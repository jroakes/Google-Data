DE112015004764T5 - CONTINUOUS PRESIDENTIAL AREA - Google Patents
CONTINUOUS PRESIDENTIAL AREA Download PDFInfo
- Publication number
- DE112015004764T5 DE112015004764T5 DE112015004764.6T DE112015004764T DE112015004764T5 DE 112015004764 T5 DE112015004764 T5 DE 112015004764T5 DE 112015004764 T DE112015004764 T DE 112015004764T DE 112015004764 T5 DE112015004764 T5 DE 112015004764T5
- Authority
- DE
- Germany
- Prior art keywords
- block
- frame
- spherical
- video
- tile
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
Images
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/50—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding
- H04N19/597—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding specially adapted for multi-view video sequence encoding
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/134—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or criterion affecting or controlling the adaptive coding
- H04N19/167—Position within a video image, e.g. region of interest [ROI]
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T11/00—2D [Two Dimensional] image generation
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/102—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or selection affected or controlled by the adaptive coding
- H04N19/103—Selection of coding mode or of prediction mode
- H04N19/105—Selection of the reference unit for prediction within a chosen coding or prediction mode, e.g. adaptive choice of position and number of pixels used for prediction
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/102—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or selection affected or controlled by the adaptive coding
- H04N19/103—Selection of coding mode or of prediction mode
- H04N19/107—Selection of coding mode or of prediction mode between spatial and temporal predictive coding, e.g. picture refresh
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/102—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or selection affected or controlled by the adaptive coding
- H04N19/124—Quantisation
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/169—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding
- H04N19/17—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding the unit being an image region, e.g. an object
- H04N19/174—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding the unit being an image region, e.g. an object the region being a slice, e.g. a line of blocks or a group of blocks
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/44—Decoders specially adapted therefor, e.g. video decoders which are asymmetric with respect to the encoder
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/50—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding
- H04N19/503—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding involving temporal prediction
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/50—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding
- H04N19/593—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding involving spatial prediction techniques
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/60—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using transform coding
- H04N19/61—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using transform coding in combination with predictive coding
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N23/00—Cameras or camera modules comprising electronic image sensors; Control thereof
- H04N23/60—Control of cameras or camera modules
- H04N23/698—Control of cameras or camera modules for achieving an enlarged field of view, e.g. panoramic image capture
Abstract
Ein Verfahren für die Codierung eines sphärischen Videos wird offenbart. Das Verfahren beinhaltet die Abbildung eines Frames des sphärischen Videos auf einer zweidimensionalen Darstellung auf Basis einer Projektion. Des Weiteren beinhaltet das Verfahren in einem Prädiktionsprozess die Ermittlung, ob sich mindestens ein Block der einem Prädiktionsschema zugeordnet ist, an einer Grenze der zweidimensionalen Darstellung befindet, und, nach dem Ermitteln, dass sich der mindestens eine Block, der dem Prädiktionsschema zugeordnet ist, an der Grenze befindet, das Auswählen eines benachbarten Endblocks als ein Block einschließlich mindestens eines Pixels für die Verwendung während des Prädiktionsprozesses, wobei der benachbarte Endblock zwei oder mehr Grenzen der zweidimensionalen Darstellung zugeordnet ist.A method for coding a spherical video is disclosed. The method involves imaging a spherical video frame on a two-dimensional representation based on a projection. Further, in a prediction process, the method includes determining whether at least one block associated with a prediction scheme is located at a boundary of the two-dimensional representation and, upon determining that the at least one block associated with the prediction scheme is present the boundary, selecting an adjacent end block as a block including at least one pixel for use during the prediction process, wherein the adjacent end block is associated with two or more boundaries of the two-dimensional representation.
Description
VERWANDTE ANWENDUNGENRELATED APPLICATIONS
Diese Anmeldung beansprucht Priorität und Nutzen aus der nicht provisorischen US-Patentanmeldung Nr. 14/518,956, eingereicht am 20. Oktober 2014, mit dem Titel „CONTINUOUS PREDICTION DOMAIN”, der nicht provisorischen US-Patentanmeldung Nr. 14/519,006, eingereicht am 20. Oktober 2014, unter dem Titel „COMPRESSING AND REPRESENTING MULTI-VIEW VIDEO”, der nicht provisorischen US-Patentanmeldung Nr. 14/518,710, eingereicht am 20. Oktober 2014, unter dem Titel „STREAMING THE VISIBLE PARTS OF A SPHERICAL VIDEO”, und der nicht provisorischen US-Patentanmeldung Nr. 14/518,779, eingereicht am 20. Oktober 2014, unter dem Titel „MAPPING SPHERICAL IMAGE TO 2D REPRESENTATIONS”, deren Inhalt durch Bezugnahme vollständig hierin aufgenommen wird.This application claims priority and benefit of U.S. Non-Provisional Patent Application No. 14 / 518,956, filed October 20, 2014, and entitled "CONTINUOUS PREDICTION DOMAIN," which is assigned to Non-Provisional US Patent Application No. 14 / 519,006, filed on May 20, 2014 October 2014, under the title "COMPRESSING AND REPRESENTING MULTI-VIEW VIDEO", the non-provisional US Patent Application No. 14 / 518,710, filed October 20, 2014, entitled "STREAMING THE VISIBLE PARTS OF A SPHERICAL VIDEO", and U.S. Non-Provisional Patent Application No. 14 / 518,779, filed October 20, 2014, entitled "MAPPING SPHERICAL IMAGE TO 2D REPRESENTATIONS," the contents of which are fully incorporated herein by reference.
TECHNISCHES GEBIETTECHNICAL AREA
Ausführungsformen beziehen sich auf die Codierung und Decodierung eines sphärischen Bildes und eines sphärischen Videos. Ausführungsformen beziehen sich auf das Streamen sphärischer Videos.Embodiments relate to the encoding and decoding of a spherical image and a spherical video. Embodiments relate to the streaming of spherical videos.
HINTERGRUNDBACKGROUND
Normalerweise wählt ein herkömmliches, zweidimensionales (2D) Intraprädiktionsschema eine Grenze von 1, 2, 3... n Pixeln links und über dem zu codierenden Block für die Ermittlung von Resten aus einem oberen oder linken rekonstruierten Block. Des Weiteren wird in einem Intraprädiktionsschema ein Referenzblock ähnlich dem zu codierenden Block mithilfe einer Bewertungsfunktion innerhalb eines Suchbereichs von mindestens einem Referenzbild gesucht. Jedoch kann es sein, dass es während der Intraprädiktion entlang einer Grenze eines 2D-Frames oder -Bildes nicht mindestens einen oberen oder linken rekonstruierten Block gibt. Des Weiteren kann der Suchbereich entlang der Grenze während der Interprädiktion begrenzt sein. Daher besteht die Notwendigkeit eines Intra-/Interprädiktionsschemas, in dem Eigenschaften eines 2D-Frames oder -Bildes, das einem sphärischen Video oder Bild entspricht, genutzt werden können.Normally, a conventional two-dimensional (2D) intra-prediction scheme selects a boundary of 1, 2, 3 ... n pixels to the left and over the block to be coded for detection of residues from an upper or left reconstructed block. Furthermore, in an intra-prediction scheme, a reference block similar to the block to be coded is searched by means of an evaluation function within a search area of at least one reference picture. However, during intra prediction along a boundary of a 2D frame or image, there may not be at least one upper or left reconstructed block. Furthermore, the search range along the boundary may be limited during the inter-prediction. Therefore, there is a need for an intra / inter prediction scheme in which characteristics of a 2D frame or image corresponding to a spherical video or image can be utilized.
Das Streamen des sphärischen Videos (oder eines anderen dreidimensionalen Videos) kann eine erhebliche Menge an Systemressourcen verbrauchen. Ein codiertes sphärisches Video kann zum Beispiel eine große Anzahl an Bits für die Übertragung beinhalten, die eine erhebliche Menge der Bandbreite sowie der Verarbeitung und des Speichers verbrauchen können, die Codierern und Decodierern zugewiesen sind.Streaming the spherical video (or other three-dimensional video) can consume a significant amount of system resources. For example, an encoded spherical video may include a large number of bits for transmission that may consume a significant amount of the bandwidth as well as the processing and memory allocated to encoders and decoders.
Bei der Codierung von Bildern und/oder Frames eines Videos werden Codierer und Decodierer normalerweise auf einer zweidimensionalen (2D) Palette betrieben. Sphärische Bilder und Videos sind dreidimensional, daher sind herkömmliche Codierer und Decodierer nicht in der Lage, sphärische Bilder und Videos zu codieren/decodieren.When encoding images and / or frames of a video, encoders and decoders are normally operated on a two-dimensional (2D) palette. Spherical images and video are three-dimensional, so conventional encoders and decoders are incapable of encoding / decoding spherical images and video.
KURZDARSTELLUNGSUMMARY
Exemplarische Ausführungsformen beschreiben Techniken für die Umwandlung sphärischer Bilder und Videos in 2D-Darstellungen und die Nutzung spezieller Eigenschaften der 2D-Darstellungen während der Codierung/Decodierung der Bilder und/oder Frames eines Videos.Exemplary embodiments describe techniques for converting spherical images and video into 2D representations, and utilizing special features of the 2D representations during encoding / decoding of the images and / or frames of a video.
In einem allgemeinen Aspekt kann ein Verfahren für das Codieren eines sphärischen Videos die Abbildung eines Frames des sphärischen Videos auf einer zweidimensionalen Darstellung auf Basis einer Projektion beinhalten. Des Weiteren kann das Verfahren in einem Prädiktionsprozess das Ermitteln beinhalten, ob sich mindestens ein Block, der einem Prädiktionsschema zugeordnet ist, an einer Grenze der zweidimensionalen Darstellung befindet, und, nach dem Ermitteln, dass sich der mindestens eine Block, der dem Prädiktionsschema zugeordnet ist, an der Grenze befindet, das Auswählen eines benachbarten Endblocks als ein Block einschließlich mindestens eines Pixels für die Verwendung während des Prädiktionsprozesses, wobei der benachbarte Endblock zwei oder mehr Grenzen der zweidimensionalen Darstellung zugeordnet ist.In a general aspect, a method of encoding a spherical video may include imaging a frame of the spherical video on a two-dimensional representation based on a projection. Further, in a prediction process, the method may include determining whether at least one block associated with a prediction scheme is at a boundary of the two-dimensional representation and, upon determining that the at least one block is associated with the prediction scheme , located at the boundary, selecting an adjacent end block as a block including at least one pixel for use during the prediction process, wherein the adjacent end block is associated with two or more boundaries of the two-dimensional representation.
Implementierungen können eines oder mehrere der folgenden Merkmale beinhalten. Der Prädiktionsprozess kann zum Beispiel ein Intraprädiktionsprozess sein, der mindestens eine Block, der dem Prädiktionsschema zugeordnet ist, kann ein zu codierender Block sein, und der benachbarte Endblock kann als ein linker rekonstruierter Block oder ein oberer rekonstruierter Block des zu codierenden Blocks ausgewählt werden. Der Prädiktionsprozess kann ein Interprädiktionsprozess sein und der mindestens eine Block, der dem Prädiktionsschema zugeordnet ist, kann ein Block sein, der in einer Vielzahl von Blöcken in einem Referenzframe enthalten ist, in dem nach einem übereinstimmenden Block gesucht werden soll. Der Prädiktionsprozess kann ein Interprädiktionsprozess sein und der mindestens eine Block, der dem Prädiktionsschema zugeordnet ist, kann als Prädiktionsblock aus einer Vielzahl von Blöcken in einem zu durchsuchenden Referenzframe ausgewählt werden, wobei die Vielzahl von Blöcken eine Grenze des Referenzframes queren.Implementations may include one or more of the following features. The prediction process may be, for example, an intra prediction process, the at least one block associated with the prediction scheme may be a block to be coded, and the neighboring end block may be selected as a left reconstructed block or an upper reconstructed block of the block to be coded. The prediction process may be an inter prediction process, and the at least one block associated with the prediction scheme may be a block contained in a plurality of blocks in a reference frame in which to search for a matching block. The prediction process may be an inter prediction process, and the at least one block associated with the prediction scheme may be selected as a prediction block from a plurality of blocks in a reference frame to be searched, wherein the plurality of blocks traverse a boundary of the reference frame.
Die Abbildung des Frames des sphärischen Videos auf der zweidimensionalen Darstellung kann zum Beispiel die Verwendung einer Gleichung beinhalten, die auf einer äquirektangulären Projektion basiert. Die Abbildung des Frames des sphärischen Videos auf der zweidimensionalen Darstellung kann die Verwendung einer Gleichung beinhalten, die auf einer semi-äquirektangulären Projektion basiert. Das Verfahren kann zum Beispiel des Weiteren nach dem Ermitteln, dass sich der zu codierende Block von der Grenze entfernt befindet, in einem Intraprädiktionsprozess das Auswählen eines benachbarten Blocks als Vorlage beinhalten, wobei der benachbarte Endblock mindestens ein linker rekonstruierter Block oder ein oberer rekonstruierter Block des zu codierenden Blocks ist. Die Auswahl des benachbarten Endblocks beinhaltet das Auswählen eines rekonstruierten Blocks aus mindestens einem entgegengesetzten Ende einer gleichen Reihe wie dem Block, der dem Prädiktionsschema zugeordnet ist, oder einem entgegengesetzten Ende derselben Spalte wie der zu codierende Block. Die Auswahl des benachbarten Endblocks beinhaltet das Auswählen eines rekonstruierten Blocks aus einer Lookup-Tabelle. For example, the mapping of the spherical video frame to the two-dimensional representation may involve the use of an equation based on an angular-angular projection. The mapping of the spherical video frame to the two-dimensional representation may involve the use of an equation based on a semi-angular-angular projection. For example, after determining that the block to be coded is away from the boundary, the method may further include selecting an adjacent block as a template in an intra prediction process, wherein the adjacent end block is at least one left reconstructed block or upper reconstructed block is to be coded blocks. The selection of the adjacent end block involves selecting a reconstructed block from at least one opposite end of a same row as the block associated with the prediction scheme or an opposite end of the same column as the block to be coded. The selection of the adjacent end block involves selecting a reconstructed block from a lookup table.
Das Verfahren kann zum Beispiel des Weiteren das Erzeugen mindestens eines Rests auf Basis nicht codierter Pixel eines zu codierenden Blocks beinhalten, das Codieren des mindestens einen Rests durch Anwendung einer Transformation auf einen restlichen Block einschließlich des mindestens einen Rests, das Quantisieren von Transformationskoeffizienten, die dem codierten mindestens einen Rest zugeordnet sind, das Entropiecodieren der quantisierten Transformationskoeffizienten als ein komprimierter Videobit-Datenstrom und das Übertragen des komprimierten Videobit-Datenstroms einschließlich eines Headers, der einen Intraframe-Codiermodus angibt, wobei der Intraframe-Codiermodus eine Technik angibt, die während der Abbildung des Frames des sphärischen Videos auf der zweidimensionalen Darstellung verwendet wird.For example, the method may further include generating at least one reminder based on unencoded pixels of a block to be coded, coding the at least one remainder by applying a transform to a remainder block including the at least one remainder, quantizing transform coefficients corresponding to the remainder of the block coded at least one remainder, entropy coding the quantized transform coefficients as a compressed video bit stream and transmitting the compressed video bit stream including a header indicating an intraframe coding mode, the intraframe coding mode indicating a technique during the mapping of the spherical video frame is used on the two-dimensional representation.
In einem allgemeinen Aspekt beinhaltet ein Verfahren für die Decodierung eines sphärischen Videos das Empfangen eines codierten Bit-Datenstroms einschließlich eines Headers, der einen Intraframe-Codiermodus angibt, wobei der Intraframe-Codiermodus eine Technik angibt, die während einer Umwandlung eines Frames eines sphärischen Videos in eine zweidimensionale Darstellung verwendet wird. Des Weiteren kann das Verfahren in einem Prädiktionsprozess die Ermittlung beinhalten, ob sich mindestens ein Block, der einem Prädiktionsschema zugeordnet ist, an einer Grenze der zweidimensionalen Darstellung befindet, nach dem Ermitteln, dass sich der mindestens eine Block, der dem Prädiktionsschema zugeordnet ist, an der Grenze befindet, das Auswählen eines benachbarten Endblocks als ein Block einschließlich mindestens eines Pixels für die Verwendung während des Prädiktionsprozesses, wobei der benachbarte Endblock zwei oder mehr Grenzen der zweidimensionalen Darstellung zugeordnet ist. Das Verfahren beinhaltet des Weiteren das Umwandeln der zweidimensionalen Darstellung in einen Frame des sphärischen Videos auf Basis einer zylindrischen Projektion.In a general aspect, a method for decoding a spherical video includes receiving a coded bitstream including a header indicating an intraframe coding mode, the intraframe coding mode indicating a technique that is used during a conversion of a spherical video frame into a two-dimensional representation is used. Furthermore, in a prediction process, the method may include determining whether at least one block associated with a prediction scheme is at a boundary of the two-dimensional representation, after determining that the at least one block associated with the prediction scheme is on the boundary, selecting an adjacent end block as a block including at least one pixel for use during the prediction process, wherein the adjacent end block is associated with two or more boundaries of the two-dimensional representation. The method further includes converting the two-dimensional representation into a spherical video frame based on a cylindrical projection.
Implementierungen können eines oder mehrere der folgenden Merkmale beinhalten. Das Umwandeln der zweidimensionalen Darstellung kann zum Beispiel die Abbildung der zweidimensionalen Darstellung auf einem sphärischen Bild mithilfe einer Gleichung beinhalten, die auf der inversen Transformation einer Projektion basiert. Der Prädiktionsprozess kann ein Intraprädiktionsprozess sein, der mindestens eine Block, der dem Prädiktionsschema zugeordnet ist, kann ein zu codierender Block sein, und der benachbarte Endblock kann als ein linker rekonstruierter Block oder ein oberer rekonstruierter Block ausgewählt werden. Der Prädiktionsprozess kann zum Beispiel ein Interprädiktionsprozess sein und der mindestens eine Block, der dem Prädiktionsschema zugeordnet ist, kann ein Block sein, der in einer Vielzahl von Blöcken in einem Referenzframe beinhaltet ist, in dem nach einem übereinstimmenden Block gesucht werden soll. Der Prädiktionsprozess kann ein Interprädiktionsprozess sein und der mindestens eine Block, der dem Prädiktionsschema zugeordnet ist, kann als Prädiktionsblock aus einer Vielzahl von Blöcken in einem zu durchsuchenden Referenzframe ausgewählt werden, wobei die Vielzahl von Blöcken eine Grenze des Referenzframes queren.Implementations may include one or more of the following features. For example, converting the two-dimensional representation may involve mapping the two-dimensional representation on a spherical image using an equation based on the inverse transformation of a projection. The prediction process may be an intra prediction process, the at least one block associated with the prediction scheme may be a block to be coded, and the neighboring end block may be selected as a left reconstructed block or an upper reconstructed block. The prediction process may be, for example, an inter prediction process, and the at least one block associated with the prediction scheme may be a block included in a plurality of blocks in a reference frame in which to search for a matching block. The prediction process may be an inter prediction process, and the at least one block associated with the prediction scheme may be selected as a prediction block from a plurality of blocks in a reference frame to be searched, wherein the plurality of blocks traverse a boundary of the reference frame.
In einen allgemeinen Aspekt kann auf einem nicht flüchtigen, computerlesbaren Speichermedium computerlesbarer Programmcode gespeichert sein, der, wenn er auf einem Computersystem ausgeführt wird, das Computersystem veranlasst, Schritte einschließlich der Abbildung eines Frames des sphärischen Videos auf einer zweidimensionalen Darstellung auf Basis einer Projektion durchzuführen. Des Weiteren können die Schritte in einem Prädiktionsprozess die Ermittlung beinhalten, ob sich mindestens ein Block, der einem Prädiktionsschema zugeordnet ist, an einer Grenze der zweidimensionalen Darstellung befindet, und, nach dem Ermitteln, dass sich der mindestens eine Block, der dem Prädiktionsschema zugeordnet ist, an der Grenze befindet, das Auswählen eines benachbarten Endblocks als ein Block einschließlich mindestens eines Pixels für die Verwendung während des Prädiktionsprozesses, wobei der benachbarte Endblock zwei oder mehr Grenzen der zweidimensionalen Darstellung zugeordnet ist.In a general aspect, computer readable program code may be stored on a non-transitory computer-readable storage medium which, when executed on a computer system, causes the computer system to perform steps including mapping a spherical video frame onto a two-dimensional representation based on a projection. Further, the steps in a prediction process may include determining whether at least one block associated with a prediction scheme is at a boundary of the two-dimensional representation and, upon determining that the at least one block is associated with the prediction scheme , located at the boundary, selecting an adjacent end block as a block including at least one pixel for use during the prediction process, wherein the adjacent end block is associated with two or more boundaries of the two-dimensional representation.
Implementierungen können eines oder mehrere der folgenden Merkmale beinhalten. Der Prädiktionsprozess kann zum Beispiel ein Intraprädiktionsprozess sein, der mindestens eine Block, der dem Prädiktionsschema zugeordnet ist, kann ein zu codierender Block sein, und der benachbarte Endblock kann als ein linker rekonstruierter Block oder ein oberer rekonstruierter Block des zu codierenden Blocks ausgewählt werden. Der Prädiktionsprozess kann zum Beispiel ein Interprädiktionsprozess sein und der mindestens eine Block, der dem Prädiktionsschema zugeordnet ist, kann ein Block sein, der in einer Vielzahl von Blöcken in einem Referenzframe beinhaltet ist, in dem nach einem übereinstimmenden Block gesucht werden soll. Der Prädiktionsprozess kann ein Interprädiktionsprozess sein und der mindestens eine Block, der dem Prädiktionsschema zugeordnet ist, kann als Prädiktionsblock aus einer Vielzahl von Blöcken in einem zu durchsuchenden Referenzframe ausgewählt werden, wobei die Vielzahl von Blöcken eine Grenze des Referenzframes queren. Die Auswahl des benachbarten Endblocks kann das Auswählen eines rekonstruierten Blocks aus mindestens einem entgegengesetzten Ende einer gleichen Reihe wie dem Block, der dem Prädiktionsschema zugeordnet ist, oder einem entgegengesetzten Ende derselben Spalte wie der zu codierende Block, beinhalten.Implementations may include one or more of the following features. The prediction process can for example be Intra-prediction process, the at least one block associated with the prediction scheme may be a block to be coded, and the neighboring end block may be selected as a left reconstructed block or an upper reconstructed block of the block to be coded. The prediction process may be, for example, an inter prediction process, and the at least one block associated with the prediction scheme may be a block included in a plurality of blocks in a reference frame in which to search for a matching block. The prediction process may be an inter prediction process, and the at least one block associated with the prediction scheme may be selected as a prediction block from a plurality of blocks in a reference frame to be searched, wherein the plurality of blocks traverse a boundary of the reference frame. The selection of the adjacent end block may include selecting a reconstructed block from at least one opposite end of a same row as the block associated with the prediction scheme or an opposite end of the same column as the block to be coded.
KURZBESCHREIBUNG DER ZEICHNUNGENBRIEF DESCRIPTION OF THE DRAWINGS
Exemplarische Ausführungsformen werden aus der hierin unten gegebenen genauen Beschreibung und den begleitenden Beschreibungen besser verständlich, wobei ähnliche Elemente durch ähnliche Bezugsnummern dargestellt werden, die nur der Veranschaulichung dienen und somit die exemplarischen Ausführungsformen nicht begrenzen, und wobei:Exemplary embodiments will be better understood from the detailed description given hereinbelow and the accompanying descriptions, wherein like elements are represented by like reference numerals, which are given by way of illustration only, and thus do not limit the exemplary embodiments, and wherein:
Es sollte beachtet werden, dass diese Figuren dazu gedacht sind, die allgemeinen Eigenschaften der in gewissen exemplarischen Ausführungsformen verwendeten Verfahren, Struktur und/oder Materialien und die unten bereitgestellte schriftliche Beschreibung zu ergänzen. Diese Zeichnungen sind jedoch nicht maßstabsgetreu und es kann sein, dass sie nicht den exakten strukturellen oder Leistungseigenschaften einer bestimmten Ausführungsform entsprechen. Sie sollten nicht als Definition oder Begrenzung des Bereichs der Werte oder Eigenschaften interpretiert werden, die die exemplarischen Ausführungsformen beinhalten. Die relative Dicke oder Positionierung struktureller Elemente können zum Beispiel zur besseren Übersichtlichkeit verkleinert oder vergrößert sein. Die Verwendung von ähnlichen oder identischen Referenznummern in den verschiedenen Zeichnungen soll auf das Vorhandensein von ähnlichen oder identischen Elementen oder Funktionen hinweisen.It should be noted that these figures are intended to supplement the general characteristics of the methods, structure and / or materials used in certain exemplary embodiments and the written description provided below. However, these drawings are not to scale and may not conform to the exact structural or performance characteristics of a particular embodiment. They should not be interpreted as defining or limiting the range of values or properties that include the exemplary embodiments. The relative thickness or positioning of structural elements may, for example, be reduced or increased for clarity. The use of similar or identical reference numbers in the various drawings is intended to indicate the presence of similar or identical elements or functions.
DETAILLIERTE BESCHREIBUNG DER AUSFÜHRUNGSFORMENDETAILED DESCRIPTION OF THE EMBODIMENTS
Obwohl exemplarische Ausführungsformen verschiedene Änderungen und alternative Formen beinhalten können, werden dazugehörige Ausführungsformen in den Zeichnungen als Beispiele dargestellt und werden hierin im Detail beschrieben. Es sollte aber beachtet werden, dass es nicht beabsichtigt ist, die exemplarischen Ausführungsformen auf die offenbarten besonderen Formen zu beschränken, sondern dass die exemplarischen Ausführungsformen im Gegenteil alle Änderungen, Äquivalente und Alternativen abdecken sollen, die in den Umfang dieser Ansprüche fallen. In der gesamten Beschreibung der Figuren beziehen sich ähnliche Nummern auf ähnliche Elemente.Although exemplary embodiments may include various changes and alternative forms, corresponding embodiments are illustrated in the drawings as examples and will be described in detail herein. It should be noted, however, that it is not intended to limit the exemplary embodiments to the particular forms disclosed, but on the contrary, that the exemplary embodiments are intended to cover all changes, equivalents, and alternatives that fall within the scope of these claims. Throughout the description of the figures, similar numbers refer to similar elements.
Im Beispiel in
Der mindestens eine Prozessor
Der mindestens eine Speicher
Der Controller
Der Videocodierer
Die komprimierten Videobits
Der mindestens eine Prozessor
Im Beispiel in
Somit kann der mindestens eine Prozessor
Der mindestens eine Speicher
Der Controller
Der Videodecodierer
Der mindestens eine Prozessor
Jeder der vorher erwähnten Blöcke kann als Softwarecode ausgeführt werden, der in einem Speicher (z. B. dem mindestens einen Speicher
Der Block der sphärischen-zu-2D-Darstellung
Der Prädiktionsblock
Der Transformationsblock
Der Transformationsblock
Der Quantisierungsblock
Die quantisierten Transformationskoeffizienten werden dann durch den Entropiecodierungsblock
Der Rekonstruktionspfad in
Der oben in Bezug auf
Die Datenelemente in den komprimierten Videobits
Unter Verwendung von Headerinformationen, die aus den komprimierten Videobits
Der Block der sphärischen-zu-2D-Darstellung
Der oben in Bezug auf
Der Codierer
Ein sphärisches Bild kann eine Perspektive haben. Ein sphärisches Bild könnte zum Beispiel das Bild eines Globus sein. Eine Innenperspektive könnte eine Sicht aus der Mitte des Globus nach außen sein. Oder die Innenperspektive könnte auf dem Globus, nach außen in den Weltraum blickend sein. Eine Außenperspektive könnte eine Sicht aus dem Weltraum, nach unten auf den Globus blickend sein. Als weiteres Beispiel kann die Perspektive darauf basieren, was sichtbar ist. Mit anderen Worten, eine sichtbare Perspektive kann die sein, die von einem Betrachter gesehen werden kann. Die sichtbare Perspektive kann ein Teil des sphärischen Bildes sein, das sich vor dem Betrachter befindet. Bei der Sicht aus einer Innenperspektive könnte ein Betrachter zum Beispiel am Boden (z. B. auf der Erde) liegen und in den Weltraum hinaus blicken. Der Betrachter könnte im Bild den Mond, die Sonne oder bestimmte Sterne sehen. Jedoch befindet sich, auch wenn der Boden, auf dem der Betrachter liegt, im sphärischen Bild enthalten ist, der Boden außerhalb der zurzeit sichtbaren Perspektive. In diesem Beispiel könnte der Betrachter seinen Kopf drehen und der Boden wäre in einer peripheren sichtbaren Perspektive enthalten. Der Betrachter könnte sich umdrehen und der Boden wäre in der sichtbaren Perspektive, der Mond, die Sonne oder die Sterne dagegen nicht.A spherical image can have a perspective. For example, a spherical image could be the image of a globe. An interior perspective could be a view from the center of the globe to the outside. Or the inner perspective could be on the globe, looking out into space. An outside perspective could be a view from space, looking down on the globe. As another example, the perspective may be based on what is visible. In other words, a visible perspective can be the one that can be seen by a viewer. The visible perspective may be part of the spherical image that is in front of the viewer. For example, when viewing from an interior perspective, a viewer might be lying on the ground (eg, on the ground) and looking out into space. The viewer could see in the picture the moon, the sun or certain stars. However, even if the floor on which the viewer is lying is contained in the spherical image, the floor is outside the currently visible perspective. In this example, the viewer could turn his head and the floor would be contained in a peripheral visible perspective. The viewer could turn around and the ground would be in the visible perspective, the moon, the sun or the stars, however, not.
Eine sichtbares Perspektive aus einer Außenperspektive könnte ein Teil eines sphärischen Bildes sein, das nicht blockiert ist (z. B. durch einen anderen Teil des Bildes) und/oder ein Teil des sphärischen Bildes, das nicht aus der Sicht nach außen gekrümmt ist. Ein anderer Teil des sphärischen Bildes kann in aus einer Außenperspektive in eine sichtbare Perspektive gebracht werden, indem das sphärische Bild bewegt (z. B. gedreht) wird und/oder durch Bewegung des sphärischen Bildes. Daher ist die sichtbare Perspektive ein Teil des sphärischen Bildes, der sich innerhalb eines sichtbaren Bereichs eines Betrachters des sphärischen Bildes befindet.A visible perspective from an outside perspective could be part of a spherical image that is not blocked (eg, by another part of the image) and / or a part of the spherical image that is not outwardly curved. Another part of the spherical image may be brought into a visible perspective from an outside perspective by moving (e.g., rotating) the spherical image and / or by moving the spherical image. Therefore, the visible perspective is part of the spherical image that is within a visible area of a viewer of the spherical image.
Ein sphärisches Bild ist ein Bild, das sich in Bezug auf die Zeit nicht ändert. Ein sphärisches Bild aus einer Innenperspektive in Bezug auf die Erde kann den Mond und die Sterne in einer Position zeigen. Dagegen kann sich ein sphärisches Video (oder eine Reihe von Bildern) in Bezug auf die Zeit ändern. Ein sphärisches Bild aus einer Innenperspektive in Bezug auf die Erde kann zum Beispiel den Mond und die Sterne in Bewegung (z. B. aufgrund der Erdrotation) und/oder einen Flugzeugstreifen über das Bild (z. B. den Himmel) zeigen.A spherical image is an image that does not change with time. A spherical image from an interior perspective with respect to the earth can show the moon and the stars in one position. In contrast, a spherical video (or a series of images) may change with time. For example, a spherical image from an interior perspective with respect to the earth may show the moon and the stars in motion (eg, due to the Earth's rotation) and / or an aircraft's stripes over the image (eg, the sky).
In einer anderen exemplarischen Implementierung kann die Projektion semi-äquirektangulär sein. In einer semi-äquirektangulären Projektion wird jede horizontale Linie auf dem Zylinder als eine gerade Linie über die Mitte des Bildes abgebildet, wobei die vertikale Linie genauso wie bei der äquirektangulären Projektion vertikal bleibt. Wenn die horizontale Linie jedoch immer näher zu den Polen A und B gelangt, kann das Bild auf den Zylinder projiziert werden, ohne Dehnung oder mit verringerter Dehnung (z. B. skaliert). In der semi-äquirektangulären Projektion sind Teile des Bildes, die auf den Zylinder projiziert werden, leere oder Nullpixel. Die leeren oder Nullpixel können als schwarze oder weiße (oder eine andere konstante Pixeldarstellung) Pixel dargestellt werden. Mathematisch kann die semi-äquirektanguläre Projektion als x = aλcosθ und y = bθ definiert werden, wobei λ der Längengrad und θ der Breitengrad ist und wobei a und b Skalierungsfaktoren sind. Andere zylindrische Projektionen entsprechen dem Umfang dieser Offenbarung.In another exemplary implementation, the projection may be semi-angular ectectangular. In a semi-angular projection, each horizontal line on the cylinder is imaged as a straight line across the center of the image, with the vertical line remaining vertical, as in the angular-angular projection. However, as the horizontal line gets closer and closer to the poles A and B, the image can be projected onto the cylinder without strain or with reduced strain (eg, scaled). In the semi-angular-angular projection, portions of the image projected onto the cylinder are blank or zero pixels. The blank or null pixels can be represented as black or white (or other constant pixel representation) pixels. Mathematically, the semi-angular-angular projection can be defined as x = aλcosθ and y = bθ, where λ is the longitude and θ is the latitude and where a and b are scaling factors. Other cylindrical projections are within the scope of this disclosure.
In Schritt S510 wird die zylindrische Darstellung in einer rechteckigen 2D-Darstellung abgewickelt. Zylinder
In Schritt S515 wird die rechteckige 2D-Darstellung in eine C×R-Matrix von N×N-Blöcken zerlegt. Wie zum Beispiel in
In Schritt S520 sind Nullblöcke bezeichnet. In einer semi-äquirektangulären Projektion kann zum Beispiel eine Anzahl an Blöcken leere oder Nullpixel beinhalten. Blöcke, die alle, die meisten oder einen erheblichen Teil leere oder Nullpixel beinhalten, können als Nullblöcke bezeichnet werden. Wenn die Blöcke zum Beispiel 2×2 Blöcke sind, können alle Blöcke, die zum Beispiel eine Schwellenwertanzahl oder einen Prozentsatz von leeren oder Nullpixeln beinhalten, als Nullblöcke bezeichnet werden. Nullblöcke können in einer Tabelle oder Lookup-Tabelle gespeichert werden. Nullblöcke können zum Beispiel in der Lookup-Tabelle
Wie oben erörtert, ist ein sphärisches Bild ein Bild, das in alle Richtungen kontinuierlich ist. Demgemäß sind, wenn das sphärische Bild in eine Vielzahl von Blöcken zerlegt wird, die Vielzahl von Blöcken über das sphärische Bild fortlaufend. Mit anderen Worten, es gibt keine Ränder oder Grenzen wie in einem 2D-Bild. In exemplarischen Implementierungen kann ein benachbarter Endblock neben einer Grenze der 2D-Darstellung liegen. Außerdem kann ein benachbarter Endblock ein fortlaufender Block zu einem Block an der Grenze der 2D-Darstellung sein. Der benachbarte Endblock ist zum Beispiel zwei oder mehr Grenzen der zweidimensionalen Darstellung zugeordnet. Mit anderen Worten, da ein sphärisches Bild ein Bild ist, das in alle Richtungen fortlaufend ist, kann ein benachbarter Endblock einer oberen Grenze (z. B. einer Spalte von Blöcken) und einer unteren Grenze in einem Bild oder Frame zugewiesen und/oder einer linken Grenze (z. B. einer Reihe von Blöcken) und einer rechten Grenze in einem Bild oder Frame zugewiesen sein.As discussed above, a spherical image is an image that is continuous in all directions. Accordingly, when the spherical image is decomposed into a plurality of blocks, the plurality of blocks are continuous over the spherical image. In other words, there are no borders or borders as in a 2D image. In exemplary implementations, an adjacent endblock may be adjacent to a boundary of the 2D representation. In addition, an adjacent end block may be a contiguous block to a block at the boundary of the 2D representation. For example, the adjacent end block is associated with two or more boundaries of the two-dimensional representation. In other words, since a spherical image is an image that is continuous in all directions, an adjacent end block may be assigned and / or assigned to an upper bound (eg, a column of blocks) and a lower bound in an image or frame assigned to a left boundary (eg, a series of blocks) and a right boundary in a picture or frame.
Wenn zum Beispiel äquirektanguläre Projektion verwendet wird, kann ein benachbarter Endblock der Block am anderen Ende der Spalte oder Reihe sein. Wie in
Demgemäß werden in Schritt S525 benachbarte Endblöcke zugeordnet. Wie oben erörtert, kann in einer semi-äquirektangulären Projektion zum Beispiel eine Anzahl an Blöcken leere oder Nullpixel beinhalten. Daher kann es sein, dass sich ein Endblock in einer Reihe oder Spalte nicht unten oder oben in einer Reihe und/oder links oder rechts von einer Spalte befindet. Demgemäß kann es bei Blöcken, die sich am Ende eines Bildes, aber nicht am Ende einer Spalte oder Reihe befinden (z. B. Block
Die Nutzung der räumlichen Redundanz zwischen Mustern innerhalb eines Frames (z. B. Frame, Bild, Schicht, Gruppe von Makroblöcken) wird als Intraprädiktion bezeichnet. Bei der Intraprädiktion kann eine Vorlage aus früher codierten und rekonstruierten Blöcken, Pixeln oder Subpixeln (z. B. 1/2, 1/4 und dergleichen) in demselben Frame (oder Bild) erzeugt werden. Die Vorlage wird vor der Codierung aus dem aktuellen Block subtrahiert. Bei Luminanz(Luma)-Proben kann die Vorlage zum Beispiel für jeden N×N(z. B. 4×4)-Teilblock oder für einen N×N(z. B. 16×16)-Makroblock gebildet werden. Bei der Codierung und/oder Decodierung können die Blöcke oder Makroblöcke sequenziell innerhalb jedes Frames oder jede Schicht codiert werden. Gemäß exemplarischen Ausführungsformen beinhaltet die räumliche Redundanz die Berücksichtigung der kontinuierlichen Natur des Frames auf Basis eines sphärischen Videos oder Bildes. Demgemäß kann Intraprädiktion eine Vorlage auf Basis früher codierter und rekonstruierter Blöcke, Pixel oder Subpixel (z. B. 1/2, 1/4 und dergleichen) über Grenzen hinweg in demselben Frame (oder Bild) verwenden.The use of spatial redundancy between patterns within a frame (eg, frame, image, layer, group of macroblocks) is referred to as intra prediction. In intraprediction, a template may be generated from previously coded and reconstructed blocks, pixels, or subpixels (eg, 1/2, 1/4, and the like) in the same frame (or image). The template is subtracted from the current block before encoding. For luminance (luma) samples, the template may be for Example, for each N × N (eg 4 × 4) sub-block or for an N × N (eg 16 × 16) macroblock are formed. In coding and / or decoding, the blocks or macroblocks may be encoded sequentially within each frame or layer. According to exemplary embodiments, the spatial redundancy includes considering the continuous nature of the frame based on a spherical video or image. Accordingly, intra-prediction may use a template based on previously coded and reconstructed blocks, pixels, or sub-pixels (eg, 1/2, 1/4, and the like) across boundaries in the same frame (or image).
Bei der Intraprädiktion kann ein Codierdurchlauf die sequenzielle Codierung von Blöcken entlang einer Reihe (z. B. von oben nach unten), einer Spalte (z. B. von links nach rechts) oder eines Zickzack-Musters (z. B. beginnend in der oberen linken Ecke) beinhalten. In einem Intraprädiktionsschema oder Codierdurchlauf wurden die Blöcke, die sich über dem und links vom aktuellen Block im Frame (oder Bild) befinden, früher codiert und rekonstruiert. Demgemäß können die Blöcke, die sich über dem und links vom aktuellen Block befinden, für den Codierer/Decodierer als Vorlage verfügbar sein. Wenn sich der aktuelle Block (oder der zu codierende Block) jedoch in der oberen linken Ecke eines Frames befinden, wurden keine früheren Blöcke im Frame früher codiert und rekonstruiert oder decodiert. Des Weiteren wurden, wenn sich der aktuelle Block in der oberen Reihe eines Frames befindet, keine Nachbarn über dem aktuellen Block (oder dem zu codierenden Block) früher codiert und rekonstruiert oder decodiert. Noch des Weiteren wurden, wenn sich der aktuelle Block (oder der zu codierende Block) in der linken Spalte eines Frames befinden, keine zwei Nachbarn in derselben Reihe wie der aktuelle Block früher codiert und rekonstruiert oder decodiert.In intraprediction, a coding pass may include the sequential encoding of blocks along a row (eg, from top to bottom), a column (eg, from left to right), or a zigzag pattern (eg, starting in the left) upper left corner). In an intra-prediction scheme or coding pass, the blocks that are above and to the left of the current block in the frame (or picture) have been earlier coded and reconstructed. Accordingly, the blocks that are above and to the left of the current block may be available to the encoder / decoder as a template. However, if the current block (or block to be encoded) is in the upper left corner of a frame, no previous blocks in the frame have been previously encoded and reconstructed or decoded. Furthermore, if the current block is in the top row of a frame, no neighbors above the current block (or block to be coded) were earlier coded and reconstructed or decoded. Still further, when the current block (or block to be encoded) is in the left column of a frame, no two neighbors in the same row as the current block were previously encoded and reconstructed or decoded.
Die Nutzung der räumlichen Redundanz für Muster zwischen Frames (z. B. Frame, Bild, Schicht, Gruppe von Makroblöcken) wird als Interprädiktion bezeichnet. Bei der Interprädiktion kann ein Prädiktionsblock als Reaktion auf früher codierte und rekonstruierte Blöcke in einem anderen (z. B. im Zeitverlauf früheren oder Basis/Vorlagen)-Frame erzeugt werden.The use of spatial redundancy for patterns between frames (eg, frame, image, layer, group of macroblocks) is called inter-prediction. In interprediction, a prediction block may be generated in response to previously coded and reconstructed blocks in another (eg, earlier or base / template) frame.
Bei der Interprädiktion kann der aktuelle Frame in Blöcke (z. B. Makroblöcke) von fester Größe aufgeteilt werden. Um einen Block (z. B. einen aktuellen Block oder einen zu codierenden Block) zu codieren, wird ein am besten passender Block im Referenzframe gesucht. Die Suche kann zum Beispiel das Durchsuchen eines Suchbereichs eines Referenzframes beinhalten. Es wird ein Vergleich zwischen dem Makroblock im aktuellen Frame mit möglichen Kandidaten-Makroblöcken durchgeführt, um einen passenden (z. B. eine weitgehende oder gute Übereinstimmung) Kandidaten-Makroblock zu finden. Kandidaten-Makroblöcke können im Suchbereich zum Beispiel auf Basis einer gewünschten Bewegungsschätzungsauflösung, dem Unterschied zwischen dem Makroblock des aktuellen Frames und dem Kandidaten-Makroblock, den Verarbeitungskosten der Codierung des Bewegungsvektors für diesen Makroblock oder dergleichen geprüft werden (z. B. Pixel für Pixel und/oder Subpixel für Subpixel). Gemäß exemplarischen Ausführungsformen beinhaltet die räumliche Redundanz die Berücksichtigung der kontinuierlichen Natur des Frames auf Basis eines sphärischen Videos oder Bildes. Demgemäß kann Interprädiktion einen Suchbereich eines Referenzframes einschließlich Blöcken, Pixeln oder Subpixeln (z. B. 1/2, 1/4 und dergleichen) über Grenzen im Referenzframe (oder Bild) hinweg verwenden, um einen am besten passenden Block, einen Kandidatenblock und/oder einen Prädiktionsblock auszuwählen.In interprediction, the current frame can be divided into blocks (eg, macroblocks) of fixed size. To code a block (eg, a current block or a block to be coded), a best matching block in the reference frame is searched for. The search may include, for example, searching a search scope of a reference frame. A comparison is made between the macroblock in the current frame with candidate candidate macroblocks to find an appropriate (eg, a broad or good match) candidate macroblock. For example, candidate macroblocks may be examined in the search area based on a desired motion estimation resolution, the difference between the current frame's macroblock and the candidate macroblock, the processing cost of encoding the motion vector for that macroblock, or the like (eg, pixel by pixel and the like) / or subpixels for subpixels). According to exemplary embodiments, the spatial redundancy includes considering the continuous nature of the frame based on a spherical video or image. Accordingly, inter-prediction may use a search range of a reference frame including blocks, pixels, or sub-pixels (eg, 1/2, 1/4, and the like) across boundaries in the reference frame (or image) to obtain a best fit block, a candidate block, and / or select a prediction block.
In Schritt S610 wird ermittelt, ob sich ein Block, der einem Prädiktionsschema zugeordnet ist, an/auf einer Framegrenze (oder Bildgrenze) der rechteckigen 2D-Darstellung befindet (oder Blöcke eine solche Grenze beinhalten). Der zugeordnete Block (oder die zugeordneten Blöcke) können ein oder mehrere benachbarten linke oder obere Blöcke in einer Intraprädiktionsimplementierung sein. Alternativ können der Block oder die Blöcke ein oder mehrere Blöcke innerhalb eines Suchbereichs eines Referenzframes in einer Interprädiktionsimplementierung sein. In einer exemplarischen Ausführungsform kann zum Beispiel eine C×R-Matrix von N×N-Blöcken Pixel in jedem Block beinhalten (z. B. wenn eine äquirektanguläre Projektion verwendet wird). Demgemäß beinhalten Blöcke in Reihe 0, Spalte 0, Reihe R-1 und Spalte C-1 Pixel des sphärischen Bildes. Daher befindet sich, wenn die C×R-Matrix der Blöcke während eines Scans oder einer Suche Pixel in jedem Block beinhaltet (z. B. äquirektanguläre Projektion) und die Spalte/Reihe = 0 oder die Spalte/Reihe = C-1/R-1 ist, der Block an der Grenze.In step S610, it is determined whether a block associated with a prediction scheme is at (or blocks include such a boundary) on / at a frame boundary (or frame boundary) of the 2D rectangular representation. The associated block (or blocks) may be one or more adjacent left or top blocks in an intraprediction implementation. Alternatively, the block or blocks may be one or more blocks within a search range of a reference frame in an inter prediction implementation. For example, in an exemplary embodiment, a CxR matrix of NxN blocks may include pixels in each block (eg, when an eighteen-angular projection is used). Accordingly, blocks in row 0, column 0, row R-1, and column C-1 include pixels of the spherical image. Therefore, if the CxR matrix of the blocks during a scan or search includes pixels in each block (eg, angular projection) and column / row = 0 or column / row = C-1 / R -1 is the block on the border.
In einer weiteren exemplarischen Implementierung beinhaltet eine N×N-Matrix von Blöcken mindestens einen Nullblock oder leere oder Nullpixel in mindestens einem Block (z. B. wenn eine semi-äquirektanguläre Projektion verwendet wird). Daher befindet sich, wenn ein benachbarter Block während eines Scans oder einer Suche ein Nullblock ist, der Block an einer Grenze. Um zum Beispiel zu ermitteln, ob ein benachbarter Block ein Nullblock ist, kann der benachbarte Block in einer Lookup-Tabelle (z. B. LUT
In Schritt S615 wird ein benachbarter Endblock/werden benachbarte Endblöcke nachgeschlagen. In einer exemplarischen Implementierung kann zum Beispiel eine C×R-Matrix von N×N-Blöcken Pixel in jedem Block beinhalten (wenn beispielsweise eine äquirektanguläre Projektion verwendet wird). Demgemäß ist ein benachbarter Endblock, der einer Spalte für einen Block in Reihe 0 zugeordnet ist, ein Block in Reihe R-1. Des Weiteren ist ein benachbarter Endblock, der einer Spalte für einen Block in Reihe R-1 zugeordnet ist, ein Block in Reihe 0. Ein benachbarter Endblock, der einer Reihe für einen Block in Spalte 0 zugeordnet ist, ist ein Block in Spalte C-1. Und schließlich, ist ein benachbarter Endblock, der einer Reihe für einen Block in Spalte C-1 zugeordnet ist, ein Block in Spalte 0. In einer weiteren exemplarischen Implementierung beinhaltet zum Beispiel eine C×R-Matrix von Blöcken Nullblöcke (z. B. wenn eine semi-äquirektanguläre Projektion verwendet wird). In diesem Beispiel können Spalten und Reihen benachbarter Endblöcke in einer Lookup-Tabelle (z. B. LUT
In Schritt S620 wird mindestens ein Block einschließlich eines benachbarten Endblocks ausgewählt. In einem Intraprädiktionsschema kann mindestens ein benachbarter Endblock als Vorlage ausgewählt werden. Mit anderen Worten, ein oder mehrere der 1, 2, 3, ..., n Pixel links vom und/oder über dem zu codierenden Block können aus der Vorlage ausgewählt werden, die aus mindestens einem benachbarten Endblock ausgewählt werden kann. Der benachbarte Endblock ist zwei oder mehr Grenzen der zweidimensionalen Darstellung zugeordnet. Die Auswahl des benachbarten Endblocks kann das Auswählen eines rekonstruierten Blocks aus mindestens einem entgegengesetzten Ende einer gleichen Reihe wie dem Block, der dem Prädiktionsschema zugeordnet ist, oder einem entgegengesetzten Ende derselben Spalte wie der zu codierende Block, beinhalten.In step S620, at least one block including an adjacent end block is selected. In an intra prediction scheme, at least one adjacent endblock can be selected as a template. In other words, one or more of the 1, 2, 3, ..., n pixels to the left of and / or over the block to be coded can be selected from the template that can be selected from at least one adjacent end block. The adjacent end block is associated with two or more boundaries of the two-dimensional representation. The selection of the adjacent end block may include selecting a reconstructed block from at least one opposite end of a same row as the block associated with the prediction scheme or an opposite end of the same column as the block to be coded.
Der benachbarte Endblock kann zum Beispiel ein rekonstruierter Endblock außer einem linken rekonstruierten Endblock oder einem oberen rekonstruierten Endblock des (oder im Vergleich zu dem) zu codierenden Blocks sein. Mit anderen Worten, ein benachbarter Endblock befindet sich während des Intraprädiktionsscans der nicht codierten Blöcke nicht über dem oder links vom zu codierenden Block. Wie oben erörtert, kann zum Beispiel während der Intraprädiktion eine Vorlage auf Basis früher codierter und rekonstruierter Blöcke in demselben Frame (oder Bild) erzeugt werden. Der früher codierte und rekonstruierte Block/die früher codierten und rekonstruierten Blöcke können aus benachbarten Blöcken (z. B. einem Block, der sich über dem und/oder links vom zu codierenden Block befindet) als Vorlage ausgewählt werden. In diesem Fall befindet sich der zu codierende Block am Ende einer Spalte und/oder Reihe in der C×R-Matrix oder neben einem Nullblock (z. B. der Block darüber ist null oder der linke Block ist null). Mit anderen Worten, ein Block der als Vorlage verwendet werden würde, ist nicht vorhanden oder ist ein Nullblock. Demgemäß kann mindestens einer der benachbarten Blöcke, der als Vorlage ausgewählt werden soll, einer der nachgeschlagenen benachbarten Endblöcke sein.The adjacent end block may, for example, be a reconstructed end block other than a left reconstructed end block or an upper reconstructed end block of (or compared to) the block to be coded. In other words, an adjacent end block is not above or to the left of the block to be coded during the intra prediction scan of the unencoded blocks. For example, as discussed above, during intraprediction, a template may be generated based on previously encoded and reconstructed blocks in the same frame (or image). The previously coded and reconstructed block (s) may be selected from adjacent blocks (eg, a block located above and / or to the left of the block to be coded) as a template. In this case, the block to be coded is at the end of a column and / or row in the CxR matrix or next to a null block (eg, the block above it is zero or the left block is zero). In other words, a block that would be used as a template does not exist or is a null block. Accordingly, at least one of the adjacent blocks to be selected as a template may be one of the looked-up adjacent end blocks.
In einem Interprädiktionsschema kann mindestens ein benachbarter Block als Block in einem Suchbereich eines Referenzframes ausgewählt werden. Demgemäß kann mindestens ein benachbarter Block als am besten passender Block, Kandidatenblock und/oder Prädiktionsblock ausgewählt werden.In an inter prediction scheme, at least one neighboring block may be selected as a block in a search area of a reference frame. Accordingly, at least one neighboring block may be selected as the best matching block, candidate block, and / or prediction block.
In Schritt S625 wird mindestens ein Block auswählt. In diesem Fall beinhaltet der mindestens eine Block keinen benachbarten Endblock. In einem Intraprädiktionsschema können zum Beispiel der vorher codierte und rekonstruierte Block/die früher codierten und rekonstruierten Blöcke aus benachbarten Blöcken (z. B. einem Block, der sich über dem und/oder links vom zu codierenden Block befindet) als Vorlage ausgewählt werden. In diesem Fall befindet sich der zu codierende Block von der Grenze entfernt. Mit anderen Worten, der zu codierende Block befindet sich nicht am Ende einer Spalte und/oder Reihe in der C×R-Matrix und nicht neben einem Nullblock. Demgemäß kann mindestens einer der benachbarten Blöcke, der als Vorlage ausgewählt werden sollen, aus einem Block über dem und/oder links vom zu codierenden Block ausgewählt werden. In einem Interprädiktionsschema kann der Suchbereich zum Beispiel im 2D-Frame fortlaufend sein. Demgemäß kann der Suchbereich ausgewählt werden, ohne eine Grenze des 2D-Rahmens zu überqueren. Daher beinhaltet der Suchbereich keinen benachbarten Endblock.In step S625, at least one block is selected. In this case, the at least one block does not include an adjacent end block. For example, in an intra-prediction scheme, the previously encoded and reconstructed block (s) may be selected from adjacent blocks (eg, a block located above and / or to the left of the block to be encoded) as a template. In this case, the block to be coded is removed from the boundary. In other words, the block to be coded is not at the end of a column and / or row in the CxR matrix and not next to a null block. Accordingly, at least one of the adjacent blocks to be selected as a template may be selected from a block above and / or to the left of the block to be coded. For example, in an interprediction scheme, the search area may be continuous in the 2D frame. Accordingly, the search area can be selected without crossing a boundary of the 2D frame. Therefore, the search area does not include an adjacent end block.
In mindestens einer exemplarischen Implementierung kann mehr als ein Block für die Verwendung als Vorlage ausgewählt werden. In einem Intraprädiktionsschema können zum Beispiel ein benachbarter Block und ein Block neben (in derselben Richtung) dem benachbarten Block ausgewählt werden (z. B. zwei Blöcke). Die ausgewählten Blöcke können gemittelt werden, um einen Vorlagenblock zu bilden. In diesem Beispiel ist es möglich, dass die Vorlage auf einem benachbarten Block und einem benachbarten Endblock basiert. In einem Interprädiktionsschema kann der am besten passende Block auf einem Pixel mit Teilen einer Vielzahl von Blöcken zentriert werden, die den am besten passenden Block, den Kandidatenblock und/oder den Prädiktionsblock bilden.In at least one example implementation, more than one block may be for the Use to be selected as a template. For example, in an intra prediction scheme, an adjacent block and a block may be selected adjacent to (in the same direction) the neighboring block (eg, two blocks). The selected blocks can be averaged to form a template block. In this example, it is possible that the template is based on a neighboring block and an adjacent end block. In an inter-prediction scheme, the best matching block on a pixel may be centered with parts of a plurality of blocks that make up the best matching block, the candidate block, and / or the prediction block.
In Schritt S630 wird ein Satz von Resten für nicht codierte Pixel des Videosequenz-Frames (oder Bildes) auf Basis der Vorlage erzeugt. Der Satz von Resten kann einem Intraprädiktionsprozess oder Interprädiktionsprozess zugeordnet sein. Im Intraprädiktionsprozess kann zum Beispiel mindestens ein Wert, der dem jeweiligen Pixel zugeordnet ist, von einem entsprechenden Wert subtrahiert werden, der einem entsprechenden Block (oder Pixel) der ausgewählten Vorlage zugeordnet ist. Im Interprädiktionsprozess kann zum Beispiel mindestens ein Wert, der dem jeweiligen Pixel zugeordnet ist, von einem entsprechenden Wert subtrahiert werden, der einem entsprechenden Block (oder Pixel) des ausgewählten, am besten passenden Blocks, eines Kandidatenblocks und/oder eines Prädiktionsblocks zugeordnet ist.In step S630, a set of remnants for unencoded pixels of the video sequence frame (or image) is generated based on the template. The set of residues may be associated with an intra prediction process or inter prediction process. For example, in the intra-prediction process, at least one value associated with each pixel may be subtracted from a corresponding value associated with a corresponding block (or pixel) of the selected template. For example, in the inter-prediction process, at least one value associated with the respective pixel may be subtracted from a corresponding value associated with a corresponding block (or pixel) of the selected best matching block, a candidate block, and / or a prediction block.
In Schritt S635 werden die nicht codierten Pixel codiert. Die Reste für die nicht codierten Pixel können zum Beispiel mithilfe einer konfigurierten Transformation (z. B. einer KLT, einer SVD, einer DCT oder einer ADST) in Transformationskoeffizienten transformiert (codiert oder komprimiert) werden.In step S635, the non-coded pixels are coded. For example, the remainders for the unencoded pixels may be transformed (coded or compressed) into transform coefficients using a configured transformation (eg, a KLT, an SVD, a DCT, or an ADST).
In Schritt S640 quantisiert der Codierer den codierten Satz der Restwerte für den Block. Der Controller
In Schritt S650 gibt der Codierer den/die codierten (komprimierten) Videoframe(s) aus. Der Controller
In Schritt S710 entropiedecodiert der Videodecodierer die codierten Videobits. Die komprimierten Videobits können zum Beispiel durch Entropiedecodierung decodiert werden, z. B. mithilfe kontextadaptiver binärarithmetischer Decodierung, um eine Reihe quantisierter Transformationskoeffizienten zu erzeugen. In Schritt S715 dequantisiert der Videodecodierer die Transformationskoeffizienten, die durch die entropiedecodierten Bits angegeben werden. Die entropiedecodierten Videobits können zum Beispiel durch Abbildung von Werten in einem relativ kleinen Bereich der Werte in einen relativ großen Bereich dequantisiert werden (z. B. im Gegensatz zur oben beschriebenen Quantisierungsabbildung). Des Weiteren transformiert in Schritt S720 der Videodecodierer die Videobits mithilfe einer angegebenen (z. B. im Header) Transformation (z. B. einer KLT, einer SVD, einer DCT oder einer ADST).In step S710, the video decoder entropy decodes the coded video bits. The compressed video bits may be decoded by, for example, entropy decoding, e.g. Using context-adaptive binary arithmetic decoding, for example Series of quantized transform coefficients. In step S715, the video decoder dequantizes the transform coefficients indicated by the entropy-decoded bits. For example, the entropy decoded video bits may be dequantized by mapping values in a relatively small range of values into a relatively wide range (eg, unlike the quantization map described above). Further, in step S720, the video decoder transforms the video bits using a specified (eg, header) transformation (eg, a KLT, an SVD, a DCT, or an ADST).
In Schritt S725 wird ermittelt, ob sich ein Block, der einem Prädiktionsschema zugeordnet ist, an/auf einer Framegrenze (oder Bildgrenze) der rechteckigen 2D-Darstellung befindet (oder Blöcke eine solche Grenze beinhalten). Der zugeordnete Block (oder die zugeordneten Blöcke) können ein oder mehrere benachbarten linke oder obere Blöcke in einer Intraprädiktionsimplementierung sein. Alternativ können der Block oder die Blöcke ein oder mehrere Blöcke innerhalb eines Suchbereichs eines Referenzframes in einer Interprädiktionsimplementierung sein. In einer exemplarischen Ausführungsform kann zum Beispiel eine C×R-Matrix von N×N-Blöcken Pixel in jedem Block beinhalten (z. B. wenn eine äquirektanguläre Projektion verwendet wird). Demgemäß beinhalten Blöcke in Reihe 0, Spalte 0, Reihe R-1 und Spalte C-1 Pixel des sphärischen Bildes. Daher befindet sich, wenn die C×R-Matrix der Blöcke während eines Scans oder einer Suche Pixel in jedem Block beinhaltet (z. B. äquirektanguläre Projektion) und die Spalte/Reihe = 0 oder die Spalte/Reihe = C-1/R-1 ist, der Block an der Grenze.In step S725, it is determined whether or not a block associated with a prediction scheme is at (or blocks include) a borderline (or frame boundary) of the 2D rectangular representation. The associated block (or blocks) may be one or more adjacent left or top blocks in an intraprediction implementation. Alternatively, the block or blocks may be one or more blocks within a search range of a reference frame in an inter prediction implementation. For example, in an exemplary embodiment, a CxR matrix of NxN blocks may include pixels in each block (eg, when an eighteen-angular projection is used). Accordingly, blocks in row 0, column 0, row R-1, and column C-1 include pixels of the spherical image. Therefore, if the CxR matrix of the blocks during a scan or search includes pixels in each block (eg, angular projection) and column / row = 0 or column / row = C-1 / R -1 is the block on the border.
In einer weiteren exemplarischen Implementierung beinhaltet eine C×R-Matrix von N×N-Blöcken mindestens einen Nullblock oder leere oder Nullpixel in mindestens einem Block (z. B. wenn eine semi-äquirektanguläre Projektion verwendet wird). Daher befindet sich, wenn ein benachbarter Block während eines Scans oder einer Suche ein Nullblock ist, der Block an einer Grenze. Um zum Beispiel zu ermitteln, ob ein benachbarter Block ein Nullblock ist, kann der benachbarte Block in einer Lookup-Tabelle (z. B. LUT
In Schritt S730 wird ein benachbarter Endblock nachgeschlagen. In einer exemplarischen Implementierung kann zum Beispiel eine C×R-Matrix von Blöcken Pixel in jedem Block beinhalten (z. B. wenn eine äquirektanguläre Projektion verwendet wird). Demgemäß ist ein benachbarter Endblock, der einer Spalte für einen Block in Reihe 0 zugeordnet ist, ein Block in Reihe R-1. Des Weiteren ist ein benachbarter Endblock, der einer Spalte für einen Block in Reihe R-1 zugeordnet ist, ein Block in Reihe 0. Ein benachbarter Endblock, der einer Reihe für einen Block in Spalte 0 zugeordnet ist, ist ein Block in Spalte C-1. Und schließlich, ist ein benachbarter Endblock, der einer Reihe für einen Block in Spalte C-1 zugeordnet ist, ein Block in Spalte 0. In einer weiteren exemplarischen Implementierung beinhaltet zum Beispiel eine C×R-Matrix von Blöcken Nullblöcke (z. B. wenn eine semi-äquirektanguläre Projektion verwendet wird). In diesem Beispiel können Spalten und Reihen benachbarter Endblöcke in einer Lookup-Tabelle (z. B. LUT
In Schritt S735 wird mindestens ein Block einschließlich eines benachbarten Endblocks ausgewählt. In einem Intraprädiktionsschema kann mindestens ein benachbarter Endblock als Vorlage ausgewählt werden. Mit anderen Worten, ein oder mehrere der 1, 2, 3, ..., n Pixel links vom und/oder über dem zu codierenden Block können aus der Vorlage ausgewählt werden, die aus mindestens einem benachbarten Endblock ausgewählt werden kann. Der benachbarte Endblock ist zwei oder mehr Grenzen der zweidimensionalen Darstellung zugeordnet. Der benachbarte Endblock kann zum Beispiel ein rekonstruierter Endblock außer einem linken rekonstruierten Endblock oder einem oberen rekonstruierten Endblock des (oder im Vergleich zu dem) zu codierenden Blocks sein. Mit anderen Worten, ein benachbarter Endblock befindet sich während des Intraprädiktionsscans der nicht codierten Blöcke nicht über dem oder links vom zu codierenden Block. Wie oben erörtert, kann zum Beispiel während der Intraprädiktion eine Vorlage auf Basis früher codierter und rekonstruierter Blöcke in demselben Frame (oder Bild) erzeugt werden. Der früher codierte und rekonstruierte Block/die früher codierten und rekonstruierten Blöcke können aus benachbarten Blöcken (z. B. einem Block der sich über dem und/oder links vom zu codierenden Block befindet) als Vorlage ausgewählt werden. In diesem Fall befindet sich der zu codierende Block am Ende einer Spalte und/oder Reihe in der C×R-Matrix oder neben einem Nullblock (z. B. der Block darüber ist null oder der linke Block ist null). Mit anderen Worten, ein Block der als Vorlage verwendet werden würde, ist nicht vorhanden oder ist ein Nullblock. Demgemäß kann mindestens einer der benachbarten Blöcke, der als Vorlage ausgewählt werden soll, einer der nachgeschlagenen benachbarten Endblöcke sein.In step S735, at least one block including an adjacent end block is selected. In an intra prediction scheme, at least one adjacent endblock can be selected as a template. In other words, one or more of the 1, 2, 3, ..., n pixels to the left of and / or over the block to be coded can be selected from the template that can be selected from at least one adjacent end block. The adjacent end block is associated with two or more boundaries of the two-dimensional representation. The adjacent end block may, for example, be a reconstructed end block other than a left reconstructed end block or an upper reconstructed end block of (or compared to) the block to be coded. In other words, an adjacent end block is not above or to the left of the block to be coded during the intra prediction scan of the unencoded blocks. For example, as discussed above, during intraprediction, a template may be generated based on previously encoded and reconstructed blocks in the same frame (or image). The previously coded and reconstructed block (s) and the previously coded and reconstructed blocks may be selected from adjacent blocks (eg, a block located above and / or to the left of the block to be coded) as a template. In this case, the block to be coded is at the end of a column and / or row in the CxR matrix or next to a null block (eg, the block above it is zero or the left block is zero). In other words, a block that would be used as a template does not exist or is a null block. Accordingly, at least one of the adjacent blocks to be selected as a template may be one of the looked-up adjacent end blocks.
In einem Intraprädiktionsschema kann mindestens ein benachbarter Block als Block in einem Suchbereich eines Referenzframes ausgewählt werden. Demgemäß kann mindestens ein benachbarter Block als am besten passender Block, Kandidatenblock und/oder Prädiktionsblock ausgewählt werden.In an intra prediction scheme, at least one neighboring block may be selected as a block in a search area of a reference frame. Accordingly, at least one adjacent Block as the best matching block, candidate block and / or prediction block.
In Schritt S740 wird mindestens ein Block auswählt. In diesem Fall beinhaltet der mindestens eine Block keinen benachbarten Endblock. In einem Intraprädiktionsschema können zum Beispiel der vorher codierte und rekonstruierte Block/die früher codierten und rekonstruierten Blöcke aus benachbarten Blöcken (z. B. einem Block, der sich über dem und/oder links vom zu codierenden Block befindet) als Vorlage ausgewählt werden. In diesem Fall befindet sich der zu codierende Block nicht am Ende einer Spalte und/oder Reihe in der C×R-Matrix und nicht neben einem Nullblock. Demgemäß kann mindestens einer der benachbarten Blöcke, der als Vorlage ausgewählt werden sollen, aus einem Block über dem und/oder links vom zu codierenden Block ausgewählt werden. In einem Interprädiktionsschema kann der Suchbereich zum Beispiel im 2D-Frame fortlaufend sein. Demgemäß kann der Suchbereich ausgewählt werden, ohne eine Grenze des 2D-Rahmens zu überqueren. Daher beinhaltet der Suchbereich keinen benachbarten Endblock.In step S740, at least one block is selected. In this case, the at least one block does not include an adjacent end block. For example, in an intra-prediction scheme, the previously encoded and reconstructed block (s) may be selected from adjacent blocks (eg, a block located above and / or to the left of the block to be encoded) as a template. In this case, the block to be coded is not at the end of a column and / or row in the CxR matrix and not next to a null block. Accordingly, at least one of the adjacent blocks to be selected as a template may be selected from a block above and / or to the left of the block to be coded. For example, in an interprediction scheme, the search area may be continuous in the 2D frame. Accordingly, the search area can be selected without crossing a boundary of the 2D frame. Therefore, the search area does not include an adjacent end block.
In mindestens einer exemplarischen Implementierung kann mehr als ein Block für die Verwendung als Vorlage ausgewählt werden. In einem Intraprädiktionsschema können zum Beispiel ein benachbarter Block und ein Block neben (in derselben Richtung) dem benachbarten Block ausgewählt werden (z. B. zwei Blöcke). Die ausgewählten Blöcke können gemittelt werden, um einen Vorlagenblock zu bilden. In diesem Beispiel ist es möglich, dass die Vorlage auf einem benachbarten Block und einem benachbarten Endblock basiert. In einem Interprädiktionsschema kann der am besten passende Block auf einem Pixel mit Teilen einer Vielzahl von Blöcken zentriert werden, die den am besten passenden Block, den Kandidatenblock und/oder den Prädiktionsblock bilden.In at least one exemplary implementation, more than one block may be selected for use as a template. For example, in an intra prediction scheme, an adjacent block and a block may be selected adjacent to (in the same direction) the neighboring block (eg, two blocks). The selected blocks can be averaged to form a template block. In this example, it is possible that the template is based on a neighboring block and an adjacent end block. In an inter-prediction scheme, the best matching block on a pixel may be centered with parts of a plurality of blocks that make up the best matching block, the candidate block, and / or the prediction block.
In Schritt S745 erzeugt der Videodecodierer rekonstruierte Pixel als Videoframe auf Basis decodierter Videobits. In einem Intraprädiktionsschema können die rekonstruierten Pixel mithilfe des Blocks als Vorlage erzeugt werden. Mit anderen Worten, ein oder mehrere der 1, 2, 3, ..., n Pixel links vom und/oder über dem zu decodierenden Block können aus dem Block/den Blöcken ausgewählt und als Vorlage verwendet werden, um rekonstruierte Pixel aus den decodierten Videobits zu erzeugen. In einer exemplarischen Implementierung kann der Block (und damit die 1, 2, 3, ..., n Pixel links vom und/oder über dem zu codierenden Block) benachbarte Endblöcke beinhalten. In einem Intraprädiktionsschema können die rekonstruierten Pixel mithilfe des Blocks als Prädiktionsblock erzeugt werden. Daher kann in einer exemplarischen Implementierung der Prädiktionsblock benachbarte Endblöcke beinhalten. Um zum Beispiel die rekonstruierten Pixel zu erzeugen, kann der Videodecodierer die Reste (z. B. transformierte oder dekomprimierte Videobits) zur entsprechenden Position in der Vorlage oder im Prädiktionsblock hinzufügen, was zu einem rekonstruierten Pixel führt.In step S745, the video decoder generates reconstructed pixels as a video frame based on decoded video bits. In an intra-prediction scheme, the reconstructed pixels can be created using the block as a template. In other words, one or more of the 1, 2, 3, ..., n pixels to the left of and / or above the block to be decoded may be selected from the block (s) and used as a template to extract reconstructed pixels from the decoded ones To generate video bits. In an exemplary implementation, the block (and thus the 1, 2, 3, ..., n pixels to the left of and / or over the block to be encoded) may include adjacent end blocks. In an intra prediction scheme, the reconstructed pixels can be generated using the block as a prediction block. Thus, in an exemplary implementation, the prediction block may include adjacent end blocks. For example, to generate the reconstructed pixels, the video decoder may add the remainders (eg, transformed or decompressed video bits) to the corresponding position in the template or prediction block, resulting in a reconstructed pixel.
In Schritt S750 filtert der Videodecodierer das rekonstruierte Pixel im Videoframe. Ein Schleifenfilter kann zum Beispiel auf den rekonstruierten Block angewendet werden, um Blockartefakte zu verringern. Ein Deblockierungsfilter kann zum Beispiel auf den rekonstruierten Block angewendet werden, um Verzerrungen zu verringern.In step S750, the video decoder filters the reconstructed pixel in the video frame. For example, a loop filter may be applied to the reconstructed block to reduce block artifacts. For example, a deblocking filter may be applied to the reconstructed block to reduce distortion.
In Schritt S755 wird der 2D-Frame (oder das Bild) in ein sphärisches Videoframe (oder Bild) umgewandelt. Der 2D-Frame kann zum Beispiel durch Umkehr der Technik, wie oben in Bezug auf die Abbildung eines sphärischen Frames (oder Bildes) auf einer 2D-Darstellung des sphärischen Frames (oder Bildes) beschrieben, umgewandelt werden. Eine Beispieltechnik ist in Bezug auf
In Schritt S760 erzeugt der Videodecodierer einen sphärischen Videodatenstrom (oder ein sphärisches Bild) auf Basis des/der Videoframes. Mindestens ein Videoframe der rekonstruierten umgewandelten Pixel kann zum Beispiel in einer Sequenz organisiert werden, um einen sphärischen Videodatenstrom zu bilden.In step S760, the video decoder generates a spherical video data stream (or a spherical image) based on the video frame (s). For example, at least one video frame of the reconstructed converted pixels may be organized in a sequence to form a spherical video data stream.
In Schritt S810 wird die 2D-Darstellung in einem sphärischen Frame (oder Bild) abgebildet. Die zylindrische Darstellung kann zum Beispiel mithilfe einer inversen Transformation (z. B. mithilfe der Umkehr der oben beschriebenen Gleichungen) basierend darauf auf einem sphärischen Bild abgebildet werden, welche Art von Projektion (z. B. äquirektanguläre oder semi-äquirektanguläre) zum Umwandeln des sphärischen Bildes in die 2D-Darstellung verwendet wurde. Die Gleichungen können die Umkehr von x = λcosθ und y = θ sein, wobei λ der Längengrad und θ der Breitengrad von λ = xcosy und θ = y ist. Andere inverse Transformationen entsprechen dem Umfang dieser Offenbarung.In step S810, the 2D representation is mapped into a spherical frame (or image). For example, the cylindrical representation may be mapped onto a spherical image based on an inverse transformation (eg, using the inverse of the equations described above) based on what type of projection (eg, angular-eukaryotic or semi-angular-angular) for transformation of the spherical image was used in the 2D representation. The equations may be the inverse of x = λcosθ and y = θ, where λ is the longitude and θ is the latitude of λ = xcosy and θ = y. Other inverse transformations are within the scope of this disclosure.
Gemäß einer exemplarischen Implementierung können sich Kacheln überlappen. Mit anderen Worten, ein Teil eines Blocks, ein Pixel und/oder eine Vielzahl von Pixeln können mehr als einer Kachel zugeordnet sein. Wie in
Gemäß einer exemplarischen Implementierung kann nur ein Teil des sphärischen Videos gestreamt werden, um während des Streamens des sphärischen Videos Ressourcen zu sparen. Zum Beispiel kann der Teil des sphärischen Videos, von dem angegeben wird, dass er von einem Betrachter während der Wiedergabe angesehen wird, gestreamt werden. Unter Bezugnahme auf
Daher kann gemäß mindestens einer exemplarischen Ausführungsform eine Vielzahl von Kacheln (z. B. als Teil des sphärischen Videoframes) gestreamt werden. Unter erneuter Bezugnahme auf
Demgemäß sind decodierte Kacheln, die Kacheln
Sollte daher der Betrachter ändern, was angesehen wird (z. B. indem er seine Augen oder seinen Kopf bewegt), sieht der Betrachter weiterhin das gestreamte sphärische Video (wenn auch mit einer möglicherweise geringeren Qualität). Ein nachfolgend gestreamter Frame kann dann eine periphere Ansicht auf Basis der geänderten Position beinhalten und somit ein gewünschtes Benutzererlebnis aufrechterhalten und gleichzeitig Ressourcen während des Streamens des sphärischen Videos sparen.Therefore, should the viewer change what is being viewed (eg, by moving his eyes or head), the viewer will continue to see the streamed spherical video (albeit with possibly lower quality). A subsequently streamed frame may then include a peripheral view based on the changed position, thus maintaining a desired user experience while saving resources while streaming the spherical video.
In einer exemplarischen Implementierung kann Kachel
Wenn Kachel
Gemäß einer exemplarischen Implementierung erkennt der Positionssensor
Die Anforderung für den Frame des sphärischen Videos, die Kachel oder die Vielzahl von Kacheln kann zusammen mit einer Anforderung für einen Frame eines sphärischen Videos kommuniziert werden. Die Anforderung für die Kachel kann getrennt von einer Anforderung für einen Frame des sphärischen Videos kommuniziert werden. Die Anforderung für die Kachel kann zum Beispiel als Reaktion auf eine geänderte Ansicht, Perspektive oder Ansichtsperspektive erfolgen, die zu einer Notwendigkeit führt, früher eine vorher angeforderte und/oder in die Warteschlange gestellte Kachel, Vielzahl von Kacheln oder einen Frame zu ersetzen.The request for the spherical video frame, the tile or the plurality of tiles may be communicated together with a request for a frame of spherical video. The request for the tile may be communicated separately from a request for a frame of the spherical video. For example, the request for the tile may be in response to a modified view, perspective, or view perspective that results in a need to replace a previously requested and / or queued tile, plurality of tiles, or a frame earlier.
Das Ansichtspositionssteuermodul
Demgemäß kann der Positionssensor
Das Ansichtspositionsermittlungsmodul
Das Ansichtspositionssteuermodul
Der Block der sphärischen-zu-2D-Darstellung
Das Frame-Zerlegungsmodul
Das Ansichtsauswahlmodul
Das Kachelmodul
Das Kachelmodul
Der Paketersteller
In einer exemplarischen Implementierung kann der Paketersteller
Das Frame-Erstellungsmodul
Der Block der sphärischen-zu-2D-Darstellung
In einer exemplarischen Implementierung kann der Decodierer
Es ist darauf hinzuweisen, dass die Systeme
In Schritt S1210 wird der sphärische Frame (Bild) auf einer 2D-Darstellung abgebildet. Die Abbildung eines Frames (oder sphärischen Bildes) auf einer 2D-Darstellung kann zum Beispiel die Projektion des Frames (oder sphärischen Bildes) auf die Oberfläche eines Zylinders (der dann in ein Rechteck abgewickelt wird), ein Quadrat oder Rechteck beinhalten. In einer exemplarischen Implementierung kann die Projektion äquirektangulär sein. Mit anderen Worten, Pixel entlang einer Linie in der Mitte der Kugel (z. B. ein Äquator) werden auf einer abstandsgleichen Linie zwischen der Oberseite und Unterseite des Zylinders, Quadrats oder Rechtecks abgebildet. Beim Wegbewegen von der Linie (z. B. nach oben und nach unten von der Linie) wird dann jede horizontale Linie auf dem Zylinder als gerade Linie durch die Mitte des Bildes abgebildet, wobei die vertikale Linie vertikal bleibt. Wenn die horizontale Linie immer näher zu den Polen der Kugel gelangt, kann das Bild gedehnt werden, um zum Zylinder, Quadrat oder Rechteck zu passen. Andere Projektionen werden erwägt. Zum Beispiel könnte eine semi-äquirektanguläre Projektion verwendet werden. Eine semi-äquirektanguläre Projektion kann den Umfang der vorher erwähnten Dehnung so skalieren, dass die Projektion den Zylinder, das Quadrat oder das Rechteck nicht vollständig füllt.In step S1210, the spherical frame (image) is imaged on a 2D representation. For example, mapping a frame (or spherical image) onto a 2D representation may involve projecting the frame (or spherical image) onto the surface of a cylinder (which is then unwound into a rectangle), square, or rectangle. In an exemplary implementation, the projection may be eighteen-angular. In other words, pixels along a line in the center of the sphere (eg, an equator) are imaged on an equidistant line between the top and bottom of the cylinder, square, or rectangle. Moving away from the line (eg, up and down the line), each horizontal line on the cylinder is then imaged as a straight line through the center of the image, with the vertical line remaining vertical. As the horizontal line gets closer and closer to the poles of the sphere, the image can be stretched to fit the cylinder, square or rectangle. Other projections are being considered. For example, a semi-ectectangular projection could be used. A semi-ectectangular projection can scale the extent of the previously mentioned strain so that the projection is the Cylinder that does not completely fill square or rectangle.
In Schritt S1215 wird der Frame einschließlich der 2D-Darstellung in eine C×R-Matrix von N×N-Blöcken oder Makroblöcken zerlegt. Der Controller
In Schritt S1220 wird eine Angabe einer Ansichtsperspektive empfangen. Die Angabe der Ansichtsperspektive kann von einem Gerät empfangen werden, das eine Wiedergabe des sphärischen Videos durchführt. Mit anderen Worten, die Angabe der Ansichtsperspektive kann von einem Gerät empfangen werden, das einen Decodierer (z. B. Decodierer
In einer exemplarischen Implementierung wird die Angabe einer Ansichtsperspektive empfangen, bevor der sphärische Frame (oder Bild) in einer 2D-Darstellung abgebildet wird. In dieser Implementierung kann der sphärische Frame (oder das sphärische Bild) gedreht werden, sodass die Ansichtsperspektive zum Beispiel entlang der Linie in der Mitte der Kugel (z. B. entlang des Äquators) zentriert ist. Als Folge können die Pixel, Blöcke und/oder Makroblöcke (aus denen z. B. die oben beschriebenen Kacheln bestehen) in einer solchen Position sein, dass jegliche Verzerrung der Pixel, Blöcke und/oder Makroblöcke während einer Projektion der Pixel, Blöcke und/oder Makroblöcke auf der Oberfläche des Zylinders, Rechtecks oder Quadrats minimiert werden können.In an exemplary implementation, the indication of a view perspective is received before the spherical frame (or image) is mapped in a 2D representation. In this implementation, the spherical frame (or the spherical image) may be rotated such that the view perspective is centered, for example, along the line in the center of the sphere (eg, along the equator). As a result, the pixels, blocks, and / or macroblocks (of which, for example, the tiles described above may be made) may be in a position such that any distortion of the pixels, blocks, and / or macroblocks during projection of the pixels, blocks, and / or or macroblocks on the surface of the cylinder, rectangle or square can be minimized.
In Schritt S1225 wird eine Kachelposition im sphärischen Frame auf Basis der Ansichtsperspektive ermittelt. Wenn die Angabe zum Beispiel ein Punkt oder eine Position auf der Kugel (als ein sphärisches Bild oder ein sphärischer Frame) ist, kann eine Kachel (z. B. eine Anzahl an Pixeln, ein Block und/oder ein Makroblock) auf Basis des Punkts oder der Position ermittelt werden. In einer exemplarischen Implementierung kann die Position der Kachel (mindestens eine Kachel oder eine Vielzahl von Kacheln) ein Rechteck sein, das am Punkt oder an der Position zentriert ist.In step S1225, a tile position in the spherical frame is determined based on the view perspective. For example, if the indication is a point or position on the sphere (as a spherical image or a spherical frame), a tile (eg, a number of pixels, a block, and / or a macroblock) may be based on the point or position. In an exemplary implementation, the location of the tile (at least one tile or a plurality of tiles) may be a rectangle centered at the point or at the location.
In Schritt S1230 wird eine Vielzahl von 2D-Kacheln auf Basis der Kachelposition erzeugt. Wie oben erörtert, können die 2D-Kacheln zum Beispiel ein Bild einschließlich einer Vielzahl von Pixeln oder Blöcken sein. Die 2D-Kacheln können einen Teil des Frames des sphärischen Videos beinhalten. Die Vielzahl von 2D-Kacheln können durch Auswählen eines ersten Teils des Frames des sphärischen Videos als erste zweidimensionale Kachel (z. B.
In Schritt S1235 werden die 2D-Kacheln mithilfe von zwei oder mehr QoS-Einstellungen codiert. Die 2D-Kachel kann zum Beispiel mithilfe einer konfigurierten Transformation (z. B. einer KLT, einer SVD, einer DCT oder einer ADST) in Transformationskoeffizienten transformiert (codiert oder komprimiert) werden. Die codierte Transformationskoeffizienten oder Sätze von Restwerten für den Block können quantisiert werden. Der Controller
In einer exemplarischen Implementierung kann eine andere Qualität (oder Servicequalität (QoS) bei einer Kachel (oder der Vielzahl von Kacheln) verwendet werden, die die Ansichtsperspektive beinhaltet, im Vergleich zu Kacheln an einer peripheren Ansicht oder außerhalb der Ansichtsperspektive (z. B. von einem Betrachter während der Wiedergabe nicht gesehen). Die QoS kann auf einem Kompressionsalgorithmus, einer Übertragungsrate und/oder einem Codierschema basieren. Die Kachel (oder Kacheln), die die Ansichtsperspektive beinhaltet, kann mit einer höheren QoS codiert sein, als die Kacheln an der Peripheriesicht oder außerhalb der Ansichtsperspektive. Die QoS kann die Auflösung der Kachel und/oder Kacheln bei der Decodierung beeinflussen. Demgemäß kann die Kachel, die die Ansichtsperspektive (als sichtbare Perspektive einschließlich eines Teils des sphärischen Videoframes) beinhaltet, so codiert werden, dass die Kachel, die die Ansichtsperspektive beinhaltet, (wenn sie decodiert ist) eine höhere Auflösung hat im Vergleich zu Kacheln an einer peripheren Ansicht oder außerhalb der Ansichtsperspektive (z. B. von einem Betrachter während der Wiedergabe nicht gesehen) (wenn sie decodiert sind).In an exemplary implementation, a different quality (or quality of service QoS) may be used on a tile (or plurality of tiles) that includes the view perspective, as compared to tiles on a peripheral view or outside the view perspective (e.g. QoS may be based on a compression algorithm, a transmission rate and / or a coding scheme The tile (or tiles) containing the view perspective may be encoded with a higher QoS than the tiles on the The QoS may affect the resolution of the tile and / or tiles during decoding Accordingly, the tile containing the view perspective (as a visible perspective including a portion of the spherical video frame) may be encoded such that the tile that includes the view perspective (when it decodes is) has a higher resolution compared to tiles on a peripheral view or outside the view perspective (e.g. Not seen by a viewer during playback) (if they are decoded).
In einer exemplarischen Implementierung kann die Vielzahl von 2D-Kacheln an einer peripheren Ansicht oder außerhalb der Ansichtsperspektive Kacheln unterschiedlicher Dimensionen beinhalten. Des Weiteren kann eine größere der Kacheln mit unterschiedlichen Dimensionen mit einer geringeren QoS codiert werden im Vergleich zu einer QoS einer kleineren der Kacheln mit unterschiedlichen Dimensionen. Demgemäß kann sich eine Auflösung decodierter Kacheln, die 2D-Kacheln an einer peripheren Ansicht oder außerhalb der Ansichtsperspektive zugeordnet sind, auf Basis einer Größe einer Kachel und/oder einer Position einer Kachel unterscheiden.In an exemplary implementation, the plurality of 2D tiles at a peripheral view or outside the view perspective may include tiles of different dimensions. Furthermore, a larger one of the tiles of different dimensions may be encoded with a lower QoS compared to a QoS of a smaller one of the tiles of different dimensions. Accordingly, a resolution of decoded tiles associated with 2D tiles at a peripheral view or outside the view perspective may differ based on a size of a tile and / or a position of a tile.
In Schritt S1240 wird ein codiertes (komprimiertes) Videobitpaket einschließlich codierter 2D-Kacheln erzeugt. Der Paketersteller
In einer exemplarischen Implementierung erstellt der Paketersteller
In Schritt S1310 kann in einer Implementierung eine 2D-Darstellung des sphärischen Videoframes (oder Bildes), das auf den 2D-Kacheln basiert, erzeugt werden. In diesem Fall wird zum Beispiel nur die Vielzahl der codierten Kacheln empfangen. Daher kann ein Decodierer (der z. B. Frame-Erstellungsmodul
In Schritt S1315 wird die 2D-Darstellung, die die Vielzahl codierter Kacheln beinhaltet, decodiert. Ein Videodecodierer (z. B. Decodierer
In Schritt S1320 wird die 2D-Darstellung in das sphärische Videoframe umgewandelt. Die decodierte 2D-Darstellung kann zum Beispiel in ein sphärisches Videoframe (oder Bild) umgewandelt werden. Die 2D-Darstellung kann zum Beispiel durch Umkehr der Technik wie oben in Bezug auf die Abbildung eines sphärischen Frames (oder Bildes) auf einer 2D-Darstellung des sphärischen Frames (oder Bildes) beschrieben umgewandelt werden.In step S1320, the 2D representation is converted to the spherical video frame. For example, the decoded 2D representation may be converted to a spherical video frame (or image). For example, the 2D representation may be converted by reversing the technique as described above with respect to the imaging of a spherical frame (or image) on a 2D representation of the spherical frame (or image).
In Schritt S1325 wird ein sphärischer Videodatenstrom (oder sphärisches Bild) auf Basis mindestens eines sphärischen Videoframes einschließlich der decodierten Vielzahl von Kacheln erzeugt. Mindestens ein Videoframe der rekonstruierten umgewandelten Pixel des sphärischen Videos, das die decodierte Vielzahl von Kacheln beinhaltet, kann zum Beispiel in einer Sequenz organisiert werden, um einen sphärischen Videodatenstrom zu bilden. Wie oben erörtert, wurde die Kachel (oder die Vielzahl von Kacheln), die die Ansichtsperspektive beinhaltet, mit einer höhere QoS codiert als die Kacheln an der peripheren Ansicht oder außerhalb der Ansichtsperspektive (z. B. von einem Betrachter während der Wiedergabe nicht gesehen). Demgemäß kann das Erzeugen des sphärischen Videodatenstroms dazu führen, dass der sichtbare Teil des sphärischen Videodatenstroms von einer höheren Qualität ist als der periphere oder nicht sichtbare Teil des sphärischen Videodatenstroms während einer Wiedergabe des sphärischen Videodatenstroms.In step S1325, a spherical video data stream (or spherical image) is generated based on at least one spherical video frame including the decoded plurality of tiles. For example, at least one video frame of the reconstructed converted pixels of the spherical video including the decoded plurality of tiles may be organized in a sequence to form a spherical video data stream. As discussed above, the tile (or plurality of tiles) that includes the view perspective has been encoded with a higher QoS than the tiles on the peripheral view or out of the view perspective (eg, not seen by a viewer during playback). , Accordingly, generating the spherical video data stream may result in the visible portion of the spherical video data stream being of a higher quality than the peripheral or invisible portion of the spherical video data stream during playback of the spherical video data stream.
In einer exemplarischen Implementierung kann, wenn sich die Ansichtsperspektive, wie vom Betrachter gesehen, während des Streamens (und/oder Decodieren) des sphärischen Videos oder Bildes ändert, eine Angabe der geänderte Ansichtsperspektive ausgelöst und an ein Gerät gesendet werden, das eine Codierung des sphärischen Videos ausführt.In an exemplary implementation, if the view perspective changes, as viewed by the viewer, during the streaming (and / or decoding) of the spherical video or image, an indication of the changed view perspective may be triggered and sent to a device encoding the spherical one Run videos.
Außerdem beinhaltet der Videocodierer
Das Ansichtsauswahlmodul
In einer exemplarischen Implementierung können Parameter, die in Codierer
Der Teil des sphärischen Videoframes oder Bildes kann als Bild verarbeitet werden. Daher kann der Teil des sphärischen Videoframes in eine C×R-Matrix von Blöcken (im Folgenden als Blöcke bezeichnet) umgewandelt werden. Der Teil des sphärischen Videoframes kann in eine C×R-Matrix mit jeweils 16×16, 16×8, 8×16, 8×8, 8×4, 4×8, 4×4 oder 2×2 Blöcken umgewandelt werden, die jeweils eine Anzahl an Pixeln haben.The part of the spherical video frame or image can be processed as an image. Therefore, the part of the spherical video frame can be converted into a C × R matrix of blocks (hereinafter referred to as blocks). The portion of the spherical video frame may be converted to a CxR matrix of 16x16, 16x8, 8x16, 8x8, 8x4, 4x8, 4x4, or 2x2 blocks, respectively. each having a number of pixels.
Gemäß einer exemplarischen Implementierung kann Codierer
Der Paketersteller
In einer alternativen Implementierung (und/oder einer zusätzlichen Implementierung) kann der Codierer
In einer alternativen Implementierung (und/oder einer zusätzlichen Implementierung) beinhaltet der Codierer
Der Paketdekonstruktor
In einer exemplarischen Implementierung können Parameter, die in Decodierer
Das Ansichtsauswahlmodul
In einer alternativen Implementierung (und/oder einer zusätzlichen Implementierung) kann der Codierer
Der Teil des sphärischen Videoframes oder Bildes kann als Bild verarbeitet werden. Daher kann der Teil des sphärischen Videoframes in eine C×R-Matrix von Blöcken (im Folgenden als Blöcke bezeichnet) umgewandelt werden. Der Teil des sphärischen Videoframes kann in eine C×R-Matrix mit jeweils 16×16, 16×8, 8×8, 4×4 oder 2×2 Blöcken umgewandelt werden, die jeweils eine Anzahl an Pixeln haben.The part of the spherical video frame or image can be processed as an image. Therefore, the part of the spherical video frame can be converted into a C × R matrix of blocks (hereinafter referred to as blocks). The portion of the spherical video frame may be converted to a CxR matrix of 16x16, 16x8, 8x8, 4x4 or 2x2 blocks, each having a number of pixels.
Codierer
Daher kann in einer exemplarischen Implementierung der Codierer
Wie in
Gemäß einer exemplarischen Implementierung erkennt der Orientierungssensor
Die Anforderung für die Kachel kann zusammen mit einer Anforderung für einen Frame des sphärischen Videos kommuniziert werden. Die Anforderung für die Kachel kann getrennt von einer Anforderung für einen Frame des sphärischen Videos kommuniziert werden. Die Anforderung für die Kachel kann zum Beispiel als Reaktion auf eine geänderte Ansicht, Perspektive oder Ansichtsperspektive erfolgen, die zu einer Notwendigkeit führt, eine früher angeforderte und/oder in die Warteschlange gestellte Kachel zu ersetzen.The request for the tile may be communicated along with a request for a frame of the spherical video. The request for the tile may be communicated separately from a request for a frame of the spherical video. For example, the request for the tile may be in response to a modified view, perspective, or view perspective that results in a need to replace a previously requested and / or queued tile.
Das Ansichtspositionssteuermodul
Demgemäß kann der Orientierungssensor
Das Ansichtspositionsermittlungsmodul
Das Ansichtspositionssteuermodul
In Schritt S1710 wird der sphärische Frame auf einer 2D-Darstellung abgebildet. Die Abbildung eines Frames (oder sphärischen Bildes) auf einer 2D-Darstellung kann zum Beispiel die Projektion des Frames (oder sphärischen Bildes) auf die Oberfläche eines Zylinders (der dann in ein Rechteck abgewickelt wird), ein Quadrat oder Rechteck beinhalten. In einer exemplarischen Implementierung kann die Projektion äquirektangulär sein. Mit anderen Worten, Pixel entlang einer Linie in der Mitte der Kugel (z. B. ein Äquator) werden auf einer abstandsgleichen Linie zwischen der Oberseite und Unterseite des Zylinders, Quadrats oder Rechtecks abgebildet. Beim Wegbewegen von der Linie (z. B. nach oben und nach unten von der Linie) wird dann jede horizontale Linie auf dem Zylinder als gerade Linie durch die Mitte des Bildes abgebildet, wobei die vertikale Linie vertikal bleibt. Wenn die horizontale Linie immer näher zu den Polen der Kugel gelangt, kann das Bild gedehnt werden, um zum Zylinder, Quadrat oder Rechteck zu passen. Andere Projektionen werden erwägt. Zum Beispiel könnte eine semi-äquirektanguläre Projektion verwendet werden. Eine semi-äquirektanguläre Projektion kann den Umfang der vorher erwähnten Dehnung so skalieren, dass die Projektion den Zylinder, das Quadrat oder das Rechteck nicht vollständig füllt.In step S1710, the spherical frame is imaged on a 2D representation. For example, mapping a frame (or spherical image) onto a 2D representation may involve projecting the frame (or spherical image) onto the surface of a cylinder (which is then unwound into a rectangle), square, or rectangle. In an exemplary implementation, the projection may be eighteen-angular. In other words, pixels along a line in the center of the sphere (eg, an equator) are imaged on an equidistant line between the top and bottom of the cylinder, square, or rectangle. Moving away from the line (eg, up and down the line), each horizontal line on the cylinder is then imaged as a straight line through the center of the image, with the vertical line remaining vertical. As the horizontal line gets closer and closer to the poles of the sphere, the image can be stretched to fit the cylinder, square or rectangle. Other projections are being considered. For example, a semi-ectectangular projection could be used. A semi-eighteen-angular projection can scale the extent of the aforementioned strain such that the projection does not completely fill the cylinder, square, or rectangle.
In Schritt S1715 wird eine Angabe einer Ansichtsperspektive empfangen. Die Angabe der Ansichtsperspektive kann von einem Gerät empfangen werden, das eine Wiedergabe des sphärischen Videos durchführt. Mit anderen Worten, die Angabe der Ansichtsperspektive kann von einem Gerät empfangen werden, das einen Decodierer (z. B. Decodierer
In Schritt S1720 wird eine Kachelposition im sphärischen Frame auf Basis der Ansichtsperspektive ermittelt. Wenn die Angabe zum Beispiel ein Punkt oder eine Position auf der Kugel (als ein sphärisches Bild oder Frame) ist, kann eine Kachel (z. B. eine Anzahl an Pixeln, ein Block und/oder ein Makroblock) auf Basis des Punkts oder der Position ermittelt werden. In einer exemplarischen Implementierung kann die Position der Kachel (mindestens eine Kachel oder eine Vielzahl von Kacheln) ein Rechteck sein, das am Punkt oder an der Position zentriert ist.In step S1720, a tile position in the spherical frame is determined based on the view perspective. For example, if the indication is a point or position on the sphere (as a spherical image or frame), a tile (eg, a number of pixels, a block, and / or a macroblock) may be based on the point or Position are determined. In an exemplary implementation, the location of the tile (at least one tile or a plurality of tiles) may be a rectangle centered at the point or at the location.
In Schritt S1725 wird eine 2D-Kachel auf Basis der Kachelposition erzeugt. Die 2D-Kachel kann zum Beispiel ein Bild einschließlich einer Vielzahl von Pixeln sein. Die 2D-Kachel oder das Bild kann einen Teil des Frames des sphärischen Videos sein. Die 2D-Kachel oder das Bild kann die Vielzahl von Kacheln beinhalten, die im Rechteck enthalten sind, das am Punkt oder an der Position zentriert ist.In step S1725, a 2D tile is created based on the tile position. The 2D tile may be, for example, an image including a plurality of pixels. The 2D tile or image may be part of the spherical video frame. The 2D tile or image may include the plurality of tiles contained in the rectangle centered at the point or position.
In einer alternativen Implementierung (und/oder einer zusätzlichen Implementierung) kann die Kachel mithilfe einer anderen Projektionstechnik oder eines anderen Algorithmus projiziert werden als zur Erzeugung der 2D-Darstellung des sphärischen Videoframes verwendet. Einige Projektionen können zum Beispiel Verzerrungen in bestimmten Bereichen des Frames haben, daher kann eine Projektion der Kachel, die sich vom sphärischen Frame unterscheidet, die Qualität des endgültigen Bildes verbessern und/oder Pixel effizienter nutzen. In einer exemplarischen Implementierung kann das sphärische Bild vor Projektion der Kachel gedreht werden, um die Kachel in einer Position auszurichten, die auf Basis des Projektionsalgorithmus minimal verzerrt ist. In einer anderen exemplarischen Implementierung kann die Kachel einen Projektionsalgorithmus verwenden (und/oder ändern), der auf der Position der Kachel basiert. Die Projektion des sphärischen Videoframes der 2D-Darstellung kann zum Beispiel eine äquirektanguläre Projektion verwenden, während die Projektion des sphärischen Videoframes in einer Darstellung einschließlich eines Teils, der als Kachel ausgewählt werden muss, eine kubische Projektion verwenden kann.In an alternative implementation (and / or additional implementation), the tile may be projected using a different projection technique or algorithm than used to generate the 2D representation of the spherical video frame. For example, some projections may have distortions in certain areas of the frame, so projecting the tile other than the spherical frame may improve the quality of the final image and / or use pixels more efficiently. In an exemplary implementation, the spherical image may be rotated prior to projection of the tile to align the tile in a position that is minimally distorted based on the projection algorithm. In another exemplary implementation, the tile may use (and / or modify) a projection algorithm based on the location of the tile. For example, the projection of the spherical video frame of the 2D representation may use an angular projection, while the Projecting the spherical video frame in a display, including a part that must be selected as a tile, can use a cubic projection.
In Schritt S1730 wird die 2D-Darstellung codiert. Die 2D-Darstellung kann zum Beispiel mithilfe einer konfigurierten Transformation (z. B. einer KLT, einer SVD, einer DCT oder einer ADST) in Transformationskoeffizienten transformiert (codiert oder komprimiert) werden. Die codierte Transformationskoeffizienten oder Sätze von Restwerten für den Block können quantisiert werden. Der Controller
In Schritt S1735 wird die 2D-Kachel codiert. Die 2D-Kachel kann zum Beispiel mithilfe einer konfigurierten Transformation (z. B. einer KLT, einer SVD, einer DCT oder einer ADST) in Transformationskoeffizienten transformiert (codiert oder komprimiert) werden. Die codierte Transformationskoeffizienten oder Sätze von Restwerten für den Block können quantisiert werden. Der Controller
In Schritt S1740 wird ein codiertes (komprimiertes) Videobitpaket einschließlich codierter 2D-Darstellung und der codierten 2D-Kachel erzeugt. Der Paketersteller
In Schritt S1810 wird eine Vielzahl von Ansichtsperspektiven erzeugt. Das Ansichtsauswahlmodul
In Schritt S1815 wird eine Vielzahl von Kachelpositionen im sphärischen Frame auf Basis jeder der Ansichtsperspektiven ermittelt. Es kann zum Beispiel eine Kachelposition für jede der Vielzahl von Ansichtsperspektiven ermittelt werden. Wenn die Vielzahl von Ansichtsperspektiven zum Beispiel jeweils auf einem Punkt oder einer Position auf der Kugel (als ein sphärisches Bild oder ein sphärischer Frame) basiert, kann eine Kachel (z. B. eine Anzahl an Pixeln, ein Block und/oder ein Makroblock) auf Basis des Punkts oder der Position ermittelt werden. In einer exemplarischen Implementierung kann die Position der Kachel (mindestens eine Kachel oder eine Vielzahl von Kacheln) ein Rechteck sein, das am Punkt oder an der Position zentriert ist.In step S1815, a plurality of tile positions in the spherical frame are determined based on each of the view perspectives. For example, a tile position may be determined for each of the plurality of view perspectives. For example, if the plurality of view perspectives are each based on a point or position on the sphere (as a spherical image or a spherical frame), a tile (eg, a number of pixels, a block, and / or a macroblock) may be used. based on the point or position. In an exemplary implementation, the location of the tile (at least one tile or a plurality of tiles) may be a rectangle centered at the point or at the location.
In Schritt S1820 wird eine Vielzahl von 2D-Kacheln auf Basis der Kachelpositionen erzeugt. Es kann zum Beispiel eine 2D-Kachel für jede der Vielzahl von Kachelpositionen erzeugt werden (z. B. als Vielzahl von Bildern). Jede der 2D-Kacheln kann zum Beispiel ein Bild einschließlich einer Vielzahl von Pixeln sein. Die 2D-Kacheln oder Bilder können ein Teil des Frames des sphärischen Videos sein. Die 2D-Kacheln oder Bilder können die Vielzahl von Kacheln beinhalten, die im Rechteck enthalten sind, das am Punkt oder an der Position zentriert ist.In step S1820, a plurality of 2D tiles are created based on the tile positions. For example, a 2D tile may be generated for each of the plurality of tile locations (eg, as a plurality of images). For example, each of the 2D tiles may be an image including a plurality of pixels. The 2D tiles or images may be part of the spherical video frame. The 2D tiles or images may include the plurality of tiles contained in the rectangle centered at the point or position.
In einer alternativen Implementierung (und/oder einer zusätzlichen Implementierung) kann die Kachel mithilfe einer anderen Projektionstechnik oder eines anderen Algorithmus projiziert werden als zur Erzeugung der 2D-Darstellung des sphärischen Videoframes verwendet. Einige Projektionen können zum Beispiel Verzerrungen in bestimmten Bereichen des Frames haben, daher kann eine Projektion der Kachel, die sich vom sphärischen Frame unterscheidet, die Qualität des endgültigen Bildes verbessern und/oder Pixel effizienter nutzen. In einer exemplarischen Implementierung kann das sphärische Bild vor Projektion der Kachel gedreht werden, um die Kachel in einer Position auszurichten, die auf Basis des Projektionsalgorithmus minimal verzerrt ist. In einer anderen exemplarischen Implementierung kann die Kachel einen Projektionsalgorithmus verwenden (und/oder ändern), der auf der Position der Kachel basiert. Die Projektion des sphärischen Videoframes der 2D-Darstellung kann zum Beispiel eine äquirektanguläre Projektion verwenden, während die Projektion des sphärischen Videoframes in einer Darstellung einschließlich eines Teils, der als Kachel ausgewählt werden muss, eine kubische Projektion verwenden kann.In an alternative implementation (and / or additional implementation), the tile may be projected using a different projection technique or algorithm than used to generate the 2D representation of the spherical video frame. For example, some projections may have distortions in certain areas of the frame, so projecting the tile other than the spherical frame may improve the quality of the final image and / or use pixels more efficiently. In an exemplary implementation, the spherical image may be rotated prior to projection of the tile to align the tile in a position that is minimally distorted based on the projection algorithm. In another exemplary implementation, the tile may use (and / or modify) a projection algorithm based on the location of the tile. For example, the projection of the spherical video frame of the 2D representation may use an eighteen-angular projection, while the projection of the spherical video frame in a representation including a part to be selected as a tile may use a cubic projection.
In Schritt S1825 wird jede der 2D-Kacheln codiert. Jede der Vielzahl von 2D-Kacheln kann zum Beispiel mithilfe einer konfigurierten Transformation (z. B. einer KLT, einer SVD, einer DCT oder einer ADST) in Transformationskoeffizienten transformiert (codiert oder komprimiert) werden. Die codierte Transformationskoeffizienten oder Sätze von Restwerten für den Block können quantisiert werden. Der Controller
In Schritt S1830 wird jede der 2D-Kacheln zusammen mit einer Angabe des Frames und einer Position der codierten Kachel im Frame gespeichert. Jede der Vielzahl von Kacheln der codierten 2D-Kacheln kann zum Beispiel in einem Ansichtsframe-Speicher
In Schritt S1910 werden ein Frame und eine Kachelposition in einem sphärischen Video auf Basis der Ansichtsperspektive ermittelt. Die vorher erwähnten Informationen über den Frame können zum Beispiel Informationen sein, die angeben, dass der Frame der aktuelle zu codierende Frame oder ein früher codierter Frame ist (z. B. als Framesequenz oder als Sequenznummer). Demgemäß kann der Frame als aktueller zu codierender Frame oder früher codierter Frame ermittelt werden. Anschließend kann die Kachelposition auf der Ansicht oder Ansichtsperspektive im ermittelten Frame basieren.In step S1910, a frame and a tile position in a spherical video are determined based on the view perspective. The aforementioned information about the frame may be, for example, information indicating that the frame is the current frame to be encoded or an earlier encoded frame (eg, as a frame sequence or as a sequence number). Accordingly, the frame can be determined as the current frame to be coded or the frame coded earlier. Then the tiling position can be based on the view or view perspective in the detected frame.
In Schritt S1915 wird ein Ort einer codierten 2D-Kachel auf Basis des Frames und der Kachelposition ermittelt. Mithilfe des Frames und der Kachelposition kann zum Beispiel eine codierte 2D-Kachel im Ansichtsframe-Speicher
In Schritt S1920 wird eine codierte 2D-Darstellung des Frames des sphärischen Videos empfangen. Zum Beispiel kann die Ausgabe von Codierer
In Schritt S1925 wird ein codiertes (komprimiertes) Videobitpaket einschließlich codierter 2D-Darstellung und der codierten 2D-Kachel erzeugt. Der Paketersteller
In einer alternativen Implementierung der Schritte, die
In einer anderen alternativen Implementierung können die QoS der codierten rechteckigen 2D-Darstellung und die QoS der codierten 2D-Kachel dynamisch angepasst werden, zum Beispiel auf Basis der Bandbreite, die für den Videodatenstrom verfügbar ist. Demgemäß kann in einigen Implementierungen die QoS der codierten rechteckigen 2D-Darstellung ungefähr gleich der QoS der codierten 2D-Kachel sein, sollte zum Beispiel ein Schwellenwert der Bandbreite verfügbar sein. Die Decodierung kann ähnlich implementiert werden.In another alternative implementation, the QoS of the coded rectangular 2D representation and the QoS of the coded 2D tile may be dynamically adjusted, for example based on the bandwidth available for the video data stream. Accordingly, in some implementations, the QoS of the encoded rectangular 2D representation may be approximately equal to the QoS of the encoded 2D tile, for example, a bandwidth threshold should be available. The decoding can be implemented similarly.
In Schritt S2010 wird die codierte 2D-Darstellung decodiert. Ein Videodecodierer (z. B. Decodierer
In Schritt S2015 wird die 2D-Darstellung in das sphärische Videoframe umgewandelt. Die decodierte 2D-Darstellung kann zum Beispiel in ein sphärisches Videoframe (oder Bild) umgewandelt werden. Die 2D-Darstellung kann zum Beispiel durch Umkehr der Technik wie oben in Bezug auf die Abbildung eines sphärischen Frames (oder Bildes) auf einer 2D-Darstellung des sphärischen Frames (oder Bildes) beschrieben umgewandelt werden.In step S2015, the 2D representation is converted to the spherical video frame. For example, the decoded 2D representation may be converted to a spherical video frame (or image). For example, the 2D representation may be converted by reversing the technique as described above with respect to the imaging of a spherical frame (or image) on a 2D representation of the spherical frame (or image).
In Schritt S2020 wird die codierte 2D-Kachel decodiert. Ein Videodecodierer (z. B. Decodierer
In Schritt S2025 werden entsprechende Blöcke des sphärischen Videoframes durch die decodierte 2D-Kachel ersetzt. Das Kachelaustauschmodul
In Schritt S2030 wird ein sphärischer Videodatenstrom auf Basis mindestens eines sphärischen Videoframes einschließlich der ersetzten 2D-Kachel erzeugt. Mindestens ein Videoframe der rekonstruierten umgewandelten Pixel des sphärischen Videos, das Teile beinhaltet, die durch die 2D-Kachel ersetzt wurden, kann zum Beispiel in einer Sequenz organisiert werden, um einen sphärischen Videodatenstrom zu bilden. Wie oben erörtert, wurde die Kachel mit einer höheren QoS codiert als die rechteckige 2D-Darstellung des sphärischen Videoframes. Demgemäß kann das Erzeugen des sphärischen Videodatenstroms einschließlich des Ersetzen durch die 2D-Kachel dazu führen, dass der sichtbare Teil des sphärischen Videodatenstroms von einer höheren Qualität ist als der nicht sichtbare Teil des sphärischen Videodatenstroms während einer Wiedergabe des sphärischen Videodatenstroms.In step S2030, a spherical video data stream is generated based on at least one spherical video frame including the replaced 2D tile. For example, at least one video frame of the reconstructed converted pixels of the spherical video, including portions replaced by the 2D tile, may be organized in a sequence to form a spherical video data stream. As discussed above, the tile was taken with a higher QoS than the rectangular 2D representation of the spherical video frame. Accordingly, generating the spherical video data stream, including replacement by the 2D tile, may result in the visible portion of the spherical video data stream being of a higher quality than the invisible portion of the spherical video data stream during playback of the spherical video data stream.
Wie in
Wie oben erörtert, ist ein sphärisches Bild ein Bild, das in alle Richtungen kontinuierlich ist. Demgemäß sind, wenn das sphärische Bild in eine Vielzahl von Blöcken zerlegt wird, die Vielzahl von Blöcken über das sphärische Bild fortlaufend. Mit anderen Worten, es gibt keine Ränder oder Grenzen wie in einem 2D-Bild. In exemplarischen Implementierungen kann ein benachbarter Endblock ein fortlaufender Block zu einem Block n der Grenze der 2D-Darstellung sein. In der exemplarischen Implementierung, die in
Daher kann in einem Codierschema, in dem ein benachbarter Block verwendet wird, ein Block an einer Grenze der rechteckigen 2D-Darstellung einen entsprechenden benachbarten Endblock haben, der sich anderswo in der rechteckigen 2D-Darstellung befindet.
Der Quincunx-Projektionsalgorithmus nach Pierce gibt einen Punkt P auf der Oberfläche der Erde an, ein Abstand p vom Nordpol mit Längengrad θ und Breitengrad λ wird zuerst auf einem Punkt (p, θ) der Ebene durch den Äquator abgebildet, gesehen als komplexe Ebene mit Koordinate w; diese w Koordinate wird auf einem anderen Punkt (x, y) der komplexen Eben (gegeben sei die Koordinate z) durch eine elliptische Funktion der ersten Art abgebildet. Bei Verwendung der Notation von Gudermann für die Ellipsenfunktion nach Jabobi sind die Beziehungen:
Andere quadratische und/oder rechteckige Projektionen entsprechen dem Umfang dieser Offenbarung.Other square and / or rectangular projections are within the scope of this disclosure.
In Schritt S2210 wird die quadratische 2D-Darstellung auf einer rechteckigen 2D-Darstellung abgebildet. Die Abbildung kann die Abbildung der quadratischen 2D-Darstellung auf einer anderen (oder zweiten) 2D-Darstellung beinhalten. Die andere 2D-Darstellung kann ein Rechteck sein.
In Schritt S2215 wird die rechteckige 2D-Darstellung in eine C×R-Matrix von N×N-Blöcken zerlegt. Wie zum Beispiel in
Demgemäß sind in Schritt S2220 benachbarte Endblöcke zugeordnet. Wie oben erörtert, werden zum Beispiel Blöcke
In der exemplarischen Implementierung, die in
Die Nutzung der räumlichen Redundanz zwischen Mustern innerhalb eines Frames (z. B. Frame, Bild, Schicht, Gruppe von Makroblöcken) wird als Intraprädiktion bezeichnet. Die Nutzung der räumlichen Redundanz für Muster zwischen Frames (z. B. Frame, Bild, Schicht, Gruppe von Makroblöcken) wird als Interprädiktion bezeichnet. Bei der Intraprädiktion kann ein Prädiktionsblock als Reaktion auf früher codierte und rekonstruierte Blöcke in demselben Frame (oder Bild) erzeugt werden. Bei der Interprädiktion kann ein Prädiktionsblock als Reaktion auf früher codierte und rekonstruierte Blöcke in einem anderen (z. B. im Zeitverlauf früheren oder Basis/Vorlagen)-Frame erzeugt werden. Der Prädiktionsblock wird vor der Codierung aus dem aktuellen Block subtrahiert. Bei Luminanz(Luma)-Proben kann der Prädiktionsblock zum Beispiel für jeden N×N(z. B. 4×4)-Teilblock oder für einen N×N(z. B. 16×16)-Makroblock gebildet werden. Bei der Codierung und/oder Decodierung können die Blöcke oder Makroblöcke sequenziell innerhalb jedes Frames oder jede Schicht codiert werden.The use of spatial redundancy between patterns within a frame (eg, frame, image, layer, group of macroblocks) is referred to as intra prediction. The use of spatial redundancy for patterns between frames (eg, frame, image, layer, group of macroblocks) is called inter-prediction. In intraprediction, a prediction block may be generated in response to previously coded and reconstructed blocks in the same frame (or image). In interprediction, a prediction block may be generated in response to previously coded and reconstructed blocks in another (eg, earlier or base / template) frame. The prediction block is subtracted from the current block before encoding. For example, in luminance (luma) samples, the prediction block may be formed for every N × N (e.g., 4 × 4) sub-block or for an N × N (e.g., 16 × 16) macroblock. In coding and / or decoding, the blocks or macroblocks may be encoded sequentially within each frame or layer.
Bei der Intraprädiktion kann ein Codierdurchlauf die sequenzielle Codierung von Blöcken entlang einer Reihe (z. B. von oben nach unten), einer Spalte (z. B. von links nach rechts) oder eines Zickzack-Musters (z. B. beginnend in der oberen linken Ecke) beinhalten. In einem Intraprädiktionscodierdurchlauf wurden die Blöcke, die sich über dem und links vom aktuellen Block im Frame (oder Bild) befinden, früher codiert und rekonstruiert. Demgemäß können die Blöcke, die sich über dem und links vom aktuellen Block befinden, für den Codierer/Decodierer als Prädiktionsreferenz verfügbar sein. Wenn sich der aktuelle Block jedoch in der oberen linken Ecke eines Frames befindet, wurden keine früheren Blöcke im Frame codiert. Des Weiteren wurden, wenn sich der aktuelle Block in der oberen Reihe eines Frames befindet, keine Nachbarn über dem aktuellen decodiert. Noch des Weiteren wurden, wenn sich der aktuelle Block in der linken Spalte eines Frames befindet, keine zwei Nachbarn in derselben Reihe wie der aktuelle Block codiert.In intraprediction, a coding pass may include the sequential encoding of blocks along a row (eg, from top to bottom), a column (eg, from left to right), or a zigzag pattern (eg, starting in the left) upper left corner). In an intraprediction encoding pass, the blocks that are above and to the left of the current block in the frame (or image) were coded earlier and reconstructed. Accordingly, the blocks that are above and to the left of the current block may be available to the encoder / decoder as a prediction reference. However, if the current block is in the upper left corner of a frame, no previous blocks in the frame have been encoded. Furthermore, if the current block is in the top row of a frame, no neighbors were decoded above the current one. Still further, when the current block is in the left column of a frame, no two neighbors in the same row as the current block were coded.
In Schritt S2310 wird ermittelt, ob der aktuelle Block eine Frame(oder Bild)-Grenze ist. In einer exemplarischen Implementierung kann zum Beispiel eine C×R-Matrix von N×N-Blöcken Pixel in jedem Block beinhalten. Demgemäß beinhalten Blöcke in Reihe 0, Spalte 0, Reihe R-1 und Spalte C-1 Pixel des sphärischen Bildes. Daher befindet sich, wenn die C×R-Matrix der Blöcke während eines Scans Pixel in jedem Block beinhaltet und die Spalte/Reihe = 0 oder die Spalte/Reihe = C-1/R-1 ist, der Block an der Grenze. Wenn der Block an einer Grenze ist, geht die Verarbeitung zu Schritt S2315 weiter. Andernfalls fährt die Verarbeitung mit Schritt S2325 fort.In step S2310, it is determined whether the current block is a frame (or image) boundary. For example, in one exemplary implementation, a CxR matrix of NxN blocks may include pixels in each block. Accordingly, blocks in row 0, column 0, row R-1, and column C-1 include pixels of the spherical image. Therefore, if the CxR matrix of the blocks during a scan includes pixels in each block and the column / row = 0 or column / row = C-1 / R-1, the block is at the boundary. If the block is at a boundary, the processing proceeds to step S2315. Otherwise, the processing proceeds to step S2325.
In Schritt S2315 wird ein benachbarter Endblock nachgeschlagen (oder identifiziert oder gesucht). In einer exemplarischen Implementierung kann zum Beispiel eine C×R-Matrix von Blöcken eine zugeordnete LUT haben, die Grenzblöcke auf einem entsprechenden benachbarten Endblock abbildet. In diesem Beispiel können Spalten und Reihen benachbarter Endblöcke in einer Lookup-Tabelle (z. B. LUT
In Schritt S2320 wird ein benachbarter Endblock als mindestens eine Vorlage ausgewählt. Wie oben erörtert, kann zum Beispiel während der Intraprädiktion ein Prädiktionsblock als Reaktion auf früher codierte und rekonstruierte Blöcke in demselben Frame (oder Bild) erzeugt werden. Der früher codierte und rekonstruierte Block/die früher codierten und rekonstruierten Blöcke können aus benachbarten Blöcken (z. B. einem Block, der sich über dem und/oder links vom zu codierenden Block befindet) als Vorlage ausgewählt werden. In diesem Fall befindet sich der zu codierende Block am Ende einer Spalte und/oder Reihe in der C×R-Matrix. Demgemäß kann mindestens einer der benachbarten Blöcke, der als Vorlage ausgewählt werden soll, einer der nachgeschlagenen benachbarten Endblöcke sein.In step S2320, an adjacent end block is selected as at least one template. For example, as discussed above, during intraprediction, a prediction block may be generated in response to previously coded and reconstructed blocks in the same frame (or image). The previously coded and reconstructed block (s) may be selected from adjacent blocks (eg, a block located above and / or to the left of the block to be coded) as a template. In this case, the block to be coded is at the end of a column and / or row in the CxR matrix. Accordingly, at least one of the adjacent blocks to be selected as a template may be one of the looked-up adjacent end blocks.
In Schritt S2325 wird ein benachbarter Block als mindestens eine Vorlage ausgewählt. Der früher codierte und rekonstruierte Block/die früher codierten und rekonstruierten Blöcke können zum Beispiel aus benachbarten Blöcken (z. B. einem Block, der sich über dem und/oder links vom zu codierenden Block befindet) als Vorlage ausgewählt werden. In diesem Fall befindet sich der zu codierende Block nicht am Ende einer Spalte und/oder Reihe in der C×R-Matrix. Demgemäß kann mindestens einer der benachbarten Blöcke, der als Vorlage ausgewählt werden sollen, aus einem Block über dem und/oder links vom zu codierenden Block ausgewählt werden.In step S2325, an adjacent block is selected as at least one template. For example, the previously encoded and reconstructed block (s) may be selected from adjacent blocks (eg, a block located above and / or to the left of the block to be encoded) as a template. In this case, the block to be coded is not at the end of a column and / or row in the CxR matrix. Accordingly, at least one of the adjacent blocks to be selected as a template may be selected from a block above and / or to the left of the block to be coded.
In mindestens einer exemplarischen Ausführungsform kann mehr als ein benachbarter Block für die Verwendung als Vorlage ausgewählt werden. Zum Beispiel können ein benachbarter Block und ein Block neben (in derselben Richtung) dem benachbarten Block ausgewählt werden (z. B. zwei Blöcke). Die ausgewählten Blöcke können gemittelt werden, um einen Vorlagenblock zu bilden. In diesem Beispiel ist es möglich, dass die Vorlage auf einem benachbarten Block und einem benachbarten Endblock basiert.In at least one exemplary embodiment, more than one adjacent block may be selected for use as a template. For example, an adjacent block and a block may be selected adjacent to (in the same direction) the neighboring block (eg, two blocks). The selected blocks can be averaged to form a template block. In this example, it is possible that the template is based on a neighboring block and an adjacent end block.
In Schritt S2330 wird ein Satz von Resten für nicht codierte Pixel des Videosequenz-Frames (oder Bildes) auf Basis der Vorlage erzeugt. Zum Beispiel kann mindestens ein Wert, der dem jeweiligen Pixel zugeordnet ist, von einem entsprechenden Wert subtrahiert werden, der einem entsprechenden Block der ausgewählten Vorlage zugeordnet ist.In step S2330, a set of remnants for unencoded pixels of the video sequence frame (or image) is generated based on the template. For example, at least one value associated with each pixel may be subtracted from a corresponding value associated with a corresponding block of the selected template.
In Schritt S2335 werden die nicht codierten Pixel codiert. Die erzeugten Pixel können zum Beispiel mithilfe einer konfigurierten Transformation (z. B. einer KLT, einer SVD, einer DCT oder einer ADST) in Transformationskoeffizienten transformiert (codiert oder komprimiert) werden.In step S2335, the non-coded pixels are coded. For example, the generated pixels may be transformed (coded or compressed) into transform coefficients using a configured transformation (eg, a KLT, SVD, DCT, or ADST).
In Schritt S2340 quantisiert der Codierer den codierten Satz der Restwerte für den Block. Der Controller
In Schritt S2350 gibt der Codierer den/die codierten (komprimierten) Videoframe(s) aus. Der Controller
In Schritt S2410 entropiedecodiert der Videodecodierer die codierten Videobits. Die komprimierten Videobits können zum Beispiel durch Entropiedecodierung decodiert werden, z. B. mithilfe kontextadaptiver binärarithmetischer Decodierung, um eine Reihe quantisierter Transformationskoeffizienten zu erzeugen. In Schritt S2415 dequantisiert der Videodecodierer die Transformationskoeffizienten, die durch die entropiedecodierten Bits angegeben werden. Die entropiedecodierten Videobits können zum Beispiel durch Abbildung von Werten in einem relativ kleinen Bereich der Werte in einen relativ großen Bereich dequantisiert werden (z. B. im Gegensatz zur oben beschriebenen Quantisierungsabbildung). Des Weiteren transformiert in Schritt S2420 der Videodecodierer die Videobits mithilfe einer angegebenen (z. B. im Header) Transformation (z. B. einer KLT, einer SVD, einer DCT oder einer ADST).In step S2410, the video decoder entropy decodes the coded video bits. The compressed video bits may be decoded by, for example, entropy decoding, e.g. Using context-adaptive binary arithmetic decoding to generate a set of quantized transform coefficients. In step S2415, the video decoder dequantizes the transform coefficients indicated by the entropy-decoded bits. For example, the entropy decoded video bits may be dequantized by mapping values in a relatively small range of values into a relatively wide range (eg, unlike the quantization map described above). Further, in step S2420, the video decoder transforms the video bits using a specified (eg, header) transformation (eg, a KLT, an SVD, a DCT, or an ADST).
In Schritt S2425 wird ermittelt, ob der aktuelle Block eine Frame(oder Bild)-Grenze ist. In einer exemplarischen Implementierung kann zum Beispiel eine C×R-Matrix von N×N-Blöcken Pixel in jedem Block beinhalten. Demgemäß beinhalten Blöcke in Reihe 0, Spalte 0, Reihe R-1 und Spalte C-1 Pixel des sphärischen Bildes. Daher befindet sich, wenn die C×R-Matrix der Blöcke während eines Scans Pixel in jedem Block beinhaltet und die Spalte/Reihe = 0 oder die Spalte/Reihe = C-1/R-1 ist, der Block an der Grenze. Wenn der Block an einer Grenze ist, geht die Verarbeitung zu Schritt S2430 weiter. Andernfalls fährt die Verarbeitung mit Schritt S2440 fort.In step S2425, it is determined whether the current block is a frame (or image) boundary. For example, in one exemplary implementation, a CxR matrix of NxN blocks may include pixels in each block. Accordingly, blocks in row 0, column 0, row R-1, and column C-1 include pixels of the spherical image. Therefore, if the CxR matrix of the blocks during a scan includes pixels in each block and the column / row = 0 or column / row = C-1 / R-1, the block is at the boundary. If the block is at a boundary, the processing proceeds to step S2430. Otherwise, the processing proceeds to step S2440.
In Schritt S2430 wird ein benachbarter Endblock nachgeschlagen. In einer exemplarischen Implementierung kann zum Beispiel eine C×R-Matrix von Blöcken eine zugeordnete LUT haben, die Grenzblöcke auf einem entsprechenden benachbarten Endblock abbildet. In diesem Beispiel können Spalten und Reihen benachbarter Endblöcke in einer Lookup-Tabelle (z. B. LUT
In Schritt S2435 wird ein benachbarter Endblock als mindestens eine Vorlage ausgewählt. Wie oben erörtert, kann zum Beispiel während der Intraprädiktion ein Prädiktionsblock als Reaktion auf früher codierte und rekonstruierte Blöcke in demselben Frame (oder Bild) erzeugt werden. Der früher codierte und rekonstruierte Block/die früher codierten und rekonstruierten Blöcke können aus benachbarten Blöcken (z. B. einem Block der sich über dem und/oder links vom zu codierenden Block befindet) als Vorlage ausgewählt werden. In diesem Fall befindet sich der zu codierende Block am Ende einer Spalte und/oder Reihe in der C×R-Matrix. Demgemäß kann mindestens einer der benachbarten Blöcke, der als Vorlage ausgewählt werden soll, einer der nachgeschlagenen benachbarten Endblöcke sein.In step S2435, an adjacent end block is selected as at least one template. For example, as discussed above, during intraprediction, a prediction block may be generated in response to previously coded and reconstructed blocks in the same frame (or image). The previously coded and reconstructed block (s) and the previously coded and reconstructed blocks may be selected from adjacent blocks (eg, a block located above and / or to the left of the block to be coded) as a template. In this case, the block to be coded is at the end of a column and / or row in the CxR matrix. Accordingly, at least one of the adjacent blocks to be selected as a template may be one of the looked-up adjacent end blocks.
In Schritt S2440 wird ein benachbarter Block als mindestens eine Vorlage ausgewählt. Der früher codierte und rekonstruierte Block/die früher codierten und rekonstruierten Blöcke können zum Beispiel aus benachbarten Blöcken (z. B. einem Block, der sich über dem und/oder links vom zu codierenden Block befindet) als Vorlage ausgewählt werden. In diesem Fall befindet sich der zu codierende Block nicht am Ende einer Spalte und/oder Reihe in der N×N-Matrix. Demgemäß kann mindestens einer der benachbarten Blöcke, der als Vorlage ausgewählt werden sollen, aus einem Block über dem und/oder links vom zu codierenden Block ausgewählt werden.In step S2440, an adjacent block is selected as at least one template. For example, the previously encoded and reconstructed block (s) may be selected from adjacent blocks (eg, a block located above and / or to the left of the block to be encoded) as a template. In this case, the block to be coded is not at the end of a column and / or row in the NxN matrix. Accordingly, at least one of the adjacent blocks to be selected as a template may be selected from a block above and / or to the left of the block to be coded.
In mindestens einer exemplarischen Ausführungsform kann mehr als ein benachbarter Block für die Verwendung als Vorlage ausgewählt werden. Zum Beispiel können ein benachbarter Block und ein Block neben (in derselben Richtung) dem benachbarten Block ausgewählt werden (z. B. zwei Blöcke). Die ausgewählten Blöcke können gemittelt werden, um einen Vorlagenblock zu bilden. In diesem Beispiel ist es möglich, dass die Vorlage auf einem benachbarten Block und einem benachbarten Endblock basiert.In at least one exemplary embodiment, more than one adjacent block may be selected for use as a template. For example, an adjacent block and a block may be selected adjacent to (in the same direction) the neighboring block (eg, two blocks). The selected blocks can be averaged to form a template block. In this example, it is possible that the template is based on a neighboring block and an adjacent end block.
In Schritt S2445 erzeugt der Videodecodierer rekonstruierte Pixel als Videoframe auf Basis der passenden Vorlage und der decodierten Videobits. Der Videodecodierer kann zum Beispiel die Reste (z. B. transformierte oder dekomprimierte Videobits) zur entsprechenden Position in der passenden Vorlage hinzufügen, was zu einem rekonstruierten Pixel führt.In step S2445, the video decoder generates reconstructed pixels as a video frame based on the matching template and the decoded video bits. For example, the video decoder may add the remainders (eg, transformed or decompressed video bits) to the appropriate location in the appropriate template, resulting in a reconstructed pixel.
In Schritt S2450 filtert der Videodecodierer das rekonstruierte Pixel im Videoframe. Ein Schleifenfilter kann zum Beispiel auf den rekonstruierten Block angewendet werden, um Blockartefakte zu verringern. Ein Deblockierungsfilter (z. B. wie unten in Bezug auf
In Schritt S2455 wird der 2D-Frame (oder das Bild) in ein sphärisches Videoframe (oder Bild) umgewandelt. Der 2D-Frame kann zum Beispiel durch Umkehr der Technik, wie oben in Bezug auf die Abbildung eines sphärischen Frames (oder Bildes) auf einer 2D-Darstellung des sphärischen Frames (oder Bildes) beschrieben, umgewandelt werden. Eine Beispieltechnik ist in Bezug auf
In Schritt S2460 erzeugt der Videodecodierer einen sphärischen Videodatenstrom (oder ein sphärisches Bild) auf Basis des/der Videoframes. Mindestens ein Videoframe der rekonstruierten umgewandelten Pixel kann zum Beispiel in einer Sequenz organisiert werden, um einen sphärischen Videodatenstrom zu bilden.In step S2460, the video decoder generates a spherical video data stream (or a spherical image) based on the video frame (s). For example, at least one video frame of the reconstructed converted pixels may be organized in a sequence to form a spherical video data stream.
In Schritt S2510 wird die quadratische 2D-Darstellung auf einem sphärischen Frame (oder Bild) abgebildet. Der Quincunx-Projektionsalgorithmus nach Pierce kann zum Beispiel verwendet werden, um die quadratische 2D-Darstellung in einen sphärischen Frame umzuwandeln. Gleichung 1 kann zum Beispiel verwendet werden, um sphärische Koordinaten für Pixel im sphärischen Frame auf Basis der X-, Y-Koordinaten der entsprechenden Pixel in der quadratischen 2D-Darstellung zu erzeugen.In step S2510, the 2D quadratic representation is mapped to a spherical frame (or image). For example, Pierce's quincunx projection algorithm can be used to transform the quadratic 2D representation into a spherical frame. For example, Equation 1 can be used to generate spherical coordinates for pixels in the spherical frame based on the X, Y coordinates of the corresponding pixels in the 2D quadratic representation.
Wie in
In Schritt S2610 wird ermittelt, ob der aktuelle Block eine Frame(oder Bild)-Grenze ist. In einer exemplarischen Implementierung kann zum Beispiel eine C×R-Matrix von N×N-Blöcken Pixel in jedem Block beinhalten. Demgemäß beinhalten Blöcke in Reihe 0, Spalte 0, Reihe R-1 und Spalte C-1 Pixel des sphärischen Bildes. Daher befindet sich, wenn die C×R-Matrix der Blöcke während eines vertikalen Scans Pixel in jedem Block beinhaltet und die Spalte = 0 oder die Spalte = C-1 ist, der Block an der Grenze. Des Weiteren könnten sich bei einem vertikalen Scan die zu scannenden Blöcke links vom zum verarbeitenden Block oder rechts vom zu verarbeitenden Block befinden. Daher kann beim Scannen mit einer linken Verarbeitungsorientierung Spalte 0 Grenzblöcke beinhalten. Beim Scannen mit einer rechten Verarbeitungsorientierung kann Spalte C-1 Grenzblöcke beinhalten. Beim Scannen mit einer doppelten Verarbeitungsorientierung können Spalten 0 und C-1 Grenzblöcke beinhalten. Wenn der Block an einer Grenze ist, geht die Verarbeitung zu Schritt S2615 weiter. Andernfalls fährt die Verarbeitung mit Schritt S2625 fort.In step S2610, it is determined whether the current block is a frame (or image) boundary. For example, in one exemplary implementation, a CxR matrix of NxN blocks may include pixels in each block. Accordingly, blocks in row 0, column 0, row R-1, and column C-1 include pixels of the spherical image. Therefore, if the CxR matrix of blocks during a vertical scan includes pixels in each block and column = 0 or column = C-1, the block is at the boundary. Furthermore, in a vertical scan, the blocks to be scanned could be to the left of the block to be processed or to the right of the block to be processed. Therefore, when scanning with a left processing orientation, column 0 may include boundary blocks. When scanning with a right processing orientation, column C-1 may include boundary blocks. When scanning with a dual processing orientation, columns 0 and C-1 may contain boundary blocks. If the block is at a boundary, the processing proceeds to step S2615. Otherwise, the processing proceeds to step S2625.
In Schritt S2615 wird ein benachbarter Endblock nachgeschlagen. In einer exemplarischen Implementierung kann zum Beispiel eine C×R-Matrix von Blöcken eine zugeordnete LUT haben, die Grenzblöcke auf einem entsprechenden benachbarten Endblock abbildet. In diesem Beispiel können Spalten und Reihen benachbarter Endblöcke in einer Lookup-Tabelle (z. B. LUT
In Schritt S2620 wird ein benachbarter Endblock als ein Vergleichsblock ausgewählt. Wie oben erörtert, können zum Beispiel während der Deblockierungsfilterung Pixel über einen Rand von zwei Blöcken hinweg gefiltert werden, um blockartige Übergänge zu entfernen. Der Vergleichsblock (für einen gescannten vertikalen Randblock) kann aus benachbarten Blöcken (z. B links vom Block, der den zu filternden vertikalen Rand beinhaltet) als Vergleichsblock ausgewählt werden. In diesem Fall befindet sich der Block, der den zu filternden vertikalen Rand beinhaltet, an einer Endspalte in der C×R-Matrix des Frames (oder Bildes). Demgemäß kann mindestens einer der benachbarten Blöcke, der als Vergleichsblock ausgewählt werden soll, einer der nachgeschlagenen benachbarten Endblöcke sein. Mit anderen Worten, der benachbarte Block, der als Vergleichsblock ausgewählt werden soll, kann ein anderer als der linke rekonstruierte Block im Vergleich zum zu deblockierenden Block sein.In step S2620, an adjacent end block is selected as a comparison block. For example, as discussed above, during deblocking filtering, pixels may be filtered over an edge of two blocks to remove blocky transitions. The comparison block (for a scanned vertical edge block) may be selected from adjacent blocks (eg, to the left of the block containing the vertical edge to be filtered) as the comparison block. In this case, the block containing the vertical edge to be filtered is located at an end column in the CxR matrix of the frame (or image). Accordingly, at least one of the adjacent blocks to be selected as the comparison block may be one of the looked-up adjacent end blocks. In other words, the adjacent block to be selected as the comparison block may be other than the left reconstructed block compared to the block to be deblocked.
In Schritt S2625 wird ein benachbarter Block als ein Vergleichsblock ausgewählt. Wie oben erörtert, können zum Beispiel während der Deblockierungsfilterung Pixel über einen Rand von zwei Blöcken hinweg gefiltert werden, um blockartige Übergänge zu entfernen. Der Vergleichsblock (für einen gescannten vertikalen Randblock) kann aus benachbarten Blöcken (z. B links vom Block, der den zu filternden vertikalen Rand beinhaltet) als Vergleichsblock ausgewählt werden. In diesem Fall befindet sich der Block, der den zu filternden vertikalen Rand beinhaltet, nicht an einer Endspalte in der C×R-Matrix des Frames (oder Bildes). Demgemäß kann mindestens einer der benachbarten Blöcke, der als Vergleichsblock ausgewählt werden soll, aus einem Block in einer benachbarten (z. B. linken) Spalte ausgewählt werden.In step S2625, an adjacent block is selected as a comparison block. For example, as discussed above, during deblocking filtering, pixels may be filtered over an edge of two blocks to remove blocky transitions. The comparison block (for a scanned vertical edge block) may be selected from adjacent blocks (eg, to the left of the block containing the vertical edge to be filtered) as the comparison block. In this case, the block containing the vertical edge to be filtered is not at an end column in the CxR matrix of the frame (or image). Accordingly, at least one of the adjacent blocks to be selected as a comparison block may be selected from one block in an adjacent (eg, left) column.
In Schritt S2630 wird der vertikale Rand gefiltert. Wie oben erörtert, kann zum Beispiel der die Breite des Deblockierungsfilters (z. B. Anzahl der zu deblockierenden Pixel) von der Breite des Artefakts (oder Verzerrung) abhängen. Daher wird eine Anzahl an Pixeln aus dem Block, der den zu filternden vertikalen Rand beinhaltet (z. B. 1, 2, 4 oder 8), eine entsprechende Anzahl aus dem Vergleichsblock ausgewählt. Die Pixel werden dann gefiltert. Das Filtern (oder Deblockieren) kann zum Beispiel einen Tiefpassfilter (z. B. zur Verringerung der Helligkeit über den Rand), die Anwendung eines Regressionsalgorithmus über die ausgewählten Pixel, die Anwendung eines Wavelet-basierenden Algorithmus über die ausgewählten Pixel, die Anwendung eines auf anisotroper Diffusion basierenden Algorithmus über die ausgewählten Pixel und/oder die Durchführung einer gewichteten Summe von Pixeln über die ausgewählten Pixel beinhalten. In jedem Fall kann ein Deblockieren über Blockgrenzen hinweg durchgeführt werden.In step S2630, the vertical edge is filtered. For example, as discussed above, the width of the deblocking filter (e.g., number of pixels to be deblocked) may depend on the width of the artifact (or distortion). Therefore, a number of pixels from the block including the vertical edge to be filtered (e.g., 1, 2, 4, or 8) is selected from the comparison block. The pixels are then filtered. For example, filtering (or deblocking) may include a low-pass filter (e.g., to reduce brightness across the edge), applying a regression algorithm over the selected pixels, applying a wavelet-based algorithm over the selected pixels, applying a anisotropic diffusion based algorithm over the selected pixels and / or performing a weighted sum of pixels over the selected pixels. In any case, de-blocking can be performed across block boundaries.
In Schritt S2635 wird ermittelt, ob der aktuelle Block der letzte vertikale Block ist. Wenn das Scannen zum Beispiel bei Block 0,0 begonnen wurde, kann der letzte Block C-1, R-1 sein. Wenn der Block der letzte vertikale Block ist, geht die Verarbeitung zu Schritt S2640 weiter. Andernfalls kehrt die Verarbeitung zu Schritt S2605 zurück.In step S2635, it is determined whether the current block is the last vertical block. For example, if scanning was started at block 0.0, the last block may be C-1, R-1. If the block is the last vertical block, the processing proceeds to step S2640. Otherwise, the processing returns to step S2605.
In Schritt S2640 wird ein horizontaler Rand gescannt. Ein Scan kann zum Beispiel in der oberen linken Ecke (0,0) des decodierten Frames beginnen. Der Scan kann sich entlang (nach rechts) bewegen, bis er Spalte C-1 erreicht. Der Scan kann erneut bei Spalte 0 beginnen und sich nach rechts arbeiten oder in einer Sequenz nach rechts-nach links-nach rechts scannen. Jedes Scannen eines horizontalen Randes kann einen oder mehrere Blöcke beinhalten.In step S2640, a horizontal edge is scanned. For example, a scan may begin in the upper left corner (0,0) of the decoded frame. The scan can move along (to the right) until it reaches column C-1. The scan can start again from column 0 and work to the right, or scan right-to-left to right in a sequence. Each scan of a horizontal border may include one or more blocks.
In Schritt S2645 wird ermittelt, ob der aktuelle Block eine Frame(oder Bild)-Grenze ist. In einer exemplarischen Implementierung kann zum Beispiel eine C×R-Matrix von N×N-Blöcken Pixel in jedem Block beinhalten. Demgemäß beinhalten Blöcke in Reihe 0, Spalte 0, Reihe R-1 und Spalte C-1 Pixel des sphärischen Bildes. Daher befindet sich, wenn die C×R-Matrix der Blöcke während eines horizontalen Scans Pixel in jedem Block beinhaltet und die Reihe = 0 oder die Reihe = R-1 ist, der Block an der Grenze. Wenn der Block an einer Grenze ist, geht die Verarbeitung zu Schritt S2650 weiter. Andernfalls fährt die Verarbeitung mit Schritt S2660 fort.In step S2645, it is determined whether the current block is a frame (or image) boundary. For example, in one exemplary implementation, a CxR matrix of NxN blocks may include pixels in each block. Accordingly, blocks in row 0, column 0, row R-1, and column C-1 include pixels of the spherical image. Therefore, if the CxR matrix of blocks during a horizontal scan includes pixels in each block and row = 0 or row = R-1, the block is at the boundary. If the block is at a boundary, the processing proceeds to step S2650. Otherwise, the processing proceeds to step S2660.
In Schritt S2650 wird ein benachbarter Endblock nachgeschlagen. In einer exemplarischen Implementierung kann zum Beispiel eine C×R-Matrix von Blöcken eine zugeordnete LUT haben, die Grenzblöcke auf einem entsprechenden benachbarten Endblock abbildet. In diesem Beispiel können Spalten und Reihen benachbarter Endblöcke in einer Lookup-Tabelle (z. B. LUT
In Schritt S2655 wird ein benachbarter Endblock als ein Vergleichsblock ausgewählt. Wie oben erörtert, können zum Beispiel während der Deblockierungsfilterung Pixel über einen Rand von zwei Blöcken hinweg gefiltert werden, um blockartige Übergänge zu entfernen. Der Vergleichsblock (für einen gescannten horizontalen Randblock) kann aus benachbarten Blöcken (z. B über dem Block, der den zu filternden horizontalen Rand beinhaltet) als Vergleichsblock ausgewählt werden. In diesem Fall befindet sich der Block, der den zu filternden horizontalen Rand beinhaltet, in einer oberen oder unteren Reihe in der C×R-Matrix des Frames (oder Bildes). Demgemäß kann mindestens einer der benachbarten Blöcke, der als Vergleichsblock ausgewählt werden soll, einer der nachgeschlagenen benachbarten Endblöcke sein. Mit anderen Worten, der benachbarte Block, der als Vergleichsblock ausgewählt werden soll, kann ein anderer als der obere rekonstruierte Block im Vergleich zum zu deblockierenden Block sein.In step S2655, an adjacent end block is selected as a comparison block. For example, as discussed above, during deblocking filtering, pixels may be filtered over an edge of two blocks to remove blocky transitions. The comparison block (for a scanned horizontal edge block) may be off adjacent blocks (eg above the block containing the horizontal edge to be filtered) are selected as the comparison block. In this case, the block containing the horizontal edge to be filtered is located in an upper or lower row in the CxR matrix of the frame (or image). Accordingly, at least one of the adjacent blocks to be selected as the comparison block may be one of the looked-up adjacent end blocks. In other words, the adjacent block to be selected as the comparison block may be other than the upper reconstructed block compared to the block to be deblocked.
In Schritt S2660 wird ein benachbarter Block als ein Vergleichsblock ausgewählt. Wie oben erörtert, können zum Beispiel während der Deblockierungsfilterung Pixel über einen Rand von zwei Blöcken hinweg gefiltert werden, um blockartige Übergänge zu entfernen. Der Vergleichsblock (für einen gescannten horizontalen Randblock) kann aus benachbarten Blöcken (z. B über dem Block, der den zu filternden horizontalen Rand beinhaltet) als Vergleichsblock ausgewählt werden. In diesem Fall befindet sich der Block, der den zu filternden horizontalen Rand beinhaltet, nicht in einer oberen oder unteren Reihe in der C×R-Matrix des Frames (oder Bildes). Demgemäß kann mindestens einer der benachbarten Blöcke, der als Vergleichsblock ausgewählt werden soll, aus einem Block in einer benachbarten (z. B. oberen) Reihe ausgewählt werden.In step S2660, an adjacent block is selected as a comparison block. For example, as discussed above, during deblocking filtering, pixels may be filtered over an edge of two blocks to remove blocky transitions. The comparison block (for a scanned horizontal edge block) may be selected from adjacent blocks (eg, above the block containing the horizontal edge to be filtered) as the comparison block. In this case, the block containing the horizontal edge to be filtered is not in an upper or lower row in the CxR matrix of the frame (or image). Accordingly, at least one of the adjacent blocks to be selected as a comparison block may be selected from one block in an adjacent (eg upper) row.
In Schritt S2665 wird der horizontale Rand gefiltert. Wie oben erörtert, kann zum Beispiel der die Breite des Deblockierungsfilters (z. B. Anzahl der zu deblockierenden Pixel) von der Höhe des Artefakts (oder Verzerrung) abhängen. Daher wird eine Anzahl an Pixeln aus dem Block, der den zu filternden horizontalen Rand beinhaltet (z. B. 1, 2, 4 oder 8), und eine entsprechende Anzahl aus dem Vergleichsblock ausgewählt. Die Pixel werden dann gefiltert. Das Filtern (oder Deblockieren) kann zum Beispiel einen Tiefpassfilter (z. B. zur Verringerung der Helligkeit über den Rand), die Anwendung eines Regressionsalgorithmus über die ausgewählten Pixel, die Anwendung eines Wavelet-basierenden Algorithmus über die ausgewählten Pixel, die Anwendung eines auf anisotroper Diffusion basierenden Algorithmus über die ausgewählten Pixel und/oder die Durchführung einer gewichteten Summe von Pixeln über die ausgewählten Pixel beinhalten. In jedem Fall kann ein Deblockieren über Blockgrenzen hinweg durchgeführt werden.In step S2665, the horizontal border is filtered. For example, as discussed above, the width of the deblocking filter (e.g., number of pixels to be deblocked) may depend on the artifact (or distortion) height. Therefore, a number of pixels from the block including the horizontal edge to be filtered (e.g., 1, 2, 4 or 8) and a corresponding number from the comparison block are selected. The pixels are then filtered. For example, filtering (or deblocking) may include a low-pass filter (e.g., to reduce brightness across the edge), applying a regression algorithm over the selected pixels, applying a wavelet-based algorithm over the selected pixels, applying a anisotropic diffusion based algorithm over the selected pixels and / or performing a weighted sum of pixels over the selected pixels. In any case, de-blocking can be performed across block boundaries.
In Schritt S2670 wird ermittelt, ob der aktuelle Block der letzte horizontale Block ist. Wenn das Scannen zum Beispiel bei Block 0,0 begonnen wurde, kann der letzte Block C-1, R-1 sein. Wenn der Block der letzte horizontale Block ist, endet der Deblockierungsvorgang. Andernfalls kehrt die Verarbeitung zu Schritt S2640 zurück.In step S2670, it is determined whether the current block is the last horizontal block. For example, if scanning was started at block 0.0, the last block may be C-1, R-1. If the block is the last horizontal block, the deblocking process ends. Otherwise, the processing returns to step S2640.
Es ist darauf hinzuweisen, dass die Systeme
Computergerät
Der Speicher
Das Speichergerät
Ein Computerprogrammprodukt kann konkret in einem Informationsträger ausgeführt sein. Das Computerprogrammprodukt kann auch Anweisungen enthalten, die, wenn sie ausgeführt werden, ein oder mehrere Verfahren wie die oben beschriebenen durchführen. Der Informationsträger ist ein computer- oder maschinenlesbares Medium wie der Speicher
Der High-Speed-Controller
Das Computergerät
Computergerät
Der Prozessor
Prozessor
Der Speicher
Der Speicher kann zum Beispiel Flashspeicher und/oder NVRAM-Speicher beinhalten, wie unten besprochen. In einer Implementierung ist ein Computerprogrammprodukt greifbar in einem Informationsträger ausgeführt. Das Computerprogrammprodukt enthält Anweisungen, die, wenn sie ausgeführt werden, ein oder mehrere Verfahren wie die oben beschriebenen durchführen. Der Informationsträger ist ein computer- oder maschinenlesbares Medium, wie der Speicher
Gerät
Gerät
Das Computergerät
Einige der vorstehend genannten exemplarischen Ausführungsformen werden als Prozesse oder Verfahren anhand von Flussdiagrammen beschrieben. Obwohl die Flussdiagramme die Operationen als sequentielle Prozesse darstellen, verlaufen viele der Operationen parallel, gleichzeitig oder simultan. Zusätzlich kann die Reihenfolge der Vorgänge neu angeordnet werden. Die Prozesse können beendet werden, wenn die Operationen abgeschlossen sind, können aber auch zusätzliche Schritte innehaben, die nicht in der Figur dargestellt sind. Die Prozesse können Verfahren, Funktionen, Prozeduren, Subroutinen, Subprogrammen, usw. entsprechen.Some of the above exemplary embodiments are described as processes or methods by way of flowcharts. Although the flowcharts represent the operations as sequential processes, many of the operations are parallel, simultaneous, or simultaneous. In addition, the order of operations can be rearranged. The processes may be terminated when the operations are completed, but may also have additional steps not shown in the figure. The processes may correspond to methods, functions, procedures, subroutines, subprograms, etc.
Die oben erörterten Verfahren, von denen einige durch die Flussdiagramme veranschaulicht sind, können durch Hardware, Software, Firmware, Middleware, Mikrocode, Hardwarebeschreibungssprachen oder eine beliebige Kombination davon implementiert sein. Falls durch Software, Firmware, Middleware oder Microcode implementiert, können der Programmcode oder Codesegmente, die die erforderlichen Aufgaben ausführen, auf einem maschinen- oder computerlesbaren Medium wie einem Speichermedium gespeichert werden. Ein Prozessor/Prozessoren kann/können die nötigen Aufgaben durchführen.The methods discussed above, some of which are illustrated by the flowcharts, may be implemented by hardware, software, firmware, middleware, microcode, hardware description languages, or any combination thereof. If implemented by software, firmware, middleware or microcode, For example, the program code or code segments performing the required tasks may be stored on a machine or computer readable medium such as a storage medium. A processor / processors can / do the necessary tasks.
Spezifische strukturelle und funktionelle Details, die hierin offenbart sind, sind lediglich zum Zwecke der Beschreibung exemplarischer Ausführungsformen angegeben. Exemplarische Ausführungsformen können in vielen Formen ausgeführt sein und sollten nicht als durch die hierin beschriebenen Ausführungsformen begrenzt angesehen werden.Specific structural and functional details disclosed herein are given solely for the purpose of describing exemplary embodiments. Exemplary embodiments may be embodied in many forms and should not be construed as limited by the embodiments described herein.
Obgleich die Begriffe erste, zweite usw. hierin verwendet werden können, um verschiedene Elemente zu beschreiben, sollten diese Elemente nicht durch diese Begriffe beschränkt werden. Diese Begriffe werden nur verwendet, um ein Element vom anderen zu unterscheiden. Ein erstes Element könnte beispielsweise als zweites Element bezeichnet sein und, auf gleiche Weise, kann ein zweites Element als erstes Element bezeichnet sein, ohne dass von dem Umfang der exemplarischen Ausführungsform abgewichen wird. Wie hierin verwendet, schließt der Begriff „und/oder” sämtliche Kombinationen von einem oder mehreren der zugewiesenen aufgeführten Posten ein.Although the terms first, second, etc. may be used herein to describe various elements, these elements should not be limited by these terms. These terms are only used to distinguish one element from the other. For example, a first element could be referred to as a second element and, in like manner, a second element may be referred to as a first element, without departing from the scope of the exemplary embodiment. As used herein, the term "and / or" includes all combinations of one or more of the listed listed items.
Es versteht sich, dass, wenn ein Element als mit einem anderen Element „verbunden” oder „gekoppelt” bezeichnet wird, es mit dem anderen Element direkt verbunden oder gekoppelt sein kann, oder es können dazwischen geschaltete Elemente vorhanden sein. Wenn hingegen ein Element als mit einem anderen Element „direkt verbunden” oder „direkt gekoppelt” bezeichnet wird, gibt es keine vorhandenen, dazwischenliegenden Elemente. Andere Worte, die verwendet werden, um die Beziehung zwischen Elementen zu beschreiben, sollten in einer ähnlichen Weise interpretiert werden (z. B. „zwischen” versus „direkt zwischen”, „benachbart” und „direkt benachbart” usw.).It should be understood that when an element is referred to as being "connected" or "coupled" to another element, it may be directly connected or coupled to the other element, or there may be intervening elements. Conversely, when an element is referred to as being "directly connected" or "directly coupled" to another element, there are no existing intermediate elements. Other words used to describe the relationship between elements should be interpreted in a similar manner (eg, "between" versus "directly between," "adjacent" and "directly adjacent," etc.).
Die hier verwendete Terminologie dient lediglich der Beschreibung spezieller Ausführungsformen und soll keine Beschränkung von exemplarischen Ausführungsformen darstellen. Wie hierin verwendet, sind die Singularformen „ein” und „die” dafür beabsichtigt, ebenso die Pluralformen mit einzuschließen, außer wenn der Kontext eindeutig etwas anderes angibt. Es versteht sich ferner, dass die Begriffe „umfasst”, „umfassend”, „beinhalten” und/oder „beinhaltend”, wenn sie hierin verwendet werden, das Bestehen angegebener Funktionen, Ganzzahlen, Schritte, Operationen, Elemente und/oder Komponenten angeben, aber nicht das Bestehen oder Hinzufügen von einem oder mehreren anderen Funktionen, Ganzzahlen, Schritten, Operationen, Elementen, Komponenten und/oder Gruppen davon ausschließt.The terminology used herein is for the purpose of describing specific embodiments only and is not intended to be limiting of exemplary embodiments. As used herein, the singular forms "a" and "the" are intended to include as well the plural forms unless the context clearly indicates otherwise. It is further understood that the terms "comprising," "comprising," "including," and / or "including," as used herein, indicate the existence of specified functions, integers, steps, operations, elements, and / or components. but does not exclude the existence or addition of one or more other functions, integers, steps, operations, elements, components and / or groups thereof.
Es sollte auch angemerkt werden, dass in einigen alternativen Ausführungsformen die Funktionen/Vorgänge außerhalb der in den Figuren dargestellten Reihenfolge auftreten können. Zwei Figuren, die beispielsweise nacheinander gezeigt werden, können gleichzeitig oder manchmal in umgekehrter Reihenfolge ausgeführt werden, je nach den involvierten Funktionalitäten/Handlungen.It should also be noted that in some alternative embodiments, the functions / operations may occur outside the order shown in the figures. For example, two figures, shown one at a time, may be executed simultaneously or sometimes in reverse order, depending on the functionalities / actions involved.
Sofern nicht anders definiert, haben alle hierin verwendeten Begriffe (einschließlich technischer und wissenschaftlicher Begriffe) dieselbe Bedeutung wie sie von Fachleuten auf dem Gebiet, zu dem exemplarischen Ausführungsformen gehören, allgemein verstanden werden. Es sollte auch beachtet werden, dass Begriffe, z. B. solche, die in allgemeingültigen Wörterbüchern verwendet werden, so zu verstehen sind, dass sie die Bedeutung annehmen, die für sie im fachlichen Zusammenhang gilt und dass sie nicht idealisiert oder übermäßig formal verwendet werden, es sei denn, dies wird ausdrücklich angegeben.Unless otherwise defined, all terms (including technical and scientific terms) used herein have the same meaning as commonly understood by one of ordinary skill in the art to which exemplary embodiments belong. It should also be noted that terms such. For example, those used in generic dictionaries are to be understood to assume the meaning that applies to them in a technical context and that they are not idealized or excessively formally used unless expressly stated.
Teile der obigen exemplarischen Ausführungsformen und entsprechende detaillierte Beschreibung werden in Bezug auf Software oder Algorithmen und symbolische Darstellungen der Operationen an Databits innerhalb eines Computerspeichers präsentiert. Diese Beschreibungen und Darstellungen sind von Datenverarbeitungsexperten verwendete Mittel, um das Wesentliche ihrer Arbeit anderen Fachleuten auf dem Gebiet zu vermitteln. Ein Algorithmus, so wie der Begriff hier verwendet wird und im Allgemeinen verstanden wird, wird als selbstkonsistente Sequenz von Schritten verstanden, die zu einem erwünschten Ergebnis führen. Die Schritte sind die, die eine physische Manipulierung der physischen Mengen erfordern. Normalerweise, aber nicht notwendigerweise, können solche Mengen die Form optischer, elektrischer oder magnetischer Signale annehmen, die gespeichert, übertragen, kombiniert, verglichen oder sonst manipuliert werden können. Es hat sich zuweilen bewährt, diese Signale hauptsächlich aus Gründen der gemeinsamen Verwendung, als Bits, Werte, Elemente, Symbole, Zeichen, Begriffe, Zahlen oder dergleichen zu bezeichnen.Portions of the above exemplary embodiments and corresponding detailed description are presented in terms of software or algorithms and symbolic representations of the operations on data bits within a computer memory. These descriptions and representations are means used by data processing experts to convey the substance of their work to others skilled in the art. An algorithm, as the term is used herein and generally understood, is understood to be a self-consistent sequence of steps that result in a desired result. The steps are those that require a physical manipulation of the physical quantities. Usually, but not necessarily, such amounts may take the form of optical, electrical or magnetic signals that may be stored, transferred, combined, compared or otherwise manipulated. It has sometimes been found useful to refer to these signals principally for purposes of common usage, as bits, values, elements, symbols, characters, terms, numbers, or the like.
Bei den obigen veranschaulichenden Ausführungsformen beinhaltet die Bezugnahme auf Handlungen und symbolische Darstellungen von Operationen (z. B. in Form von Flussdiagrammen), die als Programmmodule oder funktionale Prozesse implementiert werden können, Routinen, Programme, Objekte, Komponenten, Datenstrukturen usw., die bestimmte Aufgaben durchführen oder bestimmte abstrakte Datentypen implementieren, und sie können unter Verwendung bestehender Hardware an vorhandenen Strukturelementen beschrieben und/oder implementiert werden. Diese bestehende Hardware kann eine oder mehrere zentrale Recheneinheiten (CPUs), digitale Signalprozessoren (DSPs), anwendungsspezifische integrierte Schaltungen, feldprogrammierbare Gate-Arrays(FPGAs)-Computer oder dergleichen beinhalten.In the above illustrative embodiments, reference to acts and symbolic representations of operations (eg, in the form of flowcharts) that may be implemented as program modules or functional processes include routines, programs, objects, components, data structures, and so on Perform tasks or implement certain abstract data types, and they can under Use existing hardware to existing structural elements described and / or implemented. This existing hardware may include one or more central processing units (CPUs), digital signal processors (DSPs), application specific integrated circuits, field programmable gate arrays (FPGAs) computers, or the like.
Es sollte jedoch beachtet werden, dass alle diese und ähnliche Begriffe den entsprechenden physikalischen Mengen zugeordnet werden müssen und lediglich praktische Beschriftungen sind, die auf diese Mengen angewendet werden. Außer wenn spezifisch anders ausgesagt als aus der obigen Abhandlung ersichtlich, beziehen sich verwendete Begriffe, wie z. B. „verarbeitend” oder „berechnend” oder „bestimmend” oder „anzeigend” oder dergleichen, auf die Aktion und Prozesse eines Computersystems oder eines ähnlichen elektronischen Computergeräts beziehen, das Daten manipuliert und umwandelt, die als physikalische (elektronische) Mengen innerhalb der Computersystemspeicher oder -register oder anderer solcher Informationsspeicher-, Übertragungs- oder Anzeigegeräte dargestellt sind.It should be noted, however, that all of these and similar terms must be assigned to the corresponding physical quantities and are merely practical labels applied to those quantities. Unless specifically stated otherwise than apparent from the above discussion, terms used such as, for example: "Processing" or "calculating" or "determining" or "indicating" or the like, to the action and processes of a computer system or similar electronic computing device that manipulates and converts data stored as physical (electronic) amounts within the computer system memory or register or other such information storage, transmission or display devices are shown.
Es ist auch zu beachten, dass die softwareimplementierten Aspekte der exemplarischen Ausführungsformen normalerweise auf irgendeiner Form eines nicht flüchtigen Programmspeichermediums codiert oder über irgendeine Art von Übertragungsmedium implementiert werden. Das Programmspeichermedium kann magnetisch (z. B. eine Diskette oder ein Festplattenlaufwerk) oder optisch (z. B. eine CD-Nur-Lesespeicher oder „CD-ROM”) sein und kann als Nur-Lesen oder Zufallszugriff gestaltet sein. Auf gleiche Weise kann das Transmissionsmedium verdrillte Adernpaare, Koaxialkabel, Lichtwellenleiter oder ein anderes passendes, dem Fach bekanntes Transmissionsmedium sein. Die exemplarischen Ausführungsformen sind nicht auf diese Aspekte jeglicher beschriebener Implementierungen limitiert.It should also be noted that the software-implemented aspects of the exemplary embodiments are normally encoded on some form of nonvolatile program storage medium or implemented over some type of transmission medium. The program storage medium may be magnetic (eg, a floppy disk or a hard disk drive) or optical (eg, a CD read-only memory or "CD-ROM") and may be configured as read-only or random access. Likewise, the transmission medium may be twisted-wire pairs, coaxial cables, optical fibers, or any other suitable transmission medium known in the art. The exemplary embodiments are not limited to these aspects of any described implementations.
Exemplarische Ausführungsformen beschreiben Techniken für die Umwandlung sphärischer Bilder und Videos in 2D-Darstellungen und die Nutzung spezieller Eigenschaften der 2D-Darstellungen während der Codierung/Decodierung der Bilder und/oder Frames eines Videos.Exemplary embodiments describe techniques for converting spherical images and video into 2D representations, and utilizing special features of the 2D representations during encoding / decoding of the images and / or frames of a video.
In einem allgemeinen Aspekt kann ein Verfahren für das Codieren eines sphärischen Videos die Abbildung eines Frames des sphärischen Videos auf einer zweidimensionalen Darstellung auf Basis einer Projektion beinhalten. Des Weiteren kann das Verfahren in einem Prädiktionsprozess die Ermittlung beinhalten, ob sich mindestens ein Block, der einem Prädiktionsschema zugeordnet ist, an einer Grenze der zweidimensionalen Darstellung befindet, und, nach dem Ermitteln, dass sich der mindestens eine Block, der dem Prädiktionsschema zugeordnet ist, an der Grenze befindet, das Auswählen eines benachbarten Endblocks als ein Block einschließlich mindestens eines Pixels für die Verwendung während des Prädiktionsprozesses, wobei der benachbarte Endblock zwei oder mehr Grenzen der zweidimensionalen Darstellung zugeordnet ist.In a general aspect, a method of encoding a spherical video may include imaging a frame of the spherical video on a two-dimensional representation based on a projection. Further, in a prediction process, the method may include determining whether at least one block associated with a prediction scheme is at a boundary of the two-dimensional representation and, upon determining that the at least one block is associated with the prediction scheme , located at the boundary, selecting an adjacent end block as a block including at least one pixel for use during the prediction process, wherein the adjacent end block is associated with two or more boundaries of the two-dimensional representation.
Implementierungen können eines oder mehrere der folgenden Merkmale beinhalten. Der Prädiktionsprozess kann zum Beispiel ein Intraprädiktionsprozess sein, der mindestens eine Block, der dem Prädiktionsschema zugeordnet ist, kann ein zu codierender Block sein, und der benachbarte Endblock kann als ein linker rekonstruierter Block oder ein oberer rekonstruierter Block des zu codierenden Blocks ausgewählt werden. Der Prädiktionsprozess kann ein Interprädiktionsprozess sein und der mindestens eine Block, der dem Prädiktionsschema zugeordnet ist, kann ein Block sein, der in einer Vielzahl von Blöcken in einem Referenzframe enthalten ist, in dem nach einem übereinstimmenden Block gesucht werden soll. Der Prädiktionsprozess kann ein Interprädiktionsprozess sein und der mindestens eine Block, der dem Prädiktionsschema zugeordnet ist, kann als Prädiktionsblock aus einer Vielzahl von Blöcken in einem zu durchsuchenden Referenzframe ausgewählt werden, wobei die Vielzahl von Blöcken eine Grenze des Referenzframes queren.Implementations may include one or more of the following features. The prediction process may be, for example, an intra prediction process, the at least one block associated with the prediction scheme may be a block to be coded, and the neighboring end block may be selected as a left reconstructed block or an upper reconstructed block of the block to be coded. The prediction process may be an inter prediction process, and the at least one block associated with the prediction scheme may be a block contained in a plurality of blocks in a reference frame in which to search for a matching block. The prediction process may be an inter prediction process, and the at least one block associated with the prediction scheme may be selected as a prediction block from a plurality of blocks in a reference frame to be searched, wherein the plurality of blocks traverse a boundary of the reference frame.
Die Abbildung des Frames des sphärischen Videos auf der zweidimensionalen Darstellung kann zum Beispiel die Verwendung einer Gleichung beinhalten, die auf einer äquirektangulären Projektion basiert. Die Abbildung des Frames des sphärischen Videos auf der zweidimensionalen Darstellung kann die Verwendung einer Gleichung beinhalten, die auf einer semi-äquirektangulären Projektion basiert. Das Verfahren kann zum Beispiel des Weiteren nach dem Ermitteln, dass der zu codierende Block sich von der Grenze entfernt befindet, in einem Intraprädiktionsprozess das Auswählen eines benachbarten Blocks als Vorlage beinhalten, wobei der benachbarte Endblock mindestens ein linker rekonstruierter Block oder ein oberer rekonstruierter Block des zu codierenden Blocks ist. Die Auswahl des benachbarten Endblocks beinhaltet das Auswählen eines rekonstruierten Blocks aus mindestens einem entgegengesetzten Ende einer gleichen Reihe wie dem Block, der dem Prädiktionsschema zugeordnet ist, oder einem entgegengesetzten Ende derselben Spalte wie der zu codierende Block. Die Auswahl des benachbarten Endblocks beinhaltet das Auswählen eines rekonstruierten Blocks aus einer Lookup-Tabelle.For example, the mapping of the spherical video frame to the two-dimensional representation may involve the use of an equation based on an angular-angular projection. The mapping of the spherical video frame to the two-dimensional representation may involve the use of an equation based on a semi-angular-angular projection. For example, after determining that the block to be coded is away from the boundary, the method may further include selecting an adjacent block as a template in an intra prediction process, wherein the adjacent end block is at least one left reconstructed block or upper reconstructed block of the is to be coded blocks. The selection of the adjacent end block involves selecting a reconstructed block from at least one opposite end of a same row as the block associated with the prediction scheme or an opposite end of the same column as the block to be coded. The selection of the adjacent end block involves selecting a reconstructed block from a lookup table.
Das Verfahren kann zum Beispiel des Weiteren das Erzeugen mindestens eines Rests auf Basis nicht codierter Pixel eines zu codierenden Blocks beinhalten, das Codieren des mindestens einen Rests durch Anwendung einer Transformation auf einen restlichen Block einschließlich des mindestens einen Rests, das Quantisieren von Transformationskoeffizienten, die dem codierten mindestens einen Rest zugeordnet sind, das Entropiecodieren der quantisierten Transformationskoeffizienten als ein komprimierter Videobit-Datenstrom und das Übertragen des komprimierten Videobit-Datenstroms einschließlich eines Headers, der einen Intraframe-Codiermodus angibt, wobei der Intraframe-Codiermodus eine Technik angibt, die während der Abbildung des Frames des sphärischen Videos auf der zweidimensionalen Darstellung verwendet wird.For example, the method may further include generating at least one reminder based on unencoded pixels of a block to be coded, encoding the at least one remainder by applying a transform to one remaining block including the at least one remainder, quantizing transform coefficients associated with the coded at least one remainder, entropy coding the quantized transform coefficients as a compressed video bit stream, and transmitting the compressed video bit data stream including a header encoding an intraframe coding mode where the intraframe coding mode indicates a technique used during the imaging of the spherical video frame on the two-dimensional representation.
In einem allgemeinen Aspekt beinhaltet ein Verfahren für die Decodierung eines sphärischen Videos das Empfangen eines codierten Bit-Datenstroms einschließlich eines Headers, der einen Intraframe-Codiermodus angibt, wobei der Intraframe-Codiermodus eine Technik angibt, die während einer Umwandlung eines Frames eines sphärischen Videos in eine zweidimensionale Darstellung verwendet wird. Des Weiteren kann das Verfahren in einem Prädiktionsprozess die Ermittlung beinhalten, ob sich mindestens ein Block, der einem Prädiktionsschema zugeordnet ist, an einer Grenze der zweidimensionalen Darstellung befindet, nach dem Ermitteln, dass sich der mindestens eine Block, der dem Prädiktionsschema zugeordnet ist, an der Grenze befindet, das Auswählen eines benachbarten Endblocks als ein Block einschließlich mindestens eines Pixels für die Verwendung während des Prädiktionsprozesses, wobei der benachbarte Endblock zwei oder mehr Grenzen der zweidimensionalen Darstellung zugeordnet ist. Das Verfahren beinhaltet des Weiteren das Umwandeln der zweidimensionalen Darstellung in einen Frame des sphärischen Videos auf Basis einer zylindrischen Projektion.In a general aspect, a method for decoding a spherical video includes receiving a coded bitstream including a header indicating an intraframe coding mode, the intraframe coding mode indicating a technique that is used during a conversion of a spherical video frame into a two-dimensional representation is used. Furthermore, in a prediction process, the method may include determining whether at least one block associated with a prediction scheme is at a boundary of the two-dimensional representation, after determining that the at least one block associated with the prediction scheme is on the boundary, selecting an adjacent end block as a block including at least one pixel for use during the prediction process, wherein the adjacent end block is associated with two or more boundaries of the two-dimensional representation. The method further includes converting the two-dimensional representation into a spherical video frame based on a cylindrical projection.
Implementierungen können eines oder mehrere der folgenden Merkmale beinhalten. Das Umwandeln der zweidimensionalen Darstellung kann zum Beispiel die Abbildung der zweidimensionalen Darstellung auf einem sphärischen Bild mithilfe einer Gleichung beinhalten, die auf der inversen Transformation einer Projektion basiert. Der Prädiktionsprozess kann ein Intraprädiktionsprozess sein, der mindestens eine Block, der dem Prädiktionsschema zugeordnet ist, kann ein zu codierender Block sein, und der benachbarte Endblock kann als ein linker rekonstruierter Block oder ein oberer rekonstruierter Block ausgewählt werden. Der Prädiktionsprozess kann zum Beispiel ein Interprädiktionsprozess sein und der mindestens eine Block, der dem Prädiktionsschema zugeordnet ist, kann ein Block sein, der in einer Vielzahl von Blöcken in einem Referenzframe beinhaltet ist, in dem nach einem übereinstimmenden Block gesucht werden soll. Der Prädiktionsprozess kann ein Interprädiktionsprozess sein und der mindestens eine Block, der dem Prädiktionsschema zugeordnet ist, kann als Prädiktionsblock aus einer Vielzahl von Blöcken in einem zu durchsuchenden Referenzframe ausgewählt werden, wobei die Vielzahl von Blöcken eine Grenze des Referenzframes queren.Implementations may include one or more of the following features. For example, converting the two-dimensional representation may involve mapping the two-dimensional representation on a spherical image using an equation based on the inverse transformation of a projection. The prediction process may be an intra prediction process, the at least one block associated with the prediction scheme may be a block to be coded, and the neighboring end block may be selected as a left reconstructed block or an upper reconstructed block. The prediction process may be, for example, an inter prediction process, and the at least one block associated with the prediction scheme may be a block included in a plurality of blocks in a reference frame in which to search for a matching block. The prediction process may be an inter prediction process, and the at least one block associated with the prediction scheme may be selected as a prediction block from a plurality of blocks in a reference frame to be searched, wherein the plurality of blocks traverse a boundary of the reference frame.
In einen allgemeinen Aspekt kann auf einem nicht flüchtigen, computerlesbaren Speichermedium computerlesbarer Programmcode gespeichert sein, der, wenn er auf einem Computersystem ausgeführt wird, das Computersystem veranlasst, Schritte einschließlich der Abbildung eines Frames des sphärischen Videos auf einer zweidimensionalen Darstellung auf Basis einer Projektion durchzuführen. Des Weiteren können die Schritte in einem Prädiktionsprozess die Ermittlung beinhalten, ob sich mindestens ein Block, der einem Prädiktionsschema zugeordnet ist, an einer Grenze der zweidimensionalen Darstellung befindet, und, nach dem Ermitteln, dass sich der mindestens eine Block, der dem Prädiktionsschema zugeordnet ist, an der Grenze befindet, das Auswählen eines benachbarten Endblocks als ein Block einschließlich mindestens eines Pixels für die Verwendung während des Prädiktionsprozesses, wobei der benachbarte Endblock zwei oder mehr Grenzen der zweidimensionalen Darstellung zugeordnet ist.In a general aspect, computer readable program code may be stored on a non-transitory computer-readable storage medium which, when executed on a computer system, causes the computer system to perform steps including mapping a spherical video frame onto a two-dimensional representation based on a projection. Further, the steps in a prediction process may include determining whether at least one block associated with a prediction scheme is at a boundary of the two-dimensional representation and, upon determining that the at least one block is associated with the prediction scheme , located at the boundary, selecting an adjacent end block as a block including at least one pixel for use during the prediction process, wherein the adjacent end block is associated with two or more boundaries of the two-dimensional representation.
Implementierungen können eines oder mehrere der folgenden Merkmale beinhalten. Der Prädiktionsprozess kann zum Beispiel ein Intraprädiktionsprozess sein, der mindestens eine Block, der dem Prädiktionsschema zugeordnet ist, kann ein zu codierender Block sein, und der benachbarte Endblock kann als ein linker rekonstruierter Block oder ein oberer rekonstruierter Block des zu codierenden Blocks ausgewählt werden. Der Prädiktionsprozess kann zum Beispiel ein Interprädiktionsprozess sein und der mindestens eine Block, der dem Prädiktionsschema zugeordnet ist, kann ein Block sein, der in einer Vielzahl von Blöcken in einem Referenzframe beinhaltet ist, in dem nach einem übereinstimmenden Block gesucht werden soll. Der Prädiktionsprozess kann ein Interprädiktionsprozess sein und der mindestens eine Block, der dem Prädiktionsschema zugeordnet ist, kann als Prädiktionsblock aus einer Vielzahl von Blöcken in einem zu durchsuchenden Referenzframe ausgewählt werden, wobei die Vielzahl von Blöcken eine Grenze des Referenzframes queren. Die Auswahl des benachbarten Endblocks kann das Auswählen eines rekonstruierten Blocks aus mindestens einem entgegengesetzten Ende einer gleichen Reihe wie dem Block, der dem Prädiktionsschema zugeordnet ist, oder einem entgegengesetzten Ende derselben Spalte wie der zu codierende Block, beinhalten.Implementations may include one or more of the following features. The prediction process may be, for example, an intra prediction process, the at least one block associated with the prediction scheme may be a block to be coded, and the neighboring end block may be selected as a left reconstructed block or an upper reconstructed block of the block to be coded. The prediction process may be, for example, an inter prediction process, and the at least one block associated with the prediction scheme may be a block included in a plurality of blocks in a reference frame in which to search for a matching block. The prediction process may be an inter prediction process, and the at least one block associated with the prediction scheme may be selected as a prediction block from a plurality of blocks in a reference frame to be searched, wherein the plurality of blocks traverse a boundary of the reference frame. The selection of the adjacent end block may include selecting a reconstructed block from at least one opposite end of a same row as the block associated with the prediction scheme or an opposite end of the same column as the block to be coded.
Exemplarische Ausführungsformen beschreiben Systeme und Verfahren zur Optimierung des Streamens sphärischer Videos (und/oder dreidimensionalen Videos) auf Basis sichtbarer (durch einen Betrachter eines Videos) Teile des sphärischen Videos.Exemplary embodiments describe systems and methods for optimizing the streaming of spherical videos (and / or three-dimensional videos) based on visible (through a Viewer of a video) parts of the spherical video.
In einem allgemeinen Aspekt beinhaltet ein Verfahren die Ermittlung einer Kachelposition in einem Frame eines sphärischen Videos auf Basis einer Ansichtsperspektive, das Auswählen eines ersten Teils des Frames des sphärischen Videos als erste zweidimensionale Kachel auf Basis der Kachelposition, das Auswählen einer Vielzahl von zweiten zweidimensionalen Kacheln aus einem zweiten Teil des Frames des sphärischen Videos, wobei der zweite Teil des Frames den ersten Teil des Frames umgibt und sich vom ersten Teil des Frames weg erstreckt, das Codieren der ersten zweidimensionalen Kachel mithilfe einer ersten Qualität, das Codieren der Vielzahl zweiter zweidimensionaler Kacheln mithilfe mindestens einer zweiten Qualität und das Übertragen eines Pakets als ein streamendes sphärisches Video, wobei das Paket die codierte erste zweidimensionale Kachel und die Vielzahl codierter zweiten zweidimensionalen Kacheln beinhaltet.In a general aspect, a method includes determining a tile location in a spherical video frame based on a view perspective, selecting a first portion of the spherical video frame as the first two-dimensional tile based on the tile location, selecting a plurality of second two-dimensional tiles a second portion of the spherical video frame, the second portion of the frame surrounding the first portion of the frame and extending away from the first portion of the frame, encoding the first two-dimensional tile using a first quality, encoding the plurality of second two-dimensional tiles of at least a second quality and transmitting a packet as a streaming spherical video, the packet including the encoded first two-dimensional tile and the plurality of encoded second two-dimensional tiles.
Implementierungen können eines oder mehrere der folgenden Merkmale beinhalten. Das Verfahren kann zum Beispiel des Weiteren die Abbildung des Frames des sphärischen Videos auf einer zweidimensionalen Darstellung auf Basis einer Projektion auf einer Fläche einer zweidimensionalen Form beinhalten. Die erste Qualität ist eine höhere Qualität im Vergleich zu der mindestens einen zweiten Qualität. Die Ansichtsperspektive basiert auf einem sichtbaren Teil des sphärischen Videos, wie von einem Betrachter während einer Wiedergabe des sphärischen Videos gesehen. Das Verfahren kann des Weiteren das Empfangen einer Angabe der Ansichtsperspektive von einem Gerät beinhalten, das eine Wiedergabe des sphärischen Videos ausführt. Das Paket beinhaltet des Weiteren einen Header und einen nachgeahmten Frame einschließlich Dummydaten an Datenorten des Frames, die nicht der codierten ersten zweidimensionalen Kachel und der Vielzahl codierter zweiten zweidimensionalen Kacheln zugeordnet sind. Die Vielzahl codierter zweidimensionaler Kacheln beinhaltet zwei oder mehr zweidimensionale Kacheln unterschiedlicher Größe und die zwei oder mehr zweidimensionalen Kacheln überlappen einander. Da sich die Vielzahl zweiter zweidimensionaler Kacheln vom ersten Teil des Frames weg erstreckt, beinhaltet die Vielzahl zweiter zweidimensionaler Kacheln eine dritte Kachel, die eine Dimension hat, die größer im Vergleich zu einer Dimension einer vierten Kachel ist, die sich näher bei der ersten Kachel befindet.Implementations may include one or more of the following features. For example, the method may further include imaging the frame of the spherical video on a two-dimensional representation based on a projection on a surface of a two-dimensional shape. The first quality is a higher quality compared to the at least one second quality. The view perspective is based on a visible portion of the spherical video as seen by a viewer during a spherical video display. The method may further include receiving an indication of the view perspective from a device that is performing a rendering of the spherical video. The packet further includes a header and a fake frame including dummy data at data locations of the frame that are not associated with the encoded first two-dimensional tile and the plurality of encoded second two-dimensional tiles. The plurality of coded two-dimensional tiles includes two or more two-dimensional tiles of different sizes and the two or more two-dimensional tiles overlap each other. As the plurality of second two-dimensional tiles extend away from the first portion of the frame, the plurality of second two-dimensional tiles includes a third tile that has a dimension that is larger compared to a dimension of a fourth tile closer to the first tile ,
Die Vielzahl zweiter zweidimensionaler Kacheln beinhaltet Kacheln von unterschiedlichen Dimensionen und eine größere der Kacheln unterschiedlicher Dimensionen ist mit einer geringeren Qualität codiert im Vergleich zu einer kleineren der Kacheln unterschiedlicher Dimensionen. Das Codieren der ersten zweidimensionalen Kachel und der Vielzahl zweiter zweidimensionaler Kacheln kann das getrennte Codieren jeder Kachel beinhalten, wobei das Codieren das Erzeugen mindestens eines Rests für die zweidimensionale Kachel durch Subtrahieren einer Vorlage von nicht codierten Pixeln eines Blocks der zu codierenden zweidimensionalen Kachel beinhalten kann, wobei das Codieren des mindestens einen Rests durch Anwendung einer Transformation auf einen Restblock einschließlich des mindestens einen Rests, das Quantisieren von Transformationskoeffizienten, die dem codierten mindestens einen Rest zugeordnet sind, und das Entropiecodieren der quantisierten Transformationskoeffizienten als mindestens ein komprimiertes Videobit beinhaltet, wobei mindestens eine der Optionen – das Erzeugen des mindestens einen Rests, das Codieren des mindestens einen Rests, das Quantisieren der Transformationskoeffizienten und/oder das Quantisieren der Transformationskoeffizienten – das Einstellen des mindestens einen Parameters auf Basis der ersten Qualität beinhaltet.The plurality of second two-dimensional tiles includes tiles of different dimensions, and a larger one of the tiles of different dimensions is encoded with a lower quality compared to a smaller one of the tiles of different dimensions. The encoding of the first two-dimensional tile and the plurality of second two-dimensional tiles may include separately encoding each tile, wherein the encoding may include generating at least one remainder for the two-dimensional tile by subtracting a template from unencoded pixels of a block of the two-dimensional tile to be coded, wherein encoding the at least one remainder by applying a transform to a remainder block including the at least one remainder, quantizing transform coefficients associated with the coded at least one remainder, and entropy coding the quantized transform coefficients as at least one compressed video bit, wherein at least one the options - generating the at least one remainder, encoding the at least one remainder, quantizing the transform coefficients, and / or quantizing the transform coefficients - the remainder contains at least one parameter based on the first quality.
In einem allgemeinen Aspekt beinhaltet ein Verfahren das Empfangen eines codierten Bitdatenstroms einschließlich einer Vielzahl codierter zweidimensionaler Kacheln, die aus einem Frame eines sphärischen Videos ausgewählt wurden, das Decodieren einer zweidimensionalen Darstellung auf Basis der Vielzahl codierter zweidimensionaler Kacheln, das Umwandeln der zweidimensionalen Darstellung in einen sphärisches Videoframe und das Wiedergeben des sphärischen Videos einschließlich des sphärischen Videoframes. Der sphärische Videoframe kann eine Kachel in höhere Qualität beinhalten, die einem Teil des sphärischen Videoframes in einer Ansichtsperspektive, wie von einem Betrachter gesehen, zugeordnet ist, im Vergleich zu einem Teil des sphärischen Videoframes in einer peripheren Ansicht oder außerhalb der Ansichtsperspektive während der Wiedergabe des sphärischen Videos.In a general aspect, a method includes receiving an encoded bitstream including a plurality of encoded two-dimensional tiles selected from a spherical video frame, decoding a two-dimensional representation based on the plurality of encoded two-dimensional tiles, converting the two-dimensional representation to a spherical one Video frame and playing the spherical video including the spherical video frame. The spherical video frame may include a higher quality tile that surrounds a portion of the spherical video frame in one View perspective as viewed from a viewer compared to a portion of the spherical video frame in a peripheral view or out of the view perspective during the playback of the spherical video.
Implementierungen können eines oder mehrere der folgenden Merkmale beinhalten. Das Verfahren kann zum Beispiel des Weiteren das Erzeugen der zweidimensionalen Darstellung auf Basis eines nachgeahmten Frames des sphärischen Videos einschließlich Dummydaten an Datenorten des Frames beinhalten, die nicht der Vielzahl codierter zweidimensionaler Kacheln zugeordnet sind. Das Umwandeln der zweidimensionalen Darstellung des sphärischen Videoframes beinhaltet die Abbildung der zweidimensionalen Darstellung des sphärischen Videoframes auf einem sphärischen Bild mithilfe einer Umkehr einer Technik, die zum Abbilden des sphärischen Videoframes auf der zweidimensionalen Darstellung des sphärischen Videoframes verwendet wurde. Das Verfahren kann des Weiteren zum Beispiel das Ermitteln beinhalten, dass sich die Ansichtsperspektive, wie von einem Betrachter gesehen, geändert hat, und nach dem Ermitteln, dass sich die Ansichtsperspektive geändert hat, das Auslösen einer Angabe der geänderten Ansichtsperspektive für ein Gerät, das eine Codierung des sphärischen Videos ausführt.Implementations may include one or more of the following features. For example, the method may further include generating the two-dimensional representation based on a fake frame of the spherical video including dummy data at data locations of the frame that are not associated with the plurality of encoded two-dimensional tiles. Converting the two-dimensional representation of the spherical video frame involves mapping the two-dimensional representation of the spherical video frame onto a spherical image by reversing a technique used to image the spherical video frame on the two-dimensional representation of the spherical video frame. The method may further include, for example, determining that the view perspective has changed as seen by a viewer, and after determining that the view perspective has changed, triggering an indication of the changed view perspective for a device having a Encoding the spherical video.
In einem allgemeinen Aspekt kann auf einem nicht flüchtigen, computerlesbaren Speichermedium computerlesbarer Programmcode gespeichert sein, der, wenn er auf einem Computersystem ausgeführt wird, das Computersystem veranlasst, Schritte einschließlich der Ermittlung einer Kachelposition in einem Frame eines sphärischen Videos auf Basis einer Ansichtsperspektive, das Auswählen eines ersten Teils des Frames des sphärischen Videos als erste zweidimensionale Kachel auf Basis der Kachelposition, das Auswählen einer Vielzahl von zweiten zweidimensionalen Kacheln aus einem zweiten Teil des Frames des sphärischen Videos, wobei der zweite Teil des Frames den ersten Teil des Frames umgibt und sich vom ersten Teil des Frames weg erstreckt, das Codieren der ersten zweidimensionalen Kachel mithilfe einer ersten Qualität, das Codieren der Vielzahl zweiter zweidimensionaler Kacheln mithilfe mindestens einer zweiten Qualität und das Übertragen eines Pakets als ein sphärisches Streaming-Video, wobei das Paket die codierte erste zweidimensionale Kachel und die Vielzahl codierter zweiten zweidimensionalen Kacheln beinhaltet.In a general aspect, computer readable program code may be stored on a non-transitory computer readable storage medium which, when executed on a computer system, causes the computer system to perform steps including determining a tile position in a spherical video frame based on a view perspective a first portion of the spherical video frame as the first two-dimensional tile based on the tiling position, selecting a plurality of second two-dimensional tiles from a second portion of the spherical video frame, the second portion of the frame surrounding and extending from the first portion of the frame first encoding the first two-dimensional tile using a first quality, encoding the plurality of second two-dimensional tiles using at least a second quality, and transmitting a packet as a spherical streaming video o, wherein the packet includes the coded first two-dimensional tile and the plurality of coded second two-dimensional tiles.
Implementierungen können eines oder mehrere der folgenden Merkmale beinhalten. Die erste Qualität ist zum Beispiel eine höhere Qualität im Vergleich zur mindestens einen zweiten Qualität. Die Ansichtsperspektive basiert auf einem sichtbaren Teil des sphärischen Videos, wie von einem Betrachter während einer Wiedergabe des sphärischen Videos gesehen. Die Schritte können des Weiteren das Empfangen einer Angabe der Ansichtsperspektive von einem Gerät beinhalten, das eine Wiedergabe des sphärischen Videos ausführt. Die Vielzahl codierter zweidimensionaler Kacheln beinhaltet zwei oder mehr zweidimensionale Kacheln unterschiedlicher Größe und die zwei oder mehr zweidimensionalen Kacheln überlappen einander. Da sich die Vielzahl zweiter zweidimensionaler Kacheln vom ersten Teil des Frames weg erstreckt, beinhaltet die Vielzahl zweiter zweidimensionaler Kacheln eine dritte Kachel, die eine Dimension hat, die größer im Vergleich zu einer Dimension einer vierten Kachel ist, die sich näher bei der ersten Kachel befindet.Implementations may include one or more of the following features. For example, the first quality is a higher quality compared to at least a second quality. The view perspective is based on a visible portion of the spherical video as seen by a viewer during a spherical video display. The steps may further include receiving an indication of the view perspective from a device that is performing a rendering of the spherical video. The plurality of coded two-dimensional tiles includes two or more two-dimensional tiles of different sizes and the two or more two-dimensional tiles overlap each other. As the plurality of second two-dimensional tiles extend away from the first portion of the frame, the plurality of second two-dimensional tiles includes a third tile that has a dimension that is larger compared to a dimension of a fourth tile closer to the first tile ,
Exemplarische Ausführungsformen beschreiben Systeme und Verfahren zur Optimierung des Streamens sphärischer Videos (und/oder dreidimensionalen Videos) auf Basis sichtbarer (durch einen Betrachter eines Videos) Teile des sphärischen Videos.Exemplary embodiments describe systems and methods for optimizing the streaming of spherical videos (and / or three-dimensional videos) based on visible (through a viewer of a video) portions of the spherical video.
In einem allgemeinen Aspekt beinhaltet ein Verfahren die Ermittlung einer Kachelposition in einem Frame eines sphärischen Videos auf Basis einer Ansichtsperspektive, das Auswählen eines Teils des Frames des sphärischen Videos als eine zweidimensionale Kachel auf Basis der Kachelposition, das Codieren der zweidimensionalen Kachel mit einer ersten Qualität, die Abbildung des Frames des sphärischen Videos auf einer zweidimensionalen Darstellung des sphärischen Videos auf Basis eines zweidimensionalen Projektionsalgorithmus und das Codieren der zweidimensionalen Darstellung des sphärischen Videos mit einer zweiten Qualität.In a general aspect, a method includes determining a tile location in a spherical video frame based on a view perspective, selecting a portion of the spherical video frame as a two-dimensional tile based on the tile location, encoding the two-dimensional tile with a first quality, the image of the spherical video frame on a two-dimensional representation of the spherical video based on a two-dimensional projection algorithm and the coding of the two-dimensional representation of the spherical video with a second quality.
Implementierungen können eines oder mehrere der folgenden Merkmale beinhalten. Das Verfahren kann das Weiteren das Übertragen der codierten zweidimensionalen Kachel und der codierten zweidimensionalen Darstellung als sphärisches Streaming-Video beinhalten. Die erste Qualität ist eine höhere Qualität im Vergleich zur zweiten Qualität. Die Ansichtsperspektive kann auf einem sichtbaren Teil des sphärischen Videos basieren, wie von einem Betrachter während einer Wiedergabe des sphärischen Videos gesehen. Das Verfahren kann des Weiteren das Empfangen einer Angabe der Ansichtsperspektive von einem Gerät beinhalten, das eine Wiedergabe des sphärischen Videos ausführt. Das Verfahren kann des Weiteren das Übertragen der codierten zweidimensionalen Kachel über einen ersten Zeitraum, während das sphärische Video übertragen wird, und das Übertragen der codierten zweidimensionalen Kachel und der codierten zweidimensionalen Darstellung über einen ersten Zeitraum, während das sphärische Video gestreamt wird, beinhalten.Implementations may include one or more of the following features. The method may further include transmitting the coded two-dimensional tile and the coded two-dimensional representation as spherical streaming video. The first quality is a higher quality compared to the second quality. The view perspective may be based on a visible portion of the spherical video as viewed by a viewer during a spherical video display. The method may further include receiving an indication of the view perspective from a device that is performing a rendering of the spherical video. The method may further include transmitting the coded two-dimensional tile over a first time period while the spherical video is being transmitted, and transmitting the coded two-dimensional tile and the coded two-dimensional representation over a first time period while the spherical video is being streamed.
Das Auswählen des Teils des Frames des sphärischen Videos als zweidimensionale Kachel und das Codieren der zweidimensionalen Kachel können zum Beispiel das Auswählen der zweidimensionalen Kachel aus einem Datenspeicher früher codierter Kacheln und das Lesen der zweidimensionalen Kachel aus dem Datenspeicher beinhalten. Das Auswählen des Teils des Frames des sphärischen Videos als zweidimensionale Kachel kann das Auswählen der zweidimensionalen Kachel aus dem Frame des sphärischen Videos als zu codierendes Frame auf Basis einer Position des sphärischen Videos beinhalten, wobei die Position auf dem sphärischen Video auf der Ansichtsperspektive basiert. Das Codieren der zweidimensionalen Kachel kann das Erzeugen mindestens eines Rests für die zweidimensionale Kachel durch Subtrahieren einer Vorlage von nicht codierten Pixeln eines Blocks der zu codierenden zweidimensionalen Kachel beinhalten, das Codieren des mindestens einen Rests durch Anwendung einer Transformation auf einen Restblock einschließlich des mindestens einen Rests, das Quantisieren von Transformationskoeffizienten, die mit dem codierten mindestens eines Rests verbunden sind, und das Entropiecodieren der quantisierten Transformationskoeffizienten als mindestens ein komprimiertes Videobit, wobei mindestens die Erzeugung des mindestens einen Rests, das Codieren des mindestens einen Rests, das Quantisieren der Transformationskoeffizienten und/oder das Quantisieren der Transformationskoeffizienten die Einstellung mindestens eines Parameters auf Basis der ersten Qualität beinhaltet.Selecting the portion of the spherical video frame as a two-dimensional tile and encoding the two-dimensional tile may include, for example, selecting the two-dimensional tile from a data store of earlier coded tiles and reading the two-dimensional tile from the data store. Selecting the part of the spherical video frame as a two-dimensional tile may include selecting the two-dimensional tile from the spherical video frame as a frame to be coded based on a position of the spherical video, the position on the spherical video being based on the view perspective. The coding of the two-dimensional tile may include generating at least one remainder for the two-dimensional tile by subtracting a template from unencoded pixels of a block of the two-dimensional tile to be coded, coding the at least one remainder by applying a transformation to a remainder block including the at least one remainder , quantizing transform coefficients associated with the encoded at least one residue, and entropy coding the quantized transform coefficients as at least one compressed video bit, wherein at least the generation of the at least one remainder, encoding the at least one remainder, quantizing the transform coefficients, and / or quantizing the transform coefficients includes adjusting at least one first quality based parameter ,
Das Codieren der zweidimensionalen Darstellung des sphärischen Videos kann das Erzeugen mindestens eines Rests für die zweidimensionale Darstellung des sphärischen Videos durch Subtrahieren einer Vorlage von nicht codierten Pixeln eines Blocks der zu codierenden zweidimensionalen Darstellung des sphärischen Videos beinhalten, das Codieren des mindestens einen Rests durch Anwendung einer Transformation auf einen Restblock einschließlich des mindestens einen Rests, das Quantisieren von Transformationskoeffizienten, die dem codierten mindestens einen Rest zugeordnet sind, und das Entropiecodieren der quantisierten Transformationskoeffizienten als mindestens ein komprimiertes Videobit, wobei mindestens die Erzeugung des mindestens einen Rests, das Codieren des mindestens einen Rests, das Quantisieren der Transformationskoeffizienten und/oder das Quantisieren der Transformationskoeffizienten die Einstellung mindestens eines Parameters auf Basis der ersten Qualität beinhaltet.The coding of the two-dimensional representation of the spherical video may include generating at least one remainder for the two-dimensional representation of the spherical video by subtracting a template from unencoded pixels of a block of the two-dimensional representation of the spherical video to be coded, coding the at least one remainder by using a Transforming to a residual block including the at least one remainder, quantizing transform coefficients associated with the coded at least one remainder, and entropy coding the quantized transform coefficients as at least one compressed video bit, wherein at least generating the at least one remainder encoding the at least one remainder Rests, the quantization of the transformation coefficients and / or the quantization of the transformation coefficients includes the setting of at least one parameter based on the first quality.
In einem allgemeinen Aspekt beinhaltet ein Verfahren das Empfangen eines codierten Bitdatenstroms einschließlich einer codierten zweidimensionalen Darstellung eines sphärischen Videoframes und einer codierten zweidimensionalen Kachel, die aus dem sphärischen Videoframe ausgewählt wurde, das Decodieren der zweidimensionalen Kachel, das Decodieren der zweidimensionalen Darstellung des sphärischen Videoframes, das Umwandeln der zweidimensionalen Darstellung des sphärischen Videoframes und das Ersetzen entsprechender Blöcke des sphärischen Videoframes durch die decodierte zweidimensionale Kachel.In a general aspect, a method includes receiving an encoded bitstream including a coded two-dimensional representation of a spherical video frame and a coded two-dimensional tile selected from the spherical video frame, decoding the two-dimensional tile, decoding the two-dimensional representation of the spherical video frame, the Converting the two-dimensional representation of the spherical video frame and replacing corresponding blocks of the spherical video frame with the decoded two-dimensional tile.
Implementierungen können eines oder mehrere der folgenden Merkmale beinhalten. Das Empfangen des codierten Bitdatenstroms beinhaltet das Empfangen eines Headers, der eine Technik angibt, die während einer Umwandlung des Frames des sphärischen Videos in die zweidimensionale Darstellung des sphärischen Videoframes verwendet wurde. Das Ersetzen der entsprechenden Blöcke des sphärischen Videoframes durch die decodierte zweidimensionale Kachel beinhaltet einen Ersetzung Pixel für Pixel oder Block für Block von Pixeln oder Blöcken im decodierten und umgewandelten sphärischen Videoframe durch Pixel oder Blöcke der decodierten zweidimensionalen Kachel.Implementations may include one or more of the following features. Receiving the coded bit stream includes receiving a header indicating a technique used during a conversion of the spherical video frame to the two-dimensional representation of the spherical video frame. The replacement of the corresponding blocks of the spherical video frame by the decoded two-dimensional tile involves a pixel by pixel replacement or block by block of blocks in the decoded and converted spherical video frame by pixels or blocks of the decoded two-dimensional tile.
Das Umwandeln der zweidimensionalen Darstellung des sphärischen Videoframes beinhaltet zum Beispiel die Abbildung der zweidimensionalen Darstellung des sphärischen Videoframes auf einem sphärischen Bild mithilfe einer Umkehr einer Technik, die zum Abbilden des sphärischen Videoframes auf der zweidimensionalen Darstellung des sphärischen Videoframes verwendet wurde. Das Verfahren kann des Weiteren zum Beispiel das Erzeugen eines sphärischen Videodatenstroms auf Basis mindestens eines sphärischen Videoframes einschließlich der ersetzten zweidimensionalen Kachel während der Wiedergabe des sphärischen Videodatenstroms beinhalten, wobei ein sichtbarer Teil des sphärischen Videodatenstroms von höherer Qualität ist als ein nicht sichtbarer Teil des sphärischen Videodatenstroms.For example, converting the two-dimensional representation of the spherical video frame involves mapping the two-dimensional representation of the spherical video frame onto a spherical image by reversing a technique used to image the spherical video frame on the two-dimensional representation of the spherical video frame. The method may further include, for example, generating a spherical video data stream based on at least one spherical video frame including the replaced two-dimensional tile during reproduction of the spherical video data stream, wherein a visible portion of the spherical video data stream is of higher quality than an invisible portion of the spherical video data stream ,
In einem allgemeinen Aspekt kann auf einem nicht flüchtigen, computerlesbaren Speichermedium computerlesbarer Programmcode gespeichert sein, der, wenn er auf einem Computersystem ausgeführt wird, das Computersystem veranlasst, Schritte einschließlich der Ermittlung einer Kachelposition in einem Frame eines sphärischen Videos auf Basis einer Ansichtsperspektive, das Auswählen eines Teils des Frames des sphärischen Videos als eine zweidimensionale Kachel auf Basis der Kachelposition, das Codieren der zweidimensionalen Kachel mit einer ersten Qualität, die Abbildung des Frames des sphärischen Videos auf einer zweidimensionalen Darstellung des sphärischen Videos auf Basis eines zweidimensionalen Projektionsalgorithmus und das Codieren der zweidimensionalen Darstellung des sphärischen Videos mit einer zweiten Qualität, durchzuführen.In a general aspect, computer readable program code may be stored on a non-transitory computer readable storage medium which, when executed on a computer system, causes the computer system to perform steps including determining a tile position in a spherical video frame based on a view perspective a portion of the spherical video frame as a two-dimensional tile based on the tiling position, encoding the two-dimensional tile with a first quality, imaging the spherical video frame on a two-dimensional representation of the spherical video based on a two-dimensional projection algorithm, and encoding the two-dimensional Representation of the spherical video with a second quality, perform.
Implementierungen können eines oder mehrere der folgenden Merkmale beinhalten. Die Schritte können des Weiteren das Empfangen einer Angabe der Ansichtsperspektive von einem Gerät beinhalten, das eine Wiedergabe des sphärischen Videos ausführt, wobei die Ansichtsperspektive auf einem sichtbaren Teil des sphärischen Videos basiert, wie von einem Betrachter während der Wiedergabe des sphärischen Videos gesehen. Die erste Qualität ist eine höhere Qualität im Vergleich zur zweiten Qualität. Das Auswählen des Teils des Frames des sphärischen Videos als zweidimensionale Kachel und das Codieren der zweidimensionalen Kachel kann das Auswählen der zweidimensionalen Kachel aus einem Datenspeicher früher codierter Kacheln und das Lesen der zweidimensionalen Kachel aus der zweidimensionalen Kachel aus dem Datenspeicher beinhalten. Das Auswählen des Teils des Frames des sphärischen Videos als zweidimensionale Kachel kann das Auswählen der zweidimensionalen Kachel aus dem Frame des sphärischen Videos als zu codierendes Frame auf Basis einer Position des sphärischen Videos beinhalten, wobei die Position auf dem sphärischen Video auf der Ansichtsperspektive basiert.Implementations may include one or more of the following features. The steps may further include receiving an indication of the view perspective from a device that is performing a rendering of the spherical video, the view perspective being based on a visible portion of the spherical video as viewed by a viewer during the rendering of the spherical video. The first quality is a higher quality compared to the second quality. Selecting the portion of the spherical video frame as a two-dimensional tile and encoding the two-dimensional tile may include selecting the two-dimensional tile from a data store of previously coded tiles and reading the two-dimensional tile from the two-dimensional tile from the data store. Selecting the part of the spherical video frame as a two-dimensional tile may include selecting the two-dimensional tile from the spherical video frame as a frame to be coded based on a position of the spherical video, the position on the spherical video being based on the view perspective.
Exemplarische Ausführungsformen beschreiben Techniken für die Umwandlung sphärischer Bilder und Videos in 2D-Darstellungen und die Nutzung spezieller Eigenschaften der 2D-Darstellungen während der Codierung/Decodierung der Bilder und/oder Frames eines Videos. Exemplary embodiments describe techniques for converting spherical images and video into 2D representations, and utilizing special features of the 2D representations during encoding / decoding of the images and / or frames of a video.
In einem allgemeinen Aspekt kann ein Verfahren für das Codieren eines sphärischen Videos die Abbildung eines Frames des sphärischen Videos auf einer ersten zweidimensionalen Darstellung auf Basis einer Projektion sphärisch zu quadratisch beinhalten, wobei die erste zweidimensionale Darstellung ein Quadrat ist, die Abbildung der ersten zweidimensionalen Darstellung auf einer zweiten zweidimensionalen Darstellung, die ein Rechteck ist, und das Codieren der zweiten zweidimensionalen Darstellung als codierter Bitdatenstrom.In a general aspect, a method of encoding a spherical video may include imaging a frame of the spherical video on a first two-dimensional representation based on a spherical to square projection, wherein the first two-dimensional representation is a square, the image of the first two-dimensional representation a second two-dimensional representation that is a rectangle, and encoding the second two-dimensional representation as a coded bit stream.
Implementierungen können eines oder mehrere der folgenden Merkmale beinhalten. Die Projektion sphärisch zu quadratisch kann zum Beispiel eine Quincunx-Projektion nach Pierce sein. Während eines Intraprädiktionsprozesses kann das Verfahren das Ermitteln beinhalten, ob sich ein zu codierender Block an einer Grenze der zweiten zweidimensionalen Darstellung befindet, und nach dem Ermitteln, dass sich der zu codierende Block an der Grenze befindet, einen benachbarten Endblock als eine Vorlage auswählen, wobei der benachbarte Endblock ein anderer als ein linker rekonstruierter Block oder ein oberer rekonstruierter Block des zu codierenden Blocks ist. Das Verfahren kann des Weiteren das Ermitteln beinhalten, ob sich ein zu deblockierender Block an einer Grenze der zweidimensionalen Darstellung befindet, und nach dem Ermitteln, dass sich der zu deblockierende Block an der Grenze befindet, einen benachbarten Endblock als einen Vergleichsblock auswählen, wobei der benachbarte Endblock ein anderer als ein linker rekonstruierter Block oder ein oberer rekonstruierter Block des zu deblockierenden Blocks ist.Implementations may include one or more of the following features. The spherical to square projection may be, for example, a Quincunx projection to Pierce. During an intra-prediction process, the method may include determining if a block to be encoded is at a boundary of the second two-dimensional representation and, upon determining that the block to be encoded is at the boundary, selecting an adjacent end block as a template the adjacent end block is a block other than a left reconstructed block or an upper reconstructed block of the block to be coded. The method may further include determining if a block to be deblocked is at a boundary of the two-dimensional representation and, upon determining that the block to be deblocked is at the boundary, selecting an adjacent end block as a comparison block, the adjacent one Endblock is a block other than a left reconstructed block or an upper reconstructed block of the block to be deblocked.
Die zweite zweidimensionale Darstellung wird zum Beispiel von zwei Quadraten mit gleichen Längenseiten gebildet, und den zwei Quadraten, die aus der ersten zweidimensionalen Darstellung erzeugt werden. Die Abbildung der ersten zweidimensionalen Darstellung auf der zweiten zweidimensionalen Darstellung kann die Ermittlung eines ersten Quadrats mit Ecken beinhalten, die jede Seite der ersten zweidimensionalen Darstellung abstandsgleich von den Ecken der ersten zweidimensionalen Darstellung schneiden, die Ermittlung von vier Dreiecken, von denen eine Seite eine andere Seite des Innenkreises des Frames des sphärischen Videos berührt, das Erzeugen eines zweiten Quadrats auf Basis der vier Dreiecke und das Erzeugen der zweiten zweidimensionalen Darstellung auf Basis des ersten Quadrats und des zweiten Quadrats. Das Verfahren kann des Weiteren das Erzeugen einer Lookup-Tabelle beinhalten, die eine Position von mindestens einem entsprechenden benachbarten Endblock angibt.The second two-dimensional representation is formed, for example, by two squares with equal length sides, and the two squares created from the first two-dimensional representation. The mapping of the first two-dimensional representation to the second two-dimensional representation may include determining a first square with corners that intersect each side of the first two-dimensional representation equidistant from the corners of the first two-dimensional representation, identifying four triangles, one side another Contacting the side of the inner circle of the frame of the spherical video, creating a second square based on the four triangles and generating the second two-dimensional representation based on the first square and the second square. The method may further include generating a lookup table indicating a position of at least one corresponding adjacent end block.
Das Codieren der zweiten zweidimensionalen Darstellung kann zum Beispiel das Erzeugen mindestens eines Rests durch Subtrahieren einer Vorlage von nicht codierten Pixeln des zu codierenden Blocks beinhalten, das Codieren des mindestens einen Rests durch Anwenden einer Transformation auf den Restblock einschließlich des mindestens einen Rests, das Quantisieren von Transformationskoeffizienten, die dem mindestens einen Rest zugeordnet sind, das Entropiecodieren der quantisierten Transformationskoeffizienten als komprimierten Videobit-Datenstrom und das Übertragen des komprimierten Videobit-Datenstroms einschließlich eines Headers, der einen Intraframe-Codiermodus angibt, wobei der Intraframe-Codiermodus eine Technik angibt, die während der Abbildung des Frames des sphärischen Videos auf der zweidimensionalen Darstellung verwendet wird.The encoding of the second two-dimensional representation may include, for example, generating at least one remainder by subtracting a template from unencoded pixels of the block to be coded, coding the at least one remainder by applying a transform to the remainder block including the at least one remainder, quantizing Transform coefficients associated with the at least one remainder, entropy coding the quantized transform coefficients as compressed video bitstream data, and transmitting the compressed video bitstream data including a header indicating an intraframe coding mode, the intraframe coding mode indicating a technique during the image of the frame of the spherical video is used on the two-dimensional representation.
In einem allgemeinen Aspekt kann ein Verfahren für das Decodieren eines sphärischen Videos das Empfangen eines codierten Bitdatenstroms einschließlich eines Headers beinhalten, der eine Projektionstechnik angibt, die während der Umwandlung eines Frames eines sphärischen Videos in eine erste zweidimensionale Darstellung verwendet wird, des Decodieren der ersten zweidimensionalen Darstellung, die Abbildung der ersten zweidimensionalen Darstellung auf einer zweiten zweidimensionalen Darstellung, wobei die erste zweidimensionale Darstellung ein Rechteck und die zweite zweidimensionale Darstellung ein Quadrat ist, und die Abbildung der zweiten zweidimensionalen Darstellung auf einem Frame des sphärischen Videos auf Basis einer Projektion sphärisch zu quadratisch.In a general aspect, a method for decoding a spherical video may include receiving a coded bitstream including a header indicating a projection technique used during the conversion of a spherical video frame to a first two-dimensional representation, decoding the first two-dimensional video Representation, the mapping of the first two-dimensional representation on a second two-dimensional representation, wherein the first two-dimensional representation is a rectangle and the second two-dimensional representation is a square, and the mapping of the second two-dimensional representation on a frame of the spherical video on the basis of a projection from spherical to square ,
Implementierungen können eines oder mehrere der folgenden Merkmale beinhalten. Die Projektion sphärisch zu quadratisch ist zum Beispiel eine Quincunx-Projektion nach Pierce. Während eines Intraprädiktionsprozesses kann das Verfahren des Weiteren die Ermittlung beinhalten, ob sich ein zu decodierender Block an einer Grenze der ersten zweidimensionalen Darstellung befindet, und nach dem Ermitteln, dass sich der zu decodierende Block an der Grenze befindet, einen benachbarten Endblock als eine Vorlage auswählen, wobei der benachbarte Endblock ein anderer als ein linker rekonstruierter Block oder ein oberer rekonstruierter Block des zu codierenden Blocks ist.Implementations may include one or more of the following features. The spherical to square projection is, for example, a Quincunx projection to Pierce. During an intra-prediction process, the method may further include determining if a block to be decoded is at a boundary of the first two-dimensional representation and selecting an adjacent end block as a template after determining that the block to be decoded is at the boundary wherein the adjacent end block is a block other than a left reconstructed block or an upper reconstructed block of the block to be coded.
Das Verfahren kann des Weiteren zum Beispiel das Ermitteln beinhalten, ob sich ein zu deblockierender Block an einer Grenze der zweidimensionalen Darstellung befindet, und nach dem Ermitteln, dass sich der zu deblockierende Block an der Grenze befindet, einen benachbarten Endblock als einen Vergleichsblock auswählen, wobei der benachbarte Endblock ein anderer als ein linker rekonstruierter Block oder ein oberer rekonstruierter Block des zu deblockierenden Blocks ist. Die erste zweidimensionale Darstellung wird durch zwei Quadrate mit gleichen Längsseiten gebildet. Die Abbildung der ersten zweidimensionalen Darstellung auf der zweiten zweidimensionalen Darstellung kann das Erzeugen eines ersten Quadrats und eines zweiten Quadrats auf Basis der ersten zweidimensionalen Darstellung beinhalten, die Ermittlung von vier Dreiecken aus dem zweiten Quadrat, wobei jedes der Dreiecke eine Seite des zweiten Quadrats hat, und die Neupositionierung von drei der vier Dreiecke, um ein drittes Quadrat als zweite zweidimensionale Darstellung zu bilden.The method may further include, for example, determining whether a block to be deblocked is at a boundary of the two-dimensional representation, and after determining that the block to be deblocked is at the boundary, selecting an adjacent end block as a comparison block the adjacent end block is a block other than a left reconstructed block or an upper reconstructed block of the block to be deblocked. The first two-dimensional representation is formed by two squares with equal longitudinal sides. The mapping of the first two-dimensional representation to the second two-dimensional representation may include generating a first square and a second square based on the first two-dimensional representation, determining four triangles from the second square, each of the triangles having a side of the second square, and repositioning three of the four triangles to form a third square as a second two-dimensional representation.
Das Verfahren kann des Weiteren das Erzeugen einer Lookup-Tabelle beinhalten, die eine Position von mindestens einem entsprechenden benachbarten Endblock angibt. Das Decodieren der ersten zweidimensionalen Darstellung kann das Entropie decodieren des codierten Bitdatenstroms beinhalten, um quantisierte codierte Transformationskoeffizienten zu erzeugen, das Dequantisieren der quantisierten codierten Transformationskoeffizienten, um codierte Transformationskoeffizienten zu erzeugen, das Anwenden einer Transformation auf die codierten Transformationskoeffizienten, um mindestens einen rekonstruierten Prädiktionsrest zu erzeugen, und das Hinzufügen des mindestens einen rekonstruierten Prädiktionsrests zu einem Prädiktionsblock, der mit der passenden Vorlage verbunden ist, um einen Pixelblock zu rekonstruieren.The method may further include generating a lookup table indicating a position of at least one corresponding adjacent end block. The decoding of the first two-dimensional representation may include decoding the entropy encoded bitstream to produce quantized encoded transform coefficients, dequantizing the quantized encoded transform coefficients to produce encoded transform coefficients, applying a transform to the encoded transform coefficients to at least one reconstructed prediction residual and adding the at least one reconstructed prediction residual to a prediction block associated with the matching template to reconstruct a pixel block.
In einem allgemeinen Aspekt kann auf einem nicht flüchtigen, computerlesbaren Speichermedium computerlesbarer Programmcode gespeichert sein, der, wenn er auf einem Computersystem ausgeführt wird, das Computersystem veranlasst, Schritte einschließlich der der Abbildung eines Frames eines sphärischen Videos auf einer ersten zweidimensionalen Darstellung auf Basis einer Projektion sphärisch zu quadratisch durchzuführen, wobei die erste zweidimensionale Darstellung ein Quadrat ist, die Zuordnung der der ersten zweidimensionalen Darstellung auf einer zweiten zweidimensionalen Darstellung, wobei die zweite zweidimensionale Darstellung ein Rechteck ist, und das Codieren der zweiten zweidimensionalen Darstellung als codierter Bitdatenstrom.In a general aspect, computer readable program code may be stored on a non-transitory computer-readable storage medium which, when executed on a computer system, causes the computer system to take steps including imaging a frame of a spherical video on a first two-dimensional representation based on a projection spherical to quadratic, where the first two-dimensional representation is a square, the assignment of the first two-dimensional representation to a second two-dimensional representation, the second two-dimensional representation being a rectangle, and encoding the second two-dimensional representation as a coded bitstream.
Implementierungen können eines oder mehrere der folgenden Merkmale beinhalten. Während eines Intraprädiktionsprozesses können die Schritte des Weiteren das Ermitteln beinhalten, ob sich ein zu codierender Block an einer Grenze der zweiten zweidimensionalen Darstellung befindet, und nach dem Ermitteln, dass sich der zu codierende Block an der Grenze befindet, einen benachbarten Endblock als eine Vorlage auswählen, wobei der benachbarte Endblock ein anderer als ein linker rekonstruierter Block oder ein oberer rekonstruierter Block des zu codierenden Blocks ist. Die Schritte können des Weiteren die Ermittlung beinhalten, ob sich ein zu deblockierender Block an einer Grenze der zweidimensionalen Darstellung befindet, und nach dem Ermitteln, dass sich der zu deblockierende Block an der Grenze befindet, einen benachbarten Endblock als einen Vergleichsblock auswählen, wobei der benachbarte Endblock ein anderer als ein linker rekonstruierter Block oder ein oberer rekonstruierter Block des zu deblockierenden Blocks ist.Implementations may include one or more of the following features. During an intra-prediction process, the steps may further include determining if a block to be encoded is at a boundary of the second two-dimensional representation and, after determining that the block to be encoded is at the boundary, selecting an adjacent end block as a template wherein the adjacent end block is a block other than a left reconstructed block or an upper reconstructed block of the block to be coded. The steps may further include determining whether a block to be deblocked is at a boundary of the two-dimensional representation and, upon determining that the block to be deblocked is at the boundary, selecting an adjacent end block as a comparison block, the adjacent one Endblock is a block other than a left reconstructed block or an upper reconstructed block of the block to be deblocked.
Die Abbildung der ersten zweidimensionalen Darstellung auf der zweiten zweidimensionalen Darstellung kann die Ermittlung eines ersten Quadrats mit Ecken beinhalten, die jede Seite der ersten zweidimensionalen Darstellung abstandsgleich von den Ecken der ersten zweidimensionalen Darstellung schneiden, die Ermittlung von vier Dreiecken, von denen eine Seite eine andere Seite des Innenkreises des Frames des sphärischen Videos berührt, das Erzeugen eines zweiten Quadrats auf Basis der vier Dreiecke und das Erzeugen der zweiten zweidimensionalen Darstellung auf Basis des ersten Quadrats und des zweiten Quadrats.The mapping of the first two-dimensional representation to the second two-dimensional representation may include determining a first square with corners that intersect each side of the first two-dimensional representation equidistant from the corners of the first two-dimensional representation, identifying four triangles, one side another Contacting the side of the inner circle of the frame of the spherical video, creating a second square based on the four triangles and generating the second two-dimensional representation based on the first square and the second square.
Obwohl die beigefügten Ansprüche spezielle Kombinationen von Merkmalen darstellen, die hierin beschrieben sind, ist der Umfang der vorliegenden Offenbarung nicht auf die speziellen Kombinationen beschränkt, die hierin nachstehend beansprucht werden, sondern umfasst stattdessen eine beliebige Kombination von Merkmalen oder Ausführungsformen, die hierin offenbart sind, unabhängig davon, ob diese spezielle Kombination in den beigefügten Ansprüchen zu diesem Zeitpunkt speziell aufgezählt worden ist.While the appended claims set forth specific combinations of features described herein, the scope of the present disclosure is not limited to the particular combinations claimed hereinafter, but instead includes any combination of features or embodiments disclosed herein. regardless of whether this particular combination has been specifically enumerated in the appended claims at this time.
Claims (20)
Applications Claiming Priority (9)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/518,956 US9918082B2 (en) | 2014-10-20 | 2014-10-20 | Continuous prediction domain |
US14/519,006 | 2014-10-20 | ||
US14/518,779 US20160112713A1 (en) | 2014-10-20 | 2014-10-20 | Mapping spherical image to 2d representations |
US14/518,956 | 2014-10-20 | ||
US14/519,006 US9918094B2 (en) | 2014-10-20 | 2014-10-20 | Compressing and representing multi-view video |
US14/518,779 | 2014-10-20 | ||
US14/518,710 US9917877B2 (en) | 2014-10-20 | 2014-10-20 | Streaming the visible parts of a spherical video |
US14/518,710 | 2014-10-20 | ||
PCT/US2015/056442 WO2016064862A1 (en) | 2014-10-20 | 2015-10-20 | Continuous prediction domain |
Publications (1)
Publication Number | Publication Date |
---|---|
DE112015004764T5 true DE112015004764T5 (en) | 2017-10-19 |
Family
ID=55761417
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
DE112015004764.6T Pending DE112015004764T5 (en) | 2014-10-20 | 2015-10-20 | CONTINUOUS PRESIDENTIAL AREA |
Country Status (5)
Country | Link |
---|---|
EP (2) | EP3813374A1 (en) |
CN (2) | CN112218074A (en) |
DE (1) | DE112015004764T5 (en) |
GB (1) | GB2545999A (en) |
WO (1) | WO2016064862A1 (en) |
Families Citing this family (34)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9918082B2 (en) | 2014-10-20 | 2018-03-13 | Google Llc | Continuous prediction domain |
US9917877B2 (en) | 2014-10-20 | 2018-03-13 | Google Llc | Streaming the visible parts of a spherical video |
US9918094B2 (en) | 2014-10-20 | 2018-03-13 | Google Llc | Compressing and representing multi-view video |
US20170214937A1 (en) * | 2016-01-22 | 2017-07-27 | Mediatek Inc. | Apparatus of Inter Prediction for Spherical Images and Cubic Images |
FI20165547A (en) | 2016-06-30 | 2017-12-31 | Nokia Technologies Oy | Arrangement, procedure and computer programs for video coding and decoding |
US10375371B2 (en) * | 2016-07-15 | 2019-08-06 | Mediatek Inc. | Method and apparatus for filtering 360-degree video boundaries |
WO2018035721A1 (en) * | 2016-08-23 | 2018-03-01 | SZ DJI Technology Co., Ltd. | System and method for improving efficiency in encoding/decoding a curved view video |
WO2018045108A1 (en) * | 2016-09-02 | 2018-03-08 | Vid Scale, Inc. | Method and system for signaling of 360-degree video information |
WO2018059500A1 (en) * | 2016-09-30 | 2018-04-05 | 华为技术有限公司 | Motion compensation prediction method and device |
CN107888928B (en) * | 2016-09-30 | 2020-02-14 | 华为技术有限公司 | Motion compensated prediction method and apparatus |
EP3301931A1 (en) * | 2016-09-30 | 2018-04-04 | Thomson Licensing | Method and apparatus for omnidirectional video coding with adaptive intra prediction |
CN108111851B (en) * | 2016-11-25 | 2020-12-22 | 华为技术有限公司 | Deblocking filtering method and terminal |
CN108235031B (en) * | 2016-12-15 | 2019-11-05 | 华为技术有限公司 | A kind of motion vector decoder method and decoder |
US20180192074A1 (en) * | 2017-01-03 | 2018-07-05 | Mediatek Inc. | Video processing method for processing projection-based frame with 360-degree content represented by projection faces packed in 360-degree virtual reality projection layout |
MX2019008789A (en) * | 2017-01-31 | 2019-09-11 | Sharp Kk | Systems and methods for partitioning a picture into video blocks for video coding. |
US10728494B2 (en) | 2017-02-20 | 2020-07-28 | Disney Enterprises, Inc. | Differential transformation of video |
US20180242017A1 (en) * | 2017-02-22 | 2018-08-23 | Twitter, Inc. | Transcoding video |
CN107071445A (en) * | 2017-04-10 | 2017-08-18 | 上海国茂数字技术有限公司 | A kind of panoramic video intraframe predictive coding method and device |
CN110692249A (en) * | 2017-04-11 | 2020-01-14 | Vid拓展公司 | 360 degree video coding using face continuity |
WO2018217057A1 (en) * | 2017-05-26 | 2018-11-29 | 엘지전자 주식회사 | 360 video processing method and apparatus therefor |
GB2563944B (en) * | 2017-06-30 | 2021-11-03 | Canon Kk | 360-Degree video encoding with block-based extension of the boundary of projected parts |
WO2019009750A1 (en) | 2017-07-05 | 2019-01-10 | Huawei Technologies Co., Ltd | Apparatus and method for coding panoramic video |
US10798417B2 (en) * | 2017-07-05 | 2020-10-06 | Qualcomm Incorporated | Deblock filtering for 360-degree video coding |
US10614609B2 (en) * | 2017-07-19 | 2020-04-07 | Mediatek Inc. | Method and apparatus for reduction of artifacts at discontinuous boundaries in coded virtual-reality images |
EP3685585A1 (en) | 2017-09-20 | 2020-07-29 | Vid Scale, Inc. | Handling face discontinuities in 360-degree video coding |
US10818087B2 (en) | 2017-10-02 | 2020-10-27 | At&T Intellectual Property I, L.P. | Selective streaming of immersive video based on field-of-view prediction |
WO2019083119A1 (en) * | 2017-10-23 | 2019-05-02 | 엘지전자 주식회사 | Image decoding method and device using rotation parameters in image coding system for 360-degree video |
WO2019159820A1 (en) * | 2018-02-14 | 2019-08-22 | シャープ株式会社 | Moving image encoding device and moving image decoding device |
WO2019166107A1 (en) * | 2018-03-02 | 2019-09-06 | Huawei Technologies Co., Ltd. | Apparatus and method for picture coding with selective loop-filtering |
US10659815B2 (en) | 2018-03-08 | 2020-05-19 | At&T Intellectual Property I, L.P. | Method of dynamic adaptive streaming for 360-degree videos |
US11039139B2 (en) | 2018-09-14 | 2021-06-15 | Tencent America LLC | Method and apparatus for identity transform in multiple transform selection |
EP3672251A1 (en) * | 2018-12-20 | 2020-06-24 | Koninklijke KPN N.V. | Processing video data for a video player apparatus |
GB2580084B (en) * | 2018-12-20 | 2022-12-28 | Canon Kk | Video coding and decoding |
CN110677692B (en) * | 2019-09-27 | 2022-12-06 | 腾讯科技（深圳）有限公司 | Video decoding method and device and video encoding method and device |
Family Cites Families (15)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6466254B1 (en) * | 1997-05-08 | 2002-10-15 | Be Here Corporation | Method and apparatus for electronically distributing motion panoramic images |
US6356297B1 (en) * | 1998-01-15 | 2002-03-12 | International Business Machines Corporation | Method and apparatus for displaying panoramas with streaming video |
FR2798761B1 (en) * | 1999-09-17 | 2002-03-29 | Thomson Multimedia Sa | METHOD OF CONSTRUCTING A 3D SCENE MODEL BY ANALYSIS OF IMAGE SEQUENCE |
US6993074B2 (en) * | 2000-03-24 | 2006-01-31 | Microsoft Corporation | Methods and arrangements for handling concentric mosaic image data |
EP1296243A3 (en) * | 2001-09-25 | 2007-04-11 | Interuniversitair Microelektronica Centrum Vzw | A method for operating a real-time multimedia terminal in a QoS manner |
KR100677142B1 (en) * | 2004-08-13 | 2007-02-02 | 경희대학교 산학협력단 | Motion estimation and compensation for panorama image |
KR100679031B1 (en) * | 2004-12-03 | 2007-02-05 | 삼성전자주식회사 | Method for encoding/decoding video based on multi-layer, and apparatus using the method |
JP4413203B2 (en) * | 2006-05-08 | 2010-02-10 | 富士通株式会社 | Image presentation device |
CN101771830B (en) * | 2008-12-30 | 2012-09-19 | 华为终端有限公司 | Three-dimensional panoramic video stream generating method and equipment and video conference method and equipment |
KR20160093105A (en) * | 2010-04-23 | 2016-08-05 | 엠앤케이홀딩스 주식회사 | Image encoding device and method |
US9930225B2 (en) * | 2011-02-10 | 2018-03-27 | Villmer Llc | Omni-directional camera and related viewing software |
JP2013255210A (en) * | 2012-01-19 | 2013-12-19 | Nippon Telegr & Teleph Corp <Ntt> | Video display method, video display device and video display program |
EP2645713A1 (en) * | 2012-03-30 | 2013-10-02 | Alcatel Lucent | Method and apparatus for encoding a selected spatial portion of a video stream |
CN102685532B (en) * | 2012-06-04 | 2014-04-16 | 山东大学 | Coding method for free view point four-dimensional space video coding system |
CN102831644A (en) * | 2012-07-09 | 2012-12-19 | 哈尔滨工程大学 | Marine environment information three-dimensional visualization method |
-
2015
- 2015-10-20 WO PCT/US2015/056442 patent/WO2016064862A1/en active Application Filing
- 2015-10-20 GB GB1621542.8A patent/GB2545999A/en not_active Withdrawn
- 2015-10-20 EP EP20211098.7A patent/EP3813374A1/en active Pending
- 2015-10-20 DE DE112015004764.6T patent/DE112015004764T5/en active Pending
- 2015-10-20 EP EP15853542.7A patent/EP3210379B1/en active Active
- 2015-10-20 CN CN202010965871.2A patent/CN112218074A/en active Pending
- 2015-10-20 CN CN201580035476.1A patent/CN106664403B/en active Active
Also Published As
Publication number | Publication date |
---|---|
EP3210379A1 (en) | 2017-08-30 |
GB201621542D0 (en) | 2017-02-01 |
EP3813374A1 (en) | 2021-04-28 |
GB2545999A (en) | 2017-07-05 |
EP3210379A4 (en) | 2018-03-21 |
WO2016064862A1 (en) | 2016-04-28 |
CN106664403B (en) | 2020-10-16 |
CN112218074A (en) | 2021-01-12 |
CN106664403A (en) | 2017-05-10 |
EP3210379B1 (en) | 2021-02-17 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
DE112015004764T5 (en) | CONTINUOUS PRESIDENTIAL AREA | |
US10681377B2 (en) | Streaming the visible parts of a spherical video | |
US20220182543A1 (en) | Method and apparatus for reconstructing 360-degree image according to projection format | |
DE102016225270A1 (en) | METHOD, APPLICATION PROCESSOR, AND MOBILE DEVICE FOR PROCESSING A REFERENCE PICTURE | |
DE102016125117B4 (en) | Motion vector coding with dynamic reference motion vectors | |
DE112018000280T5 (en) | BLOCK FILTER FOR 360 VIDEO | |
DE102016125379B4 (en) | Motion vector breakdown of the last frame | |
JP6858277B2 (en) | Directional intra-predictive coding | |
US20160112713A1 (en) | Mapping spherical image to 2d representations | |
DE112017001540T5 (en) | METHOD AND DEVICE FOR CODING VIDEO USING SIGNAL DEPENDENT ADAPTIVE QUANTIZATION AND DECODING | |
DE112016005457T5 (en) | Efficient, compatible and scalable intra-video / image encoding using wavelets and HEVC coding | |
KR101946598B1 (en) | Image coding and decoding method and device | |
DE112019000219T5 (en) | Adaptive loop filtering method for a reconstructed projection-based frame, which uses a projection arrangement of a 360-degree virtual reality projection | |
DE202016008175U1 (en) | Adaptive directed intra-prediction with block size | |
DE102016207230A1 (en) | Noticeable color conversions for video encoding with a wide range of colors | |
DE102019201370A1 (en) | PROCESSING MULTIDIRECTIONAL IMAGES IN SPATIAL VIDEO CODING APPLICATIONS | |
DE102016124926A1 (en) | Motion vector prediction using a previous frame residual | |
DE102016125591A1 (en) | Hybrid prediction modes for encoding videos | |
DE202016008164U1 (en) | Intelligent sorting of recursive block partitioning for advanced intra-prediction in video coding | |
DE102016125086A1 (en) | Adaptive directional loop filter | |
Olanda et al. | Terrain data compression using wavelet-tiled pyramids for online 3D terrain visualization | |
DE102016015996B3 (en) | Adaptive tile data size encoding for video and image compression | |
DE112015005159B4 (en) | CODING IN ALTERNATE BLOCK LIMITED DECISION MODE | |
WO2019130794A1 (en) | Video processing device | |
DE112019000287T5 (en) | Sample-Adaptive-Offset-Filtering method for a reconstructed projection-based frame, which uses a projection arrangement of a 360-degree-virtual-reality-projection |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
R012 | Request for examination validly filed | ||
R081 | Change of applicant/patentee |
Owner name: GOOGLE LLC (N.D.GES.D. STAATES DELAWARE), MOUN, USFree format text: FORMER OWNER: GOOGLE INC., MOUNTAIN VIEW, CALIF., US |
|
R082 | Change of representative |
Representative=s name: BETTEN & RESCH PATENT- UND RECHTSANWAELTE PART, DE |
|
R016 | Response to examination communication |