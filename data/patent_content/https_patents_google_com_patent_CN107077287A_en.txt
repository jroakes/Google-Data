CN107077287A - Start the application with interface switching - Google Patents
Start the application with interface switching Download PDFInfo
- Publication number
- CN107077287A CN107077287A CN201580035882.8A CN201580035882A CN107077287A CN 107077287 A CN107077287 A CN 107077287A CN 201580035882 A CN201580035882 A CN 201580035882A CN 107077287 A CN107077287 A CN 107077287A
- Authority
- CN
- China
- Prior art keywords
- computing device
- gesture
- interactive
- application
- interactive gesture
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0487—Interaction techniques based on graphical user interfaces [GUI] using specific features provided by the input device, e.g. functions controlled by the rotation of a mouse with dual sensing arrangements, or of the nature of the input device, e.g. tap gestures based on pressure sensed by a digitiser
- G06F3/0488—Interaction techniques based on graphical user interfaces [GUI] using specific features provided by the input device, e.g. functions controlled by the rotation of a mouse with dual sensing arrangements, or of the nature of the input device, e.g. tap gestures based on pressure sensed by a digitiser using a touch-screen or digitiser, e.g. input of commands through traced gestures
- G06F3/04883—Interaction techniques based on graphical user interfaces [GUI] using specific features provided by the input device, e.g. functions controlled by the rotation of a mouse with dual sensing arrangements, or of the nature of the input device, e.g. tap gestures based on pressure sensed by a digitiser using a touch-screen or digitiser, e.g. input of commands through traced gestures for inputting data by handwriting, e.g. gesture or text
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0487—Interaction techniques based on graphical user interfaces [GUI] using specific features provided by the input device, e.g. functions controlled by the rotation of a mouse with dual sensing arrangements, or of the nature of the input device, e.g. tap gestures based on pressure sensed by a digitiser
- G06F3/0488—Interaction techniques based on graphical user interfaces [GUI] using specific features provided by the input device, e.g. functions controlled by the rotation of a mouse with dual sensing arrangements, or of the nature of the input device, e.g. tap gestures based on pressure sensed by a digitiser using a touch-screen or digitiser, e.g. input of commands through traced gestures
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0484—Interaction techniques based on graphical user interfaces [GUI] for the control of specific functions or operations, e.g. selecting or manipulating an object, an image or a displayed text element, setting a parameter value or selecting a range
- G06F3/04842—Selection of displayed objects or displayed text elements
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/44—Arrangements for executing specific programs
- G06F9/445—Program loading or initiating
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/44—Arrangements for executing specific programs
- G06F9/451—Execution arrangements for user interfaces
Abstract
Technology for starting and switching application is provided.A kind of exemplary method, which is included at computing device, receives interactive gesture, when interactive gesture is matched with prearranged gesture, at least it is based on one or more tasks, the current context of computing device is determined, task includes previous being performed at computing device for task or the Future direction that will be performed at computing device predicted；Based on identified context, one or more software applications are recognized, software application includes the application being carrying out, the application or uninstalled application that have terminated, to perform one or more tasks；And display represents one or more user interface elements of software application, wherein, user interface element is to be selected to instantiate recognized software application.
Description
Background technology
The disclosure is usually directed to software application, and is particularly used for the user interface of such application.
The content of the invention
Disclosure theme involves starting up the application with interface switching.
In some innovation implementation modes, the theme of the disclosure can be embodied in method.This method is included in computing device
Place receives interactive gesture；When interactive gesture is matched with prearranged gesture, at least based on one or more tasks, it is determined that calculating
The current context of equipment, task includes previous being performed at computing device for task or being held at computing device of being predicted
Capable Future direction；Based on identified context, one or more software applications are recognized, software application should including what is be carrying out
With, the application or uninstalled application that have terminated, to perform one or more tasks；Display represents one or many of software application
Individual user interface element, wherein, user interface element is to may be selected to instantiate recognized software application.
In some innovation implementation modes, disclosed theme can be embodied in machine readable media.Machine readable Jie
Matter includes instruction, and the instruction is when being executed by a processor so that computing device is operated, and the operation includes：At least it is based on
One or more tasks, determine the current context of computing device, task include previously having been performed at computing device for task or
The Future direction that will be performed at computing device predicted；Interactive gesture is received at computing device；It is determined that being set in calculating
Whether the interactive gesture that standby place is received matches with prearranged gesture；And work as the interactive gesture and predetermined hand received
When gesture is matched, based on identified context, display may be selected to instantiate one or more users circle of corresponding software application
Surface element, wherein, when respective software application is not installed at computing device, selecting one or more user interface elements
When, respective software application, which is downloaded from server and is installed in computing device, sentences display.
In some innovation implementation modes, disclosed theme can be embodied in systems.The system includes including instruction
Memory；And processor, be configured as execute instruction with：Interactive gesture is received at computing device；When interactive gesture
When being matched with prearranged gesture, at least based on one or more tasks, the current context of computing device is determined, task includes previously existing
Being performed at computing device for task or the Future direction that will be performed at computing device predicted；Based on identified field
Border, identification performs one or more software applications of one or more tasks, and software application includes performing one or more tasks
The application terminated or uninstalled application；And one or many that display may be selected to instantiate recognized software application
Individual user interface element.
It will be appreciated that being described in detail from following, the other configurations of this subject technology will become to one skilled in the art
Obtain it is clear that wherein, by example, showing and describing the various configurations of this subject technology.This subject technology energy will be recognized
There are other and different configurations, and in the case of the scope all without departing from this subject technology, some details can be each
Plant otherwise modification.Therefore, accompanying drawing and detailed description will substantially be considered exemplary rather than restricted.
Brief description of the drawings
The novel feature of this subject technology is illustrated in the appended claims.However, for the purpose of illustration, in following summaries
In accompanying drawing, if illustrating the stem structure of this subject technology.
Figure 1A is suitable for implementing the example apparatus and the figure of network environment of some embodiments of this subject technology.
Figure 1B illustrates the example user interface including application and user interface element.
Fig. 2 illustrates the instantiation procedure for the embodiment for implementing this subject technology for the example apparatus using Figure 1A.
Fig. 3 illustrates the instantiation procedure for the embodiment for implementing this subject technology for the example apparatus using Figure 1A.
Fig. 4 illustrates the another example mistake for the embodiment for implementing this subject technology for the example apparatus using Figure 1A
Journey.
Embodiment
Detailed description described below is intended to the description of the various configurations as this subject technology, and be not intended to expression can
To implement unique configuration of this subject technology.Accompanying drawing merges wherein and constitutes a part for detailed description.This subject technology is not
It is limited to detail as described herein, and this subject technology can also be implemented in the case of not such detail.
Some applications can be arranged on computing device (for example, smart phone or tablet PC) by user.For example
Change or open application, user may be needed from menu setecting application icon.As time go on, when user installation application number
During amount increase, user is needed before positioning user is intended to the application that uses, filters out some application icons.As long as in addition, opening
Using to use, user is needed before another application is switched to, and browses some applications that other have been opened.This time-consuming and reduction is used
Experience at family.
Disclosed aspect can allow user to use unified interface method, easily start or switch application.For example, user
Gesture can be provided to touch-screen, when providing gesture every time, automatically to show that startup user needs to use one or more
The user interface element (for example, icon) of application.It is easily shown on the touchscreen that user can also provide permission user
The gesture (for example, slip gesture) switched between one or more applications having been turned on.Some embodiments are included in calculating and set
Standby place receives interactive gesture.When interactive gesture is matched with prearranged gesture (for example, continuously slipping gesture), can at least it be based on
The one or more tasks previously performed at computing device or the prediction Future direction that will be performed at computing device, to determine
The current context (for example, current operation context) of computing device.Based on identified context, it can recognize that one or more softwares should
With (including application, the application or uninstalled application that have terminated being carrying out) to perform one or more tasks.Can display
One or more user interface elements of software application are represented, wherein, it is corresponding soft to instantiate to select user interface element
Part application.When selecting one or more user interface elements, the identified current context of computing device can be automatically updated.
When next interactive gesture can be received, other software application can be recognized using updated context.In some implementations
In mode, identification gesture (for example, the continuously slipping gesture) user interface element that is terminated thereon and can show or switch with
The display software application associated with user interface element.By this way, user can use unified interface method, come easily
Start or switching application.Which improve Consumer's Experience.
Some aspects of this subject technology include storage and the user account information relevant with software application use activity.With
Family has the option for preventing storing such information.Control program can also be provided the user or whether feature collects or shared use
The chance of family information (for example) with user account, software application use pattern, the user preferences of user etc. for information about.By
This, user has the right to control how to collect and uses the information relevant with user by computing device.
Figure 1A is to illustrate to be used for the example of application startup and interface switching according to some embodiments of this subject technology
The figure of framework.Client computing device 190 includes processor 112, memory 120, holder 126, bus 124, input/output
Module 128, input equipment 116, output equipment 114 and communication module 118.Memory 120 includes one or more software applications
130A-N, interaction determiner 132, context and application identifier 134, user interface manager 136 and use activity data 140.
In some embodiments, client computing device 190 includes being used for applying via browser or Web, promotes user mutual
One or more modules.Client computing device 190 can include with client computing device 190 connecting by 150 pairs of network
The proprietary application that data that are being stored at the server 180 connect or being retrieved from server 180 are handled.Client computing device
190 may be implemented as individual machine or multiprocessor machine with single processor.Communication module 118 can make client meter
Equipment 190 is calculated to transmit data to server 180 by network 150 and receive data from server 180.
In some embodiments, server 180 can store with client computing device 190 install or operate
Using use data (or any other data) relevant 130A-N.It can be included using data related to each application 130A-N
The access times of connection and the use duration of each application in application 130A-N.Server 180 can also store can by with
Carry out at client computing device 190 to perform the database of the application of one or more tasks.Using need not be in client meter
Calculate and installed at equipment 190, access or perform in advance.For example, server 180 can be stored in one or more database list rows
Indicate that " application voice (application voice) " can be used for the information of " call (phone call) ".In some realities
Apply in mode, server 180 can store the social content associated with social networking service (for example, the content puted up
).Server 180 can store the data relevant with user account and the content item associated with user account.For example, service
Device 180 can include indicating to be checked, shared, commented on or annotated (for example, agreeing with or not praising via using 130A-N by user account
Into) content item data.Server 180 can also store related to one or more social networking services or application 130A-N
The authentication data (for example, username and password) of connection.
In some embodiments, client computing device 190 and server 180 can be in communication with each other via network 150.Net
Network 150 can include internet, Intranet, LAN, wide area network, cable network, wireless network or Virtual Private Network (VPN).
Although only figure shows a client computing device 190 and server 180, this subject technology can be by any number of visitor
Family end computing device 190 and server 180 are realized jointly.In some non-limiting embodiments, single computing device can be real
The function of other assemblies shown in existing client computing device 190, server 190 and Figure 1A.
Client computing device 190 can be laptop computer, desktop computer, mobile phone, personal digital assistant
(PDA), tablet PC, notebook, the TV with built-in or coupled thereto one or more processors, physical machine or
Virtual machine.Client computing device 190 can include one or more of keyboard, mouse, display or touch-screen.Client
Computing device 190 can include being configured as display webpage or the browser of any web content or any Web applications.For example, browsing
Device, which can be shown, includes the webpage of the content from server 180.As an alternative, client computing device 190 can include being used to visit
Ask the proprietary application (for example, mobile phone or tablet PC application) with display content.
Figure 1B is illustrated including the application 130A-N's and user interface element 138A-N for representing corresponding application 130A-N
Example user interface.For example, user interface element 138A can be selected 130A is applied to instantiate (or switching to show).User
176 can on the touch-sensitive display of computing device 190 using touch gestures (for example, slip gesture) come by touch one or
Multiple application 130A-N shown expression is come the shown application 130A-N that navigates.User 176 can use search to input
Area 154 allows the search inquiry of user's search content and application to provide.Notification area 154 may be displayed on client computing device
The notice or message (for example, Email, prompting, processing business and updates etc.) received at 190.It will be recognized that shown in fig. ib
Application 130A-N and user interface element 138A-N be exemplary, and be not intended to limitation disclosed in embodiment.
As described above, the memory 120 of client computing device 190 can include one or more software application 130A-N,
Interaction determiner 132, context and application identifier 134, user interface manager 136 and use activity data 140.In some realities
Apply in mode, context and the one or more applications for determining to perform in client computing device 190 using identifier 134
130A-N, wherein, representing application 130A-N one or more user interface element 138A-N allows with application 130A-N's
Switch between interaction.In some embodiments, it need not be mounted or pre- via client computing device 190 using 130A-N
First access or interact and can be used to download from server 180.Although Figure 1A illustrates installed application 130A-N, application
One or more of 130A-N can not also be mounted or be not installed in advance at client computing device 190.Such
In the case of, client computing device 190 can be downloaded or installed using one in 130A-N from server 180 or from installation file
It is individual or multiple, the installation file with reside in client computing device 190 those are associated using 130A-N.
In some embodiments, interactive gesture can be received at client computing device 190.Gesture can be appointed
The interactive gesture (for example, touch gestures) of what type.Interactive gesture can be any shape or pattern (for example, circular, sliding
Dynamic, order touch etc.).When user 176 by finger touch on the touch-screen display of client computing device 190 when, from
Family 176 receives the gesture.Then, interaction determiner 132 can check the gesture that is received from user 176 whether with prearranged gesture
Matching.Prearranged gesture can be stored in memory 120.
In some embodiments, when the interactive gesture received is matched with prearranged gesture, context and application identification
Device 134 can at least be based on one or more tasks, determine the current context of client computing device 190.Task can be included in
Previously having been performed at client computing device 190 for task or the future by the execution at client computing device 190 of prediction appoint
Business.Previously having performed for task can include but is not limited to application example (or opening), in the interior performed action (example of application
Such as, record, audio play, typewriting, will be using being mirrored to another screen etc.), using terminating (or closing).In some embodiments
In, whether the Future direction predicted is the state based on one or more applications (such as 130B-N) with ought previously perform application
It is similar or similar as one or more tasks performed by user 130A relative to predicted time during 130A.When context and application
Identifier 134 determines that application 130B-N state is matched with when starting application 130A using 130B-N specific original state,
Context and application identifier 134 are determined in future when application 130B-N state is matched with specific original state again, again
130A is applied in startup.The example is only exemplary and can predict any other task by context and using identifier 134.
In some embodiments, current context and the interactive hand of reception determined by context and application identifier 134
The special time of gesture is associated and can indicate relative to the special time, previously in the special time in client computing device
Any task is performed at 190 and is predicted after the special time, what Future direction will be performed.It can be used by checking
Activity 134, the determining previously to have performed by context and using identifier 134 of the task.As described above, being answered based on one or more
With the state of (such as 130B-N) whether with when it is previous perform application 130A when similar or time relative to the prediction by with
One or more nearest tasks that family 130A is performed, to predict Future direction.Currently context can also be recognized in the special time,
What resource (for example, memory, hardware or software resource) is available at client computing device 190.Current context can
With including representing or recognizing one or many of the previous tasks associated with client computing device 190, Future direction and resource
Individual value and can be stored in can be in the memory 120 by the corresponding time value index for determining current context (or updating context)
In the data structure (for example, database table) stored.Current context can also include (or based on) and use activity data 140.
In some embodiments, the frequency of use of one or more applications can be included, from most using activity data 140
At the time of afterwards in the time, one day of first use application or what day, the geographical position of client computing device 190, from client
Hold the content of the reception/transmission of computing device 190, any other signal outside client computing device 190.Use activity data
140 can store the identifier and their phases for the application 130A-N for representing to be arranged in client computing device 190
The database table or any data structure for the use parameter answered.Application identifier can be any numerical value or alphanumeric values.Example
Such as, application identifier can " apply 130A " and use parameter associated therewith be used recently by user 176
The date and time of application is (for example, on January 2nd, 2014,12:05AM).User 176 can with " apply that 130A " interacts other
Time is also stored as using the historical data in activity data 140.It can also be stored in using activity data 140 and apply 130A
Interior performed operation (for example, record, audio play, will be using being mirrored to another screen etc.).
Based on the context of the client computing device 190 determined by context and application identifier 134, one or many is recognized
Individual software application.The application being carrying out that software application can include performing one or more tasks, the application terminated or not
The application of installation.In some embodiments, context and the identification of application identifier do not interacted with computing device 190 previously or via
Software application or software service that computing device is accessed.Before execution task at client computing device 190, context and application are known
Other device 134 can recognize the one or more applications for performing one or more tasks.In other words, it is not necessary to receive and come from user
The instruction of the application-specific of 176 identification execution task.On the contrary, context and can automatically be recognized using identifier 134 can be by
User 176 uses the one or more application 130A-N for carrying out perform prediction task.
In some embodiments, when recognizing one or more application 130A-N by context and using identifier 134, use
The display of family interface manager 136 represents application 130A-N one or more user interface element 138A-N, wherein, it can select to use
Family interface element 138A-N applies 130A-N accordingly to instantiate.As mentioned above, it can include not installing using 130A-N
Application, mounted application, the application terminated, the application being carrying out and do not interact with computing device 190 previously or
The software application accessed via computing device 190 or software service.For example, user interface element 138A can be shown (for example, language
Sound application icon) and the user interface element 138A can be selected to instantiate using 130A (for example, audio call application).
It need not be installed at client computing device 190 or be accessed in advance via client computing device 190 using 130A.When should
When being not installed in 130A at client computing device 190, context and application identifier 134 can be (from server 180) certainly
Download dynamicly and the application is installed, for being used by user 176 so that when user 176 selects to represent application 130A user
During interface element 138A, it can be started by user 176 or instantiated and apply 130A to use.By this way, regardless of whether
Software application is installed or terminated at computing device, can select user interface element 138A-N to instantiate corresponding software application
130A-N.It will be appreciated that before use, using 130A-N need not before use " mounted " at client computing device 190
And can be the Web applications or the application based on browser for not requiring to install.
In some embodiments, when selecting one or more user interface element 138A-N, context and application identification
Device 134 automatically determines the updated context of client computing device 190.Then, connect when at client computing device 190
When receiving next interactive gesture, based on updated context, context and the application identification other software of identifier 134 apply (example
Such as, using 130B-C) and the other users interface element for representing other software application is shown, wherein, other users can be selected
Interface element (for example, 138B-C) instantiates corresponding other software application.
In some embodiments, interactive gesture can be lasting slip gesture, wherein, user 176 touch finger and
The touch-screen of finger lift-off client computing device is not made, untill finger reaches user's user interface element interested.
In some embodiments, when receiving lasting slip gesture from user 176, user interface manager 136 initiates user interface
Element 138A-N display.Context and application identifier 134, which can be recognized, terminates the particular user interface member for continuing slip gesture
Plain (for example, 138C).Then, context and application identifier 134 instantiate the software associated with particular user interface element and answered
With (for example, 130C).By this way, using unified interface method, user easily can start or switch application.This is improved
Consumer's Experience.
In some embodiments, interaction determiner 132 recognizes the received during the first interactive gesture is received
Two interactive gestures.Interaction determiner 132 can independently be determined with the first interactive gesture the second interactive gesture whether with
Another prearranged gesture matching.First interactive gesture and the second interactive gesture can be stored in memory 120, can be by
Interaction determiner 132 verifies them from memory 120.First interactive gesture can be differently configured from the second interactive gesture.As
Illustrative examples, the first interactive gesture can be the slip to the left of finger, and the second interactive gesture can be another hand
The slip to the right referred to.Such as another exemplary example, the first interactive gesture can be the constant touch gestures using a gesture,
And second interactive gesture can be using another gesture to the right, to the left or circular slide.Can simultaneously or successively it connect
Receive the first and second gestures.Such example is pure to be exemplary and not restrictive.In some embodiments, interaction is worked as
When determiner 132 determines that the second interactive gesture is matched with other prearranged gestures, context and application identifier 134 are based on being determined
Client computing device 190 context, recognize the one or more action (examples that can be performed at client computing device 190
Such as, one or more applications in application or particular task are started), and based on the second interactive gesture or the first interactive hand
The combination of gesture and the second interactive gesture, performs one or more actions.
Fig. 2 is the example process 200 for the embodiment for implementing this subject technology using Figure 1A example apparatus.Although ginseng
The element for examining Figure 1A describes Fig. 2, but Fig. 2 process not limited to this and can be used in other systems.
Process 200 is started (stage 202) with receiving interactive gesture at computing device.For example, can be in client meter
At the touch-screen display for calculating equipment 190, touch gestures are received from user 176.
When interactive gesture is matched with prearranged gesture, one or more tasks can be at least based on, computing device is determined
Current context, the task includes previously being performed at computing device for task or will held what is predicted at computing device
Capable Future direction (stage 204).For example, when interaction determiner 132 determines the friendship that is received at client computing device 190
When mutual formula gesture 132 is matched with the prearranged gesture stored in memory 120, context and application identifier 134 can determine visitor
The current context of family end computing device 190.Can based on the task including previously having been performed at client computing device 190 or
The task by the Future direction performed at client computing device 190 predicted, determines working as client computing device 190
Preceding context.
Based on identified context, one or more software applications can be recognized, wherein, software application include perform one or
The application being carrying out of multiple tasks, the application terminated or uninstalled application (stage 206).Answered for example, can recognize
Particular task (for example, audio call) is performed with 130A (for example, audio call application).
The one or more user interface elements for representing software application can be shown, wherein, user interface element is optional
To instantiate (stage 208) of recognized software application.For example, user interface element 138A can be shown and can be chosen
Select and apply 130A to instantiate.
Fig. 3 is the instantiation procedure 300 for the embodiment for implementing this subject technology using Figure 1A example devices.Although ginseng
The element for examining Figure 1A describes Fig. 3, Fig. 3 process not limited to this and can be used in other systems.
Process 300 is started with the current context at least determining computing device based on one or more tasks, the task bag
Include previous being performed at computing device for task or the Future direction (stage that will be performed at computing device predicted
302).For example, can be based on the task including previously having been performed at client computing device 190 (for example, video or audio are broadcast
Put, typewrite, open or close using etc.) or predicted will at client computing device 190 perform task, to determine visitor
The current context of family end computing device 190.
Interactive gesture is received the interaction that (stage 304) and determination are received at computing device at computing device
Whether formula gesture matches (stage 306) with prearranged gesture.For example, when interaction determiner 132 is determined in client computing device 190
When place receives interactive gesture, whether interaction determiner 132 can check received gesture with being stored in memory 120
Prearranged gesture matching.
When the interactive gesture received is matched with prearranged gesture, based on identified context, display may be selected to come real
One or more user interface elements of the corresponding software application of exampleization.When corresponding software application is not installed in computing device
During place, after one or more user interface elements are selected, corresponding software application is downloaded and is arranged on from server
Computing device is sentenced for showing (stage 308).
For example, user interface element 138A (for example, voice application icon) can be shown and can be selected to example
Change application 130A (for example, audio call application).For example, need not be installed at client computing device 190 using 130A
Or accessed in advance via client computing device 190.When being not installed in using 130A at client computing device 190, field
Border and application identifier 134 automatically can be downloaded and installed and apply to be used by user 176 so that when user 176 selects table
When showing the user interface element 138A using 130A, start or instantiate application 130A to be used by user 176.When based on really
Fixed context, recognizes the one or more software applications (for example, 130A) associated with user interface element (for example, 138A)
When, it is automatic to download and install and occur.For example, when the application and application that are identified as to be opened by user 176 using 130A
176 when not being mounted or can use at client computing device 190, then context and application identifier 134 are from server 180
After download, it will can be arranged on using 130A at client computing device 190.When selecting one or more user interfaces by user
During element (for example, 138A), automatic download and installation can also occur.
Fig. 4 is the instantiation procedure 400 for the embodiment for implementing this subject technology using Figure 1A example apparatus.Although with reference to
Figure 1A element describes Fig. 4, but Fig. 4 process not limited to this and can be used in other systems.
Process 400 is started (stage 402) with receiving interactive gesture at computing device.For example, can be in client meter
At the touch-screen display for calculating equipment 190, touch gestures are received from user 176.
When interactive gesture is matched with prearranged gesture, one or more tasks can be at least based on, computing device is determined
Current context, the task includes previous being performed at computing device for task or being performed at computing device of being predicted
Future direction (stage 404).For example, when interaction determiner 132 determines the interaction that is received at client computing device 190
When formula gesture 132 is matched with the prearranged gesture stored in memory 120, context and application identifier 134 can determine visitor
The current context of family end computing device 190.Can based on the task including previously having been performed at client computing device 190 or
The task by the Future direction performed at client computing device 190 predicted, determines working as client computing device 190
Preceding context.
Based on identified context, one or more software applications can be recognized to perform one or more tasks, software should
With the application including having terminated or perform one or more tasks application (stage 406) is not installed.For example, application can be recognized
130A (for example, audio call application) performs particular task (for example, audio call).In some embodiments, Ke Yishi
All applications of particular task Ke Yongyu not performed.In other embodiments, the application of execution particular task can be recognized
Subset.
It can show and may be selected to instantiate one or more user interface element (stages of recognized software application
408).For example, user interface element 138A can be shown and can be selected to instantiation application 130A.
Return to Figure 1A, in some aspects, server 180 and client computing device 190 can use hardware or software and
The combination of hardware is realized, is either integrated into private server in another entity or across the distribution of multiple entities.
For example, client computing device 190 can include bus 124 or other communication mechanisms for the communication information and
For the processor 112 coupled with bus 124 of processing information.Processor 112 can be general purpose microprocessor, microcontroller,
Digital signal processor (DSP), application specific integrated circuit (ASIC), field programmable gate array (FPGA), programmable logic device
(PLD), controller, state machine, gate logic, discrete hardware components or can perform calculating or other information manipulate it is any its
His suitable entities.
In addition to hardware, server 180 can include creating the performing environment for discussed computer program
Code, for example, building processor firmware, protocol stack, data base management system, the code of operating system, or is stored in memory
The combination of one or more of code in 120.Memory 120 can include random access memory (RAM), flash memory storage
It is device, read-only storage (ROM), programmable read only memory (PROM), erasable PROM (EPROM), register, hard disk, removable
Disk, CD-ROM, DVD or any other suitable storage device, the memory 120 be coupled to bus 124 be used for store letter
Breath and the instruction performed by processor 112.Processor 112 and memory 120 can be supplemented by dedicated logic circuit, or
It is integrated into dedicated logic circuit.
Instruction can be stored in memory 120 and can be implemented in one or more computer program products,
One or more modules of the computer program instructions encoded on a computer-readable medium, one or more of modules are used
To perform or control the operation of server 180 by server 180, and according to well known to a person skilled in the art any method,
Including but not limited to the language (for example, SQL, dBase) of such as data-oriented, system language are (for example, C, object C, C++, remittance
Compile), the machine word of schema languages (for example, Java .NET) and applicational language (for example, PHP, Ruby, Perl, Python)
Speech.Instruction can also be implemented with computer language, such as the language of array language, AOP, assembler language, writing language
Speech, command line interface language, compiler language, concurrent language, brace language, data-flow language, data structure language, declaratively
Language, secret language, extension language, fourth generation language, functional explanations, interactive mode language, interpreted languages, iteration language
Speech, the language based on list, small language, the language of logic-based, machine language, macrolanguage, metaprogramming language, many normal form languages
Speech, numerical analysis, the language based on non-english, the language based on classification of object-oriented, the language based on prototype of object-oriented
Speech, offside rule language, procedural language, reflection language, rule-based language, script, the language based on stack, synchronous language
Speech, grammer disposal language, visual language, Butterworth (wirth) language, embedded language and the language based on xml.Memory
120 can be also used for storing temporary variable or other average informations during the instruction to be performed by processor 112 is performed.
Computer program discussed herein need not be corresponding with the file in file system.Program can be stored in
Keep other programs or data file a part in (for example, the one or more pin stored in marking language document
Originally), (for example, storing one or many in the single file for being exclusively used in inquired into program or in multiple coordinated files
The file of individual module, subprogram or code section).Computer program can be deployed as will be on a computer or positioned at one
Individual website is performed across on multiple computers that multiple websites are distributed and pass through interconnection of telecommunication network.Described in this specification
Process and logic flow can be performed by the one or more programmable processors for performing one or more computer programs, with
By operating and generating output on the input data come perform function.
Server 180 further comprises data storage device 126, such as disk or CD, the data storage device 126
Being coupled to bus 124 is used for storage information and instruction.Server 180 can be coupled to respectively via input/output module 128
Plant equipment.Input/output module 128 can be any input/output module.Example input/output module 128 is included such as
The FPDP of USB port.Input/output module 128 is configured to connect to communication module 118.Example communication module 118
(for example, communication module 118 and 238) includes NIC, such as Ethernet card and modem.In some aspects, it is defeated
Enter/output module 128 is configured to connect to multiple equipment, such as input equipment 116 and/or output equipment 114.Example is inputted
Equipment 114 include keyboard and pointing device, such as mouse or trace ball, user can with its to server 180 offer input.Its
The input equipment 114 of his species be can be utilized to provide and be interacted with user, and such as tactile input device, vision are inputted and set
Standby, audio input device or brain-computer-interface equipment.For example, the feedback for being supplied to user can be any type of sensation
Feedback, such as visual feedback, audio feedback or touch feedback；Also, the input from user can be received with arbitrary form,
Including the input of acoustics, language, tactile or brain wave.Example output device 116 includes display apparatus, such as LED (light-emitting diodes
Pipe), CRT (cathode-ray tube) or LCD (liquid crystal display) screen, for user's display information.
According to an aspect of this disclosure, server 180 can use server 180 to be performed in response to server 112 and deposit
One or more sequences of one or more instructions included in reservoir 120 are realized.Such instruction can from it is all in full
According to another machine readable media read in memory 120 of storage device 126.To the sequence of the instruction included in main storage 120
The execution of row causes processor 112 to perform process block specifically described herein.One or many in can also being arranged using multiprocessing
Individual processor performs the sequence of the instruction included in memory 120.In alternative aspects, hard-wired circuit can be used to replace
Software instruction or with the combined various aspects to realize the disclosure of software instruction.Therefore, it is not limited to hardware in terms of the disclosure
Any particular combination of circuit and software.
The various aspects of theme described in this specification can be implemented in computing systems, and the computing system includes
Aft-end assembly (such as data server), either including middleware component (such as application server) or including
Front end assemblies (for example can be used to graphic user interface or web that the realization with theme described in this specification is interacted with user
The client computer of browser), or one or more such rear ends, middleware or front end assemblies any combinations.System
The component of system can be interconnected by the arbitrary form or medium of digital data communications, such as communication network.Communication network (example
Such as, network 150) it can include, for example, Personal Area Network (PAN), LAN (LAN), campus network (CAN), Metropolitan Area Network (MAN) (MAN), wide area
Any one or more in net (WAN), broadband networks (BBN), internet etc..Further, for example, communication network can be wrapped
Include, but be not limited to, it is any one or more in network topology below, including bus network, star network, loop network,
Mesh network, star-bus network, tree-like or hierarchical network etc..For example, communication module can be modem or Ethernet
Card.
For example, without limitation, server 180 can be desktop computer, laptop computer or flat
Plate computer.Server 180 can also be embedded in another equipment, for example, without limitation, being embedded into movement
Phone, personal digital assistant (PDA), Mobile audio player, global positioning system (GPS) receiver, video game machine and/
Or TV set-top box.
Term " machinable medium " or " computer-readable medium " as used herein refer to participating in processing
Device 112, which provides instruction or data, is used for the arbitrary medium or medium of execution.Such medium can use many forms, including but
It is not limited to, non-volatile media and Volatile media.For example, non-volatile media includes, CD, disk or flash memories,
Such as data storage device 126.Volatile media includes dynamic memory, such as memory 120.Transmission medium includes coaxial electrical
Cable, copper cash and optical fiber, including include the electric wire of bus 124.For example, the common form of machine readable media includes floppy disk, soft
Formula disk, hard disk, tape, any other magnetizing mediums, CD-ROM, DVD, any other optical medium, punch card, paper tape, with hole
Any other physical medium, RAM, PROM, EPROM, flash eprom, any other memory chip or the chuck of pattern or
Any other medium that computer can therefrom be read.Machinable medium can be machine readable storage device, machine
Readable storage substrate, memory devices, the composition of the machine readable transmitting signal of influence or the one or more group of the above
Close.
As it is used herein, " at least one " in a series of foregoing items of phrase, and with term " and " or "or" come
Separate any in the item, list modified as overall, rather than list each member (i.e. each item).Phrase
" at least one " does not require to select at least one；On the contrary, the phrase allows to include at least one of any one in item,
And/or at least one in any combination of item, and/or at least one each in item.For example, phrase is " in A, B and C
At least one " or " at least one in A, B or C " it is each all referring to only A, only B or only C；A, B and C any combinations；
And/or at least one each in A, B and C.
Moreover, on term " comprising ", " having " or similar, the such art used in specification or claim
Language is intended to inclusive, in the way of similar to term " comprising ", as " comprising " is used as conjunction in the claims
When the implication that is used.
The reference to element is intended to mean that " one and only one " in the singular, unless specifically stated, otherwise awareness of defecation
Taste " one or more ".Those of ordinary skill in the art are known or being described in the whole text to the disclosure of will be appreciated by later various match somebody with somebody
The equivalent form of value of all 26S Proteasome Structure and Functions for the element put clearly is incorporated in herein and is intended to by theme skill by quoting
Included by art.Moreover, disclosed herein being not intended to contributes to the public, no matter it is such open whether in superincumbent description
Clearly describe.
Although this specification includes many details, such details is not construed as the scope to that can be claimed
Limitation, but be used as the description of the specific implementation to theme.In this specification described in the context of single aspect
Some features can also be in combination implemented in single aspect.On the contrary, being retouched in the context of single aspect
The various features stated can also be realized in many aspects or in any suitable sub-portfolio respectively.Although moreover, feature can be as
Worked described in upper in some combinations and even initially so claimed, one or many from claimed combination
Individual feature can be removed from combination in some cases, and combination claimed is directed into sub-portfolio or son
The modification of combination.
Similarly, although depicting operation in the accompanying drawings with certain order, this, which is not construed as such operation, needs
It either can be just performed in sequential order with shown certain order or the operation of all diagrams be performed, could obtained
Desired result.In certain environments, multitask and parallel processing are probably favourable.Moreover, various systems in above-mentioned aspect
The separation of component is required for such separation, and it should be understood that described program component in being not construed as in all respects
It can be generally integrated or be encapsulated in multiple software product in single software product with system.
The theme of this specification is described on particular aspects, but other aspect can also be implemented and
In scope of the following claims.For example, the action described in claim can in different order be performed but still obtain
Desired result.For example, the process described in the accompanying drawings is without requiring shown certain order or sequentially order, with
Obtain desired result.In some implementations, multitask and parallel processing are probably favourable.Other changes will in appended right
In the range of asking.
Such and other embodiment is all in the range of following claims.
Claims (20)
1. a kind of computer implemented method, including：
Interactive gesture is received at computing device；
When the interactive gesture is matched with prearranged gesture, at least based on one or more tasks, the computing device is determined
Current context, the task includes previous being performed at the computing device for task or being calculated described of being predicted
The Future direction performed at equipment；
Based on identified context, one or more software applications are recognized, application that the software application includes being carrying out,
The application of termination or uninstalled application, to perform one or more of tasks；And
Display represents one or more user interface elements of the software application, wherein, the user interface element can be chosen
Select to instantiate recognized software application.
2. the method as described in claim 1, further comprises：
Receive next interactive gesture；
When next interactive gesture is matched with the prearranged gesture, at least based on one or more of tasks, really
The current context of the fixed computing device, the task includes task or the institute previously performed at the computing device
The Future direction that will be performed at the computing device of prediction；
Based on identified context, one or more other software applications are recognized；And
Display represents the other users interface element of other software application, wherein, the other users interface element can be chosen
To instantiate the corresponding other software application.
3. the method for claim 1, wherein the interactive gesture is to include the touch screen display from the computing device
Show first on device point of continuously slipping gesture of touch for starting to terminate at the second point on the touch-screen display.
4. method as claimed in claim 3, further comprises：
When receiving the continuously slipping gesture, the display of the user interface element is initiated；
Recognize the particular user interface element shown at the second point on the touch-screen display；And
The instantiation software application associated with the particular user interface element.
5. the method as described in claim 1, further comprises：
Recognize the second interactive gesture received during or after the described first interactive gesture is received；
Independently determine whether the described second interactive gesture matches with another prearranged gesture with the described first interactive gesture；
When the described second interactive gesture is matched with another prearranged gesture,
Based on identified context, the one or more actions that can be performed at the computing device are recognized；And
Combination based on the described second interactive gesture or the first interactive gesture and the second interactive gesture, is performed
The one or more actions recognized.
6. the Future direction the method for claim 1, wherein predicted be the time based on relative to the prediction by
One or more nearest tasks performed by the user, the time of the prediction occurs described in the computing device
When current context is determined.
7. the method as described in claim 1, further comprises：
It is that identification user does not interact previously via the computing device or accessed as service via the computing device
Software application or software service；And
Using one or more of user interface elements, display represents the user interface element of the software application.
8. a kind of including the machine readable media of the instruction wherein stored, the instruction is when being executed by a processor so that described
Computing device is operated, and the operation includes：
One or more tasks are at least based on, the current context of computing device is determined, the task includes previously calculating described
Being performed at equipment for task or the Future direction that will be performed at the computing device predicted；
Interactive gesture is received at the computing device；
It is determined that whether the interactive gesture received at the computing device matches with prearranged gesture；And
When the interactive gesture received is matched with the prearranged gesture, based on identified context, display can be selected to
One or more user interface elements of corresponding software application are instantiated, wherein, when corresponding software application is not pacified
When at the computing device, corresponding software application is when one or more of user interface elements are chosen
Downloaded from server and be installed in the computing device and sentence display.
9. machine readable media as claimed in claim 8, further comprises the instruction wherein stored, the instruction is when by described
During computing device so that the computing device operation, the operation includes：
Receive next interactive gesture；
When next interactive gesture is matched with the prearranged gesture, at least based on one or more of tasks, really
The current context of the fixed computing device, the task includes task or the institute previously performed at the computing device
The Future direction that will be performed at the computing device of prediction；
Based on identified context, one or more other software applications are recognized；And
Display represents the other users interface element of the other software application, wherein, the other users interface element energy quilt
Select to instantiate the corresponding other software application.
10. machine readable media as claimed in claim 8, wherein, the interactive gesture is included from the computing device
Touch-screen display on first point of continuous cunning of touch for starting to terminate at the second point on the touch-screen display
Start gesture.
11. machine readable media as claimed in claim 10, further comprises the instruction wherein stored, the instruction is when by institute
When stating computing device so that the computing device operation, the operation includes：
When receiving the continuously slipping gesture, the display of the user interface element is initiated；
Recognize the particular user interface element shown at the second point on the touch-screen display；And
The instantiation software application associated with the particular user interface element.
12. machine readable media as claimed in claim 8, further comprises the instruction wherein stored, the instruction is when by institute
When stating computing device so that the computing device operation, the operation includes：
Recognize the second interactive gesture received during or after the described first interactive gesture is received；
Independently determine whether the described second interactive gesture matches with another prearranged gesture with the described first interactive gesture；
When the described second interactive gesture is matched with another prearranged gesture,
Based on identified context, the one or more actions that can be performed at the computing device are recognized；And
Combination based on the described second interactive gesture or the first interactive gesture and the second interactive gesture, is performed
The one or more actions recognized.
13. machine readable media as claimed in claim 8, wherein, the Future direction predicted is based on pre- relative to described
The time of survey is occurred to calculate described as one or more nearest tasks performed by the user, the time of the prediction
When the current context of equipment is determined.
14. machine readable media as claimed in claim 8, further comprises the instruction wherein stored, the instruction is when by institute
When stating computing device so that the computing device operation, the operation includes：
It is that identification user does not interact previously via the computing device or accessed as service via the computing device
Software application or software service；And
Using one or more of user interface elements, display represents the user interface element of the software application.
15. a kind of system, including：
Memory including instruction；And
Processor, the processor be configured as performing the instruction with：
Interactive gesture is received at computing device；
When the interactive gesture is matched with prearranged gesture, at least based on one or more tasks, the computing device is determined
Current context, the task includes previous being performed at the computing device for task or being calculated described of being predicted
The Future direction performed at equipment；
Based on identified context, identification performs one or more software applications of one or more of tasks, the software
Using the application terminated or uninstalled application including performing one or more of tasks；And
Display can be selected to instantiate one or more user interface elements of recognized software application.
16. system as claimed in claim 15, wherein, the processor be further configured to perform the instruction with：
Receive next interactive gesture；
When next interactive gesture is matched with the prearranged gesture, at least based on one or more of tasks, really
The current context of the fixed computing device, the task includes task or the institute previously performed at the computing device
The Future direction that will be performed at the computing device of prediction；
Based on identified context, one or more other software applications are recognized；And
Display represents the other users interface element of the other software application, wherein, the other users interface element energy quilt
Select to instantiate the corresponding other software application.
17. system as claimed in claim 16, wherein, the interactive gesture is to include the touch-screen from the computing device
First point on the display continuously slipping gesture of touch that starts to terminate at the second point on the touch-screen display.
18. system as claimed in claim 15, further comprises the instruction wherein stored, the instruction is when by the processor
During execution so that the computing device operation, the operation includes：
When receiving the continuously slipping gesture, the display of the user interface element is initiated；
Recognize the particular user interface element shown at the second point on the touch-screen display；And
The instantiation software application associated with the particular user interface element.
19. system as claimed in claim 15, further comprises the instruction wherein stored, the instruction is when by the processor
During execution so that the computing device operation, the operation includes：
Recognize the second interactive gesture received during or after the described first interactive gesture is received；
Independently determine whether the described second interactive gesture matches with another prearranged gesture with the described first interactive gesture；
When the described second interactive gesture is matched with another prearranged gesture,
Based on identified context, the one or more actions that can be performed at the computing device are recognized；And
Combination based on the described second interactive gesture or the first interactive gesture and the second interactive gesture, is performed
The one or more actions recognized.
20. system as claimed in claim 15, wherein, the Future direction predicted is the time based on relative to the prediction
As one or more nearest tasks performed by the user, the institute in the computing device occurs for the time of the prediction
When stating current context and being determined.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/561,163 US20160162148A1 (en) | 2014-12-04 | 2014-12-04 | Application launching and switching interface |
US14/561,163 | 2014-12-04 | ||
PCT/US2015/063525 WO2016090042A1 (en) | 2014-12-04 | 2015-12-02 | Application launching and switching interface |
Publications (1)
Publication Number | Publication Date |
---|---|
CN107077287A true CN107077287A (en) | 2017-08-18 |
Family
ID=56092413
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201580035882.8A Pending CN107077287A (en) | 2014-12-04 | 2015-12-02 | Start the application with interface switching |
Country Status (6)
Country | Link |
---|---|
US (1) | US20160162148A1 (en) |
EP (1) | EP3227777B1 (en) |
CN (1) | CN107077287A (en) |
DE (1) | DE112015004111T5 (en) |
GB (1) | GB2549358B (en) |
WO (1) | WO2016090042A1 (en) |
Cited By (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN110574057A (en) * | 2017-12-20 | 2019-12-13 | 谷歌有限责任公司 | Suggesting actions based on machine learning |
CN114008590A (en) * | 2019-10-01 | 2022-02-01 | 谷歌有限责任公司 | Providing auxiliary user interface using execution blocks |
Families Citing this family (17)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10453325B2 (en) | 2015-06-01 | 2019-10-22 | Apple Inc. | Creation of reminders using activity state of an application |
US10552218B2 (en) * | 2017-01-06 | 2020-02-04 | Microsoft Technology Licensing, Llc | Dynamic context of tasks |
US10979235B2 (en) | 2017-10-20 | 2021-04-13 | Dropbox, Inc. | Content management system supporting third-party code |
US10878019B2 (en) * | 2017-10-20 | 2020-12-29 | Dropbox, Inc. | Hosted storage for third-party services |
US11113411B2 (en) | 2017-10-20 | 2021-09-07 | Dropbox, Inc. | Authentication security model for a content management system |
CN109144260B (en) | 2018-08-24 | 2020-08-18 | 上海商汤智能科技有限公司 | Dynamic motion detection method, dynamic motion control method and device |
JP6765545B2 (en) | 2017-12-22 | 2020-10-07 | ベイジン センスタイム テクノロジー デベロップメント カンパニー， リミテッド | Dynamic gesture recognition method and device, gesture dialogue control method and device |
WO2019143187A1 (en) * | 2018-01-18 | 2019-07-25 | Samsung Electronics Co., Ltd. | Method and system of context-based visual cue management for content |
CN108595228B (en) | 2018-05-10 | 2021-03-12 | Oppo广东移动通信有限公司 | Application program prediction model establishing method and device, storage medium and mobile terminal |
CN108595227A (en) | 2018-05-10 | 2018-09-28 | Oppo广东移动通信有限公司 | Application program preloads method, apparatus, storage medium and mobile terminal |
CN108710513B (en) | 2018-05-15 | 2020-07-21 | Oppo广东移动通信有限公司 | Application program starting method and device, storage medium and terminal |
CN108829457B (en) * | 2018-05-29 | 2020-09-29 | Oppo广东移动通信有限公司 | Application program prediction model updating method and device, storage medium and terminal |
CN108804157A (en) | 2018-06-05 | 2018-11-13 | Oppo广东移动通信有限公司 | Application program preloads method, apparatus, storage medium and terminal |
US11099706B1 (en) * | 2020-06-30 | 2021-08-24 | Dell Products L.P. | Enhanced user interface using touch gestures |
US11544684B2 (en) | 2020-07-30 | 2023-01-03 | Block, Inc. | Embedded applications |
US20220038570A1 (en) * | 2020-07-30 | 2022-02-03 | Square, Inc. | Integrating customer and/or merchant functionality with discoverable applications |
EP4178232A1 (en) * | 2021-11-04 | 2023-05-10 | Abb Schweiz Ag | Managing the operation of applications on mobile computing devices |
Citations (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20070067373A1 (en) * | 2003-11-03 | 2007-03-22 | Steven Higgins | Methods and apparatuses to provide mobile applications |
US20100318576A1 (en) * | 2009-06-10 | 2010-12-16 | Samsung Electronics Co., Ltd. | Apparatus and method for providing goal predictive interface |
US20120084292A1 (en) * | 2010-09-15 | 2012-04-05 | Jisheng Liang | Recommending mobile device activities |
US20120304132A1 (en) * | 2011-05-27 | 2012-11-29 | Chaitanya Dev Sareen | Switching back to a previously-interacted-with application |
CN103109249A (en) * | 2010-09-06 | 2013-05-15 | 三星电子株式会社 | Method of operating mobile device by recognizing user's gesture and mobile device using the method |
US20130254705A1 (en) * | 2012-03-20 | 2013-09-26 | Wimm Labs, Inc. | Multi-axis user interface for a touch-screen enabled wearable device |
US20140250433A1 (en) * | 2013-02-11 | 2014-09-04 | Google Inc. | Managing applications on a client device |
Family Cites Families (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20110307354A1 (en) * | 2010-06-09 | 2011-12-15 | Bilgehan Erman | Method and apparatus for recommending applications to mobile users |
US20120072283A1 (en) * | 2010-09-16 | 2012-03-22 | Mobilmeme, Inc. | Mobile application recommendation system and method |
US9781540B2 (en) * | 2011-07-07 | 2017-10-03 | Qualcomm Incorporated | Application relevance determination based on social context |
US9020925B2 (en) * | 2012-01-04 | 2015-04-28 | Trustgo Mobile, Inc. | Application certification and search system |
US20130326499A1 (en) * | 2012-05-31 | 2013-12-05 | Microsoft Corporation | Automatically installing and removing recommended applications |
US9806942B2 (en) * | 2013-12-02 | 2017-10-31 | Yahoo Holdings, Inc. | Deep linking to mobile applications |
-
2014
- 2014-12-04 US US14/561,163 patent/US20160162148A1/en not_active Abandoned
-
2015
- 2015-12-02 CN CN201580035882.8A patent/CN107077287A/en active Pending
- 2015-12-02 DE DE112015004111.7T patent/DE112015004111T5/en active Pending
- 2015-12-02 GB GB1621534.5A patent/GB2549358B/en active Active
- 2015-12-02 EP EP15865461.6A patent/EP3227777B1/en active Active
- 2015-12-02 WO PCT/US2015/063525 patent/WO2016090042A1/en active Application Filing
Patent Citations (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20070067373A1 (en) * | 2003-11-03 | 2007-03-22 | Steven Higgins | Methods and apparatuses to provide mobile applications |
US20100318576A1 (en) * | 2009-06-10 | 2010-12-16 | Samsung Electronics Co., Ltd. | Apparatus and method for providing goal predictive interface |
CN103109249A (en) * | 2010-09-06 | 2013-05-15 | 三星电子株式会社 | Method of operating mobile device by recognizing user's gesture and mobile device using the method |
US20120084292A1 (en) * | 2010-09-15 | 2012-04-05 | Jisheng Liang | Recommending mobile device activities |
US20120304132A1 (en) * | 2011-05-27 | 2012-11-29 | Chaitanya Dev Sareen | Switching back to a previously-interacted-with application |
US20130254705A1 (en) * | 2012-03-20 | 2013-09-26 | Wimm Labs, Inc. | Multi-axis user interface for a touch-screen enabled wearable device |
US20140250433A1 (en) * | 2013-02-11 | 2014-09-04 | Google Inc. | Managing applications on a client device |
Cited By (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN110574057A (en) * | 2017-12-20 | 2019-12-13 | 谷歌有限责任公司 | Suggesting actions based on machine learning |
CN110574057B (en) * | 2017-12-20 | 2023-10-31 | 谷歌有限责任公司 | Suggesting actions based on machine learning |
CN114008590A (en) * | 2019-10-01 | 2022-02-01 | 谷歌有限责任公司 | Providing auxiliary user interface using execution blocks |
CN114008590B (en) * | 2019-10-01 | 2024-04-09 | 谷歌有限责任公司 | Providing an auxiliary user interface using execution blocks |
Also Published As
Publication number | Publication date |
---|---|
EP3227777A1 (en) | 2017-10-11 |
GB2549358A (en) | 2017-10-18 |
DE112015004111T5 (en) | 2017-06-14 |
WO2016090042A1 (en) | 2016-06-09 |
GB2549358B (en) | 2021-11-10 |
EP3227777B1 (en) | 2022-02-02 |
GB201621534D0 (en) | 2017-02-01 |
EP3227777A4 (en) | 2018-08-01 |
US20160162148A1 (en) | 2016-06-09 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN107077287A (en) | Start the application with interface switching | |
US10762299B1 (en) | Conversational understanding | |
US10949748B2 (en) | Deep learning of bots through examples and experience | |
US9865264B2 (en) | Selective speech recognition for chat and digital personal assistant systems | |
CN105701214B (en) | Preload the mobile Web browser of webpage | |
CN104981774B (en) | Method and system for background control panel configuration selection | |
CN104081382B (en) | Establish the method and system for the user interface that can dynamically specify | |
US20160117082A1 (en) | Integrated task launcher user interface | |
US20160140215A1 (en) | External action suggestions in search results | |
CN104838632A (en) | Method and system for transferable customized contextual user interfaces | |
CN106537349A (en) | Multi-purpose application launching interface | |
CN104321768A (en) | Method and system for executing an application for consulting content and services accessible by browsing a telecommunications network | |
CN109076107A (en) | It is customized based on detection and the automatic detection and optimization of user experience upgrading is provided | |
US10261968B2 (en) | Method and apparatus for navigational searching of a website | |
US9069864B2 (en) | Prioritizing a content item for a user | |
WO2012158571A2 (en) | Training statistical dialog managers in spoken dialog systems with web data | |
EP3942490A1 (en) | Enhanced task management feature for electronic applications | |
CN106663246A (en) | Systems and methods for biasing task assistance auto-complete suggestions | |
CN111984355A (en) | Method and device for realizing man-machine multi-turn conversation | |
CN105531661B (en) | Full screen content checks that interface enters | |
Machiraju et al. | Conversations as platforms | |
US11775261B2 (en) | Dynamic process model palette | |
US9176948B2 (en) | Client/server-based statistical phrase distribution display and associated text entry technique | |
US11455555B1 (en) | Methods, mediums, and systems for training a model | |
EP4348524A1 (en) | Apparatus and method for suggesting user-relevant digital content using edge computing |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
CB02 | Change of applicant information |
Address after: American CaliforniaApplicant after: Google limited liability companyAddress before: American CaliforniaApplicant before: Google Inc. |
|
CB02 | Change of applicant information |