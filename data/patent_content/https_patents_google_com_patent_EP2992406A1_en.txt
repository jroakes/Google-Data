EP2992406A1 - Alternative hypothesis error correction for gesture typing - Google Patents
Alternative hypothesis error correction for gesture typingInfo
- Publication number
- EP2992406A1 EP2992406A1 EP14731439.7A EP14731439A EP2992406A1 EP 2992406 A1 EP2992406 A1 EP 2992406A1 EP 14731439 A EP14731439 A EP 14731439A EP 2992406 A1 EP2992406 A1 EP 2992406A1
- Authority
- EP
- European Patent Office
- Prior art keywords
- computing device
- alternative
- gesture
- word
- character
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
- 238000012937 correction Methods 0.000 title claims description 197
- 238000000034 method Methods 0.000 claims abstract description 158
- 230000017105 transposition Effects 0.000 claims description 42
- 238000006467 substitution reaction Methods 0.000 claims description 21
- 230000004044 response Effects 0.000 description 66
- 238000004891 communication Methods 0.000 description 57
- 230000008901 benefit Effects 0.000 description 21
- 238000010586 diagram Methods 0.000 description 18
- 230000015654 memory Effects 0.000 description 15
- 230000000007 visual effect Effects 0.000 description 15
- 238000003780 insertion Methods 0.000 description 12
- 230000037431 insertion Effects 0.000 description 12
- 230000003287 optical effect Effects 0.000 description 11
- 238000012217 deletion Methods 0.000 description 7
- 230000037430 deletion Effects 0.000 description 7
- 230000006870 function Effects 0.000 description 6
- 238000012545 processing Methods 0.000 description 5
- 238000010079 rubber tapping Methods 0.000 description 5
- 238000005516 engineering process Methods 0.000 description 4
- 230000001939 inductive effect Effects 0.000 description 4
- 230000009471 action Effects 0.000 description 3
- 238000013500 data storage Methods 0.000 description 3
- 239000004973 liquid crystal related substance Substances 0.000 description 3
- 238000004590 computer program Methods 0.000 description 2
- 230000001419 dependent effect Effects 0.000 description 2
- 239000000835 fiber Substances 0.000 description 2
- 230000007774 longterm Effects 0.000 description 2
- 238000004806 packaging method and process Methods 0.000 description 2
- 230000001052 transient effect Effects 0.000 description 2
- 238000003491 array Methods 0.000 description 1
- 230000001413 cellular effect Effects 0.000 description 1
- 230000008859 change Effects 0.000 description 1
- 238000001514 detection method Methods 0.000 description 1
- DWRKFAJEBUWTQM-UHFFFAOYSA-N etaconazole Chemical compound O1C(CC)COC1(C=1C(=CC(Cl)=CC=1)Cl)CN1N=CN=C1 DWRKFAJEBUWTQM-UHFFFAOYSA-N 0.000 description 1
- 238000013507 mapping Methods 0.000 description 1
- 239000011159 matrix material Substances 0.000 description 1
- 239000000203 mixture Substances 0.000 description 1
- 230000000704 physical effect Effects 0.000 description 1
- 239000010454 slate Substances 0.000 description 1
- 230000003068 static effect Effects 0.000 description 1
- 238000010897 surface acoustic wave method Methods 0.000 description 1
- 208000006379 syphilis Diseases 0.000 description 1
- 238000012546 transfer Methods 0.000 description 1
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0487—Interaction techniques based on graphical user interfaces [GUI] using specific features provided by the input device, e.g. functions controlled by the rotation of a mouse with dual sensing arrangements, or of the nature of the input device, e.g. tap gestures based on pressure sensed by a digitiser
- G06F3/0488—Interaction techniques based on graphical user interfaces [GUI] using specific features provided by the input device, e.g. functions controlled by the rotation of a mouse with dual sensing arrangements, or of the nature of the input device, e.g. tap gestures based on pressure sensed by a digitiser using a touch-screen or digitiser, e.g. input of commands through traced gestures
- G06F3/04886—Interaction techniques based on graphical user interfaces [GUI] using specific features provided by the input device, e.g. functions controlled by the rotation of a mouse with dual sensing arrangements, or of the nature of the input device, e.g. tap gestures based on pressure sensed by a digitiser using a touch-screen or digitiser, e.g. input of commands through traced gestures by partitioning the display area of the touch-screen or the surface of the digitising tablet into independently controllable areas, e.g. virtual keyboards or menus
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/02—Input arrangements using manually operated switches, e.g. using keyboards or dials
- G06F3/023—Arrangements for converting discrete items of information into a coded form, e.g. arrangements for interpreting keyboard generated codes as alphanumeric codes, operand codes or instruction codes
- G06F3/0233—Character input methods
- G06F3/0237—Character input methods using prediction or retrieval techniques
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0487—Interaction techniques based on graphical user interfaces [GUI] using specific features provided by the input device, e.g. functions controlled by the rotation of a mouse with dual sensing arrangements, or of the nature of the input device, e.g. tap gestures based on pressure sensed by a digitiser
- G06F3/0488—Interaction techniques based on graphical user interfaces [GUI] using specific features provided by the input device, e.g. functions controlled by the rotation of a mouse with dual sensing arrangements, or of the nature of the input device, e.g. tap gestures based on pressure sensed by a digitiser using a touch-screen or digitiser, e.g. input of commands through traced gestures
- G06F3/04883—Interaction techniques based on graphical user interfaces [GUI] using specific features provided by the input device, e.g. functions controlled by the rotation of a mouse with dual sensing arrangements, or of the nature of the input device, e.g. tap gestures based on pressure sensed by a digitiser using a touch-screen or digitiser, e.g. input of commands through traced gestures for inputting data by handwriting, e.g. gesture or text
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0487—Interaction techniques based on graphical user interfaces [GUI] using specific features provided by the input device, e.g. functions controlled by the rotation of a mouse with dual sensing arrangements, or of the nature of the input device, e.g. tap gestures based on pressure sensed by a digitiser
- G06F3/0489—Interaction techniques based on graphical user interfaces [GUI] using specific features provided by the input device, e.g. functions controlled by the rotation of a mouse with dual sensing arrangements, or of the nature of the input device, e.g. tap gestures based on pressure sensed by a digitiser using dedicated keyboard keys or combinations thereof
- G06F3/04897—Special input arrangements or commands for improving display capability
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/20—Natural language analysis
- G06F40/232—Orthographic correction, e.g. spell checking or vowelisation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/20—Natural language analysis
- G06F40/274—Converting codes to words; Guess-ahead of partial word inputs
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/02—Input arrangements using manually operated switches, e.g. using keyboards or dials
- G06F3/023—Arrangements for converting discrete items of information into a coded form, e.g. arrangements for interpreting keyboard generated codes as alphanumeric codes, operand codes or instruction codes
- G06F3/0233—Character input methods
- G06F3/0236—Character input methods using selection techniques to select from displayed items
-
- Y—GENERAL TAGGING OF NEW TECHNOLOGICAL DEVELOPMENTS; GENERAL TAGGING OF CROSS-SECTIONAL TECHNOLOGIES SPANNING OVER SEVERAL SECTIONS OF THE IPC; TECHNICAL SUBJECTS COVERED BY FORMER USPC CROSS-REFERENCE ART COLLECTIONS [XRACs] AND DIGESTS
- Y10—TECHNICAL SUBJECTS COVERED BY FORMER USPC
- Y10S—TECHNICAL SUBJECTS COVERED BY FORMER USPC CROSS-REFERENCE ART COLLECTIONS [XRACs] AND DIGESTS
- Y10S707/00—Data processing: database and file management or data structures
- Y10S707/99931—Database or file accessing
- Y10S707/99933—Query processing, i.e. searching
- Y10S707/99935—Query augmenting and refining, e.g. inexact access
-
- Y—GENERAL TAGGING OF NEW TECHNOLOGICAL DEVELOPMENTS; GENERAL TAGGING OF CROSS-SECTIONAL TECHNOLOGIES SPANNING OVER SEVERAL SECTIONS OF THE IPC; TECHNICAL SUBJECTS COVERED BY FORMER USPC CROSS-REFERENCE ART COLLECTIONS [XRACs] AND DIGESTS
- Y10—TECHNICAL SUBJECTS COVERED BY FORMER USPC
- Y10S—TECHNICAL SUBJECTS COVERED BY FORMER USPC CROSS-REFERENCE ART COLLECTIONS [XRACs] AND DIGESTS
- Y10S707/00—Data processing: database and file management or data structures
- Y10S707/99931—Database or file accessing
- Y10S707/99933—Query processing, i.e. searching
- Y10S707/99936—Pattern matching access
Definitions
- Some computing devices provide a graphical keyboard as part of a graphical user interface for composing text (e.g., using a presence- sensitive input device and/or display, such as a touchscreen).
- the graphical keyboard may enabl e a user of the computing device to enter text (e.g., an e-mail, a text message, or a document, etc.).
- a presence-sensitive display of a computing device may output a graphical (or "soft") keyboard that enables the user to enter data by indicating (e.g., by tapping) keys displayed at the presence-sensitive display.
- the computing device may present a continuous-gesture graphical keyboard (sometimes referred to as a "gesture keyboard” or “combo gesture keyboard”) with which a user can interact by sliding his or her finger over regions of the presence-sensitive display that are associated with keys of the graphical keyboard, thereby essentially gesturing a word to be input to the computing device.
- a continuous-gesture graphical keyboard sometimes referred to as a "gesture keyboard” or “combo gesture keyboard”
- continuous-gesture graphical keyboards provide an input method that allows the user to enter a word or group of words with a gesture.
- a continuous-gesture graphical keyboard may allow the user to achieve a certain degree of efficiency, especially compared to one-handed tapping of a presence-sensitive screen (e.g., a presence-sensitive screen operatively coupled to or integrated with a computing device).
- a presence-sensitive screen e.g., a presence-sensitive screen operatively coupled to or integrated with a computing device.
- a computing device that provides a gesture keyboard may rely on word prediction, auto-correction, and/or suggestion techniques for determining a word from a gesture input. These techniques may speed up text entry and minimize spelling mistakes of in-vocabulary character strings (e.g., words in a dictionar ''). However, one or more of the techniques may have certain drawbacks. For instance, in some examples, a computing device that provides a gesture keyboard and relies on one or more of the techniques may not correctly determine the word intended by a user based upon the gesture input entered at the presence-sensitive screen. As such, a user may need to perform additional effort to enter words using a gesture input,
- a method may include outputting, by a computing device and for display a graphical keyboard comprising a plurality of keys.
- the method may include receiving, by the computing device, an indication of a gesture detected at a presence-sensitive input device.
- the method may include determining, by the computing device, an alignment score that is based at least in part on a word prefix and an alignment point traversed by the gesture, wherein the alignment score represents a probability that the alignment point indicates a key of the plurality of keys.
- the method may include determining, by the computing device, at least one alternative character that is based at least in part on a misspelling that includes at least a portion of the word prefix.
- the method may include determining, by the computing device, an alternative alignment score that is based at least in part on the alternative character.
- the method may include outputting, by the computing device for display, and based at least in part on the alternative alignment score, a candidate w r ord.
- a computer-readable storage medium may be encoded with instructions that, when executed, cause at least one processor to: output for display, a graphical keyboard comprising a plurality of keys.
- the computer-readable storage medium may be encoded with instructions that, when executed, cause at least one processor to: receive an indication of a gesture detected at a presence- sensitive input device.
- the computer-readable storage medium may be encoded with instructi ns that, when executed, cause at least one processor to determine an alignment score that is based at least in part on a word prefix and an alignment point traversed by the gesture, wherein the alignment score represents a probability that the alignment point indicates a key of the plurality of keys.
- the computer- readable storage medium may be encoded with instructions that, when executed, cause at least one processor to determine at least one alternative character that is based at least in part on a misspelling thai includes at least a portion of the word prefix.
- the computer-readable storage medium may be encoded with instructions thai, when executed, cause at least one processor to determine an alternative alignment score that is based at least in part on the alternative character.
- the computer-readable storage medium may be encoded with instructions that, when executed, cause at least one processor to output for display, and based at least in part on the alternative alignment score, a candidate word based at least in part on the alternative character.
- a computing device may include at least one processor, wherein the at least one processor is configured to output for display a graphical keyboard comprising a plurality of keys.
- the at least one processor may be configured to receive an indication of a gesture detected at a presence-sensitive input device.
- the at least one processor may be configured to determine an alignment score that is based at least in part on a word prefix and an alignment point traversed by the gesture, wherein the alignment score represents a probability that the alignment point indicates a key of the plurality of keys.
- the at least one processor may be configured to, responsive to determining that the alignment score fails to satisfy a threshold, determining, by the computing device, at least one alternative word prefsx.
- the at least one processor may be configured to determine an alternative alignment score that is based at least in part on the at least one alternative word prefix.
- the at least one processor may be configured to output for display, and based at least in part on the alternative alignment score, a. candidate word.
- FIG. 1 is a conceptual diagram illustrating an example computing device that is used to perform error correction of input using gesture-based input, in accordance with techniques of the disclosure.
- FIG. 2 is a block diagram illustrating an example computing device, in accordance with one or more aspects of the present disclosure.
- FIG. 3 is a block diagram illustrating an example computing device that outpuis graphical content for dispiay at a remote device, in accordance with one or more techniques of the present disclosure.
- FIGS. 4A-4C are block diagrams illustrating further details of one example of a computing device shown in FIG. i that is used to perform substitution error correction for gesture-based input, in accordance with one or more techniques of the present disclosure.
- FIGS. 5A---5C are block diagrams illustrating further details of one example of a computing device shown in FIG. 1 ihai is used to perform deletion error correction for gesture-based input, in accordance with one or more techniques of the present disclosure.
- FIGS. 6A--6C are block diagrams illustrating further details of one example of a computing de vice shown in FIG. 1 that is used to perform insertion error correction for gesture-based input, in accordance with one or more techniques of the present disclosure.
- FIGS. 7A-7C are block diagrams illustrating further details of one example of a computing device shown in FIG. 1 that is used to perform transposition error correction for gesture -based input, in accordance with one or more techniques of the present disclosure.
- FIG. 8 is a flowchart illustrating example operations of a computing device configured to perform error correction of input using gesture-based input, in accordance with techniques of the disclosure.
- FIG. 9 is a flowchart illustrating example operations of a computing de vice configured to perform error correction of input using gesture-based input, in accordance with techniques of the disclosure.
- FIG. 10 is a flowchart illustrating example operations of a computing de vice configured to perform error correction of input using gesture-based input, in accordance with techniques of the disclosure.
- a computing device that outputs a graphical keyboard for display may receive indications of gestures detected at the presence-sensitive screen. For instance, a continuous (e.g., non-tap) gesture that traverses locations of a presence-sensitive screen associated with mul tiple keys of the graphical keyboard may indicate a selection of one or more of the keys.
- the computing device may receive input associated with one or more gestures at or near the presence-sensitive screen that is indicative of one or more character strings that include one or more characters.
- Such character strings may be included in a lexicon (e.g., words of a dictionary) and represent a word in a. vocabulary of a. language or a portion of the word in the vocabulary.
- the gesture may traverse group of keys that correspond to the characters included in the character string.
- the gesture may not traverse through a group of keys that respectively corresponds to a character string that is included in a lexicon.
- the user may have provided an erroneous continuous gesture that does not correspond to keys that represent a character string intended as input by the user.
- a user may erroneously perform a continuous gesture that traverses the keys T-R-U-E-L-Y of the graphical keyboard although the user desired to input the character string "truly.”
- techniques of the disclosure may generate at least one alternative hypothesis that is based upon an autocorrected spelling of the character string "truly” that, in this example, the user intended.
- the techniques described in this disclosure may impro ve the accuracy with which a computing device determines a candidate word using auto-correction in response to an erroneous selection of keys.
- techniques of the disclosure may improve the accuracy of word predictions for a variety of types of spelling errors, including but not limited to: substitution errors ("cemetary” “cemetery”), deletion errors ("Farenheit” -> “Fahrenheit”), insertion errors ("truely” - “truly”), and transposition errors (“wierd” -> "weird”).
- a computing device implementing techniques of the disclosure may incrementally determine different groups of key s of the graphical keyboard that are traversed by the gesture path of a gesture.
- the incremental determinations may include searching for one or more points of a gesture that align with a given keyboard position of a key that corresponds to a given letter.
- Each different group of keys may correspond to a respective group of characters that, collectively, represents a character string.
- Each character string may he a hypothesis, for example, a prefix of one or more words included in a lexicon.
- a computing device may determine alternative hypotheses, e.g., prefixes of one or more words thai include characters based on misspellings of characters, combinations of characters, and/or words in a lexicon. That is, if a gesture path is not well-aligned to one or more keys that correspond to a word in the lexicon (e.g., the user erroneously gestured an incorrect spelling of an intended word), the computing device may determine alternative hypotheses based on the misspellings. The alternative hypotheses that indicate higher probabilities for certain words in the lexicon that include the characters of the alternative hypotheses. Techniques of the disclosure may therefore relax constraints on continuous gesture input that would otherwise require a gesture path to match every key corresponding to every character of an intended word. Consequently, a computing device implementing techniques of the disclosure may more accurately output words the user intended.
- alternative hypotheses e.g., prefixes of one or more words thai include characters based on misspellings of characters, combinations
- FIG. 1 is a conceptual diagram illustrating an example computing device that is used to perform error correction of input using gesture-based input, in accordance with techniques of the disclosure.
- computing device 10 may be a mobile phone.
- computing device 10 may be a tablet computer, a personal digital assistant (PDA), a laptop computer, a portable gaming device, a portable media player, an e-book reader, a watch, television platform, or another type of computing device.
- PDA personal digital assistant
- computing device 10 includes a user interface device (UID) 12.
- UID 12 of computing device 10 may function as an input device for computing device 10 and as an output device.
- UID 12 may be implemented using various technologies.
- UID 12. may function as a presence-sensitive input device using a presence-sensitive screen, such as a resistive touchscreen, a surface acoustic wave touchscreen, a capacitive touchscreen, a projective capacitance touchscreen, a pressure sensitive screen, an acoustic pulse recognition touchscreen, or another presence-sensitive screen technology.
- UID 12 may function as an output device using any one or more of a liquid crystal display (LCD), dot matrix display, light emitting diode (LED) display, organic light- emitting diode (OLED) display, e-ink, or similar monochrome or color display capable of outputting visible information to the user of computing device 10.
- LCD liquid crystal display
- LED light emitting diode
- OLED organic light- emitting diode
- e-ink e-ink
- monochrome or color display capable of outputting visible information to the user of computing device 10.
- UID 12 of computing device 10 may include a presence-sensitive screen that may recei v e tactile user input from a user of computing device 10.
- UID 12 may receive indications of the tactile user input by detecting one or more tap and/or non-tap gestures from a user of computing device 10 (e.g., the user touching or pointing to one or more locations of UID 12 with a finger or a stylus pen).
- the presence-sensitive screen of UID 12 may present output to a user.
- UID 12 may present the output as a user interface (e.g., user interface 14) which may be related to functionality provided by computing device 10.
- UID 12 may- present various user interfaces of applications (e.g., an electronic message application, an Internet browser application, etc.) executing at computing device 10.
- applications e.g., an electronic message application, an Internet browser application, etc.
- a user of computing device 10 may interact with one or more of these applications to perform a function with computing device 10 through the respective user interface of each application.
- Computing device 10 may include user interface ("UT") module 20, keyboard module 22, and gesture module 24.
- Modules 20, 22, and 24 may perform operations described using software, hardware, firmware, or a mixture of both hardware, software, and firmware residing in and executing on computing device 10.
- Computing device 10 may execute modules 20, 22, and 24, with multiple processors.
- Computing device 10 may execute modules 20, 22, and 24 as a virtual machine executing on underlying hardware.
- Modules 2.0, 22, and 24 may be implemented in various ways.
- UI module 20 may be implemented as a downloadable or pre-installed application or "app.”
- UI module 20 may be implemented as part of an operating system of computing device 10.
- Gesture module 24 of computing device 10 may receive from UID 12, one or more indications of user input detected at the presence-sensitive screen of UID 12, Generally , each time UID 12 recei v es an indication of user input detected at a location of the presence-sensitive screen, gesture module 24 may receive information about the user input from UID 12. Gesture module 24 may assemble the information receiv ed from UID 12 into a time-ordered set of events indicative of a gesture, such as a sequence of touch events. Each touch event in the sequence may include data or components that represents parameters (e.g., when, where, originating direction) characterizing a presence and or movement of input at the presence-sensitive screen.
- parameters e.g., when, where, originating direction
- Each touch event in the sequence may include a location component corresponding to a location of U ID 12, a time component related to when UID 12 detected user input at the location, and an action component related to whether the touch event corresponds to a lift up or a push down at the location.
- one or more of the events may have a concurrent time component, and such events are described as touch events merely for purposes of example and may be indicative of a gesture at any form of presence- sensitive input device.
- Gesture module 24 may determine one or more characteristics of the user input based on the sequence of touch events and include information about these one or more characteristics within each touch e v ent in the sequence of touch events. For example, gesture module 24 may determine a start location of the user input, an end location of the user input, a density of a portion of the user input, a speed of a portion of the user input, a direction of a portion of the user input, and a curv ature of a portion of the user input.
- One or more touch events in the sequence of touch events may include (in addition to a time, a location, and an action component as described above) a characteristic component that includes information about one or more characteristics of the user input (e.g., a density, a speed, etc.).
- gesture module 24 determines one or more locations of UID 12 that are touched or otherwise detected in response to a user gesture, based on information received from UI module 20.
- gesture module 24 can determine one or more features associated with a gesture, such as the Euclidean distance between two alignment points, the length of a gesture path, the direction of a gesture, the curvature of a gesture path, the shape of the gesture, and maximum curvature of a gesture between alignment points, speed of the gesture, etc.
- Gesture module 24 may transmit, as data to keyboard module 22, the sequence of touch events including the components or parameterized data associated with each touch event.
- UI module 20 may cause UID 12 to present example user interface 14.
- user interface 14 includes graphical elements displayed at various locations of UID 12.
- FIG. 1 illustrates edit region I6A of user interface 14, and graphical keyboard I6B of user interface 14.
- Edit region 16A may include graphical elements such as images, objects, hyperlinks, characters of text, etc.
- Graphical keyboard 16B includes graphical elements displayed as keys.
- User interface 14 includes suggested character string regions 18A - 18C that include selectable spelling corrections or character siring suggestions to replace character strings that are included in edit region 16A,
- edit region 16 may include graphical elements displayed as characters of text (e.g., a character string).
- a user of computing device 10 may enter text in edit region 16A by providing user input at locations of UID 12 that display the keys of graphical keyboard 16B.
- computing device 10 may output one or more suggested character strings in suggested character string regions 18A-18C.
- UI module 20 may act as an intermediary between various components of computing device 10 to make determinations based on input detected by UID 12 and generate output presented by UID 12. For instance, UI module 20 may receive, as an input from keyboard module 22, a representation of a keyboard layout of the keys included in graphical keyboard 16B. UI module 20 may send indications of user input to gesture module 24, which may generate a sequence of touch events generated from information about user input detected by UID 12. Keyboard module 2.2, upon receiving touch events from gesture module 24 may determine, based on the location components in the sequence touch events, that one or more location components approximate a selection of one or more keys. In response, UI module 20 may receive, from keyboard module 22, one or more suggested character strings. UI module 20 may update user interface 14 to include the one or more character strings within edit region I6A and/or character string regions 18A-18C. UI module 20 may cause UID 12 to present the updated user interface 14.
- Keyboard module 22 of computing device 10 may transmit, as data to UI module 20 (for inclusion as graphical keyboard 16B of user interface 14) a keyboard layout including a plurality of keys related to one or more written languages (e.g., English, Spanish, etc). Keyboard module 22 may assign one or more characters or operations to each key of the plurality of keys in the keyboard layout. For instance, keyboard module 22 may generate a QWERTY keyboard layout including keys that represent characters used in typing the English language. The QWERTY keyboard layout may also include keys that represent operations used in typing the English language (e.g., backspace, delete, spacebar, enter, etc.).
- Graphical keyboard 16B may include a plurality of keys, such as "Q" key 32A, "W" key 32B, etc. In some examples, each of the plurality of keys included in graphical keyboard 16 represents a single character. n other examples, one or more of the plurality of keys included in graphical keyboard 16 represents a group of characters selected based on a plurality of modes.
- Computing device 10 may include one or more spatial models, such as spatial model 26, to incrementally determine different selections of one or more keys based on a sequence of touch events.
- spatial model 26 may generate one or more probabilities that a particular key of a graphical keyboard has been selected based on location data associated with a user input.
- spatial model 26 includes a bivariate Gaussian model for each key.
- the bivariate Gaussian model for a key may include a distribution of coordinates (e.g., (x,y) coordinate pairs) that correspond to locations of UID 12 that present the given key.
- a bivariate Gaussian model for a key may include a distribution of coordinates that correspond to locations of UID 12 that are most frequently selected by a user when the user intends to select the given key. The shorter the distance between location data of a user input and a higher density area of spatial model 26, the higher the probability that the key associated with spatial model 26 has been selected. A greater distance between location data of a user input and a higher density area of spatial model 26, the lower the probability that the key associated with spatial model 26 has been selected.
- Keyboard module 22 may use spatial model 2.6 to compare the location components (e.g., coordinates) of one or more touch events in the sequence of touch events to respective locations of one or more keys of graphical keyboard 16B and generate a probability based on these comparisons that a selection of a key occurred.
- keyboard module 22 may generate a spatial score using spatial model 26.
- the spatial score may indicate a probability of a selected key based at least in part on locations of U1D 12 traversed by a gesture.
- a spatial score may indicate a combined probability of a group of selected keys based at least in part on locations of UTD 12 traversed by a gesture.
- keyboard module 22 may use spatial model 26 to compare the location component of one or more touch event in the sequence of touch e vents to a key location of a particular key of graphical keyboard 16B.
- the location componen t of each touch even t in the sequence may include one location of U1D 12
- a key location (e.g., a centroid of a key) of a key in graphical keyboard 16B may include a different location of UID 12.
- Keyboard module 22 may use spatial model 26 to determine a Euclidian distance between the two locations and generate a probability based on the Euclidian distance that the key was selected.
- Spatial model 26 may indicate a.
- keyboard module 22 may assemble the individual key selections with the highest spatial model probabilities into a time- ordered sequence of keys that keyboard module 22 may then determine represents a character string.
- the combined probabilities of each key may represent a spatial score for the character string.
- Computing device 10 includes language model 28.
- Language model 28 may include a lexicon.
- a lexicon may include a listing of words and may include additional information about the listed words.
- a lexicon may be represented by one or more data structures, such as by one or more of an array, a list, a tree, or other data structures. For example,
- I I language model 28 may include a lexicon stored in a trie data structure.
- a lexicon trie data structure may include a plurality of nodes. Each node of the lexicon trie may represent a letter. The first node in a lexicon trie may be considered an entry node, which may not correspond to a letter. In other examples, the entry node may correspond to a letter. Each node may have one or more child nodes. For instance, the entry node may have twent -six child nodes, each corresponding to a letter of the English alphabet.
- a subset of the nodes in a lexicon trie may each include a flag which indicates that the node is a terminal node.
- Each terminal node of a lexicon trie may indicate a complete word (e.g., a candidate word) included in the lexicon.
- the letters indicated by the nodes along a path of nodes from the entry node to a terminal node may spell out a word indicated by the terminal node.
- language model 28 may be based on a default dictionary installed on computing device 10.
- language model 28 may include a group of predefined phrases installed on computing device 10.
- language model 28 may include multiple sources of lexicons, which may be stored at computing device 2 or stored at one or more remote computing devices that are accessible to computing device 2 via one or more communication channels.
- language model 28 may be implemented in the firmware of computing device 10.
- Language model 28 may include language model frequency information such as n-gram language models.
- An n-gram language model may provide a probability distribution for an item x; (letter, word, punctuation character or other delimiter) in a contiguous sequence of items based on the previous items in the sequence (i.e., Pfe j xun-ij, ⁇ . ,3 ⁇ 4-;)).
- a bigram language model an n-gram model where n ⁇ 2
- a trigram language model may provide a probability that a delimiter character (e.g., a comma delimiter character, a period delimiter character, a semicolon delimiter character) is positioned between a first character string and a second character string.
- a trigram language model may provide a probability that a comma delimiter character is positioned between a first character siring "example” and a second character string "the.”
- language model 28 includes a lexicon trie with integrated language model frequency information. For instance, each node of the lexicon trie may include a representation of a letter and a probability value.
- Keyboard module 22 may access language model 28 of computing device 10 to incrementally determine language scores for a group of one or more character strings based on sequences of keys corresponding to a gesture.
- the character strings may be prefixes of words modeled in language model 28.
- keyboard module 2.2. may incrementally determine spatial and language scores corresponding to the prefixes.
- keyboard module 22 may determine a combined score (e.g., an alignment score) for each character siring based on the spatial and language score for each respective character string.
- Keyboard module 22 may update the spatial, language, and/or alignment scores incrementally as keyboard module 22. determines subsequent indications of gestures. Keyboard module 22.
- keyboard module 22 may rank the prefixes by their respective alignment scores as further described in this disclosure. Keyboard module 22 may then output character strings, words, phrases, etc., based on the prefixes. Keyboard module 22 may search or "look ahead" to determine one or more words in language model 28 that correspond respectively to a prefix. For instance, given a character string t-r-u, keyboard module 22 may determine, using language model 28 the probability of a character string truly. Keyboard module 22 may determine a language score based on the probability. In this way, character strings in language model 28 having higher probabilities in a given language context may have higher language scores. [ ⁇ 838] In some examples, keyboard module 22 determines an alignment score for each prefix based at least in part on the respective spatial and language module scores for each respective character string.
- the alignment, score for a character string may therefore represent the probability of the character string.
- Keyboard module 22 may order each character siring in a group of character strings by alignment score in descending order from most probable character string to least probable character string.
- keyboard module 22 may determine one or more words based on the one or more prefixes with the highest probabilities.
- UID 12 may output such character strings as suggested character strings in suggested character string regions 18A-18C.
- one or more candidate character strings with the highest probabilities may be output at edit region 16A.
- computing device 10 may incrementally receive indications of user input that indicate an erroneous gesture input. That is, the gesture path may not align well with words in language model 28. Rather than outputting less probable words from a lexicon based on one or more incorrect keys indicated by the gesture, techniques of the present disclosure may improve word determination and/or prediction based on continuous gesture input by determining alternative hypotheses incrementally using correction data. For instance, each token as described herein may represent a word prefix for the gesture - e.g., the token "w-?" may represents the hypothesis that the gestures starts with the letter ' V", though the remaining letters have not been recognized yet.
- a computing device implementing techniques of the disclosure may advance the token to consider the possible next letter of the word (e.g.. “w-e-?", "VIM-?”, etc.), in response to receiving further indications of ges ture input.
- the computing device may compare each of the possible next letters to the gesture path to determine whether the gesture actually passes through these possible next letters.
- the techniques may consider different edits or hypothesis at one or more character positions of a word prefix to generate possible word candidates.
- a gesture path does not match a given word prefix (e.g., a probability of a match does not satisfy a threshold)
- the techniques may consider one or more alternat ve hypotheses that are due to a spelling/edit error in the intended word. Therefore, the techniques may, for example, allow a computing device to align a w-i-? gesture to a w-e-? word candidate, although the gesture does not pass through or even near to the letter "e".
- Such techniques may relax constraints on continuous gesture input that would otherwise require a gesture path to match every character of an intended word.
- techniques of the disclosure may provide for improved word prediction and therefore an improved user experience when entering input,
- computing device 10 outputs for display graphical keyboard 16B comprising a plurality of keys.
- keyboard module 22 may generate data ihai includes a representation of graphical keyboard 16B.
- UI module 20 may generate user interface 14 and include graphical keyboard 16B in user interface 14 based on the data representing graphical keyboard 16B.
- UI module 20 may send information to UID 12 that includes instructions for displaying user interface 14 at a presence-sensitive screen of UID 12, UID 12 may receive the information and cause the presence-sensitive screen of UID 12 to present user interface 14 including edit region 16 A, graphical keyboard 16B, and suggested character string regions 18A-18C.
- Graphical keyboard 16B may include a plurality of keys.
- Keyboard module 22 may incrementally determine a group of keys indicated by a gesture, as a user performs the gesture. For instance, keyboard module 22 may receive one or more indications of a gesture that are detected at UID 12.
- the gesture may be a continuous motion gesture that includes a motion of an input unit (e.g., a finger, pen, stylus, etc.) from a first location of UID 12. to a second location of UID 12 such that the gesture performed from the first location to the second location is detected by UID 12 throughout the performance of the gesture.
- the gesture may include a motion of an input unit from the first location to the second location with substantially constant contact betwee the input unit and UID 12.
- UID 12 may detect a gesture including gesture path 34 provided by a finger of a user from a location of UID 12 that displays "B" key 32C to a location of UID 12 that display s "E" key 32D along gesture path 2.2 such that UID 12 detects the finger throughout gesture path 34.
- the gesture corresponding to gesture path 34 may include a plurality of portions.
- the gesture may be divided into portions with substantially equivalent time durations.
- the gesture may include a final portion which may be a portion of the gesture detected prior to detecting that the gesture is complete. For instance, a portion of the gesture may be designated as the final portion where a user moves his/her finger out of proximity with UID 12 such that the finger is no longer detected by UID 12.
- keyboard module 22 may receive one or more indications of a gesture that traverses a group of keys of the plurality of keys.
- UI module 6 may incrementally detect the gesture having gesture path 34 at the UID 12 as the user performs the gesture by tracing gesture path 34 through or near keys of graphical keyboard 16B that correspond to one or more characters of a desired word (e.g., the characters corresponding to the word "benefit"), UI module 20 may send data that indicates gesture path 34 to gesture module 24, which in turn sends touch events to keyboard module 22.
- UI module 20 incrementally sends data indicating gesture path 34 to gesture module 24 as gesture path 34 is detected by UI device 4.
- Key board module 22 may receive the indications of the gesture and determine an alignment score that is based at least in part on a word prefix and at least one alignment point traversed by the gesture. In some examples, keyboard module 22 may determine group of alignment scores where each alignment score corresponds to a different prefix. An alignment score may represent a probability that the at least one alignment point indicates a key of the plurality of keys.
- Keyboard module 22 may determine the one or more tokens by determining a group of alignment points traversed by gesture path 34 and determining respective alignment scores for prefixes that each respectively include characters of keys that are in proximity to the alignment points. For instance, in response to determining a portion of gesture 34 beginning with “B" key 32C through “N” key 32E, keyboard module 2.2 may determine respective alignment scores for prefixes “ben,” brn,” “bem,” “ven,” etc. That is, keyboard module 22, may initially determine a prefix "b” in a token as gesture path 34 initially traverses near "B" key 32C.
- keyboard module 22 may "advance” the token for prefix "b" in a lexicon trie by creating tokens "br" and "be” (among other additional tokens).
- An alignment point maybe a point along gesture path 34 that may correspond to a key of the plurality of keys included in graphical keyboard 16B, An alignment point may include one or more coordinates corresponding to the determined position of the alignment point. For instance, an alignment point may include Cartesian coordinates corresponding to a point on user interface 14.
- keyboard module 2.2 determines the group of alignment points traversed by gesture path 34 based on a plurality of features associated with gesture path 22.
- the plurality of features associated with gesture path 34 may include a length, speed, curvature, direction, etc., of a segment of gesture path 34.
- gesture module 24 may determine the length along the gesture segment from a previous alignment point and the current alignment point. For better alignments, the length will more closely approximate the straight-line distance between to two corresponding keyboard letters.
- the alignment points may be compared to spatial models that correspond to keys in proximity to the alignment points. In this way, keyboard module 22 may determine higher probabilities for keys that are closer to the alignment points.
- gesture module 24 may determine one or more tokens as described above, each of the tokens including a single siring of a plurality of predicted characters. For example, based at least in part on a portion of gesture path 34, keyboard module 22 may determine one or more tokens, each of the tokens including a single string of predic ted characters indicated by the portion of gesture path 34. As described in the example above, keyboard module 22. may determine a first token as the string of predicted characters "ben” corresponding to an indication of a predicted selection of "13" key 32C, "E" key 32D and "N" key 32E.
- gesture module 8 may determine a second token as the string of predicted characters "brn" corresponding to an indication of a predicted selection of "B" key 32C, "R” key 32G, and "N” key 32E.
- Keyboard module 22 may incrementally determine multiple such tokens based at least in part the proximity of gesture path 34 to one or more keys of graphical keyboard 16B.
- Each character of each token may be associated with a region of UID 12 that displays a key corresponding to the character.
- Keyboard module 22 may determine the one or more tokens based on observed touch points relative to the area of UI device 4 that displays the one or more keys corresponding to the one or more characters of the token.
- Each of the tokens including a string of predicted characters may be a prefix of a word included in a lexicon.
- the lexicon may be modeled in language module 28.
- Keyboard module 22 may determine one or more candidate words based at least in part on the one or more tokens.
- a candidate word may be a word suggested to the user that is composed of a group of keys indicated by gesture path 34.
- keyboard module 34 may determine one or more tokens in response to receiving an indication of a portion of gesture path 34, such as a first token including the string of predicted characters "ben”, a second token including the string of predicted characters "brn", a third token including the string of predicted characters "bem”, or other tokens.
- One or more of the tokens may be a prefix of a word included in a lexicon.
- Key board module 22 may , in certain examples, incrementally determine one or more candidate words as one or more of the words included in the lexicon for which a token is a prefix.
- keyboard module 22 may determine respective alignment scores for prefixes that include characters associated with keys included in keyboard 16B. Each of the respective alignment scores may represent a probability thai an alignment point indicates a key. That is, keyboard module 22 may determine an alignment store that indicates how closely gesture path 34 matches a given word modeled in language model 28. In some examples, an alignment score for a prefix in a token may be based on the character string that represents the word prefix, one or more alignment points of the gesture, and/or one or more keys.
- an alignment score for a word prefix may be based on the physical location of the alignment point with reference to the physical location of the key, and may be based on the probability that the word prefix, when appended with a character corresponding to the key, corresponds to a word in the lexicon.
- the respective alignment scores may be based on language model 28.
- the respective alignment scores may be based on the probability that a second key will be selected after a first key (e.g., the probability that the "e” key will be selected after the "b” key).
- the respective alignment scores may be based on the probability that a second candidate word will follow a first candidate word (e.g., the probability that the candidate word "benefit” will follow the candidate word "you”).
- the keys for which respective alignment scores are determined are selected based at least in part on language model 28.
- the alignment scores are lower where there is a greater likelihood that an alignment point indicates a key.
- the alignment scores are higher where there is a greater likelihood that an alignment point indicates a key.
- the user may make an error in performing a gesture to enter an intended word. For instance, as illustrated in FIG. 1 , the user may perform a continuous gesture indicated by gesture path 34. Although the user intended to enter the word "benefit,” the user entered a gesture as shown by gesture path 34 that corresponds to the misspelling "benefit.” Rather than outputting an unintended word (e.g., "Bemidji") based on the erroneous gesture input, keyboard module 22 may determine at least one alternative hypothesis that is based at least in part on a misspelling of the candidate word "benefit" that included the prefix "ben.” In other words, although the alignment score for "beni" and/or "benif ' may be low, keyboard module 22 may output the intended word "benefit” using at least one alternative character (e.g.. substituting "i” from the prefix with an "e”), which may be based at least in part on a misspelling of a candidate word that includes the prefix "ben
- the alternative character may be associated with a key of the graphical that is a distance away from an alignment point that is greater than threshold distance. For instance, locations of one or more neighboring keys of the graphical keyboard may be within the threshold distance of the alignment point.
- the alternative character may be associated with a key that is not a neighboring key, e.g., the alternative character may be associated with a key of the graphical keyboard that is a distance away from the alignment point that is greater than a threshold distance.
- the alternative character may be associated with a key that is a neighboring key, i.e., the alternative character may be associated with a key of the graphical keyboard that is a distance away from the alignment point that is less than or equal to a threshold distance.
- Keyboard module 22 may use correction data 30, in some examples, to determine at least one alternative character that is based at least in part on a misspelling of a candidate word that includes a given word prefix,
- a misspelling may be a spelling that is incorrect.
- a misspelling may be a character string comprising an incorrect spelling of a word in a vocabulary (a vocabu lary that includes a body of words used in a language, may be included in a dictionary used by computing device 10 and/or modeled in language model 28).
- Correction data 30 may, generally, include data that indicates alternative characters and/or combinations of one or more characters.
- correction data 30 may include data indicating a phonetic relationship between (he letter “i” and “e” because phonetically the letters "i” and “e” may be erroneously interchanged, e.g., "substituted” by a misspelling of a user (e.g., the user intends to enter the word "benefit” but instead gestures b-e-n-i-f-i-t).
- keyboard module 22 may determine an alternative hypothesis "bene” based on such data in response to determining the prefix "beni" is associated with a low alignment score (e.g., an alignment score that is less than a threshold).
- a low alignment score e.g., an alignment score that is less than a threshold.
- correction data 30 may include data ihai indicates positional relationship between one or more characters and/or combinations of characters.
- correction data 30 may include data indicating a position relationship between (he letter “i” and “e” because positionally, the characters "i” and “e” may be erroneously interchanged, e.g., "transposed” by a user (e.g., the user intends to enter the word “weird” but instead gestures w-i-e-r-d).
- Keyboard module 22 may determine an alternative hypothesis "weir” based on such data in response to determining that the prefix "wier” is associated with a low alignment score (e.g., an alignment score that is less than a threshold).
- correction data 30 may include data that indicate omissions of one or more characters and/or combinations of characters.
- correction data 30 may include daia indicating an omission relationship between the character "h” and the character combination "Faren” because the character "h” may be erroneously omitted by a user (e.g., the user intends to enter the word "Farhenheit” but instead gestures F-a-r-e-n-h-e-i-f).
- Keyboard module 22 may determine an alternative hypothesis "Farhen” based on such data in response to determining that the prefix "Faren” is associated with a low alignment score.
- correction data 30 may include data that indicates erroneous insertions of one or more characters and/or combinations of characters.
- correction data 30 may include data indicating an insertion relationship between the character "e” and the character combination "uly” because the character "e” may be erroneously inserted by a user (e.g., the user intends to enter the word "truly” but instead gestures t-r-u-e-l-y).
- Keyboard module 22 may determine an alternatively hypothesis ''truly” based on such data in response to determining that the prefix "true! is associated with a low alignment score.
- correction data 30 any other such suitable correction data indicating relationships between characters and/or combinations of characters based on one or more rules (e.g., relating to misspellings, mispronunciations, semantic errors, etc.) may be included in correction data 30.
- rules e.g., relating to misspellings, mispronunciations, semantic errors, etc.
- keyboard module 22 may determine that the alignment score for "beni" fails to satisfy a threshold. For instance, keyboard module 22 may determine that the alignment score for "bens" is less than the threshold.
- the threshold may be a value configured by an engineer ami/or user of computing device 10. In other examples, keyboard module 22 may dynamically determine the threshold. In response to determining that the alignment score fails to satisfy the threshold, keyboard module 22 may determine at least one alternative character that is based at least in part on a misspelling of that includes the word prefix. For instance, in the example of FIG.
- keyboard module 22 may determine an alternative hypothesis "bene” based on a relationship in correction data 30 that indicates "e” may be substituted for the alternative character "i” (e.g., the user may have made a phonetic substitution error of "i” for "e” in the gesture).
- keyboard module 22 may create a token that includes the word prefix "bene”, e.g., the alternative hypothesis, based on the substitution of "i” for "e” as indicated by correction data 30.
- Keyboard module 22 may determine an alternative alignment score for the word prefix "bene” that is included in the token. Because the word “benefit” may be modeled in language model 28 and, in some examples, with a higher probability than words beginning with "beni", the alternative alignment score for word prefix "bene” may be higher than "beni". in some examples, keyboard module 22 may determine the alignment score as further describe herein without creating a token thai includes the alternative hypothesis.
- keyboard module 22 may send data to UI module 20 that causes UID 12 to output for display, a candidate word based at least in part on the alternative character "e” that was substituted for "i" in the alternative hypothesis "bene.” For example, keyboard module 22. may search or "look ahead” to determine one or more candidate words in language model 28 thai correspond respectively to the prefix "bene”.
- keyboard module 22 may determine, using language model 2.8, the respective probabilities of candidate words “benefit,” “beg,” and “benoit.” Keyboard module 22 may therefore output the candidate words “benefit,” “beg,” and “benoit.”
- probabilities associated with candidate words “benefit,” “beg,” and “benoit” may be greater than any other candidate words given the word prefix "bene.”
- respective probabilities associated with candidate words "benefit,” “beg,” and “benoit” may be greater than one or more thresholds.
- the threshold may be a value that is equal to a quantity of a first subset of word prefixes associated with one or more alignment scores that are greater than alignment scores associated word prefixes in a second subset of word prefixes.
- keyboard module 22 may apply a penalty for each and/or one or more corrections (e.g., applying one or more error correction operations), so a word with many spelling corrections would have a lower alignment score. That is, as keyboard module 2.2 generates an alternative word prefix and/or determines an alternative alignment score, keyboard module 22 may apply a penalty value to the alignment score associated with a word prefix to which keyboard module 22 applied one or more error correction operations. Furthermore, to improve performance, keyboard module 22 may limit the number of spelling corrections allowed for a single word, or limit the frequency of spelling con-eciions relative to the number of letters (e.g., at most 1 correction every N letters) as further described in FIG. 8.
- keyboard module 22 may, in response to determining at least one alternative character that is based at least in part on a misspelling that includes at least a portion of the word prefix (e.g., applying an error correction operation), may determine a penalty value.
- the penalty value may be a value set by a user and/or engineer or determined dynamically as further describe herein.
- Keyboard module 22 may determine an alternative alignment score based at least in part on the at least one alternative character. In such examples, keyboard module 22 may determine the alternative alignment score based at least in part on the penalty value.
- keyboard module 22 may add the penalty value to the alternative alignment score or generate a new alternative alignment score that is the product of the alignment score and the penal ty value, in this way, keyboard module 22 may apply a penal ty value to an alternative alignment score. Further details of the techniques of the disclosure are described in examples of FIGS 2-9.
- FIG. 2 is a block diagram illustrating an example computing device, in accordance with one or more aspects of the present disclosure.
- Computing device 10 of FIG. 2 is described below within the context of FIG. 1.
- FIG. 2 illustrates only one particular example of computing device 10, and many other examples of computing device 10 may be used in other instances and may include a subset of the components included in example computing device 10 or may include additional components not shown in FIG. 2.
- computing device 10 includes user- interface device 12 (e.g., a presence-sensitive display), one or more processors 40, one or more input devices 42, one or more communication units 44, one or more output devices 46, and one or more storage devices 48.
- Storage devices 48 of computing device 10 also include UI module 20, keyboard module 22, gesture module 24, spatial model 26, language module 28, correction data 30, active beam 52, and next beam 54.
- Communication channels 50 may interconnect each of the components 12, 40, 42, 44, 46, 48, 20, 22, 24, 26, 28, 30, 52, 54, and 56 for inter- component communications (physically, communicatively, and/or operatively).
- communication channels 50 may include a system bus, a network connection, an inter-process communication data structure, or any other construct for communicating data.
- One or more input devices 42 of computing device 10 may receive input. Examples of input are tactile, audio, and v ideo input. Input de vices 42. of computing device 10, in one example, includes a mouse, keyboard, voice responsive system, video camera, microphone or any other type of device for detecting input from a human or machine. In some examples, input device 42 may be a presence-sensitive input device, which may include presence-sensitive screen, touch-sensitive screen, etc.
- One or more output devices 46 of computing device 10 may generate output. Examples of output are tactile, audio, and video output.
- Output devices 46 of computing device 10 includes a presence-sensitive screen, sound card, video graphics adapter card, speaker, cathode ray tube (CRT) monitor, liquid crystal display (LCD), or any other type of device for generating output to a human or machine.
- Output devices 46 may include display devices such as cathode ray tube (CRT) monitor, liquid crystal display (LCD), or any other type of device for generating visual output.
- One or more communication units 44 of computing device 10 may communicate with external devices via one or more networks by transmitting and/or receiving network signals on the one or more networks.
- computing device 10 may use communication unit 44 to transmit and/or receive radio signals on a radio network such as a cellular radio network.
- communication units 44 may transmit and/or receive satellite signals on a satellite network such as a GPS network.
- Examples of communication unit 44 include a network interface card (e.g. such as an Ethernet card), an optical transceiver, a radio frequency transceiver, a GPS receiver, or any other type of de vice that can send and/or receive information.
- Other examples of communication units 44 may include Bluetooth®, GPS, 3G, 4G, and Wi-Fi® radios found in mobile devices as well as Universal Serial Bus (USB) controllers.
- USB Universal Serial Bus
- UID 12 of computing device 10 may include functionality of input devices 42 and/or outpui devices 46.
- UID 12 may be or may include a presence-sensitive input device, such as a presence-sensitive screen, touch- sensitive screen, etc.
- a presence sensitive screen may detect an object at and/or near the presence-sensitive screen.
- UID 12 may detect an object, such as a finger or stylus that is within 2. inches or less of the presence-sensitive screen.
- the presence-sensitive screen may determine a location (e.g., an (x,y) coordinate) of the presence-sensitive screen at which the object was detected.
- a presence-sensitive screen may detect an object 6 inches or less from the presence-sensitive screen and other ranges are also possible.
- the presence- sensitive screen may determine the location of the screen selected by a user's finger using capacitive, inductive, and/or optical recognition techniques.
- UID 12 pro vides output to a user using tactile, audio, or video stimuli as described with respect to output device 46.
- UID 12 presents a user interface, such as user interface 14 of FIG. 1.
- UID 12 may also represent an external component that shares a data path with other components of computing device 10 for transmitting and/or receiving input and outpui.
- UID 12 represents a built-in component of computing device 10 located within and physically connected to the external packaging of computing device 10 (e.g., a screen on a mobile phone).
- UID 12 may be an external component of computing device 10 located outside and physically separated from the packaging of computing device 10 (e.g., a monitor, a projector, etc. that shares a wired and/or wireless data path with a tablet computer).
- One or more storage devices 48 within computing device 10 may store information for processing during operation of computing device 10.
- storage device 48 is a temporary memory, meaning that a primary purpose of storage device 48 is not long-term storage.
- Storage devices 48 on computing device i 0 may configured for short-term storage of information as volatile memory and therefore not retain stored contents if powered off. Examples of volatile memories include random access memories (RAM), dynamic random access memories (DRAM), static random access memories (SRAM), and other forms of volatile memories known in the art.
- RAM random access memories
- DRAM dynamic random access memories
- SRAM static random access memories
- Storage devices 48 also include one or more computer- readable storage media.
- Storage devices 48 may be configured to store larger amounts of information than volatile memory.
- Storage devices 48 may further be configured for long-term storage of information as non-volatile memory space and retain information after power on/off cycles. Examples of non-volatile memories include magnetic hard discs, optical discs, floppy discs, flash memories, or forms of electrically programmable memories (EPROM) or electrically erasable and programmable (EEPROM) memories.
- Storage de vices 48 may store program instructions and/or data associated with Ul module 20, keyboard module 22, gesture module 24, spatial model 26, language module 28, correction data 30, active beam 52, next beam 54, and operating system 56.
- processors 40 may implement functionality and/or execute instructions within computing device 10.
- processors 40 on computing device 10 may receive and execute instructions stored by storage devices 48 that execute the functionality of UI module 20, keyboard module 22, gesture module 24, spatial model 26, language module 28, correction data 30, active beam 52, next beam 54, and operating system 56. These instructions executed by processors 40 may cause computing device 10 to store information, within storage devices 48 during program execution.
- Processors 40 may execute instructions of Ul module 20, keyboard module 22, gesture module 24, spatial model 26, language module 28, correction data 30, active beam 52, next beam 54, and operating system 56 to cause UID 12. to display user interface 14.
- modules Ul module 20, keyboard module 22, gesture module 24, spatial model 26, language module 28, correction data 30, active beam 52, next beam 54, and operating system 56 may be operable by processors 40 to perform various actions, including receiving an indication of a gesture at locations of the presence-sensitive screen of UID 12 and causing UID to present user interface 14.
- Computing device 2 may include operating system 56.
- Operating system 56 controls the operation of components of computing device 2.
- operating system 56 in one example, facilitates the
- UI module 20 communication of UI module 20, gesture module 24, and keyboard module 22 with processors 40, communication unit 44, storage device 48, input device 42, and output device 46.
- Computing device 2 may include active beam 52.
- Active beam 52 in some examples, is configured to store one or more tokens generated by keyboard module 2.2, Active beam 52 may be included within storage devices 48, Computing device 2 may also include next beam 54.
- Next beam 54 in some examples, is configured to store one or more tokens generated by keyboard module 22.
- Next beam 56 may be included within storage devices 48.
- Correction data 30 in some examples, may maintain a misspelling dictionary, with one or more explicit entries comprising data that indicates that common gesture misspellings like "wierd" should be corrected to "weird".
- Computing device 10 can include additional components that, for clarity, are not shown in FIG. 2.
- computing device 10 can include a battery to provide power to the components of computing device 2.
- the components of computing device 2 shown in FIG. 2 may not be necessary in every example of computing device 2.
- computing device 2 may not include communication unit 44.
- keyboard module 22 may send data to UI module 20 that causes UID 12 to output for display, graphical keyboard 16B, which includes a plurality of keys.
- A. user may perform a gesture at UID 12 that traverses one or more regions of graphical keyboard 1613 that correspond to keys of graphical keyboard 16B.
- UID 12 may detect a gesture path, such as gesture path 34 of FIG. 1, which may be received by UI module 20 as gesture path data.
- the gesture path may include one or more portions, which UID UI module 20 may determine incrementally as the user performs the gesture.
- Gesture module 24 may receive the gesture path data from UI module 20 and assemble one or more touch events as described in FIG, 1 that correspond to the gesture path data.
- UI module 20 incrementally sends the gesture path data to gesture module 24 as gesture path 34 is detected by UID 12.
- keyboard module 22 may create one or more tokens that include prefixes corresponding to keys traversed by gesture path 34.
- keyboard module 22 may create a token at the entry node of a lexicon which may be included in language model 28.
- language module 28 may be implemented as a trie data structure.
- Each mo vable token may represent a partial alignment between a node in the lexicon (i.e., a partial word and/or phrase) and a point along the gesture.
- techniques of the disclosure may determine how far the token needs to advance along the gesture path. For instance, techniques of the disclosure may include searching for an alignment point along the gesture that best aligns to a letter of a key.
- a lexicon trie data structure may contain a plurality of nodes, each node may represent a letter.
- Keyboard module 22 may push each token into active beam 52.
- Gesture module 8 may create a token copy on each of the token's child nodes as keyboard module 22 incrementally receives further indications of user input along gesture path 34.
- keyboard module 22 may create a first token copy on the child node representing the letter "B" (e.g., corresponding to a predicted key selection of "B" key 32C) and a second token copy on the child node representing the fetter "V” (e.g., corresponding to a predicted key selection of "V” key 32H).
- keyboard module 22 may determine, based on one or more features associated with the gesture path data, one or more alignment points traversed by the gesture. In the example of FIG. 1, keyboard module 22 may determine that a first alignment point is located at the start of gesture path 34. In some examples, keyboard module 22. may determine the curvature of the path at a point along the gesture path (e.g., in proximity to "E" key 32D).
- keyboard module 22 may determine that the point is more lilvely to be an alignment point where there is a high curvature (where the gesture path changes direction abruptly at the point), in other examples, keyboard module 22 may determine a mid-segment curvature (the maximum curvature of the gesture path between two points along the gesture). In another example, keyboard module 22 may determine that a point is less likely to be the next alignment point where there is a high mid- segment curvature, in some examples, keyboard module 22. may determine that a point is an alignment point based on the speed at which the gesture path was detected. In some examples, a slower rate of detection indicates that the point is an alignment point.
- a high mid-segment curvature may indicate that there were corners between a first point and a second point, suggesting that the second point is less likely to be the ne t alignment point (i.e., a point was missed in-between).
- an alignment point may be based on the maximum distance between points of a gesture segment between two or more points and an ideal line from a first key to a second key.
- An ideal line may be, e.g., a shortest distance path from the first key to the second key. For a better alignment the maximum distance may be small, signifying that the gesture segment does not deviate from the ideal line.
- gesture module 8 may determine respective alignment scores for each of at least two keys of the plurality of keys. Each of the respective alignment scores may represent a probability that the alignment point indicates a key of the plurality of keys.
- keyboard module 2.2 may determine a first alignment score representing a probability that the first alignment point indicates the node representing the letter "B" and a second alignment score representing a probability that the first alignment point indicates the node representing the letter "V”.
- keyboard module 22 may then update the token copy (e.g., that includes "B") with the respective alignment point and/or alignment score and push the token copy in next beam 54.
- keyboard module 22 may add the first alignment score to the first token copy (e.g., that includes "B") and the second cost value to the second token copy (e.g., that includes "V").
- Keyboard module 22 may determine respective physical scores for each of the at least two keys of the pluralit of key s.
- Each of the respective phy sical cost values may represent a probability that physical features of an alignment point of the group of alignment points indicate a key of the plurality of keys.
- keyboard module 22 may determine the respective physical scores by evaluating the Euclidian distance between an alignment point of the group of alignment points and a keyboard position of key. in other examples, keyboard module 22 may use spatial model 26 to determine the probability of a key based on the location of an alignment point corresponding to gesture path 34 and the spatial model.
- key regions may include, for each of the plurality of keys, a set of coordinates that correspond to a location and/or area of graphical keyboard 16B where each key is displayed.
- key board module 22 may determine a first physical score based on the Euclidian distance between the first alignment point and "B" key 32C,
- keyboard module 22 may determine the physical scores by comparing the Euclidian distance between a first alignment point and a second alignment point with the Euclidian distance between a first key indicated by the first alignment point and a second key which may be represented by the second alignment point.
- Keyboard module 22 may determine the respective alignment scores for prefixes included in tokens by determining respective language scores for each of the at least two keys of the plurality of keys. Each of the respective language scores may represent a probability that a ieiter represented by a key of the plurality of keys is included in a candidate word that is based on the token.
- the language scores may be based on language model 28. For instance, the language scores may represent the likelihood that a given key corresponding to a letter is selected based on probable words included in language model 28.
- L keyboard module 22 may determine a language score based on an entry in language model 28 indicating a frequency that the letter "B" is the first letter in a word. As described in FIG.
- the alignment score for the token including the word prefix "B” may be based on the spatial score and the language score for "B". For instance, keyboard module 22 may determine a product of spatial and language scores for the word prefix "B" in the first token as the alignment score,
- keyboard module 22 may also determine whether the token is at a terminal node of the lexicon.
- a terminal node of the lexicon may be a node that represents a complete word included in the lexicon. For instance, in the example of FIG, 1 , keyboard module 22 may determine, based at least in part on an indication of a portion of gesture path 34, a token including the single string of predicted characters.
- the token may itself represent a complete word included in the lexicon, such as a complete word in the English language.
- keyboard module 22 may generate a next-word token.
- the next-word token may indicate that a next determined key of the plurality of keys based on the gesture path is a prefix of a second word included in the lexicon.
- gesture module keyboard module 22 may select a token and create a token copy on each of the token's child nodes in the lexicon. Each child node may include a predicted character indicated by the received portion of the gesture. For instance, keyboard module 22 may select a token that includes the word prefix "beni". As gesture corresponding to gesture path 34 mo ves to "F" key 32F as illustrated in FIG. 1, computing device 10 may create a token copy of "beni” and append the character " ' corresponding to "F” key 32F that is in proximity to the gesture, in order to create a word prefix "benif '.
- Keyboard module 22 may create one or more additional word prefixes in token copies in a similar manner, such as word prefix “benig”, “benit”, etc.
- keyboard module 22 may determine an alignment score for each token included in active beam 52.
- keyboard module 10 may determine at least one alternative character that is based at least in part on a misspelling that includes at least a portion of a word prefix included in one or more of the tokens. For example, as described in FIG. 1 , keyboard module 22 may generate an alternative word prefix "bene ' by substituting "e” for "i" in the word prefix "benif. Keyboard module 22 may store the alternative word prefix in a new token in active beam 52 as further described in FIGS. 4-7. [0087] In some examples, keyboard module 22 may determine an alignment score for the word prefix "benef '. In some examples, keyboard module 22.
- keyboard module 22 may determine at least one alternative character that is based at least in part on a misspelling that includes at least a portion of the word prefix. For instance, keyboard module 22 may determine at least one alternative character that is based at least in part on a misspelling that includes at least a portion of the word prefix, in response to determining that that one or more alignment scores associated with one or more word prefixes fail to satisfy a threshold. In other examples, keyboard module 22 may determine at least one alternative character that is based at least in part on a misspelling that includes at least a portion of the word prefix, without determining whether an alignment score associated with a word prefix satisfies a threshold.
- Keyboard module 22 may determine at least one alternative character that is based at least in part on a misspelling that includes at least a portion of the word prefix using one or more error correction operations that are identified by type.
- a first example of error correction operations may include the techniques described in FIGS. 4A-4C to perform substitution error correction, and the type of error correction operations may be "substitution error correction.”
- a second example of error correction operations may include the techniques described in FIGS. 5A-5C to perform deletion error correction, and the type of error correction operations may be "deletion error correction.”
- a third example of error correction operations may include the techniques described in FIGS.
- keyboard module 22 may use other suitable, example error correction techniques to determine at least one alternative character that is based at least in part on a misspelling that includes at least a portion of the word prefix.
- keyboard module 22 may determine an alternative alignment score that is based at least in part on the alternative character. For instance, keyboard moduie 22 may determine an alignment score of the alternative word prefix "benef ' included in the new token copy added to active beam 52.
- Computing device 10 may, in response to determining that the alternative alignment score satisfies a second threshold, output for display, a candidate word based at least in part on the alternative character. For instance, each of the tokens in active beam 52. may be sorted in a ranked ordering from a largest (or highest) alignment score to a smallest (or lowest) alignment score.
- Keyboard module 22 may determine one or more candidate words based at least in part on or more word prefixes that are associated with alignment scores that satisfy the second threshold. For instance, keyboard moduie 2.2 may determine that the word prefix associated w th the largest alignment score satisfies a threshold, and therefore keyboard module 22 may output one or more candidate words based at least in part on the word prefix. In some examples, keyboard module 22 may determine that a plurality of word prefixes satisfy the second threshold an d therefore output a. plurality of candidate words that are based respectively on the plurality of word prefixes that satisfy the second threshold.
- the alternative alignment score associated with the alternative word prefix may satisfy the threshold and therefore keyboard module 22 may output one or more candidate words based at least in part on the alternative character that may be included in an alternative word prefix.
- keyboard module 2.2 may apply a penalty value to an alignment score.
- Keyboard module 22 may apply different penalty values to alignment scores, in some examples. For instance, keyboard moduie 22 may apply larger penalty values or smaller penalty values to alignment scores based on the error correction operation applied to generate alternative alignment scores.
- Keyboard module 22 may, for example, maintain a hierarchy and/or mapping of different penalty values. Each one or more error correction operations may be associated with a type of error correction, and keyboard moduie 22 may maintain a plurality of different types. Each type may be associated with a different penalty value. In some examples, different penalty values may be letter dependent and/or multi-letter dependent, such that a smaller penalty value may be applied single letter corrections while keyboard module 22. may apply larger penalty values to n- letter corrections based on the size of n. Keyboard module 22 may, in response to determining an alternative alignment score, determine a type of error correction operation from a plurality of error correction operations that keyboard module 22 used to determine the alternative alignment score. Keyboard module 22 may select the penalty value from a plurality of penalty values. Each penalty value in the plurality of penalty va lues may be ordered in a ranked ordering. In some examples, each penalty value is associated with at least one type of error correction operation.
- common misspellings indicated in correction data 30 may be associated with a first penalty value that is less than a second penalty value.
- the second penalty value may be associated with phonetic substitutions (e.g., "i" substituted for "e") that is less than a third penalty value.
- the third penalty value may be a ssociated with transposition errors. If keyboard module 22 performs an error correction operation that generates an alternative alignment score based on a common misspelling, keyboard module 22 may apply the first penalty value to the alternative alignment score. In another example, if keyboard module 22 performs an error correction operation that generates an alternative alignment score based on a phonetic substitution, keyboard module 22. may apply the second penalty value to the alternative alignment score. In still another example, if keyboard module 22 performs an error correction operation that generates an alternative alignment score based on a transposition, keyboard module 2.2 may apply the third penalty value to the alternative alignment score.
- keyboard module 22 may improve perform for the extra token expansions due to error correction operations without greatly expanding the search space by limiting these extra correction expansions to only the top N tokens in the active beam (where Nis typically smaller than the regular beam size.
- keyboard module 22 may determine alignment scores and/or alternative word prefixes only for a subsei of word prefixes in the active beam that are associated with the largest alignment scores that are each greater than alignment scores associated with word prefixes in a second a subset of the active beam.
- each token that includes an alternative word prefix may include a flag or other suitable data that indicates the token includes an alternative word prefix.
- Keyboard module 22 may store only a threshold quantity of tokens in the active beam that include the flag or other suitable data that indications the token includes an alternative word prefix. In this way, if keyboard module 2.2 determines that the quantity of tokens in the active beam that include alternative word prefixes satisfies a threshold, keyboard module 22 will not generate additional alternative word prefixes (and/or tokens to include the alternative word prefixes) until one or more tokens that include alternative word prefixes are removed from the active beam.
- FIG. 3 is a block diagram illustrating an example computing device that outputs graphical content for display at a remote device, in accordance with one or more techniques of the present disclosure.
- Graphical content generally, may include any visual information that may be output for display, such as text, images, a group of moving images, etc.
- the example shown in FIG, 3 includes a computing device 60, presence-sensitive display 64, communication unit 70, projector 80, projector screen 82, mobile device 86, and visual display device 90.
- a computing device such as computing device 60 may generally, be any component or system that includes a processor or other suitable computing environment for executing software instructions and, for example, need not include a presence- sensitive display.
- computing device 60 may be a processor that includes functionality as described with respect to processor 40 in FIG. 2.
- computing device 60 may be operatively coupled to presence-sensitive display 64 by a communication channel 62.A, which may be a system bus or other suitable connection.
- Computing device 60 may also be operatively coupled to communication unit 70, further described below, by a communication channel 62B, which may also be a system bus or other suitable connection.
- communication channel 62B may also be a system bus or other suitable connection.
- computing device 60 may be operatively coupled to presence-sensitive display 64 and communication unit 70 by any number of one or more communication channels. I . 0095J in other examples, such as illustrated previously by computing device 10 in FIGS.
- a computing device may refer to a portable or mobile device such as mobile phones (including smart phones), laptop computers, etc.
- a computing device may be a desktop computers, tablet computers, smart television platforms, cameras, personal digital assistants (PDAs), servers, mainframes, etc.
- PDAs personal digital assistants
- Presence-sensitive display 64 which may be a user-interface device such as IJID 12. as shown in FIG. 1 , may include display device 66 and presence-sensitive input device 68.
- Display device 66 may, for example, receive data from computing device 60 and display the graphical content.
- presence-sensitive input device 68 may determine one or more user inputs (e.g., continuous gestures, multi-touch gestures, single -touch gestures, etc.) at presence-sensitive display 64 using capacitive, inductive, and/or optical recognition techniques and send indications of such user input to computing device 60 using communication channel 62A.
- presence-sensitive input device 68 may be physically positioned on top of display device 66 such that, when a user positions an input unit over a graphical element displayed by display device 66, the location at which presence-sensitive input device 68 corresponds to the location of display device 66 at which the graphical element is displayed.
- computing device 60 may also include and/or be operatively coupled with communication unit 70.
- Communication unit 70 may include functionality of communication unit 44 as described in FIG. 2. Examples of communication unit 70 may include a network interface card, an Ethernet card, an optical transceiver, a radio frequency transceiver, or any other type of device that can send and receive information. Other examples of such communication units may include Bluetooth, 3G, and WiFi radios, Universal Serial Bus (USB) interfaces, etc.
- Computing device 60 may also include and/or be operatively coupled with one or more other devices, e.g., input devices, output devices, memory, storage devices, etc. that are not shown in FIG. 3 for purposes of brevity and illustration. [ ⁇ 898] FIG.
- Projector 80 and projector screen 82 may include one or more communication units that enable the respective devices to communicate with computing device 60. In some examples, the one or more communication units may enable
- Projector 80 may receive data from computing device 60 that includes graphical content. Projector 80, in response to receiving the data, may project the graphical content onto projector screen 82. In some examples, projector 80 may determine one or more user inputs (e.g., continuous gestures, multi-touch gestures, single-touch gestures, etc.) at projector screen using optical recognition or other suitable techniques and send indications of such user input using one or more communication units to computing device 60. In such examples, projector screen 82 may be unnecessary, and projector 80 may project graphical content on any suitable medium and detect one or more user inputs using optical recognition or other such suitable techniques.
- user inputs e.g., continuous gestures, multi-touch gestures, single-touch gestures, etc.
- Projector screen 82 may include a presence-sensitive display 84
- Presence-sensitive display 84 may include a subset of functionality or all of the functionality of UID 12 as described in this disclosure.
- presence- sensitive display 84 may include additional functionality.
- Projector screen 82 e.g., an electronic whiteboard
- Projector screen 82 may receive data from computing device 60 and display the graphical content.
- presence- sensitive display 84 may determine one or more user inputs (e.g., continuous gestures, multi-touch gestures, single-touch gestures, etc.) at projector screen 82 using capacitive, inductive, and/or optical recognition techniques and send indications of such user input using one or more communication units to computing device 60.
- FIG. 3 also illustrates mobile device 86 and visual display device 90.
- Mobile device 86 and visual display device 90 may each include computing and connectivity capabilities. Examples of mobile device 86 may include e-reader devices, convertible notebook devices, hybrid slate devices, etc. Examples of visual display device 90 may include other semi-stationary devices such as televisions, computer monitors, etc. As shown in FIG. 3, mobile device 86 may include a presence-sensitive display 88. Visual display device 90 may include a presence-sensitive display 92. Presence-sensitive displays 88, 92 may include a subset of functionality or ail of the functionality of UTD 12 as described in this disclosure. In some examples, presence-sensitive displays 88, 92 may include additional functionality. In any case, presence-sensitive display 92, for example, may receive data from computing device 60 and display the graphical content.
- presence-sensitive display 92 may determine one or more user inputs (e.g., continuous gestures, multi-touch gestures, single-touch gestures, etc.) at projector screen using capacitive, inductive, and/or optical recognition techniques and send indications of such user input using one or more user inputs (e.g., continuous gestures, multi-touch gestures, single-touch gestures, etc.) at projector screen using capacitive, inductive, and/or optical recognition techniques and send indications of such user input using one or more
- computing device 60 may output graphical content for display at presence-sensitive display 64 that is coupled to computing device 60 by a system bus or other suitable communication channel.
- Computing device 60 may also output graphical content for display at one or more remote devices, such as projector 80, projector screen 82, mobile device 86, and visual display device 90.
- computing device 60 may execute one or more instructions to generate and/or modify graphical content in accordance with techniques of the present disclosure.
- Computing device 60 may output the data that includes the graphical content to a communication unit of computing device 60, such as communication unit 70.
- Communication unit 70 may send the data to one or more of the remote devices, such as projector 80, projector screen 82, mobile device 86, and/or visual display device 90.
- computing device 60 may output the graphical content for display at one or more of the remote de vices.
- one or more of the remote devices may output the graphical content at a presence-sensitive display that is included in and/or operatively coupled to the respective remote devices.
- computing device 60 may not output graphical content at presence-sensitive display 64 thai is operatively coupled to computing device 60, In other examples, computing device 60 may output graphical content for display at both a presence-sensitive display 64 that is coupled to computing device 60 by communication channel 62A, and at one or more remote devices. In such examples, the graphical content may be displayed substantially contemporaneously at each respective device. For instance, some delay may be introduced by the communication latency to send the data that includes the graphical content to the remote device. In some examples, graphical content generated by computing device 60 and output for display at presence-sensitive display 64 may be different than graphical content display output for display at one or more remote devices.
- Computing device 60 may send and receive data using any suitable communication techniques.
- computing device 60 may be operatively coupled to external network 74 using network link 72A.
- Each of the remote devices illustrated in FTG. 3 may be operatively coupled to network external network 74 by one of respective network links 72B, 72C, and 72D.
- External network 74 may include network hubs, network switches, network routers, etc., that are operatively inter-coupled thereby providing for the exchange of information between computing device 60 and the remote devices illustrated in FIG. 3.
- network links 72A-72D may be Ethernet, ATM or other network connections. Such connections may be wireless and/or wired connections.
- computing device 60 may be operatively coupled to one or more of the remote devices included in FIG. 3 using direct device
- Direct device communication 78 may include communications through which computing device 60 sends and receives data directly with a remote device, using wired or wireless communication. That is, in some examples of direct device communication 78, data sent by computing device 60 may not be forwarded by one or more additional devices before being received at the remote device, and vice-versa. Examples of direct device communication 78 may include Bluetooth, Near-Field Communication, Universal Serial Bus, WiFi, infrared, etc.
- Examples of direct device communication 78 may include Bluetooth, Near-Field Communication, Universal Serial Bus, WiFi, infrared, etc.
- One or more of the remote devices illustrated in FIG. 3 may be operatively coupled with computing device 60 by communication links 76A-76D.
- communication links 76A-76D may be connections using Bluetooth, Near-Field Communication, Universal Serial Bus, infrared, etc. Such connections may be wireless and/or wired connections.
- computing device 60 may be operatively coupled to visual display device 90 using external network 74.
- Computing device 60 may output a graphical keyboard for display at presence- sensitive display 92.
- computing device 60 may send data that includes a representation of the graphical keyboard to communication unit 70.
- Communication unit 70 may send the data that includes the representation of the graphical keyboard to visual display device 90 using external network 74.
- Visual display device 90 in response to receiving the data using external network 74, may- cause presence-sensitive display 92 to output the graphical keyboard.
- visual display device 90 may send an indication of the gesture to computing device 60 using external network 74.
- Communication unit 70 of may receive the indication of the gesture, and send the indication to computing device 60.
- computing device 60 may determine an alignment score that is based at least in part on a word prefix and at least one alignment point traversed by the gesture.
- the alignment score represents a probability that the at least one alignment point indicates a key of the plurality of keys.
- Computing device 60 may, in response to determining that the alignment score fails to satisfy a first threshold, determine at least one alternative character that is based at least in part on a misspelling that includes at least a portion of the word prefix.
- Computing device 60 may determine an alternative alignment score that is based at least in part on the alternative character. In some examples, in response to determining that the alternative alignment score satisfies a second threshold, computing device 60 may output for display, a candidate word based at least in part on the alternative character. For instance, computing device 60 may send data representing the at the candidate word to communication unit 70. Communication unit 70 may send the data to visual display device 90 via external network 74. Visual display device 90 may cause presence-sensitive display 92 to output character string represented by the data.
- FIGS. 4A-4C are block diagrams illustrating further details of one example of a computing device shown in FIG.
- a computing device may detect substitution errors in a continuous gesture and determine one or more alternative hypotheses to improve the accuracy of word prediction. For instance, a user may have intended to input "cemetery"; however, she may have erroneously gestured c-e-m-e-t-a-r-y. In such substituiion error examples, for one or more letters in a candidate word, computing de vice 10 may consider (wo types of hypotheses.
- the first hypothesis is that the gesture passes through the exact letter, e.g., "cemetery.”
- the second hypothesis is that the gesture passes through a different letter instead (e.g., a "substituiion"), e.g., "cemet ry.”
- the substitution techniques implemented by computing device 10 may provide for arbitrary substitution or, alternatively, specific substitutions based on common mis-spellings in the current language (e.g., in English "e” could be commonly substituted with similar sounding letters "o” or "i", but not “k”).
- the substitution techniques are now further described with respect to FIGS. 4A-4C,
- FTGS. 4A-4C are block diagrams illustrating further details of one example of a computing device shown in FIGS. 1-3, in accordance with one or more techniques of the present disclosure.
- computing device 10 may include GUI 100, active beam 102, and next beam 104.
- GUI 100 may include graphical keyboard 106 which may include "B" key 108A, "E” key 108B, and "N" key 108C.
- gesiure path 110 that includes 110A ⁇ 1 10B and/or alignment points 1 12A-1 12C may not be visible during the performance of the techniques described herein.
- a user may desire to enter the word "benefit" into computing device 10 by performing a gesiure at graphical keyboard 106.
- computing device 10 may incrementally receive indications of the gesture having a gesture path 1 10.
- computing device 10 is shown, as having detected gesture path 1 1 OA— 1 10B.
- computing device 10 may determine alignment points 1 12A-1 12B along gesture path I I0A. In response to detecting gesture path 1 10A, computing device 10 may create one or more tokens and push the tokens into active beam 102. A portion of example contents of active beam 102 may be represented by Table 1 below.
- each row represents an individual token
- the index column represents a unique identifier for each token
- the parent index column represents the index value of the token to which the listed token is a child
- the letter key of the current node column represent the letter key represented by the current node of the token
- the letter chain column represents a ll of the letter keys represented by the nodes from an entry node to the current node of the token
- the alignment score column represents the alignment score of the token.
- the created tokens have indices of io-ii (e.g., corresponding to tokeno- token;).
- computing device 10 may create a copy of each token on its child nodes in response to additional indications of gesture input indicating gesture path 1 10B.
- Computing device 10 may, for example, create a copy of the token with index 0 on child node "BE" (i.e., tokeno) and child node "VE" (i.e., tokeni).
- computing device 10 may determine an alignment score as described in FIGS. 1-2.
- Computing device 10 may push each token copy to next beam 104, a portion of example contents of which may be represented by Table 2 below.
- Table 2 The entries shown in Table 2 are similar in format to the entry shown in Table 1.
- tokens has cost value A So + AS 3 and token] has cost value ASi + AS 4 .
- Computing device 10 may iterate or otherwise advance each token from active beam 102 by adding a character to each token in a similar manner and adding the updated token to next beam 104.
- Computing device 10 may subsequently determine whether active beam 102 is empty (i.e., contains no further tokens to be processed). In response to determining that active beam 102 is empty, computing device 10 may copy the contents of next beam 104 to acti v e beam 102 of FIG. 4B and discard the contents of next beam 104.
- computing device 10 may detect gesture path 1 IOC. As described above, the contents of active beam 102 may be represented by Table 2. Computing device 10 may determine alignment point 1 12D along gesture path 1 10. Computing device 10 may, for each token in active beam 102, create a copy on each child node. In the example of FIG. 4B, tokene and tokeng each have child nodes with letter keys "I" and token? has a child node with letter key "U.” For each created token copy, computing device 10 may determine an alignment score as described in FIGS. 1-2. Computing device 10 may push each token copy in to nex t beam 104, a portion of example contents of which may be represented by Table 3 below.
- Comp uting device 10 may determine which, if any, of the tokens are on terminal nodes, e.g., the path of nodes from the root node to the terminal node comprising a string of characters that represent a word in language model 28. in some examples, if a token is on a terminal node, computing device 10 may select the word, e.g., to output the word for display.
- computing device 10 may determine that the alignment score associated with a word prefix fails to satisfy a threshold. For instance, computing de vice 10 may determine that the alignment score is less than the threshold. As one example, computing device 10 may determine that the alignment score for VENI, ASj + AS 4 + ASe, does not satisfy a threshold. In some examples, computing device 10 may determine that a plurality of alignment scores associated with respective word prefixes fail to satisfy a threshold. For instance, computing device 10 may determine that the alignment scores for VENL BEMU, and BEN! each fail to satisfy a threshold.
- computing device 10 may determine at least one alternative character that is based at least in part 011 a misspelling that includes at least a portion of the word prefix.
- the word prefix "BENT' may include a first substring “BEN” and a second substring “I”.
- each substring may include zero or more characters.
- the second substring in this example includes at least one character "I”.
- Compuiing device 10 may determine that the second substring "I” of the word prefix "BENI” matches a first string in correction data 30.
- the first string may include one or more characters.
- computing device 10 may determine that the second substring "I” matches a first siring "I” in correction data 30.
- Correction data 30 may include one or more relationships between strings.
- correction data 30 may include data indicating a relationship between the first string "1" in correction data 30 and a second string ' ⁇ " in correction data 30.
- the second string "E” in correction data 30 may be a phonetic substitution for the first string "I” in correction data 30. Although described with respect to phonetic substitutions, any other suitable relationships between strings may be stored and retrieved in correction data 30 to perform subsitutions.
- Computing device 10 may determine, based at least in part on the first string in the correction data "T", the second string “E” in the correction data that comprises at least one alternative character to be included in an alternative word prefix. That is, computing device 10 may generate an alternative word prefix "BENE” that is comprised of the first substring “BEN” of the word prefix "BENI” and the second string “E” in correction data 30. In some examples, computing device 10 may concatenate “BEN” and “E” to form the alternative word prefix "BENE.” Computing device 10 may store “BENE” in a new token within active beam 102. Computing device 10 may also determine an alignment score for "BENE" thai is stored in the new token.
- computing device 10 is shown as having detected gesture path 1 10D. As described above, the contents of active beam 102. may be represented by T able 4. Computing device 10 may determine alignment point 1 12E along gesture path 1 10D, Computing device 10 may, for each token in active beam 102, create a copy on each child node. In the example of FIG. 4C, tokens through token each have child nodes with letter keys "F" and "G" (e.g., in proximity to and/or within a predefined distance of alignment point 1 12E). For each created token copy computing device 10 may determine an alignment score as described in FIGS. 1-2. Computing device 10 may push each token copy into next beam 104, the contents of which may be represented by Tabl e 5 below.
- the entries shown in Table 6 are similar in format to the entries shown in Tables 1-5.
- the alignment score for each token includes the alignment score for the previous letters and the alignment score for the current letter.
- tokeiiio that includes alternative word prefix "BENEF” may be associated with the largest alignment score ASo + AS3 + AS9 + AS 10. That is, the alignment score ASo + AS;, + AS 9 -i- AS JO may be the largest alignment score in Table 6.
- computing device 10 may "look ahead” to additional nodes in language model 28, including a terminal node for "e”, that collectively indicate the candidate word "benefit.”
- computing device 10 may output "benefit” for display based on the word prefix "BENEF” being associated with the largest alignment score in active beam 104.
- Computing device 10 may continue to incrementally determine the one or more tokens as computing device 10 receives further indications of the gesture, thereby enabling a user to provide a single gesture to select a group of keys of a word or phrase.
- computing device 10 may determine whether the user has completed performing the gesture. In response to determining that the user has completed performing the gesture, computing device 10 may output a list of candidate words. The candidate words may be based at least in part on the one or more tokens. In some examples, the candidate words may be modeled in language model 28 and based on the contents of one or more dictionaries that include words of a written language. In some examples, computing device 10 may determine a subset of the list of candidate words which have the highest alignment scores (i.e., the predictions with the highest probability). Additionally, in some examples, computing device 10 may, at each subsequent alignment point, revise the alignment scores of the tokens contained in active beam 102 as described in the examples of FIGS 4A-4C.
- FIGS. 5A-5C are block diagrams illustrating further details of one example of a computing device shown in FIG. I that is used to perform deletion error correction for gesture -based input, in accordance with one or more techniques of the present disclosure.
- a computing device may detect deletion errors in a continuous gesture and determine one or more alternative hypotheses to improve the accuracy of word prediction. For instance, a user may have intended to input "Fahrenheit"; however, she may have erroneously gestured f-a-r-e-n. For each letter in a candidate word, the techniques of the disclosure may also consider an alternative hypothesis the user accidentally left one or more letters out of the gesture.
- the user may have inadvertently omitted the key corresponding to the letter "h” in the gesture.
- the techmques of the disclosure may skip the current letter and continue matching the gesture to the next letter in the word.
- the techniques may align the first two letters “F"-"a” to the valid word “Fahrenheit.”
- the techniques of th e disclosure may al so consider an alternative hypothesis that the "h" is missing, and skip to the next letter "r".
- the previous letter that the gesture passed through is “a” so the techniques may determine that the gesture path travels from “a” to “r” (instead of the original “h” to “r”).
- the deletion error techniques are now further described with respect to FIGS. 5A-5C.
- FIGS. 5A-5C are block diagrams illustrating further details of one example of a computing device shown in FIGS. 1 -3, in accordance with one or more techniques of the present disclosure.
- computing device 10 may include GUI 124, active beam 120, and next beam 122.
- GUI 124 may include graphical keyboard 12.6 which may include "A" key 128 A, "Q" key 128B, and "U” key 128C.
- gesture path 132 that includes portion 132A and/or alignment point 130A may not be visible during the performance of the techniques described herein,
- a user may desire to enter the word "acquire" into computing device 10 by performing a gesture at graphical keyboard 126.
- computing device 10 may incrementally receive indications of the gesture having a gesture path I 32A.
- computing device 10 is shown as having detected gesture path 132A.
- computing device 10 may determine alignment point 130A. along gesture path 132 A.
- Computing device 10 may create one or more tokens and push the tokens into active beam 120,
- the initial contents of active beam 120 may be represented by Table 1 below prior to creating one or more tokens and pushing the tokens into active beam 120 in response to indications of gesture input. Table 1
- each row represents an individual token
- the index column represents a unique identifier for each token
- the parent index column represents the index value of the token to which the listed token is a child
- the letter key of the current node column represent the letter key represented by the current node of the token
- the letter chain column represents all of the letter keys represented by the nodes from an entry node to the current node of the token
- the alignment score column represents the alignment score of the token.
- the created token has an index of i 0 (e.g., corresponding to an empty tokeno).
- computing device 10 may create a copy of each token on its child nodes in response to additional indications of gesture input comprising gesture path 132 A.
- Table 1 may include an empty token (not shown) with an index of i 0 .
- Computing device 10 may create a copy of the token with index i 0 on child node "A" (i.e., tokeno) and child node "S" (i.e., token]).
- computing device 10 may determine an alignment score as described in FTGS. 1-2.
- Computing device 10 may push each token copy to next beam 122, a portion of example contents of which may be represented by Table 2 below.
- computing device 0 may iterate or otherwise advance each token from active beam 120 by adding a character (e.g., "A" or "Q") to each token (e.g., the empty tokeno) in a similar manner and adding the updated token to next beam 122.
- Computing device 10 may subsequently determine whether active beam 120 is empty (i.e., contains no further tokens to be processed). In response to determining that active beam 120 is empty, computing device 10 may copy the contents of next beam 122 to active beam 120 of FIG. 5B and discard the contents of next beam 120.
- computing device 10 may determine alignment point 130B along gesture path 132.
- Computing device 10 may, for each token in active beam 120, create a copy on each child node.
- token-, and token* each have child nodes with letter key s "Q"
- computing device 10 m y determine an alignment score as described in FIGS. 1-2
- Computing device 10 may push each token copy in to next beam 122, a portion of example contents of which may be represented by Table 3 below.
- the entries shown in Table 3 are similar in format to the entries shown in Table 1 and Table 2.
- the alignment score for each token includes the alignment score for the previous letters and the alignment score for the current letter.
- Computing device 10 may determine which, if any, of the tokens are on terminal nodes, e.g., the path of nodes from the root node to the terminal node comprising a string of characters that represent a word in language model 2.8. In some examples, if a token is on a terminal node, computing device 10 may select the word, e.g., to output the word for display.
- computing device 10 may determine that the alignment score associated with a word prefix fails to satisfy a threshold. For instance, computing device 10 may determine that the alignment score is less than the threshold. As one example, computing device 10 may determine that the alignment score for "AQ", ASo + AS2 does not satisfy a threshold. In some examples, computing device 10 may determine that a plurality of alignment scores associated with respective word prefixes fail to satisfy a threshold. For instance, computing device 10 may determine that the alignment scores for AQ and SQ each fail to satisfy a threshold.
- computing device 10 may determine at least one alternative character that is based at least in part on a misspelling that includes at least a portion of the word prefix.
- the word prefix "AQ” may include a first substring “AQ” and a second substring "”. That is, each substring may include zero or more characters.
- the second substring in this example is empty.
- Computing device 10 may determine that the first substring "AQ" of the word prefix "AQ” matches a first siring in correction data 30.
- the first string may include one or more characters.
- computing device 10 may determine that the first substring "QC" matches a first string "AQ” in correction data 30
- Correction data 30 may include one or more relationships between strings.
- correction data 30 may include data indicating a relationship between the first string "AQ” in correction data 30 and a second string "C” in correction data 30.
- the second string may be a wildcard character "*" that may represent any character. That is, an alternative character may include a wildcard character that represents each possible character in a character set. For instance, the wildcard character "*" may represent any character ⁇ a...z ⁇ in the English alphabet character set.
- Computing device 10 may determine, based at least in part on the first string in the correction data "AQ", the second string "*" in the correction data that comprises at least one alternative character to be included in an alternative word prefix. That is, computing device 10 may generate an alternative word prefix "ACQ" that is comprised of the first substring "AQ” of the word prefix "AQ” and the second string “C” in correction data 30. In some examples, computing device 10 may splice and/or concatenate "AQ” and “C” to form the alternative word prefix "ACQ.”
- Correction data 30 may include data that indications the character position at which to splice and/or concatenate the word prefix "AC” and the second string "C”.
- Computing device 10 may store "ACQ” in a new token within active beam 120. Computing device 10 may also determine an alignment score for "ACQ” that is stored in the new token. Because “ACQ” matches the first three characters of the word “acquire” that is modeled in language model 28, the alignment score for "ACQ” may be higher than "AQ,” Thus, although the user may have performed a gesture with gesture path 132A corresponding to an erroneous spelling of "acquire,” computing device 10 may generate an alternative word prefix based on a misspelling of "acquire” that includes the portion of the word prefix "ACQ". As illustrated further in FIG. 5C, as the user continues the gesture to spell the remaining portion of "acquire,” the word prefix "ACQ” will result in higher alignment scores than, for example, "AQ.” A portion of example contents of active beam 120 are illustrated in Table 4.
- computing device 10 is shown as having detected gesture path I32B.
- the contents of active beam 120 may be represented by Table 4.
- Computing device 10 may determine alignment point 130C along gesture path 132B.
- Computing device 10 may, for each token in active beam 12.0, create a copy on each child node, in the example of FIG. 5C, tokens through tokenjo each have child nodes with letter keys "U" and "I" (e.g., in proximity to and/or within a predefined distance of alignment point 130C).
- For each created token copy computing device 10 may determine an alignment score as described in FIGS, 1-2 and illustrated in Table 4.
- the entries shown in Table 4 are similar in format to the entries shown in Tables 1-3.
- the alignment score for each token includes the alignment score for the previous letters and the alignment score for the current letter.
- tokens that includes alternative word prefi "ACQU" may be associated with the largest alignment score ASo + AS? + AS4. That is, the alignment score ASo + AS 2 + AS4 may be the largest alignment score in Table 4.
- computing device 10 may "look ahead” to additional nodes in language model 28, including a terminal node for "e”, that collectively indicate the candidate word “acquire.”
- computing device 10 as further described below, ma output "acquire” for display based on the word prefi "ACQU” being associated with the largest alignment score in active beam 120.
- Computing device 10 may continue to incrementally determine the one or more tokens as computing device 10 receives further indications of the gesture, thereby enabling a user to provide a single gesture to select a group of keys of a word or phrase.
- computing device 10 may determine whether the user has completed performing the gesture. In response to determining that the user has completed performing the gesture, computing device 10 may output a list of candidate words. The candidate words may be based at least in part on the one or more tokens. In some examples, the candidate words may be modeled in language model 28 and based on the contents of one or more dictionaries that include words of a written language. In some examples, computing device 10 may determine a subset of the list of candidate words which have the highest alignment scores (i.e., the predictions with the highest probability). Additionally, in some examples, computing device 10 may, at each subsequent alignment point, revise the alignment scores of the tokens contained in active beam 120 as described in the examples of FIGS 5A-5C.
- FIGS. 6A-6C are block diagrams illustrating further details of one example of a computmg device shown in FIG. 1 that is used to perform insertion error correction for gesture-based input, in accordance with one or more techniques of the present disclosure.
- a computing device may detect insertion errors in a continuous gesture and determine one or more al ternative hypotheses to improve the accuracy of word prediction. For instance, a user may have intended to input "bleep"; however, she may have erroneously gestured b-i-s-c-e-p.
- the techniques of the disclosure may consider an alternative hypothesis that the one or more characters (e.g., the "s" in “bicep") are accidental insertions and are therefore not part of the candidate word.
- the teeliniques of the disclosure may create an alternative hypothesis that allows the gesture to travel to other arbitrary letters (e.g., "s") before returning to the next intended letter (e.g., "c").
- the techniques of the disclosure may generate an alternative insertion hypothesis that allows the gesture to pass through another arbitrary letter (*) on the way to "f ' ("t"-"r"-"u”-*-”l”).
- the insertion error techniques are now further described with respect to FIGS. 6A-6C,
- FIGS. 6A-6C are block diagrams illustrating further details of one example of a computing device shown in FIGS. 1-3, in accordance with one or more techniques of the present disclosure.
- computing device 10 may include GUI 144, active beam 140, and next beam 142.
- GUI 100 may include graphical keyboard 146 which may include "B" key- MSA, "I” key i486, and "S" key 148C.
- gesture path 150 that includes gesture path portions 150A-150B and/or alignment points 152A- 152.C may not be visible during the performance of the techniques described herein.
- a user may desire to enter the word "bleep" into computing device 10 by performing a gesture at graphical keyboard 146.
- computing device 10 may incrementally receive indications of the gesture having a gesture path 152.
- computing device 10 is shown as having detected gesture path 15QA-150C.
- computing device 10 may determine alignment points 152A-152C along gesture path 150A-150B. In response to detecting gesture path 15QA-150B, computing device 10 may create one or more tokens and push the tokens into active beam 140.
- a portion of example contents of active beam 140 may be represented by Table 1 below.
- each row represents an individual token
- the index column represents a unique identifier for each token
- the parent index column represents the index vakte of the token to which the listed token is a child
- the letter key of the current node column represent the letter key represented by the current node of the token
- the letter chain column represents all of the letter keys represented by the nodes from an e try node to the current node of the token
- the alignment score column represents the alignment score of the token.
- the created tokens have indices of io-ii (e.g., corresponding to tokeno- tokeni).
- computing device 10 may create a copy of each token on its child nodes in response to additional indications of gesture input indicating gesture path 150B.
- Computing device 10 may, for example, create a copy of the token with index 0 on child node "BI" (i.e., tokeno) and child node "BU" (i.e., tokenj).
- computing device 10 may determine an alignment score as described in FIGS. 1-2.
- Computing de vice 10 may push each token copy to next beam 142, a portion of example contents of which may be represented by Table 2 bel ow.
- Table 2 The entries shown in Table 2 are similar in format to the e try shown in Table 1.
- tokens has cost value ASo + ASj token* has cost value AS] + AS/i and token 5 has cost value ASo + AS 5 .
- Computing device 10 may iterate or otherwise advance each token from active beam 140 by adding a character to each token in a similar manner and adding the updated token to next beam 142.
- Computing device 10 may subsequently determine whether active beam 140 is empty (i.e., contains no further tokens to be processed). In response to determining that active beam 140 is empty, computing device 10 may copy the contents of next beam 142 to active beam 140 of FIG. 6B and discard the contents of next beam 142.
- computing device 10 may determine at least one alternative character that is based at least in part on a misspelling that includes at least a portion of the word prefix. For example, as illustrated in Table 2, computing device 10 may generate an alternative word prefix that includes at least a substring of the word prefix "BIS". As one example, the alternative word prefix may include the substring "BI.” from the word prefix "BIS”. Computing device 10 may insert a placeholder value in the substring "BI” to generate alternative word prefix "BI ⁇ ". As illustrated in Table 2, the placeholder value is indicted by " ⁇ " in the alternative word prefix. A.
- placeholder value may be data that indicates to computing device 10 at least one arbitraiy character that the gesture may pass through, but that is not included in in one or more candidate words that are based on the alternative word prefix.
- the placeholder value " ⁇ " may indicate to computing device 10 to determine candidate words in language model 28 that are based on "BI” although the gesture may indicate the user has gestured to "BIS”.
- computing device 10 may determine candidate words (e.g., "bicep”) based on a prefix "bice” corresponding to
- computing device 10 may implement insertion error correction by refraining from advancing an alternative word prefix in a lexicon trie in response to one or more gestures. For instance, computing device 10 may generate an alternative w ord prefix that includes at least a substring of an existing word prefix. In the example of FIG. 6, computing device 10 may create a copy of word prefix "BI" selected from tokeno. Computing device 10 may store this copy as an alternative word prefix in a new token. In response to receiving a second gesture (e.g., gesture path 150B), computing device 10 may refrain from inserting one or more characters in the alternative word prefix. That is, computing device 10 may not advance the token that includes " ⁇ ' in the lexicon trie.
- a second gesture e.g., gesture path 150B
- computing device 10 allowas the gesture to pass through the arbitrary letter "S" (which may be a user error) on the way to "c".
- Computing device 10 may, in response to receiving an indication of a third gesture (e.g., I S0C) that is subsequent to gesture path 150B, may insert at least one character, such as "c" in the alternative word prefix, which would then include "bic".
- computing device 10 may skip advancing alternative word prefix for a portion of the gesture and then continue advancing the alternative word prefix by inserting additional characters (e.g., at the end of the word prefix) as computing device 10 determines additional gesture paths (e.g., portions of a continuous gesture path),
- computing device 10 may detect gesture path 150C. As described above, the contents of aciive beam 140 may be represented by Table 2. Computing device 10 may determine alignment point 152D along gesture path 150C. Computing device 10 may, for each token in active beam 140, create a copy on each child node. In the example of FIG. 6B shown in Table 3, iokeiie through tokens each have child nodes with letter keys "C". For each created token copy, computing device 10 may determine an alignment score as described in FIGS. 1-2. Computing device 10 ma push each token copy in to next beam 142, a portion of example contents of which may be represented by Table 3 below. Table 3
- the entries shown in Table 3 are similar in format to the entries shown in Table 1 and Table 2.
- the alignment score for each token includes the alignment score for the previous letters and the alignment score for the current letter.
- Computing device 10 may determine which, if any, of the tokens are on terminal nodes, e.g., the path of nodes from ihe root node to the terminal node comprising a string of characters that represent a word in language model 28. In some examples, if a token is on a terminal node, computing device 10 may select the word, e.g., to output the word for display.
- computing device 10 is shown as having detected gesture path I SOD.
- the contents of active beam 140 may be represented by Table 3.
- Computing device 10 may determine alignment point I52E along gesture path 150D, Computing device 10 may, for each token in active beam 140, create a copy on each child node.
- token ? through tokenjo each have child nodes with letter key "E" (e.g., in proximity to and/or within a predefined distance of alignment point 152D).
- For each created token copy computing device 10 may determine an alignment score as described in FIGS. 1-2.
- Computing device 10 may push each token copy into next beam 142, the contents of which may be represented by Table 4 below r .
- the entries shown in Table 4 are similar in format to the entries shown in Tables 1-3.
- the alignment score for each token includes the alignment score for the previous letters and the alignment score for the current letter.
- token, ! that includes alternative word prefix "BI ⁇ CE" may be associated with the largest alignment score AS j + AS 4 + AS ? + ASn. That is, the alignment score ASi + AS 4 + AS? + ASn may be the largest alignment score in Table 4.
- computing device 10 may "look ahead” to additional nodes in language model 28, including a terminal node for "p", that collectively indicate the candidate word “bleep.” m some examples, computing device 10, as further described below, may output "bleep” for display based on the % r ord prefix
- Computing device 10 may continue to incrementally determine the one or more tokens as computing device 10 receives further indications of the gesture, thereby enabling a user to provide a single gesture to select a group of keys of a word or phrase.
- computing device 10 may determine whether the user has completed performing the gesture, in response to determining that the user has completed performing the gesture, computing device 10 may output a list of candidate words.
- the candidate words may be based at least in part on the one or more tokens.
- the candidate words may be modeled in language model 28 and based on the contents of one or more dictionaries that include words of a written language.
- computing device 10 may determine a subsei of the list of candidaie words which have the highesi alignment scores (i.e., the predictions with the highest probability). Additionally, in some examples, computing device 10 may, at each subsequent alignment point, revise the alignment scores of the tokens contained in active beam 102 as described in the examples of FIGS 6A-6C.
- FIGS. 7A--7C are block diagrams illustrating further details of one example of a computing de vice shown in FIG. 1 that is used to perform transposition error correction for gesture-based input, in accordance with one or more techniques of the present disclosure.
- a computing device may detect transposition errors in a continuous gesture and determine one or more alternative hypotheses to improve the accuracy of word prediction. That is, the user may perform a gesture that interchanges the position of two characters, e.g., gesturing t-r-h-i-f-t when the user intended to enter "thrift.” In other words the user may have erroneously gestured the "r" key before for the "h” key.
- Another example may include gesturing w-i-e-r-d when the user intended to enter "weird.” That is, the user may have erroneously gestured the "i" key before for the "e” key.
- the techniques of the disclosure may, for one or more characters in a candidate word, consider an alternative hypothesis that the next two letters are transposed. For the "wierd” misspelling example, when the techniques of the disclosure compare the gesture to the dictionary word "weird", the techniques will also consider the alternative that the second and third letters are accidentally switched from “ei” to "ie”. The techniques then determine whether the original "wfeij" interpretation or the transposition-corrected "w[ie]" interpretation is the best geometric match to the gesture. Once the most probable or highest alignment scoring hypothesis is identified, the techniques continue the alignment to the next letter in the word ("r"). The transposition error techniques are now further described with respect to FIGS. 6A-6C.
- FIGS. 7A-7C are block diagrams illustrating further details of one example of a computing device shown in FIGS. 1-3, in accordance with one or more techniques of the present disclosure.
- computing device 10 may include GUI 160, active beam 1 62, and next beam 164.
- GUI 160 may include graphical keyboard 166 which may include "R" key 168A and "T" key 168B.
- gesture path 172 ihai includes gesture path portion 17A and/or alignment points I 70A-170B may not be visible during the performance of the techniques described herein.
- a user may desire to enter the word "thrift" into computing de vice 10 by performing a gesture at graphical keyboard 166, As previously discussed, while the user performs the gesture at a presence-sensitive input device, computing device 10 may incrementally receive indications of the gesture having a gesture path 172, In the example of FIG, 7 A, computing device 10 is shown as having detected gesture path 172 A.
- computing device 10 may determine alignment points 170A-170B along gesture path 172A. In response to detecting gesture path 172A, computing device 10 may create one or more tokens and push the tokens into active beam 162. A portion of example contents of active beam 162 may be represented by Table 1 below.
- each row represents an individual token
- the index column represents a unique identifier for each token
- ihe parent index column represents the index value of the token to which the listed token is a child
- the letter key of the current node column represent the letter key represented by the current node of the token
- the letter chain column represents a ll of the ieiter keys represented by ihe nodes from an entry node to the current node of the token
- the alignment score column represents the alignment score of the token.
- the created tokens have indices of io-ii (e.g., corresponding to tokeno- token;).
- computing device 10 may create a copy of each token on its child nodes in response to additional indications of gesture input indicating gesture path 172 A.
- Computing device 10 may, for example, create a copy of the token with index 0 on child node "TR" (i.e., tokeno) and child node "GR" (i.e., tokenj).
- computing device 10 may determine an alignment score as described in FIGS. 1-2.
- Computing device 10 may push each token copy to next beam 1 64, a portion of example contents of which may be represented by Table 2 below.
- Table 2 The entries shown in Table 2 are similar in format to the entry shown in Table 1.
- token- has cost value ASo + AS token* has cost value ASi + AS4.
- Computing device 10 may iterate or otherwise advance each token from active beam 162 by adding a character to each token in a similar manner and adding the updated token to next beam 164.
- Computing device 10 may subsequently determine whether active beam 162 is empty (i.e., contains no further tokens to be processed). In response to determining that active beam 162 is empty, computing device 10 may copy the contents of next beam 164 to active beam 162 of FIG. 7B and discard ihe contents of next beam 164,
- computing device 10 may detect gesture path 172B. As described above, the contents of active beam 162 may be represented by- Table 2. Computing device 10 may determine alignment point 170C along gesture path 172B. Computing device 10 may, for each token in active beam 162, create a copy on each child node. In the example of FIG. 7B shown in Table 3, tokene through token 7 each have child nodes with letter keys "H”. Tokens each has a child node with letter keys "G”. For each created token copy, computing device 10 may determine an alignment score as described in FIGS. 1-2. Computing device 1 0 may push each token copy in to next beam 164, a portion of example contents of which may be represented by Table 3 below. Table 3
- the entries shown in Table 3 are similar in format to the entries shown in Table 1 and Table 2.
- the alignment score for each token includes the alignment score for the previous letters and the alignment score for the current letter.
- Computing device 10 may determine which, if any, of the tokens are on terminal nodes, e.g., the path of nodes from the root node to the terminal node comprising a string of characters that represent a word in language model 28. In some examples, if a token is on a terminal node, computing device 10 may select the word, e.g., to output the word for display.
- computing device 10 may determine that the aiignment score associated with a word prefix fails to satisfy a threshold. For instance, computing device 10 may determine that the alignment score is less than the threshold. As one example, computing device 10 may determine that the alignment score for 'TRH," AS] + AS + ASg, does not satisfy a threshold. In some examples, computing device 10 may determine that a plurality of alignment scores associated with respective word prefixes fail to satisfy a threshold. For instance, computing device 10 may determine that the alignment scores for TRH, GRH, and TRG each fail to satisfy a threshold.
- computing device 10 may determine at least one alternative character that is based at least in part on a misspelling that includes at least a portion of the word prefix.
- the word prefix "TRH” may include a first substring “T” and a second substring “RH”. That is, each substring may include zero or more characters.
- the second substring in this example includes two characters "RH”.
- Computing device 10 may determine a transposition of the second substring, wherein character positions of at least two characters of the second substring are transposed in the transposition.
- the transposition may include one or more characters of the second substring that have the character positions of the characters inverted or changed.
- At least one alternative character may be included in the transposition, e.g., "RH".
- computing device 10 may determine that the second substring "RH” of the word prefix "TRH” matches a first string in correction data 30.
- the first string may include one or more characters.
- computing device 10 may determine that the second substring "RH” matches a first string "RH” in correction data 30.
- Correction data 30 may include one or more relationships between strings. For instance, correction data 30 may include data indicating a relationship between the first string "RH” in correction data 30 and a second string "HR” in correction data 30.
- the second string "HR” in correction data 30 may be a transposition of the first string "RH” in correction data 30.
- correction data 30 may include data that causes keyboard module 22 to transpose a substring of a word prefix.
- the data may cause keyboard module 22 to determine a substring of a word prefix and transpose the substring.
- keyboard module 2.2 may transpose the two characters that follow a currently determined character in a word prefix.
- keyboard module 22 may determine that a token includes the character "wei” and may transpose the substring "ei” to generate an alternative word prefix "wie”.
- computing device 10 may automatically transpose "RH” to "HR” to generate an alternative word prefix.
- computing device 10 may automatically invert or otherwise change the character positions of at least two characters in the word prefix to generate the alternative word prefix.
- computing device 10 may "look ahead" in a lexicon trie to determine one or more nodes in a path the trie that correspond respectively to characters. Computing device 10 may then generate a transposition of one or more of the characters corresponding to the nodes of the path. For example, computing device 10 may determine a token includes the word prefix "t". Computing device 10 may determine that the token is currently on the "t" node of a path in a lexicon trie from root t. Computing de vice 10 may receive an indication of a gesture traversing the "R" key of graphical keyboard 16B, in which case computing device 10 may advance the tokens of the active beam and generate a token copy that includes the word prefix "tr".
- computing device 10 may also look ahead to one or more nodes of the lexicon trie from the node that includes "w” to determine an alternative path, such as root ⁇ i ⁇ h.
- computing device 10 may determine ihe alternative path based on the character "r" that corresponds to the "R" key.
- correction data 30 may indicate a relationship between “r” and “h” and/or between “tr” and “th”.
- computing device 10 may generate a token that includes an alternative word prefix "in”, which computing device 10 may include in active beam 162.
- computing device 10 may transpose multiple characters along a path in the lexicon trie to determine how well the transposed characters of the word prefix align to a gesture. For instance, computing device 10 may store a token that includes the word prefix "w". Computing device 10 may determine the next two nodes in a path of the lexicon trie include the characters "e" and "i" following node "w". Computing device 10 may generate an alternative word prefix that includes the transposition of the next two characters "ei” to generate an alternative word prefix "wie”. Computing device 10 may determine an alignment score for "wie” based on the gesture path. In some examples, computing device 10 may assign ihe alignment score for "wie” to ihe token for "wei” and apply a penalty to the score for "wei”.
- computing device 10 may generate an alternative word prefix "THR" that is comprised of the first substring “T” of the word prefix "TRH” and the second string “HR” based on correction data 30 or otherwise automatically transposed by computing device 10 as "HR”.
- computing device 10 may concatenate "T” and "HR” to form the alternative word prefix "THR.”
- Computing device 10 may store "THR” in a new token within active beam 162, Computing device 10 may also determine an alignment score for "THR" that is stored in the new token.
- the alignment score for "THR” may be higher than “TRH.”
- compu ting device 10 may generate an alternative w ord prefix based on a misspelling of "thrift” that includes the portion of the word prefix "THR”.
- FIG, 7C as the user continues the gesture to spell the remaining portion of "thrift,” the word prefix "THR” will result in higher alignment scores than, for example, "TRH.”
- Table 4 A portion of example contents of activ e beam 162 are illustrated in Table 4.
- computing device 10 is shown as having detected gesture path 172C.
- the contents of active beam 162 may be represented by Table 4.
- Computing device 10 may determine alignment point I 70D along gesture path 172C.
- Computing device 10 may, for each token in active beam 162, create a copy on each child node.
- tokens through tokenp each have child nodes with letter keys "U" and "I" (e.g., in proximity to and/or within a predefined distance of alignment point 170D),
- For each created token copy computing device 10 may determine an alignment score as described in FIGS. 1-2.
- Computing device 10 may push each token copy into next beam 164, the contents of which may be represented by Table 5 below.
- the entries shown in Table 5 are similar in format to the entries shown in Tables 1 -4.
- the alignment score for each token includes the alignment score for the previous letters and the alignment score for the current letter.
- tokens that includes alternative word prefix "THRI" may be associated with the largest alignment score AS ; + A84 + A89 + AS 10. That is, the alignment score AS ⁇ + AS 4 + A SQ + AS10 may be the largest alignment score in ' Table 5.
- computing device 10 may "look ahead” to additional nodes in language model 2.8, including a terminal node for "t", that collectively indicate the candidate word "thrift.”
- computing device 10 may output "thrift” for display based on the word prefix "THRI” being associated with the largest alignment score in active beam 162.
- Computing device 10 may continue to incrementally determine the one or more tokens as computing device 10 receives further indications of the gesture, thereby enabling a user to provide a single gesture to select a group of keys of a word or phrase.
- computing device 10 may determine whether the user has completed performing the gesture, in response to determining that the user has completed performing the gesture, computing device 10 may output a list of candidate words.
- the candidate words may be based at least in part on the one or more tokens.
- the candidate words may be modeled in language model 28 and based on the contents of one or more dictionaries that include words of a written language.
- computing de vice 10 may determine a subset of the list of candidate words which have the highest alignment scores (i.e., the predictions with the highest probability). Additionally, in some examples, computing device 10 may, at each subsequent alignment point, revise the alignment scores of the tokens contained in active beam 162. as described in the examples of FIGS 7A-7C.
- FIG. 8 is a flowchart illustrating example operations of a computing device configured to perform error correction of input using gesture-based input in accordance with techniques of the disclosure. For purposes of illustration, the example operations are described below within the context of computing device 10, as shown in FIGS. 1 and 2.
- computing device 10 may incrementally receive indications of user input 180 that are detected in response to a user performing a gesture (180).
- computing device 10 may select each token in an active beam, create one or more copies of the token and advance the respective token copies to different child nodes in a lexicon trie as described in FIGS. 1-2 (184).
- computing device 10 may determine whether one or more alignment scores for one or more respective tokens satisfy a threshold (186). For instance, if the respective alignment scores for one or more tokens satisfy a threshold (e.g., the alignment scores are each greater than the threshold) (1 0), computing device 10 may determine one or more candidate words without determining one or more alternative gesture alignments (199).
- a threshold e.g., the alignment scores are each greater than the threshold
- computing device 10 perform one or more techniques to generate alternative word prefixes.
- computing device 10 store information that indicates the number of corrections applied to a word prefix. For instance, computing device 10 may determine how many error correction operations were applied to a word prefix. If, for example, computing device 10 generated a first alternative word prefix from a word prefix using a error correction operation (e.g., substitution error correction) and subsequently generated a second alternative word prefix from the first alternative word prefix using a second error correction operation (e.g., transposition error correction), computing device 10 may store information that indicates a quantity of two error correction techniques were applied to the second alternative word prefix. In some examples, the quantity of error correction techniques applied to a word prefix may be stored in the token that includes the word prefix.
- a error correction operation e.g., substitution error correction
- a second error correction operation e.g., transposition error correction
- computing device 10 may store information that indicates a quantity of two error correction techniques were applied to the second alternative word prefix. In
- computing device 10 may apply a first error correction operation to a word prefix based at least in part on a substring of the word prefix.
- Computing device 10 may generate an alternative word prefix when applying the first error correction operation and store information in the token that includes the word prefix that indicates a quantity of one error correction operation has been applied to generate the alternative word prefix.
- computing device 10 may determine a quantity of error correction operations applied to the word prefix (192).
- Computing device 10 may determine that the quantity of error correction operations indicated in the token satisfies a threshold (e.g., is greater than a threshold or greater than or equal to a threshold) and refrain from applying an error correction operation to the word prefix (194).
- a threshold e.g., is greater than a threshold or greater than or equal to a threshold
- computing device 10 may determine an alternative alignment score based at least in part on an alternative character or group of characters that is based on a misspelling that includes at least a portion of the word prefix (198). In some examples, computing device 10 may determine one or more candidate words based on the alternative alignment score. In this way, as computing device 10 performs corrections and/or generates alternative alignment scores and'or alternative word prefixes, computing device 10 may determine the quantity of error correction operations (e.g., different techniques) that have been applied to a generate an alternative word prefix. If a threshold number of operations have been applied by computing device 10 to generate an alternative word prefix, computing device 10 can refrain from generating additional alternative word prefixes.
- a threshold e.g., is less than the threshold
- computing device 10 may determine whether a word prefix has a degree of similarity to a word modeled in language model 28, and if the degree of similarity does not satisfy a threshold, computing device 10 may refrain from applying one or more error correction operations to the word prefix. In this way, computing device 10 may avoid performing unnecessary processing on word prefixes that are more dissimilar from one or more words in language model 28 than the threshold. As an example, computing device 10, may determine at least one alternative character that is based at least in part on a misspelling that includes at least a portion of the word prefix by applying a first error correction operation based at least in part on a substring of the word prefix.
- computing device 0 may determine a degree of similarity between the word prefix and at least one candidate word in lexicon (e.g., as modeled in language model 28.
- the degree of similarity may be included within a range of degrees of similarity.
- Computing device 10 may, responsive to determining that the degree of similarity does not satisfy a threshold (e.g., is less than the threshold), refrain from applying an error correction operation to the word prefix. If, however, the degree of similarity does satisfy the threshold (e.g., is greater than or equal to the threshold), computing device 10 may apply one or more error correction operations to the word prefix.
- FIG. 9 is a flowchart illustrating example operations of a computing device configured to perform error correction of input using gesture-based input, in accordance with techniques of the disclosure. For purposes of illustration, the example operations are described below within the context of computing device 10, as shown in FIGS. 1 and 2.
- computing device 10 may initially output for display, a graphical keyboard comprising a plurality of keys (200).
- Computing device 10 may further receive an indication of a gesture detected at a presence- sensitive input device (202). For instance, computing device 10 may recei ve one or more indications of a continuous gesture input performed by a user at a presence-sensitive input device.
- computing device 10 may determine an alignment score that is based at least in part on a word prefix and at least one alignment point traversed by the gesture (204). In some examples, the alignment score represents a probability that the at least one alignment point indicates a key of the plurality of keys.
- Computing device 10 may determine whether the alignment score satisfies a first threshold (206). If the alignment score satisfies the threshold (209), computing device 10 may output one or more candidate words based at least in part on the word prefix (216). If, however, the alignment score does not satisfy a first threshold, computing device 10 may determine at least one alternative character that is based at least in part on a misspelling that includes at least a portion of the word prefix (208).
- computing device 1 0 may determine an alternative alignment score that is based at least in part on the alternative character (210).
- computing device 10 may output for display, based at least in part on the alternative alignment score, a candidate word. For instance, computing device 10 may determine whether the alignment score satisfies a second threshold (212). If the alignment score does satisfy a second threshold (213), computing device 10 may output one or more candidate words for display at least in part on the alternative character (2.16). In other examples, if the alignment score does not satisfy a second threshold (215), computing device 10 may receive subsequent indications of the gesture detected at the presence-sensitive input device (202). In other words, computing de vice 10 may not output one or more candidate words based on the alternative character at that time.
- FIG. 10 is a flowchart illustrating example operations of a computing device configured to perform error correction of input using gesture-based input, in accordance with techniques of the disclosure. For purposes of illustration, the example operations are described below within the context of computing device 10, as shown in FIGS. 1 and 2.
- Computing device 10 may output for display, a graphical keyboard comprising a plurality of keys (230).
- Computing device 10 may also receive an indication of a gesture detected at a presence-sensitive input device (232).
- computing device 10 may determine an alignment score that is based at least in part on a word prefix and an alignment point traversed by the gesture, wherein the alignment score represents a probability thai the alignment point indicates a key of the plurality of keys (234).
- Compitting device 10 may determine at least one alternative character that is based at least in part on a misspelling that includes at least a portion of the word prefix (236).
- computing device 10 may determine an alternative alignment score thai is based at least in part on the alternative character (238).
- Computing device 10 may also output for display, based at least in part on the alternative alignment score, a candidate word (240).
- the operations may include determining, by the computing device, that the second substring of the word prefix matches a first string in correction data; determining, by the computing device and based at least in part on the first string in the correction data, a second string in the correction data that comprises the at least one alternative character; and generating, by the computing de vice, an alternative word prefix comprising the first substring of the word prefix and the second string in the correction data.
- the second string in the correction data may include a phonetic substitution of the second substring in the word prefix.
- the operations may include determining, by the computing device, a substring of the word prefix that matches a first string in correction data; determining, by the computing device and based at least in part on the first string in the correction data, at least one alternative character; and generating, by the computing device, an alternative word prefix comprising the word prefix and the at least one alternative character.
- the alternative character may include a wildcard character that represents each possible character in character set.
- the operations may include generating, by the computing device, an alternative word prefix comprising at least a substring of the word prefix; and inserting, by the computing device, at least one placeholder value in the alternative word prefix, wherein the at least one placeholder value indicates at least one arbitrar '- character that is not included in in one or more candidate words that are based on the alternative word prefix.
- the operations may include generating, by the computing device, an alternative word prefix comprising at least a substring of the word prefix; in response to receiving an indication of a second gesture that is subsequent to the first gesture, refraining, by the computing device, from inserting one or more characters in the alternative word prefix; and in response to receiving an indication of a third gesture that is subsequent to the second gesture, inserting, by the computing device, at least one character in the alternative word prefix.
- the operations may include generating, by the computing device, an alternative word prefix comprising at least a substring of the word prefix; in response to receiving an indication of a second gesture that is subsequent to the first gesture, refraining, by the computing device, from inserting one or more characters in the alternative word prefix; and in response to receiving an indication of a third gesture that is subsequent to the second gesture, inserting, by the computing device, at least one character in the alternative word prefix.
- the operations may include determining, by the computing device, a transposition of the second substring, wherein character positions of at least two characters of the second substring are transposed in the transposition, wherein the at least one alternative character is included in the transposition; and generating, by the computing device, an alternative word prefix comprising at least the transposition.
- the operations may include determining, by the computing device, that at least one of the first substring and the second substring matches a string in correction data; and determining, by the computing device and based at least in part on the match, the transposition.
- the operations may include wherein determining at least one alternative character comprises applying a first error correction operation based at least in part on a substring of the word prefix, the method, further comprising: responsive to receiving a subsequent indication of a gesture detected at a presence-sensitive input device, determining, by the computing device, a quantity of error correction operations applied to the word prefix; and responsive to determining that the quantity of error correction operations satisfies a threshold, refraining, by the computing device, from applying an error correction operation to the word prefix.
- the operations may include determining, by the computing device and in response to determining the at least one alternative character, a penalty value; and determining, by the computing device and based at least in part on the penalty value, the alternative alignment score.
- the operations may include determining, by the computing device, a type of an error correction operation from a plurality of error correction operations; and selecting, by the computing device, the penalty value from a plurality of penalty v alues, wherein each penalty va lue in the piuraiity of penalty values is ordered in a ranked ordering, wherein each penalty value is associated with at least one type of error correction operation.
- the operations may include in response to determining that the alternative alignment score satisfies a threshold, outputting, by the computing device and for display, the candidate word based at feast in part on the alternative character, wherein the threshold comprises a value that is equal to a quantity of a first subset of word prefixes associated with one or more alignment scores that are greater than alignment scores associated word prefixes in a second subset of word prefixes.
- the operations may include, responsive to receiving a subsequent indication of a gesture detected at a presence -sensitive input device, determining, by the computing device, determining a degree of similarity between the word prefix and at least one candidate word in a lexicon, wherein the degree of similarity is within a range of degrees of similarity; and responsive to determining that the degree of similarity does not satisfy a threshoid, refraining, by the computing device, from applying an error correction operation to the word prefix.
- Example 1 A method comprising: outputting, by a computing device and for display, a graphical keyboard comprising a plurality of keys; receiving, by the computing device, an indication of a gesture detected at a presence-sensitive input device; determining, by the computing device, an alignment score that is based at least in part on a word prefix and an alignment point traversed by the gesture, wherein the alignment score represents a probability that the alignment point indicates a key of the plurali ty of keys; de termining, by the computing device, at least one alternative character that is based at least in part on a misspelling that includes at least a portion of the word prefix; determining, by the computing device, an alternative alignment score that is based at least in part on the alternative character; and outputting, by the computing device, for display, and based at least in part on the alternative alignment score, a candidate word,
- Example 2 The method of Example 1, wherein the word prefix includes a first substring and a second substring, the second substring including the at least one character, and wherein determining at least one alternative character further comprises: determining, by the computing device, that the second substring of the word prefix matches a first string in correction data; determining, by the computing device and based at least in part on the first string in the correction data, a second string in the correction data that comprises the at least one alternative character; and generating, by the computing device, an alternative word prefix comprising the first substring of the word prefix and the second string in the correction data.
- Example 3 The method of any of Examples 1-2, wherein the second string in the correction data comprises a phonetic substitution of the second substring in the word prefix,
- Example 4 The method of any of Examples 1-3, further comprising: determining, by the computing device, a substring of the word prefix that matches a first string in correction data; determining, by the computing device and based at least in part on the first string in the correction data, at least one alternative character; and generating, by the computing device, an alternative word prefix comprising the word prefix and the at least one alternative character.
- Example 5 The method of any of Examples 1-4, wherein the alternative character comprises a wildcard character that represents each possible character in character set,
- Example 6 The method of any of Examples 1-5, wherein the at least one alternative character comprises at least one placeholder value, wherein determining at least one alternative character further comprises: generating, by the computing device, an alternative word prefix comprising at least a substring of the word prefix; and inserting, by the computing device, at least one placeholder value in the alternative word prefix, wherein the at least one placeholder value indicates at least one arbitrary character that is not included in in one or more candidate words that are based on the alternative word prefix. 5 [0196]
- Example 7 The method of any of Examples 1-6, wherein the gesture is a first gesture, the method further comprising: generating, by the computing device, an alternative word prefix comprising at least a substring of the word prefix;
- Example 8 The method of any of Examples 1 -7, wherein the word prefix includes a first substring and a second substring, wherein determining at least one alternative character further comprises: determining, by the computing device, a transposition of the second substring, wherein charac ter posi tions of at least two characters of the second substring are transposed in the transposition, wherein the at least one alternative character is included in the transposition; and generating, by the computing device, an alternative word prefix comprising at least the transposition.
- Example 9 The method of any of Examples 1-8, further comprising: determining, by the computing device, that at least one of the first substring and the second substring matches a string in correction data; and determining, by the computing de vice and based at least in part on the match, the transposition.
- Example 10 The method of any of Examples 1 -9, wherein determining at least one alternative character comprises applying a first error correction operation based at least in part on a substring of the word prefix, the method, further comprising: responsive to receiving a subsequent indication of a gesture detected at a presence-sensitive input device, determining, by the computing device, a quantity of error correction operations applied to the word prefix; and responsive to determining that the quantity of error correction operations satisfies a threshold, refraining, by the computing device, from applying an error correction operation to the word prefix.
- Example 11 The method of any of Examples 1-10, wherein determining the altemaiive alignment score that is based at least in part on the alternative character further comprises: determining, by the computing device and responsive to determining the at least one alternative character, a penalty value; and determining, by the computing device and based at least in part on the penalty value, the alternative alignment score.
- Example 12 The method of any of Examples 1 - 1 1 , wherein determining the at least one alternative character comprises determining at least one error correction operation based at least in part on a substring of the word prefix, the method further comprising: determining, by the computing device, a type of an error correction operation from a plurality of error correction operations; and selecting, by the computing device, the penalty value from a plurality of penalty values, wherein each penalty value in the plurality of penalty values is ordered in a ranked ordering, wherein each penalty value is associated with at feast one type of error correction operation.
- Example 13 The method of any of Examples 1-12, wherein outputting the candidate word based at least in part on the alternative character, further comprises: responsive to determining that the alternative alignment score satisfies a threshold, outputting, by the computing device and for display, the candidate word based at least in part on the alternative character, wherein the threshold comprises a value that is equal to a quantity of a first subset of word prefixes associated with one or more alignment scores that are greater than alignment scores associated word prefixes in a second subset of word prefixes.
- Example 14 The method of any of Examples 1 -13, wherein determining at least one alternative character comprises applying a first error correction operation based at least in part on a substring of the word prefix, the method further comprising: responsive to receiving a subsequent indication of a gesture detected at a presence-sensitive input device, determining, by the computing device, determining a degree of similarity between the word prefix and at least one candidate word in a lexicon, wherein the degree of similarity is within a range of degrees of similarity; and responsive to determining that the degree of similarity does not satisfy a threshold, refraining, by the computing device, from applying an error correction operation to the word prefix.
- Example 15 The method of any of Examples 1 - 14, further comprising: responsive to determining, by the computing device, that the alignment score fails
- determining the at least one alternative character thai is based at least in part on the misspelling that includes at least the portion of the word prefix
- Example 16 A computer-readable storage medium encoded with instructions that, when executed, cause at least one processor to: output for display, a graphical keyboard comprising a plurality of keys: receive an indication of a gesture detected at a presence-sensitive input device; determine an alignment score thai is based at least in part on a word prefix and an alignment point traversed by the gesture, wherein the alignment score represents a probability that the alignment point indicates a key of the plurality of keys; determine at least one alternative character that is based at least in part on a misspelling that includes at least a portion of the word prefix; determine an alternative alignmeni score that is based at least in part on the alternative character; and output for display, and based at least in part on the alternative alignment score, a candidate word based at least in part on the alternative character.
- Example 17 The computer-readable storage medium of Example 16, wherein the word prefix includes a first substring and a second substring, the second substring including the at least one character, and wherein the computer- readable storage medium is encoded with instructions that, when executed, cause at least one processor to: determine that the second substring of the word prefix matches a first string in correction data; determine based at least in part on the first string in the correction data, a second stiing in the correction data that comprises the at least one alternative character; and generate an alternative word prefix comprising the first substring of the word prefix and the second string in the correction data.
- Example I S The computer-readable storage medium of any of Examples 16-17, wherein the at least one alternative character comprises at least one placeholder value, and wherein the computer-readable storage medium is encoded with instructions that, when executed, cause at least one processor to: generate an alternative word prefix comprising at least a substring of the word prefix; and insert at least one placeholder value in the alternative word prefix, wherein the at least one placeholder value indicates at least one arbitrary character that is not included in in one or more candidate words that are based on the alternati ve word prefix.
- Examples 19 The computer-readable storage medium of any of Examples 16- 18, wherem the gesture is a first gesture, wherein the computer-readable storage medium is encoded with instructions that, when executed, cause at least one processor to: generate an alternative word prefix comprising at least a substring of the word prefix; responsive to receiving an indication of a second gesture that is subsequent to the first gesture, refrain from inserting one or more characters in the alternative word prefix; and responsive to receiving an indication of a third gesture that is subsequent to the second gesture, insert at least one character in the alternative word prefix.
- Example 20 The computer-readable storage medium of any of Examples 16-19, wherein the word prefix includes a first substring and a second substring, wherein the computer-readable storage medium is encoded with instructions that, when executed, cause at least one processor to: determine a transposition of the second substring, wherein character positions of at least two characters of the second substring are transposed in the transposition, wherein the at least one alternative character is included in the transposition; and generate an alternative word prefix comprising at least the transposition.
- Example 21 A computing device comprising at least one processor, wherein the at least one processor is configured to: output for display a graphical keyboard comprising a plurality of keys; receive an indication of a gesture detected at a presence-sensitive input device; determine an alignment score that is based at least in part on a word prefix and an alignment point traversed by the gesture, wherein the alignment score represents a probability that the alignment point indicates a key of the plurality of keys; responsive to determining that the alignment score fails to satisfy a threshold, determine at least one alternative word prefix; determine an alternative alignment score that is based at least in part on the at least one alternative word prefix; and output for display, and based at least in part on the alternative alignment score, a candidate word.
- Example 22 The computing device of Example 21, wherein the word prefix includes a first substring and a second substring, the second substring, and
- the at least one processor is configured to: determine thai the second substring of the word prefix matches a first string in correction data; determine based at least in part on the first string in the correction data, a second string in the correction data; and generate an alternative word prefix comprising the first substring of the word prefix and the second string in the correction data.
- Example 23 The computing device of any of Examples 21 -22, wherein the at least one processor is configured to: generate the alternative word prefix comprising at least a substring of the word prefix; and insert at least one placeholder value in the alternative word prefix, wherein the at least one placeholder value indicates at least one arbitrary character that is not included in in one or more candidate words that are based on the alternative word prefix,
- Example 24 The computing device of any of Examples 21-23, wherein the gesture is a first gesture, wherein the at least one processor is configured to:
- the alternative word prefix comprising at least a substring of the word prefix; responsive to receiving an indication of a second gesture that is subsequent to the first gesture, refrain from inserting one or more characters in the alternative word prefix ; and responsive to receiving an indication of a third gesture that is subsequent to the second gesture, insert at least one character in the alternative word prefix.
- Example 25 The computing device of any of Examples 21 -24, wherein the word prefix includes a first substring and a second substring, wherein the at least one processor is configured to: determine a transposition of the second substring, wherein character positions of at least two characters of the second substring are transposed in the transposition, wherein the at least one alternative character is included in the transposition; and generate an alternative word prefix comprising at least the transposition.
- Example 26 A computing device comprising: means for outputting for display a graphical keyboard comprising a plurality of keys; receive an indication of a gesture detected at a presence-sensitive input device; means for determining an alignment score that is based ai least in part on a word prefix and an alignment point traversed by the gesture, wherein the alignment score represents a probability that the alignment point indicates a key of the plurality of keys; means for,
- determining at least one alternative word prefix means for determining an alternative alignment score that is based at least in part on the at least one alternative word prefix; and means for outputting for display, and based at feast in part on the alternative alignment score, a candidate word.
- Example 27 The computing device of Example 26 comprising means for performing any of the methods of Examples 2-15.
- Example 28 A computer-readable storage medium encoded with instructions that, when executed, cause at least one processor of a computing device to perform the method recited by any of Examples 1-15.
- Example 29 A device comprising: at least one processor; and at least one module operable by the at least one processor to perform the method recited by any of Examples 1-15.
- Computer-readable media may include computer-readable storage media, which corresponds to a tangible medium such as data storage media, or communication media including any medium that facilitates transfer of a computer program from one place to another, e.g., according to a communication protocol.
- computer-readable media generally may correspond to (1) tangible computer-readable storage media, which is non- transitory or (2) a communication medium such as a signal or carrier wave.
- Data storage media may be any avail ble media that can be accessed by one or more computers or one or more processors to retrieve instructions, code and/or data structures for implementation of ihe techniques described in this disclosure.
- a computer program product may include a computer-readable medium.
- such computer- readable storage media can comprise RAM, ROM, EEPROM, CD-ROM or other optical disk storage, magnetic disk storage, or other magnetic storage devices, flash memory, or any other medium that can be used to store desired program code in the form of instructions or data structures and that can be accessed by a computer. Also, any connection is properly termed a computer -readable medium.
- coaxial cable, fiber optic cable, twisted pair, digital subscriber line (DSL), or wireless technologies such as infrared, radio, and microwave are included in the definition of medium.
- DSL digital subscriber line
- computer-readable storage media and data storage media do not include connections, carrier waves, signals, or other transient media, but are instead directed to non-transient, tangible storage media.
- Disk and disc includes compact disc (CD), laser disc, optical disc, digital versatile disc (DVD), floppy disk and Blu-ray disc, where disks usually reproduce data magnetically, while discs reproduce data optically with lasers. Combinations of the above should also be included within the scope of computer-readable media.
- processors such as one or more digital signal processors (DSPs), general purpose microprocessors, application specific integrated circuits (ASICs), field programmable logic arrays (FPGAs), or other equivalent integrated or discrete logic circuitry.
- DSPs digital signal processors
- ASICs application specific integrated circuits
- FPGAs field programmable logic arrays
- processors may refer to any of the foregoing structure or any other structure suitable for implementation of the techniques described.
- the functionality described may be provided within dedicated hardware and/or software modules. Also, the techniques could be fully implemented in one or more circuits or logic elements.
- the techniques of this disclosure may be implemented in a wide variety of devices or apparatuses, including a wireless handset, an integrated circuit (IC) or a set of ICs (e.g., a chip set).
- IC integrated circuit
- a set of ICs e.g., a chip set.
- Various components, modules, or units are described in this disclosure to emphasize functional aspects of devices configured to perform the disclosed techniques, but do not necessarily require realization by different hardware units. Rather, as described above, various units may be combined in a hardware unit or provided by a collection of interoperative hardware units, including one or more processors as described above, in conjunction with suitable software and/or firmware.
Abstract
Description
Claims
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201361819363P | 2013-05-03 | 2013-05-03 | |
US13/907,614 US9081500B2 (en) | 2013-05-03 | 2013-05-31 | Alternative hypothesis error correction for gesture typing |
PCT/US2014/036459 WO2014179624A1 (en) | 2013-05-03 | 2014-05-01 | Alternative hypothesis error correction for gesture typing |
Publications (2)
Publication Number | Publication Date |
---|---|
EP2992406A1 true EP2992406A1 (en) | 2016-03-09 |
EP2992406B1 EP2992406B1 (en) | 2022-01-12 |
Family
ID=51841200
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
EP14731439.7A Active EP2992406B1 (en) | 2013-05-03 | 2014-05-01 | Alternative hypothesis error correction for gesture typing |
Country Status (7)
Country | Link |
---|---|
US (3) | US9081500B2 (en) |
EP (1) | EP2992406B1 (en) |
KR (1) | KR101750969B1 (en) |
CN (1) | CN105378606B (en) |
AU (1) | AU2014259754B2 (en) |
CA (1) | CA2910413C (en) |
WO (1) | WO2014179624A1 (en) |
Families Citing this family (26)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9081500B2 (en) | 2013-05-03 | 2015-07-14 | Google Inc. | Alternative hypothesis error correction for gesture typing |
US9690478B2 (en) * | 2014-03-04 | 2017-06-27 | Texas Instruments Incorporated | Method and system for processing gestures to cause computation of measurement of an angle or a segment using a touch system |
US9952763B1 (en) * | 2014-08-26 | 2018-04-24 | Google Llc | Alternative gesture mapping for a graphical keyboard |
CN104268166B (en) * | 2014-09-09 | 2017-04-19 | 北京搜狗科技发展有限公司 | Input method, device and electronic device |
USD771646S1 (en) * | 2014-09-30 | 2016-11-15 | Apple Inc. | Display screen or portion thereof with graphical user interface |
CN104317426B (en) * | 2014-09-30 | 2018-02-27 | 联想(北京)有限公司 | Input method and electronic equipment |
CN104615591B (en) * | 2015-03-10 | 2019-02-05 | 上海触乐信息科技有限公司 | Forward direction input error correction method and device based on context |
US9678664B2 (en) | 2015-04-10 | 2017-06-13 | Google Inc. | Neural network for keyboard input decoding |
US10402490B1 (en) * | 2015-08-14 | 2019-09-03 | Shutterstock, Inc. | Edit distance based spellcheck |
CN107229348B (en) * | 2016-03-23 | 2021-11-02 | 北京搜狗科技发展有限公司 | Input error correction method and device for input error correction |
US20180018086A1 (en) * | 2016-07-14 | 2018-01-18 | Google Inc. | Pressure-based gesture typing for a graphical keyboard |
US10884610B2 (en) * | 2016-11-04 | 2021-01-05 | Myscript | System and method for recognizing handwritten stroke input |
US10572591B2 (en) * | 2016-11-18 | 2020-02-25 | Lenovo (Singapore) Pte. Ltd. | Input interpretation based upon a context |
US20180188823A1 (en) * | 2017-01-04 | 2018-07-05 | International Business Machines Corporation | Autocorrect with weighted group vocabulary |
US20190013016A1 (en) * | 2017-07-07 | 2019-01-10 | Lenovo Enterprise Solutions (Singapore) Pte. Ltd. | Converting speech to text and inserting a character associated with a gesture input by a user |
CN107390894A (en) * | 2017-07-21 | 2017-11-24 | Tcl移动通信科技（宁波）有限公司 | Control method, storage device and mobile terminal are identified before the input of five-stroke input method |
US11928083B2 (en) | 2017-10-09 | 2024-03-12 | Box, Inc. | Determining collaboration recommendations from file path information |
US11709753B2 (en) | 2017-10-09 | 2023-07-25 | Box, Inc. | Presenting collaboration activities |
US11030223B2 (en) * | 2017-10-09 | 2021-06-08 | Box, Inc. | Collaboration activity summaries |
RU2726009C1 (en) | 2017-12-27 | 2020-07-08 | Общество С Ограниченной Ответственностью "Яндекс" | Method and system for correcting incorrect word set due to input error from keyboard and/or incorrect keyboard layout |
US11061556B2 (en) * | 2018-01-12 | 2021-07-13 | Microsoft Technology Licensing, Llc | Computer device having variable display output based on user input with variable time and/or pressure patterns |
JP2020026086A (en) * | 2018-08-10 | 2020-02-20 | 京セラドキュメントソリューションズ株式会社 | Image forming apparatus |
US10757208B2 (en) | 2018-08-28 | 2020-08-25 | Box, Inc. | Curating collaboration activity |
US11163834B2 (en) | 2018-08-28 | 2021-11-02 | Box, Inc. | Filtering collaboration activity |
US10788889B1 (en) * | 2019-03-25 | 2020-09-29 | Raytheon Company | Virtual reality locomotion without motion controllers |
WO2023137099A2 (en) * | 2022-01-14 | 2023-07-20 | Bierman, Ellen, M. | Contextual keyboard input method, system, and techniques |
Family Cites Families (232)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4534261A (en) | 1983-03-30 | 1985-08-13 | Raymond Fabrizio | Vent key modification for flute |
US4833610A (en) * | 1986-12-16 | 1989-05-23 | International Business Machines Corporation | Morphological/phonetic method for ranking word similarities |
US4988981B1 (en) | 1987-03-17 | 1999-05-18 | Vpl Newco Inc | Computer data entry and manipulation apparatus and method |
US4847766A (en) | 1988-01-05 | 1989-07-11 | Smith Corona Corporation | Dictionary typewriter with correction of commonly confused words |
US5075896A (en) | 1989-10-25 | 1991-12-24 | Xerox Corporation | Character and phoneme recognition based on probability clustering |
US5307267A (en) | 1990-03-27 | 1994-04-26 | Yang Gong M | Method and keyboard for input of characters via use of specified shapes and patterns |
EP0450196B1 (en) | 1990-04-02 | 1998-09-09 | Koninklijke Philips Electronics N.V. | Data processing system using gesture-based input data |
US5604897A (en) | 1990-05-18 | 1997-02-18 | Microsoft Corporation | Method and system for correcting the spelling of misspelled words |
US6094188A (en) | 1990-11-30 | 2000-07-25 | Sun Microsystems, Inc. | Radio frequency tracking system |
US5202803A (en) | 1991-07-02 | 1993-04-13 | International Business Machines Corporation | Disk file with liquid film head-disk interface |
US5848187A (en) | 1991-11-18 | 1998-12-08 | Compaq Computer Corporation | Method and apparatus for entering and manipulating spreadsheet cell data |
FR2689290B1 (en) | 1992-03-26 | 1994-06-10 | Aerospatiale | MULTIMODE AND MULTIFUNCTIONAL COMMUNICATION METHOD AND DEVICE BETWEEN AN OPERATOR AND ONE OR MORE PROCESSORS. |
CA2089784C (en) | 1992-04-15 | 1996-12-24 | William Joseph Anderson | Apparatus and method for disambiguating an input stream generated by a stylus-based user interface |
JP3367116B2 (en) | 1992-09-02 | 2003-01-14 | ヤマハ株式会社 | Electronic musical instrument |
US5502803A (en) | 1993-01-18 | 1996-03-26 | Sharp Kabushiki Kaisha | Information processing apparatus having a gesture editing function |
US5677710A (en) | 1993-05-10 | 1997-10-14 | Apple Computer, Inc. | Recognition keypad |
US5522932A (en) | 1993-05-14 | 1996-06-04 | Applied Materials, Inc. | Corrosion-resistant apparatus |
US5606494A (en) | 1993-11-25 | 1997-02-25 | Casio Computer Co., Ltd. | Switching apparatus |
US6008799A (en) * | 1994-05-24 | 1999-12-28 | Microsoft Corporation | Method and system for entering data using an improved on-screen keyboard |
JPH0844719A (en) | 1994-06-01 | 1996-02-16 | Mitsubishi Electric Corp | Dictionary access system |
US5761689A (en) | 1994-09-01 | 1998-06-02 | Microsoft Corporation | Autocorrecting text typed into a word processing document |
WO1996009579A1 (en) | 1994-09-22 | 1996-03-28 | Izak Van Cruyningen | Popup menus with directional gestures |
US5521986A (en) | 1994-11-30 | 1996-05-28 | American Tel-A-Systems, Inc. | Compact data input device |
FI97508C (en) | 1995-01-09 | 1996-12-27 | Nokia Mobile Phones Ltd | Quick selection in a personal mobile device |
US5748512A (en) * | 1995-02-28 | 1998-05-05 | Microsoft Corporation | Adjusting keyboard |
US5797098A (en) | 1995-07-19 | 1998-08-18 | Pacific Communication Sciences, Inc. | User interface for cellular telephone |
JPH0981364A (en) | 1995-09-08 | 1997-03-28 | Nippon Telegr & Teleph Corp <Ntt> | Multi-modal information input method and device |
US6061050A (en) | 1995-10-27 | 2000-05-09 | Hewlett-Packard Company | User interface device |
US6041292A (en) | 1996-01-16 | 2000-03-21 | Jochim; Carol | Real time stenographic system utilizing vowel omission principle |
USRE37654E1 (en) | 1996-01-22 | 2002-04-16 | Nicholas Longo | Gesture synthesizer for electronic sound device |
US6115482A (en) | 1996-02-13 | 2000-09-05 | Ascent Technology, Inc. | Voice-output reading system with gesture-based navigation |
JP3280559B2 (en) | 1996-02-20 | 2002-05-13 | シャープ株式会社 | Jog dial simulation input device |
US5917493A (en) | 1996-04-17 | 1999-06-29 | Hewlett-Packard Company | Method and apparatus for randomly generating information for subsequent correlating |
US5905246A (en) | 1996-10-31 | 1999-05-18 | Fajkowski; Peter W. | Method and apparatus for coupon management and redemption |
JP3889466B2 (en) | 1996-11-25 | 2007-03-07 | ソニー株式会社 | Text input device and method |
US5953541A (en) | 1997-01-24 | 1999-09-14 | Tegic Communications, Inc. | Disambiguating system for disambiguating ambiguous input sequences by displaying objects associated with the generated input sequences in the order of decreasing frequency of use |
US6047300A (en) | 1997-05-15 | 2000-04-04 | Microsoft Corporation | System and method for automatically correcting a misspelled word |
US6278453B1 (en) | 1997-06-13 | 2001-08-21 | Starfish Software, Inc. | Graphical password methodology for a microprocessor device accepting non-alphanumeric user input |
US6686931B1 (en) | 1997-06-13 | 2004-02-03 | Motorola, Inc. | Graphical password methodology for a microprocessor device accepting non-alphanumeric user input |
US6141011A (en) | 1997-08-04 | 2000-10-31 | Starfish Software, Inc. | User interface methodology supporting light data entry for microprocessor device having limited user input |
US6160555A (en) | 1997-11-17 | 2000-12-12 | Hewlett Packard Company | Method for providing a cue in a computer system |
US6057845A (en) | 1997-11-14 | 2000-05-02 | Sensiva, Inc. | System, method, and apparatus for generation and recognizing universal commands |
WO1999028811A1 (en) | 1997-12-04 | 1999-06-10 | Northern Telecom Limited | Contextual gesture interface |
US8479122B2 (en) | 2004-07-30 | 2013-07-02 | Apple Inc. | Gestures for touch sensitive input devices |
US7614008B2 (en) | 2004-07-30 | 2009-11-03 | Apple Inc. | Operation of a computer with touch screen interface |
KR100327209B1 (en) | 1998-05-12 | 2002-04-17 | 윤종용 | Software keyboard system using the drawing of stylus and method for recognizing keycode therefor |
US6438523B1 (en) | 1998-05-20 | 2002-08-20 | John A. Oberteuffer | Processing handwritten and hand-drawn input and speech input |
US6424983B1 (en) | 1998-05-26 | 2002-07-23 | Global Information Research And Technologies, Llc | Spelling and grammar checking system |
US6131102A (en) * | 1998-06-15 | 2000-10-10 | Microsoft Corporation | Method and system for cost computation of spelling suggestions and automatic replacement |
US6407679B1 (en) | 1998-07-31 | 2002-06-18 | The Research Foundation Of The State University Of New York | System and method for entering text in a virtual environment |
US6150600A (en) | 1998-12-01 | 2000-11-21 | Buchla; Donald F. | Inductive location sensor system and electronic percussion system |
GB2347247A (en) | 1999-02-22 | 2000-08-30 | Nokia Mobile Phones Ltd | Communication terminal with predictive editor |
US7293231B1 (en) | 1999-03-18 | 2007-11-06 | British Columbia Ltd. | Data entry for personal computing devices |
US7030863B2 (en) | 2000-05-26 | 2006-04-18 | America Online, Incorporated | Virtual keyboard system with automatic correction |
US7750891B2 (en) | 2003-04-09 | 2010-07-06 | Tegic Communications, Inc. | Selective input system based on tracking of motion parameters of an input device |
CA2392446C (en) | 1999-05-27 | 2009-07-14 | America Online Incorporated | Keyboard system with automatic correction |
US6904405B2 (en) | 1999-07-17 | 2005-06-07 | Edwin A. Suominen | Message recognition using shared language model |
US6396523B1 (en) | 1999-07-29 | 2002-05-28 | Interlink Electronics, Inc. | Home entertainment device remote control |
US6512838B1 (en) | 1999-09-22 | 2003-01-28 | Canesta, Inc. | Methods for enhancing performance and data acquired from three-dimensional image systems |
US6789231B1 (en) | 1999-10-05 | 2004-09-07 | Microsoft Corporation | Method and system for providing alternatives for text derived from stochastic input sources |
US7798417B2 (en) | 2000-01-03 | 2010-09-21 | Snyder David M | Method for data interchange |
DE60025901T2 (en) | 2000-01-11 | 2006-08-24 | International Business Machines Corp. | Method and device for marking a text document with a pattern of additional blanks for the purpose of authentication |
US6573844B1 (en) | 2000-01-18 | 2003-06-03 | Microsoft Corporation | Predictive keyboard |
US7028259B1 (en) | 2000-02-01 | 2006-04-11 | Jacobson Robert L | Interactive legal citation checker |
US6630924B1 (en) | 2000-02-22 | 2003-10-07 | International Business Machines Corporation | Gesture sensing split keyboard and approach for capturing keystrokes |
US7047493B1 (en) | 2000-03-31 | 2006-05-16 | Brill Eric D | Spell checker with arbitrary length string-to-string transformations to improve noisy channel spelling correction |
US7035788B1 (en) | 2000-04-25 | 2006-04-25 | Microsoft Corporation | Language model sharing |
AU2001270420A1 (en) | 2000-07-21 | 2002-02-05 | Raphael Bachmann | Method for a high-speed writing system and high-speed writing device |
US20020015064A1 (en) | 2000-08-07 | 2002-02-07 | Robotham John S. | Gesture-based user interface to multi-level and multi-modal sets of bit-maps |
US6606597B1 (en) | 2000-09-08 | 2003-08-12 | Microsoft Corporation | Augmented-word language model |
WO2002033582A2 (en) | 2000-10-16 | 2002-04-25 | Text Analysis International, Inc. | Method for analyzing text and method for builing text analyzers |
EP1887451A3 (en) | 2000-10-18 | 2009-06-24 | 602531 British Columbia Ltd. | Data entry method and system for personal computer, and corresponding computer readable medium |
AU2002230766A1 (en) * | 2000-11-08 | 2002-05-21 | New York University | System, process and software arrangement for recognizing handwritten characters |
US6570557B1 (en) | 2001-02-10 | 2003-05-27 | Finger Works, Inc. | Multi-touch system and method for emulating modifier keys via fingertip chords |
CA2340531C (en) | 2001-03-12 | 2006-10-10 | Ibm Canada Limited-Ibm Canada Limitee | Document retrieval system and search method using word set and character look-up tables |
US7035794B2 (en) | 2001-03-30 | 2006-04-25 | Intel Corporation | Compressing and using a concatenative speech database in text-to-speech systems |
FI116591B (en) | 2001-06-29 | 2005-12-30 | Nokia Corp | Method and apparatus for performing a function |
US7042443B2 (en) | 2001-10-11 | 2006-05-09 | Woodard Scott E | Speed Writer program and device with Speed Writer program installed |
US7610189B2 (en) | 2001-10-18 | 2009-10-27 | Nuance Communications, Inc. | Method and apparatus for efficient segmentation of compound words using probabilistic breakpoint traversal |
US7296019B1 (en) | 2001-10-23 | 2007-11-13 | Microsoft Corporation | System and methods for providing runtime spelling analysis and correction |
US7362243B2 (en) | 2001-11-16 | 2008-04-22 | International Business Machines Corporation | Apparatus and method using color-coded or pattern-coded keys in two-key input per character text entry |
US6765556B2 (en) | 2001-11-16 | 2004-07-20 | International Business Machines Corporation | Two-key input per character text entry apparatus and method |
US7075520B2 (en) | 2001-12-12 | 2006-07-11 | Zi Technology Corporation Ltd | Key press disambiguation using a keypad of multidirectional keys |
US7231343B1 (en) | 2001-12-20 | 2007-06-12 | Ianywhere Solutions, Inc. | Synonyms mechanism for natural language systems |
US7175438B2 (en) | 2002-03-01 | 2007-02-13 | Digit Wireless | Fast typing system and method |
US7170430B2 (en) | 2002-03-28 | 2007-01-30 | Michael Goodgoll | System, method, and computer program product for single-handed data entry |
US7151530B2 (en) | 2002-08-20 | 2006-12-19 | Canesta, Inc. | System and method for determining an input selected by a user through a virtual interface |
DE60212976T2 (en) | 2002-11-20 | 2006-11-16 | Nokia Corp. | Method and user interface for character input |
US7199786B2 (en) | 2002-11-29 | 2007-04-03 | Daniel Suraqui | Reduced keyboards system using unistroke input and having automatic disambiguating and a recognition method using said system |
US7251367B2 (en) | 2002-12-20 | 2007-07-31 | International Business Machines Corporation | System and method for recognizing word patterns based on a virtual keyboard layout |
US7382358B2 (en) | 2003-01-16 | 2008-06-03 | Forword Input, Inc. | System and method for continuous stroke word-based text input |
US7453439B1 (en) | 2003-01-16 | 2008-11-18 | Forward Input Inc. | System and method for continuous stroke word-based text input |
US7098896B2 (en) | 2003-01-16 | 2006-08-29 | Forword Input Inc. | System and method for continuous stroke word-based text input |
SG135918A1 (en) | 2003-03-03 | 2007-10-29 | Xrgomics Pte Ltd | Unambiguous text input method for touch screens and reduced keyboard systems |
NZ529518A (en) | 2003-11-13 | 2005-03-24 | Andy Zheng Song | Input method, system and device |
US20050114115A1 (en) | 2003-11-26 | 2005-05-26 | Karidis John P. | Typing accuracy relaxation system and method in stylus and other keyboards |
DE10357475A1 (en) * | 2003-12-09 | 2005-07-07 | Siemens Ag | Communication device and method for entering and predicting text |
US7250938B2 (en) * | 2004-01-06 | 2007-07-31 | Lenovo (Singapore) Pte. Ltd. | System and method for improved user input on personal computing devices |
US7706616B2 (en) * | 2004-02-27 | 2010-04-27 | International Business Machines Corporation | System and method for recognizing word patterns in a very large vocabulary based on a virtual keyboard layout |
US8095364B2 (en) | 2004-06-02 | 2012-01-10 | Tegic Communications, Inc. | Multimodal disambiguation of speech recognition |
EP2017696A1 (en) | 2004-06-02 | 2009-01-21 | 2012244 Ontario Inc. | Handheld electronic device with text disambiguation |
US20060004638A1 (en) | 2004-07-02 | 2006-01-05 | Royal Eliza H | Assisted electronic product design |
JP4284531B2 (en) | 2004-07-06 | 2009-06-24 | オムロン株式会社 | Mounting board and driving device using the same |
US7207004B1 (en) | 2004-07-23 | 2007-04-17 | Harrity Paul A | Correction of misspelled words |
US20060176283A1 (en) | 2004-08-06 | 2006-08-10 | Daniel Suraqui | Finger activated reduced keyboard and a method for performing text input |
US7508324B2 (en) | 2004-08-06 | 2009-03-24 | Daniel Suraqui | Finger activated reduced keyboard and a method for performing text input |
US20060055669A1 (en) | 2004-09-13 | 2006-03-16 | Mita Das | Fluent user interface for text entry on touch-sensitive display |
JP4843505B2 (en) | 2004-12-24 | 2011-12-21 | 独立行政法人科学技術振興機構 | Nanographite structure-metal nanoparticle composite |
US8552984B2 (en) | 2005-01-13 | 2013-10-08 | 602531 British Columbia Ltd. | Method, system, apparatus and computer-readable media for directing input associated with keyboard-type device |
US7487461B2 (en) | 2005-05-04 | 2009-02-03 | International Business Machines Corporation | System and method for issuing commands based on pen motions on a graphical keyboard |
US20060256139A1 (en) | 2005-05-11 | 2006-11-16 | Gikandi David C | Predictive text computer simplified keyboard with word and phrase auto-completion (plus text-to-speech and a foreign language translation option) |
US8036878B2 (en) | 2005-05-18 | 2011-10-11 | Never Wall Treuhand GmbH | Device incorporating improved text input mechanism |
US7886233B2 (en) | 2005-05-23 | 2011-02-08 | Nokia Corporation | Electronic text input involving word completion functionality for predicting word candidates for partial word inputs |
US20070016862A1 (en) | 2005-07-15 | 2007-01-18 | Microth, Inc. | Input guessing systems, methods, and computer program products |
GB0516246D0 (en) | 2005-08-08 | 2005-09-14 | Scanlan Timothy | A data entry device and method |
US20070152980A1 (en) | 2006-01-05 | 2007-07-05 | Kenneth Kocienda | Touch Screen Keyboards for Portable Electronic Devices |
US7542029B2 (en) | 2005-09-20 | 2009-06-02 | Cliff Kushler | System and method for a user interface for text editing and menu selection |
US20070094024A1 (en) | 2005-10-22 | 2007-04-26 | International Business Machines Corporation | System and method for improving text input in a shorthand-on-keyboard interface |
US20070106317A1 (en) | 2005-11-09 | 2007-05-10 | Shelton Frederick E Iv | Hydraulically and electrically actuated articulation joints for surgical instruments |
US7657526B2 (en) | 2006-03-06 | 2010-02-02 | Veveo, Inc. | Methods and systems for selecting and presenting content based on activity level spikes associated with the content |
US7831911B2 (en) | 2006-03-08 | 2010-11-09 | Microsoft Corporation | Spell checking system including a phonetic speller |
ITRM20060136A1 (en) | 2006-03-10 | 2007-09-11 | Link Formazione S R L | INTERACTIVE MULTIMEDIA SYSTEM |
EP1860576A1 (en) | 2006-05-23 | 2007-11-28 | Harman/Becker Automotive Systems GmbH | Indexing big world lists in databases |
US7831423B2 (en) | 2006-05-25 | 2010-11-09 | Multimodal Technologies, Inc. | Replacing text representing a concept with an alternate written form of the concept |
WO2008013658A2 (en) | 2006-07-03 | 2008-01-31 | Cliff Kushler | System and method for a user interface for text editing and menu selection |
US8564544B2 (en) | 2006-09-06 | 2013-10-22 | Apple Inc. | Touch screen device, method, and graphical user interface for customizing display of content category icons |
US7774193B2 (en) | 2006-12-05 | 2010-08-10 | Microsoft Corporation | Proofing of word collocation errors based on a comparison with collocations in a corpus |
US20080172293A1 (en) | 2006-12-28 | 2008-07-17 | Yahoo! Inc. | Optimization framework for association of advertisements with sequential media |
US8074172B2 (en) | 2007-01-05 | 2011-12-06 | Apple Inc. | Method, system, and graphical user interface for providing word recommendations |
US7957955B2 (en) * | 2007-01-05 | 2011-06-07 | Apple Inc. | Method and system for providing word recommendations for text input |
US7907125B2 (en) | 2007-01-05 | 2011-03-15 | Microsoft Corporation | Recognizing multiple input point gestures |
US8225203B2 (en) | 2007-02-01 | 2012-07-17 | Nuance Communications, Inc. | Spell-check for a keyboard system with automatic correction |
US7809719B2 (en) | 2007-02-08 | 2010-10-05 | Microsoft Corporation | Predicting textual candidates |
US20080229255A1 (en) | 2007-03-15 | 2008-09-18 | Nokia Corporation | Apparatus, method and system for gesture detection |
US20080232885A1 (en) | 2007-03-19 | 2008-09-25 | Giftventure Studios, Inc. | Systems and Methods for Creating Customized Activities |
US7903883B2 (en) | 2007-03-30 | 2011-03-08 | Microsoft Corporation | Local bi-gram model for object recognition |
US7895518B2 (en) | 2007-04-27 | 2011-02-22 | Shapewriter Inc. | System and method for preview and selection of words |
US8504349B2 (en) | 2007-06-18 | 2013-08-06 | Microsoft Corporation | Text prediction with partial selection in a variety of domains |
US8059101B2 (en) | 2007-06-22 | 2011-11-15 | Apple Inc. | Swipe gestures for touch screen keyboards |
TW200905538A (en) | 2007-07-31 | 2009-02-01 | Elan Microelectronics Corp | Touch position detector of capacitive touch panel and method of detecting the touch position |
US20090058823A1 (en) | 2007-09-04 | 2009-03-05 | Apple Inc. | Virtual Keyboards in Multi-Language Environment |
US8661340B2 (en) | 2007-09-13 | 2014-02-25 | Apple Inc. | Input methods for device having multi-language environment |
US8015232B2 (en) * | 2007-10-11 | 2011-09-06 | Roaming Keyboards Llc | Thin terminal computer architecture utilizing roaming keyboard files |
US20090100383A1 (en) | 2007-10-16 | 2009-04-16 | Microsoft Corporation | Predictive gesturing in graphical user interface |
US20090119376A1 (en) | 2007-11-06 | 2009-05-07 | International Busness Machines Corporation | Hint-Based Email Address Construction |
US8232973B2 (en) | 2008-01-09 | 2012-07-31 | Apple Inc. | Method, device, and graphical user interface providing word recommendations for text input |
US8456425B2 (en) | 2008-01-30 | 2013-06-04 | International Business Machines Corporation | Self-adapting keypad |
US8280886B2 (en) | 2008-02-13 | 2012-10-02 | Fujitsu Limited | Determining candidate terms related to terms of a query |
US20090249198A1 (en) | 2008-04-01 | 2009-10-01 | Yahoo! Inc. | Techniques for input recogniton and completion |
WO2010011972A1 (en) | 2008-07-24 | 2010-01-28 | Headsprout, Inc. | Teaching reading comprehension |
US8619048B2 (en) | 2008-08-08 | 2013-12-31 | Moonsun Io Ltd. | Method and device of stroke based user input |
EA201100347A1 (en) | 2008-08-12 | 2011-10-31 | Килесс Системз Лтд. | DATA INPUT SYSTEM |
US20100070908A1 (en) | 2008-09-18 | 2010-03-18 | Sun Microsystems, Inc. | System and method for accepting or rejecting suggested text corrections |
US20100079382A1 (en) | 2008-09-26 | 2010-04-01 | Suggs Bradley N | Touch-screen monitoring |
US8788261B2 (en) | 2008-11-04 | 2014-07-22 | Saplo Ab | Method and system for analyzing text |
US7996369B2 (en) | 2008-11-14 | 2011-08-09 | The Regents Of The University Of California | Method and apparatus for improving performance of approximate string queries using variable length high-quality grams |
US20100131447A1 (en) | 2008-11-26 | 2010-05-27 | Nokia Corporation | Method, Apparatus and Computer Program Product for Providing an Adaptive Word Completion Mechanism |
KR101126406B1 (en) | 2008-11-27 | 2012-04-20 | 엔에이치엔(주) | Method and System for Determining Similar Word with Input String |
US20100141484A1 (en) | 2008-12-08 | 2010-06-10 | Research In Motion Limited | Optimized keyboard for handheld thumb-typing and touch-typing |
US20100199226A1 (en) | 2009-01-30 | 2010-08-05 | Nokia Corporation | Method and Apparatus for Determining Input Information from a Continuous Stroke Input |
RU2011134935A (en) | 2009-02-04 | 2013-03-10 | Кейлесс Системз Лтд. | DATA INPUT SYSTEM |
US20100235780A1 (en) | 2009-03-16 | 2010-09-16 | Westerman Wayne C | System and Method for Identifying Words Based on a Sequence of Keyboard Events |
US8566045B2 (en) | 2009-03-16 | 2013-10-22 | Apple Inc. | Event recognition |
US9684521B2 (en) | 2010-01-26 | 2017-06-20 | Apple Inc. | Systems having discrete and continuous gesture recognizers |
US9311112B2 (en) | 2009-03-16 | 2016-04-12 | Apple Inc. | Event recognition |
US8566044B2 (en) | 2009-03-16 | 2013-10-22 | Apple Inc. | Event recognition |
US20100238125A1 (en) | 2009-03-20 | 2010-09-23 | Nokia Corporation | Method, Apparatus, and Computer Program Product For Discontinuous Shapewriting |
KR101844366B1 (en) | 2009-03-27 | 2018-04-02 | 삼성전자 주식회사 | Apparatus and method for recognizing touch gesture |
US9189472B2 (en) | 2009-03-30 | 2015-11-17 | Touchtype Limited | System and method for inputting text into small screen devices |
GB0905457D0 (en) | 2009-03-30 | 2009-05-13 | Touchtype Ltd | System and method for inputting text into electronic devices |
US20120046544A1 (en) | 2009-04-16 | 2012-02-23 | Shimadzu Corporation | Radiation tomography apparatus |
US20100315266A1 (en) | 2009-06-15 | 2010-12-16 | Microsoft Corporation | Predictive interfaces with usability constraints |
DE102010031878A1 (en) | 2009-07-22 | 2011-02-10 | Logitech Europe S.A. | System and method for remote on-screen virtual input |
DE212009000220U1 (en) | 2009-08-04 | 2012-05-07 | Google, Inc. | Generation of search query proposals |
US9317116B2 (en) | 2009-09-09 | 2016-04-19 | Immersion Corporation | Systems and methods for haptically-enhanced text interfaces |
US20110063231A1 (en) | 2009-09-14 | 2011-03-17 | Invotek, Inc. | Method and Device for Data Input |
US8341558B2 (en) | 2009-09-16 | 2012-12-25 | Google Inc. | Gesture recognition on computing device correlating input to a template |
US8135582B2 (en) | 2009-10-04 | 2012-03-13 | Daniel Suraqui | Keyboard system and method for global disambiguation from classes with dictionary database from first and last letters |
US8386574B2 (en) | 2009-10-29 | 2013-02-26 | Xerox Corporation | Multi-modality classification for one-class classification in social networks |
US8365059B2 (en) | 2009-11-03 | 2013-01-29 | Oto Technologies, Llc | E-reader semantic text manipulation |
US8884872B2 (en) | 2009-11-20 | 2014-11-11 | Nuance Communications, Inc. | Gesture-based repetition of key activations on a virtual keyboard |
US8358281B2 (en) | 2009-12-15 | 2013-01-22 | Apple Inc. | Device, method, and graphical user interface for management and manipulation of user interface elements |
US8587532B2 (en) | 2009-12-18 | 2013-11-19 | Intel Corporation | Multi-feature interactive touch user interface |
US8782556B2 (en) | 2010-02-12 | 2014-07-15 | Microsoft Corporation | User-centric soft keyboard predictive technologies |
US9417787B2 (en) | 2010-02-12 | 2016-08-16 | Microsoft Technology Licensing, Llc | Distortion effects to indicate location in a movable data collection |
US8515969B2 (en) | 2010-02-19 | 2013-08-20 | Go Daddy Operating Company, LLC | Splitting a character string into keyword strings |
US9965165B2 (en) | 2010-02-19 | 2018-05-08 | Microsoft Technology Licensing, Llc | Multi-finger gestures |
KR101557358B1 (en) | 2010-02-25 | 2015-10-06 | 엘지전자 주식회사 | Method for inputting a string of charaters and apparatus thereof |
US20110210850A1 (en) | 2010-02-26 | 2011-09-01 | Phuong K Tran | Touch-screen keyboard with combination keys and directional swipes |
CN101788855B (en) | 2010-03-09 | 2013-04-17 | 华为终端有限公司 | Method, device and communication terminal for obtaining user input information |
KR101477530B1 (en) | 2010-03-12 | 2014-12-30 | 뉘앙스 커뮤니케이션즈, 인코포레이티드 | Multimodal text input system, such as for use with touch screens on mobile phones |
US8542195B2 (en) | 2010-03-30 | 2013-09-24 | International Business Machines Corporation | Method for optimization of soft keyboards for multiple languages |
CN101853126B (en) * | 2010-05-12 | 2012-02-15 | 中国科学院自动化研究所 | Real-time identification method for on-line handwriting sentences |
US8266528B1 (en) | 2010-06-24 | 2012-09-11 | Google Inc. | Spelling suggestions based on an input sequence including accidental “delete” |
US8918734B2 (en) | 2010-07-28 | 2014-12-23 | Nuance Communications, Inc. | Reduced keyboard with prediction solutions when input is a partial sliding trajectory |
US20120036468A1 (en) | 2010-08-03 | 2012-02-09 | Nokia Corporation | User input remapping |
US20120036485A1 (en) | 2010-08-09 | 2012-02-09 | XMG Studio | Motion Driven User Interface |
US8898586B2 (en) | 2010-09-24 | 2014-11-25 | Google Inc. | Multiple touchpoints for efficient text input |
GB201200643D0 (en) | 2012-01-16 | 2012-02-29 | Touchtype Ltd | System and method for inputting text |
US8810581B2 (en) | 2010-10-20 | 2014-08-19 | Blackberry Limited | Character input method |
US20120113008A1 (en) | 2010-11-08 | 2012-05-10 | Ville Makinen | On-screen keyboard with haptic effects |
US9235828B2 (en) | 2010-11-17 | 2016-01-12 | Z124 | Email client display transition |
US9870141B2 (en) | 2010-11-19 | 2018-01-16 | Microsoft Technology Licensing, Llc | Gesture recognition |
EP2641145A4 (en) | 2010-11-20 | 2017-05-03 | Nuance Communications, Inc. | Systems and methods for using entered text to access and process contextual information |
US20120166428A1 (en) | 2010-12-22 | 2012-06-28 | Yahoo! Inc | Method and system for improving quality of web content |
US8730188B2 (en) * | 2010-12-23 | 2014-05-20 | Blackberry Limited | Gesture input on a portable electronic device and method of controlling the same |
US8922489B2 (en) | 2011-03-24 | 2014-12-30 | Microsoft Corporation | Text input using key and gesture information |
US8914275B2 (en) | 2011-04-06 | 2014-12-16 | Microsoft Corporation | Text prediction |
US8570372B2 (en) | 2011-04-29 | 2013-10-29 | Austin Russell | Three-dimensional imager and projection device |
US8587542B2 (en) | 2011-06-01 | 2013-11-19 | Motorola Mobility Llc | Using pressure differences with a touch-sensitive display screen |
US9471560B2 (en) | 2011-06-03 | 2016-10-18 | Apple Inc. | Autocorrecting language input for virtual keyboards |
US8719719B2 (en) | 2011-06-17 | 2014-05-06 | Google Inc. | Graphical icon presentation |
US20130212515A1 (en) | 2012-02-13 | 2013-08-15 | Syntellia, Inc. | User interface for text input |
US8751972B2 (en) | 2011-09-20 | 2014-06-10 | Google Inc. | Collaborative gesture-based input language |
US20130082824A1 (en) | 2011-09-30 | 2013-04-04 | Nokia Corporation | Feedback response |
US8490008B2 (en) * | 2011-11-10 | 2013-07-16 | Research In Motion Limited | Touchscreen keyboard predictive display and generation of a set of characters |
US9310889B2 (en) | 2011-11-10 | 2016-04-12 | Blackberry Limited | Touchscreen keyboard predictive display and generation of a set of characters |
US9122672B2 (en) | 2011-11-10 | 2015-09-01 | Blackberry Limited | In-letter word prediction for virtual keyboard |
CN102411477A (en) | 2011-11-16 | 2012-04-11 | 鸿富锦精密工业（深圳）有限公司 | Electronic equipment and text reading guide method thereof |
CN102508553A (en) | 2011-11-23 | 2012-06-20 | 赵来刚 | Technology for inputting data and instructions into electronic product by hands |
US8436827B1 (en) | 2011-11-29 | 2013-05-07 | Google Inc. | Disambiguating touch-input based on variation in characteristic such as speed or pressure along a touch-trail |
WO2013119712A1 (en) | 2012-02-06 | 2013-08-15 | Colby Michael K | Character-string completion |
CN102629158B (en) | 2012-02-29 | 2015-04-08 | 广东威创视讯科技股份有限公司 | Character input method and device on basis of touch screen system |
US8667414B2 (en) | 2012-03-23 | 2014-03-04 | Google Inc. | Gestural input at a virtual keyboard |
US8782549B2 (en) | 2012-10-05 | 2014-07-15 | Google Inc. | Incremental feature-based gesture-keyboard decoding |
US9021380B2 (en) | 2012-10-05 | 2015-04-28 | Google Inc. | Incremental multi-touch gesture recognition |
US8843845B2 (en) | 2012-10-16 | 2014-09-23 | Google Inc. | Multi-gesture text input prediction |
US8850350B2 (en) | 2012-10-16 | 2014-09-30 | Google Inc. | Partial gesture text entry |
US8701032B1 (en) | 2012-10-16 | 2014-04-15 | Google Inc. | Incremental multi-word recognition |
US8819574B2 (en) | 2012-10-22 | 2014-08-26 | Google Inc. | Space prediction for text input |
US8832589B2 (en) | 2013-01-15 | 2014-09-09 | Google Inc. | Touch keyboard using language and spatial models |
US9081500B2 (en) | 2013-05-03 | 2015-07-14 | Google Inc. | Alternative hypothesis error correction for gesture typing |
-
2013
- 2013-05-31 US US13/907,614 patent/US9081500B2/en active Active
-
2014
- 2014-05-01 CA CA2910413A patent/CA2910413C/en active Active
- 2014-05-01 KR KR1020157033499A patent/KR101750969B1/en active IP Right Grant
- 2014-05-01 WO PCT/US2014/036459 patent/WO2014179624A1/en active Application Filing
- 2014-05-01 EP EP14731439.7A patent/EP2992406B1/en active Active
- 2014-05-01 CN CN201480038018.9A patent/CN105378606B/en active Active
- 2014-05-01 AU AU2014259754A patent/AU2014259754B2/en active Active
-
2015
- 2015-06-12 US US14/738,449 patent/US9841895B2/en active Active
-
2017
- 2017-11-09 US US15/808,233 patent/US10241673B2/en active Active
Non-Patent Citations (2)
Title |
---|
None * |
See also references of WO2014179624A1 * |
Also Published As
Publication number | Publication date |
---|---|
KR101750969B1 (en) | 2017-06-26 |
US20150277757A1 (en) | 2015-10-01 |
CN105378606A (en) | 2016-03-02 |
US9081500B2 (en) | 2015-07-14 |
US20140327622A1 (en) | 2014-11-06 |
CA2910413A1 (en) | 2014-11-06 |
AU2014259754A1 (en) | 2015-11-12 |
US20180074698A1 (en) | 2018-03-15 |
US9841895B2 (en) | 2017-12-12 |
US10241673B2 (en) | 2019-03-26 |
WO2014179624A1 (en) | 2014-11-06 |
EP2992406B1 (en) | 2022-01-12 |
AU2014259754B2 (en) | 2016-08-18 |
CA2910413C (en) | 2019-04-02 |
CN105378606B (en) | 2018-10-02 |
KR20160003765A (en) | 2016-01-11 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US10241673B2 (en) | Alternative hypothesis error correction for gesture typing | |
US10073536B2 (en) | Virtual keyboard input for international languages | |
US9542385B2 (en) | Incremental multi-word recognition | |
CN110083254B (en) | Multi-gesture text input prediction | |
US9026428B2 (en) | Text/character input system, such as for use with touch screens on mobile phones | |
US10095405B2 (en) | Gesture keyboard input of non-dictionary character strings | |
US8756499B1 (en) | Gesture keyboard input of non-dictionary character strings using substitute scoring | |
AU2014212844A1 (en) | Character and word level language models for out-of-vocabulary text input | |
US20170336969A1 (en) | Predicting next letters and displaying them within keys of a graphical keyboard | |
EP3241105B1 (en) | Suggestion selection during continuous gesture input | |
US20170286395A1 (en) | Dynamic key mapping of a graphical keyboard | |
US9298276B1 (en) | Word prediction for numbers and symbols |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PUAI | Public reference made under article 153(3) epc to a published international application that has entered the european phase |
Free format text: ORIGINAL CODE: 0009012 |
|
17P | Request for examination filed |
Effective date: 20151125 |
|
AK | Designated contracting states |
Kind code of ref document: A1Designated state(s): AL AT BE BG CH CY CZ DE DK EE ES FI FR GB GR HR HU IE IS IT LI LT LU LV MC MK MT NL NO PL PT RO RS SE SI SK SM TR |
|
AX | Request for extension of the european patent |
Extension state: BA ME |
|
DAX | Request for extension of the european patent (deleted) | ||
RAP1 | Party data changed (applicant data changed or rights of an application transferred) |
Owner name: GOOGLE LLC |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: EXAMINATION IS IN PROGRESS |
|
17Q | First examination report despatched |
Effective date: 20181108 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: EXAMINATION IS IN PROGRESS |
|
GRAP | Despatch of communication of intention to grant a patent |
Free format text: ORIGINAL CODE: EPIDOSNIGR1 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: GRANT OF PATENT IS INTENDED |
|
RIC1 | Information provided on ipc code assigned before grant |
Ipc: G06F 40/274 20200101ALI20210528BHEPIpc: G06F 40/232 20200101ALI20210528BHEPIpc: G06F 3/0488 20130101ALI20210528BHEPIpc: G06F 3/023 20060101AFI20210528BHEP |
|
RIN1 | Information on inventor provided before grant (corrected) |
Inventor name: ZHAI, SHUMINInventor name: OUYANG, YU |
|
INTG | Intention to grant announced |
Effective date: 20210625 |
|
GRAJ | Information related to disapproval of communication of intention to grant by the applicant or resumption of examination proceedings by the epo deleted |
Free format text: ORIGINAL CODE: EPIDOSDIGR1 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: EXAMINATION IS IN PROGRESS |
|
GRAP | Despatch of communication of intention to grant a patent |
Free format text: ORIGINAL CODE: EPIDOSNIGR1 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: GRANT OF PATENT IS INTENDED |
|
INTC | Intention to grant announced (deleted) | ||
INTG | Intention to grant announced |
Effective date: 20210927 |
|
GRAS | Grant fee paid |
Free format text: ORIGINAL CODE: EPIDOSNIGR3 |
|
GRAA | (expected) grant |
Free format text: ORIGINAL CODE: 0009210 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: THE PATENT HAS BEEN GRANTED |
|
AK | Designated contracting states |
Kind code of ref document: B1Designated state(s): AL AT BE BG CH CY CZ DE DK EE ES FI FR GB GR HR HU IE IS IT LI LT LU LV MC MK MT NL NO PL PT RO RS SE SI SK SM TR |
|
REG | Reference to a national code |
Ref country code: GBRef legal event code: FG4D |
|
REG | Reference to a national code |
Ref country code: CHRef legal event code: EP |
|
REG | Reference to a national code |
Ref country code: DERef legal event code: R096Ref document number: 602014082144Country of ref document: DE |
|
REG | Reference to a national code |
Ref country code: IERef legal event code: FG4D |
|
REG | Reference to a national code |
Ref country code: ATRef legal event code: REFRef document number: 1462821Country of ref document: ATKind code of ref document: TEffective date: 20220215 |
|
REG | Reference to a national code |
Ref country code: LTRef legal event code: MG9D |
|
REG | Reference to a national code |
Ref country code: NLRef legal event code: MPEffective date: 20220112 |
|
REG | Reference to a national code |
Ref country code: ATRef legal event code: MK05Ref document number: 1462821Country of ref document: ATKind code of ref document: TEffective date: 20220112 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: NLFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20220112 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: SEFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20220112Ref country code: RSFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20220112Ref country code: PTFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20220512Ref country code: NOFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20220412Ref country code: LTFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20220112Ref country code: HRFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20220112Ref country code: ESFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20220112Ref country code: BGFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20220412 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: PLFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20220112Ref country code: LVFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20220112Ref country code: GRFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20220413Ref country code: FIFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20220112Ref country code: ATFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20220112 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: ISFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20220512 |
|
REG | Reference to a national code |
Ref country code: DERef legal event code: R097Ref document number: 602014082144Country of ref document: DE |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: SMFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20220112Ref country code: SKFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20220112Ref country code: ROFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20220112Ref country code: EEFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20220112Ref country code: DKFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20220112Ref country code: CZFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20220112 |
|
PLBE | No opposition filed within time limit |
Free format text: ORIGINAL CODE: 0009261 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: NO OPPOSITION FILED WITHIN TIME LIMIT |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: ALFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20220112 |
|
26N | No opposition filed |
Effective date: 20221013 |
|
REG | Reference to a national code |
Ref country code: CHRef legal event code: PL |
|
REG | Reference to a national code |
Ref country code: BERef legal event code: MMEffective date: 20220531 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: MCFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20220112Ref country code: LUFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20220501Ref country code: LIFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20220531Ref country code: CHFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20220531 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: SIFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20220112 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: IEFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20220501 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: BEFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20220531 |
|
P01 | Opt-out of the competence of the unified patent court (upc) registered |
Effective date: 20230505 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: ITFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20220112 |
|
PGFP | Annual fee paid to national office [announced via postgrant information from national office to epo] |
Ref country code: FRPayment date: 20230526Year of fee payment: 10Ref country code: DEPayment date: 20230530Year of fee payment: 10 |
|
PGFP | Annual fee paid to national office [announced via postgrant information from national office to epo] |
Ref country code: GBPayment date: 20230529Year of fee payment: 10 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: HUFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMIT; INVALID AB INITIOEffective date: 20140501 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: MKFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20220112Ref country code: CYFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20220112 |