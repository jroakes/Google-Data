US20150186787A1 - Cloud-based plagiarism detection system - Google Patents
Cloud-based plagiarism detection system Download PDFInfo
- Publication number
- US20150186787A1 US20150186787A1 US14/143,710 US201314143710A US2015186787A1 US 20150186787 A1 US20150186787 A1 US 20150186787A1 US 201314143710 A US201314143710 A US 201314143710A US 2015186787 A1 US2015186787 A1 US 2015186787A1
- Authority
- US
- United States
- Prior art keywords
- documents
- document
- feature vector
- database
- edit
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/93—Document management systems
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N5/00—Computing arrangements using knowledge-based models
- G06N5/04—Inference or reasoning models
- G06N5/048—Fuzzy inferencing
-
- G06F17/30011—
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N20/00—Machine learning
-
- G06N99/005—
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q10/00—Administration; Management
- G06Q10/10—Office automation; Time management
- G06Q10/107—Computer-aided management of electronic mailing [e-mailing]
Definitions
- Massive online open courses (“MOOC”) are aimed at large-scale courses provided to participants around the world. Because the number of participants can be large, sometimes reaching over tens or hundreds of thousand people, it is difficult for the instructor and/or teaching assistants to identify whether any students have plagiarized any content for their homework or assignments. Many assignments include writing essays or developing computer programs to solve a particular problem. With the increasing popularity of distance education programs, manually sifting through a large number of documents to detect plagiarism is a cumbersome process.
- a system includes a database and a feature extraction module.
- the database may store one or more documents. Each of the documents may be associated with at least one user.
- the database may be configured to receive a group of documents related to a course. It may receive at least one edit to one of the group of documents by a user.
- the database may store the at least one edit and at least one time reference corresponding to the time during which the at least one edit was made. Sharing of content between each of the one or more documents may be restricted.
- the feature extraction module may be configured to obtain a writing history for at least one user associated with the one of the group of documents. It may determine a writing pattern associated with the one of the group of documents based on the writing history for the at least one user, the at least one edit, and at least one time reference.
- the feature extraction module may be configured to generate a feature vector for the writing pattern. In some configurations, it may compare the feature vector to at least one other feature vector to generate a similarity score. The at least one other feature vector may correspond to a second at least one user who is not present in the first at least one user.
- the extraction module may provide an indication of the similarity score.
- a machine learning technique may be trained on a first set of documents that are known to be plagiarized. The trained machine learning algorithm may be used to classify the feature vector.
- the at least one other feature vector may correspond to a second at least one user who is not present in the first at least one user.
- An indication of the similarity score may be provided.
- a machine learning technique may be trained on a first set of documents that are known to be plagiarized.
- the feature vector may be classified using the trained machine learning algorithm.
- FIG. 3 is an example system for generating a feature vector for a writing pattern according to an implementation.
- FIG. 4 is an example system for determining a probability that a document is plagiarized according to an implementation.
- FIG. 5 is an example method for generating a feature vector as disclosed herein.
- FIG. 6 is an example method for determining a probability that a document is plagiarized according to an implementation disclosed herein.
- Changes in the distribution of words over two time periods may be computed according to an implementation to capture temporal features for each document.
- the duration of a change and the extent to which content is modified may be factored into whether or not a document has been plagiarized.
- a cut and paste operation or a systemic change such as renaming a variable may be an indication that an individual has plagiarized a portion of an essay or computer code.
- An angle between normalized feature vectors or Jaccard (normalized set intersection) similarity may be used to determine a similarity between a pair of documents.
- Other similarity measures in addition to, or instead of cosine or Jaccard similarity may be used according to implementations disclosed herein, such as histogram intersection or chi-square distance.
- the database 310 may be configured to receive a group of documents 312 , 314 related to a course. For example, an instructor for a course may assign an essay. Each of the students may cause a document to be stored in the database 310 for the essay assignment. Each of the documents may be associated with the course. For example, the students may provide an indication that the document is for the course by entering in a course number and/or an assignment code. The system may prompt a user to enter such information before or subsequent to the user electing to create a document. In some configurations, the course instructor may create a template document for the assignment that is populated to an account associated with each student. When a student accesses an account, the student may find the template document and begin work on the essay.
- the database 310 may receive edits to the group of documents by a user (i.e., a student).
- the group of documents may refer to documents related to a specific course and/or an assignment for that course. Although described here in the context of one document per student, the system may be configured to allow multiple users to work on a single document for group projects. For example, a user may create a document for an assignment and elect to share the document with one or more other individuals. An indication of the sharing may be a part of the record created in the database 310 for the document. Edits made to a document and a time reference corresponding to when the edit was made may be stored in the database 310 . For example, a user inserting a paragraph may be associated with a time at which the paragraph was inserted into a document. An indication of the content of the paragraph may also be stored to the database 310 . The indication may be a mathematical representation of the paragraph such as a matrix or a vector.
- Tf-idf Term frequency inverse document frequency
- the feature extraction module 320 may determine a writing pattern associated with the document based on the writing history for the user, an edit made to the document, and/or at least one time reference. If the user does not have any other documents in the database 310 then the feature extraction module may determine a writing pattern for the user based on the single available document, such as by analyzing edits and corresponding time references for the document. A feature vector may be generated for the writing pattern for each user.
- a feature extraction module may determine a distribution of words (e.g., n-grams) for a user for any document written by the user that is stored in the database.
- the distribution of words may be a count for every word that is in the documents (i.e., there may be 100 “the” or 1 “agape”).
- the database may have a temporal history of edits for each of the documents written by the user.
- the feature extraction module may generate a histogram of the distribution of words written over time based on the temporal history and the count of words.
- the histogram may be a signal or represented as a feature vector which may be classified according to a trained machine learning algorithm.
- the feature vector for a first user may be compared to a feature vector for one or more other users.
- the feature vectors for students of a course may be compared to one another in a pairwise fashion.
- An indication of the similarity between the feature vectors may be provided.
- a similarity score for a feature vector to one or more other feature vectors may be determined using cosine or Jaccard similarity.
- the features, such as the distribution of words or n-grams, utilized for a pairwise similarity between the first user and one or more other users may be different than the features utilized for a machine learning classification (described below).
- a machine learning technique may be trained on a first set of documents that are known to be plagiarized, and the feature vector may be classified using the trained machine learning algorithm. For example, writing patterns based on features extracted from a set of documents that have been known to be plagiarized may be obtained and feature vectors representing the plagiarized writing patterns may be generated. For example, training data may be generated by using those documents that are known to be plagiarized, by manually reviewing a set of documents and grouping plagiarized and non-plagiarized works, and/or by generating synthetic sets of documents that employ techniques commonly used for plagiarism (e.g., copying in a whole paragraph, global replacement of a variable, etc.).
- plagiarism e.g., copying in a whole paragraph, global replacement of a variable, etc.
- Writing patterns from non-plagiarized works may be determined and feature vectors may be generated from the non-plagiarized documents based on the writing patterns.
- the machine learning algorithm may be trained on the feature vectors for both plagiarized and non-plagiarized documents.
- the trained classifier may be applied to the feature vector extracted from the group of documents described earlier.
- a system that include a database and a processor connected thereto.
- the database 410 may store one or more documents 412 and may restrict sharing of content between documents 412 stored therein.
- the processor 420 may be configured to receive one or more edits 422 to a document 412 stored in the database 410 .
- a user may open the document 412 and paste in text or other content, type a new paragraph, or the like.
- a time reference 424 may be associated with the edit 422 to the document 412 .
- the edit 422 , the time reference 424 and/or the type of edit may be stored.
- the machine learning model such as a logistical regression model or a support vector machine (“SVM”) may be trained on a set of documents known to be plagiarized. Classification of the feature vector by the machine learning technique may result in a ranked list of documents according to the probability that they have been plagiarized. An instructor may set a threshold value of probability of plagiarism above which the instructor may elect to manually review the documents.
- SVM support vector machine
- a group of documents related to a course may be received at 510 .
- a database may store several groups of documents from several different courses.
- At least one edit to one of the group of documents by at least one user may be received at 520 .
- the at least one edit and at least one time reference corresponding to the time during which the at least one edit was made may be stored at 530 as described earlier.
- a writing history for the at least one user associated with the one of the group of documents may be obtained at 540 .
- the writing pattern may be based on other documents authored by a particular user in the database.
- a writing pattern associated with the one of the group of documents may be determined based on the writing history for the at least one user, the at least one edit, and at least one time reference at 550 .
- a feature vector for the writing pattern may be generated at 560 . The feature vector may then be used, for example, to detect potential plagiarism and/or assign a probability of plagiarism as previously described.
- an edit to a document stored in a database may be received at 610 .
- a time reference may be associated with the edit to the document at 620 .
- the edit and the time reference may be stored to the database as a document history at 630 .
- a feature vector may be generated based on the document history at 640 and a probability that the document is plagiarized may be determined based on a classification of the feature vector by a machine learning technique at 650 as described above.
- FIG. 1 is an example computer system 20 suitable for implementing implementations of the presently disclosed subject matter.
- the computer 20 includes a bus 21 which interconnects major components of the computer 20 , such as one or more processors 24 , memory 27 such as RAM, ROM, flash RAM, or the like, an input/output controller 28 , and fixed storage 23 such as a hard drive, flash storage, SAN device, or the like.
- a user display such as a display screen via a display adapter
- user input interfaces such as controllers and associated user input devices
- keyboard, mouse, touchscreen, or the like and other components known in the art to use in or in conjunction with general-purpose computing systems.
- the bus 21 allows data communication between the central processor 24 and the memory 27 .
- the RAM is generally the main memory into which the operating system and application programs are loaded.
- the ROM or flash memory can contain, among other code, the Basic Input-Output system (BIOS) which controls basic hardware operation such as the interaction with peripheral components.
- BIOS Basic Input-Output system
- Applications resident with the computer 20 are generally stored on and accessed via a computer readable medium, such as the fixed storage 23 and/or the memory 27 , an optical drive, external storage mechanism, or the like.
- Each component shown may be integral with the computer 20 or may be separate and accessed through other interfaces.
- Other interfaces such as a network interface 29 , may provide a connection to remote systems and devices via a telephone link, wired or wireless local- or wide-area network connection, proprietary network connections, or the like.
- the network interface 29 may allow the computer to communicate with other computers via one or more local, wide-area, or other networks, as shown in FIG. 2 .
- FIG. 1 Many other devices or components (not shown) may be connected in a similar manner, such as document scanners, digital cameras, auxiliary, supplemental, or backup systems, or the like. Conversely, all of the components shown in FIG. 1 need not be present to practice the present disclosure. The components can be interconnected in different ways from that shown. The operation of a computer such as that shown in FIG. 1 is readily known in the art and is not discussed in detail in this application. Code to implement the present disclosure can be stored in computer-readable storage media such as one or more of the memory 27 , fixed storage 23 , remote storage locations, or any other storage mechanism known in the art.
- FIG. 2 shows an example arrangement according to an implementation of the disclosed subject matter.
- One or more clients 10 , 11 such as local computers, smart phones, tablet computing devices, remote services, and the like may connect to other devices via one or more networks 7 .
- the network may be a local network, wide-area network, the Internet, or any other suitable communication network or networks, and may be implemented on any suitable platform including wired and/or wireless networks.
- the clients 10 , 11 may communicate with one or more computer systems, such as processing units 14 , databases 15 , and user interface systems 13 .
- clients 10 , 11 may communicate with a user interface system 13 , which may provide access to one or more other systems such as a database 15 , a processing unit 14 , or the like.
- the user interface 13 may be a user-accessible web page that provides data from one or more other computer systems.
- the user interface 13 may provide different interfaces to different clients, such as where a human-readable web page is provided to web browser clients 10 , and a computer-readable API or other interface is provided to remote service clients 11 .
- the user interface 13 , database 15 , and processing units 14 may be part of an integral system, or may include multiple computer systems communicating via a private network, the Internet, or any other suitable network.
- Processing units 14 may be, for example, part of a distributed system such as a cloud-based computing system, search engine, content delivery system, or the like, which may also include or communicate with a database 15 and/or user interface 13 .
- an analysis system 5 may provide back-end processing, such as where stored or acquired data is pre-processed by the analysis system 5 before delivery to the processing unit 14 , database 15 , and/or user interface 13 .
- a machine learning system 5 may provide various prediction models, data analysis, or the like to one or more other systems 13 , 14 , 15 .
- implementations of the presently disclosed subject matter may include or be implemented in the form of computer-implemented processes and apparatuses for practicing those processes. Implementations also may be implemented in the form of a computer program product having computer program code containing instructions implemented in non-transitory and/or tangible media, such as floppy diskettes, CD-ROMs, hard drives, USB (universal serial bus) drives, or any other machine readable storage medium, wherein, when the computer program code is loaded into and executed by a computer, the computer becomes an apparatus for practicing implementations of the disclosed subject matter.
- Implementations also may be implemented in the form of computer program code, for example, whether stored in a storage medium, loaded into and/or executed by a computer, or transmitted over some transmission medium, such as over electrical wiring or cabling, through fiber optics, or via electromagnetic radiation, wherein when the computer program code is loaded into and executed by a computer, the computer becomes an apparatus for practicing implementations of the disclosed subject matter.
- the computer program code segments configure the microprocessor to create specific logic circuits.
- a set of computer-readable instructions stored on a computer-readable storage medium may be implemented by a general-purpose processor, which may transform the general-purpose processor or a device containing the general-purpose processor into a special-purpose device configured to implement or carry out the instructions.
- Implementations may be implemented using hardware that may include a processor, such as a general purpose microprocessor and/or an Application Specific Integrated Circuit (ASIC) that implements all or part of the techniques according to implementations of the disclosed subject matter in hardware and/or firmware.
- the processor may be coupled to memory, such as RAM, ROM, flash memory, a hard disk or any other device capable of storing electronic information.
- the memory may store instructions adapted to be executed by the processor to perform the techniques according to implementations of the disclosed subject matter.
Abstract
Description
- Massive online open courses (“MOOC”) are aimed at large-scale courses provided to participants around the world. Because the number of participants can be large, sometimes reaching over tens or hundreds of thousand people, it is difficult for the instructor and/or teaching assistants to identify whether any students have plagiarized any content for their homework or assignments. Many assignments include writing essays or developing computer programs to solve a particular problem. With the increasing popularity of distance education programs, manually sifting through a large number of documents to detect plagiarism is a cumbersome process.
- According to an implementation of the disclosed subject matter, a system is provided that includes a database and a feature extraction module. The database may store one or more documents. Each of the documents may be associated with at least one user. The database may be configured to receive a group of documents related to a course. It may receive at least one edit to one of the group of documents by a user. The database may store the at least one edit and at least one time reference corresponding to the time during which the at least one edit was made. Sharing of content between each of the one or more documents may be restricted.
- The feature extraction module may be configured to obtain a writing history for at least one user associated with the one of the group of documents. It may determine a writing pattern associated with the one of the group of documents based on the writing history for the at least one user, the at least one edit, and at least one time reference. The feature extraction module may be configured to generate a feature vector for the writing pattern. In some configurations, it may compare the feature vector to at least one other feature vector to generate a similarity score. The at least one other feature vector may correspond to a second at least one user who is not present in the first at least one user. The extraction module may provide an indication of the similarity score. In some configurations, a machine learning technique may be trained on a first set of documents that are known to be plagiarized. The trained machine learning algorithm may be used to classify the feature vector.
- In an implementation, a system is provided that includes a database and a processor connected thereto. The database may store one or more documents. Sharing of the documents may be restricted. The processor may be configured to receive an edit to a document stored in the database. It may associate a time reference with the edit to the document and store the edit and the time reference to the database as a document history. The processor may generate a feature vector based on the document history and determine a probability that the document is plagiarized based on a classification of the feature vector by a machine learning technique. In some configurations, the probability may be based on at least one pairwise comparison of the feature vector for the document to at least one other feature vector for a second document in the database. In some configurations, the probability may be based on a comparison of the feature history to an independent signal, wherein the independent signal corresponds to other documents generated by an author of the document stored in the database.
- As disclosed herein, a group of documents related to a course may be received. At least one edit to one of the group of documents by a user may be received. The at least one edit and at least one time reference corresponding to the time during which the at least one edit was made may be stored. A writing history may be obtained for the at least one user associated with the one of the group of documents. A writing pattern associated with the one of the group of documents may be determined based on the writing history for the at least one user, the at least one edit, and at least one time reference. A feature vector for the writing pattern may be generated. Sharing of content between each document in the group of documents may be restricted. In some configurations the feature vector may be compared to at least one other feature vector to generate a similarity score. The at least one other feature vector may correspond to a second at least one user who is not present in the first at least one user. An indication of the similarity score may be provided. In some configurations, a machine learning technique may be trained on a first set of documents that are known to be plagiarized. The feature vector may be classified using the trained machine learning algorithm.
- In an implementation, an edit to a document stored in a database may be received. A time reference may be associated with the edit to the document. The edit and the time reference may be stored to the database as a document history. A feature vector may be generated based on the document history. A probability that the document is plagiarized may be determined based on a classification of the feature vector by a machine learning technique. The probability may be based on at least one pairwise comparison of the feature vector for the document to at least one other feature vector for a second document in the database. In some instances, the probability may be based on a comparison of the feature history to an independent signal, wherein the independent signal corresponds to other documents generated by an author of the document stored in the database.
- The disclosed implementations may be useful to detect plagiarism in a MOOC. Additional features, advantages, and implementations of the disclosed subject matter may be set forth or apparent from consideration of the following detailed description, drawings, and claims. Moreover, it is to be understood that both the foregoing summary and the following detailed description provide examples of implementations and are intended to provide further explanation without limiting the scope of the claims.
- The accompanying drawings, which are included to provide a further understanding of the disclosed subject matter, are incorporated in and constitute a part of this specification. The drawings also illustrate implementations of the disclosed subject matter and together with the detailed description serve to explain the principles of implementations of the disclosed subject matter. No attempt is made to show structural details in more detail than may be necessary for a fundamental understanding of the disclosed subject matter and various ways in which it may be practiced.
-
FIG. 1 shows a computer according to an implementation of the disclosed subject matter. -
FIG. 2 shows a network configuration according to an implementation of the disclosed subject matter. -
FIG. 3 is an example system for generating a feature vector for a writing pattern according to an implementation. -
FIG. 4 is an example system for determining a probability that a document is plagiarized according to an implementation. -
FIG. 5 is an example method for generating a feature vector as disclosed herein. -
FIG. 6 is an example method for determining a probability that a document is plagiarized according to an implementation disclosed herein. - Three components are disclosed that in combination provide detection of plagiarized content. The first component is a cloud-based platform for document writing or computer program development that allows restricted sharing and maintains records of changes. The records of changes or edits made to a document on the cloud-platform may include a time that a change was made. A second component is a feature extraction module which is based on a writing pattern for a user and incremental content addition as will be described below. The third component is a machine-learning based scheme that predicts which pairs or groups of documents have similar contents indicating plagiarism.
- Each time a change is made to a document on the cloud-based platform, the change and time may be incrementally recorded. Once an assignment is submitted for grading, features are extracted based on the stored history of the document. For example, a sequence or distribution of word n-grams over time may be an indicator of document content. Each person typically is associated with a set of words, phrases, or style of writing that may be utilized to uniquely identify the individual. Similarly, for computer programs, a distribution over programming language-dependent keywords and their relative orders may be computed. A variety of features in addition to, or instead of, n-grams or programming dependent keywords may be extracted from a document. For example, hashes may be generated from the text content and the hashes may be classified by a machine trained on hashes derived from works known to be plagiarized. Variable-invariant features may be extracted for computer programs or essays to prevent variable swapping or synonym swaps from eluding detection. For example, a synonym swap may refer to replacing a word in a sentence with a second word that does not alter the meaning of the sentence. For example, a user may change the sentence, “Alan turned the wheel” to “Alan rotated the tire” as part of a synonym swap.
- Changes in the distribution of words over two time periods may be computed according to an implementation to capture temporal features for each document. The duration of a change and the extent to which content is modified may be factored into whether or not a document has been plagiarized. For example, a cut and paste operation or a systemic change such as renaming a variable may be an indication that an individual has plagiarized a portion of an essay or computer code. An angle between normalized feature vectors or Jaccard (normalized set intersection) similarity may be used to determine a similarity between a pair of documents. Other similarity measures in addition to, or instead of cosine or Jaccard similarity may be used according to implementations disclosed herein, such as histogram intersection or chi-square distance. In an implementation, groups of documents that are similar may be detected (e.g., to detect group plagiarism) using a clustering technique such as hierarchical agglomerative clustering, graph-based spectral clustering, topic-models-based clustering, etc. If the similarity between any pair of documents is above a certain threshold, the degree of similarity may indicate plagiarism in one or both of the documents and the document(s) may be flagged for human verification. A number of visualization techniques can be used that display parts or all of documents that match for easy verification
- In an implementation, an example of which is provided in
FIG. 3 , a system is provided that includes adatabase 310. Thedatabase 310 may store one or more documents for two ormore courses database 310 may be configured to restrict sharing of content (e.g., text, code, pictures, etc.) between documents. For example, within the system, content from one document may not be allowed to be copied to or otherwise shared with another document. Each of the documents stored on thedatabase 310 may be associated with at least one user. For example, a user may access the system and be presented with a user interface that allows the user to create a document. Upon the user doing so, the database may create a record ordocument history 316 for the document. Therecord 316 may include changes that are visible to the user such as new lines of code, edits, new or edited words, etc. Therecord 316 may contain information that is not visible to the user. For example, therecord 316 may be associated with or contain the time at which any changes or additions to the document are made. It may contain an indication of what specifically was changed or added to the document. For example, it may indicate that a paragraph with 200 words was added at a particular time. It may contain a count of the words utilized and/or an n-gram. Thus, mathematical representations, time references, and/or other indicators of features associated with the document may be contained in therecord 316 for the document stored in the database and may not be visible to the user or author of the document. - The
database 310 may be configured to receive a group ofdocuments database 310 for the essay assignment. Each of the documents may be associated with the course. For example, the students may provide an indication that the document is for the course by entering in a course number and/or an assignment code. The system may prompt a user to enter such information before or subsequent to the user electing to create a document. In some configurations, the course instructor may create a template document for the assignment that is populated to an account associated with each student. When a student accesses an account, the student may find the template document and begin work on the essay. - The
database 310 may receive edits to the group of documents by a user (i.e., a student). The group of documents may refer to documents related to a specific course and/or an assignment for that course. Although described here in the context of one document per student, the system may be configured to allow multiple users to work on a single document for group projects. For example, a user may create a document for an assignment and elect to share the document with one or more other individuals. An indication of the sharing may be a part of the record created in thedatabase 310 for the document. Edits made to a document and a time reference corresponding to when the edit was made may be stored in thedatabase 310. For example, a user inserting a paragraph may be associated with a time at which the paragraph was inserted into a document. An indication of the content of the paragraph may also be stored to thedatabase 310. The indication may be a mathematical representation of the paragraph such as a matrix or a vector. - The system may include a
feature extraction module 320 such as the one shown inFIG. 3 . The feature extraction module may be a computer system or a portion of a computer system including a processor configured to perform the module's functions, or similar. Thefeature extraction module 320 may obtain a writing history for the one or more users associated with the one of the group of documents. For example, thefeature extraction module 320 may determine if a user has submitted and/or created any other documents in thedatabase 310. If the user has other documents stored to the database, thefeature extraction module 320 may determine a writing pattern for each of the user's documents. For example, it may determine a distribution of words (e.g., n-grams) that the user has used in each of the other documents stored to the database. Term frequency inverse document frequency (“Tf-idf”) may be applied to the extracted features to remove or reduce the influence of common words such as “a” or “the” from the user's n-gram. Thefeature extraction module 320 may determine a writing pattern associated with the document based on the writing history for the user, an edit made to the document, and/or at least one time reference. If the user does not have any other documents in thedatabase 310 then the feature extraction module may determine a writing pattern for the user based on the single available document, such as by analyzing edits and corresponding time references for the document. A feature vector may be generated for the writing pattern for each user. - As an example, a feature extraction module may determine a distribution of words (e.g., n-grams) for a user for any document written by the user that is stored in the database. The distribution of words may be a count for every word that is in the documents (i.e., there may be 100 “the” or 1 “agape”). The database may have a temporal history of edits for each of the documents written by the user. The feature extraction module may generate a histogram of the distribution of words written over time based on the temporal history and the count of words. The histogram may be a signal or represented as a feature vector which may be classified according to a trained machine learning algorithm.
- The feature vector for a first user may be compared to a feature vector for one or more other users. For example, the feature vectors for students of a course may be compared to one another in a pairwise fashion. An indication of the similarity between the feature vectors may be provided. As stated earlier, a similarity score for a feature vector to one or more other feature vectors may be determined using cosine or Jaccard similarity. The features, such as the distribution of words or n-grams, utilized for a pairwise similarity between the first user and one or more other users may be different than the features utilized for a machine learning classification (described below).
- According to an implementation, a machine learning technique may be trained on a first set of documents that are known to be plagiarized, and the feature vector may be classified using the trained machine learning algorithm. For example, writing patterns based on features extracted from a set of documents that have been known to be plagiarized may be obtained and feature vectors representing the plagiarized writing patterns may be generated. For example, training data may be generated by using those documents that are known to be plagiarized, by manually reviewing a set of documents and grouping plagiarized and non-plagiarized works, and/or by generating synthetic sets of documents that employ techniques commonly used for plagiarism (e.g., copying in a whole paragraph, global replacement of a variable, etc.). Writing patterns from non-plagiarized works may be determined and feature vectors may be generated from the non-plagiarized documents based on the writing patterns. The machine learning algorithm may be trained on the feature vectors for both plagiarized and non-plagiarized documents. The trained classifier may be applied to the feature vector extracted from the group of documents described earlier.
- In an implementation, a system is provided that include a database and a processor connected thereto. An example of the system is provided in
FIG. 4 . Thedatabase 410 may store one ormore documents 412 and may restrict sharing of content betweendocuments 412 stored therein. Theprocessor 420 may be configured to receive one ormore edits 422 to adocument 412 stored in thedatabase 410. For example, a user may open thedocument 412 and paste in text or other content, type a new paragraph, or the like. Atime reference 424 may be associated with theedit 422 to thedocument 412. Theedit 422, thetime reference 424 and/or the type of edit may be stored. In an implementation, a hash of the edit, time reference, and/or type of edit may be generated and stored in addition to, or instead of, separately storing the edit, time reference, and/or type of edit. A type of edit may refer to, for example, copy, paste, delete, add, move, search-and-replace, etc. Theedit 422 and thetime reference 424 may be stored to the database as adocument history 414. Afeature vector 426 based on thedocument history 414 may be generated. In some configurations, the feature vector may be stored to the database. A probability that the document is plagiarized may be determined based on a classification of the feature vector by a machine learning technique. As described earlier, the machine learning model, such as a logistical regression model or a support vector machine (“SVM”) may be trained on a set of documents known to be plagiarized. Classification of the feature vector by the machine learning technique may result in a ranked list of documents according to the probability that they have been plagiarized. An instructor may set a threshold value of probability of plagiarism above which the instructor may elect to manually review the documents. - Two types of features may be evaluated according to implementations disclosed herein, including independent features and/or pairwise features. Independent features may relate to a user's own writing pattern and typically do not convey or utilize information from other users. Pairwise features can be obtained by comparing the independent features against other users, for example, that are taking the same course. For example, a feature vector for a particular user that reflects the distribution of words used for a document may be compared against feature vectors generated from documents for other users taking the same course. Distances of the nearest matches to the particular user's feature vector may be features themselves. The number of nearest matches selected as features may be predefined or configured as desired. This may assume that the twenty nearest feature vectors to the particular user's feature vector were not plagiarizing. The twenty distance features may be compared to all other documents in the group of documents. Documents that are plagiarized are likely to be close in distance to the twenty distance features. The probability may be based on at least one pairwise comparison of the feature vector for the document to at least one other feature vector for a second document in the database. The probability may be based on a comparison of the feature history to an independent signal (i.e., feature). As stated above, the independent signal may correspond to other documents generated by an author of the document stored in the database.
- In an implementation, an example of which is provided in
FIG. 5 , a group of documents related to a course may be received at 510. For example, a database may store several groups of documents from several different courses. At least one edit to one of the group of documents by at least one user may be received at 520. The at least one edit and at least one time reference corresponding to the time during which the at least one edit was made may be stored at 530 as described earlier. A writing history for the at least one user associated with the one of the group of documents may be obtained at 540. As stated earlier, the writing pattern may be based on other documents authored by a particular user in the database. A writing pattern associated with the one of the group of documents may be determined based on the writing history for the at least one user, the at least one edit, and at least one time reference at 550. A feature vector for the writing pattern may be generated at 560. The feature vector may then be used, for example, to detect potential plagiarism and/or assign a probability of plagiarism as previously described. - According to an implementation, an example of which is provided in
FIG. 6 , an edit to a document stored in a database may be received at 610. A time reference may be associated with the edit to the document at 620. The edit and the time reference may be stored to the database as a document history at 630. A feature vector may be generated based on the document history at 640 and a probability that the document is plagiarized may be determined based on a classification of the feature vector by a machine learning technique at 650 as described above. - Implementations of the presently disclosed subject matter may be implemented in and used with a variety of component and network architectures.
FIG. 1 is anexample computer system 20 suitable for implementing implementations of the presently disclosed subject matter. Thecomputer 20 includes a bus 21 which interconnects major components of thecomputer 20, such as one ormore processors 24,memory 27 such as RAM, ROM, flash RAM, or the like, an input/output controller 28, and fixedstorage 23 such as a hard drive, flash storage, SAN device, or the like. It will be understood that other components may or may not be included, such as a user display such as a display screen via a display adapter, user input interfaces such as controllers and associated user input devices such as a keyboard, mouse, touchscreen, or the like, and other components known in the art to use in or in conjunction with general-purpose computing systems. - The bus 21 allows data communication between the
central processor 24 and thememory 27. The RAM is generally the main memory into which the operating system and application programs are loaded. The ROM or flash memory can contain, among other code, the Basic Input-Output system (BIOS) which controls basic hardware operation such as the interaction with peripheral components. Applications resident with thecomputer 20 are generally stored on and accessed via a computer readable medium, such as the fixedstorage 23 and/or thememory 27, an optical drive, external storage mechanism, or the like. - Each component shown may be integral with the
computer 20 or may be separate and accessed through other interfaces. Other interfaces, such as anetwork interface 29, may provide a connection to remote systems and devices via a telephone link, wired or wireless local- or wide-area network connection, proprietary network connections, or the like. For example, thenetwork interface 29 may allow the computer to communicate with other computers via one or more local, wide-area, or other networks, as shown inFIG. 2 . - Many other devices or components (not shown) may be connected in a similar manner, such as document scanners, digital cameras, auxiliary, supplemental, or backup systems, or the like. Conversely, all of the components shown in
FIG. 1 need not be present to practice the present disclosure. The components can be interconnected in different ways from that shown. The operation of a computer such as that shown inFIG. 1 is readily known in the art and is not discussed in detail in this application. Code to implement the present disclosure can be stored in computer-readable storage media such as one or more of thememory 27, fixedstorage 23, remote storage locations, or any other storage mechanism known in the art. -
FIG. 2 shows an example arrangement according to an implementation of the disclosed subject matter. One ormore clients 10, 11, such as local computers, smart phones, tablet computing devices, remote services, and the like may connect to other devices via one ormore networks 7. The network may be a local network, wide-area network, the Internet, or any other suitable communication network or networks, and may be implemented on any suitable platform including wired and/or wireless networks. Theclients 10, 11 may communicate with one or more computer systems, such asprocessing units 14,databases 15, anduser interface systems 13. In some cases,clients 10, 11 may communicate with auser interface system 13, which may provide access to one or more other systems such as adatabase 15, aprocessing unit 14, or the like. For example, theuser interface 13 may be a user-accessible web page that provides data from one or more other computer systems. Theuser interface 13 may provide different interfaces to different clients, such as where a human-readable web page is provided to web browser clients 10, and a computer-readable API or other interface is provided toremote service clients 11. Theuser interface 13,database 15, andprocessing units 14 may be part of an integral system, or may include multiple computer systems communicating via a private network, the Internet, or any other suitable network.Processing units 14 may be, for example, part of a distributed system such as a cloud-based computing system, search engine, content delivery system, or the like, which may also include or communicate with adatabase 15 and/oruser interface 13. In some arrangements, ananalysis system 5 may provide back-end processing, such as where stored or acquired data is pre-processed by theanalysis system 5 before delivery to theprocessing unit 14,database 15, and/oruser interface 13. For example, amachine learning system 5 may provide various prediction models, data analysis, or the like to one or moreother systems - More generally, various implementations of the presently disclosed subject matter may include or be implemented in the form of computer-implemented processes and apparatuses for practicing those processes. Implementations also may be implemented in the form of a computer program product having computer program code containing instructions implemented in non-transitory and/or tangible media, such as floppy diskettes, CD-ROMs, hard drives, USB (universal serial bus) drives, or any other machine readable storage medium, wherein, when the computer program code is loaded into and executed by a computer, the computer becomes an apparatus for practicing implementations of the disclosed subject matter. Implementations also may be implemented in the form of computer program code, for example, whether stored in a storage medium, loaded into and/or executed by a computer, or transmitted over some transmission medium, such as over electrical wiring or cabling, through fiber optics, or via electromagnetic radiation, wherein when the computer program code is loaded into and executed by a computer, the computer becomes an apparatus for practicing implementations of the disclosed subject matter. When implemented on a general-purpose microprocessor, the computer program code segments configure the microprocessor to create specific logic circuits. In some configurations, a set of computer-readable instructions stored on a computer-readable storage medium may be implemented by a general-purpose processor, which may transform the general-purpose processor or a device containing the general-purpose processor into a special-purpose device configured to implement or carry out the instructions. Implementations may be implemented using hardware that may include a processor, such as a general purpose microprocessor and/or an Application Specific Integrated Circuit (ASIC) that implements all or part of the techniques according to implementations of the disclosed subject matter in hardware and/or firmware. The processor may be coupled to memory, such as RAM, ROM, flash memory, a hard disk or any other device capable of storing electronic information. The memory may store instructions adapted to be executed by the processor to perform the techniques according to implementations of the disclosed subject matter.
- The foregoing description, for purpose of explanation, has been described with reference to specific implementations. However, the illustrative discussions above are not intended to be exhaustive or to limit implementations of the disclosed subject matter to the precise forms disclosed. Many modifications and variations are possible in view of the above teachings. The implementations were chosen and described in order to explain the principles of implementations of the disclosed subject matter and their practical applications, to thereby enable others skilled in the art to utilize those implementations as well as various implementations with various modifications as may be suited to the particular use contemplated.
Claims (13)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/143,710 US9514417B2 (en) | 2013-12-30 | 2013-12-30 | Cloud-based plagiarism detection system performing predicting based on classified feature vectors |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/143,710 US9514417B2 (en) | 2013-12-30 | 2013-12-30 | Cloud-based plagiarism detection system performing predicting based on classified feature vectors |
Publications (2)
Publication Number | Publication Date |
---|---|
US20150186787A1 true US20150186787A1 (en) | 2015-07-02 |
US9514417B2 US9514417B2 (en) | 2016-12-06 |
Family
ID=53482184
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US14/143,710 Expired - Fee Related US9514417B2 (en) | 2013-12-30 | 2013-12-30 | Cloud-based plagiarism detection system performing predicting based on classified feature vectors |
Country Status (1)
Country | Link |
---|---|
US (1) | US9514417B2 (en) |
Cited By (13)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20160293035A1 (en) * | 2015-03-31 | 2016-10-06 | Fujitsu Limited | Assignment guidance in curation learning |
US20160378435A1 (en) * | 2015-06-25 | 2016-12-29 | Ca, Inc. | Automatic Discovery of Comparable Features Based on N-gram Analysis |
US20170004410A1 (en) * | 2015-07-03 | 2017-01-05 | Christopher William Paran | Standardized process to quantify the value of research manuscripts |
US20170364827A1 (en) * | 2016-06-16 | 2017-12-21 | Jack Conrad | Scenario Analytics System |
US20180365589A1 (en) * | 2017-06-16 | 2018-12-20 | International Business Machines Corporation | Machine learning for ranking candidate subjects based on a training set |
US10649740B2 (en) * | 2015-01-15 | 2020-05-12 | International Business Machines Corporation | Predicting and using utility of script execution in functional web crawling and other crawling |
US10963627B2 (en) * | 2018-06-11 | 2021-03-30 | Adobe Inc. | Automatically generating digital enterprise content variants |
US11094335B1 (en) * | 2016-07-22 | 2021-08-17 | Educational Testing Service | Systems and methods for automatic detection of plagiarized spoken responses |
US20210334013A1 (en) * | 2020-04-22 | 2021-10-28 | EMC IP Holding Company LLC | Method and Apparatus for Identifying a Device Missing from a Consistency Group |
US20210390649A1 (en) * | 2015-07-23 | 2021-12-16 | Hee Jae Cho | Integrated scholarship management system and scholarship operation method using same |
US11488012B2 (en) * | 2016-12-27 | 2022-11-01 | Obschestvo S Ogranichennoy Otvetstvennostyu “Vizhnlabs” | Training of deep neural networks on the basis of distributions of paired similarity measures |
US20220414317A1 (en) * | 2019-12-04 | 2022-12-29 | Microsoft Technology Licensing, Llc | Method and System for Intelligently Detecting and Modifying Unoriginal Content |
WO2024085717A1 (en) * | 2022-10-20 | 2024-04-25 | 주식회사 아이팩토리 | Thesis writing device, method, computer program, computer-readable recording medium, server, and system |
Families Citing this family (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20160196342A1 (en) * | 2015-01-06 | 2016-07-07 | Inha-Industry Partnership | Plagiarism Document Detection System Based on Synonym Dictionary and Automatic Reference Citation Mark Attaching System |
US11416503B2 (en) | 2018-02-09 | 2022-08-16 | Microsoft Technology Licensing, Llc | Mining data for generating consumable collaboration events |
US20190333401A1 (en) * | 2018-04-30 | 2019-10-31 | Brian Cepuran | Systems and methods for electronic prediction of rubric assessments |
US10943059B2 (en) * | 2018-06-27 | 2021-03-09 | Microsoft Technology Licensing, Llc | Document editing models and management |
Citations (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20050060643A1 (en) * | 2003-08-25 | 2005-03-17 | Miavia, Inc. | Document similarity detection and classification system |
US20120131015A1 (en) * | 2010-11-24 | 2012-05-24 | King Abdulaziz City For Science And Technology | System and method for rating a written document |
US20120254333A1 (en) * | 2010-01-07 | 2012-10-04 | Rajarathnam Chandramouli | Automated detection of deception in short and multilingual electronic messages |
US20130138428A1 (en) * | 2010-01-07 | 2013-05-30 | The Trustees Of The Stevens Institute Of Technology | Systems and methods for automatically detecting deception in human communications expressed in digital form |
US20130246431A1 (en) * | 2011-12-27 | 2013-09-19 | Mcafee, Inc. | System and method for providing data protection workflows in a network environment |
Family Cites Families (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6978419B1 (en) | 2000-11-15 | 2005-12-20 | Justsystem Corporation | Method and apparatus for efficient identification of duplicate and near-duplicate documents and text spans using high-discriminability text fragments |
US20090226872A1 (en) | 2008-01-16 | 2009-09-10 | Nicholas Langdon Gunther | Electronic grading system |
US20120296637A1 (en) | 2011-05-20 | 2012-11-22 | Smiley Edwin Lee | Method and apparatus for calculating topical categorization of electronic documents in a collection |
-
2013
- 2013-12-30 US US14/143,710 patent/US9514417B2/en not_active Expired - Fee Related
Patent Citations (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20050060643A1 (en) * | 2003-08-25 | 2005-03-17 | Miavia, Inc. | Document similarity detection and classification system |
US20120254333A1 (en) * | 2010-01-07 | 2012-10-04 | Rajarathnam Chandramouli | Automated detection of deception in short and multilingual electronic messages |
US20130138428A1 (en) * | 2010-01-07 | 2013-05-30 | The Trustees Of The Stevens Institute Of Technology | Systems and methods for automatically detecting deception in human communications expressed in digital form |
US20120131015A1 (en) * | 2010-11-24 | 2012-05-24 | King Abdulaziz City For Science And Technology | System and method for rating a written document |
US20130246431A1 (en) * | 2011-12-27 | 2013-09-19 | Mcafee, Inc. | System and method for providing data protection workflows in a network environment |
Non-Patent Citations (4)
Title |
---|
Alzahrani et al., Understanding Plagiarism Linguistic Patterns, Textual Features, and Detection Methods, 2012, IEEE TRANSACTIONS ON SYSTEMS, MAN, AND CYBERNETICS, pp:133-149 * |
Ceska, Plagiarism Detection Based on Singular Value Decomposition, 2008, Springer-Verlag, pp:108-119 * |
Lukashenko et al., Computer-Based Plagiarism Detection Methods and Tools: An Overview, 2007, CompSysTech, pp: 1-6 * |
Subroto et al., Plagiarism Detection on the Student Assignment from Internet using Words n-grams Fingerprints, 2008, PARS, pp:1-4 * |
Cited By (19)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10740071B2 (en) * | 2015-01-15 | 2020-08-11 | International Business Machines Corporation | Predicting and using utility of script execution in functional web crawling and other crawling |
US10649740B2 (en) * | 2015-01-15 | 2020-05-12 | International Business Machines Corporation | Predicting and using utility of script execution in functional web crawling and other crawling |
US20160293035A1 (en) * | 2015-03-31 | 2016-10-06 | Fujitsu Limited | Assignment guidance in curation learning |
US10062131B2 (en) * | 2015-03-31 | 2018-08-28 | Fujitsu Limited | Assignment guidance in curation learning |
US20160378435A1 (en) * | 2015-06-25 | 2016-12-29 | Ca, Inc. | Automatic Discovery of Comparable Features Based on N-gram Analysis |
US9778914B2 (en) * | 2015-06-25 | 2017-10-03 | Ca, Inc. | Automatic discovery of comparable features based on N-gram analysis |
US20170004410A1 (en) * | 2015-07-03 | 2017-01-05 | Christopher William Paran | Standardized process to quantify the value of research manuscripts |
US20210390649A1 (en) * | 2015-07-23 | 2021-12-16 | Hee Jae Cho | Integrated scholarship management system and scholarship operation method using same |
US20170364827A1 (en) * | 2016-06-16 | 2017-12-21 | Jack Conrad | Scenario Analytics System |
US11094335B1 (en) * | 2016-07-22 | 2021-08-17 | Educational Testing Service | Systems and methods for automatic detection of plagiarized spoken responses |
US11488012B2 (en) * | 2016-12-27 | 2022-11-01 | Obschestvo S Ogranichennoy Otvetstvennostyu “Vizhnlabs” | Training of deep neural networks on the basis of distributions of paired similarity measures |
US11182692B2 (en) * | 2017-06-16 | 2021-11-23 | International Business Machines Corporation | Machine learning for ranking candidate subjects based on a training set |
US20180365589A1 (en) * | 2017-06-16 | 2018-12-20 | International Business Machines Corporation | Machine learning for ranking candidate subjects based on a training set |
US10963627B2 (en) * | 2018-06-11 | 2021-03-30 | Adobe Inc. | Automatically generating digital enterprise content variants |
US20220414317A1 (en) * | 2019-12-04 | 2022-12-29 | Microsoft Technology Licensing, Llc | Method and System for Intelligently Detecting and Modifying Unoriginal Content |
US11651147B2 (en) * | 2019-12-04 | 2023-05-16 | Microsoft Technology Licensing, Llc | Method and system for intelligently detecting and modifying unoriginal content |
US20210334013A1 (en) * | 2020-04-22 | 2021-10-28 | EMC IP Holding Company LLC | Method and Apparatus for Identifying a Device Missing from a Consistency Group |
US11520488B2 (en) * | 2020-04-22 | 2022-12-06 | Dell Products, L.P. | Method and apparatus for identifying a device missing from a consistency group |
WO2024085717A1 (en) * | 2022-10-20 | 2024-04-25 | 주식회사 아이팩토리 | Thesis writing device, method, computer program, computer-readable recording medium, server, and system |
Also Published As
Publication number | Publication date |
---|---|
US9514417B2 (en) | 2016-12-06 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US9514417B2 (en) | Cloud-based plagiarism detection system performing predicting based on classified feature vectors | |
US20210286830A1 (en) | Data loss prevention system for cloud security based on document discourse analysis | |
US11016966B2 (en) | Semantic analysis-based query result retrieval for natural language procedural queries | |
WO2021174919A1 (en) | Method and apparatus for analysis and matching of resume data information, electronic device, and medium | |
US9678949B2 (en) | Vital text analytics system for the enhancement of requirements engineering documents and other documents | |
US11010673B2 (en) | Method and system for entity relationship model generation | |
JP7289047B2 (en) | Method, computer program and system for block-based document metadata extraction | |
US9852215B1 (en) | Identifying text predicted to be of interest | |
CN107436922A (en) | Text label generation method and device | |
US9224103B1 (en) | Automatic annotation for training and evaluation of semantic analysis engines | |
CN110569335B (en) | Triple verification method and device based on artificial intelligence and storage medium | |
US9679050B2 (en) | Method and apparatus for generating thumbnails | |
US20180285448A1 (en) | Producing personalized selection of applications for presentation on web-based interface | |
JP6420268B2 (en) | Image evaluation learning device, image evaluation device, image search device, image evaluation learning method, image evaluation method, image search method, and program | |
CN106663123B (en) | Comment-centric news reader | |
US10504002B2 (en) | Systems and methods for clustering of near-duplicate images in very large image collections | |
Hulpuș et al. | Knowledge graphs meet moral values | |
KR102280490B1 (en) | Training data construction method for automatically generating training data for artificial intelligence model for counseling intention classification | |
CN116402166B (en) | Training method and device of prediction model, electronic equipment and storage medium | |
WO2021139242A1 (en) | Presentation file generation method, apparatus, and device and storage medium | |
US11880798B2 (en) | Determining section conformity and providing recommendations | |
US20220164714A1 (en) | Generating and modifying ontologies for machine learning models | |
US20220309276A1 (en) | Automatically classifying heterogenous documents using machine learning techniques | |
CN114168715A (en) | Method, device and equipment for generating target data set and storage medium | |
US20190318223A1 (en) | Methods and Systems for Data Analysis by Text Embeddings |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:KERNIGHAN, BRIAN;KUMAR, SANJIV;SIGNING DATES FROM 20131224 TO 20131227;REEL/FRAME:031859/0476 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044097/0658Effective date: 20170929 |
|
FEPP | Fee payment procedure |
Free format text: MAINTENANCE FEE REMINDER MAILED (ORIGINAL EVENT CODE: REM.); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
LAPS | Lapse for failure to pay maintenance fees |
Free format text: PATENT EXPIRED FOR FAILURE TO PAY MAINTENANCE FEES (ORIGINAL EVENT CODE: EXP.); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
STCH | Information on status: patent discontinuation |
Free format text: PATENT EXPIRED DUE TO NONPAYMENT OF MAINTENANCE FEES UNDER 37 CFR 1.362 |
|
FP | Lapsed due to failure to pay maintenance fee |
Effective date: 20201206 |