CN117043767A - Multi-source extraction and scoring of abbreviated query answers - Google Patents
Multi-source extraction and scoring of abbreviated query answers Download PDFInfo
- Publication number
- CN117043767A CN117043767A CN202280005247.5A CN202280005247A CN117043767A CN 117043767 A CN117043767 A CN 117043767A CN 202280005247 A CN202280005247 A CN 202280005247A CN 117043767 A CN117043767 A CN 117043767A
- Authority
- CN
- China
- Prior art keywords
- paragraphs
- candidate
- accuracy score
- passage
- paragraph
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
- 238000000605 extraction Methods 0.000 title description 3
- 238000000034 method Methods 0.000 claims abstract description 56
- 238000012549 training Methods 0.000 claims abstract description 34
- 230000015654 memory Effects 0.000 claims description 77
- 238000004590 computer program Methods 0.000 claims description 16
- 230000006870 function Effects 0.000 claims description 15
- 238000012545 processing Methods 0.000 claims description 15
- 230000004044 response Effects 0.000 claims description 12
- 238000004891 communication Methods 0.000 description 24
- 241000251468 Actinopterygii Species 0.000 description 15
- 235000019688 fish Nutrition 0.000 description 15
- 238000010586 diagram Methods 0.000 description 11
- 230000003287 optical effect Effects 0.000 description 7
- 230000008569 process Effects 0.000 description 7
- 238000012986 modification Methods 0.000 description 4
- 230000004048 modification Effects 0.000 description 4
- 235000015170 shellfish Nutrition 0.000 description 4
- 238000013528 artificial neural network Methods 0.000 description 3
- 230000001413 cellular effect Effects 0.000 description 3
- 235000020988 fatty fish Nutrition 0.000 description 3
- 239000007787 solid Substances 0.000 description 3
- 241000972773 Aulopiformes Species 0.000 description 2
- 239000000796 flavoring agent Substances 0.000 description 2
- 235000019634 flavors Nutrition 0.000 description 2
- 230000003993 interaction Effects 0.000 description 2
- 235000021190 leftovers Nutrition 0.000 description 2
- 239000004973 liquid crystal related substance Substances 0.000 description 2
- 235000013372 meat Nutrition 0.000 description 2
- 235000019515 salmon Nutrition 0.000 description 2
- 238000013515 script Methods 0.000 description 2
- 241000276457 Gadidae Species 0.000 description 1
- 235000019687 Lamb Nutrition 0.000 description 1
- 241000269908 Platichthys flesus Species 0.000 description 1
- 241000269978 Pleuronectiformes Species 0.000 description 1
- 238000003491 array Methods 0.000 description 1
- 230000000712 assembly Effects 0.000 description 1
- 238000000429 assembly Methods 0.000 description 1
- 235000015278 beef Nutrition 0.000 description 1
- 230000008901 benefit Effects 0.000 description 1
- 238000007796 conventional method Methods 0.000 description 1
- 230000009193 crawling Effects 0.000 description 1
- 230000001419 dependent effect Effects 0.000 description 1
- 238000005516 engineering process Methods 0.000 description 1
- 238000007429 general method Methods 0.000 description 1
- 238000010801 machine learning Methods 0.000 description 1
- 238000010295 mobile communication Methods 0.000 description 1
- 230000006855 networking Effects 0.000 description 1
- 235000015277 pork Nutrition 0.000 description 1
- 230000009467 reduction Effects 0.000 description 1
- 238000012552 review Methods 0.000 description 1
- 230000001953 sensory effect Effects 0.000 description 1
- 230000003068 static effect Effects 0.000 description 1
- 238000006467 substitution reaction Methods 0.000 description 1
- 230000001502 supplementing effect Effects 0.000 description 1
- 239000010409 thin film Substances 0.000 description 1
- 230000000007 visual effect Effects 0.000 description 1
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/95—Retrieval from the web
- G06F16/957—Browsing optimisation, e.g. caching or content distillation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/95—Retrieval from the web
- G06F16/953—Querying, e.g. by the use of web search engines
- G06F16/9538—Presentation of query results
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/95—Retrieval from the web
- G06F16/951—Indexing; Web crawling techniques
Abstract
Techniques for generating short answers to queries by search engines include: a training operation is performed on a training data corpus containing candidate paragraphs providing short answers for display in a legend and remaining corresponding paragraphs from which the top scoring short answers are generated to train a score prediction engine. In such embodiments, the training data corpus also includes the remaining respective paragraphs and the respective headings of the candidate paragraphs and the remaining respective paragraphs.
Description
Technical Field
The present description relates to generating short answers for display in a browser running a search engine.
Background
Some search engines support short answers displayed in a legend that is displayed at a prominent position within a search browser window displaying search engine results. This highlighting of short answers provides the user with a very quick answer to the factual query without the user having to select a search result and click on it before obtaining an answer to the query. Furthermore, search engines can directly provide answers to a diverse range of questions without the need for elaborate knowledge bases.
Disclosure of Invention
Embodiments described herein relate to generating a short answer for display based on a plurality of paragraphs generated by a query provided to a search engine. The abbreviated answer is an answer to a factual query highlighted in a browser window running the search engine; such answers may originate from, or be, paragraphs in the top ranked search results. Only the paragraphs from which the simple answers are derived are good, the short answers are good; thus, when a short answer is derived from a paragraph, using other paragraphs as context should improve the quality of the short answer. Determining whether to display the particular abbreviated answer depends on an accuracy score provided by an accuracy score prediction engine; a brief answer may or may not be displayed based on whether the accuracy score is greater than or less than an accuracy score threshold, respectively. The accuracy score may be determined by an accuracy score prediction engine that predicts an accuracy score for a paragraph from the top-ranked search result based on consistency of the paragraph from the top-ranked search result with other paragraphs from other search results. The accuracy score prediction engine is trained using paragraphs from search engine results, which the raters manually score based on consistency of the paragraphs from search engine results with contextual paragraphs from other search results.
In one general aspect, a computer-based method may include receiving query data representing a search query entered by a user into a search engine. The method may also include generating a plurality of search results based on the search query, each of the plurality of search results having a respective paragraph related to the search query. The method may further include selecting a set of respective paragraphs, one of the respective paragraphs in the set being a candidate paragraph belonging to a top-ranked search result of the plurality of search results, and the remaining respective paragraphs in the set being contextual paragraphs. The method may further comprise scoring the candidate paragraphs using the contextual paragraphs to produce an accuracy score for the candidate paragraphs. The method may further include providing the candidate paragraphs for display in a search results page presented by a browser window on the display as a brief answer based on the accuracy score.
In another general method, a computer program product comprising a non-transitory storage medium, the computer program product comprising code that, when executed by processing circuitry of a computing device, causes the processing circuitry to perform the method. The method may include receiving query data representing a search query entered by a user into a search engine. The method may also include generating a plurality of search results based on the search query, each of the plurality of search results having a respective paragraph related to the search query. The method may further include selecting a set of respective paragraphs, one of the respective paragraphs in the set being a candidate paragraph belonging to a top-ranked search result of the plurality of search results, and the remaining respective paragraphs in the set being contextual paragraphs. The method may further comprise scoring the candidate paragraphs using the contextual paragraphs to produce an accuracy score for the candidate paragraphs. The method may further include providing the candidate paragraphs for display in a search results page presented by a browser window on the display as a brief answer based on the accuracy score.
In another general aspect, an electronic device includes a memory and a control circuit coupled to the memory. The control circuitry may be configured to receive query data representing a search query entered into a search engine by a user. The control circuitry may be further configured to generate a plurality of search results based on the search query, each of the plurality of search results having a respective paragraph related to the search query. The control circuitry may be further configured to select a set of respective paragraphs, one of the respective paragraphs in the set being a candidate paragraph belonging to a top-ranked search result of the plurality of search results, and the remaining respective paragraphs in the set being contextual paragraphs. The control circuitry may be further configured to score the candidate passage using the context passage to produce an accuracy score for the candidate passage. The control circuitry may be further configured to provide the candidate paragraphs for display in a search results page presented by a browser window on the display as a brief answer based on the accuracy score.
The details of one or more embodiments are set forth in the accompanying drawings and the description below. Other features will be apparent from the description and drawings, and from the claims.
Drawings
FIG. 1A is a diagram illustrating an example search engine in which the improved techniques described herein may be implemented.
FIG. 1B is a diagram illustrating an example short answer generated by a search query displayed in a browser window on a display.
FIG. 2 is a diagram illustrating an example electronic environment in which the improved techniques described herein may be implemented.
FIG. 3 is a diagram illustrating an example data flow from a plurality of top-scoring paragraphs from search results into a legend.
FIG. 4 is a diagram illustrating example inputs and outputs from an accuracy score prediction engine.
FIG. 5 is a flowchart illustrating an example method of performing consistency-based presentation of short answers in accordance with the disclosed embodiments.
Fig. 6 is a diagram illustrating an example of a computer device and a mobile computer device that may be used to implement the described techniques.
FIG. 7 is a diagram illustrating an example of a distributed computer apparatus that may be used to implement the described techniques.
Detailed Description
Some search engines support short answers displayed in a prominent position within a search browser window displaying search engine results. The short answers contain paragraphs or extractions of paragraphs that represent answers to the factual queries. This highlighting of short answers provides the user with a very quick answer to the query without the user having to select a search result and click on it before obtaining the answer to the query. Furthermore, search engines can directly provide answers to a diverse range of questions without the need for elaborate knowledge bases. But selecting paragraphs for brief answers can be complex and error prone.
For example, in response to the query "What does NFC stand for in sports (what NFC stands for in sports)" from the user, the search engine may display a brief answer at the highlighting of the user's display. In this case, the user would like to see "National Football Conference (national football association)" highlighted in the search engine browser window on the user display. However, the answer "Near Field Communication (near field communication)" may alternatively be displayed.
Conventional search engines that support short answers, sometimes displayed in legends, obtain each short answer separately from the corresponding search results. The search results selected for the abbreviated answers to a given query may represent a web site and include links to the web site displayed in the search results, from which the abbreviated answers are retrieved. The selection of a short answer by the search engine involves retrieving the top ranked paragraph of search results from the web site and selecting the paragraph (text span) that is determined to be most likely to contain the answer to the query.
The technical problem of the conventional method of generating short answers described above is that the short answers in the conventional search engine described above may have different qualities depending on the selected search results. In such methods, the logic for selecting the paragraph for which the simple answer is obtained does not take into account the quality of the short answer. Thus, in some cases, the brief answer may be misleading or even erroneous.
According to the embodiments described herein, the technical solution of the technical problem described above comprises an improved scoring engine (accuracy score prediction engine) for determining whether to display a short answer. The improved scoring engine uses a plurality of paragraphs from a plurality of different corresponding search results. Determining whether to display the particular abbreviated answer depends on an accuracy score provided by an accuracy score prediction engine; a brief answer may or may not be displayed based on whether the accuracy score is greater than or less than an accuracy score threshold, respectively. The accuracy score may be determined by an accuracy score prediction engine that predicts an accuracy score for a paragraph from the top ranked search result based on consistency with other paragraphs from other search results. The accuracy score prediction engine is trained using paragraphs from search engine results, and raters manually score paragraphs from search engine results based on consistency with contextual paragraphs from other search results.
A technical advantage of the disclosed embodiments is that the short answers provided by the improved search engine described above are of higher quality (e.g., more likely to be correct) than conventional search engines because the search engine determines the degree of consistency between multiple paragraphs from different sources. Furthermore, the quality of the improved short answer may result in fewer user queries and a corresponding reduction in network data.
FIG. 1A depicts an example environment 100 in which a user may interact with one or more computer-implemented search services. An example computer-implemented search service may include a search service for: email services, chat services, document sharing services, calendar sharing services, photo sharing services, video sharing services, shopping services, blogging services, microblog services, social networking services, location (location awareness) services, registration services, and/or rating and review services. In the example of fig. 1A, an internet search service is depicted, which will be discussed in further detail herein. However, it should be understood that embodiments of the present disclosure may include one or more computer-implemented services, such as the examples discussed herein.
With continued reference to FIG. 1A, the search system 120 provides search services. The example environment 100 includes a network 102, such as a local area network (local area network; LAN), wide area network (wide area network; WAN), the Internet, or a combination thereof, that connects the web site 104, the user device 106, and the search system 120. In some examples, network 102 may be accessed through wired and/or wireless communication links. For example, a mobile computing device such as a smart phone may utilize a cellular network to access the network. The environment 100 may contain millions of websites 104 and user devices 106.
In some examples, the website 104 is provided as one or more resources 105 associated with a domain name and hosted by one or more servers. An example website is a collection of web pages formatted in a suitable machine-readable language, such as hypertext markup language (HTML), which may contain text, images, multimedia content, and programming elements, such as scripts. Each website 104 is maintained by a publisher, e.g., an entity that manages and/or owns the website. The web site resources 105 may be static or dynamic.
In some examples, the resource 105 is data provided over the network 102 and is associated with a resource address, such as a Uniform Resource Locator (URL). In some examples, resources 105 that may be provided by web site 104 include web pages, word processing documents, and Portable Document Format (PDF) documents, images, videos, and feeds, among other suitable digital content. The resource 105 may contain content, such as words, phrases, images, and sounds, and may contain embedded information, such as meta information and hyperlinks, and/or embedded instructions, such as scripts.
In some examples, the user device 106 is an electronic device that is under user control and is capable of requesting and receiving resources 105 through the network 102. Example user devices 106 include personal computers, mobile computing devices, such as smartphones, wearable devices, and/or tablet computing devices, that can send and receive data over the network 102. As used in this document, the term mobile computing device ("mobile device") refers to a user device configured to communicate over a mobile communications network. Smart phones, such as those capable of communicating over the internet, are examples of mobile devices, as are wearable devices and other smart devices such as smart speakers. User device 106 typically includes a user application, such as a web browser, to facilitate the sending and receiving of data over network 102.
In some examples, to facilitate searching for resources 105, search system 120 identifies resources 105 by crawling and indexing resources 105 provided on web site 104. The data about the resources 105 may be indexed based on the resources to which the data corresponds. The indexed and optionally cached copy of resource 105 is stored in search index 122, for example, as indexed resource 126.
User device 106 submits search query 109 to search system 120. In some examples, the user device 106 may contain one or more input modes. Example modes may include a keyboard, a touch screen, and/or a microphone. For example, a user may type a search query using a keyboard and/or touch screen. As another example, a user may speak a search query, capture user speech through a microphone, and process the user speech through speech recognition to provide the search query.
In response to receiving the search query 109, the search system 120 accesses the search index 122 to identify resources 105 relevant to the search query 109, e.g., resources 105 having at least a minimum specified relevance score for the search query 109. The search system 120 identifies the resource 105, generates a search results display 111 containing search results 112 identifying the resource 105 and a short answer 113, and returns the search results display 111 to the user device 106. In an example context, the search results display may include one or more web pages, such as one or more search results pages. In some examples, the web page may be provided based on a web document that may be written in any suitable machine-readable language. However, it is contemplated that embodiments of the present disclosure may include other suitable display types. For example, the search results may be provided in a display generated by an application executing on the computing device and/or a display generated by an operating system, such as a mobile operating system. In some examples, the search results may be provided based on any suitable form, e.g., javaScript-html, plaintext.
Search results 112 are data generated by search system 120 that identifies resources 105 that are responsive to a particular search query and that contains links to resources 105. Example search results 112 may include a web page title, a segment of text or a portion of an image extracted from the web page, and a URL of the web page. In some examples, the data provided in the search results 112 may be retrieved from a resource data store. For example, search system 120 may provide search results display 111 that displays search results 112. In some examples, the search results display 111 may be populated with information provided from a resource data store, such as a web page title, a segment of text extracted from a web page, or a portion of an image.
According to embodiments of the present disclosure, the example environment 100 also includes a short answer system 130 communicatively coupled to the search system 120, for example, directly coupled or coupled to the search system 120 through a network such as the network 102. In some examples, and in the case of multiple computer-implemented services, the short reply system 130 is communicatively coupled to a respective system that provides the functionality of the respective computer-implemented service. In some examples, a system, such as search system 120, may interact with short answer system 130 to provide accurate short answers 113 at prominent locations in a browser window running search system 120, sometimes shown in a legend, as discussed in further detail herein.
Fig. 1B is a diagram illustrating a user interface 150 in which an example short answer 190 appears. In the example of fig. 1B, the short answer 190 contains the extracted answer 170. The extracted answer 170 is extracted from short answer 190. The short answers 190 are displayed in a browser window on the display generated by the search query 160. In this case, the abbreviated answer 190 is based on the passage from the top-ranked search result 180. It should be noted that the short answer 190 (and more specifically, the extracted answer 170) correctly answers the question. In some embodiments, a brief answer 190 may be displayed without the extracted answer 170.
Conventional search engines display a short answer 190 based on the search results 180; typically, this may result in inaccurate short answers because the paragraphs that are short answers are extracted from the top-ranked search results and are not checked for accuracy. In this case, the technical solution described above will involve generating an accuracy score based not only on this paragraph but also on other paragraphs obtained from other search results. Thus, if the paragraph to be the short answer does not sufficiently coincide with the information in the other paragraphs, the short answer 190 is not displayed.
Fig. 2 is a diagram illustrating an example electronic environment 200 in which the above-described technical solutions may be implemented. The computer 220 is configured to generate short answers using an accuracy score prediction engine and train the accuracy score prediction engine using a training data corpus.
Computer 220 includes a network interface 222, one or more processing units 224, a memory 226, and a display interface 228. The network interface 222 comprises, for example, an ethernet adapter, a token ring adapter, or the like, for converting electronic and/or optical signals received from the network into electronic form for use by the computer 220. The collection of processing units 224 includes one or more processing chips and/or assemblies. Memory 226 includes volatile memory (e.g., RAM) and nonvolatile memory such as one or more ROMs, magnetic disk drives, solid state drives, and the like. Together, the collection of processing units 224 and the memory 226 form a control circuit configured and arranged to perform the various methods and functions described herein. The display interface 228 is configured to provide data to a display device for presentation and display to a user.
In some embodiments, one or more components of computer 220 may be or may include a processor (e.g., processing unit 224) configured to process instructions stored in memory 226. Examples of such instructions depicted in fig. 2 include a query manager 230, a search engine manager 232, an accuracy score manager 240, and a prediction engine manager 250. Further, as shown in fig. 2, the memory 226 is configured to store various data, described with respect to the respective manager using such data.
The query manager 230 is configured to receive query data 231. In some embodiments, query manager 230 receives query data 231 through network interface 222, i.e., through a network. In some embodiments, query manager 230 receives query data 231 directly as user input.
Query data 231 represents a query entered into a search engine (e.g., search system 120 in FIG. 1A). In some embodiments, the query data 231 is in the form of a string of characters. In some implementations, the query data 231 takes alternative forms, such as graphics, images, audio clips, video, and so forth.
The search engine manager 232 is configured to process the query data 231 for input to a search engine (e.g., the search system 120 of fig. 1A) to generate search engine data 233. The search engine data 233 contains a collection of search engine results 234 (1), …, 234 (N). Each of the search engine results 234 (1), …, 234 (N) contains links to websites containing respective paragraphs 235 (1), …, 235 (N) and respective ranks 236 (1), …, 236 (N).
Each paragraph, such as paragraph 235 (1), is at least a portion of the content on the website to which search result 234 (1) is linked. In the examples described herein, each of paragraphs 235 (1), …, 235 (N) contains text. In some embodiments, the text forms a paragraph. In some embodiments, there is a specified amount of text, e.g., a specified number of words, sentences, or other measures of information amount, in a paragraph, e.g., paragraph 235 (1). However, in some implementations, at least one of paragraphs 235 (1), …, 235 (N), e.g., paragraph 235 (1), contains graphics, such as emoticons, a portion of an image, an audio clip, a video clip, and the like.
The respective ranks 236 (1), …, 236 (N) of search results 234 (1), …, 234 (N) represent an arrangement of search results displayed in a browser window displayed on a display, for example, via display interface 228. In some embodiments, the respective ranks 236 (1), …, 236 (N) take the form of numbers of the sequence. In this way, the top ranked search result will be 234 (1) and the top ranked search result will be 234 (N).
The accuracy score manager 240 is configured to receive accuracy score data 241 from the human raters as training data for a prediction engine configured to predict accuracy scores for paragraphs of the top rated search results 234 (1). As shown in FIG. 2, accuracy score data 241 received from a human rater includes a respective accuracy score 242 (1), …, 242 (N) for each paragraph 235 (1), …, 235 (N). In some implementations, the human rater provides accuracy scores for only the M top-ranked paragraphs 235 (1), …, 235 (M), M < N. In some implementations, only the top-ranked paragraph 235 (1) is provided with an accuracy score.
In some implementations, the accuracy score of the top-ranked paragraph 235 (1) is based on the accuracy of the paragraph 235 (1) that the human rater understands in the context of the collection of other paragraphs, e.g., 235 (2), …, 235 (K). In some embodiments, k=1 or 2. In some embodiments, there are a plurality of top-ranked paragraphs, each with an accuracy score.
For example, in response to query data 231"how long can fish last in the freezer (how long fish can be stored in the ice bin)", the search engine returns paragraph 235 (1) with the foremost rating, "white vacuum-sealed and properly stored in the freezer, fish can last for as long as two yes. If frozen fish is properly thawed, there should be little to no difference in texture when compared to fresh fish" (when vacuum sealed and properly stored in the ice bin, fish can be stored for up to two years.) if frozen fish is properly thawed, its texture should have little difference compared to fresh fish) "in some embodiments, then, based on the brief answer of paragraph 235 (1), can contain" two years "displayed in the prominent position. In some embodiments, the short answer may be paragraph 235 (1). Without further context, the accuracy score 242 (1) provided by a human rater depends only on the paragraph 235 (1) and the rater's personal knowledge of the topic, which may be lacking.
However, in the improved search engine, the accuracy score manager 240 provides the rater with an opportunity to check the context of other paragraphs in order to provide a more correct accuracy score 242 (1) for the paragraph 235 (1) that is less dependent on the personal knowledge of the rater. For example, paragraph 235 (2) may indicate "Any frozen fish or shellfish will be safe indefinitely; however, the flavor and texture will lessen after lengthy storage.for best quality, freeze (0F/-17.8C or less) cooked fish for up to 3months.Frozen raw fish is best used within 3to 8months; shellfish,3to 12 montants any frozen fish or shellfish will be safe indefinitely; however, after long storage, its flavor and texture will decrease. For best quality, cooked fish are frozen (0F/-17.8C or less) for up to 3months. Frozen raw fish is preferably used for 3to 8months; shellfish is used for 3to 12months. "if paragraph 235 (2) is used for context, the rater may provide a low accuracy score 242 (1) for the short answer" two years "because paragraph 235 (2) is significantly different from paragraph 235 (1). If a brief answer is derived from paragraph 235 (2), the rater may provide "3to 8 montants" instead of "two years". In this case, the prediction engine manager trained using accuracy scores may result in no brief answers being displayed.
In some implementations, the accuracy score manager 240 provides the rater with more than one paragraph for the context. For example, in addition to paragraphs 235 (1) and 235 (2), paragraph 235 (3) may indicate "Fatty fish like salmon can be frozen for two to three months, while lean fish like cod or flounder will last up to six.coded leftovers: wire months.group means (coef, lamb, park) keeps for two to three months; the steps, steaks, and chops can be kept in the freezer for at least half a year (a fatty fish such as salmon may be frozen for two to three months, and a fatty fish such as cod or flatfish may be frozen for six months, cooked leftovers: three months, minced meat (beef, mutton, pork) may be kept for two to three months, roast meat, steaks, and spareribs may be kept in a freezer for at least half a year) the rater may provide an even lower accuracy score 242 (1) for a short answer "two years" if paragraph 235 (3) is provided for context in addition to paragraph 235 (2), because paragraph 235 (3) is also significantly different from paragraph 235 (1). In this case, however, if either paragraph 235 (2) or 235 (3) is selected as the top-rated paragraph for which a brief answer is obtained, then the accuracy score 242 (1) of that paragraph may be higher than the accuracy score of paragraph 235 (1) because there is some degree of consistency between paragraphs 235 (2) and 235 (3).
In some embodiments, when there is more than one top-ranked paragraph, the accuracy score manager 240 selects the top-ranked paragraph with the highest accuracy score.
In some implementations, the decision as to whether to display a brief answer is based on whether accuracy score 242 (1) is greater than or less than a specified accuracy score threshold 244. In some implementations, the rater provides an accuracy score between-1.0 and 3.0, with a step size of 0.5, where-1.0 represents a brief answer that is obviously wrong in the context of the other paragraph (or in the personal knowledge of the rater), and 3.0 represents a brief answer that is entirely consistent in context with the other paragraph. In this case, the prediction engine manager 250 may be trained to output a score between-1.0 and 3.0, and the search system may use an accuracy score threshold 244 of 0.5; that is, short answers rated-1.0, -0.5, and 0.0 may not be displayed, but short answers with accuracy scores of 0.5, 1.0, 1.5, 2.0, 2.5, or 2.0 may be displayed.
In some implementations, there are multiple accuracy score thresholds corresponding to different levels of short answer accuracy. For example, an accuracy score threshold 244 of 0.5 as described above may be considered a low threshold ("good answer accuracy (GAP)"). Other thresholds may be defined as, for example, 1.5 ("very good answer accuracy (VGAP)") or 2.0 ("very good answer accuracy (XGAP)").
In some implementations, to generate training data for an accuracy score prediction engine, a data set of examples (e.g., main paragraphs) is provided to a human rater to score based on accuracy levels derived from the rater's knowledge and additional context paragraphs. The main paragraph is selected as a response to the query and contains a short answer, which the rater is asked to rate as a bad answer, a good answer, a very good answer, etc. In some embodiments, examples are selected based on specified criteria such as "hard to rate without additional study", "random traffic examples", and the like. In some embodiments, such as "1+1is equal to what number? (1+1 is equal to how much. In some embodiments, of these examples, a large percentage of the examples, e.g., 95%, may meet the GAP threshold, while a smaller percentage, e.g., 85%, may meet the VGAP threshold.
To provide these examples and scoring results to the accuracy score prediction engine, in some embodiments, the template itself from which the raters provide accuracy scores may be evaluated. In some embodiments, the assessment takes the form of VGAP accuracy and VGAP recall. (accuracy is the ratio of the number of true positives to the total number of true positives and false positives; recall is the ratio of the number of true positives to the total number of false positives and false negatives.) for example, VGAP accuracy of about 50% for some data sets means a large number of false positives, while in such examples, VGAP accuracy of about 95% means a smaller number of false negatives.
In some implementations, templates for which raters provide accuracy scores may be adjusted to increase VGAP accuracy. For example, the baseline template may not use the title or URL of the search results 234 (1), …, 234 (N). In some embodiments, the following partial or total modifications may be made to the template to increase VGAP accuracy:
add two additional paragraphs, which are the foremost paragraphs from different search results. The other paragraphs themselves provide answers at least at the GAP threshold.
The rater has more time to provide an accuracy score.
Request/ask the rater to provide comments and display the result title.
Randomizing paragraph order (e.g., not necessarily listing the main paragraphs first).
Add a bias term (e.g., -0.5) to the accuracy score.
In some embodiments, VGAP recall is reduced as the above actions are taken to increase VGAP accuracy. Empirically, adding bias terms has the greatest negative impact on recall and the greatest positive impact on accuracy.
The prediction engine manager 250 is configured to generate accuracy score predictions based on the prediction engine data 253 provided by the raters to generate predicted accuracy score data 265 and, in some embodiments, short answer data 270. As shown in fig. 2, the prediction engine manager 250 includes an encoder 251 and a decoder 252.
The encoder 251 is configured to encode the input to the prediction engine into a form suitable for input into a machine learning engine such as a neural network. For example, in some implementations, the input to the accuracy score prediction engine includes a query (e.g., query data 231), a top-rated paragraph (e.g., paragraph 235 (1)), a title of the top-rated paragraph, and additional paragraphs. In some implementations, the input can include an additional title (e.g., corresponding to an additional paragraph). The extra paragraph is called a context paragraph. The encoder 251 is configured to convert these inputs into an input token embedded vector. The decoder 252 is configured to decode the output layer of the accuracy score prediction engine to produce a predicted accuracy score. Fig. 4 shows the actions of the encoder 251 and the decoder 252.
FIG. 4 is a diagram illustrating example inputs 405 and outputs 422 from the accuracy score prediction engine. As shown in FIG. 4, the input takes the form of a query 410, top-ranked paragraph 420, corresponding title 422, additional paragraphs 430 and 434, and their respective titles 432 and 436. Encoder 251 (fig. 2) encodes the input to produce an input token embedding 408; these token embeddings 408 are input to the input layer of the neural network from which the accuracy score prediction engine 438 is generated. Once the training period is complete, the accuracy score prediction engine 438 decodes the encoded output 442 to produce a prediction accuracy score 444. However, during training, the neural network produces an output 440 based only on the loss function of the top-ranked paragraph 420.
Returning to fig. 2, prediction engine data 253 represents data used to train an accuracy score prediction engine. As shown in fig. 2, the prediction engine data 253 includes input embedded data 254 and intermediate data 255. In some embodiments, the accuracy score prediction engine as shown in fig. 2 employs a teacher-student model from knowledge refinement (KD). The main idea of KD is to include two network structures, named teacher and student. The teacher is a very powerful model, while the students can be simple models. The teacher model is used to teach the student model by teaching important knowledge to the student.
Intermediate data 255 represents the data used by the accuracy score prediction engine during its training. As shown in fig. 2, the intermediate data 255 includes any one of a loss function output, a hidden layer value, and an intermediate score prediction fed between the teacher model and the student model. In some embodiments, the teacher model and the student model each have multiple phases such that the output of one phase is input to the next phase. In some embodiments, the teacher model has four phases and the student model has two phases.
The predicted accuracy score data 265 represents the output of the accuracy score prediction engine. In some embodiments, the predicted accuracy score data 265 is used to determine whether a brief answer is displayed.
The short answer data 270 represents short answers that may or may not be displayed.
The components (e.g., modules, processing units 224) of the user device 106 may be configured to operate based on one or more platforms (e.g., one or more similar or different platforms), which may include one or more types of hardware, software, firmware, operating systems, runtime libraries, etc. In some embodiments, components of computer 220 may be configured to operate within a cluster of devices (e.g., a server farm). In such embodiments, the functions and processing of the components of computer 220 may be distributed to several devices of a device cluster.
The components of computer 220 may be or may include any type of hardware and/or software configured to process attributes. In some embodiments, one or more portions of the components shown in the components of computer 220 in fig. 2 may be or may contain hardware-based modules (e.g., digital Signal Processors (DSPs), field Programmable Gate Arrays (FPGAs), memory), firmware modules and/or software-based modules (e.g., computer code modules, sets of computer-readable instructions executable at a computer). For example, in some embodiments, one or more portions of the components of computer 220 may be or may contain software modules configured to be executed by at least one processor (not shown). In some embodiments, the functionality of the components may be included in different modules and/or different components than illustrated in fig. 2, including combining the functionality illustrated as two components into a single component.
Although not shown, in some embodiments, components of computer 220 (or portions thereof) may be configured to operate within, for example, a data center (e.g., a cloud computing environment), a computer system, one or more server/host devices, and the like. In some embodiments, components of computer 220 (or portions thereof) may be configured to operate within a network. Accordingly, components of computer 220 (or portions thereof) may be configured to operate in various types of network environments that may include one or more devices and/or one or more server devices. For example, the network may be or may include a Local Area Network (LAN), a Wide Area Network (WAN), or the like. The network may be or may include a wireless network and/or a wireless network implemented using, for example, gateway devices, bridges, switches, etc. The network may contain one or more segments and/or may have portions based on various protocols, such as Internet Protocol (IP) and/or proprietary protocols. The network may comprise at least a portion of the internet.
In some embodiments, one or more components of the search system 120 may be or may include a processor configured to process instructions stored in memory. For example, query manager 230 (and/or portions thereof), search engine manager 232 (and/or portions thereof), accuracy score manager 240 (and/or portions thereof), and prediction engine manager 250 (and/or portions thereof).
In some embodiments, memory 226 may be any type of memory, such as random access memory, disk drive memory, flash memory, and the like. In some embodiments, memory 226 may be implemented as more than one memory component associated with a component of computer 220 (e.g., one RAM component or disk drive memory is arranged). In some embodiments, the memory 226 may be a database memory. In some embodiments, memory 226 may be or may include non-local memory. For example, the memory 226 may be or may contain memory shared by multiple devices (not shown). In some embodiments, memory 226 may be associated with a server device (not shown) within the network and configured to serve components of computer 220. As shown in fig. 2, memory 226 is configured to store various data including query data 231, search engine data 233, accuracy score data 241, prediction engine data 253, prediction accuracy score data 265, and short answer data 270.
FIG. 3 is a diagram illustrating an example data flow 300 from a plurality of top-scoring paragraphs from search results into a legend. As shown in FIG. 3, a query 310 input to a search engine produces search results in the form of documents 320 (1-4). As shown in FIG. 3, each of documents 320 (1-4) has M paragraphs (although some may have fewer paragraphs) 330 (1-4) (1-M). Paragraphs 330 (1) (1), 330 (1) (2) and 330 (1, 3) are input to the accuracy score prediction engine to generate a legend 340.
FIG. 5 is a flow chart describing an example method 500 of generating a short answer for display based on a plurality of paragraphs derived from a query provided to a search engine in accordance with the improved techniques described above. The method 500 may be performed by a software construct described in connection with fig. 2, residing in memory 226 of computer 220 and being executed by the set of processing units 224.
At 502, query manager 230 receives query data (e.g., query data 231) representing a search query entered into a search engine by a user.
At 504, the search engine manager 232 generates a plurality of search results (e.g., search results 234 (1-N)) based on the search query, each of the plurality of search results having a respective paragraph (e.g., paragraph 235 (1-N)) related to the search query.
At 506, the prediction engine manager 250 selects a set of respective paragraphs for short answer scoring, one of the respective paragraphs in the set being a candidate paragraph belonging to a top-ranked search result of the plurality of search results, and the remaining respective paragraphs in the set being contextual paragraphs. In some implementations, the collection contains a predetermined number of paragraphs, for example, from a predetermined number of top ranked search results. In some embodiments, the collection contains three paragraphs, including the paragraph from the top ranked search results.
At 508, the prediction engine manager 250 scores the candidate paragraphs using the contextual paragraphs to produce an accuracy score for the candidate paragraphs. In addition to the context paragraphs, the prediction engine manager 250 may also contain as input a search query (or a portion thereof) and a title corresponding to the candidate paragraph. In some embodiments, prediction engine manager 250 may also include as input a title corresponding to the context paragraph.
At 510, the prediction engine manager 250 provides candidate paragraphs for display in a search results page presented by a browser window on the display as a brief answer based on the accuracy score meeting a threshold.
Fig. 6 illustrates an example of a general purpose computer device 600 and a general purpose mobile computer device 650 that may be used with the techniques described here. Computer device 600 is one example configuration of search system 120 and/or short answer system 130 of fig. 1A and computer 220 of fig. 2.
As shown in FIG. 6, computing device 600 is intended to represent various forms of digital computers, such as laptops, desktops, workstations, personal digital assistants, servers, blade servers, mainframes, and other appropriate computers. Computing device 650 is intended to represent various forms of mobile devices, such as personal digital assistants, cellular telephones, smartphones, and other similar computing devices. The components shown herein, their connections and relationships, and their functions, are meant to be exemplary only, and are not limiting, and are not meant to limit implementations of the invention described and/or claimed in this document.
Computing device 600 includes a processor 602, memory 604, storage 606, a high-speed interface 608 connected to memory 604 and high-speed expansion ports 610, and a low-speed interface 612 connected to low-speed bus 614 and storage 606. Each of the components 602, 604, 606, 608, 610, and 612 are interconnected using various buses, and may be mounted on a common motherboard or in other manners as appropriate. The processor 602 may process instructions for execution within the computing device 600, including instructions stored in the memory 604 or on the storage device 606, to display graphical information for a GUI on an external input/output device, such as a display 616 coupled to the high-speed interface 608. In other embodiments, multiple processors and/or multiple buses may be used, as appropriate, along with multiple memories and types of memory. In addition, multiple computing devices 600 may be connected, with each device providing portions of the necessary operations (e.g., as a server bank, a group of blade servers, or a multiprocessor system).
Memory 604 stores information within computing device 600. In some implementations, the memory 604 is one or more volatile memory units. In another implementation, the memory 604 is one or more non-volatile memory units. Memory 604 may also be another form of computer-readable medium, such as a magnetic or optical disk.
The storage 606 is capable of providing mass storage for the computing device 600. In one embodiment, the storage device 606 may be or contain a computer-readable medium, such as a floppy disk device, a hard disk device, an optical disk device, or a tape device, a flash memory or other similar solid state memory device, or an array of devices, including devices in a storage area network or other configurations. The computer program product may be tangibly embodied in an information carrier. The computer program product may also contain instructions that, when executed, perform one or more methods, such as the methods described above. The information carrier is a computer-or machine-readable medium, such as the memory 604, the storage device 606, or memory on processor 602.
The high speed controller 608 manages bandwidth-intensive operations of the computing device 600, while the low speed controller 612 manages lower bandwidth-intensive operations. Such allocation of functions is merely an example. In some embodiments, the high-speed controller 608 is coupled to the memory 604, the display 616 (e.g., via a graphics processor or accelerator), and to the high-speed expansion port 610, which high-speed expansion port 610 may accept various expansion cards (not shown). In an embodiment, a low speed controller 612 is coupled to the storage 506 and to a low speed expansion port 614. The low-speed expansion port, which may contain various communication ports (e.g., USB, bluetooth, ethernet, wireless ethernet), may be coupled to one or more input/output devices, such as a keyboard, a pointing device, a scanner, or a network device such as a switch or router, for example, through a network adapter.
As shown, computing device 600 may be implemented in a number of different forms. For example, it may be implemented as a standard server 620, or multiple times in a group of such servers. It may also be implemented as part of a rack server system 624. Furthermore, it may be implemented in a personal computer such as a laptop computer 622. Alternatively, components from computing device 600 may be combined with other components in a mobile device (not shown), such as device 650. Each of such devices may contain one or more of the computing devices 600, 605, and the entire system may be made up of multiple computing devices 600, 605 communicating with each other.
The computing device 650 includes a processor 652, a memory 664, an input/output device such as a display 654, a communication interface 666, and a transceiver 668, among other components. The device 650 may also be provided with a storage device, such as a microdrive or other device, to provide additional storage. Each of the components 650, 652, 664, 654, 666, and 668, are interconnected using various buses, and several of the components may be mounted on a common motherboard or in other manners as appropriate.
Processor 652 can execute instructions within computing device 650, including instructions stored in memory 664. The processor may be implemented as a chipset comprising separate multiple analog and digital processors. For example, the processor may provide for coordination of the other components of the device 650, such as control of user interfaces, applications run by device 650, and wireless communication by device 650.
The processor 652 may communicate with a user through a control interface 658 and a display interface 656 coupled to a display 654. The display 654 may be, for example, a TFT LCD (thin film transistor liquid crystal display) or OLED (organic light emitting diode) display or other suitable display technology. The display interface 656 may comprise suitable circuitry for driving the display 654 to present graphical and other information to a user. The control interface 658 may receive commands from a user and translate the commands for submission to the processor 652. In addition, an external interface 660 may be provided in communication with the processor 652 to enable near area communication of the device 650 with other devices. External interface 660 may provide, for example, for wired communication in some embodiments, or for wireless communication in other embodiments, and multiple interfaces may also be used.
The memory 664 stores information within the computing device 650. The memory 664 may be implemented as one or more computer-readable media, volatile memory units, or non-volatile memory units. Expansion memory 674 may also be provided and connected to device 650 via expansion interface 672, which expansion interface 672 may include, for example, a SIMM (Single wire memory Module) card interface. Such expansion memory 674 may provide additional storage space for device 650, or may also store applications or other information for device 650. In particular, expansion memory 674 may contain instructions for performing or supplementing the processes described above, and may also contain secure information. Thus, for example, expansion memory 674 may be provided as a security module for device 650, and may be programmed with instructions that allow for secure use of device 650. Further, secure applications may be provided via the SIMM card, as well as additional information, such as placing identifying information on the SIMM card in an indestructible manner.
The memory may include, for example, flash memory and/or NVRAM memory, as described below. In one embodiment, the computer program product is tangibly embodied in an information carrier. The computer program product contains instructions that when executed perform one or more methods, such as the methods described above. The information carrier is a computer-or machine-readable medium, such as the memory, expansion memory 674, or memory on processor 652 that may be received, for example, over transceiver 668 or external interface 660.
The device 650 may communicate wirelessly through a communication interface 666, which communication interface 666 may include digital signal processing circuitry as necessary. Communication interface 666 may provide for communication under various modes or protocols, such as GSM voice calls, SMS, EMS, or MMS messaging, CDMA, TDMA, PDC, WCDMA, CDMA2000, or GPRS, among others. Such communication may occur, for example, through radio frequency transceiver 668. In addition, short-range communications may occur, such as using bluetooth, wiFi, or other such transceivers (not shown). In addition, a GPS (global positioning system) receiver module 670 may provide additional navigation-and location-related wireless data to the device 650, which may be used as appropriate by applications running on the device 650.
The device 650 may also communicate audibly using an audio codec 660, the audio codec 660 may receive voice information from a user and convert it to usable digital information. Audio codec 660 may likewise generate audible sound for a user, such as through a speaker in a handset of device 650, for example. Such sound may include sound from voice telephone calls, may include recorded sound (e.g., voice messages, music files, etc.), and may also include sound generated by applications operating on device 650.
As shown, the computing device 650 may be implemented in a number of different forms. For example, it may be implemented as a cellular telephone 680. It may also be implemented as part of a smart phone 682, personal digital assistant, or other similar mobile device.
Fig. 7 illustrates an example of a general purpose computer device 700, which may be the search system 120 of fig. 2, that may be used with the techniques described herein. Computing device 700 is intended to represent various example forms of large data processing devices, such as servers, blade servers, data centers, mainframes, and other large computing devices. Computing device 700 may be a distributed system having multiple processors, possibly including network-attached storage nodes interconnected by one or more communication networks. The components shown herein, their connections and relationships, and their functions, are meant to be exemplary only, and are not limiting, and are not meant to limit implementations of the invention described and/or claimed in this document.
The distributed computing system 70 may include any number of computing devices 780. Computing device 780 may include a server or rack-mounted server, mainframe, etc. that communicates over a local or wide area network, a dedicated optical link, modem, bridge, router, switch, wired or wireless network, etc.
In some embodiments, each computing device may contain multiple racks. For example, computing device 780a includes a plurality of racks 758a-758n. Each rack may contain one or more processors, such as processors 752a-752n and 762a-762n. The processor may include a data processor, network attached storage, and other computer control devices. In some embodiments, one processor may operate as a master processor and control scheduling and data distribution tasks. The processors may be interconnected by one or more rack-mounted switches 762a-762n, and one or more racks may be connected by a switch 778. Switch 778 may handle communications between multiple connected computing devices 700.
Each rack may contain memory such as memory 754 and memory 764, as well as storage devices such as 756 and 766. The memories 756 and 766 may provide mass storage devices and may comprise volatile or non-volatile storage devices, such as network attached magnetic disks, floppy disks, hard disks, optical disks, magnetic tape, flash memory, or other similar solid state memory devices, or comprise an array of devices in a storage area network or other configuration. Memory 756 or 766 may be shared among multiple processors, multiple racks, or multiple computing devices, and may include a computer-readable medium storing instructions executable by one or more processors. The memories 754 and 764 may comprise, for example, one or more volatile memory units, one or more non-volatile memory units, and/or other forms of computer-readable media, such as magnetic or optical disks, flash memory, cache memory, random Access Memory (RAM), read Only Memory (ROM), and combinations thereof. Memory, such as memory 754, may also be shared among the processors 752a-752 n. For example, data structures such as indexes may be stored across storage 756 and memory 754. Computing device 700 may contain other components not shown, such as controllers, buses, input/output devices, communication modules, and the like.
An overall system, such as environment 100 of fig. 1, may be comprised of a plurality of computing devices 700 in communication with each other. For example, device 780a may communicate with devices 780b, 780c, and 780d, and these devices may be collectively referred to as environment 100. As another example, computer 220 of fig. 2 may contain one or more computing devices 700. Some computing devices may be geographically close to each other while other computing devices may be geographically distant. The layout of system 700 is merely an example, and the system may employ other layouts or configurations.
In some implementations, providing the candidate paragraphs for display based on the accuracy score includes: comparing the accuracy score to an accuracy score threshold; in response to the accuracy score being greater than the accuracy score threshold, displaying the candidate passage on the display; and in response to the accuracy score being less than the accuracy score threshold, not displaying the candidate passage on the display.
In some implementations, scoring the candidate paragraphs using the context paragraphs includes determining a level of consistency between the candidate paragraphs and the set of context paragraphs, the accuracy score being based on the level of consistency.
In some implementations, scoring the candidate paragraphs using the context paragraphs includes inputting the candidate paragraphs and the remaining corresponding paragraphs into a score prediction engine configured to predict scores based on the candidate paragraphs and the remaining corresponding paragraphs.
In some implementations, scoring the candidate paragraphs using the contextual paragraphs further includes inputting respective titles of the candidate paragraphs and the remaining respective paragraphs into the score prediction engine in addition to inputting the candidate paragraphs and the remaining respective paragraphs into the score prediction engine.
In some embodiments, the method further comprises performing a training operation on a training data corpus to train the score prediction engine, the training data corpus containing candidate paragraphs that provide the short answers for display in the legend and remaining corresponding paragraphs from which the top scoring short answers are generated. In such embodiments, the training data corpus also includes the remaining respective paragraphs and the respective headings of the candidate paragraphs and the remaining respective paragraphs. In such implementations, performing the training operation includes applying a loss function based on a set of accuracy score thresholds applied to the candidate paragraphs, the loss function including a threshold score of sigmoid cross entropy loss for each accuracy score threshold in the set of accuracy score thresholds of the main paragraph. In such implementations, the loss function produces as output an average of the sigmoid cross entropy losses over a set of accuracy score thresholds. In such embodiments, the training operation includes a plurality of training phases, and the set of accuracy score thresholds varies between the plurality of training phases of the training operation. In such embodiments, the training operations include a teacher training operation that generates a teacher model and a student training operation that generates a student model, wherein the student training takes as input a teacher accuracy score generated by the teacher model. In such embodiments, the teacher training operation is based on a loss function that includes the mean square error across the teacher and student models.
In some embodiments, the training data corpus further includes a third set of previously scored paragraphs, the respective accuracy scores of the previously scored paragraphs not being based on consistency with the candidate paragraphs and the remaining respective paragraphs.
In some embodiments, providing the candidate paragraphs for display as a brief answer includes selecting a top-ranked paragraph of the predetermined number of top-ranked paragraphs having a highest accuracy score.
Various implementations of the systems and techniques described here can be implemented in digital electronic circuitry, integrated circuitry, specially designed ASICs (application specific integrated circuits), computer hardware, firmware, software, and/or combinations thereof. These various embodiments may comprise embodiments in one or more computer programs executable and/or interpretable on a programmable system including at least one programmable processor, which may be special or general purpose, coupled to receive data and instructions from, and to transmit data and instructions to, a storage system, at least one input device, and at least one output device.
These computer programs (also known as programs, software applications or code) contain machine instructions for a programmable processor, and may be implemented in a high-level procedural and/or object-oriented programming language, and/or in assembly/machine language. As used herein, the terms "machine-readable medium" and "computer-readable medium" refer to any computer program product, apparatus and/or device (e.g., magnetic discs, optical disks, memory, programmable Logic Devices (PLDs)) used to provide machine instructions and/or data to a programmable processor, including a machine-readable medium that receives machine instructions as a machine-readable signal. The term "machine-readable signal" refers to any signal used to provide machine instructions and/or data to a programmable processor.
To provide for interaction with a user, the systems and techniques described here can be implemented on a computer having a display device such as a CRT (cathode ray tube) or LCD (liquid crystal display) monitor for displaying information to the user and a keyboard and a pointing device such as a mouse or a trackball by which the user can provide input to the computer. Other types of devices may also be used to provide for interaction with a user; for example, feedback provided to the user may be any form of sensory feedback (e.g., visual feedback, auditory feedback, or tactile feedback); and input from the user may be received in any form, including acoustic, speech, or tactile input.
The systems and techniques described here can be implemented in a computing system that includes a back-end component (e.g., as a data server), or that includes a middleware component (e.g., an application server), or that includes a front-end component (e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the systems and techniques described here), or any combination of one or more such back-end, middleware, or front-end components. The components of the system can be interconnected by any form or medium of digital data communication (e.g., a communication network). Examples of communication networks include a local area network ("LAN"), a wide area network ("WAN"), and the Internet.
The computing system may include clients and servers. The client and server are typically remote from each other and typically interact through a communication network. The relationship between client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other.
Many embodiments have been described. Nevertheless, it will be understood that various modifications may be made without departing from the spirit and scope of the disclosure.
It will also be understood that when an element is referred to as being "on", "connected" to, electrically connected "to, coupled" to, or electrically coupled "to another element, it can be directly on, connected" to, or coupled "to the other element or intervening elements may be present. In contrast, when an element is referred to as being directly on, directly connected to, or directly coupled to another element, there are no intervening elements present. Although terms directly on …, directly connected to, or directly coupled to may not be used throughout the detailed description, elements shown directly on …, directly connected to, or directly coupled to may be referred to as such elements. The claims of the present application may be modified to detail the example relationships described in the specification or shown in the drawings.
While certain features of the described embodiments have been illustrated as described herein, many modifications, substitutions, changes, and equivalents will now occur to those skilled in the art. It is, therefore, to be understood that the appended claims are intended to cover all such modifications and changes as fall within the scope of the embodiments. It is to be understood that they have been presented by way of example only, and not limitation, and various changes in form and details may be made. Any portion of the apparatus and/or methods described herein may be combined in any combination, except mutually exclusive combinations. The embodiments described herein may include various combinations and/or sub-combinations of the functions, components, and/or features of the different embodiments described.
Moreover, the logic flows depicted in the figures do not require the particular order shown, or sequential order, to achieve desirable results. Further, other steps may be provided from the described flows, or steps may be eliminated, and other components may be added to, or removed from, the described systems. Accordingly, other embodiments are within the scope of the following claims.
Claims (20)
1. A computer-implemented method, comprising:
Receiving a search query;
generating a plurality of search results based on the search query, each of the plurality of search results having a respective paragraph related to the search query;
selecting a set of the respective paragraphs, one of the respective paragraphs in the set being a candidate paragraph belonging to a top-ranked search result of the plurality of search results, and the remaining respective paragraphs in the set being contextual paragraphs;
scoring the candidate paragraphs using the contextual paragraphs to produce an accuracy score for the candidate paragraphs; and
based on the accuracy score, the candidate paragraphs are provided for display as a short answer in a search results page presented by a browser window on a display.
2. The computer-implemented method of claim 1, wherein providing the candidate passage for display based on the accuracy score comprises:
comparing the accuracy score to an accuracy score threshold;
in response to the accuracy score being greater than the accuracy score threshold, displaying the candidate passage on the display; and
in response to the accuracy score being less than the accuracy score threshold, the candidate passage is not displayed on the display.
3. The computer-implemented method of claim 1, wherein scoring the candidate paragraphs using the contextual paragraphs comprises:
a level of consistency between the candidate paragraph and the context paragraph is determined, the accuracy score being based on the level of consistency.
4. The computer-implemented method of claim 1, wherein scoring the candidate paragraphs using the contextual paragraphs comprises:
the candidate passage, the search query, and the context passage are input into a score prediction engine configured to predict the accuracy score based on the candidate passage, the search query, and the context passage.
5. The computer-implemented method of claim 4, wherein scoring the candidate paragraphs using the contextual paragraphs further comprises:
in addition to inputting the candidate passage, the search query, and the context passage into the score prediction engine, respective titles of the candidate passage and the context passage are also input into the score prediction engine.
6. The computer-implemented method of claim 4, wherein the score prediction engine is trained on a training record corpus comprising training queries, a main paragraph selected for the training queries, at least one contextual paragraph, and respective accuracy scores of the main paragraph.
7. The computer-implemented method of claim 6, wherein the corpus of training records further comprises respective headings for the main paragraph of the at least one context paragraph.
8. The computer-implemented method of claim 6, wherein the score prediction engine is further trained by applying a loss function based on a set of accuracy score thresholds applied to a main paragraph, the loss function comprising, for each accuracy score threshold in the set of accuracy score thresholds for the main paragraph, an S-shaped cross entropy loss of the threshold score.
9. The computer-implemented method of claim 8, wherein the loss function generates as output an average of the S-shaped cross entropy losses over the set of accuracy score thresholds.
10. The computer-implemented method of claim 8, wherein the score prediction engine is trained using a plurality of training phases, and
wherein the set of accuracy score thresholds varies between the plurality of training phases.
11. The computer-implemented method of claim 6, wherein the corpus of training records further comprises a set of previously scored paragraphs, respective accuracy scores of the previously scored paragraphs not being based on consistency with the main paragraph and at least one contextual paragraph.
12. The computer-implemented method of claim 1, wherein the set of respective paragraphs includes a predetermined number of top-ranked paragraphs.
13. The computer-implemented method of claim 12,
wherein providing the candidate paragraphs for display as the abbreviated answer includes selecting a top-ranked paragraph of the predetermined number of top-ranked paragraphs having a highest accuracy score.
14. A computer program product comprising a non-transitory storage medium, the computer program product comprising code that, when executed by processing circuitry having a search engine configured thereon, causes the processing circuitry to perform a method comprising:
receiving query data representing a search query;
generating a plurality of search results based on the search query, each of the plurality of search results having a respective paragraph related to the search query;
selecting a set of the respective paragraphs, one of the respective paragraphs in the set being a candidate paragraph belonging to a top-ranked search result of the plurality of search results, and the remaining respective paragraphs in the set being contextual paragraphs;
Scoring the candidate paragraphs using the contextual paragraphs to produce an accuracy score for the candidate paragraphs; and
based on the accuracy score, the candidate paragraphs are provided for display as a short answer in a search results page presented by a browser window on a display.
15. The computer program product of claim 14, wherein providing the candidate passage for display based on the accuracy score comprises:
comparing the accuracy score to an accuracy score threshold;
in response to the accuracy score being greater than the accuracy score threshold, displaying the candidate passage on the display; and
in response to the accuracy score being less than the accuracy score threshold, the candidate passage is not displayed on the display.
16. The computer program product of claim 14, wherein scoring the candidate passage using the contextual passage comprises:
the candidate passage and the context passage are input into a score prediction engine configured to predict the accuracy score based on the candidate passage and the context passage.
17. The computer program product of claim 16, wherein scoring the candidate passage using the contextual passage further comprises:
in addition to inputting the candidate passage and the context passage into the score prediction engine, respective titles of the candidate passage and the context passage are also input into the score prediction engine.
18. The computer program product of claim 16, wherein the method further comprises:
a training operation is performed on a training data corpus to train the score prediction engine, the training data corpus including candidate paragraphs that provide short answers for display and remaining corresponding paragraphs from which the top scoring short answers are generated.
19. An apparatus, the apparatus comprising:
a memory; and
a control circuit coupled to the memory, the control circuit configured to:
receiving query data representing a search query;
generating a plurality of search results based on the search query, each of the plurality of search results having a respective paragraph related to the search query;
selecting a set of the respective paragraphs, one of the respective paragraphs in the set being a candidate paragraph belonging to a top-ranked search result of the plurality of search results, and the remaining respective paragraphs in the set being contextual paragraphs;
Scoring the candidate paragraphs using the contextual paragraphs to produce an accuracy score for the candidate paragraphs; and
based on the accuracy score, the candidate paragraphs are provided for display as a short answer in a search results page presented by a browser window on a display.
20. The device of claim 19, wherein the control circuitry configured to provide the candidate passage for display based on the accuracy score is further configured to:
comparing the accuracy score to an accuracy score threshold;
in response to the accuracy score being greater than the accuracy score threshold, displaying the candidate passage on the display; and
in response to the accuracy score being less than the accuracy score threshold, the candidate passage is not displayed on the display.
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
PCT/US2022/071054 WO2023172334A1 (en) | 2022-03-09 | 2022-03-09 | Multi source extraction and scoring of short query answers |
Publications (1)
Publication Number | Publication Date |
---|---|
CN117043767A true CN117043767A (en) | 2023-11-10 |
Family
ID=80952144
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202280005247.5A Pending CN117043767A (en) | 2022-03-09 | 2022-03-09 | Multi-source extraction and scoring of abbreviated query answers |
Country Status (6)
Country | Link |
---|---|
US (1) | US20230342411A1 (en) |
EP (1) | EP4264454A1 (en) |
JP (1) | JP2024514724A (en) |
KR (1) | KR20230133265A (en) |
CN (1) | CN117043767A (en) |
WO (1) | WO2023172334A1 (en) |
Family Cites Families (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10936969B2 (en) * | 2016-09-26 | 2021-03-02 | Shabaz Basheer Patel | Method and system for an end-to-end artificial intelligence workflow |
US20210406294A1 (en) * | 2020-06-24 | 2021-12-30 | International Business Machines Corporation | Relevance approximation of passage evidence |
US20220171873A1 (en) * | 2020-11-30 | 2022-06-02 | Xayn Ag | Apparatuses, methods, and computer program products for privacy-preserving personalized data searching and privacy-preserving personalized data search training |
US11803558B2 (en) * | 2021-12-15 | 2023-10-31 | Microsoft Technology Licensing, Llc | Relevance-independent position effects estimator for digital item ranking |
-
2022
- 2022-03-09 US US18/000,152 patent/US20230342411A1/en active Pending
- 2022-03-09 KR KR1020237001630A patent/KR20230133265A/en unknown
- 2022-03-09 EP EP22713246.1A patent/EP4264454A1/en active Pending
- 2022-03-09 CN CN202280005247.5A patent/CN117043767A/en active Pending
- 2022-03-09 JP JP2023502802A patent/JP2024514724A/en active Pending
- 2022-03-09 WO PCT/US2022/071054 patent/WO2023172334A1/en active Application Filing
Also Published As
Publication number | Publication date |
---|---|
KR20230133265A (en) | 2023-09-19 |
JP2024514724A (en) | 2024-04-03 |
US20230342411A1 (en) | 2023-10-26 |
EP4264454A1 (en) | 2023-10-25 |
WO2023172334A1 (en) | 2023-09-14 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN109219811B (en) | Related paragraph retrieval system | |
US20190251083A1 (en) | Retrieving context from previous sessions | |
CN105786977B (en) | Mobile search method and device based on artificial intelligence | |
US8990692B2 (en) | Time-marked hyperlinking to video content | |
CN110023928B (en) | Predictive search engine ranking signal values | |
US10698707B2 (en) | Using salience rankings of entities and tasks to aid computer interpretation of natural language input | |
US10755040B2 (en) | Method and system for semantically generating and digitally publishing articles | |
JP2019532422A (en) | Display keyframes for videos on online social networks | |
JP6361351B2 (en) | Method, program and computing system for ranking spoken words | |
AU2016222481B2 (en) | Suggesting tags in status messages based on social context | |
US9934283B2 (en) | Social annotations for enhanced search results | |
CN113079417B (en) | Method, device and equipment for generating bullet screen and storage medium | |
US10909174B1 (en) | State detection of live feed | |
US8799257B1 (en) | Searching based on audio and/or visual features of documents | |
US10061774B2 (en) | Estimating article publication dates and authors based on social media context | |
CN106471497B (en) | Context-using assisted browsing | |
US11790953B2 (en) | Smart summarization, indexing, and post-processing for recorded document presentation | |
US10037321B1 (en) | Calculating a maturity level of a text string | |
US11651039B1 (en) | System, method, and user interface for a search engine based on multi-document summarization | |
US11262978B1 (en) | Voice-adapted reformulation of web-based answers | |
US20230342411A1 (en) | Multi source extraction and scoring of short query answers | |
WO2024019753A1 (en) | Category recommendation with implicit item feedback | |
KR20090005687A (en) | Method, system, server for searching multimedia contents by using trackback structure | |
US20240020538A1 (en) | Systems and methods for real-time search based generative artificial intelligence | |
Erkmen | Data Journalism: A Systematic Literature Review |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination |