US8635172B1 - Dynamic techniques for evaluating quality of clustering or classification system aimed to minimize the number of manual reviews based on Bayesian inference and Markov Chain Monte Carlo (MCMC) techniques - Google Patents
Dynamic techniques for evaluating quality of clustering or classification system aimed to minimize the number of manual reviews based on Bayesian inference and Markov Chain Monte Carlo (MCMC) techniques Download PDFInfo
- Publication number
- US8635172B1 US8635172B1 US13/267,937 US201113267937A US8635172B1 US 8635172 B1 US8635172 B1 US 8635172B1 US 201113267937 A US201113267937 A US 201113267937A US 8635172 B1 US8635172 B1 US 8635172B1
- Authority
- US
- United States
- Prior art keywords
- precision
- grouping
- document
- probability distribution
- machine learning
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Expired - Fee Related, expires
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F18/00—Pattern recognition
- G06F18/20—Analysing
- G06F18/21—Design or setup of recognition systems or techniques; Extraction of features in feature space; Blind source separation
- G06F18/217—Validation; Performance evaluation; Active pattern learning techniques
Definitions
- the present disclosure relates generally to machine learning techniques and more particularly to techniques to improve performance of machine learning systems using Bayesian analysis to evaluate quality of clusters and/or classifications produced by those machine-learning systems.
- Computer-implemented or machine learning-based clustering or classifier systems are often used to separate a corpus of documents (text-based documents, images, etc.) into classes or clusters of like documents, to which business use case labels may (or may not) be applied. For example, a first classifier might classify all documents relating to topic A, a second classifier for topic B, etc. Once classified in this automated fashion, the respective classes can then be used to assist a computer-implemented search algorithm or used to extract business information relevant to a particular user.
- Clustering and classifier systems are often implemented using statistical models. Generally, a classification system will include several individual classifiers; whereas a clustering system may often employ just one clusterer. Classifiers are sometimes said to be “trained,” using training data. A classifier system may thus be fed a set of training data that are digested by a machine learning algorithm to define a set of trained models, each model being associated with a class represented in the training data. The training data are pre-labeled as belonging to a particular class. Hence, classification is sometimes called supervised learning because the learning system is told what each set of training data represents. Clusterers are not trained in this fashion but instead generate clusters based on automatic discovery of the underlying structure, so clustering is sometimes called unsupervised learning.
- a subject matter expert supplies the classifier with sample documents (training data) known to represent email messages relating to topic A, and the classifier stores parameters computed from those training data in a predetermined model for subsequent use in classifying later submitted documents.
- the supervised learning process would then be repeated for messages relating to topics B, C, and D, if desired, resulting in a set of trained models associated with a set of classifiers, each designed to recognize one of the topics A, B, C, D, etc.
- the set of classifiers may be used to identify whether a test document belongs to one of the trained topics.
- the test document is submitted to each of the classifiers (A, B, C, D, etc.) which are asked whether the test document belongs to its class. For example, if a test document about topic A is supplied, classifier A would respond with “yes,” while the remaining classifiers would respond with “no.” In some instances classifiers may also supply a likelihood score indicating how certain is its decision.
- Clustering systems work in essentially the same way, except that the clusters do not have labels previously supplied by a human rater.
- a classifier or clustering system's accuracy may drift, as the corpus of test documents evolves. Perhaps a new topic will be added, or perhaps some underlying document feature has changed, necessitating new training. In addition, when a particular cluster gets too large, it may be necessary to subdivide it, again necessitating new training. In all these scenarios, the system designer needs a way of assessing how well the classifier or clustering system is performing, to know when it is time to retrain the models or when to build new ones.
- Assessing the performance of a classifier or clustering system has traditionally involved a great deal of human labor. Traditionally a human rater would individually look at each document within the assigned class or cluster and determine whether it does or does not belong. While there are some statistical techniques that can be used to ameliorate the task, the review process still involves a human looking at potentially hundreds or thousands of documents before the performance quality of the classifier or clustering system can be ascertained.
- the techniques described here improve performance of machine learning systems using Bayesian analysis to evaluate quality of clusters and/or classifications produced by those machine-learning systems and thereby minimize the time and effort expended by a human rater, while still achieving the desired level of confidence in evaluating quality of clustering or classification.
- the techniques are applicable to both supervised machine learning systems, which generate classifications and unsupervised machine learning system, which generate clusters.
- groupings is used to collectively refer to “classifications” and “clusters.” Thus unless otherwise expressly stated or apparent from the context, it is understood that the principles described here apply to both supervised and unsupervised machine learning systems.
- the performance of a machine learning system of the type that generates a grouping from a plurality of documents is determined using at least one processor that performs several steps as follows. At least one processor associates a precision probability distribution to the grouping and then initially sets the precision probability to a predetermined probability distribution, such as a uniform distribution. At least one processor then receives review information about a first document associated with the grouping and assigns that first document a first document rating indicating whether the machine learning technique correctly or incorrectly assigned that first document to the grouping. At least one processor then applies Bayesian inference using the first document rating to update the precision probability distribution.
- the technique continues in iterative fashion to successively process subsequent documents associated with the grouping, by assigning the subsequent document a subsequent document rating indicating whether the classifier correctly or incorrectly assigned that subsequent document to the grouping; and to apply Bayesian inference using the subsequent document rating and the updated precision probability distribution to further update the precision probability distribution and to generate a grouping precision.
- the iterative process continues until terminated by a stopping rule that includes analyzing the relation of the grouping precision to at least one predetermined threshold.
- the grouping precision is used as a metric to assess performance of the machine learning system.
- the present disclosure relates to a technique of determining performance of a machine learning apparatus of the type that generates plural groupings each from a plurality of documents.
- the technique includes using at least one processor to perform a number of steps set forth below.
- the technique includes associating a precision probability distribution to one of the groupings based on Markov Chain Monte Carlo analysis of at least another of the plural groupings.
- the technique further includes receiving review information about a first document associated with the one of the groupings and assigning that first document a first document rating indicating whether the machine learning apparatus correctly or incorrectly assigned that first document to the first one of the groupings.
- the technique includes applying Bayesian analysis using the first document rating to update the precision probability distribution.
- the technique additionally includes performing the following steps (a) and (b) until termination by a stopping rule that includes analyzing the relation of a grouping precision to at least one predetermined threshold: (a) successively processing subsequent documents associated with said one of the groupings by assigning that subsequent document a subsequent document rating indicating whether the machine learning apparatus correctly or incorrectly assigned that subsequent document to the one of said groupings; and (b) applying Bayesian analysis using the subsequent document rating and the updated precision probability distribution to further update the precision probability distribution and to thereby generate the grouping precision.
- the technique uses the grouping precision as a metric to assess performance of the machine learning system.
- the present disclosure relates to a technique of determining performance of a machine learning apparatus of the type that generates a grouping from a plurality of documents.
- the technique utilizes at least one processor to perform each of the following steps.
- the technique includes the step of associating a precision probability distribution to the grouping and initially setting the precision probability distribution to a predetermined distribution.
- the technique further includes receiving review information about a first document associated with the grouping and assigning that first document a first document rating indicating whether the machine learning apparatus correctly or incorrectly assigned that first document to the proper grouping.
- the technique applies Bayesian analysis using the first document rating to update the precision probability distribution.
- the technique also includes performing the following steps (a) and (b) until termination by a stopping rule that includes analyzing the relation of a grouping precision to at least one predetermined threshold: (a) successively processing subsequent documents associated with said grouping by assigning that subsequent document a subsequent document rating indicating whether the machine learning apparatus correctly or incorrectly assigned that subsequent document to the proper grouping, and (b) applying Bayesian analysis using the subsequent document rating and the updated precision probability distribution to further update the precision probability distribution and to thereby generate the grouping precision.
- the technique additionally includes using the grouping precision as a metric to assess performance of the machine learning system.
- the present disclosure relates to an apparatus for testing a machine learning apparatus of the type which generates a grouping from a plurality of documents.
- the apparatus includes a document review processor having associated non-transitory machine readable medium storing the plurality of documents, the document review processor generating a user interface that iteratively presents one-at-a-time the plurality of documents to a human rater, harvests the human rater's vote as to whether a presented document belongs to the grouping and stores the vote in the non-transitory machine readable medium in association with the presented document.
- the apparatus further includes a Bayesian inference processor receptive of the stored vote and operable to compute a precision probability distribution for the presented document associated with the vote.
- the Bayesian inference processor being further operable to enforce at least one stopping rule by comparing the computed precision probability distribution to at least one predetermined threshold.
- the Bayesian inference processor upon enforcing said at least one stopping rule, will generate an output indicating whether the machine learning apparatus under test generated correct groupings with a probability above a predetermined threshold.
- FIG. 1 is a block diagram of an apparatus employing Bayesian inference and Markov Chain Monte Carlo processor operating on a beta binomial model to determine performance of an exemplary classifier system;
- FIG. 2 is a flowchart diagram illustrating an example technique for determining performance of a machine learning classifier or clustering system
- FIG. 3 is an example graph showing an example precision probability distribution to which precision thresholds and confidence levels are assessed.
- FIG. 4 is a flowchart diagram further describing the Markov Chain Monte Carlo processor.
- the embodiments disclosed use Bayesian analysis mediated by a Markov Chain Monte Carlo (MCMC) process (processor) to evaluate quality of clusters and/or classifications (referred herein as groupings) produced by those machine-learning systems.
- MCMC Markov Chain Monte Carlo
- a set of stopping rules monitor certain parameters generated by the techniques, allowing functional quality of the machine learning system to be assessed without the need to review all documents assigned to the grouping.
- the dynamic technique of evaluating quality seeks to minimize the number of documents the human rater must look at in order to assess the performance quality of the machine learning system. At the same time the technique seeks to retain high confidence that the quality assessment is correct.
- the technique associates a precision probability distribution with each document in the grouping. For the first document in the grouping, the technique assumes the precision probability distribution to be a uniform distribution. As the rater examines each document, the technique updates the precision probability distribution using a Bayesian analytical technique, with the result that the precision probability distribution serves as a model of what the prior experience has been. With this model of prior experience the system is better able to predict what the future will bring and is thus able to assess the quality of the grouping without the need for the human to examine every document in the grouping. Graphically depicted, the precision probability distribution curve shows the confidence level (probability) for any desired degree of precision.
- the technique exploits this Bayesian-generated precision probability distribution to determine when the human rater can stop examining documents. This is done by setting stopping rules; for example: stop when the precision probability distribution curve reflects that the confidence level is above 95% that the grouping precision is above 80%. That is, stop when there is a 95% probability that at least 80% of the documents correctly belong to the grouping (were the human rater to actually examine all documents in the grouping).
- the technique applies a second stopping rule to handle the case where the grouping does not pass muster: stop when the confidence level is above 95% that the grouping precision is below 80%.
- a third stopping rule terminates the process, to save time, if neither the first two stopping rules are met within a certain number of documents examined.
- the first stopping rule results in the machine learning system being judged favorably (accept); the second and third stopping rules result in the machine learning system being judged unfavorably (reject).
- the 80% and 95% values described here are exemplary and could be different, depending on system requirements.
- Bayesian analysis can effectively be performed to assess the quality of a single machine learning classifier or single machine learning clustering system (i.e., a system producing a single grouping)
- the more practical situation involves perhaps hundreds or thousands of machine learning classifiers or clustering systems (one for each of a plurality of different groupings of interest).
- the technique exploits the predictive power of Bayesian analysis so that each grouping being examined benefits from knowledge obtained by prior examination of preceding groupings.
- one example Bayesian analytical technique uses a Bayesian hierarchical model, known as a beta binomial model.
- the beta binomial model defines a tree structure having a root node and plural leaf nodes.
- the root node represents the distribution of grouping precision (how good of a job all of the machine learning classifiers or clustering systems collectively are doing).
- the leaf nodes each represent one of the individual groupings and are added to the tree structured beta binomial model as each new grouping is examined by the human rater.
- Each of the leaf nodes stores a single parameter representing the precision parameter for that grouping.
- the root node stores two parameters, representing the centrality and dispersion of the overall distribution of grouping precision.
- the model is updated, taking into account not only the rater's assessment of the document in hand, but also the prior knowledge stored in the beta binomial model. With large systems, the beta binomial model can become quite complex, making it essentially impossible to update by hand.
- the technique uses a sampling/simulation technique known as Markov Chain Monte Carlo (MCMC) to update the model. While MCMC is specifically discussed herein, other sampling/simulation tools can be used.
- MCMC Markov Chain Monte Carlo
- the MCMC algorithm essentially samples (takes random draws from) the parameters stored in the model and iteratively arrives at a new overall grouping precision distribution. It iteratively uses samples of the leaf node parameters to compute or estimate parameters for the root node and then uses the root node to compute subsequent parameters for the leaf nodes, and so forth. In this way the MCMC algorithm fits the beta binomial model to the observed data from the human rater and exploits a concept called shrinkage whereby information stored in the root is shared across leaf nodes.
- the above-described technique may be applied to both unsupervised and supervised learning systems.
- cluster precision will typically be evaluated with respect to multiple topics in a given cluster; whereas in a supervised learning system (e.g., classifier) classifier precision is typically evaluated for one topic for a given classifier.
- supervised learning system e.g., classifier
- the machine learning system generates a data store of document groupings 12 which are then accessed by a document review station 14 operated by a human rater.
- the machine learning system 10 may be a supervised machine learning system (classifier) in which case the document groupings would correspond to documents that are classified based on the trained models 16 .
- the machine learning system 10 may be a clustering system, in which case the document groupings would correspond to document clusters based on the trained models 16 .
- the term “document” refers to a unit of digitized information. Examples include text files, digital image data files, audio and video files, and the like.
- the human rater uses the document review station 14 to retrieve a first record from the document grouping data store, which corresponds to a first document belonging to a designated grouping. For example, if the documents are text-based web pages organized into groupings by different topics, the human rater might be reviewing documents assigned to the grouping: shoes.
- the document review station produces an on-screen display 18 identifying the grouping under consideration (shoes) and displaying the first document of that grouping.
- the human rater examines the displayed document to determine whether it does or does not belong to the assigned grouping and enters his or her assessment (yes/no) in the user interface provided.
- the document review station 14 sends the human rater's vote as Boolean binary data (yes/no) to the Bayesian inference analyzer 20 implemented by a computer processor.
- the Bayesian inference analyzer uses the rater's decision as observation data to update a precision probability distribution which the Bayesian inference analyzer 20 stores in non-transitory computer-readable memory 22 associated with its processor.
- the Bayesian inference analyzer 20 operates upon a Beta binomial model, which has been depicted diagrammatically at 22 to include a plurality of Level 0 leaf nodes 24 coupled in tree structure fashion to a Level 1 root node 26 .
- the leaf nodes each correspond to one of the groupings generated by the machine learning system 10 .
- Beta ( ⁇ , ⁇ ).
- the parameters ( ⁇ , ⁇ ) correspond respectively to the success or failure of a given document to belong to the grouping.
- the success parameter ⁇ is incremented by 1.
- the Beta function becomes Beta ( ⁇ +1, ⁇ ).
- the Beta function is updated by incrementing the failure parameter: Beta ( ⁇ , ⁇ +1). While there are many suitable ways of implementing the Beta function, a suitable library may be found in the R statistical computing package available at http://www.r-project.org/.
- the document review station 14 and Bayesian inference analyzer 20 work together to process the human rater's votes and update the precision probability distribution, one grouping at a time. Each time a new grouping is begun for analysis, a new leaf node 24 is added to the Beta binomial model. Thus, for example, the precision probability distribution for the grouping “shoes” would correspond to the leaf node 24 s (the most newly added node in the tree).
- Bayesian inference analysis upon each individual grouping allows the apparatus to enforce a set of stopping rules stored in non-transitory computer-readable memory 28 . These stopping rules allow the system to make an accept/reject decision as to the quality of the grouping, in most cases long before the human rater has examined all documents within that grouping. This saves substantial time and effort and a commensurate savings in cost. While Bayesian inference alone affords a significant time, effort and cost savings, the illustrated embodiment implements another component that improves the system even further.
- a Markov Chain Monte Carlo (MCMC) processor 30 operates upon the Beta binomial model stored in memory 22 , allowing information learned while processing a first grouping to improve the predictive ability of Bayesian inferences drawn about later processed groupings.
- the Markov Chain Monte Carlo processor 30 is thus invoked after the Bayesian inference analyzer has made its accept/reject decision about the current grouping under test.
- the Markov Chain Monte Carlo processor samples data stored in the leaf nodes by the Bayesian inference analyzer 20 and estimates an overall grouping precision distribution stored in the root node 26 from the sampled data. Whereas each of the leaf nodes corresponds to a single grouping, the root node corresponds to a probability distribution for the entire set of groupings.
- the Bayesian inference analyzer 20 uses information from the root node in making its inference assessment of each grouping under test. In this way, the system gradually benefits more and more from the collective knowledge stored in the root node.
- the root node has little or no information about the leaf nodes, thus the first groupings assessed by the Bayesian inference analyzer are assessed primarily on the observations about those groupings, and the Bayesian inferences drawn therefrom.
- the root node contributes more and more to the leaf node assessment, allowing the system to make its stopping rules assessment even more quickly and with high accuracy.
- the machine learning system is a classifier and thus the document groupings represent classes based on the trained models of the classifier.
- the process begins at steps 100 and 102 where the stopping rules are stored in the stopping rules memory 28 ( FIG. 1 ).
- the precision threshold and confidence levels are determined for acceptance and rejection of a document.
- the acceptance rule may require a 95% confidence level that the precision is above 80%.
- the rejection rule might require a 95% confidence level that the precision probability is below 80%.
- a maximum number of trials per classifier is set at step 102 to terminate review and thus reject the classifier if a maximum number of trials is reached. An exemplary value for such maximum number might be 20 trials.
- a classifier is selected at random from the collection of classifiers stored in the document grouping data store 12 ( FIG. 1 ).
- a Level 1 precision distribution is set at 108 to be a uniform distribution: Beta (1,1).
- the precision distribution at root node 26 would be set to a uniform distribution.
- the review of subsequent classifiers do not make this initial assumption of a uniform distribution. Rather they use the precision distribution as calculated by the Markov Chain Monte Carlo processor 30 ( FIG. 1 ).
- step 110 is also reached directly (without instantiating Level 1 to uniform) if the classifier selected at step 104 is not the first classifier sampled from the collection.
- a first item (document) is selected at random from the selected classifier and presented to the human rater by displaying it at the document review station 14 ( FIG. 1 ).
- the rater is presented an on-screen display question of whether the item (document) belongs to the class associated with the classifier under test, as at step 111 .
- the rater supplies his or her answer by suitable manipulation of the document review station user interface and the answer (yes/no) is supplied to the Bayesian inference analyzer 20 ( FIG. 1 ), which then updates the precision distribution as illustrated at 112 (for the “yes” case) and at 114 (for the “no” case).
- the Bayesian inference analyzer 20 updates the precision distribution by incrementing either the a parameter (step 112 ) or the ⁇ parameter (step 114 ) of the Beta function programmed into the Bayesian inference analyzer 20 .
- the technique next tests whether any of the stopping rules have been met. Shown generally at 116 , the stopping rules are applied to assess whether the precision thresholds and confidence levels have reached the point where the classifier can be accepted, as at 118 , or rejected, as at 120 . The third stopping rule, whether the maximum number of trials has been reached, is also tested for and may serve as another reason to reject the classifier as at 122 . If none of the stopping rules are satisfied, the technique loops back to step 110 where the next item (document) is randomly selected from the classifier under test, whereupon the procedure repeats until a stopping rule is satisfied.
- FIG. 3 An exemplary precision probability graph has been illustrated at FIG. 3 .
- the graph plots grouping precision (i.e., classification precision or cluster precision) along the x-axis and a confidence level (probability) along the y-axis.
- the precision threshold has been indicated at 124 .
- the portions of the precision probability curve to the right of the precision threshold line represent precision greater than 80% (in this case) and portions of the curve to the left of precision threshold 124 represent precisions less than 80% (in this case).
- the technique proceeds to step 126 where the Markov Chain Monte Carlo (MCMC) processor 30 ( FIG. 1 ) updates the Level 1 precision distribution.
- the MCMC processor does this by making a plurality of draws or samples from the manually evaluated items; that is, from the data stored in the leaf nodes 24 of the Beta binomial model ( FIG. 1 ).
- FIG. 4 shows in greater detail how the Markov Chain Monte Carlo processor functions.
- the Markov Chain Monte Carlo processor operates upon a model 200 that describes both data level information and parameter level information.
- the processor iteratively performs computer processing steps 202 and 204 to produce a sequence of draws that are sequentially correlated across iterations.
- a machine learning classifier has been assumed. It will be understood that this explanation would also apply to machine learning clusterers.
- model 200 may be described as follows:
- the unknowns in model 200 are (alpha, beta, theta[1], . . . , theta[N]). If the theta[i]'s were observed, then it would be easy to estimate alpha and beta. If alpha and beta had been observed, then it would be easy to estimate each theta[i] from n[i] and y[i].
- Step 1 Draw each theta[i] ⁇ Beta(alpha+y[i], beta+n[i] ⁇ y[i]).
- Step 1 of the algorithm can be done in closed form, because conjugacy implies that p(theta[i]
- Step 2 is somewhat more complicated because p(alpha, beta
- a “slice sampler” is used (described in Neal 2003, Annals of Statistics). Others possible implementations might use a Metropolis-Hastings step.
- the MCMC algorithm is run for a long time (a few thousand iterations). It produces a sequence of draws that are sequentially correlated across iterations. But time averages (across iterations) of any subset of unknowns have very similar properties to averages of draws from a hypothetical sampler that could produce independent draws. Thus (for example) you can estimate the upper and lower confidence limits for theta[i] from this Monte Carlo sample, and those upper and lower limits will capture the fact that you don't know exact values for alpha and beta.
- Example embodiments are provided so that this disclosure will be thorough, and will fully convey the scope to those who are skilled in the art. Numerous specific details are set forth such as examples of specific components, devices, and methods, to provide a thorough understanding of embodiments of the present disclosure. It will be apparent to those skilled in the art that specific details need not be employed, that example embodiments may be embodied in many different forms and that neither should be construed to limit the scope of the disclosure. In some example embodiments, well-known procedures, well-known device structures, and well-known technologies are not described in detail.
- first, second, third, etc. may be used herein to describe various elements, components, regions, layers and/or sections, these elements, components, regions, layers and/or sections should not be limited by these terms. These terms may be only used to distinguish one element, component, region, layer or section from another region, layer or section. Terms such as “first,” “second,” and other numerical terms when used herein do not imply a sequence or order unless clearly indicated by the context. Thus, a first element, component, region, layer or section discussed below could be termed a second element, component, region, layer or section without departing from the teachings of the example embodiments.
- module may refer to, be part of, or include an Application Specific Integrated Circuit (ASIC); an electronic circuit; a combinational logic circuit; a field programmable gate array (FPGA); a processor (shared, dedicated, or group) that executes code, or a process executed by a distributed network of processors and storage in networked clusters or datacenters; other suitable components that provide the described functionality; or a combination of some or all of the above, such as in a system-on-chip.
- the term module may include memory (shared, dedicated, or group) that stores code executed by the one or more processors.
- code may include software, firmware, byte-code and/or microcode, and may refer to programs, routines, functions, classes, and/or objects.
- shared means that some or all code from multiple modules may be executed using a single (shared) processor. In addition, some or all code from multiple modules may be stored by a single (shared) memory.
- group means that some or all code from a single module may be executed using a group of processors. In addition, some or all code from a single module may be stored using a group of memories.
- the techniques described herein may be implemented by one or more computer programs executed by one or more processors.
- the computer programs include processor-executable instructions that are stored on a non-transitory tangible computer readable medium.
- the computer programs may also include stored data.
- Non-limiting examples of the non-transitory tangible computer readable medium are nonvolatile memory, magnetic storage, and optical storage.
- the present disclosure also relates to an apparatus for performing the operations herein.
- This apparatus may be specially constructed for the required purposes, or it may comprise a general-purpose computer selectively activated or reconfigured by a computer program stored on a computer readable medium that can be accessed by the computer.
- a computer program may be stored in a tangible computer readable storage medium, such as, but is not limited to, any type of disk including floppy disks, optical disks, CD-ROMs, magnetic-optical disks, read-only memories (ROMs), random access memories (RAMs), EPROMs, EEPROMs, magnetic or optical cards, application specific integrated circuits (ASICs), or any type of media suitable for storing electronic instructions, and each coupled to a computer system bus.
- the computers referred to in the specification may include a single processor or may be architectures employing multiple processor designs for increased computing capability.
- the present disclosure is well suited to a wide variety of computer network systems over numerous topologies.
- the configuration and management of large networks comprise storage devices and computers that are communicatively coupled to dissimilar computers and storage devices over a network, such as the Internet.
Abstract
Description
-
- (Data Level): Suppose there are N classifiers being assessed. The success rate for classifier i is theta[i] (a number between 0 and 1). The number of successes that have been observed for this classifier is y[i]. The number of cases that have been observed is n[i]. Thus an empirical estimate of theta[i] is y[i]/n[i]. The model for the data produced by classifier i is y[i] ˜Binomial(n[i], theta[i]). That is Pr(y[i])=K (theta[i])^y[i]*(1−theta[i])^(n[i]−y[i]), where K is a binomial normalizing constant.
- (Parameter Level): Suppose that theta[i]−Beta(alpha, beta). That is: p(theta[i])=K2 (theta[i])^alpha*(1−theta[i])^beta, where K2 is a different normalizing constant. This distribution is “conjugate” to the binomial distribution, which means that they have the same functional form. The only difference is that at the data level, y[i] is the random variable. At the parameter level, theta[i] is the random variable. alpha and beta are global model parameters that describe the success rates for a typical classifier, and the amount of dispersion among classifiers. People often think of “alpha” as “prior successes” and “beta” as “prior failures”. Thus an estimate of the overall success rate (across all classifiers) is alpha/(alpha+beta). If alpha+beta is a large number, then the individual theta[i]'s will all be very close to alpha/(alpha+beta). If it is small then the success rates theta[i] can vary substantially from one classifier to the next.
- Prior. One of the inputs into a Bayesian analysis is a prior distribution specifying your belief about model parameters before seeing any data. Our prior is p(alpha, beta). If we have not seen any data then we want our prior to reflect ignorance. We can accomplish this by setting p(alpha/(alpha+beta))˜U(0, 1), and p(alpha+beta)˜Gamma(0.1.1). The prior on alpha/(alpha+beta) obviously says that we have no information about the location parameter. The prior on alpha+beta favors values close to zero, but it is heavy tailed, so values far from zero are not penalized very much.
p(alpha,beta)*product_i Beta(theta[i]|alpha,beta).
Claims (20)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US13/267,937 US8635172B1 (en) | 2011-10-07 | 2011-10-07 | Dynamic techniques for evaluating quality of clustering or classification system aimed to minimize the number of manual reviews based on Bayesian inference and Markov Chain Monte Carlo (MCMC) techniques |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US13/267,937 US8635172B1 (en) | 2011-10-07 | 2011-10-07 | Dynamic techniques for evaluating quality of clustering or classification system aimed to minimize the number of manual reviews based on Bayesian inference and Markov Chain Monte Carlo (MCMC) techniques |
Publications (1)
Publication Number | Publication Date |
---|---|
US8635172B1 true US8635172B1 (en) | 2014-01-21 |
Family
ID=49919321
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US13/267,937 Expired - Fee Related US8635172B1 (en) | 2011-10-07 | 2011-10-07 | Dynamic techniques for evaluating quality of clustering or classification system aimed to minimize the number of manual reviews based on Bayesian inference and Markov Chain Monte Carlo (MCMC) techniques |
Country Status (1)
Country | Link |
---|---|
US (1) | US8635172B1 (en) |
Cited By (18)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20140149060A1 (en) * | 2012-11-29 | 2014-05-29 | Sensor Platforms, Inc. | Combining Monitoring Sensor Measurements and System Signals to Determine Device Context |
CN104850698A (en) * | 2015-05-15 | 2015-08-19 | 西安交通大学 | Measuring and adjusting process-considered tolerance design method of precise machine tool |
US20150332157A1 (en) * | 2014-05-15 | 2015-11-19 | International Business Machines Corporation | Probability mapping model for location of natural resources |
CN106104577A (en) * | 2014-03-07 | 2016-11-09 | 高通股份有限公司 | Photo management |
CN106575223A (en) * | 2014-07-21 | 2017-04-19 | 宇龙计算机通信科技(深圳)有限公司 | Image classification method and image classification apparatus |
US9665628B1 (en) * | 2015-12-06 | 2017-05-30 | Xeeva, Inc. | Systems and/or methods for automatically classifying and enriching data records imported from big data and/or other sources to help ensure data integrity and consistency |
CN107229733A (en) * | 2017-06-12 | 2017-10-03 | 上海智臻智能网络科技股份有限公司 | Evaluation method and device are asked in extension |
US20180204084A1 (en) * | 2017-01-17 | 2018-07-19 | International Business Machines Corporation | Ensemble based labeling |
US20180260759A1 (en) * | 2017-03-07 | 2018-09-13 | Mighty AI, Inc. | Segmentation of Images |
JP2019148445A (en) * | 2018-02-26 | 2019-09-05 | 日立オートモティブシステムズ株式会社 | Hammering sound inspection device |
CN110501421A (en) * | 2019-07-24 | 2019-11-26 | 武汉大学 | A kind of track profiling method of detection based on mechanical arm |
CN110909146A (en) * | 2019-11-29 | 2020-03-24 | 支付宝(杭州)信息技术有限公司 | Label pushing model training method, device and equipment for pushing question-back labels |
US20200401937A1 (en) * | 2019-06-20 | 2020-12-24 | Fuji Xerox Co., Ltd. | Information processing apparatus and non-transitory computer readable medium |
US11409589B1 (en) | 2019-10-23 | 2022-08-09 | Relativity Oda Llc | Methods and systems for determining stopping point |
US11580571B2 (en) * | 2016-02-04 | 2023-02-14 | LMP Software, LLC | Matching reviews between customer feedback systems |
US11699132B1 (en) | 2019-10-23 | 2023-07-11 | Relativity Oda Llc | Methods and systems for facilitating family-based review |
US11704534B2 (en) | 2018-10-29 | 2023-07-18 | Industrial Technology Research Institute | Neural-network-based classification device and classification method |
WO2023249755A1 (en) * | 2022-06-24 | 2023-12-28 | Microsoft Technology Licensing, Llc | Automatic thresholding for classification models |
Citations (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7801839B2 (en) * | 2002-07-04 | 2010-09-21 | Kates Ronald E | Method for training a learning-capable system |
US7890438B2 (en) * | 2007-12-12 | 2011-02-15 | Xerox Corporation | Stacked generalization learning for document annotation |
US8352384B2 (en) * | 2008-03-04 | 2013-01-08 | Massachusetts Institute Of Technology | Combinational stochastic logic |
US8386403B2 (en) * | 2010-03-02 | 2013-02-26 | Empire Technology Development Llc | Distributed-type Markov chain Monte Carlo |
-
2011
- 2011-10-07 US US13/267,937 patent/US8635172B1/en not_active Expired - Fee Related
Patent Citations (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7801839B2 (en) * | 2002-07-04 | 2010-09-21 | Kates Ronald E | Method for training a learning-capable system |
US7890438B2 (en) * | 2007-12-12 | 2011-02-15 | Xerox Corporation | Stacked generalization learning for document annotation |
US8352384B2 (en) * | 2008-03-04 | 2013-01-08 | Massachusetts Institute Of Technology | Combinational stochastic logic |
US8386403B2 (en) * | 2010-03-02 | 2013-02-26 | Empire Technology Development Llc | Distributed-type Markov chain Monte Carlo |
Non-Patent Citations (1)
Title |
---|
Andrieu, Christophe et al., "An Introduction to MCMC for Machine Learning", Machine Learning, 2003, pp. 5-43, vol. 50. |
Cited By (33)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20140149060A1 (en) * | 2012-11-29 | 2014-05-29 | Sensor Platforms, Inc. | Combining Monitoring Sensor Measurements and System Signals to Determine Device Context |
US9726498B2 (en) * | 2012-11-29 | 2017-08-08 | Sensor Platforms, Inc. | Combining monitoring sensor measurements and system signals to determine device context |
CN106104577A (en) * | 2014-03-07 | 2016-11-09 | 高通股份有限公司 | Photo management |
CN106104577B (en) * | 2014-03-07 | 2020-07-03 | 高通股份有限公司 | Photo management |
US11500905B2 (en) | 2014-05-15 | 2022-11-15 | Kyndryl, Inc. | Probability mapping model for location of natural resources |
US10318552B2 (en) * | 2014-05-15 | 2019-06-11 | International Business Machines Corporation | Probability mapping model for location of natural resources |
US20150332157A1 (en) * | 2014-05-15 | 2015-11-19 | International Business Machines Corporation | Probability mapping model for location of natural resources |
CN106575223A (en) * | 2014-07-21 | 2017-04-19 | 宇龙计算机通信科技(深圳)有限公司 | Image classification method and image classification apparatus |
CN104850698B (en) * | 2015-05-15 | 2018-11-09 | 西安交通大学 | It is a kind of to consider to measure the precision machine tool tolerance design method with adjusting process |
CN104850698A (en) * | 2015-05-15 | 2015-08-19 | 西安交通大学 | Measuring and adjusting process-considered tolerance design method of precise machine tool |
US9740979B2 (en) | 2015-12-06 | 2017-08-22 | Xeeva, Inc. | Model stacks for automatically classifying data records imported from big data and/or other sources, associated systems, and/or methods |
US9665628B1 (en) * | 2015-12-06 | 2017-05-30 | Xeeva, Inc. | Systems and/or methods for automatically classifying and enriching data records imported from big data and/or other sources to help ensure data integrity and consistency |
US11100408B2 (en) | 2015-12-06 | 2021-08-24 | Xeeva, Inc. | System and/or method for generating clean records from imperfect data using model stack(s) including classification model(s) and confidence model(s) |
US10176427B2 (en) | 2015-12-06 | 2019-01-08 | Xeeva, Inc. | System and/or method for generating clean records from imperfect data using model stack(s) including classification model(s) and confidence model(s) |
US11669750B2 (en) | 2015-12-06 | 2023-06-06 | Xeeva, Inc. | System and/or method for generating clean records from imperfect data using model stack(s) including classification model(s) and confidence model(s) |
US11580571B2 (en) * | 2016-02-04 | 2023-02-14 | LMP Software, LLC | Matching reviews between customer feedback systems |
US20180204082A1 (en) * | 2017-01-17 | 2018-07-19 | International Business Machines Corporation | Ensemble based labeling |
US10339471B2 (en) * | 2017-01-17 | 2019-07-02 | International Business Machines Corporation | Ensemble based labeling |
US20180204084A1 (en) * | 2017-01-17 | 2018-07-19 | International Business Machines Corporation | Ensemble based labeling |
US10733537B2 (en) * | 2017-01-17 | 2020-08-04 | International Business Machines Corporation | Ensemble based labeling |
US20180260759A1 (en) * | 2017-03-07 | 2018-09-13 | Mighty AI, Inc. | Segmentation of Images |
CN107229733B (en) * | 2017-06-12 | 2020-01-14 | 上海智臻智能网络科技股份有限公司 | Extended question evaluation method and device |
CN107229733A (en) * | 2017-06-12 | 2017-10-03 | 上海智臻智能网络科技股份有限公司 | Evaluation method and device are asked in extension |
JP2019148445A (en) * | 2018-02-26 | 2019-09-05 | 日立オートモティブシステムズ株式会社 | Hammering sound inspection device |
US11704534B2 (en) | 2018-10-29 | 2023-07-18 | Industrial Technology Research Institute | Neural-network-based classification device and classification method |
US20200401937A1 (en) * | 2019-06-20 | 2020-12-24 | Fuji Xerox Co., Ltd. | Information processing apparatus and non-transitory computer readable medium |
CN110501421A (en) * | 2019-07-24 | 2019-11-26 | 武汉大学 | A kind of track profiling method of detection based on mechanical arm |
US11409589B1 (en) | 2019-10-23 | 2022-08-09 | Relativity Oda Llc | Methods and systems for determining stopping point |
US11699132B1 (en) | 2019-10-23 | 2023-07-11 | Relativity Oda Llc | Methods and systems for facilitating family-based review |
US11921568B2 (en) | 2019-10-23 | 2024-03-05 | Relativity Oda Llc | Methods and systems for determining stopping point |
CN110909146B (en) * | 2019-11-29 | 2022-09-09 | 支付宝(杭州)信息技术有限公司 | Label pushing model training method, device and equipment for pushing question-back labels |
CN110909146A (en) * | 2019-11-29 | 2020-03-24 | 支付宝(杭州)信息技术有限公司 | Label pushing model training method, device and equipment for pushing question-back labels |
WO2023249755A1 (en) * | 2022-06-24 | 2023-12-28 | Microsoft Technology Licensing, Llc | Automatic thresholding for classification models |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US8635172B1 (en) | Dynamic techniques for evaluating quality of clustering or classification system aimed to minimize the number of manual reviews based on Bayesian inference and Markov Chain Monte Carlo (MCMC) techniques | |
CN111124840B (en) | Method and device for predicting alarm in business operation and maintenance and electronic equipment | |
US20210136098A1 (en) | Root cause analysis in multivariate unsupervised anomaly detection | |
Metevier et al. | Offline contextual bandits with high probability fairness guarantees | |
EP2814218A1 (en) | Detecting anomalies in work practice data by combining multiple domains of information | |
US20140258187A1 (en) | Generating database cluster health alerts using machine learning | |
US20220012632A1 (en) | Generalized metric for machine learning model evaluation for unsupervised classification | |
Lum et al. | De-biasing “bias” measurement | |
CN110909758A (en) | Computer-readable recording medium, learning method, and learning apparatus | |
CN110457471A (en) | File classification method and device based on A-BiLSTM neural network | |
CN111340233B (en) | Training method and device of machine learning model, and sample processing method and device | |
Fitzgerald et al. | Early failure prediction in feature request management systems | |
Pendharkar | Exhaustive and heuristic search approaches for learning a software defect prediction model | |
Grün et al. | Dealing with label switching in mixture models under genuine multimodality | |
KR20180056013A (en) | Method and apparatus for predicting toxicity of nano material | |
Tolochko et al. | Same but different: A comparison of estimation approaches for exponential random graph models for multiple networks | |
CN117540826A (en) | Optimization method and device of machine learning model, electronic equipment and storage medium | |
CN113761193A (en) | Log classification method and device, computer equipment and storage medium | |
CN113704389A (en) | Data evaluation method and device, computer equipment and storage medium | |
Alasalmi et al. | Classification uncertainty of multiple imputed data | |
Pousi et al. | Simulation metamodelling with Bayesian networks | |
US20220391724A1 (en) | Unsupervised Anomaly Detection With Self-Trained Classification | |
Farhad et al. | Keep Your Distance: Determining Sampling and Distance Thresholds in Machine Learning Monitoring | |
CN112906805A (en) | Image training sample screening and task model training method and device and electronic equipment | |
Iliashov et al. | Formalization of the procedure of allocation of technical devices among monitoring objects based on the theory of fuzzy sets |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:BURYAK, KIRILL;SCOTT, STEVEN LEE;DOUBILET, STEVEN;SIGNING DATES FROM 20111005 TO 20111006;REEL/FRAME:027029/0701 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
FPAY | Fee payment |
Year of fee payment: 4 |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044101/0299Effective date: 20170929 |
|
FEPP | Fee payment procedure |
Free format text: MAINTENANCE FEE REMINDER MAILED (ORIGINAL EVENT CODE: REM.); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
LAPS | Lapse for failure to pay maintenance fees |
Free format text: PATENT EXPIRED FOR FAILURE TO PAY MAINTENANCE FEES (ORIGINAL EVENT CODE: EXP.); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
STCH | Information on status: patent discontinuation |
Free format text: PATENT EXPIRED DUE TO NONPAYMENT OF MAINTENANCE FEES UNDER 37 CFR 1.362 |
|
FP | Lapsed due to failure to pay maintenance fee |
Effective date: 20220121 |