CN112840667A - Method and system for classification and categorization of video paths in interactive video - Google Patents
Method and system for classification and categorization of video paths in interactive video Download PDFInfo
- Publication number
- CN112840667A CN112840667A CN201980063003.0A CN201980063003A CN112840667A CN 112840667 A CN112840667 A CN 112840667A CN 201980063003 A CN201980063003 A CN 201980063003A CN 112840667 A CN112840667 A CN 112840667A
- Authority
- CN
- China
- Prior art keywords
- video
- classification
- genre
- segment
- path
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
Images
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/80—Generation or processing of content or additional data by content creator independently of the distribution process; Content per se
- H04N21/85—Assembly of content; Generation of multimedia applications
- H04N21/854—Content authoring
- H04N21/8541—Content authoring involving branching, e.g. to different story endings
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/20—Servers specifically adapted for the distribution of content, e.g. VOD servers; Operations thereof
- H04N21/25—Management operations performed by the server for facilitating the content distribution or administrating data related to end-users or client devices, e.g. end-user or client device authentication, learning user preferences for recommending movies
- H04N21/258—Client or end-user data management, e.g. managing client capabilities, user preferences or demographics, processing of multiple end-users preferences to derive collaborative data
- H04N21/25866—Management of end-user data
- H04N21/25891—Management of end-user data being end-user preferences
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/20—Servers specifically adapted for the distribution of content, e.g. VOD servers; Operations thereof
- H04N21/25—Management operations performed by the server for facilitating the content distribution or administrating data related to end-users or client devices, e.g. end-user or client device authentication, learning user preferences for recommending movies
- H04N21/266—Channel or content management, e.g. generation and management of keys and entitlement messages in a conditional access system, merging a VOD unicast channel into a multicast channel
- H04N21/26603—Channel or content management, e.g. generation and management of keys and entitlement messages in a conditional access system, merging a VOD unicast channel into a multicast channel for automatically generating descriptors from content, e.g. when it is not made available by its provider, using content analysis techniques
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/47—End-user applications
- H04N21/482—End-user interface for program selection
- H04N21/4828—End-user interface for program selection for searching program descriptors
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/80—Generation or processing of content or additional data by content creator independently of the distribution process; Content per se
- H04N21/83—Generation or processing of protective or descriptive data associated with content; Content structuring
- H04N21/84—Generation or processing of descriptive data, e.g. content descriptors
- H04N21/8405—Generation or processing of descriptive data, e.g. content descriptors represented by keywords
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/80—Generation or processing of content or additional data by content creator independently of the distribution process; Content per se
- H04N21/83—Generation or processing of protective or descriptive data associated with content; Content structuring
- H04N21/845—Structuring of content, e.g. decomposing content into time segments
- H04N21/8456—Structuring of content, e.g. decomposing content into time segments by decomposing the content in the time domain, e.g. in time segments
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/80—Generation or processing of content or additional data by content creator independently of the distribution process; Content per se
- H04N21/85—Assembly of content; Generation of multimedia applications
- H04N21/854—Content authoring
- H04N21/8545—Content authoring for generating interactive applications
Abstract
Methods, systems, and apparatus, including computer programs encoded on computer storage media, identify and classify various video paths in interactive video based on their content. A video comprising a plurality of video segments is obtained from a video library. Each video segment is directly linked to at least one other video segment, and the plurality of video segments includes a start segment, an intermediate segment (including an interactive segment), and a final segment. A plurality of video paths in a video are identified. For each identified video path, classification data is generated, and each such video path is then stored in a video library. When a video is selected from a particular category of the video library, then a video clip is displayed that has a video path of the same classification as the classification associated with the particular category.
Description
Background
The specification generally relates to identifying and classifying content of interactive videos and displaying video paths of the interactive videos on user devices.
Conventional video includes a series of video segments that together make up a single video path. Interactive video, on the other hand, includes video segments that make up a plurality of different video paths, any of which a viewer can select during video presentation. In particular, at different points during the interactive video presentation, the viewer is prompted to make certain decisions based on which the viewer ultimately views a particular video path in the interactive video.
Interactive video may be used for training purposes, for example, in reality simulators. An operator of such a simulator, such as a simulator used to simulate control of an aircraft or train (or other vehicle) or a piece of complex plant machinery, may be prompted at different points in the interactive video to select one of several different options. Different selections may result in different video paths being displayed, where each video path simulates the result selected for training. As another example, the interactive video can be a movie that includes a plurality of different video paths. For such interactive videos, the viewer may be prompted to make certain decisions at different points during the video presentation, which may result in one of these paths being displayed.
Each interactive video can include a plurality of different video paths, and thus each video path can include different types of content (e.g., content categorized by different genres).
Disclosure of Invention
In general, one innovative aspect of the subject matter described in this specification can be embodied in methods that include the actions of: obtaining a video comprising a plurality of video segments from a video library, wherein each video segment is directly linked to at least one other video segment; the plurality of video segments includes a start video segment, an intermediate video segment, and a final video segment; and the intermediate video segments comprise a set of interactive video segments, wherein each interactive video segment is directly linked to at least two other video segments, only one of which is selectable by the viewer at the end of the display of the interactive video segment; identifying a plurality of video paths in the video, wherein each video path comprises a different subset of video segments among the plurality of video segments, and each subset of video segments comprises a starting video segment, a set of intermediate segments, and a final video segment; for each video path in the video, generating classification data describing content in the video path; for each video path in the video, storing the video in a category of a video library along with other videos in the category of the video library based on the classification data for the video path, wherein the video library includes a plurality of categories each associated with a different classification; and upon selecting a video from a particular category of the video library and presenting it on the user device, displaying a video clip having a video path of the same category as the category associated with the particular category.
Other embodiments of this aspect include corresponding systems, apparatus, devices, and computer programs configured to perform the actions of the methods. A computer program (e.g., instructions) can be encoded on a computer storage device. These and other embodiments can each optionally include one or more of the following features.
In some implementations, the classification data describing the content in each video path specifies a genre classification for the video path.
In some embodiments, the method comprises: identifying a set of preferred video paths in a video, the identifying comprising: obtaining a preference genre classification set; and determining a set of video paths from among the plurality of video paths each having a genre classification included in the set of preferred genre classifications.
In some embodiments, the method comprises: generating classification data describing content in the video, wherein the classification data includes a genre classification describing the content in each of a plurality of video paths; and providing the video and the genre classification for presentation on the interface.
In some implementations, the displayed video segments of the video path include at least one interactive video segment; and the method comprises: providing a prompt at the end of the display of the at least one interactive video segment, the prompt having a recommendation for the viewer to select one of: (1) a video segment directly linked to at least one interactive video segment; and (2) a video clip associated with the video path.
In some implementations, generating classification data that describes content in each video path includes: for each video segment of the video path, generating a score distribution using a genre classifier, wherein each score in the score distribution indicates a likelihood that the video segment is classified to a particular genre; aggregating score distributions of all video segments of the video path; determining, based on the aggregated score distribution, a score higher than other scores in the aggregated score distribution; and identifying a genre associated with the determined score.
In some embodiments, the method comprises: receiving a query from a viewer requesting videos in a video library that are classified as a particular genre; and in response to the query, identifying a set of videos in the video library that are classified as a particular genre, wherein the set of videos includes a first video that includes a plurality of video paths, and at least one video path in the first video has a genre classification that matches the particular genre.
Particular embodiments of the subject matter described in this specification can be implemented to realize one or more of the following advantages. The innovations described in this specification improve ease of use and user experience through the provision of interactive video for a content platform. Conventionally, interactive videos do not include any classification data that describes the content of the various video paths in the interactive video. Absent such classification data, the content platform is unable to include interactive videos with other videos that are categorized into different categories based on the content classification in those videos. From the viewer's perspective, the lack of classification data for different video paths means that selection of an appropriate interactive video by a computing device as an option to provide to a user under a particular scene may not be the best choice. Additionally or alternatively, the lack of classification data may mean that the viewer may decide not to view the interactive video (if presented as an option), or may view the interactive video but make a decision during its presentation, which may result in the viewer consuming a class of video paths (e.g., video paths of a particular genre) that does not suit the viewer (e.g., based on the viewer's specified interests and viewing preferences).
In contrast, the innovations described in this specification are able to automatically classify content in different video paths in interactive video-without any manual classification (which can take a significant amount of time). Based on these classifications, the innovations described in this specification enable viewers to easily access content in the video paths by presenting interactive videos along with categories of videos having the same or similar classifications as those of the video paths in the videos. Furthermore, when a viewer chooses to view an interactive video, the innovations described in this specification simplify and improve the viewing experience of the interactive video, for example, by presenting only video segments in the video path that may be of interest to the viewer. The innovations described in this specification can also simplify and improve the viewing experience by, for example, guiding the viewer through a series of decisions in an interactive video to ensure that the viewer only views video segments associated with video paths that are appropriate for the user (e.g., viewing video paths that are consistent with the viewer's interests based on the viewer's viewing history and viewing preferences, or viewing video paths that are appropriate for the task the viewer is engaged in, such as training for a particular vehicle scene).
In some embodiments, the innovations described in this specification can also achieve operational efficiencies (i.e., save significant time and computational resources) by identifying and classifying only those video paths in the interactive video that are appropriate/suitable for the viewer (based on the viewer's interests or the tasks the viewer is to undertake, such as the case of the training scenario described above). Some interactive videos can include a large number of video paths. For such interactive videos, a significant amount of time and computational resources may be required to identify and classify each different video path included in the interactive video. However, the innovations described in this specification can ignore those video paths that may not be of interest to the viewer, based on, for example, the viewer's preferences and viewing history, but instead spend time and computing resources identifying and classifying video paths that may actually be of interest to the viewer and/or are relevant to the task being undertaken by the viewer.
The details of one or more embodiments of the subject matter described in this specification are set forth in the accompanying drawings and the description below. Other features, aspects, and advantages of the subject matter will become apparent from the description, the drawings, and the claims.
Drawings
Fig. 1 is a block diagram illustrating an example interactive video.
Fig. 2 is a block diagram of an example system for sorting and presenting storylines included in interactive video.
Fig. 3 is a flow diagram of an example process for sorting and presenting storylines included in interactive video.
FIG. 4 is a block diagram of an example computer system.
Like reference numbers and designations in the various drawings indicate like elements.
Detailed Description
This specification relates generally to identifying and sorting various video paths in an interactive video based on their content and displaying the video paths to a viewer on a user device.
As described below and detailed throughout the specification, the interactive video engine is capable of categorizing various storylines included in the interactive video. In this specification, a video path is also called a storyline.
The interactive video engine first identifies all or a subset of storylines in the interactive video. For each identified storyline, the interactive video engine uses a content classifier (such as a genre classifier, which can be implemented as a learning model, e.g., a supervised or unsupervised machine learning model) to generate the most likely or first three (or another suitable number) content classifications (e.g., genre classifications) in that storyline. The interactive video engine then stores the interactive video along with the one or more video categories stored in the memory. In particular, the interactive video engine stores interactive video in each video category stored in memory that is associated with the same or similar classification as one or more generated classifications of storylines in the interactive video.
When a viewer selects an interactive video from a particular category for presentation on a user device (e.g., browser, mobile device, television, etc.), the interactive video engine can display only those video segments of the storyline of the same or similar category as the category associated with the particular category. Alternatively, when a viewer selects an interactive video from a particular category for presentation on a user device, the interactive video engine can play video clips in the interactive video, but include prompts with recommendations that guide the viewer to make only those decisions that result in selecting a video clip in a particular storyline.
In some implementations, a viewer can search for videos in a particular category (e.g., in a genre such as comedy). In response to such a query, the interactive video engine presented to the viewer provides a list of videos for the category that includes non-interactive videos belonging to the category and interactive videos having video paths belonging to the category. The video listings can be ordered/sequenced in different ways, e.g., by relevance of the video to the search term in the query, by video rating (by reviewer and/or other viewer), by video publication date, etc.
These and additional features are described in detail below with reference to fig. 1-4.
Further to the extent of this document, the user may be provided with controls that allow the user to select whether and when the systems, programs, or features described herein may initiate gathering information (e.g., information about the user's social network, social actions or activities, profession, user preferences, or the user's current location) and whether to send content or communications from the server to the user. In addition, certain data may be processed in one or more ways before it is stored or used in order to delete personally identifiable information. For example, the user identity may be processed such that no personally identifiable information can be determined for the user, or in the case of location information, the user's geographic location may be generalized (such as at the city, zip code, or state level) such that no particular location of the user can be determined. Thus, the user may have control over which information is collected by the user, how the information is used, and which information is provided to the user.
Fig. 1 is a block diagram illustrating an example interactive video 100. The interactive video 100 includes a plurality of video segments: a starting video segment 102, a plurality of intermediate video segments (104-a to 104-C, 106-a to 106-E), and a plurality of final video segments (108-a to 108-E). The starting video segment 102 is the first video segment of the interactive video presented to the user when the interactive video is launched. Each of the final video clips (108-a to 108-E) represents the last video clip in any particular storyline in the interactive video 100. The intermediate video segments (104-A through 104-C, 106-A through 106-E) include all video segments between the starting video segment 102 and the final video segments 108-A through 108-E.
Each video segment of the interactive video 100 is directly connected to at least one other video segment. As shown in fig. 1, some video segments are directly connected to only one other video segment. For example, the intermediate segment 106-A is directly connected only to the intermediate segment 106-E, and the start video segment 102 is directly connected only to the intermediate video segment 104-A. In such instances where a video clip is directly connected to only one other video clip, the interactive video 100 seamlessly plays two video clips one after the other without any pause.
The intermediate video segments 104-a to 104-C (also referred to as interactive video segments) of the interactive video 100 are directly connected to more than one video segment. At the end of the display of each such interactive video segment, the interactive video 100 typically pauses and presents a set of decisions to the viewer. This is illustrated using interactive video clip 104-a shown in fig. 1. At the end of the interactive video segment 104-a, the video frame 110 shows the person standing above the building (110), and under the video frame 110, the video presents three decisions to the viewer: (1) "Jump" 112; (2) "Turn Around" 114; (3) "Call a Friend" 116. Each of these decisions is linked to an intermediate video segment 104-B, 106-a, and 106-B, respectively. The viewer can only select one of these decisions. When the viewer selects one of these three decisions (e.g., using pointing device 118 or another suitable interface interaction technique, such as remote control, stylus, finger touch), interactive video 100 plays a video segment linked to the selected decision. As shown in fig. 1, the viewer selects "Turn Around" 114, which causes the interactive video 100 to resume the interactive video by playing the intermediate video segment 106-a (which links to the decision of "Turn Around" 114).
Each path from the starting video segment 102 to one of the final video segments (108-a to 108-E) forms a story line. Fig. 1 depicts five different storylines: (1) a first storyline consisting of video segments 102, 104-A, 104-B, 106-C, and 108-A; (2) a second storyline consisting of video segments 102, 104-A, 104-B, 106-D, and 108-B; (3) a third storyline consisting of video segments 102, 104-A, 106-E, and 108-C; (4) a fourth storyline consisting of video segments 102, 104-A, 106-B, 104-C, and 108-D; (5) a fifth storyline consisting of video segments 102, 104-A, 106-B, 104-C, and 108-E.
Each storyline is composed of a different subset of video segments selected from among a plurality of video segments of the interactive video. Each such subset includes a starting video segment 102, a set of intermediate video segments, and a final video segment.
Although fig. 1 shows each interactive video clip directly connected to two or three other video clips, each interactive video clip can also be directly connected to any number (more than one) of other video clips.
Fig. 2 is a block diagram of an example system 200 for sorting and presenting storylines included in interactive video.
The system 200 includes an interactive video engine 204, the interactive video engine 204 receiving interactive video from a video library 202. The video library 202 can be part of a content platform and can include one or more databases (or other suitable data storage structures) stored in one or more non-transitory data storage media (e.g., hard disk drives, flash memory, etc.). Interactive video engine 204 uses its subcomponents (interactive video identifier 206, classification model 208, and presentation manager 210) to identify a set of video storylines included in the interactive video and classify those storylines based on their content. When a viewer requests to view an interactive video, the interactive video engine 204 can play a video clip in one of the categorized storylines that may be of interest to the viewer, for example, based on the viewer's selections, preferences (e.g., viewing preferences, vehicle/machine control simulations), and/or viewing history). The operation of system 200 and its components is further described below with reference to fig. 3.
Fig. 3 is a flow diagram of an example process 300 for sorting and presenting storylines included in interactive video. For purposes of illustration, the operation of process 300 is described below using system 200 and interactive video 100. The operations of process 300 can be performed by any suitable device or system, such as any suitable data processing apparatus. The operations of process 300 can also be implemented as instructions stored on a non-transitory computer-readable medium. Execution of the instructions causes the one or more data processing apparatus to perform the operations of process 300.
The interactive video engine 204 obtains (at 302) interactive videos from the video library 202. In some implementations, the video library 202 includes a library or database of different videos categorized based on a classification (e.g., genre classification) of content in the videos. Interactive videos are generally not categorized by any particular genre, but rather are categorized along with other interactive videos. The video library 202 can periodically send videos that are tagged or identified as interactive videos (e.g., in metadata of the interactive videos) to the interactive video engine 204. Alternatively, the interactive video engine 204 can query the video library 202 for videos tagged or identified as interactive videos and, in response, receive interactive videos from the video library 202.
Interactive video identifier 206 identifies different storylines in the interactive video (at 304). Interactive video identifier 206 identifies different storylines in the interactive video by first identifying different interactive video clips within the interactive video. In some implementations, the interactive video identifier 206 can search for and identify video segments identified using "interactive segments" or other similar tags. In some implementations, the metadata of the interactive video (or other portions of the video, such as its presentation layer) can disclose various decision points in the interactive video that request the user to interact with the video. In such implementations, the interactive video identifier 206 can use the decision points to identify the interactive video segments associated with the decisions.
The interactive video identifier 206 can then use the identified decision points in the interactive video segment to identify each possible video segment path from the starting video segment 102 to one of the final video segments 108-a through 108-E in the interactive video. Each of these possible paths represents a different storyline in the interactive video.
In some instances, interactive video can have a large number of storylines. In such instances, identifying each possible storyline can consume a significant amount of time and computing resources. To reduce the time and resources required to identify storylines, interactive video identifier 206 can be configured to generate only a subset of storylines that may be of interest to a particular viewer (and conversely, to ignore those storylines that may not be of interest to the user and/or may not be relevant), as further described below.
In some implementations, interactive video identifier 206 identifies a subset of storylines (from among the different possible storylines included in the video) by using a learning model. When such a model receives a set of decisions as input in an interactive video segment, it determines the decisions that a viewer may make based on the viewer's viewing preferences and/or the viewing preferences of other users who are similar to the viewer's viewing preferences. Such models can be implemented as supervised or unsupervised machine learning models. In some implementations, the model can be a supervised machine learning model that is trained using multiple decision sets and selected decisions of viewers (and/or other viewers with similar viewing preferences). Thus, using such a model, interactive video identifier 206 is able to identify decisions that a viewer is likely to make when presenting an interactive video clip to the viewer. Using information about the decisions that the viewer is likely to make, interactive video identifier 206 then identifies only those paths (or storylines) that are associated with the decisions that are likely to be selected.
In some implementations, the classifier can be a genre classifier (which can be implemented as a genre classification neural network) that is trained using a training video set and its known genre classifications and determines the genre classification for each video clip in the interactive storyline. Thus, for each video clip of the input storyline, the genre classifier outputs a score distribution across different possible genres, e.g. a score for each possible genre (ranging from 0 to 1, which specifies a likelihood that a particular video clip can be classified as a particular genre). For example, the genre classifier may determine that a particular video segment has the following score distribution: [ comedy: 0; 0.4 of drama; 0.93 for terrorism; action 0.5 ]. Alternatively, the genre classifier may, for example, determine that a particular video segment has a score distribution [ first vehicle control scene: 0; second vehicle control scenario 0.4; third vehicle control scenario 0.93; fourth vehicle control scenario 0.5 ].
Depending on the length of each video segment (which may vary from segment to segment), the content of the video segment may not be long enough to provide the genre classifier with sufficient context to provide a meaningful distribution of genre classification scores. Thus, as an alternative to scoring each video segment, the genre classifier can score a sequence of video segments that provide more context for the content within the sequence of video segments. The genre classifier can identify the sequence of video clips in the story line in different ways. As an example, the genre classifier can identify video clips between different interactive video clips, video clips between the starting clip 102 and the first interactive video clip, and video clips between the last interactive video clip of the story line and the last video clip of the story line. The genre classifier then scores each sequence of video segments in the story line in the same manner as described in the preceding paragraph with reference to a single video segment.
Using the score distribution for each video clip in the story line (or for each sequence of video clips in the story line), the combiner model determines the most likely genre (or the first two or three most likely genres) in the story line. In some implementations, the combiner model aggregates (e.g., sums) the score distributions for each video clip (or each sequence of video clips) to determine the overall score for each genre in the storyline. Based on these determined total scores for each genre, the combined model identifies the genre with the highest score as the genre classification of the story line. Alternatively, the combiner model identifies the first three genres (or any other suitable number of genres) in the overall score distribution for which the overall score is highest as the genre classification of the story line.
Alternatively, instead of scoring each video clip in the story line or multiple sequences of video clips in the story line, the entire sequence of video clips that make up the story line may be input to a genre classifier, which then outputs a score distribution for all of the different genres in the story line. From this score distribution, the combiner model identifies (in the same manner as described above) the highest scoring genre or the first three (or another suitable number) highest scoring genres as the genre classification of the story line.
The presentation manager 210 categorizes (at 310) the interactive video along with other videos in the video library 202 having the same or similar category as determined for the storyline identified in operation 308. For example, if the classification model determines that the storylines identified in the interactive video are classified as comedy and drama, for example, or as related to a particular vehicle control (training) scene, the presentation manager 210 can then include the interactive video along with other videos that are included or classified as part of the same genre in the video store. For example, the presentation manager 210 can then include the interactive video along with other videos included or categorized as comedy and drama genre parts in the video library 202.
In some implementations, classification model 208 may not identify preferred storylines in the interactive video (as described with reference to operation 308). In such implementations, the presentation manager 210 categorizes the interactive video along with other videos categorized by the same genres as those identified in each storyline in the interactive video (identified in operation 306). Each video category in the video library 202 is associated with a particular classification.
The presentation manager 210 then displays the identified video segments on the user device (e.g., browser, mobile device, television, etc.). This can be done in any of the following ways. In some implementations, presentation manager 210 can seamlessly display the video clips in the storyline (e.g., without pausing the video to display any interactive decisions). For example, the presentation manager 210 can automatically select all decisions, i.e., no interaction by any viewer, which would result in the video clips in the storyline playing in sequence without any pause (or requiring any viewer interaction).
In some implementations, the presentation manager 210 can allow the viewer to interact with the video to make decisions, but in such implementations, the presentation manager 210 provides prompts with recommendations as to which decisions to select to cause the user to continue viewing the video clip associated with the preferred storyline. For example, by using the interactive video segment 104-A to illustrate, the presentation manager 210 can highlight the decision that the user must select to continue with the preferred comedy genre (e.g., mark the decision with a particular color, flash a button associated with the decision, etc.). Alternatively or additionally, the presentation manager 210 can insert recommended text on the interface that prompts the viewer to make a particular decision, such as "select this decision if it wants to continue with the particular training scenario" or "select this decision if it wants to continue watching the comedy," for example. The presentation manager 210 can also include text for other decisions about the interactive video clip, those other decisions indicating the types of genres that the user may encounter if selected, such as "select this decision if you want to view a horror story" or "select this decision if you want to take a task of a person in training scene".
In some implementations, the classification model 208 may not categorize the interactive video (as described with reference to operation 310) into any genre-specific categories of videos stored in the video library 202. In such implementations, presentation manager 210 can maintain the interactive videos within interactive video categories (which include other interactive videos) and can include text describing genre classifications of preferred story lines in the interactive videos. For example, if the classification model classifies preferred storylines in interactive video (e.g., into "comedy," "horror," and "drama," or into "training scene 1," "training scene 2," "training scene 3," "and" training scene 4 "), presentation manager 210 can use these classifications to label or identify interactive video having these classifications. The viewer can use this classification information of the interactive video to decide whether or not to view the interactive video. Even if videos are categorized together with other videos included in different genres, the categories can be presented to the viewer.
Further, in embodiments where interactive videos are categorized along with other interactive videos in this manner, when the viewer selects to view an interactive video, the presentation manager 110 displays the interactive video along with a text prompt with recommendations (as described above) along with the decision. These cues describe the types of storylines that may result if the viewer selects any particular decision.
In some implementations, the viewer is also able to search for and retrieve videos (including interactive videos) stored in the video library 202. In such implementations, the front-end interface of the video library 202 (or another service that allows searching for videos stored in the video library 202, such as a search engine) can receive a search query from a viewer that can specify, for example, a content category (e.g., a genre category, such as comedy) and/or additional search terms that specify additional aspects (e.g., animals, popular actors, etc.) that the viewer wishes to see. The search query is communicated to the presentation manager 210 (or alternatively may be operated and processed by another service, such as a search engine), which the presentation manager 210 identifies a list of videos (from the video library 202) in response to the viewer's query.
In some implementations, the presentation manager 210 (or alternatively another service such as a search engine) identifies the videos in response to the search query using a content classification of the videos, such as a genre classification (which is included with and/or generated for interactive videos as described with reference to fig. 2 and 3) and other data stored in the video library 202 about the videos (e.g., actor names, brief descriptions about the videos, release dates, etc.). For example, if the viewer's query requests "Comedy inclusion operator John Smith (including the Comedy of the actor John Smith)", the presentation manager 210 (or another service such as a search engine) identifies videos in the video library that have been classified as "Comedy" and that include the name "John Smith".
The presentation manager 210 (or another service such as a search engine) identifies non-interactive videos that satisfy the query parameters and interactive videos that satisfy the parameters. When identifying an interactive video that is responsive to a search query, the presentation manager 210 (or another service such as a search engine) determines whether query parameters specifying a content category (e.g., a genre category, such as comedy) match a category generated for any storylines included in the interactive video (as described above with reference to fig. 2 and 3). If so, the presentation manager 210 (or another service such as a search engine) identifies the interactive video as being responsive to the query.
Before presenting the list of identified videos to the viewer, presentation manager 210 (or another service such as a search engine) can sort the identified videos in different ways. In some implementations, the video list can be sorted alphabetically. Alternatively or additionally, the list of videos can be sorted based on the release date of the videos. For example, the release date can be used to sort the video list in the order of the latest to the earliest. Alternatively or additionally, the video list can be ranked based on relevance to the query. For example, if the query requests "comedy videos of John Smith (comedy videos of John Smith)", the video list may rate comedy movies including John Smith (John Smith) higher than comedy videos including John Smith (John Smith). Alternatively or additionally, the list of videos can be ordered based on ratings assigned to different videos on the list (e.g., ratings of reviewers and/or ratings of other viewers). For example, the video list can be sorted in order of highest rating to lowest rating using the ratings of reviewers. It should be appreciated that the videos can be ordered in any number of other ways, such as in a total rating generated by the videos, etc.
FIG. 4 is a block diagram of an example computer system 400 that may be used to perform the operations described above. System 400 includes processor 410, memory 420, storage 430, and input/output device 440. Each of the components 410, 420, 430, and 440 may be interconnected, for example, using a system bus 450. The processor 410 is capable of processing instructions for execution within the system 400. In one implementation, the processor 410 is a single-threaded processor. In another implementation, the processor 410 is a multi-threaded processor. The processor 410 is capable of processing instructions stored in the memory 420 or on the storage device 430.
The storage device 430 is capable of providing mass storage for the system 400. In one implementation, the storage device 430 is a computer-readable medium. In various different implementations, the storage device 430 may include, for example, a hard disk device, an optical disk device, a storage device shared by multiple computing devices (e.g., cloud storage devices) over a network, or some other mass storage device.
The input/output device 440 provides input/output operations for the system 400. In one embodiment, the input/output devices 440 may include one or more network interface devices, such as an Ethernet card, a serial communication device such as an RS-232 port, and/or a wireless interface device such as an 802.11 card. In another embodiment, the input/output devices may include driver devices configured to receive input data and to send output data to other input/output devices, such as a keyboard, printer, and display device 460. However, other implementations may also be used, such as being a mobile computing device, a mobile communications device, a set-top box television client device, and so forth.
Although an example processing system has been described in fig. 4, implementations of the subject matter and the functional operations described in this specification can be implemented in other types of digital electronic circuitry, or in computer software, firmware, or hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them.
Embodiments of the subject matter and the operations described in this specification can be implemented in digital electronic circuitry, or in computer software, firmware, or hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them. Embodiments of the subject matter described in this specification can be implemented as one or more computer programs, i.e., one or more modules of computer program instructions, encoded on a computer storage medium (or multiple media) for execution by, or to control the operation of, data processing apparatus. Alternatively or in addition, the program instructions may be encoded on an artificially generated propagated signal, e.g., a machine-generated electrical, optical, or electromagnetic signal, that is generated to encode information for transmission to suitable receiver apparatus for execution by data processing apparatus. The computer storage medium may be or be included in a computer-readable storage device, a computer-readable storage substrate, a random or serial access memory array or device, or a combination of one or more of them. Further, although the computer storage medium is not a propagated signal, the computer storage medium can be a source or destination of computer program instructions encoded in an artificially generated propagated signal. The computer storage medium may also be or be included in one or more separate physical components or media (e.g., multiple CDs, disks, or other storage devices).
The operations described in this specification may be implemented as operations performed by data processing apparatus on data stored on one or more computer-readable storage devices or received from other sources.
The term "data processing apparatus" encompasses all kinds of apparatus, devices, and machines for processing data, including by way of example a programmable processor, a computer, a system on a chip, or multiple programmable processors, computers, systems on a chip, or a combination of the foregoing. An apparatus may comprise special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit). The apparatus can include, in addition to hardware, code that creates an execution environment for the computer program, e.g., code that constitutes processor firmware, a protocol stack, a database management system, an operating system, a cross-platform runtime environment, a virtual machine, or a combination of one or more of them. The apparatus and execution environment may implement a variety of different computing model infrastructures, such as web services, distributed computing, and grid computing infrastructures.
A computer program (also known as a program, software application, script, or code) can be written in any form of programming language, including compiled or interpreted languages, declarative or procedural languages, and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, object, or other unit suitable for use in a computing environment. A computer program may, but need not, correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data (e.g., one or more scripts stored in a markup language document), in a single file dedicated to the program in question, or in multiple coordinated files (e.g., files that store one or more modules, sub-programs, or portions of code). A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network.
The processes and logic flows described in this specification can be performed by one or more programmable processors executing one or more computer programs to perform actions by operating on input data and generating output. The processes and logic flows can also be performed by, and apparatus can also be implemented as, special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit).
Processors suitable for the execution of a computer program include, by way of example, both general and special purpose microprocessors. Generally, a processor will receive instructions and data from a read-only memory or a random access memory or both. The essential elements of a computer are a processor for performing actions in accordance with the instructions and one or more memory devices for storing instructions and data. Generally, a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks. However, a computer need not have such devices. Further, the computer may be embedded in another device, e.g., a mobile telephone, a Personal Digital Assistant (PDA), a mobile audio or video player, a game console, a Global Positioning System (GPS) receiver, or a portable storage device (e.g., a Universal Serial Bus (USB) flash drive), to name a few. Devices suitable for storing computer program instructions and data include all forms of non-volatile memory, media and memory devices, including by way of example: semiconductor memory devices, such as EPROM, EEPROM, and flash memory devices; magnetic disks, such as internal hard disks or removable disks; magneto-optical disks; and CD ROM and DVD-ROM disks. The processor and the memory can be supplemented by, or incorporated in, special purpose logic circuitry.
To provide for interaction with a user, embodiments of the subject matter described in this specification can be implemented on a computer having a display device, e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor, for displaying information to the user and a keyboard and a pointing device, e.g., a mouse or a trackball, by which the user can provide input to the computer. Other kinds of devices may also be used to provide for interaction with a user; for example, feedback provided to the user can be any form of sensory feedback, such as visual feedback, auditory feedback, or tactile feedback; and input from the user can be received in any form, including acoustic, speech, or tactile input. Further, the computer may interact with the user by sending documents to and receiving documents from the device used by the user; for example, by sending a web page to a web browser on the user's client device in response to a request received from the web browser.
Embodiments of the subject matter described in this specification can be implemented in a computing system that includes a back-end component (e.g., as a data server), or that includes a middleware component (e.g., an application server), or that includes a front-end component (e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the subject matter described in this specification), or any combination of one or more such back-end, middleware, or front-end components. The components of the system can be interconnected by any form or medium of digital data communication, e.g., a communication network. Examples of communication networks include a local area network ("LAN") and a wide area network ("WAN"), an internetwork (e.g., the internet), and a peer-to-peer network (e.g., an ad hoc peer-to-peer network).
The computing system may include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other. In some embodiments, the server sends data (e.g., an HTML page) to the client device (e.g., for purposes of displaying data to a user interacting with the client device and receiving user input from the user interacting with the client device). Data generated at the client device (e.g., a result of the user interaction) may be received at the server from the client device.
While this specification contains many specific implementation details, these should not be construed as limitations on the scope of any invention or of what may be claimed, but rather as descriptions of features specific to particular embodiments of particular inventions. Certain features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely, various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable subcombination. Furthermore, although features may be described above as acting in certain combinations and even initially claimed as such, one or more features from a claimed combination can in some cases be excised from the combination, and the claimed combination may be directed to a subcombination or variation of a subcombination.
Similarly, while operations are depicted in the drawings in a particular order, this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order, or that all illustrated operations be performed, to achieve desirable results. In some cases, multitasking and parallel processing may be advantageous. Moreover, the separation of various system components in the embodiments described above should not be understood as requiring such separation in all embodiments, and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.
Thus, particular embodiments of the subject matter have been described. Other embodiments are within the scope of the following claims. In some cases, the actions recited in the claims can be performed in a different order and still achieve desirable results. Moreover, the processes depicted in the accompanying figures do not necessarily require the particular order shown, or sequential order, to achieve desirable results. In some embodiments, multitasking and parallel processing may be advantageous.
Claims (21)
1. A computer-implemented method, comprising:
obtaining a video comprising a plurality of video segments from a video library, wherein:
each video segment is directly linked to at least one other video segment;
the plurality of video segments comprises a starting video segment, an intermediate video segment, and a final video segment; and is
The intermediate video segments comprise a set of interactive video segments, wherein each interactive video segment is directly linked to at least two other video segments, only one of which is selectable by a viewer at the end of the display of the interactive video segment;
identifying a plurality of video paths in the video, wherein each video path comprises a different subset of video segments from among the plurality of video segments, and each subset of video segments comprises the starting video segment, a set of intermediate segments, and one final video segment;
for each of the plurality of video paths, generating classification data describing content in the video path;
for each video path of the plurality of video paths, storing videos in a category of the video library along with other videos in the category of the video library based on the classification data for the video path, wherein the video library includes a plurality of categories each associated with a different classification; and
upon selection of the video from a particular category of the video library and for presentation on a user device, displaying a video clip having a video path of the same classification as the classification associated with the particular category.
2. The computer-implemented method of claim 1, wherein the classification data describing content in each video path specifies a genre classification for the video path.
3. The computer-implemented method of claim 2, further comprising: identifying a set of preferred video paths in the video, the identifying comprising:
obtaining a preference genre classification set; and
determining a set of video paths from among the plurality of video paths each having a genre classification included in the set of preferred genre classifications.
4. The computer-implemented method of claim 1, further comprising:
generating classification data describing content in the video, wherein the classification data includes a genre classification describing content in each of the plurality of video paths; and
providing the video and the genre classification for presentation on the interface.
5. The computer-implemented method of claim 1:
wherein the displayed video segments of the video path comprise at least one interactive video segment; and is
The computer-implemented method of claim 1 further comprising: providing a prompt at the end of the display of the at least one interactive video segment, the prompt having a recommendation for the viewer to select one of: (1) a video segment directly linked to the at least one interactive video segment; and (2) a video clip associated with the video path.
6. The computer-implemented method of claim 2, wherein generating classification data describing content in each video path comprises:
for each video segment of the video path, generating a score distribution using a genre classifier, wherein each score in the score distribution indicates a likelihood that the video segment is classified to a particular genre;
aggregating the score distributions for all video segments of the video path;
determining, based on the aggregated score distribution, a score higher than other scores in the aggregated score distribution; and
a genre associated with the determined score is identified.
7. A system, comprising:
one or more memory devices to store instructions; and
one or more data processing apparatus configured to interact with the one or more memory devices and, when the instructions are executed, perform operations comprising:
obtaining a video comprising a plurality of video segments from a video library, wherein:
each video segment is directly linked to at least one other video segment;
the plurality of video segments comprises a starting video segment, an intermediate video segment, and a final video segment; and is
The intermediate video segments comprise a set of interactive video segments, wherein each interactive video segment is directly linked to at least two other video segments, only one of which is selectable by a viewer at the end of the display of the interactive video segment;
identifying a plurality of video paths in the video, wherein each video path comprises a different subset of video segments from among the plurality of video segments, and each subset of video segments comprises the starting video segment, a set of intermediate segments, and one final video segment;
for each of the plurality of video paths, generating classification data describing content in the video path;
for each video path of the plurality of video paths, storing videos in a category of the video library along with other videos in the category of the video library based on the classification data for the video path, wherein the video library includes a plurality of categories each associated with a different classification; and
upon selection of the video from a particular category of the video library and for presentation on a user device, displaying a video clip having a video path of the same classification as the classification associated with the particular category.
8. The system of claim 7, wherein the classification data describing the content in each video path specifies a genre classification for the video path.
9. The system of claim 8, wherein the one or more data processing apparatus are configured to perform operations further comprising:
identifying a set of preferred video paths in the video, the identifying comprising:
obtaining a preference genre classification set; and
determining a set of video paths from among the plurality of video paths each having a genre classification included in the set of preferred genre classifications.
10. The system of claim 7, wherein the one or more data processing apparatus are configured to perform operations further comprising:
generating classification data describing content in the video, wherein the classification data includes a genre classification describing content in each of the plurality of video paths; and
providing the video and the genre classification for presentation on the interface.
11. The system of claim 7:
wherein the displayed video segments of the video path comprise at least one interactive video segment; and is
Wherein the one or more data processing apparatus are configured to perform operations further comprising: providing a prompt at the end of the display of the at least one interactive video segment, the prompt having a recommendation for the viewer to select one of: (1) a video segment directly linked to the at least one interactive video segment; and (2) a video clip associated with the video path.
12. The system of claim 8, wherein generating classification data describing the content in each video path comprises:
for each video segment of the video path, generating a score distribution using a genre classifier, wherein each score in the score distribution indicates a likelihood that the video segment is classified to a particular genre;
aggregating the score distributions for all video segments of the video path;
determining, based on the aggregated score distribution, a score higher than other scores in the aggregated score distribution; and
a genre associated with the determined score is identified.
13. A non-transitory computer-readable medium storing instructions that, when executed by one or more data processing apparatus, cause the one or more data processing apparatus to perform operations comprising:
obtaining a video comprising a plurality of video segments from a video library, wherein:
each video segment is directly linked to at least one other video segment;
the plurality of video segments comprises a starting video segment, an intermediate video segment, and a final video segment; and is
The intermediate video segments comprise a set of interactive video segments, wherein each interactive video segment is directly linked to at least two other video segments, only one of which is selectable by a viewer at the end of the display of the interactive video segment;
identifying a plurality of video paths in the video, wherein each video path comprises a different subset of video segments from among the plurality of video segments, and each subset of video segments comprises the starting video segment, the set of intermediate segments, and one final video segment;
for each of the plurality of video paths, generating classification data describing content in the video path;
for each video path of the plurality of video paths, storing videos in a category of the video library along with other videos in the category of the video library based on the classification data for the video path, wherein the video library includes a plurality of categories each associated with a different classification; and
upon selection of the video from a particular category of the video library and for presentation on a user device, displaying a video clip having a video path of the same classification as the classification associated with the particular category.
14. The non-transitory computer-readable medium of claim 13, wherein the classification data describing content in each video path specifies a genre classification for the video path.
15. The non-transitory computer-readable medium of claim 14, further comprising: identifying a set of preferred video paths in the video, the identifying comprising:
obtaining a preference genre classification set; and
determining a set of video paths from among the plurality of video paths each having a genre classification included in the set of preferred genre classifications.
16. The non-transitory computer-readable medium of claim 13, further comprising:
generating classification data describing content in the video, wherein the classification data includes a genre classification describing content in each of the plurality of video paths; and
providing the video and the genre classification for presentation on the interface.
17. The non-transitory computer-readable medium of claim 13:
wherein the displayed video segments of the video path comprise at least one interactive video segment; and is
The non-transitory computer readable medium of claim 13 further comprising: providing a prompt at the end of the display of the at least one interactive video segment, the prompt having a recommendation for the viewer to select one of: (1) a video segment directly linked to the at least one interactive video segment; and (2) a video clip associated with the video path.
18. The non-transitory computer-readable medium of claim 14, wherein generating classification data describing the content in each video path comprises:
for each video segment of the video path, generating a score distribution using a genre classifier, wherein each score in the score distribution indicates a likelihood that the video segment is classified to a particular genre;
aggregating the score distributions for all video segments of the video path;
determining, based on the aggregated score distribution, a score higher than other scores in the aggregated score distribution; and
a genre associated with the determined score is identified.
19. The computer-implemented method of claim 2, further comprising:
receiving a query from a viewer, the query requesting videos in the video library that are classified as a particular genre; and
in response to the query, identifying a set of videos in the video library that are classified as the particular genre, wherein the set of videos includes a first video that includes a plurality of video paths, and at least one video path in the first video has a genre classification that matches the particular genre.
20. The system of claim 8, wherein the one or more data processing apparatus are configured to perform operations further comprising:
receiving a query from a viewer, the query requesting videos in the video library that are classified as a particular genre; and
in response to the query, identifying a set of videos in the video library that are classified as the particular genre, wherein the set of videos includes a first video that includes a plurality of video paths, and at least one video path in the first video has a genre classification that matches the particular genre.
21. The non-transitory computer-readable medium of claim 14, further comprising:
receiving a query from a viewer, the query requesting videos in the video library that are classified as a particular genre; and
in response to the query, identifying a set of videos in the video library that are classified as the particular genre, wherein the set of videos includes a first video that includes a plurality of video paths, and at least one video path in the first video has a genre classification that matches the particular genre.
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
PCT/UA2019/000095 WO2021015705A1 (en) | 2019-07-23 | 2019-07-23 | Method and system for the classification and categorization of video pathways in interactive videos |
Publications (1)
Publication Number | Publication Date |
---|---|
CN112840667A true CN112840667A (en) | 2021-05-25 |
Family
ID=68542729
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201980063003.0A Pending CN112840667A (en) | 2019-07-23 | 2019-07-23 | Method and system for classification and categorization of video paths in interactive video |
Country Status (6)
Country | Link |
---|---|
US (1) | US11490172B2 (en) |
EP (1) | EP3831086A1 (en) |
JP (1) | JP7171903B2 (en) |
KR (1) | KR102465853B1 (en) |
CN (1) | CN112840667A (en) |
WO (1) | WO2021015705A1 (en) |
Citations (8)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20140052696A1 (en) * | 2012-08-20 | 2014-02-20 | United Video Properties, Inc. | Systems and methods for visual categorization of multimedia data |
US9098807B1 (en) * | 2011-08-29 | 2015-08-04 | Google Inc. | Video content claiming classifier |
WO2016115154A1 (en) * | 2015-01-14 | 2016-07-21 | MindsightMedia, Inc. | Data mining, influencing viewer selections, and user interfaces |
CN107005747A (en) * | 2014-07-31 | 2017-08-01 | 麦恩得赛特米迪尔公司 | Method, equipment and the product of delivering media content are presented via at user option narration |
US20180052758A1 (en) * | 2016-08-22 | 2018-02-22 | Oath Inc. | Systems and methods for determining user engagement with electronic devices |
US10147461B1 (en) * | 2017-12-29 | 2018-12-04 | Rovi Guides, Inc. | Systems and methods for alerting users to differences between different media versions of a story |
US20190098371A1 (en) * | 2017-09-27 | 2019-03-28 | Podop, Inc. | Media narrative presentation systems and methods with interactive and autonomous content selection |
US10334328B1 (en) * | 2017-01-20 | 2019-06-25 | Render Inc. | Automatic video generation using auto-adaptive video story models |
Family Cites Families (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP3850671B2 (en) * | 2001-03-05 | 2006-11-29 | シャープ株式会社 | CONTENT DISTRIBUTION SYSTEM, SERVER USED FOR THE SAME, CLIENT TERMINAL USED FOR THE SAME, CONTENT DISTRIBUTION METHOD, AND RECORDING MEDIUM CONTAINING PROGRAM FOR CAUSING COMPUTER TO EXECUTE THE METHOD |
JP2002330419A (en) * | 2001-04-27 | 2002-11-15 | Matsushita Electric Ind Co Ltd | Multi-story viewing device and multi-story viewing method |
US20060288362A1 (en) * | 2005-06-16 | 2006-12-21 | Pulton Theodore R Jr | Technique for providing advertisements over a communications network delivering interactive narratives |
US9607656B1 (en) * | 2015-07-27 | 2017-03-28 | Amazon Technologies, Inc. | Dynamic multiple video ratings |
US10659505B2 (en) * | 2016-07-09 | 2020-05-19 | N. Dilip Venkatraman | Method and system for navigation between segments of real time, adaptive and non-sequentially assembled video |
JP2019075604A (en) * | 2017-10-12 | 2019-05-16 | 株式会社ミクシィ | Information processing device, moving image distribution method, and moving image distribution program |
-
2019
- 2019-07-23 US US17/282,492 patent/US11490172B2/en active Active
- 2019-07-23 EP EP19802324.4A patent/EP3831086A1/en active Pending
- 2019-07-23 JP JP2021515023A patent/JP7171903B2/en active Active
- 2019-07-23 CN CN201980063003.0A patent/CN112840667A/en active Pending
- 2019-07-23 KR KR1020217007575A patent/KR102465853B1/en active IP Right Grant
- 2019-07-23 WO PCT/UA2019/000095 patent/WO2021015705A1/en unknown
Patent Citations (8)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9098807B1 (en) * | 2011-08-29 | 2015-08-04 | Google Inc. | Video content claiming classifier |
US20140052696A1 (en) * | 2012-08-20 | 2014-02-20 | United Video Properties, Inc. | Systems and methods for visual categorization of multimedia data |
CN107005747A (en) * | 2014-07-31 | 2017-08-01 | 麦恩得赛特米迪尔公司 | Method, equipment and the product of delivering media content are presented via at user option narration |
WO2016115154A1 (en) * | 2015-01-14 | 2016-07-21 | MindsightMedia, Inc. | Data mining, influencing viewer selections, and user interfaces |
US20180052758A1 (en) * | 2016-08-22 | 2018-02-22 | Oath Inc. | Systems and methods for determining user engagement with electronic devices |
US10334328B1 (en) * | 2017-01-20 | 2019-06-25 | Render Inc. | Automatic video generation using auto-adaptive video story models |
US20190098371A1 (en) * | 2017-09-27 | 2019-03-28 | Podop, Inc. | Media narrative presentation systems and methods with interactive and autonomous content selection |
US10147461B1 (en) * | 2017-12-29 | 2018-12-04 | Rovi Guides, Inc. | Systems and methods for alerting users to differences between different media versions of a story |
Non-Patent Citations (1)
Title |
---|
陈兵: "数字叙事中的用户参与行为研究", 《出版科学》 * |
Also Published As
Publication number | Publication date |
---|---|
US11490172B2 (en) | 2022-11-01 |
JP7171903B2 (en) | 2022-11-15 |
KR20210042388A (en) | 2021-04-19 |
EP3831086A1 (en) | 2021-06-09 |
US20210385557A1 (en) | 2021-12-09 |
WO2021015705A1 (en) | 2021-01-28 |
KR102465853B1 (en) | 2022-11-11 |
JP2022542719A (en) | 2022-10-07 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN107430630B (en) | Methods, systems, and media for aggregating and presenting content related to a particular video game | |
US10356462B1 (en) | Recommending a composite channel | |
US10740392B2 (en) | System and method for streaming individualized media content | |
US10762161B2 (en) | Intelligent humanoid interactive content recommender | |
CN111771384B (en) | Method, system and readable storage medium for automatically adjusting playback speed and context information | |
US9558244B2 (en) | Systems and methods for social recommendations | |
KR101908099B1 (en) | Automated click type selection for content performance optimization | |
CN104782138B (en) | Thumbnail image selects system, method and computer-readable medium | |
US11435890B2 (en) | Systems and methods for presentation of content items relating to a topic | |
CN112074857A (en) | Combining machine learning and social data to generate personalized recommendations | |
US10866982B2 (en) | Intelligent content recommender for groups of users | |
US9467744B2 (en) | Comment-based media classification | |
CN107463698B (en) | Method and device for pushing information based on artificial intelligence | |
US11003720B1 (en) | Relevance-ordered message search | |
US20200074481A1 (en) | System, method, and device for analyzing media asset data | |
US20170155939A1 (en) | Method and System for Processing Data Used By Creative Users to Create Media Content | |
US8725795B1 (en) | Content segment optimization techniques | |
US20140089238A1 (en) | Information processing device and information processing method | |
US11490172B2 (en) | Method and system for the classification and categorization of video pathways in interactive videos | |
US20200175058A1 (en) | Methods and systems generating curated playlists | |
CN115244941A (en) | User interface for improved video packaging | |
US20230283849A1 (en) | Content navigation and personalization | |
EP4318360A1 (en) | Rendering a dynamic endemic banner on streaming platforms using content recommendation systems and content modeling for user exploration and awareness | |
US20230081938A1 (en) | Digital video analysis | |
CN118013133A (en) | Content recommendation method of meta-universe, meta-universe device and readable storage medium |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
WD01 | Invention patent application deemed withdrawn after publication | ||
WD01 | Invention patent application deemed withdrawn after publication |
Application publication date: 20210525 |