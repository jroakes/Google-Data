US8646077B1 - IP address based detection of spam account generation - Google Patents
IP address based detection of spam account generation Download PDFInfo
- Publication number
- US8646077B1 US8646077B1 US12/648,246 US64824609A US8646077B1 US 8646077 B1 US8646077 B1 US 8646077B1 US 64824609 A US64824609 A US 64824609A US 8646077 B1 US8646077 B1 US 8646077B1
- Authority
- US
- United States
- Prior art keywords
- account
- creation request
- count
- account creation
- created
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active, expires
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/60—Protecting data
- G06F21/62—Protecting access to data via a platform, e.g. using keys or access control rules
- G06F21/6209—Protecting access to data via a platform, e.g. using keys or access control rules to a single file or object, e.g. in a secure envelope, encrypted and accessed using a key, or with access control rules appended to the object itself
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/50—Monitoring users, programs or devices to maintain the integrity of platforms, e.g. of processors, firmware or operating systems
- G06F21/55—Detecting local intrusion or implementing counter-measures
- G06F21/554—Detecting local intrusion or implementing counter-measures involving event detection and direct action
Definitions
- the disclosed embodiments relate generally to the creation of new user accounts for online services and, in particular, to methods and systems for detecting and preventing spam account generation.
- Users of the Internet may register for online user accounts for many different purposes. However, certain users register for and create multiple new accounts (e.g., with an online or web based service) with or without an actual human user being involved. Such accounts may be used for sending unsolicited electronic communications known as spam.
- a computer implemented method may include receiving an account creation request from an IP address, determining a first count of new accounts created from the IP address during a first time period, determining a second count of predefined account access operations associated with the IP address during a second time period, associating a score, based at least in part on the first count and second count, with the account creation request, and performing an action associated with the account creation request based at least in part on the score.
- the action may include at least one of refusing the account creation request, modifying an account created in response to the account creation request, accepting the account creation request, and maintaining the account created in response to the account creation request.
- FIG. 1 is a diagram of an environment for detecting spam accounts (e.g., email accounts used for sending spam) for online services according to some embodiments.
- spam accounts e.g., email accounts used for sending spam
- FIG. 2 is a block diagram illustrating data structures according to some embodiments.
- FIG. 3A is a flow diagram of a process for evaluating account creation requests according to some embodiments.
- FIG. 3B is a flow diagram of a process for evaluating account creation requests according to some embodiments.
- FIG. 3C is a flow diagram of a process for evaluating account creation requests according to some embodiments.
- FIG. 3D is a flow diagram of a process for evaluating account creation requests according to some embodiments.
- FIG. 3E is a flow diagram of a process for acting on scores associated with account creation requests according to some embodiments.
- FIG. 4 is an illustration of a graphical user interface (GUI) showing an example of a human interaction proof according to some embodiments.
- GUI graphical user interface
- FIG. 5 is an illustration of a GUI showing an example of an account creation form according to some embodiments.
- FIG. 6 is a block diagram of a client according to some embodiments.
- FIG. 7 is a block diagram of a server according to some embodiments.
- spammming is the abuse of electronic systems to generate “spam.” Spam may include excessive postings and unsolicited communications, such as email, instant messages (IMs), text messages, faxes, advertisements, repetitive posts, forgeries, or the like. In some cases, spam may include electronic communications in violation of the United States CAN-SPAM Act of 2003 or the Junk Fax Prevention Act of 2005. A “spammer” is an entity that engages in spamming.
- FIG. 1 is a diagram of a distributed computer system 100 (also called an environment) in which embodiments of the present invention may be practiced.
- the distributed system includes a server 106 (also known as a server system, since it include multiple servers) that is configured to detect spam accounts (i.e., user accounts created or used for sending spam), as described in more detail below.
- the server 106 and one or more clients, computers, or devices 102 are connected to a communication network 104 .
- the communication network 104 can be any wired or wireless local area network (LAN) and/or wide area network (WAN), such as an intranet, an extranet, or the Internet. It is sufficient that communication network 104 provides communication capability between clients 102 and server 106 .
- HTTP HyperText Transport Protocol
- TCP/IP Transmission Control Protocol/Internet Protocol
- IP address includes an identifier and locator of a client within the communication network, and is not limited to the use of any particular protocol.
- the term “resource” as used throughout this specification refers to a unit of information or a service that is accessible via a Uniform Resource Locator (URL) and can be, for example, a webpage, a document, a database, an image, a computational object, a search engine, a web application, an online information service, or the like.
- URL Uniform Resource Locator
- a respective client 102 can be any of a number of devices (e.g., a computer, an internet kiosk, a personal digital assistant, a cell phone, a gaming device, a desktop computer, or a laptop computer) and can include a client application 132 and/or client memory (not shown).
- Client memory can store information such as resources, system information, and/or information about a user.
- the client application 132 can be an application that permits a user to interact with the client and/or network resources to perform one or more tasks.
- the client application 132 can be a browser (e.g., the computer program available under the trademark Firefox®) or other type of application that permits a user to search for, browse, and/or use resources.
- Client application 132 can provide a window to be displayed on a display device (e.g., a monitor) for rendering information sent by the server 106 as well as information entered by a user of the client 102 .
- the client application 132 may provide a graphical user interface (GUI) 134 for displaying information.
- GUI graphical user interface
- a user may submit an account creation request through client application 132 to the server 106 to register for a new account (sometimes called an online account) for one or more online services.
- a user includes any entity capable of using client 102 and/or client application 132 to create or access an account. Users may be humans, computer programs such as bots, or the like.
- website refers to a logical location (e.g., an Internet or intranet location) identified by a URL, or it refers to a web server hosting the web site represented by the URL.
- a logical location e.g., an Internet or intranet location
- some “websites” are distributed over multiple Internet or network locations, but have a shared web server hosting those locations, and in many situations it is logical to consider those network locations to all be part of “a website.”
- the server 106 includes a network communication module 108 , a web application 110 , a spam scoring module 112 , an inverse IP index 114 , a user account database 116 , and a user account module 118 .
- the user account module 118 includes a registration module 120 .
- the terms “module,” “procedure,” and “application” correspond to instructions, executable by the one or more processors in a computer system, for performing one or more functions. These instructions need not be implemented as separate software programs, procedures or modules. The various modules and sub-modules may be rearranged, separated, and/or combined.
- the server 106 may include additional modules and/or sub-modules, or fewer modules and/or sub-modules than indicated in FIG. 1 .
- the spam scoring module 112 may be integrated with the user account module 118 .
- various modules and sub-modules of server 106 may be distributed on one or more other servers.
- the network communication module 108 receives requests from respective clients 102 and returns resources, responses, and other information to the requesting clients 102 via communication network 104 .
- network communication module 108 receives user account creation requests from clients 102 .
- a respective user account creation request (sometimes called a user account request, account request, or account creation request) is passed by network communication module 108 to user account module 118 .
- user account module 118 makes one or more procedure calls to spam scoring module 112 to determine how to handle the user account request.
- the user account request is passed to user account module 118 via spam scoring module 112 .
- Spam scoring module 112 assigns one or more scores to each user account and/or a user account request, such as a user account request to access web application 110 .
- the scores indicate the likelihood that a user account is used to generate spam.
- the scores indicate the likelihood that a user account will be used to generate spam.
- the scores indicate the likelihood that an account creation request is associated with spam.
- Registration module 120 allows users to register for corresponding user accounts ( 122 - 1 through 122 -N) allowing access to the web application 110 .
- N is an integer that changes over time as new user accounts are generated.
- the account creation request is received at server 106 by network communication module 108 and is directed to registration module 120 .
- the account creation request is directed to registration module 120 only upon meeting some predefined criteria.
- the account creation request includes a set of account creation parameter values.
- the account creation request optionally includes an account creation form and/or parameter values obtained from an account creation form.
- each account creation request from a user is communicated to and stored in user account database 116 .
- user account database 116 stores additional information such as login information, for example user name and password, user payment information (such as credit card information), and the like.
- registration module 120 sends an account creation notice through communication network 104 to requesting client 102 . If the request is refused, registration module 120 may send an account refusal notice through communication network 104 to requesting client 102 .
- registration module 120 may perform other actions (e.g., one or more of: failing to send a response to the request, requiring the requesting client to respond to one or more additional human interaction proof (HIP) challenges, increasing the response time to the requesting client 102 (e.g., from one second to one minute or longer)) to discourage the client from sending additional account creation requests.
- HIP human interaction proof
- Web application 110 provides online services to users of clients 102 having user accounts.
- the web application 110 may be an online calendar service, financial services application, a retail or wholesale product sales application, a social networking application, an email application, a blogging application, or any other online service or application (or set of applications) associated with user accounts.
- multiple user accounts for one or more online services may be associated with a single originating user account.
- inverse IP index 114 stores data regarding the user accounts in records associated with respective IP addresses, including the number of user accounts associated with each IP address. Inverse IP index 114 is further discussed with reference to FIG. 2 .
- FIGS. 1 and 7 depicts discrete functional elements (e.g., modules and data structures), these figures are intended more as a functional description of some embodiments of the invention rather than a structural description of the functional elements.
- the user account database 116 may be implemented using one or more other servers whose primary function is to store and process user information.
- the user account database 116 and the inverse IP index 114 shown separately in FIG. 1 may be implemented by one, two, or more distinct databases spread over as many servers as needed to store and provide timely access to data in the databases.
- the layout of the server 106 as shown in FIGS. 1 and 7 is merely exemplary and may take on any other suitable layout or configuration.
- the actual number of computers constituting the server 106 and the allocation of features among the computers may vary from one implementation to another, and may depend in part on the amount of traffic that the server 106 handles during peak usage periods as well as during average usage periods.
- one or more of the modules or components in FIG. 1 may be implemented on one or more servers designed to provide the described functionality.
- FIG. 2 is a block diagram illustrating data structures stored in user account database 116 and inverse IP index 114 according to some embodiments.
- the data structures shown are by way of example and different data structures known to those skilled in the art may be used in some embodiments.
- user account database 116 stores multiple user account records 218 .
- a user account record 218 includes a unique identifier 220 , such as the user ID 204 for the associated user account, an account request matrix 200 and a information 221 (e.g., record 221 - 1 -Y for operation Y on user account 1 ) regarding each account access operation associated with the user account.
- Examples of account access operations that may be recorded in the user account record 218 for a respective account include user login to the account, sending an email message, opening an email message received by the account, changing the password for the account, logging out of the account, and adding or deleting services to the account.
- each user account record 218 - 1 In the example shown in FIG. 2 , each user account record 218 - 1 .
- each account access operation includes the corresponding user ID 204 - 1 . . . 204 -N, the corresponding account request matrix 200 - 1 . . . 200 -N, and a record of each account access operation 1 . . . Y associated with the respective user account.
- the record 221 of each account access operation may include an access time, an access type (e.g., sending an email message, etc.), and an IP address entry identifying the IP address from which the account access operation was performed.
- An account request may be processed and the associated information is stored in the account request matrix 200 .
- Account request matrix 200 in FIG. 2 stores information for a single account request (e.g., account request-1, having a request identifier 202 - 1 ).
- each user account record 218 is associated with no more than one account creation request, in which case the account request matrix 200 has only one column.
- account request matrix 200 may alternately include multiple columns associated with separate account requests associated with an originating account.
- the originating account may be associated with an email account having a secondary email address 208 .
- the account request matrix 200 includes a unique request identifier 202 for each account request and includes a user ID 204 , a password 206 (or hash of the password), an optional secondary email address 208 , a human interaction proof (HIP) response 210 (described below), a request time 212 , a cookie 214 , and an IP address 216 associated with the account request.
- a secondary email address 208 is an email address associated with the account request but distinct from the email address of the new account.
- the account request matrix 200 includes a subset of the aforementioned fields, and may include additional fields as well.
- a respective account request matrix 200 may not include a secondary email address.
- account request matrix 200 includes a timestamp indicating when an account creation form was sent to client 102 by server 106 .
- user ID 204 , password 206 , secondary email address 208 , and HIP response 210 are provided by the user in response to the account creation form.
- client 102 and/or server 106 identify the request time 212 - 1 , the cookie 214 - 1 , and the IP address 216 - 1 associated with the account request 202 - 1 upon receipt of the account creation form.
- inverse IP index 114 stores multiple IP records 215 associating IP addresses with user account data.
- Each IP record 215 in the inverse IP index 114 includes an IP address 216 , a user count 222 , and one or more unique identifiers 220 , such as user ID 204 , for each user account associated with the IP address 216 .
- User count 222 is a field storing information about the number of user accounts associated with IP address 216 .
- the user count 222 includes a count of the number of accounts created in response to requests from a respective IP address 16 during multiple time periods or intervals.
- the user count may have a sequence of values, C1, C2, C3, C4, etc., where C1 represents an ongoing user count for a current time period, C2 represents the user count for a first time period prior to the current time period, C3 represents the user count for a second time period prior to the first time period, and so on.
- the user count 222 may include user counts for several (e.g., a number between 2 and 10), recent, short time periods (e.g., one day each), and user counts for one or more (e.g., a number between 1 and 100), less recent, longer time periods (e.g., one week, or eight weeks, or the like).
- account records 218 in user account database 116 and/or IP records 215 in the inverse IP index 114 may include more or less information than described here.
- IP records 215 in the inverse IP index 114 may include additional fields that store the values of the first count and second count, discussed below, and/or additional fields that store historical counts, which are used to compute the values of the first count and second count.
- the term “user” in the present application does not necessarily correspond to a human being.
- the term “user” may refer to any entity that uniquely identifies a client 102 at a particular time, such as an IP address, a cookie, a pair of user ID and password or a combination thereof.
- IP addresses may be associated with multiple clients having multiple users, including both spammers and non-spammers, such lists may block legitimate messages and prevent non-spammers from accessing web applications.
- IP addresses may be associated with multiple clients having multiple users, including both spammers and non-spammers, such lists may block legitimate messages and prevent non-spammers from accessing web applications.
- proxy servers when identifying an IP address as a source of spam it is important to distinguish between static IP addresses associated with a single client and IP addresses that may be associated with multiple clients, such as proxy servers.
- FIG. 3A is a flow diagram of a process for evaluating account creation requests according to some embodiments.
- some or all of the process is performed by the spam scoring module 112 ( FIG. 1 ).
- Optional operations are indicated by dashed lines or boxes having dashed-line borders.
- Operations by a respective client 102 which is associated with an IP address, are shown on the left side of FIGS. 3A-3E , while operations by the server 106 for an online service are shown on the right side of FIGS. 3A-3E .
- the IP address of the client 102 may be a static, globally unique IP address that always identifies the particular client 102 , a dynamically assigned IP address, or an IP address associated with multiple clients, such as the IP address of a proxy server.
- client 102 sends an account creation request to a web application 110 at server 106 ( 302 ).
- client application 132 e.g., a browser application
- client application 132 e.g., a browser application
- the web server 106 receives the account creation request ( 304 ) and creates an account ( 309 ).
- creation of the account may be conditional, or the account may be revoked after it is created.
- registration module 120 at the server 106 receives the account creation request and creates the account. For instance, in some embodiments, it may be a default condition that an account is created upon receiving the account creation request before the account creation request is associated with a spam score. In other embodiments, an account is created upon receiving the account creation request before the account creation request is associated with a spam score only in certain situations. For example, when server 106 receives a large number of account creation requests, an account may be created before a spam score is obtained for the associated account creation request.
- server 106 optionally sends a response to the requesting client 102 , responding to the account creation request, prior to performing additional processing of the account creation request.
- the client 102 receives the response ( 306 ).
- a user may perform account access operations ( 308 ), examples of which are: logging in to the account using client application 132 , and performing the various functions (or, equivalently, accessing various online services) enabled by the account.
- the registration module 120 does not respond to the account creation request until after the spam scoring module 112 has evaluated the request, Evaluating the request typically includes examining historical information in its database and uses that historical information to determines whether or not to grant the request.
- the request is evaluated in part by determining the number (also called the “first count”) of new accounts associated with the IP address created during a particular time period ( 310 ), sometimes called a first time period.
- the first time interval (for which a count of new accounts is made) ranges from one day to eight weeks. Other appropriate time intervals may be used in other embodiments.
- spam scoring module 112 determines the number of new accounts created from the same IP address by accessing user count 222 stored in inverse IP index 114 (see FIG. 2 ).
- user count 222 is the number of user accounts associated with an IP address 216 .
- the user count 222 includes information about the numbers of user accounts associated with an IP address 216 that are created within a plurality of respective time intervals.
- the process may inspect activity by accounts previously generated (e.g., generated within the same time interval or a previous time interval) from the same IP address. For example, for an account creation request received on a Tuesday, user account module 118 may query inverse IP index 114 ( FIG. 2 ) to determine the user accounts associated with the IP address. The user account module 118 may also query user account database 116 ( FIG. 2 ) to determine which of the user accounts associated with the IP address were created on Monday and review characteristics of the user accounts, such as the account access operations associated with each account.
- user account module 118 can determine whether there has been an increase in the number of accounts created in response to requests from a given IP address. Additionally, user account module 118 can determine the number and character of the account access operations from each of those accounts.
- the character of an account access operation is determined by evaluating whether the corresponding user account was created within a predetermined time window, e.g. a day. For example, user account module 118 may determine that there are 256 “new” account access operations associated with IP address-1 216 - 1 and 356,798 “old” account access operations associated with IP address-1 216 - 1 . In some cases “new” account access operations are account access operations 1 through Y from user accounts created within the same time interval (in the example above, on Monday). “Old” account access operations may be account access operations associated with user accounts created during a previous time interval (in the example above, Sunday or some period of time before Monday).
- This methodology may be used to inspect a set of user accounts created using the same IP address for evidence of spammy or other undesirable activity. The evidence may then be used as a basis for remedial action, such as disabling or limiting access to such accounts.
- the process may also determine at least one of (i) the distribution of user account creation requests associated with the IP address over time and (ii) the distribution of account access operations associated with the IP address over time. In other words the process may be used to track the number of user accounts created from an IP address over time as well as the number of account access operations associated with those accounts over time. In some cases the distributions may be referred to as a “first count” and a “second count,” respectively.
- the first count is a time weighted average of new accounts created from the IP address per time interval during successive time intervals.
- a third count of new accounts created from the IP address during a recent time interval may be given more weight (e.g., assigned a higher weight) than a fourth count of new accounts created from the IP address during a less recent time interval.
- the first count may be determined as follows:
- FirstCount [ ( ThirdCount ) + 0.5 * ( FourthCount ) + ... + ( 1 n ) * ( ( n + 2 ) ⁇ thCount ) ] n ( Eq . ⁇ 1 )
- ThirdCount is the number of new accounts created one day before the currently pending account creation request
- FourthCount is the number of new accounts created two days before the currently pending account creation request
- (n+2)thCount is the number of new accounts created n days before the currently pending account creation request
- n is a whole number equal to the number of days over which the number of new accounts created from the IP address per day is being averaged (also called the “time period”).
- the denominator of the equation (see Eq. 1, above) for computing the first count is equal to
- the first count is an average or time weighted average, over a time period, of new accounts created from the IP address per time interval, where the time period is equal to two or more time intervals (e.g., a multiple of the time interval).
- the first count may be the average (or time weighted average) number of new accounts created daily from an IP address over a week, a month, or a year.
- spam scoring module 112 may also determine the number of new accounts associated with usernames that are similar to the username in the new account creation request ( 312 ) and that are created within a predefined time period (e.g., a day, N days, a week, N weeks, etc., where N is an integer greater than 1). Whether a respective username is similar to the username in the account creation request is determined using a set of one or more predefined similarity rules, such as stemming, matching the longest common substring, similarity algorithms, or the like.
- the spam scoring module 112 may treat all new accounts (e.g., newly created accounts or account generation requests) having a username that includes a numerical string before or after the string “john” (e.g., “john01,” “2007john,” etc.) as new accounts having similar user names.
- the spam scoring module 112 may treat all new accounts (e.g., newly created accounts or account generation requests) having a username that includes a numerical string before or after the string “john” (e.g., “john01,” “2007john,” etc.) as new accounts having similar user names.
- a predefined similarity rule based on prefixes and suffixes, if another username has the same prefix (i.e., initial substring) or the same suffix (i.e., ending substring) as the username in the new account request, that username is treated as similar to the username in the new account creation request.
- a predefined similarity rule may require that the common prefix or suffix have at least a predefined length (e.g., at least 4 characters) in order for two usernames to be determined to be similar.
- a username is determined to be similar to the username in a new account creation request
- the account associated with the similar username is counted at operation 312 .
- the total number of recently generated accounts having similar usernames to the username for the current new account creation request may be called a “third count,” or “similar username count,” or the like.
- Spam scoring module 112 may also determine the number (also called the “second count”) of account access operations associated with the IP address ( 314 ) during a second time period.
- the second time period is the same as the first time period used for computing the first count.
- the account access operations comprise account logins (sometimes called “unique logins”) associated with the IP address (e.g., logins by one or more respective users of one or more clients at the IP address, or alternatively, logins to accounts created in response to requests received from the IP address).
- the account access operations that are used for the second count may include other operations associated with the IP address, such as sending an email message, reading an email message, or accessing a resource of the online service.
- spam scoring module 112 determines the number of account access operations associated with the IP address by accessing the user account database 116 (discussed above in reference to FIG. 2 ), which stores information regarding each account access operation associated with a respective user account.
- spam scoring module 112 may determine the second count without limiting the count of access operations to any time interval. In other embodiments, spam scoring module 112 determines the second count based on account access operations associated with the IP address during successive predefined time intervals of the second time period. In various embodiments, each of the predefined time intervals is a day, N days, a week, or N weeks, where N is an integer greater than one. In some embodiments, the second count is a weighted average of account access operations during the time intervals. Further, in some embodiments, a count of account access operations on accounts created during a recent time interval is given less weight than a count of account access operations on accounts created during a less recent time interval. For example:
- SecondCount AccessOps ⁇ ⁇ on ⁇ ⁇ New ⁇ ⁇ Accounts + C ⁇ ⁇ 2 * ( Access ⁇ ⁇ Ops ⁇ ⁇ on ⁇ ⁇ Older ⁇ ⁇ Accounts ) 1 + C ⁇ ⁇ 2 ( Eq .
- AccessOps on New Accounts is a count (e.g., a fifth count) of account access operations (over a predefined period of time) on new accounts associated with the IP address, created within a predefined time interval, such as the last week or N days
- C2 is a constant or coefficient having a predefined value greater than one
- AccessOps on Older Accounts is a count (e.g., a sixth count) of account access operations (over the predefined period of time) on older accounts associated with the IP address, created prior to the predefined interval.
- C2 is greater than one so as to give account access operations on older accounts (created during a less recent time interval) more importance than account access operations on new accounts (created during a recent time interval).
- Account access operations on older accounts is an indicator of legitimate (non-spammy) accounts associated with the IP address.
- the second count is a count of account access operations (over the predefined period of time) only on older accounts associated with the IP address, created prior to a predefined interval.
- spam scoring module 112 may associate a score (Score IP — Address ) with the account creation request based at least on the first and second counts ( 316 ).
- the score may be called a “spam score” and may be a function of the first count and the second count, or a combination of counts (optionally including one or more other counts, such as the “similar username count” discussed above, in addition to the first and second counts) determined by the spam scoring module 112 .
- the score is proportional to a ratio of the first count to the second count. Note that the score as described here in connection with FIG. 3A is an IP address related score.
- W1 is chosen such that there is an appropriate ratio between the IP address-based spam score and the other types of spam scores. For example, W1 may range from 1 to 50.
- Spam scoring module 112 determines if the score meets predetermined criteria ( 318 ). If the score meets the predetermined criteria, the account created at block 309 may be disabled ( 320 ). For example, if the score exceeds a predetermined threshold indicating that many more accounts associated with an IP address were created than were accessed in the last day, the account created at block 309 in response to the account creation request may be disabled ( 320 ). If the score does not meet the predefined criteria, an action to perform based on the score is determined ( 322 ) according to the process shown in FIG. 3E .
- FIG. 3B is a flow diagram of a process for evaluating account creation requests according to another embodiment. In some embodiments some or all of the process is performed by the spam scoring module 112 . Optional operations are indicated by dashed lines or boxes having dashed-line borders. Furthermore, operations that are the same as or similar to the operations in the process depicted by FIG. 3A have been labeled with the same or similar reference numbers and will be described briefly here.
- a client 102 sends an account creation request to an online service ( 302 ).
- the account creation request includes a password.
- a user of client 102 may use client application 132 (e.g., a browser application) to interact with client 102 to generate the account creation request.
- client application 132 e.g., a browser application
- a server 106 providing an online service, or a server performing account management services for the online service receives the account creation request, including the password ( 304 - 1 ).
- registration module 120 receives the account creation request ( 304 - 1 ) and optionally creates an account ( 309 ), as discussed above with reference to FIG. 3A .
- the online service determines a count of new account requests (also called “PasswordCount”), received within a predefined period of time, that have the same password as the password in the account creation request now being processed.
- the password count can be a count of new account requests within the predefined period of time having respective passwords that are similar to, or more generally, a function of, the password in the account creation request now being processed ( 310 - 1 ).
- the predefined time period may range from one day to one month or any other time interval deemed appropriate according to the type of service offered by the online service.
- the function (used in operation 310 - 1 ) is the identity function of the password (i.e., the passwords must be the same).
- the function is to determine if two passwords meet predefined similarity criteria. For example, whether a respective password is similar to the password in the account creation request may be determined using a set of similarity rules, such as stemming, matching the longest common substring, similarity algorithms, or the like.
- a predefined similarity rule may require that the common prefix or suffix have at least a predefined length (e.g., at least 4 characters) in order for two usernames to be determined to be similar.
- the function used to determine if two passwords are similar may require the two passwords to be the same after removing from the passwords the usernames (or the same portions of the usernames) of the accounts associated with the two passwords.
- the methodology described above in connection with the determination of the first count is used to determine the PasswordCount as an average or time weighted average of the multiple counts of new account creation requests having similar passwords, one count per time interval, over a time period that is longer than a single time interval.
- the online service determines a popularity value associated with the password (also called “PasswordPopularityValue”) ( 314 - 1 ).
- the password popularity is a function of (i) the number of accounts that have the same or similar passwords, and/or (ii) the number of times the same or similar passwords have been used by some users (e.g., hackers) who attempt unauthorized access to other accounts over a predefined period of time, such as a day, week, or year.
- the online service e.g., the spam scoring module 112 of a server 106 for the online service
- identify a set of popular passwords used by many authorized users e.g., the popularity of a password is set to a default value (e.g., 1) unless the number of accounts using the same or similar passwords or the number of unauthorized attempts using the password is greater than a threshold value.
- the spam scoring module 112 Based at least in part on the count (PasswordCount) and the popularity value (PasswordPopularityValue), the spam scoring module 112 associates a score (Score Password ) with the account creation request ( 338 ).
- the score is inversely proportional to (or more generally, inversely related to) the popularity value of the password.
- the score may be referred to as a “spam score” or may be one of multiple components considered by the spam scoring module 112 for determining the spam score. In some embodiments, this score is set to be lower for accounts created with popular passwords than for accounts created with less popular passwords.
- This spam scoring methodology is based on the observation that an account creation request with a popular password is more likely from an authorized user of the online service and an account creation request with a more unique password is more likely from an unauthorized user.
- the value of W2 is chosen in light of the other weighting factors, such as W1 described above, such that there is an appropriate ratio between the password-based spam score and the other types of spam scores.
- Spam scoring module 112 determines if the score meets predetermined criteria ( 318 ). For example, the score may be compared with a predefined threshold value. If the score meets the predetermined criteria (e.g., the score is above the predefined threshold) ( 318 —Yes), the created account may be disabled ( 320 ) or, if a pending account creation request is being processed, the account creation request may be denied. If the score does not meet the predefined criteria ( 318 —No), the spam scoring module 112 (or the online service for which an account creation request has been made) determines what action to perform based on the score ( 322 ) according to the process shown in FIG. 3E .
- predetermined criteria e.g., the score is above the predefined threshold
- the action to be performed includes at least one of: refusing the account creation request, modifying an account created in response to the account creation request (e.g., disabling the account or limiting the account access), accepting the account creation request, and maintaining the newly-created account.
- options for limiting the account access include at least one of requiring a response to a human interaction proof from the requesting client 102 for access to the account, limiting access time to the account (e.g., the user may be allowed to access the account only within a predefined time period within each day), limiting use of account functions (e.g., the user may be allowed to only receive messages delivered to the account but not send messages from the account), and limiting transmission from the account (e.g., the user may be allowed to send no more than a predefined number of messages from the account within each day).
- FIG. 3C is a flow diagram of a process for evaluating account creation requests according to another embodiment.
- some or all of the process is performed by the spam scoring module 112 .
- Optional operations are indicated by dashed lines or boxes having dashed-line borders.
- operations that are the same as or similar to the operations in the process depicted by FIG. 3A have been labeled with the same or similar reference numbers and will be described briefly here.
- a client 102 sends an account creation request to an online service ( 302 ).
- the account creation request is associated with a cookie.
- a user of client 102 may use client application 132 (e.g., a browser application) to interact with client 102 to generate the account creation request.
- client application 132 e.g., a browser application
- the online service receives the account creation request associated with the cookie ( 304 - 2 ).
- registration module 120 optionally creates an account ( 309 ).
- the spam scoring module 112 associates a score (sometimes known as “CookieCount”) with the account creation request ( 316 - 2 ), based at least in part on a number of new account requests associated with the same cookie (as the cookie associated with the account creation request) received during a predefined time period.
- the predefined time period has a duration that is in the range of one day to one month.
- the spam scoring module 112 associates a score (sometimes known as “CookieCount”) with the account creation request ( 316 - 2 ), based at least in part on a number of new account requests associated with the same cookie (as the cookie associated with the account creation request) received during the predefined time period.
- the number of new accounts created using the same cookie over the predefined time period is indicative of spam account generation.
- Two cookies are determined to be the same if the same unique identifier is found in both cookies, received with the account creation requests (e.g., using the HTTP protocol) for generating the corresponding new accounts.
- the number of new accounts (created during the predefined time period) that are associated with the same cookie must be greater than a predefined threshold (e.g., two) for this score to be greater than zero.
- the value of W3 is chosen in light of the other weighting factors such as W1 and W2 described above such that there is an appropriate ratio between the cookie-based spam score and the other types of spam scores.
- W3 is equal to zero when CookieCount is less than a threshold value and is equal to a non-zero value otherwise.
- ScoreCookie is equal to W3 times a predefined function of CookieCount, where the predefined function is a linear or non-linear function of CookieCount (e.g., a piecewise linear function which is equal to zero below a first threshold, and which linearly or non-linearly increases from a starting value when CookieCount is above the first threshold).
- the methodology described above in connection with the determination of the first count is used to determine the CookieCount as an average or time weighted average of the multiple counts of new account creation requests having the same cookie, one count per time interval, over a predefined time period that is longer than a single time interval.
- the server 106 or online service determines if the score meets predetermined criteria ( 318 ). If the score meets the predetermined criteria ( 318 , yes), the created account (see 309 ) may be disabled ( 320 ) or, if a pending account creation request is being processed, the account creation request may be denied. If the score does not meet the predefined criteria ( 318 , no), the spam scoring module 112 determines what action to perform based on the score ( 322 ) according to the process shown in FIG. 3E .
- the action to be performed includes at least one of: refusing the account creation request, modifying an account created in response to the account creation request (e.g., disabling the account or limiting the account access), accepting the account creation request, and maintaining the newly-created account.
- options for limiting the account access include at least one of requiring a response to a human interaction proof from the requesting client 102 for access to the account, limiting access time to the account (e.g., the user may be allowed to access the account only within a predefined time period within each day), limiting use of account functions (e.g., the user may be allowed to only receive messages delivered to the account but not send messages from the account), and limiting transmission from the account (e.g., the user may be allowed to send no more than a predefined number of messages from the account within each day).
- FIG. 3D is a flow diagram of a process for evaluating account creation requests according to another embodiment. In some embodiments some or all of the process is performed by the spam scoring module 112 . Optional operations are indicated by dashed lines or boxes having dashed-line borders. Furthermore, operations that are the same as or similar to the operations in the process depicted by FIG. 3A have been labeled with the same or similar reference numbers and will be described briefly here.
- the online service sends an account creation form including a human interaction proof to a client 102 ( 323 ).
- the account creation form is sent out in response to an account creation request associated with the client 102 .
- a user at the client Upon receiving the account creation form ( 323 - 1 ), a user at the client needs to complete the account creation form ( 323 - 2 ) by providing the information requested by the form.
- the information includes at least a subset of username, password, security question/answer, secondary email, location, HIP test, etc.
- the term “HIP” is an acronym for “Human Interaction Proof,” an example of which is described below in connection with FIG. 4 .
- the completed form, including a response to the human interaction proof from the client 102 is returned to the online service ( 323 - 3 ).
- the spam scoring module 112 evaluates a time difference between sending the form and receiving the completed form (also referred as “HIPResponseTime”) ( 327 ). In some embodiments, this time difference is also referred to as “response time.”
- HIP time difference between sending the form and receiving the completed form
- this time difference is also referred to as “response time.”
- automated tools may be used by unauthorized users (e.g., spammers) of the online service to fill certain parts (e.g., username and password) of the account creation form, these automated tools are often useless when faced with a HIP test. Therefore, it is common for humans to be involved in the spamming activities in order to deal with HIP tests.
- a person can respond to the HIP test much faster than ordinary people after he or she practices for a certain number of times. Therefore, a noticeable difference between account creation requests from spammers and account creation requests from ordinary users is that the response time from a spammer is much shorter than the average response time from an ordinary user. For example, if the average response time for completing the account creation form for a particular online service (also called “Average_HIPResponseTime”), including a HIP test, is 40 seconds, the response time from a spammer for completing the same form could be less than 15 seconds, which is indicative of spam account generation.
- a particular online service also called “Average_HIPResponseTime”
- spam scoring module 112 Based at least in part on the time difference (HIPResponseTime), spam scoring module 112 associates a score (Score HIP ) with the account creation form ( 316 - 3 ). In some embodiments, other factors, such as one or more of the spam scoring factors discussed elsewhere in this application, also contribute to the spam score generated by the spam scoring module. In some embodiments, the score is inversely proportional (or more generally, inversely related) to the time difference. In some embodiments, the score is equal to a default value unless the time difference is less than a predetermined threshold.
- the score is a function of the time difference and an average time difference over a predefined time period (e.g., a day, N days, a week, N weeks, etc., where N is an integer greater than 1).
- the value of W4 is chosen in light of the other weighting factors such as W1, W2, and W3 described above such that there is an appropriate ratio between the HIP-based spam score and the other types of spam scores.
- Score HIP is equal to W4 times a predefined function of Average_HIPResponse Time and HIPResponse Time, where the predefined function is a linear or non-linear function of HIPResponse Time and HIPResponse Time (e.g., a piecewise linear function).
- a table lookup function is used to generate the score based on the response time as follows (note that the weighting factor W4 may still be needed to adjust these scores when they are combined with the other types of spam scores):
- Spam scoring module 112 determines if the score meets predetermined criteria ( 318 ). If the score meets the predetermined criteria ( 318 , yes), the created account may be disabled ( 320 ) or, if a pending account creation request is being processed, the account creation request may be denied. If the score does not meet the predefined criteria ( 318 , no), the spam scoring module 112 determines what action to perform based on the score ( 322 ) according to the process shown in FIG. 3E .
- the action to be performed includes at least one of: refusing the account creation request, modifying an account created in response to the account creation request (e.g., disabling the account or limiting the account access), accepting the account creation request, and maintaining the newly-created account in response to the account creation request.
- options for limiting the account access include at least one of requiring a response to a human interaction proof from the requesting client 102 for access to the account, limiting access time to the account (e.g., the user may be allowed to access the account only within a predefined time period within each day), limiting use of account functions (e.g., the user may be allowed to only receive messages delivered to the account but not send messages from the account), and limiting transmission from the account (e.g., the user may be allowed to send no more than a predefined number of messages from the account within each day).
- the spam scoring module 112 employs two or more of the schemes described above to determine multiple spam scores, each score having its own merit and sensitivity in detecting spam account generation activities.
- the spam scoring module 112 combines two or more of the multiple spam scores into a hybrid spam score using a predefined formula and gives each type of spam score an appropriate weighting factor.
- the predefined formula and the weighting factors can be determined through various experiments and heuristics.
- the hybrid spam score does not have to include all the types of spam scores described in this application, and instead may include, two, three or four of the types of spam scores described above. Alternately, or in addition, the hybrid spam score may include other types of spam scores, such as other spam scores that would be apparent in light of the present application. Similarly, the combination of the different types of spam scores does not have to be linear as shown above. Other types of combination (e.g., non-linear or piecewise linear combinations) would be possible in light of the teachings herein.
- FIG. 3E is a flow diagram of a process for performing actions in accordance with the spam scores associated with account creation requests according to some embodiments.
- some or all of the process is performed by user account module 118 of a server 106 for an online service.
- Optional operations are indicated by dashed lines or boxes having dashed-line borders.
- the user account module 118 may determine an action to perform based on the spam score being compared with a predetermined threshold ( 322 ).
- user account module 118 receives a spam score associated with an IP address from spam scoring module 112 .
- user account module 118 receives an indication from spam scoring module 112 that the spam score exceeds the predetermined threshold.
- the predetermined threshold may be a static threshold, or may be dynamically determined based on one or more criteria, such as capacity of server 106 , utilization of server 106 , and so on.
- the account creation request is accepted ( 338 ) if the spam score indicates a low to moderate likelihood that the account will be used to generate spam. If the account creation request is accepted ( 338 ), user account module 118 typically sends an account creation notice to the client 102 . The client 102 receives the account creation notice ( 344 ), if one is sent by user account module 118 .
- the account creation notice may include account terms that limit account access, in some or all of the ways described above, if the score indicates a moderate likelihood that the account will be used to generate spam.
- user account module 118 may take further action with the account generated at block 309 (if one was generated) and/or other accounts associated with the IP address.
- the account generated at block 309 (if one was generated) and/or one or more other existing accounts associated with the IP address may be maintained ( 324 ). For example, if the spam score indicates that there is a low chance that the account is used to generate spam, the account is maintained ( 324 ) without change to the terms of the account.
- the user account module 118 refuses an account creation request ( 340 ) if the corresponding spam score indicates a moderate to high likelihood that the account will be used to generate spam. If the account creation request is refused ( 340 ), user account module 118 optionally sends an account refusal notice to the client 102 , for instance via network communication module 108 . The client 102 may receive the account refusal notice ( 344 ).
- user account module 118 may take further action with the account generated at block 309 (if one was generated) and/or other accounts associated with the IP address.
- the account generated at block 309 (if one was generated) and/or one or more other existing accounts associated with the IP address may be modified ( 326 ).
- an account is modified ( 326 ) by disabling or closing the account ( 320 ) or limiting account access ( 328 ).
- Limiting account access includes one or more of: limiting use of account functions ( 330 ), requiring a response to a HIP for one or more additional account access operations associated with the account ( 332 ), limiting access time to the account ( 334 ), and limiting transmission from the account ( 336 ).
- the user account module 118 may limit account access by limiting the use of the account functions ( 330 ). For example, if the account is an email account, the use of the account functions may be limited by restricting the user's ability to send email but allowing the user to receive email. In some embodiments, the user account module 118 may require a HIP response for account access ( 332 ), including the use of some or all account functions. In some embodiments, the user account module 118 may modify the account by limiting access time to the account ( 334 ), for example to thirty minutes (or any other suitable amount of time) per day.
- the user account module 118 may modify the account by limiting transmission from the account ( 336 ), for example by permitting only ten transmissions (e.g., limiting email messages sent from the account to ten messages, and/or sending messages to no more than ten email addresses) from the account per day.
- the user account may be modified by setting the user to a “probation” state, in which any other indication of spam activity or other undesirable activity, such as a verified spam posting or a flag by another user, will cause the account to be disabled or closed.
- FIG. 4 is an example of a graphical user interface (GUI) 400 showing a form requiring a HIP test 402 according to some embodiments.
- Human interaction proof (HIP) tests are challenge-response type tests that are used to distinguish between human and computer users.
- HIPs include CAPTCHAs® (Completely Automated Public Turing tests to tell Computers and Humans Apart) available from Carnegie Mellon University, text recognition tests, image recognition tests, and the like.
- An example of an HIP test is element 402 in FIG. 4 .
- a HIP test 402 shows warped or distorted text 404 to the user that is difficult or impossible for current computers to recognize. The user is then required to input, using keyboard characters, the sequence of symbols (e.g., text or characters from a particular language) in the distorted text 404 .
- An example of a user input HIP response 210 -N is shown in FIG. 4 .
- web application 110 may limit account access by requiring a response to a HIP test 402 in order to access the account ( 332 ).
- a user may be required to send a response to a HIP test 210 -N, along with User ID 204 -N, password 206 -N, and secondary email address 208 -N associated with the account in order to login if the spam score meets a predetermined threshold.
- the user may be required to provide more or less information.
- FIG. 5 is an example of a GUI 500 showing an account creation form 502 according to some embodiments.
- Account creation form 502 may include fields for the user's first name 504 , last name 506 , and desired login name 508 .
- account creation form 502 includes a button 510 allowing the user to check the availability of desired login name 508 .
- the account creation form 502 may also include fields for the user to choose a password 512 , confirm the password 514 , choose a security question 516 , answer the security question 518 , provide a secondary email address, such as secondary email address 208 -N, and indicate the user's geographic location 520 .
- the web application 110 requires the user to agree to the terms of service 522 , program policy, and privacy policy in order to submit the account request form 502 with the button 524 .
- the account creation form may include more or fewer fields and buttons, require answers to some or all fields, or include a HIP test 402 .
- FIG. 6 is a block diagram of a client 102 according to some embodiments.
- the client 102 of FIG. 6 may be the client participant in any of the methods and systems described above.
- the client 102 typically includes one or more processing units (CPUs) 602 , one or more network or other communications interfaces 604 , memory 606 , and one or more communication buses 608 for interconnecting these components.
- the communication buses 608 may include circuitry (sometimes called a chipset) that interconnects and controls communications between system components.
- the client 102 optionally includes a user interface 610 , which optionally includes a display 612 and a keyboard 614 .
- Memory 606 includes high-speed random access memory, such as DRAM, SRAM, DDR RAM or other random access solid state memory devices; and may include non-volatile memory, such as one or more magnetic disk storage devices, optical disk storage devices, flash memory devices, or other non-volatile solid state storage devices. Memory 606 may optionally include one or more storage devices remotely located from the CPU(s) 602 . Memory 606 , or alternately non-volatile memory device(s) of memory 606 , comprises a computer readable storage medium. In some embodiments, memory 606 or the computer readable storage medium of memory 606 stores the following programs, modules and data structures, or a subset thereof:
- FIG. 7 is a block diagram of a server system 106 according to some embodiments.
- the server system 106 of FIG. 7 may be the server participant in any of the methods and systems described above.
- Server system 106 (sometimes called an online service, or online service system or online application system) typically includes one or more processing units (CPUs) 702 , one or more network or other communications interfaces 704 , memory 706 , and one or more communication buses 708 for interconnecting these components.
- the communication buses 708 may include circuitry (sometimes called a chipset) that interconnects and controls communications between system components.
- the server system 106 may optionally include a user interface, for instance a display and a keyboard.
- Memory 706 includes high-speed random access memory, such as DRAM, SRAM, DDR RAM or other random access solid state memory devices; and may include non-volatile memory, such as one or more magnetic disk storage devices, optical disk storage devices, flash memory devices, or other non-volatile solid state storage devices. Memory 706 may optionally include one or more storage devices remotely located from the CPU(s) 702 . Memory 706 , or one or more of the non-volatile memory devices in memory 806 comprise a computer readable storage medium that stores one or more programs for execution by one or more processors. In some embodiments, memory 706 or the computer readable storage medium of memory 706 stores the following programs, modules and data structures, or a subset thereof:
Abstract
Description
where ThirdCount is the number of new accounts created one day before the currently pending account creation request, FourthCount is the number of new accounts created two days before the currently pending account creation request, (n+2)thCount is the number of new accounts created n days before the currently pending account creation request, and n is a whole number equal to the number of days over which the number of new accounts created from the IP address per day is being averaged (also called the “time period”). Optionally, the denominator of the equation (see Eq. 1, above) for computing the first count is equal to
(i.e., the sum of the weights applied to the counts), instead of n. More generally, the first count is an average or time weighted average, over a time period, of new accounts created from the IP address per time interval, where the time period is equal to two or more time intervals (e.g., a multiple of the time interval). For example, the first count may be the average (or time weighted average) number of new accounts created daily from an IP address over a week, a month, or a year.
where “AccessOps on New Accounts” is a count (e.g., a fifth count) of account access operations (over a predefined period of time) on new accounts associated with the IP address, created within a predefined time interval, such as the last week or N days, C2 is a constant or coefficient having a predefined value greater than one, and “AccessOps on Older Accounts” is a count (e.g., a sixth count) of account access operations (over the predefined period of time) on older accounts associated with the IP address, created prior to the predefined interval. C2 is greater than one so as to give account access operations on older accounts (created during a less recent time interval) more importance than account access operations on new accounts (created during a recent time interval). Account access operations on older accounts is an indicator of legitimate (non-spammy) accounts associated with the IP address. In some embodiments, the second count is a count of account access operations (over the predefined period of time) only on older accounts associated with the IP address, created prior to a predefined interval.
ScoreIP
where W1 is a weighting factor of the IP address related score if the score is to be combined with the other types of spam scores, such as one or more of the other spam scores described below. In some embodiments, the value of W1 is chosen such that there is an appropriate ratio between the IP address-based spam score and the other types of spam scores. For example, W1 may range from 1 to 50.
ScorePassword =W2*(PasswordCount/PasswordPopularityValue)
where W2 is a weighting factor if the score is to be combined with the other types of spam scores, such as one or more of the other spam scores described in this application. In some embodiments, the value of W2 is chosen in light of the other weighting factors, such as W1 described above, such that there is an appropriate ratio between the password-based spam score and the other types of spam scores.
ScoreCookie =W3*CookieCount
where W3 is a weighting factor if the score is to be combined with the other types of spam scores, such as one or more of the other spam scores described in this application. In some embodiments, the value of W3 is chosen in light of the other weighting factors such as W1 and W2 described above such that there is an appropriate ratio between the cookie-based spam score and the other types of spam scores. In some embodiments, W3 is equal to zero when CookieCount is less than a threshold value and is equal to a non-zero value otherwise. In yet other embodiments, ScoreCookie is equal to W3 times a predefined function of CookieCount, where the predefined function is a linear or non-linear function of CookieCount (e.g., a piecewise linear function which is equal to zero below a first threshold, and which linearly or non-linearly increases from a starting value when CookieCount is above the first threshold).
ScoreHIP =W4*(Average_HIPResponseTime/HIPResponseTime)
where W4 is a weighting factor if the score is to be combined with the other types of spam scores, such as one or more of the other spam scores described in this application. In some embodiments, the value of W4 is chosen in light of the other weighting factors such as W1, W2, and W3 described above such that there is an appropriate ratio between the HIP-based spam score and the other types of spam scores. In some embodiments, ScoreHIP is equal to W4 times a predefined function of Average_HIPResponse Time and HIPResponse Time, where the predefined function is a linear or non-linear function of HIPResponse Time and HIPResponse Time (e.g., a piecewise linear function).
Response | |||
Time (Seconds) | HIPScore | ||
>15 | 0 (legitimate) | ||
11-15 | 1 (suspicious) | ||
10 | 2 | ||
9 | 3 | ||
8 | 4 | ||
7 | 5 | ||
1-6 | 10 (unusually fast, highly | ||
indicative of a spammer) | |||
ScoreUsername =W5*UsernameCount
where W5 is a weighting factor if the score is to be combined with the other types of spam scores, such as one or more of the other spam scores described in this application. In some embodiments, the value of W5 is chosen in light of the other weighting factors such as W1, W2, W3, and W4 described above such that there is an appropriate ratio between the Username-based spam score and the other types of spam scores.
Spam_Score=ScoreIP
-
- an
operating system 616 that includes procedures for handling various basic system services and for performing hardware dependent tasks; - a
network communication module 618 that is used for connecting theclient 102 to other computers via the one or more communication network interfaces 604 and one ormore communication networks 104, such as the Internet, other wide area networks, local area networks, metropolitan area networks, and the like; - a client application 132 (e.g., a browser application) that enables a user to interact with the
client 102 and to access remotely located resources via the one ormore communication networks 104, as described above; and - a
GUI 134 for displaying information.
- an
-
- an
operating system 710 that includes procedures for handling various basic system services and for performing hardware dependent tasks; - a
network communication module 108 that is used for connecting theserver system 106 to other servers or computers (e.g., clients) via one ormore communications interfaces 704 and one or more communication networks (wired or wireless) (such as communication network 104), such as the Internet, other wide area networks, local area networks, metropolitan area networks, and so on; - a
web application 110 that provides services to users with user accounts 122; - a
spam scoring module 112 that assigns scores to user accounts; - an
inverse IP index 114 for storing data regarding the user accounts in records associated with respective IP addresses, including the number of user accounts associated with each IP address; - a
user account database 116 for storing data regarding the user accounts, including new account requests and account access operations in user records associated with respective user accounts; and - a
user account module 118 for managing user accounts 122 for theweb application 110; theuser account module 118 may include aregistration module 120 for creating new user accounts as described above.
- an
Claims (20)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US12/648,246 US8646077B1 (en) | 2008-12-29 | 2009-12-28 | IP address based detection of spam account generation |
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14120408P | 2008-12-29 | 2008-12-29 | |
US12/648,246 US8646077B1 (en) | 2008-12-29 | 2009-12-28 | IP address based detection of spam account generation |
Publications (1)
Publication Number | Publication Date |
---|---|
US8646077B1 true US8646077B1 (en) | 2014-02-04 |
Family
ID=49640956
Family Applications (3)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US12/648,258 Active 2032-01-02 US8601548B1 (en) | 2008-12-29 | 2009-12-28 | Password popularity-based limiting of online account creation requests |
US12/648,246 Active 2031-09-30 US8646077B1 (en) | 2008-12-29 | 2009-12-28 | IP address based detection of spam account generation |
US12/648,251 Active 2030-12-22 US8601547B1 (en) | 2008-12-29 | 2009-12-28 | Cookie-based detection of spam account generation |
Family Applications Before (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US12/648,258 Active 2032-01-02 US8601548B1 (en) | 2008-12-29 | 2009-12-28 | Password popularity-based limiting of online account creation requests |
Family Applications After (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US12/648,251 Active 2030-12-22 US8601547B1 (en) | 2008-12-29 | 2009-12-28 | Cookie-based detection of spam account generation |
Country Status (1)
Country | Link |
---|---|
US (3) | US8601548B1 (en) |
Cited By (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20120066034A1 (en) * | 2010-09-10 | 2012-03-15 | Appredeem, Inc. | Online account to mobile device link |
US20140373139A1 (en) * | 2013-06-13 | 2014-12-18 | Alibaba Group Holding Limited | Method and system of distinguishing between human and machine |
RU2693325C2 (en) * | 2017-07-26 | 2019-07-02 | Общество С Ограниченной Ответственностью "Яндекс" | Method and system for detecting actions potentially associated with spamming in account registration |
US11108752B2 (en) * | 2013-08-29 | 2021-08-31 | Verizon Media Inc. | Systems and methods for managing resetting of user online identities or accounts |
Families Citing this family (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9094389B2 (en) * | 2013-09-04 | 2015-07-28 | Facebook, Inc. | Systems and methods for authenticating nodes |
US9148424B1 (en) * | 2015-03-13 | 2015-09-29 | Snapchat, Inc. | Systems and methods for IP-based intrusion detection |
US20180218134A1 (en) * | 2017-01-27 | 2018-08-02 | Microsoft Technology Licensing, Llc | Determining computer ownership |
US9781160B1 (en) * | 2017-05-31 | 2017-10-03 | KnowBe4, Inc. | Systems and methods for discovering suspect bot IP addresses and using validated bot IP address to ignore actions in a simulated phishing environment |
US20220147613A1 (en) * | 2019-07-19 | 2022-05-12 | Hewlett-Packard Development Company, L.P. | Automatic password expiration based on password integrity |
WO2021015713A1 (en) * | 2019-07-19 | 2021-01-28 | Hewlett-Packard Development Company, L.P. | Password integrity scoring |
CN110324360A (en) * | 2019-08-02 | 2019-10-11 | 联永智能科技（上海）有限公司 | Offline cryptogram setting, management method, device, system, server and medium |
Citations (29)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20040249789A1 (en) * | 2003-06-04 | 2004-12-09 | Microsoft Corporation | Duplicate data elimination system |
US20050021649A1 (en) * | 2003-06-20 | 2005-01-27 | Goodman Joshua T. | Prevention of outgoing spam |
US20050076230A1 (en) | 2003-10-02 | 2005-04-07 | George Redenbaugh | Fraud tracking cookie |
US20060149820A1 (en) | 2005-01-04 | 2006-07-06 | International Business Machines Corporation | Detecting spam e-mail using similarity calculations |
US20060168006A1 (en) | 2003-03-24 | 2006-07-27 | Mr. Marvin Shannon | System and method for the classification of electronic communication |
US7117528B1 (en) | 2002-10-24 | 2006-10-03 | Microsoft Corporation | Contested account registration |
US20070100929A1 (en) | 2005-10-27 | 2007-05-03 | International Business Machines Corporation | Method, system and program storage device for assigning unique identification numbers to new user accounts and groups in a computing environment with multiple registries |
US20070208868A1 (en) | 2006-03-03 | 2007-09-06 | Kidd John T | Electronic Communication Relationship Management System And Methods For Using The Same |
US20080034424A1 (en) | 2006-07-20 | 2008-02-07 | Kevin Overcash | System and method of preventing web applications threats |
US7337324B2 (en) | 2003-12-01 | 2008-02-26 | Microsoft Corp. | System and method for non-interactive human answerable challenges |
US20080140781A1 (en) * | 2006-12-06 | 2008-06-12 | Microsoft Corporation | Spam filtration utilizing sender activity data |
US20080244021A1 (en) | 2007-04-02 | 2008-10-02 | Chin Fang | Spam resistant e-mail system |
US20090044264A1 (en) | 2007-08-07 | 2009-02-12 | Microsoft Corporation | Spam reduction in real time communications by human interaction proof |
US20090204820A1 (en) | 2008-01-30 | 2009-08-13 | Brandenburg Wes G | Method and apparatus for Account Management |
US20090241174A1 (en) | 2008-02-19 | 2009-09-24 | Guru Rajan | Handling Human Detection for Devices Connected Over a Network |
US7606918B2 (en) * | 2004-04-27 | 2009-10-20 | Microsoft Corporation | Account creation via a mobile device |
US20090300720A1 (en) * | 2008-05-30 | 2009-12-03 | Microsoft Corporation | Centralized account reputation |
US20090307313A1 (en) * | 2008-06-04 | 2009-12-10 | Tak Yin Wang | System and method for determining spam |
US20090319274A1 (en) | 2008-06-23 | 2009-12-24 | John Nicholas Gross | System and Method for Verifying Origin of Input Through Spoken Language Analysis |
US20090328163A1 (en) | 2008-06-28 | 2009-12-31 | Yahoo! Inc. | System and method using streaming captcha for online verification |
US7657935B2 (en) * | 2001-08-16 | 2010-02-02 | The Trustees Of Columbia University In The City Of New York | System and methods for detecting malicious email transmission |
US20100077043A1 (en) * | 2008-09-19 | 2010-03-25 | Yahoo! Inc. | Detecting spam from a bulk registered e-mail account |
US20100115040A1 (en) | 2008-09-30 | 2010-05-06 | James Sargent | Systems And Methods For Creating And Updating Reputation Records |
US7725421B1 (en) * | 2006-07-26 | 2010-05-25 | Google Inc. | Duplicate account identification and scoring |
US20100287484A1 (en) | 2004-07-19 | 2010-11-11 | The Go Daddy Group, Inc. | Notification system and method for domain name options |
US20100299326A1 (en) | 2007-10-26 | 2010-11-25 | Scott Germaise | Apparatuses, Methods and Systems For A Forum Ferreting System |
US7877800B1 (en) | 2005-12-19 | 2011-01-25 | Symantec Corporation | Preventing fraudulent misdirection of affiliate program cookie tracking |
US7899759B1 (en) | 2004-01-05 | 2011-03-01 | Heggem Richard A | Obtaining reliable information about a seller's practices |
US20110214169A1 (en) | 2002-04-25 | 2011-09-01 | Intertrust Technologies Corp. | Secure Authentication Systems and Methods |
Family Cites Families (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
AU5301700A (en) * | 1999-05-28 | 2000-12-18 | Coca-Cola Company, The | Method and apparatus for surrogate control of network-based electronic transactions |
US6404866B1 (en) * | 1999-11-09 | 2002-06-11 | Vesta Corporation | Telephone calling account system and method |
US7672998B1 (en) * | 2000-05-16 | 2010-03-02 | Ziplink, Inc. | Apparatus and methods for controlling the transmission of messages |
US7467411B2 (en) * | 2004-08-27 | 2008-12-16 | Astav, Inc. | Protecting a service provider from abuse |
US7603435B2 (en) * | 2006-11-15 | 2009-10-13 | Palm, Inc. | Over-the-air device kill pill and lock |
US8069210B2 (en) * | 2008-10-10 | 2011-11-29 | Microsoft Corporation | Graph based bot-user detection |
US8381291B2 (en) * | 2009-12-10 | 2013-02-19 | At&T Intellectual Property I, L.P. | Methods, systems, and computer program products for mitigating email address harvest attacks by positively acknowledging email to invalid email addresses |
-
2009
- 2009-12-28 US US12/648,258 patent/US8601548B1/en active Active
- 2009-12-28 US US12/648,246 patent/US8646077B1/en active Active
- 2009-12-28 US US12/648,251 patent/US8601547B1/en active Active
Patent Citations (31)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7657935B2 (en) * | 2001-08-16 | 2010-02-02 | The Trustees Of Columbia University In The City Of New York | System and methods for detecting malicious email transmission |
US20110214169A1 (en) | 2002-04-25 | 2011-09-01 | Intertrust Technologies Corp. | Secure Authentication Systems and Methods |
US7117528B1 (en) | 2002-10-24 | 2006-10-03 | Microsoft Corporation | Contested account registration |
US20060168006A1 (en) | 2003-03-24 | 2006-07-27 | Mr. Marvin Shannon | System and method for the classification of electronic communication |
US20040249789A1 (en) * | 2003-06-04 | 2004-12-09 | Microsoft Corporation | Duplicate data elimination system |
US20050021649A1 (en) * | 2003-06-20 | 2005-01-27 | Goodman Joshua T. | Prevention of outgoing spam |
US20050076230A1 (en) | 2003-10-02 | 2005-04-07 | George Redenbaugh | Fraud tracking cookie |
US7337324B2 (en) | 2003-12-01 | 2008-02-26 | Microsoft Corp. | System and method for non-interactive human answerable challenges |
US7899759B1 (en) | 2004-01-05 | 2011-03-01 | Heggem Richard A | Obtaining reliable information about a seller's practices |
US7606918B2 (en) * | 2004-04-27 | 2009-10-20 | Microsoft Corporation | Account creation via a mobile device |
US20100287484A1 (en) | 2004-07-19 | 2010-11-11 | The Go Daddy Group, Inc. | Notification system and method for domain name options |
US20060149820A1 (en) | 2005-01-04 | 2006-07-06 | International Business Machines Corporation | Detecting spam e-mail using similarity calculations |
US20070100929A1 (en) | 2005-10-27 | 2007-05-03 | International Business Machines Corporation | Method, system and program storage device for assigning unique identification numbers to new user accounts and groups in a computing environment with multiple registries |
US7877800B1 (en) | 2005-12-19 | 2011-01-25 | Symantec Corporation | Preventing fraudulent misdirection of affiliate program cookie tracking |
US20070208868A1 (en) | 2006-03-03 | 2007-09-06 | Kidd John T | Electronic Communication Relationship Management System And Methods For Using The Same |
US20080034424A1 (en) | 2006-07-20 | 2008-02-07 | Kevin Overcash | System and method of preventing web applications threats |
US7725421B1 (en) * | 2006-07-26 | 2010-05-25 | Google Inc. | Duplicate account identification and scoring |
US20080140781A1 (en) * | 2006-12-06 | 2008-06-12 | Microsoft Corporation | Spam filtration utilizing sender activity data |
US20080244021A1 (en) | 2007-04-02 | 2008-10-02 | Chin Fang | Spam resistant e-mail system |
US20090044264A1 (en) | 2007-08-07 | 2009-02-12 | Microsoft Corporation | Spam reduction in real time communications by human interaction proof |
US20100299326A1 (en) | 2007-10-26 | 2010-11-25 | Scott Germaise | Apparatuses, Methods and Systems For A Forum Ferreting System |
US20090204820A1 (en) | 2008-01-30 | 2009-08-13 | Brandenburg Wes G | Method and apparatus for Account Management |
US20090241174A1 (en) | 2008-02-19 | 2009-09-24 | Guru Rajan | Handling Human Detection for Devices Connected Over a Network |
US20090300720A1 (en) * | 2008-05-30 | 2009-12-03 | Microsoft Corporation | Centralized account reputation |
US20090307313A1 (en) * | 2008-06-04 | 2009-12-10 | Tak Yin Wang | System and method for determining spam |
US20090319271A1 (en) | 2008-06-23 | 2009-12-24 | John Nicholas Gross | System and Method for Generating Challenge Items for CAPTCHAs |
US20090319274A1 (en) | 2008-06-23 | 2009-12-24 | John Nicholas Gross | System and Method for Verifying Origin of Input Through Spoken Language Analysis |
US20090328163A1 (en) | 2008-06-28 | 2009-12-31 | Yahoo! Inc. | System and method using streaming captcha for online verification |
US20100077040A1 (en) | 2008-09-19 | 2010-03-25 | Yahoo! Inc. | Detection of outbound sending of spam |
US20100077043A1 (en) * | 2008-09-19 | 2010-03-25 | Yahoo! Inc. | Detecting spam from a bulk registered e-mail account |
US20100115040A1 (en) | 2008-09-30 | 2010-05-06 | James Sargent | Systems And Methods For Creating And Updating Reputation Records |
Cited By (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20120066034A1 (en) * | 2010-09-10 | 2012-03-15 | Appredeem, Inc. | Online account to mobile device link |
US20140373139A1 (en) * | 2013-06-13 | 2014-12-18 | Alibaba Group Holding Limited | Method and system of distinguishing between human and machine |
US9529999B2 (en) * | 2013-06-13 | 2016-12-27 | Alibaba Group Holding Limited | Method and system of distinguishing between human and machine |
US20170078318A1 (en) * | 2013-06-13 | 2017-03-16 | Alibaba Group Holding Limited | Method and system of distinguishing between human and machine |
US10356114B2 (en) * | 2013-06-13 | 2019-07-16 | Alibaba Group Holding Limited | Method and system of distinguishing between human and machine |
US11108752B2 (en) * | 2013-08-29 | 2021-08-31 | Verizon Media Inc. | Systems and methods for managing resetting of user online identities or accounts |
RU2693325C2 (en) * | 2017-07-26 | 2019-07-02 | Общество С Ограниченной Ответственностью "Яндекс" | Method and system for detecting actions potentially associated with spamming in account registration |
Also Published As
Publication number | Publication date |
---|---|
US8601547B1 (en) | 2013-12-03 |
US8601548B1 (en) | 2013-12-03 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US8646077B1 (en) | IP address based detection of spam account generation | |
US8949948B2 (en) | Determining a trust level of a user in a social network environment | |
Workman | Wisecrackers: A theory‐grounded investigation of phishing and pretext social engineering threats to information security | |
US9565235B2 (en) | System and method for controlling access to internet sites | |
JP5775003B2 (en) | Using social information to authenticate user sessions | |
US9311679B2 (en) | Enterprise social media management platform with single sign-on | |
US9424612B1 (en) | Systems and methods for managing user reputations in social networking systems | |
Crossler et al. | Robbing Peter to pay Paul: Surrendering privacy for security’s sake in an identity ecosystem | |
US10432615B2 (en) | Aggregator technology without usernames and passwords implemented in unified risk scoring | |
Bhatnagar et al. | Student Attitudes, Awareness, and Perceptions of Personal Privacy and Cybersecurity in the Use of Social Media: An Initial Study. | |
Renaud et al. | Cyber security responsibilization: an evaluation of the intervention approaches adopted by the Five Eyes countries and China | |
Xia et al. | Privacy in Crowdsourcing: a Review of the Threats and Challenges | |
Wiefling et al. | What’s in score for website users: A data-driven long-term study on risk-based authentication characteristics | |
Aïmeur et al. | Upp: User privacy policy for social networking sites | |
Hossain et al. | Privacy and security concern of online social networks from user perspective | |
KR101086452B1 (en) | System for identity management with privacy policy using number and method thereof | |
Galpin et al. | Online social networks: Enhancing user trust through effective controls and identity management | |
Laurent et al. | Privacy management and protection of personal data | |
Douglas | Should Internet Researchers Use Ill-Gotten Information? | |
RU2786353C1 (en) | System and method for providing content to the user | |
Dillard | Privacy and security implications of undergraduate students using Facebook: A quantitative examination | |
Almotiri | Security & Privacy Awareness & Concerns of Computer Users Posed by Web Cookies and Trackers | |
Ashetakr et al. | 5 Users’ privacy at online social networks in Indian context: comprehensive multiaged group survey and discussion | |
KR102567355B1 (en) | System for providing data portability based personal information sharing platform service | |
US11068467B2 (en) | Apparatus and method to create secure data blocks to validate an information source |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:SHEN, HONGHAI;REEL/FRAME:023873/0128Effective date: 20091228 |
|
FEPP | Fee payment procedure |
Free format text: PAYOR NUMBER ASSIGNED (ORIGINAL EVENT CODE: ASPN); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
FPAY | Fee payment |
Year of fee payment: 4 |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044101/0299Effective date: 20170929 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 8TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1552); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 8 |