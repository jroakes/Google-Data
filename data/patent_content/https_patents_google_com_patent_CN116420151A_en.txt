CN116420151A - Universal package for learning from tag proportions - Google Patents
Universal package for learning from tag proportions Download PDFInfo
- Publication number
- CN116420151A CN116420151A CN202280005333.6A CN202280005333A CN116420151A CN 116420151 A CN116420151 A CN 116420151A CN 202280005333 A CN202280005333 A CN 202280005333A CN 116420151 A CN116420151 A CN 116420151A
- Authority
- CN
- China
- Prior art keywords
- data
- computing system
- tag
- packets
- training
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
- 238000012549 training Methods 0.000 claims abstract description 170
- 238000000034 method Methods 0.000 claims abstract description 163
- 238000010801 machine learning Methods 0.000 claims abstract description 127
- 238000009826 distribution Methods 0.000 claims description 79
- 239000013598 vector Substances 0.000 claims description 23
- 238000005070 sampling Methods 0.000 claims description 14
- 239000011159 matrix material Substances 0.000 claims description 12
- 230000004044 response Effects 0.000 claims description 5
- 230000002596 correlated effect Effects 0.000 abstract description 5
- 230000008569 process Effects 0.000 description 51
- 230000003993 interaction Effects 0.000 description 24
- 238000012545 processing Methods 0.000 description 24
- 238000013528 artificial neural network Methods 0.000 description 19
- 230000015654 memory Effects 0.000 description 16
- 230000000875 corresponding effect Effects 0.000 description 10
- 238000004891 communication Methods 0.000 description 7
- 230000006870 function Effects 0.000 description 7
- 230000000007 visual effect Effects 0.000 description 7
- 238000013480 data collection Methods 0.000 description 5
- 230000000306 recurrent effect Effects 0.000 description 5
- 230000008901 benefit Effects 0.000 description 4
- 238000011156 evaluation Methods 0.000 description 4
- 230000004048 modification Effects 0.000 description 4
- 238000012986 modification Methods 0.000 description 4
- 238000004458 analytical method Methods 0.000 description 3
- 238000013527 convolutional neural network Methods 0.000 description 3
- 230000007246 mechanism Effects 0.000 description 3
- 238000013519 translation Methods 0.000 description 3
- 238000013459 approach Methods 0.000 description 2
- 238000000354 decomposition reaction Methods 0.000 description 2
- 238000001514 detection method Methods 0.000 description 2
- 238000005516 engineering process Methods 0.000 description 2
- 238000003709 image segmentation Methods 0.000 description 2
- 230000007787 long-term memory Effects 0.000 description 2
- 238000005259 measurement Methods 0.000 description 2
- 238000012544 monitoring process Methods 0.000 description 2
- 230000011218 segmentation Effects 0.000 description 2
- 230000006403 short-term memory Effects 0.000 description 2
- 230000009466 transformation Effects 0.000 description 2
- 238000000844 transformation Methods 0.000 description 2
- 230000009471 action Effects 0.000 description 1
- 238000007792 addition Methods 0.000 description 1
- 230000004075 alteration Effects 0.000 description 1
- 230000006399 behavior Effects 0.000 description 1
- 230000005540 biological transmission Effects 0.000 description 1
- 230000008859 change Effects 0.000 description 1
- 238000006243 chemical reaction Methods 0.000 description 1
- 238000007906 compression Methods 0.000 description 1
- 230000006835 compression Effects 0.000 description 1
- 238000013144 data compression Methods 0.000 description 1
- 238000013500 data storage Methods 0.000 description 1
- 238000010586 diagram Methods 0.000 description 1
- 230000000694 effects Effects 0.000 description 1
- 238000001914 filtration Methods 0.000 description 1
- 230000006872 improvement Effects 0.000 description 1
- 238000002372 labelling Methods 0.000 description 1
- 238000007726 management method Methods 0.000 description 1
- 230000003287 optical effect Effects 0.000 description 1
- 230000001105 regulatory effect Effects 0.000 description 1
- 230000002040 relaxant effect Effects 0.000 description 1
- 230000001960 triggered effect Effects 0.000 description 1
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/084—Backpropagation, e.g. using gradient descent
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/088—Non-supervised learning, e.g. competitive learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/09—Supervised learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/044—Recurrent networks, e.g. Hopfield networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/045—Combinations of networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/0464—Convolutional networks [CNN, ConvNet]
Abstract
Example aspects of the present disclosure relate to an example method. The example method includes obtaining, by a computing system including one or more processors, a plurality of data packets. In an example method, each respective data packet of the plurality of data packets includes a respective plurality of instances and is associated with one or more proportional labels, respectively. The example method also includes generating, by the computing system, a plurality of training packets from the plurality of data packets according to the plurality of weights. In an example method, training packets are generated such that packet-level prediction scaling tag errors of a machine-learning prediction model over a plurality of training packets are correlated with instance-level prediction scaling tag errors of the machine-learning prediction model.
Description
RELATED APPLICATIONS
The present application is based on and claims the priority and benefit of indian provisional patent application No. 202121050228 filed on month 11 and 2 of 2021, which is incorporated herein by reference in its entirety.
Technical Field
The present disclosure relates generally to training machine-learning models (machine-assisted models). More particularly, aspects of the present disclosure relate to training a machine learning model using label proportions (Proportions).
Background
In general, machine learning models can be trained to use labeled (labeled) instances of similar items to infer information about the items. However, in some weakly labeled data sets, instance-level labels may not be available. For example, in some weakly labeled data sets, a collection or "bag" of instances may only be labeled as containing a specified proportion of instances associated with the label. It may still be necessary to train a machine learning model to generate instance-level reasoning.
For example, in some real world systems, data may only be collected without assigning tags to individual items. A single item (or "instance") may not be tagged (or may have an incomplete tag), but a collection (or "package") containing instances may be tagged with ratio data indicating the relative ratio of tags represented in the package. For example, a packet of unlabeled examples may contain scale data indicating that a portion has a first label (e.g., indicating that a portion of the example is positive for a certain characteristic), and for a dataset having multiple labels, the corresponding scale for each label may also be indicated.
For example, in implementations where data collection capacity is limited, data with a tagged proportion may appear. For example, the data collection capability may be limited by instrument accuracy or error, instrument capability, experimental or viewing constraints, feasibility or policy constraints, cost constraints (e.g., computational cost, data collection cost, etc.), and the like. The tagging capability may also be limited because in some cases, individual tagged data for any one instance or set of instances may not exist, be unknown, or even unknown, while relative proportion data may be more readily available (e.g., known or estimated probabilities using statistics or other models, themes, batch estimations, rough manual processing, etc.).
Various existing approaches to learning from tag proportions disadvantageously rely on several limiting assumptions that hinder real-world implementation. For example, some previous approaches rely on classification condition independence assumptions-e.g., examples in each package are not related to each other via their features. However, real world behavior is often relevant: as one example, a user of an automobile website that interacts with content related to one automobile may also tend to interact with content related to a competitor automobile, and thus data related to the interaction will likely be relevant. In another example, some existing methods rely on hypothetical discontinuity properties, e.g., instances happen to occur in one package, and thus have equal representations. However, in some real world implementations, the instances may not have equal representations: as one example, a few instance categories in a dataset may appear in several or only one package (e.g., showing long-tail category membership distributions), while other more instance categories may appear in multiple or many packages. Furthermore, in some real world implementations, a small subset of packets may inherently have a large number of instances, while there is also a larger subset of packets (e.g., showing long tail packet size distribution). For example, as one example, the flight telemetry of a popular route may correspond to a larger package than the flight telemetry of a less popular route. The learning result will be different for each packet due to the diversity of packet sizes.
Disclosure of Invention
Aspects and advantages of embodiments of the disclosure will be set forth in part in the description which follows, or may be learned from the description, or may be learned by practice of the embodiments.
In one example aspect, the present disclosure provides an example method. The example method includes obtaining, by a computing system including one or more processors, a plurality of data packets. In an example method, each respective data packet of the plurality of data packets includes a respective plurality of instances and is associated with one or more proportional labels, respectively. The example method includes generating, by a computing system, a plurality of generic training packets from a plurality of data packets according to a plurality of weights. In an example method, a generic training packet is generated such that a packet-level prediction scaling tag error of a machine-learning prediction model over a plurality of training packets is correlated with an instance-level prediction scaling tag error of the machine-learning prediction model.
In some embodiments, an example method includes obtaining, by a computing system, a plurality of untagged runtime instances. In some embodiments, the example method includes generating, by the computing system and using the machine-learned prediction model, output data describing the one or more untagged runtime instances and tags associated therewith. In some embodiments, an example method includes querying, by a computing system, output data with a query tag. In some embodiments, an example method includes returning, by a computing system, data describing a subset of output data associated with a query tag. In some embodiments of example methods, the output data includes a data store identified as an instance related to the query tag. In some embodiments of the example method, the machine-learned prediction model is configured to retrieve one or more of the unlabeled runtime instances related to the query tag.
In some embodiments, an example method includes inputting, by a computing system, input data based at least in part on a plurality of generic training packets into a machine learning predictive model; obtaining, by a computing system, a packet level prediction scaling tag error; and updating, by the computing system, one or more parameters of the machine-learned prediction model based at least in part on the packet-level prediction scale tag error.
In some embodiments, an example method includes determining, by a computing system, a weight distribution for generating a plurality of generic training packets from a plurality of data packets. In some embodiments, the example method further comprises, for each respective generic training packet of the plurality of generic training packets: (i) Sampling, by the computing system, a plurality of weights from the weight distribution; (ii) Sampling, by the computing system, a plurality of data packets from a distribution of data packets; and (iii) outputting, by the computing system, the respective generic training packet based at least in part on the plurality of weights and the plurality of data packets.
In one example aspect, the present disclosure provides an example system. The example system includes one or more processors and one or more storage devices. The one or more memory devices store computer-readable instructions that, when implemented, cause the one or more processors to perform operations. These operations include obtaining a plurality of data packets. In an example system, each respective data packet of the plurality of data packets includes a respective plurality of instances and is respectively associated with one or more proportional labels. The operations include generating a plurality of generic training packets from a plurality of data packets according to a plurality of weights. In an example system, a generic training package is generated such that a package-level prediction scaling tag error of a machine-learning prediction model over a plurality of training packages is correlated with an instance-level prediction scaling tag error of the machine-learning prediction model.
In one example aspect, the present disclosure provides an example computer-readable medium storing computer-readable instructions for causing one or more processors to perform operations. These operations include obtaining a plurality of data packets. In an example system, each respective data packet of the plurality of data packets includes a respective plurality of instances and is respectively associated with one or more proportional labels. The operations include generating a plurality of generic training packets from a plurality of data packets according to a plurality of weights. In an example system, a generic training package is generated such that a package-level prediction scaling tag error of a machine-learning prediction model over a plurality of training packages is correlated with an instance-level prediction scaling tag error of the machine-learning prediction model.
These and other features, aspects, and advantages of various embodiments of the present disclosure will become better understood with reference to the following description and appended claims. The accompanying drawings, which are incorporated in and constitute a part of this specification, illustrate exemplary embodiments of the disclosure and together with the description, serve to explain the principles of interest.
Drawings
A detailed discussion of embodiments directed to one of ordinary skill in the art is set forth in the specification in reference to the accompanying drawings, wherein:
FIG. 1 depicts an example system 100 for learning from a generic training package in accordance with an example aspect of the present disclosure;
FIG. 2 depicts an example embodiment of a model trainer for learning from a generic training package in accordance with an example aspect of the present disclosure;
FIG. 3 depicts an example processing system 300 for learning from a generic training package in accordance with an example aspect of the present disclosure;
FIG. 4 depicts a flowchart of an example method for learning from a generic training package, in accordance with an example aspect of the present disclosure; and
fig. 5 depicts a flowchart of another example method for learning from a generic training package in accordance with an example aspect of the present disclosure.
Repeated reference characters in the drawings are intended to represent like features in the various embodiments.
Detailed Description
SUMMARY
In general, the present disclosure relates to techniques for training a machine learning model using an input dataset with labeled scale by converting the input dataset into a generic intermediate representation prior to training. Example systems and methods according to example aspects of the present disclosure enable and support machine learning based on weakly labeled real world datasets by generating well behaved training datasets from the real world datasets.
Advantageously, embodiments in accordance with example aspects of the present disclosure may convert a set of training packages (e.g., containing real world data) to produce a generic set of training packages that conform to a set of desired criteria. For example, in some embodiments, the criteria may include characteristics of a desired training package distribution to mitigate and/or eliminate challenges presented by real world data distribution. In this way, for example, generic training packages can be obtained to better train the model to generate improved instance-level reasoning (e.g., even in the absence of instance-level training data).
Example systems and methods according to example aspects of the present disclosure may provide various technical effects and benefits. For example, in some embodiments, example systems and methods can use machine learning models in environments where data is limited, which would otherwise lack sufficient data to train an effective machine learning model. In some embodiments, by providing learning from a real-world dataset, example systems and methods may allow training data to be generated (e.g., tagged) in less time, effort, and/or expense (e.g., computational expense), for which scaling data may be obtained (e.g., retrieved, generated, etc.). For example, by overcoming various dependencies of limiting assumptions on underlying input data, example systems and methods may extend the capabilities of machine learning computing systems to operate and function efficiently in the real world using real world input data sets.
In some embodiments, example systems and methods according to example aspects of the present disclosure may provide improved storage, management, retrieval, and cross-referencing of data structures in memory (e.g., in a database). For example, an example database may contain real world data structures describing various untagged instances. The example database (or another database) may also contain data structure packages describing real world instances, which packages are labeled with tag proportions. While the intermediate set of data structures may not necessarily be interpretable by a human observer (e.g., may be interpreted as cognizable representing underlying real world data), the intermediate set of training data structures may be used to cause a computing system executing the machine learning model to learn to associate the unlabeled instance data structures with the labels for storage.
In some embodiments, example systems and methods according to example aspects of the present disclosure may provide index instances (e.g., create an index, generate a label for an index, etc.) for a set of unlabeled instances. For example, in accordance with aspects of the present disclosure, a set of unlabeled examples may be provided as inputs to a machine-learned tag model. A machine-learned tag model may index unlabeled instances according to one or more output tags, the model having been trained on an intermediate training data structure generated according to example aspects of the present disclosure. In this way, for example, systems and methods according to example aspects of the present disclosure may provide a data structure of an index in the event that, for example, index information (e.g., instance level labels) may not be available, thereby facilitating access to data.
In some embodiments, example systems and methods according to example aspects of the present disclosure may be used to determine relevance of unlabeled examples to one or more query values. For example, by associating unlabeled instances with one or more predicted instance tags using a generic training package according to the present disclosure, example systems and methods of the present disclosure may retrieve those unlabeled instances by processing queries directed to the predicted instance tags. In this way, for example, the systems and methods of the present disclosure may enable machine learning models to train models using real world data to determine relevance of unlabeled data to a query, and thus may facilitate, for example, execution of structured queries.
As shown herein, the example systems and methods of the present disclosure provide improvements to data storage, indexing, query processing, and result retrieval, which in turn may, in some examples, extend resolution of computing system measurements (e.g., by observing predicted instance level information based on packet levels), improve the ability of the computing system to associate data structures (e.g., by indexing previously untagged real world data for queries), improve computational efficiency (e.g., by returning fewer empty query results due to untagged data), and reduce computational costs (e.g., by predicting tags of untagged data instead of requiring manual regression and/or additional data collection). For example, in some embodiments, example systems and methods of the present disclosure may provide reduced data requirements for generating training model(s) of instance tags. For example, by using an intermediate training data structure configured in accordance with example aspects of the present disclosure, the number of samples of the tag for obtaining a desired accuracy may be limited to a high confidence. In this way, for example, additional computational costs (e.g., by transmitting, storing, and processing additional training data, etc.) may be avoided.
Example systems and methods
Referring now to the drawings, example embodiments of the present disclosure will be discussed in more detail. FIG. 1 depicts one example system 100 for generating inferences in accordance with example aspects of the present disclosure. The example system 100 includes a computing system 102. Computing system 102 may be any type of system of one or more computing devices. The computing device may be, for example, a personal computing device (e.g., laptop or desktop), a mobile computing device (e.g., smart phone or tablet), a game console or controller, a wearable computing device, an embedded computing device, a server computing device, a node of a distributed computing device, a virtual instance hosted on a shared server, or any other type of computing device. In some embodiments, computing system 102 includes multiple computing devices interconnected by a network or distributed in an interoperable manner. For example, computing system 102 may include a server for providing content over a network (e.g., network 180). For example, computing system 102 may include a web server for hosting web content, for collecting data about web content (e.g., for receiving, monitoring, generating, or otherwise processing data about web content, such as use of, downloading, and/or interaction with web content).
Computing system 102 may include processor(s) 112 and memory 114. The one or more processors 112 may be any suitable processing device (e.g., a processor core, microprocessor, ASIC, FPGA, controller, microcontroller, etc.), and may be an operatively connected processor or processors. Memory 114 may include one or more non-transitory computer-readable storage media, such as RAM, ROM, EEPROM, EPROM, flash memory devices, magnetic disks, and the like. And combinations thereof. Memory 114 may store data 116 and instructions 118 that are executed by processor 112 to cause computing system 102 to perform operations.
In some implementations, the client computing system 102 may store or include one or more machine learning models 120. For example, the machine learning model 120 may be or may otherwise include various machine learning models, such as a neural network (e.g., deep neural network) or other types of machine learning models, including nonlinear models and/or linear models. The neural network may include a feed forward neural network, a recurrent neural network (e.g., a long and short term memory recurrent neural network), a convolutional neural network, or other form of neural network. Some example machine learning models may utilize an attention mechanism such as self-attention. For example, some example machine learning models may include a multi-headed self-attention model (e.g., a transformer model). In general, the example system 100 may be model agnostic such that various implementations of the example system 100 may include or otherwise execute various machine learning models that may not be suitable or specifically tailored for learning from tag proportions, for example.
Computing system 102 may also include one or more input components 122 that receive input (e.g., user input, input from other systems, etc.). For example, the input component 122 may be a touch-sensitive component (e.g., a touch-sensitive display screen or touch pad) that is sensitive to the touch of an input object (e.g., a finger or stylus). Other example input components include a microphone, a keyboard (e.g., physical and/or graphical), a network port (e.g., wireless, wired, etc.), a communication bus, and so forth.
As shown in FIG. 1, an embodiment of an example system 100 may be configured to receive an untagged runtime instance 130 and generate output data 140. The untagged runtime instance 130 may include substantially any kind or type of data that may describe various phenomena. Generally, an instance refers to a set of one or more data values that are combined together to describe a particular subject or topic. For example, an instance may be a feature vector. Examples may be associated with image data (e.g., feature vectors of images, hashed images, etc.). An instance may be associated with a measurement or other data collection event (e.g., at a particular time, or a particular object, or using a particular device, or from a particular perspective, etc.). An instance may be associated with a network session, such as a set of interactions with a web server. In some embodiments, the instance may be associated with user interactions with web content (e.g., anonymous or identified).
In some embodiments, the untagged runtime instance 130 may not contain a tag for the instance. In some embodiments, the untagged runtime instance 130 may contain some tag information, but lack other tag information. For example, the untagged runtime instance 130 may lack tags related to tag queries that are expected to be processed on the set of untagged runtime instances 130.
In some embodiments, output data 140 may include instance data 142 and instance tag data 144. In some embodiments, output data 140 includes a data structure that relates one or more instances to a tag (e.g., instance data 142 to instance tag data 144). For example, in some embodiments, the output data 140 includes data that effectively indexes the untagged runtime instance 130 according to one or more predictive tags.
For example, in some embodiments, the output data 140 may be queried to retrieve one or more instances that are responsive to or otherwise relevant to the tag query (e.g., data describing it, its count, etc.). In some embodiments, the output data 140 may be queried after being generated by the machine learning model(s) 120, and in some embodiments, the output data 140 may be structured as a data store for the output(s) of the machine learning model(s) 120 in response to a particular query. For example, in some embodiments, the output data 140 is determined to be a data store identified as instances related to query X, and the machine learning model(s) 120 may be configured to retrieve one or more instances related to query X (e.g., data describing it, counts thereof, etc.) from the untagged runtime instance 130 for output in the output data 140.
In some embodiments, the output data 140 may include one or more data structures for associating the untagged runtime instance 130 with one or more tags using the machine learning model(s) 120. For example, the machine learning model(s) 120 may index the unlabeled runtime instances 130 according to one or more labels predicted for each of the unlabeled runtime instances 130. In this manner, for example, the resulting output data 140 (e.g., one or more data structures therein) may be processed by performing structured queries (e.g., filtering, sorting, classifying, sorting, counting, etc.) based on the predicted tags.
Model trainer 150 may be configured to train machine learning model(s) 120 (e.g., to enable tagging and/or querying of untagged runtime instances 130). Model trainer 150 may contain unlabeled training instances 152 that have been labeled with label proportions 154. Unlabeled training instance 152 may include substantially any kind or type of data that may describe various phenomena, as discussed above with respect to unlabeled runtime instance 130. In some examples, label proportions 154 may be associated with one or more subsets of unlabeled training examples 152. For example, unlabeled training instance 152 may include a plurality of data packets, each data packet collecting a plurality of instances of a data set (e.g., a data set of instances, such as a data set of feature vectors, etc.). Each data packet may be associated with a tag ratio from tag ratio 154. For example, the tag proportion 154 may include a plurality of histograms (e.g., for one or more tags) indicative of tag frequencies, and each of the plurality of data packets may be associated with a histogram of tag frequencies in the packet. In some embodiments, tag ratio 154 may include a set of one-hot tag encodings.
Model trainer 150 may also include a generic data generator 156. Generic data generator 156 may be configured to convert training data (e.g., unlabeled training examples 152 and label proportions 154) into an intermediate generic representation, and model trainer 150 may use the intermediate generic representation to train machine learning model(s) 120. For example, in some embodiments, the machine learning model 120 may not be trained directly using the unlabeled training examples 152. In some embodiments, data packets collected from unlabeled training instance 152 (along with associated label proportions 154) may be converted into generic training packets (along with associated generic training label proportions, such as generic histograms, etc.), and the machine learning model(s) 120 may be trained using the training packets.
During training, in some embodiments, a training package (e.g., an entire package, an instance of a package, etc.) is passed to the machine learning model(s) 120 for training (e.g., as shown by the dashed line of the training cycle). The output data 140 may then be a training output, which may be passed back to the model trainer 150 for evaluation by the evaluator 158 (e.g., as shown by the dashed line of the training cycle). The evaluator 158 may determine whether the output data 140 is aligned with training data (e.g., training packets) in a desired manner. For example, the evaluator 158 may determine the objective function value on the output data 140. The evaluator 158 may determine a score, such as a penalty, based on the output data 140 and the generic training package.
In some embodiments, the evaluator 158 is configured to determine an evaluation of machine learning model 120 instance level prediction output(s) related to one or more qualities of training data. For example, the training data may include training packets associated with a label histogram. In some embodiments, the output data 140 may be aggregated into packets (e.g., reconstructed training packets and/or histograms associated therewith) to evaluate the output data 140. In some embodiments, the evaluation of the output data 140 for training packets is related to the quality of the instance-level output. For example, the evaluator 158 may be configured to determine a target for reducing the packet level error such that the target may be associated with reducing the instance level error. In some embodiments, this association is achieved by converting unlabeled training examples 152 and label proportions 154 into training packets by generic data generator 156.
Model trainer 150 may update (e.g., directly, indirectly) one or more parameters of machine learning model(s) 120 or cause one or more parameters of machine learning model(s) 120 to be updated (e.g., directly, indirectly) based at least in part on an output of evaluator 158.
In some embodiments, model trainer 150 is included in computing system 102. In some embodiments, model trainer 150 is external to computing system 102 (e.g., connected to computing system 102 via a network or other intersystem communication protocol)
In this way, for example, training the machine learning model(s) 120 using a generic training package configured in accordance with example aspects of the present disclosure may provide query processing for unlabeled runtime instances 130. For example, while the intermediate set of packages (generic training packages) may not necessarily be interpretable by a human observer (e.g., interpretable as cognitively representing the underlying real world data), the intermediate set of training data structures may provide a set of parameters for learning the machine learning model(s) 120 to learn to associate the unlabeled runtime instance 130 with a structurally stored label. In this manner, for example, an intermediate set of training data may be used to enable improved storage, retrieval, and analysis of those unlabeled runtime instances 130 (e.g., storage based on one or more tags, retrieval based on one or more tags, etc.). For example, training with the generic packages of the present disclosure may provide an index of unlabeled runtime instances 130 that use real-world training data (e.g., provide an actual implementation of the present technology on computing systems, extending their ability to execute queries, otherwise they may not be able to do so).
For example, example embodiments of a generic training package according to the present disclosure may advantageously eliminate challenges (e.g., cases where the prior art fails) presented by reality of intra-package dependencies. Example embodiments of generic training packages according to the present disclosure may advantageously eliminate challenges presented by the reality of long-tail package representations (e.g., a few instance categories in a dataset may appear in a few or only one package). And exemplary embodiments of generic training packages according to the present invention may advantageously eliminate challenges presented by the reality of long tail package size distribution.
More advantageously, example embodiments of machine learning model(s) including parameters determined using generic training packages according to the present disclosure may provide label prediction and data indexing using weakly labeled training data without spending additional time and other resources to improve the labeling of the training data (e.g., manually, etc.), for example, by overcoming many of the challenges faced by the prior art of learning subject to label scaling.
For example, in some embodiments, the weakly labeled training data itself may be generated from one or more predictions. For example, the tag proportion may be predicted based on statistics or other knowledge about the population. For example, in some embodiments, population statistics may have a higher confidence than the statistics of any one individual. In such examples, for example, knowledge of population level statistics may be utilized to obtain instance level label predictions, according to example embodiments of the present disclosure. In this way, for example, example embodiments of a generic training package according to the present disclosure may advantageously reduce the amount of training data (or effort spent obtaining training data) that may be required to obtain an index and/or tagged data structure.
FIG. 2 depicts an exemplary model trainer 150'. The example model trainer 150' includes a plurality of data packets 210, each of which includes a plurality of unlabeled training examples and corresponding label proportions. For example, in one package, unlabeled training instance 212 may correspond to label ratio 214, while in another package, unlabeled training instance 216 may correspond to label ratio 218, and so on. In another example, the unlabeled training instance 212 may be associated with a plurality of data packets or a distribution of data packets and may correspond to a distribution of label proportions 214 associated with the distribution of data packets. Also, in some embodiments, unlabeled training examples 216 may be associated with multiple data packets or a distribution of data packets and may correspond to a distribution of label proportions 218 associated with the distribution of data packets. Thus, in some embodiments, the data packet 210 may include one or more (e.g., multiple) data packet distributions.
The generic data generator 156' may access the data packet 210. For example, the weight generator 220 may access the data packet 210 to generate a set of weights 222 (e.g., a plurality of weights 222). In some embodiments, weight generator 220 may generate a weight distribution from which weights 222 are sampled. Multiple sampled data packets 230 may be sampled from the data packet 210 (e.g., sampled from one or more data packet distributions, etc.). In some embodiments, the weights 222 and the sampled data packets 230 may be sampled independently.
The weights 222 and the sampled data packets 230 may be input into a transformer 240 to generate training packets 250. For example, transformer 240 may generate training packets 250 from sample data packets 230 according to weights 222. In some embodiments, weights 222 are parameters of transformer 240 (e.g., parameters of a model, such as a machine learning model). In some embodiments, the sampled data packets 230 may be combined into weighted combinations (e.g., linear combinations) according to the weights 222. For example, in some embodiments, given a set of k data packets B and corresponding histograms σ, a generic training packet may be expressed as
Model trainer 150' may use training package 250 to provide instances as input to machine learning model(s) 120 (e.g., generic training instance 260) to obtain output(s) 140. Model trainer 150' may access output(s) 140 for evaluation. For example, evaluator 270 can access output(s) 140 to determine prediction scaling data 274 (e.g., by determining a scaling of a set of predicted instances from instance data 142 and instance tag data 144, such as by effectively reconstructing a generic histogram associated with generic training package 250). Using the predicted scale data 274, the evaluator 270 may determine the loss 276. For example, the loss 276 may include a distance error. For example, the loss 276 may include a euclidean loss, such as an L1 loss, an L2 loss, etc., such as a squared euclidean loss to sum the outputs (e.g., to sum the predicted ratio data 274 for each of the training packets 250). However, in some embodiments, the evaluator 270 may determine the loss 276 directly from the output(s) 140 (e.g., without first determining the predicted ratio data 274).
Based at least in part on the output or results of the evaluator 270, the model updater 280 can update the machine learning model(s) 120 (e.g., one or more parameters thereof). For example, the model updater 280 may include or perform substantially any model updating technique, such as a gradient-based method, an evolutionary method, and the like.
In some embodiments, the weight generator 220 may operate asynchronously to the generation of the training package 250. For example, in one embodiment, the weight generator 220 may initially operate to determine a set of weights 222. The set of weights 222 may then be used to generate a plurality of training packets 250 using the data packets 210. In some embodiments, the same set of weights 222 may be used for data packets other than data packets 210 and/or in addition to data packets 210. In some embodiments, the weight generator 220 may be executed in response to a trigger from the evaluator 270: for example, the weight generator 220 may be triggered by an output error above a threshold.
In some embodiments, the weight generator 220 may determine a weight distribution to obtain a training packet 250, the training packet 250 configured to cause a correlation between packet level loss on the output(s) 140 and instance level error on the output(s) 140. For example, in some embodiments, the weight generator 220 may determine a weight distribution such that the training package 250 is associated with an isotropic training package distribution (e.g., generate a plurality of isotropic training packages 250).
In some examples, the training packet 250 distribution may be considered to be equidirectional if the feature vectors of the training packet are sampled from an isotropic distributionSex. For example, a feature vector may be determined for one or more data packets 210 (e.g., optionally uniquely identifying each packet). Since the data packets 210 are transformed by the generic data generator 156', the feature vectors of the packets may also be transformed accordingly, thereby generating feature vectors for each training packet 250. For example, in some embodiments, a given data packet
In this way, for example, the isotropy condition may be evaluated with respect to the feature vector of the training package 250. In some examples, weights 222 may be sampled from the weight distribution generated by weight generator 220 such that one or more feature vectors generated using weights 222 may be effectively sampled from the isotropic distribution.
In some examples, determining the weight distribution such that one or more feature vectors generated using weights 222 may be effectively sampled from the isotropic distribution includes solving (e.g., accurately, approximately, analytically, numerically, etc.) a convex problem, such as a semi-definite programming solution. In some embodiments, determining the weight distribution such that one or more feature vectors generated using the weights 222 may be effectively sampled from the isotropic distribution includes solving a covariance matrix of the weight distribution to satisfy the isotropy constraint. In some embodiments, the isotropic constraint may be relaxed (e.g., by inserting a relaxation value).
In some embodiments, the covariance matrix may be determined such that its traces are reduced (e.g., minimized). For example, the trace of the covariance matrix may be related to a bound for the sample size used to obtain a desired margin of error (e.g., a result within a given amount of error). For example, by reducing the bounds of the norms of the feature vector(s) of the training packet 250, the sample size used to obtain the desired error bound with probability (e.g., high probability) may be reduced. In some embodiments, reducing the trace of the covariance matrix corresponds to reducing the bounds of the norms of the feature vector(s) of the training packet 250.
In some embodiments, a covariance matrix may be used to obtain the weight distribution. For example, in some embodiments, the covariance matrix is a semi-positive definite covariance matrix, which may be decomposed, and the decomposition uniformly sampled as weights 222 to give a weight distribution. In some embodiments, a set of weights 222 may be considered a gaussian vector with zero mean using covariance matrix sampling.
In some embodiments, a solution to the covariance matrix (e.g., a solution to a convex problem, such as a semi-definite procedure) may not be feasible. For example, an approximation solution may be used instead. In some embodiments, the weight generator 220 may determine feasibility and, in response to determining feasibility, obtain an approximate solution (e.g., by relaxing isotropic constraints). In some embodiments, the weight generator 220 may return an error, and/or may default to the previously obtained weight 222.
For example, in some embodiments, algorithm 1 may be used to obtain a weight distribution.
Algorithm 1: finding weight distribution
Input data packets/profiles;
attempting to solve a covariance matrix;
providing an approximation if the solution is not feasible, ending the if;
returning to the weight distribution using W samples;
algorithm 2 may be used to obtain training packets in training packet 250 using one or more weight distributions.
Algorithm 2: generating training packages
The input weight and the independent distribution(s) of the data packet;
independently sampling data packets from the data packet distribution(s);
independently sampling weights from the weight distribution(s);
returning a general packet obtained by using the sampling data packet and the sampling weight;
for example, in one embodiment, a plurality of packet distributions { D 1 ，...，D k Weight vector w=w may be obtained from the weight distribution 1 ，...，w k To provide a universal package
for y u ， v More than or equal to 0 (e.g., each tuple (u, v) ∈n]×[n]) One) satisfying equation 2 may obtain an approximate solution, while optionally including a minimization of the target trace (W) +λ Σ for an appropriate λ+.gtoreq.0 u,v y u,v 。
In some embodiments, one or more slack values (e.g., y u,v ). For example, in some embodiments, the number of relaxation variables may be the square of the number of instances in the training dataset. In some embodiments, independence of instance sampling in one or more packets of a packet distribution may provide a solution to the problem of relaxation across instance groups (e.g., clusters of two instances each).
In some embodiments, the above algorithm may be repeated as follows:
algorithm 1': finding weight distribution
Input { A (i) |i∈[k]}；
Attempting to solve equation 1;
if the solution is not feasible, providing a solution of equation 2, ending if;
returning to the weight distribution using W samples;
for example, weight distribution G w By decomposition of
"Algorithm 2": generating training packages
Input independent distribution(s) G w Sum { D ] 1 ,...,D k }；
Independently sampling data packets from the data packet distribution(s), as follows
(B i ,σ i )←D i (1≤i≤k)；
The weights are independently sampled from the weight distribution(s), as follows
w←G w ；
Returning a generic package with a corresponding generic histogram, as follows
In some embodiments, model trainer 150', via generic data generator 156', may construct a plurality of training packages 250 (e.g., with their corresponding generic label proportions) by executing, for example, algorithm 2 or 2' to generate each of the plurality of training packages 250.
In some embodiments, the number of training packets 250 used to obtain the target accuracy and/or error rate may be defined by a value related to a norm of one or more feature vectors (e.g., a maximum norm of a feature vector). In some embodiments, the maximum norm of a feature vector may be expressed astraining packets 250 used to achieve a target accuracy and/or error rate may be represented by O (opt (k) 2 nlogn)/δ 2 ) Is defined to have a value of at least 1-n -3 Probability of (sigma) min (A),σ max (A))∈[1-δ,1+δ]Where opt is the value of the semi-definite program solved in algorithm 1
Fig. 3 depicts a block diagram of an example computing system 300, according to an example embodiment of the disclosure. The example system 300 includes a client computing system 302, a server computing system 330, and a training computing system 350 communicatively coupled by a network 380.
Client computing system 302 may be any type of system of one or more computing devices. The computing device may be, for example, a personal computing device (e.g., laptop or desktop), a mobile computing device (e.g., smart phone or tablet), a game console or controller, a wearable computing device, an embedded computing device, a server computing device, a node of a distributed computing device, a virtual instance hosted on a shared server, or any other type of computing device. In some embodiments, client computing system 302 includes multiple computing devices interconnected by a network or distributed in an interoperable manner. For example, client computing system 302 may include a server for providing content over a network (e.g., network 380). For example, client computing system 302 may include a web server for hosting web content, for collecting data about the web content (e.g., for receiving, monitoring, generating, or otherwise processing data about the web content, such as use of, downloading, and/or interaction with the web content).
Client computing system 302 includes one or more processors 312 and memory 314. The one or more processors 312 may be any suitable processing device (e.g., a processor core, microprocessor, ASIC, FPGA, controller, microcontroller, etc.) and may be an operatively connected processor or processors. Memory 314 may include one or more non-transitory computer-readable storage media such as RAM, ROM, EEPROM, EPROM, flash memory devices, disks, and the like, as well as combinations thereof. Memory 314 may store data 316 and instructions 318 that are executed by processor 312 to cause client computing system 302 to perform operations.
In some implementations, the client computing system 302 can store or include one or more machine learning models 320. For example, the machine learning model(s) 320 may be or may otherwise include various machine learning models, such as a neural network (e.g., deep neural network) or other types of machine learning models, including nonlinear models and/or linear models. The neural network may include a feed forward neural network, a recurrent neural network (e.g., a long and short term memory recurrent neural network), a convolutional neural network, or other form of neural network. Some example machine learning models may utilize an attention mechanism such as self-attention. For example, some example machine learning models may include a multi-headed self-attention model (e.g., a transformer model). Example machine learning model(s) 320 are discussed with reference to machine learning model(s) 120.
In some implementations, one or more machine learning models 320 may be received from a server computing system 330 over a network 380, stored in a client computing system memory 314, and then used or otherwise implemented by one or more processors 312. In some implementations, the client computing system 302 may implement multiple parallel instances of a single machine learning model 320.
Additionally or alternatively, one or more machine learning models 340 may be included in a server computing system 330 in communication with the client computing system 302 according to a client-server relationship, or stored and implemented by the server computing system 330. For example, the machine learning model 340 may be implemented by the server computing system 340 as part of a web service (e.g., a service for handling untagged runtime instances according to any of the various aspects of the present disclosure). Accordingly, one or more machine learning models 320 may be stored and implemented at client computing system 302 and/or one or more machine learning models 340 may be stored and implemented at server computing system 330.
The client computing system 302 may also include one or more input components 322 that receive input (e.g., user input, input from other systems, etc.). For example, the input component 322 may be a touch-sensitive component (e.g., a touch-sensitive display screen or touch pad) that is sensitive to the touch of an input object (e.g., a finger or stylus). Other example input components include a microphone, a keyboard (e.g., physical and/or graphical), a network port (e.g., wireless, wired, etc.), a communication bus, and so forth.
The server computing system 330 includes one or more processors 332 and memory 334. The one or more processors 332 may be any suitable processing device (e.g., a processor core, microprocessor, ASIC, FPGA, controller, microcontroller, etc.) and may be an operatively connected processor or processors. Memory 334 may include one or more non-transitory computer-readable storage media such as RAM, ROM, EEPROM, EPROM, flash memory devices, magnetic disks, and the like, as well as combinations thereof. Memory 334 may store data 336 and instructions 338 that are executed by processor 332 to cause server computing system 330 to perform operations.
In some implementations, the server computing system 330 includes or is implemented by one or more server computing devices. Where the server computing system 330 includes multiple server computing devices, such server computing devices may operate in accordance with a sequential computing architecture, a parallel computing architecture, or some combination thereof.
As described above, the server computing system 330 may store or otherwise include one or more machine learning models 340. Example machine learning models include neural networks or other multi-layer nonlinear models. Example neural networks include feed forward neural networks, deep neural networks, recurrent neural networks, and convolutional neural networks. Some example machine learning models may utilize an attention mechanism such as self-attention. For example, some example machine learning models may include a multi-headed self-attention model (e.g., a transformer model).
In some embodiments, client computing system 302 may access information that is not available to server computing system 330 and/or training computing system 350. In some embodiments, the client computing system 302 may be configured to host first party content. The first party content may include, for example, content associated with an owner, operator, and/or beneficiary of the client computing system 302 (e.g., a contractual beneficiary, such as a tenant of a computing time on the client computing system 302). In some embodiments, the client computing system 302 may collect (e.g., telemetry, analysis, usage statistics, logs, etc.) data regarding the downloading, viewing, and usage of the first party content.
The server computing system 330 may not have full or unrestricted access to the first party content on the client computing system 302 or unrestricted access to data regarding viewing and using the content. However, in some examples, the server computing system 330 may access data describing third-party content related to the first-party content (e.g., content linked to or otherwise advertising the first-party content). Due to technical, legal, or regulatory restrictions, a client computing system may in some cases only be able to provide weakly tagged data describing the first party content and its interactions. Thus, according to example aspects of the present disclosure, one or more machine learning models 340 may be advantageously trained to associate data describing third party content with various instances in data describing first party content.
For example, in one example, client computing system 302 may host a first party web content. The server computing system 330 may host third party advertising content. Interactions with third party advertising content may be associated with interactions with first party web content. It may be desirable to associate interactions with third party content with subsequent interactions with first party content. For example, a first party content provider may be interested in determining which interactions with third party content resulted in which interactions with the first party content. For example, it may be desirable to index interactions with third party content according to tags (e.g., transformations, other metrics, etc.) associated with the first party content.
The information of the link interactions may be limited. For example, information about a first party interaction may be owned by a first party provider and there may be a limit to the ability of the first party provider to grant full access to the information. Information about the third party interactions may also be restricted in various ways such that the first party provider cannot fully access or see the third party interactions. However, in some embodiments, the first party provider may access some information about the third party interaction (e.g., query text processed on the third party platform, creative ID or campaign ID of the third party content, etc.). In some embodiments, the first party provider may upload or otherwise transmit data describing the first party interactions to the server computing system 330 for processing along with any third party interaction information that may be associated therewith. In some embodiments, the first party provider may upload only weakly tagged data (e.g., only tagged with tag proportions, such as percent conversion, etc.).
Advantageously, one or more machine learning models 340 may be trained in accordance with example aspects of the present disclosure to learn to use the uploaded data and optionally any other data associated therewith on a third party platform to generate a relationship (e.g., generate one or more index data structures) between the first party data and the third party data. In this way, for example, the server computing system 330 may process (e.g., at runtime) instances of third-party interactions to determine one or more tags (e.g., transformations, attributes, etc.) associated therewith. For example, the server computing system 330 may process instances of third party interactions to run one or more queries against the instances. Advantageously, in accordance with example aspects of the present disclosure, in some embodiments, instances may be indexed (e.g., configured for efficient querying). For example, in accordance with example aspects of the present disclosure, the server computing system 330 may generate generic training packages from first party data (e.g., first party data uploaded or otherwise transmitted to the server computing system 330, etc.) in order to train one or more machine learning models 340 to process instances of third party interactions to run one or more queries against the instances.
Client computing system 302 and/or server computing system 330 may train models 320 and/or 340 through interactions with training computing system 350 communicatively coupled via network 380. The training computing system 350 may be separate from the server computing system 330 or may be part of the server computing system 330.
The training computing system 350 includes one or more processors 352 and memory 354. The one or more processors 352 may be any suitable processing device (e.g., a processor core, microprocessor, ASIC, FPGA, controller, microcontroller, etc.) and may be a processor or multiple processors operatively connected. Memory 354 may include one or more non-transitory computer-readable storage media, such as RAM, ROM, EEPROM, EPROM, flash memory devices, magnetic disks, and the like, and combinations thereof. Memory 354 may store data 356 and instructions 358 that are executed by processor 352 to cause training computing system 350 to perform operations. In some implementations, the training computing system 350 includes or is implemented by one or more server computing devices.
Training computing system 350 may include a model trainer 360 that trains machine learning models 320 and/or 340 stored at client computing system 302 and/or server computing system 330 using various training or learning techniques, such as error back propagation. For example, the loss function may be counter-propagated through the model(s) to update one or more parameters of the model(s) (e.g., based on gradients of the loss function). Various loss functions may be used, such as mean square error, likelihood loss, cross entropy loss, hinge loss, and/or various other loss functions. Gradient descent techniques may be used to iteratively update parameters over multiple training iterations. In some embodiments, performing back-propagation of the error may include performing truncated back-propagation over time. Model trainer 360 may perform a variety of techniques (e.g., weight decay, exit, etc.) to enhance the ability of the model to be trained.
In particular, model trainer 360 may train machine learning models 320 and/or 340 based on a set of training data 362. Training data 362 may include, for example, general training data in accordance with example aspects of the present disclosure (e.g., as described above, such as with reference to fig. 1 and 2). For example, in some embodiments, model trainer 360 may be or include model trainer 150 or 150'.
In some implementations, the training data 362 can include data provided by the client computing system 302. Thus, in such implementations, model 320 provided to client computing system 302 and/or model 340 provided to server computing system 330 may be trained by training computing system 350 based on data received from client computing system 302. In some embodiments, training data 362 includes data that is not accessible to server computing system 330 and/or training computing system 350 unless provided by client computing system 302.
Model trainer 360 includes computer logic for providing the desired functionality. Model trainer 360 may be implemented in hardware, firmware, and/or software that controls a general purpose processor. For example, in some implementations, model trainer 360 includes program files stored on a storage device, loaded into memory, and executed by one or more processors. In other implementations, model trainer 360 includes one or more sets of computer-executable instructions stored in a tangible computer-readable storage medium, such as RAM, a hard disk, or an optical or magnetic medium.
The machine learning models described in this specification (e.g., models 120, 320, 340, etc.) may be used in a variety of tasks, applications, and/or use cases. In some implementations, the input of the machine learning model(s) of the present disclosure can be image data. The machine learning model(s) may process the image data to generate an output. As an example, the machine learning model(s) may process the image data to generate an image recognition output (e.g., recognition of the image data, potential embedding of the image data, encoded representation of the image data, hashing of the image data, etc.). As another example, the machine learning model(s) may process the image data to generate an image segmentation output. As another example, the machine learning model(s) may process image data to generate an image classification output. As another example, the machine learning model(s) may process the image data to generate an image data modification output (e.g., a change in the image data, etc.). As another example, the machine learning model(s) may process the image data to generate an encoded image data output (e.g., an encoded and/or compressed representation of the image data, etc.). As another example, the machine learning model(s) may process the image data to generate an enlarged image data output. As another example, the machine learning model(s) may process the image data to generate a prediction output.
In some implementations, the input of the machine learning model(s) of the present disclosure can be text or natural language data. The machine learning model(s) may process text or natural language data to generate an output. For example, the machine learning model(s) may process natural language data to generate a linguistic coded output. As another example, the machine learning model(s) may process text or natural language data to generate a potential text-embedded output. As another example, the machine learning model(s) may process text or natural language data to generate a translation output. As another example, the machine learning model(s) may process text or natural language data to generate a classification output. As another example, the machine learning model(s) may process text or natural language data to generate text segmentation output. As another example, the machine learning model(s) may process text or natural language data to generate semantic intent output. As another example, the machine learning model(s) may process text or natural language data to generate an upgraded text or natural language output (e.g., text or natural language data of higher quality than the input text or natural language, etc.). As another example, the machine learning model(s) may process text or natural language data to generate a predictive output.
In some implementations, the input of the machine learning model(s) of the present disclosure can be speech data. The machine learning model(s) may process the speech data to generate an output. For example, the machine learning model(s) may process the speech data to generate speech recognition output. As another example, the machine learning model(s) may process the speech data to generate a speech translation output. As another example, the machine learning model(s) may process the speech data to generate potentially embedded output. As another example, the machine learning model(s) may process the speech data to generate an upgraded speech output (e.g., higher quality speech data than the input speech data, etc.), as another example, the machine learning model(s) may process the speech data to generate a textual representation output (e.g., a textual representation of the input speech data, etc.), as another example, the machine learning model(s) may process the speech data to generate a predictive output.
In some implementations, the input of the machine learning model(s) of the present disclosure can be potentially encoded data (e.g., a potential spatial representation of the input, etc.). The machine learning model(s) may process the potentially encoded data to generate an output. For example, the machine learning model(s) may process the potentially encoded data to generate the recognition output. As another example, the machine learning model(s) may process the potentially encoded data to generate a reconstructed output. As another example, the machine learning model(s) may process the potentially encoded data to generate a search output. As another example, the machine learning model(s) may process the potentially encoded data to generate a reclustering output. As another example, the machine learning model(s) may process the potentially encoded data to generate a prediction output.
In some implementations, the input to the machine learning model(s) of the present disclosure can be statistical data. The statistical data may be, represent, or otherwise include calculated and/or calculated data from some other data source. The machine learning model(s) may process the statistical data to generate an output. For example, the machine learning model(s) may process the statistical data to generate an identification output. As another example, the machine learning model(s) may process the statistical data to generate a prediction output. As another example, the machine learning model(s) may process the statistical data to generate a classification output. As another example, the machine learning model(s) may process the statistical data to generate a segmentation output. As another example, the machine learning model(s) may process the statistical data to generate a visual output. As another example, the machine learning model(s) may process the statistical data to generate a diagnostic output.
In some implementations, the input to the machine learning model(s) of the present disclosure can be sensor data. The machine learning model(s) may process the sensor data to generate an output. For example, the machine learning model(s) may process the sensor data to generate an identification output. As another example, the machine learning model(s) may process the sensor data to generate a prediction output. As another example, the machine learning model(s) may process the sensor data to generate classification output. As another example, the machine learning model(s) may process the sensor data to generate a segmented output. As another example, the machine learning model(s) may process the sensor data to generate a visual output. As another example, the machine learning model(s) may process the sensor data to generate diagnostic output. As another example, the machine learning model(s) may process the sensor data to generate a detection output.
In some cases, the machine learning model(s) may be configured to perform tasks including encoding input data for reliable and/or efficient transmission or storage (and/or corresponding decoding). For example, the task may be an audio compression task. The input may comprise audio data and the output may comprise compressed audio data. In another example, the input includes visual data (e.g., one or more images or videos), the output includes compressed visual data, and the task is a visual data compression task. In another example, the task may include generating an embedding for input data (e.g., input audio or video data).
In some cases, the input includes visual data and the task is a computer visual task. In some cases, pixel data including one or more images is input, and the task is an image processing task. For example, an image processing task may be an image classification, where the output is a set of scores, each score corresponding to a different object class, and representing a likelihood that one or more images depict an object belonging to that object class. The image processing task may be object detection, wherein the image processing output identifies one or more regions in the one or more images, and for each region, identifies a likelihood that the region depicts the object of interest. As another example, the image processing task may be image segmentation, wherein the image processing output defines a respective likelihood for each category in the predetermined set of categories for each pixel in the one or more images. For example, the set of categories may be foreground and background. As another example, the set of categories may be object classes. As another example, the image processing task may be depth estimation, where the image processing output defines a respective depth value for each pixel in one or more images. As another example, the image processing task may be motion estimation, where the network input includes a plurality of images, and the image processing output defines for each pixel of one of the input images a motion of a scene depicted at pixels between the images in the network input.
In some cases, the input includes audio data representing a spoken utterance, and the task is a speech recognition task. The output may include a text output mapped to the spoken utterance. In some cases, the task includes encrypting or decrypting the input data. In some cases, the task includes a microprocessor performance task, such as branch prediction or memory address translation.
In some embodiments, any of the inputs described above may be provided for a tagged task or other indexing task. For example, any of the inputs described above or other inputs may be or include instances, such as untagged instances (e.g., lack of some or all of the tagging, such as lack of desired tagging). In some embodiments, the task is to process queries for input instances. The output (e.g., or intermediate output) may include a data structure that associates the unlabeled instance with one or more values that indicate a relationship with the query tag. In this way, for example, a task may be an indexing task to index unlabeled instances in order to process queries for tag data (e.g., tag data about tags that were not previously associated with an instance). The output may include a count or other summary output describing the relationship(s) between the unlabeled instance and the query tag(s). The output may include a retrieval of unlabeled instance(s) determined to be relevant to the query tag(s). In some embodiments, the index may be temporary (e.g., stored to obtain various metrics and/or analyses from processing queries for the indexed instance, and later offloaded) or stored for a longer duration than temporary (e.g., written to disk, etc.).
FIG. 3 illustrates one example computing system that may be used to implement the present disclosure. Other computing systems may also be used. For example, in some implementations, the client computing system 102 may include a model trainer 160 and a training data set 162. In such implementations, the model 120 may be trained and used locally at the client computing system 102. In some such implementations, the client computing system 102 may implement a model trainer 160 to personalize the model 120 based on user-specific data.
Fig. 4 depicts a flowchart of an example method 400 performed in accordance with an example embodiment of the present disclosure. Although fig. 4 depicts steps performed in a particular order for purposes of illustration and discussion, the methods of the present disclosure are not limited to the particular illustrated order or arrangement. The various steps of the example method 400 may be omitted, rearranged, combined, and/or modified in various ways without departing from the scope of the present disclosure.
At 402, the example method 400 includes obtaining a plurality of data packets. In some embodiments, each respective data packet of the plurality of data packets corresponds to a respective plurality of instances and is associated with one or more proportional tags, respectively. In some embodiments, the one or more data packets are samples from one or more data packet distributions. In some embodiments, one or more data packets are obtained by a server computing system from a client computing system. In some embodiments, the one or more data packets include data records from the server computing system and from the client computing system.
At 404, the example method 400 includes generating a distribution of training packets from a plurality of data packets according to a plurality of weights. In some embodiments, a plurality of generic training packets are generated such that packet-level prediction scale tag errors of a machine-learned prediction model on the plurality of training packets are correlated with instance-level prediction scale tag errors of the machine-learned prediction model. In some embodiments of the example method 400, the packet-level prediction scaling tag error is based at least in part on the distance error. In some embodiments of the example method 400, the packet-level prediction scaling tag error is based at least in part on a euclidean error. In some embodiments of the example method 400, the packet-level prediction scaling tag error is based at least in part on a squared euclidean error.
In some embodiments of the example method 400, generating the plurality of generic training packages includes generating a generic training package distribution. In some embodiments of the example method 400, the plurality of generic training packets are samples from a generic training packet distribution.
In some embodiments, the example method 400 further includes obtaining a plurality of unlabeled runtime instances. In some embodiments, the example method 400 further includes generating output data describing the one or more untagged runtime instances and tags associated therewith using the machine-learned prediction model.
In some embodiments, the example method 400 further includes determining a correlation between the tag query and the instance tag data. In some embodiments, the example method 400 further includes querying the output data with the query tag and returning data describing a subset of the output data associated with the query tag. In some embodiments, the example method 400 further includes outputting instance tag data predicted by the machine-learned prediction model for one or more of the plurality of instances. In some embodiments, the example method 400 further includes outputting a data structure including instance tag data and data describing one or more of the plurality of instances associated with the instance tag data.
In some embodiments, in the example method 400, the output data includes a data store identified as instances related to the query tag, and the machine learning predictive model is configured to retrieve one or more unlabeled runtime instances related to the query tag.
In some embodiments, the example method 400 further includes inputting input data based at least in part on the plurality of generic training packets into the machine learning predictive model. In some embodiments, the example method 400 further includes obtaining a packet level prediction scaling tag error. In some embodiments, the example method 400 further includes updating one or more parameters of the machine-learned prediction model based at least in part on the packet-level prediction scale tag error.
In some embodiments of the example method 400, the plurality of generic training packets is based at least in part on a combination of one or more data packets according to the plurality of weights. In some embodiments of the example method 400, the plurality of generic training packets is based at least in part on a linear combination of one or more data packets according to the plurality of weights.
In some embodiments of the example method 400, the weight distribution is determined based at least in part on a system of equations with coefficients derived from covariance matrices (and/or second moment matrices) of one or more data packet distributions. In some embodiments of the example method 400, the weight distribution is determined from a relaxation constraint on isotropy of the generic training packet distribution. In some embodiments, the example method 400 further includes selecting a relaxation constraint in response to determining the infeasibility of the ideal weight distribution. In some embodiments of the example method 400, the plurality of weights is based at least in part on a solution to the convex problem. In some embodiments of example method 400, the plurality of weights is based at least in part on a solution of the semi-definite programming.
In some embodiments of the example method 400, a plurality of weights are sampled from a weight distribution. In some embodiments of the example method 400, a plurality of weights are sampled from the weight distribution to obtain an isotropic distribution of feature vectors corresponding to a plurality of generic training packets.
In some embodiments of the example method 400, the method is model agnostic. In some embodiments of the example method 400, the data packet includes real world data.
In some embodiments, the example method 400 further includes determining a weight distribution for generating a plurality of generic training packets from the plurality of data packets. For example, fig. 5 depicts a flowchart of an embodiment of an example method 400 performed in accordance with an example embodiment of the present disclosure. Although FIG. 5 depicts steps performed in a particular order for purposes of illustration and discussion, the methods of the present disclosure are not limited to the particular illustrated order or arrangement. For example, at 504, the example method 400 includes determining a weight distribution for generating a plurality of generic training packets from a plurality of data packets.
At 506, the example method 400 further includes, for each respective generic training packet of the plurality of generic training packets: sampling (at 508) a plurality of weights from the weight distribution by the computing system; sampling (at 510) a plurality of data packets from a distribution of data packets by a computing system; and outputting (at 512), by the computing system, a respective generic training packet based at least in part on the plurality of weights and the plurality of data packets.
Additional disclosure
The technology discussed herein relates to servers, databases, software applications, and other computer-based systems, as well as actions taken and information sent to and received from such systems. The inherent flexibility of computer-based systems allows for a variety of possible configurations, combinations, and divisions of tasks and functions between components. For example, the processes discussed herein may be implemented using a single device or component or multiple devices or components working in combination. The database and application may be implemented on a single system or may be distributed across multiple systems. Distributed components may operate sequentially or in parallel.
While the present subject matter has been described in detail with respect to various specific example embodiments thereof, each example is provided by way of explanation and not limitation of the present disclosure. Alterations, modifications and equivalents will readily occur to those skilled in the art after having appreciated the foregoing description. Accordingly, this subject disclosure does not preclude inclusion of such modifications, variations and/or additions to the present subject matter as would be readily apparent to one of ordinary skill in the art. For instance, features illustrated or described as part of one embodiment, can be used with another embodiment to yield a still further embodiment. Accordingly, the present disclosure is intended to cover such alternatives, modifications, and equivalents.
Claims (29)
1. A method, comprising:
obtaining, by a computing system comprising one or more processors, a plurality of data packets, wherein each respective data packet of the plurality of data packets comprises a respective plurality of instances and is associated with one or more proportional labels, respectively;
generating, by the computing system, a plurality of generic training packets from the plurality of data packets according to the plurality of weights;
wherein the plurality of generic training packets are generated such that the packet-level predictive scaling tag error of the machine-learned predictive model over the plurality of training packets is related to the instance-level predictive scaling tag error of the machine-learned predictive model.
2. The method of claim 1, further comprising:
inputting, by the computing system, input data based at least in part on the plurality of generic training packets into a machine learning predictive model;
obtaining, by a computing system, a packet level prediction scaling tag error; and
one or more parameters of the machine-learned prediction model are updated by the computing system based at least in part on the packet-level prediction scale tag error.
3. The method of claim 1 or claim 2, further comprising:
determining, by the computing system, a weight distribution for generating a plurality of generic training packets from the plurality of data packets; and
for each respective generic training package of the plurality of generic training packages,
sampling, by the computing system, a plurality of weights from the weight distribution;
sampling, by the computing system, a plurality of data packets from a distribution of data packets; and
the respective generic training packets are output by the computing system based at least in part on the plurality of weights and the plurality of data packets.
4. The method of any of the preceding claims, further comprising:
obtaining, by a computing system, a plurality of unlabeled runtime instances; and
output data describing one or more of the untagged runtime instances and tags associated with the untagged runtime instances is generated by the computing system and using the machine-learning predictive model.
5. The method of any of the preceding claims, further comprising:
querying, by the computing system, the output data with a query tag; and
data describing a subset of the output data associated with the query tag is returned by the computing system.
6. The method of any of the preceding claims, wherein:
the output data includes a data store identified as instances related to the query tag; and is also provided with
The machine-learning predictive model is configured to retrieve one or more of the unlabeled runtime instances related to the query tag.
7. The method of any of the preceding claims, wherein the plurality of generic training packets is based at least in part on a combination of one or more data packets according to a plurality of weights.
8. The method of any of the preceding claims, wherein the plurality of generic training packets is based at least in part on a linear combination of one or more data packets according to a plurality of weights.
9. The method of any preceding claim, wherein the one or more data packets are samples from one or more data packet distributions.
10. The method of any of the preceding claims, wherein the plurality of weights is based at least in part on a solution to a convex problem.
11. The method of any of the preceding claims, wherein the plurality of weights is based at least in part on a solution of a semi-definite plan.
12. The method of any of the preceding claims, wherein the plurality of weights are sampled from a weight distribution.
13. The method of any of the preceding claims, wherein the plurality of weights are sampled from a weight distribution to obtain an isotropic distribution of feature vectors corresponding to the plurality of generic training packets.
14. The method of any one of the preceding claims, wherein the method is model agnostic.
15. A method according to any preceding claim, wherein the data packets comprise real world data.
16. The method of any of the preceding claims, wherein packet-level prediction scaling tag error is based at least in part on distance error.
17. The method of any of the preceding claims, wherein packet-level prediction scaling tag errors are based at least in part on euclidean errors.
18. The method of any of the preceding claims, wherein the packet-level prediction scaling tag error is based at least in part on a squared euclidean error.
19. The method of any of the preceding claims, wherein generating a plurality of generic training packages comprises generating a generic training package distribution.
20. The method of any of the preceding claims, wherein the plurality of generic training packets are samples from a generic training packet distribution.
21. The method of any of the preceding claims, wherein the weight distribution is determined from a relaxation constraint on isotropy of the generic training packet distribution.
22. The method of any of the preceding claims, further comprising:
in response to determining the infeasibility of the ideal weight distribution, a relaxation constraint is selected.
23. The method of any of the preceding claims, wherein the weight distribution is determined based at least in part on a system of equations with coefficients derived from covariance matrices of one or more data packet distributions.
24. The method of any of the preceding claims, wherein the weight distribution is determined based at least in part on a system of equations with coefficients derived from a second moment matrix of one or more data packet distributions.
25. The method of any of the preceding claims, further comprising:
instance tag data predicted by the machine-learned prediction model is output by the computing system for one or more of the plurality of instances.
26. The method of any of the preceding claims, further comprising:
A data structure including instance tag data and data describing one or more instances of a plurality of instances associated with the instance tag data is output by a computing system.
27. The method of any of the preceding claims, further comprising:
a correlation between the tag query and the instance tag data is determined by the computing system.
28. A system, comprising:
one or more processors; and
one or more storage devices storing computer-readable instructions that, when executed, cause the one or more processors to perform operations comprising the method of any of the preceding claims.
29. A computer-readable medium storing computer-readable instructions for causing one or more processors to perform operations comprising the method of any one of claims 1 to 27.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
IN202121050228 | 2021-11-02 | ||
IN202121050228 | 2021-11-02 | ||
PCT/US2022/011558 WO2023080912A1 (en) | 2021-11-02 | 2022-01-07 | Generalized bags for learning from label proportions |
Publications (1)
Publication Number | Publication Date |
---|---|
CN116420151A true CN116420151A (en) | 2023-07-11 |
Family
ID=80123286
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202280005333.6A Pending CN116420151A (en) | 2021-11-02 | 2022-01-07 | Universal package for learning from tag proportions |
Country Status (4)
Country | Link |
---|---|
US (1) | US20240119295A1 (en) |
EP (1) | EP4196915A1 (en) |
CN (1) | CN116420151A (en) |
WO (1) | WO2023080912A1 (en) |
-
2022
- 2022-01-07 EP EP22701783.7A patent/EP4196915A1/en active Pending
- 2022-01-07 CN CN202280005333.6A patent/CN116420151A/en active Pending
- 2022-01-07 US US18/013,053 patent/US20240119295A1/en active Pending
- 2022-01-07 WO PCT/US2022/011558 patent/WO2023080912A1/en active Application Filing
Also Published As
Publication number | Publication date |
---|---|
EP4196915A1 (en) | 2023-06-21 |
WO2023080912A1 (en) | 2023-05-11 |
US20240119295A1 (en) | 2024-04-11 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US11270225B1 (en) | Methods and apparatus for asynchronous and interactive machine learning using word embedding within text-based documents and multimodal documents | |
CN113822494B (en) | Risk prediction method, device, equipment and storage medium | |
CN109388807B (en) | Method, device and storage medium for identifying named entities of electronic medical records | |
CN111191791B (en) | Picture classification method, device and equipment based on machine learning model | |
US10521734B2 (en) | Machine learning predictive labeling system | |
US10824949B2 (en) | Method and system for extracting information from graphs | |
US20180053071A1 (en) | Distributed event prediction and machine learning object recognition system | |
AU2020385264B2 (en) | Fusing multimodal data using recurrent neural networks | |
CN110555469B (en) | Method and device for processing interactive sequence data | |
CN113688304A (en) | Training method for search recommendation model, and method and device for sequencing search results | |
CN111680217A (en) | Content recommendation method, device, equipment and storage medium | |
CN111680147A (en) | Data processing method, device, equipment and readable storage medium | |
WO2023179429A1 (en) | Video data processing method and apparatus, electronic device, and storage medium | |
CN110708285A (en) | Flow monitoring method, device, medium and electronic equipment | |
Loyola et al. | UNSL at eRisk 2021: A Comparison of Three Early Alert Policies for Early Risk Detection. | |
CN116018621A (en) | System and method for training multi-class object classification model using partially labeled training data | |
CN117197722B (en) | User perception and analysis system based on mobile internet video | |
CN113297351A (en) | Text data labeling method and device, electronic equipment and storage medium | |
CN113570512A (en) | Image data processing method, computer and readable storage medium | |
CN116863116A (en) | Image recognition method, device, equipment and medium based on artificial intelligence | |
CN116108363A (en) | Incomplete multi-view multi-label classification method and system based on label guidance | |
CN115269998A (en) | Information recommendation method and device, electronic equipment and storage medium | |
CN116420151A (en) | Universal package for learning from tag proportions | |
CN114898426A (en) | Synonym label aggregation method, device, equipment and storage medium | |
CN112231572A (en) | User feature extraction method, device, equipment and storage medium |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination |