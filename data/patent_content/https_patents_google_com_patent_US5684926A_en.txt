US5684926A - MBE synthesizer for very low bit rate voice messaging systems - Google Patents
MBE synthesizer for very low bit rate voice messaging systems Download PDFInfo
- Publication number
- US5684926A US5684926A US08/592,252 US59225296A US5684926A US 5684926 A US5684926 A US 5684926A US 59225296 A US59225296 A US 59225296A US 5684926 A US5684926 A US 5684926A
- Authority
- US
- United States
- Prior art keywords
- components
- excitation
- voiced
- voicing
- unvoiced
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Expired - Lifetime
Links
Images
Classifications
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L19/00—Speech or audio signals analysis-synthesis techniques for redundancy reduction, e.g. in vocoders; Coding or decoding of speech or audio signals, using source filter models or psychoacoustic analysis
- G10L19/04—Speech or audio signals analysis-synthesis techniques for redundancy reduction, e.g. in vocoders; Coding or decoding of speech or audio signals, using source filter models or psychoacoustic analysis using predictive techniques
- G10L19/16—Vocoder architecture
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L19/00—Speech or audio signals analysis-synthesis techniques for redundancy reduction, e.g. in vocoders; Coding or decoding of speech or audio signals, using source filter models or psychoacoustic analysis
- G10L19/04—Speech or audio signals analysis-synthesis techniques for redundancy reduction, e.g. in vocoders; Coding or decoding of speech or audio signals, using source filter models or psychoacoustic analysis using predictive techniques
- G10L19/08—Determination or coding of the excitation function; Determination or coding of the long-term prediction parameters
- G10L19/09—Long term prediction, i.e. removing periodical redundancies, e.g. by using adaptive codebook or pitch predictor
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L19/00—Speech or audio signals analysis-synthesis techniques for redundancy reduction, e.g. in vocoders; Coding or decoding of speech or audio signals, using source filter models or psychoacoustic analysis
- G10L19/04—Speech or audio signals analysis-synthesis techniques for redundancy reduction, e.g. in vocoders; Coding or decoding of speech or audio signals, using source filter models or psychoacoustic analysis using predictive techniques
- G10L19/08—Determination or coding of the excitation function; Determination or coding of the long-term prediction parameters
- G10L19/10—Determination or coding of the excitation function; Determination or coding of the long-term prediction parameters the excitation function being a multipulse excitation
Definitions
- This invention relates generally to MBE synthesizers for use in communication receivers, and more specifically to an improved MBE synthesizer which utilizes very low bit rate data transmission rates in a compressed voice digital communication system to obtain high quality voice messages.
- Communications systems such as paging systems, have had to in the past compromise the length of messages, number of users and convenience to the user in order to operate the systems profitably.
- the number of users and the length of the messages were limited to avoid over crowding of the channel and to avoid long transmission time delays.
- the user's convenience is directly affected by the channel capacity, the number of users on the channel, system features and type of messaging.
- tone In a paging system, tone only pagers that simply alerted the user to call a predetermined telephone number offered the highest channel capacity but were some what inconvenient to the users.
- Conventional analog voice pagers allowed the user to receive a more detailed message, but severally limited the number of users on a given channel.
- Analog voice pagers being real time devices, also had the disadvantage of not providing the user with a way of storing and repeating the message received.
- the introduction of digital pagers with numeric and alphanumeric displays and memories overcame many of the problems associated with the older pagers. These digital pagers improved the message handling capacity of the paging channel, and provide the user with a way of storing messages for later review.
- the vocoder analyzes short segments of speech, called speech frames, and characterizes the speech in terms of several parameters that are digitized and encoded for transmission.
- the speech characteristics that are typically analyzed include voiding characteristics, pitch, frame energy, and spectral characteristics.
- Vocoder synthesizers used these parameters to reconstruct the original speech by mimicking the human voice mechanism.
- Vocoder synthesizers modeled the human voice as an excitation source, controlled by the pitch and frame energy parameters followed by a spectrum shaping controlled by the spectral parameters.
- the voicing characteristic describes the repetitiveness of the speech waveform. Speech consists of periods where the speech waveform has a repetitive nature and periods where no repetitive characteristics can be detected. The periods where the waveform has a periodic repetitive characteristic are said to be voiced. Periods where the waveform seems to have a totally random characteristic are said to be unvoiced. The voiced/unvoiced characteristics are used by the vocoder speech synthesizer to determine the type of excitation signal which will be used to reproduce that segment of speech. Due to the complexity and irregularities of human speech production, no single parameter can reliably determine when a speech frame is voiced or unvoiced.
- Pitch defines the fundamental frequency of the repetitive portion of the voiced wave form. Pitch is typically defined in terms of a pitch period or the time period of the repetitive segments of the voiced portion of the speech wave forms.
- the speech waveform is a highly complex waveform and very rich in harmonics. The complexity of the speech waveform makes it very difficult to extract pitch information. Changes in pitch frequency must also be smoothly tracked for an MBE vocoder synthesizer to smoothly reconstruct the original speech.
- Most vocoders employ a time-domain auto-correlation function to perform pitch detection and tracking. Auto-correlation is a very computationally intensive and time consuming process. It has also been observed that conventional auto-correlation methods are unreliable when used with speech derived from a telephone network.
- the frequency response of the telephone network causes deep attenuation of the lower harmonics of a speaker having a low pitch frequency (the range of the fundamental frequency of the human voice is 50 Hz to 400 Hz). Because of the deep attenuation of the fundamental frequency, pitch trackers can erroneously identify the second or third harmonic as the fundamental frequency.
- the human auditory process is very sensitive to changes in pitch and the perceived quality of the reconstructed speech is strongly effected by the accuracy of the pitch derived.
- Frame energy is a measure of the normalized average RMS power of the speech frame. This parameter defines the loudness of the speech during the speech frame.
- the spectral characteristics define the relative amplitude of the harmonics and the fundamental pitch frequency during the voiced portions of speech and the relative spectral shape of the noise like unvoiced speech segments.
- the data transmitted defines the spectral characteristics of the reconstructed speech signal. Non optimum spectral shaping results in poor reconstruction of the voice by an MBE vocoder synthesizer and poor noise suppression.
- the human voice during a voiced period, has portions of the spectrum that are voiced and portions that are unvoiced.
- MBE vocoders produce natural sounding voice because the excitation source, during a voiced period, is a mixture of voiced and unvoiced frequency bands.
- the speech spectrum is divided into a number of frequency bands and a determination is made for each band as to the voiced/unvoiced nature of each band.
- the MBE speech synthesizer generates an additional set of data to control the excitation of the voiced speech frames.
- the band voiced/unvoiced decision metric is pitch dependent and computationally intensive. Errors in pitch may lead to errors in the band voiced/unvoiced decision that will affect the synthesized speech quality. Transmission of the band voiced/unvoiced data also substantially increases the quantity of data that must be transmitted.
- MBE synthesizers can generate natural sounding speech at a data rate of 2400 to 6400 bit per second.
- MBE synthesizers are being used in a number of commercial mobile communications systems, such as the INMARSAT (International Marine Satellite Organization) and the ASTROTM portable transceiver manufactured by Motorola Inc. of Schaumburg, Ill.
- the standard MBE vocoder compression methods currently used very successfully by two way radios, fail to provide the degree of compression required for use on a paging channel. Voice messages that are digitally encoded using the current state of the art would monopolize such a large portion of the paging channel capacity that they may render the system commercially unsuccessful.
- Portable communication devices such as paging receivers are typically battery powered. Most paging receivers are powered by a single cell battery such that highly computational processes such as speech synthesizers that require high speed digital signals adversely affect battery life.
- an MBE synthesizer to accurately reproduce voice from compressed data, where the phase and voicing information has been reduced or eliminated from the transmitted data. Also what is needed is an MBE synthesizer that will compensate for non optimum spectral shaping and spectral components caused by poor noise suppression at the encoder by enhances the spectral shaping thus improving clarity and reducing noise. Furthermore there is a need to reduce the computational intensity within the MBE synthesizer for very highly compressed voice messages while maintaining acceptable speech quality.
- an MBE synthesizer generates a segment of speech from compressed speech data which is received by a receiver that is coupled to the MBE synthesizer.
- the compressed speech data received includes one or more indexes.
- the MBE synthesizer includes an excitation generator, a memory, a harmonic amplitude estimator, a multi-band voicing controller and a multiplier.
- the excitation generator generates voiced excitation components and unvoiced excitation components.
- the memory stores a table of predetermined spectral vectors which are identified by the indexes, a portion of the table of the predetermined spectral vectors stored is associated with predetermined voicing vectors.
- the harmonic amplitude estimator is responsive to the one or more predetermined spectral vectors identified by the indexes received for generating harmonic amplitude control signals.
- the multi-band voicing controller is responsive to the predetermined voicing vectors which are associated with the one or more predetermined spectral vectors identified for controlling a selection of the excitation components.
- the multiplier multiplies the harmonic amplitude control signals and the excitation components selected to generate special components representing the segment of speech.
- an MBE synthesizer generates a segment of speech from compressed speech data which is received by a receiver which is coupled to the MBE synthesizer.
- the compressed speech data received includes one or more indexes and pitch dam.
- the MBE synthesizer includes an excitation generator, a memory, a harmonic amplitude estimator, a multi-band voicing controller and a multiplier.
- the excitation generator is responsive to the pitch data and utilizes a transform function to generate transformed voiced excitation components and transformed unvoiced excitation components.
- the memory stores one or more tables of predetermined spectral vectors that are identified by the indexes received.
- the harmonic amplitude estimator generates harmonic amplitude control signals, and is responsive to one or more predetermined spectral vectors that are identified by indexes received.
- the multi-band voicing controller controls a selection of the transformed voiced excitation components and transformed unvoiced excitation components the multiplier multiplies the harmonic amplitude control signals and the transformed voiced excitation components and transformed unvoiced excitation components selected to generate spectral components representing the segment of speech.
- an MBE synthesizer generates a segment of speech from compressed speech data which is received by a receiver which is coupled to the MBE synthesizer.
- the compressed speech data received includes one or more indexes and pitch data.
- the MBE synthesizer includes an exaltation generator, a memory, a harmonic amplitude estimator, a multi-band voicing controller and a multiplier.
- the excitation generator is responsive to the pitch data for generating transformed voiced excitation components and transformed unvoiced excitation components.
- the memory stores one or more tables of predetermined spectral vectors that are identified by the indexes.
- the harmonic amplitude estimator is responsive to one or more predetermined spectral vectors identified by indexes corresponding to the one or more indexes received, and generates harmonic amplitude control signals which are associated with harmonics defined by the pitch data received.
- the multi-band voicing controller controls a selection of the transformed voiced excitation components and transformed unvoiced excitation components.
- the multiplier multiplies the harmonic amplitude control signals, the transformed voiced excitation components and transformed unvoiced excitation components selected to generate spectral components representing the segment of speech.
- the harmonic amplitude estimator also includes a peak detector a peak enhancer, a valley detector and a valley enhancer.
- the peak detector has a peak magnitude threshold and detects harmonic amplitude control signals which have a magnitude greater then the peak magnitude threshold.
- the peak enhancer generates peak enhanced harmonic amplitude control signals by enhancing magnitudes of harmonic amplitude control signals which have magnitudes greater then the peak magnitude threshold.
- the valley detector has a minimum magnitude threshold and detects peak enhanced harmonic amplitude control signals which have a magnitude less then the minimum magnitude threshold.
- the valley enhancer generates enhanced harmonic amplitude control signals by decreasing the magnitudes of the peak enhanced harmonic amplitude control signals which have magnitudes less then the minimum magnitude threshold.
- an MBE synthesizer generates a segment of speech from compressed speech data which is received by a receiver which is coupled to the MBE synthesizer.
- the compressed speech data received includes one or more indexes.
- the MBE synthesizer includes a memory, a harmonic amplitude estimator, a multi-band voicing controller, a multi-band excitation generator and a multiplier.
- the memory stores a table of predetermined spectral vectors identified by indexes, at least a portion of the table of the predetermined spectral vectors is associated with predetermined voicing vectors.
- the predetermined voicing vectors have a plurality of voicing parameters associated with a plurality of bands of spectral information.
- the voicing parameters identify the likelihood of a band of a bands being voiced or unvoiced.
- the harmonic amplitude estimator is responsive to one or more predetermined spectral vectors identified by the one or more indexes for to generate harmonic amplitudes coefficients.
- the multi-band voicing controller is responsive to the predetermined voicing vector and to the harmonic amplitudes coefficients and controls the voiced/unvoiced characteristics of each of the bands of spectral information.
- the multi-band excitation generator generates excitation components which are divided into a plurality of bands of spectral information.
- the multiplier is coupled to the harmonic amplitude estimator and to the multi-band voicing controller and controls the amplitudes of the excitation components by multiplying the harmonic amplitude coefficients and the excitation components to generate a spectral components representing a segment of speech.
- FIG. 1 is a block diagram of a very low bit rate voice messaging system using an improved MBE synthesizer in accordance with the present invention.
- FIG. 2 is an electrical block diagram of the receiver shown in FIG. 1.
- FIG. 3 is a flow chart which illustrates the operation of the receiver of FIG. 2.
- FIG. 4 is an block diagram showing the improved MBE synthesizer in accordance with the present invention.
- FIG. 5 shows the waveform of a typical pitch signal generated by the pitch generator shown in FIG. 4.
- FIG. 6 is a graphic illustration of a portion of a typical LPC function analyzed by the harmonic amplitude estimator shown in FIG. 4.
- FIG. 7 is a flow chart illustrating spectral enhancement within the improved MBE synthesizer of FIG. 4.
- FIG. 8 is a flow chart describing the peak enhancement process shown in FIG. 7.
- FIG. 9 is a flow chart describing the valley enhancement process shown in FIG. 7.
- FIG. 10 is a plot of several harmonics illustrating a harmonic valley determination used in the valley enhancement process of FIG. 9.
- FIG. 11 is a flow chart describing the operation of the voicing controller shown in FIG. 4.
- FIG. 12 shows an electrical block diagram of a digital signal processor used in the receiver 114 of FIG. 2.
- FIG. 1 shows a block diagram of a very low bit rate voice messaging system, such as provided in a paging or data transmission system which utilizes speech compression to provide a very low bit rate speech transmission using an improved Multi Band Exciter (MBE) voice coder (vocoder) in accordance with the present invention.
- MBE Multi Band Exciter
- a paging terminal 106 uses an unique speech analyzer 107 to generate excitation parameters and spectral parameters representing speech data, and the communication receiver, such as a paging receiver 114 uses a unique MBE synthesizer 116 to reproduce the original speech.
- MBE Multi Band Exciter
- a paging system will be utilized to describe the present invention, although it will be appreciated that any non-real time communication system will benefit from the present invention as well.
- a paging system is designed to provide service to a variety of users, each requiring different services. Some of the users may require numeric messaging services, other users alpha-numeric messaging services, and still other users may require voice messaging services.
- the caller originates a page by communicating with a paging terminal 106 via a telephone 102 through a public switched telephone network (PSTN) 104.
- PSTN public switched telephone network
- the paging terminal 106 prompts the caller for the recipient's identification, and a message to be sent.
- the paging terminal 106 Upon receiving the required information, the paging terminal 106 returns a prompt indicating that the message has been received by the paging terminal 106.
- the paging terminal 106 encodes the message and places the encoded message into a transmission queue.
- the paging terminal 106 compresses and encodes the message using a speech analyzer 107.
- the message is transmitted using a transmitter 108 and transmitting antenna 110. It will be appreciated that a simulcast transmission system, utilizing a multiplicity of transmitters covering different geographic areas can be utilized as well.
- the signal transmitted from the transmitting antenna 110 is intercepted by a receiving antenna 112 and processed by a receiver 114, shown in FIG. 1 as a paging receiver.
- Voice messages received are decoded and reconstructed using an MBE synthesizer 116.
- the person being paged is alerted and the message is displayed or annunciated depending on the type of messaging being received.
- the digital voice encoding and decoding process used by the speech analyzer 107 and the MBE synthesizer 116, described herein, is readily adapted to the non-real time nature of paging and any non-real time communication system.
- These non-real time communication systems provide the time required to perform a highly computational compression process on the voice message. Delays of up to two minutes can be reasonably tolerated in paging systems, whereas delays of two seconds are unacceptable in real time communication systems.
- the asymmetric nature of the digital voice compression process described herein minimizes the processing required to be performed at the receiver 114, making the process ideal for paging applications and other similar non-real time voice communications.
- the highly computational portion of the digital voice compression process is performed in the fixed portion of the system, i.e. at the paging terminal 106. Such operation, together with the use of an MBE synthesizer 116 that operates almost entirely in the frequency domain, greatly reduces the computation required to be performed in the portable portion of the communication system.
- the speech analyzer 107 analyzes the voice message and generates spectral parameters and excitation parameters.
- the spectral parameters are generated by first performing a fixed dimension LPC analysis.
- the LPC analysis generates ten spectral parameters.
- Two spectral code books are used to vector quantize the ten spectral parameters into two 11 bits indexes for transmission by the paging terminal 106.
- the speech analyzer 107 does not generate harmonic phase information as in prior art analyzers, but instead a unique frequency domain technique, described below, is used by the MBE synthesizer 116 to artificially regenerate phase information at the receiver 114. This unique technique eliminates the need to transmit additional data to convey the phase information.
- the excitation parameters generated by the speech analyzer 107 to define a segment of speech preferably include a seven bit pitch parameter, a six bit RMS parameter, and an one bit frame voiced/unvoiced parameter. Multi-band voicing information is not generated as in the prior art speech analyzers.
- the pitch parameter defines the fundamental frequency of the repetitive portion of speech. Pitch is measured in vocoders as the period of the fundamental frequency.
- the frame voiced/unvoiced parameter describes the repetitive nature of the sound. Segments of speech that have a highly repetitive waveform are described as voiced, whereas segments of speech that have a random waveform are described as being unvoiced.
- the frame voiced/unvoiced parameter generated by the speech analyzer 107 determines whether the MBE synthesizer 116 uses a periodic signal as an excitation source or a noise like signal source as an excitation source. Frames of speech that are classified as voiced often have spectral portions that are unvoiced.
- the speech analyzer 107 and MBE synthesizer 116 produces excellent quality speech by dividing the voice spectrum into a number of sub-bands and including information describing the voiced/unvoiced nature of the voice signal in each sub-band.
- the sub-band voice/unvoiced parameters in conventional synthesizers, must be degenerated by the speech analyzer 107 and transmitted to the MBE synthesizer 116.
- the voicing information for each sub-band is not transmitted by the paging terminal 106, but a relationship between the sub-band voiced/unvoiced information and the spectral information is established.
- a ten band voicing code book containing the voiced/unvoiced likelihood parameter is associated with a spectral code book.
- the index of the ten band voicing code book is the same as the index of the spectral code book, thus only a common index need be transmitted.
- the present invention uses voicing parameters stored in the voicing code book to generate the ten sub-band voicing information thus eliminating the need to transmit this information as would be required by a convention MBE synthesizer.
- the RMS parameter is a measurement of the total energy of all the harmonics in a frame.
- the RMS parameter is generated by the speech analyzer 107 and is used by the MBE synthesizer 116 to establish the volume of the reproduced speech.
- FIG. 2 is an electrical block diagram of the receiver 114 of FIG. 1, such as a paging receiver or data communication receiver.
- the signal transmitted from the transmitting antenna 110 is intercepted by the receiving antenna 112 which is coupled to a receiver 2004.
- the receiver 2004 processes the signal received by the receiving antenna 112 and produces a receiver output signal 2016 which is a replica of the encoded data transmitted.
- the encoded data is encoded in a predetermined signaling protocol.
- One such encoding method is the InFLEXion® protocol, developed by Motorola Inc. of Schaumburg, Ill., although it will be appreciated that there are other suitable encoding methods that can be utilized as well, for example, the Post Office Code Standards Advisory Group (POCSAG) code.
- POCSAG Post Office Code Standards Advisory Group
- a digital signal processor 2008 performing the function of a decoder, controller and MBE synthesizer 116 processes the receiver output signal 2016 and produces a decompressed digital speech data 2018 as will be described below.
- a digital to analog converter converts the decompressed digital speech data 2018 to an analog signal that is amplified by the audio amplifier 2012 and annunciated by a speaker 2014.
- the digital signal processor 2008 also provides the basic control of the various functions of the receiver 114.
- the digital signal processor 2008 is coupled to a battery saver switch 2006, a code memory 2022, a user interface 2024, and a message memory 2026, via the control bus 2020.
- the code memory 2022 stores unique identification information or address information, necessary for the controller to implement the selective call feature.
- the user interface 2024 provides the user with an audio, visual or mechanical signal indicating the reception of a message and can also include a display and push buttons for the user to input commands to control the receiver.
- the message memory 2026 provides a place to store messages for future review, or to allow the user to repeat the message.
- the battery saver switch 2006 provide a means of selectively disabling the supply of power to the receiver during a period when the system is communicating with other pagers or not transmitting, thereby reducing power consumption and extending battery life in a manner well known to one ordinarily skill in the art.
- FIG. 3 is a flow chart which illustrates the operation of the receiver 114 of FIG. 2.
- the digital signal processor 2008 sends a command to the battery saver switch 2006 to supply power to the receiver 2004.
- the digital signal processor 2008 monitors the receiver output signal 2016 for a bit pattern indicating that the paging terminal is transmitting a signal modulated with a preamble.
- step 2104 a decision is made as to the presence of the preamble.
- the digital signal processor 2008 sends a command to the battery saver switch 2006 to inhibit the supply of power to the receiver 2004 for a predetermined length of time.
- monitoring for preamble is again repeated as is well known in the art.
- the digital signal processor 2008 will synchronize at step 2106 with the receiver output signal.
- the digital signal processor 2008 may issue a command to the battery saver switch 2006 to disable the supply of power to the receiver 2004 until the frame assigned to the receiver 114 is expected. At the assigned frame, the digital signal processor 2008 sends a command to the battery saver switch 2006 to supply power to the receiver 2004.
- the digital signal processor 2008 monitors the receiver output signal 2016 for an address that matches the address assigned to the receiver 114. When no match is found the digital signal processor 2008 sends a command to the battery saver switch 2006 to inhibit the supply of power to the receiver until the next transmission of a synchronization code word or the next assigned frame, after which step 2102 is repeated. When an address match is found then in step 2108, power is maintained to the receiver 2004 and the data is received at step 2110.
- step 2112 error correction is performed on the data received in step 2110 to improve the quality of the voice reproduced.
- the encoded frame provides nine parity bits which are used in the error correction process. Error correction techniques are well known to one of ordinary skill in the art.
- the corrected data is stored in step 2114.
- the stored data is processed in step 2116. The processing of digital voice data de-quantizes and enhances the spectral information, combines the spectral information with the excitation information, artificially generates phase information and synthesizes the voice data as will be described below.
- step 2118 the digital signal processor 2008 stores the voice data, received in the message memory 2026 and sends a command to the user interface 2024 to alert the user.
- step 2120 the user enters a command to play out the message.
- step 2122 the digital signal processor 2008 responds by passing the decompressed voice data that is stored in message memory to the digital to analog converter 2010.
- the digital to analog converter 2010 converts the digital speech data 2018 to an analog signal that is amplified by the audio amplifier 2012 and annunciated by speaker 2014.
- FIG. 4 is a block diagram of the improved MBE synthesizer 116 shown in FIG. 2 and at step 2116 in FIG. 3.
- the MBE synthesizer 116 generates segments of speech from compressed speech data which are received by receiver 114 as preferably a thirty-six bit data word and stored in a buffer 2202.
- the buffer 2202 is also referred to herein as an input buffer 2202.
- the input buffer 2202 preferably stores a minimum of two thirty-six bit data words representing at least two sequential segments of speech.
- the thirty-six bit data words stored in the buffer 2202 and decoded in step 2114 comprises one or more indexes, a first eleven bit index 2240, a second eleven bit index 2242, a six bit RMS data 2244, a one bit of frame voicing data 2246 and seven bits of pitch data 2248.
- the first eleven bit index 2240 is coupled to a co-indexed code book 2204 to provide a first index.
- the second eleven bit index 2242 is coupled to code book two 2206 to provide a second index.
- the co-indexed code book 2204 stores a first table of predetermined spectral vectors 2205 and the code book 2206 stores a second table of predetermined residue vectors.
- Each predetermined spectral vectors 2205 comprises a plurality of spectral parameters.
- the co-indexed code book 2204 also stores a table of associated predetermined voicing vectors 2203.
- Each predetermined voicing vector comprises a plurality of voicing parameters.
- Each of the voicing parameters is associated with a band of excitation components.
- Two LPC parameters from the co-indexed code book 2204 indexed by the first eleven bit index 2240 and the residue LPC parameters from code book two 2206 indexed by the second eleven bit index 2242 are coupled to a harmonic amplitude estimator 2208, a part of an improved harmonic amplitude estimator 2209.
- the six bit RMS data 2244 is also coupled to the harmonic amplitude estimator 2208.
- the improved harmonic amplitude estimator 2209 comprises a harmonic amplitude estimator 2208, a spectral enhancer 2216 and a stair function generator 2218.
- the output of the harmonic amplitude estimator 2208 is coupled to a multi-band voicing controller 2214.
- the one bit of frame voicing data 2246 and the data from the MBE voicing portion of the co-indexed code book 2204 is also coupled to the multi-band voicing controller 2214.
- the output of the harmonic amplitude estimator 2208 is also coupled to a spectral enhancer 2216 which provides a spectral enhancement function.
- the output of the spectral enhancer 2216 is coupled to a stair function generator 2218 which in turn is coupled to a multiplier 2234.
- An excitation generator 2241 generates transformed voiced excitation components and transformed unvoiced excitation components utilizing a transform function.
- the excitation generator 2241 comprises a pitch wave generator 2210, a 256 point framer 2212, a FFT transform generator 2222, a RMS normalization 2224, a random phase generator 2220, and a constant amplitude generator 2228.
- the seven bits of pitch data 2248 is coupled to a pitch wave generator 2210.
- the output of the pitch wave generator 2210 is coupled to a 256 point framer 2212 and the output of the 256 point framer 2212 is coupled to a FFT transform generator 2222.
- a phase output of the FFT transform generator 2222 is coupled to the spectral phase selector 2230.
- the output of a random phase generator 2220 is also coupled to the spectral phase selector 2230.
- An amplitude output of the FFT transform generator 2222 is coupled to a RMS normalization 2224 which is in turn coupled to a spectral amplitude selector 2232.
- the output of a constant amplitude generator 2228 is also coupled to the spectral amplitude selector 2232.
- the multi-band voicing controller 2214 is coupled to a stair function generator 2215 which in turn is coupled to and controls the spectral phase selector 2230 and the spectral amplitude selector 2232.
- the spectral phase selector 2230 and the spectral amplitude selector 2232 are also referred to herein as a selector 2231.
- the output of the spectral phase selector 2230 is coupled to an IFFT inverse transform generator 2226.
- the output of the spectral amplitude selector 2232 is coupled to the multiplier 2234.
- the multiplier 2234 is also coupled the harmonic amplitude estimator for generating spectral amplitude components which in turn are coupled to the IFFT inverse transform generator 2226.
- the output of the IFFT inverse transform generator 2226 is coupled to an overlap adder 2236 which produces digitized samples of the original speech message.
- the harmonic amplitude estimator 2208 is coupled to the LPC parameters in a predetermined spectral vector 2205 stored in the voicing portion of the co-indexed code book 2204, in a spectral vector stored in the code book two 2206, and the seven bits of pitch data 2248 from the thirty-six bit data word stored in the buffer 2202 to generate a variable length harmonic amplitude function S(i).
- the speech spectral amplitude information is conveyed by the two eleven bit indexes which are received and which are part of the thirty-six bit data word stored in the buffer 2202.
- the first eleven bit index 2240 points to a first predetermined spectral vector of the table of predetermined spectral vectors 2205 stored in the voicing portion of the co-indexed code book 2204.
- the table of predetermined spectral vectors 2205 stored in the voicing portion of the co-indexed code book 2204 is a duplicate of the table of predetermined spectral vectors, which comprise a spectral code book used by the paging terminal 106 during the speech compression process.
- the first spectral vector contains a first set of LPC parameters.
- the second eleven bit index 2242 points to a second predetermined spectral vector of a second table of predetermined residue vectors stored in the code book 2206.
- the second residue vector contains a second set of residue LPC parameters.
- the first set of LPC parameters is added to the second set of LPC parameters to produce a set of LPC parameters that are used to determine the amplitude of the spectral component produced by the excitation generator 2241.
- the length of the variable length harmonic amplitude function, S(i) is determined by the seven bits of pitch data 2248.
- the variable length function S(i) has one spectral gain parameter for each harmonic of the pitch signal.
- the generation of the pitch signal is described below.
- the number of harmonics in the pitch signal is a function of the pitch and is calculated using the following formula. ##EQU1##
- INT is a function that returns a integer value
- N the number of harmonics.
- the function S(i) is multiplied by a value derived from the value of the six bit RMS code received as part of the thirty-six bit data word stored in the buffer 2202.
- the RMS code sets the volume of the segment of speech being reproduced
- the parameters of the function S(i), generated, by the harmonic amplitude estimator 2208, are analyzed and adjusted by a spectral enhancer 2216.
- the spectral enhancement function of the spectral enhancer 2216 compensates for the under estimation of the harmonic amplitude by harmonic amplitude estimator 2208 and for the spectral distortion generated by noise.
- the spectral enhancement function 2216 generates the enhanced function S"(i). It will be appreciated by one skilled in the art that the spectral information can also be pre-enhanced at the paging terminal 106 prior to transmission. The operation of the spectral enhancement function is described below.
- a stair function generator 2218 transforms the variable length function S"(i) into a fixed length function of 128 points.
- the function S"(i) has one spectral gain parameter for each harmonic of the fundamental frequency of the pitch signal.
- the 128 points are divided up into a number of bands, one band for each harmonic, with each band centered about each harmonic. The value of all the points of the function that fall into each band is set equal to the corresponding spectral gain parameter.
- the resulting spectral gain factor function has a stair step appearance.
- a pitch wave generator 2210 produces the basic synchronous pitch signal, responsive to the seven bits of pitch data 2248 that was received and stored in the thirty-six bit data word buffer 2202.
- the synchronous pitch signal is used by the MBE synthesizer 116 to reproduce the original speech.
- the pitch is defined as the number of samples between the repetitive portions of the pitch signal.
- the pitch signal has the range of 20 to 128.
- a value of one is subtracted from the pitch data prior to transmission such that the pitch can be encoded using seven bits. A value of one must be added back at the receiver by the digital signal processor 2008 to correct for the value of one subtracted at the transmitter.
- FIG. 5 shows, by way of example, the wave from of a typical pitch signal.
- the wave form is a sequence of replicated, pre-defined pulses 2302 of a fixed duration with variable pitch distance 2304 between start of the pulses.
- the distance between the predefined pulses 2302 in the first half of the frame is continuously interpolated between the ending distance of the previous frame and the distance defined by the current seven bits of pitch data 2248 received.
- the distance in the last half of the frame is continuously interpolated between the distance defined by the current seven bits of pitch data 2248 received and the distance defined by the seven bits of pitch data 2248 received for the subsequent frame.
- the interpolation produces a pitch signal that smoothly follows the changes in the pitch data.
- the pre-defined pulses 2302 are stored as a table of values in the MBE synthesizer 116.
- Two hundred fifty six points of the pitch signal are framed by the 256 point framer 2212 to produce a windowed sequence of repetitive digitized pitch samples of a predetermined length.
- An FFT is performed on the 256 sample frame to produce 128 point Fourier amplitude function containing discrete Fourier voiced amplitude components and a 128 point Fourier phase function containing discrete Fourier voiced phase components.
- No phase information is transmitted in the present invention, and therefor the phase information is regenerated by the FFT transform generator 2222 calculation of the FFT spectrum of the pitch signal 2300 is used to derive phase information.
- This artificially generated phase information produces natural sounding speech without the burden of transmitting the large quantity of information necessary to convey the phase information, as in the prior art MBE synthesizers.
- Each pre-defined pulses 2302 has a fixed duration and amplitude, resulting in a fixed amount of energy, and therefor the power of the pitch signal is a function of the number of pre-defined pulses 2302 in each frame. Frames having fewer pitch pulses therefor have less power than frames having more pitch pulses.
- the RMS normalization 2224 normalizes Fourier amplitude function to maintain the total energy at a predetermined energy level for pitch signals of all frames.
- the normalized Fourier amplitude function and Fourier phase function as used as an excitation source for the MBE synthesizer during voiced periods to reproduce the original speech.
- the constant amplitude generator 2228 produces discrete Fourier unvoiced amplitude components of a constant amplitude and the random phase generator 2220 produces discrete Fourier unvoiced phase components.
- the one bit of frame voicing data 2246 is use by the multi-band voicing controller 2214 along with ten band predetermined voicing vector 2203, P, that is stored in a MBE voicing portion of the co-indexed code book 2204 and spectral gain parameters in the function S(i) to determine the voiced/unvoiced characteristics of the speech being reproduced.
- the first eleven bit index 2240 points to the first predetermined spectral vector of the table of predetermined spectral vectors 2225 stored in the co-indexed code book 2204 is also used to index a ten band predetermined voicing vector 2203, P, stored in the MBE voicing portion of the co-indexed code book 2204.
- the operation of the multi-band voicing controller 2214 is described below.
- the multi-band voicing controller 2214 produces a variable length binary function h(i).
- the stair function generator 2215 transforms the variable length binary function h(i) into a fixed length binary function of 128 points.
- the function h(i) has a one bit binary parameter for each of the harmonics of the fundamental frequency of the pitch signal.
- the 128 points of the fixed length function are divided up into a number of bands, one band for each harmonic, with each band centered about the harmonic. The value of all the points of the fixed length function that fall into each band is set equal to the corresponding binary voicing parameter.
- the output of the stair function generator 2215 is coupled to the spectral phase selector 2230 and the spectral amplitude selector 2232 to enable the multi-band voicing controller 2214 to control a selection of phase excitation components from the discrete Fourier voiced phase components and from the discrete Fourier unvoiced phase components, and to further controls a selection of amplitude excitation components from the discrete Fourier voiced amplitude components and from the discrete Fourier unvoiced amplitude components.
- the spectral phase selector 2230 selects the Fourier phase function from the FFT transform generator 2222 and the spectral amplitude selector 2232 selects the Fourier amplitude function from the FFT transform generator 2222.
- the output of the multi-band voicing controller 2214 is set to a value of 0 the spectral phase selector 2230 selects the phase information from the random phase generator 2220 and the spectral amplitude selector 2232 selects the Fourier amplitude function from the constant amplitude generator 2228.
- the FFT amplitude function from the spectral amplitude selector 2232 is coupled to the multiplier 2234.
- the multiplier 2234 multiplies the Fourier amplitude function from the spectral amplitude selector 2232 by harmonic amplitude control signals defined in the spectral gain factor function generated by the stair function generator 2218 to produce a Fourier function containing the spectral amplitude information.
- the phase information from the spectral phase selector 2230 and the Fourier function from the multiplier 2234 are coupled to the IFFT inverse transform generator 2226.
- the IFFT inverse transform generator 2226 performs a Inverse Fourier Transform (IFFT) to produce a time domain function.
- IFFT Inverse Fourier Transform
- the time domain function is overlapped by the past and future frame in the overlap adder 2236 to generate a pulse amplitude coded representation of the original speech.
- the sampled speech segments are extended such that all segments overlap the previous and future segments by fifty percent.
- An overlap adder function 2236 tends to smooth the transition between speech segments.
- the operation of the overlap adder function 2236 is well known to one of ordinary skill in the art.
- FIG. 6 shows, by way of example, a graphic illustration of a portion of a typical LPC function analyzed by the harmonic amplitude estimator 2208 shown in FIG. 4.
- the LPC parameters resulting from the addition of the first set of LPC parameters from the co-indexed code book 2204 and the second set of LPC parameters from the code book two 2206 have ten coefficients.
- the ten coefficients are coefficients of a polynomial that define a continuous LPC function 2402.
- the value of the continuous LPC function 2402 is calculated at two hundred fifty six points.
- the two hundred fifty six points are divided into a number of bands, with the number of bands equal to the number of harmonics.
- the number of harmonics being a function of pitch as described above.
- the first six harmonic bands, N 1 through N 6 are shown by way of example in FIG. 6.
- the harmonic band N 4 has seven, A 1 through A 7 of the two hundred fifty six points of the continuous LPC function 2402.
- the harmonic amplitude estimate is defined by the following equation. ##EQU2##
- H i the amplitude of harmonic i
- j the number of the 256 points that fall band i.
- the function H i is multiplied by a value derived from the value of the six bit RMS data 2244 received as part of the thirty-six bit data word stored in the buffer 2202 to produce S(i).
- the function S(i) is a discrete function comprising a harmonic amplitude control signal for each harmonic of the pitch signal.
- FIG. 7 is a flow chart illustrating the spectral enhancement function within the improved MBE synthesizer of FIG. 4.
- the spectral enhancement function performed by the spectral enhancer 2216 is a two step process.
- the spectral gain parameters generated by the harmonic amplitude estimator 2208 are a variable length function S(i) 2502.
- the function S(i) 2502 has one parameter for each harmonic amplitude estimated above.
- the parameters are also referred to herein as harmonic amplitude control signals.
- a peak detector 2503 is provided for detecting harmonic amplitude control signals having a magnitude greater then a peak magnitude threshold and a peak enhancer 2505 is provided for generating peak enhanced harmonic amplitude control signals by enhancing magnitudes of harmonic amplitude control signals having magnitudes greater then the peak magnitude threshold.
- the levels of the harmonics that occur at the peaks of the function S(i) 2502 are increased, generating function S'(i) 2506.
- a valley detector 2507 is provided for detecting peak enhanced harmonic amplitude control signals having a magnitude less then a minimum magnitude threshold
- a valley enhancer 2509 is provided for generating enhanced harmonic amplitude control signals by decreasing the magnitudes of the peak enhanced harmonic amplitude control signals having magnitudes less then the minimum magnitude threshold.
- the level of the harmonics that occur at the valleys of the function S'(i) 2506 are reduced, generating the function S"(i) 2510.
- FIG. 8 is a flow chart of the peak enhancement process of step 2504 of FIG. 7.
- the steps of the flow chart associated with the peak detector 2503 and the peak enhancer 2505 are enclosed with a dotted line.
- the peak enhancement process starts at step 2602 where a search is made of the function S(i) for the parameter S i having a maximum amplitude, S i Max.
- the variable i is set equal to 1.
- step 2608 a test is made to determine if the frame is voiced or unvoiced by checking the frame voiced/unvoiced bit, which is part of the thirty-six bit data word stored in the buffer 2202.
- S'(i) is set equal to S(i) and then at step 2620 S'(i) is returned.
- a test is made to determine if the value of S i is greater than a predetermined proportion of S i Max, where the predetermined proportion is preferably 0.5.
- the value of S' i is multiplied by a predetermined number, where the predetermined number is preferably 1.2.
- S i is not greater than 0.5*S i Max then at step 2614 the value of S' i is set equal to S i .
- step 2616 the value of i is incremented by 1. Then at step 2618 a test is made to determine if the value i is greater than the number N of parameters in S(i). When the value of i is not greater than N the process goes to step 2610 where this process is repeated on the next parameter. When the value of i is not greater than N, then at step 2612 S'(i) is returned.
- FIG. 9 is a flow chart showing the valley enhancement process of step 2508 of FIG. 7.
- the steps of the flow chart associated with the valley detector 2507 and the valley enhancer 2509 are enclosed with a dotted line.
- a search is made of the function S'(i) for the parameter S' i having the largest value, S' i Max.
- S' i Max the largest value
- N the number of parameters in S(i)
- S i Max the largest parameter of S(i).
- step 2706 the value of i is incremented by a value of one. Then at step 2708 a test is made to determine if the value of i is greater then N. When the value of i is greater than N the process is complete and the value of S"(i) is returned at step 2714. When the value of i is not greater than N the process continues at step 2710.
- a test is made to determine if the value of i is greater then the constant k 1 .
- the value of i is not grater than k 1 no enhancement is made and the process goes to step 2714 where the value of S" i is set equal to S' i , followed by step 2706 where i is incremented by a value of one in preparation to examine the next i.
- a test is made at step 2712 to determine if the parameter is in a valley. The test to determine if the parameter is in a valley is described below.
- step 2712 When at step 2712 it is determined that the parameter is not in a valley then no enhancement is made and the process goes to step 2714 where the value of S" i is set equal to S' i , followed by step 2706 where i is incremented by a value of one in preparation to examine the next i.
- step 2712 it is determined that the parameter is in a valley the process goes to step 2714 where the enhanced valley value is determined.
- a test is made to determine if the value of i is greater than k 0 .
- the value of the variable c i is set equal to c 0 at step 2718.
- the value of the variable c i is calculated by the following formulas at step 2716. ##EQU3##
- a threshold, t is calculated using the following formula ##EQU4##
- the digital signal processor 2008 performs the function of a magnitude comparator to determine if the value of S' i is greater then threshold t.
- the digital signal 2008 performs the function of a magnitude calculator to calculate the value of S" i using the following first predetermined formula ##EQU5##
- the digital signal processor 2008 performs the function of a magnitude calculator to calculate the value of S" i using the following second predetermined formula
- FIG. 10 is, by way of example, a plot of several typical harmonics illustrating harmonic valley determination used in the enhancement process of FIG. 9.
- a harmonics amplitude must be less then the two adjacent harmonics by a predetermined amount to qualify as a valley.
- N 7 through N 11 are shown. Harmonic N 9 has the lowest amplitude.
- N 8 a first adjacent peak enhanced harmonic amplitude control signal
- N 10 a second adjacent peak enhanced harmonic amplitude control signal
- N 8 has the largest amplitude.
- the harmonic must be less than the lesser of a first predetermined proportion, preferably 60%, of the amplitude of the highest adjacent harmonic and less than a second predetermined proportion, preferably 80%, of the opposite adjacent harmonic amplitude control signal.
- N 9 must be less than 60% of the amplitude of N 8 and N 9 must be less than 80% of N 10 to qualify as an valley.
- FIG. 11 is a flow chart describing the operation of the multi-band voicing controller 2214 shown in FIG. 4.
- the voicing controller 2214 examines every harmonic of the pitch signal and generates a variable length binary function, having a bit for each harmonic, indicating the voicing characteristic of each harmonic.
- the process starts at 2902.
- a test of the frame voiced/unvoiced bit which is part of the thirty-six bit data word stored in the buffer 2202 is made to determine if the frame is designated as voiced or unvoiced.
- the frame is designated as unvoiced then at step 2906 all harmonics are designated as unvoiced and the process is completed at step 2908.
- step 2904 the frame is designated as voiced then at step 2910 the variable i is initialized to a value of one.
- a determination is made to determine which of the ten MBE bands the harmonic i is falls in and i is set equal to that band.
- step 2914 a test is made to determine if i is less then a value of 4.
- j is less than a value of 4
- a test is made at step 2916 to determine if the value of the parameter P j of the vector P is greater than a value of 0.5.
- the process goes to step 2926 where the value of H i is set equal to a value of 1.
- step 2924 the value of H i is set equal to a value of 0.
- step 2914 When at step 2914 the value of j is not less than a value of 4 a test is made at step 2918 to determine if the value of the parameter P j of the vector P is greater than a value of 0.7. When the value of the parameter P j is greater than a value of 0.7. The process goes to step 2926 where the value of H i is set equal to a value of 1.
- step 2918 the value of the parameter P j is not greater than a value of 0.7 the process goes to step 2920 where a test is made to determine if P j is less than a value of 0.3.
- step 2924 the value of H i is set equal to a value of 0.
- step 2920 value of P j is not less than a value of 0.3 the process goes to step 2922 where a test is made to determine if the harmonic S i is the strongest harmonic in the harmonics in band j.
- the process goes to step 2926 where the value of H i is set equal to a value of 1.
- the process goes to step 2924 where the value of H i is set equal to a value of 0.
- step 2928 the value of i is incremented by one.
- a test is made to determine if the value of i is greater than the number of the maximum harmonic in the function S(i).
- the process goes to step 2912 where the voicing determination is made on the next harmonic.
- the process is complete at step 2908 where H(i) is returned.
- FIG. 12 shows an electrical block diagram of the digital signal processor 2008 used in the receiver 114 shown in FIG. 2.
- the processor 3004 is one of several standard commercially available digital signal processor ICs specifically designed to perform the computations associated with digital signal processing. Digital signal processor ICs are available from several different manufactures. One such processor is the DSP56100 manufactured by Motorola Inc. of Schaumburg, Ill.
- the processor 3004 is coupled to a read only memory (ROM) 3006, a RAM 3008, a digital input port 3012, a digital output port 3014, and a control bus port 3016, via the processor address and data bus 3010.
- the ROM 3006 stores the instructions used by the processor 3004 to perform the signal processing function required to decompress the message and to interface with the control bus port 3016.
- the ROM 3006 also contains the instructions to perform the functions associated with compressed voice messaging.
- the RAM 3008 provides temporary storage of data and program variables.
- the digital input port 3012 provides the interface between the processor 3004 and the receiver 2004 under control of the data input function.
- the digital output port 3014 provides the interface between the processor 3004 and the digital to analog converter 2010 under control of the output control function.
- the control bus port 3016 provides an interface between the processor 3004 and the control bus 2020.
- a clock 3002 generates a timing signal for the processor 3004.
- the ROM 3006 stores by way of example the following: a receiver control function routine 3018, a user interface function routine 3020, a data input function routine 3022, a POCSAG decoding function routine 3024, a code memory interface function routine 3026, an address compare function routine 3028, a processing routine for the multi-band voicing controller 2214, a processing routine for the pitch wave generator 2210, a processing routine for the harmonic amplitude estimator 2208, a processing routine for the spectral enhancement function 2216, a processing routine for the FFT transform generator 2222, a processing routine for the IFFT inverse transform generator 2226, a message memory interface function routine 3042, a processing routine for the overlap adder 2236, an output control function routine 3048 and one or more code books 3046 comprising one or more tables of predetermined spectral vectors 2205 identified by indexes and associated predetermined voicing vectors 2203, as described above.
- speech sampled at an 8 KHz rate and encoded using conventional telephone techniques requires a data rate of 64 Kilo bits per second.
- speech encoded in accordance with the present requires a substantial slower transmission rate.
- speech sampled at a 8 KHz rate and grouped into frames representing 25 milliseconds of speech in accordance with the present invention can be transmitted at an average data rate of 1,440 bits per second.
- the very low bit rate voice messaging system in accordance with the present invention digitally encodes the voice messages in such a way that the resulting data is very highly compressed and can easily be mixed with the normal data sent over a paging channel.
- the operation of the improved MBE synthesizer in accordance with the present invention provides an apparatus and method for providing multi-band voicing information which is not provided in the transmission of the encoded speech.
- the improved MBE synthesizer utilizes a unique time domain processing system that reduces processing complexity and time, and provides a natural sounding voice message while artificially generating phase information which is absent in the encoded speech transmission.
- the improved MBE synthesizer enhances the spectral information to improve the speech quality and reduces noise.
- the voice message is digitally encoded in such a way that processing in the receiver is minimized. While specific embodiments of this invention have been shown and described, it can be appreciated that further modification and improvement will occur to those skilled in the art.
Abstract
Description
S"=a*S'.sub.i
Claims (30)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US08/592,252 US5684926A (en) | 1996-01-26 | 1996-01-26 | MBE synthesizer for very low bit rate voice messaging systems |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US08/592,252 US5684926A (en) | 1996-01-26 | 1996-01-26 | MBE synthesizer for very low bit rate voice messaging systems |
Publications (1)
Publication Number | Publication Date |
---|---|
US5684926A true US5684926A (en) | 1997-11-04 |
Family
ID=24369935
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US08/592,252 Expired - Lifetime US5684926A (en) | 1996-01-26 | 1996-01-26 | MBE synthesizer for very low bit rate voice messaging systems |
Country Status (1)
Country | Link |
---|---|
US (1) | US5684926A (en) |
Cited By (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5873059A (en) * | 1995-10-26 | 1999-02-16 | Sony Corporation | Method and apparatus for decoding and changing the pitch of an encoded speech signal |
WO1999050832A1 (en) * | 1998-03-30 | 1999-10-07 | Motorola Inc. | Voice recognition system in a radio communication system and method therefor |
WO1999053480A1 (en) * | 1998-04-13 | 1999-10-21 | Motorola Inc. | A low complexity mbe synthesizer for very low bit rate voice messaging |
WO2001006494A1 (en) * | 1999-07-19 | 2001-01-25 | Qualcomm Incorporated | Method and apparatus for identifying frequency bands to compute linear phase shifts between frame prototypes in a speech coder |
US20010001853A1 (en) * | 1998-11-23 | 2001-05-24 | Mauro Anthony P. | Low frequency spectral enhancement system and method |
US20090254350A1 (en) * | 2006-07-13 | 2009-10-08 | Nec Corporation | Apparatus, Method and Program for Giving Warning in Connection with inputting of unvoiced Speech |
CN103946918A (en) * | 2011-09-28 | 2014-07-23 | Lg电子株式会社 | Voice signal encoding method, voice signal decoding method, and apparatus using the same |
Citations (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4885790A (en) * | 1985-03-18 | 1989-12-05 | Massachusetts Institute Of Technology | Processing of acoustic waveforms |
US4937873A (en) * | 1985-03-18 | 1990-06-26 | Massachusetts Institute Of Technology | Computationally efficient sine wave synthesis for acoustic waveform processing |
US5081681A (en) * | 1989-11-30 | 1992-01-14 | Digital Voice Systems, Inc. | Method and apparatus for phase synthesis for speech processing |
US5195166A (en) * | 1990-09-20 | 1993-03-16 | Digital Voice Systems, Inc. | Methods for generating the voiced portion of speech signals |
US5216747A (en) * | 1990-09-20 | 1993-06-01 | Digital Voice Systems, Inc. | Voiced/unvoiced estimation of an acoustic signal |
US5574823A (en) * | 1993-06-23 | 1996-11-12 | Her Majesty The Queen In Right Of Canada As Represented By The Minister Of Communications | Frequency selective harmonic coding |
US5630011A (en) * | 1990-12-05 | 1997-05-13 | Digital Voice Systems, Inc. | Quantization of harmonic amplitudes representing speech |
-
1996
- 1996-01-26 US US08/592,252 patent/US5684926A/en not_active Expired - Lifetime
Patent Citations (9)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4885790A (en) * | 1985-03-18 | 1989-12-05 | Massachusetts Institute Of Technology | Processing of acoustic waveforms |
US4937873A (en) * | 1985-03-18 | 1990-06-26 | Massachusetts Institute Of Technology | Computationally efficient sine wave synthesis for acoustic waveform processing |
US5081681A (en) * | 1989-11-30 | 1992-01-14 | Digital Voice Systems, Inc. | Method and apparatus for phase synthesis for speech processing |
US5081681B1 (en) * | 1989-11-30 | 1995-08-15 | Digital Voice Systems Inc | Method and apparatus for phase synthesis for speech processing |
US5195166A (en) * | 1990-09-20 | 1993-03-16 | Digital Voice Systems, Inc. | Methods for generating the voiced portion of speech signals |
US5216747A (en) * | 1990-09-20 | 1993-06-01 | Digital Voice Systems, Inc. | Voiced/unvoiced estimation of an acoustic signal |
US5226108A (en) * | 1990-09-20 | 1993-07-06 | Digital Voice Systems, Inc. | Processing a speech signal with estimated pitch |
US5630011A (en) * | 1990-12-05 | 1997-05-13 | Digital Voice Systems, Inc. | Quantization of harmonic amplitudes representing speech |
US5574823A (en) * | 1993-06-23 | 1996-11-12 | Her Majesty The Queen In Right Of Canada As Represented By The Minister Of Communications | Frequency selective harmonic coding |
Cited By (14)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5873059A (en) * | 1995-10-26 | 1999-02-16 | Sony Corporation | Method and apparatus for decoding and changing the pitch of an encoded speech signal |
WO1999050832A1 (en) * | 1998-03-30 | 1999-10-07 | Motorola Inc. | Voice recognition system in a radio communication system and method therefor |
WO1999053480A1 (en) * | 1998-04-13 | 1999-10-21 | Motorola Inc. | A low complexity mbe synthesizer for very low bit rate voice messaging |
US6694291B2 (en) * | 1998-11-23 | 2004-02-17 | Qualcomm Incorporated | System and method for enhancing low frequency spectrum content of a digitized voice signal |
US20010001853A1 (en) * | 1998-11-23 | 2001-05-24 | Mauro Anthony P. | Low frequency spectral enhancement system and method |
WO2001006494A1 (en) * | 1999-07-19 | 2001-01-25 | Qualcomm Incorporated | Method and apparatus for identifying frequency bands to compute linear phase shifts between frame prototypes in a speech coder |
US6434519B1 (en) | 1999-07-19 | 2002-08-13 | Qualcomm Incorporated | Method and apparatus for identifying frequency bands to compute linear phase shifts between frame prototypes in a speech coder |
KR100756570B1 (en) | 1999-07-19 | 2007-09-07 | 퀄컴 인코포레이티드 | Method and apparatus for identifying frequency bands to compute linear phase shifts between frame prototypes in a speech coder |
US20090254350A1 (en) * | 2006-07-13 | 2009-10-08 | Nec Corporation | Apparatus, Method and Program for Giving Warning in Connection with inputting of unvoiced Speech |
US8364492B2 (en) * | 2006-07-13 | 2013-01-29 | Nec Corporation | Apparatus, method and program for giving warning in connection with inputting of unvoiced speech |
CN103946918A (en) * | 2011-09-28 | 2014-07-23 | Lg电子株式会社 | Voice signal encoding method, voice signal decoding method, and apparatus using the same |
US20140236581A1 (en) * | 2011-09-28 | 2014-08-21 | Lg Electronics Inc. | Voice signal encoding method, voice signal decoding method, and apparatus using same |
US9472199B2 (en) * | 2011-09-28 | 2016-10-18 | Lg Electronics Inc. | Voice signal encoding method, voice signal decoding method, and apparatus using same |
CN103946918B (en) * | 2011-09-28 | 2017-03-08 | Lg电子株式会社 | Voice signal coded method, voice signal coding/decoding method and use its device |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US6018706A (en) | Pitch determiner for a speech analyzer | |
EP1337999B1 (en) | Method and system for comfort noise generation in speech communication | |
RU2214048C2 (en) | Voice coding method (alternatives), coding and decoding devices | |
US6496798B1 (en) | Method and apparatus for encoding and decoding frames of voice model parameters into a low bit rate digital voice message | |
US6996523B1 (en) | Prototype waveform magnitude quantization for a frequency domain interpolative speech codec system | |
EP0843301B1 (en) | Methods for generating comfort noise during discontinous transmission | |
US6418405B1 (en) | Method and apparatus for dynamic segmentation of a low bit rate digital voice message | |
US6931373B1 (en) | Prototype waveform phase modeling for a frequency domain interpolative speech codec system | |
US7013269B1 (en) | Voicing measure for a speech CODEC system | |
US5933803A (en) | Speech encoding at variable bit rate | |
US6081776A (en) | Speech coding system and method including adaptive finite impulse response filter | |
US6119082A (en) | Speech coding system and method including harmonic generator having an adaptive phase off-setter | |
US6370500B1 (en) | Method and apparatus for non-speech activity reduction of a low bit rate digital voice message | |
US6138092A (en) | CELP speech synthesizer with epoch-adaptive harmonic generator for pitch harmonics below voicing cutoff frequency | |
US6418407B1 (en) | Method and apparatus for pitch determination of a low bit rate digital voice message | |
US6064955A (en) | Low complexity MBE synthesizer for very low bit rate voice messaging | |
JPH0713600A (en) | Vocoder ane method for encoding of drive synchronizing time | |
WO2000075919A1 (en) | Methods and apparatus for generating comfort noise using parametric noise model statistics | |
KR19980702591A (en) | Method and apparatus for speech compression in a communication system | |
US6424942B1 (en) | Methods and arrangements in a telecommunications system | |
JP4860859B2 (en) | Method and apparatus for subsampling phase spectral information | |
US5806038A (en) | MBE synthesizer utilizing a nonlinear voicing processor for very low bit rate voice messaging | |
US5684926A (en) | MBE synthesizer for very low bit rate voice messaging systems | |
US6772126B1 (en) | Method and apparatus for transferring low bit rate digital voice messages using incremental messages | |
Wong et al. | Low rate speech coding for telecommunications |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: MOTOROLA, INC., ILLINOISFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:HUANG, JIAN-CHENG;LI, XIAOJUN;SIMPSON, FLOYD;REEL/FRAME:007887/0320Effective date: 19960123 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
FEPP | Fee payment procedure |
Free format text: PAYOR NUMBER ASSIGNED (ORIGINAL EVENT CODE: ASPN); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
FPAY | Fee payment |
Year of fee payment: 4 |
|
FPAY | Fee payment |
Year of fee payment: 8 |
|
FPAY | Fee payment |
Year of fee payment: 12 |
|
AS | Assignment |
Owner name: MOTOROLA MOBILITY, INC, ILLINOISFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:MOTOROLA, INC;REEL/FRAME:025673/0558Effective date: 20100731 |
|
AS | Assignment |
Owner name: MOTOROLA MOBILITY LLC, ILLINOISFree format text: CHANGE OF NAME;ASSIGNOR:MOTOROLA MOBILITY, INC.;REEL/FRAME:029216/0282Effective date: 20120622 |
|
AS | Assignment |
Owner name: GOOGLE TECHNOLOGY HOLDINGS LLC, CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:MOTOROLA MOBILITY LLC;REEL/FRAME:034487/0001Effective date: 20141028 |