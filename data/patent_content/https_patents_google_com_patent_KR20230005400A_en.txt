KR20230005400A - Text or voice communication using standard utterances - Google Patents
Text or voice communication using standard utterances Download PDFInfo
- Publication number
- KR20230005400A KR20230005400A KR1020227043712A KR20227043712A KR20230005400A KR 20230005400 A KR20230005400 A KR 20230005400A KR 1020227043712 A KR1020227043712 A KR 1020227043712A KR 20227043712 A KR20227043712 A KR 20227043712A KR 20230005400 A KR20230005400 A KR 20230005400A
- Authority
- KR
- South Korea
- Prior art keywords
- standard
- utterance
- utterances
- user
- processor
- Prior art date
Links
Images
Classifications
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/08—Speech classification or search
- G10L15/18—Speech classification or search using natural language modelling
- G10L15/1815—Semantic context, e.g. disambiguation of the recognition hypotheses based on word meaning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/40—Processing or translation of natural language
- G06F40/58—Use of machine translation, e.g. for multi-lingual retrieval, for server-side translation for client devices or for real-time translation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/30—Semantic analysis
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/30—Information retrieval; Database structures therefor; File system structures therefor of unstructured textual data
- G06F16/36—Creation of semantic tools, e.g. ontology or thesauri
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/005—Language recognition
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/08—Speech classification or search
- G10L15/18—Speech classification or search using natural language modelling
- G10L15/183—Speech classification or search using natural language modelling using context dependencies, e.g. language models
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/26—Speech to text systems
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L25/00—Speech or voice analysis techniques not restricted to a single one of groups G10L15/00 - G10L21/00
- G10L25/48—Speech or voice analysis techniques not restricted to a single one of groups G10L15/00 - G10L21/00 specially adapted for particular use
- G10L25/51—Speech or voice analysis techniques not restricted to a single one of groups G10L15/00 - G10L21/00 specially adapted for particular use for comparison or discrimination
- G10L25/54—Speech or voice analysis techniques not restricted to a single one of groups G10L15/00 - G10L21/00 specially adapted for particular use for comparison or discrimination for retrieval
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/08—Speech classification or search
- G10L2015/088—Word spotting
Abstract
메모리는 표준 발언 세트을 나타내는 정보를 저장한다. 프로세서는 애플리케이션의 제1 사용자로부터의 발언을 나타내는 정보를 수신하고 제1 사용자로부터의 발언과 표준 발언 세트의 시맨틱 비교에 기초하여 표준 발언 세트로부터 표준 발언을 선택한다. 시맨틱 비교에는 시맨틱 자연어 처리 기계 학습 모델에 의해 수행될 수 있는 시맨틱 검색 및 시맨틱 유사성 연산이 포함된다. 프로세서는 제1 사용자로부터의 발언을 제공하는 대신 애플리케이션의 제2 사용자에게 표준 발언을 제공한다. 경우에 따라 프로세서는 텍스트 스트림 또는 음성 채팅에서 사용자로부터의 발언을 표준 발언 세트의 표준 발언으로 대체한다.The memory stores information representing a set of standard utterances. The processor receives information representing a utterance from a first user of the application and selects a standard utterance from the set of standard utterances based on a semantic comparison of the set of standard utterances with the utterance from the first user. Semantic comparison includes semantic search and semantic similarity operations that can be performed by semantic natural language processing machine learning models. Instead of providing a utterance from the first user, the processor provides a standard utterance to the second user of the application. Optionally, the processor replaces utterances from the user in the text stream or voice chat with standard utterances from the standard utterance set.
Description
텍스트 또는 음성 채팅은 애플리케이션(예를 들어, 비디오 게임) 사용자가 애플리케이션을 사용하여 동시에 커뮤니케이션(의사 소통)할 수 있도록 한다. 예를 들어, 다수의 플레이어는 동일한 비디오 게임을 플레이하는 동안 음성 채팅을 사용하여 커뮤니케이션할 수 있다. 애플리케이션의 텍스트/음성 채팅 기능은 의사 소통, 협력 및 동지애를 촉진하기 위한 것이지만 텍스트/음성 채팅을 통해 사용자는 서로에게 무례하거나, 비하하거나, 욕설을 할 수도 있다는 단점이 있다. 예를 들어, 비디오 게임에서 잘 알려진 문제는 텍스트 또는 음성 채팅 채널을 사용하여 다른 플레이어를 적대시하는 유해한 플레이어의 존재이다. 결과적으로, 많은 애플리케이션이 텍스트 또는 음성 채팅을 구현하지 않으며 음성 채팅이 제공될 때 많은 사용자는 그것을 비활성화한다. 텍스트 또는 음성 채팅이 구현된 경우, 애플리케이션 제공자는 사용자가 다른 사용자를 차단하거나 음소거할 수 있을 뿐만 아니라 통신 채널 남용에 대해 다른 사용자를 신고할 수 있는 조정 도구(moderation tools)를 제공해야 한다. 통신 시스템은 또한 예를 들어 플레이어의 어휘 또는 플레이어 목소리 톤이 플레이어의 캐릭터와 일치하지 않는 경우 게임의 몰입형 경험을 방해할 수 있다. 텍스트/음성 채팅은 또한 동일한 언어를 사용하는 플레이어 간의 커뮤니케이션으로 제한된다. Text or voice chat allows users of an application (eg, a video game) to communicate (communicate) simultaneously using the application. For example, multiple players may communicate using voice chat while playing the same video game. The application's text/voice chat feature is intended to promote communication, cooperation, and camaraderie, but the downside is that text/voice chat allows users to be rude, demeaning, or swearing at each other. For example, a well-known problem in video games is the presence of toxic players using text or voice chat channels to antagonize other players. As a result, many applications do not implement text or voice chat and many users disable it when voice chat is offered. If text or voice chat is implemented, application providers should provide moderation tools that allow users to block or mute other users as well as report other users for abuse of the communication channel. The communication system may also interfere with the immersive experience of the game, for example if the player's vocabulary or the tone of the player's voice does not match the player's character. Text/voice chat is also limited to communication between players who speak the same language.
일부 유형의 댓글(comments)을 다른 플레이어가 듣기(또는 읽기) 전에 제거하기 위해 때때로 필터가 "채팅" 통신 시스템에 적용된다. 예를 들어, 사용자가 생성한 텍스트 스트림은 모니터링되어 모독적이거나 모욕적인 댓글이 검출된 다음 다른 사용자에게 텍스트 스트림을 제공하기 전에 필터링될 수 있다. 이 접근 방식은 일반적으로 텍스트 채팅 모니터링으로 제한되며 대부분의 자동 음성 인식 모델은 효과적인 필터링을 지원하기에 충분히 빠르고 추운히 높은 품질로 음성을 텍스트로 변환할 수 없기 때문에 음성 채팅 시스템에는 쉽게 구현될 수 없다. 게다가, 악성(toxicity) 필터링 기술은 일부 악성 댓글이 필터를 통과하여 다른 사용자에게 도달할 수 있는 허위 부정(false negatives)을 생성한다. 인기 있는 온라인 멀티플레이어 비디오 게임과 같은 인기 있는 애플리케이션의 텍스트 또는 음성 채팅 시스템을 통해 전달되는 악성 댓글의 총량은 악성 필터의 허위 부정으로 인해 비디오 게임의 거의 모든 플레이어가 결국 악성 언어에 노출될 정도로 높다. 이것은 가족 중심의 게임 개발자에게 허용되지 않으며 텍스트 또는 음성 채팅의 구현을 방해한다. 필터링은 댓글의 특성을 변경하지 않고 댓글을 제거하는데 중점을 두기 때문에 게임의 몰입형 경험을 개선하는 데에도 대체로 비효율적이다.Filters are sometimes applied to the "chat" communication system to remove some types of comments before other players can hear (or read) them. For example, a user-generated text stream can be monitored to detect profane or offensive comments and then filtered before presenting the text stream to other users. This approach is generally limited to text chat monitoring and cannot be easily implemented in voice chat systems because most automatic speech recognition models cannot convert speech to text fast enough and with sufficiently high quality to support effective filtering. Furthermore, toxicity filtering technology creates false negatives that allow some malicious comments to pass through the filter and reach other users. The total amount of malicious comments delivered through text or voice chat systems in popular applications such as popular online multiplayer video games is high enough that almost all players in video games end up exposed to malicious language due to false negatives from malicious filters. This is unacceptable for family-oriented game developers and hinders the implementation of text or voice chat. Filtering is also largely ineffective in improving the immersive experience of a game, as it focuses on removing comments without altering their nature.
제안된 솔루션은 특히 적어도 하나의 프로세서에 의해, 애플리케이션의 제1 사용자로부터의 발언 표현과 표준(정규) 발언 세트의 표준 발언에 대한 시맨틱(의미론적) 빅에 기초하여 표준 발언 세트로부터 표준 발언을 선택하는 단계와; 그리고 애플리케이션의 제1 사용자의 발언을 제시하는 대신에 선택된 표준 발언을 애플리케이션의 제2 사용자에게 제시하는 단계를 포함하는 컴퓨터 구현 방법에 관한 것이다.The proposed solution specifically selects, by at least one processor, a standard utterance from a standard utterance set based on a utterance representation from a first user of the application and a semantic (semantic) big for the standard utterance of the standard (canonical) utterance set. step of doing; and presenting the selected standard utterance to a second user of the application instead of presenting the utterance of the first user of the application.
일반적으로, 발언은 애플리케이션의 제1 사용자로부터의 텍스트 문자열 및/또는 음성 발언을 포함할 수 있다. 음성 발언의 경우 이 방법은 추가로 적어도 하나의 프로세서에 의해 음성-텍스트 변환 애플리케이션을 사용하여, 음성 발언을 표준 발언 세트의 표준 발언과 비교될 제1 사용자로부터의 발언의 텍스트 표현으로 변환하는 단계를 추가적으로 포함할 수 있다.Generally, the utterances may include text strings and/or spoken utterances from the first user of the application. For spoken utterances, the method further includes converting, by the at least one processor, using a speech-to-text application, the spoken utterance into a textual representation of the utterance from the first user to be compared with standard utterances of the set of standard utterances. may additionally be included.
예시적인 실시예에서, 표준 발언 세트로부터 표준 발언을 선택하는 단계는 자연어 처리(NLP)에 기초한다. 이것은 표준 발언 세트로부터 표준 발언을 선택하는 단계가 (a) 발언에 기초하여 표준 발언 세트로부터 표준 발언의 시맨틱 검색을 사용하거나 (b) 표준 발언과 제1 사용자로부터 수신된 발언의 시맨틱 유사성을 사용하여 표준 발언 세트로부터 표준 발언을 선택하는 단계를 포함함을 의미할 수 있다.In an exemplary embodiment, selecting a standard utterance from a set of standard utterances is based on natural language processing (NLP). This means that the step of selecting a standard utterance from a set of standard utterances can be accomplished by (a) using a semantic search of standard utterances from the set of standard utterances based on the utterances, or (b) using semantic similarity between the standard utterances and the utterances received from the first user. It may mean including selecting a standard utterance from a set of standard utterances.
예시적인 실시예에서, 표준 발언 세트로부터 표준 발언을 선택하는 단계는 표준 발언 세트와 관련된 메타데이터에 기초하여 표준 발언을 선택하는 단계를 포함한다. 메타데이터는 예를 들어 표준 발언 세트의 서브세트를 나타낼 수 있다. 메타데이터는 예를 들어 상이한 캐릭터에 의해 만들어진 표준 발언과 상이한 음성 특성 또는 발음을 연관시키는데 사용될 수 있다. 따라서 표준 발언 세트로부터 표준 발언을 선택하는 단계는 메타데이터를 제1 사용자로부터 수신된 발언의 적어도 하나의 특징과 비교하고 서브세트들 중 식별된 하나로부터 표준 발언을 선택함으로써 서브세트들 중 하나를 식별하는 단계를 포함할 수 있다. 예를 들어, 발언의 특징은 비디오 게임 애플리케이션의 상태 및/또는 비디오 게임 애플리케이션에서 제1 사용자가 제어하는 캐릭터의 유형과 같이, 제1 및 제2 사용자에 의해 플레이되는 비디오 게임 애플리케이션의 적어도 하나의 비디오 게임 애플리케이션 파라미터에 관련될 수 있다.In an illustrative embodiment, selecting a standard utterance from the set of standard utterances includes selecting the standard utterance based on metadata associated with the set of standard utterances. Metadata may represent, for example, a subset of a set of standard utterances. Metadata can be used, for example, to associate different voice characteristics or pronunciations with standard utterances made by different characters. Selecting a standard utterance from the set of standard utterances thus identifies one of the subsets by comparing metadata to at least one characteristic of a utterance received from the first user and selecting a standard utterance from the identified one of the subsets. steps may be included. For example, the characteristics of the utterance may include at least one video of the video game application being played by the first and second users, such as the state of the video game application and/or the type of character the first user controls in the video game application. It may relate to game application parameters.
예시적인 실시예에서, 방법은 세트 내의 표준 발언을 나타내는 벡터를 포함하는 열을 갖는 행렬로서 표준 발언 세트를 임베딩하는 단계를 더 포함할 수 있다. 일반적으로, 사전 결정된 차원 수를 갖는 공간에서 발언을 벡터로 표현하는 것은 본 명세서에서 발언을 "임베딩(embedding)"하는 것으로 지칭한다. 표준 발언 세트를 나타내는 행렬의 사용은 표준 발언에 대한 시맨틱 유사성 스코어를 생성함으로써 표준 발언 세트로부터 표준 발언을 선택하는 것을 허용할 수 있다. 그런 다음, 표준 발언 세트로부터 표준 발언을 선택하는 단계는 사전 결정된 최소 임계값 이상의 시맨틱 유사성 스코어와 관련된 표준 발언을 선택하는 단계를 또한 포함할 수 있다. 일 실시예에서, 시맨틱 유사성 스코어 중 어느 것도 사전 결정된 최소 임계값 이상이 아니라는 것에 응답하여 디폴트 발언이 선택될 수 있다.In an exemplary embodiment, the method may further include embedding the set of standard utterances as a matrix having columns including vectors representing standard utterances in the set. In general, representing an utterance as a vector in a space having a predetermined number of dimensions is referred to herein as "embedding" the utterance. The use of a matrix representing a set of standard utterances may allow selecting standard utterances from a set of standard utterances by generating a semantic similarity score for the standard utterances. Then, selecting standard utterances from the set of standard utterances may also include selecting standard utterances associated with a semantic similarity score above a predetermined minimum threshold. In one embodiment, a default utterance may be selected in response to none of the semantic similarity scores being above a predetermined minimum threshold.
표준 발언 세트로부터 선택된 표준 발언으로 사용자 발언을 대체하기 위해, 일부 실시예는 세트 내의 표준 발언을 나타내는 벡터를 포함하는 열을 갖는 행렬로서 표준 발언 세트를 임베딩한다. 다시 말해, 표준 발언 세트는 그 세트의 각 표준 발언을 숫자 엘리먼트만 포함하는 벡터로 변환한 행렬 포멧으로 저장될 수 있다. 예를 들어, 사용자 발언의 벡터 표현은 1, m-행렬과 같은 1차원 행렬로서 임베딩될 수 있으므로 Uu = a1, a2, a3, … m 과 같은 벡터로서 포함될 수 있다. 이러한 임베딩된 사용자 발언의 숫자 엘리먼트는 저장된 표준 발언과의 비교에 사용되며 따라서 유사성 평가에 사용될 수 있다.To replace user utterances with standard utterances selected from the set of standard utterances, some embodiments embed the set of standard utterances as a matrix with columns containing vectors representing standard utterances in the set. In other words, a set of standard utterances can be stored in a matrix format in which each standard utterance in the set is converted into a vector containing only numeric elements. For example, a vector representation of a user's speech can be embedded as a one-dimensional matrix such as a 1, m-matrix, so Uu = a1, a2, a3, ... It can be included as a vector like m. The numeric elements of these embedded user utterances are used for comparison with stored standard utterances and thus can be used for similarity evaluation.
예시적인 실시예에서, 표준 발언 세트를 나타내는 임베딩된 행렬은 m행과 n열을 갖는 m, n 행렬로 나타낼 수 있다. 따라서, 표준 발언에 대한 예시적인 임베딩된 행렬(Me)은 다음과 같이 주어질 수 있다.In an exemplary embodiment, an embedded matrix representing a set of standard utterances may be represented as an m, n matrix having m rows and n columns. Thus, an exemplary embedded matrix Me for a standard utterance can be given as
비교 및 이에 따른 유사성 평가를 위해, (Uu와 같은) 임베딩된 사용자 발언과 (Me와 같은) 임베딩된 행렬의 숫자 값을 수학적으로 결합함으로써 표준 발언에 대한 시맨틱 유사성 스코어가 생성될 수 있다. 벡터 및 행렬 표현의 숫자 엘리먼트를 사용하면 복잡하지 않은 계산에 기초하여 적당한 계산 부하로 빠른 비교가 가능하다.For comparison and thus similarity evaluation, a semantic similarity score for a standard utterance may be generated by mathematically combining the embedded user utterances (such as Uu) and the numeric values of the embedded matrix (such as Me). The use of numeric elements in vector and matrix representations allows fast comparisons with moderate computational load based on uncomplicated calculations.
예를 들어, 표준 발언에 대한 시맨틱 유사성 스코어는 사용자로부터 수신된 발언을 나타내는 벡터의 엘리먼트와 임베딩된 행렬의 각 열의 엘리먼트를 (요소별로) 곱함으로써(여기서 각 열은 표준 발언들 중 하나를 나타내는 벡터의 엘리먼트를 포함함) 생성될 수 있다. 이에 의해, 임베딩된 표준 발언과 임베딩된 사용자 발언의 비교를 위해 유사성 벡터가 계산될 수 있다. 예를 들어, 위의 임베딩된 벡터(Uu)와 임베딩된 행렬(Me)의 처음 두 열에 대한 유사성 벡터는 다음과 같이 계산될 수 있다.For example, the semantic similarity score for a canonical utterance is obtained by multiplying (element-by-element) an element of a vector representing a utterance received from a user with an element in each column of an embedded matrix, where each column is a vector representing one of the canonical utterances. (including elements of) can be created. Thereby, a similarity vector may be calculated for comparison between the embedded standard utterance and the embedded user utterance. For example, the similarity vectors for the first two columns of the above embedded vector Uu and the embedded matrix Me can be calculated as follows.
S1 = (a1b11, a2b21, a3b31,...,ambm1)S 1 = (a1b11, a2b21, a3b31,...,ambm1)
S2 = (a1b21, a2b22, a3b32,...,ambm2)S 2 = (a1b21, a2b22, a3b32,...,ambm2)
그런 다음 이러한 유사성 벡터는 표준 발언에 대한 시맨틱 유사성 스코어를 생성하는데 사용될 수 있다. 일 예에서, 세트 내의 표준 발언들에 대한 시맨틱 유사성 스코어는 유사성 벡터(S1 및 S2)와 같은 유사성 벡터의 크기와 동일하다. 그런 다음 최소 임계값 이상의 시맨틱 유사성 스코어를 갖는 표준 발언들 중 하나 이상이 사용자 발언을 대체할 후보로서 선택될 수 있다. 예를 들어, 가장 높은 시맨틱 유사성 스코어와 관련된 표준 발언이 분석된 사용자 발언을 대체하도록 선택될 수 있다. 일 실시예에서, 표준 발언에 대한 시맨틱 유사성 스코어 중 어느 것도 최소 임계값 이상이 아닌 경우, 디폴트 발언이 발언을 대체하도록 선택될 수 있다. 일부 실시예에서는, 임베딩된 표준 발언 및 사용자 발언에 기초하여 시맨틱 유사성 스코어를 결정하거나 시맨틱 매칭을 수행하기 위한 다른 기술이 사용된다.These similarity vectors can then be used to generate semantic similarity scores for canonical utterances. In one example, the semantic similarity score for the canonical utterances in the set is equal to the magnitude of the similarity vector, such as similarity vectors S 1 and S 2 . Then, one or more of the standard utterances with a semantic similarity score above a minimum threshold may be selected as a candidate to replace the user utterance. For example, the standard utterance associated with the highest semantic similarity score may be selected to replace the analyzed user utterance. In one embodiment, a default utterance may be selected to replace the utterance if none of the semantic similarity scores for the standard utterance are above a minimum threshold. In some embodiments, other techniques are used to determine a semantic similarity score or perform semantic matching based on embedded standard utterances and user utterances.
제안된 솔루션은 또한 실행 가능한 명령 세트를 구현하는 비-일시적 컴퓨터 판독 가능 매체에 관한 것이며, 실행 가능한 명령 세트는 제안된 방법의 실시예를 수행하기 위해 적어도 하나의 프로세서를 조작한다.The proposed solution also relates to a non-transitory computer readable medium embodying a set of executable instructions, the set of executable instructions operating at least one processor to perform embodiments of the proposed method.
제안된 솔루션은 또한 표준 발언 세트를 저장하도록 구성된 메모리와, 그리고 애플리케이션의 제1 사용자로부터의 발언과 표준 발언 세트의 표준 발언의 시맨틱 비교에 기초하여 표준 발언 세트로부터 표준 발언을 선택하고, 제1 사용자의 발언을 제공하는 대신 선택된 표준 발언을 애플리케이션의 제2 사용자에게 제시하도록 구성된 적어도 하나의 프로세서를 포함하는 시스템에 관한 것이다. 제안된 시스템의 실시예는 제안된 방법의 실시예를 수행하도록 구성될 수도 있다.The proposed solution also includes a memory configured to store a set of standard utterances, and a standard utterance selected from the set of standard utterances based on a semantic comparison of standard utterances in the set of standard utterances with utterances from a first user of the application; A system comprising at least one processor configured to present selected standard utterances to a second user of an application instead of providing utterances of the utterance. Embodiments of the proposed system may be configured to perform embodiments of the proposed method.
본 발명은 텍스트 또는 음성 채팅의 댓글을 표준 용어 및 경우에 따라 캐릭터-특정(specific) 어휘 또는 음성 특징으로 번역하여 악성을 제거하고 비디오 게임에 대한 몰입감을 향상시키는 기술에 관한 것이다. 일부 실시예에서, 사용자로부터의 발언(텍스트 또는 음성)은 예를 들어, 자연어 처리(NLP) 기계 학습(ML) 모델에 의해 수행된 시맨틱(의미론적) 검색 또는 시맨틱 유사성을 사용하여 표준 발언 세트로부터 선택된 표준 발언으로 변환/재생된다. 표준 발언은 다른 사용자에게 제공되는 텍스트 또는 채팅 스트림의 사용자 발언을 대체하므로 사용자 간의 통신에 악성 언어가 없도록 한다. 일부 경우에는 캐릭터에 의한 커뮤니케이션(의사 소통이)이 캐릭터의 본성 또는 성격과 일치하는지 확인하기 위해 캐릭터-특정 표준 발언도 사용된다. 음성 채팅이 사용중인 경우, 사용자 발언은 마이크로폰에 의해 캡처되고 대기 시간이 짧은 음성 인식 알고리즘은 사용자 발언을 오디오에서 NLP ML 모델에 제공되는 텍스트로 변환한다. 표준 발언 세트가 생성되고 심사되어 표준 발언에 욕설이나 비방 언어와 같은 악성(유해한) 단어나 문구가 포함되지 않았는지 검증(확인)한다. 메타데이터는 다양한 유형의 문자에 사용할 수 있는 표준 발언의 서브세트와 같은 서브세트를 나타내기 위해 표준 발언과 연관될 수 있다. 메타데이터는 또한 다양한 음성 특징이나 발음을 다양한 캐릭터가 만든 표준 발언과 연관시키는데 사용될 수 있다. 일부 실시예에서, 표준 발언 세트는 다른 언어를 말하는 사용자 간의 커뮤니케이션을 용이하게 하기 위해 하나 이상의 다른 언어로의 표준 발언의 번역과 관련된다.The present invention relates to a technique for removing malicious comments and improving immersion in a video game by translating comments in a text or voice chat into standard terms and, in some cases, character-specific vocabulary or voice characteristics. In some embodiments, a utterance (text or voice) from a user is extracted from a set of standard utterances using, for example, semantic (semantic) search or semantic similarity performed by a natural language processing (NLP) machine learning (ML) model. It is converted/played back to the selected standard utterance. Standard utterances replace user utterances in text or chat streams presented to other users, ensuring communication between users is free of malicious language. In some cases, character-specific standard utterances are also used to ensure that communication by a character is consistent with the character's nature or personality. When voice chat is in use, user utterances are captured by microphones and low-latency speech recognition algorithms convert user utterances from audio to text that is fed to the NLP ML model. A set of standard utterances is created and vetted to verify (verify) that the standard utterances do not contain malicious (harmful) words or phrases such as profanity or slurs. Metadata may be associated with canonical utterances to indicate subsets, such as subsets of canonical utterances available for various types of characters. Metadata can also be used to associate various voice characteristics or pronunciations with standard utterances made by various characters. In some embodiments, a set of standard utterances involves translation of standard utterances into one or more other languages to facilitate communication between users speaking different languages.
NLP ML 모델은 표준 발언(또는 메타데이터로 표시된 그의 서브세트)에 대한 사용자 발언의 시맨틱 유사성을 나타내는 스코어를 생성한다. 위에서 설명한 바와 같이, 일부 실시예에서, 표준 발언은 사전 결정된 차원 수를 갖는 공간에서 벡터로 표현되며, 이는 본 명세서에서 표준 발언을 "임베딩"하는 것으로 지칭된다. 일부 실시예에서, 표준 발언 세트를 임베딩하는 것은 세트 내의 각 표준 발언의 벡터 표현을 포함하는 행렬을 생성한다. 임베딩 행렬은 NLP ML 모델에 의한 나중 사용을 위해 저장된다. 사용자 발언은 임베딩되어 사용자 발언의 벡터 표현을 생성한다. 그런 다음 NLP ML 모델은 표준 발언을 나타내는 벡터를 포함하는 임베딩 행렬의 대응하는 열과 사용자 발언을 나타내는 벡터를 곱함으로써 각각의 표준 발언에 대한 시맨틱 유사성 스코어를 생성한다. 스코어는 텍스트 또는 채팅 스트림에서 사용자 발언을 대체하는 표준 발언을 선택하는데 사용된다. 일부 실시예에서, 임계값 이상의 스코어를 갖는 표준 발언의 서브세트가 사용자에게 제공되고 사용자는 사용자 발언을 가장 정확하게 나타내는 서브세트 중 하나를 선택한다. 어떤 스코어도 사용자 발언과 충분히 유사한 표준 발언을 나타내는 최소 임계값 이상이 아닌 경우, 디폴트 발언이 사용자 발언을 대체한다.NLP ML models produce scores representing the semantic similarity of user utterances to standard utterances (or a subset thereof indicated by metadata). As described above, in some embodiments, standard utterances are represented by vectors in a space having a predetermined number of dimensions, which are referred to herein as “embedding” standard utterances. In some embodiments, embedding a set of standard utterances creates a matrix containing a vector representation of each standard utterance in the set. The embedding matrix is stored for later use by the NLP ML model. The user utterance is embedded to create a vector representation of the user utterance. The NLP ML model then generates a semantic similarity score for each canonical utterance by multiplying the vector representing the user's utterance with the corresponding column of the embedding matrix containing the vector representing the canonical utterance. Scores are used to select standard utterances to replace user utterances in text or chat streams. In some embodiments, subsets of standard utterances with scores above a threshold are presented to the user and the user selects one of the subsets that most accurately represents the user's utterance. If no score is above the minimum threshold representing a standard utterance that is sufficiently similar to the user's utterance, the default utterance replaces the user's utterance.
본 개시는 첨부된 도면을 참조함으로써 당업자에게 더 잘 이해될 수 있고, 그의 수많은 특징 및 이점이 명백해진다. 다른 도면에서 동일한 참조 기호를 사용하면 유사하거나 동일한 항목을 나타낸다.
도 1은 일부 실시예에 따라 플레이어 간의 커뮤니케이션을 위한 표준 어휘를 구현하는 비디오 게임 처리 시스템의 블록도이다.
도 2는 일부 실시예에 따라 플레이어들 간의 커뮤니케이션을 위한 표준 어휘를 구현하는 클라우드 기반 시스템의 블록도이다.
도 3은 일부 실시예에 따라 네트워크로 연결된 사용자 간의 커뮤니케이션을 위한 표준 어휘를 구현하는 네트워크 처리 시스템의 블록도이다.
도 4는 일부 실시예에 따라 음성-텍스트 변환을 사용하여 음성 채팅에서 표준 발언을 생성하는 네트워크 처리 시스템의 블록도이다.
도 5는 일부 실시예에 따른 표준 발언 세트를 포함하는 블록도이다.
도 6은 일부 실시예에 따라 텍스트 또는 음성 채팅 동안 사용자들로부터 수신된 발언을 표준 발언으로 대체하는 방법의 흐름도이다.BRIEF DESCRIPTION OF THE DRAWINGS The present disclosure may be better understood and its numerous features and advantages made apparent to those skilled in the art by referring to the accompanying drawings. Use of the same reference symbols in different drawings indicates similar or identical items.
1 is a block diagram of a video game processing system that implements a standard vocabulary for communication between players, in accordance with some embodiments.
2 is a block diagram of a cloud-based system implementing a standard vocabulary for communication between players, in accordance with some embodiments.
3 is a block diagram of a network processing system implementing a standard vocabulary for communication between networked users, in accordance with some embodiments.
4 is a block diagram of a network processing system for generating standard utterances in a voice chat using speech-to-text, in accordance with some embodiments.
5 is a block diagram including a set of standard utterances in accordance with some embodiments.
6 is a flow diagram of a method for substituting standard utterances for utterances received from users during text or voice chat, in accordance with some embodiments.
도 1은 일부 실시예에 따라 플레이어 간의 커뮤니케이션(의사 소통)을 위한 표준 어휘를 구현하는 비디오 게임 처리 시스템(100)의 블록도이다. 처리 시스템(100)은 동적 랜덤 액세스 메모리(DRAM)와 같은 비-일시적 컴퓨터 판독 가능 매체를 사용하여 구현되는 시스템 메모리(105) 또는 다른 저장 엘리먼트를 포함하거나 그에 액세스할 수 있다. 그러나, 메모리(105)의 일부 실시예는 정적 RAM(SRAM), 비휘발성 RAM 등을 포함하는 다른 유형의 메모리를 사용하여 구현된다. 처리(프로세싱) 시스템(100)은 또한 메모리(105)와 같은 처리 시스템(100)에 구현된 엔티티들 간의 통신을 지원하기 위한 버스(110)를 포함한다. 처리 시스템(100)의 일부 실시예는 명확성을 위해 도 1에 도시되지 않은 다른 버스, 브리지, 스위치, 라우터 등을 포함한다.1 is a block diagram of a video
처리 시스템(100)은 중앙 처리 장치(CPU)(115)를 포함한다. CPU(115)의 일부 실시예는 명령을 동시에 또는 병렬로 실행하는 다중 처리 엘리먼트(명확성을 위해 도 1에 도시되지 않음)를 포함한다. 처리 엘리먼트는 프로세서 코어, 컴퓨팅 유닛 또는 다른 용어를 사용하여 지칭된다. CPU(115)는 버스(110)에 연결되고 CPU(115)는 버스(110)를 통해 메모리(105)와 통신한다. CPU(115)는 메모리(105)에 저장된 프로그램 코드(120)와 같은 명령(어)를 실행하고, CPU(115)는 실행된 명령의 결과와 같은 정보를 메모리(105)에 저장한다. CPU(115)는 또한 드로우 콜(draw call)을 발행함으로써 그래픽 처리를 개시할 수 있다.The
입력/출력(I/O) 엔진(125)은 스크린(135) 상에 이미지 또는 비디오를 제시하는 디스플레이(130)와 관련된 입력 또는 출력 동작을 처리한다. 예시된 실시예에서, I/O 엔진(125)은 사용자가 게임 컨트롤러(140) 상의 하나 이상의 버튼을 누르거나 다른 방식으로)예를 들어, 예를 들어 가속도계에 의해 감지된 모션을 사용하여) 게임 컨트롤러(140)와 상호 작용하는 것에 응답하여 제어 신호를 I/O 엔진(125)에 제공하는 게임 컨트롤러(140)에 연결된다. I/O 엔진(125)은 또한 신호를 게임 컨트롤러(140)에 제공하여 게임 컨트롤러(140)에서 진동, 조명 등과 같은 응답을 트리거한다. I/O 엔진(125)은 또한 플레이어의 음성을 I/O 엔진(125)으로 전달되는 신호로 변환하고 I/O 엔진(125)으로부터 수신된 오디오 신호를 헤드셋(143)을 착용한 플레이어에게 전달되는 사운드(다른 플레이어의 음성 등)로 변환하는 마이크로폰을 포함하는 헤드셋(143)에 연결된다. 예시된 실시예에서, I/O 엔진(125)은 CD(Compact Disk), DVD(Digital Video Disc) 등과 같은 비-일시적 컴퓨터 판독 가능 매체를 사용하여 구현되는 외부 저장 엘리먼트(145)에 저장된 정보를 판독한다. I/O 엔진(125)은 또한 CPU(115)에 의한 처리 결과와 같은 정보를 외부 저장 엘리먼트(145)에 기록한다. I/O 엔진(125)의 일부 실시예는 키보드, 마우스, 프린터, 외부 디스크 등과 같은 처리 시스템(100)의 다른 엘리먼트에 결합된다. I/O 엔진(125)은 버스(110)에 결합되므로 I/O 엔진(125)은 메모리(105), CPU(115) 또는 버스(110)에 연결된 다른 엔티티와 통신한다.Input/output (I/O)
처리 시스템(100)은 예를 들어 스크린(135)을 구성하는 픽셀을 제어함으로써 디스플레이(130)의 스크린(135)에 프리젠테이션하기 위한 이미지를 렌더링하는 그래픽 처리 장치(GPU)(150)를 포함한다. 예를 들어, GPU(150)는 렌더링된 객체들을 나타내는 이미지를 디스플레이하기 위해 픽셀 값을 사용하는 디스플레이(130)에 제공되는 픽셀 값을 생성하기 위해 객체들을 렌더링한다. GPU(150)는 명령을 동시에 또는 병렬로 실행하는 컴퓨팅 유닛의 어레이(155)와 같은 하나 이상의 처리 엘리먼트를 포함한다. GPU(150)의 일부 실시예는 범용 컴퓨팅에 사용된다. 예시된 실시예에서, GPU(150)는 버스(110)를 통해 메모리(105)(및 버스(110)에 연결된 다른 엔티티들)와 통신한다. 그러나, GPU(150)의 일부 실시예는 직접 연결을 통해 또는 다른 버스, 브리지, 스위치, 라우터 등을 통해 메모리(105)와 통신한다. GPU(150)는 메모리(105)에 저장된 명령을 실행하고, GPU(150)는 실행된 명령의 결과와 같은 정보를 메모리(105)에 저장한다. 예를 들어, 메모리(105)는 GPU(150)에 의해 실행될 프로그램 코드(160)를 나타내는 명령을 저장한다.
예시된 실시예에서, CPU(115) 및 GPU(150)는 대응하는 프로그램 코드(120, 160)를 실행하여 비디오 게임 애플리케이션을 구현한다. 예를 들어, 게임 컨트롤러(140) 또는 헤드셋(143)을 통해 수신된 사용자 입력은 비디오 게임 애플리케이션의 상태를 수정하기 위해 CPU(115)에 의해 처리된다. CPU(115)는 디스플레이(130)의 스크린(135)에 디스플레이하기 위해 비디오 게임 애플리케이션의 상태를 나타내는 이미지를 렌더링하도록 GPU(150)에 지시하기 위해 드로우 콜(draw calls)을 전송한다. 본 명세서에서 논의된 바와 같이, GPU(150)는 또한 물리 엔진 또는 기계 학습 알고리즘을 실행하는 것과 같이 비디오 게임과 관련된 범용 컴퓨팅을 수행할 수 있다. CPU(115) 및 GPU(150)는 디스플레이(130)를 통해 (텍스트 형태로) 또는 헤드셋(143)을 통해 (오디오로서) 플레이어에게 제시되는 텍스트 또는 음성 채팅과 같은 (잠재적으로 다른 컴퓨팅 시스템을 사용하는) 다른 플레이어와의 통신도 지원한다.In the illustrated embodiment,
메모리(105)는 플레이어에 의해 생성된 텍스트 또는 음성 채팅 통신을 대체하는데 사용되는 표준 발언(canonical utterances)(165) 세트를 나타내는 정보를 저장한다. 텍스트 또는 음성 채팅 통신은 본 명세서에서 플레이어의 "발언"으로 지칭된다. 표준 발언 세트(165)에는 표준 발언이 "가족 친화적"이고 게임 또는 기타 애플리케이션의 맥락에서 표준 발언을 읽거나 듣는 실질적으로 모든 사람들에게 불쾌하지 않을 것으로 예상되도록 심사된 표준 발언이 포함된다. 표준 발언 세트(165)는 한 번만 심사되면 게임이나 애플리케이션에서 지원하는 텍스트 또는 음성 스트림에서 플레이어의 발언을 대체하는데 무한정 사용될 수 있는 임의의 수의 표준 발언을 포함할 수 있다. 일부 실시예에서, 표준 발언 세트(165)는 예를 들어, 비디오 게임 애플리케이션의 상태 및/또는 비디오 게임 애플리케이션에서 제1 사용자가 제어하는 캐릭터의 유형과 같은 적어도 하나의 비디오 게임 애플리케이션 파라미터에 기초하여 표준 발언의 다양한 서브세트를 정의하는 메타데이터를 포함한다. 표준 발언 세트(165)는 또한 다른 언어를 사용하는 플레이어 간의 번역을 용이하게 하기 위해 다른 언어로 된 발언을 포함할 수 있다.Memory 105 stores information representing a set of
CPU(115), GPU(150), 컴퓨팅 엘리먼트의 어레이(155) 또는 기타 프로세서 엘리먼트는 애플리케이션의 사용자(또는 게임 플레이어)로부터의 발언을 나타내는 정보를 수신한다. 발언은 헤드셋(143)의 마이크로폰(음성 채팅의 경우), 키보드(텍스트 채팅의 경우) 또는 기타 입력 디바이스를 통해 수신된다. 헤드셋(143)을 통해 수신된 음성 발언은 본 명세서에서 논의된 바와 같이, 음성-텍스트 변환 애플리케이션을 사용하여 텍스트로 변환된다. 프로세서는 제1 사용자로부터의 발언과 표준 발언 세트(165)의 시맨틱(의미론적) 비교에 기초하여 표준 발언 세트(165)로부터 표준 발언을 선택한다. 시맨틱 비교에는 시맨틱 자연어 처리 기계 학습 모델에 의해 수행될 수 있는 시맨틱 검색 및 시맨틱 유사성 동작이 포함된다. 그런 다음 선택된 표준 발언은 제1 사용자의 발언을 제시하는 대신 애플리케이션의 제2 사용자에게 제시된다. 일부 경우, 사용자의 발언은 텍스트 스트림 또는 음성 채팅에서 상기 선택된 표준 발언으로 대체된다.The
CPU(115), GPU(150), 컴퓨팅 엘리먼트의 어레이(155) 또는 이들의 조합의 일부 실시예는 시맨틱 검색 및 시맨틱 유사성과 같은 NLP 분석을 수행하는데 사용되는 프로그램 코드(170)를 실행한다. 시맨틱 NLP ML 알고리즘은 자연어 데이터의 코퍼스(corpuse, 말뭉치)를 사용하여 트레이닝된다. 미디어/제품 리뷰, 뉴스 기사, 이메일/스팸/뉴스그룹 메시지, 트윗, 대화 등과 관련된 모음을 포함하여 기계 학습 알고리즘을 트레이닝하는데 많은 텍스트 코퍼스가 사용될 수 있다. 예시된 실시예에서, NLP 분석의 결과는 메모리(105)의 일부(175)에 저장되지만, 일부 실시예에서 이 정보 또는 그의 사본은 다른 위치에 저장된다.Some embodiments of
도 2는 일부 실시예에 따라 플레이어 간의 커뮤니케이션을 위한 표준 어휘를 구현하는 클라우드 기반 시스템(200)의 블록도이다. 클라우드 기반 시스템(200)은 네트워크(210)와 상호 연결된 서버(205)를 포함한다. 도 2에는 단일 서버(205)가 도시되어 있지만, 클라우드 기반 시스템(200)의 일부 실시예는 네트워크(210)에 연결된 하나 이상의 서버를 포함한다. 예시된 실시예에서, 서버(205)는 네트워크(210)로 신호를 전송하고 네트워크(210)로부터 신호를 수신하는 트랜시버(215)를 포함한다. 트랜시버(215)는 하나 이상의 별도의 송신기 및 수신기를 사용하여 구현될 수 있다. 서버(205)는 또한 하나 이상의 프로세서(220) 및 하나 이상의 메모리(225)를 포함한다. 프로세서(220)는 메모리(225)에 저장된 프로그램 코드와 같은 명령을 실행하고, 프로세서(220)는 실행된 명령의 결과와 같은 정보를 메모리(225)에 저장한다.2 is a block diagram of a cloud-based
클라우드 기반 시스템(200)은 네트워크(210)를 통해 서버(205)에 연결된 컴퓨터, 셋탑 박스, 게임 콘솔 등과 같은 하나 이상의 처리 디바이스(230)를 포함한다. 예시된 실시예에서, 처리 디바이스(230)는 네트워크(210)로 신호를 전송하고 네트워크(210)로부터 신호를 수신하는 트랜시버(235)를 포함한다. 트랜시버(235)는 하나 이상의 별도의 송신기 및 수신기를 사용하여 구현될 수 있다. 처리 디바이스(230)는 또한 하나 이상의 프로세서(240) 및 하나 이상의 메모리(245)를 포함한다. 프로세서(240)는 메모리(245)에 저장된 프로그램 코드와 같은 명령을 실행하고, 프로세서(240)는 실행된 명령의 결과와 같은 정보를 메모리(245)에 저장한다. 트랜시버(235)는 스크린(255), 게임 컨트롤러(260), 헤드셋(265) 및 기타 텍스트 또는 음성 입력 디바이스에 이미지 또는 비디오를 디스플레이하는 디스플레이(250)에 연결된다. 따라서 클라우드 기반 시스템(200)의 일부 실시예는 클라우드 기반 게임 스트리밍 애플리케이션에 의해 사용된다.The cloud-based
프로세서(220), 프로세서(240) 또는 이들의 조합은 프로그램 코드를 실행하여 애플리케이션의 사용자 또는 게임 플레이어로부터 수신된 발언을 표준 발언 세트로부터의 하나 이상의 표준 발언으로 교체한다. 서버(205)의 프로세서(220)와 처리 디바이스(230)의 프로세서(240) 사이의 작업 분할은 다른 실시예에서 상이하다. 예를 들어, 헤드셋(265)을 통해 수신된 발언을 나타내는 신호는 트랜시버(215, 235)를 통해 서버(205)로 전달될 수 있고, 프로세서(220)는 네트워크(210)에 연결된 헤드셋(270)을 통해 제2 사용자 또는 플레이어에게 전달되는 텍스트 또는 음성 채팅 스트림에서 상기 수신된 발언을 대체할 표준 발언을 식별할 수 있다. 다른 예로, 프로세서(240)는 헤드셋(265)을 통해 수신된 발언에 대응하는 표준 발언을 식별하고, 헤드셋(270)을 착용한 사용자/플레이어와 같은 다른 사용자 또는 플레이어에게 배포하기 위해 서버(205)에 제공되는 스트림에서 상기 수신된 발언을 표준 발언으로 대체한다.
도 3은 일부 실시예에 따라 네트워크(305)로 연결된 사용자 간의 커뮤니케이션을 위한 표준 어휘를 구현하는 네트워크 처리 시스템(300)의 블록도이다. (비디오 게임 플레이어와 같은) 애플리케이션의 사용자(310, 315)는 네트워크(305)에 연결된 대응하는 처리 시스템(320, 325)에서 실행되는 애플리케이션의 인스턴스를 사용하면서 네트워크를 통해 통신하고 있다. 처리 시스템(320, 325)은 도 1에 도시된 처리 시스템(100) 또는 도 2에 도시된 클라우드 기반 시스템(200)의 일부 실시예를 사용하여 구현된다.3 is a block diagram of a
처리 시스템(320)은 사용자(310)로부터의 발언(330)을 나타내는 정보를 포함하는 스트림을 수신한다. 일부 실시예에서, 발언(330)는 사용자(310)로부터 수신된 악성 텍스트 또는 음성 채팅 댓글(comment)이다. 발언(330)은 스트림의 발언(330)을 나타내는 정보를 표준 발언 세트로부터 선택된 표준 발언을 나타내는 정보로 대체하는 표준화기(335)에 의해 처리된다. 표준화기(335)의 일부 실시예는 표준 발언 세트를 세트 내의 표준 발언을 나타내는 벡터를 포함하는 열을 갖는 행렬로서 임베딩한다. 즉, 표준화기(335)는 세트의 각각의 표준 발언이 단지 숫자 엘리먼트를 갖는 벡터로 변환된 표준 발언 세트가 행렬 포멧으로 저장되는 메모리를 포함한다.Processing system 320 receives a stream containing information representative of
표준화기(335)는 또한 (실제) 발언(330)의 (예를 들어, 1, n 행렬의 형태로) 벡터 표현을 생성하여 세트의 표준 발언과 비교하기 위한 임베딩된(embedded) 사용자 발언을 생성한다. 예를 들어 사용자 발언의 벡터 표현은 다음과 같다.
Uu = (0.0, 0.1, 0.9,...,0.0)Uu = (0.0, 0.1, 0.9,...,0.0)
이러한 임베딩된 사용자 발언의 숫자 엘리먼트는 저장된 표준 발언과 비교하고 유사성 평가를 생성하는데 사용될 수 있다. 일부 실시예에서, 표준 발언 세트를 나타내는 임베딩된 행렬는 다음과 같이 표현된다.The numeric elements of these embedded user utterances can be compared to stored standard utterances and used to generate similarity ratings. In some embodiments, an embedded matrix representing a set of standard utterances is expressed as
비교 및 이에 따른 유사성 평가를 위해, 표준화기(335)는 임베딩된 사용자 발언(Uu와 같은) 및 임베딩된 행렬(Me)의 숫자 값을 수학적으로 결합함으로써 표준 발언에 대한 시맨틱 유사성 스코어를 생성한다. 벡터 및 행렬 표현의 숫자 엘리먼트를 사용하면 복잡하지 않은 계산을 기반으로 하여 적당한 계산 부하로 빠른 비교를 가능하게 한다. For comparison and thus similarity evaluation,
예를 들어, 표준화기(335)는 사용자(310)로부터 수신된 발언(330)를 나타내는 벡터의 엘리먼트를 행렬의 각 열의 엘리먼트와 (각 요소별로) 곱함으로써(각 열은 표준 발언 중 하나를 나타내는 벡터의 요소를 포함함) 표준 발언에 대한 시맨틱 유사성 스코어를 생성한다. 이것에 의햐, 임베딩된 표준 발언과 임베딩된 사용자 발언의 비교를 위해 유사성 벡터가 계산된다. 예를 들어, 위의 임베딩된 벡터와 임베딩된 행렬의 처음 두 열에 대한 유사성 벡터는 다음과 같다.For example,
S1 = (0.00, 0.02, 0.72,...,0.0)S 1 = (0.00, 0.02, 0.72,...,0.0)
S2 = (0.0, 0.01, 0.09,...,0.0)S 2 = (0.0, 0.01, 0.09,...,0.0)
그런 다음 이러한 유사성 벡터는 표준 발언에 대한 시맨틱 유사성 스코어를 생성하는데 사용될 수 있다. 일 예에서, 세트 내의 표준 발언에 대한 시맨틱 유사성 스코어는 유사성 벡터(S1) 및 S2)와 같은 유사성 벡터의 크기와 동일하다.These similarity vectors can then be used to generate semantic similarity scores for canonical utterances. In one example, the semantic similarity score for the canonical utterances in the set is equal to the magnitude of similarity vectors, such as similarity vectors S 1 and S 2 .
시맨틱 유사성 스코어가 최소 임계값 이상인 표준 발언 중 하나 이상이 발언(330)를 대체할 후보로 선택된다. 예를 들어, 가장 높은 시맨틱 유사성 스코어와 관련된 표준 발언이 발언(330)을 대체하기 위해 선택될 수 있다. 표준 발언에 대한 시맨틱 유사성 스코어 중 어느 것도 최소 임계값보다 높지 않은 경우, 발언(330)를 대체하기 위해 디폴트 발언이 선택된다. 본 명세서에 개시된 벡터 및 행렬 표현에 대해 수행되는 연산이 도시된 실시예에서 시맨틱 유사성 스코어를 생성하는데 사용되지만, 다른 실시예는 다른 유사성 척도를 사용하여 사용자 발언을 표준 발언과 비교하고 사용자 발언을 나타내기 위해 표준 발언을 선택한다.One or more of the standard utterances having a semantic similarity score equal to or greater than a minimum threshold are selected as candidates to replace
표준 발언(340)는 사용자(315)에게 제시되는 스트림에서 발언(330)를 대체하도록 선택된다. 일부 실시예에서, 스코어는 표준 발언(340)의 의미가 그들의 원래 의도와 매칭(일치)하는지 확인하기 위해 시스템이 원래 플레이어에게 프롬프트해야 하는지 여부를 결정하는데 사용된다. 플레이어는 또한 가능한 옵션 목록에서 표준 발언(340)를 선택하도록 프롬프트될 수 있다. 예를 들어, 플레이어가 "어깨 너머에 나쁜 사람이 있어(Bad guy over your shoulder)"라고 말하면 표준화기(335)는 유사성 스코어와 함께 다음 일치 항목을 찾을 수 있다.
옵션 1: "당신 뒤에 적이 있어!" 스코어 = 0.7Option 1: "There's an enemy behind you!" score = 0.7
옵션 2: "조심해! 저기에 적이 있어!" 스코어 = 0.6Option 2: "Watch out! There's an enemy over there!" score = 0.6
옵션 3: "당신 뒤에 친절한 사람이 있어!" 스코어 = 0.1Option 3: "There's a kind person behind you!" score = 0.1
플레이어에게는 사전 결정된 임계값보다 높은 두 개의 스코어가 제시되고(이 예에서 임계값이 0.5이고 플레이어에게 옵션 1과 옵션 2가 제시됨) 어느 것이 올바른지 선택하도록 프롬프트된다. 만약 스코어가 충분히 높으면, 시스템은 추가 플레이어 입력 없이 표준 발언(340)를 전송한다. 스코어는 확률을 나타내기 위해 선택적으로 정규화될 수 있다.The player is presented with two scores above a predetermined threshold (in this example the threshold is 0.5 and the player is presented with option 1 and option 2) and is prompted to select which one is correct. If the score is high enough, the system sends a
도 4는 일부 실시예에 따라 음성-텍스트 변환을 사용하여 음성 채팅에서 표준 발언을 생성하는 네트워크 처리 시스템(400)의 블록도이다. 처리 시스템(400)은 도 1에 도시된 처리 시스템(100) 또는 도 2에 도시된 클라우드 기반 시스템(200)의 일부 실시예를 사용하여 구현된다. 예시된 실시예에서, 사용자(405)는 하나 이상의 다른 사용자와 플레이하는 게임과 같은 다른 애플리케이션의 일부 또는 독립형 애플리케이션일 수 있는 음성 채팅 애플리케이션을 사용하고 있다. 사용자(405)는 마이크로폰(410)에 대고 말하고 발화된 단어가 발언(415)으로서 캡처된다.4 is a block diagram of a
발언(415)를 포함하여 마이크로폰(410)에 의해 캡처되는 모든 발언은 소프트웨어, 펌웨어, 하드웨어 또는 이들의 조합을 사용하여 구현되는 음성-텍스트 변환 모듈(420)에 제공된다. 음성-텍스트 변환 모듈(420)은 발언(415)의 텍스트 표현을 생성하고 그 텍스트 표현을 자연어 처리(NLP) 분석기(425)에 제공한다. 음성-텍스트 변화 모듈(420)의 일부 실시예는 로컬 음성 인식 모듈을 구현하거나 원격 전사 서비스를 이용하는데, 예를 들어, 음성-텍스트 변환 모듈(420)은 발언(415)을 나타내는 오디오 스니펫을 원격 전사 서비스로 전송하고, 원격 전사 서비스는 발언(415)의 텍스트 표현을 반환한다.All speech captured by
이전에 심사된 표준 발언 세트를 포함하는 표준 세트(430)는 NLP 분석기(425)에 액세스할 수 있다. NLP 분석기(425)는 발언(415)의 텍스트 표현을 표준 세트(430)의 표준 발언과 비교한다. 하나 이상의 표준 발언은 발언(415)를 나타내도록 선택된다. NLP 분석기(425)의 일부 실시예는 발언(415)를 나타내기 위해 표준 발언을 선택하기 위한 ML 기술을 구현한다. 예를 들어, NLP 분석기(425)는 발언(415)의 텍스트 표현에 기초하여 표준 세트(430)로부터 표준 발언을 선택하기 위해 시맨틱 검색을 구현할 수 있다. 다른 예로, NLP 분석기(425)는 표준 발언과 발언(415)의 시맨틱 유사성에 기초하여 표준 세트(430)으로부터 표준 발언을 선택할 수 있다.The standard set 430 , which includes the previously screened standard utterance set, is accessible to the NLP analyzer 425 . NLP analyzer 425 compares the textual representation of
표준 세트(430)로부터 선택된 표준 발언(435)는 도 1에 도시된 헤드셋(143) 또는 도 2에 도시된 헤드셋(265)에 구현된 스피커와 같은 스피커(440)로 제공된다. 스피커(440)에 제공되는 신호는 스피커(440)에 의해 오디오로 변환된 텍스트를 나타내는 신호 또는 스피커(440)에 의해 생성된 오디오를 나타내는 신호를 포함한다. 일부 실시예에서, 표준 발언(435)에는 표준 발언(435)의 텍스트 또는 오디오 표현을 생성하기 위해 스피커 또는 다른 엔티티에 제공되는 식별 번호가 주어진다. 표준 발언(435)의 오디오 버전(445)은 표준 발언(435)을 나타내는 신호에 기초하여 스피커(440)에 의해 생성된다.
도 5는 일부 실시예에 따른 발언의 표준 세트(500)를 포함하는 블록도이다. 표준 세트(500)는 도 1에 도시된 표준 발언 세트(165) 및 도 2에 도시된 표준 세트(430)의 일부 실시예를 나타낸다. 표준 세트(500)는 표준 발언(501, 502, 503, 504)를 포함하며 이들은 본 명세서에서 집합적으로 "표준 발언(501-504)"으로 지칭된다. 표준 발언(501-504)에는 비디오 게임 플레이어와 같은 애플리케이션 사용자 간의 커뮤니케이션(의사 소통)을 용이하게 하는데 사용되는 저장된 단어 또는 문구를 포함한다. 표준 발언(501-504)은 의도된 청중에 대한 적합성을 결정하기 위해 심사되는데, 예를 들어 표준 발언(501-504)은 "가족 친화적"인지 확인하기 위해 심사된다. 본 명세서에서 논의되는 바와 같이, 표준 발언(501-504)은 텍스트 스트림 또는 음성 채팅 스트림에서 사용자 또는 플레이어로부터 수신된 발언을 대체한다. 일부 실시예에서, 사용자 또는 플레이어로부터 수신된 모든 발언은 대응하는 표준 발언(501-504)으로 대체되어 사용자 또는 플레이어 간의 모든 커뮤니케이션이 이전에 심사된 표준 발언(501-504) 중 하나로 표현되도록 보장한다.5 is a block diagram comprising a standard set of utterances 500 according to some embodiments. Standard set 500 represents some embodiments of standard utterance set 165 shown in FIG. 1 and standard set 430 shown in FIG. 2 . Standard set 500 includes
예시된 실시예에서, 메타데이터(511, 512, 513, 514)(집합적으로 본 명세서에서 "메타데이터(511-514)"로 지칭됨)는 표준 발언(501-504)과 관련된다. 메타데이터(511-514)는 표준 발언(501-504)의 속성, 특성 또는 서브세트을 나타낸다. 예를 들어, 메타데이터(511, 512)는 대응하는 표준 발언(501, 502)이 제1 캐릭터 유형(가령, 늙은 마법사)과 관련되어 있음을 나타낼 수 있고, 메타데이터(513, 514)는 대응하는 표준 발언(503, 504)이 제2 캐릭터 유형(예를 들어, 젊은 호빗)과 관련되어 있음을 나타낼 수 있다. 표준 발언(501-504)은 메타데이터(511-514)에 기초하여 사용자로부터 수신된 발언을 대체하도록 선택된다. 예를 들어, 표준 발언(501, 502)은 늙은 마법사로서 롤-플레이하는 플레이어들로부터 수신되는 발언을 대체하기 위해 사용되며 표준 발언(503, 504)은 젊은 호빗으로서 롤-플레이하는 플레이어들로부터 수신되는 발언을 대체하는데 사용된다. .In the illustrated embodiment, metadata 511, 512, 513, and 514 (collectively referred to herein as “metadata 511-514”) are associated with standard utterances 501-504. Metadata 511-514 represent attributes, characteristics, or subsets of canonical utterances 501-504. For example, metadata 511 and 512 may indicate that corresponding
예시된 실시예에서, 표준 세트(500)는 번역된 발언(520)으로 표현되는 원래 언어와 하나 이상의 다른 언어 사이의 발언의 번역과 관련(또는 포함)된다. 표준 발언(501-504)는 미리 번역되어 번역된 발언(520)를 포함하는 룩업 테이블을 생성한다. 따라서 사용자 발언을 대체하기 위해 선택된 표준 발언(501-504)의 번역은 사용자 또는 플레이어 발언에 대한 대체로서 표준 발언(501-504) 중 하나의 선택에 응답하여 거의 순간적으로 수행될 수 있다. 가족 친화적인 발언의 표준 세트(500)는 기계 번역 또는 인간 번역을 통해 번역된다. 번역된 발언(520)은 (다른 사용자에게 전송하기 전에 표준 발언(501-504)의 번역을 위해) 원래 사용자의 위치 또는 (수신 사용자가 수신한 후 표준 발언(501-504)의 번역을 위해) 수신자의 위치에 저장될 수 있다. 일부 실시예에서, 선택된 표준 발언(501-504)의 식별자는 수신자인 사용자에게 전송되고 수신자는 식별자를 사용하여 번역된 발언 세트(520)에서 적절한 번역을 조회한다.In the illustrated embodiment, the set of standards 500 relates to (or includes) the translation of utterances between an original language represented by translated
도 6은 일부 실시예에 따라 텍스트 또는 음성 채팅 동안 사용자로부터 수신된 발언을 표준 발언으로 대체하는 방법(600)의 흐름도이다. 방법(600)은 도 1에 도시된 처리 시스템(100), 도 2에 도시된 클라우드 기반 시스템(200), 도 3에 도시된 네트워크 처리 시스템(300) 및 도 4에 도시된 네트워크 처리 시스템(400)의 일부 실시예에서 구현된다.6 is a flow diagram of a
블록(605)에서, 처리 시스템(또는 표준화기)은 사용자 발언의 텍스트 표현을 수신한다. 일부 실시예에서, 사용자의 발언은 마이크로폰에 의해 캡처된 다음 예를 들어 도 4에 도시된 바와 같이 사용자 발언의 텍스트 표현을 생성하는 음성-텍스트 변환 모듈에 제공된다.At
블록(610)에서, 처리 시스템은 사용자 발언의 텍스트 표현에 기초하여 표준 발언들에 대한 스코어를 생성한다. 일부 실시예에서, 시맨틱 NLP ML 알고리즘은 사용자의 발언 및 하나 이상의 표준 발언의 시맨틱 유사성 또는 시맨틱 검색을 사용하여 스코어를 생성한다.At
결정 블록(615)에서, 처리 시스템은 스코어들 중 하나 이상이 사용자의 발언을 표준 발언으로 대체하기 위한 최소 임계값을 나타내는 임계값보다 높은지 여부를 결정한다. 그런 경우, 방법(600)은 블록(620)으로 흐른다. 표준 발언에 대한 스코어 중 어느 것도 최소 임계값을 초과하지 않아 사용자의 발언과 표준 세트의 표준 발언 사이의 불일치를 나타내는 경우, 방법(600)은 블록(625)으로 이어진다.At
블록(620)에서, 임계값 이상의 스코어를 갖는 표준 발언들 중 하나 이상이 사용자의 발언을 대체하기 위해 선택된다. 예를 들어, 사용자의 발언을 대체하기 위해 가장 높은 스코어를 갖는 표준 발언이 선택될 수 있다. 다른 예의 경우, 사용자가 전달하고자 하는 의미와 가장 근접하게 일치하는 표준 발언을 선택하기 위해 임계값 이상의 스코어를 갖는 다수의 표준 발언이 사용자에게 제시될 수 있다. 사용자에게 가능한 표준 발언들을 제시하면 의사소통 속도가 느려지지만, 의사소통 의미의 정확성 증가는 트레이드 오프를 가치 있게 만들 수 있다. 일부 실시예에서, 표준 발언은 그 표준 발언과 관련된 메타데이터로 표시되는 세브세트과 같은 표준 세트의 하위 세트으로부터 선택된다. 예를 들어, 임계값 이상의 스코어를 가지며 사용자가 롤-플레잉하는 캐릭터와 동일한 캐릭터 유형과 관련된(메타데이터에 의해) 표준 발언이 사용자의 발언을 대체하기 위해 선택된다. 그런 다음 방법(600)은 블록(630)으로 이어진다.At
블록(625)에서, 처리 시스템은 세트 내의 표준 발언들 중 어느 것도 사용자의 발언과 충분히 유사하지 않다고 결정했다. 따라서, 처리 시스템은 사용자 발언을 대체할 디폴트 발언을 선택한다. 그런 다음 방법(600)은 블록(630)으로 진행한다.At
블록(630)에서, 표준 발언은 하나 이상의 다른 사용자에게 전달된다. 본 명세서에서 논의된 바와 같이, 표준 발언은 그 표준 발언을 나타내는 텍스트, 음성 또는 기타 오디오로서 다른 사용자에게 전달된다.At
일부 실시예에서, 전술한 기술의 특정 양태는 소프트웨어를 실행하는 처리 시스템의 하나 이상의 프로세서에 의해 구현될 수 있다. 소프트웨어는 비-일시적 컴퓨터 판독 가능 저장 매체에 저장되거나 유형적으로 구현된 하나 이상의 실행 가능한 명령 세트를 포함한다. 소프트웨어는 하나 이상의 프로세서에 의해 실행될 때 하나 이상의 프로세서를 조작하여 위에서 설명한 기술의 하나 이상의 양태를 수행하는 명령 및 특정 데이터를 포함할 수 있다. 비-일시적 컴퓨터 판독 가능 저장 매체는 예를 들어, 자기 또는 광 디스크 저장 디바이스, 플래시 메모리와 같은 솔리드 스테이트 저장 디바이스, 캐시, 랜덤 액세스 메모리(RAM) 또는 기타 비-휘발성 메모리 디바이스 또는 디바이스(들)을 포함할 수 있다. 비-일시적 컴퓨터 판독 가능 저장 매체에 저장된 실행 가능 명령들은 소스 코드, 어셈블리 언어 코드, 객체 코드 또는 하나 이상의 프로세서에 의해 해석되거나 실행 가능한 기타 명령 형식일 수 있다.In some embodiments, certain aspects of the foregoing techniques may be implemented by one or more processors of a processing system executing software. Software includes one or more sets of executable instructions stored in or tangibly embodied in a non-transitory computer readable storage medium. Software may include instructions and specific data that, when executed by one or more processors, cause the one or more processors to perform one or more aspects of the techniques described above. Non-transitory computer readable storage media may include, for example, magnetic or optical disk storage devices, solid state storage devices such as flash memory, caches, random access memory (RAM), or other non-volatile memory devices or device(s). can include Executable instructions stored on a non-transitory computer readable storage medium may be in source code, assembly language code, object code, or other instructional form that is interpretable or executable by one or more processors.
컴퓨터 판독 가능 저장 매체는 명령 및/또는 데이터를 컴퓨터 시스템에 제공하기 위해 사용하는 동안 컴퓨터 시스템에 의해 액세스 가능한 임의의 저장 매체 또는 저장 매체의 조합을 포함할 수 있다. 이러한 저장 매체는 광 매체(예를 들어, CD(compact disc), DVD(digital Versatile Disc), Blu-Ray 디스크), 자기 매체(예를 들어, 플로피 디스크, 자기 테이프 또는 자기 하드 드라이브), 휘발성 메모리(예를 들어, RAM(Random Access Memory) 또는 캐시), 비-휘발성 메모리(예를 들어, ROM(Read-Only Memory) 또는 플래시 메모리) 또는 MEMS(Microelectromechanical System) 기반 저장 매체를 포함할 수 있지만 이에 한정되지 않는다. 컴퓨터 판독 가능 저장 매체는 컴퓨팅 시스템(예를 들어, 시스템 RAM 또는 ROM)에 내장되고, 컴퓨팅 시스템(예를 들어, 자기 하드 드라이브)에 고정적으로 부착되며, 컴퓨팅 시스템(예를 들어, 광 디스크 또는 Universal USB(Serial Bus) 기반 플래시 메모리) 또는 유선 또는 무선 네트워크(예를 들어, NAS(Network Accessible Storage))를 통해 컴퓨터 시스템에 연결된다.A computer readable storage medium may include any storage medium or combination of storage media that is accessible by a computer system while in use to provide instructions and/or data to the computer system. Such storage media may include optical media (e.g. compact discs (CDs), digital versatile discs (DVDs), Blu-Ray discs), magnetic media (e.g. floppy disks, magnetic tapes or magnetic hard drives), volatile memory (eg, random access memory (RAM) or cache), non-volatile memory (eg, read-only memory (ROM) or flash memory), or microelectromechanical system (MEMS) based storage media, but Not limited. A computer-readable storage medium may be embedded in a computing system (eg, system RAM or ROM), fixedly attached to a computing system (eg, a magnetic hard drive), and included in a computing system (eg, an optical disk or universal It is connected to a computer system through a serial bus (USB)-based flash memory) or a wired or wireless network (eg, Network Accessible Storage (NAS)).
일반적인 설명으로 위에서 설명한 모든 활동 또는 엘리먼트가 필요한 것은 아니며 특정 활동 또는 디바이스의 일부가 필요하지 않으며 일부 실시예에서 설명된 것 외에 하나 이상의 추가 활동이 수행되거나 요소가 포함된다. 또한 활동이 나열되는 순서가 반드시 수행되는 순서는 아니다. 또한, 개념들은 구체적인 실시예를 참조하여 설명되었다. 그러나, 당업자라면 하기 청구범위에 기재된 본 발명의 범위를 벗어나지 않고 다양한 수정 및 변경이 이루어질 수 있음을 이해할 것이다. 따라서, 명세서 및 도면은 제한적인 의미가 아닌 예시적인 것으로 간주되어야 하며, 이러한 모든 변형은 본 개시의 범위 내에 포함되도록 의도된다.As a general description, not all activities or elements described above are required, and certain activities or parts of devices are not required, and in some embodiments, one or more additional activities or elements are performed beyond those described. Also, the order in which activities are listed is not necessarily the order in which they are performed. Also, concepts have been described with reference to specific embodiments. However, those skilled in the art will understand that various modifications and changes can be made without departing from the scope of the invention as set forth in the claims below. Accordingly, the specification and drawings are to be regarded in an illustrative rather than restrictive sense, and all such modifications are intended to be included within the scope of this disclosure.
이점, 다른 장점 및 문제에 대한 해결책은 특정 실시예와 관련하여 위에서 설명되었다. 그러나, 이점, 장점, 문제에 대한 솔루션 및 그 이점, 장점 또는 솔루션을 발생시키거나 더 뚜렷하게 만들 수 있는 모든 기능은 일부 또는 모든 청구의 중요하거나 필수이거나 필수적인 기능으로 해석되어서는 안 된다. 더욱이, 위에 개시된 특정 실시예는 개시된 주제는 단지 예시적인 것이며, 이는 상이하지만 본 명세서의 교시의 이점을 갖는 당업자에게 명백한 동등한 방식으로 수정 및 실시될 수 있기 때문이다. 아래의 청구 범위에 기술된 것 외에 본 명세서에 도시된 구성 또는 설계의 세부 사항에 대한 제한은 없다. 따라서, 위에 개시된 실시예는 변경 또는 수정될 수 있고 이러한 모든 변형은 개시된 주제의 범위 내에서 고려된다는 것이 명백하다. 따라서, 본 명세서에서 추구하는 보호는 아래의 청구범위에 설명된 바와 같다.Advantages, other advantages, and solutions to problems have been described above with respect to specific embodiments. However, an advantage, advantage, solution to a problem, and any feature that may give rise to or make that advantage, advantage, or solution apparent, is not to be construed as an important, essential, or essential feature of any or all claims. Moreover, the specific embodiments disclosed above are illustrative only, as the disclosed subject matter may be modified and practiced in different but equivalent ways obvious to those skilled in the art having the benefit of the teachings herein. No limitations are intended to the details of construction or design herein shown, other than as described in the claims below. It is therefore evident that the embodiments disclosed above may be altered or modified and all such variations are considered within the scope of the disclosed subject matter. Accordingly, the protection sought herein is as set forth in the claims below.
Claims (28)
적어도 하나의 프로세서에 의해, 애플리케이션의 제1 사용자로부터의 발언의 표현과 표준 발언 세트의 표준 발언과의 시맨틱 비교에 기초하여 표준 발언 세트로부터 표준 발언을 선택하는 단계와; 그리고
제1 사용자로부터의 발언을 제시하는 대신 애플리케이션의 제2 사용자에게 상기 선택된 표준 발언을 제시하는 단계를 포함하는 것을 특징으로 하는 컴퓨터 구현 방법.As a computer implemented method,
selecting, by at least one processor, a standard utterance from the standard utterance set based on a semantic comparison of a representation of a utterance from a first user of the application with standard utterances in the standard utterance set; And
and presenting the selected standard utterance to a second user of the application instead of presenting the utterance from the first user.
상기 발언은 애플리케이션의 제1 사용자로부터의 텍스트 문자열을 포함하는 것을 특징으로 하는 컴퓨터 구현 방법.According to claim 1,
wherein the utterance comprises a text string from a first user of the application.
상기 발언은 애플리케이션의 제1 사용자로부터의 음성 발언을 포함하는 것을 특징으로 하는 컴퓨터 구현 방법.According to claim 1 or 2,
wherein the utterance comprises an audio utterance from a first user of the application.
적어도 하나의 프로세서에 의해 음성-텍스트 변환 애플리케이션을 사용하여, 표준 발언 세트의 표준 발언과 비교될 제1 사용자로부터의 발언의 텍스트 표현으로 상기 음성 발언을 변환하는 단계를 더 포함하는 것을 특징으로 하는 컴퓨터 구현 방법.According to claim 3,
converting, by at least one processor, the spoken utterance into a textual representation of a utterance from the first user to be compared with a standard utterance of a set of standard utterances using a speech-to-text conversion application. How to implement.
상기 표준 발언 세트로부터 표준 발언을 선택하는 단계는 자연어 처리에 기초하는 것을 특징으로 하는 컴퓨터 구현 방법.According to any one of the preceding claims,
and the step of selecting a standard utterance from a set of standard utterances is based on natural language processing.
상기 표준 발언 세트로부터 표준 발언을 선택하는 단계는
발언에 기초하여 표준 발언 세트로부터의 표준 발언의 시맨틱 검색을 사용하거나 표준 발언과 제1 사용자로부터 수신된 발언의 시맨틱 유사성을 사용하여 표준 발언 세트로부터 표준 발언을 선택하는 단계를 포함하는 것을 특징으로 하는 컴퓨터 구현 방법.According to claim 5,
Selecting a standard utterance from the set of standard utterances
based on the utterance, selecting a standard utterance from the standard utterance set using a semantic search of a standard utterance from the standard utterance set or using a semantic similarity between the standard utterance and a utterance received from the first user. computer implemented method.
상기 표준 발언 세트로부터 표준 발언을 선택하는 단계는,
표준 발언 세트와 관련된 메타데이터에 기초하여 표준 발언을 선택하는 단계를 포함하는 것을 특징으로 하는 컴퓨터 구현 방법.According to any one of the preceding claims,
Selecting a standard utterance from the set of standard utterances,
A computer implemented method comprising selecting a standard utterance based on metadata associated with a set of standard utterances.
상기 메타데이터는 표준 발언 세트의 서브세트를 나타내는 것을 특징으로 하는 컴퓨터 구현 방법.According to claim 7,
The computer implemented method of claim 1 , wherein the metadata represents a subset of a set of standard utterances.
상기 표준 발언 세트로부터 표준 발언을 선택하는 단계는
메타데이터를 제1 사용자로부터 수신된 발언의 적어도 하나의 특성과 비교하고 서브세트들 중 식별된 하나로부터 표준 발언을 선택함으로써 서브세트들 중 하나를 식별하는 단계를 포함하는 것을 특징으로 하는 컴퓨터 구현 방법.According to claim 8,
Selecting a standard utterance from the set of standard utterances
identifying one of the subsets by comparing metadata with at least one characteristic of utterances received from the first user and selecting a canonical utterance from the identified one of the subsets; .
세트에 있는 표준 발언을 나타내는 벡터를 포함하는 열을 갖는 행렬로서 표준 발언 세트를 임베딩하는 단계를 더 포함하는 것을 특징으로 하는 컴퓨터 구현 방법.According to any one of the preceding claims,
Embedding the set of standard utterances as a matrix having columns containing vectors representing standard utterances in the set.
상기 표준 발언 세트로부터 표준 발언을 선택하는 단계는
제1 사용자로부터 수신된 발언을 나타내는 벡터의 요소를 상기 표준 발언을 나타내는 벡터를 포함하는 행렬의 열의 대응하는 엘리먼트와 곱함으로써 표준 발언에 대한 시맨틱 유사성 스코어를 생성하는 단계를 포함하는 것을 특징으로 하는 컴퓨터 구현 방법.According to claim 10,
Selecting a standard utterance from the set of standard utterances
generating a semantic similarity score for a canonical utterance by multiplying an element of a vector representing a utterance received from the first user by a corresponding element of a column of a matrix containing a vector representing the canonical utterance. How to implement.
상기 표준 발언 세트로부터 표준 발언을 선택하는 단계는,
시전 결정된 최소 임계값 이상의 시맨틱 유사성 스코어와 관련된 표준 발언을 선택하는 단계를 포함하는 것을 특징으로 하는 컴퓨터 구현 방법.According to claim 11,
Selecting a standard utterance from the set of standard utterances,
and selecting canonical utterances associated with a semantic similarity score equal to or greater than a pre-determined minimum threshold.
상기 표준 발언 세트로부터 표준 발언을 선택하는 단계는,
시맨틱 유사성 스코어 중 어느 것도 사전 결정된 최소 임계값을 초과하지 않는다는 것에 응답하여 표준 발언을 선택하는 단계를 포함하는 것을 특징으로 하는 컴퓨터 구현 방법.According to claim 12,
Selecting a standard utterance from the set of standard utterances,
and selecting a canonical utterance in response to none of its semantic similarity scores exceeding a predetermined minimum threshold.
표준 발언 세트를 저장하도록 구성된 메모리와; 그리고
적어도 하나의 프로세서를 포함하고,
상기 적어도 하나의 프로세서는,
애플리케이션의 제1 사용자로부터의 발언과 표준 발언 세트의 표준 발언과의 시맨틱 비교에 기초하여 표준 발언 세트로부터 표준 발언을 선택하고, 제1 사용자로부터의 발언을 제시하는 대신 애플리케이션의 제2 사용자에게 상기 선택된 표준 발언을 제시하도록 구성되는 것을 특징으로 하는 시스템..As a system,
a memory configured to store a set of standard utterances; And
includes at least one processor;
The at least one processor,
Select a standard utterance from a set of standard utterances based on a semantic comparison of utterances from a first user of the application with standard utterances in the standard utterance set, and present the selected utterance to a second user of the application instead of presenting the utterance from the first user. A system characterized in that it is configured to present standard utterances.
상기 적어도 하나의 프로세서는,
애플리케이션의 제1 사용자로부터의 발언을 나타내는 텍스트 문자열을 수신하도록 구성되는 것을 특징으로 하는 시스템.According to claim 16,
The at least one processor,
A system configured to receive a text string representing a utterance from a first user of an application.
상기 애플리케이션의 제1 사용자로부터의 발언은 음성 발언을 포함하고,
상기 적어도 하나의 프로세서는 애플리케이션의 제1 사용자로부터의 음성 발언을 나타내는 오디오 스트림을 수신하도록 구성되는 것을 특징으로 하는 시스템.The method of claim 16 or 17,
the utterance from the first user of the application includes an audio utterance;
The system of claim 1 , wherein the at least one processor is configured to receive an audio stream representative of an audio utterance from a first user of an application.
상기 적어도 하나의 프로세서는,
음성-텍스트 변환 애플리케이션을 사용하여, 음성 발언을 상기 표준 발언 세트의 표준 발언와 비교될 애플리케이션의 제1 사용자로부터의 발언으로 변환하도록 구성되는 것을 특징으로 하는 시스템. According to claim 18,
The at least one processor,
and converting, using a speech-to-text application, spoken utterances into utterances from a first user of the application to be compared with standard utterances of the set of standard utterances.
상기 적어도 하나의 프로세서는,
자연어 처리에 기초하여 표준 발언 세트로부터 표준 발언을 선택하도록 구성되는 것을 특징으로 하는 시스템.According to any one of claims 16 to 19,
The at least one processor,
A system configured to select a standard utterance from a set of standard utterances based on natural language processing.
상기 적어도 하나의 프로세서는,
발언에 기초하여 표준 발언 세트로부터의 표준 발언의 의미적 검색을 사용하거나 표준 발언과 애플리케이션의 제1 사용자로부터 수신된 발언의 시맨틱 유사성을 사용하여 표준 발언 세트로부터 표준 발언을 선택하도록 구성되는 것을 특징으로 하는 시스템.According to claim 20,
The at least one processor,
and selecting a standard utterance from the standard utterance set based on the utterance using semantic retrieval of a standard utterance from the standard utterance set or using a semantic similarity between the standard utterance and a utterance received from the first user of the application. system to do.
상기 메모리는 표준 발언 세트와 관련된 메타데이터를 저장하도록 구성되고,
상기 적어도 하나의 프로세서는 메타데이터에 기초하여 표준 발언을 선택하도록 구성되는 것을 특징으로 하는 시스템.According to any one of claims 16 to 21,
the memory is configured to store metadata associated with a set of standard utterances;
The system of claim 1 , wherein the at least one processor is configured to select standard utterances based on metadata.
상기 메타데이터는 표준 발언 세트의 서브세트를 나타내는 것을 특징으로 하는 시스템.The method of claim 22,
Wherein the metadata represents a subset of a set of standard utterances.
상기 적어도 하나의 프로세서는,
메타데이터를 제1 사용자로부터 수신된 발언의 적어도 하나의 특성과 비교하고 서브세트들 중 식별된 하나로부터 표준 발언을 선택함으로써 서브세트들 중 하나를 식별하도록 구성되는 것을 특징으로 하는 시스템.According to claim 23,
The at least one processor,
and identify one of the subsets by comparing the metadata with at least one characteristic of utterances received from the first user and selecting a standard utterance from the identified one of the subsets.
상기 적어도 하나의 프로세서는,
세트 내의 표준 발언을 나타내는 벡터를 포함하는 열을 갖는 행렬로서 표준 발언 세트를 임베딩하도록 구성되는 것을 특징으로 하는 시스템.The method of any one of claims 16 to 24,
The at least one processor,
A system configured to embed a set of standard utterances as a matrix having columns containing vectors representing standard utterances in the set.
상기 적어도 하나의 프로세서는,
제1 사용자로부터 수신된 발언을 나타내는 벡터의 엘리먼트를 표준 발언을 나타내는 벡터를 포함하는 행렬의 대응하는 열의 엘리먼트와 곱함으로써 표준 발언에 대한 시맨틱 유사성 스코어를 생성하도록 구성되는 것을 특징으로 하는 시스템.According to claim 25,
The at least one processor,
A system configured to generate a semantic similarity score for a canonical utterance by multiplying an element of a vector representing a utterance received from the first user by an element in a corresponding column of a matrix containing vectors representing a canonical utterance.
상기 적어도 하나의 프로세서는,
최소 임계값 이상의 시맨틱 유사성 스코어와 관련된 표준 발언을 선택하도록 구성되는 것을 특징으로 하는 시스템.The method of claim 26,
The at least one processor,
A system configured to select canonical utterances associated with a semantic similarity score above a minimum threshold.
상기 적어도 하나의 프로세서는,
시맨틱 유사성 스코어 중 어느 것도 최소 임계값을 초과하지 않는다는 것에 응답하여 표준 발언을 선택하도록 구성되는 것을 특징으로 하는 시스템.The method of claim 27,
The at least one processor,
and select a canonical utterance in response to none of the semantic similarity scores exceeding a minimum threshold.
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
PCT/US2020/037269 WO2021251973A1 (en) | 2020-06-11 | 2020-06-11 | Using canonical utterances for text or voice communication |
Publications (1)
Publication Number | Publication Date |
---|---|
KR20230005400A true KR20230005400A (en) | 2023-01-09 |
Family
ID=71452740
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
KR1020227043712A KR20230005400A (en) | 2020-06-11 | 2020-06-11 | Text or voice communication using standard utterances |
Country Status (6)
Country | Link |
---|---|
US (1) | US20230245650A1 (en) |
EP (1) | EP4165542A1 (en) |
JP (1) | JP2023530421A (en) |
KR (1) | KR20230005400A (en) |
CN (1) | CN115668205A (en) |
WO (1) | WO2021251973A1 (en) |
Families Citing this family (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20230178079A1 (en) * | 2021-12-07 | 2023-06-08 | International Business Machines Corporation | Adversarial speech-text protection against automated analysis |
US20240087596A1 (en) * | 2022-09-08 | 2024-03-14 | Roblox Corporation | Artificial latency for moderating voice communication |
Family Cites Families (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7437290B2 (en) * | 2004-10-28 | 2008-10-14 | Microsoft Corporation | Automatic censorship of audio data for broadcast |
AU2011279558A1 (en) * | 2010-07-15 | 2013-03-07 | The University Of Queensland | A communications analysis system and process |
US10366690B1 (en) * | 2017-05-15 | 2019-07-30 | Amazon Technologies, Inc. | Speech recognition entity resolution |
US10956670B2 (en) * | 2018-03-03 | 2021-03-23 | Samurai Labs Sp. Z O.O. | System and method for detecting undesirable and potentially harmful online behavior |
US10586532B1 (en) * | 2019-01-28 | 2020-03-10 | Babylon Partners Limited | Flexible-response dialogue system through analysis of semantic textual similarity |
-
2020
- 2020-06-11 CN CN202080101794.4A patent/CN115668205A/en active Pending
- 2020-06-11 KR KR1020227043712A patent/KR20230005400A/en unknown
- 2020-06-11 WO PCT/US2020/037269 patent/WO2021251973A1/en unknown
- 2020-06-11 US US18/009,488 patent/US20230245650A1/en active Pending
- 2020-06-11 JP JP2022576135A patent/JP2023530421A/en active Pending
- 2020-06-11 EP EP20736491.0A patent/EP4165542A1/en active Pending
Also Published As
Publication number | Publication date |
---|---|
EP4165542A1 (en) | 2023-04-19 |
CN115668205A (en) | 2023-01-31 |
JP2023530421A (en) | 2023-07-18 |
US20230245650A1 (en) | 2023-08-03 |
WO2021251973A1 (en) | 2021-12-16 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN106796496B (en) | Display apparatus and method of operating the same | |
US11195507B2 (en) | Translating between spoken languages with emotion in audio and video media streams | |
JP2008077601A (en) | Machine translation device, machine translation method and machine translation program | |
CN105869629A (en) | Voice recognition method and device | |
JP6235280B2 (en) | Simultaneous audio processing apparatus, method and program | |
KR20170035529A (en) | Electronic device and voice recognition method thereof | |
KR20230005400A (en) | Text or voice communication using standard utterances | |
KR102451925B1 (en) | Network-Based Learning Models for Natural Language Processing | |
JP6305629B2 (en) | Classification apparatus, method and program | |
US11837221B2 (en) | Age-sensitive automatic speech recognition | |
KR20160131505A (en) | Method and server for conveting voice | |
JP2018185561A (en) | Dialogue support system, dialogue support method, and dialogue support program | |
JP2010160608A (en) | Interaction device, interaction program, and interaction method | |
JP5159853B2 (en) | Conference support apparatus, method and program | |
JP2010078877A (en) | Speech recognition device, speech recognition method, and speech recognition program | |
JP2015219582A (en) | Interactive method, interaction device, interactive program, and recording medium | |
JP5997813B2 (en) | Speaker classification apparatus, speaker classification method, and speaker classification program | |
US20230107968A1 (en) | Systems and methods for replaying a content item | |
JP2019205114A (en) | Data processing apparatus and data processing method | |
US11862144B2 (en) | Augmented training data for end-to-end models | |
JP7416078B2 (en) | Speech recognition device, speech recognition method, and program | |
CN114424148B (en) | Electronic device and method for providing manual thereof | |
WO2016151692A1 (en) | Tagging support device, method and program | |
JP6143824B2 (en) | Spoken dialogue support apparatus, method, and program | |
JP6633708B2 (en) | Tag assignment support apparatus, method and program |