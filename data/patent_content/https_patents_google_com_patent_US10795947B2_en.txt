US10795947B2 - Unified message search - Google Patents
Unified message search Download PDFInfo
- Publication number
- US10795947B2 US10795947B2 US15/156,567 US201615156567A US10795947B2 US 10795947 B2 US10795947 B2 US 10795947B2 US 201615156567 A US201615156567 A US 201615156567A US 10795947 B2 US10795947 B2 US 10795947B2
- Authority
- US
- United States
- Prior art keywords
- messages
- interface
- platform
- user
- message
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active, expires
Links
- 238000004891 communication Methods 0.000 claims abstract description 189
- 238000000034 method Methods 0.000 claims abstract description 89
- 230000015654 memory Effects 0.000 claims description 36
- 230000004044 response Effects 0.000 claims description 31
- 230000002123 temporal effect Effects 0.000 claims description 20
- 230000005540 biological transmission Effects 0.000 claims description 12
- 230000000007 visual effect Effects 0.000 claims description 5
- 230000006855 networking Effects 0.000 claims description 4
- 238000004590 computer program Methods 0.000 abstract description 17
- 230000008569 process Effects 0.000 description 43
- 238000012545 processing Methods 0.000 description 7
- 230000009471 action Effects 0.000 description 6
- 230000003993 interaction Effects 0.000 description 6
- 230000003287 optical effect Effects 0.000 description 6
- 238000004422 calculation algorithm Methods 0.000 description 5
- 238000010586 diagram Methods 0.000 description 5
- 230000006870 function Effects 0.000 description 5
- 230000004048 modification Effects 0.000 description 4
- 238000012986 modification Methods 0.000 description 4
- 241000718541 Tetragastris balsamifera Species 0.000 description 3
- 230000001413 cellular effect Effects 0.000 description 2
- 239000000470 constituent Substances 0.000 description 2
- 238000001514 detection method Methods 0.000 description 2
- 238000005516 engineering process Methods 0.000 description 2
- 239000004973 liquid crystal related substance Substances 0.000 description 2
- 239000000203 mixture Substances 0.000 description 2
- 230000000644 propagated effect Effects 0.000 description 2
- 238000013515 script Methods 0.000 description 2
- 238000000926 separation method Methods 0.000 description 2
- 238000013528 artificial neural network Methods 0.000 description 1
- 238000005352 clarification Methods 0.000 description 1
- 230000000694 effects Effects 0.000 description 1
- 238000007689 inspection Methods 0.000 description 1
- 238000010801 machine learning Methods 0.000 description 1
- 230000000306 recurrent effect Effects 0.000 description 1
- 238000009877 rendering Methods 0.000 description 1
- 238000012552 review Methods 0.000 description 1
- 238000010079 rubber tapping Methods 0.000 description 1
- 239000004065 semiconductor Substances 0.000 description 1
- 230000001953 sensory effect Effects 0.000 description 1
- 239000007787 solid Substances 0.000 description 1
- 239000000758 substrate Substances 0.000 description 1
- 239000013589 supplement Substances 0.000 description 1
- 238000012546 transfer Methods 0.000 description 1
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/95—Retrieval from the web
- G06F16/951—Indexing; Web crawling techniques
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q10/00—Administration; Management
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/904—Browsing; Visualisation therefor
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q10/00—Administration; Management
- G06Q10/10—Office automation; Time management
- G06Q10/107—Computer-aided management of electronic mailing [e-mailing]
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04M—TELEPHONIC COMMUNICATION
- H04M1/00—Substation equipment, e.g. for use by subscribers
- H04M1/26—Devices for calling a subscriber
- H04M1/27—Devices whereby a plurality of signals may be stored simultaneously
- H04M1/271—Devices whereby a plurality of signals may be stored simultaneously controlled by voice recognition
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04M—TELEPHONIC COMMUNICATION
- H04M1/00—Substation equipment, e.g. for use by subscribers
- H04M1/72—Mobile telephones; Cordless telephones, i.e. devices for establishing wireless links to base stations without route selection
- H04M1/724—User interfaces specially adapted for cordless or mobile telephones
- H04M1/72403—User interfaces specially adapted for cordless or mobile telephones with means for local support of applications that increase the functionality
- H04M1/7243—User interfaces specially adapted for cordless or mobile telephones with means for local support of applications that increase the functionality with interactive means for internal management of messages
-
- H04M1/72547—
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04W—WIRELESS COMMUNICATION NETWORKS
- H04W4/00—Services specially adapted for wireless communication networks; Facilities therefor
- H04W4/12—Messaging; Mailboxes; Announcements
- H04W4/14—Short messaging services, e.g. short message services [SMS] or unstructured supplementary service data [USSD]
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04M—TELEPHONIC COMMUNICATION
- H04M2250/00—Details of telephonic subscriber devices
- H04M2250/74—Details of telephonic subscriber devices with voice recognition means
Definitions
- This specification describes technologies related to search engines.
- the disclosed embodiments relate to computerized processes that enable a communications device, such as a mobile telephone, smart phone, or tablet computer, to generate terms of a search query, to identify multiple messages across multiple messaging platforms based on the search terms, and to present a single interface that enables the user to interact with the identified messages generated by multiple messaging platforms.
- a communications device such as a mobile telephone, smart phone, or tablet computer
- cross-platform messages refers to a set of messages that includes a message from each of multiple different messaging platforms or messaging services.
- the communications device may receive a search query based on one or more utterances spoken by the user and captured by a microphone.
- the communications device may apply various speech-recognition algorithms to the captured audio data and generate corresponding textual output data, which may include user-specified search terms.
- the specified search terms may include, but are not limited to, a request to identify cross-platform messages associated with a particular sender and/or receiver, a particular messaging platform, a presence of words or phrases within corresponding message subjects or message bodies, and/or a particular range of transmission and/or receipt dates.
- the search query may be open-ended and, for example, may request access to all cross-platform messages transmitted from or received by the communications device.
- the communications device may access one or more repositories of stored cross-platform message data, and based on the user-specified search terms, may obtain at least a portion of the stored cross-platform message data that corresponds to the search query.
- the communications device may generate one or more interface elements that describe cross-platform messages within the obtained cross-platform message data (e.g., message cards), and additionally or alternatively, summarize groups of the cross-platform messages generated by corresponding ones of the messaging platforms (e.g., digest cards).
- the communications device may also generate a unified interface that includes the interface elements, which include, but are not limited to, the message cards and/or digest cards.
- the communications device may process the generated data and render the unified interface, and the constituent interface elements, for presentation to the user through a corresponding presentation device, such as a touchscreen display of the communication device.
- a computer-implemented method includes receiving, by one or more processors, a query at a communications device, and obtaining, by the one or more processors, message data responsive to the received query.
- the message data may include a plurality of messages associated with at least one messaging platform, the messages may be associated with a plurality of messaging platforms, and at least one of the messages are associated with each of a plurality of messaging platforms.
- the method may also include identifying, by the one or more processors, one or more first messages of the plurality of messages that are associated with a first messaging platform, and determining, by the one or more processors, that a number of the first messages exceeds a threshold number of messages.
- the method may generate, by the one or more processors, a first interface element that includes at least a portion of each of the first messages, and generate, by the one or more processors, a user interface that includes the first interface element.
- the method may also include providing, by the one or more processors, the generated user interface to at least one of a display device or an audio interface for presentation to a user.
- the method may also include the step of receiving the first messages at the client device, and the message data may include temporal data indicative of at least one of a time or date at which the communications device received each of the first messages.
- the step of generating the one or more interface elements may also include establishing a chronological ordering of the received first messages based on the temporal data, and arranging the first message portions within the first interface element in accordance with the established chronological ordering.
- the first message portions may include at least one of textual content or image data, and the first interface element further comprises a portion of the temporal data associated with an initial one of the first messages within the chronological ordering.
- the disclosed methods may also include the steps of detecting a user input associated with the presented first interface element, in response to the detected input, generating second interface elements associated with each of the first messages, modifying at least a portion of the user interface to include the second interface elements, and providing the modified user interface to the display device for presentation to the user.
- the second interface elements may include portions of corresponding ones of the first messages
- the first interface element may correspond to a digest card
- the digest card may provide a summary of the messages included within the first subset of messages.
- the disclosed methods may include the steps of identifying second messages within the plurality of messages that are associated with a second messaging platform, determining that a number of the second messages fails to exceed the threshold message number, and in response to the determination that the second message number fails to exceed the threshold message number, generating a second interface element associated with each of the second messages.
- the second interface elements may, for example, include portions of corresponding ones of the second messages.
- the disclosed methods may also include the step of generating a second interface element that include at least a portion of a second one of the messages.
- the query may include at least one keyword
- the portion of the second message may include textual content that includes the keyword
- the method may also include the step of modifying, within the second interface element, at least one visual characteristic of the textual content that includes the keyword.
- the generated user interface may include the second interface element; and the disclosed methods may also include the steps of detecting a user input associated with the presented second interface element and in response to the detected input, at least one of executing an application program associated with the at least one messaging platform or performing operations that initiate an assistant flow.
- the executed application may, for example, perform one or more operations related to the corresponding message.
- the disclosed methods may also include determining that a a body of a second one of the messages exceeds a predetermined size and in response to the determination, generating a second interface element that includes a portion of the body of the second message.
- the disclosed methods may include the step of generating a plurality of second interface elements.
- the second interface elements may be associated with corresponding ones of the messages
- the message data may also include temporal data indicative of at least one of a time or date at which the communications device received each of the corresponding messages
- the generated user interface may include the second interface elements.
- the step of generating the user interface may also include establishing a chronological ordering of the corresponding messages based on the temporal data, and arranging the second interface elements within the user interface in accordance with the established chronological ordering.
- Methods consistent with the disclosed embodiments may also include receiving audio data at the communications device, and generating the query based on at least a portion of the received audio data.
- the audio data may include an utterance spoken by a user into a microphone of the communications device.
- the disclosed methods may include transmitting at least a portion of the received query to a computing system across a communications network, and receiving at least a portion of the message data from the computing system in response to the transmission.
- at least two of the plurality of messages are selected from a different one of the group consisting of: email, instant messaging, SMS/MMS text messaging, social networking application, and chat-based application.
- corresponding systems, devices, and computer programs may be configured to perform the actions of the methods, encoded on computer storage devices.
- a device having one or more processors may be so configured by virtue of software, firmware, hardware, or a combination of them installed on the device that in operation cause the device to perform the actions.
- One or more computer programs can be so configured by virtue of having instructions that, when executed by device, cause the device to perform the actions.
- FIG. 1 is a diagram of an exemplary computing system, consistent with the disclosed embodiments.
- FIGS. 2A-2C, 3, 4A-4B, and 5 are diagrams of exemplary unified interfaces, consistent with the disclosed embodiments.
- FIG. 6 is a flowchart of exemplary processes for searching stored cross-platform messages in response to a single user query, consistent with the disclosed embodiments.
- FIG. 7 is a diagram of computing devices that may be used to implement the systems and methods described in this document, as either a client or as a server or plurality of server.
- FIG. 1 is a diagram of an exemplary system 100 that, responsive to a user's query, may perform a search of messaging data generated across multiple messaging platforms, in accordance with the disclosed embodiments.
- system 100 may include a communications device 110 , such as a user's smartphone or tablet computer, and a computing system 130 , which may be associated with and/or maintained by one or more messaging platforms. Additionally, although not shown in FIG. 1 , system 100 may also include a communications network that interconnects various components of system 100 , such as communication device 110 and computing system 130 .
- the communications network may include, but is not limited to, a wireless local area network (LAN), e.g., a “WiFi” network, a RF network, a Near Field Communication (NFC) network, a wireless Metropolitan Area Network (MAN) connecting multiple wireless LANs, and a wide area network (WAN), e.g., the Internet.
- LAN wireless local area network
- RF wireless local area network
- NFC Near Field Communication
- MAN wireless Metropolitan Area Network
- WAN wide area network
- a user 101 of a communications device 110 may generate and receive messages using a number of different messaging platforms, including, but not limited to, various email applications, instant messaging applications, SMS- and/or MMS-based text messaging, social-networking applications, chat-based applications (e.g., GoogleTM hangouts), and other communications platforms that facilitate text-, voice-, or video-based communications between one or more individuals.
- Various components of system 100 such as communications device 110 and/or computing system 130 , may store data identifying portions of these transmitted or received messages.
- the stored data e.g., message data, may include structured data stored in a format consistent with the native messaging platforms and/or metadata characterizing the transmitted and/or received messages.
- communications device 110 may perform operations that, in response to a user-specified query, parse locally stored and/or remotely accessible message data to identify one or more messages generated across the various platforms (e.g., cross-platform messages) that are consistent with the user-specified query.
- communications device 110 may perform operations that generate or access an index built over the transmitted and/or received messages, and that search the index to identify the one or more cross-platform messages that are consistent with the user-specified query,
- various components of system 100 may generate interface elements that, when rendered for presentation, provide a single, unified interface that facilitates user 101 's interaction with the identified cross-platform messages.
- the generated interface elements may include a platform-specific interface element, which may describe a portion of the identified messages generated by a corresponding messaging application, and additionally or alternatively, may include a message-specific interface element, which may describe content included within a corresponding one of the identified messages.
- the unified interface may represent a single consistent interface that enables user 101 to identify and interact with messages of interest generated, transmitted, and/or received across multiple messaging platforms.
- communications device 110 may include a speech recognition module 112 , a search engine 114 , a cross-platform message storage 116 , and an interface generating module 118 , which may established by one or more elements of stored code or instructions executed by a processor of communications device 110 .
- communications device 110 may include additional or alternate modules, such as a text-to-speech (TTS) module, which may established by one or more elements of stored code or instructions executed by a processor of communications device 110 .
- Communications device 110 may also include a presentation device 120 , such as a touchscreen display, capable of presenting rendered interface elements to user 101 .
- Communications device 110 may also include an audio interface, such as a microphone, capable of detecting an utterance 102 spoken by user 101 , and the audio interface may provide audio data, which includes utterance 102 , to a speech recognition module 112 .
- speech recognition module 112 may apply one or more speech recognition algorithms to the provided audio data to generate corresponding textual output data, and speech recognition algorithms and models consistent with the disclosed embodiments may include, but are not limited to, statistical speech-recognition algorithms, such as hidden Markov models, and machine-learning algorithms, such as deep feedforward and recurrent neural networks. Additionally, in some instances, speech recognition module 112 may be associated with and may leverage the speech-recognition functionality of one or more applications executed by communications device 110 , such as the speech recognition functionalities provided by a virtual assistant provided by communications device 110 .
- user 101 may activate the audio interface (e.g., by uttering a predetermined word or phrase, such as “Okay Google,” or alternatively, by touching or tapping a presented interface device associated with the microphone), and utter the phrase “Show me my messages.”
- the audio interface may detect and capture the spoken phrase as utterance 102 , and audio data that includes the spoken phrase to speech recognition module 112 , which may process the audio data and generate corresponding textual output using any of the exemplary processes described above.
- Speech recognition module 112 may process the audio data, which include the spoken utterance “Okay, show me my messages,” to generate output data 122 , which may include recognized textual data corresponding to the spoken utterance, e.g., “show my messages.”
- Speech recognition module 112 may provide output data 122 A to search engine 114 , which may process output data 122 A to generate search terms and/or criteria for a corresponding search query (e.g., search query 122 B).
- search engine 114 may access cross-platform message storage 116 , identify one or more stored cross-platform messages based on the generated search terms and/or criteria, and obtain, as search results (e.g., search results 122 C), portions of the message data that describe the one or more identified cross-platform messages.
- the obtained portion of the message data may, for example, include metadata that characterizes the identified cross-platform messages (e.g., identifying senders, recipient, send or receipt times, etc.), and additionally or alternatively, portion of the identified cross-platform messages (e.g., portions of the message subjects, message contents, and/or message attachments).
- speech recognition module 112 may provide output data 122 A to other modules or components of communications device 110 , or to other accessible computing systems or servers, e.g., cloud-based systems and servers, which may process output data 122 A to generate search query 122 B, as described above.
- the generated search terms and/or criteria may include, but are not limited to, a term that identifies one or more messaging platforms (e.g., SMS text messages, email messages, chat messages, etc.), a term that identifies a particular sender and/or recipient (e.g., a name, an email address, a telephone number, a handle in a chat or social media network, etc.), a term identifying a particular temporal limitation (e.g., messages sent or received in the last fifteen minutes, thirty minutes, etc.), a term that identifies one or more attributes of the messages (e.g., new messages, unread messages, etc.), and/or a term that identifies a desired word or phrase within the bodies and/or subject of the messages.
- a term that identifies one or more messaging platforms e.g., SMS text messages, email messages, chat messages, etc.
- a term that identifies a particular sender and/or recipient e.g., a name, an email address, a
- search engine 114 may establish any additional or alternate search term that would be appropriate to the stored cross-platform messages, communications device 110 , and to user 101 , such as volume-based limitations that caps the number of returned cross-platform messages.
- speech recognition module 112 may also be configured to detect, within received audio data (e.g., as spoken by user 101 ), one or more commands that cause communications device 110 to perform additional operations related to a particular cross-platform message. For example, speech recognition module 112 may detect user 101 's utterance of ‘read it” within the audio data, and communications device 110 may perform operations that convert portions of the text of the specific message to audio content and present that audio content to user 101 through a speaker or other interface.
- speech recognition module 112 may detect user 101 's utterance of “skip it” within the audio data, and communications device 110 may perform operations that identify a successive message within a set of search results (e.g., search results 112 C or message data 122 D), as described below. Speech recognition module 112 may also detect, within the audio data, a presence of user 101 's utterance of “reply,” which may cause communications device 110 to execute a message composition action via a virtual assistant or execute a native application associated with a corresponding message (e.g., a text-message application) and generate a reply to the corresponding message, as described below.
- a native application associated with a corresponding message e.g., a text-message application
- speech recognition module 112 may detect additional utterances indicative of user 101 's interaction with identified and presented messages, such as utterances representing follow-up to a prior utterance and/or that filter the messages included within search results 112 C or message data 122 D. For example, speech recognition module 112 may detect user 101 's utterance of “read the next one from Bob,” or “reply to the second one,” and communications device 110 may perform any of the exemplary processes described above to identify and present to user 101 a successive message received from “Bob,” and/or to perform operations that identify and generate a reply to the second message within the set of search results.
- the disclosed embodiments are, however, not limited to these exemplary commands or dialog-state phrases, and in other aspects, speech recognition module 112 may identify any additional or alternative command or dialog-state message appropriate to communications device 110 or one or more cross-platform messages, such as “cancel.”
- speech recognition module 112 may also be configured to detect additional user inquiries that characterize an identified set of cross-platform messages. For example, speech recognition module 112 may be configured to detect, within the audio data, inquiries that include, but are not limited to, inquiries regarding a number of “new” cross-platform messages (e.g., “how many new emails do I have”), inquiries regarding specific types of cross-platform messages (e.g., “do I have a new SMS”), inquiries regarding when a specific type of cross-platform message was transmitted by a particular contact (e.g., “when did Bob text me last”), inquiries regarding whether user 101 replied to a particular cross-platform message or message thread (e.g., “has the ‘my stocks launch’ thread been updated”), inquiries as to whether user 101 received a specific type of cross-platform message (or messages) from a contact (e.g., “has Bob sent an email to me” or “did Bob reply to my last SMS”), and/or inquiries that seek to identify a number of “new” cross-platform messages (e.g.
- speech recognition module 112 may be capable of detecting an utterance that include any additional or alternate request to characterize a receive or transmitted cross-platform message appropriate to the message and to communications device 110 .
- speech recognition module 112 may be configured to detect, within the audio data, inquiries that identify one or more attributes of the cross-platform messages.
- inquiries consistent with the disclosed embodiments may include, but are not limited to, inquiries that request messages with embedded objects or attachment, inquiries that refer to specific types of embedded objects or attachments, such as images and video, and inquiries that relate to specific concepts mentioned within the messages.
- Search engine 114 may, in some aspects, may parse output data 122 A, e.g., as received from speech recognition module 112 , and automatically generate one or more of the terms and/or criteria for search query 122 B based on portion of output data 122 A. For example, search engine 114 may establish that output data 112 A, which includes “show my messages,” corresponds to a request from user 101 to view all cross-platform messages transmitted by or received at communications device 110 , and may generate an appropriate search term that facilitates a search of all stored messages across any messaging platform.
- search engine 114 may establish one or more of the search terms and/or criteria in accordance with previously established or “default” parameters or values. For example, search engine 114 limit search results 122 C to those messages transmitted from or received by communications device 110 within a predetermined prior time period, such as fifteen minutes, and search engine 114 may establish an appropriate “default” search term based on this temporal limitation.
- Search engine 114 may, in some aspects, be configured to modify certain ones of the default search terms in response to user input received via output data 122 A (e.g., a portion of the user 101 's utterance that requests messages within the last thirty minutes) and additionally or alternatively, may be configured to present user-specific modifications to certain others of the default search terms (e.g., a limitation on a number of returned messages established based on a functionality of communications device 110 ).
- search engine 114 may access cross-platform message storage 116 , and based on search query 122 B, may identify one or more cross-platform messages that are consistent with the established search terms and/or criteria.
- cross-platform message storage 116 may include data (e.g., message data) identifying messages (e.g., cross-platform messages) generated by, transmitted from, and received by communications device 110 using multiple and different messaging platforms.
- data identifying one or more of the cross-platform messages generated by, transmitted from, and received by communications device 110 may be stored in one or more remote data repositories accessible to communications device 110 across the network, such as cloud-based repositories and repositories associated with the messaging platforms.
- these multiple messaging platforms may include, but are not limited to, email applications and clients, social-networking applications, text and instant messaging applications, SMS- and MMS-based text messaging, text-, voice-, and/or video-based chat applications, other communications platforms that facilitate text-, voice-, or video-based communications between one or more individuals.
- the message data may, by way of example, include structured data records that, for each of the cross-platform messages, identify a message direction (e.g., transmitted or received by communications device 110 ), a sender and/or a recipient, a timestamp associated with transmission or receipt, additionally or alternatively, a messaging platform that facilitated the transmission or receipt.
- cross-platform message storage 116 may include metadata that characterizes one or more of the cross-platform messages, the storage locations of which may be linked to corresponding ones of the structured data records.
- one or more of the multiple messaging platforms may be accessible to an operating system of communications device 110 (e.g., AndroidTM, iOSTM, etc.), search engine 114 may access the messages transmitted or received by these accessible messaging platforms and perform indexing operations on portions of these messages, such as the message subjects and message bodies.
- an operating system of communications device 110 e.g., AndroidTM, iOSTM, etc.
- search engine 114 may access the messages transmitted or received by these accessible messaging platforms and perform indexing operations on portions of these messages, such as the message subjects and message bodies.
- search engine 114 may identify one of more of the cross-platform messages stored within cross-platform message storage 116 that are consistent with the search terms and/or criteria. For example, as described above, search engine 114 may determine that output data 122 corresponds to a request from user 101 to view all cross-platform messages transmit by or received at communications device 110 , and may query cross-platform message storage 116 to identify the requested cross-platform messages, subject to any of the temporal-based and/or volume-based restrictions described above.
- search terms of search query 122 B may identify a specific sender or a specific recipient, and additionally or alternatively, a specific messaging platform, and search engine 114 may access the structured data records of cross-platform message storage 116 to identify one or more of the cross-platform messages associated with the specific sender, specific recipient, and/or specific messaging platform. Further, and as described above, search engine 114 may determine, based on output data 122 A, that utterance 102 represents a request by user 101 to view messages that included specific words or phrases within their subject lines or bodies and search engine 114 may generate search terms that include the specific words or phrases.
- search engine 114 may access the indexed portions of the cross-platform messages, e.g., as stored within cross-platform message storage 116 , and identify one of more of the cross-platform messages whose subject lines and/or bodies include the specific words or phrases.
- search engine 114 may obtain search results 122 C that include message data corresponding to the identified messages (e.g., that are consistent with the search terms of query 122 B) and additionally or alternatively, portions of the identified messages, such as portions of the subject lines and bodies of the identified messages.
- search engine 114 may extract portions of the message data from the structured data records stored within cross-platform message storage 116 , and the message data within results 122 C may include, but is not limited to, data that identifies the sender, the recipient, the messaging platform, and the timestamp for each of the identified messages.
- search engine 144 may provide search results 122 C, along with additional data identifying the terms of search query 122 B, to interface generating module 118 within as message data 122 D.
- Interface generating module 118 may generate one or more interface elements (e.g., interface elements 122 E) that include textual and/or graphical data that describes the cross-platform messages identified within search results 122 C and further, may generate a unified interface that includes the one or interface elements.
- Interface generating module 118 may provide data specifying interface elements 122 E and the generated unified interface (e.g., data describing a layout and arrangement of interface elements 122 E within the unified interface, dimensions of interface elements 122 E within the unified interface, shape of interface elements 122 E within the unified interface, data describing a layout and arrangement of portions of information within interface elements 122 E, etc.) to a presentation device 120 of communications device 110 .
- Presentation device 120 may include, but is not limited to, a touchscreen display unit, and may be configured to render and present the user interface, which includes portions of interface elements 122 E, to user 101 .
- the unified interface may represent a single, consistent interface that facilitates not only user 101 's inspection of the cross-platform messages that match portions of the spoken query, but also user 101 's interaction with these and other cross-platform messages based on spoken input and other input channels.
- FIG. 2A illustrates an exemplary interface element 201 , which may be generated by interface generating module 118 and presented within a unified interface 200 by presentation device 120 in accordance with the disclosed embodiments.
- communications device 110 may present interface element 201 within a corresponding user interface.
- interface element 201 may be rectangular in shape, and may be characterized by a first dimension 201 A established by a lateral dimension of presentation device 120 (e.g., a width of a touchscreen display of communication device 110 ) and a longitudinal dimension 201 B established by interface generating module 118 based on an amount of included content and/or one or more dimensional limitations.
- unified interface 200 may also include an additional interface element, e.g., icon 200 A, associated with an audio interface, such as a microphone, capable of detecting an utterance spoken by user 101 .
- an audio interface such as a microphone
- user 101 may tap, touch, or provide other input selecting icon 200 A, which may cause communications device 110 to activate one or more functionalities of the audio interface, as described above.
- interface element 201 is visually similar in shape and/or size to an index or business card.
- one or more of interface elements 122 E, including interface element 201 may be characterized as electronic “message” cards that describe one or more cross-platform messages matching the search query uttered by user 101 .
- the disclosed embodiments are, however, not limited to interface elements having these exemplary shapes, and in other aspects, interface elements consistent with the disclosed embodiments may be characterized by any additional or alternate shape appropriate to the cross-platform messages and presentation device 120 , include other regular polygons, circular or ellipsoidal shapes, and other user-defined or user-specified shapes.
- interface elements 122 E may include a message-specific interface element (e.g., a message card) that identifies and describes a corresponding one of the cross-platform messages included within message data 122 D.
- a message-specific interface element e.g., a message card
- interface element 201 may corresponding to a message transmitted to user 101 from “Randy Wilson” at 11:15 a.m.
- message data 122 D may include, for the transmitted message, data identifying the sender, the recipient, the corresponding messaging platform (e.g., an text-messaging application), and at least a portion of the message body (e.g., “Wanna grab a bit to eat at Masa?”).
- interface generating module 118 may receive and process message data 122 D to extract the data identifying the sender, the recipient, the corresponding messaging platform, and the portion of the message body of the transmitted message, and may generate interface element 210 that include portions of the extracted data.
- interface element 201 may include textual data identifying the sender of the message (e.g., “Randy Wilson”), the recipient (e.g., “me”), a time of receipt (e.g., “11:28 a.m.”) and the body of the message (e.g., “Wanna grab a bit to eat at Masa?”).
- the sender name e.g., “Randy Wilson”
- message data 122 D may include an identifier of the sender within the text-messaging application (e.g., a telephone number, user name, or other handle), and interface generating module 118 (and additionally or alternatively, other modules of communications device 110 ) may access a contact list or other data associated with the text-messaging application and identify the sender's name based on a correspondence with the sender identifier.
- an identifier of the sender within the text-messaging application e.g., a telephone number, user name, or other handle
- interface generating module 118 may access a contact list or other data associated with the text-messaging application and identify the sender's name based on a correspondence with the sender identifier.
- interface generating module 118 may truncate the message body and include only a portion of the message body within an interface element, such as interface element 201 and other interface elements described below.
- interface generating module 118 may also include graphical content 210 C, such as an avatar or image associated with the sender and an image or icon representative of the text-messaging application.
- interface generating module 118 (and additionally or alternatively, other modules of communications device 110 ) may obtain the avatar or image of the sender, e.g., “Randy Wilson,” from the contact list or other data associated with the text-messaging application, and further, may obtain the image or icon representative of the text-messaging application from a data repository maintained by an operating system executed by communications device 110 .
- the disclosed embodiments are, however, interface elements that include these exemplary data elements, and in other aspects, interface generating module 118 may generate interface element that include any additional or alternate data information that would be appropriate to the identified messages and presentation device 120 .
- user 101 may provide input to communications device 110 that enables user 101 to interact with the message received from “Randy Wilson” at 11:15 a.m., as described within interface element 201 .
- user 101 may utter one or more specific phrases that, upon detection by the audio interface and processing by speech recognition module 112 , cause communications device 110 to execute the corresponding text-messaging application and interact with the received message.
- user 101 may utter the term “Reply,” and upon detection by the audio interface and processing by speech recognition module 112 , communications device 110 may execute the text message application and enable user 101 to provide additional input in response to the message.
- user 101 may touch, tap, or otherwise content a surface of presentation device 120 (e.g., a touchscreen display) associated with a region 200 B of unified interface 200 , and in response to the detected input, communications device 110 may execute the text message application and enable user 101 to provide additional input in response to the message.
- presentation device 120 e.g., a touchscreen display
- communications device 110 may enable user 101 to provide any additional or alternate spoken or manual input to perform any additional or alternate operations associated with the cross-platform message, such as “delete,” “forward,” etc.
- message data 122 D may include data identifying one or more cross-platform messages (e.g., the message from “Randy Wilson” described above) that are consistent with the search query uttered by user 101 .
- cross-platform messages e.g., the message from “Randy Wilson” described above
- the number of identified cross-platform messages that are consistent with the uttered search query may be large, and the dimensions of presentation device 120 may render impractical the generation of a unified interface including message-specific interface elements that characterize each of the identified messages.
- interface generating module 118 may also generate a platform-specific interface element, e.g., a digest card, that includes textual and graphical content characterizing multiple messages received by or transmitted from communications device 110 using a corresponding one of the messaging platforms.
- a platform-specific interface element e.g., a digest card
- interface generating module 118 may selectively generate message-specific and platform-specific interface elements based on the number of identified cross-platform messages that are consistent with the uttered search query. For example, interface generating module 118 (and additionally or alternatively, other modules of communications device 110 ) may establish that user 101 is capable of readily viewing a threshold number of distinct, message-specific interface element (e.g., message cards) within presentation device 120 of communications device 110 , communications device 110 may store data indicative of the threshold interface-element number within a locally accessible data repository.
- message-specific interface element e.g., message cards
- Interface generating module 118 may, in certain aspects, determine the number of discrete cross-platform messages included within message data 122 D, and when the determined number falls below the established threshold number, interface generating module 118 may elect to generate message cards for each of cross-platform messages using any of the exemplary processes described herein. Alternatively, if interface generating module 118 were to determine that the determined number exceeds the established threshold number, interface generating module 118 may elect to generate one or more digest cards that include textual and graphical content summarizing groups of the cross-platform messages associated with corresponding ones of the messaging platforms.
- search query 122 B may correspond to a request from user 101 to view all cross-platform messages transmitted by or received at communications device 110 within a prior temporal interval, e.g., thirty minutes.
- search engine 114 may identify fourteen cross-platform messages received and/or transmitted by communications device 110 within the last thirty minutes, and these cross-platform messages may include three messages received using a text-messaging application and eleven messages received by using an email application, such as GmailTM.
- Search engine 114 may provide data associated with these fourteen messages (e.g., sender, recipient, messaging platform, message content, etc.) to interface generating module 118 within message data 122 D using any of the exemplary processes described above, and may determine that these fourteen messages exceed the threshold number of messages that trigger the generation of platform-specific interface elements (e.g., seven messages).
- interface generating module 118 may generate a first digest card that identifies and summarizes the three cross-platform messages received using the text-messaging application, and a second digest card that identifies and summarizes the eleven cross-platform messages received using the email application.
- message data 122 D may include text messages transmitted from “Mike,” “Bill,” and “Margaret” to user 101 using the text-messaging application
- message data 112 D may include, for each of these three messages, data identifying the sender (e.g., “Mike,” “Bill,” or “Margaret”), the recipient (e.g., user 101 ), the corresponding messaging platform (e.g., the text-messaging application), and a portion of the corresponding message bodies.
- Interface generating module 118 may access message data 122 D and extract the data identifying the sender, the recipient, the corresponding messaging platform, and the portion of the message body for each of the three text-messages. In certain aspects, illustrated in FIG. 2B , interface generating module 118 may generate the first digest card (e.g., digest card 202 ) that identifies and summarizes the three cross-platform messages received using the text-messaging application, which may be presented to user 101 within unified interface 200 by presentation device 120 . For instance, in FIG.
- the first digest card e.g., digest card 202
- digest card 202 may include an icon or image 202 A that identifies the text-messaging application (e.g., as maintained by communication device 110 's operating system within a corresponding data repository), and content 202 B, 202 C, and 202 D, that identifies the text messages transmitted, respectively, by “Mike,” “Bill,” and “Margaret” to user 101 .
- content 202 B, 202 C, and 202 D may identify a corresponding one of the senders (e.g., “Mike,” “Bill,” or “Margaret”) and portions of the corresponding message bodies, which may be truncated depending on a length of the message body and a dimension of interface element 202 .
- digest card 202 may also include a time stamp 202 E, which may specify an earliest one of the receipt times of three text-messages (e.g., as extracted by interface generating module 118 from message data 122 D).
- interface generating module 118 may access message data 122 D and extract the data identifying the sender, the recipient, the corresponding messaging platform, and the message body portion for each of the eleven messages received through the email application. Using any of the exemplary processes described above, interface generating module 118 may generate the second digest card (e.g., digest card 204 ) that identifies and summarizes the eleven cross-platform messages received using the text-email application, which may also be presented to user 101 within unified interface 200 by presentation device 120 .
- the second digest card e.g., digest card 204
- Digest card 204 may include content associated with the eleven email messages that is similar to the text-message content described above with respect to digest card 202 , and digest card 204 may also include an icon or image associated with the email application and a time stamp specifying an earliest one of the receipt times of eleven email messages. Further, although described in terms of textual and graphical content, the disclosed embodiments are not limited to digest cards and platform-specific interface elements that include this exemplary content, and in other aspects, the disclosed digest cards may include any additional or alternate elements of textual or graphical content appropriate to the cross-platform messages and to presentation device 120 .
- user 101 may view digest card 202 , and may wish to obtain more detailed information that characterizes each of the three text messages received from “Mike,” “Bill,” and “Margaret.”
- user 101 may provide additional input related to digest card 202 (e.g., the platform-specific interface element summarizing cross-platform messages received via the text-messaging application), which may cause interface generating module 118 to generate additional interface elements that characterize corresponding ones of the three text messages received from “Mike,” “Bill,” and “Margaret,” and provide these additional interface elements (e.g., interface elements 122 E) to presentation device 120 for rendering and presentation to user 101 .
- additional interface elements e.g., interface elements 122 E
- user 101 may touch or tap a surface of presentation device 120 corresponding to a particular region 210 of digest card 202 , and in response to the received input, interface generating module 118 may generate message cards 222 , 224 , and 226 that include content describing corresponding ones of text messages 202 B, 202 C, and 202 D, and may provide message cards 222 , 224 , and 226 (and additionally or alternatively, data describing a dimension, layout, and/or format of message-specific interface elements 222 , 224 , and 226 ) to presentation device 120 , which may render and present message cards 222 , 224 , and 226 to user 101 through unified interface 200 .
- the content of message cards 222 , 224 , and 226 may be similar to that described above in reference to message card 201 , and may include, for example, content identifying the senders (e.g., “Mike,” “Bill,” or “Margaret”), the recipient (e.g., user 101 ), the messaging platform (e.g., the text-messaging application), and portions of the bodies of the corresponding text messages.
- content identifying the senders e.g., “Mike,” “Bill,” or “Margaret”
- the recipient e.g., user 101
- the messaging platform e.g., the text-messaging application
- the portions of the text-message bodies included within message cards 222 , 224 , and 226 may include textual content (e.g., in message cards 222 and 224 ), image data (e.g., in message card 226 ), video content, and any additional or alternate multimedia content appropriate to interface generating module 118 and presentation device 120 .
- interface generating module 118 may be configured to exclude the image, video, and other multimedia content within these and other messages from the digest cards (e.g., digest cards 202 and 204 ), and instead include predetermined text to indicate, to user 101 , the presence of mage, video, and/or multimedia content within the underlying messages (e.g., “image” text in digest card 202 of FIGS. 2B and 2C ).
- an utterance spoken by user 101 corresponds to a request to view all cross-platform messages transmitted by or received at communications device 110 during a particular temporal interval, e.g., thirty minutes.
- search queries consistent with the disclosed embodiments may specify any additional or alternate characteristic of the stored cross-platform messages, which may include a particular sender and/or receiver, a particular messaging platform, a presence of words or phrases within corresponding message subjects or message bodies, and/or a particular date range.
- user 101 may, through presentation device 120 of communications device 110 , view the message and/or digest cards that characterize the cross-platform messages received during the past thirty minutes.
- user 101 may utter a request to view those messages sent to user 101 by a particular individual, e.g., “Randy Wilson,” during the past thirty minutes.
- the audio interface of communications device 110 may capture and provide the uttered request (e.g., as utterance 102 ) to speech recognition module 112 , which may generate output data corresponding to the spoken request and provide that output data to search engine 114 .
- search engine 114 may process the output data to generate terms and/or criteria of a corresponding search request (e.g., terms of search request 122 B, which may identify the sender “Randy Wilson,” the particular time period, and that results should not be limited to particular messaging platforms), access cross-platform message storage 116 , and obtain data identifying all cross-platform messages sent to user 101 by “Randy Wilson” within the last thirty minutes (e.g., as search results 122 C).
- terms of search request 122 B which may identify the sender “Randy Wilson,” the particular time period, and that results should not be limited to particular messaging platforms
- access cross-platform message storage 116 e.g., data identifying all cross-platform messages sent to user 101 by “Randy Wilson” within the last thirty minutes (e.g., as search results 122 C).
- search engine 112 may provide portions of the obtained message data and information identifying the terms of search query 122 B to interface generating module 118 (e.g., as message data 122 D).
- message data 122 D may include data that identifies the sender (e.g., “Randy Wilson”), the recipient (e.g., user 101 ), a messaging platform, a time stamp, and message portions for six cross-platform messages transmitted from “Randy Wilson” to user 101 during the last thirty minutes.
- interface generating module 118 may access the previously established threshold number of messages that trigger a generation of platform-specific interface elements, and may compare that threshold number against the number of cross-platform messages in message data 122 D.
- the threshold number may include seven messages, and as message data 122 D includes six cross-platform messages, interface generating module 118 may elect to generate message-specific interface elements, e.g., message cards, corresponding to each of the six cross-platform messages using any of the exemplary processes described above. Interface generating module 118 may also provide data associated with the generated interface elements (e.g., interface elements 122 E) to presentation device 120 , which may present the generated message cards to user 101 within a unified interface.
- message-specific interface elements e.g., message cards
- Interface generating module 118 may also provide data associated with the generated interface elements (e.g., interface elements 122 E) to presentation device 120 , which may present the generated message cards to user 101 within a unified interface.
- FIG. 3 illustrates additional exemplary portions of unified interface 200 , in accordance with the disclosed embodiments.
- interface generating module 118 may generate message cards 302 , 304 , 306 , 308 , and 310 , which include information and content that describes and characterizes corresponding ones of the cross-platform messages transmitted to user 101 by “Randy Wilson” during the past thirty minutes.
- message cards 302 , 306 , and 310 may correspond to text messages received from “Randy Wilson” using various text-messaging applications
- message cards 304 and 308 may correspond to email messages received from “Randy Wilson” using various email applications.
- each of message cards 302 , 304 , 306 , 308 , and 310 may include content similar to that described above in reference to message card 201 , which includes, but is not limited to, a sender, a recipient, a corresponding messaging platform, and a portions of a corresponding message body or a message subject.
- interface generating module 118 and/or presentation device 120 may arrange message cards 302 , 304 , 306 , 308 , and 310 within unified interface 200 chronologically in order of their receipt by or transmission from communications device 110 . Further, in additional or alternate aspects, interface generating module 118 and/or presentation device 120 may arrange message cards 302 , 304 , 306 , 308 , and 310 in order according to their corresponding messaging platforms or based on any additional or alternate message characteristics, including combinations of characteristics such as receipt or transmission time, sender, recipient, messaging platform and/or relevance to the user's query.
- presentation device 120 may be insufficiently large to simultaneously present message cards 302 , 304 , 306 , 308 , and 310 to user 101 at any meaningful display resolution.
- presentation device 120 may present a subset of messaging cards 302 , 304 , 306 , 308 , and 310 within a particular viewing pane of unified interface 200 (e.g., messaging card 302 and a portion of messaging card 304 in FIG.
- user 101 may scroll through additional viewing panes of unified interface 200 to view additional subsets of messaging cards 302 , 304 , 306 , 308 , and 310 (e.g., by contacting a surface of a touchscreen display with a fingertip or stylus, and subsequent moving the fingertip or stylus across the surface along direction 320 ).
- interface resolution module 118 may be configured to generate a merged interface element (e.g., a merged message card) that describes multiple cross-platform messages that are consistent with the uttered search query and are transmitted from and/or received by communications device 110 within a predetermined time period.
- interface generating module 118 may generate message cards 402 , 404 , and 406 include content describing and characterizing text messages received from “Randy Wilson” using a text-messaging application at 11:27 a.m., 11:28 a.m., and 11:31 a.m., respectively.
- Presentation device 120 may, for example, sort and present these message cards within unified interface 200 in order of their times of receipt, or in accordance with any additional or alternate message characteristic or combinations of messaging characteristics.
- interface generating module 118 may determine that communications device 110 received the text messages associated with message cards 402 , 404 , and 406 (e.g., as received from “Randy Wilson”) within the predetermined time period.
- the predetermined time period may corresponding to a time period of five minutes
- interface generating module 118 may determine that communication device 110 received the first text message (e.g., corresponding to message card 402 ) at 11:27 a.m., and received the second and third text messages (e.g., corresponding to message cards 404 and 406 ) within the five-minute time period the initial text message.
- a value of the predetermined time period may be established and/or modified by interface generating module 118 (and additionally or alternatively, another component of communications device 110 ) to capture multiple related text messages related to a particular topic of discussion between user 101 and one or more other individuals, and although described in terms of a five-minute interval, predetermined time periods consistent with the disclosed embodiments may include any additional or alternate appropriate temporal interval capable of capturing exchanges of successive and related cross-platform messages.
- interface generating module 118 may generate a merged interface element, e.g., merged message card 410 , that includes data identifying and describing each of the three text messages, as illustrated in FIG. 4B .
- merged message card 410 may include message data 410 A, which includes portions of the bodies and/or subjects of each of the three messages, and time stamp 410 B, which corresponding to a time at which communications device 110 received the first or final of the three text messages (e.g., corresponding to message card 406 ).
- interface generating module 118 may arrange the portions of the message bodies and/or subjects within message data 410 A based on a chronological order in which communications device 110 received the corresponding text messages.
- merged message card 410 may include data identifying the sender (e.g., “Randy Wilson”), an avatar or image associated with the sender, data identifying the recipient (e.g., user 101 ), and an icon or image associated with the messaging platform, as described above.
- an utterance spoken by user 101 corresponds to a request from to view all cross-platform messages transmitted by or received at communications device 110 during a particular temporal interval, e.g., thirty minutes, or received at communications device 110 from a particular sender during that temporal interval.
- search queries consistent with the disclosed embodiments may specify any additional or alternate characteristic of the stored cross-platform messages, which may include a particular recipient, a particular messaging platform, a presence of words or phrases within corresponding message subjects or message bodies, and/or a particular date range.
- the disclosed embodiments may also identify, and present to user 101 , one or more cross-platform messages that match combinations of the exemplary search terms described above.
- user 101 's uttered search query may represent a request to view all cross-platform messages received from a particular sender (e.g., “Liz Day”) within a particular time period (e.g., thirty minutes) that include specific words or phrases within their subject lines or bodies (e.g., the word “Tahoe”).
- the audio interface of communications device 110 may capture and provide the uttered request (e.g., as utterance 102 ) to speech recognition module 112 , which may generate output data (e.g., output data 122 A) corresponding to the spoken request and provide that output data to search engine 114 .
- search engine 114 may obtain and provide to interface generating module 118 messaging data (e.g., message data 122 D) that identifying one or more cross-platform messages that include the word “Tahoe” and were received from sender “Liz Day” within the last thirty minutes.
- messaging data e.g., message data 122 D
- message data 122 D may include, for each of the identified cross-platform messages, data that identifies the sender (e.g., “Liz Day”), the recipient (e.g., user 101 ), a messaging platform, a time stamp, and portions of the identified cross-platform messages that include the word “Tahoe.” Further, in certain aspects, messaging data 122 D may also identify one or more terms and/or criteria of the uttered search query, including the specified sender, the specified word (e.g., “Tahoe”), and/or the specified time period (e.g., thirty minutes).
- interface generating module 118 may generate one or more platform-specific interface elements (e.g., digest cards) and/or message-specific interface elements (e.g., message cards) that characterize and describe the identified cross-platform messages using any of the exemplary techniques described above.
- message data 122 D may identify a single cross-platform message associated with the specified sender, e.g., “Liz Day,” that that includes the specified word, e.g., “Tahoe,” and as illustrated in FIG. 5 , interface generating module 118 may generate a single message card 502 for presentation within unified interface 200 by presentation device 120 .
- message card 502 may include data identifying the sender (e.g., “Liz Day”), an avatar or image associated with the sender, data identifying the recipient (e.g., user 101 ), and an icon or image associated with the messaging platform. Further, in FIG. 5 , message card 502 may also include a portion of the identified message that includes the specified word “Tahoe,” and interface generating module 118 may generate and transmit data instructing presentation device 120 to modify a visual characteristic of the specified work within the presented message portions.
- interface generating module 118 may instruct presentation device 120 to highlight text portions 502 A and 502 B as bolded text, which represent portions of the presented message body that include the word “Tahoe.”
- the disclosed embodiments are, however, not limited to processes present specified words within the message body using bold text, and in other aspects, interface generating module 118 may instruct presentation device 120 to modify any additional or alternate visual characteristic of the presented message portions to highlight a presence of specific words or phrases to user 101 , include underlying portions of text, a modification to text color, and/or a modification to a font or a font size.
- FIG. 6 is a flowchart of an exemplary process 600 for cross-platform searching of generated messages in response to a single user query, in accordance with the disclosed embodiments.
- a communications device e.g., communications device 110
- may perform the steps of exemplary process 600 which may enable communications device 110 to generate terms and/or criteria of a search query based on user 101 's spoken utterances, identify multiple cross-platform messages based on the generated terms and/or criteria, and present a single interface that enables user 101 to interact with identified messages generated by multiple messaging platforms.
- communications device 110 may provide functionality that enables user 101 generate and receive messages using a number of different messaging platforms, including, but not limited to, various email applications, instant messaging applications, SMS- and/or MMS-based text messaging, social-networking applications, and other communications platforms that facilitate text-, voice-, or video-based communications between one or more individuals.
- communications device 110 (and additionally or alternatively, other computing systems connected to communications device 110 across a communications network) may store data identifying portions of these generated, transmitted and/or received messages.
- the stored data e.g., message data, may include structured data stored in a format consistent with the native messaging platforms and/or metadata characterizing the transmitted and/or received messages.
- communications device 110 may provide operations that, in response to a user-specified query, parse locally stored and/or remotely accessible message data to identify one or more messages generated across the various messaging platform (e.g., cross-platform messages) that are consistent with the user-specified query.
- various messaging platform e.g., cross-platform messages
- communication device 110 receive the user-specified query, which may specify various search terms and search criteria, and which may corresponding to a request by user 101 to access and interact with various cross-platform messages that are consistent with the specified search terms and search criteria.
- the specified search terms and/or search criteria may include, but are not limited to, a request to identity cross-platform messages associated with a particular sender and/or receiver, a particular messaging platform, a presence of words or phrases within corresponding message subjects or message bodies, and/or a particular range of transmission and/or receipt dates.
- the search query may be open-ended and, for example, may request access to all cross-platform messages transmitted from or received by communications device 110 during a particular time period.
- communications device 110 may receive the search query based on one or more utterances spoken by user 101 and captured by an audio interface of communications device 110 , such as a microphone.
- user 101 may activate the audio interface, and may utter one or more phrases that, collectively, establish the user-specified query and user specified search terms and/or criteria.
- the audio interface may detect the spoken words and phrases (e.g., utterance 102 ), and may capture audio data that includes the spoken words and phrases.
- communications device 110 e.g., using speech recognition module 112
- communications device 110 may access one or more repositories of stored cross-platform message data (e.g., in step 604 ), and based on the user-specified search terms and/or criteria, may obtain at least a portion of the stored cross-platform message data that corresponds to the received search query (e.g., in step 606 ).
- communications device 110 may store data associated with one or more cross-platform messages transmitted from or received by communications device within a locally accessible data repository (e.g., cross-platform message storage 116 of FIG. 1 ).
- communications device 110 may perform operations (e.g., via search engine 114 of FIG. 1 ) that access cross-platform message storage 116 , identify one or more of the stored cross-platform messages based on the user-specified search terms and/or criteria, and obtain portions of the message data that describe the one or more identified cross-platform messages.
- additional cross-platform message data may be stored remotely in computing systems connected to communications device 110 across a corresponding communications network, such as computing system 130 .
- computing system 130 be maintained by or associated with one or more of the multiple messaging platforms (e.g., cloud-based storage associated with or maintained by the messaging platforms), and in step 604 and 606 , communications device 110 may perform additional operations that access computing system 130 , identify additional stored cross-platform messages based on the user-specified search terms and/or criteria, and obtain portions of the stored message data that describe these additional cross-platform messages.
- Communications device 110 may, in certain aspects, perform operations (e.g., using interface generating module 118 ) that identify a number of cross-platform messages described within the obtained messaging data (e.g., in step 608 ) and further, that identify the messaging platforms associated with these cross-platform messages (e.g., in step 610 ).
- the obtained message data may include structured data records that, for each of the identified cross-platform messages, specify a message direction (e.g., transmitted or received by communications device 110 ), a sender, a recipient, a timestamp associated with transmission or receipt, and/or a messaging platform that facilitated the transmission or receipt.
- the obtained message data may also include metadata associated with the one or more of the cross-platform messages, and certain instances, portions of the identified cross-platform messages, such as the message subjects and message bodies (e.g., when an operating system of communications device 110 is capable of accessing and indexing corresponding ones of the multiple messaging platforms.
- communications device 110 may generate one or more interface elements that describe corresponding ones of the cross-platform message, and additionally or alternatively, summarize groups of cross-platform messages generated by corresponding ones of the messaging platforms (e.g., in step 612 ).
- communications device 110 may generate message-specific interface elements (e.g., message cards) that identify and characterize the contents of corresponding ones of the cross-platform messages using any of the exemplary processes described above.
- message cards consistent with the disclosed embodiments may include, for example, data identifying corresponding senders, an avatar or image associated with the sender, data identifying the recipient (e.g., user 101 ), and/or an icon or image associated with the messaging platform.
- the generated message cards may include textual, image, video, and/or other multimedia data included within the bodies of corresponding ones of the cross-platform message.
- communications device 110 may perform operations that truncate the message body and include only a portion of the message body within a corresponding message card, as described above.
- communications device 110 may also perform operations that merge together multiple message cards and generate a single interface element (e.g., a “merged” message card) that represents each of the multiple message cards. For example, communications device 110 may merge together multiple message cards when the communications device 110 received or transmitted the cross-platform messages represented by these message cards within a predetermined time period.
- a single interface element e.g., a “merged” message card
- communications device 110 may generate one or more platform-specific interface elements, e.g., digest cards, that include textual and/or graphical content characterizing multiple messages received by or transmitted from communications device 110 using corresponding ones of the messaging platforms.
- each of the digest cards may be associated with a particular messaging platform, and may include content that summarizes groups of the identified cross-platform messages that were generated, transmitted, or received using the particular messaging platform.
- the disclosed embodiments are, however, not limited to digest cards that include platform-specific interface elements.
- one or more of the device cards may include interface elements representative of cross-platform messages associated with, among other things, common senders, common recipients, and common ranges of transmission dates or receipt dates.
- communication device 110 may selectively generate message cards and digest cards in step 612 based on the number of identified cross-platform messages that are consistent with the user-specified search terms and/or criteria. For example, and using any of the exemplary processes described above, communications device 110 may establish that user 101 is capable of readily viewing a threshold number of distinct message cards within presentation device 120 of communications device 110 , and may determine whether the number of discrete cross-platform messages within the obtained message data exceeds the established threshold number (e.g., as identified in step 308 ). When the number of cross-platform messages falls below the established threshold number, communications device 110 may elect to generate message cards for each of cross-platform messages using any of the exemplary processes described above.
- communications device 110 may elect to generate one or more digest cards that include textual and graphical content summarizing groups of the cross-platform messages associated with corresponding ones of the messaging platforms.
- communications device 110 may generate a unified interface that includes the one or more generated interface elements, which include, but are not limited to, one or more of the message cards, merged message cards, and/or digest cards (e.g., in step 614 ).
- communications device 110 may also generate data describing a layout and arrangement of the generated interface elements within the unified interface, dimensions of the generated interface elements within the unified interface, and/or shapes of the generated interface elements within the unified interface.
- Communications device 110 may process the generated data and render the unified interface, and the constituent interface elements, for presentation to user 101 through a corresponding presentation device, such as a touchscreen display of communication device 110 (e.g., in step 616 ).
- user 101 may utter words or phrases that specify additional search terms and/or criteria to limit the previous search query.
- communications device 110 may present, to user 101 , an unified interface that identifies multiple cross-platform messages received by communications device 110 during the last thirty minutes.
- user 101 may utter an additional search query that requests messages received within the last thirty minutes that are associated with a particular sender, with a particular messaging platform, or include specified words or phrases.
- communications device 110 may determine whether the audio interface (e.g., the microphone) detect an additional search query uttered by user 101 (e.g., in step 618 ). If communications device 110 were to determine that the audio interface captured audio data specifying additional search terms and/or criteria (e.g., step 618 ; YES), exemplary process 600 may pass back to step 612 , and communications device 110 may establish the additional search terms and/or criteria based on user 101 's spoken utterances, identify additional or alternate cross-platform messages based on the generated terms, and generate, via a presentation device, a single interface that enables user 101 to interact with additional or alternate messages using any of the exemplary processes described above.
- the audio interface e.g., the microphone
- exemplary process 600 may pass back to step 612 , and communications device 110 may establish the additional search terms and/or criteria based on user 101 's spoken utterances, identify additional or alternate cross-platform messages based on the generated terms, and generate, via a presentation device, a single
- exemplary process 600 is complete in step 620 .
- communications device 110 may identify one or more cross-platform messages that correspond to a generated search query, and may generate interface elements, e.g., interface elements 122 E, for presentation to user 101 through a graphical user interface, e.g., using presentation device 120 .
- interface elements e.g., interface elements 122 E
- presentation device 120 may provide a voice-user interface (VUI) that generates and presents to user 101 and allows user 101 to interact with the presented representations through an ongoing, non-linear dialogue.
- VUI voice-user interface
- communications device 110 may identify one or more cross-platform messages that are consistent with a user-specified search query.
- interface generating module 118 and additionally or alternatively, a text-to-speech module or a speech generation module (not shown in FIG. 1 ) may generate an aural representation of the identified cross-platform messages, and communications device 110 may present the aural representation to user 101 through the speaker or other interface.
- the presented aural representation may “read” the contents of the identified cross-platform messages to user 110 , and in response to the presented aural representation, speech recognition module 112 may detect additional utterances indicative of user 101 's interaction with presented cross-platform messages.
- these additional utterances may represent a follow-up to a prior utterance (e.g., “read the next one from Bob”), a request to filter the messages included within search results 112 C or message data 122 D (e.g., “read me messages received today’), and/or a request to perform a specific operation on one or more of the identified cross-platform messages (e.g., “reply to the second one”), and communications device 110 may perform any of the exemplary processes described above to perform operations consistent with the additional detected utterances.
- a follow-up to a prior utterance e.g., “read the next one from Bob”
- a request to filter the messages included within search results 112 C or message data 122 D e.g., “read me messages received today’
- a request to perform a specific operation on one or more of the identified cross-platform messages e.g., “reply to the second one”
- communications device 110 may perform any of the exemplary processes described above to perform operations consistent
- communications device 110 may perform operations that generate, e.g., using the TTS module, and present to user 101 through the audio interface additional aural content associated with one or more expected user responses.
- the additional aural content may include a specific question (e.g., requesting clarification regarding a requested cross-platform message associated with similarly named senders) associated with an answer having expected content and/or an expected format.
- communications device 110 may generate and present to user 110 follow-up aural content that poses a variation of the question and/or includes additional context.
- communications device 110 may repeatedly generate and present to user 110 aural content that poses the question, with additional or alternate variations and/or content, in an attempt to elicit an utterance having the expected content or format,
- communications device 110 may perform operations that, responsive to a user's query, search messaging data generated across multiple messaging platforms and present one or more cross-platform messages that are consistent with the search query to a user via a graphical user interface (GUI) or a voice-user interface (VUI).
- GUI graphical user interface
- VUI voice-user interface
- certain functions performed by communications device 110 including certain functions of speech recognition module 112 , search engine 114 , interface generating module 118 , the text-to-speech (TTS) module, and/or the speech generation module, may be performed by other communications devices connected to communications device 110 across the network, and additionally or alternatively, by other cloud-based computing systems and servers.
- data identifying one or more of the cross-platform messages generated by, transmitted from, and received by communications device 110 may be stored in one or more remote data repositories accessible to communications device 110 across the network, such as cloud-based repositories and repositories associated with the messaging platforms.
- FIG. 7 is a block diagram of computing devices 700 , 750 that may be used to implement the systems and methods described in this document, as either a client or as a server or plurality of servers.
- Computing device 700 is intended to represent various forms of digital computers, such as laptops, desktops, workstations, personal digital assistants, servers, blade servers, mainframes, and other appropriate computers (e.g., computing system 130 of FIG. 1 ).
- Computing device 750 is intended to represent various forms of mobile devices, such as personal digital assistants, cellular telephones, smartphones, and other similar computing devices (e.g., communications device 110 of FIG. 1 ).
- Additionally computing device 700 or 750 can include Universal Serial Bus (USB) flash drives.
- USB flash drives may store operating systems and other applications.
- the USB flash drives can include input/output components, such as a wireless transmitter or USB connector that may be inserted into a USB port of another computing device.
- input/output components such as a wireless transmitter or USB connector that may be inserted into a USB port of another computing device.
- Computing device 700 includes a processor 702 , memory 704 , a storage device 706 , a high-speed interface 708 connecting to memory 704 and high-speed expansion ports 710 , and a low speed interface 712 connecting to low speed bus 714 and storage device 706 .
- Each of the components 702 , 704 , 706 , 708 , 710 , and 712 are interconnected using various busses, and may be mounted on a common motherboard or in other manners as appropriate.
- the processor 702 can process instructions for execution within the computing device 700 , including instructions stored in the memory 704 or on the storage device 706 to display graphical information for a GUI on an external input/output device, such as display 716 coupled to high speed interface 708 .
- multiple processors and/or multiple buses may be used, as appropriate, along with multiple memories and types of memory.
- multiple computing devices 700 may be connected, with each device providing portions of the necessary operations (e.g., as a server bank, a group of blade servers, or a multi-processor system).
- the memory 704 stores information within the computing device 700 .
- the memory 704 is a volatile memory unit or units.
- the memory 704 is a non-volatile memory unit or units.
- the memory 704 may also be another form of computer-readable medium, such as a magnetic or optical disk.
- the storage device 706 is capable of providing mass storage for the computing device 700 .
- the storage device 706 may be or contain a computer-readable medium, such as a floppy disk device, a hard disk device, an optical disk device, or a tape device, a flash memory or other similar solid state memory device, or an array of devices, including devices in a storage area network or other configurations.
- a computer program product can be tangibly embodied in an information carrier.
- the computer program product may also contain instructions that, when executed, perform one or more methods, such as those described above.
- the information carrier is a computer- or machine-readable medium, such as the memory 704 , the storage device 706 , or memory on processor 702 .
- the high speed controller 708 manages bandwidth-intensive operations for the computing device 700 , while the low speed controller 712 manages lower bandwidth-intensive operations.
- the high-speed controller 708 is coupled to memory 704 , display 716 (e.g., through a graphics processor or accelerator), and to high-speed expansion ports 710 , which may accept various expansion cards (not shown).
- low-speed controller 712 is coupled to storage device 706 and low-speed expansion port 714 .
- the low-speed expansion port which may include various communication ports (e.g., USB, Bluetooth, Ethernet, wireless Ethernet) may be coupled to one or more input/output devices, such as a keyboard, a pointing device, microphone/speaker pair, a scanner, or a networking device such as a switch or router, e.g., through a network adapter.
- input/output devices such as a keyboard, a pointing device, microphone/speaker pair, a scanner, or a networking device such as a switch or router, e.g., through a network adapter.
- the computing device 700 may be implemented in a number of different forms, as shown in the figure. For example, it may be implemented as a standard server 720 , or multiple times in a group of such servers. It may also be implemented as part of a rack server system 524 . In addition, it may be implemented in a personal computer such as a laptop computer 722 .
- components from computing device 700 may be combined with other components in a mobile device (not shown), such as device 750 .
- a mobile device not shown
- Each of such devices may contain one or more of computing device 700 , 750 , and an entire system may be made up of multiple computing devices 700 , 750 communicating with each other.
- Computing device 750 includes a processor 752 , memory 764 , an input/output device such as a display 754 , a communication interface 766 , and a transceiver 768 , among other components.
- the device 750 may also be provided with a storage device, such as a microdrive or other device, to provide additional storage.
- a storage device such as a microdrive or other device, to provide additional storage.
- Each of the components 750 , 752 , 764 , 754 , 766 , and 768 are interconnected using various buses, and several of the components may be mounted on a common motherboard or in other manners as appropriate.
- the processor 752 can execute instructions within the computing device 750 , including instructions stored in the memory 764 .
- the processor may be implemented as a chipset of chips that include separate and multiple analog and digital processors. Additionally, the processor may be implemented using any of a number of architectures.
- the processor 702 may be a CISC (Complex Instruction Set Computers) processor, a RISC (Reduced Instruction Set Computer) processor, or a MISC (Minimal Instruction Set Computer) processor.
- the processor may provide, for example, for coordination of the other components of the device 750 , such as control of user interfaces, applications run by device 750 , and wireless communication by device 750 .
- Processor 752 may communicate with a user through control interface 758 and display interface 756 coupled to a display 754 .
- the display 754 may be, for example, a TFT (Thin-Film-Transistor Liquid Crystal Display) display or an OLED (Organic Light Emitting Diode) display, or other appropriate display technology.
- the display interface 756 may comprise appropriate circuitry for driving the display 754 to present graphical and other information to a user.
- the control interface 758 may receive commands from a user and convert them for submission to the processor 752 .
- an external interface 762 may be provide in communication with processor 752 , so as to enable near area communication of device 750 with other devices. External interface 762 may provide, for example, for wired communication in some implementations, or for wireless communication in other implementations, and multiple interfaces may also be used.
- the memory 764 stores information within the computing device 750 .
- the memory 764 can be implemented as one or more of a computer-readable medium or media, a volatile memory unit or units, or a non-volatile memory unit or units.
- Expansion memory 774 may also be provided and connected to device 750 through expansion interface 772 , which may include, for example, a SIMM (Single In Line Memory Module) card interface.
- SIMM Single In Line Memory Module
- expansion memory 774 may provide extra storage space for device 750 , or may also store applications or other information for device 750 .
- expansion memory 774 may include instructions to carry out or supplement the processes described above, and may include secure information also.
- expansion memory 774 may be provide as a security module for device 750 , and may be programmed with instructions that permit secure use of device 750 .
- secure applications may be provided via the SIMM cards, along with additional information, such as placing identifying information on the SIMM card in a non-hackable manner.
- the memory may include, for example, flash memory and/or NVRAM memory, as discussed below.
- a computer program product is tangibly embodied in an information carrier.
- the computer program product contains instructions that, when executed, perform one or more methods, such as those described above.
- the information carrier is a computer- or machine-readable medium, such as the memory 764 , expansion memory 774 , or memory on processor 752 that may be received, for example, over transceiver 768 or external interface 762 .
- Device 750 may communicate wirelessly through communication interface 766 , which may include digital signal processing circuitry where necessary. Communication interface 766 may provide for communications under various modes or protocols, such as GSM voice calls, SMS, EMS, or MMS messaging, CDMA, TDMA, PDC, WCDMA, CDMA2000, or GPRS, among others. Such communication may occur, for example, through radio-frequency transceiver 768 . In addition, short-range communication may occur, such as using a Bluetooth, WiFi, or other such transceiver (not shown). In addition, GPS (Global Positioning System) receiver module 770 may provide additional navigation- and location-related wireless data to device 750 , which may be used as appropriate by applications running on device 750 .
- GPS Global Positioning System
- Device 750 may also communicate audibly using audio codec 760 , which may receive spoken information from a user and convert it to usable digital information. Audio codec 760 may likewise generate audible sound for a user, such as through a speaker, e.g., in a handset of device 750 . Such sound may include sound from voice telephone calls, may include recorded sound (e.g., voice messages, music files, etc.) and may also include sound generated by applications operating on device 750 .
- Audio codec 760 may receive spoken information from a user and convert it to usable digital information. Audio codec 760 may likewise generate audible sound for a user, such as through a speaker, e.g., in a handset of device 750 . Such sound may include sound from voice telephone calls, may include recorded sound (e.g., voice messages, music files, etc.) and may also include sound generated by applications operating on device 750 .
- the computing device 750 may be implemented in a number of different forms, as shown in the figure. For example, it may be implemented as a cellular telephone 780 . It may also be implemented as part of a smartphone 782 , personal digital assistant, or other similar mobile device.
- the systems and/or methods discussed here may collect personal information about users, or may make use of personal information
- the users may be provided with an opportunity to control whether programs or features collect personal information, e.g., information about a user's social network, social actions or activities, profession, preferences, or current location, or to control whether and/or how the system and/or methods can perform operations more relevant to the user.
- certain data may be anonymized in one or more ways before it is stored or used, so that personally identifiable information is removed.
- a user's identity may be anonymized so that no personally identifiable information can be determined for the user, or a user's geographic location may be generalized where location information is obtained, such as to a city, ZIP code, or state level, so that a particular location of a user cannot be determined.
- location information such as to a city, ZIP code, or state level, so that a particular location of a user cannot be determined.
- the user may have control over how information is collected about him or her and used.
- Embodiments and all of the functional operations described in this specification may be implemented in digital electronic circuitry, or in computer software, firmware, or hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them.
- Embodiments may be implemented as one or more computer program products, i.e., one or more modules of computer program instructions encoded on a computer readable medium for execution by, or to control the operation of, data processing apparatus.
- the computer readable medium may be a machine-readable storage device, a machine-readable storage substrate, a memory device, a composition of matter effecting a machine-readable propagated signal, or a combination of one or more of them.
- data processing apparatus encompasses all apparatus, devices, and machines for processing data, including by way of example a programmable processor, a computer, or multiple processors or computers.
- the apparatus may include, in addition to hardware, code that creates an execution environment for the computer program in question, e.g., code that constitutes processor firmware, a protocol stack, a database management system, an operating system, or a combination of one or more of them.
- a propagated signal is an artificially generated signal, e.g., a machine-generated electrical, optical, or electromagnetic signal that is generated to encode information for transmission to suitable receiver apparatus.
- a computer program (also known as a program, software, software application, script, or code) may be written in any form of programming language, including compiled or interpreted languages, and it may be deployed in any form, including as a stand alone program or as a module, component, subroutine, or other unit suitable for use in a computing environment.
- a computer program does not necessarily correspond to a file in a file system.
- a program may be stored in a portion of a file that holds other programs or data (e.g., one or more scripts stored in a markup language document), in a single file dedicated to the program in question, or in multiple coordinated files (e.g., files that store one or more modules, sub programs, or portions of code).
- a computer program may be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network.
- the processes and logic flows described in this specification may be performed by one or more programmable processors executing one or more computer programs to perform functions by operating on input data and generating output.
- the processes and logic flows may also be performed by, and apparatus may also be implemented as, special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application specific integrated circuit).
- FPGA field programmable gate array
- ASIC application specific integrated circuit
- processors suitable for the execution of a computer program include, by way of example, both general and special purpose microprocessors, and any one or more processors of any kind of digital computer.
- a processor will receive instructions and data from a read only memory or a random access memory or both.
- the essential elements of a computer are a processor for performing instructions and one or more memory devices for storing instructions and data.
- a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto optical disks, or optical disks.
- mass storage devices for storing data, e.g., magnetic, magneto optical disks, or optical disks.
- a computer need not have such devices.
- a computer may be embedded in another device, e.g., a tablet computer, a mobile telephone, a personal digital assistant (PDA), a mobile audio player, a Global Positioning System (GPS) receiver, to name just a few.
- PDA personal digital assistant
- GPS Global Positioning System
- Computer readable media suitable for storing computer program instructions and data include all forms of non-volatile memory, media and memory devices, including by way of example semiconductor memory devices, e.g., EPROM, EEPROM, and flash memory devices; magnetic disks, e.g., internal hard disks or removable disks; magneto optical disks; and CD ROM and DVD-ROM disks.
- semiconductor memory devices e.g., EPROM, EEPROM, and flash memory devices
- magnetic disks e.g., internal hard disks or removable disks
- magneto optical disks e.g., CD ROM and DVD-ROM disks.
- the processor and the memory may be supplemented by, or incorporated in, special purpose logic circuitry.
- embodiments may be implemented on a computer having a display device, e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor, for displaying information to the user and a keyboard and a pointing device, e.g., a mouse or a trackball, by which the user may provide input to the computer.
- a display device e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor
- keyboard and a pointing device e.g., a mouse or a trackball
- Other kinds of devices may be used to provide for interaction with a user as well; for example, feedback provided to the user may be any form of sensory feedback, e.g., visual feedback, auditory feedback, or tactile feedback; and input from the user may be received in any form, including acoustic, speech, or tactile input.
- Embodiments may be implemented in a computing system that includes a back end component, e.g., as a data server, or that includes a middleware component, e.g., an application server, or that includes a front end component, e.g., a client computer having a graphical user interface or a Web browser through which a user may interact with an implementation, or any combination of one or more such back end, middleware, or front end components.
- the components of the system may be interconnected by any form or medium of digital data communication, e.g., a communication network. Examples of communication networks include a local area network (“LAN”) and a wide area network (“WAN”), e.g., the Internet.
- LAN local area network
- WAN wide area network
- the computing system may include clients and servers.
- a client and server are generally remote from each other and typically interact through a communication network.
- the relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other.
- HTML file In each instance where an HTML file is mentioned, other file types or formats may be substituted. For instance, an HTML file may be replaced by an XML, JSON, plain text, or other types of files. Moreover, where a table or hash table is mentioned, other data structures (such as spreadsheets, relational databases, or structured files) may be used.
Abstract
Description
Claims (23)
Priority Applications (6)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US15/156,567 US10795947B2 (en) | 2016-05-17 | 2016-05-17 | Unified message search |
CN201680084954.2A CN109074523A (en) | 2016-05-17 | 2016-12-30 | Unified message search |
PCT/US2016/069379 WO2017200595A1 (en) | 2016-05-17 | 2016-12-30 | Unified message search |
EP16828893.4A EP3423994B1 (en) | 2016-05-17 | 2016-12-30 | Unified message search |
US16/740,236 US11562036B2 (en) | 2016-05-17 | 2020-01-10 | Unified message search |
US18/100,486 US11947603B2 (en) | 2016-05-17 | 2023-01-23 | Unified message search |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US15/156,567 US10795947B2 (en) | 2016-05-17 | 2016-05-17 | Unified message search |
Related Child Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US16/740,236 Continuation US11562036B2 (en) | 2016-05-17 | 2020-01-10 | Unified message search |
Publications (2)
Publication Number | Publication Date |
---|---|
US20170337274A1 US20170337274A1 (en) | 2017-11-23 |
US10795947B2 true US10795947B2 (en) | 2020-10-06 |
Family
ID=57838544
Family Applications (3)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US15/156,567 Active 2038-09-20 US10795947B2 (en) | 2016-05-17 | 2016-05-17 | Unified message search |
US16/740,236 Active 2036-09-11 US11562036B2 (en) | 2016-05-17 | 2020-01-10 | Unified message search |
US18/100,486 Active US11947603B2 (en) | 2016-05-17 | 2023-01-23 | Unified message search |
Family Applications After (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US16/740,236 Active 2036-09-11 US11562036B2 (en) | 2016-05-17 | 2020-01-10 | Unified message search |
US18/100,486 Active US11947603B2 (en) | 2016-05-17 | 2023-01-23 | Unified message search |
Country Status (4)
Country | Link |
---|---|
US (3) | US10795947B2 (en) |
EP (1) | EP3423994B1 (en) |
CN (1) | CN109074523A (en) |
WO (1) | WO2017200595A1 (en) |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11562036B2 (en) | 2016-05-17 | 2023-01-24 | Google Llc | Unified message search |
Families Citing this family (23)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20150161087A1 (en) | 2013-12-09 | 2015-06-11 | Justin Khoo | System and method for dynamic imagery link synchronization and simulating rendering and behavior of content across a multi-client platform |
US20190220727A1 (en) * | 2018-01-17 | 2019-07-18 | SameDay Security, Inc. | Computing Devices with Improved Interactive Animated Conversational Interface Systems |
US10813572B2 (en) | 2015-12-11 | 2020-10-27 | Electronic Caregiver, Inc. | Intelligent system for multi-function electronic caregiving to facilitate advanced health diagnosis, health monitoring, fall and injury prediction, health maintenance and support, and emergency response |
US11240189B2 (en) * | 2016-10-14 | 2022-02-01 | International Business Machines Corporation | Biometric-based sentiment management in a social networking environment |
US10282402B2 (en) | 2017-01-06 | 2019-05-07 | Justin Khoo | System and method of proofing email content |
USD838740S1 (en) * | 2017-03-06 | 2019-01-22 | United Services Automobile Association (Usaa) | Portion of a display panel with an animated graphical user interface |
USD838741S1 (en) * | 2017-03-06 | 2019-01-22 | United Services Automobile Association (Usaa) | Portion of a display panel with an animated graphical user interface |
US10516637B2 (en) * | 2017-10-17 | 2019-12-24 | Microsoft Technology Licensing, Llc | Smart communications assistant with audio interface |
US20190206385A1 (en) * | 2017-12-29 | 2019-07-04 | Knowmail S.A.L LTD. | Vocal representation of communication messages |
US11213224B2 (en) | 2018-03-19 | 2022-01-04 | Electronic Caregiver, Inc. | Consumer application for mobile assessment of functional capacity and falls risk |
US11102316B1 (en) | 2018-03-21 | 2021-08-24 | Justin Khoo | System and method for tracking interactions in an email |
US11923058B2 (en) | 2018-04-10 | 2024-03-05 | Electronic Caregiver, Inc. | Mobile system for the assessment of consumer medication compliance and provision of mobile caregiving |
US11488724B2 (en) | 2018-06-18 | 2022-11-01 | Electronic Caregiver, Inc. | Systems and methods for a virtual, intelligent and customizable personal medical assistant |
US10817317B2 (en) * | 2019-01-24 | 2020-10-27 | Snap Inc. | Interactive informational interface |
EP3920797A4 (en) | 2019-02-05 | 2022-11-02 | Electronic Caregiver, Inc. | 3d environment risks identification utilizing reinforced learning |
US11113943B2 (en) | 2019-05-07 | 2021-09-07 | Electronic Caregiver, Inc. | Systems and methods for predictive environmental fall risk identification |
CN112148349B (en) * | 2020-07-03 | 2024-03-15 | 上海金融期货信息技术有限公司 | Cross-platform instruction and system for configuring unified interface |
USD959461S1 (en) * | 2020-07-15 | 2022-08-02 | Vyaire Medical, Inc. | Computing device with graphical user interface for communicating health-related messages regarding ventilated patients |
USD959464S1 (en) * | 2020-07-15 | 2022-08-02 | Vyaire Medical, Inc. | Computing device with graphical user interface for communicating health-related messages regarding ventilated patients |
US11088980B1 (en) * | 2020-11-10 | 2021-08-10 | Micron Technology, Inc. | Single message management platform |
CN112764628B (en) * | 2021-01-28 | 2022-07-19 | 维沃移动通信有限公司 | Content display method, content display device, electronic equipment and storage medium |
CN112800084A (en) * | 2021-02-24 | 2021-05-14 | 北京小米移动软件有限公司 | Data processing method and device |
US11316818B1 (en) * | 2021-08-26 | 2022-04-26 | International Business Machines Corporation | Context-based consolidation of communications across different communication platforms |
Citations (28)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6044260A (en) * | 1997-09-02 | 2000-03-28 | Motorola, Inc. | Method of controlling the number of messages received by a personal messaging unit |
US20040025663A1 (en) * | 2002-08-07 | 2004-02-12 | Minoru Harada | Electronic percussion system and electronic percussion instrument incorporated therein |
US20050076109A1 (en) * | 2003-07-11 | 2005-04-07 | Boban Mathew | Multimedia notification system and method |
US20060031340A1 (en) * | 2004-07-12 | 2006-02-09 | Boban Mathew | Apparatus and method for advanced attachment filtering within an integrated messaging platform |
EP1647906A2 (en) | 2004-10-18 | 2006-04-19 | Microsoft Corporation | Semantic thumbnails |
US20070011258A1 (en) | 2002-09-18 | 2007-01-11 | Advenix, Corp. (Ca Corporation) | Enhancement of e-mail client user interfaces and e-mail message formats |
US20070174388A1 (en) | 2006-01-20 | 2007-07-26 | Williams Michael G | Integrated voice mail and email system |
US7296241B2 (en) | 2002-10-18 | 2007-11-13 | Microsoft Corporation | System and method for managing a message view |
US20080239955A1 (en) * | 2007-03-26 | 2008-10-02 | Cisco Technology, Inc. | Adaptive cross-network message bandwidth allocation by message servers |
US7460874B1 (en) * | 2005-08-12 | 2008-12-02 | Sprint Spectrum L.P. | Method for monitoring performance of a message-delivery system |
US20090106366A1 (en) | 2007-10-17 | 2009-04-23 | Nokia Corporation | System and method for visualizing threaded communication across multiple communication channels using a mobile web server |
US20090209286A1 (en) | 2008-02-19 | 2009-08-20 | Motorola, Inc. | Aggregated view of local and remote social information |
US20100159883A1 (en) * | 2008-12-23 | 2010-06-24 | At&T Mobility Ii Llc | Message content management system |
US20110053565A1 (en) | 2009-08-26 | 2011-03-03 | Telefonaktiebolaget Lm Ericsson (Publ) | System and method for delivering a message digest |
US20110078247A1 (en) | 2009-09-25 | 2011-03-31 | At&T Intellectual Property I, L.P. | System and Method for Message Recall in a Unified Messaging System |
US20110209196A1 (en) | 2010-02-22 | 2011-08-25 | Avaya Inc. | Flexible security requirements in an enterprise network |
US8239461B2 (en) | 2007-06-28 | 2012-08-07 | Chacha Search, Inc. | Method and system for accessing search services via messaging services |
US20130238651A1 (en) | 2012-03-09 | 2013-09-12 | Joseph Eytan Benedek | Message search method and electronic device |
US20140067401A1 (en) * | 2011-06-29 | 2014-03-06 | Manvi Sanjeeva | Provide services using unified communication content |
US20140164507A1 (en) * | 2012-12-10 | 2014-06-12 | Rawllin International Inc. | Media content portions recommended |
US20150057997A1 (en) | 2011-12-21 | 2015-02-26 | Nuance Communications, Inc. | Concept search and semantic annotation for mobile messaging |
US20150186538A1 (en) | 2013-12-31 | 2015-07-02 | Abbyy Development Llc | Method and System for Cross-Platform Searching of Multiple Information Sources and Devices |
US20150193457A1 (en) | 2014-01-08 | 2015-07-09 | International Business Machines Corporation | Integrating and searching electronic communications received from a plurality of different communication platforms |
US20150312193A1 (en) * | 2012-11-30 | 2015-10-29 | Conversepoint Llc | Systems and methods for accumulating messages in a messaging conversation |
US20160034977A1 (en) * | 2014-08-01 | 2016-02-04 | Yahoo! Inc. | System and method for embedded search within messaging applications |
US20170286429A1 (en) * | 2013-01-02 | 2017-10-05 | Microsoft Technology Licensing, Llc | Computer System for Automated Assessment at Scale of Topic-Specific Social Media Impact |
US9838542B1 (en) * | 2007-03-26 | 2017-12-05 | Callwave Communications, Llc | Methods and systems for managing communications |
US20190155871A1 (en) * | 2015-05-22 | 2019-05-23 | Microsoft Technology Licensing, Llc | Unified messaging platform and interface for providing inline replies |
Family Cites Families (24)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5493692A (en) * | 1993-12-03 | 1996-02-20 | Xerox Corporation | Selective delivery of electronic messages in a multiple computer system based on context and environment of a user |
CA2139081C (en) * | 1994-12-23 | 1999-02-02 | Alastair Gordon | Unified messaging system and method |
US6260039B1 (en) * | 1997-12-15 | 2001-07-10 | International Business Machines Corporation | Web interface and method for accessing directory information |
US6208986B1 (en) * | 1997-12-15 | 2001-03-27 | International Business Machines Corporation | Web interface and method for accessing and displaying directory information |
US7130885B2 (en) * | 2000-09-05 | 2006-10-31 | Zaplet, Inc. | Methods and apparatus providing electronic messages that are linked and aggregated |
US7194516B2 (en) * | 2003-10-23 | 2007-03-20 | Microsoft Corporation | Accessing different types of electronic messages through a common messaging interface |
US7155466B2 (en) * | 2003-10-27 | 2006-12-26 | Archivas, Inc. | Policy-based management of a redundant array of independent nodes |
US9819624B2 (en) * | 2004-03-31 | 2017-11-14 | Google Inc. | Displaying conversations in a conversation-based email system |
US7912904B2 (en) * | 2004-03-31 | 2011-03-22 | Google Inc. | Email system with conversation-centric user interface |
US7870200B2 (en) * | 2004-05-29 | 2011-01-11 | Ironport Systems, Inc. | Monitoring the flow of messages received at a server |
US8503624B2 (en) * | 2005-09-28 | 2013-08-06 | Cisco Technology, Inc. | Method and apparatus to process an incoming message |
US8170189B2 (en) * | 2005-11-02 | 2012-05-01 | Qwest Communications International Inc. | Cross-platform message notification |
US8107977B2 (en) * | 2007-09-07 | 2012-01-31 | United Video Properties, Inc. | Cross-platform messaging |
US9111538B2 (en) * | 2009-09-30 | 2015-08-18 | T-Mobile Usa, Inc. | Genius button secondary commands |
US9438554B2 (en) * | 2012-03-08 | 2016-09-06 | Citrix Systems, Inc. | Cross platform messaging |
US9578060B1 (en) * | 2012-06-11 | 2017-02-21 | Dell Software Inc. | System and method for data loss prevention across heterogeneous communications platforms |
KR102114201B1 (en) * | 2014-04-29 | 2020-05-25 | 삼성전자주식회사 | Electronic devic and method for processing message in electronic device |
US9940393B2 (en) * | 2015-06-03 | 2018-04-10 | International Business Machines Corporation | Electronic personal assistant privacy |
US9559997B1 (en) * | 2016-01-11 | 2017-01-31 | Paul Everton | Client agnostic email processing |
US9824332B1 (en) * | 2017-04-12 | 2017-11-21 | eTorch Inc. | Email data collection compliance enforcement |
US10893009B2 (en) * | 2017-02-16 | 2021-01-12 | eTorch Inc. | Email fraud prevention |
US10979393B2 (en) * | 2016-01-11 | 2021-04-13 | Mimecast North America, Inc. | Identity-based messaging security |
US10795947B2 (en) | 2016-05-17 | 2020-10-06 | Google Llc | Unified message search |
US10509531B2 (en) * | 2017-02-20 | 2019-12-17 | Google Llc | Grouping and summarization of messages based on topics |
-
2016
- 2016-05-17 US US15/156,567 patent/US10795947B2/en active Active
- 2016-12-30 CN CN201680084954.2A patent/CN109074523A/en active Pending
- 2016-12-30 WO PCT/US2016/069379 patent/WO2017200595A1/en active Application Filing
- 2016-12-30 EP EP16828893.4A patent/EP3423994B1/en active Active
-
2020
- 2020-01-10 US US16/740,236 patent/US11562036B2/en active Active
-
2023
- 2023-01-23 US US18/100,486 patent/US11947603B2/en active Active
Patent Citations (33)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6044260A (en) * | 1997-09-02 | 2000-03-28 | Motorola, Inc. | Method of controlling the number of messages received by a personal messaging unit |
US20040025663A1 (en) * | 2002-08-07 | 2004-02-12 | Minoru Harada | Electronic percussion system and electronic percussion instrument incorporated therein |
US20070011258A1 (en) | 2002-09-18 | 2007-01-11 | Advenix, Corp. (Ca Corporation) | Enhancement of e-mail client user interfaces and e-mail message formats |
US7296241B2 (en) | 2002-10-18 | 2007-11-13 | Microsoft Corporation | System and method for managing a message view |
US20050076109A1 (en) * | 2003-07-11 | 2005-04-07 | Boban Mathew | Multimedia notification system and method |
US20050108341A1 (en) * | 2003-07-11 | 2005-05-19 | Boban Mathew | Apparatus and method for double-blind instant messaging |
US20050114462A1 (en) * | 2003-07-11 | 2005-05-26 | Boban Mathew | Apparatus and method for meta-document creation and processing |
US20050114456A1 (en) * | 2003-07-11 | 2005-05-26 | Boban Mathew | Apparatus and method for advanced contacts management within an integrated message/document management system |
US20050172033A1 (en) * | 2003-07-11 | 2005-08-04 | Boban Mathew | Apparatus and method for multi-layer rule application within an integrated messaging platform |
US20060031340A1 (en) * | 2004-07-12 | 2006-02-09 | Boban Mathew | Apparatus and method for advanced attachment filtering within an integrated messaging platform |
EP1647906A2 (en) | 2004-10-18 | 2006-04-19 | Microsoft Corporation | Semantic thumbnails |
US7460874B1 (en) * | 2005-08-12 | 2008-12-02 | Sprint Spectrum L.P. | Method for monitoring performance of a message-delivery system |
US20070174388A1 (en) | 2006-01-20 | 2007-07-26 | Williams Michael G | Integrated voice mail and email system |
US20080239955A1 (en) * | 2007-03-26 | 2008-10-02 | Cisco Technology, Inc. | Adaptive cross-network message bandwidth allocation by message servers |
US9838542B1 (en) * | 2007-03-26 | 2017-12-05 | Callwave Communications, Llc | Methods and systems for managing communications |
US8239461B2 (en) | 2007-06-28 | 2012-08-07 | Chacha Search, Inc. | Method and system for accessing search services via messaging services |
US20090106366A1 (en) | 2007-10-17 | 2009-04-23 | Nokia Corporation | System and method for visualizing threaded communication across multiple communication channels using a mobile web server |
US20090209286A1 (en) | 2008-02-19 | 2009-08-20 | Motorola, Inc. | Aggregated view of local and remote social information |
US20100159883A1 (en) * | 2008-12-23 | 2010-06-24 | At&T Mobility Ii Llc | Message content management system |
US8566403B2 (en) * | 2008-12-23 | 2013-10-22 | At&T Mobility Ii Llc | Message content management system |
US20110053565A1 (en) | 2009-08-26 | 2011-03-03 | Telefonaktiebolaget Lm Ericsson (Publ) | System and method for delivering a message digest |
US20110078247A1 (en) | 2009-09-25 | 2011-03-31 | At&T Intellectual Property I, L.P. | System and Method for Message Recall in a Unified Messaging System |
US20110209196A1 (en) | 2010-02-22 | 2011-08-25 | Avaya Inc. | Flexible security requirements in an enterprise network |
US20140067401A1 (en) * | 2011-06-29 | 2014-03-06 | Manvi Sanjeeva | Provide services using unified communication content |
US20150057997A1 (en) | 2011-12-21 | 2015-02-26 | Nuance Communications, Inc. | Concept search and semantic annotation for mobile messaging |
US20130238651A1 (en) | 2012-03-09 | 2013-09-12 | Joseph Eytan Benedek | Message search method and electronic device |
US20150312193A1 (en) * | 2012-11-30 | 2015-10-29 | Conversepoint Llc | Systems and methods for accumulating messages in a messaging conversation |
US20140164507A1 (en) * | 2012-12-10 | 2014-06-12 | Rawllin International Inc. | Media content portions recommended |
US20170286429A1 (en) * | 2013-01-02 | 2017-10-05 | Microsoft Technology Licensing, Llc | Computer System for Automated Assessment at Scale of Topic-Specific Social Media Impact |
US20150186538A1 (en) | 2013-12-31 | 2015-07-02 | Abbyy Development Llc | Method and System for Cross-Platform Searching of Multiple Information Sources and Devices |
US20150193457A1 (en) | 2014-01-08 | 2015-07-09 | International Business Machines Corporation | Integrating and searching electronic communications received from a plurality of different communication platforms |
US20160034977A1 (en) * | 2014-08-01 | 2016-02-04 | Yahoo! Inc. | System and method for embedded search within messaging applications |
US20190155871A1 (en) * | 2015-05-22 | 2019-05-23 | Microsoft Technology Licensing, Llc | Unified messaging platform and interface for providing inline replies |
Non-Patent Citations (7)
Title |
---|
"How to Use Spotlight Search on Your iPhone or iPad," How-To Geek, publically available before May 17, 2016 [retrieved on May 20, 2016]. Retrieved from the Internet: URL<http://www.howtogeek.com/229060/how-to-use-spotlight-search-on-your-iphone-or-ipad/>, 4 pages. |
El Khoury, "PSA: Google Now Can Read Your Last Five Text Messages Like An Answering Machine And Let You Reply To Them," Android Police, Dec. 2, 2015 [retrieved on May 20, 2016]. Retrieved from the Internet: URL<http://www.androidpolice.com/2015/12/02/psa-google-now-can-read-your-last-five-text-messages-like-an-answering-machine-and-let-you-reply-to-them/>, 5 pages. |
European Patent Office; Examination Report issued in Application No. EP16828893.4; 7 pages; dated Aug. 7, 2020. |
International Preliminary Report on Patentability issued in International Application No. PCT/US2016/069379, dated Nov. 29, 2018, 7 pages. |
International Search Report and Written Opinion in International Application No. PCT/US2016/069379, dated Mar. 20, 2017, 13 pages. |
Miera, "The ultimate guide to Google Now cards," Android Central, Sep. 5, 2014 [retrieved on May 20, 2016]. Retrieved from the Internet: URL<http://www.androidcentral.com/ultimate-guide-google-now-cards>, 38 pages. |
Rittmeyer, "Android Tutorial: Adding Search to Your Apps," Grokking Android, Jul. 6, 2012 [retrieved on May 20, 2016]. Retrieved from the Internet: URL <http://www.grokkingandroid.com/android-tutorial-adding-search-to-your-apps/>, 15 pages. |
Cited By (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11562036B2 (en) | 2016-05-17 | 2023-01-24 | Google Llc | Unified message search |
US20230237104A1 (en) * | 2016-05-17 | 2023-07-27 | Google Llc | Unified message search |
US11947603B2 (en) * | 2016-05-17 | 2024-04-02 | Google Llc | Unified message search |
Also Published As
Publication number | Publication date |
---|---|
CN109074523A (en) | 2018-12-21 |
US20170337274A1 (en) | 2017-11-23 |
WO2017200595A1 (en) | 2017-11-23 |
EP3423994B1 (en) | 2023-12-27 |
EP3423994A1 (en) | 2019-01-09 |
US20230237104A1 (en) | 2023-07-27 |
US11562036B2 (en) | 2023-01-24 |
US20200151223A1 (en) | 2020-05-14 |
US11947603B2 (en) | 2024-04-02 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US11947603B2 (en) | Unified message search | |
US11379529B2 (en) | Composing rich content messages | |
US9990925B2 (en) | Privacy-preserving training corpus selection | |
US10558701B2 (en) | Method and system to recommend images in a social application | |
US20120201362A1 (en) | Posting to social networks by voice | |
US11334182B2 (en) | Selection biasing | |
US11321675B2 (en) | Cognitive scribe and meeting moderator assistant | |
US20150066935A1 (en) | Crowdsourcing and consolidating user notes taken in a virtual meeting | |
US11423113B2 (en) | Contextual deep bookmarking | |
CN113111658A (en) | Method, device, equipment and storage medium for checking information | |
US10296510B2 (en) | Search query based form populator | |
US11973734B2 (en) | Processing electronic communications according to recipient points of view |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:LY, VINH QUOC;TEKDAS, AHMET ONUR;MERTENS, TIMO;AND OTHERS;SIGNING DATES FROM 20160607 TO 20160610;REEL/FRAME:038892/0355 |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044567/0001Effective date: 20170929 |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: RESPONSE TO NON-FINAL OFFICE ACTION ENTERED AND FORWARDED TO EXAMINER |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: FINAL REJECTION MAILED |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: DOCKETED NEW CASE - READY FOR EXAMINATION |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: NON FINAL ACTION MAILED |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: RESPONSE TO NON-FINAL OFFICE ACTION ENTERED AND FORWARDED TO EXAMINER |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: NOTICE OF ALLOWANCE MAILED -- APPLICATION RECEIVED IN OFFICE OF PUBLICATIONS |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: PUBLICATIONS -- ISSUE FEE PAYMENT RECEIVED |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: PUBLICATIONS -- ISSUE FEE PAYMENT VERIFIED |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: PUBLICATIONS -- ISSUE FEE PAYMENT VERIFIED |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: AWAITING TC RESP., ISSUE FEE NOT PAID |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: PUBLICATIONS -- ISSUE FEE PAYMENT VERIFIED |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 4TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1551); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 4 |