JP2022529803A - Prediction of expected waiting time for business-agnostic contact centers using deep neural networks - Google Patents
Prediction of expected waiting time for business-agnostic contact centers using deep neural networks Download PDFInfo
- Publication number
- JP2022529803A JP2022529803A JP2021562800A JP2021562800A JP2022529803A JP 2022529803 A JP2022529803 A JP 2022529803A JP 2021562800 A JP2021562800 A JP 2021562800A JP 2021562800 A JP2021562800 A JP 2021562800A JP 2022529803 A JP2022529803 A JP 2022529803A
- Authority
- JP
- Japan
- Prior art keywords
- support request
- support
- waiting time
- pending
- request
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Withdrawn
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q10/00—Administration; Management
- G06Q10/04—Forecasting or optimisation specially adapted for administrative or management purposes, e.g. linear programming or "cutting stock problem"
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q10/00—Administration; Management
- G06Q10/06—Resources, workflows, human or project management; Enterprise or organisation planning; Enterprise or organisation modelling
- G06Q10/063—Operations research, analysis or management
- G06Q10/0631—Resource planning, allocation, distributing or scheduling for enterprises or organisations
- G06Q10/06311—Scheduling, planning or task assignment for a person or group
- G06Q10/063114—Status monitoring or status determination for a person or group
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q10/00—Administration; Management
- G06Q10/06—Resources, workflows, human or project management; Enterprise or organisation planning; Enterprise or organisation modelling
- G06Q10/063—Operations research, analysis or management
- G06Q10/0633—Workflow analysis
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q30/00—Commerce
- G06Q30/01—Customer relationship services
- G06Q30/015—Providing customer assistance, e.g. assisting a customer within a business location or via helpdesk
- G06Q30/016—After-sales
Abstract
推定待ち時間（１３０）を予測する方法（８００）は、ユーザ（１０）から保留中サポート要求（１２０）を受け取る工程を備える。保留中サポート要求は、アクティブなサポートエージェントの数（２０２ａ）と、利用可能なサポートエージェントの数（２０２ｂ）と、およびキュー深さ（２０２ｃ）とを備える複数の高レベル特徴（２０２）に関連付けられる。本方法はまた、複数の高レベル特徴を特徴入力として受け取る待ち時間予測モデル（２７０）を用いて、保留中サポート要求のユーザに対する推定待ち時間（１３０）を予測する工程を備える。待ち時間予測モデルは、対応する高レベル特徴と、対応する実際の待ち時間（２０２ｇ）とを備える学習サポート要求（１２０Ｈ）のコーパスで学習される。本方法はさらに、保留中サポート要求に回答するまでの推定持続時間を示す推定待ち時間をユーザに提供する工程も備える。The method (800) for predicting the estimated waiting time (130) comprises the step of receiving a pending support request (120) from the user (10). A pending support request is associated with a number of high-level features (202) with the number of active support agents (202a), the number of available support agents (202b), and the queue depth (202c). .. The method also comprises a step of predicting an estimated wait time (130) for a user with a pending support request using a wait time prediction model (270) that receives a plurality of high level features as feature inputs. The latency prediction model is trained on a corpus of learning support requests (120H) with corresponding high-level features and corresponding actual latency (202g). The method further comprises a step of providing the user with an estimated waiting time indicating an estimated duration before responding to a pending support request.
Description
本開示は、ユーザからのサポート要求に対する予想待ち時間を予測することに関する。 The present disclosure relates to predicting expected latency for support requests from users.
多くのビジネス（事業者）は、事業者が提供する商品またはサービスに対する顧客サポートを提供するべく、かなりの量のリソースを投資している。事業者は、少なくとも部分的には、高度な顧客満足度を向上または提供するべく、これらのリソースを投資する。 Many businesses (operators) invest a significant amount of resources to provide customer support for the goods or services they offer. Operators invest these resources, at least in part, to improve or provide a high degree of customer satisfaction.
顧客と顧客サポートとのやり取りは、顧客の満足度に強く影響すると考えられる。具体的には、顧客と顧客サポートエージェントとの間の接続を事業者が確立するまで顧客が実際にどのくらい待つかに比較して、顧客がどのくらい待つと事業者が見積もっているかが、顧客満足度に強く影響する可能性がある。 Interactions between customers and customer support are likely to have a strong impact on customer satisfaction. Specifically, customer satisfaction is how long the operator estimates that the customer will wait, compared to how long the customer actually waits for the operator to establish a connection between the customer and the customer support agent. May have a strong effect on.
本開示の一態様は、ユーザサポート要求に対する推定待ち時間を予測する方法を提供する。本方法は、データ処理ハードウェアにおいて、ユーザから保留中（ペンディング）サポート要求を受け取る工程を備えている。保留中サポート要求は、アクティブなサポートエージェントの数を備えている複数の高レベル特徴に関連付けられる。各アクティブなサポートエージェントは、キュー（ｑｕｅｕｅ。待ち行列）に入ったサポート要求の処理において現在アクティブである。また、高レベル特徴は、利用可能（ａｖａｉｌａｂｌｅ）なサポートエージェントの数を備えており、各利用可能なサポートエージェントは、キューイングされたサポート要求を処理するべく現在利用可能である。また、高レベル特徴は、処理されるのを待っているサポート要求の数を示すキュー深さを備えている。本方法はさらに、データ処理ハードウェアによって、複数の高レベル特徴を特徴入力として受け取るように構成された待ち時間予測モデルを使用して、保留中サポート要求のユーザに対する推定待ち時間を予測する工程を備えている。待ち時間予測モデルは、学習サポート要求のコーパスで学習される。各学習サポート要求は、対応する複数の高レベル特徴と、対応する実際の待ち時間とを備えている。本方法はまた、データ処理ハードウェアによって、推定待ち時間をユーザに提供する工程を備えている。推定待ち時間は、保留中サポート要求に回答するまでの推定持続（継続）時間を示す。 One aspect of the present disclosure provides a method of predicting an estimated latency for a user support request. The method comprises the process of receiving a pending support request from a user in data processing hardware. A pending support request is associated with multiple high-level features that have a number of active support agents. Each active support agent is currently active in processing queued support requests. Also, the high-level feature features a number of available support agents, each available support agent currently available to handle queued support requests. High-level features also have a queue depth that indicates the number of support requests waiting to be processed. The method further involves predicting the estimated latency for a user of a pending support request using a latency prediction model configured by the data processing hardware to receive multiple high-level features as feature inputs. I have. The latency prediction model is trained in a corpus of learning support requests. Each learning support request has a corresponding high-level feature and a corresponding actual latency. The method also comprises a step of providing the user with an estimated latency by means of data processing hardware. The estimated wait time indicates the estimated duration until the pending support request is answered.
本開示の実装は、以下の任意の特徴のうちの１つまたは複数を備えていることができる。いくつかの実装では、保留中サポート要求に関連付けられた複数の高レベル特徴はさらに、以前に回答されたサポート要求の実際の待ち時間と、保留中サポート要求に関連付けられたビジネス（事業者）の識別と、またはビジネス（事業者）に関連付けられたビジネスキューの識別と、のうちの少なくとも１つを備えている。複数の高レベル特徴はさらに、いくつかの例では、保留中サポート要求が受け取られた時間帯を示す時間帯表示と、または、それぞれのビジネス識別およびそれぞれのキュー識別に関連付けられたサポートエージェントが、対応するサポート要求を完了するのにかかる平均時間量を代表する平均解決時間と、のうちの少なくとも１つを備えている。 Implementations of the present disclosure may include one or more of any of the following features: In some implementations, multiple high-level features associated with pending support requests are also the actual latency of previously answered support requests and the business (operator) associated with the pending support request. It comprises at least one of identification and identification of a business queue associated with a business (operator). Multiple high-level features also include, in some cases, a time zone display that indicates when a pending support request was received, or a support agent associated with each business identification and each queue identification. It has at least one of an average resolution time representing the average amount of time it takes to complete the corresponding support request.
任意で、学習サポート要求のコーパス内の各学習サポート要求は、データ処理ハードウェアによって以前に処理された複数の履歴（ヒストリカル）サポート要求を備えている。待ち時間予測モデルは、いくつかの実装において、対応する複数の高レベル特徴と、構成可能な頻度に亘る履歴サポート要求のそれぞれに対する対応する実際の待ち時間とを用いて、構成可能な頻度（ｃｏｎｆｉｇｕｒａｂｌｅｆｒｅｑｕｅｎｃｙ）で学習される。構成可能な頻度は、１日１回を備えてもよい。 Optionally, each learning support request in the learning support request corpus has multiple historical support requests previously processed by the data processing hardware. The latency prediction model, in some implementations, uses the corresponding high-level features and the corresponding actual latency for each of the history support requests over a configurable frequency. ) To be learned. The configurable frequency may include once a day.
いくつかの例では、本方法はさらに、保留中サポート要求に回答した後に、データ処理ハードウェアによって、ユーザに対する実際の待ち時間を決定する工程を備えている。実際の待ち時間は、保留中サポート要求が受け取られたときから、ユーザが保留中サポート要求に対する回答を受け取るまでの実際の持続時間を示す。本方法はさらに、データ処理ハードウェアによって、保留中サポート要求に対する実際の待ち時間を使用して、待ち時間予測モデルを調整（チューニング）する工程も備えている。また、本方法はさらに、データ処理ハードウェアによって、待ち時間予測モデルによって予測された推定待ち時間と、実際の待ち時間とに基づき、待ち時間予測モデルの損失を決定する工程と、データ処理ハードウェアによって、損失が、以前に学習されたモデルの損失と比較して閾値を満たすかどうかを判定する工程と、データ処理ハードウェアによって、損失が閾値を満たす場合に、以前に学習されたモデルに戻す工程と、を備えていることができる。 In some examples, the method further comprises the step of determining the actual wait time for the user by the data processing hardware after answering the pending support request. The actual wait time indicates the actual duration from when the pending support request is received until the user receives a response to the pending support request. The method also comprises the process of tuning the latency prediction model using the actual latency for pending support requests by the data processing hardware. In addition, the method further includes a process of determining the loss of the latency prediction model based on the estimated latency predicted by the latency prediction model and the actual latency by the data processing hardware, and the data processing hardware. To determine if the loss meets the threshold compared to the loss of the previously trained model, and to revert to the previously trained model if the loss meets the threshold by the data processing hardware. It can be equipped with a process.
いくつかの実装では、損失を決定する工程は、平均二乗誤差を使用する工程を備えている。任意で、待ち時間予測モデルは、ニューラルネットワークを備えている。ニューラルネットワークは、回帰深層ニューラルネットワークを備えてもよい。また、ニューラルネットワークは、第１隠れ層および第２隠れ層を有する深層ニューラルネットワークを備えてもよい。 In some implementations, the process of determining loss comprises the process of using mean square error. Optionally, the latency prediction model comprises a neural network. The neural network may include a regression deep neural network. Further, the neural network may include a deep neural network having a first hidden layer and a second hidden layer.
本開示の別の態様は、ユーザサポート要求に対する推定待ち時間を予測するシステムを提供する。システムは、データ処理ハードウェアと、データ処理ハードウェアに通信するメモリハードウェアとを備えている。メモリハードウェアは、データ処理ハードウェア上で実行されると、データ処理ハードウェアに動作（オペレーションズ）を実行させる命令を格納する。動作は、ユーザから保留中サポート要求を受け取る工程を備えている。保留中サポート要求は、アクティブなサポートエージェントの数を備えている複数の高レベル特徴に関連付けられている。各アクティブなサポートエージェントは、キューイングされたサポート要求の処理において現在アクティブである。また複数の高レベル特徴には、利用可能なサポートエージェントの数も含まれ、各利用可能なサポートエージェントは、キューに入ったサポート要求を処理するべく現在利用可能である。また、複数の高レベル特徴はさらに、処理されるのを待っているサポート要求の数を示すキュー深さを備えている。動作はさらに、複数の高レベル特徴を特徴入力として受け取るように構成された待ち時間予測モデルを使用して、保留中サポート要求のユーザに対する推定待ち時間を予測する工程を備えている。待ち時間予測モデルは、学習サポート要求のコーパスで学習される。各学習サポート要求は、対応する複数の高レベル特徴と、対応する実際の待ち時間とを備えている。また、動作はさらに、推定待ち時間をユーザに提供する工程を備えている。推定待ち時間は、保留中サポート要求に回答するまでの推定持続時間を示す。 Another aspect of the present disclosure provides a system for predicting an estimated latency for a user support request. The system comprises data processing hardware and memory hardware that communicates with the data processing hardware. When executed on the data processing hardware, the memory hardware stores an instruction to cause the data processing hardware to execute an operation (operations). The operation comprises the process of receiving a pending support request from the user. A pending support request is associated with multiple high-level features with a number of active support agents. Each active support agent is currently active in processing queued support requests. Several high-level features also include the number of support agents available, and each available support agent is currently available to handle queued support requests. In addition, several high-level features also have a queue depth that indicates the number of support requests waiting to be processed. The operation further comprises predicting the estimated latency for the user of the pending support request using a latency prediction model configured to receive multiple high-level features as feature inputs. The latency prediction model is trained in a corpus of learning support requests. Each learning support request has a corresponding high-level feature and a corresponding actual latency. The operation also comprises a step of providing the user with an estimated waiting time. Estimated wait time indicates the estimated duration before responding to a pending support request.
この態様は、以下の任意の特徴のうちの１つまたは複数を備えてもよい。いくつかの実施例では、保留中サポート要求に関連付けられた複数の高レベル特徴はさらに、以前に回答されたサポート要求に対する実際の待ち時間と、保留中サポート要求に関連付けられたビジネス（事業者）の識別と、またはビジネス（事業者）に関連付けられたビジネスキューの識別と、のうちの少なくとも１つを備えている。複数の高レベル特徴はさらに、いくつかの例では、保留中サポート要求が受け取られた時間帯を示す時間帯表示と、または、それぞれのビジネス識別およびそれぞれのキュー識別に関連付けられたサポートエージェントが、対応するサポート要求を完了するのにかかる平均時間量を代表する平均解決時間と、のうちの少なくとも１つを備えている。 This aspect may include one or more of any of the following features: In some embodiments, the multiple high-level features associated with the pending support request further include the actual wait time for the previously answered support request and the business (operator) associated with the pending support request. It comprises at least one of the identification of, or the identification of the business queue associated with the business (business). Multiple high-level features also include, in some cases, a time zone display that indicates when a pending support request was received, or a support agent associated with each business identification and each queue identification. It has at least one of an average resolution time representing the average amount of time it takes to complete the corresponding support request.
任意で、学習サポート要求のコーパス内の各学習サポート要求は、データ処理ハードウェアによって以前に処理された複数の履歴サポート要求を備えている。待ち時間予測モデルは、いくつかの実装において、対応する複数の高レベル特徴と、構成可能な頻度に亘る履歴サポート要求のそれぞれに対する対応する実際の待ち時間とを用いて、構成可能な頻度で学習される。構成可能な頻度は、１日１回を備えてもよい。 Optionally, each learning support request in the learning support request corpus comprises multiple historical support requests previously processed by the data processing hardware. The latency prediction model is trained at a configurable frequency in some implementations, using the corresponding high-level features and the corresponding actual latency for each of the configurable frequency of historical support requests. Will be done. The configurable frequency may include once a day.
いくつかの例では、動作はさらに、保留中サポート要求に回答した後に、ユーザの実際の待ち時間を決定する工程を備えている。実際の待ち時間は、保留中サポート要求が受け取られたときから、ユーザが保留中サポート要求に対する回答を受け取るまでの実際の持続時間を示す。動作はさらに、保留中サポート要求に対する実際の待ち時間を使用して、待ち時間予測モデルを調整する工程も備えている。また、動作はさらに、待ち時間予測モデルによって予測された推定待ち時間と、実際の待ち時間とに基づき、待ち時間予測モデルの損失を決定する工程と、損失が、以前に学習されたモデルの損失と比較して閾値を満たすかどうかを判定する工程と、損失が閾値を満たす場合に、以前に学習されたモデルに戻す工程とを備えていることができる。 In some examples, the operation further comprises a step of determining the user's actual wait time after answering the pending support request. The actual wait time indicates the actual duration from when the pending support request is received until the user receives a response to the pending support request. The operation also includes the process of adjusting the latency prediction model using the actual latency for the pending support request. In addition, the behavior is further determined by the process of determining the loss of the latency prediction model based on the estimated latency predicted by the latency prediction model and the actual latency, and the loss is the loss of the previously learned model. It can be provided with a step of determining whether or not the threshold is satisfied by comparison with the above, and a step of returning to the previously trained model when the loss satisfies the threshold.
いくつかの実装では、損失を決定する工程は、平均二乗誤差を使用する工程を備えている。任意で、待ち時間予測モデルは、ニューラルネットワークを備えている。ニューラルネットワークは、回帰深層ニューラルネットワークを備えてもよい。また、ニューラルネットワークは、第１隠れ層および第２隠れ層を有する深層ニューラルネットワークを備えてもよい。 In some implementations, the process of determining loss comprises the process of using mean square error. Optionally, the latency prediction model comprises a neural network. The neural network may include a regression deep neural network. Further, the neural network may include a deep neural network having a first hidden layer and a second hidden layer.
保留中サポート要求は複数の高レベル特徴に関連付けられているか、または、高レベル特徴は保留中サポート要求に関連付けられている。保留中サポート要求に関連付けられている高レベル特徴は、高レベル特徴のそれぞれについて、保留中サポート要求（これは、ユーザが実際のサポート要求を提出することに関心があることを示す、（例えばウェブページを介して）受け取った最初のユーザサポート要求であってもよいし、ユーザが提出した実際のサポート要求であってもよい）の受け取りに応答して、取得または収集または受け取った高レベル特徴の値または数を備えてもよい。例えば、値または数は、受け取った保留中サポート要求から取得されてもよく、または保留中サポート要求を受け取ったときにシステムから取得されてもよい。例えば、保留中サポート要求に関連する複数の高レベル特徴は、アクティブなサポートエージェントの数であって、各アクティブなサポートエージェントは、保留中サポート要求の受け取り時にキューに入っているサポート要求の処理に現在アクティブである、アクティブなサポートエージェントの数と、利用可能なサポートエージェントの数であって、各利用可能なサポートエージェントは、保留中サポート要求の受け取り時にサポート要求を処理するべく現在利用可能である、利用可能なサポートエージェントの数と、および保留中サポート要求の受け取り時に処理を待っているサポート要求の数を示すキュー深さとを備えてもよい。 A pending support request is associated with multiple high-level features, or a high-level feature is associated with a pending support request. The high-level features associated with the pending support request indicate that, for each of the high-level features, the pending support request, which indicates that the user is interested in submitting the actual support request (eg, the web). High-level features acquired or collected or received in response to the receipt of (either through the page) the first user support request received or the actual support request submitted by the user). It may have a value or a number. For example, the value or number may be obtained from the pending support request received, or from the system when the pending support request is received. For example, several high-level features related to pending support requests are the number of active support agents, where each active support agent handles the support requests that are queued when the pending support request is received. The number of currently active and active support agents and the number of available support agents, each available support agent is currently available to process the support request upon receipt of the pending support request. , The number of support agents available, and the queue depth indicating the number of support requests waiting to be processed when a pending support request is received.
待ち時間予測モデルを使用してユーザに対する推定待ち時間を予測するべく、アクティブなサポートエージェントの数および／または非アクティブなエージェントの数と、利用可能なサポートエージェントの数と、およびキュー深さとを備えている、保留中サポート要求に関連する高レベル特徴を使用することで、本明細書に記載の実装は、サポート要求システムが一般的におよび／または容易に入手できるデータを使用して、ユーザに対する推定待ち時間を高い精度で予測することができる。待ち時間予測モデルへの入力として使用されるデータは、一般的に／容易に入手可能であるので、収集が容易であり、サポートソフトウェアの高価な計算／計測を必要とする複雑なシステムを必要とすることなく、新しいデータで迅速に更新することができる。これは、複雑な待ち行列理論モデルで必要とされるような、ｎ次微分メトリクス（例えば、オンラインエージェント数の２次微分、複雑なローリング窓メトリクス）、またはニッチメトリクスなどのモデルへの入力として、特定の、時には測定が困難な情報を必要とする典型的な待ち行列理論モデルとは対照的であるが、そうでなければ価値を提供しないか、または既存のメトリクスの収集を必要としない。 Includes the number of active and / or inactive agents, the number of available support agents, and the queue depth to predict the estimated latency for the user using the latency prediction model. By using the high-level features associated with pending support requests, the implementations described herein are for users using data that is generally and / or readily available to the support request system. The estimated waiting time can be predicted with high accuracy. The data used as input to the latency prediction model is generally / easily available, so it is easy to collect and requires a complex system that requires expensive calculations / measurements of support software. You can quickly update with new data without having to. This is as input to a model such as nth derivative metrics (eg, second derivative of the number of online agents, complex rolling window metrics), or niche metrics, as required by complex queuing theory models. In contrast to typical queuing-theoretic models that require specific, sometimes difficult-to-measure information, but otherwise do not provide value or require the collection of existing metrics.
本開示の１つまたは複数の実装の詳細は、添付の図面および以下の説明に記載されている。他の態様、特徴、および利点は、説明および図面、ならびに特許請求の範囲から明らかになるであろう。 Details of one or more implementations of the present disclosure are given in the accompanying drawings and the description below. Other aspects, features, and advantages will become apparent from the description and drawings, as well as the claims.
様々な図面における同様の参照記号は、同様の要素を示す。
従来の顧客サービス待ち行列（ｑｕｅｕｉｎｇ。キューイング）システムは、典型的には、顧客が顧客サービス電話番号に電話をかけ、顧客サービスエージェントが電話に回答（応答）するべく利用可能になるまでキュー（ｑｕｅｕｅ。待ち行列）に顧客が入れられることを備えている。顧客は、エージェントに接続されるまで、この待ち行列で待つ。通信コストの削減と顧客満足度の向上とを目指して、企業（ビジネス）は仮想待ち行列を提供し始めている。仮想待ち行列システムでは、顧客はサービス番号に電話をかけるか、またはオンラインポータルを通じてサービスを要求する。そして、顧客サポートシステムは、予想される待ち時間を顧客に伝える。つまり、システムは、事業者が顧客に電話をかけて利用可能なエージェントに接続するまで、ユーザが仮想待ち行列でどれくらい待つかを予測してユーザに通知する。システムは、顧客を仮想の待ち行列に入れ、顧客が行列の先頭に近づくと、事業者は顧客に電話をかけ、その後すぐに、次に利用可能なエージェントに接続する。これによって、事業者は通信費を最小限に抑えることができ、顧客は電話がかかってくるまで空いている（フリーである）ので、顧客満足度を高めることができる。しかし、予想される待ち時間を正確に伝えられないと、顧客満足度が低下する可能性がある。
Similar reference symbols in various drawings indicate similar elements.
Traditional customer service queuing systems typically queue until a customer calls a customer service phone number and a customer service agent is available to answer (answer) the call. It is equipped with a customer service (queuing). The customer waits in this queue until it is connected to the agent. Companies (businesses) have begun to provide virtual queues with the aim of reducing communication costs and improving customer satisfaction. In a virtual queue system, customers call the service number or request service through an online portal. The customer support system then informs the customer of the expected waiting time. That is, the system predicts how long the user will wait in the virtual queue until the operator calls the customer and connects to an available agent to notify the user. The system puts the customer in a virtual queue, and when the customer approaches the top of the queue, the operator calls the customer and then immediately connects to the next available agent. As a result, the operator can minimize the communication cost, and the customer is free (free) until the call is received, so that the customer satisfaction can be improved. However, failure to accurately communicate expected wait times can reduce customer satisfaction.
仮想待ち行列システムまたは他の待ち行列システムのために、顧客の予想待ち時間を予測することは、悪名高い困難な作業である。既存のシステムはよく知られた数学的定式化を使用するが、よく知られた数学的定式化は複雑であり、特定のまたはより詳細なデータを取得するべく、基礎となるソフトウェアサービスの広範な計装（ｉｎｓｔｒｕｍｅｎｔａｔｉｏｎｓ）を必要とする。例えば、既存のシステムは、オンライン機械学習システムにおけるｎ次微分メトリクス（例えば、オンラインエージェント数の２次微分、複雑なローリング窓メトリクス）や、複雑な待ち行列理論モデルで必要とされるようなニッチメトリクスなど、特定のまたはより詳細なデータを必要とする可能性がある。このようなデータは、収集にコスト（すなわち、過剰な計算やストレージ）がかかり、そうでなければ価値を提供できなかったり、既存のメトリックの収集が必要になったりすることがある。しかし、このような複雑なシステムでは、多くの一般的なシナリオで、正確な待ち時間を予測できないことがよくある。そのため、企業は一定の見積もりや範囲に頼ることが多く、それらは簡単ではあるが、正確性はさらに低くなる。さらに、既存のソリューションでは、提供されるサポートキューごとに個別で一意のモデルを開発しなければならないことが多く、サポート電話のトピックやビジネスにとらわれない（ａｇｎｏｓｔｉｃ）ものとなっている。つまり、多くの企業は多種多様なサービスや製品を提供しているが、顧客サポートのエージェントは通常、特定のサービスや製品をサポートするようにしか学習されていないので、多くの企業は通常ではサービスや製品ごとに専用のサポートキューを提供している。既存のシステムでは、サポートキューごとにモデルを開発する必要があるが、これでは大規模な企業には対応できない。顧客サポートシステムは、手動で定義された定式化を計算するべくデータを収集する不合理な負担なしに、任意の数のビジネスユニットまたはサポートキューにわたって高度な精度を提供するモデルから利益を得ることができる。 Predicting expected customer latency due to virtual queue systems or other queue systems is a notorious and difficult task. Existing systems use well-known mathematical formulation, but well-known mathematical formulation is complex and a wide range of underlying software services to obtain specific or more detailed data. Requires instrumentation. For example, existing systems include n-th derivative metrics in online machine learning systems (eg, second derivative of online agent numbers, complex rolling window metrics) and niche metrics such as those required in complex queuing theory models. May require specific or more detailed data, such as. Such data may be costly to collect (ie, excessive computation or storage), otherwise it may not be able to provide value or may require the collection of existing metrics. However, in such complex systems, accurate latency is often unpredictable in many common scenarios. As a result, companies often rely on certain estimates and ranges, which are simple but even less accurate. In addition, existing solutions often require the development of individual and unique models for each support queue provided, making them agnostic to support phone topics and businesses. That is, while many companies offer a wide variety of services and products, many companies are usually services because customer support agents are usually only learned to support a particular service or product. And provide a dedicated support queue for each product. Existing systems require the development of a model for each support queue, which is not suitable for large enterprises. Customer support systems can benefit from models that provide a high degree of accuracy across any number of business units or support queues without the unreasonable burden of collecting data to calculate manually defined formulations. can.
本明細書の実施は、保留中サポート要求に回答するまでの推定持続時間を示す推定待ち時間を予測する待ち時間予測モデルを実装するサポート要求システムに向けられている。システムは、アクティブなエージェントの数（すなわち、働いているエージェントの数）と、利用可能なエージェントの数（すなわち、サポート要求に答えるべく利用可能なエージェントの数）と、および処理を待っているサポート要求の数を示すキュー深さと、を備えている複数の高レベル特徴（すなわち、サポート要求システムにとって一般的および／または容易に利用可能なデータ）を受け取る。保留中サポート要求は複数の高レベル特徴に関連付けられているか、または高レベル特徴は保留中サポート要求に関連付けられている。保留中サポート要求に関連付けられている高レベル特徴は、高レベル特徴のそれぞれについて、保留中サポート要求（これは、ユーザが実際のサポート要求を提出することに関心があることを示す、（例えば、ウェブページを介して）受け取られた最初のユーザサポート要求であってもよいし、ユーザによって提出された実際のサポート要求であってもよい）の受け取りに応答して取得または収集または受け取られた、高レベル特徴の値または数を備えてもよい。例えば、値または数は、受け取った保留中サポート要求から取得されてもよく、または保留中サポート要求を受け取ったときにシステムから取得されてもよい。例えば、保留中サポート要求に関連付けられる複数の高レベル特徴は、アクティブなサポートエージェントの数であって、各アクティブなサポートエージェントは、保留中サポート要求の受け取り時にキューに入ったサポート要求の処理に現在アクティブである、アクティブなサポートエージェントの数と、利用可能なサポートエージェントの数であって、各利用可能なサポートエージェントは、保留中サポート要求の受け取り時にサポート要求を処理するべく現在利用可能である、利用可能なサポートエージェントの数と、保留中サポート要求の受け取り時に処理されるのを待っているサポート要求の数を示すキュー深さと、を備えてもよい。また、高レベル特徴は、保留中サポート要求に関連するビジネス（事業者）の識別（ＩＤ）と、ビジネス（事業者）に関連するビジネス（事業者）キューのＩＤと、および／または、以前の実際の待ち時間（すなわち、最も直近に回答されたサポート要求がキューで待っていた時間量）と、を備えてもよい。 The implementation of this specification is directed to a support request system that implements a wait time prediction model that predicts an estimated wait time that indicates the estimated duration of responding to a pending support request. The system has the number of active agents (ie, the number of working agents), the number of available agents (ie, the number of agents available to respond to support requests), and the support waiting for processing. Receives multiple high-level features (ie, data that is common and / or readily available to support request systems) with a queue depth that indicates the number of requests. A pending support request is associated with multiple high-level features, or a high-level feature is associated with a pending support request. The high-level features associated with the pending support request indicate that, for each of the high-level features, the pending support request, which indicates that the user is interested in submitting the actual support request (eg,). Obtained, collected or received in response to the receipt of the first user support request received (via a web page) or the actual support request submitted by the user). It may have a value or number of high level features. For example, the value or number may be obtained from the pending support request received, or from the system when the pending support request is received. For example, multiple high-level features associated with pending support requests are the number of active support agents, each active support agent currently processing a support request that was queued when the pending support request was received. The number of active, active support agents and the number of available support agents, each available support agent is currently available to process the support request upon receipt of the pending support request. It may have a queue depth that indicates the number of support agents available and the number of support requests waiting to be processed when a pending support request is received. High-level features also include the identity (ID) of the business (operator) associated with the pending support request, the ID of the business (operator) queue associated with the business (operator), and / or previous. It may include the actual wait time (ie, the amount of time the most recently answered support request was waiting in the queue).
待ち時間予測モデルは、それぞれが対応する複数の高レベル特徴と、対応する実際の待ち時間とを備えている学習サポート要求のコーパスで学習される。待ち時間予測モデルは、高レベル特徴を受け取った後、保留中サポート要求の顧客に対する推定待ち時間を予測する。システムは、保留中サポート要求に回答するまでの、すなわち、顧客が顧客サポートエージェントに接続されるまでの、推定持続時間を示すべく、推定待ち時間を顧客に提供する。待ち時間予測モデルは、あらゆるビジネス／企業に展開可能なビジネスにとらわれないソリューションを提供する一方で、ソフトウェアサポートサービスの計装はあったとしても最小限にとどめ、多様で大量の環境におけるビジネス／企業の規模に合わせて容易に拡張することが可能である。 The latency prediction model is trained in a corpus of learning support requests, each with a corresponding high-level feature and a corresponding actual latency. The latency prediction model predicts the estimated latency for a customer with a pending support request after receiving a high-level feature. The system provides the customer with an estimated latency to indicate the estimated duration until the pending support request is answered, i.e., the customer is connected to the customer support agent. The latency prediction model provides a business-agnostic solution that can be deployed to any business / enterprise, while minimizing the instrumentation of software support services, if any, for businesses / enterprises in diverse and high-volume environments. It can be easily expanded according to the scale of.
図１および図２を参照すると、いくつかの実装では、システム１００は、ユーザ装置１１０に関連するユーザ１０（例えば、顧客）からサポート要求１２０を発行するユーザ装置１１０（例えば、顧客装置）を備えている。サポート要求１２０は、エンティティ（例えば、企業や会社）からのサポート（支援）を求めてユーザ１０が生成した要求である。例えば、ユーザ１０は、関連する事業者の製品またはサービスに関する質問をしたいと思うかもしれない。ユーザ１０は、例えば、電話、ウェブサイト、またはモバイルアプリケーションを通じて、ユーザ装置１１０を介してサポート要求１２０を生成してもよい。すなわち、ユーザ１０は、事業者と対話し（例えば、事業者に電話をかけたり、オンラインポータルにアクセスしたりして）、プロンプトに従ってサポート要求１２０を提出してもよい。事業者は、ユーザのサポート要求１２０が顧客サポートエージェント２３０の適切なグループに向けられるように、情報（例えば、名前、製品／サービスの説明、問題の説明など）を引き出すことができる。例えば、事業者は、ウェブベースのアプリケーションやモバイルアプリケーションなどのアプリケーション１１１（図６）を通じて、サポート要求１２０を提出する前にユーザ１０による関連情報の入力を要求するフォームを提供してもよい。
Referring to FIGS. 1 and 2, in some implementations, the
ユーザ装置１１０は、ネットワーク１１４を介して、サポート要求１２０をリモート（遠隔）システム１４０に通信してもよい。リモートシステム１４０は、スケーラブル／エラスティックなリソース１４２を有する分散システム（例えば、クラウドコンピューティング環境）であってもよい。リソース１４２は、コンピューティングリソース１４４（例えば、データ処理ハードウェア）および／またはストレージリソース１４６（例えば、メモリハードウェア）を備えている。いくつかの実装形態では、リモートシステム１４０は、ユーザ１０からサポート要求１２０を受け取るように構成されたサポート要求マネージャ２００を実行する。サポート要求マネージャ２００は、サポート要求１２０と、サポート要求１２０に関連付けられた複数の高レベル特徴２０２，２０２ａ～２０２ｎとを用いて、予測される待ち時間１３０をユーザ１０に返す。予測待ち時間（「推定待ち時間」とも呼ばれる）１３０は、保留中サポート要求１２０が回答１２２されるまでの推定持続時間（すなわち、ビジネス（事業者）に関連する顧客サポートエージェント２３０がユーザ１０と直接対話するまでの時間量）を示す。本明細書で使用されるように、エージェント２３０がサポート要求１２０に回答１２２することに関連する「回答」（アンサー）という用語は、エージェント２３０が何らかの方法でサポート要求１２０のサービスを開始したこと（例えば、エージェント２３０が電話を介してまたはチャットインタフェースを介して、ユーザ１０に接続したこと）を示す。サポート要求１２０に対する回答１２２は、顧客サポートエージェント２３０から回答１２２を受け取るまでサポート要求１２０が保留されていた実際の持続期間を示す実際の待ち時間２０２ｆに関連付けられてもよい。
The
図示の例では、サポート要求マネージャ２００は、サポート要求キュー４００、サポートエージェントプール３００、および待ち時間予測器２６０を備えている。ユーザ装置１１０から受け取ったサポート要求１２０は、サポート要求キュー４００に入力されており、顧客サポートエージェント２３０がサポート要求１２０に回答１２２できるようになるまで、１つまたは複数の他のサポート要求１２０と共にサポート要求キュー４００に保留中のままである。サポート要求キュー４００に保留中のサポート要求１２０は、先入れ先出し（ファーストインファーストアウト）方式で回答されてもよい。いくつかの例では、サポート要求キュー４００は、サポート要求１２０が向けられる対応するビジネス／企業にそれぞれ関連する対応するビジネスキューに分割される。したがって、各サポート要求１２０は、保留中サポート要求１２０に関連するビジネスを識別するビジネスＩＤ２０２ｄと、および／または、保留中サポート要求１２０をキューイングするためのそれぞれのサポート要求キュー４００を識別するキューＩＤ２０２ｅとを指定することができる。サポート要求１２０がサポート要求キュー４００内で保留中の間、待ち時間予測器２６０は、保留中サポート要求１２０の推定待ち時間１３０を予測するように構成されている。その後、サポート要求マネージャ２００は、推定待ち時間１３０を、ユーザ１０に関連するユーザ装置１１０に提供してもよい。
In the illustrated example, the support request manager 200 includes a
いくつかの例では、待ち時間予測器２６０は、保留中サポート要求１２０に関連する複数の高レベル特徴２０２，２０２ａ～２０２ｎを特徴入力として受け取るように構成された待ち時間予測モデル２７０を使用する。複数の高レベル特徴２０２は、アクティブなエージェント２０２ａの数と、利用可能なエージェント２０２ｂの数と、キュー深さ２０２ｃと、ビジネスＩＤ（業務ＩＤ）２０２ｄと、キューＩＤ２０２ｅと、または、エージェント２３０によって最近に回答１２２されたサポート要求キュー４００からの１つまたは複数の他のサポート要求１２０に関連付けられた以前の実際の待ち時間２０２ｆと、のうちの１つまたは複数を備えてもよい。待ち時間予測モデル２７０は、一部の高レベル特徴２０２（例えば、ビジネスＩＤ２０２ｄおよびキュー２０２ｅ）を保留中サポート要求１２０から直接取得する一方で、他の高レベル特徴２０２を他のソースから（例えば、保留中サポート要求１２０に応答して、または保留中サポート要求１２０の受け取り時に）取得してもよい。例えば、待ち時間予測モデル２７０は、サポートエージェントプール３００からアクティブな顧客サポートエージェント２０２ａの数および利用可能な顧客サポートエージェント２０２ｂの数を受け取ったり、例えば、保留中サポート要求１２０の受け取りまたはそのような要求の提出に対する関心の受け取り（すなわち、ユーザ１０がチケットの提出を検討（ｉｎｖｅｓｔｉｇａｔｅ）するべくウェブページを訪問したとき）に応答して、サポート要求キュー４００からキュー深さ２０２ｃを受け取ったりしてもよい。高レベル特徴２０２はすべて、顧客サポートシステムによってすでに一般的に収集されたデータを表しており、したがって一般的に、余計なユーザデータの保持や、サポートソフトウェアの高価な計算／計装を要求することはない。他の簡単に収集される高レベル特徴２０２も含まれることがある。例えば、保留中サポート要求１２０が受け取られた、一日のうちの時間を示す時間帯表示２０２ｎが含まれてもよい。別の例では、高レベル特徴２０２は平均解決時間を備えており、平均解決時間は、それぞれのビジネスＩＤ２０２ｄおよび／またはそれぞれのキューＩＤ２０２ｅに関連付けられたサポートエージェント２３０が、対応するサポート要求１２０を完了するべくかかる平均時間量を代表する。以下でより詳細に説明すると、待ち時間予測モデル２７０は、対応する高レベル特徴２０２を備えている学習データ２０２Ｔで学習される。
In some examples, the
図２を参照すると、いくつかの実装では、待ち時間予測モデル２７０は、履歴サポート要求データストア２５０から得られた学習データ２０２Ｔで学習される。履歴サポート要求データストア２５０は、分散システム１４０のストレージリソース１４６上に存在してもよいし、システム１４０に通信している他のリモートロケーションに存在してもよい。学習データ２０２Ｔは、履歴サポート要求１２０Ｈ（「学習サポート要求１２０Ｈ」とも呼ばれる）のコーパスを備えており、各履歴サポート要求１２０Ｈは、対応する複数の高レベル特徴２０２ａ～２０２ｎと、対応する実際の待ち時間２０３とを備えている。例えば、各履歴サポート要求１２０Ｈは、対応する履歴サポート要求１２０Ｈに関連付けられた、アクティブなエージェント２０２ａの数と、利用可能なエージェント２０２ｂの数と、キュー深さ２０２ｃと、ビジネスＩＤ２０２ｄと、キューＩＤ２０２ｅと、または実際の待ち時間２０２ｆとのうちの１つまたは複数を備えている。ここで、対応する履歴サポート要求１２０Ｈに関連付けられた実際の待ち時間２０２ｆは、サポート要求１２０Ｈが「履歴」であるので、サポート要求マネージャ２００によって既に処理されていることから、知られている。したがって、対応する履歴サポート要求１２０Ｈに関連付けられた実際の待ち時間２０３は、履歴サポート要求１２０Ｈが、回答される前に保留されていた実際の期間を示している。さらに、履歴サポート要求１２０Ｈはさらに、対応する履歴サポート要求１２０Ｈの前に回答された１つまたは複数の過去のサポート要求１２０に関連する、以前の実際の待ち時間２０２ｆを備えていることができる。実際の待ち時間２０３は、図４および図５を参照して以下でより詳細に説明される。図示の例では、学習データ２０２Ｔは、待ち時間予測モデル２７０を学習するために待ち時間学習器２０４に渡される。学習データ２０２Ｔに基づき、待ち時間学習器２０４は、待ち時間予測モデル２７０を学習するべく、サポート要求パラメータ２０６をモデル化することができる。一旦学習されると、待ち時間予測モデル（例えば、学習されたモデル）２７０は、対応する保留中サポート要求１２０に対する推定待ち時間１３０を予測するための推論中に、待ち時間予測器２６０によって使用される。したがって、それぞれが対応する複数の高レベル特徴２０２および／または既知の対応する実際の待ち時間２０２ｆを備えている履歴サポート要求１２０Ｈのコーパスに関連する学習データ２０２Ｔを使用して、待ち時間予測モデル２７０は、推定待ち時間１３０を予測するように学習される。
Referring to FIG. 2, in some implementations, the
待ち時間予測モデル２７０は、ニューラルネットワークを備えてもよい。例えば、待ち時間学習器２０４は、学習データ２０２Ｔを出力データにマッピングして、ニューラルネットワークモデル２７０を生成してもよい。一般に、待ち時間学習器２０４は、隠れノードと、学習データ２０２Ｔに対応する入力ノードと隠れノードとの間の接続の重みと、隠れノードと出力ノードとの間の接続の重みと、および隠れノード自体の層同士間の接続の重みとを生成する。その後、完全に学習されたニューラルネットワークモデル２７０は、未知の出力データ（例えば、推定待ち時間１３０）を生成するべく、入力データ（例えば、保留中サポート要求１２０）に対して採用されてもよい。いくつかの例では、ニューラルネットワークモデル２７０は、第１隠れ層および第２隠れ層を有する深層ニューラルネットワーク（例えば、回帰深層ニューラルネットワーク）である。例えば、第１隠れ層は１６個のノードを有し、第２隠れ層は８個のノードを有してもよい。待ち時間学習器２０４は、典型的には、待ち時間予測モデル２７０をバッチで学習する。すなわち、待ち時間予測モデル２７０は、典型的には、一度に一群の入力パラメータ（すなわち、高レベル特徴２０２および実際の待ち時間２０３）に対して学習される。いくつかの実装では、学習された待ち時間予測モデル２７０は、１０のバッチサイズで学習される。本明細書に記載の待ち時間予測モデルの実装は、最小限の前処理で既存の履歴データを使用し、それによって、深層ニューラルネットワークアプローチの有効性を高める。
The waiting
次に図３を参照すると、例示的なサポートエージェントプール３００は、サポート要求１２０に答えることができるエージェント２３０、２３０ａ～２３０ｎの総数を備えている。例えば、コールセンターは、所定のビジネスユニット、製品、またはサービスのサポート要求に答えるべく、現在コールセンターに存在する合計５人のエージェント２３０を有することができる。サポートエージェントプール３００内のサポートエージェント２３０の一部は、キューイングされたサポート要求１２０の処理に現在アクティブなエージェント２０２ａを備えていてもよい。サポートエージェントプール３００内のサポートエージェント２３０の残りの部分は、キューイングされたサポート要求１２０を処理するべく現在利用可能なエージェント２３０に関連する利用可能なエージェント２０２ｂを備えてもよい。言い換えれば、利用可能なエージェント２０２ｂの数は、サポート要求に答えるべく現在空いているエージェント２３０の数で構成される。図示の例では、サポートエージェントプール３００内のエージェント２３０のうち、３人のエージェント２３０ｃ，２３０ｄ，２３０ｎはアクティブエージェント２０２ａ（すなわち、現在顧客をサポートしているエージェント２３０）として分類されており、２人のエージェント２３０ａ，２３０ｂは、利用可能なエージェント２０２ｂとして分類されている。
Next, referring to FIG. 3, the exemplary
図１に戻って、待ち時間予測モデル２７０は、アクティブなエージェント２０２ａの数および利用可能なエージェント２０２ｂの数に加えて、サポート要求キュー４００からキュー深さ２０２ｃを受け取る。キュー深さ２０２ｃは、現在処理を待っている（すなわち、保留中の）サポート要求１２０の数を示している。別の言い方をすれば、キュー深さ２０２ｃは、それぞれのサポート要求１２０に答えてもらうべく、現在何人のユーザ１０が列（すなわち、キュー４００）に並んで待っているかを表している。例えば、ゼロに等しいキュー深さ２０２ｃは、現在、キュー４００内に保留中サポート要求１２０が無いことを示しており、一方、「８」（エイト）に等しいキュー深さ２０２ｃは、現在、キュー４００内に８つの別々の保留中サポート要求１２０があることを示す。典型的には、エージェント２３０は、キューに入れられたサポート要求１２０に順に答える。すなわち、エージェント２３０がそれぞれのサポート要求１２０に回答１２２を提供する前に、エージェント２３０は一般的に、それぞれのサポート要求１２０よりも先に受け取ったサポート要求１２０のすべてに既に回答１２２を提供しているであろう。
Returning to FIG. 1, the
図４は、異なるユーザ１０（例えば、顧客）からサポート要求１２０，１２０ａ～１２０ｎを受け取るサポート要求キュー４００を示す。示されている例では、キュー４００は、特定のビジネス／企業に関連していてもよく、ＦＩＦＯ（Ｆｉｒｓｔ－ＩｎＦｉｒｓｔ－Ｏｕｔ）キューに対応していてもよい。すなわち、キュー４００の先頭４１０にあるサポート要求１２０は次に回答されるべき順番であり、到着したばかりのサポート要求１２０はキュー４００の末尾４１２に置かれる。例えば、第１サポート要求１２０ａは、他の第２サポート要求１２０ｂおよび第３サポート要求１２０ｃよりも先にキュー４００に入れられたので、先頭４１０で次に回答されることになる。エージェント２３０ａが利用可能になると、エージェント２３０ａは、キュー４００内の次の第１サポート要求１２０ａに回答１２２するか、または応答する。いくつかの例では、エージェント２３０ａが第１サポート要求１２０ａに回答すると、待ち時間予測モデル２７０の調整／学習に使用されるべく、第１サポート要求１２０ａに対する実際の待ち時間２０２ｆが得られる。例えば、実際の待ち時間２０２ｆおよび第１サポート要求１２０ａは、図２を参照して上述したように、学習データ２０２Ｔとして使用されるべく、履歴サポート要求データストア２５０に格納されてもよい。加えてまたは代替的に、第１サポート要求１２０ａに対する実際の待ち時間２０２ｆは、キュー４００によってその後に受け取られる１つまたは複数のサポート要求１２０（例えば、第４サポート要求１２０ｄ）に対する推定待ち時間１３０を予測するための高レベル特徴２０２として適用されてもよい。いくつかの実装では、待ち時間予測モデル２７０は、単一の以前の実際の待ち時間２０２ｆのみを記憶する。すなわち、エージェント２３０がサポート要求１２０に回答するたびに、以前の実際の待ち時間２０２ｆは、新しい値で上書きされる。他の実装では、複数の以前の実際の待ち時間２０２ｆが記憶される（例えば、履歴サポート要求データストア２５０（図２）内に）。待ち時間予測器２６０は、待ち時間予測モデル２７０を学習するための学習データ２０２Ｔとして使用するべく、複数の以前の実際の待ち時間２０２ｆを統計的に処理（例えば、平均値を求める）してもよい。
FIG. 4 shows a
引き続き図４を参照すると、最も直近に受け取った第４サポート要求１２０ｄは、キュー４００の末尾４１２に追加される。エージェント２３０がサポート要求１２０に答えると、第４サポート要求１２０ｄは、キュー４００の先頭４１０になるまでキュー４００内を前進し、その後にエージェント２３０によって答えられる。第４サポート要求１２０ｄがキュー４００に追加されると、待ち時間予測モデル２７０は、第４サポート要求１２０ｄに関連付けられた高レベル特徴２０２（すなわち、第４サポート要求１２０ｄを受け取った時点でのシステム１００の状態やステータスに対応する高レベル特徴２０２）を用いて、推定待ち時間１３０を予測し、予測された推定待ち時間１３０を、対応する第４サポート要求１２０ｄに割り当てる。ここで、サポート要求マネージャ２００は、第４サポート要求１２０ｄを入力したユーザ装置１１０に、推定待ち時間１３０を伝達してもよい。エージェント２３０が第４サポート要求１２０ｄに回答１２２したとき、第４サポート要求１２０ｄに対する実際の待ち時間２０２ｇは、待ち時間予測モデル２７０をさらに調整または学習するべく、対応する推定待ち時間１３０と比較するべく取得されてもよい。
Continuing with reference to FIG. 4, the most recently received
ここで図５を参照すると、待ち時間予測器２６０は、サポート要求１２０に関連する複数の高レベル特徴２０２を受け取るように構成されている。特徴のいくつかは数値特徴２０２（例えば、アクティブなエージェント数２０２ａ、利用可能なエージェント数２０２ｂ、キュー深さ２０２ｃ、および実際の待ち時間２０２ｆ）であってもよく、いくつかの特徴は文字列特徴２０２（例えば、ビジネスＩＤ２０２ｄおよびキューＩＤ２０２ｅ）であってもよい。これらの特徴２０２の１つまたは複数を用いて、待ち時間予測モデル２７０は、推定待ち時間１３０を予測する。サポート要求１２０が回答された際に実際の待ち時間２０２ｆが得られると（すなわち、エージェント２３０がサポート要求１２０に回答するまでにサポート要求１２０がキュー４００内で過ごした時間）、待ち時間予測器２６０は、推定待ち時間１３０と実際の待ち時間２０２ｆとの間の損失５２０を決定してもよい。すなわち、待ち時間予測器２６０は、損失関数５１０（例えば、平均二乗誤差損失関数）を使用して、推定待ち時間１３０の損失５２０を決定してもよく、損失５２０は、予測された待ち時間推定値１３０が実際の待ち時間２０２ｆに対してどれだけ正確であるかの尺度である。待ち時間予測器２６０は、いくつかの実装において、損失５２０を使用して、待ち時間予測モデル２７０をさらに学習または調整する。
Now referring to FIG. 5, the
いくつかの例では、待ち時間予測器２６０（またはサポート要求マネージャ２００、またはデータ処理ハードウェア１４４上で実行される他のシステム）は、最近回答されたサポート要求１２０の実際の待ち時間２０２ｆを待ち時間予測器２６０が受け取った直後に、損失５２０および／または任意の関連する高レベル特徴２０２を用いて、待ち時間予測モデル２７０を調整する。他の例では、待ち時間予測器２６０は、構成可能な頻度で、待ち時間予測モデル２７０を学習する。例えば、待ち時間予測器２６０は、１日に１回待ち時間予測モデル２７０を学習してもよく、学習データ２０２Ｔは、その日に発生したサポート要求１２０および関連する特徴２０２のすべて（すなわち、図２の履歴サポート要求１２０Ｈ）を備えてもよい。構成可能な頻度は、１日に１回に限定されず、他の期間（例えば、１時間に１回、１週間に１回など）を含んでもよいことが理解される。例えば、待ち時間予測器２６０は、前日のデータに基づきモデルを調整するべく、１日に１回（または他の所定の期間）、待ち時間予測モデル２７０を自動的に学習してもよい。いくつかの実装では、調整または再学習された待ち時間予測モデル２７０の損失５２０は、以前の待ち時間予測モデル２７０（例えば、前日から学習された待ち時間予測モデル２７０）の損失と比較されており、仮に、新しい待ち時間予測モデル２７０の損失５２０が、以前の待ち時間予測モデル２７０の損失５２０に対して閾値を満たす場合（例えば、今日学習された待ち時間予測モデル２７０の損失５２０対昨日学習された待ち時間予測モデル２７０の損失５２０）、待ち時間予測器２６０は、以前に学習された待ち時間予測モデル２７０に戻してもよい（すなわち、新しく調整または再学習された待ち時間予測モデル２７０を破棄する）。別の言い方をすれば、待ち時間予測モデル２７０が新しい学習データ２０２Ｔ（例えば、その日から収集されたもの）でさらに学習されたが、待ち時間予測モデル２７０の精度が低下したことを損失５２０が示している場合、待ち時間予測モデル２７０は、以前のより精度の高い待ち時間予測モデル２７０に戻されてもよい。
In some examples, the latency predictor 260 (or the support request manager 200, or any other system running on the data processing hardware 144) waits for the
図１に戻って、待ち時間予測モデル２７０は、高レベル特徴２０２および保留中サポート要求１２０に基づき、受け取った保留中サポート要求１２０に対する推定待ち時間１３０を予測し、サポート要求マネージャ２００は、推定待ち時間１３０を、ユーザ１０（すなわち、顧客）に関連するユーザ装置１１０に提供する。ユーザ装置１１０は、デスクトップワークステーション、ラップトップワークステーション、モバイル装置（例えば、スマートフォンまたはタブレット）、ウェアラブル装置、スマートアプライアンス、スマートディスプレイ、またはスマートスピーカなどのコンピューティング装置に対応することができる。すなわち、ユーザ装置１１０は、ネットワーク１１４を介してリモートシステム１４０に通信可能な任意のコンピューティング装置であり得る。サポート要求マネージャ２００は、ユーザ装置１１０が電話を介して要求１２０を提出する際に、音声応答として推定待ち時間１３０をユーザ装置１１０に提供することができ、または、サポート要求マネージャ２００は、ユーザ装置１１０に送信される電子メッセージとして推定待ち時間１３０を提供することができる。電子メッセージは、ユーザ装置１１０による表示のためのテキストを備えていることができ、または電子メッセージは、推定待ち時間１３０をユーザ１０に伝える合成音声をユーザ装置１１０によって聴覚的に出力させる音声合成メッセージを備えていることができる。ここで、合成音声は、サポート要求マネージャ２００からネットワーク１１４を介して提供されてもよく、または、ユーザ装置１１０は、テキストを合成音声に変換するためのテキスト音声変換（ＴＴＳ）モジュールを備えてもよい。いくつかの例では、ユーザ装置１１０は、音声アシスタントソフトウェアを実行し、ユーザによって話されたサポート要求１２０に関連する発話をキャプチャし、サポート要求１２０をサポート要求マネージャ２００に送信する。ここで、ユーザ１０は、サポート要求１２０をサポート要求マネージャ２００に提供するようにユーザ装置１１０に指示する、音声コマンドを使用してもよい。ユーザ装置１１０は、ローカルに音声認識を用いて、サポート要求１２０の発話を、対応するテキストに変換し、サポート要求１２０を表すテキストを、サポート要求マネージャ２００に送信してもよい。他方、ユーザ装置１１０は、サポート要求１２０を表す音声データをサポート要求マネージャ２００に送信し、サポート要求マネージャ２００は、音声認識装置を活用して音声をテキストに変換してもよい。
Returning to FIG. 1, the
次に図６を参照すると、いくつかの実装では、ユーザ装置１１０は、ウェブページや、ウェブベースのアプリケーションにアクセスすることで、またはユーザ装置１１０上で実行される専用ソフトウェアアプリケーション１１１を介して、サポート要求マネージャ２００に通信する。図示の例では、ユーザ装置１１０は、サポート要求１２０を入力するべく、ユーザ装置１１０上で表示するためのグラフィカルユーザインタフェース（ＧＵＩ）１１２を実行する。ＧＵＩは、サポート要求１２０を定義するための詳細またはパラメータを入力するための１つまたは複数の欄６１０，６１０ａ～６１０ｎを備えてもよい。例えば、名前欄６１０ａは、ユーザ１０がユーザ１０の名前（例えば、ジェーン・ドゥ（ＪａｎｅＤｏｅ））を入力する（例えば、タイピングする）ことを許可してもよく、電話番号欄６１０ｂは、ユーザ１０の連絡先電話番号（例えば、（５５５）５５５－５５５５）を入力することを許可してもよい。図示の例では、ユーザ１０は、問題記述欄６１０ｃにおいて、注文番号＃１２３４で１月１４日に発注された注文を受け取らなかったことを示している。また、ＧＵＩは、サポート要求１２０を記入するための欄６１０ｄを備えていてもよい。例えば、「ＣａｌｌＭｅ」（電話して下さい）ボタンは、サポート要求１２０を記入（完了）させ、ユーザ１０がキュー４００の先頭４１０にいるときに、ユーザ１０がキュー４００に入り、サポート要求マネージャ２００からの電話（すなわち、回答１２２）を受けるのがユーザ１０にとって賢明であるとサポート要求マネージャ２００に通知してもよい。ユーザ１０は、他の手段を介して詳細またはパラメータを入力してもよいことが理解される。例えば、ユーザ装置１１０上で実行されるＧＵＩ１１２または他のソフトウェア１１１は、ユーザ１０が、ユーザ装置１１０のマイクロフォンを介してキャプチャされた音声入力として詳細を入力することを可能にしてもよい。同様に、ユーザ１０は、ユーザ装置１１０を単に電話として使用して、サポート要求マネージャ２００に電話をかけてもよく、それによって、ユーザ１０は、サポート要求１２０の詳細をオペレータに単に話してもよい。
Next, referring to FIG. 6, in some implementations, the
いくつかの実装では、サポート要求マネージャ２００は、ユーザがサポート要求１２０を提出した後（例えば、ユーザ１０がＣａｌｌ Ｍｅボタン６１０ｄを押した後）に、推定待ち時間１３０をユーザ１０に提供する。すなわち、ユーザは、サポート要求１２０を提出した後に、推定待ち時間１３０を受け取る。他の実装では、また、示された例では、ユーザ装置１１０は、サポート要求１２０を正式に提出してキュー４００に入る前に、ＧＵＩ１１２の欄６１４に推定待ち時間１３０を受け取って表示してもよい。すなわち、サポート要求マネージャ２００は、例えば、ユーザ１０がウェブページ上のリンクを選択することで、サポート要求１２０を提出することに関心を示したときに、推定待ち時間１３０を予測するためのデータ（例えば、高レベル特徴２０２）を収集してもよい。このようにして、ユーザ１０は、待ち時間が満足できるものであるかどうかを、キュー４００に入る前に判定することができる。
In some implementations, the support request manager 200 provides the
ここで図７を参照すると、高レベル特徴２０２の一部は、カテゴリー的特徴を備えてもよい。例えば、ビジネスＩＤ２０２ｄおよびキューＩＤ２０２ｅは、カテゴリー的特徴である。カテゴリー的特徴は、自然には数値形式ではなく、待ち時間予測モデル２７０に入力される前に数値形式にエンコードされなければならない特徴である。すなわち、ビジネスＩＤ２０２ｄおよびキューＩＤ２０２ｅは、エンコードを必要とする文字列特徴（図５）であってもよい。いくつかの実装では、文字列特徴２０２は、ワンショット符号化される。別の言い方をすれば、文字列特徴２０２（すなわち、ビジネスＩＤ２０２ｄおよびキューＩＤ２０２ｅ）は、待ち時間予測モデル２７０が使用することができる方法でカテゴリーデータを表現するための指標列として扱われてもよい。
Now referring to FIG. 7, some of the high-level features 202 may have categorical features. For example, business ID 202d and queue ID 202e are categorical features. Categorical features are not naturally in numerical format, but are features that must be encoded in numerical format before being input into the
示された例では、入力文字列特徴は、８１個の異なる文字列入力を備えてもよく（すなわち、入力は、８１個の異なる文字列のうちのいずれかに等しくてもよい）、８１個の文字列のそれぞれには、［０］～［８０］の間の値が割り当てられる。例示されている４つの文字列のうち、「ｄｏｇ」（犬）には［０］の値が割り当てられ、「ｓｐｏｏｎ」（スプーン）には［３２］の値が割り当てられ、「ｓｃｉｓｓｏｒｓ」（鋏）には［７９］の値が割り当てられ、「ｇｕｉｔａｒ」（ギター）には［８０］の値が割り当てられている。指標列として表現すると、文字列は８１次元を持つベクトルでワンショット符号化される。つまり、８０個の「０」と、１個の「１」からなるベクトルは、それぞれの文字列を表しており、ベクトル内の「１」の位置は、８１個の文字列のうちのどの文字列に当該ベクトルが関連しているかを示している（つまり、一致するカテゴリーは「１」の値を有しており、それ以外は「０」の値を有している）。例えば、値が［０］の「犬」は、ベクトルの最初の要素で「１」と表され、値が［８０］の「ギター」は、ベクトルの最後の要素で「１」と表される。同様に、値が［３２］の「スプーン」は、ベクトルの３２番目の要素に「１」と表され、値が［７９］の「鋏」は、ベクトルの７９番目の要素に「１」と表される。カテゴリーの数が増えれば（つまり、可能な文字列入力の数が増えれば）、ベクトルの長さも同様に長くなる。例えば、１００万個の可能な入力の場合、ベクトルの長さは１００万個の要素になる。カテゴリーの数が大きくなると、指標列を用いた待ち時間予測モデル２７０の学習が困難になる（計算資源の増加、学習時間の増加など）。
In the example shown, the input string feature may have 81 different string inputs (ie, the input may be equal to any of 81 different strings), 81. A value between [0] and [80] is assigned to each of the character strings of. Of the four illustrated strings, "dog" (dog) is assigned a value of [0], "spoon" (spoon) is assigned a value of [32], and "scissors" (scissors). ) Is assigned the value of [79], and the “guitar” (guitar) is assigned the value of [80]. Expressed as an index string, the character string is one-shot encoded by a vector having 81 dimensions. That is, the vector consisting of 80 "0" s and 1 "1" represents each character string, and the position of "1" in the vector is any character among the 81 character strings. The column indicates whether the vector is related (that is, the matching category has a value of "1", the others have a value of "0"). For example, a "dog" with a value of [0] is represented as "1" in the first element of the vector, and a "guitar" with a value of [80] is represented as "1" in the last element of the vector. .. Similarly, a "spoon" with a value of [32] is represented as "1" in the 32nd element of the vector, and a "scissors" with a value of [79] is represented as "1" in the 79th element of the vector. expressed. As the number of categories increases (that is, the number of possible string inputs increases), so does the length of the vector. For example, for one million possible inputs, the length of the vector would be one million elements. As the number of categories increases, it becomes difficult to learn the waiting
他の実装では、カテゴリー的特徴（すなわち、文字列特徴２０２）は、埋め込み列として表される。埋め込み列は、カテゴライズされたデータを、指標列よりも低次元のベクトルに格納する。埋め込みカラムを使用する場合、図示の例では、８１行のルックアップテーブルが作成される。各行は８１個の可能な入力文字列に対応しており、各行には３個の要素のベクトルが含まれている。ルックアップテーブルは、文字列の特徴ごとに参照される。例えば、値が［０］の「犬」には、ルックアップテーブルの０行目に３個の要素のベクトル（例えば、［０．４２１，０．３９９，０．５１２］）が割り当てられる。同様に、「ギター」の値が［８０］の場合、「ギター」には８０行目に３個の要素のベクトルが割り当てられる（例：［０．７２２，０．６８９，０．２１９］）。ルックアップテーブル内の実際の値は、どのような値であってもよいことが理解される。いくつかの例では、値は学習中に割り当てられる。列を埋め込むことは、入力ベクトルの次元を小さくすることに加えて、カテゴリー値同士間の関係を表現することも可能にする。例えば、「ｐｈｏｎｅｓａｌｅｓ」（電話販売）は、「ａｃｃｏｕｎｔ ｓｕｐｐｏｒｔ」（口座サポート）よりも「ｐｈｏｎｅ ｓｕｐｐｏｒｔ」（電話サポート）に意味的に似ているように割り当てられることがある。 In other implementations, categorical features (ie, string features 202) are represented as embedded columns. The embedded column stores the categorized data in a vector having a lower dimension than the index column. When using embedded columns, a look-up table with 81 rows is created in the illustrated example. Each line corresponds to 81 possible input strings, and each line contains a vector of three elements. The lookup table is referenced for each string feature. For example, a “dog” having a value of [0] is assigned a vector of three elements (for example, [0.421, 0.399, 0.512]) in the 0th row of the lookup table. Similarly, when the value of "guitar" is [80], the vector of three elements is assigned to the "guitar" on the 80th line (example: [0.722,0.689,0.219]). .. It is understood that the actual value in the lookup table can be any value. In some examples, the values are assigned during training. Embedding columns makes it possible to express relationships between category values in addition to reducing the dimensions of the input vector. For example, "phone sales" (telemarketing) may be assigned to be semantically more similar to "phone support" (telemarketing) than "account support" (account support).
図８は、推定待ち時間１３０をユーザ１０に提供するための例示的な方法８００のフローチャートである。方法８００は、図１～図７を参照して説明することができる。方法８００は、データ処理ハードウェア１４４において、顧客１０から保留中サポート要求１２０を受け取ることで、動作８０２で開始する。保留中サポート要求１２０は、アクティブなサポートエージェント２０２ａの数と、利用可能なサポートエージェント２０２ｂの数と、およびキュー深さ２０２ｃとを備えている複数の高レベル特徴２０２に関連付けられる。各アクティブなサポートエージェント２０２ａは、キューイングされたサポート要求１２０を処理することに現在アクティブであり（例えば、保留中サポート要求１２０の受け取り時に）、各利用可能なサポートエージェントは、キューイングされたサポート要求１２０を処理することに現在利用可能である（例えば、保留中サポート要求１２０の受け取り時に、サポート要求１２０を現在サポートしていない）。キュー深さ２０２ｃは、（例えば、保留中サポート要求１２０の受け取り時に）処理されるのを待っているサポート要求１２０の数を示す。
FIG. 8 is a flowchart of an
方法８００は、動作８０４において、データ処理ハードウェア１４４によって、複数の高レベル特徴２０２を特徴入力として受け取るように構成された待ち時間予測モデル２７０を用いて、保留中サポート要求１２０の顧客またはユーザ１０に対する推定待ち時間１３０を予測する工程を備えている。待ち時間予測モデル２７０は学習サポート要求１２０Ｈのコーパスで学習されており、各学習サポート要求１２０Ｈは、対応する複数の高レベル特徴２０２と、対応する実際の待ち時間２０２ｇとを備えている。
方法８００は、動作８０６において、データ処理ハードウェア１４４によって、推定待ち時間１３０を顧客１０に提供する工程を備えている。推定待ち時間１３０は、保留中サポート要求１２０が（例えば、エージェント２３０によって）回答されるまでの推定持続時間を示す。いくつかの実装では、保留中サポート要求１２０に関連付けられた複数の高レベル特徴２０２はさらに、以前のサポート要求１２０Ｈに対する実際の待ち時間２０２ｆと、保留中サポート要求１２０に関連付けられたビジネス識別２０２ｄと、またはビジネス（事業者）に関連付けられたビジネスキュー識別２０２ｅと、のうちの少なくとも１つを備えている。
The
図９は、本明細書に記載されているシステムおよび方法を実施するべく使用され得る例示的なコンピューティング装置９００の概略図である。コンピューティング装置９００は、ラップトップ、デスクトップ、ワークステーション、パーソナルデジタルアシスタント、サーバ、ブレードサーバ、メインフレーム、および他の適切なコンピュータなど、様々な形態のデジタルコンピュータを表すことを意図している。ここに示されている構成要素、それらの接続と関係、およびそれらの機能は、例示的なものであることを意図しており、本書に記載および／または請求されている発明の実施を制限することを意図していない。
FIG. 9 is a schematic representation of an
コンピューティング装置９００は、プロセッサ９１０と、メモリ９２０と、ストレージ装置９３０と、メモリ９２０および高速拡張ポート９５０に接続する高速インタフェース／コントローラ９４０と、および低速バス９７０およびストレージ装置９３０に接続する低速インタフェース／コントローラ９６０とを備えている。構成要素９１０、９２０、９３０、９４０、９５０、９６０のそれぞれは、様々なバスを用いて相互に接続されており、共通のマザーボードに搭載されていてもよいし、適宜他の態様で搭載されていてもよい。プロセッサ９１０は、高速インタフェース９４０に結合されたディスプレイ９８０などの外部入出力装置にグラフィカルユーザインタフェース（ＧＵＩ）のためのグラフィカル情報を表示するべく、メモリ９２０またはストレージ装置９３０に格納された命令を備えている、コンピューティング装置９００内で実行するための命令を処理することができる。他の実装では、複数のプロセッサおよび／または複数のバスが、複数のメモリおよびメモリの種類とともに、適宜使用されてもよい。また、複数のコンピューティング装置９００が接続され、各装置が必要な動作の一部を提供してもよい（例えば、サーババンク、ブレードサーバグループ、またはマルチプロセッサシステムとして）。
The
メモリ９２０は、コンピューティング装置９００内の情報を非一時的に格納する。メモリ９２０は、コンピュータ読取可能媒体、揮発性メモリユニット（複数可）、または不揮発性メモリユニット（複数可）であってもよい。不揮発性メモリ９２０は、コンピューティング装置９００による使用をするべく、プログラム（例えば、命令のシーケンス）またはデータ（例えば、プログラム状態情報）を一時的または永久的に格納するべく使用される物理装置であってもよい。不揮発性メモリの例としては、フラッシュメモリおよびリードオンリーメモリ（ＲＯＭ）／プログラマブルリードオンリーメモリ（ＰＲＯＭ）／消去可能プログラマブルリードオンリーメモリ（ＥＰＲＯＭ）／電子的消去可能プログラマブルリードオンリーメモリ（ＥＥＰＲＯＭ）（例えば、ブートプログラムなどのファームウェアに典型的に使用される）などが挙げられるが、これらに限定されない。揮発性メモリの例としては、ＲＡＭ（ＲａｎｄｏｍＡｃｃｅｓｓ Ｍｅｍｏｒｙ）、ＤＲＡＭ（ＤｙｎａｍｉｃＲａｎｄｏｍ Ａｃｃｅｓｓ Ｍｅｍｏｒｙ）、ＳＲＡＭ（Ｓｔａｔｉｃ Ｒａｎｄｏｍ Ａｃｃｅｓｓ Ｍｅｍｏｒｙ）、ＰＣＭ（Ｐｈａｓｅ Ｃｈａｎｇｅ Ｍｅｍｏｒｙ）のほか、ディスクやテープなどが挙げられるが、これらに限定されるものではない。
The
ストレージ装置９３０は、コンピューティング装置９００に大容量記憶を提供することができる。いくつかの実施態様において、ストレージ装置９３０は、コンピュータ読取可能媒体である。様々な異なる実装において、ストレージ装置９３０は、フロッピー（登録商標）ディスク装置、ハードディスク装置、光ディスク装置、またはテープ装置、フラッシュメモリまたは他の類似のソリッドステートメモリ装置、または、ストレージエリアネットワークまたは他の構成の装置を備えている装置のアレイであってもよい。追加の実装では、コンピュータプログラム製品が、情報キャリア（担体）に有形的に具現化される。コンピュータプログラム製品は、実行されると上述したような１つまたは複数の方法を実行する命令を備えている。情報キャリアは、メモリ９２０、ストレージ装置９３０、またはプロセッサ９１０上のメモリなどの、コンピュータ読取可能媒体または機械読取可能媒体である。
The
高速コントローラ９４０は、コンピューティング装置９００のための帯域幅集中型の動作を管理し、低速コントローラ９６０は、より低い帯域幅集中型の動作を管理する。このような職務の割り当ては、例示的なものに過ぎない。いくつかの実装では、高速コントローラ９４０は、メモリ９２０に、ディスプレイ９８０（例えば、グラフィックプロセッサまたはアクセラレータを介して）に、および、様々な拡張カード（図示せず）を受け入れ得る高速拡張ポート９５０に結合される。いくつかの実装では、低速コントローラ９６０は、ストレージ装置９３０および低速拡張ポート９９０に結合される。様々な通信ポート（例えば、ＵＳＢ、Ｂｌｕｅｔｏｏｔｈ（登録商標）、イーサネット（登録商標）、ワイヤレスイーサネット（登録商標））を備えてもよい低速拡張ポート９９０は、キーボード、ポインティング装置、スキャナ、またはスイッチやルータなどのネットワーク装置などの１つまたは複数の入出力装置に、例えば、ネットワークアダプタを介して結合されてもよい。
The
コンピューティング装置９００は、図に示すように、いくつかの異なる形態で実装されてもよい。例えば、標準的なサーバ９００ａとして、またはそのようなサーバ９００ａのグループ内の複数倍として、ラップトップコンピュータ９００ｂとして、またはラックサーバシステム９００ｃの一部として実装されてもよい。
The
本明細書に記載のシステムおよび技術の様々な実装は、デジタル電子および／または光学回路、集積回路、特別に設計されたＡＳＩＣ（特定用途向け集積回路）、コンピュータハードウェア、ファームウェア、ソフトウェア、および／またはそれらの組み合わせで実現することができる。これらの様々な実装には、ストレージ装置、少なくとも１つの入力装置、および少なくとも１つの出力装置からデータおよび命令を受け取るとともに、それら装置にデータおよび命令を送信するように結合された、特殊用途または汎用用途の少なくとも１つのプログラマブルプロセッサを備えているプログラマブルシステム上で実行可能および／または解釈可能な１つまたは複数のコンピュータプログラムでの実装が含まれ得る。 Various implementations of the systems and techniques described herein include digital electronic and / or optical circuits, integrated circuits, specially designed ASICs (application specific integrated circuits), computer hardware, firmware, software, and /. Or it can be realized by a combination of them. These various implementations are special purpose or general purpose combined to receive data and instructions from a storage device, at least one input device, and at least one output device and send data and instructions to those devices. Implementations in one or more computer programs that are runnable and / or interpretable on a programmable system with at least one programmable processor for the application may be included.
ソフトウェアアプリケーション（すなわち、ソフトウェアリソース）は、コンピューティング装置にタスクを実行させるコンピュータソフトウェアを指すことがある。いくつかの例では、ソフトウェアアプリケーションは、「アプリケーション」、「アプリ」、または「プログラム」と呼ばれることがある。アプリケーションの例としては、システム診断アプリケーション、システム管理アプリケーション、システムメンテナンスアプリケーション、ワープロアプリケーション、表計算アプリケーション、メッセージングアプリケーション、媒体ストリーミングアプリケーション、ソーシャルネットワーキングアプリケーション、ゲームアプリケーションなどがあるが、これらに限定されるものではない。 Software applications (ie, software resources) may refer to computer software that causes a computing device to perform a task. In some examples, software applications may be referred to as "applications," "apps," or "programs." Examples of applications include, but are not limited to, system diagnostic applications, system management applications, system maintenance applications, word processing applications, table computing applications, messaging applications, media streaming applications, social networking applications, gaming applications, etc. do not have.
これらのコンピュータプログラム（プログラム、ソフトウェア、ソフトウェアアプリケーションまたはコードとも呼ばれる）は、プログラム可能なプロセッサのための機械命令を備えており、高レベルの手続き型および／またはオブジェクト指向のプログラミング言語、および／またはアセンブリ／機械言語で実装することができる。本明細書において、「機械読取可能媒体」および「コンピュータ読取可能媒体」という用語は、機械読取可能信号として機械命令を受け取る機械読取可能媒体を備えている、機械命令および／またはデータをプログラマブルプロセッサに提供するべく使用される任意のコンピュータプログラム製品、非一時的なコンピュータ読取可能媒体、アパレイタスおよび／または装置（例えば、磁気ディスク、光ディスク、メモリ、プログラマブルロジック装置（ＰＬＤ））を意味する。「機械読取可能信号」という用語は、機械命令および／またはデータをプログラマブルプロセッサに提供するべく使用される任意の信号を指す。 These computer programs (also called programs, software, software applications or codes) include machine instructions for programmable processors, high-level procedural and / or object-oriented programming languages, and / or assemblies. / Can be implemented in machine language. As used herein, the terms "machine readable medium" and "computer readable medium" include machine readable media that receive machine commands as machine readable signals, to a programmable processor for machine instructions and / or data. It means any computer program product, non-temporary computer readable medium, apparator and / or device (eg, magnetic disk, optical disk, memory, programmable logic device (PLD)) used to provide. The term "machine readable signal" refers to any signal used to provide machine instructions and / or data to a programmable processor.
本明細書に記載されている処理および論理フローは、データ処理ハードウェアとも呼ばれる１つまたは複数のプログラマブルプロセッサが、１つまたは複数のコンピュータプログラムを実行して、入力データを操作して出力を生成することで機能を実行することができる。また、ＦＰＧＡ（ＦｉｅｌｄＰｒｏｇｒａｍｍａｂｌｅ ＧａｔｅＡｒｒａｙ）やＡＳＩＣ（Ａｐｐｌｉｃａｔｉｏｎ Ｓｐｅｃｉｆｉｃ Ｉｎｔｅｇｒａｔｅｄ Ｃｉｒｃｕｉｔ）などの特殊な論理回路によっても処理や論理フローを実行することができる。コンピュータプログラムの実行に適したプロセッサには、一例として、汎用および特殊目的のマイクロプロセッサの両方、および任意の種類のデジタルコンピュータの任意の１つまたは複数のプロセッサが含まれる。一般に、プロセッサは、読み取り専用メモリまたはランダムアクセスメモリ、あるいはその両方から命令とデータを受け取る。コンピュータの本質的な要素は、命令を実行するためのプロセッサと、命令やデータを格納するための１つまたは複数のメモリ装置である。一般に、コンピュータは、データを格納するための１つまたは複数の大容量ストレージ装置、例えば、磁気ディスク、光磁気ディスク、または光ディスクを備えているか、またはそれらからデータを受け取るか、またはデータを転送するようにそれらに動作可能に結合されるか、または両方である。しかし、コンピュータはそのような装置を持っている必要はない。コンピュータプログラムの命令やデータを格納するのに適したコンピュータ読取可能媒体には、あらゆる形態の不揮発性メモリ、媒体、およびメモリ装置が含まれ、例として、半導体メモリ装置、例えばＥＰＲＯＭ、ＥＥＰＲＯＭ、およびフラッシュメモリ装置、磁気ディスク、例えば内蔵ハードディスクまたはリムーバブルディスク、光磁気ディスク、およびＣＤ－ＲＯＭおよびＤＶＤ－ＲＯＭディスクが挙げられる。プロセッサとメモリは、特別な目的の論理回路によって補完されるか、またはそれに組み込まれることができる。 The processing and logical flows described herein are such that one or more programmable processors, also referred to as data processing hardware, run one or more computer programs to manipulate the input data and produce output. You can execute the function by doing. Further, the processing and the logical flow can be executed by a special logic circuit such as FPGA (Field Programmable Gate Array) or ASIC (Application Specific Integrated Circuit). Suitable processors for running computer programs include, for example, both general purpose and special purpose microprocessors, and any one or more processors of any type of digital computer. In general, processors receive instructions and data from read-only memory and / or random access memory. The essential elements of a computer are a processor for executing instructions and one or more memory devices for storing instructions and data. In general, a computer has or has one or more mass storage devices for storing data, such as magnetic disks, magneto-optical disks, or optical disks, or receives or transfers data from them. They are operably coupled to them, or both. However, the computer does not have to have such a device. Computer-readable media suitable for storing computer program instructions and data include all forms of non-volatile memory, media, and memory devices, such as semiconductor memory devices such as EPROM, EEPROM, and flash. Examples include memory devices, magnetic disks, such as internal hard disks or removable disks, magneto-optical disks, and CD-ROMs and DVD-ROM disks. Processors and memory can be complemented or incorporated into logic circuits of special purpose.
ユーザとのインタラクションを提供するべく、本開示の１つまたは複数の態様は、ユーザに情報を表示するためのディスプレイ装置、例えばＣＲＴ（ｃａｔｈｏｄｅｒａｙ ｔｕｂｅ）、ＬＣＤ（ｌｉｑｕｉｄｃｒｙｓｔａｌ ｄｉｓｐｌａｙ）モニタ、またはタッチスクリーンと、任意でユーザがコンピュータに入力を提供することができるキーボードおよびポインティング装置、例えばマウスまたはトラックボールとを有するコンピュータ上で実装することができる。ユーザとのインタラクションを提供するべく同様に他の種類の装置が使用されることができ、例えば、ユーザに提供されるフィードバックは、視覚的なフィードバック、聴覚的なフィードバック、触覚的なフィードバックなど、あらゆる形態の感覚的なフィードバックであり、ユーザからの入力は、音響的な入力、音声的な入力、触覚的な入力など、あらゆる形態で受け取ることができる。さらに、コンピュータは、ユーザが使用する装置にドキュメントを送信したり、装置からドキュメントを受け取ったりすることで、ユーザと対話することができる。例えば、ユーザのクライアント装置上のウェブブラウザに、ウェブブラウザから受け取った要求に応じてウェブページを送信することができる。 In order to provide interaction with the user, one or more aspects of the present disclosure include a display device for displaying information to the user, such as a CRT (catalysis tube), an LCD (liquid crystal display) monitor, or a touch screen. It can optionally be implemented on a computer with a keyboard and pointing device, such as a mouse or trackball, on which the user can provide input to the computer. Other types of devices can be used as well to provide interaction with the user, for example, the feedback provided to the user may be visual feedback, auditory feedback, tactile feedback, etc. It is a form of sensory feedback, and the input from the user can be received in any form such as acoustic input, audio input, and tactile input. In addition, the computer can interact with the user by sending and receiving documents from the device used by the user. For example, a web page can be sent to a web browser on a user's client device in response to a request received from the web browser.
多数の実施例を説明してきた。それにもかかわらず、本開示の精神および範囲から逸脱することなく、様々な変更を行うことができることが理解されるであろう。したがって、他の実施態様は、以下の請求項の範囲内にある。 Many examples have been described. Nevertheless, it will be appreciated that various changes can be made without departing from the spirit and scope of this disclosure. Therefore, other embodiments are within the scope of the following claims.
Claims (24)
アクティブなサポートエージェント（２０２ａ）の数であって、各アクティブなサポートエージェント（２０２ａ）は、キューイングされたサポート要求（１２０）を処理する際に現在アクティブである、前記アクティブなサポートエージェント（２０２ａ）の数と、
利用可能なサポートエージェント（２０２ｂ）の数であって、各利用可能なサポートエージェント（２０２ｂ）は、キューに入れられたサポート要求（１２０）を処理するべく現在利用可能である、前記利用可能なサポートエージェント（２０２ｂ）の数と、および
処理されるのを待っているサポート要求（１２０）の数を示すキュー（４００）の深さと、
を備えている、前記保留中サポート要求（１２０）を受け取る工程と、
前記データ処理ハードウェア（１４４）によって、前記複数の高レベル特徴（２０２）を特徴入力として受け取るように構成された待ち時間予測モデル（２７０）を使用して、前記保留中サポート要求（１２０）の前記ユーザ（１０）に対する推定待ち時間（１３０）を予測する工程であって、前記待ち時間予測モデル（２７０）は学習サポート要求（１２０Ｈ）のコーパスで学習されており、各学習サポート要求（１２０Ｈ）は、対応する複数の高レベル特徴（２０２）と、対応する実際の待ち時間（２０２ｇ）とを備えている、前記推定待ち時間（１３０）を予測する工程と、および
前記データ処理ハードウェア（１４４）によって、前記推定待ち時間（１３０）を前記ユーザ（１０）に提供する工程であって、前記推定待ち時間（１３０）は、前記保留中サポート要求（１２０）に回答するまでの推定持続時間を示す、前記推定待ち時間（１３０）を提供する工程と、
を備えている、方法（８００）。 In the data processing hardware (144), a step of receiving a pending support request (120) from a user (10), said pending support request (120) being associated with a plurality of high level features (202). , The plurality of high-level features (202)
The number of active support agents (202a), wherein each active support agent (202a) is currently active in processing the queued support request (120), said active support agent (202a). And the number of
The number of available support agents (202b), wherein each available support agent (202b) is currently available to process the queued support request (120), said available support. The depth of the queue (400), which indicates the number of agents (202b) and the number of support requests (120) waiting to be processed.
And the process of receiving the pending support request (120).
The pending support request (120) using a latency prediction model (270) configured by the data processing hardware (144) to receive the plurality of high-level features (202) as feature inputs. In the step of predicting the estimated waiting time (130) for the user (10), the waiting time prediction model (270) is learned by the corpus of the learning support request (120H), and each learning support request (120H). The step of predicting the estimated latency (130) and the data processing hardware (144) comprising the corresponding plurality of high-level features (202) and the corresponding actual latency (202 g). ) To provide the estimated waiting time (130) to the user (10), wherein the estimated waiting time (130) determines the estimated duration until the pending support request (120) is answered. The step of providing the estimated waiting time (130), which is shown,
The method (800).
以前に回答されたサポート要求（１２０）に対する実際の待ち時間（２０２ｇ）と、
前記保留中サポート要求（１２０）に関連付けられたビジネスの識別であるビジネス識別（２０２ｄ）と、または
前記ビジネスに関連付けられたビジネスキュー識別（２０２ｅ）と、
のうちの少なくとも１つを備えている、
請求項１に記載の方法（８００）。 The plurality of high-level features (202) associated with the pending support request (120) further include.
The actual waiting time (202g) for the previously answered support request (120) and
The business identification (202d), which is the identification of the business associated with the pending support request (120), or the business queue identification (202e) associated with the business.
Has at least one of
The method according to claim 1 (800).
前記保留中サポート要求（１２０）が受け取られた一日のうちの時間帯を示す、一日のうちの時間帯表示（２０２ｎ）と、または
それぞれの前記ビジネス識別（２０２ｄ）とそれぞれの前記ビジネスキュー識別（２０２ｅ）とに関連付けられたサポートエージェント（２３０）が、対応するサポート要求（１２０）を完了するのにかかる平均時間量を代表する、平均解決時間と、
のうちの少なくとも１つを備えている、
請求項２に記載の方法（８００）。 The plurality of high-level features (202) are further enhanced.
A time zone display (202n) of the day indicating the time zone of the day when the pending support request (120) was received, or each said business identification (202d) and each said business queue. An average resolution time and an average resolution time, which represents the average amount of time it takes for the support agent (230) associated with the identification (202e) to complete the corresponding support request (120).
Has at least one of
The method according to claim 2 (800).
請求項１～３のいずれか一項に記載の方法（８００）。 Each learning support request (120H) in the corpus of said learning support request (120H) comprises a plurality of historical support requests (120H) previously processed by the data processing hardware (144).
The method according to any one of claims 1 to 3 (800).
請求項４に記載の方法（８００）。 The latency prediction model (270) uses the corresponding high-level features (202) and the corresponding actual latency (202 g) for each of the configurable frequency of historical support requests (120). , Learned at the configurable frequency,
The method according to claim 4 (800).
請求項５に記載の方法（８００）。 The configurable frequency is once a day.
The method according to claim 5 (800).
前記データ処理ハードウェア（１４４）によって、前記ユーザ（１０）の実際の待ち時間（２０２ｇ）を決定する工程であって、前記実際の待ち時間（２０２ｇ）は、前記保留中サポート要求（１２０）が受け取られたときから、前記ユーザ（１０）が前記保留中サポート要求（１２０）に対する回答（１２２）を受け取るまでの実際の持続時間を示す、前記実際の待ち時間（２０２ｇ）を決定する工程と、
前記データ処理ハードウェア（１４４）によって、前記保留中サポート要求（１２０）に対する前記実際の待ち時間（２０２ｇ）を使用して、前記待ち時間予測モデル（２７０）を調整する工程と、
を備えている、請求項１～６のいずれか一項に記載の方法（８００）。 After the pending support request (120) has been answered, the method (800) further
In the step of determining the actual waiting time (202 g) of the user (10) by the data processing hardware (144), the actual waiting time (202 g) is determined by the pending support request (120). A step of determining the actual waiting time (202 g), which indicates the actual duration from the time it is received until the user (10) receives the response (122) to the pending support request (120).
A step of adjusting the wait time prediction model (270) by the data processing hardware (144) using the actual wait time (202 g) for the pending support request (120).
The method according to any one of claims 1 to 6, comprising the method (800).
前記データ処理ハードウェア（１４４）によって、前記待ち時間予測モデル（２７０）によって予測された推定待ち時間（１３０）と、実際の待ち時間（２０２ｇ）とに基づき、前記待ち時間予測モデル（２７０）の損失（５２０）を決定する工程と、
前記データ処理ハードウェア（１４４）によって、前記損失（５２０）が、以前に学習されたモデル（２７０）の損失（５２０）と比較して、閾値を満たすかどうかを判定する工程と、
前記データ処理ハードウェア（１４４）によって、前記損失（５２０）が前記閾値を満たす場合に、前記以前に学習されたモデル（２７０）に戻す工程と
を備えている、請求項７に記載の方法（８００）。 The method further
The waiting time prediction model (270) based on the estimated waiting time (130) predicted by the waiting time prediction model (270) by the data processing hardware (144) and the actual waiting time (202 g). The process of determining the loss (520) and
A step of determining whether the loss (520) meets the threshold by the data processing hardware (144) as compared to the loss (520) of the previously trained model (270).
The method of claim 7, wherein the data processing hardware (144) comprises a step of returning to the previously trained model (270) when the loss (520) meets the threshold. 800).
請求項８に記載の方法（８００）。 The step of determining the loss (520) comprises a step of using a mean square error.
The method according to claim 8 (800).
請求項１～９のいずれか一項に記載の方法（８００）。 The waiting time prediction model (270) includes a neural network.
The method (800) according to any one of claims 1 to 9.
請求項１０に記載の方法（８００）。 The neural network includes a regression deep neural network.
The method according to claim 10 (800).
請求項１０または１１に記載の方法（８００）。 The neural network includes a deep neural network having a first hidden layer and a second hidden layer.
The method according to claim 10 or 11 (800).
前記データ処理ハードウェア（１４４）に通信するメモリハードウェア（９２０）であって、前記メモリハードウェア（９２０）は、前記データ処理ハードウェア（１４４）上で実行されたときに、前記データ処理ハードウェア（１４４）に動作を実行させる命令を格納する、前記メモリハードウェア（９２０）と、
を備えているシステム（１００）であって、前記動作は、
ユーザ（１０）から保留中サポート要求（１２０）を受け取る工程であって、前記保留中サポート要求（１２０）は複数の高レベル特徴（２０２）に関連付けられており、前記複数の高レベル特徴（２０２）は、
アクティブなサポートエージェント（２０２ａ）の数であって、各アクティブなサポートエージェント（２０２ａ）は、キューイングされたサポート要求（１２０）を処理するべく現在アクティブである、前記アクティブなサポートエージェント（２０２ａ）の数と、
利用可能なサポートエージェント（２０２ｂ）の数であって、各利用可能なサポートエージェント（２０２ｂ）は、キューに入れられたサポート要求（１２０）を処理するべく現在利用可能である、前記利用可能なサポートエージェント（２０２ｂ）の数と、および
処理されるのを待っているサポート要求（１２０）の数を示すキュー（４００）深さと、を備えている、前記保留中サポート要求（１２０）を受け取る工程と、
前記複数の高レベル特徴（２０２）を特徴入力として受け取るように構成された待ち時間予測モデル（２７０）を使用して、前記保留中サポート要求（１２０）の前記ユーザ（１０）に対する推定待ち時間（１３０）を予測する工程であって、前記待ち時間予測モデル（２７０）は学習サポート要求（１２０Ｈ）のコーパスで学習され、各学習サポート要求（１２０Ｈ）は、対応する複数の高レベル特徴（２０２）と、対応する実際の待ち時間（２０２ｇ）とを備えている、前記推定待ち時間（１３０）を予測する工程と、および
前記推定待ち時間（１３０）を前記ユーザ（１０）に提供する工程であって、前記推定待ち時間（１３０）は、前記保留中サポート要求（１２０）に回答するまでの推定持続時間を示す、前記推定待ち時間（１３０）を提供する工程と、
を備えている、システム（１００）。 The data processing hardware (144) and the memory hardware (920) that communicates with the data processing hardware (144), wherein the memory hardware (920) is on the data processing hardware (144). The memory hardware (920), which stores an instruction to cause the data processing hardware (144) to execute an operation when executed, and the memory hardware (920).
The system (100) is equipped with the above-mentioned operation.
In the process of receiving a pending support request (120) from a user (10), the pending support request (120) is associated with a plurality of high-level features (202) and the plurality of high-level features (202). )teeth,
The number of active support agents (202a), each active support agent (202a) of said active support agent (202a) currently active to process the queued support request (120). Number and
The number of available support agents (202b), wherein each available support agent (202b) is currently available to process the queued support request (120), said available support. A step of receiving said pending support request (120), comprising a number of agents (202b) and a queue (400) depth indicating the number of support requests (120) waiting to be processed. ,
An estimated wait time (10) for the user (10) of the pending support request (120) using a wait time prediction model (270) configured to receive the plurality of high-level features (202) as feature inputs. In the process of predicting 130), the wait time prediction model (270) is trained by a corpus of learning support requests (120H), and each learning support request (120H) has a plurality of corresponding high-level features (202). A step of predicting the estimated waiting time (130), which comprises a corresponding actual waiting time (202 g), and a step of providing the estimated waiting time (130) to the user (10). The estimated waiting time (130) is the step of providing the estimated waiting time (130), which indicates the estimated duration until the pending support request (120) is answered.
The system (100).
以前に回答されたサポート要求（１２０）に対する実際の待ち時間（２０２ｇ）と、
前記保留中サポート要求（１２０）に関連付けられたビジネスの識別であるビジネス識別（２０２ｄ）と、または
前記ビジネスに関連付けられたビジネスキュー識別（２０２ｅ）と、
のうちの少なくとも１つを備えている、
請求項１３に記載のシステム（１００）。 The plurality of high-level features (202) associated with the pending support request (120) further include.
The actual waiting time (202g) for the previously answered support request (120) and
The business identification (202d), which is the identification of the business associated with the pending support request (120), or the business queue identification (202e) associated with the business.
Has at least one of
The system (100) according to claim 13.
一日のうちの時間帯表示（２０２ｎ）であって、前記保留中サポート要求（１２０）が受け取られた一日のうちの時間帯を示す、一日のうちの時間帯表示（２０２ｎ）と、または
平均解決時間であって、それぞれの前記ビジネス識別（２０２ｄ）およびそれぞれの前記ビジネスキュー識別に関連付けられたサポートエージェント（２３０）が、対応するサポート要求（１２０）を完了するのにかかる平均時間量を代表する、前記平均解決時間と、
のうちの少なくとも１つを備えている、
請求項１４に記載のシステム（１００）。 The plurality of high-level features (202) are further enhanced.
The time zone display (202n) of the day, which indicates the time zone of the day when the pending support request (120) is received, and the time zone display (202n) of the day. Or the average resolution time, the average amount of time it takes for each said business identification (202d) and the support agent (230) associated with each said business queue identification to complete the corresponding support request (120). The average resolution time and
Has at least one of
The system (100) according to claim 14.
請求項１３～１５のいずれか一項に記載のシステム（１００）。 Each learning support request (120H) in the corpus of said learning support request (120H) comprises a plurality of historical support requests (120H) previously processed by the data processing hardware (144).
The system (100) according to any one of claims 13 to 15.
請求項１６に記載のシステム（１００）。 The latency prediction model (270) uses the corresponding high-level features (202) and the corresponding actual latency (202 g) for each of the configurable frequency of historical support requests (120). , Learned at the configurable frequency,
The system (100) according to claim 16.
請求項１７に記載のシステム（１００）。 The configurable frequency is once a day.
The system (100) according to claim 17.
前記ユーザ（１０）に対する実際の待ち時間（２０２ｇ）を決定する工程であって、前記実際の待ち時間（２０２ｇ）は、前記保留中サポート要求（１２０）が受け取られたときから、前記保留中サポート要求（１２０）に対する回答（１２２）を前記ユーザ（１０）が受け取るまでの実際の持続時間を示す、前記実際の待ち時間（２０２ｇ）を決定する工程と、
前記保留中サポート要求（１２０）に対する前記実際の待ち時間（２０２ｇ）を用いて、前記待ち時間予測モデル（２７０）を調整する工程と、
を備えている、請求項１３～１８のいずれか一項に記載のシステム（１００）。 After the pending support request (120) has been answered, the operation further
In the step of determining the actual waiting time (202 g) for the user (10), the actual waiting time (202 g) is the pending support from the time when the pending support request (120) is received. A step of determining the actual waiting time (202 g), which indicates the actual duration until the user (10) receives the response (122) to the request (120).
A step of adjusting the waiting time prediction model (270) using the actual waiting time (202 g) for the pending support request (120).
The system (100) according to any one of claims 13 to 18.
前記待ち時間予測モデル（２７０）によって予測された前記推定待ち時間（１３０）と、前記実際の待ち時間（２０２ｇ）とに基づき、前記待ち時間予測モデル（２７０）の損失（５２０）を決定する工程と、
前記損失（５２０）が、以前に学習されたモデル（２７０）の損失（５２０）と比較して、閾値を満たすかどうかを判定する工程と、
前記損失（５２０）が前記閾値を満たす場合に、以前に学習されたモデル（２７０）に戻す工程と、
を備えている、請求項１９に記載のシステム（１００）。 The above operation further
A step of determining a loss (520) of the waiting time prediction model (270) based on the estimated waiting time (130) predicted by the waiting time prediction model (270) and the actual waiting time (202 g). When,
A step of determining whether the loss (520) satisfies the threshold value as compared with the loss (520) of the previously trained model (270).
When the loss (520) satisfies the threshold value, the step of returning to the previously trained model (270) and the process of returning to the previously learned model (270).
The system (100) according to claim 19.
請求項２０に記載のシステム（１００）。 The step of determining the loss (520) comprises a step of using a mean square error.
The system (100) according to claim 20.
請求項１３～２１のいずれか一項に記載のシステム（１００）。 The waiting time prediction model (270) includes a neural network.
The system (100) according to any one of claims 13 to 21.
請求項２２に記載のシステム（１００）。 The neural network includes a regression deep neural network.
The system (100) according to claim 22.
請求項２２または２３に記載のシステム（１００）。 The neural network includes a deep neural network having a first hidden layer and a second hidden layer.
The system (100) according to claim 22 or 23.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US16/390,409 | 2019-04-22 | ||
US16/390,409 US20200334615A1 (en) | 2019-04-22 | 2019-04-22 | Predicting Business-Agnostic Contact Center Expected Wait Times With Deep Neural Networks |
PCT/US2019/064748 WO2020219108A1 (en) | 2019-04-22 | 2019-12-05 | Predicting business-agnostic contact center expected wait times with deep neural networks |
Publications (1)
Publication Number | Publication Date |
---|---|
JP2022529803A true JP2022529803A (en) | 2022-06-24 |
Family
ID=69006061
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2021562800A Withdrawn JP2022529803A (en) | 2019-04-22 | 2019-12-05 | Prediction of expected waiting time for business-agnostic contact centers using deep neural networks |
Country Status (6)
Country | Link |
---|---|
US (1) | US20200334615A1 (en) |
EP (1) | EP3959671A1 (en) |
JP (1) | JP2022529803A (en) |
KR (1) | KR20210154831A (en) |
CN (1) | CN113748437A (en) |
WO (1) | WO2020219108A1 (en) |
Families Citing this family (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11611658B2 (en) | 2009-01-28 | 2023-03-21 | Virtual Hold Technology Solutions, Llc | System and method for adaptive cloud conversation platform |
US11475327B2 (en) * | 2019-03-12 | 2022-10-18 | Swampfox Technologies, Inc. | Apparatus and method for multivariate prediction of contact center metrics using machine learning |
US11190643B1 (en) * | 2020-07-30 | 2021-11-30 | Bank Of America Corporation | Automated redistribution of queries to underutilized channels |
EP4260548A1 (en) * | 2020-12-08 | 2023-10-18 | Genesys Cloud Services Holdings II, LLC. | Method and system for robust wait time estimation in a multi-skilled contact center with abandonment |
CN116508016A (en) | 2021-01-29 | 2023-07-28 | 三星电子株式会社 | Electronic device for determining time of maintaining conversation of chat robot and operation method thereof |
KR20220109895A (en) * | 2021-01-29 | 2022-08-05 | 삼성전자주식회사 | The electronic device for determining session time of chatbot and the method for operating the same |
-
2019
- 2019-04-22 US US16/390,409 patent/US20200334615A1/en not_active Abandoned
- 2019-12-05 WO PCT/US2019/064748 patent/WO2020219108A1/en unknown
- 2019-12-05 JP JP2021562800A patent/JP2022529803A/en not_active Withdrawn
- 2019-12-05 CN CN201980095740.9A patent/CN113748437A/en active Pending
- 2019-12-05 KR KR1020217037551A patent/KR20210154831A/en not_active Application Discontinuation
- 2019-12-05 EP EP19828131.3A patent/EP3959671A1/en not_active Withdrawn
Also Published As
Publication number | Publication date |
---|---|
KR20210154831A (en) | 2021-12-21 |
CN113748437A (en) | 2021-12-03 |
EP3959671A1 (en) | 2022-03-02 |
WO2020219108A1 (en) | 2020-10-29 |
US20200334615A1 (en) | 2020-10-22 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
JP2022529803A (en) | Prediction of expected waiting time for business-agnostic contact centers using deep neural networks | |
US10762113B2 (en) | Conversational knowledge graph powered virtual assistant for application performance management | |
US11223723B2 (en) | Call center system having reduced communication latency | |
US10742813B2 (en) | Semantic artificial intelligence agent | |
EP3913545A2 (en) | Method and apparatus for updating parameter of multi-task model, and electronic device | |
US10943070B2 (en) | Interactively building a topic model employing semantic similarity in a spoken dialog system | |
US10582055B2 (en) | System and method for managing contact center system | |
US11176472B2 (en) | Chat delta prediction and cognitive opportunity system | |
US11475207B2 (en) | Subject line tester | |
EP3614264B1 (en) | Performance engineering | |
US11790894B2 (en) | Machine learning based models for automatic conversations in online systems | |
CN113519000A (en) | System for multi-angle discussion within a conversation | |
CN110688401A (en) | Dynamic cache processing method and device, storage medium and electronic equipment | |
US10380150B2 (en) | Identifying user expectations in question answering | |
US11463328B2 (en) | Training a machine learning algorithm to create survey questions | |
US20180217855A1 (en) | Estimating wait times for requests | |
US20210209168A1 (en) | Natural language interaction based data analytics | |
CN111368195A (en) | Model training method, device, equipment and storage medium | |
US20220366427A1 (en) | Systems and methods relating to artificial intelligence long-tail growth through gig customer service leverage | |
CN109829744A (en) | Consultation method, device, electronic equipment and medium based on natural language processing | |
US11810022B2 (en) | Contact center call volume prediction | |
CN116703046A (en) | Control method and system for real-time dispatching sequence, electronic equipment and storage medium | |
CA3119490A1 (en) | Contact center call volume prediction | |
CN111291957A (en) | Method and device for generating customer service scheduling information, electronic equipment and storage medium | |
CN113420227B (en) | Training method of click rate estimation model, click rate estimation method and device |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
A621 | Written request for application examination |
Free format text: JAPANESE INTERMEDIATE CODE: A621Effective date: 20211117 |
|
A761 | Written withdrawal of application |
Free format text: JAPANESE INTERMEDIATE CODE: A761Effective date: 20220913 |