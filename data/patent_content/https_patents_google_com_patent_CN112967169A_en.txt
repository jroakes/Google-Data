CN112967169A - Data sheet generator for image generator - Google Patents
Data sheet generator for image generator Download PDFInfo
- Publication number
- CN112967169A CN112967169A CN202110171547.8A CN202110171547A CN112967169A CN 112967169 A CN112967169 A CN 112967169A CN 202110171547 A CN202110171547 A CN 202110171547A CN 112967169 A CN112967169 A CN 112967169A
- Authority
- CN
- China
- Prior art keywords
- data
- slice
- image data
- input
- shift register
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
Images
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N1/00—Scanning, transmission or reproduction of documents or the like, e.g. facsimile transmission; Details thereof
- H04N1/32—Circuits or arrangements for control or supervision between transmitter and receiver or between image input and image output device, e.g. between a still-image camera and its memory or between a still-image camera and a printer device
- H04N1/32101—Display, printing, storage or transmission of additional information, e.g. ID code, date and time or title
-
- B—PERFORMING OPERATIONS; TRANSPORTING
- B41—PRINTING; LINING MACHINES; TYPEWRITERS; STAMPS
- B41F—PRINTING MACHINES OR PRESSES
- B41F15/00—Screen printers
- B41F15/08—Machines
- B41F15/0804—Machines for printing sheets
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T1/00—General purpose image data processing
- G06T1/20—Processor architectures; Processor configuration, e.g. pipelining
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T1/00—General purpose image data processing
- G06T1/60—Memory management
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T2200/00—Indexing scheme for image data processing or generation, in general
- G06T2200/28—Indexing scheme for image data processing or generation, in general involving image processing hardware
Abstract
A data sheet generator for an image generator is disclosed. A data slice generator circuit is described herein. The sheet generator includes electronic circuitry to receive a line group of image data including a plurality of lines of data from a frame of image data. The plurality of rows is sufficient in number to contain a plurality of adjacent overlapping stencils. The electronic circuitry parses the line set into smaller sized pieces of data. The electronic circuitry loads the piece of data into a data computation unit having a two-dimensional shift array structure coupled to a processor array.
Description
The present application is a divisional application, the original application number is 201680019786.9, the application date is 2016, 4 and 4, and the invention name is "data sheet generator for image generator".
Technical Field
The field of the invention relates generally to image processing and, more particularly, to a data slice generator for an image generator.
Background
Image processing typically involves the processing of pixel values organized into an array. Here, the two-dimensional nature of an image is captured via a spatially organized two-dimensional array (additional dimensions may include time (e.g., a sequence of two-dimensional images) and data type (e.g., color).
The first extreme performs image processing tasks as a software program executing on a general purpose processor or general purpose class of processors (e.g., a general purpose processor with vector instruction enhancement). While the first extreme typically provides a highly versatile application software development platform, its use of finer-grained data structures in conjunction with associated overhead (e.g., instruction fetch and decode, processing on-and off-chip data, speculative execution) can ultimately result in more energy being consumed per unit of data during execution of program code.
The second opposite extreme applies fixed function hard-wired circuitry to much larger blocks of data. The use of larger (as opposed to finer grained) blocks of data directly applied to custom designed circuits greatly reduces power consumption per unit of data. However, the use of custom designed fixed function circuits often results in a processor that can only perform a limited set of tasks. Thus, there is a lack of a widely common programming environment in the second extreme (which is associated with the first extreme).
A technology platform that provides a highly versatile application software development opportunity combined with improved power efficiency per unit data remains an ideal but missing solution.
Disclosure of Invention
A data slice generator circuit is described. The sheet generator includes electronic circuitry for receiving a line group of image data including a plurality of lines of data from a frame of image data. The plurality of rows is sufficient in number to contain a plurality of adjacent overlapping stencils. The electronic circuit parses the wire set into smaller sized pieces of data. The electronic circuitry loads the data patch into a data computation unit having a two-dimensional shift array structure coupled to the processor array.
A device is described having means for receiving a line group of image data comprising a plurality of lines of data from a frame of image data. The plurality of rows is sufficient in number to contain a plurality of adjacent overlapping stencils. The device further comprises means for parsing the line groups into smaller sized pieces of data. The apparatus also includes means for loading the piece of data into a two-dimensional shift array structure of an array coupled to the processor. The apparatus also includes means for executing program code on the array of processors to process a plurality of adjacent overlapping stencils on the sheet of data.
Drawings
The following description and the annexed drawings set forth in detail certain illustrative embodiments of the invention. In the figure:
FIG. 1 illustrates an embodiment of an image processor hardware architecture;
FIGS. 2a, 2b, 2c, 2d and 2e depict parsing image data into line groups, parsing line groups into tiles and performing operations on the tiles by overlapping stencils;
FIG. 3a illustrates an embodiment of a stencil processor;
FIG. 3b illustrates an embodiment of an instruction word for a stencil processor;
FIG. 4 illustrates an embodiment of a data computation unit within a stencil processor;
5a, 5b, 5c, 5d, 5e, 5f, 5g, 5h, 5i, 5j and 5k depict examples of determining a pair of adjacent output pixel values using a two-dimensional shift array and an execution lane array by overlapping a stencil;
FIG. 6 illustrates an embodiment of a unit cell for an integrated execution lane array and two-dimensional shift array;
FIG. 7 relates to a first operation performed by the slice generator;
FIG. 8 relates to a second operation performed by the slice generator;
FIG. 9 relates to a third operation performed by the sheet generator;
FIG. 10 relates to a fourth operation performed by the sheet generator;
FIG. 11 relates to a fifth operation performed by the sheet generator;
FIG. 12 relates to a sixth operation performed by the sheet generator;
FIG. 13 illustrates an embodiment of a data slice generator;
FIG. 14 illustrates an embodiment of a computing system.
Detailed Description
a. Image processor hardware architecture and operation
Fig. 1 shows an embodiment of an architecture 100 for an image processor implemented in hardware. The image processor may, for example, be the target of a compiler that converts program code written for a virtual processor within a simulated environment into program code that is actually executed by a hardware processor. As shown in fig. 1, the architecture 100 includes a plurality of line buffer units 101_1 to 101_ M, the line buffer units 101_1 to 101_ M being interconnected to a plurality of stencil processor units 102_1 to 102_ N and corresponding data patch generator units 103_1 to 103_ N via a network 104 (e.g., a Network On Chip (NOC), including a switched network on chip, a ring network on chip, or other type of network). In one embodiment, any line buffer unit may be connected to any data slice generator and corresponding stencil processor through the network 104.
In one embodiment, the program code is compiled and loaded onto the corresponding stencil processor 102 to perform image processing operations defined earlier by the software developer (the program code may also be loaded onto the stencil processor's associated data patch generator 103, depending on design and implementation, for example). In at least some examples, the image processing pipeline may be implemented by loading a first kernel for a first pipeline stage into the first stencil processor 102_1, a second kernel for a second pipeline stage into the second stencil processor 102_2, etc., wherein the first kernel performs the functions of the first stage of the pipeline, the second kernel performs the functions of the second stage of the pipeline, etc., and installing additional control flow methods to transition output image data from one stage of the pipeline to the next stage of the pipeline.
In other configurations, the image processor may be implemented as a parallel machine with two or more stencil processors 102_1, 102_2 operating on the same kernel program code. For example, high density and high data rate streams of image data may be processed by expanding frames across multiple stencil processors, each of which performs the same function.
In still other configurations, substantially any DAG of kernels may be loaded onto a hardware processor by configuring, in a DAG design, the respective template processor with its respective corresponding program code kernel, and configuring appropriate control flow hooks into the hardware to direct the output image from one kernel to the input of the next.
As a general flow, frames of image data are received by the macro I/O unit 105 and transferred to one or more of the line buffer units 101 on a frame-by-frame basis. A particular line buffer unit parses its frame of image data into smaller regions of image data, called "line groups," which are then transferred over the network 104 to a particular slice generator. A complete or "complete" single line set may, for example, consist of a number of consecutive complete rows or columns of data of a frame (for simplicity, this description refers primarily to consecutive rows). The sheet generator further parses the line groups of image data into smaller regions of image data, called "sheets" (sheets), and provides the sheets to their corresponding stencil processors.
In the case of an image processing pipeline or DAG stream with a single input, typically, the input frames are directed to the same line buffer unit 101_1, which parses the image data into line groups and directs the line groups to the slice generator 103_1, whose corresponding stencil processor 102_1 is executing the code of the first core in the pipeline/DAG. After the line group processed by the stencil processor 102_1 completes the operation, the sheet generator 103_1 sends the output line group to the "downstream" line buffer unit 101_2 (in some use cases, the output line group may be sent back to the same line buffer unit 101_1 as the input line group that was sent earlier).
Then, one or more "consumer" kernels receive the image data generated by the first stencil processor 102_1 from the downstream line buffer unit 101_2, the "consumer" representing the next stage/operation in the pipeline/DAG executing on the respective other data slice generator and stencil processor (e.g., data slice generator 103_2 and stencil processor 102_ 2). In this way, the "producer" kernel running on the first stencil processor forwards its output data to the "consumer" kernel running on the second stencil processor, where the consumer kernel performs the next set of tasks behind the producer kernel, consistent with the design of the overall pipeline or DAG.
The stencil processor 102 is designed to operate on multiple overlapping stencils (tencils) of image data simultaneously. The multiple overlapping stencils and internal hardware processing capabilities of the stencil processor effectively determine the size of the data sheet. Here, within the stencil processor 102, the array operation of the streets is performed in unison so that the image data surface areas covered by the plurality of overlapping stencils are processed simultaneously.
As described in detail below, in various embodiments, a data slice of image data is loaded into a two-dimensional register array structure within stencil processor 102. The use of a slice of data and a two-dimensional register array architecture is believed to effectively provide power consumption improvements by shifting large amounts of data into a large amount of register space, e.g., as a single load operation, followed by the execution of processing tasks on the data directly by the execution lane array. Furthermore, the use of an execution lane array and corresponding register array provides different stencil sizes that can be easily programmed/configured.
Fig. 2a to 2e illustrate high level embodiments of the parsing activity of the line buffer unit 101, the finer grained parsing activity of the data patch generator unit 103 and the stencil processing activity of the stencil processor 102 coupled to the data patch generator unit 103.
Fig. 2a depicts an embodiment of an input frame of image data 201. Fig. 2a also depicts a schematic of three overlapping stencils 202 (each having a size of 3 pixels by 3 pixels) that the stencil processor is designed to operate with. Output pixels for which each stencil generates output image data, respectively, are highlighted in solid black. For simplicity, the three overlapping stencils 202 are depicted as overlapping only in the vertical direction. It is necessary to recognize that in practice, the stencil processor may be designed with overlapping stencils in both the vertical and horizontal directions.
Due to the vertically overlapping stencil 202 within the stencil processor, as shown in FIG. 2a, there is a wide range of image data within a frame in which a single stencil processor is capable of operating. As described in detail below, in one embodiment, the stencil processor processes data within its overlapping stencil in a left-to-right manner across the image data (and then repeats the next set of lines in top-to-bottom order). Thus, as the stencil processor continues its operation, the number of solid black output pixel blocks increases to the right in the horizontal direction. As discussed above, the line buffer unit 101 is responsible for parsing the line groups of input image data from the input frame, which is sufficient for the stencil processor to operate in more upcoming cycles. An exemplary depiction of a line group is illustrated as shaded area 203. In one embodiment, as described further below, the line buffer unit 101 can have different dynamics for sending/receiving line groups to/from the slice generator. For example, according to a mode known as "full-team", a full width line of image data is transferred between the line buffer unit and the slice generator. According to a second pattern, called "real high", the line group is initially transferred with a subset of the full-width rows. The remaining rows are then sequentially transferred in smaller pieces (less than full width).
As the line groups 203 of input image data have been defined by the line buffer unit and transferred to the slice generator unit, the slice generator unit further parses the line groups into finer slices, which more accurately fit the hardware limitations of the stencil processor. More specifically, as described in detail below, in one embodiment, each stencil processor is comprised of a two-dimensional array of shift registers. The two-dimensional shift register array essentially shifts the image data "below" the array of execution lanes, in a pattern such that each execution lane operates on the data within its respective template (that is, each execution lane processes its own information template to generate an output for that template). In one embodiment, a slice of data is a surface area of input image data that is "filled" or otherwise loaded into a two-dimensional shift register array.
As will be described in more detail below, in various embodiments there are actually multiple layers of two-dimensional register data that are shifted over any period. For convenience, much of this specification will simply use the term "two-dimensional shift register" or the like to refer to a structure having one or more such layers of two-dimensional register data that can be shifted.
Thus, as shown in FIG. 2b, the sheet generator parses the initial sheet 204 from the line set 203 and provides it to the stencil processor (where the sheet of data corresponds to the shaded area generally indicated by reference numeral 204). As shown in fig. 2c and 2d, the stencil processor operates on the data sheet of the input image data by effectively moving the overlapping stencil 202 in a left-to-right manner over the data sheet. As shown in fig. 2d, the number of pixels of output values that can be calculated from the data within the data slice is exhausted (no other pixel position will have an output value determined from the information within the data slice). For simplicity, the border regions of the image have been omitted.
The tile generator then provides the stencil processor with the next tile 205 to continue operation, as shown in fig. 2 e. Note that the initial position at which the stencil starts to operate on the next piece of data is the next progression from the exhaustion point on the first piece of data to the right (as previously shown in figure 2 d). With respect to the new piece of data 205, the stencil will simply continue to move to the right as the stencil processor operates on the new piece of data in the same manner as the processing of the first piece of data.
Note that there is some overlap between the data of the first sheet of data 204 and the data of the second sheet of data 205 due to the border region of the stencil surrounding the output pixel locations. The overlap can be handled simply by the data slice generator resending the overlapped data twice. In an alternative embodiment, to feed the next data piece to the stencil processor, the data piece generator may simply continue to send new data to the stencil processor, and the stencil processor reuses overlapping data from the previous data piece.
b. Stencil processor design and operation
Fig. 3a illustrates an embodiment of a stencil processor architecture 300. As shown in fig. 3a, the stencil processor includes a data computation unit 301, a scalar processor 302, and associated memory 303 and I/O unit 304. The data computation unit 301 includes an execution lane array 305, a two-dimensional shift array structure 306, and a separate random access memory 307 associated with a particular row or column of the array.
The I/O unit 304 is responsible for loading the "input" data pieces received from the data piece generator into the data calculation unit 301 and storing the "output" data pieces from the stencil processor into the data piece generator. In one embodiment, loading the data slice data into the data computation unit 301 entails parsing the received data slice into rows/columns of image data and loading the rows/columns of image data into the two-dimensional shift register structure 306 or corresponding random access memory 307 (described in more detail below) that executes the rows/columns of the lane array. If a piece of data is initially loaded into memory 307, then each execution lane within the execution lane array 305 may load the piece of data from the random access memory 307 into the two-dimensional shift register structure 306 as appropriate (e.g., as a load instruction prior to operating on the piece of data). Upon completion of loading the data slice into the register structure 306 (whether directly from the data slice generator or from memory 307), the execution tracks of the execution track array 305 operate on the data and eventually "write back" the completed data as a data slice directly to the data slice generator or to random access memory 307. If the I/O unit 304 later fetches data from the random access memory 307 to form an output data slice, it is forwarded to the data slice generator.
The scalar processor 302 includes a program controller 309 that reads instructions of the program code of the stencil processor from the scalar memory 303 and sends these instructions to the execution lanes in the execution lane array 305. In one embodiment, a single identical instruction is broadcast to all execution lanes within array 305 to implement SIMD-like behavior from data computation unit 301. In one embodiment, the instruction format of instructions read from scalar memory 303 and issued to execution lanes of execution lane array 305 includes a Very Long Instruction Word (VLIW) type format that includes more than one opcode per instruction. In another embodiment, the VLIW format includes ALU operation codes that indicate mathematical functions to be performed by the ALUs of each execution lane (which, in one embodiment, may specify more than one conventional ALU operation, as described below) and memory operation codes that indicate memory operations for a particular execution lane or set of execution lanes.
The term "execution lane" refers to a collection of one or more execution units capable of executing instructions (e.g., logic capable of executing instructions). However, in various embodiments, an execution lane can include more processor-like functions in addition to execution units. For example, an execution lane may include logic to decode a received instruction, or in the case of a more MIMD-like design, to fetch and decode instructions, in addition to one or more execution units. With respect to the MIMD-like approach, although largely described herein to a centralized program control approach, a more distributed approach (e.g., including program code and program controllers within each execution lane of the array 305) may be implemented in various alternative embodiments.
The combination of the execution lane array 305, the program controller 309, and the two-dimensional shift register structure 306 provide a widely applicable/configurable hardware platform for a wide range of programmable functions. For example, application software developers can program kernels with widely varying functional capabilities and sizes (e.g., stencil sizes) given that individual execution lanes can perform a wide variety of functions and can easily access input image data adjacent to any output array location.
In addition to serving as a data storage area for image data operated on by the track array 305, the random access memory 307 may also hold one or more look-up tables. In various embodiments, one or more scalar look-up tables may also be instantiated within scalar memory 303.
Scalar lookups involve transferring the same data value from the same lookup table from the same index to each of the execution ways within execution way array 305. In various embodiments, the above VLIW instruction format is extended to also include a scalar opcode that directs a lookup operation performed by a scalar processor into a scalar lookup table. The index designated for use with the opcode may be an immediate operation number or extracted from some other data storage location. Regardless, in one embodiment, looking up from a scalar lookup table within scalar memory involves essentially broadcasting the same data value to all of the execution lanes within execution lane array 305 during the same clock cycle. Additional details regarding the use and operation of the lookup table are provided further below.
Fig. 3b summarizes an embodiment of a VLIW instruction word discussed above. As shown in fig. 3b, the VLIW instruction word format includes fields for three separate instructions: 1) scalar instructions 351 executed by a scalar processor; 2) ALU instructions 352 that are broadcast and executed in SIMD fashion by each ALU within the execution lane array; and 3) memory instructions 353 that are broadcast and executed in a partial SIMD manner (e.g., if execution lanes along the same row in an array of execution lanes share the same random access memory, one execution lane from each of the different rows actually executes the instruction (the format of the memory instructions 353 may include an operand identifying which execution lane from each row executes the instruction)).
In one embodiment, the scalar instructions executed by the scalar processor include commands sent to the slice generator to load/store slices of data from/to memory or 2D shift registers of the data computation unit. Here, the operation of the slice generator can depend on the operation of the line buffer unit or other variables that prevent the number of cycles from including a pre-run that would cause the slice generator to complete any commands issued by the scalar processor. Thus, in one embodiment, any VLIW word for which scalar instruction 351 corresponds to or otherwise results in a command to the data-slice generator also includes a no-operation (NOOP) instruction in the other two instruction fields 352, 353. The NOOP instruction of the program code input instruction field 352, 353 then loops until the slice generator completes its load/store to/from the data computation unit. Here, after issuing a command to the slice generator, the scalar processor may set the bit of the interlock register that the slice generator resets after completing the command. During the NOOP cycle, the scalar processor monitors the bits of the interlock bits. Normal execution resumes when the scalar processor detects that the slice generator has completed its command.
Fig. 4 illustrates an embodiment of a data computation component 1001. As shown in FIG. 4, the data computation element 401 includes an array of execution lanes 405 logically positioned "above" a two-dimensional shift register array structure 406. As described above, in various embodiments, a slice of image data provided by the slice generator is loaded into the two-dimensional shift register 406. The execution lane then operates on the data slice data from register structure 406.
The execution lane array 405 and the shift register structure 406 are fixed in position relative to each other. However, the data within the shift register array 406 is shifted in a strategic and coordinated manner such that each execution lane in the execution lane array processes a different template within the data. In this way, each execution lane determines the output image values of different pixels in the output data slice being generated. From the architecture of FIG. 4, it should be clear that the overlapping stencil is not only arranged vertically, but also horizontally, since the execution lane array 405 includes vertically adjacent execution lanes as well as horizontally adjacent execution lanes.
Some of the salient architectural features of the data computation unit 401 include a shift register structure 406 having a wider dimension than the execution lane array 405. That is, there is a "halo" 409 of registers outside the execution lane array 405. Although halo 409 is shown to be present on both sides of the execution lane array, halo may be present on fewer sides (one side) or more sides (three or four sides) of execution lane array 405, depending on the implementation. Halo 409 is used to provide "overflow" space for data that overflows outside the boundaries of execution lane array 405 when the data is shifted "below" execution lane 405. In a simple case, a 5 × 5 stencil centered at the right edge of the execution lane array 405 requires four more halo register locations to the right when processing the leftmost pixel of the stencil. For ease of drawing, fig. 4 shows that in a standard embodiment, the registers on the right side of the halo have only horizontal shift connections, while the registers on the bottom side of the halo have only vertical shift connections, while the registers on either side (right, bottom) have both horizontal and vertical connections.
Additional overflow space is provided by random access memory 407 that is coupled to each row and/or column in the array or a portion thereof (e.g., random access memory may be allocated to a "region" of the execution lane array that spans 4 execution lane rows and 2 execution lane columns. Here, if the kernel operation of the execution lane requires it to process pixel values outside of the two-dimensional shift register array 406 (which some image processing routines may require), the plane of image data can overflow further, for example, from the halo region 409 into the random access memory 407. For example, consider a 6 × 6 template, where the hardware includes a halo region of only four storage elements to the right of an execution lane on the right edge of the execution lane array. In this case, the data needs to be further shifted to the right of the right edge of halo 409 to completely process the stencil. Data shifted outside the halo region 409 may overflow into random access memory 407. Random access memory 407 and other applications of the stencil processor of fig. 3 are further provided below.
Fig. 5a to 5k show working examples of the manner in which image data as described above is shifted "below" the execution lane array within the two-dimensional shift register array. As shown in fig. 5a, the data content of the two-dimensional shift array is depicted in the first array 507, and the execution lane array is depicted by a frame 505. Furthermore, two adjacent execution lanes 510 within the execution lane array are simply depicted. In this simple depiction 510, each execution lane includes a register R1 that is capable of accepting data from a shift register, accepting data from the ALU output (e.g., appearing as an accumulator between cycles), or writing output data to an output destination.
In local register R2, each execution lane may also apply to the contents "below" it in a two-dimensional shift array. Thus, R1 is the physical register of the execution lane, while R2 is the physical register of the two-dimensional shift register array. The execution lane includes an ALU capable of operating on operands provided by R1 and/or R2. As described in detail below, in one embodiment, the shift register is actually implemented with multiple storage/register elements per array location (the "depth") but the shifting activity is limited to one plane of storage elements (e.g., only one plane of storage elements can be shifted per cycle). Fig. 5a to 5k depict one of these deeper register locations for storing the result X from the corresponding execution lane. For ease of illustration, the deeper result register is drawn beside its companion register R2 rather than below it.
FIGS. 5 a-5 k focus on the computation of two templates whose center positions are aligned with a pair of execution lane positions 511 depicted within the execution lane array. For ease of illustration, the pair of execution lanes 510 are drawn as horizontal neighbors, while they are actually vertical neighbors according to the following example.
As initially shown in FIG. 5a, the execution lane is centered on its central stencil position. FIG. 5b shows object code being executed by two execution lanes. As shown in fig. 5b, the program code for two execution lanes causes the data within the shift register array to be shifted one position down and one position to the right. This aligns the two execution tracks with the top left corner of their respective stencils. The program code then causes the data located at their respective positions (in R2) to be loaded into R1.
As shown in FIG. 5c, the program code next causes the pair of execution lanes to shift the data within the shift register array one unit to the left, which causes the value to the right of the corresponding position of each execution lane to be shifted to the position of each execution lane. The value in R1 (the previous value) is then added with the new value (in R2) that has been shifted to the location of the execution lane. The result is written to R1. As shown in FIG. 5d, the same process as described above with respect to FIG. 5C is repeated, which results in the resulting R1 now including the value A + B + C in the previous execution lane and F + G + H in the next execution lane. At this point, both execution lanes have processed the uplinks of their respective templates. Note that if there is no halo region to the left of the execution lane array, then it will overflow into the halo region to the left of the execution lane array (if there is one halo region to the left) or into random access memory.
As shown in FIG. 5e, the program code next causes the data in the shift register array to be shifted up by one unit, which causes both execution lanes to be aligned with the right edge of the middle row of their respective stencil. The registers R1 for both execution lanes currently comprise the sum of the rightmost values of the top and middle lines of the stencil. Fig. 5f and 5g show successive progresses of the stencil's middle row moving to the left across two execution lanes. The accumulation continues so that at the end of the process of FIG. 5g, the two execution tracks comprise the sum of the values of the top and middle rows of their respective templates.
FIG. 5h illustrates another shift to align each execution lane with the lowermost row of its corresponding stencil. FIGS. 5i and 5j illustrate the shift continuing in progress of the template for two execution lanes to complete the process. FIG. 5k shows an additional shift to align each execution lane with its correct position in the data array and write the result thereto.
In the example of fig. 5a to 5k, note that the object code for the shift operation may include an instruction format that identifies the direction and magnitude of the shift expressed in (X, Y) coordinates. For example, the target code for shifting up one position may be expressed as SHIFT 0, +1 in the target code. As another example, a SHIFT to the right by one position may be expressed in the target code as SHIFT +1, 0. In various embodiments, a larger magnitude SHIFT may also be specified in the target code (e.g., SHIFT 0, + 2). Here, if the 2D shift register hardware only supports shifting one position per cycle, the instruction may be interpreted by the machine as requiring multiple cycles to execute, or the 2D shift register hardware may be designed to support shifting more than one position per cycle. An embodiment of the latter case will be described in further detail below.
Fig. 6 shows another more detailed description of the array execution lane and unit cell (cell) of the shift register structure (the register in the halo region does not include the corresponding execution lane). In one embodiment, execution lanes and register space associated with each location in the execution lane array are implemented by instantiating the circuitry shown in FIG. 12 at each node of the execution lane array. As shown in fig. 6, the unit cell includes an execution lane 601 coupled to a register file 602 composed of four registers R2-R5. During any cycle, the execution lane 601 may read from or write to any of the registers R1-R5. For instructions requiring two input operand counts, the execution lane may obtain two operands from any of R1 through R5.
In one embodiment, a two-dimensional shift register structure is implemented by allowing the contents of any (only) one of the registers R2-R4 to "shift out" to one of its neighbor's register files through the output multiplexer 603 during a single cycle, and replacing the contents of any (only) one of the registers R2-R4 with the contents of the corresponding one that would have been "shifted in" if its neighbor were "shifted in" from the corresponding one through the input multiplexer 604, so that the shifts between the neighbors are in the same direction (e.g., all perform lane-to-left shifts, all perform lane-to-right shifts, etc.). While it is generally possible for the same register to shift out its contents and replace them with those shifted in the same cycle, the multiplexer devices 603, 604 allow different shift source and shift target registers within the same register file during the same cycle.
As shown in FIG. 6, note that during the shift sequence, a trace shifts content from its register file 602 to each of its left, right, top, and bottom neighbors. In conjunction with the same shift sequence, an execution lane also shifts content from a particular one of its left, right, top, and bottom neighbors into its register file. In addition, for all execution lanes, the move-out target and the move-in source should conform to the same shift direction (e.g., if the move-out is a right-hand neighbor, the move-in should be a left-hand neighbor).
While in one embodiment each execution lane allows shifting the contents of a unique register per cycle, other embodiments may allow shifting in/out the contents of multiple registers. For example, if the second instance of multiplexer circuits 603, 604 shown in FIG. 6 is incorporated into the design of FIG. 6, the contents of both registers may be shifted out/in during the same cycle. Of course, in embodiments that allow shifting the contents of a unique register per cycle, shifting from multiple registers may be performed between mathematical operations by consuming more clock cycles for shifting between mathematical operations (e.g., the contents of two registers may be shifted between mathematical operations by consuming two shift operations between mathematical operations).
If the contents shifted out during the shift sequence are less than the full contents of the register file of the execution lane, then note that the contents of the unshifted registers of each execution lane remain in place (not shifted). In this way, any un-shifted content that is not replaced with shifted-in content remains locally in the execution track for the entire shift cycle. The memory cells ("M") observed in each execution lane are used to load/store data from/to random access memory space associated with rows and/or columns of execution lanes within the execution lane array. Here, the M-cell acts as a standard M-cell, as it is often used to load/store data that cannot be loaded/stored from/to the register space of the execution lane itself. In various embodiments, the main operation of the M-cell is to write data from the local register to the memory and to read data from the memory and write it to the local register.
With respect to ISA opcodes supported by the ALU units of the hardware execution lane 601, in various embodiments, the mathematical opcodes supported by the hardware ALUs are identical (e.g., substantially identical) to the mathematical opcodes supported by the virtual execution lane (e.g., ADD, SUB, MOV, MUL, MAD, ABS, DIV, SHL, SHR, MIN/MAX, SEL, AND, OR, XOR, NOT) as a whole. As described above, memory access instructions can be executed by the execution lane 601 to fetch/store data from/to its associated random access memory. In addition, the hardware execution lane 601 supports shift operation instructions (right, left, up, down) to shift data within the two-dimensional shift register structure. As described above, the program control instructions are mainly executed by the scalar processor of the stencil processor.
c. Operation and design of a data slice generator
Fig. 7-12 relate to particular considerations and/or operation of the data slice generator. As described above, the tile generator is responsible for generating a tile of information for processing by the corresponding stencil processor. To implement extensive versatility/programmability in the overall processor design, the sheet generator may in some cases need to perform additional operations in preparation for an incoming sheet, rather than merely parsing the appropriate portion from the received set of lines.
For example, in some cases, program code will require multiple channels of the same image to be processed simultaneously. For example, many video images have a red (R) channel, a blue (B) channel, and a green (G) channel. In one embodiment, the slice generator is implemented using a processor with an associated memory and program code executing outside the memory.
As shown in fig. 7, in response to detecting from the application software a need for the kernel to process data from different channels simultaneously (which may have been prompted from the compiler), the program code executed by the slice generator will continue to form separate slices along different "planes" (i.e. form different slices per channel) and load them together into the data computation unit. That is, the slice generator will generate an R slice, a B slice, and a G slice for the same portion of the array and load all three slices into the compute unit. Then, the execution lanes within the execution lane array are free to operate on R, G and the B data slice as needed (e.g., by storing the R data slice in one layer of the register file, the G data slice in another layer of the register file, and the B data slice in yet another layer of the register file).
Fig. 8 relates to a data patch generation for a multi-dimensional input image. Here, although many input images are in the form of simple arrays, in some cases, each location in the array will correspond to a multi-dimensional data structure. As an illustrative example, fig. 8 depicts an image where each array position contains 27 different values corresponding to different sections of a 3 x 3 cube. Where each array position has a multidimensional data structure, the data slice generator will "unroll" the input array such that a separate data slice is formed for each data structure dimension. Thus, as shown in FIG. 8, the data slice generator will generate 27 data slices (one per cube section), where each array position of each data slice in the total data slice contains a scalar value (one cube section). Then, 27 pieces of data are loaded into the stencil processor. Program code executed by execution tracks within the execution track array then operates on the 27 data pieces with knowledge of the manner in which the multi-dimensional input array has been expanded.
FIG. 9 relates to techniques for allowing execution lanes within an execution lane array to handle different data bit widths. Here, as is understood in the art, a greater dynamic range is achieved by increasing the bit width of the data value (a 16-bit value is able to express a value having a greater dynamic range than an 8-bit value). In one embodiment, it is contemplated that the stencil processor operates on images having different bit widths, such as 8, 16, or 32 bit pixel values. Thus, according to one approach, the execution lane itself is a 32-bit machine, in the sense that 32-bit operands can be processed internally to the execution lane.
However, to reduce the size and complexity of a two-dimensional shift register, the individual storage elements of the registers within the register file of each execution lane are limited to 8 bits. This is not a problem in the case of 8-bit image data, since the entire piece of data can fit into one register in the register file. Conversely, in the case of 16-bit or 32-bit operands, the slice generator generates multiple slices to properly express the data set of the input operand.
For example, as shown in FIG. 9, in the case of a 16-bit input operand, the slice generator will generate a HI half slice and a LO half slice. The HI half slice contains the upper 8 bits of each data item at the correct array position. The LO half-slice contains the lower 8 bits of each data item at the correct array position. Then, the 16-bit operation is performed by loading two pieces of data into the stencil processor and notifying the execution lane hardware (e.g., via an immediate value in the program code) to perform the 16-bit operation. Here, as just one possible mode of operation, both the HI and LO slices are loaded into two different registers of each execution lane register file.
The execution lane unit can internally construct the correct operand by first reading data from one of the register file locations and appending therein the data read from the other of the register file locations. Similarly, in the write direction, the execution lane unit performs writing twice. Specifically, the lower 8 bits are written to a first register of the register file containing the LO slice for the first time, and then the upper 8 bits are written to a second register of the register file containing the HI slice for the second time.
Referring back to the discussion of FIG. 12, in various embodiments, only the contents of one register are allowed to shift per cycle. Thus, to move 16-bit data values around a two-dimensional shift register structure, in the case of 8-bit data values, each shift sequence (between mathematical operations) consumes two cycles, rather than one cycle. That is, in the nominal case of an 8-bit data value, all data may be shifted between locations in a single cycle. Conversely, in the case of a 16-bit data value, the shift operations (HI half-slice and LO half-slice) of each shift register have to shift two 8-bit values. In one embodiment, in the case of 32 bits, the same principles apply except that four data slices are created to represent the entire image data instead of two. Also, each shift sequence may need to consume up to four cycles.
Fig. 10 relates to the case where the image processor "upsamples" the input image data from a low density resolution to a high density resolution. Here, the stencil processor is responsible for generating more output values per unit area of the image than the input image contains. The slice generator handles the upsampling problem by repeating the same data values on the slices such that the slice data value density corresponds to the upsampled (high density) output image. That is, for example, as shown in fig. 10, in view of the density of the output image, in the case where the output execution lane array density corresponds to 4:1 upsampling (four output pixels per input pixel), the data slice generator makes a data slice having four identical values for each input value.
Fig. 11 relates to the reverse case of "down-sampling". In the case of downsampling, the slice generator will generate more slices than for a low density input image. Specifically, if the input image has a factor of S high resolution in one (e.g., X) direction and a factor of T high resolution in the other (e.g., Y) direction, the slice generator will generate S X T slices from the initial slices with the greater initial density. This effectively assigns more input pixels to any particular output pixel.
FIG. 12 relates to the case where the mathematical operations performed by execution lanes within an execution lane array require an image data surface area that is larger than the size of a two-dimensional shift register structure. As shown in fig. 12, a piece of data to be loaded into a two-dimensional shift register structure for processing corresponds to a shadow area 1201 of an input frame. However, the mathematical operation that will calculate the output values for the array locations within the shaded region requires values within the frame shown in FIG. 12 bounded by the dashed border 1202. Thus, there is a large "support area" outside the surface area of the two-dimensional shift register structure, which will be involved in the operation.
Under these conditions, the data patch generator will not only load the data patch corresponding to the shadow area 1201 into the stencil processor, but also three (non-shadow) adjacent data patches into the data calculation unit. Program code executed by the execution lanes will call and move pieces of data to/from random access memory as needed and/or store some or all of the pieces of data in a deeper register of the two-dimensional shift register array.
Fig. 13 provides an embodiment of a hardware design 1300 for a slice generator. As shown in fig. 13, in one embodiment, the data slice generator is implemented as a computing system having a processor/controller 1301 that executes program code stored in memory 1302 to perform data slice generator tasks, such as any of the tasks described above with reference to fig. 7-12. The sheet generator further comprises an I/O unit 1303 for receiving/sending the set of lines from/to the network and the sheet from/to the associated stencil processor of the sheet generator.
A relevant feature of the data slice generator is its configuration space 1304, which may be implemented as a separate register space within the data slice generator (as shown in fig. 13), within the processor/controller 1301, and/or within the memory 1302. The configuration space 1304 facilitates wide adaptability and programmability of the overall platform. Here, the settings made in the configuration space 1304 may include, for example, relevant image features and dimensions such as frame size, line group size, slice size, pixel resolution of the input image, pixel resolution of the output image, and the like. The program code in memory 1302 then performs the correct operation on the correctly sized pieces of data or the like using the information in the configuration space as input variables.
Alternatively, or in some combination, the broad adaptability and programmability of the overall platform may be achieved by loading custom program code into memory 1302 for a particular application and/or image size. Here, for example, the compiler can easily refer to the X, Y coordinates of the position relative addressing scheme and/or any of the frame size and the line group size in order to determine the data slice size, the data slice boundary, etc., and to customize the generic program code template to the software program dedicated to the image processing task at hand. Likewise, any such translated and actual use relative positioning or other image dimensions may be entered into the configuration space 1304, where program code present on the data slice generator determines the data slice boundaries, data slice size, and the like.
d. Examples of the embodiments
It is important to note that the various image processor architectural features described above are not necessarily limited to image processing in the traditional sense and thus may be applied to other applications that may (or may not) cause an image processor to be re-characterized. For example, an image processor may be characterized as a graphics processing unit if any of the various image processor architectural features described above are to be used to create and/or generate and/or render an animation, rather than processing the actual camera image. Furthermore, the above-described image processor architectural features may be applied to other technical applications, such as video processing, vision processing, image recognition, and/or machine learning. Applied in this manner, the image processor may be integrated (e.g., as a coprocessor) with a more general-purpose processor (e.g., as the CPU of a computing system or a portion thereof), or may be a separate processor within the computing system.
The hardware design embodiments discussed above may be implemented within a semiconductor chip and/or as descriptions of circuit designs for ultimately targeted semiconductor fabrication processes. In the latter case, such circuit descriptions may take the form of high-level/behavioral-level circuit descriptions (e.g., VHDL descriptions) or low-level circuit descriptions (e.g., Register Transfer Level (RTL) descriptions, transistor-level descriptions, or mask descriptions), or various combinations thereof. The circuit description is typically embodied on a computer readable storage medium, such as a CD-ROM or other type of storage technology.
From the foregoing, it is necessary to recognize that the image processor as described above may be embodied in hardware on a computer system (e.g., as part of a system on a chip (SOC) of a handheld device that processes data from a camera of the handheld device). In the case where the image processor is implemented as a hardware circuit, it is noted that the image data processed by the image processor may be directly received from the camera. Here, the image processor may be part of a separate camera, or part of a computing system with an integrated camera. In the latter case, the image data may be received directly from the camera or from a system memory of the computing system (e.g., the camera sends its image data to the system memory instead of the image processor). It should also be noted that many of the features described in the preceding sections may be applicable to a graphics processor unit (which renders animation).
FIG. 14 provides an exemplary depiction of a computing system. Many of the components of the computing systems described below may be applied to computing systems (e.g., handheld devices such as smart phones or tablet computers) having integrated cameras and associated image processors. The relationship between the two can be readily understood by one of ordinary skill in the art.
As shown in fig. 14, a basic computing system may include a central processing unit 1401 (which may, for example, include a plurality of general purpose processing cores 1415_1 through 1415_ N and a main memory controller 1417 or application processor disposed on a multi-core processor), a system memory 1402, a display 1403 (e.g., touchscreen, tablet), a local wired point-to-point link (e.g., USB) interface 1404, various network I/O functions 1405 (such as an ethernet interface and/or cellular modem subsystem), a wireless local area network (e.g., WiFi) interface 1406, a wireless point-to-point link (e.g., bluetooth) interface 1407 and a global positioning system interface 1408, various sensors 1409_1 to 1409_ N, one or more cameras 1410, a battery 1411, a power management control unit 1414, a speaker and microphone 1413, and an audio encoder/decoder 1414.
The application processor or multicore processor 1450 may include one or more general purpose processing cores 1415, one or more graphics processing units 1416, memory management functions 1417 (e.g., memory controllers), I/O control functions 1418, and image processing units 1419 within its CPU 1401. The general purpose processing core 1415 typically executes the operating system and application software of the computing system. The graphics processing unit 1416 typically performs graphics-sensitive functions, for example, to generate graphical information for presentation on the display 1403. The memory control function 1417 interfaces with the system memory 1402 to write data to and read data from the system memory 1402. The power management control unit 1414 generally controls the power consumption of the system 1400.
The image processing unit 1419 may be implemented according to any of the image processing unit embodiments described in detail in the preceding sections. Alternatively or in combination, the IPU 1419 may be coupled to one or both of the GPU 1416 and the CPU 1401 as a co-processor thereof. Further, in various embodiments, GPU 1416 may be implemented with any of the image processor features described in detail above.
Each of the touchscreen display 1403, communication interfaces 1404-1407, GPS interface 1408, sensor 1409, camera 1410, and speaker/ microphone codecs 1413, 1414 can be considered various forms of I/O (input and/or output) that also include integrated peripherals (e.g., one or more cameras 1410) where appropriate with respect to the overall computing system. Depending on the implementation, each of these I/O components may be integrated on the application processor/multi-core processor 1450, or may be located off-die of the processor/multi-core processor 1450 or off-package thereof.
In one embodiment, the one or more cameras 1410 include a depth camera capable of measuring depth between the camera and objects within its field of view. Application software, operating system software, device driver software, and/or firmware executing on a general purpose CPU core (or other functional block having an instruction execution pipeline for executing program code) of an application processor or other processor may perform any of the functions described above.
Embodiments of the invention may include various processes as described above. The processes may be embodied in machine-executable instructions. These instructions can be used to cause a general-purpose or special-purpose processor to perform certain processes. Alternatively, the processes may be performed by specific hardware components that contain hardwired logic for performing the processes, or by any combination of programmed computer components and custom hardware components.
Elements of the present invention may also be provided as a machine-readable medium for storing the machine-executable instructions. The machine-readable medium may include, but is not limited to, floppy diskettes, optical disks, CD-ROMs, and magneto-optical disks, flash memory, ROMs, RAMs, EPROMs, EEPROMs, magnetic or optical cards, propagation media or other type of media/machine-readable medium suitable for storing electronic instructions. For example, the invention may be downloaded as a computer program which may be transferred from a remote computer (e.g., a server) to a requesting computer (e.g., a client) by way of data signals embodied in a carrier wave or other propagation medium via a communication link (e.g., a modem or network connection).
In the foregoing specification, the invention has been described with reference to specific exemplary embodiments thereof. It will, however, be evident that various modifications and changes may be made thereto without departing from the broader spirit and scope of the invention as set forth in the appended claims. The specification and drawings are, accordingly, to be regarded in an illustrative rather than a restrictive sense.
Claims (19)
1. A method, comprising:
receiving, by a slice generator, a line group including image data from a plurality of lines of a frame of image data from a line buffer;
loading, by the slice generator, an input slice of data into a two-dimensional shift register array coupled to an execution lane array, the input slice of data including a subset of data from the line group, wherein the input slice of data is smaller than the line group received from the line buffer, and wherein the input slice of data has a size corresponding to a size of the two-dimensional shift register array;
executing, by each execution lane of the array of execution lanes, program code to process image data of the input data slice loaded into the two-dimensional shift register array, wherein executing the program code causes each execution lane to generate, from the image data of the input data slice, a respective output value of an output data slice of the image data stored in the two-dimensional shift register array; and
providing an output data slice of the image data computed by the execution lane array back to the data slice generator.
2. The method of claim 1, further comprising: an output line group of an output data slice including the image data is supplied to a downstream line buffer by the data slice generator.
3. The method of claim 1, wherein the two-dimensional shift register array comprises a plurality of layers, and wherein the image data comprises a plurality of portions of image data for each location,
wherein loading the input data slice into the two-dimensional shift register array comprises: loading a first piece of data having first data from a first one of the plurality of portions into a first one of the plurality of layers, and further comprising:
loading a second piece of data having second data from a second portion of the plurality of portions into a second tier of the plurality of tiers.
4. The method of claim 3, wherein the portions of the image data comprise components of a multi-dimensional data structure at each location in the image data.
5. The method of claim 3, wherein the two-dimensional shift register array comprises registers having a bit width less than the image data, and wherein the portions of the image data comprise upper and lower bits of the image data.
6. The method of claim 3, wherein the plurality of portions of image data comprises a plurality of channels of image data at each location in the image data.
7. The method of claim 1, wherein loading the input data slice comprises:
an upsampled input data slice having upsampled image data is generated by copying a plurality of instances of each data value in the image data.
8. The method of claim 1, wherein loading the input data slice comprises:
generating a downsampled input data slice having downsampled image data by combining a plurality of instances of each input data value into a single value in the downsampled input data slice.
9. The method of claim 1, wherein executing the program code causes the two-dimensional shift register array to shift the data slice such that each execution lane traverses a respective template in two dimensions, wherein generating respective output values comprises: generating, by each execution lane, the respective output value from image data encountered by the execution lane as the input data slice is shifted by the two-dimensional shift register array.
10. An apparatus, comprising:
a data slice generator configured to:
receiving a line group including image data from a plurality of lines of a frame of image data from a line buffer; and
loading an input data slice into a two-dimensional shift register array coupled to an execution lane array, the input data slice comprising a subset of data from the line group, wherein the input data slice is smaller than the line group received from the line buffer, and wherein the input data slice has a size corresponding to a size of the two-dimensional shift register array,
wherein each execution lane in the execution lane array is configured to: executing program code to process image data of the input data slices loaded into the two-dimensional shift register array, wherein executing the program code causes each execution lane to generate, from the image data of the input data slices, a respective output value of an output data slice of image data stored in the two-dimensional shift register array; and providing an output data slice of the image data computed by the execution lane array back to the data slice generator.
11. The device of claim 10, wherein the data slice generator is further configured to: the set of output lines is provided to a downstream line buffer.
12. The apparatus of claim 10, wherein the two-dimensional shift register array comprises a plurality of layers, and wherein the image data comprises a plurality of portions of image data for each location,
wherein loading the input data slice into the two-dimensional shift register array comprises: loading a first data slice having first data from a first one of the plurality of portions into a first one of the plurality of layers, and the data slice generator is further configured to: loading a second piece of data having second data from a second portion of the plurality of portions into a second tier of the plurality of tiers.
13. The apparatus of claim 12, wherein the plurality of portions of the image data comprise components of a multi-dimensional data structure at each location in the image data.
14. The apparatus of claim 12, wherein said two-dimensional shift register array comprises registers having a bit width less than said image data, and wherein said portions of said image data comprise upper and lower bits of said image data.
15. The apparatus of claim 12, wherein the plurality of portions of image data comprises a plurality of channels of image data at each location in the image data.
16. The apparatus of claim 10, wherein loading the input data slice comprises:
an upsampled input data slice having upsampled image data is generated by copying a plurality of instances of each data value in the image data.
17. The apparatus of claim 10, wherein loading the input data slice comprises:
generating a downsampled input data slice having downsampled image data by combining a plurality of instances of each input data value into a single value in the downsampled input data slice.
18. The apparatus of claim 10, wherein executing the program code causes the two-dimensional shift register array to shift the data slice such that each execution lane traverses a respective template in two dimensions, wherein generating respective output values comprises: generating, by each execution lane, the respective output value from image data encountered by the execution lane as the input data slice is shifted by the two-dimensional shift register array.
19. One or more non-transitory computer storage media encoded with computer program instructions that, when executed by an image processor, cause the image processor to perform operations comprising:
receiving, by a slice generator, a line group including image data from a plurality of lines of a frame of image data from a line buffer;
loading, by the slice generator, an input slice of data into a two-dimensional shift register array coupled to an execution lane array of the image processor, the input slice of data comprising a subset of data from the line group, wherein the input slice of data is smaller than the line group received from the line buffer, and wherein the input slice of data has a size corresponding to a size of the two-dimensional shift register array;
executing, by each execution lane of the array of execution lanes, program code to process image data of the input data slice loaded into the two-dimensional shift register array, wherein executing the program code causes each execution lane to generate, from the image data of the input data slice, a respective output value of an output data slice of image data stored in the two-dimensional shift register array; and
providing an output data slice of the image data computed by the execution lane array back to the data slice generator.
Applications Claiming Priority (4)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/694,806 US10291813B2 (en) | 2015-04-23 | 2015-04-23 | Sheet generator for image processor |
US14/694,806 | 2015-04-23 | ||
PCT/US2016/025895 WO2016171882A1 (en) | 2015-04-23 | 2016-04-04 | Sheet generator for image processor |
CN201680019786.9A CN107438861B (en) | 2015-04-23 | 2016-04-04 | Data sheet generator for image generator |
Related Parent Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201680019786.9A Division CN107438861B (en) | 2015-04-23 | 2016-04-04 | Data sheet generator for image generator |
Publications (2)
Publication Number | Publication Date |
---|---|
CN112967169A true CN112967169A (en) | 2021-06-15 |
CN112967169B CN112967169B (en) | 2022-06-03 |
Family
ID=55858888
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201680019786.9A Active CN107438861B (en) | 2015-04-23 | 2016-04-04 | Data sheet generator for image generator |
CN202110171547.8A Active CN112967169B (en) | 2015-04-23 | 2016-04-04 | Data sheet generator for image generator |
Family Applications Before (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201680019786.9A Active CN107438861B (en) | 2015-04-23 | 2016-04-04 | Data sheet generator for image generator |
Country Status (7)
Country | Link |
---|---|
US (4) | US10291813B2 (en) |
EP (1) | EP3286725B1 (en) |
JP (2) | JP6563512B2 (en) |
KR (2) | KR102146515B1 (en) |
CN (2) | CN107438861B (en) |
DE (1) | DE112016001835T5 (en) |
WO (1) | WO2016171882A1 (en) |
Families Citing this family (15)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10291813B2 (en) * | 2015-04-23 | 2019-05-14 | Google Llc | Sheet generator for image processor |
US10313641B2 (en) | 2015-12-04 | 2019-06-04 | Google Llc | Shift register with reduced wiring complexity |
US9830150B2 (en) | 2015-12-04 | 2017-11-28 | Google Llc | Multi-functional execution lane for image processor |
US10387988B2 (en) | 2016-02-26 | 2019-08-20 | Google Llc | Compiler techniques for mapping program code to a high performance, power efficient, programmable image processing hardware platform |
US10204396B2 (en) * | 2016-02-26 | 2019-02-12 | Google Llc | Compiler managed memory for image processor |
US10380969B2 (en) | 2016-02-28 | 2019-08-13 | Google Llc | Macro I/O unit for image processor |
US10546211B2 (en) | 2016-07-01 | 2020-01-28 | Google Llc | Convolutional neural network on programmable two dimensional image processor |
US20180005346A1 (en) * | 2016-07-01 | 2018-01-04 | Google Inc. | Core Processes For Block Operations On An Image Processor Having A Two-Dimensional Execution Lane Array and A Two-Dimensional Shift Register |
US20180007302A1 (en) | 2016-07-01 | 2018-01-04 | Google Inc. | Block Operations For An Image Processor Having A Two-Dimensional Execution Lane Array and A Two-Dimensional Shift Register |
US20180005059A1 (en) | 2016-07-01 | 2018-01-04 | Google Inc. | Statistics Operations On Two Dimensional Image Processor |
KR20180012439A (en) * | 2016-07-27 | 2018-02-06 | 삼성전자주식회사 | Accelerator in convolutional neural network and operation method thereof |
US10789202B2 (en) * | 2017-05-12 | 2020-09-29 | Google Llc | Image processor with configurable number of active cores and supporting internal network |
US10489199B2 (en) * | 2017-05-12 | 2019-11-26 | Google Llc | Program code transformations to improve image processor runtime efficiency |
US10489878B2 (en) * | 2017-05-15 | 2019-11-26 | Google Llc | Configurable and programmable image processor unit |
US10552939B1 (en) | 2019-02-12 | 2020-02-04 | Google Llc | Image processor complex transfer functions |
Citations (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN101202914A (en) * | 2006-12-01 | 2008-06-18 | 汤姆森许可贸易公司 | Array of processing elements with local registers |
CN103019656A (en) * | 2012-12-04 | 2013-04-03 | 中国科学院半导体研究所 | Dynamically reconfigurable multi-stage parallel single instruction multiple data array processing system |
CN103201764A (en) * | 2010-11-12 | 2013-07-10 | 高通股份有限公司 | Parallel image processing using multiple processors |
US20140164737A1 (en) * | 2012-12-06 | 2014-06-12 | Kalray | Execution efficiency in a single-program, multiple-data processor |
US20150086134A1 (en) * | 2013-09-20 | 2015-03-26 | The Board Of Trustees Of The Leland Stanford Junior University | Low power programmable image processor |
Family Cites Families (88)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4445177A (en) | 1981-05-22 | 1984-04-24 | Data General Corporation | Digital data processing system utilizing a unique arithmetic logic unit for handling uniquely identifiable addresses for operands and instructions |
US4835712A (en) | 1986-04-14 | 1989-05-30 | Pixar | Methods and apparatus for imaging volume data with shading |
JP2554255B2 (en) | 1987-03-23 | 1996-11-13 | 旭光学工業株式会社 | Filtering device |
DE3851005T2 (en) | 1987-06-01 | 1995-04-20 | Applied Intelligent Syst Inc | Parallel neighboring processing system and method. |
US4935894A (en) | 1987-08-31 | 1990-06-19 | Motorola, Inc. | Multi-processor, multi-bus system with bus interface comprising FIFO register stocks for receiving and transmitting data and control information |
US5253308A (en) | 1989-06-21 | 1993-10-12 | Amber Engineering, Inc. | Massively parallel digital image data processor using pixel-mapped input/output and relative indexed addressing |
WO1994009595A1 (en) | 1991-09-20 | 1994-04-28 | Shaw Venson M | Method and apparatus including system architecture for multimedia communications |
JP3482660B2 (en) | 1993-09-08 | 2003-12-22 | ソニー株式会社 | Image data processing apparatus and image data processing method |
US5612693A (en) | 1994-12-14 | 1997-03-18 | International Business Machines Corporation | Sliding window data compression using a toroidal bit shift register |
JP3573755B2 (en) | 1996-01-15 | 2004-10-06 | シーメンス アクチエンゲゼルシヤフト | Image processing processor |
US6031573A (en) | 1996-10-31 | 2000-02-29 | Sensormatic Electronics Corporation | Intelligent video information management system performing multiple functions in parallel |
US5892962A (en) | 1996-11-12 | 1999-04-06 | Lucent Technologies Inc. | FPGA-based processor |
US6661421B1 (en) | 1998-05-21 | 2003-12-09 | Mitsubishi Electric & Electronics Usa, Inc. | Methods for operation of semiconductor memory |
US6366289B1 (en) | 1998-07-17 | 2002-04-02 | Microsoft Corporation | Method and system for managing a display image in compressed and uncompressed blocks |
US6587158B1 (en) | 1998-07-23 | 2003-07-01 | Dvdo, Inc. | Method and apparatus for reducing on-chip memory in vertical video processing |
US7010177B1 (en) | 1998-08-27 | 2006-03-07 | Intel Corporation | Portability of digital images |
EP1164544B1 (en) | 1999-03-16 | 2011-11-02 | Hamamatsu Photonics K.K. | High-speed vision sensor |
US7792298B2 (en) | 1999-06-30 | 2010-09-07 | Silverbrook Research Pty Ltd | Method of using a mobile device to authenticate a printed token and output an image associated with the token |
JP3922859B2 (en) | 1999-12-28 | 2007-05-30 | 株式会社リコー | Image processing apparatus, image processing method, and computer-readable recording medium storing program for causing computer to execute the method |
US6745319B1 (en) | 2000-02-18 | 2004-06-01 | Texas Instruments Incorporated | Microprocessor with instructions for shuffling and dealing data |
US6728862B1 (en) | 2000-05-22 | 2004-04-27 | Gazelle Technology Corporation | Processor array and parallel data processing methods |
US6728722B1 (en) | 2000-08-28 | 2004-04-27 | Sun Microsystems, Inc. | General data structure for describing logical data spaces |
US6986025B2 (en) | 2001-06-11 | 2006-01-10 | Broadcom Corporation | Conditional execution per lane |
US7286717B2 (en) | 2001-10-31 | 2007-10-23 | Ricoh Company, Ltd. | Image data processing device processing a plurality of series of data items simultaneously in parallel |
JP4146654B2 (en) | 2002-02-28 | 2008-09-10 | 株式会社リコー | Image processing circuit, composite image processing circuit, and image forming apparatus |
US9170812B2 (en) | 2002-03-21 | 2015-10-27 | Pact Xpp Technologies Ag | Data processing system having integrated pipelined array data processor |
WO2003088033A1 (en) | 2002-04-09 | 2003-10-23 | University Of Rochester | Multiplier-based processor-in-memory architectures for image and graphics processing |
JP2004013873A (en) | 2002-06-03 | 2004-01-15 | Sony Corp | Image processor |
AU2003286131A1 (en) | 2002-08-07 | 2004-03-19 | Pact Xpp Technologies Ag | Method and device for processing data |
GB2398446B (en) | 2003-02-12 | 2006-06-07 | Snell & Wilcox Ltd | Image processing |
US20060044576A1 (en) | 2004-07-30 | 2006-03-02 | Kabushiki Kaisha Toshiba | Apparatus for image processing |
US7667764B2 (en) | 2004-06-04 | 2010-02-23 | Konica Minolta Holdings, Inc. | Image sensing apparatus |
KR100614647B1 (en) * | 2004-07-02 | 2006-08-22 | 삼성전자주식회사 | Register array structure for effective edge filtering operation of deblocking filter |
JP4219887B2 (en) | 2004-12-28 | 2009-02-04 | 富士通マイクロエレクトロニクス株式会社 | Image processing apparatus and image processing method |
ATE504043T1 (en) | 2005-04-28 | 2011-04-15 | Univ Edinburgh | RECONFIGURABLE INSTRUCTION CELL ARRAY |
US7882339B2 (en) | 2005-06-23 | 2011-02-01 | Intel Corporation | Primitives to enhance thread-level speculation |
JP2007067917A (en) | 2005-08-31 | 2007-03-15 | Matsushita Electric Ind Co Ltd | Image data processing apparatus |
US7602974B2 (en) | 2005-10-21 | 2009-10-13 | Mobilic Technology (Cayman) Corp. | Universal fixed-pixel-size ISP scheme |
FR2895103B1 (en) | 2005-12-19 | 2008-02-22 | Dxo Labs Sa | METHOD AND SYSTEM FOR PROCESSING DIGITAL DATA |
US7802073B1 (en) | 2006-03-29 | 2010-09-21 | Oracle America, Inc. | Virtual core management |
JP2007304803A (en) | 2006-05-10 | 2007-11-22 | Fuji Xerox Co Ltd | Image processor |
US20080111823A1 (en) | 2006-11-13 | 2008-05-15 | Faraday Technology Corp. | Graphics processing system |
US8321849B2 (en) | 2007-01-26 | 2012-11-27 | Nvidia Corporation | Virtual architecture and instruction set for parallel thread computing |
US20080244222A1 (en) | 2007-03-30 | 2008-10-02 | Intel Corporation | Many-core processing using virtual processors |
US8068114B2 (en) | 2007-04-30 | 2011-11-29 | Advanced Micro Devices, Inc. | Mechanism for granting controlled access to a shared resource |
JP4389976B2 (en) | 2007-06-29 | 2009-12-24 | ブラザー工業株式会社 | Image processing apparatus and image processing program |
JP2009021459A (en) | 2007-07-13 | 2009-01-29 | Fuji Xerox Co Ltd | Method for driving surface emitting semiconductor laser and optical transmission module |
JP4844853B2 (en) | 2007-09-05 | 2011-12-28 | 国立大学法人東北大学 | Solid-state imaging device and driving method thereof |
JP4917561B2 (en) | 2008-03-18 | 2012-04-18 | 株式会社リコー | Image processing device |
CN102047241B (en) | 2008-05-30 | 2014-03-12 | 先进微装置公司 | Local and global data share |
US8098894B2 (en) | 2008-06-20 | 2012-01-17 | Yahoo! Inc. | Mobile imaging device as navigator |
JP4999791B2 (en) | 2008-06-30 | 2012-08-15 | キヤノン株式会社 | Information processing apparatus, control method thereof, and program |
US8456480B2 (en) | 2009-01-14 | 2013-06-04 | Calos Fund Limited Liability Company | Method for chaining image-processing functions on a SIMD processor |
US8332794B2 (en) | 2009-01-22 | 2012-12-11 | Taiwan Semiconductor Manufacturing Company, Ltd. | Circuits and methods for programmable transistor array |
WO2010093828A1 (en) * | 2009-02-11 | 2010-08-19 | Quartics, Inc. | Front end processor with extendable data path |
KR101572879B1 (en) | 2009-04-29 | 2015-12-01 | 삼성전자주식회사 | Dynamic parallel system and method for parallel application program |
US20110055495A1 (en) | 2009-08-28 | 2011-03-03 | Qualcomm Incorporated | Memory Controller Page Management Devices, Systems, and Methods |
US8976195B1 (en) | 2009-10-14 | 2015-03-10 | Nvidia Corporation | Generating clip state for a batch of vertices |
US8436857B2 (en) | 2009-10-20 | 2013-05-07 | Oracle America, Inc. | System and method for applying level of detail schemes |
US8595428B2 (en) | 2009-12-22 | 2013-11-26 | Intel Corporation | Memory controller functionalities to support data swizzling |
JP2011165132A (en) * | 2010-02-15 | 2011-08-25 | Seiko Epson Corp | Image processing apparatus, image processing circuit, and image processing method |
US8749667B2 (en) | 2010-08-02 | 2014-06-10 | Texas Instruments Incorporated | System and method for maintaining maximum input rate while up-scaling an image vertically |
CN101968851B (en) * | 2010-09-09 | 2012-08-08 | 西安电子科技大学 | Medical image processing method based on dictionary studying upsampling |
US8508612B2 (en) | 2010-09-30 | 2013-08-13 | Apple Inc. | Image signal processor line buffer configuration for processing ram image data |
CN102572207B (en) * | 2010-12-30 | 2014-05-14 | 无锡华润矽科微电子有限公司 | Color space transformation method suitable for joint photographic experts group (JPEG) image |
US8797323B2 (en) | 2011-01-18 | 2014-08-05 | Intel Corporation | Shadowing dynamic volumetric media |
WO2012105174A1 (en) | 2011-01-31 | 2012-08-09 | パナソニック株式会社 | Program generation device, program generation method, processor device, and multiprocessor system |
US9092267B2 (en) | 2011-06-20 | 2015-07-28 | Qualcomm Incorporated | Memory sharing in graphics processing unit |
US20130027416A1 (en) | 2011-07-25 | 2013-01-31 | Karthikeyan Vaithianathan | Gather method and apparatus for media processing accelerators |
US9641866B2 (en) | 2011-08-18 | 2017-05-02 | Qualcomm Incorporated | Applying partition-based filters |
JP5742651B2 (en) | 2011-10-15 | 2015-07-01 | コニカミノルタ株式会社 | Image processing apparatus, linkage method, and linkage program |
JP5746100B2 (en) | 2011-12-27 | 2015-07-08 | 京セラドキュメントソリューションズ株式会社 | Image forming apparatus |
US8823736B2 (en) | 2012-01-20 | 2014-09-02 | Intel Corporation | Graphics tiling architecture with bounding volume hierarchies |
US10244246B2 (en) | 2012-02-02 | 2019-03-26 | Texas Instruments Incorporated | Sub-pictures for pixel rate balancing on multi-core platforms |
US9235769B2 (en) | 2012-03-15 | 2016-01-12 | Herta Security, S.L. | Parallel object detection method for heterogeneous multithreaded microarchitectures |
TWI520598B (en) | 2012-05-23 | 2016-02-01 | 晨星半導體股份有限公司 | Image processing apparatus and image processing method |
CN102685439A (en) * | 2012-05-28 | 2012-09-19 | 上海海事大学 | Device and method for realizing image data transmission control with field programmable gate array (FPGA) |
US20140019486A1 (en) | 2012-07-13 | 2014-01-16 | Amitava Majumdar | Logic Content Processing for Hardware Acceleration of Multi-Pattern Search |
US9232139B2 (en) | 2012-07-24 | 2016-01-05 | Apple Inc. | Image stabilization using striped output transformation unit |
US9378181B2 (en) | 2012-11-09 | 2016-06-28 | Intel Corporation | Scalable computing array |
CN103179408B (en) * | 2012-11-27 | 2016-01-06 | 上海高清数字科技产业有限公司 | A kind of system and method solving chromaticity sampling mistake |
US8954992B2 (en) | 2013-03-15 | 2015-02-10 | Lenovo Enterprise Solutions (Singapore) Pte. Ltd. | Distributed and scaled-out network switch and packet processing |
US9058673B2 (en) | 2013-03-15 | 2015-06-16 | Oracle International Corporation | Image mosaicking using a virtual grid |
US9589175B1 (en) * | 2014-09-30 | 2017-03-07 | Amazon Technologies, Inc. | Analyzing integral images with respect to Haar features |
US9818166B2 (en) | 2015-01-16 | 2017-11-14 | Intel Corporation | Graph-based application programming interface architectures with producer/consumer nodes for enhanced image processing parallelism |
US9749548B2 (en) | 2015-01-22 | 2017-08-29 | Google Inc. | Virtual linebuffers for image signal processors |
US10291813B2 (en) * | 2015-04-23 | 2019-05-14 | Google Llc | Sheet generator for image processor |
US10310998B2 (en) * | 2015-06-30 | 2019-06-04 | Microsoft Technology Licensing, Llc | Direct memory access with filtering |
-
2015
- 2015-04-23 US US14/694,806 patent/US10291813B2/en active Active
-
2016
- 2016-04-04 JP JP2017550906A patent/JP6563512B2/en active Active
- 2016-04-04 KR KR1020207005068A patent/KR102146515B1/en active IP Right Grant
- 2016-04-04 DE DE112016001835.5T patent/DE112016001835T5/en active Pending
- 2016-04-04 EP EP16719164.2A patent/EP3286725B1/en active Active
- 2016-04-04 CN CN201680019786.9A patent/CN107438861B/en active Active
- 2016-04-04 KR KR1020177028006A patent/KR20170125393A/en not_active Application Discontinuation
- 2016-04-04 CN CN202110171547.8A patent/CN112967169B/en active Active
- 2016-04-04 WO PCT/US2016/025895 patent/WO2016171882A1/en active Application Filing
-
2017
- 2017-05-18 US US15/598,933 patent/US10284744B2/en active Active
-
2019
- 2019-03-04 US US16/291,047 patent/US10560598B2/en active Active
- 2019-07-24 JP JP2019136231A patent/JP6793228B2/en active Active
-
2020
- 2020-02-10 US US16/786,359 patent/US11140293B2/en active Active
Patent Citations (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN101202914A (en) * | 2006-12-01 | 2008-06-18 | 汤姆森许可贸易公司 | Array of processing elements with local registers |
CN103201764A (en) * | 2010-11-12 | 2013-07-10 | 高通股份有限公司 | Parallel image processing using multiple processors |
CN103019656A (en) * | 2012-12-04 | 2013-04-03 | 中国科学院半导体研究所 | Dynamically reconfigurable multi-stage parallel single instruction multiple data array processing system |
US20140164737A1 (en) * | 2012-12-06 | 2014-06-12 | Kalray | Execution efficiency in a single-program, multiple-data processor |
US20150086134A1 (en) * | 2013-09-20 | 2015-03-26 | The Board Of Trustees Of The Leland Stanford Junior University | Low power programmable image processor |
Non-Patent Citations (1)
Title |
---|
P H J VAN OOSTERHOUT: "OPTIMIZED PIXEL TEMPLATE IMAGE CORRELATOR", 《HTTP://ALEXANDRIA.TUE.NL/EXTRA2/AFSTVERSL/E/563812.PDF》 * |
Also Published As
Publication number | Publication date |
---|---|
KR20200021003A (en) | 2020-02-26 |
US20170257515A1 (en) | 2017-09-07 |
EP3286725A1 (en) | 2018-02-28 |
CN107438861B (en) | 2021-02-26 |
CN112967169B (en) | 2022-06-03 |
KR20170125393A (en) | 2017-11-14 |
CN107438861A (en) | 2017-12-05 |
US20160316094A1 (en) | 2016-10-27 |
JP6793228B2 (en) | 2020-12-02 |
DE112016001835T5 (en) | 2018-02-15 |
EP3286725B1 (en) | 2021-10-06 |
JP6563512B2 (en) | 2019-08-21 |
US10560598B2 (en) | 2020-02-11 |
US11140293B2 (en) | 2021-10-05 |
JP2019215887A (en) | 2019-12-19 |
US10284744B2 (en) | 2019-05-07 |
US10291813B2 (en) | 2019-05-14 |
JP2018513474A (en) | 2018-05-24 |
US20190208075A1 (en) | 2019-07-04 |
WO2016171882A1 (en) | 2016-10-27 |
US20200186667A1 (en) | 2020-06-11 |
KR102146515B1 (en) | 2020-08-21 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN112967169B (en) | Data sheet generator for image generator | |
JP7202987B2 (en) | Architecture for High Performance, Power Efficient, Programmable Image Processing | |
CN107563952B (en) | Convolutional neural network on programmable two-dimensional image processor | |
CN107430760B (en) | Two-dimensional shift array for image processor | |
KR101971657B1 (en) | Energy-efficient processor core architecture for image processors | |
CN107133908B (en) | Compiler managed memory for image processor | |
CN110300944B (en) | Image processor with configurable number of active cores and supporting internal network | |
KR102278021B1 (en) | Program code transformation to improve image processor runtime efficiency | |
CN110574067A (en) | Image processor I/O unit |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
GR01 | Patent grant | ||
GR01 | Patent grant |