US6760390B1 - Log-map metric calculation using the avg* kernel - Google Patents
Log-map metric calculation using the avg* kernel Download PDFInfo
- Publication number
- US6760390B1 US6760390B1 US09/696,784 US69678400A US6760390B1 US 6760390 B1 US6760390 B1 US 6760390B1 US 69678400 A US69678400 A US 69678400A US 6760390 B1 US6760390 B1 US 6760390B1
- Authority
- US
- United States
- Prior art keywords
- log
- add
- correction factor
- input arguments
- recited
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Expired - Lifetime, expires
Links
Images
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L1/00—Arrangements for detecting or preventing errors in the information received
- H04L1/004—Arrangements for detecting or preventing errors in the information received by using forward error control
- H04L1/0045—Arrangements at the receiver end
- H04L1/0055—MAP-decoding
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L25/00—Baseband systems
- H04L25/02—Details ; arrangements for supplying electrical power along data transmission lines
- H04L25/06—Dc level restoring means; Bias distortion correction ; Decision circuits providing symbol by symbol detection
- H04L25/067—Dc level restoring means; Bias distortion correction ; Decision circuits providing symbol by symbol detection providing soft decisions, i.e. decisions together with an estimate of reliability
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L27/00—Modulated-carrier systems
- H04L27/18—Phase-modulated carrier systems, i.e. using phase-shift keying
- H04L27/22—Demodulator circuits; Receiver circuits
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L27/00—Modulated-carrier systems
- H04L27/32—Carrier systems characterised by combinations of two or more of the types covered by groups H04L27/02, H04L27/10, H04L27/18 or H04L27/26
- H04L27/34—Amplitude- and phase-modulated carrier systems, e.g. quadrature-amplitude modulated carrier systems
- H04L27/38—Demodulator circuits; Receiver circuits
Definitions
- the present invention relates to a novel operator for decoding block and convolutional codes in digital communications systems and particularly for simplifying log-MAP decoding of block and convolutional codes.
- the operator the avg* representation of a kernel operation, may allow log-MAP decoding of many information services.
- the invention also relates to a low-complexity implementation of generating an optimal log-likelihood ratio (LLR) for use in decoders such as block and convolutional decoders.
- LLR log-likelihood ratio
- Block and convolutional codes which have been advantageous in digital communications systems, are among some techniques used to transport information reliably.
- a variety of methods can be used to decode block and convolutional codes and to recover the information.
- one method is a Viterbi algorithm, which is a maximum-likelihood decoding method that minimizes the probability of word error. Since a word is comprised of a sequence of symbols (or bits), the Viterbi algorithm is often called a sequence estimator. The Viterbi algorithm however does not minimize the probability of symbol (or bit) error.
- Another method for decoding block and convolutional codes uses a maximum aposterio (MAP) principle.
- MAP maximum aposterio
- MAP decoders make optimum symbol-by-symbol decisions, as well as providing “soft” reliability information which, for example, is desired in concatenated decoding systems such as turbo decoders.
- a possible algorithm for MAP decoding is the Bahl, Cocke, Jelink, and Rajiv (BCJR) algorithm. While the BCJR algorithm is the most commonly used MAP algorithm, the BCJR algorithm however suffers several shortcomings that make it difficult for hardware and software implementations, e.g., the requirement for multiplications and exponentiations.
- a MAP decoder requires forward and backward generalized Viterbi recursions on the code trellis, requiring sums of products of probabilities.
- a MAP decoder also computes likelihood ratios that are based on the results of the forward and backward recursions.
- the log-MAP algorithm couches the MAP decoder in the logarithmic domain, eliminating exponentiations and turning the products into sums, but also turning the sums into operations of a complicated function (i.e., log-add). This complicated function is the kernel operation of the log-MAP decoder that dominates the overall decoder complexity, similar to the add-compare-select (ACS) operation in a conventional Viterbi decoder.
- ACS add-compare-select
- the complicated function has been represented as the max* function, a maximization (max) operation plus a correction term.
- One common implementation method for the max* function computes the max and adds a correction term which is accessed from a lookup table. Although this method appears to be efficient, the table lookup may be too complex to implement in both software and hardware. For example, table lookups may cause pipeline stalls within processors.
- One sub-optimal implementation known as a max-log-MAP function, omits the correction term (i.e., max instead of max*).
- turbo code is, for example, being proposed for third generation (3G) cellular services.
- the decoders for turbo codes can be difficult to implement because they are complex and because the decoder is iterative. For instance, complexity estimates for turbo decoding 3G services can prohibit optimal (MAP or log-MAP) decoding of the constituent codes that comprise a turbo code.
- a sub-optimal algorithm such as the max-log-MAP or Soft Output Viterbi Algorithm (SOVA) may be used to meet the complexity constraints, either the decoder performance suffers from not using the optimal algorithm or number of iterations required to meet a specified performance increases. Therefore, there is a need for an algorithm that allows computationally efficient log-MAP decoding.
- the optimal soft value for bit k of a received symbol y, for any set of possible modulated (transmitted) symbols X is: ln ⁇ ⁇ ( p ⁇ ⁇ ( y
- x , x ⁇ X 1 ) ) ln ⁇ ⁇ ( ⁇ X 0 ⁇ ⁇ p ⁇ ⁇ ( y
- Equation (1) is complex to implement, sub-optimal methods of generating soft values are employed.
- the current method of generating soft values is the dual-min, K ⁇ ⁇ ( min X 1 ⁇ ⁇ d 1 2 - min X 0 ⁇ ⁇ d 0 2 ) ,
- K is a scale factor proportional to the signal-to-noise ratio (SNR)
- X 1 is the set of constellation points with a “1” in the desired bit position
- X 0 is the set of constellation points with a “0” in the desired bit position.
- d 1 2 (d 0 2 ) is the squared Euclidean distance from the received symbol to the constellation symbol with a 1 (0) in the desired position.
- the dual-min essentially compares the received symbol to all possible transmitted symbols, and assigns a soft value based only on the closest symbol with a 0 and the closest symbol with a 1 in that bit position.
- the dual-min is much easier to implement than the optimal method, but it unfortunately suffers a performance degradation from the optimal method.
- FIG. 1 is a flowchart for implementing the max* kernel using a lookup table
- FIG. 2 is a flowchart for implementing the avg* kernel using a fourth-order correction factor
- FIG 3 graphically illustrates the accuracy of various approximations to the optimal log-add function ln(e x +e y );
- FIG. 4 shows an advantageous combination of the avg* kernel and the max operation
- FIG. 5 shows a sequential computation of an 8-input log-add
- FIG. 6 shows a tree-like representation of an 8-input log-add
- FIG. 7 shows a block diagram of a communication system including bit soft value generation and higher-order modulation
- FIG. 8 shows an example of a higher-order 8-PSK constellation and a received symbol point
- FIG. 9 shows the soft value generation for the example in FIG. 8 using two input log-add functions developed for turbo decoding applications.
- FIG. 10 shows the performance in decoded frame error rate (FER) for the present invention using the avg* method and constant-log-MAP method compared to the optimal soft value generation and the dual-min prior art for 8-PSK, 16-QAM, 64-QAM, and 256QAM.
- FER decoded frame error rate
- Optimal decoding of high data rate services can exceed complexity constraints of many hardware and software implementations. For example, current complexity estimates for turbo decoding high data rate 3G services prohibit optimal decoding of the constituent codes within turbo codes. While sub-optimal algorithms such as the max-log-MAP or SOVA may be used to meet the complexity constraints, performance suffers due to the inability to use optimal algorithms.
- a novel avg* representation is proposed for the log-add kernel operation of the log-MAP decoder to simplify decoding, and to allow log-MAP decoding of many high data rate services. The avg* function provides a low complexity alternative to the max* kernel operation.
- the log-add kernel is computed using an average “(x+y)/2” plus correction factors instead of the max plus correction terms.
- the correction factor is comprised of a constant and a transcendental function.
- the transcendental function can be accurately represented with the first few terms of its Taylor series expansion.
- the Taylor expansion may be modified such that the transcendental function can be computed with simple additions, multiplications, and shift operations.
- the log-add kernel operation may be extended to more than two arguments, for application, for example, to the final log likelihood ratio (LLR) computation in the log-MAP algorithm, as well as, for example, the kernel operation of the generalized Viterbi decoder with a branch fan-in greater than 2.
- LLR final log likelihood ratio
- the log-add kernel operation with several variations may be extended to generating soft values for higher-order modulation.
- the described embodiments provide a maximum a posteriori (MAP) decoding method and system in which a code graph is generated and used.
- MAP maximum a posteriori
- block and convolutional codes can be implemented on a code graph, or more specifically a code trellis.
- a code graph which is a generalization of a code trellis, allows LLR computation to be included for describing decoding methods.
- a MAP decoder can utilize the graph structure for making the symbol-by-symbol decisions.
- a MAP decoder examines the probability p(s′, s, y) of transitioning from state s′ to state s during the k th section of the graph, given an entire received sequence y.
- s′), and future ⁇ k (s) p(y j>k
- the notation “y j ⁇ k ” refers to the sequence of symbols that precedes the k th symbol of y.
- the alpha and beta probabilities are calculated through forward and backward generalized Viterbi recursions on the code graph, each of which also involves sums of products of probabilities. Likelihood ratios are also computed from the three probabilities.
- Implementing the MAP algorithm in the log domain i.e., log-MAP algorithm
- the function (2) is the kernel operation of the log-MAP decoder that dominates the overall decoder complexity, similar to the add-compare-select (ACS) in conventional Viterbi decoding.
- the function (2) is one example of computing a logarithm of a sum of a plurality of exponentiated input arguments. Function (2) illustrates an example for two input arguments, x and y. Table 1 lists some of the properties of the log-add function.
- equation (2) is represented as the max* operation, as follows:
- equation (3) is a max operation plus a correction term based on an absolute difference of the arguments x and y.
- the max term in equation (3) is defined as a primary term.
- the sub-optimal log-MAP with the correction term omitted i.e., max instead of max* is known as the max-log-MAP.
- FIG. 1 illustrates a flowchart for implementing the max* algorithm. Note that finding the max is simple but the overhead for the correction term is quite high.
- Equation (4) implements an average (avg) plus a correction factor comprised of a constant and a transcendental function based on a difference.
- the resulting expansion, a sixth order correction factor, has three terms and is f ⁇ ⁇ ( z ) ⁇
- the constant within equation (4) may be omitted under certain conditions and will be shown later. However, for illustration purposes, the constant shall be kept.
- the Taylor expansion can be modified such that the correction factor can be computed with simple additions, multiplications, and shift operations. ln ⁇ ⁇ ( e x + e y ) ⁇ x + y 2 + ln ⁇ ⁇ 2 + 1 2 ⁇ ⁇ ( x - y 2 ) 2 - 1 16 ⁇ ⁇ ( x - y 2 ) 4 ( 6 )
- Equation (6) the Taylor series expansion is represented by two terms. Note that factors of two, such as ⁇ fraction (1/16) ⁇ , can be implemented with shifts, such as right shifts. In many cases, only a single term of the expansion may be necessary, resulting in ln ⁇ ⁇ ( e x + e y ) ⁇ x + y 2 + ln ⁇ ⁇ 2 + 1 2 ⁇ ⁇ ( x - y 2 ) 2 ( 7 )
- the quadratic term can be dropped altogether (i.e., the Taylor series expansion is represented by zero terms) leaving only the average plus a constant
- FIG. 2 which is a flowchart for implementing equation (6), illustrates that the new representation does reduce the implementation cost over the table lookup approach.
- FIG. 2 which is a flowchart for implementing equation (6), illustrates that the new representation does reduce the implementation cost over the table lookup approach.
- FIG. 2 when compared to FIG. 1, there is the ability to operate the blocks in parallel. This ability allows the avg* kernel representation to execute faster and potentially allows the steps to be combined. For example in information processors such as digital signal processors (DSPs), multiplication and addition can occur concurrently.
- DSPs digital signal processors
- multiplication and addition can occur concurrently.
- the complexity reduction does not include some efficiencies gained by pipelining and algorithm simplification.
- An alternate preferred embodiment combines the avg* and the max operation, as shown in FIG. 4 .
- avg* when
- ln ⁇ ⁇ ( e x + e y ) ⁇ x x - y > T y y - x > T ( x + y 2 ) + f ⁇ ⁇ ( ⁇ x - y ⁇ ) else ( 8 )
- Equation (8) is preferably implemented with the correction factor being a constant, such as ln 2.
- This alternate preferred embodiment has the advantage of close approximation to the true log-add kernel, and the advantage of reduced computation burden since the terms of equation (8) can be produced via a parallel circuit or instructions.
- y n ln(e x 1 + . . . +e x n ).
- y n ln(e x 1 + . . . +e x n ) is a logarithm of a sum of a plurality (i.e., 8) of exponentiated input arguments, x 1 , . . . , x 8 .
- the 8-argument function can be computed sequentially with
- equation (9) can be used with any representation of the two-argument function
- the two-argument avg* can be applied to the final log likelihood ratio computation in the log-MAP algorithm as well as the kernel operation of the generalized Viterbi decoder.
- y n ln(e x 1 + . . .
- the avg* is also generalized to n arguments.
- the n-argument avg* is attractive because summing values is extremely simple to implement in hardware or software, much easier than finding pairwise or n-wise maxima. Furthermore, the division by n can be avoided since the result is used in a likelihood ratio.
- Table 1 indicates that the two-argument log-add function (and hence the avg* function) is invariant to the addition of constants. This property suggests that the ln 2 term within the avg* function can be disregarded (the preferred embodiment but not in the alternate preferred embodiment) when performing a pairwise log-add. Furthermore, the property suggests that any constant can be added (or subtracted) without changing the log-add. However, for an n-argument log-add (n>2), the method how arguments are added affects how constants are treated. For example, there are several methods of-computing the 8-argument function for the 8-state code in the 3GPP standard. FIG. 5 and FIG.
- FIG. 6 suggests that a tree-like representation to implement an n-argument log-add provides a flexibility of eliminating constants, such as ln 2. Since the tree-like representation itself can apply to any kernel operation (not just the avg*) within a log-MAP decoder, it provides a low complexity approach for implementing a log-MAP decoder. However, it is more advantageous for kernel operations having constants, such as the avg*. Although the tree-like representation may require a little more memory for storing intermediate results, the increase is minor when examining the overall memory needed for a decoder.
- the avg* representation of the kernel operation of the log-MAP decoder simplifies log-MAP decoding by avoiding table lookups.
- the simplification to the kernel operation of the log-MAP decoder can allow cellular 3G products to implement an “optimal” log-MAP decoder within software and hardware for many 3G services.
- Products using the optimal log-MAP decoder, examples include turbo decoders, will have better performance for a given number of iterations, or require a smaller number of iterations for a performance target
- the avg* representation can also be used to improve future hardware log-MAP decoders or accelerators.
- the log-add kernel is also present in generating soft values for higher-order modulations.
- modulation a group of bits is mapped into a symbol.
- the reciprocal operation occurs where a symbol is mapped into soft values.
- an accurate soft value can improve decoder performance.
- mapping more than two bits per symbol include 8-PSK (phase shift keying), 16-QAM (quadrature amplitude modulation), 64-QAM, and 256-QAM.
- the optimal method of generating soft values is comprised of transcendental functions that are impracticable to implement
- Equation (11) uses a log-add, a logarithm of a sum of a plurality of exponentiated input arguments with the input arguments being ⁇ d 0 2 ( ⁇ d 0 2 ). Since the log-add function can be difficult to implement, it is approximated.
- max* Another method of approximating the log-add function ln(e x +e y ) is the max*, shown in equation (3).
- the primary operation is a maximum (max) operator and a correction term, In(1+e ⁇
- parameterized correction factor refers to a correction factor that has definable terms, such as scalars (e.g., S), thresholds, and constants.
- the parameterized correction factor includes a constant C and a threshold T.
- avg* approximation Another method is the avg* approximation, which is shown in equation (4).
- the correction factor in the avg* approximation can be implemented in a variety of ways, including equation (6). Note that in equation (6), the correction factor is not parameterized.
- a preferred embodiment combines the avg* with the max operation, yielding ln ⁇ ⁇ ( e x + e y ) ⁇ ⁇ x x - y > T y y - x > T ( x + y ) 2 + C else . ( 14 )
- the parameterized correction factor for the avg* method which is comprised of a parameter T and a constant C, can be optimized for turbo decoding.
- C and T were optimized for turbo decoding, those parameters may not be optimal for soft value generation.
- the log-add function can have two or more sets of parameters.
- one set of parameters can be used for generating soft values while another set of parameters can be used for decoding, such as turbo decoding and log-MAP decoding.
- equation (14) defines an avg* operation for generating soft values while equation (8) defines an avg* operation for log-MAP decoding.
- the parameters in equation (14) can be different from the parameters in equation (8).
- FIG. 7 shows an example of a higher-order 8-PSK constellation and a received symbol point
- equation (11) requires the use of multi-input log-add functions.
- An n-input log-add y n ln(e x 1 +. . . e x 1 ) can be computed recursively using equation (9) or with a tree-like representation.
- the recursive formulation can be used with any of the methods, such as the constant-log-MAP, the linear-log-MAP, the max*, or the avg*.
- Equation (15) extends the two-input avg* method to a multi-input function.
- the multi-input log-add due to generating soft values for higher-order modulation can be computed advantageously using a tree-like representation.
- FIG. 9 shows the soft value generation for the example in FIG. 8 using a tree-like representation of two-input log-add functions.
- the log add functions in a tree-like representation are defined as “nodes.” In the example in FIG. 9, the nodes have two inputs.
- the results indicate that using a low-complexity log-add kernel developed for turbo decoding but optimized for soft value generation can offer up to 0.25 dB or more improvement in an AWGN channel over the prior art dual-min algorithm.
- the results also indicate that the application of the constant-log-MAP with parameters optimized for turbo decoding does not perform as well as it did for log-MAP turbo decoding. Because these low-complexity methods which use a primary term and parameterized correction factor are implemented without a table lookup, the overall complexity is roughly the same as the dual-min algorithm.
- FIG. 1, numeral 100 depicts a flowchart for implementing a max* kernel with a lookup table for adding variables (arguments) x and y.
- Module 110 computes a maximum between the variables x and y.
- Module 120 which in some implementations can occur parallel with Module 110 , computes z, an absolute difference between the variables x and y.
- Module 125 which may be necessary for certain arithmetic representations, converts the absolute difference z into an integer. For example, the conversion in Module 125 can be a simple scaling.
- Module 130 computes an address for a lookup table using the integer. For instance, in processors, Module 130 can represent a pointer operation. Once the address is computed, Module 135 fetches a correction term from memory.
- Module 140 adds the correction term to the maximum of x and y.
- the flowchart illustrates that computing a max* with a lookup table can be difficult to implement because there are limited opportunities for parallelism.
- FIG. 2 depicts a flowchart for implementing an avg* kernel for adding variables x and y.
- the flowchart illustrates an example for a fourth-order correction factor, such as the factor in equation (6). Extending the flowchart to a larger order correction factor can be performed easily. Also reducing the number of terms (lower order correction factor) can be accomplished by eliminating several modules. Furthermore, the sequence of modules may be reordered for reasons such as numerical accuracy and pipelining.
- FIG. 2 provides an example of one implementation.
- Module 210 computes an average of variables (arguments) x and y.
- Module 215 provides a capability of adding a constant, such as ln 2, to the average. When the constant is zero, Module 215 can be removed.
- Module 220 which in some implementations can occur parallel with Module 210 , computes z, a difference between the variables x and y.
- Module 225 squares the difference z to produce z 2 .
- Module 230 scales the squared difference z 2 while Module 235 adds the scaled squared difference.
- the scaling may be performed with shifts.
- information processors such as in DSPs, the scaling and addition within Modules 230 and 235 , respectively, may be combined because DSPs can multiply and accumulate in one operation.
- Module 240 computes the square of z 2 (i.e., z 4 ) while Module 245 scales z 4 .
- Module 250 adds the scaled z 4 term to produce the avg* with a fourth order correction factor.
- the scaling within Module 245 may be performed with shifts.
- the scaling and addition within Modules 245 and 250 may be combined because some implementations can multiply and accumulate concurrently.
- the flowchart illustrates that computing the avg* kernel provides several opportunities for parallelism. As a result, the kernel can meet timing constraints while maintaining accuracy and lowering complexity.
- FIG. 3 illustrates that the max operation deviates the largest from the log-add curve when the absolute difference
- the approximation given by equation (6) closely follows the log-add curve.
- the approximation given by equation (7) starts to deviate from the log-add curve as the absolute difference increases.
- FIG. 4, numeral 400 provides an example for the second preferred embodiment represented by equation (8).
- a joint max and avg* block 400 operates on input arguments x 405 and y 406 to produce a log-add sum w 445 .
- a subtractor 410 is responsive to the input arguments x 405 and y 406 and computes a difference 415 .
- a comparator 420 is responsive to the difference 415 and a threshold T 418 to produce a signal 425 indicating the relationship of the difference 415 and the threshold T 418 .
- An avg* operator 430 is responsive to the input arguments x 405 and y 406 and computes a sum 435 using the avg* operation.
- the avg* operation can be computed using the flowchart in FIG. 2 .
- the avg* operation can be computed using an average plus a constant
- a mux 440 is responsive to the input arguments x 405 and y 406 , the sum 435 , and the signal 425 .
- the mux 440 uses signal 425 to select one of the three inputs, input argument x 405 , input argument y 406 , and the sum 435 , as the log-add sum w 445 .
- FIG. 5 provides an example diagram for a sequential log-add addition of 8 input arguments (signals).
- the associative and commutative properties of the log-add function listed in Table 1 suggest that a large number of log-add permutations exist among the input signals x and the intermediate results y 1 .
- FIG. 5 illustrates just one possible permutation.
- a log-adder 510 is responsive to input signals x 1 504 and x 2 505 and computes an intermediate log-add sum y 2 515 .
- One example of a log-adder 510 is a max* operator.
- Another example of the log-adder 510 is an avg* operator.
- a log-adder 520 is responsive to the intermediate log-add sum y 2 515 and an input signal x 3 514 and computes an intermediate log-add sum y 3 525 .
- a log-adder 530 is responsive to the intermediate log-add sum y 3 525 and an input signal x 4 524 and computes an intermediate log-add sum y 4 535 .
- a log-adder 540 is responsive to the intermediate log-add sum y 4 535 and an input signal x 5 534 and computes an intermediate log-add sum y 5 545 .
- a log-adder 550 is responsive to the intermediate log-add sum y 545 and an input signal x 6 544 and computes an intermediate log-add sum y 6 555 .
- a log-adder 560 is responsive to the intermediate log-add sum y 6 555 and an input signal x 7 554 and computes an intermediate log-add sum y 7 565 .
- a log-adder 570 is responsive to the intermediate log-add sum y 7 565 and an input signal x 8 564 and computes a final log-add sum y 8 575 .
- FIG. 6 numeral 600 , provides an example diagram for a tree-like log-add addition of 8 input arguments (signals).
- the associative and commutative properties of the log-add function listed in Table 1 suggest that a large number of permutations exist among the input signals x and the intermediate results z 1 .
- FIG. 6 illustrates just one possible permutation.
- the tree-like log-add representation can apply to log-MAP decoding as well as generating soft values.
- a log-adder 610 is responsive to input signals x 1 601 and x 2 602 and computes an intermediate log-add sum z 1 615 .
- One example of a log-adder 610 is a max* operator.
- Another example of the log-adder 610 is an avg* operator.
- a log-adder 620 is responsive to the input signals x 3 603 and x 4 604 and computes an intermediate log-add sum z 2 625 .
- a log-adder 630 is responsive to the input signals x 5 605 and x 6 606 and computes an intermediate log-add sum z 3 635 .
- a log-adder 640 is responsive to the input signals x 7 607 and x 8 608 and computes an intermediate log-add sum z 4 645 .
- a log-adder 650 is responsive to the intermediate log-add sums z 1 615 and z 2 625 and computes an intermediate log-add sum z 5 655 .
- a log-adder 660 is responsive to the intermediate log-add sums z 3 635 and z 4 645 and computes an intermediate log-add sum z 6 665 .
- a log-adder 670 is responsive to the intermediate log-add sums z 5 655 and z 6 665 and computes a final log-add sum y 8 675 .
- FIG. 7, numeral 700 illustrates a block diagram of a baseband-equivalent model of a communication system 700 .
- an encoder 710 encodes an information sequence x(n) 705 to produce a vector of bits v(n) 715 .
- a higher-order modulator 720 includes an operation of mapping the vector of bits v(n) 715 into a vector of complex symbols c(n) 725 .
- One example of the mapping is grouping m bits into each symbol of the vector of complex symbols c(n) 725 . For instance, for 8-PSK, three bits are mapped onto a point on a circle in a complex plane.
- the vector of complex symbols c(n) 725 is transmitted through a channel 730 that possibly corrupts the vector 725 .
- One type of corruption is additive white Gaussian noise (AWGN).
- the output of the channel 730 is a vector of complex received symbols r(n) 735 .
- a soft value generator 740 processes the vector of complex received symbols r(n) 735 to produce a vector of soft values y(n) 745 .
- each symbol (element) of the vector of received complex symbols r(n) 735 can produce m soft values.
- the soft value generator 740 is comprised of a plurality of bit soft value generators. An example of a bit soft value generator is shown in FIG. 9 .
- the vector of soft values y(n) 745 is processed by a decoder 750 to produce an estimate of the information sequence b(n) 755 .
- FIG. 8, numeral 800 illustrates an example of a mapping for 8-PSK, a higher-order modulation.
- the notation (x,y,z) indicates a mapping of bits into a complex symbol of a constellation. For example, a bit sequence 1,1,1 is mapped into a complex symbol of ⁇ 1+j0.
- the notation s k represents a distance measure from an element r 736 to the k th complex symbol.
- element refers to a member of the vector of received complex symbols r(n) 735 .
- One example of a distance measure is squared Euclidean distance.
- the distance measure s 0 801 is the distance from the element r 736 and the complex symbol associated with the bits (0,0,0).
- the distance measure s 1 802 is the distance from the element r 736 and the complex symbol associated with the bits (0,0,1).
- the distance measure s 2 803 is the distance from the element r 736 and the complex symbol associated with the bits (0,1,0).
- the distance measure s 3 804 is the distance from the element r 736 and the complex symbol associated with the bits (0,1,1).
- the distance measure s 4 805 is the distance from the element r 736 and the complex symbol associated with the bits (1,0,0).
- the distance measure s 5 806 is the distance from the element r 736 and the complex symbol associated with the bits (1,0,1).
- the distance measure s 6 807 is the distance from the element r 736 and the complex symbol associated with the bits (1,1,0).
- the distance measure s 7 808 is the distance from the element r 736 and the complex symbol associated with the bits (1,1,1).
- FIG. 9, numeral 900 illustrates a block diagram for a bit soft value generator 900 .
- FIG. 9 is an example implementation for the higher-order modulation shown in FIG. 8 .
- the bit soft value generator 900 processes the distance measures 801 , 802 , 803 , 804 , 805 , 805 , 807 , and 808 to generate a soft value for the most significant bit (MSB) when the higher-order modulation is 8-PSK.
- the bit soft value generator 900 uses tree-like log-adds. In FIG.
- distance measures 801 , 802 , 803 , and 804 correspond to an MSB equal to “0” while distance measures 805 , 806 , 807 , and 808 correspond to an MSB equal to “1”.
- a negator 990 is responsive to an input distance measure, for example 801 , and negates the distance measure to produce a negative distance measure, for example 901 .
- a log-adder 910 is responsive to negative distance measures 901 and 902 and produces an intermediate sum z 1 915 .
- An example of the log-adder 910 includes a log-add approximation that has a primary term and a parameterized correction factor.
- a log-adder 920 is responsive to negative distance measures 903 and 904 and produces an intermediate sum z 2 925 .
- a log-adder 930 is responsive to negative distance measures 905 and 906 and produces an intermediate sum z 3 935 .
- a log-adder 940 is responsive to negative distance measures 907 and 908 and produces an intermediate sum z 4 945 .
- a log-adder 950 is responsive to the intermediate sums z 1 915 and z 2 925 and produces a log-add sum z 5 955 .
- a log-adder 960 is responsive to the intermediate sums z 3 935 and z 4 945 and produces a log-add sum z 6 965 .
- a subtractor 970 computes the difference between the log-add sums z 5 955 and z 6 965 and produces an intermediate soft bit value 975 .
- a scale factor K 978 multiplies the intermediate soft bit value 975 to produce a soft bit value 985 .
- the scale factor K 978 is defined in equation (11). Many permutations of FIG. 9 exist due to the log-add properties listed in Table 1. When K 978 is one, the multiplier 980 can be removed.
- the higher-order modulations shown on the graph are 8-PSK, 16-QAM, 64-QAM, and 256-QAM.
- the number of bits per symbol for the higher-order modulations is 3, 4, 6, and 8 respectively.
- a turbo decoder is used to simulate the performance of the different methods of generating soft values.
- the independent axis is signal-to-noise ratio (SNR), such as E b /N o , while the dependent axis is a frame-error-rate, which is a metric for evaluating decoder performance.
- SNR signal-to-noise ratio
- the channel applies AWGN.
- the general trend in FIG. 10 is that as the number of bits per symbol increase, the dual-min method requires more SNR to produce the same performance as the optimal method. However, the avg* method performs as well as the optimal method even as the number of bits per symbol increase.
- the results also indicate that the application of the constant-log-MAP with parameters optimized for turbo decoding does not perform as well as it did for log-MAP turbo decoding.
Abstract
Description
TABLE 1 |
Properties of the log-add function f(), where x, y, |
and z are variables while c is an arbitrary constant |
Property | ||
Additive identity | f(x,−∞) = x |
Commutative | f(x,y) = f(y,x) |
Associative | f(f(x,y),z) = f(x,f(y,z)) |
Compositions | f(f(x,y),z) = f(x,y,z) |
Addition of constants | f(x + c,y + c) = f(x,y) + c |
Compositions and constants | if g(x,y) ≡ f(x,y) + c, |
g(x,y,z,−∞) = g(g(x,y),g(z,−∞)) = f(x,y,z) + | |
2c, but g(x,y,z) ≠ f(x,y,z) + 2c | |
Claims (18)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US09/696,784 US6760390B1 (en) | 2000-10-25 | 2000-10-25 | Log-map metric calculation using the avg* kernel |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US09/696,784 US6760390B1 (en) | 2000-10-25 | 2000-10-25 | Log-map metric calculation using the avg* kernel |
Publications (1)
Publication Number | Publication Date |
---|---|
US6760390B1 true US6760390B1 (en) | 2004-07-06 |
Family
ID=32595582
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US09/696,784 Expired - Lifetime US6760390B1 (en) | 2000-10-25 | 2000-10-25 | Log-map metric calculation using the avg* kernel |
Country Status (1)
Country | Link |
---|---|
US (1) | US6760390B1 (en) |
Cited By (19)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20020048329A1 (en) * | 2000-09-12 | 2002-04-25 | Tran Hau Thien | Method and apparatus for min star calculations in a map decoder |
US20020131515A1 (en) * | 2001-01-18 | 2002-09-19 | Motorola, Inc. | Soft-decision metric generation for higher order modulation |
US20030091129A1 (en) * | 2001-07-12 | 2003-05-15 | Mingming Zhang | Look-up table index value generation in a turbo decoder |
US20030226096A1 (en) * | 2002-05-31 | 2003-12-04 | Ba-Zhong Shen | True bit level decoding of TTCM (Turbo Trellis Code Modulation ) |
US20040044946A1 (en) * | 2002-08-30 | 2004-03-04 | Bickerstaff Mark Andrew | Higher radix Log MAP processor |
US20040153942A1 (en) * | 2003-01-24 | 2004-08-05 | Nathan Shtutman | Soft input soft output decoder for turbo codes |
US20050262408A1 (en) * | 2000-09-12 | 2005-11-24 | Tran Hau T | Fast min* - or max* - circuit in LDPC (Low Density Parity Check) decoder |
US20060265634A1 (en) * | 2005-05-18 | 2006-11-23 | Seagate Technology Llc | Iterative detector with ECC in channel domain |
US20060282753A1 (en) * | 2005-05-18 | 2006-12-14 | Seagate Technology Llc | Second stage SOVA detector |
US20060282712A1 (en) * | 2005-05-18 | 2006-12-14 | Seagate Technology Llc | Low complexity pseudo-random interleaver |
US20070044001A1 (en) * | 2002-11-20 | 2007-02-22 | Broadcom Corporation, A California Corporation | Single stage implementation of min*, max*, min and/or max to perform state metric calculation in SISO decoder |
US20080112498A1 (en) * | 2002-02-05 | 2008-05-15 | Qualcomm Incorporated | System for soft symbol decoding with mimo log-map detection |
US20110057108A1 (en) * | 2009-09-10 | 2011-03-10 | Avago Technologies Ecbu (Singapore) Pte. Ltd. | Compact Optical Proximity Sensor with Ball Grid Array and Windowed Substrate |
US20110121181A1 (en) * | 2009-11-23 | 2011-05-26 | Avago Technologies Ecbu (Singapore) Pte. Ltd. | Infrared Proximity Sensor Package with Improved Crosstalk Isolation |
US20110204233A1 (en) * | 2009-06-30 | 2011-08-25 | Avago Technologies Ecbu (Singapore) Pte. Ltd. | Infrared Attenuating or Blocking Layer in Optical Proximity Sensor |
US20120166501A1 (en) * | 2010-12-24 | 2012-06-28 | Sokolov Andrey P | Computation of jacobian logarithm operation |
US20120219097A1 (en) * | 2011-02-24 | 2012-08-30 | Qualcomm Incorporated | Two-step joint demapping algorithm for llr computation of mimo signal based on sphere decoding |
WO2013148619A1 (en) * | 2012-03-30 | 2013-10-03 | Apple Inc. | Transcendental and non-linear components using series expansion |
US20150186077A1 (en) * | 2013-12-27 | 2015-07-02 | Intel Corporation | Processor with architecturally-visible programmable on-die storage to store data that is accessible by instruction |
Citations (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5442627A (en) | 1993-06-24 | 1995-08-15 | Qualcomm Incorporated | Noncoherent receiver employing a dual-maxima metric generation process |
US6304996B1 (en) * | 1999-03-08 | 2001-10-16 | General Electric Company | High-speed turbo decoder |
US20020034269A1 (en) * | 2000-07-28 | 2002-03-21 | Victor Demjanenko | Use of soft-decision or sum-product inner coders to improve the performance of outer coders |
US6381728B1 (en) * | 1998-08-14 | 2002-04-30 | Qualcomm Incorporated | Partitioned interleaver memory for map decoder |
US6526539B1 (en) * | 1999-06-23 | 2003-02-25 | Fujitsu Limited | Turbo decoder |
US6625778B1 (en) * | 1999-09-06 | 2003-09-23 | Mitsubishi Denki Kabushiki Kaisha | Turbo error-correcting decoder and turbo error-correcting decoding method |
-
2000
- 2000-10-25 US US09/696,784 patent/US6760390B1/en not_active Expired - Lifetime
Patent Citations (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5442627A (en) | 1993-06-24 | 1995-08-15 | Qualcomm Incorporated | Noncoherent receiver employing a dual-maxima metric generation process |
US6381728B1 (en) * | 1998-08-14 | 2002-04-30 | Qualcomm Incorporated | Partitioned interleaver memory for map decoder |
US6304996B1 (en) * | 1999-03-08 | 2001-10-16 | General Electric Company | High-speed turbo decoder |
US6526539B1 (en) * | 1999-06-23 | 2003-02-25 | Fujitsu Limited | Turbo decoder |
US6625778B1 (en) * | 1999-09-06 | 2003-09-23 | Mitsubishi Denki Kabushiki Kaisha | Turbo error-correcting decoder and turbo error-correcting decoding method |
US20020034269A1 (en) * | 2000-07-28 | 2002-03-21 | Victor Demjanenko | Use of soft-decision or sum-product inner coders to improve the performance of outer coders |
Non-Patent Citations (5)
Title |
---|
L. R. Bahl, J. Cocke, F. Jelinek, and J. Raviv, "Optimal decoding of linear codes for minimizing symbol error rate," IEEE Trans. Inform. Theory, vol. IT-20, pp. 284-287, Mar. 1974. |
P. Robertson, E. Villebrun, and P. Hoeher, "A comparison of optimal and sub-optimal MAP decoding algorithms operating in the log domain," International Conference on Communications, pp. 1009-1013, Jun. 1995. |
S. Le Goff, A. Glavieux, and C. Berrou, "Turbo-codes and high spectral efficiency modulation," International Conference on Communications, Jun. 1994. |
V. Kuhn, "Evaluating the performance of turbo codes and turbo-coded modulation in a DS-CDMA environment," IEEE Journal on Selected Areas of Communications, vol. 17, pp. 2138-2147, Dec. 1999. |
W. Gross and P. Gulak, "Simplified MAP algorithm suitable for implementation of turbo decoders," Electronics Letters, vol. 34, No. 16, pp. 1577-1578, Aug. 1998. |
Cited By (37)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7023934B2 (en) * | 2000-09-12 | 2006-04-04 | Broadcom Corporation | Method and apparatus for min star calculations in a map decoder |
US20020048329A1 (en) * | 2000-09-12 | 2002-04-25 | Tran Hau Thien | Method and apparatus for min star calculations in a map decoder |
US7383485B2 (en) * | 2000-09-12 | 2008-06-03 | Broadcom Corporation | Fast min*- or max*-circuit in LDPC (low density parity check) decoder |
US20050262408A1 (en) * | 2000-09-12 | 2005-11-24 | Tran Hau T | Fast min* - or max* - circuit in LDPC (Low Density Parity Check) decoder |
US20020131515A1 (en) * | 2001-01-18 | 2002-09-19 | Motorola, Inc. | Soft-decision metric generation for higher order modulation |
US7076000B2 (en) * | 2001-01-18 | 2006-07-11 | Motorola, Inc. | Soft-decision metric generation for higher order modulation |
US20030091129A1 (en) * | 2001-07-12 | 2003-05-15 | Mingming Zhang | Look-up table index value generation in a turbo decoder |
US20100111234A1 (en) * | 2002-02-05 | 2010-05-06 | Qualcomm Incorporated | System for soft symbol decoding mimo log-map detection |
US8483328B2 (en) | 2002-02-05 | 2013-07-09 | Qualcomm Incorporated | System for soft symbol decoding MIMO log-map detection |
US7649966B2 (en) * | 2002-02-05 | 2010-01-19 | Qualcomm Incorporated | System for soft symbol decoding with MIMO log-map detection |
US20080112498A1 (en) * | 2002-02-05 | 2008-05-15 | Qualcomm Incorporated | System for soft symbol decoding with mimo log-map detection |
US8473822B2 (en) * | 2002-05-31 | 2013-06-25 | Broadcom Corporation | True bit level decoding of TTCM (turbo trellis coded modulation) of variable rates and signal constellations |
US20100077282A1 (en) * | 2002-05-31 | 2010-03-25 | Broadcom Corporation | True bit level decoding of TTCM (Turbo Trellis Coded Modulation) of variable rates and signal constellations |
US7657822B2 (en) * | 2002-05-31 | 2010-02-02 | Broadcom Corporation | True bit level decoding of TTCM (turbo trellis code modulation) of variable rates and signal constellations |
US20030226096A1 (en) * | 2002-05-31 | 2003-12-04 | Ba-Zhong Shen | True bit level decoding of TTCM (Turbo Trellis Code Modulation ) |
US7107509B2 (en) * | 2002-08-30 | 2006-09-12 | Lucent Technologies Inc. | Higher radix Log MAP processor |
US20040044946A1 (en) * | 2002-08-30 | 2004-03-04 | Bickerstaff Mark Andrew | Higher radix Log MAP processor |
US20070044001A1 (en) * | 2002-11-20 | 2007-02-22 | Broadcom Corporation, A California Corporation | Single stage implementation of min*, max*, min and/or max to perform state metric calculation in SISO decoder |
US20040153942A1 (en) * | 2003-01-24 | 2004-08-05 | Nathan Shtutman | Soft input soft output decoder for turbo codes |
US20080215831A1 (en) * | 2005-05-18 | 2008-09-04 | Seagate Technology Llc | Interleaver With Linear Feedback Shift Register |
US20060282753A1 (en) * | 2005-05-18 | 2006-12-14 | Seagate Technology Llc | Second stage SOVA detector |
US7395461B2 (en) | 2005-05-18 | 2008-07-01 | Seagate Technology Llc | Low complexity pseudo-random interleaver |
US7360147B2 (en) * | 2005-05-18 | 2008-04-15 | Seagate Technology Llc | Second stage SOVA detector |
US20060282712A1 (en) * | 2005-05-18 | 2006-12-14 | Seagate Technology Llc | Low complexity pseudo-random interleaver |
US7788560B2 (en) | 2005-05-18 | 2010-08-31 | Seagate Technology Llc | Interleaver with linear feedback shift register |
US7502982B2 (en) | 2005-05-18 | 2009-03-10 | Seagate Technology Llc | Iterative detector with ECC in channel domain |
US20060265634A1 (en) * | 2005-05-18 | 2006-11-23 | Seagate Technology Llc | Iterative detector with ECC in channel domain |
US20110204233A1 (en) * | 2009-06-30 | 2011-08-25 | Avago Technologies Ecbu (Singapore) Pte. Ltd. | Infrared Attenuating or Blocking Layer in Optical Proximity Sensor |
US20110057108A1 (en) * | 2009-09-10 | 2011-03-10 | Avago Technologies Ecbu (Singapore) Pte. Ltd. | Compact Optical Proximity Sensor with Ball Grid Array and Windowed Substrate |
US20110121181A1 (en) * | 2009-11-23 | 2011-05-26 | Avago Technologies Ecbu (Singapore) Pte. Ltd. | Infrared Proximity Sensor Package with Improved Crosstalk Isolation |
US20120166501A1 (en) * | 2010-12-24 | 2012-06-28 | Sokolov Andrey P | Computation of jacobian logarithm operation |
US20120219097A1 (en) * | 2011-02-24 | 2012-08-30 | Qualcomm Incorporated | Two-step joint demapping algorithm for llr computation of mimo signal based on sphere decoding |
US8693588B2 (en) * | 2011-02-24 | 2014-04-08 | Qualcomm Incorporated | Two-step joint demapping algorithm for LLR computation of MIMO signal based on sphere decoding |
WO2013148619A1 (en) * | 2012-03-30 | 2013-10-03 | Apple Inc. | Transcendental and non-linear components using series expansion |
US9015217B2 (en) | 2012-03-30 | 2015-04-21 | Apple Inc. | Transcendental and non-linear components using series expansion |
US20150186077A1 (en) * | 2013-12-27 | 2015-07-02 | Intel Corporation | Processor with architecturally-visible programmable on-die storage to store data that is accessible by instruction |
US9207880B2 (en) * | 2013-12-27 | 2015-12-08 | Intel Corporation | Processor with architecturally-visible programmable on-die storage to store data that is accessible by instruction |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US6760390B1 (en) | Log-map metric calculation using the avg* kernel | |
US7757151B2 (en) | Turbo decoder employing simplified log-MAP decoding | |
US6145114A (en) | Method of enhanced max-log-a posteriori probability processing | |
US7076000B2 (en) | Soft-decision metric generation for higher order modulation | |
JP3958764B2 (en) | Apparatus and method for reducing bit error rate and frame error rate using turbo decoding in digital communication system | |
EP0937336B1 (en) | Soft decision output decoder for decoding convolutionally encoded codewords | |
US6907084B2 (en) | Method and apparatus for processing modulation symbols for soft input decoders | |
US6865711B2 (en) | System of and method for decoding trellis codes | |
US7159168B2 (en) | Iterative decoding with likelihood weighting | |
US6393076B1 (en) | Decoding of turbo codes using data scaling | |
EP1314254B1 (en) | Iteration terminating for turbo decoder | |
US20040005019A1 (en) | Turbo decoder employing max and max* map decoding | |
CN110417512B (en) | Joint iterative decoding method for CPM communication system | |
US7391826B2 (en) | Decoding method and apparatus | |
US6343103B1 (en) | Methods and apparatus for representation of branch metrics in a communication system decoder | |
US7840884B2 (en) | Turbo decoding with iterative estimation of channel parameters | |
Sybis | Log-MAP equivalent Chebyshev inequality based algorithm for turbo TCM decoding | |
Lim et al. | Hybrid log-map algorithm for turbo decoding over awgn channel | |
Park | Bitwise log-likelihood ratios for quadrature amplitude modulations | |
Karakchieva et al. | A recursive SISO decoding algorithm | |
US20020122507A1 (en) | System for carrier phase tracking of multi-dimensional coded symbols | |
US6795512B1 (en) | System for carrier phase tracking of coded symbols using reliability metrics for symbol estimates | |
Sun et al. | Improved max-log-map turbo decoding by extrinsic information scaling and combining | |
Sybis | Branch canceling technique for turbo TCM decoding | |
Ashwini et al. | Area Efficient of Max Log Map Algorithm Using SB/DB Methods for Turbo Decoder |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: MOTOROLA, INC., ILLINOISFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:DESAI, VIPUL ANIL;CLASSON, BRIAN KEITH;BLANKENSHIP, THOMAS KEITH;REEL/FRAME:011283/0899Effective date: 20001023 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
FPAY | Fee payment |
Year of fee payment: 4 |
|
AS | Assignment |
Owner name: MOTOROLA MOBILITY, INC, ILLINOISFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:MOTOROLA, INC;REEL/FRAME:025673/0558Effective date: 20100731 |
|
FPAY | Fee payment |
Year of fee payment: 8 |
|
AS | Assignment |
Owner name: MOTOROLA MOBILITY LLC, ILLINOISFree format text: CHANGE OF NAME;ASSIGNOR:MOTOROLA MOBILITY, INC.;REEL/FRAME:029216/0282Effective date: 20120622 |
|
AS | Assignment |
Owner name: GOOGLE TECHNOLOGY HOLDINGS LLC, CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:MOTOROLA MOBILITY LLC;REEL/FRAME:034422/0001Effective date: 20141028 |
|
FPAY | Fee payment |
Year of fee payment: 12 |