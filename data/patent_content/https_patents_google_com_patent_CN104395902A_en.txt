CN104395902A - Determining 3D model information from stored images - Google Patents
Determining 3D model information from stored images Download PDFInfo
- Publication number
- CN104395902A CN104395902A CN201380018797.1A CN201380018797A CN104395902A CN 104395902 A CN104395902 A CN 104395902A CN 201380018797 A CN201380018797 A CN 201380018797A CN 104395902 A CN104395902 A CN 104395902A
- Authority
- CN
- China
- Prior art keywords
- applicable
- light field
- viewing angle
- model
- described object
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/40—Information retrieval; Database structures therefor; File system structures therefor of multimedia data, e.g. slideshows comprising image and additional audio data
- G06F16/43—Querying
- G06F16/432—Query formulation
- G06F16/434—Query formulation using image data, e.g. images, photos, pictures taken by a user
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T15/00—3D [Three Dimensional] image rendering
- G06T15/50—Lighting effects
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/50—Information retrieval; Database structures therefor; File system structures therefor of still image data
- G06F16/58—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually
- G06F16/583—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using metadata automatically derived from the content
- G06F16/5854—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using metadata automatically derived from the content using shape and object relationship
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/50—Information retrieval; Database structures therefor; File system structures therefor of still image data
- G06F16/58—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually
- G06F16/5866—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using information manually generated, e.g. tags, keywords, comments, manually generated location and time information
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T2215/00—Indexing scheme for image rendering
- G06T2215/16—Using real world measurements to influence rendering
Abstract
Methods and systems are provided for determining and transmitting applicable lighting information, applicable viewing perspective, and a 3D model for an object in response to a search query. An example method includes receiving, at a server, a search query regarding an object, A 3D model for the object is determined. The 3D model includes three-dimensional shape information about the object. The method also includes determining, based on a plurality of stored images of the object, at least one applicable light field and at least one applicable viewing perspective. A search query result is transmitted from the server. The search query result may include the 3D model, the applicable light field(s), and the applicable viewing perspective(s). A server and a non-transitory computer readable medium are also disclosed that could perform a similar method.
Description
The cross reference of related application
This application claims the 61/619th in submission on April 2nd, 2012, the right of priority of No. 224 U.S. Provisional Patent Application, its content is incorporated to herein by reference.
Background technology
In computer graphics, three-dimensional (3D) modeling relates to the expression on the 3D surface of formation object.This expression can be called as 3D object data model, or referred to as 3D model, and can (render) be played up via 3D and be played up for or be shown as two dimensional image, or can 3-D view be shown as.3D object data model can utilize set that be connected with the various geometry entities of curved surface etc. by such as triangle, line, that put in the 3 d space to represent 3D object.There are the various technology utilizing some cloud and geometric configuration to generate 3D object data model.
Summary of the invention
In a first aspect, a kind of method is provided.The method is included in server place and receives search inquiry.Search inquiry comprises the request to the information about object.Method also comprises the 3D model determining object.3D model comprises the three-dimensional shape information about object.Method additionally comprises object-based multiple image stored, and determines at least one applicable light field and at least one applicable viewing angle.In each image stored of object, object is by least one respective light field illumination and by from respective viewing angle imaging.Method also comprises from server transmission search query results.Search query results comprises 3D model, at least one applicable light field and at least one applicable viewing angle described.
In second aspect, provide a kind of computing machine.The instruction that this computing machine comprises processor, non-volatile computer-readable medium and is stored in non-volatile computer-readable medium.This instruction can be performed to make computing machine n-back test by processor.Described function comprises reception search inquiry.Search inquiry comprises the request to the information about object.Function also comprises the 3D model determining object.3D model comprises the three-dimensional shape information about object.Function additionally comprises object-based multiple image stored, and determines at least one applicable light field and at least one applicable viewing angle.In each image stored of object, object is by least one respective light field illumination and by from respective viewing angle imaging.Function also comprises transmission search query results.Search query results comprises 3D model, at least one applicable light field and at least one applicable viewing angle.
In a third aspect, a kind of non-transitory computer-readable medium is provided.This non-transitory computer-readable medium comprises instruction, and described instruction can be performed to make computing equipment n-back test by computing equipment, and described function comprises reception search inquiry.Search inquiry comprises the request to the information about object.Function also comprises the 3D model determining object.3D model comprises the three-dimensional shape information about object.Function additionally comprises object-based multiple image stored, and determines at least one applicable light field and at least one applicable viewing angle.In each image stored of object, object is by least one respective light field illumination and by from respective viewing angle imaging.Function also comprises transmission search query results.Search query results comprises 3D model, at least one applicable light field and at least one applicable viewing angle.
Accompanying drawing explanation
Figure 1A is the functional block diagram of the system for object data modeling according to example embodiment.
Figure 1B is the functional block diagram of the distributed computing architecture according to example embodiment.
Fig. 1 C is the functional block diagram of the computing equipment according to example embodiment.
Fig. 1 D is the functional block diagram of the server system based on cloud according to example embodiment.
Fig. 2 is the process flow diagram of the method according to example embodiment.
Fig. 3 is the process flow diagram of the method for determining at least one applicable light field according to example embodiment.
Fig. 4 is the process flow diagram of the method for determining at least one applicable viewing angle according to example embodiment.
Fig. 5 is the process flow diagram of the method for assessment of at least one applicable light field and at least one applicable viewing angle according to example embodiment.
Fig. 6 is the process flow diagram of method for sorting to tinter according to example embodiment.
Fig. 7 is the process flow diagram of the method for tinter selection according to example embodiment.
Fig. 8 is the schematic diagram of the computer program according to example embodiment.
Embodiment
In the following detailed description, with reference to the accompanying drawing forming its part.In the drawings, similar symbol identifies similar assembly usually, unless the context indicates otherwise.The illustrative embodiment described in detailed description and figure is not that intention limits.When not departing from the spirit or scope of the theme proposed here, other embodiment can be utilized, also can make other and changing.To be readily appreciated that, aspect of the present disclosure, as general description here and to illustrate in the drawings, can arrange, substitute, combine or be separated with various configuration, all these is here all susceptible to.
Example embodiment disclosed herein relates in response to the search inquiry about object, determines the 3D model of object, and object-based multiple image stored determines applicable light field and applicable viewing angle.Determined information can send from server with the form of search query results.
Certain methods disclosed herein partly or wholly can be performed by server system.In the exemplary embodiment, server can receive search inquiry, and described search inquiry can comprise the request to the information about object.In such an example, the 3D model of object can be determined based on the information in search inquiry at least in part.3D model can comprise such as, about the three-dimensional shape information of object.Additionally, object-based multiple image stored, can determine at least one applicable light field and at least one applicable viewing angle.In each image stored of object, object is by least one respective light field illumination and by from respective viewing angle imaging.Then determined information can be sent to output target with search query results from server, the source of such as search inquiry.
In the exemplary embodiment, the server instruction that comprises processor, non-transitory computer-readable medium and be stored in non-transitory computer-readable medium.Instruction can be that processor is executable, performs and those the functionally similar functions described in preceding method to make server.
There is also disclosed the non-transitory computer-readable medium of the instruction with storage.Instruction can be that computing equipment is executable, performs and those the functionally similar functions described in preceding method to make computing equipment.
It will be understood to those of skill in the art that, there is much different specific method and systems, described method and system can be used to: when receiving the search inquiry about object, determine the 3D model of object, and object-based multiple image stored determines applicable light field and applicable viewing angle, then send the search query results comprising determined information from server.Each in these specific method and systems is here expected, and several example embodiment are described below.
Figure 1A illustrates the example system 100 for object data modeling.System 100 comprises the input source 102 being coupled to server 104 and database 106.Server 104 is also shown to be coupled to database 106 and exports target 108.System 100 can comprise more or less assembly, and input source 102, server 104, database 106 and each output in target 108 also can comprise multiple element, or input source 102, server 104, database 106 and each output in target 108 also can be interconnected.Therefore, one or more in the function of described system 100 can be divided in additional function or physical assemblies, or are incorporated in less function or subject component.At some in other example, additional function and/or physical assemblies can be added to the example illustrated in Figure 1A.
The assembly of system 100 can be coupled to network (not shown), or being configured to can via the communication of network (not shown), and described network is such as LAN (Local Area Network) (LAN), wide area network (WAN), wireless network or the Internet such as.In addition, the random component of system 100 can utilize wired or wireless communication to intercouple.Such as, communication link between input source 102 and server 104 can comprise the wired connection of such as universal serial bus or parallel bus and so on, or wireless connections, such as bluetooth, IEEE 802.11 (IEEE802.11 can refer to IEEE 802.11-2007, IEEE 802.11n-2009 or other IEEE802.11 revised edition any) or other is based on wireless communication link.
Input source 102 can be any source, can receive search inquiry and/or 3D model from described source, or object data model.Search inquiry can be derived from any amount of equipment, comprises mobile device (such as, smart phone, flat computer, wearable computer etc.), or is derived from other computing system.Search inquiry comprises the request to the information about object.Can be overall request to the request of information.Under such general status, search inquiry context can be " showing me chair ".Can be alternatively request content more specifically to the request of information, such as, " showing me the height back of the body swivel chair of the model X manufactured by company Y ".In certain embodiments, specified response is asked to provide 3D model in request.
When receiving search inquiry, system 100 can be configured to perform variously to be determined.Such as, the 3D model of object can be determined.Determine to comprise and search data storage device and/or database, this can the 3D model of returning an object value.Other means determining 3D model are possible.
System 100 can also be configured to object-based multiple image stored, and determines at least one applicable light field and at least one applicable viewing angle.Multiple image stored can comprise object rest image in various lighting environment, in various positions etc.Further describe applicable light field and applicable viewing angle below.
System 100 can also be configured to send search query results, and described search query results comprises 3D model, at least one applicable light field and the applicable viewing angle of at least one.
In some instances, 3D model (shape and/or outward appearance) can be determined from the 3D scanning of object.Such as, structured light scanner can captured object image and monochromatic stereoscopic camera and pattern projector can be utilized to recover the shape of object.Known in the art from the various methods of the Postprocessing technique 3D shape of such seizure and colouring information.Such as, exercise recovery structure (Structure From Motion, SFM), stereoscopic vision (stereoscopy), various visual angles method (multiscopy), can be used alone by other technology known in Structured Illumination and computer vision and 3D imaging field or to form 3D model with various combinationally using.In interchangeable example, 3D model can have been known and/or be stored in data storage device or database 106 by serviced device 104.
Server 104 comprises model builder 110, object data model processor 112, semantics and search index 114 and shape library 116.The random component of server 104 can be coupled to each other.In addition, alternatively, the random component of server 104 can be the assembly of the separation of being coupled to server 104.Server 104 can also comprise such as processor and storer, and described storer comprises the instruction of the function that can be executed by processor the assembly performing server 104.
Model builder 110 receives the Grid dataset of each object from input source 102, this Network data set can comprise the data set of the dense surface mesh geometry of definition (dense surface mesh geometry), and can generate the animation model of the object of 3D.Such as, model builder 110 can perform to be disassembled (coherent texture unwrapping) from the consistance texture of surface mesh, and determines the texture on the surface according to geometry emulation.
Object data model processor 112 can also receive the Grid dataset of each object from input source 102 and generate show grid.Such as, the grid image of scanning can utilize texture preservation simplification (decimation) to carry out simplifying (such as, from 500 ten thousand to 120,000 surfaces).The generation of texture also can be performed to determine mapping the color and vein played up.For generating whole texture, each image pixel can be associated with a texture pixel.
The image that semantics and search index 114 can receive seizure or the image of process being simplified and having compressed, and the index of texture resampling and Shape-based interpolation can be performed.Such as, for each object, semantics and search index 114 can by the component of image (such as, each pixel) index for or be labeled as there are specific texture, color, shape, geometric figure, attribute etc.
Shape library 116 can such as use WebGL or OpenGL mesh compression to reduce grid file size.Shape library 116 such as can provide 3D object data model (or 3D model) for the form shown on a web browser.In some instances, 3D object data model reader can be used to the image showing 3D object data model.3D object data model reader can such as utilize WebGL or OpenGL in web browser to realize.
Database 106 can comprise multiple images stored of object.The image stored can comprise frame of video and/or rest image.The quantity of image may be very large, and such as thousands of picture is even more.The image of a special object can be comprised in database 106.In various embodiments, database 106 can comprise the image of many different objects.Image can comprise object from different viewing angles, various photo under different lighting conditions and different situation environment and/or frame of video.Such as, database 106 can comprise multiple images of stapler.In the various image stored, stapler can be revealed as from the crown, from the side, from behind etc. illuminated.Image can comprise the stapler of different colours and shape.The image stored can also comprise the picture of the stapler from different viewing angles.In addition, the environment of stapler image can change between family office and small business environment.In database 106, the object of image and other example of type can be possible.In one embodiment, database 106 can represent the image on multiple distributed computers of being stored in server system.
In another example embodiment, database 106 can with the various forms from the raw data of seizure to any amount of the data of the process for showing to store all data sets of 3D object data model.Database 106 is coupled to server 104 communicatedly, but does not need to be connected to server 104 physically or otherwise.Database 106 also can be integrated in server 104.In certain embodiments, the comparison that database 106 can also be used between the image played up of object and the image stored of object is compared to determine similarity measurement (metric) or to perform other.
Export target 108 and can comprise many different targets, such as webpage, search engine, database on the internet.Export target 108 and can comprise 3D object data model reader, its permission realizes product advertising or product search based on 3D object data model.In example here, export target 108 and can also comprise input source 102.Such as, search inquiry can be supplied to system 100 and be considered to input source 102 by mobile device.In such example, system 100 can generate search query results and search query results is sent to mobile device.Therefore, mobile device also can be considered to export target 108.Other output target 108 is possible.Such as, search query results can be sent to different mobile devices and/or other computing equipment from system 100.
Figure 1B, Fig. 1 C and Fig. 1 D is the functional block diagram illustrating the exemplary computing system arranged according at least some embodiment described herein.Computing system can be used to realize system and method for the search inquiry that i) receives the request comprised the information about object; Ii) the 3D model of object is determined; Iii) object-based multiple image stored determines at least one applicable light field and at least one applicable viewing angle; And iv) send and comprise the search query results of determined information, as described herein with as illustrated in Figure 1A and Fig. 2.
Figure 1B shows server apparatus 128,130, and it is configured to communicate with 124c with programmable device 124a, 124b via network 126.Network 126 can correspond to LAN, wide area network (WAN), company intranet, public the Internet or be configured to the network of other type any of the communication path provided between the computing equipment of networking.Network 126 also can correspond to the combination of one or more LAN, WAN, company intranet and/or public the Internet.
Server apparatus 128 and 130 can be similar or identical with the server 104 described with reference to Figure 1A.
Although Figure 1B illustrate only three programmable devices, Distributed Application framework can serve tens of, hundreds of, thousands of or even more programmable device.In addition, programmable device 124a, 124b and 124c (or programmable device additional arbitrarily) can be the computing equipments of any kind, such as common laptop computer, desktop PC, the network terminal, Wireless Telecom Equipment (such as, cell phone or smart phone) etc.In certain embodiments, programmable device 124a, 124b and 124c can be absorbed in the design and use of software application.In other embodiments, programmable device 124a, 124b and 124c is configured to perform many tasks and the multi-purpose computer need not being absorbed in SDK (Software Development Kit).Programmable device 124a, 124b and 124c can represent the one or more input sources 102 described by reference Figure 1A or input target 108.
Server apparatus 128,130 can be configured to the one or more service that execution programmable device 124a, 124b and/or 124c ask.Such as, content can be supplied to programmable device 124a-124c by server apparatus 128 and/or 130.Content can include but not limited to, webpage, hypertext, script, such as through the binary data of software of compiling, image, audio frequency and/or video.Content can comprise content that is compressed and/or uncompressed.Content can be encrypted and/or not encrypted.The content of other type is also possible.
As another example, server apparatus 128 and/or 130 can to programmable device 124a-124c be provided to for database, search, calculating, figure, audio frequency, video, WWW/the Internet utilize and/or the access of software of other function.Other examples a lot of of server apparatus are also possible.
Fig. 1 C is the block diagram of the computing equipment according to example embodiment.Specifically, the computing equipment 150 shown in Fig. 1 C can be configured to perform server apparatus 128,130, one or more one or more functions in network 126 and/or programmable device 124a, 124b and 124c.Computing equipment 150 can comprise Subscriber Interface Module SIM 151, network communication interface module 152, one or more processor 153 and data-carrier store 154, and all these can link together via system bus, network or other connection mechanism 155.
It is one or more that computing equipment 150 also can represent as with reference in programmable device 124a, 124b and the 124c described by Figure 1B.In addition, computing equipment 150 can represent the input source 102 described by reference Figure 1A or export target 108.
Subscriber Interface Module SIM 151 can be exercisable to send data to external user input-output apparatus and/or to receive data from external user input-output apparatus.Such as, Subscriber Interface Module SIM 151 can be configured to send data to user input device and/or receive data from user input device, and described user input device is keyboard, keypad, touch-screen, computer mouse, tracking ball, operating rod, camera, sound recognition module and/or other similar devices such as.Subscriber Interface Module SIM 151 also can be configured to output to be supplied to user's display device, such as one or more cathode-ray tube (CRT) (CRT), liquid crystal display (LCD), light emitting diode (LED), the display utilizing digital light process (DLP) technology, printer, bulb and/or other similar devices, or now known or exploitation later.Subscriber Interface Module SIM 151 also can be configured to produce audible (multiple) and export, such as loudspeaker, loudspeaker socket, audio output port, audio output apparatus, earphone and/or other similar devices.
Network communication interface module 152 can comprise one or more wave point 157 and/or one or more wireline interface 158, and they can be configured to the network service via all networks 126 as shown in fig. 1b and so on.Wave point 157 can comprise one or more radio transmitters, receiver and/or transceiver, such as bluetooth transceiver, WLAN (wireless local area network) (WLAN) transceiver, cellular radio transceiver and/or be configured to the wireless transceiver of other similar type via wireless communication.Wireline interface 158 can comprise one or more wired transmitter, receiver and/or transceiver, the similar transceiver that such as ethernet transceiver, USB (universal serial bus) (USB) transceiver or be configured to communicates via twisted-pair feeder, concentric cable, optical fiber link or the similar physical connection to cable network.
In certain embodiments, network communication interface module 152 can be configured to provide communication that is reliable, safe and/or certification.For each communication described herein, the information guaranteeing reliable communication (namely guaranteed information delivery) can be provided for, this information is perhaps provided as a part for message header and/or afterbody (footer) (such as, the transmission authorization information of bag/Message sequence information, (multiple) encapsulated header and/or (multiple) afterbody, size/temporal information and such as CRC and/or parity values and so on).Can utilize such as, but not limited to, one or more cipher protocol of DES, AES, RSA, Diffie-Hellman (Di Fei-Herman) and/or DSA and/or algorithm make communication security (such as, encoded or encrypt) and/or decrypted/decoding.Other cipher protocol and/or algorithm also can be used or be used, to protect (then deciphering/decoding) communication with listing here together with those agreements.
Processor 153 can comprise one or more general processor and/or one or more application specific processor (such as, digital signal processor, special IC etc.).Processor 153 can be configured to perform and be included in computer-readable program instructions 156a in data-carrier store 154 and/or other instruction as described herein.
Data-carrier store 154 can comprise one or more computer-readable recording mediums that can be read by least one in processor 153 and/or access.One or more computer-readable recording medium can comprise can integrally or partly with at least one the integrated volatibility in processor 153 and/or non-volatile storage component, as optics, magnetic, organically or other storer or disk storage.In certain embodiments, data-carrier store 154 can utilize single physical equipment (such as, an optics, magnetic, organically or other storer or disk storage unit) realize, but in other embodiments, data-carrier store 154 can utilize two or more physical equipments to realize.
The data that data-carrier store 154 can comprise computer-readable program instructions 156a, true environment 156b and may add.True environment 156b can at least some in the data that use of one or more process of stores software applications and/or thread.In certain embodiments, data-carrier store 154 can additionally comprise perform Method and Technology described herein at least partially and/or the storer required at least partially of the function of equipment described herein and network.
Fig. 1 D depicts the network 126 being arranged to computing cluster 159a, 159b and 159c of the server system based on cloud according to example embodiment.Server apparatus 128 and/or 130 can be the equipment based on cloud, the described device storage programmed logic based on cloud and/or based on the application of cloud and/or the data of service.In certain embodiments, server apparatus 128 and/or 130 can be the single computing equipment resided in single computing center.In other embodiments, server apparatus 128 and/or 130 can be included in the multiple computing equipment in single computing center or even comprise the multiple computing equipments being arranged in the multiple computing centers being in diverse geographic location.Such as, Figure 1B depicts each in the server apparatus 128 and 130 resided in different physical location.
In certain embodiments, the data at server apparatus 128 and/or 130 place and service can be encoded as and be stored in computer-readable information that is in tangible computer-readable medium (or computer readable memory medium) and that can be accessed by programmable device 124a, 124b and 124c and/or other computing equipment.In certain embodiments, can be stored on single disc driver or other tangible storage medium in the data at server apparatus 128 and/or 130 place, or can realize on the multiple disk drive being positioned at one or more diverse geographic location place or other tangible storage medium.
In Fig. 1 D, the function of server apparatus 128 and/or 130 can distribute among three computing cluster 159a, 159b and 159c.Computing cluster 159a can comprise one or more computing equipment 150a, the cluster memory array 160a and cluster routers 161a that are connected by local cluster network 162a.Similarly, computing cluster 159b can comprise one or more computing equipment 150b, the cluster memory array 160b and cluster routers 161b that are connected by local cluster network 162b.Similarly, computing cluster 159c can comprise one or more computing equipment 150c, the cluster memory array 160c and cluster routers 161c that are connected by local cluster network 162c.
In certain embodiments, each in computing cluster 159a, 159b and 159c can have the cluster routers of the computing equipment of equal number, the cluster memory array of equal number and equal number.But in other embodiments, each computing cluster can have the cluster routers of the computing equipment of varying number, the cluster memory array of varying number and varying number.The quantity of the computing equipment in each computing cluster, cluster memory array and cluster routers can depend on the one or more calculation tasks being assigned to each computing cluster.
In computing cluster 159a, such as, computing equipment 150a can be configured to the various calculation tasks performing server 130.In one embodiment, the various functions of server 130 are among can be distributed in computing equipment 150a, 150b and 150c one or more.Computing equipment 150b and 150c in computing cluster 159b and 159c can be configured to the computing equipment 150a be similar in computing cluster 159a.On the other hand, in certain embodiments, computing equipment 150a, 150b and 150c can be configured to perform different functions.
In certain embodiments, the calculation task be associated with server apparatus 128 and/or 130 and the data of storage can at least in part based between the processing power of the processing requirements of server apparatus 128 and/or 130, computing equipment 150a, 150b and 150c, computing equipment in each computing cluster and network linking between computing cluster itself delay and/or can contribute to the cost of whole system framework, speed, fault-tolerant, elasticity, efficiency and/or other design object other factors and distribute across computing equipment 150a, 150b and 150c.
Cluster memory array 160a, 160b and 160c of computing cluster 159a, 159b and 159c can be the data storage arrays comprising disk array controller, and described disk array controller is configured to manage the write access to hard disk drive group.Disk array controller, individually or with their respective computing equipments synergistically, also backup or the redundant copy of the data of managed storage in cluster memory array can be configured to, to take precautions against disk drive or other cluster memory array failure and/or network failure, described fault and/or network failure stop one or more computing equipment to access one or more cluster memory array.
The mode that can distribute across computing equipment 150a, 150b and 150c of computing cluster 159a, 159b and 159c with the function of server apparatus 128 and/or 130 is similar, and the various movable part of these assemblies and/or reserve piece also can distribute across cluster memory array 160a, 160b and 160c.Such as, some cluster memory arrays can be configured to the data of storage server equipment 128, and other cluster memory array can the data of storage server equipment 130.Additionally, some cluster memory arrays can be configured to the backup version being stored in the data stored in other cluster memory array.
Cluster routers 161a, 161b and 161c in computing cluster 159a, 159b and 159c can comprise the network equipment, and this network equipment is configured to provide intercommunication and PERCOM peripheral communication to computing cluster.Such as, cluster routers 161a in computing cluster 159a can comprise one or more the Internet and exchange and routing device, described the Internet exchanges and routing device is configured to provide (i) local area network communication via local cluster network 162a between computing equipment 150a and cluster memory array 160a, and (ii) wan communication connecting 163a via the wide area network to network 126 between computing cluster 159a and computing cluster 159b and 159c.Cluster routers 161b and 161c can comprise the network equipment similar with cluster routers 161a, and cluster routers 161b and 161c can be the similar network function of network function that computing cluster 159a performs for computing cluster 159b and 159c performs with cluster routers 161a.
In certain embodiments, the configuration of cluster routers 161a, 161b and 161c can at least in part based on the delay of computing equipment and the data communication requirements of cluster memory array, its communication ability of the network equipment in cluster routers 161a, 161b and 161c, the delay of localized network 162a, 162b and 162c and handling capacity, Wide Area Network link 163a, 163b and 163c, handling capacity and cost and/or the other factors that can contribute to the cost of computing system, speed, fault-tolerant, elasticity, efficiency and/or other design object.
Supplying method 200 is for receiving the search inquiry comprising request to the information about object, the 3D model determining object object-based multiple image stored determines applicable light field and applicable viewing angle at server place.The method can also comprise the search query results comprising determined information from server transmission.The method can use performing with above-described any device shown in Fig. 1, but, other also can be used to configure.Fig. 2 illustrates the step in exemplary method, but should be appreciated that in other embodiments, these steps can occur with different order and step can be added or remove.
Step 202 is included in server place and receives search inquiry.Search inquiry can comprise the request to the information about object.As mentioned above, usually or particularly object can be related to the request of information.The search inquiry received can have much different forms.Such as, the search inquiry received can be text formatting or can view-based access control model (such as, rest image or video) and/or audio frequency (such as, voice) clue.Search inquiry can alternatively receive with other form.
Step 204 comprises the 3D model determining object.3D model comprises the three-dimensional shape information about object.3D model can represent that the wire frame (wireframe) of three-dimensional object or some cloud (point cloud) represent.In certain embodiments, more information can be comprised in the 3D model of object.Such as, colouring information can be comprised in 3D model.3D model can be determined by searching it in the data storage device of the 3D model at object or another set.Alternatively, 3D model can use method described herein to determine from multiple images stored of object.
Step 206 comprises object-based multiple image stored, and determines at least one applicable light field and at least one applicable viewing angle.Multiple images stored of object can any set of image of representative object, data storage device, database or other storage vault.The image of object that multiple images stored of object can comprise under different lighting conditions and/or catch from different viewing angles.
Lighting condition can comprise one or more light field, each image of original captured object under this lighting condition.Each light field can comprise such as, one or more light source and about light how from the information that how mutual with subject surface the light of (multiple) light source projects and projection is.Light source can comprise point source and/or distributed source, and it can comprise isotropy and/or anisotropy photocurrent versus light intensity.Light field can comprise about light under given specific incidence and emergence angle how with the information of the surface interaction of object, such as can definition in bidirectional reflectance distribution function (bidirectional reflectance distribution function, BRDF).
Other light comprising other distribution function can be determined from the image stored of object alternately.Such as, ambient illumination, surrounding block the surface that (occlusion), Lambertian reflection, mirror-reflection and other light as known in the art can be mapped to the image stored of object and/or the 3D model of object itself alternately.Other mapping corresponding alternately from different illumination as known in the art can realize in the context of the method.
By multiple images stored of analytic target, the various information about object and environment thereof can be determined.Such as, image can comprise the information about object, such as its material, color, texture, shape and other attribute.In addition, image can comprise the information about light source in the picture, such as they transmitting distribution, colour temperature, intensity, with the relative position of object and distance etc.Image can also comprise the information of the typical environment about object.Such as, office chair can be usually depicted in the image stored in working environment and fluorescent lighting by the crown time.
Information in the object-based image stored, can determine applicable light field.Such as, one group of the most frequently used (or specification (canonical)) light field can be determined.In other words, the light field of the specification relevant with the exemplary illumination environment of special object can be determined.In addition, can light field be determined so that such as, highlight the special characteristic of object.Such as, can by the shape utilizing strong backlight outline to highlight object.Further, can light field be determined in case in typical environment suitably lighting object.In another embodiment, applicable light field can be determined so that the lighting condition of at least one image stored of basic match objects.In another embodiment, applicable light field can be determined based on three-dimensional two-way Reflectance Distribution Function (BRDF).By this way, at least one applicable light field can be determined in the context of disclosed method.In practice, at least one applicable light field can comprise such as, may be used for the illumination information played up of the photo true to nature of formation object.
Fig. 3 illustrates the exemplary method 210 for determining at least one applicable light field that can use in step 206.Method 210 can comprise the object-based image stored, and determines at least one material of object, indicated by frame 212.Method 210 can also comprise the object-based image stored, and determines at least one texture of object, indicated by frame 214.In addition, method 210 can comprise the object-based image stored, at least the three-dimensional two-way Reflectance Distribution Function (BRDF) of determining section, indicated by frame 216.Further, method 210 can comprise the object-based image stored, and determines the environment of at least one specification of object, indicated by frame 218.The environment of the specification of object such as can correspond to the typical or modal environment of object in the image stored of object.Then, method 210 can comprise the environment of at least one specification based at least one superficial makings of at least one material of (i) object, (ii) object, (iii) three-dimensional BRDF and/or (iv) object, determine at least one applicable light field, indicated by frame 220.
Although Fig. 3 illustrates have the method 210 that (frame 212-218) is determined on four bases that can use when determining at least one applicable light field (frame 220), but be appreciated that the specific implementation of method 210 can not comprise these bases determine in each and/or dissimilar basis can be comprised determine.In addition, one or more basis determines that can be based in part on other basis determines.Such as, determine that at least one material (frame 212) of object can be used to help to determine at least one superficial makings (frame 214) of object, or vice versa.
One or more mapping is generated to each side that the determination of one or more applicable light field can comprise based on applicable light field.Such as, ambient light can be generated map.Such mapping can describe the ambient illumination aspect of given 3D model.Other such mapping can describe other illumination aspect of 3D model.Such as, other illumination aspect can comprise around block, Lambertian reflection and mirror-reflection etc.
In addition, multiple images stored of object can comprise the information about respective viewing angle.Fig. 4 illustrates exemplary method 230, for determining at least one applicable viewing angle that can use in step 206.Method 230 can comprise the object-based image stored, and determines the viewing angle of at least one specification, as indicated at block 232.The viewing angle of specification can corresponding to the typical case in the image stored of object or modal viewing angle.Alternatively or additionally, applicable viewing angle can be determined based on product imaging standards.Such as, the GS1 standard disclosed for the specific viewing angle of product imaging can be used to determine one or more applicable viewing angle.Therefore, method 230 can comprise at least one the product standard viewing angle (such as, at least one GS1 standard viewing angle) determining object, indicated by frame 234.It is one or more that method 230 can also comprise based in the image stored of predetermined Standard Selection object, as indicated at block 236.Such as, one or more in the image stored can be selected as representing the specification determined in frame 232 viewing angle, represent the product standard viewing angle determined in frame 234 or based on other predetermined standard.Be appreciated that the specific implementation of method 230 not necessarily comprises above described in frame 232-236 and shown allly determine and select.Such as, specific implementation can comprise the viewing angle and uncertain product standard viewing angle of determining specification, or vice versa.
Then, method 230 can comprise the one or more selected images based on the viewing angle of (i) at least one specification, (ii) at least one product standard viewing angle and/or (III) object, determine at least one applicable viewing angle, as indicated at block 238.Therefore, in some instances, at least one applicable viewing angle can correspond to the viewing angle of at least one specification determined in frame 232.In other example, at least one applicable viewing angle can correspond at least one product standard viewing angle determined in frame 234.In other example of other, (multiple) applicable viewing angle can be determined by the viewing angle attempting substantially mating in one or more images stored of the object selected in frame 236.Also other method determining one or more applicable viewing angle can be used.
Once determine applicable light field and applicable viewing angle, just can by using the 3D model of determined applicable light field and viewing angle rendering objects and one or more in such playing up being assessed it with one or more the comparing in the image stored of object.Fig. 5 illustrates the exemplary method 240 for performing such assessment.Method 240 can comprise at least one expression of playing up 3D model based at least one applicable light field and at least one applicable viewing angle, at least one being configured in the image stored of basic match objects is represented, indicated by frame 242 to make at least one.At least one expression can comprise such as, the 2D image of object.Method 240 can also comprise and at least one be represented and to compare, indicated by frame 244 with at least one image stored of object.Method 240 can also comprise determines similarity measurement, based on the comparison indicated by frame 246.Similarity measurement can form the basis that (heat map) is penetrated in hot showing, and described hot showing is penetrated and can be described two or more to graphically by the relative similarities between the image that compares and the relative mistake opposite sex.Therefore, method 240 can comprise based on the mapping of similarity measurement Heat of Formation, indicated by frame 248.
In some instances, applicable light field can comprise tinter (shader), and it is can the program of special pattern aspect of the expression of having played up of regulating object.Depend on applicable light field, one or more tinter be associated can be implemented while creating in desired figure in object encoding at rendering image.
Disclosed method can comprise being used for the automated process that single candidate's tinter of rendering objects assesses and sort.Fig. 6 illustrates the exemplary method 250 for sorting to tinter.Method 250 can comprise selects at least one candidate's tinter, based on applicable light field indicated by frame 252 from one group of tinter.Method 250 can also comprise plays up candidate image based on 3D model and at least one candidate's tinter, as indicated at block 254.Method 250 can also be included in candidate image relatively, is compared, indicated by frame 256 by the reference picture of candidate image with at least one image stored comprising object.Compare based on candidate/reference picture, each candidate's tinter can be confirmed as having vision and improve tolerance.In addition, each candidate's tinter can have graphic process unit cost and download size.View-based access control model improves tolerance, graphic process unit cost and downloads size, can for each candidate's tinter determination tinter sorting measure.Therefore, method 250 can comprise and determining for each respective candidate's tinter: the vision that (i) compares based on candidate image improves tolerance; (ii) graphic process unit cost; (iii) size is downloaded; (iv) at least view-based access control model improves tolerance, graphic process unit cost and downloads the tinter sorting measure of size, indicated by frame 258.
Step 208 comprises from server transmission search query results.Search query results can comprise the 3D model of object, at least one applicable light field and at least one applicable viewing angle.Search query results can comprise the tinter one or more applicatory that can be used to play up 3D model alternatively.Search query results can be sent to the equipment of the search inquiry that have sent step 202 or be configured to receive any miscellaneous equipment of such search query results.Such as, other computing machine or mobile device (such as smart phone, laptop computer, flat computer etc.) can receive such search query results.Search query results can send via wireless or wire communication means.
Comprise in search query results in the embodiment of one or more tinters that can be used to play up 3D model, server can select one or more tinter based on the performance information of the prediction relevant with performing the client device played up.Fig. 7 illustrates the exemplary method 260 selected for tinter.Method 260 can be included in the performance information that server place receives prediction, and it comprises server/customer end communication bandwidth and client end processor information, indicated by frame 262.The performance information of prediction also can comprise and the out of Memory uploaded/download and image rendering is relevant.Method 260 can also comprise determines at least one tinter applicatory, indicated by frame 264 based on the performance information of prediction, predetermined frame rate and tinter sorting measure.Predetermined frame rate can relate to image rendering speed (such as, 30 frames per second).Tinter sorting measure can such as by determining with above-described method 250 shown in Fig. 6.Method 260 can also comprise adds at least one tinter applicatory to search query results, indicated by frame 266.By this way, one group of tinter applicatory can be determined and is sent to miscellaneous equipment, so as under one group of given constraint (it can comprise any combination of the network bandwidth, graphic process unit ability and tinter complexity/size) realize the true to nature of 3D model and play up.
In the particular example of further graphic technique 200, the search inquiry of the request related generally to the information about stapler can be received by server.The 3D model of stapler can such as be determined by searching for one group of 3D model stored.
Based on multiple images stored of stapler, at least one applicable light field can be determined.Such as, applicable light field can comprise the information of how to be thrown light on by the diffused light source on the crown (desk lamp as having tungsten bulb) about object.In addition, the mutual light field between the light that description provides and the 3D model of stapler can be determined.Such as, some regions of stapler can be high reverse--bias, and the other parts of stapler can (Lambertian pattern) reflected light in a lambertian pattern.In addition, determined light field can comprise the information how affecting illumination about stapler due to other element blocked in environment.Such as, stapler can cast diffusion shade on substrate surface (such as desk).
According to the image stored of stapler, the material composition of stapler can be inferred.Such as, because a lot of stapler image can imply the Lambert emission pattern of autonomous agent, therefore plastic body material can be inferred.In addition, because the some parts of stapler can describe mirror-reflection (such as, from nail kit box (staple magazine) shell and the anvil block from the base plate as the aduncate nail shape of formation), can infer that those regions of stapler are metal materials.By this way, applicable light field can be determined based on the material of inferring according to the image stored of stapler for object.
Out of Memory can be inferred according to the image stored.Such as, due to mirror-reflection, level and smooth superficial makings can be inferred.In another example, if material has lambert type BRDF, then coarse texture can be inferred.The texture of other type can be inferred according to the image stored of object.
Additionally, the environment of object can be inferred.Such as, if most of images of stapler are included in that stapler of (such as, on wood table, by fluorescent lighting etc.) in office environment, then that environment can be considered to the environment of specification.In addition, determined applicable light field can comprise such information.
Based on multiple images stored of stapler, can settle the standard viewing angle.The viewing angle of this standard/specification can be confirmed as applicable viewing angle.Such as, standard viewing angle can be 45 degree of elevations angle (to overlook stapler) and 30 degree of left radial angles (pitch angle to the left side of the stapler longitudinal axis).In addition, applicable viewing angle can comprise apart from object one distance and/or to object and arround visual field.In concrete example, viewing distance can be two feet far away, and it has 45 degree of wide visual field centered by stapler.Additionally, more than one applicable viewing angle can be determined.Such as, several GS1 standard viewing angles can be determined.Alternatively or additionally, by determining that there is different object viewing distances and the viewing angle of visual field, " amplification " view and/or " reducing " view can be provided.
It will be understood to those of skill in the art that, the method having other similar can perform following operation: the search inquiry receiving the request comprised the information about object at server place, determine the 3D model of object, the object-based image stored determines applicable light field and applicable viewing angle, and in search query results, send determined information.These similar methods are here susceptible to implicitly.
In certain embodiments, disclosed method may be implemented as the computer program instructions of encoding in non-transitory computer readable storage medium or on other non-state medium or manufacture with machine-readable form.Fig. 8 illustrates the conceptual partial view comprising the exemplary computer program product 300 of computer program arranged according at least some embodiment in this paper, and described computer program is used for moving calculation machine process on the computing device.
In one embodiment, signal bearing medium 302 is utilized to provide exemplary computer program product 300.Signal bearing medium 302 can comprise one or more programmed instruction 304, and described one or more programmed instruction 304 can provide the above function about the Subgraph description in Figure 1A-Fig. 1 D and Fig. 2-Fig. 7 or partial function when executed by one or more processors.In some instances, signal bearing medium 302 can comprise computer-readable medium 306, such as, but not limited to hard disk drive, compact disk (CD), digital video disc (DVD), numerical tape, storer etc.In some implementations, signal bearing medium 302 can comprise computing machine recordable media 308, such as, but not limited to storer, read/write (R/W) CD, R/W DVD etc.In some implementations, signal bearing medium 302 can comprise communication media 310, such as, but not limited to numeral and/or analogue communication medium (such as, optical cable, waveguide, wired communications links, wireless communication link etc.).Therefore, such as, signal bearing medium 302 can be transmitted by the communication media 310 (such as, meeting the wireless communication medium of IEEE 802.8 standard or other host-host protocol) of wireless.
One or more programmed instruction 304 can be the instruction of the executable and/or logic realization of such as computing machine.In some instances, computing equipment (such as with reference to computing equipment and the system of Figure 1A-Fig. 1 D description) can be configured to provide various operation, function or action in response to by the one or more programmed instruction 304 being sent to computing equipment in computer-readable medium 306, computing machine recordable media 308 and/or communication media 310.
Non-transitory computer-readable medium also can be distributed in multiple data storage elements, and they can be placed away from each other.The computing equipment of some or all performed in the instruction that stored can be mobile device, the illustrated and input source 102 that describes with reference to Figure 1A and/or output source 108 in such as Figure 1A.Alternatively, the computing equipment of some or all performed in the instruction stored can be server, illustrated server 104 in such as Figure 1A.
More than describe the various Characteristic and function describing disclosed system, equipment and method with reference to the accompanying drawings in detail.Although disclosed various aspect and embodiment herein, other side and embodiment will be clearly for those skilled in the art.Various aspect disclosed herein and embodiment are for exemplary purposes, and also not intended to be limits, and real scope and spirit are indicated by claim.
Claims (20)
1. a method, comprising:
Receive search inquiry at server place, wherein, described search inquiry comprises the request to the information about object;
Determine the 3D model of described object, wherein, described 3D model comprises the three-dimensional shape information about described object;
Based on multiple images stored of described object, determine at least one applicable light field and at least one applicable viewing angle, wherein, in each image stored of object, described object is by least one respective light field illumination and by from respective viewing angle imaging; And
Send search query results from described server, wherein, described search query results comprises described 3D model, at least one applicable light field described and at least one applicable viewing angle described.
2. the method for claim 1, wherein at least one applicable light field described by the lighting condition determining to make it substantially to mate at least one image stored of described object.
3. the method for claim 1, wherein at least one applicable viewing angle described by least one viewing angle determining to make it substantially to mate at least one image stored of described object.
4. the method for claim 1, also comprise at least one expression of playing up described 3D model based at least one applicable light field described and at least one applicable viewing angle described, wherein, at least one expression described is configured at least one image stored substantially mating described object.
5. method as claimed in claim 4, also comprises:
At least one expression described is compared with at least one image stored of described object; And
Similarity measurement is determined based on described comparison.
6. method as claimed in claim 5, also comprise Heat of Formation and map, wherein, described hot showing is penetrated based on described similarity measurement.
7. the method for claim 1, wherein at least one applicable light field described comprises ambient illumination mapping.
8. the method for claim 1, wherein at least one applicable light field described blocks mapping around comprising.
9. the method for claim 1, wherein at least one applicable light field described comprises Lambertian reflection mapping.
10. the method for claim 1, wherein at least one applicable light field described comprises mirror-reflection mapping.
11. the method for claim 1, also comprise the image stored based on described object, at least the three-dimensional two-way Reflectance Distribution Function (BRDF) of determining section, and wherein, at least one applicable light field described is based on described three-dimensional BRDF.
12. the method for claim 1, also comprise:
Based on the image stored of described object, determine the viewing angle of at least one specification, wherein, at least one applicable viewing angle described corresponds to the viewing angle of at least one specification described.
13. the method for claim 1, also comprise:
Determine at least one GS1 standard viewing angle of described object, wherein, at least one applicable viewing angle described corresponds at least one GS1 standard viewing angle of described object.
14. the method for claim 1, also comprise:
Based on the image stored of described object, determine at least one material of described object, wherein, at least one applicable light field described determines based at least one material of described object.
15. the method for claim 1, also comprise:
Based on the image stored of described object, determine at least one superficial makings of described object, wherein, at least one applicable light field described determines based at least one superficial makings of described object.
16. the method for claim 1, also comprise:
Based on the image stored of described object, determine the environment of at least one specification of described object, wherein, at least one applicable light field described determines based on the environment of at least one specification of described object.
17. the method for claim 1, also comprise:
Based on described applicable light field, select at least one candidate's tinter from one group of tinter;
Based on described 3D model and at least one candidate's tinter described, play up candidate image;
In candidate image relatively, described candidate image and reference picture are compared, wherein, described reference picture comprises at least one image stored of described object; And
For each respective candidate's tinter, determine:
I) vision compared based on described candidate image improves tolerance;
Ii) graphic process unit cost;
Iii) size is downloaded; And
Iv) the tinter sorting measure of tolerance, described graphic process unit cost and described download size is at least improved based on described vision.
18. the method for claim 1, also comprise:
Receive the performance information of prediction at described server place, wherein, the performance information of described prediction comprises server/customer end communication bandwidth and client end processor information;
Based on the performance information of described prediction, predetermined frame rate and tinter sorting measure, determine at least one tinter applicatory; And
Add at least one tinter applicatory described to search query results.
19. 1 kinds of computing machines, comprising:
Processor;
Non-transitory computer-readable medium; And
Be stored in the instruction in described non-transitory computer-readable medium, wherein, described instruction can be performed to make described computing machine n-back test by processor, and described function comprises:
I) receive search inquiry, wherein, described search inquiry comprises the request to the information about object;
Ii) determine the 3D model of described object, wherein, described 3D model comprises the three-dimensional shape information about described object;
Iii) based on multiple images stored of described object, determine at least one applicable light field and at least one applicable viewing angle, wherein, in each image stored of described object, described object is by least one respective light field illumination and by from respective viewing angle imaging; And
Iv) send search query results, wherein, described search query results comprises described 3D model, at least one applicable light field described and at least one applicable viewing angle described.
20. 1 kinds of non-transitory computer-readable medium wherein storing instruction, described instruction can be performed to make described computing equipment n-back test by computing equipment, and described function comprises:
Receive search inquiry, wherein, described search inquiry comprises the request to the information about object;
Determine the 3D model of described object, wherein, described 3D model comprises the three-dimensional shape information about described object;
Based on multiple images stored of described object, determine at least one applicable light field and at least one applicable viewing angle, wherein, in each image stored of described object, described object is by least one respective light field illumination and by from respective viewing angle imaging; And
Send search query results, wherein, described search query results comprises described 3D model, at least one applicable light field described and at least one applicable viewing angle described.
Applications Claiming Priority (5)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201261619224P | 2012-04-02 | 2012-04-02 | |
US61/619,224 | 2012-04-02 | ||
US13/607,364 | 2012-09-07 | ||
US13/607,364 US8416240B1 (en) | 2012-04-02 | 2012-09-07 | Determining 3D model information from stored images |
PCT/US2013/030121 WO2013151673A1 (en) | 2012-04-02 | 2013-03-11 | Determining 3d model information from stored images |
Publications (2)
Publication Number | Publication Date |
---|---|
CN104395902A true CN104395902A (en) | 2015-03-04 |
CN104395902B CN104395902B (en) | 2016-09-14 |
Family
ID=47999243
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201380018797.1A Active CN104395902B (en) | 2012-04-02 | 2013-03-11 | Image according to storage determines 3D model information |
Country Status (4)
Country | Link |
---|---|
US (2) | US8416240B1 (en) |
EP (1) | EP2807587B1 (en) |
CN (1) | CN104395902B (en) |
WO (1) | WO2013151673A1 (en) |
Cited By (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN106202545A (en) * | 2015-05-28 | 2016-12-07 | 达索系统公司 | Utilize proximity criterion to inquire about data base |
CN107256265A (en) * | 2017-06-14 | 2017-10-17 | 成都四方伟业软件股份有限公司 | A kind of search-engine results data visualization methods of exhibiting and system |
CN107545597A (en) * | 2016-06-24 | 2018-01-05 | 奥多比公司 | Digital picture is rendered on substrate |
CN109242978A (en) * | 2018-08-21 | 2019-01-18 | 百度在线网络技术（北京）有限公司 | The visual angle regulating method and device of threedimensional model |
Families Citing this family (41)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10298834B2 (en) | 2006-12-01 | 2019-05-21 | Google Llc | Video refocusing |
US20120249550A1 (en) * | 2009-04-18 | 2012-10-04 | Lytro, Inc. | Selective Transmission of Image Data Based on Device Attributes |
US8314790B1 (en) | 2011-03-29 | 2012-11-20 | Google Inc. | Layer opacity adjustment for a three-dimensional object |
US8576223B1 (en) | 2011-03-29 | 2013-11-05 | Google Inc. | Multiple label display for 3D objects |
US8416240B1 (en) | 2012-04-02 | 2013-04-09 | Google Inc. | Determining 3D model information from stored images |
US9858649B2 (en) | 2015-09-30 | 2018-01-02 | Lytro, Inc. | Depth-based image blurring |
US9564175B2 (en) | 2013-04-02 | 2017-02-07 | International Business Machines Corporation | Clustering crowdsourced videos by line-of-sight |
US10334151B2 (en) | 2013-04-22 | 2019-06-25 | Google Llc | Phase detection autofocus using subaperture images |
CN105229703B (en) * | 2013-05-23 | 2018-02-09 | 谷歌有限责任公司 | System and method for generating threedimensional model using the position data of sensing |
TWI503579B (en) | 2013-06-07 | 2015-10-11 | Young Optics Inc | Three-dimensional image apparatus, three-dimensional scanning base thereof, and operation methods thereof |
US20150066997A1 (en) * | 2013-08-30 | 2015-03-05 | General Electric Company | Systems and Methods for Managing Power Plant Component Information |
US9639773B2 (en) * | 2013-11-26 | 2017-05-02 | Disney Enterprises, Inc. | Predicting a light probe for an outdoor image |
US9280825B2 (en) * | 2014-03-10 | 2016-03-08 | Sony Corporation | Image processing system with registration mechanism and method of operation thereof |
US10546424B2 (en) | 2015-04-15 | 2020-01-28 | Google Llc | Layered content delivery for virtual and augmented reality experiences |
US10444931B2 (en) | 2017-05-09 | 2019-10-15 | Google Llc | Vantage generation and interactive playback |
US10540818B2 (en) | 2015-04-15 | 2020-01-21 | Google Llc | Stereo image generation and interactive playback |
US10567464B2 (en) | 2015-04-15 | 2020-02-18 | Google Llc | Video compression with adaptive view-dependent lighting removal |
US10341632B2 (en) | 2015-04-15 | 2019-07-02 | Google Llc. | Spatial random access enabled video system with a three-dimensional viewing volume |
US10565734B2 (en) | 2015-04-15 | 2020-02-18 | Google Llc | Video capture, processing, calibration, computational fiber artifact removal, and light-field pipeline |
US10440407B2 (en) | 2017-05-09 | 2019-10-08 | Google Llc | Adaptive control for immersive experience delivery |
US10419737B2 (en) | 2015-04-15 | 2019-09-17 | Google Llc | Data structures and delivery methods for expediting virtual reality playback |
US10469873B2 (en) | 2015-04-15 | 2019-11-05 | Google Llc | Encoding and decoding virtual reality video |
US11328446B2 (en) | 2015-04-15 | 2022-05-10 | Google Llc | Combining light-field data with active depth data for depth map generation |
US10275898B1 (en) | 2015-04-15 | 2019-04-30 | Google Llc | Wedge-based light-field video capture |
US10412373B2 (en) | 2015-04-15 | 2019-09-10 | Google Llc | Image capture for virtual reality displays |
EP3107007B1 (en) | 2015-06-17 | 2020-05-20 | InterDigital CE Patent Holdings | Method and apparatus for data retrieval in a lightfield database |
US9979909B2 (en) | 2015-07-24 | 2018-05-22 | Lytro, Inc. | Automatic lens flare detection and correction for light-field images |
WO2017131771A1 (en) | 2016-01-29 | 2017-08-03 | Hewlett-Packard Development Company, L.P. | Identify a model that matches a 3d object |
US10275892B2 (en) | 2016-06-09 | 2019-04-30 | Google Llc | Multi-view scene segmentation and propagation |
EP3264286B1 (en) | 2016-06-28 | 2020-11-18 | Dassault Systèmes | Querying a database with morphology criterion |
EP3321817A1 (en) | 2016-11-14 | 2018-05-16 | Dassault Systèmes | Querying a database based on a parametric view function |
US10679361B2 (en) | 2016-12-05 | 2020-06-09 | Google Llc | Multi-view rotoscope contour propagation |
US10594945B2 (en) | 2017-04-03 | 2020-03-17 | Google Llc | Generating dolly zoom effect using light field image data |
US10474227B2 (en) | 2017-05-09 | 2019-11-12 | Google Llc | Generation of virtual reality with 6 degrees of freedom from limited viewer data |
US10354399B2 (en) | 2017-05-25 | 2019-07-16 | Google Llc | Multi-view back-projection to a light-field |
US10545215B2 (en) | 2017-09-13 | 2020-01-28 | Google Llc | 4D camera tracking and optical stabilization |
US11281824B2 (en) | 2017-12-13 | 2022-03-22 | Dassault Systemes Simulia Corp. | Authoring loading and boundary conditions for simulation scenarios |
US10965862B2 (en) | 2018-01-18 | 2021-03-30 | Google Llc | Multi-camera navigation interface |
EP3991441A1 (en) * | 2019-06-28 | 2022-05-04 | PCMS Holdings, Inc. | System and method for hybrid format spatial data distribution and rendering |
CN111327886B (en) * | 2020-03-05 | 2021-11-16 | 胡嘉君 | 3D light field rendering method and device |
US10979672B1 (en) * | 2020-10-20 | 2021-04-13 | Katmai Tech Holdings LLC | Web-based videoconference virtual environment with navigable avatars, and applications thereof |
Citations (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20110227922A1 (en) * | 2010-03-22 | 2011-09-22 | Samsung Electronics Co., Ltd. | Apparatus and method extracting light and texture, and rendering apparatus using light and texture |
Family Cites Families (12)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6347398B1 (en) * | 1996-12-12 | 2002-02-12 | Microsoft Corporation | Automatic software downloading from a computer network |
US7952583B2 (en) * | 2000-06-19 | 2011-05-31 | Mental Images Gmbh | Quasi-monte carlo light transport simulation by efficient ray tracing |
WO2004047426A2 (en) * | 2002-11-15 | 2004-06-03 | Esc Entertainment, A California Corporation | Reality-based light environment for digital imaging in motion pictures |
EP1551178A1 (en) * | 2003-12-18 | 2005-07-06 | Koninklijke Philips Electronics N.V. | Supplementary visual display system |
KR20070059951A (en) * | 2005-12-06 | 2007-06-12 | 삼성전자주식회사 | Device and method for displaying screen image in wireless terminal |
JP5406019B2 (en) * | 2006-05-17 | 2014-02-05 | セルーメン、インコーポレイテッド | Method for automated tissue analysis |
US7756356B2 (en) * | 2007-03-08 | 2010-07-13 | Mitsubishi Electric Research Laboratories, Inc. | System and method for factorizing light in a sequence of images |
US8014572B2 (en) * | 2007-06-08 | 2011-09-06 | Microsoft Corporation | Face annotation framework with partial clustering and interactive labeling |
US8406567B2 (en) * | 2008-01-09 | 2013-03-26 | Purdue Research Foundation | Reconstruction of shapes of near symmetric and asymmetric objects |
US8442305B2 (en) * | 2009-06-30 | 2013-05-14 | Mitsubishi Electric Research Laboratories, Inc. | Method for determining 3D poses using points and lines |
US20110018876A1 (en) * | 2009-07-21 | 2011-01-27 | Zebra Imaging, Inc. | Systems and Methods for Determining Lighting for 3D Geometry |
US8416240B1 (en) | 2012-04-02 | 2013-04-09 | Google Inc. | Determining 3D model information from stored images |
-
2012
- 2012-09-07 US US13/607,364 patent/US8416240B1/en active Active
-
2013
- 2013-03-08 US US13/791,182 patent/US8976179B2/en active Active
- 2013-03-11 WO PCT/US2013/030121 patent/WO2013151673A1/en active Application Filing
- 2013-03-11 EP EP13711242.1A patent/EP2807587B1/en active Active
- 2013-03-11 CN CN201380018797.1A patent/CN104395902B/en active Active
Patent Citations (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20110227922A1 (en) * | 2010-03-22 | 2011-09-22 | Samsung Electronics Co., Ltd. | Apparatus and method extracting light and texture, and rendering apparatus using light and texture |
Non-Patent Citations (2)
Title |
---|
MARSCHNER, ET AL.: "Inverse Lighting for Photography", 《COLOR AND IMAGING CONFERENCE》 * |
NOAH SNAVELY,ET AL.: "Modeling the World from Internet Photo Collections", 《INTERNATIONAL JOURNAL OF COMPUTER VISION》 * |
Cited By (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN106202545A (en) * | 2015-05-28 | 2016-12-07 | 达索系统公司 | Utilize proximity criterion to inquire about data base |
CN106202545B (en) * | 2015-05-28 | 2022-04-29 | 达索系统公司 | Querying a database using proximity criteria |
CN107545597A (en) * | 2016-06-24 | 2018-01-05 | 奥多比公司 | Digital picture is rendered on substrate |
CN107545597B (en) * | 2016-06-24 | 2021-11-05 | 奥多比公司 | Rendering digital images on a substrate |
CN107256265A (en) * | 2017-06-14 | 2017-10-17 | 成都四方伟业软件股份有限公司 | A kind of search-engine results data visualization methods of exhibiting and system |
CN109242978A (en) * | 2018-08-21 | 2019-01-18 | 百度在线网络技术（北京）有限公司 | The visual angle regulating method and device of threedimensional model |
CN109242978B (en) * | 2018-08-21 | 2023-07-07 | 百度在线网络技术（北京）有限公司 | Viewing angle adjusting method and device for three-dimensional model |
Also Published As
Publication number | Publication date |
---|---|
CN104395902B (en) | 2016-09-14 |
US20130262511A1 (en) | 2013-10-03 |
US8976179B2 (en) | 2015-03-10 |
US8416240B1 (en) | 2013-04-09 |
EP2807587B1 (en) | 2017-05-17 |
EP2807587A1 (en) | 2014-12-03 |
WO2013151673A1 (en) | 2013-10-10 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN104395902A (en) | Determining 3D model information from stored images | |
US20140028799A1 (en) | Use of Color and Intensity Modulation of a Display for Three-Dimensional Object Information | |
US9836483B1 (en) | Using a mobile device for coarse shape matching against cloud-based 3D model database | |
US11631218B2 (en) | Efficient compression of data representing triangular mesh attributes | |
CN107533771A (en) | Carried out by 3D Model Reconstructions lattice simplified | |
WO2017142766A1 (en) | Determining depth from structured light using trained classifiers | |
CN102439862A (en) | Ray tracing device and method | |
US9509905B2 (en) | Extraction and representation of three-dimensional (3D) and bidirectional reflectance distribution function (BRDF) parameters from lighted image sequences | |
Peng et al. | A GPU‐based approach for massive model rendering with frame‐to‐frame coherence | |
US10997761B2 (en) | Systems and methods for creating and delivering augmented reality content | |
CN109493431B (en) | 3D model data processing method, device and system | |
WO2018094883A1 (en) | Method for generating three-dimensional model, and terminal device | |
CN107016732B (en) | Method, apparatus, medium, and system for 3D object localization using descriptors | |
Lauterbach et al. | ReduceM: Interactive and memory efficient ray tracing of large models | |
US10872469B2 (en) | System and method for subdividing large polygon mesh datasets into hierarchical subsets for level-of-detail use | |
CN107066926A (en) | Positioned using the 3D objects of descriptor | |
Buchholz et al. | Quantized point‐based global illumination | |
KR102131190B1 (en) | System for providing a 3d model in on-line | |
CN108920598A (en) | Panorama sketch browsing method, device, terminal device, server and storage medium | |
US10872463B2 (en) | Depth-compressed representation for 3D virtual scene | |
WO2023066122A1 (en) | Three-dimensional model data processing method, three-dimensional model data generation method, and related apparatuses | |
US11972534B2 (en) | Modifying materials of three-dimensional digital scenes utilizing a visual neural network | |
Fanini et al. | Encoding VR sessions: image-based techniques to record and inspect immersive experiences | |
CN114064187A (en) | Cross-rendering-engine intermediate device, data processing method and storage medium | |
Terrace | Content Conditioning and Distribution for Dynamic Virtual Worlds |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
C06 | Publication | ||
PB01 | Publication | ||
C10 | Entry into substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
C14 | Grant of patent or utility model | ||
GR01 | Patent grant | ||
CP01 | Change in the name or title of a patent holder | ||
CP01 | Change in the name or title of a patent holder |
Address after: American CaliforniaPatentee after: Google limited liability companyAddress before: American CaliforniaPatentee before: Google Inc. |