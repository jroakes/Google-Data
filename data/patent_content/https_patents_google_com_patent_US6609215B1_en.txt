US6609215B1 - Method and system for implementing network filesystem-based customized computer system automated rebuild tool - Google Patents
Method and system for implementing network filesystem-based customized computer system automated rebuild tool Download PDFInfo
- Publication number
- US6609215B1 US6609215B1 US09/422,361 US42236199A US6609215B1 US 6609215 B1 US6609215 B1 US 6609215B1 US 42236199 A US42236199 A US 42236199A US 6609215 B1 US6609215 B1 US 6609215B1
- Authority
- US
- United States
- Prior art keywords
- computer system
- script
- automated
- computer systems
- computer
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Expired - Lifetime
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F11/00—Error detection; Error correction; Monitoring
- G06F11/07—Responding to the occurrence of a fault, e.g. fault tolerance
- G06F11/16—Error detection or correction of the data by redundancy in hardware
- G06F11/20—Error detection or correction of the data by redundancy in hardware using active fault-masking, e.g. by switching out faulty elements or by switching in spare elements
- G06F11/202—Error detection or correction of the data by redundancy in hardware using active fault-masking, e.g. by switching out faulty elements or by switching in spare elements where processing functionality is redundant
- G06F11/2023—Failover techniques
- G06F11/203—Failover techniques using migration
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F11/00—Error detection; Error correction; Monitoring
- G06F11/07—Responding to the occurrence of a fault, e.g. fault tolerance
- G06F11/16—Error detection or correction of the data by redundancy in hardware
- G06F11/20—Error detection or correction of the data by redundancy in hardware using active fault-masking, e.g. by switching out faulty elements or by switching in spare elements
- G06F11/202—Error detection or correction of the data by redundancy in hardware using active fault-masking, e.g. by switching out faulty elements or by switching in spare elements where processing functionality is redundant
- G06F11/2023—Failover techniques
- G06F11/2028—Failover techniques eliminating a faulty processor or activating a spare
Definitions
- the present invention relates to information processing technology. More particularly the present invention relates to a system and method for simplifying rebuilding a system following a failure.
- the UNIX operating system is a multi-user operating system supporting serial or network connected terminals for more than one user. It supports multi-tasking and a hierarchical directory structure for the organization and maintenance of files. UNIX is portable, requiring only the kernel ( ⁇ 10%) written in assembler, and supports a wide range of support tools including development, debuggers, and compilers.
- the UNIX operating system consists of the kernel, shell, and utilities.
- the kernel schedules tasks, manages data/file access and storage, enforces security mechanisms, and performs all hardware access.
- the shell presents each user with a prompt, interprets commands typed by a user, executes user commands, and supports a custom environment for each user.
- the utilities provide file management (rm, cat, ls, rmdir, mkdir), user management (passwd, chmod, chgrp), process management (kill, ps), and printing (lp, troff, pr).
- a multi-user operating system allows more than one user to share the same computer system at the same time. It does this by time-slicing the computer processor at regular intervals between the various people using the system. Each user gets a set percentage of some amount of time for instruction execution during the time each user has the processor. After a user's allotted time has expired, the operations system intervenes, saving the program's state (program code and data), and then starts running the next user's program (for the user's set percentage of time). This process continues until, eventually, the first user has the processor again.
- dispatching It takes time to save/restore the program's state and switch from one program to another (called dispatching). This action is performed by the kernel and must execute quickly, because it is important to spend the majority of time running user programs, not switching between them. The amount of time that is spent in the system state (i.e., running the kernel and performing tasks like switching between user programs) is called the system overhead and should typically be less than 10%.
- Main system memory is divided into portions for the operating system and user programs. Kernel space is kept separate from user programs. Where there is insufficient main memory to run a program, some other program residing in main memory must be written out to a disk unit to create some free memory space. A decision is made about which program is the best candidate to swap out to disk. This process is called swapping.
- swapping When the system becomes overloaded (i.e., where there are more people than the system can handle), the operating system spends most of its time shuttling programs between main memory and the disk unit, and response time degrades.
- each user is presented with a shell.
- This is a program that displays the user prompt, handles user input, and displays output on the terminal.
- the shell program provides a mechanism for customizing each user's setup requirements and storing this information for re-use (in a file called profile).
- the UNIX operating system When the UNIX operating system starts up, it also starts a system process (getty), which monitors the state of each terminal input line. When getty detects that a user has turned on a terminal, it presents the logon prompt; and once the password is validated, the UNIX system associates the shell program (such as sh) with that terminal (typically there are a number of different shells including ksh and csh). Each user interacts with sh, which interprets each command typed. Internal commands are handled within the shell (set, unset); external commands are invoked as programs (ls, grep, sort, ps).
- a system process getty
- Multi-tasking operating systems permit more than one program to run at once. This is done in the same way as a multi-user system, by rapidly switching the processor between the various programs.
- OS/2 available from IBM Corporation, One New Orchard Road, Armonk, N.Y. 10504
- Windows 95 available from Microsoft Corporation, One Microsoft Way, Redmond, Wash. 98052
- UNIX is an example of a multi-tasking multi-user operating system.
- a multi-user system is also a multi-tasking system. This means that a user can run more than one program at once using key selections to switch between them.
- Multi-tasking systems support foreground and background tasks.
- a foreground task is one the user interacts directly with using the keyboard and screen.
- a background task is one that runs in the background and does not have access to the screen or keyboard. Background tasks include operations like printing, which can be spooled for later execution.
- the role of the operating system is to keep track of all the programs, allocating resources like disks, memory, and printer queues as required. To do this, it must lensure that one program does not get more than its fair share of the computer resources.
- the operating system does this by two methods: scheduling priority and system semaphores. Each program is assigned a priority level. Higher priority tasks (like reading and writing to the disk) are performed more regularly. User programs may have their priority adjusted dynamically, upwards, or downwards, depending upon their activity and available system resources.
- System semaphores are used by the operating system to control system resources. A program can be assigned a resource by getting a semaphore (via a system call to the operating system). When the resource is no longer needed, the semaphore is returned to the operating system, which can then allocate it to another program.
- Disk drives and printers are serial in nature. This means that only one request can be performed at any one time.
- the operating system manages them via queues. Each serial device is associated with a queue.
- a user program wants access to the disk, i.e., it sends the request to the queue associated with the disk.
- the operating system runs background tasks (called daemons), which monitor these queues and service requests from them. A request is then performed by this daemon process, and the results are sent back to the user's program.
- daemons background tasks
- Multi-tasking systems provide a set of utilities for managing processes. In UNIX, these are ps (list processes), kill (kill a process), and (run a process in the background). In UNIX, all user programs and application software use the system call interface to access system resources like disks, printers, memory etc.
- the system call interface in UNIX provides a set of system calls (C functions). The purpose of the system call interface is to provide system integrity, as all low level hardware access is under control of the operating system. This prevents a program from corrupting the system.
- the operating system Upon receiving a system call, the operating system validates its authenticity or permission, executes it on behalf of the program, then it returns the results. If the request is invalid or not authenticated, the operating system does not perform the request, it simply returns an error code to the program.
- the system call is accessible as a set of ‘C ’ functions, as the majority of UNIX is also written in ‘C ’. Typical system calls are: _read —for reading from the disk unit; _write —for writing to the disk unit; _getch —for reading a character from a terminal; _putch —for writing a character to the terminal; and_ioctl —for controlling and setting device parameters.
- a file is a sequence of bytes, typically 8 bits long, and is equivalent to a character.
- UNIX keeps track of files internally by assigning each one a unique identifying number. These numbers, called i-node numbers, are used only within the UNIX operating system kernel itself. While UNIX uses i-node numbers to refer to files, it allows users to identify each file by a user-assigned name.
- a file name can be any sequence containing from one to fourteen characters.
- UNIX provides users with a way of organizing files. Files may be grouped into directories. Internally, a directory is a file that contains the names of ordinary files and other directories and their corresponding i-node numbers. Given the name of a file, UNIX looks in the file's directory and obtains the corresponding i-node number for the file. With this i-node number, UNIX can examine other internal tables to determine where the file is stored and make it accessible to the user. UNIX directories themselves have names, each of which may also contain fourteen characters.
- UNIX supports the grouping of directories into a hierarchical file system.
- a directory At the very top of a hierarchy is a directory. It may contain the names of individual files and the names of other directories. These, in turn, may contain the names of individual files (and still other directories, and so on).
- a hierarchy of files is the result.
- the UNIX file hierarchy resembles an upside-down tree with its root at the top. The various directories branch out until they finally trace a path to the individual files, which correspond to the tree's leaves.
- the UNIX file system is described as “tree-structured,” with a single directory. All the files that can be reached by tracing a path down through the directory hierarchy from the root directory constitute the file system.
- UNIX maintains a great deal of information about the files that it manages. For each file, the file system keeps track of the file's size, location, ownership, security, type, creation time, modification time, and access time. All of this information is maintained automatically by the file system as the files are created and used.
- UNIX file systems reside on mass storage devices such as disk files. These disk files may use fixed or removable type media, which may be rigid or flexible.
- UNIX organizes a disk as a sequence of blocks, which compose the file system. These blocks are usually either 512 or 2048 bytes long. The contents of a file are stored in one or more blocks, which may be widely scattered on the disk.
- Each i-node is addressed by an index contained in an i-list.
- the i-list is generated based on the size of the file system, with larger file systems generally implying more files and, thus, larger i-lists.
- Each i-node contains thirteen 4-byte disk address elements.
- the direct i-node can contain up to ten block addresses. If the file is larger than this, then the eleventh address points to the first level indirect block. Address 12 and address 13 are used for second level and third level indirect blocks, respectively, with the indirect addressing chain before the first data block growing by one level as each new address slot in the direct i-node is required.
- All input and output (I/O) is done by reading the writing files, because all peripheral devices, even terminals, are files in the file system.
- I/O input and output
- the system checks for the right to do so and, if all is well, returns a non-negative integer called a file descriptor. Whenever I/O is to be done on this file, the file descriptor is used, instead of the name, to identify the file.
- This open file descriptor has associated with it a file table entry kept in the “process” space of the user who has opened the file.
- process is used interchangeably with a program that is being executed.
- the file table entry contains information about an open file, including an i-node pointer for the file and the file pointer for the file, which defines the current position to be read or written in the file. All information about an open file is maintained by the system.
- the parameters of the ‘read’ and ‘write’ system calls may be manipulated by the application program that is accessing the file. Therefore the application must be sensitive to and take advantage of the multi-level store characteristics inherent in a standard system memory hierarchy. From the application perspective, it is advantageous if the system memory components can be viewed as a single level hierarchy. If this is properly done, the application could dispense with most of the I/O overhead.
- VGs volume groups
- the omnipresent “rootvg” contains the operating system details, and it is from this volume group that the computer runs.
- data or application volume groups can also be created.
- the advantage of such volume groups is that, unlike competitive operating systems, an upgrade to a UNIX based operating system will only impact the rootvg and will not affect application data. Analogously, application upgrades will not impact the operating system in any way, presuming that the application has been segregated into its own VG.
- fault-tolerant systems Even with the recent developments in fault-tolerant systems, there are characteristics of UNIX systems that make them difficult to adapt to conventional fault-tolerant operation.
- An important element of fault-tolerant systems is a maintenance and diagnostic system that automatically monitors the condition (or “state”) of functional units of the data processing system, particularly those that are more readily replaceable (“field replaceable units,” or FRUs).
- the complexity of UNIX based systems requires that such fault-tolerant systems maintenance and diagnostic systems (or “state machines”) have capabilities that require state-of-the-art systems maintenance and diagnostics systems.
- Catastrophic failure is defined as any hardware problem, including but not limited to disk, planar, or adapter anomalies, which cause information about data placement or user environment to be lost to the base operating system. It is also possible, though less likely, that such failure incidents can originate within software due to defects in coding or method of execution.
- UNIX Unfortunatelyly speaking, the beauty of UNIX is that it suffers fewer catastrophic failures than many other operating systems. For instance, protection of the kernel is far greater than is found in Win 95/98/NT.
- the complexity of UNIX and the adaptability/configurability of it means that reconfiguration following such a catastrophic failure can be a far more difficult task than configuring other operating systems. While UNIX based systems tend to fail less often than other operating systems, it is harder to recover from those failures because of the complexity of the system.
- UNIX system problems that precipitate failure may have been discoverable for some length of time before the actual failure occurs.
- recovery actions are taken (a) manually by human intervention; and/or (b) only if all such parameters have been captured onto some recoverable media or hard copy, such that an administrator can review the appropriate parameters after they have been lost from the system.
- the present invention relates to a system and method for simplifying a system rebuild process.
- an automated data collection script is updated to include the identity and location of files containing personality and license information.
- a list of workstations to be rebuilt, which are supported in case of failure, is then compiled.
- the workstation list is called by the data collection script when it is executed.
- the data collection script collects personality and license information from the specified file on the listed workstations.
- the data collection script then outputs personality and license information to a temporary file at an offboard location.
- a restoration script is executed, which uses the output from the data collection script for restoring personality and license information that may have been lost due to the system failure.
- FIG. 1 is a pictorial representation of a distributed data processing system in which the present invention may be implemented
- FIG. 2 is a block diagram depicting a data processing system that may be implemented as a server in accordance with a preferred embodiment of the present invention
- FIG. 3 is a block diagram illustrating a data processing system in which the present invention may be implemented
- FIG. 4 is a flow chart depicting a high level view of a preferred embodiment of the present invention.
- FIG. 5 is a lower level flowchart depicting a process for collecting data for simplifying a post-failure rebuild in accordance with a preferred embodiment of the present invention
- FIG. 6 is a lower level flowchart depicting a process for the restoration of personality information on post-failure systems for simplifying the rebuild process
- FIGS. 7A-7B illustrate a script for building a checklist.
- the script is called “crchscr.txt”.
- Crchscr builds a checklist, which is used during the building of the new system;
- FIGS. 8A-8L illustrate a script, which gets all of the “personality” information from a system
- FIG. 9 illustrates a list of workstations by hostname, which are going to be customized
- FIGS. 10A-10U illustrate a script for restoring the “personality” to the workstation/server
- FIG. 11 illustrates a script, which is used by refuscr.txt for special customizing of X11mwmrc file for X-Windows;
- FIG. 12 illustrates a file used by refuscr.txt for resetting permissions of key files
- FIG. 13 illustrates a script for collecting filesystem size information, logical volume names, and mount points.
- FIG. 1 is a pictorial representation of a distributed data processing system in which the present invention may be implemented.
- Distributed data processing system 100 is a network of computers in which the present invention may be implemented.
- Distributed data processing system 100 contains a network 102 , which is the medium used to provide communications links between various devices and computers connected together within distributed data processing system 100 .
- Network 102 may include permanent connections, such as wire or fiber optic cables, or temporary connections made through telephone connections.
- a server 104 is connected to network 102 along with storage unit 106 .
- clients 108 , 110 and 112 also are connected to network 102 .
- These clients 108 , 110 and 112 may be, for example, personal computers or network computers.
- a network computer is any computer coupled to a network, which receives a program or other application from another computer coupled to the network.
- server 104 provides data, such as boot files, operating system images, and applications to clients 108 , 110 and 112 .
- Clients 108 , 110 and 112 are clients to server 104 .
- Distributed data processing system 100 may include additional servers, clients, and other devices not shown.
- distributed data processing system 100 is the Internet, with network 102 representing a worldwide collection of networks and gateways that use the TCP/IP suite of protocols to communicate with one another.
- network 102 representing a worldwide collection of networks and gateways that use the TCP/IP suite of protocols to communicate with one another.
- network 102 representing a worldwide collection of networks and gateways that use the TCP/IP suite of protocols to communicate with one another.
- network 102 representing a worldwide collection of networks and gateways that use the TCP/IP suite of protocols to communicate with one another.
- At the heart of the Internet is a backbone of high-speed data communication lines between major nodes or host computers, consisting of thousands of commercial, government, education, and other computer systems that route data and messages.
- distributed data processing system 100 may also be implemented as a number of different types of networks, such as an intranet, a local area network (LAN), or a wide area network (WAN).
- FIG. 1 is intended as an example and not as an architectural limitation for the present invention.
- Data processing system 200 may be a symmetric multiprocessor (SMP) system including a plurality of processors 202 and 204 connected to system bus 206 . Alternatively, a single processor system may be employed. Also connected to system bus 206 is memory controller/cache 208 , which provides an interface to local memory 209 . I/O bus bridge 210 is connected to system bus 206 and provides an interface to I/O bus 212 . Memory controller/cache 208 and I/O bus bridge 210 may be integrated as depicted.
- SMP symmetric multiprocessor
- Peripheral component interconnect (PCI) bus bridge 214 connected to I/O bus 212 provides an interface to PCI local bus 216 .
- PCI bus 216 A number of modems may be connected to PCI bus 216 .
- Typical PCI bus implementations support four PCI expansion slots or add-in connectors.
- Communications links to network computers 108 , 110 and 112 in FIG. 1 may be provided through modem 218 and network adapter 220 connected to PCI local bus 216 through add-in boards.
- Additional PCI bus bridges 222 and 224 provide interfaces for additional PCI buses 226 and 228 , from which additional modems or network adapters may be supported.
- a memory-mapped graphics adapter 230 and hard disk 232 may also be connected to I/O bus 212 as depicted, either directly or indirectly.
- FIG. 2 may vary.
- other peripheral devices such as optical disk drives and the like, may also be used in addition to or in place of the hardware depicted.
- the depicted example is not meant to imply architectural limitations with respect to the present invention.
- the data processing system depicted in FIG. 2, for example, may be an IBM RISC/System 6000 system, a product of International Business Machines Corporation in Armonk, New York, running the Advanced Interactive Executive (AIX) operating system.
- AIX Advanced Interactive Executive
- Data processing system 300 is an example of a client computer.
- Data processing system 300 employs a peripheral component interconnect (PCI) local bus architecture.
- PCI peripheral component interconnect
- Processor 302 and main memory 304 are connected to PCI local bus 306 through PCI bridge 308 .
- PCI bridge 308 also may include an integrated memory controller and cache memory for processor 302 . Additional connections to PCI local bus 306 may be made through direct component interconnection or through add-in boards.
- local area network (LAN) adapter 310 SCSI host bus adapter 312 , and expansion bus interface 314 are connected to PCI local bus 306 by direct component connection.
- audio adapter 316 graphics adapter 318 , and audio/video adapter 319 are connected to PCI local bus 306 by add-in boards inserted into expansion slots.
- Expansion bus interface 314 provides a connection for a keyboard and mouse adapter 320 , modem 322 , and additional memory 324 .
- SCSI host bus adapter 312 provides a connection for hard disk drive 326 , tape drive 328 , and CD-ROM drive 330 .
- Typical PCI local bus implementations support three or four PCI expansion slots or add-in connectors.
- An operating system runs on processor 302 and is used to coordinate and provide control of various components within data processing system 300 in FIG. 3 .
- the operating system may be a commercially available operating system such as a UNIX based operating system, AIX for instance, which is available from International Business Machines Corporation. “AIX” is a trademark of International Business Machines Corporation. Other operating systems include OS/2.
- An object oriented programming system, such as Java may run in conjunction with the operating system and provide calls to the operating system from Java programs or applications executing on data processing system 300 . “Java” is a trademark of Sun Microsystems, Inc. Instructions for the operating system, the object-oriented operating system, and applications or programs are located on storage devices, such as hard disk drive 326 , and may be loaded into main memory 304 for execution by processor 302 .
- FIG. 3 may vary depending on the implementation.
- Other internal hardware or peripheral devices such as flash ROM (or equivalent nonvolatile memory) or optical disk drives and the like, may be used in addition to or in place of the hardware depicted in FIG. 3 .
- the processes of the present invention may be applied to a multiprocessor data processing system.
- data processing system 300 may not include SCSI host bus adapter 312 , hard disk drive 326 , tape drive 328 , and CD-ROM 330 , as noted by dotted line 332 in FIG. 3, denoting optional inclusion.
- the computer to be properly called a client computer, must include some type of network communication interface, such as LAN adapter 310 , modem 322 , or the like.
- data processing system 300 may be a stand-alone system configured to be bootable without relying on some type of network communication interface, whether or not data processing system 300 comprises some type of network communication interface.
- data processing system 300 may be a Personal Digital Assistant (PDA) device, which is configured with ROM and/or flash ROM in order to provide nonvolatile memory for storing operating system files and/or user-generated data.
- PDA Personal Digital Assistant
- a preferred embodiment of the present invention provides a method and system for solving the problem of post-failure rebuild for many system parameters in UNIX computers and utilizes NFS in the manner described above.
- a set of comprehensive scripts has been painstakingly constructed to record many facets of a system's configuration, including printer definitions, tty definitions, network interfaces, user's Ids and passwords.
- the outputs of these scripts can be fed into their reconstructive counterparts, another series of scripts which has the ability to automatically reconstruct lost or destroyed system parameters back onto the “damaged” computer.
- any of the aforementioned parameters are lost via hardware, software or administrator error, they can be easily reconstructed using the mechanisms described herein.
- the process might be broken into two separate high level functions —the data collection process and the restoration process after a catastrophic failure on the system.
- the two functions are independent of each other, in that the data collection function may be repeatedly invoked without invoking the restoration function.
- the restoration process is invoked only after the detection of a filesystem failure. Once a failure occurs, a replacement workstation (or the repaired workstation) must be brought online with a minimum of downtime and difficulty.
- FIG. 4 is a flow chart depicting a high level view of a preferred embodiment of the present invention.
- a starting point for describing the process is with a decision of whether or not it is time to collect data (step 402 ).
- time-based data collection is only one parameter from which to initiate data collection.
- Data collection is performed with an eye on rebuilding an image for the replacement workstation.
- system parameter values define a system's personality.
- Personality information can be thought of as any user and/or group selectable parameters, settings and/or options used for customizing either a computer system, software or firmware attributes. Personality parameters might be as uncomplicated as menu color schemes or as sophisticated as the specification of preferred algorithms needed for processing information on a specific application.
- step 402 data collection cannot be performed after a catastrophic system failure.
- the personality values are either compromised or unavailable due the hardware failure. If the data is not to be collected the process flows to step 408 where a decision is made as to whether the system has failed.
- step 404 filesystems containing personality information and license information are identified, as well as the workstations which are to be supported by the data collection process. Additionally, filesystem, workstation, and server parameters used in the data collection process are checked for compliance with the requirements of the data collection process.
- the refuscr.txt is an example of a data collection script.
- the data collection script (or collection tool) is executed and the requested data is stored on a specified server.
- the output of the collection script is personality and license information from the workstations supported by the restoration process. That information is stored offboard the supported workstations on a secure location (a server, usually the NIM server (network installation management, an environment that provides installation and configuration of software within a network interface), but could be any NFS server).
- the restoration process may be simultaneously invoked across a variety of replacement workstations. Therefore a list of workstations supported by the restoration, specified by hostname, is used by the data collection script for identifying workstations where personality and license information must be collected.
- the restoration process may be performed.
- the restoration function is initiated by a test performed to determine whether a catastrophic failure has occurred (step 408 ).
- the personality information may merely be stored for use in case of a failure, in that case the process ends without executing the restoration function.
- the process depicted in FIG. 4 is a recursive process that is repetitively performed in the background. The process continues to iterate without executing a function until a condition is met for invoking either the data collection function or the restoration function.
- the personality information is immediately used to restore the replacement workstation.
- the process then flows to step 410 .
- the process initially prepares for restoring the personality of the system subsequent to the system personality information being restored (step 410 ).
- specific attribute values associated with the workstations to be rebuilt, as well as both the NIM, the NFS (network filesystem) servers and the restoration scripts are updated for the execution of the restoration function.
- the system may be restored by invoking the restoration function (step 412 ).
- the personality information is transferred to the individual replacement workstation(s).
- personality information need not only be used by a replacement workstation, but might instead be used by the original workstation after it has been brought back up. Data that was lost or compromised as a result of the failure may now be restored from the personality information. The integrity of the personality data is guaranteed, as it was collected prior to the occurrence of the failure. The computer system is thereby immediately ready for use.
- the process iterates back to step 402 and tests for the condition to perform the data collection function.
- FIG. 5 is a lower level flowchart depicting a process for collecting data for simplifying a post-failure rebuild in accordance with a preferred embodiment of the present invention.
- an NFS server is used for storing personality and license information is the NIM server.
- the NSF server used for storing the personality information must be checked for space needed for storing the personality and license information (step 502 ).
- the personality and license information files identified above pertain to specific workstations.
- the data is collected as a safeguard against any of the workstations failing and needing restoration. Therefore, a list of workstations to be supported by the restoration process, which will be rebuilt in the event that one fails, must be compiled (step 510 ). If one of the workstations on the list fails, it will be restored using the personality and license information collected by the gcisci.txt script.
- the list is maintained in the wsnlst.txt file (workstation.name.list) and represents all workstations for which personality information will be collected (step 512 ).
- the gciscr.txt script When invoked, the gciscr.txt script(get.client.information.script) calls the wsnlst.txt script for the list of workstations from which to collect information.
- the wsnlst.txt script For workstations to be restored using the restoration script of the present invention, personality and license information must be collected from specified files which are associated with workstations specified in the wsnlst.txt list. Only those workstations or their replacements will be rebuilt using the collected information.
- the .rhosts (remote host) file associated with each workstation is updated to include the NIM server (nimsvr) as a remote host (step 514 ).
- Setting .rhosts will allow for rsh commands to be executed on each workstation.
- the rsh command logs into the remote host specified by the .rhost parameter.
- the rsh command then sends standard input from the local command line to the remote command (the NIM server) and receives standard output and standard error from the remote command.
- the gciscr.txt script After the gciscr.txt script is updated, the wsnlst.txt list is created and the remote server is authorized for the workstations, the gciscr.txt script (get.client.information.script) can be executed (step 516 ).
- the gciscr.txt script collects personality and license information for the workstations listed in the wsnlst.txt list from the files specified in the gciscr.txt script.
- the gciscr.txt script simultaneously calls the wsnlst.txt file for workstations hostnames, the fssfscr.txt file, which collects filesystem size information, logical volume names, and mount points (step 520 ) and the crchscr.txt script, which builds a checklist (step 522 ) that is used during the building of the new system to verify the success of the (get.client.information.script) (step 524 ).
- step 520 once executed the fssfscr.txt script also generates temporary output files containing the filesystem size information, logical volume names, and mount points and collects and recreates the application filesystem. That information is also written to the NFS server (step 518 ).
- step 516 if there are errors during the execution of the gciscr.txt script, the program will display error messages. All error messages are written to an errorlog.txt.file. If the error message “Unsuccessful NFS mount to” is displayed, the user can either cancel the entire capture session for all workstations named in wsnlst.txt with a control break, or the user can let the process continue on its own. Successful steps also display messages on the screen. For example, this message is critical to the success of the process: “Successful NFS mount to”. When the list of workstations has had the data captured, then a checklist is printed for each workstation (step 522 ). The checklist built by the crchscr.txt script is used during the building of the new system. This is used whenever the workstation parameters have to be restored.
- FIG. 6 is a lower level flowchart depicting a process for the restoration of personality information on post-failure systems for simplifying the rebuild process.
- the process begins with restoration preparations.
- the refuscr.txt script (restore.full.script) is updated with information from a temporary file, which was created by executing the gciscr.txt script (step 602 ).
- the restore.full.script is updated with the application information, so that licenses will be either restored or upgraded, applications will be either restored or upgraded, and/or application data filesystems will be restored.
- a permanent hostname and IP address are selected for the rebuilt computer systems (step 604 ).
- Hostname and IP address are used to tell refuscr.txt the identity of the new system and the location of the “personality” files on the NIM server (NFS server).
- the restoration scripts are then copied to the rebuilt workstation (step 606 ).
- the permanent hostname and IP address are available for the replacement (or repaired) workstation.
- the restoration scripts are then executed on the replacement workstations from a root user session on the replacement workstation. Status messages are displayed as each parameter is restored to the replacement workstation.
- the present invention ensures a heightened readiness of client operations.
- the present invention provides a mechanism to minimize recovery time while mitigating the chance of operator induced errors. Accordingly, the result is increased customer satisfaction through reduced cost of ownership for clients.
- FIGS. 8A-8L illustrate a script, which gets all of the “personality” information from a system.
- the script is called “gciscr.txt” (also called get.client.info.script).
- This is the main program and stores an output file containing personality and license information on an NFS server. In the process, it creates a variety of files, which are used during the building of the new system. It requires wsnlst.txt (also known as wsname.list) as an input file.
- FIGS. 10A-10U illustrate a script for restoring the “personality” to the workstation/server.
- the script is called “refuscr.txt” (also called restore.full.script) is the main program, which restores the “personality” to the workstation/server, which is retrieved from the NFS server. It uses the output files created by gciscr.txt.
Abstract
Description
Claims (23)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US09/422,361 US6609215B1 (en) | 1999-10-21 | 1999-10-21 | Method and system for implementing network filesystem-based customized computer system automated rebuild tool |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US09/422,361 US6609215B1 (en) | 1999-10-21 | 1999-10-21 | Method and system for implementing network filesystem-based customized computer system automated rebuild tool |
Publications (1)
Publication Number | Publication Date |
---|---|
US6609215B1 true US6609215B1 (en) | 2003-08-19 |
Family
ID=27734820
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US09/422,361 Expired - Lifetime US6609215B1 (en) | 1999-10-21 | 1999-10-21 | Method and system for implementing network filesystem-based customized computer system automated rebuild tool |
Country Status (1)
Country | Link |
---|---|
US (1) | US6609215B1 (en) |
Cited By (8)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20010016921A1 (en) * | 1999-12-27 | 2001-08-23 | Hidenori Takata | Information management apparatus, information management system, and information management software |
US20030084438A1 (en) * | 2001-10-25 | 2003-05-01 | Konas Marc A. | System, method, and article of manufacture for creating and updating an application using software application elements |
US20040006588A1 (en) * | 2002-07-08 | 2004-01-08 | Jessen John H. | System and method for collecting electronic evidence data |
US20070016791A1 (en) * | 2005-07-14 | 2007-01-18 | Smita Bodepudi | Issuing a command and multiple user credentials to a remote system |
US20070220319A1 (en) * | 2006-02-03 | 2007-09-20 | Emc Corporation | Automatic classification of backup clients |
US20120185435A1 (en) * | 2011-01-14 | 2012-07-19 | Apple Inc. | Organizing versioning according to permissions |
US20120297234A1 (en) * | 2011-05-19 | 2012-11-22 | International Business Machines Corporation | Concurrent management console operations |
US20130246348A1 (en) * | 2011-01-06 | 2013-09-19 | International Business Machines Corporation | Records declaration filesystem monitoring |
Citations (15)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5673382A (en) * | 1996-05-30 | 1997-09-30 | International Business Machines Corporation | Automated management of off-site storage volumes for disaster recovery |
US5790773A (en) | 1995-12-29 | 1998-08-04 | Symbios, Inc. | Method and apparatus for generating snapshot copies for data backup in a raid subsystem |
US5799147A (en) * | 1994-10-19 | 1998-08-25 | Shannon; John P. | Computer recovery backup method |
US5819020A (en) * | 1995-10-16 | 1998-10-06 | Network Specialists, Inc. | Real time backup system |
US5838660A (en) | 1996-11-14 | 1998-11-17 | Mci Communications Corporation | Dynamic restoration process |
US5909540A (en) | 1996-11-22 | 1999-06-01 | Mangosoft Corporation | System and method for providing highly available data storage using globally addressable memory |
US5958062A (en) * | 1997-03-19 | 1999-09-28 | Fujitsu Limited | Client/server system and computer system |
US6219719B1 (en) * | 1994-05-05 | 2001-04-17 | Openservice Inc. | Method and system for managing a group of computers |
US6249879B1 (en) * | 1997-11-11 | 2001-06-19 | Compaq Computer Corp. | Root filesystem failover in a single system image environment |
US6332200B1 (en) * | 1998-10-29 | 2001-12-18 | International Business Machines Corporation | Capturing and identifying a complete and consistent set of checkpoint files |
US6363499B1 (en) * | 1998-09-21 | 2002-03-26 | Microsoft Corporation | Method and system for restoring a computer to its original state after an unsuccessful installation attempt |
US6363498B1 (en) * | 1997-11-20 | 2002-03-26 | Lucent Technologies, Inc. | Method and apparatus to automatically back up switching system files |
US6385707B1 (en) * | 1998-02-24 | 2002-05-07 | Adaptec, Inc. | Method and apparatus for backing up a disk drive upon a system failure |
US6405325B1 (en) * | 1999-01-30 | 2002-06-11 | Inventec Corp. | Method and tool for restoring crashed operation system of computer |
US6438749B1 (en) * | 1999-03-03 | 2002-08-20 | Microsoft Corporation | Method and system for restoring a computer to its original state after an unsuccessful patch installation attempt |
-
1999
- 1999-10-21 US US09/422,361 patent/US6609215B1/en not_active Expired - Lifetime
Patent Citations (16)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6219719B1 (en) * | 1994-05-05 | 2001-04-17 | Openservice Inc. | Method and system for managing a group of computers |
US5799147A (en) * | 1994-10-19 | 1998-08-25 | Shannon; John P. | Computer recovery backup method |
US5974563A (en) * | 1995-10-16 | 1999-10-26 | Network Specialists, Inc. | Real time backup system |
US5819020A (en) * | 1995-10-16 | 1998-10-06 | Network Specialists, Inc. | Real time backup system |
US5790773A (en) | 1995-12-29 | 1998-08-04 | Symbios, Inc. | Method and apparatus for generating snapshot copies for data backup in a raid subsystem |
US5673382A (en) * | 1996-05-30 | 1997-09-30 | International Business Machines Corporation | Automated management of off-site storage volumes for disaster recovery |
US5838660A (en) | 1996-11-14 | 1998-11-17 | Mci Communications Corporation | Dynamic restoration process |
US5909540A (en) | 1996-11-22 | 1999-06-01 | Mangosoft Corporation | System and method for providing highly available data storage using globally addressable memory |
US5958062A (en) * | 1997-03-19 | 1999-09-28 | Fujitsu Limited | Client/server system and computer system |
US6249879B1 (en) * | 1997-11-11 | 2001-06-19 | Compaq Computer Corp. | Root filesystem failover in a single system image environment |
US6363498B1 (en) * | 1997-11-20 | 2002-03-26 | Lucent Technologies, Inc. | Method and apparatus to automatically back up switching system files |
US6385707B1 (en) * | 1998-02-24 | 2002-05-07 | Adaptec, Inc. | Method and apparatus for backing up a disk drive upon a system failure |
US6363499B1 (en) * | 1998-09-21 | 2002-03-26 | Microsoft Corporation | Method and system for restoring a computer to its original state after an unsuccessful installation attempt |
US6332200B1 (en) * | 1998-10-29 | 2001-12-18 | International Business Machines Corporation | Capturing and identifying a complete and consistent set of checkpoint files |
US6405325B1 (en) * | 1999-01-30 | 2002-06-11 | Inventec Corp. | Method and tool for restoring crashed operation system of computer |
US6438749B1 (en) * | 1999-03-03 | 2002-08-20 | Microsoft Corporation | Method and system for restoring a computer to its original state after an unsuccessful patch installation attempt |
Cited By (16)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7000144B2 (en) * | 1999-12-27 | 2006-02-14 | Canon Kabushiki Kaisha | Information management apparatus, information management system, and information management software |
US20010016921A1 (en) * | 1999-12-27 | 2001-08-23 | Hidenori Takata | Information management apparatus, information management system, and information management software |
US20030084438A1 (en) * | 2001-10-25 | 2003-05-01 | Konas Marc A. | System, method, and article of manufacture for creating and updating an application using software application elements |
US6944855B2 (en) * | 2001-10-25 | 2005-09-13 | Siemens Medical Solutions Health Services Corporation | System, method, and article of manufacture for creating and updating an application using software application elements |
US7370072B2 (en) * | 2002-07-08 | 2008-05-06 | Electronic Evidence Discovery, Inc. | System and method for collecting electronic evidence data |
US20040006588A1 (en) * | 2002-07-08 | 2004-01-08 | Jessen John H. | System and method for collecting electronic evidence data |
US20070016791A1 (en) * | 2005-07-14 | 2007-01-18 | Smita Bodepudi | Issuing a command and multiple user credentials to a remote system |
US7966513B2 (en) * | 2006-02-03 | 2011-06-21 | Emc Corporation | Automatic classification of backup clients |
US20070220319A1 (en) * | 2006-02-03 | 2007-09-20 | Emc Corporation | Automatic classification of backup clients |
US20130246348A1 (en) * | 2011-01-06 | 2013-09-19 | International Business Machines Corporation | Records declaration filesystem monitoring |
US9075815B2 (en) * | 2011-01-06 | 2015-07-07 | International Business Machines Corporation | Records declaration filesystem monitoring |
US9959283B2 (en) | 2011-01-06 | 2018-05-01 | International Business Machines Corporation | Records declaration filesystem monitoring |
US20120185435A1 (en) * | 2011-01-14 | 2012-07-19 | Apple Inc. | Organizing versioning according to permissions |
US8868502B2 (en) * | 2011-01-14 | 2014-10-21 | Apple Inc. | Organizing versioning according to permissions |
US20120297234A1 (en) * | 2011-05-19 | 2012-11-22 | International Business Machines Corporation | Concurrent management console operations |
US9298501B2 (en) * | 2011-05-19 | 2016-03-29 | Globalfoundries Inc. | Concurrent management console operations |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US6496977B1 (en) | Method and system for implementing network filesystem-based aid for computer operating system upgrades | |
US6493729B2 (en) | Method and system to administer mirrored filesystems | |
US6904424B1 (en) | Method and a system for managing shell script file development and execution | |
US6490690B1 (en) | Method and apparatus for unix system catastrophic recovery aid | |
Frisch | Essential system administration: Tools and techniques for linux and unix administration | |
US6912676B1 (en) | Automated risk assessment tool for AIX-based computer systems | |
US6944790B2 (en) | System and method for collecting and restoring user environment data using removable storage | |
US6567811B1 (en) | Method and system to merge volume groups on a UNIX-based computer system | |
JP2009519544A (en) | Automated software testing framework | |
US6880108B1 (en) | Risk assessment methodology for AIX-based computer systems | |
US6832236B1 (en) | Method and system for implementing automatic filesystem growth monitor for production UNIX computer system | |
US9043781B2 (en) | Algorithm for automated enterprise deployments | |
US6633977B1 (en) | System and method for computer system duplication | |
US6931422B1 (en) | Enhanced backup and recovery methodology | |
US6609215B1 (en) | Method and system for implementing network filesystem-based customized computer system automated rebuild tool | |
WO2008103429A1 (en) | Data management in a data storage system using data sets | |
Randall et al. | Deploying the Tivoli Storage Manager Client in a Windows 2000 Environment | |
Vargas et al. | Sun Cluster Environment: Sun Cluster 2.2 | |
Kirkland et al. | Linux Troubleshooting for System Administrators and Power Users: Linu Trou Syst Admi Powe U | |
Sack | SQL Server 2000 Fast Answers for DBAs and Developers, Signature Edition: Signature Edition | |
Adra et al. | IBM System p Advanced POWER Virtualization Best Practices | |
Miller | Getting Started with OpenVMS System Management | |
Sack | SQL Server 2000 Fast Answers | |
Chao | Managing Online Computer Labs | |
Clear et al. | control. This is acceptable for a few dozen machines, but with hundreds of machines spread across several administrative groups, some mechanism is needed to share administrative control over the master administrative files. The Computer Science Division of the Applied Research |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: INTERNATIONAL BUSINESS MACHINES CORPORATION, NEW YFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:HAMILTON, RICK A. II;LIPTON, STEVEN JAY;REEL/FRAME:010341/0241;SIGNING DATES FROM 19991013 TO 19991014 |
|
FEPP | Fee payment procedure |
Free format text: PAYOR NUMBER ASSIGNED (ORIGINAL EVENT CODE: ASPN); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
FPAY | Fee payment |
Year of fee payment: 4 |
|
REMI | Maintenance fee reminder mailed | ||
FPAY | Fee payment |
Year of fee payment: 8 |
|
SULP | Surcharge for late payment |
Year of fee payment: 7 |
|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:INTERNATIONAL BUSINESS MACHINES CORPORATION;REEL/FRAME:026664/0866Effective date: 20110503 |
|
FPAY | Fee payment |
Year of fee payment: 12 |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044127/0735Effective date: 20170929 |