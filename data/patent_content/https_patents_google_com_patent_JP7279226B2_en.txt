JP7279226B2 - Alternate loop limit - Google Patents
Alternate loop limit Download PDFInfo
- Publication number
- JP7279226B2 JP7279226B2 JP2022031840A JP2022031840A JP7279226B2 JP 7279226 B2 JP7279226 B2 JP 7279226B2 JP 2022031840 A JP2022031840 A JP 2022031840A JP 2022031840 A JP2022031840 A JP 2022031840A JP 7279226 B2 JP7279226 B2 JP 7279226B2
- Authority
- JP
- Japan
- Prior art keywords
- loop
- tensor
- iterations
- nested
- iteration
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
- 230000015654 memory Effects 0.000 claims description 65
- 238000000034 method Methods 0.000 claims description 28
- 238000004364 calculation method Methods 0.000 claims description 13
- 238000010801 machine learning Methods 0.000 claims description 6
- 230000004044 response Effects 0.000 claims description 4
- 238000013528 artificial neural network Methods 0.000 description 24
- 230000008569 process Effects 0.000 description 12
- 238000004590 computer program Methods 0.000 description 7
- 239000011159 matrix material Substances 0.000 description 6
- 238000010586 diagram Methods 0.000 description 4
- 230000003287 optical effect Effects 0.000 description 3
- 230000004913 activation Effects 0.000 description 2
- 238000003491 array Methods 0.000 description 2
- 238000013527 convolutional neural network Methods 0.000 description 2
- 238000000926 separation method Methods 0.000 description 2
- ROXBGBWUWZTYLZ-UHFFFAOYSA-N [6-[[10-formyl-5,14-dihydroxy-13-methyl-17-(5-oxo-2h-furan-3-yl)-2,3,4,6,7,8,9,11,12,15,16,17-dodecahydro-1h-cyclopenta[a]phenanthren-3-yl]oxy]-4-methoxy-2-methyloxan-3-yl] 4-[2-(4-azido-3-iodophenyl)ethylamino]-4-oxobutanoate Chemical compound O1C(C)C(OC(=O)CCC(=O)NCCC=2C=C(I)C(N=[N+]=[N-])=CC=2)C(OC)CC1OC(CC1(O)CCC2C3(O)CC4)CCC1(C=O)C2CCC3(C)C4C1=CC(=O)OC1 ROXBGBWUWZTYLZ-UHFFFAOYSA-N 0.000 description 1
- 230000008859 change Effects 0.000 description 1
- 238000004891 communication Methods 0.000 description 1
- 238000013500 data storage Methods 0.000 description 1
- 230000006870 function Effects 0.000 description 1
- 230000000644 propagated effect Effects 0.000 description 1
- 239000004065 semiconductor Substances 0.000 description 1
- 239000007787 solid Substances 0.000 description 1
- 239000000758 substrate Substances 0.000 description 1
- 230000009466 transformation Effects 0.000 description 1
- 238000000844 transformation Methods 0.000 description 1
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/044—Recurrent networks, e.g. Hopfield networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F8/00—Arrangements for software engineering
- G06F8/40—Transformation of program code
- G06F8/41—Compilation
- G06F8/45—Exploiting coarse grain parallelism in compilation, i.e. parallelism between groups of instructions
- G06F8/451—Code distribution
- G06F8/452—Loops
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/46—Multiprogramming arrangements
- G06F9/50—Allocation of resources, e.g. of the central processing unit [CPU]
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N20/00—Machine learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/06—Physical realisation, i.e. hardware implementation of neural networks, neurons or parts of neurons
- G06N3/063—Physical realisation, i.e. hardware implementation of neural networks, neurons or parts of neurons using electronic means
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T1/00—General purpose image data processing
- G06T1/20—Processor architectures; Processor configuration, e.g. pipelining
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F8/00—Arrangements for software engineering
- G06F8/40—Transformation of program code
- G06F8/41—Compilation
- G06F8/44—Encoding
- G06F8/443—Optimisation
- G06F8/4441—Reducing the execution time required by the program code
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
Description
背景
本明細書は、一般に、複数の計算ユニットを含む専用の計算ユニットを用いて機械学習計算を行うことに関する。
BACKGROUND This specification relates generally to performing machine learning computations using a dedicated computational unit that includes multiple computational units.
ニューラルネットワークは、モデルの１つ以上の層を用いて、受信した入力について出力、たとえば分類を生成する機械学習モデルである。ニューラルネットワークの中には、外層に加えて１つ以上の隠れ層を含むものもある。各隠れ層の出力は、ネットワークにおける次の層、すなわち、ネットワークの次の隠れ層または出力層に対する入力として用いられる。ネットワークの各層は、パラメータのそれぞれの組の現在値に従って、受信された入力から出力を生成する。 A neural network is a machine learning model that uses one or more layers of the model to generate an output, such as a classification, for the input it receives. Some neural networks contain one or more hidden layers in addition to the outer layer. The output of each hidden layer is used as input to the next layer in the network, ie the next hidden or output layer of the network. Each layer of the network produces an output from the received input according to the current values of its respective set of parameters.
ニューラルネットワークの中には、１つ以上の畳み込みニューラルネットワーク層を含むものもある。各畳み込みニューラルネットワーク層は、カーネルの関連する組を有する。カーネルは、重み入力のマトリックス構造として表すことができる。各畳み込み層は、カーネルを使用して、層に対する入力を処理する。層に対する入力の組は、マトリックス構造として表すこともできる。 Some neural networks include one or more convolutional neural network layers. Each convolutional neural network layer has an associated set of kernels. A kernel can be represented as a matrix structure of weight inputs. Each convolutional layer uses a kernel to process the input to the layer. The set of inputs to a layer can also be represented as a matrix structure.
概要
本明細書で説明される主題のある革新的な態様によると、Ｎ次元テンソルにアクセスするための方法は、第１のネステッドループの１つ以上の第１の反復の各々について、第１のネステッドループ内にネストされた第２のネステッドループの第１のループ限界値に達するまで、第２のネステッドループの反復を行うことを備える。第１のネステッドループの１つ以上の第１の反復についての第２のネステッドループの反復回数は、第２のネステッドループが計算システムのハードウェアのプロパティの値を超える反復の総数を有することに応じて、第１のループ限界値によって制限されてもよい。第１のネステッドループの最後から２番目の反復が終了した後で、第１のループ限界値よりも小さい代替ループ限界値に達するまで、第１のネステッドループの最後の反復について、第２のネステッドループの１つ以上の反復を行ってもよい。
SUMMARY According to certain innovative aspects of the subject matter described herein, a method for accessing an N-dimensional tensor includes, for each of one or more first iterations of a first nested loop, a first Performing iterations of a second nested loop until a first loop limit of a second nested loop nested within the nested loop is reached. The number of iterations of the second nested loop for the one or more first iterations of the first nested loop is such that the second nested loop has a total number of iterations exceeding a value of a hardware property of the computing system. Accordingly, it may be limited by the first loop limit. After the penultimate iteration of the first nested loop ends, the second nested One or more iterations of the loop may be performed.
これらのおよび他の実現例は各々、任意に以下の特徴のうちの１つ以上を含んでもよい。いくつかの局面は、第１のネステッドループの最後から２番目の反復が終了したという判断に応じて、第１のネステッドループの最後の反復について、第１のループ限界値の代わりに代替限界値を用いることを備えてもよい。 Each of these and other implementations may optionally include one or more of the following features. Some aspects provide an alternate bound instead of the first loop bound for the last iteration of the first nested loop in response to determining that the penultimate iteration of the first nested loop has terminated. may comprise using
いくつかの局面では、ハードウェアのプロパティの値は、計算システムの複数の個別の計算ユニットを含む。個々の計算ユニットは、計算タイル、プロセッサ、または数値演算ユニットを含んでもよい。 In some aspects, the value of the hardware property includes multiple individual computing units of the computing system. Individual computational units may include computational tiles, processors, or math units.
第２のネステッドループの第１のループ限界値に達するまで、第１のネステッドループ内にネストされた第２のネステッドループの反復を行うことは、計算ユニットを用いて、第２のネステッドループの各々の反復を並列して行うことを含んでもよい。各計算ユニットは、第２のネステッドループのそれぞれの反復を行ってもよい。 performing iterations of a second nested loop nested within the first nested loop until a first loop limit of the second nested loop is reached: It may include performing each iteration in parallel. Each computing unit may perform a respective iteration of the second nested loop.
いくつかの局面では、代替ループ限界値は、第２のネステッドループの反復の総数を計算ユニットの数で除算することによって生じる余りの値に基づいている。第１のネステッドループと第２のネステッドループとを含むネステッドループの組は、第１のネステッドループと第２のネステッドループとの間でネストされた１つ以上のループを含んでもよく、第２のネステッドループは、他のループ内にネストされてもよい。第２のネステッドループは、第１のネステッドループと第２のネステッドループとの間に他のループがネストされていない状態で、第１のネステッドループ内に直接ネストされてもよい。 In some aspects, the alternate loop limit is based on a remainder resulting from dividing the total number of iterations of the second nested loop by the number of computational units. A set of nested loops comprising a first nested loop and a second nested loop may comprise one or more loops nested between the first nested loop and the second nested loop; nested loops may be nested within other loops. A second nested loop may be nested directly within a first nested loop, with no other loops nested between the first nested loop and the second nested loop.
本明細書に記載されている主題は、以下の利点のうちの１つ以上を実現するように、特定の実施形態において実現されてもよい。複数の計算ユニット、たとえば、複数の計算タイル、複数のプロセッサ、または複数の数値演算ユニットを用いて機械学習計算を並列して行うことによって、計算速度および効率が増加し、より複雑な機械学習計算をより短い時間で行うことができる。ネステッドループの調整可能なループ限界値によって、反復回数が個別の計算ユニットの数の倍数または他のハードウェアのプロパティでない場合であっても、ネステッドループの反復を並列して処理することができる。内側ループのループ限界値は、内側ループの反復回数が、内側ループがネストされている外側ループの最後の反復以外の全ての反復について個別の計算ユニットの数に等しくなるように、設定可能である。これにより、外側ループの各反復について、内側ループの各反復が並列して、たとえば同時に行われる。さらに、外側ループの最後の反復以外の全ての反復について、個々の計算ユニットは、外側ループの各反復について使用され、その結果、計算がより速くより効率的になる。外側ループの最後の反復について内側ループの代わりに代替ループ限界値を用いることによって、内側ループの反復を行うために必要な反復の数を減らすことができ、メモリデバイスの数が少なくなる、および／または、より多くのメモリが利用可能になる。 The subject matter described herein may be implemented in particular embodiments to achieve one or more of the following advantages. Performing machine learning computations in parallel using multiple computational units, e.g., multiple computational tiles, multiple processors, or multiple math units, increases computational speed and efficiency, and more complex machine learning computations can be done in less time. Adjustable loop limits for nested loops allow iterations of nested loops to be processed in parallel even if the number of iterations is not a multiple of the number of distinct computational units or other hardware property. A loop limit for an inner loop is configurable such that the number of iterations of the inner loop equals the number of distinct computational units for all but the last iteration of the outer loop in which the inner loop is nested. . Thus, for each iteration of the outer loop, each iteration of the inner loop is performed in parallel, eg, simultaneously. Furthermore, for all iterations of the outer loop but the last iteration, a separate computation unit is used for each iteration of the outer loop, resulting in faster and more efficient computation. By using an alternate loop limit instead of the inner loop for the last iteration of the outer loop, the number of iterations required to perform the iterations of the inner loop can be reduced, reducing the number of memory devices and/or Or more memory becomes available.
このおよび他の局面の他の実現例は、コンピュータ記憶装置に符号化された方法の動作を実行するように構成された、対応するシステム、装置およびコンピュータプログラムを含む。１つ以上のコンピュータのシステムは、操作時にシステムに動作を実行させる、システムにインストールされたソフトウェア、ファームウェア、ハードウェア、またはそれらの組合わせによって、そのように構成されてもよい。１つ以上のコンピュータプログラムは、データ処理装置によって実行されると装置に動作を実行させる命令を有することによって、そのように構成されてもよい。 Other implementations of this and other aspects include corresponding systems, apparatus and computer programs configured to perform the acts of the methods encoded in computer storage. A system of one or more computers may be so configured by software, firmware, hardware, or a combination thereof installed on the system that causes the system to perform actions when in operation. One or more computer programs may be so configured by having instructions which, when executed by a data processing apparatus, cause the apparatus to perform operations.
本明細書に記載されている主題の１つ以上の実現例の詳細については、添付の図面および以下の説明に記載されている。主題の他の考えられる特徴、局面および利点は、明細書、図面および特許請求の範囲から明らかになる。 The details of one or more implementations of the subject matter described in this specification are set forth in the accompanying drawings and the description below. Other possible features, aspects and advantages of the subject matter will become apparent from the specification, drawings and claims.
様々な図における同様の参照番号および名称は、同様の要素を示す。
詳細な説明
本明細書で説明される主題は、ネステッドループの反復を並列して処理するための代替ループ制限値の使用、たとえば、複数の計算ユニットを含むハードウェア計算システムの使用に関する。各計算ユニットは、計算タイル、プロセッサ、または数値演算ユニットとして実現されてもよい。複数の計算ユニットは、ニューラルネットワークの推論作業負荷
を加速するように、および／または、テンソル要素のメモリアドレスを求めるための計算を加速するように構成可能である。ハードウェア計算システムの各計算ユニットは、自己完結型であり、多層ニューラルネットワークの所与の層が求める計算を独立して実行可能である。
Like reference numbers and designations in the various figures indicate like elements.
DETAILED DESCRIPTION The subject matter described herein relates to the use of alternate loop bounds to process iterations of nested loops in parallel, eg, the use of hardware computing systems that include multiple computing units. Each computational unit may be implemented as a computational tile, a processor, or a math unit. The plurality of computational units can be configured to accelerate the inference workload of the neural network and/or to accelerate computations for determining memory addresses of tensor elements. Each computational unit of the hardware computing system is self-contained and can independently perform the computations required by a given layer of the multilayer neural network.
複数の層を有するニューラルネットワークは、推論を計算するために使用可能である。たとえば、入力を与えられると、ニューラルネットワークはその入力について推論を計算可能である。ニューラルネットワークは、ニューラルネットワークの層の各々を通じて入力を処理することによって、この推論を計算する。特に、ニューラルネットワークの層は各々、重みのそれぞれの組を有する。各層は、入力を受信し、当該層の重みの組に従って入力を処理して、出力を生成する。 A neural network with multiple layers can be used to compute the inference. For example, given an input, a neural network can compute inferences about that input. A neural network computes this inference by processing the input through each of the layers of the neural network. Specifically, each layer of the neural network has a respective set of weights. Each layer receives an input and processes the input according to that layer's set of weights to produce an output.
したがって、ニューラルネットワークは、受信した入力から推論を計算するために入力を受信し、推論を生成するためにニューラルネットワーク層の各々を介して入力を処理し、１つのニューラルネットワーク層からの出力は、次のニューラルネットワーク層に対する入力として提供される。ニューラルネットワーク層に対するデータ入力、たとえば、ニューラルネットワークに対する入力、または、シーケンスにおけるニューラルネットワーク層の下の層のニューラルネットワーク層に対する出力は、層に対する起動入力と呼ぶことができる。 Thus, a neural network receives inputs to compute inferences from the received inputs, processes the inputs through each of the neural network layers to generate inferences, and outputs from one neural network layer are It is provided as input to the next neural network layer. A data input to a neural network layer, eg, an input to a neural network, or an output to a neural network layer of a layer below a neural network layer in the sequence, can be referred to as an activation input to the layer.
本明細書で説明される技術は、複数の計算ユニット、たとえば、複数の計算タイル、複数のプロセッサ、または複数の数値演算ユニットにわたってテンソル計算を分散することによって、テンソル要素のメモリアドレスの計算を行うことが可能である。メモリアドレスの計算は、テンソル状態要素に基づいてメモリアドレスのオフセットを求めることと、このオフセットをテンソル要素のベースアドレスに加算することとを含み得る。 The techniques described herein perform computation of memory addresses of tensor elements by distributing the tensor computation across multiple computation units, e.g., multiple computation tiles, multiple processors, or multiple math units. Is possible. Computing the memory address may include determining a memory address offset based on the tensor state element and adding this offset to the base address of the tensor element.
テンソルは多次元形状オブジェクトであり、多次元形状オブジェクトの例としては、行列およびデータ配列が挙げられる。一般に、ソフトウェアアルゴリズムは、１つ以上の計算タイルによって実行されて、ネステッドループを処理することによってテンソル計算を行って、Ｎ次元テンソルのトラバースを行う。計算プロセスの一例では、各ループは、Ｎ次元テンソルの特定の次元のトラバースに関与してもよい。所与のテンソル構造について、計算タイルは、テンソルと関連する１つ以上のドット積の計算を実行するために、特定のテンソルの要素へのアクセスを必要とすることがある。ニューラルネットワーク層内で行われる計算プロセスは、入力起動を含む入力テンソルに重みを含むパラメータテンソルを乗算することを含んでもよい。この計算は、入力起動に１つ以上のサイクルの重みを乗算することと、複数のサイクルにわたって積を累算することとを含む。メモリ構造によって提供される入力起動に、他のメモリ構造によって提供されるパラメータまたは重みが乗算されると、計算が発生する。テンソルはメモリに記憶されるため、テンソルインデックスの組は、メモリからテンソルの正しい要素を検索するために、メモリアドレスの組への変換を必要としてもよい。一般に、計算タイルのテンソルトラバーサルユニットは、テンソルと関連する各次元のインデックス、および計算を行うためにインデックス要素がトラバースされる順序を提供する制御動作を実行する。乗算の結果が出力バスに書き込まれてメモリに記憶されると、テンソル計算は終了する。 Tensors are multidimensional shape objects, and examples of multidimensional shape objects include matrices and data arrays. In general, software algorithms are executed by one or more computational tiles to perform tensor computations by processing nested loops to traverse an N-dimensional tensor. In one example of a computational process, each loop may involve traversing a particular dimension of an N-dimensional tensor. For a given tensor structure, a computational tile may need access to the elements of a particular tensor in order to perform one or more dot product computations associated with the tensor. A computational process performed within a neural network layer may include multiplying an input tensor containing input actuations by a parameter tensor containing weights. This computation involves multiplying the input actuations by one or more cycle weights and accumulating the products over multiple cycles. Computation occurs when input actuations provided by a memory structure are multiplied by parameters or weights provided by other memory structures. Since tensors are stored in memory, a set of tensor indices may require translation into a set of memory addresses in order to retrieve the correct element of the tensor from memory. In general, the tensor traversal unit of a computational tile performs control operations that provide an index for each dimension associated with the tensor, and the order in which the index elements are traversed to perform computations. The tensor computation ends when the result of the multiplication is written to the output bus and stored in memory.
１つの計算タイル（または複数の計算タイル）内の複数の数値演算ユニットは、Ｎ次元テンソルについてのメモリアドレス計算を並列して行う。たとえば、ネステッドループのうち最も内側のループの反復毎に、計算が行われてもよい。テンソル計算が行われる各ループは、「テンソル計算ループ」と呼ばれ、常に最も内側のループでなくてもよい。これらの反復の計算は、数値演算ユニットを用いて並列に行うことが可能である。 Multiple math units within a computational tile (or multiple computational tiles) perform memory address computations on an N-dimensional tensor in parallel. For example, the computation may be performed on each iteration of the innermost loop of the nested loops. Each loop in which tensor computation is performed is called a "tensor computation loop" and may not always be the innermost loop. The computation of these iterations can be done in parallel using a math unit.
ネステッドループにおけるテンソルのトラバースを行うには、要素の対応するデータ値のロードまたは格納を行うために、要素のメモリアドレス値の計算が必要である。たとえば、３次元テンソルの要素は、画像がニューラルネットワークによって分類されるという特徴を表してもよい。第１の次元（Ｚ）は画像の幅を表し、第２の次元（Ｙ）は画像の高さを表し、第３の次元（Ｘ）は画像内の画素のＲＧＢ値を表してもよい。画像を分類するために、各ＲＢＧ値に畳み込み層のフィルタ値を乗算して、起動マップを生成してもよい。 Traversing a tensor in a nested loop requires computing the memory address values of the elements in order to load or store the corresponding data values of the elements. For example, the elements of a 3D tensor may represent features that an image is classified by a neural network. A first dimension (Z) may represent the width of the image, a second dimension (Y) may represent the height of the image, and a third dimension (X) may represent the RGB values of the pixels in the image. To classify the image, each RBG value may be multiplied by the filter value of the convolutional layer to generate the activation map.
ネステッドループを使用して、テンソルの各ＲＢＧ値にアクセスするためのメモリアドレスを決定することができる。ネステッドループは、テンソルの各次元のループを含んでもよい。たとえば、出力ループ（ｚ）は、Ｚ次元（画像の幅）のトラバースを行うために使用可能であり、中間ループ（ｙ）は、Ｙ次元（画像の高さ）のトラバースを行うために使用可能であり、内側ループ（ｘ）は、Ｘ次元（各画素の３つのＲＧＢ値）のトラバースを行うために使用可能である。内側ループの各反復において、外側ループｚおよび中間ループｙの値によって表される画像の特定の画素の３つのＲＧＢ値のうちの１つについて、メモリアドレスが求められる。たとえば、Ｚ＝０およびＹ＝０によって表される画像の画素のＲ値のメモリアドレスは、ｚ＝０およびｙ＝０（たとえば、ｚ＝０；ｙ＝０；ｘ＝０）の場合に、内側ループｘの第１の反復の間に求められてもよい。同様に、Ｚ＝５およびＹ＝２によって表される画像の画素のＧ値のメモリアドレスは、ｚ＝５およびｙ＝２（たとえば、ｚ＝５；ｙ＝２；ｘ＝２）の場合に、内側ループの第３の反復の間に求められてもよい。 A nested loop can be used to determine the memory address to access each RBG value of the tensor. Nested loops may include a loop for each dimension of the tensor. For example, the output loop (z) can be used to traverse the Z dimension (image width) and the intermediate loop (y) can be used to traverse the Y dimension (image height). and the inner loop (x) can be used to traverse the X dimension (three RGB values for each pixel). At each iteration of the inner loop, the memory address is determined for one of the three RGB values of a particular pixel of the image represented by the outer loop z and middle loop y values. For example, the memory address for the R value of a pixel in an image represented by Z=0 and Y=0 is may be determined during the first iteration of the inner loop x. Similarly, the memory address for the G value of the pixel in the image represented by Z=5 and Y=2 is , may be determined during the third iteration of the inner loop.
メモリアドレスの計算は、複数の計算ユニットを用いて並列して行うことができる。たとえば、３つの計算ユニットがある場合、特定の画素の各ＲＧＢ値のメモリアドレス値は、並列して求めることができる。第１の計算ユニットは、画素のＲ値のメモリアドレスを求めることができ、第２の計算ユニットは、画素のＧ値のメモリアドレスのメモリアドレスを求めることができ、第３の計算ユニットは、画素のＢ値のメモリアドレスを求めることができる。ＲＧＢ値についてメモリアドレスが求められると、処理ユニットは、メモリアドレスを用いて値にアクセスし、この値にフィルタ値を乗算することができる。 Calculation of memory addresses can be performed in parallel using multiple calculation units. For example, if there are three computation units, the memory address values for each RGB value for a particular pixel can be determined in parallel. The first computing unit is capable of determining the memory address of the pixel's R value, the second computing unit is capable of determining the memory address of the pixel's G value, and the third computing unit is capable of: The memory address of the pixel's B value can be determined. Once the memory address is determined for the RGB value, the processing unit can use the memory address to access the value and multiply it by the filter value.
場合によっては、テンソル計算ループの反復回数は、計算ユニットの数を超えてもよい。そのような場合、テンソル計算ループの反復は、テンソル計算ループがネストされる外側ループの複数の並列反復に分けられる。たとえば、テンソル計算ループに対応するＮ次元テンソルの次元は、１２８個の要素を含んでもよく、計算システムは、６４個の計算ユニットを含んでもよい。この例では、テンソル計算ループは、外側ループの２つの反復の各々について６４個の計算が並列して行われるように、２つの６４個の外側ループ反復に分けることができる１２８回の反復を含む。この例では、第１の６４回の反復を、計算ユニットの間で分散可能である。第１の６４回の反復が完了すると、計算ユニットの間で次の６４回の反復を分散可能である。 In some cases, the number of iterations of the tensor computation loop may exceed the number of computation units. In such cases, the iterations of the tensor computation loop are divided into multiple parallel iterations of the outer loop in which the tensor computation loop is nested. For example, the dimension of the N-dimensional tensor corresponding to the tensor computation loop may contain 128 elements and the computation system may contain 64 computation units. In this example, the tensor computation loop contains 128 iterations that can be divided into two 64 outer loop iterations, such that 64 computations are performed in parallel for each of the two iterations of the outer loop. . In this example, the first 64 iterations can be distributed among the computational units. After completing the first 64 iterations, the next 64 iterations can be distributed among the computational units.
場合によっては、テンソル計算ループの反復回数は、計算ユニットの数の正確な倍数でなくてもよい。たとえば、テンソル計算ループに対応する次元は、１６０個の要素を含んでもよく、計算システムは、６４個の計算ユニットを有してもよい。この例では、テンソル計算ループは、２つの６４個の外側ループの反復と第３の３２個の外側ループの反復とに分けることができる、１６０回の反復を含む。第３の外側ループの反復についてのテンソル計算ループの反復回数を調整するために、テンソル計算ループのループ限界値は、外側ループの第２の反復の後で、たとえば外側ループの最後の反復の前に、６４から３２に変更されてもよい。 In some cases, the number of iterations of the tensor computation loop may not be an exact multiple of the number of computational units. For example, the dimension corresponding to the tensor computation loop may contain 160 elements and the computation system may have 64 computation units. In this example, the tensor computation loop contains 160 iterations, which can be divided into two 64 outer loop iterations and a third 32 outer loop iterations. To adjust the number of iterations of the tensor computation loop for the third outer loop iteration, the loop limit of the tensor computation loop is set after the second iteration of the outer loop, e.g., before the last iteration of the outer loop. , may be changed from 64 to 32.
図１は、計算システム１０２の例がテンソル計算を加速する環境１００のブロック図で
ある。たとえば、計算システム１０２は、ディープニューラルネットワーク（ＤＮＮｓ）と関連する計算を促進可能である。計算システム１０２は、コントローラ１０５と、複数の個別の計算タイル１１２Ａ～１１２Ｚとを含む。コントローラ１０５は、計算システム１０２内のテンソル計算に関連する１つ以上の命令を実行するように構成される。図示されていないが、コントローラ１０５は、計算システム１０２内で発生する計算に関連する様々なデータを記憶し、これらにアクセスするためのデータメモリと、コントローラ１０５の１つ以上のプロセッサによって実行可能な１つ以上の機械可読命令を記憶するための命令メモリとを含み得る。
FIG. 1 is a block diagram of an
コントローラ１０５は、入力１３２、たとえば命令、コンパイルされたプログラムなどをホスト１３０から受信することができる。計算システム１０２がテンソル計算を行うと、コントローラ１０５は、ホストに出力１３４を提供できる。たとえば、出力１３４は、テンソル要素のメモリアドレスでもよい。コントローラ１０５は、ホストインターフェース（図示せず）を介してホスト１３０に対する入力１３２の受信および出力１３４の提供が可能である。
Controller 105 may receive
コントローラ１０５は、１つ以上のデータ通信路、たとえば１つ以上のバスを介して、計算タイル１１２‐Ａ～１１２‐Ｚと通信できる。同様に、計算タイル１１２‐Ａ～１１２‐Ｚは、１つ以上のバスを介して互いに通信できる。複数の計算タイルを有する計算システムの例は、２０１６年１０月２７日に出願された「ニューラルネットワーク計算タイル」と題された米国特許出願第１５／３３５，７６９号に記載されており、その開示全体を本明細書に引用により援用する。 Controller 105 can communicate with compute tiles 112-A through 112-Z via one or more data communication paths, eg, one or more buses. Similarly, compute tiles 112-A through 112-Z can communicate with each other via one or more buses. An example of a computational system having multiple computational tiles is described in U.S. patent application Ser. The entirety is incorporated herein by reference.
各計算タイル１１２‐Ａ～１１２‐Ｚは、処理ユニット１１４と、データ記憶媒体１１６と、テンソルトラバーサルユニット１２０とを含む。記憶媒体１１６は、計算システム１０２内の情報を格納する。記憶媒体１１６が１つまたは複数の揮発性メモリユニットである実現例もあれば、記憶媒体１１６が１つまたは複数の不揮発性メモリユニットである実現例もある。記憶媒体１１６は、フロッピー（登録商標）ディスクデバイス、ハードディスクデバイス、光ディスクデバイスもしくはテープデバイス、フラッシュメモリもしくは他の同様のソリッドステートメモリデバイス、またはストレージエリアネットワークもしくは他の構成内のデバイスを含むデバイスのアレイなどの、別の形態のコンピュータ可読媒体であってもよい。命令は、処理ユニット１１４によって実行されると、処理ユニット１１４に１つ以上のタスクを実行させる。
Each computational tile 112 -A through 112 -Z includes a processing unit 114 , a
処理ユニット１１４は、１つ以上のプロセッサおよび／または１つ以上の有限状態機械（ＦＳＭ）を含み得る。処理ユニット１１４は、コントローラ１０５から受信された命令を実行可能である。たとえば、処理ユニット１１４は、テンソルトラバーサルユニット１２０を用いてテンソル要素のメモリアドレス（またはメモリアドレスオフセット）を計算するための命令を実行可能である。ＦＳＭを含む処理ユニットの場合、ＦＳＭは、テンソルトラバーサルユニット１２０に、テンソル要素のメモリアドレスを問合わせることができる。
Processing unit 114 may include one or more processors and/or one or more finite state machines (FSMs). Processing unit 114 is capable of executing instructions received from controller 105 . For example, processing unit 114 can execute instructions to compute memory addresses (or memory address offsets) of tensor elements using
一般に、テンソルトラバーサルユニット１２０は、１つ以上のテンソルと関連する状態を求める。いくつかの実現例では、この状態は、メモリアドレス値を求めるためのループ限界値、現在のループインデックス変数値、部分アドレスオフセット値、および／または、ブランチループ限界値を処理するためのプログラムカウンタ値を含んでもよい。テンソルトラバーサルユニット１２０は、特定用途向け集積回路として実現されてもよい。
In general,
テンソルトラバーサルユニット１２０は、テンソルインデックスをメモリアドレスに変換する。たとえば、テンソルトラバーサルユニット１２０は、Ｎ次元テンソルインデック
スの組を１次元アドレス空間に変換してもよい。テンソルトラバーサルユニット１２０は、テンソル要素のメモリアドレスを要素の次元インデックスの結合（たとえば、線形結合）にすることによって、そのような変換を行うことが可能である。
テンソルトラバーサルユニット１２０は、１つ以上のテンソル状態要素１２２と、１つ以上の数値演算ユニット１２４とを含み得る。たとえば、計算タイル１１２‐Ａのテンソルトラバーサルユニット１２０は、４つの数値演算ユニット１２４‐Ａ～１２４‐Ｄを含む。他の計算タイルの他のテンソルトラバーサルユニットは、他の数の数値演算ユニットを含んでもよい。テンソル状態要素１２２の各々は、記憶素子、たとえば、レジスタまたは任意の好適な記憶回路でもよい。各数値演算ユニット１２４は、１つまたは複数の算術論理演算ユニット（ＡＬＵｓ）および／または１つ以上のハードウェア加算器を含み得る。数値演算ユニット１２４は、たとえばテンソル状態要素に格納された値に基づいて、テンソル要素のメモリアドレスまたはメモリアドレスオフセット値を計算するために使用可能である。テンソルトラバーサルユニットを用いてメモリアドレスを求める技法の例は、２０１６年１０月２７日に出願された「ニューラルネットワーク計算タイル」と題された米国特許出願第１５／３３５，７６９号、および２０１６年２月３日に出願された「多次元テンソルにおけるデータへのアクセス」と題された米国特許出願第１５／０１４，２６５号に記載されている。コントローラ１０５は、計算タイル１１２‐Ａ～１１２‐Ｚを用いてテンソル計算を調整可能である。たとえば、コントローラ１０５は、命令を受信して、テンソル要素のメモリアドレスを求めることができる。コントローラ１０５は、ネステッドループを用いてテンソル計算を行うことができる。
各ループは、Ｎ次元テンソルのそれぞれの次元のトラバースに関与することができる。多次元テンソルは、マトリックスまたは多次元マトリックスでもよい。たとえば、２次元テンソルはマトリックスである一方で、３次元テンソルは、複数の２次元マトリックスで構成される３次元マトリックスである。Ｎ次元テンソルの各次元は１つ以上の要素を含んでもよく、各要素は、それぞれのデータ値を格納してもよい。たとえば、テンソルは、プログラムにおける変数でもよく、この変数は３次元でもよい。第１の次元は３００個の要素の長さを有してもよく、第２の次元は１０００個の要素の長さを有してもよく、第３の次元は２０個の要素の長さを有してもよい。当然のことながら、各次元における他の数の要素が可能である。 Each loop can participate in traversing a respective dimension of the N-dimensional tensor. A multidimensional tensor may be a matrix or a multidimensional matrix. For example, a 2D tensor is a matrix, while a 3D tensor is a 3D matrix composed of multiple 2D matrices. Each dimension of an N-dimensional tensor may contain one or more elements, and each element may store a respective data value. For example, a tensor may be a variable in a program, and this variable may be three-dimensional. The first dimension may have a length of 300 elements, the second dimension may have a length of 1000 elements, and the third dimension may have a length of 20 elements. may have Of course other numbers of elements in each dimension are possible.
ネステッドループ内のテンソルのトラバースは、要素の対応するデータ値のロードまたは格納を行うための要素のメモリアドレス値の計算を含み得る。ｆｏｒループは、ネステッドループの一例であり、３つのループインデックス変数（たとえば、ｉ、ｊ、およびｋ）によってトラックされる３つのループが、３次元テンソルのトラバースを行うようにネスト可能である。ニューラルネットワークでは、要素の値は、テンソルと関連付けられた１つ以上のドット積の計算で用いられてもよい。たとえば、要素の値は、対応するパラメータまたは重みが乗算されてもよい。テンソルの要素をネステッドｆｏｒループを用いて順番にトラバースして、要素にアクセスし、要素の値を用いて１つ以上の計算を行ってもよい。３次元テンソルの例を続けると、変数ｉによってトラックされるループのトラバースを行うために外側ｆｏｒループを用いてもよく、変数ｊによってトラックされるループのトラバースを行うために中央ｆｏｒループを用いてもよく、変数ｋによってトラックされるループのトラバースを行うために内側ｆｏｒループを用いてもよい。この例では、アクセスされる第１の要素は、（ｉ＝０，ｊ＝０，ｋ＝０）であってもよく、第２の要素は、（ｉ＝０，ｊ＝０，ｋ＝１）であってもよい、などである。処理ユニットが要素の値にアクセスできるように、かつ、要素の値を用いて１つ以上の計算を行えるように、計算タイル１１２‐Ａ～１１２‐Ｚのテンソルトラバーサルユニット１２０を用いて、ネステッドループを用いて順番に要素のメモリアドレスを求めることが可能である。重みまたはパラメータの値も、ネステッドｆｏｒループを用いて同様にアクセス可能である。また、テ
ンソルトラバーサルユニット１２０は、計算で用いられる重みまたはパラメータについて、および／または計算の出力についてアドレスを求めるために使用可能であり、計算の出力は、ニューラルネットワークの隠れ層に対する入力として用いられてもよい。
Traversing a tensor within a nested loop may involve computing memory address values of elements to load or store corresponding data values of the elements. A for loop is an example of a nested loop, where three loops tracked by three loop index variables (eg, i, j, and k) can be nested to traverse a three-dimensional tensor. In a neural network, the element values may be used in one or more dot product calculations associated with the tensor. For example, element values may be multiplied by corresponding parameters or weights. The elements of the tensor may be traversed in order using nested for-loops to access the elements and perform one or more computations using the values of the elements. Continuing the 3D tensor example, we may use an outer for-loop to traverse the loop tracked by variable i, and a central for-loop to traverse the loop tracked by variable j. may also use an inner for loop to traverse the loop tracked by variable k. In this example, the first element accessed may be (i=0, j=0, k=0) and the second element may be (i=0, j=0, k=1 ), and so on. Nested loops using
たとえば、米国特許出願第１５／０１４，２６５号に記載されているように、テンソル状態要素１２２は、テンソルインデックス要素のグループ、テンソル限界値要素のグループ、および次元乗数要素のグループを含み得る。要素の各グループは、Ｍ個の行とＮ個の列とを有する２Ｄアレイとして配置され得る。グループの各行は、テンソルのテンソルインデックス情報を表し得る。グループの各列は、テンソルに関連付けられたネステッドループインデックス変数値についての情報（たとえば、テンソルインデックス値、テンソル限界値、または次元乗数値）を表し得る。たとえば、テンソルインデックス要素の２Ｄアレイにおける１つの列は、変数ｉについてのテンソルインデックス情報を表してもよく、１つの列は、変数ｉについてのテンソルインデックス情報を表してもよく、１つの列は、変数ｉについてのテンソルインデックス情報を表してもよく、１つの列は、変数ｋについてのテンソルインデックス情報を表してもよい。
For example, as described in US patent application Ser. No. 15/014,265,
各テンソルインデックス要素は、ネステッドループにおけるループのネステッドループ変数をトラックできる。たとえば、１つのテンソルインデックス要素は、ネステッドループインデックス変数ｉをトラックするように割当てられてもよく、１つのテンソルインデックス要素は、ネステッドループインデックス変数ｊをトラックするように割当てられてもよく、１つのテンソルインデックス要素は、ネステッドループインデックス変数ｋをトラックするように割当てられてもよい。各テンソル限界値要素は、テンソルインデックス要素における対応する要素を有する。各テンソル限界値要素は、テンソルに関連付けられたネステッドループインデックス変数値についてのテンソル限界値情報を表してもよい。たとえば、１つのテンソル限界値要素は、ネステッドループインデックス変数ｉについてのテンソル限界値情報を表してもよく、１つのテンソル限界値要素は、ネステッドループインデックス変数ｊについてのテンソル限界値情報を表してもよく、１つのテンソル限界値要素は、ネステッドループインデックス変数ｋについてのテンソル限界値情報を表してもよい。 Each tensor index element can track a nested loop variable for loops in nested loops. For example, one tensor index element may be assigned to track nested loop index variable i, one tensor index element may be assigned to track nested loop index variable j, and one Tensor index elements may be assigned to track the nested loop index variable k. Each tensor limit value element has a corresponding element in the tensor index element. Each tensor bounds element may represent tensor bounds information for the nested loop index variable values associated with the tensor. For example, one tensor bounds element may represent tensor bounds information for nested loops index variable i, and one tensor bounds element may represent tensor bounds information for nested loops index variable j. Well, one tensor bounds element may represent the tensor bounds information for the nested loop index variable k.
各次元乗数要素は、テンソルインデックス要素における対応する要素に乗算される乗数を表し得る。要素のメモリアドレスを求めるために、テンソルトラバーサルユニット１２０は、ネステッドループインデックス変数のテンソルインデックス要素に格納された値にネステッドループインデックス変数の乗数を乗算することによって、各ネステッドループインデックス変数のメモリアドレスオフセットを求めることができる。次に、テンソルトラバーサルユニット１２０は、全ての乗算結果を合計して、アクセスされる要素に対応するメモリアドレスを求めることができる。
Each dimension multiplier element may represent a multiplier by which the corresponding element in the tensor index element is multiplied. To determine the memory address of the element,
テンソルトラバーサルユニット１２０は、ネステッドループの内側ループの各反復後に、テンソルインデックス要素を更新することができる。内側ループの各反復について、テンソルトラバーサルユニット１２０は、たとえば内側ループのテンソルインデックス要素をインクリメントすることによって、ループのテンソルインデックス要素を更新することができる。内側ループの更新されたテンソルインデックス要素が、内側ループのテンソル限界値要素に格納された値に等しい場合には、テンソルインデックス要素をリセットすることができ、内側ループがネストされる次の外側ループのテンソルインデックス要素を更新することができる。次に、テンソルトラバーサルユニット１２０は、上述したように、テンソルインデックス要素にそれらの対応する乗数を乗算し、結果を合計することによって、内側ループのこの反復に対応する次の要素のメモリアドレスを求めることができる。
コントローラ１０５は、プログラムのネステッドループを反復することと、ループのう
ちの１つ以上の各反復について、たとえば、ネステッドループの最も内側の（他の）ループの各反復について計算を行うこととによって、テンソル計算を調整してもよい。テンソル計算を加速するために、コントローラ１０５は、複数の計算ユニットを用いてテンソル計算のうち少なくとも一部を並列して行ってもよい。計算ユニットは、個別の計算タイルまたは個別の数値演算ユニットでもよい。たとえば、コントローラ１０５は、計算タイル１１２‐Ａが第１のテンソル計算を行うように要求し、同時に、計算タイル１１２‐Ｂが第２のテンソル計算を行うように要求してもよい。他の例では、コントローラ１０５は、計算タイル１１２‐Ａが特定のテンソルのテンソル計算を行うように要求してもよい。その後、テンソルトラバーサルユニット１２０は、数値演算ユニット１２４‐Ａ～１２４‐Ｄを用いてテンソル計算を並列して行うことができる。
Controller 105 iterates nested loops of the program and performs a calculation for each iteration of one or more of the loops, e.g., for each iteration of the innermost (other) loop of the nested loops: Tensor calculations may be adjusted. To accelerate tensor computation, controller 105 may perform at least some of the tensor computations in parallel using multiple computation units. The computational units may be discrete computational tiles or discrete math units. For example, controller 105 may request computation tile 112-A to perform a first tensor computation, while simultaneously requesting computation tile 112-B to perform a second tensor computation. In another example, controller 105 may request that computation tile 112-A perform tensor computations for a particular tensor.
ループは一般に、ループのインデックス変数がループの限界値に等しくなると（またはこれを上回ると）終了する。たとえば、ループは、「ｆｏｒ（ｉ＝０；ｊ＜３；ｉ＋＋）」とプログラムされてもよく、ここで、ｉはインデックス値であり、限界値は３である。この例のループは、３つの反復(ｉ＝０、ｉ＝１、およびｉ＝２)を含む。インデックス変数が３に等しい場合、計算しなくてもループから出る。複数の計算ユニット（たとえば、複数の計算タイル１１２または複数の数値演算ユニット１２４）を用いて並列計算を行う場合、コントローラ１０５は、計算が計算ユニットに割当てられるたびにインデックス変数を反復し、ループの他の反復を他の計算ユニットに割当てる前に、インデックス変数を限界値と比較してもよい。
A loop generally terminates when the loop index variable equals (or exceeds) the loop limit. For example, the loop may be programmed as "for (i=0; j<3; i++)", where i is the index value and the limit value is 3. The loop in this example contains three iterations (i=0, i=1, and i=2). If the index variable equals 3, exit the loop without doing any calculations. When performing parallel computations using multiple compute units (eg,
いくつかの実現例では、コントローラ１０５によって実行されるプログラムのネステッドループは、計算システム１０２のプロパティに基づいて求められたループ限界値を有していてもよい。たとえば、ループのうちの１つ以上のループ限界値は、計算システム１０２の計算タイル１１２‐Ａ～１１２‐Ｚの数またはテンソルトラバーサルユニット１２０の数値演算ユニットの数に基づいて求められてもよい。
In some implementations, nested loops in programs executed by controller 105 may have loop bounds determined based on properties of
いくつかの実現例では、コンパイラ１３６は、テンソルのテンソル計算を行うためのプログラムをコンパイルする。コンパイラ１３６は、テンソルの次元のうちの１つ以上に含まれる要素の数、および／または、計算システム１０２の計算ユニットの数に基づいて、ループのうちの１つ以上のループ限界値を求めるように構成可能である。ループのループ限界値は、ループのインデックス値がループ限界値と等しくなるとループが終了する数である。言い換えると、ループのループ限界値は、ループの反復回数に等しくなり得る。
In some implementations, compiler 136 compiles programs to perform tensor computations on tensors. Compiler 136 may determine loop bounds for one or more of the loops based on the number of elements in one or more of the dimensions of the tensor and/or the number of computational units of
コンパイラ１３６は、１つ以上のテンソル計算ループ（テンソル計算が行われるループ）の外側ループを生成するように、かつ、外側ループの１つ以上のループ限界値を求めるように構成されてもよい。生成された外側ループは、テンソル計算ループの反復を外側ループの複数の反復に分割するために使用されてもよい。たとえば、計算システム１０２は６４個の計算ユニット（たとえば、計算タイルまたは数値演算ユニット）を含んでもよく、テンソル計算ループは１２８回の反復を含んでもよい。この例では、計算システム１０２は、６４個のテンソル計算を並列して行うことが可能である。６４個のテンソル計算を並列して行うために、テンソル計算ループの１２８回の反復は、各々がテンソル計算ループの６４回の反復を含む、２つの外側ループの反復に分割可能である。たとえば、外側ループの第１の反復は、テンソル計算ループの反復１～６４を含んでもよい。外側ループの第２の反復は、テンソル計算ループの反復６５～１２８を含んでもよい。このように、６４個のテンソル計算が、計算システムの６４個の計算ユニットの各々を用いて外側ループの第１の反復について並列して行われ（たとえば、１つのタイルにつき１つの計算）、６４個のテンソル計算が、６４個の計算ユニットを用いて外側ループの第２の反復について並列して行われる。
Compiler 136 may be configured to generate outer loops for one or more tensor computation loops (loops in which tensor computations are performed) and to determine one or more loop bounds for the outer loops. The generated outer loop may be used to split an iteration of the tensor computation loop into multiple iterations of the outer loop. For example,
コンパイラ１３６は、外側ループが生成されるべきかどうかを判断し、生成されるべきであると判断すると、コンパイルされたプログラムにおいて外側ループを生成することができる。いくつかの実現例では、コンパイラ１３６は、プログラムが実行される計算システム１０２の計算ユニットの数よりも多い反復をテンソル計算ループが有している場合、外側ループを（コンパイルされているプログラムにおける任意の外側ループに加えて）生成するだけである。テンソル計算ループが計算ユニットの数よりも多い反復を有している場合、コンパイラ１３６は、外側ループを生成して、テンソル計算ループの反復を複数の外側ループの反復に分割可能である。 Compiler 136 can determine whether an outer loop should be generated, and if so, can generate an outer loop in the compiled program. In some implementations, compiler 136 removes the outer loop (any (in addition to the outer loop of ). If the tensor computation loop has more iterations than the number of computation units, compiler 136 may generate an outer loop to divide the tensor computation loop iterations into multiple outer loop iterations.
コンパイラ１３６は、テンソル計算が行われるループの反復回数、および／または、プログラムが実行される計算システム１０２の計算ユニットの数に基づいて、生成された外側ループのループ限界値を求めることもできる。テンソル計算ループの反復回数が計算ユニットの数の倍数であれば、反復回数は、ループに対応する次元における要素の数に等しくてもよい。計算ユニットの数は、計算ユニットを用いて並列して行うことが可能な反復回数の最大値を表すため、コンパイラ１３６は、計算ユニットの数でテンソル計算ループの反復回数を除算できる。たとえば、テンソル計算ループの反復回数が１２８であり計算ユニットの数が６４であれば、生成された外側ループのループ限界値は２（１２８／６４）でもよい。そのため、この例では、外側ループの第１の反復は、テンソル計算ループの６４回の並列反復を含み、外側ループの第２の反復は、テンソル計算ループの６４回の並列反復を含む。除算結果が余りを生じる場合、以下で説明するように、外側ループのループ限界値は、１だけインクリメントされてもよい。
Compiler 136 may also determine loop bounds for the generated outer loop based on the number of loop iterations in which the tensor computation is performed and/or the number of computational units of
コンパイラ１３６は、テンソル計算ループの反復回数と、プログラムが実行される計算システム１０２の計算ユニットの数とに基づいて、テンソル計算ループの１つ以上のループ限界値を求めることもできる。テンソル計算ループの反復回数が計算ユニットの数の正確な倍数である場合、テンソル計算ループのループ限界値は、テンソル計算ループについて生成された外側ループの各反復の計算ユニットの数と等しくなり得る。たとえば、テンソル計算ループが１２０回の反復を有し計算システムが６０個の計算ユニットを含む場合、テンソル計算ループのループ限界値は６０でもよく、外側ループのループ限界値は２でもよい。この例では、外側ループの第１の反復はテンソル計算ループの６０回の反復（並列反復）を含み、外側ループの第２の反復は、テンソル計算ループの６０回の反復を含んでもよい。
Compiler 136 may also determine one or more loop bounds for the tensor computation loop based on the number of iterations of the tensor computation loop and the number of computation units of
テンソル計算ループの反復回数が計算ユニットの数の正確な倍数でない場合、コンパイラ１３６は、テンソル計算ループの２つ以上のループ限界値を求めてもよい。たとえば、コンパイラ１３６は、テンソル計算ループの反復回数を計算ユニットの数で除算してもよい。反復回数は正確な倍数ではないので、この除算の結果は、余りの値を含むことになる。たとえば、反復回数は１６０でもよく、計算ユニットの数は５０でもよい。この例では、コンパイラ１３６は、反復回数（１６０）を計算ユニットの数（５０）で除算して、３の商と１０の余りを得てもよい。コンパイラ１３６は、計算ユニットの数（たとえば、５０）に等しいテンソル計算ループの第１のループ限界値と、余り（たとえば、１０）に等しいテンソル計算ループの代替ループ限界値とを設定できる。プログラムの実行中、代替ループ限界値を、外側ループの第１の反復のテンソル計算ループについて用いてもよく、第１のループ限界値を外側ループの各々の他の反復について用いてもよい。前の例を続けると、外側ループは、１６０／５０＝３で余りが１０の４のループ限界値を有することがあり、外側ループのループ限界値は、余りに基づいて１だけインクリメントされる。外側ループの第１の３回の反復の場合、テンソル計算ループのループ限界値は５０のことがある。そのため、外側ループの第１の３回の反復の各々について、テンソル計算ループの５０回の反復が並列して行われ、結果として１５０回の反復が行われることになる。外側ループの最後の反復について、テンソル計算ループのループ限界値は１０であり、テンソル
計算ループの１６０回の反復全てが外側ループの４回の反復において行われることになる。
Compiler 136 may determine more than one loop bound for the tensor computation loop if the number of iterations of the tensor computation loop is not an exact multiple of the number of computation units. For example, compiler 136 may divide the number of iterations of the tensor computation loop by the number of computation units. Since the number of iterations is not an exact multiple, the result of this division will contain a remainder value. For example, the number of iterations may be 160 and the number of computational units may be 50. In this example, the compiler 136 may divide the number of iterations (160) by the number of computational units (50) to obtain a quotient of 3 and a remainder of 10. Compiler 136 may set a first loop limit for the tensor computation loop equal to the number of computation units (eg, 50) and an alternate loop limit for the tensor computation loop equal to the remainder (eg, 10). During program execution, the alternate loop bound may be used for the tensor computation loop of the first iteration of the outer loop, and the first loop bound may be used for each other iteration of the outer loop. Continuing the previous example, the outer loop may have a loop limit of 4 with 160/50=3 and a remainder of 10, and the loop limit of the outer loop is incremented by 1 based on the remainder. For the first three iterations of the outer loop, the loop limit for the tensor computation loop may be 50. So, for each of the first three iterations of the outer loop, 50 iterations of the tensor computation loop are performed in parallel, resulting in 150 iterations. For the last iteration of the outer loop, the loop limit of the tensor computation loop is 10, and all 160 iterations of the tensor computation loop will be performed in the 4 iterations of the outer loop.
コンパイルされたプログラムは、コントローラ１０５のプロセッサに、外側ループの最後から２番目の反復が終了した後で外側ループの最後の反復が行われる前に、テンソル計算ループのループ限界値を第１のループ限界値から代替ループ限界値に変更させる命令を含み得る。このように、テンソル計算ループの反復を複数の外側ループの反復に分割するために生成された外側ループの最後の反復についてのテンソル計算ループのループ限界値として、代替ループ限界値のループ限界値が用いられる。 The compiled program instructs the processor of the controller 105 to set the loop limit of the tensor computation loop to the first loop after the penultimate iteration of the outer loop and before the last iteration of the outer loop. It may contain an instruction to change from a limit to an alternate loop limit. Thus, as the loop bound of the tensor computation loop for the last iteration of the outer loop generated to split the iteration of the tensor computation loop into multiple outer loop iterations, the loop bound of the alternative loop bound is Used.
いくつかの実現例では、コンパイラ１３６は、テンソル計算ループがネストされている隣接した外側ループとして、すなわち、外側ループとテンソル計算ループとの間に他のループがネストされていない外側ループとして、テンソル計算ループの外側ループを生成可能である。いくつかの実現例では、コンパイラ１３６は、テンソル計算ループがネストされている、すなわち、外側ループが他のループ内にネストされていないネステッドループの最も外側のループとして、外側ループを生成可能である。ネステッドループの最も外側のループにおいて外側ループを生成することによって、ネストループおよびテンソルトラバーサルユニット１２０を用いて求められたメモリアドレスによって、テンソル要素がより隣接して整列する。たとえば、最後の反復のループ限界値を調整することなく、データが格納されないループの反復についてメモリアドレスが求められ、無駄なメモリ空間が生じることがある。ループの最後の反復についての代替の限界値によって、テンソルトラバーサルユニットは、付加的な命令を用いることなくテンソル要素のみのメモリアドレスを求めることができる。
In some implementations, compiler 136 parses tensor computation loops as adjacent outer loops in which the tensor computation loops are nested, i.e., as outer loops with no other loops nested between the outer loop and the tensor computation loop. It is possible to generate an outer loop of the calculation loop. In some implementations, compiler 136 may generate the outer loop as the outermost loop of nested loops in which the tensor computation loop is nested, i.e., the outer loop is not nested within other loops. . By creating an outer loop at the outermost loop of the nested loops, the memory addresses determined using the nested loops and
図２は、複数の計算ユニット２１０を用いてテンソル２０５のトラバースを行うためのネステッドループ２１５および２２０の例を示す図である。個々の計算ユニット２１０は、計算タイルまたは数値演算ユニットであり得る。この例では、テンソル２０５は、Ｘ次元、Ｙ次元、およびＺ次元を有する３次元テンソルである。テンソル２０５は縮尺通りに描かれていないが、Ｘ次元は１６０個の要素の長さを有し、Ｙ次元は３０個の要素の長さを有し、Ｚ次元は１００個の要素の長さを有する。テンソル１０５の各要素は、ニューラルネットワーク計算で使用されるそれぞれのデータ値を格納可能である。
FIG. 2 is a diagram illustrating examples of nested
一般に、テンソルは、ネステッドループ２１５を用いてトラバース可能である。この例では、Ｘ次元は内側ループを用いてトラバースされ、Ｙ次元は中央ループを用いてトラバースされ、Ｚ次元は外側ループを用いてトラバースされる。内側ループの各反復について、メモリアドレスが、内側ループの反復に関してｘ、ｙ、およびｚの値に対応するテンソル要素について計算される。
In general, tensors are traversable using nested
複数の計算ユニット２１０は、計算システムの一部であり得る、たとえば、各計算ユニット２１０は、図１の計算タイル１１２‐Ａ～１１２‐Ｚまたは図１の数値演算ユニット１２４と同じまたは同様であり得る。この例では、計算システムは６４個の計算ユニットを含むが、他の数の計算ユニットも可能である。計算ユニット２１０は、たとえばネステッドループ２２０を用いて、テンソル２０５についてテンソル計算を並列して行うことができる。
Multiple
コンパイラ、たとえば図１のコンパイラ１３６は、ネステッドループ２１５（または、ネステッドループ２１５を表すコード）を含むプログラムと、プログラムが実行される計算システムの計算ユニット２１０の数とに基づいて、ネステッドループ２２０を生成できる。たとえば、コンパイラは、テンソル計算ループ（この例ではＸ次元についてのループ）の反復を複数の外側ループの反復に分割するために、外側ループが生成されるべきであ
ると判断してもよい。
A compiler, such as compiler 136 of FIG. 1, identifies nested
外側ループが生成されるべきかどうかを判断するために、コンパイラは、各テンソル計算ループの反復回数を、計算システムのハードウェアのプロパティと比較してもよい。たとえば、ハードウェアのプロパティは、計算ユニット２１０の数、または計算システムが並列して行うことができる計算の総数でもよい。テンソル計算ループのループの反復回数がハードウェアのプロパティの値を超える場合、コンパイラは外側ループを生成してもよい。この例では、Ｘ次元についてのループの反復回数（１６０）は、計算ユニットの数（６４）を上回る。このため、コンパイラは、インデックス変数「ｉ」を有する外側ループを生成している。
To determine whether an outer loop should be generated, the compiler may compare the number of iterations of each tensor computation loop to the hardware properties of the computation system. For example, the hardware property may be the number of
コンパイラは、テンソル計算ループの反復回数とハードウェアのプロパティの値（たとえば、計算ユニットの数）とに基づいて、外側ループのループ限界値を求めることもできる。たとえば、コンパイラは、テンソル計算ループの反復回数（１６０）を計算ユニットの数（６４）で除算することによって限界値を求めてもよく、その結果は２で余りが３２である。上述したように、外側ループ限界値は、いずれの余りについても１だけインクリメントしてもよい。このため、この例における外側ループ限界値は３である。 The compiler can also determine loop bounds for the outer loop based on the number of iterations of the tensor computation loop and the values of hardware properties (eg, number of computation units). For example, the compiler may find the bound by dividing the number of iterations of the tensor computation loop (160) by the number of computational units (64), the result being 2 with a remainder of 32. As noted above, the outer loop limit may be incremented by one for any remainder. Thus, the outer loop limit in this example is three.
コンパイラは、テンソル計算ループの反復回数とハードウェアのプロパティの値とに基づいて、テンソル計算ループの１つ以上のループ限界値を求めることもできる。テンソル計算ループの反復回数がハードウェアのプロパティの値を超えない場合、テンソル計算ループのループ限界値は、反復回数に等しくなり得る。テンソル計算ループの反復回数がハードウェアのプロパティの正確な倍数である場合、テンソル計算ループのループ限界値は、ハードウェアのプロパティの値に等しくてもよい。テンソル計算ループの反復回数がハードウェアのプロパティの値を超えるがハードウェアのプロパティの値の正確な倍数ではない場合、テンソル計算ループは、ループの最後の反復以外の全てについての第１のループ限界値と、ループの最後の反復についての代替ループ限界値とを有してもよい。第１のループ限界値は、ハードウェアのプロパティの値に等しくてもよく、代替ループ限界値は、テンソル計算ループの反復回数をハードウェアのプロパティの値で除算した後の余りに等しくてもよい。 The compiler may also determine one or more loop bounds for the tensor computation loop based on the number of iterations of the tensor computation loop and values of hardware properties. The loop bound value of the tensor computation loop can be equal to the number of iterations if the number of iterations of the tensor computation loop does not exceed the value of the hardware property. If the number of iterations of the tensor computation loop is an exact multiple of the hardware property, the loop bound value of the tensor computation loop may be equal to the value of the hardware property. If the number of iterations of the tensor computation loop exceeds the value of the hardware property, but is not an exact multiple of the value of the hardware property, then the tensor computation loop follows the first loop limit for all but the last iteration of the loop. and an alternate loop limit value for the last iteration of the loop. The first loop bound value may be equal to the value of the hardware property, and the alternate loop bound value may be equal to the remainder of the number of iterations of the tensor computation loop divided by the value of the hardware property.
この例では、テンソル計算ループの反復回数（１６０）は計算ユニットの数（６４）を超えるが、計算ユニットの数の正確な倍数ではない。このため、Ｘ次元の第１のループ限界値は６４であり、代替限界値は３２である（１６０／６４＝２、余り３２）。外側ループ（ループｉ）の最初の２つの反復について、Ｘ次元のループのループ限界値は６４となる。外側ループの最後の反復について、Ｘ次元のループ限界値は３２となる。 In this example, the number of iterations of the tensor computation loop (160) exceeds the number of computation units (64), but is not an exact multiple of the number of computation units. Thus, the first loop bound in the X dimension is 64 and the alternate bound is 32 (160/64=2, remainder 32). For the first two iterations of the outer loop (loop i), the loop limit in the X dimension is 64. For the last iteration of the outer loop, the X dimension loop limit will be 32.
外側ループの第１の反復回数について、テンソルの６４個のメモリアドレスを、６４個の計算ユニットを用いて並列して求めてもよい。たとえば、第１の計算ユニットは、ｚ＝０；ｙ＝０；ｘ＝０のメモリアドレスを求め、第２の計算ユニットは、ｚ＝０；ｙ＝０；ｘ＝０のメモリアドレスを求め、・・・第６４の計算ユニットは、ｚ＝０；ｙ＝０；ｘ＝６３のメモリアドレスを計算してもよい。外側ループの最後の反復について、６４個の計算ユニットのうち３２個の計算ユニットを用いて、内側ループの最後の３２回の反復を求めてもよい。 For the first number of iterations of the outer loop, 64 memory addresses of the tensor may be determined in parallel using 64 computational units. For example, the first computing unit determines the memory address of z=0; y=0; x=0, the second computing unit determines the memory address of z=0; y=0; ... the 64th computation unit may compute the memory address of z=0; y=0; x=63. For the last iteration of the outer loop, 32 of the 64 computation units may be used to determine the last 32 iterations of the inner loop.
図３は、テンソル計算を行うためのプロセスの例３００を示すフローチャートである。プロセス３００は、１つ以上のコンピュータからなるシステム、たとえば、図１の計算システム１０２によって行われてもよい。
FIG. 3 is a flowchart illustrating an
第１のネステッドループの１つ以上の第１の反復の各々について、第１のネステッドル
ープ内にネストされた第２のネステッドループの第１のループ限界値に達するまで、システムは、第２のネステッドループの反復を行う（３０２）。たとえば、第２のネステッドループは、テンソル計算（たとえば、メモリアドレス計算のドット積の計算）がプログラムの一部として行われるループでもよい。
For each of the one or more first iterations of the first nested loop, the system repeats the second An iteration of the nested loop is performed (302). For example, the second nested loop may be a loop in which tensor computations (eg dot product computations of memory address computations) are performed as part of the program.
第１のループは、たとえば、第１および第２のネストループを含むプログラムをコンパイルしたコンパイラによって生成された外側ループでもよい。たとえば、コンパイラは、テンソル計算ループの識別、テンソル計算ループの外側ループの生成を行うかどうかの判断を行うことができ、そのような生成を行うと判断した場合、生成された外側ループおよび／またはテンソル計算ループの１つ以上のループ限界値を求めることができる。 The first loop may be, for example, an outer loop generated by a compiler that compiled a program containing first and second nested loops. For example, the compiler can identify a tensor computation loop, determine whether to generate an outer loop for a tensor computation loop, and if so, determine whether the generated outer loop and/or One or more loop bounds of the tensor computation loop can be determined.
コンパイラは、第２のネステッドループの反復の総数（たとえば、第２のループに対応するテンソルの次元における要素の総数）とシステムの計算ユニットの数とに基づいて、第２のネステッドループの第１のループ限界値を求めることができる。たとえば、第２のループの反復の総数が計算ユニットの数よりも少ない場合、第１のループ限界値は、第２のネステッドループの反復の総数と等しくてもよい。第２のネステッドループの反復の総数が計算ユニットの数の正確な倍数である場合、第１のループ限界値は、反復回数に等しくてもよい。第２のネステッドループの反復の総数が計算ユニットの数よりも多いものの計算ユニットの正確な倍数でない場合、コンパイラは、第１のループ限界値を計算ユニットの数に設定してもよく、計算ユニットの数によって除算された第２のネステッドループの反復の総数の余りに等しい代替ループ限界値を求めてもよい。 The compiler determines the first iteration of the second nested loop based on the total number of iterations of the second nested loop (e.g., the total number of elements in the dimension of the tensor corresponding to the second loop) and the number of computational units in the system. can be determined. For example, the first loop limit may be equal to the total number of iterations of the second nested loop if the total number of iterations of the second loop is less than the number of computational units. The first loop limit may be equal to the number of iterations if the total number of iterations of the second nested loop is an exact multiple of the number of computational units. If the total number of iterations of the second nested loop is greater than the number of computation units but not an exact multiple of the number of computation units, the compiler may set the first loop bound to the number of computation units, An alternative loop limit value may be determined that is equal to the total number of iterations of the second nested loop divided by the number of .
この例では、第２のネステッドループの反復の総数は計算ユニットの数よりも多く、かつ、第２のネステッドループの反復の総数は計算ユニットの数の正確な倍数ではないと仮定する。このため、この例では、第１のネステッドループの１つ以上の第１の反復回数についての第２のネステッドループの反復回数は、第２のネステッドループが計算ユニットのハードウェアのプロパティの値を超える反復の総数を有することに応じて、第１のループ限界値によって制限される。 This example assumes that the total number of iterations of the second nested loop is greater than the number of computational units, and that the total number of iterations of the second nested loop is not an exact multiple of the number of computational units. Thus, in this example, the number of iterations of the second nested loop for one or more first number of iterations of the first nested loop is the value of Limited by the first loop limit according to having the total number of iterations exceeded.
システムは、第２のネステッドループの反復を並列して行ってもよい。たとえば、上述した通り、第２のネステッドループの反復回数が計算ユニットの数を超えないように、第２のネステッドループの第１のループ限界値は求められてもよい。この例では、第１のネステッドループの１つ以上の第１の反復についての各々の第２のループの各反復は、並列して行うことができる。システムが第２のネステッドループの反復を計算ユニットに割当てると、システムは、第２のループのインデックス変数を反復することができる。インデックス変数が第１のループ限界値に等しくなると、第２のループは完了している。 The system may perform a second nested loop iteration in parallel. For example, as described above, a first loop limit for the second nested loop may be determined such that the number of iterations of the second nested loop does not exceed the number of computational units. In this example, each iteration of each second loop for one or more first iterations of the first nested loop can be performed in parallel. When the system assigns iterations of the second nested loop to computation units, the system can iterate the index variable of the second loop. The second loop is complete when the index variable equals the first loop limit.
システムは、第１のループの最後から２番目（すなわち、最後から１つ手前）の反復が完了しているかどうかを判断する（３０４）。たとえば、システムは、第１のループのインデックス変数を第１のループのループ限界値と比較してもよい。ループ限界値とインデックス変数との間の相違が特定の値（たとえば、１）の場合、システムは、第１のループの最後から２番目の反復が完了していないと判断してもよい。たとえば、「ｉ」のインデックス変数を有するループは、３つの反復を含んでもよい。この例では、ループは、「ｆｏｒ (ｉ＝０；ｉ＜３)」または「ｆｏｒ (ｉ＝１；ｉ＜４）」とプログラムされてもよ
い。
The system determines (304) whether the penultimate (ie, penultimate) iteration of the first loop is complete. For example, the system may compare the index variable of the first loop to the loop limit of the first loop. If the difference between the loop limit value and the index variable is a certain value (eg, 1), the system may determine that the penultimate iteration of the first loop is not complete. For example, a loop with an index variable of 'i' may contain 3 iterations. In this example, the loop may be programmed as "for (i=0; i<3)" or "for (i=1; i<4)".
第１の例では、ループ限界値は３であり、ループの最後の反復はｉ＝２について行われ、ループの最後から２番目の反復はｉ＝１について行われる。一般に、インデックス変数は、典型的にはループの反復が行われるときにまたはその直後にインクリメントされる。この例では、ループの反復が行われた後のインデックス変数が２である場合、行われた反
復は、最後から２番目の反復である。このため、限界値（３）とインデックス変数との間の相違が１に等しい場合、ループの最後から２番目の反復は終了した反復である。
In the first example, the loop limit is 3, the last iteration of the loop is performed for i=2, and the penultimate iteration of the loop is performed for i=1. In general, the index variable is typically incremented when or immediately after an iteration of the loop is performed. In this example, if the index variable is 2 after an iteration of the loop is performed, the iteration performed is the penultimate iteration. Thus, the penultimate iteration of the loop is a finished iteration if the difference between the limit value (3) and the index variable is equal to one.
同様に、第２の例では、ループ限界値は４であり、ループの最後の反復はｉ＝３について行われ、ループの最後から２番目の反復はｉ＝２について行われる。この例では、ループの反復が行われた後のインデックス変数が３の場合、行われた反復は最後から２番目の反復である。したがって、限界値（３）とインデックス変数との間の相違が１に等しい場合、ループの最後から２番目の反復は、終了した反復である。第１のループの最後から２番目の反復が終了していない場合、システムは動作３０２に戻って、更新されたインデックス変数値に対応する第１のネステッドループの次の反復について第２のネステッドループの反復を行う。 Similarly, in the second example, the loop limit is 4, the last iteration of the loop is performed for i=3, and the penultimate iteration of the loop is performed for i=2. In this example, if the index variable is 3 after an iteration of the loop is performed, the iteration performed is the penultimate iteration. Thus, if the difference between limit (3) and the index variable is equal to 1, the penultimate iteration of the loop is a terminated iteration. If the penultimate iteration of the first loop has not finished, the system returns to operation 302 to perform a second nested loop for the next iteration of the first nested loop corresponding to the updated index variable value. Iteration of
第１のループの最後から２番目の反復が完了している場合、システムは、第２のループについて、第１のループ限界値の代わりに代替限界値を用いる（３０８）。たとえば、システムは、第１のネステッドループの最後の反復について、第２のネステッドループ限界値に代替限界値を使用してもよい。 If the penultimate iteration of the first loop is complete, the system substitutes the alternate limit for the first loop limit (308) for the second loop. For example, the system may use an alternate limit value for the second nested loop limit value for the last iteration of the first nested loop.
システムは、代替ループ限界値に達するまで、第１のネステッドループの反復について、第２のネステッドループの１つ以上の反復を行う（３１０）。たとえば、第２のネステッドループの複数の反復が残っている場合、システムは、複数の計算ユニットを用いて反復を並列して行ってもよい。 The system performs one or more iterations of the second nested loop for each iteration of the first nested loop until the alternate loop limit is reached (310). For example, if multiple iterations of the second nested loop remain, the system may perform the iterations in parallel using multiple computation units.
主題の実施形態および本明細書に記載されている機能動作は、本明細書に開示されている構造およびそれらの構造的等価物を含むデジタル電子回路、有形に具体化されたコンピュータソフトウェアもしくはファームウェア、コンピュータハードウェア、またはそれらのうちの１つ以上の組合わせで実現することができる。本明細書に記載されている主題の実施形態は、１つ以上のコンピュータプログラムとして、すなわちデータ処理装置によって実行されるようにまたはデータ処理装置の動作を制御するように有形の非一時的なプログラムキャリアに符号化されるコンピュータプログラム命令の１つ以上のモジュールとして実現可能である。代替的にまたはさらに、プログラム命令は、人工的に発生させた伝搬信号、たとえば機械によって生成される電気信号、光信号または電磁信号に符号化することができ、この信号は、情報を符号化するように生成され、好適な受信機装置に送信され、データ処理装置によって実行される。コンピュータ記憶媒体は、機械可読記憶装置、機械可読記憶基板、ランダムもしくはシリアルアクセスメモリデバイス、またはそれらのうちの１つ以上の組合わせであってもよい。 Embodiments of the subject matter and functional operations described herein may be implemented in digital electronic circuits, tangibly embodied computer software or firmware, including the structures disclosed herein and their structural equivalents. It can be implemented in computer hardware, or a combination of one or more thereof. Embodiments of the subject matter described herein may be implemented as one or more computer programs, i.e., non-transitory programs tangible to be executed by a data processing apparatus or to control the operation of a data processing apparatus. It can be implemented as one or more modules of computer program instructions encoded on a carrier. Alternatively or additionally, program instructions can be encoded in an artificially generated propagated signal, such as an electrical, optical or electromagnetic signal produced by a machine, which encodes information. and transmitted to a suitable receiver device and executed by a data processing device. A computer storage medium may be a machine-readable storage device, a machine-readable storage substrate, a random or serial access memory device, or a combination of one or more thereof.
本明細書に記載されているプロセスおよび論理フローは、入力データ上で動作して出力を生成することによって機能を実行するように１つ以上のコンピュータプログラムを実行する１つ以上のプログラム可能なコンピュータによって実行することができる。これらのプロセスおよび論理フローは、特殊目的論理回路、たとえばＦＰＧＡ（フィールドプログラマブルゲートアレイ）、ＡＳＩＣ（特定用途向け集積回路）、ＧＰＧＰＵ（汎用グラフィックス処理ユニット）またはその他の処理ユニットによっても実行されてもよく、装置は、特殊目的論地回路、たとえばＦＰＧＡ、ＡＩＳＣ、またはＧＰＧＰＵとして実現されてもよい。 The processes and logic flows described herein are implemented by one or more programmable computers executing one or more computer programs to perform functions by operating on input data and generating output. can be run by These processes and logic flows may also be performed by special purpose logic circuits such as FPGAs (Field Programmable Gate Arrays), ASICs (Application Specific Integrated Circuits), GPGPUs (General Purpose Graphics Processing Units) or other processing units. Well, the device may be implemented as a special purpose logic circuit, eg FPGA, AISC or GPGPU.
コンピュータプログラムの実行に適したコンピュータは、一例として、汎用マイクロプロセッサもしくは特殊目的マイクロプロセッサもしくはそれら両方、またはその他の種類の中央処理装置を含み、それらに基づくものであってもよい。一般に、中央処理装置は、リードオンリメモリまたはランダムアクセスメモリまたはそれら両方から命令およびデータを受信する。コンピュータの必須の要素は、命令を実施または実行するための中央処理
装置、ならびに、命令およびデータを記憶するための１つ以上のメモリ装置である。一般に、コンピュータは、データを格納するための１つ以上の大容量記憶装置（たとえば磁気ディスク、光磁気ディスクもしくは光ディスク）も含み、または、１つ以上の大容量記憶装置からデータを受信するように、もしくは１つ以上の大容量記憶装置にデータを送信するように、もしくは１つ以上の大容量記憶装置に対してデータを送受信するように動作可能に結合される。しかしながら、コンピュータはこのような装置を有していなくてもよい。さらに、コンピュータは、別の装置、たとえばほんの数例を挙げると、携帯電話、パーソナルデジタルアシスタント（ＰＤＡ）、携帯オーディオまたはビデオプレーヤ、ゲーム機、グローバルポジショニングシステム（ＧＰＳ）受信機、または携帯型記憶装置（たとえば、ユニバーサルシリアルバス（ＵＳＢ）フラッシュドライブ）に組み込まれてもよい。
Computers suitable for the execution of a computer program may include, by way of example, general and/or special purpose microprocessors, or other types of central processing units. Generally, a central processing unit receives instructions and data from read-only memory and/or random-access memory. The essential elements of a computer are a central processing unit for implementing or executing instructions, and one or more memory units for storing instructions and data. Generally, a computer also includes one or more mass storage devices (e.g., magnetic, magneto-optical, or optical discs) for storing data, or to receive data from one or more mass storage devices. , or operably coupled to transmit data to, or transmit data to, one or more mass storage devices. However, a computer need not have such devices. Additionally, a computer may be used on another device such as a cell phone, personal digital assistant (PDA), portable audio or video player, game console, global positioning system (GPS) receiver, or portable storage device, to name just a few. (eg, a Universal Serial Bus (USB) flash drive).
コンピュータプログラム命令およびデータの格納に好適なコンピュータ可読媒体は、全ての形態の不揮発性メモリ、媒体およびメモリデバイスを含み、これらのデバイスは、一例として、半導体メモリデバイス（たとえば、ＥＰＲＯＭ、ＥＥＰＲＯＭおよびフラッシュメモリデバイス）、磁気ディスク（たとえば、内部ハードディスクまたはリムーバブルディスク）、磁気ディスク（たとえば、内部ハードディスクまたはリムーバブルディスク）、光磁気ディスク、ならびにＣＤ ＲＯＭおよびＤＶＤ－ＲＯＭディスクを含む。プロセッサおよびメモリは、特殊目的論理回路によって補完されてもよく、または特殊目的論理回路に組み入れられてもよい。 Computer-readable media suitable for storing computer program instructions and data include all forms of non-volatile memories, media and memory devices, such as, by way of example, semiconductor memory devices (e.g., EPROM, EEPROM and flash memory). devices), magnetic disks (eg, internal hard disk or removable disk), magnetic disks (eg, internal hard disk or removable disk), magneto-optical disks, and CD ROM and DVD-ROM disks. The processor and memory may be supplemented by, or incorporated into, special purpose logic circuitry.
本明細書は、多くの具体的な実現例の詳細を含んでいるが、これらは、いずれの発明または請求の範囲を限定するものとして解釈されるべきではなく、特定の発明の特定の実施形態に特有の特徴を説明するものとして解釈されるべきである。別々の実施形態の文脈で本明細書に記載されている特定の特徴は、単一の実施形態において組み合わせて実現することも可能である。逆に、単一の実施形態の文脈で記載されているさまざまな特徴は、複数の実施形態において別々にまたは任意の好適な部分的な組み合わせで実現することも可能である。さらに、特徴は、特定の組合わせで動作するものとして上記され、最初にそのように記載されているかもしれないが、記載されている組み合わせの中の１つ以上の特徴は、場合によってはこの組合わせから除外されてもよく、記載されている組み合わせは、部分的な組み合わせまたは部分的な組み合わせの変形例を対象としてもよい。 While this specification contains details of many specific implementations, these should not be construed as limiting any invention or claim, rather than specific embodiments of the particular invention. should be construed as describing the characteristics peculiar to Certain features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely, various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable subcombination. Further, although features are described above as operating in a particular combination, and may initially be described as such, one or more of the features in the described combination may in some cases be used in this manner. Combinations may be excluded and combinations described may cover subcombinations or variations of subcombinations.
同様に、動作は、特定の順序で図面に示されているが、これは、望ましい結果を達成するために、示されている特定の順序またはシーケンシャルな順序でこのような動作を実行しなければならないものとして理解されるべきではなく、示されている動作を全て実行しなければならないものとして理解されるべきでもない。特定の状況では、マルチタスクおよび並列処理が有利である場合もある。さらに、上記の実施形態におけるさまざまなシステムモジュールおよびコンポーネントの分離は、このような分離が全ての実施形態で必要であるものとして理解されるべきではなく、記載されているプログラムコンポーネントおよびシステムは、一般に、単一のソフトウェア製品に一体化されるかまたは複数のソフトウェア製品にパッケージングされてもよいということが理解されるべきである。 Similarly, although acts have been shown in the figures in a particular order, it is understood that such acts must be performed in the specific order shown or sequential order to achieve desirable results. It should not be construed as not having to, nor should it be construed as a requirement that all indicated actions must be performed. Multitasking and parallel processing can be advantageous in certain situations. Furthermore, the separation of various system modules and components in the above embodiments should not be understood as requiring such separation in all embodiments, the program components and systems described generally , may be integrated into a single software product or packaged into multiple software products.
主題の特定の実施形態について説明してきた。他の実施形態は、以下の特許請求の範囲の範囲内である。たとえば、特許請求の範囲に記載されている動作は、異なる順序で実行されても、依然として望ましい結果を達成することができる。一例として、添付の図面に示されているプロセスは、望ましい結果を達成するために、示されている特定の順序またはシーケンシャルな順序を必ずしも必要としない。特定の実現例では、マルチタスクおよび並列処理が有利である場合もある。 Particular embodiments of the subject matter have been described. Other embodiments are within the scope of the following claims. For example, the actions recited in the claims can be performed in a different order and still achieve desirable results. As an example, the processes illustrated in the accompanying figures do not necessarily require the particular order shown or sequential order shown to achieve desirable results. Multitasking and parallel processing may be advantageous in certain implementations.
Claims (19)
前記Ｎ次元テンソルの特定の次元のテンソル要素の数が、前記Ｎ次元テンソルの前記テンソル要素に基づいて計算を行うために使用されるコンピューティングシステムの個別の計算ユニットの数の正確な倍数でないと判断することを備え、前記判断に応じて、
前記特定の次元のトラバースを行うために用いられる第２のループの反復回数を制御するための第１のループを生成することと、
前記特定の次元の前記テンソル要素の数と、前記コンピューティングシステムの前記個別の計算ユニットの数とに基づいて、前記第２のループの第１のループ限界値と、前記第２のループの代替ループ限界値とを判断することとを備え、前記第２のループの前記反復回数が前記計算を行うために用いられるテンソル要素の数を超えないように、前記第１のループ限界値は、前記第１のループの１つ以上の最初の反復について前記第２のループの反復回数を制御し、前記代替ループ限界値は、前記第１のループの最後の反復について前記第２のループの前記反復回数を制御し、判断に応じてさらに、
前記第１のループ内にネストされた前記第２のループを有するコードを生成することを備え、前記方法はさらに、
前記Ｎ次元テンソルにアクセスするように前記コードを実行することを備え、前記実行は、
前記第１のループの１つ以上の最初の反復の各々について、前記第２のループの前記第１のループ限界値に達するまで、前記第１のループ内にネストされた前記第２のループの反復を行うことを含み、
前記第２のループの反復の各々について、複数の計算ユニットのうちの計算ユニットは、前記Ｎ次元テンソルのテンソル要素に基づいて計算を行い、各テンソル要素はデータ値を含み、前記実行はさらに、
前記第１のループの最後から２番目の反復が終了した後で、前記第１のループ限界値よりも小さい前記代替ループ限界値に達するまで、前記第１のループの最後の反復について前記第２のループの１つ以上の反復を行うことと、
各計算の出力を示すデータを処理ユニットに出力することとを含む、方法。 A method for performing computations based on tensor elements of an N-dimensional tensor, comprising:
unless the number of tensor elements of a particular dimension of said N-dimensional tensor is an exact multiple of the number of separate computational units of a computing system used to perform computations based on said tensor elements of said N-dimensional tensor; determining, and in response to said determination,
generating a first loop for controlling the number of iterations of a second loop used to traverse the particular dimension;
a first loop bound for the second loop and an alternative for the second loop based on the number of tensor elements of the particular dimension and the number of distinct computational units of the computing system; and determining a loop limit, wherein the first loop limit is such that the number of iterations of the second loop does not exceed the number of tensor elements used to perform the calculation. controlling the number of iterations of said second loop for one or more first iterations of said first loop, said alternative loop limit being said iteration of said second loop for said last iteration of said first loop; Control the number of times, further depending on the judgment,
The method comprises generating code having the second loop nested within the first loop, the method further comprising:
executing the code to access the N-dimensional tensor, the executing comprising:
nested within the first loop until the first loop limit of the second loop is reached for each of the one or more initial iterations of the first loop ; performing an iteration of said second loop with
For each iteration of the second loop, a computation unit of the plurality of computation units performs a computation based on tensor elements of the N-dimensional tensor, each tensor element comprising data values, the execution further comprising:
a final iteration of the first loop after the penultimate iteration of the first loop ends until reaching the alternate loop limit that is less than the first loop limit. performing one or more iterations of the second loop for
and outputting data indicative of the output of each calculation to a processing unit .
各計算ユニットは、前記第２のループのそれぞれの反復を行う、請求項１～３のいずれか１項に記載の方法。 performing iterations of the second loop nested within the first loop until the first loop limit of the second loop is reached using the computing unit; performing each iteration of said second loop in parallel with
A method according to any one of claims 1 to 3 , wherein each computing unit performs a respective iteration of said second loop .
複数の個別の計算ユニットと、
１つ以上のプロセッサとを備え、前記１つ以上のプロセッサは、
前記Ｎ次元テンソルの特定の次元のテンソル要素の数が、前記Ｎ次元テンソルの前記テンソル要素に基づいて計算を行うために使用されるコンピューティングシステムの個別の計算ユニットの数の正確な倍数でないと判断するように構成され、前記判断に応じて、
前記特定の次元のトラバースを行うために用いられる第２のループの反復回数を制御するための第１のループを生成し、
前記特定の次元の前記テンソル要素の数と、前記コンピューティングシステムの前記個別の計算ユニットの数とに基づいて、前記第２のループの第１のループ限界値と、前記第２のループの代替ループ限界値とを判断するように構成され、前記第２のループの前記反復回数が前記計算を行うために用いられるテンソル要素の数を超えないように、前記第１のループ限界値は、前記第１のループの１つ以上の最初の反復について前記第２のループの反復回数を制御し、前記代替ループ限界値は、前記第１のループの最後の反復について前記第２のループの前記反復回数を制御し、前記１つ以上のプロセッサはさらに、
前記第１のループ内にネストされた前記第２のループを有するコードを生成し、
前記Ｎ次元テンソルにアクセスするように前記コードを実行するように構成され、前記コードの実行は、
前記第１のループの１つ以上の最初の反復の各々について、前記第２のループの前記第１のループ限界値に達するまで、前記第１のループ内にネストされた前記第２のループの反復を行うことを含み、
前記第２のループの反復の各々について、複数の計算ユニットのうちの計算ユニットは、前記Ｎ次元テンソルのテンソル要素に基づいて計算を行い、各テンソル要素はデータ値を含み、前記コードの実行はさらに、
前記第１のループの最後から２番目の反復が終了した後で、前記第１のループ限界値よりも小さい前記代替ループ限界値に達するまで、前記第１のループの最後の反復について前記第２のループの１つ以上の反復を行い、
各計算の出力を示すデータを処理ユニットに出力するように構成されている、システム。 A system for performing computations based on tensor elements of an N-dimensional tensor, comprising:
a plurality of separate computing units;
and one or more processors, the one or more processors comprising:
unless the number of tensor elements of a particular dimension of said N-dimensional tensor is an exact multiple of the number of separate computational units of a computing system used to perform computations based on said tensor elements of said N-dimensional tensor; configured to determine , and in response to said determination,
creating a first loop for controlling the number of iterations of a second loop used to traverse the particular dimension;
a first loop bound for the second loop and an alternative for the second loop based on the number of tensor elements of the particular dimension and the number of distinct computational units of the computing system; wherein the first loop limit is configured to determine a loop limit such that the number of iterations of the second loop does not exceed the number of tensor elements used to perform the computation; controlling the number of iterations of said second loop for one or more first iterations of said first loop, said alternative loop limit being said iteration of said second loop for said last iteration of said first loop; controlling the number of times, the one or more processors further:
generating code having the second loop nested within the first loop;
configured to execute the code to access the N-dimensional tensor, execution of the code comprising:
nested within the first loop until the first loop limit of the second loop is reached for each of the one or more initial iterations of the first loop ; performing an iteration of said second loop with
For each iteration of the second loop, a computation unit of the plurality of computation units performs a computation based on tensor elements of the N-dimensional tensor, each tensor element comprising data values, and execution of the code comprises: moreover,
a final iteration of the first loop after the penultimate iteration of the first loop ends until reaching the alternate loop limit that is less than the first loop limit. performing one or more iterations of said second loop for
A system configured to output data indicative of the output of each computation to a processing unit .
各計算ユニットは、前記第２のループのそれぞれの反復を行う、請求項１０～１２のいずれか１項に記載のシステム。 performing iterations of the second loop nested within the first loop until the first loop limit of the second loop is reached using the computing unit; performing each iteration of said second loop in parallel with
A system according to any one of claims 10 to 12 , wherein each computing unit performs a respective iteration of said second loop .
前記プログラムは、前記コンピュータに、請求項１～９のいずれか１項に記載の方法を実行させる、プログラム。A program that causes the computer to execute the method according to any one of claims 1 to 9.
Applications Claiming Priority (4)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US15/627,022 | 2017-06-19 | ||
US15/627,022 US10248908B2 (en) | 2017-06-19 | 2017-06-19 | Alternative loop limits for accessing data in multi-dimensional tensors |
PCT/US2018/029796 WO2018236468A1 (en) | 2017-06-19 | 2018-04-27 | Alternative loop limits |
JP2019556242A JP7035080B2 (en) | 2017-06-19 | 2018-04-27 | Alternate loop limit |
Related Parent Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2019556242A Division JP7035080B2 (en) | 2017-06-19 | 2018-04-27 | Alternate loop limit |
Publications (2)
Publication Number | Publication Date |
---|---|
JP2022084674A JP2022084674A (en) | 2022-06-07 |
JP7279226B2 true JP7279226B2 (en) | 2023-05-22 |
Family
ID=62186548
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2019556242A Active JP7035080B2 (en) | 2017-06-19 | 2018-04-27 | Alternate loop limit |
JP2022031840A Active JP7279226B2 (en) | 2017-06-19 | 2022-03-02 | Alternate loop limit |
Family Applications Before (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2019556242A Active JP7035080B2 (en) | 2017-06-19 | 2018-04-27 | Alternate loop limit |
Country Status (7)
Country | Link |
---|---|
US (2) | US10248908B2 (en) |
EP (1) | EP3642708A1 (en) |
JP (2) | JP7035080B2 (en) |
KR (2) | KR102278661B1 (en) |
CN (2) | CN110520834B (en) |
TW (2) | TWI672594B (en) |
WO (1) | WO2018236468A1 (en) |
Families Citing this family (19)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11321092B1 (en) * | 2017-11-08 | 2022-05-03 | Habana Labs Ltd. | Tensor-based memory access |
US10936942B2 (en) * | 2017-11-21 | 2021-03-02 | Google Llc | Apparatus and mechanism for processing neural network tasks using a single chip package with multiple identical dies |
US10373291B1 (en) | 2018-01-31 | 2019-08-06 | Google Llc | Image transformation for machine learning |
CN109359732B (en) * | 2018-09-30 | 2020-06-09 | 阿里巴巴集团控股有限公司 | Chip and data processing method based on chip |
JP6832329B2 (en) * | 2018-12-18 | 2021-02-24 | 富士通株式会社 | data structure |
US11748599B2 (en) * | 2019-02-21 | 2023-09-05 | Texas Instruments Incorporated | Super-tiling in neural network processing to enable analytics at lower memory speed |
EP3825846A1 (en) * | 2019-04-04 | 2021-05-26 | Cambricon Technologies Corporation Limited | Data processing method and apparatus, and related product |
US11354564B2 (en) * | 2019-06-27 | 2022-06-07 | Intel Corporation | Tuning of loop orders in blocked dense basic linear algebra subroutines |
CN114270319A (en) * | 2019-10-07 | 2022-04-01 | 谷歌有限责任公司 | Reallocating tensor elements among machine learning computation units |
WO2021126203A1 (en) * | 2019-12-19 | 2021-06-24 | Google Llc | Processing sequential inputs using neural network accelerators |
US11275671B2 (en) | 2020-07-27 | 2022-03-15 | Huawei Technologies Co., Ltd. | Systems, methods and media for dynamically shaped tensors using liquid types |
US11954580B2 (en) | 2020-09-16 | 2024-04-09 | Meta Platforms, Inc. | Spatial tiling of compute arrays with shared control |
US11704562B1 (en) | 2020-11-04 | 2023-07-18 | Meta Platforms, Inc. | Architecture for virtual instructions |
US11709783B1 (en) | 2020-11-11 | 2023-07-25 | Meta Platforms, Inc. | Tensor data distribution using grid direct-memory access (DMA) controller |
US11972349B1 (en) * | 2020-11-12 | 2024-04-30 | Meta Platforms, Inc. | Flexible compute array utilization in a tensor processor |
US11922306B2 (en) | 2020-12-28 | 2024-03-05 | Meta Platforms, Inc. | Tensor controller architecture |
US11656854B2 (en) * | 2021-08-30 | 2023-05-23 | Huawei Technologies Co., Ltd. | Methods and devices for computing a memory size for software optimization |
US20230196081A1 (en) * | 2021-12-21 | 2023-06-22 | International Business Machines Corporation | Federated learning for training machine learning models |
CN115599442B (en) * | 2022-12-14 | 2023-03-10 | 成都登临科技有限公司 | AI chip, electronic equipment and tensor processing method |
Family Cites Families (32)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP3102027B2 (en) * | 1990-11-20 | 2000-10-23 | 日本電気株式会社 | Nesting management mechanism for loop control |
US5752037A (en) | 1996-04-26 | 1998-05-12 | Hewlett-Packard Company | Method of prefetching data for references with multiple stride directions |
US5958048A (en) * | 1996-08-07 | 1999-09-28 | Elbrus International Ltd. | Architectural support for software pipelining of nested loops |
US6374403B1 (en) | 1999-08-20 | 2002-04-16 | Hewlett-Packard Company | Programmatic method for reducing cost of control in parallel processes |
US6438747B1 (en) * | 1999-08-20 | 2002-08-20 | Hewlett-Packard Company | Programmatic iteration scheduling for parallel processors |
GB2359641B (en) * | 2000-02-25 | 2002-02-13 | Siroyan Ltd | Mapping circuitry and method |
US6952821B2 (en) * | 2002-08-19 | 2005-10-04 | Hewlett-Packard Development Company, L.P. | Method and system for memory management optimization |
US7107199B2 (en) * | 2002-10-31 | 2006-09-12 | Hewlett-Packard Development Company, L.P. | Method and system for the design of pipelines of processors |
US7047480B2 (en) * | 2002-11-12 | 2006-05-16 | Microsoft Corporation | Matrix multiplication in a Galois field for forward error correction |
US7225439B2 (en) * | 2003-03-21 | 2007-05-29 | Sun Microsystems, Inc. | Combining write-barriers within an inner loop with fixed step |
US7631305B2 (en) | 2003-09-19 | 2009-12-08 | University Of Delaware | Methods and products for processing loop nests |
WO2006079940A2 (en) * | 2005-01-25 | 2006-08-03 | Nxp B.V. | Multi-threaded processor |
US8806183B1 (en) * | 2006-02-01 | 2014-08-12 | Ixys Ch Gmbh | Blank bit and processor instructions employing the blank bit |
US8904155B2 (en) * | 2006-03-17 | 2014-12-02 | Qualcomm Incorporated | Representing loop branches in a branch history register with multiple bits |
US8438365B2 (en) * | 2006-10-06 | 2013-05-07 | Calos Fund Limited Liability Company | Efficient data loading in a data-parallel processor |
US20080141013A1 (en) | 2006-10-25 | 2008-06-12 | On Demand Microelectronics | Digital processor with control means for the execution of nested loops |
ATE463788T1 (en) * | 2007-06-26 | 2010-04-15 | Ericsson Telefon Ab L M | DATA PROCESSING UNIT FOR NESTED LOOP INSTRUCTIONS |
US8087012B2 (en) | 2007-08-21 | 2011-12-27 | International Business Machines Corporation | Eliminating maximum/minimum operations in loop bounds |
US8509162B2 (en) * | 2008-02-13 | 2013-08-13 | Qualcomm Incorporated | System and method for scheduling over multiple hops |
US20090327674A1 (en) * | 2008-06-27 | 2009-12-31 | Qualcomm Incorporated | Loop Control System and Method |
US20100122066A1 (en) * | 2008-11-12 | 2010-05-13 | Freescale Semiconductor, Inc. | Instruction method for facilitating efficient coding and instruction fetch of loop construct |
US20100274972A1 (en) * | 2008-11-24 | 2010-10-28 | Boris Babayan | Systems, methods, and apparatuses for parallel computing |
CA2684226A1 (en) * | 2009-10-30 | 2011-04-30 | Ibm Canada Limited - Ibm Canada Limitee | Eleminating redundant operations for common properties using shared real registers |
JP5402746B2 (en) | 2010-03-18 | 2014-01-29 | 富士通株式会社 | Optimization processing program, optimization processing apparatus, and optimization processing method |
US8683185B2 (en) * | 2010-07-26 | 2014-03-25 | International Business Machines Corporation | Ceasing parallel processing of first set of loops upon selectable number of monitored terminations and processing second set |
JP2012032986A (en) | 2010-07-30 | 2012-02-16 | Fujitsu Ltd | Compile method and program |
US20140181171A1 (en) * | 2012-12-24 | 2014-06-26 | Pavel Dourbal | Method and system for fast tensor-vector multiplication |
US20140188961A1 (en) * | 2012-12-27 | 2014-07-03 | Mikhail Plotnikov | Vectorization Of Collapsed Multi-Nested Loops |
CN103218347B (en) * | 2013-04-28 | 2016-01-20 | 清华大学 | Towards the multi-parameter fusion performance modelling method of reconfigurable arrays |
US8947447B1 (en) * | 2014-02-13 | 2015-02-03 | Raycast Systems, Inc. | Computer hardware architecture and data structures for ray binning to support incoherent ray traversal |
US9875104B2 (en) * | 2016-02-03 | 2018-01-23 | Google Llc | Accessing data in multi-dimensional tensors |
US10175980B2 (en) | 2016-10-27 | 2019-01-08 | Google Llc | Neural network compute tile |
-
2017
- 2017-06-19 US US15/627,022 patent/US10248908B2/en active Active
-
2018
- 2018-04-27 JP JP2019556242A patent/JP7035080B2/en active Active
- 2018-04-27 KR KR1020217016591A patent/KR102278661B1/en active IP Right Grant
- 2018-04-27 EP EP18725366.1A patent/EP3642708A1/en active Pending
- 2018-04-27 CN CN201880025248.XA patent/CN110520834B/en active Active
- 2018-04-27 KR KR1020197030429A patent/KR102261768B1/en active IP Right Grant
- 2018-04-27 WO PCT/US2018/029796 patent/WO2018236468A1/en active Search and Examination
- 2018-04-27 CN CN202310558267.1A patent/CN116663604A/en active Pending
- 2018-06-15 TW TW107120722A patent/TWI672594B/en active
- 2018-06-15 TW TW108130504A patent/TWI710974B/en active
-
2019
- 2019-03-08 US US16/297,091 patent/US10885434B2/en active Active
-
2022
- 2022-03-02 JP JP2022031840A patent/JP7279226B2/en active Active
Non-Patent Citations (3)
Title |
---|
エイホ Ａ．Ｖ．外３名，Ｉｎｆｏｒｍａｔｉｏｎ ＆ Ｃｏｍｐｕｔｉｎｇ ｅｘ．３８ コンパイラ［第２版］，第2版，株式会社サイエンス社，2009年05月25日，pp.833-843 |
椋木大地ほか，短尺浮動小数点形式の検討，情報処理学会研究報告 ハイパフォーマンスコンピューティング（ＨＰＣ），日本，情報処理学会，2015年12月09日，Vol.2015-HPC-152, No.4，１～１０ページ |
池辺将之ほか，動的再構成ハードウェアアーキテクチャを活かしたＣＮＮの実装と評価，電子情報通信学会技術研究報告，日本，一般社団法人電子情報通信学会，2017年05月15日，第１１７巻 第４６号，１～６ページ |
Also Published As
Publication number | Publication date |
---|---|
CN110520834A (en) | 2019-11-29 |
KR20210068155A (en) | 2021-06-08 |
US10248908B2 (en) | 2019-04-02 |
KR20190126887A (en) | 2019-11-12 |
KR102261768B1 (en) | 2021-06-07 |
JP2020524318A (en) | 2020-08-13 |
TW201947466A (en) | 2019-12-16 |
US20180365561A1 (en) | 2018-12-20 |
US20190205756A1 (en) | 2019-07-04 |
CN110520834B (en) | 2023-05-23 |
TW201905730A (en) | 2019-02-01 |
JP7035080B2 (en) | 2022-03-14 |
US10885434B2 (en) | 2021-01-05 |
EP3642708A1 (en) | 2020-04-29 |
KR102278661B1 (en) | 2021-07-16 |
JP2022084674A (en) | 2022-06-07 |
WO2018236468A1 (en) | 2018-12-27 |
CN116663604A (en) | 2023-08-29 |
TWI710974B (en) | 2020-11-21 |
TWI672594B (en) | 2019-09-21 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
JP7279226B2 (en) | Alternate loop limit | |
KR102243036B1 (en) | Data access of multidimensional tensor using adder | |
CN109324827B (en) | Apparatus, method and system for processing instructions for accessing data | |
JP7379581B2 (en) | Hardware double buffering using special purpose computational units | |
TWI740274B (en) | System, computer-implemented method, and apparatus for accessing data in multi-dimensional tensors using adders | |
US10373291B1 (en) | Image transformation for machine learning | |
CN111507456A (en) | Method and apparatus with convolutional neural network processing | |
GB2567038B (en) | Accessing prologue and epilogue data |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20220331 |
|
A621 | Written request for application examination |
Free format text: JAPANESE INTERMEDIATE CODE: A621Effective date: 20220331 |
|
A977 | Report on retrieval |
Free format text: JAPANESE INTERMEDIATE CODE: A971007Effective date: 20230308 |
|
TRDD | Decision of grant or rejection written | ||
A01 | Written decision to grant a patent or to grant a registration (utility model) |
Free format text: JAPANESE INTERMEDIATE CODE: A01Effective date: 20230411 |
|
A61 | First payment of annual fees (during grant procedure) |
Free format text: JAPANESE INTERMEDIATE CODE: A61Effective date: 20230510 |
|
R150 | Certificate of patent or registration of utility model |
Ref document number: 7279226Country of ref document: JPFree format text: JAPANESE INTERMEDIATE CODE: R150 |