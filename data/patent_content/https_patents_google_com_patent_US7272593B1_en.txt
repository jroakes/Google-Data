US7272593B1 - Method and apparatus for similarity retrieval from iterative refinement - Google Patents
Method and apparatus for similarity retrieval from iterative refinement Download PDFInfo
- Publication number
- US7272593B1 US7272593B1 US09/237,646 US23764699A US7272593B1 US 7272593 B1 US7272593 B1 US 7272593B1 US 23764699 A US23764699 A US 23764699A US 7272593 B1 US7272593 B1 US 7272593B1
- Authority
- US
- United States
- Prior art keywords
- database
- user
- query
- transformed
- searching
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Expired - Fee Related
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/30—Information retrieval; Database structures therefor; File system structures therefor of unstructured textual data
- G06F16/33—Querying
- G06F16/3331—Query processing
- G06F16/334—Query execution
- G06F16/3347—Query execution using vector based model
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/30—Information retrieval; Database structures therefor; File system structures therefor of unstructured textual data
- G06F16/33—Querying
- G06F16/332—Query formulation
- G06F16/3325—Reformulation based on results of preceding query
- G06F16/3326—Reformulation based on results of preceding query using relevance feedback from the user, e.g. relevance feedback on documents, documents sets, document terms or passages
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F18/00—Pattern recognition
- G06F18/20—Analysing
- G06F18/21—Design or setup of recognition systems or techniques; Extraction of features in feature space; Blind source separation
- G06F18/213—Feature extraction, e.g. by transforming the feature space; Summarisation; Mappings, e.g. subspace methods
- G06F18/2137—Feature extraction, e.g. by transforming the feature space; Summarisation; Mappings, e.g. subspace methods based on criteria of topology preservation, e.g. multidimensional scaling or self-organising maps
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F18/00—Pattern recognition
- G06F18/40—Software arrangements specially adapted for pattern recognition, e.g. user interfaces or toolboxes therefor
- G06F18/41—Interactive pattern learning with a human teacher
-
- Y—GENERAL TAGGING OF NEW TECHNOLOGICAL DEVELOPMENTS; GENERAL TAGGING OF CROSS-SECTIONAL TECHNOLOGIES SPANNING OVER SEVERAL SECTIONS OF THE IPC; TECHNICAL SUBJECTS COVERED BY FORMER USPC CROSS-REFERENCE ART COLLECTIONS [XRACs] AND DIGESTS
- Y10—TECHNICAL SUBJECTS COVERED BY FORMER USPC
- Y10S—TECHNICAL SUBJECTS COVERED BY FORMER USPC CROSS-REFERENCE ART COLLECTIONS [XRACs] AND DIGESTS
- Y10S707/00—Data processing: database and file management or data structures
- Y10S707/953—Organization of data
- Y10S707/957—Multidimensional
-
- Y—GENERAL TAGGING OF NEW TECHNOLOGICAL DEVELOPMENTS; GENERAL TAGGING OF CROSS-SECTIONAL TECHNOLOGIES SPANNING OVER SEVERAL SECTIONS OF THE IPC; TECHNICAL SUBJECTS COVERED BY FORMER USPC CROSS-REFERENCE ART COLLECTIONS [XRACs] AND DIGESTS
- Y10—TECHNICAL SUBJECTS COVERED BY FORMER USPC
- Y10S—TECHNICAL SUBJECTS COVERED BY FORMER USPC CROSS-REFERENCE ART COLLECTIONS [XRACs] AND DIGESTS
- Y10S707/00—Data processing: database and file management or data structures
- Y10S707/99931—Database or file accessing
- Y10S707/99933—Query processing, i.e. searching
-
- Y—GENERAL TAGGING OF NEW TECHNOLOGICAL DEVELOPMENTS; GENERAL TAGGING OF CROSS-SECTIONAL TECHNOLOGIES SPANNING OVER SEVERAL SECTIONS OF THE IPC; TECHNICAL SUBJECTS COVERED BY FORMER USPC CROSS-REFERENCE ART COLLECTIONS [XRACs] AND DIGESTS
- Y10—TECHNICAL SUBJECTS COVERED BY FORMER USPC
- Y10S—TECHNICAL SUBJECTS COVERED BY FORMER USPC CROSS-REFERENCE ART COLLECTIONS [XRACs] AND DIGESTS
- Y10S707/00—Data processing: database and file management or data structures
- Y10S707/99931—Database or file accessing
- Y10S707/99933—Query processing, i.e. searching
- Y10S707/99935—Query augmenting and refining, e.g. inexact access
-
- Y—GENERAL TAGGING OF NEW TECHNOLOGICAL DEVELOPMENTS; GENERAL TAGGING OF CROSS-SECTIONAL TECHNOLOGIES SPANNING OVER SEVERAL SECTIONS OF THE IPC; TECHNICAL SUBJECTS COVERED BY FORMER USPC CROSS-REFERENCE ART COLLECTIONS [XRACs] AND DIGESTS
- Y10—TECHNICAL SUBJECTS COVERED BY FORMER USPC
- Y10S—TECHNICAL SUBJECTS COVERED BY FORMER USPC CROSS-REFERENCE ART COLLECTIONS [XRACs] AND DIGESTS
- Y10S707/00—Data processing: database and file management or data structures
- Y10S707/99931—Database or file accessing
- Y10S707/99937—Sorting
-
- Y—GENERAL TAGGING OF NEW TECHNOLOGICAL DEVELOPMENTS; GENERAL TAGGING OF CROSS-SECTIONAL TECHNOLOGIES SPANNING OVER SEVERAL SECTIONS OF THE IPC; TECHNICAL SUBJECTS COVERED BY FORMER USPC CROSS-REFERENCE ART COLLECTIONS [XRACs] AND DIGESTS
- Y10—TECHNICAL SUBJECTS COVERED BY FORMER USPC
- Y10S—TECHNICAL SUBJECTS COVERED BY FORMER USPC CROSS-REFERENCE ART COLLECTIONS [XRACs] AND DIGESTS
- Y10S707/00—Data processing: database and file management or data structures
- Y10S707/99941—Database schema or data structure
- Y10S707/99944—Object-oriented database structure
- Y10S707/99945—Object-oriented database structure processing
Definitions
- the present invention relates generally to improved information retrieval systems for images and other nonstructure data. Particular aspects of the present invention are related to (1) adjusting the similarity measure for comparing the target and the objects in the information systems by taking advantage of user feedback, while (2) maintaining the efficiency of the retrieval system.
- Recent methods for retrieving images and videos by content from large archives utilize feature descriptors and feature comparison metrics in order to index the visual information.
- content-based retrieval systems include the IBM Query by Image Content (QBIC) system, detailed in “Query by image and video content: The ⁇ QBIC ⁇ system,” by M. Flickner, et al, “IEEE Computer”, 28(9):23-32, (September 1995); the Virage visual information retrieval system, detailed in “Virage image search engine: an open framework for image management,” by J. R.
- the feature comparison between the search target and those feature vectors stored in the database is typically based upon a simple fixed metric, such as the Euclidean distance or the quadratic distance (see: “Visualseek: A fully automated content-based image query system,” by J. R. Smith and S. F. Chang in the “Proc. International Conference on Image Processing” (1996). While these simple metrics may minimize the computational requirements for feature comparison, they typically do not correspond well to human perceptual distance nor do they have the capabilities to adapt to the changing environment commonly arising in various scientific applications. Specifically, it is desirable to provide a system and method that can accommodate the following diverse requirements:
- PicHunter Bayesian relevance feedback for image retrieval,” published in the “Proceeding of the International Conference on Pattern Recognition”, pages 361-369. ⁇ IEEE ⁇ , 1996 and in “An Optimized Interactive Strategy for Bayesian Relevance Feedback,” SPIE Photonics West, San Jose, 1998.
- PicHunter the history of user selection is used to construct system's estimate of the user's goal image.
- a Bayesian learning system based on a probabilistic model of the user behavior is combined with user selection to estimate the probability of each image in the database. Instead of revising the queries, PicHunter tries to refine the answers in reply to user feedback.
- Multidimensional indexing is fundamental to spatial databases, which are widely applicable to Geographic Information Systems (GIS), Online Analytical Processing (OLAP) for decision support using a large data warehouse, and multimedia databases where high-dimensional feature vectors are extracted from the image and video data.
- GIS Geographic Information Systems
- OLAP Online Analytical Processing
- Multidimensional indexes can be used to answer different types of queries, including:
- the database search program accesses part of the stored data and part of the indexing structure; with the amount of data accessed depending upon the type of query and upon the data provided by the user, as well as upon the efficiency of the indexing algorithm.
- large databases are configured such that the data and at least part of the indexing structure reside on the larger, slower and cheaper part of the memory hierarchy of the computer system, usually consisting of one or more hard disks.
- part of the data and part of the indexing structure are loaded in the faster parts of the memory hierarchy, such as the main memory and one or more levels of cache memory.
- the faster parts of the memory hierarchy are generally more expensive and thus comprise a smaller percentage of the storage capacity of the memory hierarchy
- a program that uses instructions and data that can be completely loaded into one or more levels of cache memory is faster and more efficient than a process that in addition uses instructions and data that reside in the main memory, which in turn is faster than a program that also uses instruction and data that reside on the hard disks.
- Technological limitations are such that the cost of cache and main memory makes it too expensive to build computer systems with enough main memory or cache to completely contain large databases.
- R-trees A Dynamic index structure for spatial searching
- A. Guttman ACM SIGMOD Conf. on Management of Data
- Boston, Mass. Boston, Mass.
- variable subset selection also called feature selection
- singular value decomposition followed by variable subset selection
- the present invention comprising an improved apparatus and method for revising feature vectors according to relevance feedback from the user, and for revising the searchable multidimensional indexes in databases.
- the present invention has features for flexibly generating the indexes and for efficiently performing exact, as well as nearest neighbor, searches.
- the present invention provides a mechanism for the user to dynamically adjust the similarity measure. The experimental results show that a significant improvement on the “precision versus recall” curve has been achieved.
- an algorithm enables the revision of feature and metric transformations based upon interaction with the user in the retrieval process.
- This algorithm is based upon nonlinear multidimensional scaling (MDS) that refines the feature space based upon the user's evaluation of the retrieval results.
- MDS nonlinear multidimensional scaling
- the linear transform of the features is modified by the user's feedback.
- a deepest gradient decent process is developed to enable fast convergence of the matrix, which makes the method suited to the interactive query environment. Since this method is also consistent with the method for building multidimensional index, the transformation of the feature space does not affect the indexing efficiency.
- An example of a method for generating indexes having features of the present invention includes the steps of: (1) initial retrieval of feature vectors that are “similar” to the specification of the user query; (2) user input specifying the quality of the returned results (in the simplest case, the user indicates whether a retrieved result is similar or not similar); (3) system revision of the query, the feature space, or both, so that the retrieved results are more in line with the user's expectation; and (4) iteration of steps (2) and (3) until the user is completely satisfied.
- this invention utilizes a method based on extensions of nonlinear multi-dimensional scaling.
- step (1) similarity searches are performed on a multidimensional index created in accordance with the foregoing method for generating and refining indexes.
- a similarity search can include the steps of: finding the cluster to which specified data (such as a user-provided example or a template record) belongs; searching the efficient searchable index generated for the reduced-dimensionality version of the cluster to which the specified data belongs; retrieving via the searchable index, the k most similar elements of the cluster, assessing if other clusters can contain elements that are closer to the specified data than the farthest of the k most similar elements retrieved; searching the closest such cluster to the specified data; and repeating the last two steps until no further cluster exists that can contain elements that are closer to the specified data than the farthest of the k most similar elements retrieved.
- FIG. 1 shows an example of a block diagram of a networked client/server system
- FIG. 2 shows the flowchart for the inventive similarity retrieval with relevance feedback
- FIG. 3 shows the flowchart for building high dimensional indices to facilitate retrieval of high-dimensional feature vectors
- FIG. 4 shows the flowchart for performing similarity search in the inventive cluster-based feature vector index
- FIG. 5 shows the flowchart for selecting N clusters from the collections of the feature vectors that represent the user relevance feedback
- FIG. 6 shows the flowchart for computing linear transformation W for adjusting the feature space in order to improve the precision of the retrieval
- FIG. 7 shows two examples of satellite images used in the benchmark
- FIG. 8 shows two more examples of satellite images used in the benchmark
- FIG. 9 shows comparison of precision versus recall for raw feature vector and feature vectors transformed by the inventive iterative refinement algorithm
- FIG. 10 shows the effect on the precision versus recall for different values of the parameter
- FIG. 11 shows the effect on the precision versus recall for different values of sample size
- FIG. 12 shows the effect on the precision versus recall for different number of clusters
- FIG. 13 shows the effect on the precision versus recall for different values of final dimensionality.
- FIG. 1 depicts an example of a client/server architecture having features of the present invention.
- multiple clients ( 101 ) and multiple servers ( 106 ) are interconnected by a network ( 102 ).
- the server ( 106 ) includes one or more conventional database management systems (DBMS) ( 104 ) and one or more direct access storage devices (DASD) ( 105 ).
- DBMS database management systems
- DASD direct access storage devices
- a query is typically prepared on the client ( 101 ) machine and submitted to the server ( 106 ) through the network ( 102 ).
- Such queries are usually based on similarity search (or nearest neighbor search) and are processed by the similarity query engine ( 103 ).
- the similarity query engine interacts with a database management system (DBMS) ( 104 ) for retrieving or updating a database stored in the DASD ( 105 ).
- DBMS database management system
- a database such as a spatial database, can reside on one or more systems, and that the multidimensional indexing engine ( 107 ) can be incorporated as part of the DBMS ( 104 ).
- the multidimensional indexing engine ( 107 ) is responsible for retrieving those vectors or records which satisfy the constraints specified by the query based on one or more compact multidimensional index files ( 108 ) generated in accordance with the present invention and preferably stored in the main memory and/or cache of the server ( 106 ).
- the database can store satellite images, medical images, seismic data, and time series.
- multimedia data such as audio, video and images can be stored separately from the metadata used for indexing.
- One key component of the metadata that can be used for facilitating the indexing and retrieval of the media data are feature vectors extracted from the raw data. For example, texture, color histogram and shape can be extracted from regions of the image and be used for constructing indices for retrieval.
- indexes can be generated by first creating a representation of the database to be indexed as a set of vectors, where each vector corresponds to a row in the database and the elements of each vector correspond to the values, for the particular row, contained in the columns for which an index must be generated.
- the representation can be created by, but is not limited to, the steps of creating for each row of the database an array of length equal to the dimensionality of the index to be generated; and copying to the elements of the array, the values contained in the columns, of the corresponding row, for which the index must be generated.
- an image database consists of a set of N feature vectors.
- Each feature vector has n dimensions.
- the feature vectors potentially represent a combination of, for example, color, texture and shape information.
- a query is started by presenting a query feature vector to the system.
- the feature vector may correspond to a particular query image, region or object.
- the K best matches are retrieved using a Euclidean metric.
- the most commonly used similarity measure between two vectors, u and v is the Euclidean distance measure, d, defined as
- the K results whose feature vectors are closest to the target feature vectors are then returned to the user for visual inspection or further processing.
- the similarity between the retrieved results and the target object does not necessarily correspond to the relative similarity perceived by the human being or required by the application. Consequently, at least one of the following actions need to be taken:
- N C (X, n Q ) of the n X matches N C (X, n Q ) ⁇ min ⁇ n Q , n X ⁇ min ⁇ n Q , n X ⁇ .
- N C (X, n Q ) N C (X, n Q ) ⁇ min ⁇ n Q , n X ⁇ min ⁇ n Q , n X ⁇ .
- E X [•] denote the expectation with respect to X:
- the goal of the iterative refinement process is to discover the best transformation such that the set of vectors in the desired class has minimum separation while the distance between those vectors in different classes is preserved or maximized.
- FIG. 2 shows the flowchart for the basic iterative refinement algorithm.
- the basic idea of iterative refinement is that the user selects L 1 of the K matches that are most similar to the desired match and reissues the query. Based upon this feedback, the linear or nonlinear transform matrix is modified to better approximate the user's evaluation of similarity. Then, a second set of matches is found and is returned to the user. The user selects the L 2 best matches and again reissues the query. This process is repeated until either the result set converges, or the user stops the process.
- X i X i ⁇ 1 ⁇ U i
- U i the set of feature vectors selected during step i.
- What the inventive iterative refinement algorithm provides is the following: simultaneous provision of adaptation of the query, similarity measure, feature space and relevance weighting based on the interactions between the user and retrieved results over one or more iterations; and accounting for the high-dimensional indices associated with the feature vector database so that the same indices can be applied regardless of the adaptation.
- the inventive algorithm is as follows:
- FIG. 3 depicts the process of generating the indices for retrieving feature vectors efficiently.
- Ser. No. 960,540 filed Oct. 31, 1997, entitled “Multidimensional Data Clustering and Dimension Reduction for Indexing and Searching” by C.-S. Li, et al
- the statistics of the feature vectors in the dataset are computed ( 301 ). These statistics include, for example, the mean and variance of each dimension in the feature vector, which could include up to m dimensions.
- Singular value decomposition ( 302 ) can then be applied to the feature vector.
- Singular value decomposition produces a transformation of the original feature space into a new feature space which has fewer dimensions while preserving the most prominent characteristics of the feature space.
- SVD generates a set of coordinate systems which aligns with the principle component axis of the original feature space.
- additional space saving can come from clustering of the feature space ( 303 ), as each of the clusters potentially requires much fewer dimensions.
- clustering techniques such as those described in the aforementioned application, can be applied here.
- additional steps of SVD can be applied to see whether dimension reduction is still feasible ( 305 ).
- a high-dimensional indexing representation such as R-tree can be used to facilitate the indexing of these dimensional reduced feature vectors within each sub-cluster ( 306 ) before concluding the algorithm ( 307 ).
- the target vector is compared with the centroid or prototype of the clusters, depending on the type of clustering algorithm used in 303 of FIG. 3 .
- one or more clusters are selected, at step ( 401 ), from the collection of clusters in terms of the similarity between the target vector and the centroid/prototype vectors of the clusters.
- the target vector will then go through the same dimension reduction process as the one used for generating the representation/indices of the multidimensional feature space ( 402 ).
- a total of N candidate vectors will be selected from these clusters ( 403 ). Note that these searches are based on the nearest neighbor principle.
- the candidates selected in the similarity retrieval always have the closest distance (or best similarity measure) to the target vector. Also note that the nearest neighbor will always retrieve candidate vectors based on the distance/similarity measure between these vectors and the target vector. As a result, either the feature space needs to be reconfigured or the similarity measure needs to be adapted according to the user feedback, and this process is usually referred to as learning (as depicted in step 203 of FIG. 2 ).
- the initial query usually consists of one or more examples with each example represented by its corresponding feature vector.
- the reformulated query can be computed from these examples and counterexamples by, for example, computing the centroid and the range (or the statistical distribution such as standard deviation).
- feature vectors from new examples and counterexamples can be added to the ensemble of the feature vectors with different weights:
- the matrix Q allows the weighting of different features. A feature is assigned more weight if the feature is more discriminating than the others. Discriminating features can be determined form examples and counterexamples as described above.
- the examples and counterexamples can be used to derive the optimal p by minimizing the distance within the same examples set (or counterexample set), and maximizing the distance between the examples set and the counterexample set.
- the matrix L is determined by a set of examples and counterexamples. Note that linear feature space warping is equivalent to feature weighting or similar measure selection. What is proposed in nonlinear feature space warping. Since linear feature space warping is a special case of nonlinear feature space warping, all of the discussion below will also apply to linear feature space warping.
- the warping algorithm is based on the nonlinear multidimensional scaling method proposed by Web (A. R. Webb, “Multidimensional scaling by iterative majorization using radial basis functions,” published in “Pattern Recognition,” 28:753-759, 1995).
- J se is a class separability criterion
- J sp is a structure preserving criterion
- W is an 1 ⁇ m matrix
- ⁇ ⁇ ( x ) exp ( - ⁇ ⁇ x - c i ⁇ 2 h 2 ) ( 4 )
- the parameter h 2 is a bandwidth term where larger value gives rise to a smaller bandwidth.
- the vectors c i can be obtained from applying clustering algorithms such as K-means, Kohonen self-organization map or Tree-Structured Vector Quantizer (TSVQ) to generate l clusters from the dataset.
- TSVQ Tree-Structured Vector Quantizer
- J se ⁇ i ⁇ j ⁇ ( ⁇ i , ⁇ j ) a ij q ij 2 (5)
- ⁇ i and ⁇ j are the class labels of vector x i and x j
- q ij
- ⁇ ( ⁇ i , ⁇ j ) is defined as below:
- a ij 's are positive weights, defined as
- d ij 1 / d ij ⁇ ( X ) ⁇ i ⁇ ⁇ j ⁇ 1 / d ij ⁇ ( X ) ( 8 )
- c ij ⁇ ( V ) a ij ⁇ d ij ⁇ ( X ) / q ij ⁇ ( V ) ( i , j ) ⁇ S + 0 ( i , j ) ⁇ S 0 ( 14 )
- S + correspond to a set consisting of (i,j)'s which result in a q ij (V) greater than zero.
- J The minimization of J will minimize the intraclass distance in the transformed space, while preserving the structure of the feature vectors.
- the structure of an individual feature vector can be replaced by the structure of an individual cluster.
- FIG. 5 The process of preparing the learning process based on the learning algorithm that has been described previously is depicted in FIG. 5 .
- a subset of the feature vectors from the original feature space is selected ( 501 ). In principle, the entire set of feature vectors can be selected. However, a uniform sampling of the feature space can be adequate in many cases and may dramatically improve the speed of the subsequent clustering step.
- the centroids (c i in Eq. (4)) are then extracted by using one of the clustering algorithm mentioned above ( 502 ). In the experimental verification described below, Tree-structured Vector Quantization (TSVQ) is assumed due to its relative efficiency and accuracy as compared to other algorithms. If necessary, those matrices that are modified by the learning process can be precomputed ( 503 ).
- TSVQ Tree-structured Vector Quantization
- each new learning iteration involves the selection of at least one new set of feature vectors that are considered relevant (referred to as X i in the iterative refinement algorithm) and a set of feature vectors that are considered irrelevant (referred to as Y i in the iterative refinement algorithm).
- SVD Single Value Decomposition
- index preparation ( 303 ) and learning preparation ( 503 ) involve the clustering of the feature space. In principle, these steps can be done at the same time, and consequently share identical clustering structure. Therefore, a similarity retrieval in the transformed feature space (where the transformation is computed from the learning process) involves the computation of
- the feature vector used in these experiments has 21 dimensions, consisting of spatial texture features such as fractal dimension, coocurrence-based texture features, spatial gray level difference-based texture features, coarseness, skew, dispersion, and Moran circular correlation.
- the feature database is generated as follows: 32 random cuts of size 32 ⁇ 32 are generated from each of the 37 satellite images, each of which consist of homogeneous image regions. A 21-dimensional texture feature is then extracted from each random cut, resulting in a database consisting of a total of 1184 feature vectors. For each query, one of the random cuts from an image is used to retrieve the K most similar random cuts.
- the retrieved result is considered to be a hit if the retrieved random cut belongs to the same image as the original random cut.
- the precision and recall values given in this section are all average values, using the precision and recall equations defined earlier.
- FIGS. 7 and 8 show examples of mountain, woods, forests, and suburban areas used in the 37 benchmark images.
- the first K (K varies from 64 to 256) feature vectors are retrieved as samples and assigned class labels. Note that only two feature classes will be covered if K is equal to 64.
- the iterative refinement algorithm outlined in the previous section is then applied to the retrieved feature vectors together with its feature class.
- the resulting W is applied in conjunction with the radial basis function defined in the previous section to transform all the feature vectors in the database.
- a nearest neighbor search is then applied to determine the resulting precision and recall values.
- FIG. 9 shows the precision versus recall for a given benchmark image before and after the iterative refinement algorithm is applied.
- the sample size is selected to be 256
- the number of radial basis functions is chosen to be 20 (thus requiring the clustering function TSVQ to generate 20 clusters from 256 vectors)
- the final feature vector space has 10 dimensions.
- the parameter h in Eq.(4) is set at 3.16 throughout the experiment. It is quite apparent that iterative refinement algorithm produced a significant improvement on the precision for a given recall, and vice versa. The improvement is greater for larger recall (or smaller precision).
- ⁇ is varied from 0.2 to 0.8. Smaller ⁇ implies less emphasis on J sp and more emphasis on J se , resulting in better class separability (See Eq. (10)). This is evident from FIG. 10 , as lower ⁇ results in a better precision versus recall curve.
- FIG. 11 shows that the precision versus recall performance dramatically deteriorates as the sample size is reduced from 256 to 64. Sampling techniques of the space can be applied and may produce a better training set for the iterative refinement algorithm.
- the additional bonus of using the nonlinear multi-dimensional scaling technique is the reduction of dimensionality. As shown in FIG. 13 , the number of dimensions that are required for clean separation between the desirable and undesirable results is less than 5. Consequently, the precision versus recall curves are space fairly closely with respect to each other when the final number of dimensions is varied from 5 to 15.
Abstract
Description
-
- Retrieving Synthetic Aperture Radar (SAR) Satellite images and identifying regions in the images with texture (e.g., ice) type similar to the search target;
- Retrieving one-meter resolution satellite images and identifying regions in the images with spectral features (e.g., crop type) similar to the search target;
- Retrieving LANDSAT Thematic Mapper™ satellite images and identifying regions in the images with a combination of spectral and texture features (e.g., indicative of similar terrain type) which are similar to the search target.
The foregoing feature comparisons may be implemented for the following applications: - Environmental epidemiology: wherein the system seeks to retrieve locations of houses which are vulnerable to epidemic diseases such as Hantavirus and Denge fever based on a combination of environmental factors (e.g. isolated houses that are near bushes or wetlands), and weather patterns (e.g. a wet summer followed by a dry summer);
- Precision farming: wherein it is desirable to (1) retrieve locations of crop developments that are exposed to diseases, (for example: clubroot, which is a soil-borne disease that infects cauliflower crop). Cauliflower and clubroot have recognized spectral signatures, and exposure results from their spatial and temporal proximity; (2) retrieve those fields which have abnormal irrigation; or, (3) retrieve those regions which have higher than normal soil temperature;
- Precision forestry: wherein the system may seek to (1) calculate areas of forests that have been damaged by hurricane, forest fire, or storms, and (2) estimate the amount of the yield of a particular forest;
- Petroleum exploration: to retrieve those regions which exemplify specific characteristics in the collection of seismic data, core images, and other sensory data;
- Insurance: for which a system may be called upon to (1) retrieve those regions which may require immediate attention due to natural disasters such as earthquake, forest fire, hurricane, and tornadoes; or (2) retrieve those regions have higher than normal claim rate (or amount) that are correlated to the geography—close to coastal regions, close to mountains, in high crime rate regions, etc.;
- Medical image diagnosis: for retrieval of all MRI images of brains that have tumors located within the hypothalamus, where such tumors are characterized by shape and texture, and the hypothalamus is characterized by shape and spatial location within the brain;
- Real estate marketing: wherein the system may be required to retrieve all houses that are near a lake (color and texture), have a wooded yard (texture) and are within 100 miles of skiing (mountains are also given by texture); and
- Interior design: for use in retrieving all images of patterned carpets which consist of a specific spatial arrangement of color and texture primitives.
-
- finding record(s) with specified values of the indexed columns (exact search);
- finding record(s) that are within [a1 . . . a2], [b1 . . . b2], . . . , [z1 . . . z2] where a, b and z represent different dimensions (range search); and
- finding the k most similar records to a user-specified template or example (k-nearest neighbor search).
where u=[u1, . . . un]T and v=[v1, . . . ,vn]T.
-
- Query reformulation: Content-based retrieval systems can use image clip to find “all images with features similar to the clip”. In this case, the features extracted from the example will be used as the initial query. The reformulated query could contain a feature vector which is derived from a set of examples and counterexamples provided by the user. Note that different iterations of the user feedback may have different weights in calculating the “composite queries”;
- Feature relevance weighting: The relevance of each individual feature can be derived from the examples, counterexamples, and user interactions with the system. One possible way of producing the weight is to examine the distribution of each feature in the examples and counterexamples. If the distribution is small, with respect to the overall distribution, then the feature is potentially relevant. On the other hand, if the distribution is large asc compared to the overall distribution, then the feature is probably not going to be discriminating for the particular example;
- Feature space warping: This approach performs either linear or nonlinear transformation of the feature space so that Euclidean distance in the resulting feature space corresponds more closely with the relative similarity perceived by the human being or required by the applications. In the linear transformation case, the Euclidean distance between the vectors in the warped feature space is ∥M(u−v)∥, where M is the linear transformation; and
- Generalized distance metric: This approach utilizes a similarity measure such as the quadratic form d(u, v)=(u−v)TQ(u−v) where u and v have been defined earlier. Note that the this metric can be formulated as a special case for the metric d(u,v)=∥M(u−v)∥ of feature space warping, providing that the matrix Q can be decomposed into MTM.
-
- Precision, RE: This is the proportion of the retrieved results that are relevant. For each template X, define RE(X, nQ)=NC(X, nQ)/nQ. Then,
- RE(nQ)=EX[RE(X, nQ)]=EX[NC(X, nQ)/nQ]
- Recall, RA: This is the proportion of the relevant results that are retrieved. For each template X let RA (X, n)=NC(X, n)/min {nX, n} be the proportion of correct results in a retrieved set of size n. Then, RA(nQ)=EX[RA(X, nQ)]=EX[nC(X nQ)/min{nX, nQ}
- Precision, RE: This is the proportion of the retrieved results that are relevant. For each template X, define RE(X, nQ)=NC(X, nQ)/nQ. Then,
-
- 1. Step 201: Performing similarity search on a feature vector, v, retrieving the K most similar results in the feature space. The similarity between v and u is measured by
Eq 1. Set i=1; - 2. Step 202: Initialize X1 and U1 to those vectors which are considered to be similar. Also initialize Y1 and V1 to those vectors that are not considered to be similar. If the number of vectors is less than a prescribed threshold, set K=K+Kinc, where Kinc is a fixed increment, return to
step 1; - 3. Step 203: Perform query reformulation and learning (both of which will be described in detail later) based on two classes of vectors: Xi and Yi where Xi includes all the vectors that are considered similar (or relevant), while Yi include all the vectors that are considered to be not similar (or irrelevant). Consequently, the class label for Xi is 1, while the class label for Yi is 2. The result of the learning will yield a transformation of the feature space, revised similarity metric, and relevance weighting of the features. The feature indices built based on the feature space before the transformation can still be used for the similarity retrievals in the next step;
- 4. Step 204: Perform similarity search in the transformed feature space using the revised query based on the revised similarity measure and revised relevance weighting for the features. The results are categorized to similar (or relevant) and dissimilar (or irrelevant). Assuming that Ui and Vi are the sets that include those similar and dissimilar vectors, respectively.
- 5. Step 205: Update Xi and Yi as follows Xi=Xi−1∪Ui, Yi=Yi−1∪U Vi.
- 6. Step 206: If the difference between Xi and Xi-1 is less than a prescribed threshold, a equilibrium has been reached and exit.
- 7. Step 207: If the difference between Xi and Xi-1 is greater than a prescribed threshold, the process is repeated for Seti=i+1 (return to step 3).
- 1. Step 201: Performing similarity search on a feature vector, v, retrieving the K most similar results in the feature space. The similarity between v and u is measured by
y i =W*φ(x i) (2)
J=(1−λ)J se +λJ sp (3)
is minimized. In Eq. (3), Jse is a class separability criterion, and Jsp is a structure preserving criterion, where W is an 1×m matrix, and φ(xi) is a radial basis function where the ith component (i=1, . . . ,1) is defined as
The parameter h2 is a bandwidth term where larger value gives rise to a smaller bandwidth. The vectors ci can be obtained from applying clustering algorithms such as K-means, Kohonen self-organization map or Tree-Structured Vector Quantizer (TSVQ) to generate l clusters from the dataset.
J se=ΣiΣjε(ωi, ωj)a ij q ij 2 (5)
where ωi and ωj are the class labels of vector xi and xj, and
q ij=|η(x i)−η(x j)|=|W*(φ(x i)−φ(x j) (6)
The function δ(ωi, ωj) is defined as below:
aij's are positive weights, defined as
where dij(X) is the Euclidean distance between xi and xj and can be defined as
d ij(X)=|x i −x j| (9)
J spΣiΣj a ij(q ij −d ij(X))2 (10)
It has been shown in Webb that the optimal solution W to Eq. (3) is the solution to the following equation:
AW=D(V)V (1)
A=Σ iΣj a ij[(1−λ)δ(ωi,ωj)+λ](φi−φj)(φi−φj)* (12)
D(V)=ΣiΣj C ij(V)(φi−φj)(φi−φj)* (13)
Note that S+ correspond to a set consisting of (i,j)'s which result in a qij(V) greater than zero. On the other hand, S0 correspond to the set which contains all the (i,j)'s that result in qij(V)=0.
|y 2 −y 1 |=|W*(φ(x 2)−φ(x 1)|
On the other hand, indices have been prepared for the vectors, xi, that belongs to the i-th cluster:
z i =V*(φ(x i)).
where φ and V are determined using the same methodology outline above. According to the multidimensional indexing structure and the learning process, there exist four possible strategies for sharing the index construction process and learning preparation process:
-
- Single-level multidimensional index structure with no additional dimension reduction in the learning: In this case, it is assumed that the multidimensional index is constructed after the original feature space has gone through the transformation V*φ(x). The vector points in the transformed feature space are denoted as zi, which is supposed to have fewer dimensions than the original feature space occupied by xi. The similarity retrieval of those nearest neighbors to a vector in the feature space that has been adjusted through the learning algorithm described above is reduced to the computation of those yi's where yi is close to the target yc. In other words, it is necessary to select those yi's such that the distance between these vectors and the target vector is smaller than that for any other candidates that are not selected. This can be formulated as follows:
- |yi−yc|=|UV*(φ(xi)−φ(xc)|=|U(zi−zc)| where U is a square matrix derived from the relevance feedback process. When U is invertible (and thus U−1 is nonsingular), it is possible to formulate similarity searches simply by using z=U−1y as the search target into the multidimensional indices built based on V*φ(x). The additional overhead for doing similarity search using the new similarity measure is the computation of z=U−1y.
- Single-level multidimensional index structure with additional dimension reduction in the learning: In this case, it is assumed that the multidimensional index is constructed after the original feature space has gone through the transformation V*φ(x). The vector points in the transformed feature space are denoted as zi, which is supposed to have fewer dimensions than the original feature space occupied by xi. The learning process may reduce the dimension further. These situations may arise due to the fact that a particular application may only need a subset of the original features. The similarity retrieval of those nearest neighbors to a vector in the feature space that has been adjusted through the learning algorithm described above is to compute those yi's where yi is close to the target yc. In other words, it is necessary to select those yi 's such that the distance between these vectors and the target vector is smaller than that for any other candidates that are not selected. This can be formulated as follows:
- |yi−yc|=|UV*(φ(xi)−φ(xc)|=|U(zi−zc)| where U is a rectangular matrix derived from the relevance feedback process. Note that the matrix U is no longer invertible. Under such circumstance, the matrix U is first zero filled to have the same rank (or column dimensions) as the matrix V*. The singular value decomposition technique can be applied to decompose the matrix U into SΓT, where the diagonal elements of the matrix Γ contains the singular values of the matrix U. Those singular values that are equal to zero are then replaced with a small but finite value ε. The resulting matrix SΓ′T is then fully invertible, and the same technique can be applied as in the previous case to perform similarity search into indices built upon V*φ(x).
- Multi-level multidimensional indexing structure without additional dimension reduction due to learning: In this case, an algorithm such as RCSVD algorithm (as proposed in the aforementioned patent application) can be used. In the following discussion, it is assumed that the resulting structure is divided into three levels (the general case where there are a total of n levels can be easily extended). If the resulting structure is divided into three levels, the high dimensional index for the ijk-th subcluster (meaning this subcluster belongs to the i-th cluster at the 1st level, j-th subcluster at the 2nd level, and k-th subsubcluster at the third level) is computed based on Vk*Vj*Vi*φ(x), where the transformation matrix Vi* is computed from the i-th cluster at
level 1, and Vj* is computed from the j-th cluster at level 2, and Vk* is computed from the k-th cluster is computed from the k-th cluster at level 3. A vector in the subcluster is denoted as zi=Vk*Vj*Vi*φ(x). Under such circumstance, it is possible to confine the learning phase to UkVk*Vj*Vi*φ(x), where the matrices Ui is a square matrix. Consequently, a similarity retrieval in the new feature space (which has been transformed by UkVk*Vj*Vi*φ(x)) can be translated into the computation of Uk −1zi. - Multi-level multidimensional indexing structure with additional dimension reduction due to learning: In this case, an algorithm such as RCSVD algorithm (as proposed in the aforementioned patent application) can be used. In the following discussion, it is assumed that the resulting structure is divided into three levels (the general case where there are a total of n levels can be easily extended). If the resulting structure is divided into three levels, the high dimensional index for the ijk-th subcluster (meaning this subcluster belongs to the i-th cluster at the 1st level, j-th subcluster at the 2nd level, and k-th subsubcluster at the third level) is computed based on Vk*Vj*Vi*φ(x), where the transformation matrix Vi* is computed from the i-th cluster at
level 1, and Vj* is computed from the j-th cluster at level 2, and Vk* is computed from the k-th cluster is computed from the k-th cluster at level 3. A vector in the subcluster is denoted as zi=Vk*Vj*Vi*φ(x). Under such circumstances, it is possible to confine the learning phase to UkVk*Vj*Vi*φ(x), where the matrices Ui is a rectangular matrix. Note that the matrix U is no longer invertible. Under such circumstance, the matrix Ui is first zero filled to have the same rank (or column dimensions) as the matrix V*. The singular value decomposition technique can be applied to decompose the matrix Ui into SΓT where the diagonal elements of the matrix Γ contains the singular values of the matrix Ui. Those singular values that are equal to zero are then replaced with a small but finite value ε. The resulting matrix SΓ′T is then fully invertible, and the same technique can then be applied as for the previous case to perform similarity search into indices built upon V*φ(x).
- Single-level multidimensional index structure with no additional dimension reduction in the learning: In this case, it is assumed that the multidimensional index is constructed after the original feature space has gone through the transformation V*φ(x). The vector points in the transformed feature space are denoted as zi, which is supposed to have fewer dimensions than the original feature space occupied by xi. The similarity retrieval of those nearest neighbors to a vector in the feature space that has been adjusted through the learning algorithm described above is reduced to the computation of those yi's where yi is close to the target yc. In other words, it is necessary to select those yi's such that the distance between these vectors and the target vector is smaller than that for any other candidates that are not selected. This can be formulated as follows:
Claims (5)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US09/237,646 US7272593B1 (en) | 1999-01-26 | 1999-01-26 | Method and apparatus for similarity retrieval from iterative refinement |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US09/237,646 US7272593B1 (en) | 1999-01-26 | 1999-01-26 | Method and apparatus for similarity retrieval from iterative refinement |
Publications (1)
Publication Number | Publication Date |
---|---|
US7272593B1 true US7272593B1 (en) | 2007-09-18 |
Family
ID=38481881
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US09/237,646 Expired - Fee Related US7272593B1 (en) | 1999-01-26 | 1999-01-26 | Method and apparatus for similarity retrieval from iterative refinement |
Country Status (1)
Country | Link |
---|---|
US (1) | US7272593B1 (en) |
Cited By (43)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20050097435A1 (en) * | 2003-11-03 | 2005-05-05 | Prakash Vipul V. | Methods and apparatuses for classifying electronic documents |
US20050120105A1 (en) * | 2003-12-01 | 2005-06-02 | Popescu George V. | Method and apparatus to support application and network awareness of collaborative applications using multi-attribute clustering |
US20050149546A1 (en) * | 2003-11-03 | 2005-07-07 | Prakash Vipul V. | Methods and apparatuses for determining and designating classifications of electronic documents |
US20060122999A1 (en) * | 2004-12-06 | 2006-06-08 | Samsung Electronics Co., Ltd. | Apparatus for and method of producing graphics contents and computer-readable recording medium storing computer program for executing the method |
US20070092142A1 (en) * | 2005-10-25 | 2007-04-26 | General Electric Company | Automatic significant image generation based on image characteristics |
US20070299865A1 (en) * | 2006-06-27 | 2007-12-27 | Nahava Inc. | Method and Apparatus for fast similarity-based query, self-join, and join for massive, high-dimension datasets |
US20080037876A1 (en) * | 1999-08-09 | 2008-02-14 | Michael Galperin | Object based image retrieval |
US20080071776A1 (en) * | 2006-09-14 | 2008-03-20 | Samsung Electronics Co., Ltd. | Information retrieval method in mobile environment and clustering method and information retrieval system using personal search history |
US20080082563A1 (en) * | 2002-10-18 | 2008-04-03 | Patrick Arras | Online analytical processing (olap) |
US20090048842A1 (en) * | 2007-04-30 | 2009-02-19 | K-Nfb Reading Technology, Inc. | Generalized Object Recognition for Portable Reading Machine |
US20090094197A1 (en) * | 2007-10-04 | 2009-04-09 | Fein Gene S | Method and Apparatus for Integrated Cross Platform Multimedia Broadband Search and Selection User Interface Communication |
DE102007060478A1 (en) * | 2007-12-14 | 2009-06-18 | Adc Automotive Distance Control Systems Gmbh | Method for the cost-optimized determination of clusters in sensor data by means of an embedded system |
WO2009083841A1 (en) * | 2007-12-27 | 2009-07-09 | Koninklijke Philips Electronics, N.V. | Method and apparatus for refining similar case search |
US20090292732A1 (en) * | 2008-05-26 | 2009-11-26 | Microsoft Corporation | Similarity-based content sampling and relevance feedback |
US20100008541A1 (en) * | 2008-07-08 | 2010-01-14 | Forlines Clifton L | Method for Presenting Images to Identify Target Objects |
US20100049431A1 (en) * | 2008-04-30 | 2010-02-25 | Rafael Maya Zetune | Navigation Using Portable Reading Machine |
US20100082611A1 (en) * | 2008-09-23 | 2010-04-01 | Yahoo! Inc. | Trajectory Data Surfacing System: Surfacing Useful and Relevant Entity Annotations |
US20100125601A1 (en) * | 2001-04-04 | 2010-05-20 | Peter Jackson | System, method, and software for identifying historically related legal cases |
US20100318523A1 (en) * | 1999-02-01 | 2010-12-16 | Lg Electronics Inc. | Method of searching multimedia data |
GB2477829A (en) * | 2010-02-16 | 2011-08-17 | Honeywell Int Inc | Distance-space embedding for multi-descriptor matching and retrieval of the track segments in a video archive |
US20110231350A1 (en) * | 2008-11-26 | 2011-09-22 | Michinari Momma | Active metric learning device, active metric learning method, and active metric learning program |
US20120173559A1 (en) * | 2009-09-11 | 2012-07-05 | Someones Group Intellectual Property Holdings Pty Ltd. | Database searching method, system and controller |
US20130066592A1 (en) * | 2009-10-23 | 2013-03-14 | Commissariat A L'energie Atomique Et Aux Energies Alternatives | Method and system for evaluating the resemblance of a query object to reference objects |
US20130179439A1 (en) * | 2001-05-16 | 2013-07-11 | Pandora Media, Inc. | Methods and Systems for Utilizing Contextual Feedback to Generate and Modify Playlists |
US20130238346A1 (en) * | 2010-11-26 | 2013-09-12 | Nokia Corporation | Low complexity target vector identification |
US20130268547A1 (en) * | 2010-12-16 | 2013-10-10 | Koninklijke Philips N.V. | System and method for clinical decision support for therapy planning using case-based reasoning |
US20140046914A1 (en) * | 2008-11-19 | 2014-02-13 | Intellectual Ventures Fund 83 Llc | Method for event-based semantic classification |
US8655862B1 (en) * | 2007-10-17 | 2014-02-18 | Google Inc. | System and method for query re-issue in search engines |
US20140365463A1 (en) * | 2013-06-05 | 2014-12-11 | Digitalglobe, Inc. | Modular image mining and search |
US9082086B2 (en) | 2011-05-20 | 2015-07-14 | Microsoft Corporation | Adaptively learning a similarity model |
GB2534535A (en) * | 2014-10-08 | 2016-08-03 | Lancaster Univ Business Entpr Ltd | Data structuring and searching methods and apparatus |
US20160371274A1 (en) * | 2015-06-18 | 2016-12-22 | Nbcuniversal Media Llc | Recommendation system using a transformed similarity matrix |
US9535928B2 (en) | 2013-03-15 | 2017-01-03 | Sony Corporation | Combining information of different levels for content-based retrieval of digital pathology images |
US20170193647A1 (en) * | 2015-12-31 | 2017-07-06 | General Electric Company | System and method for seismic data interpretation |
WO2018014109A1 (en) * | 2016-07-22 | 2018-01-25 | 9206868 Canada Inc. | System and method for analyzing and searching for features associated with objects |
US10002430B1 (en) | 2013-06-04 | 2018-06-19 | Hrl Laboratories, Llc | Training system for infield training of a vision-based object detector |
US10191990B2 (en) | 2016-11-21 | 2019-01-29 | Comcast Cable Communications, Llc | Content recommendation system with weighted metadata annotations |
CN111080080A (en) * | 2019-11-25 | 2020-04-28 | 桂林理工大学南宁分校 | Method and system for estimating risk of geological disaster of villages and small towns |
US10872388B2 (en) * | 2006-07-25 | 2020-12-22 | Northrop Grumman Systems Corporation | Global disease surveillance platform, and corresponding system and method |
US11100145B2 (en) | 2019-09-11 | 2021-08-24 | International Business Machines Corporation | Dialog-based image retrieval with contextual information |
WO2021205080A1 (en) | 2020-04-11 | 2021-10-14 | IPRally Technologies Oy | System and method for performing a search in a vector space based search engine |
US11403327B2 (en) * | 2019-02-20 | 2022-08-02 | International Business Machines Corporation | Mixed initiative feature engineering |
US11882344B2 (en) | 2016-03-03 | 2024-01-23 | Comcast Cable Communications, Llc | Determining points of interest in a content item |
Citations (18)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5493677A (en) * | 1994-06-08 | 1996-02-20 | Systems Research & Applications Corporation | Generation, archiving, and retrieval of digital images with evoked suggestion-set captions and natural language interface |
US5692181A (en) * | 1995-10-12 | 1997-11-25 | Ncr Corporation | System and method for generating reports from a computer database |
US5734893A (en) * | 1995-09-28 | 1998-03-31 | Ibm Corporation | Progressive content-based retrieval of image and video with adaptive and iterative refinement |
US5781906A (en) * | 1996-06-06 | 1998-07-14 | International Business Machines Corporation | System and method for construction of a data structure for indexing multidimensional objects |
US5809297A (en) * | 1993-10-29 | 1998-09-15 | Wall Data Incorporated | Semantic object modeling system for creating relational database schemas |
US5832182A (en) * | 1996-04-24 | 1998-11-03 | Wisconsin Alumni Research Foundation | Method and system for data clustering for very large databases |
US5845278A (en) * | 1997-09-12 | 1998-12-01 | Inioseek Corporation | Method for automatically selecting collections to search in full text searches |
US5852823A (en) * | 1996-10-16 | 1998-12-22 | Microsoft | Image classification and retrieval system using a query-by-example paradigm |
US5963940A (en) * | 1995-08-16 | 1999-10-05 | Syracuse University | Natural language information retrieval system and method |
US5970499A (en) * | 1997-04-11 | 1999-10-19 | Smith; Kurt R. | Method and apparatus for producing and accessing composite data |
US5983237A (en) * | 1996-03-29 | 1999-11-09 | Virage, Inc. | Visual dictionary |
US5987446A (en) * | 1996-11-12 | 1999-11-16 | U.S. West, Inc. | Searching large collections of text using multiple search engines concurrently |
US6026388A (en) * | 1995-08-16 | 2000-02-15 | Textwise, Llc | User interface and other enhancements for natural language information retrieval system and method |
US6084595A (en) * | 1998-02-24 | 2000-07-04 | Virage, Inc. | Indexing method for image search engine |
US6134541A (en) * | 1997-10-31 | 2000-10-17 | International Business Machines Corporation | Searching multidimensional indexes using associated clustering and dimension reduction information |
US6175829B1 (en) * | 1998-04-22 | 2001-01-16 | Nec Usa, Inc. | Method and apparatus for facilitating query reformulation |
US6233578B1 (en) * | 1996-09-11 | 2001-05-15 | Nippon Telegraph And Telephone Corporation | Method and system for information retrieval |
US6298342B1 (en) * | 1998-03-16 | 2001-10-02 | Microsoft Corporation | Electronic database operations for perspective transformations on relational tables using pivot and unpivot columns |
-
1999
- 1999-01-26 US US09/237,646 patent/US7272593B1/en not_active Expired - Fee Related
Patent Citations (19)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5809297A (en) * | 1993-10-29 | 1998-09-15 | Wall Data Incorporated | Semantic object modeling system for creating relational database schemas |
US5893101A (en) * | 1994-06-08 | 1999-04-06 | Systems Research & Applications Corporation | Protection of an electronically stored image in a first color space by the alteration of digital component in a second color space |
US5493677A (en) * | 1994-06-08 | 1996-02-20 | Systems Research & Applications Corporation | Generation, archiving, and retrieval of digital images with evoked suggestion-set captions and natural language interface |
US5963940A (en) * | 1995-08-16 | 1999-10-05 | Syracuse University | Natural language information retrieval system and method |
US6026388A (en) * | 1995-08-16 | 2000-02-15 | Textwise, Llc | User interface and other enhancements for natural language information retrieval system and method |
US5734893A (en) * | 1995-09-28 | 1998-03-31 | Ibm Corporation | Progressive content-based retrieval of image and video with adaptive and iterative refinement |
US5692181A (en) * | 1995-10-12 | 1997-11-25 | Ncr Corporation | System and method for generating reports from a computer database |
US5983237A (en) * | 1996-03-29 | 1999-11-09 | Virage, Inc. | Visual dictionary |
US5832182A (en) * | 1996-04-24 | 1998-11-03 | Wisconsin Alumni Research Foundation | Method and system for data clustering for very large databases |
US5781906A (en) * | 1996-06-06 | 1998-07-14 | International Business Machines Corporation | System and method for construction of a data structure for indexing multidimensional objects |
US6233578B1 (en) * | 1996-09-11 | 2001-05-15 | Nippon Telegraph And Telephone Corporation | Method and system for information retrieval |
US5852823A (en) * | 1996-10-16 | 1998-12-22 | Microsoft | Image classification and retrieval system using a query-by-example paradigm |
US5987446A (en) * | 1996-11-12 | 1999-11-16 | U.S. West, Inc. | Searching large collections of text using multiple search engines concurrently |
US5970499A (en) * | 1997-04-11 | 1999-10-19 | Smith; Kurt R. | Method and apparatus for producing and accessing composite data |
US5845278A (en) * | 1997-09-12 | 1998-12-01 | Inioseek Corporation | Method for automatically selecting collections to search in full text searches |
US6134541A (en) * | 1997-10-31 | 2000-10-17 | International Business Machines Corporation | Searching multidimensional indexes using associated clustering and dimension reduction information |
US6084595A (en) * | 1998-02-24 | 2000-07-04 | Virage, Inc. | Indexing method for image search engine |
US6298342B1 (en) * | 1998-03-16 | 2001-10-02 | Microsoft Corporation | Electronic database operations for perspective transformations on relational tables using pivot and unpivot columns |
US6175829B1 (en) * | 1998-04-22 | 2001-01-16 | Nec Usa, Inc. | Method and apparatus for facilitating query reformulation |
Cited By (78)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20100318522A1 (en) * | 1999-02-01 | 2010-12-16 | Lg Electronics Inc. | Method of searching multimedia data |
US20100318523A1 (en) * | 1999-02-01 | 2010-12-16 | Lg Electronics Inc. | Method of searching multimedia data |
US8775451B2 (en) * | 1999-08-09 | 2014-07-08 | Almen Laboratories, Inc. | Object based image retrieval |
US20080037876A1 (en) * | 1999-08-09 | 2008-02-14 | Michael Galperin | Object based image retrieval |
US20100125601A1 (en) * | 2001-04-04 | 2010-05-20 | Peter Jackson | System, method, and software for identifying historically related legal cases |
US7984053B2 (en) * | 2001-04-04 | 2011-07-19 | West Services, Inc. | System, method, and software for identifying historically related legal cases |
US20130179439A1 (en) * | 2001-05-16 | 2013-07-11 | Pandora Media, Inc. | Methods and Systems for Utilizing Contextual Feedback to Generate and Modify Playlists |
US7856458B2 (en) | 2002-10-18 | 2010-12-21 | International Business Machines Corporation | Online analytical processing (OLAP) |
US20080082563A1 (en) * | 2002-10-18 | 2008-04-03 | Patrick Arras | Online analytical processing (olap) |
US20080183740A1 (en) * | 2002-10-18 | 2008-07-31 | Patrick Arras | Online analytical processing (olap) |
US7774302B2 (en) * | 2002-10-18 | 2010-08-10 | International Business Machines Corporation | Online analytical processing (OLAP) |
US7519565B2 (en) * | 2003-11-03 | 2009-04-14 | Cloudmark, Inc. | Methods and apparatuses for classifying electronic documents |
US20050149546A1 (en) * | 2003-11-03 | 2005-07-07 | Prakash Vipul V. | Methods and apparatuses for determining and designating classifications of electronic documents |
US20090259608A1 (en) * | 2003-11-03 | 2009-10-15 | Cloudmark, Inc. | Methods and apparatuses for classifying electronic documents |
US7890441B2 (en) | 2003-11-03 | 2011-02-15 | Cloudmark, Inc. | Methods and apparatuses for classifying electronic documents |
US20050097435A1 (en) * | 2003-11-03 | 2005-05-05 | Prakash Vipul V. | Methods and apparatuses for classifying electronic documents |
US20050120105A1 (en) * | 2003-12-01 | 2005-06-02 | Popescu George V. | Method and apparatus to support application and network awareness of collaborative applications using multi-attribute clustering |
US7975035B2 (en) * | 2003-12-01 | 2011-07-05 | International Business Machines Corporation | Method and apparatus to support application and network awareness of collaborative applications using multi-attribute clustering |
US20060122999A1 (en) * | 2004-12-06 | 2006-06-08 | Samsung Electronics Co., Ltd. | Apparatus for and method of producing graphics contents and computer-readable recording medium storing computer program for executing the method |
US7639890B2 (en) * | 2005-10-25 | 2009-12-29 | General Electric Company | Automatic significant image generation based on image characteristics |
US20070092142A1 (en) * | 2005-10-25 | 2007-04-26 | General Electric Company | Automatic significant image generation based on image characteristics |
US8117213B1 (en) | 2006-06-27 | 2012-02-14 | Nahava Inc. | Method and apparatus for fast similarity-based query, self-join, and join for massive, high-dimension datasets |
US7644090B2 (en) * | 2006-06-27 | 2010-01-05 | Nahava Inc. | Method and apparatus for fast similarity-based query, self-join, and join for massive, high-dimension datasets |
US20070299865A1 (en) * | 2006-06-27 | 2007-12-27 | Nahava Inc. | Method and Apparatus for fast similarity-based query, self-join, and join for massive, high-dimension datasets |
US10872388B2 (en) * | 2006-07-25 | 2020-12-22 | Northrop Grumman Systems Corporation | Global disease surveillance platform, and corresponding system and method |
US20080071776A1 (en) * | 2006-09-14 | 2008-03-20 | Samsung Electronics Co., Ltd. | Information retrieval method in mobile environment and clustering method and information retrieval system using personal search history |
US20090048842A1 (en) * | 2007-04-30 | 2009-02-19 | K-Nfb Reading Technology, Inc. | Generalized Object Recognition for Portable Reading Machine |
US8160880B2 (en) * | 2007-04-30 | 2012-04-17 | K-Nfb Reading Technology, Inc. | Generalized object recognition for portable reading machine |
US20090094197A1 (en) * | 2007-10-04 | 2009-04-09 | Fein Gene S | Method and Apparatus for Integrated Cross Platform Multimedia Broadband Search and Selection User Interface Communication |
US8943038B2 (en) | 2007-10-04 | 2015-01-27 | Gefemer Research Acquisitions, Llc | Method and apparatus for integrated cross platform multimedia broadband search and selection user interface communication |
US9116993B2 (en) | 2007-10-17 | 2015-08-25 | Google Inc. | System and method for query re-issue in search engines |
US8655862B1 (en) * | 2007-10-17 | 2014-02-18 | Google Inc. | System and method for query re-issue in search engines |
DE102007060478A1 (en) * | 2007-12-14 | 2009-06-18 | Adc Automotive Distance Control Systems Gmbh | Method for the cost-optimized determination of clusters in sensor data by means of an embedded system |
CN101911077B (en) * | 2007-12-27 | 2016-05-11 | 皇家飞利浦电子股份有限公司 | For the method and apparatus of hierarchical search |
US11170900B2 (en) * | 2007-12-27 | 2021-11-09 | Koninklijke Philips N.V. | Method and apparatus for refining similar case search |
WO2009083841A1 (en) * | 2007-12-27 | 2009-07-09 | Koninklijke Philips Electronics, N.V. | Method and apparatus for refining similar case search |
US20110022622A1 (en) * | 2007-12-27 | 2011-01-27 | Koninklijke Philips Electronics N.V. | Method and apparatus for refining similar case search |
US8554464B2 (en) | 2008-04-30 | 2013-10-08 | K-Nfb Reading Technology, Inc. | Navigation using portable reading machine |
US20100049431A1 (en) * | 2008-04-30 | 2010-02-25 | Rafael Maya Zetune | Navigation Using Portable Reading Machine |
US7958130B2 (en) * | 2008-05-26 | 2011-06-07 | Microsoft Corporation | Similarity-based content sampling and relevance feedback |
US20090292732A1 (en) * | 2008-05-26 | 2009-11-26 | Microsoft Corporation | Similarity-based content sampling and relevance feedback |
US20100008541A1 (en) * | 2008-07-08 | 2010-01-14 | Forlines Clifton L | Method for Presenting Images to Identify Target Objects |
US20100082611A1 (en) * | 2008-09-23 | 2010-04-01 | Yahoo! Inc. | Trajectory Data Surfacing System: Surfacing Useful and Relevant Entity Annotations |
US20140046914A1 (en) * | 2008-11-19 | 2014-02-13 | Intellectual Ventures Fund 83 Llc | Method for event-based semantic classification |
US20110231350A1 (en) * | 2008-11-26 | 2011-09-22 | Michinari Momma | Active metric learning device, active metric learning method, and active metric learning program |
US8650138B2 (en) * | 2008-11-26 | 2014-02-11 | Nec Corporation | Active metric learning device, active metric learning method, and active metric learning program |
US8832134B2 (en) * | 2009-09-11 | 2014-09-09 | Someones Group Intellectual Property Holdings Pty Ltd ACN | Method, system and controller for searching a database contaning data items |
US20120173559A1 (en) * | 2009-09-11 | 2012-07-05 | Someones Group Intellectual Property Holdings Pty Ltd. | Database searching method, system and controller |
US20130066592A1 (en) * | 2009-10-23 | 2013-03-14 | Commissariat A L'energie Atomique Et Aux Energies Alternatives | Method and system for evaluating the resemblance of a query object to reference objects |
US9576223B2 (en) * | 2009-10-23 | 2017-02-21 | Commissariat A L'energie Atomique Et Aux Energies Alternatives | Method and system for evaluating the resemblance of a query object to reference objects |
US8442977B2 (en) * | 2010-02-16 | 2013-05-14 | Honeywell International Inc. | Distance-space embedding for multi-descriptor matching and retrieval |
US20110202527A1 (en) * | 2010-02-16 | 2011-08-18 | Honeywell International Inc. | Distance-space embedding for multi-descriptor matching and retrieval |
GB2477829A (en) * | 2010-02-16 | 2011-08-17 | Honeywell Int Inc | Distance-space embedding for multi-descriptor matching and retrieval of the track segments in a video archive |
US20130238346A1 (en) * | 2010-11-26 | 2013-09-12 | Nokia Corporation | Low complexity target vector identification |
US9196255B2 (en) * | 2010-11-26 | 2015-11-24 | Nokia Technologies Oy | Low complexity target vector identification |
US20130268547A1 (en) * | 2010-12-16 | 2013-10-10 | Koninklijke Philips N.V. | System and method for clinical decision support for therapy planning using case-based reasoning |
US9082086B2 (en) | 2011-05-20 | 2015-07-14 | Microsoft Corporation | Adaptively learning a similarity model |
US9535928B2 (en) | 2013-03-15 | 2017-01-03 | Sony Corporation | Combining information of different levels for content-based retrieval of digital pathology images |
US10002430B1 (en) | 2013-06-04 | 2018-06-19 | Hrl Laboratories, Llc | Training system for infield training of a vision-based object detector |
US10482122B2 (en) * | 2013-06-05 | 2019-11-19 | Digitalglobe, Inc. | System and method for multiresolution and multitemporal image search |
US9529824B2 (en) * | 2013-06-05 | 2016-12-27 | Digitalglobe, Inc. | System and method for multi resolution and multi temporal image search |
US20140365463A1 (en) * | 2013-06-05 | 2014-12-11 | Digitalglobe, Inc. | Modular image mining and search |
US20170235767A1 (en) * | 2013-06-05 | 2017-08-17 | Digitalglobe, Inc. | System and method for multiresolution and multitemporal image search |
GB2534535A (en) * | 2014-10-08 | 2016-08-03 | Lancaster Univ Business Entpr Ltd | Data structuring and searching methods and apparatus |
US20160371274A1 (en) * | 2015-06-18 | 2016-12-22 | Nbcuniversal Media Llc | Recommendation system using a transformed similarity matrix |
US10191949B2 (en) * | 2015-06-18 | 2019-01-29 | Nbcuniversal Media, Llc | Recommendation system using a transformed similarity matrix |
US10147173B2 (en) * | 2015-12-31 | 2018-12-04 | General Electric Company | System and method for seismic data interpretation |
US20170193647A1 (en) * | 2015-12-31 | 2017-07-06 | General Electric Company | System and method for seismic data interpretation |
US11882344B2 (en) | 2016-03-03 | 2024-01-23 | Comcast Cable Communications, Llc | Determining points of interest in a content item |
WO2018014109A1 (en) * | 2016-07-22 | 2018-01-25 | 9206868 Canada Inc. | System and method for analyzing and searching for features associated with objects |
US10191990B2 (en) | 2016-11-21 | 2019-01-29 | Comcast Cable Communications, Llc | Content recommendation system with weighted metadata annotations |
US11244017B2 (en) | 2016-11-21 | 2022-02-08 | Comcast Cable Communications, Llc | Content recommendation system with weighted metadata annotations |
US11403327B2 (en) * | 2019-02-20 | 2022-08-02 | International Business Machines Corporation | Mixed initiative feature engineering |
US11860928B2 (en) | 2019-09-11 | 2024-01-02 | International Business Machines Corporation | Dialog-based image retrieval with contextual information |
US11100145B2 (en) | 2019-09-11 | 2021-08-24 | International Business Machines Corporation | Dialog-based image retrieval with contextual information |
CN111080080A (en) * | 2019-11-25 | 2020-04-28 | 桂林理工大学南宁分校 | Method and system for estimating risk of geological disaster of villages and small towns |
CN111080080B (en) * | 2019-11-25 | 2023-05-26 | 桂林理工大学南宁分校 | Village geological disaster risk prediction method and system |
WO2021205080A1 (en) | 2020-04-11 | 2021-10-14 | IPRally Technologies Oy | System and method for performing a search in a vector space based search engine |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US7272593B1 (en) | Method and apparatus for similarity retrieval from iterative refinement | |
EP1025514B1 (en) | Multidimensional data clustering and dimension reduction for indexing and searching | |
US6134541A (en) | Searching multidimensional indexes using associated clustering and dimension reduction information | |
US6084595A (en) | Indexing method for image search engine | |
Yildizer et al. | Efficient content-based image retrieval using multiple support vector machines ensemble | |
US7266545B2 (en) | Methods and apparatus for indexing in a database and for retrieving data from a database in accordance with queries using example sets | |
US7548936B2 (en) | Systems and methods to present web image search results for effective image browsing | |
US8768105B2 (en) | Method for searching a database using query images and an image anchor graph-based ranking algorithm | |
Tian et al. | Building descriptive and discriminative visual codebook for large-scale image applications | |
Song et al. | Brepartition: Optimized high-dimensional knn search with bregman distances | |
Taipalus | Vector database management systems: Fundamental concepts, use-cases, and current challenges | |
Mejdoub et al. | Embedded lattices tree: An efficient indexing scheme for content based retrieval on image databases | |
De Vries et al. | Parallel streaming signature em-tree: A clustering algorithm for web scale applications | |
Bouhlel et al. | Hypergraph learning with collaborative representation for image search reranking | |
Xu et al. | Multi-feature indexing for image retrieval based on hypergraph | |
Littau et al. | Clustering very large data sets with principal direction divisive partitioning | |
Mao et al. | Dimension reduction for distance-based indexing | |
Daoudi et al. | A fast and efficient fuzzy approximation-based indexing for CBIR | |
Li et al. | S-STIR: similarity search through iterative refinement | |
Feng et al. | Effective optimizations of cluster-based nearest neighbor search in high-dimensional space | |
Georgiadis et al. | Skyline-based dissimilarity of images | |
Bai et al. | Discriminative sparse neighbor coding | |
Shi et al. | Exploring spatial correlation for visual object retrieval | |
Xu et al. | Feature-based similarity retrieval in Content-based image retrieval | |
Guo et al. | SIP-FS: a novel feature selection for data representation |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: INTERNATIONAL BUSINESS MACHINES CORPORATION, NEW YFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:CASTELLI, VITTORIO;LI, CHUNG-SHENG;SMITH, JOHN R.;REEL/FRAME:009733/0026;SIGNING DATES FROM 19990120 TO 19990126 |
|
FEPP | Fee payment procedure |
Free format text: PAYOR NUMBER ASSIGNED (ORIGINAL EVENT CODE: ASPN); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
REMI | Maintenance fee reminder mailed | ||
FPAY | Fee payment |
Year of fee payment: 4 |
|
SULP | Surcharge for late payment | ||
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:INTERNATIONAL BUSINESS MACHINES CORPORATION;REEL/FRAME:026664/0866Effective date: 20110503 |
|
REMI | Maintenance fee reminder mailed | ||
LAPS | Lapse for failure to pay maintenance fees | ||
STCH | Information on status: patent discontinuation |
Free format text: PATENT EXPIRED DUE TO NONPAYMENT OF MAINTENANCE FEES UNDER 37 CFR 1.362 |
|
FP | Lapsed due to failure to pay maintenance fee |
Effective date: 20150918 |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044144/0001Effective date: 20170929 |