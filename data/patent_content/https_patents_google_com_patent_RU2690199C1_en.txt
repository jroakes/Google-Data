RU2690199C1 - Managing data providers for dialogue - Google Patents
Managing data providers for dialogue Download PDFInfo
- Publication number
- RU2690199C1 RU2690199C1 RU2017142336A RU2017142336A RU2690199C1 RU 2690199 C1 RU2690199 C1 RU 2690199C1 RU 2017142336 A RU2017142336 A RU 2017142336A RU 2017142336 A RU2017142336 A RU 2017142336A RU 2690199 C1 RU2690199 C1 RU 2690199C1
- Authority
- RU
- Russia
- Prior art keywords
- response
- user
- dialog
- request
- dialogue
- Prior art date
Links
Images
Classifications
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L17/00—Speaker identification or verification
- G10L17/22—Interactive procedures; Man-machine interfaces
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/30—Information retrieval; Database structures therefor; File system structures therefor of unstructured textual data
- G06F16/33—Querying
- G06F16/332—Query formulation
- G06F16/3329—Natural language query formulation or dialogue systems
Abstract
Description
УРОВЕНЬ ТЕХНИКИBACKGROUND
[0001] Данное описание изобретения относится к способу и системе ведения диалогов в ответ на запрос, выданный пользователем с использованием интерфейса на пользовательском устройстве.[0001] This description of the invention relates to a method and system for conducting conversations in response to a request issued by a user using an interface on a user device.
[0002] Традиционные мобильные устройства могут включать в себя программное обеспечение для ответа на речь пользователя мобильного устройства. Речь обычно может включать в себя команды мобильному устройству позвонить по номеру телефона, отправить сообщение на номер телефона или искать информацию на мобильном устройстве либо в Интернете. Программное обеспечение может обеспечить аудиовывод из мобильного устройства, подтверждающий те команды. Мобильное устройство может подавать принятую речь в серверную систему для обработки и приема информации, идентифицирующей операции, которые нужно выполнить.[0002] Traditional mobile devices may include software for answering the speech of the user of the mobile device. Speech can usually include commands for a mobile device to call a phone number, send a message to a phone number, or search for information on a mobile device or on the Internet. Software can provide audio output from a mobile device confirming those commands. The mobile device can feed the received speech to the server system to process and receive information identifying the operations to be performed.
СУЩНОСТЬ ИЗОБРЕТЕНИЯSUMMARY OF INVENTION
[0003] Данное описание изобретения описывает технологии, относящиеся к ведению диалогов, включая задействование разных поставщиков данных. Вообще, один изобретательский аспект изобретения, описанного в данном описании изобретения, можно воплотить в способах, которые включают в себя действия по приему от пользовательского устройства запроса, ассоциированного с задачей; представлению запроса каждому из множества отдельных поставщиков данных; приему одного или более предлагаемых диалоговых ответов от одного или более поставщиков данных; оценке одного или более предлагаемых диалоговых ответов на основе одного или более оценочных факторов; определению конкретного диалогового ответа для предоставления пользователю на основе оценки; и предоставлению выбранного диалогового ответа в пользовательское устройство. Конкретнее, аспект описанных вариантов осуществления включает в себя способ ведения диалога для пользовательского устройства, содержащий: прием от пользовательского устройства запроса в диалоговой системе, ассоциированного с задачей, при этом упомянутое пользовательское устройство соединено с возможностью связи с диалоговой системой посредством сети связи; представление диалоговой системой запроса каждому из множества отдельных поставщиков данных, где каждый поставщик данных независимо анализирует запрос в соответствии с соответствующей моделью данных; прием множества предлагаемых диалоговых ответов от двух или более поставщиков данных; оценку одного или более предлагаемых диалоговых ответов механизмом ведения диалога в диалоговой системе на основе одного или более оценочных факторов; определение механизмом ведения диалога конкретного диалогового ответа для предоставления пользователю на основе оценочного критерия; и предоставление этого определенного диалогового ответа в пользовательское устройство.[0003] This description of the invention describes the technologies related to the dialogue, including the involvement of different data providers. In general, one inventive aspect of the invention described in this description of the invention can be embodied in methods that include actions to receive a request from the user device associated with the task; submitting a request to each of a variety of individual data providers receiving one or more of the proposed dialog responses from one or more data providers; evaluating one or more proposed dialogue responses based on one or more evaluation factors; determining a specific dialogue response to provide to the user based on the assessment; and provide the selected dialog response to the user device. More specifically, an aspect of the described embodiments includes a dialogue method for a user device, comprising: receiving from a user device a request in a dialog system associated with a task, wherein said user device is connected to communicate with the dialogue system via a communication network; the presentation of a query system by the interactive system to each of a plurality of individual data providers, where each data provider independently analyzes the request in accordance with the corresponding data model; receiving multiple suggested dialog responses from two or more data providers; an assessment of one or more proposed dialogue responses by the dialogue mechanism in the dialogue system based on one or more evaluation factors; determining by the dialogue mechanism a specific dialogue response for presentation to the user based on the evaluation criterion; and providing this specific dialog response to the user device.
[0004] Другие варианты осуществления этого аспекта включают в себя соответствующие компьютерные системы, устройство и компьютерные программы, записанные на одном или более компьютерных запоминающих устройствах, каждое из которых сконфигурировано для выполнения действий в способах. Система из одного или более компьютеров, сконфигурированных для выполнения конкретных операций или действий, означает, что система установила на них программное обеспечение, микропрограммное обеспечение, аппаратные средства или их сочетание, которые при работе побуждают систему выполнять операции или действия. Одна или более компьютерных программ, сконфигурированные для выполнения конкретных операций или действий, означают, что одна или более программ включают в себя команды, которые при их исполнении устройством обработки данных побуждают устройство выполнять операции или действия.[0004] Other embodiments of this aspect include respective computer systems, a device, and computer programs recorded on one or more computer storage devices, each configured to perform actions in the methods. A system of one or more computers configured to perform specific operations or actions means that the system has installed software, firmware, hardware, or a combination of them, which, when in operation, causes the system to perform operations or actions. One or more computer programs configured to perform specific operations or actions means that the one or more programs include instructions that, when executed by the data processing device, cause the device to perform operations or actions.
[0005] Вышеупомянутые и другие варианты осуществления при необходимости могут включать в себя один или более следующих признаков, по отдельности или в комбинации. В частности, один вариант осуществления включает в себя все следующие признаки вместе. Способ включает в себя: обновление состояния диалога на основе выбранного диалогового ответа. Принятый запрос является голосовым вводом, и способ содержит преобразование голосового входного запроса в текст перед представлением запроса множеству поставщиков данных. Способ дополнительно включает в себя: определение того, требует ли диалог дополнительных ответов от пользовательского устройства, и в ответ на определение того, что никакие дополнительные ответы не требуются, завершение запрошенной пользователем задачи. Каждый поставщик данных независимо анализирует запрос в соответствии с соответствующей моделью данных. В ответ на определение того, что никакие из соответствующих оценок для множества предлагаемых диалоговых ответов не удовлетворяют пороговой величине, синтезирование ответа для предоставления пользовательскому устройству, чтобы выявить намерение пользователя. Определение конкретного диалогового ответа для предоставления пользователю на основе оценки включает в себя дисквалификацию предлагаемого диалогового ответа с оценкой, которая ниже пороговой величины, а также дисквалификацию всех предлагаемых диалоговых ответов, которые относятся к предлагаемому диалоговому ответу.[0005] The above and other embodiments may, if necessary, include one or more of the following features, individually or in combination. In particular, one embodiment includes all of the following features together. The method includes: updating the dialog state based on the selected dialog response. The received request is voice input, and the method includes converting the voice input request to text before submitting the request to a plurality of data providers. The method further includes: determining whether the dialog requires additional responses from the user device, and in response to determining that no additional answers are required, completing the task requested by the user. Each data provider independently analyzes the request according to the corresponding data model. In response to the determination that none of the corresponding estimates for a variety of proposed dialog responses satisfy the threshold, synthesizing the response to provide the user device to reveal the user's intention. Determining a specific dialogue response to provide to the user based on the assessment includes disqualifying the proposed dialogue response with a rating that is below the threshold value, as well as disqualifying all proposed dialogue responses that relate to the proposed dialogue response.
[0006] Конкретные варианты осуществления изобретения, описанного в данном описании изобретения, можно реализовать для осуществления одного или более следующих преимуществ. Ведение диалога для реагирования на задачи улучшается путем задействования разных поставщиков данных, которые могут ответить на пользовательский ввод. В частности, можно привлекать разных поставщиков данных, обладающих разными достоинствами и недостатками. Это позволяет пользоваться специализированными поставщиками данных, также обеспечивая гибкость типов пользовательского ввода, которые можно интерпретировать. Более того, ведение диалога может допускать прием параллельных ответов от разных поставщиков данных и, при необходимости, агрегирование принятых ответов. Более того, поставщики данных могут быть разнотипными по отношению к реализации, например, они могут формироваться разными производителями или создаваться с использованием разных технологий, либо могут быть доступными по разным сетям (типа локальных в отличие от разветвленных). При условии, что каждый поставщик данных предоставляет данные с использованием заданного интерфейса, система может объединять их данные в единый диалоговый ответ.[0006] Specific embodiments of the invention described in this specification can be implemented to provide one or more of the following advantages. Dialogue to respond to tasks is improved by engaging different data providers that can respond to user input. In particular, it is possible to attract different data providers with different strengths and weaknesses. This allows you to use specialized data providers, while also providing the flexibility of user input types that can be interpreted. Moreover, the dialogue can allow the reception of parallel responses from different data providers and, if necessary, aggregation of received responses. Moreover, data providers can be heterogeneous with respect to implementation, for example, they can be formed by different manufacturers or created using different technologies, or they can be available on different networks (such as local as opposed to branched). Provided that each data provider provides data using a given interface, the system can combine their data into a single interactive response.
[0007] Подробности одного или более вариантов осуществления изобретения, описанного в этом описании изобретения, излагаются на прилагаемых чертежах и в описании ниже. Другие признаки, аспекты и преимущества изобретения станут очевидны из описания, чертежей и формулы изобретения.[0007] The details of one or more embodiments of the invention described in this specification are set forth in the accompanying drawings and the description below. Other features, aspects, and advantages of the invention will become apparent from the description, drawings, and claims.
КРАТКОЕ ОПИСАНИЕ ЧЕРТЕЖЕЙBRIEF DESCRIPTION OF THE DRAWINGS
[0008] Фиг. 1 - примерная система для ведения диалога.[0008] FIG. 1 is an exemplary system for dialogue.
[0009] Фиг. 2 - алгоритмическая блок-схема примерного процесса для ведения диалога.[0009] FIG. 2 is an algorithmic flowchart of an exemplary process for conducting a dialogue.
[010] Одинаковые номера ссылок и обозначения на различных чертежах указывают одинаковые элементы.[010] The same reference numbers and designations in different drawings indicate the same elements.
ОСУЩЕСТВЛЕНИЕ ИЗОБРЕТЕНИЯIMPLEMENTATION OF THE INVENTION
[011] Пользователи могут давать голосовые команды устройству для выполнения конкретной задачи, например, формирования элемента календаря, посылки вызова или сообщения либо поиска конкретной информации. Выполнением задачи устройством или системой, связанной с устройством, можно управлять с помощью разговорного диалога, который задает вопросы пользователю по одному или более значениям, необходимым для завершения задачи, аналогично заполнению полей некой формы.[011] Users can give voice commands to a device to perform a specific task, such as forming a calendar item, making a call or message, or searching for specific information. A task or device associated with a device can be controlled using a conversational dialog, which asks the user questions about one or more values needed to complete the task, similar to filling in some form fields.
[012] Например, типовым диалогом для задачи в календаре может быть:[012] For example, a typical dialog for a task in the calendar might be:
[013] Пользователь: [создать будильник][013] User: [create alarm]
[014] Устройство/система: В котором часу вы желаете установить будильник?[014] Device / System: What time do you want to set the alarm?
[015] Пользователь: [15:00][015] User: [15:00]
[016] Устройство/система: Создан будильник на 15:00.[016] Device / System: Created the alarm at 3:00 pm
[017] В ответ на пользовательский ввод команды создания будильника система интерпретирует команду как запрашивающую задачу установить будильник на конкретное время. В частности, поставщик данных для выполнения задач может интерпретировать принятый голосовой ввод и направить конкретный диалог к информации, необходимой для завершения задачи, например, запрашивающей время для будильника.[017] In response to the user inputting an alarm creation command, the system interprets the command as a requesting task to set an alarm for a specific time. In particular, the data provider for performing tasks may interpret the received voice input and direct a specific dialogue to the information necessary to complete the task, for example, requesting time for an alarm.
[018] В другом примерном диалоге пользователь может искать конкретную информацию:[018] In another exemplary dialog, a user may search for specific information:
[019] Пользователь: [Когда начинается игра Giants?][019] User: [When does the Giants game begin?]
[020] Устройство/система: Вы имеете в виду Giants из Сан-Франциско или Giants из Нью-Йорка?[020] Device / System: Do you mean Giants from San Francisco or Giants from New York?
[021] Здесь система понимает вопрос от пользователя как запрос расписания спортивных игр, но есть неопределенность в отношении того, каких "Giants" подразумевает пользователь. Диалоговый ответ запрашивает разъяснение, на какую спортивную команду "Giants" ссылается пользователь. При разъяснении диалог может продолжаться, чтобы предоставить информацию о расписании, например, которая идентифицирована поисковой системой.[021] Here, the system understands the question from the user as a request for a schedule of sports games, but there is uncertainty as to which "Giants" the user implies. The interactive response asks for clarification of which sports team "Giants" the user refers to. When clarifying, the dialogue may continue to provide schedule information, for example, that is identified by a search engine.
[022] В некоторых случаях пользовательский ввод может поменять один тип задачи теоретически на другой тип задачи в зависимости от того, как диалоговая система интерпретирует голосовой ввод. Например:[022] In some cases, user input can change one type of task theoretically to another type of task depending on how the interactive system interprets voice input. For example:
[023] Пользователь: [Установить будильник][023] User: [Set alarm]
[024] Устройство/система: В котором часу вы желаете установить будильник?[024] Device / system: What time do you want to set the alarm?
[025] Пользователь: [Когда начинается игра Giants?][025] User: [When does the Giants play begin?]
[026] В этом примере второй ответ пользователя можно интерпретировать более чем одним способом в зависимости от того, какой поставщик данных инициируется голосовым вводом. Например, поставщик данных по задачам может интерпретировать голосовой ввод, связанный с созданием будильника, но не посчитает второй ввод об игре Giants шумным или бессмысленным ответом, потому что он не относится к предполагаемому вводу для диалога по задаче будильника. Однако другой поставщик данных, который может интерпретировать связанный со спортивными играми голосовой ввод, может обработать вопрос о расписании игры Giants. Данное описание изобретения описывает методики для задействования и объединения диалоговых ответов от множества поставщиков данных.[026] In this example, the second user response can be interpreted in more than one way, depending on which data provider is initiated by voice input. For example, a task data provider may interpret voice input associated with creating an alarm clock, but does not consider the second input about the Giants game a noisy or meaningless response, because it does not apply to the intended input for the alarm task dialog. However, another data provider that can interpret sports-related voice input can handle the Giants schedule. This specification describes techniques for engaging and combining dialog responses from multiple data providers.
[027] Фиг. 1 - примерная система 100 для ведения диалога. Система 100 включает в себя пользователя 102, пользовательское устройство 104, диалоговую систему 106 и множество поставщиков 124a, 124b-124n данных. Пользовательское устройство 104 и диалоговая система 106 осуществляют связь по сети 103, например, Интернету.[027] FIG. 1 is an
[028] Пользовательское устройство 104 может быть одним из некоторого количества подходящих устройств, включая мобильное устройство, носимый компьютер, планшет, гибридное устройство, переносной компьютер или настольный компьютер. Пользовательское устройство 104 может принимать от пользователя 102 взаимодействия, как вербальные, например, голосовой ввод, так и невербальные. В частности, пользовательское устройство 104 включает в себя микрофон 108, сконфигурированный для приема голосового ввода от пользователя 102. Пользовательское устройство 104 также может включать в себя один или более динамиков, сконфигурированных для вещания вопросов диалога в ответ на принятый запрос пользователя. Для ясности показано только одно пользовательское устройство. Однако может быть много пользовательских устройств, ассоциированных с соответствующими отдельными пользователями. Каждое из этих пользовательских устройств может осуществлять связь с диалоговой системой 106 по сети 103.[028] The user device 104 may be one of a number of suitable devices, including a mobile device, a wearable computer, a tablet, a hybrid device, a laptop computer, or a desktop computer. User device 104 may receive interactions from the
[029] Пользовательское устройство 104 дополнительно включает в себя интерфейс 110 пользователя. Интерфейс 110 пользователя в ответ на запрос пользователя может показывать пользователю информацию, включающую в себя некоторое или все содержимое, ассоциированное с диалогом. Диалог 112 задает некоторое количество ответов, например, вопросы по значениям, необходимым для выполнения задачи, запрошенной пользователем. Конкретные вопросы или другое содержимое диалога 112 можно показывать пользователю в конкретном порядке, например, посредством последовательности аудио-вопросов, вещаемых одним или более динамиками, или отображаемых в интерфейсе 110 пользователя.[029] The user device 104 further includes a user interface 110. The user interface 110, in response to a user request, can show the user information including some or all of the content associated with the dialog.
[030] В некоторых других реализациях пользовательское устройство включает в себя механизм анализа речи для преобразования в текст принятого голосового ввода в микрофон 108 перед передачей диалоговой системе 106.[030] In some other implementations, the user device includes a speech analysis engine for converting the received voice input into the microphone 108 into the text before transmitting to the interactive system 106.
[031] Диалоговая система 106 может быть одним или более вычислительными ресурсами, например, одной или более вычислительными системами, или виртуальными машинами, работающими в одной или более вычислительных системах, связанными с пользовательским устройством 104 по сети 103. Диалоговая система 106 включает в себя механизм 114 ведения диалога и механизм 116 анализа речи.[031] The dialogue system 106 may be one or more computing resources, for example, one or more computing systems, or virtual machines running on one or more computing systems connected to the user device 104 via the network 103. The dialog system 106 includes a mechanism 114 dialogue and speech analysis engine 116.
[032] Механизм 116 анализа речи может использовать подходящий процесс преобразования речи в текст для преобразования принятого голосового ввода 118 в текстовую строку. В некоторых реализациях механизм 116 анализа речи выдает текст, который может быть обработан одним или более синтаксическими анализаторами, чтобы идентифицировать один или более смыслов, например, путем формирования дерева разбора. Смысл аудио, которое преобразовано в текст, может использоваться одним или более поставщиками данных, чтобы идентифицировать конкретную задачу для выполнения в ответ на принятый запрос.[032] The speech analysis engine 116 may use a suitable speech-to-text conversion process to convert received voice input 118 into a text string. In some implementations, the speech analysis engine 116 produces text that can be processed by one or more parsers to identify one or more senses, for example, by forming a parse tree. The meaning of audio that is converted to text may be used by one or more data providers to identify a specific task to be performed in response to a received request.
[033] Механизм 114 ведения диалога управляет одним или более диалогами, ассоциированными с запрошенной задачей. Это включает в себя поддержание состояния диалога, например, на какой вопрос отвечают, чтобы механизм 116 анализа речи мог должным образом интерпретировать принятое аудио, ассоциированное с диалогом, на основе текущего контекста, предоставленного тем состоянием. К тому же механизм 114 ведения диалога определяет ответ на входящий голосовой ввод на основе состояния диалога, а также интерпретации голосового ввода одним или более поставщиками 124a, 124b и 124n данных, представляющими собой поставщика 1 данных, поставщика 2 данных и поставщика N данных, где N - некоторое целое число, представляющее общее количество поставщиков данных, которые могут предоставлять ввод в диалоговую систему 106.[033] The dialogue engine 114 controls one or more dialogs associated with the requested task. This includes maintaining the state of the dialogue, for example, which question is answered so that the speech analysis engine 116 can properly interpret the received audio associated with the dialogue based on the current context provided by that state. In addition, the dialogue engine 114 determines the response to the incoming voice input based on the state of the dialogue, as well as the interpretation of the voice input by one or
[034] Каждый из этих поставщиков 124a-n данных представляет собой серверную систему, которая конфигурируется для независимой интерпретации голосового ввода в соответствии с конкретной моделью данных для того поставщика данных. Например, первый поставщик данных может быть поставщиком задач, у которого модель данных сконфигурирована для интерпретации голосовых запросов, связанных с конкретными задачами, например, созданием записи календаря, установкой будильника, посылкой телефонного вызова или формированием текстового сообщения. Поставщик данных по задачам ожидает пользовательский ввод, ассоциированный с конкретными задачами, и распознает голосовой ввод, ассоциированный с тем предполагаемым пользовательским вводом. Второй поставщик данных может быть поставщиком спортивных игр, у которого модель данных сконфигурирована для интерпретации голосовых запросов, связанных с конкретными спортивными темами, включающими команды и счет очков. Другие поставщики данных могут включать в себя поставщиков поиска данных, которые сосредоточены на конкретных типах информации, например, местном предпринимательстве, информации из социальных сетей или торговых данных, таких как возможности покупок.[034] Each of these
[035] В ответ на голосовой ввод, который принимается от пользовательского устройства 104 и обрабатывается механизмом 116 анализа голоса, один или более поставщиков 124 данных могут интерпретировать принятый ввод и предоставить диалоговый ответ механизму 114 ведения диалога. Затем механизм 114 ведения диалога определяет, какой диалоговый ответ предоставить пользовательскому устройству 104. Ниже подробнее описываются разные способы ответа.[035] In response to voice input, which is received from the user device 104 and processed by the voice analysis mechanism 116, one or more data providers 124 can interpret the received input and provide a dialog response to the dialogue mechanism 114. The dialog engine 114 then determines which dialog response to provide to the user device 104. The various response methods are described in more detail below.
[036] Каждый поставщик 124a-n данных предлагает диалоговый ответ на основе интерпретации принятого ввода в соответствии с моделью данных у соответствующего поставщика данных. Диалоговый ответ и, при необходимости, другая информация, например, предполагаемый ответ от пользователя 102, могут кодироваться в некую структуру данных в соответствии с конкретным форматом данных. В некоторых реализациях эта информация кодируется в буфер протокола, в данном описании изобретения называемый DialogTurnIntent ("DTI"). Для удобства везде будет использоваться DTI, но могут использоваться и другие подходящие кодированные структуры данных.[036] Each
[037] Например, в диалоге для задачи составления сообщения электронной почты один вопрос в диалоге может быть запросом темы электронного письма. Поставщик данных по задачам может создать DTI, где вопросом к пользователю является запрос темы. DTI предоставляется механизму 114 ведения диалога и отправляется пользовательскому устройству 104, где его можно показать пользователю 102, например, в виде визуального вопроса в интерфейсе пользователя, например: "Какая тема?", или в виде аудио-вопроса, выданного из динамиков, например: "Какую бы тему вы хотели?".[037] For example, in the dialogue for the task of composing an e-mail message, one question in the dialogue may be a request for the subject of the e-mail. The task data provider can create a DTI where the user's question is a query for the topic. The DTI is provided to the dialogue engine 114 and sent to the user device 104 where it can be shown to the
[038] Механизм 114 ведения диалога может отправить (120) пользовательскому устройству 102 более одного DTI. В частности, DTI могут включать в себя не только текущее приглашение пользователю, но и другие DTI, связанные другими полями, необходимыми для завершения диалога для запрошенной задачи. Например, когда механизм 114 ведения диалога отправляет DTI "запрос темы", он также может отправить DTI для последующего вопроса в диалоге, например DTI "запрос тела сообщения".[038] The dialogue engine 114 may send (120) more than one DTI to the
[039] Фиг. 2 - алгоритмическая блок-схема примерного процесса 200 для ведения диалога. Для удобства процесс 200 будет описываться как выполняемый системой из одного или более компьютеров, расположенных в одном или более местоположениях, и подходящим образом запрограммированной в соответствии с данным описанием изобретения. Например, процесс 200 может выполнять подходящим образом запрограммированная диалоговая система, например, диалоговая система 106 из фиг. 1.[039] FIG. 2 is an algorithmic flowchart of an
[040] Система принимает ввод, включающий в себя запрос (202). Запрос может приниматься в виде голосового ввода, поданного пользователем в пользовательское устройство, или ручного ввода в пользовательское устройство, например, пользовательское устройство 104 по фиг. 1, и передаваться системе. В некоторых реализациях пользовательский голосовой ввод можно преобразовать в текст с помощью пользовательского устройства перед отправкой в систему. Задачей может быть, например, формирование элемента календаря, установка будильника, формирование электронного письма, посылка вызова или сообщения либо поиск конкретной информации.[040] The system accepts input that includes the request (202). The request may be received as voice input from the user to the user device, or manually entered into the user device, for example, user device 104 of FIG. 1, and transferred to the system. In some implementations, user voice input can be converted to text using a user device before being sent to the system. The task may be, for example, the formation of a calendar item, setting an alarm clock, the formation of an e-mail, making a call or message, or searching for specific information.
[041] Система предоставляет запрос множеству поставщиков данных (204). Каждый поставщик данных может быть сконфигурирован для интерпретации разных типов запросов с использованием конкретной модели данных. Таким образом, принятый запрос может быть интерпретирован по-разному разными поставщиками данных в зависимости от того, как обрабатывается запрос в соответствии с соответствующими моделями данных.[041] The system provides a query to a variety of data providers (204). Each data provider can be configured to interpret different types of requests using a specific data model. Thus, a received request can be interpreted differently by different data providers, depending on how the request is processed in accordance with the corresponding data models.
[042] Система принимает предлагаемый диалоговый ответ от одного или более поставщиков данных (206). Каждый поставщик данных независимо анализирует запрос в соответствии с соответствующей моделью данных. Модель данных может включать в себя модель, обученную на характерной совокупности данных, ассоциированной с конкретным типом информации или действия. Запрос может инициировать ответ от некоторых, но не всех поставщиков данных среди множества поставщиков данных. Таким образом, голосовой входной запрос расписания бейсбола может инициировать предлагаемый диалоговый ответ от поставщика данных, обученного предоставлять связанные со спортивными играми ответы, но не инициировать поставщика данных, обученного предоставлять информацию о погоде, потому что голосовой ввод не совпадает с предполагаемым запросом, ассоциированным с информацией о погоде. В некоторых реализациях поставщик данных может предоставить ответ на нераспознанный голосовой ввод, указывающий, например, что ввод не понят, и попросить пользователя повторить ответ.[042] The system accepts a proposed dialog response from one or more data providers (206). Each data provider independently analyzes the request according to the corresponding data model. A data model may include a model trained on a characteristic data set associated with a particular type of information or action. A request may trigger a response from some, but not all, data providers among multiple data providers. Thus, a voice input request to a baseball schedule may initiate a proposed interactive response from a data provider trained to provide sports-related responses, but not initiate a data provider trained to provide weather information because voice input does not match the intended request associated with the information about the weather. In some implementations, the data provider may provide a response to unrecognized voice input, indicating, for example, that the input is not understood, and ask the user to repeat the response.
[043] Один или более поставщиков данных могут предоставить предлагаемый диалоговый ответ в виде DTI, который включает в себя предлагаемый ответ для предоставления пользовательскому устройству.[043] One or more data providers may provide a suggested interactive response in the form of a DTI, which includes a proposed response for providing to a user device.
[044] В некоторых реализациях каждый поставщик данных способен видеть предлагаемые диалоговые ответы, предоставленные другими поставщиками данных. В ответ данный поставщик данных может изменить или добавить предлагаемые диалоговые ответы на основе диалоговых ответов других поставщиков данных. Например, поставщик данных по задачам может предложить ответ, который основывается на предлагаемом ответе поставщика поиска данных, например, предлагая время для установки будильника на основе ответа от поставщика поиска данных, предоставляющего время для спортивной игры. Более того, в некоторых реализациях каждый поставщик данных может предоставить множество предлагаемых диалоговых ответов. Например, каждый ответ может основываться на контексте предлагаемого ответа другого поставщика данных, а также ответа, который игнорирует предложения других поставщиков данных.[044] In some implementations, each data provider is able to see the proposed interactive responses provided by other data providers. In response, the data provider can modify or add the proposed dialog responses based on the dialog responses of other data providers. For example, a task data provider may offer a response that is based on a proposed data retrieval provider response, for example, offering time to set an alarm based on a response from a data retrieval provider that provides time for a sports game. Moreover, in some implementations, each data provider may provide a variety of suggested interactive responses. For example, each response may be based on the context of the proposed response from another data provider, as well as a response that ignores suggestions from other data providers.
[045] Система определяет, какой диалоговый ответ выбрать (208). В частности, система анализирует все предлагаемые диалоговые ответы и определяет, какой предлагаемый диалоговый ответ больше всего подходит для выбора. Анализ выполняется после приема всех индивидуальных предложений от поставщиков данных, но перед тем, как любые диалоговые ответы отправляются пользовательскому устройству. Система может оценить каждый предлагаемый ответ на основе одного или более факторов. Можно использовать различные факторы для оценки предлагаемых диалоговых ответов для выбора, включая одно или более из основанной на журналах настройки вероятного намерения пользователя, моделей персонализации пользователя, оценок, указывающих правдоподобие семантической интерпретации каждого поставщика данных, или полной конфигурации стратегии диалога, которая определяет равновесие между точным соответствием и минимизацией количества вопросов, задаваемых как часть диалога.[045] The system determines which dialog answer to select (208). In particular, the system analyzes all the proposed dialog answers and determines which proposed dialog answer is most suitable for selection. The analysis is performed after receiving all the individual offers from the data providers, but before any online responses are sent to the user device. The system can evaluate each proposed response based on one or more factors. You can use various factors to evaluate the proposed dialog responses for selection, including one or more log-based user settings, user personalization patterns, ratings indicating the likelihood of each data provider’s semantic interpretation, or a complete configuration of the dialogue strategy that determines the exact balance matching and minimizing the number of questions asked as part of the dialogue.
[046] В некоторых реализациях поставщики данных включают в свои результаты оценки уверенности. Оценки уверенности можно использовать для определения того, какой предлагаемый ответ выбрать. В некоторых других реализациях другие факторы выбора могут включать в себя длину беседы в диалоге и предысторию беседы в диалоге. Например, если пользователь задает один и тот же вопрос множество раз, а поставщик данных не может предоставить информацию, которую ищет пользователь, то вместо него можно выбрать другого поставщика данных.[046] In some implementations, data providers include confidence in their results. Confidence scores can be used to determine which suggested answer to choose. In some other implementations, other factors of choice may include the length of the conversation in the dialogue and the background of the conversation in the dialogue. For example, if a user sets the same question multiple times, and the data provider cannot provide the information that the user is looking for, then you can select another data provider instead.
[047] В некоторых реализациях фактором выбора является правдоподобие того, что рассматриваемая информация является чем-то, что интересовало бы обычного пользователя (в отличие от экзотики). Например, если нет такой спортивной команды, как Giants, то следует считать, что пользователя не поняли, перед выполнением поиска, например, "гиганты, которые играют".[047] In some implementations, the factor of choice is the likelihood that the information in question is something that would be of interest to the average user (as opposed to exotic). For example, if there is no such sports team as Giants, then it should be assumed that the user was not understood before the search, for example, the "giants who play".
[048] В некоторых реализациях фактором выбора является качество рассматриваемой информации. Качество может основываться, например, на том, получал ли поставщик данных информацию из структурированного источника, например, официальной службы расписания бейсбола, или неструктурированного источника, например, блогов случайных людей.[048] In some implementations, the factor of choice is the quality of the information in question. Quality can be based, for example, on whether the data provider received information from a structured source, such as the official baseball scheduling service, or an unstructured source, such as random blogs.
[049] В некоторых реализациях фактор выбора основывается на прагматике и планировании задач. Например, если системе не известно, в какое время играет любая из команд Giants, то системе не следует спрашивать пользователя, каких Giants он подразумевает, потому что ответ не окажет никакого влияния на расширенную задачу.[049] In some implementations, the selection factor is based on pragmatics and task planning. For example, if the system does not know at what time any of the Giants teams plays, then the system should not ask the user what Giants it implies, because the answer will have no effect on the extended task.
[050] В некоторых реализациях фактор выбора выводится на основе релевантности рассматриваемой информации запросу пользователя. Например, если бы "Giants" были лишь малоизвестной командой в далекой стране, то системе следует считать их нерелевантными.[050] In some implementations, the selection factor is derived based on the relevance of the information in question to the user's request. For example, if the Giants were just a little-known team in a distant country, then the system should be considered irrelevant.
[051] В некоторых реализациях фактор выбора основывается на том, выполняется ли определение, что запрос настолько неопределенный, что система должна попросить пользователя прояснить свое намерение, не раздражая его глупыми/очевидными вопросами. Определение может выполняться, например, на основе географической информации о том, где располагается пользователь, персонализации, например, прошлого обсуждения пользователем Giants из Сан-Франциско в сравнении с Giants из Нью-Йорка, или контекста, например, только у одной из команд есть расписание игр в ближайшее время.[051] In some implementations, the selection factor is based on whether the determination is made that the request is so vague that the system should ask the user to clarify his intention without annoying him with stupid / obvious questions. The definition can be done, for example, based on geographic information about where the user is located, personalization of, for example, the past discussion by the Giants user from San Francisco versus the Giants from New York, or the context, for example, only one of the teams has a schedule games coming soon.
[052] В некоторых реализациях, если на основе этих факторов конкретный предлагаемый диалоговый ответ оценивается низко, например, предлагаемый диалоговый ответ не удовлетворяет конкретной пороговой оценке, то механизм ведения диалога может дисквалифицировать не только тот предлагаемый диалоговый ответ, но также и любые другие предлагаемые диалоговые ответы, которые относятся к этому предлагаемому диалоговому ответу. В некоторых реализациях, если оценки от двух или более поставщиков данных не отличаются на заданную пороговую величину, то механизм ведения диалога в качестве диалогового ответа может формировать вопрос устранения неоднозначности намерения.[052] In some implementations, if based on these factors a specific proposed dialogue response is rated low, for example, the proposed dialogue response does not satisfy a specific threshold assessment, then the dialogue mechanism may disqualify not only that proposed dialogue response, but also any other proposed dialogue Answers that relate to this proposed dialog answer. In some implementations, if the estimates from two or more data providers do not differ by a predetermined threshold value, then the dialogue mechanism may form the question of disambiguation of intent as a dialog answer.
[053] Система предоставляет выбранный диалоговый ответ пользовательскому устройству (210) и обновляет состояние диалога (212). Диалоговый ответ, отправленный пользовательскому устройству, может включать в себя DTI выбранного диалогового ответа, который указывает ответ, который нужно показать пользователю на пользовательском устройстве. Этот ответ можно синтезировать в голосовой ответ или показать в интерфейсе пользователя пользовательского устройства. В некоторых реализациях ответ отправляется вместе с дополнительной информацией, например, одним или более результатами поиска, ассоциированными с диалоговым ответом. Например, если диалоговый ответ основывается на поиске поставщика данных или релевантных веб-страницах, то вместе с диалоговым ответом можно предоставить ссылку на те веб-страницы.[053] The system provides the selected dialog response to the user device (210) and updates the dialog state (212). The dialog response sent to the user device may include a DTI of the selected dialog response that indicates the response to be shown to the user on the user device. This response can be synthesized into a voice response or shown in the user interface of the user device. In some implementations, the response is sent along with additional information, for example, one or more search results associated with a dialog response. For example, if a dialog response is based on a search for a data provider or relevant web pages, then along with the dialog response you can provide a link to those web pages.
[054] Обновленное состояние диалога может использоваться для определения следующей части диалога для отправки в ответ на принятые пользовательские ответы. Более того, обновленное состояние диалога может предоставить контекст для анализа последующего голосового ввода, принятого от пользовательского устройства, так что голосовой ввод можно интерпретировать должным образом.[054] The updated dialog state may be used to determine the next part of the dialog to be sent in response to received user responses. Moreover, the updated dialog state can provide context for analyzing the subsequent voice input received from the user device, so that voice input can be interpreted properly.
[055] Система завершает запрос, когда подходящие диалоги завершены (214).[055] The system terminates the request when suitable conversations are completed (214).
[056] Система может определить, необходимы ли дополнительные значения, или завершен ли диалог. Если необходимы дополнительные значения, то один или более дополнительных DTI можно отправить пользовательскому устройству, либо система может подождать дополнительные ответы от пользовательского устройства. Если никакие дополнительные значения не нужны, то система может завершить задачу, например, путем формирования записи календаря или сообщения электронной почты либо путем предоставления конкретной запрошенной информации. Завершенную задачу можно отправить пользовательскому устройству для одобрения перед исполнением, либо ее можно выполнить автоматически.[056] The system can determine if additional values are needed, or whether the dialog has been completed. If additional values are needed, one or more additional DTIs can be sent to the user device, or the system can wait for additional responses from the user device. If no additional values are needed, the system can complete the task, for example, by creating a calendar entry or an e-mail message or by providing the specific information requested. The completed task can be sent to the user device for approval before execution, or it can be performed automatically.
[057] Имеется некоторое количество разных способов, которыми система может интерпретировать входные данные на основе предложений от разных поставщиков данных и применяемой оценки. Нижеследующее описывает некоторые примерные сценарии для интерпретирования пользовательского ввода:[057] There are a number of different ways in which the system can interpret input data based on suggestions from different data providers and the assessment applied. The following describes some exemplary scenarios for interpreting user input:
[058] Сценарий 1:[058] Scenario 1:
[059] Пользователь: [Установить будильник][059] User: [Set alarm]
[060] Система/устройство: В котором часу вы желаете установить будильник?[060] System / device: What time do you want to set the alarm?
[061] Пользователь: [В какое время начинается игра Giants?][061] User: [At what time does the Giants play begin?]
[062] В этом примере поставщики данных могут включать в себя поставщика задач, поставщика спортивных игр и поставщика веб-ответов. Если система определяет, что диалоговые предложения от поставщиков спортивных игр и веб-данных шумные, то эти ответы не следует одобрять, и диалогом должен руководить поставщик задач, который уже инициирован. Это может привести к ответу типа:[062] In this example, data providers may include a task provider, a sports game provider, and a web response provider. If the system determines that the interactive offers from the suppliers of sports games and web data are noisy, then these answers should not be approved, and the task provider, which has already been initiated, should guide the dialogue. This may lead to an answer like:
[063] Система/устройство: Извините, это непонятно. В котором часу вы желаете установить будильник?[063] System / device: Sorry, this is not clear. What time do you want to set the alarm?
[064] Сценарий 2:[064] Scenario 2:
[065] В этом сценарии пользователь задает побочный вопрос, потому что хочет посмотреть игру Giants. На этот раз у системы больше уверенности в веб-ответах, что отражено в оценке для соответствующего предлагаемого диалогового ответа, и поэтому они выбираются в сравнении с поставщиком спортивных игр и поставщиком задач для создания смешанного диалога:[065] In this scenario, the user asks a side question because he wants to watch a Giants game. This time, the system has more confidence in the web responses, which is reflected in the assessment for the corresponding proposed dialogue response, and therefore they are selected in comparison with the supplier of sports games and the supplier of tasks to create a mixed dialogue:
[066] Пользователь: [Установить будильник][066] User: [Set alarm]
[067] Система/устройство: В котором часу вы желаете установить будильник?[067] System / device: What time do you want to set the alarm?
[068] Пользователь: [В какое время начинается игра Giants?][068] User: [At what time does the Giants play begin?]
[069] Система/устройство: На основе нижеследующих результатов игра Giants начинается сегодня в 15 ч. Установить будильник на это время?[069] System / device: Based on the following results, the Giants game starts today at 15:00. Set the alarm for this time?
[070] Сценарий 3:[070] Scenario 3:
[071] Аналогичен сценарию 2 за исключением того, что механизм ведения диалога синтезирует новый вопрос для определения, намеревался ли пользователь поменять тематику, либо он по-прежнему заинтересован в исходной задаче:[071] Similar to Scenario 2, except that the dialogue engine synthesizes a new question to determine if the user intended to change the subject or is still interested in the original task:
[072] Пользователь: [Установить будильник][072] User: [Set alarm]
[073] Система/устройство: В котором часу вы желаете установить будильник?[073] System / device: What time do you want to set the alarm?
[074] Пользователь: [В какое время начинается игра Giants?][074] User: [At what time does the Giants play begin?]
[075] Система/устройство: На основе нижеследующих результатов игра Giants начинается сегодня в 15 ч. Все еще желаете установить будильник?[075] System / device: Based on the following results, the Giants game starts today at 3 pm Do you still want to set the alarm?
[076] Сценарий 4:[076] Scenario 4:
[077] В сценарии 4 пользователь задает побочный вопрос, потому что хочет посмотреть игру Giants. Даже если поставщик веб-ответов предоставляет время в качестве предлагаемого ответа, система дает возможность предложению поставщика спортивных игр, которое оценено выше, устранить неопределенность и подтвердить правильную сущность. Сохраняя намерение установить будильник, может происходить следующий смешанный диалог:[077] In Scenario 4, the user asks a side question because he wants to watch the Giants game. Even if the web response provider provides time as the proposed response, the system allows the sports game vendor, which is rated higher, to suggest uncertainty and confirm the correct entity. Keeping the intention to set the alarm, the following mixed dialog can occur:
[078] Пользователь: [Установить будильник][078] User: [Set alarm]
[079] Система/устройство: В котором часу вы желаете установить будильник?[079] System / device: What time do you want to set the alarm?
[080] Пользователь: [В какое время начинается игра Giants?][080] User: [At what time does the Giants play begin?]
[081] Система/устройство: Вы имеете в виду Giants из Сан-Франциско или Giants из Нью-Йорка?[081] System / Device: Do you mean Giants from San Francisco or Giants from New York?
[082] Пользователь: [Giants из Сан-Франциско][082] User: [Giants from San Francisco]
[083] Система/устройство: На основе нижеследующих результатов Giants из Сан-Франциско играют в 15 ч. Установить будильник на это время?[083] System / device: Based on the following results, the Giants from San Francisco play at 3 pm. Set the alarm for this time?
[084] Сценарий 5:[084] Scenario 5:
[085] В этом сценарии пользователь меняет тему и уже не желает устанавливать будильник. Здесь механизм ведения диалога уверен, что поставщик веб-ответов, идентифицирующий время игры Giants, оценивается выше, чем другие предлагаемые диалоговые ответы, и не предлагает будильник, который продолжает прежнюю задачу.[085] In this scenario, the user changes the subject and no longer wants to set the alarm. Here, the dialogue engine is confident that the provider of web responses that identifies the time of the Giants game is rated higher than the other suggested interactive responses, and does not offer an alarm clock that continues the previous task.
[086] Пользователь: [Установить будильник][086] User: [Set alarm]
[087] Система/устройство: В котором часу вы желаете установить будильник?[087] System / Device: At what time do you want to set the alarm?
[088] Пользователь: [В какое время начинается игра Giants?][088] User: [At what time does the Giants play begin?]
[089] Система/устройство: На основе нижеследующих результатов игра Giants начинается сегодня в 15 ч.[089] System / Device: Based on the following results, the Giants game begins today at 3 pm
[090] Сценарий 6:[090] Scenario 6:
[091] В этом сценарии пользователь меняет тему и уже не желает устанавливать будильник. Механизм ведения диалога использует предложение с наивысшей оценкой от поставщика данных спортивных игр, чтобы прояснить сущность, а затем веб-ответы, чтобы идентифицировать время. Не предлагается никакого будильника.[091] In this scenario, the user changes the subject and no longer wants to set the alarm. The dialogue engine uses the highest-rated bid from the sports game data provider to clarify the essence and then the web responses to identify the time. No alarm clock is offered.
[092] Пользователь: [Установить будильник][092] User: [Set Alarm]
[093] Система/устройство: В котором часу вы желаете установить будильник?[093] System / Device: At what time do you want to set the alarm?
[094] Пользователь: [В какое время начинается игра Giants?][094] User: [At what time does the Giants play begin?]
[095] Система/устройство: Вы имеете в виду Giants из Сан-Франциско или Giants из Нью-Йорка?[095] System / Device: Do you mean Giants from San Francisco or Giants from New York?
[096] Пользователь: [Giants из Сан-Франциско][096] User: [Giants from San Francisco]
[097] Система/устройство: На основе нижеследующих результатов игра Giants начинается сегодня в 15 ч.[097] System / Device: Based on the following results, the Giants game begins today at 3 pm
[098] Сценарий 7:[098] Scenario 7:
[099] В этом сценарии механизм ведения диалога может синтезировать вопрос, чтобы устранить неоднозначность в том, меняет ли пользователь тему или задает побочный вопрос. Это может происходить потому, что два или более предлагаемых ответов оценены слишком похоже, чтобы определить, какой следует предпочесть.[099] In this scenario, the dialogue engine may synthesize a question to eliminate the ambiguity of whether the user changes the subject or asks a side question. This may occur because two or more of the proposed responses are judged too similar to determine which one should be preferred.
[0100] Пользователь: [Установить будильник][0100] User: [Set alarm]
[0101] Система/устройство: В котором часу вы желаете установить будильник?[0101] System / device: What time do you want to set the alarm?
[0102] Пользователь: [В какое время начинается игра Giants?][0102] User: [At what time does the Giants play begin?]
[0103] Система/устройство: Погодите, вы желаете завершить настройку будильника или пытаетесь запланировать будильник накануне игры?[0103] System / device: Wait, do you want to finish setting the alarm, or are you trying to schedule an alarm before the game?
[0104] В каждом из этих сценариев различные поставщики данных предлагают один или более диалоговых ответов на основе пользовательского ввода. Более того, поставщики данных могут предложить множество диалоговых ответов на основе предлагаемых диалоговых ответов других поставщиков данных.[0104] In each of these scenarios, various data providers offer one or more interactive responses based on user input. Moreover, data providers can offer a variety of dialog responses based on the proposed dialog responses from other data providers.
[0105] Ссылаясь на примерные сценарии выше, поставщик задач может предоставить предлагаемый диалоговый ответ "Извините, это непонятно. В котором часу вы желаете установить будильник?". Это соответствует вышеприведенному сценарию 1.[0105] Referring to the sample scenarios above, the task provider can provide a suggested interactive response, “Sorry, this is not clear. At what time do you want to set the alarm?”. This corresponds to the above scenario 1.
[0106] Когда поставщик задач узнает, что предлагаемый диалоговый ответ был отправлен поставщиком веб-ответов, поставщик задач может формировать другой предлагаемый диалоговый ответ, который относится к предлагаемому веб-ответами диалоговому ответу с дополнительным содержимым "Установить будильник на это время?". Это соответствует вышеприведенному сценарию 2.[0106] When the task provider finds out that the proposed dialog response has been sent by the web response provider, the task provider can generate another proposed dialog response that relates to the dialog response offered by the web responses with the additional content "Set an alarm for this time?". This corresponds to the above scenario 2.
[0107] Когда поставщик задач узнает, что предлагаемый диалоговый ответ был отправлен поставщиком веб-ответов, поставщик задач может формировать другой предлагаемый диалоговый ответ, который относится к предлагаемому веб-ответами диалоговому ответу с дополнительным содержимым "Все еще желаете установить будильник?". Это соответствует вышеприведенному сценарию 3.[0107] When the task provider finds out that the proposed dialog response has been sent by the web response provider, the task provider may generate another proposed dialog response that relates to the dialog response offered by the web responses with additional content "Do you still want to set the alarm?". This corresponds to the above scenario 3.
[0108] Когда поставщик задач узнает, что предлагаемый диалоговый ответ был отправлен поставщиком данных спортивных игр, чтобы устранить неоднозначность у сущности, поставщик задач может формировать другой предлагаемый диалоговый ответ, который относится к предлагаемому спортивными ответами диалоговому ответу с дополнительным содержимым "Установить будильник на это время?". Это соответствует вышеприведенному сценарию 4.[0108] When the task provider finds out that the proposed interactive response has been sent by the sports game data provider, in order to eliminate ambiguity in the entity, the task provider can form another proposed interactive response that relates to the interactive response offered by the sports answers with the additional content "Set an alarm time?". This corresponds to the above scenario 4.
[0109] Различные предлагаемые диалоговые ответы от каждого из поставщиков данных оцениваются в соответствии с одним или более факторами. На основе оценки механизм ведения диалога может выбрать подходящий диалоговый ответ. Ссылаясь опять на примерные сценарии выше, тот механизм ведения диалога может на основе соответствующих оценок:[0109] The various proposed dialog responses from each of the data providers are evaluated according to one or more factors. Based on the evaluation, the dialogue mechanism can select the appropriate dialogue response. Referring again to the exemplary scenarios above, that dialogue mechanism can, based on appropriate assessments:
[0110] A) Выбрать предлагаемый диалоговый ответ от поставщика задач (сценарий 1)[0110] A) Select the proposed interactive response from the task provider (scenario 1)
[0111] B) Выбрать альтернативный предлагаемый диалоговый ответ от поставщика задач, а также принять предлагаемый диалоговый ответ от поставщика веб-ответов (сценарий 2)[0111] B) Select an alternative proposed interactive response from the task provider, and also accept the proposed interactive response from the web response provider (Scenario 2)
[0112] C) Выбрать альтернативный предлагаемый диалоговый ответ от поставщика задач, а также принять альтернативный предлагаемый диалоговый ответ от поставщика веб-ответов (сценарий 3)[0112] C) Select an alternative proposed interactive response from the task provider, and also accept an alternative proposed interactive response from the web response provider (Scenario 3)
[0113] D) Выбрать альтернативный предлагаемый диалоговый ответ от поставщика задач, а также принять предлагаемый диалоговый ответ от поставщика данных спортивных игр (сценарий 4)[0113] D) Select an alternative proposed interactive response from the task provider, and also accept the proposed interactive response from the provider of the sports data data (scenario 4)
[0114] E) Выбрать предлагаемый диалоговый ответ от поставщика веб-ответов и полностью сбросить состояние будильника (сценарий 5)[0114] E) Select the proposed dialog response from the web response provider and completely reset the alarm state (scenario 5)
[0115] F) Выбрать предлагаемый диалоговый ответ от поставщика данных спортивных игр и полностью сбросить состояние будильника (сценарий 6)[0115] F) Select the proposed interactive response from the sports data provider and completely reset the alarm state (scenario 6)
[0116] G) Сформировать полностью новый предлагаемый диалоговый ответ, чтобы спросить пользователя о его намерении (сценарий 7). Например, если оценки от поставщиков данных не отличаются на пороговую величину.[0116] G) Generate a completely new proposed interactive response to ask the user about his intention (scenario 7). For example, if the estimates from the data providers do not differ by the threshold.
[0117] Исключение предлагаемого диалогового ответа может отразиться на других предлагаемых диалоговых ответах, которые к нему относятся. Таким образом, если предлагаемый диалоговый ответ от поставщика веб-ответов имеет дисквалифицирующую оценку, то исключается не только сценарий 5, но также сценарии 2 и 3. В некоторых реализациях при оценке также может использоваться географическая информация. Например, используя географическую информацию для указания, на каких Giants ссылается пользователь (Сан-Франциско в отличие от Нью-Йорка), предлагаемый поставщиком данных спортивных игр ответ можно скрыть, чтобы исключить не только сценарий 6, но также сценарий 4.[0117] The exclusion of the proposed dialog response may affect other proposed dialog responses that relate to it. Thus, if the proposed online response from the web response provider has a disqualifying rating, then not only scenario 5 is excluded, but also scenarios 2 and 3. In some implementations, geographic information can also be used in the assessment. For example, using geographic information to indicate which Giants the user is referring to (San Francisco unlike New York), the answer offered by the sports data provider can be hidden to exclude not only scenario 6, but also scenario 4.
[0118] Варианты осуществления изобретения и операций, описанных в данном описании изобретения, можно реализовать в цифровых электронных схемах либо в компьютерном программном обеспечении, микропрограммном обеспечении или аппаратных средствах, включая раскрытые в данном описании изобретения структуры и их структурные эквиваленты, либо в сочетаниях одного или более из них. Варианты осуществления объекта изобретения, описанного в данном описании изобретения, можно реализовать в виде одной или более компьютерных программ, то есть одного или более модулей из команд компьютерной программы, кодированных на компьютерном носителе информации для исполнения устройством обработки данных или для управления его работой. В качестве альтернативы или дополнительно команды программы могут кодироваться в искусственно сформированном распространяемом сигнале, например, сформированном машиной электрическом, оптическом или электромагнитном сигнале, который формируется, чтобы кодировать информацию для передачи подходящему приемному устройству для исполнения устройством обработки данных. Компьютерный носитель информации может быть или включаться в машиночитаемое запоминающее устройство, машиночитаемую основу хранения, матрицу или устройство памяти с произвольным или последовательным доступом либо сочетание одного или более из них. Кроме того, хотя компьютерный носитель информации не является распространяемым сигналом, компьютерный носитель информации может быть источником или назначением команд компьютерной программы, кодированных в искусственно сформированном распространяемом сигнале. Компьютерный носитель информации также может быть или включаться в один или более отдельных физических компонентов или носителей (например, множество CD, дисков или других запоминающих устройств).[0118] Embodiments of the invention and the operations described in this description of the invention can be implemented in digital electronic circuits or in computer software, firmware or hardware, including the structures disclosed in this description of the invention and their structural equivalents, or in combinations of one or more of them. Embodiments of the object of the invention described in this description of the invention can be implemented in one or more computer programs, that is, one or more modules of computer program instructions encoded on a computer storage medium for execution by a processing unit or for controlling its operation. Alternatively or additionally, program instructions may be encoded in an artificially generated propagated signal, for example, a machine-generated electrical, optical, or electromagnetic signal that is generated to encode information for transmission to a suitable receiving device for execution by the processing unit. The computer storage medium may or may be included in a computer-readable storage device, a computer-readable storage base, a matrix or memory device with random or sequential access, or a combination of one or more of them. In addition, although the computer storage medium is not a propagated signal, the computer storage medium may be the source or destination of computer program commands encoded in an artificially generated propagated signal. The computer storage medium may also be or be included in one or more separate physical components or media (for example, multiple CDs, discs, or other storage devices).
[0119] Описанные в данном описании изобретения операции можно реализовать как операции, выполняемые устройством обработки данных над данными, сохраненными в одном или более машиночитаемых запоминающих устройствах или принятыми из других источников.[0119] The operations described in this specification can be implemented as operations performed by a data processing device on data stored in one or more computer-readable storage devices or received from other sources.
[0120] Термин "устройство обработки данных" включает в себя все виды устройств и машин для обработки данных, включая, в качестве примера, программируемый процессор, компьютер, систему на кристалле или их множество, либо сочетания вышеупомянутого. Устройство может включать в себя специализированные логические схемы, например, FPGA (программируемая пользователем вентильная матрица) или ASIC (специализированная интегральная схема). Устройство в дополнение к аппаратным средствам также может включать в себя код, который создает среду выполнения для компьютерной программы, о которой идет речь, например, код, который составляет микропрограммное обеспечение процессора, стек протоколов, систему управления базами данных, операционную систему, межплатформенную среду исполнения, виртуальную машину или сочетание одного или более из них. Устройство и среда выполнения могут реализовать различные инфраструктуры моделей вычислений, например, инфраструктуры веб-служб, распределенных вычислений и коллективных вычислений.[0120] The term "data processing device" includes all kinds of data processing devices and machines, including, by way of example, a programmable processor, a computer, a system on a chip, or a variety of them, or combinations of the above. The device may include specialized logic circuits, such as an FPGA (user-programmable gate array) or ASIC (specialized integrated circuit). The device, in addition to the hardware, may also include code that creates the runtime for the computer program in question, for example, the code that makes up the processor firmware, protocol stack, database management system, operating system, cross-platform execution environment virtual machine or a combination of one or more of them. The device and runtime can implement various computing model infrastructures, such as web services infrastructure, distributed computing, and collective computing.
[0121] Компьютерная программа (также известная как программа, программное обеспечение, программное приложение, сценарий или код) может быть написана на любом виде языка программирования, включая компилируемые или интерпретируемые языки, декларативные или процедурные языки, и она может быть развернута в любом виде, включая автономную программу или модуль, компонент, подпрограмму, объект или другую единицу, подходящую для использования в вычислительной среде. Компьютерная программа может, но не должна, соответствовать файлу в файловой системе. Программа может храниться в части файла, который хранит другие программы или данные (например, один или более сценариев, сохраненных в документе на языке разметки), в одном файле, выделенном для программы, о которой идет речь, или в множестве согласованных файлов (например, файлах, которые хранят один или более модулей, подпрограмм или частей кода). Компьютерная программа может быть развернута для исполнения на одном компьютере или на множестве компьютеров, которые располагаются на одной площадке или распределены по множеству площадок и взаимосвязаны с помощью сети связи.[0121] A computer program (also known as a program, software, software application, script, or code) can be written in any kind of programming language, including compiled or interpreted languages, declarative or procedural languages, and it can be deployed in any form, including a standalone program or module, component, subroutine, object, or other unit suitable for use in a computing environment. A computer program can, but does not have to, match the file in the file system. A program may be stored in a part of a file that stores other programs or data (for example, one or more scripts stored in a markup language document) in a single file dedicated to the program in question, or in a number of matched files (for example, files that store one or more modules, subroutines, or pieces of code). A computer program can be deployed to run on a single computer or on multiple computers that are located on the same site or distributed across multiple sites and interconnected via a communications network.
[0122] Процессы и логические потоки, описанные в данном описании изобретения, могут выполняться одним или более программируемыми процессорами, исполняющими одну или более компьютерных программ для выполнения действий путем воздействия на входные данные и формирования вывода. Процессы и логические потоки также могут выполняться специализированными логическими схемами, например, FPGA (программируемая пользователем вентильная матрица) или ASIC (специализированная интегральная схема), и устройство также может быть реализовано в виде специализированных логических схем.[0122] The processes and logic flows described in this specification may be executed by one or more programmable processors executing one or more computer programs for performing actions by affecting the input data and generating the output. Processes and logic flows can also be performed by specialized logic circuits, for example, FPGA (user-programmable gate array) or ASIC (specialized integrated circuit), and the device can also be implemented as specialized logic circuits.
[0123] Процессоры, подходящие для исполнения компьютерной программы, в качестве примера включают в себя как универсальные, так и специализированные микропроцессоры и любой один или более процессоров в любом виде цифрового компьютера. Как правило, процессор будет принимать команды и данные из постоянного запоминающего устройства или оперативного запоминающего устройства, либо из обоих. Неотъемлемыми элементами компьютера являются процессор для выполнения действий в соответствии с командами и одно или более запоминающих устройств для хранения команд и данных. Как правило, компьютер также будет включать в себя, или функционально соединяться для приема данных или передачи данных, либо того и другого, одно или более запоминающих устройств большой емкости для хранения данных, например, магнитные, магнитооптические диски или оптические диски. Однако компьютеру не обязательно содержать такие устройства. Кроме того, компьютер может быть встроен в другое устройство, например, назовем только несколько, мобильный телефон, персональный цифровой помощник (PDA), мобильный аудио- или видеопроигрыватель, игровую приставку, приемник системы глобального позиционирования (GPS) или портативное запоминающее устройство (например, флэш-накопитель на универсальной последовательной шине (USB)). Устройства, подходящие для хранения команд компьютерной программы и данных, включают в себя все виды энергонезависимого запоминающего устройства, носителей и запоминающих устройств, в качестве примера включающих в себя полупроводниковые запоминающие устройства, например EPROM, EEPROM, и устройства на флэш-памяти; магнитные диски, например внутренние жесткие диски или съемные диски; магнитооптические диски; и диски CD-ROM и DVD-ROM. Процессор и запоминающее устройство могут дополняться специализированными логическими схемами либо включаться в них.[0123] Processors suitable for executing a computer program include, as an example, both universal and specialized microprocessors and any one or more processors in any kind of digital computer. Typically, the processor will receive commands and data from either read-only memory or random access memory, or from both. The integral elements of the computer are the processor for performing actions in accordance with the instructions and one or more memory devices for storing instructions and data. Typically, the computer will also include, or functionally, connect to receive data or transmit data, or both, one or more mass storage devices for data storage, such as magnetic, magneto-optical disks or optical disks. However, the computer does not need to contain such devices. In addition, a computer can be embedded in another device, for example, call only a few, a mobile phone, a personal digital assistant (PDA), a mobile audio or video player, a game console, a global positioning receiver (GPS) receiver or a portable storage device (for example, flash drive on universal serial bus (USB)). Devices suitable for storing computer program commands and data include all types of non-volatile memory, media, and storage devices, including semiconductor memory devices such as EPROM, EEPROM, and flash memory devices as an example; magnetic disks, such as internal hard drives or removable disks; magneto-optical disks; and CD-ROM and DVD-ROM. The processor and the storage device can be supplemented with specialized logic circuits or included in them.
[0124] Чтобы предусмотреть взаимодействие с пользователем, варианты осуществления изобретения, описанного в данном описании изобретения, можно реализовать на компьютере с устройством отображения, например монитором CRT (электронно-лучевая трубка) или LCD (жидкокристаллический дисплей), для отображения информации пользователю и клавиатурой и указательным устройством, например мышью или шаровым манипулятором, с помощью которого пользователь может предоставить компьютеру входные данные. Другие виды устройств с тем же успехом могут использоваться для обеспечения взаимодействия с пользователем; например, обратная связь, предоставленная пользователю, может быть любым видом сенсорной обратной связи, например, визуальной обратной связью, звуковой обратной связью либо тактильной обратной связью; и входные данные от пользователя могут приниматься в любом виде, включая звуковой, речевой или тактильный ввод. К тому же компьютер может взаимодействовать с пользователем путем отправки документов и приема документов от устройства, которое используется пользователем; например, путем отправки веб-страниц в веб-обозреватель на клиентском устройстве пользователя в ответ на запросы, принятые от веб-обозревателя.[0124] To provide user interaction, embodiments of the invention described in this specification may be implemented on a computer with a display device, such as a CRT (cathode ray tube) or LCD (liquid crystal display) monitor, to display information to the user and the keyboard and pointing device, such as a mouse or trackball, with which the user can provide the computer with input data. Other types of devices can equally well be used to provide user interaction; for example, the feedback provided to the user can be any kind of sensory feedback, for example, visual feedback, audio feedback or tactile feedback; and user input can be received in any form, including audio, speech or tactile input. In addition, the computer can interact with the user by sending documents and receiving documents from the device that is used by the user; for example, by sending web pages to a web browser on a user's client device in response to requests received from a web browser.
[0125] Варианты осуществления изобретения, описанного в данном описании изобретения, можно реализовать в вычислительной системе, которая включает в себя внутренний компонент, например, в виде сервера данных, либо которая включает в себя промежуточный компонент, например сервер приложений, либо которая включает в себя внешний компонент, например клиентский компьютер с графическим интерфейсом пользователя или веб-обозревателем, посредством которых пользователь может взаимодействовать с реализацией изобретения, описанного в данном описании изобретения, либо любое сочетание одного или более таких внутренних, промежуточных или внешних компонентов. Компоненты системы могут быть взаимосвязаны с помощью любой формы или среды цифровой передачи данных, например, с помощью сети связи. Примеры сетей связи включают в себя локальную сеть ("LAN") и глобальную сеть ("WAN"), сетевой комплекс (например, Интернет) и одноранговые сети (например, произвольные одноранговые сети).[0125] Embodiments of the invention described in this specification may be implemented in a computing system that includes an internal component, for example, as a data server, or that includes an intermediate component, such as an application server, or that includes an external component, such as a client computer with a graphical user interface or a web browser, through which the user can interact with the implementation of the invention described in this described and inventions, or any combination of one or more such internal, intermediate or external components. System components can be interconnected using any form or medium of digital data transmission, for example, using a communication network. Examples of communication networks include a local area network (“LAN”) and a wide area network (“WAN”), a network complex (eg, the Internet) and peer-to-peer networks (eg, arbitrary peer-to-peer networks).
[0126] Вычислительная система может включать в себя клиенты и серверы. Клиент и сервер обычно удалены друг от друга и обычно взаимодействуют по сети связи. Взаимосвязь клиента и сервера происходит посредством компьютерных программ, работающих на соответствующих компьютерах и имеющих клиент-серверную связь друг с другом. В некоторых вариантах осуществления сервер передает данные (например, HTML-страницу) клиентскому устройству (например, с целью отображения данных и приема пользовательского ввода от пользователя, взаимодействующего с клиентским устройством). Данные, сформированные на клиентском устройстве (например, результат взаимодействия с пользователем), могут приниматься на сервере от клиентского устройства.[0126] The computing system may include clients and servers. The client and server are usually remote from each other and usually interact over a communication network. The relationship between the client and the server occurs through computer programs running on the respective computers and having client-server communication with each other. In some embodiments, the server transmits data (eg, an HTML page) to the client device (eg, to display data and receive user input from a user interacting with the client device). Data generated on the client device (for example, the result of user interaction) can be received on the server from the client device.
[0127] Хотя данное описание изобретения содержит многие специфические подробности реализации, эти подробности не следует толковать как ограничения объема любых изобретений или того, что может быть заявлено, а скорее как описания признаков, характерных для конкретных вариантов осуществления конкретных изобретений. Некоторые признаки, которые описываются в данном описании изобретения применительно к отдельным вариантам осуществлениям, также можно реализовать вместе в одном варианте осуществления. Наоборот, различные признаки, которые описываются применительно к одному варианту осуществления, также можно реализовать в множестве вариантов осуществления, отдельно или в любой подходящей субкомбинации. Кроме того, хотя признаки могут описываться выше как действующие в некоторых сочетаниях и даже сначала заявляться как таковые, один или более признаков из заявленного сочетания в некоторых случаях могут исключаться из сочетания, и заявленное сочетание может относиться к субкомбинации или разновидности субкомбинации.[0127] Although this description of the invention contains many specific implementation details, these details should not be interpreted as limiting the scope of any inventions or what may be stated, but rather as descriptions of features specific to specific embodiments of specific inventions. Some of the features that are described in this specification with reference to individual embodiments may also be implemented together in one embodiment. Conversely, various features that are described with reference to one embodiment can also be implemented in a variety of embodiments, separately or in any suitable subcombination. In addition, although the features may be described above as acting in some combinations, and even first stated as such, one or more features from the claimed combination may in some cases be excluded from the combination, and the claimed combination may refer to a sub-combination or a sub-combination.
[0128] Аналогичным образом, хотя операции изображаются на чертежах в конкретном порядке, это не следует понимать как требование того, что для достижения желаемых результатов такие операции должны выполняться в конкретном показанном порядке или в последовательном порядке, или что должны выполняться все проиллюстрированные операции. В некоторых обстоятельствах могут быть полезны многозадачность и параллельная обработка. Кроме того, разделение различных компонентов системы в описанных выше вариантах осуществления не следует понимать как требование такого разделения во всех вариантах осуществления, а следует понимать так, что описанные компоненты программ и систем обычно можно объединять в единый программный продукт или укомплектовать в множество программных продуктов.[0128] Similarly, although operations are depicted in the drawings in a specific order, this should not be understood as requiring that such operations must be performed in the particular order shown or in sequential order to achieve the desired results, or that all the illustrated operations must be performed. In some circumstances, multitasking and parallel processing may be helpful. In addition, the separation of the various components of the system in the embodiments described above should not be understood as a requirement for such separation in all the embodiments, but it should be understood that the described components of the programs and systems can usually be combined into a single software product or bundled into a plurality of software products.
[0129] Таким образом, описаны конкретные варианты осуществления изобретения. Другие варианты осуществления входят в объем, определяемый нижеследующей формулой изобретения. В некоторых случаях перечисленные в формуле изобретения действия могут выполняться в ином порядке и, тем не менее, добиваться желаемых результатов. К тому же изображенные на прилагаемых чертежах процессы не обязательно требуют конкретного показанного порядка или последовательного порядка для достижения желаемых результатов. В некоторых реализациях могут быть полезны многозадачность и параллельная обработка.[0129] Thus, specific embodiments of the invention have been described. Other embodiments are included in the scope defined by the following claims. In some cases, the actions listed in the claims may be carried out in a different order and, nevertheless, achieve the desired results. In addition, the processes depicted in the accompanying drawings do not necessarily require the particular order or sequential order shown to achieve the desired results. In some implementations multitasking and parallel processing may be useful.
Claims (42)
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/815,794 US10255921B2 (en) | 2015-07-31 | 2015-07-31 | Managing dialog data providers |
US14/815,794 | 2015-07-31 | ||
PCT/US2016/044864 WO2017023807A1 (en) | 2015-07-31 | 2016-07-29 | Managing dialog data providers |
Publications (1)
Publication Number | Publication Date |
---|---|
RU2690199C1 true RU2690199C1 (en) | 2019-05-31 |
Family
ID=56616091
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
RU2017142336A RU2690199C1 (en) | 2015-07-31 | 2016-07-29 | Managing data providers for dialogue |
Country Status (5)
Country | Link |
---|---|
US (4) | US10255921B2 (en) |
EP (1) | EP3329395A1 (en) |
CN (2) | CN114595316A (en) |
RU (1) | RU2690199C1 (en) |
WO (1) | WO2017023807A1 (en) |
Families Citing this family (101)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US8677377B2 (en) | 2005-09-08 | 2014-03-18 | Apple Inc. | Method and apparatus for building an intelligent automated assistant |
US9318108B2 (en) | 2010-01-18 | 2016-04-19 | Apple Inc. | Intelligent automated assistant |
US8977255B2 (en) | 2007-04-03 | 2015-03-10 | Apple Inc. | Method and system for operating a multi-function portable electronic device using voice-activation |
US8676904B2 (en) | 2008-10-02 | 2014-03-18 | Apple Inc. | Electronic devices with voice command and contextual data processing capabilities |
US10706373B2 (en) | 2011-06-03 | 2020-07-07 | Apple Inc. | Performing actions associated with task items that represent tasks to perform |
US10276170B2 (en) | 2010-01-18 | 2019-04-30 | Apple Inc. | Intelligent automated assistant |
US8682667B2 (en) | 2010-02-25 | 2014-03-25 | Apple Inc. | User profiling for selecting user specific voice input processing information |
US10417037B2 (en) | 2012-05-15 | 2019-09-17 | Apple Inc. | Systems and methods for integrating third party services with a digital assistant |
CN104969289B (en) | 2013-02-07 | 2021-05-28 | 苹果公司 | Voice trigger of digital assistant |
US10652394B2 (en) | 2013-03-14 | 2020-05-12 | Apple Inc. | System and method for processing voicemail |
US10748529B1 (en) | 2013-03-15 | 2020-08-18 | Apple Inc. | Voice activated device for use with a voice-based digital assistant |
US10813584B2 (en) * | 2013-05-21 | 2020-10-27 | Happify, Inc. | Assessing adherence fidelity to behavioral interventions using interactivity and natural language processing |
US10176167B2 (en) | 2013-06-09 | 2019-01-08 | Apple Inc. | System and method for inferring user intent from speech inputs |
KR101959188B1 (en) | 2013-06-09 | 2019-07-02 | 애플 인크. | Device, method, and graphical user interface for enabling conversation persistence across two or more instances of a digital assistant |
US10296160B2 (en) | 2013-12-06 | 2019-05-21 | Apple Inc. | Method for extracting salient dialog usage from live data |
US10170123B2 (en) | 2014-05-30 | 2019-01-01 | Apple Inc. | Intelligent assistant for home automation |
US9430463B2 (en) | 2014-05-30 | 2016-08-30 | Apple Inc. | Exemplar-based natural language processing |
US9966065B2 (en) | 2014-05-30 | 2018-05-08 | Apple Inc. | Multi-command single utterance input method |
US9715875B2 (en) | 2014-05-30 | 2017-07-25 | Apple Inc. | Reducing the need for manual start/end-pointing and trigger phrases |
US9338493B2 (en) | 2014-06-30 | 2016-05-10 | Apple Inc. | Intelligent automated assistant for TV user interactions |
US9668121B2 (en) | 2014-09-30 | 2017-05-30 | Apple Inc. | Social reminders |
US10127911B2 (en) | 2014-09-30 | 2018-11-13 | Apple Inc. | Speaker identification and unsupervised speaker adaptation techniques |
US10152299B2 (en) | 2015-03-06 | 2018-12-11 | Apple Inc. | Reducing response latency of intelligent automated assistants |
US9721566B2 (en) | 2015-03-08 | 2017-08-01 | Apple Inc. | Competing devices responding to voice triggers |
US9886953B2 (en) | 2015-03-08 | 2018-02-06 | Apple Inc. | Virtual assistant activation |
US10460227B2 (en) | 2015-05-15 | 2019-10-29 | Apple Inc. | Virtual assistant in a communication session |
US10200824B2 (en) | 2015-05-27 | 2019-02-05 | Apple Inc. | Systems and methods for proactively identifying and surfacing relevant content on a touch-sensitive device |
US10083688B2 (en) | 2015-05-27 | 2018-09-25 | Apple Inc. | Device voice control for selecting a displayed affordance |
US9578173B2 (en) | 2015-06-05 | 2017-02-21 | Apple Inc. | Virtual assistant aided communication with 3rd party service in a communication session |
US20160378747A1 (en) | 2015-06-29 | 2016-12-29 | Apple Inc. | Virtual assistant for media playback |
US10255921B2 (en) | 2015-07-31 | 2019-04-09 | Google Llc | Managing dialog data providers |
US10747498B2 (en) | 2015-09-08 | 2020-08-18 | Apple Inc. | Zero latency digital assistant |
US10331312B2 (en) | 2015-09-08 | 2019-06-25 | Apple Inc. | Intelligent automated assistant in a media environment |
US10671428B2 (en) | 2015-09-08 | 2020-06-02 | Apple Inc. | Distributed personal assistant |
US10740384B2 (en) | 2015-09-08 | 2020-08-11 | Apple Inc. | Intelligent automated assistant for media search and playback |
US10691473B2 (en) | 2015-11-06 | 2020-06-23 | Apple Inc. | Intelligent automated assistant in a messaging environment |
US10956666B2 (en) | 2015-11-09 | 2021-03-23 | Apple Inc. | Unconventional virtual assistant interactions |
US10223066B2 (en) | 2015-12-23 | 2019-03-05 | Apple Inc. | Proactive assistance based on dialog communication between devices |
US11227589B2 (en) | 2016-06-06 | 2022-01-18 | Apple Inc. | Intelligent list reading |
US10586535B2 (en) | 2016-06-10 | 2020-03-10 | Apple Inc. | Intelligent digital assistant in a multi-tasking environment |
DK179415B1 (en) | 2016-06-11 | 2018-06-14 | Apple Inc | Intelligent device arbitration and control |
DK201670540A1 (en) | 2016-06-11 | 2018-01-08 | Apple Inc | Application integration with a digital assistant |
US10606952B2 (en) | 2016-06-24 | 2020-03-31 | Elemental Cognition Llc | Architecture and processes for computer learning and understanding |
US10474753B2 (en) | 2016-09-07 | 2019-11-12 | Apple Inc. | Language identification using recurrent neural networks |
US11204787B2 (en) | 2017-01-09 | 2021-12-21 | Apple Inc. | Application integration with a digital assistant |
US10860628B2 (en) | 2017-02-16 | 2020-12-08 | Google Llc | Streaming real-time dialog management |
US10713289B1 (en) * | 2017-03-31 | 2020-07-14 | Amazon Technologies, Inc. | Question answering system |
US11003839B1 (en) * | 2017-04-28 | 2021-05-11 | I.Q. Joe, Llc | Smart interface with facilitated input and mistake recovery |
DK201770383A1 (en) | 2017-05-09 | 2018-12-14 | Apple Inc. | User interface for correcting recognition errors |
DK180048B1 (en) | 2017-05-11 | 2020-02-04 | Apple Inc. | MAINTAINING THE DATA PROTECTION OF PERSONAL INFORMATION |
US10395654B2 (en) | 2017-05-11 | 2019-08-27 | Apple Inc. | Text normalization based on a data-driven learning network |
US10726832B2 (en) | 2017-05-11 | 2020-07-28 | Apple Inc. | Maintaining privacy of personal information |
DK179496B1 (en) | 2017-05-12 | 2019-01-15 | Apple Inc. | USER-SPECIFIC Acoustic Models |
DK179745B1 (en) | 2017-05-12 | 2019-05-01 | Apple Inc. | SYNCHRONIZATION AND TASK DELEGATION OF A DIGITAL ASSISTANT |
KR102211675B1 (en) * | 2017-05-12 | 2021-02-04 | 애플 인크. | Synchronization and task delegation of a digital assistant |
US11301477B2 (en) | 2017-05-12 | 2022-04-12 | Apple Inc. | Feedback analysis of a digital assistant |
DK201770427A1 (en) | 2017-05-12 | 2018-12-20 | Apple Inc. | Low-latency intelligent automated assistant |
US10311144B2 (en) | 2017-05-16 | 2019-06-04 | Apple Inc. | Emoji word sense disambiguation |
DK179560B1 (en) | 2017-05-16 | 2019-02-18 | Apple Inc. | Far-field extension for digital assistant services |
US10303715B2 (en) | 2017-05-16 | 2019-05-28 | Apple Inc. | Intelligent automated assistant for media exploration |
US20180336892A1 (en) | 2017-05-16 | 2018-11-22 | Apple Inc. | Detecting a trigger of a digital assistant |
CN107967308B (en) * | 2017-11-16 | 2021-04-23 | 百度在线网络技术（北京）有限公司 | Intelligent interaction processing method, device, equipment and computer storage medium |
US10592604B2 (en) | 2018-03-12 | 2020-03-17 | Apple Inc. | Inverse text normalization for automatic speech recognition |
US11100146B1 (en) * | 2018-03-23 | 2021-08-24 | Amazon Technologies, Inc. | System management using natural language statements |
US10818288B2 (en) | 2018-03-26 | 2020-10-27 | Apple Inc. | Natural assistant interaction |
US11145294B2 (en) | 2018-05-07 | 2021-10-12 | Apple Inc. | Intelligent automated assistant for delivering content from user experiences |
US10928918B2 (en) | 2018-05-07 | 2021-02-23 | Apple Inc. | Raise to speak |
DK179822B1 (en) | 2018-06-01 | 2019-07-12 | Apple Inc. | Voice interaction at a primary device to access call functionality of a companion device |
DK180639B1 (en) | 2018-06-01 | 2021-11-04 | Apple Inc | DISABILITY OF ATTENTION-ATTENTIVE VIRTUAL ASSISTANT |
US10892996B2 (en) | 2018-06-01 | 2021-01-12 | Apple Inc. | Variable latency device coordination |
US11010561B2 (en) | 2018-09-27 | 2021-05-18 | Apple Inc. | Sentiment prediction from textual data |
US11462215B2 (en) | 2018-09-28 | 2022-10-04 | Apple Inc. | Multi-modal inputs for voice commands |
US11170166B2 (en) | 2018-09-28 | 2021-11-09 | Apple Inc. | Neural typographical error modeling via generative adversarial networks |
US10839159B2 (en) | 2018-09-28 | 2020-11-17 | Apple Inc. | Named entity normalization in a spoken dialog system |
US11037048B2 (en) * | 2018-10-22 | 2021-06-15 | Moveworks, Inc. | Virtual conversation method or system |
US11475898B2 (en) | 2018-10-26 | 2022-10-18 | Apple Inc. | Low-latency multi-speaker speech recognition |
US11638059B2 (en) | 2019-01-04 | 2023-04-25 | Apple Inc. | Content playback on multiple devices |
US11194796B2 (en) * | 2019-02-14 | 2021-12-07 | Microsoft Technology Licensing, Llc | Intuitive voice search |
US11348573B2 (en) | 2019-03-18 | 2022-05-31 | Apple Inc. | Multimodality in digital assistant systems |
US11307752B2 (en) | 2019-05-06 | 2022-04-19 | Apple Inc. | User configurable task triggers |
DK201970509A1 (en) | 2019-05-06 | 2021-01-15 | Apple Inc | Spoken notifications |
US11475884B2 (en) | 2019-05-06 | 2022-10-18 | Apple Inc. | Reducing digital assistant latency when a language is incorrectly determined |
US11423908B2 (en) | 2019-05-06 | 2022-08-23 | Apple Inc. | Interpreting spoken requests |
US11140099B2 (en) * | 2019-05-21 | 2021-10-05 | Apple Inc. | Providing message response suggestions |
US11496600B2 (en) | 2019-05-31 | 2022-11-08 | Apple Inc. | Remote execution of machine-learned models |
DK201970510A1 (en) | 2019-05-31 | 2021-02-11 | Apple Inc | Voice identification in digital assistant systems |
US11289073B2 (en) | 2019-05-31 | 2022-03-29 | Apple Inc. | Device text to speech |
EP3959714B1 (en) * | 2019-05-31 | 2024-04-17 | Apple Inc. | Voice identification in digital assistant systems |
DK180129B1 (en) | 2019-05-31 | 2020-06-02 | Apple Inc. | User activity shortcut suggestions |
US11227599B2 (en) | 2019-06-01 | 2022-01-18 | Apple Inc. | Methods and user interfaces for voice-based control of electronic devices |
US11360641B2 (en) | 2019-06-01 | 2022-06-14 | Apple Inc. | Increasing the relevance of new available information |
US11438452B1 (en) | 2019-08-09 | 2022-09-06 | Apple Inc. | Propagating context information in a privacy preserving manner |
US11488406B2 (en) | 2019-09-25 | 2022-11-01 | Apple Inc. | Text detection using global geometry estimators |
US11431658B2 (en) * | 2020-04-02 | 2022-08-30 | Paymentus Corporation | Systems and methods for aggregating user sessions for interactive transactions using virtual assistants |
US11061543B1 (en) | 2020-05-11 | 2021-07-13 | Apple Inc. | Providing relevant data items based on context |
US11043220B1 (en) | 2020-05-11 | 2021-06-22 | Apple Inc. | Digital assistant hardware abstraction |
US11755276B2 (en) | 2020-05-12 | 2023-09-12 | Apple Inc. | Reducing description length based on confidence |
US11490204B2 (en) | 2020-07-20 | 2022-11-01 | Apple Inc. | Multi-device audio adjustment coordination |
US11438683B2 (en) | 2020-07-21 | 2022-09-06 | Apple Inc. | User identification using headphones |
CN113297359B (en) * | 2021-04-23 | 2023-11-28 | 阿里巴巴新加坡控股有限公司 | Method and device for information interaction |
US11961516B1 (en) * | 2022-10-23 | 2024-04-16 | Conversation Processing Intelligence, Corp. | System and method for modifying operations of telecommunication devices using conversation processing |
Citations (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US8566102B1 (en) * | 2002-03-28 | 2013-10-22 | At&T Intellectual Property Ii, L.P. | System and method of automating a spoken dialogue service |
RU2012135502A (en) * | 2010-01-18 | 2014-02-27 | Эппл Инк. | PERSONALIZED DICTIONARY FOR DIGITAL ASSISTANT |
Family Cites Families (42)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6144989A (en) * | 1998-06-15 | 2000-11-07 | Dejima, Inc. | Adaptive agent-oriented software architecture |
EP1044416A1 (en) * | 1998-10-09 | 2000-10-18 | Scansoft, Inc. | Automatic inquiry method and system |
US6604075B1 (en) | 1999-05-20 | 2003-08-05 | Lucent Technologies Inc. | Web-based voice dialog interface |
US6990670B1 (en) * | 1999-11-05 | 2006-01-24 | Ianywhere Solutions, Inc. | Interpretation phase for adaptive agent oriented software architecture |
US6615172B1 (en) | 1999-11-12 | 2003-09-02 | Phoenix Solutions, Inc. | Intelligent query engine for processing voice based queries |
US8200485B1 (en) | 2000-08-29 | 2012-06-12 | A9.Com, Inc. | Voice interface and methods for improving recognition accuracy of voice search queries |
US7257537B2 (en) | 2001-01-12 | 2007-08-14 | International Business Machines Corporation | Method and apparatus for performing dialog management in a computer conversational interface |
US7987151B2 (en) * | 2001-08-10 | 2011-07-26 | General Dynamics Advanced Info Systems, Inc. | Apparatus and method for problem solving using intelligent agents |
US20030135582A1 (en) * | 2001-12-21 | 2003-07-17 | Docomo Communications Laboratories Usa, Inc. | Context aware search service |
US7716199B2 (en) * | 2005-08-10 | 2010-05-11 | Google Inc. | Aggregating context data for programmable search engines |
US7869998B1 (en) | 2002-04-23 | 2011-01-11 | At&T Intellectual Property Ii, L.P. | Voice-enabled dialog system |
US7398209B2 (en) * | 2002-06-03 | 2008-07-08 | Voicebox Technologies, Inc. | Systems and methods for responding to natural language speech utterance |
US7209915B1 (en) * | 2002-06-28 | 2007-04-24 | Microsoft Corporation | Method, system and apparatus for routing a query to one or more providers |
US7693720B2 (en) * | 2002-07-15 | 2010-04-06 | Voicebox Technologies, Inc. | Mobile systems and methods for responding to natural language speech utterance |
US7249321B2 (en) | 2002-10-03 | 2007-07-24 | At&T Knowlege Ventures, L.P. | System and method for selection of a voice user interface dialogue |
US20040162724A1 (en) * | 2003-02-11 | 2004-08-19 | Jeffrey Hill | Management of conversations |
KR100965437B1 (en) * | 2003-06-05 | 2010-06-24 | 인터트러스트 테크놀로지즈 코포레이션 | Interoperable systems and methods for peer-to-peer service orchestration |
US7640160B2 (en) * | 2005-08-05 | 2009-12-29 | Voicebox Technologies, Inc. | Systems and methods for responding to natural language speech utterance |
US7620549B2 (en) * | 2005-08-10 | 2009-11-17 | Voicebox Technologies, Inc. | System and method of supporting adaptive misrecognition in conversational speech |
US7949529B2 (en) * | 2005-08-29 | 2011-05-24 | Voicebox Technologies, Inc. | Mobile systems and methods of supporting natural language human-machine interactions |
US7962466B2 (en) * | 2006-01-23 | 2011-06-14 | Chacha Search, Inc | Automated tool for human assisted mining and capturing of precise results |
US8073681B2 (en) * | 2006-10-16 | 2011-12-06 | Voicebox Technologies, Inc. | System and method for a cooperative conversational voice user interface |
US8055502B2 (en) * | 2006-11-28 | 2011-11-08 | General Motors Llc | Voice dialing using a rejection reference |
US8140335B2 (en) * | 2007-12-11 | 2012-03-20 | Voicebox Technologies, Inc. | System and method for providing a natural language voice user interface in an integrated voice navigation services environment |
US20100082652A1 (en) * | 2008-09-29 | 2010-04-01 | Chacha Search, Inc. | Method and system for managing user interaction |
US8126875B2 (en) * | 2009-05-08 | 2012-02-28 | Microsoft Corporation | Instant answers and integrated results of a browser |
US8706172B2 (en) * | 2010-10-26 | 2014-04-22 | Miscrosoft Corporation | Energy efficient continuous sensing for communications devices |
US9858343B2 (en) * | 2011-03-31 | 2018-01-02 | Microsoft Technology Licensing Llc | Personalization of queries, conversations, and searches |
WO2013155619A1 (en) * | 2012-04-20 | 2013-10-24 | Sam Pasupalak | Conversational agent |
KR20130128716A (en) * | 2012-05-17 | 2013-11-27 | 포항공과대학교 산학협력단 | Foreign language learning system and method thereof |
US9973457B2 (en) * | 2012-06-26 | 2018-05-15 | Nuance Communications, Inc. | Method and apparatus for live chat integration |
US9424233B2 (en) * | 2012-07-20 | 2016-08-23 | Veveo, Inc. | Method of and system for inferring user intent in search input in a conversational interaction system |
CA2823835C (en) * | 2012-08-15 | 2018-04-24 | Homer Tlc, Inc. | Voice search and response based on relevancy |
US9070366B1 (en) * | 2012-12-19 | 2015-06-30 | Amazon Technologies, Inc. | Architecture for multi-domain utterance processing |
US9171542B2 (en) | 2013-03-11 | 2015-10-27 | Nuance Communications, Inc. | Anaphora resolution using linguisitic cues, dialogue context, and general knowledge |
US9805718B2 (en) * | 2013-04-19 | 2017-10-31 | Sri Internaitonal | Clarifying natural language input using targeted questions |
US9431008B2 (en) * | 2013-05-29 | 2016-08-30 | Nuance Communications, Inc. | Multiple parallel dialogs in smart phone applications |
CN103544219A (en) * | 2013-09-24 | 2014-01-29 | 北京光年无限科技有限公司 | Question-answering system with intelligent recommendation |
US20150178392A1 (en) * | 2013-12-20 | 2015-06-25 | Chacha Search, Inc. | Method and system of providing a search tool |
US9544310B2 (en) * | 2014-01-27 | 2017-01-10 | Microsoft Technology Licensing, Llc | Discovering and disambiguating identity providers |
CN103995870A (en) * | 2014-05-21 | 2014-08-20 | 百度在线网络技术（北京）有限公司 | Interactive searching method and device |
US10255921B2 (en) * | 2015-07-31 | 2019-04-09 | Google Llc | Managing dialog data providers |
-
2015
- 2015-07-31 US US14/815,794 patent/US10255921B2/en active Active
-
2016
- 2016-07-29 CN CN202210121104.2A patent/CN114595316A/en active Pending
- 2016-07-29 EP EP16748460.9A patent/EP3329395A1/en not_active Withdrawn
- 2016-07-29 WO PCT/US2016/044864 patent/WO2017023807A1/en active Application Filing
- 2016-07-29 CN CN201680034889.2A patent/CN107889533B/en active Active
- 2016-07-29 RU RU2017142336A patent/RU2690199C1/en active
-
2019
- 2019-04-08 US US16/378,546 patent/US11120806B2/en active Active
-
2021
- 2021-09-13 US US17/473,750 patent/US11727941B2/en active Active
-
2023
- 2023-07-14 US US18/222,325 patent/US20230360654A1/en active Pending
Patent Citations (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US8566102B1 (en) * | 2002-03-28 | 2013-10-22 | At&T Intellectual Property Ii, L.P. | System and method of automating a spoken dialogue service |
RU2012135502A (en) * | 2010-01-18 | 2014-02-27 | Эппл Инк. | PERSONALIZED DICTIONARY FOR DIGITAL ASSISTANT |
Also Published As
Publication number | Publication date |
---|---|
US11727941B2 (en) | 2023-08-15 |
EP3329395A1 (en) | 2018-06-06 |
US20210407522A1 (en) | 2021-12-30 |
CN114595316A (en) | 2022-06-07 |
US11120806B2 (en) | 2021-09-14 |
CN107889533A (en) | 2018-04-06 |
US20170032791A1 (en) | 2017-02-02 |
US20190304471A1 (en) | 2019-10-03 |
US10255921B2 (en) | 2019-04-09 |
CN107889533B (en) | 2022-03-01 |
US20230360654A1 (en) | 2023-11-09 |
WO2017023807A1 (en) | 2017-02-09 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
RU2690199C1 (en) | Managing data providers for dialogue | |
US11887595B2 (en) | User-programmable automated assistant | |
CN109804428B (en) | Synthesized voice selection for computing agents | |
US20190019112A1 (en) | Automated assistant invocation of appropriate agent | |
Qiu et al. | Improving worker engagement through conversational microtask crowdsourcing | |
US11853778B2 (en) | Initializing a conversation with an automated agent via selectable graphical element | |
RU2637874C2 (en) | Generation of interactive recommendations for chat information systems | |
US11425215B1 (en) | Methods and systems for virtual assistant routing | |
JP2018524676A (en) | Messenger-based service providing apparatus and method using the same | |
US11776537B1 (en) | Natural language processing system for context-specific applier interface | |
Hautsalo | Search engine optimisation for digital voice assistants and voice search |