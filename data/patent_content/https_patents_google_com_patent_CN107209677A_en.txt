CN107209677A - The IPO architectures of fine granulation requirement drive - Google Patents
The IPO architectures of fine granulation requirement drive Download PDFInfo
- Publication number
- CN107209677A CN107209677A CN201680008221.0A CN201680008221A CN107209677A CN 107209677 A CN107209677 A CN 107209677A CN 201680008221 A CN201680008221 A CN 201680008221A CN 107209677 A CN107209677 A CN 107209677A
- Authority
- CN
- China
- Prior art keywords
- function
- source code
- module
- multiple modules
- intermediate representation
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F8/00—Arrangements for software engineering
- G06F8/40—Transformation of program code
- G06F8/41—Compilation
- G06F8/44—Encoding
- G06F8/443—Optimisation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F8/00—Arrangements for software engineering
- G06F8/40—Transformation of program code
- G06F8/41—Compilation
- G06F8/44—Encoding
- G06F8/443—Optimisation
- G06F8/4441—Reducing the execution time required by the program code
- G06F8/4443—Inlining
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F8/00—Arrangements for software engineering
- G06F8/40—Transformation of program code
- G06F8/54—Link editing before load time
Abstract
There is provided the method and system for inter-procedure optimization (IPO).New IPO frameworks (being referred to as " ThinLTO ") are designed to solve existing IPO means (such as, traditional link time optimization (LTO) and lightweight inter-procedure optimization (LIPO)) shortcoming and limitation, and turn into new link time optimisation criteria.Using ThinLTO, requirement drive and the fine granulation based on summary importing maximize it is cross-module optimization (CMO) potentiality, this causes CMO as useful as possible.ThinLTO also provides global index, and it makes it possible to quick function and imported；The interprocedural analysis and conversion of some parallel performance-criticals but costliness；The Debugging message by the memory consumption minimum built is debugged is imported using the inertia of requirement drive；And allow to be easily integrated the distributed constructing system of third party.In addition, ThinLTO can also use IPO servers to realize, so that the need for eliminating to series steps.
Description
The cross reference of related application
This application claims the preferential of the U.S. Provisional Patent Application Serial No. 62/110,738 submitted for 2nd for 2 months in 2015
Power, the entire disclosure is incorporated herein by reference.
Background technology
Cross-module optimization (CMO) (it generally means that inter-procedure optimization (IPO)) is so that compiler can optimize user's journey
One of most effective mode of sequence.Traditionally, the technology for optimizing (LTO) using referred to as link time realizes CMO.LTO is compiling mould
Type, it enables cross-module optimization and the analysis of whole program in link (as its name suggests).However, LTO is made it by several limitations
Very big application is not suitable for.Such limitation is included for example：(1) LTO needs substantial amounts of memory to perform link step
Suddenly；(2) link step is continuous, and has slowed down overall compiling significantly；(3) LTO can not easily with it is large-scale distributed
Constructing system is integrated.
For realizing that CMO other prior arts are referred to as lightweight IPO (LIPO), it has more scalability than LTO.So
And, LIPO is limited by oneself, and has reached the upper limit in the aspect of performance that can further improve LIPO.With LIPO
Some examples of associated affairs include：(1) LIPO needs profile (profile) to feed back, and gives tacit consent to and can not enable；(2)
LIPO is invaded constructing system (for example, it is desired to complicated constructing system is supported to dispose it) very much；And (3) LIPO is used slightly
Granularity introduction method is omited, it greatly limit CMO potentiality.
The content of the invention
Present invention describes the selection of concept in simplified form, to provide the basic reason of some aspects of this disclosure
Solution.Present invention is not extensive overview ot of this disclosure, and is not intended to the key or important elements of the identification disclosure or retouches
Paint the scope of the present disclosure.Some concepts of the disclosure are simply rendered as the embodiment being provided below by present invention
Preamble.
The disclosure relates generally to the method and system for compilation of source code.More specifically, being related to use in terms of the disclosure
In the new framework for realizing IPO.
As will be described in greater detail herein, the IPO frameworks of the disclosure are designed to expand to very big program,
Almost do not limited in the quantitative aspects of its manageable source module, very soon, and for acquiescence pattern compiler (for example,
Acquiescence is opened).In addition, IPO architecture designs as described herein are to the parallel structure of individual machine and large-scale distributed constructing system
It is all friendly, and allow to carry out very deep optimization with minimum expense.
One embodiment of the disclosure is related to a kind of method for inter-procedure optimization, including：For multiple modules of source code
In each generation intermediate representation file；For each generating function index in multiple modules of source code and function summary number
According to；Stored in the unitary part of each intermediate representation file for corresponding modules of source code the index functions generated and
Function summary data；Archives are simplified using the generated intermediate representation file of composite function mapping generation；And to multiple sources
Code module performs cross-module optimization.
In another embodiment, cross-module optimization is performed in the method for inter-procedure optimization including the use of combination letter
Number mapping performs quick function and imported.
In another embodiment, cross-module optimization is performed in the method for inter-procedure optimization including the use of from one
The importing of the requirement drive of the Debugging message of individual or a number of other modules.
Another embodiment of the disclosure is related to a kind of computer implemented method, including multiple modules of source code are performed
Cross-module optimization, wherein cross-module optimization is parallel with module granularity, performing quick function using composite function mapping imports, and makes
With the importing of the requirement drive of the Debugging message from other modules.
In another embodiment, this method also includes being each generation intermediate representation text in multiple modules of source code
Part.
In another embodiment, this method also include be multiple modules of source code in each generating function index and
Function summary data.
In still another embodiment, this method also includes：For each generation middle table in multiple modules of source code
Show file；For each generating function index and function summary data in multiple modules of source code；In each intermediate representation text
The index functions generated and function summary data for corresponding modules of source code are stored in the unitary part of part；And make
Archives are simplified with the generated intermediate representation file of composite function mapping generation.
Another embodiment of the present disclosure is related to a kind of system for inter-procedure optimization, including at least one processor and coupling
Close the non-transitory computer-readable medium of at least one processor, with the instruction being stored thereon, the instruction when by
Make at least one processor during at least one computing device：For each generation intermediate representation text in multiple modules of source code
Part；For each generating function index and function summary data in multiple modules of source code；In each intermediate representation file
The index functions generated and function summary data for corresponding modules of source code are stored in unitary part；Use combination letter
Count the generated intermediate representation file of mapping generation simplifies archives；Cross-module optimization is performed with to multiple modules of source code.
In another embodiment, group is further used at least one processor in the system that optimizes between process
Close Function Mapping and perform quick function importing.
In another embodiment, at least one processor in the system of inter-procedure optimization, further use comes
From the importing of the requirement drive of the Debugging message of one or more of the other module.
Another embodiment of the disclosure is related to a kind of system, including at least one processor and is coupled at least one
The non-transitory computer-readable medium of device is managed, it has the instruction being stored thereon, and the instruction is when by least one processing
When device is performed, make at least one processor：Cross-module optimization is performed to multiple modules of source code, wherein cross-module optimization is with module
Granularity is parallel, and performing quick function using composite function mapping imports, and uses the need of the Debugging message from other modules
Ask the importing of driving.
In another embodiment, at least one processor in system further makes：For in multiple modules of source code
Each generation intermediate representation file.
In another embodiment, at least one processor in system further makes：For in multiple modules of source code
Each generating function is indexed and function summary data.
In another embodiment, at least one processor in system further makes：For in multiple modules of source code
Each generation intermediate representation file；For each generating function index and function summary data in multiple modules of source code；
The institute's generating function index and function for corresponding modules of source code are stored in the unitary part of each intermediate representation file
Summary data；And simplify archives using the generated intermediate representation file of composite function mapping generation.
It is above-mentioned that the embodiment of some or all processors disclosed herein and accumulator system can be additionally configured to execution
Some or all of disclosed embodiment of the method.The embodiment of some or all of method as disclosed above can also be by table
The instruction embodied on temporary or non-transitory processor readable storage medium (such as optics or magnetic memory) is shown as, or
Person is expressed as being supplied to the propagation of processor or data processing equipment to believe via communication network (such as internet or phone connection)
Number.
From embodiment given below, other scopes of the applicability of disclosed method and system will become
Obviously.It is to be understood, however, that although embodiment and specific example indicate the implementation of method and system
Example, but only provide by way of illustration, because the various changes and modifications in the spirit and scope of concept disclosed herein
It will become obvious to those skilled in the art according to the embodiment.
Brief description of the drawings
Research with reference to appended claims and accompanying drawing to detailed description below, these and other mesh of the disclosure
, features and characteristics will become apparent for those skilled in the art, it is all these all formed this specification one
Part.In the accompanying drawings：
Fig. 1 is the flow for illustrating the example phase in the IPO systems according to one or more embodiments as described herein
Figure.
Fig. 2 is the flow chart for illustrating the example IR generating process according to one or more embodiments as described herein.
Fig. 3 is to illustrate the example IPO imported according to the use inertia function of one or more embodiments as described herein
The flow chart of process.
Fig. 4 is to illustrate the example that iteration inertia function is imported that is used for according to one or more embodiments as described herein
The flow chart of method.
Fig. 5 is to illustrate to be used to create showing for cross-module optimization according to the arrangement of one or more embodiments as described herein
The block diagram of example computing device.
Provided herein is title for convenience only, scope or implication that the disclosure is claimed might not be influenceed.
In the accompanying drawings, the element of identical reference and the identification of any abbreviation with same or similar structure or function
Or action, in order to understand and conveniently.Accompanying drawing is will be described in during following embodiment.
Embodiment
The various examples and embodiment of disclosed method and system will now be described.Following description provides these are shown
The thorough understanding of example and the detail for realizing description.However, various equivalent modifications will be understood that, can there is no these thin
One or more embodiments described herein are put into practice in the case of many of section.Similarly, those skilled in the relevant art will also
Understand, one or more other embodiments of the present disclosure can include the further feature not being described in detail herein.In addition, some many institutes
Known structure or function can not may be shown and described below, to avoid unnecessarily obscuring associated description.
Cross-module optimization (CMO) (it generally means that inter-procedure optimization (IPO)) is so that compiler can optimize user's journey
One of most effectual way of sequence.Under default situations, compiler is run under individual module pattern.In such a mode, compiler
Optimization ability limited by the artificial source module alignment that programmer sets up.
Several existing mechanism have been proposed to solve this problem, including such as link time optimizes (LTO) and light
Magnitude inter-procedure optimization (LIPO).However, this existing means are restricted so that they are not suitable for acquiescence and opened.Such as will be
It is described more fully below, the new CMO frameworks (it there may come a time when referred to as " ThinLTO " herein) of the disclosure are designed to solution
Certainly both LTO and LIPO shortcoming and limitation, and as it is new link-when m- optimisation criteria.
There are ThinLTO many features, it provides the various advantages relative to existing means.For example, the disclosure
Method and system solves CMO scalability problems, and these problems annoying the existing means for implementing CMO.In default situations,
ThinLTO is also reduced the time spent in serial (for example, can not parallelization, so as to the run into bottleneck) part in compilation process
To bare minimum.I/O operation is also minimized, because can for example eliminate the second intermediate representation (IR) serializing.For example, making
Traditional CMO is used, after interprocedural analysis, in order to be changed in different subregions, compiler needs to read in IR files, enters
Clone's (for example, inline conversion) of function needed for row conversion, and the IR of subregion again is write back into disk.This serialisation step is non-
Normal I/O is sensitive, and is eliminated in method and system presented herein.
Using ThinLTO, requirement drive and the fine granulation based on summary import maximize CMO potentiality, this causes CMO
It is as useful as possible.ThinLTO also provides global index, and it makes it possible to quick function and imported；Some parallel performance-criticals but high
Expensive interprocedural analysis and conversion；The debugging by the memory consumption minimum built is debugged is imported using the inertia of requirement drive
Information；And allow to be easily integrated the distributed constructing system of third party.In addition, ThinLTO can also use IPO servers to realize,
So as to the need for eliminating to series steps.
New IPO (for example, CMO) architecture combined of the disclosure LIPO and tradition LTO many best features, in addition to base
This change and/or increase.Although these included in ThinLTO change/increased there is provided many relative to existing means substantially
Advantage, but between each some concepts included still have some similarities.Describe to make in the disclosure below
Some examples of Essential Terms.
Inter-procedure optimization (IPO).IPO generally means that CMO, it means that cross-module optimization.
Main modular.The concept used in LIPO and ThinLTO.It is defined as module, wherein the internal function defined
Outside line copy (out-of-line copy) will be issued.Global variable defined in primary module also will be in data space
" possessing " stores.
Supplementary module.The concept used in LIPO and ThinLTO.It is the module imported by primary module.Except minority
Beyond exception, the function body defined wherein will be dropped after CMO (inline).
Auxiliary function.LIPO and ThinLTO concepts.It is the function defined in supplementary module.These functions have spy
Different contact.
Function is imported.ThinLTO concepts.It refers to the mistake that required function is quickly loaded into primary module from other modules
Journey.
Static state promotes.Concept in LIPO, ThinLTO and LTO based on subregion.Static state promotes to refer to when reference is cross-module
Or during partition boundaries, file static variable and function are promoted to outside process.
Simplify archives.The notation index of clean copy comprising the member file to archives and the archives quoted.Simplify shelves
Case avoids duplicate of the document unnecessary in local constructing system or remote cache.For example, when creating archives/Function Mapping,
The copy of IR files is not made.On the contrary, archives only quote original IR files.
Intermediate representation (IR).Intermediate program representation term.It should be noted that intermediate representation can be referred to as intermediate language sometimes
(IL).However, for the sake of clarity, when describing the various features and embodiment of the disclosure, only quoting IR.
Linker plug-in unit.The component used by traditional LTO and ThinLTO.Plug-in unit is loading to real linker
Module, for handling the intermediate file with the form for not being final relocatable target.
In following part, traditional LTO and LIPO will be described in detail first, to understand its shortcoming and limitation, and with
It is the detailed description of the ThinLTO according to one or more other embodiments of the present disclosure afterwards.
Traditional LTO
LTO is compilation model, and it enables cross-module optimization and the analysis of whole program (as its name suggests) in link time.Normal
During rule compiling, bit code file of the compiler generation with program IR (intermediate representation), rather than generate real relocatable
File destination.These files are collected and merged by linker plug-in unit in link time.The IPA and code generator group of compiler
Part is called to generate real file destination using CMO by plug-in unit.Then real file destination is passed into real link
Device can perform storehouse or shared library to generate target.In the presence of the several different of tradition (for example, routine, classics) LTO models
Change, including it is for example following：
(i) fully unitary model：In the model, LTO links stage progress all working, and without any parallel
Change.The work includes all IPA and analyzes and change, and the optimization of function level and code building.For example, (it is compiler to LLVM
Architecture, it is designed as one group and had to explicitly define the reusable libraries of interface) current LTO employ fully unitary mould
Type.As another example, when-fwhopr is not specified, the GCC (set of GNU compilers) of older version LTO has also been used
Full block mold.GCC deletion-fwhopr the options of more redaction, and whopr patterns are set to acquiescence.Using option-
Flto-partition=none, block mold still can be opened in GCC.
(ii) there is the block mold of Thread level parallelism：The model is similar to the fully unitary mould described in above-mentioned (i)
Type, its main distinction is to complete function level optimization/code building using Thread level parallelism.
(iii) the parallel BE of serial i PO+：In the model, LTO link steps perform all IPA analysis and conversion (including
Inline conversion).After series steps, the parallel structure of calling process level is given birth to performing optimization/code in module level
Into.
(iv) there is the LTO of subregion：In the model, the IPA analyses based on summary are performed in serial link step.
Can use this model complete IPA it is inline (model only generates inline decision, but postpone be transformed into after).It is analyzed in IPA
Afterwards, calling figure division can be performed.It by calling figure node division is balance subgraph that target, which is, so that across subregion edge weights are minimum
Change.Each subregion is handled by different subprocess, is generated with being changed in implementation procedure with machine code.Subprocess can be simultaneously big
Amount is produced.The size of subregion can not too greatly can not be too small.If it is too big, the rear end of large-scale subregion is compiled with high
Memory pressure, and entirely the structure time will run into bottleneck thereon.On the other hand, if subregion is too small, CMO effect
It will substantially reduce, or if across partitioned nodes duplications are completed, then will cause serious serializing expense.For example, GCC LTO
Use such model.Default mode will perform equilibrium.The quantity of subregion is dynamic, but give tacit consent to it will be in average value 32
Around.Each subregion should also be more than the minimal size that parameter is specified.
In addition to fully unitary model (i) as described above, all other existing LTO models all attempt by using
The concurrencys of some ranks improves scalability.However, they are all intended to be designed to build with single multinuclear machine,
It is not suitable for large-scale distributed constructing system.Even if in addition, the effort of maximum is made by the pattern based on subregion, in serial chain
It can be still important to connect the compiling work completed in step.
On Thread level parallelism it should be noted that, although it can accelerate LTO compiling, but it can also accelerate
There is no the baseline compiling in the case of LTO.For non-LTO compilings, parsing can not easily parallelization, therefore compiled using non-LTO
Thread may not be equally effective.Non- LTO compilings are also usually using process level concurrency.Therefore, thread-level is blindly increased
Concurrency can make system overload.
No matter whether-g is designated, GCC IR carries the expense of all types information.This be GCC IR sizes it is much big
One of in the reason for LLVM.However, using-g, LLVM IR sizes can be than not big 10x times, and this will be under one-piece pattern
Or the important limiting factor of large-scale application is built using large-scale subregion.
It is worth noting that, traditional LTO technology is used for for a long time.Early stage compiler uses referred to as pre-linking
The black box of device performs cross-module optimization.Pre-linking device produces the .o files of combination, is then fed to actual link
Device is to generate final executable/shared library.Early stage, LLVM implemented LTO in the same way.
Realize that expansible LTO early stage existing compiler introduces two innovations first.One innovation is linker plug-in unit,
And another is the rear end of complete parallel.The introducing of linker plug-in unit allows LTO to use minimum change and existing constructing system
Seamless integration-.It also enables the whole program function for the feedback for needing real linker.In addition to plug-in unit is changed, LLVM's
LTO remains in that whole afterwards in the differentiation (the nearest effort that there is the progress GCC categories subareas in LLVM) by more than ten years
Body.
Lightweight IPO (LIPO)
LIPO represents lightweight IPO.LIPO is to optimize (FDO) close-coupled with feedback guidance and need letter based on LTO
Shelves feedback is so as to the cross-module optimisation technique effectively observed.In the compilation model, program inserting operation add one it is attached
Plus step：Lightweight dynamic IP A (dyn-ipa).In this additional step, based on from directly or indirectly calling profile counter structure
The dynamic call figure built performs the inline analysis of coarse-grained, and is recorded analysis result as module group in profile data.
Using LIPO, in optimization builds (profile uses path), without serial link plug-in unit step, as traditional
Done in LTO like that.In LIPO models, a source module can be included in multiple module groups as so-called supplementary module
In.Therefore, profile uses compiling fully parallelized as any conventional O2 structures.It also naturally with any distribution
Formula constructing system works build concurrency with abundant explore together.Make together with the complete Debugging message that LIPO can be with unlatching
With the production binary file that this is built for being optimized using peak value is critically important.
LIPO limitation
Existing LIPO technologies are influenceed by some limitations and complexity, including for example following：
(i) LIPO is restricted to be used only Profile Feedback structure (although when when FDO is used together, LTO may more have
Effect)；
(ii) the multimode compiling based on resolver can not handle intermediate language packet；
(iii) based on resolver multimode compiling implement be it is complicated and intractable (for example, isolation parse above and below
Text)；
(iv) due to memory constraints, module packet size is restricted.For large-scale C++ programs, C++ modules include number
Thousand functions are not uncommon for.For carrying out the LIPO dyn-ipa paths that the inline analysis of coarse-grained and module are grouped quite
It is difficult to, optimum heuristic is proposed to select the optimal supplementary module of specifying constraint.Module packet, which is slightly different, also may be used
To cause marvellous performance inconsistency；
(v) need to instruct distributed constructing system on the additional source dependence introduced by LIPO, will correct text
Part set is sent to structure node；
(vi) for traditional generation file (makefile), the dependence to the new introducing of the source file of generation can be led
Cause to build mistake；With
(vii) more distributed front ends that build are needed to support, to handle outmoded profile.
ThinLTO general introduction
As described above, traditional LTO and LIPO suffers from various limitations, and it is not suitable for unpacking/typically using.Cause
This, embodiment of the disclosure provides new LTO mechanism (" ThinLTO "), to overcome the limit associated with LIPO LTO with tradition
System and problem.As will be discussed later in detail, ThinLTO is designed to safeguard LIPO many using identical principle
Prime, but without any LIPO inherent shortcoming.In LIPO with wherein carrying out module group decision when training and running not
With, ThinLTO is determined in compiling, but in the inertia pattern for being easy to large-scale parallel.Use
ThinLTO, the serial link device plug-in unit stage is designed to simplify very much and quickly.In addition, according at least one embodiment, acquiescence
The step only carries out the preparation of minimum, and parallel inertia importing is performed to enable later.
ThinLTO design objects and characteristic
According to one or more embodiments as described herein, cross-module optimization method, system and the framework of the disclosure are based on
One or more of following purpose and feature are designed：
(i) ThinLTO can be operated in the case of independent of Profile Feedback.
(ii) acquiescence ThinLTO is designed to lean and average, and independent of the machine configured with large memories.
ThinLTO may be easy to use and expansible as traditional O2.
(iii) LTO serial section simplifies (according to Amdahl laws) as far as possible, so that a large amount of concurrencys are effective.This meaning
Taste, for example, acquiescence can trim any operation not strictly necessary in this step.I/O operation may be minimum, and mostly
Number calculating may be deferred to parallel.
(iv) ThinLTO is designed to cross-module inline excellent to maximize with the memory and compilation time expense of minimum
Point.Alternatively the whole program based on summary with different costs can be opened using the optimization rank of additional mark or higher
Analysis.
(v) using the Profile Feedback opened, series steps can be completely eliminated.
(vi) parallelization granularity, which may remain in source module rank and import granularity on demand, is maintained at functional class.For
Distribution is built, and granularity should not too greatly (for example, relatively low concurrency) or too small (for example, high setting cost, lacks importing altogether
Enjoy, Code copying cost etc.).
(vii) ThinLTO is designed to be friendly to the parallel structure of individual machine and large-scale distributed structure.
(viii) ThinLTO enables simple compilation time and run time error classification and debugged (for example, it is allowed to non-LTO
The light of file destination is mixed and matched).
According at least one embodiment, built similar to traditional LTO, ThinLTO is the compiling of three stages (except ThinLTO+
Outside FDO, it can be reduced to for 1 stage, as will be described in more detail below).However, each stage holds in ThinLTO
Capable task is different from the task that each stage performs in tradition LTO.Compared with traditional LTO, ThinLTO design is solved simultaneously
Row simultaneously improves overall scalability.
Following part provides the additional detail of the Basic Design (for example, being built for individual machine) on ThinLTO, and
And also description can be directed to the ThinLTO of different scenes (including such as distribution structure, FDO etc.) several variants.
The ThinLTO built parallel for individual machine
Fig. 1 figures show the stage of example three compiling in the ThinLTO according to one or more embodiments as described herein
100.Each in stage shown in Fig. 1 will be described in greater detail below.
Stage I：Use the IR generations of index functions and summary
According to one or more other embodiments of the present disclosure, in the first stage (for example, the example shown in Fig. 1 is compiled in 100
110) in, compiler can produce IR bit codes file rather than real relocatable target.In addition, compiler can also be generated
Below and store it in the unitary part of IR files：
(1) function body is indexed.It is substantially functional symbol table, its from function ID be mapped to IR files in they
This solid offsetting.Quick-searching afterwards and inertia is so allowed to import.
(2) function summary data.Summary data is used to aid in the function importing decision completed in the compiling of stage 3.Function
Summary data can include but is not limited to following：(a) core function attribute, such as size, preamble/coda cost, branch's number, tool
There is malloc to call；Transmission function (if any), wherein inline after transmission function by parameter value/value model (b)
Enclose and be mapped to implicit costs saving.
Fig. 2 figures show according to one or more embodiments as described herein be used for cross-module optimization method, system and
The example compiling streamline 200 in the stage 1 of framework.The compiler directive row of example phase 1 is probably：
${CC}-O2-c-fthin-lto-o source.o source.cc
Stage 2：Superfinishing letter linker layer plug
According at least one embodiment of the disclosure, the second stage in ThinLTO is given tacit consent to (for example, the example shown in Fig. 1
The work of minimum 120) can be only carried out in compiling 100.In ThinLTO, plug-in unit only needs to reflect using the function of combination
Penetrate from the generated IR files of the generation of stage 1 and simplify archives.Therefore, memory will be using will be very small, and I/O will be minimum
Change.Furthermore, it is possible to perform the example below technology to reduce generic function index size：
(1) " COMDAT " is eliminated.For example, only picking up a comdat copy in final index.There is profile wherein
In the case of data, outside line copy can be picked up.
(2) if impossible/cold function can not bring other benefits (for example, reduce size), skip it is all it is impossible/
Cold function (for example, marked by user or profile data).It should be noted that unless point of invocation information can be used to make more smart
True estimation, otherwise this technology is possible should be restricted to the function of very little).
(3) the very big function without good inline advantage is skipped.
According at least one embodiment, the IPA paths based on summary of more weight level can be alternatively performed.But,
Giving tacit consent to such path possibly can not open.The design details of this additional via is beyond the scope of the present disclosure.
Using acquiescence ThinLTO patterns, linker plug-in unit step is substantially the synchronous point in stage 1, and the stage 3 can be with afterwards
Start shared IR.It should be noted that synchronizing step can be completely free of.The example that this point how can be realized is by even
The continuous structure server for precalculating IR.Therefore, compiler is built can simply obtain function body from database.If
Lack, on-demand request can be carried out to building server.
At the end of stage 2, plug-in unit is by parallel calling backend driver.Called for each backend driver, it
Unmodified IR files will be transmitted from the stage 1 and simplify files with what compound function body was indexed.For call chain
The example command line for connecing device plug-in unit is probably：
$ { CC }-fthin-lto=./$ { some_dir }/prog_thin_arch.a sourcel.o
source2.o…-o a.out
In above-mentioned example order line, sourcex.o files are with the Function Mapping and summary number produced in the stage 1
According to IR files.Linker plug-in unit will produce prog_thin_arch.a files in the stage 2.Heavyweight IPA paths wherein
In the case of unlatching, IPA analysis results may also be stored in files.
The following is the example parallel backend driver call instruction row of ld plug-in units：
$ { BE_DRIVER }-fthin-lto-use=./$ { some_dir }/prog_thin_arch.a source1.o-
o source1_real.o....
The additional detail presented below occurred on the example command line.
Stage 3：The IPO of the fully parallelized requirement drive imported using inertia function
According to one or more other embodiments of the present disclosure, ThinLTO phase III is (for example, the example compiling shown in Fig. 1
In 100 130) in compiling streamline can include Fig. 3 shown in example frame.
Frame 305 in ThinLTO phase III 300 can include iteration inertia function and import.In this step, its is attached
Refinement section is illustrated in Fig. 4, and the auxiliary function that the possibility only from the supplementary module simplified in archives needs could be imported
Primary module.It should be noted that this is different from LIPO, all functions in LIPO in supplementary module are all forced while leading
Enter.The further detail below imported on the iteration inertia function that can be performed at frame 305 is provided below in reference to Fig. 4.
Fig. 4 figures show the instantiation procedure imported according to the iteration inertia function of one or more embodiments as described herein
400。
At frame 405, it may be determined that to all points of invocation of outside non-library function in (for example, identification, positioning etc.) module.
At frame 410, for each point of invocation determined at frame 405, the function summary data of point of invocation can be read,
And determined on estimated importing benefit.According at least one embodiment of the disclosure, if it is true to import the point
It is set to beneficial (for example, the importing benefit of the estimation determined for the point>0), then the point can be placed in Priority Queues.
At frame 415, can carry out whether being empty on Priority Queues or having reached the limitation of Priority Queues really
It is fixed.
If it is limitation that is empty or having reached Priority Queues that Priority Queues is determined at frame 415, function is imported
Complete, and the process can be moved to frame 440.
At frame 440, once iteration function, which is imported, completes (for example, as determined by frame 415), the function of importing
Type information can be imported by inertia.
On the other hand, if determining Priority Queues at frame 415 not for sky and not yet reaching the limitation of Priority Queues,
Iterative process can continue at frame 420, wherein, the top entry from Priority Queues may be ejected.
At frame 425, the entry of the function in overall situation function index can be used for positioning and loading in corresponding module
The IR of function.
At frame 430, if there is the profile for function, and profile is not yet in the function IR of loading, then may be used
So that profile is annotated onto the function IR loaded at frame 425.
At frame 435, the function IR that can be loaded at frame 425 is collected outside the new non-storehouse such as (for example, obtain, it is determined that)
Point of invocation.If it is determined that any new non-storehouse external call point be introduced into it is beneficial (for example, function summary based on point of invocation and
Call point analysis), then it can add them to Priority Queues.
The instantiation procedure 300 shown in Fig. 3 is returned to, frame 310 can include global symbol link (cross-module) and static rush
Enter.Explicit mark is does not import " chill block need not so do.
Frame 315 can include the inertia Debugging message for importing and merging from auxiliary.In this step, only by the function of importing
Required debugging DIE (or its metadata) merges and (for example unified) into primary module.It should be noted that according to the one of the disclosure or
Multiple embodiments, can be iteratively performed (the global symbol chain of frame 310 during ThinLTO phase III 300 (function importing)
Connect and static promotion) and frame 315 (debugging importing) in any one or two.
Frame 320 can be included in the interprocedural analysis path on extension primary module.
Frame 325 in ThinLTO phase III 300 can include later stage global optimization, machine certain optimisation and code
Generation.
It should be appreciated that all functions imported from other modules are the auxiliary functions defined according to LIPO.They can be
It is discarded safely after inline conversion, unless copy is changed into local or it cannot be guaranteed that by the situation of other module definitions.
ThinLTO inertia Debugging message is imported
Debugging message consumes substantial amounts of memory, and uniformly/many types of merging are probably expensive.If primary module
N number of function is imported from M different modules, then it is probably very expensive to import Debugging message from all M modules.According to
A kind of one or more other embodiments of the present disclosure, the mode for handling the problem is that debugging letter is imported by way of with requirement drive
Cease entry.Such means can be included for example for the IR walkings (walk) of the function each imported, and calculating can pass reference
The set of Debugging message entity, and merge them into primary module.
Stage 2 and stage 3 are built and are divided into two paths
In order to which using concurrency is built, the stage 1 compiles generally to complete (for example, via compiler in the path of its own
The independent structure action of option-c and each source file).However, according at least one embodiment of the disclosure, giving tacit consent to ThinLTO
Stage 2 and can be completed in path is merged the step of stage 3, the wherein parallel structure of linker plug-in unit driving rear end action
Build.
For ThinLTO, also there are different forming types：In linker plug-in unit step, archives text is simplified in establishment
After part, linker plug-in unit can select to create rear end motion file (for example, typically GNU makefile), and stop logical
Crossing participates in backend driver to compile replacement recovery compiling.Then user directly can be adjusted using the makefile of generation
With " make ".For example：
Path 1:
${CC}-fthin-lto-c source1.cc
${CC}-fthin-lto-c source2.cc
Path 2:# (generates generated.mk and stops and never call BE)
$ { CC }-fthin-lto=./thin_arch.a-fthin-lto-twopass=./generated.mk
source1.cc source2.c
Path 3:# (is explicitly called) by user
make-j10-f./generated.mk
Above-mentioned pattern, which gives user ThinLTO easily is built into the constructing system that is customized with it, to be integrated for remote compilation
Flexibility.
ThinLTO for distributed constructing system
According at least one embodiment of the disclosure, stage 1ThinLTO can be completely by any distributed constructing system
The influence of the complete parallel of offer.Although linker plug-in unit is series steps, ThinLTO is narrowed down to absolute minimum
Value.However, during the more expensive step of structure, the stage 3 (for example, linker plug-in unit) needs and any distributed structure system
Work is unified, in constructing system specific knowledge is embedded into compiler in itself.
Using the ThinLTO designs and framework of the disclosure, the problem can be easily solved.For example, 2 above-mentioned paths are compiled
Translating can be for solving this problem.After linker plug-in unit generation makefile, the specific transformation tool of constructing system can
File format is built for makefile is transformed into target.Then before this structure file feed can be built to distribution
Hold to perform.
Built (FDO/AFDO) using Profile Feedback
ThinLTO instructs optimization (AFDO) pellucidly to be worked even with outmoded profile using automatic feedback.Use base
In the FDO of instrument, single phase can be reduced to as being built traditional O2 or LIPO using compiling using ThinLTO profile
Compiling.Idea be can in profile generation path generation and in profile using step in reuse and simplify archives.
It should be noted that according to one or more embodiments as described herein, for the ThinLTO with Profile Feedback, mould
Block level is made a summary the need for can eliminating to enter most of chill block line function importing.Instructed using profile, function level, which is imported, also may be used
With more selective and more rapidly.
According at least one embodiment of the disclosure, description below can be realized similar to ThinLTO cross-module inline
In validity IPO architectures a possible alternate design example.
(1) in linker plug-in unit step, the inline analysis of LIPO styles coarse-grained is performed.Inline analysis is based on summary number
According to (for example, mainly calling figure)；
(2) substitute and carry out complete inline decision (for example, as done in GCC), the path only determines needs
Any packet is completed to enable useful CMO；
(3) subregion can be carried out to function based on original source module alignment；
(4) above-mentioned inline analysis is based on, the inline required functions of CM can will be enabled and be cloned into target source module.Function
Clone is substantially that the auxiliary function in ThinLTO is imported, but is completed in the linker plug-in unit stage.
Compared with ThinLTO, above-mentioned example alternate design has some shortcomings, including for example following：
(i) inline analysis is added in the bottleneck of compiling streamline, so as to reduce using parallelization maximum possible
Velocity factor；
(ii) auxiliary function steps for importing is also added into serialisation step.Even if Thread level parallelism can be applied, its
It is also limited to individual machine；
(iii) size of summary data is still linear for program size, and therefore may in the future some when
Reach structure machine limit quarter；
(iv) Debugging message process problem.In order to support inertia/debug-type importing on demand, compiler is needed in serializing
The IR of most of modules is traveled through in step.
Fig. 5 be according to one or more embodiments described herein be arranged to create the exemplary of cross-module optimization
The high level block diagram of computer (500).In very basic configuration (501), computing device (500) generally includes one or more
Processor (510) and system storage (520).Memory bus (530) can be used for processor (510) and system storage
(520) communication between.
According to desired configuration, processor (510) can be it is any kind of, including but not limited to microprocessor (μ P),
Microcontroller (μ C), digital signal processor (DSP) or its any combinations.Processor (510) can be slow including one or more levels
Deposit, such as level cache (511) and L2 cache (512), processor core (513) and register (514).Processor core
(513) can include ALU (ALU), floating point unit (FPU), digital signal processing core (DSP core) or its
What is combined.Memory Controller (516) can also be used together with processor (510), or in some implementations, memory control
Device (515) processed can be the interior section of processor (510).
According to desired configuration, system storage (520) can be any kind of, including but not limited to volatile storage
Device (such as RAM), nonvolatile memory (such as ROM, flash memory etc.) or its any combination.System storage
(520) operating system (521), one or more applications (522) and routine data (524) are generally included.It can be wrapped using (522)
Include the method and framework (523) for creating cross-module optimization for application.Routine data (524) can include store instruction, institute
State the method and framework (523) for instructing and being realized when being performed by one or more processing equipments for code optimization.According at least
Some embodiments, can be arranged to using (522) and be operated together with the routine data (524) in operating system (521).
Computing device (500) can have supplementary features or function, and for promoting basic configuration (501) and any institute
Need the additional interface of the communication between device and interface.
System storage (520) is the example of computer-readable storage medium.Computer-readable storage medium include but is not limited to RAM,
ROM, EEPROM, flash memory or other memory technologies, CD-ROM, digital universal disc (DVD) or other optical memory,
Cassette, tape, magnetic disk storage or other magnetic memory apparatus or available for storage information needed and can be by computing device 500
Any other medium accessed.Any such computer-readable storage medium can be a part for device (500).
Computing device (500) may be implemented as small portable (or mobile) electronic installation (such as cell phone, intelligence
Phone, personal digital assistant (PDA), personal media player apparatus, tablet personal computer (flat board), wireless web watch device, individual
Headphone device, application specific device include the mixing arrangement of any of the above described function) a part.Computing device (500) may be used also
To be embodied as the personal computer for including laptop computer and non-laptop computer configuration.
Embodiment above elaborates equipment and/or mistake by using block diagram, flow chart and/or example
The various embodiments of journey.As long as these block diagrams, flow chart and/or example include one or more functions and/or operation, this area
Technical staff will be understood that, can be by various hardware, software, firmware or its virtual any combinations individually and/or jointly
Realize each function and/or the operation in these block diagrams, flow chart or example.It is described herein according at least one embodiment
Several parts of theme can be via application specific integrated circuit (ASIC), field programmable gate array (FPGA), Digital Signal Processing
Device (DSP) or other integrated forms are realized.However, it would be recognized by those skilled in the art that embodiment disclosed herein certain
A little aspects completely or partially can be realized equally in integrated circuits, be used as one run on one or more computers
Or multiple computer programs, as the one or more programs run on the one or more processors, it is used as firmware or its void
Intend any combinations, and design circuit and/or write software and/or code those skilled in the art of firmware will be according to the disclosure
It is known.Further, it will be understood by those skilled in the art that the mechanism of theme described herein can as diversified forms program product
Distribute, and the illustrative embodiment of theme described herein is applied without considering to be used for the non-transitory letter of actual execution distribution
The particular type of number bearing medium.The example of non-transitory signal bearing medium includes but is not limited to following：Recordable-type media,
Floppy disk, hard disk drive, compact disk (CD), digital video disc (DVD), digital magnetic tape, computer storage etc.；And pass
Defeated type media, such as numeral and/or analogue communication medium.(for example, fiber optic cables, waveguide, wired communications links, channel radio
Believe link etc.).
On using substantially any plural number and/or singular references, those skilled in the art can be from plural number transformation herein
It is changed into plural form to be suitable for context and/or application for singulative and/or from odd number.For the sake of clarity, can be with
Various singular/plural arrangements are expressly recited herein.
Therefore, it has been described that the specific embodiment of theme.Other embodiments are within the scope of the appended claims.One
In the case of a little, the action described in claim can be executed in different order and still realize desired result.In addition,
The process described in accompanying drawing be not necessarily required to shown in particular order or order realize desired result.Realized some
In, multitask and parallel processing are probably favourable.
Claims (20)
1. a kind of method for inter-procedure optimization, including：
For each generation intermediate representation file in multiple modules of source code；
For each generating function index and function summary data in the multiple modules of source code；
The index functions generated and function of correspondence modules of source code are stored in the unitary part of each intermediate representation file
Summary data；
Archives are simplified using the generated intermediate representation file of composite function mapping generation；And
Cross-module optimization is performed to the multiple modules of source code.
2. according to the method described in claim 1, wherein, it is described it is cross-module optimization it is parallel with module granularity.
3. according to the method described in claim 1, wherein, perform it is described it is cross-module optimization include：
Quick function is performed using composite function mapping to import.
4. according to the method described in claim 1, wherein, perform it is described it is cross-module optimization include：
Imported using the requirement drive of the Debugging message from one or more of the other module.
5. a kind of computer implemented method, including：
Cross-module optimization is performed to multiple modules of source code, wherein, the cross-module optimization is parallel with module granularity, uses combination
Function Mapping performs quick function and imported, and is imported using the requirement drive of the Debugging message from other modules.
6. method according to claim 5, in addition to：
For each generation intermediate representation file in the multiple modules of source code.
7. method according to claim 5, in addition to：
For each generating function index and function summary data in the multiple modules of source code.
8. method according to claim 5, in addition to：
For each generation intermediate representation file in the multiple modules of source code；
For each generating function index and function summary data in the multiple modules of source code；
The index functions generated and function of correspondence modules of source code are stored in the unitary part of each intermediate representation file
Summary data；And
Archives are simplified using the generated intermediate representation file of composite function mapping generation.
9. a kind of system for inter-procedure optimization, including：
At least one processor；With
Non-transitory computer-readable medium, the non-transitory computer-readable medium is coupled at least one described processing
Device, with the instruction being stored thereon, the instruction makes described at least one when by least one described computing device
Manage device：
For each generation intermediate representation file in multiple modules of source code；
For each generating function index and function summary data in the multiple modules of source code；
The index functions generated and function of correspondence modules of source code are stored in the unitary part of each intermediate representation file
Summary data；
Archives are simplified using the generated intermediate representation file of composite function mapping generation；And
Cross-module optimization is performed to the multiple modules of source code.
10. system according to claim 9, wherein, the cross-module optimization is parallel with the module granularity.
11. system according to claim 9, wherein, further make at least one described processor：
Quick function is performed using composite function mapping to import.
12. system according to claim 9, wherein, further make at least one described processor：
Imported using the requirement drive of the Debugging message from one or more of the other module.
13. a kind of system, including：
At least one processor；With
Non-transitory computer-readable medium, the non-transitory computer-readable medium is coupled at least one described processing
Device, with the instruction being stored thereon, the instruction makes described at least one when by least one described computing device
Manage device：
Cross-module optimization is performed to multiple modules of source code, wherein, the cross-module optimization is parallel with module granularity, uses combination
Function Mapping performs quick function and imported, and is imported using the requirement drive of the Debugging message from other modules.
14. system according to claim 13, wherein, further make at least one described processor：
For each generation intermediate representation file in the multiple modules of source code.
15. system according to claim 13, wherein, further make at least one described processor：
For each generating function index and function summary data in the multiple modules of source code.
16. system according to claim 13, wherein, further make at least one described processor：
For each generation intermediate representation file in the multiple modules of source code；
For each generating function index and function summary data in the multiple modules of source code；
The index functions generated and function of correspondence modules of source code are stored in the unitary part of each intermediate representation file
Summary data；And
Archives are simplified using the generated intermediate representation file of composite function mapping generation.
17. storing one or more non-transitory computer-readable mediums of computer executable instructions, the computer can be held
Row instruction when executed by one or more processors, operates one or more of computing devices, and the operation includes：
For each generation intermediate representation file in multiple modules of source code；
For each generating function index and function summary data in the multiple modules of source code；
The index functions generated and function of correspondence modules of source code are stored in the unitary part of each intermediate representation file
Summary data；
Archives are simplified using the generated intermediate representation file of composite function mapping generation；And
Cross-module optimization is performed to the multiple modules of source code.
18. one or more non-transitory computer-readable mediums according to claim 17, wherein, it is described cross-module excellent
Change parallel with module granularity.
19. one or more non-transitory computer-readable mediums according to claim 17, wherein, the computer can
Execute instruction makes one or more of computing devices further grasp when by one or more of computing devices
Make, the operation includes：
Quick function is performed using composite function mapping to import.
20. one or more non-transitory computer-readable mediums according to claim 17, wherein, the computer can
Execute instruction makes one or more of computing devices further grasp when by one or more of computing devices
Make, the operation includes：
Imported using the requirement drive of the Debugging message from one or more of the other module.
Applications Claiming Priority (5)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201562110738P | 2015-02-02 | 2015-02-02 | |
US62/110,738 | 2015-02-02 | ||
US14/634,401 US9841959B2 (en) | 2015-02-02 | 2015-02-27 | Fine-grained demand driven IPO infrastructure |
US14/634,401 | 2015-02-27 | ||
PCT/US2016/012938 WO2016126386A1 (en) | 2015-02-02 | 2016-01-12 | A fine-grained demand driven ipo infrastructure |
Publications (2)
Publication Number | Publication Date |
---|---|
CN107209677A true CN107209677A (en) | 2017-09-26 |
CN107209677B CN107209677B (en) | 2020-09-25 |
Family
ID=56554287
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201680008221.0A Active CN107209677B (en) | 2015-02-02 | 2016-01-12 | Fine-grained demand-driven IPO infrastructure |
Country Status (6)
Country | Link |
---|---|
US (1) | US9841959B2 (en) |
EP (1) | EP3254190B1 (en) |
JP (1) | JP6275929B1 (en) |
CN (1) | CN107209677B (en) |
DE (1) | DE202016007872U1 (en) |
WO (1) | WO2016126386A1 (en) |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN107832102A (en) * | 2017-10-31 | 2018-03-23 | 努比亚技术有限公司 | A kind of operating method of contextual model, device and computer-readable recording medium |
Families Citing this family (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP6759851B2 (en) * | 2016-08-22 | 2020-09-23 | 富士通株式会社 | Program generation program, program generation method, program generator and compilation program |
US20180275976A1 (en) * | 2017-03-22 | 2018-09-27 | Qualcomm Innovation Center, Inc. | Link time optimization in presence of a linker script using path based rules |
US20230083849A1 (en) * | 2021-08-31 | 2023-03-16 | Cdev, Llc | Parsing tool for optimizing code for deployment on a serverless platform |
US20230266950A1 (en) * | 2022-02-18 | 2023-08-24 | Huawei Technologies Co., Ltd. | Methods and devices for compiler function fusion |
CN114816370A (en) * | 2022-06-29 | 2022-07-29 | 广州易方信息科技股份有限公司 | Method for splitting SDK static library at iOS end at any fine granularity |
Citations (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5375242A (en) * | 1993-09-29 | 1994-12-20 | Hewlett-Packard Company | Compiler architecture for cross-module optimization |
CN101169718A (en) * | 2006-10-23 | 2008-04-30 | 国际商业机器公司 | System and method for instantiating abstract class |
CN101546263A (en) * | 2009-03-23 | 2009-09-30 | 深圳市金蝶中间件有限公司 | Method and a system for binding Java source code and corresponding accessory information |
CN102112988A (en) * | 2008-06-10 | 2011-06-29 | 绿洲模具公司 | Methods and devices for independent evaluation of cell integrity, changes and origin in chip design for production workflow |
US20140025622A1 (en) * | 2008-10-02 | 2014-01-23 | Global Healthcare Exchange, Llc | Universal data discernment |
US8789032B1 (en) * | 2009-02-27 | 2014-07-22 | Google Inc. | Feedback-directed inter-procedural optimization |
Family Cites Families (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7275242B2 (en) * | 2002-10-04 | 2007-09-25 | Hewlett-Packard Development Company, L.P. | System and method for optimizing a program |
US7743368B2 (en) * | 2005-08-09 | 2010-06-22 | Hewlett-Packard Development Company, L.P. | Method and apparatus for providing class hierarchy information for function devirtualization |
TW201128383A (en) * | 2009-07-29 | 2011-08-16 | Reversinglabs Corp | Portable executable file analysis |
US8627300B2 (en) * | 2009-10-13 | 2014-01-07 | Empire Technology Development Llc | Parallel dynamic optimization |
US8689200B1 (en) | 2011-01-12 | 2014-04-01 | Google Inc. | Method and system for optimizing an executable program by generating special operations for identical program entities |
WO2013188337A2 (en) * | 2012-06-12 | 2013-12-19 | Risk Management Solutions, Inc. | Predicting and managing impacts from catastrophic events |
-
2015
- 2015-02-27 US US14/634,401 patent/US9841959B2/en active Active
-
2016
- 2016-01-12 CN CN201680008221.0A patent/CN107209677B/en active Active
- 2016-01-12 JP JP2017538219A patent/JP6275929B1/en active Active
- 2016-01-12 EP EP16704723.2A patent/EP3254190B1/en active Active
- 2016-01-12 WO PCT/US2016/012938 patent/WO2016126386A1/en active Application Filing
- 2016-01-12 DE DE202016007872.1U patent/DE202016007872U1/en active Active
Patent Citations (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5375242A (en) * | 1993-09-29 | 1994-12-20 | Hewlett-Packard Company | Compiler architecture for cross-module optimization |
CN101169718A (en) * | 2006-10-23 | 2008-04-30 | 国际商业机器公司 | System and method for instantiating abstract class |
CN102112988A (en) * | 2008-06-10 | 2011-06-29 | 绿洲模具公司 | Methods and devices for independent evaluation of cell integrity, changes and origin in chip design for production workflow |
US20140025622A1 (en) * | 2008-10-02 | 2014-01-23 | Global Healthcare Exchange, Llc | Universal data discernment |
US8789032B1 (en) * | 2009-02-27 | 2014-07-22 | Google Inc. | Feedback-directed inter-procedural optimization |
CN101546263A (en) * | 2009-03-23 | 2009-09-30 | 深圳市金蝶中间件有限公司 | Method and a system for binding Java source code and corresponding accessory information |
Cited By (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN107832102A (en) * | 2017-10-31 | 2018-03-23 | 努比亚技术有限公司 | A kind of operating method of contextual model, device and computer-readable recording medium |
CN107832102B (en) * | 2017-10-31 | 2020-12-29 | 廊坊市朔程燃气有限公司 | Contextual model operation method and device and computer-readable storage medium |
Also Published As
Publication number | Publication date |
---|---|
DE202016007872U1 (en) | 2017-01-26 |
EP3254190B1 (en) | 2020-10-21 |
US20160224324A1 (en) | 2016-08-04 |
CN107209677B (en) | 2020-09-25 |
JP6275929B1 (en) | 2018-02-07 |
WO2016126386A1 (en) | 2016-08-11 |
EP3254190A1 (en) | 2017-12-13 |
JP2018506117A (en) | 2018-03-01 |
US9841959B2 (en) | 2017-12-12 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN107209677A (en) | The IPO architectures of fine granulation requirement drive | |
Phothilimthana et al. | Chlorophyll: Synthesis-aided compiler for low-power spatial architectures | |
Dave et al. | RAMP: Resource-aware mapping for CGRAs | |
US9864590B2 (en) | Method and system for automated improvement of parallelism in program compilation | |
US7926046B2 (en) | Compiler method for extracting and accelerator template program | |
de Fine Licht et al. | StencilFlow: Mapping large stencil programs to distributed spatial computing systems | |
US20160357703A1 (en) | Parallel computing apparatus, compiling apparatus, and parallel processing method | |
CN105706057A (en) | Parallel dynamic programming through rank convergence | |
Kong et al. | Pipes: a language and compiler for task-based programming on distributed-memory clusters | |
Rausch et al. | A data-centric optimization framework for machine learning | |
Baumstark et al. | Adaptive query compilation in graph databases | |
CN113791770B (en) | Code compiler, code compiling method, code compiling system, and computer medium | |
Ejjaaouani et al. | , a Programming Model to Decouple Performance from Algorithm in HPC Codes | |
Rink et al. | Memory-efficient array redistribution through portable collective communication | |
Wang et al. | Parallel training via computation graph transformation | |
CN113885877A (en) | Compiling method, device, equipment and medium | |
EP3688572B1 (en) | Interactive code optimizer | |
Nguyen et al. | Design and Implementation of a Coarse-grained Dynamically Reconfigurable Multimedia Accelerator | |
Chae et al. | Centralized generic interfaces in hardware/software co-design for ai accelerators | |
Jing et al. | An Automatic Task Partition Method for Multi-core System | |
Phothilimthana | Programming Abstractions and Synthesis-Aided Compilation for Emerging Computing Platforms | |
Blindell | Survey on instruction selection: An extensive and modern literature review | |
Townsend | Compiling Irregular Software to Specialized Hardware | |
Schlaak | Multi-level functional IR with rewrites for higher-level synthesis of accelerators | |
Zhang | Code Generation Techniques for Raw Data Processing |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
CB02 | Change of applicant information |
Address after: American CaliforniaApplicant after: Google limited liability companyAddress before: American CaliforniaApplicant before: Google Inc. |
|
CB02 | Change of applicant information | ||
GR01 | Patent grant | ||
GR01 | Patent grant |