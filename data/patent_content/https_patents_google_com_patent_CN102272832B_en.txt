The application relates to the following U. S. application of being owned together by Motorola Inc. together with the application:
Application No.12/345,165, exercise question is " METHOD AND APPARATUS FOR GENERATING AN ENHANCEMENT LAYER WITHIN AMULTIPLE-CHANNEL AUDIO CODING SYSTEM " (lawyer's Docket No. No.CS36250AUD);
Application No.12/345,117, exercise question is " METHOD AND APPARATUS FOR GENERATING AN ENHANCEMENT LAYER WITHIN A MULTIPLE-CHANNEL AUDIO CODING SYSTEM " (lawyer's Docket No. No.CS36627AUD); And
Application No.12/345,096, exercise question is " SELECTIVE SCALING MASK COMPUTATION BASED ON PEAK DETECTION " (lawyer's Docket No. No.CS36655AUD), all applications are all submitted in same date with the application.
Embodiment
In order to solve above-mentioned needs, described a kind of for generate the method and apparatus of enhancement layer in audio coding system at this.During operation, the input signal that encode is received and coding, to produce the sound signal of coding.Then, come the sound signal of scalable coded with a plurality of yield values, to produce the coding audio signal of a plurality of convergent-divergents, the coding audio signal of each convergent-divergent has the yield value that is associated, and determines a plurality of error amounts of existing between each of the coding audio signal of input signal and a plurality of convergent-divergents.Then, select yield value, this yield value is associated with the coding audio signal of convergent-divergent, makes and have low error amount between the coding audio signal of input signal and this convergent-divergent.At last, this low error amount part as the enhancement layer of coding audio signal together with this yield value is transmitted.
Figure 1 illustrates the embedded speech of prior art/audio compression system.Input audio frequency s (n) is at first processed by
core layer scrambler 120, and for these purposes,
core layer scrambler 120 can be CELP type speech coding algorithm.The bit stream of coding is sent to
channel 125, and is imported into local core layer decoder 115, at this, has generated the core sound signal s of reconstruct
c(n).Then,
enhancement layer encoder 120 is used for based on signal s (n) and s
c(n) certain additional information of relatively encoding, and can use alternatively parameter from core layer decoder 115.As in core layer decoder 115,
core layer decoder 130 is converted to the core layer sound signal with core layer bit stream parameter
Then,
enhancement layer decoder 135 uses enhancement layer bit-stream and the signal of self-
channel 125
Produce the audio output signal of enhancing
The major advantage of embedded encoded system like this is that specific channel 125 can not be supported the bandwidth requirement that is associated with the high quality audio encryption algorithm constantly.Yet embedded encoder allows when enhancement layer bit-stream is lost or damage from channel 125 receiving unit bit streams (for example, only core layer bit stream), for example only to produce the core output audio.Yet, between embedded and non-embedded scrambler and also between different embedded encoded optimization purposes have qualitatively compromise.Namely, the enhancement layer coding of better quality can help to realize the balance preferably between core layer and enhancement layer, and also reduce overall data rates to obtain preferably transport property (for example, minimizing congested), this may cause the lower packet error rate of enhancement layer.
Provided the more detailed example of prior art enhancement layer encoder 120 in Fig. 2.At this, error signal maker 210 is comprised of the difference signal of weighting, and this weighted difference signal is transformed in MDCT (discrete cosine transform of modification) territory to be processed by error signal encoder 220 being used for.Error signal E is given:
E＝MDCT{W(s-s
c)} (1)
Wherein, W is based on the perceptual weighting matrix from the LP of core layer decoder 115 (linear prediction) filter factor A (z), and s is from the vector of the sample of input audio signal s (n) (that is, frame), and s
cIt is the corresponding vector from the sample of core layer decoder 115.Having described example MDCT in G.729.1 ITU-T recommends processes.Then, error signal E is processed by error signal encoder 220, to produce coded word i
E, this coded word i
EBe sent to subsequently channel 125.For this example, be important to note that, error signal encoder 220 only is provided with an error signal E, and exports a coded word i who is associated
EIts reason will become apparent below.
Then,
enhancement layer decoder 135 is from the bit stream of
channel 125 received codes, and suitably this bit stream of demultiplexing to produce coded word i
E Error signal decoder 230 uses coded word i
ECome reconstruct enhancement layer error signal
Then by signal combiner 240 with this enhancement layer error signal
With the core layer output audio signal
Make up as follows, to produce the enhancement layer audio output signal
Wherein, MDCT
-1Contrary MDCT (comprising overlap-add), and W
-1It is contrary perceptual weighting matrix.
Figure 3 illustrates another example of enhancement layer encoder.At this, the generation of the error signal E of error signal maker 315 relates to the pre-convergent-divergent of self-adaptation, wherein, carries out for core layer audio frequency output s
c(n) some modifications.This processing causes generating the bit of some, and the bit of this some is shown as coded word i in enhancement layer encoder 120
s
In addition,
enhancement layer encoder 120 shows the core layer output audio S of input audio signal s (n) and conversion
cBe imported into error signal encoder 320.These signals are for the psychoacoustic model of the coding of the improvement that is configured to enhancement layer error signal E.Then, coded word i
sAnd i
EBeing re-used, (MUX) 325 is multiplexing for device, and then is sent to subsequently the decoding of
channel 125 to be used for being undertaken by enhancement layer decoder 135.The bit stream of coding is received by
demodulation multiplexer 335, and
demodulation multiplexer 335 is separated into component i with bit stream
sAnd i
EThen, coded word i
EUsed with reconstruct enhancement layer error signal by
error signal decoder 340
Signal combiner 345 uses convergent-divergent bit i
sCome scale signal in some way
And then with result and enhancement layer error signal
Combination is to produce the audio output signal that strengthens
Provided the first embodiment of the present invention in Fig. 4.The figure shows by unit for scaling 415 and receive core layer output signal s
c(n) enhancement layer encoder 410.Predetermined gain sets g} for generation of the core layer output signal of a plurality of convergent-divergents S}, wherein, g
jAnd S
jJ candidate of corresponding set.In unit for scaling 416, the first embodiment in (MDCT) territory with signal s
c(n) be treated to:
S
j＝G
j×MDCT{Ws
c}；0≤j＜M (3)
Wherein, W can be certain perceptual weighting matrix, s
cBe the vector from the sample of core layer decoder 115, MDCT is operation well known in the art, and G
jCan be by utilizing gain vector candidate g
jAnd the gain matrix that forms, and wherein M is gain vector candidate's number.In the first embodiment, G
jUse vectorial g
jUse zero (that is, diagonal matrix) as the diagonal angle and in other any positions, but have many possibilities.For example, G
jCan be band matrix or can be even that simple scalar multiplication is with unit matrix I.Alternatively, with signal S
jStaying in time domain to have some advantages, maybe following situation may be arranged: advantageously, audio frequency is transformed to different territories, such as discrete Fourier transform (DFT) (DFT) territory.Many such conversion are known in the art.In these cases, unit for scaling can be exported the suitable S based on corresponding vector field
j
But under any circumstance, the main cause of convergent-divergent core layer output audio is compensation model mismatch (or certain other coding defective), and model mismatch may cause the marked difference between input signal and core layer codec.For example, if input audio signal is mainly music signal, and core layer codec is based on speech model, core layer output may comprise the characteristics of signals of serious distortion, in this case, from the angle of sound quality, the energy that selectively reduced this component of signal before the additional coding of using signal by one or more enhancement layers is useful.
Then, can be with the core layer audio frequency candidate vector S of gain convergent-divergent
jWith the input of input audio frequency s (n) as error signal maker 420.In the exemplary embodiment, input audio signal s (n) is converted into vectorial S, makes S and S
jAlignment accordingly.Namely, vectorial s and the s of expression s (n)
cIn upper alignment of time (phase place), and can use corresponding operation, make in this embodiment:
E
j＝MDCT{Ws}-S
j；0≤j＜M (4)
This expression formula produces a plurality of error signal vector E
j, described a plurality of error signal vector E
jBe illustrated in the weighted difference between the core layer output audio of input audio frequency and gain convergent-divergent in the MDCT spectrum domain.In having considered not other embodiment of same area, can revise top expression formula based on corresponding processing domain.
Then, according to the first embodiment of the present invention, gain selection device 425 is for assessment of a plurality of error signal vector E
j, to produce best error vector E
*, optimum gain parameter g
*, and produce subsequently corresponding gain index i
gGain selection device 425 can be determined optimal parameter E with several different methods
*And g
*, this may relate to the combination of closed-loop policy (for example, distortion metrics minimizes), open-loop method (for example, heuristic classification, model performance estimation etc.) or two kinds of methods.In this exemplary embodiment, can use the distortion metrics of biasing, its offset energy that is given between the signal vector of original audio signal vector S and compound reconstruct is poor:
Wherein,
Can be error signal vector E
jQuantitative estimation, and β
jCan be to select sensing optimal gain error index j for replenishing
*The bias term of judgement.Provided the illustrative methods that is used for the vector quantization of signal vector in exercise question is the U.S. Patent application No.11/531122 of APPARATUS AND METHOD FOR LOW COMPLEXITY COMBINATORIAL CODING OF SIGNALS, but many additive methods are possible.Recognizing E
j=S-S
jSituation under, formula (5) can be rewritten as:
In this expression formula,
Item is illustrated in the energy of the difference between the error signal of non-quantized error signal and quantification.For clear, this quantity can be called as " residual amount of energy ", and further can for assessment of " gain selection criterion ", in the gain selection criterion, select optimum gain parameter g
*Provided a kind of such gain selection criterion in formula (6), but many criterions are possible.
For bias term β
jNeeds may be due to following situation: the error weighting function W in formula (3) and (4) may be not enough to be created in vector
On appreciable distortion equally.For example, although error weighting function W can be used for attempting with error spectrum " albefaction " to a certain extent, because of the perception of people's ear for distortion, more weighting is placed on low frequency may specific advantage.As the result of the error weighting of the raising in low frequency, may come modeling insufficiently (under-modeled) high-frequency signal by enhancement layer.In these cases, with distortion metrics to unattenuated S
jThe g of high fdrequency component
jValue biasing direct benefit is arranged, make the not enough modeling of high frequency can not cause disagreeable or factitious acoustic artificial product in the sound signal of in the end reconstruct.Such example will be the situation of unvoiced speech signal.In this case, the input audio frequency is made of the noise class signal of the intermediate frequency tremendously high frequency that produces from the air turbulence from mouth usually.Can be core layer scrambler such waveform of directly not encoding, but can generate similar wave audio signal with noise model.This may cause the common low correlativity between input audio frequency and core layer output audio signal.Yet, in this embodiment, error signal vector E
jPoor based between input audio frequency and core layer audio output signal.Because these signals may be not relevant well, so error signal E
jEnergy may be not necessarily lower than input audio frequency or core layer output audio.In this case, the error in formula (6) to minimize the convergent-divergent that may cause gaining too positive, this may cause the possible artefact of listening.
In another case, bias factor β
jCan be based on other characteristics of signals of input audio frequency and/or core layer output audio signal.For example, the peak value of the frequency spectrum of signal and average ratio can provide the indication of the harmonic content of that signal.Signal such as the music of voice and particular type can have higher harmonics content, and therefore has high peak value and average ratio.Yet the music signal of processing by audio coder ﹠ decoder (codec) can cause because of the mismatch of encoding model bad quality, and result, and the core layer output signal spectrum can have peak value and the average ratio that reduces when making comparisons with input signal spectrum.In this case, can be useful be, reduce amount of bias in minimization, in order to allow the core layer output audio to be zoomed to lower energy by gain, allow thus enhancement layer coding to have impact more significantly for compound output audio.On the contrary, the voice of particular type or music input signal can represent lower peak value and average ratio, in this case, signal may be perceived as more and make a lot of noise, and may therefore benefit from the less convergent-divergent of core layer output audio by improving the error biasing.Be used for generating for β
jThe example of function of bias factor be given:
Wherein, λ can be certain threshold value, and is used for peak value and the average ratio φ of vector
yCan be given:
And, wherein,
Be the vectorial subset of y (k), make
k
1≤ k≤k
2
In case determined optimum gain index j from formula (6)
*, generate the coded word i that is associated
g, and with Optimal Error vector E
*Send to
error signal encoder 430, wherein, E
*Be encoded as and be suitable for the multiplexing form of (by multiplexer 440) and other coded words, and be transmitted with the demoder by correspondence and use.In the exemplary embodiment, error signal encoder 408 uses factorial pulse code (FPC).From processing the complicacy viewpoint, this method is useful because with vectorial E
*Coding be associated enumerate to process and be independent of for generation
Vector generate to process.
Enhancement layer decoder 450 reverses these and processes, to produce the audio frequency output that strengthens
More specifically,
demoder 450 receives i
gAnd i
E,
demodulation multiplexer 455 is with i
ESend to error
signal decoder 460, wherein, derive Optimal Error vector E from coded word
*Optimal Error vector E
*Be passed to signal
combiner 465, wherein, as received in revising in formula (2)
To produce
The second embodiment of the present invention relates to multilayer embedded coded system as shown in Figure 5.At this, can find out, there are five embeding layers that provide for this example.Layer 1 and 2 can all be based on encoding and decoding speech, and layer 3,4 and 5 can be the MDCT enhancement layer.Therefore, the scrambler 502 and 503 input signal s (n) that can utilize audio coder ﹠ decoder (codec) to produce and export to have encoded.Scrambler 510,610 and 514 comprises enhancement layer encoder, and wherein each exports the different enhancing of the signal of having encoded.Similar with previous embodiment, the error signal vector that is used for layer 3 (scramblers 510) can be given:
E
3＝S-S
2 (9)
Wherein, S=MDCT{Ws} is the input signal of weighted transformation, and S
2=MDCT{Ws
2It is the signal from the weighted transformation of layer 1/2 demoder 506 generation.In this embodiment, layer 3 can be that low rate quantizes layer, and same, may be useful in quantization error signal corresponding to coding
Relatively less bit.In order to provide good quality under these constraints, only can quantize at E
3The part of interior coefficient.The position of the coefficient of encoding can be that what to fix can be maybe variable, if but allow to change, can require to send additional information to demoder, to identify these positions.If for example the scope of the position of coding is at k
sThe beginning and at k
eFinish, wherein 0≤k
s＜k
e＜N, the error signal that quantizes vector
Can comprise zero of the only nonzero value in that scope and the position outside that scope.According to the coding method of using, position and range information also can imply.For example, be well known that in audio coding, frequency band can be considered to important in perception, and the coding of signal vector can concentrate on those frequencies.In these cases, the scope of coding can be variable, and can not cross over continuous frequency sets.But in any speed, in case this signal is quantized, the output spectrum of composite coding can be constructed to:
Then it be used as the input of layer 4 scrambler 610.
Layer 4 scrambler 610 are similar to the enhancement layer encoder 410 of previous embodiment.Use gain vector candidate g
j, the error vector of correspondence is described as:
E
4(j)＝S-G
jS
3 (11)
Wherein, G
jCan be gain matrix, wherein, with vectorial g
jAs diagonal components.Yet, in current embodiment, gain vector g
jCan be vectorial with the error signal that has quantized in the following manner
Relevant.Due to the error signal vector that has quantized
May be limited on frequency range, for example, at vector position k
sBeginning, and at vector position k
eFinish, so supposition layer 3 output signal S
3Very accurately encoded in that scope.Therefore, according to the present invention, based on the coding site k of layer 3 error signal vector
sAnd k
eAdjust gain vector g
jMore specifically, in order to be retained in the signal integrity of those positions, individual gain element that can correspondence is set to constant value α.Namely:
Wherein, usually, 0≤r
j(k)≤1 and g
j(k) be the gain of the k position of j candidate vector.In the exemplary embodiment, constant value is 1 (α=1), yet many values are possible.In addition, frequency range can be crossed over a plurality of starting positions and end position.Namely, formula (12) can be segmented into based on error signal
The discontinuous scope of gain of variation of certain function, and it more generally can be written as:
For this example, when the error signal that formerly quantizes
In correspondence position when being non-zero, α generates g with fixed gain
j(k), and when
In the position of correspondence when being zero, use gain function γ
j(k).A possible gain function can be defined as:
Wherein, Δ is step-length (for example, Δ ≈ 2.2dB), and α is constant, and M is candidate's number (for example, M=4 can only represent it with 2 bits), and, k
lAnd k
hBe respectively low frequency and high-frequency cut-off frequency, on them, gain may occur reduce.Parameter k
lAnd k
hBe introduced in wherein only useful in the system of expectation convergent-divergent on specific frequency range.For example, in given embodiment, high frequency may be by sufficiently modeling of core layer, and therefore the energy in high frequency band may be inherently lower than the energy in input audio signal.In this case, layer 3 output of convergent-divergent in that regional signal have benefit seldom or are no advantage, because the global error energy may as a result of increase.
Generally speaking, a plurality of gain vector candidate g
jBased on certain function of the code element of the signal vector of previous coding, in this case, this vectorial code element is
This can briefly be expressed as:
Corresponding demoder operation is shown on the right-hand side of Fig. 5.Bit stream (i when each layer that receives coding
1To i
5) time, set up the output signal of better quality on the level of the enhancement layer on core layer (layer 1) demoder.Namely, for this specific embodiment, the first two layer by time domain speech model coding (for example, CELP) consist of and remaining three layers by transform domain coding (for example, when MDCT) consisting of, according to the following last output that comes generation system
Wherein,
Layer 2 temporal enhancement layer signal, and,
Be and layer 2 audio frequency output
Corresponding weighting MDCT vector.In this expression formula, can determine whole output signal from the highest level of the successive bits fluid layer that receives
In this embodiment, suppose than low-level layers to have the high probability that is suitably received from channel, therefore, coded word collection { i
1, { i
1i
2, { i
1i
2i
3Etc. determine the appropriate level of the enhancement layer decoder in formula (16).
Fig. 6 is the block diagram that
layer 4
scrambler 610 and
demoder 650 are shown.Encoder shown in Figure 6 and shown in Figure 4 those are similar, except selecting
Gain generating device 630 and 660 to derive by unit for scaling 615 and 670 yield values that use via frequency respectively.During operation layer 3, audio frequency output S
3Exported from layer 3 scrambler, and scaled
unit 615 receives.In addition, layer 3 error vector
Exported from layer 3
scrambler 510, and selected
Gain generating device 630 to receive by frequency.As mentioned above, due to the error signal vector that quantizes
May be limited on frequency range, so based on for example position k as shown in formula 12
sAnd k
eOr the more generally expression formula in formula 13 is adjusted gain vector g
j
The audio frequency S of convergent-divergent
jFrom unit for scaling 615 outputs, and received by error signal maker 620.As mentioned above, error signal maker 620 receives input audio signal S, and determines the error value E by each scale vectors of unit for scaling 615 utilizations
jThese error vectors with based on optimum gain value g
*Determine error vector and certain errors E
*The yield value of middle use is passed to gain selection device circuit 635 together.Be used for expression optimum gain g
*Coded word (i
g) from 635 outputs of gain selection device, and Optimal Error vector E
*Be passed to error signal encoder 640, determine in error signal encoder 640 and exported coded word i
Ei
gAnd i
EBe output to multiplexer 645, and be sent to layer 4 demoder 650 via channel 125.
At the operating period of
layer 4
demoder 650, i
gAnd i
EReceive from
channel 125, and by
demodulation multiplexer 655 demultiplexings.According to the method for the correspondence of
scrambler 610, gain code word i
gWith layer 3 error vector
Be used as frequency and select the input of Gain generating device 660, to produce gain vector g
*Then, in unit for scaling 670, with gain vector g
*Be applied to the audio frequency vector of layer 3 reconstruct
And the output of unit for scaling 670 is then at
signal combiner 675 and by coded word i
EThe
layer 4 enhancement layer error vector E that obtain from
error signal decoder 655 of decoding
*Combined, to produce the audio frequency output of
layer 4 reconstruct
As shown in the figure.
Fig. 7 is the process flow diagram 700 of the operation of scrambler according to the first and second aspects of the present invention.As mentioned above, two embodiment utilize enhancement layer, the audio frequency that this enhancement layer utilizes a plurality of scale value to come convergent-divergent to encode, and then select to cause the scale value of minimum error.Yet in the second embodiment of the present invention, frequency selects Gain generating device 630 to be used for generating yield value.
Logic flow is in frame 710 beginnings, and wherein the core layer scrambler receives the input signal that will encode, and this input signal of encoding is to produce the sound signal of having encoded.Enhancement layer encoder 410 receives the sound signal (s that has encoded
c(n)), and, the sound signal that unit for scaling 415 utilizes a plurality of yield values to come convergent-divergent to encode, to produce the coding audio signal of a plurality of convergent-divergents, wherein each has the yield value (frame 720) that is associated.At frame 730, error signal maker 420 is determined a plurality of error amounts of existing between each in the coding audio signal of input signal and a plurality of convergent-divergents.Then, gain selection device 425 is selected yield value (frame 740) from a plurality of yield values.As mentioned above, yield value (g
*) be associated with the coding audio signal of convergent-divergent, cause at input signal and had low error amount between the coding audio signal of convergent-divergent.At last, at frame 750, transmitter 440 will hang down error amount (E
*) and yield value (g
*) together the part as the enhancement layer of coding audio signal transmit.Those of ordinary skill in the art will recognize, E had correctly encoded before transmission
*And g
*Both.
As mentioned above, at the receiver side place, will receive encoded audio signal together with enhancement layer.Enhancement layer is for comprising yield value (g
*) and the error signal (E that is associated with this yield value
*) the enhancing of encoded audio signal.
Be used for stereosonic core layer convergent-divergent
In superincumbent description, a kind of embedded encoded system has been described, wherein, each layer encoding mono signal.Now, the embedded encoded system that is used for encoded stereo or other multi-channel signals is described.For simplicity, technology in the background context of the stereophonic signal that is made of two audio frequency inputs (source) has been described; Yet exemplary embodiment described here can easily be expanded to stereophonic signal wherein and be had the situation that surpasses two audio frequency inputs, in the situation that the multichannel audio input is exactly like this.In order to illustrate rather than to limit, two audio frequency inputs are by left signal (s
L) and right signal (s
R) stereophonic signal that consists of, wherein, s
LAnd s
RIt is the n dimensional vector for the frame of expression voice data.Again for simplicity, will discuss by two layers---being core layer and enhancement layer---embedded encoded system of formation in detail.The thought that proposes can easily be extended to multilayer embedded coded system.Also can not embed codec itself, that is, it can only have a layer, and some of the bit of that codec are exclusively used in stereo, and remaining bit is used for monophonic signal.
Known embedded stereoscopic sound codec, this embedded stereoscopic sound codec is by the core layer of encoding mono signal and the enhancement layer of coding upper frequency or stereophonic signal consist of simply.Under that limited situation, core layer is encoded from s
LAnd s
RThe monophonic signal (s) that obtains of combination, to produce the monophonic signal of coding
If H is for 2 * 1 combinatorial matrixs that generate monophonic signal, that is,
s＝(s
L s
R)H (17)
Note, in formula (17), s
RCan be the delay version of right audio signal, and be not only right-channel signals.For example, can calculate for maximizing s
LWith delay version s
RThe delay of correlativity.If matrix H is [0.5 0.5]
T, formula 17 causes the equal weight of the corresponding right side and L channel, i.e. s=0.5s
L+ 0.5s
RBe not limited to the core layer of encoding mono signal and the enhancement layer of encoded stereo signal at this embodiment that provides.The core layer of embedded codec and the enhancement layer multi-channel audio signal of can encoding.Can be less than can be by the number of the sound channel in the multi-channel audio signal of enhancement layer coding by the number of the sound channel in multi-channel audio signal of core layer multi-channel encoder.If (m, n) is respectively will be by the number of the sound channel of core layer and enhancement layer coding.If s
1, s
2, s
3..., s
nWill be by the expression of n audio track of embedded system coding.Obtaining from these sound channels will be by m sound channel of core layer coding, and obtainedly is:
[s
1 s
2 ... s
m]＝[s
1 s
2 ... s
n]H，(17a)
Wherein, H is n * m matrix.
As mentioned above, core layer encoding mono signal s is to produce the signal of core layer coding
For from
Generate the estimation of stereo component, calculated balance factor.This balance factor is calculated as:
Can illustrate, if combinatorial matrix H is [0.5 0.5]
T,
w
L＝2-w
R (19)
Notice, this ratio has been realized the only quantification of a parameter, and can easily extract another from first.Now, stereo output is calculated as
In part subsequently, we will act on frequency domain, rather than time domain.Therefore, be illustrated in the signal of the correspondence in frequency domain with capitalization, that is, S,
S
L, S
R,
With
Be respectively s,
s
L, s
R,
With
Frequency domain representation.Use the item in frequency domain to calculate balance factor in frequency domain, and provide this balance factor by following formula:
And
In frequency domain, vector further can be divided into non-overlapped subvector, that is, the vectorial S of dimension n can be split into dimension m
1, m
2... m
tT subvector S
1, S ..., S
t, make
In this case, can calculate different balance factors for different subvectors, that is,
Balance factor is in this example considered irrelevant with gain.
Referring now to Fig. 8 and 9,, demonstrated the accompanying drawing to the stereo prior art relevant with other multi-channel signals.The embedded speech of the prior art of Fig. 8/
audio compression system 800 is similar to Fig. 1, but has a plurality of audio input signals, and in this example, described a plurality of audio input signals are shown as left and right stereo input signal S (n).These input audio signals are fed to
combiner 810, and
combiner 810 produces input audio frequency s (n), as shown in the figure.Described a plurality of input signal also is provided to
enhancement layer encoder 820, as shown in the figure.On the decoding side,
enhancement layer decoder 830 produces and strengthens output audio signal
As shown in the figure.
Fig. 9 illustrates the enhancement layer encoder 900 of the prior art that can use in Fig. 8.Described a plurality of audio frequency input with shown in the core layer output audio signal together be provided to the balance factor maker.The balance factor maker 920 of enhancement layer encoder 910 receives a plurality of audio frequency inputs, to produce signal i
B, this signal i
BBe delivered to forward multiplexer 325, as shown in the figure.Signal i
BIt is the expression of balance factor.In the preferred embodiment, i
BIt is the bit sequence for the expression balance factor.On decoder-side, this signal i
BBe balanced factor demoder 940 and receive, balance factor demoder 940 produces balance factor element W
L(n) and W
R(n), as shown in the figure, shown signal combiner 950 receiving balance factor element W
L(n) and W
R(n).
The multichannel balance factor calculates
As mentioned above, under many situations, the codec that is used for the coding of monophonic signal is designed to the monophony voice, and causes the encoding model noise when it is used for signal that coding do not supported fully by the codec model.Music signal and other non-voice class signals are not by based on some in the signal of the correctly modeling of core layer codec of speech model.Top description with reference to figure 1-7 has proposed to selecting gain by the signal application frequency of core layer coding.Convergent-divergent is optimized to be minimized in the certain distortion (error amount) between the coded signal of audio frequency input and convergent-divergent.Method as above is for the monophonic signal function well, but application core layer convergent-divergent is not best may be for or other multi-channel signals stereo when enhancement layer coding the time.
Because the combination from the input of two or more stereo audios has obtained monophonic components such as the multi-channel signal of stereophonic signal, so composite signal s may not meet the monophony speech model yet; Therefore, when this composite signal of coding, core layer codec may produce noise.Therefore, need the method for the convergent-divergent of the core layer coded signal of realization in embedded encoded system, reduce thus the noise that is generated by core layer.In above-mentioned monophonic signal method, obtain frequency and select the certain distortion tolerance of convergent-divergent based on the error in monophonic signal.Superincumbent formula has illustrated this error E in (11)
4(j).Yet only the distortion of monophonic signal is not enough to improve the quality of stereo communication system.The convergent-divergent that comprises in formula (11) can be undertaken by the zoom factor of unit (1) or the function of any other sign.
For stereophonic signal, distortion metrics should be caught the distortion of R channel and L channel.If E
LAnd E
RBe respectively the error vector for L channel and R channel, and be presented by following formula:
In the prior art, for example, as described in the AMR-WB+ standard, these error vectors are calculated as:
Now, we consider frequency selection gain vector g
j(0≤j＜M) be applied to
Situation.This frequency selects gain vector to be represented as G with matrix form
j, wherein, G
jTo have diagonal element g
jDiagonal matrix.For each vectorial G
j, error vector is calculated as:
By
Item provides the estimation of stereophonic signal.Can find out, gain matrix G can be unit matrix (1), or it can be any other diagonal matrix; Can recognize, be not that each possible estimation can be worked for each scale signal.
The distortion metrics ε that is minimized to improve stereosonic quality is the function of two error vectors, namely
ε
j＝f(E
L(j)，E
R(j)) (28)
Can find out, distortion value can be made of a plurality of distortion metrics.
Provide the index j of the frequency selection gain vector of selection by following formula:
In the exemplary embodiment, distortion metrics is all square distortions that provide by following formula:
ε
j＝‖E
L(j)‖
2+‖E
R(j)‖
2 (30)
Perhaps, it can be the weighting that provides by following formula or the distortion of biasing:
ε
j＝B
L‖E
L(j)‖
2+B
R‖E
R(j)‖
2 (31)
Biasing B
LAnd B
RIt can be the function of L channel and R channel energy.
As mentioned above, in frequency domain, vector can further be split into non-overlapped subvector.To comprise, frequency domain vector is divided into subvector in order to expand the technology that proposes, calculates the balance factor that uses for each subvector in (27).Therefore, the cascade by the error subvector that provided by following formula comes forming frequency to select each error vector E in gain
LAnd E
R
Distortion metrics ε in (28) is the function of the error vector that forms of the cascade by above error subvector now.
The calculated equilibrium factor
Use the balance factor of prior art (formula 21) generation and the output of core layer to have nothing to do.Yet in order to be minimized in the distortion metrics that provides in (30) and (31), what possibility was useful is that also the calculated equilibrium factor is to minimize corresponding distortion.Now, balance factor W
LAnd W
RCan be calculated as:
Wherein, can find out, balance factor is irrelevant with gain, for example, and as shown in the accompanying drawing of Figure 11.This formula is minimized in the distortion in formula (30) and (31).The problem of using such balance factor is present:
W
L(j)≠2-W
R(j)，(34)
The bit field that therefore, may need to separate quantizes W
LAnd W
RBy retraining W
L(j)=2-W
R(j) be placed on described the best and avoid this point.By this constraint, provide the optimum solution of formula (30) by following formula:
Wherein, as shown, balance factor to shown in gain term relevant; Figure 10 of accompanying drawing illustrates relevant balance factor.If bias factor B
LAnd B
RUnit,
Item in formula (33) and (36)
Be illustrated in the correlation between at least one in the sound signal of the coding audio signal of convergent-divergent and multi-channel audio signal.
In stereo coding, the direction in the source of sound and position may be than all square distortion is more important.Therefore the ratio of left channel energy and R channel energy can be the better designator of direction (or the position in the source of sound), rather than the distortion metrics of minimizing Weighted.Under such situation, the balance factor that calculates in formula (35) and (36) may not be the good method for the calculated equilibrium factor.Needed is to keep the ratio of left and right acoustic channels energy before and after coding identical.Be given in respectively coding before and the ratio of the channel energies after coding by following formula:
Make these two energy ratios equate and use supposition W
L(j)=2-W
R(j), we obtain
W
R＝2-W
L.(38)
It provides the balance factor component of the balance factor that generates.Notice, the balance factor that calculates in (38) now and G
jIrrelevant, be therefore no longer the function of j, consider irrelevant autocorrelative balance factor in being to provide in gain; Further illustrate relevant balance factor in Figure 10 of accompanying drawing.Use this result for formula 29 and 32, we can be extended to the selection of best core layer convergent-divergent index j and comprise cascade vector segmentation k, make:
The expression of optimum gain value.This index j of yield value
*Output signal as enhancement layer encoder is transmitted.
Referring now to Figure 10,, illustrate according to the enhancement layer encoder of each embodiment and the block diagram 1000 of enhancement layer decoder.Input audio signal s (n) is enhanced the balance factor maker 1050 of layer coder 1010 and error signal (distorted signal) maker 1030 of gain vector maker 1020 receives.Sound signal from the coding of core layer
The unit for scaling 1025 of the gain vector maker 1020 shown in quilt receives.Unit for scaling 1025 operates to utilize the sound signal of a plurality of yield value scalable coded
To generate a plurality of candidates' coding audio signal, wherein, convergent-divergent at least one in candidate's coding audio signal.As mentioned above, can adopt convergent-divergent by the sign function of unit or any expectation.The audio frequency S of unit for scaling 1025 output convergent-divergents
j, the audio frequency S of this convergent-divergent
jBeing balanced factor maker 1030 receives.The above discussion in conjunction with formula (18), (21), (24) and (33) generates the balance factor with a plurality of balance factor components, and wherein each balance factor component is associated with a sound signal in the multi-channel audio signal that is received by enhancement layer encoder 1010.This be by shown in balance factor maker 1050 complete, with the balance factor component shown in producing
Discuss in conjunction with formula (38) as above, balance factor maker 1030 with balance factor be illustrated as with gain irrelevant.
Gain vector maker 1020 is responsible for determining will be to the yield value of the sound signal application of encoding, to generate the estimation of multi-channel audio signal, as discussing in formula (27), (28) and (29).This completes by unit for scaling 1025 and balance factor maker 1050, and unit for scaling 1025 and balance factor maker 1050 are worked together and generated this estimation with the coding audio signal based on balance factor and at least one convergent-divergent.Yield value is based on balance factor and multi-channel audio signal, and wherein, yield value is configured to be minimized in the distortion value between the estimation of multi-channel audio signal and multi-channel audio signal.The function that formula (30) has been described as the estimation of multichannel input signal and real input signal itself generates distortion value.Therefore, the balance factor component is received by error signal maker 1030 together with input audio signal s (n), to determine the error value E by each scale vectors of unit for scaling 1025 utilizations
jThese error vectors with based on optimum gain value g
*Determine error vector and certain errors E
*The yield value of middle use is passed to gain selection device circuit 1035 together.Then, gain selection device 1035 can operate for estimation and actual signal itself based on the multichannel input signal and assess distortion value, in order to determine the optimum gain value g of possible yield value
*Expression.Be used for expression optimum gain g
*Coded word (i
g) from 1035 outputs of gain selection device, and the MUX multiplexer shown in quilt 1040 receives.
i
gAnd i
BAll be output to multiplexer 1040, and be launched machine 1045 and be sent to enhancement layer decoder 1060 via channel 125.Yield value i
gThe channel 125 of expression shown in being output to be transferred to, if but expectation, it also can be stored.
On decoder-side, at the operating period of
enhancement layer decoder 1060, i
gAnd i
EReceived and by
demodulation multiplexer 1065 demultiplexings from channel 125.Therefore, enhancement layer decoder received code sound signal
Coding balance factor i
BWith coding gain value i
gFrequency shown in
gain vector demoder 1070 comprises is selected Gain generating device 1075 and unit for scaling 1080.
Gain vector demoder 1070 generates the yield value of decoding from the yield value of coding.Coding gain value i
gBe imported into frequency and select Gain generating device 1075, produce gain vector g with the corresponding method according to
scrambler 1010
*Then to unit for scaling 1080 using gain vector g
*, unit for scaling 1080 utilizes the yield value g of decoding
*Come the sound signal of scalable coded
To generate the sound signal of convergent-divergent.The coding balance factor of
signal combiner 1095 receiving balance factor demoders 1090 outputs signal to the sound signal of convergent-divergent
To generate and to export the multi-channel audio signal of the decoding of the output audio signal that is shown as enhancing.
Illustrate the block diagram 1100 of exemplary enhancement layer encoder and enhancement layer decoder, wherein as above described in conjunction with formula (33), balance factor maker 1030 generates the balance factor relevant to gain.By generating G
jThe error signal maker of signal 1110 illustrates this point.
Referring now to Figure 12-14,, presented the flow process of the method that this each embodiment that provides is provided.In the flow process 1200 of Figure 12, presented the method that is used for the coding multi-channel audio signal.At frame 1210, receive the multi-channel audio signal with a plurality of sound signals.At frame 1220, multi-channel audio signal is encoded to generate the sound signal of coding.The sound signal of coding can be monophony or multi-channel signal, such as the illustrated stereophonic signal of giving an example in the accompanying drawings.And the sound signal of coding can comprise a plurality of sound channels.A more than sound channel can be arranged, and the number of the sound channel in enhancement layer can be greater than the number of the sound channel in core layer in core layer.Next, at frame 1230, generate the balance factor with balance factor component, each balance factor component is associated with a sound signal of multi-channel audio signal.The generation of balance factor has been described in formula (18), (21), (24), (33).Each balance factor component can be relevant to other balance factor components that generate, as the situation in formula (38).Generating balance factor can comprise: be created on the correlation between at least one in the sound signal of the coding audio signal of convergent-divergent and multi-channel audio signal, such as in formula (33), (36).Can as be created on the autocorrelation between at least one of sound signal in formula (38), can generate square root thus.At frame 1240, determine to be applied to the yield value of coding audio signal, to generate the estimation of multi-channel audio signal based on balance factor and multi-channel audio signal.This yield value is configured to be minimized in the distortion value between the estimation of multi-channel audio signal and multi-channel audio signal.Definite yield value has been described in formula (27), (28), (29), (30).Can select yield value from a plurality of yield values, with the sound signal of scalable coded, and the coding audio signal of generation convergent-divergent.Can estimate to generate distortion value based on this; This yield value can be based on this distortion value.At frame 1250, export the expression of this yield value to be used for transmission and/or storage.
The flow process 1300 of Figure 13 has been described the another kind of method that is used for the coding multi-channel audio signal according to each embodiment.At frame 1310, receive the multi-channel audio signal with a plurality of sound signals.At frame 1320, multi-channel audio signal is encoded to generate the sound signal of coding.As mentioned above, the core layer scrambler is carried out the processing of frame 1310 and 1320.As mentioned above, the sound signal of coding can be monophony or multi-channel signal, such as illustrational stereophonic signal in the accompanying drawings.And the sound signal of coding can comprise a plurality of sound channels.A more than sound channel can be arranged, and the number of the sound channel in enhancement layer can be greater than the number of the sound channel in core layer in core layer.
At frame 1330, utilize a plurality of yield values to come the sound signal of scalable coded, to generate the sound signal of a plurality of candidate code, at least one in the sound signal of described candidate code is scaled.Unit for scaling by the gain vector maker is completed convergent-divergent.As mentioned above, the sound signal of scalable coded can comprise that the yield value of the unit of utilization comes convergent-divergent.The yield value of a plurality of yield values can be gain matrix, wherein with vectorial g
jBe used as diagonal components as above.Gain matrix can be that frequency is selected.It can depend on the output of core layer, the sound signal of coding, as shown in the figure.Can select yield value from a plurality of yield values, with the sound signal of scalable coded and the coding audio signal of generation convergent-divergent.At frame 1340, generate the balance factor with balance factor component, each is associated described balance factor component with the sound signal of multi-channel audio signal.Carrying out balance factor by the balance factor maker generates.Each balance factor component can be relevant to another balance factor component that generates, as the situation in formula (38).Generate the correlation between at least one in the sound signal that balance factor can comprise the coding audio signal that is created on convergent-divergent and multi-channel audio signal, such as in formula (33), (36) like that.The autocorrelation between at least one in sound signal can be created on, as in formula (38), square root can be generated thus.
At frame 1350, generate the estimation of multi-channel audio signal based on the coding audio signal of balance factor and at least one convergent-divergent, generate this estimation based on the coding audio signal (a plurality of) of convergent-divergent and the balance factor that generates.This estimation can comprise a plurality of estimations corresponding with a plurality of candidates' coding audio signal.At frame 1360, based on the estimation of multi-channel audio signal with multi-channel audio signal is assessed and/or can generate distortion value, to determine the expression of the optimum gain value in yield value.Distortion value can comprise a plurality of distortion values corresponding with a plurality of estimations.Complete the assessment of distortion value by gain selection device circuit.Provide presenting of optimum gain value by formula (39).At frame 1370, expression that can the output gain value is to be used for transmission and/or storage.The transmitter of enhancement layer encoder can transmit as mentioned above yield value and represent.
The processing that comprises in the process flow diagram 1400 of Figure 14 illustrates the decoding of multi-channel audio signal.At frame 1410, the yield value of the sound signal of received code, the balance factor of coding and coding.At frame 1420, generate the yield value of decoding from the yield value of coding.Yield value can be gain matrix, and as mentioned above, and gain matrix can be that frequency is selected.The audio frequency of the coding that gain matrix also can receive to the output as core layer is relevant.And the sound signal of coding can be monophony or multi-channel signal, such as the illustrated stereophonic signal of giving an example in the accompanying drawings.In addition, the sound signal of coding can comprise a plurality of sound channels.For example, a more than sound channel is arranged, and the number of the sound channel in enhancement layer can be greater than the number of the sound channel in core layer in core layer.
At frame 1430, the yield value of utilization decoding comes the sound signal of scalable coded, to generate the sound signal of convergent-divergent.At frame 1440, the balance factor of coding is applied to the sound signal of convergent-divergent to generate the multi-channel audio signal of decoding.At frame 1450, the multi-channel audio signal of output decoding.
The selective scaling mask that detects based on peak value calculates
Can define frequency and select gain matrix G as in superincumbent (14)
j, this matrix is to have the gain vector of formation g
jThe diagonal matrix of diagonal element:
Wherein, Δ is step sizes (for example, Δ ≈ 2.0dB), and α is constant, and M is candidate's number (for example, M=8 can only represent it with 3 bits), and, k
lAnd k
hBe respectively low frequency and high-frequency cut-off frequency, on them, gain may occur reduce.At this, k represents k MDCT or fourier transform coefficient.Notice g
jBe that frequency is selected, but it have nothing to do with the output of previous layer.Gain vector g
jCan be based on the signal vector of previous coding---be in this case
---certain function of code element, this can be expressed as:
In multilayer embedded coded system (have surpass 2 layers), wherein, obtaining from the contribution of at least two previous layers will be by yield value vector g
jThe output of convergent-divergent
Namely
Wherein,
The output of ground floor (core layer), and
It is the contribution of the second layer or the first enhancement layer.In this case, gain vector g
jIt can be the signal vector of previous coding
The element of coding and certain function of the contribution of the first enhancement layer:
Observe, because the noise that the great majority that the encoding model of lower level causes can be heard is in valley, rather than be in peak value.In other words, between spectrum peak is in the frequency spectrum of original and coding, coupling is arranged preferably.Therefore, should not change peak value, that is, convergent-divergent should be limited to valley.In order advantageously to use this observation, in one of embodiment, the function in formula (41) based on
Peak value and valley.If
Be based on detected
The convergent-divergent mask of peak amplitude.The convergent-divergent mask can be vector valued function, and it has nonzero value at detected peak value place, namely
Wherein,
Be
I element.Formula (41) can be modified to now:
Can make and in all sorts of ways to carry out the peak value detection.In the preferred embodiment, come detection peak by following manner: transmit absolute frequency spectrum by two independent weighted mean wave filters
And the then output of filtering more.If A
1And A
2It is the matrix representation of two average filters.If l
1And l
2(l
1＞l
2) be the length of two wave filters.The peak value detection function is given:
Wherein, β is empirical value.
Property example as an illustration is referring to Figure 15 and Figure 16.At this, the absolute value of the signal of the coding in the MDCT territory
Be given 1510 at two in without line chart.This signal indication is from the sound of " pipe of setting the tone ", and the pipe of setting the tone creates the harmonic sequence of fixed intervals, as shown in the figure.Be difficult to based on speech model with core layer scrambler this signal of encoding, because the basic frequency of this signal is being thought for voice signal outside rational scope.This causes the quite high noise rank that produced by core layer, can be by with
coded signal 1510 and original signal | and the mono version of S| makes comparisons to observe this noise rank (1610).
Signal (1510) from this coding produces
threshold value 1520 with the threshold value maker, and
threshold value 1520 is corresponding to the expression formula in formula 45
At this, A
1Be convolution matrix, this convolution matrix utilizes the cosine window of length 45 to realize signal in the preferred embodiment
Convolution.Many window shape are possible, and can comprise different length.And, in the preferred embodiment, A
2It is unit matrix.Then, peak detctor is made comparisons signal 1510 and
threshold value 1520, is shown as 1530 convergent-divergent mask with generation
Then, core layer scale vectors candidate (providing in formula 45) can be used for convergent-divergent at coded signal
Peak value between noise, to produce the
reconstruction signal 1620 of convergent-divergent.Can or otherwise select optimal candidate according to the processing of describing in above formula 39.
Referring now to Figure 17-19,, presented diagram according to process flow diagram each embodiment, method that be associated with the selective scaling mask calculating that detects based on above-mentioned peak value.In the process flow diagram 1700 of Figure 17, at frame 1710, detect the audio frequency vector in the reconstruct of the sound signal that receives
In peak set.Can embed this sound signal in a plurality of layers.The audio frequency vector of this reconstruct
Can be in frequency domain, and described peak set can be the frequency domain peak value.For example, carry out this peak set of detection according to the peak value detection function that is provided by formula (46).Notice, this set can be empty, just as full content is attenuated and does not have the situation of peak value.At frame 1720, generate the convergent-divergent mask based on detected peak set
Then, at frame 1730, generate at least based on the convergent-divergent mask and be used for the gain vector g of the index j of expression gain vector
*At frame 1740, come the sound signal of convergent-divergent reconstruct with gain vector, to produce the reconstructed audio signal of convergent-divergent.At frame 1750, generate the distortion based on the reconstructed audio signal of sound signal and convergent-divergent.At frame 1760, output is based on the index of the gain vector of the distortion that generates.
Referring now to Figure 18,, process flow diagram 1800 illustrates the alternate embodiment according to the coding audio signal of specific embodiment.At frame 1810, received audio signal.Can be at embedded audio signal in a plurality of layer.Then, at frame 1820 coding audio signals, to generate the audio frequency vector of reconstruct
The audio frequency vector of reconstruct
Can be in frequency domain, and this peak set can be the frequency domain peak value.At frame 1830, detect the audio frequency vector in the reconstruct of the sound signal that receives
In peak set.For example, carry out the described peak set of detection according to the peak value detection function that is provided by formula (46).Again, notice, this set can be empty, just as full content is attenuated and does not have the situation of peak value.At frame 1840, generate the convergent-divergent mask based on detected peak set
At frame 1850, generate a plurality of gain vector g based on the convergent-divergent mask
jAt frame 1860, utilize a plurality of gain vectors to come the sound signal of convergent-divergent reconstruct, to produce the reconstructed audio signal of a plurality of convergent-divergents.Next, at frame 1870, generate a plurality of distortions based on the reconstructed audio signal of sound signal and a plurality of convergent-divergents.At frame 1880, select gain vector based on described a plurality of distortions from a plurality of gain vectors.This gain vector can be selected to corresponding with the minimum distortion of described a plurality of distortions.At frame 1890, the index that is used for the expression gain vector is output to transmit and/or store.
Can realize illustrated scrambler flow process in above Figure 17-18 by previous described apparatus structure.Reference flowchart 1700 at the device that can operate for coding audio signal, detects audio frequency vector in the reconstruct of the sound signal that receives such as the gain selection device of the gain selection device 1035 of the gain vector maker 1020 of enhancement layer encoder 1010
In peak set, and generate the convergent-divergent mask based on detected peak set
Again, can be at embedded audio signal in a plurality of layer.The audio frequency vector of reconstruct
Can be in frequency domain, and this peak set can be the frequency domain peak value.For example, carry out the described peak set of detection according to the peak value detection function that is provided by formula (46).Notice, if the full content in signal is attenuated, peak set can be zero.Unit for scaling such as the unit for scaling 1025 of gain vector maker 1020 generates gain vector g based on the index j of convergent-divergent mask and expression gain vector at least
*, utilize gain vector to come the sound signal of convergent-divergent reconstruct, to produce the reconstructed audio signal of convergent-divergent.The error signal maker 1030 of gain vector maker 1025 generates distortion based on the reconstructed audio signal of sound signal and convergent-divergent.Transmitter such as the transmitter 1045 of enhancement layer decoder 1010 can operate for the index of output based on the gain vector of the distortion that generates.
With reference to the
flow process 1800 of Figure 18, at the device that can operate for coding audio signal, the scrambler received audio signal, and this sound signal of encoding is to generate the audio frequency vector of reconstruct
Detect audio frequency vector in the reconstruct of the sound signal that receives such as the unit for scaling of the unit for scaling 1025 of
gain vector maker 1020
In peak set, generate the convergent-divergent mask based on detected peak set
Generate a plurality of gain vector g based on the convergent-divergent mask
j, and utilize a plurality of gain vectors to come the sound signal of this reconstruct of convergent-divergent, to produce the reconstructed audio signal of a plurality of convergent-divergents.
Error signal maker 1030 generates a plurality of distortions based on the reconstructed audio signal of sound signal and a plurality of convergent-divergents.Gain selection device such as
gain selection device 1035 is selected gain vector based on described a plurality of distortions from a plurality of gain vectors.For example,
transmitter 1045 outputs are used for the index of expression gain vector to transmit after a while and/or to store.
In the process flow diagram 1900 of Figure 19, illustrate the method for decoded audio signal.Audio frequency vector in
frame 1910 places reception reconstruct
Index with the expression
gain vector.At frame 1920, detect the peak set in the audio frequency vector of reconstruct.For example, carry out the described peak set of detection according to the peak value detection function that is for example provided by formula (46).Again, notice, this set can be empty, just as full content is attenuated and does not have the situation of
peak value.At frame 1930, generate the convergent-divergent mask based on detected peak set
At
frame 1940, generate at least based on the gain vector g of convergent-divergent mask with the index of expression gain vector
*At
frame 1950, utilize gain vector to come the sound signal of convergent-divergent reconstruct, to produce the reconstructed audio signal of convergent-divergent.The method may further include: generate the enhancing for the audio frequency vector of institute's reconstruct, and then with the reconstructed audio signal of convergent-divergent with make up to generate the decoded signal of enhancing for the enhancing of the audio frequency vector of institute's reconstruct.
Can realize illustrated demoder flow process in Figure 19 by previously described apparatus structure.At the device that can operate for decoded audio signal, for example, the
gain vector demoder 1070 of
enhancement layer decoder 1060 receives the audio frequency vector of reconstruct
Index i with the expression gain vector
gAs shown in Figure 10, gain selection device 1075 receives i
g, and the unit for scaling 1080 of
gain vector demoder 1070 receives the audio frequency vector of reconstruct
Detect peak set in the audio frequency vector of institute's reconstruct such as the gain selection device of the gain selection device 1075 of
gain vector demoder 1070, generate the convergent-divergent mask based on detected peak set
And the index based on convergent-divergent mask and expression gain vector generates gain vector g at least
*Again, if signal is decayed by major part, this set can be empty.For example, the gain selection device is according to detect this peak set such as the peak value detection function that provides in formula (46).For example, unit for scaling 1080 utilizes gain vector to come the audio frequency vector of convergent-divergent institute reconstruct, to produce the reconstructed audio signal of convergent-divergent.
And, can generate enhancing for the audio frequency vector of institute's reconstruct such as the error signal decoder of the error signal decoder 665 of the enhancement layer decoder in Fig. 6.Such as the signal combiner of the signal combiner 675 of Fig. 6 with the reconstructed audio signal of convergent-divergent and enhancing combination for the audio frequency vector of reconstruct, to generate the decoded signal that strengthens.
Further should be noted that and to come the flow process with selective scaling mask guiding that peak value detects of the flow process of balance factor guiding of execution graph 12-14 and Figure 17-19 and device described herein and structural support this point with various combinations.
Although specifically illustrated and described the present invention with reference to specific embodiment, it will be apparent to one skilled in the art that in the situation that without departing from the spirit and scope of the present invention, can carry out therein the various changes on form and details.For example, although the transmission of passing through channel in telecommunication system and receive and to have described above technology, described technology can be applicable to come for minimizing in the system such as the purpose of the memory requirement on the digital media equipment of solid storage device or hard disc of computer with signal compression system equally.Changing one's intention within the scope of appended claim like this.