CN113207304A - Converting static content items into interactive content items - Google Patents
Converting static content items into interactive content items Download PDFInfo
- Publication number
- CN113207304A CN113207304A CN201980004992.6A CN201980004992A CN113207304A CN 113207304 A CN113207304 A CN 113207304A CN 201980004992 A CN201980004992 A CN 201980004992A CN 113207304 A CN113207304 A CN 113207304A
- Authority
- CN
- China
- Prior art keywords
- content
- segments
- content item
- segment
- data processing
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
- 230000002452 interceptive effect Effects 0.000 title abstract description 268
- 230000003068 static effect Effects 0.000 title abstract description 147
- 238000013515 script Methods 0.000 claims abstract description 222
- 230000000007 visual effect Effects 0.000 claims abstract description 155
- 238000012545 processing Methods 0.000 claims abstract description 134
- 238000005192 partition Methods 0.000 claims abstract description 77
- 238000000034 method Methods 0.000 claims abstract description 48
- 230000009471 action Effects 0.000 claims abstract description 35
- 230000003993 interaction Effects 0.000 claims description 184
- 230000004044 response Effects 0.000 claims description 81
- 238000000638 solvent extraction Methods 0.000 claims description 25
- 230000011218 segmentation Effects 0.000 claims description 5
- 230000033001 locomotion Effects 0.000 abstract description 6
- 238000004891 communication Methods 0.000 description 16
- 238000004590 computer program Methods 0.000 description 11
- 230000006870 function Effects 0.000 description 9
- 238000009877 rendering Methods 0.000 description 9
- 230000008569 process Effects 0.000 description 8
- 238000010586 diagram Methods 0.000 description 7
- 230000003287 optical effect Effects 0.000 description 6
- 230000000670 limiting effect Effects 0.000 description 5
- 239000013598 vector Substances 0.000 description 5
- 238000013528 artificial neural network Methods 0.000 description 4
- 230000002123 temporal effect Effects 0.000 description 4
- 230000005540 biological transmission Effects 0.000 description 3
- 238000001514 detection method Methods 0.000 description 3
- 230000000977 initiatory effect Effects 0.000 description 3
- 238000010801 machine learning Methods 0.000 description 3
- 230000000644 propagated effect Effects 0.000 description 3
- 230000001953 sensory effect Effects 0.000 description 3
- 238000004422 calculation algorithm Methods 0.000 description 2
- 230000001413 cellular effect Effects 0.000 description 2
- 239000003795 chemical substances by application Substances 0.000 description 2
- 238000013527 convolutional neural network Methods 0.000 description 2
- 238000013461 design Methods 0.000 description 2
- 238000011161 development Methods 0.000 description 2
- 230000018109 developmental process Effects 0.000 description 2
- 238000010348 incorporation Methods 0.000 description 2
- 238000012417 linear regression Methods 0.000 description 2
- 230000007246 mechanism Effects 0.000 description 2
- 238000012544 monitoring process Methods 0.000 description 2
- 238000000926 separation method Methods 0.000 description 2
- 230000007704 transition Effects 0.000 description 2
- 206010012586 Device interaction Diseases 0.000 description 1
- 230000006399 behavior Effects 0.000 description 1
- 230000006835 compression Effects 0.000 description 1
- 238000007906 compression Methods 0.000 description 1
- 125000004122 cyclic group Chemical group 0.000 description 1
- 230000000694 effects Effects 0.000 description 1
- 239000000835 fiber Substances 0.000 description 1
- 239000004973 liquid crystal related substance Substances 0.000 description 1
- 238000007726 management method Methods 0.000 description 1
- 230000006855 networking Effects 0.000 description 1
- 238000004806 packaging method and process Methods 0.000 description 1
- 238000003825 pressing Methods 0.000 description 1
- 230000000306 recurrent effect Effects 0.000 description 1
- 239000004065 semiconductor Substances 0.000 description 1
- 239000000758 substrate Substances 0.000 description 1
- 238000012546 transfer Methods 0.000 description 1
- 238000012800 visualization Methods 0.000 description 1
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q50/00—Systems or methods specially adapted for specific business sectors, e.g. utilities or tourism
- G06Q50/10—Services
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/95—Retrieval from the web
- G06F16/958—Organisation or management of web site content, e.g. publishing, maintaining pages or automatic linking
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/30—Authentication, i.e. establishing the identity or authorisation of security principals
- G06F21/31—User authentication
- G06F21/36—User authentication by graphic or iconic representation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/10—Text processing
- G06F40/12—Use of codes for handling textual entities
- G06F40/151—Transformation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/10—Text processing
- G06F40/166—Editing, e.g. inserting or deleting
- G06F40/186—Templates
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F2221/00—Indexing scheme relating to security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F2221/21—Indexing scheme relating to G06F21/00 and subgroups addressing additional information or applications relating to security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F2221/2133—Verifying human interaction, e.g., Captcha
Abstract
At least one aspect of the present disclosure is directed to systems and methods for converting static content items into interactive content items. The data processing system may identify a first content item. The data processing system may divide the visual content of the first content item into a plurality of segments according to the partition template. The partition template may define a plurality of segments to be formed from the visual content. The data processing system may generate a second script. The second script may assign a location to each segment. The script may enable movement of each segment in the box. The script may determine that the segment is moved to the target location. The script may perform an action to provide information related to the visual content. The data processing system may provide the second content item to the client device.
Description
Background
In a computer networking environment, such as the internet, third party content providers provide third party content items for display on end user computing devices. These third-party content items may be displayed on web pages associated with respective publishers. These third-party content items may include content that identifies the third-party content provider that provided the content item.
Disclosure of Invention
At least one aspect of the present disclosure is directed to a method of converting a static content item into an interactive content item. The method may include identifying, by a data processing system including one or more processors, a first content item having visual content and a first script. The first script may be configured to present the visual content in response to the loading of the first content item. The method can include dividing, by the data processing system, the visual content of the first content item into a plurality of segments according to the partition template. The partition template may define a number of segments to be formed by the visual content, a shape of each segment of the plurality of segments, and a size of each shape. Each of the plurality of segments may correspond to a different portion of the visual content. The method may include generating, by the data processing system, a second content item to include the plurality of segments to be rendered in the box and a second script. The second script may be configured to: each of the plurality of segments is assigned to one of a plurality of locations in response to the loading of the second content item. Each location of the plurality of locations may define an area in the frame in which the segment is to be presented. The second script may be configured to render the plurality of segments within the frame according to the plurality of locations assigned to each of the plurality of segments. The second script may be configured to enable each of the plurality of segments to move between the plurality of locations within the frame through interaction. The second script may be configured to determine that the plurality of segments move from the plurality of locations to the target plurality of locations in response to detecting an interaction with one of the plurality of segments. The second script may be configured to perform an action that provides information related to the visual content in response to determining that the plurality of segments move to the target plurality of locations. The method may include providing, by the data processing system, the second content item to the client device to cause the client device to render the plurality of segments according to the second script.
In some implementations, the method can include selecting, by the data processing system, a partition template from a plurality of partition templates based on the visual content of the first content item. In some implementations, partitioning the visual content further includes: in response to selecting a partition template from the plurality of partition templates, the visual content is divided into a plurality of segments according to the partition template.
In some implementations, the method can include determining, by the data processing system, for each of a plurality of partition templates, a predicted interaction rate with visual content partitioned according to the respective partition template. In some implementations, the method can include selecting, by the data processing system, a partition template from a plurality of partition templates based on the predicted interaction rate determined for each of the plurality of partition templates. In some implementations, partitioning the visual content further includes: in response to selecting a partition template from the plurality of partition templates, the visual content is divided into a plurality of segments according to the partition template.
In some implementations, the method can include determining, by the data processing system, that the first content item is suitable for adding interactivity based on visual content of the first content item. In some implementations, partitioning the visual content further includes: in response to determining that the first content item is suitable, the visual content is divided into a plurality of segments according to the partitioning template.
In some implementations, the method can include identifying, by the data processing system, an initial plurality of locations of the plurality of segments as a target plurality of locations. Each location of the initial plurality of locations may define an area within the visual content of the first content item from which the segment is retrieved. In some implementations, generating the second content item further includes generating the second content item to include a second script configured to determine that the plurality of segments moved from the plurality of locations to the initial plurality of locations in response to detecting interaction with one of the plurality of segments.
In some implementations, the second script can be configured to present a prompt to initiate interaction with the second content item within the frame. In some implementations, in response to detecting interaction with the prompt, a plurality of segments are presented within the frame according to a plurality of locations.
In some implementations, the method can include generating a second content item to include a second script configured to perform an action including presenting a prompt to present information related to visual content, the information provided by a content provider associated with the first content item.
In some implementations, the method can include dividing the visual content into a plurality of segments according to a partition template. The partition template includes a piecewise path defining a number of segments to be formed, a shape of each segment of the plurality of segments, and a size of each shape.
In some implementations, the method can include receiving a request from a content provider to include interactivity into content, the request including a first content item. In some implementations, the method may include receiving, by the data processing system from the client device, an indication of the plurality of segments moving to the first plurality of locations in response to performing the action.
Another aspect of the present disclosure is directed to a system. The system may include a data processing system having one or more processors. The data processing system can identify a first content item having visual content and a first script. The first script is configured to present the visual content in response to the loading of the first content item. The data processing system may divide the visual content of the first content item into a plurality of segments according to the partition template. The partition template may define a number of segments to be formed by the visual content, a shape of each segment of the plurality of segments, and a size of each shape. Each of the plurality of segments may correspond to a different portion of the visual content. The data processing system may generate a second content item to include the plurality of segments to be rendered in the box and a second script. The second script may be configured to assign each of the plurality of segments to one of a plurality of locations in response to loading of the second content item. Each location of the plurality of locations may define an area in the frame in which the segment is to be presented. The second script may be configured to render the plurality of segments within the frame according to the plurality of locations assigned to each of the plurality of segments. The second script may be configured to enable each of the plurality of segments to move between the plurality of locations within the frame through interaction. The second script may be configured to determine that the plurality of segments move from the plurality of locations to the target plurality of locations in response to detecting an interaction with one of the plurality of segments. The second script may be configured to perform an action that provides information related to the visual content in response to determining that the plurality of segments move to the target plurality of locations. The data processing system may provide the second content item to the client device to cause the client device to render the plurality of segments according to the second script.
In some implementations, the data processing system can select a partition template from a plurality of partition templates based on the visual content of the first content item. In some implementations, the data processing system can divide the visual content into a plurality of segments according to a partitioning template in response to selecting the partitioning template from a plurality of partitioning templates.
In some implementations, the data processing system can determine, for each of a plurality of partition templates, a predicted interaction rate with visual content partitioned according to the respective partition template. In some implementations, the data processing system can select a partition template from the plurality of partition templates based on the predicted interaction rate determined for each of the plurality of partition templates. In some implementations, the data processing system can divide the visual content into a plurality of segments according to a partitioning template in response to selecting the partitioning template from a plurality of partitioning templates.
In some implementations, the data processing system can determine that the first content item is suitable for adding interactivity based on the visual content of the first content item. In some implementations, the data processing system can divide the visual content into a plurality of segments according to the partitioning template in response to determining that the first content item is suitable.
In some implementations, the data processing system can identify an initial plurality of locations of the plurality of segments as a target plurality of locations. Each location of the initial plurality of locations may define an area within the visual content of the first content item from which the segment is retrieved. In some implementations, the data processing system can generate the second content item to include a second script configured to determine that the plurality of segments moved from the plurality of locations to the initial plurality of locations in response to detecting an interaction with one of the plurality of segments.
In some implementations, the second script can present a prompt to initiate interaction with the second content item within the box. In some implementations, in response to detecting interaction with the prompt, a plurality of segments within the frame are presented according to a plurality of locations.
In some implementations, the data processing system can generate the second content item to include a second script configured to perform the action. The action may include presenting a prompt to present information related to the visual content. The information may be provided by a content provider associated with the first content item.
In some implementations, the data processing system can divide the visual content into a plurality of segments according to a partition template. The partition template includes a segmentation path defining a number of segments to be formed, a shape of each segment of the plurality of segments, and a size of each shape.
In some implementations, a data processing system can receive a request from a content provider to include interactivity into content, the request including a first content item. In some implementations, the data processing system may receive, from the client device, an indication of the plurality of segments moving to the first plurality of locations in response to performing the action.
Drawings
The accompanying drawings are not intended to be drawn to scale. Like reference numbers and designations in the various drawings indicate like elements. For purposes of clarity, not every component may be labeled in every drawing. In the drawings:
FIG. 1A shows a block diagram depicting an example environment or system for converting static content items into interactive content items.
FIG. 1B shows a diagram depicting an example transition from a static content item to an interactive content item.
FIG. 2 shows a diagram illustrating an example partitioning of static content items according to a partition template.
FIG. 3 shows a diagram illustrating an example of interaction with an interactive content item.
FIG. 4 illustrates a flow chart of an example method of converting a static content item to an interactive content item.
FIG. 5 shows a block diagram of the general architecture of an illustrative computer system that may be used to implement any of the computers discussed herein.
Detailed Description
The following is a detailed description of various concepts related to a method, apparatus, and system for converting static content into interactive content and implementations thereof. The various concepts introduced above and discussed in greater detail below may be implemented in any of numerous ways, as the described concepts are not limited to any particular implementation.
The content provider platform may provide static content items for presentation on information resources (e.g., web pages) and with which human users may interact. In some cases, the content provider platform may wish to ensure that the user is a human user to prevent, or at least detect, when interactions with providing content items are performed by an automated agent or online bot. Many mechanisms are currently being used to perform this function, such as CAPTCHA checking, but additional mechanisms may be required. Furthermore, CAPTCHA checks typically require additional data to be sent to the user device and interrupt the provision of information that the user has requested.
The content items provided by the content provider platform may include static content items. The static content items may include a wide variety of content, such as text, images, video, and audio, or any combination thereof. However, such content items have limited functionality, in particular with respect to interactivity. For example, in response to an interaction, the content item may merely redirect the application (e.g., a web browser) to another information resource (also referred to herein as a landing page). Because static content items are less interactive, static content items may result in less human-computer interaction (HCI) than comparable interactive content items. Furthermore, by sending static content items that do not cause interactions (e.g., low click-through rates and HCI), the content provider platform wastes network resources that could otherwise be used for content that causes interactions or other responses from users.
Interactive content items may address some of the shortcomings of static content items and may improve user interactivity and interaction performance with content items. The interactive content items may be displayed to increase the click through rate of the content items when compared to still image-based or text-based content items. Static-based content items are distinguished from interactive content items by: they may not provide any interaction other than redirection to a landing page associated with the publisher of the content item. Interactive content items, on the other hand, may provide more user interaction and participation opportunities than static content items, and may be, for example, mini-games. Interactive content items may require more development time by content publishers, which may be disadvantageous to both large and small content publishers. Furthermore, due to the effort required to create interactive content items, the quality may vary greatly between different providers and platforms. Because of their complexity, manually created interactive content items can be large, consume disk space or memory, and thus consume significant network resources when communicating between computer networks.
To address the foregoing technical problem, a content distribution platform may automatically generate interactive content items from image, video, or text-based assets received from content publishers. The assets may initially be static with little to no interactivity other than redirection to a landing page when interacting with a content item. The platform may analyze assets received from content publishers and generate HTML5 and JavaScript instructions to create bundles that can be provided to client devices for execution in a web browser or native application. The generated bundle may provide an interactive content item that may provide feedback to the content distribution platform regarding the client device's interaction with the content item. Each of these steps may be performed by an interactive content pipeline (pipeline) provided by the content distribution platform using the systems and methods described herein, thereby providing a convenient and fast way to generate interactive content items from static assets.
To generate the bundle, the content distribution platform can identify image assets provided by the content publisher to determine whether the assets are suitable for incorporation into the interactive content item. After determining that the assets are suitable for interaction, the content distribution platform may generate an interactive bundle by dividing the static content into a number of pieces or segments using the partition template. The partition template may be, for example, a scalar vector graphical path, and may define the number of segments to be generated, the size of each segment, the shape of the segments, and the positions of the segments relative to each other. These pieces may correspond to interlocking portions of a static asset, for example, in the form of puzzle (puzzle) pieces. In conjunction with dividing the static asset into segments, the content provider platform may generate a script that controls the behavior of the interactive content item when executed on the client device. After the script has been generated, the content provider platform may combine the generated segments and the generated script into an HTML5 bundle, which is then provided to the client device for execution. Furthermore, each of these steps may be performed without intervention or guidance by the content distribution platform, enabling interactive content to be generated quickly and automatically.
Once loaded on the client device, the script may cause the client device to render and randomly distribute the generated segments within the content item box on the client device and allow the user to interact with the segments to move them to different locations. The script may randomly assign segments each time the script is run on the client device, thereby providing a different experience each time the interactive content item is displayed. In addition, the script may provide progress updates to the platform regarding the interaction between the end user and the interactive content item. For example, the script may provide an indication to the platform that the segment has been returned to its original location (e.g., the puzzle has been resolved).
Thus, the technical solution described herein may provide a content item that requires user interaction before further action is enabled. This may enable the content provider to determine that the entity interacting with the content item is a human user, rather than an automated agent. This may also be implemented in the process of providing content that may be provided without the need to provide, execute, and store other interactive elements, such as CAPTCHAs. Furthermore, the solution described herein may provide enhanced human-computer interaction by generating interactive content items and significantly reduce the development time of content item-based complex HTML 5. By sending interactive content items with higher click-through rates and interactivity, the content provider platform may make better and efficient use of network resources relative to communicating static content items. Furthermore, by generating HTML5 bundles within a predetermined size requirement, memory and disk space may be saved, and the amount of network resources used when communicating interactive content items may be reduced. The predetermined size requirement allows the content provider platform to control and improve network utilization of the generated interactive content items.
Referring now to FIG. 1A, a block diagram of a system or environment 100 that converts static content items into interactive content items is depicted. The environment 100 may include at least one computer network 110. The environment 100 may include at least one content publisher 115. The environment 100 may include at least one content provider 175. The environment 100 may include at least one client device 120A-N (hereinafter referred to generally as client devices 120). The environment 100 may include at least one data processing system 105. The data processing system 105 may include at least one content retriever 125, at least one content partitioner 130, at least one content packager 135, at least one interaction predictor 140, at least one template selector 145, and at least one performance monitor 150. The data processing system 105 may include at least one database 155. In some implementations, the data processing system 105 can include a content publisher 115. In some implementations, the data processing system 105 can include a content provider 175. In some implementations, the database 155 may be located external to the data processing system 105. The database 155 may include content items 160A and 160B (hereinafter referred to generally as content items 160), templates 165, and a script library 170.
Each of the components of environment 100 (e.g., network 110, content publisher 115, content provider 175, client device 120, data processing system 105, content retriever 125, content partitioner 130, content packager 135, interaction predictor 140, template selector 145, performance monitor 150, database 155, content items 160A and 160B, template 165, and script library 170) may be implemented using hardware components or a combination of software and hardware components of computing system 500 described in detail herein in connection with FIG. 5. For example, the data processing system 105 may include a server or other computing device. Content provider 175 and content publisher 115 may also include servers or other computing devices. Each component of the data processing system 105 may perform the functions detailed herein.
The network 110 may include a computer network (such as a local internet, a wide area network, a metropolitan area network, or other local area network, an intranet, a satellite network), other computer networks (such as a voice or data mobile telephone communication network), and combinations thereof. The data processing system 105 of the environment 100 may communicate with, for example, at least one content publisher 115 and at least one content provider 175 and at least one client device 120 via the network 110. Network 110 may be any form of computer network that relays information between client device 120, data processing system 105, and one or more content sources (such as web servers), among others. In some implementations, the network 110 may include the internet and/or other types of data networks, such as a Local Area Network (LAN), a Wide Area Network (WAN), a cellular network, a satellite network, or other types of data networks. Network 110 may also include any number of computing devices (e.g., computers, servers, routers, network switches, etc.) configured to receive and/or transmit data within network 110. Network 110 may also include any number of hardwired and/or wireless connections. The client device 120 may communicate wirelessly (e.g., via WiFi, cellular, radio, etc.) with a transceiver that is hardwired (e.g., via fiber optic cable, CAT5 cable, etc.) to other computing devices in the network 110. The client device 120 may also communicate wirelessly with computing devices of the network 110 via a proxy device (e.g., a router, network switch, or gateway).
The data processing system 105 may include at least one processor and memory, i.e., processing circuitry. The memory stores processor-executable instructions that, when executed by the processor, cause the processor to perform one or more of the operations described herein. The processor may comprise a microprocessor, an Application Specific Integrated Circuit (ASIC), a Field Programmable Gate Array (FPGA), the like, or a combination thereof. The memory may include, but is not limited to, electronic, optical, magnetic, or any other storage or transmission device capable of providing program instructions to the processor. The memory may also include a floppy disk, a CD-ROM, a DVD, a magnetic disk, a memory chip, an ASIC, an FPGA, a read-only memory (ROM), a Random Access Memory (RAM), an Electrically Erasable Programmable ROM (EEPROM), an Erasable Programmable ROM (EPROM), a flash memory, an optical medium, or any other suitable memory from which a processor may read instructions. The instructions may include code from any suitable computer programming language. The data processing system 105 may include one or more computing devices or servers that may perform various functions.
The client device 120 may be a device configured to communicate via the network 110 to display data such as content provided by the content publisher 115 (e.g., original web page content or other information resources) and content provided by the content provider 175 (e.g., content items configured for display in information resources). Client device 120 may be a desktop computer, laptop computer, tablet computer, smart phone, personal digital assistant, mobile device, consumer computing device, server, client, digital video recorder, set-top box for a television, video game console, or any other computing device configured to communicate via network 110, and so forth. Client device 120 may be a communication device through which an end user may submit a request to receive content. The request may be a request for a search engine, and the request may include a search query. In some implementations, the request can include a request to access a web page.
Client device 120 may include a processor and memory, i.e., processing circuitry. The memory stores machine instructions that, when executed by the processor, cause the processor to perform one or more of the operations described herein. The processor may comprise a microprocessor, an Application Specific Integrated Circuit (ASIC), a Field Programmable Gate Array (FPGA), the like, or a combination thereof. The memory may include, but is not limited to, electronic, optical, magnetic, or any other storage or transmission device capable of providing program instructions to the processor. The memory may also include a floppy disk, a CD-ROM, a DVD, a magnetic disk, a memory chip, an ASIC, an FPGA, a read-only memory (ROM), a Random Access Memory (RAM), an Electrically Erasable Programmable ROM (EEPROM), an Erasable Programmable ROM (EPROM), a flash memory, an optical medium, or any other suitable memory from which a processor may read instructions. The instructions may include code from any suitable computer programming language.
Client device 120 may also include one or more user interface devices. In general, a user interface device refers to any electronic device (e.g., a keyboard, a mouse, a pointing device, a touch screen display, a microphone, etc.) that communicates data to a user by generating sensory information (e.g., a visualization on a display, one or more sounds, etc.) and/or converting sensory information received from the user into electronic signals. The one or more user interface devices may be internal to the housing of client device 120 (e.g., a built-in display, microphone, etc.) or external to the housing of client device 120 (e.g., a monitor connected to client device 120, a speaker connected to client device 120, etc.). In some implementations, the client device 120 can include an electronic display that visually displays a web page using web page data received via the network 110 from one or more content sources and/or from the content publisher 115 or the content provider 175.
The content retriever 125 may identify at least one static content item 160A to which interactivity is added. The static content item 160A may be associated with one of the content providers 175. The static content item 160A may be a content item with minimal interactivity and include static visual content such as text, images, audio, or video, and a script that directs the client device 120 to a landing page in response to an interaction thereon. In some implementations, the content retriever 125 can access the database 155 to retrieve the static content item 160A. In some implementations, the content retriever 125 can identify static visual content to be included in the static content item 160A. The identification of static visual content may be the opposite of the identification of the entire static content item 160A itself. In some implementations, the content retriever 125 can automatically identify the static content item 160A without any command or request to add interactivity to the static content item 160A.
In some implementations, the content retriever 125 can receive a request from the content provider 175 to include interactivity into the static content. In some implementations, the request can be generated and sent by content provider 175 using a graphical user interface for a content placement platform associated with data processing system 155. The graphical user interface may include a user interface that triggers the request to include interactivity with the static content item 160A. For example, a graphical user interface may be used to upload the static content item 160A to the data processing system 105. The graphical user interface may include a prompt with an option (e.g., corresponding to a radio button) to include interactivity with the static content item 160A. Once this option is selected, content provider 175 may send a request to add interactivity to static content item 160A. In some implementations, the content retriever 125 can receive one or more static content items 160A included in the request. In some implementations, the content retriever 125 can retrieve the visual content 180 of each static content item 160A as part of the request. The request may include a desired type of interaction (e.g., a trivia game, other type of interaction, etc.).
The request received by the content retriever 125 can be the start of an interactive content generation pipeline, which can convert static content assets provided by the content provider 175 into interactive content items. Each of the techniques described herein with respect to the data processing system 105 or any of its components (e.g., content retriever 125, content divider 130, content packager 135, interaction predictor 140, template selector 145, performance monitor 150, content items 160A-B, templates 165, and script library 170) may be performed using minimal input from the content provider 175 (e.g., only a single request to provide static content). In this manner, interactivity may be added to static content without requiring manual or laborious work of the part of content provider 175.
In some implementations, upon receiving the static content item 160A (or visual content therein) from the content provider 175, the content retriever 125 can store the static content item 160A in the database 155. In some implementations, the request can include information identifying the static content item 160A in the database 155 (e.g., a URL address of the static content item 160A or the visual content 180). Upon receiving the information identifying the static content item 160A, the content retriever 125 may access the database 155 to retrieve the static content item 160A. In some implementations, the content retriever 125 may receive the target device information included in the request. For example, the request may include information indicating that the interactive content is to be provided to a device having a predetermined screen resolution.
Referring now to FIG. 1B, an example transition from a static content item 160A to an interactive content item 160B is depicted. The static content item 160A may include static visual content 180. The static visual content 180 may include, for example, images, video, or text. The static visual content 180 may be associated with or attributed to one or more parameters, such as dimensions (e.g., dimensions of an image or video), descriptive keywords, estimated interaction rates, and/or content metadata, among others. The static visual content 180 may be drawn, rendered, or otherwise displayed in a frame (frame). The box may define an area where the content item may be provided. In some implementations, the box may exist among other content, such as an information resource provided by the content publisher 115. The static content item 160A can include at least one static content script 185. In some implementations, the static content script 185 can open a login page on the client device 120 in response to interaction (e.g., clicking, pressing, or touching the screen) with the static content item 160A. The static content script 185 may cause the static visual content 180 of the static content item 160A to be rendered, animated, displayed, or otherwise presented. In some implementations, the static content script 185 can send information about the client device 120 to the content provider 175 or the content publisher 115. In some implementations, the static content script 185 can send interaction information about the static content item 160A to the content provider 175 or the content publisher 115. In some implementations, the static content script 185 may not provide a prompt to the client device 120. Upon detecting the input, the static content script 185 may not enable interaction with the static visual content 180 other than directing the client device 120 to a login page.
Through the identification of the static content item 160A, the content retriever 125 can determine whether the static content item 160A is suitable for adding interactivity. To determine suitability, the content retriever 125 can identify one or more parameters of the static content item 160A, such as dimensions (e.g., height and width) of the static visual content 180. With this identification, the content retriever 125 may determine whether the parameters of the static content item 160A satisfy specified parameters to suit. For example, the static visual content 180 may be designated as being within a particular range of widths and heights, as appropriate.
In some implementations, the content retriever 125 can determine eligibility (eligibility) of the static content item 160A based on the content of the visual content 180 of the static content item 160A. For example, visual content 180 with a large amount of text may not be appropriate for an interactive content item, while visual content depicting an image without text may be appropriate. In some implementations, the content retriever 125 can use machine learning algorithms (e.g., neural networks, convolutional neural networks, recurrent neural networks, linear regression models, and sparse vector machines) to determine eligibility for static content. The content retriever 125 can input one or more static content items 160A into the machine learning model and receive an output signal from the model indicating that the static content fits into interactivity.
In some implementations, the content retriever 125 can display the interactive content item 160B generated from the static content item 160A on the target client device 120 based on the eligibility of the target client device 120 to determine the static content item 160A. The target client device 120 may correspond to the type of client device (e.g., smartphone, desktop, or laptop) for which the interactive content item 160B is provided. Client devices 120 may have different display and input/output capabilities, and a static content item 160A that is appropriate for interaction on one type of client device 120 may not be appropriate for interaction on another type of client device 120. The target client device 120 may be predefined according to the display capabilities of the type of client device 120. For each type of client device 120 corresponding to a target client device 120, the content retriever 125 may determine whether the static visual content 180 is appropriate. To fit a certain type of client device 120, the static visual content 180 may be designated to be within a range of widths and heights. In some implementations, upon determining that the static content item 160A is appropriate for the type of client device 120, the content retriever 125 can store an association of the target client device 120 with the static content item 160A to the database 155.
If it is determined that the static content item 160A does not fit, the content retriever 125 (and the data processing system 105) may cease further processing of the static content item 160A and may maintain the static content item 160A. Otherwise, if the static content item 160A is determined to be suitable, the content retriever 125 (and the data processing system 105) may further process the static content item 160A to add interactivity to the static content item 160A. In some implementations, the content retriever 125 can store the static content item 160A to the database 155 for further processing to include interactivity. The processing of the static content item 160A is described in detail below.
Template selector 145 may select one of the set of templates 165 from database 155 based on the visual content 180 of static content item 160A. Each template 165 may include at least one segmentation path that defines the number of segments 190 to be formed, the shape of each segment 190, and the dimensions of each shape. In some implementations, the segmentation path may be a Scalable Vector Graphics (SVG) path. The SVG path may define the boundaries of one or more segments 190. Each segment 190 may have a size, shape, and location. In some implementations, the template 165 can include instructions to divide the static visual content 180 into a predetermined number of equally sized shapes, each shape having a predetermined position. In some implementations, the template 165 can include instructions to divide the static visual content 180 into a predetermined number of interlocking shapes (e.g., tiles), each having a predetermined position. In some implementations, the number of segments 190 and the size, shape, and location of each segment 190 may be predetermined. In some implementations, the number of segments 190 and the size, and location of each segment 190 can be dynamically determined by template selector 145 based on input from content provider 175. For example, content provider 175 may include the size, position, shape, and size of segment 190 in template 165 in a request to generate interactive content. The content divider 130 may use the template 165 to create one or more segments 190 from the static visual content 180.
In some implementations, template selector 145 may select template 165 based on dimensions (e.g., width and height) of visual content 180. In some implementations, some of the set of templates 165 can be applied to static visual content 180 having a particular dimension or size. Selection of the template 165 may be in response to determining that the static content item 160A is suitable for adding interactivity. Each of the templates 165 may be selected for static visual content 180 having a particular width or height. Template selector 145 may select template 165 by comparing compatible width and height information for static visual content 180 with the width and height of template 165. Template selector 145 may select template 165 if the width and height specifications of template 165 are sufficiently similar to the width and height of static visual content 180 (e.g., their respective differences are less than a predetermined threshold, such as within 10% of the difference). If the width and height are not sufficiently similar (e.g., differ by more than 10%), template selector 145 may compare parameters of different templates from the set of templates 165. In some implementations, template selector 145 may select template 165 based on the target client device 120 on which interactive content item 160B is to be displayed. For example, one template 165 may be optimized for a mobile device (e.g., smartphone, tablet, etc.), while another template 165 may be optimized for a personal computing device (e.g., laptop, desktop, etc.).
In some implementations, to select one of the templates 165, interaction predictor 140 may calculate, determine, or predict an interaction rate for each template 165 maintained on database 155. The interaction rate may indicate a number of impressions (e.g., browsing, clicking, or other interactions) associated with the interactive content item 160B generated using the particular template 165. In some implementations, the interaction rate may represent an estimated click-through rate of the interactive content item 160B generated using the corresponding template 165. In some implementations, the interaction rate may represent an estimated browsing (view-through) rate of the interactive content item 160B generated using the corresponding template 165. The interaction rate may be predicted based on the visual content 180 of the static content item 160A, the target platform of the interactive content item 160B, and/or the type of template 165. In some implementations, the interaction rate for each template 165 may be determined based on the number of segments 190 defined by each template 165. For example, if the target device is a type of mobile device (e.g., smartphone, tablet, e-reader, etc.), the interaction rate for a template 165 with many small segments 190 may be lower than the interaction rate for a template 165 with a few larger segments 190.
In some implementations, the interaction predictor 140 may determine the interaction rate of the template 165 based on feedback from one or more client devices 120. The client feedback may be used to train an interaction model, which may be a machine learning model (e.g., linear regression, neural network, convolutional neural network, cyclic neural network, sparse vector machine, etc.). The client feedback may include the type of client device 120, the type of interaction with the interactive content item 160B generated using the template 165 (e.g., click, hover, key press, and touch screen), the duration of the interaction, and whether the interactive content item 160B displayed on the client device 120 resulted in access to a landing page associated with the interactive content item 160B. Interaction predictor 140 may store the interaction rate for each template 165 in database 155 at a location associated with the respective template 165. In some implementations, the interaction predictor 140 may determine an interaction rate for each type of client device 120 (e.g., a smartphone, a smartwatch, a tablet, a laptop, a personal computer, other computing device, etc.). Interaction predictor 140 may store the interaction rate for each client device 120 at a location in database 155 associated with corresponding template 165.
In some implementations, template selector 145 may select template 165 from database 155 based on the corresponding interaction rate determined by interaction predictor 140. The templates 165 used to create the interactive content item 160B from static content provided by the content provider 175 can affect the overall interaction rate of the interactive content item 160B. For example, a particular template 165 may have a higher interaction rate on a particular type of client device 120. Template selector 145 may access database 155 to determine the interaction rate for each template 165. In some implementations, template selector 145 may select template 165 with the highest interaction rate. In some implementations, template selector 145 may select template 165 having the highest interaction rate for the type of client device 120 (e.g., smartphone, tablet, laptop, personal computer, other computing device, etc.). For example, template selector 145 may select template 165 having the highest interaction rate with the smartphone.
By selection, the content divider 130 may divide the visual content 180 of the static content item 160A into a plurality of segments 190A-N (hereinafter generally referred to as segments 190) according to the selected partition template 165. Each segment 190 may include parameters that define the respective dimensions, shape, size, and location of the segment 190. Each segment 190 may have or be assigned an original position corresponding to a portion of the visual content 180 from which the segment 190 originated. The original position may define the coordinates of the segment 190 because the segment 190 corresponds to the original static visual content 180. The coordinates of segment 190 may be defined by template 165 and may include an index position (e.g., in the form of (x, y)) or pixel coordinates, among others. In some implementations, the original position of segment 190 may correspond to the upper left corner of segment 190 as defined by template 165. In some implementations, the original location of segment 190 may correspond to the center of segment 190 as defined by template 165. The content divider 130 may apply the instructions in the template 165 to the visual content 180 of the static content item 160A to generate one or more segments 190. For example, template 165 may include an SVG path that may define the boundaries of one or more content shapes. Applying the SVG path to the static visual content 180 may cut the static visual content 180 into one or more segments 190 defined by the SVG path. The SVG path may be configured such that each segment 190 seamlessly mates (fit) with all other segments 190 in template 165. In some implementations, template 165 is configured such that segments 190 do not fit together seamlessly, but rather include gaps between each segment 190.
In partitioning the static visual content 180, the content partitioner 130 may determine a target location for each segment 190. For each segment 190, the content divider 130 may identify the original location as the target location. One or more segments 190 may be assigned a target location based on the segment locations included in template 165. The target location may define a location (e.g., an index location or a pixel location) in which each segment 190 of the interactive content item 160B may appear to create a completion condition. Content divider 130 may store segments 190 at locations in computer memory (e.g., database 155). For example, template 165 may include nine segments, with three rows of three equally sized square segments. Because segments 190 are square in this example, each segment 190 may have an equal width and height. When the example template 165 is applied to the static visual content 180, the static visual content 180 may be divided into nine equal-sized segments, and each segment may include a unique portion of the static visual content 180, such as in fig. 2. Immediately after applying the template 165 to the static visual content 180, a target location for each segment 190 may be assigned to each segment 190 by the content divider 130 based on the location of the corresponding segment. In some implementations, the target location may be stored as two-dimensional coordinates. In some implementations, the target location can be stored as a relative location value (e.g., upper left corner) to the original location in the static visual content 180. In some implementations, the target location of each segment 190 may be a relative location with respect to another segment 190 (e.g., the right edge of segment zero may border the left edge of segment one, etc.). Content divider 130 may store the target location of each segment 190 in a data structure in computer memory (e.g., database 155).
The content divider 130 may include additional visual elements of the static visual content 180. In some implementations, the content retriever 135 can add the overlay element to the static visual content 180 in response to receiving an indication to create the interactive content item. For example, the content retriever 135 may insert edits specifying that the static visual content 180 or the segments 190 formed therefrom are initially obscured (e.g., by a digital cloud or a fog animation, etc.) until cleared in response to a user interaction. The content divider 130 may provide the static visual content 180 and additional visual elements for packaging into the interactive content item 160B to the content packager 135.
Referring now to FIG. 2, the use of a partition template 220 to divide static visual content 180 into segments 190 for incorporation into an interactive content item 160B is depicted. In the context of fig. 1A and 1B, the content divider 130 may use a partition template 220 (corresponding to one of the templates 165) selected by the template selector 145 to divide the static visual content 180 into nine segments 190A-I. The partition template 220 may include one or more SVG paths (e.g., as depicted) that may partition the static visual content 180 such that the segments 190 may interlock. At step 210, content divider 130 may identify a target location for each segment 190A-I, as depicted positioned as an original location for the respective segment 190A-I. The target location may be a location of the segment 190 after being divided by the content divider 130. Although it is described herein that segments 190A-I occur at particular locations, it should be understood that partition template 220 may specify a target location for each segment 190, and that segments 190A-I may occur at any location. At step 215, when segments 190A-I are rendered, the initial assigned position of segment 190 may be different from the original position. For example, each segment 190 may be randomly assigned to a location by the script.
The content packager 135 can generate an interactive content item 160B that includes the segmented segment 190 from the visual content 180 and an interactive script 195 that replaces the original static content script 185. In some implementations, the content packager 135 can generate an interactive content item 160B that includes the static visual content 180 and an interactive script 196 that replaces the original static script 185. The content packager 135 may generate an interactive script 195. The interactive script 195 may include instructions executable by a computing device. For example, the interactive script 195 may include JavaScript, HTML5, PHP, or any other type of machine-executable instructions. The interactive script 195 may also include metadata (e.g., metadata about the visual content 180), the size or other metadata of the interactive content item 160B, and the like. The metadata may be stored in a data structure, or in a particular format for maintaining metadata (e.g., JSON).
In some implementations, the interactive scripts 195 may download, cache, or otherwise access executable instructions, such as one or more script libraries 170. Each script library 170 provides one or more functions or instructions that may be common to other operations of the interactive script 195 performed by the client device 120. For example, the script library 170 may include JavaScript libraries that may be included to enhance the functionality of JavaScript code. Additionally, the script library 170 may include an HTML5 library, which may be provided as an HTML5 library to extend the functionality of the HTML5 code. In some implementations, the interactive script 195 can cache one or more script libraries 170 retrieved from the database 155 in computer memory of the client device 120. In some implementations, the cached script library 170 can be accessed by one or more interactive content items 160B. For example, the interactive script 195 may access computer memory on the client device 120 to determine whether the script library 170 resides on the client device 120. When the script library 170 is accessed via the client device 120, the interactive script 195 may provide for interaction with the segments 190 without providing separate instructions for the interaction. In this manner, the file size of the interactive content item 160B may be reduced relative to a separate application that provides similar interactivity on graphical elements. In this way, the amount of network bandwidth consumed in communicating the interactive content item 160B over the network 110 may be reduced relative to the communication of such applications. In some implementations, the interactive script 195 may be read and executed by the client device 120 for which the interactive content item 160B is provided.
The content packager 135 may determine a file size specification for the interactive content item 160B and generate the interactive content item 160B such that the total size of the interactive content item 160B is less than or equal to the size specification. In some implementations, the size specification can be received from the content provider 175. In some implementations, the size specification may be a predetermined value. By limiting the size of the generated interactive content item 160B, the content packager 135 can generate the interactive content item 160B to match a particular bandwidth specification of the computer network and provide additional control to network resources to provide the interactive content item 160B.
The content packager 135 may configure the interactive script 195 to assign each segment 190 of the static visual content 180 to a new location when executed. The location of at least some of the segments 190 may be an initial location of each segment 190, which may be different from a target location of each segment. The initial position may be the position of the display segment 190 after the interactive script 195 is executed. The segments 190 may be moved from an initial position to a target position based on the input to provide a prompt or other action through the interactive script 195. The initial position of each segment 190 may be assigned to increase the overall interactivity of the interactive content item 160B. To achieve the target condition, the interactive script 195 may be configured to define each segment 190 to be returned to the target location. The content packager 135 may configure the interactive script 195 to assign at least some of the segments 190 to locations that are not equal or match the original locations. The assigned positions may maximize interactivity of the content item (e.g., all segments 190 will be interacted with to reach a target condition). In some implementations, each time the client device 120 executes the interactive script 195, the content packager 135 can configure the interactive script 195 to randomly assign each segment 190 to a random location (e.g., using a pseudorandom number generator).
In implementations where segments 190 are not present in the interactive content item 160B, the content packager 135 may configure the interactive script 195 to initially obscure the static visual content 180 included in the interactive content item 160B. The content packager 135 may obscure the static visual content 180 by rendering a fog effect on the static visual content 180, or by rendering some other image or animation in the foreground of the rendering pane that provides the interactive content item 160B. In some implementations, the content packager 135 may configure the interactive script 195 to render a "scratch-off" surface that may partially expose the static visual content 180 in response to one or more input events. For example, a swipe may expose coordinate position values of the static visual content 180 at which the interaction occurred. In some implementations, the content packager 135 can implement one or more event listeners to determine the coordinates of the interaction event. Based on the coordinates of the interaction event, the interactive script 195 configured by the content packager 135 may provide one or more animations at those coordinates and expose portions of the static visual content 180.
The content packager 135 may configure the interactive script 195 to present a prompt via a user interface for initiating interaction with the interactive content item 160B. The prompt may be a small window or dialog box that may appear in the box in which interactive content item 160B is rendered. The prompt or dialog box may include text that references the interactive request. The prompt may include one or more buttons that may trigger the script to continue execution in response to the interaction. In some implementations, the content packager 135 can configure the interactive script 195 to provide options for interaction and options for static content. In some implementations, the prompt may include details of the nature of the interactive content item 160B (e.g., a trivia game or other type of interactive content, etc.). For example, the prompt may include an instruction that outlines a rule or goal to interact with the interactive content item 160B, such as "please complete a puzzle. In some implementations, the content packager 135 may configure the interactive script 195 to pause enabling interaction with the segment 190 until interaction with the prompt has been detected. In some implementations, in response to detecting selection of an interaction option from the prompt, the interactive script 195 may continue to execute as described herein. Conversely, when the interaction option is not selected, the interactive script 195 may stop executing. In some implementations, when the interaction option is not selected, a different kind of content may be displayed in place of the interactive content item 160B.
The content packager 135 may configure the interactive script 195 to display, render, or otherwise render the segments 190 of the interactive content item 160B. Presentation of segment 190 may be in response to detecting an interaction with a presented prompt. The interactive script 195 may access graphical functions from the client device 120 executing the interactive script 195. The graphical function may be used to render, draw, or otherwise visually display the segment 190 in the box in which the interactive content item 160B is provided, such as in a web page or native application. The box may define an area where third party content may be displayed, such as static content item 160A or interactive content item 160B. The frame may include a presentation boundary (e.g., width and height) that may provide a limit by which the content item may be displayed. In some implementations, the boxes have fixed locations in other content, such as information resources provided by the content publishers 115. In some implementations, the box may occupy the entire screen of the client device 120 (e.g., displayed in full screen mode). In some implementations, the boxes may be provided dynamically in the media stream (e.g., in video or other media content). Segment 190 of interactive content item 160B may be rendered within a box. In some implementations, the content packager 135 may configure the interactive script 195 to cause the segment 190 to be rendered, drawn, or otherwise visually displayed in full-screen mode. In some implementations, the content packager 135 can configure the interactive script 195 so that it can render the segment 190 without the user interacting with the prompt.
The content packager 135 may configure the interactive script 195 to present each segment 190 of the interactive content item 160B in the position originally assigned for the segment 190. Presenting segments 190 of interactive content item 160B may include rendering, drawing, or otherwise visually presenting each segment 190 at an initial location. Rendering of segment 190 may be performed such that segment 190 is presented within a box that provides interactive content item 160B. In some implementations, the interactive script 195 may be configured by the content packager 135 to display the segment 190 to limit movement beyond the boundary defined by the box of the interactive content item 160B. The content packager 135 may configure the interactive script 195 to randomly assign each segment 190 to an initial location. In some implementations, the initial position of each segment 190 may be different from the target position of each segment 190. In some implementations, the initial position of one segment 190 may be a target position of another segment 190. In some implementations, rendering segments 190 may include first rendering, drawing, or otherwise visually displaying each segment 190 at a target location, and then moving segments 190 to an initial location after a predetermined amount of time, for example, using an animation or other kind of motion. In some implementations, the content packager 135 can configure the interactive script 195 to render the segments 190 of the interactive content item 160B using animations, visual effects, or other additional visual features in response to the segments 190 appearing at their respective initial positions.
The content packager 135 may configure the interactive script 195 to determine whether the segments 190 of the interactive content item 160B are in the corresponding target locations. The content packager 135 may configure the script to continuously monitor the location of each segment 190. During the assignment of an initial position to each segment 190, the interactive script 195 may compare the initial position of each segment 190 to the target position of the segment 190. If any of the segments 190 has an initial position equal to the target position of the corresponding segment 190, the interactive script 195 may be configured to reassign the initial position of the segment to another position. In some implementations, if at least one segment has an initial position equal to its target position, the content packager 135 may configure the interactive script 195 to re-assign the initial positions of all segments. The content packager 135 may configure the interactive script 195 to enable interaction with the segments 190 in response to determining that each segment 190 is in the respective initial position and not in the target position.
The content packager 135 may configure the interactive script 195 to enable interaction with the segment 190 of the interactive content item 160B within the frame. Where interaction is enabled, each segment 190 may correspond to a user element of a graphical user interface corresponding to the interactive content item 160B. For example, each segment 190 may correspond to an HTML5 object of the interactive content item 160B, such as an inline (inline) box, a command button object, an image object, and so forth. The content packager 135 may configure the interactive script 195 to enable interaction with the segments 190 before determining that each segment 190 differs from the target location. In some implementations, the content packager 135 can configure the interactive script 195 to handle interactions with each segment 190.
In some implementations, the content packager 135 can configure the interactive script 195 to associate or include an event listener (e.g., a drag listener) with each segment 190. For example, the content packager 135 may include an event listener for a mouse pointer or touch-based interface in the interactive script 195 to move the segments 190 of the interaction from one location to another. Interaction with segment 190 may include a click input, a touch input, and/or a drag input, among others. Click input may be detected by one or more event listeners configured to detect clicks associated with the segment 190. Touch input may be detected by one or more event listeners associated with each segment, which may be configured to detect touch interaction with each segment 190. The content packager 135 may configure the drag listener to assign a location for each segment 190 based on the detected drag operation. The event listener associated with each segment 190 may be configured by the content packager 135 to identify a previous location and a next location in response to event detection. In some embodiments, when an event listener for a segment 190 detects n interactions from the segment's initial location to a new location, the interactive script 195 may be configured to move the segment 190 to the new location indicated by the event listener. In some implementations, if an interaction with a segment has been detected, the content packager 135 can configure the interactive script 195 to move the corresponding segment 190. For example, the content packager 135 may configure the interactive script 195 to enable dragging of each segment 190 in response to touch and movement input from the touch screen.
Whenever interaction with one of the segments 190 is detected, the content packager 135 may configure the interactive script 195 to update the rendering of the segment 190 to a position within the box that provides the interactive content item 160B indicated by one or more event listeners (e.g., a drag listener). In some embodiments, when an interaction (e.g., a drag event) is detected by an event listener associated with segment 190, the event listener may continuously provide its location when the interaction event occurs. The content packager 135 may configure the interactive script 195 to render the corresponding segment 190 within the frame in which the interactive content item 160B is provided at the location indicated by the event listener, which may make the segment 190 appear to follow the client-detected interactive event. In some implementations, the content packager 135 can configure the interactive script 195 to render an animation in response to interactions detected by one or more event listeners. For example, if interaction with segment 190 is detected, content packager 135 may configure interactive script 195 to render a light-emitting animation, as in connection with step 305C of FIG. 3.
The content packager 135 may configure the interactive script 195 to determine whether the segment 190 of the interactive content item 160B has been moved to the corresponding target location. The determination of whether a segment 190 is moved to a corresponding target location may be part of the determination of whether the interactive script 195 determines that the target condition is satisfied. The target condition may specify that each segment 190 is to be moved from the initially assigned location to the target location. The content packager 135 may configure the interactive script 195 to continuously monitor the location of each segment 190 and compare the location of each segment 190 to its corresponding target location. Each segment 190 may be moved to a different location by input received from client device 120. In some implementations, the content packager 135 can configure the interactive script 195 to perform a comparison between the location of each segment 190 and the corresponding target location in response to user input. For example, if a segment 190 has been moved, the script may check for a location update. In some implementations, the content packager 135 may configure the interactive script 195 to compare the location of each segment 190 to a corresponding target location based on a predetermined time interval (e.g., ten times per second). Upon determining that the segments 190 are in the respective target locations, the content packager 135 may configure the interactive script 195 to display an animation, visual effect, or other kind of visual indicator. In response to determining that the segment 190 has not been moved to the corresponding target location, the content packager 135 may configure the interactive script 195 to continue monitoring for interaction with the segment 190.
The content packager 135 may configure the interactive script 195 to perform an action in response to determining that a segment of static content has been moved to a corresponding target location. In some implementations, the action of the interactive script 195 may include displaying a prompt with information related to the segment 190. The information may be provided by the content provider 175 or the content publisher 115. In some implementations, the actions of the interactive script 195 may include directing the client device 120 to a login page (e.g., a web page, a native application, etc.) in response to determining that all of the segments 190 are at their respective target locations. The address of the landing page may be provided by content provider 175. In some embodiments, the content packager 135 may identify the address of the landing page from the static content script 185 of the static content item 180A. In some implementations, the content packager 135 can configure the interactive script 195 to automatically open an address to a landing page when the target condition is reached.
In some implementations, the content packager 135 can configure the interactive script 195 to present a prompt via a user interface to provide information related to the interactive content item 160B. Presentation of the prompt may be one of the actions that may be performed in response to determining that the segment of static content has been moved to the respective target location. In some implementations, the content packager 135 can configure the interactive script 195 to access a native application interface present on the client device 120 to present the prompt via a user interface. In some implementations, the content packager 135 may configure the interactive script 195 to execute instructions that provide a user interface without relying on a native application interface. For example, the content packager 135 may configure the interactive script 195 to display a pop-up window with a customized graphical design that defines the prompt. The customized graphical design may be included in a request for interactive content received by content provider 175. In some implementations, the content packager 135 can configure the interactive script 195 to provide a prompt that includes information about the login page associated with the interactive content item 160B (e.g., the title of the login page, any parties associated with the login page, the address of the login page, a link to the login page, etc.). In some implementations, the content packager 135 can configure the interactive script 195 to provide a display prompt that includes a request to open an address associated with a landing page associated with the interactive content item 160B. In some implementations, the content packager 135 can configure the interactive script 195 to open an application on the client device 120 in response to interaction with the prompt.
The content packager 135 may configure the interactive script 195 to provide the interaction data to the performance monitor 150. The interaction data may include the location of each segment 190 and their respective current locations. The interaction data may also include the location of each segment 190 and their previous locations prior to detecting interaction with the segment 190. The content packager 135 may configure the interactive script 195 to provide an indication to the performance monitor 150 that an interaction has been detected via one or more event listeners associated with the segment 190. In some implementations, the content packager 135 can configure the interactive script 195 to include a timer to count the time with respect to interaction with one or more segments 190 in the interactive content item 160B. In some implementations, the interaction data may include temporal data regarding interactions with one or more segments 190. The time data may include a timestamp of each interaction with segment 190. The temporal data may also include an amount of time that has elapsed since the interaction with the initial prompt was detected.
In some implementations, the content packager 135 may provide the interaction data to the performance monitor 150. In some implementations, the content packager 135 may configure the interactive script 195 to provide interaction data to the performance monitor 150 at predetermined intervals. For example, content packager 135 may configure interactive script 195 to send all stored interaction data to performance monitor 150 in bursts. The interaction data may be used, for example, to track how many segments 190 have moved to their respective target locations.
The content packager 135 may configure the interactive script 195 to provide the interaction data to the performance monitor 150 after the target condition is met (e.g., all segments 190 are in their respective target positions). In some implementations, the content packager 135 may configure the interactive script 195 to provide an indication to the performance monitor 150 regarding the target condition. The indication may be part of the interaction data. In some implementations, the temporal data of the interaction data may include a time from the beginning to the detection of the satisfaction of the target condition. In some implementations, the content packager 135 can configure the interactive script 195 to provide an indication that interaction with the prompt was detected after the target condition. The indication may be part of the interaction data sent to performance monitor 150. In some implementations, the time data of the interaction data may include a timestamp of the interaction with the prompt.
By generating the interactive script 195, the content packager 135 may package the interactive script 195 with the segments 190 or add the interactive script 195 to the segments 190 to create the interactive content item 160B. In some implementations, the interactive content item 160B can be an HTML5 bundle with interactive content item 160B scripts. The interactive content item 160B script may be JavaScript and may include one or more script libraries 170, such as the script library 170. In some implementations, the content packager 135 can obfuscate (e.g., by encrypting) the interactive script 195. In some implementations, the content packager 135 may configure the interactive scripts 195 to automatically download and cache one or more script libraries 170 in response to execution of the interactive scripts 195 on the client device 120. The interactive content item 160B may be accessed by one or more content publishers 115, and the one or more content publishers 115 may provide the interactive content item 160B to one or more client devices 120. In some implementations, the content packager 135 can apply compression algorithms to the segments 190 and/or the interactive scripts 195 to reduce network bandwidth utilization.
The content packager 135 can provide the interactive content item 160B to one or more client devices 120 via the network 110. The content packager 135 may provide the interactive content item 160B in response to a request from the respective client device 120. For example, the content publisher 115 can provide information resources (e.g., web pages) to a client device 120 (e.g., an application such as a web browser). The information resource may include at least one content slot (e.g., inline box) into which additional content from one of the content providers 175 is to be inserted. The information resources may include scripts, the execution of which may cause the client device 120 to send a request for content to the data processing system 105. Upon receiving the request, the content packager 135 may send the interactive content item 160B to the client device 120 via the network 110. In sending content, the content packager 135 may run a content selection process to find and select the interactive content item 160B. The interactive content item 160B sent to the client device 120 may include one or more segments 190 and an interactive script 195. In some implementations, the content packager 135 can provide the client device 120 with an address to the interactive content item 160B (e.g., a URL address referencing the content provider 175). In some implementations, the content packager 135 can provide an address for each segment 190 (or one or more of the segments 190) to be included in the interactive content item 160B. In some implementations, the content packager 135 can provide an address to the interactive script 195 to provide interactive functionality to the segment 190 of the interactive content item 160B.
In some implementations, upon receiving a request for the interactive content item 160B, the data processing system 105 may select the interactive content item 160B based on one or more selection factors. The selection may be according to a content placement process. Selection factors may include information about the client device 120, such as the type of device (e.g., smartphone, tablet, laptop, personal computer, etc.), the type of application requesting the content item, the screen resolution of the client device 120, the size of the box included in the information resource, and any other factors related to the display or delivery of the content item. After selecting the appropriate interactive content item 160B based on the selection factors, the data processing system 105 can send the interactive content item 160B to the client device 120 for display in a content slot (or box) included in the information resource.
In some implementations, the content packager 135 can provide the interactive content item 160B based on the type of the client device 120 from which the request for content was received from the client device 120. The content packager 135 may identify the type of the client device 120 (e.g., smartphone, laptop, set-top box, or desktop). The content packager 135 may determine whether the type of client device 120 associated with the request matches the target client device 120 of the static content item 160A determined to be suitable for adding interactivity. In some implementations, the content packager 135 can access the database 155 to identify an association of the target client device 120 with a static content item 160A that is determined to be appropriate for the type of client device corresponding to the target. When there is a match, the content packager 135 may provide the interactive content item 160B to the client device 120. Otherwise, when there is no match, the content packager 135 may search for another content item (e.g., the corresponding static content item 160A) to provide.
By transmitting the interactive content item 160B from the data processing system 105, the client device 120 can receive the interactive content item 160B. Upon receipt, the client device 120 (or an application running on the client device 120) may parse the interactive content item 160B to identify the interactive script 195 and the segment 190. In some implementations, the client device 120 can identify the address of the interactive content item 160B received from the data processing system 105, and can retrieve the interactive content item 160B using the address (e.g., from the content provider 175). In some implementations, client device 120 may identify the address of one or more segments 190 and may use the address to retrieve segments 190. In some implementations, the client device 120 can be an address of the interactive script 195 provided by the data processing system 105 and can use the address to retrieve the interactive script 195.
After parsing the interactive script 195 and segment 190 from the interactive content item 160B, the client device 120 (or an application running on the client device 120) may insert the interactive content item 160B into a content slot of the information resource. Client device 120 may also invoke and execute the functions specified in interactive script 195. The functionality of the interactive script 195 may be separate from the functionality of the information resource that is inserted into the interactive content item 160B. Further, the client device 120 may load the interactive script 195 and the segments 190 into locations in computer memory. The computer memory of the client device 120 is accessible to an application (e.g., a web browser) that provides an information resource. In some implementations, the loading process of the interactive content item 160B can include requesting and downloading one or more script libraries 170.
Through invocation of the interactive script 195, the client device 120 may execute instructions specified by the interactive script 195. The client device 120 may utilize the content slots of the information resource to show, render, or otherwise display the segments 190 extracted from the interactive content item 160B. When the interactive content item 160B is inserted into one of the content slots of the information resource, the functionality of the interactive script 195 may be constrained to the boundaries of the box corresponding to the content slot. In some implementations, the segments 190 may be displayed in their initial positions. For example, the segments 190 may be displayed at their target locations and automatically moved to their initial locations.
Further, client device 120 may enable interaction with segments 190 through an event listener in accordance with interactive script 195. For example, using a mouse-drag event listener associated with one of the segments 190, the client device 120 may detect a drag-and-drop event for the segment 190. The event listener associated to each segment 190 by the interactive script 195 may be constrained by the boundaries of the box corresponding to the content slot for which the information resource of the interactive content item 160B is inserted. In this way, interactions outside the boundaries of the content slot may not affect or trigger any event listeners of the interactive scripts 195 associated with the segments 190 of the interactive content item 160B. In response to detection of the event, the client device 120 may identify a final location of the interaction and render the segment 190 that moved from the initially assigned location to the final location. The client device 120 may continue to execute the interactive script 195 until the target condition has been reached. The target condition may occur or be detected in response to the segments 190 being moved to their respective target locations.
While the interactive script 195 is executing, the client device 120 may send interaction data to the data processing system 105. For example, the interaction data may include the location of each segment 190 and their respective current locations. Additionally, the interaction data may include a timestamp of each interaction with segment 190. Client device 120 may execute a script to render a prompt in response to a target condition. For example, upon reaching the target condition, the client device 120 may present a message box with the text "click here to download the application". Client device 120 may send additional interaction data indicating whether interaction with the prompt was detected. The time data of the interaction data may include an amount of time elapsed until the target condition is detected.
Referring to FIG. 3, an example illustration of interaction with an interactive content item 160B is depicted. At step 305A, client device 120 may have rendered a segment of the interactive content item (e.g., segment 190). The segments 310 may not be at the respective target locations. In step 305B, the client device has received input indicating interaction with segment 310. In this example, the interaction is a drag event detected by an interactive script (e.g., interactive script 195) executing on client device 120. The position of segment 310 may have been changed to correspond to a drag event. At step 305C, segment 310 may have been moved to its corresponding target location by a drag event detected by the client device. Client device 120 may provide an animation, shown here as a light-emitting animation, in response to segment 310 reaching a respective target location. In some implementations, the animation can be temporary. In some implementations, the client device 120 may maintain the location of the segment 310 after the segment 310 has been moved to the target location. At step 305D, the animation has stopped and segment 310 may no longer be illuminated. Segment 310 may have reached the target location and rendered by the client device as interlocked with other segments.
After providing the interactive content item 160B to the client device 102, the performance monitor 150 may receive interaction data from the client device 120. The interaction data may indicate the location of each segment 190. In some implementations, the interaction data may indicate whether the segment 190 has moved to the target location. In some implementations, performance monitor 150 may receive interaction data from a respective client device in response to detecting an interaction with one of segments 190. The interaction data may be provided according to interactive scripts 195 running on the client device 120. For example, the interaction data may include interactions corresponding to each segment 190. The interaction data may specify a previous location and a subsequent location for each segment 190 in response to an interaction detected by an event listener associated with the segment 190. The interaction data may also include a timestamp for each interaction. In some implementations, the interaction monitor may receive the interaction data in real-time (e.g., the interaction data is sent to performance monitor 150 and received by performance monitor 150 when the interaction occurs on client device 120). In some implementations, performance monitor 150 may receive interactive data at intervals. In some implementations, the interaction data may be received periodically based on a predetermined time interval (e.g., ranging from 10 seconds to 5 minutes).
Further, performance monitor 150 may receive interaction data from client device 120 after all segments 190 reach the respective target locations. In some implementations, the interaction data can include an indication that the client device 120 has accessed a landing page associated with the interactive content item 160B. In some implementations, the interaction data may include an indication of whether interaction with the prompt provided by the interactive script 195 was detected at the client device 120. The indication may be part of the interaction data and may include temporal data related to the prompted interaction. In some implementations, performance monitor 150 may receive an indication that all segments 190 have reached their respective target locations. The indication may be part of the interaction data and may include time data, such as the time elapsed to reach the target condition.
Referring now to FIG. 4, a flow diagram of a method 400 for generating an interactive content item including a script and executing the script on a client device is depicted. The method 400 may be implemented or performed using the data processing system 105 in conjunction with at least one client device 120 as described in detail herein above, or the computer system 500 described herein below in conjunction with fig. 5. In general, a data processing system may identify a content item and a script (405). The data processing system may determine whether the content item is suitable (410). The data processing system may partition the content items using the partition template (415). The data processing system may generate a second content item and a script (420). The data processing system may provide the content item to the client device (425). The client device may initiate a script from the content item (430). The client device may assign a location to each segment (435). The client device may render each segment (440). The client device may enable segment interaction (445). The client device may determine whether the segments are in their respective target locations (450). The client device may perform the action (455).
A data processing system (e.g., data processing system 105) may identify a content item (e.g., static content item 160A) (405). The content items may include visual content (e.g., visual content 180). Visual content may include images, video, text, and the like. The visual content may be associated with or attributed to one or more parameters, such as dimensions (e.g., width and height), coding information, descriptive text strings or other metadata, and so forth. The content items may include scripts (e.g., static content scripts 185). In some implementations, the data processing system can extract visual content and one or more parameters thereof from the content item for further processing. In some implementations, the data processing system can receive visual content and one or more parameters from a content provider (e.g., content provider 175).
The data processing system may determine whether the content item is suitable (410). In some implementations, the data processing system can determine eligibility based on the size (e.g., width and height) of the visual content. For example, the data processing system may compare the width and height of the visual content to predetermined thresholds. In some implementations, the data processing system can determine that the content item is unsuitable if the width and/or height of the content item exceeds one or more predetermined thresholds. The data processing system may determine that the visual content is appropriate if the width and height of the content item are within one or more predetermined thresholds. In some implementations, the predetermined threshold is selected based on a target platform for the interactive content item. For example, the target platform may have a particular screen resolution that defines its own predetermined threshold for the width and height of the content item. If the data processing system determines that the visual content is suitable, the data processing system may proceed to partition the visual content in step (415). If the data processing system determines that the content item is not suitable, the data processing system may return to step (405) to identify different visual content.
The data processing system may use a partition template (e.g., template 165) to partition the visual content of the content item (415). Partitioning the visual content item may include selecting a partition template. In some implementations, a partition template may include one or more SVG paths. The SVG path may define the boundaries, shape, and/or size of a segment (e.g., segment 190) to be created using the visual content identified in step (405). The template may include a target location for each segment. The data processing system may create one or more segments by applying a partition template to the visual content. Applying the partition template may include partitioning the visual content along an SVG path included in the partition template. In some implementations, each divided segment can be interlocked with other segments of the divided visual content to form an image, video, or other visual representation (e.g., a puzzle) associated with the visual content.
The data processing system may generate interactive content items and scripts (420). The data processing system may generate a script to add interactivity to the partitioned segments generated in step (415). In some implementations, generating the script can include configuring the script to initiate movement of the segment in response to an input event received from a computing device executing the script. The input event may be a touch input or a mouse movement input, etc. In some implementations, the script can be configured to randomly assign to each segment a random (e.g., pseudo-random) location that is not equal to its respective target location. In some implementations, the script may be configured to render one or more segments in a box and render them for interaction. In some implementations, the script can be configured to provide a prompt indicating that the content in the box is interactive. In some implementations, the script may be configured to provide the interaction data to the data processing system. The data processing system may package the script and the one or more segments to create an interactive content item (e.g., interactive content item 160B). The interactive content items may be implemented as, for example, HTML5 bundles, which may include JavaScript. In some implementations, the data processing system can generate the interactive content item such that it is within a particular predetermined size specification (e.g., two megabytes).
The data processing system may provide an interactive content item (425). The data processing system may provide the interactive content item to at least one client device (e.g., one of the client devices 120). The data processing system may send the content item via a computer network (e.g., network 110). In some implementations, the interactive content items may be displayed in one or more boxes on the client device. In some implementations, the client device can extract the segments and scripts from the interactive content item in response to receiving the interactive content item from the data processing system.
A client device (e.g., one of client devices 120) may initiate a script (430). Initiating the script may include allocating a buffer in computer memory for one or more segments. In some implementations, initiating the script may include downloading one or more script libraries (e.g., script library 170) from the data processing system. Downloading the script library may include allocating storage for the script library. The client device may cache the script library in a location in computer memory in response to receiving the script library from the data processing system. The client device may begin executing the script in response to storing or caching a script library and/or storing the segments in computer memory.
The client device may assign an initial location for each segment (435). The locations may be randomly assigned by a script included in the interactive content item (e.g., using a pseudo-random number generator). In some implementations, segments can be assigned different locations than their respective target locations. The target location of each segment may be defined by the partition template used to create the segment. In some implementations, the partition template may assign an initial position for each segment. The client device may determine whether each segment is assigned an initial location that is different from its respective target location. If the client device determines that the initial position of the segment is the same as the target position of the segment, the client device may assign a new initial position for the segment, for example, using a pseudo-random number generator.
The client device may present each segment (440). The client device may present each segment by accessing one or more display functions of the client device. The client device may present each segment within a box. The box may specify boundaries of the interactive content item and the segment, and may include a predetermined width, height, and position for rendering the segment of the interactive content item therein. In some implementations, the block may be included in an information resource provided by a content publisher (e.g., content publisher 115). In some implementations, the client devices may render one or more segments of the interactive content item at their respective initial positions. In some implementations, the client device may render one or more segments of the interactive content item at their respective target locations and then visually move the segments to their respective initial locations. In some implementations, presenting each segment can include providing an animation that includes the segment.
The client device may enable interaction with each segment (445). The client device may begin monitoring for input from an input device (e.g., a mouse pointer, touch-based input, etc.) to determine whether the input includes interaction with the one or more segments presented at step (435). In some implementations, the client device may move one or more segments to a new location in response to input from the input device. For example, if the input includes one of clicking and dragging a segment, the client device may move the segment to the location indicated by the input device. In some implementations, the client device can provide an animation in response to the input.
The client device may determine whether each segment is in the target location (450). In some implementations, the client device may continuously monitor the location of each segment. In some implementations, the client device can monitor the location of each segment in response to an input event (e.g., a mouse click, a touch-based input, etc.). The client device may compare the location of each segment to its respective target location. In some implementations, if the client device determines that the location of the segment is equal to its target location, the client device may provide an animation indicating that the segment has reached its target location. In some implementations, if the client device determines that a segment has reached its target location, the client device may disable interaction with the segment. The client device may send interaction data including the location of each segment to the data processing system in response to the segment being moved to its target location. If the client device determines that all segments have been moved to their target locations, the client device may perform the action in step (450). If the client device determines that not all segments have been moved to their respective target locations, the client device may continue to enable interaction with the segments, as shown at step (445).
The client device may perform the action (455). In some implementations, the client device may perform an action in response to all segments being moved to their respective target locations. In some implementations, the action may include presenting a prompt on the client device indicating that all segments have been moved to their respective target locations. In some implementations, the prompt can include a link to a landing page or other information related to the interactive content item. The client device may open the address of the login page. For example, the client device may open an address of a login page related to the interactive content item using a web browser. In some implementations, the client device can open the address of the login page in a native application executing on the client device. In some implementations, the action may include providing an indication to the data processing system that all of the segments have been moved to their respective target locations. The indication may include data indicating that the prompt has been presented on the client device. The client device may provide interaction data to the data processing system in response to opening a login page on the client device, including an indication that the login page has been opened on the client device.
Fig. 5 illustrates the general architecture of an exemplary computer system 500, according to some implementations, which exemplary computer system 500 may be used to implement any of the computer systems discussed herein. Computer system 500 may be used to provide information for display via network 110. The computer system 500 of fig. 5 includes one or more processors 520 communicatively coupled to memory 525, one or more communication interfaces 505, one or more output devices 510 (e.g., one or more display units), and one or more input devices 515. The processor 520 may be included in the data processing system 105 or other components of the system 500.
In computer system 500 of fig. 5, memory 525 may comprise any computer-readable storage medium and may store computer instructions, such as processor-executable instructions for the various systems implementing the various functions described herein, as well as any data associated therewith, generated thereby or received via a communication interface or input device (if any). Referring again to the system 500 of FIG. 5, the data processing system may include a memory 525 to store information related to the set of user identifiers, the generated vectors, and the like. The processor 520 shown in fig. 5 may be used to execute instructions stored in the memory 525 and, in so doing, may also read from and write to the memory various information processed and/or generated in accordance with the execution of the instructions.
The processor 520 of the computer system 500 shown in fig. 5 may also be communicatively coupled to or control the communication interface(s) 505 to send or receive various information in accordance with the execution of instructions. For example, the communication interface(s) 505 may be coupled to a wired or wireless network, bus, or other communication means, and thus may allow the computer system 800 to send information to and receive information from other devices (e.g., other computer systems). Although not explicitly shown in the system of fig. 5, one or more communication interfaces facilitate the flow of information between components of the system 500. In some implementations, the communication interface(s) may be configured (e.g., via various hardware or software components) to provide a website as an access portal to at least some aspects of the computer system 500. Examples of the communication interface 505 include a user interface (e.g., a web page) through which a user can communicate with the data processing system 105.
An output device 510 of the computer system 500 shown in fig. 5 may be provided to allow various information to be viewed or otherwise perceived in connection with execution of the instructions. An input device(s) 515 may be provided, for example, to allow a user to manually adjust, make selections, input data, or interact with the processor during execution of instructions. Additional information regarding general computer system architectures that may be used for the various systems discussed herein is further provided herein.
Implementations of the subject matter and the operations described in this specification can be implemented in digital electronic circuitry, or in computer software embodied in tangible media, firmware, or hardware, including the structures disclosed in this specification and their equivalents, or in combinations of one or more of them. Implementations of the subject matter described in this specification can be implemented as one or more computer programs, i.e., one or more components of computer program instructions, encoded on a computer storage medium for execution by, or to control the operation of, data processing apparatus. Program instructions may be encoded on an artificially generated propagated signal (e.g., a machine-generated electrical, optical, or electromagnetic signal) that is generated to encode information for transmission to suitable receiver apparatus for execution by a data processing apparatus. The computer storage media may be or be included in a computer-readable storage device, a computer-readable storage substrate, a random or serial access memory array or device, or a combination of one or more thereof. Further, although the computer storage medium is not a propagated signal, the computer storage medium can comprise a source or destination of computer program instructions encoded in an artificially generated propagated signal. The computer storage media may also be or be embodied in one or more separate physical components or media (e.g., multiple CDs, disks, or other storage devices).
The features disclosed herein may be implemented on a smart television module (or connected television module, hybrid television module, etc.) that may include a processing module configured to integrate an internet connection with a more traditional television program source (e.g., via cable, satellite, over-the-air, or other signal reception). The smart television module may be physically incorporated into a television set or may comprise a separate device such as a set-top box, a blu-ray or other digital media player, a game console, a hotel television system, and other companion devices. The smart television module may be configured to allow viewers to search for and find videos, movies, photos, and other content on the network, on local cable channels, on satellite television channels, or stored on a local hard disk. A set-top box (STB) or set-top unit (STU) may include an information device that may contain a tuner and connect to a television and an external signal source, tune the signal to content, and then display on a television screen or other display device. The smart television module may be configured to provide a home screen or top level screen including icons for a number of different applications (such as a Web browser and a number of streaming media services), connected cable or satellite media sources, other Web "channels". The smart television module may also be configured to provide an electronic program guide to the user. A companion application to the smart television module may operate on the mobile computing device to provide additional information to the user about available programming, to allow the user to control the smart television module, and so on. In alternative implementations, the features may be implemented on a laptop or other personal computer, smartphone, other mobile phone, palmtop, tablet, or other computing device.
The operations described in this specification may be implemented as operations performed by a data processing apparatus on data stored on one or more computer-readable storage devices or received from other sources.
The terms "data processing apparatus," "data processing system," "user equipment," or "computing device" encompass various devices, apparatuses, and machines for processing data, including by way of example a programmable processor, a computer, a system on a chip, or a plurality or combination of the foregoing. An apparatus may comprise special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit). The apparatus can include, in addition to hardware, code that creates an execution environment for the computer program in question, e.g., code that constitutes processor firmware, a protocol stack, a database management system, an operating system, a cross-platform runtime environment, a virtual machine, or a combination of one or more of them. The apparatus and execution environment may implement a variety of different computing model architectures, such as web services, distributed computing, and grid computing architectures.
A computer program (also known as a program, software application, script, or code) can be written in any form of programming language, including compiled or interpreted languages, declarative or procedural languages, and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, object, or other unit suitable for use in a computing environment. A computer program may, but need not, correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data (e.g., one or more scripts stored in a markup language document), in a single file dedicated to the program in question, or in multiple coordinated files (e.g., files that store one or more modules, sub programs, or portions of code). A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network.
The processes and logic flows described in this specification can be performed by one or more programmable processors executing one or more computer programs to perform actions by operating on input data and generating output. The processes and logic flows can also be performed by, and apparatus can also be implemented as, special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit).
Processors suitable for the execution of a computer program include, by way of example, both general and special purpose microprocessors, and any one or more processors of any kind of digital computer. Generally, a processor will receive instructions and data from a read-only memory or a random access memory or both. Elements of a computer include a processor for performing actions in accordance with instructions and one or more memory devices for storing instructions and data. Generally, a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks. However, a computer need not have such devices. Further, the computer may be embedded in another device, e.g., a mobile telephone, a Personal Digital Assistant (PDA), a mobile audio or video player, a game player, a Global Positioning System (GPS) receiver, or a portable storage device (e.g., a Universal Serial Bus (USB) flash drive). Devices suitable for storing computer program instructions and data include all forms of non-volatile memory, media and storage devices, including by way of example semiconductor memory devices (e.g., EPROM, EEPROM, and flash memory devices); magnetic disks, (e.g., internal hard disks or removable disks); magneto-optical disks; and CD-ROM and DVD-ROM disks. The processor and the memory can be supplemented by, or incorporated in, special purpose logic circuitry.
To provide for interaction with a user, an implementation of the subject matter described in this specification can be implemented on a computer having a display device (e.g., a CRT (cathode ray tube), plasma, or LCD (liquid crystal display) monitor) for displaying information to the user and a keyboard and a pointing device (e.g., a mouse or a trackball) by which the user can provide input to the computer. Other kinds of devices may also be used to provide for interaction with a user; for example, feedback provided to the user can include any form of sensory feedback, e.g., visual feedback, auditory feedback, or tactile feedback; and input from the user may be received in any form, including acoustic, speech, or tactile input. In addition, the computer may interact with the user by sending and receiving documents to and from the device used by the user; for example, by sending a web page to a web browser on the user's client device in response to a request received from the web browser.
Implementations of the subject matter described in this specification can be implemented in a computing system that includes a back-end component (e.g., as a data server), or that includes a middleware component (e.g., an application server), or that includes a front-end component (e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the subject matter described in this specification), or a combination of one or more such back-end, middleware, or front-end components. The components of the system can be interconnected by any form or medium of digital data communication (e.g., a communication network). Examples of communication networks include local area networks ("LANs") and wide area networks ("WANs"), the internet (e.g., the internet), and peer-to-peer networks (e.g., ad hoc peer-to-peer networks).
A computing system, such as data processing system 105, may include clients and servers. For example, the data processing system 105 may include one or more data centers or one or more servers in a server farm. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other. In some implementations, the server sends data (e.g., HTML pages) to the client device (e.g., for the purpose of displaying data to and receiving user input from a user interacting with the client device). Data generated at the client device (e.g., a result of the user interaction) may be received from the client device at the server.
While this specification contains many specific implementation details, these should not be construed as limitations on the scope of any inventions or of what may be claimed, but rather as descriptions of features specific to particular implementations of the systems and methods described herein. Some features that are described in this specification in the context of separate implementations can also be implemented in combination in a single implementation. Conversely, various features that are described in the context of a single implementation can also be implemented in multiple implementations separately or in any suitable subcombination. Furthermore, although features may be described above as acting in certain combinations and even initially claimed as such, one or more features from a claimed combination can in some cases be excised from the combination, and the claimed combination may be directed to a subcombination or variation of a subcombination.
Similarly, while operations are depicted in the drawings in a particular order, this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order, or that all illustrated operations be performed, to achieve desirable results. In some cases, the actions recited in the claims can be performed in a different order and still achieve desirable results. In addition, the processes depicted in the accompanying figures do not necessarily require the particular order shown, or sequential order, to achieve desirable results.
In some cases, multitasking and parallel processing may be advantageous. Moreover, the separation of various system components in the implementations described above should not be understood as requiring such separation in all implementations, and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products. For example, the data processing system 105 may be part of a single module, a logical device with one or more processing modules, one or more servers, or a search engine.
Having now described some illustrative implementations, it is apparent that the foregoing is illustrative and not limiting, and has been presented by way of example. In particular, although many of the examples presented herein involve specific combinations of method acts or system elements, those acts and those elements may be combined in other ways to accomplish the same objectives. Acts, elements and features discussed only in connection with one implementation are not intended to be excluded from a similar role in other implementations.
The phraseology and terminology used herein is for the purpose of description and should not be regarded as limiting. The use of "including," "having," "containing," "involving," "characterized by," and variations thereof herein, is meant to encompass the items listed thereafter and equivalents thereof as well as additional items and alternative implementations consisting of the items specifically listed thereafter. In one implementation, the systems and methods described herein consist of one, each combination of more than one, or all of the described elements, acts, or components.
Any reference to an implementation or element or action of a system or method referred to herein in singular form may also encompass implementations comprising a plurality of such elements, and any reference to any implementation or element or action herein in plural form may also encompass implementations comprising only a single element. References in the singular or plural form are not intended to limit the presently disclosed systems or methods, their components, acts or elements to a single or multiple configurations. A reference to any action or element based on any information, action, or element may include an implementation in which the action or element is based, at least in part, on any information, action, or element.
Any implementation disclosed herein may be combined with any other implementation, and references to "an implementation," "some implementations," "an alternative implementation," "various implementations," "one implementation," etc. are not necessarily mutually exclusive and are intended to indicate that a particular feature, structure, or characteristic described in connection with the implementation may be included in at least one implementation. Such terms as used herein do not necessarily all refer to the same implementation. Any implementation may be combined, inclusively or exclusively, with any other implementation in any manner consistent with aspects and implementations disclosed herein.
References to "or" may be construed as inclusive such that any term described using "or" may refer to any single, more than one, and all of the described terms.
Where technical features in the drawings, detailed description or any claim are followed by reference signs, the reference signs have been included for the sole purpose of increasing the intelligibility of the drawings, detailed description and claims. Thus, the presence or absence of a reference numeral does not have any limiting effect on the scope of any claim element.
The systems and methods described herein may be embodied in other specific forms without departing from the characteristics thereof. Although the examples provided herein relate to controlling the display of information resource content, the systems and methods described herein may include application to other environments. The foregoing implementations are illustrative, and not limiting of the described systems and methods. The scope of the systems and methods described herein is, therefore, indicated by the appended claims rather than by the foregoing description, and all changes that come within the meaning and range of equivalency of the claims are intended to be embraced therein.
Claims (20)
1. A method, comprising:
identifying, by a data processing system comprising one or more processors, visual content of a first content item comprising a first script configured to render the visual content in response to loading of the first content item;
dividing, by the data processing system, the visual content of the first content item into a plurality of segments according to a partitioning template, the partitioning template defining a number of segments to be formed from the visual content, a shape of each segment of the plurality of segments, and a dimension of each shape, each segment of the plurality of segments corresponding to a different portion of the visual content;
generating, by the data processing system, a second content item to include the plurality of segments to be rendered in the frame and a second script configured to:
in response to the loading of the second content item, assigning each of the plurality of segments to one of a plurality of locations, each of the plurality of locations defining an area in the frame in which the segment is to be presented;
presenting the plurality of segments within the frame according to the plurality of locations assigned to each of the plurality of segments;
enabling, via interaction, each of the plurality of segments to move between a plurality of positions within the frame;
in response to detecting interaction with one of the plurality of segments, determining that the plurality of segments move from the plurality of locations to a target plurality of locations; and
in response to determining that the plurality of segments move to the target plurality of locations, performing an action that provides information related to the visual content; and
the second content item is provided to the client device by the data processing system to cause the client device to render the plurality of segments according to the second script.
2. The method of claim 1, further comprising: selecting, by the data processing system, a partition template from a plurality of partition templates based on the visual content of the first content item,
wherein dividing the visual content further comprises: in response to selecting a partition template from the plurality of partition templates, the visual content is divided into a plurality of segments according to the partition template.
3. The method of claim 1 or 2, further comprising:
determining, by the data processing system, for each of the plurality of partition templates, a predicted interaction rate with the visual content partitioned according to the corresponding partition template; and
selecting, by the data processing system, a partition template from the plurality of partition templates based on the predicted interaction rate determined for each of the plurality of partition templates,
wherein dividing the visual content further comprises: in response to selecting a partition template from the plurality of partition templates, the visual content is divided into a plurality of segments according to the partition template.
4. The method of any of the preceding claims, further comprising: determining, by the data processing system, that the first content item is suitable for adding interactivity based on the visual content of the first content item, an
Wherein dividing the visual content further comprises: in response to determining that the first content item is suitable, the visual content is divided into a plurality of segments according to the partitioning template.
5. The method of any of the preceding claims, further comprising: identifying, by the data processing system, an initial plurality of locations of the plurality of segments as a target plurality of locations, each location of the initial plurality of locations defining an area within the visual content of the first content item from which the segment was obtained; and
wherein generating the second content item further comprises generating the second content item to include a second script configured to determine that the plurality of segments are moved from the plurality of locations to the initial plurality of locations in response to detecting the interaction with one of the plurality of segments.
6. The method of any preceding claim, wherein generating a second content item further comprises generating a second content item to include a second script configured to:
presenting, within the frame, a prompt to initiate interaction with the second content item; and
in response to detecting interaction with the prompt, a plurality of segments are presented within the frame according to the plurality of locations.
7. The method of any of the preceding claims, wherein generating the second content item further comprises generating the second content item to include a second script configured to perform an action comprising presenting a prompt to present information related to the visual content, the information provided by a content provider associated with the first content item.
8. The method of any of the preceding claims, wherein dividing the visual content of the first content item further comprises dividing the visual content into a plurality of segments according to a partitioning template, the partitioning template comprising a segmentation path to define a number of segments to be formed, a shape of each segment of the plurality of segments, and a dimension of each shape.
9. The method of any preceding claim, wherein identifying the first content item further comprises receiving a request from a content provider to include interactivity into the content, the request including the first content item.
10. The method of any of the preceding claims, further comprising: in response to performing the action, an indication is received, by the data processing system, from the client device that the plurality of segments were moved to the first plurality of locations.
11. A system, comprising:
a data processing system comprising one or more processors, the data processing system configured to:
identifying visual content of a first content item comprising a first script configured to render the visual content in response to loading of the first content item;
dividing the visual content of the first content item into a plurality of segments according to a partitioning template, the partitioning template defining a number of segments to be formed from the visual content, a shape of each segment of the plurality of segments, and a dimension of each shape, each segment of the plurality of segments corresponding to a different portion of the visual content;
generating a second content item to include a plurality of segments to be rendered in a frame and a second script configured to:
in response to the loading of the second content item, assigning each of the plurality of segments to one of a plurality of locations, each of the plurality of locations defining an area in the frame in which the segment is to be presented;
presenting the plurality of segments within the frame according to the plurality of locations assigned to each of the plurality of segments;
enabling, via interaction, each of the plurality of segments to move between a plurality of positions within the frame;
in response to detecting interaction with one of the plurality of segments, determining that the plurality of segments move from the plurality of locations to a target plurality of locations; and
in response to determining that the plurality of segments are moved to the target plurality of locations, performing an action that provides information related to the visual content; and
the second content item is provided to the client device to cause the client device to render the plurality of segments according to the second script.
12. The system of claim 11, wherein the data processing system is further configured to:
selecting a partition template from a plurality of partition templates based on the visual content of the first content item; and
in response to selecting a partition template from the plurality of partition templates, the visual content is divided into a plurality of segments according to the partition template.
13. The system of claim 11 or 12, wherein the data processing system is further configured to:
determining, for each of a plurality of partition templates, a predicted interaction rate with visual content partitioned according to the corresponding partition template;
selecting a partition template from the plurality of partition templates based on the predicted interaction rate determined for each of the plurality of partition templates, an
In response to selecting a partition template from the plurality of partition templates, the visual content is divided into a plurality of segments according to the partition template.
14. The system of claim 11, 12 or 13, wherein the data processing system is further configured to:
determining that the first content item is suitable for adding interactivity based on the visual content of the first content item; and
in response to determining that the first content item is suitable, the visual content is divided into a plurality of segments according to the partitioning template.
15. The system of any of claims 11-14, wherein the data processing system is further configured to:
identifying an initial plurality of locations of the plurality of segments as a target plurality of locations, each location of the initial plurality of locations defining an area within the visual content of the first content item from which the segment was obtained; and
generating a second content item to include a second script configured to determine that the plurality of segments moved from the plurality of locations to the initial plurality of locations in response to detecting interaction with one of the plurality of segments.
16. The system of any of claims 11-15, wherein the data processing system is further configured to:
generating a second content item to include a second script configured to:
presenting, within the frame, a prompt to initiate interaction with the second content item; and
in response to detecting interaction with the prompt, a plurality of segments are presented within the frame according to the plurality of locations.
17. The system of any of claims 11-16, wherein the data processing system is further configured to:
generating a second content item to include a second script configured to perform an action including presenting a prompt to present information related to visual content, the information provided by a content provider associated with the first content item.
18. The system of any of claims 11-17, wherein the data processing system is further configured to:
the visual content is divided into a plurality of segments according to a partitioning template, the partitioning template including a segmentation path to define a number of segments to be formed, a shape of each segment of the plurality of segments, and a dimension of each shape.
19. The system of any of claims 11-18, wherein the data processing system is further configured to:
a request to include interactivity into content is received from a content provider, the request including a first content item.
20. The system of any of claims 11-19, wherein the data processing system is further configured to:
an indication is received from the client device that the plurality of segments are moved to the first plurality of locations in response to performing the action.
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
PCT/US2019/064238 WO2021112827A1 (en) | 2019-12-03 | 2019-12-03 | Converting static content items into interactive content items |
Publications (1)
Publication Number | Publication Date |
---|---|
CN113207304A true CN113207304A (en) | 2021-08-03 |
Family
ID=69104838
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201980004992.6A Pending CN113207304A (en) | 2019-12-03 | 2019-12-03 | Converting static content items into interactive content items |
Country Status (7)
Country | Link |
---|---|
US (2) | US11625472B2 (en) |
EP (1) | EP3850511A1 (en) |
JP (1) | JP7227236B2 (en) |
KR (1) | KR102541981B1 (en) |
CN (1) | CN113207304A (en) |
CA (1) | CA3160602A1 (en) |
WO (1) | WO2021112827A1 (en) |
Citations (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN102342165A (en) * | 2009-03-04 | 2012-02-01 | 莫亚西斯环球公司 | Cell-allocation in location-selective information provision systems |
US9495532B1 (en) * | 2016-03-28 | 2016-11-15 | Mikhail Zhurkin | Image based tile puzzle CAPTCHA system |
CN106462555A (en) * | 2014-05-14 | 2017-02-22 | 网页云股份有限公司 | Methods and systems for web content generation |
US9785619B1 (en) * | 2012-03-23 | 2017-10-10 | Amazon Technologies, Inc. | Interaction based display of visual effects |
CN109074214A (en) * | 2015-08-21 | 2018-12-21 | 谷歌有限责任公司 | System and method for controlling the display of content |
CN110140144A (en) * | 2017-10-31 | 2019-08-16 | 谷歌有限责任公司 | For verifying the image processing system of the data of rendering |
Family Cites Families (13)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US8621396B1 (en) | 2008-10-20 | 2013-12-31 | Google Inc. | Access using image-based manipulation |
US8671058B1 (en) * | 2009-08-07 | 2014-03-11 | Gary Isaacs | Methods and systems for generating completely automated public tests to tell computers and humans apart (CAPTCHA) |
US9105034B2 (en) | 2011-03-23 | 2015-08-11 | International Business Machines Corporation | Implementing computer interaction response tests |
WO2012128916A2 (en) | 2011-03-24 | 2012-09-27 | AYaH, LLC | Method for generating a human likeness score |
US20120323700A1 (en) * | 2011-06-20 | 2012-12-20 | Prays Nikolay Aleksandrovich | Image-based captcha system |
US20150170204A1 (en) * | 2012-07-11 | 2015-06-18 | Minteye Ltd. | Means and methods for providing marketing information |
KR20140069943A (en) * | 2012-11-30 | 2014-06-10 | 삼성전자주식회사 | Apparatus and method for processing a contents of portable terminal |
JP6236976B2 (en) | 2013-08-09 | 2017-11-29 | 富士通株式会社 | Authentication control program, authentication control apparatus, and authentication control method |
US9519766B1 (en) * | 2015-09-07 | 2016-12-13 | Voicebox Technologies Corporation | System and method of providing and validating enhanced CAPTCHAs |
US9977892B2 (en) | 2015-12-08 | 2018-05-22 | Google Llc | Dynamically updating CAPTCHA challenges |
US9870623B2 (en) * | 2016-05-14 | 2018-01-16 | Google Llc | Segmenting content displayed on a computing device into regions based on pixels of a screenshot image that captures the content |
EP3273377B1 (en) | 2016-07-21 | 2018-09-12 | Deutsche Telekom AG | System for dynamic image captcha |
US11856264B2 (en) | 2016-11-15 | 2023-12-26 | Google Llc | Systems and methods for reducing download requirements |
-
2019
- 2019-12-03 KR KR1020207010067A patent/KR102541981B1/en active IP Right Grant
- 2019-12-03 US US16/759,509 patent/US11625472B2/en active Active
- 2019-12-03 CA CA3160602A patent/CA3160602A1/en active Pending
- 2019-12-03 JP JP2020520119A patent/JP7227236B2/en active Active
- 2019-12-03 EP EP19831959.2A patent/EP3850511A1/en active Pending
- 2019-12-03 CN CN201980004992.6A patent/CN113207304A/en active Pending
- 2019-12-03 WO PCT/US2019/064238 patent/WO2021112827A1/en unknown
-
2023
- 2023-04-10 US US18/132,864 patent/US20230244774A1/en active Pending
Patent Citations (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN102342165A (en) * | 2009-03-04 | 2012-02-01 | 莫亚西斯环球公司 | Cell-allocation in location-selective information provision systems |
US9785619B1 (en) * | 2012-03-23 | 2017-10-10 | Amazon Technologies, Inc. | Interaction based display of visual effects |
CN106462555A (en) * | 2014-05-14 | 2017-02-22 | 网页云股份有限公司 | Methods and systems for web content generation |
CN109074214A (en) * | 2015-08-21 | 2018-12-21 | 谷歌有限责任公司 | System and method for controlling the display of content |
US9495532B1 (en) * | 2016-03-28 | 2016-11-15 | Mikhail Zhurkin | Image based tile puzzle CAPTCHA system |
CN110140144A (en) * | 2017-10-31 | 2019-08-16 | 谷歌有限责任公司 | For verifying the image processing system of the data of rendering |
Non-Patent Citations (2)
Title |
---|
谭涛;: "高效的动态脚本网页关联性挖掘算法研究", 电脑知识与技术, no. 13, 5 May 2012 (2012-05-05), pages 84 - 87 * |
贾诺: "网络拓扑可视化系统设计与实现", 中国优秀硕士学位论文全文数据库 信息科技辑, no. 10, 15 October 2018 (2018-10-15), pages 139 - 40 * |
Also Published As
Publication number | Publication date |
---|---|
US20230244774A1 (en) | 2023-08-03 |
CA3160602A1 (en) | 2021-06-10 |
EP3850511A1 (en) | 2021-07-21 |
KR102541981B1 (en) | 2023-06-12 |
US11625472B2 (en) | 2023-04-11 |
KR20210071869A (en) | 2021-06-16 |
JP7227236B2 (en) | 2023-02-21 |
JP2022517286A (en) | 2022-03-08 |
WO2021112827A1 (en) | 2021-06-10 |
US20210406356A1 (en) | 2021-12-30 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US10489395B2 (en) | Methods and systems for providing functional extensions with a landing page of a creative | |
CN108811514B (en) | System and method for detecting that an application executing on a client device improperly implements presentation of a content item | |
KR102038640B1 (en) | System and method for assigning scroll events in an infinite scroll graphical user interface | |
US20160371751A1 (en) | Methods and systems for reducing inadvertent interactions with advertisements displayed on a computing device | |
US9665965B2 (en) | Video-associated objects | |
US20230368250A1 (en) | Systems and methods for dynamically inserting content item slots in an information resource | |
CN108604204B (en) | Selecting and distributing records of applications executing on computing devices in a network environment | |
US10120839B2 (en) | Methods and systems for identifying elements of a mobile application | |
CN111226198B (en) | Controlling triggering of function calls from content items | |
EP3286668A1 (en) | Systems and methods for dynamically appending supplemental content to an information resource response to scroll activity | |
KR20140092908A (en) | Input mapping regions | |
US11579766B2 (en) | Methods and systems for reducing inadvertent interactions with advertisements displayed on a computing device | |
US10565118B2 (en) | Systems and methods for prefetching content items | |
US10055508B1 (en) | Platform-agnostic thick-client system for combined delivery of disparate streaming content and dynamic content by combining dynamic data with output from a continuous queue transmitter | |
US11625472B2 (en) | Converting static content items into interactive content items | |
US11675492B2 (en) | Determining user engagement in content based on scrolling events |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination |