US20180357548A1 - Recommending Media Containing Song Lyrics - Google Patents
Recommending Media Containing Song Lyrics Download PDFInfo
- Publication number
- US20180357548A1 US20180357548A1 US14/701,275 US201514701275A US2018357548A1 US 20180357548 A1 US20180357548 A1 US 20180357548A1 US 201514701275 A US201514701275 A US 201514701275A US 2018357548 A1 US2018357548 A1 US 2018357548A1
- Authority
- US
- United States
- Prior art keywords
- candidate
- song
- feature vector
- seed
- lyric
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Abandoned
Links
Images
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L67/00—Network arrangements or protocols for supporting network services or applications
- H04L67/2866—Architectures; Arrangements
- H04L67/30—Profiles
- H04L67/306—User profiles
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N5/00—Computing arrangements using knowledge-based models
- G06N5/04—Inference or reasoning models
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N20/00—Machine learning
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L67/00—Network arrangements or protocols for supporting network services or applications
- H04L67/14—Session management
- H04L67/146—Markers for unambiguous identification of a particular session, e.g. session cookie or URL-encoding
-
- H04L67/42—
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L67/00—Network arrangements or protocols for supporting network services or applications
- H04L67/50—Network services
- H04L67/535—Tracking the activity of the user
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L67/00—Network arrangements or protocols for supporting network services or applications
- H04L67/01—Protocols
- H04L67/02—Protocols based on web technology, e.g. hypertext transfer protocol [HTTP]
Definitions
- the disclosure generally relates to the field of identifying similar media, and in particular, to identifying media having similar song lyric content.
- a content server allows users to upload media (also referred to as content) such as videos, audio, images, and/or animations. Other users may experience the media using client devices to browse media hosted on the content server.
- the content server may recommend content to users.
- Many existing content servers use collaborative filtering to generate recommendations for content. Collaborative filtering identifies users who exhibit similar behaviors (e.g., views, plays, ratings, likes, dislikes) with respect to content. Commonalities in those behaviors may then be used to indicate content to recommend to any individual user.
- collaborative filtering may not account for the idiosyncrasies of individual users' tastes or accurately predict a listening user's reaction to content experienced by only a few users.
- Other types of analysis such as content-based recommendations, can predict a user's reaction to newly uploaded content by comparing inherent characteristics of the content to previous content the user has experienced.
- analyzing content such as audio and video to identify characteristics is both computationally intensive and often inaccurate.
- a content server stores video and audio, and other media containing songs.
- One or more seed songs associated with one or more seed lyrics and a client device are obtained.
- a seed feature vector characterizing the seed lyrics is obtained.
- a song lyric corpus including candidate feature vectors characterizing candidate song lyrics of candidate songs is accessed.
- Song lyric features are stored in the song lyric corpus to facilitate identification of candidate lyrics most similar to the seed lyrics.
- the candidate feature vectors in the song lyric corpus may be reduced-dimension versions of high-dimensional feature vectors quantifying characteristics of the song lyrics.
- One of the candidate songs is selected according to a measure of similarity between the seed feature vector and one of the candidate feature vectors corresponding to the selected candidate song.
- a song recommendation including the selected candidate song is generated and provided to the client device associated with the song.
- the disclosed embodiments include a computer-implemented method, a system, and a non-transitory computer-readable medium.
- FIG. 1 is a block diagram of a networked computing environment for experiencing media, in accordance with an embodiment.
- FIGS. 2A and 2B are block diagrams of an example lyric analyzer and an example recommendation engine, respectively, in accordance with an embodiment.
- FIG. 3 is a block diagram of an example feature generator, in accordance with an embodiment.
- FIG. 4 is a flowchart illustrating an example process for generating a song lyric corpus, in accordance with an embodiment.
- FIG. 5 is a flowchart illustrating an example process for recommending a song, in accordance with an embodiment.
- FIG. 6 is a level block diagram illustrating an example computer usable to implement entities of the content sharing environment, in accordance with one embodiment.
- FIG. 1 illustrates a block diagram of a networked environment for sharing media, in accordance with one embodiment.
- the entities of the networked environment include a client device 110 , a content server 130 , and a network 120 . Although single instances of the entities are illustrated, multiple instances may be present. For example, multiple client devices 110 associated with multiple users may request and present media to multiple content servers 130 .
- the functionalities of the entities may be distributed among multiple instances. For example, a content distribution network of servers at geographically dispersed locations implements the content server 130 to increase server responsiveness and to reduce media loading times.
- a client device 110 is a computing device that accesses the content server 130 through the network 120 . By accessing the content server 130 , the client device 110 may carry out user-initiated tasks that are provided by the content server 130 such as browsing media, presenting media, or uploading media.
- Media or content refers to an electronically distributed representation of information and includes videos, audio, images, animation, and/or text. To present media, the client device 110 may play a video or audio file or may display an image or animation, for example.
- the client device 110 may receive from the content server 130 identifiers of media recommended for the user and present a media preview of the recommended media to the user.
- the media preview may be a thumbnail image, a title of the media, and a playback duration of the media, for example.
- the client device 110 detects an input from a user to select one of the media previews and requests the media corresponding to the selected media preview from the content server 130 for playback through an output device (e.g., display, speakers) of the client device 110 .
- the client device 110 includes a computer, which is described further below with respect to FIG. 6 .
- Example client devices 110 include a desktop computer, a laptop, a tablet, a mobile device, a smart television, and a wearable device.
- the client device 110 may contain software such as a web browser or other application for presenting media from the content server 130 .
- the client device 110 may include software such a video player, an audio player, or an animation player to support presentation of media.
- the content server 130 stores media, in some cases uploaded by a user through a client device 110 , and serves uploaded media to a listening user through a client device 110 .
- the content server 130 may also store media acquired from content owners (e.g., production companies, record labels, publishers).
- the content server 130 generates and provides the recommendations to client devices 110 . For instance, if a client device 110 presents a music video, then the content server 130 is configured to recommend other music videos similar to the presented music video.
- the content server 130 recommends one or more songs or media containing those songs (e.g., music videos) having song lyrics with characteristics related to characteristics of song lyrics of a seed song (e.g., from a recently presented music video).
- a song refers to media (typically audio or video) representing music associated with a song lyric.
- a song lyric is a collection of words accompanying music.
- Song lyrics include both audible words (e.g., sung, rapped, chanted, or spoken words) and visible words (e.g., printed words or gestured words as in sign language).
- Words are meaningful elements of speech and may include both semantically meaningful words and semantically meaningless words (e.g., gibberish or representations of vocalizations).
- the content server 130 includes a content store 131 , an account store 133 , a content interface module 134 , a lyric analyzer 135 , a recommendation engine 137 , and a web server 139 .
- the functionality of the illustrated components may be distributed (in whole or in part) among a different configuration of modules. Some described functionality may be optional; for example, in one embodiment the content server 130 does not include an account store 133 .
- the content server 130 stores songs and other media in the content store 131 .
- the content store 131 may be a database containing entries each corresponding to a song and other information related to the song.
- the database is an organized collection of data stored on one or more non-transitory, computer-readable media.
- a database includes data stored across multiple computers whether located in a single data center or multiple geographically dispersed data centers. Databases store, organize, and manipulate data according to one or more database models such as a relational model, a hierarchical model, or a network data model.
- the entry for a song in the content store 131 may include the song itself (e.g., the audio or video file) or a pointer (e.g., a memory address, a uniform resource identifier (URI), an internet protocol (IP) address) to another database storing the song.
- a song's entry in the content store 131 may indicate associated metadata, which are properties of the media and may indicate the media's source (e.g., an uploader name, an uploader user identifier) and/or attributes (e.g., a video identifier, a title, a description, a file size, a file type, a frame rate, a resolution, an upload date, a channel including the media).
- Metadata associated with media may also include a pointer to song lyrics associated with media, or the song lyrics themselves.
- the song lyrics may be stored as text as in a song's entry in the content store 131 or in another database.
- the account store 133 contains account profiles of content server users.
- the account store 133 may store the account profiles as entries in a database.
- An account profile includes information provided by a user of an account to the content server, including a user identifier, access credentials, and user preferences.
- the account profile may include a history of media experienced by the user, media uploaded by the user, or media included in search results from a user query to the content server 130 , as well as records describing how the user engaged with experienced media. These engagement records may describe a rating provided by a user (e.g., numerical, like, dislike, or other qualitative rating), a share by the user (e.g., via a social network, email, or short message), or portions of the media presented to the user (and portions skipped by the user), for example.
- a rating provided by a user (e.g., numerical, like, dislike, or other qualitative rating)
- a share by the user e.g., via a social network, email, or short message
- the recommendation engine 137 uses the media in a user's history to provide more relevant song recommendations.
- a user's account profile includes privacy settings established by a user to control use and sharing of personal information by the content server 130 .
- the web server 139 links the content server 130 via the network 120 to the client device 110 .
- the web server 139 serves web pages, as well as other content, such as JAVA®, FLASH®, XML, and so forth.
- the web server 139 may receive uploaded content items from the one or more client devices 110 . Additionally, the web server 139 communicates instructions from the content interface 125 for presenting media and for processing received input from a user of a client device 110 . Additionally, the web server 139 may provide application programming interface (API) functionality to send data directly to an application native to a client device's operating system, such as IOS®, ANDROIDTM, or WEBOS®.
- API application programming interface
- the content interface module 134 generates a graphical user interface that a user interacts with through software and input devices (e.g., a touchscreen, a mouse) on the client device 110 .
- the user interface is provided to the client device 110 through the web server 139 , which communicates with the software of the client device 110 that presents the user interface.
- the user accesses content server functionality including browsing, experiencing, and uploading media.
- the content interface may include a media player (e.g., a video player, an audio player, an image viewer) that presents content.
- the content interface module 134 may display metadata associated with the media and retrieved from the content store 131 .
- Example displayed metadata includes a title, upload data, an identifier of an uploading user, and content categorizations.
- the content interface module 134 may incorporate a search interface for browsing content or a recommendation interface presenting song recommendations generated by the recommendation engine 137 .
- the lyric analyzer 135 obtains song lyrics associated with songs and generates feature vectors quantifying characteristics of the song lyrics.
- the recommendation engine 137 uses these feature vectors to generate song recommendations.
- a feature vector may be generated from an initial feature vector having more dimensions quantifying individual characteristics of the corresponding song lyric than the dimensions of the feature vector.
- Example characteristics of song lyrics include prevalence of rhymes, presence of particular words, emotional tone, rhyming structure, or musical structure.
- An initial feature vectors may be transformed with a dimensionality reduction to produce a corresponding feature vector. Reducing the number of dimensions beneficially increases computational efficiency of comparisons between feature vectors.
- Feature vectors may be stored in a song lyric corpus accessed by the recommendation engine 137 .
- the song lyric corpus beneficially reduces processing time to generate a song recommendation by organizing song lyric data to facilitate retrieval of feature vectors corresponding to song lyrics similar to a seed lyric.
- the lyric analyzer 135 is described in further detail with respect to FIG. 2A .
- the recommendation engine 137 obtains one or more seed songs and generates a song recommendation including other songs having similar song lyrics to seed lyrics of the one or more seed songs.
- the recommendation engine 137 identifies candidate songs likely to have similar lyrics to the one or more seed songs.
- a seed song is associated with a seed feature vector quantifying characteristics of the seed lyrics
- the candidate songs are associated with candidate feature vectors quantifying characteristics of the candidate song's song lyrics.
- the recommendation engine 137 selects one or more of the candidate songs. For instance, the recommendation engine 137 compares the feature vectors by determining a measure of similarity between the seed feature vector and a candidate feature vector.
- the one or more of the selected songs may be included in a recommendation interface generated by the recommendation interface module 134 and provided to a client device 110 .
- the recommendation engine 137 is described in further detail with respect to FIG. 2B .
- the network 120 enables communications among the entities connected thereto through one or more local-area networks and/or wide-area networks.
- the network 120 e.g., the Internet
- the network 120 may use standard and/or custom wired and/or wireless communications technologies and/or protocols.
- the data exchanged over the network 120 can be encrypted or unencrypted.
- the network 120 may include multiple sub-networks to connect the client device 110 and the content server 130 .
- the network 120 may include a content distribution network using geographically distributed data centers to reduce transmission times for media sent and received by the content server 130 .
- FIG. 2A is a block diagram of an example lyric analyzer 135 , in accordance with an embodiment.
- the lyric analyzer 135 includes a lyric store 205 , a feature generator 210 , a feature reducer 215 , a lyric corpus generator 220 , and a song lyric corpus 225 .
- the functionality of the lyric analyzer 135 may be provided by additional, different, or fewer modules than those described herein.
- the lyric store 205 stores song lyrics associated with songs in the content store 131 .
- the lyrics store 205 may stores the song lyrics as text in corresponding entries of a database.
- the content server 130 may obtain the song lyrics by analyzing audio content, analyzing user-transcribed lyrics, receiving the song lyrics from a content owner (e.g., an artist, recording label, or media company), or a combination thereof. For instance, the content server 130 obtains and reconciles user-generated transcriptions of song lyrics to correct inconsistencies between different versions of song lyrics.
- the content server 130 transcribes lyrics from audio content by filtering frequencies outside a human vocal range from song audio, identifying non-vocalized sounds based on timbre outside the human vocal range, and applying a text-to-speech algorithm to transcribe the remaining audio.
- the content server 130 stores the resulting reconciled song lyrics in the lyric store 205 .
- song lyrics are provided by a content owner or other official source, these song lyrics may be used in place of user-transcribed or machine-transcribed song lyrics.
- the feature generator 210 accesses song lyrics in the lyric store 205 and generates feature vectors.
- a feature vector quantifies characteristics of a song lyric.
- the quantified characteristics are generally numerical in nature, such as a count (e.g., number of rhyming word pairs) or a binary indicator (e.g., whether rhyming words are present).
- the feature generator 210 combines the different quantifications of different characteristics as different dimensions of the feature vector.
- the feature vector may be generated in a particular format specifying an order of dimensions and corresponding characteristics.
- Other functionally equivalent representations of a feature vector include a key/value table, an n-tuple, an array, a matrix row or column, or any other grouping of numerical values. Particular characteristics encoded in the feature vector are described in further detail with respect to FIG. 3 .
- the feature reducer 215 obtains a feature vector generated by the feature generator 210 and generates a dimensionally reduced feature vector from the initial feature vector.
- the feature vector generated by the feature generator 210 may be referred to as an “initial feature vector,” and the feature vector generated by the feature reducer 215 may be referred to as a “reduced feature vector.”
- the feature reducer 215 performs a dimensionality reduction algorithm to approximate the initial feature vector using fewer dimensions. In some dimensionality reduction algorithms, the feature reducer 215 determines a transform to de-correlate a set of initial feature vectors and determines a measure of information represented within each dimension of the set of transformed feature vectors.
- a dimension of a transformed feature vector represents a combination of characteristics of the corresponding song lyrics, and the measure of information for the dimension indicates how much a combination of characteristics differentiates the song lyrics from other song lyrics.
- the feature reducer 215 ranks the transformed dimensions according to the corresponding measures of information and selects a subset of the transformed dimensions according to the ranking.
- the selected dimensions represent those combinations of characteristics that, in the aggregate, differentiate song lyrics from each other.
- the feature reducer 215 may select a pre-determined number of transformed dimensions or may determine a number of transformed dimensions to select so that a total measure of information in the selected dimensions equals or exceeds a threshold.
- the feature reducer 215 generates a reduced feature vector by applying the transform to an initial feature vector and by selecting the subset of transformed dimensions to form the reduced feature vector.
- the feature reducer 215 generates reduced feature vectors corresponding to the set of initial feature vectors used to determine the transform and stores the reduced feature vectors in the song lyric corpus 225 .
- the feature reducer 215 obtains an initial feature vector corresponding to the additional song lyrics and generates a corresponding reduced feature by applying the transform determined from the set of initial feature vectors.
- the feature reducer 215 may apply a dimensionality reduction algorithm such as a principal component analysis (PCA) transform to generate the reduced feature vector.
- PCA principal component analysis
- the feature reducer 215 subtracts an average of the set of initial feature vectors to determine de-trended feature vectors, determines a covariance matrix of the de-trended feature vectors, and rotates the de-trended feature vectors into alignment with eigenvectors of the covariance matrix.
- the dimensions of the resulting rotated feature vectors no longer quantify individual characteristics of song lyrics but rather correspond to linear combinations of the quantified characteristics.
- the eigenvalue corresponding to a dimension of the rotated feature vectors is proportional to the variance represented in the dimension, so the feature reducer 215 uses the eigenvalue of a dimension (normalized by the total sum of the eigenvalues) as the measure of information in the dimension of the rotated feature vectors. The feature reducer 215 then selects a subset of the dimensions of the rotated feature vector to generate the reduced feature vector.
- the feature reducer 215 applies a different linear dimensionality reduction algorithm than PCA or applies a non-linear dimensionality reduction algorithm to project the initial feature vector onto a hyperplane or other manifold having fewer dimensions than the initial feature vector.
- the lyric corpus generator 220 obtains feature vectors (e.g., reduced features vector from the feature reducer 215 or initial feature vectors from the feature generator 210 ) and generates the song lyric corpus 225 to store the feature vectors.
- the lyric corpus generator 220 may also insert, modify, or delete a feature vector from the song lyric corpus 225 .
- a newly released song is uploaded to the content server 130 , the feature generator 210 generates an initial feature vector, the feature reducer 215 generates a reduced feature vector, and the lyric corpus generator 220 adds the reduced feature vector to the song lyric corpus 225 .
- Feature vectors stored in the song lyric corpus 225 may be initial feature vectors or reduced feature vectors.
- the lyric corpus generator 220 may generate the song lyric corpus 225 as a structure that facilitates identification of feature vectors similar to a seed feature vector.
- the lyric corpus generator 220 generates the song lyric corpus 225 as a k-dimensional tree (k-d tree) having nodes corresponding to feature vectors arranged in a branched tree structure.
- a layer of the k-d tree corresponds to a particular dimension of the feature vectors. Different branches from a node in a layer correspond to different ranges in the value of the dimension corresponding to the layer.
- a node corresponding to a feature vector has two branches, and the node is in a layer of the k-d tree corresponding to a third dimension of the feature vectors, so the value of the third dimension of the feature vector corresponding to the node is used as a threshold value.
- one branch from the node includes feature vectors having a value in the third dimension exceeding the threshold value
- the other branch from the node includes feature vectors having a value in the third dimension not exceeding the threshold value.
- the resulting k-d tree may be accessed to find feature vectors similar to a seed vector without comparing the seed vector to every feature vector in the song lyric corpus 225 .
- the lyric corpus generator 220 generates the song lyric corpus 225 as a structure to enable identification of similar feature vectors without guaranteeing retrieval of the feature vector most similar to the seed vector. For instance, the lyric corpus generator 220 generates the song lyric corpus 225 as one or more hashing tables indicating outputs of one or more locality-sensitive hash (LSH) functions.
- LSH locality-sensitive hash
- An LSH function deterministically maps an input to an output.
- LSH functions have a limited number of outputs to increase the probability of hashing collisions.
- the lyric corpus generator 220 creates a hashing table including an entry for each feature vector indicating the output from an LSH function given the feature vector as input.
- the lyric corpus generator 220 may also generate an inverse hashing table identifying the feature vectors (and corresponding song lyrics) that correspond to a given output of the LSH function. Those feature vectors having a same output from the LSH function make up a bucket of feature vectors likely to be similar to each other.
- LSH functions reduces the dimensionality of the feature vectors, thereby obviating the feature reducer 215 .
- FIG. 2B is a block diagram of an example recommendation engine 137 , in accordance with an embodiment.
- the recommendation engine 137 obtains one or more seed songs and generates a song recommendation including at least one song having song lyrics similar to seed lyrics of the one or more seed songs.
- the obtained seed song may be a song the user has watched as part of a video, a song identified based on a corresponding user search, or a song the user has engaged, for example.
- the recommendation engine 137 selects the song to recommend according to a measure of similarity between a seed feature vector quantifying characteristics of the one or more seed songs' seed lyrics and a feature vector corresponding to song lyrics to the selected song.
- the recommendation engine 137 includes a seed feature vector provider 227 , a lyric selector 230 , a similarity evaluator 235 , and a recommendation generator 240 .
- the functionality of the recommendation engine 137 may include additional, different, or fewer modules than those described herein.
- the seed feature vector provider 227 accesses a user's account profile from the account store 133 and obtains a seed feature vector for recommending songs to the user. From the account store 133 , the seed vector provider 227 obtains songs associated with the user, including songs experienced by the user, songs uploaded by the user, or songs included in search results from a user query to the content server 130 . The songs associated with the user may include songs identified by another song recommendation algorithm (e.g., collaborative filtering). From the songs associated with the user, the seed vector provider 227 selects a seed song. For example, the seed song is a song the user is currently streaming from the content server 130 .
- the seed vector provider 227 selects a seed song. For example, the seed song is a song the user is currently streaming from the content server 130 .
- the seed feature vector provider 227 accesses the seed feature vector corresponding to the selected seed song from the song lyric corpus 225 and provides the seed feature vector to the lyric selector 230 . Alternatively to accessing the seed feature vector, the seed feature vector provider 227 generates the seed feature vector according to the process described with respect to the feature generator 210 and/or the feature reducer 215 .
- the seed feature vector provider 227 selects multiple seed songs and obtains a composite seed feature vector characterizing a composite of the seed songs.
- the seed songs are a number of songs the user has watched most recently or has experienced most frequently within a threshold duration of a current time (i.e., time of generating the recommendation).
- the seed feature vector provider 227 accesses (or generates) seed feature vectors corresponding to the selected seed songs and combines the seed feature vectors to determine a composite seed feature vector.
- the seed feature vector provider 227 may determine the composite seed feature vector from a measure of central tendency (e.g., mean, median, mode) of the seed song vectors or a weighted combination of the seed song vectors. For example, the seed song vectors are weighted according to the songs' overall popularity, number of streams by the user, or number of engagements by the user.
- the seed feature vector provider 227 selects one or more seed songs from the songs associated with a user by clustering the songs associated with the user according to one or more variables describing the user's session (e.g., time, location, client device type, client device operating system, client device browser, network connection speed, network connection type) when experiencing the songs.
- variables describing the user's session e.g., time, location, client device type, client device operating system, client device browser, network connection speed, network connection type
- One or more variables describing the user's current session are obtained, and the seed feature vector provider 227 selects songs in a cluster corresponding to the variables describing the user's current session.
- the seed feature vector provider 227 identifies distinct clusters of songs associated with (1) songs provided to the user's mobile device while commuting through multiple locations in the morning, (2) songs provided to the user's desktop at a work location in the afternoon, and (3) songs provided to the user's laptop at a home location during the evening.
- the seed feature vector provider 227 obtains variables describing the user's current session and indicating that the user is currently experiencing songs on the user's laptop at the home location during the evening, so the seed feature vector provider 227 selects one or more seed songs from the corresponding cluster (3).
- the seed feature vector provider 227 accesses (or generates) one or more seed feature vectors corresponding to the selected one or more songs, combines them (if necessary) into a composite seed feature vector, and provides the composite seed feature vector to the lyric selector 230 .
- the lyric selector 230 obtains a seed feature vector from the seed feature vector provider 227 and selects one or more songs having song lyrics similar to those of the one or more seed songs according to a measure of similarity between the seed feature vector and a feature vector corresponding to song lyrics of the selected one or more songs.
- the lyric selector 230 identifies candidate feature vectors, which are a subset of feature vectors in the song lyric corpus 225 expected to have a higher measure of similarity to the seed feature vector than other feature vectors in the song lyric corpus 225 .
- the song lyric corpus 225 includes one or more LSH hash tables, and the lyric selector 230 identifies candidate feature vectors from feature vectors having an LSH hash output value matching the LSH output value of the seed vector in one or more of the LSH hash tables.
- the lyric selector 230 includes all the feature vectors in the song lyric corpus 225 as candidate feature vectors.
- the lyric selector 230 ranks the candidate feature vectors according to measures of similarity determined between the seed feature vector and each candidate feature vector.
- the lyric selector 230 selects a number of songs according to the ranking of their respective candidate feature vectors.
- the number of songs selected may be a pre-determined number (e.g., a number of recommended songs to appear in a user interface) or may be determined from the number of candidate feature vectors having a measure of similarity equaling or exceeding a threshold measure of similarity.
- the lyric selector 230 may identify, rank, and select candidate feature vectors simultaneously. For example, as the song lyric selector 230 identifies the candidate feature vectors, the song lyric selector 230 compares each identified candidate feature vector to a “best match” candidate feature vector. If the measure of similarity between the identified candidate feature vector and the seed feature vector equals or exceeds the measure of similarity between the best match candidate vector and the seed feature vector, then the identified candidate feature vector replaces the current best match candidate feature vector as the best match candidate feature vector. Once the search for candidate feature vectors is complete, the lyric selector 230 selects the remaining best match candidate feature vector for use in the recommendation.
- the song lyric corpus 225 is a k-d tree
- the lyric selector 230 identifies the candidate feature vectors by performing a nearest neighbor search of the k-d tree.
- the lyric selector 230 traverses nodes corresponding to the candidate feature vectors.
- the traversed nodes include the root node of the k-d tree and nodes between the root node and a node representing the seed feature vector.
- the lyric selector 230 traverses nodes in other branches of the k-d tree and determines whether to traverse farther down those branches according to the measure of similarity between candidate feature vectors at root nodes of the other branches and the seed feature vector. If the measure of similarity for the node of a branch equals or exceeds the measure of similarities for previously traversed nodes, the lyric selector 230 traverses additional nodes in the other branch to identify additional candidate feature vectors.
- the similarity evaluator 235 accesses a seed feature vector and a candidate feature vector from the song lyric corpus 225 and determines a measure of similarity between the seed feature vector and the candidate feature vector.
- the measure of similarity increases as the difference decreases between corresponding dimensions of the seed feature vector and the candidate feature vector.
- “similarity” between first and second song lyrics may be determined according to the measure of similarity between first and second feature vectors corresponding to the first and second song lyrics.
- the measure of similarity may be the cosine similarity.
- the measure of similarity may be determined from a measure of dissimilarity such as the L2 norm (Cartesian distance) or L1 norm (Manhattan distance).
- the measure of similarity may be the inverse of the Cartesian distance between the candidate feature vector and the seed feature vector.
- the similarity evaluator 235 may obtain either or both feature vectors from the feature generator 210 and/or the feature reducer 215 .
- the recommendation generator 240 obtains one or more songs selected by the lyric selector 230 and generates a song recommendation.
- the generated recommendation may include a subset of the selected songs or may include all the subset of selected songs.
- the songs selected by the lyric selector 230 may be filtered according to preferences of the user's account profile.
- the recommendation generator 240 may rank the selected songs according to a user's likelihood of engagement with the song.
- the recommendation generator 240 may include in the ranking additional songs or other media identified according to additional recommendation techniques (e.g., collaborative filtering).
- the recommendation generator 240 selects songs according to the ranking and generates a song recommendation including the selected songs.
- the content interface module 134 incorporates the song recommendation into a user interface (e.g., as a sidebar of a video player) and provides the song recommendation to the client device 110 associated with the user.
- FIG. 3 is a block diagram of an example feature generator 210 , in accordance with an embodiment.
- the feature generator 210 generates feature vectors for a song quantifying characteristics of the song.
- the feature generator 210 generates feature vectors including dimensions that quantify characteristics of song lyrics, but the generated feature vectors may also include dimensions quantifying other properties of a song such as musical properties (e.g., tempo, tonality, instrumentation), visual properties (e.g., brightness, number of intra-coded frames), other song metadata (e.g., song length, song data size), or characteristics of users experiencing a song (e.g., average and total number of times users have experienced a song, demographic characteristics).
- musical properties e.g., tempo, tonality, instrumentation
- visual properties e.g., brightness, number of intra-coded frames
- other song metadata e.g., song length, song data size
- characteristics of users experiencing a song e.g., average and total number of times users have experienced a song, demographic
- the feature generator 210 includes a word feature module 311 , a term feature module 312 , a line feature module 313 , a character feature module 314 , an affective feature module 315 , a rhyme feature module 316 , and a structural feature module 317 .
- the feature generator 210 may include additional, different, or fewer modules than those described herein.
- the word feature module 311 obtains song lyrics and determines values for a dimension of the feature vector that quantifies words in the song lyrics.
- a dimension of the feature vector generated by the word feature module 311 may correspond to a total number (e.g., total words, total unique words), a normalized total (e.g., total unique words per total words), or a measure of central tendency (e.g., average word length in syllables or characters, average word difficulty, average word rarity).
- a measure of central tendency includes an average, mean, median or mode.
- the rarity of a word may be determined based on a logarithm of frequency of the word among lyrics in the lyric store 205 or in an external database (e.g., the Brown University Standard Corpus of Present-Day American English).
- the feature vector may include a dimension corresponding to the presence of a particular word or a number of instances of a particular word (e.g., number of instances of an obscenity).
- the term feature module 312 obtains song lyrics and determines values for a dimension of the feature vector that quantifies terms in the song lyrics.
- a term is a group of one or more words having distinct semantic meaning (i.e., a phrase).
- a dimension of the feature vector generated by the term feature module 312 may correspond to a total number (e.g., total terms, total unique terms), a normalized total (e.g., total unique terms per total words), or a measure of central tendency (e.g., average term length, average term rarity).
- the rarity of a term may be determined based on a logarithm of frequency (i.e. song lyrics containing the word per total number of song lyrics) of the term among lyrics in the lyric store 205 .
- the feature vector may include a dimension corresponding to the presence of a particular term or a number of instances of a particular term.
- the term feature module 312 may determine the term frequency-inverse document frequency (TF-IDF) of a particular term for inclusion as a dimension of the feature vector.
- the term feature module 312 determines the TF-IDF from the term frequency of the term in the song relative to total words (or total terms) in the song lyric.
- the term feature module 312 determines the inverse document frequency from the order of magnitude (e.g., logarithm) of the total number of lyrics in the lyric store 205 normalized by the number of lyrics in the lyric store 205 containing the term. In other words, the TF-IDF is normalized by the prevalence of the term.
- the line feature module 313 obtains song lyrics and determines values for a dimension of the feature vector that quantifies lines in the song lyrics.
- a line of a song lyric indicates a rhythmic or other break and is typically indicated by a line break in song lyric text.
- a dimension of the feature vector generated by the line feature module 313 may correspond to a total number (e.g., total lines, total unique lines), a normalized total (e.g., total unique lines per total lines or per total words), or a measure of central tendency (e.g., average words per line, average unique words per line, average unique words per unique line).
- the character feature module 314 obtains song lyrics and generates features quantifying characters in the song lyrics. Characters refer to letters, numbers, or punctuation in song lyrics. A dimension of the feature vector generated by the character feature module 314 may quantify occurrences of a particular character (e.g., a total number of exclamation points, total number of numerical digits, average number of punctuation marks per total words in lyric) or instances of consecutive characters (e.g., total number of occurrences of three consecutive question marks, average number of occurrence of consecutive characters per total words in lyric).
- a particular character e.g., a total number of exclamation points, total number of numerical digits, average number of punctuation marks per total words in lyric
- consecutive characters e.g., total number of occurrences of three consecutive question marks, average number of occurrence of consecutive characters per total words in lyric.
- the affective feature module 315 obtains song lyrics and determines values for a dimension of the feature vector that indicates an affective rating of the song lyrics.
- An affective rating quantifies emotional content evoked by a word or set of words.
- Example affective ratings of a word include valence (i.e., pleasantness), arousal (i.e., intensity), and dominance (i.e., control).
- the affective feature module 315 obtains affective ratings corresponding to individual terms (or words) in song lyrics and determines an overall affective rating of the song lyric according to the number of occurrences of the term and the corresponding affective rating.
- the total affective rating is an inner product of a vector indicating the affective rating of individual words and a vector indicating the number of instances (or length-normalized instances) of the word in the song lyric.
- the feature vector may include one or more dimensions including different total affective ratings.
- the rhyme feature module 316 obtains song lyrics and determines values for a dimension of the feature vector that quantifies rhymes in the song lyrics.
- the rhyme feature module 316 obtains phonemes of the words in the song lyric from a pronunciation database and identifies pairs (or sets) of rhyming words. Words rhyme when the phonemes in their respective last syllables at least partially match.
- the rhyme feature module 316 may also identify sets of rhyming lines that end in rhyming last words.
- a dimension of a feature vector may quantify rhymes using total numbers (e.g., total rhyming words, total sets of rhyming words, number of rhyming lines, number of sets of rhyming lines) as well as measures of central tendency (e.g., rhyming words per word length, rhyming words per line, rhyming lines per total lines).
- total numbers e.g., total rhyming words, total sets of rhyming words, number of rhyming lines, number of sets of rhyming lines
- measures of central tendency e.g., rhyming words per word length, rhyming words per line, rhyming lines per total lines.
- the structural feature module 317 obtains song lyrics and determines values for a dimension of the feature vector that quantifies structures in the song lyrics. Structures in song lyrics are multi-line patterns.
- the structural feature module 317 may identify rhyme-based structures following a rhyming line pattern. For example, different rhyming line patterns include AA, AABB, ABAB, and ABBA, where A refers to lines ending with words in a first set of rhyming words and B refers to lines ending with words in a second set of rhyming words.
- Feature vectors may have a dimension indicating a number of each type of rhyming line pattern.
- the structural feature module 317 may identify parts of a song such as verses, choruses, refrains, and bridges. Parts of a song may be identified based on paragraph breaks in song lyric text, repetition of large blocks of lines, and number of lines between paragraph breaks. Feature vectors may have a dimension indicating a number of a particular type of part (e.g., number of verses, number of unique verses) or indicating the presence of a type of part (e.g., presence of a bridge).
- FIG. 4 is a flowchart illustrating an example process for generating a song lyric corpus 225 , in accordance with an embodiment.
- the lyric analyzer 135 may generate the song lyric corpus 225 for later access by the recommendation engine 137 . Generating the song lyric corpus 225 prior to receiving a request for a song recommendation reduces the time to provide a song recommendation by reducing computations after the time of the request.
- the structure of the song lyric corpus 225 may facilitate identifying song lyrics similar to the seed lyrics (e.g., when the structure is a k-d tree or an LSH hash table).
- the lyric analyzer 135 accesses 410 candidate song lyrics of candidate songs from the lyrics store 205 .
- the feature generator 210 generates 420 initial feature vectors having a number of dimensions, where each dimension quantifies a different characteristic of the candidate song lyrics.
- the feature reducer 215 generates 430 candidate feature vectors having fewer dimensions than the initial feature vector by applying a dimensionality reduction algorithm to the initial feature vectors.
- the lyric corpus generator 220 generates 440 a structure representing the reduced candidate feature vectors and stores 450 the structure as the song lyric corpus 225 .
- the process described herein may be performed in a different order or using different, fewer, or additional steps. For example, steps described as being performed sequentially may be performed in parallel.
- the lyric analyzer 135 is described as generating feature vectors prior to generating a song recommendation, but the lyric analyzer 135 may instead generate feature vectors in response to receiving a seed song used to generate the song recommendation. In other words, feature vectors may be generated for use by the recommendation engine 135 without being stored in the song lyric corpus 225 .
- FIG. 5 is a flowchart illustrating an example process for recommending a song, in accordance with an embodiment.
- the recommendation engine 137 obtains 510 a seed song associated with a seed lyric.
- the seed song associated with a client device 110 For instance, the seed song is a video provided to the client device 110 within a threshold amount time before a current time.
- the lyric selector 230 accesses 520 a seed feature vector characterizing the seed lyric (e.g., from the song lyric corpus 225 ).
- the lyric selector 230 accesses 530 candidate feature vectors characterizing candidate song lyrics of candidate songs stored in the song lyric corpus 225 .
- the candidate feature vectors accessed may be from an identified subset of feature vectors in the song lyric corpus 225 to beneficially reduce a number of comparisons between the seed feature vector and the candidate feature vectors.
- the lyric selector 230 selects 540 a candidate song according to a measure of similarity between the seed feature vector and a candidate feature vector determined by the similarity evaluator 235 .
- the recommendation generator 240 generates 550 a song recommendation including the selected candidate song.
- the interface module 235 provides 560 the song recommendation to the client device 110 .
- Providing 560 the song recommendation refers to including the song recommendation in a user interface provided to the client device 110 .
- the content interface module 134 displays the song recommendation alongside a media player while a song plays or in the media player while or after the song plays, where the song is the seed song used to generate the song recommendation.
- the content interface module 134 presents the song recommendation as audio at the end of a seed song used to generate the song recommendation.
- the content interface module 134 generates a stream or web page displaying song recommendations generated from seed songs that the user has recently experienced.
- the process described herein may be performed in a different order or using different, fewer, or additional steps. For example, steps described as being performed sequentially may be performed in parallel.
- the recommendation engine 137 is described as accessing pre-computed feature vectors in the song lyric corpus 225 , but the feature vectors may instead be computed in response to receiving a seed song used to generate a song recommendation.
- FIG. 6 is a level block diagram illustrating an example computer 600 usable to implement entities of the content sharing environment, in accordance with one embodiment.
- the example computer 600 has sufficient memory, processing capacity, network connectivity bandwidth, and other computing resources to provide song recommendations as described herein.
- the computer 600 includes at least one processor 602 (e.g., a central processing unit, a graphics processing unit) coupled to a chipset 604 .
- the chipset 604 includes a memory controller hub 620 and an input/output (I/O) controller hub 622 .
- a memory 606 and a graphics adapter 612 are coupled to the memory controller hub 620
- a display 618 is coupled to the graphics adapter 612 .
- a storage device 608 , keyboard 610 , pointing device 614 , and network adapter 616 are coupled to the I/O controller hub 622 .
- Other embodiments of the computer 600 have different architectures.
- the storage device 608 is a non-transitory computer-readable storage medium such as a hard drive, compact disk read-only memory (CD-ROM), DVD, or a solid-state memory device.
- the memory 606 holds instructions and data used by the processor 602 .
- the processor 602 may include one or more processors 602 having one or more cores that execute instructions.
- the pointing device 614 is a mouse, touch-sensitive screen, or other type of pointing device, and in some instances is used in combination with the keyboard 610 to input data into the computer 600 .
- the graphics adapter 612 displays media and other images and information on the display 618 .
- the network adapter 616 couples the computer 600 to one or more computer networks (e.g., network 120 ).
- the computer 600 is adapted to execute computer program modules for providing functionality described herein including presenting media, playlist lookup, and/or metadata generation.
- module refers to computer program logic used to provide the specified functionality.
- a module can be implemented in hardware, firmware, and/or software.
- program modules such as the lyric analyzer 135 and the recommendation engine 137 are stored on the storage device 608 , loaded into the memory 606 , and executed by the processor 602 .
- the types of computers 600 used by the entities of the content sharing environment can vary depending upon the embodiment and the processing power required by the entity.
- the client device 110 is a smart phone, tablet, laptop, or desktop computer.
- the content server 130 might comprise multiple blade servers working together to provide the functionality described herein.
- the computers 600 may contain duplicates of some components or may lack some of the components described above (e.g., a keyboard 610 , a graphics adapter 612 , a pointing device 614 , a display 618 ).
- the content server 130 run in a single computer 600 or multiple computers 600 communicating with each other through a network such as in a server farm.
- the content server 130 may use a non-transitory computer-readable medium that stores the operations as instructions executable by one or more processors. Any of the operations, processes, or steps described herein may be performed using one or more processors. Furthermore, it has also proven convenient at times, to refer to these arrangements of operations as modules, without loss of generality.
- the described operations and their associated modules may be embodied in software, firmware, hardware, or any combinations thereof.
- any reference to “one embodiment” or “an embodiment” means that a particular element, feature, structure, or characteristic described in connection with the embodiment is included in at least one embodiment.
- the appearances of the phrase “in one embodiment” in various places in the specification are not necessarily all referring to the same embodiment.
- the terms “comprises,” “comprising,” “includes,” “including,” “has,” “having” or any other variation thereof, are intended to cover a non-exclusive inclusion.
- a process, method, article, or apparatus that comprises a list of elements is not necessarily limited to only those elements but may include other elements not expressly listed or inherent to such process, method, article, or apparatus.
- “or” refers to an inclusive or and not to an exclusive or. For example, a condition A or B is satisfied by any one of the following: A is true (or present) and B is false (or not present), A is false (or not present) and B is true (or present), and both A and B are true (or present).
Abstract
Description
- The disclosure generally relates to the field of identifying similar media, and in particular, to identifying media having similar song lyric content.
- A content server allows users to upload media (also referred to as content) such as videos, audio, images, and/or animations. Other users may experience the media using client devices to browse media hosted on the content server. The content server may recommend content to users. Many existing content servers use collaborative filtering to generate recommendations for content. Collaborative filtering identifies users who exhibit similar behaviors (e.g., views, plays, ratings, likes, dislikes) with respect to content. Commonalities in those behaviors may then be used to indicate content to recommend to any individual user.
- However, collaborative filtering may not account for the idiosyncrasies of individual users' tastes or accurately predict a listening user's reaction to content experienced by only a few users. Other types of analysis, such as content-based recommendations, can predict a user's reaction to newly uploaded content by comparing inherent characteristics of the content to previous content the user has experienced. However, analyzing content such as audio and video to identify characteristics is both computationally intensive and often inaccurate.
- A content server stores video and audio, and other media containing songs. One or more seed songs associated with one or more seed lyrics and a client device are obtained. A seed feature vector characterizing the seed lyrics is obtained. A song lyric corpus including candidate feature vectors characterizing candidate song lyrics of candidate songs is accessed. Song lyric features are stored in the song lyric corpus to facilitate identification of candidate lyrics most similar to the seed lyrics. The candidate feature vectors in the song lyric corpus may be reduced-dimension versions of high-dimensional feature vectors quantifying characteristics of the song lyrics. One of the candidate songs is selected according to a measure of similarity between the seed feature vector and one of the candidate feature vectors corresponding to the selected candidate song. A song recommendation including the selected candidate song is generated and provided to the client device associated with the song.
- The disclosed embodiments include a computer-implemented method, a system, and a non-transitory computer-readable medium. The features and advantages described in this summary and the following description are not all inclusive and, in particular, many additional features and advantages will be apparent in view of the drawings, specification, and claims. Moreover, it should be noted that the language used in the specification has been principally selected for readability and instructional purposes, and may not have been selected to delineate or circumscribe the disclosed subject matter.
- The disclosed embodiments have other advantages and features which will be more readily apparent from the detailed description and the accompanying figures. A brief introduction of the figures is below.
-
FIG. 1 is a block diagram of a networked computing environment for experiencing media, in accordance with an embodiment. -
FIGS. 2A and 2B are block diagrams of an example lyric analyzer and an example recommendation engine, respectively, in accordance with an embodiment. -
FIG. 3 is a block diagram of an example feature generator, in accordance with an embodiment. -
FIG. 4 is a flowchart illustrating an example process for generating a song lyric corpus, in accordance with an embodiment. -
FIG. 5 is a flowchart illustrating an example process for recommending a song, in accordance with an embodiment. -
FIG. 6 is a level block diagram illustrating an example computer usable to implement entities of the content sharing environment, in accordance with one embodiment. - The figures and the following description relate to particular embodiments by way of illustration only. It should be noted that from the following discussion, alternative embodiments of the structures and methods disclosed herein will be readily recognized as viable alternatives that may be employed without departing from the principles of what is claimed.
- Reference will now be made in detail to several embodiments, examples of which are illustrated in the accompanying figures. It is noted that wherever practicable similar or like reference numbers may be used in the figures and may indicate similar or like functionality. The figures depict embodiments of the disclosed system (or method) for purposes of illustration only. Alternative embodiments of the structures and methods illustrated herein may be employed without departing from the principles described herein.
-
FIG. 1 illustrates a block diagram of a networked environment for sharing media, in accordance with one embodiment. The entities of the networked environment include aclient device 110, acontent server 130, and anetwork 120. Although single instances of the entities are illustrated, multiple instances may be present. For example,multiple client devices 110 associated with multiple users may request and present media tomultiple content servers 130. The functionalities of the entities may be distributed among multiple instances. For example, a content distribution network of servers at geographically dispersed locations implements thecontent server 130 to increase server responsiveness and to reduce media loading times. - A
client device 110 is a computing device that accesses thecontent server 130 through thenetwork 120. By accessing thecontent server 130, theclient device 110 may carry out user-initiated tasks that are provided by thecontent server 130 such as browsing media, presenting media, or uploading media. Media (or content) refers to an electronically distributed representation of information and includes videos, audio, images, animation, and/or text. To present media, theclient device 110 may play a video or audio file or may display an image or animation, for example. - The
client device 110 may receive from thecontent server 130 identifiers of media recommended for the user and present a media preview of the recommended media to the user. The media preview may be a thumbnail image, a title of the media, and a playback duration of the media, for example. Theclient device 110 detects an input from a user to select one of the media previews and requests the media corresponding to the selected media preview from thecontent server 130 for playback through an output device (e.g., display, speakers) of theclient device 110. - The
client device 110 includes a computer, which is described further below with respect toFIG. 6 .Example client devices 110 include a desktop computer, a laptop, a tablet, a mobile device, a smart television, and a wearable device. Theclient device 110 may contain software such as a web browser or other application for presenting media from thecontent server 130. Theclient device 110 may include software such a video player, an audio player, or an animation player to support presentation of media. - The
content server 130 stores media, in some cases uploaded by a user through aclient device 110, and serves uploaded media to a listening user through aclient device 110. Thecontent server 130 may also store media acquired from content owners (e.g., production companies, record labels, publishers). Thecontent server 130 generates and provides the recommendations toclient devices 110. For instance, if aclient device 110 presents a music video, then thecontent server 130 is configured to recommend other music videos similar to the presented music video. In one embodiment, thecontent server 130 recommends one or more songs or media containing those songs (e.g., music videos) having song lyrics with characteristics related to characteristics of song lyrics of a seed song (e.g., from a recently presented music video). - A song refers to media (typically audio or video) representing music associated with a song lyric. A song lyric is a collection of words accompanying music. Song lyrics include both audible words (e.g., sung, rapped, chanted, or spoken words) and visible words (e.g., printed words or gestured words as in sign language). Words are meaningful elements of speech and may include both semantically meaningful words and semantically meaningless words (e.g., gibberish or representations of vocalizations).
- In one embodiment, the
content server 130 includes acontent store 131, anaccount store 133, acontent interface module 134, alyric analyzer 135, arecommendation engine 137, and aweb server 139. The functionality of the illustrated components may be distributed (in whole or in part) among a different configuration of modules. Some described functionality may be optional; for example, in one embodiment thecontent server 130 does not include anaccount store 133. - The
content server 130 stores songs and other media in thecontent store 131. Thecontent store 131 may be a database containing entries each corresponding to a song and other information related to the song. The database is an organized collection of data stored on one or more non-transitory, computer-readable media. A database includes data stored across multiple computers whether located in a single data center or multiple geographically dispersed data centers. Databases store, organize, and manipulate data according to one or more database models such as a relational model, a hierarchical model, or a network data model. - The entry for a song in the
content store 131 may include the song itself (e.g., the audio or video file) or a pointer (e.g., a memory address, a uniform resource identifier (URI), an internet protocol (IP) address) to another database storing the song. A song's entry in thecontent store 131 may indicate associated metadata, which are properties of the media and may indicate the media's source (e.g., an uploader name, an uploader user identifier) and/or attributes (e.g., a video identifier, a title, a description, a file size, a file type, a frame rate, a resolution, an upload date, a channel including the media). Metadata associated with media may also include a pointer to song lyrics associated with media, or the song lyrics themselves. The song lyrics may be stored as text as in a song's entry in thecontent store 131 or in another database. - The
account store 133 contains account profiles of content server users. Theaccount store 133 may store the account profiles as entries in a database. An account profile includes information provided by a user of an account to the content server, including a user identifier, access credentials, and user preferences. The account profile may include a history of media experienced by the user, media uploaded by the user, or media included in search results from a user query to thecontent server 130, as well as records describing how the user engaged with experienced media. These engagement records may describe a rating provided by a user (e.g., numerical, like, dislike, or other qualitative rating), a share by the user (e.g., via a social network, email, or short message), or portions of the media presented to the user (and portions skipped by the user), for example. Therecommendation engine 137 uses the media in a user's history to provide more relevant song recommendations. Insofar as theaccount store 133 contains personal information provided by a user, a user's account profile includes privacy settings established by a user to control use and sharing of personal information by thecontent server 130. - The
web server 139 links thecontent server 130 via thenetwork 120 to theclient device 110. Theweb server 139 serves web pages, as well as other content, such as JAVA®, FLASH®, XML, and so forth. Theweb server 139 may receive uploaded content items from the one ormore client devices 110. Additionally, theweb server 139 communicates instructions from the content interface 125 for presenting media and for processing received input from a user of aclient device 110. Additionally, theweb server 139 may provide application programming interface (API) functionality to send data directly to an application native to a client device's operating system, such as IOS®, ANDROID™, or WEBOS®. - The
content interface module 134 generates a graphical user interface that a user interacts with through software and input devices (e.g., a touchscreen, a mouse) on theclient device 110. The user interface is provided to theclient device 110 through theweb server 139, which communicates with the software of theclient device 110 that presents the user interface. Through the user interface, the user accesses content server functionality including browsing, experiencing, and uploading media. The content interface may include a media player (e.g., a video player, an audio player, an image viewer) that presents content. Thecontent interface module 134 may display metadata associated with the media and retrieved from thecontent store 131. Example displayed metadata includes a title, upload data, an identifier of an uploading user, and content categorizations. Thecontent interface module 134 may incorporate a search interface for browsing content or a recommendation interface presenting song recommendations generated by therecommendation engine 137. - The
lyric analyzer 135 obtains song lyrics associated with songs and generates feature vectors quantifying characteristics of the song lyrics. Therecommendation engine 137 uses these feature vectors to generate song recommendations. A feature vector may be generated from an initial feature vector having more dimensions quantifying individual characteristics of the corresponding song lyric than the dimensions of the feature vector. Example characteristics of song lyrics include prevalence of rhymes, presence of particular words, emotional tone, rhyming structure, or musical structure. An initial feature vectors may be transformed with a dimensionality reduction to produce a corresponding feature vector. Reducing the number of dimensions beneficially increases computational efficiency of comparisons between feature vectors. Feature vectors may be stored in a song lyric corpus accessed by therecommendation engine 137. The song lyric corpus beneficially reduces processing time to generate a song recommendation by organizing song lyric data to facilitate retrieval of feature vectors corresponding to song lyrics similar to a seed lyric. Thelyric analyzer 135 is described in further detail with respect toFIG. 2A . - The
recommendation engine 137 obtains one or more seed songs and generates a song recommendation including other songs having similar song lyrics to seed lyrics of the one or more seed songs. Therecommendation engine 137 identifies candidate songs likely to have similar lyrics to the one or more seed songs. A seed song is associated with a seed feature vector quantifying characteristics of the seed lyrics, and the candidate songs are associated with candidate feature vectors quantifying characteristics of the candidate song's song lyrics. By comparing the candidate feature vectors to the seed feature vector (or a composite seed feature vector characterizing multiple seed songs), therecommendation engine 137 selects one or more of the candidate songs. For instance, therecommendation engine 137 compares the feature vectors by determining a measure of similarity between the seed feature vector and a candidate feature vector. The one or more of the selected songs may be included in a recommendation interface generated by therecommendation interface module 134 and provided to aclient device 110. Therecommendation engine 137 is described in further detail with respect toFIG. 2B . - The
network 120 enables communications among the entities connected thereto through one or more local-area networks and/or wide-area networks. The network 120 (e.g., the Internet) may use standard and/or custom wired and/or wireless communications technologies and/or protocols. The data exchanged over thenetwork 120 can be encrypted or unencrypted. Thenetwork 120 may include multiple sub-networks to connect theclient device 110 and thecontent server 130. Thenetwork 120 may include a content distribution network using geographically distributed data centers to reduce transmission times for media sent and received by thecontent server 130. -
FIG. 2A is a block diagram of anexample lyric analyzer 135, in accordance with an embodiment. Thelyric analyzer 135 includes alyric store 205, afeature generator 210, afeature reducer 215, alyric corpus generator 220, and asong lyric corpus 225. The functionality of thelyric analyzer 135 may be provided by additional, different, or fewer modules than those described herein. - The
lyric store 205 stores song lyrics associated with songs in thecontent store 131. Thelyrics store 205 may stores the song lyrics as text in corresponding entries of a database. Thecontent server 130 may obtain the song lyrics by analyzing audio content, analyzing user-transcribed lyrics, receiving the song lyrics from a content owner (e.g., an artist, recording label, or media company), or a combination thereof. For instance, thecontent server 130 obtains and reconciles user-generated transcriptions of song lyrics to correct inconsistencies between different versions of song lyrics. Alternatively or additionally, thecontent server 130 transcribes lyrics from audio content by filtering frequencies outside a human vocal range from song audio, identifying non-vocalized sounds based on timbre outside the human vocal range, and applying a text-to-speech algorithm to transcribe the remaining audio. Thecontent server 130 stores the resulting reconciled song lyrics in thelyric store 205. When song lyrics are provided by a content owner or other official source, these song lyrics may be used in place of user-transcribed or machine-transcribed song lyrics. - The
feature generator 210 accesses song lyrics in thelyric store 205 and generates feature vectors. A feature vector quantifies characteristics of a song lyric. The quantified characteristics are generally numerical in nature, such as a count (e.g., number of rhyming word pairs) or a binary indicator (e.g., whether rhyming words are present). Thefeature generator 210 combines the different quantifications of different characteristics as different dimensions of the feature vector. The feature vector may be generated in a particular format specifying an order of dimensions and corresponding characteristics. Other functionally equivalent representations of a feature vector include a key/value table, an n-tuple, an array, a matrix row or column, or any other grouping of numerical values. Particular characteristics encoded in the feature vector are described in further detail with respect toFIG. 3 . - The
feature reducer 215 obtains a feature vector generated by thefeature generator 210 and generates a dimensionally reduced feature vector from the initial feature vector. The feature vector generated by thefeature generator 210 may be referred to as an “initial feature vector,” and the feature vector generated by thefeature reducer 215 may be referred to as a “reduced feature vector.” Thefeature reducer 215 performs a dimensionality reduction algorithm to approximate the initial feature vector using fewer dimensions. In some dimensionality reduction algorithms, thefeature reducer 215 determines a transform to de-correlate a set of initial feature vectors and determines a measure of information represented within each dimension of the set of transformed feature vectors. A dimension of a transformed feature vector represents a combination of characteristics of the corresponding song lyrics, and the measure of information for the dimension indicates how much a combination of characteristics differentiates the song lyrics from other song lyrics. Thefeature reducer 215 ranks the transformed dimensions according to the corresponding measures of information and selects a subset of the transformed dimensions according to the ranking. The selected dimensions represent those combinations of characteristics that, in the aggregate, differentiate song lyrics from each other. Thefeature reducer 215 may select a pre-determined number of transformed dimensions or may determine a number of transformed dimensions to select so that a total measure of information in the selected dimensions equals or exceeds a threshold. - The
feature reducer 215 generates a reduced feature vector by applying the transform to an initial feature vector and by selecting the subset of transformed dimensions to form the reduced feature vector. Thefeature reducer 215 generates reduced feature vectors corresponding to the set of initial feature vectors used to determine the transform and stores the reduced feature vectors in thesong lyric corpus 225. To add an entry to thesong lyric corpus 225 corresponding to additional song lyrics not used to determine the transform, thefeature reducer 215 obtains an initial feature vector corresponding to the additional song lyrics and generates a corresponding reduced feature by applying the transform determined from the set of initial feature vectors. - For instance, the
feature reducer 215 may apply a dimensionality reduction algorithm such as a principal component analysis (PCA) transform to generate the reduced feature vector. Thefeature reducer 215 subtracts an average of the set of initial feature vectors to determine de-trended feature vectors, determines a covariance matrix of the de-trended feature vectors, and rotates the de-trended feature vectors into alignment with eigenvectors of the covariance matrix. The dimensions of the resulting rotated feature vectors no longer quantify individual characteristics of song lyrics but rather correspond to linear combinations of the quantified characteristics. The eigenvalue corresponding to a dimension of the rotated feature vectors is proportional to the variance represented in the dimension, so thefeature reducer 215 uses the eigenvalue of a dimension (normalized by the total sum of the eigenvalues) as the measure of information in the dimension of the rotated feature vectors. Thefeature reducer 215 then selects a subset of the dimensions of the rotated feature vector to generate the reduced feature vector. As another example, thefeature reducer 215 applies a different linear dimensionality reduction algorithm than PCA or applies a non-linear dimensionality reduction algorithm to project the initial feature vector onto a hyperplane or other manifold having fewer dimensions than the initial feature vector. - The
lyric corpus generator 220 obtains feature vectors (e.g., reduced features vector from thefeature reducer 215 or initial feature vectors from the feature generator 210) and generates thesong lyric corpus 225 to store the feature vectors. Thelyric corpus generator 220 may also insert, modify, or delete a feature vector from thesong lyric corpus 225. For example, a newly released song is uploaded to thecontent server 130, thefeature generator 210 generates an initial feature vector, thefeature reducer 215 generates a reduced feature vector, and thelyric corpus generator 220 adds the reduced feature vector to thesong lyric corpus 225. Feature vectors stored in thesong lyric corpus 225 may be initial feature vectors or reduced feature vectors. - The
lyric corpus generator 220 may generate thesong lyric corpus 225 as a structure that facilitates identification of feature vectors similar to a seed feature vector. In one embodiment thelyric corpus generator 220 generates thesong lyric corpus 225 as a k-dimensional tree (k-d tree) having nodes corresponding to feature vectors arranged in a branched tree structure. A layer of the k-d tree corresponds to a particular dimension of the feature vectors. Different branches from a node in a layer correspond to different ranges in the value of the dimension corresponding to the layer. For example, a node corresponding to a feature vector has two branches, and the node is in a layer of the k-d tree corresponding to a third dimension of the feature vectors, so the value of the third dimension of the feature vector corresponding to the node is used as a threshold value. In the example, one branch from the node includes feature vectors having a value in the third dimension exceeding the threshold value, and the other branch from the node includes feature vectors having a value in the third dimension not exceeding the threshold value. The resulting k-d tree may be accessed to find feature vectors similar to a seed vector without comparing the seed vector to every feature vector in thesong lyric corpus 225. - In some embodiments, the
lyric corpus generator 220 generates thesong lyric corpus 225 as a structure to enable identification of similar feature vectors without guaranteeing retrieval of the feature vector most similar to the seed vector. For instance, thelyric corpus generator 220 generates thesong lyric corpus 225 as one or more hashing tables indicating outputs of one or more locality-sensitive hash (LSH) functions. An LSH function deterministically maps an input to an output. In contrast to cryptographic hash functions, LSH functions have a limited number of outputs to increase the probability of hashing collisions. To take advantage of this, in one embodiment thelyric corpus generator 220 creates a hashing table including an entry for each feature vector indicating the output from an LSH function given the feature vector as input. Thelyric corpus generator 220 may also generate an inverse hashing table identifying the feature vectors (and corresponding song lyrics) that correspond to a given output of the LSH function. Those feature vectors having a same output from the LSH function make up a bucket of feature vectors likely to be similar to each other. Using LSH functions reduces the dimensionality of the feature vectors, thereby obviating thefeature reducer 215. -
FIG. 2B is a block diagram of anexample recommendation engine 137, in accordance with an embodiment. Therecommendation engine 137 obtains one or more seed songs and generates a song recommendation including at least one song having song lyrics similar to seed lyrics of the one or more seed songs. The obtained seed song may be a song the user has watched as part of a video, a song identified based on a corresponding user search, or a song the user has engaged, for example. Therecommendation engine 137 selects the song to recommend according to a measure of similarity between a seed feature vector quantifying characteristics of the one or more seed songs' seed lyrics and a feature vector corresponding to song lyrics to the selected song. Therecommendation engine 137 includes a seedfeature vector provider 227, alyric selector 230, asimilarity evaluator 235, and arecommendation generator 240. The functionality of therecommendation engine 137 may include additional, different, or fewer modules than those described herein. - The seed
feature vector provider 227 accesses a user's account profile from theaccount store 133 and obtains a seed feature vector for recommending songs to the user. From theaccount store 133, theseed vector provider 227 obtains songs associated with the user, including songs experienced by the user, songs uploaded by the user, or songs included in search results from a user query to thecontent server 130. The songs associated with the user may include songs identified by another song recommendation algorithm (e.g., collaborative filtering). From the songs associated with the user, theseed vector provider 227 selects a seed song. For example, the seed song is a song the user is currently streaming from thecontent server 130. The seedfeature vector provider 227 accesses the seed feature vector corresponding to the selected seed song from thesong lyric corpus 225 and provides the seed feature vector to thelyric selector 230. Alternatively to accessing the seed feature vector, the seedfeature vector provider 227 generates the seed feature vector according to the process described with respect to thefeature generator 210 and/or thefeature reducer 215. - In some embodiments, the seed
feature vector provider 227 selects multiple seed songs and obtains a composite seed feature vector characterizing a composite of the seed songs. For example, the seed songs are a number of songs the user has watched most recently or has experienced most frequently within a threshold duration of a current time (i.e., time of generating the recommendation). The seedfeature vector provider 227 accesses (or generates) seed feature vectors corresponding to the selected seed songs and combines the seed feature vectors to determine a composite seed feature vector. The seedfeature vector provider 227 may determine the composite seed feature vector from a measure of central tendency (e.g., mean, median, mode) of the seed song vectors or a weighted combination of the seed song vectors. For example, the seed song vectors are weighted according to the songs' overall popularity, number of streams by the user, or number of engagements by the user. - In some embodiments, the seed
feature vector provider 227 selects one or more seed songs from the songs associated with a user by clustering the songs associated with the user according to one or more variables describing the user's session (e.g., time, location, client device type, client device operating system, client device browser, network connection speed, network connection type) when experiencing the songs. One or more variables describing the user's current session are obtained, and the seedfeature vector provider 227 selects songs in a cluster corresponding to the variables describing the user's current session. For example, the seedfeature vector provider 227 identifies distinct clusters of songs associated with (1) songs provided to the user's mobile device while commuting through multiple locations in the morning, (2) songs provided to the user's desktop at a work location in the afternoon, and (3) songs provided to the user's laptop at a home location during the evening. In the example, the seedfeature vector provider 227 obtains variables describing the user's current session and indicating that the user is currently experiencing songs on the user's laptop at the home location during the evening, so the seedfeature vector provider 227 selects one or more seed songs from the corresponding cluster (3). The seedfeature vector provider 227 accesses (or generates) one or more seed feature vectors corresponding to the selected one or more songs, combines them (if necessary) into a composite seed feature vector, and provides the composite seed feature vector to thelyric selector 230. - The
lyric selector 230 obtains a seed feature vector from the seedfeature vector provider 227 and selects one or more songs having song lyrics similar to those of the one or more seed songs according to a measure of similarity between the seed feature vector and a feature vector corresponding to song lyrics of the selected one or more songs. Thelyric selector 230 identifies candidate feature vectors, which are a subset of feature vectors in thesong lyric corpus 225 expected to have a higher measure of similarity to the seed feature vector than other feature vectors in thesong lyric corpus 225. For example, thesong lyric corpus 225 includes one or more LSH hash tables, and thelyric selector 230 identifies candidate feature vectors from feature vectors having an LSH hash output value matching the LSH output value of the seed vector in one or more of the LSH hash tables. Alternatively to identifying a subset of feature vectors in thesong lyric corpus 225 as candidate feature vectors, thelyric selector 230 includes all the feature vectors in thesong lyric corpus 225 as candidate feature vectors. - The
lyric selector 230 ranks the candidate feature vectors according to measures of similarity determined between the seed feature vector and each candidate feature vector. Thelyric selector 230 selects a number of songs according to the ranking of their respective candidate feature vectors. The number of songs selected may be a pre-determined number (e.g., a number of recommended songs to appear in a user interface) or may be determined from the number of candidate feature vectors having a measure of similarity equaling or exceeding a threshold measure of similarity. - In some embodiments, the
lyric selector 230 may identify, rank, and select candidate feature vectors simultaneously. For example, as thesong lyric selector 230 identifies the candidate feature vectors, thesong lyric selector 230 compares each identified candidate feature vector to a “best match” candidate feature vector. If the measure of similarity between the identified candidate feature vector and the seed feature vector equals or exceeds the measure of similarity between the best match candidate vector and the seed feature vector, then the identified candidate feature vector replaces the current best match candidate feature vector as the best match candidate feature vector. Once the search for candidate feature vectors is complete, thelyric selector 230 selects the remaining best match candidate feature vector for use in the recommendation. - For example, the
song lyric corpus 225 is a k-d tree, and thelyric selector 230 identifies the candidate feature vectors by performing a nearest neighbor search of the k-d tree. To perform the nearest neighbor search, thelyric selector 230 traverses nodes corresponding to the candidate feature vectors. The traversed nodes include the root node of the k-d tree and nodes between the root node and a node representing the seed feature vector. Thelyric selector 230 traverses nodes in other branches of the k-d tree and determines whether to traverse farther down those branches according to the measure of similarity between candidate feature vectors at root nodes of the other branches and the seed feature vector. If the measure of similarity for the node of a branch equals or exceeds the measure of similarities for previously traversed nodes, thelyric selector 230 traverses additional nodes in the other branch to identify additional candidate feature vectors. - The
similarity evaluator 235 accesses a seed feature vector and a candidate feature vector from thesong lyric corpus 225 and determines a measure of similarity between the seed feature vector and the candidate feature vector. The measure of similarity increases as the difference decreases between corresponding dimensions of the seed feature vector and the candidate feature vector. As used herein, “similarity” between first and second song lyrics may be determined according to the measure of similarity between first and second feature vectors corresponding to the first and second song lyrics. As one example, the measure of similarity may be the cosine similarity. The measure of similarity may be determined from a measure of dissimilarity such as the L2 norm (Cartesian distance) or L1 norm (Manhattan distance). As another example, the measure of similarity may be the inverse of the Cartesian distance between the candidate feature vector and the seed feature vector. Alternatively to accessing the seed feature vector and the candidate feature vector in thesong lyric corpus 225, thesimilarity evaluator 235 may obtain either or both feature vectors from thefeature generator 210 and/or thefeature reducer 215. - The
recommendation generator 240 obtains one or more songs selected by thelyric selector 230 and generates a song recommendation. The generated recommendation may include a subset of the selected songs or may include all the subset of selected songs. The songs selected by thelyric selector 230 may be filtered according to preferences of the user's account profile. Therecommendation generator 240 may rank the selected songs according to a user's likelihood of engagement with the song. Therecommendation generator 240 may include in the ranking additional songs or other media identified according to additional recommendation techniques (e.g., collaborative filtering). Therecommendation generator 240 selects songs according to the ranking and generates a song recommendation including the selected songs. Thecontent interface module 134 incorporates the song recommendation into a user interface (e.g., as a sidebar of a video player) and provides the song recommendation to theclient device 110 associated with the user. -
FIG. 3 is a block diagram of anexample feature generator 210, in accordance with an embodiment. Thefeature generator 210 generates feature vectors for a song quantifying characteristics of the song. Thefeature generator 210 generates feature vectors including dimensions that quantify characteristics of song lyrics, but the generated feature vectors may also include dimensions quantifying other properties of a song such as musical properties (e.g., tempo, tonality, instrumentation), visual properties (e.g., brightness, number of intra-coded frames), other song metadata (e.g., song length, song data size), or characteristics of users experiencing a song (e.g., average and total number of times users have experienced a song, demographic characteristics). Thefeature generator 210 includes aword feature module 311, aterm feature module 312, aline feature module 313, acharacter feature module 314, anaffective feature module 315, arhyme feature module 316, and astructural feature module 317. Thefeature generator 210 may include additional, different, or fewer modules than those described herein. - The
word feature module 311 obtains song lyrics and determines values for a dimension of the feature vector that quantifies words in the song lyrics. A dimension of the feature vector generated by theword feature module 311 may correspond to a total number (e.g., total words, total unique words), a normalized total (e.g., total unique words per total words), or a measure of central tendency (e.g., average word length in syllables or characters, average word difficulty, average word rarity). A measure of central tendency includes an average, mean, median or mode. The rarity of a word may be determined based on a logarithm of frequency of the word among lyrics in thelyric store 205 or in an external database (e.g., the Brown University Standard Corpus of Present-Day American English). The feature vector may include a dimension corresponding to the presence of a particular word or a number of instances of a particular word (e.g., number of instances of an obscenity). - The
term feature module 312 obtains song lyrics and determines values for a dimension of the feature vector that quantifies terms in the song lyrics. A term is a group of one or more words having distinct semantic meaning (i.e., a phrase). A dimension of the feature vector generated by theterm feature module 312 may correspond to a total number (e.g., total terms, total unique terms), a normalized total (e.g., total unique terms per total words), or a measure of central tendency (e.g., average term length, average term rarity). The rarity of a term may be determined based on a logarithm of frequency (i.e. song lyrics containing the word per total number of song lyrics) of the term among lyrics in thelyric store 205. The feature vector may include a dimension corresponding to the presence of a particular term or a number of instances of a particular term. - The
term feature module 312 may determine the term frequency-inverse document frequency (TF-IDF) of a particular term for inclusion as a dimension of the feature vector. Theterm feature module 312 determines the TF-IDF from the term frequency of the term in the song relative to total words (or total terms) in the song lyric. Theterm feature module 312 determines the inverse document frequency from the order of magnitude (e.g., logarithm) of the total number of lyrics in thelyric store 205 normalized by the number of lyrics in thelyric store 205 containing the term. In other words, the TF-IDF is normalized by the prevalence of the term. - The
line feature module 313 obtains song lyrics and determines values for a dimension of the feature vector that quantifies lines in the song lyrics. A line of a song lyric indicates a rhythmic or other break and is typically indicated by a line break in song lyric text. A dimension of the feature vector generated by theline feature module 313 may correspond to a total number (e.g., total lines, total unique lines), a normalized total (e.g., total unique lines per total lines or per total words), or a measure of central tendency (e.g., average words per line, average unique words per line, average unique words per unique line). - The
character feature module 314 obtains song lyrics and generates features quantifying characters in the song lyrics. Characters refer to letters, numbers, or punctuation in song lyrics. A dimension of the feature vector generated by thecharacter feature module 314 may quantify occurrences of a particular character (e.g., a total number of exclamation points, total number of numerical digits, average number of punctuation marks per total words in lyric) or instances of consecutive characters (e.g., total number of occurrences of three consecutive question marks, average number of occurrence of consecutive characters per total words in lyric). - The
affective feature module 315 obtains song lyrics and determines values for a dimension of the feature vector that indicates an affective rating of the song lyrics. An affective rating quantifies emotional content evoked by a word or set of words. Example affective ratings of a word include valence (i.e., pleasantness), arousal (i.e., intensity), and dominance (i.e., control). Theaffective feature module 315 obtains affective ratings corresponding to individual terms (or words) in song lyrics and determines an overall affective rating of the song lyric according to the number of occurrences of the term and the corresponding affective rating. For example, the total affective rating is an inner product of a vector indicating the affective rating of individual words and a vector indicating the number of instances (or length-normalized instances) of the word in the song lyric. The feature vector may include one or more dimensions including different total affective ratings. - The
rhyme feature module 316 obtains song lyrics and determines values for a dimension of the feature vector that quantifies rhymes in the song lyrics. Therhyme feature module 316 obtains phonemes of the words in the song lyric from a pronunciation database and identifies pairs (or sets) of rhyming words. Words rhyme when the phonemes in their respective last syllables at least partially match. Therhyme feature module 316 may also identify sets of rhyming lines that end in rhyming last words. A dimension of a feature vector may quantify rhymes using total numbers (e.g., total rhyming words, total sets of rhyming words, number of rhyming lines, number of sets of rhyming lines) as well as measures of central tendency (e.g., rhyming words per word length, rhyming words per line, rhyming lines per total lines). - The
structural feature module 317 obtains song lyrics and determines values for a dimension of the feature vector that quantifies structures in the song lyrics. Structures in song lyrics are multi-line patterns. Thestructural feature module 317 may identify rhyme-based structures following a rhyming line pattern. For example, different rhyming line patterns include AA, AABB, ABAB, and ABBA, where A refers to lines ending with words in a first set of rhyming words and B refers to lines ending with words in a second set of rhyming words. Feature vectors may have a dimension indicating a number of each type of rhyming line pattern. - The
structural feature module 317 may identify parts of a song such as verses, choruses, refrains, and bridges. Parts of a song may be identified based on paragraph breaks in song lyric text, repetition of large blocks of lines, and number of lines between paragraph breaks. Feature vectors may have a dimension indicating a number of a particular type of part (e.g., number of verses, number of unique verses) or indicating the presence of a type of part (e.g., presence of a bridge). -
FIG. 4 is a flowchart illustrating an example process for generating asong lyric corpus 225, in accordance with an embodiment. Thelyric analyzer 135 may generate thesong lyric corpus 225 for later access by therecommendation engine 137. Generating thesong lyric corpus 225 prior to receiving a request for a song recommendation reduces the time to provide a song recommendation by reducing computations after the time of the request. Furthermore, the structure of thesong lyric corpus 225 may facilitate identifying song lyrics similar to the seed lyrics (e.g., when the structure is a k-d tree or an LSH hash table). - The
lyric analyzer 135 accesses 410 candidate song lyrics of candidate songs from thelyrics store 205. Thefeature generator 210 generates 420 initial feature vectors having a number of dimensions, where each dimension quantifies a different characteristic of the candidate song lyrics. Thefeature reducer 215 generates 430 candidate feature vectors having fewer dimensions than the initial feature vector by applying a dimensionality reduction algorithm to the initial feature vectors. Thelyric corpus generator 220 generates 440 a structure representing the reduced candidate feature vectors and stores 450 the structure as thesong lyric corpus 225. - The process described herein may be performed in a different order or using different, fewer, or additional steps. For example, steps described as being performed sequentially may be performed in parallel. The
lyric analyzer 135 is described as generating feature vectors prior to generating a song recommendation, but thelyric analyzer 135 may instead generate feature vectors in response to receiving a seed song used to generate the song recommendation. In other words, feature vectors may be generated for use by therecommendation engine 135 without being stored in thesong lyric corpus 225. -
FIG. 5 is a flowchart illustrating an example process for recommending a song, in accordance with an embodiment. Therecommendation engine 137 obtains 510 a seed song associated with a seed lyric. The seed song associated with aclient device 110. For instance, the seed song is a video provided to theclient device 110 within a threshold amount time before a current time. Thelyric selector 230 accesses 520 a seed feature vector characterizing the seed lyric (e.g., from the song lyric corpus 225). Thelyric selector 230 accesses 530 candidate feature vectors characterizing candidate song lyrics of candidate songs stored in thesong lyric corpus 225. The candidate feature vectors accessed may be from an identified subset of feature vectors in thesong lyric corpus 225 to beneficially reduce a number of comparisons between the seed feature vector and the candidate feature vectors. Thelyric selector 230 selects 540 a candidate song according to a measure of similarity between the seed feature vector and a candidate feature vector determined by thesimilarity evaluator 235. Therecommendation generator 240 generates 550 a song recommendation including the selected candidate song. - The
interface module 235 provides 560 the song recommendation to theclient device 110. Providing 560 the song recommendation refers to including the song recommendation in a user interface provided to theclient device 110. For example, thecontent interface module 134 displays the song recommendation alongside a media player while a song plays or in the media player while or after the song plays, where the song is the seed song used to generate the song recommendation. As another example, thecontent interface module 134 presents the song recommendation as audio at the end of a seed song used to generate the song recommendation. As a third example, thecontent interface module 134 generates a stream or web page displaying song recommendations generated from seed songs that the user has recently experienced. - The process described herein may be performed in a different order or using different, fewer, or additional steps. For example, steps described as being performed sequentially may be performed in parallel. The
recommendation engine 137 is described as accessing pre-computed feature vectors in thesong lyric corpus 225, but the feature vectors may instead be computed in response to receiving a seed song used to generate a song recommendation. - The
client device 110 and thecontent server 130 are each implemented using computers.FIG. 6 is a level block diagram illustrating anexample computer 600 usable to implement entities of the content sharing environment, in accordance with one embodiment. Theexample computer 600 has sufficient memory, processing capacity, network connectivity bandwidth, and other computing resources to provide song recommendations as described herein. - The
computer 600 includes at least one processor 602 (e.g., a central processing unit, a graphics processing unit) coupled to achipset 604. Thechipset 604 includes amemory controller hub 620 and an input/output (I/O)controller hub 622. Amemory 606 and agraphics adapter 612 are coupled to thememory controller hub 620, and adisplay 618 is coupled to thegraphics adapter 612. Astorage device 608,keyboard 610, pointingdevice 614, andnetwork adapter 616 are coupled to the I/O controller hub 622. Other embodiments of thecomputer 600 have different architectures. - The
storage device 608 is a non-transitory computer-readable storage medium such as a hard drive, compact disk read-only memory (CD-ROM), DVD, or a solid-state memory device. Thememory 606 holds instructions and data used by theprocessor 602. Theprocessor 602 may include one ormore processors 602 having one or more cores that execute instructions. Thepointing device 614 is a mouse, touch-sensitive screen, or other type of pointing device, and in some instances is used in combination with thekeyboard 610 to input data into thecomputer 600. Thegraphics adapter 612 displays media and other images and information on thedisplay 618. Thenetwork adapter 616 couples thecomputer 600 to one or more computer networks (e.g., network 120). - The
computer 600 is adapted to execute computer program modules for providing functionality described herein including presenting media, playlist lookup, and/or metadata generation. As used herein, the term “module” refers to computer program logic used to provide the specified functionality. Thus, a module can be implemented in hardware, firmware, and/or software. In one embodiment of acomputer 600 that implements thecontent server 130, program modules such as thelyric analyzer 135 and therecommendation engine 137 are stored on thestorage device 608, loaded into thememory 606, and executed by theprocessor 602. - The types of
computers 600 used by the entities of the content sharing environment can vary depending upon the embodiment and the processing power required by the entity. For example, theclient device 110 is a smart phone, tablet, laptop, or desktop computer. As another example, thecontent server 130 might comprise multiple blade servers working together to provide the functionality described herein. Thecomputers 600 may contain duplicates of some components or may lack some of the components described above (e.g., akeyboard 610, agraphics adapter 612, apointing device 614, a display 618). For example, thecontent server 130 run in asingle computer 600 ormultiple computers 600 communicating with each other through a network such as in a server farm. - Some portions of above description describe the embodiments in terms of algorithms and symbolic representations of operations on information. These algorithmic descriptions and representations are commonly used by those skilled in the data processing arts to convey the substance of their work effectively to others skilled in the art. These operations, while described functionally, computationally, or logically, are understood to be implemented by computer programs or equivalent electrical circuits, microcode, or the like. To implement these operations, the
content server 130 may use a non-transitory computer-readable medium that stores the operations as instructions executable by one or more processors. Any of the operations, processes, or steps described herein may be performed using one or more processors. Furthermore, it has also proven convenient at times, to refer to these arrangements of operations as modules, without loss of generality. The described operations and their associated modules may be embodied in software, firmware, hardware, or any combinations thereof. - As used herein any reference to “one embodiment” or “an embodiment” means that a particular element, feature, structure, or characteristic described in connection with the embodiment is included in at least one embodiment. The appearances of the phrase “in one embodiment” in various places in the specification are not necessarily all referring to the same embodiment.
- As used herein, the terms “comprises,” “comprising,” “includes,” “including,” “has,” “having” or any other variation thereof, are intended to cover a non-exclusive inclusion. For example, a process, method, article, or apparatus that comprises a list of elements is not necessarily limited to only those elements but may include other elements not expressly listed or inherent to such process, method, article, or apparatus. Further, unless expressly stated to the contrary, “or” refers to an inclusive or and not to an exclusive or. For example, a condition A or B is satisfied by any one of the following: A is true (or present) and B is false (or not present), A is false (or not present) and B is true (or present), and both A and B are true (or present).
- In addition, use of the “a” or “an” are employed to describe elements and components of the embodiments herein. This is done merely for convenience and to give a general sense of the embodiments. This description should be read to include one or at least one and the singular also includes the plural unless it is obvious that it is meant otherwise.
- Additional alternative structural and functional designs may be implemented for a system and a process for a recommending a song. Thus, while particular embodiments and applications have been illustrated and described, it is to be understood that the disclosed embodiments are not limited to the precise construction and components disclosed herein. Various modifications, changes and variations may be made in the arrangement, operation and details of the method and apparatus disclosed herein without departing from the spirit and scope defined in the appended claims.
Claims (20)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/701,275 US20180357548A1 (en) | 2015-04-30 | 2015-04-30 | Recommending Media Containing Song Lyrics |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/701,275 US20180357548A1 (en) | 2015-04-30 | 2015-04-30 | Recommending Media Containing Song Lyrics |
Publications (1)
Publication Number | Publication Date |
---|---|
US20180357548A1 true US20180357548A1 (en) | 2018-12-13 |
Family
ID=64562398
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US14/701,275 Abandoned US20180357548A1 (en) | 2015-04-30 | 2015-04-30 | Recommending Media Containing Song Lyrics |
Country Status (1)
Country | Link |
---|---|
US (1) | US20180357548A1 (en) |
Cited By (13)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20190066641A1 (en) * | 2017-08-31 | 2019-02-28 | Spotify Ab | Lyrics analyzer |
CN110162664A (en) * | 2018-12-17 | 2019-08-23 | 腾讯科技（深圳）有限公司 | Video recommendation method, device, computer equipment and storage medium |
US20190332849A1 (en) * | 2018-04-27 | 2019-10-31 | Microsoft Technology Licensing, Llc | Detection of near-duplicate images in profiles for detection of fake-profile accounts |
CN110769288A (en) * | 2019-11-08 | 2020-02-07 | 杭州趣维科技有限公司 | Video cold start recommendation method and system |
US20200089675A1 (en) * | 2014-04-04 | 2020-03-19 | Fraunhofer-Gesellschaft | Methods and apparatuses for iterative data mining |
US20210174208A1 (en) * | 2018-01-31 | 2021-06-10 | Pure Storage, Inc. | Search acceleration for artificial intelligence |
CN113127674A (en) * | 2019-12-31 | 2021-07-16 | 中移(成都)信息通信科技有限公司 | Singing bill recommendation method and device, electronic equipment and computer storage medium |
CN113158022A (en) * | 2021-01-29 | 2021-07-23 | 北京达佳互联信息技术有限公司 | Service recommendation method, device, server and storage medium |
US20220269723A1 (en) * | 2017-05-25 | 2022-08-25 | Microsoft Technology Licensing, Llc | Song similarity determination |
WO2022196973A1 (en) * | 2021-03-19 | 2022-09-22 | 주식회사 카카오엔터테인먼트 | Method and apparatus for recommending music content |
US20220345758A1 (en) * | 2021-04-23 | 2022-10-27 | At&T Intellectual Property I, L.P. | System and method for identifying encrypted, pre-recorded media content in packet data networks |
US11500816B2 (en) * | 2019-03-12 | 2022-11-15 | Citrix Systems, Inc. | Intelligent file recommendation engine |
WO2024001548A1 (en) * | 2022-07-01 | 2024-01-04 | 北京字跳网络技术有限公司 | Song list generation method and apparatus, and electronic device and storage medium |
Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20030205124A1 (en) * | 2002-05-01 | 2003-11-06 | Foote Jonathan T. | Method and system for retrieving and sequencing music by rhythmic similarity |
US6996575B2 (en) * | 2002-05-31 | 2006-02-07 | Sas Institute Inc. | Computer-implemented system and method for text-based document processing |
US8819043B2 (en) * | 2010-11-09 | 2014-08-26 | Microsoft Corporation | Combining song and music video playback using playlists |
-
2015
- 2015-04-30 US US14/701,275 patent/US20180357548A1/en not_active Abandoned
Patent Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20030205124A1 (en) * | 2002-05-01 | 2003-11-06 | Foote Jonathan T. | Method and system for retrieving and sequencing music by rhythmic similarity |
US6996575B2 (en) * | 2002-05-31 | 2006-02-07 | Sas Institute Inc. | Computer-implemented system and method for text-based document processing |
US8819043B2 (en) * | 2010-11-09 | 2014-08-26 | Microsoft Corporation | Combining song and music video playback using playlists |
Non-Patent Citations (5)
Title |
---|
Eric Brochu and Nando de Freitas, ""Name That Song!": A Probabilistic Approach to Querying on Music and Text", 1 January 2002, NIPS'02 Proceedings of the 15th International Conference on Neural Information Processing Systems, pgs. 1-8. * |
Menno van Zaanen and Pieter Kanters, "Automatic Mood Classification Using TF*IDF Based Lyrics", 2010, 11th International Society for Music Information Retrieval Conference (ISMIR 2010), pgs. 75-80. * |
Robert Neumayer and Andreas Rauber, "Integration of Text and Audio Features for Genre Classification in Music Information Retrieval", 2007, Springer-Verlag Berlin Heidelberg, pgs. 724-727. * |
Rudolf Mayer, Robert Neumayer, and Andreas Rauber, "Rhyme and Style Features for Musical Genre Classification by Song Lyrics", 2008, ISMIR 2008, pgs. 337-342. * |
Yunqing Xia, Linlin Wang, Kam-Fai Wong, and Mingxing Xu, "Sentiment Vector Space Model for Lyric-based Song Sentiment Classification", June 2008, Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pgs. 133-136. * |
Cited By (20)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20200089675A1 (en) * | 2014-04-04 | 2020-03-19 | Fraunhofer-Gesellschaft | Methods and apparatuses for iterative data mining |
US20220269723A1 (en) * | 2017-05-25 | 2022-08-25 | Microsoft Technology Licensing, Llc | Song similarity determination |
US10510328B2 (en) * | 2017-08-31 | 2019-12-17 | Spotify Ab | Lyrics analyzer |
US10770044B2 (en) | 2017-08-31 | 2020-09-08 | Spotify Ab | Lyrics analyzer |
US10957290B2 (en) | 2017-08-31 | 2021-03-23 | Spotify Ab | Lyrics analyzer |
US11636835B2 (en) | 2017-08-31 | 2023-04-25 | Spotify Ab | Spoken words analyzer |
US20190066641A1 (en) * | 2017-08-31 | 2019-02-28 | Spotify Ab | Lyrics analyzer |
US11966841B2 (en) * | 2018-01-31 | 2024-04-23 | Pure Storage, Inc. | Search acceleration for artificial intelligence |
US20210174208A1 (en) * | 2018-01-31 | 2021-06-10 | Pure Storage, Inc. | Search acceleration for artificial intelligence |
US20190332849A1 (en) * | 2018-04-27 | 2019-10-31 | Microsoft Technology Licensing, Llc | Detection of near-duplicate images in profiles for detection of fake-profile accounts |
US11074434B2 (en) * | 2018-04-27 | 2021-07-27 | Microsoft Technology Licensing, Llc | Detection of near-duplicate images in profiles for detection of fake-profile accounts |
CN110162664A (en) * | 2018-12-17 | 2019-08-23 | 腾讯科技（深圳）有限公司 | Video recommendation method, device, computer equipment and storage medium |
US11500816B2 (en) * | 2019-03-12 | 2022-11-15 | Citrix Systems, Inc. | Intelligent file recommendation engine |
CN110769288A (en) * | 2019-11-08 | 2020-02-07 | 杭州趣维科技有限公司 | Video cold start recommendation method and system |
CN113127674A (en) * | 2019-12-31 | 2021-07-16 | 中移(成都)信息通信科技有限公司 | Singing bill recommendation method and device, electronic equipment and computer storage medium |
CN113158022A (en) * | 2021-01-29 | 2021-07-23 | 北京达佳互联信息技术有限公司 | Service recommendation method, device, server and storage medium |
WO2022196973A1 (en) * | 2021-03-19 | 2022-09-22 | 주식회사 카카오엔터테인먼트 | Method and apparatus for recommending music content |
US20220345758A1 (en) * | 2021-04-23 | 2022-10-27 | At&T Intellectual Property I, L.P. | System and method for identifying encrypted, pre-recorded media content in packet data networks |
US11665377B2 (en) * | 2021-04-23 | 2023-05-30 | At&T Intellectual Property I, L.P. | System and method for identifying encrypted, pre-recorded media content in packet data networks |
WO2024001548A1 (en) * | 2022-07-01 | 2024-01-04 | 北京字跳网络技术有限公司 | Song list generation method and apparatus, and electronic device and storage medium |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US20180357548A1 (en) | Recommending Media Containing Song Lyrics | |
US11151145B2 (en) | Tag selection and recommendation to a user of a content hosting service | |
US20200334496A1 (en) | Systems and methods for identifying semantically and visually related content | |
US10152517B2 (en) | System and method for identifying similar media objects | |
WO2018072071A1 (en) | Knowledge map building system and method | |
US11157542B2 (en) | Systems, methods and computer program products for associating media content having different modalities | |
US8380727B2 (en) | Information processing device and method, program, and recording medium | |
US11301528B2 (en) | Selecting content objects for recommendation based on content object collections | |
US7849092B2 (en) | System and method for identifying similar media objects | |
Saari et al. | Semantic computing of moods based on tags in social media of music | |
US20140074269A1 (en) | Method for Recommending Musical Entities to a User | |
Hopfgartner et al. | Semantic user profiling techniques for personalised multimedia recommendation | |
US20200278997A1 (en) | Descriptive media content search from curated content | |
US20220222294A1 (en) | Densification in Music Search and Recommendation | |
US20150160847A1 (en) | System and method for searching through a graphic user interface | |
JP2018073429A (en) | Retrieval device, retrieval method, and retrieval program | |
JP5367872B2 (en) | How to provide users with selected content items | |
Wang et al. | Tag-based personalized music recommendation | |
US20180349372A1 (en) | Media item recommendations based on social relationships | |
Li et al. | Query-document-dependent fusion: A case study of multimodal music retrieval | |
Pollacci et al. | The italian music superdiversity: Geography, emotion and language: one resource to find them, one resource to rule them all | |
Chen et al. | Cold-start playlist recommendation with multitask learning | |
Wu | Research on Product Design Strategy Based on User Preference and Machine Learning Intelligent Recommendation | |
US20130325846A1 (en) | Latent collaborative retrieval | |
Hosanagar et al. | AI in Personalized Product Recommendations |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:NICHOLS, ERIC PAUL;SONG, YADING;ZHAO, JUSTIN;SIGNING DATES FROM 20150512 TO 20150702;REEL/FRAME:035974/0127 |
|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:NICHOLS, ERIC PAUL;SONG, YADING;ZHAO, JUSTIN;SIGNING DATES FROM 20170803 TO 20170807;REEL/FRAME:043214/0308 |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044567/0001Effective date: 20170929 |
|
STCB | Information on status: application discontinuation |
Free format text: ABANDONED -- FAILURE TO RESPOND TO AN OFFICE ACTION |