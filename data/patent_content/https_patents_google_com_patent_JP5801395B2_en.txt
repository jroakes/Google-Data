JP5801395B2 - Automatic media sharing via shutter click - Google Patents
Automatic media sharing via shutter click Download PDFInfo
- Publication number
- JP5801395B2 JP5801395B2 JP2013521938A JP2013521938A JP5801395B2 JP 5801395 B2 JP5801395 B2 JP 5801395B2 JP 2013521938 A JP2013521938 A JP 2013521938A JP 2013521938 A JP2013521938 A JP 2013521938A JP 5801395 B2 JP5801395 B2 JP 5801395B2
- Authority
- JP
- Japan
- Prior art keywords
- user
- content data
- images
- image
- media
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/50—Information retrieval; Database structures therefor; File system structures therefor of still image data
- G06F16/58—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually
- G06F16/583—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using metadata automatically derived from the content
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q50/00—Systems or methods specially adapted for specific business sectors, e.g. utilities or tourism
- G06Q50/10—Services
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/40—Information retrieval; Database structures therefor; File system structures therefor of multimedia data, e.g. slideshows comprising image and additional audio data
- G06F16/43—Querying
- G06F16/435—Filtering based on additional data, e.g. user or group profiles
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/24—Querying
- G06F16/245—Query processing
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/50—Information retrieval; Database structures therefor; File system structures therefor of still image data
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L63/00—Network architectures or network communication protocols for network security
- H04L63/10—Network architectures or network communication protocols for network security for controlling access to devices or network resources
Description
本開示は、概して、写真およびビデオを含むデジタルメディアの分野に関し、より具体的には、ユーザ間のデジタルメディアの共有に関する。 The present disclosure relates generally to the field of digital media, including photography and video, and more specifically to sharing digital media between users.
デジタル画像捕捉技術の進歩は、現在では、ユーザが、写真およびビデオを含むデジタルメディアを迅速かつ便利に捕捉することを可能にする。加えて、モバイルデバイスにおけるデジタルカメラの統合、デジタルメディア用の安価な記憶装置、およびインターネットを通したネットワーク接続等の革新は、ユーザが、任意の場所からデジタルメディアを捕捉し、それを他のユーザと共有することを可能にする。 Advances in digital image capture technology now allow users to quickly and conveniently capture digital media including photos and videos. In addition, innovations such as digital camera integration in mobile devices, inexpensive storage for digital media, and network connectivity over the Internet allow users to capture digital media from anywhere and share it with other users. To share with.
デジタルメディアの共有は、典型的には、ユーザのコンピュータデバイス上で作動するブラウザまたは他のアプリケーションを使用して、例えば、ＰｉｃａｓａおよびＰｉｃａｓａ Ｗｅｂ Ａｌｂｕｍｓ等のメディア共有ウェブサイトへユーザがメディアをアップロードすることを伴う。メディアは、ウェブサイトによって運営される遠隔サーバに記憶され、ユーザがメディアを共有することを選択した、他のユーザによって後にアクセスされる。しかしながら、デジタルメディアおよびデジタルメディア集合体の量が増大するにつれて、あるユーザと共有する特定の画像を検索することが煩雑になる。 Digital media sharing typically involves a user uploading media to a media sharing website such as Picasa and Picasa Web Albums using a browser or other application that runs on the user's computing device. Accompanied by. The media is stored on a remote server operated by the website and later accessed by other users who have chosen to share the media. However, as the amount of digital media and digital media aggregates increases, it becomes cumbersome to search for specific images to share with a user.
実施形態は、メディアを自動的に共有するためのコンピュータ実装方法に関する。一実施形態では、それぞれ、第１のユーザおよび第２のユーザに関連付けられる、第１の画像の集合体および第２の画像の集合体が受信される。第１の画像の集合体は、第１のコンテンツデータを含み、第２の画像の集合体は、第２のコンテンツデータを含む。加えて、第１および第２のユーザは、互に関連付けられる。次に、第１および第２の集合体は、ユーザ介入なしで、第１および第２のコンテンツデータに従ってイベントグループに自動的にグループ化される。次いで、第１および第２のユーザは、ユーザ介入なしで、イベントグループへのアクセスが提供される。イベントグループは、第１および第２のユーザのうちの少なくとも１つに関連付けられている１つ以上の新しい画像で自動的に更新され得、第１および第２のユーザは、更新されたイベントグループへのアクセスを自動的に提供され得る。 Embodiments relate to a computer-implemented method for automatically sharing media. In one embodiment, a first image collection and a second image collection associated with a first user and a second user, respectively, are received. The first image group includes first content data, and the second image group includes second content data. In addition, the first and second users are associated with each other. The first and second aggregates are then automatically grouped into event groups according to the first and second content data without user intervention. The first and second users are then provided access to the event group without user intervention. The event group may be automatically updated with one or more new images associated with at least one of the first and second users, wherein the first and second users Access to can be provided automatically.
別の実施形態では、メディアを自動的に共有するためのシステムは、少なくとも１つのメモリと、メディア入力モジュールと、メディア共有モジュールとを含む。メディア入力モジュールおよびメディア共有モジュールは、少なくとも１つのメモリの中に位置する。メディア入力モジュールは、第１のユーザに関連付けられる第１の画像の集合体および第２のユーザに関連付けられる第２の画像の集合体を受信するように構成され、第１の集合体は、第１のコンテンツデータを含み、第２の集合体は、第２のコンテンツデータを含む。加えて、第１および第２のユーザは、互に関連付けられる。メディア共有モジュールは、ユーザ介入なしで、第１および第２のコンテンツデータに従って、第１および第２の集合体をイベントグループに自動的にグループ化するように構成される。メディア共有モジュールは、ユーザ介入なしで、第１および第２のユーザにイベントグループへのアクセスを自動的に提供するようにさらに構成される。イベントグループは、第１および第２のユーザのうちの少なくとも１つに関連付けられている１つ以上の新しい画像で、メディア共有モジュールによって自動的に更新され得、第１および第２のユーザは、更新されたイベントグループへのアクセスを自動的に提供され得る。 In another embodiment, a system for automatically sharing media includes at least one memory, a media input module, and a media sharing module. The media input module and the media sharing module are located in at least one memory. The media input module is configured to receive a first image collection associated with the first user and a second image collection associated with the second user, the first collection comprising: 1 content data is included, and the second aggregate includes second content data. In addition, the first and second users are associated with each other. The media sharing module is configured to automatically group the first and second collections into event groups according to the first and second content data without user intervention. The media sharing module is further configured to automatically provide access to the event group to the first and second users without user intervention. The event group may be automatically updated by the media sharing module with one or more new images associated with at least one of the first and second users, wherein the first and second users Access to updated event groups may be provided automatically.
実施形態は、ハードウェア、ファームウェア、ソフトウェア、またはそれらの組み合わせを使用して実装され得、１つ以上のコンピュータシステムまたは他の処理システムで実装され得る。 Embodiments may be implemented using hardware, firmware, software, or combinations thereof, and may be implemented with one or more computer systems or other processing systems.
さらなる実施形態、特徴、利点、ならびに種々の実施形態の構造および動作は、添付図面を参照して以下で詳細に説明される。本開示は、本明細書で説明される具体的実施形態に限定されないことに留意されたい。そのような実施形態は、例証目的のみで本明細書で提示される。追加の実施形態が、本明細書に含まれる情報に基づいて、当業者に明白となるであろう。
本発明は、例えば、以下を提供する。
（項目１）
ユーザ間でメディアを自動的に共有するコンピュータ実装方法であって、
第１のユーザに関連付けられている第１の画像の集合体を、少なくとも１つのコンピュータデバイス上で受信することであって、前記第１の集合体は、第１のコンテンツデータを有する、ことと、
第２のユーザに関連付けられている第２の画像の集合体を、前記少なくとも１つのコンピュータデバイス上で受信することであって、前記第２の集合体は、第２のコンテンツデータを有し、前記第１および第２のユーザは、互に関連付けられている、ことと、
前記第１および第２のユーザの関連に基づいて、前記第１および第２のコンテンツデータに従って前記第１および第２の集合体をイベントグループにグループ化することと、
前記第１および第２のユーザに前記イベントグループへのアクセスを提供することと
を含む、方法。
（項目２）
前記第１の画像の集合体および前記第２の画像の集合体のうちの１つに関連付けられている１つ以上の追加の画像を受信することと、
前記第１および第２のユーザのうちの少なくとも１つに関連付けられている１つ以上の追加の画像を含むように、前記イベントグループを更新することであって、前記第１および第２のユーザは、前記更新されたイベントグループへのアクセスを自動的に提供され得る、ことと
をさらに含む、項目１に記載の方法。
（項目３）
前記１つ以上の追加の画像は、画像シャッタデバイスのクリックに応答して受信される、項目２に記載の方法。
（項目４）
前記第１および第２のコンテンツデータのうちの少なくとも１つが第３のユーザに対応する顔の識別を含むことを決定することに応答して、前記第１および第２のユーザのうちの少なくとも１つに関連付けられている前記第３のユーザに、前記イベントグループへのアクセスを提供することをさらに含む、項目１に記載の方法。
（項目５）
前記第１および第２の集合体をイベントグループにグループ化することは、
前記第１のコンテンツデータに従って、前記第１のユーザに関連付けられている前記第１の集合体を、第１の組の１つ以上のアルバムに分割することであって、前記第１のユーザは、第１の共有選好を有する、ことと、
前記第２のコンテンツデータに従って、前記第２のユーザに関連付けられている前記第２の集合体を、第２の組の１つ以上のアルバムに分割することであって、前記第２のユーザは、第２の共有選好を有する、ことと、
前記第１および第２のコンテンツデータと、前記第１のユーザの前記第１の共有選好および前記第２のユーザの前記第２の共有選好とに基づいて、前記第１および第２の組のアルバムを前記イベントグループにクラスタ化することであって、前記第１および第２の共有選好は、少なくとも部分的に合致している、ことと
を含む、項目１に記載の方法。
（項目６）
前記第１および第２のユーザに前記イベントグループへのアクセスを提供することは、前記イベントグループへのアクセスリンクを有する通知を前記第１および第２のユーザに送信することを含む、項目１に記載の方法。
（項目７）
前記第１の集合体の画像は、第１のビデオの少なくとも一部分からのフレームであり、前記第２の集合体の画像は、第２のビデオの少なくとも一部分からのフレームである、項目１に記載の方法。
（項目８）
前記第１の集合体における画像に対する前記第１のコンテンツデータを決定することと、
前記第２の集合体における画像に対する前記第２のコンテンツデータを決定することと
をさらに含む、項目１に記載の方法。
（項目９）
前記第１のコンテンツデータを決定することは、前記第１の集合体の画像における第１の顔を認識することを含み、前記第１のコンテンツデータは、前記第１の顔の識別を含み、
前記第２のコンテンツデータを決定することは、前記第２の集合体の画像における第２の顔を認識することを含み、前記第２のコンテンツデータは、前記第２の顔の識別を含む、
項目８に記載の方法。
（項目１０）
前記第１の顔を認識することは、前記第１のユーザから、前記第１の顔の前記第１の識別を取得することを含み、
前記第２の顔を認識することは、前記第２のユーザから、前記第２の顔の前記第２の識別を取得することを含み、
前記第１の顔の前記第１の識別は、前記第２のユーザに対応し、
前記第２の顔の前記第２の識別は、前記第１のユーザに対応する、
項目９に記載の方法。
（項目１１）
前記第１のコンテンツデータを決定することは、前記第１の集合体の画像における第１の目印を認識することを含み、前記第１のコンテンツデータは、前記第１の目印に対応し、
前記第２のコンテンツデータを決定することは、前記第２の集合体の画像における第２の目印を認識することを含み、前記第２のコンテンツデータは、前記第２の目印に対応する、項目８に記載の方法。
（項目１２）
前記第１のコンテンツデータを決定することは、前記第１の集合体の画像における第１のオブジェクトを認識することを含み、前記第１のコンテンツデータは、前記第１のオブジェクトに対応し、
前記第２のコンテンツデータを決定することは、前記第２の集合体の画像における第２のオブジェクトを認識することを含み、前記第２のコンテンツデータは、前記第１のオブジェクトに対応する、項目８に記載の方法。
（項目１３）
前記第１のコンテンツデータを決定することは、前記第１の集合体の画像から第１のメタデータを抽出することを含み、前記第１のコンテンツデータは、前記第１のメタデータに対応し、
前記第２のコンテンツデータを決定することは、前記第２の集合体の画像から第２のメタデータを抽出することを含み、前記第２のコンテンツデータは、前記第２のメタデータに対応する、項目８に記載の方法。
（項目１４）
前記第１のメタデータを抽出することは、前記第１の集合体の画像が露出された第１の時間を抽出することを含み、前記第２のメタデータを抽出することは、前記第２の集合体の画像が露出された第２の時間を抽出することを含む、項目１３に記載の方法。
（項目１５）
前記第１のメタデータを抽出することは、前記第１の集合体の画像が露出された第１の場所を抽出することを含み、前記第２のメタデータを抽出することは、前記第２の集合体の画像が露出された第２の場所を抽出することを含む、項目１３に記載の方法。
（項目１６）
ユーザ間でメディアを自動的に共有するためのシステムであって、
１つ以上のプロセッサと、
第１のユーザに関連付けられている第１の画像の集合体、および第２のユーザに関連付けられている第２の画像の集合体を受信するように構成されているメディア入力モジュールであって、前記第１の集合体は、第１のコンテンツデータを有し、前記第２の集合体は、第２のコンテンツデータを有し、前記第１および第２のユーザは、互に関連付けられている、メディア入力モジュールと、
前記第１および第２のユーザの関連に基づいて、前記第１および第２のコンテンツデータに従って前記第１および第２の集合体をイベントグループにグループ化し、かつ、前記第１および第２のユーザに前記イベントグループへのアクセスを提供するメディア共有モジュールと
を備え、
前記メディア入力モジュールおよび前記メディア共有モジュールは、前記１つ以上のプロセッサを使用して実装されている、システム。
（項目１７）
前記メディア入力モジュールは、前記第１の画像の集合体および前記第２の画像の集合体に関連付けられている１つ以上の追加の画像を受信するようにさらに構成され、前記メディア共有モジュールは、前記第１および第２のユーザのうちの少なくとも１つに関連付けられている１つ以上の追加の画像を含むために、前記イベントグループを更新するようにさらに構成され、前記第１および第２のユーザは、前記更新されたイベントグループへのアクセスを自動的に提供され得る、項目１６に記載のシステム。
（項目１８）
前記１つ以上の追加の画像は、画像シャッタデバイスのクリックに応答して受信される、項目１７に記載のシステム。
（項目１９）
前記メディア共有モジュールは、前記第１および第２のコンテンツデータのうちの少なくとも１つが第３のユーザに対応する顔の識別を含むことを決定することに応答して、前記第１および第２のユーザのうちの少なくとも１つに関連付けられている前記第３のユーザに、前記イベントグループへのアクセスを提供するようにさらに構成されている、項目１６に記載のシステム。
（項目２０）
前記メディア共有モジュールは、
アルバム分割モジュールであって、前記アルバム分割モジュールは、
前記第１のコンテンツデータに従って、前記第１のユーザに関連付けられている前記第１の集合体を、第１の組の１つ以上のアルバムに自動的に分割することであって、前記第１のユーザは、第１の共有選好を有する、ことと、
前記第２のコンテンツデータに従って、前記第２のユーザに関連付けられている前記第２の集合体を、第２の組の１つ以上のアルバムに分割することであって、前記第２のユーザは、第２の共有選好を有する、ことと
を行うように構成されている、アルバム分割モジュールと、
前記第１および第２のコンテンツデータと、前記第１のユーザの前記第１の共有選好および前記第２のユーザの前記第２の共有選好とに基づいて、前記第１および第２の組のアルバムをイベントグループにクラスタ化するように構成されているイベントクラスタ化モジュールであって、前記第１および第２の共有選好は、少なくとも部分的に合致している、イベントクラスタ化モジュールと
を備えている、項目１６に記載のシステム。
（項目２１）
前記メディア共有モジュールは、前記イベントグループへのアクセスリンクを有する通知を前記第１および第２のユーザに送信するように構成されている通知マネージャを備えている、項目１６に記載のシステム。
（項目２２）
前記第１の集合体の画像は、第１のビデオの少なくとも一部分からのフレームであり、前記第２の集合体の画像は、第２のビデオの少なくとも一部分からのフレームである、項目１６に記載のシステム。
（項目２３）
前記メディア入力モジュールは、前記第１の集合体における画像に対する前記第１のコンテンツデータを決定することと、前記第２の集合体における画像に対する前記第２のコンテンツデータを決定することとを行うようにさらに構成されている、項目１６に記載のシステム。
（項目２４）
前記メディア入力モジュールは、顔認識モジュールを備え、前記顔認識モジュールは、前記第１の集合体の画像における第１の顔を認識することであって、前記第１のコンテンツデータは、前記第１の顔の識別を含む、ことと、前記第２の集合体の画像における第２の顔を認識することであって、前記第２のコンテンツデータは、前記第２の顔の識別を含む、こととを行うように構成されている、項目２３に記載のシステム。
（項目２５）
前記顔認識モジュールは、前記第１のユーザから、前記第１の顔の前記第１の識別を取得することであって、第１の顔の前記第１の識別は、前記第２のユーザに対応する、ことと、前記第２のユーザから、前記第２の顔の前記第２の識別を取得することであって、第２の顔の前記第２の識別は、前記第１のユーザに対応する、こととを行うように構成されている、項目２４に記載のシステム。
（項目２６）
前記メディア入力モジュールは、目印認識モジュールを備え、前記目印認識モジュールは、前記第１の集合体の画像における第１の目印を認識することであって、前記第１のコンテンツデータは、前記第１の目印に対応する、ことと、前記第２の集合体の画像における第２の目印を認識することであって、前記第２のコンテンツデータは、前記第２の目印に対応する、こととを行うように構成されている、項目２３に記載のシステム。
（項目２７）
前記メディア入力モジュールは、オブジェクト認識モジュールを備え、前記オブジェクト認識モジュールは、前記第１の集合体の画像における第１のオブジェクトを認識することであって、前記第１のコンテンツデータは、前記第１のオブジェクトに対応する、ことと、前記第２の集合体の画像における第２のオブジェクトを認識することであって、前記第２のコンテンツデータは、前記第２のオブジェクトに対応する、こととを行う、項目２３に記載のシステム。
（項目２８）
前記メディア入力モジュールは、メタデータ抽出器を備え、前記メタデータ抽出器は、前記第１の集合体の画像から第１のメタデータを抽出することであって、前記第１のコンテンツデータは、前記第１のメタデータに対応する、ことと、前記第２の集合体の画像から第２のメタデータを抽出することであって、前記第２のコンテンツデータは、前記第２のメタデータに対応する、こととを行う、項目２３に記載のシステム。
（項目２９）
前記第１のメタデータは、前記第１の集合体の前記画像が露出された第１の時間を含み、前記第２のメタデータは、前記第２の集合体の画像が露出された第２の時間を含む、項目２８に記載のシステム。
（項目３０）
前記第１のメタデータは、前記第１の集合体の画像が露出された第１の場所を含み、前記第２のメタデータは、前記第２の集合体の画像が露出された第２の場所を含む、項目２８に記載のシステム。
Further embodiments, features, advantages, and structure and operation of the various embodiments are described in detail below with reference to the accompanying drawings. It should be noted that the present disclosure is not limited to the specific embodiments described herein. Such embodiments are presented herein for illustrative purposes only. Additional embodiments will be apparent to those skilled in the art based on the information contained herein.
For example, the present invention provides the following.
(Item 1)
A computer-implemented method for automatically sharing media between users,
Receiving on a at least one computing device a first collection of images associated with a first user, the first collection comprising first content data; ,
Receiving on the at least one computing device a second collection of images associated with a second user, the second collection having second content data; The first and second users are associated with each other;
Grouping the first and second aggregates into event groups according to the first and second content data based on the association of the first and second users;
Providing access to the event group to the first and second users;
Including a method.
(Item 2)
Receiving one or more additional images associated with one of the first set of images and the second set of images;
Updating the event group to include one or more additional images associated with at least one of the first and second users, the first and second users Can automatically be provided with access to the updated event group; and
The method according to Item 1, further comprising:
(Item 3)
The method of item 2, wherein the one or more additional images are received in response to a click of an image shutter device.
(Item 4)
In response to determining that at least one of the first and second content data includes an identification of a face corresponding to a third user, at least one of the first and second users. 2. The method of item 1, further comprising providing access to the event group for the third user associated with one.
(Item 5)
Grouping the first and second aggregates into event groups includes
Splitting the first collection associated with the first user into a first set of one or more albums according to the first content data, wherein the first user Having a first shared preference,
Dividing the second collection associated with the second user into a second set of one or more albums according to the second content data, wherein the second user Having a second shared preference,
Based on the first and second content data and the first shared preference of the first user and the second shared preference of the second user, the first and second sets of Clustering albums into the event group, wherein the first and second shared preferences are at least partially matched;
The method according to item 1, comprising:
(Item 6)
Providing access to the event group for the first and second users includes sending a notification with an access link to the event group to the first and second users. The method described.
(Item 7)
Item 1. The image of the first collection is a frame from at least a portion of a first video, and the image of the second collection is a frame from at least a portion of a second video. the method of.
(Item 8)
Determining the first content data for images in the first aggregate;
Determining the second content data for images in the second aggregate;
The method according to Item 1, further comprising:
(Item 9)
Determining the first content data includes recognizing a first face in the image of the first collection, wherein the first content data includes identifying the first face;
Determining the second content data includes recognizing a second face in the image of the second aggregate, and the second content data includes identifying the second face;
9. The method according to item 8.
(Item 10)
Recognizing the first face includes obtaining the first identification of the first face from the first user;
Recognizing the second face includes obtaining the second identification of the second face from the second user;
The first identification of the first face corresponds to the second user;
The second identification of the second face corresponds to the first user;
10. The method according to item 9.
(Item 11)
Determining the first content data includes recognizing a first landmark in the image of the first aggregate, the first content data corresponding to the first landmark;
Determining the second content data includes recognizing a second landmark in the image of the second aggregate, wherein the second content data corresponds to the second landmark. 9. The method according to 8.
(Item 12)
Determining the first content data includes recognizing a first object in an image of the first aggregate, the first content data corresponding to the first object;
Determining the second content data includes recognizing a second object in the second aggregate image, wherein the second content data corresponds to the first object. 9. The method according to 8.
(Item 13)
Determining the first content data includes extracting first metadata from an image of the first aggregate, wherein the first content data corresponds to the first metadata. ,
Determining the second content data includes extracting second metadata from an image of the second aggregate, wherein the second content data corresponds to the second metadata. The method according to item 8.
(Item 14)
Extracting the first metadata includes extracting a first time at which an image of the first aggregate is exposed, and extracting the second metadata includes the second metadata. 14. A method according to item 13, comprising extracting a second time at which an image of the set of images is exposed.
(Item 15)
Extracting the first metadata includes extracting a first location where an image of the first aggregate is exposed, and extracting the second metadata includes the second metadata. 14. The method of item 13, comprising extracting a second location where an image of the collection of images is exposed.
(Item 16)
A system for automatically sharing media between users,
One or more processors;
A media input module configured to receive a collection of first images associated with a first user and a collection of second images associated with a second user, The first aggregate has first content data, the second aggregate has second content data, and the first and second users are associated with each other. , Media input module,
Based on the relationship between the first and second users, the first and second aggregates are grouped into event groups according to the first and second content data, and the first and second users A media sharing module that provides access to the event group
With
The system, wherein the media input module and the media sharing module are implemented using the one or more processors.
(Item 17)
The media input module is further configured to receive one or more additional images associated with the first collection of images and the second collection of images, and the media sharing module includes: Further configured to update the event group to include one or more additional images associated with at least one of the first and second users, the first and second The system of item 16, wherein a user may be automatically provided with access to the updated event group.
(Item 18)
18. The system of item 17, wherein the one or more additional images are received in response to a click on an image shutter device.
(Item 19)
The media sharing module is responsive to determining that at least one of the first and second content data includes a facial identification corresponding to a third user. The system of item 16, further configured to provide access to the event group to the third user associated with at least one of the users.
(Item 20)
The media sharing module is
An album division module, wherein the album division module
Automatically dividing the first collection associated with the first user into a first set of one or more albums according to the first content data, Users have a first sharing preference,
Dividing the second collection associated with the second user into a second set of one or more albums according to the second content data, wherein the second user Having a second shared preference, and
An album split module configured to
Based on the first and second content data and the first shared preference of the first user and the second shared preference of the second user, the first and second sets of An event clustering module configured to cluster albums into event groups, wherein the first and second shared preferences are at least partially matched;
The system according to item 16, comprising:
(Item 21)
The system of item 16, wherein the media sharing module comprises a notification manager configured to send a notification with an access link to the event group to the first and second users.
(Item 22)
Item 17. The image of the first collection is a frame from at least a portion of a first video, and the image of the second collection is a frame from at least a portion of a second video. System.
(Item 23)
The media input module is configured to determine the first content data for images in the first collection and to determine the second content data for images in the second collection. Item 17. The system according to Item 16, further configured to:
(Item 24)
The media input module includes a face recognition module, wherein the face recognition module recognizes a first face in an image of the first aggregate, and the first content data is the first content data. And identifying the second face in the image of the second aggregate, wherein the second content data includes the identification of the second face. 24. The system of item 23, wherein the system is configured to:
(Item 25)
The face recognition module obtains the first identification of the first face from the first user, wherein the first identification of the first face is made to the second user. Corresponding to obtaining the second identification of the second face from the second user, wherein the second identification of the second face is to the first user 25. A system according to item 24, configured to do the corresponding.
(Item 26)
The media input module includes a landmark recognition module, wherein the landmark recognition module recognizes a first landmark in the image of the first aggregate, and the first content data is the first content data. And recognizing a second mark in the image of the second aggregate, wherein the second content data corresponds to the second mark. 24. A system according to item 23, configured to perform.
(Item 27)
The media input module includes an object recognition module. The object recognition module recognizes a first object in an image of the first aggregate, and the first content data is the first content data. And recognizing a second object in the image of the second aggregate, wherein the second content data corresponds to the second object. 24. The system according to item 23.
(Item 28)
The media input module includes a metadata extractor, wherein the metadata extractor extracts first metadata from an image of the first aggregate, wherein the first content data is: Corresponding to the first metadata, and extracting second metadata from the image of the second aggregate, wherein the second content data is included in the second metadata. 24. The system according to item 23, wherein the corresponding is performed.
(Item 29)
The first metadata includes a first time when the image of the first collection is exposed, and the second metadata includes a second time when the image of the second collection is exposed. 29. A system according to item 28, comprising:
(Item 30)
The first metadata includes a first location where an image of the first collection is exposed, and the second metadata includes a second location where an image of the second collection is exposed. 29. The system of item 28, including location.
添付図面を参照して、一例のみとして実施形態が説明される。図面中、類似参照番号は、同一または機能的に同様の要素を示し得る。要素が最初に現れる図面は、典型的には、対応する参照番号の中の１つまたは複数の左端の数字によって示される。本明細書に組み込まれ、本明細書の一部を形成する添付図面は、本開示の実施形態を図示し、説明とともに、さらに本開示の原理を説明し、当業者がその実施形態を作製して使用することを可能にする働きをする。
目次
Ｉ．概説
ＩＩ．システム
Ａ．クライアントアプリケーション
Ｂ．メディア共有サービス
１．顔認識
２．目印およびオブジェクト／場面認識
３．メタデータ抽出
４．画像グループ化
ａ．アルバム分割
ｂ．イベントクラスタ化および共有
ｃ．リアルタイムイベント共有
ＩＩＩ．方法
Ａ．ユーザ間の自動メディア共有
Ｂ．クライアントアプリケーション
Ｃ．アルバム分割
Ｄ．イベントクラスタ化
ＩＶ．コンピュータシステム実装例
Ｖ．終わりに
（Ｉ．概説）
画像の検索および共有を促進するために、ユーザは、アルバム名別または日付別に、デジタルメディア集合体を異なるフォルダに整理することができる。ユーザはまた、タグまたはタグワードを画像または一群の画像に関連付けることもできる。タグは、画像のコンテンツを説明する１つ以上のキーワードを含む。しかしながら、ユーザが提供したタグを伴う組織化スキームは、多様なソースからの大型画像集合体のためにうまく拡張しない。例えば、ユーザは、全ての利用可能な画像を一貫して、および／または正確にタグ付けできない場合があり、同じ画像に対して異なるユーザによって提供されるタグに差異が存在し得る。さらに、多数の画像をタグ付けするために有意なユーザ入力が要求され、その結果として、ユーザは、利用可能な画像の全てをタグ付けする可能性が低い。一群の画像を共有するために、各ユーザは、一群の画像を手動で整理し、タグ付けし、メディア共有ウェブサイトにアップロードしなければならない。また、これは、データ入力が煩雑である携帯電話ユーザにとって、または共有することを希望するメディアの記述データを整理して入力する時間がないユーザにとっては、特に困難である。
Table of Contents I. Overview II. System A. Client application Media sharing service Face recognition 2. Markers and object / scene recognition Metadata extraction Image grouping a. Divide album b. Event clustering and sharing c. Real-time event sharing III. Method A. Automatic media sharing between users Client application C.I. Album division Event clustering IV. Computer system implementation example At the end (I. Overview)
To facilitate image searching and sharing, users can organize digital media aggregates into different folders by album name or date. A user can also associate a tag or tag word with an image or group of images. The tag includes one or more keywords that describe the content of the image. However, organization schemes with user-provided tags do not scale well for large image collections from a variety of sources. For example, a user may not be able to tag all available images consistently and / or accurately, and there may be differences in tags provided by different users for the same image. Furthermore, significant user input is required to tag a large number of images, so that the user is less likely to tag all of the available images. In order to share a group of images, each user must manually organize, tag and upload the group of images to a media sharing website. This is particularly difficult for mobile phone users who have trouble entering data, or for users who do not have time to organize and input media description data they wish to share.
加えて、メディア共有サイトは、概して、複数のユーザからの画像を自動的にグループ化する能力を提供しない。例えば、ユーザは、イベントにおいて撮影された画像を、イベントの他の出席者と共有することを希望し得る。同様に、他の出席者は、イベントからの画像をユーザと共有することを希望し得る。２人以上のユーザが、複数のユーザからの画像を含む共同アルバムまたは画像集合体を作成することができ得るが、そのようなアルバムまたは画像集合体の作成および更新は、依然としてユーザにとって手動過程である。 In addition, media sharing sites generally do not provide the ability to automatically group images from multiple users. For example, a user may wish to share images taken at an event with other attendees of the event. Similarly, other attendees may wish to share images from the event with the user. Although two or more users may be able to create a collaborative album or image collection that includes images from multiple users, the creation and update of such an album or image collection is still a manual process for the user. is there.
実施形態は、ユーザ間でメディアを自動的に共有することに関する。実施形態は、ユーザ介入なしで、メディアオブジェクトのコンテンツに基づいて、ユーザに関連付けられる、写真およびビデオを含むデジタルメディアを、１つ以上のアルバムに自動的にグループ化する。さらに、実施形態は、ユーザ介入なしで、アルバムのコンテンツに基づいて、複数のユーザからのアルバムを１つ以上のイベントグループに自動的にグループ化する。次いで、自動的に生成されたイベントグループは、相互とのユーザの関連および個々の共有選好に応じて、複数のユーザ間で共有され得る。実施形態は、イベントグループが新しい画像で更新されることも可能にし、ユーザ間で最新のイベントグループを自動的に共有する。 Embodiments relate to automatically sharing media between users. Embodiments automatically group digital media, including photos and videos, associated with a user into one or more albums based on the content of the media object without user intervention. In addition, embodiments automatically group albums from multiple users into one or more event groups based on album content without user intervention. The automatically generated event group can then be shared among multiple users depending on the user's association with each other and individual sharing preferences. Embodiments also allow event groups to be updated with new images and automatically share the latest event group among users.
例えば、第１のユーザおよび第２のユーザは、各ユーザが、写真およびビデオを含む、相互のデジタルメディア集合体に他者がアクセスすることを可能にする、ソーシャルネットワークに属し得る。第１および第２のユーザは、両者が出席する特定のイベントから写真を捕捉し得る。各ユーザは、他の無関係の写真とともに、イベント写真を記憶し得る。実施形態は、各ユーザに関連付けられる写真のコンテンツを自動的に決定し、イベントに対応する写真をイベントグループにグループ化し、任意の新しいイベント写真を含むイベントグループをユーザ間で共有する。実施形態は、メディアのコンテンツを決定するために、顔認識、目印認識、および場面またはオブジェクト認識を含むが、それらに限定されない、いくつかの異なる技法を使用し得る。実施形態はまた、そのコンテンツを決定するために、メディアからメタデータを抽出し得る。 For example, a first user and a second user may belong to a social network that allows each user to access others' collections of digital media, including photos and videos. The first and second users can capture photos from the specific event they both attend. Each user may store event photos along with other unrelated photos. Embodiments automatically determine the content of photos associated with each user, group photos corresponding to events into event groups, and share event groups including any new event photos among users. Embodiments may use a number of different techniques to determine media content, including but not limited to face recognition, landmark recognition, and scene or object recognition. Embodiments may also extract metadata from the media to determine its content.
本開示は、特定の用途に対する例証的実施形態を参照して本明細書で説明されるが、実施形態は、それらに限定されないことを理解されたい。他の実施形態が可能である、本明細書の教示、ならびに実施形態が有意に有用となる追加の分野の精神および範囲内で、修正を実施形態に行うことができる。さらに、特定の特徴、構造、または特性が、実施形態に関連して説明される場合に、明示的に説明されるか否かにかかわらず、他の実施形態に関連して、そのような特徴、構造、または特性に影響を及ぼすことは、当業者の知識の範囲内であることが提示される。 Although the present disclosure is described herein with reference to illustrative embodiments for particular applications, it is to be understood that the embodiments are not limited thereto. Modifications can be made to the embodiments within the spirit and scope of the additional teachings where the other embodiments are possible, and where the embodiments are significantly useful. Furthermore, when a particular feature, structure, or characteristic is described in connection with an embodiment, such feature in connection with other embodiments, whether or not explicitly described. It is suggested that affecting the structure, characteristics, or properties is within the knowledge of one of ordinary skill in the art.
また、本明細書で説明されるような実施形態は、図に図示されるソフトウェア、ハードウェア、ファームウェア、および／またはエンティティの多くの異なる実施形態で実装できることも、当業者に明白となるであろう。実施形態を実装するためのハードウェアの特殊制御を伴う、いずれの実際のソフトウェアコードも、詳細な説明の限定ではない。したがって、実施形態の動作挙動は、本明細書で提示される詳細のレベルを考慮して、実施形態の修正および変化例が可能であるという理解とともに説明される。 It will also be apparent to those skilled in the art that embodiments as described herein may be implemented with many different embodiments of the software, hardware, firmware, and / or entities illustrated in the figures. Let's go. Any actual software code with special control of the hardware to implement the embodiments is not a limitation of the detailed description. Accordingly, the operational behavior of the embodiments is described with the understanding that modifications and variations of the embodiments are possible in view of the level of detail presented herein.
本明細書の詳細な実施例では、「一実施形態」、「実施形態」、「実施形態例」等への言及は、説明される実施形態が、特定の特徴、構造、または特性を含み得るが、全ての実施形態が必ずしも、特定の特徴、構造、または特性を含まなくてもよいことを示す。また、そのような語句は、必ずしも同じ実施形態を指しているとは限らない。さらに、特定の特徴、構造、または特性は、実施形態に関連して説明されるが、明示的に説明されるか否かにかかわらず、他の実施形態に関連して、そのような特徴、構造、または特性に影響を及ぼすことは、当業者の知識の範囲内であることが提示される。 In the detailed examples herein, references to “one embodiment,” “embodiment,” “example embodiment,” etc. may include specific features, structures, or characteristics of the described embodiment. However, it is shown that all embodiments may not necessarily include specific features, structures, or characteristics. Moreover, such phrases are not necessarily referring to the same embodiment. Furthermore, although specific features, structures, or characteristics are described in connection with an embodiment, such features, in connection with other embodiments, whether explicitly described or not, It is suggested that affecting the structure or properties is within the knowledge of one of ordinary skill in the art.
「メディア」および「デジタルメディア」という用語は、デジタル写真、またはデジタルフォト、およびデジタルビデオを広義かつ包括的に指すために、本明細書で交換可能に使用される。「画像」という用語は、１人以上の個人、１つ以上の目印、および／または１つ以上のオブジェクトを含むが、それらに限定されない、場面の画像およびその場面内のアイテムを描写する、デジタル写真を広義かつ包括的に指すために、本明細書で使用される。加えて、「画像」という用語は、デジタルビデオの少なくとも一部分からの１つ以上のフレームを指し得る。さらに、「写真／フォト」、「ビデオ」、「メディア」、および「画像」という用語は、用語が「デジタル」という用語によって修飾されるか否かにかかわらず、デジタル写真およびデジタルビデオを指すために、本明細書で使用される。 The terms “media” and “digital media” are used interchangeably herein to refer broadly and comprehensively to digital photos, or digital photos, and digital videos. The term “image” is a digital that depicts an image of a scene and items within that scene, including but not limited to one or more individuals, one or more landmarks, and / or one or more objects. Used herein to refer broadly and comprehensively to photographs. In addition, the term “image” may refer to one or more frames from at least a portion of a digital video. Further, the terms “photo / photo”, “video”, “media”, and “image” refer to digital photos and digital videos, regardless of whether the term is modified by the term “digital”. As used herein.
「メディア共有サイト」という用語は、写真およびビデオを含むデジタルメディアを種々のユーザ間で共有するように適合される、任意のウェブサイト、サービス、フレームワーク、またはプロトコルを広義かつ包括的に指すために、本明細書で使用される。そのようなウェブサイトまたはサービスは、サイトのメンバー間でメディアを共有する追加能力を伴うソーシャルネットワーキングサイトも含み得る。 The term “media sharing site” is intended to refer broadly and comprehensively to any website, service, framework, or protocol that is adapted to share digital media, including photos and videos, among various users. As used herein. Such websites or services may also include social networking sites with the added ability to share media among site members.
「画像キャプチャデバイス」および「画像捕捉デバイス」という用語は、写真およびビデオを含むデジタルメディアを捕捉するように適合される任意のデバイスを広義かつ包括的に指すために、本明細書で交換可能に使用される。そのようなデバイスの実施例は、デジタルカメラ、統合デジタルカメラを伴うモバイルデバイスを含むが、それらに限定されない。さらに、画像露出の目的でシャッタデバイスを開くボタンまたはキーを手動で押す、選択する、またはクリックすることによって、そのようなデバイスを使用して、画像が捕捉されることが想定される。しかしながら、「シャッタ」という用語は、（すなわち、シャッタデバイスを呼び出すことによって）画像を捕捉するために使用される、画像キャプチャデバイス上の任意の種類のボタンまたはキーを広義かつ包括的に指すためにも、本明細書で使用される。 The terms “image capture device” and “image capture device” are interchangeable herein to refer broadly and comprehensively to any device that is adapted to capture digital media, including photos and videos. used. Examples of such devices include, but are not limited to, digital cameras, mobile devices with integrated digital cameras. It is further envisioned that an image is captured using such a device by manually pressing, selecting, or clicking a button or key that opens the shutter device for image exposure purposes. However, the term “shutter” is intended to refer broadly and comprehensively to any kind of button or key on an image capture device that is used to capture an image (ie, by calling the shutter device). Are also used herein.
（ＩＩ．システム）
図１は、本明細書で説明される実施形態を実装することができる、システム１００を例証する図である。システム１００は、クライアントデバイス１１０および１１０Ａ−Ｃと、クライアントアプリケーション１１２と、デバイス入力１１４と、ローカルメモリ１１６と、ブラウザ１１５と、メディアビューア１１８と、メディア１２０と、通知１３０と、ネットワーク１４０と、サーバ１５０、１６０、および１７０と、メディア共有サービス１５２と、データベース１８０とを含む。
(II. System)
FIG. 1 is a diagram illustrating a
クライアントデバイス１１０、１１０Ａ、１１０Ｂ、および１１０Ｃは、例えば、ネットワーク１４０を介し、１つ以上のサーバ１５０、１６０、および１７０と通信する。サーバ１５０、１６０、および１７０（以降「サーバ１５０」と集合的に呼ばれる）のみが示されているが、より多くのサーバが必要に応じて使用され得る。同様に、クライアントデバイス１１０および１１０Ａ−Ｃのみが示されているが、より多くのクライアントデバイスが必要に応じて使用され得る。クライアントデバイス１１０は、通信インターフェースを通してネットワーク１４０に通信可能に連結される。クライアントデバイス１１０は、１つ以上のプロセッサと、ネットワーク上でデータを受信および伝送することが可能な通信インフラストラクチャとを有する、任意の種類のコンピュータデバイスであり得る。クライアントデバイス１１０は、デバイス入力１１４も含む。デバイス入力１１４は、マウス、ＱＷＥＲＴＹキーボード、タッチスクリーン、マイクロホン、またはＴ９キーボードを含むが、それらに限定されない、クライアントデバイス１１０に連結される任意の種類のユーザ入力デバイスであり得る。クライアントデバイス１１０は、携帯電話、携帯情報端末（ＰＤＡ）、コンピュータ、コンピュータ群、セットトップボックス、または命令を処理すること、ならびに人間および他のコンピュータデバイスからデータを受信し、そこへデータを伝送することが可能な他の同様の種類のデバイスを含むことができるが、それらに限定されない。
サーバ１５０は、同様に、データをクライアントデバイス１１０に供給することが可能な任意の種類のコンピュータデバイスであり得る。サーバ１５０は、メディア共有サービス１５２を実行する。メディア共有サービス１５２は、サーバ１５０に関して示されているが、メディア共有サービス１５２は、任意のサーバ上に実装され得る。さらに、メディア共有サービス１５２の機能性は、例えば、サーバ１５０等の単一のサーバ上で、あるいは、例えば、分散またはクラスタ化サーバ環境内のサーバ１５０、１６０、および１７０等の複数のサーバにわたって、実装され得る。
実施形態では、サーバ１５０は、データベース１８０に通信可能に連結される。データベース１８０は、当業者に公知である任意の種類のデータ記憶装置であり得る。実施例では、データ記憶装置は、ＯＲＡＣＬＥデータベースまたは当業者に公知である他のデータベース等のデータベース管理システムであり得る。データベース１８０は、サーバ１５０によってアクセス可能である、任意の種類のメディアおよび任意の対応メディアデータを記憶し得る。１つだけのデータベース１８０が示されているが、より多くのデータベースが必要に応じて使用され得る。
In an embodiment,
実施形態では、ローカルメモリ１１６は、クライアントデバイス１１０によってアクセス可能な情報を記憶するために使用される。例えば、ローカルメモリ１１６の中に記憶される情報は、１つ以上のデジタルメディアファイル、１人以上のユーザの連絡先情報、またはデジタル形式の任意の他の種類の情報を含み得るが、それらに限定されない。ローカルメモリ１１６は、記録媒体へのアクセスを制御する集積回路に連結される、任意の種類の記録媒体であり得る。記録媒体は、例えば、限定するものではないが、半導体メモリ、ハードディスク、あるいは他の同様の種類のメモリまたは記憶デバイスであり得る。または、ローカルメモリ１１６は、クライアントデバイス１１０内に統合され得、または直接接続を介してクライアントデバイス１１０に通信可能に連結される独立型デバイスであり得る。例えば、ローカルメモリ１１６は、クライアントデバイス１１０の内部メモリデバイス、コンパクトフラッシュ（登録商標）カード、セキュアデジタル（ＳＤ）フラッシュメモリカード、または他の同様の種類のメモリデバイスを含み得る。
In an embodiment,
ネットワーク１４０は、データ通信を運ぶことができる、任意のネットワークまたはネットワークの組み合わせであり得る。そのようなネットワーク１４０は、有線（例えば、イーサネット（登録商標））または無線（例えば、Ｗｉ−Ｆｉおよび３Ｇ）ネットワークを含むが、それらに限定されない。加えて、ネットワーク１４０は、ローカルエリアネットワーク、中域ネットワーク、および／またはインターネット等の広域ネットワークを含むことができるが、それらに限定されない。ネットワーク１４０は、インターネットあるいはワールドワイドプロトコルおよび／またはサービスを含むが、それらに限定されない、プロトコルおよび技術をサポートすることができる。中間ネットワークルータ、ゲートウェイ、またはサーバが、特定の用途または環境に応じて、システム１００の構成要素間に提供され得る。
The
実施形態では、クライアントデバイス１１０および１１０Ａ−Ｃは、クライアントアプリケーション１１２を実行する。さらなる実施形態では、クライアントデバイス１１０および１１０Ａ−Ｃは、メディアビューア１１８を実行する。クライアントアプリケーション１１２およびメディアビューア１１８の動作は、以下でさらに詳細に説明される。クライアントアプリケーション１１２およびメディアビューア１１８は、任意の種類のコンピュータデバイス上で実装され得る。そのようなコンピュータデバイスは、パーソナルコンピュータ、携帯電話等のモバイルデバイス、ワークステーション、埋め込みシステム、ゲームコンソール、テレビ、セットトップボックス、または任意の他のコンピュータデバイスを含むことができるが、それらに限定されない。さらに、コンピュータデバイスは、命令を実行し、記憶するためのプロセッサおよびメモリを有する、デバイスを含むことができるが、それに限定されない。ソフトウェアは、１つ以上のアプリケーションと、オペレーティングシステムとを含み得る。ハードウェアは、プロセッサ、メモリ、およびグラフィカルユーザインターフェースディスプレイを含むことができるが、それらに限定されない。コンピュータデバイスはまた、複数のプロセッサと、複数の共有または別個のメモリ構成要素とを有し得る。例えば、コンピュータデバイスは、クラスタ化コンピュータ環境またはサーバファームであり得る。
In an embodiment,
図１に図示されるような実施形態では、クライアントデバイス１１０は、クライアントアプリケーション１１２、メディアビューア１１８、またはそれらの任意の組み合わせを介して、メディアデータ１２０を、サーバ１５０上のメディア共有サービス１５２に送信し、またはそこから受信し得る。メディアデータ１２０は、１つ以上のメディアファイルを含む。メディアファイルは、写真、ビデオ、または両方の組み合わせであり得る。加えて、メディアファイルは、送信される、または取り出されるメディアに対応する、メディアコンテンツ情報およびメタデータを含み得る。クライアントアプリケーション１１２およびメディアビューア１１８は、クライアントデバイス１１０のディスプレイ上で、取り出されたメディアの視覚表現を提示し得る。そのようなディスプレイは、デジタル写真および／またはビデオを閲覧するための任意の種類のディスプレイであり得、あるいはデジタル写真および／またはビデオを閲覧するように適合される任意の種類のレンダリングデバイスであり得る。
In an embodiment as illustrated in FIG. 1,
実施形態では、メディアビューア１１８は、独立型アプリケーションであり得、あるいはそれは、例えば、Ｇｏｏｇｌｅ ＣｈｒｏｍｅまたはＭｉｃｒｏｓｏｆｔ Ｉｎｔｅｒｎｅｔ Ｅｘｐｌｏｒｅｒ等のブラウザ１１５内で実行することができる。メディアビューア１１８は、ブラウザ１１５内のスクリプトとして、ブラウザ１１５内のプラグインとして、または、例えば、Ａｄｏｂｅ（Ｍａｃｒｏｍｅｄｉａ）Ｆｌａｓｈプラグイン等のブラウザプラグイン内で実行するプログラムとして、実行することができる。実施形態では、クライアントアプリケーション１１２および／またはメディアビューア１１８は、メディア共有サービス１５２と一体化している。
In an embodiment, the media viewer 118 may be a stand-alone application, or it may run within a browser 115 such as Google Chrome or Microsoft Internet Explorer, for example. The media viewer 118 can be executed as a script in the browser 115, as a plug-in in the browser 115, or as a program executed in a browser plug-in such as an Adobe (Macromedia) Flash plug-in, for example. In an embodiment,
実施形態では、クライアントデバイス１１０は、ネットワーク１４０上でメディア共有サービス１５２から通知１３０を受信するようにも構成される。実施形態では、通知１３０は、共有されるメディアが記憶されるウェブ上の場所へのアクセスリンクを含む。例えば、アクセスリンクは、ユニフォームリソースロケータ（ＵＲＬ）等のウェブ場所アドレスの形態でウェブサイトへの場所を含み得る。通知１３０は、いくつかの異なるプロトコルおよび方法のうちのいずれかを使用して、メディア共有サービス１５２からクライアントデバイス１１０へ送信され得る。例えば、通知１３０は、電子メールまたはショートメッセージサービス（ＳＭＳ）を介して、メディア共有サービス１５２から送信され得る。通知１３０は、クライアントアプリケーション１１２、メディアビューア１１８、あるいは、例えば、電子メールクライアントまたはＳＭＳアプリケーション等の、そのような通知を受信するように適合される任意の他のアプリケーションまたはユーティリティによって、クライアントデバイス１１０において受信され得る。
In an embodiment,
（Ａ． クライアントアプリケーション）
図２は、図１のクライアントデバイス１１０のクライアントアプリケーション１１２の例示的実施形態を例証する図である。クライアントアプリケーション１１２は、画像キャプチャモジュール２１０と、顔検出モジュール２２０と、メタデータ挿入モジュール２３０と、ユーザインターフェースモジュール２４０と、画像転送モジュール２５０とを含む。画像キャプチャモジュール２１０、顔検出モジュール２２０、メタデータ挿入モジュール２３０、ユーザインターフェースモジュール２４０、および画像転送モジュール２５０を含む、クライアントアプリケーション１１２の構成要素のうちの各々は、相互に通信可能に連結され得る。
(A. Client application)
FIG. 2 is a diagram illustrating an exemplary embodiment of
動作において、クライアントアプリケーション１１２は、クライアントデバイス１１０におけるユーザにデジタル画像を捕捉するためのオプションを提示するためにユーザインターフェースモジュール２４０を使用する。オプションのユーザ選択に応じて、クライアントアプリケーション１１２は、デジタル写真またはビデオを捕捉するために画像キャプチャモジュール２１０を使用する。画像を捕捉するために、画像キャプチャモジュール２１０を、例えば、クライアントデバイス１１０と一体化したデジタルカメラ等の画像キャプチャデバイス（図示せず）に連結することができる。加えて、ユーザインターフェースモジュール２４０を、例えば、クライアントデバイス１１０におけるタッチスクリーンまたは入力ボタン（例えば、デバイス入力１１４）等のユーザ入力デバイスに連結することができる。写真またはビデオが捕捉されると、それは、クライアントデバイス１１０における画像キャプチャモジュール２１０によって、例えば、ローカルメモリ１１６の中に記憶することができる。
In operation,
顔検出モジュール２２０は、画像キャプチャモジュール２１０によって捕捉された後に、メディアを分析するように構成することができる。実施形態では、顔検出モジュール２２０は、以前に捕捉され、クライアントデバイス１１０に記憶されたメディアを分析することもできる。そのような記憶されたメディアは、１１０における画像捕捉デバイスを使用して、（例えば、画像キャプチャモジュール２１０、またはクライアントデバイス１１０において実行される別のアプリケーションによって）捕捉されていてもよく、または、クライアントデバイス１１０に連結されていない別個の画像捕捉デバイスを使用して捕捉され、後にローカルメモリ１１６に転送されていてもよい。顔検出モジュール２２０は、１つ以上の画像、またはユーザによって特定される画像を分析して、画像内の顔を検出するように構成することができる。例えば、ユーザがデジタル写真のアルバムをローカルメモリ１１６に転送する場合、顔検出モジュール２２０は、そのアルバムの中の各デジタル写真を分析して、顔を検出することができる。
The
顔が検出された場合に、顔検出モジュール２２０は、検出された顔に対応する顔画像または顔モデルを生成するために、検出された顔を包含する領域、例えば、検出された顔を包含する長方形の領域のデジタルコピーを作製することができる。次いで、顔画像は、ローカルメモリ１１６の中に記憶することができる。代替として、顔画像は、ネットワーク（例えば、ネットワーク１４０）を介してクライアントアプリケーション１１２によってアクセス可能である、顔画像データベース（図示せず）の中に記憶することができる。実施形態では、顔検出モジュール２２０は、後に分析される画像の中で顔を検出するのに役立つために、記憶された顔画像を使用することができる。
If a face is detected, the
この説明で挙げられる関連技術の当業者であれば、いくつかの周知の技法のうちのいずれか１つが、画像の中の顔を検出するために顔検出モジュール２２０で使用され得ることを理解するであろう。そのような技法の実施例は、米国特許第６，２２２，９３９号で説明されるような弾性バンチグラフマッチング、米国特許第６，９１７，７０３号で説明されるような「ガボールジェット」上のニューラルネットワークを使用すること、および米国特許第７，０９９，５１０号で説明されるようなブーストされた原始的特徴を使用した顔検出を含むが、それらに限定されない。
Those skilled in the relevant art listed in this description will understand that any one of several well-known techniques can be used in the
場合によっては、顔検出モジュール２２０の自動顔検出は、画像の中の全ての顔を検出しないことがある。したがって、いくつかの実施形態では、ユーザは、特定的に特定された画像を処理するように、顔検出モジュール２２０を誘起し得る。例えば、顔検出モジュール２２０は、画像の中の１つ以上の顔を検出しないことがある。この場合、実施形態では、顔検出モジュール２２０は、ユーザが顔検出過程を手動で支援するための能力を提供する。例えば、ユーザインターフェースモジュール２１０は、ユーザが検出することを望む各顔の周囲に、境界領域または境界ボックスを描くように、グラフィカルユーザインターフェースを提示し得る。この説明で挙げられる関連技術の当業者であれば、同じ顔検出技法が、わずかな修正を伴って自動顔検出ならびに手動支援型顔検出で使用され得ることを理解するであろう。例えば、手動で支援された場合に、顔検出ソフトウェアは単純に、画定された領域内で識別される顔の目印特徴をより強調し得る。
In some cases, automatic face detection of the
実施形態では、顔が顔検出モジュール２２０を使用して検出されると、ユーザインターフェースモジュール２４０は、検出された顔に対応する個人を識別するための追加の記述データを提供するためにユーザが使用することができる１つ以上のユーザ入力フィールドを表示し得る。例えば、ユーザは、検出された顔画像にタグ付けするための名前を提供することができる。タグは、他の画像の中の個人を識別するために、後に使用することができる。記述データはまた、識別された個人の連絡先情報を含み得るが、それに限定されない。検出された顔画像に対応する追加の情報のユーザ入力時に、メタデータ挿入モジュール２３０は、識別された個人のタグ名、各識別された個人の連絡先情報、および／または画像キャプションあるいは説明情報を含むが、それらに限定されない、任意のユーザ提供情報に加えて、検出された顔情報（例えば、顔検出モジュール２２０によって生成される顔画像）に、画像を関連付ける、または画像に注釈を付けるように構成することができる。
In an embodiment, when a face is detected using the
実施形態では、顔検出モジュール２２０は、検出された顔を識別するために、記憶された顔画像を使用し得る。上記で説明されるように、顔画像は、ローカルメモリ１１６の中に、またはネットワーク１４０上でクライアントアプリケーション１１２によってアクセス可能な顔データベースの中に記憶され得る。そのような顔データベースは、各顔画像に対応する個人の名前および／または連絡先情報を含む、メタデータに加えて、顔画像を記憶するように適合される任意の種類のデータベースであり得る。記憶された顔画像は、顔画像に対応する個人の識別に対する識別情報を含む、独自のメタデータを含むこともできる。例えば、識別情報は、名前および連絡先情報を含み得る。
In an embodiment, the
したがって、この実施形態では、ユーザは、もはや検出された顔の識別情報を提供するように要求されなくなる。この実施形態の利点は、ユーザ介入なしで、メタデータ挿入モジュール２３０が、検出された顔情報および対応識別情報を関連付けることができることである。しかしながら、顔検出モジュール２２０は、検出された顔を記憶された顔画像または顔モデルと照合するために、追加の顔認識機能性を伴って構成される必要があり得る。そのような顔認識機能性は、以下で説明される、図３のメディア共有サービス１５２の顔認識モジュール３３２と同様に動作する。
Thus, in this embodiment, the user is no longer required to provide detected face identification information. An advantage of this embodiment is that the
実施形態では、メタデータ挿入モジュール２３０は、画像が撮影された時間、および画像が撮影された場所を含むが、それらに限定されない、他のメタデータを画像に関連付け得る。例えば、クライアントデバイス１１０は、全地球測位衛星（ＧＰＳ）受信機を含み得、メタデータ挿入モジュール２３０は、任意の他の情報に加えて、画像が撮影された場所を画像に関連付けるように構成され得る。この説明で挙げられる関連技術の当業者であれば、任意の種類の周知の情報形式がメタデータに使用される場合があることを認識するであろう。例えば、画像の場所は、画像が捕捉された地理的な場所に対応する、緯度および経度座標を含み得る。
In an embodiment, the
実施形態では、画像転送モジュール２５０は、ネットワーク１４０上で、クライアントデバイス１１０から、図１に示されるサーバ１５０のメディア共有サービス１５２へ１つ以上の画像を転送する。転送された画像は、メタデータ挿入モジュール２３０によって画像に関連付けられるメタデータ情報を含む。画像転送モジュール２５０は、クライアントデバイス１１０の通信インターフェースを介して、画像を転送するように構成される。画像は、ネットワーク１４０上でクライアントデバイス１１０とメディア共有サービス１５２との間にデジタルファイルを転送するための任意の種類の周知の方法を使用して、画像転送モジュール２５０によって転送され得る。
In an embodiment, the
画像キャプチャモジュール２１０、顔検出モジュール２２０、メタデータ挿入モジュール２３０、ユーザインターフェースモジュール２４０、および画像転送モジュール２５０の実施形態は、ソフトウェア、ファームウェア、ハードウェア、またはそれらの任意の組み合わせで実装することができる。画像キャプチャモジュール２１０、顔検出モジュール２２０、メタデータ挿入モジュール２３０、ユーザインターフェースモジュール２４０、および画像転送モジュール２５０、またはそれらの複数部分の実施形態は、本明細書で説明される機能性を実行することが可能な１つ以上のコンピュータデバイス上で実行されるコンピュータ可読コードとして実装することもできる。そのようなコンピュータデバイスの実施例は、コンピュータ、埋め込みシステム、ネットワークデバイス、モバイルデバイス、あるいは本明細書で説明される機能性を実行することが可能な他の種類のプロセッサまたはコンピュータシステムを含むが、それらに限定されない。
Embodiments of the
加えて、クライアントアプリケーション１１２内にあることが示される、画像キャプチャモジュール２１０、顔検出モジュール２２０、メタデータ挿入モジュール２３０、ユーザインターフェースモジュール２４０、および画像転送モジュール２５０は、本開示の実施形態を実装する上での機能性を表す。当業者であれば、クライアントアプリケーション１１２の中で示されるよりも多いまたは少ないモジュールが、本開示の機能性を達成するようにソフトウェアで実装され得ることを理解するであろう。
In addition, the
（Ｂ．メディア共有サービス）
図３は、メディア共有サービス１５２が実装され得る、例示的なシステム３００の実施形態を例証する図である。システム３００は、図１のクライアントデバイス３１０、メディアデータベース３２０、メディア共有サービス１５２と、アルバムデータベース３５０と、イベントデータベース３６０と、ソーシャルグラフデータベース３７０とを含む。メディア共有サービス１５２は、メディア入力モジュール３３０およびメディア共有モジュール３４０を含む、種々の構成要素モジュールを含む。メディア入力モジュール３３０は、顔認識モジュール３３２と、目印認識モジュール３３４と、オブジェクト認識モジュール３３６と、メタデータ抽出器モジュール３３８とを含む。
(B. Media sharing service)
FIG. 3 is a diagram illustrating an embodiment of an
メディアデータベース３２０は、写真またはビデオデータ等の任意の種類のメディアデータを記憶し得る。画像は、例えば、デジタルカメラから撮影された写真であり得る。画像は、ＪＰＥＧ、ＴＩＦＦ、またはデジタル画像ファイル用の他の同様の形式で符号化され得る。各画像は、画像に関連付けられるメタデータを有し得る。例えば、画像は、画像の写真が撮影された時間、写真が撮影された場所、ならびに、型式、モデル、焦点距離、およびズーム等の、画像を捕捉した、例えば、デジタルカメラ等の画像捕捉デバイスについての情報等の情報を記憶する交換可能画像ファイル形式（ＥＸＩＦ）ヘッダを有し得る。画像が撮影された時間は、画像が画像捕捉デバイスによって露出された時間に対応し得る。ビデオは、一連のフレームを含み、各フレームは、画像を含む。ビデオはまた、例えば、デジタルカメラ等のビデオを捕捉することが可能な画像捕捉デバイスを使用して、捕捉され得る。
The
実施例では、メディアデータベース３２０は、Ｐｉｃａｓａ等のメディア共有サイト（図示せず）に連結され得る。ユーザは、メディア共有サイトからメディアデータベース３２０にメディアをアップロードし得る。例えば、再び図１を参照すると、ユーザは、メディア共有サイトへナビゲートするために、クライアントデバイス１１０におけるブラウザ１１５を使用し、メディア共有サイトによって提供されるユーザインターフェースを介して画像をメディアデータベース３２０にアップロードし得る。さらなる実施例では、ユーザは、メディアデータベース３２０から画像を取り出すことも可能であり得る。例えば、ユーザは、ローカルメモリ１１６の中に記憶するためにクライアント１１０上に画像をダウンロードすること、または、同様にメディア共有サイトに連結され得るメディアビューア１１８を使用して画像を閲覧することの選択を有し得る。
In an embodiment, the
メディアデータ３０１は、メディア入力モジュール３３０によってメディアデータベース３２０から取り出される。メディア入力モジュール３３０は、例えば、ＳＱＬ ＳＥＬＥＣＴ文を使用して、メディアデータベース３２０からメディアデータ３０１を取り出し得る。代替として、メディア入力モジュール３３０は、ウェブサービスを使用してメディアデータベース３２０にアクセスすることができる。メディアデータベース３２０は、メディアデータ３０１をメディア入力モジュール３３０にプッシュ配信し得る、１つ以上の中間サーバを有し得る。上記で説明されるメディアデータ１２０のように、メディアデータ３０１は、１つ以上の画像ファイルを含み得る。画像ファイルは、写真、１つ以上のビデオからのフレーム、または両方の組み合わせであり得る。画像ファイルは、例えば、図２に図示されるクライアントアプリケーション１１２のメタデータ挿入モジュール２３０によって追加されるメタデータ情報等の画像コンテンツおよびメタデータを含み得る。
メディア入力モジュール３３０は、通信チャネル３０２を介したクライアントデバイス１１０、通信チャネル３０４を介したクライアントデバイス１１０Ａ、および／または通信チャネル３０３を介したクライアントデバイス３１０のうちの１つ以上からも、ネットワーク１４０上でメディアデータ１２０を受信し得る。クライアントデバイス１１０、クライアントデバイス１１０Ａ、およびクライアントデバイス３１０のみが示されているが、追加のクライアントデバイスが必要に応じて使用され得る。クライアントデバイス３１０は、ネットワーク１４０上で、メディア共有サービス１５２を含むサーバ１５０に捕捉された画像を送信する能力を伴う任意の画像捕捉デバイスを含み得る。例えば、クライアントデバイス３１０は、画像を記憶し、記憶された画像をメディア共有サイトに直接アップロードする能力を提供する、ＥＹＥ−ＦＩ ＳＤカードを伴うデジタルカメラを含むが、それに限定されない、独立型デジタルカメラであり得る。
Media input module 330 may also be connected to network 140 from one or more of
メディアデータ１２０を受信すると、および／またはメディアデータ３０１を取り出すと、メディア入力モジュール３３０は、メディアデータ１２０および／またはメディアデータ３０１を、顔認識モジュール３３２、目印認識モジュール３３４、オブジェクト認識モジュール３３６、およびメタデータ抽出器モジュール３３８に送信する。
Upon receiving
（１．顔認識）
顔認識モジュール３３２は、１つ以上の顔を認識するように自動顔認識を行うことによって、メディアデータ１２０および／またはメディアデータ３０１（以降「メディアデータ１２０／３０１」と集合的に呼ばれる）のコンテンツを解釈する。顔認識モジュール３３２の自動顔認識は、顔検出段階および顔認識段階の２つの段階で機能し得る。しかしながら、顔認識モジュール３３２は、顔検出情報がメディアデータ１２０／３０１にすでに含まれている場合、メディアデータ１２０／３０１に対する顔検出段階を省略することが可能であり得る。例えば、すでに顔検出を行い、画像ファイルに顔検出情報を含む画像が、クライアントデバイス１１０のクライアントアプリケーション１１２によって送信されていることがある。全ての画像が顔検出情報を含むわけではないので、顔認識モジュール３３２は、それが受信する画像ファイルが、そのような情報を含むかどうかを決定し、決定に基づいて、必要に応じて顔検出を行わなければならない。
(1. Face recognition)
The face recognition module 332 performs the automatic face recognition so as to recognize one or more faces, whereby the contents of the
顔認識モジュール３３２の顔検出段階は、メディアデータ１２０／３０１の画像の中で顔を自動的に検出することを含む。そのような自動検出は、例えば、一般的な顔の特性に基づき得る。顔認識モジュール３３２は、画像内の顔を検出するように画像を分析する。１つ以上の顔が検出された場合に、顔認識モジュール３３２は、例えば、画像内の検出された顔を包含する有界領域を含む、各検出された顔に対応する顔検出情報を生成し得る。実施形態では、顔認識モジュール３３２は、例えば、クライアントアプリケーション１１２および／またはメディアビューア１１８を通して、ユーザが顔検出を手動で支援することを可能にし得る。そのような実施形態では、顔検出段階の動作は、上記で説明される、図２の顔検出モジュール２２０の手動またはユーザ支援動作と同様である。
The face detection step of the face recognition module 332 includes automatically detecting a face in the image of the
顔認識モジュール３３２の顔認識段階は、検出された顔を識別することを含む。顔認識モジュール３３２の動作は、以前に認識された顔画像のうちの１つ以上に対して、検出された顔の比較を行うことを含み得る。例えば、以前に認識された顔は、顔認識モジュール３３２によってアクセス可能な１つ以上の顔画像データベース（図示せず）の中に記憶され得る。この説明で挙げられる関連技術の当業者であれば、顔検出および認識のためのいくつかの方法のうちのいずれか１つが使用され得ることを理解するであろう。そのような方法の一実施例は、Ｌｕｉ ａｎｄ Ｃｈｅｎ，“Ｖｉｄｅｏ−ｂａｓｅｄ Ｆａｃｅ Ｒｅｃｏｇｎｉｔｉｏｎ Ｕｓｉｎｇ Ａｄａｐｔｉｖｅ Ｈｉｄｄｅｎ Ｍａｒｋｏｖ Ｍｏｄｅｌｓ”，２００１，ＣＶＰＲで説明されている。 The face recognition stage of the face recognition module 332 includes identifying the detected face. The operation of the face recognition module 332 may include performing a detected face comparison against one or more of the previously recognized face images. For example, previously recognized faces may be stored in one or more face image databases (not shown) accessible by the face recognition module 332. One of ordinary skill in the relevant art listed in this description will understand that any one of several methods for face detection and recognition can be used. One example of such a method is described in Lui and Chen, “Video-based Face Recognition Using Adaptive Hidden Markov Models”, 2001, CVPR.
（２．目印およびオブジェクト／場面認識）
目印認識モジュール３３４は、目印を有するメディアデータ１２０／３０１の画像の部分を検出し、目印を識別する。目印認識モジュール３３４の一実施例は、その全体で参照することにより本明細書に組み込まれる、「Ａｕｔｏｍａｔｉｃ Ｄｉｓｃｏｖｅｒｙ ｏｆ Ｐｏｐｕｌａｒ Ｌａｎｄｍａｒｋｓ」と題された、共有に係る米国特許出願第１２／１１９，３５９号で説明されている。目印認識モジュール３３４は、例えば、目印を認識するために、視覚クラスタ化を使用し得る。
(2. Marks and object / scene recognition)
The
オブジェクト認識モジュール３３６は、画像によって表される場面内のオブジェクトを認識するために、メディアデータ１２０／３０１の画像を解釈する。例えば、メディアデータ１２０／３０１は、場面の画像を含み得、オブジェクト認識モジュール３３６は、その画像の中のオブジェクトを認識し得る。別の実施例では、オブジェクト認識モジュール３３６は、ビデオの１つ以上のフレームの中のオブジェクトを認識し得る。オブジェクト認識モジュール３３６は、当技術分野で公知であるような任意の種類のオブジェクト認識モジュールであり得る。一般に、オブジェクト認識モジュール３３６の動作は、顔認識モジュール３３２のように、２つのステップを含み得る。第１に、オブジェクトを含む画像の一部分が検出される。第２に、画像の一部分は、オブジェクトを検出する分類子機能等の機能に入力される。この説明で挙げられる関連技術の当業者であれば、オブジェクト認識モジュール３３６が、異なる種類のオブジェクトを検出するように構成される他の認識モジュールを含む、追加の従属構成要素を含み得ることを認識するであろう。
The object recognition module 336 interprets the image of the
いくつかの実施形態では、オブジェクト認識モジュール１２０は、特定のオブジェクトを選択し、１組の既知のオブジェクトの中のオブジェクトと照合するために、隠れマルコフモデルを使用し得る。メディアデータ１０４がビデオである場合において、オブジェクト認識モジュール１２０は、１つ以上のフレームにわたってオブジェクトを追跡し、次いで、追跡されたフレームに基づいてオブジェクトを認識し得る。
In some embodiments, the
顔認識モジュール３３２を使用して顔を、目印認識モジュール３３４を使用して目印を、オブジェクト認識モジュール３３６を使用してオブジェクトを認識することによって、メディア入力モジュール３３０は、メディアコンテンツデータ３０６を決定する。メディアコンテンツデータ３０６は、例えば、メディアの集合体、ならびにメディアの集合体のコンテンツに対応する顔、目印、および／またはオブジェクトのメタ情報を含み得る。メディアコンテンツデータ３０６を決定するためにメディアデータ１２０／３０１のコンテンツを使用することに加えて、メディア入力モジュール３３０は、実施形態に従って、メタデータ抽出器モジュール３３８を使用して、メディアデータ１２０／３０１から直接メタデータを抽出し得る。
The media input module 330 determines the
（３．メタデータ抽出）
メタデータ抽出器モジュール３３８は、例えば、メディアデータ１２０／３０１に含まれるメタデータを抽出し得る。メディアデータ１２０／３０１は、例えば、メディアファイルの集合体であり得、各メディアファイルは、上記で説明されるように、メタデータを含み得る。実施形態では、メディアファイルは、ＪＰＥＧまたはＴＩＦＦ等の写真画像ファイルであり得る。写真画像ファイルは、画像についてのデータとともにＥＸＩＦヘッダを含み得る。ＥＸＩＦヘッダは、例えば、写真が撮影された時等のデータを含み得る。例えば、クライアントデバイス３１０は、ＧＰＳセンサ等の位置センサを含み得る。クライアントデバイス３１０によって生成される画像ファイルは、各写真が撮影された場所を、それらのＥＸＩＦヘッダに含み得る。例えば、ＥＸＩＦヘッダは、写真が撮影された場所に対応する、緯度および経度値を有し得る。このようにして、メタデータ抽出器モジュール３３８は、メディアコンテンツデータ３０６に含まれるべきメタデータをメディアデータ１２０／３０１から読み出す。
(3. Metadata extraction)
The metadata extractor module 338 may extract metadata included in the
顔認識モジュール３３２、目印認識モジュール３３４、オブジェクト認識モジュール３３６、およびメタデータ抽出器モジュール３３８の実施形態は、ソフトウェア、ファームウェア、ハードウェア、またはそれらの任意の組み合わせで実装することができる。顔認識モジュール３３２、目印認識モジュール３３４、オブジェクト認識モジュール３３６、およびメタデータ抽出器モジュール３３８、またはそれらの複数部分の実施形態はまた、コンピュータ、ワークステーション、埋め込みシステム、ネットワークデバイス、モバイルデバイス、あるいは本明細書で説明される機能性を実行することが可能な他の種類のプロセッサまたはコンピュータシステムを含むが、それらに限定されない、任意の種類の処理デバイス上で作動するように実装することもできる。
Embodiments of the face recognition module 332, the
（４．画像グループ化）
メディアコンテンツデータ３０６を使用して、メディア共有モジュール３４０は、異なるユーザからのメディアの集合体を自動的にグループ化し、メディアのコンテンツおよびユーザ間の関連に基づいて、ユーザ間でグループ化されたメディアを共有する。例えば、メディア入力モジュール３３０は、異なる画像、おそらく画像のアルバム全体を受信または獲得し得、各画像および／またはアルバムは、異なるユーザに関連付けられている。ユーザ自身は、例えば、ソーシャルネットワーキングサイト上で指定された共有選好を介して、ユーザが、相互とリンクされる、または関連付けられる、例えば、同じソーシャルネットワークまたはソーシャルグラフのメンバーとして、相互に関連付けられ得る。実施例では、各ユーザは、ソーシャルネットワーキングサイトに記憶されたメンバープロファイル情報を有し得る。加えて、各ユーザのプロファイルは、メディア共有、またはユーザが他のユーザに提供するアクセス権および特権を特定する、共有選好を有し得る。共有選好は、ユーザがメディアを共有することを選択する他のユーザを識別するために使用され得る。例えば、第１のユーザの共有選好は、第２のユーザを識別し得、第１および第２のユーザは、相互に関連付けられる。一般に、相互に関連付けられるユーザは、メディア共有特権を相互に提供し、各ユーザは、他方のユーザに関連付けられる画像へのアクセスが許可される。したがって、相互に関連付けられるユーザは、それらの共有選好を介して相互を識別し得る。この説明で挙げられる関連技術の当業者であれば、共有選好をユーザに関連付けるため、および異なるユーザを相互に関連付けるための任意の数の既知の方法を認識するであろう。
(4. Image grouping)
Using the
（ａ．アルバム分割）
メディア共有モジュール３４０は、各個別ユーザに関連付けられる画像を、ユーザ用の１つ以上のアルバムにグループ化するように、メディアコンテンツデータ３０６を自動的に解釈する。次いで、メディア共有モジュール３４０は、異なるユーザに対応するアルバムを１つ以上のイベントグループにグループ化するように、メディアコンテンツデータ３０６を自動的に解釈し、イベントグループは、異なるユーザに関連付けられる。次いで、メディア共有モジュール３４０は、ユーザ介入なしで、それらのソーシャルグラフおよび相互との関連に基づいて、異なるユーザ間でイベントグループを自動的に共有する。実施形態では、メディア共有モジュール３４０はまた、利用可能なイベントグループの通知をユーザに送信する。
(A. Album division)
The media sharing module 340 automatically interprets the
メディア共有モジュール３４０は、アルバム分割モジュール３４２と、イベントクラスタ化モジュール３４４と、共有マネージャ３４６と、通知マネージャ３４８とを含む。実施形態では、メディア共有モジュール３４０は、アルバムデータベース３５０、イベントデータベース３６０、およびソーシャルグラフデータベース３７０のうちの各々に、それぞれ、通信ライン３０７、３０８、および３０９を介して通信可能に連結される。
The media sharing module 340 includes an album division module 342, an event clustering module 344, a sharing manager 346, and a
アルバム分割モジュール３４２は、メディアコンテンツデータ３０６に含まれるメディアコンテンツデータ情報に基づいて、メディアの集合体を１つ以上のアルバムにグループ化することによって、メディア入力モジュール３３０からのメディアの集合体を分割する。アルバム分割モジュール３４２は、メディアコンテンツデータ３０６を使用して、メディアの集合体の各画像に対応するメディアコンテンツデータを決定する。各画像の決定されたメディアコンテンツデータに基づいて、アルバム分割モジュール３４２は、メディアの集合体を１つ以上のアルバムに分割する。
The album division module 342 divides the collection of media from the media input module 330 by grouping the collection of media into one or more albums based on the media content data information included in the
例えば、メディアコンテンツデータ３０６は、メディアの集合体の画像が捕捉された時および場所の時間および位置を（例えば、ＧＰＳ座標で）含み得る。集合体の各画像の決定された時間および場所に基づいて、アルバム分割モジュール３４２は、画像の集合体またはグループを、各アルバムが実質的に同様の時間および場所情報を有する画像を含む、１つ以上のアルバムに分割する。分割動作の精度、および分割されたアルバムの中の異なる画像間のコンテンツの相関を向上させるために、アルバム分割モジュール３４２は、それがメディアコンテンツデータ３０６から導出することができる限りの多くの情報に基づいて、メディアの集合体を分割する。例えば、アルバム分割モジュール３４２は、画像の集合体をアルバムに分割するために、顔認識情報、目印認識情報、オブジェクト認識情報、メタデータ、またはそれらの任意の組み合わせを使用し得る。
For example, the
実施形態では、アルバム分割モジュール３４２は、メディア入力モジュール３３０から受信される特定の画像または一群の画像と同様のメディアコンテンツデータを伴う画像を含む既存のアルバムについて、アルバムデータベース３５０を検索し得る。上記で説明される以前の実施例を使用して、アルバム分割モジュール３４２は、メディア入力モジュール３３０からの画像と実質的に同様の時間および場所情報を有する画像を含む、アルバムデータベース３５０の中の既存のアルバムを見つけ得る。この実施例では、アルバム分割モジュール３４２は、画像を既存のアルバムに追加する。検索基準（例えば、同様のメディアコンテンツデータを伴う画像）に合致する既存のアルバムが見つからない場合、アルバム分割モジュール３４２は、１つ以上の新しいアルバムを作成し得る。実施形態では、アルバム分割モジュール３４２は、新しいアルバムを記憶するためにアルバムデータベース３５０を使用し得る。アルバム分割モジュール３４２は、各アルバムを、一群の画像に関連付けられるユーザに関連付ける。
In an embodiment, album split module 342 may search
（ｂ．イベントクラスタ化および共有）
イベントクラスタ化モジュール３４４は、メディアコンテンツデータ３０６に含まれるメディアコンテンツデータ情報、および２人以上のユーザに関連付けられる共有選好に基づいて、アルバムを１つ以上のイベントグループにグループ化することによって、アルバム分割モジュール３４２によって分割されるアルバムをクラスタ化する。イベントクラスタ化モジュール３４４がアルバムをグループ化し、異なるアルバムが異なるユーザに関連付けられることを除いて、イベントクラスタ化モジュール３４４のクラスタ化動作は、アルバム分割モジュール３４２の分割動作と同様である。上記で論議されるように、異なるユーザは、互を識別する共有選好を介して、互に関連付けられ得る。また、上記で論議されるように、そのような選好は、どのユーザが特定のユーザに関連付けられるメディアにアクセスする特権を有するかを決定するために使用される。
(B. Event clustering and sharing)
The event clustering module 344 groups albums into one or more event groups based on media content data information included in the
イベントクラスタ化モジュール３４４は、共有選好および異なるユーザ間の関連を決定するために、共有マネージャ３４６を使用する。実施形態では、共有マネージャ３４６は、ソーシャルグラフデータベース３７０と通信可能に連結される。ソーシャルグラフデータベース３７０は、互に社会的関係を有する２人以上のユーザ間の任意の種類の関連を記憶し得る。そのような関連は、ユーザの共有選好を含み得、共有選好は、各ユーザが互に有するアクセス権または特権を特定する。共有マネージャ３４６およびソーシャルグラフデータベース３７０の実施形態は、例えば、１つ以上のソーシャルネットワーキングサイト、写真共有サイト、あるいは異なるユーザ間の関連または社会的つながりを可能にする他の同様の種類のサイトと一体化し得る。
Event clustering module 344 uses sharing manager 346 to determine sharing preferences and associations between different users. In an embodiment, share manager 346 is communicatively coupled to
実施形態では、共有マネージャ３４６は、ソーシャルグラフデータベース３７０から、ユーザの共有選好を含む、２人以上のユーザ間の記憶された関連を取り出す。メディアコンテンツデータ３０６と組み合わせた、ユーザに関する取り出された情報は、アルバムを１つ以上のイベントグループにクラスタ化するために、イベントクラスタ化モジュール３４４によって使用される。イベントグループがイベントクラスタ化モジュール３４４によってクラスタ化されると、共有マネージャ３４６は、イベントグループをユーザに関連付け、互のユーザの関連および各ユーザの個別共有選好に基づいて、ユーザにイベントグループへのアクセスを提供する。実施形態では、イベントデータベース３６０は、イベントグループとのユーザの関連を記憶するために使用され得る。
In an embodiment, the sharing manager 346 retrieves a stored association between two or more users, including user sharing preferences, from the
例えば、ソーシャルイベントに対応する、特定の時間および場所で捕捉された画像の第１のアルバムが、第１のユーザに関連付けられ得る。同じ時間および場所（すなわち、イベント）で捕捉された画像の第２のアルバムが、第２のユーザに関連付けられ得る。加えて、他のユーザに関連付けられる、そのイベントで捕捉された画像の他のアルバムもあり得る。この実施例では、イベントクラスタ化モジュール３４４は、どのユーザの関連であるか、およびどのユーザの共有選好であるかを決定するために、共有マネージャ３４６を使用し得る。共有マネージャ３４６が第１および第２のユーザの間の関連を識別し、各ユーザの共有選好が、共有特権を相互に提供する場合、イベントクラスタ化モジュール３４４は、例えば、第１および第２のアルバムを、同じ時間および場所で捕捉された画像のイベントグループにクラスタ化し得る。この実施例でのイベントグループは、両方のユーザに関連付けられる画像を含む。イベントグループがクラスタ化モジュール３４４によって作成されると、クラスタ化モジュール３４４は、イベントグループをイベントデータベース３６０の中に記憶し得る。次いで、共有マネージャ３４６は、第１および第２のユーザにイベントグループへのアクセスを提供し得る。
For example, a first album of images captured at a particular time and location that corresponds to a social event may be associated with the first user. A second album of images captured at the same time and place (ie, event) may be associated with the second user. In addition, there may be other albums of images captured at that event that are associated with other users. In this example, the event clustering module 344 may use the sharing manager 346 to determine which users are relevant and which users are sharing preferences. If the sharing manager 346 identifies an association between the first and second users and each user's sharing preferences provide sharing privileges to each other, the event clustering module 344 may, for example, Albums can be clustered into event groups of images captured at the same time and place. The event group in this example includes images associated with both users. Once the event group is created by the clustering module 344, the clustering module 344 may store the event group in the
実施形態では、通知マネージャ３４８は、通知（例えば、図１の通知１３０）をイベントグループの１人以上のユーザに自動的に送信するように構成される。実施形態では、通知は、イベントグループへのアクセスリンクを含む。例えば、アクセスリンクは、ユーザが自動的にイベントグループに方向付けられることを選択できる、ユニフォームリソースロケータ（ＵＲＬ）アドレスの形態のウェブベースの場所アドレスであり得る。再び図１を参照すると、イベントグループの画像は、例えば、クライアントアプリケーション１１２、メディアビューア１１８、またはユーザがメディアを閲覧するために使用することができる同様の種類のアプリケーションを介して、アクセス可能であり得る。
In an embodiment, the
実施形態では、イベントクラスタ化モジュール３４４は、実質的に同様のコンテンツデータに基づいて新たにクラスタ化されたイベントグループを追加するために、既存のイベントグループについてイベントデータベース３６０を検索し得る。イベントクラスタ化モジュール３４４は、イベントデータベース３６０の中で見つかった場合、クラスタ化されたイベントグループを合致するイベントグループに追加し得る。代替として、イベントクラスタ化モジュール３４４は、合致するイベントグループがイベントデータベース３６０の中で見つからない場合に、クラスタ化されたイベントグループのためにイベントデータベース３６０の中に新しいイベントグループを作成し得る。
In an embodiment, event clustering module 344 may search
（ｃ．リアルタイムイベント共有）
実施形態では、共有マネージャ３４６は、メディアコンテンツデータ３０６のコンテンツ情報に基づいて、イベントグループへのリアルタイムアクセスおよび共有を自動的に可能にし得る。例えば、共有マネージャ３４６は、メディアコンテンツデータ３０６から決定される時間および場所メタデータをソーシャルグラフデータベース３７０からのソーシャルグラフ情報と組み合わせて使用することにより、時間、場所、およびソーシャルグラフ情報に基づいて、イベントグループへのリアルタイムアクセスおよび共有を可能にし得る。
(C. Real-time event sharing)
In an embodiment, sharing manager 346 may automatically enable real-time access and sharing to event groups based on content information in
共有マネージャ３４６を介したリアルタイム共有の実施例を例証するために、イベントの画像がイベント中に第１のユーザおよび第２のユーザによって捕捉されると仮定されたい。イベントクラスタ化モジュール３４４は、例えば、第１および第２のユーザによってイベント中に捕捉されるメディアのコンテンツに基づいて、イベントに対するイベントグループを自動的に生成し得る。メディアコンテンツデータ３０６は、例えば、画像が捕捉された時および場所の時間および位置を含み得る。この実施例では、共有マネージャ３４６は、第１および第２のユーザが互に関連付けられ、合致する共有選好を有する（例えば、第１のユーザが、第２のユーザのためのメディア共有特権を許可し、その逆も同様である）と決定し得る。時間および場所情報に基づいて、共有マネージャ３４６は、両方のユーザが同じイベントにいることを決定し、その結果として、第１および第２のユーザをそのイベントグループに自動的に関連付け、ユーザにそのイベントグループへのアクセスを提供し始める。通知マネージャ３４８は、例えば、イベントグループへのアクセスリンクを含む通知を第１および第２のユーザに送信し得る。第１および第２のユーザは、例えば、彼らのそれぞれのモバイルデバイス上で、通知を受信し得る。次いで、第１および第２のユーザは、例えば、彼らのそれぞれのモバイルデバイスを使用して（例えば、図１のクライアントアプリケーション１１２またはメディアビューア１１８の中で）、イベントグループの画像を閲覧することが可能であり得る。これは、第１および第２のユーザが、イベント中に互の間でメディアを自動的かつ効率的に共有することを可能にする。
To illustrate an example of real-time sharing via the sharing manager 346, assume that an image of the event is captured by the first user and the second user during the event. The event clustering module 344 may automatically generate an event group for the event based on, for example, the content of the media captured during the event by the first and second users.
アルバム分割モジュール３４２、イベントクラスタ化モジュール３４４、共有マネージャ３４６、および通知マネージャ３４８の実施形態は、ソフトウェア、ファームウェア、ハードウェア、またはそれらの任意の組み合わせで実装することができる。アルバム分割モジュール３４２、イベントクラスタ化モジュール３４４、共有マネージャ３４６、および通知マネージャ３４８、またはそれらの複数部分の実施形態はまた、コンピュータ、ワークステーション、埋め込みシステム、ネットワークデバイス、モバイルデバイス、あるいは本明細書で説明される機能性を実行することが可能な他の種類のプロセッサまたはコンピュータシステムを含むが、それらに限定されない、任意の種類の処理デバイス上で作動するように実装することもできる。
Embodiments of album partition module 342, event clustering module 344, share manager 346, and
アルバムデータベース３５０、イベントデータベース３６０、およびソーシャルグラフデータベース３７０は、当業者に公知である任意の種類のデータ記憶装置であり得る。実施例では、データ記憶装置は、ＯＲＡＣＬＥデータベースまたは当業者に公知である他のデータベース等のデータベース管理システムであり得る。アルバムデータベース３５０およびイベントデータベース３６０は、画像またはビデオに対応するメタデータおよび他のコンテンツ情報を含む、メタ情報に加えて、（例えば、それぞれ、アルバムまたはイベントグループに整理された）画像またはビデオ等の任意の種類のメディアを記憶し得る。
再び図１を参照すると、メディア共有サービス１５２はサーバ１５０に関して示されているが、メディア共有サービス１５２およびその構成要素（メディア入力モジュール３３０およびメディア共有モジュール３４０）またはそれらの複数部分の実施形態は、例えば、サーバ１５０等の単一のサーバ上で、あるいは、例えば、分散またはクラスタ化サーバ環境内のサーバ１５０、１６０、および１７０等の複数のサーバにわたって、実装できることに留意されたい。さらに、メディア入力モジュール３３０の従属構成要素（顔認識モジュール３３２、目印認識モジュール３３４、オブジェクト認識モジュール３３６、およびメタデータ抽出器モジュール３３８）、またはそれらの複数部分は、単一のサーバ上で、または複数のサーバにわたって実装することができる。同様に、メディア共有モジュール３４０の従属構成要素（アルバム分割モジュール３４２、イベントクラスタ化モジュール３４４、共有マネージャ３４６、および通知マネージャ３４８）、またはそれらの複数部分は、単一のサーバ上で、または複数のサーバにわたって実装することができる。
Referring again to FIG. 1,
（ＩＩＩ．方法）
（Ａ．ユーザ間の自動メディア共有）
図４Ａおよび４Ｂは、ユーザ間でメディアを自動的に共有するための方法４００の過程フローチャートである。方法４００は、ステップ４０２、４０４、４０６、４０８、４１０、４１２、４１４、４１６、４１８、４２０、４２２、４２４、および４２６を含む。方法４００の利益は、ユーザが相互の間でメディアを共有するためのより高速で効率的な自動方法を含むが、それに限定されない。また、方法４００は、画像を手動でアルバムにグループ化し、記述子（例えば、アルバム題名）をアルバムに追加し、アルバムを他のユーザと共有しなければならないというユーザの負担を軽減する。
(III. Method)
(A. Automatic media sharing between users)
4A and 4B are process flowcharts of a
説明を容易にするために、上記で説明されるような図１のシステム１００および図３のシステム３００は、方法４００を説明するために使用されるが、それに限定されることを目的としていない。再び図３を参照すると、方法４００は、例えば、メディア共有サービス１５２を介してサーバ１５０によって行われ得る。方法４００は、図４Ａのステップ４０２で始まり、第１のユーザに関連付けられる第１の画像の集合体を受信することを含むステップ４０４へ進む。ステップ４０４は、例えば、メディア入力モジュール３３０によって行われ得る。実施形態では、第１の画像の集合体は、例えば、クライアントデバイス１１０等の第１のユーザのクライアントデバイスを介して、第１のユーザから直接受信され得る。別の実施形態では、第１の集合体は、後に取り出すために、例えば、メディアデータベース３２０等の１つ以上のメディアデータベースの中に記憶され得る。例えば、第１の画像の集合体は、例えば、上記で説明されるように、メディアデータベース３２０が連結され得る、写真共有サイトを介して、第１のユーザによって以前にアップロードされていてもよい。また、上記で説明されるように、第１の集合体の画像は、デジタル写真、デジタルビデオからのフレーム、またはそれらの任意の組み合わせであり得る。
For ease of explanation, the
方法４００は、第１の集合体の中の各画像に対する第１のコンテンツデータを決定することを含むステップ４０６へ進む。ステップ４０６は、例えば、顔認識モジュール３３２、目印認識モジュール３３４、オブジェクト認識モジュール３３６、メディア抽出器モジュール３３８、またはそれらの任意の組み合わせによって行われ得る。上記で説明されるように、第１のコンテンツデータは、第１の画像の集合体内の認識された顔、目印、および／またはオブジェクトを備えている情報を含み得る。また、上記で説明されるように、第１のコンテンツデータは、加えて、画像が捕捉された時および場所の時間および位置を含むが、それらに限定されない、第１の集合体から抽出されたメタデータを含み得る。
次いで、方法４００は、第１の集合体を第１の組の１つ以上のアルバムに分割することを含むステップ４０８へ進む。ステップ４０８は、例えば、メディア共有モジュール３４０のアルバム分割モジュール３４２によって行われ得る。上記で説明されるように、第１の集合体は、ステップ４０６における決定された第１のコンテンツデータに基づいて分割される。
The
方法４００のステップ４１０、４１２、および４１４は、それぞれ、上記のステップ４０４、４０６、および４０８と同様である。しかしながら、ステップ４１０、４１２、および４１４は、第２のユーザに関連付けられる第２の画像の集合体に対応する。したがって、ステップ４１０では、第２のユーザに関連付けられる第２の画像の集合体が受信される。ステップ４０４における第１の画像の集合体のように、第２の集合体は、第２のユーザから直接受信され、または、例えば、メディアデータベース３２０等のメディアデータベースからアクセスされ得る。ステップ４１０も、例えば、メディア入力モジュール３３０によって行われ得る。ステップ４１２では、第２の集合体の中の各画像に対する第２のコンテンツデータが決定される。ステップ４１２は、例えば、顔認識モジュール３３２、目印認識モジュール３３４、オブジェクト認識モジュール３３６、メディア抽出器モジュール３３８、またはそれらの任意の組み合わせによって行われ得る。ステップ４１４では、第２の集合体は、第２のコンテンツデータに基づいて、第２の組の１つ以上のアルバムに分割される。ステップ４１４は、例えば、アルバム分割モジュール３４２によって行われ得る。
実施形態では、第１および第２の組の１つ以上のアルバムは、それぞれ、第１および第２のユーザに関連付けられる。上記で説明されるように、第１および第２のユーザはまた、互に関連付けられ得る。加えて、第１および第２のユーザは、それぞれ、第１および第２の共有選好を有し得る。各ユーザの共有選好は、ユーザが他方のユーザに提供するメディア共有権および特権を識別する。例えば、第１のユーザは、第１のユーザに関連付けられるメディアへのアクセス権を第２のユーザに提供することによって、第２のユーザとメディアを共有することを可能にする共有選好を有し得る。第２のユーザも、第１のユーザに対応する同様の共有選好を有し得る。 In an embodiment, the first and second sets of one or more albums are associated with first and second users, respectively. As described above, the first and second users can also be associated with each other. In addition, the first and second users may have first and second shared preferences, respectively. Each user's sharing preferences identify the media sharing rights and privileges that the user provides to the other user. For example, a first user has a sharing preference that allows a second user to share media by providing the second user with access to the media associated with the first user. obtain. The second user may also have similar sharing preferences corresponding to the first user.
第１および第２の集合体が、それぞれの第１および第２の組の１つ以上のアルバムに分割されると、方法４００は、ステップ４１６へ進む。ステップ４１６では、第１および第２の組が、第１および第２のコンテンツデータと、第１および第２のユーザの共有選好に従って、イベントグループにクラスタ化される。ステップ４１６は、例えば、共有マネージャ３４６と組み合わせてイベントクラスタ化モジュール３４４によって行われ得る。
Once the first and second collections are divided into one or more sets of one or more albums, the
イベントグループがステップ４１６において作成された後、方法４００は、第１および第２のユーザにイベントグループへのアクセスを提供することを含むステップ４１８へ進む。方法４００で示されていないが、第１および第２のユーザも、実施形態によれば、イベントグループに関連付けられ得る。加えて、イベントグループと第１および第２のユーザの任意の関連とは、図３に図示されるように、例えば、通信ライン３０８を介して、イベントクラスタ化モジュール３４４によってイベントデータベース３６０に記憶され得る。ステップ４１８は、例えば、共有マネージャ３４６によって行われ得る。実施形態では、方法４００は、イベントグループの通知を第１および第２のユーザに送信することを含む、追加のステップ（図示せず）も含み得る。通知は、上記で説明されるように、イベントグループへのアクセスリンクを含み得る。この随意的なステップは、例えば、通知マネージャ３４８によって行われ得る。
After the event group is created in
次に、方法４００は、イベントグループが対応する特定のイベントからの場面を表す、１つ以上の新しい画像を受信することを含む、図４Ｂのステップ４２０へ進む。例えば、ステップ４１６において作成されたイベントグループは、特定のイベント中に第１および第２のユーザによって捕捉された画像を含み得る。イベントグループが作成された後に、第１および／または第２のユーザは、そのイベントからまた捕捉された新しい画像を送信し得る。新しい画像は、例えば、イベント中にモバイルデバイスから、第１および／または第２のユーザによって送信され得、あるいは、例えば、イベント後にメディア共有サイトにアップロードされ得る。前者のシナリオでは、ステップ４２０は、ユーザの一方または両方から直接画像を受信することを含む。しかしながら、後者のシナリオでは、ステップ４２０は、メディア共有サイトと連結または一体化したメディアデータベースからのアップロードされた画像にアクセスすることを含む。メディアデータベースは、例えば、図３のメディアデータベース３２０であり得る。
The
さらなるシナリオでは、イベントからの第１の組の新しい画像は、第１のユーザから直接受信され得、イベントからの第２の組の新しい画像は、第２のユーザによってメディア共有サイトにアップロードされていてもよい。このシナリオでは、ステップ４２０は、新しい画像を直接受信し、メディアデータベースからの新しい画像にアクセスすることを含む。いずれか一方のユーザは、画像を直接送信すること、または画像をメディア共有サイトにアップロードすることを選択し得ることに留意されたい。ステップ４２０は、例えば、図３のメディア入力モジュール３３０によって行われ得る。
In a further scenario, a first set of new images from the event may be received directly from the first user, and a second set of new images from the event has been uploaded to the media sharing site by the second user. May be. In this scenario,
新しい画像が受信またはアクセスされた場合、方法４００は、受信またはアクセスされた新しい画像でイベントグループを更新することを含むステップ４２２へ進み、第１および第２のユーザに更新されたイベントグループへのアクセスを提供することを含むステップ４２４へ進む。第１および第２のユーザに更新されたイベントグループへのアクセスを提供することは、第１および第２のユーザの間でイベントグループを共有することを可能にする。新しい画像自体が、ユーザのうちの一方のみによって最初に送信またはアップロードされたか否かにかかわらず、第１および第２のユーザの両方には、イベントグループへのアクセスが提供されることに留意されたい。ステップ４２２は、例えば、イベントクラスタ化モジュール３４４によって行われ得る。ステップ４２４は、例えば、共有マネージャ３４６によって行われ得る。実施形態では、方法４００は、更新されたイベントグループの通知を第１および第２のユーザに送信するという追加のステップ（図示せず）を含み得る。このステップは、例えば、通知マネージャ３４８によって行われ得る。新しい画像が受信もアクセスもされない場合、方法４００は、ステップ４２６で終了する。
If a new image is received or accessed, the
実施形態では、ステップ４２０、４２２、および４２４は、シャッタのクリックを介して、第１および第２のユーザの間の自動メディア共有を可能にする。例えば、ステップ４２０において受信される新しい画像は、統合デジタルカメラを伴うコンピュータデバイス（例えば、図３のクライアントデバイス１１０）、または、例えば、ＥＹＥ−ＦＩカードを伴うデジタルカメラ等の独立型画像捕捉デバイス（例えば、図３のクライアントデバイス３１０）上で実行するアプリケーション（例えば、クライアントアプリケーション１１２）を使用して画像を捕捉したユーザに由来し得る。画像が受信されると、イベントグループは、ユーザ介入なしで、ステップ４２２において新しい画像で自動的に更新され、更新されたイベントグループは、ユーザ介入なしで、ステップ４２４においてユーザ間で自動的に共有される。
In an embodiment, steps 420, 422, and 424 allow automatic media sharing between the first and second users via a shutter click. For example, the new image received in
方法４００の１つの利点は、画像および画像の集合体を手動で標識化およびグループ化するようにユーザに要求することなく、（ステップ４２４で）ユーザ間のメディアの自動共有を可能にすることである。これは、メディアを共有するためのより高速で容易かつ効率的なユーザ体験につながり、メディアを共有することをより容易にすることによって、メディアを捕捉するユーザに利益をもたらす。さらに、ユーザによって捕捉されるメディアが共有される可能性を増加させるので、ユーザに関連付けられる他のユーザも、利益を享受する。
One advantage of the
（Ｂ．クライアントアプリケーション）
図５は、クライアントアプリケーションを使用してメディアを送信するための例示的な方法５００のフローチャートである。説明を容易にするために、図２のクライアントアプリケーション１１２および図３のシステム３００が、方法５００の記述を容易にするために使用される。さらに、説明を容易にするために、方法５００は、例えば、デジタルカメラ等の統合画像捕捉デバイスを伴うモバイルデバイス（例えば、図１のクライアントデバイス１１０）との関連で説明される。しかしながら、本明細書の説明に基づいて、当業者であれば、カメラまたは他の画像捕捉デバイスを有する任意の種類のコンピュータデバイス上で実行することができる他のクライアントアプリケーション内に、方法５００を組み込むことができると認識するであろう。
(B. Client application)
FIG. 5 is a flowchart of an
方法５００は、ステップ５０２、５０４、５０６、５０８、５１０、５１２、５１４、および５１６を含む。方法５００は、ステップ５０２において始まり、１人以上の個人がいる場面を表す画像を捕捉することを伴うステップ５０４へ進む。画像は、デジタル写真またはデジタルビデオの１つ以上のビデオフレームであり得る。ステップ５０４は、（例えば、ユーザがシャッタをクリックする時に）例えば、画像キャプチャモジュール２１０によって行われ得る。画像キャプチャモジュール２１０によって捕捉される画像に加えて、方法５００は、すでに捕捉され、ローカルメモリ（例えば、クライアントデバイス１１０のローカルメモリ１１６）の中に記憶された画像を使用することもできる。ステップ５０６では、画像の中の各個人の顔が、上記で説明されるように検出される。ステップ５０６は、上記で説明される顔検出モジュール２２０によって行われ得る。次いで、方法５００は、検出された顔の識別情報を取得することを含むステップ５０８へ進む。
一実施形態では、ステップ５０８において識別情報を取得することは、ユーザが画像の中で検出される顔を識別できるようにすることを含む。ユーザは、顔に対応する個人の識別情報を入力することによって、顔を識別し得る。そのような識別情報は、識別されている個人の名前および／または連絡先情報（例えば、Ｅメールアドレス）を含み得るが、それに限定されない。例えば、捕捉された画像は、クライアントアプリケーション（例えば、クライアントアプリケーション１１２）を実行するコンピュータデバイス（例えば、図１のクライアントデバイス１１０）に連結されるディスプレイ上に表示され得る。加えて、画像の中の検出された顔は、顔の境界を定めるように顔の周囲に描かれた仮想ボックスとともに、ディスプレイ上に表示され得る。ユーザは、例えば、タッチスクリーンまたはキーボード（例えば、デバイス入力１１４）等のユーザ入力デバイスを使用して、名前および連絡先情報を入力し得る。ステップ５０８のこの実施形態は、例えば、上記で説明されるユーザインターフェースモジュール２４０によって行われ得る。
In one embodiment, obtaining identification information at
別の実施形態では、ステップ５０８において識別情報を取得することは、例えば、上記で説明されるようにクライアントアプリケーション１１２によってアクセス可能なローカルメモリから（例えば、ローカルメモリ１１６の中）、各検出された顔に合致する記憶された顔画像を取り出すことを含む。別の実施例では、記憶された顔画像は、例えば、ネットワーク１４０上でクライアントアプリケーション１１２によってアクセス可能であり得る、顔画像データベース（図示せず）等の遠隔場所から、ステップ５０８において取り出され得る。記憶された顔画像は、顔画像に対応する個人の識別に対する識別情報を含む、独自のメタデータを含むこともできる。例えば、識別情報は、名前および連絡先情報を含み得る。したがって、この実施形態では、ステップ５０８は、もはや検出された顔の識別情報を提供するようにユーザに要求しなくなる。この実施形態の利点は、さらなるユーザ介入なしで、方法５００が続行することを可能にすることである。ステップ５０８のこの実施形態は、例えば、上記で説明されるメディア共有サービス１５２の顔認識モジュール３３２等の顔認識モジュールと組み合わせて、例えば、顔検出モジュール２２０によって行われ得る。
In another embodiment, obtaining the identification information at
検出された顔が識別されると、方法５００は、検出された顔情報および識別情報（例えば、名前および連絡先情報）を画像に関連付けることを伴うステップ５１０へ進む。そのような情報は、メタデータとして画像に関連付けられ得る。随意的なステップ５１２では、画像が捕捉された時間および画像が捕捉された場所を含むが、それらに限定されない、追加のメタデータが、画像に関連付けられ得る。例えば、場所情報は、クライアントアプリケーションを実行するデバイスがＧＰＳ受信機を含む場合のみ利用可能であり得る。ステップ５１０および５１２は、例えば、メタデータ挿入モジュール２３０によって行われ得る。
Once the detected face is identified, the
メタデータ情報が捕捉された画像に関連付けられた後に、方法５００は、メタデータ情報を含む画像を、例えば、図１および３のメディア共有サービス１５２等のメディア共有サービスに送信することを伴うステップ５１４へ進む。送信された画像は、例えば、図３に示されるメディア共有サービス１５２のメディア入力モジュール３３０によって受信され得る。ステップ５１４は、例えば、画像転送モジュール２５０によって行われ得る。方法５００は、画像が送信されるとステップ５１６で終了する。
After the metadata information is associated with the captured image, the
特に方法４００と組み合わせた、方法５００の１つの利点は、ユーザが、最小限のステップを用いて、高速かつ容易な方法でメディアを自動的に共有できるようにすることである。メディアは、（ステップ５０４で）単純にシャッタをクリックすることによってユーザによって共有されることができる。
One advantage of the
（Ｃ．アルバム分割）
図６は、画像をアルバムにグループ化するための例示的な方法６００の実施形態のフローチャートである。方法６００は、ステップ６０２、６０４、６０６、６０８、６１０、６１２、６１４、および６１６を含む。方法６００は、ステップ６０２において始まり、ユーザに関連付けられる画像を受信することを含むステップ６０４へ進む。ステップ６０４は、例えば、図３のメディア入力モジュール３３０によって行われ得る。画像を受信すると、方法６００は、画像に対するコンテンツデータを決定することを含むステップ６０６へ進む。画像コンテンツデータは、顔認識情報、目印認識情報、メタデータ情報（例えば、時間および場所情報）、および任意の他の種類の画像コンテンツ情報を含み得るが、それらに限定されない。ステップ６０６は、例えば、顔認識モジュール３３２、目印認識モジュール３３４、オブジェクト認識モジュール３３６、メタデータ抽出器モジュール３３８、またはそれらの任意の組み合わせを含む、メディア入力モジュール３３０の従属構成要素によって行われ得る。
(C. Album division)
FIG. 6 is a flowchart of an embodiment of an
方法６００は、画像コンテンツデータに基づいて、該当する場合、合致するアルバムについて、ユーザの既存のアルバムを検索することを含むステップ６０８へ進む。既存のアルバムが、受信された画像と実質的に同様のコンテンツデータを伴う画像を含む場合に、既存のアルバムは合致と見なされ得る。この説明で挙げられる関連技術の当業者であれば、合致するアルバムを効率的に検索するために、検索のためのいくつかのアプローチのうちのいずれか１つが使用され得ることを理解するであろう。１つのそのようなアプローチの実施例は、画像コンテンツデータの特質のうちの１つに対応して、ユーザアルバムを記憶するために使用されるデータベース（例えば、図３のアルバムデータベース３５０）の中で、ローカルインデックスを作成することを含む。例えば、アルバムの終了タイムスタンプに対応するインデックスが作成され得る。そのようなタイムスタンプインデックスは、何らかの所定の閾値を引いた、画像タイムスタンプ（すなわち、画像が捕捉された時間）から、データベースの中のテーブルの端までの範囲をスキャンするために、使用することができる。次いで、スキャンから生成される候補アルバムは、例えば、場所情報等の画像コンテンツデータの残りの特質によって、フィルタにかけることができる。このアプローチ例の利点は、検索するアルバムの数を削減することである。
The
合致するアルバムがステップ６０８で見つかった場合、方法６００は、画像が合致するアルバムに追加されるステップ６１０へ進む。代替として、合致するアルバムがステップ６０８で見つからない場合、方法６００は、新しいアルバムが画像のために作成されるステップ６１２へ進む。ステップ６０８、６１０、６１２、および６１４は、例えば、図３に示されるメディア共有モジュール３４０のアルバム分割モジュール３４２によって行われ得る。ステップ６１０または６１２の後に、方法６００はステップ６１４で終了する。
If a matching album is found at step 608, the
（Ｄ．イベントクラスタ化）
図７は、２人以上のユーザに関連付けられるアルバムをイベントグループにグループ化するための例示的な方法６００の実施形態のフローチャートである。方法７００は、ステップ７０２、７０４、７０６、７０８、７１０、７１２、７１４、および７１６を含む。方法７００は、ステップ７０２において始まり、各アルバムが異なるユーザに関連付けられる２つ以上のアルバムを受信することを含むステップ７０４へ進む。ステップ７０４は、例えば、図３のメディア入力モジュール３３０によって行われ得る。アルバムを受信すると、方法７００は、各アルバムに対するアルバムコンテンツデータを決定することを含むステップ７０６へ進む。アルバムコンテンツデータは、所与のアルバム内の画像に対応するコンテンツ情報を含む。そのようなアルバムコンテンツデータは、顔認識情報、目印認識情報、メタデータ情報（例えば、時間および場所情報）、および任意の種類のアルバムコンテンツ情報を含み得るが、それらに限定されない。ステップ７０６は、例えば、顔認識モジュール３３２、目印認識モジュール３３４、オブジェクト認識モジュール３３６、メタデータ抽出器モジュール３３８、またはそれらの任意の組み合わせを含む、メディア入力モジュール３３０の従属構成要素によって行われ得る。
(D. Event clustering)
FIG. 7 is a flowchart of an embodiment of an
方法７００は、アルバムコンテンツデータに基づいて、該当する場合、合致するアルバムについて、ユーザに関連付けられる既存のイベントグループを検索することを含むステップ７０８へ進む。方法６００のように、既存のイベントグループが、受信されたアルバムと実質的に同様のコンテンツデータを伴うアルバムを含む場合に、既存のイベントグループはアルバムに対する合致と見なされ得る。また、方法６００のように、この説明で挙げられる関連技術の当業者であれば、方法７００は、合致するイベントグループを効率的に検索するために、検索のためのいくつかのアプローチのうちのいずれか１つを使用し得ることを理解するであろう。例えば、方法６００における実施例のように、方法７００のための１つのアプローチは、イベントグループを記憶するために使用されるデータベース（例えば、図３のイベントデータベース３６０）の中で、ローカルインデックスを作成することを含む。
The
合致するイベントグループがステップ７０８で見つかった場合、方法７００は、アルバムが合致するイベントグループに追加される、ステップ７１０へ進む。代替として、合致するイベントグループがステップ７０８で見つからない場合、方法７００は、新しいイベントグループがアルバムのために作成されるステップ７１２へ進む。ステップ７０８、７１０、７１２、および７１４は、例えば、図３に示されるメディア共有モジュール３４０のイベントクラスタ化モジュール３４４によって行われ得る。ステップ７１０または７１２の後に、方法７００はステップ７１４で終了する。
If a matching event group is found at
実施形態では、方法７００はまた、提案されたイベントグループについてユーザに問い合わせを行うことを伴う、１つ以上の追加のステップ（図示せず）を含み得る。この実施形態では、方法７００は、例えば、ユーザの１つ以上のアルバムを含む、イベントグループのリストを表示することによって、１つ以上のイベントグループを提案し得る。リストは、例えば、ユーザによってアクセスされるメディア共有サイトで表示され得る。ユーザがイベントグループを選択すると、方法７００は、ユーザに関連付けられている１つ以上のアルバムを、ユーザ選択されたイベントグループに挿入することへ進む。ユーザに問い合わせを行い、ユーザの選択を受信することを伴う追加のステップは、例えば、図３の共有マネージャ３４６によって行われ得る。アルバムを選択されたイベントグループに追加することを伴うステップは、例えば、イベントクラスタ化モジュール３４４によって行われ得る。
In an embodiment, the
（ＩＶ．コンピュータシステム実装例）
図１−７に示される本開示の側面、あるいはそれらの任意の部分または機能は、ハードウェア、ソフトウェアモジュール、ファームウェア、その上に記憶された命令を有する有形コンピュータ可読媒体、またはそれらの組み合わせを使用して実装され得、１つ以上のコンピュータシステムまたは他の処理システムで実装され得る。
(IV. Computer system implementation example)
The aspects of the present disclosure shown in FIGS. 1-7, or any portion or function thereof, use hardware, software modules, firmware, tangible computer readable media having instructions stored thereon, or combinations thereof. Can be implemented as one or more computer systems or other processing systems.
図８は、本開示の実施形態またはそれらの複数部分が、コンピュータ可読コードとして実装され得る、コンピュータシステム例８００を図示する。例えば、図３のシステム３００は、ハードウェア、ソフトウェアモジュール、ファームウェア、その上に記憶された命令を有する有形コンピュータ可読媒体、またはそれらの組み合わせを使用して、コンピュータシステム８００で実装することができる。ハードウェア、ソフトウェア、またはそのようなものの任意の組み合わせは、図１−７のモジュールおよび構成要素のうちの任意のものを具現化し得る。
FIG. 8 illustrates an
プログラム可能な論理が使用される場合、そのような論理は、市販の処理プラットフォームまたは特殊用途デバイス上で実行し得る。当業者であれば、開示された主題の実施形態は、マルチコアマルチプロセッサシステム、ミニコンピュータ、メインフレームコンピュータ、分散機能とリンクまたはクラスタ化されたコンピュータ、ならびに事実上あらゆるデバイスに組み込まれ得る普及型または小型コンピュータを含む、種々のコンピュータシステム構成を用いて実践できることを理解し得る。 If programmable logic is used, such logic may execute on commercially available processing platforms or special purpose devices. For those skilled in the art, embodiments of the disclosed subject matter are multi-core multi-processor systems, minicomputers, mainframe computers, computers linked or clustered with distributed functions, as well as popular or It can be appreciated that various computer system configurations can be practiced, including small computers.
例えば、少なくとも１つのプロセッサデバイスおよびメモリが、上記の実施形態を実装するために使用され得る。プロセッサデバイスは、単一のプロセッサ、複数のプロセッサ、またはそれらの組み合わせであり得る。プロセッサデバイスは、１つ以上のプロセッサ「コア」を有し得る。 For example, at least one processor device and memory may be used to implement the above embodiments. The processor device may be a single processor, multiple processors, or a combination thereof. A processor device may have one or more processor “cores”.
本開示の種々の実施形態は、このコンピュータシステム例８００に関して説明される。この説明を読んだ後に、他のコンピュータシステムおよび／またはコンピュータアーキテクチャを使用して、どのようにして本開示の実施形態を実装するかが、当業者に明白となるであろう。動作は、連続した過程として説明され得るが、動作のうちのいくつかは実際には、単一またはマルチプロセッサマシンによるアクセスのためにローカルまたは遠隔に記憶されたプログラムコードを用いて、並行して、同時に、および／または分散環境で行われ得る。加えて、いくつかの実施形態では、動作の順序は、開示された主題の精神から逸脱することなく再編成され得る。
Various embodiments of the present disclosure are described with respect to this
プロセッサデバイス８０４は、専用または汎用プロセッサデバイスであり得る。当業者によって理解されるように、プロセッサデバイス８０４はまた、単独で動作するシステム等のマルチコア／マルチプロセッサシステムの中、あるいはクラスタまたはサーバファームの中で動作するコンピュータデバイス群の中の単一のプロセッサであり得る。プロセッサデバイス８０４は、通信インフラストラクチャ８０６、例えば、バス、メッセージ待ち行列、ネットワーク、またはマルチコアメッセージパッシングスキームに接続される。
The processor device 804 may be a dedicated or general purpose processor device. As will be appreciated by those skilled in the art, the processor device 804 is also a single processor in a multicore / multiprocessor system, such as a system operating alone, or in a group of computer devices operating in a cluster or server farm. It can be. The processor device 804 is connected to a
コンピュータシステム８００はまた、例えば、ランダムアクセスメモリ（ＲＡＭ）等のメインメモリ８０８を含み得、また、二次メモリ８１０を含み得る。二次メモリ８１０は、例えば、ハードディスクドライブ８１２、可撤性記憶ドライブ８１４を含み得る。可撤性記憶ドライブ８１４は、フロッピー（登録商標）ディスクドライブ、磁気テープドライブ、光ディスクドライブ、フラッシュメモリ、または同等物を備え得る。可撤性記憶ドライブ８１４は、周知の方式で可撤性記憶ユニット８１８から読み取り、および／またはそこに書き込む。可撤性記憶ユニット８１８は、可撤性記憶ドライブ８１４によって読み取られ、それに書き込まれる、フロッピー（登録商標）ディスク、磁気テープ、光ディスク等を備え得る。この説明で挙げられる関連技術の当業者によって理解されるように、可撤性記憶ユニット８１８は、その中にコンピュータソフトウェアおよび／またはデータを記憶している、コンピュータ利用可能記憶媒体を含む。
The
代替実装では、二次メモリ８１０は、コンピュータプログラムまたは他の命令がコンピュータシステム８００にロードされることを可能にするための他の同様の手段を含み得る。そのような手段は、例えば、可撤性記憶ユニット８２２およびインターフェース８２０を含み得る。そのような手段の実施例は、（ビデオゲームデバイスで見られるもの等の）プログラムカートリッジおよびカートリッジインターフェースと、（ＥＰＲＯＭまたはＰＲＯＭ等の）可撤性メモリチップおよび関連ソケットと、他の可撤性記憶ユニット８２２と、ソフトウェアおよびデータが可撤性記憶ユニット８２２からコンピュータシステム８００へ転送されることを可能にするインターフェース８２０とを含み得る。
In alternative implementations, secondary memory 810 may include other similar means for allowing computer programs or other instructions to be loaded into
コンピュータシステム８００はまた、通信インターフェース８２４を含み得る。通信インターフェース８２４は、ソフトウェアおよびデータがコンピュータシステム８００と外部デバイスとの間で転送されることを可能にする。通信インターフェース８２４は、モデム、（イーサネット（登録商標）カード等の）ネットワークインターフェース、通信ポート、ＰＣＭＣＩＡスロットおよびカード、または同等物を含み得る。通信インターフェース８２４を介して転送されるソフトウェアおよびデータは、電子、電磁、光、または通信インターフェース８２４によって受信されることが可能な他の信号であり得る、信号の形態であり得る。これらの信号は、通信経路８２６を介して、通信インターフェース８２４に提供され得る。通信経路８２６は、信号を運び、ワイヤまたはケーブル、光ファイバ、電話回線、携帯電話リンク、ＲＦリンク、または他の通信チャネルを使用して実装され得る。
この文書では、「コンピュータプログラム媒体」および「コンピュータ使用可能媒体」という用語は、概して、可撤性記憶ユニット８１８、可撤性記憶ユニット８２２、およびハードディスクドライブ８１２にインストールされたハードディスク等の媒体を指すために使用される。コンピュータプログラム媒体およびコンピュータ使用可能媒体はまた、メモリ半導体（例えば、ＤＲＡＭ等）であり得る、メインメモリ８０８および二次メモリ８１０等のメモリを指し得る。
In this document, the terms “computer program medium” and “computer usable medium” generally refer to a medium such as a removable storage unit 818, a
コンピュータプログラム（コンピュータ制御論理とも呼ばれる）は、メモリ８０８および／または二次メモリ８１０の中に記憶される。コンピュータプログラムはまた、通信インターフェース８２４を介して受信され得る。そのようなコンピュータプログラムは、実行された場合に、コンピュータシステム８００が、本明細書で論議されるように本開示を実装することを可能にする。具体的には、コンピュータプログラムは、実行された場合に、プロセッサデバイス８０４が、上記で論議される、それぞれ図４Ａ−Ｂ、６、および７のフローチャート４００、６００、および７００によって図示される方法における段階等の本開示の過程を実装することを可能にする。したがって、そのようなコンピュータプログラムは、コンピュータシステム８００のコントローラを表す。本開示の実施形態がソフトウェアを使用して実装される場合、ソフトウェアは、コンピュータプログラム製品の中に記憶され、可撤性記憶ドライブ８１４、インターフェース８２０、ハードディスクドライブ８１２、または通信インターフェース８２４を使用してコンピュータシステム８００にロードされ得る。
Computer programs (also called computer control logic) are stored in memory 808 and / or secondary memory 810. A computer program may also be received via
本開示の実施形態はまた、任意のコンピュータ使用可能媒体上に記憶されたソフトウェアを備えているコンピュータプログラム製品を対象とし得る。そのようなソフトウェアは、１つ以上のデータ処理デバイスにおいて実行された場合に、データ処理デバイスを本明細書で説明されるように動作させる。本開示の実施形態は、任意のコンピュータ使用可能または可読媒体を採用する。コンピュータ使用可能媒体の実施例は、一次記憶デバイス（例えば、任意の種類のランダムアクセスメモリ）、二次記憶デバイス（例えば、ハードドライブ、フロッピー（登録商標）ディスク、ＣＤ ＲＯＭ、ＺＩＰディスク、テープ、磁気記憶デバイス、および光学記憶デバイス、ＭＥＭＳ、ナノ技術記憶デバイス等）、および通信媒体（例えば、有線および無線通信ネットワーク、ローカルエリアネットワーク、広域ネットワーク、イントラネット等）を含むが、それらに限定されない。 Embodiments of the present disclosure may also be directed to a computer program product comprising software stored on any computer usable medium. Such software, when executed on one or more data processing devices, causes the data processing devices to operate as described herein. Embodiments of the present disclosure employ any computer-usable or readable medium. Examples of computer usable media include primary storage devices (eg, any type of random access memory), secondary storage devices (eg, hard drive, floppy disk, CD ROM, ZIP disk, tape, magnetic Storage devices, and optical storage devices, MEMS, nanotechnology storage devices, etc.), and communication media (eg, wired and wireless communication networks, local area networks, wide area networks, intranets, etc.), but are not limited thereto.
（Ｖ．終わりに）
概要および要約の項ではなく、発明を実施するための形態項は、請求項を解釈するために使用されることを目的としていると理解されたい。概要および要約の項は、発明者によって検討されるような本開示の例示的実施形態の全てではないが１つ以上を説明し得、したがって、決して本開示および添付の請求項を限定することを目的としていない。
(V. At the end)
It should be understood that the detailed description, rather than the summary and abstract sections, is intended to be used for interpreting the claims. The summary and summary sections may explain one or more, but not all, of the exemplary embodiments of the present disclosure as discussed by the inventors, and are therefore in no way intended to limit the present disclosure and the appended claims. Not intended.
本開示は、特定機能の実装およびそれらの関係を図示する機能的構成要素を用いて、上記で説明されている。これらの機能的構成要素の境界は、説明の便宜上、本明細書では恣意的に画定されている。特定機能およびそれらの関係が適切に果たされる限り、代替的な境界を画定することができる。 The present disclosure has been described above using functional components that illustrate the implementation of particular functions and their relationships. The boundaries of these functional components are arbitrarily defined herein for convenience of explanation. Alternative boundaries can be defined as long as certain functions and their relationships are properly performed.
具体的実施形態の先述の説明は、本開示の一般概念から逸脱することなく、必要以上の実験を伴わずに、当技術分野内の知識を適用することによって、他者がそのような具体的実施形態を容易に修正し、および／または種々の用途のために適合させることができるという、本開示の一般的性質を十分に明らかにするであろう。したがって、そのような適合および修正は、本明細書で提示される教示および指導に基づいて、開示された実施形態の同等物の意味および範囲内であることを目的としている。本明細書の用語または表現が、教示および指導を踏まえて当業者によって解釈されるものであるように、本明細書の表現または用語は、限定ではなく説明の目的のためであることを理解されたい。 The foregoing description of specific embodiments has been shown to others by applying knowledge within the art without undue experimentation without departing from the general concept of the present disclosure. The general nature of the present disclosure will be sufficiently clear that the embodiments can be easily modified and / or adapted for various applications. Accordingly, such adaptations and modifications are intended to be within the meaning and scope of the equivalents of the disclosed embodiments based on the teachings and guidance presented herein. It is understood that the expressions or terms herein are for purposes of illustration and not limitation, as the terms or expressions herein are to be interpreted by one of ordinary skill in the art in light of the teaching and guidance. I want.
本開示の幅および範囲は、上記の例示的実施形態のうちのいずれによっても限定されるべきではなく、以下の請求項およびそれらの均等物のみに従って定義されるべきである。 The breadth and scope of the present disclosure should not be limited by any of the above-described exemplary embodiments, but should be defined only in accordance with the following claims and their equivalents.
Claims (31)
第１のユーザに関連付けられている第１の画像の集合体を、少なくとも１つのコンピュータデバイス上で受信することであって、前記第１のユーザは、第１の共有選好に関連付けられ、前記第１の集合体は、第１のコンテンツデータを有する、ことと、
第２のユーザに関連付けられている第２の画像の集合体を、前記少なくとも１つのコンピュータデバイス上で受信することであって、前記第２のユーザは、第２の共有選好に関連付けられ、前記第２の集合体は、第２のコンテンツデータを有し、前記第１のユーザおよび前記第２のユーザは、互に関連付けられている、ことと、
前記第１のユーザと前記第２のユーザとの間の関連付けに基づいて、前記第１のコンテンツデータおよび前記第２のコンテンツデータに従って前記第１の集合体および前記第２の集合体をイベントグループにグループ化することと、
前記第１のコンテンツデータに基づいて、前記第１のユーザに関連付けられている前記第１の画像の集合体を、第１の組の１つ以上のアルバムに分割することと、
前記第２のコンテンツデータに基づいて、前記第２のユーザに関連付けられている前記第２の画像の集合体を、第２の組の１つ以上のアルバムに分割することと、
前記第１のコンテンツデータおよび前記第２のコンテンツデータと、前記第１のユーザの前記第１の共有選好および前記第２のユーザの前記第２の共有選好とに基づいて、前記第１の組のアルバムおよび前記第２の組のアルバムを前記イベントグループにクラスタ化することであって、前記第１の共有選好および前記第２の共有選好は、少なくとも部分的に合致している、ことと、
前記第１のユーザおよび前記第２のユーザに前記イベントグループへのアクセスを提供することと
を含む、方法。 A computer-implemented method for automatically sharing media between users,
Receiving a first collection of images associated with a first user on at least one computing device, wherein the first user is associated with a first shared preference; 1 aggregate has first content data;
Receiving on the at least one computing device a second collection of images associated with a second user , wherein the second user is associated with a second shared preference, the second assembly includes a second content data, the first user and the second user is associated with each other, and that,
Wherein the first user based on an association between the second user, the first content data and the second the following content data of the first assembly and the second aggregates event Grouping into groups,
Dividing the collection of first images associated with the first user into a first set of one or more albums based on the first content data;
Dividing the collection of second images associated with the second user into a second set of one or more albums based on the second content data;
Based on the first content data and the second content data, and the first shared preference of the first user and the second shared preference of the second user, the first set And the second set of albums into the event group, wherein the first shared preference and the second shared preference are at least partially matched;
And providing access to said first user and said event group to said second user, the method.
前記第１のユーザおよび前記第２のユーザのうちの少なくとも１つに関連付けられている１つ以上の追加の画像を含むように、前記イベントグループを更新することであって、前記第１のユーザおよび前記第２のユーザは、前記更新されたイベントグループへのアクセスを自動的に提供され得る、ことと
をさらに含む、請求項１に記載の方法。 Receiving one or more additional images associated with one of the first collection of images or the second collection of images;
To include at least one or more additional images that are associated with one of said first user and said second user, the method comprising updating the event group, the first user and the second user, the access to the updated event group can be provided automatically, it further comprises a method according to claim 1.
前記第２の集合体の画像に対する前記第２のコンテンツデータを決定することと
をさらに含む、請求項１に記載の方法。 Determining a first content data to the image of the first assembly,
Further comprising the method of claim 1 and determining the second content data for the image of the second assembly.
前記第２のコンテンツデータを決定することは、前記第２の集合体の１つ以上の画像における第２の顔を認識することを含み、前記第２のコンテンツデータは、前記第２の顔の識別を含む、
請求項７に記載の方法。 Determining the first content data includes recognizing a first face in one or more images of the first collection, wherein the first content data is the first face data of the first face. Including identification,
Determining the second content data includes recognizing a second face in one or more images of the second collection, wherein the second content data is the second face data. Including identification,
The method of claim 7 .
前記第２の顔を認識することは、前記第２のユーザから、前記第２の顔の前記第２の識別を取得することを含み、
前記第１の顔の前記第１の識別は、前記第２のユーザに対応し、
前記第２の顔の前記第２の識別は、前記第１のユーザに対応する、
請求項８に記載の方法。 Recognizing the first face includes obtaining the first identification of the first face from the first user;
Recognizing the second face includes obtaining the second identification of the second face from the second user;
The first identification of the first face corresponds to the second user;
The second identification of the second face corresponds to the first user;
The method of claim 8 .
前記第２のコンテンツデータを決定することは、前記第２の集合体の１つ以上の画像における第２の目印を認識することを含み、前記第２のコンテンツデータは、前記第２の目印に対応する、請求項７に記載の方法。 Determining the first content data includes recognizing a first landmark in one or more images of the first aggregate, and the first content data is included in the first landmark. Correspondingly,
Determining the second content data includes recognizing a second landmark in one or more images of the second aggregate, and the second content data is included in the second landmark. The method of claim 7 corresponding.
前記第２のコンテンツデータを決定することは、前記第２の集合体の１つ以上の画像における第２のオブジェクトを認識することを含み、前記第２のコンテンツデータは、前記第２のオブジェクトに対応する、請求項７に記載の方法。 Determining the first content data includes recognizing a first object in one or more images of the first collection, wherein the first content data is stored in the first object. Correspondingly,
Determining the second content data includes recognizing a second object in one or more images of the second collection, and the second content data is stored in the second object. The method of claim 7 corresponding.
前記第２のコンテンツデータを決定することは、前記第２の集合体の１つ以上の画像から第２のメタデータを抽出することを含み、前記第２のコンテンツデータは、前記第２のメタデータに対応する、請求項７に記載の方法。 Determining the first content data includes extracting first metadata from one or more images of the first aggregate, wherein the first content data is the first metadata. Corresponding to the data,
Determining the second content data includes extracting second metadata from one or more images of the second collection, wherein the second content data is the second metadata. The method of claim 7 , corresponding to data.
１つ以上のプロセッサと、
第１のユーザに関連付けられている第１の画像の集合体と、第２のユーザに関連付けられている第２の画像の集合体とを受信するように構成されているメディア入力モジュールであって、前記第１のユーザは、第１の共有選好に関連付けられ、前記第２のユーザは、第２の共有選好に関連付けられ、前記第１の集合体は、第１のコンテンツデータを有し、前記第２の集合体は、第２のコンテンツデータを有し、前記第１のユーザおよび前記第２のユーザは、互に関連付けられている、メディア入力モジュールと、
前記第１のユーザおよび前記第２のユーザの関連付けに基づいて、前記第１のコンテンツデータおよび前記第２のコンテンツデータに従って前記第１の集合体および前記第２の集合体をイベントグループにグループ化することであって、前記グループ化することは、
前記第１のコンテンツデータに基づいて、前記第１のユーザに関連付けられている前記第１の集合体を、第１の組の１つ以上のアルバムに分割することと、
前記第２のコンテンツデータに基づいて、前記第２のユーザに関連付けられている前記第２の画像の集合体を、第２の組の１つ以上のアルバムに分割することと、
前記第１のコンテンツデータおよび前記第２のコンテンツデータと、前記第１のユーザの前記第１の共有選好および前記第２のユーザの前記第２の共有選好とに基づいて、前記第１の組のアルバムおよび前記第２の組のアルバムを前記イベントグループにクラスタ化することであって、前記第１の共有選好および前記第２の共有選好は、少なくとも部分的に合致している、ことと
によって行われる、ことと、前記第１のユーザおよび前記第２のユーザに前記イベントグループへのアクセスを提供することとを行うように構成されているメディア共有モジュールと
を備え、
前記メディア入力モジュールおよび前記メディア共有モジュールは、前記１つ以上のプロセッサを使用して実装されている、システム。 A system for automatically sharing media between users,
One or more processors;
A set of first image associated with a first user, a media input module configured to receive a set of second image associated with the second user , The first user is associated with a first shared preference, the second user is associated with a second shared preference, the first aggregate has first content data; said second assembly has a second content data, the first user and the second user is associated with each other, a media input module,
Based on the association of the first user and the second user, the first content data and groups to the first assembly and the event group the second assembly in accordance with the second content data And the grouping is
Dividing the first collection associated with the first user into a first set of one or more albums based on the first content data;
Dividing the collection of second images associated with the second user into a second set of one or more albums based on the second content data;
Based on the first content data and the second content data, and the first shared preference of the first user and the second shared preference of the second user, the first set And the second set of albums into the event group, wherein the first shared preference and the second shared preference are at least partially matched,
The place, it and, a first user and the second media sharing module configured to allow the user to do and to provide access to the event group,
The system, wherein the media input module and the media sharing module are implemented using the one or more processors.
Applications Claiming Priority (5)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US36816610P | 2010-07-27 | 2010-07-27 | |
US61/368,166 | 2010-07-27 | ||
US13/188,879 | 2011-07-22 | ||
US13/188,879 US8270684B2 (en) | 2010-07-27 | 2011-07-22 | Automatic media sharing via shutter click |
PCT/US2011/045532 WO2012015919A1 (en) | 2010-07-27 | 2011-07-27 | Automatic media sharing via shutter click |
Publications (2)
Publication Number | Publication Date |
---|---|
JP2013541060A JP2013541060A (en) | 2013-11-07 |
JP5801395B2 true JP5801395B2 (en) | 2015-10-28 |
Family
ID=44630017
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2013521938A Active JP5801395B2 (en) | 2010-07-27 | 2011-07-27 | Automatic media sharing via shutter click |
Country Status (6)
Country | Link |
---|---|
US (4) | US8270684B2 (en) |
EP (1) | EP2599016A1 (en) |
JP (1) | JP5801395B2 (en) |
KR (1) | KR101810578B1 (en) |
CN (1) | CN103119595B (en) |
WO (1) | WO2012015919A1 (en) |
Families Citing this family (135)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9319357B2 (en) | 2009-01-15 | 2016-04-19 | Social Communications Company | Context based virtual area creation |
US10786736B2 (en) | 2010-05-11 | 2020-09-29 | Sony Interactive Entertainment LLC | Placement of user information in a game space |
JP5740972B2 (en) * | 2010-09-30 | 2015-07-01 | ソニー株式会社 | Information processing apparatus and information processing method |
TWI435597B (en) * | 2010-10-20 | 2014-04-21 | Altek Corp | Photo information display method combined with face recognition and electronic device with camera function thereof |
US8977767B2 (en) * | 2010-10-20 | 2015-03-10 | Qualcomm Incorporated | Methods and apparatuses for affecting programming of content for transmission over a multicast network |
US20120213404A1 (en) | 2011-02-18 | 2012-08-23 | Google Inc. | Automatic event recognition and cross-user photo clustering |
JP2013003630A (en) * | 2011-06-13 | 2013-01-07 | Sony Corp | Information processing device, information processing method, program, and information processing system |
JP5995520B2 (en) * | 2011-06-14 | 2016-09-21 | キヤノン株式会社 | Image processing support system, information processing apparatus, and image processing shadow support method |
US8831294B2 (en) * | 2011-06-17 | 2014-09-09 | Microsoft Corporation | Broadcast identifier enhanced facial recognition of images |
US9049176B2 (en) | 2011-06-22 | 2015-06-02 | Dropbox, Inc. | File sharing via link generation |
US9342817B2 (en) * | 2011-07-07 | 2016-05-17 | Sony Interactive Entertainment LLC | Auto-creating groups for sharing photos |
US8893008B1 (en) | 2011-07-12 | 2014-11-18 | Relationship Science LLC | Allowing groups expanded connectivity to entities of an information service |
US9015856B2 (en) * | 2011-08-08 | 2015-04-21 | Facebook, Inc. | Mobile-device user authentication |
US10089327B2 (en) * | 2011-08-18 | 2018-10-02 | Qualcomm Incorporated | Smart camera for sharing pictures automatically |
US8831360B2 (en) | 2011-10-21 | 2014-09-09 | Intellectual Ventures Fund 83 Llc | Making image-based product from digital image collection |
US8959082B2 (en) * | 2011-10-31 | 2015-02-17 | Elwha Llc | Context-sensitive query enrichment |
US9349147B2 (en) * | 2011-11-01 | 2016-05-24 | Google Inc. | Displaying content items related to a social network group on a map |
US9280545B2 (en) * | 2011-11-09 | 2016-03-08 | Microsoft Technology Licensing, Llc | Generating and updating event-based playback experiences |
US10960300B2 (en) | 2011-11-23 | 2021-03-30 | Sony Interactive Entertainment LLC | Sharing user-initiated recorded gameplay with buffered gameplay |
US10486064B2 (en) | 2011-11-23 | 2019-11-26 | Sony Interactive Entertainment America Llc | Sharing buffered gameplay in response to an input request |
US20130244790A1 (en) | 2012-03-13 | 2013-09-19 | Sony Computer Entertainment America Llc | System and method for capturing and sharing console gaming data |
US9116555B2 (en) | 2011-11-23 | 2015-08-25 | Sony Computer Entertainment America Llc | Gaming controller |
US8672765B2 (en) * | 2012-03-13 | 2014-03-18 | Sony Computer Entertainment America Llc | System and method for capturing and sharing console gaming data |
US10525347B2 (en) | 2012-03-13 | 2020-01-07 | Sony Interactive Entertainment America Llc | System and method for capturing and sharing console gaming data |
WO2013089423A1 (en) * | 2011-12-12 | 2013-06-20 | Samsung Electronics Co., Ltd. | System, apparatus and method for utilizing a multimedia service |
KR101993163B1 (en) * | 2011-12-12 | 2019-06-26 | 삼성전자주식회사 | Method and apparatus for experiencing a multimedia service |
US8364817B1 (en) * | 2012-02-09 | 2013-01-29 | Gramboo Inc. | Method and system for managing a data item |
US8917943B2 (en) * | 2012-05-11 | 2014-12-23 | Intellectual Ventures Fund 83 Llc | Determining image-based product from digital image collection |
US9374399B1 (en) * | 2012-05-22 | 2016-06-21 | Google Inc. | Social group suggestions within a social network |
WO2013188682A1 (en) * | 2012-06-13 | 2013-12-19 | Google Inc | Sharing information with other users |
US8861804B1 (en) * | 2012-06-15 | 2014-10-14 | Shutterfly, Inc. | Assisted photo-tagging with facial recognition models |
US8798401B1 (en) * | 2012-06-15 | 2014-08-05 | Shutterfly, Inc. | Image sharing with facial recognition models |
US9584834B1 (en) | 2012-06-25 | 2017-02-28 | Google Inc. | Video broadcasting with geolocation |
US9665773B2 (en) * | 2012-06-25 | 2017-05-30 | Google Inc. | Searching for events by attendants |
WO2014004907A2 (en) * | 2012-06-27 | 2014-01-03 | Google Inc. | System and method for determining appropriate content for an event content stream |
US9391792B2 (en) | 2012-06-27 | 2016-07-12 | Google Inc. | System and method for event content stream |
US9104704B2 (en) | 2012-07-16 | 2015-08-11 | Htc Corporation | Imaging systems and related methods |
US9460205B2 (en) * | 2012-07-20 | 2016-10-04 | Google Inc. | Crowdsourced video collaboration |
US20140025755A1 (en) * | 2012-07-20 | 2014-01-23 | Google Inc. | Inferring events based on mob source video |
FR2993686A1 (en) * | 2012-07-23 | 2014-01-24 | France Telecom | Method for generating multi-media document e.g. video, relative to multi-media event such as festival, involves combining multimedia contents to geolocation point according to time-stamping data of certain multimedia contents |
JP5692181B2 (en) * | 2012-07-26 | 2015-04-01 | カシオ計算機株式会社 | Network service system, wrist terminal, display method, and program |
US9075954B2 (en) | 2012-08-29 | 2015-07-07 | Dropbox, Inc. | Requesting modification rights to a linked file set |
JP5175404B1 (en) * | 2012-09-20 | 2013-04-03 | 株式会社 ディー・エヌ・エー | Server apparatus, method, and system |
WO2014058349A1 (en) | 2012-10-10 | 2014-04-17 | Ikonomov Artashes Valeryevich | Electronic payment system |
US9361626B2 (en) * | 2012-10-16 | 2016-06-07 | Google Inc. | Social gathering-based group sharing |
US9418370B2 (en) | 2012-10-23 | 2016-08-16 | Google Inc. | Obtaining event reviews |
JP5977147B2 (en) | 2012-11-05 | 2016-08-24 | 株式会社ソニー・インタラクティブエンタテインメント | Information processing apparatus and input device |
JP6258862B2 (en) * | 2012-11-09 | 2018-01-10 | ソニー株式会社 | Image processing apparatus, image processing method, and program |
US9336435B1 (en) | 2012-11-21 | 2016-05-10 | Ozog Media, LLC | System, method, and computer program product for performing processing based on object recognition |
US9330301B1 (en) | 2012-11-21 | 2016-05-03 | Ozog Media, LLC | System, method, and computer program product for performing processing based on object recognition |
US9286456B2 (en) * | 2012-11-27 | 2016-03-15 | At&T Intellectual Property I, Lp | Method and apparatus for managing multiple media services |
KR102138160B1 (en) * | 2012-12-07 | 2020-07-27 | 티-데이터 시스템스 (에스) 피티이 엘티디 | A memory card and a method for allowing access to digital files stored on the memory card |
US20140160148A1 (en) * | 2012-12-10 | 2014-06-12 | Andrew J. Barkett | Context-Based Image Customization |
US9104687B2 (en) | 2012-12-20 | 2015-08-11 | Dropbox, Inc. | System and method for preventing duplicate uploads of modified photos in a synchronized content management system |
US8838681B2 (en) | 2012-12-21 | 2014-09-16 | Dropbox, Inc. | Systems and methods for adding digital content to content management service accounts |
CN103902551B (en) * | 2012-12-25 | 2017-11-17 | 华为技术有限公司 | Information processing method, device and control device |
US9424280B2 (en) * | 2012-12-28 | 2016-08-23 | Animoto Inc. | Organizing media items based on metadata similarities |
US20140201227A1 (en) * | 2013-01-15 | 2014-07-17 | Getty Images (Us), Inc. | Content-identification engine based on social media |
US10133754B2 (en) * | 2013-02-10 | 2018-11-20 | Qualcomm Incorporated | Peer-to-peer picture sharing using custom based rules for minimal power consumption and better user experience |
US20140250175A1 (en) | 2013-03-01 | 2014-09-04 | Robert M. Baldwin | Prompted Sharing of Photos |
US20140258850A1 (en) * | 2013-03-11 | 2014-09-11 | Mathew R. Carey | Systems and Methods for Managing the Display of Images |
US9823813B2 (en) | 2013-03-15 | 2017-11-21 | Salesforce.Com, Inc. | Apparatus and methods for performing an action on a database record |
US20140280577A1 (en) | 2013-03-15 | 2014-09-18 | Salesforce.Com, Inc. | Systems and methods for interacting with an application in a publisher |
EP2989807A4 (en) * | 2013-05-03 | 2016-11-09 | Digimarc Corp | Watermarking and signal recogniton for managing and sharing captured content, metadata discovery and related arrangements |
US9843623B2 (en) | 2013-05-28 | 2017-12-12 | Qualcomm Incorporated | Systems and methods for selecting media items |
US10243899B2 (en) * | 2013-05-30 | 2019-03-26 | Dropbox, Inc. | Content-item relationship messaging system |
CN104243517B (en) * | 2013-06-14 | 2018-12-11 | 腾讯科技（深圳）有限公司 | Content share method and device between different terminals |
DE102013009958A1 (en) * | 2013-06-14 | 2014-12-18 | Sogidia AG | A social networking system and method of exercising it using a computing device that correlates to a user profile |
US9313399B2 (en) * | 2013-06-14 | 2016-04-12 | Qualcomm Incorporated | System and method for identifying people in an image |
WO2015017865A1 (en) * | 2013-08-02 | 2015-02-05 | Shoto, Inc. | Discovery and sharing of photos between devices |
US9910865B2 (en) | 2013-08-05 | 2018-03-06 | Nvidia Corporation | Method for capturing the moment of the photo capture |
WO2015026263A1 (en) * | 2013-08-20 | 2015-02-26 | Ikonomov Artashes Valeryevich | Server for storing images and/or video files |
US9405964B1 (en) | 2013-09-09 | 2016-08-02 | Amazon Technologies, Inc. | Processes for generating content sharing recommendations based on image content analysis |
US9338242B1 (en) | 2013-09-09 | 2016-05-10 | Amazon Technologies, Inc. | Processes for generating content sharing recommendations |
US9531823B1 (en) | 2013-09-09 | 2016-12-27 | Amazon Technologies, Inc. | Processes for generating content sharing recommendations based on user feedback data |
EP3063730B1 (en) * | 2013-09-18 | 2018-10-24 | Intel Corporation | Automated image cropping and sharing |
US20150085146A1 (en) * | 2013-09-23 | 2015-03-26 | Nvidia Corporation | Method and system for storing contact information in an image using a mobile device |
US9628986B2 (en) | 2013-11-11 | 2017-04-18 | At&T Intellectual Property I, L.P. | Method and apparatus for providing directional participant based image and video sharing |
CN103686375B (en) * | 2013-11-19 | 2017-02-22 | 乐视致新电子科技（天津）有限公司 | Video sharing method and device |
KR101791518B1 (en) | 2014-01-23 | 2017-10-30 | 삼성전자주식회사 | Method and apparatus for verifying user |
US10673922B2 (en) * | 2014-02-19 | 2020-06-02 | RealCloud Imaging Inc. | Cloud based 2D dental imaging system with HTML web browser acquisition |
US10540541B2 (en) * | 2014-05-27 | 2020-01-21 | International Business Machines Corporation | Cognitive image detection and recognition |
WO2015190473A1 (en) * | 2014-06-12 | 2015-12-17 | 本田技研工業株式会社 | Photographic image replacement system, imaging device, and photographic image replacement method |
US20160050704A1 (en) * | 2014-08-12 | 2016-02-18 | Lyve Minds, Inc. | Image linking and sharing |
US10216996B2 (en) * | 2014-09-29 | 2019-02-26 | Sony Interactive Entertainment Inc. | Schemes for retrieving and associating content items with real-world objects using augmented reality and object recognition |
US9405774B2 (en) * | 2014-10-17 | 2016-08-02 | Verizon Patent And Licensing Inc. | Automated image organization techniques |
US9544307B2 (en) * | 2014-10-29 | 2017-01-10 | Salesforce.Com, Inc. | Providing a security mechanism on a mobile device |
US20160125062A1 (en) * | 2014-10-30 | 2016-05-05 | Futurewei Technologies, Inc. | Multi-scale timeling photograph album management with incremental spectral photograph clustering |
CN105760408B (en) * | 2014-12-19 | 2020-04-28 | 华为终端有限公司 | Picture sharing method and device and terminal equipment |
US9781228B2 (en) * | 2014-12-23 | 2017-10-03 | Palo Alto Research Center Incorporated | Computer-implemented system and method for providing contextual media tagging for selective media exposure |
US10284537B2 (en) * | 2015-02-11 | 2019-05-07 | Google Llc | Methods, systems, and media for presenting information related to an event based on metadata |
US11048855B2 (en) | 2015-02-11 | 2021-06-29 | Google Llc | Methods, systems, and media for modifying the presentation of contextually relevant documents in browser windows of a browsing application |
US11392580B2 (en) | 2015-02-11 | 2022-07-19 | Google Llc | Methods, systems, and media for recommending computerized services based on an animate object in the user's environment |
US9769564B2 (en) | 2015-02-11 | 2017-09-19 | Google Inc. | Methods, systems, and media for ambient background noise modification based on mood and/or behavior information |
US9767305B2 (en) * | 2015-03-13 | 2017-09-19 | Facebook, Inc. | Systems and methods for sharing media content with recognized social connections |
CN104852967B (en) * | 2015-04-21 | 2018-03-27 | 小米科技有限责任公司 | Image sharing method and device |
KR20160149959A (en) * | 2015-06-19 | 2016-12-28 | 라인 가부시키가이샤 | System and method for creating contents by collaborating between users |
US10778855B2 (en) | 2015-06-19 | 2020-09-15 | Line Corporation | System and method for creating contents by collaborating between users |
US10462524B2 (en) * | 2015-06-23 | 2019-10-29 | Facebook, Inc. | Streaming media presentation system |
US9917870B2 (en) | 2015-06-23 | 2018-03-13 | Facebook, Inc. | Streaming media presentation system |
US10094655B2 (en) | 2015-07-15 | 2018-10-09 | 15 Seconds of Fame, Inc. | Apparatus and methods for facial recognition and video analytics to identify individuals in contextual video streams |
CN105069075B (en) * | 2015-07-31 | 2018-02-23 | 小米科技有限责任公司 | Photo be shared method and apparatus |
US10416850B1 (en) * | 2015-08-06 | 2019-09-17 | Western Digital Technologies, Inc. | Sharing groups for capturing digital media |
US20170060892A1 (en) * | 2015-09-01 | 2017-03-02 | Dropbox, Inc. | Search-based shareable collections |
WO2017044910A1 (en) | 2015-09-10 | 2017-03-16 | I'm In It, Llc | Methods, devices, and systems for determining a subset for autonomous sharing of digital media |
CN107710197B (en) | 2015-09-28 | 2021-08-17 | 谷歌有限责任公司 | Sharing images and image albums over a communication network |
CN105187560A (en) * | 2015-09-29 | 2015-12-23 | 北京奇艺世纪科技有限公司 | Cloud server-based data pushing method and device |
US9875511B1 (en) * | 2015-09-30 | 2018-01-23 | Sipree, Inc. | Method and system for desktop-invoked image or video capture |
EP3365838A4 (en) | 2015-10-21 | 2019-08-28 | 15 Seconds Of Fame, Inc. | Methods and apparatus for false positive minimization in facial recognition applications |
US10083720B2 (en) * | 2015-11-06 | 2018-09-25 | Aupera Technologies, Inc. | Method and system for video data stream storage |
US20170134595A1 (en) * | 2015-11-11 | 2017-05-11 | Vivint, Inc. | Automated image album |
US20170150197A1 (en) * | 2015-11-20 | 2017-05-25 | Nady International Limited | Multimedia content sharing and distribution |
JP6674798B2 (en) * | 2016-03-07 | 2020-04-01 | 富士フイルム株式会社 | Image processing apparatus, image processing method, program, and recording medium |
US10459970B2 (en) * | 2016-06-07 | 2019-10-29 | Baidu Usa Llc | Method and system for evaluating and ranking images with content based on similarity scores in response to a search query |
US20190207946A1 (en) * | 2016-12-20 | 2019-07-04 | Google Inc. | Conditional provision of access by interactive assistant modules |
US10200560B2 (en) * | 2017-01-13 | 2019-02-05 | Adobe Inc. | Automated sharing of digital images |
US10740388B2 (en) | 2017-01-24 | 2020-08-11 | Microsoft Technology Licensing, Llc | Linked capture session for automatic image sharing |
US11436417B2 (en) | 2017-05-15 | 2022-09-06 | Google Llc | Providing access to user-controlled resources by automated assistants |
US10127227B1 (en) | 2017-05-15 | 2018-11-13 | Google Llc | Providing access to user-controlled resources by automated assistants |
EP3568787B1 (en) | 2017-05-17 | 2024-04-10 | Google LLC | Automatic image sharing with designated users over a communication network |
US20180341878A1 (en) * | 2017-05-26 | 2018-11-29 | Get Attached, Inc. | Using artificial intelligence and machine learning to automatically share desired digital media |
US10706265B2 (en) * | 2017-07-28 | 2020-07-07 | Qualcomm Incorporated | Scanning a real-time media stream to detect one or more faces that are prevalent among a set of media files stored on a user equipment |
US10885315B2 (en) | 2018-03-19 | 2021-01-05 | Rovi Guides, Inc. | Systems and methods for alerting a user to published undesirable images depicting the user |
US10375432B1 (en) * | 2018-06-05 | 2019-08-06 | Rovi Guides, Inc. | Systems and methods for seamlessly connecting devices based on relationships between the users of the respective devices |
EP3682345B1 (en) | 2018-08-07 | 2021-11-24 | Google LLC | Assembling and evaluating automated assistant responses for privacy concerns |
US10936856B2 (en) | 2018-08-31 | 2021-03-02 | 15 Seconds of Fame, Inc. | Methods and apparatus for reducing false positives in facial recognition |
US10917372B2 (en) | 2018-09-21 | 2021-02-09 | Blackberry Limited | Method and system for integration of shared photo albums with messaging applications |
US20200213510A1 (en) * | 2018-12-30 | 2020-07-02 | Luke Trevitt | System and method to capture and customize relevant image and further allows user to share the relevant image over a network |
US11010596B2 (en) | 2019-03-07 | 2021-05-18 | 15 Seconds of Fame, Inc. | Apparatus and methods for facial recognition systems to identify proximity-based connections |
CN110399520A (en) * | 2019-07-30 | 2019-11-01 | 腾讯音乐娱乐科技（深圳）有限公司 | Obtain the methods, devices and systems of singer informations |
US11409788B2 (en) * | 2019-09-05 | 2022-08-09 | Albums Sas | Method for clustering at least two timestamped photographs |
US10963588B1 (en) | 2019-10-30 | 2021-03-30 | International Business Machines Corporation | Analyzing recordings for data to be protected and identifying recipients and alerts |
US11341351B2 (en) | 2020-01-03 | 2022-05-24 | 15 Seconds of Fame, Inc. | Methods and apparatus for facial recognition on a user device |
US11539647B1 (en) * | 2020-06-17 | 2022-12-27 | Meta Platforms, Inc. | Message thread media gallery |
CN112015986B (en) * | 2020-08-26 | 2024-01-26 | 北京奇艺世纪科技有限公司 | Data pushing method, device, electronic equipment and computer readable storage medium |
Family Cites Families (26)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6222939B1 (en) | 1996-06-25 | 2001-04-24 | Eyematic Interfaces, Inc. | Labeled bunch graphs for image analysis |
US7099510B2 (en) | 2000-11-29 | 2006-08-29 | Hewlett-Packard Development Company, L.P. | Method and system for object detection in digital images |
US6917703B1 (en) | 2001-02-28 | 2005-07-12 | Nevengineering, Inc. | Method and apparatus for image analysis of a gabor-wavelet transformed image using a neural network |
US7890871B2 (en) * | 2004-08-26 | 2011-02-15 | Redlands Technology, Llc | System and method for dynamically generating, maintaining, and growing an online social network |
KR100641791B1 (en) | 2006-02-14 | 2006-11-02 | (주)올라웍스 | Tagging Method and System for Digital Data |
JP2007249821A (en) * | 2006-03-17 | 2007-09-27 | Nec Corp | Content sharing system |
US7668405B2 (en) * | 2006-04-07 | 2010-02-23 | Eastman Kodak Company | Forming connections between image collections |
WO2007122726A1 (en) * | 2006-04-21 | 2007-11-01 | Mitsubishi Denki Kabushiki Kaisha | Authenticating server device, terminal device, authenticating system and authenticating method |
US7916976B1 (en) * | 2006-10-05 | 2011-03-29 | Kedikian Roland H | Facial based image organization and retrieval method |
JP4829762B2 (en) * | 2006-12-06 | 2011-12-07 | キヤノン株式会社 | Information processing apparatus, control method therefor, and program |
US9665597B2 (en) | 2006-12-05 | 2017-05-30 | Qualcomm Incorporated | Method and system for processing images using time and location filters |
US9122645B1 (en) * | 2006-12-20 | 2015-09-01 | Qurio Holdings, Inc. | Method and system for tagging within virtual groups |
US8788529B2 (en) * | 2007-02-26 | 2014-07-22 | Microsoft Corp. | Information sharing between images |
JP5164398B2 (en) * | 2007-03-08 | 2013-03-21 | キヤノン株式会社 | Information processing apparatus and control method thereof |
US8732161B2 (en) | 2007-04-27 | 2014-05-20 | The Regents Of The University Of California | Event based organization and access of digital photos |
US20090199093A1 (en) | 2007-09-04 | 2009-08-06 | Tridib Chakravarty | Image Capture And Sharing System and Method |
US8385950B1 (en) * | 2007-11-09 | 2013-02-26 | Google Inc. | Capturing and automatically uploading media content |
JP5045413B2 (en) * | 2007-12-13 | 2012-10-10 | 日本電気株式会社 | Photo output system |
US8166034B2 (en) * | 2008-03-26 | 2012-04-24 | Fujifilm Corporation | Saving device for image sharing, image sharing system, and image sharing method |
JP5080524B2 (en) | 2008-03-26 | 2012-11-21 | 富士フイルム株式会社 | Storage device for image sharing, image sharing and method |
JP2011516966A (en) * | 2008-04-02 | 2011-05-26 | グーグル インコーポレイテッド | Method and apparatus for incorporating automatic face recognition in a digital image collection |
US8224899B2 (en) * | 2008-04-17 | 2012-07-17 | Eloy Technology, Llc | Method and system for aggregating media collections between participants of a sharing network |
US8676001B2 (en) | 2008-05-12 | 2014-03-18 | Google Inc. | Automatic discovery of popular landmarks |
US20100056188A1 (en) | 2008-08-29 | 2010-03-04 | Motorola, Inc. | Method and Apparatus for Processing a Digital Image to Select Message Recipients in a Communication Device |
WO2010028169A2 (en) | 2008-09-05 | 2010-03-11 | Fotonauts, Inc. | Reverse tagging of images in system for managing and sharing digital images |
US8571331B2 (en) * | 2009-11-30 | 2013-10-29 | Xerox Corporation | Content based image selection for automatic photo album generation |
-
2011
- 2011-07-22 US US13/188,879 patent/US8270684B2/en not_active Expired - Fee Related
- 2011-07-27 WO PCT/US2011/045532 patent/WO2012015919A1/en active Application Filing
- 2011-07-27 KR KR1020137004789A patent/KR101810578B1/en active IP Right Grant
- 2011-07-27 CN CN201180046353.XA patent/CN103119595B/en active Active
- 2011-07-27 JP JP2013521938A patent/JP5801395B2/en active Active
- 2011-07-27 EP EP11741726.1A patent/EP2599016A1/en not_active Ceased
- 2011-09-27 US US13/246,628 patent/US8194940B1/en active Active
-
2012
- 2012-08-21 US US13/590,354 patent/US8634603B2/en active Active
-
2014
- 2014-01-07 US US14/149,483 patent/US20140304269A1/en not_active Abandoned
Also Published As
Publication number | Publication date |
---|---|
US8270684B2 (en) | 2012-09-18 |
CN103119595B (en) | 2016-10-05 |
WO2012015919A1 (en) | 2012-02-02 |
JP2013541060A (en) | 2013-11-07 |
US20120314917A1 (en) | 2012-12-13 |
US8194940B1 (en) | 2012-06-05 |
CN103119595A (en) | 2013-05-22 |
EP2599016A1 (en) | 2013-06-05 |
US20120027256A1 (en) | 2012-02-02 |
KR20130102549A (en) | 2013-09-17 |
US20140304269A1 (en) | 2014-10-09 |
US8634603B2 (en) | 2014-01-21 |
KR101810578B1 (en) | 2018-01-25 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
JP5801395B2 (en) | Automatic media sharing via shutter click | |
US10303756B2 (en) | Creating a narrative description of media content and applications thereof | |
US9904723B2 (en) | Event based metadata synthesis | |
US8805165B2 (en) | Aligning and summarizing different photo streams | |
US9727565B2 (en) | Photo and video search | |
US9349077B2 (en) | Computer-implemented method, a computer program product and a computer system for image processing | |
KR101417548B1 (en) | Method and system for generating and labeling events in photo collections | |
US8380039B2 (en) | Method for aligning different photo streams | |
US8300953B2 (en) | Categorization of digital media based on media characteristics | |
JP6396897B2 (en) | Search for events by attendees | |
US20120114307A1 (en) | Aligning and annotating different photo streams | |
KR101479260B1 (en) | Method for searching closeness between people based on photos | |
KR101563238B1 (en) | Apparatus and method for creating closeness between people based on photos, and computer-readable recording medium with program therefor | |
US20180189602A1 (en) | Method of and system for determining and selecting media representing event diversity | |
US20230205812A1 (en) | Ai-powered raw file management |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
A621 | Written request for application examination |
Free format text: JAPANESE INTERMEDIATE CODE: A621Effective date: 20140424 |
|
A977 | Report on retrieval |
Free format text: JAPANESE INTERMEDIATE CODE: A971007Effective date: 20150220 |
|
A131 | Notification of reasons for refusal |
Free format text: JAPANESE INTERMEDIATE CODE: A131Effective date: 20150310 |
|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20150610 |
|
TRDD | Decision of grant or rejection written | ||
A01 | Written decision to grant a patent or to grant a registration (utility model) |
Free format text: JAPANESE INTERMEDIATE CODE: A01Effective date: 20150810 |
|
A61 | First payment of annual fees (during grant procedure) |
Free format text: JAPANESE INTERMEDIATE CODE: A61Effective date: 20150826 |
|
R150 | Certificate of patent or registration of utility model |
Ref document number: 5801395Country of ref document: JPFree format text: JAPANESE INTERMEDIATE CODE: R150 |
|
S533 | Written request for registration of change of name |
Free format text: JAPANESE INTERMEDIATE CODE: R313533 |
|
R350 | Written notification of registration of transfer |
Free format text: JAPANESE INTERMEDIATE CODE: R350 |
|
R250 | Receipt of annual fees |
Free format text: JAPANESE INTERMEDIATE CODE: R250 |
|
R250 | Receipt of annual fees |
Free format text: JAPANESE INTERMEDIATE CODE: R250 |
|
RD02 | Notification of acceptance of power of attorney |
Free format text: JAPANESE INTERMEDIATE CODE: R3D02 |
|
R250 | Receipt of annual fees |
Free format text: JAPANESE INTERMEDIATE CODE: R250 |
|
R250 | Receipt of annual fees |
Free format text: JAPANESE INTERMEDIATE CODE: R250 |
|
R250 | Receipt of annual fees |
Free format text: JAPANESE INTERMEDIATE CODE: R250 |
|
R250 | Receipt of annual fees |
Free format text: JAPANESE INTERMEDIATE CODE: R250 |