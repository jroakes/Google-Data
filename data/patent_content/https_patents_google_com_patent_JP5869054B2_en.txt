JP5869054B2 - Method and apparatus for incorporating automatic face recognition in a digital image collection - Google Patents
Method and apparatus for incorporating automatic face recognition in a digital image collection Download PDFInfo
- Publication number
- JP5869054B2 JP5869054B2 JP2014128813A JP2014128813A JP5869054B2 JP 5869054 B2 JP5869054 B2 JP 5869054B2 JP 2014128813 A JP2014128813 A JP 2014128813A JP 2014128813 A JP2014128813 A JP 2014128813A JP 5869054 B2 JP5869054 B2 JP 5869054B2
- Authority
- JP
- Japan
- Prior art keywords
- face
- images
- image
- displaying
- similar groups
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
- 238000000034 method Methods 0.000 title claims description 83
- 230000001815 facial effect Effects 0.000 claims description 50
- 238000001514 detection method Methods 0.000 description 38
- 230000008569 process Effects 0.000 description 20
- 238000010586 diagram Methods 0.000 description 7
- 230000006870 function Effects 0.000 description 7
- 238000012545 processing Methods 0.000 description 7
- 230000000694 effects Effects 0.000 description 5
- 230000007246 mechanism Effects 0.000 description 5
- 125000002066 L-histidyl group Chemical group [H]N1C([H])=NC(C([H])([H])[C@](C(=O)[*])([H])N([H])[H])=C1[H] 0.000 description 4
- 238000012986 modification Methods 0.000 description 4
- 230000004048 modification Effects 0.000 description 4
- 239000013598 vector Substances 0.000 description 4
- 230000015572 biosynthetic process Effects 0.000 description 3
- 230000004044 response Effects 0.000 description 3
- 238000012552 review Methods 0.000 description 3
- 230000002776 aggregation Effects 0.000 description 2
- 238000004220 aggregation Methods 0.000 description 2
- 238000012790 confirmation Methods 0.000 description 2
- 230000003993 interaction Effects 0.000 description 2
- 230000006978 adaptation Effects 0.000 description 1
- 238000013459 approach Methods 0.000 description 1
- 238000013528 artificial neural network Methods 0.000 description 1
- 238000004422 calculation algorithm Methods 0.000 description 1
- 238000004364 calculation method Methods 0.000 description 1
- 230000008859 change Effects 0.000 description 1
- 230000001149 cognitive effect Effects 0.000 description 1
- 238000004891 communication Methods 0.000 description 1
- 230000003247 decreasing effect Effects 0.000 description 1
- 238000012217 deletion Methods 0.000 description 1
- 230000037430 deletion Effects 0.000 description 1
- 238000005516 engineering process Methods 0.000 description 1
- 238000011156 evaluation Methods 0.000 description 1
- 239000000284 extract Substances 0.000 description 1
- 230000010354 integration Effects 0.000 description 1
- 230000002452 interceptive effect Effects 0.000 description 1
- 238000012423 maintenance Methods 0.000 description 1
- 238000000513 principal component analysis Methods 0.000 description 1
- 230000001960 triggered effect Effects 0.000 description 1
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V40/00—Recognition of biometric, human-related or animal-related patterns in image or video data
- G06V40/10—Human or animal bodies, e.g. vehicle occupants or pedestrians; Body parts, e.g. hands
- G06V40/16—Human faces, e.g. facial parts, sketches or expressions
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V40/00—Recognition of biometric, human-related or animal-related patterns in image or video data
- G06V40/10—Human or animal bodies, e.g. vehicle occupants or pedestrians; Body parts, e.g. hands
- G06V40/16—Human faces, e.g. facial parts, sketches or expressions
- G06V40/172—Classification, e.g. identification
Description
（技術分野）
本発明は、概して、デジタル画像の集合に関し、より具体的には、デジタル画像の集合内での自動顔認識の使用に関する。
(Technical field)
The present invention relates generally to a collection of digital images, and more specifically to the use of automatic face recognition within a collection of digital images.
（背景）
デジタルカメラ、安価なデジタル記憶装置、およびインターネットを介した広範なネットワーク接続性は、分散した写真の集合の数、サイズおよびアクセスの大規模な成長をもたらした。しかしながら、デジタル写真およびデジタル写真の集合が成長するに従い、特定の特徴を含む特定の写真（複数可）の検索は、ますます煩雑となる。
(background)
Digital cameras, inexpensive digital storage devices, and extensive network connectivity over the Internet have led to massive growth in the number, size and access of distributed photo collections. However, as digital photos and collections of digital photos grow, searching for specific photo (s) that contain specific features becomes increasingly complicated.
個人がそのデジタル写真の集合をアルバム名または日付ごとにフォルダに整理することができる。しかしながら、これらのフォルダにまたがって写真にアクセスしたい場合が数多くあり得る。例えば、集合のうち特定の個人の写真を見付けたい場合があり得る。写真の内容に基づくそのような検索活動を促進するために、多くの技術を使用することができる。１つ以上のキーワードによる各写真のタグ付けは、そのような技術の一つである。 Individuals can organize their collection of digital photos into folders by album name or date. However, there may be many cases where you want to access photos across these folders. For example, you may want to find a picture of a particular individual in the set. Many techniques can be used to facilitate such search activities based on the content of the photos. Tagging each photo with one or more keywords is one such technique.
一般に、各写真のタグ付けはユーザにより行われ、ユーザは手作業でタグまたはタグワードを提供する。さらに、そのようなタグは、日付、アルバムまたはフォルダ情報等、各写真に関連した情報から派生し得る。しかしながら、これらの手法は、著しいユーザ入力を必要とし、一般に大量のデジタル写真の集合には良好に適合しない。自動顔認識技術を使用する写真の自動タグ付けは、大量の写真の集合の総合的なタグ付けを達成するための有望な手法である。 In general, each photo is tagged by the user, who provides the tag or tag word manually. In addition, such tags may be derived from information associated with each photo, such as date, album or folder information. However, these approaches require significant user input and are generally not well suited for large collections of digital photographs. Automatic tagging of photos using automatic face recognition technology is a promising technique for achieving comprehensive tagging of large collections of photos.
自動顔認識は、一般に、顔検出段階および顔認識段階の２段階で機能する。前者は、全体的な顔の特徴に基づき写真内の顔を自動的に選び出すことにより達成することができる。後者は、以前に認識された顔画像のうちの１つ以上に対する検出された顔の比較を含み得る。新たに検出された顔を比較することができる特定の顔の複数の識別および確認された画像が存在すれば、第２段階の正確性は増加する。 Automatic face recognition generally functions in two stages, a face detection stage and a face recognition stage. The former can be accomplished by automatically selecting faces in the photo based on overall facial features. The latter may include a comparison of detected faces against one or more of the previously recognized face images. The accuracy of the second stage is increased if there are multiple identified and confirmed images of a particular face that can be compared with newly detected faces.
大量のデジタル画像の集合における自動顔認識の有効性は、ユーザにより識別および確認されるそれぞれの人物の十分な数および種類の顔画像がないために、また誤った識別のために制限され得る。デジタル写真の集合においてユーザが顔を識別および確認できるようにする現在利用可能なインタフェースは、ユーザが１度に多くの顔画像を識別することをより容易にすることを試みている。例えば、あるインタフェースは、特定の識別された人物に属する可能性のある顔画像を１つ以上の行に配設してユーザに提示し、システムが生成した分類をユーザが認めるかまたは拒否するかを聞くことができる。別のインタフェースは、写真において新たに検出された特定の顔に対する１つ以上の名前付けオプションをユーザに提示することができる。例えば、第１の場合において、ユーザは、リストされた集合に属さないそれぞれの個々の顔を削除する作業を課される。第２の場合において、ユーザは、それぞれの個々の画像を名前でタグ付けする作業を課される。上記の両方の場合において、画像を取り除き個々の画像に名前を付けるのがまだ煩雑である。１度に複数の画像を識別するタスクを便利および効率的とするには、自動顔認識をデジタル写真の集合全体にわたり実行することができるような、よりユーザに優しく効率的な方法が必要である。 The effectiveness of automatic face recognition in large collections of digital images can be limited due to the lack of a sufficient number and type of face images for each person identified and verified by the user and due to false identification. Currently available interfaces that allow a user to identify and confirm faces in a collection of digital photos attempt to make it easier for the user to identify many face images at once. For example, an interface may display facial images that may belong to a particular identified person in one or more rows and present it to the user, allowing the user to accept or reject the system-generated classification Can hear. Another interface can present the user with one or more naming options for a particular face newly detected in the photo. For example, in the first case, the user is tasked with deleting each individual face that does not belong to the listed set. In the second case, the user is tasked with tagging each individual image with a name. In both of the above cases, it is still cumbersome to remove images and give names to individual images. To make the task of identifying multiple images at once convenient and efficient, there is a need for a more user-friendly and efficient method that allows automatic face recognition to be performed across a collection of digital photos. .
ユーザは、プロセスのほとんどを自動化する柔軟な能力を必要とする。特定の人物のより多様な画像を利用した自動顔認識は、確認プロセスがユーザにとってより容易となり、それによってより多数の画像のタグ付けを促進するように、検出された顔画像をユーザ確認のために類別および配設することがより可能となる。 Users need the flexible ability to automate most of the process. Automatic face recognition using a wider variety of images of a specific person can make the confirmation process easier for the user, thereby facilitating tagging of a larger number of images for user confirmation. It becomes more possible to classify and arrange them.
（概要）
本発明の実施形態は、デジタル画像の集合の整理に対する自動顔認識の統合に関する。一実施形態において、デジタル画像の集合から顔画像データベースを作成および更新するための方法が実施される。デジタル画像の集合からの画像において顔画像が検出される。検出された顔画像は、検出された顔画像のそれぞれに対して計算された顔認識テンプレートに基づき類似グループにグループ分けされる。検出された顔画像は、類似グループとしてユーザに表示され、表示された類似グループのそれぞれにおける個々の顔画像を認めるかまたは拒否するユーザ入力が受容される。類似グループのそれぞれは、受容されたユーザ入力に基づき更新され、更新された類似グループは、顔画像データベースに記憶される。
(Overview)
Embodiments of the present invention relate to the integration of automatic face recognition for organizing a collection of digital images. In one embodiment, a method for creating and updating a face image database from a collection of digital images is implemented. A face image is detected in an image from the set of digital images. The detected face images are grouped into similar groups based on the face recognition templates calculated for each of the detected face images. The detected face images are displayed to the user as similar groups, and user input is accepted that accepts or rejects individual face images in each of the displayed similar groups. Each of the similar groups is updated based on the received user input, and the updated similar group is stored in the face image database.
別の実施形態において、対象名、例えば人物の名前等がユーザから受容される。顔画像データベースに記憶された顔画像の少なくとも１つの名前を付けられた類似グループから第１組の顔画像が取得され、取得された類似グループと関連付けられた名前は、ユーザにより提供された対象名と実質的に一致する。第２組の顔画像が、関連した名前を有さず、第１組の顔画像の顔認識テンプレートと実質的に一致する顔認識テンプレートを有する顔画像データベースにおける類似グループから取得される。第１組および第２組は、クラスタとしてグラフィカルユーザインタフェースに表示される。第２組の表示された類似グループにおける個々の顔画像のメンバーシップを認めるかまたは拒絶するユーザ入力が受容され、第２組はユーザ入力に応じて更新される。一実施形態において、第１組はクラスタとして表示され、第２組はクラスタとして各類似グループとともに表示される。別の実施形態において、第１組は、グラフィカルユーザインタフェースの第１の領域に表示され、第２組は、第１組との類似性の順で配設された画像とともに第２の領域に表示される。 In another embodiment, a subject name, such as a person's name, is received from the user. A first set of face images is acquired from at least one similar group of face images stored in the face image database, and the name associated with the acquired similar group is an object name provided by the user Substantially matches. A second set of face images is obtained from a similar group in the face image database that does not have an associated name and has a face recognition template that substantially matches the face recognition template of the first set of face images. The first set and the second set are displayed on the graphical user interface as clusters. User input to accept or reject membership of individual facial images in the second set of displayed similar groups is accepted, and the second set is updated in response to the user input. In one embodiment, the first set is displayed as a cluster and the second set is displayed with each similar group as a cluster. In another embodiment, the first set is displayed in the first area of the graphical user interface, and the second set is displayed in the second area with images arranged in order of similarity to the first set. Is done.
別の実施形態は、デジタル画像の集合において検出された複数の顔に名前を割り当てるための名前付けツールを含む。顔画像データベースは、デジタル画像の集合の画像において検出された顔画像に関連するデータを記憶する。さらに、名前付けツールは、グラフィカルユーザインタフェースと、デジタル画像の集合において顔を検出し、検出された顔に関連するデータを顔画像データベースに記憶する、顔検出モジュールと、顔画像データベース内の各顔画像に対する少なくとも１つの顔認識テンプレートを計算する、顔認識モジュールと、類似した顔画像が１つの類似グループに属するように、それぞれのテンプレートに従い顔画像データベース内の顔画像をグルー分けする、類似グループ分けモジュールとを含み得る。 Another embodiment includes a naming tool for assigning names to a plurality of faces detected in a collection of digital images. The face image database stores data related to face images detected in the images of the set of digital images. The naming tool further includes a graphical user interface, a face detection module that detects faces in the collection of digital images and stores data related to the detected faces in the face image database, and each face in the face image database. Similar grouping that calculates at least one face recognition template for an image, and groups the face images in the face image database according to each template so that similar face images belong to one similar group Modules.
さらに別の実施形態は、デジタル画像の集合にアクセスする方法を含む。システムは、対象名を得、対象名が割り当てられた顔画像データベース内の１組の顔画像を選択し、選択された顔画像と関連付けられたデジタル画像の集合からのデジタル画像を見付ける。一実施形態において、見付かったデジタル画像は、パーソナライズされたスライドショーとして表示され得る。 Yet another embodiment includes a method of accessing a collection of digital images. The system obtains an object name, selects a set of face images in the face image database to which the object name is assigned, and finds a digital image from the set of digital images associated with the selected face image. In one embodiment, the found digital images can be displayed as a personalized slide show.
さらに別の実施形態は、複数のソース顔画像を使用して人物の画像を検索する方法を含む。システムは、対象名を受容し、対象名が割り当てられた顔画像データベースから一組の顔画像を選択し、選択されたソース画像の組を使用して顔認識により１つ以上のデジタル画像の集合を検索する。 Yet another embodiment includes a method of retrieving a person image using a plurality of source face images. The system accepts an object name, selects a set of face images from the face image database assigned the object name, and uses the selected set of source images to collect one or more digital images by face recognition. Search for.
別の実施形態は、デジタル画像の集合内の１組の画像への制限されたアクセスを提供する方法を含む。ユーザは、対象名を割り当てられた顔画像へのアクセスを認証される。対象名を割り当てられた１組の顔画像が選択され、ユーザは、画像の集合内のそれらの画像へのアクセスを許可される。 Another embodiment includes a method for providing limited access to a set of images in a collection of digital images. The user is authenticated for access to the face image assigned the subject name. A set of face images assigned subject names is selected and the user is allowed access to those images in the set of images.
本明細書は、例えば、以下の項目も提供する。
（項目１）
デジタル画像の集合から顔画像データベースを作成および更新するための方法であって、
（ａ）該デジタル画像の集合からの画像において、第１組の顔画像を検出することと、
（ｂ）該第１組の顔画像を類似グループにグループ分けすることであって、該類似グループのそれぞれにおいて、顔画像の顔認識テンプレートが、所定の範囲内にある、ことと、
（ｃ）該類似グループの１つ以上をグラフィカルユーザインタフェースに表示することであって、該類似グループのそれぞれは、実質的に別個に表示される、ことと、
（ｄ）該表示された類似グループの１つ以上における個々の顔画像を確認または拒否するためのユーザ入力を受容することと、
（ｅ）該ユーザ入力により該表示された類似グループの１つ以上を更新することと
を含む、方法。
（項目２）
（ｆ）前記更新された類似グループを前記顔画像データベースに記憶することをさらに含む、項目１に記載の方法。
（項目３）
（ｇ）前記表示された類似グループの１つ以上に対する対象名を受容することと、
（ｈ）該対象名により該表示された類似グループの１つ以上を更新することと
をさらに含む、項目２に記載の方法。
（項目４）
前記段階（ｇ）は、
ユーザが、前記表示された類似グループのうちの少なくとも１つに対する名前をエントリのリストから選択することを可能にすることであって、該エントリのリストの各エントリは、名前および顔画像のうちの少なくとも１つを有し、該各エントリは、名前と関連した１つ以上の顔画像に対応し、該エントリのリストは、該表示された類似グループのうちの少なくとも１つへの類似性に従い順序付けられる、ことを含む、項目３に記載の方法。
（項目５）
前記段階（ｃ）は、
（ｉ）前記１つ以上の類似グループのそれぞれからの代表的顔画像を、選択可能なフィルムストリップレイアウトで表示するステップと、
（ｉｉ）ユーザ入力に基づいて、代表的顔画像を選択することと、
（ｉｉｉ）該選択された代表的顔画像に対応する少なくとも１つの類似グループのうちの顔画像を表示することと
を含む、項目２に記載の方法。
（項目６）
デジタル画像の集合から顔画像データベースを更新する方法であって、
（ａ）ユーザから対象名を受容することと、
（ｂ）該顔画像データベースに記憶された顔画像の少なくとも１つの名前を付けられた類似グループから第１組の顔画像を取得することであって、該少なくとも１つの類似グループと関連付けられた名前は、対象名と実質的に一致する、ことと、
（ｃ）該第１組に対する第１の顔認識テンプレートを決定することと、
（ｄ）該顔画像データベースにおける１つ以上の名前を付けられていない類似グループから第２組の顔画像を取得することであって、該名前を付けられていない類似グループは関連した名前を有さず、該名前を付けられていない類似グループの顔認識テンプレートは該第１の顔認識テンプレートと実質的に一致する、ことと、
（ｅ）該第１組をグラフィカルユーザインタフェースに表示することと、
（ｆ）該第２組を該グラフィカルユーザインタフェースに表示することと、
（ｇ）該第２組に関連付けられたユーザ入力を受容することと、
（ｈ）該ユーザ入力に従い該第２組を更新することと
を含む、方法。
（項目７）
ステップ（ｅ）は、
（ｉ）クラスタに配設された前記第１組をグラフィカルユーザインタフェースに表示することを含む、項目６に記載の方法。
（項目８）
ステップ（ｆ）は、
（ｉ）前記第２組の各類似グループが別個のクラスタに配設された状態で、該第２組を前記グラフィカルユーザインタフェースに表示することを含む、項目７に記載の方法。
（項目９）
ユーザ入力を受容することは、
（ｉ）前記ユーザ入力に基づき１つ以上の顔画像を拒否することであって、該拒否された１つ以上の顔画像は、前記対象名を割り当てられない、ことと、
（ｉｉ）該ユーザ入力に基づき前記第２組の１つ以上の類似グループを拒否することであって、該拒否された１つ以上の類似グループは、該対象名を割り当てられない、ことと、
（ｉｉｉ）該ユーザ入力に基づき該第２組の１つ以上の類似グループを確認することと
のうちの１つ以上をさらに含む、項目６に記載の方法。
（項目１０）
前記段階（ｈ）は、
（ｉ）前記ユーザ入力に基づき前記第２組の類似グループの顔画像に前記対象名を割り当てることをさらに含む、項目６に記載の方法。
（項目１１）
ステップ（ｅ）は、
（ｉ）前記第１組を前記グラフィカルユーザインタフェースの第１の領域内に表示することを含む、項目６に記載の方法。
（項目１２）
ステップ（ｆ）は、
（ｉ）前記第２組を前記グラフィカルユーザインタフェースの第２の領域に表示することであって、該第２の組は、前記第１組との類似性に従い順序付けられる、ことを含む、項目１１に記載の方法。
（項目１３）
デジタル画像の集合において検出された複数の顔に名前を割り当てるための名前付けツールであって、
（ａ）該デジタル画像の集合からの画像において検出された顔画像に関連するデータを記憶するように構成される、顔画像データベースと、
（ｂ）少なくとも１つのグラフィカルユーザインタフェースと、
（ｃ）該少なくとも１つのグラフィカルユーザインタフェースを通して、該データおよび該画像の一方または両方の操作を可能にする少なくとも１つのユーザ入力デバイスと、
（ｄ）該デジタル画像の集合の画像において顔を検出することと、該検出された顔に関連するデータを該顔画像データベースに記憶することとを行うように構成される、顔検出モジュールと、
（ｅ）該顔画像データベース内の各顔画像に対する少なくとも１つの顔認識テンプレートを計算するように構成される、顔認識モジュールと、
（ｆ）実質的に類似した顔画像が１つの類似グループに属するように、それぞれの顔認識テンプレートに従い該顔画像データベース内の顔画像をグループ分けするように構成される、類似性順位付けモジュールと、
（ｇ）類似グループに従い該顔画像をレイアウトするように構成される、表示レイアウト生成モジュールと
を備え、該少なくとも１つのユーザ入力デバイス、該少なくとも１つのグラフィカルユーザインタフェース、該デジタル画像の集合、および該顔画像データベースは、該顔検出モジュール、該顔認識モジュール、該類似性順位付けモジュール、および該表示レイアウト生成モジュールに通信可能に結合される、名前付けツール。
（項目１４）
デジタル画像の集合からデジタル画像にアクセスする方法であって、
（ａ）対象名を受容することと、
（ｂ）顔画像データベース内の第１組の顔画像を選択することであって、該第１組の中の顔画像は、該対象名を割り当てられる、ことと、
（ｃ）該デジタル画像の集合からデジタル画像を見付けることであって、該デジタル画像は、以前に該第１組の顔画像に関連付けられた、ことと
を含む、方法。
（項目１５）
（ｄ）前記デジタル画像を表示することと、
（ｅ）前記顔画像データベースに記憶されたデータを使用して、１つ以上の表示されたデジタル画像における少なくとも１つの顔に特殊効果を表示することと
をさらに含む、項目１４に記載の方法。
（項目１６）
（ｄ）前記対象名を割り当てられた顔画像にユーザがアクセスするのを認証することと、
（ｅ）前記第１組に以前に関連付けられた前記デジタル画像の集合の中の画像に該ユーザがアクセスするのを許可することと
をさらに含む、項目１４に記載の方法。
（項目１７）
複数のソース画像を使用して人物の画像を検索する方法であって、
（ａ）対象名を受容することと、
（ｂ）該対象名を割り当てられる顔画像データベース内の第１組の顔画像を選択することと、
（ｃ）１つ以上のデジタル画像の集合を検索することであって、検索は、該第１組の顔画像を使用する自動顔認識を含む、ことと、
を含む、方法。
（項目１８）
（ｄ）一致画像が見付かった時に警告を生成することであって、該一致画像は、前記第１組の顔画像の中の少なくとも１つの顔画像に実質的に一致する顔画像を含む、ことをさらに含む、項目１７に記載の方法。
（項目１９）
（ｅ）ユーザを前記対象名に関連付けることをさらに含む、項目１８に記載の方法。
（項目２０）
前記警告を生成することは、
（ｉ）一致画像を見付けることであって、該一致画像は、前記第１の組の顔画像の中の少なくとも１つの顔画像に実質的に一致する顔画像を含む、ことと、
（ｉｉ）掲載された画像において所定の種類の表示イベントのうちの少なくとも１つを検出することであって、該掲載された画像は、該少なくとも１つの顔画像に実質的に一致する一致顔画像を含む、ことと、
（ｉｉｉ）該所定の種類の表示イベントのうちの前記少なくとも１つに関して前記ユーザに通知することと、
（ｉｖ）該ユーザから入力選択を受容することと
を含む、項目１９に記載の方法。
（項目２１）
（ｆ）前記入力選択に基づき、１つ以上の場所から前記掲載された画像を自動的に削除することをさらに含む、項目２０に記載の方法。
（項目２２）
（ｆ）前記入力選択に基づき、前記掲載された画像に割り当てられた１つ以上のタグを修正することをさらに含む、項目２０に記載の方法。
（項目２３）
（ｆ）前記入力選択に基づき、前記少なくとも１つの画像を有する１つ以上のソースに通知することをさらに含む、項目２０に記載の方法。
（項目２４）
一致画像を見付けることは、
（ｉ）前記少なくとも１つの画像において顔画像を検出することと、
（ｉｉ）前記対象名を表す該顔画像を決定することと、
（ｉｉｉ）該対象名および前記ユーザのうちの１つ以上を関連付けるタグを、該少なくとも１つの画像に割り当てることと
を含む、項目２０に記載の方法。
本発明のさらなる実施形態、特徴、および利点、ならびに本発明の様々な実施形態の構造および作用を、付随の図面を参照して以下で詳細に説明する。
This specification also provides the following items, for example.
(Item 1)
A method for creating and updating a face image database from a collection of digital images, comprising:
(A) detecting a first set of face images in an image from the set of digital images;
(B) grouping the first set of face images into similar groups, wherein in each of the similar groups, the face recognition template of the face image is within a predetermined range;
(C) displaying one or more of the similar groups in a graphical user interface, wherein each of the similar groups is displayed substantially separately;
(D) accepting user input to confirm or reject individual facial images in one or more of the displayed similar groups;
(E) updating one or more of the displayed similar groups according to the user input.
(Item 2)
(F) The method of item 1, further comprising storing the updated similarity group in the face image database.
(Item 3)
(G) accepting subject names for one or more of the displayed similar groups;
(H) The method according to item 2, further comprising: updating one or more of the displayed similar groups with the target name.
(Item 4)
Said step (g) comprises:
Allowing a user to select a name for at least one of the displayed similar groups from a list of entries, each entry of the list of entries being a name and a face image And each entry corresponds to one or more facial images associated with a name, and the list of entries is ordered according to similarity to at least one of the displayed similar groups 4. The method of item 3, comprising
(Item 5)
Said step (c) comprises:
(I) displaying representative face images from each of the one or more similar groups in a selectable filmstrip layout;
(Ii) selecting a representative face image based on user input;
(Iii) displaying a face image of at least one similar group corresponding to the selected representative face image.
(Item 6)
A method of updating a face image database from a set of digital images,
(A) accepting the subject name from the user;
(B) obtaining a first set of facial images from at least one named similar group of facial images stored in the facial image database, the name associated with the at least one similar group Substantially matches the subject name, and
(C) determining a first face recognition template for the first set;
(D) obtaining a second set of face images from one or more unnamed similar groups in the face image database, wherein the unnamed similar groups have associated names; And the unnamed similar group of face recognition templates substantially match the first face recognition template;
(E) displaying the first set on a graphical user interface;
(F) displaying the second set on the graphical user interface;
(G) accepting user input associated with the second set;
(H) updating the second set according to the user input.
(Item 7)
Step (e)
The method of item 6, comprising: (i) displaying the first set arranged in a cluster on a graphical user interface.
(Item 8)
Step (f)
8. The method of item 7, comprising: (i) displaying the second set on the graphical user interface with each similar group of the second set arranged in a separate cluster.
(Item 9)
Accepting user input is
(I) rejecting one or more face images based on the user input, wherein the rejected one or more face images are not assigned the subject name;
(Ii) rejecting the second set of one or more similar groups based on the user input, wherein the rejected one or more similar groups are not assigned the subject name;
7. The method of item 6, further comprising one or more of: (iii) confirming the second set of one or more similar groups based on the user input.
(Item 10)
Step (h) includes
7. The method of item 6, further comprising: (i) assigning the target name to face images of the second set of similar groups based on the user input.
(Item 11)
Step (e)
(I) The method of item 6, comprising displaying the first set in a first region of the graphical user interface.
(Item 12)
Step (f)
(I) displaying the second set in a second region of the graphical user interface, wherein the second set is ordered according to similarity to the first set. The method described in 1.
(Item 13)
A naming tool for assigning names to multiple faces detected in a collection of digital images,
(A) a face image database configured to store data associated with face images detected in images from the set of digital images;
(B) at least one graphical user interface;
(C) at least one user input device that allows manipulation of one or both of the data and the image through the at least one graphical user interface;
(D) a face detection module configured to detect a face in the image of the set of digital images and store data related to the detected face in the face image database;
(E) a face recognition module configured to calculate at least one face recognition template for each face image in the face image database;
(F) a similarity ranking module configured to group face images in the face image database according to respective face recognition templates so that substantially similar face images belong to one similar group; ,
(G) a display layout generation module configured to lay out the face image according to a similarity group, the at least one user input device, the at least one graphical user interface, the set of digital images, and the A naming tool communicatively coupled to the face detection module, the face recognition module, the similarity ranking module, and the display layout generation module.
(Item 14)
A method of accessing a digital image from a set of digital images,
(A) accepting the subject name;
(B) selecting a first set of face images in the face image database, wherein the face images in the first set are assigned the target name;
(C) finding a digital image from the set of digital images, the digital image having been previously associated with the first set of face images.
(Item 15)
(D) displaying the digital image;
15. The method of item 14, further comprising: (e) displaying special effects on at least one face in one or more displayed digital images using data stored in the face image database.
(Item 16)
(D) authenticating a user accessing a face image to which the subject name is assigned;
15. The method of item 14, further comprising: (e) authorizing the user to access an image in the set of digital images previously associated with the first set.
(Item 17)
A method for searching for an image of a person using multiple source images,
(A) accepting the subject name;
(B) selecting a first set of face images in the face image database to which the subject name is assigned;
(C) searching a set of one or more digital images, the search including automatic face recognition using the first set of face images;
Including a method.
(Item 18)
(D) generating a warning when a matching image is found, the matching image including a facial image that substantially matches at least one facial image in the first set of facial images; The method according to item 17, further comprising:
(Item 19)
(E) The method of item 18, further comprising associating a user with the subject name.
(Item 20)
Generating the warning is
(I) finding a matching image, the matching image including a face image substantially matching at least one face image in the first set of face images;
(Ii) detecting at least one of a predetermined type of display event in the posted image, wherein the posted image substantially matches the at least one face image Including, and
(Iii) notifying the user about the at least one of the predetermined types of display events;
(Iv) The method of item 19, comprising accepting an input selection from the user.
(Item 21)
(F) The method of item 20, further comprising automatically deleting the posted image from one or more locations based on the input selection.
(Item 22)
(F) The method of item 20, further comprising modifying one or more tags assigned to the posted image based on the input selection.
(Item 23)
(F) The method of item 20, further comprising notifying one or more sources having the at least one image based on the input selection.
(Item 24)
Finding a matching image
(I) detecting a face image in the at least one image;
(Ii) determining the face image representing the object name;
21. The method of item 20, comprising: (iii) assigning a tag that associates the subject name and one or more of the users to the at least one image.
Further embodiments, features, and advantages of the present invention, as well as the structure and operation of the various embodiments of the present invention, are described in detail below with reference to the accompanying drawings.
本発明の特徴および利点は、図面と併せて考慮すると以下に記載の詳細な説明からより明らかとなる。図面において、類似の参照番号は、全般的に、同一、機能的に同様、および／または実質的に同様の要素を示す。一般に、要素が最初に現れる図面は、対応する参照番号の最も左側の桁（複数を含む）により示される。 The features and advantages of the present invention will become more apparent from the detailed description set forth below when considered in conjunction with the drawings. In the drawings, like reference numbers generally indicate identical, functionally similar, and / or substantially similar elements. In general, the drawing in which an element first appears is indicated by the leftmost digit (s) in the corresponding reference number.
（実施形態の詳細な説明）
本明細書において、特定の用途の例示的な実施形態を参照しながら本発明を説明するが、本発明はそれに限定されないことを理解されたい。当業者は、本明細書における教示を利用して、本発明の範囲内、および本発明が有意に実用的となる追加の分野の範囲内で、追加の修正、用途、および実施形態を認識する。
(Detailed description of embodiment)
Although the present invention is described herein with reference to illustrative embodiments for particular applications, it should be understood that the invention is not limited thereto. Those skilled in the art will be able to utilize the teachings herein to recognize additional modifications, uses, and embodiments within the scope of the present invention and within additional fields where the present invention will be significantly practical. .
図１は、本発明の一実施形態による、自動顔認識をデジタル画像の集合に組み込むためのシステム１００の図である。サーバ１０１は、ネットワーク１３０を介してクライアント１２０に接続される。サーバ１０１は、ソフトウェアモジュール１０２を備えてもよい。これらは、顔検出１０６、顔認識１０５、類似グループ１０４の作成および維持、ならびにサーバ側の画像レイアウト生成１０３のためのモジュールと、顔画像のデータベース１０８と、デジタル画像の集合１０７とを含み得る。一実施形態において、サーバ１０１は、１つの計算プラットフォームであってもよく、ソフトウェアモジュール１０２およびデータベース１０７〜１０８は、その同じプラットフォーム上に実装されていてもよい。 FIG. 1 is a diagram of a system 100 for incorporating automatic face recognition into a collection of digital images, according to one embodiment of the invention. The server 101 is connected to the client 120 via the network 130. The server 101 may include a software module 102. These may include modules for face detection 106, face recognition 105, creation and maintenance of similarity groups 104, and server-side image layout generation 103, a face image database 108, and a set of digital images 107. In one embodiment, the server 101 may be a single computing platform, and the software module 102 and the databases 107-108 may be implemented on that same platform.
別の実施形態において、サーバ１０１は、１つ以上のネットワークにより相互接続された複数の計算プラットフォームを備えてもよい。ソフトウェアモジュール１０２およびデータベース１０７〜１０８は、サーバ１０１が備える計算プラットフォーム上に分散されてもよく、モジュール１０２およびデータベース１０７〜１０８の間の通信は、同じメッセージング機構、例えばＨＴＴＰ、ＵＤＰ、ＴＣＰ、ＩＰ、またはこれらの任意の組合せを使用して行われてもよい。例えば、サーバ１０１は、ウェブクライアントまたはブラウザからの要求を受信およびそれに応答するウェブサーバと、ユーザに対し画像管理および自動顔認識機能を有効化し、ウェブサーバからのコマンドを受信する別個のアプリケーションサーバと、アプリケーションサーバと通信してデジタル画像１０７の集合および顔画像１０８のデータベースを有効化する１つ以上のデータベースサーバとを備えてもよい。ウェブサーバ、アプリケーションサーバ、およびデータベースサーバの使用を組み合わせたシステムは、当技術分野において周知である。 In another embodiment, the server 101 may comprise multiple computing platforms interconnected by one or more networks. The software module 102 and the databases 107 to 108 may be distributed on a computing platform included in the server 101, and the communication between the module 102 and the databases 107 to 108 is performed by the same messaging mechanism, for example, HTTP, UDP, TCP, IP, Or any combination of these may be used. For example, the server 101 receives a web client or a request from a browser and a web server that responds to the request, and a separate application server that enables image management and automatic face recognition functions for the user and receives commands from the web server. , One or more database servers that communicate with the application server to validate the collection of digital images 107 and the database of facial images 108. Systems that combine the use of web servers, application servers, and database servers are well known in the art.
モジュール１０３〜１０６は、本発明の実施形態の実装における機能性を表す。１０２に示されるものより多い、または少ないモジュールをソフトウェアに実装して本発明の機能性を達成し得ることが、当業者には理解される。モジュール１０３〜１０６のそれぞれは、例えば、これに限定されないが、Ｊａｖａ（登録商標）、Ｃ＋＋、およびＣ等のコンピュータプログラミング言語の１つまたは組合せを使用して実装することができる。 Modules 103-106 represent functionality in the implementation of an embodiment of the present invention. Those skilled in the art will appreciate that more or fewer modules than those shown in 102 may be implemented in software to achieve the functionality of the present invention. Each of the modules 103-106 can be implemented using one or a combination of computer programming languages such as, but not limited to, Java, C ++, and C, for example.
いくつかの実施形態において、各データベース１０７および１０８は、１つ以上の相互接続されたデータベースを備えてもよい。例えば、デジタル画像の集合１０７は、デジタル画像の複数の分散した集合の集約を備えてもよく、分散した集合は、同じまたは異なるユーザにより所有され得る。例えば、集合は、１人以上のユーザのデジタル写真アルバムを備えてもよい。現在利用可能な例は、ＧｏｏｇｌｅのＰＩＣＡＳＡウェブベースデジタル写真サービスにおける１組のユーザアルバムであってもよい。本明細書においてはデータベースと呼ばれるが、デジタル画像の集合１０７は、所望の画像を検索および取得する能力を伴った、デジタル画像を記憶する任意の機構として実装され得ることが、当業者には理解される。 In some embodiments, each database 107 and 108 may comprise one or more interconnected databases. For example, the digital image collection 107 may comprise an aggregation of multiple distributed collections of digital images, which may be owned by the same or different users. For example, a collection may comprise a digital photo album of one or more users. An example currently available may be a set of user albums in Google's PICASA web-based digital photo service. Although referred to herein as a database, those skilled in the art will appreciate that the collection of digital images 107 can be implemented as any mechanism for storing digital images with the ability to retrieve and obtain the desired images. Is done.
顔画像１０８のデータベースは、１組のエントリを含んでもよく、各エントリは、集合１０７において検出される、本明細書において顔画像と呼ばれる顔に対応する。 The database of face images 108 may include a set of entries, each entry corresponding to a face, referred to herein as a face image, detected in the set 107.
データベース１０８内のエントリは、顔画像と、顔画像が検出された集合１０７における対応する画像へのポインタと、割り当てられた名前に対するタグ値を含む１つ以上のタグ値と、１つ以上の顔認識値と、類似グループの識別とを含み得る。タグおよび類似グループについて、以下でより詳細に説明する。 The entries in the database 108 include a face image, a pointer to a corresponding image in the set 107 from which the face image was detected, one or more tag values including a tag value for the assigned name, and one or more faces. It may include a recognition value and identification of a similar group. Tags and similar groups are described in more detail below.
本明細書において使用される場合、「タグ」は、顔画像を識別または説明するために使用される単語または語句またはその他のデータを指す。「顔認識値」は、顔画像の中の単一の顔の指標に割り当てられる数値、または個々の顔の指標を含む因子に基づき計算された総合値のいずれかである。したがって、データベース１０８のエントリにおける１つ以上の顔認識値は、所定の組の顔の指標に対する個々の数値および総合値を含み得る。文献に記載されているいくつかの顔認識指標評価機構のいずれかを、データベース１０８内の顔画像に顔認識値を割り当てる上で使用することができる。これらの顔画像エントリのそれぞれにおけるこれらの顔認識値、例えば個々の指標の顔認識値の総合値の１つ以上は、類似グループを形成するための各画像の代表とみなすことができる。この代表値は、以降、「顔認識テンプレート」と呼ばれる。別の実施形態において、各エントリにおけるいくつかの顔認識値は、値のベクトルとみなすことができ、ベクトルに対して計算された対応する値は、対応する顔画像の代表的顔認識テンプレートとして使用することができる。さらに別の実施形態において、顔認識テンプレート自体が、顔の指標に対する個々の顔認識値を含むベクトルであってもよい。 As used herein, a “tag” refers to a word or phrase or other data used to identify or describe a facial image. The “face recognition value” is either a numerical value assigned to a single face index in the face image, or a total value calculated based on factors including individual face indices. Thus, the one or more face recognition values in the database 108 entries may include individual numerical values and total values for a predetermined set of face indicators. Any of several face recognition index evaluation mechanisms described in the literature can be used in assigning face recognition values to face images in the database 108. One or more of these face recognition values in each of these face image entries, eg, the total value of the face recognition values of the individual indices, can be considered representative of each image to form a similar group. This representative value is hereinafter referred to as a “face recognition template”. In another embodiment, some face recognition values in each entry can be considered as a vector of values, and the corresponding values calculated for the vectors are used as representative face recognition templates for the corresponding face images. can do. In yet another embodiment, the face recognition template itself may be a vector containing individual face recognition values for the face index.
いくつかの実施形態において、顔画像１０８のデータベース内のエントリは、顔画像を含有しなくてもよく、その代わりにエントリは、集合１０７内のそれぞれの画像内の顔画像の場所パラメータを含むことができる。例えば、場所パラメータは、所望の顔画像を包含する四角形の左下角部および右上角部に対する画素数を使用して、二次元で指定することができる。データベース１０８の各エントリに含まれる集合１０７内の対応する画像へのポインタは、様々な形態で実装され得る。例えば、これに限定されないが、ポインタは、集合１０７へのインデックス、対応する画像へのメモリ参照、または、集合１０７内の画像への参照をハッシュ化するテーブルに対するインデックス等の間接的参照であってもよい。 In some embodiments, the entries in the database of face images 108 may not contain face images, instead the entries include the location parameters of the face images in each image in the set 107. Can do. For example, the location parameter can be specified in two dimensions using the number of pixels for the lower left and upper right corners of a quadrangle that contains the desired face image. Pointers to corresponding images in the set 107 included in each entry of the database 108 can be implemented in various forms. For example, but not limited to, a pointer is an indirect reference such as an index to the set 107, a memory reference to the corresponding image, or an index to a table that hashes a reference to an image in the set 107. Also good.
「類似グループ」は、本明細書において使用される場合、所定範囲内の顔認識テンプレート値を有する１組の画像である。例えば、２つの顔画像間の類似性は、２つの対応する顔認識テンプレート間のユークリッド距離により測定することができる。対応する顔認識テンプレートを使用する顔画像の類似グループの形成は、クラスタ化プロセスにより達成され得る。例えば、ｋ平均クラスタ化またはｃ平均クラスタ化等の周知のクラスタ化技術を類似グループの形成おいて使用することができる。類似グループは、単一の人物の顔画像をグループ分けすることを意図している。 A “similar group”, as used herein, is a set of images having face recognition template values within a predetermined range. For example, the similarity between two face images can be measured by the Euclidean distance between two corresponding face recognition templates. Formation of similar groups of face images using corresponding face recognition templates can be achieved by a clustering process. For example, well-known clustering techniques such as k-mean clustering or c-mean clustering can be used in forming similar groups. Similar groups are intended to group face images of a single person.
顔検出モジュール１０６は、多くのプログラミング言語のうちの１つ、例えばＣ言語を使用してソフトウェアに実装することができる。モジュール１０６は、画像を、またはユーザにより指定された画像を精査し、それらの画像内の顔を検出する。例えば、一実施形態において、ユーザがデジタル写真のアルバムを集合１０７に追加した場合、顔検出モジュール１０６は、そのアルバム内の各デジタル写真を精査し、顔を検出することができる。顔が検出されると、モジュール１０６は、検出された顔を包含する領域、例えば検出された顔画像を包含する四角形領域のデジタルコピーを作成し、顔画像のデータベース１０８内の対応するエントリに記憶することができる。集合１０７内で検出されたそれぞれの新たな顔に対し、顔検出モジュール１０６は、顔画像データベース１０８内に新たなエントリを形成するか、形成させることができる。いくつかの場合において、自動顔検出は、画像内のすべての顔を検出しない可能性がある。したがって、いくつかの実施形態において、ユーザは、特定の画像を処理するために特定的に顔検出モジュール１０６を起動することができる。これについては、手動補助顔検出に関して後述する。 The face detection module 106 can be implemented in software using one of many programming languages, such as C language. Module 106 reviews the images or images specified by the user and detects faces in those images. For example, in one embodiment, when a user adds an album of digital photos to collection 107, face detection module 106 can review each digital photo in the album and detect a face. When a face is detected, the module 106 creates a digital copy of the area containing the detected face, eg, a rectangular area containing the detected face image, and stores it in a corresponding entry in the face image database 108. can do. For each new face detected in the set 107, the face detection module 106 can create or form a new entry in the face image database 108. In some cases, automatic face detection may not detect all faces in the image. Thus, in some embodiments, a user can specifically activate the face detection module 106 to process a particular image. This will be described later with respect to manual auxiliary face detection.
当技術分野において、多くの顔検出技術が説明されている。例えば、米国特許第６，２２２，９３９号に記載のような、弾性バンチグラフマッチング、米国特許第６，９１７，７０３号に記載のようなゲーバージェット（ｇａｂｏｒ ｊｅｔｓ）に対するニューラルネットワークの使用、および米国特許第７，０９９，５１０号に記載のような増大されたプリミティブ機能を使用する顔検出等は、本明細書に記載の目的において使用することができる周知の顔検出技術のいくつかである。これらの技術のいくつかのうちのいずれかをモジュール１０６において使用して、本発明に従いながら集合１０７の画像内の顔を検出することができることが、当業者には理解される。 A number of face detection techniques have been described in the art. For example, the use of neural networks for elastic bunch graph matching, as described in US Pat. No. 6,222,939, Gabor jets as described in US Pat. No. 6,917,703, and Face detection, etc., using increased primitive functionality, such as that described in US Pat. No. 7,099,510, is some of the well-known face detection techniques that can be used for the purposes described herein. One of ordinary skill in the art will appreciate that any of several of these techniques can be used in module 106 to detect faces in the images of collection 107 in accordance with the present invention.
顔認識モジュール１０５は、データベース１０８内の顔画像を精査し、所定の組の顔の指標に顔認識値を割り当てる。モジュール１０５はまた、データベース１０８内の各顔画像に対する代表的顔認識テンプレートを計算する。上述したように、顔認識テンプレートは、単一の値または値のベクトルであってもよい。本発明の実施形態において使用可能な、顔認識のためのいくつかのアルゴリズムが、当技術分野において説明されている。例えば、Ｍ． Ｔｕｒｋ ａｎｄ Ａ． Ｐｅｎｔｌａｎｄ， ’’Ｅｉｇｅｎｆａｃｅｓ ｆｏｒ Ｒｅｃｏｇｎｉｔｉｏｎ’’， Ｊｏｕｒｎａｌ ｏｆ Ｃｏｇｎｉｔｉｖｅ Ｎｅｕｒｏｓｃｉｅｎｃｅ， Ｖｏｌ． ３， Ｎｏ． １， １９９１， ｐｐ． ７１−８６に記載のように、テンプレート値は、主成分分析により得られた固有顔により画定されたサブスペースへの顔画像の投影により生成することができる。別の例示的技術は、米国特許第６，３０１，３７０号に記載のように、顔画像の局所的特徴から得られたゲーバージェットで構成されるテンプレートの作成であってもよい。 The face recognition module 105 examines the face image in the database 108 and assigns a face recognition value to a predetermined set of face indices. Module 105 also calculates a representative face recognition template for each face image in database 108. As described above, the face recognition template may be a single value or a vector of values. Several algorithms for face recognition that can be used in embodiments of the present invention have been described in the art. For example, M.M. Turk and A.M. Pentland, "" Eigenfaces for Recognition "", Journal of Cognitive Neuroscience, Vol. 3, no. 1, 1991, pp. As described in 71-86, the template value can be generated by projecting a face image onto a subspace defined by the eigenface obtained by principal component analysis. Another exemplary technique may be the creation of a template composed of Gaver jets derived from local features of facial images, as described in US Pat. No. 6,301,370.
類似グループモジュール１０４は、顔検出モジュール１０５により顔識別テンプレートを割り当てられた顔画像のデータベース１０８内の顔画像の処理を含む。モジュール１０４は、所定の顔認識テンプレート値または値の範囲に基き、顔認識テンプレートを割り当てられた顔画像を類似グループにグループ分けすることができる。類似グループは、理想的には単一の人物の画像を共にグループ分けするように設計される。実際には、類似グループの効力は、ほとんどが顔認識テンプレートおよび類似グループを定義する値の境界等のいくつかの因子の正確性に依存する。 The similarity group module 104 includes processing of face images in the face image database 108 that has been assigned a face identification template by the face detection module 105. The module 104 can group the face images assigned the face recognition template into similar groups based on a predetermined face recognition template value or range of values. Similar groups are ideally designed to group together images of a single person. In practice, the effectiveness of a similarity group depends mostly on the accuracy of several factors such as the face recognition template and the value boundaries that define the similarity group.
サーバ側画像レイアウト生成モジュール１０３は、顔画像のデータベース１０８とグラフィカルユーザインタフェース（ＧＵＩ）１２１との間のインタフェースのサーバ側コンポーネントを含む。組み合わされたクライアント側画像レイアウト生成モジュール１２３およびサーバ側画像レイアウト生成モジュール１０３は、クライアント１２０とサーバ１０１との間でデータベース１０８からの顔画像および集合１０７からの画像を交換するためのユーザ入力を促進する機能性を含み得る。さらに、サーバ側モジュール１０３は、データベース１０８から顔画像を選択および取得する機能性、データベース１０８内のエントリで参照される集合１０７からの画像を取得する機能性、ならびに、クライアント１２０における所望のユーザの活動を可能にするために類似グループモジュール１０４、顔認識モジュール１０５、および顔検出モジュール１０６と相互作用する機能を含み得る。 The server-side image layout generation module 103 includes a server-side component of an interface between the face image database 108 and the graphical user interface (GUI) 121. The combined client-side image layout generation module 123 and server-side image layout generation module 103 facilitate user input for exchanging facial images from the database 108 and images from the set 107 between the client 120 and the server 101. Functionality may be included. In addition, the server-side module 103 has the functionality to select and obtain facial images from the database 108, the functionality to obtain images from the set 107 referenced by entries in the database 108, and the desired user's at the client 120. Functions that interact with the similarity group module 104, the face recognition module 105, and the face detection module 106 to allow activity may be included.
クライアント１２０は、ＧＵＩ１２１、１つ以上の入力デバイス１２２、およびクライアント側画像レイアウト生成モジュール１２３を備えることができる。クライアント１２０は、同じ計算プラットフォームにサーバ１０１として存在してもよく、または異なる計算プラットフォーム上に存在してもよい。本発明の機能性の達成において、１００に示されていない他のソフトウェアおよびハードウェアモジュールを使用することができることも、当業者には認識される。ＧＵＩ１２１は、コンピュータモニタならびに関連した表示ソフトウェアおよびハードウェアを含み得る。入力デバイス１２２は、キーボード、マウスまたは他の入力機構を含み得る。クライアント側画像レイアウト生成モジュール１２３は、上述の機能性に加えて、データベース１０８からの顔画像および集合１０７からの画像を、ＧＵＩ１２１での表示のために処理する機能性、ならびに、ＧＵＩ１２１の性能およびＧＵＩ１２１とのユーザインタラクションの最適化に必要な任意の機能性を含み得る。 The client 120 can include a GUI 121, one or more input devices 122, and a client-side image layout generation module 123. Client 120 may exist as server 101 on the same computing platform, or may reside on a different computing platform. Those skilled in the art will also recognize that other software and hardware modules not shown in 100 may be used in achieving the functionality of the present invention. The GUI 121 may include a computer monitor and associated display software and hardware. Input device 122 may include a keyboard, mouse, or other input mechanism. In addition to the functionality described above, the client-side image layout generation module 123 performs processing for processing the face image from the database 108 and the image from the set 107 for display on the GUI 121, and the performance of the GUI 121 and the GUI 121. May include any functionality necessary to optimize user interaction with.
クライアント側画像レイアウト生成モジュール１２３は、いくつかのプログラミング言語のうちの１つ、例えば、クライアント１２０がＪａｖａ（登録商標）機能に対応している場合はＪａｖａ（登録商標）により実装することができることが、当業者には認識される。サーバ側画像レイアウト生成モジュールはまた、サーバソフトウェアモジュール１０２に関して前述したように、多くの言語のうちの１つを使用して実装することができるが、実装言語およびソフトウェアプラットフォームは、クライアント側およびサーバ側画像レイアウトモジュール、それぞれ１２３および１０３のインタラクションを促進することを考慮して選択することができる。例えば、本発明がインタラクティブウェブアプリケーションを含み得る一実施形態において、モジュール１２３および１０３は、そのようなアプリケーション用に特別設計された言語、例えばＡｓｙｎｃｈｒｏｎｏｕｓ Ｊａｖａ（登録商標）Ｓｃｒｉｐｔ ａｎｄ ＸＭＬ（ＡＪＡＸ）で実装され得る。 The client-side image layout generation module 123 can be implemented by one of several programming languages, for example, Java (registered trademark) when the client 120 supports the Java (registered trademark) function. Those skilled in the art will recognize. The server-side image layout generation module can also be implemented using one of many languages, as described above with respect to the server software module 102, although the implementation language and software platform can be client-side and server-side. An image layout module can be selected in view of facilitating 123 and 103 interaction, respectively. For example, in one embodiment where the present invention may include interactive web applications, modules 123 and 103 are implemented in a language specially designed for such applications, such as Asynchronous Java® Script and XML (AJAX). obtain.
図２は、いくつかの実施形態における、顔画像のデータベース１０８を新たに検出された顔で更新するフローチャート２００である。フローチャート２００により定義されたプロセスは、一般に、サーバ１０１において実行される。段階２０１において、顔検出モジュール１０６は、デジタル画像の集合１０７に新たに追加された画像を処理する。顔検出モジュール１０６は、新たな画像を処理するために、多くの機構により、例えば、デジタル写真の新たなアルバムが集合１０７に追加されるたびに顔検出モジュール１０８を起動するソフトウェアトリガを実装することにより起動され得る。顔検出モジュール１０６は、顔検出モジュール１０６を含むサーバソフトウェアモジュール１０２の機能に関して上でさらに説明されている。 FIG. 2 is a flowchart 200 for updating the face image database 108 with newly detected faces in some embodiments. The process defined by the flowchart 200 is generally executed on the server 101. In step 201, the face detection module 106 processes the newly added image to the digital image collection 107. The face detection module 106 implements a software trigger that activates the face detection module 108 by a number of mechanisms to process a new image, for example, whenever a new album of digital photos is added to the set 107. Can be activated by The face detection module 106 is further described above with respect to the functionality of the server software module 102 that includes the face detection module 106.
段階２０２において、集合１０７の新たな画像において検出された各顔に対し、顔画像のデータベース１０８内に対応するエントリが形成される。これらのエントリの形成は、顔検出モジュール１０６ソフトウェアにより行われてもよい。顔検出モジュール１０６に関して上で説明したように、データベース１０８内のエントリは、検出された顔画像のデジタルコピーを含んでも含まなくてもよい。 In step 202, for each face detected in the new image of set 107, a corresponding entry in the face image database 108 is formed. Formation of these entries may be performed by the face detection module 106 software. As described above with respect to the face detection module 106, the entry in the database 108 may or may not include a digital copy of the detected face image.
顔認識モジュール１０５は、段階２０３において、顔画像のデータベース１０８に新たに追加された顔画像を処理することができる。モジュール１０５による処理は、顔認識モジュール１０５を含むサーバ側ソフトウェアモジュール１０２に関して上で詳細に説明されている。段階２０３において、顔認識モジュール１０５の機能は、１組の所定の顔の指標の割り当て、および顔画像のそれぞれに対する顔認識テンプレートの形成を含み得る。 In step 203, the face recognition module 105 can process the newly added face image in the face image database 108. The processing by module 105 is described in detail above with respect to server-side software module 102 that includes face recognition module 105. In step 203, the functions of the face recognition module 105 may include assigning a set of predetermined facial indicators and forming a face recognition template for each of the face images.
段階２０４において、類似グループモジュール１０４は、顔画像のデータベース１０８内の顔画像を処理する。モジュール１０４による処理は、類似グループモジュール１０４を含むサーバ側ソフトウェアモジュール１０２に関して上で詳細に説明されている。類似グループは、単一の人物に属する顔画像をグループ分けすることを意図している。この目的のため、類似グループモジュール１０４は、顔認識テンプレートにおける所定の範囲、および顔認識テンプレートの生成の正確性に依存し得る。類似グループモジュール１０４により処理が完了すると、データベース１０８内の顔画像は、顔認識値、顔認識テンプレートを割り当てられ、さらに類似グループへの一時的グループ分けが割り当てられている。 In step 204, the similarity group module 104 processes the face image in the face image database 108. The processing by module 104 is described in detail above with respect to server-side software module 102 including similar group module 104. Similar groups are intended to group face images belonging to a single person. For this purpose, the similarity group module 104 may rely on a predetermined range in the face recognition template and the accuracy of the generation of the face recognition template. When the process is completed by the similar group module 104, the face image in the database 108 is assigned a face recognition value and a face recognition template, and further assigned a temporary grouping into similar groups.
いくつかの実施形態において、ユーザが顔画像に名前を付けることを可能にすることは、概して２つの方向で進めることができ、すなわちユーザはアルバムに基づいて顔に名前を付けることができ、あるいはユーザは人物の名前を指定することにより顔に名前を付けることができる。図３は、一実施形態における、アルバムに基き顔画像に名前を付ける段階を示すフローチャート３００である。例えば、この実施形態において、ユーザは、そのアルバム内のあらゆる画像におけるあらゆる顔に対し、顔画像に名前を付けることを選択している。段階３０１によって、ユーザは、それらの画像にある顔に名前を付けるための処理を望む１つ以上のアルバムを指定することができる。段階３０１の前に、ユーザがアルバムに基き顔に名前を付けることを選択し、集合１０７からの利用可能なアルバムのリストがまずユーザに提示される、１つ以上の他の段階（図示せず）が存在してもよい。段階３０１において受容された入力に基き、段階３０２において、処理されるアルバムが選択される。例えば、アルバムは、ユーザにより指定された順番で処理され得る。アルバムが選択されたら、例えば、モジュール１０３は、集合１０７内の選択されたアルバムにアクセスし、選択されたアルバム内の各画像に対し、その画像に対応するデータベース１０８内の顔画像を特定することができる。このようにして特定された顔画像は、選択されたアルバム内の画像に対する第１組にグループ分けされる。段階３０３〜３０５は、第１組の形成に関連した活動を表す。段階３０２〜３０７は、ユーザにより指定されたアルバム内の画像の処理において繰り返され、第１組の顔画像が形成される。段階３０７での処理ループの完了後に得られる第１組の顔画像は、ユーザにより指定されたアルバム内の検出された顔を含む。 In some embodiments, allowing a user to name a face image can generally proceed in two directions, i.e., the user can name a face based on an album, or The user can name the face by specifying the name of the person. FIG. 3 is a flowchart 300 that illustrates naming a face image based on an album in one embodiment. For example, in this embodiment, the user has chosen to name the face image for every face in every image in the album. Step 301 allows the user to specify one or more albums that they wish to process to name the faces in those images. Prior to step 301, the user chooses to name the face based on the album, and a list of available albums from the set 107 is first presented to the user in one or more other steps (not shown). ) May be present. Based on the input received in step 301, in step 302, the album to be processed is selected. For example, albums can be processed in the order specified by the user. Once an album is selected, for example, module 103 accesses the selected album in collection 107 and for each image in the selected album, identifies a face image in database 108 corresponding to that image. Can do. The face images identified in this way are grouped into a first set for the images in the selected album. Stages 303-305 represent activities related to the formation of the first set. Steps 302-307 are repeated in processing the images in the album specified by the user to form a first set of face images. The first set of face images obtained after completion of the processing loop at step 307 includes the detected faces in the album specified by the user.
段階３０８において、第１組の顔画像は、類似グループに従いソートされる。このソーティングは、理想的には、段階３０１においてユーザにより指定されたアルバム内の任意の画像に存在する単一の人物の顔画像を共にグループ分けする。しかしながら、前述したように、類似グループの自動生成は、１人の人物のみの画像を類似グループにグループ分けする上で、また人物の顔画像を単一の類似グループ内にグループ分けする上で完全に正確ではない可能性がある。 In step 308, the first set of face images is sorted according to similar groups. This sorting ideally groups together the single person's face images present in any image in the album specified by the user in step 301. However, as described above, the automatic generation of similar groups is complete for grouping images of only one person into similar groups and grouping facial images of persons into a single similar group. May not be accurate.
段階３０９〜３１１において、類似グループごとに第１組の顔画像がＧＵＩ１２１上に表示される。例えば、類似グループは、行または図４に示されるような枠 ４０１に表示されてもよく、ユーザ入力４０４が可能となる。ユーザ入力は、例えば、図４に示されるようなチェックボックス４０３により、示された類似グループに属するものとして表示された各顔画像を選択または選択解除するように可能とすることができる。また、各類似グループに名前を付けるためのユーザ入力は、これも図４に示されるような最も近い名前の最初のいくつかのプルダウンリスト４０２により容易化されてもよい。例えば、表示された類似グループを識別する名前を選択するための最も近い名前のリストは、顔認識テンプレート値を比較して、表示された類似グループから近い範囲内の類似グループのすでに名前が付けられた顔画像から派生してもよい。図５は、一実施形態における、最も近い名前の選択肢のリストを生成するための上述のような方法のフローチャートである。図５に示されるプロセスは、以下でより詳細に説明する。多くの他の技術を使用して最も近い名前のそのようなプルダウンリストを生成することができることが、当業者には理解される。 In steps 309 to 311, a first set of face images is displayed on the GUI 121 for each similar group. For example, similar groups may be displayed in a row or frame 401 as shown in FIG. 4, allowing user input 404. User input can be enabled, for example, by selecting or deselecting each facial image displayed as belonging to the indicated similar group by way of a check box 403 as shown in FIG. Also, user input for naming each similar group may be facilitated by the first few pull-down lists 402 with the closest names as shown in FIG. For example, a list of closest names for selecting a name that identifies a displayed similar group is compared with the face recognition template values, and similar groups within a range closer to the displayed similar group are already named. It may be derived from the face image. FIG. 5 is a flowchart of a method as described above for generating a list of closest name choices in one embodiment. The process shown in FIG. 5 is described in more detail below. Those skilled in the art will appreciate that many other techniques can be used to generate such a pull-down list of closest names.
段階３１２〜３１３において、対応する類似グループ内の表示された顔画像のそれぞれの包含に関する、およびそれぞれの表示された類似グループに対する名前に関するユーザ入力が収集される。段階３１４において、顔画像のデータベースは、段階３１２〜３１３において収集されたユーザ入力に基き更新される。データベース１０８内のエントリの更新は、いくつかの実施形態において、顔認識テンプレートの更新を含み得る。更新はまた、いくつかの顔画像に対し割り当てられたタグの変更、および／または割り当てられた類似グループの変更を含み得る。図６は、グラフィカルユーザインタフェース６００の別の例を示し、１組の顔画像（またはそれらの顔画像のサムネイル抽出）がフィルムストリップ形式６０１で表示される。フィルムストリップ形式で表示された顔画像は、顔画像のそれぞれのグループの代表画像を含み得る。フィルムストリップは、選択されたグループ分けレベル内の利用可能な代表顔画像のすべてを閲覧するために、いずれの方向にもスクロール可能である。例えば、図６に示されるように、フィルムストリップ６０１は、すべての利用可能なアルバム内の各類似グループの代表画像を表示してもよい。フィルムストリップ６０１内のサムネイル画像は、意味のある順番で配設され得る。例えば、サムネイルは、確認されるべきほとんどの顔画像とともにクラスタのサムネイル画像を表示し、次いでフィルムストリップ内の他のサムネイルは最初に表示されたクラスタとの類似性の順で配設することにより、顔画像クラスタの名前を付け確認する上でユーザの補助となるように配設され得る。次いでユーザは、フィルムストリップ６０１内のサムネイル画像の１つを選択して、対応する類似グループ６０２内の顔画像を表示することができる。次いでユーザは、例えば、図６における類似グループ６０２顔画像のそれぞれの真下のチェックボックス等の対応するチェックボックスを選択することにより、現在割り当てられている類似グループ内のそれらの画像のそれぞれの場所を確認することができる。また、図６に示されるように、ユーザは、類似グループに対し名前を割り当てるか、または現在割り当てられている名前を確認することができる。さらに、図６に示されているように、名前付けの選択肢の提案が表示されてもよい。提案６０３は、顔画像のデータベース１０８内の利用可能なすでに名前を付けられた顔画像に基くものであってもよい。 In steps 312-313, user input is collected regarding the inclusion of each displayed facial image in the corresponding similar group and the name for each displayed similar group. In step 314, the face image database is updated based on the user input collected in steps 312-313. Updating entries in the database 108 may include updating face recognition templates in some embodiments. Updates may also include changes in assigned tags and / or changes in assigned similar groups for some facial images. FIG. 6 shows another example of a graphical user interface 600 where a set of face images (or thumbnail extracts of those face images) is displayed in a filmstrip format 601. The face image displayed in the film strip format may include a representative image of each group of face images. The filmstrip can be scrolled in either direction to view all of the available representative face images within the selected grouping level. For example, as shown in FIG. 6, filmstrip 601 may display a representative image of each similar group in all available albums. The thumbnail images in the filmstrip 601 can be arranged in a meaningful order. For example, the thumbnail displays a thumbnail image of the cluster with most face images to be confirmed, and then the other thumbnails in the filmstrip are arranged in order of similarity to the first displayed cluster, It may be arranged to assist the user in naming and confirming the face image cluster. The user can then select one of the thumbnail images in the filmstrip 601 to display the corresponding face image in the similar group 602. The user then selects the location of each of those images in the currently assigned similarity group, for example, by selecting a corresponding checkbox such as the checkbox directly below each of the similarity group 602 face images in FIG. Can be confirmed. In addition, as shown in FIG. 6, the user can assign a name to the similar group or check the currently assigned name. Further, as shown in FIG. 6, a suggestion of naming options may be displayed. Proposal 603 may be based on an already named face image available in the face image database 108.
段階３１４の最後に、集合１０７内のユーザが指定したアルバム内の対応する画像を有したデータベース１０８内の顔画像は、特定の類似グループへの包含およびタグ名に関して更新されている。ユーザにより確認された対象名タグを有する顔画像は、本明細書において、「すでに名前を付けられた」顔画像と呼ばれる。 At the end of step 314, facial images in the database 108 with corresponding images in the album specified by the user in the set 107 have been updated for inclusion in specific similar groups and tag names. A face image having a target name tag confirmed by the user is referred to herein as a “already named” face image.
図５は、選択された類似グループに対する可能な名前のリストを生成するプロセス５００を示す。段階５０１において、選択された類似グループに対する顔認識テンプレートが決定される。上述したように、各類似グループは、対応する顔認識テンプレートを有し得る。段階５０２において、顔画像のデータベース１０８内の利用可能なすでに名前を付けられた顔画像を含む類似グループが検索される。所定の範囲内の顔認識テンプレートを有する類似グループを使用して、それらの類似グループ内のすでに名前を付けられた画像から名前を得ることができる。段階５０３において、段階５０２で得られた所定の数までの名前を、選択された類似グループに対する可能な選択肢としてリストすることができる。リストは、複数の基準に従い、例えば選択された類似グループの顔認識テンプレートと、すでに名前を付けられた顔画像を有するそれぞれの類似グループとの間の差異に従い、順序付けることができる。 FIG. 5 shows a process 500 for generating a list of possible names for selected similar groups. In step 501, a face recognition template for the selected similar group is determined. As described above, each similar group may have a corresponding face recognition template. In step 502, a similar group that includes available already named facial images in the facial image database 108 is searched. Using similar groups with face recognition templates within a predetermined range, names can be obtained from already named images in those similar groups. In step 503, up to a predetermined number of names obtained in step 502 can be listed as possible choices for the selected similar group. The list can be ordered according to a plurality of criteria, for example according to the difference between the selected similar group face recognition template and each similar group having a face image already named.
ユーザが顔画像に名前を付けるために選択することができる別の手法は、ユーザ名を指定し、指定された集合（例えば、システムにより最初に選択された集合１０７のサブセット）内の画像が指定されたユーザに属することを確認するように試みることである。図７におけるフローチャート７００は、一実施形態における一連の段階であり、これを通してユーザは単一の人物に属する顔画像に名前を付けることができる。 Another technique that the user can select to name the face image is to specify the user name and specify an image in a specified set (eg, a subset of the set 107 that was initially selected by the system). To try to confirm that it belongs to the selected user. Flowchart 700 in FIG. 7 is a series of steps in one embodiment through which a user can name a facial image belonging to a single person.
段階７０１において、対象名は、ユーザからの入力としてシステムにより受容される。例えば、ユーザは、ＧＵＩ１２１を使用して、顔画像に名前を付けたい対象の名前を、システムが生成したリストに入力するか、またはそこから選択することができる。次いで、例えば、クライアント側画像レイアウトモジュール１２３は、ユーザが指定した対象名をサーバ側画像レイアウト生成モジュール１０３に受け渡すことができる。対象名を受容した後、例えば、段階７０２のように、サーバ側モジュール１０３は、ユーザにより指定された対象名と一致する、データベース１０８内のすでに名前を付けた顔画像の、本明細書において第２組と呼ばれる組を生成することができる。その後、段階７０３において、モジュール１０３は、第２組における顔画像に対応する１つ以上の顔認識テンプレート値を決定することができる。例えば、現在データベース１０８内に分類されているため、第２組における顔画像は複数の類似グループに属するが、これらの画像は単一の対象名を割り当てられていてもよい。類似グループのそれぞれは、グループを定義する顔認識テンプレート値の固有の範囲を有し得る。段階７０３において、顔認識テンプレートに対する１組の値が決定される。段階７０４において、段階７０３で決定された顔認識テンプレートの範囲を使用して、顔認識テンプレート値が段階７０３で選択されたそれらの値に最も近い、まだ名前を付けられていない第３組の顔画像と呼ばれる組が選択される。その後、段階７０５において、第２組における顔画像（すでに名前を付けられた顔画像）および第３組における顔画像（名前を付けられていない顔画像）がＧＵＩ上に配設される。例えば、いくつかの実施形態において、第２組は画像の単一のクラスタとしてレイアウトされてもよく、第３組は、それぞれのクラスタが類似グループに対応した複数のクラスタとしてレイアウトされてもよい。第３組のクラスタは、いくつかの実施形態において、第２組の顔画像のクラスタへの近接性がそれぞれの顔認識テンプレートの近似を示すように、ＧＵＩ上に整理されてもよい。図８は、一実施形態における、フローチャート７００に従い生成されたＧＵＩ８００である。例えば、第２組における画像を有するクラスタ８０１および第３組のクラスタ８０２〜８０８が、図８に示されるようにレイアウトされ得る。段階７０７において、示された類似グループへのそれぞれの表示された顔画像の包含に関するユーザ入力が受容され、指定された対象名で更新される画像の組へのそれぞれの表示された顔画像の包含に関するユーザ入力もまた受容される。段階７０８において、データベース１０８は、ユーザ入力に従い更新される。例えば、データベース１０８内の対応するエントリは、指定された対象名を割り当てるかまたはエントリから削除することにより更新することができ、エントリの類似グループ情報もまた更新することができる。 In step 701, the subject name is accepted by the system as input from the user. For example, the user can use the GUI 121 to enter or select from the system-generated list the names of objects for which they want to name the facial image. Next, for example, the client-side image layout module 123 can pass the target name designated by the user to the server-side image layout generation module 103. After accepting the subject name, for example, as in step 702, the server-side module 103 uses the first name of the face image already named in the database 108 that matches the subject name specified by the user. A set called two sets can be generated. Thereafter, in step 703, the module 103 can determine one or more face recognition template values corresponding to the face images in the second set. For example, since the face images in the second set belong to a plurality of similar groups because they are currently classified in the database 108, these images may be assigned a single target name. Each similar group may have a unique range of face recognition template values that define the group. In step 703, a set of values for the face recognition template is determined. In step 704, using the range of face recognition templates determined in step 703, the third set of unnamed faces whose face recognition template values are closest to those values selected in step 703 A set called an image is selected. Thereafter, in step 705, the face images in the second set (already named face images) and the face images in the third set (unnamed face images) are placed on the GUI. For example, in some embodiments, the second set may be laid out as a single cluster of images, and the third set may be laid out as multiple clusters, each cluster corresponding to a similar group. The third set of clusters, in some embodiments, may be organized on the GUI such that the proximity of the second set of facial images to the cluster indicates an approximation of the respective face recognition template. FIG. 8 is a GUI 800 generated according to flowchart 700 in one embodiment. For example, a cluster 801 with images in the second set and a third set of clusters 802-808 may be laid out as shown in FIG. In step 707, user input relating to the inclusion of each displayed face image in the indicated similar group is received and the inclusion of each displayed face image in the set of images updated with the specified subject name. User input for is also accepted. In step 708, the database 108 is updated according to the user input. For example, the corresponding entry in the database 108 can be updated by assigning or deleting a specified subject name, and the similar group information of the entry can also be updated.
別の実施形態において、図９のフローチャート９００のプロセスを使用して、ユーザが対象名に基き顔画像に名前を付けることができるようにしてもよい。段階９０１〜９０３は、フローチャート７００の段階７０１〜７０４に対応し、同様の説明が適用される。段階９０１において、すでに名前を付けられた顔画像の、以降第４組と呼ばれる組が生成される。段階９０３において、まだ名前を付けられていない顔画像の、以降第５組と呼ばれる別の組が生成される。段階９０４において、第４組がＧＵＩの領域に表示される。段階９０５において、第５組がＧＵＩの別個の領域に表示され、第４組との類似性が低くなる順で個々の顔画像が配設され得る。図１０は、一実施形態における、フローチャート９００に従うＧＵＩの例である。この実施形態において、第４組および第５組の顔画像は、異なるタブシートに表示され、図１０に見られるように、１度に１つだけが見えるようにしてもよい（１００１）。段階９０６において、指定された対象名を割り当てるべき個々の顔画像に関するユーザ入力が受容される。段階９０７において、データベース１０８は、ユーザ入力に従い更新される。例えば、ユーザにより選択されたまだ名前を付けられていない顔画像のそれぞれが、ここで対象名により更新されてもよい。同様に、すでに名前を付けられた顔画像のタブシート内の各顔画像に対し、対応するエントリを更新して、ユーザがそのように示した場合には対象名を削除することができる。図６は、ユーザにより指定された１つ以上の名前に基き類似クラスタを表示およびそれに名前を付けるために使用することができるユーザインタフェースを示す。 In another embodiment, the process of flowchart 900 of FIG. 9 may be used to allow a user to name a facial image based on the subject name. Steps 901 to 903 correspond to steps 701 to 704 of flowchart 700 and the same description applies. In step 901, a set of face images that have already been named, referred to hereinafter as the fourth set, is generated. In step 903, another set of face images that have not been named yet, hereinafter referred to as the fifth set, is generated. In step 904, the fourth set is displayed in the area of the GUI. In step 905, the fifth set may be displayed in a separate area of the GUI, and individual face images may be arranged in order of decreasing similarity to the fourth set. FIG. 10 is an example of a GUI according to flowchart 900 in one embodiment. In this embodiment, the fourth and fifth sets of face images may be displayed on different tab sheets so that only one is visible at a time as seen in FIG. 10 (1001). In step 906, user input relating to individual face images to be assigned a specified subject name is received. In step 907, the database 108 is updated according to the user input. For example, each of the face images that are selected by the user but not yet named may be updated here with the subject name. Similarly, for each face image in the tab sheet for a face image that has already been named, the corresponding entry can be updated and the target name can be deleted if the user indicates so. FIG. 6 illustrates a user interface that can be used to display and name similar clusters based on one or more names specified by the user.
いくつかの状況において、顔検出プロセス自体は、いくつかの顔に対して失敗する可能性がある。例えば、顔検出モジュール１０６は、集合１０７内の画像において１つ以上の顔を検出しない可能性がある。この場合、一実施形態またはその実施形態において、本発明は、顔検出プロセスを手動で補助する機能を提供する。図１１は、一実施形態における手動補助顔検出のＧＵＩコンポーネントを示す。例えば、ユーザは、境界領域、この場合ではバウンディングボックス１１０１を、ユーザがシステムに検出および認識させたいそれぞれの顔の周りに描くことが可能となる。さらに、１１０２に示されるように、ユーザは、そのような画像に対し、追加の説明データ、例えば対象名を表示または入力することができる。図１２は、そのプロセスを示したフローチャート１２００を示す。 In some situations, the face detection process itself can fail for some faces. For example, the face detection module 106 may not detect one or more faces in the images in the set 107. In this case, in one embodiment or embodiment thereof, the present invention provides the ability to manually assist the face detection process. FIG. 11 illustrates the GUI component of manual assist face detection in one embodiment. For example, the user can draw a border region, in this case a bounding box 1101, around each face that the user wants the system to detect and recognize. Further, as shown at 1102, the user can display or enter additional descriptive data, such as a subject name, for such an image. FIG. 12 shows a flowchart 1200 illustrating the process.
段階１２０１および１２０２において、集合１０７からの画像がＧＵＩに示され、ユーザは１つ以上の顔の周りに境界領域を画定することができる。段階１２０３において、境界を付けられた領域は、例えば、顔検出モジュール１０６により処理される。自動顔検出および手動補助顔検出において、同じ顔検出技術に若干の修正を加えて使用することができることが、当業者には理解される。例えば、手動補助される場合、顔検出ソフトウェアは、単に、画定された領域内で識別された、顔の指標となる特徴により大きな重みを付けることができる。段階１２０４において顔が検出されると、段階１２０５は、ユーザが追加情報を、例えばデータベース１０８内の顔画像にタグを付けるための対象名を提供することができるようにする。段階１２０６において、顔データベース１０８は、検出された顔情報、およびおそらくは対象名を含むユーザが提供した情報で更新される。 In steps 1201 and 1202, images from the set 107 are shown in the GUI, and the user can define a border region around one or more faces. In step 1203, the bounded region is processed by the face detection module 106, for example. Those skilled in the art will appreciate that the same face detection technique can be used with some modifications in automatic face detection and manual auxiliary face detection. For example, when manually assisted, the face detection software can simply weight more features that are identified in the defined area and that are indicative of the face. If a face is detected in step 1204, step 1205 allows the user to provide additional information, eg, a subject name for tagging the face image in the database 108. In step 1206, the face database 108 is updated with information provided by the user, including detected face information and possibly subject names.
別の実施形態において、顔認識および名前付けプロセスを補助するために性別検出が使用される。画像における性別検出の方法は、当技術分野において周知である。性別検出を使用して、すでにクラスタに割り当てられた顔画像の性別を決定することができる。クラスタ内の顔画像の性別を決定したら、システムはその情報を使用して、新たに追加された画像に対する顔検出結果にバイアスをかけることができる。例えば、システムは、新たな顔画像がクラスタに追加され、新たな画像の性別とすでにクラスタ内にある画像の性別が一致しない場合、ユーザを留まらせるかまたはユーザに通告することができる。クラスタ内の画像がすでにタグを付けられている別の実施形態において、辞書ルックアップを使用してクラスタ内の顔画像の性別を決定することができる。 In another embodiment, gender detection is used to assist the face recognition and naming process. Methods for gender detection in images are well known in the art. Gender detection can be used to determine the gender of a facial image that has already been assigned to a cluster. Once the gender of the face images in the cluster is determined, the system can use that information to bias the face detection results for the newly added image. For example, the system can leave the user or notify the user if a new face image is added to the cluster and the gender of the new image does not match the gender of the image already in the cluster. In another embodiment where the images in the cluster are already tagged, dictionary lookup can be used to determine the gender of the facial images in the cluster.
別の実施形態において、本発明は、異なるエンティティにより維持される顔画像の集合を統合するシステムを提供する。顔画像の集合が異なるエンティティにより別個に維持される場合、特定の人物の顔画像は、別個の集合間で異なるタグ付けがなされ得る。例えば、第１の集合を有するユーザは、Ｊｏｈｎ Ｓｍｉｔｈの顔画像を「Ｊｏｈｎ Ｓｍｉｔｈ」とタグ付けする可能性があり、一方、第２の集合を有する別のユーザは、Ｊｏｈｎ Ｓｍｉｔｈの画像を「Ｊ． Ｓｍｉｔｈ」とタグ付けする可能性がある。すると、２つの集合の単純な集約により、集約された集合において異なるタグの下に同じ人物が現れる結果となる。本発明は、画像テンプレートの比較において追加の情報要素を比較することにより、別個の集合の顔画像を統合する方法を提供する。例えば、これに限定されないが、２つの集合がマージされる際、顔の特徴、画像から検出された性別、辞書検索から検出された性別、割り当てられた名前／タグ、年齢、人種、ポーズ、アクセサリー、地理上の座標および時間（使用可能な場合）、他の既知の顔画像との共起といった情報要素のいくつかまたはすべてが画像テンプレートに組み込まれ得る。統合された集合における顔画像に割り当てられるタグは、情報要素の組を比較する様々な方法により決定され得る。例えば、数値を各情報要素に割り当てることができ、一致する情報要素が所定の数値閾値を超える場合にはタグが自動的に消去され得、また一致する情報要素がそのような閾値を超えない場合は手動での介入により半自動的に消去され得る。
例示的用途
その実施形態のひとつにおいて、本発明は、顔画像データベース１０８および関連情報を利用して、パーソナライズされたサービスをユーザに提供する。例えば、図１３は、パーソナライズされたスライドショーを実行するフローチャート１３００を示す。段階１３０１において、ユーザは対象名を指定し、その後段階１３０２において、システムは対応する顔画像を特定する。次いで、段階１３０３〜１３０５において、それぞれの特定された顔画像に対し、システムは集合１０７内の対応する画像を特定し、ＧＵＩ１２１においてそれをユーザに表示する。フローチャート１３００を使用して、ユーザは、指定された対象に対応する顔画像を有する集合１０７内のすべてまたはいくつかの画像を表示させることができる。いくつかの実施形態において、集合１０７内の各画像における顔画像に関する情報を使用して、対応する画像を表示する際にそれらの顔画像に対して特殊効果を実行することができる。例えば、集合１０７内の対応する画像を表示させる時に顔画像に対するデータベース１０８に記憶された場所パラメータを使用して、表示の時点で顔の境界を特定するために追加の計算を行うことなく、画像のその領域をズームインまたは拡大することができる。
In another embodiment, the present invention provides a system for integrating a set of facial images maintained by different entities. If a set of face images is maintained separately by different entities, a particular person's face image may be tagged differently between the separate sets. For example, a user with a first set may tag John Smith's face image as “John Smith”, while another user with a second set may copy a John Smith image as “J Smith”. . "Smith". Then, a simple aggregation of the two sets results in the same person appearing under different tags in the aggregated set. The present invention provides a method for integrating separate sets of facial images by comparing additional information elements in a comparison of image templates. For example, but not limited to, when two sets are merged, facial features, gender detected from the image, gender detected from the dictionary search, assigned name / tag, age, race, pose, Some or all of the information elements such as accessories, geographic coordinates and time (if available), and co-occurrence with other known facial images may be incorporated into the image template. The tags assigned to face images in the integrated set can be determined by various methods that compare sets of information elements. For example, a numerical value can be assigned to each information element, the tag can be automatically deleted if the matching information element exceeds a predetermined numerical threshold, and the matching information element does not exceed such a threshold Can be erased semi-automatically by manual intervention.
Exemplary Applications In one of its embodiments, the present invention utilizes the facial image database 108 and related information to provide a personalized service to the user. For example, FIG. 13 shows a flowchart 1300 for performing a personalized slide show. In step 1301, the user specifies a subject name, and then in step 1302, the system identifies the corresponding face image. Then, in steps 1303-1305, for each identified face image, the system identifies the corresponding image in set 107 and displays it to the user in GUI 121. Using flowchart 1300, the user can display all or some images in collection 107 having facial images corresponding to the specified object. In some embodiments, information about face images in each image in the set 107 can be used to perform special effects on those face images when displaying the corresponding images. For example, using the location parameters stored in the database 108 for face images when displaying the corresponding images in the set 107, the images can be used without additional calculations to identify the face boundaries at the time of display. You can zoom in or enlarge that area.
別の実施形態において、データベース１０８は、指定された人物の似顔絵（複数可）を含み得る画像を、外部画像集合に対し検索するために使用することができる。図１４は、段階１４０１においてユーザから対象名を受容し、段階１４０２において一致する名前が割り当てられたデータベース１０８内の顔画像の組を特定するプロセスのフローチャート１４００である。また、段階１４０２において、システムは、選択された顔画像に対応する１つ以上の顔認識テンプレートを決定することができ、これは段階１４０３における検索に使用することができる。段階１４０３において、外部画像集合が検索され、顔認識テンプレートの点で段階１４０２において選択された顔画像の１つに十分近い顔画像を含む任意の画像が識別され得る。例えば、検索は、各画像上での顔検出、続いて一組の所定の顔の指標に対する値を決定するための顔認識、次いで段階１４０２において選択された顔画像の１つ以上に対する整合プロセスを含み得る。一実施形態において、一致する顔画像が見付かったら、ユーザは、自動生成されたメッセージ、例えばユーザの登録された連絡先への自動生成された電子メールまたはテキストメッセージを含むいくつかの手段を介して警告され得る。別の実施形態において、一致する顔画像を有する画像を、集合１０７内に含めることができる。 In another embodiment, the database 108 can be used to search the external image set for images that may include the designated person's caricature (s). FIG. 14 is a flowchart 1400 of a process for receiving a subject name from a user in step 1401 and identifying a set of facial images in the database 108 assigned a matching name in step 1402. Also, at step 1402, the system can determine one or more face recognition templates corresponding to the selected face image, which can be used for the search at step 1403. In step 1403, the external image set is searched and any image containing a face image that is sufficiently close to one of the face images selected in step 1402 in terms of the face recognition template may be identified. For example, the search may include face detection on each image, followed by face recognition to determine a value for a set of predetermined face indicators, and then a matching process for one or more of the face images selected in step 1402. May be included. In one embodiment, once a matching face image is found, the user can go through a number of means including an automatically generated message, eg, an automatically generated email or text message to the user's registered contact. You can be warned. In another embodiment, images with matching face images can be included in the set 107.
別の実施形態において、対象は、自分の画像が表示される、および／または自分の画像が名前等の識別情報とともに表示されるのを拒否することが可能である。図１５は、一実施形態における、ユーザ拒否システムにおける操作の例示的フローチャート１５００を示す。段階１５０１において、１人のユーザ、例えば対象Ｘに関する表示イベントが生じる。表示イベントは、対象Ｘの顔画像を有する画像、および／または対象Ｘの情報を有する画像のタグの、画像の集合１０７への追加を含み得る。対象Ｘは、所定の特徴を有する表示イベントが生じた場合通知を受けるように予め登録されていてもよい。段階１５０２において、対象Ｘの優先傾向を含む構成情報に基き、対象Ｘが表示イベントを通知されるべきかが決定され得る。段階１５０３において、対象Ｘに通知が送信される。通知は、対象Ｘが使用可能なアドレスへの電子メールメッセージ、または対象Ｘが使用可能な１つ以上のアドレスへのインスタントメッセージを含む任意の形態で伝達され得る。メッセージは、リンク、例えば対象Ｘがさらなる情報を得る、および／またはその拒否を登録することになっているウェブページへのユニフォームリソースロケータ（ＵＲＬ）を含んでもよい。
通知を伝送したら、段階１５０４において、対象Ｘからの応答が受容され得る。応答は、通知メッセージ内で送られたＵＲＬに対象Ｘが訪問したことを含み得る。段階１５０５において、対象Ｘが拒否する上で依拠するのに十分な情報を得るように、通知を送信させる元となった画像および／またはタグが対象Ｘに表示される。例えば、いくつかの実施形態において、対象Ｘのタグと一致するタグを有する集合１０７内の画像のすべてが表示されてもよく、一方いくつかの他の実施形態は、Ｘへの通知を誘引した表示イベントの直接の原因であった画像およびタグのみを表示してもよい。段階１５０６において、Ｘの入力が受容される。対象Ｘは、一連のチェックボックスを使用して、または他の入力手段を使用して、自分の入力を登録することができる。受容された入力は、画像が削除されるべきか否か、指定されたタグが表示されるか否か、任意のタグの修正、Ｘが問題の画像のソースが通知されるのを望むか否か、およびＸが問題の画像のソースを知らされたいか否かに関するＸの選択を含み得る。段階１５０７において、Ｘの入力した選択は、Ｘに権限があるか、またはその他要求されたサービスを受けることができるかを決定するために検証され得る。例えば、１組の所定の基準を満たすユーザのみが画像の削除を要求することができてもよい。Ｘが画像（複数可）の削除、またはタグ情報の削除もしくは修正の要求を検証される場合、段階１５０８においてそのような変更が集合１０７および顔画像データベース１０８において達成される。例えば、Ｘとしてタグ付けされた画像の自動除去を要求する権限がＸにある場合、画像および関連タグは集合１０７および／またはデータベース１０８から除去され得る。Ｘの権限のレベルに依存して、画像を削除させるＸの要求により、集合１０７の所有者により画像を手動で除去するためにログ入力が行われることになってもよい。また、Ｘの権限に依存して、要求された任意のタグの変更は、自動的になされてもよく、または後に検討するために記録されてもよい。段階１５０９において、Ｘが適切な権限を有する場合、Ｘに問題の画像（複数可）を得た場所が知らされてもよい。最後に、段階１５１０において、問題の画像（複数可）のソースにＸの拒否が通知されてもよい。例えば、Ｘの拒否および問題の画像（複数可）を含む電子メールが自動的にソースに生成されてもよい。さらに別の実施形態は、画像の集合に対する制限されたアクセスをユーザに提供するために、データベース１０８内の情報を使用することができる。例えば、ユーザは、自分の顔画像を有する集合１０７内の画像のみにアクセスすることができる。あるいは、ユーザは、自分の顔画像、または１つ以上の他の所定の組の人物の顔画像を含む１組のアルバムへのアクセスが与えられてもよい。例えば、一実施形態において、アルバムは、共有鍵に基いて制御することができ、鍵は所定の組の基準を満たすユーザにのみ配布される。図１６のフローチャート１６００は、一実施形態におけるそのような制限されたアクセスを実装するための段階を示す。段階１６０１において、ユーザは、自分の顔画像を有する画像へのアクセスが認証され得る。同様に、いくつかの実施形態において、ユーザは、１人以上の他の人物の画像へのアクセスが認証され得る。１人以上の他の人物の画像へアクセスするユーザの特権は、例えば、ユーザ識別子、予め定義されたユーザグループ、および／またはアルバム、画像もしくは対象名ごとに設定されたアクセス特権等に基き、システムにアクセス可能な構成ファイル内で定義することができる。段階１６０２において、一致する対象名を有するデータベース１０８内のすでに名前が付けられた顔画像が取得され得る。段階１６０３において、集合１０７は、段階１６０２において取得された顔画像のみに基いてアクセスされ得る。例えば、ユーザが集合１０７内の画像にアクセスしようとするたびに、そのアクセスは、段階１６０２において取得された顔画像が集合１０７内の選択された画像を参照していることを確かめることにより検証される。
In another embodiment, the subject may refuse to display his / her image and / or display his / her image with identifying information such as a name. FIG. 15 shows an exemplary flowchart 1500 of operations in a user rejection system in one embodiment. In step 1501, a display event for one user, eg, object X, occurs. A display event may include the addition of an image having a face image of subject X and / or a tag of an image having information on subject X to image collection 107. The target X may be registered in advance so as to receive a notification when a display event having a predetermined characteristic occurs. In step 1502, based on the configuration information including the priority trend of the target X, it may be determined whether the target X should be notified of a display event. In step 1503, a notification is sent to the target X. The notification may be communicated in any form including an email message to an address where subject X can be used, or an instant message to one or more addresses where subject X can be used. The message may include a link, for example a uniform resource locator (URL) to a web page where subject X is to obtain further information and / or register its rejection.
Once the notification has been transmitted, in step 1504, a response from subject X may be accepted. The response may include the subject X visiting the URL sent in the notification message. In step 1505, the image and / or tag from which the notification is sent is displayed on the subject X so that the subject X has enough information to rely on to refuse. For example, in some embodiments, all of the images in collection 107 that have a tag that matches the tag of subject X may be displayed, while some other embodiments have triggered a notification to X Only the images and tags that were the direct cause of the display event may be displayed. In step 1506, the input of X is accepted. Subject X can register his input using a series of checkboxes or using other input means. Accepted inputs are whether the image should be deleted, whether the specified tag is displayed, any tag modifications, whether X wants to be notified of the source of the image in question And a choice of X regarding whether X wants to be informed of the source of the image in question. In step 1507, the input selection of X may be verified to determine whether X is authorized or can receive other requested services. For example, only a user who satisfies a set of predetermined criteria may be able to request image deletion. If X is verified to delete the image (s) or request to delete or modify the tag information, such a change is accomplished in the set 107 and the face image database 108 at step 1508. For example, if X has the authority to request automatic removal of images tagged as X, the images and associated tags may be removed from the collection 107 and / or database 108. Depending on the level of authority of X, a request for X to delete an image may result in a log entry being made by the owner of set 107 to manually remove the image. Also, depending on the authority of X, any requested tag changes may be made automatically or may be recorded for later review. In step 1509, if X has the appropriate authority, X may be informed of where the problem image (s) were obtained. Finally, at step 1510, the source of the image (s) in question may be notified of the X rejection. For example, an email containing the X rejection and the image (s) in question may be automatically generated at the source. Yet another embodiment can use information in the database 108 to provide a user with limited access to a collection of images. For example, the user can access only the images in the set 107 having his / her face image. Alternatively, the user may be given access to a set of albums that include their face images, or one or more other predetermined sets of person face images. For example, in one embodiment, an album can be controlled based on a shared key, and the key is distributed only to users who meet a predetermined set of criteria. The flowchart 1600 of FIG. 16 shows the steps for implementing such restricted access in one embodiment. In step 1601, the user may be authenticated for access to an image having his / her face image. Similarly, in some embodiments, a user may be authenticated for access to one or more other person's images. The user's privileges to access one or more other person's images can be based on, for example, user identifiers, predefined user groups, and / or access privileges set for each album, image or subject name, Can be defined in a configuration file accessible to In step 1602, an already named face image in the database 108 with a matching subject name may be obtained. In step 1603, the set 107 can be accessed based only on the facial image acquired in step 1602. For example, each time a user attempts to access an image in the set 107, the access is verified by verifying that the facial image obtained in step 1602 refers to the selected image in the set 107. The
別の実施形態において、本発明は、ユーザが顔画像にタグを割り当てる際に、ユーザが、タグ付けされている人物の顔画像を含む任意の画像に望ましい公開レベル（すなわちアクセスレベル）、および／またはその人物に指定された１つ以上のタグを表示するかどうかを指定することを可能にする。いくつかの実施形態において、１組の画像が公衆、ユーザの所定のグループ、または画像の所有者のみに表示され得るように、様々な許可レベルをアクセスレベルとして設定することができる。アクセスレベルに基き、選択されたタグとともに、またはタグなしで、同じ画像が表示され得る。また、画像がタグ付けされる際、タグ付けアプリケーションは、他のアプリケーションと相互作用して情報を交換することができる。例えば、１つ以上の顔画像のタグ付けの間、タグ付けアプリケーションは、連絡先リストアプリケーションまたは電子メールシステムと相互作用して、一方または両方のアプリケーションに有用となり得る情報を交換することができる。 In another embodiment, the present invention provides that when a user assigns a tag to a face image, the user is exposed to a desired public level (ie, access level) for any image that includes the face image of the person being tagged, and / or Alternatively, it is possible to specify whether to display one or more tags specified for the person. In some embodiments, various permission levels can be set as access levels so that a set of images can be displayed only to the public, a predetermined group of users, or the image owner. Based on the access level, the same image can be displayed with or without the selected tag. Also, when images are tagged, the tagging application can interact with other applications to exchange information. For example, during the tagging of one or more facial images, the tagging application can interact with a contact list application or email system to exchange information that may be useful to one or both applications.
概要および要約の項ではなく、発明を実施するための形態の項は、特許請求の範囲を解釈するために使用されることを目的とすることを理解されたい。概要および要約の項は、本発明者らにより企図されるように、本発明の例示的実施形態のすべてではないが１つ以上を説明し得るが、本発明および添付の特許請求の範囲を制限することを全く意図しない。 It should be understood that the Detailed Description section, rather than the Summary and Summary section, is intended to be used for interpreting the scope of the claims. The summary and summary sections may explain one or more, but not all, of the exemplary embodiments of the invention as contemplated by the inventors, but limit the scope of the invention and the appended claims. Not intended to do anything.
特定の機能の実装およびその関係を例示した機能的な基礎的要素の助けにより本発明を上で説明した。これらの機能的な基礎的要素の境界は、説明に便利なように本明細書において適宜画定されている。特定の機能およびその関係が適切に実行される限り、代替の境界を画定することができる。 The invention has been described above with the aid of functional building blocks illustrating the implementation of specific functions and their relationships. The boundaries of these functional building blocks are appropriately defined herein for convenience of explanation. Alternative boundaries can be defined as long as certain functions and their relationships are properly performed.
特定の実施形態の上記説明は、当技術の範囲内の知識を適用することにより、必要以上の実験を行わずに、また本発明の一般的概念から逸脱せずに、他の者がそのような特定の実施形態を様々な用途に合わせ容易に修正および／または適合させることができるように、本発明の一般的性質を十分明らかとしている。したがって、そのような適合および修正は、本明細書に示された教示および指針に基き、開示された実施形態の同等物の意味および範囲内であることが意図される。本明細書における語法または用語は説明を目的としており、限定を目的とせず、本明細書の用語または語法は教示および指針に照らして当業者により解釈されるべきであることを理解されたい。 The above description of specific embodiments has been described by others without applying undue experimentation and without departing from the general concept of the invention by applying knowledge within the skill of the art. The general nature of the present invention is well understood so that such specific embodiments can be readily modified and / or adapted to various applications. Accordingly, such adaptations and modifications are intended to be within the meaning and scope of the equivalents of the disclosed embodiments based on the teachings and guidance presented herein. It is to be understood that the terminology or terminology herein is for the purpose of description, is not intended to be limiting, and the terminology or terminology herein should be construed by those skilled in the art in light of the teachings and guidelines.
本発明の外延および範囲は、上述の例示的な実施形態のいずれによっても限定されるべきではなく、以下の請求項およびその同等物によってのみ定義されるべきである。 The extension and scope of the invention should not be limited by any of the above-described exemplary embodiments, but should be defined only in accordance with the following claims and their equivalents.
Claims (12)
該デジタル画像の集合からの画像において顔画像を検出することと、
該顔画像を類似グループにグループ分けすることと、
該類似グループのうちの少なくとも１つからの第１組の顔画像に対する第１顔認識テンプレートを決定することと、
該顔画像データベースにおける１つ以上の名前を付けられていない類似グループから第２組の顔画像を取得することであって、該名前を付けられていない類似グループは関連した名前を有さず、該名前を付けられていない類似グループの顔認識テンプレートは、該第１顔認識テンプレートと実質的に一致する、ことと、
該類似グループの１つ以上をグラフィカルユーザインタフェースに表示することと、
該第２組の顔画像を該グラフィカルユーザインタフェースに表示することと、
該第２組に関連付けられたユーザ入力を受容することと、
該ユーザ入力に従い該第２組を更新することと
を含む、方法。 A method for creating and updating a face image database from a collection of digital images, comprising:
Detecting a face image in an image from the set of digital images;
Grouping the facial images into similar groups;
Determining a first face recognition template for a first set of face images from at least one of the similar groups;
Obtaining a second set of facial images from one or more unnamed similar groups in the facial image database, wherein the unnamed similar groups have no associated names; The unnamed similar group of face recognition templates substantially matches the first face recognition template;
Displaying one or more of the similar groups in a graphical user interface;
Displaying the second set of face images on the graphical user interface;
Accepting user input associated with the second set;
Updating the second set according to the user input.
該対象名により該表示された類似グループの１つ以上を更新することと
をさらに含む、請求項２に記載の方法。 Accepting subject names for one or more of the displayed similar groups;
The method of claim 2, further comprising: updating one or more of the displayed similar groups with the subject name.
ユーザが、該表示された類似グループのうちの少なくとも１つに対する名前をエントリのリストから選択することを可能にすることであって、該エントリのリストの各エントリは、名前および顔画像のうちの少なくとも１つを有し、該各エントリは、名前と関連した１つ以上の顔画像に対応し、該エントリのリストは、該表示された類似グループのうちの少なくとも１つへの類似性に従い順序付けられる、ことを含む、請求項３に記載の方法。 Accepting subject names for one or more of the displayed similar groups,
Allowing a user to select a name for at least one of the displayed similar groups from a list of entries, each entry of the list of entries being a name and a face image And each entry corresponds to one or more facial images associated with a name, and the list of entries is ordered according to similarity to at least one of the displayed similar groups 4. The method of claim 3, comprising:
（ｉ）該１つ以上の類似グループのそれぞれからの代表的顔画像を、選択可能なフィルムストリップレイアウトで表示することと、
（ｉｉ）ユーザ入力に基づいて、代表的顔画像を選択することと、
（ｉｉｉ）該選択された代表的顔画像に対応する少なくとも１つの類似グループの顔画像を表示することと
を含む、請求項２に記載の方法。 Displaying one or more of the similar groups in a graphical user interface;
(I) displaying representative face images from each of the one or more similar groups in a selectable filmstrip layout;
(Ii) selecting a representative face image based on user input;
3. The method of claim 2, comprising: (iii) displaying at least one similar group of face images corresponding to the selected representative face image.
少なくとも１つの類似グループから前記第１組の顔画像を取得することであって、該少なくとも１つの類似グループと関連付けられた名前は、該対象名と実質的に一致する、ことと、
該第１組を前記グラフィカルユーザインタフェースに表示することと
をさらに含む、請求項１に記載の方法。 Accepting the subject name from the user;
Obtaining the first set of facial images from at least one similar group, wherein a name associated with the at least one similar group substantially matches the subject name;
The method of claim 1, further comprising: displaying the first set on the graphical user interface.
（ｉ）クラスタに配設された該第１組を該グラフィカルユーザインタフェースに表示することを含む、請求項６に記載の方法。 Displaying the first set on a graphical user interface comprises:
7. The method of claim 6, comprising: (i) displaying the first set arranged in a cluster on the graphical user interface.
（ｉ）該第２組の各類似グループが別個のクラスタに配設された状態で、該第２組を該グラフィカルユーザインタフェースに表示することを含む、請求項１または７に記載の方法。 Displaying the second set of facial images on a graphical user interface comprises:
8. The method of claim 1 or 7, comprising: (i) displaying the second set on the graphical user interface with each similar group of the second set arranged in a separate cluster.
（ｉ）前記ユーザ入力に基づき１つ以上の顔画像を拒否することであって、該拒否された１つ以上の顔画像は、ユーザから受容された対象名を割り当てられない、ことと、
（ｉｉ）該ユーザ入力に基づき前記第２組の１つ以上の類似グループを拒否することであって、該拒否された１つ以上の類似グループは、該対象名を割り当てられない、ことと、
（ｉｉｉ）該ユーザ入力に基づき該第２組の１つ以上の類似グループを確認することと
のうちの１つ以上をさらに含む、請求項１に記載の方法。 Accepting user input is
(I) rejecting one or more face images based on the user input, wherein the rejected one or more face images are not assigned a subject name accepted from a user ;
(Ii) rejecting the second set of one or more similar groups based on the user input, wherein the rejected one or more similar groups are not assigned the subject name;
The method of claim 1, further comprising: one or more of: (iii) confirming the second set of one or more similar groups based on the user input.
（ｉ）該ユーザ入力に基づき該第２組の類似グループの顔画像に前記対象名を割り当てることをさらに含む、請求項６に記載の方法。 Updating the second set according to the user input is:
7. The method of claim 6, further comprising: (i) assigning the subject name to face images of the second set of similar groups based on the user input.
（ｉ）該第１組を該グラフィカルユーザインタフェースの第１の領域内に表示することを含む、請求項６に記載の方法。 Displaying the first set on a graphical user interface comprises:
The method of claim 6, comprising: (i) displaying the first set in a first region of the graphical user interface.
（ｉ）該第２組を該グラフィカルユーザインタフェースの第２の領域に表示することであって、該第２組は、前記第１組との類似性に従い順序付けられる、ことを含む、請求項１１に記載の方法。 Displaying the second set of facial images on a graphical user interface comprises:
12. (i) displaying the second set in a second region of the graphical user interface, the second set being ordered according to similarity to the first set. The method described in 1.
Applications Claiming Priority (4)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US4188308P | 2008-04-02 | 2008-04-02 | |
US61/041,883 | 2008-04-02 | ||
US5051408P | 2008-05-05 | 2008-05-05 | |
US61/050,514 | 2008-05-05 |
Related Parent Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2011502952A Division JP2011516966A (en) | 2008-04-02 | 2009-04-01 | Method and apparatus for incorporating automatic face recognition in a digital image collection |
Publications (2)
Publication Number | Publication Date |
---|---|
JP2014222519A JP2014222519A (en) | 2014-11-27 |
JP5869054B2 true JP5869054B2 (en) | 2016-02-24 |
Family
ID=40886267
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2011502952A Pending JP2011516966A (en) | 2008-04-02 | 2009-04-01 | Method and apparatus for incorporating automatic face recognition in a digital image collection |
JP2014128813A Active JP5869054B2 (en) | 2008-04-02 | 2014-06-24 | Method and apparatus for incorporating automatic face recognition in a digital image collection |
Family Applications Before (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2011502952A Pending JP2011516966A (en) | 2008-04-02 | 2009-04-01 | Method and apparatus for incorporating automatic face recognition in a digital image collection |
Country Status (6)
Country | Link |
---|---|
US (2) | US8358811B2 (en) |
EP (3) | EP2618289A3 (en) |
JP (2) | JP2011516966A (en) |
KR (1) | KR101618735B1 (en) |
CN (1) | CN101990667B (en) |
WO (1) | WO2009123711A1 (en) |
Families Citing this family (168)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US8447077B2 (en) | 2006-09-11 | 2013-05-21 | Validity Sensors, Inc. | Method and apparatus for fingerprint motion tracking using an in-line array |
EP1800243B1 (en) | 2004-10-04 | 2010-08-11 | Validity Sensors, Inc. | Fingerprint sensing assemblies comprising a substrate |
US9639740B2 (en) | 2007-12-31 | 2017-05-02 | Applied Recognition Inc. | Face detection and recognition |
CN104866553A (en) | 2007-12-31 | 2015-08-26 | 应用识别公司 | Method, system, and computer program for identification and sharing of digital images with face signatures |
US9721148B2 (en) | 2007-12-31 | 2017-08-01 | Applied Recognition Inc. | Face detection and recognition |
JP2011516966A (en) | 2008-04-02 | 2011-05-26 | グーグル インコーポレイテッド | Method and apparatus for incorporating automatic face recognition in a digital image collection |
CN103475837B (en) | 2008-05-19 | 2017-06-23 | 日立麦克赛尔株式会社 | Record reproducing device and method |
CA2728497A1 (en) * | 2008-06-17 | 2009-12-23 | Jostens, Inc. | System and method for yearbook creation |
US9141863B2 (en) * | 2008-07-21 | 2015-09-22 | Facefirst, Llc | Managed biometric-based notification system and method |
US20100115036A1 (en) * | 2008-10-31 | 2010-05-06 | Nokia Coporation | Method, apparatus and computer program product for generating a composite media file |
US8457366B2 (en) | 2008-12-12 | 2013-06-04 | At&T Intellectual Property I, L.P. | System and method for matching faces |
US9727312B1 (en) | 2009-02-17 | 2017-08-08 | Ikorongo Technology, LLC | Providing subject information regarding upcoming images on a display |
US9210313B1 (en) | 2009-02-17 | 2015-12-08 | Ikorongo Technology, LLC | Display device content selection through viewer identification and affinity prediction |
US10706601B2 (en) | 2009-02-17 | 2020-07-07 | Ikorongo Technology, LLC | Interface for receiving subject affinity information |
US20110044512A1 (en) * | 2009-03-31 | 2011-02-24 | Myspace Inc. | Automatic Image Tagging |
JP2010259064A (en) * | 2009-04-03 | 2010-11-11 | Olympus Imaging Corp | Display and image pickup device |
US8768313B2 (en) * | 2009-08-17 | 2014-07-01 | Digimarc Corporation | Methods and systems for image or audio recognition processing |
US8649602B2 (en) * | 2009-08-18 | 2014-02-11 | Cyberlink Corporation | Systems and methods for tagging photos |
JP5503921B2 (en) * | 2009-08-21 | 2014-05-28 | ソニーモバイルコミュニケーションズ， エービー | Information terminal, information terminal information control method and information control program |
US8503739B2 (en) * | 2009-09-18 | 2013-08-06 | Adobe Systems Incorporated | System and method for using contextual features to improve face recognition in digital images |
US20110148857A1 (en) * | 2009-12-23 | 2011-06-23 | Microsoft Corporation | Finding and sharing of digital images based on shared face models |
US8416997B2 (en) * | 2010-01-27 | 2013-04-09 | Apple Inc. | Method of person identification using social connections |
US8645287B2 (en) | 2010-02-04 | 2014-02-04 | Microsoft Corporation | Image tagging based upon cross domain context |
US9465993B2 (en) * | 2010-03-01 | 2016-10-11 | Microsoft Technology Licensing, Llc | Ranking clusters based on facial image analysis |
US20110243397A1 (en) | 2010-03-30 | 2011-10-06 | Christopher Watkins | Searching digital image collections using face recognition |
US8495057B2 (en) | 2010-05-17 | 2013-07-23 | Microsoft Corporation | Image searching with recognition suggestion |
US20120030575A1 (en) * | 2010-07-27 | 2012-02-02 | Cok Ronald S | Automated image-selection system |
US8270684B2 (en) * | 2010-07-27 | 2012-09-18 | Google Inc. | Automatic media sharing via shutter click |
JP5653131B2 (en) | 2010-08-25 | 2015-01-14 | キヤノン株式会社 | Object recognition apparatus and recognition method thereof |
US8724910B1 (en) * | 2010-08-31 | 2014-05-13 | Google Inc. | Selection of representative images |
US8630494B1 (en) | 2010-09-01 | 2014-01-14 | Ikorongo Technology, LLC | Method and system for sharing image content based on collection proximity |
US8774528B2 (en) * | 2010-09-24 | 2014-07-08 | Kodak Alaris Inc. | Method of selecting important digital images |
US8824748B2 (en) * | 2010-09-24 | 2014-09-02 | Facebook, Inc. | Auto tagging in geo-social networking system |
WO2012042631A1 (en) * | 2010-09-30 | 2012-04-05 | 富士通フロンテック株式会社 | Registration program, registration device, and registration method |
US8744196B2 (en) * | 2010-11-26 | 2014-06-03 | Hewlett-Packard Development Company, L.P. | Automatic recognition of images |
US20120328168A1 (en) * | 2011-01-31 | 2012-12-27 | Andrea Dailey | System and Method for Yearbook Creation |
US20120213404A1 (en) | 2011-02-18 | 2012-08-23 | Google Inc. | Automatic event recognition and cross-user photo clustering |
US9251854B2 (en) | 2011-02-18 | 2016-02-02 | Google Inc. | Facial detection, recognition and bookmarking in videos |
JP5795650B2 (en) * | 2011-02-18 | 2015-10-14 | グーグル・インク | Face recognition |
KR101770262B1 (en) * | 2011-03-16 | 2017-08-22 | 엘지전자 주식회사 | Mobile terminal and control method for mobile terminal |
US8782136B1 (en) | 2011-03-28 | 2014-07-15 | Google Inc. | System and method for providing access to data objects based on proximity |
US9317530B2 (en) | 2011-03-29 | 2016-04-19 | Facebook, Inc. | Face recognition based on spatial and temporal proximity |
US8631084B2 (en) | 2011-04-29 | 2014-01-14 | Facebook, Inc. | Dynamic tagging recommendation |
US9552376B2 (en) | 2011-06-09 | 2017-01-24 | MemoryWeb, LLC | Method and apparatus for managing digital files |
US20120314916A1 (en) * | 2011-06-13 | 2012-12-13 | Reagan Inventions, Llc | Identifying and tagging objects within a digital image |
US8831294B2 (en) | 2011-06-17 | 2014-09-09 | Microsoft Corporation | Broadcast identifier enhanced facial recognition of images |
US9147047B1 (en) | 2011-08-11 | 2015-09-29 | West Corporation | Image capture to enforce remote agent adherence |
US9195679B1 (en) | 2011-08-11 | 2015-11-24 | Ikorongo Technology, LLC | Method and system for the contextual display of image tags in a social network |
US8548207B2 (en) | 2011-08-15 | 2013-10-01 | Daon Holdings Limited | Method of host-directed illumination and system for conducting host-directed illumination |
US8903138B1 (en) | 2011-09-06 | 2014-12-02 | Google Inc. | Face recognition using pre-templates |
US8593452B2 (en) * | 2011-12-20 | 2013-11-26 | Apple Inc. | Face feature vector construction |
US9135410B2 (en) * | 2011-12-21 | 2015-09-15 | At&T Intellectual Property I, L.P. | Digital rights management using a digital agent |
WO2013100697A1 (en) * | 2011-12-29 | 2013-07-04 | Intel Corporation | Method, apparatus, and computer-readable recording medium for authenticating a user |
US9202105B1 (en) | 2012-01-13 | 2015-12-01 | Amazon Technologies, Inc. | Image analysis for user authentication |
CN108073948A (en) * | 2012-01-17 | 2018-05-25 | 华为技术有限公司 | A kind of photo sort management, server, apparatus and system |
US20130198836A1 (en) * | 2012-01-31 | 2013-08-01 | Google Inc. | Facial Recognition Streamlined Login |
US8824750B2 (en) * | 2012-03-19 | 2014-09-02 | Next Level Security Systems, Inc. | Distributive facial matching and notification system |
US8666123B2 (en) | 2012-04-26 | 2014-03-04 | Google Inc. | Creating social network groups |
US8891883B2 (en) | 2012-05-15 | 2014-11-18 | Google Inc. | Summarizing a photo album in a social network system |
US20140233811A1 (en) * | 2012-05-15 | 2014-08-21 | Google Inc. | Summarizing a photo album |
KR101964348B1 (en) * | 2012-05-18 | 2019-04-01 | 삼성전자주식회사 | Method for line up contents of media equipment, apparatus thereof, and medium storing program source thereof |
US9483556B1 (en) | 2012-05-25 | 2016-11-01 | Google Inc. | Aggregating photos captured at an event |
US8855369B2 (en) | 2012-06-22 | 2014-10-07 | Microsoft Corporation | Self learning face recognition using depth based tracking for database generation and update |
US9665773B2 (en) * | 2012-06-25 | 2017-05-30 | Google Inc. | Searching for events by attendants |
US9391792B2 (en) | 2012-06-27 | 2016-07-12 | Google Inc. | System and method for event content stream |
JP6071288B2 (en) * | 2012-07-09 | 2017-02-01 | キヤノン株式会社 | Image processing apparatus, image processing method, and program |
JP6071287B2 (en) * | 2012-07-09 | 2017-02-01 | キヤノン株式会社 | Image processing apparatus, image processing method, and program |
US20140056489A1 (en) * | 2012-08-22 | 2014-02-27 | Google Inc. | System and method for sharing media |
US8856541B1 (en) | 2013-01-10 | 2014-10-07 | Google Inc. | Liveness detection |
US9396384B2 (en) | 2013-03-13 | 2016-07-19 | Intel Corporation | User authentication via image manipulation |
US9405771B2 (en) * | 2013-03-14 | 2016-08-02 | Microsoft Technology Licensing, Llc | Associating metadata with images in a personal image collection |
US9449216B1 (en) * | 2013-04-10 | 2016-09-20 | Amazon Technologies, Inc. | Detection of cast members in video content |
US10235508B2 (en) * | 2013-05-08 | 2019-03-19 | Jpmorgan Chase Bank, N.A. | Systems and methods for high fidelity multi-modal out-of-band biometric authentication with human cross-checking |
US9760785B2 (en) | 2013-05-08 | 2017-09-12 | Jpmorgan Chase Bank, N.A. | Systems and methods for high fidelity multi-modal out-of-band biometric authentication |
US9721175B2 (en) | 2013-05-08 | 2017-08-01 | Jpmorgan Chase Bank, N.A. | Systems and methods for high fidelity multi-modal out-of-band biometric authentication through vector-based multi-profile storage |
US10032091B2 (en) * | 2013-06-05 | 2018-07-24 | Emotient, Inc. | Spatial organization of images based on emotion face clouds |
US9875431B2 (en) | 2013-06-28 | 2018-01-23 | Nec Corporation | Training data generating device, method, and program, and crowd state recognition device, method, and program |
US9923855B2 (en) | 2013-08-01 | 2018-03-20 | Jpmorgan Chase Bank, N.A. | Systems and methods for electronic message prioritization |
US9892576B2 (en) | 2013-08-02 | 2018-02-13 | Jpmorgan Chase Bank, N.A. | Biometrics identification module and personal wearable electronics network based authentication and transaction processing |
US9910865B2 (en) | 2013-08-05 | 2018-03-06 | Nvidia Corporation | Method for capturing the moment of the photo capture |
US20150066941A1 (en) * | 2013-08-30 | 2015-03-05 | U-Me Holdings LLC | Photo cataloging, storage and retrieval using relationships between people |
US20150085146A1 (en) * | 2013-09-23 | 2015-03-26 | Nvidia Corporation | Method and system for storing contact information in an image using a mobile device |
US9829480B2 (en) | 2013-09-26 | 2017-11-28 | Alcohol Monitoring Systems, Inc. | Remote breath alcohol monitor |
CN103593650B (en) * | 2013-10-28 | 2017-01-25 | 浙江大学 | Method for generating artistic images on basis of facial expression recognition system |
US9569656B2 (en) | 2013-12-06 | 2017-02-14 | Google Inc. | Local real-time facial recognition |
KR101480256B1 (en) * | 2013-12-13 | 2015-01-09 | 계명대학교 산학협력단 | Image transmission apparatus considering the position of face region and method thereof |
CN103646199B (en) * | 2013-12-26 | 2016-06-15 | 中国电子科技集团公司第三研究所 | A kind of based on the auth method of nine grids password and facial image |
KR101534808B1 (en) * | 2013-12-30 | 2015-07-08 | 주식회사 시어스랩 | Method and System for managing Electronic Album using the Facial Recognition |
US9635108B2 (en) | 2014-01-25 | 2017-04-25 | Q Technologies Inc. | Systems and methods for content sharing using uniquely generated idenifiers |
US10121060B2 (en) * | 2014-02-13 | 2018-11-06 | Oath Inc. | Automatic group formation and group detection through media recognition |
US9268793B2 (en) * | 2014-03-12 | 2016-02-23 | Google Inc. | Adjustment of facial image search results |
CN104933391B (en) * | 2014-03-20 | 2018-08-10 | 联想(北京)有限公司 | Method and apparatus for carrying out face recognition and electronic equipment |
US9614724B2 (en) | 2014-04-21 | 2017-04-04 | Microsoft Technology Licensing, Llc | Session-based device configuration |
US9639742B2 (en) | 2014-04-28 | 2017-05-02 | Microsoft Technology Licensing, Llc | Creation of representative content based on facial analysis |
US9773156B2 (en) | 2014-04-29 | 2017-09-26 | Microsoft Technology Licensing, Llc | Grouping and ranking images based on facial recognition data |
US9519826B2 (en) | 2014-05-08 | 2016-12-13 | Shutterfly, Inc. | Automatic image product creation for user accounts comprising large number of images |
US9384335B2 (en) | 2014-05-12 | 2016-07-05 | Microsoft Technology Licensing, Llc | Content delivery prioritization in managed wireless distribution networks |
US9430667B2 (en) | 2014-05-12 | 2016-08-30 | Microsoft Technology Licensing, Llc | Managed wireless distribution network |
US10111099B2 (en) | 2014-05-12 | 2018-10-23 | Microsoft Technology Licensing, Llc | Distributing content in managed wireless distribution networks |
US9384334B2 (en) | 2014-05-12 | 2016-07-05 | Microsoft Technology Licensing, Llc | Content discovery in managed wireless distribution networks |
US9874914B2 (en) | 2014-05-19 | 2018-01-23 | Microsoft Technology Licensing, Llc | Power management contracts for accessory devices |
US10037202B2 (en) | 2014-06-03 | 2018-07-31 | Microsoft Technology Licensing, Llc | Techniques to isolating a portion of an online computing service |
KR102223205B1 (en) | 2014-06-11 | 2021-03-08 | 삼성전자주식회사 | Image classification device, method for operating the same and electronic system comprising the image classification device |
US9367490B2 (en) | 2014-06-13 | 2016-06-14 | Microsoft Technology Licensing, Llc | Reversible connector for accessory devices |
US9460493B2 (en) | 2014-06-14 | 2016-10-04 | Microsoft Technology Licensing, Llc | Automatic video quality enhancement with temporal smoothing and user override |
US20150362989A1 (en) * | 2014-06-17 | 2015-12-17 | Amazon Technologies, Inc. | Dynamic template selection for object detection and tracking |
US9373179B2 (en) | 2014-06-23 | 2016-06-21 | Microsoft Technology Licensing, Llc | Saliency-preserving distinctive low-footprint photograph aging effect |
WO2015200350A1 (en) | 2014-06-24 | 2015-12-30 | Google Inc. | Ranking and selecting images for display from a set of images |
US10698995B2 (en) | 2014-08-28 | 2020-06-30 | Facetec, Inc. | Method to verify identity using a previously collected biometric image/data |
CA2902093C (en) | 2014-08-28 | 2023-03-07 | Kevin Alan Tussy | Facial recognition authentication system including path parameters |
US10614204B2 (en) | 2014-08-28 | 2020-04-07 | Facetec, Inc. | Facial recognition authentication system including path parameters |
US10803160B2 (en) | 2014-08-28 | 2020-10-13 | Facetec, Inc. | Method to verify and identify blockchain with user question data |
US10915618B2 (en) | 2014-08-28 | 2021-02-09 | Facetec, Inc. | Method to add remotely collected biometric images / templates to a database record of personal information |
US11256792B2 (en) | 2014-08-28 | 2022-02-22 | Facetec, Inc. | Method and apparatus for creation and use of digital identification |
CN104284252A (en) * | 2014-09-10 | 2015-01-14 | 康佳集团股份有限公司 | Method for generating electronic photo album automatically |
KR102024867B1 (en) | 2014-09-16 | 2019-09-24 | 삼성전자주식회사 | Feature extracting method of input image based on example pyramid and apparatus of face recognition |
US20160092082A1 (en) * | 2014-09-29 | 2016-03-31 | Apple Inc. | Visualizing Relationships Between Entities in Content Items |
US10121056B2 (en) | 2015-03-02 | 2018-11-06 | International Business Machines Corporation | Ensuring a desired distribution of content in a multimedia document for different demographic groups utilizing demographic information |
US9507996B2 (en) | 2015-03-02 | 2016-11-29 | International Business Machines Corporation | Ensuring a desired distribution of images in a multimedia document utilizing facial signatures |
US10445391B2 (en) | 2015-03-27 | 2019-10-15 | Jostens, Inc. | Yearbook publishing system |
CN104852967B (en) * | 2015-04-21 | 2018-03-27 | 小米科技有限责任公司 | Image sharing method and device |
US9448704B1 (en) | 2015-04-29 | 2016-09-20 | Dropbox, Inc. | Navigating digital content using visual characteristics of the digital content |
US10094655B2 (en) | 2015-07-15 | 2018-10-09 | 15 Seconds of Fame, Inc. | Apparatus and methods for facial recognition and video analytics to identify individuals in contextual video streams |
CN106371551A (en) * | 2015-07-20 | 2017-02-01 | 深圳富泰宏精密工业有限公司 | Operation system and operation method for facial expression, and electronic device |
CN106453209B (en) * | 2015-08-07 | 2020-01-21 | 阿里巴巴集团控股有限公司 | Identity verification method and device |
CN105224838B (en) * | 2015-09-28 | 2018-02-09 | 广东欧珀移动通信有限公司 | A kind of user authority control method and system based on recognition of face |
CN107710197B (en) | 2015-09-28 | 2021-08-17 | 谷歌有限责任公司 | Sharing images and image albums over a communication network |
US10320861B2 (en) | 2015-09-30 | 2019-06-11 | Google Llc | System and method for automatic meeting note creation and sharing using a user's context and physical proximity |
EP3365838A4 (en) | 2015-10-21 | 2019-08-28 | 15 Seconds Of Fame, Inc. | Methods and apparatus for false positive minimization in facial recognition applications |
EP3371742A4 (en) | 2015-11-04 | 2019-06-26 | Shutterfly, Inc. | Automatic image product creation for user accounts comprising large number of images |
CN105426485A (en) * | 2015-11-20 | 2016-03-23 | 小米科技有限责任公司 | Image combination method and device, intelligent terminal and server |
CN105608425B (en) * | 2015-12-17 | 2019-02-15 | 小米科技有限责任公司 | The method and device of classification storage is carried out to photo |
SG10201601838TA (en) * | 2016-03-09 | 2017-10-30 | Trakomatic Pte Ltd | Method and system for visitor tracking at a pos area |
US10127945B2 (en) | 2016-03-15 | 2018-11-13 | Google Llc | Visualization of image themes based on image content |
US10198625B1 (en) | 2016-03-26 | 2019-02-05 | Videomining Corporation | Association of unique person to a mobile device using repeat face image matching |
USD987653S1 (en) | 2016-04-26 | 2023-05-30 | Facetec, Inc. | Display screen or portion thereof with graphical user interface |
WO2018015988A1 (en) * | 2016-07-19 | 2018-01-25 | 株式会社オプティム | Person painting identification system, person painting identification method, and program |
US10083358B1 (en) | 2016-07-26 | 2018-09-25 | Videomining Corporation | Association of unique person to point-of-sale transaction data |
US9996773B2 (en) | 2016-08-04 | 2018-06-12 | International Business Machines Corporation | Face recognition in big data ecosystem using multiple recognition models |
US10614436B1 (en) | 2016-08-25 | 2020-04-07 | Videomining Corporation | Association of mobile device to retail transaction |
EP3475848B1 (en) | 2016-09-05 | 2019-11-27 | Google LLC | Generating theme-based videos |
JP2018081402A (en) * | 2016-11-15 | 2018-05-24 | キヤノン株式会社 | Image processing system, image processing method, and program |
US20180157681A1 (en) * | 2016-12-06 | 2018-06-07 | Ebay Inc. | Anchored search |
US11222227B2 (en) | 2017-01-25 | 2022-01-11 | Chaim Mintz | Photo subscription system and method using biometric identification |
US10095915B2 (en) | 2017-01-25 | 2018-10-09 | Chaim Mintz | Photo subscription system and method using biometric identification |
EP3568787B1 (en) | 2017-05-17 | 2024-04-10 | Google LLC | Automatic image sharing with designated users over a communication network |
US11169661B2 (en) * | 2017-05-31 | 2021-11-09 | International Business Machines Corporation | Thumbnail generation for digital images |
WO2019040654A1 (en) * | 2017-08-22 | 2019-02-28 | Incode Technologies, Inc. | Apparatus and method for configurable automated distribution of images |
CN109947965B (en) * | 2017-09-04 | 2023-09-05 | 阿里巴巴集团控股有限公司 | Object recognition, data set updating and data processing method and device |
CN108170750A (en) * | 2017-12-21 | 2018-06-15 | 深圳英飞拓科技股份有限公司 | A kind of face database update method, system and terminal device |
US11735018B2 (en) | 2018-03-11 | 2023-08-22 | Intellivision Technologies Corp. | Security system with face recognition |
WO2019206251A1 (en) * | 2018-04-27 | 2019-10-31 | Shanghai Truthvision Information Technology Co., Ltd. | Systems and methods for image archiving |
KR102102405B1 (en) | 2018-06-08 | 2020-04-20 | 부산대학교 산학협력단 | System and Method for Recognitioning Image Pattern using Machine Learning |
CN109101542B (en) * | 2018-07-02 | 2021-02-02 | 深圳市商汤科技有限公司 | Image recognition result output method and device, electronic device and storage medium |
US10936856B2 (en) | 2018-08-31 | 2021-03-02 | 15 Seconds of Fame, Inc. | Methods and apparatus for reducing false positives in facial recognition |
CN111125391A (en) * | 2018-11-01 | 2020-05-08 | 北京市商汤科技开发有限公司 | Database updating method and device, electronic equipment and computer storage medium |
US20200151453A1 (en) * | 2018-11-08 | 2020-05-14 | International Business Machines Corporation | Reducing overlap among a collection of photographs |
CN112041847A (en) | 2018-12-07 | 2020-12-04 | 微软技术许可有限责任公司 | Providing images with privacy tags |
CN109753920B (en) * | 2018-12-29 | 2021-09-17 | 深圳市商汤科技有限公司 | Pedestrian identification method and device |
US10936178B2 (en) | 2019-01-07 | 2021-03-02 | MemoryWeb, LLC | Systems and methods for analyzing and organizing digital photos and videos |
US11010596B2 (en) | 2019-03-07 | 2021-05-18 | 15 Seconds of Fame, Inc. | Apparatus and methods for facial recognition systems to identify proximity-based connections |
US11283937B1 (en) | 2019-08-15 | 2022-03-22 | Ikorongo Technology, LLC | Sharing images based on face matching in a network |
US11341351B2 (en) | 2020-01-03 | 2022-05-24 | 15 Seconds of Fame, Inc. | Methods and apparatus for facial recognition on a user device |
WO2021141568A1 (en) * | 2020-01-06 | 2021-07-15 | Google Llc | Privacy controls for sharing embeddings for searching and indexing media content |
CN111797746A (en) * | 2020-06-28 | 2020-10-20 | 北京小米松果电子有限公司 | Face recognition method and device and computer readable storage medium |
CN112817503B (en) * | 2021-01-18 | 2024-03-26 | 陈林斌 | Intelligent display method of electronic photo frame, electronic photo frame and readable storage medium |
US11750666B2 (en) * | 2021-04-22 | 2023-09-05 | Bank Of America Corporation | Dynamic group session data access protocols |
WO2023129561A1 (en) * | 2021-12-28 | 2023-07-06 | Woods Jeremiah | Consumption of a video feed from a remotely located camera device |
Family Cites Families (30)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6222939B1 (en) | 1996-06-25 | 2001-04-24 | Eyematic Interfaces, Inc. | Labeled bunch graphs for image analysis |
US6301370B1 (en) | 1998-04-13 | 2001-10-09 | Eyematic Interfaces, Inc. | Face recognition from video images |
US7634662B2 (en) * | 2002-11-21 | 2009-12-15 | Monroe David A | Method for incorporating facial recognition technology in a multimedia surveillance system |
US6606398B2 (en) * | 1998-09-30 | 2003-08-12 | Intel Corporation | Automatic cataloging of people in digital photographs |
US7099510B2 (en) | 2000-11-29 | 2006-08-29 | Hewlett-Packard Development Company, L.P. | Method and system for object detection in digital images |
JP2002207741A (en) * | 2001-01-12 | 2002-07-26 | Minolta Co Ltd | Image data retrieval device, image data retrieval method, image data retrieval program, and computer-readable storage medium with image data retrieval program stored therein |
US6917703B1 (en) | 2001-02-28 | 2005-07-12 | Nevengineering, Inc. | Method and apparatus for image analysis of a gabor-wavelet transformed image using a neural network |
US8086867B2 (en) * | 2002-03-26 | 2011-12-27 | Northrop Grumman Systems Corporation | Secure identity and privilege system |
US20030210808A1 (en) * | 2002-05-10 | 2003-11-13 | Eastman Kodak Company | Method and apparatus for organizing and retrieving images containing human faces |
AU2003282943A1 (en) * | 2002-10-11 | 2004-05-04 | Digimarc Corporation | Systems and methods for recognition of individuals using multiple biometric searches |
JP3809823B2 (en) * | 2003-02-24 | 2006-08-16 | 日本電気株式会社 | Person information management system and person information management apparatus |
US7286723B2 (en) * | 2003-06-27 | 2007-10-23 | Hewlett-Packard Development Company, L.P. | System and method for organizing images |
US7274822B2 (en) * | 2003-06-30 | 2007-09-25 | Microsoft Corporation | Face annotation for photo management |
JP2005032163A (en) * | 2003-07-11 | 2005-02-03 | Nec Commun Syst Ltd | Face collation system |
JP2005080216A (en) * | 2003-09-03 | 2005-03-24 | Casio Comput Co Ltd | Image processing apparatus, image processing method and its program |
US7822233B2 (en) * | 2003-11-14 | 2010-10-26 | Fujifilm Corporation | Method and apparatus for organizing digital media based on face recognition |
WO2005055138A2 (en) * | 2003-11-26 | 2005-06-16 | Yesvideo, Inc. | Statical modeling of a visual image for use in determining similarity between visual images |
KR100601997B1 (en) * | 2004-10-12 | 2006-07-18 | 삼성전자주식회사 | Method and apparatus for person-based photo clustering in digital photo album, and Person-based digital photo albuming method and apparatus using it |
JP4267584B2 (en) * | 2005-02-28 | 2009-05-27 | 株式会社東芝 | Device control apparatus and method |
JP2006244279A (en) * | 2005-03-04 | 2006-09-14 | Mitsubishi Electric Corp | Image-classifying device |
US7646895B2 (en) * | 2005-04-05 | 2010-01-12 | 3Vr Security, Inc. | Grouping items in video stream images into events |
US7809722B2 (en) * | 2005-05-09 | 2010-10-05 | Like.Com | System and method for enabling search and retrieval from image files based on recognized information |
JP2007026316A (en) * | 2005-07-20 | 2007-02-01 | Yamaha Motor Co Ltd | Image management device, image-managing computer program and recording medium recording the same |
JP2007052646A (en) * | 2005-08-18 | 2007-03-01 | Fujifilm Holdings Corp | Image retrieval device, image printer, print ordering system, storefront print terminal device, imaging device, and image retrieval program and method |
US7920745B2 (en) | 2006-03-31 | 2011-04-05 | Fujifilm Corporation | Method and apparatus for performing constrained spectral clustering of digital image data |
US7907755B1 (en) * | 2006-05-10 | 2011-03-15 | Aol Inc. | Detecting facial similarity based on human perception of facial similarity |
CN100511230C (en) * | 2006-05-29 | 2009-07-08 | 北京万网志成科技有限公司 | Webpage-text based image search and display method thereof |
US7684651B2 (en) * | 2006-08-23 | 2010-03-23 | Microsoft Corporation | Image-based face search |
JP2011516966A (en) | 2008-04-02 | 2011-05-26 | グーグル インコーポレイテッド | Method and apparatus for incorporating automatic face recognition in a digital image collection |
US8036417B2 (en) * | 2008-06-11 | 2011-10-11 | Eastman Kodak Company | Finding orientation and date of hardcopy medium |
-
2009
- 2009-04-01 JP JP2011502952A patent/JP2011516966A/en active Pending
- 2009-04-01 CN CN2009801124564A patent/CN101990667B/en active Active
- 2009-04-01 KR KR1020107024606A patent/KR101618735B1/en active IP Right Grant
- 2009-04-01 WO PCT/US2009/002014 patent/WO2009123711A1/en active Application Filing
- 2009-04-01 EP EP13164484.1A patent/EP2618289A3/en not_active Ceased
- 2009-04-01 EP EP13164485.8A patent/EP2618290A3/en not_active Ceased
- 2009-04-01 US US12/416,632 patent/US8358811B2/en active Active
- 2009-04-01 EP EP09727089A patent/EP2281248A1/en not_active Withdrawn
-
2012
- 2012-12-17 US US13/717,426 patent/US8897508B2/en active Active
-
2014
- 2014-06-24 JP JP2014128813A patent/JP5869054B2/en active Active
Also Published As
Publication number | Publication date |
---|---|
KR20100129783A (en) | 2010-12-09 |
JP2014222519A (en) | 2014-11-27 |
WO2009123711A1 (en) | 2009-10-08 |
EP2281248A1 (en) | 2011-02-09 |
EP2618290A2 (en) | 2013-07-24 |
CN101990667A (en) | 2011-03-23 |
US20090252383A1 (en) | 2009-10-08 |
EP2618289A3 (en) | 2014-07-30 |
EP2618290A3 (en) | 2014-08-06 |
US8358811B2 (en) | 2013-01-22 |
KR101618735B1 (en) | 2016-05-09 |
CN101990667B (en) | 2013-08-28 |
US8897508B2 (en) | 2014-11-25 |
EP2618289A2 (en) | 2013-07-24 |
JP2011516966A (en) | 2011-05-26 |
US20130251217A1 (en) | 2013-09-26 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
JP5869054B2 (en) | Method and apparatus for incorporating automatic face recognition in a digital image collection | |
US20220269715A1 (en) | Facial based image organization and retrieval method | |
US9721148B2 (en) | Face detection and recognition | |
US8473525B2 (en) | Metadata generation for image files | |
US9639740B2 (en) | Face detection and recognition | |
US20180046855A1 (en) | Face detection and recognition | |
US8416997B2 (en) | Method of person identification using social connections | |
US8027541B2 (en) | Image organization based on image content | |
US9030502B2 (en) | System and method for organizing documents | |
JP5524219B2 (en) | Interactive image selection method | |
JP2007507775A (en) | How to cluster and query media items | |
US20140270550A1 (en) | Presentation and organization of content | |
JP2019508826A (en) | Masking limited access control system | |
WO2007129474A1 (en) | Object recognition device, object recognition program, and image search service providing method | |
US20220050867A1 (en) | Image management with region-based metadata indexing | |
KR100827845B1 (en) | Apparatus and method for providing person tag | |
Cerosaletti et al. | Approaches to consumer image organization based on semantic categories | |
US20170109803A1 (en) | Method and system for visual search based user-specific and customizable inventory management system |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
A977 | Report on retrieval |
Free format text: JAPANESE INTERMEDIATE CODE: A971007Effective date: 20150723 |
|
A131 | Notification of reasons for refusal |
Free format text: JAPANESE INTERMEDIATE CODE: A131Effective date: 20150804 |
|
RD03 | Notification of appointment of power of attorney |
Free format text: JAPANESE INTERMEDIATE CODE: A7423Effective date: 20151007 |
|
RD04 | Notification of resignation of power of attorney |
Free format text: JAPANESE INTERMEDIATE CODE: A7424Effective date: 20151016 |
|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20151102 |
|
TRDD | Decision of grant or rejection written | ||
A01 | Written decision to grant a patent or to grant a registration (utility model) |
Free format text: JAPANESE INTERMEDIATE CODE: A01Effective date: 20151207 |
|
A61 | First payment of annual fees (during grant procedure) |
Free format text: JAPANESE INTERMEDIATE CODE: A61Effective date: 20160106 |
|
R150 | Certificate of patent or registration of utility model |
Ref document number: 5869054Country of ref document: JPFree format text: JAPANESE INTERMEDIATE CODE: R150 |
|
S533 | Written request for registration of change of name |
Free format text: JAPANESE INTERMEDIATE CODE: R313533 |
|
R350 | Written notification of registration of transfer |
Free format text: JAPANESE INTERMEDIATE CODE: R350 |
|
R250 | Receipt of annual fees |
Free format text: JAPANESE INTERMEDIATE CODE: R250 |
|
RD02 | Notification of acceptance of power of attorney |
Free format text: JAPANESE INTERMEDIATE CODE: R3D02 |
|
R250 | Receipt of annual fees |
Free format text: JAPANESE INTERMEDIATE CODE: R250 |
|
R250 | Receipt of annual fees |
Free format text: JAPANESE INTERMEDIATE CODE: R250 |
|
R250 | Receipt of annual fees |
Free format text: JAPANESE INTERMEDIATE CODE: R250 |
|
R250 | Receipt of annual fees |
Free format text: JAPANESE INTERMEDIATE CODE: R250 |
|
R250 | Receipt of annual fees |
Free format text: JAPANESE INTERMEDIATE CODE: R250 |