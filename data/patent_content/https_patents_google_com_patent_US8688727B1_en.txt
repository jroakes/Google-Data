US8688727B1 - Generating query refinements - Google Patents
Generating query refinements Download PDFInfo
- Publication number
- US8688727B1 US8688727B1 US13/094,794 US201113094794A US8688727B1 US 8688727 B1 US8688727 B1 US 8688727B1 US 201113094794 A US201113094794 A US 201113094794A US 8688727 B1 US8688727 B1 US 8688727B1
- Authority
- US
- United States
- Prior art keywords
- query
- queries
- search query
- search
- candidate refinement
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active, expires
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/24—Querying
- G06F16/245—Query processing
- G06F16/2457—Query processing with adaptation to user needs
- G06F16/24575—Query processing with adaptation to user needs using context
Definitions
- This specification relates to generating query refinements.
- Internet search engines provide information about Internet accessible resources, e.g., Web pages, images, text documents, multimedia content, that are responsive to a user's search query by returning a set of search results in response to the search query.
- a search result includes, for example, a Uniform Resource Locator (URL) and perhaps a snippet of descriptive information for resources responsive to a search query.
- a search engine may also present query refinements, e.g., other queries related to the user's search query, that may be directed to what a user may consider to be relevant to the search.
- one aspect of the subject matter described in this specification can be embodied in methods that include the actions of obtaining a search query; dividing the search query into one or more n-grams; determining that each of the one or more n-grams represents a same concept, and in response to the determination: selecting one or more candidate refinement queries; determining one or more categories for the search query; determining one or more categories for each of the candidate refinement queries; determining a respective first score for each of the candidate refinement queries, wherein determining the respective first score for a particular candidate refinement query comprises adjusting the respective first score for the particular candidate refinement query based on a number of categories shared between the particular candidate refinement query and the search query; and identifying as query refinements for the search query one or more of the candidate refinement queries based on the first scores.
- Other embodiments of this aspect include corresponding systems, apparatus, and computer program products.
- Selecting one or more candidate refinement queries comprises: selecting one or more training terms as candidate refinement queries, wherein the training terms occur in a same context as the search query in training data.
- a respective right context of each of the selected training terms includes at least one word in a right context of the search query that is not a stop word, and wherein a respective left context of each of the selected training terms includes at least one word in a left context of the search query that is not a stop word.
- the respective right contexts and left contexts of the selected training terms are features of at least one of the previously submitted queries having a frequency of being submitted beyond a threshold value.
- Selecting one or more candidate refinement queries comprises: Selecting one or more previously submitted queries as candidate refinement queries, wherein the selected previously submitted queries were submitted during a first search session following submission of the search query.
- the selected previously submitted queries do not contain any terms from the search query that are not stop words.
- the respective first score for each of the selected previously submitted queries is based at least in part on a respective correlation value for each selected previously submitted query, wherein the correlation value for a particular previously submitted query represents the correlation between the search query and the particular previously submitted query.
- Selecting one or more candidate refinement queries comprises: selecting as candidate refinement queries one or more sibling queries of the search query, wherein sibling queries are queries that have one or more shared parent queries in common, and wherein each of the sibling queries was submitted during a second search session following submission of a shared parent query during the first search session.
- the search query is textually distinct from each of the selected sibling queries and all the substrings of the selected sibling queries.
- Determining the one or more categories for a particular candidate refinement query includes: determining, in training data, a frequency of occurrence of the particular candidate refinement query in a Hearst pattern with a particular category label; and determining that the particular candidate refinement query belongs to a category corresponding to the particular category label based on the frequency of occurrence.
- Determining that a particular query is parent-like includes: generating a modified query that semantically represents a grouping, where the grouping is related to a lexical item represented by the particular query; and determining that the particular query is parent like when the modified query has a frequency of being submitted beyond a threshold value.
- Generating and providing query refinements for display to a user reduces how much user interaction is required to obtain alternatives to an input search query, and perform searches using one or more of the alternatives.
- the alternatives can be textually different, e.g., include alternatives that are not expansions or completions of the input search query, and in a same domain, e.g., be related to a same category or topic as the input search query.
- providing query refinements can increase the precision, accuracy, and coverage, including diversity, of a search by capturing alternatives to the input search query that are directed to what a user may consider to be relevant to the search.
- query refinements can allow the user to broaden a search in a direction related to the input search query, but different from the input search query.
- query refinements can provide suggested topics of interest, e.g., by suggesting terms that identify concepts related to the input search query.
- FIG. 1 is a screenshot illustrating an example graphical user interface presenting search results and query refinements.
- FIG. 2 is a block diagram illustrating an example of data flow in an example system that generates query refinements.
- FIG. 3 is a block diagram of an example refinement engine.
- FIG. 4 is a flow chart showing an example process for generating query refinements.
- FIG. 1 is a screenshot illustrating an example graphical user interface (GUI) 100 presenting search results 104 and query refinements 106 .
- GUI graphical user interface
- the GUI 100 can be implemented in a web browser or other software application.
- a query “Jupiter” 102 is submitted to a search engine through the GUI 100 , and the search results 104 that are responsive to the query 102 are generated by the search engine and presented in the GUI 100 .
- a search result can include a web page title, a snippet of text extracted from the web page, and the URL of the web page.
- one search result illustrated in FIG. 1 includes a web page title “Overview of Jupiter”, a snippet “Many don't realize what a beautiful planet Jupiter is . . . ”, and a URL “http://exampleURL1.com”.
- presenting search results can include various forms of presentation including, for example, transmitting search results to a user's computer for presentation to the user, transmitting search results to another device, transmitting sounds corresponding to the search results, providing haptic feedback corresponding to the search results, or transmitting signals including haptic feedback corresponding to the search results to a user's computer for presentation to the user.
- Other methods of presenting search results are possible.
- the query 102 is a starting point for the exploration of a topic, or is an attempt to find specific information.
- users are exploring a topic, they are often looking for a general overview of the topic that may not be provided by search results alone.
- the search results will often be what the user is looking for, and a user will click (e.g., select with a mouse or other input device, for example, a keyboard, or a tactile or audio input device) one or more of the search results 104 .
- a user may not be satisfied with the search results 104 generated in response to a query.
- Users can be unsatisfied, for example, when the queries they submit are too broad. For example, when a user submits “Jupiter” but is really looking for “Jupiter moons,” the search engine may identify search results that are relevant to Jupiter, but not relevant to the moons of Jupiter. Users can also be unsatisfied, for example, when the queries they submit use incorrect terminology. For example, a user may submit a query for “Jupiter,” but really be interested in information on “Mars.” Other reasons for user dissatisfaction are also possible.
- a group of query refinements 106 e.g., related queries that a user may find have search results that are more relevant to the user's interests, can be generated and presented in the GUI 100 .
- the search engine can generate the query refinements 106 , for example.
- a query refinement of a given query is another query that is related to the given query.
- Some of the query refinements 106 presented in the user interface 100 are sibling queries to the user-entered query “Jupiter” 102 .
- two queries are siblings when one or more users submitted one of the queries after submitting a given parent query, and one or more users submitted the other query after submitting the given parent query.
- the search engine When a user selects one of the query refinements 106 (e.g., “NASA”), the search engine presents, in the GUI 100 , a new set of search results responsive to a query including the query refinement. In some implementations, the search engine can also present a new group of query refinements for the selected query refinement along with the new set of search results.
- the query refinements 106 e.g., “NASA”
- FIG. 2 is a block diagram illustrating an example of data flow in an example system 200 that generates query refinements.
- a user 202 interacts with a search system 214 through a client device 204 .
- the search system 214 is an example of an information retrieval system that can be used to generate search results 228 and query refinements.
- the client device 204 can be a computer (e.g., a personal computer, a mobile phone, a smart phone, a tablet computer, and so on) coupled to the search system 214 through a wired or wireless local area network (LAN) or wide area network (WAN), e.g., the Internet.
- LAN local area network
- WAN wide area network
- the search system 214 and the client device 204 are the same device.
- a user can install a desktop search application on the client device 204 .
- the client device 204 will generally include a random access memory (RAM) 206 and a processor 208 .
- RAM random access memory
- a user 202 submits a query 210 , e.g., a search query, to a search engine 230 within a search system 214 .
- a query 210 e.g., a search query
- the query 210 is transmitted through a network to the search system 214 .
- the search system 214 can be implemented as, for example, computer programs running on one or more computers in one or more locations that are coupled to each other through a network.
- the search system 214 includes an index database 222 and a search engine 230 .
- the search system 214 responds to the query 210 by generating search results 228 , which are transmitted through the network to the client device 204 in a form that can be presented to the user 202 (e.g., as a search results web page to be displayed in a web browser running on the client device 204 ).
- the search engine 230 identifies documents that match the query 210 .
- the search engine 230 will generally include software that implements an indexing engine 220 that is configured to index documents, e.g., web pages, images, multimedia content, or news articles on the Internet, found in a corpus, e.g., a collection or repository of content, an index database 222 that stores the index information, and a ranking engine 252 (or other software) to rank the documents that match the query 210 .
- the indexing and ranking of the documents can be performed, for example, using conventional techniques.
- the search engine 230 transmits the search results 228 through the network to the client device 204 for presentation to the user 202 .
- the search system further 214 includes a refinement engine 260 which generates query refinements.
- the search 230 engine can provide the query refinements to the client device 204 along with the search results 228 .
- FIG. 3 is a block diagram of an example refinement engine, e.g., an example of refinement engine 260 of FIG. 2 .
- the refinement engine generates query refinements that can be alternatives to the query 210 .
- the refinement engine is included in a search system, e.g., in the search system 214 of FIG. 2 .
- the refinement engine is external to a search system, and provides query refinements to the search system.
- the refinement server includes a data processing engine 310 , an extraction engine 320 , a query generation engine 330 , a calculation engine 340 , an identification engine 350 , and a filter engine 360 .
- the engines in FIG. 3 logically represent executing software components or modules. These components can be combined or subdivided in ways other than those shown in FIG. 3 and can be distributed on multiple data processing apparatus.
- the data processing engine 310 obtains and sends the query 210 to the extraction engine 320 .
- the extraction engine 320 identifies one or more segments in the query 210 by dividing the query 210 into one or more n-grams.
- An n-gram is a sequence of n consecutive tokens, e.g., words or characters.
- An n-gram has an order, which is the number of tokens in the n-gram.
- a 1-gram or unigram
- a 2-gram or bi-gram
- a 2-gram can be the term “new york”, where the tokens are words.
- a 3-gram can be the term “new york times”.
- Each n-gram has an associated probability estimate that is calculated as a function of n-gram relative frequency in training data.
- training data include dictionaries, web pages, search query logs, blogs, and news articles.
- a probability can be assigned to the string W 1 L as:
- ⁇ w 1 i - 1 ) ⁇ ⁇ i 1 L ⁇ P ⁇ ⁇ ( w i ⁇
- the strings and associated probabilities can be stored in a language model.
- the extraction engine 320 can use the language model to identify the one or more n-grams. As an example, the extraction engine 320 can divide a query “new york times square” into two n-grams, i.e., two 2-grams, “new york” and “times square”, based on probabilities of the n-grams each occurring as a term in training data.
- the extraction engine 320 sends information identifying the segments, e.g., the n-grams, to the data processing engine 310 .
- the data processing engine 310 determines for each identified n-gram a concept (or thing) represented by the n-gram, e.g., using conventional techniques such as identifying a meaning of the n-gram using a dictionary.
- the data processing engine 310 further compares the one or more concepts represented by the n-grams and determines whether the one or more n-grams represent the same concept.
- the data processing engine 310 sends each of the n-grams that represents a distinct concept to the query generation engine 330 and the query generation engine 330 generates query refinements for each of the n-grams that represents a distinct concept as if it were a separate query.
- the data processing engine 310 only sends the query to the query generation engine 330 when the one or more n-grams represent a same concept.
- a query “new york city NYC” can be divided into the n-grams “new york city” and “NYC”, which each represent the same concept, i.e., the city New York City.
- the extraction engine 320 may not segment a query, i.e., may identify only one n-gram.
- the query may be a lexical item, i.e., a word or phrase that conveys a single meaning.
- a query consisting of the lexical item “new york city” can be determined to be a single n-gram.
- the extraction engine 320 did not divide the query into multiple n-grams, the query can be considered as representing only one concept.
- a query “cheap new york city restaurants” can be divided into the three n-grams “cheap”, “new york city”, and “restaurants”, each of which represents a different concept.
- the query generation engine 330 receives the query and generates one or more candidate refinement queries.
- the query generation engine 330 can use one or more techniques, e.g., in parallel, to generate the one or more candidate refinement queries. Some possible techniques are described below.
- the query generation engine 330 obtains, e.g., from a service external to the refinement engine, a data set including pairs of terms that represent similar queries.
- the pairs of terms can be identified, for example, from training data by determining pairs of training terms that occur in the same context in the training data.
- Terms that occur in the same context can be, for example, terms that share similar left contexts and right contexts.
- the left context of a term is an n-gram that immediately precedes the term in training data.
- the right context of the term is an n-gram that immediately follows the term in training data.
- the query generation engine 330 can select one or more pairs of terms from the dataset of pairs of terms such that one of the terms in the pair is the search query.
- the other term in each of the pairs is identified as being a candidate refinement query.
- Stop words are words which are filtered out during processing of natural language data, e.g., commonly used words that may not be considered important to a search query. Examples of stop words include conjunctions (e.g., “and”, “or”) and articles (e.g., “a”, “an”, “the”). The other words in the term can be considered to be core words (or core terms), e.g., words that are important to a search query.
- only terms with a left context and a right context that are features of at least one previously-submitted query with a frequency of being submitted beyond a threshold value are identified as being candidate refinement queries. That is, the query generation engine 330 can consult a query log of previously submitted queries to determine whether each selected term shares a left and right context with a query in the query log that has been submitted beyond a threshold value.
- the previously submitted queries in the query log can be anonymized, e.g., using conventional anonymization techniques, so that a particular query in the query log cannot be associated with any user or user-identifying information.
- the query generation engine 330 sends the search query and the one or more candidate refinement queries to the extraction engine 320 .
- the extraction engine 320 extracts, e.g., using conventional techniques, features from training data for each of the search query and the candidate refinement queries, respectively. Examples of features include a right context, a left context, and edits of n-grams, in training data, that correspond to the search query and candidate refinement queries.
- the extracted features can be used to generate a feature vector for the search query and a feature vector for each of the one or more candidate refinement queries.
- the data processing engine 310 , extraction engine 320 , and the calculation engine 340 can compare the feature vectors to determine a first initial score for each of the candidate refinement queries.
- the first initial score can represent a degree of similarity between the search query and a particular candidate refinement query.
- the first initial score is the value of a dot product of the feature vectors.
- the calculation engine 340 determines the value of a dot product of a first function ⁇ of the feature vector X of the search query, e.g., ⁇ (X), and a second function g of the feature vector Y of a candidate refinement query, e.g., g(Y).
- the dot product can be represented as a mathematical expression in the equation:
- the functions f and g can be square functions.
- candidate refinement queries are identified from session data, e.g., from queries from a particular search session in a query log.
- Each search session is a period of time during which a single user is submitting queries.
- a session is a number of queries submitted by a single user. Search sessions can be measured by a pre-defined period of time, or a predefined period of inactivity.
- the query generation engine 330 can identify, in the session data, a previously-submitted query as being a candidate refinement query when the search query was submitted during a search session following submission of the previously-submitted query. In general, as the time period between the submission of two queries, e.g., during a single search session, decreases, the likelihood that the two queries are related increases.
- only the identified previously-submitted queries that include core terms that are each distinct from the core terms of the search query are identified as being candidate refinement queries. That is, of the identified previously submitted queries, only the queries that do not have any core terms in common with the search query are identified as being candidate refinement queries. In some implementations, only the identified previously-submitted queries that do not include terms shared in common with the search query and are associated with an Inverse Document Frequency (IDF) beyond a threshold value (e.g., an IDF greater than 4.0), are identified as being candidate refinement queries.
- IDF Inverse Document Frequency
- the IDF for a particular term is calculated by dividing a total number of documents in a corpus, e.g., the corpus of documents indexed by search engine or another corpus of documents accessible to query generation engine 330 , by the number of documents in the corpus containing the term and taking the logarithm of the quotient.
- a second initial score that represents a degree of correlation between the search query and a particular candidate refinement query can be calculated.
- the second initial score can be used as an input to calculate a total score for the particular candidate refinement query.
- the initial score is referred to as a second initial score because the various techniques performed may be performed together and may identify one or more of the same candidate refinement queries. Each technique can generate an independent, initial score for a given candidate refinement query.
- the second initial score can be a correlation value that is expressed by a ratio of the probability of the candidate refinement query R occurring in the search session following the search query Q, P(R
- the correlation value is used to indicate, i.e., is proportional to, the correlation between the candidate refinement query and the search query.
- the identification engine 350 identifies candidate refinement queries with a frequency of being submitted beyond a threshold submission value and with a correlation value beyond a first threshold correlation value, as being a query refinement. Furthermore, the identification engine 350 identifies candidate refinement queries with a frequency of being submitted that is not beyond the threshold value and with a correlation value beyond a different, second threshold correlation value as being a query refinement.
- the first threshold correlation value can be less than the different, second threshold correlation value.
- the threshold correlation value for a popular query i.e., a query that is submitted more frequently than the threshold submission value
- the threshold correlation value for a non-popular query i.e., a query that is submitted less frequently than the threshold submission value.
- the first threshold value and the second threshold value can be a same value.
- the query generation engine 330 identifies sibling queries to the search query as being candidate refinement queries.
- the sibling queries can be identified from session data.
- Sibling queries are queries that have one or more shared parent queries in common. Each of the sibling queries was submitted during a search session following submission of a shared parent query during the search session.
- a sibling query is identified as being a candidate refinement query only when the search query is textually distinct from the candidate refinement query and all the substrings of the candidate refinement query. In other words, superstrings of the search query, e.g., strings that include the search query as a substring, are not identified as being candidate refinement queries.
- a third initial score for each of the candidate refinement queries can be calculated based on a strength of relationship between a child query, e.g., the search query, and its sibling query, e.g., a candidate refinement query.
- the strength of the relationship between a child query and its sibling query can be measured from the strength of relationship each query has with the common parents shared between the two queries.
- the strength of the relationship between a parent query and a child query is derived from the number of times users submitted the parent query and then submitted the child query during a session, e.g., as determined from session data.
- the strength of relationship between a parent query and a child query is weighted by a weight that is inversely proportional to the number of child queries that share the parent query, inversely proportional to the number of parent queries the child query has, or both.
- the query generation engine 330 generates candidate query refinements by identifying, in predetermined data representing parent-child hierarchies, a parent query of a previously-submitted query that corresponds to the search query.
- a previously-submitted query can be determined to correspond to the search query if, for example, the edit distance between the previously-submitted query and the search query is less than a specified threshold value.
- the query generation engine 330 identifies one or more other child queries of the parent query, i.e., a sibling query of the previously submitted query corresponding to the search query, is identified as being a candidate query refinement.
- a fourth initial score for the candidate query refinement can be adjusted, e.g., increased where a higher score indicates an increased quality of the candidate query refinement.
- the initial scores of each candidate refinement query can be combined to produce a combined score for the candidate refinement query.
- the combination can include weights for each of the initial scores.
- the weights can represent confidence in the initial scores (and their respective techniques for generating the candidate refinement query and initial scores).
- a weight e.g., alpha, beta, delta
- the identification engine 350 can validate the candidate query refinements generated from the various techniques described above.
- the identification engine 350 determines categories in which the search query belongs.
- the identification engine 350 also determines categories in which the candidate query refinements belong.
- the identification engine 350 determines only a predetermined number of top categories (e.g., the top ten categories based on a number of occurrences in training data).
- the categories are determined from parsing training data to determine IS-A relations. For example, a term A in the training data can be said to belong to a category B if the phrase “A is a B” would be considered correct by a speaker of the language. For instance, the terms “apple” and “orange” can both belong to a “fruit” category.
- the IS-A relations can be derived from the training data, for example, by identifying the occurrence of the Hearst patterns “B such as A”, “such B as A . . . ”, “A . . . or other B”, “A . . . and other B”, “B including A”, and “B, especially A . . . ” in the training data.
- a term A can then be identified as belonging to a category B based on a frequency of occurrence of the term A in the same Hearst pattern as term B in the training data.
- the identification engine 350 compares the categories of the search query to the categories of the candidate refinement query. As the number of shared categories increases, the combined score for the given candidate refinement query can be adjusted to indicate an improvement in the quality of the given candidate refinement query. As the number of shared categories decreases, the combined score can be adjusted to indicate a decreased quality.
- a generic category can be identified by determining a number of previously submitted queries that belong in a given category. If the number of previously submitted queries that belong to the given category is greater than a threshold number, indicating that the category is likely to be broad, then the given category is identified as being a generic category.
- the data processing engine 310 ranks, i.e., places in an order, the candidate query refinements according to their respective combined scores.
- the data processing engine 310 can then identify one or more of the candidate query refinements as query refinements, i.e., query suggestions, for the search query based on the ranking. For example, each candidate query refinement having a score above a particular threshold value can be selected. Alternatively, the data processing engine 310 can select a specified number of highest-ranked candidate query refinements.
- the selected query refinements can be transmitted for presentation to a user, e.g., as query refinements for the received search query.
- Each query suggestion can be presented as a selectable link that, when activated, obtains search results for a query including the query refinement.
- the group of candidate query refinements selected according to their combined scores can be further refined, e.g., filtered using various techniques, by the filter engine 360 .
- queries are identified as being parent-like.
- only other parent-like queries are identified as being query refinements to the search query.
- Identifying a query as being parent-like includes generating a modified query from the query.
- the modified query semantically represents a grouping that is related to a lexical item that is represented by the query.
- the modified query can be generated by appending a singular or plural form of the search query to text that indicates a grouping, e.g., “list of”, “types of”, “series of”, “index of”, “listing of”, “classifications of”, “categories of”, “genres of”, “varieties of”, and “ways of”.
- the query is identified as being parent-like when the modified query has a frequency of being submitted that is beyond a threshold value.
- a query “tennis player” may be identified as being parent-like, as the modified query “list of tennis players” may have a high frequency of being submitted.
- a query “Roger Federer” would not be identified as being parent-like, as the modified queries “list of Roger Federer” and “list of Roger Federers” would not have a high frequency of being submitted.
- the system can filter out queries that are pornographic (e.g., contain pornographic text or will lead to pornographic results), or that contain offensive or hateful speech.
- the list of phrases to filter can be pre-defined.
- duplicate queries can be excluded from the query refinements that are provided.
- Duplicate queries can be identified from a syntactical analysis of the queries. For example, if the two queries have an edit distance that satisfies, e.g., is below, a threshold, then the two queries can be determined to be duplicates.
- FIG. 4 is a flow chart showing an example process 400 for generating query refinements.
- the process 400 includes dividing 410 a search query into one or more n-grams.
- the process 400 also includes determining 420 that each of the one or more n-grams represents the same concept.
- the process 400 also includes, in response to the determination, performing steps 430 , 440 , 450 , 460 , and 470 .
- the process 400 includes selecting 430 one or more candidate refinement queries.
- the process 400 also includes determining 440 one or more categories for the search query.
- the process 400 further includes determining 450 one or more categories for each of the candidate refinement queries.
- the process further includes determining 460 a respective first score for each of the candidate refinement queries, wherein the first score for a particular candidate refinement query is adjusted based on a number of categories shared between the particular candidate refinement query and the search query.
- the process further includes identifying 470 as query refinements for the search query one or more of the candidate refinement queries based on the first scores
- Embodiments of the subject matter and the functional operations described in this specification can be implemented in digital electronic circuitry, or in computer software, firmware, or hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them.
- Embodiments of the subject matter described in this specification can be implemented as one or more computer programs, i.e., one or more modules of computer program instructions encoded on a computer storage medium for execution by, or to control the operation of, data processing apparatus.
- the program instructions can be encoded on a propagated signal that is an artificially generated signal, e.g., a machine-generated electrical, optical, or electromagnetic signal, that is generated to encode information for transmission to suitable receiver apparatus for execution by a data processing apparatus.
- the computer storage medium can be a machine-readable storage device, a machine-readable storage substrate, a random or serial access memory device, or a combination of one or more of them.
- data processing apparatus encompasses all kinds of apparatus, devices, and machines for processing data, including by way of example a programmable processor, a computer, or multiple processors or computers.
- the apparatus can include special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit).
- the apparatus can also include, in addition to hardware, code that creates an execution environment for the computer program in question, e.g., code that constitutes processor firmware, a protocol stack, a database management system, an operating system, or a combination of one or more of them.
- a computer program (also known as a program, software, software application, script, or code) can be written in any form of programming language, including compiled or interpreted languages, or declarative or procedural languages, and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, or other unit suitable for use in a computing environment.
- a computer program may, but need not, correspond to a file in a file system.
- a program can be stored in a portion of a file that holds other programs or data (e.g., one or more scripts stored in a markup language document), in a single file dedicated to the program in question, or in multiple coordinated files (e.g., files that store one or more modules, sub-programs, or portions of code).
- a computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network.
- the processes and logic flows described in this specification can be performed by one or more programmable processors executing one or more computer programs to perform functions by operating on input data and generating output.
- the processes and logic flows can also be performed by, and apparatus can also be implemented as, special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit).
- processors suitable for the execution of a computer program include, by way of example, both general and special purpose microprocessors, and any one or more processors of any kind of digital computer.
- a processor will receive instructions and data from a read-only memory or a random access memory or both.
- the essential elements of a computer are a processor for performing or executing instructions and one or more memory devices for storing instructions and data.
- a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks.
- mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks.
- a computer need not have such devices.
- a computer can be embedded in another device, e.g., a mobile telephone, a personal digital assistant (PDA), a mobile audio or video player, a game console, a Global Positioning System (GPS) receiver, or a portable storage device (e.g., a universal serial bus (USB) flash drive), to name just a few.
- PDA personal digital assistant
- GPS Global Positioning System
- USB universal serial bus
- Computer-readable media suitable for storing computer program instructions and data include all forms of non-volatile memory, media and memory devices, including by way of example semiconductor memory devices, e.g., EPROM, EEPROM, and flash memory devices; magnetic disks, e.g., internal hard disks or removable disks; magneto-optical disks; and CD-ROM and DVD-ROM disks.
- semiconductor memory devices e.g., EPROM, EEPROM, and flash memory devices
- magnetic disks e.g., internal hard disks or removable disks
- magneto-optical disks e.g., CD-ROM and DVD-ROM disks.
- the processor and the memory can be supplemented by, or incorporated in, special purpose logic circuitry.
- a computer having a display device, e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor, for displaying information to the user and a keyboard and a pointing device, e.g., a mouse or a trackball, by which the user can provide input to the computer.
- a display device e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor
- keyboard and a pointing device e.g., a mouse or a trackball
- Other kinds of devices can be used to provide for interaction with a user as well; for example, feedback provided to the user can be any form of sensory feedback, e.g., visual feedback, auditory feedback, or tactile feedback; and input from the user can be received in any form, including acoustic, speech, or tactile input.
- a computer can interact with a user by sending documents to and receiving documents from a device that is used by the user; for example, by sending web pages to a
- Embodiments of the subject matter described in this specification can be implemented in a computing system that includes a back-end component, e.g., as a data server, or that includes a middleware component, e.g., an application server, or that includes a front-end component, e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the subject matter described in this specification, or any combination of one or more such back-end, middleware, or front-end components.
- the components of the system can be interconnected by any form or medium of digital data communication, e.g., a communication network. Examples of communication networks include a local area network (“LAN”) and a wide area network (“WAN”), e.g., the Internet.
- LAN local area network
- WAN wide area network
- the computing system can include clients and servers.
- a client and server are generally remote from each other and typically interact through a communication network.
- the relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other.
Abstract
Description
where the approximation is based on a Markov assumption that only the most recent (n−1) tokens are relevant when predicting a next token in the string, and the “^” notation for P indicates that it is an approximation of the probability function.
where n is an integer greater than 1. As an example, the functions f and g can be square functions.
combined_score=αs 1 +βs 2 + . . . +δs j,
where an initial score s is adjusted by a weight (e.g., alpha, beta, delta), and the candidate refinement query has j initial scores. Other combinations are possible. For example, higher order polynomial combinations can be used to produce the combined scores.
Claims (48)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US13/094,794 US8688727B1 (en) | 2010-04-26 | 2011-04-26 | Generating query refinements |
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US32816110P | 2010-04-26 | 2010-04-26 | |
US13/094,794 US8688727B1 (en) | 2010-04-26 | 2011-04-26 | Generating query refinements |
Publications (1)
Publication Number | Publication Date |
---|---|
US8688727B1 true US8688727B1 (en) | 2014-04-01 |
Family
ID=50348990
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US13/094,794 Active 2031-12-17 US8688727B1 (en) | 2010-04-26 | 2011-04-26 | Generating query refinements |
Country Status (1)
Country | Link |
---|---|
US (1) | US8688727B1 (en) |
Cited By (20)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20140358906A1 (en) * | 2013-05-31 | 2014-12-04 | Google Inc. | Query suggestions based on search data |
US20150134781A1 (en) * | 2013-11-13 | 2015-05-14 | Palo Alto Research Center Incorporated | Method and apparatus for pre-fetching remote content based on static and dynamic recommendations |
US20150199699A1 (en) * | 2013-01-04 | 2015-07-16 | PlaceIQ, Inc. | Location-based analytic platform and methods |
US9116952B1 (en) | 2013-05-31 | 2015-08-25 | Google Inc. | Query refinements using search data |
US20150324425A1 (en) * | 2014-05-12 | 2015-11-12 | Google Inc. | Interpreting user queries based on nearby locations |
US20160283546A1 (en) * | 2015-03-26 | 2016-09-29 | International Business Machines Corporation | Query strength indicator |
EP3232336A4 (en) * | 2015-12-01 | 2018-03-21 | Huawei Technologies Co., Ltd. | Method and device for recognizing stop word |
US10051071B2 (en) | 2016-03-04 | 2018-08-14 | Cisco Technology, Inc. | Method and system for collecting historical network information in a content centric network |
US10067948B2 (en) | 2016-03-18 | 2018-09-04 | Cisco Technology, Inc. | Data deduping in content centric networking manifests |
US10091330B2 (en) | 2016-03-23 | 2018-10-02 | Cisco Technology, Inc. | Interest scheduling by an information and data framework in a content centric network |
US10185746B2 (en) | 2014-08-20 | 2019-01-22 | Google Llc | Interpreting user queries based on device orientation |
US10264099B2 (en) | 2016-03-07 | 2019-04-16 | Cisco Technology, Inc. | Method and system for content closures in a content centric network |
US10313227B2 (en) | 2015-09-24 | 2019-06-04 | Cisco Technology, Inc. | System and method for eliminating undetected interest looping in information-centric networks |
US10320760B2 (en) | 2016-04-01 | 2019-06-11 | Cisco Technology, Inc. | Method and system for mutating and caching content in a content centric network |
US20190197131A1 (en) * | 2017-12-27 | 2019-06-27 | Yandex Europe Ag | Method and server for predicting a query-completion suggestion for a partial user-entered query |
US10366621B2 (en) * | 2014-08-26 | 2019-07-30 | Microsoft Technology Licensing, Llc | Generating high-level questions from sentences |
US20190286677A1 (en) * | 2010-01-29 | 2019-09-19 | Ipar, Llc | Systems and Methods for Word Offensiveness Detection and Processing Using Weighted Dictionaries and Normalization |
US10742596B2 (en) | 2016-03-04 | 2020-08-11 | Cisco Technology, Inc. | Method and system for reducing a collision probability of hash-based names using a publisher identifier |
US11276037B2 (en) * | 2016-09-22 | 2022-03-15 | Microsoft Technology Licensing, Llc | Search prioritization interfaces for communication platform users |
US20230141570A1 (en) * | 2021-11-08 | 2023-05-11 | Microsoft Technology Licensing, Llc | Query admission control for online data systems based on response time objectives |
Citations (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20120209858A1 (en) * | 2007-04-24 | 2012-08-16 | Wal-Mart Stores, Inc. | Determining concepts associated with a query |
-
2011
- 2011-04-26 US US13/094,794 patent/US8688727B1/en active Active
Patent Citations (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20120209858A1 (en) * | 2007-04-24 | 2012-08-16 | Wal-Mart Stores, Inc. | Determining concepts associated with a query |
Non-Patent Citations (1)
Title |
---|
Hearst, M.A., "Automatic Acquisition of Hyponyms from Large Text Corpora", Proceedings of the Fourteenth International Conference on Computational Linguistics, Nantes, France, Jul. 1992, pp. 1-8. |
Cited By (34)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20190286677A1 (en) * | 2010-01-29 | 2019-09-19 | Ipar, Llc | Systems and Methods for Word Offensiveness Detection and Processing Using Weighted Dictionaries and Normalization |
US10262330B2 (en) * | 2013-01-04 | 2019-04-16 | PlaceIQ, Inc. | Location-based analytic platform and methods |
US20150199699A1 (en) * | 2013-01-04 | 2015-07-16 | PlaceIQ, Inc. | Location-based analytic platform and methods |
US11514035B1 (en) | 2013-05-31 | 2022-11-29 | Google Llc | Query refinements using search data |
US9336277B2 (en) * | 2013-05-31 | 2016-05-10 | Google Inc. | Query suggestions based on search data |
US9727603B1 (en) | 2013-05-31 | 2017-08-08 | Google Inc. | Query refinements using search data |
US10691680B1 (en) | 2013-05-31 | 2020-06-23 | Google Llc | Query refinements using search data |
US9116952B1 (en) | 2013-05-31 | 2015-08-25 | Google Inc. | Query refinements using search data |
US20140358906A1 (en) * | 2013-05-31 | 2014-12-04 | Google Inc. | Query suggestions based on search data |
US10129365B2 (en) * | 2013-11-13 | 2018-11-13 | Cisco Technology, Inc. | Method and apparatus for pre-fetching remote content based on static and dynamic recommendations |
US20150134781A1 (en) * | 2013-11-13 | 2015-05-14 | Palo Alto Research Center Incorporated | Method and apparatus for pre-fetching remote content based on static and dynamic recommendations |
US20150324425A1 (en) * | 2014-05-12 | 2015-11-12 | Google Inc. | Interpreting user queries based on nearby locations |
US10474671B2 (en) * | 2014-05-12 | 2019-11-12 | Google Llc | Interpreting user queries based on nearby locations |
US10185746B2 (en) | 2014-08-20 | 2019-01-22 | Google Llc | Interpreting user queries based on device orientation |
US10922321B2 (en) | 2014-08-20 | 2021-02-16 | Google Llc | Interpreting user queries based on device orientation |
US10366621B2 (en) * | 2014-08-26 | 2019-07-30 | Microsoft Technology Licensing, Llc | Generating high-level questions from sentences |
US20160283546A1 (en) * | 2015-03-26 | 2016-09-29 | International Business Machines Corporation | Query strength indicator |
US9864775B2 (en) * | 2015-03-26 | 2018-01-09 | International Business Machines Corporation | Query strength indicator |
US10313227B2 (en) | 2015-09-24 | 2019-06-04 | Cisco Technology, Inc. | System and method for eliminating undetected interest looping in information-centric networks |
EP3232336A4 (en) * | 2015-12-01 | 2018-03-21 | Huawei Technologies Co., Ltd. | Method and device for recognizing stop word |
CN108027814B (en) * | 2015-12-01 | 2020-06-16 | 华为技术有限公司 | Stop word recognition method and device |
CN108027814A (en) * | 2015-12-01 | 2018-05-11 | 华为技术有限公司 | Disable word recognition method and device |
US10019492B2 (en) * | 2015-12-01 | 2018-07-10 | Huawei Technologies Co., Ltd. | Stop word identification method and apparatus |
US10742596B2 (en) | 2016-03-04 | 2020-08-11 | Cisco Technology, Inc. | Method and system for reducing a collision probability of hash-based names using a publisher identifier |
US10051071B2 (en) | 2016-03-04 | 2018-08-14 | Cisco Technology, Inc. | Method and system for collecting historical network information in a content centric network |
US10264099B2 (en) | 2016-03-07 | 2019-04-16 | Cisco Technology, Inc. | Method and system for content closures in a content centric network |
US10067948B2 (en) | 2016-03-18 | 2018-09-04 | Cisco Technology, Inc. | Data deduping in content centric networking manifests |
US10091330B2 (en) | 2016-03-23 | 2018-10-02 | Cisco Technology, Inc. | Interest scheduling by an information and data framework in a content centric network |
US10320760B2 (en) | 2016-04-01 | 2019-06-11 | Cisco Technology, Inc. | Method and system for mutating and caching content in a content centric network |
US11276037B2 (en) * | 2016-09-22 | 2022-03-15 | Microsoft Technology Licensing, Llc | Search prioritization interfaces for communication platform users |
US20190197131A1 (en) * | 2017-12-27 | 2019-06-27 | Yandex Europe Ag | Method and server for predicting a query-completion suggestion for a partial user-entered query |
RU2711103C2 (en) * | 2017-12-27 | 2020-01-15 | Общество С Ограниченной Ответственностью "Яндекс" | Method and server for predicting query-completion suggestion for partial user-entered query |
US10846340B2 (en) * | 2017-12-27 | 2020-11-24 | Yandex Europe Ag | Method and server for predicting a query-completion suggestion for a partial user-entered query |
US20230141570A1 (en) * | 2021-11-08 | 2023-05-11 | Microsoft Technology Licensing, Llc | Query admission control for online data systems based on response time objectives |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US8688727B1 (en) | Generating query refinements | |
US11847176B1 (en) | Generating context-based spell corrections of entity names | |
US10997370B2 (en) | Hybrid classifier for assigning natural language processing (NLP) inputs to domains in real-time | |
US8630847B2 (en) | Word probability determination | |
US9740754B2 (en) | Facilitating extraction and discovery of enterprise services | |
US9031970B1 (en) | Query autocompletions | |
US10783156B1 (en) | Scoring candidate answer passages | |
CN107092615B (en) | Query suggestions from documents | |
US8386240B2 (en) | Domain dictionary creation by detection of new topic words using divergence value comparison | |
US9542476B1 (en) | Refining search queries | |
JP5475795B2 (en) | Custom language model | |
US8825571B1 (en) | Multiple correlation measures for measuring query similarity | |
US8346754B2 (en) | Generating succinct titles for web URLs | |
US9336277B2 (en) | Query suggestions based on search data | |
US20170270159A1 (en) | Determining query results in response to natural language queries | |
US9183323B1 (en) | Suggesting alternative query phrases in query results | |
Guy | The characteristics of voice search: Comparing spoken with typed-in mobile web search queries | |
US7996379B1 (en) | Document ranking using word relationships | |
JP5379138B2 (en) | Creating an area dictionary | |
US9830379B2 (en) | Name disambiguation using context terms | |
US20120323948A1 (en) | Dialog-enhanced contextual search query analysis | |
US10180964B1 (en) | Candidate answer passages | |
US9213768B1 (en) | Assumption mechanism for queries | |
US8452795B1 (en) | Generating query suggestions using class-instance relationships | |
US20150317313A1 (en) | Searching locally defined entities |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:DAS, ANWIS;DAS, ABHINANDAN S.;REEL/FRAME:026462/0060Effective date: 20110511 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
CC | Certificate of correction | ||
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044101/0299Effective date: 20170929 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 4TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1551)Year of fee payment: 4 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 8TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1552); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 8 |