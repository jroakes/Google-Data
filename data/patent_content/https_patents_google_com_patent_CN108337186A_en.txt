CN108337186A - Device and method for scalable traffic shaping - Google Patents
Device and method for scalable traffic shaping Download PDFInfo
- Publication number
- CN108337186A CN108337186A CN201711331943.2A CN201711331943A CN108337186A CN 108337186 A CN108337186 A CN 108337186A CN 201711331943 A CN201711331943 A CN 201711331943A CN 108337186 A CN108337186 A CN 108337186A
- Authority
- CN
- China
- Prior art keywords
- grouping
- time
- packet
- network interface
- network
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L47/00—Traffic control in data switching networks
- H04L47/10—Flow control; Congestion control
- H04L47/22—Traffic shaping
- H04L47/225—Determination of shaping rate, e.g. using a moving window
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L47/00—Traffic control in data switching networks
- H04L47/10—Flow control; Congestion control
- H04L47/22—Traffic shaping
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L47/00—Traffic control in data switching networks
- H04L47/10—Flow control; Congestion control
- H04L47/19—Flow control; Congestion control at layers above the network layer
- H04L47/193—Flow control; Congestion control at layers above the network layer at the transport layer, e.g. TCP related
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L47/00—Traffic control in data switching networks
- H04L47/10—Flow control; Congestion control
- H04L47/27—Evaluation or update of window size, e.g. using information derived from acknowledged [ACK] packets
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L47/00—Traffic control in data switching networks
- H04L47/10—Flow control; Congestion control
- H04L47/28—Flow control; Congestion control in relation to timing considerations
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L47/00—Traffic control in data switching networks
- H04L47/50—Queue scheduling
- H04L47/56—Queue scheduling implementing delay-aware scheduling
- H04L47/568—Calendar queues or timing rings
Abstract
This application involves the device and method of scalable traffic shaping.Provide the system and method for executing rate limit using the time index data structure in the network equipment.The transport protocol module of the network equipment can receive packet from remote computing device.Transport protocol module can generate the packet acknowledgement message received by network interface driver.Network interface driver can handle the packet acknowledgement message received, at least to determine the transmission time of packet acknowledgement message based on rate limit strategy.Identifier associated with packet acknowledgement message can be stored in time index data structure by network interface driver.Network interface driver can determine the time for having arrived at and being indexed in time index data structure, and it in response, transmits and is stored in packet acknowledgement message associated with the identifier at the position of the time correlation connection reached in time index data structure.
Description
Technical field
This application involves scalable traffic shapings, more particularly in the receiver with time index data structure
The device and method of scalable traffic shaping are carried out at machine.
Background technology
Traffic shaping (traffic shaping) be it is a kind of using various mechanism come the technology of regulating networks data service,
The various mechanism are used to carry out shaping, speed to being confirmed as more inessential than prioritized traffic stream or more undesirable Business Stream
Rate limitation, pacing (pace), prioritized or delay, or carry out point of Internet resources across the stream of packets that All factors being equal, preference will be give to changes
Cloth.For making the mechanism of traffic shaping include the grader based on strategy to be matched between different queue and movement is grouped, use
In delay, discarding or label grouping the specific shaping algorithm of queue, and for across different queue liberally to distribute into
The dispatching algorithm that row major grade is ranked.Using the traffic shaping system of these mechanism in the expectation for considering maintenance a large number of services classification
It is difficult to when disposing traffic shaping system when the requirement of network performance or in various network host frameworks scalable.
Invention content
According to one side, this disclosure relates to a kind of network equipment.The network equipment includes network interface card, at least one processing
The memory and network interface driver of device, storage transportation protocol module.Transport protocol module, which includes that computer is executable, to be referred to
Enable, the computer executable instructions cause when executed by the processor processor from remote computing device receive packet and
Generate packet acknowledgement message.Network interface driver includes computer executable instructions, the computer executable instructions by
Reason device makes processor receive the packet acknowledgement message from transport protocol module when executing, and is based on being grouped with received data
Associated at least one associated rate limit strategy determines transmission time to be directed to packet acknowledgement message.Network interface drives
Device further comprises executable instruction, which when executed deposits identifier associated with packet acknowledgement message
Storage is in the associated time index data structure of transmission time determined for packet acknowledgement message.Network interface driver into
One step includes executable instruction, which determines to have arrived at and index in time index data structure when executed
Time and pass through network interface card transmission and the position with the time correlation connection reached in the time index data structure
The associated packet acknowledgement message of identifier of storage.
According to another aspect, this disclosure relates to a kind of method.This method is included at the transport protocol module of the network equipment
Packet is received from remote computing device, and packet acknowledgement message is generated by transport protocol module.This method further includes by net
The network interface driver of network equipment receives packet acknowledgement message, and based on it is associated with received data grouping at least
One rate limit strategy determines transmission time to be directed to packet acknowledgement message.This method further comprises：For to be sent
Packet acknowledgement message is stored in time index in time index data structure, by identifier associated with packet acknowledgement message
In data structure at the position associated with the transmission time determined for the packet acknowledgement message.This method is further wrapped
It includes：The time for having arrived at and being indexed in time index data structure is determined by network interface driver, and is connect by network
Mouthful card transmission be stored in it is associated with the identifier at the position of the time correlation reached in time index data structure
Packet acknowledgement message.
Description of the drawings
When in conjunction with the following drawings, above-mentioned and related purpose, feature and the advantage of the disclosure will refer to described in detail below
It is more fully understood, in the accompanying drawings：
Fig. 1 is the block diagram of the network environment with the network equipment according to some embodiments；
Fig. 2A is the block diagram of example virtual machine environment；
Fig. 2 B are the block diagrams of example container environment；
Fig. 3 is the flow chart for the operation for showing the network equipment according to some embodiments；
Fig. 4 A to Fig. 4 C are the block diagrams for the operation for showing the network equipment according to some embodiments；
Fig. 5 is the flow chart for the operation for showing the network equipment according to some embodiments；
Fig. 6 A-6B are the exemplary block diagrams for the operation for indicating the network equipment according to some embodiments；
Fig. 7 A-7C are the exemplary block diagrams for the operation for indicating the network equipment according to some embodiments；
Fig. 8 is the flow chart for the operation for showing the network equipment according to some embodiments；
Fig. 9 is the flow chart for the operation for showing the network equipment according to some embodiments；
And
Figure 10 is the block diagram of exemplary computing system.
Specific embodiment
It, should be by traffic shaping system while the more advanced congestion control in managing such as transmission control protocol (TCP)
System is used designed for efficient memory and host-processor ability consumes.For example, being postponed to grouping, pacing or speed
Higher Internet resources and host may be implemented to avoid the traffic shaping system of burst or unnecessary transmission delay in rate limitation
The utilization rate of process resource.Packetization delay mechanism can reduce the demand to large memories buffering area.For example, when grouping is delayed by
When, feedback mechanism can apply " back pressure (back to sending module (for example, component software of equipment or such as software application)
Pressure) " --- feedback is sent, so that sending module reduces the rate that it sends grouping.In no packetization delay
In the case of mechanism, application will continue to generate grouping, and be grouped and may be buffered or be abandoned, to spend additional memory
Grouping is lined up or regenerated with host-processor ability.
It proposes and carries out that scalable traffic shaping is related to be set with usage time index data structure and delay completion mechanism
Standby and method.In some embodiments, the network interface driver of the network equipment is configured as receiving network from multiple applications
Grouping at the TCP layer of host.The grouping received is originated from the application executed on the computing device, for example, by computing device
The application executed in the one or more virtual machines or containerization performing environment of trustship.Network interface driver can prevent from applying
Additional grouping is sent for transmission, confirms that the succeeded message of transmission of the grouping that had previously forwarded is until application receives
Only.For example, before additional data packet is forwarded to network interface driver, grouping is transmitted for network interface driver
Message such as is transmitted at the software application or Client OS to be received for being grouped and being transmitted message.As described in this article
, in some embodiments, network interface driver processing receive grouping with based at least one rate limit strategy come
Determine the transmission time being each grouped.For example, rate limit strategy may include rate pacing strategy or targeted rate limitation.It is attached
Add ground or as an alternative, rate limit strategy may include specific policy associated with specific cluster classification or specific cluster class
Other aggregate rate.In some embodiments, network interface driver, will be with respective packets based on received grouping is handled
Associated identifier is stored in associated with for transmission time determined by respective packets in time index data structure
Position at.Time index data structure may include single time-based queue --- such as timing wheel or calendar queue number
According to structure --- with receive with from multiple queues or the associated identifier of the grouping of TCP sockets (socket).Grouping mark
Knowing symbol can be inserted into and be extracted based on identified transmission time.In some embodiments, network interface driver or
Network interface card can determine the time for having arrived at and being indexed in single time index queue, and in response, transmission is deposited
With the identifier position of the time correlation connection that is reached at associated grouping of the storage in time index data structure.Example
Such as, network interface driver or network interface card can determine the time t reached0, and as a result, network interface
Driver and/or network interface card make and specified t0The associated network being grouped by the network equipment of identifier of transmission time
Interface card transmits.In some embodiments, after network interface card transmission grouping, network interface driver can will transmit
Completion notice is transmitted back to the application for the grouping for initiating to have transmitted.
By the host processing power consumption during reducing packet transaction and transmission, single queue shaping can be provided than more teams
The higher CPU efficiency of row system.Single queue orthopedic systems are also based on the transmission strategy of grouping to realize more accurate grouping
Rate limit and schedulability.For example, using single time-based queue or calendar queue, can make full use of by generating
The packet time stamp that the application of grouping creates, to be based on rate limit associated with the grouping, pacing rate, and/or bandwidth
Best packet transmission time is dispatched in the combination of sharing policy.
The network equipment discussed here and method can be by being based on rate policy or scheduling strategy to each grouping added-time
Between stamp realize the scalable traffic shaping being often grouped.In some embodiments, grouping is at least initially by initiating the grouping
Application add timestamp.By in Yuan Chu, --- application i.e. by generating grouping --- adds timestamp the grouping, can mitigate
The demand of pre-filtering grouping.Need that pre-filtered device and method can introduce expensive processing requirement or specific hardware is matched
It sets, such as requires multiple queues according to one or more rate limit strategies to be added timestamp to grouping.Therefore, when incorporating source
Between stab the embodiment of addition and can reduce processing time and resource used in these device and method.
The network equipment and method can according to timestamp by will packet identifier associated with grouping in the single time
It is formed into columns in index data structure to further realize the scalable traffic shaping of every grouping.With this method with single time rope
The embodiment for the data structure drawn can support number with ten thousand when being realized with specific transmission rule with minimum processing expense
The stream of packets of meter.For example, efficient single time index data structure can be configured as avoid by timestamp with it is current when
Between --- such as " present " --- compare earlier or in its past packet queue because these groupings should be passed immediately
It send.Additionally or as an alternative, efficient single time index data structure can be configured as including maximum time range,
Grouping should not be dispatched except the maximum time range.Efficient single time index data configured with maximum time range
The alternative embodiment of structure may further include rate limit strategy, the specified minimum supporting rate of the rate limit strategy
(for example, maximum support time between grouping) or the maximum holding load in terms of the grouping number of transmission.Additionally or replace
The embodiment of selection of land, efficient single time index data structure may include limitation network stack (networking
Stack) the frequency that can be interacted with time index data structure, and thus define the granularity of time index data structure.
In some embodiments, the network equipment and method are further by when the transmission identified in timestamp ends
Between past tense make grouping leave queue as quickly as possible and deliver to grouping source to complete message to enable to transmission new
It is grouped and realizes and be often grouped scalable traffic shaping.In conventional system, it is grouped from transmission queue --- for example advanced elder generation
Go out (FIFO) queue --- it handles in order, and returns complete in order.In some embodiments of the disclosure, network is set
Standby and method can be by removing some packets for postponing transmission (the case where not abandoning grouping from transmission queue
Under) and so that completing message disorderly returns.Match using this " unordered to complete (out of order completion) "
In the case of setting, because being transmitted to network interface driver until receiving using more packets will do not sent
Until the completion message of packet, it is possible to which mandatory use reduces its transmission rate.This configuration can be by preventing from counting
Through reservation according to grouping and is delayed by the queue and avoids hol blocking (head of line blocking).Moreover, one
In a little embodiments, it is somebody's turn to do " unordered " completion configuration and can be applied to apply --- it is for example opened for corresponding flow or stream a large amount of
The individual flow (or stream or class) of the application of connection --- interior packet so that each flow can selectively slow down or
Accelerate.
In addition, in some embodiments, " unordered " completion configuration can be in the case of no hol blocking to transmission
Module or application apply " back pressure ", how to be put into grouping but regardless of there are how many main transmission queues or in each queue, only
Completing message can disorderly return.In some embodiments, have " unordered " the traffic shaping mechanism for completing configuration can
To be realized with particular network/hardware configuration (for example, certain number of main transmission queue and particular queue allocation rule).Example
Such as, in order to make thousands of a flow/flow shapings of business, single queue or a small amount of queue (for example, 16-32 queue) can only be used
To realize traffic shaping mechanism.When being realized in the system with a small amount of queue, traffic shaping mechanism can return to each point
Group is placed into correct queue and Packet Service still " randomly " is dispersed in " nothing in queue based on predetermined queue assignment rule
Sequence " completes message.For example, can be realized in virtual machine for point to being dispersed in from linux system on multiple hardware queues
Group business carries out " unordered " finishing service orthopedic systems of shaping, and without modification network/hardware configuration (for example, linux system
Queue assignment rule or hardware queue number).In some embodiments, traffic shaping system can be by applying or using
Family hides traffic shaping layer, traffic classification rule and strategy to provide such network/hardware compatibility.
The network equipment and the configuration of associated network interface driver may be implemented as having single scheduler and single
The data structure of time index, or with the multiple schedulers and multiple times for using identical or different traffic shaping strategy
The data structure of index.
In the above-described embodiment, it is grouped source --- such as (relative in virtual machine on the true OS of the network equipment
On client computer OS) operation software application or the TCP storehouses in the client computer OS by management program management upper layer or soft
Part application --- the traffic shaping strategy or algorithm for requiring no knowledge about in network interface driver or being realized on network interface card.
Therefore, the cost for realizing network interface driver and Client OS in a virtual machine environment can be reduced.Moreover, grouping
Source also requires no knowledge about other configurations parameter, such as packet classification rule and other rate limit strategies.Therefore, traffic shaping can
To be executed in such a way that the method than detailed algorithm as application or user configuration and strategy is more reliable.
Fig. 1 is the block diagram of the example network environment 100 with the network equipment 110.Generally, illustrated network environment
100 include the network 700 of interconnection network nodes 750.Network node 750 as data source, data destination (or data sink) and
Network 700 is participated in from source by intermediate node of the network 700 towards destination propagation data.Network 700 includes having to lead to
The network equipment 110 of each other links 600 for participating in network node 750.Referring more particularly to Fig. 1, network 700 is to promote ginseng
The network of interaction between person's equipment.Illustrated examples network 700 is internet；However, in other embodiments, network
700 can be another network, the local network in such as data center, network structure or any other local area or wide area network.Net
Network 700 can be made of the sub-network or autonomous networks of multiple connections.Network 700 can be LAN (LAN) --- it is such as public
Take charge of Intranet, Metropolitan Area Network (MAN) (MAN), wide area network (WAN), the internet or peer-to-peer network of such as internet --- such as point
To point WiFi peer-to-peer networks.The data network and/or communication network of any types and/or form may be used to network 700.It
It can be the combination of common network, dedicated network or common network and dedicated network.In general, network 700 in calculating for setting
Information is conveyed between standby --- such as network node 750 ---, and the network equipment 110 of data service orthopedic systems is according to it
It configures to promote the communication.
As shown in Figure 1, the network equipment 110 is the one or more application that trustship executes on real system (OS)
The server of 150a-150c (typically applying 150).As discussed further below, in other embodiments, the network equipment
Can be that trustship is carrying out using 150 virtual machine or the server of container.The network equipment 110 includes network interface driver
120, memory 115, network interface card 140, true OS 220 and apply 150.Network interface driver 120 may include scheduling
Device 125, timing wheel data structure 130, and include transponder 135 (shown in dotted line) in some embodiments.At some
In embodiment, the network equipment 110 has configuration similar with computing system 1010 shown in Fig. 10.For example, memory 115 can
With with the configuration similar with memory shown in Figure 10 1070, and network interface card 140 can have and such as Figure 10 institutes
The similar configuration of the network interface card 1022 or network interface controller 1020 that show.Calculating is more fully described referring to Figure 10
System 1010.Element shown in illustrated computing system 1010 does not need to all be present in the illustrated nets of Fig. 1 in Figure 10
In some embodiments of network equipment 110.
Referring again to Fig. 1, in some embodiments, 110 trustship one or more application 150 of the network equipment (such as answer
With 150a, 150b and 150c).One or more application 150a-150c can be on the real system of the network equipment 110
The software application of operation.As further related to Fig. 2A and 2B discussed, in some embodiments, software application 150a-
One or more of 150c can be the software on the client computer OS operated in by the management program management in virtual machine environment
Using or virtual machine environment client computer OS protocol stack (such as TCP storehouses) upper layer.For example, with reference to figure 2A, application
150a-150c can be the software application 230 run on true OS 220 respectively, on the client computer OS 260 of virtual machine 1
The protocol stack of the client computer OS 260 of operation, the software application 265 managed by management program 250 or the virtual machine 1 in Fig. 2A
261 upper layer.Management program 250 and relative virtual machine environment is more fully described referring to Fig. 2A.
Fig. 1 is referred back to, in some embodiments, the network equipment 110 includes memory 115.In some embodiments
In, the storage of memory 115 is transmitted via the grouping that true OS 220 is received from application 150 by network interface card 140.One
In a little embodiments, memory 115 can store (such as Transmission Control Protocol mould of transport protocol module 145 to execute on a processor
The TCP layer of block or network stack) computer executable instructions.In some other embodiments, memory 115 can store
The computer executable instructions of network interface driver 120.Additionally or alternatively, memory 115 can be stored by scheduler
125 rate-limiting algorithm, rate limit strategy or the computer executable instructions used.In some embodiments, memory
115 can store with flow transmitted via the network equipment 110 and/or the grouping that has been scheduled for future transmission or
The associated statistics of classification or measurement.For example, memory 115 can store statistic or measurement, such as application rate is being wanted to limit
The previous and upcoming transmission time and historic transmission rate of grouping in every class grouping of system.Statistical data can also wrap
Include the number of the grouping currently in timing wheel associated with each classification 130 (being discussed further below).Memory 115
It can store with the operation of network interface driver 120 and use related data and/or instruction.Memory 115 may include：
Such as it is random access memory (RAM), dynamic random access memory (DRAM), static RAM (SRAM), same
It walks dynamic random access memory (SDRAM), ferroelectric RAM (FRAM), read-only memory (ROM), may be programmed only
Read memory (PROM), Erasable Programmable Read Only Memory EPROM (EPROM), electrically erasable programmable read-only memory
(EEPROM), and/or flash memory.In some embodiments, memory 115 stores computer executable instructions, which can
Execute instruction make when being executed by network interface driver 120 network interface driver 120 at least execute it is shown in Fig. 3 hereafter
The process stage 330,340 and 350 further described.
Network interface driver 120 may include the network interface driver software module run on true OS.Such as
The network interface driver of network interface driver 120 can be stored in the computer executable instructions in memory 115
Set, makes function discussed below be achieved when executed by the processor.In some other embodiments, network connects
Mouth driver 120 may be implemented as the logic realized in hardware processor or other integrated circuits, or be embodied as hardware
With the combination of software logic.Network interface driver 120 can be directly (if grasped on the true OS 220 of the network equipment 110
Make), via virtual machine client computer OS (or in some embodiments, passing through management program and client computer OS) (if
Operated in virtual machine environment) or via containerization environment container manager and with one in software application 150a-150c
(for example, application 265 in Fig. 2A) communicates.In some embodiments, network interface driver 120 is included in the network equipment
In the first layer of transmission control protocol (TCP) storehouse of 110 true OS, and it is soft in TCP storehouses upper layer with being included in
Part module or application communication.In one example, network interface driver 120 is included in the transport layer of TCP storehouses, and
It is communicated with the software module or application being included in the application layer of TCP storehouses.In another example, network interface drives
Dynamic device 120 be included in the link layer of TCP storehouses and with the TCP/ that is included in internet/transport layer of TCP storehouses
IP modules are communicated.In some embodiments, which is additionally or alternatively configured as from another network or transmission
Layer protocol module receives grouping, another network or transport layer protocol module such as User Datagram Protocol (UDP) module, can
By datagram protocol (RDP) module, Reliable User Datagram Protocol (RUDP) module or datagram congestion control protocol (DCCP)
Module.In some other embodiments, network interface driver 120 can be included as a part for network interface card 140.
As described above, network interface driver 120 includes scheduler 125.Scheduler --- such as scheduler 125 --- can
To be the set for the computer executable instructions being for example stored in memory 115, make when executed by the processor following
The function of discussion is realized.In some other embodiments, scheduler 125 may be implemented as in hardware processor or other collection
At the logic realized in circuit, or it is embodied as the combination of hardware and software logic.In some embodiments, scheduler 125
It is inserted into timing wheel data structure 130 and the packet identifier that is extracted from timing wheel data structure 130 for managing
Sequence.Additionally or alternatively, known, the existing net that can be used for different operating system kernel may be implemented in scheduler 125
Network dispatching algorithm.In some embodiments, the user-defined dispatching algorithm of customization may be implemented in scheduler 125.For example, adjusting
Degree device 125 may include the rate limit policing algorithm for the timestamp that can calculate the grouping received.In some embodiments
In, weighted-fair-queuing may be implemented to ensure multiple packet traffics in min-max fair allocat scheme in scheduler 125
In in a manner of proportional to its weight share bandwidth.Additionally or alternatively, scheduler 125 can merge timestamp so that
Larger timestamp indicates smaller target transmission speed.In some embodiments, scheduler 125 can be to memory 115
Storage and/or retrieval rate limit dispatching algorithm.Additionally or alternatively, scheduler 125 can be assessed and be driven by network interface
Device 120 receive grouping and packet identifier is stored in timing wheel data structure 130.In some embodiments, it adjusts
Degree device 125 can assess received grouped data to determine that transmission time associated with the grouping received is stabbed.Additionally
Or as an alternative, scheduler 125 can be directed to receive, had by initiate grouping application, virtual machine or container application
The grouping of timestamp determines newer transmission time stamp, and can the newer transmission time stamp be applied to packet identification
Symbol.In some embodiments, scheduler 125 can instruct timing wheel data structure 130 in timing wheel data structure 130
Storage has the packet identifier of transmission time stamp at appropriate time slot.Additionally or alternatively, scheduler 125 can instruct timing
Wheel 130 extracts the packet identifier of storage, such as include the packet identification of transmission time stamp when transmission time has arrived at
Symbol.Scheduler 125 is more fully described below with reference to Fig. 4 A-4C.
It is as mentioned above and as shown in Figure 1, network interface driver 120 include timing wheel data structure 130 (also by
It is defined as timing wheel 130).Timing wheel data structure is a time index queue, can be implemented as cyclic buffer, is used for
Object is lined up by the given time in O (1), and the specific time in O (1) obtains object to be processed.It can be by algorithm
Time complexity be estimated as the basic operation performed by algorithm number function.This estimated value can use the form of O (n)
To indicate.For example, if the value T (n) of run time is limited by the value unrelated with input size, algorithm can have constant
Time (for example, O (n), wherein n=1).As described above, access timing wheel data structure in individual element (for example,
Packet identifier) the constant time (for example, O (1)) is needed, because only that an operation must be performed to position the element.
In some embodiments, timing wheel data structure 130 packet identifier provided by scheduler 125 can be stored in by giving birth to
In the associated time slot of timestamp specified at the application 150 of the grouping, or according to the newer biography determined by scheduler 125
Defeated timestamp stores.Timing wheel data structure 130 is more fully described below with reference to Fig. 4 A-4C.In some other embodiment party
In formula, timing wheel is substituted, the data structure of different time indexs --- such as calendar queue --- is used to dispatch grouping
Transmission.
As is further illustrated in figure 1, network interface driver 140 can also include transponder 135 (shown in dotted line).Such as
The transponder of transponder 135 can be the set for the computer executable instructions being for example stored in memory 115, the computer
Executable instruction makes to realize function discussed below when executed by the processor.In some embodiments, transponder 135 can
To be implemented as the logic realized in hardware processor or other integrated circuits, or it is embodied as the group of hardware and software logic
It closes.Transponder 135 is configured as inquiry timing wheel 130 to determine whether to have arrived at the time indexed in timing wheel 130, and
The transmission time that it is indexed in timing wheel 130 is had reached based on determination to extract appropriate packet identifier from timing wheel 130.
Transponder 135 can be executed instruction to forward the packet to network interface card 140 for transmission.In some embodiments, turn
Hair device 135 can be included in network interface driver 120.In some embodiments, as described further below, turn
The function of hair device 135 or transponder 135 can be integrated into scheduler 125.
Network interface card 140 includes being configured as sending to network node 750 and receiving the hard of communication from network node 750
Part.In some embodiments, network interface card 140 can support high-speed data to receive and transmit as needed, for example, in number
It is likely to be breached according to frame rate in the optical-fibre channel of 100 gigabit per second.In some embodiments, network interface card 140 can
To be configured as supporting the logical of the relatively low velocity for example by copper (or other metals) line, wireless channel or other communication medias
Letter.
It can be additionally or alternatively in network protocol stack described above as the function of occurring in the TCP layer of the network equipment
Transport layer, execute in another network protocol module in network layer or combination of transmitted/network layer.For example, can be in user
Datagram protocol (UDP) module, reliability datagram protocol (RDP) module, Reliable User Datagram Protocol (RUDP) module or number
The function is realized according to reporting in Congestion control protocol (DCCP) module.As used herein, network layer, transport layer or combination
Transmission/network layer will be generally referred to as the packet layer of network protocol stack.
Fig. 2A shows the block diagram for the example server 200a for realizing virtual machine environment.In some embodiments, it services
Device 200a includes hardware 210, the real system run on hardware 210 (OS) 220, management program 250 and has visitor
Two virtual machines of family machine operating system (client computer OS) 260 and 270.Hardware 210 may include network interface card (NIC) 215
And other components.Hardware 210 can have the configuration similar with the configuration of computing system shown in Figure 10 1010.Hardware
210 NIC 215 can have the configuration class with network interface controller 1020 or network interface card 1022 as shown in Figure 10
As configure.In some embodiments, true OS 220 has protocol stack 225 (for example, TCP stack) as shown in Figure 1 or passes
Defeated protocol module 145.In some embodiments, true OS 220 includes the software application run on true OS 220.
In some embodiments, client computer OS 260 and 270 respectively includes protocol stack 261 and 271.Client OS 260 and 270
In each can be with the various applications of trustship, such as software application 265,266,275 and 276.Server 200a can be file clothes
Business device, application server, web server, proxy server, instrument, structure of network instrument, gateway, gateway server, virtualization services
Device, deployment services device, SSL vpn servers or fire wall.
Referring again to Fig. 2A, server 200a executive supervisors 250, the management program 250 is respectively in virtual machine 1 and void
The first client computer OS 260 and the second client computer OS 270 is instantiated and managed on quasi- machine 2.The first visitor configured on virtual machine 1
260 trustship the first software applications 265 of family machine OS and the second software application 266.The the second client computer OS configured on virtual machine 2
260 trustship third software applications 275 and the 4th software application 276.For example, using may include database server, data bins
Library, stock market's transaction software, Internet bank application, content is issued and the table of management system, the video-game of trustship, trustship
Face, e-mail server, travel reservation system, customer relation management application, storage controlling management database and corporate resources
Management system.In some embodiments, the other types of application of client computer OS trustships.Clothes are further described with reference to Fig. 3
Interaction between the component of business device 200a.
Fig. 2 B show to realize the block diagram of the example server 200b of containerization environment.In some embodiments, server
200b includes hardware 210, the real system run on hardware 210 (OS) 220, container manager 240, executes answer respectively
With 241 and 242 two containerization environment (such as container 1 and container 2).Among other components, hardware 210 can also wrap
Include network interface card (NIC) 215.Hardware 210 can have to be similarly configured with computing system 1010 as shown in Figure 10
Configuration.The NIC 215 of hardware 210 can have and network interface controller 1020 shown in Fig. 10 or network interface card 1022
The configuration being similarly configured.In some embodiments, true OS 220 has protocol stack 225 (for example, TCP storehouses) and has
The software application run on true OS 220.Each in container (such as container 1 and container 2) can with the various applications of trustship,
Such as software application 241 and 242.Server 200b can be file server, application server, web server, agency service
Device, instrument, structure of network instrument, gateway, gateway server, virtualized server, deployment services device, SSL vpn servers or fire prevention
Wall.
Referring again to Fig. 2 B, server 200b executes container manager 240, the container manager 240 instantiate respectively with
Manage container 1 and container 2.1 Hosted Software of container applies 241.2 Hosted Software of container applies 242.For example, using may include
Database server, data warehouse program, stock market transaction software, Internet bank application, content publication and management system, trustship
Video-game, the desktop of trustship, e-mail server, travel reservation system, customer relation management application, storage controlling management
Database and ERP System.In some embodiments, container (for example, container 1 or container 2) can with trustship its
The application of its type.The interaction between the component of server 200b is further described with reference to Fig. 3.
Fig. 3 is using the exemplary method 300 of the network equipment execution by the network equipment 110 such as shown in FIG. 1 come to net
The flow chart of network traffic shaping.The TCP layer that method 300 is included in network host receives the grouping (stage from multiple applications
310) and prevent one in applying application send additional packet for transmission until the application receives be transmitted it is logical
Know (stage 320).This method further comprises the grouping that processing receives to determine the transmission time (stage being each grouped
330), and in time index data structure will identifier associated with each respective packets be stored in it is true for the grouping
The associated position of fixed transmission time (stage 340).Method 300 further includes that determination has arrived in time index data structure
The time (stage 350) of middle index, and by network interface driver transmission with time index data structure in be stored in
The associated grouping (stage 360) of identifier of the position of the time correlation connection reached.This method further includes that will be transmitted
Notification transmission, which is responded, uses (stage 370).
Method 300 includes from the grouping (stage 310) from the TCP layer that multiple applications receive network host.In some implementations
In mode, the multiple applications for generating grouping can be application of the trustship in virtualizing machine environment, the application in such as Fig. 2A
265, any of 266,275 or 276.Additionally or alternatively, the grouping received can be by answering in such as Fig. 2A
It is generated with the application executed on the true OS of 230 network host.In some embodiments, as shown in Figure 2 B, using can be with
It is included in the environment of containerization, such as using 241 or 242.Additionally or alternatively, receiving the TCP layer of grouping can be
The upper-layer protocol stack of client computer OS in virtual machine environment.
Method 300 further includes：Prevent an application in applying from sending additional packet for transmission, until the application connects
It receives and is transmitted notice (stage 320).In some embodiments, traffic shaping can partially by from application to
TCP layer forwarding additional data packet come until rate limit indicates that the message completed is transmitted in grouping until receiving real
It is existing.For example, network interface card 140 (being more fully described as shown in fig. 1, and in Fig. 6 A-6B later) can be generated and be returned
The completion notice using 150 is returned to, instruction is grouped by transmission of network.This is transmitted notice and is provided instead to application
Infeed mechanism, and limit and forward additional packet to TCP layer using 150.This mechanism can be with existing TCP functions-such as TCP
Small queue-is in conjunction with being fully utilized, for example, it can effectively limit the significant byte between sender and recipients
Number.
As further shown in figure 3, the grouping received is handled to determine the transmission time (stage 330) being each grouped.
In some embodiments, scheduler 125 can be received based on the rate-limiting algorithm or strategy that are stored in memory 115 to handle
To packet to determine the transmission time that is each grouped.For example, scheduler 125 can handle grouping and according to it is specific
The associated rate-limiting algorithm of packet class or strategy carry out application transport timestamp.In some embodiments, scheduler 125
It is configured as determining the transmission time being each grouped based on rate pacing strategy or targeted rate limitation.For example, scheduler 125
The biography being each grouped can be determined based on the rate pacing strategy of such as packet class rate policy and/or aggregate rate strategy
The defeated time.In some embodiments, scheduler 125 can the rate pacing strategy based on such as weighted fair queuing come
Transmission time is determined to handle multiple packet traffics.Additionally or alternatively, each grouping can have by generating the grouping
It is stabbed using requested transmission time.In some embodiments, scheduler 125 can be received it being grouped at TCP layer
It is preceding and by scheduler 125 handle the grouping before receive the grouping, the grouping include by it is multiple application one of distribute to this
The requested transmission time of grouping.Scheduler 125 can substantially real-time processing grouping be based on exceed at least one speed
Rate restriction strategy and associated with grouping rate-limiting algorithm is called to determine newer transmission time.For example, if connecing
The grouping received is handled and scheduler 125 determines the transmission time of the grouping by more than the rate limit of packet class, then
Scheduler 125 can be stabbed to update the transmission time with the transmission time of adjustment, and the transmission time of the adjustment is stabbed so that grouping energy
It is enough to be transmitted for avoiding exceeding rate limit defined in the rate limit strategy of specific cluster classification in later time.Scheduling
Device 125 can be configured as to be come via the hash table or mapping that identify rate-limiting algorithm associated with the grouping received
Find associated rate-limiting algorithm.
Method 300 further includes：The transmission that the network equipment 110 determines in time index data structure and for respective packets
Storage identifier (stage 340) associated with the grouping at position in the time index data structure of time correlation connection.When
Between index data structure --- such as time index data structure 130 --- can be configured as including multiple positions or time slot with
Store data or event.Time index data structure includes time range, which is that data or event are possibly stored to
The maximum time period in future.For example, time index data structure can be configured as including 50 time slots, wherein each slot table
Show the minimum time granularity between two events.If the time index data structure including 50 time slots is configured such that often
A time slot represents the granularity of 2 microseconds, then time range will be 100 microseconds.It in this illustration, will without any data or event
It is scheduled in after 100 microseconds in the future.Suitable time range and timing wheel granularity (for example, number of time slot) can be based on wanting
The rate limit strategy of implementation configures.For example, in order to carry out the rate of 1 megabit (Mb) per second, suitable time range will
It is 12 milliseconds.The suitable number of time slot of timing wheel 130 or position can be in the ranges of 10-1,000,000 time slot or position
It is interior.The suitable time range of timing wheel 130 can be in the range of several microseconds be by several seconds.In some embodiments, one
Or multiple timing wheels can be realized hierarchically, and each in one or more timing wheels can be configured as with difference
The time slot of number and different timing wheel granularities.In this illustration, each in one or more layering timing wheels can be with
With different time ranges.In some embodiments, packet identifier can correspond to be asked by the application for generating grouping
The timestamp asked or the adjusted transmission time stamp determined by scheduler 125.For example, grouping may include that may specify to be asked
Transmission time identifier, the transmission time of the request is 10 microsecond since current time.Scheduler 125 can be handled point
Group based on rate limit strategy associated with the specific cluster classification to determine whether transmission grouping immediately will be more than speed
Rate limits.Assuming that being not above rate limit, then packet identifier can be inserted into time index data structure by scheduler 125
In 130 at position associated with the following transmission time of 10 microseconds.In some embodiments, it is if all groupings have
Zero timestamp (for example, transmission time is present) or less than present any value, then time index data structure can fill
When first in first out (FIFO) queue.For example, the packet identifier with zero-time stamp will be immediately transmitted.Additionally or alternative
There are all packet identifiers than timestamp now earlier to be inserted into data structure location with the minimum time on ground,
Therefore they can be immediately transmitted.Any grouping mark of timestamp with the time range beyond time index data structure
Know symbol to be inserted into the rearmost position in data structure (for example, indicating the position of maximum time range).
Method 300 further includes that determination has arrived at the time (stage 350) indexed in time index data structure.One
In a little embodiments, network interface driver 120, which can determine, to be had reached and is stored in time index data structure 130
The packet identifier associated specific transmission time.Network interface driver 120 can be using current time come query time rope
Draw data structure 130 to determine whether any grouping to be transmitted.For example, network interface driver 120 can use currently
The cpu clock time (or such as regularly some other reference time value of progressive whole number value) inquires data structure.
Frequent poll can provide the consistency of higher packet scheduling and rate limit strategy, and with use individual timer phase
Than expense can be reduced, significant CPU overhead may be caused due to interruption using individual timer.In some embodiments
In, time index data structure 130 can be realized in dedicated cpu core.Additionally or alternatively, time index data structure
130 can realize in the system based on interruption, and the system based on interruption of being somebody's turn to do can be with the wheel of constant interval execution data structure
It askes to determine block transmission dispatching.For example, can be with the period equal to time span associated with each time slot or its multiple
Time index data structure 130 is periodically polled.In some embodiments, the poll of timing wheel can be by being different from
The logic of scheduler 125 --- all transponders 135 as shown in Figure 1 --- executes.
As further shown in figure 3, the network equipment 110 is transmitted by network interface card 140 and in time index data structure
In with the associated grouping (stage 360) of identifier that is stored at the position of the time correlation connection reached.In some embodiment party
In formula, network interface driver 120 can be based on arrival (or passage) and be stored in the grouping mark in time index data structure 130
Know the transmission time identified in symbol, the grouping being stored in memory 115 is transmitted to network interface card 140.For example, network connects
Mouthful driver 120 can poll time index data structure 130, and can determine the transmission for having reached and being identified in packet identifier
Time.In response, network interface driver 120 can instruct the network equipment that the grouping from memory 115 is made to leave one's post, and
The grouping can be transmitted via network interface card 140.In some embodiments, network interface driver 120 can identify ratio
Transmission time earlier now, and in response, transmission grouping immediately.
Method 300 includes that will be transmitted notification transmission to respond with (stage 370).It is successfully transmitted in network interface card 140
After grouping, completion notice can be transmitted back to the application 150 for initiating the grouping by network interface driver 120.Completion notice is permitted
Apply 150 to send additional packet to network interface driver 120 perhaps.It is more fully described and is transmitted below with reference to Fig. 6 A-6B
Informing mechanism.
The function described above of occurring in the TCP layer of the network equipment can be additionally or alternatively in network protocol stack
Transport layer, execute in another network protocol module in network layer or combination of transmitted/network layer.For example, can be in user
Datagram protocol (UDP) module, reliability datagram protocol (RDP) module, Reliable User Datagram Protocol (RUDP) module or number
The function is realized according to reporting in Congestion control protocol (DCCP) module.
Fig. 4 A-4C are the schedulers and time index number indicated using being executed by the network equipment of such as network equipment 110
To carry out network service the block diagram of the exemplary operations of shaping according to structure.Generally, and as shown in Figure 4 A, the network equipment
110 receive packet from 150 (for example, using 150a, 150b and 150c) of application.The network equipment 110 includes one or more
Socket buffering area 405,410 and 415, the grouping received from application 150 is lined up and be handled.The network equipment 110 is also
Including：For storing instruction with one or more memory devices 115 of data, it is stored in memory 115 for basis
Rate-limiting algorithm or strategy handle the scheduler of grouping.The network equipment 110 further includes time index data structure 130 ---
Also referred to as timing wheel 130 --- to store the packet identifier according to the transmission time of packet identifier.The network equipment 110
Further include that one or more network interface cards 140 are grouped with transmitting.
With reference to figure 4A and Fig. 3, the network equipment 110 is at its TCP layer from multiple applications 150 (for example, using 150a, 150b
Or 150c) receive grouping.As shown in Figure 4 A, the TCP layer of the network equipment 110 includes three socket buffering area (405,410 and
415), each to apply one.For illustrative purposes, it is assumed that the grouping for carrying out self-application 150a is queued and in socket buffering area
It is handled in 405, the grouping for carrying out self-application 150b is queued and is handled in socket buffering area 410, and carrys out self-application
The grouping of 150c is queued and is handled in socket buffering area 415.In some embodiments, the network equipment 110 can be with
One or more socket buffering areas with grouping of the processing from multiple applications.The network equipment 110 can be configured as from
The combination reception of virtual machine environment, container performing environment or real system, virtual machine and/or container performing environment comes from
The grouping of the application executed on the real system of the network equipment 110.
As shown in Figure 4 A, come the grouping of self-application 150a by socket buffering area 405 with using 150a it is transmitted according to
Secondary sequence receives.For example, grouping A1 is the initial packet transmitted from application 150a or the first grouping, and start by scheduler
125 processing.Grouping A2, A3, A4 and A5 hold queue in socket buffering area 405.Similarly, it generates and is grouped using 150b
And transmit the packet to socket buffering area 410.For example, grouping B1, B2, B3, B4 and B5 are indicated by application 150b transmission point
The sequence (for example, B1 is the first grouping) successively of group, and it is maintained in socket buffering area 410 and is lined up with by scheduler
125 processing.Similarly, grouping C1, C2, C3, C4 and C5 indicates the sequence successively by application 150c transmission groupings (for example, C1 is
First grouping), and it is maintained in socket buffering area 415 and is lined up with by scheduler handle.In some embodiments, and
And discussed in more detail about Fig. 6 A-6B, it can be prevented from sending the additional packet being used for transmission using 150, until the application
It receives and is transmitted notice (as shown in the stage 320 of Fig. 3).
As further shown in the stage 330 of Fig. 4 A and Fig. 3, the grouping that the processing of scheduler 125 is lined up is to determine each grouping
Transmission time.Scheduler 125 can in sequential order, random sequence or some other predetermined orders come from turn to handle
The grouping of one or more socket buffering areas.Scheduler 125 can be by identifying rate-limiting algorithm associated with grouping
Or strategy and to grouping distribution is initial or newer transmission time determines the transmission time of the grouping each received.Scheduler
125 can be from 115 retrieval rate limit algorithm of memory or strategy to determine the initial or newer of the grouping each received
Transmission time.The grouping of the reception device 125 that can be scheduled is identified to belong to specific cluster classification.The grouping of particular category may need
Want specific rate-limiting algorithm or strategy associated with packet class.Scheduler 125 can utilize specific rate limit
Algorithm or strategy determine initial or newer transmission time that each of category is grouped.In some embodiments, it dispatches
Device 125 can be assessed using 150 requested grouping transmission times, and determine whether requested transmission time is more than and divides
The associated rate-limiting algorithm of group classification or strategy are (for example, if biography in view of other groupings transmitted recently in the category
Defeated history or the grouping for being scheduled for future transmission can lead to the packet class mistake in the transmission of requested time
High transmission rate).Scheduler 125 can handle grouping and determine and violate and be somebody's turn to do using 150 requested transmission times
The associated rate limit of packet class or strategy.If rate limit or strategy are exceeded or violate in other ways, adjust
Degree device 125 can determine the newer transmission time for being no more than or not violating the rate limit being each grouped or strategy.Scheduler
125 can determine that the requested or newer transmission time of institute is current time, and can execute instruction will be grouped immediately
Network interface card 140 is transmitted to for transmission.
As shown in Figure 4 A, scheduler 125 in time index data structure (for example, timing wheel) 130 with for grouping
Identifier (stage 340 of Fig. 3) associated with respective packets is stored at the associated position of determining transmission time.Timing wheel
130 can be data structure or the queue of time index, can be deposited based on the identified transmission time of associated packet
Storage and extraction packet identifier.In some embodiments, each time slot storage single data element or thing in timing wheel 130
Part (for example, packet identifier associated with grouping).In some embodiments, each time slot can store multiple data elements
Element or event.Timing wheel 130 may include being pre-configured time slot or the position of number, and each time slot or position can represent spy
Fixed incremental time.It in some embodiments, can be based on the change level of data service and congestion at the network equipment 110
To dynamically adjust the number of time slot or position.Timing wheel 130 may include any number of time slot or position, wherein when each
Gap is defined as fully handling necessary to wanting the portfolio of shaping.The summation of all time slots or position in timing wheel 130
Indicate the time range or forward direction queuing time frame (forward queueing time-frame) that timing wheel 130 can be supported.
Suitable time range and timing wheel granularity (for example, number of time slot) can be matched based on the rate limit strategy to be carried out
It sets.For example, to carry out the rate of 1 megabit (Mb) per second, suitable time range will be 12 milliseconds.Timing wheel 130 it is appropriate
The time slot of number or position can be in the range of 10-1,000,000 time slots or position.The suitable time of timing wheel 130
Range can be in the range of 10 microsecond -1 second.For example, as shown in Figure 4 A, timing wheel 130 have 10 time slots, and it is each when
Gap can represent 2 microseconds.Therefore, the time range of example timing wheel 130 shown in Fig. 4 A is 20 microseconds, and timing wheel
130 granularity is 2 microseconds.In some embodiments, timing wheel 130 will have maximum time range, be more than the time range
Packet identifier will not be dispatched.Timing wheel 130 may not be needed to store the packet identifier having than timestamp now earlier,
Because should be immediately transmitted with the grouping than transmission time now earlier.Once the time slot in timing wheel 130 becomes to compare
Now earlier, the element in time slot can leave one's post and be ready to transmit.
For example, as shown in Figure 4 A, it is assumed that grouping A1 be scheduled device 125 handle and moved from socket buffering area 405
It removes.Grouping A1 may remain in memory 115, and scheduler 125 in timing wheel 130 with for grouping A1 determine
Storage identifier associated with grouping A1 is (for example, ID at the associated position of transmission time：A1).Packet identifier ID：A1
Include the transmission time t determined by scheduler 1250.Packet identifier ID：A1 with transmission time t0Corresponding time slot is inserted into
Into timing wheel 130.Timing wheel 130 stores packet identifier ID：A1 has reached until determining for determined by grouping A1
Until transmission time.Network interface driver 120 can utilize current time query time index data structure 130 be with determination
It is no to have any grouping to be transmitted.For example, network interface driver 120 can use cpu clock time (or to indicate current time
Some other values, such as regularly progressive whole number) polling data structure.The determination of network interface driver 120 has arrived at
In packet identifier ID：It the transmission time that is identified in A1 and is grouped A1 and is transmitted.
As shown in Figure 4 B, scheduler 125 handles next grouping from socket buffering area 410 to determine grouping B1's
Transmission time.Scheduler 125 can based on from the associated rate-limiting algorithm of the packet class that receives using 150b or
Strategy come determine grouping B1 should be in time t1It is transmitted.Grouping B1 can be stored in memory 115, be passed until having reached
Defeated time t1.Packet identifier ID：B1 can be stored in timing wheel 130 with for grouping B1 determine transmission time t1Phase
At associated position.As further shown in fig. 4b, timing wheel 130 is corresponding with the transmission time determined by scheduler 125
Packet identifier ID is stored in time slot：A1 and packet identifier ID：B1.For example, by packet identifier ID：A1 is stored in and transmits
Time t0In associated position, and by packet identifier ID：B1 is stored in and transmission time t1In associated position.Point
Group identifier ID：A1 and ID：B1 can be stored in timing wheel 130, until the determination of scheduler 125 has arrived at for grouping mark
The transmission time of the index of each in symbol is known (such as in TimeNow420) until, as described by the stage 350 in Fig. 3.
As shown in Figure 4 C, scheduler 125 continues with the grouping received from application 150.For example, scheduler 125 is
The grouping A2 from socket buffering area 405 is handled, grouping B2 from socket buffering area 410 and slow from socket
Rush the grouping C1 and C2 in area 415.The processing of scheduler 125 grouping A2, B2, C1 and C2 is to determine the transmission time being each grouped.Point
Group A2, B2, C1 and C2 are stored in memory 115, until having arrived at their corresponding transmission time.For example, scheduler
125 can execute the rate-limiting algorithm being stored in memory 115 or strategy to determine biography associated with grouping A2 and B2
The defeated time.The transmission time of grouping A2 can be determined that t4, and be grouped B2 transmission time can be based on respectively with from
It is confirmed as t using the associated rate-limiting algorithm of the grouping of 150a or 150b or strategy5.Scheduler 125 is also handled and is come from
Using the grouping of 150c to determine the transmission time of grouping C1 and C2.Scheduler 125 can determine the grouping for carrying out self-application 150c
It is associated with specific rate-limiting algorithm or strategy, the specific rate-limiting algorithm or the tactful scheduler 125 that enables
Since handle the grouping for carrying out self-application 150c self-application 150a or application 150b twice of rate of grouping.Such as Fig. 4 C institutes
Show, the packet identifier ID associated with grouping C1 and C2 respectively that scheduler 125 will be generated by application 150C：C1 and ID：C2
It is stored in timing wheel 130.Scheduler 125 determines that grouping C1 and C2 has transmission time more faster than grouping A2 and B2.As a result,
By packet identifier ID：C1 and ID：Position associated with identified faster transmission time in the timing wheel 130 that C2 is stored in
It sets.For example, packet identifier ID：C1 and ID：C2 is stored in than packet identifier ID：A2 and ID：B2 is closer to TimeNow420
Position.
As further shown in Fig. 4 C, scheduler 125 continues to be grouped determining transmission with for each in timing wheel 130
Storage identifier associated with grouping A2, B2, C1 and C2 at the position of time correlation connection.Timing wheel 130 includes multiple groupings
Identifier, each packet identifier include the transmission time determined for its associated packet.Scheduler 125 will be periodically polled
Timing wheel 130 is to determine the time having arrived in timing wheel 130.For example, 125 poll timing wheel 130 of scheduler, and determine
Indexed in timing wheel 130 with packet identifier ID：The A1 associated times are (for example, t0) pass by or compared
TimeNow420 earlier.As a result, packet identifier ID:A1 is from (such as dotted line ID of timing wheel 130：Shown in A1) in extraction, and dispatch
Device 125 is executed instruction is forwarded to network interface card 140 for transmission will be grouped A1.Grouping A1 is removed from memory 115
(for example, dotted line grouping A1 is shown as in memory 115 now).In some embodiments, the poll of timing wheel and general
Forwarding a packet to network interface card 140 can be by the logic different from scheduler 125 --- all transponders as shown in Figure 1
135 --- to execute.
Fig. 5 is using the exemplary method 500 executed by the network equipment 110 come the flow chart to network service shaping.Summarize
For, method 500 is since the stage 510, the wherein network equipment --- network interface card shown in such as Fig. 1 and 6A-6B
140 --- it determines associated with the identifier of position being stored in time index data structure with the time correlation that is reached joins
Grouping whether successfully transmitted via network interface card.In the stage 520, if the network equipment 110 determines and is stored in the time
Grouping associated with the identifier at the position of the time correlation connection reached in index data structure has successfully transmitted, then
The network equipment 110 will be transmitted notice and be sent to application, described to apply before forwarding additional data packet to the network equipment
Waiting is received from the network equipment is transmitted notice.
Referring more particularly to Fig. 5, in the stage 510, the network equipment determine be stored in time index data structure with
Whether the associated grouping of identifier at the position of the time correlation connection reached has successfully been transmitted by network interface card.Example
Such as, with reference to figure 6B, the transmission of grouping A1, B1 and C1 is successfully completed in response to network interface card 140, the network equipment passes through transmission
Single message multiple is transmitted notice (for example, M-A1, M-B1 and M-C1) to notify to be transferred successfully grouping using 150.
Based on the notice being transmitted from network interface card 140, determines and be stored in time index data structure using 150
With reached time correlation connection position at identifier it is associated it is each grouping by network interface card 140 successfully
Transmission.
At the stage 520, in response to the network equipment determine be stored in time index data structure with reached
The associated grouping of identifier at the position of time correlation connection successfully transmits, and the network equipment is attached to network equipment forwarding
Notice will be transmitted by adding before packet is sent to the application for waiting for and being transmitted notice from network equipment reception.For example,
With reference to figure 6B, it has been successfully delivered by network interface card 140 in response to determining from the grouping A1 being originally sent using 150a, net
Network equipment 110 will be transmitted notice M-A1 and be sent to using 150c.Similarly, point in response to initially being sent from application 150b
Group B1 is successfully transmitted by network interface card 140, and the network equipment 110 will be transmitted notice M-B1 and be transferred to using 150b.
In some embodiments, it can be small (for example, 32 bytes or including several 64 integers) to be transmitted notice.
In some embodiments, using each in 150 can be configured as forwarded to the network equipment 110 it is additional
It is waited for before grouping from the reception of the network equipment 110 and is transmitted notice.It in some embodiments, can using each in 150
To be configured as before the additional packet of the same category is transmitted to the network equipment 110, waits for from the network equipment 110 and receive needle
Message is transmitted to the grouping of particular category.For example, as shown in Figure 6B, A6, B6 and C6 will be grouped (such as void using 150
Shown in line) be forwarded to socket buffering area 405,410 and 415 respectively before etc. to be received be transmitted notice (such as M-A1, M-
B1 and M-C1).
Fig. 6 A-6B indicate, according to some embodiments, using scheduler, time index data structure and to be transmitted
The delay of notice is completed to carry out the exemplary block diagram of the operation to network service shaping.In Fig. 6 A-6B, using with Fig. 4 A-4C phases
Same reference numeral, omits similar description.
As shown in Figure 6A, to sum up, the network equipment 110 connects from using 150 (for example, using 150a, 150b and 150c)
Receive packet.The network equipment 110 includes one or more socket buffering areas 405,410 and 415, to be lined up and handle from answering
The grouping received with 150.The network equipment 110 further includes one or more memory devices 115 and scheduler 125, is deposited with basis
Rate-limiting algorithm or strategy in memory 115 are stored up to handle grouping.The network equipment 110 further includes time index data knot
Structure 130 --- also referred to as timing wheel 130, and the packet identifier is stored according to the transmission time of packet identifier.Network
Equipment 110 further includes one or more network interface cards 140 to transmit grouping.Network interface card 140 will be transmitted notice and pass
It is defeated by and applies 150.In some embodiments, network interface card 140 is transmitted notice and creates by being deferred to using 150
Build back pressure.The network equipment 110 can be transmitted notice until network interface card 140 has been successfully delivered point by delay
Group to carry out rate limit to network service.Delay be transmitted notice can prevent using 150 generate it is additional grouping for
The processing of the network equipment 110.In some embodiments, the network equipment 110 can utilize the small queues of TCP at socket buffering area
It can be by the grouping number of network device processing to limit.The small queues of TCP are flow restrictions known to persons of ordinary skill in the art
Mechanism can be configured in TCP protocol stack, which is designed to realize smaller buffer size and reduce
The number of TCP groupings in the transmission queue of given time.The use of the small queues of TCP can allow delay completion mechanism due to
It is reduced in the grouping number of given time conveying and realizes lower memory and utilize.
As shown in the stage 310 of Fig. 6 A and Fig. 3, the network equipment 110 TCP layer from it is multiple application 150 (for example, using
150a, 150b or 150c) receive grouping.The network equipment 110 shown in Fig. 6 A includes three socket buffering area (405,410 and
415).It is queued and handles it is assumed for purposes of illustration that carrying out being grouped in socket buffering area 405 for self-application 150a, come
Being grouped in socket buffering area 410 for self-application 150b is lined up and handles, and that carrys out self-application 150c is grouped in socket
It is lined up and handles in buffering area 415.The network equipment 110 can also or include grouping of the processing from multiple applications as an alternative
One or more socket buffering areas.As shown in Figure 6A, the grouping for carrying out self-application 150a is suitable by being transmitted using 150a by it
Sequence is received by socket buffering area 405.For example, grouping A1 is initial or the first grouping transmitted from application 150a, and
It is handled for transmission by scheduler 125.A2 is grouped to handle to determine transmission time (for example, t via scheduler 1253), and
And packet identifier ID：A2 be already stored in timing wheel 130 with transmission time t3At associated position.It is grouped A3-
A5 holds queue in socket buffering area 405, waits for the processing of scheduler 125.Grouping A6 is being forwarded (shown in dotted line)
To being retained in before socket buffering area 405 using in 150a, waiting 150a to be applied to receive and be previously forwarded to by application 150a
The one or more packets of socket buffering area 405 are associated to be transmitted notice.Similarly, it can be generated point using 150b
Group simultaneously transfers the packet to socket buffering area 410.For example, grouping B1 is transmitted and via scheduler from application 150b
125 processing are for the initial of transmission or first is grouped.B2 is grouped to be handled to determine the transmission time of grouping by scheduler 125
(for example, t4), and packet identifier ID：B2 have stored in timing wheel 130 with transmission time t4At associated position.
Grouping B3-B5 holds queue in socket buffering area 410, waits for the processing of scheduler 125.Grouping B6 is retained in using 150b
In, it waits 150b to be applied to receive and previously forwarded the one or more packets (shown in dotted line) to socket buffering area 410
It is associated to be transmitted notice.As further shown in fig. 6 a, grouping C1 is initial or the first grouping transmitted from application 150c,
And it is handled for transmission by scheduler 125.Grouping C2 has been scheduled the processing of device 125 to determine the transmission time of grouping
(for example, t5), and packet identifier ID：C2 be already stored in timing wheel 130 with transmission time t5Associated position
Place.Grouping C3-C5 holds queue in socket buffering area 415, waits for the processing of scheduler 125.Grouping C6 is retained in application
In 150c, waits 150c to be applied to receive and previously forward the one or more (shown in dotted line) to socket buffering area 415 point
Group is associated to be transmitted notice.
As shown in Figure 6A, scheduler 125 have determined that in timing wheel 130 index and with the biography of grouping A1, B1 and C1
The time of defeated time correlation connection has arrived at (or process).A1, B1 and C1 is grouped to remove from memory 115 (for example, existing
It is grouped A1, B1 and C1 being shown as dotted line in memory 115) and network interface card 140 is forwarded to for transmission.It adjusts
Degree device 125 has been processed by the transmission time that grouping A2, B2 and C2 is each grouped with determination and will be with each grouping phase
Associated identifier be stored in timing wheel 130 at the associated position of the determining transmission time of each grouping.Example
Such as, packet identifier ID：A2 is already stored at and transmission time t3Associated position, and packet identifier ID：B2 quilts
It is stored in and transmission time t4Associated position.Similarly, packet identifier ID：C2 is stored in and transmission time t5It is related
The position of connection.Grouping A2, B2 and C2 are stored in memory 115.
As shown in Figure 6B, scheduler 125 handles next grouping from socket buffering area 405,410 and 415 with true
Surely the transmission time of A3, B3 and C3 are grouped.Scheduler 125 is based on rate associated with the packet class received from application 150a
Limit algorithm or strategy determine that grouping A3 should be in time t6It is transmitted.Grouping A3 is stored in memory 115, Zhi Daoyi
Through reaching transmission time t6.Scheduler 125 is calculated based on rate limit associated with the packet class received from application 150b
Method or strategy, determination should be in time t7Transmission grouping B3.Grouping B3 is stored in memory 115, until having reached transmission
Time t7.Packet identifier ID：B3 is stored in timing wheel 130 and the transmission time t for grouping B3 determinations7It is associated
At position.Scheduler 125 is based on rate-limiting algorithm associated with the packet class received from application 150c or strategy, really
Surely grouping C3 should be in time t8It is transmitted.Grouping C3 is stored in memory 115, until having reached transmission time t8.Grouping
Identifier ID：C3 is stored in timing wheel 130 and the transmission time t for grouping B3 determinations8At associated position.Periodically
Wheel 130 stores packet identifier ID in time location corresponding with the transmission time determined by scheduler 125：A3、ID：B3
And ID：C3.Packet identifier ID：A3、ID：B3 and ID：C3 is stored in timing wheel 130, until the determination of scheduler 125 has been arrived
The transmission time of each packet identifier index has been reached (for example, in TimeNow420)。
As further shown in Fig. 6 B, scheduler 125 have determined arrived indexed in timing wheel 130 with grouping A2, B2
With the C2 associated times and execute instruction to forward grouping A2, B2 and C2 to network interface card 140.It is grouped A2, B2 and C2
From removing (for example, be shown as in memory 115 now dotted line be grouped A2, B2 and C2) in memory 115 and turned
Network interface card 140 is dealt into for transmission.
As shown in Figure 6B, network interface card 140 will be transmitted notification transmission to using 150.Based on network interface card 140
Transmission grouping A1, B1 and C1, will be transmitted notification transmission to using 150a, 150b and 150c.For example, receiving base using 150a
Being transmitted for grouping A1, which is successfully transmitted, in network interface card 140 notifies M-A1.It is prevented from what forwarding was used for transmission using 150a
Additional packet is transmitted notice M-A1 until being received using 150a.It is opposite with the grouping Successful transmissions of A1 as receiving
Being transmitted for answering notifies M-A1's as a result, grouping A6 to be forwarded to the socket buffering area of the network equipment 110 using 150a
405.It is prevented from additional packet being sent to the network equipment 110 using 150a, until receiving next transfer using 150a
At notice.As a result, grouping A7 is retained in using in 150a, and it is not forwarded to the socket buffering area of the network equipment 110
405.In some embodiments, the network equipment 110 can be configured as adds what one of prevention application transmission was used for transmission
From the grouping of a reception predetermined number in multiple groupings before grouping.In some embodiments, being transmitted notice can
It is assisted to network service shaping with being delayed by.For example, being transmitted the communication of notice can be delayed by, until from network interface
After 140 transmission grouping of card.Make to return to source reduces new point generated by application 150 using the 150 notice delay that is transmitted
The number and reduction of group are transmitted to the number of the grouping of the network equipment 110.In some embodiments, being transmitted notice can
It is transmitted with delayed mode with handling the sequence of grouping according to network interface card 140.For example, being transmitted notice M-A1, M-B1
With M-C1 compared with the sequence for receiving grouping at network interface card 140, it is transmitted with identical sequence or different sequences.It passes
Defeated completion notice after the transmission of network interface card 140 to receive the identical or different of grouping respectively in grouping A1, B1 and C1
Sequential delivery.It when executing, to be transmitted the delay of notice completes that network can be reduced when by disorderly transmitting completion notice
Hol blocking in equipment 110.In some embodiments, be transmitted notice can it is smaller (for example, 32 bytes or including
Several 64 integers).As further shown in figure 6b, logical based on being transmitted for grouping A1, B1 and C1 is received using 150
Know, the network equipment 110 receives next sequential packet (example in socket buffering area 405,410 and 415 respectively from application 150
Such as, A6, B6 and C6 are grouped) in.
Fig. 7 A-7C indicate according to some embodiments, using multiple schedulers, multiple time index data structures with
And it is transmitted the delay of notice and completes to carry out the exemplary block diagram to the network device operation of network service shaping.
The network equipment 110 includes two processors, memory 115 and the network interface for being shown as processor 1 and processor 2
Card 140.Each processor include one or more socket buffering areas (e.g., including the socket buffering area in processor 1
705 and 710 and the socket buffering area 715 that is included in processor 2 and 720) and one or more schedulers (for example,
The scheduler 125b in scheduler 125a or processor 2 in processor 1).Each processor includes one or more time ropes
The data structure drawn, also referred to as timing wheel (such as timing wheel 130a in the processor 1 or timing wheel 130b in processor 2).
As further shown in Fig. 7 A, network equipment trustship is multiple to apply 150, including using 150a and applies 150b, each
Packet is generated so that the network equipment 110 transmits using 150.In some embodiments, it can be incited somebody to action using 150a and 150b
Grouping is only forwarded to processor 1 or processor 2.In some other embodiments, using one or two in 150a and 150b
It is a that both processor 1 and processor 2 can be forwarded the packet to identical or different rate.As shown in Figure 7 A, from application
The grouping that 150a is received is received by processor 1 in socket buffering area 705.The grouping received from application 150b is by processor 1
It is received in socket buffering area 710.For example, as shown in Figure 7 A, grouping P1A1 to P1A10 is received from application 150a, and point
Group P1B1 to P1B10 is received by the socket buffering area 710 of processor 1.Similarly, as shown in Figure 7 A, it is received from application 150a
Grouping by processor 2 receive in socket buffering area 715.It is received from the grouping received using 150b by processor 2
In socket buffering area 720.For example, socket buffering area 715 receives grouping P2A1 to P2A5 from application 150a, and by processor
2 socket buffering area 720 receives grouping P2B1 to P2B5 from application.
As further shown in Fig. 7 A, the network equipment 110 includes by the shared memory 115 of processor 1 and processor 2.
In some embodiments, memory 115 can not be shared, and each processor can be with the memory 115 of their own.
Memory 115 can store packet and scheduler 125 is used for determining that the rate limit for the transmission time being each grouped is calculated
Method or strategy.Each processor 1 and processor 2 include scheduler 125 to handle the grouping received, and according to each spy
Packet class or the corresponding appropriate rate-limiting algorithm of application packet flow or strategy are determined to determine transmission time.For example, place
Reason device 1 includes scheduler 125a to handle grouping associated with 150a and application 150b is applied.Similarly, processor 2 includes
Scheduler 125b is to handle the grouping received from application 150a and application 150b.Each scheduler 125 can be configured with unique
Logic or process instruction with the classification or type for realizing the packet handled with it is associated or based on processor store
The rate-limiting algorithm or strategy of device or power specification.
In some embodiments, network interface driver 120 can be executed instruction with across one or more processors needles
Manage specific cluster classification or flow and/or adjust the aggregate rate of grouping to be sent.In some embodiments, net
Network interface driver 120 can determine specific cluster classification to be applied to using the statistical data being stored in memory 115
Or the processor special speed limitation of flow.For example, network interface driver 120 can be based on being sent to the given of processor 1
The history average of the ratio of the grouping of classification come determine processor 1 special speed limitation.For example, if in history, giving
The 70% of the total number packets of classification is transmitted by processor 1, then the scheduler 125a of processor 1 can utilize the grouping of the category
Rate limit, the rate limit be the category aggregate rate limitation 70%.About various types of other point between processor
The statistical data of the distribution of group may remain in memory, and the specific rate limit of processor can be between processor
Grouping distribution change over time and be updated.
As further shown in Fig. 7 A, processor 1 includes timing wheel 130a, and processor 2 includes timing wheel 130b.In some realities
It applies in mode, each processor can be configured with the timing wheel 130 of their own, and in other embodiments, processor
Timing wheel 130 can be shared.Each timing wheel 130 is time index data structure, in time index data structure with
Packet identifier is stored for the determining associated position of transmission time of each grouping.It is same as shown in Figure 7 A, the network equipment
110 include network interface card 140, to be had arrived at based on scheduler 125 (for example, scheduler 125a or scheduler 125b) determination
The time indexed in timing wheel 130 (for example, timing wheel 130a or timing wheel 130b) transmits grouping.In some embodiments
In, processor 1 and processor 2 can respectively include the network interface card 140 of themselves.Network interface card 140 can be with
Notification transmission will be transmitted to respond with 150 to assist from application 150 generating rates limitation grouping.
As shown in Figure 7 A, the scheduler 125a processing of processor 1 is received from socket buffering area 705 and 710
Grouping is to determine the transmission time being each grouped.Identifier associated with respective packets is stored in timing wheel by scheduler 125a
In 130a at the associated position of transmission time that the grouping determines.For example, packet identifier ID：P1A1, from answering
With 150a generate the first sequential packet via scheduler 125a be treated and stored in timing wheel 130a with it is identified
Transmission time is (for example, t0) at associated position.Similarly, packet identifier ID：P1B1, associated with application 150b the
One sequential packet via scheduler 125a be treated and stored in timing wheel 130a with determining transmission time (for example,
t1) at associated position.Packet identifier ID：P1A1 and ID：P1B1 is stored in timing wheel 130a, until scheduler 125a
It determines until having arrived at the time indexed in timing wheel 130a.For example, timing wheel is periodically polled in scheduler 125a
130a is to determine and packet identifier ID：P1A1 or ID：The associated transmission times of P1B1 whether than current time or
TimeNow725 earlier.In some embodiments, it poll timing wheel and forwards the packet to network interface card 140 and can lead to
The logic --- such as transponder 135 shown in Fig. 1 --- crossed different from scheduler 125 executes.P1A1 and P1B1 is grouped to protect
It stays in memory 115, is had reached and be each grouped relevant transmission time until scheduler 125a has determined.It is similar
Ground, as further shown in Fig. 7 A, the scheduler 125b of processor 2 handles the grouping received from socket buffering area 715 and 720
To determine the transmission time being each grouped.Identifier associated with respective packets is stored in timing wheel 130b by scheduler 125b
In at the associated position of transmission time that the grouping determines.For example, packet identifier ID：P2A1, by applying
150a generate the first sequential packet via scheduler 125b be treated and stored in timing wheel 130b with determining biography
The defeated time is (for example, t2) at associated position.Similarly, packet identifier ID：P2B1, with application 150b associated first
Sequential packet via scheduler 125b be treated and stored in timing wheel 130B with identified transmission time (for example,
t3) at associated position.Packet identifier ID：P2A1 and ID：P2B1 is stored in timing wheel 130b, until having arrived at
Until scheduler 125b determines the time indexed in timing wheel 130b.For example, timing wheel is periodically polled in scheduler 125b
130b is to determine and packet identifier ID：P2A1 or ID：Whether the associated transmission times of P2B1 are than current time or TimeNow
730 earlier.Grouping P2A1 and P2B1 is retained in memory 115 until scheduler 125b determinations have reached and are each grouped phase
Associated transmission time.
As shown in Figure 7 B, the scheduler 125a grouping P1A2 processed separately from socket buffering area 705 and 710 and
P1B2 is to determine the transmission time being each grouped.Based on the transmission time being each grouped is determined, scheduler 125a will be with each point
The associated identifier of group is stored at the position associated with identified transmission time in timing wheel 130a.For example, point
Group identifier ID：P1A2 and ID：P1B2 is stored in timing wheel 130a
t4And t5) at associated position.Grouping P1A2 and P1B2 is stored in memory 115.Scheduler 125a is periodically polled fixed
Hour wheel 130a is with by by the identified transmission time of each grouping and current time TimeNow725 are compared to determine
Whether the time that among timing wheel 130as indexes is had arrived at.For example, having arrived at grouping P1A1 (for example, t based on determining0) and
P1B1 is grouped (for example, t1) time index, scheduler 125a, which is executed instruction, to be forwarded to network will be grouped P1A1 and P1B1 and connects
Mouth card 140 is to be transmitted.Grouping P1A1 and P1B1 removes (shown in dotted line) from memory 115.
As shown in Figure 7 B, scheduler 125b poll timing wheel 130b and determination had arrived in timing wheel 130b
In for grouping P2A1 indexes time (730).For example, based on the time having arrived at for grouping P2A1 indexes is determined, adjust
Degree device 125b is executed instruction is forwarded to network interface card 140 for transmission will be grouped P2A1.P2A1 will be grouped from memory 115
Middle removal (shown in dotted line).
As seen in figure 7 c, processor 1 continues to receive new grouping from application 150, and scheduler 125a continues with than place
The grouping that the faster rate processings of scheduler 125b of reason device 2 receive.Scheduler 125a has been processed by respectively from socket
The grouping P1A3 and P1B3 of mouth buffering area 705 and 710, to determine the transmission time being each grouped.It is each grouped based on determination
Transmission time, scheduler 125a by identifier associated with each grouping be stored in timing wheel 130a with identified biography
At the position of defeated time correlation connection.For example, packet identifier ID：P1A3 and ID：P1B3 by it is in storage timing wheel 130A and its
Determining transmission time (such as be respectively t6And t7) associated position.Grouping P1A3 and P1B3 is stored in memory 115
In.Scheduler 125a be periodically polled timing wheel 130a with by by the identified transmission time of each grouping with it is current when
Between TimeNow725 are compared to determine whether to have had arrived at the time indexed in timing wheel 130a.For example, scheduler 125a
Based on the time for having arrived at for grouping P1A2 and being grouped P1B2 indexes is determined, execute instruction grouping P1A2 and P1B2 forwardings
To network interface card 140 to be transmitted.Grouping P1A2 and P1B2 removes (shown in dotted line) from memory 115.
As further shown in Fig. 7 C, based on the transmission grouping P1A1 and P1B1 of network interface card 140, it is transmitted notice and is passed
Defeated arrive applies 150.For example, network interface card 140 has been successfully delivered grouping P1A1 and P1B1 and in response to successfully transmitting,
The grouping is transmitted to the application 150 for initially generating each grouping be transmitted notice (for example, M-P1A1 and M-P1B1) respectively.
It will be prevented from sending the additional packet being used for transmission using 150a, notice M-P1A1 be transmitted until it is received.Similarly,
It will be prevented from sending the additional packet being used for transmission using 150b, notice M-P1B1 be transmitted until it is received.Based on connecing
It receives and is transmitted notice, will can newly be grouped (for example, P1A11 and P1B11) respectively using 150 is forwarded to network equipment socket
Buffering area 705 and 710, for scheduler 125a processing.
As seen in figure 7 c, scheduler 125b has been processed by the grouping P2A2 from socket buffering area 715, and is directed to and answers
New grouping with 150b not in socket buffering area 720 is handled.Scheduler 125b determines the biography of grouping P2A2
The defeated time, and identifier ID is stored at position associated with determining transmission time in timing wheel 130B：P2A2.Grouping
P2A2 is stored in memory 115.Timing wheel 130b is periodically polled in scheduler 125b, with by will each be grouped really
Fixed transmission time and current time TimeNow730 are compared to determine whether to have arrived to index in timing wheel 130b
Time and based on the time having arrived at for grouping P2B1 indexes is determined, scheduler 125b, which is executed, forwards grouping P2B1
Instruction to network interface card 140 to be transmitted.Grouping P2B1 removes (shown in dotted line) from memory 115.
As further shown in Fig. 7 C, based on the transmission grouping P2A1 of network interface card 140, from network interface card
After 140 transmission grouping P2A1, it is transmitted notice and is transferred to using 150.It is prevented from what transmission was used for transmission using 150a
Additional packet is transmitted notice M-P2A1 until it is received.It is transmitted notice based on receiving, can be incited somebody to action using 150a
New grouping (for example, P2A6) is forwarded to network equipment socket buffering area 715 for scheduler 125b processing.
As described above, the data structure of time index and the completion mechanism of delay can be used for at the transmission network equipment
Network service carry out rate limit.Confirmation data packet receipt can also be dispatched using similar mechanism by receiving the network equipment
To realize recipient side rate limiting technique.In some embodiments, recipient side rate limiting technique can make full use of
The revision --- i.e. the TCP congestion windows of transmission equipment --- of the existing capability of Transmission Control Protocol sends to limit transmission equipment
The rate of future grouping.It is not yet being confirmed to be one of ordinary skill in the art will be understood that TCP congestion windows are transmission equipments
The threshold value of the dynamic adjustment of the amount for the TCP data that can be sent in the case of being received.That is, when the TCP groupings of transmission unconfirmed
In data volume when meeting TCP congestion window threshold values, transmission equipment can not send any additional grouping.As a result, receiving device
Can when may be used to manipulate transmission equipment by controlling its time that TCP acknowledgment message (TCP ACK) is sent back transmission equipment
To send additional packet.In some embodiments, such as in transmission equipment the feelings executed in containerization or virtual machine environment
Under condition, individual TCP congestion windows can be maintained in each virtual machine or each container, are come to allow to be individually controlled
The rate of the grouping of each virtual machine or container.In some embodiments, on the true OS of transmission equipment or at it
The each stream of packets transmitted by transmission equipment in the transport protocol module of interior operation, can maintain individual TCP congestion windows.
In some embodiments, the congestion window function of modification may include completion notice feature, wherein application, virtual machine and/or appearance
The biography that additional packet can not be forwarded on the true OS of transmission equipment or be run in the true OS of transmission equipment by device environment
Defeated protocol module is sent to corresponding application, virtual machine or container environment until that will be transmitted notification message.Such completion
Notification message is transmitted by Transmission Control Protocol message when receiving the TCP ACK messages from recipient side, TCP ACK messages card
The grouping being previously sent in fact is successfully received really.The function is further described below with reference to Fig. 8 and 9.Fig. 8 shows to connect with above-mentioned
The flow chart of the example collection of the associated conveyer side operation of receipts person side rate limiting technique.Fig. 9 is shown and recipient side
The flow chart of the example collection of the associated recipient side operation of rate limiting technique.
Fig. 8 is using the exemplary method 800 executed by the transmission network equipment 110 come the flow chart to network service shaping.
To sum up, method 800 is since the stage 830, and wherein packet is transmitted to the network equipment by the network equipment 110 from data source
110.In the stage 835, if the congestion window of data source is full, this method includes preventing from sending other packet
To the transport protocol module of the network equipment, until data sources to completion notice, as shown in the stage 838.In the stage
840, if the determination of the network equipment 110 receives the packet acknowledgement for the packet transmitted from destination equipment,
Then the network equipment 110 will be transmitted notice and send packet source to, as shown in the stage 850 also, if the data source
Congestion window had previously been expired, then allowed the transport protocol module of the network equipment to receive the additional packet from packet data source, such as
Shown in stage 855.In the stage 860, if not yet receiving the packet acknowledgement message of transmitted packet, the network equipment
110 determine whether to be more than congestion window timeout value.In the stage 870, congestion window timeout value if more than, then the network equipment
110 retransfer packet.In the stage 880, if the determination of the network equipment 110 has not exceeded congestion window timeout value, net
Network equipment 110 redefines the packet acknowledgement message whether having been received for the packet transmitted.
More detailed reference chart 8, in the stage 830, the packet from data source is transmitted to by the transmission network equipment 110 to be connect
Receive the network equipment 110.For example, data source can be the application executed on network devices.Sender side as described above
Rate limiting technique is the same, and the application for being used as data source 150 can be held in the palm with trustship on the real system of the network equipment 110
Pipe is in the virtual machine on the network equipment 110 or trustship is in the performing environment of the containerization by 110 trustship of the network equipment.
In the stage 835, transport protocol module --- TCP layer of such as network protocol stack --- determines the grouping phase with transmission
Whether associated congestion window is become full due to the transmission of grouping.The network equipment 110 can be various by transport protocol module
Data source maintains congestion window, such as TCP congestion windows.The network equipment 110 can be directed on the network equipment 110 and each of execute
Using, for 110 trustship of the network equipment each virtual machine or containerization environment or for the network equipment 110 transmit it is every
A packet traffic maintains individual congestion window.It can be application, virtual machine, container, flow that congestion window, which defines equipment,
The maximum amount of data of equal transmission, the data are confirmed as being received by target destination equipment not yet.In some embodiments
In, congestion window is initially set in link initialization or the value of twice of maximum segment size after time-out occurs, but
It is that can also use other values.If caused in the transmission for the packet that the stage 830 transmits associated with the packet
Congestion window becomes full, then the network equipment 110 can prevent packet to be further forwarded to net from the data source for initiating the grouping
The transport protocol module of network equipment 110, until the data sources to completion notice message, completion notice message instruction
Its previously caused transmission grouping in some be received.To multiple some implementations using specific congestion window
In mode, when determining that congestion window has been expired, the network equipment can prevent each in application associated with the congestion window
Additional packet is transmitted to the transport protocol module of the network equipment 110.It is prevented when congestion window has been expired to transport protocol module
Forwarding grouping (in the stage 838) alleviates memory limitation associated with the queue in transport protocol module.
In the stage 840, the network equipment 110 determines whether that the packet acknowledgement for the packet transmitted has been received
Message.For example, the transmission network equipment 110 can be determined being received when TCP ACK are grouped from reception destination network equipment 110
Packet is successfully delivered.
In the stage 850, the TCP having been received for the packet transmitted is determined in response to the network equipment 110
ACK, the network equipment 110 are transmitted notice to packet data source.For example, the transport protocol mould of the transmission network equipment 110
Block 145 can be identified that the data source of the grouping of reception is transmitted notice to initiation.The biography transmitted by packet source
Defeated completion notice is used to notify that additional packet can be lined up for transmission (rank to the packet source such as using 150
Section is 855).
As further described in association with figure 8, in the stage 860, based on the packet acknowledgement for being not received by the packet to being transmitted
Message, the transmission network equipment 110 determine whether to have been over congestion window timeout value.In some embodiments, transmission net
Network equipment 110 can be configured with the individual congestion window for the every class to be transmitted grouping.For example, the transmission network equipment
110 can be configured with multiple congestion windows, each congestion window correspond to different classes of grouping, such as by application 150 (such as
150a, 150b and 150c) in each generate packet.
In the stage 870, if the determination of the network equipment 110 has been over congestion window timeout value, 110 weight of the network equipment
Newly transmit the packet.Timeout value is arranged to Timer Threshold and indicates to receive when the network equipment 110 will confirm that biography
The conservative estimation for the packet sent.If timer is being not received by confirmation message of the instruction by destination reception grouping
Expire in the case of (for example, TCP ACK messages), then the packet that retransfers will be attempted by transmitting the network equipment 110.
In the stage 880, if the determination of the network equipment 110 is not above TCP congestion window timeout values, the network equipment 110
The packet acknowledgement message whether having been received for the packet previously transmitted redefined.
Fig. 9 shows the recipient side rate limit skill with the network equipment execution by the network equipment 110 such as shown in FIG. 1
The flow chart of the example collection of the associated recipient side operation of art.Method 900 includes receiving data point from remote computing device
Group (stage 910), and packet acknowledgement message is generated by the transport protocol module 145 of the network equipment of reception packet 110
(stage 920).This method further includes：Based at least one rate limit strategy associated with the packet received come really
Determine the transmission time (stage 930) of packet acknowledgement message, and in time index data structure with the time index data knot
Storage is associated with the grouping of packet acknowledgement message at the associated position of transmission time determined for packet acknowledgement message in structure
Identifier (stage 940).Method 900 further includes that determination has arrived at (stage time indexed in time index data structure
950), and by the network interface card of the network equipment 110 transmission be stored in time index data structure with reached
Time correlation connection position the associated packet acknowledgement message (stage 960) of identifier.
Method 900 includes receiving packet (stage 910) from remote computing device 110.Remote computing device 110 can be with
It is any network equipment 110 that can generate packet.In some embodiments, remote computing device is configured with
Method 800 shown in Fig. 8 controls the transmission of packet.Method 900 further includes：By transport protocol module (such as Transmission Control Protocol
The TCP layer of module or network stack) generate packet acknowledgement message (for example, TCP ACK messages) (stage 920).As begged for above
By the network equipment 110 for receiving packet sends the grouping of packet acknowledgement message to the network equipment 110, the network equipment 110
Packet has been transmitted to confirm that the data of transmission have been received.
As further illustrated in figure 9, based at least one rate limit strategy associated with the packet received come
Determine the transmission time (stage 930) of packet acknowledgement message.In some embodiments, the network interface of the network equipment 110 drives
Dynamic device 120 can be based on being stored in rate-limiting algorithm in memory 115, associated with the packet of reception or strategy
To determine the transmission time of each packet acknowledgement message.For example, network interface driver 120 can connect according to particular category
Transmission time stamp is applied to packet acknowledgement message by the associated rate-limiting algorithm of packet or strategy received.In addition
Or as an alternative, each packet acknowledgement message can have the transmission time of the request generated by transport protocol module to stab.One
In some such embodiments, network interface driver 120 can based on more than it is associated with received grouping extremely
Lack a rate limit strategy and calls rate-limiting algorithm associated with received data grouping newer to determine
Transmission time.For example, if receive packet associated with the packet class of rate, and network interface driver
The transmission time of 120 determination packet acknowledgement message will lead to the additional data transmission from identical traffic equipment so that will be more than
Corresponding rate limit, then network interface driver 120 can be stabbed with the transmission time of adjustment update transmission time, the tune
Whole transmission time, which is stabbed, to transmit packet acknowledgement message in the time later, associated with the packet class to be effectively reduced
Transmission network equipment 110 transmission rate.In some embodiments, the network interface driver 120 of the network equipment is received
It can be configured to ensure that the transmission of packet acknowledgement message is not delayed to postpone to cause the degree more than congestion window timeout value,
Because the occurrence of such, can cause transmission rate significantly more to be reduced than desired.
Method 900 further includes：Network interface driver 120 will identifier associated with packet acknowledgement message store when
Between in index data structure, it is related to the transmission time determined for packet acknowledgement message in the time index data structure
At the position of connection (stage 940).Suitable time index data structure another example is above-mentioned timing wheels 130.
Method 900 further includes that determination has arrived at the time (stage 950) indexed in time index data structure.At some
In embodiment, network interface driver 120 can determine point having reached and be stored in time index data structure 130
The group acknowledge message identifier associated specific transmission time.When network interface driver 120 can utilize current time to inquire
Between index data structure 130 to determine whether there is any packet acknowledgement message that will be transmitted.For example, network interface driver
120 can use the current cpu clock time (or such as regularly some other reference time value of progressive whole number value)
Inquire data structure.
As further illustrated in figure 9, the network equipment 110 is transmitted by network interface card 140 and is stored in time index data
Packet acknowledgement message (stage 960) in structure, associated with the identifier of position of the time correlation connection reached.One
In a little embodiments, network interface driver 120 can be based on arrival (or passage) and be stored in the packet acknowledgement in memory 115
The transmission time identified in message identifier, by the packet acknowledgement messaging being stored in memory 115 to network interface card
140。
Although described above as two different rate limiting techniques, in some embodiments, the network equipment can
To realize above-mentioned conveyer side rate limit processing and the processing of recipient side rate limit.That is, the network equipment can use
Time index data structure similar to timing wheel 130 and the network interface driver similar to network interface driver 120
Dispatch the transmission for the new data packet initiated at the network equipment 110, and the transmission of scheduling packet acknowledgement message.Configured in this way
The network equipment can execute the rate limit strategy of themselves, while the rate limit mistake also to being not carried out themselves
The network equipment of journey carries out rate limit.
In addition, although recipient side described above rate limiting technique is described as realizing in conjunction with TCP transmission agreement,
But it can come in conjunction with the other transport protocols being unequivocally established needed to being grouped reception or in other layers of network protocol stack
Realize this function without departing from the scope of the present disclosure.
Figure 10 is illustrated according to illustrated embodiment, can be used to realize system described and illustrated herein and side
The block diagram of the generic structure of the computer system 1000 of the element of method.
Generally, computing system 1010 include at least one processor 850 for being acted according to instruction execution and
For storing instruction with one or more memory devices 1070 or 1075 of data.The exemplary computing system 1010 of diagram includes
Via the one or more processors 1050 that bus 1015 is communicated at least one network interface driver controller 1020, wherein
One or more network interface cards 1022 are connected to one or more network equipments 1024, memory 1070 and any other equipment
1080, such as I/O interfaces.Network interface card 1022 can have one or more network interface driver ports with connect
Equipment or component are communicated.In general, the instruction that processor 1050 receives execution from memory.Illustrated processor 1050
Including or being directly connected to cache memory 1075.
In more detail, processor 1050 can be process instruction --- for example carried from memory 1070 or cache 1075
The instruction taken --- any logic circuit.In many examples, processor 1050 is microprocessor unit or dedicated processes
Device.Computing device 1000 is based upon any processor as described herein operated or processor group.Processor
1050 can be single or multiple core processor.Processor 1050 can be multiple processors.In some embodiments, processor
1050 can be configured as operation multithreading operation.In some embodiments, processor 1050 can be with trustship one or more
Virtual machine or container, together with the management program or container manager of the operation for managing virtual machine or container.In such reality
It applies in mode, it is real in the environment for the virtualization or containerization that method can provide on processor 1050 shown in Fig. 3 and Fig. 5
It is existing.
Memory 1070 can be suitable for any equipment of storage mechanized data.Memory 1070 can be tool
There are the equipment of fixed storage or the equipment for reading movable storage medium.Example includes the non-volatile memories of form of ownership
Device, medium and memory devices, semiconductor memory devices (for example, EPROM, EEPROM, SDRAM and flash memory device), disk,
Magneto-optic disk and CD (such as CD ROM, DVD-ROM and Blu-ray Disc).Computing system 1000 can have any number of storage
Device equipment 1070.In some embodiments, memory 1070 supports the virtual machine provided by computing system 1010 or container to hold
The memory of the addressable virtualization of row environment or containerization.
Cache memory 1075 is commonly held within the computer that processor 1050 is nearby used for fast read-time
A kind of form of memory.In some embodiments, cache memory 1075 be processor 1050 a part or
On chip identical with processor 1050.In some embodiments, there are multilevel caches 1075, such as L2 and L3 high
Fast cache layer.
Network interface driver controller 1020 is managed (to be also referred to as via the data exchange of network interface driver 1022
Network interface driver port).Network interface driver controller 1020 disposition for network communication osi model physics and
Data link layer.In some embodiments, some tasks of network interface drive control device are disposed by processor 1050.One
In a little embodiments, network interface drive control device 1020 is a part for processor 1050.In some embodiments, it calculates
System 1010 has multiple network interface drive control devices 1020.The network interface driver configured in network interface card 1022
Port is the tie point for physical network links.In some embodiments, network interface controller 1020 supports wireless network
Network connects, and interface port associated with network interface card 1022 is wireless receiver/transmitter.In general, computing device
1010 via with the physics of network interface driver port interfaces or Radio Link that are configured in network interface card 1022 and its
Its network equipment 1024 exchanges data.In some embodiments, network interface controller 1020 realizes such as Ethernet etc
Procotol.
Other network equipments 1024 are connected to via the network interface driver port being included in network interface card 1022
Computing device 1010.Other network equipments 1024 can be peer computing device, the network equipment or with any of network function
Other computing devices.For example, first network equipment 1024 can be that computing device 1010 is connected to the data of such as internet
The network equipment of network, such as hub, bridge, interchanger or router.
Miscellaneous equipment 1080 may include I/O interfaces, external series device port and any additional coprocessor.
For example, computing system 1010 may include for connect input equipment (such as keyboard, microphone, mouse or it is other instruction set
It is standby), (such as the portable flash memory driving of output equipment (such as video display, loud speaker or printer) or additional memory devices
Device or external agency driver) interface (such as universal serial bus (USB) interface).In some embodiments, calculating is set
Standby 1000 include the optional equipment 1080 of such as coprocessor, for example, math co-processor can with high precision or complicated calculations
Carry out assist process device 1050.
Theme described in this specification and the embodiment of operation may be implemented in Fundamental Digital Circuit, or in body
It is now tangible medium, firmware or hardware --- including the computer in structure disclosed in this specification and its equivalent structures
In software, or in wherein one or more combinations.The embodiment of the theme described in the present specification can be by reality
Now to be embodied in one or more computer programs on tangible medium, i.e. one or more modules of computer program instructions,
It encodes on one or more computer storage medias so that data processing equipment executes or controls the operation of data processing equipment.
Computer storage media can be computer readable storage devices, computer-readable memory substrate, random or serial access storage
The combination of device array or equipment or one or more of which, or can be included therein.Computer storage media
It can also be one or more individually component or media (for example, multiple CD, disk or other storage devices) or be included in
Wherein.Computer storage media can be tangible and nonvolatile.
Operation described in this specification may be implemented as by data processing equipment to being stored in one or more calculating
The operation of data or the data execution received from other sources in machine readable storage device.Operation can be in data processing equipment
Primitive ring it is domestic or executed in the one or more virtual machines or container by data processing equipment trustship.
Computer program (also referred to as program, software, software application, script or code) can be in any form programming
Language is write, including compiling or interpretative code, and declaratively or procedural language, and it can be disposed in any form, including makees
It is independent program or as module, component, subprogram, object or the suitable other units used in a computing environment.Meter
Calculation machine program can with but not necessarily correspond to the file in file system.Program, which can be stored in, preserves other programs or data
In a part for the file of (for example, being stored in one or more of marking language document script), it is exclusively used in discussed journey
In the single file of sequence, or multiple coordination files are stored in (for example, the one or more modules of storage, subprogram or part generation
The file of code) in.Computer program can be deployed as being distributed positioned at a website or across multiple websites and passing through communication network
It is executed on the computer or multiple stage computers or one or more virtual machine or container of network interconnection.The example packet of communication network
LAN (" LAN ") and wide area network (" WAN ") are included, inter-network network (such as internet) and peer-to-peer network are (for example, point-to-point equity
Network).
Process and logic flow described in this specification can by execute one of one or more computer programs or
Multiple programmable processors execute, to execute action by being operated to input data and generating output.It handles and patrols
Collecting flow can also be by dedicated logic circuit --- such as FPGA (field programmable gate array) or ASIC (special integrated electricity
Road) --- to execute, and device can also be implemented as dedicated logic circuit.
Although this specification includes many concrete implementation details, these be not construed as to any invention or
The limitation for the range that person can be claimed, but as the description of feature specific to the particular implementation of specific invention.
Certain features described in the context (context) of independent embodiment can also be in single embodiment in the present specification
In realize in combination.On the contrary, the various features described in the context of single embodiment can also be in multiple embodiments
Individually or with any suitable sub-portfolio realize.In addition, although can describe feature as acting as with certain combinations above
With and it is even initially so claimed, but the one or more features from combination claimed are in some cases
Under can be deleted from the combination, and combination claimed can be related to the variation of sub-portfolio or sub-portfolio.
Similarly, although depicting operation in a particular order in the accompanying drawings, this be understood not to require with
Shown particular order or the such operation of execution in sequential order, or to execute the operation of all diagrams and it is expected with realizing
Result.In some cases, it may be advantageous for multitask and parallel processing.Moreover, each germline in the above embodiment
The separation of system component should not be construed as being required for such separation in all embodiments, and it is to be understood that described
Program assembly and system usually can be integrated in single software product or be encapsulated into multiple software product together.
Inclusive can be interpreted to the reference of "or" so that any term described using "or" can indicate to retouch
It is any one of single, more than one and all in the term stated.Label " first ", " second ", " third " etc. no
It is certain to mean instruction sequence, and be generally used only for distinguishing similar or similar project or element.
Various modifications for the embodiment described in the disclosure may be aobvious to those skilled in the art
And be clear to, and without departing from the spirit or the scope of the present disclosure, it can be by generic principles defined herein application
In other embodiment.Therefore, claim is not limited to embodiment shown in this article, but will be endowed and this public affairs
It opens, the widest range that principle disclosed herein is consistent with novel feature.
Claims (16)
1. a kind of network equipment, including：
Network interface card；
At least one processor；
The memory of storage transportation protocol module；And
Network interface driver；Wherein, the transport protocol module includes computer executable instructions, and the computer is executable
Instruction causes at least one processor when being executed by least one processor：
Packet is received from remote computing device,
Packet acknowledgement message is generated,
And wherein, the network interface driver includes computer executable instructions, the computer executable instructions by
At least one processor causes at least one processor when executing：
The packet acknowledgement message is received from the transport protocol module,
It is directed to the packet acknowledgement message based at least one rate limit strategy associated with received data grouping
Determine transmission time,
Identifier associated with the packet acknowledgement message is stored in the time index in time index data structure
In data structure with for the associated position of the transmission time determined by the packet acknowledgement message at,
Determination has reached the time indexed in the time index data structure, and
By the network interface card transmit be stored in the time index data structure with the time correlation that is reached
The associated packet acknowledgement message of identifier at the position of connection.
2. the network equipment according to claim 1, wherein the network interface driver is configured as in virtual machine, holds
It is executed in one of device performing environment or in the real system of network host.
3. the network equipment according to claim 1, wherein at least one rate limit strategy is and the number that is received
According to the associated rate pacing strategy of grouping or targeted rate limitation.
4. the network equipment according to claim 1, wherein the computer executable instructions of the transport protocol module
Further result in that at least one processor generates the transmission time of request for the packet acknowledgement message.
5. the network equipment according to claim 4, wherein the computer of the network interface driver is executable to be referred to
Order further results in that at least one processor based at least one rate limit strategy associated with the grouping received
It is exceeded and calls rate-limiting algorithm associated with received data grouping to determine newer transmission time.
6. the network equipment according to claim 1, wherein the computer of the network interface driver is executable to be referred to
Order further results in that at least one processor is associated with received data grouping to identify using hash table or mapping
At least one rate limit strategy.
7. the network equipment according to claim 1, wherein the computer of the network interface driver is executable to be referred to
Order executes in dedicated cpu core.
8. the network equipment according to claim 1, wherein the transport protocol module includes Transmission Control Protocol module, and institute
It includes TCP ACK messages to state packet acknowledgement message.
9. a kind of method, including：
At the transport protocol module of the network equipment packet is received from remote computing device；
Packet acknowledgement message is generated by the transport protocol module；
The packet acknowledgement message is received by the network interface driver of the network equipment；
It is directed to the packet acknowledgement message based at least one rate limit strategy associated with received data grouping
Determine transmission time；
It, will be related to the packet acknowledgement message in time index data structure for the packet acknowledgement message to be transmitted
The identifier of connection is stored in the time index data structure and is directed to the transmission determined by the packet acknowledgement message
At the position of time correlation connection；
The time for having reached and being indexed in the time index data structure is determined by the network interface driver；And
By network interface card transmit be stored in the time index data structure with reached time correlation connection
The associated packet acknowledgement message of identifier at position.
10. according to the method described in claim 9, wherein, the network interface driver is configured as holding in virtual machine, container
It is executed in one of row environment or in the real system of network host.
11. according to the method described in claim 9, wherein, at least one rate limit strategy is received with described
The associated rate pacing strategy of packet or targeted rate limitation.
12. according to the method described in claim 9, wherein, the transport protocol module is further configured to for described point
Group acknowledge message generates the transmission time of request.
13. according to the method described in claim 9, wherein, determining that transmission time is further wrapped for each packet acknowledgement message
It includes：
It is exceeded based at least one rate limit strategy and calls rate limit associated with received data grouping
Algorithm determines newer transmission time.
14. according to the method for claim 13, further comprising：It is linked to rate-limiting algorithm using by packet
Hash table maps to find associated rate-limiting algorithm.
15. according to the method described in claim 9, wherein, the method is performed on dedicated cpu kernel.
16. according to the method described in claim 9, wherein, the transport protocol module includes Transmission Control Protocol module, and described
Packet acknowledgement message includes TCP ACK messages.
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US15/411,335 | 2017-01-20 | ||
US15/411,335 US20180212885A1 (en) | 2017-01-20 | 2017-01-20 | Device and method for scalable traffic shaping at a receiver with a time-indexed data structure |
Publications (2)
Publication Number | Publication Date |
---|---|
CN108337186A true CN108337186A (en) | 2018-07-27 |
CN108337186B CN108337186B (en) | 2023-05-30 |
Family
ID=60543682
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201711331943.2A Active CN108337186B (en) | 2017-01-20 | 2017-12-13 | Apparatus and method for scalable traffic shaping |
Country Status (4)
Country | Link |
---|---|
US (1) | US20180212885A1 (en) |
CN (1) | CN108337186B (en) |
DE (2) | DE202017106795U1 (en) |
WO (1) | WO2018136132A1 (en) |
Cited By (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN111970149A (en) * | 2020-08-17 | 2020-11-20 | 浪潮云信息技术股份公司 | Shared bandwidth realizing method based on hardware firewall QOS |
CN112041826A (en) * | 2018-09-28 | 2020-12-04 | 谷歌有限责任公司 | Fine-grained traffic shaping offload for network interface cards |
CN112804115A (en) * | 2019-11-14 | 2021-05-14 | 北京华为数字技术有限公司 | Method, device and equipment for detecting abnormity of virtual network function |
CN113301605A (en) * | 2021-05-18 | 2021-08-24 | 成都欧珀通信科技有限公司 | Message transmission method, system and related device |
CN115150327A (en) * | 2022-06-29 | 2022-10-04 | 济南浪潮数据技术有限公司 | Interface setting method, device, equipment and medium |
Families Citing this family (16)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20190044809A1 (en) | 2017-08-30 | 2019-02-07 | Intel Corporation | Technologies for managing a flexible host interface of a network interface controller |
CA3074282A1 (en) | 2017-08-31 | 2019-03-07 | Pensando Systems Inc. | Methods and systems for network congestion management |
US11038807B2 (en) * | 2018-09-14 | 2021-06-15 | Fungible, Inc. | Timer management for network devices |
US10944852B2 (en) * | 2019-04-23 | 2021-03-09 | Cisco Technology, Inc. | Computer network packet transmission timing |
US11212227B2 (en) | 2019-05-17 | 2021-12-28 | Pensando Systems, Inc. | Rate-optimized congestion management |
EP4014446B1 (en) * | 2019-08-14 | 2024-05-15 | Telefonaktiebolaget LM Ericsson (publ) | Techniques for adaptive bitrate video traffic shaping |
US11153221B2 (en) * | 2019-08-28 | 2021-10-19 | Pensando Systems Inc. | Methods, systems, and devices for classifying layer 4-level data from data queues |
US10873533B1 (en) | 2019-09-04 | 2020-12-22 | Cisco Technology, Inc. | Traffic class-specific congestion signatures for improving traffic shaping and other network operations |
US10917352B1 (en) | 2019-09-04 | 2021-02-09 | Cisco Technology, Inc. | Selective tracking of acknowledgments to improve network device buffer utilization and traffic shaping |
US11321135B2 (en) * | 2019-10-31 | 2022-05-03 | Oracle International Corporation | Rate limiting compliance assessments with multi-layer fair share scheduling |
CN111092907B (en) * | 2019-12-30 | 2021-09-03 | 人和未来生物科技（长沙）有限公司 | UDP (user Datagram protocol) -based data stream fast transmission method, system and medium |
US11394700B2 (en) | 2020-01-31 | 2022-07-19 | Pensando Systems Inc. | Proxy service through hardware acceleration using an IO device |
US11431681B2 (en) | 2020-04-07 | 2022-08-30 | Pensando Systems Inc. | Application aware TCP performance tuning on hardware accelerated TCP proxy services |
US20220201066A1 (en) * | 2020-12-22 | 2022-06-23 | Microsoft Technology Licensing, Llc | Proactive placement of virtualized computing resources and tuning of network resources based on seasonal variations |
US11196710B1 (en) * | 2021-02-05 | 2021-12-07 | Lookingglass Cyber Solutions, Inc. | Systems and methods for monitoring and securing networks using a shared buffer |
US20220086100A1 (en) * | 2021-11-24 | 2022-03-17 | Intel Corporation | Egress packet scheduling |
Citations (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
EP1441474A2 (en) * | 2003-01-24 | 2004-07-28 | Microsoft Corporation | Pacing network packet transmission using at least partially uncorrelated network events |
US20110228697A1 (en) * | 2010-03-19 | 2011-09-22 | Hitachi, Ltd. | Mobile Communication System and Communication Method |
CN103229465A (en) * | 2012-11-12 | 2013-07-31 | 华为技术有限公司 | Message sending method and device |
US20140032955A1 (en) * | 2012-03-31 | 2014-01-30 | Joshua Boelter | Method, device, and system for delaying packets during a network-triggered wake of a computing device |
CN104184677A (en) * | 2013-05-24 | 2014-12-03 | 中兴通讯股份有限公司 | Traffic shaping drive method and driver |
Family Cites Families (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6894974B1 (en) * | 2000-05-08 | 2005-05-17 | Nortel Networks Limited | Method, apparatus, media, and signals for controlling packet transmission rate from a packet source |
US20030152096A1 (en) * | 2002-02-13 | 2003-08-14 | Korey Chapman | Intelligent no packet loss networking |
US7236459B1 (en) * | 2002-05-06 | 2007-06-26 | Packeteer, Inc. | Method and apparatus for controlling data transmission volume using explicit rate control and queuing without data rate supervision |
GB0517304D0 (en) * | 2005-08-23 | 2005-10-05 | Netronome Systems Inc | A system and method for processing and forwarding transmitted information |
-
2017
- 2017-01-20 US US15/411,335 patent/US20180212885A1/en not_active Abandoned
- 2017-11-07 WO PCT/US2017/060308 patent/WO2018136132A1/en active Application Filing
- 2017-11-09 DE DE202017106795.5U patent/DE202017106795U1/en active Active
- 2017-11-09 DE DE102017126197.4A patent/DE102017126197A1/en active Granted
- 2017-12-13 CN CN201711331943.2A patent/CN108337186B/en active Active
Patent Citations (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
EP1441474A2 (en) * | 2003-01-24 | 2004-07-28 | Microsoft Corporation | Pacing network packet transmission using at least partially uncorrelated network events |
US20110228697A1 (en) * | 2010-03-19 | 2011-09-22 | Hitachi, Ltd. | Mobile Communication System and Communication Method |
US20140032955A1 (en) * | 2012-03-31 | 2014-01-30 | Joshua Boelter | Method, device, and system for delaying packets during a network-triggered wake of a computing device |
CN103229465A (en) * | 2012-11-12 | 2013-07-31 | 华为技术有限公司 | Message sending method and device |
CN104184677A (en) * | 2013-05-24 | 2014-12-03 | 中兴通讯股份有限公司 | Traffic shaping drive method and driver |
Cited By (10)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN112041826A (en) * | 2018-09-28 | 2020-12-04 | 谷歌有限责任公司 | Fine-grained traffic shaping offload for network interface cards |
US11831550B2 (en) | 2018-09-28 | 2023-11-28 | Google Llc | Fine grain traffic shaping offload for a network interface card |
CN112041826B (en) * | 2018-09-28 | 2024-03-29 | 谷歌有限责任公司 | Fine-grained traffic shaping offload for network interface cards |
CN112804115A (en) * | 2019-11-14 | 2021-05-14 | 北京华为数字技术有限公司 | Method, device and equipment for detecting abnormity of virtual network function |
CN112804115B (en) * | 2019-11-14 | 2022-04-12 | 北京华为数字技术有限公司 | Method, device and equipment for detecting abnormity of virtual network function |
CN111970149A (en) * | 2020-08-17 | 2020-11-20 | 浪潮云信息技术股份公司 | Shared bandwidth realizing method based on hardware firewall QOS |
CN111970149B (en) * | 2020-08-17 | 2023-05-30 | 浪潮云信息技术股份公司 | Shared bandwidth implementation method based on hardware firewall QOS |
CN113301605A (en) * | 2021-05-18 | 2021-08-24 | 成都欧珀通信科技有限公司 | Message transmission method, system and related device |
CN113301605B (en) * | 2021-05-18 | 2023-03-24 | 成都欧珀通信科技有限公司 | Message transmission method, system and related device |
CN115150327A (en) * | 2022-06-29 | 2022-10-04 | 济南浪潮数据技术有限公司 | Interface setting method, device, equipment and medium |
Also Published As
Publication number | Publication date |
---|---|
WO2018136132A1 (en) | 2018-07-26 |
US20180212885A1 (en) | 2018-07-26 |
CN108337186B (en) | 2023-05-30 |
DE102017126197A1 (en) | 2018-07-26 |
DE202017106795U1 (en) | 2018-02-19 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN108337186A (en) | Device and method for scalable traffic shaping | |
CN108337185A (en) | The device and method of scalable traffic shaping with time index data structure | |
US10116574B2 (en) | System and method for improving TCP performance in virtualized environments | |
CN104081736B (en) | The system and method for schedule packet transmissions on client device | |
TWI262690B (en) | Method and system for transmit scheduling for multi-layer network interface controller (NIC) operation | |
CN112041826B (en) | Fine-grained traffic shaping offload for network interface cards | |
US20040117794A1 (en) | Method, system and framework for task scheduling | |
US20120054362A1 (en) | Mechanism for autotuning mass data transfer from a sender to a receiver over parallel connections | |
CN107181698B (en) | System and method for single queue multi-stream traffic shaping | |
CN109412958A (en) | The jamming control method and device of data center | |
Li et al. | OPTAS: Decentralized flow monitoring and scheduling for tiny tasks | |
Huang et al. | ARS: Cross-layer adaptive request scheduling to mitigate TCP incast in data center networks | |
Wu et al. | Potential performance bottleneck in Linux TCP | |
Guo et al. | IEEE SA Industry Connections-IEEE 802 Nendica Report: Intelligent Lossless Data Center Networks | |
Hu et al. | Queueing model based analysis on flow scheduling in information-agnostic datacenter networks | |
Shen et al. | Rendering differential performance preference through intelligent network edge in cloud data centers | |
Wang et al. | An Incast-Coflow-Aware Minimum-Rate-Guaranteed Congestion Control Protocol for Datacenter Applications | |
Liu et al. | Flow Scheduling Strategies for Minimizing Flow Completion Times in Information-agnostic Data Center Networks | |
Shewmaker | Network congestion and performance management |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
REG | Reference to a national code |
Ref country code: HKRef legal event code: DERef document number: 1259197Country of ref document: HK |
|
GR01 | Patent grant | ||
GR01 | Patent grant |