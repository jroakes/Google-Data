EP1904974B1 - Apparatuses, computer program product, and method for digital image processing - Google Patents
Apparatuses, computer program product, and method for digital image processing Download PDFInfo
- Publication number
- EP1904974B1 EP1904974B1 EP06743560A EP06743560A EP1904974B1 EP 1904974 B1 EP1904974 B1 EP 1904974B1 EP 06743560 A EP06743560 A EP 06743560A EP 06743560 A EP06743560 A EP 06743560A EP 1904974 B1 EP1904974 B1 EP 1904974B1
- Authority
- EP
- European Patent Office
- Prior art keywords
- digital image
- block
- motion
- search area
- errors
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Not-in-force
Links
Images
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/50—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding
- H04N19/503—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding involving temporal prediction
- H04N19/51—Motion estimation or motion compensation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T7/00—Image analysis
- G06T7/20—Analysis of motion
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T7/00—Image analysis
- G06T7/20—Analysis of motion
- G06T7/223—Analysis of motion using block-matching
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/60—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using transform coding
- H04N19/61—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using transform coding in combination with predictive coding
Definitions
- the invention relates to a digital image processing apparatus, an arrangement for digital image processing, a computer program product for digital image processing, embodied on a distribution medium, an integrated digital image processing circuit, and a method for defining motion between digital images.
- the best solution would probably be not to divide the image into blocks, but to estimate one vector for the whole image, calculating for instance about 1089 pixel differences for one single pixel in a search area of ⁇ 16. Again, for a cif-sized image, it would be about 80 million operations.
- the second solution leads to a stuffing problem: how the stuffing should be done without breaking the image?
- the third solution is simply annoying because of the zooming effect and besides, it requires even more calculation.
- the first solution is described in more detail later on.
- US 5,926,212 describes a first digital image and a second digital image each having at least one block.
- a camera shake motion vector is detected based on difference values between the blocks of the two images.
- a motion compensation is used on the image data to correct a camera shake detected from the camera shake motion vector.
- Gunnar Thalin Deshaker - a video stabilizer for VirtualDub, Version 1.6, Released 24.11.2003 , describes a video stabilizer to eliminate camera shakiness and make panning, rotation and zooming smoother.
- the present invention seeks to provide an improved digital image processing apparatus, an improved arrangement for digital image processing, an improved computer program product for digital image processing, embodied on a distribution medium, an improved integrated digital image processing circuit, and an improved method for defining motion between digital images.
- a digital image processing apparatus comprising: an input interface to obtain a first digital image and a second digital image; and a processing unit coupled with the input interface to define at least one block in the first digital image, to define for each block a search area in the second digital image, the search area being larger than the block, to map the block and its search area to an equal size, to calculate pixelwise errors between each block and its search area that are mapped to an equal size, to collect the errors into a motion register, and to define a motion between the first digital image and the second digital image by utilizing the motion register.
- an arrangement for digital image processing comprising: means for obtaining a first digital image and a second digital image; means for defining at least one block in the first digital image; means for defining for each block a search area in the second digital image, the search area being larger than the block; means for mapping the block and its search area to an equal size; means for calculating pixelwise errors between each block and its search area that are mapped to an equal size; means for collecting the errors into a motion register; and means for defining a motion between the first digital image and the second digital image by utilizing the motion register.
- a computer program product for digital image processing embodied on a distribution medium and comprising: an input module to obtain a first digital image and a second digital image; and a computing module coupled with the input module to define at least one block in the first digital image, to define for each block a search area in the second digital image, the search area being larger than the block, to map the block and its search area to an equal size, to calculate pixelwise errors between each block and its search area that are mapped to an equal size, to collect the errors into a motion register, and to define a motion between the first digital image and the second digital image by utilizing the motion register.
- an integrated digital image processing circuit comprising: an input block to obtain a first digital image and a second digital image; and a processing block coupled with the input block to define at least one block in the first digital image, to define for each block a search area in the second digital image, the search area being larger than the block, to map the block and its search area to an equal size, to calculate pixelwise errors between each block and its search area that are mapped to an equal size, to collect the errors into a motion register, and to define a motion between the first digital image and the second digital image by utilizing the motion register.
- a method for defining motion between digital images comprising: obtaining a first digital image and a second digital image; defining at least one block in the first digital image; defining for each block a search area in the second digital image, the search area being larger than the block; mapping the block and its search area to an equal size; calculating pixelwise errors between each block and its search area that are mapped to an equal size; collecting the errors into a motion register; and defining a motion between the first digital image and the second digital image by utilizing the motion register.
- the invention provides several advantages. It provides a reliable calculation method for global motion vector with less calculations and low memory needs: the invention is not dependent on the traditional and slow motion estimation, which requires heavy calculation.
- the invention also offers a fast and low-memory video stabilization solution when connected to a video encoding system.
- the invention also offers a solution for predictive motion estimation with the global motion vector, local motion vectors and a topographic map of motion.
- the predictive motion estimation is used for example in video codecs, where motion estimation searches need to be minimized by predicting the most probable motion vector, with which the search process is then started to provide a good reference block for a limited amount of searches.
- the invention also provides a global motion vector or a map of predictive vectors for a motion estimation phase of a video encoding system to efficiently find a motion vector for a single block.
- a source of inspiration was a map of Finland on the wall of the inventor's workroom. Realizing that there is one and only one point on the map that lies over the same spot that it represents, the inventor created the following general motion vector calculation method.
- the method utilizes a pair of "maps" taken from consecutive images of a video sequence, for instance: a "map" of a search area and a "map" of a block, whose scales differ from each other, forming the map situation mentioned above. If a map has one and only one pixel that represents the spot where it lies, then, when computing differences between two differently scaled maps, that spot is zero, for the pixel's difference to itself is zero. Even if it is not that simple in reality, because video images not only move but also change, the theory is suitable and efficient when numerous maps are combined together.
- Figure 1A describes an overall simplified scene of the global motion vector definition process: when defining a global motion vector between two consecutive digital images or frames, a previous frame 100 and a present frame 102 on the video sequence, the present image 102 is divided into blocks 104, and for each block 104 a search area 106 wider than the block 104 is defined in the previous image 100. The block 104 is then expanded into the size of the search area 106 forming an "inverse" map 108 of the block 104. "inverse" here refers to the fact that normally a map is smaller than the area it represents, while in the present case, the map 108 is actually larger than the block 104.
- the algorithm calculates absolute difference values 110 of the related pixels of these two pixel matrices 106 and 108 and arranges them into the motion register 112.
- a topographic map of the motion between frames 100 and 102 is formed into the register 112, where the minimum value shows the desired global motion vector between the frames.
- this brings a minor problem: how to deal with the edge blocks of frame 102 when the search area 106 exceeds the edge of frame 100? Fortunately, there are several practical solutions: to copy the edge pixels of frame 100 to fill the search area or to ignore the edge blocks of frame 102 when the frame 102 is large enough, etc.
- the present image 102 and the previous image 100 may be in the opposite order: the backward “motion estimation” is then just turned into the forward "motion estimation”.
- the reference image i.e. previous image, may also be any other frame for which the global motion vector is to be defined.
- the expansion may be virtual, so that the difference calculation process runs the pixels of the block and search area in different phases. Also, different interpolation methods in block expansion should be taken into account, at least when the search area is not a multiple of the block.
- Other functions may also be used, quadratic functions, for example, which are also efficient in motion estimation algorithms.
- Figure 1B illustrates how the previously explained theory works in practice.
- 102 illustrates a present frame with a person in it and 100 illustrates a previous frame where the person is in a slightly different position.
- a cross section 118 of luminance data 107 at the person's eye level is shown, when a block 103 is processed.
- the corresponding eye-level cross section 116 is selected inside the search area 105, and the cross section 116 of luminance data 109 is shown.
- the expansion of 107 is shown as 108.
- These two luminance data elements 108, 109 are combined as 111, where the absolute difference is calculated and added into a motion register 112.
- the motion register gathers the difference information of every block and search area and the topographic map of motion grows block-by-block. Finally, after every block is processed, the motion register 114 shows where the global motion vector is.
- the map of a block does not necessarily show exactly where the global motion vector is, because the map 112 may contain several minimum values, i.e. possible candidates for a motion vector. In the places where the volume of the map grows larger, the possibility for the existence of a motion vector decreases. -
- Figure 2 shows the connection between the topographic map in the motion register and motion vectors as a chart.
- the block size 200 is 3x3 pixels and the search area 202 is 15x15 pixels.
- top values 204 stand for horizontal motion vectors and left values 206 stand for vertical motion vectors.
- the location of the map's minimum value shows the motion vector, which can easily be read from the chart's edge values, or calculated in an application.
- the minimum value may also be found without filtering or with a different filter. However, filtering is assumed to be a more secure way to finding the minimum value.
- the method starts from 300.
- initializations are made; they may contain definitions for block size, search area size, etc.
- the register for motion map is initialized to neutral.
- An optional block selection may be made in 305, with feature or detail detection, for example.
- the block data is read.
- the block data may be in luminance, chrominances Cb or Cr, red, blue, or in whatever digital color format.
- the search area data is read from the other image around the position of the block.
- the block is then (virtually) enlarged to the size of the search area and their difference is calculated pixel by pixel in 310, and the difference is then saved into the motion register 312.
- the loop 306, 308, 310, and 312 repeats until there are no more blocks left 314.
- the minimum value is searched from the motion register and a general motion vector is then defined with it.
- an optional feature 318 follows, which may be for example stabilization or predictive motion estimation in a video encoder.
- the method loops frame pairs until there are no more frames left 320, whereupon the method is stopped in 322.
- FIGs 4, 5A, 5B, 6A, and 6B illustrate the use of a global motion vector for stabilization purposes.
- a person is standing in front of the text "HANTRO OULU".
- a frame 402 defines a filming scene of the camera.
- An image scene 404 is found inside the filming scene 402 and it is conveyed into an application, a video codec, for instance.
- the area 406 is a difference of the sizes between frames 402 and 404 and it is the area where frame 404 can move freely, i.e. where the stabilization is most efficient. Basically, the larger the area 406, the better the stabilization result.
- Figures 5A and 5B illustrate the effect of the camera motion on the filming scene 402 and the image scene 404.
- Figure 5A illustrates the situation at the beginning, i.e. the first image, in which the image scene 502 is inside and in the middle of the filming scene 500.
- Figure 5B illustrates the following image, in which the camera has moved to the right in the direction of arrow 504, and the person to be filmed has disturbingly shifted to the left side of the image scene and of the filming scene 506.
- Figures 5A and 5B thus illustrate how the image is impaired due to the unintended camera motion, if no motion compensation is available.
- Figures 6A and 6B illustrate the compensation of camera motion by employing the described method for motion definition.
- the contents of Figure 6A correspond to the contents of Figure 5A .
- the direction and magnitude of the camera motion between the filming scene, i.e. previous image 500 in Figure 5A , and image scene, i.e. present image 506 in Figure 5B is calculated and a global motion vector is obtained.
- our example only includes the horizontal camera motion 504, which is actually the same as the global motion vector, but opposite.
- the camera motion is compensated by moving the image scene 508 inside the filming scene 506 with an (opposite) global motion vector.
- Figure 7 shows the actual phases of the scenes 400, 402, and 404 in a camera/stabilization/video encoder system.
- a person 700 stands in front of the camera 702 and this illustrates the scene 400. But the camera shoots only a limited area 402 of that view, which is taken into the stabilization phase 704.
- the stabilization is then performed between the present filming scene 402 and the previous frame's filming scene 402-2.
- the image scene 404 is taken to the video encoder 710 and the present image's filming scene 402 replaces the previous image's filming scene 402-2.
- Figure 7 also illustrates the overall scene of the predictive motion estimation arrangement, where the global motion vector 706 is delivered to an encoder 710. Then, the filming scene 404 in the video encoder may be replaced by an unstabilized image scene 402.
- the digital image processing apparatus comprises an input interface 712 to obtain a first digital image and a second digital image, and a processing unit 704 (and possibly also 710) coupled with the input interface 712.
- the processing unit 704 defines at least one block in the first digital image, defines for each block a search area in the second digital image, the search area being larger than the block, maps the block and its search area to an equal size, calculates pixelwise errors between each block and its search area that are mapped to an equal size, collects the errors into a motion register, and defines a motion between the first digital image and the second digital image by utilizing the motion register.
- the digital image processing apparatus may be implemented as one or more integrated circuits, such as application-specific integrated circuits ASIC.
- One embodiment is a computer program product for digital image processing, embodied on a distribution medium.
- the described functionality/structures may be implemented as software modules.
- the distribution medium may be any means for distributing software to customers, such as a (computer readable) program storage medium, a (computer readable) memory, a (computer readable) software distribution package, a (computer readable) signal, or a (computer readable) telecommunications signal.
- Figure 8 illustrates the (mpeg-4 type) encoder 710 more closely.
- First input image 708 arrives from a stabilization phase into the frame buffer 800, from where it continues block by block into encoding phases 802, whose details need not be specified here, because the stabilization is independent of the encoding implementation.
- the encoded image is rearranged into a second frame buffer 804.
- the motion estimation block 806 begins to estimate the motion, synchronized block-by-block to the encoding phase 802, between the first and second images 804, 800.
- the block to be encoded is taken from image 800 and the reference block, i.e. search area, is taken from image 804.
- full search methods are used in motion estimation, which means that a block is fitted into a search area with every possible motion vector starting from the upper left corner, for instance. Afterwards, a best match is selected for a reference block.
- the motion estimation block gets a global motion vector 706 from the stabilization. The motion estimation starts by using the global motion vector, and ends if a good reference block is found instantly.
- the selected motion vector 808 is conveyed to a variable-length coder 810, whose output 812 provides compressed data.
- Figure 9 illustrates the usage of a global motion vector in the motion estimation of an encoder.
- Frame 900 represents a reference frame, from which the reference block will be taken to encode a block.
- Block 902 represents the location of a block (to be encoded) in a reference frame 900, i.e. a zero location.
- a limited search area 904 Around the zero location is a limited search area 904, which is typically a multiple of the size of block 902.
- the arrow 906 is the global motion vector calculated for a frame to be encoded and reference frame 900. So the most probable reference block for a block to be coded is found at the location 908, to which the global motion vector 906 points.
- the procedure may continue by checking the second lowest value from the map, the third lowest value, and so on. Local minimums usually also point to a local motion vector, so they can be checked too.
- a mpeg-4 standard offers for a luminance frame a 16x16 pixel macroblock, which comprises four 8x8 pixel blocks.
Description
- The invention relates to a digital image processing apparatus, an arrangement for digital image processing, a computer program product for digital image processing, embodied on a distribution medium, an integrated digital image processing circuit, and a method for defining motion between digital images.
- Undesired movement of the camera used for filming, caused by shaking of the cameraman's hands, for instance, is a big and widely studied problem in video research area. Various mechanical and electronic solutions have been designed for stabilizing video images, since a stable video looks much more pleasant than a video that sways, shakes and wanders around. Also, in video coding, a stable video stream requires much less bit rate or disc space, not to mention coding efficiency or speed.
- Great results have been achieved with mechanical solutions, such as acceleration sensors, but because of their unacceptable prize and need for space, they are unsuitable for many video filming devices, like mobile phones. Digital video stabilization, especially real-time video stabilization, which is needed for the above-mentioned mobile phones, for instance, has been a goal beyond reach for a long time.
- Digital video stabilization concerns solving two problems:
- 1) How to define a single global motion vector between two consecutive video frames? So far, there has not been an unambiguous solution to this problem. One can always calculate a best local motion vector for every block of moving image, but the calculation of a global motion vector still remains. Concerning all the possible situations, it is clear that there is no algorithm that can perfectly define the global motion vector from the local ones in every case. In any case, this is a widely used solution with the great disadvantage of heavy calculation caused by the motion estimation. For a cif-sized image, a motion estimation with 16x16 blocks and a ±16 search area would require (16x16x33x33x369) about 100 million operations!
- The best solution would probably be not to divide the image into blocks, but to estimate one vector for the whole image, calculating for instance about 1089 pixel differences for one single pixel in a search area of ±16. Again, for a cif-sized image, it would be about 80 million operations.
- Attempts have been made to reduce the heavy calculation of motion estimation by decreasing the amount of used blocks in a motion estimation phase by detecting strong details or features from a single image and processing the motion estimation only for them. However, it is then inevitable that this decreases the reliability of the algorithm while feature detection increases the calculations.
- 2) How to stabilize the video with an offered global motion vector? Basically, there are three different solutions to this problem: (1) canceling the motion by moving the next image frame to a direction opposite to the global motion vector; (2) filtering the motion with Kalman filtering or FIR-filtering, for example, and canceling the motion after that; (3) zooming the image to achieve the motion canceling effect with the global motion vector, as described in
US 5,317,685 , for instance. The first two solutions require a larger image within which the stabilized image moves. The first solution suffers from discontinuations when the inner image achieves the edge of the outer image, and the second solution requires more calculation because of the filtering and image stuffing when the inner image exceeds the edge of the outer one. Furthermore, the second solution leads to a stuffing problem: how the stuffing should be done without breaking the image? The third solution is simply annoying because of the zooming effect and besides, it requires even more calculation. The first solution is described in more detail later on.
US 5,926,212 describes a first digital image and a second digital image each having at least one block. A camera shake motion vector is detected based on difference values between the blocks of the two images. A motion compensation is used on the image data to correct a camera shake detected from the camera shake motion vector.
Another publication, Gunnar Thalin: Deshaker - a video stabilizer for VirtualDub, Version 1.6, Released 24.11.2003, describes a video stabilizer to eliminate camera shakiness and make panning, rotation and zooming smoother. It further describes using blocks of pixels in two images and finding a shift (motion vector) that makes the blocks match. The shift finding starts from scale-reduced images and scales up in each iteration until the full scale is reached. An optimal camera motion is then calculated from the shifts. - The present invention seeks to provide an improved digital image processing apparatus, an improved arrangement for digital image processing, an improved computer program product for digital image processing, embodied on a distribution medium, an improved integrated digital image processing circuit, and an improved method for defining motion between digital images.
- According to an aspect of the invention, there is provided a digital image processing apparatus, comprising: an input interface to obtain a first digital image and a second digital image; and a processing unit coupled with the input interface to define at least one block in the first digital image, to define for each block a search area in the second digital image, the search area being larger than the block, to map the block and its search area to an equal size, to calculate pixelwise errors between each block and its search area that are mapped to an equal size, to collect the errors into a motion register, and to define a motion between the first digital image and the second digital image by utilizing the motion register.
- According to another aspect of the invention, there is provided an arrangement for digital image processing, comprising: means for obtaining a first digital image and a second digital image; means for defining at least one block in the first digital image; means for defining for each block a search area in the second digital image, the search area being larger than the block; means for mapping the block and its search area to an equal size; means for calculating pixelwise errors between each block and its search area that are mapped to an equal size; means for collecting the errors into a motion register; and means for defining a motion between the first digital image and the second digital image by utilizing the motion register.
- According to another aspect of the invention, there is provided a computer program product for digital image processing, embodied on a distribution medium and comprising: an input module to obtain a first digital image and a second digital image; and a computing module coupled with the input module to define at least one block in the first digital image, to define for each block a search area in the second digital image, the search area being larger than the block, to map the block and its search area to an equal size, to calculate pixelwise errors between each block and its search area that are mapped to an equal size, to collect the errors into a motion register, and to define a motion between the first digital image and the second digital image by utilizing the motion register.
- According to another aspect of the invention, there is provided an integrated digital image processing circuit, comprising: an input block to obtain a first digital image and a second digital image; and a processing block coupled with the input block to define at least one block in the first digital image, to define for each block a search area in the second digital image, the search area being larger than the block, to map the block and its search area to an equal size, to calculate pixelwise errors between each block and its search area that are mapped to an equal size, to collect the errors into a motion register, and to define a motion between the first digital image and the second digital image by utilizing the motion register.
- According to another aspect of the invention, there is provided a method for defining motion between digital images, comprising: obtaining a first digital image and a second digital image; defining at least one block in the first digital image; defining for each block a search area in the second digital image, the search area being larger than the block; mapping the block and its search area to an equal size; calculating pixelwise errors between each block and its search area that are mapped to an equal size; collecting the errors into a motion register; and defining a motion between the first digital image and the second digital image by utilizing the motion register.
- The invention provides several advantages. It provides a reliable calculation method for global motion vector with less calculations and low memory needs: the invention is not dependent on the traditional and slow motion estimation, which requires heavy calculation. The invention also offers a fast and low-memory video stabilization solution when connected to a video encoding system. The invention also offers a solution for predictive motion estimation with the global motion vector, local motion vectors and a topographic map of motion. The predictive motion estimation is used for example in video codecs, where motion estimation searches need to be minimized by predicting the most probable motion vector, with which the search process is then started to provide a good reference block for a limited amount of searches. The invention also provides a global motion vector or a map of predictive vectors for a motion estimation phase of a video encoding system to efficiently find a motion vector for a single block.
- In the following, the invention will be described in greater detail with reference to the embodiments and the accompanying drawings, in which
-
Figure 1A is an overview of the general motion definition method; -
Figure 1B illustrates the method's theory in practice; -
Figure 2 is a table illustrating the relation between a motion map and motion vectors; -
Figure 3 is a block diagram illustrating the general motion definition method; -
Figure 4 illustrates filming and image scenes in video stabilization; -
Figures 5A and 5B illustrate how a moving camera affects the filming scene and image scene; -
Figures 6A and 6B illustrate the compensation of a camera motion; -
Figure 7 illustrates a digital image processing apparatus and also shows how it relates to a video source; -
Figure 8 is an overview of a video encoder; and -
Figure 9 illustrates the usage of a global motion vector in the motion estimation of an encoder. - A source of inspiration was a map of Finland on the wall of the inventor's workroom. Realizing that there is one and only one point on the map that lies over the same spot that it represents, the inventor created the following general motion vector calculation method.
- This method, unlike the others, is not related to a prior art motion estimation algorithm at all, but introduces a totally new and different approach for global motion vector calculation. Based on the above-mentioned interesting fact about the maps, the method utilizes a pair of "maps" taken from consecutive images of a video sequence, for instance: a "map" of a search area and a "map" of a block, whose scales differ from each other, forming the map situation mentioned above. If a map has one and only one pixel that represents the spot where it lies, then, when computing differences between two differently scaled maps, that spot is zero, for the pixel's difference to itself is zero. Even if it is not that simple in reality, because video images not only move but also change, the theory is suitable and efficient when numerous maps are combined together.
-
Figure 1A describes an overall simplified scene of the global motion vector definition process: when defining a global motion vector between two consecutive digital images or frames, aprevious frame 100 and apresent frame 102 on the video sequence, thepresent image 102 is divided intoblocks 104, and for each block 104 asearch area 106 wider than theblock 104 is defined in theprevious image 100. Theblock 104 is then expanded into the size of thesearch area 106 forming an "inverse"map 108 of theblock 104. "inverse" here refers to the fact that normally a map is smaller than the area it represents, while in the present case, themap 108 is actually larger than theblock 104. After expansion, the algorithm calculates absolute difference values 110 of the related pixels of these twopixel matrices motion register 112. After processing every block inimage 104, a topographic map of the motion betweenframes register 112, where the minimum value shows the desired global motion vector between the frames. For equal sized images, like 100 and 102, this brings a minor problem: how to deal with the edge blocks offrame 102 when thesearch area 106 exceeds the edge offrame 100? Fortunately, there are several practical solutions: to copy the edge pixels offrame 100 to fill the search area or to ignore the edge blocks offrame 102 when theframe 102 is large enough, etc. - It is noteworthy that the
present image 102 and theprevious image 100 may be in the opposite order: the backward "motion estimation" is then just turned into the forward "motion estimation". On the other hand, the reference image, i.e. previous image, may also be any other frame for which the global motion vector is to be defined. - Furthermore, it should be noted that the expansion may be virtual, so that the difference calculation process runs the pixels of the block and search area in different phases. Also, different interpolation methods in block expansion should be taken into account, at least when the search area is not a multiple of the block.
- The function between the k x l sized search area S and the expanded block B may be expressed as an error block E:
where i runs from 0 to k-1 and j runs from 0 to l-1. Moreover, the topographic motion map T that fills the motion register may be expressed as
where the frame is divided into n blocks. These blocks can overlap and their union need not cover the entire frame, so feature detection can be applied. Other functions may also be used, quadratic functions, for example, which are also efficient in motion estimation algorithms. - Based on the configuration of
Figure 1A ,Figure 1B illustrates how the previously explained theory works in practice. Again, 102 illustrates a present frame with a person in it and 100 illustrates a previous frame where the person is in a slightly different position. For the sake of clarity, only across section 118 ofluminance data 107 at the person's eye level is shown, when ablock 103 is processed. The corresponding eye-level cross section 116 is selected inside thesearch area 105, and thecross section 116 ofluminance data 109 is shown. The expansion of 107 is shown as 108. These twoluminance data elements motion register 112. The motion register gathers the difference information of every block and search area and the topographic map of motion grows block-by-block. Finally, after every block is processed, themotion register 114 shows where the global motion vector is. The map of a block does not necessarily show exactly where the global motion vector is, because themap 112 may contain several minimum values, i.e. possible candidates for a motion vector. In the places where the volume of the map grows larger, the possibility for the existence of a motion vector decreases. - -
Figure 2 shows the connection between the topographic map in the motion register and motion vectors as a chart. Theblock size 200 is 3x3 pixels and thesearch area 202 is 15x15 pixels. What is noteworthy here, is the periodic character of the motion vectors, which is shown in edges of the chart: top values 204 stand for horizontal motion vectors and leftvalues 206 stand for vertical motion vectors. The length of themotion vector period 208 is the rate between the sizes of the block and the search area. Here, the period is 5 = 15/3. Which means that there will be repeating values in the topographic map. For example, there is an area of fourvalues 210 that all point to the same vector (2, -2). This can be eliminated by combining all four values into their mean value while filling the map or afterwards, for example. The location of the map's minimum value shows the motion vector, which can easily be read from the chart's edge values, or calculated in an application. - The minimum value can be filtered from the map by a simple matrix filter, for example
which proved to be efficient in the simulations of the method. The minimum value may also be found without filtering or with a different filter. However, filtering is assumed to be a more secure way to finding the minimum value. - In the following, with reference to the flow chart shown in
Figure 3 , a method for finding the global motion vector between two images is described. The method starts from 300. In 302, initializations are made; they may contain definitions for block size, search area size, etc. Next, in 304 the register for motion map is initialized to neutral. An optional block selection may be made in 305, with feature or detail detection, for example. In 306, the block data is read. The block data may be in luminance, chrominances Cb or Cr, red, blue, or in whatever digital color format. In 308, the search area data is read from the other image around the position of the block. The block is then (virtually) enlarged to the size of the search area and their difference is calculated pixel by pixel in 310, and the difference is then saved into themotion register 312. Theloop optional feature 318 follows, which may be for example stabilization or predictive motion estimation in a video encoder. The method loops frame pairs until there are no more frames left 320, whereupon the method is stopped in 322. -
Figures 4, 5A, 5B, 6A, and 6B illustrate the use of a global motion vector for stabilization purposes. InFigure 4 , a person is standing in front of the text "HANTRO OULU". For the sake of clarity, only a region defined by aframe 400 is shown. Aframe 402 defines a filming scene of the camera. Animage scene 404 is found inside thefilming scene 402 and it is conveyed into an application, a video codec, for instance. The area 406 is a difference of the sizes betweenframes frame 404 can move freely, i.e. where the stabilization is most efficient. Basically, the larger the area 406, the better the stabilization result. -
Figures 5A and 5B illustrate the effect of the camera motion on thefilming scene 402 and theimage scene 404.Figure 5A illustrates the situation at the beginning, i.e. the first image, in which theimage scene 502 is inside and in the middle of thefilming scene 500.Figure 5B illustrates the following image, in which the camera has moved to the right in the direction ofarrow 504, and the person to be filmed has disturbingly shifted to the left side of the image scene and of thefilming scene 506.Figures 5A and 5B thus illustrate how the image is impaired due to the unintended camera motion, if no motion compensation is available. -
Figures 6A and 6B illustrate the compensation of camera motion by employing the described method for motion definition. The contents ofFigure 6A correspond to the contents ofFigure 5A . As described, the direction and magnitude of the camera motion between the filming scene, i.e.previous image 500 inFigure 5A , and image scene, i.e.present image 506 inFigure 5B , is calculated and a global motion vector is obtained. For the sake of simplicity, our example only includes thehorizontal camera motion 504, which is actually the same as the global motion vector, but opposite. The camera motion is compensated by moving theimage scene 508 inside thefilming scene 506 with an (opposite) global motion vector. When comparingFigures 5B and 6B , it is noticed that by using the compensation, the person to be filmed and the text behind him have not shifted to the side. As the video sequence goes on, the stabilization has to keep trace on the location of the image scene, for it could be stabilized on the next pair of images. It should be noted that besides canceling the motion by moving the next image frame to a direction opposite to the global motion vector, the defined motion may also be utilized in other prior art techniques for video stabilization, such as filtering the motion with Kalman filtering or FIR-filtering (FIR = Finite Impulse Response), for example, and canceling the motion after that. - In accordance with
Figure 4, Figure 7 shows the actual phases of thescenes person 700 stands in front of thecamera 702 and this illustrates thescene 400. But the camera shoots only alimited area 402 of that view, which is taken into thestabilization phase 704. The stabilization is then performed between thepresent filming scene 402 and the previous frame's filming scene 402-2. After stabilization, theimage scene 404 is taken to thevideo encoder 710 and the present image'sfilming scene 402 replaces the previous image's filming scene 402-2. -
Figure 7 also illustrates the overall scene of the predictive motion estimation arrangement, where theglobal motion vector 706 is delivered to anencoder 710. Then, thefilming scene 404 in the video encoder may be replaced by anunstabilized image scene 402. - The digital image processing apparatus comprises an
input interface 712 to obtain a first digital image and a second digital image, and a processing unit 704 (and possibly also 710) coupled with theinput interface 712. The processing unit 704 (and possibly also 710) defines at least one block in the first digital image, defines for each block a search area in the second digital image, the search area being larger than the block, maps the block and its search area to an equal size, calculates pixelwise errors between each block and its search area that are mapped to an equal size, collects the errors into a motion register, and defines a motion between the first digital image and the second digital image by utilizing the motion register. The digital image processing apparatus may be implemented as one or more integrated circuits, such as application-specific integrated circuits ASIC. Other embodiments are also feasible, such as a circuit built of separate logic components, or a processor with its software. A hybrid of these different embodiments is also feasible. When selecting the method of implementation, a person skilled in the art will consider the requirements set on the size and power consumption of the device, necessary processing capacity, production costs, and production volumes, for example. One embodiment is a computer program product for digital image processing, embodied on a distribution medium. In that case, the described functionality/structures may be implemented as software modules. The distribution medium may be any means for distributing software to customers, such as a (computer readable) program storage medium, a (computer readable) memory, a (computer readable) software distribution package, a (computer readable) signal, or a (computer readable) telecommunications signal. -
Figure 8 illustrates the (mpeg-4 type)encoder 710 more closely.First input image 708 arrives from a stabilization phase into theframe buffer 800, from where it continues block by block into encoding phases 802, whose details need not be specified here, because the stabilization is independent of the encoding implementation. The encoded image is rearranged into asecond frame buffer 804. Whensecond input image 708 arrives at theframe buffer 800, themotion estimation block 806 begins to estimate the motion, synchronized block-by-block to theencoding phase 802, between the first andsecond images image 800 and the reference block, i.e. search area, is taken fromimage 804. Typically, full search methods are used in motion estimation, which means that a block is fitted into a search area with every possible motion vector starting from the upper left corner, for instance. Afterwards, a best match is selected for a reference block. The motion estimation block gets aglobal motion vector 706 from the stabilization. The motion estimation starts by using the global motion vector, and ends if a good reference block is found instantly. The selectedmotion vector 808 is conveyed to a variable-length coder 810, whoseoutput 812 provides compressed data. - By comparing
Figures 7 and8 , it can be seen that there is a duplicate frame buffer: one forimage 402 at the stabilization and onebuffer 800 at the decoder. They can be combined so that theencoder 710 uses the buffer forimage 402 asbuffer 800. This can be done, for example, so thatencoder 710 reads the stabilizedimage 404 after the stabilization phase. Another duplicate is found from image 402-2 at the stabilization ofFigure 7 andframe buffer 804 at the decoder ofFigure 8 . They can be combined the same way: the stabilization phase uses 814 the stabilizedimage 404 frombuffer 804 as a reference frame 402-2. In this way the stabilization does not increase the need for memory in a video encoding system at all (except for the motion map). -
Figure 9 illustrates the usage of a global motion vector in the motion estimation of an encoder. Frame 900 represents a reference frame, from which the reference block will be taken to encode a block.Block 902 represents the location of a block (to be encoded) in a reference frame 900, i.e. a zero location. Around the zero location is alimited search area 904, which is typically a multiple of the size ofblock 902. Thearrow 906 is the global motion vector calculated for a frame to be encoded and reference frame 900. So the most probable reference block for a block to be coded is found at thelocation 908, to which theglobal motion vector 906 points. In the case of failure, i.e. the reference block seems not to be the best one, the procedure may continue by checking the second lowest value from the map, the third lowest value, and so on. Local minimums usually also point to a local motion vector, so they can be checked too. - Note that the solution is not related to a block size, which may vary from video coding standard to another. For example, a mpeg-4 standard offers for a luminance frame a 16x16 pixel macroblock, which comprises four 8x8 pixel blocks.
- Even though the invention is described above with reference to an example according to the accompanying drawings, it is clear that the invention is not restricted thereto but it can be modified in several ways within the scope of the appended claims.
Claims (10)
- A digital image processing apparatus, comprising:an input interface to obtain a first digital image and a second digital image; anda processing unit coupled with the input interface to define at least one block in the first digital image, to define for each block a search area in the second digital image, the search area being larger than the block, to map the block and its search area to an equal size, to calculate pixelwise errors between each block and its search area that are mapped to an equal size, to collect the errors into a motion register, and to define a motion between the first digital image and the second digital image by utilizing the motion register.
- The digital image processing apparatus of claim 1, wherein the errors are calculated with an error function
where B is the block, S is search area, i and j represent indexes of the block and the search area, and the errors are collected into the motion register by a function
where the first digital image is divided into n blocks. - The digital image processing apparatus of claim 1, wherein the processing unit selects the blocks such that the blocks overlap and/or do not cover the first digital image entirely.
- The digital image processing apparatus of claim 1, wherein the processing unit selects the blocks with feature detection.
- The digital image processing apparatus of claim 1, which further operates for video sequence stabilization, whereby the processing unit defines the motion as a global motion vector obtained with a global minimum in the motion register and cancels the motion between the first digital image and the second digital image.
- The digital image processing apparatus of claim 1, which further operates for video encoding, whereby the processing unit predicts the motion from a global motion vector obtained with a global minimum in the motion register or from a motion map formed on the basis of the motion register, or from at least one local motion vector obtained with a local minimum in the motion register.
- An arrangement for digital image processing, comprising:means for obtaining a first digital image and a second digital image;means for defining at least one block in the first digital image;means for defining for each block a search area in the second digital image, the search area being larger than the block;means for mapping the block and its search area to an equal size;means for calculating pixelwise errors between each block and its search area that are mapped to an equal size;means for collecting the errors into a motion register; andmeans for defining a motion between the first digital image and the second digital image by utilizing the motion register.
- A computer program product for digital image processing, embodied on a distribution medium and comprising:an input module to obtain a first digital image and a second digital image; anda computing module coupled with the input module to define at least one block in the first digital image, to define for each block a search area in the second digital image, the search area being larger than the block, to map the block and its search area to an equal size, to calculate pixelwise errors between each block and its search area that are mapped to an equal size, to collect the errors into a motion register, and to define a motion between the first digital image and the second digital image by utilizing the motion register.
- An integrated digital image processing circuit, comprising:an input block to obtain a first digital image and a second digital image; anda processing block coupled with the input block to define at least one block in the first digital image, to define for each block a search area in the second digital image, the search area being larger than the block, to map the block and its search area to an equal size, to calculate pixelwise errors between each block and its search area that are mapped to an equal size, to collect the errors into a motion register, and to define a motion between the first digital image and the second digital image by utilizing the motion register.
- A method for defining motion between digital images, comprising:obtaining a first digital image and a second digital image;defining at least one block in the first digital image;defining for each block a search area in the second digital image, the search area being larger than the block;mapping the block and its search area to an equal size;calculating pixelwise errors between each block and its search area that are mapped to an equal size;collecting the errors into a motion register; anddefining a motion between the first digital image and the second digital image by utilizing the motion register.
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US11/172,972 US20070009034A1 (en) | 2005-07-05 | 2005-07-05 | Apparatuses, computer program product, and method for digital image processing |
PCT/FI2006/050218 WO2007003694A1 (en) | 2005-07-05 | 2006-05-29 | Apparatuses, computer program product, and method for digital image processing |
Publications (3)
Publication Number | Publication Date |
---|---|
EP1904974A1 EP1904974A1 (en) | 2008-04-02 |
EP1904974A4 EP1904974A4 (en) | 2012-03-28 |
EP1904974B1 true EP1904974B1 (en) | 2013-03-20 |
Family
ID=37604111
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
EP06743560A Not-in-force EP1904974B1 (en) | 2005-07-05 | 2006-05-29 | Apparatuses, computer program product, and method for digital image processing |
Country Status (6)
Country | Link |
---|---|
US (1) | US20070009034A1 (en) |
EP (1) | EP1904974B1 (en) |
JP (1) | JP4991712B2 (en) |
CN (1) | CN101238486B (en) |
GB (1) | GB2430831B (en) |
WO (1) | WO2007003694A1 (en) |
Families Citing this family (23)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
EP2025159A4 (en) * | 2006-05-30 | 2013-04-10 | Google Inc | Apparatus, arrangement, method and computer program product for digital video processing |
JP4813517B2 (en) * | 2008-05-29 | 2011-11-09 | オリンパス株式会社 | Image processing apparatus, image processing program, image processing method, and electronic apparatus |
US8385404B2 (en) * | 2008-09-11 | 2013-02-26 | Google Inc. | System and method for video encoding using constructed reference frame |
FI20095273A0 (en) * | 2009-03-17 | 2009-03-17 | On2 Technologies Finland Oy | Digital video coding |
EP2405661B1 (en) | 2010-07-06 | 2017-03-22 | Google, Inc. | Loss-robust video transmission using two decoders |
US8503528B2 (en) | 2010-09-15 | 2013-08-06 | Google Inc. | System and method for encoding video using temporal filter |
US8611415B1 (en) | 2010-11-15 | 2013-12-17 | Google Inc. | System and method for coding using improved motion estimation |
US8638854B1 (en) | 2011-04-07 | 2014-01-28 | Google Inc. | Apparatus and method for creating an alternate reference frame for video compression using maximal differences |
US9154799B2 (en) | 2011-04-07 | 2015-10-06 | Google Inc. | Encoding and decoding motion via image segmentation |
US8724854B2 (en) | 2011-04-08 | 2014-05-13 | Adobe Systems Incorporated | Methods and apparatus for robust video stabilization |
US8767821B2 (en) | 2011-05-09 | 2014-07-01 | Google Inc. | System and method for providing adaptive media optimization |
CN102868879B (en) * | 2011-07-05 | 2015-04-29 | 北京大学 | Method and system for converting video frame rate |
US9014265B1 (en) | 2011-12-29 | 2015-04-21 | Google Inc. | Video coding using edge detection and block partitioning for intra prediction |
WO2013162980A2 (en) | 2012-04-23 | 2013-10-31 | Google Inc. | Managing multi-reference picture buffers for video data coding |
US9609341B1 (en) | 2012-04-23 | 2017-03-28 | Google Inc. | Video data encoding and decoding using reference picture lists |
US9014266B1 (en) | 2012-06-05 | 2015-04-21 | Google Inc. | Decimated sliding windows for multi-reference prediction in video coding |
CN103517052B (en) * | 2012-06-29 | 2017-09-26 | 乐金电子(中国)研究开发中心有限公司 | Visual point synthesizing method, device and encoder during a kind of coding depth information |
US9210424B1 (en) | 2013-02-28 | 2015-12-08 | Google Inc. | Adaptive prediction block size in video coding |
US9756331B1 (en) | 2013-06-17 | 2017-09-05 | Google Inc. | Advance coded reference prediction |
US9313493B1 (en) | 2013-06-27 | 2016-04-12 | Google Inc. | Advanced motion estimation |
US9807416B2 (en) | 2015-09-21 | 2017-10-31 | Google Inc. | Low-latency two-pass video coding |
US11240407B2 (en) * | 2016-10-31 | 2022-02-01 | Eizo Corporation | Image processing device, image display device, and program |
US10591731B2 (en) * | 2016-12-06 | 2020-03-17 | Google Llc | Ocular video stabilization |
Family Cites Families (19)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
KR950006045B1 (en) | 1990-05-21 | 1995-06-07 | 마쯔시다덴기산교 가부시기가이샤 | Image motion vector detecting device and swing correcting device |
SE469866B (en) * | 1991-04-12 | 1993-09-27 | Dv Sweden Ab | Method for estimating motion content in video signals |
FI92896C (en) * | 1992-12-31 | 1995-01-10 | Salon Televisiotehdas Oy | Procedure for estimating motion in a video signal and motion estimator |
JP3333012B2 (en) * | 1993-09-10 | 2002-10-07 | オリンパス光学工業株式会社 | Image synthesis device |
US5537155A (en) * | 1994-04-29 | 1996-07-16 | Motorola, Inc. | Method for estimating motion in a video sequence |
US5550480A (en) * | 1994-07-05 | 1996-08-27 | Motorola, Inc. | Method and means for controlling movement of a chuck in a test apparatus |
WO1996008114A1 (en) * | 1994-09-02 | 1996-03-14 | David Sarnoff Research Center, Inc. | Method and apparatus for global-to-local block motion estimation |
US5835138A (en) | 1995-08-30 | 1998-11-10 | Sony Corporation | Image signal processing apparatus and recording/reproducing apparatus |
DE59704258D1 (en) * | 1996-11-25 | 2001-09-13 | Siemens Ag | METHOD AND ARRANGEMENT FOR COMPUTER-ASSISTED MOTION ESTIMATION OR MOTION COMPENSATION |
JPH10262258A (en) * | 1997-03-19 | 1998-09-29 | Sony Corp | Image coder and its method |
US6140828A (en) * | 1997-05-08 | 2000-10-31 | Tokyo Electron Limited | Prober and probe method |
JP3356683B2 (en) * | 1998-04-04 | 2002-12-16 | 東京エレクトロン株式会社 | Probe device |
DE10039336C2 (en) * | 2000-08-04 | 2003-12-11 | Infineon Technologies Ag | Method for testing semiconductor circuits and test device for carrying out the method |
JP4782953B2 (en) * | 2001-08-06 | 2011-09-28 | 東京エレクトロン株式会社 | Probe card characteristic measuring device, probe device, and probe method |
US7221776B2 (en) * | 2001-10-31 | 2007-05-22 | Arcsoft, Inc. | Video stabilizer |
KR100451184B1 (en) * | 2001-12-15 | 2004-10-02 | 엘지전자 주식회사 | Method for searching motion vector |
US7433497B2 (en) * | 2004-01-23 | 2008-10-07 | Hewlett-Packard Development Company, L.P. | Stabilizing a sequence of image frames |
US7447337B2 (en) * | 2004-10-25 | 2008-11-04 | Hewlett-Packard Development Company, L.P. | Video content understanding through real time video motion analysis |
JP4507896B2 (en) * | 2005-01-27 | 2010-07-21 | パナソニック株式会社 | Moving picture compression apparatus and moving picture compression processing method |
-
2005
- 2005-07-05 US US11/172,972 patent/US20070009034A1/en not_active Abandoned
-
2006
- 2006-05-29 GB GB0625491A patent/GB2430831B/en not_active Expired - Fee Related
- 2006-05-29 EP EP06743560A patent/EP1904974B1/en not_active Not-in-force
- 2006-05-29 WO PCT/FI2006/050218 patent/WO2007003694A1/en active Application Filing
- 2006-05-29 CN CN2006800244141A patent/CN101238486B/en not_active Expired - Fee Related
- 2006-05-29 JP JP2008519953A patent/JP4991712B2/en not_active Expired - Fee Related
Also Published As
Publication number | Publication date |
---|---|
CN101238486B (en) | 2012-03-21 |
GB2430831A (en) | 2007-04-04 |
EP1904974A1 (en) | 2008-04-02 |
GB2430831B (en) | 2011-05-11 |
WO2007003694A1 (en) | 2007-01-11 |
JP2009500931A (en) | 2009-01-08 |
EP1904974A4 (en) | 2012-03-28 |
CN101238486A (en) | 2008-08-06 |
JP4991712B2 (en) | 2012-08-01 |
GB0625491D0 (en) | 2007-02-07 |
US20070009034A1 (en) | 2007-01-11 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
EP1904974B1 (en) | Apparatuses, computer program product, and method for digital image processing | |
US7809212B2 (en) | Digital mosaic image construction | |
US7605845B2 (en) | Motion stabilization | |
US8134603B2 (en) | Method and system for digital image stabilization | |
JP4837615B2 (en) | Image processing method and image processing apparatus | |
RU2018143851A (en) | IMAGE FORECASTING METHOD AND IMAGE FORECASTING METHOD | |
CN110830802A (en) | Video compression based on machine learning | |
US5754240A (en) | Method and apparatus for calculating the pixel values of a block from one or two prediction blocks | |
JP2004173224A (en) | Method and apparatus for motion estimation by full binary expression | |
US20060274075A1 (en) | Moving picture conversion apparatus and method, moving picture reconstruction apparatus and method, and computer program | |
US8923400B1 (en) | Method and/or apparatus for multiple pass digital image stabilization | |
US8149911B1 (en) | Method and/or apparatus for multiple pass digital image stabilization | |
US7965767B2 (en) | Two-dimensional filtering architecture | |
WO2013054463A1 (en) | Image pickup apparatus and integrated circuit therefor, image pickup method, image pickup program, and image pickup system | |
US20090022408A1 (en) | Imiage processing apparatus and image processing program | |
US9843812B2 (en) | Video transmission system with color gamut partitioning and method of operation thereof | |
Crawford et al. | Gradient based dominant motion estimation with integral projections for real time video stabilisation | |
EP2230850B1 (en) | Motion analysis for digital images | |
EP2237560A1 (en) | Halo reducing motion-compensated interpolation | |
JP2002509627A (en) | Method and apparatus for generating half-pixel SAD | |
JP2934155B2 (en) | Method and apparatus for detecting moving vector of moving image | |
JP2004242000A (en) | Encoding device and method, and decoding device and method | |
TWI423680B (en) | Design space exploration method of reconfigurable motion compensation architecture | |
JP4140501B2 (en) | Image segment composition order determination apparatus and composition order determination program | |
JPH09261661A (en) | Method for forming bidirectional coding picture from two reference pictures |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PUAI | Public reference made under article 153(3) epc to a published international application that has entered the european phase |
Free format text: ORIGINAL CODE: 0009012 |
|
17P | Request for examination filed |
Effective date: 20080204 |
|
AK | Designated contracting states |
Kind code of ref document: A1Designated state(s): AT BE BG CH CY CZ DE DK EE ES FI FR GB GR HU IE IS IT LI LT LU LV MC NL PL PT RO SE SI SK TR |
|
RBV | Designated contracting states (corrected) |
Designated state(s): AT BE BG CH CY CZ DE DK EE ES FI FR GR HU IE IS IT LI LT LU LV MC NL PL PT RO SE SI SK TR |
|
DAX | Request for extension of the european patent (deleted) | ||
RBV | Designated contracting states (corrected) |
Designated state(s): AT BE BG CH CY CZ DE DK EE ES FI FR GR HU IE IS IT LI LT LU LV MC NL PL PT RO SE SI SK TR |
|
RAP1 | Party data changed (applicant data changed or rights of an application transferred) |
Owner name: GOOGLE INC. |
|
A4 | Supplementary search report drawn up and despatched |
Effective date: 20120224 |
|
RIC1 | Information provided on ipc code assigned before grant |
Ipc: G06T 7/20 20060101AFI20120220BHEPIpc: H04N 7/26 20060101ALI20120220BHEP |
|
17Q | First examination report despatched |
Effective date: 20120309 |
|
GRAP | Despatch of communication of intention to grant a patent |
Free format text: ORIGINAL CODE: EPIDOSNIGR1 |
|
GRAS | Grant fee paid |
Free format text: ORIGINAL CODE: EPIDOSNIGR3 |
|
GRAA | (expected) grant |
Free format text: ORIGINAL CODE: 0009210 |
|
AK | Designated contracting states |
Kind code of ref document: B1Designated state(s): AT BE BG CH CY CZ DE DK EE ES FI FR GR HU IE IS IT LI LT LU LV MC NL PL PT RO SE SI SK TR |
|
REG | Reference to a national code |
Ref country code: CHRef legal event code: EP |
|
REG | Reference to a national code |
Ref country code: IERef legal event code: FG4D |
|
REG | Reference to a national code |
Ref country code: ATRef legal event code: REFRef document number: 602473Country of ref document: ATKind code of ref document: TEffective date: 20130415 |
|
REG | Reference to a national code |
Ref country code: DERef legal event code: R096Ref document number: 602006035185Country of ref document: DEEffective date: 20130516 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: SEFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20130320Ref country code: LTFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20130320Ref country code: ESFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20130701Ref country code: BGFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20130620 |
|
REG | Reference to a national code |
Ref country code: ATRef legal event code: MK05Ref document number: 602473Country of ref document: ATKind code of ref document: TEffective date: 20130320 |
|
REG | Reference to a national code |
Ref country code: LTRef legal event code: MG4D |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: LVFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20130320Ref country code: FIFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20130320Ref country code: SIFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20130320Ref country code: GRFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20130621 |
|
REG | Reference to a national code |
Ref country code: NLRef legal event code: VDEPEffective date: 20130320 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: BEFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20130320 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: ATFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20130320Ref country code: EEFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20130320Ref country code: ROFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20130320Ref country code: ISFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20130720Ref country code: CZFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20130320Ref country code: SKFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20130320Ref country code: NLFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20130320Ref country code: PTFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20130722 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: PLFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20130320Ref country code: CYFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20130320 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: MCFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20130320 |
|
REG | Reference to a national code |
Ref country code: CHRef legal event code: PL |
|
PLBE | No opposition filed within time limit |
Free format text: ORIGINAL CODE: 0009261 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: NO OPPOSITION FILED WITHIN TIME LIMIT |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: CHFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20130531Ref country code: LIFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20130531Ref country code: DKFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20130320 |
|
26N | No opposition filed |
Effective date: 20140102 |
|
REG | Reference to a national code |
Ref country code: IERef legal event code: MM4A |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: ITFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20130320 |
|
REG | Reference to a national code |
Ref country code: FRRef legal event code: STEffective date: 20140131 |
|
REG | Reference to a national code |
Ref country code: DERef legal event code: R097Ref document number: 602006035185Country of ref document: DEEffective date: 20140102 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: IEFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20130529 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: FRFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20130531 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: TRFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20130320 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: HUFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMIT; INVALID AB INITIOEffective date: 20060529Ref country code: LUFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20130529 |
|
PGFP | Annual fee paid to national office [announced via postgrant information from national office to epo] |
Ref country code: DEPayment date: 20150528Year of fee payment: 10 |
|
REG | Reference to a national code |
Ref country code: DERef legal event code: R119Ref document number: 602006035185Country of ref document: DE |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: DEFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20161201 |
|
P01 | Opt-out of the competence of the unified patent court (upc) registered |
Effective date: 20230519 |