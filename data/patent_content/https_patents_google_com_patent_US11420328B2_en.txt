US11420328B2 - Generating a robot control policy from demonstrations - Google Patents
Generating a robot control policy from demonstrations Download PDFInfo
- Publication number
- US11420328B2 US11420328B2 US17/425,257 US202017425257A US11420328B2 US 11420328 B2 US11420328 B2 US 11420328B2 US 202017425257 A US202017425257 A US 202017425257A US 11420328 B2 US11420328 B2 US 11420328B2
- Authority
- US
- United States
- Prior art keywords
- robot
- space
- obstacle
- vector field
- control policy
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
Images
Classifications
-
- B—PERFORMING OPERATIONS; TRANSPORTING
- B25—HAND TOOLS; PORTABLE POWER-DRIVEN TOOLS; MANIPULATORS
- B25J—MANIPULATORS; CHAMBERS PROVIDED WITH MANIPULATION DEVICES
- B25J9/00—Programme-controlled manipulators
- B25J9/16—Programme controls
- B25J9/1656—Programme controls characterised by programming, planning systems for manipulators
- B25J9/1664—Programme controls characterised by programming, planning systems for manipulators characterised by motion, path, trajectory planning
- B25J9/1666—Avoiding collision or forbidden zones
-
- B—PERFORMING OPERATIONS; TRANSPORTING
- B25—HAND TOOLS; PORTABLE POWER-DRIVEN TOOLS; MANIPULATORS
- B25J—MANIPULATORS; CHAMBERS PROVIDED WITH MANIPULATION DEVICES
- B25J9/00—Programme-controlled manipulators
- B25J9/16—Programme controls
- B25J9/1656—Programme controls characterised by programming, planning systems for manipulators
- B25J9/1664—Programme controls characterised by programming, planning systems for manipulators characterised by motion, path, trajectory planning
-
- B—PERFORMING OPERATIONS; TRANSPORTING
- B25—HAND TOOLS; PORTABLE POWER-DRIVEN TOOLS; MANIPULATORS
- B25J—MANIPULATORS; CHAMBERS PROVIDED WITH MANIPULATION DEVICES
- B25J9/00—Programme-controlled manipulators
- B25J9/02—Programme-controlled manipulators characterised by movement of the arms, e.g. cartesian coordinate type
- B25J9/023—Cartesian coordinate type
-
- B—PERFORMING OPERATIONS; TRANSPORTING
- B25—HAND TOOLS; PORTABLE POWER-DRIVEN TOOLS; MANIPULATORS
- B25J—MANIPULATORS; CHAMBERS PROVIDED WITH MANIPULATION DEVICES
- B25J9/00—Programme-controlled manipulators
- B25J9/16—Programme controls
- B25J9/1628—Programme controls characterised by the control loop
- B25J9/163—Programme controls characterised by the control loop learning, adaptive, model based, rule based expert control
-
- G—PHYSICS
- G05—CONTROLLING; REGULATING
- G05B—CONTROL OR REGULATING SYSTEMS IN GENERAL; FUNCTIONAL ELEMENTS OF SUCH SYSTEMS; MONITORING OR TESTING ARRANGEMENTS FOR SUCH SYSTEMS OR ELEMENTS
- G05B19/00—Programme-control systems
- G05B19/02—Programme-control systems electric
- G05B19/42—Recording and playback systems, i.e. in which the programme is recorded from a cycle of operations, e.g. the cycle of operations being manually controlled, after which this record is played back on the same machine
- G05B19/423—Teaching successive positions by walk-through, i.e. the tool head or end effector being grasped and guided directly, with or without servo-assistance, to follow a path
-
- G—PHYSICS
- G05—CONTROLLING; REGULATING
- G05B—CONTROL OR REGULATING SYSTEMS IN GENERAL; FUNCTIONAL ELEMENTS OF SUCH SYSTEMS; MONITORING OR TESTING ARRANGEMENTS FOR SUCH SYSTEMS OR ELEMENTS
- G05B2219/00—Program-control systems
- G05B2219/30—Nc systems
- G05B2219/40—Robotics, robotics mapping to robotics vision
- G05B2219/40116—Learn by operator observation, symbiosis, show, watch
-
- G—PHYSICS
- G05—CONTROLLING; REGULATING
- G05B—CONTROL OR REGULATING SYSTEMS IN GENERAL; FUNCTIONAL ELEMENTS OF SUCH SYSTEMS; MONITORING OR TESTING ARRANGEMENTS FOR SUCH SYSTEMS OR ELEMENTS
- G05B2219/00—Program-control systems
- G05B2219/30—Nc systems
- G05B2219/40—Robotics, robotics mapping to robotics vision
- G05B2219/40391—Human to robot skill transfer
-
- G—PHYSICS
- G05—CONTROLLING; REGULATING
- G05B—CONTROL OR REGULATING SYSTEMS IN GENERAL; FUNCTIONAL ELEMENTS OF SUCH SYSTEMS; MONITORING OR TESTING ARRANGEMENTS FOR SUCH SYSTEMS OR ELEMENTS
- G05B2219/00—Program-control systems
- G05B2219/30—Nc systems
- G05B2219/40—Robotics, robotics mapping to robotics vision
- G05B2219/40475—In presence of moving obstacles, dynamic environment
-
- G—PHYSICS
- G05—CONTROLLING; REGULATING
- G05B—CONTROL OR REGULATING SYSTEMS IN GENERAL; FUNCTIONAL ELEMENTS OF SUCH SYSTEMS; MONITORING OR TESTING ARRANGEMENTS FOR SUCH SYSTEMS OR ELEMENTS
- G05B2219/00—Program-control systems
- G05B2219/30—Nc systems
- G05B2219/40—Robotics, robotics mapping to robotics vision
- G05B2219/40517—Constraint motion planning, variational dynamic programming
Definitions
- some techniques enable a user to kinesthetically teach the robot to follow a particular trajectory. For instance, the user may physically manipulate a robot arm to cause a reference point of an end effector of the robot arm to traverse the particular trajectory—and that particular traversed trajectory may thereafter be repeatable by the robot arm.
- a camera or other device may obtain visual samples of the movement to determine a trajectory of a reference point of the user's arm, which may then be repeated by a robot arm.
- those and other techniques may suffer from one or more drawbacks, such as those described herein.
- the classical way to record a particular trajectory is to generate a time-indexed trajectory, e.g., of individual waypoints.
- This recorded trajectory can be used as a robot control policy.
- the policy may cause the robot to identify the closest individual waypoint of the time-indexed trajectory, move the end effector reference point to that way point, and then move it along the remainder of the trajectory.
- this technique may not yield optimal results in terms of time required to traverse the trajectory and/or robot wear and tear.
- a robot operating in accordance with such a simple control policy may not be well-suited to deal with dynamic obstacles in the environment.
- robot motion during a task is formulated as a differential equation.
- a dynamical systems policy can, by construction, adapt to changes in dynamic environments, making it suitable for use in unstructured environments.
- Implementations are described herein for using contraction theory and semidefinite programming to generate, from a set of data points generated during a demonstration, a dynamical systems control policy that regulates both robot motion and robot interaction with an environment.
- the dynamical systems control policy which may include and/or take the form of a polynomial contracting vector field (referred to herein as “CVF-P” in some instances), is provably optimal for the problem of minimizing imitation loss while providing continuous-time guarantees on the induced imitation behavior.
- CVF-P polynomial contracting vector field
- a set of data points sampled during demonstration-based learning of a robot trajectory is used to calculate a continuous function that corresponds to (e.g., approximates or fits) the trajectory.
- a polynomial vector field may then be fitted to the continuous function.
- a neighborhood space that contains the set of data points may be constrained into a contracting region, such as a tube around the robot trajectory.
- semidefinite programming may be employed. In various implementations, it is possible to use semidefinite programming for which a sum-of-squares relaxation yields a globally-optimal solution. Consequently, it is possible to calculate a globally-optimal polynomial vector that has the lowest imitation loss among all polynomial vector fields of a given degree.
- an inverse kinematic mapping is calculated that maps a position in Cartesian space to a subset of joint space that contains all possible joint configurations that would cause any part of a robot (particularly a robot arm) to occupy the position in Cartesian space.
- sensor data indicative of a position of obstacle in Cartesian space such as a point cloud generated by a 3D or 2.5D vision sensor, may be used to calculate a position of the obstacle in joint space.
- a repulsive polynomial vector field may be generated for the obstacle.
- the polynomial vector field of the dynamical systems control policy may then be modulated based on the repulsive polynomial vector field for the object, e.g., by adding the fields together.
- the position of the obstacle in joint space may be determined based on a mapping from Cartesian space to joint space.
- This mapping may be generated, for instance, by discretizing the joint space of the robot into a plurality of discrete positions (e.g., hundreds of thousands). In some implementations, this may include regularly sampling each joint of the robot from a minimum angle to a maximum angle using a predetermined step size, e.g., of 0.1 radians.
- the robot may then be voxelized at each of the plurality of discrete positions, e.g., using a robot simulation program, to generate a mapping from joint space to Cartesian space.
- the mapping from Cartesian space to joint space may be calculated an inverse of the mapping from joint space to Cartesian space.
- a method may be implemented using one or more processors and may include: receiving a set of data points generated based on sensor data from one or more sensors obtained during imitation learning of a robot trajectory, wherein the imitation learning includes physical manipulation of a reference point from an initial point to a target point; generating a dynamical systems control policy that regulates both robot motion and robot interaction with an environment, wherein generating the dynamical systems control policy comprises: based on the set of data points, calculating a continuous function that corresponds to the robot trajectory, and fitting a polynomial vector field to the continuous function using semidefinite programming, wherein the dynamical systems control policy comprises the polynomial vector field; and controlling a robot based on the dynamical systems control policy.
- the method may include constraining a neighborhood space that contains the set of data points into a contracting region.
- the contracting region comprises a tube around the robot trajectory.
- the mapping may be generated by: discretizing the joint space of the robot into a plurality of discrete positions; voxelizing the robot at each of the plurality of discrete positions to generate a mapping from joint space to Cartesian space; and calculating the mapping from Cartesian space to joint space as an inverse of the mapping from joint space to Cartesian space.
- the discretizing may include regularly sampling each joint of the robot from a minimum angle to a maximum angle using a predetermined step size.
- implementations include one or more processors of one or more computing devices, where the one or more processors are operable to execute instructions stored in associated memory, and where the instructions are configured to cause performance of any of the aforementioned methods.
- Some implementations also include one or more transitory and/or non-transitory computer readable storage media storing computer instructions executable by one or more processors to perform any of the aforementioned methods.
- FIG. 1 illustrates an example environment in which techniques described herein may be implemented.
- FIG. 2 illustrates an example of a robot that may be utilized in FIG. 1 , an example object, and illustrates a user physically manipulating the robot during a kinesthetic teaching.
- FIG. 3 schematically depicts an example architecture of a robot.
- FIG. 4 schematically depicts an example architecture of a computer system.
- FIGS. 5A and 5B depict examples of a problem addressed using techniques described herein.
- FIGS. 6A, 6B, 6C, 6D, 6E, 6F, and 6G depict examples of trajectories, some of which are used and/or generated using techniques described herein.
- FIG. 7 depicts an example method for practicing selected aspects of the present disclosure, in accordance with various implementations.
- FIGS. 8A, 8B, and 8C demonstrate one example of how a polynomial vector field may be modulated based on a detected obstacle, in accordance with various implementations.
- FIG. 1 depicts an example environment in which techniques described herein may be implemented.
- the example environment includes one or more robots 180 and a control policy system 120 .
- the control policy system 120 is illustrated as separate from the robot(s) 180 , in some implementations one or more aspects of the control policy system 120 may be implemented by a corresponding one of the one or more robots 180 (e.g., by one or more processors of the robot).
- each of the robot(s) 180 may include an instance of the control policy system 120 .
- one or more (e.g., all) aspects of the control policy system 120 are implemented on a computing system that is separate from the robot(s) 180 , such as one or remote computing devices and/or computing systems in network communication with the robot(s) 180 .
- one or more aspects of the control policy system 120 may be implemented by remote computing device(s), the robot(s) 180 may transmit (via one or more networks) data from demonstration(s) to the remote computing devices, the remote computing device(s) may generate the control policy based on the transmitted data, then transmit the generated control policy back to the robot(s) 180 .
- the control policy system 120 includes a data engine 122 and a learning engine 124 . In some implementations, more or fewer engines may be provided. In some implementations, the data engine 122 samples a distributed group of data points and provides them to learning engine 124 for use in generating a control policy. In some implementations, the data engine 122 additionally or alternatively automatically generates a potential gradient for a group of data points, assigns the potential gradient to the data points of the group, and provides the assigned potential gradient to learning engine 124 for use in generating a control policy. The learning engine 124 generates a control policy using one or more groups of data points that are each based on robot sensor data from a corresponding kinesthetic teaching.
- FIG. 2 illustrates an example of a robot 280 A that may be one of the robot(s) 180 utilized in FIG. 1 .
- FIG. 2 also illustrates a user 200 physically grasping an end effector 286 of the robot 280 A during physical manipulation of the robot 280 A by the user.
- a spray can 205 resting on a surface 209 .
- the illustrated robot 280 A includes a base 282 and eight actuators 284 a - h that provide degrees of freedom for the robot and provide the robot 280 A with kinematic redundancy.
- the trajectory 201 of FIG. 2 illustrates a trajectory followed by a reference point of the end effector 286 during the demonstration (the trajectory is dictated by the physical manipulation of the robot 280 A by the user 200 ).
- the demonstration started with the reference point at a starting point 202 and ends, as shown in FIG. 2 , with the reference point at a target point 203 .
- Sensor data may be generated by the robot 280 A during the demonstration, such as sensor data that indicates the pose (i.e., the position and optionally the orientation) of the end effector 286 .
- the sensor data that indicates the pose of the end effector may be, for example, sensor data from one or more position sensors associated with actuators 284 a - h that control the pose of the end effector.
- the sensor data may be utilized to generate the data points.
- the data points may be described in joint space (e.g., as the positions of each of the actuators 284 a - h ) and/or task or “Cartesian” space (e.g., as the position and orientation of the end effector 286 , as derived from the position sensors).
- robot 280 A may also include and/or be in communication with one or more user interface input devices, such as a button or other user interface element located on an exterior surface of the robot 280 A, a virtual user interface element provided via a tablet or other computing device in communication with the robot 280 A, and/or a microphone included with the robot 280 A and/or in communication with the robot.
- a user may provide user interface input via the user interface element to, for example: indicate the initiation and/or conclusion of a demonstration.
- a user may operate a graphical user interface of a computing device (e.g., touching a touchscreen with a finger or stylus, using a mouse, etc.) to draw one or more trajectories for reference point of end effector 186 from a starting location to a target location.
- a user's appendage such as the user's arm, could also be captured and used to generate one or more trajectories.
- FIG. 3 schematically depicts an example architecture of a robot 300 .
- the robot 300 includes a robot control system 302 , one or more operational components 304 a - n , and one or more sensors 308 a - m .
- the sensors 308 a - m may include, for example, vision sensors (e.g., camera(s), 3D scanners), light sensors, pressure sensors, positional sensors, pressure wave sensors (e.g., microphones), proximity sensors, accelerometers, gyroscopes, thermometers, barometers, and so forth. While sensors 308 a - m are depicted as being integral with robot 300 , this is not meant to be limiting. In some implementations, sensors 308 a - m may be located external to robot 300 , e.g., as standalone units.
- Operational components 304 a - n may include, for example, one or more end effectors (e.g., grasping end effectors) and/or one or more servo motors or other actuators to effectuate movement of one or more components of the robot.
- the robot 300 may have multiple degrees of freedom and each of the actuators may control actuation of the robot 300 within one or more of the degrees of freedom responsive to control commands provided by the robot control system 302 (e.g., torque and/or other commands generated based on a control policy).
- the term “actuator” encompasses a mechanical or electrical device that creates motion (e.g., a motor), in addition to any driver(s) that may be associated with the actuator and that translate received control commands into one or more signals for driving the actuator. Accordingly, providing a control command to an actuator may comprise providing the control command to a driver that translates the control command into appropriate signals for driving an electrical or mechanical device to create desired motion.
- the robot control system 302 may be implemented in one or more processors, such as a CPU, GPU, and/or other controller(s) of the robot 300 .
- the robot 300 may comprise a “brain box” that may include all or aspects of the control system 302 .
- the brain box may provide real time bursts of data to the operational components 304 a - n , with each of the real time bursts comprising a set of one or more control commands that dictate, inter alia, the parameters of motion (if any) for each of one or more of the operational components 304 a - n .
- the control commands can be at least selectively generated by the control system 302 based on a control policy generated according to one or more techniques disclosed herein.
- FIG. 4 is a block diagram of an example computing system 410 that may optionally be utilized to perform one or more aspects of techniques described herein.
- the computing system 410 typically includes at least one processor 414 which communicates with a number of peripheral devices via bus subsystem 412 .
- peripheral devices may include a storage subsystem 424 , including, for example, a memory subsystem 425 and a file storage subsystem 426 , user interface output devices 420 , user interface input devices 422 , and a network interface subsystem 416 .
- the input and output devices allow user interaction with the computing system 410 .
- Network interface subsystem 416 provides an interface to outside networks and is coupled to corresponding interface devices in other computing devices.
- User interface input devices 422 may include a keyboard, pointing devices such as a mouse, trackball, touchpad, or graphics tablet, a scanner, a touchscreen incorporated into the display, audio input devices such as voice recognition systems, microphones, and/or other types of input devices.
- pointing devices such as a mouse, trackball, touchpad, or graphics tablet
- audio input devices such as voice recognition systems, microphones, and/or other types of input devices.
- use of the term “input device” is intended to include all possible types of devices and ways to input information into the computing system 410 or onto a communication network.
- User interface output devices 420 may include a display subsystem, a printer, a fax machine, or non-visual displays such as audio output devices.
- the display subsystem may include a cathode ray tube (CRT), a flat-panel device such as a liquid crystal display (LCD), a projection device, or some other mechanism for creating a visible image.
- the display subsystem may also provide non-visual display such as via audio output devices.
- output device is intended to include all possible types of devices and ways to output information from the computing system 410 to the user or to another machine or computing device.
- Storage subsystem 424 stores programming and data constructs that provide the functionality of some or all of the modules and methods (e.g., method 700 of FIG. 7 ) described herein.
- Memory 425 used in the storage subsystem 424 can include a number of memories including a main random access memory (RAM) 430 for storage of instructions and data during program execution and a read only memory (ROM) 432 in which fixed instructions are stored.
- a file storage subsystem 426 can provide persistent storage for program and data files, and may include a hard disk drive, a floppy disk drive along with associated removable media, a CD-ROM drive, an optical drive, or removable media cartridges.
- the modules implementing the functionality of certain implementations may be stored by file storage subsystem 426 in the storage subsystem 424 , or in other machines accessible by the processor(s) 414 .
- Bus subsystem 412 provides a mechanism for letting the various components and subsystems of the computing system 410 communicate with each other as intended. Although bus subsystem 412 is shown schematically as a single bus, alternative implementations of the bus subsystem may use multiple busses.
- the computing system 410 can be of varying types including a workstation, server, computing cluster, blade server, server farm, or any other data processing system or computing device. Due to the ever-changing nature of computers and networks, the description of the computing system 410 depicted in FIG. 4 is intended only as a specific example for purposes of illustrating some implementations. Many other configurations of the computing system 410 are possible having more or fewer components than the computing device depicted in FIG. 4 .
- LfD Learning-from-demonstrations
- imitation learning involves inference of a dynamical systems control policy from a relatively small number of demonstrations. Such a dynamical systems control policy can then bootstrap data-efficient reinforcement learning for challenging tasks.
- the demonstrator e.g., a robot technician
- the learned dynamical systems control policy may take over operation of the robot, e.g., from a teleoperator, and enable the robot to repeatedly execute the desired task even in dynamically changing conditions.
- the origin of a picking task and the goal of a placing task may dynamically shift to configurations unseen during training, and dynamic obstacles may be encountered during execution.
- Dynamic obstacles are particularly relevant in collaborative human-robot workspaces where safety guarantees are paramount. In such situations, when faced with an obstacle, the robot can no longer follow the demonstration path anymore and should re-compute a new motion trajectory in real-time to avoid collision and still attempt to accomplish the desired task.
- such real-time adaptation can be achieved by associating demonstrations with a dynamical system.
- a vector field may be generated that defines a closed-loop velocity dynamical systems control policy. From any state that the robot finds itself in, the vector field may be used to steer the robot back towards the desired imitation behavior, without the need for path re-planning using conventional approaches.
- One advantage of the learned vector field is that it can be modulated in real-time in order to avoid collisions with obstacles.
- a naive supervised regression approach may be inadequate.
- the illustrated goal is to have a robot arm imitate a circular trajectory.
- FIG. 5A the illustrated goal is to have a robot arm imitate a circular trajectory.
- estimating vector fields from a small number of trajectories sampled in discrete-time can lead to instability.
- the estimated field diverges when the initial conditions are even slightly different from those encountered during training.
- stability constraints are often used with existing approaches.
- these approaches have one or more of the following limitations. They involve non-convex optimization for dynamics fitting and constructing Lyapunov stability certificates respectively, and hence provide no end-to-end optimality guarantees. Additionally, the notion of stability is not trajectory-centric, but rather focused on reaching a single desired equilibrium point. Finally, these approaches are computationally infeasible when formulated in continuous-time.
- implementations described herein are usable to formulate a continuous time optimization problem over vector fields involving an imitation loss, subject to a constraint that turns the neighborhood of demonstrations into contracting regions. Within this region, all trajectories are guaranteed to coalesce towards the demonstration exponentially fast. As will be explained herein, such a formulation leads to an instance of time-varying semidefinite programming for which a sum-of-squares (“SOS”) relaxation is exact. Hence, techniques described herein are able to find the globally optimal polynomial vector field that has the lowest imitation loss among all polynomial vector fields of a given degree that are contracting on a region around the demonstrations in continuous time.
- SOS sum-of-squares
- LSP continuous time least squares optimization problem
- a vector field f learned using techniques described herein may be generalized to conditions that were not encountered in the training data.
- the LSP problem generally admits multiple solutions, as it only dictates how the vector field should behave on the sample trajectories. This under-specification can easily lead to overfitting, especially if the class of function is expressive enough.
- FIGS. 5A and 5B reinforces this phenomenon even for a simple circular motion.
- a metric is given by smooth, matrix-valued function M: + ⁇ n n ⁇ n that is uniformly positive definite, i.e. there exists ⁇ >0 such that M ( t,x ) ⁇ I ⁇ t ⁇ + , ⁇ x ⁇ n , (3) where I is the identity matrix and the relation A B between two symmetric matrices A and B is used to denote that the smallest eigenvalue of their difference A ⁇ B is nonnegative.
- the Euclidean metric corresponds to the case where M(x) is constant and equal to the identity matrix.
- any infinitesimal length ⁇ x ⁇ M(x) (and by assumption, ⁇ x ⁇ 2 ) converges exponentially to zero as time goes to infinity. This implies that in a contraction region, trajectories will tend to together converge towards a nominal path. If the entire state-space is contracting and a finite equilibrium exists, then this equilibrium is unique and all trajectories converge to this equilibrium.
- LSPC least squares problem with contraction
- finding such an incremental stability certificate for a given dynamical system is a nontrivial problem. If one wishes to find the vector field and a corresponding contraction metric at the same time, then the problem becomes non-convex.
- a common approach to handle this kind of problems is to optimize over one parameter at a time and fix the other one to its latest value and then alternate (i.e. fix a contraction metric and fit the vector field, then fix the vector field and improve on the contraction metric.)
- TV-SDP optimization programs will be referred to herein in the form:
- Polynomial functions can approximate most functions reasonably well and are suitable for algorithmic operations as will be described shortly.
- each trajectory x (i) (t) may be approximated with a polynomial function of time
- the decision variable may be the polynomial vector field f and the following objective function (which is already convex and quadratic) can be optimized:
- SOS sum-of-squares
- CVF-P polynomial contracting vector field
- a polynomial p ⁇ [x] is nonnegative if p(x) ⁇ 0 for every x ⁇ n .
- a goal may be to find the coefficients of one (or several) polynomials without violating some nonnegativity constraints. While the notion of nonnegativity is conceptually easy to understand, testing whether a given polynomial is nonnegative is known to be NP-hard as soon as the degree d ⁇ 4 and the number of variables n ⁇ 3.
- a matrix-valued polynomial P(t) of degree d is PSD on the interval [0, T] (i. e. P(t) 0 ⁇ t ⁇ [0, T]) if and only if can be written as:
- V and W are SOSM.
- V and W have degree at most deg (P) ⁇ 1
- V (resp.) has degree at most deg (P) (resp. deg (P)).
- Proposition 1 (A lower bound on the contraction tube):
- f ⁇ n ⁇ n is a twice continuously differentiable vector field that satisfies ⁇ sym [ M ( x ( t )) J f ( x ( t ))] ⁇ ⁇ dot over (M) ⁇ ( x ( t )) ⁇ M ( x ) ⁇ t ⁇ [0, T ]
- ⁇ is a compact region of n
- ⁇ is a positive constant
- M(x) is a positive definite metric
- x: [0, T] n is a path
- Lemma 1 For any n ⁇ n symmetric matrices A and B
- ⁇ : T ⁇ C 2 ⁇ n ⁇ L ⁇ C > 0 ⁇ ⁇
- a “pick-and-place” robot task is a task in which objects are picked by a robot from a known location and placed into another location such as a box.
- a teleoperator can demonstrate a relatively small number of trajectories that guide a robot arm to grasp objects and place them in a box. After learning from these demonstrations, the robot arm is expected to continually fill boxes to be verified and moved by a human working in close proximity freely moving obstacles in and out of the workspace.
- FIG. 6A shows an example of a demonstration pick and place trajectory collected from a user.
- the pick and place task was collected as two separate trajectories, one (downward motion) for the pick motion and another (arc from right to left) for the place motion.
- CVP-Ps composition of pick-and-place polynomial contracting vector fields
- SCS splitting conic solver
- the CVF-P was fit to the trajectory in the 7-dimensional joint space.
- the robot arm was then operated using the CVF-P eight times starting from the home position. Each trajectory was allowed to run until the 2 —norm of the arm joint velocities dropped below a threshold of 0.01. At that point, the arm would begin to move using the second vector field.
- the trajectories taken by the arm are shown in FIG. 6B . The eight runs have very little deviation from each other.
- noise was added to the home position of the robot arm, and again the CVF-P was used to operate the robot arm through the pick-and-place task.
- noise was added uniformly from the range [ ⁇ 0.05, 0.05] radians to each value of each joint of the arm's starting home position.
- uniform noise was added in the same manner from the range [ ⁇ 0.1, 0.1]. Due to contraction, trajectories are seen to converge from random initial conditions.
- FIG. 6E demonstrates what happens if the robot arm is run eight times using a vector field without contraction. While the arm is consistent in the trajectory that it takes, the arm moves far from the demonstrated trajectory, and eventually causes an emergency break to activate at joint limits, and the task fails. This problem is exacerbated when noise is added.
- FIG. 6F the arm was again run eight times without contraction with noise added uniformly from the range [ ⁇ 0.05, 0.05] to each the value of each joint of the arm's starting home position. The trajectory of the arm varied widely and had to be cut short as it caused an emergency break to engage.
- a robot arm can be operated to follow demonstrated trajectories while avoiding obstacles unseen during training.
- collisions are avoided against any part of robot body.
- a depth sensor e.g., 2.5 or 3D vision sensor
- acquires a representation of the obstacle such as a point cloud.
- the demonstrations and trajectories exist in joint space ⁇ 7 , while the obstacle exists (e.g., as a point cloud) in Cartesian space ⁇ 3 with an origin at the base of the robot.
- a set-valued inverse kinematic map IK is precomputed that maps a position c ⁇ to a subset of a containing all the joint configurations that would cause any part of the arm to occupy the position c.
- the obstacles positions are known in Cartesian space , which is different from the control space of the robot (e.g., the joint angles are controlled, rather than end-effector pose).
- a robot arm simulator enables queries of a forward kinematics map FK: ⁇ . To compute the inverse of this map, the joint space of the robot may be discretized into some number (e.g., 658,945) discrete positions.
- These discrete positions may be created, for instance, by regularly sampling each joint from a min to max angle using a step size of, for instance, 0.1 radians.
- the robot may be positioned in a simulator at each point of the discrete joint space points. The robot may then be voxelized to generate the map FK.
- the obstacle positions may then be incorporated in a repulsive vector-field to push the arm away from collision as it moves,
- This vector field may be added to the learnt vector-field f to obtain a modulated vector field (depicted in FIG.
- Obstacle avoidance is not limited to the modulation methods described herein. Other modulation techniques are possible for obstacle avoidance, each with different guarantees and drawbacks. For example, a multiplicative modulation function may be employed that preserves equilibrium points in the case of convex or concave obstacles. However, the modulation techniques described herein, due to their additive nature, allow for handling of a large number of obstacles as every term in Equation (14) can be computed in a distributed fashion. Additionally, it is not necessary to impose any restrictions on the shape of the obstacles (convex/concave). This is particularly important as the joint control space is different from the Cartesian space where the obstacle is observed, and the map IK that links between the two spaces can significantly alter the shape of an obstacle in general (e.g. a sphere in Cartesian space can be mapped to a disconnected set in joint space).
- FIG. 6G depicts eight trajectories that were achieved using a CVF-P generated using techniques described herein, where an obstacle was introduced to the robot's workspace.
- the object's position was returned by a motion capture system.
- the object's position in Cartesian space was used to modulate the joint space vector field as described previously.
- the pick-and-place tasks were accomplished as the robot arm avoided the obstacle but remained within the joint-space contraction tube re-converging to the demonstrated behavior.
- FIG. 7 illustrates a flowchart of an example method 700 for practicing selected aspects of the present disclosure.
- the steps of FIG. 7 can be performed by one or more processors, such as one or more processors of the various computing devices/systems described herein.
- processors such as one or more processors of the various computing devices/systems described herein.
- operations of method 700 will be described as being performed by a system configured with selected aspects of the present disclosure.
- Other implementations may include additional steps than those illustrated in FIG. 7 , may perform step(s) of FIG. 7 in a different order and/or in parallel, and/or may omit one or more of the steps of FIG. 7 .
- the system may receive a set of data points generated based on sensor data from one or more sensors obtained during imitation learning of a robot trajectory.
- the imitation learning may include, for instance, physical manipulation of a reference point from an initial point to a target point.
- the system may generate a dynamical systems control policy that regulates both robot motion and robot interaction with an environment. For example, at block 704 , the system may constrain a neighborhood space that contains the set of data points into a contracting region. In some such implementations, the contracting region may take the form of a tube around the robot trajectory. At block 706 , the system may, based on the set of data points, calculate a continuous function that corresponds to the robot trajectory. At block 708 , the system may fit a polynomial vector field to the continuous function using semidefinite programming, as described previously.
- the system may control a robot based on the dynamical systems control policy. If the robot encounters an obstacle during operation, at block 712 , the system may receive sensor data indicative of a position of the obstacle in Cartesian space. For example, a dynamic obstacle may be observed in the robot's workspace using a 2.5 or 3D vision sensor. At block 714 , the system may determine a position of the obstacle in joint space based on the position of the obstacle in Cartesian space. As described previously, in some implementations, the system may discretize some number of joint configurations and determine a forward kinematics (“FK,” i.e. joint-space-to-Cartesian-space) mapping based on those discretized joint configurations.
- FK forward kinematics
- the system may calculate an inverse of that mapping, IK, which maps Cartesian space to joint space.
- IK an inverse of that mapping
- the system may generate a repulsive polynomial vector field for the obstacle.
- the system may modulate the polynomial vector field of the dynamical systems control policy based on the repulsive polynomial vector field for the obstacle.
- FIGS. 8A-C An example of this is depicted in FIGS. 8A-C .
- FIG. 8A depicts a vector field F learned from a nominal path (thickened black line).
- FIG. 8B depicts a repulsive vector field associated with an obstacle (black disk).
- FIG. 8C depicts a modulated vector field that results when the unmodulated vector field of FIG. 8A is modulated with the repulsive vector field in FIG. 8B , with the black disk in FIG. 8C representing the obstacle.
- Described herein were implementations for teleoperator imitation using contracting vector fields that are globally optimal with respect to loss minimization and providing continuous-time guarantees on the behavior of the system when started from within a contraction tube around the demonstration. Techniques described herein compare favorably with other movement generation techniques. Also described herein are techniques to generate a workspace Cartesian to joint space mapping for the robot, and for utilizing the mapping to update contracting vector fields on the fly to avoid dynamic obstacles.
Abstract
Description
{dot over (x)}=f real(x), (1)
where freal:
From this equation it is possible to derive the rate of change of the infinitesimal squared distance between two trajectories ∥δx∥2 2=δxTδx as follows:
M(t,x)
where I is the identity matrix and the relation A
where sym[M] denotes
for any square matrix M and {dot over (M)}(x) is the n×n matrix whose (i,j)-entry is ∇Mij(x)Tf(x). This motivates the following definition of contraction.
sym[M(x)J f(x)]+{dot over (M)}(x)
P
Integrating both sides yields,
Hence, any infinitesimal length ∥δx∥M(x) (and by assumption, ∥δx∥2) converges exponentially to zero as time goes to infinity. This implies that in a contraction region, trajectories will tend to together converge towards a nominal path. If the entire state-space is contracting and a finite equilibrium exists, then this equilibrium is unique and all trajectories converge to this equilibrium.
-
- s. t. f contracts on a region U⊆
- containing the demonstrations x(i)(t)
- with respect to the metric M(x).
where the variable t∈[0, T] stands for time, the loss function L:
and it can be assumed that
The decision variable may be the polynomial vector field f and the following objective function (which is already convex and quadratic) can be optimized:
In order to impose the contraction of the vector field f over some region around the trajectories in demonstration, a smoothness argument may be used to claim that it is sufficient to impose contraction only on the trajectories themselves. Put another way,
where M(x) is some known contraction metric.
p(x)=Σi=t m q i(x)2 (10)
p(x)=z(x)T Qz(x)∀x∈
where z(x) is the vector of monomials of x up to degree
and the equality between me two sides of the equation is equivalent to a set of linear equalities in the coefficients of the polynomial p(x) and the entries of the matrix Q.
where V and W are SOSM. In the first case, V and W have degree at most deg (P)−1, and in the second case V (resp.) has degree at most deg (P) (resp. deg (P)). When that is the case, it can be said that P(t) is SOSM on [0, T].
with
−sym[M(x(t))J f(x(t))]−{dot over (M)}(x(t))
where Ω is a compact region of
U:={x(t)+δ|∈[0, T], ∥δ∥2≤ϵ}∩Ω,
where ϵ is positive scalar depending only on the smoothness parameters and defined explicitly in Eqn (11).
where λmin(⋅) denotes the smallest eigenvalue function.
c=max{λ≥0|M(x)
C=min{λ≥0|λM(x)
Notice that c≤C, and since the metric M(x) is uniformly positive definite, then c>0. The following definition will be used:
Fix t∈[0, T], and let δ be a vector in
R δ:=−sym[ M(x)(t)+δ)J f(x(t)+δ)]−{dot over (M)}(x(t)+δ)
satisfies Rδ
where the integer r control how fast the effect of this vector field decays as a function of distance (a high value of r makes the effect of hobstacles local, while a small value makes its effect more uniform.) This vector field may be added to the learnt vector-field f to obtain a modulated vector field (depicted in
{tilde over (f)}(t, x)=f(x)+αh obstacles(t, x)
where α is positive constant that is responsible controlling the strength of the modulation that is then fed to the robot arm. If the modulation is local and the obstacle is well within the joint-space contraction tube, the motion can be expected to re-converge to the demonstrated behavior.
Claims (17)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US17/425,257 US11420328B2 (en) | 2019-02-01 | 2020-01-31 | Generating a robot control policy from demonstrations |
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201962800378P | 2019-02-01 | 2019-02-01 | |
PCT/US2020/016151 WO2020160431A1 (en) | 2019-02-01 | 2020-01-31 | Generating a robot control policy from demonstrations |
US17/425,257 US11420328B2 (en) | 2019-02-01 | 2020-01-31 | Generating a robot control policy from demonstrations |
Publications (2)
Publication Number | Publication Date |
---|---|
US20220040861A1 US20220040861A1 (en) | 2022-02-10 |
US11420328B2 true US11420328B2 (en) | 2022-08-23 |
Family
ID=69740761
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US17/425,257 Active US11420328B2 (en) | 2019-02-01 | 2020-01-31 | Generating a robot control policy from demonstrations |
Country Status (3)
Country | Link |
---|---|
US (1) | US11420328B2 (en) |
EP (1) | EP3898132A1 (en) |
WO (1) | WO2020160431A1 (en) |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20200189099A1 (en) * | 2017-09-15 | 2020-06-18 | Google Llc | Improvements related to generating a robot control policy from demonstrations collected via kinesthetic teaching of a robot |
Families Citing this family (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN111730605B (en) * | 2020-08-04 | 2020-12-15 | 深圳市优必选科技股份有限公司 | Robot posture control method and device, readable storage medium and robot |
US20220058482A1 (en) * | 2020-08-18 | 2022-02-24 | Nec Laboratories America, Inc. | Meta imitation learning with structured skill discovery |
CN113820978B (en) * | 2021-09-08 | 2023-05-26 | 华侨大学 | Quasi-synchronous control method of network teleoperation robot system |
CN114549269A (en) * | 2022-01-27 | 2022-05-27 | 苏州大学 | Method for automatically picking up nano-wire by micro-nano operation robot based on dynamic motion primitive |
Citations (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9643314B2 (en) * | 2015-03-04 | 2017-05-09 | The Johns Hopkins University | Robot control, training and collaboration in an immersive virtual reality environment |
US9684305B2 (en) * | 2015-09-11 | 2017-06-20 | Fuji Xerox Co., Ltd. | System and method for mobile robot teleoperation |
US20170173786A1 (en) * | 2015-12-22 | 2017-06-22 | Kindred Systems Inc. | Systems, devices, and methods for foot control of robots |
US20170269607A1 (en) * | 2016-03-15 | 2017-09-21 | Kindred Systems Inc. | Systems, devices, articles, and methods for robots in workplaces |
WO2018148437A2 (en) | 2017-02-09 | 2018-08-16 | X Development Llc | Improvements related to generating a robot control policy from demonstrations collected via kinesthetic teaching of a robot |
-
2020
- 2020-01-31 WO PCT/US2020/016151 patent/WO2020160431A1/en unknown
- 2020-01-31 US US17/425,257 patent/US11420328B2/en active Active
- 2020-01-31 EP EP20708970.7A patent/EP3898132A1/en active Pending
Patent Citations (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9643314B2 (en) * | 2015-03-04 | 2017-05-09 | The Johns Hopkins University | Robot control, training and collaboration in an immersive virtual reality environment |
US9684305B2 (en) * | 2015-09-11 | 2017-06-20 | Fuji Xerox Co., Ltd. | System and method for mobile robot teleoperation |
US20170173786A1 (en) * | 2015-12-22 | 2017-06-22 | Kindred Systems Inc. | Systems, devices, and methods for foot control of robots |
US20170269607A1 (en) * | 2016-03-15 | 2017-09-21 | Kindred Systems Inc. | Systems, devices, articles, and methods for robots in workplaces |
WO2018148437A2 (en) | 2017-02-09 | 2018-08-16 | X Development Llc | Improvements related to generating a robot control policy from demonstrations collected via kinesthetic teaching of a robot |
Non-Patent Citations (48)
Title |
---|
Ahmadi, A. et al., "Geometry of 3D Environments and Sum of Squares Polynomials;" arXiv.org, arXiv:1611.07369v3; 10 pages; Mar. 7, 2017. |
Ahmadi, A. et al., "Time-Varying Semidefinite Programs;" arXiv.org, arXiv:1808.03944v2; 34 pages; Dec. 2, 2019. |
Ahmadi, A. et al., "Towards Scalable Algorithms with Formal Guarantees for Lyapunov Analysis of Control Systems via Algebraic Optimization;" in 53rd IEEE Conference on Decision and Control; 10 pages; Dec. 2014. |
Ahmadi, A., "Algebraic Relaxations and Hardness Results in Polynomial Optimization and Lyapunov Analysis;" PhD Thesis, MIT; arXiv.org; arXiv:1201.2892v1; 156 pages; Sep. 2011. |
Atkeson, C.G. et al., "What Happened at the DARPA Robotics Challenge, and Why?" https://www.cs.cmu.edu/˜cga/drc/jfr-what.pdf; 12 pages; 2016. |
Aylward, E. et al.; "Stability and Robustness Analysis of Nonlinear Systems via Contraction Metrics and SOS Programming;" http://web.mit.edu/nsl/www/preprints/SOS_metrics.pdf; 8 pages; Dec. 30, 2007. |
Billard, A. et al., "Robot Programming by Demonstration;" Handbook of Robotics, Chapter 59; 26 pages; Sep. 7, 2007. |
Choi, M-D., "Positive Semidefinite Biquadratic Forms;" Linear Algebra and its Applications, 1975. |
Dai, H. et al., "Synthesis and Optimization of Force Closure Grasps via Sequential Semidefinite Programming;" Robotics Research; Springer; 16 pages; 2017. |
D'Donoghue, B. et al., "Conic Optimization via Operator Splitting and Homogeneous Self-Dual Embedding;" Journal of Optimization Theory and Applications; 23 pages; Jul. 2016. |
Dette, H. et al., "Matrix measures, moment spaces and Favard's theorem for the interval [0, 1] and [0, ];" Linear Algebra and its Applications, vol. 345; pp. 169-193; 2002. |
Dragan, A. et al., "Formalizing Assistive Teleoperation;" Carnegie Mellon University, Journal contribution; https://doi.org/10.1184/R1/6554936.v1; 8 pages; 2018. |
European Patent Office; International Search Report and Written Opinion of PCT Ser. No. PCT/US2020/016151; 11 pages; dated Jun. 9, 2020. |
Fong, T. et al., "Vehicle Teleoperation Interfaces;" Autonomous Robots 11; pp. 9-18; 2001. |
Gatermann, K. et al., "Symmetry groups, semidefinite programs, and sums of squares;" arXiv:math/0211450v1; 35 pages; Nov. 28, 2002. |
Goldberg, K. et al., "Desktop Teleoperation via the World Wide Web;" Proceedings of 1995 IEEE International Conference on Robotics and Automation (ICRA); 6 pages. |
Huber, L. et al., "Avoidance of Convex and Concave Obstacles with Convergence ensured through Contraction;" IEEE Robotics and Automation Letters; 8 pages; Jan. 2019. |
Ijspeert, A.J. et al., "Dynamical Movement Primitives: Learning Attractor Models for Motor Behaviors;" Neural Computation, vol. 25; pp. 328-373; 2013. |
Jouffroy, J. et al., "A Tutorial on Incremental Stability Analysis using Contraction Theory;" Modeling, Identification and Control, vol. 31, No. 3, pp. 93-106; 2010. |
Kappler, D. et al., "Real-time Perception meets Reactive Motion Generation;" arXiv.org, arXiv:1703.03512v3; 9 pages; Oct. 6, 2017. |
Keogh, E. et al., "Exact indexing of dynamic time warping;" Knowledge and Information Systems, Springer, 29 pages; 2004. |
Khansari-Zadeh, S. M., et al, (2012). "A Dynamical System Approach To Realtime Obstacle Avoidance." Autonomous Robots, 32(4), 433-454. |
Khansari-Zadeh, S. M., et al. (2011). "Learning Stable Nonlinear Dynamical Systems with Gaussian Mixture Models." IEEE Transactions on Robotics, 27(5), 943-957. |
Khansari-Zadeh, S. M., et al. (2014). "Learning Control Lyapunov Function To Ensure Stability of Dynamical System-Based Robot Reaching Motions." Robotics and Autonomous Systems, 62(6), 752-765. |
Khansari-Zadeh, S. M., et al. "Learning Potential Functions from Human Demonstrations with Encapsulated Dynamic and Compliant Behaviors", Autonomous Robots, 23 pages; 2015. |
Khansari-Zadeh, S.M., "Benchmark Handwriting ImitationTasks;" retrieved from internet, https://cs.stanford.edu/people/khansari/download.html; 2 pages; dated Mar. 2015. |
Khatib, O. (1986). "Real-Time Obstacle Avoidance for Manipulators and Mobile Robots." The International Journal of Robotics Research, 5(1), 90-98. |
Kojima, M., "Sums of Squares Relaxations of Polynomial Semidefinite Programs;" Research Reports on Mathematical and Computing Sciences Series B: Operations Research; Research Report B-397,15 pages; Nov. 2003. |
Kuindersma, S. et al., "Optimization-based Locomotion Planning, Estimation, and Control Design for the Atlas Humanoid Robot;" Autonomous Robots, 40, 3; 46 pages; 2015. |
Lasserre, J.B., "Global Optimization with Polynomials and the Problem of Moments;" Society for Industrial and Applied Mathematics, vol. 11, No. 3, pp. 796-817; Jan. 19, 2001. |
Lemme, A. et al., "Open-source benchmarking for learned reaching motion generation in robotics;" Paladyn, Journal of Behavioral Robotics, vol. 6, Issue 1; pp. 30-41; 2015. |
Lohmiller, W. et al., "On Contraction Analysis for Nonlinear Systems;" http://web.mit.edu/nsl/www/preprints/contraction pdf; 27 pages; 1997. |
Majumdar, A. et al., "Control Design along Trajectories with Sums of Squares Programming;" arXiv.org, arXiv:1210.0888v1; 8 pages; Oct. 2, 2012. |
Marturi, N. et al., "Towards advanced robotic manipulation for nuclear decommissioning: a pilot study on tele-operation and autonomy;" International Conference on Robotics and Automation for Humanitarian Applications (RAHA); 8 pages; Dec. 2016. |
Min, P., "Binvox, A 3D Mesh Voxelizer," retrieved from internet https://www.patrickmin.com/ binvox/; 3 pages; retrieved Jul. 16, 2021. |
Parrilo, P., "Semidefinite programming relaxations for semialgebraic problems;" Math. Program., Ser. B 96; https://doi.org/10.1007/s10107-003-0387-5; pp. 293-320; May 2003. |
Pauwels, E. et al., "Inverse optimal control with polynomial optimization;" arXiv.org, arXiv:1403.5180v1; 17 pages Mar. 20, 2014. |
Ravichandar, H. et al., "Learning Partially Contracting dynamical Systems from Demonstrations;" 1st Conference an Robot Learning (CoRL); 10 pages; 2017. |
Reznick, B. et al., "Real Zeros of Positive Semidefinite Forms. I.;" Mathematische Zeitschrift 171; Springer; pp. 1-26; 1980. |
Schaal, S., "Is Imitation Learning the Route to Humanoid Robots?" Trends In Cognitive Sciences, 3; 19 pages; 1999. |
Scherer, C.W. et al., "Matrix Sum-of-Squares Relaxations for Robust Semi-Definite Programs;" Mathematical Programming; 37 pages; 2006. |
Sindhwani, V. et al., "Learning Contracting Vector Fields for Stable Imitation Learning;" arXiv.org; arXiv:1804.04878v1; 9 pages; Apr. 13, 2018. |
Sindhwani, V. et al.; "Learning Contracting Vector Fields for Stable Imitation Learning;" Cornell University, arXiv.org; arXiv:1804.04878v1; 9 pages; Apr. 13, 2018. |
Tan, W. et al., "Searching for Control Lyapunov Functions using Sums of Squares Programming;" https://bcci.me.berkeley.edu/downloads/papers/weehong_3.pdf; 10 pages; 2008. |
Taylor, R.H. et al., "Medical Robotics and Computer-Integrated Surgery;" Springer Handbook of Robotics; https://doi.org/10.1007/978-3-540-30301-5_53; pp. 1199-1222; 2008. |
Washington, R. et al., "Autonomous Rovers for Mars Exploration;" Proceedings of 1999 IEEE Aerospace Conference; 15 pages; Mar. 1999. |
Watterson, M. et al.; "Smooth trajectory generation on SE(3) for a free flying space robot;" 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS); 8 pages; Oct. 9, 2016. |
Zhang, T. et at., "Deep Imitation Learning for Complex Manipulation Tasks from Virtual Reality Teleoperation;" arXiv.org, arXiv:1710.04615v2; 9 pages; Mar. 6, 2018. |
Cited By (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20200189099A1 (en) * | 2017-09-15 | 2020-06-18 | Google Llc | Improvements related to generating a robot control policy from demonstrations collected via kinesthetic teaching of a robot |
US11565412B2 (en) * | 2017-09-15 | 2023-01-31 | Google Llc | Generating a robot control policy from demonstrations collected via kinesthetic teaching of a robot |
Also Published As
Publication number | Publication date |
---|---|
US20220040861A1 (en) | 2022-02-10 |
EP3898132A1 (en) | 2021-10-27 |
WO2020160431A1 (en) | 2020-08-06 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US11420328B2 (en) | Generating a robot control policy from demonstrations | |
US11554485B2 (en) | Generating a robot control policy from demonstrations collected via kinesthetic teaching of a robot | |
Peternel et al. | Robotic assembly solution by human-in-the-loop teaching method based on real-time stiffness modulation | |
Yang et al. | Neural-learning-based telerobot control with guaranteed performance | |
US20210325894A1 (en) | Deep reinforcement learning-based techniques for end to end robot navigation | |
Kino et al. | Robust PD control using adaptive compensation for completely restrained parallel-wire driven robots: Translational systems using the minimum number of wires under zero-gravity condition | |
Sieber et al. | Human-guided multirobot cooperative manipulation | |
US11565412B2 (en) | Generating a robot control policy from demonstrations collected via kinesthetic teaching of a robot | |
Farkhatdinov et al. | Improving mobile robot bilateral teleoperation by introducing variable force feedback gain | |
Gams et al. | Learning and adaptation of periodic motion primitives based on force feedback and human coaching interaction | |
Jiang et al. | Multi-hierarchy interaction control of a redundant robot using impedance learning | |
Ahmadzadeh et al. | Learning reactive robot behavior for autonomous valve turning | |
Toussaint et al. | Dual execution of optimized contact interaction trajectories | |
Khadir et al. | Teleoperator imitation with continuous-time safety | |
Safeea et al. | A Q-learning approach to the continuous control problem of robot inverted pendulum balancing | |
Nicolin et al. | Agimus: a new framework for mapping manipulation motion plans to sequences of hierarchical task-based controllers | |
Kastritsi et al. | A pHRI Framework for Modifying a Robot's Kinematic Behaviour via Varying Stiffness and Dynamical System Synchronization | |
Kim et al. | Generalizing over uncertain dynamics for online trajectory generation | |
Fang et al. | Learning from wearable-based teleoperation demonstration | |
Yih | Robust flight control of an underactuated quadrotor via sliding modes | |
Ruud | Reinforcement learning with the TIAGo research robot: manipulator arm control with actor-critic reinforcement learning | |
EP4335598A1 (en) | Action abstraction controller for fully actuated robotic manipulators | |
Yüksel | Design, Modeling and Control of Aerial Robots for Physical Interaction and Manipulation | |
Wang et al. | DOREP 2.0: An Upgraded Version of Robot Control Teaching Experimental Platform with Reinforcement Learning and Visual Analysis | |
Eckhoff et al. | Towards Connecting Control to Perception: High-Performance Whole-Body Collision Avoidance Using Control-Compatible Obstacles |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
FEPP | Fee payment procedure |
Free format text: ENTITY STATUS SET TO UNDISCOUNTED (ORIGINAL EVENT CODE: BIG.); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:EL KHADIR, BACHIR;SINDHWANI, VIKAS;VARLEY, JACOB;SIGNING DATES FROM 20200214 TO 20200406;REEL/FRAME:057032/0863 |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: DOCKETED NEW CASE - READY FOR EXAMINATION |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: NON FINAL ACTION MAILED |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: RESPONSE TO NON-FINAL OFFICE ACTION ENTERED AND FORWARDED TO EXAMINER |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: NOTICE OF ALLOWANCE MAILED -- APPLICATION RECEIVED IN OFFICE OF PUBLICATIONS |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:EL KHADIR, BACHIR;SINDHWANI, VIKAS;VARLEY, JACOB;SIGNING DATES FROM 20200214 TO 20200406;REEL/FRAME:059683/0180 |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: AWAITING TC RESP, ISSUE FEE PAYMENT VERIFIED |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |