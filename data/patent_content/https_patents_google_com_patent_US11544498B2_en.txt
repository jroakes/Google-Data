US11544498B2 - Training neural networks using consistency measures - Google Patents
Training neural networks using consistency measures Download PDFInfo
- Publication number
- US11544498B2 US11544498B2 US17/194,090 US202117194090A US11544498B2 US 11544498 B2 US11544498 B2 US 11544498B2 US 202117194090 A US202117194090 A US 202117194090A US 11544498 B2 US11544498 B2 US 11544498B2
- Authority
- US
- United States
- Prior art keywords
- machine learning
- training
- neural network
- learning task
- output
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active, expires
Links
Images
Classifications
-
- G06K9/6256—
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/084—Backpropagation, e.g. using gradient descent
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F18/00—Pattern recognition
- G06F18/20—Analysing
- G06F18/21—Design or setup of recognition systems or techniques; Extraction of features in feature space; Blind source separation
- G06F18/214—Generating training patterns; Bootstrap methods, e.g. bagging or boosting
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F18/00—Pattern recognition
- G06F18/20—Analysing
- G06F18/21—Design or setup of recognition systems or techniques; Extraction of features in feature space; Blind source separation
- G06F18/217—Validation; Performance evaluation; Active pattern learning techniques
-
- G06K9/6262—
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/045—Combinations of networks
-
- G06N3/0454—
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V10/00—Arrangements for image or video recognition or understanding
- G06V10/70—Arrangements for image or video recognition or understanding using pattern recognition or machine learning
- G06V10/77—Processing image or video features in feature spaces; using data integration or data reduction, e.g. principal component analysis [PCA] or independent component analysis [ICA] or self-organising maps [SOM]; Blind source separation
- G06V10/774—Generating sets of training patterns; Bootstrap methods, e.g. bagging or boosting
Definitions
- This specification relates to neural networks.
- Neural networks are machine learning models that employ one or more layers of nonlinear units to predict an output for a received input.
- Some neural networks include one or more hidden layers in addition to an output layer. The output of each hidden layer is used as input to one or more other layers in the network, i.e., one or more other hidden layers, the output layer, or both.
- Each layer of the network generates an output from a received input in accordance with current values of a respective set of parameters.
- This specification describes a system implemented as computer programs on one or more computers in one or more locations that trains a first neural network to perform a first machine learning task using a measure of consistency between the outputs of the first neural network and the outputs of one or more second neural networks that are each configured to perform a respective second machine learning task that is different from the first machine learning task.
- the measure of consistency characterizes a degree to which the first output and the second outputs are consistent with each other, according to a relationship between outputs for the first machine learning task and outputs for the second machine learning tasks.
- the system can use a mediator data set to train a first neural network to perform a first machine learning task using outputs of one or more second neural networks configured to perform respective second machine learning tasks.
- the mediator training set can include unlabeled training examples that can be processed by the first neural network and the second neural networks to generated outputs for the respective machine learning tasks.
- the system can process a particular unlabeled training example using the first neural network to generate a first output for the first machine learning task, and can process the particular unlabeled training example using each of the second neural networks to generate respective second outputs for the second machine learning tasks.
- the system can generate a target consistency output for the first machine learning task. That is, the target consistency output is an output in the domain of the first machine learning task that, if the first neural network had generated it in response to the particular unlabeled training example, would have been consistent with the second outputs according to the relationship between outputs of the first neural network and outputs of the second neural networks.
- the system can then determine an error between the first output and the target consistency output, and generate a parameter update for the first neural network from the error.
- the training system of each neural network is not constrained by timing requirements of co-training with the other neural networks. For example, to determine a consistency measure between the outputs of a particular neural network and the outputs of the other neural networks, the training system of the particular neural network can submit queries ad-hoc to obtain the network outputs of the other neural networks.
- a training system of each neural network can use different hyperparameters than the training systems of the other neural networks.
- the training system can use a different optimizer, a different regularization term, a different dropout policy, a different learning rate schedule, and/or a different batch updating policy.
- a first neural network for a first machine learning task and a second neural network for a second machine learning task can be trained using the same, twice-labeled training data set, where each training example in the training data set has a first label corresponding to the first machine learning task and a second label corresponding to the second machine learning task.
- training each neural network in isolation on the same training data set can often lead to incoherence between the outputs of the two models.
- a system can enforce a consistency between the outputs of the two neural networks, improving both models.
- FIG. 1 is a diagram of an example training system.
- FIG. 2 is a diagram of an example distributed training network.
- FIG. 3 is a flow diagram of an example process for training a neural network using a consistency measure.
- This specification describes a system that trains a neural network using a consistency measure between the network outputs of the neural network and the network outputs of one or more other neural networks.
- FIG. 1 is a diagram of an example training system 100 .
- the training system 100 is an example of a system implemented as computer programs on one or more computers in one or more locations, in which the systems, components, and techniques described below can be implemented.
- the training system 100 includes a training data store 110 , N task engines 120 a - n , and a consistency loss engine 140 .
- the training system also includes N task loss engines 130 a - n .
- the training system is configured to execute joint training of N different neural networks, N>1, that each correspond to a respective different machine learning task. Examples tasks are discussed below.
- Each task engine 120 a - n is configured to process network inputs obtained from the training data store 110 and to generate network outputs using a different respective neural network from the set of N different neural networks.
- each task engine 120 a - n can obtain the same training input 112 from the training data store 110 , process the training input 112 using the respective neural network according to current values of the neural network, and generate a respective training output 122 a - n .
- the training input 112 can be sampled from a training data set that includes training inputs that can be processed by each of the N neural networks to generate a network output for the corresponding machine learning task.
- a data set that includes network inputs that can be processed by each neural network in a set of neural network is called a “mediator” data set.
- each training input 112 in the mediator data set of the training data store 110 is unlabeled.
- one or more training inputs 112 in the mediator data set are labeled for one or more of the machine learning tasks (i.e., identify a ground-truth output corresponding to the machine learning task).
- the labels are not used for determining the measures of consistency, as described in more detail below.
- the label corresponding to a machine learning task may be used to generate a supervised parameter update for the neural network corresponding to the machine learning task; this process is described in more detail below.
- the task engines 120 a - n can each provide the respective training output 122 a - n to the consistency loss engine 140 , which is configured to process the training outputs 122 a - n to determine a respective consistency update 142 a - n for each neural network.
- the consistency update 142 a - n for a respective neural network is an update to the parameters of the neural network that encourages the outputs of the N different neural networks to be consistent. That is, because the training outputs 122 a - n were all generated in response to the same training input 112 , the consistency loss engine 140 can determine a degree to which they are consistent with each other, and update the parameters of the neural networks according to the degree.
- the consistency loss engine 140 can generate a target consistency output for the machine learning task corresponding to the neural network.
- the target consistency output is an output in the domain of the machine learning task that, if the neural network had generated it in response to the training input 112 , would have been consistent with the other training outputs 122 a - n according to the relationship between outputs of the neural networks.
- the consistency loss engine 140 can then determine an error between the training output 122 a - n generated by the neural network and the target consistency output, and generate the corresponding consistency parameter update 142 a - n for the neural network from the error.
- the consistency loss engine 140 determines multiple different target consistency outputs according to respective different known relationships between i) the output of the neural network and ii) the outputs of respective other subsets of the N neural networks.
- Each known relationship is a relationship between the outputs of the particular neural network (corresponding to a first machine learning task) and the outputs of the neural networks in the corresponding subset of the N neural networks (corresponding to respective other machine learning tasks).
- the consistency loss engine 140 can determine, for each target consistency output for the particular neural network, an error between the training output 122 a - n of the neural network and the target consistency output.
- the consistency loss engine 140 can then combine the errors to generate a combined error for the particular neural network, e.g., by computing a summation of the errors or by computing an average of the errors, and generate the consistency parameter update 142 a - n for the particular neural network using the combined error.
- the relationship between a first machine learning task and one or more second machine learning tasks can be defined by an analytical function that maps outputs for the second machine learning tasks to outputs for the first machine learning task; using this analytical function, the consistency loss engine can directly generate target consistency outputs from outputs for the second machine learning tasks.
- the first machine learning task can be surface-normal prediction; that is, the first neural network can be configured to process an input image and generate an output that predicts a normal direction for one or more surfaces depicted in the input image.
- the second machine learning task can be depth estimation; that is, the second neural network can be configured to process an input image and generate a depth output that includes information about the respective distances of one or more objects depicted in the input image from the viewpoint of the input image. Given a depth output that includes a depth value for each pixel in an image, the normal direction for each pixel in the image can be determined by computing a derivative of the depth values.
- the training system 100 can generate a target consistency output for the surface-normal prediction task by computing the derivative of the depth values for each pixel of the particular image.
- the training system 100 can then compare the target consistency output with a first output corresponding to the surface-normal prediction task and generated by the first neural network in response to processing the particular image.
- the training system 100 can determine an error between the first output and the target consistency output, and generate a parameter update for the first neural network using the error. In this way, the training system 100 can enforce “consistency” between the outputs of the first neural network and the outputs of the second neural network.
- ⁇ circumflex over (n) ⁇ p is the surface-normal prediction generated by the first neural network (i.e., the first output)
- ⁇ circumflex over (n) ⁇ d is the surface normal derived from the depth prediction generated by the second neural network (i.e., the target consistency output).
- the first machine learning task can be whole-image classification; that is, the first neural network can be configured to process an input image and generate one or more class labels for the input image.
- the second machine learning task can be image segmentation; that is, the second neural network can be configured to process an input image and generate segmentation data that includes, for each pixel in the input image, a prediction for a class label, such that pixels with the same predicted class label share one or more characteristics.
- the set of class labels that the first neural network uses to classify images can be the same set of class labels that the second neural network uses to segment images.
- the training system 100 can generate a target consistency output for the whole-image classification task by determining the class labels to which the second neural network assigned at least one pixel. The training system 100 can then compare the set of particular class labels in the target consistency output with a set if class labels in a first output corresponding to the whole-image classification task and generated by the first neural network in response to processing the particular image.
- the training system 100 can compute the error to be the mean-squared error between the first output of the first neural network (i.e., a respective likelihood value corresponding to each possible class label that represents a likelihood that the input image depicts the class label) and the identifications of the class labels corresponding to each segment of the input image identified in the second output of the second neural network.
- the training system 100 can enforce that the first neural network outputs for an input image all of the class labels that the second neural network assigns to one or more pixels of the input image.
- the first machine learning task can be motion prediction; that is, the first neural network can be configured to process one or more input images each corresponding to a different time point and generate an output that predicts how one or more objects depicted in the most recent input image are moving.
- the second machine learning task can be image segmentation. Given a first segmented image corresponding to a first time point and a second segmented image corresponding to a second time point that is later than the first time point, the motion of an object that is depicted in both images can be determined by comparing the labeled pixels of the object in each respective image.
- the training system 100 can generate a target consistency output for the motion prediction task by comparing the two output images and determining the motion of the objects depicted between the two time points. The training system 100 can then compare the target consistency output with a first output corresponding to the motion prediction task and generated by the first neural network in response to processing one or more of the input images.
- the training system 100 can compute the loss between the first output and the target consistency output to be:
- L con_seg ⁇ i , j , c ⁇ L 2 ⁇ ( l c ⁇ ⁇ 1 ′ ⁇ ( i , j ) , l c ⁇ ⁇ 1 ⁇ ( i , j ) ) + ⁇ i , j , c ⁇ L 2 ⁇ ( l c ⁇ ⁇ 2 ′ ⁇ ( i , j ) , l c ⁇ ⁇ 2 ⁇ ( i , j ) ) .
- I c1 (i,j) is the likelihood that pixel (i,j) of the first image is the class c
- l′ c1 (i,j) is the likelihood that pixel (i,j) of the image at the first time point generated by interpolating the pixels of the second image according to the predicted motion is the class c
- l c2 (i,j) is the likelihood that pixel (i,j) of the second image is the class c
- l′ c2 (i,j) is the likelihood that pixel (i,j) of the image at the second time point generated by interpolating the pixels of the first image according to the predicted motion is the class c
- L 2 is the L2 loss.
- the first machine learning task can be depth estimation
- the second machine learning task can be motion prediction.
- the training system 100 can generate a target consistency output for the depth estimation task by interpolating the depictions of the objects between the two time points using the predicted motion.
- the training system 100 can then compare the target consistency output with a first output corresponding to the depth estimation task and generated by the first neural network in response to processing one or more of the input images.
- the training system 100 can compute the loss between the first output and the target consistency output to be:
- L con_photo ⁇ i , j ⁇ L ph ⁇ ( I 1 ′ ⁇ ( i , j ) , I 1 ⁇ ( i , j ) ) + ⁇ i , j ⁇ L ph ⁇ ( I 2 ′ ⁇ ( i , j ) , I 2 ⁇ ( i , j ) ) .
- I 1 is the first image I 2 is the second image
- I 1 ′ is the predicted image at the first time point generated by interpolating the pixels of the second image I 2 using the predicted motion generated by the second neural network
- I 2 ′ is the predicted image at the second time point generated by interpolating the pixels of the first image I 1 using the predicted motion generated by the second neural network
- (i,j) are pixel locations in the two images
- L ph stands for a pixelwise photometric loss, e.g., an L1 penalty on the difference in RGB space and structural similarity (SSIM), each weighed by a coefficient.
- the first machine learning task can be point cloud object detection; that is, the first neural network can be configured to process a point cloud and generate an output that predicts one or more objects represented by the point cloud.
- the second machine learning task can be point cloud object tracking; that is, the second machine learning can be configured to process multiple point clouds representing the same environment at respective time points and generate an output that predicts how one or more objects move through the environment at the respective time points. Given a first set of identified objects in a first point cloud corresponding to a first time point and a second set of identified objects in a second point cloud corresponding to a second time point that is later than the first time point, the motion of an object that is identified in both point clouds can be determined.
- the training system 100 can generate a target consistency output for the point cloud object tracking task by comparing the relative locations in the two point clouds of each object identified in both sets of identified objects and determining the motion of the object between the two time points.
- con_class (classlogit( x,y ) ⁇ classlogit( x′,y ′)) 2
- con_residual ⁇ i ⁇ (x,y, ⁇ ) ( di′ ⁇ di +(flow i ⁇ ( i′ ⁇ i )) 2 + ⁇ j ⁇ (z,l,w,h) ( dj′ ⁇ dj ) 2
- classlogit (x,y) is the predicted class of the point (x,y) (or voxel (x,y) of the point cloud, after the point cloud has been voxelized into a grid of three-dimensional voxels) of the original point cloud (i.e., a respective likelihood value corresponding to each possible class label that represents a likelihood that the point depicts the class label)
- classlogit (x′,y′) is the predicted class of the point (x,y) when the predicted motion of the point is interpolated to a different time point
- flow i is the predicted flow of dimension i of
- the first machine learning task and/or the second machine learning task can be one of: a three-dimensional tracking task, a two-dimensional tracking task, a classification task, an object motion prediction task, an egomotion prediction task, a surface-normal prediction task, a depth prediction task, or a semantic segmentation task.
- the training system 100 can train a neural network to perform a machine learning task in any machine learning domain.
- the first machine learning task can be object or action recognition of a video sequence; that is, the first neural network can be configured to process multiple frames of a video and generate an output that predicts actions that are performed in the video or objects that are depicted in the video.
- the second machine learning task can be speech recognition; that is, the second neural network can be configured to process a sequence of audio data and generate an output that represents text data corresponding to the audio data (e.g., text data representing the same sequence of words spoken in the audio data).
- the training system 100 Given text data that represents the audio of a video sequence, the training system 100 can generate a target consistency output for the object or action recognition task by determining that objects or actions identified in the text sequence are likely to be depicted in the video sequence.
- the first machine learning task can be named entity recognition; that is, the first neural network can be configured to process a text sequence and generate an output that identifies one or more named entities in the text sequence.
- the second machine learning task can be machine translation; that is, the second neural network can be configured to process a text sequence in a first language and to generate an output that represents a text sequence in a second language. Given two text sequences in respective different languages, the training system 100 can generate a target consistency output for the named entity recognition task by determining that the same named entities are likely to be detected in both text sequences.
- the relationship between a first machine learning task and one or more second machine learning tasks is machine-learned. That is, a machine learning model can be configured through training to process network outputs the one or more second neural networks (corresponding to respective second machine learning tasks) and to generate the target consistency output for the first neural network corresponding to the first machine learning task.
- the machine learning model is pre-trained before the training of the first neural network. In some other implementations, the machine learning model is trained concurrently with the first neural network.
- the training system 100 can also execute supervised training of the neural network in conjunction with the training according to consistency described above.
- the training data store 110 can include a “dedicated” training data set to train the neural network.
- the dedicated training set can include labeled training examples corresponding to the machine learning task of the neural network.
- the task engine 120 a - n of the neural network can obtain a labeled training example from the training data store 110 and process the labeled training example using the neural network to generate a training output.
- the first task loss engine 130 a - n corresponding to the neural network can then determine a supervised parameter update 132 a - n according to an error between the training output and the label for the labeled training example.
- one or more training examples can be shared between i) the mediator training data set and ii) the dedicated training data sets corresponding to each of one or more neural networks. That is, the shared training examples are included without a label in the mediator training data set, and with a label corresponding to each of the one or more neural networks.
- the training data store 110 can store, for the training input 112 , a label corresponding to the first neural network of the first task engine 120 a and a label corresponding to the N th neural network of the N th task engine 120 n .
- the first task engine 120 a can then provide the first training output 122 a to the first task loss engine 130 a , which can use the label corresponding to the first neural network to generate a first supervised parameter update 132 a for the first neural network.
- the N th task engine 120 n can provide the N th training output 122 n to the N th task loss engine 130 n , which can use the label corresponding to the N th neural network to generate an N th supervised parameter update 132 n for the N th neural network
- the training system 100 can employ any appropriate batch updating policy to train the neural networks.
- the training system 100 can alternate between i) training example batches that include only training examples from the mediator training data set and ii) training example batches that include only training examples from the dedicated training data sets.
- the system can use training example batches that include one or more training examples from both the mediator training data set and the dedicated training data set.
- the training system 100 can parallelize the training of the N neural networks by training each neural network using a respective different module, e.g., in a different container or virtual machine or on a different processing device. This process is discussed in more detail below with reference to FIG. 2 .
- one or more of the N neural networks are pre-trained. That is, the consistency loss engine 140 can obtain the respective consistency training outputs 122 a - n from the task engines 120 a - n corresponding to the one or more trained neural networks and use the obtained outputs to determine consistency updates 142 a - n for the untrained neural networks. However, the consistency loss engine 140 does not generate consistency updates 142 a - n for the trained neural networks. As a particular example, all but one of the neural networks can be pre-trained, and the consistency loss engine 140 can determine a consistency update 142 for the one untrained neural network using the outputs 122 a - n from each of the task engines 120 a - n.
- FIG. 2 is a diagram of an example distributed training system 200 .
- the distributed training system 200 is an example of a system implemented as computer programs on one or more computers in one or more locations, in which the systems, components, and techniques described below can be implemented.
- the distributed training system 200 includes N task trainers corresponding to respective different neural networks configured to perform respective different machine learning tasks, as described above with reference to FIG. 1 .
- N task trainers corresponding to respective different neural networks configured to perform respective different machine learning tasks, as described above with reference to FIG. 1 .
- Each task trainer can be hosted on a different node of the distributed training system 200 , e.g., a different processing device or a different virtual machine or container.
- the distributed training system 200 also includes N forward pass engines that are each configured to execute forward passes (i.e., process network inputs to generate network outputs) for a respective neural network.
- forward passes i.e., process network inputs to generate network outputs
- K th forward pass engine 270 corresponding to a K th neural network of the N neural networks is depicted in FIG. 2 .
- Each forward pass engine can be hosted on a different node of the distributed training system 200 , e.g., a different processing device or a different virtual machine or container.
- the first task trainer 210 is configured to train the first neural network, in parallel with the training of the other neural networks by the respective other task trainers of the distributed training system 200 .
- the first task trainer 210 includes a first dedicated data store 220 , a mediator data store 230 , a first task engine 240 , a first task loss engine 250 , and a consistency loss engine 260 .
- the mediator data store 230 can be configured to store a mediator training data set that includes unlabeled training examples that can be processed by each of the N neural networks, as described above with reference to FIG. 1 .
- Each trainer in the distributed training system 200 can include a respective mediator data store 230 storing a copy of the same mediator training data set.
- the first task engine 240 which can be configured similarly to the task engines 120 a - n depicted in FIG. 1 , can obtain a mediator training input 232 from the mediator training data set and process the mediator training input 232 using the first neural network to generate a first mediator training output 244 .
- the first task engine 240 can provide the first mediator training output 244 to the consistency loss engine 260 , which can be configured similarly to the consistency loss engine 140 described with reference to FIG. 1 .
- the consistency loss engine 260 can process the first mediator training output 244 to generate a consistency parameter update 262 to the parameters of the neural network.
- the consistency loss engine 260 can obtain respective mediator training outputs generated by the other neural networks of the N neural networks in response to processing the same mediator training input 232 .
- the consistency loss engine 260 can obtain the mediator training outputs from the respective forward pass engines of the distributed training system 200 .
- the first task trainer 210 can submit a request 212 to the K th forward pass engine 270 to provide the K th mediator training output 272 generated by the K th neural network in response to processing the mediator training input 232 .
- the K th forward pass engine 270 can process the mediator training input 232 using the K th neural network, according to the most recent parameter values of the K th neural network available, to generate the K th mediatory training output 272 .
- the K th forward pass engine 270 can obtain the latest values for the parameters of the K th neural network from the task trainer of the distributed training system 200 corresponding to the K th neural network.
- the K th forward pass engine 270 obtains the latest parameters at regular time intervals, e.g., 1 second, 10 seconds, 1 minute, 5 minutes, or 10 minutes. Therefore, in some cases (i.e., in cases where the task trainer of the K th neural network has updated the parameters of the K th neural network but the K th forward pass engine 270 has not yet obtained the updated parameter values), the K th forward pass engine 270 can generate a mediator training output 272 using stale values of the parameters of the K th neural network.
- stale values of the parameters of a neural network are values which were used by the training system of the neural network at a previous time point, but which are no longer being used by the training system of the second neural network.
- the consistency loss engine 260 can obtain the respective mediator training outputs of each of the other neural networks. The consistency loss engine 260 can then generate one or more target consistency outputs for the first machine learning task using the obtained mediatory training outputs, as described above, and generate the consistency parameter update 262 using an error between the target consistency outputs and the first mediatory training output 244 .
- the first dedicated data store 220 stores labeled training examples for training the first neural network.
- the first task engine 240 can obtain a dedicated training input 222 , which has a corresponding label stored in the first dedicated data store 220 , and process the dedicated training input 222 using the first neural network to generate a dedicated training output 242 .
- the first task engine 240 can provide the dedicated training output 242 to the first task loss engine 250 , which can be configured similarly to the task loss engines 130 a - n depicted in FIG. 1
- the first task loss engine 250 can determine an error between dedicated training output 242 and the label for the dedicated training input 222 , and generate a supervised parameter update 252 for the parameters of the first neural network according to the error.
- Each component of the distributed training system 200 can be executed on a different processing device, in parallel.
- the training of the N neural networks can be parallelized, significantly reducing the time required for training.
- each task trainer of the distributed training system 200 e.g., the first task trainer 210
- one or more of the N neural networks can be pre-trained.
- the forward pass engines of the distributed training system 200 corresponding to the trained neural networks can be configured to execute the neural networks according to the final trained parameter values.
- the consistency loss engine 260 can obtain the respective mediator training outputs 272 corresponding to the one or more trained neural networks and use the obtained outputs to determine the consistency parameter update 262 for the untrained first neural network.
- each neural network except the first neural network can be pre-trained, and the consistency loss engine 260 can determine a consistency parameter update 262 for the untrained first neural network using the outputs 272 from each of the forward pass engines executing the trained neural networks.
- FIG. 3 is a flow diagram of an example process 300 for training a first neural network using a consistency measure.
- the process 300 will be described as being performed by a system of one or more computers located in one or more locations.
- a training system e.g., the training system 100 depicted in FIG. 1 , appropriately programmed in accordance with this specification, can perform the process 300 .
- the first neural network has multiple first network parameters, and is configured to execute a first machine learning task.
- the system obtains a mediator training data set that includes multiple unlabeled training examples (step 302 ).
- the system processes a particular training example in the mediator training data set using the first neural network to generate a first network output for the first machine learning task (step 304 ).
- the system processes the particular training example using each of one or more second neural networks (step 306 ).
- Each second neural network is configured to process the particular training example to generate a second network output for a respective second machine learning task that is different from the first machine learning task.
- the system determines, for each second machine learning task and from the second output of the corresponding second neural network, a consistency target output for the first machine learning task (step 308 ).
- the consistency target output is an output of the first neural network that would be consistent with a relationship between outputs for the first machine learning task and outputs for the second machine learning task.
- the system determines, for each second machine learning task, an error between the first output and the consistency target output corresponding to the second machine learning task (step 310 ).
- the system generates a parameter update for the first neural network from the determined errors (step 312 ). For example, the system can combine the errors corresponding to the respective second machine learning tasks, e.g., by determine an average or a sum of the errors. The system can then backpropagate the combined error through the first neural network and determine the parameter update using gradient descent.
- the system can use any appropriate configuration of optimizers to generate the parameter update, e.g., stochastic gradient descent with momentum, adaptive gradients (AdaGrad), or the Adam optimizer.
- Embodiments of the subject matter and the functional operations described in this specification can be implemented in digital electronic circuitry, in tangibly-embodied computer software or firmware, in computer hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them.
- Embodiments of the subject matter described in this specification can be implemented as one or more computer programs, i.e., one or more modules of computer program instructions encoded on a tangible non transitory storage medium for execution by, or to control the operation of, data processing apparatus.
- the computer storage medium can be a machine-readable storage device, a machine-readable storage substrate, a random or serial access memory device, or a combination of one or more of them.
- the program instructions can be encoded on an artificially generated propagated signal, e.g., a machine-generated electrical, optical, or electromagnetic signal, that is generated to encode information for transmission to suitable receiver apparatus for execution by a data processing apparatus.
- data processing apparatus refers to data processing hardware and encompasses all kinds of apparatus, devices, and machines for processing data, including by way of example a programmable processor, a computer, or multiple processors or computers.
- the apparatus can also be, or further include, special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application specific integrated circuit).
- the apparatus can optionally include, in addition to hardware, code that creates an execution environment for computer programs, e.g., code that constitutes processor firmware, a protocol stack, a database management system, an operating system, or a combination of one or more of them.
- a computer program which may also be referred to or described as a program, software, a software application, an app, a module, a software module, a script, or code, can be written in any form of programming language, including compiled or interpreted languages, or declarative or procedural languages; and it can be deployed in any form, including as a stand alone program or as a module, component, subroutine, or other unit suitable for use in a computing environment.
- a program may, but need not, correspond to a file in a file system.
- a program can be stored in a portion of a file that holds other programs or data, e.g., one or more scripts stored in a markup language document, in a single file dedicated to the program in question, or in multiple coordinated files, e.g., files that store one or more modules, sub programs, or portions of code.
- a computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a data communication network.
- the term “database” is used broadly to refer to any collection of data: the data does not need to be structured in any particular way, or structured at all, and it can be stored on storage devices in one or more locations.
- the index database can include multiple collections of data, each of which may be organized and accessed differently.
- engine is used broadly to refer to a software-based system, subsystem, or process that is programmed to perform one or more specific functions.
- an engine will be implemented as one or more software modules or components, installed on one or more computers in one or more locations. In some cases, one or more computers will be dedicated to a particular engine; in other cases, multiple engines can be installed and running on the same computer or computers.
- the processes and logic flows described in this specification can be performed by one or more programmable computers executing one or more computer programs to perform functions by operating on input data and generating output.
- the processes and logic flows can also be performed by special purpose logic circuitry, e.g., an FPGA or an ASIC, or by a combination of special purpose logic circuitry and one or more programmed computers.
- Computers suitable for the execution of a computer program can be based on general or special purpose microprocessors or both, or any other kind of central processing unit.
- a central processing unit will receive instructions and data from a read only memory or a random access memory or both.
- the essential elements of a computer are a central processing unit for performing or executing instructions and one or more memory devices for storing instructions and data.
- the central processing unit and the memory can be supplemented by, or incorporated in, special purpose logic circuitry.
- a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto optical disks, or optical disks. However, a computer need not have such devices.
- a computer can be embedded in another device, e.g., a mobile telephone, a personal digital assistant (PDA), a mobile audio or video player, a game console, a Global Positioning System (GPS) receiver, or a portable storage device, e.g., a universal serial bus (USB) flash drive, to name just a few.
- PDA personal digital assistant
- GPS Global Positioning System
- USB universal serial bus
- Computer readable media suitable for storing computer program instructions and data include all forms of non volatile memory, media and memory devices, including by way of example semiconductor memory devices, e.g., EPROM, EEPROM, and flash memory devices; magnetic disks, e.g., internal hard disks or removable disks; magneto optical disks; and CD ROM and DVD-ROM disks.
- semiconductor memory devices e.g., EPROM, EEPROM, and flash memory devices
- magnetic disks e.g., internal hard disks or removable disks
- magneto optical disks e.g., CD ROM and DVD-ROM disks.
- embodiments of the subject matter described in this specification can be implemented on a computer having a display device, e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor, for displaying information to the user and a keyboard and a pointing device, e.g., a mouse or a trackball, by which the user can provide input to the computer.
- a display device e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor
- keyboard and a pointing device e.g., a mouse or a trackball
- Other kinds of devices can be used to provide for interaction with a user as well; for example, feedback provided to the user can be any form of sensory feedback, e.g., visual feedback, auditory feedback, or tactile feedback; and input from the user can be received in any form, including acoustic, speech, or tactile input.
- a computer can interact with a user by sending documents to and receiving documents from a device that is used by the user; for example, by sending web pages to a web browser on a user's device in response to requests received from the web browser.
- a computer can interact with a user by sending text messages or other forms of message to a personal device, e.g., a smartphone that is running a messaging application, and receiving responsive messages from the user in return.
- Data processing apparatus for implementing machine learning models can also include, for example, special-purpose hardware accelerator units for processing common and compute-intensive parts of machine learning training or production, i.e., inference, workloads.
- Machine learning models can be implemented and deployed using a machine learning framework, e.g., a TensorFlow framework, a Microsoft Cognitive Toolkit framework, an Apache Singa framework, or an Apache MXNet framework.
- a machine learning framework e.g., a TensorFlow framework, a Microsoft Cognitive Toolkit framework, an Apache Singa framework, or an Apache MXNet framework.
- Embodiments of the subject matter described in this specification can be implemented in a computing system that includes a back end component, e.g., as a data server, or that includes a middleware component, e.g., an application server, or that includes a front end component, e.g., a client computer having a graphical user interface, a web browser, or an app through which a user can interact with an implementation of the subject matter described in this specification, or any combination of one or more such back end, middleware, or front end components.
- the components of the system can be interconnected by any form or medium of digital data communication, e.g., a communication network. Examples of communication networks include a local area network (LAN) and a wide area network (WAN), e.g., the Internet.
- LAN local area network
- WAN wide area network
- the computing system can include clients and servers.
- a client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other.
- a server transmits data, e.g., an HTML page, to a user device, e.g., for purposes of displaying data to and receiving user input from a user interacting with the device, which acts as a client.
- Data generated at the user device e.g., a result of the user interaction, can be received at the server from the device.
Abstract
Description
where {circumflex over (n)}p is the surface-normal prediction generated by the first neural network (i.e., the first output) and {circumflex over (n)}d is the surface normal derived from the depth prediction generated by the second neural network (i.e., the target consistency output).
where Ic1(i,j) is the likelihood that pixel (i,j) of the first image is the class c, l′c1(i,j) is the likelihood that pixel (i,j) of the image at the first time point generated by interpolating the pixels of the second image according to the predicted motion is the class c, lc2(i,j) is the likelihood that pixel (i,j) of the second image is the class c, l′c2(i,j) is the likelihood that pixel (i,j) of the image at the second time point generated by interpolating the pixels of the first image according to the predicted motion is the class c, and L2 is the L2 loss.
where I1 is the first image I2 is the second image, I1′ is the predicted image at the first time point generated by interpolating the pixels of the second image I2 using the predicted motion generated by the second neural network, I2′ is the predicted image at the second time point generated by interpolating the pixels of the first image I1 using the predicted motion generated by the second neural network, (i,j) are pixel locations in the two images, and Lph stands for a pixelwise photometric loss, e.g., an L1 penalty on the difference in RGB space and structural similarity (SSIM), each weighed by a coefficient.
where classlogit (x,y) is the predicted class of the point (x,y) (or voxel (x,y) of the point cloud, after the point cloud has been voxelized into a grid of three-dimensional voxels) of the original point cloud (i.e., a respective likelihood value corresponding to each possible class label that represents a likelihood that the point depicts the class label), classlogit (x′,y′) is the predicted class of the point (x,y) when the predicted motion of the point is interpolated to a different time point, flowi is the predicted flow of dimension i of a voxel, di is the change of value of dimension i of a voxel between the two time points, di′ is the predicted change of the value of the dimension when the original value is interpolated according to the predicted flow, and (x,y,z,w,l,h,θ) are the dimensions of the voxel.
Claims (21)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US17/194,090 US11544498B2 (en) | 2020-03-05 | 2021-03-05 | Training neural networks using consistency measures |
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US202062985861P | 2020-03-05 | 2020-03-05 | |
US17/194,090 US11544498B2 (en) | 2020-03-05 | 2021-03-05 | Training neural networks using consistency measures |
Publications (2)
Publication Number | Publication Date |
---|---|
US20210279511A1 US20210279511A1 (en) | 2021-09-09 |
US11544498B2 true US11544498B2 (en) | 2023-01-03 |
Family
ID=77555777
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US17/194,090 Active 2041-07-02 US11544498B2 (en) | 2020-03-05 | 2021-03-05 | Training neural networks using consistency measures |
Country Status (1)
Country | Link |
---|---|
US (1) | US11544498B2 (en) |
Families Citing this family (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11663728B2 (en) * | 2020-01-16 | 2023-05-30 | Samsung Electronics Co., Ltd. | Depth estimation method and apparatus |
US11308971B2 (en) * | 2020-07-15 | 2022-04-19 | Bank Of America Corporation | Intelligent noise cancellation system for video conference calls in telepresence rooms |
US11496501B1 (en) * | 2021-06-30 | 2022-11-08 | Sift Science, Inc. | Systems and methods for an adaptive sampling of unlabeled data samples for constructing an informative training data corpus that improves a training and predictive accuracy of a machine learning model |
CN115551105B (en) * | 2022-09-15 | 2023-08-25 | 公诚管理咨询有限公司 | Task scheduling method, device and storage medium based on 5G network edge calculation |
Citations (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11334766B2 (en) * | 2019-11-15 | 2022-05-17 | Salesforce.Com, Inc. | Noise-resistant object detection with noisy annotations |
-
2021
- 2021-03-05 US US17/194,090 patent/US11544498B2/en active Active
Patent Citations (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11334766B2 (en) * | 2019-11-15 | 2022-05-17 | Salesforce.Com, Inc. | Noise-resistant object detection with noisy annotations |
Non-Patent Citations (87)
Also Published As
Publication number | Publication date |
---|---|
US20210279511A1 (en) | 2021-09-09 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US11132609B2 (en) | Multi-task neural network systems with task-specific policies and a shared policy | |
US11544498B2 (en) | Training neural networks using consistency measures | |
CN111279362B (en) | Capsule neural network | |
US11941527B2 (en) | Population based training of neural networks | |
US20190180136A1 (en) | Domain separation neural networks | |
US11922281B2 (en) | Training machine learning models using teacher annealing | |
WO2019084562A9 (en) | Semantically-consistent image style transfer | |
US11869170B2 (en) | Generating super-resolution images using neural networks | |
US11688077B2 (en) | Adaptive object tracking policy | |
US11783500B2 (en) | Unsupervised depth prediction neural networks | |
US20200410365A1 (en) | Unsupervised neural network training using learned optimizers | |
US10657359B2 (en) | Generating object embeddings from images | |
US11375176B2 (en) | Few-shot viewpoint estimation | |
US11010948B2 (en) | Agent navigation using visual inputs | |
US20220129740A1 (en) | Convolutional neural networks with soft kernel selection | |
US20230281966A1 (en) | Semi-supervised keypoint based models | |
US11951622B2 (en) | Domain adaptation using simulation to simulation transfer | |
EP4095758A1 (en) | Training large-scale vision transformer neural networks | |
US20220301298A1 (en) | Multi-task self-training for learning general representations | |
US10671909B2 (en) | Decreasing neural network inference times using softmax approximation | |
US20220215580A1 (en) | Unsupervised learning of object keypoint locations in images through temporal transport or spatio-temporal transport | |
US20210390407A1 (en) | Training perspective computer vision models using view synthesis | |
US20230051565A1 (en) | Hard example mining for training a neural network | |
WO2023225340A1 (en) | Performing computer vision tasks using guiding code sequences | |
WO2023059737A1 (en) | Self-attention based neural networks for processing network inputs from multiple modalities |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
FEPP | Fee payment procedure |
Free format text: ENTITY STATUS SET TO UNDISCOUNTED (ORIGINAL EVENT CODE: BIG.); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:GORDON, ARIEL;PIRK, SOEREN;ANGELOVA, ANELIA;AND OTHERS;SIGNING DATES FROM 20210316 TO 20210427;REEL/FRAME:056051/0305 |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: DOCKETED NEW CASE - READY FOR EXAMINATION |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: NOTICE OF ALLOWANCE MAILED -- APPLICATION RECEIVED IN OFFICE OF PUBLICATIONS |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: PUBLICATIONS -- ISSUE FEE PAYMENT RECEIVED |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |