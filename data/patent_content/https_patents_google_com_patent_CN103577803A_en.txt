CN103577803A - Use of color and intensity modulation of pixel display - Google Patents
Use of color and intensity modulation of pixel display Download PDFInfo
- Publication number
- CN103577803A CN103577803A CN201310316738.4A CN201310316738A CN103577803A CN 103577803 A CN103577803 A CN 103577803A CN 201310316738 A CN201310316738 A CN 201310316738A CN 103577803 A CN103577803 A CN 103577803A
- Authority
- CN
- China
- Prior art keywords
- target object
- model
- mobile device
- light field
- images
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
Images
Classifications
-
- G—PHYSICS
- G01—MEASURING; TESTING
- G01B—MEASURING LENGTH, THICKNESS OR SIMILAR LINEAR DIMENSIONS; MEASURING ANGLES; MEASURING AREAS; MEASURING IRREGULARITIES OF SURFACES OR CONTOURS
- G01B11/00—Measuring arrangements characterised by the use of optical techniques
- G01B11/24—Measuring arrangements characterised by the use of optical techniques for measuring contours or curvatures
-
- G—PHYSICS
- G01—MEASURING; TESTING
- G01B—MEASURING LENGTH, THICKNESS OR SIMILAR LINEAR DIMENSIONS; MEASURING ANGLES; MEASURING AREAS; MEASURING IRREGULARITIES OF SURFACES OR CONTOURS
- G01B11/00—Measuring arrangements characterised by the use of optical techniques
- G01B11/24—Measuring arrangements characterised by the use of optical techniques for measuring contours or curvatures
- G01B11/245—Measuring arrangements characterised by the use of optical techniques for measuring contours or curvatures using a plurality of fixed, simultaneously operating transducers
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T17/00—Three dimensional [3D] modelling, e.g. data description of 3D objects
Abstract
The invention relates to the use of both the color and the intensity modulation of a pixel display. Particularly, a method and a system for the use of a mobile device with a multi-element display, a camera, and a controller to determine a 3D model of a target object. The multi-element display is configured to generate a light field. At least a portion of the light field reflects from a target object. The camera is configured to capture a plurality of images based on the portion of the light field reflected from the target object. The controller is configured to determine a 3D model of the target object based on the images. The 3D model includes three-dimensional shape and color information about the target object. In some embodiments, the light field may include specific light patterns, spectral content, and other forms of modulated/structured light.
Description
Technical field
The disclosure relates to the color of pixel display and the use of intensity modulated.
Background technology
In computer graphics, three-dimensional (3D) modeling relates to the expression on the 3D surface that produces object.This expression can be called 3D object data model, or referred to as 3D model, and can play up via 3D (render) and played up for or be shown as two dimensional image, or can be shown as 3-D view.3D object data model can utilize by the various geometry entities such as triangle, line and curved surface etc., be connected, in the set of 3d space mid point, represent 3D object.There are the various technology of utilizing some cloud and geometric configuration to produce 3D object data model.
Summary of the invention
In first aspect, provide a kind of mobile device.This mobile device comprises polynary display, camera and controller.Described polynary display is configured to produce light field.At least a portion of light field reflects from target object.Described camera is configured to a part for the light field based on from target object reflection and catches a plurality of images.A plurality of images are caught in the modulation at least one times that described camera is also configured to be synchronized with light field.Controller is configured to the 3D model based on a plurality of image receiving target objects.3D model comprises about the 3D shape of target object and color information.Controller is also configured to determine at least one in the material of the shape of target object, the outward appearance of target object and target object based on 3D model.
In second aspect, provide a kind of method.The method comprises with mobile device illumination target object.Mobile device comprises polynary display and camera.Polynary display is configured to produce modulation light field.Modulation light field illumination target object.The method comprises a plurality of images that utilize camera target acquisition object.Catching of a plurality of images is configured to be synchronized with the modulation at least one times to modulation light field.The method also comprises the 3D model based on a plurality of image receiving target objects.3D model comprises about the 3D shape of target object and color information.In addition, the method comprises based on 3D model and determines at least one in the material of the shape of target object, the outward appearance of target object and target object.
In the third aspect, provide a kind of non-instantaneous computer-readable medium.This non-instantaneous computer-readable medium comprises that computing equipment can be carried out so that computing equipment is carried out the instruction of function, and this function comprises with calculating device illumination target object.Computing equipment comprises polynary display and camera.Polynary display is configured to produce light field.Light field illumination target object.This function comprises a plurality of images that utilize camera target acquisition object.Function also comprises the 3D model based on a plurality of image receiving target objects.3D model comprises about the 3D shape of target object and color information.In addition, function comprises based on 3D model and determines at least one in the material of the shape of target object, the outward appearance of target object and target object.
Aforesaid summary of the invention is only exemplary and is not intended to any type of restriction.Except above-mentioned exemplary aspect, embodiment and feature, reference diagram and the following detailed description, more aspect, embodiment and feature will become obvious.
Accompanying drawing explanation
Figure 1A is the functional-block diagram according to the server system of example embodiment;
Figure 1B is the functional-block diagram according to the distributed computing architecture of example embodiment;
Fig. 1 C is the functional-block diagram according to the computing equipment of example embodiment;
Fig. 1 D is the functional-block diagram according to the server system based on cloud of example embodiment;
Fig. 1 E is the schematic diagram according to the computer program of example embodiment;
Fig. 2 A is the functional-block diagram according to the mobile device of example embodiment;
Fig. 2 B-2D has shown front view, side view and the rear view of mobile device according to example embodiment;
Fig. 3 A shows the scene of the image that utilizes mobile device target acquisition object according to example embodiment;
Fig. 3 B shows the scene of the image that utilizes mobile device target acquisition object according to example embodiment;
Fig. 3 C shows the scene of the image that utilizes mobile device target acquisition object according to example embodiment;
Fig. 3 D shows the scene of the image that utilizes mobile device target acquisition object according to example embodiment;
Fig. 4 is the process flow diagram according to the method for example embodiment.
Embodiment
In the following detailed description, with reference to forming its a part of accompanying drawing.In the accompanying drawings, similarly mark identifies similar assembly conventionally, unless context provides contrary indication.The exemplary embodiment of describing in detailed description and figure is not that intention limits.In the situation that do not depart from the spirit or scope of the theme proposing here, can use other embodiment, also can make other change.To be readily appreciated that, aspect of the present disclosure, as general description here and illustrate in the drawings, can arrange, substitute, combine or separate with various configuration, all these is within the conception of this paper.
Example embodiment disclosed herein relates to utilizes light field illumination (illuminating) target object producing from polynary (multi-element) display of mobile device; The part of the light field based on from target object reflection, utilize camera (camera) to catch a plurality of images; And the 3D model of determining target object based on image.
Certain methods disclosed herein can partly or wholly be implemented by mobile device, can be with or without the mutual of mobile device user.Depend on specific embodiment, mobile device can represent flat computer, laptop computer, smart phone, wireless cellular telephony or any other mobile computing device.In these examples, the polynary display of mobile device can be used to illumination target object.Target object can be any object in the visual field of the camera on mobile device.In certain embodiments, polynary display can provide the light field that comprises white light and/or colored light.Additionally or alternatively, polynary display can produce light from the different piece of polynary display, to provide the illumination to target object (lighting) from different angles.The light field that can produce polynary display carry out other modulation (as intensity, space, color, polarization etc.).
When at least a portion of light field is during just at illumination target object, camera can target acquisition object and from the image of the part of the light field of target object reflection.Image based on catching, can determine 3D model.3D model can comprise about the 3D shape of target object and color information.Except the geometric ranges (extents) and color of target object, 3D shape and color information can also comprise the more element such as the illumination information about target object (brightness on target object surface and reflectivity).
Alternatively, can send the search inquiry based on 3D model by mobile device.Search inquiry can be for specific object (as, in order to search for the price of target object and can to buy the position of target object), or search inquiry can be general (as, for the more information about target object is usually provided).Mobile device can also receive search query results alternatively.Search query results can, for example, comprise the response from server, this response indication about target object and/or with the more information of the similar object of target object.Search query results can additionally or alternatively comprise the suggestion of the other image that obtains target object.
The part of method disclosed herein can be partly by server implementation.In the exemplary embodiment, server can receive the 3D model that comprises target object search inquiry (as, from the search inquiry of mobile device).3D model can based target object a plurality of images, and 3D model can comprise 3D shape and color information about target object.Can 3D model and shape search database be compared in relatively first.Server can relatively produce search query results based on first.Search query results can comprise information about target object, about the information with the similar one or more objects of target object and/or obtain the suggestion of more images of target object.Server can send search query results (for example,, to mobile device).
For example, in the determining of the 3D model that additionally or alternatively, (, in the server based on cloud) one or more servers can performance objective object some or all.For example, a plurality of images that mobile device can target acquisition.Image can be sent to server, and server can be determined the 3D model of target object.3D model can then be sent to mobile device and mobile device receives.In context of the present disclosure, can there is other between server and mobile device mutual.
Mobile device has also been described here.Except other elements, mobile device can comprise polynary display, camera and controller.Polynary display can be LCD display or other any many pel arrays display known in the art.Polynary display can be configured to provide light field that can illumination target object.A part for light field can reflect from target object.Camera can be configured to a plurality of images of the part acquisition target object of the light field based on from target object reflection.Controller can be configured to determine based on image the 3D model of target object.3D model can comprise about the 3D shape of target object and color information.
Alternatively, controller can also be configured to send search inquiry and also receive search query results based on 3D model.Polynary display can also be configured to show that playing up of 3D model represents and about the out of Memory of 3D model.
The non-instantaneous computer-readable medium of the instruction with storage is also disclosed here.Instruction can be that computing equipment is executable, so that those functionally similar functions of describing in computing equipment execution and said method.
It will be understood to those of skill in the art that, there are a lot of different specific method and systems, described method and system can be used to the light field illumination target object with the polynary display generation of mobile device, the part of the light field based on from target object reflection is caught a plurality of images, and the 3D model of determining target object based on image.Each in these specific method and systems is expected in context of the present disclosure, and several example embodiment are described below.
Figure 1A shows the example system 100 for object data modeling.System 100 comprises the input source 102 that is coupled to server 104 and database 106.Server is also shown as being coupled to database 106 and export target 108.System 100 can comprise assembly more or still less, and each in input source 102, server 104, database 106 and export target 108 can comprise a plurality of elements equally, or each in input source 102, server 104, database 106 and export target 108 can interconnect equally.Therefore, one or more can being divided in additional function or physical assemblies in the function of described system 100, or be combined in function or object assembly still less.At some, in other example, additional function and/or physical assemblies can be added in the example shown in Figure 1A.
The assembly of system 100 can be coupled to network (not shown), or be configured to can be via the communication of network (not shown), and described network is such as for example Local Area Network, wide area network (WAN), wireless network (Wi-Fi) or the Internet.In addition, the random component of system 100 can utilize wired or wireless communication to intercouple.For example, communication link between input source 102 and server 104 can comprise the wired connection such as universal serial bus or parallel bus, or wireless connections, described wireless connections are such as bluetooth, IEEE802.11(IEEE802.11 can refer to IEEE802.11-2007, IEEE802.11n-2009 or any other IEEE802.11 version) or other communication link based on wireless.
Input source 102 can be the source such as mobile device, from described source, can receive 3D model, or object data model.In some instances, 3D model obtains (shape and outward appearance) and can complete by work to scan the target object of 3D together with supplier or manufacturer.For example, the image that structured light scanner can target acquisition object and can utilize monochromatic three-dimensional camera and pattern projector to recover the shape of target object.The whole bag of tricks that recovers 3D shape and color information from image is known in the art.For example, exercise recovery structure (Structure From Motion, SFM), stereoscopic vision (stereoscopy), various visual angles method (multiscopy), by Structured Illumination and computer vision with other known technology of 3D imaging field can be used alone or be used in combination to form 3D model with various.
In other example, input source 102 can comprise digital single anti-(Digital Single-Lens Reflex, the DSLR) camera of the high resolving power of the image that can be used to catch color texture information.In other example, for each object, can receive one group of original (raw) computer aided drawing (CAD) and draw.In another example, mobile device (as, phone, flat computer, laptop computer etc.) can obtain a plurality of images of target object and can determine 3D model from described image.Therefore, input source 102 can offer server 104 by 3D model with various forms.As an example, the multiple scaaning of object can be processed into grid (merged mesh) and asset data (assets data) model of merging, and offers server 104 with that form.As another example, input source 102 can provide 3D model in the context of search inquiry.
Alternatively, mobile device can have the polynary display that can produce light field.A part for light field can reflect from target object.Mobile device can comprise camera, and the part of the light field that this camera can be based on from target object reflection is caught a plurality of images.These images from mobile device can represent input source, and system is determined 3D model information from described input source.Alternatively, mobile device can determine that 3D model and 3D model (and out of Memory) can be considered to the input of described system.
Server 104 comprises Construction of A Model device 110, object data model processor 112, semantics and search index 114 and shape library 116.The random component of server 104 can be coupled to each other.In addition, alternatively, the random component of server 104 can be the separated assembly that is coupled to server 104.Server 104 can also comprise for example processor and storer, and described storer comprises the instruction of the function of the assembly that can be executed by processor to carry out server 104.
The Grid dataset that Construction of A Model device 110 receives from each object of input source 102, this Network data set can comprise the data set of the dense surface mesh of definition how much (dense surface mesh geometry), and can produce the animation model of the object of 3D.For example, Construction of A Model device 110 can be carried out from the consistance texture of surface mesh and disassemble, and determines the surperficial texture by geometry emulation.
Object data model processor 112 can also receive from the Grid dataset of each object of input source 102 and produce show grid.For example, the grid image of scanning can utilize texture preserve to simplify (decimation) to simplify (as, from 500 ten thousand to 120,000 surfaces).The generation of texture also can be performed to be identified for the color texture that mapping is played up.For producing whole texture, each image pixel can be associated with predetermined texture pixel.
Semantics and search index 114 can receive the image of catching or be simplified and the image of the processing compressed, and can carry out texture and resample and the index based on shape.For example, for each object, semantics and search index 114 can by the component of image (as, each pixel) index for or be labeled as and there are specific texture, color, shape, geometric figure, attribute etc.
For example, shape library 116 can comprise that WebGL or OpenGL mesh compression are to reduce grid file size.For example, shape library 116 can provide for the form of the demonstration on browser 3D object data model (or 3D model).In some instances, 3D object data model reader can be used to show the image of 3D object data model.For example, 3D object data model reader can utilize WebGL or OpenGL in web browser to realize.
Shape search database 106 can be stored with the raw data from catching all data sets of 3D object data model to the various forms of any amount of the data of the processing for showing.In addition, shape search database 106 can be with acting on the reference shape storehouse comparing with 3D model.For example, once receive the 3D model of search inquiry form from input source 102, this 3D model can compare to obtain the information for generation of search query results with shape search database 106.Search query results can comprise the information such as similar object aspect the combination in any of the thingness at shape, texture, color, size, volume bound (bound volume), brightness, reflectivity and/or any other index in shape search database 106.
Shape search database 106 is communicatively coupled to server 104, but does not require it with physics mode or be otherwise connected to server 104.Shape search database 106 also can be integrated in server 104.Whether shape search database 106 can collaboratively with other element of system 100 be used to determine between 3D model and the object of shape search database 106 and exist and mate.
Export target 108 can comprise many different targets, such as the webpage on the Internet, search engine, database.Export target 108 can comprise 3D object data model reader, and it allows based on 3D object data model realization product advertising or product search.In the example here, export target 108 can also comprise input source 102.For example, mobile device can offer 3D model system 100 and be considered to input source 102 with search inquiry.In such example, system 100 can produce search query results and search query results is sent to mobile device.Therefore, mobile device also can be considered to export target 108.Other export target 108 is possible.For example, search query results can send to different mobile devices from system 100.
Figure 1B, Fig. 1 C and Fig. 1 D show the example of the computing equipment using in the system according at least some embodiment arrangements described herein.Depend on specific embodiment, computing equipment can be personal computer, mobile device, cellular phone, wearable computer, flat computer or server.Computing equipment can be used to realize following system and method: described system and method, for light field illumination target object, obtains a plurality of images based on acquisition from the part of the light field of target object reflection, and based on image, produces the 3D model of target object.Method can comprise that sending/receiving comprises the search inquiry of 3D model alternatively, by 3D model and the comparison of shape search database, produce based on the comparison search query results, and sending/receiving search query results, as mentioned above and as shown in Figure 1A, and as shown in other place in the disclosure.
Figure 1B shows server apparatus 128,130, and it is configured to communicate by letter with 124c with programmable device 124a, 124b via network 126.Network 126 can be corresponding to LAN, wide area network (WAN), company intranet, public the Internet or is configured to provide the network of any other type of the communication path between the computing equipment of networking.Network 126 also can be corresponding to the combination of one or more LAN, WAN, company intranet and/or public the Internet.
Although Figure 1B only shows three programmable devices, Distributed Application framework can be served tens of, hundreds of, thousands of or even more programmable device.In addition, programmable device 124a, 124b and 124c(or arbitrarily additional programmable device) can be the computing equipment of any kind, as laptop computer, flat computer, desktop PC, the network terminal, Wireless Telecom Equipment (as cellular phone or smart phone), etc.In certain embodiments, programmable device 124a, 124b and 124c can be absorbed in the design and use of software application.In other embodiments, programmable device 124a, 124b and 124c can be the multi-purpose computers that is configured to carry out many tasks and needn't be absorbed in SDK (Software Development Kit).
Server apparatus 128,130 can be configured to carry out the one or more service that programmable device 124a, 124b and/or 124c ask.For example, server apparatus 128 and/or 130 can offer content programmable device 124a-124c.Content can include but not limited to, webpage, hypertext, script, such as binary data, image, audio frequency and/or the video of the software through compiling.Content can comprise compression and/or unpressed content.Content can be encrypt and/or unencrypted.The content of other type is also possible.
As another example, server apparatus 128 and/or 130 can be provided to the access for software database, search, calculating, figure, audio frequency, video, the utilization of WWW/the Internet and/or other function to programmable device 124a-124c.A lot of other examples of server apparatus are also possible.
Fig. 1 C is computing equipment according to the example embodiment block scheme of (as, system).Specifically, the computing equipment shown in Fig. 1 C 150 can be configured to carry out the one or more one or more functions in server apparatus 128,130, network 126 and/or programmable device 124a, 124b, 124c.Computing equipment 150 can comprise Subscriber Interface Module SIM 151, network communication interface module 152, one or more processor 153 and data-carrier store 154, and all these can link together via system bus, network or other connection mechanism 155.
Subscriber Interface Module SIM 151 can be exercisable to send data to external user input-output apparatus and/or to receive data from external user input-output apparatus.For example, Subscriber Interface Module SIM 151 can be configured to send data to user input device and/or receive data from user input device, and described user input device is such as keyboard, keypad, touch-screen, computer mouse, tracking ball, operating rod, camera, voice recognition module and/or other similar devices.Subscriber Interface Module SIM 151 also can be configured to output to offer user's display device, such as one or more cathode ray tube (CRT)s, liquid crystal display (LCD), light emitting diode (LED), utilize digital light to process display, printer, bulb and/or other similar devices of (DLP) technology, or now known or exploitation later.Subscriber Interface Module SIM 151 also can be configured to produce audible output, as loudspeaker, loudspeaker socket, audio output port, audio output apparatus, earphone and/or other similar devices.
Network communication interface module 152 can comprise one or more wave points 157 and/or one or more wireline interface 158, and wave point 157 and wireline interface 158 can be configured to communicate via the network of the network 126 such as shown in Figure 1B.Wave point 157 can comprise one or more radio transmitters, receiver and/or transceiver, as bluetooth transceiver, purple honeybee transceiver, Wi-Fi transceiver, WiMAX transceiver and/or be configured to the wireless transceiver via other similar type of wireless communication.Wireline interface 158 can comprise one or more wired transmitters, receiver and/or transceiver, as ethernet transceiver, USB (universal serial bus) (USB) transceiver or be configured to via twisted-pair feeder, concentric cable, fiber optic links or similarly arrive the similar transceiver of the physical connection communication of cable network.
In certain embodiments, network communication interface module 152 can be configured to provide communication reliable, safe and/or that authenticated.For each communication described herein, can be provided for guaranteeing the information of reliable communication (namely guaranteed information delivery), this information perhaps as message header and/or afterbody (footer) (as, bag/message sequence information, encapsulated header and/or afterbody, size/temporal information and such as the transmission authorization information of CRC and/or parity values) a part be provided.Can utilize such as, but be not limited to, one or more cipher protocols of DES, AES, RSA, Diffie-Hellman and/or DSA and/or algorithm are protected (for example, coding or encrypt) and/or deciphering/decoding to communication.Other cipher protocol and/or algorithm also can be used or use together with listing those agreements here, to protect (then deciphering/decoding) communication.
Processor 153 can comprise one or more general processors and/or one or more application specific processor (as, digital signal processor, special IC, etc.).Processor 153 can be configured to carry out and be included in computer-readable program instructions 156a and/or other instruction as described herein in data-carrier store 154.
Data-carrier store 154 can comprise can be by least one the one or more computer-readable recording medium that read and/or access in processor 153.One or more computer-readable recording mediums can comprise can be integrally or partly with processor 153 at least one integrated volatibility and/or non-volatile storage component, as optics, magnetic, organically or other storer or disk storage.In certain embodiments, data-carrier store 154 can utilize single physical equipment (as, an optics, magnetic, organically or other storer or disk storage unit) realize, yet in other embodiments, data-carrier store 154 can utilize two or more physical equipments to realize.
Data-carrier store 154 can comprise computer-readable program instructions 156a, true environment 156b and possible additional data.True environment 156b can stores software applications one or more processes and/or at least some in the data used of thread.In certain embodiments, data-carrier store 154 can additionally comprise the required storer of at least a portion of carrying out method described herein and at least a portion of technology and/or the function of equipment described herein and network.
Fig. 1 D has described to be arranged to calculating cluster 159a, the 159b of the server system based on cloud and the network 126 of 159c according to example embodiment.Server apparatus 128 and/or 130 can be the equipment based on cloud, described device storage programmed logic based on cloud and/or the data of the application based on cloud and/or service.In certain embodiments, server apparatus 128 and/or 130 can be the single computing equipment being present in single computing center.In other embodiments, server apparatus 128 and/or 130 can be included in many computing equipments in single computing center or or even be arranged in a plurality of computing equipments of the many computing centers that are in diverse geographic location.For example, Figure 1B has described to be present in each in the server apparatus 128 and 130 in different physical locations.
In certain embodiments, in the data of server apparatus 128 and/or 130 and service, can be encoded as and be stored in computer-readable information in tangible computer-readable medium (or computer readable memory medium) and that can be accessed by programmable device 124a, 124b and 124c and/or other computing equipment.In certain embodiments, data in server apparatus 128 and/or 130 can be stored on single disc driver or other tangible storage medium, or can realize being positioned on many disk drives of one or more diverse geographic locations or other tangible storage medium.
Fig. 1 D has described the server system based on cloud according to example embodiment.In Fig. 1 D, server apparatus 128 and/or 130 function can distribute among calculating cluster 159a, 159b and 159c at three.Calculate cluster 159a and can comprise one or more computing equipment 150a, cluster memory array 160a and the cluster routers 161a connecting by local cluster network 162a.Similarly, calculate cluster 159b and can comprise one or more computing equipment 150b, cluster memory array 160b and the cluster routers 161b connecting by local cluster network 162b.Similarly, calculate cluster 159c and can comprise one or more computing equipment 150c, cluster memory array 160c and the cluster routers 161c connecting by local cluster network 162c.
In certain embodiments, each that calculate in cluster 159a, 159b and 159c can have the computing equipment of equal number, the cluster memory array of equal number and the cluster routers of equal number.Yet in other embodiments, each calculates cluster can the computing equipment of varying number, the cluster memory array of varying number and the cluster routers of varying number.The quantity of calculating computing equipment, cluster memory array and cluster routers in cluster at each can depend on calculation task or the task that each calculates cluster that be assigned to.
In calculating cluster 159a, for example, computing equipment 150a can be configured to carry out the various calculation tasks of server 130.In one embodiment, server 130 various functional can be distributed among one or more in computing equipment 150a, 150b and 150c.Computing equipment 150b, 150c in calculating cluster 159b, 159c can be configured to be similar to the computing equipment 150a in calculating cluster 159a.On the other hand, in certain embodiments, computing equipment 150a, 150b and 150c can be configured to carry out different functions.
In certain embodiments, the data of the calculation task associated with server apparatus 128 and/or 130 and storage at least in part the processing requirements based on server apparatus 128 and/or 130, computing equipment 150a, 150b and 150c processing power, each calculate between the computing equipment in cluster and calculate the delay of the network linking between cluster itself and/or can contribute to the cost, speed of whole system framework, fault-tolerant, elasticity, efficiency and/or other design object other factors and across computing equipment 150a, 150b and 150c distribution.
Cluster memory array 160a, the 160b and the 160c that calculate cluster 159a, 159b and 159c can be the data storage arrays that comprises disk array controller, and described disk array controller is configured to the write access of management to hard disk drive group.Disk array controller, work in coordination with individually or with their computing equipments separately, also can be configured to backup or the redundant copy of the data of managed storage in cluster memory array, to take precautions against disk drive or other cluster memory array fault and/or network failure, described fault and/or network failure stop one or more computing equipments to access one or more cluster memory arrays.
With the function of server apparatus 128 and/or 130 can be similar across calculating computing equipment 150a, the 150b of cluster 159a, 159b and 159c and mode that 150c distributes, the various active part of these assemblies and/or reserve piece also can distribute across cluster memory array 160a, 160b and 160c.For example, some cluster memory arrays can be configured to the data of storage server equipment 128, and the data that other cluster memory array can storage server equipment 130.In addition, some cluster memory arrays can be configured to be stored in the backup version of the data of storing in other cluster memory array.
In certain embodiments, the configuration of cluster routers 161a, 161b and 161c at least in part the data communication based on computing equipment and cluster memory array require, the delay of communication capacity, localized network 162a, 162b and 162c and delay, handling capacity and the cost of handling capacity, Wide Area Network link 163a, 163b and 163c of the network equipment in cluster routers 161a, 161b and 161c and/or can contribute to the other factors of the cost, speed of suitable system architecture, fault-tolerant, elasticity, efficiency and/or other design object.
Fig. 2 A shows the functional-block diagram of mobile device 200, mobile device 200 is configured to use the light field illumination target object from polynary display as what the disclosure was described, the part of the light field based on from polynary display reflects is caught a plurality of images, and from image, determines the 3D model of target object.
In example embodiment, mobile device 200 can comprise such as the subsystem of image capture system 202, positioning system 204, display 206 and peripherals 208 and power supply 210, controller 212, storer 214 and user interface 216.
Image capture system 202 can comprise the assembly such as 2D image processor 218, imageing sensor 220, camera optical device (camera optics) 222,3D Construction of A Model device 224 and illuminometer (light meter) 226.Positioning system 204 can comprise the assembly such as gyroscope 228, accelerometer 230 and stadimeter 232.Display 206 can comprise polynary display pannel 234 and display modulator 236, and peripherals 208 can comprise wireless communication interface 238, touch pad/touch-screen 240, microphone 242, loudspeaker 244 and shutter release button 246.
In some instances, polynary display can comprise that LCD display maybe can be configured to provide perhaps any other many pel arrays display of how different light fields of light field.Polynary display can comprise that a plurality of light emitting diodes (LED) and each LED or LED group can separately be controlled.In other example, display 206 can comprise two or more display pannels, and each can separately be controlled.In further example, the various elements of polynary display pannel 234 can comprise pixel, LED, panel, or the part of display 206 can be considered to the element of display 206.In some examples here, the element of polynary display pannel 234 can be independent of other element operation of polynary display pannel 234 or be controlled.
Mobile device 200 can represent still camera, video camera, cellular phone, network cameras, flat-panel devices or any other image capture device known in the art.In addition, mobile device 200 can be in a part for wearable computing system and/or the computing equipment known in the art that is integrated into any amount.
Mobile device 200 can be used in 3D machine vision.For example, the various embodiment of mobile device 200 can use robot control system (as, automatic scanning system) realize with the light field illumination target object with polynary display, the part of the light field based on from target object reflection is caught image, and based on image, determines the 3D model of target object.
Many or all functions of mobile device 200 can be controlled by controller 212.Controller 212 can comprise that execution is stored in the one or more processors (as microprocessor) as the instruction in the non-instantaneous computer-readable medium of storer 214.Controller 212 can be controlled user interface 216 and show 3D model on polynary display pannel 234.In addition, controller 212 can be controlled the light field that display modulator 236 produces for target object illumination.Controller 212 also can be controlled various other assemblies of image capture system 202 and mobile device 200.Controller 212 also can represent can be for controlling the single component of mobile device 200 or a plurality of computing equipments of subsystem with distributed way.
Except instruction, storer 214 can be stored 2D image as caught before and the data of 3D model.Therefore, storer 214 can be as the data storage of the information relevant with 3D object model.Such information can be during target object illumination, image capture and 3D Construction of A Model process, in different some mobile devices 200 and controller 212 uses.
Mobile device 200 can comprise for information being offered to the user of mobile device 200 or receiving the user interface 216 of input from the user of mobile device 200.User interface 216 can be controlled content and/or the layout of the interaction figure picture that can show on polynary display pannel 234 or realize the control to it.In addition, user interface 216 can be included in the one or more input-output apparatus in one group of peripherals 208, such as touch pad/touch-screen 240, microphone 242 and loudspeaker 244.Controller 212 can be based on receiving by user interface 216 the function of input control mobile device 200.For example, controller 212 can utilize the user input from touch pad/touch-screen 240, controls image capture system 202 and when should start to use while catching a plurality of image from the light field illumination target object of polynary display pannel 234 part of the light field based on from target object reflection.
Image capture system 202 can comprise and some assemblies like those component class that can find in digital camera.Especially, image capture system 202 can comprise the various camera optical device 222 that are configured to visual field to offer imageing sensor 220.Image capture system 202 can also comprise that being configured at least operate view data also also produces various other processors of 3D model to create a plurality of 2D image files from 2D image file.These processors can comprise 2D image processor 218 and 3D Construction of A Model device 224.Image capture system 202 can also comprise illuminometer 226.In certain embodiments, illuminometer 226 can be configured to the photo measure of the part of the light field based on from target object reflection to offer controller 212.Photo measure can be used to set exposure parameter, and described exposure parameter can comprise ISO, shutter speed and the aperture setting of using when a plurality of image of target acquisition object.In addition, user interface 216 can operate in response to photo measure.For example, if intensity level is confirmed as lower than predetermined threshold, user interface 216 can ask, provide instruction or otherwise warn user during image capture, to keep mobile device 200 stable.Alternatively, user interface 216 can ask user to move mobile device 200, so that more completely and/or from different position illumination target objects.
Gyroscope 228 can be the gyroscope of MEMS (micro electro mechanical system) (microelectromechamical system, MEMS) gyroscope, fibre optic gyroscope or other type known in the art.Gyroscope 228 can be configured to azimuth information to offer controller 212.Positioning system 204 can also comprise accelerometer 230, and it is configured to action input data to offer controller 212.Accelerometer 230 can be a kind of or combination in any in known accelerometer type known in the art, known accelerometer type is such as piezoelectricity, optics, resistance, electric capacity, shearing (shear mode), strainometer (strain gauge), surface acoustic wave, laser instrument, MEMS, etc.
Display 206 can comprise polynary display pannel 234 and display modulator 236.Polynary display pannel 234 can be LCD display, light-emitting diode display or any other face display known in the art.Display modulator 236 can be configured to modulate polynary display, so that with the various light field illumination target objects that can help to determine the 3D model of target object.For example, light field can comprise polarized light, structured light, colorama and the light producing from the different piece of polynary display pannel 234.The light field of other type is possible.Display 206 can be configured to various figures to offer the user of mobile device 200.For example, display 206 can be as a part for user interface 216, so that image, text, menu and instruction are shown to user.
Display 206 can be alternatively or is additionally comprised projector 237, and it can be used to light field to project on target object.Similar with polynary display pannel 234, projector 237 can be controlled to provide a plurality of different light fields, and described a plurality of different light fields can comprise the figure of Points And lines figure, Airy disk (airy pattern) and spectrum change etc.In certain embodiments, projector can focus light on target object, target object is used than the more photon of polynary display pannel and illuminated.
In certain embodiments, than environment light source, display 206 can be configured to provide major part to incide the photon on target object.In other words, the display 206 of mobile device 200 can be to provide the principal light source to the illumination of target object.
Display 206 can also comprise light regulator, and described light regulator can fixedly be attached to or be coupled to mobile device 200 in temporary or permanent mode, to regulate the many first display pannels 234 of display 206(or projector) light that produces.Light regulator can include, but not limited to the combination in any of grid (grid), grating and/or diffraction optical element.Also can use known in the art by distinctive structure offer light field (as, lattice array, linear array, Airy disk etc.) other light regulator.
Mobile device 200 can comprise one group of peripherals 208, and it can be configured to input be provided to mobile device 200 or other local user and the output from mobile device 200 or other local user is provided.In one example, mobile device 200 can comprise for one or more equipment directly or via the wireless communication interface 238 of communication network radio communication.For example, wireless communication interface 238 can be used 3G cellular communication, as CDMA, EVDO, GSM/GPRS or 4G cellular communication, as WiMAX or LTE.Alternatively, wireless communication interface 238 can be such as utilizing WiFi to communicate by letter with wireless lan (wlan).In certain embodiments, wireless communication interface 238 can for example be used infrared link, bluetooth or purple honeybee directly and devices communicating.
The assembly of mobile device 200 can be configured to work with the mode of their internal system separately or outside other assembly interconnect.For example, in example embodiment, the user of mobile device 200 can press shutter release button 246 when mobile device 200 is under 3D Target Modeling pattern.In response to user's input, stadimeter 232 can be determined the distance of the related objective object in camera optical device 222 visual fields.Camera optical device 222 can be gathered on target object automatically.Polynary display pannel 234 can be shown device modulator 236 and control to use light field illumination target object.Illuminometer 225 can be controlled with at least based on setting correct exposure from the part of light field and the various characteristics of camera optical device 222 and imageing sensor 220 of target object reflection, as aperture and ISO setting by controller 212.In response to setting correct exposure, a plurality of images that imageing sensor 220 can be controlled with target acquisition object by controller 212.Raw data from imageing sensor 220 can be sent to 2D image processor 218 to raw image files is converted to the picture format of compression, as JPEG (joint photographic experts group) (JPEG) Standard File Format.Image can be sent to 3D Construction of A Model device 224 to determine the 3D model of target object.
Although Fig. 2 A shows the various assemblies of mobile device 200 and is integrated in mobile device 200, described various assembly is wireless communication interface 238, controller 212, storer 214, imageing sensor 220, polynary display pannel 234 and user interface 216 namely, but one or more in these assemblies can install dividually with mobile device 200 or be associated.For example, imageing sensor 220 can be installed separately with mobile device 200.Therefore, mobile device 200 can provide can be positioned at the form of the equipment component of position separately or identical position.Form mobile device 200 equipment component can with or wired or wireless mode be coupled communicatedly.
Fig. 2 B-2D shows the mobile device 250 comprising as the various elements of main body 252, front-facing camera 254, polynary display 256, shutter release button 258 and other button 260.Mobile device 250 can also comprise post-positioned pick-up head 262.Front-facing camera 254 is positioned in the one side of common user oriented mobile device 250 in operation or in the one side of equipment with polynary display.Post-positioned pick-up head 262 is positioned in the one side of the mobile device 250 relative with front-facing camera 254.Certainly, it is arbitrarily that camera is called to preposition and postposition, and mobile device 252 can comprise the many cameras on the not ipsilateral that is positioned at mobile device 252.The element of mobile device 250 can comprise some or all in the element of describing for Fig. 2 A.Although mobile device 250 is described to flat computer, other embodiment is possible.For example, among other example, mobile device 250 can be smart phone, wearable computer or laptop computer.
Front-facing camera 254 can comprise imageing sensor and as the associated optical element of lens.Front-facing camera 254 can provide zoom capabilities maybe can have the lens of fixed focal length.In other embodiments, tradable lens can use together with front-facing camera 254.
Front-facing camera 254 can have variable mechanical aperture and mechanical shutter.Front-facing camera 254 can alternatively comprise electronic shutter.Front-facing camera 254 can be configured to catch still image, video image or both.In addition, front-facing camera 254 can represent monoscopic (monoscopic) camera, solid (stereoscopic) camera or various visual angles (multiscopic) camera.
Controller, such as the controller 212 of Fig. 2 A, can be used to determine based on a plurality of images of catching the 3D model of target object.3D model can comprise about the 3D shape of target object and color information.3D model also can comprise the information about other form of target object, comprises reflectivity and monochrome information about target object.3D model can comprise point cloud model and/or the wire-frame model of target object.3D model can utilize some methods known in computer vision and 3D imaging field to determine, comprises exercise recovery structure (SFM) and stereoscopic vision/various visual angles law technology.
The controller of mobile device 250 can be configured to send the search inquiry that comprises 3D model alternatively.Search inquiry can be the request to the more general informations about target object.Alternatively, search inquiry can be the specific request to the information about target object of the unit number such as target object and model.Specific request to the information of other type about target object is possible.Search inquiry can via the wired or wireless communication interface of any type (as, such as wireless communication interface 238) or any other mode of data transmission send.
In addition, the controller of mobile device 250 can be configured to receive search query results alternatively.Search query results can be received via the wired or wireless communication link of any type or other data transfer mode.Search query results can comprise, for example, and about the information of target object, about the information with the similar object of target object and/or the suggestion of obtaining the other image of target object.
In certain embodiments, mobile device 250 can be configured to fixedly be attached to or be coupled to, motor-driven erecting frame (motorized mount) (for example,, such as the motor-driven erecting frame 248 shown in Fig. 2 A).Motor-driven erecting frame like this can be used to, such as, one group predetermined about different visual fields, visual angle and/or the position of target object between mobile mobile device.Motor-driven erecting frame 248 can be controlled by controller 212 to determine the 3D model of target object based on a plurality of images, and described a plurality of images are hunted down at least in part when motor-driven erecting frame moves between one group of different visual fields, visual angle and/or position about target object.
Fig. 3 A shows the scene 300 of the image that utilizes mobile device target acquisition object.Fig. 3 A comprise can with the similar mobile device 302 of mobile device 200 of Fig. 2 A.Mobile device 302 can comprise the camera 304 with visual field.Mobile device 302 can the local environment of stapler 308 in being considered to target object in.In certain embodiments, shutter release button 306 can be used to trigger illumination and image capture process.Polynary display 316 can be used to light field 314 illumination target objects.Light field can comprise specific optical mode as above (as, utilize Polarization filter polarized light, have special spectrum content light, be derived from the light of the diverse location of polynary display 316, etc.).Light field can alternatively comprise that one or more lattice arrays, band array, comb mesh pattern, concentric circles, Airy disk and/or interference figure are as element.
In an exemplary scene 318 shown in Fig. 3 B, the lower part 322 of polynary display brightens and upper part 320 does not brighten.This can be considered to the first light field.Fig. 3 C shows scene 324, and wherein the upper part 326 of polynary display brightens and lower part 328 does not brighten.This can be considered to the second light field.If catch the respective image of stapler 328 during by the illumination of the first light field and the second light field when stapler 308, can determine more shape, color and texture (and other attribute) information from described image.For example, stapler staple cartridge 310 can be by high-reflectivity metal material, as stainless steel is made.The image of the stapler 308 throwing light on by the first light field can be included in the mirror-reflection of the primary importance in stapler staple cartridge 310.The image of the stapler 308 under the second light field illumination can be included in the mirror-reflection of the second place in stapler staple cartridge 310.Difference between the primary importance of each mirror-reflection and the second place (and other side of a plurality of images) can provide about the shape of stapler 308 and the information of material.Therefore,, by catching after the match a plurality of images in various light modulated, can determine 3D model.In addition the interaction of mirror-reflection and other known light/item, (as photoluminescence, absorption and/or specific to other spectral signatures of material) also can be used to determine the material of target object.
Depend on embodiment, the intensity of light field can be to make to incide most of light source on object from polynary display 316.In other words, than as other light source of surround lighting, polynary display 316 can be used as principal light source.Front-facing camera 304 can be used to catch a plurality of images of stapler 308.The image of catching can be based on being reflected by stapler 308 the part of the light field that produces of polynary display 316.Can catch image from one or more different visual angles (as the visual angle of watching shown at Fig. 3 D) of watching, to obtain the more complete data set about target object.
The controller of mobile device 302 can be configured to the 3D model that image based on obtaining and light field are determined stapler 308.3D model can utilize the whole bag of tricks known in the art such as exercise recovery structure (SFM) and other 2D determine to 3D conversion and 3D Construction of A Model technology.3D model can comprise the polygonal set of a cloud and formed shape.Out of Memory in 3D model be can be included in and texture, color, reflectivity and the relevant out of Memory of zones of different with 3D model comprised.
Controller can be configured to send the search inquiry that comprises 3D model alternatively.In addition, controller can be configured to receive search query results alternatively.
In addition, method 400 can comprise one or more one or more operations, function or the actions that illustrate in square 402-408.Although square illustrates with the order of order, these squares also can executed in parallel and/or the order execution different from order described herein.Equally, the implementation based on expectation, different squares can be combined into square still less, resolves into additional square and/or be removed.In addition, for method 400 disclosed herein and other process and method, each square can representation program code module, fragment or part, described program code comprises can be carried out to realize by processor or computing equipment one or more instructions of the step in specific logical function or process.Program code can be stored on the computer-readable medium of any type, such as the memory device that for example comprises disk or hard drive.Computer-readable medium can comprise non-instantaneous computer-readable medium, such as for example short time period store data inside picture register memory, processor high speed buffer memory and random-access memory (ram) computer-readable medium.Computer-readable medium can also comprise non-instantaneous medium, such as secondary or lasting long term memory, and for example ROM (read-only memory) (ROM), CD or disk, compact disk ROM (read-only memory) (CD-ROM).
Step 402 comprises with mobile device illumination target object.Mobile device comprises polynary display and camera.Polynary display is configured to produce the modulation light field of illumination target object.With reference to Fig. 2 A, target object can be the arbitrary objects in the visual field of the image capture system 202 of mobile device 200.Step 402 can by utilize mobile device 200 user interface 216 user interactions or by pressing shutter release button 246, trigger.Alternatively, step 402 can be triggered or other mode triggers by some automatically.
Step 402 can also be shown as shown in Figure 3A.In example embodiment, there are the light field 314 illumination staplers 308 that the mobile device 302 of front-facing camera 304 can produce with polynary display 316.Stapler 308 can be called as target object.
Step 404 comprises a plurality of images that utilize camera (such as front-facing camera 304) target acquisition object.In response to user, select 3D pattern or another trigger, as shutter release button 306 or soft-key button, mobile device 302 can start to obtain the image of target object.Except other trigger, Image Acquisition can be carried out in special time table, specified time interval, ad-hoc location/orientation based on camera.
A plurality of images can utilize monocular instrumnent camera, three-dimensional camera or many visual fields camera to catch.In addition, image capture can be carried out by least one active (active) range sensor whole or in part.The polynary display of mobile device can be used light field illumination target object, and a part for the light field producing that a plurality of image can be based on from target object reflection.Polynary display can be for example visible LED or LCD display.Other embodiment can comprise the face optical display unit of any other known type.
Polynary display can provide illumination for target object, described illumination comprise have one or more particular space patterns light field, there is the light of one or more special spectrum contents and the structured light of other form and/or light modulated.Spatial light pattern can be used to recover the three-dimensional information about target object, to determine the 3D model of target object.In addition, out of Memory, as shape, outward appearance, reflectivity, absorption, material composition etc. also can by with light field illumination target object time a plurality of images of catching information recover.
Image capture can be synchronized with the one or many modulation to light field.For example, as shown in Figure 3 B, the first scene 318 can comprise the lower part 322 that upper part 320 that polynary display does not brighten and polynary display brighten.The light illumination mode of this " half-open, semi-closure " that polynary display produces can be considered to the first light field of illumination target object.The image of the part target acquisition object (being stapler 308 in this example) of the first light field that can be based on from target object reflection.
During the second scene 324 shown in Fig. 3 C, can catch one or more different images.In such scene, the upper part 326 of polynary display can brighten and the lower part 328 of polynary display can not brighten.A part for second light field of the image of catching during the second scene 324 based on from stapler 308 reflections.
Step 406 comprises the 3D model that receives or determine target object based on a plurality of images.3D model can comprise about the 3D shape of target object and color information.In addition, 3D model can comprise about the information of brightness, reflectivity and about the general illumination information of target object.Other information about target object also can be included in 3D model.When mobile device 200 just can perform step 406 during a plurality of image at target acquisition object continuously.For example, when the new images at target acquisition image just, mobile device 200 can increase some cloud and color information to 3D model.
Step 406 can be carried out to produce the mobile device of 3D model by image data processing, or by view data being offered to server and carrying out from the mobile device that server receives the combination of 3D model or these functions.
Step 408 comprises based on 3D model determines at least one in the material of the shape of target object, the outward appearance of target object and target object.In other words, the 3D model based on definite, can determine the additional information about target object.For example, utilize above-mentioned example, between the image of stapler 308 that can be based on catching when the first light field by scene 318 and 324 respectively and the second light field illumination stapler 308, relatively carry out to determine additional information.
Based on a plurality of images, can determine out of Memory.For example, can determine based on a plurality of images the texture of 3D model.In above-mentioned example, utilize the difference between the image of the light-field capture be derived from different spatial (Fig. 3 B and Fig. 3 C) can point out the particular texture of 3D model.In another example, the mirror-reflection detecting from the region of the image of catching (as, from metal staple box) can indicate the smooth grain the corresponding region of 3D model.
An example of method can comprise utilizes a plurality of images of mobile device capture space (room) and the content in space.For example, user can trigger 3D modeling pattern, and 3D modeling pattern can start catching a plurality of images.Then, user can mobile mobile device to catch image from a lot of viewing angles.In addition specific object in, can scanning space.Like this, the 3D model in space and its content can be determined.Those skilled in the art will appreciate that described method can be used in various other exemplary scene.Each of other scene is here expected.
Method can comprise optional step, such as sending search inquiry based on 3D model from mobile device at least in part.Search inquiry can only comprise 3D model.Alternatively, search inquiry can comprise other search condition.For example, user can ask the pricing information about target object.Therefore, search inquiry can comprise 3D model and the specific request to article price.Other example of specific search inquiry is possible.Once the information about the scheduled volume of target object has merged in 3D model, just can occur optional search inquiry step.For example, once determine at least coarse some cloud ' shell ' from image, just can send search inquiry.Alternatively, once the Image Acquisition of target object starts, just can periodically send search inquiry.Therefore, search inquiry can comprise the 3D model information about the part of target object.For example, the 3D pattern search of such part is inquired about can be enough to realize and is obtained useful search query results from the server system based on cloud.
Another optional step in disclosed method is included in mobile device and receives search query results.Search query results can be the response from server or any other computing equipment.Depend on situation, search query results can comprise, i) about the information of target object (as, the price of target object, position, size and model quantity etc.); Ii) about the information with the similar object of target object; And/or iii) obtain the suggestion of more images of target object.Optional method step can depend on that the frequency of the search query results of transmission carries out continuously.Therefore, can need to catch more image via user's mobile device notification user.Other feedback kind via search query results is possible.
In an example of optional method step, may need more 3D model data to other similar object in target object and shape search database is made a distinction, described shape search database is such as the shape search database of describing with reference to Figure 1A.For example,, about the image of the stapler of catching 308 in Fig. 3 A, for example, because the back of stapler may be in the visual field of front-facing camera 304, so the each several part of the 3D model of stapler 308 may be imperfect.
Can receive suggestion and from the certain view of target object, obtain the search query results of more images.As response, the user that mobile device can offer feedback mobile device, with mobile mobile device, can obtain more image like this, to fill the 3D model data lacking.For example, mobile device can receive the suggestion of more images at the back of catching stapler 308, and mobile device can catch image from new visual angle to complete 3D model data, for example as shown in Figure 3 D.Subsequently, new data can be added to 3D model, and can send one or more new search inquiries to obtain actual search query results.
Other search query results type is possible.For example, search query results can comprise the information about target object.By above-mentioned example, stapler manufacturer, stapler model and purchase location can be included in search query results.In addition about the information with the similar object of target object, can be included in search query results.For example, search query results can comprise about having the information of the stapler of similar main style with target object.
Exemplary method, as the method 400 of Fig. 4, can be carried out by mobile device fully or partly.Therefore, here can such method be described as being implemented by mobile device in the mode of example.Yet, should be appreciated that, exemplary method can be implemented by other computing equipment fully or partly.For example, exemplary method can be implemented by the server system based on cloud fully or partly, and this server system based on cloud is from the equipment receiving data such as mobile device.In other embodiments, exemplary method can be implemented fully or partly by the one or more different computing equipment such as mobile phone, flat computer and/or on knee or desktop PC.Other examples of computing equipment or the combination of computing equipment of step that can exemplifying embodiment method are also possible.
It will be understood to those of skill in the art that, there is other similar method can carry out following operation: the light field illumination target object of using the polynary display generation of mobile device, the part of the light field based on from target object reflection is caught image, and based on image, determines the 3D model of target object.These similar methods are here expected implicitly.
In certain embodiments, disclosed method may be implemented as with machine-readable form and is coded in non-instantaneous computer readable memory medium or is coded in the computer program instructions on other non-instantaneous medium or goods.Fig. 1 E is the diagrammatic view for the concept partial view of the exemplary computer program product of the computer program of object computer process on computing equipment that comprises illustrating according at least some embodiment arrangements of presenting here.
In one embodiment, utilize signal bearing medium 172 that exemplary computer program product 170 is provided.Signal bearing medium 172 can comprise one or more programmed instruction 174, and described one or more programmed instruction 174 can provide above function or partial function about Figure 1A-1D and Fig. 2-4 description when being carried out by one or more processors.In some instances, signal bearing medium 172 can comprise computer-readable medium 176, such as, but be not limited to hard drive, compact disk (CD), digital video disc (DVD), numerical tape, storer etc.In some implementations, signal bearing medium 172 can comprise computing machine recordable media 178, such as, but be not limited to storer, read/write (R/W) CD, R/W DVD etc.In some implementations, signal bearing medium 172 can comprise communication media 180, such as, but be not limited to, numeral and/or analogue communication medium (as, Connectorized fiber optic cabling, waveguide, wire communication link, wireless communication link etc.).Therefore, for example, signal bearing medium 172 can be by communication media 180 transmission of wireless.
One or more programmed instruction 174 can be, for example, and the instruction of computer executable instructions and/or logic realization.In some instances, the computing equipment such as the computing equipment 150 of Fig. 1 C can be configured to provide various operations, function or action in response to the one or more programming instructions 174 that are transferred to computing equipment 150 by computer-readable medium 176, computing machine recordable media 178 and/or communication media 180.
Non-instantaneous computer-readable medium also can be distributed among a plurality of data storage elements that can be positioned at each other remote position.The computing equipment of carrying out some or all of storage instructions can be mobile device, such as the mobile device 200 shown in Fig. 2 A.Alternatively, the computing equipment of carrying out some or all of storage instructions can be another computing equipment, such as the server 104 shown in Figure 1A.
Detailed description has above been described various features and the function of disclosed system, equipment and method.Although disclose various aspects and embodiment here, for a person skilled in the art, other side and embodiment will be obvious.Various aspects disclosed herein and embodiment be for the object of example but not be intended to restriction, real scope is indicated by claim.
Claims (25)
1. a mobile device, comprising:
Polynary display, wherein this polynary display is configured to produce light field, and wherein at least a portion of this light field reflects from target object;
Camera, the part that wherein this camera is configured to the light field based on from target object reflection is caught a plurality of images, and is configured to and the modulation at least one times of light field is synchronously caught to described a plurality of image; And
Controller, wherein this controller is configured to the 3D model based on described a plurality of image receiving target objects, wherein this 3D model comprises 3D shape and the color information about target object, and wherein this controller is also configured to determine at least one in the material of the shape of target object, the outward appearance of target object and target object based on 3D model.
2. mobile device according to claim 1, wherein, controller is also configured to:
Send search inquiry, wherein this search inquiry comprises 3D model; And
Receive search query results.
3. mobile device according to claim 1, also comprises projector, and it is configured to provide the second light field of head for target object.
4. mobile device according to claim 1, wherein polynary display comprises a plurality of light emitting diodes.
5. mobile device according to claim 1, wherein light field comprises at least one in lattice array, band array, comb mesh pattern, concentric circles, Airy disk and interference figure.
6. mobile device according to claim 1, wherein light field is configured to provide than environment light source the most of photon inciding on target object.
7. mobile device according to claim 1, wherein mobile device comprise first surface with relative with first surface second, wherein polynary display and camera are positioned on first surface.
8. mobile device according to claim 1, its middle controller is configured to modulate polynary display and makes light field show modulation at least one times, and wherein camera is configured to synchronously catch a plurality of images with the modulation at least one times of light field.
9. mobile device according to claim 1, wherein the modulation at least one times of light field comprises the color content that changes light field.
10. mobile device according to claim 9, a plurality of images that its middle controller is also configured to color content based on light field and target object are determined the material of target object.
11. mobile devices according to claim 1, wherein the modulation at least one times of light field comprises the luminous intensity that changes light field.
12. mobile devices according to claim 1, also comprise the light regulator that is coupled to polynary display, and wherein light regulator is configured to the light that regulates polynary display to produce.
13. mobile devices according to claim 12, wherein light regulator comprises one or more in grid, grating and diffraction optical element.
14. mobile devices according to claim 1, also comprise motor-driven erecting frame, wherein mobile device is configured to be attached to regularly motor-driven erecting frame, and its middle controller is configured to control motor-driven erecting frame, so that between different visual fields mobile mobile device, wherein camera is also configured to catch a plurality of images from different visual fields, and its middle controller is also configured to based on determine the 3D model of target object from a plurality of images of different visual fields.
15. mobile devices according to claim 1, a plurality of images that its middle controller is also configured to based target object are determined the texture of 3D model, and wherein the texture based on 3D model is determined the material of target object.
16. mobile devices according to claim 1, a plurality of images that its middle controller is also configured to based target object are determined the reflectivity of 3D model, and wherein the reflectivity based on 3D model is determined the material of target object.
17. 1 kinds of methods, comprising:
With mobile device illumination target object, wherein mobile device comprises polynary display and camera, and wherein polynary display is configured to produce modulation light field, wherein modulates light field illumination target object;
Utilize a plurality of images of camera target acquisition object, wherein catching of a plurality of images is configured to and the modulation at least one times of modulation light field synchronizeed; And
3D model based on a plurality of image receiving target objects, wherein 3D model comprises 3D shape and the color information about target object; And
Based on 3D model, determine at least one in the material of the shape of target object, the outward appearance of target object and target object.
18. methods according to claim 17, a plurality of images that also comprise based target object are determined the texture of 3D model, and wherein the texture based on 3D model is determined the material of target object.
19. methods according to claim 17, a plurality of images that also comprise based target object are determined the reflectivity of 3D model, and wherein the reflectivity based on 3D model is determined the material of target object.
20. methods according to claim 17, a plurality of images that also comprise based target object are determined the color of 3D model, and wherein the color based on 3D model is determined the material of target object.
21. methods according to claim 17, wherein target object comprises the content in space and space, and wherein the 3D model of receiving target object comprises the 3D model of determining space.
22. 1 kinds of non-instantaneous computer-readable mediums, it has the instruction being stored in wherein, and this instruction can be carried out by computing equipment so that computing equipment is carried out function, and described function comprises:
With calculating device illumination target object, wherein computing equipment comprises polynary display and camera, and wherein polynary display is configured to produce light field, wherein light field illumination target object;
Utilize a plurality of images of camera target acquisition object;
3D model based on described a plurality of image receiving target objects, wherein 3D model comprises 3D shape and the color information about target object; And
Based on 3D model, determine at least one in the material of the shape of target object, the outward appearance of target object and target object.
23. non-instantaneous computer-readable mediums according to claim 22, also comprise instruction, described instruction can be carried out by computing equipment so that computing equipment is carried out function, this function comprises that a plurality of images of based target object determine the texture of 3D model, and wherein the texture based on 3D model is determined the material of target object.
24. non-instantaneous computer-readable mediums according to claim 22, also comprise instruction, described instruction can be carried out by computing equipment so that computing equipment is carried out function, this function comprises that a plurality of images of based target object determine the reflectivity of 3D model, and wherein the reflectivity based on 3D model is determined the material of target object.
25. non-instantaneous computer-readable mediums according to claim 22, also comprise instruction, described instruction can be carried out by computing equipment so that computing equipment is carried out function, this function comprises that a plurality of images of based target object determine the color of 3D model, and wherein the color based on 3D model is determined the material of target object.
Applications Claiming Priority (4)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201261675525P | 2012-07-25 | 2012-07-25 | |
US61/675,525 | 2012-07-25 | ||
US13/648,393 | 2012-10-10 | ||
US13/648,393 US20140028799A1 (en) | 2012-07-25 | 2012-10-10 | Use of Color and Intensity Modulation of a Display for Three-Dimensional Object Information |
Publications (1)
Publication Number | Publication Date |
---|---|
CN103577803A true CN103577803A (en) | 2014-02-12 |
Family
ID=48856488
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201310316738.4A Pending CN103577803A (en) | 2012-07-25 | 2013-07-25 | Use of color and intensity modulation of pixel display |
Country Status (4)
Country | Link |
---|---|
US (1) | US20140028799A1 (en) |
EP (1) | EP2690397A1 (en) |
JP (1) | JP2014025935A (en) |
CN (1) | CN103577803A (en) |
Cited By (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN106125315A (en) * | 2016-06-24 | 2016-11-16 | 北京国承万通信息科技有限公司 | Display device and method |
CN106937105A (en) * | 2015-12-29 | 2017-07-07 | 宁波舜宇光电信息有限公司 | The 3D rendering method for building up of three-dimensional scanner and target object based on structure light |
CN107302693A (en) * | 2016-04-14 | 2017-10-27 | 红梓有限公司 | Three-dimensional filming system and the mobile phone with three-dimensional filming system |
CN109155073A (en) * | 2016-06-08 | 2019-01-04 | 高通股份有限公司 | Material perceives 3-D scanning |
CN109564701A (en) * | 2016-07-18 | 2019-04-02 | 巴塞尔大学 | For improving the computer system and method that gloss indicates in digital picture |
CN110383805A (en) * | 2016-12-23 | 2019-10-25 | 弗劳恩霍夫应用研究促进协会 | For capturing the method and system of the measurement image of measurand |
Families Citing this family (25)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10262458B2 (en) * | 2013-05-31 | 2019-04-16 | Longsand Limited | Three-dimensional object modeling |
CN106062827B (en) * | 2013-12-15 | 2020-09-01 | 7893159加拿大有限公司 | 3D model comparison method and system |
WO2015099211A1 (en) * | 2013-12-24 | 2015-07-02 | 엘지전자 주식회사 | 3d camera module |
KR101561628B1 (en) * | 2013-12-30 | 2015-10-20 | 주식회사 케이티 | Search apparatus for providing realtime display information of smart glass and method thereof |
US9111214B1 (en) | 2014-01-30 | 2015-08-18 | Vishal Sharma | Virtual assistant system to remotely control external services and selectively share control |
US20150262419A1 (en) * | 2014-03-13 | 2015-09-17 | Shalong Maa | Stereoscopic 3D display model and mobile device user interface systems and methods |
JPWO2016035181A1 (en) | 2014-09-03 | 2017-06-22 | 株式会社ニコン | Imaging apparatus, information processing apparatus, and imaging system |
US9547172B2 (en) | 2014-10-13 | 2017-01-17 | Ford Global Technologies, Llc | Vehicle image display |
EP3055734A4 (en) | 2014-10-28 | 2016-10-26 | Sz Dji Technology Co Ltd | Rgb-d imaging system and method using ultrasonic depth sensing |
WO2016094807A1 (en) | 2014-12-11 | 2016-06-16 | Vishal Sharma | Virtual assistant system to enable actionable messaging |
WO2016137351A1 (en) * | 2015-02-25 | 2016-09-01 | Андрей Владимирович КЛИМОВ | Method and device for the 3d registration and recognition of a human face |
WO2017058962A1 (en) | 2015-09-28 | 2017-04-06 | Wand Labs, Inc. | User assistant for unified messaging platform |
EP3356912A1 (en) | 2015-09-28 | 2018-08-08 | Microsoft Technology Licensing, LLC | Unified virtual reality platform |
EP3428877A4 (en) | 2016-03-09 | 2019-10-30 | Nikon Corporation | Detection device, information processing device, detection method, detection program, and detection system |
US10176275B1 (en) | 2016-03-28 | 2019-01-08 | Luvlyu, Inc. | Breast shape visualization and modeling tool |
US20180232448A1 (en) * | 2017-02-11 | 2018-08-16 | Chian Chiu Li | Presenting Search Results Online |
US20210019802A1 (en) * | 2017-02-11 | 2021-01-21 | Chian Chiu Li | Presenting Search And Comparison Results |
CN107968888A (en) * | 2017-11-30 | 2018-04-27 | 努比亚技术有限公司 | A kind of method for controlling mobile terminal, mobile terminal and computer-readable recording medium |
US10489961B2 (en) * | 2018-02-12 | 2019-11-26 | Wayfair Llc | Systems and methods for generating textured three-dimensional models |
CN108632597B (en) * | 2018-05-06 | 2020-01-10 | Oppo广东移动通信有限公司 | Three-dimensional video communication method and system, electronic device and readable storage medium |
CN111246197B (en) * | 2018-05-06 | 2022-03-22 | Oppo广东移动通信有限公司 | Three-dimensional video communication method and system, electronic device, server and readable storage medium |
JP2019049572A (en) * | 2018-12-26 | 2019-03-28 | 株式会社ニコン | Imaging device, information processing device, and imaging system |
WO2020203656A1 (en) * | 2019-04-05 | 2020-10-08 | ソニー株式会社 | Information processing device, information processing method, and program |
CN110032419A (en) * | 2019-04-17 | 2019-07-19 | 深圳天际云数字技术有限公司 | The methods of exhibiting and display systems of threedimensional model |
GB2583905A (en) * | 2019-04-24 | 2020-11-18 | Univ Ulster | Method and system for generating optical spectra |
Citations (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN1955719A (en) * | 2005-10-24 | 2007-05-02 | 通用电气公司 | Method and apparatus for inspecting an object |
US20080266294A1 (en) * | 2007-04-24 | 2008-10-30 | Sony Computer Entertainment Inc. | 3D Object Scanning Using Video Camera and TV Monitor |
US20090304299A1 (en) * | 2006-08-31 | 2009-12-10 | Matsushita Electric Industrial Co., Ltd | Image Processing Device, Image Processing Method and Image Processing Program |
US20120182539A1 (en) * | 2011-01-19 | 2012-07-19 | Qualcomm Incorporated | Method and apparatus for classifying proximate materials and estimating range |
Family Cites Families (13)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP2001166810A (en) * | 1999-02-19 | 2001-06-22 | Sanyo Electric Co Ltd | Device and method for providing solid model |
US6603877B1 (en) * | 1999-06-01 | 2003-08-05 | Beltronics, Inc. | Method of and apparatus for optical imaging inspection of multi-material objects and the like |
JP2001273495A (en) * | 2000-03-24 | 2001-10-05 | Minolta Co Ltd | Object recognizing device |
DE10062214B4 (en) * | 2000-12-13 | 2013-01-24 | Smiths Heimann Gmbh | Devices for transilluminating objects |
JP2003254718A (en) * | 2002-03-05 | 2003-09-10 | Mitsutoyo Corp | Lighting equipment for image-processing type measuring machine |
JP2003302211A (en) * | 2002-04-11 | 2003-10-24 | Canon Inc | Three-dimensional image processing unit and method |
KR100615576B1 (en) * | 2003-02-06 | 2006-08-25 | 주식회사 고영테크놀러지 | Three-dimensional image measuring apparatus |
JP2005352835A (en) * | 2004-06-11 | 2005-12-22 | Brother Ind Ltd | Image i/o device |
JP2006194799A (en) * | 2005-01-14 | 2006-07-27 | Canon Inc | Method of measuring shape and material |
JP5204955B2 (en) * | 2006-02-09 | 2013-06-05 | 大成建設株式会社 | Scanning method for 3D laser scanner |
JP2011033497A (en) * | 2009-08-03 | 2011-02-17 | Honda Motor Co Ltd | Environmental recognition system, environmental recognition method, and robot |
JP2011106931A (en) * | 2009-11-16 | 2011-06-02 | Roland Dg Corp | Three-dimensional shape measuring system and mobile phone |
US8363930B1 (en) * | 2012-07-23 | 2013-01-29 | Google Inc. | Use of materials and appearances to merge scanned images |
-
2012
- 2012-10-10 US US13/648,393 patent/US20140028799A1/en not_active Abandoned
-
2013
- 2013-06-21 EP EP13173171.3A patent/EP2690397A1/en not_active Withdrawn
- 2013-07-25 CN CN201310316738.4A patent/CN103577803A/en active Pending
- 2013-07-25 JP JP2013154319A patent/JP2014025935A/en active Pending
Patent Citations (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN1955719A (en) * | 2005-10-24 | 2007-05-02 | 通用电气公司 | Method and apparatus for inspecting an object |
US20090304299A1 (en) * | 2006-08-31 | 2009-12-10 | Matsushita Electric Industrial Co., Ltd | Image Processing Device, Image Processing Method and Image Processing Program |
US20080266294A1 (en) * | 2007-04-24 | 2008-10-30 | Sony Computer Entertainment Inc. | 3D Object Scanning Using Video Camera and TV Monitor |
US20120182539A1 (en) * | 2011-01-19 | 2012-07-19 | Qualcomm Incorporated | Method and apparatus for classifying proximate materials and estimating range |
Cited By (12)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN106937105A (en) * | 2015-12-29 | 2017-07-07 | 宁波舜宇光电信息有限公司 | The 3D rendering method for building up of three-dimensional scanner and target object based on structure light |
CN107302693A (en) * | 2016-04-14 | 2017-10-27 | 红梓有限公司 | Three-dimensional filming system and the mobile phone with three-dimensional filming system |
CN107302693B (en) * | 2016-04-14 | 2019-06-14 | 东莞市棒棒糖电子科技有限公司 | Three-dimensional filming system and mobile phone with three-dimensional filming system |
CN109155073A (en) * | 2016-06-08 | 2019-01-04 | 高通股份有限公司 | Material perceives 3-D scanning |
CN109155073B (en) * | 2016-06-08 | 2023-07-14 | 高通股份有限公司 | Material aware three-dimensional scanning |
CN106125315A (en) * | 2016-06-24 | 2016-11-16 | 北京国承万通信息科技有限公司 | Display device and method |
CN106125315B (en) * | 2016-06-24 | 2019-02-15 | 北京国承万通信息科技有限公司 | Display device and method |
CN109564701A (en) * | 2016-07-18 | 2019-04-02 | 巴塞尔大学 | For improving the computer system and method that gloss indicates in digital picture |
CN110383805A (en) * | 2016-12-23 | 2019-10-25 | 弗劳恩霍夫应用研究促进协会 | For capturing the method and system of the measurement image of measurand |
US10951831B2 (en) | 2016-12-23 | 2021-03-16 | Fraunhofer-Gesellschaft zur Förderung der angewandten Forschung e.V. | System and method for capturing measurement images of an object to be measured |
CN110383805B (en) * | 2016-12-23 | 2021-08-24 | 弗劳恩霍夫应用研究促进协会 | Method and system for capturing a measurement image of a measured object |
US11588979B2 (en) | 2016-12-23 | 2023-02-21 | Fraunhofer-Gesellschaft zur Förderung derr angewandten Forschung e.V. | System and method for capturing measurement images of an object to be measured |
Also Published As
Publication number | Publication date |
---|---|
EP2690397A1 (en) | 2014-01-29 |
US20140028799A1 (en) | 2014-01-30 |
JP2014025935A (en) | 2014-02-06 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN103577803A (en) | Use of color and intensity modulation of pixel display | |
US9836483B1 (en) | Using a mobile device for coarse shape matching against cloud-based 3D model database | |
CN104395902B (en) | Image according to storage determines 3D model information | |
US10102678B2 (en) | Virtual place-located anchor | |
US10152634B2 (en) | Methods and systems for contextually processing imagery | |
WO2021096931A1 (en) | Cross reality system with localization service and shared location-based content | |
CN108292043A (en) | More optical surface optical designs | |
US20230351693A1 (en) | File generation apparatus, image generation apparatus based on file, file generation method and storage medium | |
US20160343173A1 (en) | Acousto-optical display for augmented reality | |
US20190098276A1 (en) | 3-d 360 degree depth projector | |
CN103294260A (en) | Touch sensitive user interface | |
CN101236662A (en) | Apparatus and method for generating CG image for 3-D display | |
KR102492821B1 (en) | Methods and apparatus for generating a three-dimensional reconstruction of an object with reduced distortion | |
US10444509B2 (en) | Near eye diffractive holographic projection method | |
WO2022016953A1 (en) | Navigation method and apparatus, storage medium and electronic device | |
CN112433382B (en) | Speckle projection device and method, electronic equipment and distance measurement system | |
CN107330974A (en) | merchandise display method, device and mobile device | |
EP3462128B1 (en) | 3d 360-degree camera system | |
CN110189380A (en) | Optimization method, structure optical mode group and the storage medium of nominal data | |
CN107743628A (en) | The luminous structured light in LED faces | |
KR102551261B1 (en) | Method for generating depth information by using structured light pattern projected to external object and Electronic device using the same | |
KR102067599B1 (en) | Mobile terminal and method for controlling the same | |
CN115699075A (en) | Generating panoramas using a mobile camera | |
CN116366986A (en) | Method for determining received light intensity of photosensitive chip and related equipment | |
KR20200031255A (en) | System for sharing of image data or video data for interaction contents and the method thereof |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
C06 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
C02 | Deemed withdrawal of patent application after publication (patent law 2001) | ||
WD01 | Invention patent application deemed withdrawn after publication |
Application publication date: 20140212 |