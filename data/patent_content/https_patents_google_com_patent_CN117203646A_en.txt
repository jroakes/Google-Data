CN117203646A - Transfer machine learning for attribute prediction - Google Patents
Transfer machine learning for attribute prediction Download PDFInfo
- Publication number
- CN117203646A CN117203646A CN202280007489.8A CN202280007489A CN117203646A CN 117203646 A CN117203646 A CN 117203646A CN 202280007489 A CN202280007489 A CN 202280007489A CN 117203646 A CN117203646 A CN 117203646A
- Authority
- CN
- China
- Prior art keywords
- user
- digital component
- machine learning
- attributes
- learning model
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
- 238000010801 machine learning Methods 0.000 title claims abstract description 84
- 238000012546 transfer Methods 0.000 title claims abstract description 36
- 238000012549 training Methods 0.000 claims abstract description 55
- 238000000034 method Methods 0.000 claims abstract description 38
- 238000003860 storage Methods 0.000 claims abstract description 21
- 238000004590 computer program Methods 0.000 claims abstract description 16
- 230000000694 effects Effects 0.000 claims description 25
- 230000005012 migration Effects 0.000 claims description 9
- 238000013508 migration Methods 0.000 claims description 9
- 230000006870 function Effects 0.000 claims description 7
- 238000013528 artificial neural network Methods 0.000 claims description 4
- 238000009826 distribution Methods 0.000 description 21
- 238000012545 processing Methods 0.000 description 21
- 230000008569 process Effects 0.000 description 11
- 238000004891 communication Methods 0.000 description 10
- 238000013526 transfer learning Methods 0.000 description 10
- 238000013527 convolutional neural network Methods 0.000 description 9
- 230000003993 interaction Effects 0.000 description 9
- 230000009471 action Effects 0.000 description 6
- 230000006978 adaptation Effects 0.000 description 6
- 238000000605 extraction Methods 0.000 description 6
- 230000008901 benefit Effects 0.000 description 4
- 238000010586 diagram Methods 0.000 description 4
- 230000001617 migratory effect Effects 0.000 description 4
- 230000004044 response Effects 0.000 description 4
- 230000003287 optical effect Effects 0.000 description 3
- 238000013515 script Methods 0.000 description 3
- 238000013136 deep learning model Methods 0.000 description 2
- 238000000926 separation method Methods 0.000 description 2
- 239000013589 supplement Substances 0.000 description 2
- 239000002699 waste material Substances 0.000 description 2
- 241000009334 Singa Species 0.000 description 1
- 230000002776 aggregation Effects 0.000 description 1
- 238000004220 aggregation Methods 0.000 description 1
- 230000005540 biological transmission Effects 0.000 description 1
- 230000001149 cognitive effect Effects 0.000 description 1
- 235000014510 cooky Nutrition 0.000 description 1
- 238000002790 cross-validation Methods 0.000 description 1
- 239000004973 liquid crystal related substance Substances 0.000 description 1
- 238000004519 manufacturing process Methods 0.000 description 1
- 238000010295 mobile communication Methods 0.000 description 1
- 230000000644 propagated effect Effects 0.000 description 1
- 238000007637 random forest analysis Methods 0.000 description 1
- 238000009877 rendering Methods 0.000 description 1
- 239000004065 semiconductor Substances 0.000 description 1
- 230000001953 sensory effect Effects 0.000 description 1
- 230000009466 transformation Effects 0.000 description 1
- 238000010200 validation analysis Methods 0.000 description 1
- 230000000007 visual effect Effects 0.000 description 1
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N20/00—Machine learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/084—Backpropagation, e.g. using gradient descent
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/95—Retrieval from the web
- G06F16/953—Querying, e.g. by the use of web search engines
- G06F16/9536—Search customisation based on social or collaborative filtering
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/09—Supervised learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/096—Transfer learning
Abstract
Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for predicting attributes using transfer machine learning are described. In one aspect, a method includes receiving a digital component request from a client device of a user, the digital component request including at least input context information of a display environment in which a selected digital component is to be displayed. The context information is converted into input data including input feature values for a transitional machine learning model that is trained to output predictions of user attributes of the user based on the feature values representing features of the display environment. The transfer machine learning model is trained using training data obtained for a subscriber user from a data pipeline associated with electronic resources subscribed to by the subscriber user and is adapted to predict user attributes of non-subscribed users viewing the electronic resources not subscribed to by the non-subscribed users.
Description
Technical Field
The present description relates to data processing and migration machine learning.
Background
The machine learning model receives input and generates output, such as predicted output, based on the received input. Some machine learning models are parametric models and generate an output based on received inputs and values of parameters of the model.
Some machine learning models are deep learning models that employ multiple layers of the model to generate an output for a received input. For example, a deep neural network is a deep learning model that includes an output layer and one or more hidden layers, each of which applies a nonlinear transformation to a received input to generate an output.
Disclosure of Invention
The present specification describes a system implemented as a computer program on one or more computers at one or more locations that predicts attributes using a transfer machine learning technique.
In general, one innovative aspect of the subject matter described in this specification can be embodied in methods that include: receiving a digital component request from a client device of a user, the digital component request including at least input context information of a display environment in which the selected digital component is to be displayed (contextual information); converting the context information into input data comprising input feature values for a transfer machine learning model, the transfer machine learning model being trained to output predictions of user attributes of the user based on the feature values representing features of the display environment, wherein the transfer machine learning model is (i) trained using training data for a subscriber user obtained from a data pipeline associated with subscriber user subscribed (substrine) electronic resources, and (ii) adapted to predict user attributes of a non-subscribed user viewing the non-subscribed user electronic resources, wherein the training data comprises first feature values representing features of training context information of the display environment in which the digital component is displayed to the subscriber user, second feature values representing online activities of the subscriber user, and tags representing user attribute profiles of each of the subscriber user; providing input data as input to a transfer machine learning model; receiving data indicative of a set of predicted user attributes of a user as an output of a transfer machine learning model; selecting a given digital component from a plurality of digital components for display at a client device based at least in part on the set of predicted user attributes; and sending the given digital component to a client device of the user. Other embodiments of this aspect include corresponding apparatus, systems, and computer programs, encoded on computer storage devices, configured to perform aspects of the methods.
These and other implementations can each optionally include one or more of the following features. In some aspects, the electronic resources subscribed to by the subscriber user include a content platform that displays content to the subscribed user. In some aspects, training context information of a display environment in which the digital components are displayed to the subscriber user includes client device attributes of the subscriber user. The client device attributes of each individual client device include at least one of: information indicating one or more of the operating systems of the individual client devices, or the type of browser of the individual client devices.
In some aspects, for each user access to an electronic resource subscribed to by the subscriber user, training context information of a display environment in which the digital component is displayed to the subscriber user includes at least one of: information indicating an electronic resource address of the electronic resource, a category of the electronic resource, (iii) a time at which the user access occurred, a geographic location of a client device used to access the electronic resource, or a type of data service accessed by the user.
In some aspects, the second characteristic value of the online activity of the subscriber user includes a characteristic value indicative of a characteristic of a digital component with which the subscriber user interacted during the user access, including a characteristic value indicative of a category of each digital component. In some aspects, the second characteristic value of the online activity of the subscriber user comprises a characteristic value indicative of a characteristic of one or more of: select a user selectable element, provide a search query, or view a particular page.
Some aspects include generating a migration machine learning model based on the first feature value and the second feature value. Generating the transfer machine learning model may include training a neural network with an objective function.
Some aspects include providing a set of predicted user attributes of a user as input to a second machine learning model trained to predict user interfaces (engagements) with digital components based on the user attributes, and receiving, for each digital component of a plurality of digital components, output data indicative of a predicted likelihood that the user will interact with the digital component as output of the second machine learning model. Selecting the given digital component may include selecting the given digital component based at least on the predicted likelihood of each of the plurality of digital components.
The subject matter described in this specification can be implemented in specific embodiments to realize one or more of the following advantages. Third party cache files (cookies) for collecting data from client devices across the internet are increasingly being decommissioned to prevent the collection and leakage of sensitive user data. The methods described herein may predict user attributes by training a transfer machine learning model without using third party cache files. Training the transfer machine learning model may include training the machine learning model using data collected through a first data pipeline of one or more content platforms and adapting the machine learning model for use in a second data pipeline in which more limited types of data are available. In this way, the transfer machine learning model is trained using a more robust set of data to accurately predict if limited data is available. The predicted user attributes are used to efficiently distribute content to users using transfer machine learning, thereby improving the user's experience of accessing desired electronic resources. Thus, the techniques described in this document enable accurate prediction of attributes without the need for such sensitive data.
Predicting attributes using transfer machine learning instead of using data collected by third party cache files may reduce computing resources (e.g., processor cycles) and network resources (e.g., consumed bandwidth). The computation and bandwidth savings are substantial across thousands or millions of client devices aggregation.
The details of one or more embodiments of the subject matter of this specification are set forth in the accompanying drawings and the description below. Other features, aspects, and advantages of the subject matter will become apparent from the description, the drawings, and the claims.
Drawings
FIG. 1 illustrates an exemplary computing environment in which a digital component distribution system distributes digital components using transfer learning.
FIG. 2 illustrates an example system that uses transfer learning to predict user attributes of a user and provide digital components based on the predicted user attributes.
3A-3B illustrate an example machine learning architecture for training a transfer machine learning model.
FIG. 4 is a flow diagram of an example process for predicting attributes using a transfer learning model and transmitting digital components to a client device based on the predicted attributes.
FIG. 5 is a block diagram of an example computer system.
Like reference numbers and designations in the various drawings indicate like elements.
Detailed Description
Techniques and systems for predicting attributes of a user using transfer machine learning without using information from third party cached files are described herein. Historically, third party cache files have been used to gather information about the online activities of users across different domains. The information collected about the user is typically used to customize the user's browsing experience, such as by displaying personalized content. Without using information collected by third party cache files, the systems described herein predict attributes of a user by applying migration machine learning to context information of a display environment in which the user views and interacts with electronic resources.
Electronic resources include resources that some users subscribe to view the content of the electronic resource (e.g., a particular website, mobile application, or content platform such as a video sharing platform or email service). For a subscribing user to an electronic resource, the publisher of the resource may obtain and store data in a user profile that represents self-declared user attributes (e.g., self-declared geographic locations of email users) of at least a subset of the users.
The system trains a machine learning model to predict user attributes of the user based on features related to the subscribed user for whom user attribute information and additional information are available. The system may then adapt the trained machine learning model using a transfer learning technique to generate a transfer machine learning model that may predict user attributes of the user when more limited information is available, e.g., when the identity of the user is unknown and/or when less or different context information is available. For example, the system may train a machine learning model using data obtained using a data pipeline associated with such electronic resources: the electronic resource is subscribed to by the user and user attribute information and/or user online activity is available to the electronic resource. The migratory machine learning model may then be deployed in a different digital component distribution pipeline, where limited information is available for selecting digital components.
Using the described transfer learning techniques, the system can predict user attributes of a user and select digital components to provide to the user quickly, e.g., in real-time (e.g., within milliseconds), in response to receiving a digital component request based on the predicted user attributes. This may also reduce wasted network bandwidth due to the digital components being sent to undesired users. In some implementations, the system predicts user attributes of a user based on similarity between the user's activities and activities of other users from one or more electronic resources having known user attribute profiles.
As used throughout this specification, the phrase "digital component" refers to a discrete unit of digital content or digital information (e.g., a video clip, an audio clip, a multimedia clip, an image, text, or other unit of content). The digital components may be electronically stored in the physical memory device as a single file or collection of files, and the digital components may take the form of video files, audio files, multimedia files, image files, or text files, and include advertising information, so that advertisements are one type of digital component. For example, the digital component may be content that is intended to supplement the content of a web page or other resource presented by an application. More specifically, the digital components may include digital content related to the resource content (e.g., the digital components may be related to the same topic as the web page content, or related to related topics). Thus, the provision of digital components may supplement and generally enhance web pages or application content.
In addition to the description throughout this document, controls may be provided to the user (e.g., user interface elements with which the user may interact) allowing the user to make selections as to whether and when the systems, programs, or features described herein are capable of collecting user information (e.g., information about the user's social network, social actions or activities, profession, user's preferences, or the user's current location) and whether to send content or communications from the server to the user. In addition, certain data may be processed in one or more ways to remove personally identifiable information before it is stored or used. For example, the identity of the user may be processed such that personally identifiable information of the user cannot be determined, or the geographic location of the user may be generalized (e.g., to a city, zip code, or state level) where location information is obtained such that a particular location of the user cannot be determined. Thus, the user can control which information is collected about the user, how that information is used, and which information is provided to the user.
FIG. 1 illustrates an example computing environment 100 in which a digital component distribution system distributes digital components using transfer learning. The environment 100 includes a plurality of client devices 102a through 102n in communication with a digital component distribution system 104 via a network 106, which network 106 may be a wired or wireless network or any combination thereof. In some implementations, the digital component distribution system 104 is implemented using one or more computers. The network 106 may be a Local Area Network (LAN), wide Area Network (WAN), the Internet, a mobile network, or any combination thereof. Each client device 102 a-102 n (collectively client devices 102) includes a processor (e.g., central processing unit) 110 in communication with an input/output device 112 via a bus 114. Input/output devices 112 may include a touch display, keyboard, mouse, etc.
A network interface circuit 116 is also coupled to bus 114 to provide wired and/or wireless connection to network 106. A memory or other storage medium 120 is also connected to bus 114. Memory 120 stores instructions that are executed by processor 110. In particular, memory 120 stores instructions for application 122. The application 122 may be configured to communicate with the digital component distribution system 104.
In some implementations, each client device 102 is a mobile device (e.g., a smart phone, a laptop computer, a tablet computer, a wearable device, a digital assistant device, etc.). In some implementations, each client device 102 is a streaming device or a gaming device or console. The applications 122 may include one or more electronic resources, including native (e.g., email applications) applications and web browsers (e.g., social media platforms) displayed by the applications 122. The environment 100 is able to access information from the application 122 such as activities of a user using the application 122.
The client device 102 executes one or more applications 122, such as a web browser and/or native application, to facilitate sending and receiving data over the network 106. A native application is an application developed for a particular platform or a particular device (e.g., a mobile device with a particular operating system). The publisher may develop the native application and provide the native application to the client device 102, e.g., make the native application available for download. The web browser may request a resource from a web server hosting a publisher's website, for example, in response to a user of the client device 102 entering a resource address of an electronic resource (also referred to as a resource) in an address bar of the web browser or selecting a link referencing the resource address. Similarly, the native application may request application content from a remote server of the publisher.
Digital component distribution system 104 includes a processor 130, a bus 132, input/output devices 134, and network interface circuitry 136 to provide connectivity to network 106. Memory 140 is coupled to bus 132. Memory 140 stores an attribute prediction engine 142 and a digital component selection engine 144, the digital component selection engine 144 having instructions executed by processor 130 to implement the operations described in this document. In some implementations, the environment 100 includes a database 146 in communication with the digital component distribution system 104 that stores information used by the attribute prediction engine 142 and/or the digital component selection engine 144.
The attribute prediction engine 142 implements machine learning techniques, such as training and/or adapting a transfer machine learning model, applying the model to predict user attributes of a user, and retraining the model as needed (described in more detail below).
To train the transfer machine learning model, the attribute prediction engine 142 obtains and/or generates training data for the set of users. The training data may include context information of a display environment in which the digital components and/or content are displayed to the user, user activity of the user-e.g., online activity, and/or user attribute information of the user. Such context information and user activity information may not be available for training a machine learning model without using third party cache files.
To obtain such information, the attribute prediction engine 142 may interface with a data pipeline of an electronic resource that the user subscribes to view content and typically logs in to view content. In this way, the attribute prediction engine 142 may access information about subscriber users logged into the electronic resource, context information of the display environment in which the digital components are displayed to the subscribing user, and user attribute information of the subscribing user. For example, a publisher of an electronic resource may receive a request for content from a subscriber user logged into the electronic resource and provide the content along with a digital component that is displayed along with the digital component. Such a request may include context information. The publisher may store this information along with information indicating the digital components provided for display with the content and data indicating user activity about the electronic resource occurrence (e.g., whether the user interacted with the displayed digital components, e.g., selected the displayed digital components).
The user attribute information for each user may include self-declared and/or inferred user attributes. For example, a user may provide user attribute information to a content platform (or other electronic resource) using the application 122 when ordering the content platform, or provide user attribute information to update previously provided user attribute information. In another example, the content platform may infer user attributes of the user based on group survey results, online activities, and the like. The user attribute information of the user may include group characteristic information.
The context information of the display environment in which the digital components are displayed may include client device attributes of the subscribing user, for example, information indicating: an operating system of the client device 102 used by the user to view the content of the electronic resource, a type of browser or native application used to view the content at the client device 102, a display size or type of the client device 102, and/or other suitable information about the client device 102.
For each user access to an electronic resource, the context information of the display environment in which the digital component is displayed may include a resource address (e.g., a Uniform Resource Identifier (URI) or Uniform Resource Locator (URL)) of the resource, a category of the electronic resource (e.g., a topic-based category assigned to the electronic resource), a time of occurrence of the user access (e.g., time of day, day of week, month of year, etc.), a geographic location of the client device at the time of occurrence of the user access, a type of data traffic accessed by the user, and/or other suitable context information. Examples of types of data traffic include: whether the data includes an image or video, the type or category of video viewed by the user, the type or category of video channel viewed by the user, the operating system of the device transmitting the data, and the type of device used to transmit the data.
The user activity information of the subscriber user may include, for example, electronic resources that the user has subscribed to over a period of time, interactions of the user with content displayed with the electronic resources (e.g., content of the electronic resources and/or digital components displayed with the content). For example, user activity information accessed by a user to an electronic resource may include context information accessed by the user and user interaction data indicating whether the user interacted with any content and, if so, information about the interaction, such as the type of interaction and/or data indicating the content with which the interaction was performed. The information of the content (e.g., digital components) may include data identifying the content, one or more categories (e.g., one or more vertical categories) assigned to the content, weights corresponding to each category, and/or other suitable information about the content.
The attribute prediction engine 142 uses the training data to train the transfer machine learning model. The attribute prediction engine 142 may use the training data to train a machine learning model to output predicted user attributes of the user based on context information of a display environment in which the user is viewing or is about to view the content. Since the type of context information may vary based on the type of electronic resource accessed by the user and/or the data pipeline associated therewith, the attribute prediction engine 142 may adapt the machine learning model for use in different pipelines, e.g., based on the type of context information available in the different pipelines. The output of this adaptation is a transfer machine learning model.
For example, the attribute prediction engine 142 may train a machine learning model based on training data obtained using a data pipeline of a video sharing platform. The attribute prediction engine 142 may use transfer learning techniques to adapt such machine learning models for predicting user attributes of unknown users submitting search queries to a search engine or unknown users accessing particular web sites. This may include, for example, applying adaptation in the migrated domain. The adaptation phase may be similar to another machine learning model training except that the model is initialized by domain parameters (from the source domain), but has migrated domain data. In the adaptation phase, the attribute prediction engine 142 may use data from the source domain as tag data for training a transitional machine learning model using machine learning model training techniques, as described in this document. Knowledge from the source domain may be used as a true value (ground trunk) for the adaptation phase when adapting the trained machine learning model to the migration machine learning model that is adapted to the migration domain. The attribute prediction engine 142 may train a transfer learning machine learning model to output attribute predictions of input data available in the transfer domain using knowledge from the source domain (e.g., machine learning model, parameters thereof, etc.). For example, such adaptation may map features of input data available in the migration domain to features from the source domain, and adjust the model to perform attribute prediction for features of input data available in the migration domain based on knowledge of the mapped features in the source domain.
The digital component selection engine 144 uses the predicted user attributes output by the migratory machine learning model to provide digital components or personalized content to the user's client device 102. For example, based on predicted user attributes for a particular user, the digital component selection engine 144 provides digital components that may be of benefit or particular interest to the user.
Some resources, application pages, or other application content may include digital component slots for rendering digital components with the resources or application pages. The digital component slots may include code (e.g., scripts) that cause the application 122 to request digital components from the digital component distribution system 104. For example, the code may cause the application 122 to send a digital component request that includes context information for a display environment in which the user is viewing or is about to view the content. The attribute prediction engine 142 may use the context information to predict user attributes of a user of the application 122 and provide the user attributes to the digital component selection engine 144. In turn, the digital component selection engine 144 may select digital components to provide to the application 122 for display to a user, for example, where the content of the electronic resource is displayed by the application 122.
The digital component selection engine 144 may select a digital component from a set of digital components based at least on a predicted user attribute of the user. For example, the digital component may be linked to a distribution standard that indicates that the digital component is eligible for display to a user having one or more user attributes. In this example, the digital component selection engine 144 may select a digital component when the user attributes of the distribution criteria match the predicted user attributes of the user. This ensures that the selected digital component is suitable for the user and does not waste bandwidth when it is sent to the user.
The digital component selection engine 144 may select digital components based on predicted user attributes in combination with other information. For example, the digital component selection engine 144 may select a digital component based on a predicted user attribute in combination with a current time, a location of the client device 102 that sent the digital component request, context information for the digital component request, distribution criteria for the digital component, and/or a selection value indicating a credit that the digital component provider is willing to provide to the publisher for displaying the digital component.
The context information included in the digital component request may include context information similar to that described above as part of the training data. However, some of such information may not be available in the context information requested by the digital component, and/or may include different context information than the context information of the training data. For example, the context information of the digital component request may include client device attributes of the client device 102 that sent the digital component request, context information (e.g., URI or URL, category, etc.), time, location, type of service, etc. related to the electronic resource being displayed by the application 122.
In some implementations, the digital component distribution system 104 processes the information in the database 146 (e.g., by generating a quick access identifier or reference) such that access to the information is computationally efficient. For example, digital component distribution system 104 may apply a particular user's filter to database 146 to obtain records associated with a particular user. In some implementations, the digital component distribution system 104 optimizes the structure of the database 146 based on data processing bandwidth to facilitate load balancing and efficient processing of data.
FIG. 2 illustrates an example system 200 that uses transfer learning to predict user attributes of a user and provide digital components based on the predicted user attributes. The system 200 includes a device feature extraction engine 204 that receives information about the client device 102 and generates a first set 210a of features that are indicative of device attributes of a user. The first set of features includes an operating system of the client device 102, a type of service (e.g., access from a mobile phone), a browser type of the client device 102, a location, and/or a local time associated with user interaction with the client device 102.
The system 200 includes a resource feature extraction engine 206 that receives data from the application 122 and generates a second set 210b of features indicative of user activity interacting with one or more electronic resources. The second set of features may include, for the electronic resource being displayed or to be displayed to the user, a resource address of the electronic resource, a category of the electronic resource, and/or other suitable features.
As described above, the application 122 may display one or more electronic resources to a user and request digital components from the digital component distribution system 104 for display with the electronic resources. The digital component request may include contextual information of a display environment in which the selected digital component is to be displayed. The device feature extraction engine 204 and the resource feature extraction engine 206 may extract relevant information, such as relevant context information, from the digital component requests and convert the information into feature values for input to the migratory machine learning model. Although not shown in fig. 1, the digital component distribution system 104 of fig. 1 may include a device feature extraction engine 204 and a resource feature extraction engine 206.
The attribute prediction engine 142 is configured to process the first set of features 210a or/and the second set of features 210b (collectively, features 210) to generate predicted user attributes 214 for the user. Generating the predicted user attributes 214 is based on a pre-trained, migrated machine learning model. As described above, the transfer machine learning model may be trained using training data 212 that includes such data: the data may include context information of a display environment in which the digital components and/or content are displayed to the user, user activity of the user-e.g., online activity, and/or user attribute information of the user. Training data 212 includes training tags that indicate users with known (self-declared or inferred) user attribute profiles. The attribute prediction engine 142 may access training data 212 from the database 146.
The system 200 includes a digital component selection engine 144 that receives predicted user attributes 214, selects digital components based on the predicted user attributes 214, and provides digital components 216 to a user's client device. The digital component selection engine 144 communicates with the application 122, for example, via the network 106, to enable such display.
In some implementations, the digital component selection engine 144 can use a trained machine learning model to select digital components based on information indicative of user engagement with the displayed digital components. The information indicating the user's interface with the digital component may include an information indication that the user selects a user selectable item (e.g., the digital component) and views a particular page (e.g., views the recommended video) after viewing the digital component in a particular display environment characterized by the particular context information. The machine learning model may be trained based on: information related to the digital components, information related to the user's interface with the digital components (e.g., whether the user interacted with the digital components when displayed to the user), and labels indicating the user's attributes of the user to which the digital components were displayed and their corresponding interfaces with the digital components. The machine learning model may be trained to take as input predicted user attributes 214 of a user and, for each digital component in the set of digital components, output a likelihood that the user with the predicted user attributes 214 will interact with the digital component.
In some implementations, the machine learning model also considers context information of a display environment in which the selected digital component is to be displayed. For example, the machine learning model may take as input the predicted user attributes 214 and feature values of the features 210 and output, for each digital component in the set of digital components, a likelihood that a user having the predicted user attributes 214 will interact with the digital component when displayed in a display environment having context information for the display environment in which the selected digital component is to be displayed.
Fig. 3A-3B illustrate example machine learning architectures 302, 304, and 306 for training a transfer machine learning model. Referring to fig. 3A, a system (e.g., digital component distribution system 104 of fig. 1) may train one or more predictive models, each predictive model corresponding to a set of predicted user attributes. As a specific example for user attribute prediction, the system may use the first architecture 302 to train a first prediction model 301a that may be used to predict basic user attributes (e.g., gender and age distribution). The second framework 304 may be used to train the second predictive model 301b to predict extended population characteristics, e.g., occupation, footwear size, etc. To this end, each architecture 302 and 304 may use different training data to generate their respective predictive models 301a and 301b, respectively.
In another example, each architecture 302 and 304 may be trained using different training data based on available training data. For example, architecture 301a may be used to train predictive model 301a using declared user attributes provided by a user along with context information and feature values for the user's online activity. Architecture 301b may be used to train predictive model 301a using inferred user attributes inferred by another machine learning model along with context information and feature values for the user's online activity.
The system may train the predictive models 301a and 301b using the architectures 302 and 304 and the training data 212. In some implementations, the predictive models 301a and 301b are trained convolutional neural networks. The convolutional neural network includes a plurality of layers including a convolutional layer, a pooled layer, and a fully connected layer. The system may provide an objective function (also referred to as a loss function) that is used by the convolutional neural network in minimizing the loss function during training. The system may use suitable training methods other than convolutional neural networks, including supervised machine learning (e.g., random forest), regression, naive bayes classifier, and other variants of neural networks. As an output of the training predictive model, the system obtains a first predictive model 301a and a second predictive model 301b.
Referring to fig. 3B, the system may train a third (shared) predictive model 301c for predicting user attributes of the user using a third architecture 306. In this architecture 306, two convolutional neural networks 307 and 308 are trained and share a common hidden layer 305. The first convolutional neural network 307 may be trained similar to the convolutional neural network of the predictive model 301a, e.g., using the same type of training data. Similarly, the second convolutional neural network 308 may be trained similarly to the convolutional neural network of the predictive model 301b, e.g., using the same type of training data. One advantage of the third predictive model 301c is that the system may reuse some of the data and/or models of the predictive models 301a and 301 b.
In some implementations, the system can add additional features to the features 210. Additional features include previously predicted user attributes. These additional features may also enhance context prediction.
In some implementations, the system can train a meta learner that predicts user attributes based on a plurality of pre-trained models. For example, the meta learner may be an integrated (ensable) learner that spans different training architectures (e.g., predictive models 301a, 301b, and 301 c). The meta learner may be trained by a cross-validation method that segments the training data 212 into training and validation sets.
FIG. 4 is a flow diagram of an example process 400 for predicting attributes using a transfer learning model and transmitting digital components to a client device based on the predicted attributes. The process 400 will be described as being performed by a system of one or more computers suitably programmed in accordance with the present description. For example, the digital component distribution system 100 or system 200 (e.g., the attribute prediction engine 142 and the digital component selection engine 144) may perform at least a portion of the example process 400. In some embodiments, the various steps of process 400 may be performed in parallel, in combination, in a loop, or in any order.
The system receives a digital component request from a client device of a user (402). The digital component request may be a request for the digital component to be displayed with the electronic resource at the client device. The digital component request may include, for example, input context information of a display environment in which the selected digital component is to be displayed. As described above, the entered context information may include client device attributes of the subscribing user, such as information indicative of the operating system of the client device used by the user to view the content of the electronic resource, the type of browser or native application used to view the content at the client device, the display size or type of the client device, and/or other suitable information about the client device. The entered contextual characteristics may also include attributes of the electronic resource with which the selected digital component is to be displayed, such as a resource address of the electronic resource, a category of the electronic resource (e.g., a subject), and/or other suitable information about the electronic resource. The entered contextual characteristics may also include the time of day when the digital component request was generated (e.g., time of day, day of the week, month of the year, etc.), the geographic location of the client device, the type of data traffic, and/or other appropriate contextual information.
The system converts the context information into input data for a transfer machine learning model (404). For example, the system may generate feature values for features representing the context information.
As described above, the transfer machine learning model may be trained based on training data for a set of users. For example, the migratory machine learning model may be trained using training data obtained for a subscriber user from a data pipeline associated with an electronic resource subscribed to by the subscriber user. In a particular example, training data may be obtained from a data pipeline of a content platform that displays content to a user subscribed to the content platform, and the user has provided user attribute information to the content platform. The training data may include a first characteristic value representing characteristics of training context information of a display environment in which the digital component is displayed to the subscriber user, a second characteristic value of online activity of the subscriber user, and a tag representing a user attribute profile of each subscriber user. The tag of the subscribed user may indicate one or more user attributes of the subscribed user.
In some implementations, the system may retrain the predictive model, for example, by changing training architecture, training data, and/or features. The attribute prediction engine 142 may output the performance of the trained model with respect to attribute predictions. Based on analyzing whether the performance meets a particular threshold, the attribute prediction engine 142 may optimize or at least improve the training scheme.
As described above, the migration machine learning model may be adapted to predict user attributes of an unsubscribed user viewing electronic resources that are unsubscribed by the unsubscribed user.
The system provides input data as input to a transfer machine learning model (406). The system may execute a machine learning model on the input data to generate predicted user attributes for the user. The system receives data indicative of predicted attributes of the user as an output of the transfer machine learning model (408).
The system selects a digital component based on the predicted user attributes (410). The system may select a digital component from a set of digital components based on the predicted user attributes of the user and optionally based on additional information. This ensures that the selected digital component is suitable for the user and does not waste bandwidth when it is sent to the user. The additional information may include, for example, a current time, a location of the client device 102 sending the digital component request, context information of the digital component request, distribution criteria of the digital component, and/or a selection value indicating that the digital component provider is willing to provide to the publisher for displaying the amount of the digital component.
The system provides the selected digital component to a client device of the user (412). The client device may then display the digital component, for example, along with displaying the electronic resource at the client device.
FIG. 5 is a block diagram of an example computer system 500 that may be used to perform the operations described above. The system 500 includes a processor 510, a memory 520, a storage device 530, and an input/output device 540. Each of the components 510, 520, 530, and 540 may be interconnected, for example, using a system bus 550. Processor 510 is capable of processing instructions for execution within system 500. In some implementations, the processor 510 is a single-threaded processor. In another implementation, the processor 510 is a multi-threaded processor. The processor 510 is capable of processing instructions stored in the memory 520 or on the storage device 530.
Memory 520 stores information within system 500. In one implementation, the memory 520 is a computer-readable medium. In some implementations, the memory 520 is a volatile memory unit. In another implementation, the memory 520 is a non-volatile memory unit.
The storage device 530 is capable of providing mass storage for the system 500. In some implementations, the storage device 530 is a computer-readable medium. In various different implementations, storage device 530 may include, for example, a hard disk device, an optical disk device, a storage device shared by multiple computing devices over a network (e.g., a cloud storage device), or some other mass storage device.
Input/output device 540 provides input/output operations for system 400. In some implementations, the input/output device 540 may include one or more of a network interface device, such as an ethernet card, a serial communications device, such as and RS-232 port, and/or a wireless interface device, such as and 802.11 card. In another implementation, the input/output devices may include driver devices configured to receive input data and transmit output data to external devices 560 (e.g., keyboards, printers, and display devices). However, other implementations may also be used, such as mobile computing devices, mobile communication devices, set-top box television client devices, and the like.
Although an example processing system is depicted in fig. 5, implementations of the subject matter and the functional operations described in this specification can be implemented in other types of digital electronic circuitry, or in computer software, firmware, or hardware, including the structures disclosed in this specification and structural equivalents thereof, or in combinations of one or more of them.
The term "configuration" is used in this specification in connection with systems and computer program components. For a system of one or more computers to be configured to perform particular operations or actions, it is meant that the system has installed thereon software, firmware, hardware, or a combination thereof that in operation causes the system to perform the operations or actions. By one or more computer programs to be configured to perform a particular operation or action is meant that the one or more programs include instructions that, when executed by a data processing apparatus, cause the apparatus to perform the operation or action.
Embodiments of the subject matter and the functional operations described in this specification can be implemented in digital electronic circuitry, in tangibly embodied computer software or firmware, in computer hardware (including the structures disclosed in this specification and their equivalents), or in combinations of one or more of them. Embodiments of the subject matter described in this specification can be implemented as one or more computer programs, i.e., one or more modules of computer program instructions encoded on a tangible, non-transitory storage medium, to perform or control the operation of data processing apparatus. The computer storage medium may be a machine-readable storage device, a machine-readable storage medium, a random or serial access memory device, or a combination of one or more of them. Alternatively or additionally, the program instructions may be encoded on a manually generated propagated signal (e.g., a machine-generated electrical, optical, or electromagnetic signal) that is generated to encode information for transmission to suitable receiver apparatus for execution by data processing apparatus.
The term "data processing apparatus" refers to data processing hardware and includes various means, devices, and machines for processing data, including, for example, a programmable processor, a computer, or multiple processors or computers. The apparatus may also be or further comprise a dedicated logic circuit, for example an FPGA (field programmable gate array) or an ASIC (application specific integrated circuit). In addition to hardware, the apparatus may optionally include code that creates an execution environment for the computer program, e.g., code that constitutes processor firmware, a protocol stack, a database management system, an operating system, or a combination of one or more of them.
A computer program can be written in any form of programming language, including compiled or interpreted languages, declarative or procedural languages, and it can also be referred to or described as a program, software application, application program (app), module, software module, script or code; the computer program can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, or other unit suitable for use in a computing environment. A program may, but need not, correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data (e.g., one or more scripts stored in a markup language document), in a single file dedicated to the program in question, or in multiple coordinated files (e.g., files that store one or more modules, sub-programs, or portions of code). A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a data communication network.
In this specification, the term "database" is used broadly to refer to any collection of data: the data need not be structured in any particular way, or at all, and may be stored in one or more locations of the storage device. Thus, for example, an index database may include multiple data sets, each of which may be organized and accessed differently.
Similarly, in this specification, the term "engine" is used broadly to refer to a software-based system, subsystem, or process that is programmed to perform one or more particular functions. Typically, the engine will be implemented as one or more software modules or components installed on one or more computers in one or more locations. In some cases, one or more computers will be dedicated to a particular engine; in other cases, multiple engines may be installed and run on the same computer or computers.
The processes and logic flows described in this specification can be performed by one or more programmable computers executing one or more computer programs to perform functions by operating on input data and generating output. The processes and logic flows can also be performed by, or combination of, special purpose logic circuitry (e.g., an FPGA or ASIC) and one or more programmed computers.
A computer suitable for executing a computer program may be based on a general purpose or special purpose microprocessor or both, or on any other kind of central processing unit. Typically, a central processing unit will receive instructions and data from a read only memory or a random access memory or both. The essential elements of a computer are a central processing unit for executing or executing instructions and one or more memory devices for storing instructions and data. The central processing unit and the memory may be supplemented by, or incorporated in, special purpose logic circuitry. Typically, a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices (e.g., magnetic, magneto-optical disks, or optical disks) for storing data. However, a computer need not have such devices. Furthermore, a computer may be embedded in another device, such as a mobile phone, a Personal Digital Assistant (PDA), a mobile audio or video player, a game console, a Global Positioning System (GPS) receiver, or a portable storage device, such as a Universal Serial Bus (USB) flash drive, to name a few.
Computer readable media suitable for storing computer program instructions and data include all forms of non-volatile memory, media and memory devices, including by way of example semiconductor memory devices, e.g., EPROM, EEPROM, and flash memory devices; magnetic disks, e.g., internal hard disks or removable disks; magneto-optical disk; CD ROM and DVD-ROM discs.
To provide for interaction with a user, embodiments of the subject matter described in this specification can be implemented on a computer having a display device, e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor, for displaying information to the user and a keyboard and a pointing device; the keyboard and pointing device are, for example, a mouse or a trackball by which a user can provide input to a computer. Other kinds of devices may also be used to provide for interaction with a user; for example, feedback provided to the user may be any form of sensory feedback, e.g., visual feedback, auditory feedback, or tactile feedback; and can receive input from a user in any form, including acoustic, speech, or tactile input. In addition, the computer may interact with the user by sending and receiving documents to and from the device used by the user; for example, by sending a web page to a web browser on a user device in response to a request received from the web browser. Moreover, the computer may interact with the user by sending text messages or other forms of messages to a personal device (e.g., a smart phone running a messaging application) and in turn receiving response messages from the user.
The data processing apparatus for implementing the machine learning model may also include, for example, a dedicated hardware accelerator unit for processing the public and computationally intensive portions of the machine learning training or production (i.e., inference, workload).
The machine learning model can be implemented and deployed using a machine learning framework (e.g., a TensorFlow framework, microsoft Cognitive Toolkit framework, apache Singa framework, or Apache MXNet framework).
Embodiments of the subject matter described in this specification can be implemented in a computing system that includes a back-end component (e.g., as a data server), or that includes a middleware component (e.g., an application server), or that includes a front-end component (e.g., a client computer having a graphical user interface, a web browser, or an application through which a user can interact with an implementation of the subject matter described in this specification), or any combination of one or more such back-end, middleware, or front-end components. The components of the system can be interconnected by any form or medium of digital data communication (e.g., a communication network). Examples of communication networks include a Local Area Network (LAN) and a Wide Area Network (WAN), such as the internet.
The computing system may include clients and servers. The client and server are typically remote from each other and typically interact through a communication network. The relationship between client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other. In some embodiments, the server sends data, e.g., HTML pages, to the user device, e.g., for displaying data to and receiving user input from a user interacting with the device acting as a client. Data generated at the user device, e.g., results of a user interaction, may be received at the server from the device.
While this specification contains many specific implementation details, these should not be construed as limitations on the scope of any invention or of what may be claimed, but rather as descriptions of features specific to particular embodiments of particular inventions. Certain features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely, various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable subcombination. Moreover, although features may be described above as acting in certain combinations and even initially claimed as such, one or more features from a claimed combination can in some cases be excised from the combination and the claimed combination may be directed to a subcombination or variation of a subcombination.
Similarly, although operations are depicted in the drawings and described in the claims in a particular order, this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order, or that all illustrated operations be performed, to achieve desirable results. In some cases, multitasking and parallel processing may be advantageous. Moreover, the separation of various system modules and components in the embodiments described above should not be understood as requiring such separation in all embodiments, and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.
Specific embodiments of the subject matter have been described. Other embodiments are within the scope of the following claims. For example, the actions recited in the claims can be performed in a different order and still achieve desirable results. As one example, the processes depicted in the accompanying drawings do not necessarily require the particular order shown, or sequential order, to achieve desirable results. In some cases, multitasking and parallel processing may be advantageous.
Claims (12)
1. A computer-implemented method, comprising:
Receiving a digital component request from a client device of a user, the digital component request including at least input context information of a display environment in which a selected digital component is to be displayed;
converting the context information into input data comprising input feature values for a transfer machine learning model trained to output predictions of user attributes of users based on feature values representing features of a display environment, wherein the transfer machine learning model is (i) trained using training data obtained for a subscriber user from a data pipeline associated with electronic resources subscribed to by the subscriber user, and (ii) adapted to predict user attributes of non-subscribed users viewing the non-subscribed electronic resources, wherein the training data comprises first feature values representing features of training context information of a display environment in which a digital component is displayed to the subscriber user, second feature values representing online activity of the subscriber user, and labels representing user attribute profiles of each of the subscriber users;
providing the input data as input to the transfer machine learning model;
Receiving data indicative of a set of predicted user attributes for the user as an output of the migration machine learning model;
selecting a given digital component from a plurality of digital components for display at the client device based at least in part on the set of predicted user attributes; and
the given digital component is sent to the client device of the user.
2. The method of claim 1, wherein the electronic resources subscribed to by the subscriber user comprise a content platform that displays content to the subscribed user.
3. The method of claim 1 or 2, wherein the training context information in which the display environment of digital components is displayed to the subscriber user comprises client device attributes of a subscribing user, the client device attributes of each individual client device comprising at least one of: (i) Information indicating one or more of the operating systems of the individual client devices, or (ii) the type of browser of the individual client devices.
4. The method of any preceding claim, wherein, for each user access to an electronic resource subscribed to by the subscriber user, training context information of a display environment in which a digital component is displayed to the subscriber user comprises at least one of: (i) information indicating an electronic resource address of the electronic resource, (ii) a category of the electronic resource, (iii) a time at which the user access occurred, (iv) a geographic location of a client device for accessing the electronic resource, or (v) a type of data traffic accessed by the user.
5. The method of any preceding claim, wherein the second characteristic value of the subscriber user's online activity comprises: a characteristic value indicating a characteristic of a digital component with which the subscriber user interacts during the user access includes a characteristic value indicating a category of each digital component.
6. The method of any preceding claim, wherein the second characteristic value of the subscriber user's online activity comprises a characteristic value indicative of a characteristic of one or more of: (i) select a user selectable element, (ii) provide a search query or (iii) view a particular page.
7. The method of any preceding claim, further comprising: the transfer machine learning model is generated based on the first feature value and the second feature value.
8. The method of claim 7, wherein generating the transfer machine learning model comprises training a neural network with an objective function.
9. The method of any preceding claim, further comprising:
providing the set of predicted user attributes of the user as input to a second machine learning model trained to predict user engagement with a digital component based on user attributes; and
For each digital component of the plurality of digital components, receiving output data indicative of a predicted likelihood that the user will interact with that digital component as an output of the second machine learning model,
wherein selecting the given digital component comprises: the given digital component is selected based at least on a predicted likelihood of each of the plurality of digital components.
10. A system comprising one or more computers and one or more storage devices storing instructions that, when executed by the one or more computers, cause the one or more computers to perform the operations of the respective method of any preceding claim.
11. One or more computer storage media storing instructions that, when executed by one or more computers, cause the one or more computers to perform the operations of the respective method of any one of claims 1 to 9.
12. A computer program product comprising instructions which, when executed by a computer, cause the computer to perform the method according to any one of claims 1 to 9.
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
PCT/US2022/023046 WO2023191811A1 (en) | 2022-04-01 | 2022-04-01 | Transfer machine learning for attribute prediction |
Publications (1)
Publication Number | Publication Date |
---|---|
CN117203646A true CN117203646A (en) | 2023-12-08 |
Family
ID=81595643
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202280007489.8A Pending CN117203646A (en) | 2022-04-01 | 2022-04-01 | Transfer machine learning for attribute prediction |
Country Status (4)
Country | Link |
---|---|
US (1) | US20240054392A1 (en) |
EP (1) | EP4275151A1 (en) |
CN (1) | CN117203646A (en) |
WO (1) | WO2023191811A1 (en) |
Families Citing this family (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN117237559B (en) * | 2023-11-10 | 2024-02-27 | 陕西天润科技股份有限公司 | Digital twin city-oriented three-dimensional model data intelligent analysis method and system |
Family Cites Families (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11263241B2 (en) * | 2018-10-19 | 2022-03-01 | Oracle International Corporation | Systems and methods for predicting actionable tasks using contextual models |
-
2022
- 2022-04-01 EP EP22722373.2A patent/EP4275151A1/en active Pending
- 2022-04-01 WO PCT/US2022/023046 patent/WO2023191811A1/en active Application Filing
- 2022-04-01 CN CN202280007489.8A patent/CN117203646A/en active Pending
- 2022-04-01 US US18/009,178 patent/US20240054392A1/en active Pending
Also Published As
Publication number | Publication date |
---|---|
WO2023191811A1 (en) | 2023-10-05 |
EP4275151A1 (en) | 2023-11-15 |
US20240054392A1 (en) | 2024-02-15 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN113259433B (en) | Method, device and system for optimizing user interface data cache for future actions | |
US9721019B2 (en) | Systems and methods for providing personalized recommendations for electronic content | |
US10445753B1 (en) | Determining popular and trending content characteristics | |
US20200090247A1 (en) | Method and system for generating a digital content recommendation | |
US20170142214A1 (en) | Enhanced push messaging | |
RU2757546C2 (en) | Method and system for creating personalized user parameter of interest for identifying personalized target content element | |
US20190005409A1 (en) | Learning representations from disparate data sets | |
US20170046741A1 (en) | Displaying content items based on user`s level of interest in obtaining content | |
US20230306263A1 (en) | Pattern-based classification | |
CN109075987B (en) | Optimizing digital component analysis systems | |
US20240054392A1 (en) | Transfer machine learning for attribute prediction | |
US20220292144A1 (en) | Provision of different content pages based on varying user interactions with a single content item | |
US20240054391A1 (en) | Privacy-enhanced training and deployment of machine learning models using client-side and server-side data | |
US20210350202A1 (en) | Methods and systems of automatic creation of user personas | |
CN112269942B (en) | Method, device and system for recommending object and electronic equipment | |
US20240160678A1 (en) | Distributing digital components based on predicted attributes | |
JP7223164B2 (en) | Data integrity optimization | |
JP7237194B2 (en) | Privacy-preserving machine learning predictions | |
US20230259815A1 (en) | Machine learning techniques for user group based content distribution | |
US11886524B2 (en) | Limiting provision and display of redundant digital components on a client device | |
WO2023234938A1 (en) | Distributing digital components based on predicted attributes | |
CN113892085A (en) | Limiting provision and display of redundant digital components on a client device | |
EP3997624A1 (en) | Robust model performance across disparate sub-groups within a same group | |
WO2023244641A1 (en) | Training pipeline for training machine-learned user interface customization models | |
JP2022517458A (en) | Contribution Incremental Machine Learning Model |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination |