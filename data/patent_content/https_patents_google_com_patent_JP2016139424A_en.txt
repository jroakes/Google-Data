JP2016139424A - Architecture for responding to visual query - Google Patents
Architecture for responding to visual query Download PDFInfo
- Publication number
- JP2016139424A JP2016139424A JP2016050616A JP2016050616A JP2016139424A JP 2016139424 A JP2016139424 A JP 2016139424A JP 2016050616 A JP2016050616 A JP 2016050616A JP 2016050616 A JP2016050616 A JP 2016050616A JP 2016139424 A JP2016139424 A JP 2016139424A
- Authority
- JP
- Japan
- Prior art keywords
- image
- query
- search
- query image
- resources
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/50—Information retrieval; Database structures therefor; File system structures therefor of still image data
- G06F16/53—Querying
- G06F16/532—Query formulation, e.g. graphical querying
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/24—Querying
- G06F16/245—Query processing
- G06F16/2457—Query processing with adaptation to user needs
- G06F16/24578—Query processing with adaptation to user needs using ranking
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/24—Querying
- G06F16/248—Presentation of query results
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/50—Information retrieval; Database structures therefor; File system structures therefor of still image data
- G06F16/58—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually
- G06F16/583—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using metadata automatically derived from the content
- G06F16/5838—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using metadata automatically derived from the content using colour
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V40/00—Recognition of biometric, human-related or animal-related patterns in image or video data
- G06V40/10—Human or animal bodies, e.g. vehicle occupants or pedestrians; Body parts, e.g. hands
- G06V40/16—Human faces, e.g. facial parts, sketches or expressions
- G06V40/172—Classification, e.g. identification
Abstract
Description
開示する諸実施形態は、一般に、視覚クエリを処理するための複数の並列検索システムを包含するサーバシステムアーキテクチャに関する。 The disclosed embodiments generally relate to a server system architecture that includes multiple parallel search systems for processing visual queries.
ユーザが語または語句を検索エンジンに入力し、様々な結果を受け取るテキストベースの検索または用語ベースの検索は、検索を行うための有用なツールである。しかし用語ベースのクエリでは、ユーザが関連語を入力できることが必要である。ときとして、ユーザは画像に関する情報を知りたい場合がある。例えば、ユーザは写真の中の人物の名前を知りたい場合があり、または絵の中の花や鳥の名前を知りたいこともある。したがって、視覚クエリを受け取り、検索結果を提供することができるシステムが望ましい。 A text-based or term-based search where a user enters a word or phrase into a search engine and receives various results is a useful tool for performing a search. However, term-based queries require that the user can enter related terms. Sometimes the user wants to know information about the image. For example, a user may want to know the name of a person in a picture, or may want to know the names of flowers or birds in a picture. Therefore, a system that can receive visual queries and provide search results is desirable.
一部の実施形態によれば、サーバシステムにおいて視覚クエリを処理する、コンピュータによって実施される方法がある。クライアントシステムから視覚クエリを受け取る。その視覚クエリを、同時処理用の複数の並列検索システムに送ることによって処理する。その複数の検索システムのそれぞれは、複数の視覚クエリ検索処理のうちの互いに異なる視覚クエリ検索処理を実施する。その複数の視覚クエリ検索処理には、少なくとも、光学的文字認識（ＯＣＲ）、顔認識、ならびにＯＣＲおよび顔認識以外の第１の画像によるクエリ（query-by-image）処理が含まれる。複数の並列検索システムの１つまたは複数から複数の検索結果を受け取る。その複数の検索結果の少なくとも１つをクライアントシステムに送る。
一部の実施形態では、この方法は、受け取った検索結果の少なくとも２つが所定の基準を満たすとき、所定の基準を満たす受け取った検索結果をランク付けし、ランク付けした検索結果のうちの少なくとも１つの検索結果をクライアントシステムに送ることをさらに含む。
According to some embodiments, there is a computer-implemented method for processing a visual query in a server system. Receive a visual query from a client system. The visual query is processed by sending it to multiple parallel search systems for simultaneous processing. Each of the plurality of search systems performs different visual query search processes among the plurality of visual query search processes. The plurality of visual query search processes include at least optical character recognition (OCR), face recognition, and query-by-image processing using a first image other than OCR and face recognition. A plurality of search results are received from one or more of the plurality of parallel search systems. At least one of the plurality of search results is sent to the client system.
In some embodiments, the method ranks the received search results that meet the predetermined criteria when at least two of the received search results meet the predetermined criteria, and at least one of the ranked search results. Further comprising sending one search result to the client system.
一部の実施形態では、第１の画像によるクエリ処理は、製品認識、バーコード認識、オブジェクトもしくはオブジェクトカテゴリ認識、固有表現認識、または色認識である。 In some embodiments, the query processing by the first image is product recognition, barcode recognition, object or object category recognition, proper expression recognition, or color recognition.
一部の実施形態では、視覚クエリは、写真、スクリーンショット、スキャン画像、または映像フレームである。クライアントシステムは、モバイル機器、デスクトップ装置、または他の装置とすることができる。 In some embodiments, the visual query is a photo, screenshot, scanned image, or video frame. The client system can be a mobile device, a desktop device, or other device.
一部の実施形態では、視覚クエリは、検索アプリケーション、ブラウザアプリケーション用の検索エンジンプラグイン、ブラウザアプリケーション用の検索エンジン拡張機能など、クライアントシステムが実行するクライアントアプリケーションから受け取られる。一部の実施形態では、視覚クエリはクライアントシステムが実行するコンテンツオーサリングアプリケーションから受け取られる。 In some embodiments, the visual query is received from a client application that the client system executes, such as a search application, a search engine plug-in for a browser application, a search engine extension for a browser application. In some embodiments, the visual query is received from a content authoring application executed by the client system.
視覚クエリがテキスト要素および非テキスト要素を含む画像である場合、一部の実施形態では、検索結果はテキスト要素については光学的文字認識結果を含み、非テキスト要素については少なくとも１つの画像一致結果を含む。 If the visual query is an image that includes text and non-text elements, in some embodiments the search results include optical character recognition results for text elements and at least one image match result for non-text elements. Including.
一部の実施形態では、視覚クエリがテキスト要素および非テキスト要素を含む画像である場合、検索結果は、光学的文字認識処理によってもたらされる検索結果へのリンクを有する、テキスト要素についての第１の視覚的識別子と、画像一致処理によってもたらされる検索結果へのリンクを有する、非テキスト要素についての第２の視覚的識別子とを含む対話型結果ドキュメントを含む。 In some embodiments, if the visual query is an image that includes a text element and a non-text element, the search result is a first for the text element that has a link to the search result provided by the optical character recognition process. An interactive results document is included that includes a visual identifier and a second visual identifier for the non-text element that has a link to the search results provided by the image matching process.
一部の実施形態では、この方法は、複数の検索結果のうちの少なくとも２つを複合検索結果へと組み合わせることをさらに含む。 In some embodiments, the method further includes combining at least two of the plurality of search results into a composite search result.
一部の実施形態によれば、視覚クエリを処理するための検索エンジンシステムが提供される。このシステムは、プログラムを実行するための１個または複数個の中央処理装置と、その１個または複数個の中央処理装置が実行するための１つまたは複数のプログラムを記憶するメモリとを含む。その１つまたは複数のプログラムは、以下のことを実行するための命令を含む。クライアントシステムから視覚クエリを受け取る。その視覚クエリを、同時処理用の複数の並列検索システムに送ることによって処理する。その複数の検索システムのそれぞれは、複数の視覚クエリ検索処理のうちの互いに異なる視覚クエリ検索処理を実施する。その複数の視覚クエリ検索処理には、少なくとも光学的文字認識（ＯＣＲ）、顔認識、ならびにＯＣＲおよび顔認識以外の第１の画像によるクエリ処理が含まれる。複数の並列検索システムの１つまたは複数から複数の検索結果を受け取る。その複数の検索結果の少なくとも１つをクライアントシステムに送る。そのようなシステムは、上記で論じた追加のオプションを実行するためのプログラム命令を含むこともできる。 According to some embodiments, a search engine system is provided for processing visual queries. The system includes one or more central processing units for executing programs and a memory for storing one or more programs for execution by the one or more central processing units. The one or more programs include instructions for performing the following: Receive a visual query from a client system. The visual query is processed by sending it to multiple parallel search systems for simultaneous processing. Each of the plurality of search systems performs different visual query search processes among the plurality of visual query search processes. The plurality of visual query search processes include at least optical character recognition (OCR), face recognition, and query processing using a first image other than OCR and face recognition. A plurality of search results are received from one or more of the plurality of parallel search systems. At least one of the plurality of search results is sent to the client system. Such a system may also include program instructions for performing the additional options discussed above.
一部の実施形態によれば、視覚クエリを処理するためのコンピュータ可読記憶媒体システムが提供される。このコンピュータ可読記憶媒体は、コンピュータが実行するように構成される１つまたは複数のプログラムを記憶し、その１つまたは複数のプログラムは以下のことを実行するための命令を含む。クライアントシステムから視覚クエリを受け取る。その視覚クエリを、同時処理用の複数の並列検索システムに送ることによって処理する。その複数の検索システムのそれぞれは、複数の視覚クエリ検索処理のうちの互いに異なる視覚クエリ検索処理を実施する。その複数の視覚クエリ検索処理には、少なくとも光学的文字認識（ＯＣＲ）、顔認識、ならびにＯＣＲおよび顔認識以外の第１の画像によるクエリ処理が含まれる。複数の並列検索システムの１つまたは複数から複数の検索結果を受け取る。その複数の検索結果の少なくとも１つをクライアントシステムに送る。そのようなコンピュータ可読記憶媒体は、上記で論じた追加のオプションを実行するためのプログラム命令を含んでもよい。 According to some embodiments, a computer readable storage media system for processing a visual query is provided. The computer-readable storage medium stores one or more programs configured to be executed by a computer, the one or more programs including instructions for performing the following: Receive a visual query from a client system. The visual query is processed by sending it to multiple parallel search systems for simultaneous processing. Each of the plurality of search systems performs different visual query search processes among the plurality of visual query search processes. The plurality of visual query search processes include at least optical character recognition (OCR), face recognition, and query processing using a first image other than OCR and face recognition. A plurality of search results are received from one or more of the plurality of parallel search systems. At least one of the plurality of search results is sent to the client system. Such computer readable storage media may include program instructions for performing the additional options discussed above.
図面全体を通して、同様の参照番号は一致する部分を指す。 Like reference numerals refer to corresponding parts throughout the drawings.
次に、その例を添付図面に示す諸実施形態について詳しく言及する。以下の詳細な説明では、本発明の完全な理解を与えるために数多くの具体的詳細を記載する。しかし、本発明はそれらの具体的詳細なしに実施され得ることが当業者には明らかであろう。他の例では、実施形態の諸側面を無用に不明瞭にしないように、よく知られている方法、手法、コンポーネント、回路、およびネットワークについて詳しくは記載していない。 Reference will now be made in detail to the embodiments illustrated in the accompanying drawings. In the following detailed description, numerous specific details are set forth in order to provide a thorough understanding of the present invention. However, it will be apparent to those skilled in the art that the present invention may be practiced without these specific details. In other instances, well known methods, techniques, components, circuits, and networks have not been described in detail so as not to unnecessarily obscure aspects of the embodiments.
本明細書では様々な要素を説明するために第１の、第２のなどの語を使用する場合があるが、これらの要素はこれらの語によって限定されるべきではないことも理解されたい。これらの語は、単にある要素を別の要素と区別するために使用する。例えば、本発明の範囲から逸脱せずに第１の接点を第２の接点と称することができ、同様に第２の接点を第１の接点と称することもできる。第１の接点および第２の接点はいずれも接点だが、同じ接点ではない、 It should also be understood that although first, second, etc. terms may be used herein to describe various elements, these elements should not be limited by these words. These terms are only used to distinguish one element from another. For example, a first contact can be referred to as a second contact without departing from the scope of the present invention, and similarly, a second contact can be referred to as a first contact. The first contact and the second contact are both contacts, but not the same contact.
本明細書の本発明の説明の中で使用する用語は、特定の実施形態を説明するためのものに過ぎず、本発明を限定するように意図されていない。本発明の説明および特許請求の範囲の中で使用するとき、単数形「ａ」、「an」および「the」は、特に明確な指示がない限り複数形も含むことを意図する。本明細書で使用するとき、用語「および／または」は、列挙する関連項目の１つまたは複数の任意のおよびあり得るすべての組合せを指し、包含することも理解されたい。さらに本明細書で使用するとき、用語「備える(comprises)」および／または「備えている(comprising)」は、述べた特徴、完全体、ステップ、動作、要素、および／またはコンポーネントが存在することを規定するが、１つもしくは複数の他の特徴、完全体、ステップ、動作、要素、コンポーネント、および／またはそれらのグループが存在すること、もしくは追加されることを除外しないことも理解されたい。 The terminology used in the description of the invention herein is for the purpose of describing particular embodiments only and is not intended to be limiting of the invention. As used in the description and claims of this invention, the singular forms “a”, “an” and “the” are intended to include the plural forms as well, unless expressly specified otherwise. It should also be understood that as used herein, the term “and / or” refers to and includes any and all possible combinations of one or more of the associated listed items. Further, as used herein, the terms “comprises” and / or “comprising” shall mean that the stated feature, completeness, step, action, element, and / or component exists. It should also be understood that one or more other features, completeness, steps, operations, elements, components, and / or groups thereof do not preclude the presence or addition.
本明細書で使用するとき、用語「もし(if)」は、文脈に応じて「場合(when)」もしくは「とき(upon)」、または「決定することに応答して(in response to determining)」もしくは「検出することに応答して(in response to detecting)」を意味するものと解釈されてもよい。同様に、語句「決定する場合(if it is determined)」または「検出する場合(if it is detected)」は、文脈に応じて「決定するとき(upon determining)」もしくは「決定することに応答して(in response to determining)」、または「（述べた条件または事象を）検出するとき(upon detecting)」もしくは「（述べた条件または事象を）検出することに応答して(in response to detecting)」を意味するものと解釈されてもよい。 As used herein, the term `` if '' is `` when '' or `` upon '' or `` in response to determining '' depending on the context. Or “in response to detecting”. Similarly, the phrase “if it is determined” or “if it is detected” is responsive to “upon determining” or “determining” depending on the context. "In response to determining", or "in response to detecting" or "in response to detecting" or "in response to detecting" May be interpreted to mean.
図１は、一部の実施形態による視覚クエリサーバシステムを含むコンピュータネットワークを示すブロック図である。コンピュータネットワーク１００は、１つまたは複数のクライアントシステム１０２および視覚クエリサーバシステム１０６を含む。これらのコンポーネントを１つまたは複数の通信ネットワーク１０４が相互接続する。通信ネットワーク１０４は、ローカルエリアネットワーク（ＬＡＮ）、広域ネットワーク（ＷＡＮ）、無線ネットワーク、有線ネットワーク、インターネット、またはそうしたネットワークの組合せを含む、様々なネットワークのうちの任意のものとしてもよい。
FIG. 1 is a block diagram illustrating a computer network including a visual query server system according to some embodiments. The
クライアントシステム１０２は、視覚クエリ（例えば図１１の視覚クエリ１１０２）を受け取るためにクライアントシステムが実行するクライアントアプリケーション１０８を含む。視覚クエリとは、検索エンジンまたは検索システムにクエリとしてサブミットされる画像である。視覚クエリの非限定的な例には、写真、スキャンドキュメントおよびスキャン画像、ならびに絵図が含まれる。一部の実施形態では、クライアントアプリケーション１０８は、検索アプリケーション、ブラウザアプリケーション用の検索エンジンプラグイン、およびブラウザアプリケーション用の検索エンジン拡張機能からなる組から選択される。一部の実施形態では、クライアントアプリケーション１０８は、視覚クエリとして使用する任意形式の画像をユーザが検索ボックスの中にドラッグアンドドロップすることを可能にする「手当たり次第の(omnivorous)」検索ボックスである。
クライアントシステム１０２は、視覚クエリサーバシステム１０６にクエリを送り、視覚クエリサーバシステム１０６からデータを受け取る。クライアントシステム１０２は、視覚クエリサーバシステム１０６と通信することができる任意のコンピュータまたは他の装置としてもよい。非限定的な例には、デスクトップコンピュータおよびノートブックコンピュータ、メインフレームコンピュータ、サーバコンピュータ、携帯電話や携帯情報端末などのモバイル機器、ネットワーク端末、およびセットトップボックスが含まれる。
The
視覚クエリサーバシステム１０６は、フロントエンド視覚クエリ処理サーバ１１０を含む。フロントエンドサーバ１１０はクライアント１０２から視覚クエリを受け取り、その視覚クエリを同時処理用の複数の並列検索システム１１２に送る。検索システム１１２は互いに異なる視覚クエリ検索処理をそれぞれ実施し、自らの別個の検索処理により視覚クエリを処理するために、必要に応じて自らの対応するデータベース１１４にアクセスする。例えば顔認識検索システム１１２−Ａは、画像クエリに対する顔の一致を探すために顔画像データベース１１４−Ａにアクセスする。図９に関してより詳細に説明するように、視覚クエリが顔を含む場合、顔認識検索システム１１２−Ａは顔画像データベース１１４−Ａから１つまたは複数の検索結果（例えば名前、一致する顔等）を返す。別の例では、光学的文字認識（ＯＣＲ）検索システム１１２−Ｂが、視覚クエリ内の任意の認識可能テキストを、１つまたは複数の検索結果として返すためのテキストへと変換する。光学的文字認識（ＯＣＲ）検索システム１１２−Ｂでは、図８に関してより詳細に説明するように、特定のフォントまたはテキストパターンを認識するためにＯＣＲデータベース１１４−Ｂにアクセスすることができる。
The visual query server system 106 includes a front end visual
任意の数の並列検索システム１１２を使用してもよい。一部の例には、顔認識検索システム１１２−Ａ、ＯＣＲ検索システム１１２−Ｂ、（オブジェクトまたはオブジェクトカテゴリを認識し得る）画像−用語検索システム１１２−Ｃ、（本の表紙やＣＤなどの２Ｄ画像を認識するように構成してもよく、家具などの３Ｄ画像を認識するように構成してもよい）製品認識検索システム、（１Ｄおよび２Ｄ形式のバーコードを認識する）バーコード認識検索システム、固有表現認識検索システム、（エッフェル塔のような特定の有名な名所を認識するように構成することができ、ビルボードなど、特定の画像のコーパスを認識するように構成してもよい）ランドマーク認識、クライアントシステム１０２内のＧＰＳ受信機または携帯電話網が提供する地理位置情報によって支援される場所認識、色認識検索システム、および（視覚クエリに似た画像を検索して特定する）類似画像検索システムが含まれる。図１のシステム１１２−Ｎによって示す、さらなる検索システムを追加の並列検索システムとして加えることができる。ＯＣＲ検索システムを除くすべての検索システムを、画像一致処理を実行する検索システムとして本明細書では集合的に定義する。ＯＣＲ検索システムを含むすべての検索システムを、画像によるクエリ検索システムと集合的に呼ぶ。一部の実施形態では、視覚クエリサーバシステム１０６が、顔認識検索システム１１２−Ａ、ＯＣＲ検索システム１１２−Ｂ、および少なくとも１つの他の画像によるクエリ検索システム１１２を含む。
Any number of
並列検索システム１１２は視覚検索クエリを個々に処理し、自らの結果をフロントエンドサーバシステム１１０に返す。一部の実施形態では、フロントエンドサーバ１００は、結果を複合ドキュメントへと集約すること、表示するための結果の一部を選択すること、および結果をランク付けすることのうちの１つまたは複数など、図６に関してより詳細に説明するように検索結果に対して１つまたは複数の解析を行ってもよい。フロントエンドサーバ１１０は、検索結果をクライアントシステム１０２に伝える。
The
クライアントシステム１０２は、１つまたは複数の検索結果をユーザに提供し得る。それらの結果はディスプレイ上に、音声スピーカにより、またはユーザに情報を伝えるために使用する他の任意の手段によって提供することができる。ユーザは、様々な方法で検索結果と対話してもよい。一部の実施形態では、ユーザの選択、注釈、および検索結果との他の対話を視覚クエリサーバシステム１０６に伝送し、視覚クエリとともにクエリ／注釈データベース１１６内に記録する。クエリ／注釈データベース内の情報は、視覚クエリの結果を改善するために使用することができる。一部の実施形態では、クエリ／注釈データベース１１６からの情報を並列検索システム１１２に周期的にプッシュし、並列検索システム１１２はその情報の任意の関連部分を個々のデータベース１１４内に取り入れる。
コンピュータネットワーク１００は、用語クエリに応答して検索を行うための用語クエリサーバシステム１１８を場合により含んでもよい。用語クエリとは、画像を含む視覚クエリとは対照的に、１つまたは複数の用語を含むクエリである。用語クエリサーバシステム１１８は、視覚クエリサーバシステム１０６内の様々な検索エンジンによってもたらされる情報を補足する検索結果を生成するために使用してもよい。用語クエリサーバシステム１１８から返される結果は、任意の形式を含み得る。用語クエリサーバシステム１１８は、テキストドキュメント、画像、映像等を含み得る。図１では用語クエリサーバシステム１１８を別個のシステムとして図示するが、場合により視覚クエリサーバシステム１０６が用語クエリサーバシステム１１８を含んでもよい。
The
視覚クエリサーバシステム１０６の動作に関するさらなる情報は、図２〜４のフローチャートに関して以下に示す。 Further information regarding the operation of the visual query server system 106 is provided below with respect to the flowcharts of FIGS.
図２は、本発明の特定の実施形態による、視覚クエリに応答するための視覚クエリサーバシステムの方法を示すフローチャートである。図２に示す操作のそれぞれは、コンピュータメモリまたはコンピュータ可読記憶媒体の中に記憶される命令に対応し得る。 FIG. 2 is a flowchart illustrating a method of a visual query server system for responding to a visual query, according to a particular embodiment of the present invention. Each of the operations shown in FIG. 2 may correspond to instructions stored in a computer memory or computer readable storage medium.
視覚クエリサーバシステムが、クライアントシステムから視覚クエリを受け取る（２０２）。図１に関して説明したように、このクライアントシステムは、例えばデスクトップコンピューティング装置、モバイル機器、または別の同様の装置としてもよい（２０４）。図１１に、クライアントシステムの一例上の視覚クエリの一例を示す。 A visual query server system receives a visual query from a client system (202). As described with respect to FIG. 1, the client system may be, for example, a desktop computing device, a mobile device, or another similar device (204). FIG. 11 shows an example of a visual query on an example of a client system.
視覚クエリは、任意の適切な形式の画像ドキュメントである。例えば視覚クエリは、写真、スクリーンショット、スキャン画像、または映像の複数のフレームのうちの１フレームもしくはシーケンスとすることができる（２０６）。一部の実施形態では、視覚クエリはコンテンツオーサリングプログラム（図５、７３６）が作成する絵図である。そのため、一部の実施形態ではユーザが視覚クエリを「描く」のに対し、他の実施形態ではユーザが視覚クエリをスキャンしまたは撮影する。一部の視覚クエリは、Acrobat、写真編集プログラム、描画プログラム、画像編集プログラムなどの画像生成アプリケーションを使用して作成される。例えば視覚クエリは、ユーザが自身の携帯電話上で友人の写真を撮り、その写真を視覚クエリとしてサーバシステムにサブミットすることから生じることができる。視覚クエリは、ユーザが雑誌のページをスキャンし、またはデスクトップコンピュータ上でウェブページのスクリーンショットをとり、そのスキャンまたはスクリーンショットを視覚クエリとしてサーバシステムにサブミットすることから生じることもできる。一部の実施形態では、視覚クエリはブラウザアプリケーションの検索エンジン拡張機能により、ブラウザアプリケーション用のプラグインにより、またはクライアントシステム１０２が実行する検索アプリケーションによりサーバシステム１０６にサブミットされる。視覚クエリは、クライアントシステムが遠隔設置されたサーバに伝送可能な画像をサポートするか、または生成する、（クライアントシステムが実行する）他のアプリケーションプログラムによってサブミットしてもよい。
A visual query is any suitable type of image document. For example, the visual query may be a frame or sequence of a plurality of frames of a photo, screen shot, scanned image, or video (206). In some embodiments, the visual query is a pictorial diagram created by the content authoring program (FIG. 5, 736). As such, in some embodiments the user “draws” the visual query, while in other embodiments the user scans or captures the visual query. Some visual queries are created using image generation applications such as Acrobat, photo editing programs, drawing programs, and image editing programs. For example, a visual query can result from a user taking a picture of a friend on his cell phone and submitting the picture as a visual query to a server system. A visual query can also result from a user scanning a magazine page or taking a screen shot of a web page on a desktop computer and submitting the scan or screen shot to the server system as a visual query. In some embodiments, the visual query is submitted to the server system 106 by a search engine extension of the browser application, by a plug-in for the browser application, or by a search application executed by the
視覚クエリは、テキスト要素と非テキスト要素との組合せとすることができる（２０８）。例えばクエリは、道路標識の隣に立っている人物など、画像およびテキストを含む雑誌ページのスキャンとすることができる。視覚クエリは、クライアントシステム内に埋め込まれるカメラによって撮影されたか、またはクライアントシステムによって、スキャンもしくは他の方法で受け取られたドキュメントからの人物の顔の画像を含むことができる。視覚クエリは、テキストだけを含むドキュメントのスキャンとすることもできる。視覚クエリは、森の中にいる数羽の鳥、人物とオブジェクト（例えば車、公園のベンチ等）、人物と動物（例えばペット、家畜、蝶等）など、数多くの別個のサブジェクトの画像とすることもできる。視覚クエリは、２つ以上の別個の要素を有してもよい。例えば視覚クエリは、バーコードと、製品の画像または製品パッケージ上の製品名とを含むことができる。例えば視覚クエリは、本のタイトル、表紙絵、およびバーコードを含む本の表紙の写真とすることができる。以下により詳細に論じるように、一部の例では１つの視覚クエリが、その視覚クエリの様々な部分に対応する２つ以上の別個の検索結果をもたらす。 The visual query may be a combination of text and non-text elements (208). For example, the query can be a scan of a magazine page containing images and text, such as a person standing next to a road sign. The visual query may include an image of a person's face from a document taken by a camera embedded within the client system, or scanned or otherwise received by the client system. A visual query can also be a scan of a document that contains only text. A visual query is an image of a number of separate subjects, such as several birds in the forest, people and objects (eg cars, park benches, etc.), people and animals (eg pets, farm animals, butterflies, etc.) You can also A visual query may have two or more distinct elements. For example, a visual query can include a barcode and a product image or product name on a product package. For example, the visual query may be a book cover photo including a book title, a cover picture, and a barcode. As will be discussed in more detail below, in some examples a visual query results in two or more separate search results corresponding to various portions of the visual query.
サーバシステムは、以下のように視覚クエリを処理する。フロントエンドサーバシステムが、同時処理用の複数の並列検索システムに視覚クエリを送る（２１０）。各検索システムは互いに異なる視覚クエリ検索処理を実施し、すなわち個々の検索システムは独自の処理スキームにより視覚クエリを処理する。 The server system processes the visual query as follows. The front-end server system sends a visual query to multiple parallel search systems for simultaneous processing (210). Each search system performs a different visual query search process, i.e., each search system processes a visual query with its own processing scheme.
一部の実施形態では、処理するために視覚クエリが送られる検索システムの１つが光学的文字認識（ＯＣＲ）検索システムである。一部の実施形態では、処理するために視覚クエリが送られる検索システムの１つが顔認識検索システムである。一部の実施形態では、互いに異なる視覚クエリ検索処理を実行する複数の検索システムは、少なくとも光学的文字認識（ＯＣＲ）、顔認識、ならびにＯＣＲおよび顔認識以外の別の画像によるクエリ処理を含む（２１２）。他の画像によるクエリ処理は、これだけに限定されないが、製品認識、バーコード認識、オブジェクトまたはオブジェクトカテゴリ認識、固有表現認識、および色認識が含まれる１組の処理から選択される（２１２）。 In some embodiments, one of the search systems to which visual queries are sent for processing is an optical character recognition (OCR) search system. In some embodiments, one of the search systems to which visual queries are sent for processing is a face recognition search system. In some embodiments, multiple search systems that perform different visual query search processes include at least optical character recognition (OCR), face recognition, and query processing with another image other than OCR and face recognition ( 212). Other image query processing is selected (212) from a set of processes including, but not limited to, product recognition, barcode recognition, object or object category recognition, named entity recognition, and color recognition.
一部の実施形態では、ＯＣＲ検索システムの後処理として固有表現認識が行われ、有名な人物、位置、オブジェクトなどがあるかどうかＯＣＲのテキスト結果を解析し、固有表現であると特定した用語を用語クエリサーバシステム（図１、１１８）内で検索する。他の実施形態では、画像−用語検索システムが、有名な名所、ロゴ、人物、アルバムカバー、商標等の画像を認識する。他の実施形態では、画像−用語検索システムとは別に、独特の固有表現の画像によるクエリ処理を利用する。オブジェクトまたはオブジェクトカテゴリ認識システムは、「車」のような総称的な結果の種類を認識する。一部の実施形態では、このシステムは製品ブランド、特定の製品モデルなども認識し、「ポルシェ」のようなより具体的な説明を提供する。検索システムの一部は、特別なユーザに固有の検索システムとすることができる。例えば、色認識および顔認識の特定のバージョンを、目の不自由な人が使用する専用の検索システムとすることができる。 In some embodiments, proper expression recognition is performed as a post-processing of the OCR search system, and the OCR text result is analyzed for the presence of a famous person, position, object, etc. Search within the term query server system (FIG. 1, 118). In other embodiments, the image-term search system recognizes images such as famous landmarks, logos, people, album covers, trademarks, and the like. Another embodiment utilizes query processing with unique named images separately from the image-term search system. The object or object category recognition system recognizes generic result types such as “car”. In some embodiments, the system also recognizes product brands, specific product models, etc. and provides a more specific description such as “Porsche”. Part of the search system may be a search system that is specific to a particular user. For example, specific versions of color recognition and face recognition can be dedicated search systems used by people who are blind.
フロントエンドサーバシステムが、並列検索システムから結果を受け取る（２１４）。一部の実施形態では、それらの結果に検索スコアが付随する。一部の視覚クエリでは、検索システムの一部は関連する結果を見出さない。例えば視覚クエリが花の写真であった場合、顔認識検索システムおよびバーコード検索システムは関連する結果を一切見出さない。一部の実施形態では、関連する結果が見出されない場合、ヌルまたはゼロの検索スコアをその検索システムから受け取る（２１６）。一部の実施形態では、あらかじめ定めた期間（例えば０．２秒、０．５秒、１秒、２秒、または５秒）を過ぎてもフロントエンドサーバが検索システムから結果を受け取らない場合、フロントエンドサーバは、あたかもそのタイムアウトしたサーバがヌルの検索スコアを生成したかのように受け取られる結果を処理し、他の検索システムから受け取る結果を処理する。 The front end server system receives the results from the parallel search system (214). In some embodiments, those results are accompanied by a search score. For some visual queries, parts of the search system do not find relevant results. For example, if the visual query is a flower photo, the face recognition search system and barcode search system will find no relevant results. In some embodiments, if no relevant result is found, a null or zero search score is received from the search system (216). In some embodiments, if the front-end server does not receive results from the search system after a predetermined period of time (eg, 0.2 seconds, 0.5 seconds, 1 second, 2 seconds, or 5 seconds) The front-end server processes the results received as if the timed-out server generated a null search score and processes results received from other search systems.
場合により、受け取った検索結果の少なくとも２つが所定の基準を満たすとき、それらの検索結果をランク付けする（２１８）。一部の実施形態では、所定の基準の１つが無効な結果を除去する。所定の基準は、結果が無効ではないことである。一部の実施形態では、所定の基準の１つが、所定の最小スコアを下回る（例えば適合率に関する）数値スコアを有する結果を除去する。場合により、複数の検索結果をフィルタする（２２０）。一部の実施形態では、結果の総数が定義済み閾値を上回る場合にのみ結果をフィルタする。一部の実施形態ではすべての結果をランク付けするが、所定の最小スコアを下回る結果は除外する。一部の視覚クエリでは、結果のコンテンツをフィルタする。例えば、結果の一部が個人情報または個人が保護する情報を含む場合、それらの結果をフィルタにかけて除去する。 Optionally, if at least two of the received search results meet a predetermined criterion, the search results are ranked (218). In some embodiments, one of the predetermined criteria removes invalid results. The predetermined criterion is that the result is not invalid. In some embodiments, one of the predetermined criteria removes results that have a numerical score that is below a predetermined minimum score (eg, with respect to precision). Optionally, a plurality of search results are filtered (220). In some embodiments, the results are filtered only if the total number of results exceeds a predefined threshold. Some embodiments rank all results, but exclude results below a predetermined minimum score. Some visual queries filter the resulting content. For example, if some of the results contain personal information or information protected by an individual, those results are filtered out.
場合により、視覚クエリサーバシステムは複合検索結果を作成する（２２２）。複合検索結果を作成することの一実施形態は、図３に関して説明するように、対話型結果ドキュメント内に複数の検索システムの結果を埋め込む場合である。用語クエリサーバシステム（図１、１１８）は、用語検索の結果を用いて並列検索システムのうちの１つからの結果を増補してもよく、その追加の結果はドキュメントもしくは情報源へのリンク、または視覚クエリに関連し得る追加情報を含むテキストおよび／もしくは画像である。したがって、例えば複合検索結果は、ＯＣＲの結果とＯＣＲドキュメント内の固有表現へのリンクとを含んでもよい（２２４）。 In some cases, the visual query server system creates a combined search result (222). One embodiment of creating composite search results is when embedding multiple search system results within an interactive results document, as described with respect to FIG. The term query server system (FIG. 1, 118) may use the term search results to augment the results from one of the parallel search systems, the additional results being a link to a document or information source, Or text and / or images containing additional information that may be relevant to the visual query. Thus, for example, a composite search result may include an OCR result and a link to a unique representation in the OCR document (224).
一部の実施形態では、ＯＣＲ検索システム（図１、１１２−Ｂ）またはフロントエンド視覚クエリ処理サーバ（図１、１１０）が、テキスト内の関連しそうな語を認識する。例えば、有名な人物や場所などの固有表現を認識し得る。固有表現は、クエリ用語として用語クエリサーバシステム（図１、１１８）にサブミットされる。一部の実施形態では、用語クエリサーバシステムがもたらす用語クエリの結果を、視覚クエリの結果の中に「リンク」として埋め込む。一部の実施形態では、用語クエリの結果が別個のリンクとして返される。例えば本の表紙の写真が視覚クエリである場合、その本についてオブジェクト認識検索システムが高スコアのヒットをもたらす可能性が高い。そのため、その本のタイトルを得るための用語クエリが用語クエリサーバシステム１１８上で実行され、視覚クエリの結果とともに用語クエリの結果が返される。一部の実施形態では、用語クエリの結果をラベル付けしたグループ内に提示して、それらを視覚クエリの結果と区別する。結果は個々に検索してもよく、または特に関連のある追加の検索結果をもたらすために、検索クエリ内で認識されるすべての固有表現を使用して検索を行ってもよい。例えば、視覚クエリがパリに関するスキャンされた旅行パンフレットである場合、返される結果は、用語クエリ「ノートルダム」についての検索を開始するための、用語クエリサーバシステム１１８へのリンクを含むことができる。同様に、複合検索結果は、一般に認められた有名な画像に関するテキスト検索の結果を含む。例えば同じ旅行パンフレットにおいて、「エッフェル塔」や「ルーブル」のようにパンフレット内に写真として示されている有名な目的地についての用語クエリの結果へのライブリンクも（たとえ用語「エッフェル塔」および「ルーブル」がパンフレット自体に登場しなくても）示してもよい。 In some embodiments, the OCR search system (FIG. 1, 112-B) or front-end visual query processing server (FIG. 1, 110) recognizes likely words in the text. For example, a unique expression such as a famous person or place can be recognized. The named expressions are submitted to the term query server system (FIG. 1, 118) as query terms. In some embodiments, the term query results provided by the term query server system are embedded as “links” in the results of the visual query. In some embodiments, the term query results are returned as a separate link. For example, if a photo of a book cover is a visual query, the object recognition search system is likely to yield a high score hit for that book. Thus, a term query to obtain the title of the book is executed on the term query server system 118 and the result of the term query is returned along with the result of the visual query. In some embodiments, term query results are presented in a labeled group to distinguish them from visual query results. The results may be searched individually, or the search may be performed using all unique expressions recognized in the search query to yield additional search results that are particularly relevant. For example, if the visual query is a scanned travel brochure for Paris, the returned results may include a link to the term query server system 118 to initiate a search for the term query “Notre Dame”. Similarly, the combined search results include the results of text searches on commonly accepted famous images. For example, in the same travel brochure, live links to the results of term queries for famous destinations that are shown as photos in the brochure, such as “Eiffel Tower” and “Louvre” (even if the terms “Eiffel Tower” and “ "Ruble" may be indicated (even if it does not appear in the brochure itself).
次いで、視覚クエリサーバシステムが少なくとも１つの結果をクライアントシステムに送る（２２６）。典型的には、視覚クエリ処理サーバが複数の検索システムの少なくとも一部から複数の検索結果を受け取る場合、視覚クエリ処理サーバは、その複数の検索結果のうちの少なくとも１つをクライアントシステムに送る。一部の視覚クエリでは、１つの検索システムだけが関連する結果を返す。例えば、テキストの画像だけを含む視覚クエリでは、ＯＣＲサーバの結果だけが関連する場合がある。一部の視覚クエリでは、１つの検索システムからの１つの結果だけが関連する場合がある。例えば、スキャンしたバーコードに関係する製品だけが関連する場合がある。これらの例では、フロントエンド視覚処理サーバは、関連する１つまたは複数の検索結果だけを返す。一部の視覚クエリでは、複数の検索結果がクライアントシステムに送られ、その複数の検索結果は並列検索システムのうちの複数からの検索結果を含む（２２８）。これは、視覚クエリの中に複数の別個の画像がある場合に起こり得る。例えば、視覚クエリが馬に乗っている人物の写真であった場合、馬に関するオブジェクト認知結果とともに、その人物の顔認識の結果を表示することができる。一部の実施形態では、特定の画像によるクエリ検索システムのすべての結果をグループ化し、まとめて提供する。例えば、上位Ｎ個の顔認識結果を見出し「顔認識結果」の下に表示し、上位Ｎ個のオブジェクト認識結果を見出し「オブジェクト認識結果」の下にまとめて表示する。あるいは、以下に論じるように、特定の画像検索システムからの検索結果を画像領域によってグループ化することができる。例えば視覚クエリが２つの顔を含む場合、その両方が顔認識結果をもたらし、それぞれの顔についての結果が別個のグループとして提示される。一部の視覚クエリ（例えばテキストおよび１つまたは複数のオブジェクトの両方の画像を含む視覚クエリ）では、検索結果はＯＣＲの結果と１つまたは複数の画像一致の結果とを含み得る（２３０）。 The visual query server system then sends at least one result to the client system (226). Typically, when the visual query processing server receives a plurality of search results from at least some of the plurality of search systems, the visual query processing server sends at least one of the plurality of search results to the client system. For some visual queries, only one search system returns relevant results. For example, in a visual query that includes only images of text, only OCR server results may be relevant. For some visual queries, only one result from one search system may be relevant. For example, only products related to scanned barcodes may be relevant. In these examples, the front end visual processing server returns only one or more relevant search results. In some visual queries, multiple search results are sent to the client system, and the multiple search results include search results from multiple of the parallel search systems (228). This can happen when there are multiple separate images in a visual query. For example, if the visual query is a photograph of a person riding on a horse, the result of the person's face recognition can be displayed along with the object recognition result regarding the horse. In some embodiments, all the results of a query search system with a particular image are grouped and provided together. For example, the top N face recognition results are displayed under the heading “Face recognition results”, and the top N object recognition results are displayed together under the heading “Object recognition results”. Alternatively, search results from a particular image search system can be grouped by image region, as discussed below. For example, if the visual query includes two faces, both result in face recognition results and the results for each face are presented as a separate group. For some visual queries (eg, visual queries that include images of both text and one or more objects), the search results may include an OCR result and one or more image match results (230).
一部の実施形態では、ユーザが特定の検索結果についてもっと詳しく知りたい場合がある。例えば、視覚クエリがイルカの写真であり、「画像−用語」検索システムが用語「水」、「イルカ」、「青」、および「ひれ足」を返す場合、ユーザは「ひれ足」についてのテキストベースクエリ用語検索を実行したい場合がある。ユーザが（例えば検索結果内の対応するリンクをクリックし、または他の方法で選択することにより指示するように）用語クエリによる検索を実行したい場合、クエリ用語サーバシステム（図１、１１８）にアクセスし、選択した１つまたは複数の用語による検索を実行する。対応する検索語の結果が、別個にまたは視覚クエリの結果と併せてクライアントシステム上に表示される（２３２）。一部の実施形態では、フロントエンド視覚クエリ処理サーバ（図１、１１０）が、自動で（すなわち最初の視覚クエリ以外のユーザコマンドを一切受け取ることなしに）視覚クエリについての１つまたは複数の最も可能性があるテキスト結果を選択し、用語クエリサーバシステム１１８上でそれらのテキスト結果を実行し、少なくとも１つの検索結果をクライアントシステムに送ることの一部として、視覚クエリの結果とともにそれらの用語クエリの結果をクライアントシステムに返す（２３２）。上記の例では、「ひれ足」がイルカの視覚クエリ写真についての第１の用語結果であった場合、フロントエンドサーバは「ひれ足」による用語クエリを実行し、視覚クエリの結果とともにそれらの用語クエリの結果をクライアントシステムに返す。視覚クエリの検索結果をユーザに送る前に、ユーザが選択するのではないかと思われる用語結果を自動で実行するこの実施形態は、ユーザの時間を節約する。一部の実施形態では、上記で説明したようにこれらの結果を複合検索結果として表示する（２２２）。他の実施形態では、結果は、複合検索結果の代わりに、または複合検索結果に加えて、検索結果一覧の一部である。 In some embodiments, the user may want to know more about a particular search result. For example, if the visual query is a photo of a dolphin and the “image-term” search system returns the terms “water”, “dolphins”, “blue”, and “flippers”, then the user has text about “flippers” You may want to perform a base query term search. Access to the query term server system (FIG. 1, 118) if the user wishes to perform a term query search (eg, by clicking on the corresponding link in the search results or instructing other ways to select) And performing a search by the selected term or terms. Corresponding search term results are displayed 232 separately or in conjunction with visual query results. In some embodiments, the front-end visual query processing server (FIG. 1, 110) automatically selects one or more most for a visual query (ie, without receiving any user commands other than the first visual query). As part of selecting potential text results, executing those text results on the term query server system 118, and sending at least one search result to the client system, those term queries along with the results of the visual query Is returned to the client system (232). In the above example, if “Flip” was the first term result for the dolphin visual query photo, the front-end server would execute a term query with “Flip” and those terms along with the result of the visual query. Returns the query result to the client system. This embodiment of automatically executing term results that the user may select before sending the visual query search results to the user saves the user time. In some embodiments, these results are displayed as combined search results (222) as described above. In other embodiments, the results are part of the search results list instead of or in addition to the composite search results.
図３は、対話型結果ドキュメントにより視覚クエリに応答するプロセスを示すフローチャートである。最初の３つの動作（２０２、２１０、２１４）は図２に関して上述した。並列検索システムから受け取った検索結果から（２１４）、対話型結果ドキュメントを作成する（３０２）。 FIG. 3 is a flowchart illustrating the process of responding to a visual query with an interactive results document. The first three operations (202, 210, 214) have been described above with respect to FIG. From the search results received from the parallel search system (214), an interactive result document is created (302).
次に対話型結果ドキュメントを作成すること（３０２）について詳しく説明する。一部の視覚クエリでは、対話型結果ドキュメントが、視覚クエリのそれぞれの副部分の１つまたは複数の視覚的識別子を含む。それぞれの視覚的識別子は、検索結果の少なくとも１つへの少なくとも１つのユーザ選択可能リンクを有する。視覚的識別子は、視覚クエリのそれぞれの副部分を識別する。一部の視覚クエリでは、対話型結果ドキュメントが、１つまたは複数の結果への１つのユーザ選択可能リンクを有する１つの視覚的識別子しか有さない。一部の実施形態では、検索結果の１つまたは複数へのそれぞれのユーザ選択可能リンクが活性化領域を有し、その活性化領域は、対応する視覚的識別子に関連する視覚クエリの副部分に対応する。 Next, the creation of the interactive result document (302) will be described in detail. For some visual queries, the interactive results document includes one or more visual identifiers for each subpart of the visual query. Each visual identifier has at least one user-selectable link to at least one of the search results. The visual identifier identifies each subpart of the visual query. For some visual queries, the interactive results document has only one visual identifier with one user-selectable link to one or more results. In some embodiments, each user-selectable link to one or more of the search results has an activation area that is a sub-part of the visual query associated with the corresponding visual identifier. Correspond.
一部の実施形態では、視覚的識別子が境界ボックスである（３０４）。一部の実施形態では、その境界ボックスは、図１２Ａに示すように視覚クエリの副部分を囲む。境界ボックスは正方形または長方形のボックス型である必要はなく、図１２Ｂに示すように円形、楕円形、（例えば視覚クエリ内のオブジェクトに、視覚クエリ内のエンティティに、または視覚クエリの領域に）準拠する形、不整形、または他の任意の形を含む任意の種類の形とすることができる。一部の視覚クエリでは、境界ボックスが視覚クエリの副部分内の識別可能エンティティの境界の輪郭を描く（３０６）。一部の実施形態では、各境界ボックスが１つまたは複数の検索結果へのユーザ選択可能リンクを含み、そのユーザ選択可能リンクは、境界ボックスによって囲まれる、視覚クエリの副部分に対応する活性化領域を有する。ユーザが境界ボックス内の空間（ユーザ選択可能リンクの活性化領域）を選択すると、輪郭が描かれた副部分の中の画像に対応する検索結果が返される。 In some embodiments, the visual identifier is a bounding box (304). In some embodiments, the bounding box surrounds a sub-portion of the visual query as shown in FIG. 12A. The bounding box does not have to be a square or rectangular box, but conforms to a circle, ellipse, (eg, to an object in a visual query, to an entity in a visual query, or to an area of a visual query) as shown in FIG. 12B. Can be any type of shape, including any shape, irregular shape, or any other shape. In some visual queries, a bounding box outlines the boundaries of the identifiable entities in the subpart of the visual query (306). In some embodiments, each bounding box includes a user-selectable link to one or more search results, the user-selectable link corresponding to a sub-part of the visual query surrounded by the bounding box. Has a region. When the user selects a space within the bounding box (an activation area for user selectable links), search results corresponding to the image in the outlined subpart are returned.
一部の実施形態では、図１４に示すように視覚的識別子がラベルである（３０７）。一部の実施形態では、ラベルは、視覚クエリのそれぞれの副部分内の画像に関連する少なくとも１つの用語を含む。各ラベルは、それぞれの副部分上またはその付近において対話型結果ドキュメント内で提示するためにフォーマットされる。一部の実施形態ではラベルを色分けする。 In some embodiments, the visual identifier is a label (307) as shown in FIG. In some embodiments, the label includes at least one term associated with the image in each sub-portion of the visual query. Each label is formatted for presentation in an interactive results document on or near a respective subpart. In some embodiments, the labels are color coded.
一部の実施形態では、視覚クエリのそれぞれの副部分内で認識されるエンティティの種類に応じて、視覚的に区別できる方法で提示するためにそれぞれの視覚的識別子をフォーマットする。例えば図１３に示すように、製品、人物、商標、および２つのテキスト領域を取り囲む境界ボックスを、各様に特色を与えられた透明な境界ボックスを表す互いに異なるクロスハッチングパターンを使ってそれぞれ提示する。一部の実施形態では、オーバーレイの色、オーバーレイパターン、ラベルの背景色、ラベルの背景パターン、ラベルのフォントの色、枠線色など、視覚的に区別できる方法で提示するために視覚的識別子をフォーマットする。 In some embodiments, depending on the type of entity recognized in each sub-part of the visual query, each visual identifier is formatted for presentation in a visually distinguishable manner. For example, as shown in FIG. 13, a bounding box that encloses a product, a person, a trademark, and two text regions is presented using different cross-hatching patterns that represent transparent bounding boxes that are featured in different ways. . In some embodiments, visual identifiers are presented for presentation in a visually distinguishable manner, such as overlay color, overlay pattern, label background color, label background pattern, label font color, border color, etc. Format.
一部の実施形態では、対話型結果ドキュメント内のユーザ選択可能リンクは、視覚クエリの対応する副部分に関係する１つまたは複数の結果を含むドキュメントもしくはオブジェクトへのリンクである（３０８）。一部の実施形態では、少なくとも１つの検索結果が視覚クエリの対応する副部分に関係するデータを含む。そのため、ユーザがそれぞれの副部分に関連する選択可能リンクを選択すると、ユーザは視覚クエリのそれぞれの副部分内で認識されるエンティティに対応する検索結果に導かれる。 In some embodiments, the user-selectable link in the interactive results document is a link (308) to a document or object that contains one or more results related to the corresponding subpart of the visual query. In some embodiments, at least one search result includes data related to a corresponding sub-portion of the visual query. Thus, when the user selects a selectable link associated with each subpart, the user is directed to search results corresponding to entities recognized within each subpart of the visual query.
例えば、視覚クエリがバーコードの写真であった場合、そのバーコードが添付された包装の無関連部分である写真の部分があり得る。対話型結果ドキュメントは、バーコードだけを取り囲む境界ボックスを含んでもよい。ユーザが、輪郭が描かれたバーコードの境界ボックス内を選択すると、そのバーコードの検索結果が表示される。バーコードの検索結果は、１つの結果、そのバーコードに対応する製品名を含んでもよく、またはバーコードの結果は、その製品を購入、吟味等できる様々な場所など、いくつかの結果を含んでもよい。 For example, if the visual query was a photo of a barcode, there could be a portion of the photo that is an irrelevant part of the package with the barcode attached. The interactive results document may include a bounding box that surrounds only the barcode. When the user selects within the bounding box of the outlined barcode, the barcode search result is displayed. A barcode search result may include a single result, the product name corresponding to that barcode, or a barcode result may include several results, such as various locations where the product can be purchased, reviewed, etc. But you can.
一部の実施形態では、それぞれの視覚的識別子に対応する視覚クエリの副部分が１つまたは複数の語からなるテキストを含む場合、それぞれの視覚的識別子に対応する検索結果は、そのテキスト内の語の少なくとも１つによる用語クエリ検索の結果を含む。一部の実施形態では、それぞれの視覚的識別子に対応する視覚クエリの副部分が、所定の信頼性（または他の）基準を満たす少なくとも１つの一致（すなわち検索結果）が見出される人物の顔を含む場合、それぞれの視覚的識別子に対応する検索結果は、選択可能な副部分内に顔が含まれている人物、選択可能な副部分内に顔が含まれている人物の他の画像、およびその人物の顔に関する潜在的な画像の一致に関連する名前、ハンドル、連絡先情報、アカウント情報、アドレス情報、かかわりのあるモバイル機器の現在地のうちの１つまたは複数を含む。一部の実施形態では、それぞれの視覚的識別子に対応する視覚クエリの副部分が、所定の信頼性（または他の）基準を満たす少なくとも１つの一致（すなわち検索結果）が見出される製品を含む場合、それぞれの視覚的識別子に対応する検索結果は、製品情報、製品レビュー、その製品の購入を開始するオプション、その製品に対する入札を開始するオプション、同様の製品の一覧、および関連製品の一覧のうちの１つまたは複数を含む。 In some embodiments, if the subpart of the visual query corresponding to each visual identifier includes text consisting of one or more words, the search results corresponding to each visual identifier are included in the text. Contains the results of a term query search by at least one of the words. In some embodiments, a sub-part of the visual query corresponding to each visual identifier is the face of a person for which at least one match (ie, search result) that meets a predetermined confidence (or other) criterion is found. If so, the search results corresponding to each visual identifier include a person whose face is included in the selectable subpart, other images of the person whose face is included in the selectable subpart, and Including one or more of the name, handle, contact information, account information, address information, and current location of the mobile device involved, related to potential image matches for the person's face. In some embodiments, the sub-part of the visual query corresponding to each visual identifier includes a product for which at least one match (ie, search result) that meets a predetermined confidence (or other) criterion is found. , Search results corresponding to each visual identifier include product information, product reviews, options to start purchasing the product, options to start bidding for the product, a list of similar products, and a list of related products One or more of.
場合により、対話型結果ドキュメント内のそれぞれのユーザ選択可能リンクは、リンクを活性化する必要なしにドキュメント内に表示されるアンカーテキストを含む。アンカーテキストは、リンクを活性化するときに得られる情報に関係する主要語や重要語などの情報を提供する。アンカーテキストは、ラベルの一部として（３０７）、または境界ボックスの一部の中に（３０４）、またはユーザが１秒などの所定期間にわたりユーザ選択可能リンク上にカーソルを乗せるときに表示される追加情報として表示されてもよい。 In some cases, each user-selectable link in the interactive results document includes anchor text that is displayed in the document without having to activate the link. Anchor text provides information such as key words and important words related to information obtained when activating a link. Anchor text is displayed as part of the label (307) or in part of the bounding box (304), or when the user places the cursor over a user selectable link for a predetermined period of time, such as 1 second. It may be displayed as additional information.
場合により、対話型結果ドキュメント内のそれぞれのユーザ選択可能リンクは、テキストベースクエリ（本明細書では用語クエリと呼ぶこともある）に対応する情報またはドキュメントを検索するための検索エンジンへのリンクである。リンクを活性化することは検索エンジンによる検索の実行を引き起こし、クライアントシステムに結果が返されることを伴い、クエリおよび検索エンジンはリンクによって指定される（例えば検索エンジンはリンク内のＵＲＬによって指定され、テキストベースの検索クエリはリンクのＵＲＬパラメータによって指定される）。場合により、この例におけるリンクは、検索クエリ内のテキストまたは語に特性をもたせるアンカーテキストを含んでもよい。 In some cases, each user-selectable link in an interactive results document is a link to a search engine for searching information or documents corresponding to a text-based query (sometimes referred to herein as a term query). is there. Activating the link causes the search engine to perform a search and results are returned to the client system, where the query and search engine are specified by the link (eg, the search engine is specified by the URL in the link, A text-based search query is specified by the URL parameter of the link). In some cases, the links in this example may include anchor text that characterizes the text or words in the search query.
一部の実施形態では、視覚クエリに応答して生成される対話型結果ドキュメントが、同じ検索システムからの結果に対応する複数のリンクを含むことができる。例えば、視覚クエリを人の集団の画像または写真としてもよい。対話型結果ドキュメントは、それぞれの人物を取り囲む境界ボックスを含んでもよく、その境界ボックスは活性化されると、その集団の中の顔ごとに顔認識検索システムからの結果を返す。一部の視覚クエリでは、対話型結果ドキュメント内の複数のリンクが、複数の検索システムからの検索結果に対応する（３１０）。例えば、人物と犬の写真が視覚クエリとしてサブミットされた場合、対話型結果ドキュメント内の境界ボックスは、その人物と犬とで別々に輪郭を描いてもよい。（対話型結果ドキュメント内の）人物を選択すると、顔認識検索システムからの検索結果が返され、（対話型結果ドキュメント内の）犬を選択すると、画像−用語検索システムからの結果が返される。一部の視覚クエリでは、対話型結果ドキュメントがＯＣＲの結果と画像一致の結果とを含む（３１２）。例えば、標識の隣に立っている人物の写真が視覚クエリとしてサブミットされた場合、対話型結果ドキュメントは、その人物の視覚的識別子とその標識内のテキストの視覚的識別子とを含んでもよい。同様に、雑誌のスキャンが視覚クエリとして使用された場合、対話型結果ドキュメントは、そのページ上の広告内の写真または商標の視覚的識別子、ならびに同じくそのページ上の記事のテキストの視覚的識別子を含んでもよい。 In some embodiments, an interactive results document generated in response to a visual query can include multiple links that correspond to results from the same search system. For example, the visual query may be an image or photo of a group of people. The interactive results document may include a bounding box that surrounds each person, and when the bounding box is activated, returns a result from the face recognition search system for each face in the population. In some visual queries, multiple links in the interactive results document correspond to search results from multiple search systems (310). For example, if a picture of a person and a dog is submitted as a visual query, the bounding box in the interactive results document may be outlined separately for that person and the dog. Selecting a person (in the interactive results document) returns search results from the face recognition search system, and selecting a dog (in the interactive results document) returns results from the image-term search system. For some visual queries, the interactive results document includes 312 OCR results and image match results. For example, if a picture of a person standing next to a sign is submitted as a visual query, the interactive results document may include the person's visual identifier and the visual identifier of the text in the sign. Similarly, if a magazine scan is used as a visual query, the interactive results document will include the visual identifier of the photo or trademark in the advertisement on that page, as well as the visual identifier of the text of the article on that page. May be included.
対話型結果ドキュメントを作成した後、その対話型結果ドキュメントをクライアントシステムに送る（３１４）。一部の実施形態では、対話型結果ドキュメント（例えば図１５、ドキュメント１２００）を、図２に関して上記で論じたように１つまたは複数の並列検索システムからの検索結果一覧と併せて送る。一部の実施形態では、図１５に示すように、対話型結果ドキュメントを、１つまたは複数の並列検索システムからの検索結果一覧の上にあるいはその一覧に隣接してクライアントシステムにおいて表示する（３１５）。 After creating the interactive result document, the interactive result document is sent to the client system (314). In some embodiments, an interactive results document (eg, FIG. 15, document 1200) is sent in conjunction with a search results list from one or more parallel search systems as discussed above with respect to FIG. In some embodiments, as shown in FIG. 15, an interactive results document is displayed at a client system on or adjacent to a search results list from one or more parallel search systems (315). ).
場合により、ユーザは、結果ドキュメント内の視覚的識別子を選択することにより結果ドキュメントと対話する。サーバシステムは、対話型結果ドキュメント内の視覚的識別子についてのユーザ選択に関する情報をクライアントシステムから受け取る（３１６）。上記で論じたように、一部の実施形態では、リンクは境界ボックス内の活性化領域を選択することによって活性化される。他の実施形態では、リンクは、境界ボックスではない視覚クエリの副部分の視覚的識別子をユーザが選択することによって活性化される。一部の実施形態では、リンクされた視覚的識別子は、ホットボタン、副部分の近くに位置するラベル、テキスト内の下線を引いた語、または視覚クエリ内のオブジェクトもしくはサブジェクトの他の表現である。 In some cases, the user interacts with the result document by selecting a visual identifier within the result document. The server system receives information from the client system about the user selection for the visual identifier in the interactive results document (316). As discussed above, in some embodiments, the link is activated by selecting an activation region within the bounding box. In other embodiments, the link is activated by the user selecting a visual identifier for a sub-part of the visual query that is not a bounding box. In some embodiments, the linked visual identifier is a hot button, a label located near the subpart, an underlined word in the text, or other representation of the object or subject in the visual query. .
検索結果一覧が対話型結果ドキュメントとともに提示される実施形態では（３１５）、ユーザがユーザ選択可能リンクを選択すると（３１６）、選択されたリンクに対応する検索結果一覧内の検索結果が特定される。一部の実施形態では、選択されたリンクに対応する最初の結果にカーソルがジャンプし、または自動的に移動する。対話型結果ドキュメントおよび全検索結果一覧の両方を表示するにはクライアント１０２のディスプレイが小さすぎる一部の実施形態では、対話型結果ドキュメント内のリンクを選択することが、選択されたリンクに対応する少なくとも最初の結果を表示するように、検索結果一覧をスクロールまたはジャンプさせる。他の一部の実施形態では、対話型結果ドキュメント内のリンクをユーザが選択することに応答し、そのリンクに対応する最初の結果が結果一覧の最も上に表示されるように結果一覧を並べ替える。
In embodiments where the search result list is presented with the interactive results document (315), when the user selects a user selectable link (316), the search result in the search result list corresponding to the selected link is identified. . In some embodiments, the cursor jumps to or automatically moves to the first result corresponding to the selected link. In some embodiments where the display of the
一部の実施形態では、ユーザがユーザ選択可能リンクを選択すると（３１６）、視覚クエリサーバシステムが、視覚クエリの対応する副部分に関係する結果の少なくとも一部をユーザに表示するためにクライアントに送る（３１８）。一部の実施形態では、ユーザは複数の視覚的識別子を同時に選択することができ、選択した視覚的識別子のすべての結果の一部を同時に受け取る。他の実施形態では、対話型結果ドキュメント内の１つまたは複数のリンクをユーザが選択することに応答してほぼ瞬時に検索結果をユーザに提供するために、ユーザ選択可能リンクのいずれかをユーザが選択する前に、ユーザ選択可能リンクに対応する検索結果をクライアント上にあらかじめロードしておく。 In some embodiments, when the user selects a user selectable link (316), the visual query server system prompts the client to display at least a portion of the results related to the corresponding subpart of the visual query to the user. Send (318). In some embodiments, the user can select multiple visual identifiers simultaneously and receive a portion of all the results of the selected visual identifiers simultaneously. In other embodiments, any of the user selectable links are provided to the user in order to provide the user with search results almost instantaneously in response to the user selecting one or more links in the interactive results document. Before selecting, a search result corresponding to the user-selectable link is loaded on the client in advance.
図４は、クライアントと視覚クエリサーバシステムとの間の通信を示すフローチャートである。クライアント１０２が、ユーザ／クエリ側から視覚クエリを受け取る（４０２）
。一部の実施形態では、視覚クエリシステムにサインアップし、または「オプトイン」しているユーザからのみ視覚クエリを受け付けることができる。一部の実施形態では、顔認識の一致を得るための検索は顔認識視覚クエリシステムにサインアップしているユーザに対してのみ実行される一方で、他の種類の視覚クエリは、顔認識部分に「オプトイン」しているかいないかに関係なく誰に対しても実行される。
FIG. 4 is a flowchart showing communication between the client and the visual query server system.
. In some embodiments, visual queries can be accepted only from users who have signed up or “opted in” to the visual query system. In some embodiments, the search for a facial recognition match is performed only for users who are signed up for the facial recognition visual query system, while other types of visual queries are Regardless of whether or not they are "opted in"
上記で説明したように、視覚クエリの形式は多くの形態をとることができる。視覚クエリは、視覚クエリドキュメントの副部分内に位置する１つまたは複数のサブジェクトを含む可能性が高い。一部の視覚クエリでは、クライアントシステム１０２が視覚クエリに対してタイプ認識事前処理を実行する（４０４）。一部の実施形態では、クライアントシステム１０２が、この事前処理システム内で特定の認識可能パターンを検索する。例えば一部の視覚クエリでは、クライアントが色を認識し得る。一部の視覚クエリでは、クライアントは特定の副部分が（その領域が淡い空間によって囲まれる小さな濃い文字で構成されている等の理由で）テキストを含む可能性が高いと認識し得る。クライアントは、任意の数の事前処理タイプ認識器またはタイプ認識モジュールを含み得る。一部の実施形態では、クライアントが、バーコードを認識するためのタイプ認識モジュール（バーコード認識４０６）を有する。クライアントは、長方形領域内の特有の縞模様を認識することによってバーコードを認識し得る。一部の実施形態では、クライアントは、視覚クエリの特定のサブジェクトまたは副部分が顔を含む可能性が高いことを認識するためのタイプ認識モジュール（顔検出４０８）を有する。
As explained above, the format of a visual query can take many forms. A visual query is likely to include one or more subjects located within a sub-part of the visual query document. For some visual queries, the
一部の実施形態では、認識した「タイプ」を検証するためにユーザに返す。例えばクライアントシステム１０２は、「あなたの視覚クエリの中にバーコードが見つかりました。バーコードのクエリ結果を受け取りたいですか？」と述べるメッセージを返すことができる。一部の実施形態では、メッセージは、そのタイプが見つかった視覚クエリの副部分さえも示し得る。一部の実施形態では、この提示は図３に関して論じた対話型結果ドキュメントに似ている。例えばこの提示は、視覚クエリの副部分の輪郭を描いてもよく、その副部分が顔を含む可能性が高いことを示してもよく、ユーザに顔認識結果を受け取りたいかどうか尋ねてもよい。
In some embodiments, the recognized “type” is returned to the user for verification. For example, the
クライアント１０２が視覚クエリのオプションの事前処理を実行した後、クライアントは、その視覚クエリを視覚クエリサーバシステム１０６、とりわけフロントエンド視覚クエリ処理サーバ１１０に送る。一部の実施形態では、事前処理が関連する結果をもたらした場合、すなわちタイプ認識モジュールの１つが、クエリまたはクエリの副部分が特定のタイプ（顔、テキスト、バーコード等）のものである可能性が高いことを示す一定の閾値を上回る結果をもたらした場合、クライアントは事前処理の結果に関する情報を伝える。例えばクライアントは、視覚クエリの特定の副部分が顔を含むと顔認識モジュールが７５％確信していることを示し得る。より一般には、事前処理の結果が、もしあれば、１つまたは複数のサブジェクトタイプ値（例えばバーコード、顔、テキスト等）を含む。場合により、視覚クエリサーバシステムに送られる事前処理の結果は、事前処理結果内の各サブジェクトタイプ値について、そのサブジェクトタイプ値に対応する視覚クエリの副部分を特定する情報、ならびに事前処理結果内の各サブジェクトタイプ値について、そのサブジェクトタイプ値の信頼水準を示す信頼値および／または視覚クエリの対応する副部分の特定についての信頼水準を示す信頼値のうちの１つまたは複数を含む。
After the
フロントエンドサーバ１１０が、クライアントシステムから視覚クエリを受け取る（２０２）。受け取られる視覚クエリは、上記で論じた事前処理情報を含み得る。上記で説明したように、フロントエンドサーバが視覚クエリを複数の並列検索システムに送る（２１０）。特定の種類のサブジェクトを副部分が含んでいた可能性に関する事前処理情報をフロントエンドサーバ１１０が受け取る場合、フロントエンドサーバは、この情報を並列検索システムの１つまたは複数に伝えてもよい。例えばフロントエンドサーバは、特定の副部分が顔である可能性が高いという情報を伝えてもよく、それにより、顔認識検索システム１１２−Ａは視覚クエリのその小区分を最初に処理することができる。同様に、その副部分を無視するために、または他の副部分を最初に解析するために、他の並列検索システムは（特定の副部分が顔である可能性が高いという）同一情報を送ることを使用してもよい。一部の実施形態では、フロントエンドサーバは、事前処理情報を並列検索システムに伝えないが、代わりにこの情報を使用して、並列検索システムから受け取る結果を自らが処理する方法を増強する。
The front-
図２に関して説明したように、一部の視覚クエリに関しては、フロントエンドサーバ１１０が並列検索システムから複数の検索結果を受け取る（２１４）。次いで、図２および図３に関して説明したように、フロントエンドサーバは、様々なランク付けおよびフィルタリングを実行してもよく、対話型検索結果ドキュメントを作成してもよい。特定の種類のサブジェクトを副部分が含んでいた可能性に関する事前処理情報をフロントエンドサーバ１１０が受け取る場合、フロントエンドサーバは、事前処理され認識されたサブジェクトタイプに一致する結果を優先することにより、フィルタおよび順序付けしてもよい。特定の種類の結果を要求したことをユーザが示した場合、フロントエンドサーバは結果を処理する際にユーザの要求を考慮に入れる。例えばフロントエンドサーバは、ユーザがバーコード情報だけを要求した場合、他のすべての結果をフィルタにかけて除去してもよく、または他の結果を列挙する前に要求された種類に関連するすべての結果を列挙する。対話型視覚クエリドキュメントが返される場合、サーバは、ユーザが関心をもっていると示した結果の種類に関連するリンクを事前に検索し得る一方で、対話型結果ドキュメント内に示される他のサブジェクトについては、関係する検索を行うためのリンクを提供するに過ぎない。次いで、フロントエンドサーバ１１０が、検索結果をクライアントシステムに送る（２２６）。
As described with respect to FIG. 2, for some visual queries, the front-
クライアント１０２が、サーバシステムから結果を受け取る（４１２）。該当する場合、これらの結果は事前処理段階で見つかる結果の種類に一致する結果を含む。例えば一部の実施形態では、これらの結果は、１つもしくは複数のバーコードの結果（４１４）、または１つもしくは複数の顔認識の結果（４１６）を含む。特定の種類の結果が見込まれることをクライアントの事前処理モジュールが示し、その結果が見つかった場合、その種類の見つかった結果を目立つように列挙する。
場合により、ユーザが結果の１つまたは複数を選択し、または注釈を付ける（４１８）。ユーザは、１つの検索結果を選択してもよく、特定の種類の検索結果を選択してもよく、かつ／または対話型結果ドキュメントの一部を選択してもよい（４２０）。結果が選択されることは、返した結果がクエリに関連していたという暗黙のフィードバックである。そのようなフィードバック情報は、将来のクエリ処理操作で利用することができる。注釈は返された結果に関する明示的なフィードバックを提供し、同じく将来のクエリ処理操作で利用することができる。注釈は、（誤ってＯＣＲされた語を訂正するように）返された結果の一部を訂正すること、または（自由な形式のまたは構造化された）別個の注釈の形をとる。 In some cases, the user selects or annotates (418) one or more of the results. The user may select one search result, may select a particular type of search result, and / or may select a portion of the interactive results document (420). Selecting a result is an implicit feedback that the returned result was related to the query. Such feedback information can be used in future query processing operations. Annotations provide explicit feedback about the results returned and can also be used in future query processing operations. The annotation takes the form of correcting a part of the returned result (to correct an erroneously OCR word) or a separate annotation (free form or structured).
ユーザが１つの検索結果を選択すること、一般にいくつかの同じ種類から「正しい」結果を選択すること（例えば顔認識サーバからの正しい結果を選択すること）は、解釈の中での選択(selection among interpretations)と呼ばれるプロセスである。ユーザが特定の種類の検索結果を選択すること、一般にいくつかの異なる種類の返される結果から関心のある結果の「種類」を選択すること（例えば雑誌の中の広告の視覚的結果ではなく、やはり同じページ上の記事のＯＣＲされたテキストを選択すること）は、意図の曖昧性除去と呼ばれるプロセスである。図８に関して詳しく説明するように、ユーザは、ＯＣＲされたドキュメント内の特定のリンクされた語（認識されている固有表現など）を同様に選択してもよい。 Selecting a search result by the user, generally selecting the “correct” result from several identical types (eg selecting the correct result from a face recognition server) is a selection in the interpretation. among interpretations). The user selects a particular type of search result, generally selecting the “type” of the result of interest from several different types of returned results (for example, not the visual result of an advertisement in a magazine, Selecting the OCR text of an article that is also on the same page) is a process called intent disambiguation. As will be described in detail with respect to FIG. 8, the user may similarly select particular linked words (such as recognized named expressions) within the OCR document.
ユーザは、代わりにまたは加えて、特定の検索結果に注釈を付けたいことがある。この注釈を付けることは、自由形式スタイルで、または構造化された形式で行ってもよい（４２２）。注釈は、結果の説明としてもよく、または結果のレビューとしてもよい。例えば注釈は、結果内の１つもしくは複数のサブジェクトの名前を示してもよく、または「これは良書だ」や「この製品は購入してから１年以内に壊れた」ことを示すことができる。注釈の別の例は、視覚クエリの副部分を取り囲むユーザによって描かれる境界ボックス、および境界ボックス内のオブジェクトまたはサブジェクトを特定するユーザによって提供されるテキストである。ユーザの注釈については図５に関してより詳細に説明する。 Users may instead or additionally want to annotate specific search results. This annotation may be done in a free form style or in a structured form (422). The annotation may be a description of the result or a review of the result. For example, the annotation may indicate the name of one or more subjects in the result, or may indicate "This is a good book" or "This product was broken within one year of purchase" . Another example of an annotation is a bounding box drawn by a user surrounding a sub-part of a visual query and text provided by a user identifying an object or subject within the bounding box. User annotations are described in more detail with respect to FIG.
検索結果のユーザ選択および他の注釈をサーバシステムに送る（４２４）。フロントエンドサーバ１１０がその選択および注釈を受け取り、それらをさらに処理する（４２６）。この情報が、対話型結果ドキュメント内のオブジェクト、副領域、または用語の選択であった場合、その選択に関するさらなる情報を必要に応じて要求してもよい。例えば選択が１つの視覚的結果についての選択であった場合、その視覚的結果に関するさらなる情報が要求される。選択が（ＯＣＲサーバまたは画像−用語サーバからの）語であった場合、その語のテキスト検索が用語クエリサーバシステム１１８に送られる。選択が顔画像認識検索システムからの人物についての選択であった場合、その人物のプロファイルが要求される。選択が対話型検索結果ドキュメントの特定の部分についてのものであった場合、基礎をなす視覚クエリの結果が要求される。
User selection of search results and other annotations are sent to the server system (424).
サーバシステムが注釈を受け取る場合、図５に関して説明するように、その注釈はクエリ／注釈データベース１１６内に記憶される。その後、図７〜１０に関して以下で論じるように、注釈データベース１１６からの情報を、並列サーバシステムの１つまたは複数のための個々の注釈データベースに周期的にコピーする。
When the server system receives an annotation, the annotation is stored in the query /
図５は、本発明の一実施形態によるクライアントシステム１０２を示すブロック図である。クライアントシステム１０２は、典型的には１個または複数個の処理ユニット（ＣＰＵ）７０２、１つまたは複数のネットワークインターフェイスもしくは他の通信インターフェイス７０４、メモリ７１２、およびこれらのコンポーネントを相互接続するための１つまたは複数の通信バス７１４を含む。クライアントシステム１０２は、ユーザインターフェイス７０５を含む。ユーザインターフェイス７０５は、ディスプレイ装置７０６を含み、場合によりキーボード、マウス、他の入力ボタン７０８などの入力手段を含む。あるいは、またはそれに加えて、ディスプレイ装置７０６はタッチセンス表面７０９を含み、その場合、ディスプレイ７０６／７０９はタッチセンスディスプレイである。タッチセンスディスプレイ７０６／７０９を有するクライアントシステムでは、物理的なキーボードはオプションである（例えばキーボード入力が必要な場合はソフトキーボードを表示してもよい）。さらに、一部のクライアントシステムは、マイクロフォンおよび音声認識を使用してキーボードを補足しまたは置換する。場合により、クライアント１０２は、自らの位置を求めるためのＧＰＳ（地球投影位置決定衛星）受信機または他の位置検出機器７０７を含む。一部の実施形態では、クライアントシステム１０２の位置を示す位置情報をクライアントシステム１０２が視覚クエリサーバシステムに提供することを必要とする、視覚クエリ検索サービスが提供される。
FIG. 5 is a block diagram illustrating a
クライアントシステム１０２は、カメラやスキャナなどの画像取込装置７１０も含む。メモリ７１２には、ＤＲＡＭ、ＳＲＡＭ、ＤＤＲ ＲＡＭ、または他のランダムアクセス固体メモリデバイスなどの高速ランダムアクセスメモリが含まれ、１つまたは複数の磁気ディスク記憶装置、光学ディスク記憶装置、フラッシュメモリ装置、または他の不揮発性固体記憶デバイスなどの不揮発性メモリが含まれ得る。メモリ７１２には、１個または複数個のＣＰＵ７０２から離れて位置する１つまたは複数の記憶装置が場合により含まれ得る。メモリ７１２あるいはメモリ７１２内の１つまたは複数の不揮発性メモリ装置は、持続性コンピュータ可読記憶媒体を含む。一部の実施形態では、メモリ７１２またはメモリ７１２のコンピュータ可読記憶媒体が、以下のプログラム、モジュール、およびデータ構造またはその一部を記憶する。
・ 様々な基本システムサービスを処理し、ハードウェア依存タスクを実行するためのプロシージャを含むオペレーティングシステム７１６。
・ クライアントシステム１０２を、１つまたは複数の通信ネットワークインターフェイス７０４（有線または無線）、およびインターネット、他の広域ネットワーク、ローカルエリアネットワーク、メトロポリタンエリアネットワークなどの１つまたは複数の通信ネットワークを介して他のコンピュータに接続するために使用するネットワーク通信モジュール７１８。
・ 画像取込装置／カメラ７１０が取り込んだそれぞれの画像を処理するための画像取込モジュール７２０であって、それぞれの画像は（例えばクライアントアプリケーションモジュールにより）、視覚クエリとして視覚クエリサーバシステムに送ってもよい。
・ これだけに限定されないが、視覚クエリサーバシステムに視覚クエリをサブミットするための画像によるクエリサブミットモジュール７２４、場合により、画像内の関心領域が選択されたこと（タッチセンスディスプレイ７０６／７０９上でのジェスチャなど）を検出し、その関心領域を視覚クエリとして準備する関心領域選択モジュール７２５、視覚クエリの結果を表示するための結果ブラウザ７２６、および場合により、フォームに記入するなどの構造化された注釈テキスト入力のためのオプションモジュール７３０を有し、または様々な形式からの注釈を受け付けることができる自由形式の注釈テキスト入力のためのオプションモジュール７３２を有し、ユーザが注釈用に画像の特定の副部分を選択することを可能にする画像領域選択モジュール７３４（本明細書では結果選択モジュールと呼ぶこともある）を有する注釈モジュール７２８を含む、画像によるクエリを行う様々な側面を処理するための１つまたは複数のクライアントアプリケーションモジュール７２２。
・ 画像取込装置７１０により単に画像を取り込むのではなく、画像を作成しまたは編集することによりユーザが視覚クエリを作成することを可能にする、１つまたは複数のオプションのコンテンツオーサリングアプリケーション７３６、場合により、そのようなアプリケーション７３６の１つは、視覚クエリとして使用するための画像の副部分をユーザが選択できるようにする命令を含んでもよい。
・ 視覚クエリサーバシステムに送る前に視覚クエリを事前処理する、オプションのローカル画像解析モジュール７３８。ローカル画像解析は、特定の種類の画像または画像内の副領域を認識し得る。そのようなモジュール７３８が認識し得る画像の種類の例には、顔タイプ（視覚クエリ内で認識される顔画像）、バーコードタイプ（視覚クエリ内で認識されるバーコード）、およびテキストタイプ（視覚クエリ内で認識されるテキスト）のうちの１つまたは複数が含まれる。
・ 電子メールアプリケーション、電話アプリケーション、ブラウザアプリケーション、マッピングアプリケーション、インスタントメッセージングアプリケーション、ソーシャルネットワーキングアプリケーションなど、さらなるオプションのクライアントアプリケーション７４０。一部の実施形態では、作動可能検索結果を選択すると、該当する作動可能検索結果に対応するアプリケーションを起動し、またはそのアプリケーションにアクセスすることができる。
The
An
The
An
• a query submission module by
One or more optional
An optional local
Additional
場合により、ユーザが注釈用に画像の特定の副部分を選択することを可能にする画像領域選択モジュール７３４は、ユーザが、必ずしもさらなる注釈を付けることなく検索結果を「正しい」ヒットとして選択することも可能にする。例えば、ユーザに上位Ｎ個の顔認識の一致を提示してもよく、ユーザがその結果一覧から正しい人物を選択してもよい。一部の検索クエリでは、複数の種類の結果が提示され、ユーザは結果の種類を選択する。例えば、画像クエリが木の隣に立っている人物を含むが、ユーザはその人物に関する結果だけに興味がある場合がある。したがって画像選択モジュール７３４は、ユーザが、どの画像の種類が「正しい」種類であるか、すなわちそのユーザが受け取りたいと思う種類であるかを指示することを可能にする。ユーザは、（フォームに記入するための）注釈テキスト入力モジュール７３０または自由形式注釈テキスト入力モジュール７３２のいずれかを使用し、個人的なコメントまたは説明的な言葉を加えることにより検索結果に注釈を付けたい場合もある。
In some cases, the image
一部の実施形態では、オプションのローカル画像解析モジュール７３８がクライアントアプリケーション（図１、１０８）の一部である。さらに一部の実施形態では、オプションのローカル画像解析モジュール７３８が、視覚クエリまたは視覚クエリの一部を事前処理しもしくは分類するためのローカル画像解析を実行するための、１つまたは複数のプログラムを含む。例えばクライアントアプリケーション７２２は、検索エンジンに視覚クエリをサブミットする前に画像がバーコード、顔、またはテキストを含むことを認識し得る。一部の実施形態では、視覚クエリが特定の種類の画像を含むとローカル画像解析モジュール７３８が検出する場合、そのモジュールは、対応する種類の検索結果に興味があるかどうかをユーザに尋ねる。例えば、ローカル画像解析モジュール７３８は、その一般的特徴に基づいて（すなわち誰の顔かを決定することなしに）顔を検出し得、視覚クエリサーバシステムにクエリを送る前にユーザに即時フィードバックを提供する。ローカル画像解析モジュール７３８は、「顔を検出しました。この顔について顔認識の一致を得たいですか？」のような結果を返してもよい。このようにすることで、視覚クエリサーバシステム（図１、１０６）の時間を節約し得る。一部の視覚クエリでは、フロントエンド視覚クエリ処理サーバ（図１、１１０）は、ローカル画像解析モジュール７３８が認識した画像の種類に対応する検索システム１１２にしか視覚クエリを送らない。他の実施形態では、検索システム１１２への視覚クエリは、検索システム１１２Ａ〜Ｎのすべてに視覚クエリを送ってもよいが、ローカル画像解析モジュール７３８が認識した画像の種類に対応する、検索システム１１２からの結果をランク付けする。一部の実施形態では、視覚クエリサーバシステムの動作にローカル画像解析が影響を及ぼす様式は、クライアントシステムの構成、またはユーザもしくはクライアントシステムに関連する構成または処理パラメータによって決まる。さらに、任意の特定の視覚クエリの実際のコンテンツおよびローカル画像解析によってもたらされる結果は、クライアントシステムおよび視覚クエリサーバシステムのいずれかまたは両方において異なるように処理すべき異なる視覚クエリをもたらす場合がある。
In some embodiments, an optional local
一部の実施形態では、バーコード認識を２つのステップで行い、視覚クエリがバーコードを含むかどうかの解析を、ローカル画像解析モジュール７３８においてクライアントシステム上で実行する。次いで、視覚クエリがバーコードを含む可能性が高いとクライアントが判断する場合にのみ、視覚クエリをバーコード検索システムに渡す。他の実施形態では、バーコード検索システムがすべての視覚クエリを処理する。
In some embodiments, barcode recognition is performed in two steps, and the analysis of whether the visual query includes a barcode is performed on the client system at the local
場合により、クライアントシステム１０２は、追加のクライアントアプリケーション７４０を含む。
In some cases, the
図６は、本発明の一実施形態によるフロントエンド視覚クエリ処理サーバシステム１１０を示すブロック図である。フロントエンドサーバ１１０は、典型的には１個または複数個の処理ユニット（ＣＰＵ）８０２、１つまたは複数のネットワークインターフェイスもしくは他の通信インターフェイス８０４、メモリ８１２、およびこれらのコンポーネントを相互接続するための１つまたは複数の通信バス８１４を含む。メモリ８１２には、ＤＲＡＭ、ＳＲＡＭ、ＤＤＲ ＲＡＭ、または他のランダムアクセス固体メモリデバイスなどの高速ランダムアクセスメモリが含まれ、１つまたは複数の磁気ディスク記憶装置、光学ディスク記憶装置、フラッシュメモリ装置、または他の不揮発性固体記憶デバイスなどの不揮発性メモリが含まれ得る。メモリ８１２には、１個または複数個のＣＰＵ８０２から離れて位置する１つまたは複数の記憶装置が場合により含まれ得る。メモリ８１２あるいはメモリ８１２内の１つまたは複数の不揮発性メモリ装置は、持続性コンピュータ可読記憶媒体を含む。一部の実施形態では、メモリ８１２またはメモリ８１２のコンピュータ可読記憶媒体が、以下のプログラム、モジュール、およびデータ構造またはその一部を記憶する。
・ 様々な基本システムサービスを処理し、ハードウェア依存タスクを実行するためのプロシージャを含むオペレーティングシステム８１６。
・ フロントエンドサーバシステム１１０を、１つまたは複数の通信ネットワークインターフェイス８０４（有線または無線）、およびインターネット、他の広域ネットワーク、ローカルエリアネットワーク、メトロポリタンエリアネットワークなどの１つまたは複数の通信ネットワークを介して他のコンピュータに接続するために使用するネットワーク通信モジュール８１８。
・ クライアントシステム１０２から来る視覚クエリを処理し、それらの視覚クエリを複数の並列検索システムに送るためのクエリマネージャ８２０であって、本明細書のいたるところに記載するように、視覚クエリがクライアントによって生成された命令（例えば「顔認識検索のみ」）を含む場合など、一部の特別な状況では視覚クエリを検索システムのうちの１つだけに導くことがある。
・ １つまたは複数の並列検索システムからの結果を場合によりフィルタし、提示するために最上位のまたは「関連する」結果をクライアントシステム１０２に送るための結果フィルタリングモジュール８２２。
・ １つまたは複数の並列検索システムからの結果を場合によりランク付けし、提示するために結果をフォーマットするための結果ランク付け／フォーマットモジュール８２４。
・ 結果ドキュメント作成モジュール８２６は、対話型検索結果ドキュメントを作成するために適切な場合に使用し、モジュール８２６は、これだけに限定されないが、境界ボックス作成モジュール８２８およびリンク作成モジュール８３０を含むサブモジュールを含んでもよい。
・ 視覚クエリのそれぞれの副部分の視覚的識別子であるラベルを作成するための、ラベル作成モジュール８３１。
・ ユーザから注釈を受け取り、それらの注釈を注釈データベース１１６に送るための注釈モジュール８３２。
・ 視覚クエリに応答し、クライアント側のアクションを起動するようにそれぞれが構成される、１つまたは複数の作動可能検索結果要素を生成するための作動可能検索結果モジュール８３８であって、作動可能検索結果要素の例は、通話を開始するためのボタン、電子メールメッセージを開始するためのボタン、住所の地図を描くためのボタン、レストランを予約するためのボタン、および製品を購入するオプションを提供するためのボタンである。
・ データベース自体８３４およびデータベースの索引８３６を含む、クエリ／注釈データベース１１６。
FIG. 6 is a block diagram illustrating a front-end visual query
An
Front-
A
A
A result ranking /
Results
A
An
An operable
A query /
結果ランク付け／フォーマットモジュール８２４は、１つまたは複数の並列検索システム（図１、１１２−Ａ〜１１２−Ｎ）から返される結果をランク付けする。既に上記で述べたように、一部の視覚クエリでは、１つの検索システムからの結果しか関連しない場合がある。そのような場合、その１つの検索システムからの関連する検索結果だけをランク付けする。一部の視覚クエリでは、数種類の検索結果が関連することがある。これらの例では、一部の実施形態において、結果ランク付け／フォーマットモジュール８２４は、より関連性が低い検索システムの結果に優先して、最も関連する結果（例えば最も高い関連性スコアを有する結果）を有する検索システムからの結果のすべてをランク付けする。他の実施形態では、結果ランク付け／フォーマットモジュール８２４が、関連する各検索システムからの最上位の結果を残りの結果に優先してランク付けする。一部の実施形態では、結果ランク付け／フォーマットモジュール８２４が、検索結果のそれぞれについて計算される関連性スコアに従って結果をランク付けする。一部の視覚クエリでは、並列視覚検索システムによる検索に加えて拡張(augmented)テキストクエリを実行する。一部の実施形態では、テキストクエリも実行する場合、それらの結果を視覚検索システムの結果と視覚的に区別できる方法で提示する。
The result ranking /
結果ランク付け／フォーマットモジュール８２４はさらに、結果をフォーマットする。一部の実施形態では、結果が一覧形式で提示される。一部の実施形態では、結果が対話型結果ドキュメントによって提示される。一部の実施形態では、対話型結果ドキュメントおよび結果一覧の両方が提示される。一部の実施形態では、クエリの種類が、結果を提示する方法を決定づける。例えば、視覚クエリ内で複数の検索可能サブジェクトが検出される場合、対話型結果ドキュメントが作成されるのに対し、検索可能サブジェクトが１つしか検出されない場合、結果は一覧形式でのみ表示される。
The result ranking /
結果ドキュメント作成モジュール８２６は、対話型検索結果ドキュメントを作成するために使用する。対話型検索結果ドキュメントは、１つまたは複数の検出済みおよび検索済みサブジェクトを有し得る。境界ボックス作成モジュール８２８は、検索済みサブジェクトのうちの１つまたは複数を取り囲む境界ボックスを作成する。境界ボックスは長方形のボックスとしてもよく、または１つもしくは複数のサブジェクトの１つもしくは複数の形の輪郭を描いてもよい。リンク作成モジュール８３０は、対話型検索結果ドキュメント内のそれぞれのサブジェクトに関連する検索結果へのリンクを作成する。一部の実施形態では、境界ボックス領域内でクリックすることは、リンク作成モジュールが挿入した対応するリンクを活性化する。
The result
クエリ／注釈データベース１１６は、視覚クエリの結果を改善するために使用することができる情報を含む。一部の実施形態では、視覚クエリの結果が提示された後、ユーザは画像に注釈を付けてもよい。さらに一部の実施形態では、ユーザは、画像に注釈を付けてからその画像を視覚クエリ検索システムに送ってもよい。事前に注釈を付けることは、結果の的を絞ることにより、または視覚クエリ検索に並列して注釈が付けられた語に対するテキストベース検索を実行することにより、視覚クエリの処理を促進し得る。一部の実施形態では、潜在的な画像一致ヒットとして返されるように、注釈を付けたバージョンの写真を（例えばその画像および１つまたは複数の注釈を非公開ではないと指定することにより、例えばユーザに公開する許可が与えられている場合）公開することができる。例えば、ユーザが花の写真を撮り、その花に関する詳細な属および種の情報を与えることによりその画像に注釈を付ける場合、ユーザは、その花を探している視覚クエリ調査を行うすべての人にその画像を提示したい場合がある。一部の実施形態では、クエリ／注釈データベース１１６からの情報を並列検索システム１１２に周期的にプッシュし、並列検索システム１１２はその情報の関連部分を（もしあれば）個々のデータベース１１４内に取り入れる。
Query /
図７は、視覚クエリを処理するために利用する並列検索システムのうちの１つを示すブロック図である。図７は、本発明の一実施形態による「汎用」サーバシステム１１２−Ｎを示す。このサーバシステムは、視覚クエリ検索サーバ１１２−Ｎのうちのいずれか１つを表すという点でのみ汎用である。汎用サーバシステム１１２−Ｎは、典型的には１個または複数個の処理ユニット（ＣＰＵ）５０２、１つまたは複数のネットワークインターフェイスもしくは他の通信インターフェイス５０４、メモリ５１２、およびこれらのコンポーネントを相互接続するための１つまたは複数の通信バス５１４を含む。メモリ５１２には、ＤＲＡＭ、ＳＲＡＭ、ＤＤＲ ＲＡＭ、または他のランダムアクセス固体メモリデバイスなどの高速ランダムアクセスメモリが含まれ、１つまたは複数の磁気ディスク記憶装置、光学ディスク記憶装置、フラッシュメモリ装置、または他の不揮発性固体記憶デバイスなどの不揮発性メモリが含まれ得る。メモリ５１２には、１個または複数個のＣＰＵ５０２から離れて位置する１つまたは複数の記憶装置が場合により含まれ得る。メモリ５１２あるいはメモリ５１２内の１つまたは複数の不揮発性メモリ装置は、持続性コンピュータ可読記憶媒体を含む。一部の実施形態では、メモリ５１２またはメモリ５１２のコンピュータ可読記憶媒体が、以下のプログラム、モジュール、およびデータ構造またはその一部を記憶する。
・ 様々な基本システムサービスを処理し、ハードウェア依存タスクを実行するためのプロシージャを含むオペレーティングシステム５１６。
・ 汎用サーバシステム１１２−Ｎを、１つまたは複数の通信ネットワークインターフェイス５０４（有線または無線）、およびインターネット、他の広域ネットワーク、ローカルエリアネットワーク、メトロポリタンエリアネットワークなどの１つまたは複数の通信ネットワークを介して他のコンピュータに接続するために使用するネットワーク通信モジュール５１８。
・ 特定のサーバシステムに固有の検索アプリケーション５２０であって、検索アプリケーション５２０は、例えばバーコード検索アプリケーション、色認識検索アプリケーション、製品認識検索アプリケーション、オブジェクトまたはオブジェクトカテゴリ検索アプリケーション等としてもよい。
・ 特定の検索アプリケーションが索引を利用する場合は、オプションの索引５２２。
・ 特定の検索アプリケーションに関連する画像を記憶するためのオプションの画像データベース５２４であって、記憶される画像データは、もしあれば、検索処理の種類に依拠する。
・ 検索アプリケーションからの結果にランク付けするためのオプションの結果ランク付けモジュール５２６（関連性スコアリングモジュールと呼ぶこともある）であって、このランク付けモジュールは、検索アプリケーションからの結果ごとに関連性スコアを割り当ててもよく、所定の最小スコアに達する結果がない場合、このサーバシステムの結果が関連しないことを示すヌルまたはゼロ値スコアをフロントエンド視覚クエリ処理サーバに返してもよい。
・ 注釈データベース（図１、１１６）から注釈情報を受け取り、注釈情報のいずれかが特定の検索アプリケーションに関連するかどうかを判定し、注釈情報のうちの決定した任意の関連部分をそれぞれの注釈データベース５３０内に取り入れるための注釈モジュール５２８。
FIG. 7 is a block diagram illustrating one of the parallel search systems utilized to process visual queries. FIG. 7 illustrates a “generic” server system 112-N according to one embodiment of the invention. This server system is general only in that it represents any one of the visual query search servers 112-N. The general purpose server system 112-N typically interconnects one or more processing units (CPUs) 502, one or more network interfaces or
An
General server system 112-N via one or more communication network interfaces 504 (wired or wireless) and one or more communication networks such as the Internet, other wide area networks, local area networks, metropolitan area networks, etc. A
A
An
An
An optional result ranking module 526 (sometimes referred to as a relevance scoring module) for ranking results from the search application, which ranks the relevance for each result from the search application. A score may be assigned and if no result reaches a predetermined minimum score, a null or zero value score may be returned to the front-end visual query processing server indicating that the results of this server system are not relevant.
Receives annotation information from the annotation database (FIG. 1, 116), determines whether any of the annotation information is related to a particular search application, and determines any determined relevant portion of the annotation information to the respective annotation database An
図８は、本発明の一実施形態による、視覚クエリを処理するために利用するＯＣＲ検索システム１１２−Ｂを示すブロック図である。ＯＣＲ検索システム１１２−Ｂは、典型的には１個または複数個の処理ユニット（ＣＰＵ）６０２、１つまたは複数のネットワークインターフェイスもしくは他の通信インターフェイス６０４、メモリ６１２、およびこれらのコンポーネントを相互接続するための１つまたは複数の通信バス６１４を含む。メモリ６１２には、ＤＲＡＭ、ＳＲＡＭ、ＤＤＲ ＲＡＭ、または他のランダムアクセス固体メモリデバイスなどの高速ランダムアクセスメモリが含まれ、１つまたは複数の磁気ディスク記憶装置、光学ディスク記憶装置、フラッシュメモリ装置、または他の不揮発性固体記憶デバイスなどの不揮発性メモリが含まれ得る。メモリ６１２には、１個または複数個のＣＰＵ６０２から離れて位置する１つまたは複数の記憶装置が場合により含まれ得る。メモリ６１２あるいはメモリ６１２内の１つまたは複数の不揮発性メモリ装置は、持続性コンピュータ可読記憶媒体を含む。一部の実施形態では、メモリ６１２またはメモリ６１２のコンピュータ可読記憶媒体が、以下のプログラム、モジュール、およびデータ構造またはその一部を記憶する。
・ 様々な基本システムサービスを処理し、ハードウェア依存タスクを実行するためのプロシージャを含むオペレーティングシステム６１６。
・ ＯＣＲ検索システム１１２−Ｂを、１つまたは複数の通信ネットワークインターフェイス６０４（有線または無線）、およびインターネット、他の広域ネットワーク、ローカルエリアネットワーク、メトロポリタンエリアネットワークなどの１つまたは複数の通信ネットワークを介して他のコンピュータに接続するために使用するネットワーク通信モジュール６１８。
・ 視覚クエリ内のテキストを認識しようと試み、文字画像を文字へと変換する光学的文字認識（ＯＣＲ）モジュール６２０。
・ ＯＣＲモジュール６２０が特定のフォント、テキストパターン、および文字認識に固有の他の特徴を認識するために利用する、オプションのＯＣＲデータベース１１４−Ｂ。
・ 変換された語を辞書と突き合わせて確認し、さもなければ辞書の語に一致する語の中のもしかしたら誤変換された文字を置換することにより、文字画像の文字への変換を改善するオプションのスペルチェックモジュール６２２。
・ 変換されたテキスト内で固有表現を探し、認識した固有表現を用語クエリ内の用語として用語クエリサーバシステム（図１、１１８）に送り、用語クエリサーバシステムからの結果を、認識した固有表現に関連するＯＣＲ済みテキスト内に埋め込まれたリンクとして提供する、オプションの固有表現認識モジュール６２４。
・ 変換されたセグメント（変換された文や段落など）をテキストセグメントのデータベースと突き合わせて確認し、さもなければテキスト一致アプリケーションのテキストセグメントに一致するＯＣＲ済みテキストセグメントの中のもしかしたら誤変換された文字を置換することにより、文字画像の文字への変換を改善するオプションのテキスト一致アプリケーション６３２であって、一部の実施形態では、テキスト一致アプリケーションが見つけるテキストセグメントがリンクとしてユーザに提供される（例えばユーザがNew York Timesの１ページをスキャンした場合、テキスト一致アプリケーションはNew York Timesのウェブサイト上に投稿されたすべての記事へのリンクを提供してもよい）。
・ ＯＣＲされた結果を提示するためにフォーマットし、固有表現へのオプションのリンクをフォーマットし、さらにテキスト一致アプリケーションからの関係する任意の結果を場合によりランク付けするための結果ランク付け／フォーマットモジュール６２６。
・ 注釈データベース（図１、１１６）から注釈情報を受け取り、注釈情報のいずれかがＯＣＲ検索システムに関連するかどうかを判定し、注釈情報のうちの決定した任意の関連部分をそれぞれの注釈データベース６３０内に取り入れるためのオプションの注釈モジュール６２８。
FIG. 8 is a block diagram illustrating an OCR search system 112-B utilized to process visual queries according to one embodiment of the present invention. The OCR search system 112-B typically interconnects one or more processing units (CPUs) 602, one or more network interfaces or
An operating system 616 that includes procedures for handling various basic system services and performing hardware dependent tasks.
OCR search system 112-B via one or more communication network interfaces 604 (wired or wireless) and one or more communication networks such as the Internet, other wide area networks, local area networks, metropolitan area networks, etc. A
An optical character recognition (OCR)
An optional OCR database 114-B that the
An option to improve the conversion of character images to characters by checking the converted words against the dictionary, or by replacing possibly misconverted characters in words that match the words in the dictionary
Search for the specific expression in the converted text, send the recognized specific expression as the term in the term query to the term query server system (FIG. 1, 118), and convert the result from the term query server system to the recognized specific expression An optional named
Check the converted segment (converted sentence, paragraph, etc.) against the text segment database, otherwise it was misconverted in the OCR text segment that matches the text segment of the text matching application An optional
A result ranking /
Receives annotation information from the annotation database (FIG. 1, 116), determines whether any of the annotation information is relevant to the OCR search system, and determines any relevant portion of the annotation information to the
図９は、本発明の一実施形態による、視覚クエリを処理するために利用する顔認識検索システム１１２−Ａを示すブロック図である。顔認識検索システム１１２−Ａは、典型的には１個または複数個の処理ユニット（ＣＰＵ）９０２、１つまたは複数のネットワークインターフェイスもしくは他の通信インターフェイス９０４、メモリ９１２、およびこれらのコンポーネントを相互接続するための１つまたは複数の通信バス９１４を含む。メモリ９１２には、ＤＲＡＭ、ＳＲＡＭ、ＤＤＲ ＲＡＭ、または他のランダムアクセス固体メモリデバイスなどの高速ランダムアクセスメモリが含まれ、１つまたは複数の磁気ディスク記憶装置、光学ディスク記憶装置、フラッシュメモリ装置、または他の不揮発性固体記憶デバイスなどの不揮発性メモリが含まれ得る。メモリ９１２には、１個または複数個のＣＰＵ９０２から離れて位置する１つまたは複数の記憶装置が場合により含まれ得る。メモリ９１２あるいはメモリ９１２内の１つまたは複数の不揮発性メモリ装置は、持続性コンピュータ可読記憶媒体を含む。一部の実施形態では、メモリ９１２またはメモリ９１２のコンピュータ可読記憶媒体が、以下のプログラム、モジュール、およびデータ構造またはその一部を記憶する。
・ 様々な基本システムサービスを処理し、ハードウェア依存タスクを実行するためのプロシージャを含むオペレーティングシステム９１６。
・ 顔認識検索システム１１２−Ａを、１つまたは複数の通信ネットワークインターフェイス９０４（有線または無線）、およびインターネット、他の広域ネットワーク、ローカルエリアネットワーク、メトロポリタンエリアネットワークなどの１つまたは複数の通信ネットワークを介して他のコンピュータに接続するために使用するネットワーク通信モジュール９１８。
・ 視覚クエリ内で提示される１つまたは複数の顔に一致する顔画像を顔画像データベース１１４−Ａ内で検索し、顔画像データベース１１４−Ａ内で見つかったそれぞれの一致に関連する情報を求めてソーシャルネットワークデータベース９２２を検索するための、顔認識検索アプリケーション９２０。
・ 複数のユーザの１つまたは複数の顔画像を記憶するための顔画像データベース１１４−Ａであって、場合によりこの顔画像データベースは、家族や、ユーザおよび顔画像データベース１１４−Ａ内に含まれる画像内にいると確認されている人物が知っている他者など、ユーザ以外の人物の顔画像を含み、場合によりこの顔画像データベースは、パブリックドメイン内で適法な顔画像の供給業者など、外部の情報源から得た顔画像を含む。
・ 場合により、図１２Ａに関してより詳細に論じるように、ソーシャルネットワークのユーザに関する名前、住所、職業、グループの帰属関係、ソーシャルネットワークのつながり、モバイル機器の現在のＧＰＳ位置、共有設定、関心、年齢、出身地、個人的統計、仕事情報などの情報を含む、ソーシャルネットワークデータベース９２２。
・ 顔画像データベース１１４−Ａからの潜在的な顔の一致をランク付けし（例えば、潜在的な顔の一致に関連性スコアおよび／または一致品質スコアを割り当て）、提示するために結果をフォーマットするための結果ランク付け／フォーマットモジュール９２４であって、一部の実施形態では、結果のランク付けまたはスコア付けに、前述のソーシャルネットワークデータベースから取得した関連情報を利用し、一部の実施形態では、フォーマットされた検索結果が、潜在的な画像の一致ならびにソーシャルネットワークデータベースからの情報の一部を含む。
・ 注釈データベース（図１、１１６）から注釈情報を受け取り、注釈情報のいずれかが顔認識検索システムに関連するかどうかを判定し、注釈情報のうちの決定した任意の関連部分をそれぞれの注釈データベース９２８内に記憶するための注釈モジュール９２６。
FIG. 9 is a block diagram illustrating a face recognition search system 112-A utilized to process a visual query, according to one embodiment of the present invention. The facial recognition search system 112-A typically interconnects one or more processing units (CPUs) 902, one or more network interfaces or
An
Face recognition and retrieval system 112-A through one or more communication network interfaces 904 (wired or wireless) and one or more communication networks such as the Internet, other wide area networks, local area networks, metropolitan area networks, etc. A
Search the face image database 114-A for face images that match one or more faces presented in the visual query and determine information related to each match found in the face image database 114-A. A face
A face image database 114-A for storing one or more face images of a plurality of users, and this face image database is optionally included in the family, user and face image database 114-A Contains face images of people other than the user, such as others known to the person identified as being in the image, and in some cases this face image database may be external, such as a legal face image supplier in the public domain Including face images obtained from information sources.
In some cases, as discussed in more detail with respect to FIG. 12A, the name, address, occupation, group membership, social network connection, current GPS location of the mobile device, sharing settings, interest, age, A
Rank potential face matches from face image database 114-A (eg assign relevance score and / or match quality score to potential face matches) and format the results for presentation A result ranking /
Receives annotation information from the annotation database (FIG. 1, 116), determines whether any of the annotation information is relevant to the face recognition search system, and determines any determined relevant portion of the annotation information to the respective annotation database An
図１０は、本発明の一実施形態による、視覚クエリを処理するために利用する画像−用語検索システム１１２−Ｃを示すブロック図である。一部の実施形態では、この画像−用語検索システムは視覚クエリ内のオブジェクトを認識する（インスタンス認識）。他の実施形態では、この画像−用語検索システムは視覚クエリ内のオブジェクトカテゴリを認識する（タイプ認識）。一部の実施形態では、この画像−用語システムは、オブジェクトおよびオブジェクトカテゴリの両方を認識する。この画像−用語検索システムは、視覚クエリ内の画像に関する潜在的な用語の一致を返す。画像−用語検索システム１１２−Ｃは、典型的には１個または複数個の処理ユニット（ＣＰＵ）１００２、１つまたは複数のネットワークインターフェイスもしくは他の通信インターフェイス１００４、メモリ１０１２、およびこれらのコンポーネントを相互接続するための１つまたは複数の通信バス１０１４を含む。メモリ１０１２には、ＤＲＡＭ、ＳＲＡＭ、ＤＤＲ ＲＡＭ、または他のランダムアクセス固体メモリデバイスなどの高速ランダムアクセスメモリが含まれ、１つまたは複数の磁気ディスク記憶装置、光学ディスク記憶装置、フラッシュメモリ装置、または他の不揮発性固体記憶デバイスなどの不揮発性メモリが含まれ得る。メモリ１０１２には、１個または複数個のＣＰＵ１００２から離れて位置する１つまたは複数の記憶装置が場合により含まれ得る。メモリ１０１２あるいはメモリ１０１２内の１つまたは複数の不揮発性メモリ装置は、持続性コンピュータ可読記憶媒体を含む。一部の実施形態では、メモリ１０１２またはメモリ１０１２のコンピュータ可読記憶媒体が、以下のプログラム、モジュール、およびデータ構造またはその一部を記憶する。
・ 様々な基本システムサービスを処理し、ハードウェア依存タスクを実行するためのプロシージャを含むオペレーティングシステム１０１６。
・ 画像−用語検索システム１１２−Ｃを、１つまたは複数の通信ネットワークインターフェイス１００４（有線または無線）、およびインターネット、他の広域ネットワーク、ローカルエリアネットワーク、メトロポリタンエリアネットワークなどの１つまたは複数の通信ネットワークを介して他のコンピュータに接続するために使用するネットワーク通信モジュール１０１８。
・ 画像検索データベース１１４−Ｃ内で、視覚クエリ内の１つまたは複数のサブジェクトに一致する画像を検索する、画像−用語検索アプリケーション１０２０。
・ 視覚クエリの１つまたは複数のサブジェクトに似た画像を探すために、検索アプリケーション１０２０によって検索され得る画像検索データベース１１４−Ｃ。
・ テキストベースクエリ検索エンジン１００６を使用して画像を検索する際にユーザが使用するテキスト用語を記憶する、用語−画像逆索引１０２２。
・ 潜在的な画像の一致をランク付けし、かつ／または用語−画像逆索引１０２２内で確認される、潜在的な画像の一致に関連する用語をランク付けするための、結果ランク付け／フォーマットモジュール１０２４。
・ 注釈データベース（図１、１１６）から注釈情報を受け取り、注釈情報のいずれかが画像−用語検索システム１１２−Ｃに関連するかどうかを判定し、注釈情報のうちの決定した任意の関連部分をそれぞれの注釈データベース１０２８内に記憶するための注釈モジュール１０２６。
FIG. 10 is a block diagram illustrating an image-term search system 112-C utilized to process a visual query according to one embodiment of the present invention. In some embodiments, the image-term search system recognizes objects in the visual query (instance recognition). In other embodiments, the image-term search system recognizes object categories in visual queries (type recognition). In some embodiments, the image-terminology system recognizes both objects and object categories. The image-term search system returns potential term matches for images in the visual query. Image-term search system 112-C typically includes one or more processing units (CPUs) 1002, one or more network or
An
Image-term search system 112-C with one or more communication network interfaces 1004 (wired or wireless) and one or more communication networks such as the Internet, other wide area networks, local area networks, metropolitan area networks, etc. A
An image-
An image search database 114-C that can be searched by the
A term-
A result ranking / formatting module for ranking potential image matches and / or ranking terms related to potential image matches identified in the term-
Receive annotation information from the annotation database (FIG. 1, 116), determine if any of the annotation information is relevant to the image-term search system 112-C, and determine any determined relevant portion of the annotation information An
図５〜図１０は、本明細書に記載の諸実施形態の構造上の概略図であるよりも、むしろ１組のコンピュータシステム内にあり得る様々な機能についての機能上の説明であることを意図する。実際には、および当業者によって理解されているように、別々に図示した項目を組み合わせることができ、一部の項目を分けてもよい。例えば、これらの図面の中で別々に示した一部の項目を単一のサーバ上に実装することができ、単一の項目を１つまたは複数のサーバによって実装することができる。視覚クエリの処理を実施するために使用するシステムの実際の数、およびそれらのシステム間でどのように機能を割り振るのかは実施形態ごとに異なる。 5-10 are functional descriptions of the various functions that may be within a set of computer systems, rather than structural schematics of the embodiments described herein. Intended. In practice, and as understood by those skilled in the art, the items illustrated separately may be combined, and some items may be separated. For example, some items shown separately in these drawings can be implemented on a single server, and a single item can be implemented by one or more servers. The actual number of systems used to perform the processing of visual queries, and how the functions are allocated among those systems will vary from embodiment to embodiment.
本明細書に記載の方法のそれぞれは、持続性コンピュータ可読記憶媒体の中に記憶され、１つまたは複数のサーバもしくはクライアントの１個または複数個のプロセッサによって実行される命令に準拠し得る。上記に特定したモジュールまたはプログラム（すなわち命令のセット）は、必ずしも別個のソフトウェアプログラム、プロシージャ、またはモジュールとして実装する必要はなく、よって様々な実施形態において、これらのモジュールの様々なサブセットを組み合わせ、またさもなければ再編成してもよい。図５〜図１０に示す操作のそれぞれは、コンピュータメモリまたは持続性コンピュータ可読記憶媒体の中に記憶される命令に対応し得る。 Each of the methods described herein may be compliant with instructions stored in a persistent computer readable storage medium and executed by one or more processors of one or more servers or clients. The modules or programs identified above (ie, the set of instructions) do not necessarily have to be implemented as separate software programs, procedures, or modules, and thus various embodiments combine various subsets of these modules, and Otherwise, it may be reorganized. Each of the operations illustrated in FIGS. 5-10 may correspond to instructions stored in computer memory or persistent computer readable storage media.
図１１は、例示的な視覚クエリ１１０２のスクリーンショットを有するクライアントシステム１０２を示す。図１１に示すクライアントシステム１０２は、携帯電話、携帯型音楽プレーヤ、携帯型電子メール装置などのモバイル機器である。クライアントシステム１０２は、ディスプレイ７０６、およびこの図面の中に示すボタンのような１つまたは複数の入力手段７０８を含む。一部の実施形態では、ディスプレイ７０６がタッチセンスディスプレイ７０９である。タッチセンスディスプレイ７０９を有する実施形態では、ディスプレイ７０９上に表示されるソフトボタンが電気機械的ボタン７０８の一部またはすべてを場合により置換してもよい。以下により詳細に説明するように、タッチセンスディスプレイは、視覚クエリの結果と対話する際にも役立つ。クライアントシステム１０２は、カメラ７１０などの画像取込機構も含む。
FIG. 11 shows a
図１１は、店の棚の上にあるパッケージの写真または映像フレームである視覚クエリ１１０２を示す。ここに記載する実施形態では、視覚クエリは、２つの次元のそれぞれにおいて視覚クエリのサイズに画素単位で対応する解像度を有する、二次元画像である。この例における視覚クエリ１１０２は、三次元オブジェクトの二次元画像である。視覚クエリ１１０２は、背景要素、製品パッケージ１１０４、ならびに人物の画像１１０６、商標の画像１１０８、製品の画像１１１０および様々なテキスト要素１１１２を含む、パッケージ上の様々な種類のエンティティを含む。
FIG. 11 shows a
図３に関して説明したように、視覚クエリ１１０２をフロントエンドサーバ１１０に送り、フロントエンドサーバ１１０は視覚クエリ１１０２を複数の並列検索システム（１１２Ａ〜Ｎ）に送り、結果を受け取って対話型結果ドキュメントを作成する。
As described with respect to FIG. 3, the
図１２Ａおよび図１２Ｂは、対話型結果ドキュメント１２００の一実施形態のスクリーンショットを有するクライアントシステム１０２をそれぞれ示す。対話型結果ドキュメント１２００は、視覚クエリ１１０２のそれぞれの副部分についての１つまたは複数の視覚的識別子１２０２を含み、その副部分は、検索結果の一部へのユーザ選択可能リンクをそれぞれ含む。図１２Ａおよび図１２Ｂは、境界ボックス１２０２（例えば境界ボックス１２０２−１、１２０２−２、１２０２−３）である視覚的識別子を有する対話型結果ドキュメント１２００を示す。図１２Ａおよび図１２Ｂに示す実施形態では、ユーザは、境界ボックス１２０２によって輪郭が描かれる空間内の活性化領域上でタップすることにより、特定の副部分に対応する検索結果の表示を活性化する。例えばユーザは、人物の画像を取り囲んでいる境界ボックス１３０６（図１３）上でタップすることにより、その人物の画像に対応する検索結果を活性化することになる。他の実施形態では、タッチセンスディスプレイではなく、マウスまたはキーボードを使用して選択可能リンクを選択する。一部の実施形態では、ユーザが境界ボックス１２０２をプレビューするとき（すなわちユーザが境界ボックス上でシングルクリックし、一度タップし、またはポインタを乗せるとき）、第１の対応する検索結果を表示する。ユーザがその境界ボックスを選択するとき（すなわちユーザがダブルクリックし、二度タップし、または別の機構を使用して選択したことを示すとき）、そのユーザは複数の対応する検索結果の表示を活性化する。
FIGS. 12A and 12B show
図１２Ａおよび図１２Ｂでは、視覚的識別子は、視覚クエリの副部分を取り囲んでいる境界ボックス１２０２である。図１２Ａは、正方形または長方形の境界ボックス１２０２を示す。図１２Ｂは、ドリンクボトルの境界ボックス１２０２−３など、視覚クエリの副部分内の特定可能エンティティの境界の輪郭を描く境界ボックス１２０２を示す。一部の実施形態では、それぞれの境界ボックス１２０２が、その中により小さな境界ボックス１２０２を含む。例えば、図１２Ａおよび図１２Ｂでは、パッケージを識別する境界ボックス１２０２−１が、商標を識別する境界ボックス１２０２−２および残りの境界ボックス１２０２のすべてを取り囲む。テキストを含む一部の実施形態では、テキスト用語の一部のためのアクティブホットリンク１２０４も含まれる。図１２Ｂは、「Active Drink」および「United States」がホットリンク１２０４として表示されている一例を示す。これらの用語に対応する検索結果は、用語クエリサーバシステム１１８から受け取る結果であるのに対し、境界ボックスに対応する結果は、画像によるクエリ検索システムからの結果である。
In FIGS. 12A and 12B, the visual identifier is a
図１３は、視覚クエリ内で認識されたエンティティのタイプごとにコード化された対話型結果ドキュメント１２００のスクリーンショットを有するクライアントシステム１０２を示す。図１１の視覚クエリは、人物の画像１１０６、商標の画像１１０８、製品の画像１１１０、および様々なテキスト要素１１１２を含む。そのため、図１３内に表示される対話型結果ドキュメント１２００は、人物１３０６、商標１３０８、製品１３１０、および２つのテキスト領域１３１２を取り囲む複数の境界ボックス１２０２を含む。図１３の境界ボックスは、各様に特色を与えられた透明な境界ボックス１２０２を表す別個のクロスハッチングを使ってそれぞれ提示する。一部の実施形態では、オーバーレイの色、オーバーレイパターン、ラベルの背景色、ラベルの背景パターン、ラベルのフォントの色、境界ボックスの枠線色など、視覚的に区別できる方法で提示するために境界ボックスの視覚的識別子（および／または対話型結果ドキュメント１２００内のラベルもしくは他の視覚的識別子）をフォーマットする。認識される特定のエンティティについてのタイプコード化を図１３の境界ボックスに関して図示するが、タイプごとのコード化は、ラベルである視覚的識別子にも適用することができる。
FIG. 13 shows a
図１４は、ラベル１４０２が図１１の視覚クエリ１１０２のそれぞれの副部分の視覚的識別子である、対話型結果ドキュメント１２００のスクリーンショットを有するクライアント装置１０２を示す。ラベルの視覚的識別子１４０２は、対応する検索結果の一部へのユーザ選択可能リンクをそれぞれ含む。一部の実施形態では、その選択可能リンクは、ラベル１４０２の領域内に表示される説明的テキストによって識別される。一部の実施形態は、１つのラベル１４０２の中に複数のリンクを含む。例えば図１４では、飲み物を飲んでいる女性の上にあるラベルが、その女性に関する顔認識の結果へのリンクと、その特定の写真に関する画像認識の結果（例えば同じ写真を使用する他の製品や広告の画像）へのリンクとを含む。
FIG. 14 shows the
図１４では、ラベル１４０２が、対話型結果ドキュメントのそれぞれの副部分上に位置する、テキストを有する部分的に透明な領域として表示される。他の実施形態では、それぞれのラベルが、対話型結果ドキュメントのそれぞれの副部分上には位置しないが、その付近に配置される。一部の実施形態では、図１３に関して論じたのと同じ方法でラベルをタイプごとにコード化する。一部の実施形態では、ユーザは、ラベル１３０２の縁または外周縁によって輪郭が描かれる空間内の活性化領域上でタップすることにより、ラベル１３０２に対応する特定の副部分に対応する検索結果の表示を活性化する。図１２Ａおよび図１２Ｂの境界ボックスに関して上記で論じたのと同じプレビュー機能および選択機能が、ラベルである視覚的識別子１４０２にも当てはまる。
In FIG. 14, the
図１５は、結果一覧１５００と同時に表示される対話型結果ドキュメント１２００および元の視覚クエリ１１０２のスクリーンショットを示す。図１２〜図１４に示すように、一部の実施形態では対話型結果ドキュメント１２００を単独で表示する。図１５に示すように、他の実施形態では対話型結果ドキュメント１２００を元の視覚クエリと同時に表示する。一部の実施形態では、視覚クエリの結果一覧１５００を、元の視覚クエリ１１０２および／または対話型結果ドキュメント１２００とともに同時に表示する。結果一覧１５００を対話型結果ドキュメント１２００と同時に表示するかどうかは、クライアントシステムの種類およびディスプレイ７０６上の空間量によって決まり得る。一部の実施形態では、クライアントシステム１０２は、（視覚クエリサーバシステムにサブミットする視覚クエリに応答して）結果一覧１５００および対話型結果ドキュメント１２００の両方を受け取るが、ユーザが対話型結果ドキュメント１２００の下方にスクロールする場合、結果一覧１５００だけを表示する。クライアントシステム１０２は、視覚クエリに応答して結果一覧１５００を受け取り、クライアントシステム１０２において局所的に記憶するので、これらの実施形態の一部では、クライアントシステム１０２は、ユーザが選択する視覚的識別子１２０２／１４０２に対応する結果を再度サーバにクエリする必要なしに表示する。
FIG. 15 shows a screenshot of the interactive results document 1200 and the original
一部の実施形態では、結果一覧１５００を複数のカテゴリ１５０２へと編成する。各カテゴリは少なくとも１つの結果１５０３を含む。一部の実施形態では、結果１５０３と区別するためにカテゴリのタイトルを強調表示する。カテゴリ１５０２は、その計算されたカテゴリウェイトに応じて順序付けられる。一部の実施形態では、カテゴリウェイトは、そのカテゴリ内の最上位のＮ個の結果の重みの組合せである。そのため、より関連性のある結果をもたらした可能性が高いカテゴリを最初に表示する。認識された同一エンティティについて複数のカテゴリ１５０２（図１５に示す顔画像認識の一致および画像の一致など）が返される実施形態では、最初に表示されるカテゴリがより高いカテゴリウェイトを有する。
In some embodiments, the results list 1500 is organized into
図３に関して説明したように、一部の実施形態では、クライアントシステム１０２のユーザが対話型結果ドキュメント１２００内の選択可能リンクを選択すると、カーソルが適切なカテゴリ１５０２またはそのカテゴリ内の最初の結果１５０３に自動的に移動する。あるいは、クライアントシステム１０２のユーザが対話型結果ドキュメント内の選択可能リンクを選択すると、選択されたリンクに関連する１つまたは複数のカテゴリが最初に表示されるように、結果一覧１５００が並べ替えられる。これは、例えば対応する検索結果を識別する情報を使って選択可能リンクをコード化することにより、または対応する選択可能リンクを示すように、もしくは対応する結果カテゴリを示すように検索結果をコード化することによって達成される。
As described with respect to FIG. 3, in some embodiments, when the user of the
一部の実施形態では、検索結果のカテゴリが、それらの検索結果をもたらす画像によるクエリ検索システムに対応する。例えば図１５では、カテゴリの一部は、製品の一致１５０６、ロゴの一致１５０８、顔認識の一致１５１０、画像の一致１５１２である。元の視覚クエリ１１０２および／または対話型結果ドキュメント１２００も、クエリ１５０４などのカテゴリタイトルにより同様に表示してもよい。同様に、用語クエリサーバが行う任意の用語検索の結果も、ウェブの結果１５１４などの別個のカテゴリとして表示してもよい。他の実施形態では、視覚クエリ内の複数のエンティティが、同じ画像によるクエリ検索システムからの結果をもたらす。例えば視覚クエリは、顔認識検索システムからの別個の結果を返すことになる２つの異なる顔を含むことができる。そのため一部の実施形態では、カテゴリ１５０２を、検索システムごとにではなく、認識するエンティティごとに分ける。一部の実施形態では、認識したエンティティの画像を認識エンティティカテゴリヘッダ１５０２の中に表示し、それにより、たとえ両方の結果が同じ画像によるクエリ検索システムによってもたらされても、認識したそのエンティティの結果を認識した別のエンティティの結果と区別することができる。例えば図１５では、製品の一致カテゴリ１５０６が２つのエンティティ製品のエンティティを含み、そのため、それぞれが複数の対応する検索結果１５０３を有する、箱入りの製品１５１６およびボトル入りの製品１５１８である２つのエンティティカテゴリ１５０２を含む。一部の実施形態では、カテゴリを、認識するエンティティおよび画像によるクエリシステムの種類ごとに分けることができる。例えば図１５では、製品の一致カテゴリの製品の下で、関連する結果を返した２つの別個のエンティティがある。
In some embodiments, the search result categories correspond to image-based query search systems that yield those search results. For example, in FIG. 15, some of the categories are a
一部の実施形態では、結果１５０３がサムネイル画像を含む。例えば、図１５の顔認識の一致結果について示すように、「女優Ｘ」および「ソーシャルネットワークの友人Ｙ」に関する顔の一致写真の小さなバージョン（サムネイル画像とも呼ぶ）が、その画像内の人物の名前などの何らかのテキスト記述とともに表示される。
In some embodiments, the
上記の記載は、説明目的で特定の実施形態に関して記載してきた。しかし上記の実例的な解説は、網羅的であることも本発明を開示した厳密な形態に限定することも意図しない。上記の教示に照らし、多くの修正形態および改変形態があり得る。本発明の原理およびその実用的応用を最も良く説明して、それにより当業者が本発明、および考えられる特定の用法に適合される様々な修正が加えられる様々な実施形態を最も良く利用できるようにするために実施形態を選択して説明した。 The above description has been given with reference to specific embodiments for illustrative purposes. However, the illustrative illustrations above are not intended to be exhaustive or to limit the invention to the precise forms disclosed. Many modifications and variations are possible in light of the above teaching. The principles of the present invention and their practical application are best described so that those skilled in the art can best utilize the various embodiments in which various modifications are made that are adapted to the present invention and the particular use contemplated. In order to achieve this, the embodiment has been selected and described.
１００……コンピュータネットワーク
１０２……クライアントシステム
１０４……通信ネットワーク
１１０……フロントエンド視覚クエリ処理サーバ
１１６……クエリ／注釈データベース
１１８……用語クエリサーバシステム
DESCRIPTION OF
Claims (21)
複数の画像検索コンポーネントに前記クエリ画像を提供するステップであって、前記クエリ画像がサブミットされる各画像検索コンポーネントについて、前記画像検索コンポーネントは、前記画像検索コンポーネントに固有の画像ベースの検索プロセスに前記クエリ画像の少なくともそれぞれの部分を適用することにより、前記画像検索コンポーネントに関連付けられたリソース群の中から、前記クエリ画像に一致するゼロ以上のリソースを識別するように構成される、ステップと、
前記クエリ画像の１つまたは複数の副部分であって、各々が特定のタイプに対応する副部分を識別するステップと、
各副部分について、前記クエリ画像の前記副部分が前記特定のタイプに対応することの信頼水準を示す信頼値を決定するステップと、
各副部分について、前記副部分に関連付けられた、前記複数の画像検索コンポーネントのうちの特定の画像検索コンポーネントに、前記副部分と前記対応する信頼値とを提供するステップと、
前記クエリ画像に一致すると前記複数の画像検索コンポーネントが識別するリソースのセットを取得するステップと、
前記クエリ画像に一致すると前記複数の画像検索コンポーネントが識別する前記リソースのセットのサブセットを選択するステップと、
出力のため、前記クエリ画像に一致すると前記複数の画像検索コンポーネントが識別する前記リソースのサブセットのうちの１つまたは複数のリソースを識別するデータを提供するステップと、
を含む、コンピュータによって実施される方法。 Receiving a query image;
Providing the query image to a plurality of image search components, wherein for each image search component to which the query image is submitted, the image search component performs an image-based search process specific to the image search component; Configured to identify zero or more resources that match the query image from among resources associated with the image search component by applying at least respective portions of the query image;
Identifying one or more sub-portions of the query image, each sub-portion corresponding to a particular type;
For each sub-portion, determining a confidence value indicating a confidence level that the sub-portion of the query image corresponds to the particular type;
Providing, for each sub-portion, the sub-portion and the corresponding confidence value to a particular image search component of the plurality of image search components associated with the sub-portion;
Obtaining a set of resources that the plurality of image search components identify as matching the query image;
Selecting a subset of the set of resources that the plurality of image search components identify as matching the query image;
Providing data identifying, for output, one or more resources of the subset of resources that the plurality of image search components identify as matching the query image;
A computer-implemented method comprising:
前記クエリ画像の前記１つまたは複数のテキスト要素を用語クエリ検索コンポーネントに提供するステップと、
前記クエリ画像の前記１つまたは複数のテキスト要素を前記用語クエリ検索コンポーネントに提供するステップに応じて、前記クエリ画像の前記１つまたは複数のテキスト要素に基づく、前記用語クエリ検索コンポーネントからの１つまたは複数の結果を取得するステップと、
前記用語クエリ検索コンポーネントからの前記１つまたは複数の結果を用いて、前記クエリ画像に一致すると前記複数の画像検索コンポーネントが識別する前記リソースのサブセットのうちの前記１つまたは複数のリソースを識別する前記データを増補するステップと、
をさらに含む、請求項１に記載のコンピュータによって実施される方法。 Identifying one or more text elements of the query image;
Providing the one or more text elements of the query image to a term query search component;
One from the term query search component based on the one or more text elements of the query image in response to providing the one or more text elements of the query image to the term query search component Or obtaining multiple results;
The one or more results from the term query search component are used to identify the one or more resources of the subset of resources that the plurality of image search components identify as matching the query image. Augmenting the data;
The computer-implemented method of claim 1, further comprising:
前記クエリ画像が前記認識可能パターンを含む前記確率を閾値と比較するステップと、
前記クエリ画像が前記認識可能パターンを含む前記確率を前記閾値と比較するステップに基づいて、前記確率が前記閾値より大きいと判断するステップと、
前記確率が前記閾値より大きいと判断するステップに基づいて、前記パターンに関連付けられた、前記複数の画像検索コンポーネントのうちの特定の画像検索コンポーネントに前記クエリ画像を提供するステップと、
をさらに含む、請求項１に記載のコンピュータによって実施される方法。 Identifying the probability that the query image includes a recognizable pattern;
Comparing the probability that the query image includes the recognizable pattern with a threshold;
Determining that the probability is greater than the threshold based on comparing the probability that the query image includes the recognizable pattern with the threshold;
Providing the query image to a particular image search component of the plurality of image search components associated with the pattern based on determining that the probability is greater than the threshold;
The computer-implemented method of claim 1, further comprising:
前記クエリ画像を提供するユーザに前記特定のタイプのパターンを提供するステップと、
前記ユーザから、前記クエリ画像が前記特定のタイプのパターンに関連付けられているとの表示を受け取るステップと、
前記クエリ画像が前記特定のタイプのパターンに関連付けられているとの前記表示を受け取るステップに基づいて、前記特定のタイプに関連付けられた、前記複数の画像検索コンポーネントのうちの前記特定の画像検索コンポーネントに前記クエリ画像を提供するステップと、
をさらに含む、請求項３に記載のコンピュータによって実施される方法。 The recognizable pattern is a specific type of pattern and the method comprises:
Providing the particular type of pattern to a user providing the query image;
Receiving from the user an indication that the query image is associated with the particular type of pattern;
The specific image search component of the plurality of image search components associated with the specific type based on receiving the indication that the query image is associated with the specific type of pattern Providing the query image to:
The computer-implemented method of claim 3, further comprising:
ユーザから、前記クエリ画像が特定のタイプの画像に関連付けられるとの表示を受け取るステップと、
前記特定のタイプの画像に関連付けられたリソースのみを含むように、前記リソースのサブセットをフィルタにかけるステップと、
をさらに含む、請求項１に記載のコンピュータによって実施される方法。 Selecting the subset of the set of resources that the plurality of image search components identify as matching the query image comprises:
Receiving from the user an indication that the query image is associated with a particular type of image;
Filtering the subset of resources to include only resources associated with the particular type of image;
The computer-implemented method of claim 1, further comprising:
１つまたは複数の記憶装置であって、前記１つまたは複数のコンピュータによって実行されると、前記１つまたは複数のコンピュータに、
クエリ画像を受け取ることと、
複数の画像検索コンポーネントに前記クエリ画像を提供することであって、前記クエリ画像がサブミットされる各画像検索コンポーネントについて、前記画像検索コンポーネントは、前記画像検索コンポーネントに固有の画像ベースの検索プロセスに前記クエリ画像の少なくともそれぞれの部分を適用することにより、前記画像検索コンポーネントに関連付けられたリソース群の中から、前記クエリ画像に一致するゼロ以上のリソースを識別するように構成される、ことと、
前記クエリ画像の１つまたは複数の副部分であって、各々が特定のタイプに対応する副部分を識別する、ことと、
各副部分について、前記クエリ画像の前記副部分が前記特定のタイプに対応することの信頼水準を示す信頼値を決定する、ことと、
各副部分について、前記副部分に関連付けられた、前記複数の画像検索コンポーネントのうちの特定の画像検索コンポーネントに、前記副部分と前記対応する信頼値とを提供する、ことと、
前記クエリ画像に一致すると前記複数の画像検索コンポーネントが識別するリソースのセットを取得することと、
前記クエリ画像に一致すると前記複数の画像検索コンポーネントが識別する前記リソースのセットのサブセットを選択することと、
出力のため、前記クエリ画像に一致すると前記複数の画像検索コンポーネントが識別する前記リソースのサブセットのうちの１つまたは複数のリソースを識別するデータを提供することと、
を含む動作を行わせるように動作可能な命令を記憶する１つまたは複数の記憶装置と、
を備えるシステム。 One or more computers;
One or more storage devices, when executed by the one or more computers, the one or more computers,
Receiving a query image,
Providing the query image to a plurality of image search components, wherein for each image search component to which the query image is submitted, the image search component performs an image-based search process specific to the image search component; Being configured to identify zero or more resources that match the query image from among resources associated with the image search component by applying at least a respective portion of the query image;
Identifying one or more sub-portions of the query image, each sub-portion corresponding to a particular type;
For each sub-portion, determining a confidence value indicating a confidence level that the sub-portion of the query image corresponds to the specific type;
Providing, for each sub-portion, the sub-portion and the corresponding confidence value to a particular image search component of the plurality of image search components associated with the sub-portion;
Obtaining a set of resources that the plurality of image search components identify as matching the query image;
Selecting a subset of the set of resources that the plurality of image search components identify as matching the query image;
Providing data identifying, for output, one or more resources of the subset of resources that the plurality of image search components identify as matching the query image;
One or more storage devices that store instructions operable to perform operations comprising:
A system comprising:
前記クエリ画像の１つまたは複数のテキスト要素を識別することと、
前記クエリ画像の前記１つまたは複数のテキスト要素を用語クエリ検索コンポーネントに提供することと、
前記クエリ画像の前記１つまたは複数のテキスト要素を前記用語クエリ検索コンポーネントに提供することに応じて、前記クエリ画像の前記１つまたは複数のテキスト要素に基づく、前記用語クエリ検索コンポーネントからの１つまたは複数の結果を取得することと、
前記用語クエリ検索コンポーネントからの前記１つまたは複数の結果を用いて、前記クエリ画像に一致すると前記複数の画像検索コンポーネントが識別する前記リソースのサブセットのうちの前記１つまたは複数のリソースを識別する前記データを増補することと、
をさらに含む、請求項８に記載のシステム。 The operation is
Identifying one or more text elements of the query image;
Providing the one or more text elements of the query image to a term query search component;
One from the term query search component based on the one or more text elements of the query image in response to providing the one or more text elements of the query image to the term query search component Or getting multiple results,
The one or more results from the term query search component are used to identify the one or more resources of the subset of resources that the plurality of image search components identify as matching the query image. Augmenting the data;
The system of claim 8, further comprising:
前記クエリ画像が認識可能パターンを含む確率を識別することと、
前記クエリ画像が前記認識可能パターンを含む前記確率を閾値と比較することと、
前記クエリ画像が前記認識可能パターンを含む前記確率を前記閾値と比較することに基づいて、前記確率が前記閾値より大きいと判断することと、
前記確率が前記閾値より大きいと判断することに基づいて、前記パターンに関連付けられた、前記複数の画像検索コンポーネントのうちの特定の画像検索コンポーネントに前記クエリ画像を提供することと、
をさらに含む、請求項８に記載のシステム。 The operation is
Identifying the probability that the query image includes a recognizable pattern;
Comparing the probability that the query image includes the recognizable pattern to a threshold;
Determining that the probability is greater than the threshold based on comparing the probability that the query image includes the recognizable pattern with the threshold;
Providing the query image to a particular image search component of the plurality of image search components associated with the pattern based on determining that the probability is greater than the threshold;
The system of claim 8, further comprising:
前記クエリ画像を提供するユーザに前記特定のタイプのパターンを提供することと、
前記ユーザから、前記クエリ画像が前記特定のタイプのパターンに関連付けられているとの表示を受け取ることと、
前記クエリ画像が前記特定のタイプのパターンに関連付けられているとの前記表示を受け取ることに基づいて、前記特定のタイプに関連付けられた、前記複数の画像検索コンポーネントのうちの前記特定の画像検索コンポーネントに前記クエリ画像を提供することと、
をさらに含む、請求項１０に記載のシステム。 The recognizable pattern is a specific type of pattern, and the action is
Providing the particular type of pattern to a user providing the query image;
Receiving an indication from the user that the query image is associated with the particular type of pattern;
The specific image search component of the plurality of image search components associated with the specific type based on receiving the indication that the query image is associated with the specific type of pattern Providing the query image to:
The system of claim 10, further comprising:
ユーザから、前記クエリ画像が特定のタイプの画像に関連付けられるとの表示を受け取る、ことと、
前記特定のタイプの画像に関連付けられたリソースのみを含むように、前記リソースのサブセットをフィルタにかける、ことと、
をさらに含む、請求項８に記載のシステム。 Selecting the subset of the set of resources that the plurality of image search components identify as matching the query image;
Receiving an indication from a user that the query image is associated with a particular type of image;
Filtering the subset of resources to include only resources associated with the particular type of image;
The system of claim 8, further comprising:
クエリ画像を受け取ることと、
複数の画像検索コンポーネントに前記クエリ画像を提供することであって、前記クエリ画像がサブミットされる各画像検索コンポーネントについて、前記画像検索コンポーネントは、前記画像検索コンポーネントに固有の画像ベースの検索プロセスに前記クエリ画像の少なくともそれぞれの部分を適用することにより、前記画像検索コンポーネントに関連付けられたリソース群の中から、前記クエリ画像に一致するゼロ以上のリソースを識別するように構成される、ことと、
前記クエリ画像の１つまたは複数の副部分であって、各々が特定のタイプに対応する副部分を識別する、ことと、
各副部分について、前記クエリ画像の前記副部分が前記特定のタイプに対応することの信頼水準を示す信頼値を決定する、ことと、
各副部分について、前記副部分に関連付けられた、前記複数の画像検索コンポーネントのうちの特定の画像検索コンポーネントに、前記副部分と前記対応する信頼値とを提供する、ことと、
前記クエリ画像に一致すると前記複数の画像検索コンポーネントが識別するリソースのセットを取得することと、
前記クエリ画像に一致すると前記複数の画像検索コンポーネントが識別する前記リソースのセットのサブセットを選択することと、
出力のため、前記クエリ画像に一致すると前記複数の画像検索コンポーネントが識別する前記リソースのサブセットのうちの１つまたは複数のリソースを識別するデータを提供することと、
を含む動作を行わせる、コンピュータ可読媒体。 A computer readable medium storing software including instructions executable by one or more computers, wherein the instructions are stored in the one or more computers during such execution.
Receiving a query image,
Providing the query image to a plurality of image search components, wherein for each image search component to which the query image is submitted, the image search component performs an image-based search process specific to the image search component; Being configured to identify zero or more resources that match the query image from among resources associated with the image search component by applying at least a respective portion of the query image;
Identifying one or more sub-portions of the query image, each sub-portion corresponding to a particular type;
For each sub-portion, determining a confidence value indicating a confidence level that the sub-portion of the query image corresponds to the specific type;
Providing, for each sub-portion, the sub-portion and the corresponding confidence value to a particular image search component of the plurality of image search components associated with the sub-portion;
Obtaining a set of resources that the plurality of image search components identify as matching the query image;
Selecting a subset of the set of resources that the plurality of image search components identify as matching the query image;
Providing data identifying, for output, one or more resources of the subset of resources that the plurality of image search components identify as matching the query image;
A computer-readable medium for performing an operation including:
前記クエリ画像の１つまたは複数のテキスト要素を識別することと、
前記クエリ画像の前記１つまたは複数のテキスト要素を用語クエリ検索コンポーネント
に提供することと、
前記クエリ画像の前記１つまたは複数のテキスト要素を前記用語クエリ検索コンポーネントに提供することに応じて、前記クエリ画像の前記１つまたは複数のテキスト要素に基づく、前記用語クエリ検索コンポーネントからの１つまたは複数の結果を取得することと、
前記用語クエリ検索コンポーネントからの前記１つまたは複数の結果を用いて、前記クエリ画像に一致すると前記複数の画像検索コンポーネントが識別する前記リソースのサブセットのうちの前記１つまたは複数のリソースを識別する前記データを増補することと、
をさらに含む、請求項１５に記載のコンピュータ可読媒体。 The operation is
Identifying one or more text elements of the query image;
Providing the one or more text elements of the query image to a term query search component;
One from the term query search component based on the one or more text elements of the query image in response to providing the one or more text elements of the query image to the term query search component Or getting multiple results,
The one or more results from the term query search component are used to identify the one or more resources of the subset of resources that the plurality of image search components identify as matching the query image. Augmenting the data;
The computer readable medium of claim 15, further comprising:
前記クエリ画像が前記認識可能パターンを含む前記確率を閾値と比較する、ことと、
前記確率を比較することに基づいて、前記確率が前記閾値より大きいと判断する、ことと、
前記確率が前記閾値より大きいと判断することに基づいて、前記パターンに関連付けられた、前記複数の画像検索コンポーネントのうちの特定の画像検索コンポーネントに前記クエリ画像を提供する、ことと、
をさらに含む、請求項１５に記載のコンピュータ可読媒体。 Identifying the probability that the query image includes a recognizable pattern;
Comparing the probability that the query image includes the recognizable pattern to a threshold;
Determining that the probability is greater than the threshold based on comparing the probabilities;
Providing the query image to a particular image search component of the plurality of image search components associated with the pattern based on determining that the probability is greater than the threshold;
The computer readable medium of claim 15, further comprising:
前記クエリ画像を提供するユーザに前記特定のタイプのパターンを提供する、ことと、
前記ユーザから、前記クエリ画像が前記特定のタイプのパターンに関連付けられているとの表示を受け取る、ことと、
前記クエリ画像が前記特定のタイプのパターンに関連付けられているとの前記表示を受け取ることに基づいて、前記特定のタイプに関連付けられた、前記複数の画像検索コンポーネントのうちの前記特定の画像検索コンポーネントに前記クエリ画像を提供する、ことと、
をさらに含む、請求項１７に記載のコンピュータ可読媒体。 The recognizable pattern is a specific type of pattern, and the action is
Providing the particular type of pattern to a user providing the query image;
Receiving an indication from the user that the query image is associated with the particular type of pattern;
The specific image search component of the plurality of image search components associated with the specific type based on receiving the indication that the query image is associated with the specific type of pattern Providing the query image to,
The computer-readable medium of claim 17, further comprising:
ユーザから、前記クエリ画像が特定のタイプの画像に関連付けられるとの表示を受け取る、ことと、
前記特定のタイプの画像に関連付けられたリソースのみを含むように、前記リソースのサブセットをフィルタにかける、ことと、
をさらに含む、請求項１５に記載のコンピュータ可読媒体。 Selecting the subset of the set of resources that the plurality of image search components identify as matching the query image;
Receiving an indication from a user that the query image is associated with a particular type of image;
Filtering the subset of resources to include only resources associated with the particular type of image;
The computer readable medium of claim 15, further comprising:
Applications Claiming Priority (6)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US23239709P | 2009-08-07 | 2009-08-07 | |
US61/232,397 | 2009-08-07 | ||
US26611609P | 2009-12-02 | 2009-12-02 | |
US61/266,116 | 2009-12-02 | ||
US12/850,483 | 2010-08-04 | ||
US12/850,483 US9135277B2 (en) | 2009-08-07 | 2010-08-04 | Architecture for responding to a visual query |
Related Parent Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2014254872A Division JP5933677B2 (en) | 2009-08-07 | 2014-12-17 | Architecture for responding to visual queries |
Publications (2)
Publication Number | Publication Date |
---|---|
JP2016139424A true JP2016139424A (en) | 2016-08-04 |
JP6148367B2 JP6148367B2 (en) | 2017-06-14 |
Family
ID=42752283
Family Applications (3)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2012523960A Pending JP2013501975A (en) | 2009-08-07 | 2010-08-05 | Architecture for responding to visual queries |
JP2014254872A Active JP5933677B2 (en) | 2009-08-07 | 2014-12-17 | Architecture for responding to visual queries |
JP2016050616A Active JP6148367B2 (en) | 2009-08-07 | 2016-03-15 | Architecture for responding to visual queries |
Family Applications Before (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2012523960A Pending JP2013501975A (en) | 2009-08-07 | 2010-08-05 | Architecture for responding to visual queries |
JP2014254872A Active JP5933677B2 (en) | 2009-08-07 | 2014-12-17 | Architecture for responding to visual queries |
Country Status (9)
Country | Link |
---|---|
US (3) | US9135277B2 (en) |
EP (1) | EP2462520B1 (en) |
JP (3) | JP2013501975A (en) |
KR (2) | KR101667346B1 (en) |
CN (1) | CN102625937B (en) |
AU (2) | AU2010279333B2 (en) |
BR (1) | BR112012002815B8 (en) |
CA (2) | CA3068761C (en) |
WO (1) | WO2011017557A1 (en) |
Families Citing this family (185)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20090327235A1 (en) * | 2008-06-27 | 2009-12-31 | Google Inc. | Presenting references with answers in forums |
US8463053B1 (en) | 2008-08-08 | 2013-06-11 | The Research Foundation Of State University Of New York | Enhanced max margin learning on multimodal data mining in a multimedia database |
US9135277B2 (en) | 2009-08-07 | 2015-09-15 | Google Inc. | Architecture for responding to a visual query |
EP2629211A1 (en) * | 2009-08-21 | 2013-08-21 | Mikko Kalervo Väänänen | Method and means for data searching and language translation |
US8121618B2 (en) | 2009-10-28 | 2012-02-21 | Digimarc Corporation | Intuitive computing methods and systems |
US9197736B2 (en) | 2009-12-31 | 2015-11-24 | Digimarc Corporation | Intuitive computing methods and systems |
US9176986B2 (en) | 2009-12-02 | 2015-11-03 | Google Inc. | Generating a combination of a visual query and matching canonical document |
US9405772B2 (en) | 2009-12-02 | 2016-08-02 | Google Inc. | Actionable search results for street view visual queries |
US9852156B2 (en) | 2009-12-03 | 2017-12-26 | Google Inc. | Hybrid use of location sensor data and visual query to return local listings for visual query |
WO2011082332A1 (en) | 2009-12-31 | 2011-07-07 | Digimarc Corporation | Methods and arrangements employing sensor-equipped smart phones |
US8600173B2 (en) * | 2010-01-27 | 2013-12-03 | Dst Technologies, Inc. | Contextualization of machine indeterminable information based on machine determinable information |
WO2012050251A1 (en) * | 2010-10-14 | 2012-04-19 | 엘지전자 주식회사 | Mobile terminal and method for controlling same |
US8861896B2 (en) * | 2010-11-29 | 2014-10-14 | Sap Se | Method and system for image-based identification |
US9196028B2 (en) | 2011-09-23 | 2015-11-24 | Digimarc Corporation | Context-based smartphone sensor logic |
US8995775B2 (en) * | 2011-05-02 | 2015-03-31 | Facebook, Inc. | Reducing photo-tagging spam |
JP5316582B2 (en) * | 2011-05-23 | 2013-10-16 | コニカミノルタ株式会社 | Image processing system, image processing device, terminal device, and control program |
EP2533141A1 (en) * | 2011-06-07 | 2012-12-12 | Amadeus S.A.S. | A personal information display system and associated method |
JP5830784B2 (en) * | 2011-06-23 | 2015-12-09 | サイバーアイ・エンタテインメント株式会社 | Interest graph collection system by relevance search with image recognition system |
KR101814120B1 (en) * | 2011-08-26 | 2018-01-03 | 에스프린팅솔루션 주식회사 | Method and apparatus for inserting image to electrical document |
US8890827B1 (en) | 2011-10-05 | 2014-11-18 | Google Inc. | Selected content refinement mechanisms |
US10013152B2 (en) | 2011-10-05 | 2018-07-03 | Google Llc | Content selection disambiguation |
US8825671B1 (en) * | 2011-10-05 | 2014-09-02 | Google Inc. | Referent determination from selected content |
US9652556B2 (en) | 2011-10-05 | 2017-05-16 | Google Inc. | Search suggestions based on viewport content |
US8878785B1 (en) | 2011-10-05 | 2014-11-04 | Google Inc. | Intent determination using geometric shape input |
US9032316B1 (en) | 2011-10-05 | 2015-05-12 | Google Inc. | Value-based presentation of user-selectable computing actions |
US9305108B2 (en) | 2011-10-05 | 2016-04-05 | Google Inc. | Semantic selection and purpose facilitation |
US8589410B2 (en) * | 2011-10-18 | 2013-11-19 | Microsoft Corporation | Visual search using multiple visual input modalities |
EP2587745A1 (en) | 2011-10-26 | 2013-05-01 | Swisscom AG | A method and system of obtaining contact information for a person or an entity |
TWI451347B (en) * | 2011-11-17 | 2014-09-01 | Univ Nat Chiao Tung | Goods data searching system and method thereof |
US8891907B2 (en) | 2011-12-06 | 2014-11-18 | Google Inc. | System and method of identifying visual objects |
WO2013088994A1 (en) * | 2011-12-14 | 2013-06-20 | 日本電気株式会社 | Video processing system, video processing method, and video processing device for portable terminal or for server and method for controlling and program for controlling same |
JP2015062090A (en) * | 2011-12-15 | 2015-04-02 | 日本電気株式会社 | Video processing system, video processing method, video processing device for portable terminal or server, and control method and control program of the same |
US10115127B2 (en) | 2011-12-16 | 2018-10-30 | Nec Corporation | Information processing system, information processing method, communications terminals and control method and control program thereof |
US8989515B2 (en) | 2012-01-12 | 2015-03-24 | Kofax, Inc. | Systems and methods for mobile image capture and processing |
US10146795B2 (en) * | 2012-01-12 | 2018-12-04 | Kofax, Inc. | Systems and methods for mobile image capture and processing |
US8620021B2 (en) | 2012-03-29 | 2013-12-31 | Digimarc Corporation | Image-related methods and arrangements |
US8935246B2 (en) | 2012-08-08 | 2015-01-13 | Google Inc. | Identifying textual terms in response to a visual query |
US8868598B2 (en) * | 2012-08-15 | 2014-10-21 | Microsoft Corporation | Smart user-centric information aggregation |
CN102902771A (en) * | 2012-09-27 | 2013-01-30 | 百度国际科技（深圳）有限公司 | Method, device and server for searching pictures |
CN102930263A (en) * | 2012-09-27 | 2013-02-13 | 百度国际科技（深圳）有限公司 | Information processing method and device |
US8990194B2 (en) * | 2012-11-02 | 2015-03-24 | Google Inc. | Adjusting content delivery based on user submissions of photographs |
US20140149257A1 (en) * | 2012-11-28 | 2014-05-29 | Jim S. Baca | Customized Shopping |
US9298712B2 (en) * | 2012-12-13 | 2016-03-29 | Microsoft Technology Licensing, Llc | Content and object metadata based search in e-reader environment |
WO2014124407A2 (en) * | 2013-02-08 | 2014-08-14 | Emotient | Collection of machine learning training data for expression recognition |
US10235358B2 (en) * | 2013-02-21 | 2019-03-19 | Microsoft Technology Licensing, Llc | Exploiting structured content for unsupervised natural language semantic parsing |
US9311640B2 (en) | 2014-02-11 | 2016-04-12 | Digimarc Corporation | Methods and arrangements for smartphone payments and transactions |
US9208176B2 (en) * | 2013-03-12 | 2015-12-08 | International Business Machines Corporation | Gesture-based image shape filtering |
US9355312B2 (en) | 2013-03-13 | 2016-05-31 | Kofax, Inc. | Systems and methods for classifying objects in digital images captured using mobile devices |
US10127636B2 (en) | 2013-09-27 | 2018-11-13 | Kofax, Inc. | Content-based detection and three dimensional geometric reconstruction of objects in image and video data |
US9258597B1 (en) | 2013-03-13 | 2016-02-09 | Google Inc. | System and method for obtaining information relating to video images |
US9247309B2 (en) | 2013-03-14 | 2016-01-26 | Google Inc. | Methods, systems, and media for presenting mobile content corresponding to media content |
US9705728B2 (en) | 2013-03-15 | 2017-07-11 | Google Inc. | Methods, systems, and media for media transmission and management |
US20140316841A1 (en) | 2013-04-23 | 2014-10-23 | Kofax, Inc. | Location-based workflows and services |
US20140330814A1 (en) * | 2013-05-03 | 2014-11-06 | Tencent Technology (Shenzhen) Company Limited | Method, client of retrieving information and computer storage medium |
WO2014186840A1 (en) * | 2013-05-21 | 2014-11-27 | Fmp Group (Australia) Pty Limited | Image recognition of vehicle parts |
US10176500B1 (en) * | 2013-05-29 | 2019-01-08 | A9.Com, Inc. | Content classification based on data recognition |
US10408613B2 (en) | 2013-07-12 | 2019-09-10 | Magic Leap, Inc. | Method and system for rendering virtual content |
GB201314642D0 (en) * | 2013-08-15 | 2013-10-02 | Summerfield Gideon | Image Identification System and Method |
CN104424257A (en) * | 2013-08-28 | 2015-03-18 | 北大方正集团有限公司 | Information indexing unit and information indexing method |
CN103455590B (en) * | 2013-08-29 | 2017-05-31 | 百度在线网络技术（北京）有限公司 | The method and apparatus retrieved in touch-screen equipment |
AU2014321165B2 (en) * | 2013-09-11 | 2020-04-09 | See-Out Pty Ltd | Image searching method and apparatus |
US10095833B2 (en) * | 2013-09-22 | 2018-10-09 | Ricoh Co., Ltd. | Mobile information gateway for use by medical personnel |
US9386235B2 (en) | 2013-11-15 | 2016-07-05 | Kofax, Inc. | Systems and methods for generating composite images of long documents using mobile video data |
US9491522B1 (en) | 2013-12-31 | 2016-11-08 | Google Inc. | Methods, systems, and media for presenting supplemental content relating to media content on a content interface based on state information that indicates a subsequent visit to the content interface |
US9456237B2 (en) | 2013-12-31 | 2016-09-27 | Google Inc. | Methods, systems, and media for presenting supplemental information corresponding to on-demand media content |
US10002191B2 (en) | 2013-12-31 | 2018-06-19 | Google Llc | Methods, systems, and media for generating search results based on contextual information |
US9411825B2 (en) * | 2013-12-31 | 2016-08-09 | Streamoid Technologies Pvt. Ltd. | Computer implemented system for handling text distracters in a visual search |
US10248856B2 (en) | 2014-01-14 | 2019-04-02 | Toyota Motor Engineering & Manufacturing North America, Inc. | Smart necklace with stereo vision and onboard processing |
US9915545B2 (en) | 2014-01-14 | 2018-03-13 | Toyota Motor Engineering & Manufacturing North America, Inc. | Smart necklace with stereo vision and onboard processing |
US10360907B2 (en) | 2014-01-14 | 2019-07-23 | Toyota Motor Engineering & Manufacturing North America, Inc. | Smart necklace with stereo vision and onboard processing |
US10024679B2 (en) | 2014-01-14 | 2018-07-17 | Toyota Motor Engineering & Manufacturing North America, Inc. | Smart necklace with stereo vision and onboard processing |
KR101791518B1 (en) | 2014-01-23 | 2017-10-30 | 삼성전자주식회사 | Method and apparatus for verifying user |
US9832353B2 (en) | 2014-01-31 | 2017-11-28 | Digimarc Corporation | Methods for encoding, decoding and interpreting auxiliary data in media signals |
PL3066591T3 (en) | 2014-02-10 | 2020-04-30 | Geenee Gmbh | Systems and methods for image-feature-based recognition |
US9830391B1 (en) | 2014-06-24 | 2017-11-28 | Google Inc. | Query modification based on non-textual resource context |
US9811592B1 (en) | 2014-06-24 | 2017-11-07 | Google Inc. | Query modification based on textual resource context |
US9916328B1 (en) | 2014-07-11 | 2018-03-13 | Google Llc | Providing user assistance from interaction understanding |
US10062099B2 (en) * | 2014-07-25 | 2018-08-28 | Hewlett Packard Enterprise Development Lp | Product identification based on location associated with image of product |
KR101690528B1 (en) * | 2015-06-05 | 2016-12-28 | 오드컨셉 주식회사 | Method, apparatus and computer program for displaying serch information |
US10024667B2 (en) | 2014-08-01 | 2018-07-17 | Toyota Motor Engineering & Manufacturing North America, Inc. | Wearable earpiece for providing social and environmental awareness |
US9965559B2 (en) | 2014-08-21 | 2018-05-08 | Google Llc | Providing automatic actions for mobile onscreen content |
JP6220079B2 (en) * | 2014-09-08 | 2017-10-25 | 日本電信電話株式会社 | Display control apparatus, display control method, and display control program |
US9922236B2 (en) * | 2014-09-17 | 2018-03-20 | Toyota Motor Engineering & Manufacturing North America, Inc. | Wearable eyeglasses for providing social and environmental awareness |
US10024678B2 (en) | 2014-09-17 | 2018-07-17 | Toyota Motor Engineering & Manufacturing North America, Inc. | Wearable clip for providing social and environmental awareness |
US9760788B2 (en) | 2014-10-30 | 2017-09-12 | Kofax, Inc. | Mobile document detection and orientation based on reference object characteristics |
CN104391938B (en) * | 2014-11-24 | 2017-10-10 | 武汉海川云谷软件技术有限公司 | A kind of picture batch in physical assets management imports the method and system of database |
CN104615639B (en) * | 2014-11-28 | 2018-08-24 | 北京百度网讯科技有限公司 | A kind of method and apparatus for providing the presentation information of picture |
CN105868385B (en) * | 2014-12-12 | 2020-02-07 | 北京奇虎科技有限公司 | Method and system for searching based on terminal interface touch operation |
CN104572986A (en) * | 2015-01-04 | 2015-04-29 | 百度在线网络技术（北京）有限公司 | Information searching method and device |
US11120478B2 (en) | 2015-01-12 | 2021-09-14 | Ebay Inc. | Joint-based item recognition |
US20160217157A1 (en) * | 2015-01-23 | 2016-07-28 | Ebay Inc. | Recognition of items depicted in images |
US10490102B2 (en) | 2015-02-10 | 2019-11-26 | Toyota Motor Engineering & Manufacturing North America, Inc. | System and method for braille assistance |
US9586318B2 (en) | 2015-02-27 | 2017-03-07 | Toyota Motor Engineering & Manufacturing North America, Inc. | Modular robot with smart device |
US9811752B2 (en) | 2015-03-10 | 2017-11-07 | Toyota Motor Engineering & Manufacturing North America, Inc. | Wearable smart device and method for redundant object identification |
US9922271B2 (en) | 2015-03-20 | 2018-03-20 | Netra, Inc. | Object detection and classification |
US9760792B2 (en) | 2015-03-20 | 2017-09-12 | Netra, Inc. | Object detection and classification |
US9972216B2 (en) | 2015-03-20 | 2018-05-15 | Toyota Motor Engineering & Manufacturing North America, Inc. | System and method for storing and playback of information for blind users |
CN104794220A (en) * | 2015-04-28 | 2015-07-22 | 百度在线网络技术（北京）有限公司 | Information search method and information search device |
US9703541B2 (en) | 2015-04-28 | 2017-07-11 | Google Inc. | Entity action suggestion on a mobile device |
US10062015B2 (en) | 2015-06-25 | 2018-08-28 | The Nielsen Company (Us), Llc | Methods and apparatus for identifying objects depicted in a video using extracted video frames in combination with a reverse image search engine |
AU2016277553B2 (en) * | 2015-06-26 | 2022-02-17 | Rovi Guides, Inc. | Systems and methods for automatic formatting of images for media assets based on user profile |
US10628009B2 (en) | 2015-06-26 | 2020-04-21 | Rovi Guides, Inc. | Systems and methods for automatic formatting of images for media assets based on user profile |
WO2017000109A1 (en) * | 2015-06-29 | 2017-01-05 | 北京旷视科技有限公司 | Search method, search apparatus, user equipment, and computer program product |
US10769200B1 (en) * | 2015-07-01 | 2020-09-08 | A9.Com, Inc. | Result re-ranking for object recognition |
US10242285B2 (en) | 2015-07-20 | 2019-03-26 | Kofax, Inc. | Iterative recognition-guided thresholding and data extraction |
CN105069083B (en) | 2015-07-31 | 2019-03-08 | 小米科技有限责任公司 | The determination method and device of association user |
US9898039B2 (en) | 2015-08-03 | 2018-02-20 | Toyota Motor Engineering & Manufacturing North America, Inc. | Modular smart necklace |
CN108431829A (en) * | 2015-08-03 | 2018-08-21 | 奥兰德股份公司 | System and method for searching for product in catalogue |
ITUB20153277A1 (en) * | 2015-08-28 | 2017-02-28 | St Microelectronics Srl | PROCEDURE FOR VISUAL VISA, SYSTEM, EQUIPMENT AND COMPUTER PRODUCT |
US10970646B2 (en) | 2015-10-01 | 2021-04-06 | Google Llc | Action suggestions for user-selected content |
US11055343B2 (en) | 2015-10-05 | 2021-07-06 | Pinterest, Inc. | Dynamic search control invocation and visual search |
US11609946B2 (en) * | 2015-10-05 | 2023-03-21 | Pinterest, Inc. | Dynamic search input selection |
JP6204957B2 (en) * | 2015-10-15 | 2017-09-27 | ヤフー株式会社 | Information processing apparatus, information processing method, and information processing program |
US20180004845A1 (en) * | 2015-10-16 | 2018-01-04 | Carlos A. Munoz | Web Based Information Search Method |
US10178527B2 (en) | 2015-10-22 | 2019-01-08 | Google Llc | Personalized entity repository |
US10055390B2 (en) | 2015-11-18 | 2018-08-21 | Google Llc | Simulated hyperlinks on a mobile device based on user intent and a centered selection of text |
US9881236B2 (en) | 2015-12-28 | 2018-01-30 | Google Llc | Organizing images associated with a user |
US20170185670A1 (en) * | 2015-12-28 | 2017-06-29 | Google Inc. | Generating labels for images associated with a user |
US10043102B1 (en) * | 2016-01-20 | 2018-08-07 | Palantir Technologies Inc. | Database systems and user interfaces for dynamic and interactive mobile image analysis and identification |
US9779293B2 (en) * | 2016-01-27 | 2017-10-03 | Honeywell International Inc. | Method and tool for post-mortem analysis of tripped field devices in process industry using optical character recognition and intelligent character recognition |
US10024680B2 (en) | 2016-03-11 | 2018-07-17 | Toyota Motor Engineering & Manufacturing North America, Inc. | Step based guidance system |
US10445355B2 (en) * | 2016-04-07 | 2019-10-15 | RELX Inc. | Systems and methods for providing a visualizable results list |
US11003667B1 (en) | 2016-05-27 | 2021-05-11 | Google Llc | Contextual information for a displayed resource |
US9958275B2 (en) | 2016-05-31 | 2018-05-01 | Toyota Motor Engineering & Manufacturing North America, Inc. | System and method for wearable smart device communications |
US10152521B2 (en) | 2016-06-22 | 2018-12-11 | Google Llc | Resource recommendations for a displayed resource |
US10353950B2 (en) | 2016-06-28 | 2019-07-16 | Google Llc | Visual recognition using user tap locations |
US10802671B2 (en) | 2016-07-11 | 2020-10-13 | Google Llc | Contextual information for a displayed resource that includes an image |
US10561519B2 (en) | 2016-07-20 | 2020-02-18 | Toyota Motor Engineering & Manufacturing North America, Inc. | Wearable computing device having a curved back to reduce pressure on vertebrae |
US10489459B1 (en) | 2016-07-21 | 2019-11-26 | Google Llc | Query recommendations for a displayed resource |
US10051108B2 (en) | 2016-07-21 | 2018-08-14 | Google Llc | Contextual information for a notification |
US10467300B1 (en) | 2016-07-21 | 2019-11-05 | Google Llc | Topical resource recommendations for a displayed resource |
MX2019002626A (en) * | 2016-09-06 | 2019-10-02 | Walmart Apollo Llc | Product part picture picker. |
RU2720536C1 (en) * | 2016-09-08 | 2020-04-30 | Гох Су Сиах | Video reception framework for visual search platform |
US10949605B2 (en) * | 2016-09-13 | 2021-03-16 | Bank Of America Corporation | Interprogram communication with event handling for online enhancements |
US10212113B2 (en) | 2016-09-19 | 2019-02-19 | Google Llc | Uniform resource identifier and image sharing for contextual information display |
US10535005B1 (en) | 2016-10-26 | 2020-01-14 | Google Llc | Providing contextual actions for mobile onscreen content |
US10432851B2 (en) | 2016-10-28 | 2019-10-01 | Toyota Motor Engineering & Manufacturing North America, Inc. | Wearable computing device for detecting photography |
US10346727B2 (en) * | 2016-10-28 | 2019-07-09 | Adobe Inc. | Utilizing a digital canvas to conduct a spatial-semantic search for digital visual media |
USD827143S1 (en) | 2016-11-07 | 2018-08-28 | Toyota Motor Engineering & Manufacturing North America, Inc. | Blind aid device |
US10012505B2 (en) | 2016-11-11 | 2018-07-03 | Toyota Motor Engineering & Manufacturing North America, Inc. | Wearable system for providing walking directions |
US10521669B2 (en) | 2016-11-14 | 2019-12-31 | Toyota Motor Engineering & Manufacturing North America, Inc. | System and method for providing guidance or feedback to a user |
US11237696B2 (en) | 2016-12-19 | 2022-02-01 | Google Llc | Smart assist for repeated actions |
US20180218237A1 (en) * | 2017-01-30 | 2018-08-02 | International Business Machines Corporation | System, method and computer program product for creating a contact group using image analytics |
US11449495B2 (en) * | 2017-02-01 | 2022-09-20 | United Parcel Service Of America, Inc. | Indexable database profiles comprising multi-language encoding data and methods for generating the same |
JP6807268B2 (en) * | 2017-04-18 | 2021-01-06 | 日本電信電話株式会社 | Image recognition engine linkage device and program |
KR102368847B1 (en) | 2017-04-28 | 2022-03-02 | 삼성전자주식회사 | Method for outputting content corresponding to object and electronic device thereof |
JP6353118B1 (en) * | 2017-05-10 | 2018-07-04 | ヤフー株式会社 | Display program, information providing apparatus, display apparatus, display method, information providing method, and information providing program |
US11928482B2 (en) * | 2017-06-13 | 2024-03-12 | Google Llc | Interaction with electronic chat interfaces |
US10679068B2 (en) | 2017-06-13 | 2020-06-09 | Google Llc | Media contextual information from buffered media data |
CN111295669A (en) * | 2017-06-16 | 2020-06-16 | 马克波尔公司 | Image processing system |
US10652592B2 (en) | 2017-07-02 | 2020-05-12 | Comigo Ltd. | Named entity disambiguation for providing TV content enrichment |
KR102469717B1 (en) * | 2017-08-01 | 2022-11-22 | 삼성전자주식회사 | Electronic device and method for controlling the electronic device thereof |
WO2019027240A1 (en) | 2017-08-01 | 2019-02-07 | Samsung Electronics Co., Ltd. | Electronic device and method for providing search result thereof |
KR102586170B1 (en) * | 2017-08-01 | 2023-10-10 | 삼성전자주식회사 | Electronic device and method for providing search result thereof |
JP6938680B2 (en) * | 2017-09-13 | 2021-09-22 | グーグル エルエルシーＧｏｏｇｌｅ ＬＬＣ | Efficient image enhancement with related content |
US10942966B2 (en) | 2017-09-22 | 2021-03-09 | Pinterest, Inc. | Textual and image based search |
US11126653B2 (en) | 2017-09-22 | 2021-09-21 | Pinterest, Inc. | Mixed type image based search results |
US11841735B2 (en) | 2017-09-22 | 2023-12-12 | Pinterest, Inc. | Object based image search |
KR102599947B1 (en) * | 2017-10-27 | 2023-11-09 | 삼성전자주식회사 | Electronic device and method for controlling the electronic device thereof |
US11062176B2 (en) | 2017-11-30 | 2021-07-13 | Kofax, Inc. | Object detection and image cropping using a multi-detector approach |
US11200611B2 (en) * | 2017-12-29 | 2021-12-14 | Ebay Inc. | Computer vision for unsuccessful queries and iterative search |
US10740394B2 (en) * | 2018-01-18 | 2020-08-11 | Oath Inc. | Machine-in-the-loop, image-to-video computer vision bootstrapping |
CN108270794B (en) * | 2018-02-06 | 2020-10-09 | 腾讯科技（深圳）有限公司 | Content distribution method, device and readable medium |
KR102068535B1 (en) * | 2018-02-28 | 2020-01-21 | 엔에이치엔 주식회사 | Method for schedule a service based on chat messages |
US10558857B2 (en) * | 2018-03-05 | 2020-02-11 | A9.Com, Inc. | Visual feedback of process state |
JP6684846B2 (en) * | 2018-04-23 | 2020-04-22 | 株式会社ワコム | Article search system |
US10810457B2 (en) * | 2018-05-09 | 2020-10-20 | Fuji Xerox Co., Ltd. | System for searching documents and people based on detecting documents and people around a table |
CN108897841A (en) * | 2018-06-27 | 2018-11-27 | 百度在线网络技术（北京）有限公司 | Panorama sketch searching method, device, equipment, server and storage medium |
KR102544781B1 (en) | 2018-08-08 | 2023-06-19 | 삼성전자주식회사 | Method for providing information on merchandise based on priority and electronic device thereof |
US10699112B1 (en) * | 2018-09-28 | 2020-06-30 | Automation Anywhere, Inc. | Identification of key segments in document images |
US11574473B2 (en) * | 2018-11-25 | 2023-02-07 | Google Llc | Finding and filtering elements of a visual scene |
JP6934855B2 (en) * | 2018-12-20 | 2021-09-15 | ヤフー株式会社 | Control program |
KR101982990B1 (en) * | 2018-12-27 | 2019-05-27 | 건국대학교 산학협력단 | Method and apparatus for questioning and answering using chatbot |
KR101982991B1 (en) * | 2018-12-28 | 2019-05-27 | 건국대학교 산학협력단 | Method and apparatus for questioning and answering using a plurality of chatbots |
US11494884B2 (en) | 2019-02-21 | 2022-11-08 | Canon U.S.A., Inc. | Method and system for evaluating image sharpness |
KR102245774B1 (en) | 2019-11-06 | 2021-04-27 | 연세대학교 산학협력단 | Visual Question Answering Apparatus Using Fair Classification Network and Method Thereof |
KR102368560B1 (en) | 2020-01-31 | 2022-02-25 | 연세대학교 산학협력단 | Visual Question Answering Apparatus Using Selective Residual Learning and Method Thereof |
KR102104246B1 (en) * | 2020-02-17 | 2020-04-24 | 주식회사 비에이템 | Image search system using screen segmentaion |
CN111539438B (en) * | 2020-04-28 | 2024-01-12 | 北京百度网讯科技有限公司 | Text content identification method and device and electronic equipment |
US20220092105A1 (en) * | 2020-09-18 | 2022-03-24 | Google Llc | Intelligent Systems and Methods for Visual Search Queries |
CN112733779B (en) * | 2021-01-19 | 2023-04-07 | 三星电子（中国）研发中心 | Video poster display method and system based on artificial intelligence |
CN112766269B (en) * | 2021-03-04 | 2024-03-12 | 深圳康佳电子科技有限公司 | Picture text retrieval method, intelligent terminal and storage medium |
US20220300550A1 (en) * | 2021-03-19 | 2022-09-22 | Google Llc | Visual Search via Free-Form Visual Feature Selection |
CN114969479B (en) * | 2021-04-21 | 2023-08-15 | 中移互联网有限公司 | Searching method, searching device and storage medium |
US11835995B2 (en) | 2022-02-10 | 2023-12-05 | Clarifai, Inc. | Automatic unstructured knowledge cascade visual search |
Citations (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP2005107978A (en) * | 2003-09-30 | 2005-04-21 | Nec Corp | Information retrieving device using information terminal with photographing function and information retrieving method |
JP2005215922A (en) * | 2004-01-29 | 2005-08-11 | Zeta Bridge Corp | Information retrieval system, information retrieval method, information retrieval apparatus, information retrieval program, picture recognition apparatus, picture recognition method and picture recognition program, and sales system |
US20080267504A1 (en) * | 2007-04-24 | 2008-10-30 | Nokia Corporation | Method, device and computer program product for integrating code-based and optical character recognition technologies into a mobile visual search |
JP2008269628A (en) * | 1999-09-27 | 2008-11-06 | Mitsubishi Electric Corp | Image retrieval system and image retrieval method |
Family Cites Families (215)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4888690A (en) | 1985-01-11 | 1989-12-19 | Wang Laboratories, Inc. | Interactive error handling means in database management |
US4899292A (en) * | 1988-03-02 | 1990-02-06 | Image Storage/Retrieval Systems, Inc. | System for storing and retrieving text and associated graphics |
CA2048306A1 (en) | 1990-10-02 | 1992-04-03 | Steven P. Miller | Distributed configuration profile for computing system |
US5649183A (en) | 1992-12-08 | 1997-07-15 | Microsoft Corporation | Method for compressing full text indexes with document identifiers and location offsets |
US5574898A (en) | 1993-01-08 | 1996-11-12 | Atria Software, Inc. | Dynamic software version auditor which monitors a process to provide a list of objects that are accessed |
US5544051A (en) | 1993-09-17 | 1996-08-06 | Digital Equipment Corporation | Document management system using multiple threaded processes and having asynchronous repository responses and no busy cursor |
JP2813728B2 (en) * | 1993-11-01 | 1998-10-22 | インターナショナル・ビジネス・マシーンズ・コーポレイション | Personal communication device with zoom / pan function |
US5560005A (en) | 1994-02-25 | 1996-09-24 | Actamed Corp. | Methods and systems for object-based relational distributed databases |
US6216138B1 (en) * | 1994-04-22 | 2001-04-10 | Brooks Automation Inc. | Computer interface system for automatically generating graphical representations of computer operations linked together according to functional relationships |
US6029195A (en) * | 1994-11-29 | 2000-02-22 | Herz; Frederick S. M. | System for customized electronic identification of desirable objects |
US5764799A (en) * | 1995-06-26 | 1998-06-09 | Research Foundation Of State Of State Of New York | OCR method and apparatus using image equivalents |
US5963940A (en) | 1995-08-16 | 1999-10-05 | Syracuse University | Natural language information retrieval system and method |
US6006221A (en) | 1995-08-16 | 1999-12-21 | Syracuse University | Multilingual document retrieval system and method using semantic vector matching |
US6026388A (en) * | 1995-08-16 | 2000-02-15 | Textwise, Llc | User interface and other enhancements for natural language information retrieval system and method |
US5815415A (en) | 1996-01-19 | 1998-09-29 | Bentley Systems, Incorporated | Computer system for portable persistent modeling |
US6076088A (en) * | 1996-02-09 | 2000-06-13 | Paik; Woojin | Information extraction system and method using concept relation concept (CRC) triples |
US5778378A (en) * | 1996-04-30 | 1998-07-07 | International Business Machines Corporation | Object oriented information retrieval framework mechanism |
US6014661A (en) * | 1996-05-06 | 2000-01-11 | Ivee Development Ab | System and method for automatic analysis of data bases and for user-controlled dynamic querying |
US6101515A (en) | 1996-05-31 | 2000-08-08 | Oracle Corporation | Learning system for classification of terminology |
JPH09330336A (en) | 1996-06-11 | 1997-12-22 | Sony Corp | Information processor |
US5870739A (en) * | 1996-09-20 | 1999-02-09 | Novell, Inc. | Hybrid query apparatus and method |
JP3099756B2 (en) * | 1996-10-31 | 2000-10-16 | 富士ゼロックス株式会社 | Document processing device, word extraction device, and word extraction method |
US6480194B1 (en) | 1996-11-12 | 2002-11-12 | Silicon Graphics, Inc. | Computer-related method, system, and program product for controlling data visualization in external dimension(s) |
US6498921B1 (en) | 1999-09-01 | 2002-12-24 | Chi Fai Ho | Method and system to answer a natural-language question |
US5966126A (en) | 1996-12-23 | 1999-10-12 | Szabo; Andrew J. | Graphic user interface for database system |
US5946692A (en) | 1997-05-08 | 1999-08-31 | At & T Corp | Compressed representation of a data base that permits AD HOC querying |
CA2242158C (en) * | 1997-07-01 | 2004-06-01 | Hitachi, Ltd. | Method and apparatus for searching and displaying structured document |
US5987448A (en) * | 1997-07-25 | 1999-11-16 | Claritech Corporation | Methodology for displaying search results using character recognition |
US6188403B1 (en) * | 1997-11-21 | 2001-02-13 | Portola Dimensional Systems, Inc. | User-friendly graphics generator using direct manipulation |
US6105030A (en) | 1998-02-27 | 2000-08-15 | Oracle Corporation | Method and apparatus for copying data that resides in a database |
US6173287B1 (en) | 1998-03-11 | 2001-01-09 | Digital Equipment Corporation | Technique for ranking multimedia annotations of interest |
US6269188B1 (en) | 1998-03-12 | 2001-07-31 | Canon Kabushiki Kaisha | Word grouping accuracy value generation |
US6327574B1 (en) | 1998-07-07 | 2001-12-04 | Encirq Corporation | Hierarchical models of consumer attributes for targeting content in a privacy-preserving manner |
US6137907A (en) | 1998-09-23 | 2000-10-24 | Xerox Corporation | Method and apparatus for pixel-level override of halftone detection within classification blocks to reduce rectangular artifacts |
US6529900B1 (en) | 1999-01-14 | 2003-03-04 | International Business Machines Corporation | Method and apparatus for data visualization |
US6377943B1 (en) * | 1999-01-20 | 2002-04-23 | Oracle Corp. | Initial ordering of tables for database queries |
GB9903451D0 (en) | 1999-02-16 | 1999-04-07 | Hewlett Packard Co | Similarity searching for documents |
US6584464B1 (en) | 1999-03-19 | 2003-06-24 | Ask Jeeves, Inc. | Grammar template query system |
US6263328B1 (en) * | 1999-04-09 | 2001-07-17 | International Business Machines Corporation | Object oriented query model and process for complex heterogeneous database queries |
US20030195872A1 (en) | 1999-04-12 | 2003-10-16 | Paul Senn | Web-based information content analyzer and information dimension dictionary |
US6304864B1 (en) | 1999-04-20 | 2001-10-16 | Textwise Llc | System for retrieving multimedia information from the internet using multiple evolving intelligent agents |
US6629097B1 (en) | 1999-04-28 | 2003-09-30 | Douglas K. Keith | Displaying implicit associations among items in loosely-structured data sets |
JP2000331006A (en) | 1999-05-18 | 2000-11-30 | Nippon Telegr & Teleph Corp <Ntt> | Information retrieval device |
US6721713B1 (en) * | 1999-05-27 | 2004-04-13 | Andersen Consulting Llp | Business alliance identification in a web architecture framework |
US6885990B1 (en) * | 1999-05-31 | 2005-04-26 | Nippon Telegraph And Telephone Company | Speech recognition based on interactive information retrieval scheme using dialogue control to reduce user stress |
US6408293B1 (en) * | 1999-06-09 | 2002-06-18 | International Business Machines Corporation | Interactive framework for understanding user's perception of multimedia data |
US6873982B1 (en) * | 1999-07-16 | 2005-03-29 | International Business Machines Corporation | Ordering of database search results based on user feedback |
US6341306B1 (en) * | 1999-08-13 | 2002-01-22 | Atomica Corporation | Web-based information retrieval responsive to displayed word identified by a text-grabbing algorithm |
CA2281331A1 (en) | 1999-09-03 | 2001-03-03 | Cognos Incorporated | Database management system |
US6105020A (en) | 1999-10-11 | 2000-08-15 | International Business Machines Corporation | System and method for identifying and constructing star joins for execution by bitmap ANDing |
US6850896B1 (en) * | 1999-10-28 | 2005-02-01 | Market-Touch Corporation | Method and system for managing and providing sales data using world wide web |
US6546388B1 (en) * | 2000-01-14 | 2003-04-08 | International Business Machines Corporation | Metadata search results ranking system |
US6606659B1 (en) | 2000-01-28 | 2003-08-12 | Websense, Inc. | System and method for controlling access to internet sites |
US20030120659A1 (en) * | 2000-03-20 | 2003-06-26 | Sridhar Mandayam Anandampillai | Systems for developing websites and methods therefor |
US6643641B1 (en) | 2000-04-27 | 2003-11-04 | Russell Snyder | Web search engine with graphic snapshots |
US7325201B2 (en) * | 2000-05-18 | 2008-01-29 | Endeca Technologies, Inc. | System and method for manipulating content in a hierarchical data-driven search and navigation system |
US7401131B2 (en) | 2000-05-22 | 2008-07-15 | Verizon Business Global Llc | Method and system for implementing improved containers in a global ecosystem of interrelated services |
US6754677B1 (en) * | 2000-05-30 | 2004-06-22 | Outlooksoft Corporation | Method and system for facilitating information exchange |
US7328349B2 (en) * | 2001-12-14 | 2008-02-05 | Bbn Technologies Corp. | Hash-based systems and methods for detecting, preventing, and tracing network worms and viruses |
US7640489B2 (en) * | 2000-08-01 | 2009-12-29 | Sun Microsystems, Inc. | Methods and systems for inputting data into spreadsheet documents |
US7100083B2 (en) | 2000-08-04 | 2006-08-29 | Sun Microsystems, Inc. | Checks for product knowledge management |
US20030217052A1 (en) | 2000-08-24 | 2003-11-20 | Celebros Ltd. | Search engine method and apparatus |
EP1312039B1 (en) | 2000-08-24 | 2006-03-29 | Olive Software, Inc. | System and method for automatic preparation and searching of scanned documents |
US6968343B2 (en) | 2000-09-01 | 2005-11-22 | Borland Software Corporation | Methods and systems for integrating process modeling and project planning |
US6832218B1 (en) | 2000-09-22 | 2004-12-14 | International Business Machines Corporation | System and method for associating search results |
US6823084B2 (en) * | 2000-09-22 | 2004-11-23 | Sri International | Method and apparatus for portably recognizing text in an image sequence of scene imagery |
US20020065815A1 (en) * | 2000-10-04 | 2002-05-30 | Xcelerix, Inc. | Systems and methods for searching a database |
US7016532B2 (en) | 2000-11-06 | 2006-03-21 | Evryx Technologies | Image capture and identification system and process |
US20020103920A1 (en) | 2000-11-21 | 2002-08-01 | Berkun Ken Alan | Interpretive stream metadata extraction |
US7013308B1 (en) * | 2000-11-28 | 2006-03-14 | Semscript Ltd. | Knowledge storage and retrieval system and method |
US6781599B2 (en) | 2001-01-04 | 2004-08-24 | At&T | System and method for visualizing massive multi-digraphs |
JP2002223105A (en) * | 2001-01-26 | 2002-08-09 | Sanyo Electric Co Ltd | Coaxial resonator, and dielectric filter and dielectric duplexer employing it |
JP4077608B2 (en) | 2001-02-27 | 2008-04-16 | 株式会社エヌ・ティ・ティ・ドコモ | Feature region extraction method and apparatus, and information providing method and apparatus |
US6748398B2 (en) * | 2001-03-30 | 2004-06-08 | Microsoft Corporation | Relevance maximizing, iteration minimizing, relevance-feedback, content-based image retrieval (CBIR) |
US6920477B2 (en) * | 2001-04-06 | 2005-07-19 | President And Fellows Of Harvard College | Distributed, compressed Bloom filter Web cache server |
US7031955B1 (en) * | 2001-04-27 | 2006-04-18 | I2 Technologies Us, Inc. | Optimization using a multi-dimensional data model |
US6961723B2 (en) | 2001-05-04 | 2005-11-01 | Sun Microsystems, Inc. | System and method for determining relevancy of query responses in a distributed network search mechanism |
US7398201B2 (en) | 2001-08-14 | 2008-07-08 | Evri Inc. | Method and system for enhanced data searching |
US7403938B2 (en) * | 2001-09-24 | 2008-07-22 | Iac Search & Media, Inc. | Natural language query processing |
US7313617B2 (en) * | 2001-09-28 | 2007-12-25 | Dale Malik | Methods and systems for a communications and information resource manager |
JP2003150617A (en) | 2001-11-12 | 2003-05-23 | Olympus Optical Co Ltd | Image processor and program |
US6826572B2 (en) | 2001-11-13 | 2004-11-30 | Overture Services, Inc. | System and method allowing advertisers to manage search listings in a pay for placement search system using grouping |
JP3931214B2 (en) * | 2001-12-17 | 2007-06-13 | 日本アイ・ビー・エム株式会社 | Data analysis apparatus and program |
US6988018B2 (en) * | 2001-12-26 | 2006-01-17 | Eames John D | System and method for analyzing controlling forming sections of a paper machine in operation |
US20030154071A1 (en) | 2002-02-11 | 2003-08-14 | Shreve Gregory M. | Process for the document management and computer-assisted translation of documents utilizing document corpora constructed by intelligent agents |
US7343365B2 (en) | 2002-02-20 | 2008-03-11 | Microsoft Corporation | Computer system architecture for automatic context associations |
US6928436B2 (en) | 2002-02-28 | 2005-08-09 | Ilog Sa | Interactive generation of graphical visualizations of large data structures |
US7043521B2 (en) * | 2002-03-21 | 2006-05-09 | Rockwell Electronic Commerce Technologies, Llc | Search agent for searching the internet |
US20040030731A1 (en) * | 2002-04-03 | 2004-02-12 | Liviu Iftode | System and method for accessing files in a network |
US20030208665A1 (en) | 2002-05-01 | 2003-11-06 | Jih-Kwon Peir | Reducing data speculation penalty with early cache hit/miss prediction |
US7158983B2 (en) * | 2002-09-23 | 2007-01-02 | Battelle Memorial Institute | Text analysis technique |
DE10245900A1 (en) | 2002-09-30 | 2004-04-08 | Neven jun., Hartmut, Prof.Dr. | Image based query system for search engines or databases of mobile telephone, portable computer uses image recognition to access more information about objects in image |
EP1588277A4 (en) | 2002-12-06 | 2007-04-25 | Attensity Corp | Systems and methods for providing a mixed data integration service |
US7181450B2 (en) * | 2002-12-18 | 2007-02-20 | International Business Machines Corporation | Method, system, and program for use of metadata to create multidimensional cubes in a relational database |
US7278111B2 (en) * | 2002-12-26 | 2007-10-02 | Yahoo! Inc. | Systems and methods for selecting a date or range of dates |
US7472110B2 (en) * | 2003-01-29 | 2008-12-30 | Microsoft Corporation | System and method for employing social networks for information discovery |
US7146538B2 (en) | 2003-03-28 | 2006-12-05 | Hewlett-Packard Development Company, L.P. | Bus interface module |
US7111025B2 (en) | 2003-04-30 | 2006-09-19 | International Business Machines Corporation | Information retrieval system and method using index ANDing for improving performance |
US7853508B2 (en) | 2003-05-19 | 2010-12-14 | Serena Software, Inc. | Method and system for object-oriented management of multi-dimensional data |
US7926103B2 (en) * | 2003-06-05 | 2011-04-12 | Hewlett-Packard Development Company, L.P. | System and method for preventing replay attacks |
US7836391B2 (en) | 2003-06-10 | 2010-11-16 | Google Inc. | Document search engine including highlighting of confident results |
US9026901B2 (en) | 2003-06-20 | 2015-05-05 | International Business Machines Corporation | Viewing annotations across multiple applications |
US8321470B2 (en) | 2003-06-20 | 2012-11-27 | International Business Machines Corporation | Heterogeneous multi-level extendable indexing for general purpose annotation systems |
US7162473B2 (en) | 2003-06-26 | 2007-01-09 | Microsoft Corporation | Method and system for usage analyzer that determines user accessed sources, indexes data subsets, and associated metadata, processing implicit queries based on potential interest to users |
US7274822B2 (en) * | 2003-06-30 | 2007-09-25 | Microsoft Corporation | Face annotation for photo management |
US7565425B2 (en) * | 2003-07-02 | 2009-07-21 | Amazon Technologies, Inc. | Server architecture and methods for persistently storing and serving event data |
US7814093B2 (en) * | 2003-07-25 | 2010-10-12 | Microsoft Corporation | Method and system for building a report for execution against a data store |
US7444515B2 (en) * | 2003-08-14 | 2008-10-28 | Washington University | Method and apparatus for detecting predefined signatures in packet payload using Bloom filters |
US7174328B2 (en) * | 2003-09-02 | 2007-02-06 | International Business Machines Corp. | Selective path signatures for query processing over a hierarchical tagged data structure |
US7409406B2 (en) * | 2003-09-08 | 2008-08-05 | International Business Machines Corporation | Uniform search system and method for selectively sharing distributed access-controlled documents |
US20050057566A1 (en) * | 2003-09-11 | 2005-03-17 | International Business Machines Corporation | Rich graphic visualization generation from abstract data representation |
US7236982B2 (en) * | 2003-09-15 | 2007-06-26 | Pic Web Services, Inc. | Computer systems and methods for platform independent presentation design |
US7496560B2 (en) * | 2003-09-23 | 2009-02-24 | Amazon Technologies, Inc. | Personalized searchable library with highlighting capabilities |
US7370034B2 (en) * | 2003-10-15 | 2008-05-06 | Xerox Corporation | System and method for performing electronic information retrieval using keywords |
US7620624B2 (en) * | 2003-10-17 | 2009-11-17 | Yahoo! Inc. | Systems and methods for indexing content for fast and scalable retrieval |
US20050083413A1 (en) * | 2003-10-20 | 2005-04-21 | Logicalis | Method, system, apparatus, and machine-readable medium for use in connection with a server that uses images or audio for initiating remote function calls |
US7415456B2 (en) * | 2003-10-30 | 2008-08-19 | Lucent Technologies Inc. | Network support for caller identification based on biometric measurement |
JP2005165461A (en) | 2003-11-28 | 2005-06-23 | Nifty Corp | Information providing device and program |
US7872669B2 (en) * | 2004-01-22 | 2011-01-18 | Massachusetts Institute Of Technology | Photo-based mobile deixis system and related techniques |
US7707039B2 (en) | 2004-02-15 | 2010-04-27 | Exbiblio B.V. | Automatic modification of web pages |
US20050187898A1 (en) | 2004-02-05 | 2005-08-25 | Nec Laboratories America, Inc. | Data Lookup architecture |
US7751805B2 (en) | 2004-02-20 | 2010-07-06 | Google Inc. | Mobile image-based information retrieval system |
US7451185B2 (en) | 2004-02-27 | 2008-11-11 | Fotomedia Technologies, Llc | Method and system for providing links to resources related to a specified resource |
US20050216464A1 (en) | 2004-03-27 | 2005-09-29 | Microsoft Corporation | Automated authoring tool and method to facilitate inclusion of maps and other geographical data into travelogues |
US20050219929A1 (en) | 2004-03-30 | 2005-10-06 | Navas Julio C | Method and apparatus achieving memory and transmission overhead reductions in a content routing network |
WO2005114476A1 (en) | 2004-05-13 | 2005-12-01 | Nevengineering, Inc. | Mobile image-based information retrieval system |
US20050268212A1 (en) | 2004-05-28 | 2005-12-01 | Michael Dagel | System, apparatus, and method for desktop-based creation and publication of a periodic community newsletter |
US7685112B2 (en) * | 2004-06-17 | 2010-03-23 | The Regents Of The University Of California | Method and apparatus for retrieving and indexing hidden pages |
US8051207B2 (en) * | 2004-06-25 | 2011-11-01 | Citrix Systems, Inc. | Inferring server state in s stateless communication protocol |
US7493335B2 (en) * | 2004-07-02 | 2009-02-17 | Graphlogic Inc. | Object process graph relational database interface |
US20060020582A1 (en) * | 2004-07-22 | 2006-01-26 | International Business Machines Corporation | Method and system for processing abstract derived entities defined in a data abstraction model |
US20060020630A1 (en) * | 2004-07-23 | 2006-01-26 | Stager Reed R | Facial database methods and systems |
US7890871B2 (en) * | 2004-08-26 | 2011-02-15 | Redlands Technology, Llc | System and method for dynamically generating, maintaining, and growing an online social network |
JP2006085379A (en) | 2004-09-15 | 2006-03-30 | Canon Inc | Information processor and its control method, and program |
US8385589B2 (en) | 2008-05-15 | 2013-02-26 | Berna Erol | Web-based content detection in images, extraction and recognition |
US8489583B2 (en) * | 2004-10-01 | 2013-07-16 | Ricoh Company, Ltd. | Techniques for retrieving documents using an image capture device |
US7809763B2 (en) * | 2004-10-15 | 2010-10-05 | Oracle International Corporation | Method(s) for updating database object metadata |
US20060085386A1 (en) * | 2004-10-19 | 2006-04-20 | Microsoft Corporation | Two pass calculation to optimize formula calculations for a spreadsheet |
WO2006043319A1 (en) | 2004-10-20 | 2006-04-27 | Fujitsu Limited | Terminal and server |
US8320641B2 (en) | 2004-10-28 | 2012-11-27 | DigitalOptics Corporation Europe Limited | Method and apparatus for red-eye detection using preview or other reference images |
US20060149700A1 (en) * | 2004-11-11 | 2006-07-06 | Gladish Randolph J | System and method for automatic geospatial web network generation via metadata transformation |
US7464090B2 (en) | 2006-01-27 | 2008-12-09 | Google Inc. | Object categorization for information extraction |
US20060150119A1 (en) * | 2004-12-31 | 2006-07-06 | France Telecom | Method for interacting with automated information agents using conversational queries |
US9451219B2 (en) | 2004-12-31 | 2016-09-20 | Nokia Technologies Oy | Provision of target specific information |
JP4282612B2 (en) | 2005-01-19 | 2009-06-24 | エルピーダメモリ株式会社 | Memory device and refresh method thereof |
US20060173824A1 (en) | 2005-02-01 | 2006-08-03 | Metalincs Corporation | Electronic communication analysis and visualization |
US20070201749A1 (en) | 2005-02-07 | 2007-08-30 | Masaki Yamauchi | Image Processing Device And Image Processing Method |
JP4267584B2 (en) | 2005-02-28 | 2009-05-27 | 株式会社東芝 | Device control apparatus and method |
US7917299B2 (en) * | 2005-03-03 | 2011-03-29 | Washington University | Method and apparatus for performing similarity searching on a data stream with respect to a query string |
US7587387B2 (en) | 2005-03-31 | 2009-09-08 | Google Inc. | User interface for facts query engine with snippets from information sources that include query terms and answer terms |
US7765231B2 (en) | 2005-04-08 | 2010-07-27 | Rathus Spencer A | System and method for accessing electronic data via an image search engine |
US7773822B2 (en) * | 2005-05-02 | 2010-08-10 | Colormax, Inc. | Apparatus and methods for management of electronic images |
US7783135B2 (en) * | 2005-05-09 | 2010-08-24 | Like.Com | System and method for providing objectified image renderings using recognition information from images |
US7760917B2 (en) * | 2005-05-09 | 2010-07-20 | Like.Com | Computer-implemented method for performing similarity searches |
US7809722B2 (en) * | 2005-05-09 | 2010-10-05 | Like.Com | System and method for enabling search and retrieval from image files based on recognized information |
US7945099B2 (en) * | 2005-05-09 | 2011-05-17 | Like.Com | System and method for use of images with recognition analysis |
US7519200B2 (en) | 2005-05-09 | 2009-04-14 | Like.Com | System and method for enabling the use of captured images through recognition |
US7809192B2 (en) | 2005-05-09 | 2010-10-05 | Like.Com | System and method for recognizing objects from images and identifying relevancy amongst images and information |
KR100754656B1 (en) | 2005-06-20 | 2007-09-03 | 삼성전자주식회사 | Method and system for providing user with image related information and mobile communication system |
US20080005064A1 (en) * | 2005-06-28 | 2008-01-03 | Yahoo! Inc. | Apparatus and method for content annotation and conditional annotation retrieval in a search context |
US7702681B2 (en) * | 2005-06-29 | 2010-04-20 | Microsoft Corporation | Query-by-image search and retrieval system |
JP2007018166A (en) | 2005-07-06 | 2007-01-25 | Nec Corp | Information search device, information search system, information search method, and information search program |
JP2007018456A (en) | 2005-07-11 | 2007-01-25 | Nikon Corp | Information display device and information display method |
US20070022085A1 (en) * | 2005-07-22 | 2007-01-25 | Parashuram Kulkarni | Techniques for unsupervised web content discovery and automated query generation for crawling the hidden web |
US8666928B2 (en) * | 2005-08-01 | 2014-03-04 | Evi Technologies Limited | Knowledge repository |
US7457825B2 (en) * | 2005-09-21 | 2008-11-25 | Microsoft Corporation | Generating search requests from multimodal queries |
US20090060289A1 (en) * | 2005-09-28 | 2009-03-05 | Alex Shah | Digital Image Search System And Method |
US7876978B2 (en) * | 2005-10-13 | 2011-01-25 | Penthera Technologies, Inc. | Regions of interest in video frames |
US20070098303A1 (en) * | 2005-10-31 | 2007-05-03 | Eastman Kodak Company | Determining a particular person from a collection |
US8849821B2 (en) * | 2005-11-04 | 2014-09-30 | Nokia Corporation | Scalable visual search system simplifying access to network and device functionality |
US7826665B2 (en) | 2005-12-12 | 2010-11-02 | Xerox Corporation | Personal information retrieval using knowledge bases for optical character recognition correction |
US7725477B2 (en) * | 2005-12-19 | 2010-05-25 | Microsoft Corporation | Power filter for online listing service |
US7555471B2 (en) | 2006-01-27 | 2009-06-30 | Google Inc. | Data object visualization |
US20070179965A1 (en) | 2006-01-27 | 2007-08-02 | Hogue Andrew W | Designating data objects for analysis |
US8874591B2 (en) | 2006-01-31 | 2014-10-28 | Microsoft Corporation | Using user feedback to improve search results |
US9336333B2 (en) | 2006-02-13 | 2016-05-10 | Linkedin Corporation | Searching and reference checking within social networks |
US7668405B2 (en) * | 2006-04-07 | 2010-02-23 | Eastman Kodak Company | Forming connections between image collections |
US7917514B2 (en) * | 2006-06-28 | 2011-03-29 | Microsoft Corporation | Visual and multi-dimensional search |
US9176984B2 (en) * | 2006-07-31 | 2015-11-03 | Ricoh Co., Ltd | Mixed media reality retrieval of differentially-weighted links |
US20080031506A1 (en) * | 2006-08-07 | 2008-02-07 | Anuradha Agatheeswaran | Texture analysis for mammography computer aided diagnosis |
US7934156B2 (en) * | 2006-09-06 | 2011-04-26 | Apple Inc. | Deletion gestures on a portable multifunction device |
JP2008071311A (en) | 2006-09-15 | 2008-03-27 | Ricoh Co Ltd | Image retrieval apparatus, image retrieval method, image retrieval program, and information storage medium |
KR100865973B1 (en) | 2007-02-08 | 2008-10-30 | (주)올라웍스 | Method for searching certain person and method and system for generating copyright report for the certain person |
US9058370B2 (en) | 2007-02-27 | 2015-06-16 | International Business Machines Corporation | Method, system and program product for defining imports into and exports out from a database system using spread sheets by use of a control language |
US8861898B2 (en) | 2007-03-16 | 2014-10-14 | Sony Corporation | Content image search |
CN104866469B (en) * | 2007-04-11 | 2018-10-02 | 谷歌有限责任公司 | Input Method Editor with secondary language mode |
US7917518B2 (en) * | 2007-07-20 | 2011-03-29 | Hewlett-Packard Development Company, L.P. | Compositional balance and color driven content retrieval |
US10069924B2 (en) * | 2007-07-25 | 2018-09-04 | Oath Inc. | Application programming interfaces for communication systems |
JP5207688B2 (en) | 2007-08-30 | 2013-06-12 | キヤノン株式会社 | Image processing apparatus and integrated document generation method |
US8145660B2 (en) | 2007-10-05 | 2012-03-27 | Fujitsu Limited | Implementing an expanded search and providing expanded search results |
KR101435140B1 (en) * | 2007-10-16 | 2014-09-02 | 삼성전자 주식회사 | Display apparatus and method |
US9237213B2 (en) * | 2007-11-20 | 2016-01-12 | Yellowpages.Com Llc | Methods and apparatuses to initiate telephone connections |
US20090144056A1 (en) * | 2007-11-29 | 2009-06-04 | Netta Aizenbud-Reshef | Method and computer program product for generating recognition error correction information |
KR100969298B1 (en) | 2007-12-31 | 2010-07-09 | 인하대학교 산학협력단 | Method For Social Network Analysis Based On Face Recognition In An Image or Image Sequences |
US20090237546A1 (en) | 2008-03-24 | 2009-09-24 | Sony Ericsson Mobile Communications Ab | Mobile Device with Image Recognition Processing Capability |
US8190604B2 (en) | 2008-04-03 | 2012-05-29 | Microsoft Corporation | User intention modeling for interactive image retrieval |
US8406531B2 (en) * | 2008-05-15 | 2013-03-26 | Yahoo! Inc. | Data access based on content of image recorded by a mobile device |
US20090299990A1 (en) | 2008-05-30 | 2009-12-03 | Vidya Setlur | Method, apparatus and computer program product for providing correlations between information from heterogenous sources |
JP5109836B2 (en) * | 2008-07-01 | 2012-12-26 | 株式会社ニコン | Imaging device |
US8520979B2 (en) * | 2008-08-19 | 2013-08-27 | Digimarc Corporation | Methods and systems for content processing |
US8452794B2 (en) * | 2009-02-11 | 2013-05-28 | Microsoft Corporation | Visual and textual query suggestion |
US8670597B2 (en) | 2009-08-07 | 2014-03-11 | Google Inc. | Facial recognition with social network aiding |
US9087059B2 (en) * | 2009-08-07 | 2015-07-21 | Google Inc. | User interface for presenting search results for multiple regions of a visual query |
US9135277B2 (en) | 2009-08-07 | 2015-09-15 | Google Inc. | Architecture for responding to a visual query |
US8370358B2 (en) * | 2009-09-18 | 2013-02-05 | Microsoft Corporation | Tagging content with metadata pre-filtered by context |
US9405772B2 (en) * | 2009-12-02 | 2016-08-02 | Google Inc. | Actionable search results for street view visual queries |
US9183224B2 (en) | 2009-12-02 | 2015-11-10 | Google Inc. | Identifying matching canonical documents in response to a visual query |
US8977639B2 (en) | 2009-12-02 | 2015-03-10 | Google Inc. | Actionable search results for visual queries |
US8811742B2 (en) | 2009-12-02 | 2014-08-19 | Google Inc. | Identifying matching canonical documents consistent with visual query structural information |
US9176986B2 (en) | 2009-12-02 | 2015-11-03 | Google Inc. | Generating a combination of a visual query and matching canonical document |
US8805079B2 (en) * | 2009-12-02 | 2014-08-12 | Google Inc. | Identifying matching canonical documents in response to a visual query and in accordance with geographic information |
US20110128288A1 (en) | 2009-12-02 | 2011-06-02 | David Petrou | Region of Interest Selector for Visual Queries |
US9852156B2 (en) | 2009-12-03 | 2017-12-26 | Google Inc. | Hybrid use of location sensor data and visual query to return local listings for visual query |
US8189964B2 (en) * | 2009-12-07 | 2012-05-29 | Google Inc. | Matching an approximately located query image against a reference image set |
US8489589B2 (en) * | 2010-02-05 | 2013-07-16 | Microsoft Corporation | Visual search reranking |
-
2010
- 2010-08-04 US US12/850,483 patent/US9135277B2/en active Active
- 2010-08-05 KR KR1020127006113A patent/KR101667346B1/en active IP Right Grant
- 2010-08-05 AU AU2010279333A patent/AU2010279333B2/en not_active Ceased
- 2010-08-05 CA CA3068761A patent/CA3068761C/en active Active
- 2010-08-05 JP JP2012523960A patent/JP2013501975A/en active Pending
- 2010-08-05 CN CN201080045164.6A patent/CN102625937B/en active Active
- 2010-08-05 BR BR112012002815A patent/BR112012002815B8/en active IP Right Grant
- 2010-08-05 WO PCT/US2010/044603 patent/WO2011017557A1/en active Application Filing
- 2010-08-05 EP EP10742974.8A patent/EP2462520B1/en active Active
- 2010-08-05 CA CA2771094A patent/CA2771094C/en active Active
- 2010-08-05 KR KR1020167020177A patent/KR101725885B1/en active IP Right Grant
-
2013
- 2013-05-17 AU AU2013205924A patent/AU2013205924B2/en active Active
-
2014
- 2014-02-18 US US14/183,001 patent/US10534808B2/en not_active Expired - Fee Related
- 2014-12-17 JP JP2014254872A patent/JP5933677B2/en active Active
-
2016
- 2016-03-15 JP JP2016050616A patent/JP6148367B2/en active Active
-
2018
- 2018-09-13 US US16/131,004 patent/US20190012334A1/en not_active Abandoned
Patent Citations (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP2008269628A (en) * | 1999-09-27 | 2008-11-06 | Mitsubishi Electric Corp | Image retrieval system and image retrieval method |
JP2005107978A (en) * | 2003-09-30 | 2005-04-21 | Nec Corp | Information retrieving device using information terminal with photographing function and information retrieving method |
JP2005215922A (en) * | 2004-01-29 | 2005-08-11 | Zeta Bridge Corp | Information retrieval system, information retrieval method, information retrieval apparatus, information retrieval program, picture recognition apparatus, picture recognition method and picture recognition program, and sales system |
US20080267504A1 (en) * | 2007-04-24 | 2008-10-30 | Nokia Corporation | Method, device and computer program product for integrating code-based and optical character recognition technologies into a mobile visual search |
Also Published As
Publication number | Publication date |
---|---|
JP6148367B2 (en) | 2017-06-14 |
US20190012334A1 (en) | 2019-01-10 |
CA3068761A1 (en) | 2011-02-10 |
JP2013501975A (en) | 2013-01-17 |
EP2462520B1 (en) | 2014-07-02 |
KR20120058538A (en) | 2012-06-07 |
JP5933677B2 (en) | 2016-06-15 |
US20110125735A1 (en) | 2011-05-26 |
AU2013205924A1 (en) | 2013-06-06 |
AU2010279333A1 (en) | 2012-03-15 |
US9135277B2 (en) | 2015-09-15 |
WO2011017557A1 (en) | 2011-02-10 |
BR112012002815B8 (en) | 2020-10-06 |
KR101725885B1 (en) | 2017-04-11 |
KR101667346B1 (en) | 2016-10-18 |
JP2015064901A (en) | 2015-04-09 |
AU2010279333B2 (en) | 2013-02-21 |
AU2013205924B2 (en) | 2015-12-24 |
US10534808B2 (en) | 2020-01-14 |
CA3068761C (en) | 2022-09-13 |
BR112012002815B1 (en) | 2020-06-09 |
EP2462520A1 (en) | 2012-06-13 |
KR20160092045A (en) | 2016-08-03 |
CA2771094C (en) | 2020-03-24 |
US20140164406A1 (en) | 2014-06-12 |
CN102625937A (en) | 2012-08-01 |
CA2771094A1 (en) | 2011-02-10 |
CN102625937B (en) | 2014-02-12 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
JP6148367B2 (en) | Architecture for responding to visual queries | |
JP6025812B2 (en) | User interface for presenting search results for multiple areas of a visual query | |
JP6470713B2 (en) | Method, system, and computer-readable storage device for providing search results based on images | |
US9087059B2 (en) | User interface for presenting search results for multiple regions of a visual query | |
US20110128288A1 (en) | Region of Interest Selector for Visual Queries | |
AU2016200659B2 (en) | Architecture for responding to a visual query |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
A977 | Report on retrieval |
Free format text: JAPANESE INTERMEDIATE CODE: A971007Effective date: 20161228 |
|
A131 | Notification of reasons for refusal |
Free format text: JAPANESE INTERMEDIATE CODE: A131Effective date: 20170110 |
|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20170405 |
|
TRDD | Decision of grant or rejection written | ||
A01 | Written decision to grant a patent or to grant a registration (utility model) |
Free format text: JAPANESE INTERMEDIATE CODE: A01Effective date: 20170424 |
|
A61 | First payment of annual fees (during grant procedure) |
Free format text: JAPANESE INTERMEDIATE CODE: A61Effective date: 20170518 |
|
R150 | Certificate of patent or registration of utility model |
Ref document number: 6148367Country of ref document: JPFree format text: JAPANESE INTERMEDIATE CODE: R150 |
|
S533 | Written request for registration of change of name |
Free format text: JAPANESE INTERMEDIATE CODE: R313533 |
|
R350 | Written notification of registration of transfer |
Free format text: JAPANESE INTERMEDIATE CODE: R350 |
|
R250 | Receipt of annual fees |
Free format text: JAPANESE INTERMEDIATE CODE: R250 |
|
R250 | Receipt of annual fees |
Free format text: JAPANESE INTERMEDIATE CODE: R250 |
|
R250 | Receipt of annual fees |
Free format text: JAPANESE INTERMEDIATE CODE: R250 |
|
R250 | Receipt of annual fees |
Free format text: JAPANESE INTERMEDIATE CODE: R250 |