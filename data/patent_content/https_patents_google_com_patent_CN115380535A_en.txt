CN115380535A - Multi-color lossless image compression - Google Patents
Multi-color lossless image compression Download PDFInfo
- Publication number
- CN115380535A CN115380535A CN202080099737.7A CN202080099737A CN115380535A CN 115380535 A CN115380535 A CN 115380535A CN 202080099737 A CN202080099737 A CN 202080099737A CN 115380535 A CN115380535 A CN 115380535A
- Authority
- CN
- China
- Prior art keywords
- color
- elements
- line
- image
- determining
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T9/00—Image coding
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/50—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding
- H04N19/593—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding involving spatial prediction techniques
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/70—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals characterised by syntax aspects related to video coding, e.g. related to compression standards
Abstract
A method, comprising: receiving an image targeted for compression into a compressed image; identifying a coding line comprising a plurality of elements, each element of the plurality of elements having a color; selecting an element from a plurality of elements from a coding line in an image; determining a presentation color associated with the selected element; comparing the rendered color to an expected color; and in response to determining that the rendered color is not the intended color, inserting a marker into a data structure representing a portion of the compressed image, the marker indicating that the rendered color is not the intended color, determining an encoded value corresponding to the rendered color, and inserting the encoded value into the data structure representing the compressed image.
Description
Technical Field
Embodiments relate to compressing and decompressing images.
Background
Group4 compression is a lossless compression algorithm used on some types of images. For example, group4 compression can be used on images with long strings of pixels having the same black or white color, and where the pixels in a row of pixels are very similar to the upper row. Group4 compression is effective for black and white colors.
Disclosure of Invention
In general aspects, an apparatus, a system, a non-transitory computer-readable medium (having computer-executable program code stored thereon that is executable on a computer system), and/or a method can perform a process with a method comprising: receiving an image targeted for compression into a compressed image; identifying a coding line comprising a plurality of elements, each element of the plurality of elements having a color; selecting an element from a plurality of elements from a coding line in an image; determining a presentation color associated with the selected element; comparing the rendered color to an expected color; and in response to determining that the rendered color is not the intended color, inserting a marker into a data structure representing a portion of the compressed image, the marker indicating that the rendered color is not the intended color, determining an encoding value corresponding to the rendered color, and inserting the encoding value into the data structure representing the compressed image.
Implementations can include one or more of the following features. For example, the indicia can be boolean. The coded lines can be at least a portion of a row of the image. The selected elements are capable of representing pixels of at least three (3) colors. Determining the encoding value corresponding to the presentation color can include: the method further includes looking up a presentation color in the palette, and setting the encoding value to an index value of the palette associated with the presentation color. Determining the encoding value corresponding to the presentation color can include: determining that a presentation color is not in the palette, inserting the presentation color into the palette, generating index values for the inserted presentation color, and setting the encoding values to the generated index values. Determining the encoding value corresponding to the presentation color can include: the method includes identifying a line in the image as a reference line, the reference line including a plurality of coding elements, determining that one of the plurality of coding elements in the reference line includes an expected color, and setting a coding value based on the one of the plurality of coding elements in response to determining that the one of the plurality of coding elements in the reference line includes the expected color.
Setting the encoding value based on one encoding element of the plurality of encoding elements can include: the method further includes identifying an encoding value of one of the plurality of encoding elements and setting the encoding value to the encoding value of the one of the plurality of encoding elements. Setting the encoding value based on the determined element can include: the method further includes identifying a position of one of the plurality of encoding elements in the reference line, and setting an encoding value based on the identified position. Setting the encoding value based on the identified position can include: the encoding value is set to a relative value based on the position of the selected element in the coding line and the position of the identified element in the reference line. The method can further include: selecting another element from a plurality of elements from a coding line in the image; determining whether the selected another element is the last element in the encoded line; and in response to determining that the selected other element is the last element in the encoded line, not inserting at least one of a flag and an encoded value into a data structure representing a portion of the compressed image.
In general aspects, an apparatus, a system, a non-transitory computer-readable medium (having computer-executable program code stored thereon that is executable on a computer system), and/or a method can perform a process with a method comprising: receiving a data structure representing an image to be decompressed, the image comprising a plurality of color elements; selecting an element to be decoded from a decoding line from the image; identifying an element in the data structure corresponding to the selected element; determining whether the selected element is an intended color; in response to determining that the selected element is the intended color, setting the decoded color of the selected element to the intended color; and in response to determining that the selected element is not the expected color, decoding the color of the selected element.
Implementations can include one or more of the following features. For example, the coded lines can be at least a portion of a row of the image. The first value can indicate that the color of the selected element is the intended color, and the second value can indicate that the color of the selected element is not the intended color. Decoding the color of the selected element can include: the index value associated with the selected element is looked up in the palette, and the decoded color of the selected element is set based on the index value. Decoding the color of the selected element can include: a line in the image is identified as a reference line, and it is determined that an element in the reference line includes a color of the selected element. Determining that the elements in the reference line include the color of the selected element can include: the position of the determined element in the reference line is identified, and the color of the selected element is set based on the determined position. The position can be based on the relative position of the selected element in the decoding line and the determined position of the element in the reference line.
Drawings
Example embodiments will become more fully understood from the detailed description given herein below and the accompanying drawings, wherein like elements are represented by like reference numerals, which are given by way of illustration only and thus do not limit example embodiments, and wherein:
fig. 1 illustrates a block diagram of signal flow in accordance with at least one example embodiment.
FIG. 2 illustrates a block diagram of elements in accordance with at least one example embodiment.
Fig. 3A illustrates a block diagram of an encoder system according to at least one example embodiment.
Fig. 3B illustrates a block diagram of an encoder in accordance with at least one example embodiment.
Fig. 4A illustrates a block diagram of a decoder system according to at least one example embodiment.
Fig. 4B illustrates a block diagram of a decoder according to at least one example embodiment.
Fig. 5A illustrates a block diagram of a method for encoding a color image, according to at least one example embodiment.
Fig. 5B illustrates a block diagram of a method for encoding a color image according to at least one example embodiment.
Fig. 6A illustrates a block diagram of a method for decoding a color image, according to at least one example embodiment.
Fig. 6B illustrates a block diagram of a method for decoding a color image, according to at least one example embodiment.
FIG. 7 illustrates an example of a computer device and a mobile computer device according to at least one example embodiment.
It should be noted that these figures are intended to illustrate the general characteristics of the methods, structures and/or materials utilized in certain example embodiments and to supplement the written description provided below. However, the drawings are not to scale and may not accurately reflect the precise structural or performance characteristics of any given embodiment, and should not be construed as defining or limiting the scope of values or attributes encompassed by example embodiments. For example, the relative thicknesses and positioning of molecules, layers, regions and/or structural elements may be reduced or exaggerated for clarity. The use of similar or identical reference numbers in the various figures is intended to indicate the presence of similar or identical elements or features.
Detailed Description
Compression algorithms can be used to compress the image. These typical compression algorithms can result in relatively large file sizes after image compression.
To achieve higher compression rates, group4 compression can be used for images that have characteristics that make them suitable for Group4 compression. However, these images can have more than two (2) colors. Thus, group4 compression, which can be used to compress black and white images, can be adapted to compress these images with more than two colors.
Example embodiments described herein compande Group4 for use on images with more than two (2) colors. For example, a change element can be defined as an element (e.g., a pixel) having a color that is different from the color of a previous element in the same row of the image. In response to determining that the element is a change element, an encoding event can be triggered. The encoding event can include assigning a color value (e.g., a three (3) byte value) to represent the color. Assigning color values when a color of an element (e.g., pixel) changes, rather than merely indicating a color change, can have the advantage of efficiency in using Group4 compression techniques on multi-color images, and can result in relatively small compressed file sizes.
Fig. 1 illustrates a block diagram of signal flow according to at least one example embodiment. As shown in FIG. 1, signal stream 100 includes an element selection 105 block, an element comparison 110 block, an element matching 115 block, and an element coding 120 block. The signal stream 100 may be configured to receive an input image 5 (and/or video stream) and output compressed (e.g., encoded) bits 10. In some embodiments, the image 5 (or portions thereof) can include consecutive pixels (in rows and/or columns) having the same and/or similar colors. Group4 compression can be an efficient (e.g., less processor usage, less memory usage, etc.) compression technique for images that include consecutive pixels (by rows and/or by columns) having the same and/or similar colors.
The element selection 105 block can be configured to select elements (e.g., pixels) to compress. In an example embodiment, the compression order can be row by row and pixel by row. In other words, it is possible to select rows in the image for compression and then select pixels in left-to-right (or right-to-left) order.
The element comparison 110 block can be configured to compare the color of the current (e.g., selected (e.g., target, current) element to be compressed) with the color of the previous (already compressed) element. For example, the color of the second element in a row can be compared to the color of the first element in a row, the color of the third element in a row can be compared to the color of the second element in a row, the color of the fourth element in a row can be compared to the color of the third element in a row, and so on. If the selected element to be compressed is the first element in a row, the color of the selected element can be compared to the white color.
The element matching 115 block can be configured to identify elements (except for the previous element) that have the same color as the selected element. The element matching 115 block can be configured to identify elements in the same row or different rows as selected elements. For example, the identified element can be in a row above (e.g., a row that has been compressed), an element in the same row that has been compressed (excluding a previous element), and so on.
The element coding 120 block can be configured to encode the color of the selected element. In an example embodiment, if the color of the selected element is the same color as the color of the previous element, encoding the selected element can include identifying (e.g., using a flag) the selected element as being the same as the previous element (e.g., using a boolean value (e.g., one (1) or zero (0))). Encoding the selected element can include identifying a color if the color of the selected element is not the same color as the color of the previous element. For example, the index values of a lookup table (e.g., a palette) can be used to identify the color of the selected pixel or a reference value (from the element match 115 block) that associates the color of the selected element with the matching element can be used to identify the color of the selected pixel. The index value can be used as an encoding value associated with the color. Other encoding techniques are described in more detail below.
FIG. 2 illustrates a block diagram of elements according to at least one example embodiment. The elements can be pixels in an image (e.g., image 5). The block diagram 200 includes two rows and a plurality of columns. The bottom row can be the coded line 210 and the top row can be the reference line 220. The coding line 210 includes a plurality of elements (e.g., pixels), each element having an associated color. The coded line 210 includes elements of three (3) colors (shown as an example). The coding line 210 includes elements 230 of a first color, elements 240 of a second color, and elements 250 of a third color.
The coding line 210 further includes three (3) identified elements. The identified element can be a variant element. Identified element a 0 Can be a reference or start change element on the coded line 210. The change element can be an element (e.g., a pixel) that is a different color than the color of the previous element in the same row of the image (e.g., image 5). At the beginning of the coding line 210, the identified element a can be set based on the white-changing element (e.g., non-existent element) that is located just before the first element on the coding line 210 0 . During the coding of the coding line 210, the identified element a can be defined by a coding pattern (described below) 0 The position of (a). Identified element a 1 Can be at a on the coded line 210 0 The next change element on the right. Identified element a 2 Can be at a on the coded line 210 1 The next change element on the right.
The reference line 220 includes a plurality of elements (e.g., pixels), each element having an associated color. Reference line 220 includes elements of three (3) colors (shown as an example). Reference line 220 includes elements 260 of a fourth color (among two sets of elements), elements 230 of the first color, and elements 240 of the second color.
The modified group4 compression technique can include three (3) coding modes. Can be based on a 1 The position in the coding line determines the coding mode. In a first mode (sometimes referred to as a pass-through mode), a1 (the next change pixel on the coded line 210) is in b in the reference line 220 2 (in b) 1 The next change element on the right) in the column on the right. In the first mode, the next iteration of the algorithm will be a 0 (in the code)In the wire 210) is set to b (of the reference line 220) 2 The column (c). a is 0 The color of (a) is unchanged. Thus, the signal has no color change. Can utilize a 0 The process is repeated for the new location.
In the second mode (sometimes referred to as the vertical mode), a 1 Column in b (in the coding line 210) 1 Within a plurality of elements (e.g., pixels) (in reference line 220). In the second mode, the offset can be encoded. The offset can be positive or negative. For example, a 1 Is in a position of b 1 Plus or minus an offset. The offset can be within a predetermined range (e.g., +/-3 elements). A boolean value (e.g., 0 or 1) can be used to signal a (e.g., using a flag) 1 Whether the color of (a) is different from the intended color. The desired color can be defined as b 1 The color of (c). If there is no previous row (coding line 210 is the first row), or at a on reference line 220 0 The right side has no color of a 0 Of elements (e.g. pixels) of different colors, b 1 Is not defined, the expected color can be set to be the same as a 0 Is different from any color of (a). For example, an algorithm common to the encoder and the decoder can be used.
In an example embodiment, a palette can be used. For example, the desired color can be set to be a of the color palette 0 Is different from the first color. If a is 1 Is different from the expected color, the color of a1 can be encoded based on an index in the palette, a list of recent colors, the red, green, blue values of the new color, the delta between the color and the red, green, and blue values of the previous color, and the like. a is 0 The new position (in the coding line 210) can be set to a 1 The location (in the coded line 210). Can utilize a 0 The process is repeated for the new location.
In the third mode (sometimes referred to as the horizontal mode), a 1 Can be located in a location (in the coded line 210) that does not satisfy the definition of the first pattern or the second pattern. In the third mode, a 0 And a 1 The distance between can be encoded as a distance in the range [1; distance between two adjacent plates(a 0 ,b 2 )]A value (e.g., an integer) of (a). If the end (e.g., last column) of the encoding line 210 has not been reached, a 1 And a 2 The distance between can be encoded as the range [1; distance (a) 1 ,end_of_line)]A value (e.g., an integer) of (1).
Furthermore, in the third mode, a can be signaled using the same techniques as described above with respect to the second mode 1 The color of (c). A boolean value (e.g., 0 or 1) can be used to signal a (e.g., using a flag) 1 Whether the color of (a) is different from the intended color. The desired color can be defined as b 1 The color of (c). If there is no previous row (coding line 210 is the first row), or at a on reference line 220 0 The right side has no color of a 0 Of different colors, b 1 Is not defined, the expected color can be set to be the same as a 0 Is different from any color of (a). For example, an algorithm common to the encoder and the decoder can be used. In an example embodiment, a palette can be used. For example, the desired color can be set to be a of the color palette 0 Is different from the first color. If a is 1 Is different from the expected color, a can be encoded based on an index in the palette, a list of recent colors, the red, green, blue values of the new color, the delta between the color and the red, green, and blue values of the previous color, and so on 1 The color of (c).
Can similarly encode a 2 The color of (c). A Boolean value (e.g., 0 or 1) is used to signal a (e.g., using a flag) 2 Whether the color of (a) is different from the intended color. The desired color can be defined as b 2 The color of (c). If there is no previous row (coding line 210 is the first row), or b on reference line 220 1 The right side has no color of a 1 Of different color elements (e.g. pixels), b 2 Is not defined, the expected color can be set to be the same as a 1 Is different from any color of (a). In an example embodiment, the desired color can be set to a 0 Color of (b) 2 The next color on the right, etc. If a is 2 Is different from the expected color, can be used for a 2 The actual color of the image is encoded. a is a 0 The new position (in the coding line 210) can be set to a 2 The location (in the coded line 210). Can utilize a 0 The process is repeated for the new location. In all three modes, if the end of the coding line 210 has been reached, the coding can continue with the next line.
Fig. 3A illustrates an encoder system in accordance with at least one example embodiment. As shown in fig. 3A, the encoder system 300 includes at least one processor 305, at least one memory 310, a controller 320, and an encoder 325. The at least one processor 305, the at least one memory 310, the controller 320, and the encoder 325 are communicatively coupled via a bus 315.
In the example of fig. 3A, encoder system 300 may be or include at least one computing device, and should be understood to represent virtually any computing device configured to perform the techniques described herein. Accordingly, encoder system 300 may be understood to include various components that may be used to implement the techniques described herein, or different or future versions thereof. By way of example, the encoder system 300 is illustrated as including at least one processor 305 and at least one memory 310 (e.g., a non-transitory computer-readable storage medium).
The at least one processor 305 may be used to execute instructions stored on the at least one memory 310. Thus, the at least one processor 305 is capable of implementing the various features and functions described herein, or additional or alternative features and functions. The at least one processor 305 and the at least one memory 310 may be used for various other purposes. For example, the at least one memory 310 may represent examples of various types of memory and associated hardware and software that may be used to implement any of the modules described herein.
The at least one memory 310 may be configured to store data and/or information associated with the encoder system 300. The at least one memory 310 may be a shared resource. For example, the encoder system 300 may be an element of a larger system (e.g., a server, a personal computer, a mobile device, etc.). Thus, the at least one memory 310 may be configured to store data and/or information associated with other elements within the larger system (e.g., image/video services, web browsing, or wired/wireless communications).
The controller 320 may be configured to generate and communicate various control signals to various blocks in the encoder system 300. The controller 320 may be configured to generate control signals to implement the techniques described herein. According to an example embodiment, the controller 320 may be configured to control the encoder 325 to encode an image, a sequence of images, a video frame, a sequence of video frames, or the like. For example, the controller 320 may generate a control signal corresponding to the selection of the encoding mode.
The encoder 325 may be configured to receive an input image 5 (and/or video stream) and output compressed (e.g., encoded) bits 10. The encoder 325 may convert the video input into discrete video frames (e.g., as images). The input image 5 may be compressed (e.g., encoded) into compressed image bits. The encoder 325 may further convert each image (or discrete video frame) into a CxR matrix of blocks or macroblocks (hereinafter referred to as blocks). For example, the image may be converted into a 32x32, 32x16, 16x8, 8x8, 4x4, or 2x2 matrix of blocks, each block having a plurality of pixels. Although eight (8) example matrices are listed, example embodiments are not so limited.
Further, encoder 325 may encode at least one block of the CxR matrix of blocks using a modified Group4 technique. In other words, the encoder may not use the same encoding technique for the entire image (e.g., image 5). Thus, the modified Group4 technique can be used to encode an image and/or a portion of an image (e.g., a block, a plurality of blocks, etc.). In an example implementation, a modified Group4 technique can be used to encode each block of the CxR matrix of blocks, and a portion of the encoded blocks can be selected to be included in a compressed file representing an image. The portion can be selected based on compression performance, results, file size, etc.
The compressed bits 10 may represent the output of the encoder system 300. For example, the compressed bits 10 may represent an encoded image (or video frame). For example, compressed bits 10 may be stored in a memory (e.g., at least one memory 310). For example, the compressed bits 10 may be ready for transmission to a receiving device (not shown). For example, the compressed bits 10 may be transmitted to a system transceiver (not shown) for transmission to a receiving device.
The at least one processor 305 may be configured to execute computer instructions associated with the controller 320 and/or the encoder 325. At least one processor 305 may be a shared resource. For example, the encoder system 300 may be an element of a larger system (e.g., a mobile device, a server, etc.). Thus, at least one processor 305 may be configured to execute computer instructions associated with other elements within the larger system (e.g., image/video services, web browsing, or wired/wireless communications).
Fig. 3B illustrates a block diagram of an encoder 325 according to at least one example embodiment. As shown in fig. 3B, the encoder 325 can include an element selection 105 block, an element comparison 110 block, an element matching 115 block, an element coding 120 block, and a palette 330 block. During selection of a color (e.g., index number) associated with encoding an element, the element coding 120 block can use the palette 330. In other words, the index number can be an encoded value corresponding to a color.
The color palette 330 can include a plurality of index colors. The color can be channel-based (e.g., red, green, and blue alone) or based on a combination of colors (e.g., red, green, and blue together). For example, the palette 330 can be a lookup table with n (e.g., 8, 16, 32, 256, 512) rows, where each row is indexed to a color combination. For example, the palette 330 can be a lookup table of each color (e.g., red, green, blue) with n (e.g., 8, 16, 32, 256, 512) rows, where each row is indexed to a separate color value (e.g., a value in the range of 0-255).
The color palette 330 can be preset (e.g., color and/or color combination) prior to encoding. A color palette 330 can be generated for each image (e.g., image 5). For example, when a color of an element (e.g., a change element) first appears, the color can be added to palette 330 and indexed sequentially (e.g., next number in integer order). The color palettes can be ordered based on the frequency of occurrence of the colors (e.g., the more frequently a color is seen, the earlier the color is in the look-up table). The palette 330 can be color (e.g., three (3) channels or three (3) dimensions) and/or grayscale (e.g., single channel or one (1) dimension).
In an example implementation, the element comparison 110 block can determine that an element (e.g., a pixel) is a changed element (e.g., a different color than a previously encoded element). In response to determining that an element is a change element, element coding 120 block can search color palette 330 for a color (e.g., a combination of colors, each individual color (three channels), an individual color (one channel)) and determine an index value (e.g., at least one integer value) for the color. The index value can be used to represent the color in the compressed image data structure. In other words, the index value can be used as an encoding value corresponding to the color of the element.
Fig. 4A illustrates a block diagram of a decoder system according to at least one example embodiment. As shown in fig. 4A, the decoder system 400 includes at least one processor 405, at least one memory 410, a controller 420, and a decoder 425. The at least one processor 405, the at least one memory 410, the controller 420, and the decoder 425 are communicatively coupled via a bus 415.
In the example of fig. 4A, decoder system 400 may be at least one computing device and should be understood to represent virtually any computing device configured to perform the techniques described herein. Accordingly, the decoder system 400 may be understood to include various components that may be used to implement the techniques described herein, or different or future versions thereof. For example, the decoder system 400 is illustrated as including at least one processor 405 and at least one memory 410 (e.g., a computer-readable storage medium).
Thus, the at least one processor 405 may be used to execute instructions stored on the at least one memory 410. Thus, the at least one processor 405 may be capable of implementing the various features and functions described herein, or additional or alternative features and functions. The at least one processor 405 and the at least one memory 410 may be used for various other purposes. For example, the at least one memory 410 may be understood to represent examples of various types of memory and associated hardware and software that can be used to implement any of the modules described herein. According to an example embodiment, the encoder system 300 and the decoder system 400 may be included in the same larger system (e.g., personal computer, mobile device, etc.).
The at least one memory 410 may be configured to store data and/or information associated with the decoder system 400. The at least one memory 410 may be a shared resource. For example, the decoder system 400 may be an element of a larger system (e.g., a personal computer, mobile device, etc.). Thus, the at least one memory 410 may be configured to store data and/or information associated with other elements within the larger system (e.g., web browsing or wireless communications).
The controller 420 may be configured to generate and transmit various control signals to various blocks in the decoder system 400. The controller 420 may be configured to generate control signals to implement the video encoding/decoding techniques described herein. According to an example embodiment, the controller 420 may be configured to control the decoder 425 to decode the video frames.
The decoder 425 may be configured to receive compressed (e.g., encoded) bits 10 as input and output an image 5. Compressed (e.g., encoded) bits 10 may also represent compressed video bits (e.g., video frames). Thus, decoder 425 may convert the discrete video frames of compressed bits 10 into a video stream. The decoder 425 can be configured to decompress (e.g., decode) the image compressed using the modified Group4 compression technique. Thus, decoder 425 can be configured to implement a modified Group4 decompression technique. In other words, decoder 425 can be a modified Group4 decoder.
The at least one processor 405 may be configured to execute computer instructions associated with the controller 420 and/or the decoder 425. At least one processor 405 may be a shared resource. For example, decoder system 400 may be an element of a larger system (e.g., a personal computer, mobile device, etc.). Thus, at least one processor 405 may be configured to execute computer instructions associated with other elements within the larger system (e.g., web browsing or wireless communication).
According to an example embodiment, the portion of the data structure (e.g., compression bits 10) generated using the modified Group4 compression technique may be n, 1, x 1 N, where 1 represents a change, x identifies the color of the element that changed, and n represents the number of elements in the same color. Thus, the modified Group4 decompression technique can be configured to determine the sum of x 1 The associated color.
Fig. 4B illustrates a block diagram of a decoder 425 according to at least one example embodiment. Decoder 425 can be a modified Group4 decoder. As shown in fig. 4B, decoder 425 includes an element decoder 430 block, an image generator 435 block, and a palette 330 block. The element decoder 430 can be configured to determine whether the compressed image element is the same color as the previous element (e.g., boolean 0 from the above example) or a different color than the previous element (e.g., boolean 1 from the above example).
In response to the element decoder 430 determining that the colors are the same color, the element decoder 430 transmits color information representing the same color to the image generator 435. In response to element decoder 430 determining that the colors are not the same color, element decoder 430 looks up the color in the palette using, for example, an index value, and passes color information representing the color returned from the look-up operation to image generator 435.
The image generator 435 can be configured to generate an image based on the color information received from the element decoder 430. For example, the image generator 436 can insert color values (e.g., red, green, and blue) into the data structure based on the element locations (e.g., rows and columns) representing the image. The image generator 435 can output the generated image as an image 5 (e.g., a reconstructed image 5).
Fig. 5A, 5B, 6A, and 6B illustrate block diagrams of a method according to at least one example embodiment. The steps described with respect to fig. 5A, 5B, 6A, and 6B may be performed as a result of execution of software code stored in a memory (e.g., at least one memory 310, 410) associated with an apparatus (e.g., as shown in fig. 3A and 4A) and executed by at least one processor (e.g., at least one processor 305, 405) associated with the apparatus. However, alternative embodiments are envisioned, such as a system embodied as a dedicated processor. Although the steps described below are described as being performed by a processor, the steps are not necessarily performed by the same processor. In other words, the at least one processor may perform the steps described below with respect to fig. 5A, 5B, 6A, and 6B.
Fig. 5A illustrates a block diagram of a method for encoding a color image according to at least one example embodiment. A method for encoding a color image can be triggered to compress (e.g., encode) the image in response to receiving the image (e.g., image 5) that includes a plurality of color elements (e.g., pixels). As shown in fig. 5A, a reference line is selected in step S505. For example, an image (e.g., image 5) can include a plurality of rows (R) and a plurality of columns (C). The reference line can be one of the rows (R). Alternatively or additionally, the image can be decomposed into a CxR matrix of blocks or macroblocks (referred to as blocks). The reference line can be at least one row (R) in the matrix of blocks.
In step S510, a coding line is selected. For example, an image (e.g., image 5) can include a plurality of rows (R) and a plurality of columns (C). The coded line can be one of the rows (R). Alternatively or additionally, the image can be decomposed into a CxR matrix of blocks or macroblocks (referred to as blocks). The coding line can be at least one row (R) in the matrix of blocks. In an example embodiment, the coding line is below the reference line (see fig. 2). In the case where the coded line is the first row in an image or block, the reference line can be a row of elements (e.g., pixels) having a default color (e.g., white).
In step S515, a color change in the reference line is identified. For example, each color change (from (or not including) the first color in the reference line) can be determined. Referring to fig. 2, b can be located 1 And b 2 . Note that more than two (2) color changes can be found, and b 1 And b 2 NomenclatureCan be based on a coded line color change (e.g., a) 1 ). Locating the color change can include stepping (via software code) through each element (e.g., pixel) in the reference line and comparing the color of the element to the color of the previous element. Responsive to determining that the colors are different, the element is identified as a changed element (e.g., b of FIG. 2) 1 And b 2 )。
In step S520, a color change in the coded line is identified. For example, each color change (including the first color in the coded line) can be determined. Referring to FIG. 2, a can be located 0 、a 1 And a 2 . Note that more than three (3) color changes can be found. Locating the color change can include stepping (via software code) through each element (e.g., pixel) in the coded line and comparing the color of the element to the color of the previous element. In response to determining that the colors are different, the element is identified as a changed element (e.g., a of FIG. 2) 0 、a 1 And a 2 )。
In step S525, elements in the reference line and the coded line are selected based on the identified color variations. The identified element can be a variant element. The identified elements can be the variant elements used in the iteration of the encoding algorithm. For example, the selected element can be a first element (e.g., a in FIG. 2) 0 ) A second coded line element (e.g., a in FIG. 2) 1 ) A third coded line element (e.g., a in FIG. 2) 2 ) First reference line element (e.g., b in FIG. 2) 1 ) And a second reference line element (e.g., b in FIG. 2) 2 )。
In step S530, the positions of the selected elements are compared. For example, a 1 The position (e.g., column) in the coded line 210 can be compared to b 2 The locations (e.g., columns) in the reference line 220 are compared. For example, a can be 1 Location (e.g., column) and b in the coded line 210 1 The locations (e.g., columns) in the reference line 220 are compared. The results of the comparison can be used to identify (or determine) the code (e.g., one (1) of three (3) patterns).
In step S535Identifying the encoding mode based on the comparison. For example, if a 1 The position (e.g., column) in the coded line 210 is b 2 To the right of the position (e.g., column) in the reference line 220, then the encoding mode can be the first (e.g., pass through) encoding mode. If a is 1 The position (e.g., column) in the coded line 210 is close (e.g., within multiple columns or ranges of columns) to b 1 At a position (e.g., column) in the reference line 220, the encoding mode can be a second (e.g., vertical) encoding mode. Otherwise, the coding mode can be a third (e.g., horizontal) coding mode.
In the first mode, there is no color change. In the first mode (sometimes referred to as pass-through mode), a 1 (the next change pixel on the coded line 210) is located in the reference line 220 at b 2 (b 1 The next change element on the right) in the column on the right. In the first mode, the next iteration of the algorithm will be a 0 The new position setting (in the coding line 210) is b 2 Column (in reference line 220). a is a 0 The color of (a) is unchanged. Thus, the signal has no color change. Can utilize a 0 The process is repeated for the new location.
In the second mode (sometimes referred to as the vertical mode), a 1 Column in b (in the coding line 210) 1 Within a plurality of elements (e.g., pixels) (in reference line 220). In the second mode, the offset and color can be encoded. In a second mode, a boolean value (e.g., 1 or 0) can be set to signal (e.g., using a flag) that the colors are different, and the encoding event can encode the colors of the elements (e.g., pixels) as, for example, indices in a palette, in a list of recently used colors, channel (e.g., RGB) values, channel delta (e.g., compared to previously encoded elements), and so on.
In the third mode (sometimes referred to as the horizontal mode), a 1 Can be located in a location (in the coded line 210) that does not satisfy the definition of the first pattern or the second pattern. In the third mode, a is used in addition to encoding the elements (as in the first mode) 2 Color of (b) and 2 are different in color. In response to determining a 2 Color of (b) and 2 can set a boolean value (e.g., 1 or 0) to signal (e.g., using a flag) that the color is different and can be for a 2 Is encoded (e.g., as in the first mode).
Fig. 5B illustrates a block diagram of a method for encoding a color image according to at least one example embodiment. As shown in fig. 5B, in step S545, in the second mode (step S540), an offset based on the selected element is encoded. In the second mode (sometimes referred to as the vertical mode), a 1 Column b (in the coding line 210) 1 Within a plurality of elements (e.g., pixels) (in reference line 220). The offset can be positive or negative. For example, a 1 Is at a position of 1 Plus or minus an offset. The offset can be within a predetermined range (e.g., +/-3 elements).
In step S550, it is determined whether the color of the selected element is an intended color. For example, in an example embodiment, the elements can be pixels. Each pixel can have corresponding colors (e.g., three (3) channels or three (3) dimensions) red, green, and blue and/or shades (e.g., single channel or one (1) dimension) of gradation ranging from black to white. Comparing the color (e.g., the color of the selected element to the expected color) can include determining the color of the element and comparing the determined color.
A boolean value (e.g., 0 or 1) can be used to signal a (e.g., using a flag) 1 Whether the color of (a) is different from the intended color. In an example embodiment, the desired color can be defined as b 1 The color of (c). If there is no previous row (coding line 210 is the first row), or at a on reference line 220 0 The right side has no color of a 0 Of elements (e.g. pixels) of different colors, b 1 Is not defined, the expected color can be set to be the same as a 0 Is different from any color. In an alternative embodiment, the color of the selected element can be compared to elements preceding (e.g., just to the left of) the selected element. If the color of the selected element is not the desired color, thenThe process proceeds to step S555. If the color of the selected element is the expected color, a Boolean value (e.g., boolean 0) indicating that the color is consistent with the expected can be inserted in the coded data structure (e.g., as a flag) and the process continues to step S595.
In step S555, the color of the selected element is encoded. For example, an algorithm common to the encoder and the decoder can be used. For example, a color can be encoded as an index value (e.g., as an encoded value) selected from a palette (e.g., palette 330).
A palette (e.g., palette 330) can include a plurality of index colors. The color can be channel-based (e.g., red, green, and blue alone) or based on a combination of colors (e.g., red, green, and blue together). For example, the palette can be a lookup table with n (e.g., 8, 16, 32, 256, 512) rows, where each row is indexed to a color combination. For example, the palette can be a lookup table of each color (e.g., red, green, blue) with n (e.g., 8, 16, 32, 256, 512) rows, where each row is indexed to a separate color value (e.g., a value in the range of 0-255).
The color palette (e.g., color and/or combination of colors) can be preset prior to encoding. A color palette can be generated for each image (e.g., image 5). For example, when a color of an element (e.g., a change element) first appears, the color can be added to the palette and indexed sequentially (e.g., next number in integer order). The color palettes can be ordered based on the frequency of occurrence of the colors (e.g., the more frequently a color is seen, the earlier the color is in the look-up table). The palette can be color (e.g., three (3) channels or three (3) dimensions) and/or grayscale (e.g., single channel or one (1) dimension).
The palette can be searched for the determined color of the selected palette (e.g., a lookup process, a filtering process, etc.). If the determined color of the selected element is located, an index number for the located color can be returned and used to encode the element. In an example embodiment, if the determined color of the selected element is not located, the determined color can be added to the palette and assigned a new index number. A new index number for the added color can be returned and used to encode the element. In this embodiment, the palette can be stored with the compressed image (e.g., in a header as metadata).
In an example embodiment, it is determined whether the reference line includes an element having the same color as the selected element (in the coded line). If the reference line includes elements having the same color, the color of the selected element can be encoded based on the elements in the reference line. For example, the same palette index number as the element in the reference line can be used in the encoding. For example, the relative position of the element in the reference line (e.g., the same column (C), the number of columns on the left side, the number of columns on the right side, etc.) can be used in the encoding (as compared to the selected element).
In an example embodiment, it is determined whether the coded line includes a previously encoded element having the same color as the selected element. If the coded line includes elements having the same color, the color of the selected element can be encoded based on the elements in the coded line. For example, the same palette index numbers as the elements in the coding line can be used in the encoding. For example, the relative position of the elements in the coding line (e.g., the number of columns (C) on the left) can be used in the encoding (as compared to the selected elements).
In an example embodiment, it can be determined whether the selected element has some of the same color as the previous element. For example, whether red, green or blue is changed, and the other colors remain the same in the selected element as the previous element. If the selected element has a color that is somewhat the same as the previous element, the color of the selected element can be encoded based on color similarity. For example, values of colors (e.g., 0 to 255), integer differences (e.g., +/-n), etc. can be used in the encoding.
In step S560, in the third mode (step S540), the selection of the element based on the selected element is performedThe distance is encoded. In the third mode (sometimes referred to as the horizontal mode), a 1 Can be located in a location (in the coded line 210) that does not satisfy the definition of the first pattern or the second pattern. In the third mode, a 0 And a 1 The distance between can be encoded as the range [1; distance (a) 0 ,b 2 )]Distance (e.g., an integer). If the end (e.g., last column) of the encoded line 210 has not been reached, then a 1 And a 2 The distance between can be encoded as the range [1; distance (a) 1 ,end_of_line)]Distance (e.g., an integer).
In step S565, it is determined whether the color of the selected element is the intended color. For example, in an example embodiment, the elements can be pixels. Each pixel can have corresponding colors (e.g., three (3) channels or three (3) dimensions) red, green, and blue and/or shades (e.g., single channel or one (1) dimension) of gradation ranging from black to white. Comparing the color (e.g., the color of the selected element to the expected color) can include determining the color of the element and comparing the determined color.
A boolean value (e.g., 0 or 1) can be used to signal a (e.g., using a flag) 1 Whether the color of (a) is different from the intended color. In an example embodiment, the desired color can be defined as b 1 The color of (c). If there is no previous row because (the coded line 210 is the first row), or at a on the reference line 220 0 The right side has no color of a 0 Of different colors, b 1 Is not defined, the expected color can be set to be the same as a 0 Is different from any color of (a). If the color of the selected element is not the intended color, the process continues to step S570. If the color of the selected element is the expected color, a Boolean value (e.g., boolean 0) indicating that the color is consistent with the expected can be inserted (e.g., as a flag) in the encoded data structure (e.g., as a flag), and the process continues to step S575.
In step S570, in the third mode (step S540), the color of the selected element is encoded. As in step S555, the color of the selected element can be encoded as an index value selected from a palette (e.g., palette 330), encoded based on the color of the element in the reference line, and/or encoded based on the color of the element in the coding line.
In step S575, another element in the coded line is selected. For example, the next change element can be selected (e.g., a in FIG. 2) 2 ) In the next change element (e.g., a in FIG. 2) can be selected 2 ) The previous (e.g., left) element, and/or the last element in the row (R) can be selected.
In step S580, in the third mode (step S540), the distance based on the selected element is encoded. In the third mode (sometimes referred to as the horizontal mode), a 1 Can be located in a position (in the coded line 210) that does not satisfy the definition of the first pattern or the second pattern. In the third mode, a 0 And a 1 The distance between can be encoded as a distance in the range [1; distance (a) 0 ,b 2 )]Distance (e.g., an integer). If the end (e.g., last column) of the encoded line 210 has not been reached, then a 1 And a 2 The distance between can be encoded as a distance between the range [1; distance (a) 1 ,end_of_line)]Distance (e.g., an integer).
In step S585, it is determined whether the color of the other element is the intended color. For example, in an example embodiment, the elements can be pixels. Each pixel can have corresponding colors (e.g., three (3) channels or three (3) dimensions) red, green, and blue and/or shades (e.g., single channel or one (1) dimension) of gradation ranging from black to white. Comparing the color (e.g., the color of the selected element to the expected color) can include determining the color of the element and comparing the determined color.
A boolean value (e.g., 0 or 1) can be used to signal (e.g., using a flag) whether another color is different from the intended color. The desired color can be defined as b 2 The color of (c). If there is no previous row (coding line 210 is the first row), or b on reference line 220 1 The right side has no color of a 1 Elements of different colors(e.g., pixel), b 2 Is not defined, the expected color can be set to be the same as a 1 Is different from any color of (a). In an example embodiment, the desired color can be set to a 0 Color of (b) 2 The next color on the right, etc. If a is 2 Is different from the expected color, can be used for a 2 The actual color of the image is encoded.
If the color does not match the expectation (step S585), the other elements are encoded as described above (step S590). For example, other elements can be encoded based on index values of a palette (e.g., palette 330). If the color is consistent with the expectation (step S585), the process continues to step S595.
In step S595, it is determined whether the selected element (or the selected further element) is the last element in the row (e.g. in the coded line). For example, a line can include a flag indicating the last element, a line length (or position) counter can be used, and so forth. If the selected element is the last element in the line, the process continues to step S505. Otherwise, the process proceeds to step S525. It can also include a test for the end of the image file, which can result in the compression of the image (e.g., image 5) being complete.
In an example embodiment, encoding of boolean and/or color (e.g., palette indices) can be accomplished using entropy coding, where probabilities are encoded in a compressed data structure (or bitstream). In an example embodiment, encoding (e.g., not inserting into the data structure) of the change elements (boolean, color, and/or palette indices) can be omitted if the end of the row has been reached.
Fig. 6A illustrates a block diagram of a method for decoding a color image according to at least one example embodiment. The method for decoding a color image can be triggered in response to receiving a file comprising a data structure representing a compressed image (e.g., compressed bits 10) comprising a plurality of color elements (e.g., pixels) used to generate (e.g., decompress, encode) a reconstructed image (e.g., image 5). As shown in fig. 6A, a reference line is selected in step S605. For example, an image (e.g., image 5) can include a plurality of rows (R) and a plurality of columns (C). In the decoding process, the picture can be an element of size CxR having a default color (e.g., white). The size of the image can be based on the size of the compressed image. The reference line can be one of the rows (R). Alternatively or additionally, the image can be decomposed into a CxR matrix of blocks or macroblocks (referred to as blocks). The reference line can be at least one row (R) in the matrix of blocks.
In step S610, a decoding line is selected. For example, an image (e.g., image 5) can include a plurality of rows (R) and a plurality of columns (C). The decode line can be one of the rows (R). Alternatively or additionally, the image can be decomposed into a CxR matrix of blocks or macroblocks (referred to as blocks). The decoding line can be at least one row (R) in a matrix of blocks. In an example embodiment, the coding line is below the reference line (see fig. 2). In the case where the coded line is the first row in an image or block, the reference line can be a row of elements (e.g., pixels) having a default color (e.g., white).
In step S615, an element to be decoded is selected from the decoding line. For example, the first element, the second element, the third element, \8230;, can be selected from left to right in a certain order. The selected element can be initially the first element (e.g., in a row in an image (or block)) and then the subsequent elements in turn. In an example embodiment, modes (e.g., mode one (1), mode two (2), mode three (3), etc.) can determine the sequential order. For example, in schema one, the next element can be the next sequential element. However, in schema two and/or schema three, the next element can be two or more elements after the current element. Selecting an element can include identifying a corresponding element in the data structure.
In step S620, a mode for decoding the element is determined. For example, the mode used to decode the element can be the mode used when the element is encoded. The data structure representing the compressed image can include a value indicating a mode for encoding the element. For example, in the first mode (sometimes referred to as the pass-through mode), there is no color change. In the second mode (sometimes referred to as vertical mode) and the third mode (sometimes referred to as horizontal mode), there can be a color change (compared to the previous element). If the mode is determined to be the first mode, the process continues to step S665 and no color needs to be decoded. If the mode is determined to be the second mode, the process proceeds to step S625, which starts the color decoding process. If the mode is determined to be the third mode, the process proceeds to step S630, which starts the color decoding process.
In step S625, the offset is read and the counter (N) is set to one (1) because the color of one (1) element is to be decoded. For example, the offset can be a positive or negative number. For example, referring to FIG. 2, a 1 Is in a position of b 1 Plus or minus an offset. The offset can be within a predetermined range (e.g., +/-3 elements). The offset can be read from the data structure representing the compressed image. The offset can be used to determine the color of the element using an inverse algorithm used in the encoder. The process proceeds to step S635 (see fig. 6B).
In step S630, the distance is read and the counter (N) is set to two (2) because the colors of the two (2) elements are to be decoded. For example, referring to FIG. 2, a 0 And a 1 The distance between can be encoded as a distance in the range [1; distance (a) 0 ,b 2 )]A value (e.g., an integer) of (1). If the end (e.g., last column) of the encoding line 210 has not been reached, a 1 And a 2 The distance between can be encoded as the range [1; distance (a) 1 ,end_of_line)]A value (e.g., an integer) of (1). The distance can be read from a data structure representing the compressed image. This distance can be used to determine the color of the element using an inverse algorithm used in the encoder. The process proceeds to step S635 (see fig. 6B).
Referring to fig. 6B, it is determined whether the selected element is an intended color in step S635. For example, the compressed image data structure can include a boolean value (e.g., 0) indicating (e.g., as a flag) that the color is the expected color during the encoding process or a boolean value (e.g., 1) indicating (e.g., as a flag) that the color is not the expected color during the encoding process. If the selected element is the desired color, the process continues to step S640. Otherwise, if the selected element is not the intended color, the process continues to step S645.
In step S640, the desired color is determined. For example, the expected color can be a color of an element (e.g., an element in a reference line) that has been previously decoded. The element can be an element in a reference line, with an offset based on the selected element (e.g., reference line column C +/-offset) in a column to the left or right. The color of the element in the reference line can be read as the color of the selected element.
In step S645, the color of the selected element is decoded. For example, the encoded values can be index values for colors in a palette (e.g., palette 330). Thus, a color can be decoded by looking up the color in the palette using the index values. For example, the encoded values can be associated with elements in a reference line. Thus, the color can be decoded by determining which element in the reference line is associated with the selected element (e.g., in the same column, in a different column, etc.) and using the color of the decoded element in the reference line. For example, the encoded value can be associated with a previously decoded element in a decoding line. Thus, the color can be decoded by determining (e.g., a column in the decoding line) which element in the decoding line is associated with the selected element and using the color of the decoded element in the decoding line.
In step S650, the color of the selected element is set. For example, the color of the selected element can be set to one of the decoded color (S645) or the expected color (S640). It is determined in step S655 whether N =1. For example, in mode two (2), one color may be decoded, and in mode three (3), two colors may be decoded. Thus, N is set equal to one (N = 1) in step S625 (mode two (2)), N is set equal to two (N = 2) in step S630 (mode three (3), the first color is decoded), and N is set equal to one (N = 1) in step S660 (mode three (3), the second color is decoded). If N =1, the process proceeds to step S665. Otherwise, if N =2, the process proceeds to step S660.
In step S660, the distance is read and the counter (N) is set to one (1) because the color of one (1) element is to be decoded (the first color has already been decoded in the third mode). For example, referring to FIG. 2, a 0 And a 1 The distance between can be encoded as a distance in the range [1; distance (a) 0 ,b 2 )]A value (e.g., an integer) of (1). If the end (e.g., last column) of the encoded line 210 has not been reached, then a 1 And a 2 The distance between can be encoded as a distance between the range [1; distance (a) 1 ,end_of_line)]A value (e.g., an integer) of (1). The distance can be read from a data structure representing the compressed image. This distance can be used to determine the color of the element using the inverse algorithm used in the encoder. The process proceeds to step S635 (see fig. 6B).
In step S665, if the selected element is the last element in the decoding line, the process proceeds to step S670. For example, a row can include a flag indicating the last element, a row length (or position) counter can be used, and so forth. If the selected element is the last element in the row, the process continues to step S645. Otherwise, the element is not the last element and the process returns to step S610.
In step S670, if the decoded line is the last line in the image, the process continues to step S675, where some other process (e.g., additional processing (e.g., error correction) in the image pipeline) can be performed. For example, a row can include a flag indicating the last element in the file and/or the file may not include any additional data. Otherwise, if the decoded line is not the last line in the image, the process returns to step S605.
FIG. 7 shows an example of a computer device 700 and a mobile computer device 750 that can be used with the techniques described herein. Computing device 700 is intended to represent various forms of digital computers, such as laptops, desktops, workstations, personal digital assistants, servers, blade servers, mainframes, and other appropriate computers. Computing device 750 is intended to represent various forms of mobile devices, such as personal digital assistants, cellular telephones, smart phones, and other similar computing devices. The components shown herein, their connections and relationships, and their functions, are meant to be exemplary only, and are not meant to limit embodiments of the inventions described and/or claimed in this document.
The memory 704 stores information within the computing device 700. In one implementation, the memory 704 is a volatile memory unit or units. In another implementation, the memory 704 is a non-volatile memory unit or units. The memory 704 may also be another form of computer-readable medium, such as a magnetic or optical disk.
The storage device 706 is capable of providing mass storage for the computing device 700. In one implementation, the storage device 706 may be or contain a computer-readable medium, such as a floppy disk device, a hard disk device, an optical disk device, or a tape device, a flash memory or other similar solid state memory device, or an array of devices, including devices in a storage area network or other configurations. The computer program product can be tangibly embodied in an information carrier. The computer program product may also contain instructions that, when executed, perform one or more methods, such as those described above. The information carrier is a computer-or machine-readable medium, such as the memory 704, the storage device 706, or memory on processor 702.
The high-speed controller 708 manages bandwidth-intensive operations for the computing device 700, while the low-speed controller 712 manages lower bandwidth-intensive operations. Such allocation of functions is exemplary only. In one implementation, the high-speed controller 708 is coupled to memory 704, display 716 (e.g., through a graphics processor or accelerator), and to high-speed expansion ports 710, which may accept various expansion cards (not shown). In this embodiment, low-speed controller 712 is coupled to storage device 706 and low-speed expansion port 714. The low-speed expansion port, which may include various communication ports (e.g., USB, bluetooth, ethernet, wireless ethernet) may be coupled to one or more input/output devices such as a keyboard, pointing device, scanner, or networking device such as a switch or router, for example, through a network adapter.
As shown, the computing device 700 may be implemented in a number of different forms. For example, it may be implemented as a standard server 720, or multiple times in a group of such servers. It may also be implemented as part of a rack server system 724. Further, it may be implemented in a personal computer such as a laptop computer 722. Alternatively, components from computing device 700 may be combined with other components in a mobile device (not shown), such as device 750. Each such device may contain one or more computing devices 700, 750, and an entire system may be made up of multiple computing devices 700, 750 communicating with each other.
The processor 752 is capable of executing instructions within the computing device 750, including instructions stored in the memory 764. The processor may be implemented as a chipset of chips that include separate and multiple analog and digital processors. For example, the processor may provide for coordination of the other components of the device 750, such as control of user interfaces, applications run by device 750, and wireless communication by device 750.
The processor 752 may communicate with a user through a control interface 758 and a display interface 756 coupled to a display 754. The display 754 may be, for example, a TFT LCD (thin film transistor liquid crystal display) or OLED (organic light emitting diode) display or other suitable display technology. The display interface 756 may comprise appropriate circuitry for driving the display 754 to present graphical and other information to a user. The control interface 758 may receive commands from a user and convert them for submission to the processor 752. In addition, an external interface 762 may be provided in communication with processor 752, to enable near area communication of device 750 with other devices. For example, external interface 762 may provide for wired communication in some embodiments, or for wireless communication in other embodiments, and multiple interfaces may also be used.
The memory 764 stores information within the computing device 750. The memory 764 can be implemented as one or more of a computer-readable medium or media, one or more volatile memory units, or one or more non-volatile memory units. Expansion memory 774 may also be provided and connected to device 750 through expansion interface 772, which expansion interface 772 may include, for example, a SIMM (Single in line memory Module) card interface. Such expansion memory 774 may provide additional storage space for device 750, or may also store applications or other information for device 750. Specifically, expansion memory 774 may include instructions to carry out or supplement the processes described above, and may include secure information also. Thus, for example, expansion memory 774 may be provided as a security module for device 750, and may be programmed with instructions that permit secure use of device 750. In addition, secure applications may be provided via the SIMM card, as well as additional information, such as placing identifying information on the SIMM card in a non-hackable manner.
The memory may include, for example, flash memory and/or NVRAM memory, as described below. In one implementation, a computer program product is tangibly embodied in an information carrier. The computer program product contains instructions that, when executed, perform one or more methods, such as those described above. The information carrier is a computer-or machine-readable medium, such as the memory 764, expansion memory 774, or memory on processor 752, which may be received, for example, through transceiver 768 or external interface 762.
As illustrated, computing device 750 may be implemented in a number of different forms. For example, it may be implemented as a cellular telephone 780. It may also be implemented as part of a smart phone 782, personal digital assistant, or other similar mobile device.
Embodiments can include an apparatus, a system, a non-transitory computer-readable medium having computer-executable program code stored thereon that is executable on a computer system, and/or a method that can perform a process with a method comprising: receiving an image targeted for compression into a compressed image; identifying a coding line comprising a plurality of elements, each element of the plurality of elements having a color; selecting an element from a plurality of elements from a coded line in an image; determining a presentation color associated with the selected element; comparing the rendered color to an expected color; and in response to determining that the rendered color is not the intended color, inserting a marker into a data structure representing a portion of the compressed image, the marker indicating that the rendered color is not the intended color, determining an encoded value corresponding to the rendered color, and inserting the encoded value into the data structure representing the compressed image.
Implementations can include one or more of the following features. For example, the indicia can be boolean. The coded lines can be at least a portion of a row of the image. The selected elements are capable of representing pixels of at least three (3) colors. Determining the encoding value corresponding to the presentation color can include: the method further includes looking up a presentation color in the palette, and setting the encoding value to an index value of the palette associated with the presentation color. Determining the encoding value corresponding to the presentation color can include: the method includes determining that a presentation color is not in the palette, inserting the presentation color into the palette, generating index values for the inserted presentation color, and setting encoding values to the generated index values. Determining the encoding value corresponding to the presentation color can include: the method includes identifying a line in the image as a reference line, the reference line including a plurality of coding elements, determining that one of the plurality of coding elements in the reference line includes an expected color, and setting a coding value based on the one of the plurality of coding elements in response to determining that the one of the plurality of coding elements in the reference line includes the expected color.
Setting the encoding value based on one encoding element of the plurality of encoding elements can include: the method further includes identifying an encoding value of one of the plurality of encoding elements and setting the encoding value to the encoding value of the one of the plurality of encoding elements. Setting the encoding value based on the determined element can include: the method further includes identifying a position of one of the plurality of encoding elements in the reference line, and setting an encoding value based on the identified position. Setting the encoded value based on the identified position can include: the encoding value is set to a relative value based on the position of the selected element in the coding line and the position of the identified element in the reference line. The method can further include: selecting another element from a plurality of elements from a coding line in the image; determining whether the selected another element is a last element in the encoded line; and in response to determining that the selected other element is the last element in the encoded line, not inserting at least one of a flag and an encoded value into a data structure representing a portion of the compressed image.
Embodiments can include an apparatus, a system, a non-transitory computer-readable medium having computer-executable program code stored thereon that is executable on a computer system, and/or a method that can perform a process with a method comprising: receiving a data structure representing an image to be decompressed, the image comprising a plurality of color elements; selecting an element to be decoded from a decoding line from the image; identifying an element in the data structure corresponding to the selected element; determining whether the selected element is an intended color; in response to determining that the selected element is the intended color, setting the decoded color of the selected element to the intended color; and in response to determining that the selected element is not the expected color, decoding the color of the selected element.
Implementations can include one or more of the following features. For example, the coded lines can be at least a portion of a row of the image. The first value can indicate that the color of the selected element is the intended color, and the second value can indicate that the color of the selected element is not the intended color. Decoding the color of the selected element can include: the index value associated with the selected element is looked up in the palette, and the decoded color of the selected element is set based on the index value. Decoding the color of the selected element can include: a line in the image is identified as a reference line, and it is determined that an element in the reference line includes a color of the selected element. Determining that the elements in the reference line include the color of the selected element can include: the position of the determined element in the reference line is identified, and the color of the selected element is set based on the determined position. The position can be based on the relative position of the selected element in the decoding line and the determined position of the element in the reference line.
While example embodiments may include various modifications and alternative forms, embodiments thereof are shown by way of example in the drawings and will herein be described in detail. It should be understood, however, that there is no intention to limit example embodiments to the specific forms disclosed, but on the contrary, example embodiments are to cover all modifications, equivalents, and alternatives falling within the scope of the claims. Like numbers refer to like elements throughout the description of the figures.
Various embodiments of the systems and techniques described here can be implemented in digital electronic circuitry, integrated circuitry, specially designed ASICs (application specific integrated circuits), computer hardware, firmware, software, and/or combinations thereof. These various implementations can include implementation in one or more computer programs that are executable and/or interpretable on a programmable system including at least one programmable processor, which may be special or general purpose, coupled to receive data and instructions from, and to transmit data and instructions to, a storage system, at least one input device, and at least one output device. Various implementations of the systems and techniques described here can be realized as, and/or referred to generally herein as, circuits, modules, blocks, or systems that can combine software and hardware aspects. For example, a module may comprise functions/acts/computer program instructions that are executed on a processor (e.g., a processor formed on a silicon substrate, gaAs substrate, etc.) or some other programmable data processing apparatus.
Some of the above example embodiments are described as processes or methods depicted as flowcharts. Although a flowchart may describe the operations as a sequential process, many of the operations can be performed in parallel, concurrently, or simultaneously. In addition, the order of the operations may be rearranged. These processes may terminate when their operations are completed, but may also have additional steps not included in the figures. These processes may correspond to methods, functions, procedures, subroutines, subprograms, etc.
The methods discussed above, some of which are illustrated by flow diagrams, may be implemented by hardware, software, firmware, middleware, microcode, hardware description languages, or any combination thereof. When implemented in software, firmware, middleware or microcode, the program code or code segments to perform the necessary tasks may be stored in a machine or computer readable medium such as a storage medium. The processor may perform the necessary tasks.
Specific structural and functional details disclosed herein are merely representative for purposes of describing example embodiments. However, the example embodiments are embodied in many alternate forms and should not be construed as limited to only the embodiments set forth herein.
It will be understood that, although the terms first, second, etc. may be used herein to describe various elements, these elements should not be limited by these terms. These terms are only used to distinguish one element from another. For example, a first element could be termed a second element, and, similarly, a second element could be termed a first element, without departing from the scope of example embodiments. As used herein, the term and/or includes any and all combinations of one or more of the associated listed items.
It will be understood that when an element is referred to as being connected or coupled to another element, it can be directly connected or coupled to the other element or intervening elements may be present. In contrast, when an element is referred to as being directly connected or directly coupled to another element, there are no intervening elements present. Other words used to describe the relationship between elements (e.g., between and directly between, adjacent and directly adjacent, etc.) should be interpreted in a similar manner.
The terminology used herein is for the purpose of describing particular embodiments only and is not intended to be limiting of example embodiments. As used herein, the singular forms a, an and the are intended to include the plural forms as well, unless the context clearly indicates otherwise. It will be further understood that the terms comprises, comprising, containing, and/or having, when used herein, specify the presence of stated features, integers, steps, operations, elements, and/or components, but do not preclude the presence or addition of one or more other features, integers, steps, operations, elements, components, and/or groups thereof.
It should also be noted that, in some alternative implementations, the functions/acts noted may occur out of the order noted in the figures. For example, two figures shown in succession may in fact be executed substantially concurrently or may sometimes be executed in the reverse order, depending upon the functionality/acts involved.
Unless otherwise defined, all terms (including technical and scientific terms) used herein have the same meaning as commonly understood by one of ordinary skill in the art to which example embodiments belong. It will be further understood that terms, such as those defined in commonly used dictionaries, should be interpreted as having a meaning that is consistent with their meaning in the context of the relevant art and will not be interpreted in an idealized or overly formal sense unless expressly so defined herein.
Portions of the above exemplary embodiments and corresponding detailed description are presented in terms of software or algorithms and symbolic representations of operations on data bits within a computer memory. These descriptions and representations are the ones by which those of ordinary skill in the art effectively convey the substance of their work to others of ordinary skill in the art. An algorithm, as the term is used here, and as it is used generally, is conceived to be a self-consistent sequence of steps leading to a desired result. The steps are those requiring physical manipulations of physical quantities. Usually, though not necessarily, these quantities take the form of optical, electrical, or magnetic signals capable of being stored, transferred, combined, compared, and otherwise manipulated. It has proven convenient at times, principally for reasons of common usage, to refer to these signals as bits, values, elements, symbols, characters, terms, numbers, or the like.
In the illustrative embodiments described above, references to acts and symbolic representations of operations (e.g., in the form of flowcharts) that may be implemented as program modules or functional processes include routines, programs, objects, components, data structures, etc., that perform particular tasks or implement particular abstract data types and may be described and/or implemented using existing hardware at existing structural elements. Such existing hardware may include one or more Central Processing Units (CPUs), digital Signal Processors (DSPs), application specific integrated circuits, field Programmable Gate Arrays (FPGAs) computers, and the like.
It should be borne in mind, however, that all of these and similar terms are to be associated with the appropriate physical quantities and are merely convenient labels applied to these quantities. Unless specifically stated otherwise, or as is apparent from the discussion, terms such as processing or computing or calculating or determining or displaying, or the like, refer to the action and processes of a computer system, or similar electronic computing device, that manipulates and transforms data represented as physical, electronic quantities within the computer system's registers and memories into other data similarly represented as physical quantities within the computer system memories or registers or other such information storage, transmission or display devices.
Note also that the software implemented aspects of the example embodiments are typically encoded on some form of non-transitory program storage medium or implemented over some type of transmission medium. The program storage medium may be magnetic (e.g., a floppy disk or a hard drive) or optical (e.g., a compact disk read only memory or a CD ROM), and may be read only or random access. Similarly, the transmission medium may be twisted wire pairs, coaxial cable, optical fiber, or some other suitable transmission medium known to the art. The example embodiments are not limited by these aspects of any given implementation.
Finally, it should also be noted that although the appended claims set forth particular combinations of features described herein, the scope of the present disclosure is not limited to the particular combinations claimed herein, but extends to cover any combination of features or embodiments disclosed herein regardless of whether or not that particular combination is specifically recited in the appended claims.
Claims (32)
1. A method, comprising:
receiving an image targeted for compression into a compressed image;
identifying a coding line comprising a plurality of elements, each element of the plurality of elements having a color;
selecting an element from the plurality of elements from the coding line in the image;
determining a presentation color associated with the selected element;
comparing the rendered color to an expected color; and
in response to determining that the presented color is not the expected color:
inserting a marker into a data structure representing a portion of the compressed image, the marker indicating that the rendered color is not the expected color,
determining an encoding value corresponding to the presentation color, an
Inserting the encoded values into the data structure representing the compressed image.
2. The method of claim 1, wherein the marker is a boolean.
3. The method of claims 1 and 2, wherein the coded line is at least a portion of a row of the image.
4. The method of any of claims 1 to 3, wherein the selected elements represent pixels of at least three (3) colors.
5. The method of any of claims 1 to 4, wherein determining the encoded value corresponding to the presentation color comprises:
looking up the presentation color in a palette, an
Setting the encoding value to an index value of the palette associated with the presentation color.
6. The method of any of claims 1 to 4, wherein determining the encoded value corresponding to the presentation color comprises:
determining that the presentation color is not in the color palette,
inserting the presentation colors into the color palette,
generating an index value for the inserted presentation color, an
Setting the encoded value to the generated index value.
7. The method of any of claims 1 to 4, wherein determining the encoded value corresponding to the presentation color comprises:
identifying a line in the image as a reference line, the reference line comprising a plurality of coding elements,
determining that one of the plurality of coding elements in the reference line comprises the expected color, an
In response to determining that one of the plurality of encoding elements in the reference line includes the expected color, setting the encoding value based on the one of the plurality of encoding elements.
8. The method of claim 7, wherein setting the coding value based on one of the plurality of coding elements comprises:
identifying the encoding value of one of the plurality of encoding elements, an
Setting the encoding value to the encoding value of one of the plurality of encoding elements.
9. The method of claim 8, wherein setting the encoding value based on the determined element comprises:
identifying a position of one of the plurality of coding elements in the reference line, an
Setting the encoded value based on the identified position.
10. The method of claim 9, wherein setting the encoded value based on the identified position comprises:
setting the encoding value to a relative value based on the position of the selected element in the coding line and the position of the identified element in the reference line.
11. The method of any of claims 1 to 10, further comprising:
selecting another element from the plurality of elements from the coded line in the image;
determining whether the selected another element is a last element in the encoded line; and
in response to determining that the selected other element is the last element in the encoded line, not inserting at least one of the marker and the encoded value into the data structure representing part of the compressed image.
12. A non-transitory computer-readable storage medium having stored computer-executable program code that, when executed on a computer system, causes the computer system to perform a method, the method comprising:
receiving an image and a target for compression into a compressed image;
identifying a coding line comprising a plurality of elements, each element of the plurality of elements having a color;
selecting an element from the plurality of elements from the coding line in the image;
determining a presentation color associated with the selected element;
comparing the color to an expected color;
in response to determining that the presented color is not the expected color:
inserting a marker into a data structure representing a portion of the compressed image, the marker indicating that the rendered color is not the expected color,
determining an encoding value corresponding to the presentation color, an
Inserting the encoded values into the data structure representing a portion of the compressed image.
13. The non-transitory computer-readable storage medium of claim 12, wherein the indicia is a boolean.
14. The non-transitory computer-readable storage medium of claims 12 and 13, wherein the coded line is at least a portion of the image.
15. The non-transitory computer readable storage medium of any of claims 12 to 14, wherein the selected elements represent pixels of at least three (3) colors.
16. The non-transitory computer-readable storage medium of any of claims 12 to 14, wherein determining the encoded value corresponding to the presentation color comprises:
looking up the presentation color in a color palette, an
Setting the encoding value to an index value of the palette associated with the presentation color.
17. The non-transitory computer-readable storage medium of any of claims 12 to 14, wherein determining the encoded value corresponding to the presentation color comprises:
determining that the presentation color is not in the color palette,
inserting the presentation colors into the color palette,
generating an index value for the inserted presentation color, an
Setting the encoded value to the generated index value.
18. The non-transitory computer-readable storage medium of any of claims 12 to 14, wherein determining the encoded value corresponding to the presentation color comprises:
identifying a line in the image as a reference line, the reference line comprising a plurality of coding elements,
determining that one of the plurality of coding elements in the reference line comprises the presentation color, an
In response to determining that one of the encoding elements in the reference line includes the expected color, setting the encoding value based on one of the encoding elements.
19. The non-transitory computer-readable storage medium of claim 18, wherein setting the encoding value based on one of the encoding elements comprises:
identifying the encoding value of one of the encoding elements, an
Setting the encoding value to the encoding value of one of the encoding elements.
20. The non-transitory computer-readable storage medium of claim 18, wherein setting the encoding value based on one of the encoding elements comprises:
identifying a position of one of the code elements in the reference line, an
Setting the encoded value based on the identified position.
21. The non-transitory computer-readable storage medium of claim 20, wherein setting the encoded value based on the identified location comprises:
setting the encoding value to a relative value based on the position of the selected element in the coding line and the position of the element in the reference line.
22. The non-transitory computer-readable storage medium of any one of claims 12 to 21, the method further comprising:
determining whether the selected element is the last element in the encoded line, an
In response to determining that the selected element is the last element in the encoded line, not inserting at least one of a flag and the encoded value into the data structure representing part of the compressed image.
23. A method, comprising:
receiving a data structure representing an image to be decompressed;
identifying a decoding line comprising a plurality of elements, each element of the plurality of elements having a color;
selecting an element to be decoded from the plurality of elements from the decoding line in the image;
identifying an element of the data structure corresponding to the selected element;
determining whether the selected element is an intended color;
in response to determining that the selected element is the expected color, setting a decoded color of the selected element to the expected color; and
in response to determining that the selected element is not the expected color, decoding the selected element.
24. The method of claim 23, wherein the decoding line is at least a portion of a row of the image.
25. The method of claims 23 and 24, wherein a first marker value indicates that the color of the selected element is the expected color and a second marker value indicates that the color of the selected element is not the expected color.
26. The method of any of claims 23 to 25, wherein decoding the presentation color of the selected element comprises:
looking up in the palette the index value associated with the selected element, an
Setting the decoding color of the selected element based on the index value.
27. The method of any of claims 23 to 25, wherein decoding the presentation color of the selected element comprises:
identifying a line in the image as a reference line, an
Determining that an element in the reference line includes the rendered color of the selected element.
28. The method of claim 27, wherein determining that the element in the reference line comprises the rendered color of the selected element comprises:
identifying the position of the determined element in the reference line, an
Setting the presentation color of the selected element based on the determined position.
29. The method of claim 28, wherein the position is based on a relative position of the selected element in the decoding line and a position of the determined element in the reference line.
30. A non-transitory computer readable medium containing instructions that, when executed, cause a processor of a computer system to perform any of the steps of the method of any of claims 23-29.
31. A computer system for compressing an image, configured to perform any of the steps of the method of any of claims 1 to 11 and/or 23 to 29.
32. An apparatus comprising one or more processors and memory storing instructions that, when executed by the one or more processors, cause the one or more processors to perform the method of any of claims 1-11 and/or 23-29.
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
PCT/US2020/053640 WO2022071949A1 (en) | 2020-09-30 | 2020-09-30 | Multicolor lossless image compression |
Publications (1)
Publication Number | Publication Date |
---|---|
CN115380535A true CN115380535A (en) | 2022-11-22 |
Family
ID=72964810
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202080099737.7A Pending CN115380535A (en) | 2020-09-30 | 2020-09-30 | Multi-color lossless image compression |
Country Status (4)
Country | Link |
---|---|
US (1) | US20230316578A1 (en) |
EP (1) | EP4104445A1 (en) |
CN (1) | CN115380535A (en) |
WO (1) | WO2022071949A1 (en) |
-
2020
- 2020-09-30 WO PCT/US2020/053640 patent/WO2022071949A1/en unknown
- 2020-09-30 CN CN202080099737.7A patent/CN115380535A/en active Pending
- 2020-09-30 EP EP20793874.7A patent/EP4104445A1/en active Pending
- 2020-09-30 US US18/001,694 patent/US20230316578A1/en active Pending
Also Published As
Publication number | Publication date |
---|---|
EP4104445A1 (en) | 2022-12-21 |
WO2022071949A1 (en) | 2022-04-07 |
US20230316578A1 (en) | 2023-10-05 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US9830890B2 (en) | Method and device for compressing and decompressing data information, drive compensation method and device, and display device | |
EP2406953B1 (en) | A method of compression of graphics images and videos | |
US20070065023A1 (en) | Image display encoding and/or decoding system, medium, and method | |
WO2020248488A1 (en) | Image storage method, image reading method, image storage device, and image reading device | |
CN112565772A (en) | Picture compression method and decompression method based on electronic price tags | |
US10643352B2 (en) | Vertex split connectivity prediction for improved progressive mesh compression | |
CN1984228A (en) | Image forming system and method | |
US10692248B2 (en) | Increased density of batches for improved progressive mesh compression | |
CN115380535A (en) | Multi-color lossless image compression | |
US11968406B2 (en) | Enhanced image compression with clustering and lookup procedures | |
CN109379591B (en) | Image transcoding method, electronic device and computer readable storage medium | |
CN110730277B (en) | Information coding and method and device for acquiring coded information | |
US9137549B2 (en) | Compressing image data | |
US11412260B2 (en) | Geometric transforms for image compression | |
US20230024148A1 (en) | Data processing methods and systems, and electronic devices | |
US20110038551A1 (en) | Method for encoding and decoding images | |
US9930354B2 (en) | Skip scanlines on JPEG image decodes | |
CN114584783B (en) | Picture decoding method and device, terminal equipment and readable storage medium | |
CN114868394A (en) | Gradient predictor for image compression | |
CN111788607A (en) | Batch density increase for improved progressive mesh compression | |
US9955163B2 (en) | Two pass quantization of video data | |
CN113326843B (en) | License plate recognition method and device, electronic equipment and readable storage medium | |
CN113810717B (en) | Image processing method and device | |
CN109996077A (en) | A kind of logical image decompressing method suitable for display panel detection | |
US20100009630A1 (en) | Mobile electronic device and method for displaying characters on a bluetooth device |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination |