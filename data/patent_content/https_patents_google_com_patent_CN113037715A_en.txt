CN113037715A - Transmission system and method for limiting manipulation of content in a network environment - Google Patents
Transmission system and method for limiting manipulation of content in a network environment Download PDFInfo
- Publication number
- CN113037715A CN113037715A CN202110176028.0A CN202110176028A CN113037715A CN 113037715 A CN113037715 A CN 113037715A CN 202110176028 A CN202110176028 A CN 202110176028A CN 113037715 A CN113037715 A CN 113037715A
- Authority
- CN
- China
- Prior art keywords
- component
- characters
- data processing
- processing system
- digital component
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
Images
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L63/00—Network architectures or network communication protocols for network security
- H04L63/14—Network architectures or network communication protocols for network security for detecting or protecting against malicious traffic
- H04L63/1441—Countermeasures against malicious traffic
- H04L63/1466—Active attacks involving interception, injection, modification, spoofing of data unit addresses, e.g. hijacking, packet injection or TCP sequence number attacks
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/08—Speech classification or search
- G10L15/18—Speech classification or search using natural language modelling
- G10L15/1822—Parsing for meaning understanding
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/22—Procedures used during a speech recognition process, e.g. man-machine dialogue
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L51/00—User-to-user messaging in packet-switching networks, transmitted according to store-and-forward or real-time protocols, e.g. e-mail
- H04L51/21—Monitoring or handling of messages
- H04L51/212—Monitoring or handling of messages using filtering or selective blocking
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L63/00—Network architectures or network communication protocols for network security
- H04L63/14—Network architectures or network communication protocols for network security for detecting or protecting against malicious traffic
- H04L63/1408—Network architectures or network communication protocols for network security for detecting or protecting against malicious traffic by monitoring network traffic
- H04L63/1425—Traffic logging, e.g. anomaly detection
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/08—Speech classification or search
- G10L2015/088—Word spotting
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/22—Procedures used during a speech recognition process, e.g. man-machine dialogue
- G10L2015/223—Execution procedure of a spoken command
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L63/00—Network architectures or network communication protocols for network security
- H04L63/02—Network architectures or network communication protocols for network security for separating internal from external traffic, e.g. firewalls
- H04L63/0227—Filtering policies
Abstract
A transmission system and method for restricting the manipulation of content in a network environment is disclosed. The systems and methods of the present disclosure generally relate to a data processing system that identifies potentially manipulated or fraudulent digital components in a computer network environment. The data processing system may improve the efficiency and effectiveness of data packet (or other protocol-based) transmissions over one or more computer networks by, for example, preventing or reducing the number of manipulated or fraudulent digital component transmissions.
Description
The application is a divisional application, the original application number is 201780013402.7, the application date is 2017, 12 and 8, and the invention discloses a transmission system and a method for limiting content manipulation in a network environment and a digital assistant device.
Technical Field
The present application relates to a transmission system and method for restricting the manipulation of content in a network environment.
Background
Excessive network traffic data transmitted (packet-based or otherwise) between computing devices may prevent the computing devices from properly processing the network traffic data, performing operations related to the network traffic data, or responding to the network traffic data in a timely manner. Excessive network traffic data may also complicate data routing or degrade the quality of the response if the responding computing device is at or above its processing power, which may result in bandwidth utilization inefficiencies. The large number of digital component objects that may initiate network transmission of network traffic data between computing devices may make controlling network transmissions corresponding to the digital component objects more complicated.
Disclosure of Invention
At least one aspect relates to a system for limiting content delivery in a network environment. The system may include a data processing system that may include an interface to receive a content request from a client computing device. The system may include a content selector component executed by a data processing system. The content selector component can select the first digital component based on the content request. The first digital component may include a first plurality of characters. The system may include a manipulation detection component executed by the data processing system. The manipulation detection component can retrieve a dictionary that includes indications of a portion of candidate characters included in the plurality of number components. The manipulation detection component can convert the first plurality of characters into an array of characters based on a dictionary, which can include indications of a portion of candidate characters included in the plurality of numeric components. The manipulation detection component can classify the first numeric component into a first category of a plurality of categories based on a sequence of a first plurality of characters in the array of characters. The manipulation detection component can determine that the first digital component is not included in a response to the content request from the client computing device based on classifying the first digital component into a first category of a plurality of categories. The manipulation detection component can generate a response based on a content request from a client computing device.
At least one aspect relates to a method for limiting content transmission in a network environment. The method can comprise the following steps: a content request is received from a client computing device by a data processing system. The method can comprise the following steps: the first digital component is selected based on the content request by a content selector component executed by the data processing system. The first digital component may include a first plurality of characters. The method can comprise the following steps: a dictionary is retrieved by a manipulation detection component executed by the data processing system, which may include indications of a portion of candidate characters included in the plurality of digit components. The method can comprise the following steps: the first plurality of characters is converted to an array of characters based on the dictionary by the manipulation detection component. The method can comprise the following steps: the first numeric component is classified into a first category of a plurality of categories based on a sequence of a first plurality of characters in the array of characters. The method can comprise the following steps: determining, by the manipulation detection component, that the first digital component is not included in a response to the content request from the client computing device based on classifying the first digital component into a first category of the plurality of categories. The method can comprise the following steps: a response is generated by the data processing system based on the content request from the client computing device.
At least one aspect of the present disclosure is directed to a digital assistant apparatus that may include an audio driver, a transducer (transducer), a sensor for detecting an input audio signal, and a preprocessor component. The preprocessor component can be coupled to the audio driver, the transducer, and the sensor. The preprocessor may filter the input audio signal to produce a filtered input audio signal. The pre-processor may convert the filtered input audio signal into data packets. The preprocessor may transmit the data packets to the data processing system. The data processing system may include one or more processors and memory that execute a natural language processor component, a content selector component, an interface, and a manipulation detection component. The data processing system may receive a data packet from the pre-processor component via the interface, the data packet including the filtered input audio signal detected by the sensor. The data processing system may identify a content request in the filtered input audio signal through a natural language processor component. The data processing system can select, by the content selector component, the first digital component based on the content request. The first digital component may include a first plurality of characters. The data processing system may retrieve, by manipulating the detection component, a dictionary that may include indications of a portion of candidate characters included in the plurality of number components. The data processing system may convert the first plurality of characters into a character vector based on a dictionary that includes indications of a portion of candidate characters included in the plurality of number components by manipulating the detection component. The data processing system may classify the first numeric component into a first one of a plurality of classes based on a sequence of a first plurality of characters in the character vector by manipulating the detection component. The data processing system may determine, by the manipulation detection component, that the first digital component is not included in the response to the content request from the client computing device based on classifying the first digital component into a first category of the plurality of categories. The data processing system may generate a response based on the content request from the client computing device by manipulating the detection component, the response not including the first digital component based on determining that the first digital component is not included in the response.
These and other aspects and embodiments are discussed in detail below. The foregoing information and the following detailed description include illustrative examples of various aspects and embodiments, and provide an overview or framework for understanding the nature and character of the claimed aspects and embodiments. The accompanying drawings provide an illustration and a further understanding of the various aspects and embodiments, and are incorporated in and constitute a part of this specification.
Drawings
The drawings are not intended to be drawn to scale. Like reference numbers and designations in the various drawings indicate like elements. For purposes of clarity, not every component may be labeled in every drawing. In the drawings:
FIG. 1 depicts a system for limiting content delivery in a network environment.
FIG. 2 depicts a method for limiting content transmission in a network environment in a voice-enabled computer network environment.
FIG. 3 depicts a process for dividing a numeric component into a plurality of portions and then converting the portions into an array of characters in a voice-enabled computer network environment; and
FIG. 4 is a block diagram illustrating a general architecture of a computer system that may be used to implement elements of the systems and methods described and illustrated herein.
Detailed Description
The following is a more detailed description of various concepts and embodiments related to methods, devices, and systems for limiting content transmission in a network environment. The various concepts introduced above and discussed in more detail below may be implemented in a number of ways.
The systems and methods of the present disclosure generally relate to a data processing system that identifies potentially manipulated or fraudulent digital components in a computer network environment. The data processing system may improve the efficiency and effectiveness of data packet (or other protocol-based) transmissions over one or more computer networks by, for example, preventing or reducing the number of manipulated or fraudulent digital component transmissions. The manipulated or spoofed digital component may be a content item that includes text or other content that is configured to not be detected by manual or automatic content filters. Manipulations of text may include the inclusion of near-characters, the inclusion of repeated characters, the deletion of characters, the merging of words, the transposition of characters, or any combination thereof.
The systems and methods described herein may be used with or with a digital assistant or other audio-based system. For example, a system may include a data processing system that receives an input audio query (which may also be referred to as an input audio signal). Based on the input audio query, the data processing system may identify a request and a trigger keyword corresponding to the request. Based on the trigger key or request, the data processing system may generate a response that may include one or more digital components. The data processing system may select the digital component or the digital component may be provided to the data processing system from a third party. The digital component may be user-generated content, such as a comment or comment. The data processing system may process the digital component to determine whether the digital component is fraudulent, manipulated, or should be marked as spam. The data processing system may delete, clear, disable, or otherwise limit the transmission of digital components by identifying manipulated digital components, which may reduce the overall consumption of computing power, power consumption, memory, and bandwidth because undesirable digital components are not transmitted over the network to the client computing device.
The data processing system may then select an unmanipulated digital component, which may be provided to the client computing device via a computer network by packet or other protocol-based data messaging. The digital component may also be referred to as a content item. The digital component may be included in the digital component. The output signal including the selected digital component may cause an audio driver component of the client computing device to generate a sound wave (e.g., an audio output) that may be output from the client computing device.
FIG. 1 illustrates an example system 100 for limiting content transmission in a network environment. The data processing system 102 may include at least one server having at least one processor. For example, the data processing system 102 may include a plurality of servers located in at least one data center or server farm. The data processing system 102 may determine a request and a trigger keyword associated with the request from the input audio signal. Based on the request and trigger keywords, the data processing system 102 may determine or select at least one action data structure, and may select at least one digital component (and initiate other actions as described herein).
The data processing system 102 may include a plurality of logically grouped servers and facilitate distributed computing techniques. The logical grouping of servers may be referred to as a data center, a server farm, or a machine farm. The servers may be geographically dispersed. A data center or machine farm may be managed as a single entity, or a machine farm may include multiple machine farms. Servers within each machine farm may be heterogeneous — one or more of the servers or machines may operate according to one or more types of operating system platforms. The data processing system 102 may include servers in a data center that are stored in one or more high-density rack systems and associated storage systems (e.g., located in an enterprise data center). In this manner, the data processing system 102 with integrated servers may improve system manageability, data security, physical security of the system, and system performance by locating the servers and high performance storage systems on a localized high performance network. Centralizing all or some of the data processing system 102 components (including servers and storage systems) and coupling them with advanced system management tools enables more efficient use of server resources, which saves power, reduces processing requirements, and reduces bandwidth usage.
The data processing system 102 can include at least one Natural Language Processor (NLP) component 112, at least one interface 110, at least one manipulation detection component 114, at least one content selector component 118, at least one audio signal generator component 120, at least one direct action Application Program Interface (API)116, and at least one data repository 122. The NLP component 112, the interface 110, the manipulation detection component 114, the content selector component 118, the audio signal generator component 120, and the direct action API116 may each include at least one processing unit, server, virtual server, circuit, engine, agent, device, or other logic device, such as a programmable logic array configured to communicate with the data store 122 and other computing devices (e.g., the at least one client computing device 104 or the at least one content provider computing device 106) via the at least one computer network 105. The network 105 may include a computer network such as the internet, a local area, wide area, metropolitan area, or other area network, an intranet, a satellite network, other computer networks such as voice or data mobile telephone communication networks, and combinations thereof.
The network 105 may include or constitute a display network, e.g., a subset of information resources available on the internet, associated with a content placement or search engine results system, or eligible to include third party digital components as part of a digital component placement activity. The data processing system 102 may use the network 105 to access information resources, such as web pages, websites, domain names, or uniform resource locators that may be rendered, output, rendered, or displayed by the client computing device 104. For example, a user of the client computing device 104 may access information, data provided by the data processing system 102 via the network 105, or otherwise interact with the data processing system 102 or the content provider device 106.
For example, the network 105 may include a point-to-point network, a broadcast network, a wide area network, a local area network, a telecommunications network, a data communications network, a computer network, an Asynchronous Transfer Mode (ATM) network, a Synchronous Optical Network (SONET) network, a Synchronous Digital Hierarchy (SDH) network, a wireless network, or a wired network, and combinations thereof. The network 105 may include a wireless link, such as an infrared channel or satellite band. The topology of the network 105 may include a bus, star, or ring network topology. The network 105 may include a mobile telephone network that uses any protocol or protocols for communicating between mobile devices, including advanced mobile phone protocol ("AMPS"), time division multiple access ("TDMA"), code division multiple access ("CDMA"), global system for mobile communications ("GSM"), general packet radio service ("GPRS"), Long Term Evolution (LTE), or universal mobile telecommunications system ("UMTS"). Different types of data may be transmitted via different protocols, or the same type of data may be transmitted via different protocols.
The data processing system 102 can include a manipulation detection component 114. The manipulation detection component 114 can include an application, script, or program that is executed by the data processing system 102 to detect a numeric component that includes manipulated text. The manipulation detection component 114 can limit transmission of the manipulated digital component in the network environment by detecting the manipulated digital component and then preventing (or reducing) transmission of the manipulated digital component to the client computing device 104.
Manipulation of the digital component may include manipulation of text in the digital component. Manipulation may include replacing characters with other characters, mixing additional symbols, removing or adding letters, merging words, or transposing letters. Replacing a character with other characters may include replacing the letter with a near-shape (e.g., replacing the capital letter O with 0), replacing the character with a symbol that appears similar (e.g., replacing "a" with @), or replacing the letter that sounds similar (e.g., replacing "w" with "v"). Mixing additional symbols may include adding special characters, punctuation, or spaces to a word. Adding or removing letters may include copying one or more letters, adding random letters, removing intentionally repeated letters (e.g., replacing beta with beta), or removing random letters. Merging words may include removing spaces between adjacent words. The transposed letters may include letters within the transposed word body (e.g., downlood for download).
The manipulated text may be in a digital component provided by the content provider device 106 to the data processing system 102 or the client computing device 104. The digital component may include an electronic document, a web page, an advertisement, an image, an output audio file, an output video file, a Uniform Resource Locator (URL), a visual uniform resource locator (vrurl), or other type of electronic content. The digital component may be retrieved from the content provider device 106 by the data processing system 102. For example, the digital component may include user-generated content hosted or provided by the content provider device 106. The user-generated content may include online comments or reviews. In one example, the comment may be related to a user's comment on the restaurant.
Upon receiving an input query for information about a given restaurant, the data processing system 102 may search for web pages provided by the content provider device 106 for reviews of the given restaurant. The digital component selected by the data processing system 102 for the response may include one or more of a review of the restaurant provided by the content provider device 106 or a review (related to the given restaurant) made on a webpage of the content provider device.
For example, in response to the input query "Ok, what did you feel restaurant XYZ? ", the data processing system 102 may select comments made by the user on the webpage hosted by the content provider device 106 about the restaurant XYZ. For example, the comment may be a comment stating "restaurant XYZ is a good place for a shared romantic dinner". The data processing system 102 may include comments in the response. For example, the response may be "restaurant XYZ has good reviews". It is mentioned that "restaurant XYZ is a good place for a shared romantic dinner".
The manipulation detection component 114 can detect manipulated text within the numeric components and then limit transmission of those numeric components. For example, the numeric component may be a text-based advertisement from which the manipulation detection component 114 can extract text and determine whether the text was manipulated.
The manipulation detection component 114 can determine whether a given digital component includes manipulated text by retrieving a dictionary 124 from a data store. Dictionary 124 may indicate which characters (or symbols) are most likely to occur in the digital components. The manipulation detection component 114 can select a dictionary 124 from a plurality of different dictionaries 124 based on the language or topic of the digital component being tested.
To determine whether the numeric component is manipulated, the manipulation detection component 114 can extract the text of the numeric component as a character set. If the digital component is video-based or audio-based, the manipulation detection component 114 can generate a transcription of the word spoken in the digital component and then extract the text of the digital component as a character set. The manipulation detection component 114 can divide the complete character set into different portions. For example, the manipulation detection component 114 can select and analyze only about 160 characters at a time. If the number component (or the resulting character set) includes fewer than 160 characters, the manipulation detection component 114 can zero-fill the character set to a length of 160 characters. If the character set includes more than 160 characters, the manipulation detection component 114 can use a sliding window to divide the character set into different portions, each portion including 160 characters. For example, the characters of the respective portions may be from about 100 characters to about 1000 characters, from about 150 characters to about 800 characters, from about 150 characters to about 600 characters, from about 150 characters to about 400 characters, or from about 150 characters to about 200 characters.
The manipulation detection component 114 can generate an array of characters for the character set (or portions thereof if the character set is divided into different portions). Dictionary 124 may include values or arrays of individual characters listed in dictionary 124. The manipulation detection component 114 can convert a character array from a character array to an integer array using the dictionary 124. For example, each possible character may be represented as an integer in dictionary 124. The dictionary 124 may be used as a look-up table for converting input characters to integers. In some implementations, dictionary 124 includes only the characters most likely to appear in the unmanipulated number components. Dictionary 124 may include one or more characters that may appear in an un-manipulated or manipulated digital component. If the input character is not in dictionary 124, then manipulation detection component 114 can place a 0 in the character array for the character. Dictionary 124 may be one hot (one hot) encoded to represent each character as a binary array. Once the character array is converted to an integer array, the character array may be one-hot encoded.
The manipulation detection component 114 can generate at least one dictionary 124. To generate dictionary 124, manipulation detection component 114 can receive a plurality of digital components. The digital component may be an unworked digital component. The manipulation detection component 114 can parse the received digital component to determine the number of occurrences of each character in the received digital component. For example, the manipulation detection component 114 can count the number of occurrences of "a", "b", "c", etc. in the received digital component. The manipulation detection component 114 can count the number of occurrences of all types of characters, including letters, numbers, emoticons, and special characters. The list of all possible characters may be referred to as candidate characters.
The manipulation detection component 114 can rank the candidate characters based on the number of times each respective candidate character occurs in the received numeric component. The manipulation detection component 114 can generate a dictionary by selecting the most frequently occurring candidate character from the ranked candidate characters. For example, the manipulation detection component 114 can select the most commonly occurring 50, 60, 70, 100, 125, 150, 175, 200, 250, 300, 350, 400, 450, 500 characters (or any range therein) for the dictionary 124. Dictionary 124 may include more than 500 characters.
The manipulation detection component 114 can generate different dictionaries 124 for different groupings or categories of digital components. The groupings may be language based or topic based. For example, the manipulation detection component 114 can receive a plurality of digital components in a particular language and generate a dictionary 124 for such language. In another example, the manipulation detection component 114 can receive a plurality of digital components, each having a theme related to a particular category (e.g., mobile game), and generate the dictionary 124 for the mobile game based on the digital components having themes related to the mobile game.
The manipulation detection component 114 can include a machine learning module that can classify the digital component into one of a plurality of categories. The machine learning module may include a Long Short Term Memory (LSTM) model or other recurrent neural network for classifying the input string. The LSTM model may be implemented using softmax functions in one or more layers of the network. The LSTM model may be a three-level LSTM. The LSTM model may include about 50 to 300 nodes, about 100 to about 300 nodes, or about 200 to about 300 nodes. The categories may include a manipulated category and an un-manipulated category. Each level may correspond to a respective output node.
The manipulation detection component 114 can process the array of characters on a character-by-character basis. For example, sorting the character array may be based on the sequence (or order) of characters in the character array. If the manipulation detection component 114 classifies the digital component into a classification associated with the manipulated digital component, the manipulation detection component 114 can determine not to transmit the digital component to the client computing device 104.
The system 100 may also include one or more client computing devices 104 and one or more content provider devices 106. The client computing device 104 and the content provider computing device 106 may each include at least one logic device, such as a computing device with a processor, for communicating with each other or with the data processing system 102 via the network 105. The client computing device 104 and the content provider computing device 106 may each include at least one server, processor or memory, or a variety of computing resources or servers located in at least one data center. The client computing device 104 and the content provider computing device 106 may each include at least one computing device, such as a desktop computer, a laptop computer, a tablet, a personal digital assistant, a smart phone, a portable computer, a server, a thin client computer, a virtual server, or other computing device.
The client computing device 104 may include at least one sensor 140, at least one transducer 142, at least one audio driver 144, at least one speaker 146, and at least one pre-processor 148. The client computing device 104 may be a digital assistant device. The digital assistant device may be speaker-based. The sensor 140 may include a microphone (or other audio input sensor) or a camera. The sensor 140 may be referred to as an interface. Other interfaces may also include a network connection of computing devices, screens, or input devices. The transducer 142 may convert the audio input into an electronic signal and vice versa. The audio driver 144 may include scripts or programs that are executed by one or more processors of the client computing device 104 to control the sensors 140, transducers 142, or audio driver 144, as well as other components of the client computing device 104, to process or provide audio input. Speaker 146 may transmit audio output signals.
The client computing device 104 can include a preprocessor component 148. The preprocessor component 148 may include one or more processors. The preprocessor component 148 may perform one or more functions on the input audio signal before the input audio signal is processed by the data processing system 102 or other components of the client computing device 104. The preprocessor component 148 may be coupled with the audio driver 144, the transducer 142, and the sensor 140. The preprocessor component 148 may filter the input audio signals detected by the sensors 140 (or input audio signals otherwise received by the client computing device 104) to generate filtered input audio signals. The filtering by the preprocessor 148 may include filtering (or reducing) noise in the input audio signal, amplifying a predetermined frequency in the input audio signal, reducing a predetermined frequency in the input audio signal, or up-sampling or down-sampling the input audio signal. The pre-processor component 148 may convert the filtered input audio signal into data packets and transmit the data packets to the data processing system 102 via the network 105.
The client computing device 104 can be associated with an end user that enters (via an interface) a voice-based, text-based, or image-based query into the client computing device 104, and can receive a response to the query from the data processing system 102. The response may be in the same form as the query. For example, in response to a voice-based audio input query, the data processing system 102 (or the content provider device 106) may provide output in the form of a computer-generated voice file to the client computing device 104, which the client computing device 104 may output from the speaker 146. The audio output may correspond to a digital component selected by the content selector component 118 or an action data structure received from the direct action API 116. The computer-generated speech may include recordings from real persons or computer-generated speech.
The client computing device 104 may include an application, script, or program provided by the data processing system 102 (or associated with the data processing system 102) that enables the client computing device 104 to communicate input audio signals to the at least one interface 110 of the data processing system 102. The data processing system 102 may communicate with applications to enable the data processing system 102 to drive components of the client computing device 104 to render output audio signals (e.g., for action data structures) or other output signals (e.g., digital components).
The content provider computing device 106 may provide the digital component for rendering on the client computing device 104. The content provider device 106 may transmit the digital component to the client computing device 104 bypassing the data processing system 102. The content provider device 106 may provide the digital component to the data processing system 102, and the data processing system 102 may provide the digital component to the client computing device 104. The digital component may be an audio-based, text-based, or video-based digital component or action data structure that is displayed as an audio output by the client computing device 104. The action data structure or numeric component may include an organized response or offer to a good or service, such as a voice-based message that states: "today is a sunny day, the beach temperature will reach 80 degrees" as a query for speech input "today is a good day going to the beach? "organized response. The data processing system 102 (or other system 100 components, such as the content provider computing device 106) may also provide data classification in response, such as providing a digital component of a sunscreen, voice-based, or text message.
The content provider computing device 106 may provide the digital component to the data processing system 102 for storage in the data store 122. The action data structure and digital components may comprise a packet-based data structure for transmission via the network 105. The content provider computing device 106 may also provide the audio or text based digital component (or other digital component) to the data processing system 102, where the digital component may be stored in the data store 122. In response to a query received from one of these client computing devices 104, the data processing system 102 may select the numeric components based on the audio action data structure or text and provide them to the same or a different client computing device 104 (or indicate that the content provider computing device 106 provides). The audio-based action data structure may be proprietary audio or may be combined with text, image, or video data. The digital component may be proprietary text or may be combined with audio, image, or video data. The content provider device 106 may provide the manipulated digital component.
The data store 122 may include one or more local or distributed databases and may include a database management system. The data store 122 may include a computer data store or memory and may store, in addition to data, one or more dictionaries 124, one or more policies 126, content data 128, or templates 130. Policy 126 may include rules for transmission in a voice-based system. For example, the policy 126 may be used to define the session, connection (and establishment thereof) between the client computing device 104 and the data processing system 102. The content data 128 may include digital components or related metadata, and may be an input audio message that is part of one or more communication sessions with the client computing device 104. The metadata for the digital component may include an indication of the provider of the digital component (e.g., which content provider device 106 or its owner provided the digital component). The template 130 may include a data structure that may be used in communication with the client computing device 104. Template 130 may include one or more placeholders that data processing system 102 may populate with, for example, content data 128, digital components, or other data.
The dictionary 124 can be generated by the manipulation detection component 114. The manipulation detection component 114 can generate or update the dictionary 124 at predetermined intervals. Each manipulation detection component 114 can indicate the most common character across multiple un-manipulated digital components. Dictionary 124 may be generated by inputting a number of trusted digital components to manipulation detection component 114. Dictionary 124 may be one-hot coded. The manipulation detection component 114 can include an embedded layer for the dictionary 124. For example, rather than being one-hot encoded, the manipulation detection component 114 can use an embedding matrix to maintain the size of each dictionary 124 (the size of each dictionary 124 is smaller than when only one-hot encoding is used).
The data repository 122 may include different dictionaries 124 for different languages (e.g., american english dictionary, english dictionary, french dictionary) or different topic dictionaries (e.g., scientific dictionary or clothing dictionary). The different dictionaries 124 can be generated by providing digital components related to the language or topic to the manipulation detection component 114. For example, a plurality of digital components related to clothing (e.g., clothing advertisements) can be provided to the manipulation detection component 114 to generate a clothing dictionary.
The action data structure may include several organized or non-complimentary responses to the input audio signal. For example, the action data structure may include a beach weather forecast or directions to the beach. The action data structure in this example includes organized or non-complimentary content that is directly responsive to the input audio signal. The digital component responsive to the input audio signal may include originating or unorganized content, such as an offer to purchase sunscreen from a convenience store located near the beach. In this example, the organized action data structure (beach forecast) is responsive to the input audio signal (a query related to the beach), and the numeric component (a prompt or offer for sun block) is also responsive to the same input audio signal. The data processing system 102 may evaluate system 100 parameters (e.g., power usage, available displays, display formats, memory requirements, bandwidth usage, power capacity of input power, or time (e.g., internal battery or external power source, such as a wall output power source)) to provide action data structures and digital components to different candidate interfaces on the same client computing device 104 or to different candidate interfaces on different client computing devices 104.
The NLP component 112 may convert the input audio signal into recognized text by comparing the input signal to a set of stored representative audio waveforms (e.g., in the data store 122) and selecting the closest match. Representative waveforms are generated in a large set of users, and may be augmented with voice samples. After converting the audio signal to recognized text, NLP component 112 may match the text to words associated with actions that may be serviced by data processing system 102, e.g., via inter-user training or through operational specifications. In some implementations, the manipulation detection component 114 can process or otherwise analyze the input audio signal, but need not first convert the audio waveform to text.
The input audio signal may be detected by a sensor 140 (e.g., a microphone) of the client computing device 104. The sensors 140 may be referred to as interfaces of the client computing device 104. Via the transducer 142, the audio driver 144, or other components, the client computing device 104 can provide (e.g., via the network 105) an input audio signal to the data processing system 102, where the input audio signal can be received (e.g., through the interface 110) and provided to the NLP component 112 or stored as content data 128 in the data repository 122.
The NLP component 112 may receive or otherwise acquire an input audio signal. From the input audio signal, the NLP component 112 can identify at least one request or at least one trigger keyword corresponding to the request. The request may indicate an intent or subject of the input audio signal. The trigger key may indicate the type of action that is likely to be taken. For example, the NLP component 112 may parse the input audio signal to identify at least one request for weekend seaside removal. The trigger key may comprise at least one word, phrase, root or partial word, or derivative indicating an action to be taken. For example, a trigger keyword "go" or "to go to" from an input audio signal may indicate a need to be carried or indicate a trip away from home. In this example, the input audio signal (or the identified request) does not directly express an intended delivery, but the trigger keyword indicates that the delivery is an auxiliary action to at least one other action indicated by the request.
The audio signal generator component 120 may generate or otherwise obtain an output signal including a digital component (and an action data structure) in response to an input audio signal. For example, the data processing system 102 may execute the audio signal generator component 120 to generate or produce an output signal corresponding to the motion data structure or digital component. For example, the audio signal generator component 120 may convert the text-based digital component to an audio-based digital component. The interface component 110 of the data processing system 102 may provide or transmit one or more data packets including the output signal to any client computing device 104 via the computer network 105. Interface 110 may be designed, configured, constructed, or operated to receive and transmit information using, for example, data packets. The interface 110 may receive and transmit information using one or more protocols, such as a network protocol. The interface 110 may include a hardware interface, a software interface, a wired interface, or a wireless interface. For example, interface 110 may be a network interface or port of data processing system 102. The interface 110 may facilitate converting data from one format to another or formatting data from one format to another. For example, the interface 110 may include an application programming interface that includes definitions for communicating between various components, such as software components of the system 100.
The data processing system 102 may provide output signals including the action data structure to the client computing device 104 from the data store 122 or from the audio signal generator component 120. The data processing system 102 may provide the output signal including the digital component from the data store 122 or from the audio signal generator component 120 to the same client computing device 104 or a different client computing device 104.
The data processing system 102 may also instruct the content provider computing device 106 or other computing device to provide an output signal (e.g., corresponding to an action data structure or digital component) to the client computing device 104 via a data packet transmission. The output signal may be acquired, generated, converted into one or more data packets (or other communication protocols), or transmitted from the data processing system 102 (or other computing device) to the client computing device 104 as one or more data packets (or other communication protocols).
The content selector component 118 can identify, select, or otherwise obtain a plurality of digital components generated by a plurality of content selection processes. The content selection process may be near real-time, e.g., the same conversation, communication session, or portion of a series of communication sessions between the data processing system 102 and the client computing device 104 that involve a common topic. For example, a conversation may include asynchronous communications that are separated from each other by hours or days. The conversation or communication session may last for a period of time from receipt of the first input audio signal until an estimated or known conclusion is made as to the final action associated with the first input audio signal or the data processing system 102 receives an indication to terminate the conversation or the expiration of the conversation. For example, the data processing system 102 may determine that a conversation related to a weekend beach trip begins when an input audio signal is received and expires or terminates at the end of the weekend (e.g., weekday evening or monday morning). The data processing system 102 that provides the action data structure or digital component for rendering by one or more interfaces of the client computing device 104 or of another client computing device 104 during a valid time period of the conversation (e.g., from receipt of the input audio signal until the determined expiration time) may be considered to be running in real-time. In this example, the content selection process and rendering of the digital components and action data structures occur in real-time.
Based on information received by the content selector component 118 (e.g., an indication of an upcoming beach trip), the content selector component 118 can identify at least one digital component. The digital component may be responsive to or related to the subject matter of the input audio query. For example, the digital component may include a data message identifying a store near the beach with sun protection frost or suggesting a taxi to the seaside. The content selector component 118 can query the data store 122 to select or otherwise identify a digital component (e.g., from the content data 128). The content selector component 118 can also select a digital component from the content provider computing device 106. For example, in response to a query received from the data processing system 102, the content provider computing device 106 may provide the digital component to the data processing system 102 (or components thereof) for eventual output by the client computing device 104 that initiated the input audio signal, or for output to the same end user by a different client computing device 104.
The content selector component 118 can select the digital component or the action data structure as part of a real-time content selection process. For example, the action data structure may be provided to the client computing device 104 for transmission as audio output in a conversational manner in direct response to an input audio signal through an interface of the client computing device 104. The real-time content selection process for identifying the action data structure and providing the digital component to the client computing device 104 may occur within 1 minute or less from the input audio signal and be considered real-time. The data processing system 102 can also identify the digital component and provide the digital component to at least one interface of the client computing device 104 that originated the input audio signal or to a different client computing device 104.
The motion data structure (or digital component), for example, acquired or generated by the audio signal generator component 120, transmitted to the client computing device 104 via the interface 110 and the computer network 105 may cause the client computing device 104 to execute an audio driver 144 to drive a speaker 146 to generate sound waves corresponding to the motion data structure or digital component. The sound wave may include a word of or corresponding to the motion data structure or the digital component.
The motion data structure and the digital component may correspond to a subject of the input audio signal. The direct action API116 can execute a program or script (e.g., from the NLP component 112 or the content selector component 118) to identify an action data structure or digital component for one or more of these actions. The direct action API116 may perform specified actions to meet the end user's intent, as determined by the data processing system 102. Depending on the action specified in its input, the direct action API116 may execute code or identify dialog scripts that satisfy the parameters required by the user request. Such code may, for example, look up additional information in the data store 122 (such as the name of the home automation service), or such code may provide an audio output to render at the client computing device 104 to ask an end user a question, such as the desired destination of the requested taxi. The direct action API116 may determine the necessary parameters and may encapsulate the information into an action data structure, which may then be sent to another component, such as the content selector component 118 or the content provider device 106, to be implemented.
The direct action API116 of the data processing system 102 may generate an action data structure based on the request or trigger key. The motion data structure may be generated in response to a subject of the input audio signal. Based on the input audio signal parsed by the NLP component 112, the direct action API116 can determine which, if any, of the plurality of content provider devices 106 the message should be sent to. For example, if the input audio signal includes "OK, this weekend i would like to go to the seaside," the NLP component 112 may parse the input audio signal to identify a request or trigger keyword (such as the trigger keyword "go (to go to)") as an indication that a taxi ride is desired. The direct action API116 may encapsulate the request into an action data structure for transmission as a message to the content provider computing device 106 of the taxi service. The message can also be passed to the content selector component 118. The action data structure may include information for completing the request. In this example, the information may include a pickup location (e.g., home) and a destination location (e.g., beach). The direct action API116 may retrieve the template 130 from the data store 122 to determine which fields to include in the action data structure. The direct action API116 may retrieve content from the data store 122 to obtain information for the fields of the data structure. The direct action API116 may populate fields from the template with this information to generate a data structure. The direct action API116 may also populate fields with data from the input audio signal. The template 130 may be standardized for a category of content provider or the template 130 may be standardized for a particular content provider. For example, the ride share provider may create a data structure using the following standardized templates 130: { client _ device _ identifier; authentication _ creatives; pick _ up _ location; destination _ location; no _ passers; service _ level }.
The data processing system 102 may also provide prompts to the action data structure that queries the user to determine the user's interest in obtaining the digital component. For example, the action data structure may indicate "is saturday a sunny day, the temperature at sea will reach 80 degrees, do you want to know some services that are helpful to your travel? ". The data processing system 102 may respond to a prompt "do you want to know some services helpful to your travel? "while another input audio signal is received from the client computing device 104, such as" of course ". The NLP component 112 can parse the response and interpret it as authorization for audio rendering of the digital component by the client computing device 104. In response, the data processing system 102 can provide the digital component for audio rendering by the same client computing device 104 that initiated the response "of course".
The data processing system 102 may delay transmission of the digital component associated with the action data structure to optimize processing utilization. For example, the data processing system 102 provides an action data structure in response to receiving an input audio signal for rendering in real-time as audio output by the client computing device, e.g., in a conversational manner, and may previously delay transmission of the digital component until an off-peak period or off-peak period of data center usage, thereby utilizing the data center more efficiently by reducing peak bandwidth usage, heat output, or cooling requirements. The data processing system 102 can also initiate conversions or other activities associated with the digital component based on data center utilization or bandwidth metrics or requirements of the network 105 or the data center that includes the data processing system 102, such as subscribing to automotive services in response to responses to the action data structure or the digital component.
Based on the response to the digital component or action data structure for the subsequent action (such as clicking on the digital component rendered via the selected interface), the data processing system 102 may identify the conversion or initiate the conversion or action. The processor of the data processing system 102 may call the direct action API116 to execute scripts that facilitate the conversion action, such as booking a car from a car sharing service to pick up an end user to go to the sea or leave the sea. The direct action API116 may obtain content data 128 (or parameters or policies 126) from the data store 122 and data received with the end user's consent from the client computing device 104 to determine location, time, user account, logistics or other information for reserving a car from the car sharing service.
Fig. 2 depicts a flow diagram 200 for limiting the transmission of a digital component containing manipulated content. The method 200 may include receiving a request (ACT 202). The method 200 may include selecting a digital component (ACT 204). The method 200 may include retrieving a dictionary (ACT 206). The method 200 may include generating an array of characters (ACT 208). The method 200 may include classifying the digital components (ACT 210). The method 200 may include determining not to include a digital component in the response (ACT 212). The method 200 may include generating a response (ACT 214).
As set forth above, the method 200 may include receiving a request (ACT 202). The data processing system 102 may receive a request from a client computing device 104. The request may be text-based, image-based, or audio-based. The data processing system 102 may receive the request at an interface, such as a network interface or other interface. For audio-based input signals, the data processing system 102 can execute the NLP component 112, which the NLP component 112 can parse the input signal to identify a request and one or more trigger keywords in the input audio signal.
The method 200 may include selecting a digital component (ACT 204). The content selector component 118 can select a digital component. The content selector component 118 can select the digital component based on the request and one or more trigger keywords identified in the request. The selected numeric component may include text (e.g., one or more characters). The digital component may be user-generated content, such as a user-provided comment or comment. When the digital component is video-based or audio-based, the manipulation detection component 114 can rewrite the audio from the digital component into a string. The manipulation detection component 114 can determine whether to process the digital components based on the selected digital components or metadata thereof. For example, the metadata may indicate that the digital component was received from the trusted content provider device 106, and the manipulation detection component 114 may determine that the digital component is to be included in the response without determining whether the digital component includes manipulated text because the digital component was received from the trusted content provider device 106.
The method 200 may include retrieving a dictionary (ACT 206). The dictionary may indicate the most common characters in the unmanipulated number components. The dictionary may include a portion of the total possible characters that may be used in the digital components. Characters in the dictionary may be one-hot encoded to form a matrix of one-hot encoded characters. For example, individual characters may form a row of a matrix, wherein the values of the binary array are generated by a one-hot encoding forming the columns in the row.
The data store 122 may include a plurality of different dictionaries 124. The data processing system 102 may generate and store different dictionaries 124 for different groups of digital components. The digital components may be grouped based on the language used in the digital components, the region in which the digital components are generated (or intended to be displayed), or the subject matter of the digital components. The manipulation detection component 114 can identify the grouping (e.g., which language or topic category) with which the selected digital component is associated and then select the corresponding dictionary 124.
Referring also to FIG. 3, the method 200 may include generating a character array (ACT 208). Fig. 3 illustrates the process of dividing a digital component 300 into a plurality of portions 302 and then converting the portions 302 into at least one character array 304.
As illustrated in fig. 3, wherein the numeric component 300 may include a plurality of characters 301. The manipulation detection component 114 can divide the plurality of characters into portions 302. The manipulation detection component 114 can analyze an array of characters of a predetermined length. For example, the manipulation detection component 114 can generate and analyze character arrays of about 1 to about 500 characters in length, about 20 to about 150 characters in length, about 50 to about 150 characters in length, about 100 to about 150 characters in length, or about 120 to about 150 characters in length. As illustrated in fig. 3, when the number component 300 includes more characters than a predetermined length, the manipulation detection component 114 can divide the plurality of characters into different portions each having a predetermined length (e.g., 120 characters).
When a portion is less than the predetermined length, the portion may be zero-padded to reach the predetermined length. When the digital component 300 is less than the overall predetermined length, the manipulation detection component 114 can generate a single portion that is zero-padded to reach the predetermined length. The different portions may be generated by sliding windows. In some embodiments, there is no overlap between these portions. In some examples, there may be 50% overlap between the portions and about 99%, about 60% to about 99%, about 75% to about 99%, or about 95% to about 99%. As illustrated in FIG. 3, portions 302(1) and 302(2) are generated by sliding the window a distance of one character. In the example illustrated in FIG. 3, if each portion is n characters 301 in length, the overlap is (n-1) characters 301.
Referring to fig. 1 and 3, wherein the manipulation detection component 114 can convert each of these portions 302 into an array of characters 304 by using the dictionary 124 selected and retrieved at ACT 206. For example, as illustrated in FIG. 3, portion 302(1) may be converted to character array 304(1), and portion 302(2) may be converted to character array 304 (2). The character array 304 may be a data structure that includes an array of values. Each character 301 in the portion 302 may be converted to a value (or integer) in the array of characters 302 by using the character 301 as an input to the dictionary 124, which dictionary 124 may be used as a lookup table for converting between the character 301 and its corresponding integer. The character array 304 may be one-hot encoded. For example, each value of the character array 304 may be converted to a binary array. When converting characters to integers, the dictionary indices may be one-hot encoded to generate an array of one-hot encoded characters.
Referring to FIG. 2, among other things, the method 200 may include classifying the digital components (ACT 210). The manipulation detection component 114 can classify the digital component into a first category of a plurality of categories. The classification by the manipulation detection component 114 can be based on a sequence (or order) of a first plurality of characters in the array of characters. For example, characters from the digital component (or a one-hot encoded version of the character) may be sequentially fed as input into a classifier of the manipulation detection component. The classifier may have two output categories: a manipulated category and an un-manipulated category. The classifier may be, may include, or may be part of a long-short term memory neural network.
The method 200 may include determining not to include a digital component in the response (ACT 212). Determining not to include the digital component into the response to the content request from the client computing device may be based on classifying the digital component into a manipulated category. For example, if the digital components are classified into manipulated categories, the digital components may be removed or purged from the data store 122, or restricted or excluded during the content selection process (e.g., ACT 204).
The method 200 may include generating a response (ACT 214). The response may be generated in response to the request received at the ACT 202. The data processing system 102 may generate a response that does not include the digital component selected at ACT 204. The decision not to include a digital component may be based on a classification of the digital component in the manipulated category.
The manipulation detection component 114 can instruct the content selector component 118 to select a second digital component based on determining not to include the originally selected digital component in the response (because the selected digital component has been classified into the manipulated category). The manipulation detection component 114 can repeat the ACTS 206-210 to classify the second digital component. The manipulation detection component 114 can repeat the ACT described above until a digital component classified as a non-manipulated category is selected. A numerical component classified into an unworked category may be included in the response.
If the manipulation detection component 114 determines to classify a predetermined number of digital components from the content provider device 106 as manipulated digital components, the manipulation detection component 114 can classify the content provider device 106 as an untrusted content provider. Once classified as an untrusted content provider, the data processing system 102 may not request the digital component from the untrusted content provider (or may automatically reject the digital component from the untrusted content provider). If the manipulation detection component 114 determines to classify a predetermined number of digital components from the content provider device 106 as un-manipulated digital components, the manipulation detection component 114 can classify the content provider device 106 as an authentic content provider. Based on being classified as a trusted content provider device, manipulation detection component 114 can not process the digital components from the trusted content provider device to determine whether they include manipulated text, or manipulation detection component 114 can process only a portion of the digital components from the trusted content provider device. For example, the manipulation detection component 114 can process only every n digital components from the trusted content provider device. The manipulation detection component 114 can mark the content provider device 106 as an authentic content provider based on establishing the owner or authenticity of the content provider device 106. For example, the data processing system 102 may mark the content provider device 106 as a trusted content provider if the identity of the content provider device can be verified, for example, during registration with the data processing system 102.
The input request may be voice-based and the numeric component included in the response may be text-based, such as a user-generated comment or comment. The audio signal generator component may convert the digital component into an output audio file to be transmitted and rendered at the client computing device 104.
Fig. 4 is a block diagram of an example computer system 400. Computer system or computing device 400 may include system 100 or a component thereof, such as data processing system 102, or system 100 or a component thereof, such as data processing system 102, may be implemented using computer system or computing device 400. Computing system 400 includes a bus 405 or other communication component for communicating information, and a processor 410 or processing circuit coupled with bus 405 for processing information. Computing system 400 may also include one or more processors 410 or processing circuits coupled to the bus for processing information. Computing system 400 also includes main memory 415, such as a Random Access Memory (RAM) or other dynamic storage device, coupled to bus 405 for storing information and instructions to be executed by processor 410. The main memory 415 may be or may include the data store 122. Main memory 415 also may be used for storing location information, temporary variables, or other intermediate information during execution of instructions by processor 410. Computing system 400 may further include a Read Only Memory (ROM)420 or other static storage device coupled to bus 405 for storing static information and instructions for processor 410. A storage device 425, such as a solid state device, magnetic disk or optical disk, may be coupled to bus 405 for persistently storing information and instructions. The storage 425 may include the data store 122 or may be part of the data store 122.
The processes, systems, and methods described herein may be performed by the computing system 400 in response to the processor 410 executing an arrangement of instructions contained in main memory 415. Such instructions may be read into main memory 415 by another computer-readable medium, such as storage device 425. Execution of the arrangement of instructions contained in main memory 415 causes the computing system 400 to perform the illustrative processes described herein. One or more processors in a multi-processing arrangement may also be employed to execute the instructions contained in memory 415. Hard-wired circuitry may be used in place of or in combination with software instructions and the systems and methods described herein. The systems and methods described herein are not limited to any specific combination of hardware circuitry and software.
Although an example computing system has been described in FIG. 4, the subject matter including the operations described in this specification can be implemented with other types of digital electronic circuitry, or with computer software, firmware, or hardware, including the structures disclosed in this specification and their structural equivalents, or with combinations of one or more of them.
Where the system discussed herein collects or otherwise makes available personal information about a user, the user may be provided with the following opportunities: control whether programs or features may gather personal information (e.g., information about a user's social network, social actions or activities, a user's preferences, or a user's location) or control whether or how content may be more relevant to a user is received from a content server or other data processing system. In addition, prior to storing or using the particular data, the particular data may be anonymized in one or more ways, such that the personal identity information may be removed when generating the parameters. For example, the identity of the user may be anonymized, such that no personal identity information of the user can be determined, or the geographic location of the user from which location information (such as a city, zip code, or state county level) may be obtained may be generalized, such that no particular location of the user can be determined. Thus, the manner in which information about the user is collected and used by the content server may be controlled by the user.
The subject matter and the operations described in this specification can be implemented in digital electronic circuitry, or in computer software, firmware, or hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them. The subject matter described in this specification can be implemented as one or more computer programs, e.g., one or more circuits of computer program instructions, encoded on one or more computer storage media, executed by data processing apparatus, or to control the operation of the data processing apparatus. Alternatively or in addition, the program instructions may be encoded on an artificially generated propagated signal, e.g., a machine-generated electrical, optical, or electromagnetic signal, that is generated to encode information for transmission to suitable receiver apparatus for execution by a data processing apparatus. The computer storage media may be or be included in a computer-readable storage device, a computer-readable storage substrate, a random or serial access memory array or device, or a combination of one or more of them. When the computer storage medium is not a propagated signal, the computer storage medium can be the source or destination of the computer program instructions encoded in an artificially generated propagated signal. The computer storage medium may also be, or be included in, one or more separate components or media (e.g., multiple CDs, disks, or other storage devices). The operations described in this specification may be implemented as operations performed by a data processing apparatus on data stored on one or more computer-readable storage devices or received from other sources.
The terms "data processing system," "computing device," "component," or "data processing apparatus" encompass various devices, apparatuses, and machines for processing data, including: such as a programmable processor, a computer, a system on a chip, or a combination or multiple of the foregoing. An apparatus may comprise special purpose logic circuitry, e.g., a Field Programmable Gate Array (FPGA) or an Application Specific Integrated Circuit (ASIC). The apparatus can include, in addition to hardware, code that creates an execution environment for the computer program in question, e.g., code that constitutes processor firmware, a protocol stack, a database management system, an operating system, a cross-platform runtime environment, a virtual machine, or a combination of one or more of them. The devices and execution environments may implement a variety of different computing model infrastructures, such as web services, distributed computing and grid computing infrastructures. The direct action API116, the content selector component 118, or the NLP component 112 and other data processing system 102 components may include or share one or more data processing devices, systems, computing devices, or processors.
A computer program (also known as a program, software application, script, or code) can be written in any form of programming language, including compiled or interpreted languages, declarative or procedural languages, and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, object, or other unit suitable for use in a computing environment. The computer program may correspond to a file in a file system. A computer program can be stored in a portion of a file that holds other programs or data (e.g., one or more scripts stored in a markup language document), in a single file dedicated to the program in question, or in multiple coordinated files (e.g., files that store one or more modules, sub programs, or portions of code). A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network.
The processes and logic flows described in this specification can be performed by one or more programmable processors executing one or more computer programs (e.g., components of data processing system 102) to perform actions by operating on input data and generating output. The processes and logic flows can also be performed by, and apparatus can also be implemented as, special purpose logic circuitry, e.g., an FPGA or an ASIC. Devices suitable for storing computer program instructions and data include all forms of non-volatile memory, media and memory devices, including: for example, semiconductor memory devices (e.g., EPROM, EEPROM, and flash memory devices), magnetic disks (e.g., internal hard disk or removable disk), magneto-optical disks, CD-ROM disks, and DVD-ROM disks. The processor and the memory can be supplemented by, or incorporated in, special purpose logic circuitry.
The subject matter described herein can be implemented in a computing system that includes a back-end component (e.g., as a data server), or that includes a middleware component (e.g., an application server), or that includes a front-end component (e.g., a client computer having a graphical user interface or a web browser through which a user can interact with an implementation of the subject matter described in this specification), or a computing system that includes one or more such back-end, middleware, or front-end components. The components of the system can be interconnected by any form or medium of digital data communication (e.g., a communication network). Examples of communication networks include: local area networks ("LANs") and wide area networks ("WANs"), the internet (e.g., the internet), and peer-to-peer networks (e.g., ad hoc peer-to-peer networks).
A computing system, such as system 100 or system 400, may include clients and servers. A client and server are generally remote from each other and typically interact through a communication network, such as network 105. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other. In some embodiments, the server transmits data (e.g., data packets representing the action data structure or digital components) to the client device (e.g., to the client computing device 104 for displaying data to a user interacting with the client device and receiving user input from the user, or to the content provider computing device 106). Data generated at the client device (e.g., the result of the user interaction) may be received from the client device at the server (e.g., data generated at the client device may be received by the data processing system 102 from the computing device 104 or the content provider computing device 106).
Although operations are depicted in the drawings in a particular order, these operations need not be performed in the particular order shown or in sequential order, and all illustrated operations need not be performed. The actions described herein may be performed in a different order.
The separation of various system components is not required in all embodiments, and the described program components may be included in a single hardware or software product. For example, the NLP component 112 or the content selector component 118 may be a single component, an application program, or a logic device having one or more processing circuits, or part of one or more servers of the data processing system 102.
Having now described some illustrative embodiments, it is apparent that the foregoing description is illustrative and not limiting, having been presented by way of example. In particular, although many of the examples presented herein involve specific combinations of method acts or system elements, these acts and these elements may be combined in other ways to accomplish the same objectives. Acts, elements and features discussed in connection with one embodiment are not intended to be excluded from other embodiments or similar uses in embodiments.
The phraseology and terminology used herein is for the purpose of description and should not be regarded as limiting. The use of "including", "comprising", "having", "containing", "involving", "characterized by", "characterized in that" and variations thereof herein is intended to encompass the items listed thereafter, equivalents thereof, and additional items, as well as alternative embodiments consisting of the items listed thereafter. In one embodiment, the systems and methods described herein consist of each and every combination of one, more than one, or all of the described elements, acts, or components.
Any reference to an embodiment or element or act of the systems and methods herein referred to in the singular may also encompass embodiments comprising a plurality of such elements, and a plurality of references to any embodiment or element or act herein may also encompass embodiments comprising only a single element. References in the singular or plural form are not intended to limit the presently disclosed systems and methods, their components, acts, or elements to a single or multiple configurations. Reference to any action or element based on any information, action, or element may include an implementation in which the action or element is based, at least in part, on any information, action, or element.
Any embodiment disclosed herein may be combined with any other embodiment or examples, and references to "an embodiment," "some embodiments," "an embodiment," etc. are not necessarily mutually exclusive and are intended to indicate that a particular feature, structure, or characteristic described in connection with the embodiment may be included in at least one embodiment or example. Such terms as used herein do not necessarily all refer to the same embodiment. Any embodiment may be included in any manner consistent with the aspects and embodiments disclosed herein or combined exclusively with any other embodiment.
References to "or" may be construed as inclusive such that any term described by use of "or" may indicate any of a single, more than one, and all of the described terms. For example, a reference to "at least one of a 'and' B" can include 'a', 'B', and both 'a' and 'B'. Such references used in connection with "including" or other open terms may include additional items.
Reference numerals have been attached to the figures, the detailed description, or any technical features in the claims, which have been included to increase the intelligibility of the figures, the detailed description, and the claims. Thus, the presence or absence of a reference numeral does not impose any limitation on the scope of any claim element.
The systems and methods described herein may be embodied in other specific forms without departing from the characteristics thereof. The foregoing embodiments are illustrative, and are not intended to limit the described systems and methods. The scope of the systems and methods described herein is, therefore, indicated by the appended claims rather than by the foregoing description, and all changes that come within the meaning and range of equivalency of the claims are intended to be embraced therein.
Claims (15)
1. A system for limiting content delivery in a network environment, comprising:
a data processing system having one or more processors coupled with a memory;
a natural language processor component executed by the data processing system for parsing an input audio signal acquired via a sensor on a client device to identify a content request and a trigger keyword;
a content selector component executed by the data processing system for selecting a first numeric component based on the content request and the trigger keyword, the first numeric component comprising a first plurality of characters; and
a manipulation detection component executed by the data processing system to:
retrieving a dictionary comprising indications of a portion of candidate characters included in a plurality of digit components;
converting the first plurality of characters into a character vector based on the indication in the dictionary of a portion of the candidate characters included in the plurality of numeric components;
classifying the first numeric component into a first category of a plurality of categories based on the sequence of the first plurality of characters in the character vector;
determining, based on classifying the first digital component into the first one of the plurality of categories, to include the first digital component in a response to the content request from the client device; and
generating the response based on the content request from the client device, the response including the first digital component in response to determining to include the first digital component in the response.
2. The system of claim 1, comprising:
the content selector component to select a second digital component based on a second content request, the second digital component comprising a second plurality of characters; and
the manipulation detection assembly is to:
converting the second plurality of characters into a second character vector based on the indication in the dictionary of a portion of the candidate characters included in the plurality of numeric components;
classifying the second digital component into a second one of a plurality of classes based on the sequence of the second plurality of characters in the second character vector;
based on classifying the second digital component into the second one of the plurality of categories, determining to include the second digital component in a second response to the second content request from the client device; and
generating the second response based on the second content request, the response lacking the second digital component in response to determining to include the second digital component into the response.
3. The system of claim 1, comprising:
a content selector component to select a second digital component based on a second content request, the second digital component comprising a second plurality of characters; and
the manipulation detection assembly is to:
dividing the second plurality of characters into a first portion and a second portion;
converting the first portion of the second plurality of characters to a second character vector and converting the second portion of the second plurality of characters to a third character vector; and
classifying the second digital component into the first one of the plurality of categories based on the sequence of the second plurality of characters in the first portion and the sequence of the second plurality of characters in the second portion.
4. The system of claim 1, comprising the manipulation detection component to:
identifying a length of a first plurality of characters included in the first digital component;
determining that a length of the first plurality of characters does not match a predetermined length for comparison with the indication of a portion of the candidate characters of the dictionary; and
in response to the determination, adjusting a length of the first plurality of characters to reach the predetermined length.
5. The system of claim 1, comprising the manipulation detection component to:
identifying the plurality of digital components of the dictionary;
determining, for each character of the plurality of characters, a number of occurrences between the plurality of numeric components; and
selecting a portion of the candidate characters in the plurality of number components based on a number of occurrences of each of the plurality of candidate characters in the plurality of number components.
6. The system of claim 1, comprising the manipulation detection component to:
retrieving a dictionary comprising the indication, the indication comprising an encoding for converting an input character into an encoded value for the input character; and
converting the first plurality of characters into an encoded vector based on the encoding of the dictionary, the encoded vector comprising a one-hot encoding of the first plurality of characters.
7. The system of claim 1, comprising the manipulation detection component to:
retrieving a dictionary comprising the indication, the indication comprising a look-up table to convert an input character to an integer for the input character; and
converting the first plurality of characters to integer vectors according to the lookup table of the dictionary.
8. The system of claim 1, comprising the manipulation detection component to retrieve the dictionary from a plurality of dictionaries based on at least one of a language or a subject matter of the first number component, each dictionary of the plurality of dictionaries comprising a corresponding plurality of number components.
9. The system of claim 1, comprising the manipulation detection component to create a dictionary to include a matrix of encoded characters from a portion of the candidate characters included in the plurality of numeric components.
10. The system of claim 1, comprising the manipulation detection component to convert audio output of the first digital component to the first plurality of characters for classification in response to selection of the first digital component.
11. The system of claim 1, comprising the content selector component to select the first digital component in response to determining that a second digital component is not included in the response, the second digital component including a second plurality of characters.
12. A method for limiting content transmission in a network environment, comprising:
parsing, by a data processing system having one or more processors, an input audio signal acquired via a sensor on a client device to identify a content request and a trigger keyword;
selecting, by the data processing system, a first numeric component based on the content request and the trigger keyword, the first numeric component comprising a first plurality of characters;
retrieving, by the data processing system, a dictionary comprising indications of a portion of candidate characters included in a plurality of number components;
converting, by the data processing system, the first plurality of characters into a character vector based on the indication in the dictionary of the portion of the candidate character included in the plurality of numeric components;
classifying, by the data processing system, the first numeric component into a first category of a plurality of categories based on the sequence of the first plurality of characters in the character vector;
determining, by the data processing system, to include the first digital component in a response to the content request from the client device based on classifying the first digital component into the first one of the plurality of categories; and
generating, by the data processing system, the response based on the content request from the client device, the response including the first digital component in response to determining to include the first digital component in the response.
13. The method of claim 12, comprising:
selecting, by the data processing system, a second digital component based on a second content request, the second digital component comprising a second plurality of characters;
converting, by the data processing system, the second plurality of characters into a second character vector based on the indication in the dictionary of the portion of the candidate character included in the plurality of numeric components;
classifying, by the data processing system, the second digital component into a second category of a plurality of categories based on the sequence of the second plurality of characters in the second character vector;
determining, by the data processing system, based on classifying the second digital component into the second one of the plurality of classes, to include the second digital component in a second response to the second content request from the client device; and
generating, by the data processing system, the second response based on the second content request, the response lacking the second digital component in response to determining to include the second digital component into the response.
14. The method of claim 12, comprising:
selecting, by the data processing system, a second digital component based on a second content request, the second digital component comprising a second plurality of characters;
dividing, by the data processing system, the second plurality of characters into a first portion and a second portion;
converting, by the data processing system, the first portion of the second plurality of characters into a second character vector and the second portion of the second plurality of characters into a third character vector; and
classifying, by the data processing system, the second digital component into the first one of the plurality of classes based on the sequence of the second plurality of characters in the first portion and the sequence of the second plurality of characters in the second portion.
15. The method of claim 12, comprising: retrieving, by the data processing system, the dictionary from a plurality of dictionaries based on at least one of a language or a topic of the first number component, each dictionary of the plurality of dictionaries comprising a corresponding plurality of number components.
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
CN202110176028.0A CN113037715B (en) | 2017-12-08 | 2017-12-08 | Transmission system and method for limiting manipulation of content in a network environment |
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
CN201780013402.7A CN110149810B (en) | 2017-12-08 | 2017-12-08 | Transmission system and method for limiting manipulation of content in a network environment and digital assistant device |
PCT/US2017/065457 WO2019112622A1 (en) | 2017-12-08 | 2017-12-08 | Restrict transmission of manipulated content in a networked environment |
CN202110176028.0A CN113037715B (en) | 2017-12-08 | 2017-12-08 | Transmission system and method for limiting manipulation of content in a network environment |
Related Parent Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201780013402.7A Division CN110149810B (en) | 2017-12-08 | 2017-12-08 | Transmission system and method for limiting manipulation of content in a network environment and digital assistant device |
Publications (2)
Publication Number | Publication Date |
---|---|
CN113037715A true CN113037715A (en) | 2021-06-25 |
CN113037715B CN113037715B (en) | 2023-05-30 |
Family
ID=60935971
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202110176028.0A Active CN113037715B (en) | 2017-12-08 | 2017-12-08 | Transmission system and method for limiting manipulation of content in a network environment |
CN201780013402.7A Active CN110149810B (en) | 2017-12-08 | 2017-12-08 | Transmission system and method for limiting manipulation of content in a network environment and digital assistant device |
Family Applications After (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201780013402.7A Active CN110149810B (en) | 2017-12-08 | 2017-12-08 | Transmission system and method for limiting manipulation of content in a network environment and digital assistant device |
Country Status (4)
Country | Link |
---|---|
US (1) | US11356474B2 (en) |
EP (2) | EP3661158A1 (en) |
CN (2) | CN113037715B (en) |
WO (1) | WO2019112622A1 (en) |
Families Citing this family (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11886794B2 (en) * | 2020-10-23 | 2024-01-30 | Saudi Arabian Oil Company | Text scrambling/descrambling |
Citations (10)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20050076084A1 (en) * | 2003-10-03 | 2005-04-07 | Corvigo | Dynamic message filtering |
US20110231564A1 (en) * | 2000-09-25 | 2011-09-22 | Yevgeny Korsunsky | Processing data flows with a data flow processor |
US20110321170A1 (en) * | 2010-06-29 | 2011-12-29 | Hitachi, Ltd. | Fraudulent manipulation detection method and computer for detecting fraudulent manipulation |
WO2015021485A1 (en) * | 2013-08-09 | 2015-02-12 | Behavioral Recognition Systems, Inc. | A cognitive neuro-linguistic behavior recognition system for multi-sensor data fusion |
CA2973138A1 (en) * | 2014-01-10 | 2015-07-16 | Cluep Inc. | Systems, devices, and methods for automatic detection of feelings in text |
WO2015195955A1 (en) * | 2014-06-18 | 2015-12-23 | Social Compass, LLC | Systems and methods for categorizing messages |
US20160248719A1 (en) * | 2015-02-24 | 2016-08-25 | International Business Machines Corporation | Dynamic analytics controlled information dissemination in social media |
CN106055560A (en) * | 2016-05-18 | 2016-10-26 | 上海申腾信息技术有限公司 | Method for collecting data of word segmentation dictionary based on statistical machine learning method |
CN107135314A (en) * | 2017-06-21 | 2017-09-05 | 北京奇虎科技有限公司 | Harass detection method, system, mobile terminal and the server of short message |
US20170255867A1 (en) * | 2016-03-01 | 2017-09-07 | Pearson Education, Inc. | System and method for automated pattern based alert generation |
Family Cites Families (20)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6304636B1 (en) * | 1997-12-23 | 2001-10-16 | At&T Corp. | Forwarding voice messages to a called party using electronic mail |
US6769016B2 (en) | 2001-07-26 | 2004-07-27 | Networks Associates Technology, Inc. | Intelligent SPAM detection system using an updateable neural analysis engine |
US8533270B2 (en) | 2003-06-23 | 2013-09-10 | Microsoft Corporation | Advanced spam detection techniques |
US7756535B1 (en) * | 2006-07-07 | 2010-07-13 | Trend Micro Incorporated | Lightweight content filtering system for mobile phones |
WO2010107327A1 (en) * | 2009-03-20 | 2010-09-23 | Syl Research Limited | Natural language processing method and system |
CN104969289B (en) | 2013-02-07 | 2021-05-28 | 苹果公司 | Voice trigger of digital assistant |
US9846623B2 (en) * | 2015-08-20 | 2017-12-19 | Qsigma, Inc. | Simultaneous multi-processor apparatus applicable to acheiving exascale performance for algorithms and program systems |
US10331312B2 (en) * | 2015-09-08 | 2019-06-25 | Apple Inc. | Intelligent automated assistant in a media environment |
US20170092278A1 (en) | 2015-09-30 | 2017-03-30 | Apple Inc. | Speaker recognition |
US9928840B2 (en) | 2015-10-16 | 2018-03-27 | Google Llc | Hotword recognition |
US9747926B2 (en) | 2015-10-16 | 2017-08-29 | Google Inc. | Hotword recognition |
US10691473B2 (en) | 2015-11-06 | 2020-06-23 | Apple Inc. | Intelligent automated assistant in a messaging environment |
US11244349B2 (en) | 2015-12-29 | 2022-02-08 | Ebay Inc. | Methods and apparatus for detection of spam publication |
US10467277B2 (en) * | 2016-03-25 | 2019-11-05 | Raftr, Inc. | Computer implemented detection of semiotic similarity between sets of narrative data |
US9842100B2 (en) * | 2016-03-25 | 2017-12-12 | TripleDip, LLC | Functional ontology machine-based narrative interpreter |
US20170277996A1 (en) * | 2016-03-25 | 2017-09-28 | TripleDip, LLC | Computer implemented event prediction in narrative data sequences using semiotic analysis |
US10192552B2 (en) | 2016-06-10 | 2019-01-29 | Apple Inc. | Digital assistant providing whispered speech |
US10521945B2 (en) * | 2016-12-23 | 2019-12-31 | International Business Machines Corporation | Text-to-articulatory movement |
WO2018136083A1 (en) * | 2017-01-20 | 2018-07-26 | Visa International Service Association | Automated data discovery with aggregated authentication |
US10929799B2 (en) * | 2017-06-29 | 2021-02-23 | Amazon Technologies, Inc. | Identification of inaccurate addresses for package deliveries |
-
2017
- 2017-12-08 US US16/062,540 patent/US11356474B2/en active Active
- 2017-12-08 CN CN202110176028.0A patent/CN113037715B/en active Active
- 2017-12-08 EP EP20153325.4A patent/EP3661158A1/en active Pending
- 2017-12-08 WO PCT/US2017/065457 patent/WO2019112622A1/en active Application Filing
- 2017-12-08 EP EP17825684.8A patent/EP3523942B1/en active Active
- 2017-12-08 CN CN201780013402.7A patent/CN110149810B/en active Active
Patent Citations (10)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20110231564A1 (en) * | 2000-09-25 | 2011-09-22 | Yevgeny Korsunsky | Processing data flows with a data flow processor |
US20050076084A1 (en) * | 2003-10-03 | 2005-04-07 | Corvigo | Dynamic message filtering |
US20110321170A1 (en) * | 2010-06-29 | 2011-12-29 | Hitachi, Ltd. | Fraudulent manipulation detection method and computer for detecting fraudulent manipulation |
WO2015021485A1 (en) * | 2013-08-09 | 2015-02-12 | Behavioral Recognition Systems, Inc. | A cognitive neuro-linguistic behavior recognition system for multi-sensor data fusion |
CA2973138A1 (en) * | 2014-01-10 | 2015-07-16 | Cluep Inc. | Systems, devices, and methods for automatic detection of feelings in text |
WO2015195955A1 (en) * | 2014-06-18 | 2015-12-23 | Social Compass, LLC | Systems and methods for categorizing messages |
US20160248719A1 (en) * | 2015-02-24 | 2016-08-25 | International Business Machines Corporation | Dynamic analytics controlled information dissemination in social media |
US20170255867A1 (en) * | 2016-03-01 | 2017-09-07 | Pearson Education, Inc. | System and method for automated pattern based alert generation |
CN106055560A (en) * | 2016-05-18 | 2016-10-26 | 上海申腾信息技术有限公司 | Method for collecting data of word segmentation dictionary based on statistical machine learning method |
CN107135314A (en) * | 2017-06-21 | 2017-09-05 | 北京奇虎科技有限公司 | Harass detection method, system, mobile terminal and the server of short message |
Non-Patent Citations (2)
Title |
---|
FABRÍCIO BENEVENUTO，ET.AL: "《https://pdfs.semanticscholar.org/3709/2f9c79cb6220fd6f01882e9e3c1b41d0750e.pdf?_ga=2.185452585.1822534023.1529499559-2135265224.1502202819》", 14 July 2010 * |
RADULESCU CRISTINA，ET.AL: "Identification of spam comments using natural language processing techniques", 《INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTER COMMUNICATION AND PROCESSING 》 * |
Also Published As
Publication number | Publication date |
---|---|
EP3523942A1 (en) | 2019-08-14 |
US20210168168A1 (en) | 2021-06-03 |
US11356474B2 (en) | 2022-06-07 |
CN113037715B (en) | 2023-05-30 |
EP3523942B1 (en) | 2020-02-12 |
CN110149810A (en) | 2019-08-20 |
CN110149810B (en) | 2021-02-26 |
WO2019112622A1 (en) | 2019-06-13 |
EP3661158A1 (en) | 2020-06-03 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US9449271B2 (en) | Classifying resources using a deep network | |
WO2018033030A1 (en) | Natural language library generation method and device | |
CN109857871B (en) | User relationship discovery method based on social network mass contextual data | |
US11562009B2 (en) | Generation of domain-specific models in networked system | |
CN103365833A (en) | Context scene based candidate word input prompt method and system for implementing same | |
US11848009B2 (en) | Adaptive interface in a voice-activated network | |
CN103473036B (en) | A kind of input method skin method for pushing and system | |
CN111344694B (en) | Interface for distributed network system | |
US11438346B2 (en) | Restrict transmission of manipulated content in a networked environment | |
Koswatte et al. | VGI and crowdsourced data credibility analysis using spam email detection techniques | |
CN110149810B (en) | Transmission system and method for limiting manipulation of content in a network environment and digital assistant device | |
Murthy et al. | TwitSenti: a real-time Twitter sentiment analysis and visualization framework | |
CN113065348B (en) | Internet negative information monitoring method based on Bert model | |
CN111213136B (en) | Generation of domain-specific models in networked systems | |
US11798555B2 (en) | Detection of duplicate packetized data for selective transmission into one of a plurality of a user's devices | |
CN114491235A (en) | Content recommendation device, electronic equipment and computer readable medium | |
CN116306567A (en) | Dark chain detection method, device, equipment and storage medium | |
CN117910593A (en) | Barrage information analysis method based on personalized federal learning |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
GR01 | Patent grant | ||
GR01 | Patent grant |