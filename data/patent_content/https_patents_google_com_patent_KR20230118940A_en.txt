KR20230118940A - Transferring conversational data from an initial on-call automated assistant to a subsequent on-call automated assistant - Google Patents
Transferring conversational data from an initial on-call automated assistant to a subsequent on-call automated assistant Download PDFInfo
- Publication number
- KR20230118940A KR20230118940A KR1020237023567A KR20237023567A KR20230118940A KR 20230118940 A KR20230118940 A KR 20230118940A KR 1020237023567 A KR1020237023567 A KR 1020237023567A KR 20237023567 A KR20237023567 A KR 20237023567A KR 20230118940 A KR20230118940 A KR 20230118940A
- Authority
- KR
- South Korea
- Prior art keywords
- automated assistant
- user
- assistant
- conversation
- call
- Prior art date
Links
Classifications
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/22—Procedures used during a speech recognition process, e.g. man-machine dialogue
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/903—Querying
- G06F16/9032—Query formulation
- G06F16/90332—Natural language query formulation or dialogue systems
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/16—Sound input; Sound output
- G06F3/167—Audio in a user interface, e.g. using voice commands for navigating, audio feedback
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/30—Semantic analysis
- G06F40/35—Discourse or dialogue representation
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L17/00—Speaker identification or verification
- G10L17/04—Training, enrolment or model building
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L17/00—Speaker identification or verification
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/22—Procedures used during a speech recognition process, e.g. man-machine dialogue
- G10L2015/223—Execution procedure of a spoken command
Abstract
시스템 및 방법은 초기 호출형 자동화 어시스턴트로부터 후속 호출형 자동화 어시스턴트로 대화 데이터를 제공하기 위한 것이다. 제1 자동화 어시스턴트는 사용자 발언에 의해 호출될 수 있고, 이어서 제1 자동화 어시스턴트에 의해 처리되는 사용자와의 대화가 이어질 수 있다. 대화 중에, 대화 데이터를 제2 자동화 어시스턴트로 전송하라는 요청이 수신된다. 요청은 사용자, 제1 자동화 어시스턴트 및/또는 제2 자동화 어시스턴트에서 발생할 수 있다. 일단 권한이 부여되면, 제1 자동화 어시스턴트는 제2 자동화 어시스턴트에게 이전 대화 데이터를 제공한다. 제2 자동화 어시스턴트는 대화 데이터에 기초하여 하나 이상의 액션을 수행한다.Systems and methods are for providing conversational data from an initial on-call automated assistant to a subsequent on-call automated assistant. The first automated assistant may be invoked by a user utterance, followed by a conversation with the user handled by the first automated assistant. During the conversation, a request is received to send conversation data to the second automated assistant. The request can originate from the user, the first automated assistant and/or the second automated assistant. Once authorized, the first automated assistant provides the previous conversation data to the second automated assistant. The second automated assistant performs one or more actions based on the conversation data.
Description
인간은 본 명세서에서 "자동화 어시스턴트(automated assistants)"("디지털 에이전트", "챗봇", "대화형 개인 비서", "지능형 개인 비서", "어시스턴트 애플리케이션", "대화형 에이전트"라고도 지칭됨)라고 지칭되는 대화형 소프트웨어 애플리케이션을 사용하여 인간 대 컴퓨터 대화에 참여할 수 있다. 예를 들어, 인간(자동화 어시스턴트와 상호 작용할 때 "사용자"라고 지칭될 수 있음)은 음성 자연어 입력(즉, 발언)을 사용하여 자동화 어시스턴트에게 명령(command) 및/또는 요청을 제공할 수 있으며, 이는 경우에 텍스트로 변환된 다음 처리될 수 있고 및/또는 텍스트(예를 들어, 타이핑된) 자연어 입력을 제공함으로써 가능하다. 자동화 어시스턴트는 음성 및/또는 시각적 사용자 인터페이스 출력을 포함할 수 있는 응답형 사용자 인터페이스 출력을 제공함으로써 요청에 응답한다.Humans are referred to herein as "automated assistants" (also referred to herein as "digital agents", "chatbots", "interactive personal assistants", "intelligent personal assistants", "assistant applications", "interactive agents") , can be used to engage in human-to-computer conversations. For example, a human (who may be referred to as a "user" when interacting with an automated assistant) may use spoken natural language input (i.e., speak) to provide commands and/or requests to an automated assistant; This can in some cases be converted to text and then processed and/or by providing textual (eg typed) natural language input. The automated assistant responds to the request by providing responsive user interface output, which may include audio and/or visual user interface output.
위에서 언급한 바와 같이, 많은 자동화 어시스턴트는 어시스턴트 호출에 뒤따르는 음성 발언(spoken utterances)을 통해 상호 작용하도록 구성된다. 사용자 개인 정보 보호 및/또는 리소스 절약을 위해, 사용자는 종종 자동화 어시스턴트가 음성 발언을 완전히 처리하기 전에 자동화 어시스턴트를 명시적으로 호출해야 한다. 자동화 어시스턴트의 명시적 호출은 일반적으로 클라이언트 디바이스에서 수신되는 특정 사용자 인터페이스 입력에 대한 응답으로 발생한다. 클라이언트 디바이스는 클라이언트 디바이스의 사용자에게, 자동화 어시스턴트와 인터페이스하기 위한 인터페이스를 제공(예를 들어, 사용자로부터 음성 및/또는 타이핑된 입력을 수신하고, 청각적 및/또는 그래픽 응답을 제공)하고, 자동화 어시스턴트를 구현하는 하나 이상의 컴포넌트(예를 들어, 사용자 입력을 처리하고 적절한 응답을 생성하는 원격 서버 디바이스(들))와 인터페이스한다.As noted above, many automated assistants are configured to interact through spoken utterances that follow an assistant call. To protect user privacy and/or conserve resources, users often must explicitly invoke an automated assistant before it can fully process a spoken utterance. Explicit invocation of an automated assistant typically occurs in response to certain user interface inputs received on the client device. The client device provides the user of the client device with an interface for interfacing with the automated assistant (eg, receiving voice and/or typed input from the user and providing audible and/or graphical responses), and interfaces with one or more components that implement (eg, a remote server device(s) that processes user input and generates appropriate responses).
클라이언트 디바이스를 통해 자동화 어시스턴트를 호출할 수 있는 일부 사용자 인터페이스 입력은 자동화 어시스턴트를 호출하기 위한 클라이언트 디바이스의 하드웨어 및/또는 가상 버튼(예를 들어, 하드웨어 버튼의 탭, 클라이언트 디바이스에 의해 디스플레이되는 그래픽 인터페이스 요소의 선택)을 포함한다. 많은 자동화 어시스턴트가 "핫 워드/문구" 또는 "트리거 단어/문구"라고도 하는 하나 이상의 음성 호출 문구에 응답하여 추가로 또는 대안으로 호출될 수 있다. 예를 들어, "Hey Assistant", "OK Assistant" 및/또는 "Assistant"와 같은 음성 호출 문구를 말하여 자동화 어시스턴트를 호출할 수 있다.Some user interface inputs that can invoke an automated assistant through a client device include a hardware and/or virtual button on the client device for invoking an automated assistant (e.g., a tap on a hardware button, a graphical interface element displayed by the client device). of) is included. Many automated assistants may additionally or alternatively be invoked in response to one or more spoken paging phrases, also referred to as “hot words/phrases” or “trigger words/phrases.” For example, an automated assistant may be invoked by saying a voice call phrase such as “Hey Assistant,” “OK Assistant,” and/or “Assistant.”
종종, 어시스턴트 인터페이스를 포함하는 클라이언트 디바이스는 음성 호출 문구의 발생을 적어도 선택적으로 모니터링하기 위해 클라이언트 디바이스가 이용하는 하나 이상의 로컬로 저장된 모델을 포함한다. 이러한 클라이언트 디바이스는 수신된 오디오 데이터를 로컬로 저장된 모델을 이용하여 로컬로 처리할 수 있고 음성 호출 문구를 포함하지 않는 임의의 오디오 데이터를 폐기할 수 있다. 그러나, 수신된 오디오 데이터의 로컬 처리가 음성 호출 문구의 발생을 나타내는 경우, 클라이언트 디바이스는 해당 오디오 데이터 및/또는 후속 오디오 데이터가 자동화 어시스턴트에 의해 추가로 처리되도록 할 것이다. 예를 들어, 음성 호출 문구가 "Hey, Assistant"이고 사용자가 "Hey, Assistant, what time is it"이라고 말하면, "What time is it"에 해당하는 오디오 데이터는 "Hey, Assistant"의 검출에 기초하여 자동화 어시스턴트에 의해 처리되고, 현재 시간에 대한 자동화 어시스턴트 응답을 제공하는데 이용될 수 있다. 반면에, 사용자가 (먼저 호출 문구을 말하거나 대체 호출 입력을 제공하지 않고) 단순히 "What time is it"이라고 말하면, "What time is it" 앞에 호출 문구가 없기 때문에 자동화 어시스턴트로부터의 응답이 제공되지 않을 것이다.Often, a client device that includes an assistant interface includes one or more locally stored models that the client device uses to at least selectively monitor occurrences of voice paging phrases. Such a client device can process received audio data locally using the locally stored model and discard any audio data that does not contain a voice call phrase. However, if local processing of the received audio data indicates the occurrence of a spoken paging phrase, the client device will cause that audio data and/or subsequent audio data to be further processed by the automated assistant. For example, if the voice paging phrase is "Hey, Assistant" and the user says "Hey, Assistant, what time is it", the audio data corresponding to "What time is it" is based on the detection of "Hey, Assistant". and processed by the automated assistant, and used to provide the automated assistant response for the current time. On the other hand, if the user simply says "What time is it" (without first saying the paging phrase or providing an alternative paging input), no response from the automated assistant will be provided because there is no paging phrase before "What time is it". will be.
대화 데이터를 전송하라는 요청에 응답하여 제1 자동화 어시스턴트로부터 제2 자동화 어시스턴트로 대화 데이터를 제공하기 위한 기술이 본 명세서에서 설명된다. 예를 들어, 다양한 기술은 초기 호출형(invoked, 호출된) 자동화 어시스턴트에 의해, 사용자와 초기 호출형 자동화 어시스턴트 사이의 대화를 처리하고, 대화의 일부인 질의(query)의 처리를 제2 자동화 어시스턴트로 전송하라는 요청을 수신하고, 추가 처리를 위해 대화 데이터를 나타내는 대화 데이터를 제2 자동화 어시스턴트에 제공하는 것에 관한 것이다. 사용자는 처음에 자동화 어시스턴트를 호출하고 그 호출된 자동화 어시스턴트가 응답을 생성할 수 있는 하나 이상의 질의를 말할 수 있다. 사용자와 초기 호출형 자동화 어시스턴트 사이의 대화 중 어느 지점에서, 사용자가 추가 대화에 관심이 있고 및/또는 제2 자동화 어시스턴트에 의해 처리되고 있는 질의에 관심이 있음을 나타내는 요청이 수신될 수 있다. 대화 및/또는 그 대화와 관련된 대화 데이터는 응답을 생성하기 위해 질의를 처리하는 것과 같은 하나 이상의 액션(동작)을 수행할 수 있는 제2 어시스턴트에게 초기 호출형 자동화 어시스턴트에 의해 제공될 수 있다. 이들 및 다른 방식으로, 제2 어시스턴트는 계산 부담이 큰 사용자와의 대화에 참여하지 않고도 대화 및/또는 대화 데이터를 획득할 수 있다. 게다가, 초기 호출형 자동화 어시스턴트는 대화 및/또는 대화 데이터를 제2 어시스턴트로 선택적으로 전송함으로써 사용자-어시스턴트 대화를 안내할 수 있다. 또한, 제2 어시스턴트는 일부 구현에서 초기 호출형 자동화 어시스턴트 단독으로 생성할 수 없는 응답을 생성할 수 있으므로 사용자-어시스턴트 대화의 견고성을 증가시킬 수 있다.Techniques for providing conversation data from a first automated assistant to a second automated assistant in response to a request to transmit the conversation data are described herein. For example, various technologies handle a conversation between a user and an initially invoked automated assistant by an initially invoked automated assistant, and process queries that are part of the conversation to a second automated assistant. Receiving a request to transmit and providing conversational data representative of the conversational data to a second automated assistant for further processing. A user can initially invoke an automated assistant and state one or more queries for which the invoked automated assistant can generate a response. At some point during the conversation between the user and the initial on-call automated assistant, a request may be received indicating that the user is interested in further conversation and/or a query being processed by the second automated assistant. The conversation and/or conversational data associated with the conversation may be provided by the initiating automated assistant to a second assistant that may perform one or more actions (actions), such as processing a query to generate a response. In these and other ways, the second assistant can obtain conversations and/or conversation data without engaging in conversations with users with a high computational burden. Additionally, the initial on-call automated assistant may guide the user-assistant conversation by selectively sending the conversation and/or conversation data to the second assistant. In addition, the second assistant can increase the robustness of the user-assistant conversation by being able to generate responses that in some implementations the initiating automated assistant alone cannot generate.
일부 구현에서, 사용자는 제1 자동화 어시스턴트(여기서는 "초기 호출형 자동화 어시스턴트"라고도 함)를 호출하지만 초기 호출형 자동화 어시스턴트가 호출 문구와 관련하여(예를 들어, 바로 뒤, 바로 앞에) 수신된 질의를 처리할 때 적어도 선택적으로 상호 작용할 수 있는 다른 자동화 어시스턴트(들)를 명시적으로 호출하지는 않는 "OK Assistant"와 같은 호출 문구를 말할 수 있다. 따라서, 사용자는 처음 호출된 자동 어시스턴트에 특정된(고유한) 호출 입력을 제공하는 것에 기초하여, 다른 자동화 어시스턴트(들) 중 하나를 개별적으로 호출하기보다는 초기 호출형 자동화 어시스턴트를 이용하도록 지정할 수 있다. 예를 들어, 제1 호출 문구(들)(예를 들어, "OK Assistant A")는 검출될 때 다른 자동화 어시스턴트(들)를 호출하지 않고 제1 자동화 어시스턴트를 독점적으로 호출할 수 있다. 마찬가지로, 제2 호출 문구(들)(예를 들어, "OK Assistant B")는 검출될 때 초기 호출형 자동화 어시스턴트 및/또는 임의의 다른 자동화 어시스턴트(들)를 호출하지 않고 제2 자동화 어시스턴트를 독점적으로 호출할 수 있다. 처음 호출된 어시스턴트는 호출될 때 호출과 관련하여 제공된 입력(들) 처리시 다른 자동화 어시스턴트(즉, "보조 어시스턴트")와 적어도 선택적으로 상호 작용할 수 있다.In some implementations, a user invokes a first automated assistant (also referred to herein as an “initially invoked automated assistant”) but the initial invoiced automated assistant responds to a received query with respect to (eg, immediately after, immediately before) the invocation phrase. You can say an invocation phrase such as “OK Assistant” that does not explicitly invoke another automated assistant(s) with which you can at least optionally interact when processing . Thus, the user may specify to use the initially invoked automated assistant rather than individually calling one of the other automated assistant(s) based on providing a call input specific (unique) to the first invoked automated assistant. . For example, a first paging phrase(s) (eg, “OK Assistant A”), when detected, may exclusively invoke the first automated assistant without invoking other automated assistant(s). Likewise, the second paging phrase(s) (e.g., “OK Assistant B”), when detected, exclusively invokes the second automated assistant without invoking the initially invoked automated assistant and/or any other automated assistant(s). can be called as The initially called assistant, when called, may at least optionally interact with other automated assistants (ie, “assistant assistants”) in processing the input(s) provided in connection with the call.
사용자는 일단 자동화 어시스턴트가 처음 호출되면 사용자가 그 초기 호출형 자동화 어시스턴트와 대화를 계속할 수 있도록 하는 호출 문구를 말함으로써 자동화 어시스턴트를 호출할 수 있다. 대화는 사용자에 의해 발화된 하나 이상의 질의와 이어서 초기 호출형 자동화 어시스턴트에 의해 생성된 하나 이상의 응답으로 구성될 수 있다. 예를 들어, 사용자는 처음에 "OK 어시스턴트 1, 아이들에게 좋은 영화는 뭐야?"라고 말함으로써 어시스턴트 1을 호출할 수 있다. 이 경우, "OK 어시스턴트 1"은 "영화 A가 아이들에게 좋은 영화입니다"라는 응답을 생성하고 제공할 수 있는 제1 자동화 어시스턴트를 호출하는 핫워드일 수 있다. 이에 응답하여, 사용자는 초기 호출형 자동화 어시스턴트와 사용자 사이의 대화를 생성하기 위해 제1 질의와 관련되거나 관련되지 않은 질의 중 하나에 추가 질의를 말할 수 있다. 예를 들어, 사용자는 "또 다른 좋은 영화는 뭐야?"라는 질의를 말하여 이전 질의로부터 "아이들에게 좋은 영화"와 관련된 추가 생성된 응답을 제공받을 수 있다. 또한, 예를 들어, 사용자는 다음에 "오늘 날씨가 어때?"라고 말할 수 있고, 초기 호출형 자동화 어시스턴트는 사용자의 이전 질의 및/또는 초기 호출형 자동화 어시스턴트의 이전 응답과 관련되지 않은 응답을 제공할 수 있다.A user can invoke an automated assistant by speaking a paging phrase that allows the user to continue a conversation with the initially invoked automated assistant once the automated assistant is first invoked. A conversation may consist of one or more queries uttered by a user followed by one or more responses generated by an initially invoiced automated assistant. For example, the user may invoke assistant 1 by initially saying "OK assistant 1, what's a good movie for kids?". In this case, "OK assistant 1" may be a hot word that invokes a first automated assistant that may generate and provide a response "Movie A is a good movie for kids". In response, the user may state a further query to one of the queries related or unrelated to the first query to create a conversation between the initial on-call automated assistant and the user. For example, a user may say a query "what's another good movie?" to be provided with a further generated response related to "good movies for kids" from a previous query. Also, for example, the user may next say, "How's the weather today?", and the initially in-paging automated assistant provides a response unrelated to the user's previous query and/or the initial in-paging automated assistant's previous response. can do.
또 다른 예로서, 자동화 어시스턴트가 "영화 A가 아이들에게 좋은 영화입니다"라고 응답하는 것에 응답하여, 사용자는 "OK, 그것을 스트리밍 서비스에서 재생해 줘"라는 질의를 후속 조치할 수 있다. 이 경우, 자동화 어시스턴트는 질의에 대한 의도를 결정할 수 있으며, 여기에는 사용자와 자동화 어시스턴트 간의 이전 대화에 기초하여 "영화 A"와 같은 "그것"이라는 용어로 사용자가 의도한 바를 결정하는 것이 포함될 수 있다. "그것을 스트리밍 서비스에서 재생해 줘"라는 후속 질의에 응답하여, 초기 호출형 자동화 어시스턴트는 사용자 인터페이스를 통해 사용자에게 "영화 A"를 스트리밍할 수 있는 스트리밍 미디어 애플리케이션("스트리밍 서비스")에 데이터를 제공할 수 있다.As another example, in response to the automated assistant responding "Movie A is a good movie for kids", the user can follow up with a query "OK, play it on a streaming service". In this case, the automated assistant may determine the intent for the query, which may include determining what the user intended with the term "it," such as "movie A," based on previous conversations between the user and the automated assistant. . In response to the subsequent query "play it on a streaming service", the initial invoking automated assistant provides the data to a streaming media application (the "Streaming Service") that can stream "Movie A" to the user via a user interface. can do.
또 다른 예로서, 일단 초기 호출형 자동화 어시스턴트를 호출하면, 사용자는 "샌프란시스코의 날씨는 어때"라는 문구를 말할 수 있으며, 초기 호출형 자동화 어시스턴트는 "오늘 샌프란시스코의 날씨는 화씨 50도이고 구름이 많습니다"와 같아 질의에 응답하는 응답을 생성할 수 있다. 일부 경우, 대화에는 이전 질의와 관련된 사용자의 추가 질의가 포함될 수 있다. 예를 들어, 사용자는 "마이애미는 어때?"라는 후속 질의를 말하여 마이애미의 날씨를 제공받겠다는 의도를 나타낼 수 있다. 이에 대한 응답으로, 초기 호출형 자동화 어시스턴트는 "마이애미의 날씨는 화씨 80도이고 화창한다"라고 응답할 수 있다. 관련된 질의와 관련 없는 의도를 가진 질의 모두에서 사용자와 초기 호출형 자동화 어시스턴트 간에 대화가 계속될 수 있다.As another example, once invoking the initial in-pawn automated assistant, the user can say the phrase "How's the weather in San Francisco?" You can generate a response that answers a query, such as ". In some cases, the conversation may contain additional queries from the user related to previous queries. For example, the user may indicate an intent to be provided with the weather in Miami by saying a follow-up query, “How is Miami?”. In response, the initial on-call automated assistant may respond with "It's 80 degrees Fahrenheit and sunny in Miami." A conversation may continue between the user and the initial invoking automated assistant for both related queries and queries with unrelated intents.
일부 구현에서, 다수의 자동화 어시스턴트가 동일한 환경에 존재할 수 있다. 예를 들어, 사용자는 제2 자동화 어시스턴트를 실행 중인 제2 디바이스에 근접한 디바이스 상에서 실행 중인 자동화 어시스턴트를 호출할 수 있다. 또한, 예를 들어, 사용자는 제2 자동화 어시스턴트도 실행 중인 디바이스 상에서 실행 중인 자동화 어시스턴트를 호출할 수 있다. 이전에 설명된 바와 같이, 사용자는 초기에 자동화된 어시스턴트를 활성화하지만 다른 자동화 어시스턴트를 호출하지 않는 핫워드 또는 문구를 말함으로써 초기 호출형 자동화 어시스턴트를 호출할 수 있다. 예를 들어, 사용자는 제2 자동화 어시스턴트를 호출하지 않고 제1 자동화 어시스턴트를 호출하기 위해 핫워드 "OK Assistant 1"을 말할 수 있다. 마찬가지로, 사용자는 제1 자동화 어시스턴트를 호출하지 않고 제2 자동화 어시스턴트를 호출하는 핫워드 "OK Assistant 2"를 말할 수 있다.In some implementations, multiple automated assistants can exist in the same environment. For example, a user may invoke an automated assistant running on a device proximate to the second device running the second automated assistant. Also, for example, a user can invoke an automated assistant running on a device on which a second automated assistant is also running. As previously described, a user may invoke an initially invoking automated assistant by saying a hotword or phrase that initially activates the automated assistant but does not invoke other automated assistants. For example, a user can say the hot word "OK Assistant 1" to invoke a first automated assistant without invoking a second automated assistant. Similarly, a user can say the hot word "OK Assistant 2" to invoke a second automated assistant without invoking the first automated assistant.
일부 구현에서, 자동화 어시스턴트는 자동화 어시스턴트가 처리할 수 있는 질의 및/또는 명령(command) 유형의 환경에서 다른 자동화 어시스턴트(들)에게 표시를 제공할 수 있다. 예를 들어, 자동화 어시스턴트는 캘린더 애플리케이션에 액세스할 수 있으며, 그 결과 사용자의 캘린더와 관련된 질의들을 해당 자동화 어시스턴트가 처리할 수 있음을 나타내는 표시를 다른 자동화 어시스턴트에게 제공할 수 있다. 또한, 예를 들어 자동화 어시스턴트는 하나 이상의 신호를 통해 다른 자동화 어시스턴트(들)에게, 미디어 스트리밍 애플리케이션을 통해 미디어를 스트리밍할 수 있음을 나타낼 수 있다. 다른 자동화 어시스턴트는 다른화 자동 어시스턴트의 능력(capabilities)에 관한 정보를 제공받을 수 있으므로 호출된 자동화 어시스턴트가 질의를 처리할 수 없는 경우 질의를 성공적으로 처리하고 사용자에게 응답을 제공할 수 있는 동일한 환경의 다른 자동화 어시스턴트를 인식할 수 있다. 예를 들어, 하나 이상의 자동화 어시스턴트는 브로드캐스팅 자동화 어시스턴트가 처리할 수 있는 질의 유형 및/또는 애플리케이션 유형을 나타내는 초음파 신호를 브로드캐스트할 수 있다. 또한 예를 들어, 자동화 어시스턴트는 Wi-fi, 애플리케이션 프로그래밍 인터페이스(API) 및/또는 자동화 어시스턴트가 환경에서 다른 자동화 어시스턴트의 능력을 인식할 수 있도록 하는 기타 통신 채널을 통해 자신의 능력의 표시를 제공할 수 있다.In some implementations, an automated assistant can provide indications to other automated assistant(s) in a query and/or command type environment that the automated assistant can process. For example, an automated assistant can access a calendar application and, as a result, provide an indication to other automated assistants that the automated assistant can handle queries related to the user's calendar. Also, for example, an automated assistant may indicate via one or more signals to other automated assistant(s) that it may stream media via a media streaming application. Other automated assistants can be provided with information about the capabilities of the differentiated automated assistant, so that if the called automated assistant cannot process the query, it can successfully process the query and provide a response to the user in the same environment. It can recognize other automated assistants. For example, one or more automated assistants may broadcast ultrasound signals indicating the types of queries and/or types of applications that the broadcasting automated assistant can handle. Also, for example, automated assistants may provide indications of their capabilities via Wi-fi, application programming interfaces (APIs), and/or other communication channels that allow the automated assistant to be aware of the capabilities of other automated assistants in its environment. can
일부 구현에서, 자동화 어시스턴트는 자신의 능력을 선제적으로 브로드캐스트할 수 있다. 이러한 경우, 초기 호출형 자동화 어시스턴트가 처리할 수 없는 질의를 수신하는 경우. 해당 유형의 요청을 처리할 수 있는 능력을 브로드캐스팅하고 이Y는 다른 자동화 어시스턴트를 탐색할 수 있다. 능력의 선제적 브로드캐스팅은 대화 및/또는 대화 데이터를 전송할 제2 어시스턴트(있는 경우)를 결정할 때 대기 시간(latency)을 줄일 수 있으며, 결과적으로 응답을 생성하는 제2 어시스턴트의 대기 시간을 줄일 수 있다. 일부 구현에서, 초기 호출형 자동화 어시스턴트가 처리할 수 없는 요청을 수신하는 경우, 그 요청이 하나 이상의 다른 자동화 어시스턴트에 의해 처리될 수 있는지 여부를 결정하기 위해 그 요청을 다른 자동화 어시스턴트에게 브로드캐스팅할 수 있다. 예를 들어, 초기 호출형 자동화 어시스턴트는 액세스 권한이 없는 캘린더 애플리케이션과 관련된 요청을 수신할 수 있으며, 다른 자동화 어시스턴트가 그 요청을 처리할 수 있는지 여부를 묻는 메시지를 다른 자동화 어시스턴트게 브로드캐스트할 수 있다. 이에 응답하여, 요청을 처리할 수 있는 자동화 어시스턴트가 긍정적으로 응답할 수 있으므로 초기 호출형 자동화 어시스턴트에게 해당 자동화 어시스턴트가 요청을 처리할 수 있음을 알린다.In some implementations, an automated assistant can proactively broadcast its capabilities. In this case, the initiating on-call automated assistant receives a query that it cannot handle. It broadcasts its ability to handle requests of that type, and it can discover other automated assistants. Preemptive broadcasting of capabilities can reduce latency when determining which second assistant (if any) to send a conversation and/or conversation data to, and consequently, latency of a second assistant generating a response. there is. In some implementations, when an initiating on-call automated assistant receives a request that it cannot handle, it can broadcast the request to other automated assistants to determine whether the request can be handled by one or more other automated assistants. there is. For example, an initiating on-call automated assistant may receive a request related to a calendar application that it does not have access to, and broadcast a message to other automated assistants asking whether the other automated assistants can handle the request. . In response, it informs the initiating automated assistant that it can handle the request, as any automated assistant that can handle the request can respond positively.
일부 경우에, 초기 호출형 자동화 어시스턴트는 사용자의 질의에 대한 응답을 생성하도록 구성되지 않을 수 있다. 예를 들어, 초기 호출형 자동화 어시스턴트는 사용자로부터 질의를 수신하고 질의를 처리하여 그 질의에 응답하는 응답을 생성할 수 있다. 후속 질의에서, 초기 호출형 자동화 어시스턴트는 사용자가 발화한 질의 유형에 응답하도록 구성되지 않은 경우 및/또는 사용자에 의한 명시적 요청으로 인해 다른 자동 어시스턴트에 대한 응답 생성을 전달하도록 구성되지 않은 경우와 같이 실질적인 응답을 생성하지 않을 수 있다. 이러한 경우, 초기 호출형 자동화 어시스턴트는 이전 대화의 일부 또는 이전 대화의 적어도 일부를 나타내는 데이터를 추가 처리를 위해 제2 자동화 어시스턴트로 전송할 수 있다. 질의 및/또는 이전 대화의 의도에 기초하여, 제2 자동화 어시스턴트는 응답을 생성하고 생성된 응답에 기초하여 하나 이상의 액션을 추가로 수행할 수 있다. 예를 들어, 제2 자동화 어시스턴트는 일단 이전 대화로부터 대화 및/또는 대화 데이터를 제공받으면 사용자에게 청각적 응답을 제공하고, 애플리케이션과 상호작용하고, 및/또는 질의에 기초하여 다른 작업을 수행할 수 있다.In some cases, the initial on-call automated assistant may not be configured to generate a response to a user's query. For example, an initial on-call automated assistant may receive a query from a user, process the query, and generate a response in response to the query. For subsequent queries, such as when the initial invoiced automated assistant is not configured to respond to the type of query uttered by the user and/or is not configured to forward response generation to other automated assistants due to an explicit request by the user. It may not produce a substantive response. In such a case, the initial on-call automated assistant may send a portion of the previous conversation or data representative of at least a portion of the previous conversation to the second automated assistant for further processing. Based on the query and/or intent of the previous conversation, the second automated assistant can generate a response and further perform one or more actions based on the generated response. For example, the second automated assistant, once provided with the conversation and/or conversation data from the previous conversation, can provide an audible response to the user, interact with the application, and/or perform other actions based on the query. there is.
초기 호출형 자동화 어시스턴트가 질의에 응답하도록 구성되지 않은 경우, 자동화 어시스턴트는 다른 자동화 어시스턴트가 그 질의를 더 잘 이행할 수 있다고 결정할 수 있다. 예를 들어, 사용자는 "스트리밍 서비스에서 영화 A 재생해 줘"라는 질의를 말할 수 있다. 초기 호출형 자동화 어시스턴트가 "스트리밍 서비스"에 액세스할 수 없는 경우, 초기 호출형 자동화 어시스턴트는 하나 이상의 다른 자동화 어시스턴트가 이러한 요청을 처리하도록 구성되어 있는지 여부를 결정할 수 있다. 예를 들어, 환경에 있는 다른 자동화 어시스턴트는 자신의 능력을 나타내는 초음파 신호를 브로드캐스트할 수 있다. 예를 들어, 환경에 있는 대체 자동화 어시스턴트는 이전에 대체 자동화 어시스턴트와 관련하여 해당 능력을 저장한(예를 들어, 로컬로 저장한) 상기 초기 호출형 자동화 어시스턴트에게 자신의 능력을 브로드캐스트했을 수 있다. 적절한 제2 자동화 어시스턴트가 초기 호출형 자동화 어시스턴트에 의해 식별되는 경우(예를 들어, 제2 자동화 어시스턴트에 대한 저장된 능력 연관(association)에 액세스함으로써), 대화 데이터를 전송하라는 요청이 제2 자동화 어시스턴트에 제공될 수 있다. 일단 요청이 제2 자동화 어시스턴트에 의해 승인(grant)되면, 초기 호출형 자동화 어시스턴트는 대화의 적어도 일부(예를 들어, 대화의 의도 및/또는 질의)를 포함하는 대화(dialog)를 제2 자동화 어시스턴트로 전송할 수 있다. 그러면 제2 자동화 어시스턴트는 질의를 처리하고 사용자 인터페이스를 통해 영화 A를 사용자에게 제공하기 위해 "스트리밍 서비스"를 시작하는 것과 같은 하나 이상의 액션을 수행할 수 있다.If the initial on-call automated assistant is not configured to answer the query, the automated assistant may determine that another automated assistant is better able to fulfill the query. For example, the user may say a query "play movie A on a streaming service". If the initiating automated assistant cannot access the "streaming service", the initiating automated assistant can determine whether one or more other automated assistants are configured to handle such a request. For example, other automated assistants in the environment may broadcast ultrasonic signals indicating their capabilities. For example, an alternate automated assistant in the environment may have previously broadcast its capabilities to the invoking automated assistant that has previously stored (eg, stored locally) those capabilities with respect to the alternate automated assistant. . If an appropriate second automated assistant is identified by the initial on-call automated assistant (eg, by accessing a stored capability association for the second automated assistant), a request to transfer conversation data is sent to the second automated assistant. can be provided. Once the request is granted by the second automated assistant, the initial on-call automated assistant opens a dialog that includes at least a portion of the dialog (eg, the intent and/or query of the dialog) to the second automated assistant. can be sent to The second automated assistant can then process the query and perform one or more actions, such as starting a “streaming service” to present movie A to the user via a user interface.
일부 구현에서, 초기 호출형 자동화 어시스턴트는 대화 데이터를 제2 자동화 어시스턴트로 전송하라는 제안을 사용자에게 제공할 수 있다. 예를 들어, 사용자는 초기 호출형 자동화 어시스턴트가 처리할 수 없거나 사용자에 의한 요청을 이행하는 응답을 제공할 수 없는 질의를 초기 호출형 자동화 어시스턴트에 제공할 수 있다. 초기 호출형 자동화 어시스턴트는 "잘 모르겠습니다. 어시스턴트 2로 확인하시겠습니까?"와 같은 응답을 제공하도록 다른 자동화 어시스턴트가 구성될 수 있음을 나타내는 제안으로 사용자에게 응답할 수 있다. 이에 대한 응답으로, 사용자는 "그래"라고 말할 수 있으며, 초기 호출형 자동화 어시스턴트는 대화 데이터를 어시스턴트 2에 제공할 수 있으며, 프로세싱은 어시스턴트 2에 의해 추가로 처리될 수 있다. 이 경우, 전송하라는 요청(즉, "그래"의 발언)은 사용자에 의해 직접 제공되며 제2 자동화 어시스턴트의 호출은 초기 호출형 자동화 어시스턴트에 의해 제공된다.In some implementations, the initial on-call automated assistant can provide the user with a suggestion to transfer conversational data to a second automated assistant. For example, the user may present a query to the initiating automated assistant that the initiating automated assistant cannot process or provide a response that fulfills a request by the user. The initial on-call automated assistant may respond to the user with a suggestion indicating that other automated assistants may be configured to provide a response such as "I'm not sure, would you like to check with assistant 2?" In response, the user may say "yes" and the initiating on-call automated assistant may provide the conversational data to assistant 2, which may be further processed by assistant 2. In this case, the request to transmit (i.e., the utterance of "yes") is provided directly by the user and the invocation of the second automated assistant is provided by the initially invoked automated assistant.
일부 구현에서, 전송하라는 제안은 사용자 선호도를 식별하고 질의가 사용자가 다른 자동화 어시스턴트에 의해 이행되는데 관심이 있는 유형인지를 결정하는 것에 기초하여 사용자에게 제공될 수 있다. 예를 들어, 초기 호출형 자동화 어시스턴트는 사용자가 사용자의 캘린더 애플리케이션에 액세스할 수 있는 자동화 어시스턴트와 같이 캘린더-관련 질의를 처리하기 위해 이전에 다른 자동화 어시스턴트를 활용했는지 결정할 수 있다. 초기 호출형 자동화 어시스턴트가 대화의 일부로서 캘린더 애플리케이션과 관련된 요청을 수신하는 경우, 초기 호출형 자동화 어시스턴트는 그 요청을 처리하기 위해 사용자가 선호하는 자동화 어시스턴트에게 대화의 적어도 일부 및/또는 대화를 나타내는 데이터를 제공할 수 있다.In some implementations, a suggestion to send can be provided to the user based on identifying user preferences and determining whether the query is of a type that the user is interested in having fulfilled by another automated assistant. For example, the initial on-call automated assistant can determine if the user has previously utilized another automated assistant to process a calendar-related query, such as an automated assistant that can access the user's calendar application. When the initiating automated assistant receives a request relating to the calendar application as part of a conversation, the initiating automated assistant sends at least a portion of the conversation and/or data representative of the conversation to the user's preferred automated assistant to process the request. can provide.
일부 구현에서, 전송하라는 요청은 사용자의 선호도에 기초할 수 있다. 예를 들어, 사용자는 하나 이상의 사용자 선호도(기본 설정)를 통해, 캘린더 애플리케이션과 관련된 모든 질의가 제1 자동화 어시스턴트에 의해 처리됨을 나타낼 수 있다. 다른 자동화 어시스턴트가 캘린더 애플리케이션과 관련된 질의를 수신하는 경우, 호출된 자동화 어시스턴트는 사용자가 캘린더 질의와 관련된 사용자 선호도를 설정하는 것을 캘린더 애플리케이션과 관련된 모든 질의에 대한 대화를 제1 자동화 어시스턴트로 전송하라는 요청으로 취급할 수 있다.In some implementations, the request to send can be based on a user's preferences. For example, a user may indicate, through one or more user preferences (default settings), that all queries related to the calendar application be handled by the first automated assistant. When another automated assistant receives a query related to the calendar application, the invoked automated assistant sends the user setting user preferences related to the calendar query as a request to transfer the conversation for all queries related to the calendar application to the first automated assistant. can handle
일부 구현에서, 사용자는 처음에 다른 자동화 어시스턴트를 호출한 후 제2 자동화 어시스턴트와의 대화를 계속할 수 있다. 예를 들어, 사용자는 "OK 어시스턴트 1"으로 자동화 어시스턴트를 호출하고 "마이애미의 날씨는 어때?"라는 질의를 제공할 수 있다. 초기 호출형 자동화 어시스턴트는 "날씨는 화씨 75도이고 화창합니다"와 같이 질의에 응답할 수 있다. 후속하여, 사용자는 "OK 어시스턴트 2, 샌프란시스코는 어때"라고 말할 수 있는데, 이는 사용자가 대화를 추가로 처리하기 위해 제2 어시스턴트(즉, "OK 어시스턴트 2"로 호출되는 자동화된 어시스턴트)에 관심이 있음을 나타낸다. 초기 호출형 자동화 어시스턴트는 대화(창)(dialog)가 제2 자동화 어시스턴트에 대한 참조를 포함하며 이전 대화 데이터를 제2 자동화 어시스턴트에 제공하여 제2 자동화 어시스턴트가 자신에게 향하는 질의의 컨텍스트 및/또는 의도를 결정할 수 있게 해준다고 결정할 수 있다. 예를 들어, 이전 예제의 질의에는 "샌프란시스코의 날씨는 어때"가 명시적으로 포함되어 있지 않지만, 이전 질의에 대한 질의의 관계에 기초하여 이전 대화(예를 들어, "마이애미의 날씨는 어때"에 날씨 정보를 제공하려는 의도가 포함될 수 있다.In some implementations, a user can continue a conversation with a second automated assistant after initially invoking another automated assistant. For example, a user may invoke an automated assistant with "OK assistant 1" and provide a query "How's the weather in Miami?" An initial on-call automated assistant might respond to queries like "It's 75 degrees Fahrenheit and it's sunny." Subsequently, the user may say "OK assistant 2, how about San Francisco", which means the user is interested in the second assistant (i.e., the automated assistant called "OK assistant 2") to further process the conversation. indicates that there is The initially invoked automated assistant provides the second automated assistant with previous dialog data so that the dialog (window) contains a reference to the second automated assistant so that the second automated assistant can determine the context and/or intent of a query directed to it. It can be decided that it allows you to decide. For example, the query in the previous example does not explicitly include "How's the weather in San Francisco", but it does not explicitly contain "How's the weather in Miami", but it does so based on the relationship of the query to the previous query (e.g., "How is the weather in Miami"). May include intent to provide weather information.
일부 구현에서, 후속 호출형 자동화 어시스턴트는 질의를 이행하는 데 필요한 대화의 컨텍스트 및/또는 의도가 없다고 결정할 수 있다. 예를 들어, 사용자는 어시스턴트 1을 호출하고 "어떤 영화를 봐야 할까"라는 질의를 말할 수 있으며, 어시스턴트 1은 "영화 A가 좋은 영화입니다"라고 응답할 수 있다. 이후에 사용자는 "OK 어시스턴트 2, 그것을 스트리밍 서비스에서 재생해 줘"라고 말할 수 있다. 영화의 이름(즉, "영화 A")은 어시스턴트 2와의 대화의 일부가 아니기 때문에, 어시스턴트 2는 어시스턴트 2가 "그것을 스트리밍 서비스에서 재생해 줘"라는 질의에서 "그것"이라는 용어로 사용자가 의도한 바를 결정할 수 있도록 어시스턴트 1로부터 컨텍스트, 의도 및/또는 어시스턴트 1과의 이전 대화의 일부를 요청할 수 있다. 일단 어시스턴트 1이 이전 대화의 컨텍스트를 제공하면, 어시스턴트 2는 "그것"이 "영화 A"를 참조한다고 결정하고 요청된 영화를 재생하기 위해 "스트리밍 서비스"를 시작할 수 있다.In some implementations, the subsequent on-call automated assistant may determine that there is no context and/or intent of the conversation required to fulfill the query. For example, the user may invoke Assistant 1 and state the query "Which movie should I watch?", and Assistant 1 may respond with "Movie A is a good movie". Afterwards the user can say "OK assistant 2, play it on a streaming service". Because the name of the movie (i.e., "Movie A") is not part of the conversation with Assistant 2, Assistant 2 can't find what the user intended by the term "it" in Assistant 2's "play it on a streaming service" query. It may request context, intent and/or parts of a previous conversation with Assistant 1 from Assistant 1 so that it can determine the bar. Once assistant 1 provides the context of the previous conversation, assistant 2 can determine that "it" refers to "movie A" and start a "streaming service" to play the requested movie.
일부 구현에서, 초기 호출형 자동화 어시스턴트가 후속 호출형 자동화 어시스턴트에게 대화 데이터를 제공하기 전에 화자의 검증이 수행될 수 있다. 예를 들어, 사용자가 "OK 어시스턴트 1, 구입하기 좋은 영화는 뭐야"라고 말하면 어시스턴트 1은 "영화 A가 높은 평점을 받았습니다"라는 응답을 제공할 수 있다. 이후에 사용자는 "OK 어시스턴트, 그것을 온라인 스토어에서 구입해 줘"라고 말할 수 있다. 어시스턴트 2는 예를 들어 "그것을 온라인 스토어에서 구입해 줘"라는 사용자의 발언을 포함하는 오디오 데이터와 함께, 어시스턴트 2로 향하는 질의의 컨텍스트(문맥)를 결정하기 위해 이전 대화의 일부를 요청할 수 있다. 어시스턴트 2에 이전 대화의 대화 데이터 및/또는 컨텍스트를 제공하기 전에, 어시스턴트 1은 어시스턴트 2의 오디오 데이터를 사용하여 검증을 수행하여 이전 대화의 화자가 "그것을 온라인 스토어에서 구입해 줘"라고 말한 화자와 동일한지 여부를 결정할 수 있다. 예를 들어, 어시스턴트 1은 이전 대화와 관련된 화자를 검증(확인)하기 위한 화자 벡터를 생성하기 위해 하나 이상의 온-디바이스 모델을 사용하여 텍스트 독립 화자 검증을 수행할 수 있다. 대안적으로 또는 추가적으로, 어시스턴트 1은 온-디바이스 TDSV(Text Dependent Speaker Verification) 모델을 사용하여 오디오 데이터를 처리함으로써 화자 벡터를 생성하고 화자 벡터가 이전 대화와 관련된 화자 벡터와 일치하는지 확인함으로써 텍스트 종속 화자 검증(TDSV)을 수행할 수 있다. 화자 검증에서 동일한 화자가 어시스턴트 1과의 이전 대화에서 어시스턴트 2에게 질의를 발화한 것으로 결정되는 경우, 어시스턴트 1은 앞서 설명한 바와같이 대화 데이터를 제공할 수 있다. 화자가 두 대화에서 동일한 화자로 검증될 수 없는 경우, 어시스턴트 1은 화자가 동일하지 않거나 추가 대화 데이터를 사용할 수 없다는 표시를 어시스턴트 2에 제공할 수 있다.In some implementations, verification of the speaker may be performed before an initial on-call automated assistant provides conversational data to a subsequent on-call automated assistant. For example, if the user says "OK Assistant 1, what's a good movie to buy", Assistant 1 may provide a response "Movie A has a high rating". Afterwards the user can say "OK assistant, buy it from the online store". Assistant 2 may request a portion of the previous conversation to determine the context (context) of a query directed to Assistant 2, along with audio data including, for example, the user's utterance "buy it at the online store". Before providing Assistant 2 with the dialog data and/or context from the previous conversation, Assistant 1 performs a validation using the audio data from Assistant 2 to ensure that the speaker in the previous conversation is the same as the speaker who said "Buy that from the online store". can decide whether or not For example, assistant 1 can perform text-independent speaker verification using one or more on-device models to generate speaker vectors for verifying (verifying) speakers associated with previous conversations. Alternatively or additionally, assistant 1 generates a speaker vector by processing the audio data using an on-device text dependent speaker verification (TDSV) model and verifies that the speaker vector matches a speaker vector associated with a previous conversation, thereby determining the text dependent speaker. Verification (TDSV) can be performed. If it is determined in speaker verification that the same speaker uttered a query to assistant 2 in a previous conversation with assistant 1, assistant 1 may provide conversation data as described above. If the speaker cannot be verified as the same speaker in both conversations, assistant 1 can provide an indication to assistant 2 that the speakers are not the same or that no additional conversation data is available.
일부 구현에서, 검증은 후속 호출형 자동화 어시스턴트로 향하는 질의가 이전 대화의 연속인지 여부를 결정하는 것을 포함할 수 있다. 예를 들어, 초기 호출형 자동화 어시스턴트와의 대화에는 "샌프란시스코의 날씨는 어때?"라는 사용자 발언과 초기 호출형 자동화 어시스턴트로부터의 응답이 포함될 수 있다. 사용자는 후속하여 "OK 어시스턴트 2, 마이애미는 어때"라고 말할 수 있으며, 이는 이후에 호출된 자동화 어시스턴트에게 전달된다. 후속 호출형 자동화 어시스턴트는 초기 호출형 자동화 어시스턴트에게 오디오(또는 대화 및 화자를 나타내는 데이터)의 적어도 일부를 제공할 수 있다. 검증하기 위해, 초기 호출형 자동화 어시스턴트는 이후에 호출된 자동화 어시스턴트에 대화 데이터를 제공하기 전에 발언이 사용자와의 하나 이상의 이전 대화와 관련되는지 여부를 결정할 수 있다. 예를 들어, 후속 호출형 자동화 어시스턴트는 "마이애미는 어때?"라고 말하는 사용자의 오디오 데이터를 전송할 수 있고 초기 호출형 자동화 어시스턴트는 그 발언이 샌프란시스코의 날씨에 관한 이전 대화의 컨텍스트와 관련될 수 있음을 결정할 수 있다. .In some implementations, verification can include determining whether a query directed to a subsequent on-call automated assistant is a continuation of a previous conversation. For example, a conversation with an initial in-paging automated assistant may include a user utterance "How's the weather in San Francisco?" and a response from the initial in-paging automated assistant. The user can subsequently say "OK assistant 2, how about Miami", which is then passed on to the called automated assistant. Subsequent on-call automated assistants can provide at least a portion of the audio (or data representative of the conversation and speaker) to the initial on-call automated assistant. To verify, the initial on-call automated assistant may determine whether the utterance relates to one or more previous conversations with the user before providing the conversation data to a subsequently invoked automated assistant. For example, a subsequent in-paging automated assistant could send audio data of a user saying "How's Miami?" can decide .
따라서, 본 명세서에 기술된 기술의 이용은 초기 호출형 자동화 어시스턴트가 요청을 이행할 수 없거나 사용자로부터의 요청에 응답할 수 없을 때 제2 자동화 어시스턴트를 명시적으로 호출해야 하는 사용자의 필요성을 완화시킨다. 그 결과, 다수의 자동화 어시스턴트를 가진 사용자에 의한 대화의 전체 기간이 단축되고 이에 따라 네트워크 및/또는 계산 리소스 사용이 감소한다. 게다가, 초기 호출형 자동화 어시스턴트가 객관적으로 더 완전한 응답을 반환할 가능성이 더 높은 다른 자동화 엇히스턴트를 알고 있는 경우, 사용자는 더 완전한 응답을 얻을 수 있는지 여부를 결정하기 위해 제2 자동화 어시스턴트를 호출할 필요 없이 제2 자동화 어시스턴트의 능력을 알 수 있다. 질의가 제2 자동화 어시스턴트에게 전달되도록 허용하면 사용자가 제2 자동화 어시스턴트와 대화를 다시 시작하는데 필요한 리소스를 소비할 필요 없이 질의에 긍정적으로 응답할 가능성이 가장 높은 어시스턴트로부터 응답을 수신하도록 사용자를 지원함으로써 사용자가 자동화 어시스턴트와의 대화를 연장해야 할 필요성을 완화시킨다. 게다가, 제2 자동화 어시스턴트에게 대화 데이터를 제공함으로써 제2 어시스턴트가 이미 제공된 정보를 사용자에게 프롬프트할 필요가 없다. 따라서, 사용자가 제1 자동화 어시스턴트에 제공된 정보를 반복할 필요 없이 대화의 컨텍스트가 제공될 수 있다.Thus, use of the techniques described herein alleviates the user's need to explicitly invoke a second automated assistant when the initial on-call automated assistant is unable to fulfill a request or respond to a request from the user. . As a result, the overall duration of a conversation by a user with multiple automated assistants is shortened, thereby reducing network and/or computational resource usage. Furthermore, if the initial invoked automated assistant knows of another automated assistant that is objectively more likely to return a more complete response, the user may invoke a second automated assistant to determine whether a more complete response can be obtained. The ability of the second automated assistant can be known without the need. By allowing the query to be forwarded to the second automated assistant, by assisting the user to receive a response from the assistant that is most likely to respond positively to the query without the user having to expend the resources needed to resume the conversation with the second automated assistant. Alleviates the need for users to prolong conversations with automated assistants. Moreover, by providing the conversational data to the second automated assistant, the second assistant does not have to prompt the user for information already provided. Thus, the context of the conversation can be provided without the user needing to repeat the information provided to the first automated assistant.
위의 설명은 본 발명의 일부 구현의 개요로서 제공된다. 이러한 구현 및 기타 구현에 대한 추가 설명은 아래에서 더 자세히 설명한다.The above description is provided as an overview of some implementations of the invention. Additional descriptions of these and other implementations are described in more detail below.
도 1은 본 명세서에 개시된 구현이 구현될 수 있는 예시적인 환경의 예시이다.
도 2는 본 명세서에 개시된 다양한 방법이 구현될 수 있는 예시적인 환경의 블록도이다.
도 3은 본 명세서에 개시된 다양한 방법이 구현될 수 있는 다른 예시적인 환경의 블록도이다.
도 4a는 제1 자동화 어시스턴트로부터 제2 자동화 어시스턴트로 대화 데이터를 전송하는 것을 도시하는 다이어그램이다.
도 4b는 화자를 검증한 후 초기 호출형 자동화 어시스턴트로부터 후속 호출형 자동화 어시스턴트로 대화를 전달하는 것을 나타내는 다이어그램이다.
도 5a, 도 5b 및 도 5c는 본 명세서에 개시된 다양한 구현에 따른 사용자, 제1 자동화 어시스턴트 및 제2 자동화 어시스턴트를 포함하는 대화를 도시한다.
도 6, 도 7 및 도 8은 본 명세서에 개시된 다양한 구현에 따른 예시적인 방법을 각각 나타내는 흐름도를 도시한다.
도 9는 컴퓨팅 디바이스의 예시적인 아키텍처를 도시한다.1 is an illustration of an exemplary environment in which implementations disclosed herein may be implemented.
2 is a block diagram of an exemplary environment in which various methods disclosed herein may be implemented.
3 is a block diagram of another exemplary environment in which various methods disclosed herein may be implemented.
4A is a diagram illustrating transfer of conversational data from a first automated assistant to a second automated assistant.
4B is a diagram illustrating transfer of a conversation from an initial on-call automated assistant to a subsequent on-call automated assistant after verifying a speaker.
5A, 5B and 5C illustrate a conversation involving a user, a first automated assistant and a second automated assistant according to various implementations disclosed herein.
6, 7 and 8 show flow diagrams each illustrating an exemplary method in accordance with various implementations disclosed herein.
9 shows an example architecture of a computing device.
도 1을 참조하면, 사용자(101)에 의해 호출될 수 있는 다수의 자동화 어시스턴트를 포함하는 예시적인 환경이 제공된다. 환경은 마이크로폰(미도시)이 있는 제1 독립형 대화형 스피커(105) 및 마이크로폰(또한 도시되지 않음)이 있는 제2 독립형 대화형 스피커(110)를 포함한다. 제1 화자는 호출 문구로 호출될 수 있는 제1 자동화 어시스턴트를 적어도 부분적으로 실행하고 있을 수 있다. 제2 화자(110)는 제1 자동화 어시스턴트와 동일한 호출 문구 또는 발언된 문구에 기초하여 사용자가 호출할 자동화 어시스턴트를 선택할 수 있도록 하는 다른 문구 중 하나인 호출 문구로 호출될 수 있는 제2 자동화 어시스턴트를 실행할 수 있다. 예시적인 환경에서, 사용자(101)는 제1 화자(105) 및 제2 화자(110)에 근접하여 "OK 어시스턴트, 좋은 애니메이션 영화는 뭐가 있지?"라는 음성 발언(115)를 말하고 있다. 제1 및/또는 제2 자동화 어시스턴트 중 하나가 "OK 어시스턴트"라는 문구에 의해 호출되도록 구성된 경우, 호출된 어시스턴트는 호출 문구(즉, "좋은 애니메이션 영화는 뭐가 있지")를 뒤따르는 질의를 처리할 수 있다.Referring to FIG. 1 , an exemplary environment is provided that includes a number of automated assistants that may be invoked by a user 101 . The environment includes a first standalone interactive speaker 105 with a microphone (not shown) and a second standalone interactive speaker 110 with a microphone (also not shown). The first speaker may be at least partially executing a first automated assistant that may be invoked with a paging phrase. The second speaker 110 sends a second automated assistant that can be invoked with a paging phrase that is either the same paging phrase as the first automated assistant or another paging phrase that allows the user to select an automated assistant to call based on the uttered phrase. can run In the exemplary environment, the user 101 is proximate to the first speaker 105 and the second speaker 110 and speaks the spoken utterance 115 "OK assistant, what's a good animated movie?" If one of the first and/or second automated assistants is configured to be invoked by the phrase "OK assistant", the invoked assistant will process the query following the invocation phrase (i.e., "what are some good animated movies"). can
일부 구현에서, 제1 스피커(105)와 같은 디바이스는 다수의 자동화 어시스턴트를 실행할 수 있다. 도 2를 참조하면, 다수의 자동화 어시스턴트를 실행하는 다수의 클라이언트 디바이스를 포함하는 예시적인 환경이 도시되어 있다. 시스템은 제1 자동화 어시스턴트(215) 및 제2 자동화 어시스턴트(220)를 실행하는 제1 클라이언트 디바이스(105)를 포함한다. 제1 및 제2 자동화 어시스턴트 각각은 오디오가 클라이언트 디바이스(105)의 마이크로폰(225)에 의해 캡처될 수 있도록 클라이언트 디바이스(105)에 근접하여 호출 문구(각 어시스턴트에 고유하거나 두 어시스턴트를 호출하는 동일한 문구)을 말함으로써 호출될 수 있다. 예를 들어, 사용자(101)는 클라이언트 디바이스(105) 근처에서 "OK 어시스턴트 1"을 말함으로써 제1 자동화 어시스턴트(215)를 호출할 수 있고, 클라이언트 디바이스(105) 근처에서 "OK 어시스턴트 2"라는 문구를 말함으로써 제2 자동화 어시스턴트(220)를 추가로 호출할 수 있다. 어떤 호출 문구가 발화되었는지에 기초하여, 사용자는 클라이언트 디바이스(105) 상에서 실행 중인 다수의 어시스턴트 중에서 사용자가 음성 질의를 처리하는데 관심이 있는 것을 나타낼 수 있다. 예시적인 환경은 제3 자동화 어시스턴트(245)를 실행하는 제2 클라이언트 디바이스(110)를 더 포함한다. 제3 자동화 어시스턴트는 마이크로폰(230)에 의해 캡처될 수 있도록 "OK 어시스턴트 3"과 같은 제3 호출 문구를 사용하여 호출되도록 구성될 수 있다. 일부 구현에서, 도 2의 자동화 어시스턴트 중 하나 이상은 없을 수 있다. 게다가, 예시적인 환경은 도 2에 존재하지 않는 추가 자동화 어시스턴트를 포함할 수 있다. 예를 들어, 시스템은 추가 자동화 어시스턴트를 실행하는 제3 디바이스를 포함할 수 있고 및/또는 클라이언트 디바이스(110) 및/또는 클라이언트 디바이스(105)는 추가 자동화 어시스턴트 및/또는 도시된 것보다 적은 수의 자동화 어시스턴트를 실행할 수 있다.In some implementations, a device such as first speaker 105 can run multiple automated assistants. Referring to FIG. 2 , an example environment is shown that includes multiple client devices running multiple automated assistants. The system includes a first client device 105 running a first automated assistant 215 and a second automated assistant 220 . Each of the first and second automated assistants is proximate to the client device 105 so that audio can be captured by the microphone 225 of the client device 105 and a paging phrase (unique to each assistant or the same phrase that calls both assistants). ) can be invoked by saying For example, user 101 can invoke first automated assistant 215 by saying “OK assistant 1” near client device 105 and saying “OK assistant 2” near client device 105. A second automated assistant 220 may be further invoked by speaking the phrase. Based on which paging phrase was uttered, the user may indicate among a number of assistants running on the client device 105 that the user is interested in handling the voiced query. The exemplary environment further includes a second client device 110 running a third automated assistant 245 . A third automated assistant may be configured to be called using a third paging phrase such as “OK assistant 3” to be captured by microphone 230 . In some implementations, one or more of the automated assistants of FIG. 2 may be absent. Additionally, the exemplary environment may include additional automated assistants not present in FIG. 2 . For example, the system may include a third device that runs additional automated assistants and/or the client device 110 and/or client device 105 may include additional automated assistants and/or fewer than shown. You can run automated assistants.
자동화 어시스턴트(215, 220, 245) 각각은 본 명세서에 기술된 자동화 어시스턴트의 하나 이상의 컴포넌트를 포함할 수 있다. 예를 들어, 자동화 어시스턴트(215)는 들어오는(incoming) 질의를 처리하기 위한 자체 음성 캡처 컴포넌트, 들어오는 시각적 데이터를 처리하기 위한 시각적 캡처 컴포넌트, 핫워드 검출 엔진, 및/또는 기타 컴포넌트를 포함할 수 있다. 일부 구현에서, 자동화 어시스턴트(215 및 220)와 같은 동일한 디바이스상에서 실행 중인 자동화 어시스턴트는 두 자동화 어시스턴트에 의해 이용될 수 있는 하나 이상의 컴포넌트를 공유할 수 있다. 예를 들어, 자동화 어시스턴트(215)와 자동화 어시스턴트(220)는 온-디바이스 음성 인식기, 온-디바이스 NLU 엔진, 및/또는 하나 이상의 다른 컴포넌트를 공유할 수 있다.Each of the automated assistants 215, 220, 245 may include one or more components of an automated assistant described herein. For example, automated assistant 215 may include its own audio capture component for processing incoming queries, a visual capture component for processing incoming visual data, a hotword detection engine, and/or other components. . In some implementations, automated assistants running on the same device, such as automated assistants 215 and 220, can share one or more components that can be used by both automated assistants. For example, automated assistant 215 and automated assistant 220 may share an on-device speech recognizer, an on-device NLU engine, and/or one or more other components.
일부 구현에서, 하나 이상의 자동화 어시스턴트는 자연어 프로세서 및/또는 자연어, TTS 및/또는 STT 프로세서의 결과와 같은 하나 이상의 모듈을 공유할 수 있다. 예를 들어, 다시 도 2를 참조하면, 제1 자동화 어시스턴트(215)와 제2 자동화 어시스턴트(220) 모두 자연어 처리를 공유할 수 있으므로 클라이언트 디바이스(105)가 오디오 데이터를 수신하는 경우 오디오 데이터는 자동화 어시스턴트(215 및 220) 모두에 제공될 수 있는 텍스트로 한 번 처리된다. 또한, 예를 들어, 클라이언트 디바이스(105)의 하나 이상의 컴포넌트는 본 명세서에서 추가로 설명되는 바와 같이, 오디오 데이터를 텍스트로 처리하고 오디오 데이터의 텍스트 표현을 제3 자동화 어시스턴트(245)에 제공할 수 있다. 일부 구현에서, 오디오 데이터는 텍스트로 처리되지 않을 수 있으며 대신 하나 이상의 자동화 어시스턴트에 원시 오디오 데이터로 제공될 수 있다.In some implementations, one or more automated assistants can share one or more modules, such as natural language processors and/or results of natural language, TTS and/or STT processors. For example, referring back to FIG. 2 , both first automated assistant 215 and second automated assistant 220 may share natural language processing so that when client device 105 receives audio data, audio data is automated. It is processed once into text that can be provided to both assistants 215 and 220. Also for example, one or more components of client device 105 may process audio data as text and provide a textual representation of the audio data to third automated assistant 245 , as further described herein. there is. In some implementations, the audio data may not be processed as text and instead provided as raw audio data to one or more automated assistants.
도 3을 참조하면, 2개의 자동화 어시스턴트(305 및 310)의 예가 도시되어 있다. 도시된 바와 같이, 처음(initially) 호출된 자동화 어시스턴트(305)는 제1 클라이언트 디바이스(301)상에서 실행되고 있고, 후속(subsequently) 호출된 자동화 어시스턴트(310)는 제2 클라이언트 디바이스(302)상에서 실행되고 있다. 그러나, 일부 구현에서, 자동화 어시스턴트(305 및 310) 모두는 도 2에 도시된 바와 같이 동일한 디바이스상에서 실행될 수 있다.Referring to FIG. 3 , examples of two automated assistants 305 and 310 are shown. As shown, the initially called automated assistant 305 is running on the first client device 301 and the subsequently called automated assistant 310 is running on the second client device 302. It is becoming. However, in some implementations, both automated assistants 305 and 310 can run on the same device as shown in FIG. 2 .
초기 호출형 자동화 어시스턴트(305)는 마이크로폰로폰(320)을 통해 캡처되고 호출 엔진(315)에 의해 처리되는 하나 이상의 문구에 의해 호출될 수 있다. 일부 구현에서, 초기 호출형 자동화 어시스턴트(305)는 카메라(미도시)에 의해 캡처되고 호출 엔진(315)에 의해 처리되는 하나 이상의 제스처를 통해 사용자에 의해 호출될 수 있다. 호출 엔진(315)은 음성 발언 및/또는 제스처에 기초하여, 사용자가 초기 호출형 자동화 어시스턴트(305)를 이용하는데 관심이 있는지 여부를 결정할 수 있다. 유사하게, 후속 호출형 자동화 어시스턴트(310)는 문구를 발화할 때 사용자가 후속 호출형 자동화 어시스턴트(310)의 호출에 고유한 유사한 문구 및/또는 제스처에 의해 후속 호출형 자동화 어시스턴트(310)와 상호작용하는데 관심이 있는지 여부를 결정할 수 있는 호출 엔진(385)을 포함한다.Initial paging automated assistant 305 may be invoked by one or more phrases captured via microphone 320 and processed by paging engine 315 . In some implementations, the initiating on-call automated assistant 305 can be invoked by the user through one or more gestures captured by a camera (not shown) and processed by the invocation engine 315 . The paging engine 315 may determine, based on the spoken utterance and/or gesture, whether the user is interested in using the initiating paging automated assistant 305 . Similarly, when subsequent invoking automated assistant 310 utters a phrase, the user interacts with subsequent invoking automated assistant 310 by similar phrases and/or gestures unique to the invocation of subsequent invoking automated assistant 310. and a call engine 385 that can determine whether it is interested in acting.
초기 호출형 자동화 어시스턴트(305)는 마이크로폰(320)에 의해 캡처된 음성 발언와 같이 사용자에 의해 제출된 질의를 처리할 수 있는 질의 처리 엔진(330)을 포함한다. 일부 구현에서, 사용자는 초기 호출형 자동화 어시스턴트(305)와 대화를 진행할 수 있다. 예를 들어, 사용자는 "오늘 날씨가 어때?"라는 질의를 제출할 수 있고, 질의 처리 엔진(330)은 응답을 생성할 수 있으며, 초기 호출형 자동화 어시스턴트(305)는 예를 들어 "오늘은 화창하고 80도입니다"로 질의에 응답할 수 있다. 그런 다음 사용자는 이전 질의와 관련이 있거나 이전 질의와 관련이 없는 추가 질의를 제출할 수 있다. 예를 들어, 사용자는 내일 날씨를 제공받는데 관심이 있음을 나타내는 "내일은 어때?"라는 후속 질의를 제출할 수 있으며, 질의 처리 엔진(330)은 사용자와 발생한 대화에 기초하여 응답을 생성할 수 있다. 이에 응답하여, 초기 호출형 자동화 어시스턴트(305)는 적절한 일기 예보로 응답할 수 있다. 또한, 예를 들어 사용자는 이전 질의와 관련 없는 "볼만한 영화가 뭐야"라는 관련 없는 질의를 제출하고 이전 질의와 관련 없는 적절한 응답을 제공받을 수 있다.Initial on-call automated assistant 305 includes a query processing engine 330 that can process queries submitted by the user, such as voice utterances captured by microphone 320 . In some implementations, the user may conduct a conversation with the initiating on-call automated assistant 305 . For example, a user may submit a query, "How's the weather today?", query processing engine 330 may generate a response, and introductory automated assistant 305 may send, for example, "It's sunny today." and it's 80 degrees" to answer the query. The user can then submit additional queries related to or unrelated to the previous query. For example, a user may submit a follow-up query, "How about tomorrow?" indicating an interest in being provided with the weather for tomorrow, and query processing engine 330 may generate a response based on a conversation that has occurred with the user. In response, the initiating on-call automated assistant 305 may respond with an appropriate weather forecast. Further, for example, a user may submit an unrelated query such as "what are some good movies to watch" unrelated to the previous query and be provided with an appropriate response unrelated to the previous query.
일부 구현에서, 사용자는 초기 호출형 자동화 어시스턴트(305)가 처리할 수 없는 질의를 제출할 수 있다. 예를 들어, 사용자는 사용자(101)의 캘린더 애플리케이션에 대한 액세스 권한이 없을 수 있는 자동화 어시스턴트(305)에게 "오늘 내 일캘린더(일정)에 무슨 일이 있지"라는 질의를 제출할 수 있다. 이에 응답하여, 질의 처리 엔진(330)은 "죄송합니다. 당신의 캘린더에 액세스할 수 없습니다"와 같은 부정적인 응답을 제공할 수 있다. 이것이 발생하는 경우, 사용자는 사용자의 캘린더에 액세스할 수 있는 후속 호출형 자동화 어시스턴트(310)에 질의를 제출해야 할 수 있다. 그런 경우, 자동화 어시스턴트(310)는 "오늘 3시에 회의가 있습니다"와 같은 응답을 제공할 수 있다. 초기 호출형 자동화 어시스턴트(305) 및 후속 호출형 자동화 어시스턴트(310)가 사용자의 캘린더 애플리케이션에 액세스할 수 없는 경우에, 사용자는 다른 자동화 어시스턴트를 호출하거나 캘린더 애플리케이션에 직접 액세스해야 할 수도 있다. 따라서, 이러한 경우 사용자가 어떤 자동화 어시스턴트가 관심 있는 정보를 제공할 수 있는지 결정하기 위해 컴퓨팅 리소스가 낭비된다.In some implementations, a user may submit a query that the inbound automated assistant 305 cannot process. For example, a user may submit a query “what's on my calendar today” to automated assistant 305, which may not have access to user 101's calendar application. In response, query processing engine 330 may provide a negative response, such as "Sorry, we cannot access your calendar." When this occurs, the user may need to submit a query to the subsequent invoking automated assistant 310 that can access the user's calendar. In that case, automated assistant 310 may provide a response such as "I have a meeting at 3 o'clock today". If the initial invoking automated assistant 305 and the subsequent invoking automated assistant 310 do not have access to the user's calendar application, the user may need to invoke another automated assistant or directly access the calendar application. Thus, computing resources are wasted in such cases for the user to determine which automated assistant can provide the information of interest.
도 4a를 참조하면, 사용자(101), 초기 호출형 자동화 어시스턴트(305) 및 후속 호출형 자동화 어시스턴트(310) 사이의 데이터 흐름을 도시하는 다이어그램이 제공된다. 처음에, 사용자(101)와 초기 호출형 자동화 어시스턴트(305) 사이에서 대화(415)가 발생할 수 있다. 예를 들어, 사용자는 "OK 어시스턴트 A"와 같이 초기 호출형 자동화 어시스턴트(305)를 호출하는 하나 이상의 문구를 말할 수 있다. 이 문구는 초기 호출형 자동화 어시스턴트(305)만 호출하고 후속 호출형 자동화 어시스턴트(310)는 호출하지 않는 문구일 수 있다.Referring to FIG. 4A , a diagram illustrating data flow between a user 101 , an initial on-call automated assistant 305 and a subsequent on-call automated assistant 310 is provided. Initially, a conversation 415 may occur between the user 101 and the initiating on-call automated assistant 305 . For example, the user may say one or more phrases that invoke the first-in-call automated assistant 305, such as "OK assistant A." This phrase may be a phrase that calls only the initial invocation automated assistant 305 and does not invoke subsequent invocation automated assistants 310 .
일부 경우에, 초기 호출형 자동화 어시스턴트(305)는 사용자(101)의 요청을 처리하도록 구성되지 않을 수 있다. 일부 구현에서, 초기 호출형 자동화 어시스턴트(305)는 요청을 후속 호출형 자동화 어시스턴트(310)로 전달하도록 사용자에게 제안할 수 있다. 예를 들어, 사용자(101)는 "그것을 스트리밍 서비스에서 재생해 줘"라는 질의를 제출할 수 있고 초기 호출형 자동화 어시스턴트(305)는 "스트리밍 서비스"와 통신하도록 구성 및/또는 활성화되지 않을 수 있다. 그러나, 후속 호출형 자동화 어시스턴트(310)는 스피커(370)에 의해 브로드캐스트되고 마이크로폰로폰(320)에 의해 캡처되는 초음파 신호와 같이 "스트리밍 서비스"와 통신하도록 구성되었다는 표시를 제공할 수 있다. 그러한 경우에, 초기 호출형 자동화 어시스턴트(305)는 후속 호출된 자동 어시스턴트(310)를 지칭하는 "죄송합니다. 그렇게 할 수 없습니다. 어시스턴트 B에게 물어보시겠습니까"와 같은 응답으로 응답할 수 있다. 일부 구현에서, 제안은 사용자(101)에게 제공되지 않을 수 있다. 대신에, 초기 호출형 자동화 어시스턴트(305)는 "그것을 스트리밍 서비스에서 재생해 줘"에 대한 요청이 후속 호출형 자동화 어시스턴트(310)로 대화를 전송(transfer)하라는 요청이라고 결정할 수 있다. 따라서, 일부 경우, 전송하라는 제안(420)에 대한 긍정적인 응답(예를 들어, "어시스턴트 B가 그렇게 하도록 하시겠습니까?"에 대한 응답으로 "예")이 전송하라는 요청(425)일 수 있다. 게다가, 전송하라는 제안(420)이 없는 경우에, 처음 호출된 자동 어시스턴트(305)가 수행하도록 구성되지 않은 액션을 수행하라는 사용자(101)의 요청이 전송하라는 요청(예를 들어, "그것을 스트리밍 서비스에서 재생해 줘")일 수 있다. 또한, 예를 들어, 이전에 사용자 선호도(기본 설정)로 설정된 액션을 수행하라는 자동화 어시스턴트에 대한 요청은 해당 액션이 요청된 인스턴스에서 전송하라는 요청일 수 있다.In some cases, the initial on-call automated assistant 305 may not be configured to process user 101's request. In some implementations, the initial on-call automated assistant 305 can offer the user to forward the request to a subsequent on-call automated assistant 310 . For example, user 101 may submit a query to “play it on a streaming service” and the on-call automated assistant 305 may not be configured and/or activated to communicate with the “streaming service”. However, subsequent on-call automated assistant 310 may provide an indication that it is configured to communicate with a “streaming service,” such as an ultrasonic signal broadcast by speaker 370 and captured by microphone 320. In such a case, the initially invoked automated assistant 305 may respond with a response such as "Sorry, I can't do that. Would you like to ask assistant B", which refers to the subsequently invoked automated assistant 310. In some implementations, suggestions may not be presented to user 101 . Instead, the initial on-call automated assistant 305 may determine that the request to “play it on a streaming service” is a request to transfer the conversation to the subsequent on-call automated assistant 310 . Thus, in some cases, a positive response to suggestion 420 to transmit (eg, “yes” in response to “Do you want assistant B to do that?”) may be request 425 to transmit. Moreover, if there is no suggestion to send 420, the user's 101 request to perform an action that the first-called automated assistant 305 is not configured to perform is a request to send (e.g., "do it to a streaming service"). play on"). Also, for example, a request to an automated assistant to perform an action previously set as a user preference (default setting) may be a request to be sent in the instance for which the action is requested.
일단 사용자(101)가 전송(transfer)을 요청하고 및/또는 전송하라는 제안을 확정하면, 초기 호출형 자동화 어시스턴트(305)는 후속 호출형 자동화 어시스턴트(310)를 호출할 수 있다(435). 일부 구현에서, 초기 호출형 자동화 어시스턴트(305)는 초기 호출형 자동화 어시스턴트(305)의 어시스턴트 조정 모듈(325)을 통해, 예를 들어 후속 호출형 자동화 어시스턴트(310)의 어시스턴트 조정 모듈(375)을 통해 동일하거나 상이한 디바이스에서 실행 중인 하나 이상의 추가 자동화 어시스턴트와 통신할 수 있다. 예를 들어, 초기 호출형 자동화 어시스턴트(305)는 사용자에 의해 호출될 수 있고 어시스턴트 조정 모듈(325)은 Wi-fi, 블루투스, 스피커(350)를 통해 클라이언트 디바이스(105)에 의해 브로드캐스트되고 마이크로폰(365), API(390 및 345) 및/또는 다른 통신 채널을 통해 후속 호출형 자동화 어시스턴트(302)에 의해 수신되는 초음파 신호와 같은 하나 이상의 프로토콜을 사용할 수 있다.Once user 101 requests a transfer and/or confirms an offer to transfer, initial on-call automated assistant 305 can invoke 435 subsequent on-call automated assistant 310 . In some implementations, the initial invoking automated assistant 305 via the initial invoking automated assistant's 305's assistant coordination module 325, for example, the subsequent invoking automated assistant's 310's assistant coordination module 375. to communicate with one or more additional automated assistants running on the same or different devices. For example, the initial invoking automated assistant 305 can be invoked by the user and the assistant coordination module 325 is broadcast by the client device 105 via Wi-fi, Bluetooth, speaker 350 and microphone 365, APIs 390 and 345, and/or ultrasonic signals received by follow-on automated assistant 302 over other communication channels.
후속 호출형 자동화 어시스턴트(310)의 호출 후, 초기 호출형 자동화 어시스턴트(305)는 대화 데이터의 적어도 일부를 후속 호출형 자동화 어시스턴트(310)로 전송할 수 있다(440). 대화 데이터는 요청을 말하는 사용자의 오디오 데이터를 포함할 수 있으며, 이는 이후에 후속 호출형 자동화 어시스턴트(310)에 의해 ASR 및/또는 NLU를 통해 추가로 분석될 수 있다. 일부 구현에서, 초기 호출형 자동화 어시스턴트(305)는 ASR 및/또는 NLU를 수행할 수 있고 대화 데이터에는 대화 및/또는 NLU 출력의 텍스트 표현이 포함될 수 있다.After invoking the subsequent on-call automated assistant 310 , the initial on-pace automated assistant 305 may transmit ( 440 ) at least a portion of the conversation data to the subsequent on-pace automated assistant 310 . Conversation data may include audio data of the user speaking the request, which may then be further analyzed via ASR and/or NLU by subsequent on-call automated assistant 310 . In some implementations, the initiating on-call automated assistant 305 may perform ASR and/or NLU and the conversation data may include textual representations of the conversation and/or NLU output.
대화 데이터를 제공받는 것에 응답하여, 질의 처리 엔진(340)은 질의를 처리할 수 있고 후속 호출형 자동화 어시스턴트(310)는 초기 호출형 자동화 어시스턴트(305)에 의해 제공된 대화 데이터에 응답하는 하나 이상의 액션(430)을 수행할 수 있다. 액션에는 예를 들어 하나 이상의 애플리케이션에 액세스하는 것, 하나 이상의 다른 디바이스와 통신하는 것, 검색을 수행하는 것, 합성된 음성 출력을 제공하는 것, 및/또는 후속 호출형 자동화 어시스턴트(310)이 수행하도록 구성된 다른 액션을 포함할 수 있다. 일단 하나 이상의 액션이 수행되면(430), 대화는 사용자와 초기 호출형 자동화 어시스턴트(305) 및/또는 후속 호출형 자동화 어시스턴트(310) 사이에서 계속될 수 있다.In response to being provided with the conversational data, the query processing engine 340 may process the query and the subsequent invocation automated assistant 310 may take one or more actions in response to the conversational data provided by the initial invocation automated assistant 305. (430) can be performed. Actions may include, for example, accessing one or more applications, communicating with one or more other devices, performing a search, providing synthesized speech output, and/or performed by automated assistant 310 on a follow-up call. may contain other actions configured to do so. Once one or more actions have been performed ( 430 ), the conversation may continue between the user and the initial on-call automated assistant 305 and/or the subsequent on-call automated assistant 310 .
예로서, 도 5a를 참조하면, 사용자(101)와 두 개의 자동화 어시스턴트(305, 310) 사이의 대화가 도시되어 있다. 도시된 대화 상자에는 전송(하라는) 제안이 포함되어 있지 않다. 처음에, 대화는 사용자와 초기 호출형 자동화 어시스턴트(305) 사이에서 발생한다. 대화는 사용자가 "OK 어시스턴트, 좋은 애니메이션 영화는 뭐가 있지?"(505)라고 요청하는 것으로 시작되고, 초기 호출형 자동화 어시스턴트(305)는 "영화 A가 좋은 애니메이션 영화입니다"(510)로 응답한다. 이 경우, 요청은 초기 호출형 자동화 어시스턴트(305)에 의해 처리될 수 있다. 다음으로, 사용자는 "OK 어시스턴트, 그것을 스트리밍 서비스에서 재생해 줘"(515)를 요청한다. 초기 호출형 자동화 어시스턴트(305)는 자신이 "스트리밍 서비스"에 액세스 및/또는 이용하도록 구성되지 않았음을 결정할 수 있고, 후속 호출형 자동화 어시스턴트(310)가 그 요청을 처리할 수 있다고(예를 들어, "스트리밍 서비스"와 통신하도록 구성되었다고) 추가로 결정할 수 있다. 초기 호출형 자동화 어시스턴트(305)는 후속 호출형 자동화 어시스턴트(310)를 호출하고 후속 호출형 자동화 어시스턴트(310)가 "스트리밍 서비스"에서 "영화 A"를 재생하는 액션(동작)을 수행하도록 허용할 수 있는 대화 데이터를 제공할 수 있다. 예를 들어, 초기 호출형 자동화 어시스턴트(305)는 대화의 오디오 데이터(예를 들어, 대화 부분(505, 510 및/또는 515)), 대화의 텍스트 표현, 및/또는 사용자(101)와 초기 호출형 자동화 어시스턴트(305) 사이의 대화 의도의 다른 표현을 제공할 수 있다. 이에 응답하여, 후속 호출형 자동화 어시스턴트(310)는 스트리밍 서비스에서 영화 A를 재생하는 것뿐만 아니라 "지금 스트리밍 서비스에서 재생 중입니다"(520)라는 합성된 음성 출력을 제공한다. 이 경우에, 전송(하라는) 요청에는 하나 이상의 사용자 선호도 및/또는 과거 행동을 통해, "스트리밍 서비스" 질의가 후속 호출형 자동화 어시스턴트(310)에 의해 처리된다는 것을 이전에 표시한 사용자가 포함될 수 있다.As an example, referring to FIG. 5A , a conversation between a user 101 and two automated assistants 305 and 310 is shown. The dialog box shown does not contain a proposal to send (to). Initially, a conversation takes place between the user and the initiating on-call automated assistant 305 . The conversation begins with the user asking "OK assistant, what's a good animated movie?" . In this case, the request may be processed by the initiating automated assistant 305 . Next, the user requests "OK assistant, play it on the streaming service" (515). The initial on-call automated assistant 305 may determine that it is not configured to access and/or use a "streaming service", and the subsequent on-call automated assistant 310 may process the request (e.g., e.g. configured to communicate with a “streaming service”). The initial on-call automated assistant 305 will call the subsequent on-call automated assistant 310 and allow the subsequent on-call automated assistant 310 to perform the action of playing "movie A" on the "streaming service". conversational data can be provided. For example, the initial in-call automated assistant 305 may initiate a call with the user 101, audio data of the conversation (e.g., conversation portions 505, 510, and/or 515), textual representations of the conversation, and/or Conversation between type automated assistant 305 may provide another expression of intent. In response, the follow-on automated assistant 310 plays movie A from the streaming service as well as providing a synthesized speech output of "now playing from a streaming service" 520 . In this case, the request to send may include a user who has previously indicated, through one or more user preferences and/or past actions, that the "streaming service" query will be handled by the subsequent invoking automated assistant 310. .
다른 예로서, 도 5b를 참조하면, 사용자(101)와 두 개의 자동화 어시스턴트(305, 310) 사이의 대화가 도시되어 있다. 이 도시된 대화 상자에서, 사용자(101)는 초기 호출형 자동화 어시스턴트(305)와의 대화의 적어도 일부를 후속 호출형 자동화 어시스턴트(310)로 전송하라는 제안을 받는다. 처음에, 대화는 사용자(101)와 초기 호출형 자동화 어시스턴트(305) 사이에서 발생한다. 대화는 사용자가 "OK 어시스턴트, 내 캘린더(일정)에 무슨 일이 있지?"(525)라고 요청하는 것으로 시작된다. 초기 호출형 자동화 어시스턴트(305)는 사용자의 캘린더 애플리케이션에 대한 액세스 권한이 없을 수 있고, 본 명세서에 기술된 바와 같이 다른 자동화 어시스턴트에 의해 제공된 표시에 기초하여, 자동화 어시스턴트(310)가 사용자의 캘린더 애플리케이션에 대한 액세스 권한이 있다고 결정할 수 있다. 초기 호출형 자동화 어시스턴트(305)는 "당신의 캘린더에 접근할 수 없습니다. 어시스턴트 2로 체크하시겠습니까?"(530)로 응답한다. 이 응답은 후속 호출형 자동화 어시스턴트(310)에 대한 참조인 "어시스턴트 2"에게 대화를 전달하라는 사용자(101)에 대한 명시적인 제안을 포함한다. 사용자(101)는 "그래"(535)로 응답하고, 초기 호출형 자동화 어시스턴트(305)는 전술한 바와 같이 어시스턴트(310)를 호출할 수 있고, 이전 대화(또는 대화를 나타내는 데이터)의 전부 또는 일부를 후속 호출형 자동화 어시스턴트(310)로 추가로 전송할 수 있다. 사용자의 캘린더 애플리케이션에 대한 액세스 권한이 있는 후속 호출형 자동화 어시스턴트(310)는 사용자 캘린더(540)로부터의 정보로 응답함으로써 대화를 계속할 수 있다.As another example, referring to FIG. 5B , a conversation between a user 101 and two automated assistants 305 and 310 is shown. In this illustrated dialog box, user 101 is offered a transfer of at least a portion of the conversation with the initial on-call automated assistant 305 to the subsequent on-call automated assistant 310 . Initially, a conversation takes place between the user 101 and the initiating on-call automated assistant 305 . The conversation begins with the user requesting "OK Assistant, what's on my calendar (schedule)?" (525). The initial on-call automated assistant 305 may not have access to the user's calendar application, and based on indications provided by other automated assistants as described herein, automated assistant 310 may not have access to the user's calendar application. You can decide that you have access to . The initiating automated assistant 305 responds with "Can't access your calendar. Would you like to check it with assistant 2?" (530). This response includes an explicit suggestion to user 101 to forward the conversation to “Assistant 2,” which is a reference to subsequent on-call automated assistant 310. User 101 responds "yes" 535, and initial in-paging automated assistant 305 can invoke assistant 310 as described above, and all or all of the previous conversation (or data representing the conversation) Some may be further transmitted to subsequent on-call automated assistants 310. A follow-on automated assistant 310 with access to the user's calendar application can continue the conversation by responding with information from the user's calendar 540 .
도 4b를 참조하면, 사용자(101), 초기 호출형 자동화 어시스턴트(305) 및 후속 호출형 자동화 어시스턴트(310) 사이의 데이터 흐름을 도시하는 다이어그램이 제공된다. 처음에, 대화(445)는 사용자(101)와 초기 호출형 자동화 어시스턴트(305) 사이에서 발생할 수 있다. 예를 들어, 사용자는 "OK 어시스턴트 A"와 같이 초기 호출형 자동화 어시스턴트(305)를 호출하는 하나 이상의 문구를 말할 수 있다. 문구는 초기 호출형 자동화 어시스턴트(305)만을 호출하고 후속 호출형 자동화 어시스턴트(310)는 호출하지 않는 문구일 수 있다. 대화는 사용자로부터의 "볼만한 영화는 뭐야?"와 같이 초기 호출형 자동화 어시스턴트(305)와 사용자(101) 사이에서 계속될 수 있으며, 초기 호출형 자동화 어시스턴트(305)로부터 "영화 A가 볼만한 좋은 영화입니다"라는 응답이 뒤따른다.Referring to FIG. 4B , a diagram illustrating data flow between a user 101 , an initial on-call automated assistant 305 and a subsequent on-call automated assistant 310 is provided. Initially, conversation 445 may occur between user 101 and initiating on-call automated assistant 305 . For example, the user may say one or more phrases that invoke the first-in-call automated assistant 305, such as "OK assistant A." The phrase may be a phrase that calls only the initial paging automated assistant 305 and does not invoke subsequent paging automated assistants 310 . Conversation may continue between the user 101 and the initiating automated assistant 305, such as from the user "What's a good movie to watch?" is" followed by the response.
초기 호출형 자동화 어시스턴트(305)와의 대화의 일부 지점에서, 사용자는 "OK 어시스턴트 B"와 같이 후속 호출형 자동화 어시스턴트(310)에 고유한 핫워드를 말함으로써 후속 호출형 자동화 어시스턴트(310)를 호출할 수 있다. 핫워드는 "OK 어시스턴트 B, 그것을 스트리밍 서비스에서 재생해 줘"와 같이 후속 호출형 자동화 어시스턴트(310)로 향하는 대화(450)가 뒤따를 수 있다. 따라서, 이 경우, 사용자(101)는 명시적으로 자동화 어시스턴트(310)를 호출하고 어시스턴트(310)와 직접 대화를 시작했다.At some point in the conversation with the initial invoking automated assistant 305, the user invokes the subsequently invoking automated assistant 310 by saying a hotword that is unique to the subsequently invoking automated assistant 310, such as "OK assistant B". can do. The hotword may be followed by dialog 450 directed to the next on-call automated assistant 310, such as “OK Assistant B, play it on a streaming service.” Thus, in this case, user 101 has explicitly invoked automated assistant 310 and initiated a conversation directly with assistant 310 .
일부 경우에, 후속 호출형 자동화 어시스턴트(310)는 요청에 대한 의도 및/또는 컨텍스트를 결정하기 위해 초기 호출형 자동화 어시스턴트(305)와의 이전 대화에 관한 정보를 요구할 수 있다. 예를 들어, 대화(445)에서, 사용자는 "좋은 영화가 뭐야"라고 말할 수 있고, 초기 호출형 자동화 어시스턴트(305)는 "영화 A가 좋은 영화입니다"라고 응답할 수 있다. 이어서 사용자(101)는 추가 대화(450)로서 "OK 어시스턴트 B, 그것을 스트리밍 서비스에서 재생해 줘"라고 말할 수 있다. 후속 호출형 자동화 어시스턴트(310)는 일단 호출되면 사용자(101)의 발언을 처리할 수 있다. 그러나, 해당 시점에서, 후속 호출형 자동화 어시스턴트(310)는 사용자 요청에 있는 "그것"의 의미를 해결할 컨텍스트가 없을 수 있다. 따라서, 초기 호출형 자동화 어시스턴트는 대화(450) 내의 컨텍스트 및/또는 의도를 결정하기 위해 후속 호출형 자동화 어시스턴트(310)에 대화 데이터(465)를 제공할 수 있다.In some cases, subsequent on-call automated assistant 310 may request information about a previous conversation with initial on-call automated assistant 305 to determine the intent and/or context for the request. For example, in dialogue 445, the user may say "what's a good movie", and the first-in-call automated assistant 305 may respond with "movie A is a good movie". User 101 may then say "OK Assistant B, play it on the streaming service" as an additional dialog 450 . Once invoked, the follow-on-call automated assistant 310 can process the user's 101 utterance. However, at that point in time, the subsequent on-call automated assistant 310 may not have the context to resolve the meaning of "it" in the user request. Thus, the initial in-pace automated assistant can provide conversation data 465 to subsequent in-pace automated assistants 310 to determine context and/or intent within the conversation 450 .
일부 구현에서, 후속 호출형 자동화 어시스턴트(310)가 호출되어 사용자(101)의 발언을 처리할 때, 검증 모듈(395)은 그 발언의 화자(즉, 사용자(101))가 이전에 초기 호출형 자동화 어시스턴트(305)와의 대화에 참여했음을 검증(확인)할 수 있다. 일부 구현에서, 검증 모듈(335)은 화자 검증 데이터(455)를 검증 모듈(395)에 제공할 수 있고, 검증 모듈(395)은 초기 호출형 자동화 어시스턴트(305)와의 이전 대화의 화자가 대화(445)의 화자와 동일한 화자인지 여부를 결정할 수 있다. 일부 구현에서, 마이크로폰(365)는 이전 대화 동안 사용자의 발언으로부터 오디오 데이터를 생성할 수 있고, 검증 모듈(335)은 오디오 데이터를 처리하여 (마이크로폰(365)이 캡처한) 대화(445)가 (또한 마이크로폰(365)에 의해 캡처된) 대화(450)의 화자와 동일한지 검증할 수 있다. 따라서, 일부 경우, 대화 데이터(445)는 후속 호출형 자동화 어시스턴트(310)에 의해 이미 수신되었고 초기 호출형 자동화 어시스턴트(305)에 의해 대화 데이터가 제공될 것을 요구하지 않는다.In some implementations, when subsequent invoking automated assistant 310 is invoked to process user 101's utterance, verification module 395 determines whether the speaker of that utterance (i.e., user 101) has previously made an initial invocation It can verify (confirm) that it has participated in a conversation with the automated assistant 305 . In some implementations, verification module 335 can provide speaker verification data 455 to verification module 395, where verification module 395 determines whether a speaker in a previous conversation with initially-invoked automated assistant 305 is talking ( 445), it is possible to determine whether the speaker is the same speaker. In some implementations, microphone 365 can generate audio data from the user's utterances during a previous conversation, and verification module 335 processes the audio data so that conversation 445 (captured by microphone 365) is ( It can also verify that it is the same as the speaker of conversation 450 (captured by microphone 365). Thus, in some cases, conversation data 445 has already been received by subsequent on-call automated assistant 310 and does not require conversation data to be provided by initial on-call automated assistant 305 .
화자 검증 데이터는 예를 들어 후속 호출형 자동화 어시스턴트(310)의 마이크로폰(365)에 의해 캡처된 대화의 전부 또는 일부, 화자의 음성 프로필, 및/또는 검증 모듈(395)이 대화(450)의 화자가 대화(445)와 동일한 화자인지 검증하도록 할 수 있는 다른 데이터를 포함할 수 있다. 일단 화자 검증 데이터(455)가 제공되면, 초기 호출형 자동화 어시스턴트(305)는 동일한 화자가 초기 호출형 자동화 어시스턴트(305)와의 대화에 참여했는지 여부를 결정할 수 있다. 초기 호출형 자동화 어시스턴트(305)가 사용자와의 대화가 발생했다고 결정하면, 초기 호출형 자동화 어시스턴트(305)는 후속 호출형 자동화 어시스턴트(310)에 검증 확인(verification confirmation)(460)을 제공할 수 있다. 이 확인은 화자가 이전에 초기 호출형 자동화 어시스턴트(305)를 참여시켰고 그 초기 호출형 자동화 어시스턴트(305)가 사용자(101)와 초기 호출형 자동화 어시스턴트(305) 사이에 발생한 대화의 대화 데이터(465)를 추가로 제공할 수 있음을 나타낸다. 따라서, 후속 호출형 자동화 어시스턴트(310)는 대화에 대한 컨텍스트를 결정할 수 있고 후속 호출형 자동화 어시스턴트(310)와 관련된 마이크로폰에 의해 이전에 캡처된 대화(450) 내의 임의의 모호성을 해결할 수 있다. 이어서 후속 호출형 자동화 어시스턴트(310)는 대화(450)에 응답하여 애플리케이션에 액세스 및/또는 합성 음성을 응답으로 제공하는 것과 같은 하나 이상의 액션(470)을 수행할 수 있다.Speaker verification data may include, for example, all or part of the conversation captured by the microphone 365 of the subsequent on-call automated assistant 310, the speaker's voice profile, and/or the speaker verification module 395 of the conversation 450. may contain other data that may enable it to verify that is the same speaker as conversation 445 . Once the speaker verification data 455 is provided, the initial on-call automated assistant 305 can determine whether the same speaker has engaged in a conversation with the initial on-call automated assistant 305 . If the initial invoking automated assistant 305 determines that a conversation with the user has occurred, the initial invoking automated assistant 305 can provide a verification confirmation 460 to subsequent invoking automated assistants 310 . there is. This confirmation indicates that the speaker has previously engaged the initial in-paging automated assistant 305 and that initiating automated assistant 305 has conversation data 465 of a conversation that occurred between the user 101 and the initial in-paging automated assistant 305. ) indicates that it can be additionally provided. Accordingly, the next-on-call automated assistant 310 can determine the context for the conversation and resolve any ambiguity within the conversation 450 previously captured by the microphone associated with the next-on-call automated assistant 310 . Subsequent on-call automated assistant 310 may then perform one or more actions 470 in response to dialog 450, such as accessing an application and/or providing a synthesized voice in response.
예로서, 도 5c를 참조하면, 사용자(101), 초기 호출형 자동화 어시스턴트(305) 및 후속 호출형 자동화 어시스턴트(310) 사이의 대화가 도시되어 있다. 사용자(101)는 초기 호출형 자동 어시스턴트(305)로 향하는 "OK 어시스턴트 1, 구입하기 좋은 애니메이션 영화는 뭐야?"(545)라는 음성 발언을 제공한다. 초기 호출형 자동화 어시스턴트(305)는 "영화 B가 높은 평가를 받았습니다"(550)로 발언에 응답한다. 이에 응답하여, 사용자(101)는 후속 호출형 자동화 어시스턴트(310)로 향하고 후속 호출형 자동화 어시스턴트(310)를 실행하는 클라이언트 디바이스의 하나 이상의 마이크로폰에 의해 캡처되는 "OK 어시스턴트 2, 그것을 온라인 스토어에서 구입해 줘"(555)라는 발언을 제공한다. 후속 호출형 자동화 어시스턴트(310)는 초기 호출형 자동화 어시스턴트(305)가 발언(555)이 발언(545)과 동일한 사용자에 의해 제공되었음을 검증할 수 있도록 발언(555)을 말한 사용자의 화자 검증 데이터를 초기 호출형 자동화 어시스턴트(305)에 제공할 수 있다. 일부 구현에서, 일단 동일한 화자가 검증되면, 후속 호출형 자동화 어시스턴트(310)에 이전 대화 데이터(예를 들어, 발언(545))를 제공받을 수 있다. 일부 구현에서, 후속 호출형 자동화 어시스턴트(310)는 어시스턴트를 실행하는 클라이언트 디바이스의 하나 이상의 마이크로폰를 통해 발언(545)을 캡처했을 수 있고 따라서 이미 이전 대화 데이터를 가지고 있을 수 있다. 예를 들어, 일부 구현에서, 후속 호출형 자동화 어시스턴트(310)는 제한된 오디오를 연속적으로 캡처할 수 있고, 일단 호출되면 화자가 두 인스턴스 모두에서 동일함을 검증한 후에 초기 호출형 자동화 어시스턴트(305)로 향했던 이전에 캡처된 오디오를 이용할 수 있다.By way of example, referring to FIG. 5C , a conversation is shown between user 101 , initiating automated assistant 305 and subsequently invoking automated assistant 310 . User 101 provides a voice utterance "OK assistant 1, what's a good animation movie to buy?" Initial on-call automated assistant 305 responds to the utterance with "Movie B is highly rated" 550. In response, user 101 directs to next-on-call automated assistant 310 and says "OK assistant 2, buy it from the online store" which is captured by one or more microphones of the client device running subsequent-on-call automated assistant 310. Give" (555). Subsequent in-paging automated assistant 310 uses speaker verification data from the user who uttered utterance 555 so that initial in-paging automated assistant 305 can verify that utterance 555 was provided by the same user as utterance 545. It can be provided to the initial on-call automated assistant 305. In some implementations, once the same speaker is verified, subsequent on-call automated assistant 310 may be presented with previous conversation data (eg, utterance 545 ). In some implementations, subsequent on-call automated assistant 310 may have captured utterance 545 via one or more microphones of the client device running the assistant and thus may already have previous conversation data. For example, in some implementations, subsequent on-call automated assistant 310 can continuously capture limited audio and, once called, verify that the speaker is the same in both instances before initial on-call automated assistant 305 You can use previously captured audio directed to
도 6은 제1 자동화 어시스턴트와의 대화를 처리하고 대화 데이터를 제2 자동화 어시스턴트에 제공하기 위한 예시적인 방법(600)을 예시하는 흐름도를 도시한다. 편의상, 방법(600)의 동작들은 그 동작을 수행하는 시스템을 참조하여 설명된다. 방법(600)의 이 시스템은 하나 이상의 프로세서 및/또는 클라이언트 디바이스의 다른 컴포넌트(들)를 포함한다. 더욱이, 방법(600)의 동작들이 특정 순서로 도시되어 있지만, 이것은 제한하려는 것이 아니다. 하나 이상의 동작은 재정렬, 생략 또는 추가될 수 있다.6 depicts a flow diagram illustrating an example method 600 for processing a conversation with a first automated assistant and providing conversation data to a second automated assistant. For convenience, the operations of method 600 are described with reference to a system that performs the operations. This system of method 600 includes one or more processors and/or other component(s) of a client device. Moreover, although the operations of method 600 are shown in a particular order, this is not intended to be limiting. One or more actions may be rearranged, omitted or added.
단계(605)에서, 초기 호출형 자동화 어시스턴트는 사용자와의 대화에 참여한다. 초기 호출형 자동화 어시스턴트는 사용자가 말한 하나 이상의 핫워드에 의해 호출되고 호출 엔진(315)에 의해 처리될 수 있다. 일단 호출되면, 질의 처리 엔진(330)은 사용자의 발언을 처리하고 사용자 발언에 응답하여 수행할 하나 이상의 액션(동작)을 결정할 수 있다. 예를 들어, 초기 호출형 자동화 어시스턴트(305)는 "OK 어시스턴트 A"라는 문구에 이어 "좋은 애니메이션 영화는 뭐야"라는 질의로 호출될 수 있다. 질의 처리 엔진(330)은 합성 음성을 통해 사용자에게 제공될 수 있는 "영화 A가 좋은 영화입니다"라는 응답을 결정할 수 있다. 대화는 사용자가 이전 발언과 관련된(및/또는 초기 호출형 자동화 어시스턴트(305)로부터의 응답과 관련된) 또는 발언과 관련되지 않은 추가 발언을 제공할 수 있도록 사용자와 초기 호출형 자동화 어시스턴트(305) 사이에서 계속될 수 있다.At step 605, the initiating on-call automated assistant engages in a conversation with the user. The initial invoking automated assistant may be invoked by one or more hotwords spoken by the user and processed by the invocation engine 315 . Once invoked, query processing engine 330 may process the user's utterance and determine one or more actions (actions) to perform in response to the user utterance. For example, the initial invocation automated assistant 305 may be invoked with the phrase "OK assistant A" followed by a query "what's a good animated movie". Query processing engine 330 may determine a "Movie A is a good movie" response, which may be presented to the user via synthetic voice. The conversation is between the user and the invoking automated assistant 305 so that the user can provide additional utterances related to the previous utterance (and/or in response to responses from the invoking automated assistant 305) or unrelated to the utterance. can be continued in
단계(610)에서, 초기 호출형 자동화 어시스턴트는 대화의 일부를 제2 자동화 어시스턴트로 전송하라는 요청을 수신한다. 어시스턴트 조정 모듈(325)과 하나 이상의 특성을 공유하는 컴포넌트는 후속 호출형 자동화 어시스턴트(310)와 같은 다른 자동화 어시스턴트가 대화 데이터를 처리하도록 구성되어 있는지 여부를 결정할 수 있다. 예를 들어, 어시스턴트 조정 모듈(375)은 초기 호출형 자동화 어시스턴트(305)에 의해 수신될 수 있는 스피커(370)를 통한 가청 신호 및/또는 API(345 및 390)를 통한 표시와 같은 표시를 제공할 수 있으며, 이는 후속 호출형 자동화 어시스턴트(310)에 의해 처리될 수 있는 질의 유형을 나타낸다. 예를 들어, 후속 호출형 자동화 어시스턴트(310)는 사용자의 캘린더 애플리케이션과 통신하도록 구성될 수 있고, 마이크로폰로폰(320)에 의해 수신될 수 있는 초음파 신호를 제공하여 초기 호출형 자동화 어시스턴트(305)에게 사용자의 캘린더 애플리케이션과 관련된 질의가 후속 호출형 자동화 어시스턴트(310)에 의해 처리될 수 있음을 나타낼 수 있다.At step 610, the initial on-call automated assistant receives a request to transfer a portion of the conversation to a second automated assistant. A component that shares one or more characteristics with assistant coordination module 325 can determine whether another automated assistant, such as follow-up automated assistant 310 , is configured to process conversational data. For example, assistant coordination module 375 may provide indications, such as an audible signal via speaker 370 and/or indication via APIs 345 and 390, which may be received by initial invoking automated assistant 305. , which indicates the type of query that can be processed by subsequent invoking automated assistant 310 . For example, subsequent paging automated assistant 310 can be configured to communicate with the user's calendar application and provide an ultrasonic signal that can be received by microphone 320 to initiate paging automated assistant 305. that queries related to the user's calendar application may be processed by the subsequent invoking automated assistant 310 .
일부 구현에서, 사용자는 후속 호출형 자동화 어시스턴트로 대화 데이터를 전송하도록 요청할 수 있다. 일부 경우에, 사용자는 초기 호출형 자동화 어시스턴트와 시작된 대화가 제2 자동화 어시스턴트와 계속되도록 명시적으로 요청할 수 있다. 예를 들어, 사용자는 "OK 어시스턴트 1, 어시스턴트 2에서 노래 재생해 줘"라고 말할 수 있다. 일부 경우에, 사용자는 초기 호출형 자동화 어시스턴트에 의해 처리될 수 없는 질의를 말할 수 있다. 예를 들어, 초기 호출형 자동화 어시스턴트와의 대화에서, 사용자는 "OK 어시스턴트, 온라인 스토어에서 영화 1 구입해 줘"를 말할 수 있으며 이것은 요청을 이행할 수 있는 다른 자동화 어시스턴트로 전송하라는 요청일 수 있다.In some implementations, a user can request to transfer conversational data to a subsequent on-call automated assistant. In some cases, the user may explicitly request that a conversation initiated with the initial on-call automated assistant be continued with the second automated assistant. For example, the user can say "OK assistant 1, play a song on assistant 2". In some cases, the user may state a query that cannot be handled by the initiating automated assistant. For example, in a conversation with an initial on-call automated assistant, the user can say "OK assistant, buy me a movie from the online store" which could be a request to transfer to another automated assistant that can fulfill the request.
일부 구현에서, 전송하라는 요청은 초기 호출형 자동화 어시스턴트로부터의 전송 제안에 응답하여 사용자에 의해 제공될 수 있다. 예를 들어, 사용자가 "OK 어시스턴트 1, 내 캘린더(일정)에 무슨 일이 있지"라고 말할 수 있으며, 초기 호출형 자동화 어시스턴트는 요청을 이행하도록 구성되지 않았을 수 있다. 초기 호출형 자동화 어시스턴트는 "당신의 캘린더에 액세스할 수 없습니다. 어시스턴트 2에게 물어보시겠습니까?"라고 응답할 수 있다. 그러면 사용자는 "그래"와 같이 전송하라는 요청을 말할 수 있고, 초기 호출형 자동화 어시스턴트(305)는 후속 호출형 자동화 어시스턴트(310)를 호출하여 대화 데이터를 전송할 수 있다.In some implementations, the request to transfer may be provided by the user in response to a transfer offer from an initial on-call automated assistant. For example, a user may say "OK assistant 1, what's on my calendar (schedule)", and the initial on-call automated assistant may not be configured to fulfill the request. The initial on-call automated assistant might respond with "I can't access your calendar. Would you like to ask assistant 2?" The user can then say the request to transmit, such as "yes," and the initial in-paging automated assistant 305 can invoke the subsequent in-paging automated assistant 310 to transmit the conversational data.
일부 구현에서, 후속 호출형 자동화 어시스턴트(310)는 대화 데이터의 전송을 요청할 수 있다. 예를 들어, 일부 경우에, 사용자(101)는 초기 호출형 자동화 어시스턴트(305)를 호출하여 도 5c에 도시된 대화와 같은 대화에 참여할 수 있다. 대화의 일부 지점에서, 사용자는 초기 호출형 자동화 어시스턴트(305)와의 상호 작용을 중지하고 대신에 대화(555)(즉, "OK 어시스턴트 2, 그것을 온라인 상점에서 구입해 줘")를 이용하여 후속 호출형 자동화 어시스턴트를 호출한다. 이 지점에서, 후속 호출형 자동화 어시스턴트(310)는 대화 전환(545 및 550)이 발생하는 동안 후속 호출형 자동화 어시스턴트(310)가 호출되지 않았기 때문에 이전 대화에 액세스할 수 없다. 이러한 경우, 후속 호출형 자동화 어시스턴트(310)는 대화(또는 대화를 나타내는 데이터)를 후속 호출형 자동화 어시스턴트(310)로 전송하라는 요청을 초기 호출형 자동화 어시스턴트(305)에 제출할 수 있다.In some implementations, the subsequent on-call automated assistant 310 can request transmission of conversational data. For example, in some cases, user 101 may invoke an initiating on-call automated assistant 305 to engage in a conversation, such as the one shown in FIG. 5C. At some point in the conversation, the user stops interacting with the initial in-paging automated assistant 305 and instead uses dialog 555 (i.e., "OK Assistant 2, buy it from the online store") to make a subsequent in-pocket. Call your automated assistant. At this point, the subsequent on-call automated assistant 310 cannot access the previous conversation because the subsequent on-call automated assistant 310 was not invoked while conversation transitions 545 and 550 were taking place. In this case, the subsequent on-call automated assistant 310 can submit a request to the initial on-call automated assistant 305 to transfer the conversation (or data representing the conversation) to the subsequent on-call automated assistant 310 .
일부 구현에서, 후속 호출형 자동화 어시스턴트(310)는 대화 데이터를 전송하라는 요청과 함께 음성 검증 데이터를 초기 호출형 자동화 어시스턴트(305)에 제공하여, 초기 호출형 자동화 어시스턴트(305)와의 대화의 화자가 후속 호출형 자동 어시스턴트(310)를 호출한(그리고 이어서 그와 상호작용한) 화자와 동일한 화자인지 검증할 수 있다. 예를 들어, 도 3을 참조하면, 검증 모듈(335)은 하나 이상의 통신 채널을 통해, 후속 호출형 자동화 어시스턴트(310)에게 호출 및/또는 발언의 화자를 나타내는 데이터를 제공할 수 있다. 검증 모듈(395)은 예를 들어 음성 프로파일 데이터 및/또는 후속 호출형 자동화 어시스턴트(310)로 향하는 발언의 오디오 데이터에 기초하여 이전 대화의 화자가 후속 발언과 동일한 사용자(101)임을 결정할 수 있다. 검증 시, 단계(615)에서, 대화 데이터는 초기 호출형 자동화 어시스턴트(305)에 의해 제2(또는 후속 호출형) 자동화 어시스턴트(310)에 제공된다.In some implementations, the subsequent on-call automated assistant 310 provides the voice verification data to the initial on-call automated assistant 305 along with a request to transmit the conversation data so that the speaker of the conversation with the initial on-call automated assistant 305 It may be verified that it is the same speaker as the speaker who invoked (and subsequently interacted with) the subsequent on-call automated assistant 310 . For example, referring to FIG. 3 , verification module 335 may provide data indicative of the speaker of the call and/or utterance to subsequent on-call automated assistant 310 over one or more communication channels. Verification module 395 may determine that the speaker of the previous conversation is the same user 101 as the subsequent utterance, based on, for example, voice profile data and/or audio data of utterances directed to subsequent on-call automated assistant 310 . Upon verification, at step 615 , the conversation data is provided by the initial on-call automated assistant 305 to the second (or subsequent on-call) automated assistant 310 .
일부 구현에서, 대화 데이터는 질의 처리 엔진(340)이 후속 발언에 대한 의도 및/또는 컨텍스트를 결정할 수 있는 이전 대화의 오디오 데이터일 수 있다. 일부 구현에서, 의도 및/또는 컨텍스트는 초기 호출형 자동화 어시스턴트(305)의 질의 처리 엔진(330)에 의해 결정될 수 있고, 의도 및/또는 컨텍스트는 후속 호출형 자동화 어시스턴트(310)에 대화 데이터로서 제공될 수 있다. 이러한 구현에서, 질의 처리 엔진(340)은 후속 발언 및 이전 대화에 기초하여 수행할 하나 이상의 액션을 결정할 수 있다.In some implementations, dialogue data may be audio data of a previous dialogue from which query processing engine 340 may determine intent and/or context for subsequent utterances. In some implementations, the intent and/or context can be determined by the query processing engine 330 of the initial invocation automated assistant 305, and the intent and/or context provided as conversational data to a subsequent invocation automated assistant 310. It can be. In such an implementation, query processing engine 340 may determine one or more actions to perform based on subsequent utterances and previous conversations.
단계(620)에서, 제2 자동화 어시스턴트는 대화 데이터를 제공받는 것에 응답하여 하나 이상의 액션을 수행한다. 액션에는 예를 들어 후속 호출형 자동화 어시스턴트가 요청을 이행하고 및/또는 이전 대화의 의도 및/또는 컨텍스트에 기초하여 해결되는 발언에 기초하여 응답을 제공하는 것이 포함될 수 있다. 일부 구현에서, 액션에는 후속 호출형 자동화 어시스턴트가 하나 이상의 다른 애플리케이션과 상호 작용하는 것이 포함될 수 있다. 예를 들어, 도 5c의 대화를 다시 참조하면, 후속 호출형 자동화 어시스턴트(310)에 의해 수행되는 액션은 온라인 스토어 애플리케이션 및/또는 웹사이트와 상호작용하는 것을 포함할 수 있다. 다른 액션에는 후속 호출형 자동화 어시스턴트가 이행하도록 구성된 응답으로 응답하는 것, 캘린더 애플리케이션과 상호작용하는 것, 스트리밍 서비스와 상호작용하는 것, 및/또는 다른 애플리케이션과의 상호작용이 포함될 수 있다.At step 620, the second automated assistant performs one or more actions in response to being provided with the conversation data. Actions may include, for example, having a subsequent on-call automated assistant fulfill the request and/or provide a response based on the utterance being resolved based on the intent and/or context of the previous conversation. In some implementations, an action may involve the subsequent invoking automated assistant interacting with one or more other applications. For example, referring back to the dialog of FIG. 5C , the action performed by the subsequent invoking automated assistant 310 may include interacting with an online store application and/or website. Other actions may include responding with a response that the subsequent invoking automated assistant is configured to implement, interacting with the calendar application, interacting with the streaming service, and/or interacting with other applications.
도 7은 사용자와 초기 호출형 자동화 어시스턴트 간의 대화로부터의 대화 데이터를 처리하기 위해 제2 자동화 어시스턴트에 인증을 제공하기 위한 예시적인 방법(700)을 예시하는 흐름도를 도시한다. 단계(705)에서, 제1 자동화 어시스턴트가 음성 질의를 수신한다. 제1 자동화 어시스턴트는 초기 호출형 자동화 어시스턴트(305)와 하나 이상의 특성을 공유할 수 있다. 일부 구현에서, 단계(705)는 도 6의 단계(605)와 하나 이상의 특성을 공유할 수 있다.7 depicts a flow diagram illustrating an example method 700 for providing authentication to a second automated assistant to process conversation data from a conversation between a user and an initial on-call automated assistant. At step 705, the first automated assistant receives a voice query. The first automated assistant may share one or more characteristics with the initial on-call automated assistant 305 . In some implementations, step 705 can share one or more characteristics with step 605 of FIG. 6 .
단계(710)에서, 제1 자동화 어시스턴트는 사용자와 제1(호출된) 자동화 어시스턴트 간의 이전 대화를 식별한다. 대화에는 사용자의 하나 이상의 발언 및 제1 자동화 어시스턴트의 하나 이상의 응답이 포함될 수 있다. 예를 들어, 도 5b를 참조하면, 이전 대화에는 제1 자동화 어시스턴트(305)의 응답(530)과 함께 사용자가 말한 발언(525)이 포함될 수 있다. 이전 대화 데이터는 질의 처리 엔진(330)과 하나 이상의 특성을 공유하는 컴포넌트에 의해 결정될 수 있다.At step 710, the first automated assistant identifies a previous conversation between the user and the first (called) automated assistant. A conversation may include one or more utterances of the user and one or more responses of the first automated assistant. For example, referring to FIG. 5B , the previous conversation may include a utterance 525 spoken by the user along with a response 530 from the first automated assistant 305 . Previous conversation data may be determined by a component that shares one or more characteristics with the query processing engine 330 .
단계(715)에서, 제2 자동화 어시스턴트의 승인(authorization)이 제1 자동화 어시스턴트(305)에 제공될 수 있다. 예를 들어, 승인은 전송 제안(530)에 포함된 사용자(101)의 발언(535)을 포함할 수 있다. 또한, 예를 들어 도 5a를 참조하면, 전송에 대한 승인은 제2 자동화 어시스턴트(310)와 동일한 대화를 계속하기 위해 사용자(101)에 의한 승인을 나타내는 발언(515)와 같은 사용자(101)의 발언에 의해 암시될 수 있다.At step 715 , authorization of the second automated assistant may be provided to the first automated assistant 305 . For example, the approval may include the user's 101 utterance 535 included in the transfer proposal 530 . Also, referring, for example, to FIG. 5A , the approval of the transfer is of the user 101, such as utterance 515 representing approval by the user 101 to continue the same conversation with the second automated assistant 310. can be implied by speech.
단계(720)에서, 질의의 표시가 제2 자동화 어시스턴트에 제공된다. 일부 구현에서, 단계(720)는 도 6의 단계(615)와 하나 이상의 특성을 공유할 수 있다. 예를 들어, 표시에는 제1 자동화 어시스턴트와 사용자 사이에 이전에 발생한 대화, 대화의 의도 및/또는 컨텍스트, 및/또는 제2 자동화 어시스턴트가 하나 이상의 의도를 해결하고 및/또는 제2 자동 어시스턴트로 향하는 후속 발언에 대한 컨텍스트를 결정할 수 있게 하는 다른 데이터가 포함될 수 있다.At step 720, an indication of the query is provided to the second automated assistant. In some implementations, step 720 can share one or more characteristics with step 615 of FIG. 6 . For example, the indication may include previously occurring conversations between the first automated assistant and the user, the intent and/or context of the conversation, and/or the second automated assistant resolving one or more intents and/or directed toward the second automated assistant. Other data may be included that allows determining the context for subsequent utterances.
단계(725)에서, 제2 자동화 어시스턴트로 향하는 사용자의 발언에 응답하여 제2 자동화 어시스턴트에 의해 하나 이상의 액션이 수행될 수 있다. 단계(725)는 도 6의 단계(620)와 하나 이상의 특성을 공유할 수 있다. 예를 들어, 하나 이상의 액션은 제2 자동화 어시스턴트가 응답하도록 구성된 응답을 제공하는 것 및/또는 하나 이상의 애플리케이션과 상호 작용하는 것을 포함할 수 있다.At step 725, one or more actions may be performed by the second automated assistant in response to the user's utterance directed to the second automated assistant. Step 725 may share one or more characteristics with step 620 of FIG. 6 . For example, one or more actions may include providing a response that the second automated assistant is configured to respond to and/or interacting with one or more applications.
도 8은 초기 호출형 자동화 어시스턴트와의 대화의 화자가 후속 호출형 자동화 어시스턴트에 의한 대화 데이터 처리 요청의 화자와 동일한지 검증하기 위한 예시적인 방법(800)을 예시하는 흐름도를 묘사한다.8 depicts a flow diagram illustrating an example method 800 for verifying that the speaker of a conversation with an initial on-call automated assistant is the same as the speaker of a conversation data processing request by a subsequent on-call automated assistant.
단계(805)에서, 후속 호출형 자동화 어시스턴트가 이전 대화 데이터를 이용할 것을 요청하는 음성 발언을 제공한 사용자가 결정된다. 예를 들어, 도 5c를 참조하면, 발언(555)은 자동화 어시스턴트(310)를 호출하고 대화 데이터가 후속 호출형 자동화 어시스턴트(310)로 전송될 것을 요청하는 발언이다. 일부 구현에서, 대화 데이터를 전송하라는 요청은 "OK 어시스턴트, 어시스턴트 2가 이 요청을 처리할 수 있는지 확인해 줘"와 같이 제1 자동화 어시스턴트(305)로 향할 수 있다. 일부 구현에서, 대화 데이터를 전송하라는 요청은 도 5c에 도시된 바와 같이, 후속 호출형 자동화 어시스턴트(310)로 향할 수 있다. 일부 구현에서, 사용자에 의한 요청은 도 5b에 도시된 바와 같이 대화 데이터를 전송하라는 제안에 대한 응답일 수 있다.In step 805, the user who provided the spoken utterance requesting that the subsequent on-call automated assistant use the previous conversation data is determined. For example, referring to FIG. 5C , utterance 555 is an utterance that invokes automated assistant 310 and requests that conversation data be transferred to subsequent on-call automated assistant 310 . In some implementations, a request to send conversational data can be directed to first automated assistant 305 as "OK assistant, make sure assistant 2 can handle this request". In some implementations, a request to transmit conversational data can be directed to a subsequent on-call automated assistant 310, as shown in FIG. 5C. In some implementations, the request by the user may be in response to a proposal to transmit conversational data as shown in FIG. 5B.
단계(810)에서, 음성 발언을 캡처하는 오디오 데이터가 결정된다. 오디오 데이터는 마이크로폰(365) 및/또는 마이크로폰(320)과 하나 이상의 특성을 공유하는 컴포넌트에 의해 캡처될 수 있다. 예를 들어, 마이크로폰(320)은 음성 발언을 캡처할 수 있고 어시스턴트 조정 모듈(325)은 오디오 데이터를 후속 호출형 자동화 어시스턴트(310)로 전송할 수 있다. 또한, 예를 들어, 마이크로폰(365)는 오디오 데이터를 직접 캡처할 수 있으며, 이는 전송 요청일 수 있을 뿐만 아니라 호출 엔진(385)을 통해 후속 호출형 자동화 어시스턴트(310)를 호출할 수 있다.At step 810, audio data capturing the spoken utterance is determined. Audio data may be captured by a component that shares one or more characteristics with microphone 365 and/or microphone 320 . For example, the microphone 320 can capture the spoken utterance and the assistant coordination module 325 can transmit the audio data to the subsequent on-call automated assistant 310 . Also, for example, microphone 365 may directly capture audio data, which may be a request to send as well as invoke follow-on automated assistant 310 via paging engine 385.
단계(815)에서, 하나 이상의 컴포넌트는 오디오 데이터가 이전 대화와 동일한 사용자에 의해 제공되었는지 여부를 결정한다. 하나 이상의 컴포넌트는 검증 모듈(335) 및/또는 검증 모듈(395)과 하나 이상의 특성을 공유할 수 있다. 예를 들어, 오디오 데이터는 마이크로폰(365)에 의해 캡처될 수 있고, 초기 호출형 자동화 어시스턴트(305)로 전송될 수 있으며, 검증 모듈(395)은 오디오 데이터가 이전 대화와 동일한 사용자에 의해 제공되었는지 여부를 결정할 수 있다. 또한, 예를 들어, 초기 호출형 자동화 어시스턴트(305)는 후속 호출형 자동화 어시스턴트(310)에 검증 데이터를 제공할 수 있고 검증 모듈(335)은 (마이크로폰(365)에 의해 캡처된) 음성 발언의 화자가 이전 대화와 동일한 화자인지 여부를 결정할 수 있다.At step 815, one or more components determine whether the audio data was provided by the same user as in the previous conversation. One or more components may share one or more characteristics with verification module 335 and/or verification module 395 . For example, the audio data can be captured by the microphone 365 and sent to the initial on-call automated assistant 305, where the verification module 395 determines whether the audio data was provided by the same user as the previous conversation. can decide whether Also, for example, the initial on-call automated assistant 305 can provide verification data to a subsequent on-page automated assistant 310 and the verification module 335 can perform the voice utterance (captured by the microphone 365). It may be determined whether the speaker is the same speaker as in the previous conversation.
단계(820)에서, 이전 대화 데이터가 후속 호출형 자동화 어시스턴트에 제공된다. 이전 대화 데이터에는 이전 대화의 오디오 데이터, 이전 대화의 의도 및/또는 컨텍스트, 및/또는 사용자의 후속 발언에 대한 의도 및/또는 컨텍스트를 결정하기 위해 후속 호출형 자동화 어시스턴트에 의해 이용될 수 있는 기타 데이터가 포함될 수 있다. 단계(815)의 검증이 화자가 이전 대화와 동일하지 않음을 나타내는 일부 구현에서, 하나 이상의 컴포넌트는 대화 데이터가 후속 호출형 자동화 어시스턴트(315)로 전송되는 것을 금지할 수 있다.At step 820, the previous conversation data is provided to the subsequent on-call automated assistant. Previous dialog data includes audio data of a previous dialog, intent and/or context of the previous dialog, and/or other data that may be used by subsequent invoking automated assistants to determine the intent and/or context of the user's subsequent utterances. may be included. In some implementations where the verification of step 815 indicates that the speaker is not the same as the previous conversation, one or more components can prevent conversation data from being sent to the subsequent on-call automated assistant 315 .
도 9는 본 명세서에 기술된 기술의 하나 이상의 양태를 수행하기 위해 선택적으로 이용될 수 있는 예시적인 컴퓨팅 디바이스(910)의 블록도이다. 컴퓨팅 디바이스(910)는 일반적으로 버스 서브시스템(912)을 통해 다수의 주변 디바이스와 통신하는 적어도 하나의 프로세서(914)를 포함한다. 이러한 주변 디바이스는 예를 들어 메모리 서브시스템(925) 및 파일 저장 서브시스템(926)을 포함하는 저장 서브시스템(924), 사용자 인터페이스 출력 디바이스(920), 사용자 인터페이스 입력 디바이스(922) 및 네트워크 인터페이스 서브시스템(916)을 포함할 수 있다. 입력 및 출력 디바이스는 사용자가 컴퓨팅 디바이스(910)와 상호 작용할 수 있도록 한다. 네트워크 인터페이스 서브시스템(916)은 외부 네트워크에 대한 인터페이스를 제공하고 다른 컴퓨팅 디바이스의 대응하는 인터페이스 디바이스에 결합된다.9 is a block diagram of an example computing device 910 that may optionally be used to perform one or more aspects of the techniques described herein. Computing device 910 generally includes at least one processor 914 that communicates with a number of peripheral devices via a bus subsystem 912 . Such peripheral devices include, for example, a storage subsystem 924 including a memory subsystem 925 and a file storage subsystem 926, a user interface output device 920, a user interface input device 922, and a network interface subsystem. system 916. Input and output devices allow a user to interact with computing device 910 . Network interface subsystem 916 provides an interface to external networks and is coupled to corresponding interface devices of other computing devices.
사용자 인터페이스 입력 디바이스(922)에는 키보드, 포인팅 디바이스(예를 들어, 마우스, 트랙볼, 터치패드 또는 그래픽 태블릿), 스캐너, 디스플레이에 통합된 터치스크린, 오디오 입력 디바이스(예를 들어, 음성 인식 시스템, 마이크로폰), 및/또는 기타 유형의 입력 디바이스가 포함될 수 있다. 일반적으로, "입력 디바이스"라는 용어의 사용은 정보를 컴퓨팅 디바이스(910) 또는 통신 네트워크에 입력하기 위한 모든 가능한 유형의 디바이스 및 방법을 포함하도록 의도된다.User interface input devices 922 may include a keyboard, a pointing device (e.g., a mouse, trackball, touchpad, or graphics tablet), a scanner, a touchscreen integrated into a display, an audio input device (e.g., a voice recognition system, a microphone) ), and/or other types of input devices. In general, use of the term “input device” is intended to include all possible types of devices and methods for inputting information into computing device 910 or communications network.
사용자 인터페이스 출력 디바이스(920)는 디스플레이 서브시스템, 프린터, 팩스, 또는 오디오 출력 디바이스와 같은 비시각적 디스플레이를 포함할 수 있다. 디스플레이 서브시스템은 음극선관(CRT), 액정 디스플레이(LCD)와 같은 평면 패널 장치, 프로젝션 디바이스 또는 시각적 이미지를 생성하기 위한 기타 메커니즘을 포함할 수 있다. 디스플레이 서브시스템은 오디오 출력 디바이스와 같은 비시각적 디스플레이를 제공할 수도 있다. 일반적으로, "출력 디바이스"라는 용어의 사용은 컴퓨팅 디바이스(910)로부터 사용자 또는 다른 머신 또는 컴퓨팅 디바이스로 정보를 출력하기 위한 모든 가능한 유형의 디바이스 및 방법을 포함하도록 의도된다.User interface output device 920 may include a non-visual display such as a display subsystem, printer, fax machine, or audio output device. The display subsystem may include a flat panel device such as a cathode ray tube (CRT), a liquid crystal display (LCD), a projection device, or other mechanism for producing visual images. The display subsystem may provide a non-visual display, such as an audio output device. In general, use of the term “output device” is intended to include all possible types of devices and methods for outputting information from computing device 910 to a user or other machine or computing device.
저장 서브시스템(924)은 본 명세서에 설명된 모듈의 일부 또는 전부의 기능을 제공하는 프로그래밍 및 데이터 구조를 저장한다. 예를 들어, 저장 서브시스템(924)은 도 6-8의 방법의 선택된 양태를 수행하기 위한 및/또는 도 2-4에 도시된 다양한 컴포넌트를 구현하기 위한 로직을 포함할 수 있다.Storage subsystem 924 stores programming and data structures that provide the functionality of some or all of the modules described herein. For example, storage subsystem 924 may include logic to perform selected aspects of the methods of FIGS. 6-8 and/or to implement various components shown in FIGS. 2-4.
이들 소프트웨어 모듈은 일반적으로 프로세서(914) 단독으로 또는 다른 프로세서와 결합하여 실행된다. 저장 서브시스템(924)에 사용되는 메모리(925)는 프로그램 실행 동안 명령 및 데이터 저장을 위한 주 RAM(random access memory)(930) 및 고정 명령이 저장되는 판독 전용 메모리(ROM)(932)를 포함하는 다수의 메모리를 포함할 수 있다. 파일 저장 서브시스템(926)은 프로그램 및 데이터 파일을 위한 영구 저장소를 제공할 수 있고, 하드 디스크 드라이브, 관련 이동식 미디어와 함께 플로피 디스크 드라이브, CD-ROM 드라이브, 광학 드라이브 또는 이동식 미디어 카트리지를 포함할 수 있다. 특정 구현의 기능을 구현하는 모듈은 파일 저장 하위 시스템(926)에 의해 저장 하위 시스템(924) 또는 프로세서(들)(914)에 의해 액세스 가능한 다른 기계에 저장될 수 있다.These software modules are typically executed by processor 914 alone or in conjunction with another processor. Memory 925 used by storage subsystem 924 includes main random access memory (RAM) 930 for storing instructions and data during program execution and read only memory (ROM) 932 in which fixed instructions are stored. It may contain a number of memories that File storage subsystem 926 may provide persistent storage for program and data files, and may include a hard disk drive, a floppy disk drive with associated removable media, a CD-ROM drive, an optical drive, or a removable media cartridge. there is. Modules implementing functions of a particular implementation may be stored by file storage subsystem 926 in storage subsystem 924 or on another machine accessible by processor(s) 914 .
버스 서브시스템(912)은 컴퓨팅 디바이스(910)의 다양한 컴포넌트 및 서브시스템이 의도한 대로 서로 통신하도록 하는 메커니즘을 제공한다. 버스 서브시스템(912)이 개략적으로 단일 버스로 도시되어 있지만, 버스 서브시스템의 대안적인 구현은 다중 버스를 사용할 수 있다.Bus subsystem 912 provides a mechanism for the various components and subsystems of computing device 910 to communicate with each other as intended. Although bus subsystem 912 is shown schematically as a single bus, alternative implementations of the bus subsystem may use multiple buses.
컴퓨팅 디바이스(910)는 워크스테이션, 서버, 컴퓨팅 클러스터, 블레이드 서버, 서버 팜, 또는 임의의 다른 데이터 처리 시스템 또는 컴퓨팅 디바이스를 포함하는 다양한 유형일 수 있다. 끊임없이 변화하는 컴퓨터 및 네트워크의 특성으로 인해, 도 9에 도시된 컴퓨팅 디바이스(910)의 설명은 일부 구현을 설명하기 위한 특정 예로서만 의도된 것이다. 도 9에 도시된 컴퓨팅 디바이스보다 더 많거나 더 적은 컴포넌트를 갖는 컴퓨팅 디바이스(910)의 많은 다른 구성이 가능하다.Computing device 910 may be of various types including a workstation, server, computing cluster, blade server, server farm, or any other data processing system or computing device. Due to the ever-changing nature of computers and networks, the description of computing device 910 shown in FIG. 9 is intended only as a specific example to describe some implementations. Many other configurations of computing device 910 with more or fewer components than the computing device shown in FIG. 9 are possible.
일부 구현에서, 하나 이상의 프로세서에 의해 구현되는 방법이 제공되며, 이는 사용자와 초기 호출형 자동화 어시스턴트 간의 대화 중에: 초기 호출형 자동화 어시스턴트에 의해, 사용자가 있는 환경에서 클라이언트 디바이스의 제1 자동화 어시스턴트 인터페이스를 통해, 대화의 일부로서 초기 호출형 자동화 어시스턴트로 향하는 사용자의 음성 발언을 수신하는 단계와; 초기 호출형 자동화 어시스턴트에 의해, 음성 발언에 대한 응답을 생성하도록 음성 발언를 처리하는 단계와; 초기 호출형 자동화 어시스턴트에 의해, 음성 발언에 대한 응답이 대화의 일부로서 클라이언트 디바이스에 의해 렌더링되도록 하는 단계와; 초기 호출형 자동화 어시스턴트에 의해, 응답이 렌더링되도록 한 후, 대화의 일부로서 제1 자동화 어시스턴트에 의해 생성된 대화 데이터를 제2 자동화 어시스턴트로 전송하라는 요청을 수신하는 단계를 포함한다. 요청을 수신하는 것에 응답하여, 방법은 초기 호출형 자동화 어시스턴트에 의해 제2 자동화 어시스턴트와의 통신 채널을 통해, 대화 데이터를 제2 자동화 어시스턴트에 제공하는 단계를 더 포함하고, 상기 대화 데이터를 제공하는 단계는 제2 자동화 어시스턴트가 대화 데이터에 기초하여 하나 이상의 액션을 수행하게 한다.In some implementations, a method implemented by one or more processors is provided, wherein during a conversation between a user and an initially invoiced automated assistant: by the invoked automated assistant, a first automated assistant interface of a client device in an environment in which the user is present is provided. receiving the user's spoken utterance directed to the initiating on-call automated assistant as part of a conversation; processing, by the initiating on-call automated assistant, the spoken utterance to generate a response to the spoken utterance; causing, by the initiating on-call automated assistant, a response to the spoken utterance to be rendered by the client device as part of a conversation; Receiving, by the initiating automated assistant, a request to transmit conversation data generated by the first automated assistant as part of a conversation to a second automated assistant after causing a response to be rendered. In response to receiving the request, the method further comprises providing, by the initiating automated assistant, the conversation data to the second automated assistant via a communication channel with the second automated assistant, wherein the conversation data is provided. The step causes the second automated assistant to perform one or more actions based on the conversation data.
본 명세서에 개시된 기술의 이들 및 다른 구현은 다음 특징 중 하나 이상을 포함할 수 있다.These and other implementations of the technology disclosed herein may include one or more of the following features.
일부 구현에서, 전송하라는 요청은 초기 호출형 자동화 어시스턴트로 향하는 사용자의 추가 음성 발언이다.In some implementations, the request to transmit is the user's additional spoken utterance directed to the initial on-call automated assistant.
일부 구현에서, 전송하라는 요청은 음성 발언을 처리하라는 제2 자동화 어시스턴트로부터의 요청이다. 이러한 구현 중 일부에서, 전송하라는 요청에는 음성 요청을 나타내는 오디오 데이터가 포함된다. 이러한 구현 중 일부에서, 방법은 초기 호출형 자동화 어시스턴트에 의해, 화자 검증 모델을 사용하여 오디오 데이터를 처리하는 것에 기초하여, 사용자가 오디오 데이터에 의해 표시된 화자인지 검증하는 단계를 더 포함하고, 상기 대화 데이터를 제2 자동화 어시스턴트에 제공하는 단계는 사용자가 오디오 데이터에 의해 표시된 화자인지의 검증 여부에 달려 있다.In some implementations, the request to transmit is a request from the second automated assistant to process the spoken utterance. In some of these implementations, the request to transmit includes audio data representing a voice request. In some of these implementations, the method further comprises verifying, by the initiating automated assistant, that the user is the speaker indicated by the audio data based on processing the audio data using the speaker verification model, wherein the conversation The step of providing the data to the second automated assistant is dependent on verifying that the user is the speaker indicated by the audio data.
일부 구현에서, 제2 자동화 어시스턴트는 제1 디바이스와 별개인 다른 클라이언트 디바이스에서 동작하고 있고, 하나 이상의 액션은 다른 클라이언트 디바이스를 통해 사용자에게 제공되는 제2 어시스턴트 오디오 출력을 생성하는 것을 포함한다.In some implementations, the second automated assistant is operating on another client device separate from the first device, and the one or more actions include generating a second assistant audio output that is presented to the user via the other client device.
일부 구현에서, 처리 요청에는 제2 자동화 어시스턴트에 의해 수행될 하나 이상의 액션의 표시가 포함되고, 초기 호출형 자동화 어시스턴트는 하나 이상의 액션을 수행할 수 없다.In some implementations, the processing request includes an indication of one or more actions to be performed by the second automated assistant, and the initiating automated assistant cannot perform the one or more actions.
일부 구현에서, 하나 이상의 프로세서에 의해 구현되는 다른 방법이 제공되며, 이는 초기 호출형 자동화 어시스턴트의 초기 호출형 자동화 어시스턴트 클라이언트에 의해, 사용자의 환경에서 제1 클라이언트 디바이스의 하나 이상의 마이크로폰에 의해 생성된 오디오 데이터에서 캡처된 사용자의 음성 질의를 수신하는 단계와, 상기 제1 자동화 어시스턴트 클라이언트는 제1 클라이언트 디바이스 상에 설치되고; 사용자와 오디오 데이터에 의해 표시된 초기 호출형 자동화 어시스턴트 사이의 이전 대화에 기초하여, 대화의 하나 이상의 용어로 표시된 사용자 의도를 식별하는 단계와; 환경의 제2 클라이언트 디바이스 상에 설치된 제2 자동화 어시스턴트 클라이언트에, 사용자 의도에 기초하여 질의를 처리할 권한을 제공하는 단계와; 그리고 초기 호출형 자동화 어시스턴트 클라이언트에 의해 제2 자동화 어시스턴트 클라이언트와의 통신 채널을 통해, 질의의 표시 및 사용자 의도를 제2 자동화 어시스턴트 클라이언트에 제공하는 단계를 포함하고, 상기 표시 및 사용자 의도를 제공하는 단계는 제2 자동화 어시스턴트 클라이언트가 하나 이상의 액션을 수행하게 한다.In some implementations, other methods implemented by one or more processors are provided, which include audio generated by an initial in-call automated assistant client of an init-invoked automated assistant, by one or more microphones of a first client device in the user's environment. receiving a voice query of a user captured in data, the first automated assistant client being installed on a first client device; based on a prior conversation between the user and the initially on-call automated assistant indicated by the audio data, identifying user intent indicated by one or more terms of the conversation; providing a second automated assistant client installed on a second client device in the environment with permission to process the query based on user intent; and providing, by the initial in-call automated assistant client, over a communication channel with a second automated assistant client, an indication of the query and a user intent to the second automated assistant client, providing the indication and user intent. causes the second automated assistant client to perform one or more actions.
본 명세서에 개시된 기술의 이러한 구현 및 다른 구현은 다음 특징 중 하나 이상을 포함할 수 있다.These and other implementations of the technology disclosed herein may include one or more of the following features.
일부 구현에서, 통신 채널은 초음파 통신 채널을 포함하고, 그리고 질의 표시 및 사용자 의도를 제2 자동화 어시스턴트 클라이언트에 제공하는 단계는 질의의 표시 및 사용자 의도를 통합하는 초음파 신호가 제1 클라이언트 디바이스의 하나 이상의 스피커를 통해 렌더링되도록 하는 단계를 포함한다.In some implementations, the communication channel comprises an ultrasonic communication channel, and providing the query indication and user intent to the second automated assistant client includes sending the ultrasonic signal incorporating the query presentation and user intent to one or more of the first client devices. and causing it to be rendered through the speaker.
일부 구현에서, 방법은 사용자로부터, 질의를 처리하도록 제2 자동화 어시스턴트 클라이언트에 요청하는 제2 음성 질의를 수신하는 단계를 더 포함하고, 상기 권한을 제공하는 단계는 제2 음성 질의를 수신하는 것에 대한 응답이다.In some implementations, the method further comprises receiving a second voice query from the user requesting a second automated assistant client to process the query, wherein providing the permission comprises a response to receiving the second voice query. is the answer
일부 구현에서, 방법은 제1 자동화 어시스턴트가 사용자 의도를 처리할 수 없다고 결정하는 단계와; 권한을 제공하라는 제안을 사용자에게 제공하는 단계와; 그리고 사용자로부터 승인을 수신하는 단계를 더 포함하고, 상기 권한은 사용자로부터 승인을 수신하는 것에 응답하여 제2 자동화 어시스턴트 클라이언트에 제공된다.In some implementations, the method includes determining that the first automated assistant is unable to process the user intent; providing the user with a suggestion to provide the permission; and receiving an authorization from the user, wherein the authorization is provided to the second automated assistant client in response to receiving the authorization from the user.
일부 구현에서, 방법은 텍스트 질의를 생성하도록 음성 질의를 캡처하는 오디오 데이터에 대해 자동 음성 인식을 수행하는 단계를 더 포함하고, 상기 질의의 표시는 텍스트 질의이다.In some implementations, the method further comprises performing automatic speech recognition on the audio data capturing the spoken query to generate a text query, wherein the representation of the query is a text query.
일부 구현에서, 하나 이상의 프로세서들에 의해 구현되는 또 다른 방법이 제공되고, 이는 초기 호출형 자동화 어시스턴트에서, 후속 호출형 자동화 어시스턴트가 초기 호출형 자동화 어시스턴트와 함께 사용자의 이전 대화로부터의 이전 대화 데이터를 이용할 것을 요청하는 음성 발언을 사용자가 제공한 것으로 결정하는 단계를 포함한다. 사용자가 그 음성 발언을 제공한 것으로 결정한 것에 응답하여, 방법은 초기 호출형 자동화 어시스턴트에 의해, 그 음성 발언을 캡처하는 오디오 데이터를 처리하는 단계와; 초기 호출형 자동화 어시스턴트에 의해 그 처리에 기초하여, 오디오 데이터가 이전 대화에 참여한 동일한 사용자에 의해 제공되었는지 여부를 결정하는 단계를 더 포함한다. 사용자가 동일한 사용자라고 결정되는 경우, 방법은 후속 호출형 자동화 어시스턴트에 이전 대화 데이터를 제공하는 단계를 더 포함한다. 사용자가 동일한 사용자가 아닌 것으로 결정되는 경우, 방법은 대화 데이터 제공을 금지하는 단계를 포함한다.In some implementations, another method, implemented by one or more processors, is provided whereby, at an initial invoking automated assistant, a subsequent invoking automated assistant can retrieve previous conversation data from a previous conversation of the user with the invoking automated assistant. and determining that the audio utterance requesting availability was provided by the user. In response to determining that the user has provided the spoken utterance, the method includes processing, by an initiating-on-call automated assistant, audio data capturing the spoken utterance; and determining, based on the processing by the initially on-call automated assistant, whether the audio data was provided by the same user who participated in the previous conversation. If it is determined that the user is the same user, the method further includes providing the previous conversation data to the subsequently invoked automated assistant. If it is determined that the user is not the same user, the method includes prohibiting provision of the conversation data.
본 명세서에 개시된 기술의 이러한 구현 및 다른 구현은 다음 특징 중 하나 이상을 포함할 수 있다.These and other implementations of the technology disclosed herein may include one or more of the following features.
일부 구현에서, 오디오 데이터는 초기 호출형 자동화 어시스턴트를 실행하는 제1 디바이스의 마이크로폰에 의해 캡처된다.In some implementations, the audio data is captured by the microphone of the first device running the initiating on-call automated assistant.
일부 구현에서, 오디오 데이터는 후속 호출형 자동화 어시스턴트를 실행하는 제2 디바이스의 마이크로폰에 의해 캡처된다.In some implementations, the audio data is captured by the microphone of the second device running the on-call automated assistant.
일부 구현에서, 음성 발언은 초기 호출형 자동화 어시스턴트로 향한다.In some implementations, the spoken utterance is directed to the initial on-call automated assistant.
일부 구현에서, 음성 발언은 후속 호출형 자동화 어시스턴트로 향한다.In some implementations, the spoken utterance is directed to a subsequent on-call automated assistant.
일부 구현에서, 이전 대화 데이터는 초기 호출형 자동화 어시스턴트를 실행하는 제1 클라이언트 디바이스의 스피커에 의해 생성되고 후속 호출형 자동화 어시스턴트를 실행하는 제2 클라이언트 디바이스의 하나 이상의 마이크로폰에 의해 수신되는 비-인간 가청 신호를 통해 제공된다.In some implementations, prior conversation data is generated by a speaker of a first client device running an initial in-paging automated assistant and received by one or more microphones of a second client device running a subsequent in-paging automated assistant. provided through a signal.
일부 구현에서, 이전 대화 데이터는 초기 호출형 자동화 어시스턴트와 후속 호출형 자동화 어시스턴트 사이의 애플리케이션 프로그래밍 인터페이스를 통해 제공된다.In some implementations, previous conversation data is provided through an application programming interface between an initially invoked automated assistant and a subsequently invoked automated assistant.
일부 구현에서, 이전 대화 데이터는 사용자와 초기 호출형 자동화 어시스턴트 사이의 대화의 텍스트 표현을 포함한다.In some implementations, the previous conversation data includes a textual representation of a conversation between the user and the initially invoked automated assistant.
일부 구현에서, 이전 대화 데이터는 사용자와 초기 호출형 자동화 어시스턴트 사이의 대화를 캡처하는 오디오 데이터를 포함한다.In some implementations, the previous conversation data includes audio data capturing a conversation between the user and the initially on-call automated assistant.
본 명세서에서 논의된 특정 구현이 사용자들에 관한 개인 정보(예를 들어, 다른 전자 통신으로부터 추출된 사용자 데이터, 사용자의 소셜 네트워크에 대한 정보, 사용자의 위치, 사용자의 시간, 사용자의 생체 정보, 및 이용자의 활동 및 인구통계학적 정보, 사용자 간의 관계 등)를 수집하거나 사용할 수 있는 상황에서, 사용자들에게는 정보 수집 여부, 개인 정보 저장 여부, 개인 정보 사용 여부 및 사용자에 대한 정보 수집, 저장 및 사용 방법을 제어할 수 있는 하나 이상의 기회가 제공된다. 즉, 본 명세서에서 논의된 시스템 및 방법은 관련 사용자로부터 명시적인 승인을 받은 경우에만 사용자 개인 정보를 수집, 저장 및/또는 사용한다.Certain implementations discussed herein may include personal information about users (e.g., user data extracted from other electronic communications, information about the user's social networks, the user's location, the user's time of day, the user's biometric information, and Where information may be collected or used (such as user activity and demographic information, relationships between users, etc.), users are notified of whether information is collected, whether personal information is stored, whether personal information is used, and how information about users is collected, stored and used. One or more opportunities to control are provided. That is, the systems and methods discussed herein collect, store and/or use user personal information only with explicit permission from the relevant user.
예를 들어, 사용자에게는 프로그램 또는 특징이 해당 특정 사용자 또는 프로그램 또는 특징과 관련된 다른 사용자에 대한 사용자 정보를 수집하는지 여부에 대한 컨트롤이 제공될 수 있다. 개인 정보가 수집되어야 하는 각 사용자에게는 해당 사용자와 관련된 정보 수집을 제어하고, 정보 수집 여부 및 정보의 어느 부분이 수집되는지에 대한 허가 또는 승인을 제공할 수 있는 하나 이상의 옵션이 제공된다. 예를 들어, 사용자는 통신 네트워크를 통해 하나 이상의 이러한 제어 옵션을 제공받을 수 있다. 또한, 특정 데이터는 개인 식별 정보가 제거되도록 저장 또는 사용하기 전에 하나 이상의 방식으로 처리될 수 있다. 예를 들어, 사용자의 신원은 개인 식별 정보가 확인될 수 없도록 처리될 수 있다. 다른 예로, 사용자의 지리적 위치는 사용자의 특정 위치가 확인될 수 없도록 더 넓은 지역으로 일반화될 수 있다. For example, a user may be given control over whether a program or feature collects user information about that particular user or other users associated with the program or feature. Each user from whom personal information is to be collected is provided with one or more options to control the collection of information relating to that user, and to provide permission or approval as to whether and what parts of the information are collected. For example, a user may be provided with one or more of these control options via a communication network. Additionally, certain data may be processed in one or more ways prior to storage or use such that personally identifiable information is removed. For example, the user's identity may be processed so that personally identifiable information cannot be verified. As another example, a user's geographic location may be generalized to a wider area such that the user's specific location cannot be ascertained.
여러 구현예가 본 명세서에서 설명되고 도시되었지만, 기능을 수행하고 및/또는 결과를 얻기 위한 다양한 다른 수단 및/또는 구조 및/또는 본 명세서에 기술된 하나 이상의 이점이 이용될 수 있으며, 이러한 변형 및/또는 수정 각각은 본 명세서에 설명된 구현의 범위 내에 있는 것으로 간주된다. 보다 일반적으로, 본 명세서에 설명된 모든 파라미터, 치수, 재료 및 구성은 예시를 의미하며 실제 파라미터, 치수, 재료 및/또는 구성은 교시가 사용되는 특정 애플리케이션 또는 애플리케이션에 따라 달라질 것이다. 당업자는 단지 일상적인 실험을 사용하여 본 명세서에 기술된 특정 구현에 대한 많은 등가물을 인식하거나 확인할 수 있을 것이다. 따라서, 전술한 구현은 단지 예로서 제시된 것이며, 첨부된 청구범위 및 이에 대한 등가물의 범위 내에서 구현은 구체적으로 기술되고 청구된 것과 달리 실시될 수 있음을 이해해야 한다. 본 개시의 구현은 본 명세서에 기술된 각각의 개별적인 특징, 시스템, 물품, 재료, 키트 및/또는 방법에 관한 것이다. 또한 이러한 기능, 시스템, 물품, 재료, 키트 및/또는 방법이 상호 불일치하지 않는 경우, 2개 이상의 이러한 기능, 시스템, 물품, 재료, 키트 및/또는 방법의 임의의 조합은 본 개시의 범위 내에 포함된다.Although several implementations have been described and illustrated herein, various other means and/or structures for performing functions and/or obtaining results and/or one or more of the advantages described herein may be utilized, and such variations and/or or each modification is considered to be within the scope of the implementations described herein. More generally, all parameters, dimensions, materials and configurations described herein are meant to be examples and actual parameters, dimensions, materials and/or configurations will vary depending on the particular application or applications for which the teachings are used. Those skilled in the art will recognize, or be able to ascertain using no more than routine experimentation, many equivalents to the specific implementations described herein. Accordingly, it is to be understood that the foregoing implementations are presented by way of example only and that within the scope of the appended claims and their equivalents, implementations may be practiced otherwise than those specifically described and claimed. Implementations of the present disclosure are directed to each individual feature, system, article, material, kit, and/or method described herein. Also, any combination of two or more of these functions, systems, articles, materials, kits, and/or methods is included within the scope of the present disclosure, provided that such functions, systems, articles, materials, kits, and/or methods are not inconsistent with each other. do.
Claims (22)
사용자와 초기 호출형 자동화 어시스턴트 간의 대화 중에:
초기 호출형 자동화 어시스턴트에 의해, 사용자가 있는 환경에서 클라이언트 디바이스의 제1 자동화 어시스턴트 인터페이스를 통해, 대화의 일부로서 초기 호출형 자동화 어시스턴트로 향하는 사용자의 음성 발언을 수신하는 단계와;
초기 호출형 자동화 어시스턴트에 의해, 음성 발언에 대한 응답을 생성하도록 음성 발언를 처리하는 단계와;
초기 호출형 자동화 어시스턴트에 의해, 음성 발언에 대한 응답이 대화의 일부로서 클라이언트 디바이스에 의해 렌더링되도록 하는 단계와;
초기 호출형 자동화 어시스턴트에 의해, 응답이 렌더링되도록 한 후, 대화의 일부로서 제1 자동화 어시스턴트에 의해 생성된 대화 데이터를 제2 자동화 어시스턴트로 전송하라는 요청을 수신하는 단계와;
요청을 수신하는 것에 응답하여:
초기 호출형 자동화 어시스턴트에 의해 제2 자동화 어시스턴트와의 통신 채널을 통해, 대화 데이터를 제2 자동화 어시스턴트에 제공하는 단계를 포함하고, 상기 대화 데이터를 제공하는 단계는 제2 자동화 어시스턴트가 대화 데이터에 기초하여 하나 이상의 액션을 수행하게 하는 것을 특징으로 하는 하나 이상의 프로세서에 의해 구현되는 방법.A method implemented by one or more processors, the method comprising:
During a conversation between the user and the invoking automated assistant:
receiving, by the initiating automated assistant, a user's spoken utterance directed to the initiating automated assistant as part of a conversation via a first automated assistant interface of a client device in an environment in which the user is present;
processing, by the initiating on-call automated assistant, the spoken utterance to generate a response to the spoken utterance;
causing, by the initiating on-call automated assistant, a response to the spoken utterance to be rendered by the client device as part of a conversation;
receiving, by the initiating automated assistant, a request to transmit conversation data generated by the first automated assistant to a second automated assistant as part of a conversation after causing a response to be rendered;
In response to receiving the request:
providing, by the initiating automated assistant, over a communication channel with the second automated assistant, conversation data to a second automated assistant, wherein providing the conversation data is performed by the second automated assistant based on the conversation data; A method implemented by one or more processors, characterized in that to perform one or more actions.
상기 전송하라는 요청은,
초기 호출형 자동화 어시스턴트로 향하는 사용자의 추가 음성 발언인 것을 특징으로 하는 하나 이상의 프로세서에 의해 구현되는 방법.According to claim 1,
The request to send is
A method implemented by one or more processors, characterized in that the user's additional voice utterances are directed to an initial on-call automated assistant.
상기 전송하라는 요청은,
음성 발언을 처리하라는 제2 자동화 어시스턴트로부터의 요청인 것을 특징으로 하는 하나 이상의 프로세서에 의해 구현되는 방법.According to claim 1,
The request to send is
A method implemented by one or more processors characterized by a request from a second automated assistant to process a spoken utterance.
상기 전송하라는 요청은,
음성 요청을 나타내는 오디오 데이터를 포함하는 것을 특징으로 하는 하나 이상의 프로세서에 의해 구현되는 방법.According to claim 3,
The request to send is
A method implemented by one or more processors comprising audio data representing a voice request.
초기 호출형 자동화 어시스턴트에 의해, 화자 검증 모델을 사용하여 오디오 데이터를 처리하는 것에 기초하여, 사용자가 오디오 데이터에 의해 표시된 화자인지 검증하는 단계를 더 포함하고;
상기 대화 데이터를 제2 자동화 어시스턴트에 제공하는 단계는 사용자가 오디오 데이터에 의해 표시된 화자인지의 검증 여부에 달려 있는 것을 특징으로 하는 하나 이상의 프로세서에 의해 구현되는 방법.According to claim 4,
further comprising verifying, by the initiating automated assistant, whether the user is a speaker indicated by the audio data based on processing the audio data using the speaker verification model;
wherein the step of providing the dialogue data to the second automated assistant is dependent on verifying that the user is the speaker indicated by the audio data.
상기 제2 자동화 어시스턴트는 제1 디바이스와 별개인 다른 클라이언트 디바이스에서 동작하고 있고, 그리고
상기 하나 이상의 액션에는 다른 클라이언트 디바이스를 통해 사용자에게 제공되는 제2 어시스턴트 오디오 출력을 생성하는 것이 포함되는 것을 특징으로 하는 하나 이상의 프로세서에 의해 구현되는 방법.According to any preceding claim,
the second automated assistant is running on another client device separate from the first device, and
The method implemented by one or more processors of claim 1 , wherein the one or more actions include generating a second assistant audio output that is presented to the user via another client device.
상기 대화 데이터에는 제2 자동화 어시스턴트에 의해 수행될 하나 이상의 액션의 표시가 포함되고, 그리고
상기 초기 호출형 자동화 어시스턴트는 하나 이상의 액션을 수행할 수 없는 것을 특징으로 하는 하나 이상의 프로세서에 의해 구현되는 방법.According to any preceding claim,
the conversation data includes an indication of one or more actions to be performed by a second automated assistant; and
The method of claim 1 , wherein the initially invoked automated assistant is incapable of performing one or more actions.
초기 호출형 자동화 어시스턴트의 초기 호출형 자동화 어시스턴트 클라이언트에 의해, 사용자의 환경에서 제1 클라이언트 디바이스의 하나 이상의 마이크로폰에 의해 생성된 오디오 데이터에서 캡처된 사용자의 음성 질의를 수신하는 단계와, 상기 제1 자동화 어시스턴트 클라이언트는 제1 클라이언트 디바이스 상에 설치되고;
사용자와 오디오 데이터에 의해 표시된 초기 호출형 자동화 어시스턴트 사이의 이전 대화에 기초하여, 대화의 하나 이상의 용어로 표시된 사용자 의도를 식별하는 단계와;
환경의 제2 클라이언트 디바이스 상에 설치된 제2 자동화 어시스턴트 클라이언트에, 사용자 의도에 기초하여 질의를 처리할 권한을 제공하는 단계와; 그리고
초기 호출형 자동화 어시스턴트 클라이언트에 의해 제2 자동화 어시스턴트 클라이언트와의 통신 채널을 통해, 질의의 표시 및 사용자 의도를 제2 자동화 어시스턴트 클라이언트에 제공하는 단계를 포함하고, 상기 표시 및 사용자 의도를 제공하는 단계는 제2 자동화 어시스턴트 클라이언트가 하나 이상의 액션을 수행하게 하는 것을 특징으로 하는 컴퓨터 구현 방법.As a computer implemented method,
receiving, by an initial in-pace automated assistant client of an init-invoked automated assistant, a user's voice query captured in audio data generated by one or more microphones of a first client device in the user's environment; the assistant client is installed on the first client device;
based on a prior conversation between the user and the initially on-call automated assistant indicated by the audio data, identifying user intent indicated by one or more terms of the conversation;
providing a second automated assistant client installed on a second client device in the environment with permission to process the query based on user intent; and
providing an indication of the query and a user intent to a second automated assistant client via a communication channel with the second automated assistant client by the initiating automated assistant client, wherein providing the indication and user intent A computer implemented method comprising causing a second automated assistant client to perform one or more actions.
상기 통신 채널은 초음파 통신 채널을 포함하고, 그리고
상기 질의 표시 및 사용자 의도를 제2 자동화 어시스턴트 클라이언트에 제공하는 단계는,
질의의 표시 및 사용자 의도를 통합하는 초음파 신호가 제1 클라이언트 디바이스의 하나 이상의 스피커를 통해 렌더링되도록 하는 단계를 포함하는 것을 특징으로 하는 컴퓨터 구현 방법.According to claim 8,
the communication channel comprises an ultrasonic communication channel; and
Providing the query display and user intent to a second automated assistant client comprises:
A computer-implemented method comprising causing an ultrasound signal incorporating a display of a query and a user intent to be rendered through one or more speakers of a first client device.
사용자로부터, 질의를 처리하도록 제2 자동화 어시스턴트 클라이언트에 요청하는 제2 음성 질의를 수신하는 단계를 더 포함하고, 상기 권한을 제공하는 단계는 제2 음성 질의를 수신하는 것에 대한 응답인 것을 특징으로 하는 컴퓨터 구현 방법.The method of claim 8 or 9,
Receiving a second voice query from the user requesting a second automated assistant client to process the query, wherein the providing of the permission is a response to receiving the second voice query. computer implemented method.
제1 자동화 어시스턴트가 사용자 의도를 처리할 수 없다고 결정하는 단계와;
제1 자동화 어시스턴트가 사용자 의도를 처리할 수 없다는 결정에 응답하여, 권한을 제공하라는 제안을 사용자에게 제공하는 단계와; 그리고
사용자로부터 승인을 수신하는 단계를 더 포함하고, 상기 권한은 사용자로부터 승인을 수신하는 것에 응답하여 제2 자동화 어시스턴트 클라이언트에 제공되는 것을 특징으로 하는 컴퓨터 구현 방법.According to any one of claims 8 to 10,
determining that the first automated assistant is unable to process the user intent;
in response to determining that the first automated assistant is unable to process the user intent, providing the user with a suggestion to provide authorization; and
The computer implemented method further comprising receiving an authorization from the user, wherein the authorization is provided to the second automated assistant client in response to receiving the authorization from the user.
텍스트 질의를 생성하도록 상기 음성 질의를 캡처하는 오디오 데이터에 대해 자동 음성 인식을 수행하는 단계를 더 포함하고, 상기 질의의 표시는 텍스트 질의인 것을 특징으로 하는 컴퓨터 구현 방법.According to any one of claims 8 to 11,
The computer implemented method of claim 1 , further comprising performing automatic speech recognition on audio data capturing the speech query to generate a text query, wherein the representation of the query is a text query.
초기 호출형 자동화 어시스턴트에서, 후속 호출형 자동화 어시스턴트가 초기 호출형 자동화 어시스턴트와 함께 사용자의 이전 대화로부터의 이전 대화 데이터를 이용할 것을 요청하는 음성 발언을 사용자가 제공한 것으로 결정하는 단계와;
사용자가 그 음성 발언을 제공한 것으로 결정한 것에 응답하여,
초기 호출형 자동화 어시스턴트에 의해, 그 음성 발언을 캡처하는 오디오 데이터를 처리하는 단계와;
초기 호출형 자동화 어시스턴트에 의해 그 처리에 기초하여, 오디오 데이터가 이전 대화에 참여한 동일한 사용자에 의해 제공되었는지 여부를 결정하는 단계와; 그리고
사용자가 동일한 사용자라고 결정되는 경우:
후속 호출형 자동화 어시스턴트에 이전 대화 데이터를 제공하는 단계; 및
사용자가 동일한 사용자가 아닌 것으로 결정되는 경우:
대화 데이터 제공을 금지하는 단계를 포함하는 것을 특징으로 하는 컴퓨터 구현 방법.As a computer implemented method,
determining, at the initial in-paging automated assistant, that the user has provided a spoken utterance requesting that a subsequent in-paging automated assistant use previous conversation data from a previous conversation of the user with the initial in-paging automated assistant;
in response to determining that the user provided the spoken utterance;
processing, by the initiating on-call automated assistant, audio data capturing the spoken utterance;
determining, based on the processing by the initially on-call automated assistant, whether the audio data was provided by the same user who participated in the previous conversation; and
If the user is determined to be the same user:
providing previous conversation data to a subsequent on-call automated assistant; and
If it is determined that the user is not the same user:
A computer implemented method comprising the step of prohibiting provision of conversation data.
상기 오디오 데이터는,
초기 호출형 자동화 어시스턴트를 실행하는 제1 디바이스의 마이크로폰에 의해 캡처되는 것을 특징으로 하는 컴퓨터 구현 방법.According to claim 13,
The audio data is
A computer-implemented method characterized in that captured by the microphone of a first device running an initial in-call automated assistant.
상기 오디오 데이터는,
후속 호출형 자동화 어시스턴트를 실행하는 제2 디바이스의 마이크로폰에 의해 캡처되는 것을 특징으로 하는 컴퓨터 구현 방법.According to claim 13,
The audio data is
A computer-implemented method characterized by being captured by a microphone of a second device that executes a follow-on-call automated assistant.
상기 음성 발언은 초기 호출형 자동화 어시스턴트로 향하는 것인 것을 특징으로 하는 컴퓨터 구현 방법.According to any one of claims 13 to 15,
The computer implemented method of claim 1 , wherein the spoken utterance is directed to an initiating on-call automated assistant.
상기 음성 발언은 후속 호출형 자동화 어시스턴트로 향하는 것인 것을 특징으로 하는 컴퓨터 구현 방법.According to any one of claims 13 to 15,
The computer implemented method of claim 1 , wherein the spoken utterance is directed to a subsequent on-call automated assistant.
상기 이전 대화 데이터는,
초기 호출형 자동화 어시스턴트를 실행하는 제1 클라이언트 디바이스의 스피커에 의해 생성되고 후속 호출형 자동화 어시스턴트를 실행하는 제2 클라이언트 디바이스의 하나 이상의 마이크로폰에 의해 수신되는 비-인간 가청 신호를 통해 제공되는 것을 특징으로 하는 컴퓨터 구현 방법.According to any one of claims 13 to 17,
The previous conversation data,
characterized in that it is provided via a non-human audible signal generated by a speaker of a first client device executing an initial in-paging automated assistant and received by one or more microphones of a second client device executing subsequent in-paging automated assistants. A computer-implemented way to do it.
상기 이전 대화 데이터는,
초기 호출형 자동화 어시스턴트와 후속 호출형 자동화 어시스턴트 사이의 애플리케이션 프로그래밍 인터페이스를 통해 제공되는 것을 특징으로 하는 컴퓨터 구현 방법.According to any one of claims 13 to 17,
The previous conversation data,
and through an application programming interface between an initial invoking automated assistant and a subsequent invoking automated assistant.
상기 이전 대화 데이터는,
사용자와 초기 호출형 자동화 어시스턴트 사이의 대화의 텍스트 표현을 포함하는 것을 특징으로 하는 컴퓨터 구현 방법.According to any one of claims 13 to 19,
The previous conversation data,
A computer implemented method comprising a textual representation of a conversation between a user and an initiating automated assistant.
Applications Claiming Priority (5)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US202163224250P | 2021-07-21 | 2021-07-21 | |
US63/224,250 | 2021-07-21 | ||
US17/532,276 US20230025709A1 (en) | 2021-07-21 | 2021-11-22 | Transferring dialog data from an initially invoked automated assistant to a subsequently invoked automated assistant |
US17/532,276 | 2021-11-22 | ||
PCT/US2021/063753 WO2023003585A1 (en) | 2021-07-21 | 2021-12-16 | Transferring dialog data from an initially invoked automated assistant to a subsequently invoked automated assistant |
Publications (1)
Publication Number | Publication Date |
---|---|
KR20230118940A true KR20230118940A (en) | 2023-08-14 |
Family
ID=84976816
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
KR1020237023567A KR20230118940A (en) | 2021-07-21 | 2021-12-16 | Transferring conversational data from an initial on-call automated assistant to a subsequent on-call automated assistant |
Country Status (5)
Country | Link |
---|---|
US (1) | US20230025709A1 (en) |
EP (1) | EP4147231A1 (en) |
JP (1) | JP2024505787A (en) |
KR (1) | KR20230118940A (en) |
CN (1) | CN116670638A (en) |
Family Cites Families (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9875494B2 (en) * | 2013-04-16 | 2018-01-23 | Sri International | Using intents to analyze and personalize a user's dialog experience with a virtual personal assistant |
US20150364129A1 (en) * | 2014-06-17 | 2015-12-17 | Google Inc. | Language Identification |
JP7214719B2 (en) * | 2017-09-28 | 2023-01-30 | オラクル・インターナショナル・コーポレイション | Allow autonomous agents to distinguish between questions and requests |
CN111699483B (en) * | 2018-01-16 | 2024-04-09 | 谷歌有限责任公司 | Systems, methods, and apparatus providing assistant deep links to effect third party conversation session transfer |
CN112313924A (en) * | 2018-05-07 | 2021-02-02 | 谷歌有限责任公司 | Providing a composite graphical assistant interface for controlling various connected devices |
US20200111491A1 (en) * | 2018-10-08 | 2020-04-09 | Alkira Software Holdings Pty Ltd. | Speech enabled user interaction |
EP4270224A3 (en) * | 2018-12-03 | 2023-11-15 | Google LLC | Text independent speaker recognition |
-
2021
- 2021-11-22 US US17/532,276 patent/US20230025709A1/en active Pending
- 2021-12-16 CN CN202180088756.4A patent/CN116670638A/en active Pending
- 2021-12-16 JP JP2023536522A patent/JP2024505787A/en active Pending
- 2021-12-16 EP EP21841150.2A patent/EP4147231A1/en active Pending
- 2021-12-16 KR KR1020237023567A patent/KR20230118940A/en unknown
Also Published As
Publication number | Publication date |
---|---|
CN116670638A (en) | 2023-08-29 |
US20230025709A1 (en) | 2023-01-26 |
EP4147231A1 (en) | 2023-03-15 |
JP2024505787A (en) | 2024-02-08 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US11798541B2 (en) | Automatically determining language for speech recognition of spoken utterance received via an automated assistant interface | |
KR102475719B1 (en) | Generating and transmitting invocation request to appropriate third-party agent | |
CN111902865A (en) | Text-independent speaker recognition | |
US20240046935A1 (en) | Generating and/or utilizing voice authentication biasing parameters for assistant devices | |
JP2024020472A (en) | Semi-delegated calls with automated assistants on behalf of human participants | |
KR20230118940A (en) | Transferring conversational data from an initial on-call automated assistant to a subsequent on-call automated assistant | |
JP2024510698A (en) | Contextual suppression of assistant commands | |
WO2023003585A1 (en) | Transferring dialog data from an initially invoked automated assistant to a subsequently invoked automated assistant | |
US20230230578A1 (en) | Personalized speech query endpointing based on prior interaction(s) | |
US11756533B2 (en) | Hot-word free pre-emption of automated assistant response presentation | |
US11972764B2 (en) | Providing related queries to a secondary automated assistant based on past interactions | |
US20230186909A1 (en) | Selecting between multiple automated assistants based on invocation properties | |
US11783828B2 (en) | Combining responses from multiple automated assistants | |
WO2023113877A1 (en) | Selecting between multiple automated assistants based on invocation properties | |
JP2024519261A (en) | Providing a secondary automated assistant with relevant queries based on past interactions | |
CN117121101A (en) | Selectively masking query content to be provided to an auxiliary digital assistant |