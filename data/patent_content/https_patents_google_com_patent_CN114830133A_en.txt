CN114830133A - Supervised contrast learning with multiple positive examples - Google Patents
Supervised contrast learning with multiple positive examples Download PDFInfo
- Publication number
- CN114830133A CN114830133A CN202180007180.4A CN202180007180A CN114830133A CN 114830133 A CN114830133 A CN 114830133A CN 202180007180 A CN202180007180 A CN 202180007180A CN 114830133 A CN114830133 A CN 114830133A
- Authority
- CN
- China
- Prior art keywords
- computing system
- anchor
- images
- neural network
- image
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V10/00—Arrangements for image or video recognition or understanding
- G06V10/40—Extraction of image or video features
- G06V10/44—Local feature extraction by analysis of parts of the pattern, e.g. by detecting edges, contours, loops, corners, strokes or intersections; Connectivity analysis, e.g. of connected components
- G06V10/443—Local feature extraction by analysis of parts of the pattern, e.g. by detecting edges, contours, loops, corners, strokes or intersections; Connectivity analysis, e.g. of connected components by matching or filtering
- G06V10/449—Biologically inspired filters, e.g. difference of Gaussians [DoG] or Gabor filters
- G06V10/451—Biologically inspired filters, e.g. difference of Gaussians [DoG] or Gabor filters with interaction between the filter responses, e.g. cortical complex cells
- G06V10/454—Integrating the filters into a hierarchical structure, e.g. convolutional neural networks [CNN]
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F18/00—Pattern recognition
- G06F18/20—Analysing
- G06F18/21—Design or setup of recognition systems or techniques; Extraction of features in feature space; Blind source separation
- G06F18/214—Generating training patterns; Bootstrap methods, e.g. bagging or boosting
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F18/00—Pattern recognition
- G06F18/20—Analysing
- G06F18/21—Design or setup of recognition systems or techniques; Extraction of features in feature space; Blind source separation
- G06F18/217—Validation; Performance evaluation; Active pattern learning techniques
- G06F18/2178—Validation; Performance evaluation; Active pattern learning techniques based on feedback of a supervisor
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F18/00—Pattern recognition
- G06F18/20—Analysing
- G06F18/22—Matching criteria, e.g. proximity measures
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F18/00—Pattern recognition
- G06F18/20—Analysing
- G06F18/24—Classification techniques
- G06F18/243—Classification techniques relating to the number of classes
- G06F18/2431—Multiple classes
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/045—Combinations of networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/084—Backpropagation, e.g. using gradient descent
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/09—Supervised learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V10/00—Arrangements for image or video recognition or understanding
- G06V10/70—Arrangements for image or video recognition or understanding using pattern recognition or machine learning
- G06V10/74—Image or video pattern matching; Proximity measures in feature spaces
- G06V10/761—Proximity, similarity or dissimilarity measures
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V10/00—Arrangements for image or video recognition or understanding
- G06V10/70—Arrangements for image or video recognition or understanding using pattern recognition or machine learning
- G06V10/764—Arrangements for image or video recognition or understanding using pattern recognition or machine learning using classification, e.g. of video objects
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V10/00—Arrangements for image or video recognition or understanding
- G06V10/70—Arrangements for image or video recognition or understanding using pattern recognition or machine learning
- G06V10/77—Processing image or video features in feature spaces; using data integration or data reduction, e.g. principal component analysis [PCA] or independent component analysis [ICA] or self-organising maps [SOM]; Blind source separation
- G06V10/774—Generating sets of training patterns; Bootstrap methods, e.g. bagging or boosting
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V10/00—Arrangements for image or video recognition or understanding
- G06V10/70—Arrangements for image or video recognition or understanding using pattern recognition or machine learning
- G06V10/77—Processing image or video features in feature spaces; using data integration or data reduction, e.g. principal component analysis [PCA] or independent component analysis [ICA] or self-organising maps [SOM]; Blind source separation
- G06V10/776—Validation; Performance evaluation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V10/00—Arrangements for image or video recognition or understanding
- G06V10/70—Arrangements for image or video recognition or understanding using pattern recognition or machine learning
- G06V10/82—Arrangements for image or video recognition or understanding using pattern recognition or machine learning using neural networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/082—Learning methods modifying the architecture, e.g. adding, deleting or silencing nodes or connections
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T2207/00—Indexing scheme for image analysis or image enhancement
- G06T2207/20—Special algorithmic details
- G06T2207/20084—Artificial neural networks [ANN]
Abstract
The present disclosure provides an improved training method that enables supervised contrast learning to be performed simultaneously across multiple positive and negative training examples. In particular, example aspects of the present disclosure are directed to an improved supervised version of bulk contrast loss that has been shown to be very effective for learning robust representations in an auto-supervised setting. Thus, the proposed technique adapts contrast learning to a fully supervised setting and also enables learning to occur simultaneously across multiple positive examples.
Description
Cross Reference to Related Applications
This application claims priority and benefit from U.S. provisional patent application No. 63/013,153, filed on 21/4/2020. U.S. provisional patent application No. 63/013,153 is hereby incorporated by reference in its entirety.
Technical Field
The present disclosure relates generally to systems and methods for comparative learning of visual representations. More particularly, the present disclosure relates to systems and methods for performing supervised contrast learning across multiple positive examples.
Background
Cross-entropy loss is probably the most widely used loss function in supervised learning. It is naturally defined as the KL-divergence between two discrete distributions: empirical label distribution (discrete distribution of 1-hot vectors) and empirical distribution of logits.
Many efforts have explored the drawbacks of such losses, such as lack of robustness to noise signatures and possibly poor margins, which lead to reduced generalization performance. However, in practice, most of the proposed alternatives do not seem to work better for large scale datasets, such as ImageNet, which can be demonstrated by continuing to use cross-entropy to achieve the most advanced results.
Many of the improvements proposed over conventional cross entropy actually involve relaxation of the definition of the loss, especially if the reference distribution is axis aligned. Models trained with these modifications exhibit improved generalization ability, robustness, and calibration. However, the proposed improvements do not completely eliminate the drawbacks of the cross-entropy loss approach.
Disclosure of Invention
Aspects and advantages of embodiments of the present disclosure will be set forth in part in the description which follows, or may be learned by practice of the embodiments.
One example aspect of the present disclosure is directed to a computing system that performs supervised contrast learning of visual representations. The computing system includes one or more processors and one or more non-transitory computer-readable media collectively storing: a base encoder neural network configured to process an input image to generate an embedded representation of the input image; a projection head neural network configured to process the embedded representation of the input image to generate a projected representation of the input image; and instructions that when executed by the one or more processors cause the computing system to perform operations. The operations include obtaining an anchor image associated with a first class of a plurality of classes, a plurality of positive images associated with the first class, and one or more negative images associated with one or more other classes of the plurality of classes, the one or more other classes being different from the first class. The operations include processing the anchor image with a base encoder neural network to obtain an anchor embedded representation of the anchor image, processing the plurality of positive images to obtain a plurality of positive embedded representations, respectively, and processing the one or more negative images to obtain one or more negative embedded representations, respectively. The operations include processing the anchor embedded representation with a projection head neural network to obtain an anchor projection representation of the anchor image, processing the plurality of positive embedded representations to obtain a plurality of positive projection representations, respectively, and processing the one or more negative embedded representations to obtain one or more negative projection representations, respectively. The operations include evaluating a loss function that evaluates a similarity metric between the anchor projection representation and each of the plurality of forward projection representations and each of the one or more backprojection representations. The operations include modifying one or more values of one or more parameters of at least a base encoder neural network based at least in part on a loss function.
Other aspects of the disclosure are directed to various systems, apparatuses, non-transitory computer-readable media, user interfaces, and electronic devices.
These and other features, aspects, and advantages of various embodiments of the present disclosure will become better understood with reference to the following description and appended claims. The accompanying drawings, which are incorporated in and constitute a part of this specification, illustrate exemplary embodiments of the disclosure and together with the description, serve to explain the relevant principles.
Drawings
A detailed discussion of embodiments directed to one of ordinary skill in the art is set forth in the specification with reference to the drawings, in which:
fig. 1A and 1B illustrate the difference between supervised and unsupervised contrast loss according to an example embodiment of the present disclosure.
2A-C illustrate the difference between cross-entropy, self-supervised contrast loss, and supervised contrast loss according to example embodiments of the present disclosure.
Fig. 3 illustrates an example comparative learning framework according to an example embodiment of the present disclosure.
Fig. 4 illustrates an example trim model featuring a base encoder learned according to an example contrast learning framework according to an example embodiment of the present disclosure.
Fig. 5A depicts a block diagram of an example computing system, according to an example embodiment of the present disclosure.
Fig. 5B depicts a block diagram of an example computing device, according to an example embodiment of the present disclosure.
Fig. 5C depicts a block diagram of an example computing device, according to an example embodiment of the disclosure.
Reference numerals repeated throughout the several figures are intended to identify like features in the various embodiments.
Detailed Description
Overview
In general, the present disclosure is directed to an improved training method that enables supervised contrast learning to be performed simultaneously across multiple positive and negative training examples. In particular, example aspects of the present disclosure are directed to an improved supervised version of bulk contrast loss that has proven to be very effective for learning robust representations in an auto-supervised setting. Thus, the proposed technique adapts contrast learning to a fully supervised setting and also enables learning to occur simultaneously across multiple positive examples.
By enabling contrast learning to occur simultaneously across multiple positive training cases from the same class and multiple negative training cases from other classes, the entire cluster of points belonging to the same class can be pulled together in the embedding space, while sample clusters from different classes are pushed apart simultaneously. Thus, the proposed technique serves to increase the similarity between the positive pairs of samples and decrease the similarity between the negative pairs. For example, similarity may be defined as the inner product between low-dimensional representations. The resulting representation is a very good representation and can be used for various downstream transport tasks.
Thus, the proposed system and method can utilize label or other class assignment information more efficiently than systems that use cross-entropy loss. In particular, using a contrast learning approach allows the representation of each class to be learned at any point within the embedding space, rather than forcing the representation of each class to be consistent with a particular axis-aligned class value, as is done in cross-entropy loss, allowing more robust inter-class representations to be learned.
An example model trained according to the proposed technique is consistently superior to cross-entropy on supervised learning tasks across different architectures and data enhancements. Specifically, as shown by the example experimental results contained in U.S. provisional patent application No. 63/013,153 for ResNet-50 and ResNet-200, the example model trained according to the proposed technique outperforms the cross entropy by more than 1%, setting a new best figure of 78: 8% in the method using automatic enhancement data enhancement.
The proposed loss also shows a clear benefit to robustness to natural damage on a standard basis, both in terms of calibration and accuracy. Furthermore, the proposed supervised contrast loss is more stable for hyper-parameter settings such as optimizers or data enhancement than cross entropy. Additional aspects of the present disclosure utilize key components such as large batches and normalized representations, which have proven beneficial for self-supervised learning.
More specifically, example aspects of the present disclosure are directed to a new loss of supervised training, which completely removes the reference distribution; in contrast, the example embodiments of the proposed system simply employ a normalized representation from the same class closer than a representation from a different class. The proposed penalty builds on a family of comparative objective functions that have gained excellent performance in recent years in self-supervised learning in the image and video domains, and is linked to the large body of literature for metric learning.
As the name implies, the contrast loss consists of two "opposing forces": for a given anchor, the first force pulls the anchor closer to other points in the representation space, and the second force pushes the anchor farther away from other points. The former group is called positive and the latter group is called negative.
One aspect of the present disclosure is that in addition to many negative examples, many positive examples are considered for each anchor (e.g., as opposed to the convention in self-supervised contrast learning that uses only a single positive example). In some implementations, a provided label or other class-based designation can be used to select positive and negative examples. FIGS. 1A-B and 2A-C provide a visual explanation of the proposed loss.
In particular, fig. 1A and 1B illustrate the difference between supervised and unsupervised contrast loss. In the example embodiment of supervised loss of contrast presented herein (shown generally in FIG. 1A), positive examples from one class are compared to negative examples from other classes (as labels are provided); this results in images from the same class (but not necessarily depicting the same exact scene or subject) being mapped to neighboring points in the low-dimensional hypersphere. In contrast, in the case of self-supervised contrast loss (as shown in fig. 1B), no label is provided. Thus, a positive case is generated as data enhancement (cropping, flipping, color change, etc.) for a given sample, and a negative case is randomly sampled from a mini-batch. This may result in a false negative case (shown in the bottom right) that may not map correctly, resulting in a worse representation.
Fig. 2A-C show the difference between cross entropy, self-supervised contrast loss and supervised contrast loss. In particular, cross-entropy loss (as shown in FIG. 2A) uses labels and softmax loss to train the model, while self-supervised contrast loss (as shown in FIG. 2B) uses contrast loss and data enhancement to learn representations about classes. However, in some embodiments, the proposed supervised loss of contrast (shown generally in fig. 2C) has two phases; in a first stage, the label is used to select an image for contrast loss, comprising a plurality of positive examples and one or more negative examples. In the second phase, the learned representation is frozen, and then the classifier or other task specific header (e.g., on a linear layer) can be learned using softmax or cross entropy loss. This two-stage approach combines all the advantages of using labels and contrast loss and softmax or cross-entropy loss.
As shown by the example empirical results contained in U.S. provisional patent application No. 63/013,153, the resulting losses are stable for training. As an example, an example model trained according to the proposed supervised contrast technique achieves very good top-1 accuracy on ImageNet datasets over the ResNet-50 and ResNet-200 architectures. On ResNet-50 with auto-boost, the example embodiment achieves a top-1 accuracy of 78.8%, which is a 1.6% improvement over cross-entropy loss with the same data boost and architecture. The improvement in top-1 accuracy is also accompanied by an improvement in robustness as measured on the ImageNet-C dataset.
The system and method of the present disclosure provide a number of technical effects and benefits. As an example technical effect, the proposed penalty allows the model to learn the most advanced representation compared to cross entropy, thereby significantly improving top-1 accuracy and robustness. Thus, the proposed techniques improve the performance and functionality of the computing system itself in various tasks, such as image classification tasks.
As another example technical effect, the proposed loss is less sensitive to a range of hyper-parameters than cross-entropy, which is an important practical consideration. This reduced sensitivity is due to a more natural loss formula that pulls representations from samples of the same class closer, rather than forcing them to be pulled to a particular target as in cross-entropy. In a typical training system, multiple rounds of training may be required to "tune" the hyper-parameters to find acceptable or optimal performance. By reducing the loss and sensitivity of the model to the hyper-parameters, fewer training rounds may need to be performed to adjust the hyper-parameters. Reducing the number of training rounds performed results in savings in computing resources, such as processor usage, memory usage, network bandwidth, and the like.
As another example technical effect, as shown in the analysis herein, the gradient of the proposed loss function encourages learning from hard positive and hard negative examples. In some existing systems, explicit and computationally expensive methods are typically performed to identify certain difficult cases. One example approach to this property is "hard case mining". These methods improve performance but consume significant computational resources. By naturally encouraging learning from hard positive and hard negative examples, such explicit attempts to identify hard examples (e.g., hard negative examples) may be avoided, thereby conserving computing resources such as processor usage, memory usage, network bandwidth, and the like.
As yet another example technical effect, the proposed method may result in a reduction in the number of false negatives produced by the training model. For example, by enabling learning positive examples in the same class, but depicting different topics or scenes, such positive examples may be avoided from being treated as negative examples. Thus, the trained model learns to provide a consistent representation for all class members, not just for a particular topic or scenario. Training models with reduced false negatives represent an improvement in the functionality of the computing system itself.
Accordingly, aspects of the present disclosure provide improved contrast learning loss that outperforms cross entropy on a classification accuracy and robustness basis. Furthermore, example experiments show that such losses are less sensitive to over-parameter variations, which may be a useful practical consideration. The loss function provides a natural link between fully unsupervised training on one end and fully supervised training on the other end. This opens up the possibility of semi-supervised learning applications, which can take advantage of the single loss, can smoothly change behavior based on the availability of labeled data.
Example systems and methods for supervised contrast learning
This section first reviews the comparative learning loss for the self-supervised representation learning. Next, it shows how this loss can be modified to fit fully supervised learning, while preserving attributes important to the self-supervised approach.
Example representation learning framework
One example represents a learning framework as shown in fig. 3 and similar in structure to the framework typically used for self-supervised contrast learning. As shown in FIG. 3, one example representation learning framework includes the following components. (see also FIGS. 1A-B and 2A-C, showing the differences between the supervised and the unsupervised scenarios).
An optional data enhancement module 203, a (-) that transforms the input image 202, x, into a random enhanced image 212,input image 202, the system can be implemented to generate two or more randomly enhanced images 212, each of which represents a different view of the data, and thus contains some subset of the information in the original input image. However, other embodiments may be configured to generate only a single enhanced image. Example expressions (e.g., example loss functions) that refer to twice the number of images included in a class contained herein are stylized in this manner to explain example embodiments in which two enhanced images are generated per input image. However, this stylization may be modified to account for the different number of enhanced images generated per input image.
Referring to the data enhancement module 203, as one example, the first stage of enhancement may include applying random cropping to the image and then resizing it back to the original resolution of the image. As another example, depending on the finding that the self-supervised contrast loss requires significantly different data enhancement than the cross-entropy loss, the second stage may include some or all of the different enhancements described in any of the following:
AutoAutoAutoAutoAutoAutoAutoAutoAutoaugmentation: ekin D Cubuk, Barret Zoph, Dandelion Man, Vijay Vasudevan, and Quoc V Le. AutoAutoAutoAutoAutoAutoAutoAutoAutoaugmentation: learning enhancement strategies from data (Learning augmentation strategies from data). IEEE computer vision and pattern recognition conference discourse collection, page 113-.
randAugment: ekin D Cubuk, Barret Zoph, Jonathon Shlens and Quoc V Le. Randaugment: there is no Practical data augmentation of separate search with no separate search. arXiv preprint arXiv: 1909.13719, 2019
SimAugment: variants of the strategies of Ting Chen, Simon Kornblith, Mohammad Norouzi and Geoffrey Hinto. Visual representation versus a simple framework for learning. arXiv preprint arXiv: 2002.05709, 2020 random color distortion and gaussian blur are applied sequentially, with additional sparse image distortion added probabilistically to the end of the sequence.
More generally, the data enhancement module 203 may perform any different combination of one or more enhancements. Furthermore, some example embodiments of the present disclosure do not perform enhancement of the input image 202, but simply use the input image 202 without enhancement.
Referring again to FIG. 3, the framework may include a base encoder neural network 204, E (-), which will enhance the image 212representation vector 214 and,
in some example embodiments where two enhanced images are generated for each input image of the frame, the two enhanced images for each input image may be input separately to the same encoder, resulting in a pair of representation vectors. More generally, the same encoder network 204 is typically used to generate representations of all the images in the training batch.
Two common encoder architectures for encoder network 204 include ResNet-50 and ResNet-200, e.g., a final pooling layer (D) E 2048) may be used as the representation vector 214. In some example embodiments, the presentation layer may be normalized to
The framework may also include a projection network 206, P (-), which projects the normalized representation vector r214 onto a projection representation 216 suitable for calculating contrast lossexample projection network 216 may be a single hidden layer having a size 2048 and a size D P 128 output vector. In some example embodiments, the vector may again be normalized to lie on a unit hypersphere, which enables the use of the inner product to measure distances in projection space. Normalization adds a mathematical structure to the form of the gradient, which makes training generally superior to the case where no normalization is performed.
The loss function of the input image 202 may be evaluated based on the projected representation 216 (e.g., via comparison to other projected representations generated for other input images, such as other positive and negative training examples).
In some embodiments, the projection network 206 is used only for training supervision contrast loss. After training is complete, the network may be discarded and replaced with a task-specific header (e.g., a single linear layer). The embedded representation 214 from the encoder 204 gives improved performance for downstream tasks compared to the projected representation 216 from the projection network 206. Thus, in some embodiments, the proposed inference time model may contain exactly the same number of parameters as their cross-entropy equivalents.
As one example, fig. 4 depicts a diagram of an example use of the base encoder neural network 204 after the base encoder neural network 204 has been trained in the example framework shown in fig. 3. In particular, the base encoder neural network 204 has been extracted, and an additional task-specific model 250 has been appended to the base encoder neural network 204. For example, the task specific model 250 may be any kind of model including a linear model or a non-linear model (such as a neural network).
The task-specific model 250 and/or the base encoder neural network 204 may be additionally trained (e.g., "fine-tuned") on additional training data (e.g., may be task-specific data). The additional training may be, for example, supervised learning training.
After the fine-tuning, additional inputs 252 may be provided to the base encoder neural network 204, which base encoder neural network 204 may produce the embedded representation 254. The task-specific model 250 may receive and process the embedded representation 254 to generate a task-specific prediction 256. As an example, the task-specific prediction 256 may be a classification prediction; detecting a prediction; identifying a prediction; performing regression prediction; performing segmentation prediction; and/or other predictive tasks.
Moreover, in some embodiments, embedded representation 254 may be used directly for tasks such as similarity search or retrieval without further training/fine-tuning (e.g., without additional task-specific model 250).
Although for ease of explanation, the present disclosure focuses on data examples from the image domain, the framework may be extended to data examples of different domains (including the text and/or audio domain). Example types of images that may be used include video frames, LiDAR point clouds, computed tomography scans, X-ray images, hyperspectral images, and/or various other forms of images.
Example comparative loss: self-supervision and supervision
Example embodiments of the present disclosure provide a contrast loss function that allows for efficient integration of label data while preserving contrast loss that has been critical to the success of self-supervised representation learningThe beneficial properties of the fluid. Similar to the self-supervised contrast learning, example embodiments of the present disclosure may generate mini-batches by randomly sampling data. As an example, { x ] for a set of N randomly sampled image/label pairs k ,y k } k＝1...N The corresponding mini-batch for training may include 2N pairs,
Example self-supervision contrast loss
Within a mini-batch, let i e {1.. 2N } be the index of any enhanced image, and let j (i) be the index of another enhanced image originating from the same source image. In the self-supervised comparative learning, the loss has the following forms.
Wherein
It is very interesting to consider minimizing the impact of eq.1 on the encoder. During training, for any i, the encoder is adjusted to maximize the numerator of the log parameter in Eq.2, while minimizing its denominator. The term exp (z) i ·z j(i) ) Constraints that appear in both the numerator and denominator ensure that the log parameter is not higher than 1, and because eq.1 sums all index pairs ((i, j) and (j, i)), the encoder is constrained to minimize the denominator or maximize the numerator without doing another operation. As a result, the encoder learns to map similar views to neighboring representations while mapping dissimilar views to non-neighboring views, but only a single positive case on a per-evaluation basis.
Example supervision loss of contrast
For supervised learning, the loss of contrast in Eq.2 cannot handle cases where more than one sample is determined to belong to the same class. To generalize the loss to handle any number of positive examples belonging to the same class, the following novel loss function is proposed:
wherein
generalizing to any number of positive cases. One significant structural change in eq.4 over eq.2 is that now, for any anchor, all positive cases in the mini-batch (i.e., one based on the enhancement and any of the remaining 2(N-1) entries from the same class) contribute to the molecule. For a mini-batch, which is large relative to the number of classes, a number of additional terms will occur (on average,
The amount of contrast (power) increases with increasing positive and/or negative examples. The example general form of the self-supervised contrast loss given in eq.4 makes use of the principle of improving the ability to distinguish between signal and noise (negative examples) by adding more examples of positive examples and/or more examples of negative examples. This feature has been shown to be important for representation learning via self-supervised contrast learning, and many studies have shown that as the number of negative examples increases, so does performance.
The example supervised contrast loss in eq.4 preserves this structure: more negative examples are added into the denominator, so that the contrast of positive examples is increased; likewise, adding more positive examples to the molecule increases the contrast for negative examples. More positive examples allow the model to better capture intra-class variations. More negative examples enable the model to capture changes between classes.
Discussion of example supervised contrast loss gradient Properties
This subsection now provides further motivation for the example form of supervised contrast loss in eq.4 by: showing that its gradient has a structure that naturally leads to learning to focus more on hard positive and negative examples (i.e., those that continue to benefit the encoder greatly from anchoring versus) than weak positive and negative examples (i.e., those that continue to benefit the encoder only weakly from anchoring versus). It can thus be seen that this loss is effective in its training. Other contrast losses, such as triple losses, often use computationally expensive hard case mining techniques to improve training efficiency. As a by-product of this analysis, it is shown to be beneficial to add a normalization layer at the end of the projection network, since its presence allows the gradient to have this structure.
If we assume that w represents the projection network output immediately before normalization (i.e., z ═ w/| | w |), the gradient of eq.4 with respect to w has the following form:
wherein:
wherein:
is the second of the temperature scale softmax distribution of the inner product of the representation with respect to anchor i
however, for the hard case, z i ·z j 0 and P ij Is moderate, so:
thus, for the weak positive case, where further contrast effort is rewarded less, for
Example apparatus and System
Fig. 5A depicts a block diagram of an example computing system 100, according to an example embodiment of the present disclosure. The system 100 includes a user computing device 102, a server computing system 130, and a training computing system 150 communicatively coupled via a network 180.
The user computing device 102 may be any type of computing device, such as, for example, a personal computing device (e.g., laptop or desktop), a mobile computing device (e.g., a smartphone or tablet), a gaming console or controller, a wearable computing device, an embedded computing device, or any other type of computing device.
The user computing device 102 includes one or more processors 112 and memory 114. The one or more processors 112 may be any suitable processing device (e.g., processor core, microprocessor, ASIC, FPGA, controller, microcontroller, etc.) and may be one processor or operatively connected processors. Memory 114 may include one or more non-transitory computer-readable storage media, such as RAM, ROM, EEPROM, EPROM, flash memory devices, disks, etc., and combinations thereof. The memory 114 may store data 116 and instructions 118 that are executed by the processor 112 to cause the user computing device 102 to perform operations.
In some implementations, the user computing device 102 can store or include one or more machine learning models 120. For example, the machine learning model 120 may be or may otherwise include various machine learning models, such as a neural network (e.g., a deep neural network) or other types of machine learning models, including non-linear models and/or linear models. The neural network may include a feed-forward neural network, a recurrent neural network (e.g., a long-short term memory recurrent neural network), a convolutional neural network, or other form of neural network. An example machine learning model 120 is discussed with reference to fig. 3 and 4.
In some implementations, the one or more machine learning models 120 can be received from the server computing system 130 over the network 180, stored in the user computing device memory 114, and then used or otherwise implemented by the one or more processors 112. In some implementations, the user computing device 102 can implement multiple parallel instances of a single machine learning model 120 (e.g., perform parallel predictions across multiple input instances).
Additionally or alternatively, one or more machine learning models 140 may be included in the server computing system 130 in communication with the user computing device 102 according to a client-server relationship, or stored and implemented by the server computing system 130. For example, the machine learning model 140 may be implemented by the server computing system 140 as part of a web service (e.g., a prediction service). Thus, one or more models 120 can be stored and implemented at the user computing device 102, and/or one or more models 140 can be stored and implemented at the server computing system 130.
The user computing device 102 may also include one or more user input components 122 that receive user input. For example, the user input component 122 may be a touch-sensitive component (e.g., a touch-sensitive display screen or touchpad) that is sensitive to touch by a user input object (e.g., a finger or stylus). The touch sensitive component may be used to implement a virtual keyboard. Other example user input components include a microphone, a conventional keyboard, or other devices that a user may use to provide user input.
The server computing system 130 includes one or more processors 132 and memory 134. The one or more processors 132 may be any suitable processing device (e.g., processor core, microprocessor, ASIC, FPGA, controller, microcontroller, etc.) and may be one processor or operatively connected processors. Memory 134 may include one or more non-transitory computer-readable storage media, such as RAM, ROM, EEPROM, EPROM, flash memory devices, a disk, and the like, as well as combinations thereof. The memory 134 may store data 136 and instructions 138 that are executed by the processor 132 to cause the server computing system 130 to perform operations.
In some implementations, the server computing system 130 includes or is implemented by one or more server computing devices. In instances where the server computing system 130 includes multiple server computing devices, such server computing devices may operate according to a sequential computing architecture, a parallel computing architecture, or some combination thereof.
As described above, the server computing system 130 may store or otherwise include one or more machine learning models 140. For example, the model 140 may be or may include various machine learning models. Example machine learning models include neural networks or other multi-layered nonlinear models. Example neural networks include feed-forward neural networks, deep neural networks, recurrent neural networks, and convolutional neural networks. An example model 140 is discussed with reference to fig. 3 and 4.
The user computing device 102 and/or the server computing system 130 may train the models 120 and/or 140 via interaction with a training computing system 150 communicatively coupled through a network 180. The training computing system 150 may be separate from the server computing system 130 or may be part of the server computing system 130.
In some embodiments, performing back-propagation of the error may include performing truncated back-propagation over time. Model trainer 160 may perform a variety of generalization techniques (e.g., weight decay, dropping, etc.) to improve the generalization capability of the trained models.
In particular, the model trainer 160 may train the machine learning models 120 and/or 140 based on a set of training data 162. The training data 162 may include, for example, different forms of data, such as images, audio samples, text, and so forth. Example types of images that may be used include video frames, LiDAR point clouds, X-ray images, computed tomography scans, hyperspectral images, and/or various other forms of images.
In some implementations, the training examples may be provided by the user computing device 102 if the user has provided consent. Thus, in such implementations, the model 120 provided to the user computing device 102 may be trained by the training computing system 150 on user-specific data received from the user computing device 102. In some instances, this process may be referred to as a personalization model.
The model trainer 160 includes computer logic for providing the desired functionality. Model trainer 160 may be implemented in hardware, firmware, and/or software that controls a general purpose processor. For example, in some embodiments, model trainer 160 includes program files stored on a storage device, loaded into memory, and executed by one or more processors. In other embodiments, model trainer 160 includes one or more sets of computer-executable instructions stored in a tangible computer-readable storage medium (such as a RAM hard disk or an optical or magnetic medium).
FIG. 5A illustrates one example computing system that can be used to implement the present disclosure. Other computing systems may also be used. For example, in some implementations, the user computing device 102 may include a model trainer 160 and a training data set 162. In such implementations, the model 120 may be trained and used locally at the user computing device 102. In some such implementations, the user computing device 102 may implement the model trainer 160 to personalize the model 120 based on user-specific data.
Fig. 5B depicts a block diagram of an example computing device 10, performed in accordance with an example embodiment of the present disclosure. Computing device 10 may be a user computing device or a server computing device.
As shown in fig. 5B, each application may communicate with a plurality of other components of the computing device (such as, for example, one or more sensors, a context manager, a device state component, and/or additional components). In some implementations, each application can communicate with each device component using an API (e.g., a public API). In some embodiments, the API used by each application is application specific.
Fig. 5C depicts a block diagram of an example computing device 50, performed in accordance with an example embodiment of the present disclosure. Computing device 50 may be a user computing device or a server computing device.
The central smart inlay includes a number of machine learning models. For example, as shown in fig. 5C, a respective machine learning model (e.g., model) may be provided for each application and managed by the central intelligence layer. In other embodiments, two or more applications may share a single machine learning model. For example, in some embodiments, the central smart inlay may provide a single model (e.g., a single model) for all applications. In some embodiments, the central smart inlay is included in or implemented by the operating system of the computing device 50.
The central smart inlay may communicate with a central device data plane. The central device data layer may be a centralized data repository for the computing device 50. As shown in fig. 5C, the central device data layer may communicate with a plurality of other components of the computing device, such as, for example, one or more sensors, a context manager, a device state component, and/or additional components. In some implementations, the central device data layer can communicate with each device component using an API (e.g., a private API).
Additional disclosure
The technology discussed herein relates to servers, databases, software applications, and other computer-based systems, as well as actions taken and information sent to and received from these systems. The inherent flexibility of computer-based systems allows for a variety of possible configurations, combinations, and divisions of tasks and functions between components. For example, the processes discussed herein may be implemented using a single device or component or multiple devices or components operating in combination. The database and applications may be implemented on a single system or may be distributed across multiple systems. The distributed components may operate sequentially or in parallel.
While the present subject matter has been described in detail with respect to various specific example embodiments thereof, each example is provided by way of explanation, not limitation of the disclosure. Alterations, permutations, and equivalents of these embodiments may be readily produced by those skilled in the art after understanding the foregoing. Accordingly, the subject disclosure does not preclude inclusion of such modifications, variations and/or additions to the present subject matter as would be readily apparent to one of ordinary skill in the art. For instance, features illustrated or described as part of one embodiment, can be used with another embodiment to yield a still further embodiment. Thus, the present disclosure is intended to cover such alternatives, modifications, and equivalents.
Claims (17)
1. A computing system that performs supervised contrast learning of visual representations, the computing system comprising:
one or more processors; and
one or more non-transitory computer-readable media collectively storing:
a base encoder neural network configured to process an input image to generate an embedded representation of the input image;
a projection head neural network configured to process the embedded representation of the input image to generate a projected representation of the input image; and
instructions that, when executed by the one or more processors, cause the computing system to perform operations comprising:
obtaining an anchor image associated with a first class of a plurality of classes, a plurality of positive images associated with the first class, and one or more negative images associated with one or more other classes of the plurality of classes, the one or more other classes being different from the first class;
processing the anchor image with the base encoder neural network to obtain an anchor embedded representation of the anchor image, processing the plurality of positive images to obtain a plurality of positive embedded representations, respectively, and processing one or more negative images to obtain one or more negative embedded representations, respectively;
processing the anchor embedded representation with the projection head neural network to obtain an anchor projection representation of the anchor image, processing the plurality of positive embedded representations to respectively obtain a plurality of positive projection representations, and processing the one or more negative embedded representations to respectively obtain one or more negative projection representations;
evaluating a loss function that evaluates a similarity measure between the anchor projection representation and each of the plurality of forward projection representations and each of the one or more backprojection representations; and
modifying one or more values of one or more parameters of at least the base encoder neural network based at least in part on the loss function.
2. The computing system of any preceding claim, wherein at least one of the anchor image and one or more positive images depict different objects belonging to a same first class of the plurality of classes.
3. The computing system of any preceding claim, wherein the plurality of positive images includes all images included within a training batch that are associated with the first class, and wherein one or more negative anchor images includes all images included within the training batch that are not associated with any of the plurality of classes other than the first class.
4. The computing system of any preceding claim, wherein the operations further comprise enhancing each of the anchor picture, the plurality of positive pictures, and the one or more negative pictures, respectively, prior to processing each of the anchor picture, the plurality of positive pictures, and the one or more negative pictures with the base encoder neural network.
5. The computing system of any preceding claim, wherein the projection head neural network comprises a normalization layer that normalizes a projection representation of the input image.
6. The computing system of any preceding claim, wherein the similarity measure comprises an inner product.
7. The computing system of any preceding claim, wherein the loss function comprises a sum of a normalization term multiplied by a contrast loss term across all images in the training batch, wherein the normalization term normalizes a plurality of images included in the first class of anchor images.
8. The computing system of claim 7, wherein the normalization term comprises negative one divided by twice the number of images included in the first class of anchor images minus one.
9. The computing system of claim 7 or claim 8 wherein when an image evaluated by the sum is included in the first class, a logarithm is taken of the sum of the index of similarity measure between the anchor image and the evaluated image divided by the index of similarity between the anchor and such images for all images not included in the first class.
10. The computing system of any preceding claim, wherein after modifying one or more values of one or more parameters of at least the base encoder neural network based at least in part on the loss function, the operations further comprise:
adding a classification header to the base encoder neural network; and
the classification head is fine-tuned based on a set of supervised training data.
11. The computing system of any preceding claim, wherein after modifying one or more values of one or more parameters of at least the base encoder neural network based at least in part on the loss function, the operations further comprise:
providing an additional input to the base encoder neural network;
receiving an additional embedded representation of the additional input as an output of the base encoder neural network; and
generating a prediction for the additional input based at least in part on the additional embedded representation.
12. The computing system of claim 11, wherein the prediction comprises a classification prediction, a detection prediction, an identification prediction, a regression prediction, a partition prediction, or a similarity search prediction.
13. The computing system of any preceding claim, wherein the anchor image comprises an x-ray image.
14. The computing system of any preceding claim, wherein the anchor image comprises a set of LiDAR data.
15. The computing system of any preceding claim, wherein the anchor image comprises video.
16. A computer-implemented method comprising performing, by a computing system comprising one or more computing devices, some or all of the operations of any preceding claim.
17. One or more non-transitory computer-readable media collectively storing at least one base encoder neural network that has been trained by performing some or all of the operations of any of claims 1-15.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US202063013153P | 2020-04-21 | 2020-04-21 | |
US63/013,153 | 2020-04-21 | ||
PCT/US2021/026836 WO2021216310A1 (en) | 2020-04-21 | 2021-04-12 | Supervised contrastive learning with multiple positive examples |
Publications (1)
Publication Number | Publication Date |
---|---|
CN114830133A true CN114830133A (en) | 2022-07-29 |
Family
ID=78081983
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202180007180.4A Pending CN114830133A (en) | 2020-04-21 | 2021-04-12 | Supervised contrast learning with multiple positive examples |
Country Status (6)
Country | Link |
---|---|
US (2) | US20230153629A1 (en) |
EP (1) | EP4121907A1 (en) |
JP (1) | JP2023523726A (en) |
KR (1) | KR20220166355A (en) |
CN (1) | CN114830133A (en) |
AU (1) | AU2021259170B2 (en) |
Families Citing this family (12)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20220388162A1 (en) * | 2021-06-08 | 2022-12-08 | Fanuc Corporation | Grasp learning using modularized neural networks |
US11809521B2 (en) * | 2021-06-08 | 2023-11-07 | Fanuc Corporation | Network modularization to learn high dimensional robot tasks |
KR20230037417A (en) | 2021-09-09 | 2023-03-16 | 삼성에스디에스 주식회사 | Method and apparatus for augmenting text data |
US20230281443A1 (en) * | 2022-03-01 | 2023-09-07 | Insilico Medicine Ip Limited | Structure-based deep generative model for binding site descriptors extraction and de novo molecular generation |
KR20230138314A (en) * | 2022-03-23 | 2023-10-05 | 주식회사 Lg 경영개발원 | An artificial intelligence apparatus for detecting defective products based on product images and method thereof |
KR20230138335A (en) * | 2022-03-23 | 2023-10-05 | 주식회사 Lg 경영개발원 | An artificial intelligence apparatus for detecting defective products based on product images and method thereof |
CN114490950B (en) * | 2022-04-07 | 2022-07-12 | 联通(广东)产业互联网有限公司 | Method and storage medium for training encoder model, and method and system for predicting similarity |
EP4273756A1 (en) * | 2022-05-06 | 2023-11-08 | Robert Bosch GmbH | Computer implemented method and apparatus for unsupervised representation learning |
CN115410088B (en) * | 2022-10-10 | 2023-10-31 | 中国矿业大学 | Hyperspectral image field self-adaption method based on virtual classifier |
CN115631798B (en) * | 2022-10-17 | 2023-08-08 | 哈尔滨工业大学(深圳)(哈尔滨工业大学深圳科技创新研究院) | Biomolecule classification method and device based on graph contrast learning |
WO2024091325A1 (en) * | 2022-10-25 | 2024-05-02 | Qualcomm Incorporated | Purified contrastive learning for lightweight neural network training |
CN115544260B (en) * | 2022-12-05 | 2023-04-25 | 湖南工商大学 | Contrast optimization coding and decoding method for text emotion analysis |
Family Cites Families (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10115032B2 (en) | 2015-11-04 | 2018-10-30 | Nec Corporation | Universal correspondence network |
US10621747B2 (en) * | 2016-11-15 | 2020-04-14 | Magic Leap, Inc. | Deep learning system for cuboid detection |
US20200090039A1 (en) * | 2017-07-17 | 2020-03-19 | Google Llc | Learning unified embedding |
US10671888B1 (en) * | 2017-12-14 | 2020-06-02 | Perceive Corporation | Using batches of training items for training a network |
US10832062B1 (en) * | 2018-09-28 | 2020-11-10 | Zoox, Inc. | Image embedding for object tracking |
US10922574B1 (en) * | 2018-12-10 | 2021-02-16 | Zoox, Inc. | Bounding box embedding for object identifying |
-
2021
- 2021-04-12 JP JP2022564040A patent/JP2023523726A/en active Pending
- 2021-04-12 CN CN202180007180.4A patent/CN114830133A/en active Pending
- 2021-04-12 EP EP21723497.0A patent/EP4121907A1/en active Pending
- 2021-04-12 AU AU2021259170A patent/AU2021259170B2/en active Active
- 2021-04-12 US US17/920,623 patent/US20230153629A1/en active Pending
- 2021-04-12 KR KR1020227039608A patent/KR20220166355A/en unknown
- 2021-04-21 US US17/235,992 patent/US11347975B2/en active Active
Also Published As
Publication number | Publication date |
---|---|
EP4121907A1 (en) | 2023-01-25 |
US20210326660A1 (en) | 2021-10-21 |
JP2023523726A (en) | 2023-06-07 |
AU2021259170A1 (en) | 2022-11-17 |
US20230153629A1 (en) | 2023-05-18 |
US11347975B2 (en) | 2022-05-31 |
KR20220166355A (en) | 2022-12-16 |
AU2021259170B2 (en) | 2024-02-08 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN114830133A (en) | Supervised contrast learning with multiple positive examples | |
US11386302B2 (en) | Systems and methods for contrastive learning of visual representations | |
Jalilian et al. | Iris segmentation using fully convolutional encoder–decoder networks | |
US20190303535A1 (en) | Interpretable bio-medical link prediction using deep neural representation | |
Papa et al. | Efficient supervised optimum-path forest classification for large datasets | |
GB2547068B (en) | Semantic natural language vector space | |
CN111008688B (en) | Neural network using in-loop data augmentation during network training | |
CN109766557B (en) | Emotion analysis method and device, storage medium and terminal equipment | |
JP2018513507A (en) | Relevance score assignment for artificial neural networks | |
CN116686017A (en) | Time bottleneck attention architecture for video action recognition | |
WO2021216310A1 (en) | Supervised contrastive learning with multiple positive examples | |
US20220319233A1 (en) | Expression recognition method and apparatus, electronic device, and storage medium | |
Bharadwaj et al. | Pattern recognition and machine learning | |
Sharma et al. | Deep eigen space based ASL recognition system | |
WO2022035942A1 (en) | Systems and methods for machine learning-based document classification | |
Li et al. | Radar-based human activity recognition with adaptive thresholding towards resource constrained platforms | |
JP7188856B2 (en) | Dynamic image resolution evaluation | |
Passalis et al. | Deep supervised hashing using quadratic spherical mutual information for efficient image retrieval | |
Meedeniya | Deep Learning: A Beginners' Guide | |
Ma et al. | Denoised labels for financial time series data via self-supervised learning | |
Fonseca et al. | Research trends and applications of data augmentation algorithms | |
Pal et al. | A deep learning model to detect foggy images for vision enhancement | |
Blot et al. | SHADE: SHAnnon DEcay information-based regularization for deep learning | |
US11928185B2 (en) | Interpretability analysis of image generated by generative adverserial network (GAN) model | |
US20240152749A1 (en) | Continual learning neural network system training for classification type tasks |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination |