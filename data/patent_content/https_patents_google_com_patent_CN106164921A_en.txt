CN106164921A - The spokesman utilizing colocated information verifies - Google Patents
The spokesman utilizing colocated information verifies Download PDFInfo
- Publication number
- CN106164921A CN106164921A CN201580018671.3A CN201580018671A CN106164921A CN 106164921 A CN106164921 A CN 106164921A CN 201580018671 A CN201580018671 A CN 201580018671A CN 106164921 A CN106164921 A CN 106164921A
- Authority
- CN
- China
- Prior art keywords
- user
- spokesman
- user equipment
- model
- mark
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/30—Authentication, i.e. establishing the identity or authorisation of security principals
- G06F21/31—User authentication
- G06F21/32—User authentication using biometric data, e.g. fingerprints, iris scans or voiceprints
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/08—Speech classification or search
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/08—Speech classification or search
- G10L15/18—Speech classification or search using natural language modelling
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L17/00—Speaker identification or verification
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L17/00—Speaker identification or verification
- G10L17/06—Decision making techniques; Pattern matching strategies
- G10L17/12—Score normalisation
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L17/00—Speaker identification or verification
- G10L17/20—Pattern transformations or operations aimed at increasing system robustness, e.g. against channel noise or different working conditions
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L17/00—Speaker identification or verification
- G10L17/22—Interactive procedures; Man-machine interfaces
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L17/00—Speaker identification or verification
- G10L17/22—Interactive procedures; Man-machine interfaces
- G10L17/24—Interactive procedures; Man-machine interfaces the user being prompted to utter a password or a predefined phrase
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L19/00—Speech or audio signals analysis-synthesis techniques for redundancy reduction, e.g. in vocoders; Coding or decoding of speech or audio signals, using source filter models or psychoacoustic analysis
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L63/00—Network architectures or network communication protocols for network security
- H04L63/08—Network architectures or network communication protocols for network security for authentication of entities
- H04L63/0861—Network architectures or network communication protocols for network security for authentication of entities using biometrical features, e.g. fingerprint, retina-scan
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04W—WIRELESS COMMUNICATION NETWORKS
- H04W12/00—Security arrangements; Authentication; Protecting privacy or anonymity
- H04W12/06—Authentication
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F2221/00—Indexing scheme relating to security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F2221/21—Indexing scheme relating to G06F21/00 and subgroups addressing additional information or applications relating to security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F2221/2111—Location-sensitive, e.g. geographical location, GPS
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/08—Speech classification or search
- G10L2015/088—Word spotting
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/22—Procedures used during a speech recognition process, e.g. man-machine dialogue
- G10L2015/223—Execution procedure of a spoken command
Abstract
For identifying the mthods, systems and devices of user in a multi-user environment, including coding computer program on computer-readable storage medium.A kind of including in method is received, by first user equipment, the audio signal encoding language, first spokesman's model of the first user for first user equipment is obtained by first user equipment, obtained for second spokesman's model of the second user for the second user of the second subscriber equipment positioned with first user equipment collaboration by first user equipment or to indicate described language be the second mark of the corresponding probability said by the second user, and determined that language is said by first user by first user equipment utilization (i) the first spokesman model and second spokesman's model or (ii) first spokesman's model and the second mark.
Description
Technical field
This specification relates to spokesman's checking (speaker verification).
Background technology
In voice-enabled environment (such as family or automobile), user may utilize speech input access information or controls each
Plant function.These information and function can be for given user individuals.In a multi-user environment, identify in the middle of a group spokesman
Given spokesman can be favourable.
Summary of the invention
This specification relates to by verifying that system provides more information to strengthen spokesman and verifies system to spokesman.Example
As, some spokesman verifies system to relate to continuously and listens attentively to predetermined phrase to wake up calculating equipment up, generally performing to locate further
Reason and/or reception more users input, such as voice command and inquiry.Such spokesman verifies that system can be distinguished from equipment
In the user of one group of registration and unknown, the language to predefined phrase of unregistered user.In typical scene, specific
Calculating equipment any language of predefined phrase that detection is said close to the people of equipment by position relative close, these people are such as
Group in meeting room or other diners on table side.In some cases, these people can use send out compatible with its equipment
Speech people verifies system.By utilizing colocated (co-location) information, the spokesman associated with each equipment verifies system
Language can be detected said by the registration user of relevant device or (such as, acted as fraudulent substitute for a person by another user of close proximity
Person (imposter)) say, and this information can be used for improving spokesman and verifies decision.
It is said that in general, the theme described in this manual novel aspects can be embodied in and include following action
In method: received the audio signal that language is encoded by first user equipment, first user equipment obtain for first
First spokesman's model of the first user of subscriber equipment, is positioned for first user equipment collaboration by first user equipment
The second corresponding user of the second subscriber equipment obtain for second spokesman's model of the second user or instruction language be by the
Second mark of the corresponding probability that two users say, and by first user equipment utilization (i) the first spokesman model and
Second spokesman's model or (ii) first spokesman's model and the second mark determine that language is said by first user.The party
Other embodiments in face include computer system, device and the record of the correspondence meter on one or more computer memory devices
Calculation machine program, described computer system, device and computer program are each configured to perform the action of described method.One or
Multiple system for computer can be by making the software of system execution action, firmware, hardware or combinations thereof in operation
Install and be configured to perform specific operation or action on the system.One or more computer programs can be configured to rely on
Including making the instruction of described device execution action to perform specific operation or action when being performed by data processing equipment.
It is said that in general, the theme described in this manual novel aspects can be embodied in and include following action
In method: received the audio signal that language is encoded by first user equipment, first user equipment obtain for first
First spokesman's model of the first user of subscriber equipment, is positioned for first user equipment collaboration by first user equipment
Each in other users multiple of other subscriber equipmenies obtains the spokesman's model for each relative users or instruction words
Language is the mark of the corresponding probability said by relative users, and by first user equipment utilization (i) the first spokesman mould
Type and other spokesman's models multiple or (ii) first spokesman's model and multiple mark determine that language is to be said by first user
Go out.Other embodiments of this aspect include that computer system, device and the record of correspondence are in one or more Computer Storage
Computer program on equipment, described computer system, device and computer program are each configured to perform described method
Action.One or more system for computer can be by making the software of described system execution action, firmware, hard in operation
Part or combinations thereof are installed on the system and are configured to perform specific operation or action.One or more computer journeys
Sequence can be configured to by including that the instruction making described device execution action when being performed by data processing equipment is to perform specific behaviour
Make or action.
It is said that in general, the theme described in this manual novel aspects can be embodied in and include following action
In method: received the audio signal that language is encoded by first user equipment, first user equipment determine for first
First spokesman's model of the first user of subscriber equipment, is determined storage use on the first user device by first user equipment
In with other people one or more second spokesman's models of first user equipment collaboration location, and can being set by first user
For utilizing first spokesman's model and second spokesman's model to determine that language is said by first user.Other of this aspect are real
Execute example and include computer system, device and the record of the correspondence computer program on one or more computer memory devices,
Described computer system, device and computer program are each configured to perform the action of described method.One or more calculating
The system of machine can be installed by making the software of described system execution action, firmware, hardware or combinations thereof in operation
It is configured on the system perform specific operation or action.One or more computer programs can be configured to by including
Make the instruction of described device execution action to perform specific operation or action when being performed by data processing equipment.
It is said that in general, the theme described in this manual novel aspects can be embodied in and include following action
In method: receive, by least one computer, audio signal that language is encoded, by least one computer for
Each in two or more subscriber equipmenies obtains the corresponding spokesman's mould to the relative users for respective user equipment
The identification of type, utilizes the spokesman's model identified to determine that language is by subscriber equipment by least one computer
Specific user says.Other embodiments of this aspect include that computer system, device and the record of correspondence are one or more
Computer program on computer memory device, described computer system, device and computer program are each configured to perform
The action of described method.One or more system for computer can be by making the soft of described system execution action in operation
Part, firmware, hardware or combinations thereof are installed on the system and are configured to perform specific operation or action.One or many
The instruction that individual computer program can be configured to by including making when being performed by data processing equipment described device execution action comes
Perform specific operation or action.
It is said that in general, the theme described in this manual novel aspects can be embodied in and include following action
In method: received the audio signal that language is encoded by first user equipment, first user equipment obtain instruction language
The first mark of the probability said by the first user of first user equipment, by first user equipment for first user
The second corresponding user of the second subscriber equipment of equipment collaboration location obtain instruction language be by the second user say corresponding
The second mark of probability, first user equipment determine the first mark and the combination of the second mark, by first user equipment
The combination utilizing the first mark and the second mark comes normalization the first mark and the second mark, and by first user equipment utilization
Normalized first mark and normalized second mark determine that language is said by first user.
Aforementioned and other embodiments each can include in following features the most alone or in combination
Or it is multiple.By first user equipment for second user corresponding with the second subscriber equipment that first user equipment collaboration positions
Obtain for second spokesman's model of the second user or instruction language is the of the corresponding probability said by the second user
Two marks comprise the steps that by first user equipment for the physical region being co-located near the physical location of first user equipment
In the second subscriber equipment second user obtain for the second user second spokesman's model or instruction language be by second
Second mark of the corresponding probability that user says.Described method can include in response to determining that language is to be sent by first user
Execution action.Described method can include analyzing the order that audio signal is included in language with identification, and execution is right with order
The action answered.Described method can include the part by first user equipment utilization audio signal and first spokesman's model generation
Instruction language is the first mark of the probability said by first user.Described method can include the first mark and the second mark
It is compared to determine highest score.Determine that language is to be may include determining whether that the first mark is best result by what first user was said
Number.
In some implementations, attached for the physical location being co-located on first user equipment by first user equipment
The second corresponding user of the second subscriber equipment near physical region obtains second spokesman's model for the second user
Or instruction language is that the second mark of the corresponding probability said by the second user comprises the steps that and obtained the by first user equipment
Two spokesman's models, and by the part of first user equipment utilization audio signal and second spokesman's model generation second point
Number.
In some implementations, attached for the physical location being co-located on first user equipment by first user equipment
The second corresponding user of the second subscriber equipment near physical region obtains second spokesman's model for the second user
Or instruction language is that the second mark of the corresponding probability said by the second user comprises the steps that and determined the by first user equipment
Two subscriber equipmenies are positioned in the physical region near the physical location of first user equipment, first user equipment determine the first use
Family equipment has the setting allowing first user equipment to access second spokesman's model, first user equipment receive the second speech
Human model, and by the part of first user equipment utilization audio signal and second spokesman's model generation the second mark.By
First user equipment receives second spokesman's model and can include being stored on the first user device by first user equipment identification
One or more 3rd spokesman's models, and determined that the subset of the 3rd spokesman's model can include second by first user equipment
Spokesman's model.Described method can include being removed from first user equipment by first user equipment being not included in the 3rd spokesman's mould
The 3rd spokesman's model in the subset of type.Received second spokesman's model by first user equipment can include being set by first user
Standby memory search the second spokesman model from first user equipment.Generated the second mark by first user equipment can include
By first user equipment utilization storage second spokesman's model on the first user device and a part for audio signal not
The second mark is generated from another user equipment requests the second spokesman model.Second spokesman's mould is received by first user equipment
Type can include being received second spokesman's model by first user equipment from server.Second subscriber equipment can include the second spokesman
Model.Received second spokesman's model by first user equipment can include being received the by first user equipment from the second subscriber equipment
Two spokesman's models.
In some implementations, by first user equipment for the thing being positioned near the physical location of first user equipment
The second corresponding user of the second subscriber equipment in reason region obtains the second spokesman's model or instruction for the second user
Language is that the second mark of the corresponding probability said by the second user comprises the steps that and determined the second user by first user equipment
Equipment is positioned in the physical region near the physical location of first user equipment, and is received second point by first user equipment
Number.Received the second mark by first user equipment can include being received the second mark by first user equipment from the second subscriber equipment.
Received the second mark by first user equipment can include being received the second mark by first user equipment from server.Described method can
Including being determined the device identifier for the second subscriber equipment by first user equipment, and by first user equipment, equipment is known
Fu not be supplied to server, wherein first user equipment receives second in response to identifier is supplied to server from server
Mark.
In some implementations, described method can include being determined storage on the first user device by first user equipment
For can be located at other people one or more 3rd in the physical region near the physical location of first user equipment
Speech human model, and by first user equipment utilization (i) the first spokesman model, second spokesman's model and the 3rd spokesman's mould
Type or (ii) first spokesman's model, the second mark and the 3rd spokesman's model determine that language is said by first user.
Described method can include the part by first user equipment utilization audio signal and first spokesman's model generation instruction language
It is the first mark of the probability said by first user, by first user equipment for each in the 3rd spokesman's model
Utilize a part for corresponding 3rd spokesman's model and audio signal to generate corresponding 3rd mark, and by first user
Equipment compares the first mark, the second mark and the 3rd mark to determine highest score.Described method can include being set by first user
For determining that the 3rd subscriber equipment is positioned in the physical region near the physical location of first user equipment for the 3rd subscriber equipment
Frequency, first user equipment determine whether described frequency meets threshold frequency, and by first user equipment in response to really
Fixed described frequency meets threshold frequency and the 3rd spokesman's model being used for the 3rd user of the 3rd subscriber equipment is stored in the
In three spokesman's models.Described method can include being received identification the 3rd spokesman's model by first user equipment from first user
Input, and by first user equipment in response to from user receive identify the 3rd spokesman's model input and by the 3rd
Speech human model is stored in the 3rd spokesman's model.
In some implementations, described method can include by each in subscriber equipment of at least one computer
Individual from the corresponding subscriber equipment corresponding spokesman's model of reception.Described method can include by least one computer for
Each in the equipment of family utilizes and identifies corresponding of retrieval from the memorizer being included at least one computer accordingly
Speech human model.
In some implementations, described method can include being determined that normalized first mark meets by first user equipment
Threshold value, wherein determines that language is to be determined that normalized first mark meets threshold value by being in response to of saying of first user
's.Described method can include averagely being unsatisfactory for threshold value, wherein by what first user equipment determined the first mark and the second mark
Determine that what the combination of the first mark and the second mark was in response to determine the first mark and the second mark is averagely unsatisfactory for threshold value
's.Described method can include being determined that the first mark and the second mark neither meet threshold value, wherein by first user equipment
Determine that the combination of the first mark and the second mark is in response to determine that the first mark and the second mark neither meet threshold value
's.Described method can include being determined that the first mark is unsatisfactory for threshold value by first user equipment, wherein determines the first mark and
The combination of two marks is in response to determine that the first mark is unsatisfactory for threshold value.
The theme described in this manual can realize in a particular embodiment so that realize in following advantages one
Or it is multiple.In some implementations, the use to forger spokesman's model can reduce user device responsive in by not
It it is the action of the language that other people of user of subscriber equipment say.In some implementations, when using forger to send out
During speech human model, system can reduce wrong report and reach 6%-8%.In some implementations, system may utilize and works in coordination with for different
The combination of the mark of location spokesman carrys out normalization ultimatum language mark.
Illustrate the one or more embodiments of the detail of the theme of this specification in the the accompanying drawings and the following description.According to retouching
State, drawings and claims, other features, aspect and the advantage of described theme will be apparent from.
Accompanying drawing explanation
Figure 1A-1C is shown in which that one or more subscriber equipment A-D analyzes the audio signal encoding language
The example of environment.
Fig. 2 is the example that spokesman verifies system.
Fig. 3 is for determining that whether language is the flow chart of the process said by user.
Fig. 4 is the block diagram calculating equipment that can be used for realizing the system and method described in the document.
The most same reference number and name instruction identical element.
Detailed description of the invention
Spokesman verify system can include listening attentively to predefined phrase continuously in case wake up up calculating equipment, generally perform into
One step processes and/or receives the process of more users input (such as voice command and inquiry).Such spokesman verifies system
Can distinguish from the user of in equipment one group registration and from unknown, unregistered user to hot word (hotword)
Language.
Registration relate to user the most sample utterance has been supplied to system with create can be used for by he or she with known or
The unknown separate model in other user areas.Spokesman's proof procedure can relate to by the model that creates for given language with for
The model that spokesman (or multiple spokesman) creates compares, and determines it is to accept or refusal words based on similarity thresholding
Language.
Spokesman verifies that system has applicability in the field of wide scope, and the performance also with wide scope is wanted
Ask especially for identifying that quality and forger prevent effectiveness aspect.Such as, for the spokesman of unlocker device
Checking system be used in trust environment when system in the most unlocked equipment time compared with, can have higher requirement provides
The low mistake of forger is accepted (false acceptance), and in trust environment, mistake acceptance can not be strictly to prop up
Hold relatively low False Rejects (user of nonrecognition registration).
The information only having the spokesman registered from (one or more) provide when checking system performs accepting or refusing
When giving absolutely the decision of language, due to unbounded, therefore proof procedure meeting on the collective entity of unknown possible forger
It is challenging.This language that may result in from unknown spokesman will have high probability to exceed the spokesman for registration
Similarity thresholding, thus cause mistake to accept.This challenge is even more important for mobile device, wherein in mobile device
The availability of possible forger around is constantly increasing and changes.
Can be by verifying that system provides more information to improve these systems to spokesman.Specifically, by utilize by
The colocated information that general available API (its can Already in mobile device/platform in) provides, on each device
Checking system can detect near whether there is possible forger.Such information can be used for adjusting similarity door
Limit, and also share spokesman's model of its registration to improve checking decision.In some instances, system may utilize for assisting
The normalization mark for one or more spokesman's models is carried out with the combination of the mark of the spokesman of location.Such as, Yong Hushe
Standby available storage spokesman's model on a user device and spokesman's model of receiving from other subscriber equipmenies are to generate phase
The mark answered, the combination determining mark also utilize this each mark of combination normalization.
Such as, subscriber equipment can generate relatively low mark due to background noise for language, and such as, mark can be with the back of the body
Scape noise proportionally reduces.Under conditions of height is noisy (such as, the vehicle run or the many dining room of people), for using by oneself
The mark of the language of the user of family equipment is unsatisfactory for threshold value (such as, this mark is less than or equal to accepting thresholding) and is possible to
, and may be refused mistakenly.Normalization to mark can reduce noise cost.Such as, owing to each utilizing difference
Spokesman's model generation multiple marks be averagely unsatisfactory for accept thresholding, such as, this is averagely less than or equal to accepting thresholding,
Therefore normalization will cause the improvement to each mark, so that for the mark of user of subscriber equipment it suffices that accept door
Limit, is greater than accepting thresholding.
Owing to such checking system may have access to the model of possible forger, therefore these systems are assumed another's name wherein
The language of faitour obtains according to the user of registration in the case of being higher than the similarity scores accepting thresholding, can preferably refuse
Some language (such as, reducing false acceptance rate) absolutely.Such as, if language is according to the model (example in " forger " set
As, create according to the user of colocated) in one there is equal or higher mark, then system may be assumed that this language very
Possible from forger and refuse it.This method can with various types of spokesman's models (such as, i-to
Amount, d-vector etc.) compatible.
Can there are ways to determine when equipment is co-located in given geographic area.Such as, this information can be with source
From global positioning system (GPS), near-field communication (NFC), bluetooth, secondary sound audio (Subsonic audio) and/or other sensings
One or more in device and technology.In some instances, co-located devices can associate virtually, such as, sets when described
When standby participation same phone or video conference.In these examples, described equipment or server may utilize calendar, electronics postal
Part or text message or other " soft " concepts determine colocated.
When not all user all have correspondence subscriber equipment time, multiple users can also colocated in same area
In, but some in subscriber equipment include the spokesman's model for those users.Such as, when five friends rising at them
When in room one and in these friends two have its mobile device, the first mobile device can include for not with
Body has spokesman's model of three friends of mobile device and the first and second mobile devices can utilize these spokesman's moulds
Type and which determining in friend to have said particular utterance to for having spokesman's model of the friend of equipment.
In example implementations, spokesman verifies that system receives the audio signal encoding language and determines
Whether the mark utilizing spokesman's model generation meets threshold score value.When spokesman verifies that system is merely with for specific user
During single spokesman's model of the specific user of equipment, spokesman verifies that system can be by another user (such as, brother of this user
Younger brother) language said generates the mark meeting threshold score value.
Spokesman verify system utilize multiple spokesman's model (such as, one for this user another for this use
The brother at family) increase spokesman and verify the accuracy of system.Such as, spokesman verifies that system is the sound encoding language
Frequently signal generates two marks, and one for this user, another mark is used for his brother.Spokesman verifies systematic comparison
The two mark (the two mark can all meet threshold score value) is the highest to determine which mark.Utter a word from as different people
Language (such as when spokesman's model of the people different for this will be used for generating highest score) is compared, and spokesman verifies
System most possibly utilizes spokesman's model generation highest score of the specific user for saying language.
When spokesman verifies that system determines that the mark for this user (such as, utilizes the spokesman's model for this user
Generate mark) the highest time, then this specific subscriber equipment may be in response to language to perform action.When spokesman verifies that system is true
The mark (such as, utilizing the mark of spokesman's model generation of the brother for this user) of the fixed brother for this user is the highest
Time, then action do not taked by this specific subscriber equipment.
Spokesman verifies that system may utilize in the physical region near special user equipment (such as, with described spy
Determine subscriber equipment colocated) other users other spokesman's models or from these other subscriber equipmenies receive mark
Determine which mark is the highest and whether described special user equipment should respond in language execution action.Spokesman verifies system
System can be in the upper execution of particular device or another equipment (such as, server).
Figure 1A-1C is shown in which that one or more subscriber equipment A-D 102a-d analyzes the sound encoding language
Frequently the example of the environment 100 of signal.Subscriber equipment A-D 102a-d may utilize the one in multiple algorithms of different and determines it is words
Language in response to language execution action, or should may be talked about for that said by the corresponding user of subscriber equipment and subscriber equipment
That said and subscriber equipment can not be led by corresponding user in language should not take action.
Such as, four colleagues can be in meeting room, and " well, the first colleague (such as, user D) can send order
Google, please start to demonstrate (Okay Google, please start the demo) ".The available bag of subscriber equipment A 102a
Include the spokesman model A1024a of user A for subscriber equipment A 102a and for other spokesman's models of other users
Multiple spokesman's model analysis audio signals, other users described the most sometimes or often in user A or subscriber equipment A
In the physical region that 102a is identical.Other spokesman's models can be stored in the memorizer of subscriber equipment A 102a and continue in short-term
Between section (such as, when subscriber equipment A 102a is recently from the requested specific spokesman's model of another subscriber equipment B-D 102b-d)
Or for a long time section (such as, when other user's high probabilities described be in the physical region identical with subscriber equipment A102a
Time).
Subscriber equipment A 102a determines for the mark of each in spokesman's model and determines from multiple marks
Balloon score.Subscriber equipment A 102a can such as by described in being compared to described highest score and threshold score value to determine
Balloon score whether meets threshold score value and whether to have highest score described in high probability be for subscriber equipment A 102a
User A.If described highest score is unsatisfactory for threshold score value, then subscriber equipment A 102a can not take further
Action, and determine that described language is to be said by the user its subscriber equipment A 102a to without spokesman's model.
When subscriber equipment A 102a determine described highest score be the user A for subscriber equipment A 102a (such as, really
Surely the first colleague sending described order is user A) time, subscriber equipment A 102a is in response to the reception execution to this audio signal
Action.Such as, subscriber equipment A 102a can initiate the demonstration of request.
When subscriber equipment A 102a determine described highest score be not for user A and first colleague be not user A
Time, subscriber equipment A 102a can not take further action for described audio signal.Such as, subscriber equipment A 102a can accompany
Receive another audio signal with another language said by the first colleague and do not take action in response to another language described.
In some instances, when subscriber equipment A-D 102a-d includes that identical or compatible spokesman verifies system, use
Each in the device A-D 102a-d of family can share the information about its corresponding user, such as spokesman's model, or about
Information to the analysis of the audio signal encoding language, such as mark.Such as, as shown in Figure 1A, the first colleague (such as, uses
Family D) language 106 " getting well, Google, demonstration please be start " can be said, and in each in subscriber equipment A-D 102a-d
Mike can capture and represent the signal of described language and described language is encoded into audio signal.
It is corresponding that each in subscriber equipment A-D 102a-d utilizes corresponding spokesman model A-D 104a-d to analyze
To generate, audio signal represents that the corresponding user A-D of subscriber equipment says the mark of the probability of language 106, such as institute in Figure 1B
Show.In this example, subscriber equipment A 102a is the mark that user A generates 0.76, and subscriber equipment B 102b is that user B generates
The mark of 0.23, subscriber equipment C 102c is the mark that user C generates 0.67, and subscriber equipment D 102d is that user D generates
The mark of 0.85.
Each in subscriber equipment A-D 102a-d shares respective mark with other subscriber equipmenies.Such as, Yong Hushe
Standby A-D 102a-d may utilize one or more sensor (such as GPS, NFC, bluetooth, secondary sound audio or any other is suitable
Technology) determine other subscriber equipmenies in the region being physically located near corresponding subscriber equipment.Subscriber equipment A-D
102a-d can determine that whether instruction subscriber equipment can be shared the access of its mark with another subscriber equipment and arrange, and can be the most true
Whether this another subscriber equipment fixed utilizes identical spokesman to verify system, and available described mark, or both.
All of mark is compared to each other to determine and is set by corresponding user by each in subscriber equipment A-D 102a-d
Whether the standby mark generated is highest score and whether corresponding subscriber equipment should perform action in response to language 106.Example
As, as is shown in fig. 1 c, subscriber equipment D 102d determines with the spokesman model D of the user D for subscriber equipment D 102d
The mark that 104d generates be the highest and language 106 be the probability said by user D be to be set by other users more than language 106
The probability that other users of standby A-C 102a-c say.Subscriber equipment D 102d can perform the action corresponding with language 106, example
As initiated the demonstration 108 of request.Highest score and threshold score value can be compared to guarantee to exist by subscriber equipment D 102d
Language described in high probability is by user D rather than by being such as not received by the another of mark for its subscriber equipment D 102d
One user says.
Similarly, each in other subscriber equipmenies A-C 102a-c determine its corresponding mark be not maximum and
Other subscriber equipmenies corresponding should not take action.Before determining that its corresponding mark is not maximum mark, other are used
Each in the device A-C 102a-c of family can be by highest score and threshold score value (such as, specific to corresponding subscriber equipment)
Compare to guarantee at least to exist between in described language and described spokesman's model the similarity of minimum and
Guarantee that described language is not by another use its other subscriber equipment A-C 102a-c to without corresponding spokesman's model
Family is said.When highest score is to receive from another subscriber equipment, other subscriber equipmenies A-C 102a-c it is known that
Or can not know about the user corresponding with highest score, subscriber equipment or the information of both.Such as, subscriber equipment A-
Mark can be sent to other subscriber equipmenies by each in D 102a-d, and any without such as user or subscriber equipment
Identification information.In some instances, the identifier one of the user that mark and this mark can be generated by subscriber equipment for it
Rise and send.
Fig. 2 is the example that spokesman verifies system 200.One or more subscriber equipment A-B 202a-b or server 204
The audio signal (such as, representing the data of the attribute of language) that language is encoded can be analyzed and most possibly say institute to determine
State the user of language.Two or more combination in subscriber equipment A-B 202a-b, server 204 or these equipment can profit
By spokesman's model analysis audio signal, it is compared with the different analysis to audio signal that spokesman's model determines, and
Determine whether specific user has said described language.
Such as, each in subscriber equipment A-B 202a-b includes the spokesman model A-B for its corresponding user
206a-b.Any suitable method can be utilized to generate spokesman model A-B 206a-b for specific user, described suitable
Method such as makes each user say registration phrase, the most such as from key word sample extraction mel-frequency cepstrum coefficient (mel-
Frequency cepstral coefficient, MFCC) feature, and utilize these features as the reference compared in the future,
And/or utilize the expression to the language said by specific user to train neutral net.
Spokesman authentication module A 208a utilizes the spokesman model A 206a of the user A for subscriber equipment A 202a to come
Determine that particular utterance is the probability said by user A.Such as, spokesman's authentication module A 208a receives coding particular utterance
Audio signal (such as, the expression of audio signal), and utilize spokesman model A 206a to generate the described particular utterance of expression
It it is the mark of the probability said by user A.
Spokesman authentication module A 208a may utilize be stored on subscriber equipment A 202a one or more and acts as fraudulent substitute for a person
Person spokesman model 210a to generate for each in forger spokesman model 210a to represent described particular utterance
It it is the mark of the probability said by the corresponding user corresponding with specific forger spokesman's model.Such as, user
Device A 202a can receive described audio signal, determines that subscriber equipment B 202b is positioned at the physical location of subscriber equipment A 202a attached
In near physical region (such as, in the same room), and from subscriber equipment B 202b or from server 204 request be used for
Spokesman's model (such as, spokesman's Model B 206b) of the user of family equipment B 202b.Such as, subscriber equipment A can will be used for
The device identifier of subscriber equipment B 202b or for the identifier of user B as one of the request to spokesman's Model B 206b
Part is sent to such as server 204.Subscriber equipment A 202a using spokesman's Model B 206b as forger spokesman
In memory and spokesman authentication module 208a is for forger spokesman's model for a storage in model 210a
Each in 210a generates mark.
Forger spokesman model 210a can include near the physical location for can be at subscriber equipment A 202a
Physical region (such as, part of same room, corridor or footpath or road etc.) in the speech of other users
Human model.Forger spokesman's model can include for being in continually identical with user A or subscriber equipment A 202a
Spokesman's model of the user's (such as, utilizing historical data to be determined) in physical region.Such as, subscriber equipment A 202a can
Determine that about four hours (such as, the subscriber equipment C) every workday of another subscriber equipment is in identical with subscriber equipment A 202a
Physical region in, and the persistent period of four hours this every days more than at three hours every day the thresholding persistent period (such as,
Specific to working day, average persistent period every day etc.), and should be by for spokesman's MODEL C of the user C of subscriber equipment C
It is stored in forger spokesman model 210a, such as, until user A asks from forger spokesman model 210a
In remove spokesman's MODEL C or persistent period every day for subscriber equipment C no longer meets the thresholding persistent period.Only lift several example
Son, frequency can be occurrence, such as one day four hours, or is percentage ratio, such as subscriber equipment A 202 detect specific its
The time of his subscriber equipment 5 percent or be detected as other users of other subscriber equipmenies specific by subscriber equipment A 202
The 10 of the total quantity of equipment.
In some instances, user A can recognize that subscriber equipment A 202a should be included into forger spokesman
One or more spokesman's models in model 210a.Such as, subscriber equipment A 202a can receive on subscriber equipment A 202a
The input of another spokesman's model is trained for the kinsfolk of user A or friend.Described input can such as indicate this another speech
Human model should be forger spokesman's model, and be for be not the user of subscriber equipment A 202a, user A it
Spokesman's model of outer user.This another spokesman's model can be used for the physical areas around often in subscriber equipment A 202a
Another user (such as, the child of user A) in territory, to be reduced or eliminated by subscriber equipment A 202a in response to this another user
The language said and the action performed, unless subscriber equipment A 202a separately has programming.
Such as, spokesman model A 206a is utilized to generate the first mark and for assuming another's name as spokesman authentication module 208a
When each in faitour spokesman model 210a generates corresponding second mark, spokesman authentication module 208a is relatively more described
Mark is to determine highest score.When highest score is to utilize spokesman model A 206a to generate, spokesman's authentication module
208a determines that user A says particular utterance and subscriber equipment A 202a can take suitable action, such as, sound identification module
212a can analyze particular utterance and be included in the order in this particular utterance to identify.
In one example, a clan member that may be used for user A in forger spokesman's model, example
As, when two in clan member have similar speech.Spokesman authentication module 208a can be by utilizing corresponding speech
A language said in human model analysis brother generates the first mark in user A and for its brother second point
Number.Spokesman authentication module 208a compares the two mark to determine which mark is bigger, each in said two mark
All can more than threshold score and single all by otherwise trigger subscriber equipment A 202a action (such as, due to spokesman's mould
The similarity of type).When the first mark for user A is more than the second mark, subscriber equipment A 202 is such as based on described language
Execution action, and described action can be determined in part with sound identification module 212a.As the brother for user A the
When two marks are more than the first mark, subscriber equipment A 202 does not the most take further action, and in response to described particular utterance
Do not perform action.
Some in forger spokesman model 210a can special time in one day, during specific several days,
At ad-hoc location, or the combination of in these two or more is utilized.Such as, when subscriber equipment A 202a is at user A
Kinsfolk house in time, subscriber equipment A 202a such as can use emit for living in the people in the house of kinsfolk
Name faitour spokesman's model, and unless the colocated subscriber equipment of detect in these people one, do not use
These forger spokesman's models.
In some instances, subscriber equipment A-B 202a-b may utilize the storage 214a-b that arranges in memory and determines
Corresponding spokesman's model or utilize the mark of corresponding spokesman's model generation whether can be provided (such as, to utilize wireless
Communication channel 216, such as, utilize the channel that near-field communication creates) to other subscriber equipmenies.Such as, subscriber equipment A 202a can connect
Receive specific language, determine that subscriber equipment B 202b is in the physical region near subscriber equipment A 202a, and from user
Equipment B 202b asks spokesman's model, such as, is not knowing just request in the case of requested specific spokesman's model
Spokesman's Model B 206b.Subscriber equipment B 202b receives request, analysis arranges B 214b to determine whether to set with another
Standby or specific subscriber equipment A 202a shares spokesman's Model B 206b, it addition, in response to determining that subscriber equipment B 202b can
Sharing spokesman's Model B 206b, equipment B 202b utilizes radio communication channel 216 to be sent out by the copy of spokesman's Model B 206b
Deliver to subscriber equipment A 202a.
Such as, in the example when when more than one people operable unique user equipment, subscriber equipment A 202a can be for
All users of the user B or subscriber equipment B 202b of subscriber equipment B 202b ask spokesman's model.As more than one people
In example during operation subscriber equipment A 202a, spokesman model A 206b can include multiple spokesman's model.In these examples
In, spokesman authentication module 208a can generate mark for each in the user of subscriber equipment A 202a, by these marks
Compare with other marks utilizing forger spokesman model 210a to generate, and determine highest score.When the highest
When mark is in the user for subscriber equipment A 202a, subscriber equipment A 202a can perform suitable action, such as,
At least partly utilize the action that sound identification module 212a determines.
Determination to action to be performed can utilize certain types of action, the particular user of subscriber equipment A 202a
Or both carry out.Such as, first user A can have and initiates the license of any application on subscriber equipment A 202a, and second
User B can have the license of the educational applications only initiated on subscriber equipment A 202a.
In some implementations, the one or more replacements in spokesman's model are stored on subscriber equipment A 202a-b
Or it is stored on server 204 except being stored on subscriber equipment A 202a-b.Such as, server 204 can store and be used for
Spokesman's model 218 of the user A-B of subscriber equipment A-B 202a-b.In these examples, subscriber equipment A 202a or user
Equipment B 202b can receive the audio signal encoding language and by a part (example of audio signal or audio signal
As, the expression to the part of audio signal) it is supplied to server 204.Server 204 receives subscriber equipment, spokesman's model
Or the identifier of the user of subscriber equipment, and such as utilize that spokesman's identifier 220 determines in spokesman's model 218 which
Identifier that is individual and that receive is corresponding.
In some instances, server 204 receive analyze audio signal a part of time except the speech of subscriber equipment
The identifier of other spokesman's models will being utilized outside human model.Such as, determine that user sets as subscriber equipment A 202a
When standby B 202b is physically located in the region near the physical location of subscriber equipment A 202a, the available speech of server 204
People verifies that request receives audio signal and the identifier for subscriber equipment A-B 202a-b from subscriber equipment A 202a.
Server 204 can be such as together with audio signal or dividually from subscriber equipment receiving position information and sharp
With this positional information, such as utilize the positional information of other subscriber equipmenies to determine to server 204 to provide audio signal
Other subscriber equipmenies being physically located in the region near the physical location of described subscriber equipment.Server 204 can be subsequently
Determined by other spokesman's models 218 of other equipment identifications.When server 204 can be on server 204 to generate mark
Or other spokesman's models identified are utilized when spokesman's model being supplied to subscriber equipment A-B 202a-b.
Spokesman's authentication module 222 on server 204 utilizes self-supporting server 204 to provide the user of audio signal
Equipment and determined by all spokesman's models of other subscriber equipmenies generate corresponding mark, each in corresponding mark
The individual probability all representing that corresponding people has said coding particular utterance in audio signal.Spokesman's authentication module 222 can
Spokesman's model is retrieved from the memorizer being included in server 204.Spokesman's authentication module 222 can set from corresponding user
Standby reception spokesman's model.Server 204 or spokesman's authentication module 222 determine highest score and to corresponding subscriber equipment
The message indicating the user of this subscriber equipment most possibly to say this particular utterance is provided.Server 204 can be to other users
Other users that equipment provides instruction corresponding were likely not to have the message of described language.
In some instances, specific subscriber equipment provides multiple spokesman's identifier, such as, one can to server 204
Each in the user of specific subscriber equipment of individual identifier, an identifier is for closing with this specific subscriber equipment
Each in forger spokesman's model of connection, or both.Described specific subscriber equipment can include indicate for
The data of the type of the model of each in spokesman's identifier, such as user or forger.Spokesman's authentication module
Audio signal analyzed by all spokesman's models 218 that 222 spokesman's identifiers that are available and that receive are corresponding and determine will
Use which spokesman's model to generate highest score.When the model utilizing in the user of specific subscriber equipment
When generating highest score, server 204 provides to this specific subscriber equipment and indicates the user of this specific subscriber equipment
Likely say the message of described particular utterance.Described message can include the specific speech for generating described highest score
Spokesman's identifier of human model.
In some implementations, relatively low numerical value can represent that specific user said language compared with higher numerical value
Bigger probability.Such as, the higher mark of numerical value that Wei the comparison of relatively low numerical value is high.
In some instances, when subscriber equipment has multiple user, subscriber equipment or server 204 can determine that for
Specific spokesman's model of the active user of family equipment.Such as, the spokesman being used for active user can be identified by subscriber equipment
Symbol is supplied to server 204 and to indicate every other spokesman's identifier of other users for subscriber equipment be for depositing
Storage forger spokesman's model on server 204.In some instances, subscriber equipment utilizes for active user
Spokesman's model determine whether in response to audio signal being received execution action and using for its of subscriber equipment
Spokesman's model of he user is as forger spokesman's model.Subscriber equipment may utilize any suitable method and determines
The active user of subscriber equipment, such as, utilize password, user name or both be to unlock subscriber equipment and to determine active user.
In some implementations, forger spokesman's model is utilized or from another when mark for audio signal
Model generation and described mark that subscriber equipment receives are more than or equal to the utilization speech for the user of special user equipment
During the mark that human model generates, this special user equipment does not perform action in response to the reception to audio signal.Real at these
In existing mode, when two marks are identical, in response to the reception to audio signal, subscriber equipment does not the most perform action.At other
In implementation, when two marks of two users for different user devices are identical, and two marks are all best results
During number, two subscriber equipmenies corresponding with the two mark can be carried out action.When for the model on unique user equipment
Two marks be all in implementation during identical highest score, subscriber equipment can perform action or can not perform action.Example
As, when each in said two mark be the different user for subscriber equipment time, subscriber equipment can perform action.When
In mark one is that another in mark is for forger spokesman's model for user spokesman's model
Time, subscriber equipment can not perform action.
In some implementations, the quantity of other subscriber equipmenies detected, subscriber equipment adjustable thresholding are depended on
Value.Such as after receiving audio signal, when being not detected by other equipment, threshold value with restricted relatively low, and can work as inspection
When measuring other subscriber equipmenies, threshold value can be restricted higher.Threshold value can quantity based on other equipment detected become
Restricted higher (such as, linearly or index), until reaching maximum threshold.In some instances, such as utilize for
Identical language utilizes the combination of the mark that different Similarity Model generates, and can be normalized one or more marks.
Described combination can be average and or long-pending.
In some implementations, one or more can periodically detection the in subscriber equipment A-B 202a-b is in phase
Other subscriber equipmenies in the physical region near subscriber equipment answered.Such as, subscriber equipment B 202b can every five minutes, every ten
Minute or within every 30 minutes, determine whether another subscriber equipment is in the room identical with subscriber equipment B 202b.Show at some
In example, subscriber equipment B 202b is determining that subscriber equipment B 202b has remained in the time that roughly the same regional sustained is predetermined
(such as, but the user B of subscriber equipment B 202b holds subscriber equipment B 202b does not walk about or user B remains in list section
In individual room) can determine that whether another subscriber equipment is positioned at the preset distance of distance users equipment B 202b afterwards.
Subscriber equipment A-B 202a-b can include personal computer, mobile communication equipment (such as, smart phone or flat board)
With can send and receive other equipment of data by network 224, such as wearable device, such as table or temperature controller,
The utensil that TV and network connect.Network 224 (such as, LAN (WAN), wide area network (WAN), the Internet or a combination thereof) connects
Subscriber equipment A-B 202a-b and server 204.
Fig. 3 is for determining that whether language is the flow chart of the process 300 said by user.Such as, process 300 can be by
Spokesman verifies that the subscriber equipment A 202a of system 200 or server 204 use.
Described process receives the audio signal (302) encoding language.Such as, the mike on subscriber equipment receives
Audio signal and audio signal is supplied to the spokesman's authentication module on first user equipment or is supplied to server.
Described process obtains first spokesman's model (304) of the first user for first user equipment.Such as, speech
People verifies system to determine for first user equipment to there is single first user and obtain first for this first user
Speech human model.In some instances, spokesman's authentication module determines the active user for first user equipment, and obtains use
In first spokesman's model of this user, described active user currently logins first user equipment or at first user equipment
First user equipment was logined recently when lock-out state.
In some instances, spokesman's authentication module determines and there is multiple user for first user equipment and obtain use
First spokesman's model of in these users.First user equipment then can be for other user's repetitive processs 300
In one or more steps.Such as, spokesman's authentication module can repeat step 304 and 306 for each in user.
Described process utilizes a part for audio signal and first spokesman's model generation instruction language to be by first user
First mark (306) of the probability said.Such as, spokesman's authentication module of the first equipment utilize the whole of audio signal and
First spokesman's model generates the first mark.
Described audio signal can include that spokesman's authentication module of language can be compareed first spokesman's model to be carried out
Conversion relatively.Such as, the recordable language of mike and characteristic extracting module, described feature will be provided to the record of language
Extraction module generates spokesman's authentication module for generating the audio signal of the first mark.
In the implementation when there is multiple user of first user equipment, spokesman's authentication module compares for many
The mark of each in individual user and select the mark of maximum.Such as, first user equipment can have one to five speeches
Human model, each spokesman's model is for the corresponding user of first user equipment.
Mark (such as, maximum mark) can be compared with threshold score value and determines described mark by spokesman's authentication module
Whether meet threshold score value.Such as, spokesman's authentication module such as determines when the mark that threshold score value is minimum requirements
Whether maximum mark is higher than threshold score value or determines the mark of maximum when the mark that threshold score value is peak demand
Whether less than threshold score value, and the mark of maximum has the minimum of the mark that the user for first user equipment generates
Value.
If the mark of maximum meets threshold score value, then another mould on spokesman's authentication module or first user equipment
Block can (such as, storage be on the first user device for the forger spokesman's model identified on the first user device
Or on the server) in each generate mark, and continue process 300 to perform step 308.If the mark of maximum is not
Meet threshold score value, then subscriber equipment or server can stop performing step 300.When first user equipment or server stop
Perform step 300 time, first user equipment or server can stop from other spokesman's models of other user equipment requests or its
His mark.
Spokesman's authentication module on first user equipment or the similar module on server can be sent out for forger
Speech human model in each generate mark until generate identical with the largest score of the user for first user equipment or
Higher than the mark of this largest score, now, spokesman's authentication module stops execution process 300.When spokesman's authentication module determines
Do not have more forger spokesman's model or for first user equipment user largest score with for
The mark (such as utilizing step 308 and 310 to determine) of all forger spokesman's models (includes using for for other
The mark of forger spokesman's model of other users of family equipment) when comparing, described procedure continuous with step
312。
Such as, or many during described process determines the physical region near the physical location being positioned at first user equipment
Individual second subscriber equipment (308).First user equipment may utilize near-field communication and determines the second subscriber equipment.Testing as spokesman
In example when card module has determined that the first mark, the first mark can be supplied to other users and set by first user equipment
Standby, such as, for being used by other spokesman's authentication modules performing similar procedure.In some instances, first user equipment
First spokesman's model, other spokesman's models of other users being used for first user equipment or combination of the two can be carried
Supply at least some in the second subscriber equipment.
In some implementations, described process can determine that from first user equipment collaboration location but is in different physics
The second subscriber equipment in position.Such as, first user equipment is at first user equipment and specific second subscriber equipment
Both participate in when being involved in identical phone or video conference or at first user equipment and specific second subscriber equipment
During the close equipment of identical phone or video conference, it may be determined that described specific second subscriber equipment and first user equipment
Colocated.Described equipment may be located in identical physical room or is positioned at each room and includes single video conference
In the different room of equipment.First equipment or server may utilize for relative users calendar to determine equipment be association
With location, such as, when the calendar for two users is identical and indicates all of user at activity.
Described process obtains for corresponding second user's for the second user of each in the second subscriber equipment
Second spokesman's model or instruction language are second marks (310) of the corresponding probability said by corresponding second user.
Such as, other spokesman's authentication modules on the second subscriber equipment such as utilize corresponding second spokesman's model identical with coding
Other audio signals of a part for language or identical language generate each in the user for the second subscriber equipment
Corresponding second mark.First user equipment receives each the second mark from the second subscriber equipment and can disappear single
Breath or multiple message receive multiple second marks (when this single second subscriber equipment has multiple from single second subscriber equipment
During user).
In some instances, during server can generate the second mark some and these second marks are supplied to first
Subscriber equipment.Server can be that the user of first user equipment generates first mark or multiple first mark and by first
Mark is supplied to first user equipment.All of mark can be compared and send out to the equipment with largest score by server
Send message.Server can send a message to other not corresponding with largest score equipment or can not send a message to not with
Other equipment that big mark is corresponding.
Described process determines that described language is said (312) by first user.Such as, spokesman's authentication module will be for
The largest score of first user equipment with for storage forger spokesman's model on a user device mark or from
Second subscriber equipment receive the second mark or both compare.Such as in spokesman's authentication module determines other marks
One more than or equal to during for the largest score of first user equipment, spokesman's authentication module can stop using for first
The largest score of family equipment compares with other marks, and can stop execution process 300.
Described process is in response to described language being determination execution action (314) said by first user.Such as, voice
Identification module is analyzed audio signal and determines the text representation of coding language in audio signal.First user equipment utilization
Described text representation determines the order provided in language by first user and in response to this order execution action.
The order of the step in said process 300 is only illustrative, and can be executed in different order really
Determine whether language is said by first user.Such as, subscriber equipment can receive audio signal (such as, performing step 302)
Determine the second subscriber equipment in the physical region being positioned near the physical location of this subscriber equipment before, such as, perform step
308。
In some implementations, process 300 can include extra step, less step, or some in step
It is divided into multiple step.Such as, first user equipment can determine that the second subscriber equipment, determines any speech for the second user
Whether human model stores in memory (such as, as forger spokesman's model), and only uses from corresponding second
Second spokesman's model that family device request is not stored in described memorizer.In these examples, first user equipment can be from
Memorizer removes and is such as no longer on the thing near the physical location of first user equipment for its other subscriber equipmenies corresponding
In reason region other users' and any forger spokesman's model of being currently not included in the second subscriber equipment.
When for the subscriber equipment being no longer in the physical region near the physical location of first user equipment from depositing
When reservoir removes forger spokesman's model, first user equipment can be preserved for being marked as not carrying out removing other
Any forger spokesman's model of user.Such as, one in forger spokesman's model can be used for the first use
The friend in physical region near the physical location often in first user equipment at family.First user equipment can be this friend
Friend retains this in forger spokesman's model, even if being not detected by being operated by this friend at first user equipment
Another subscriber equipment when the most such.
The theme described in this manual and the embodiment of functional performance can be with Fundamental Digital Circuit, tangible terrains
Existing computer software or firmware, computer software (being included in the structure disclosed in this specification and its structural equivalents) or
One or more combination in these realizes.The embodiment of the theme described in this manual can be implemented as one or
Multiple computer programs, are i.e. used for being performed or control the coding of the operation of data processing equipment by data processing equipment tangible
Non-transient state program carrier on one or more modules of computer program instructions.Alternately or in addition, programmed instruction can
With coding on manually generated transmitting signal, such as, electricity, light or the electromagnetic signal that machine generates, described signal is generated to
Information coding is performed for data processing equipment for transmission to suitable acceptor device.Computer-readable storage medium can be machine
Readable storage device, machine readable storage substrate, the random or memory devices of serial access or one or more of which
Combination.
Term " data processing equipment " refer to data processing hardware and the device containing all kinds for processing data,
Equipment and machine, for example include programmable processor, computer or multiple processor or computer.Described device can be
Maybe can farther include dedicated logic circuit, such as FPGA (field programmable gate array) or ASIC (special IC).Remove
Outside hardware, described device can also include creating the code performing environment for computer program, such as, structure alternatively
Become the code of the combination of processor firmware, protocol stack, data base management system, operating system or one or more of which.
It is also referred to as or is described as the calculating of program, software, software application, module, software module, script or code
Machine program can be write by programming language in any form, including compilation type or interpreted languages or statement formula language or mistake
Cheng Yuyan, and it can dispose in any form, including as stand-alone program or as module, assembly, subroutine or be suitable to
Other unit in computing environment.Computer program can (but not necessarily) corresponding with the file in file system.Program
Can be stored in a part for the file keeping other programs or data (be such as stored in marking language document one or
Multiple scripts), in the single file be exclusively used in discussed program or in the file of multiple coordinations, such as storage one or
The file of the part of multiple modules, subprogram or code.Computer program can be deployed as on a computer or multiple
Performing on computer, the plurality of computer bit is in the three unities or is distributed on multiple place and mutual by communication network
Even.
The process described in this manual and logic flow can by perform one of one or more computer programs or
Multiple programmable calculators perform, with by input data are operated and generated output and perform function.Can also be by
Dedicated logic circuit performs described process and logic flow, and device also can be embodied as dedicated logic circuit, and such as, FPGA is (existing
Field programmable gate array) or ASIC (special IC).
Be adapted for carrying out the computer of computer program for example include general purpose microprocessor or special microprocessor or
Both or the CPU of any other kind.It is said that in general, CPU will be from read only memory or random
Access memorizer or both reception instruction and data.The primary element of computer is performed for or the central authorities of operating instruction
Processing unit and for storing one or more memory devices of instruction and data.It is said that in general, computer also will include
For storing one or more mass-memory units (such as, disk, magneto-optic disk or CD) of data, or, computer is also
To be operatively coupled to receive data from described mass-memory unit or transmit data to described mass-memory unit, or
Person's both of these case.But, the such equipment of computer need not have.It addition, computer can be embedded in another equipment, institute
State another equipment and only enumerate several: mobile phone, personal digital assistant (PDA), Mobile audio frequency or video player, game control
Platform, global positioning system (GPS) receptor or portable memory apparatus, such as USB (universal serial bus) (USB) flash drive.
The computer-readable medium being suitable to store computer program instructions and data includes that the non-volatile of form of ownership is deposited
Reservoir, medium and memory devices, for example include semiconductor memory devices, and such as, EPROM, EEPROM and flash memory set
Standby；Disk, such as internal hard drive or removable disk；Magneto-optic disk；And CD-ROM and DVD-ROM dish.Processor and memorizer can
With by supplemented, or it is combined in dedicated logic circuit.
Mutual in order to support with user, the embodiment of the theme described in this manual can be implemented in have for
Display to the user that the display device (such as, CRT (cathode ray tube) or LCD (liquid crystal display) monitor) of information and keyboard and
Sensing equipment (such as, mouse or trace ball, by its user can to computer provide input) computer on.Can also utilize
The equipment support of other kind is mutual with user's；Such as, it is provided that to the feedback of user can be any type of consciousness feedback,
Such as, visual feedback, auditory feedback or sense of touch feedback；And the input from user can be received in any form, bag
Include sound, voice or sense of touch input.It addition, computer by sending documents to the equipment of user's use and can set from this
Standby reception document is mutual with user；Such as, by webpage being sent to user in response to the request received from web browser
Equipment on web browser.
The embodiment of the theme described in this manual can be implemented in calculating system, and this calculating system includes rear end
Assembly, such as the aft-end assembly of data server, or include middleware component, such as application server, or include front end
Assembly, (user can be by this client computer such as to have the client computer of graphic user interface or web browser
Interact with the implementation of the theme described in this manual), or include one or more such rear end, centre
Part or the combination in any of front end assemblies.The assembly of system can be by any type of digital data communications (such as communication network)
Or the medium of digital data communications and interconnect.The example of communication network includes LAN (LAN) and wide area network (WAN), the most mutually
Networking.
Calculating system can include client and server.Client and server be generally remote from each other and typically via
Communication network comes mutual.Client and the relation of server due to operate on corresponding computer and mutually have client-
The computer program of relationship server and produce.In certain embodiments, data (such as, html web page) are transferred to by server
Subscriber equipment, such as presenting the data to the user mutual with subscriber equipment and receiving user's input, institute from this user
State subscriber equipment and serve as client.The data (result that such as, user is mutual) generated at subscriber equipment can be at server
Place receives from subscriber equipment.
Fig. 4 is the block diagram that can be used for realizing the calculating equipment 400,450 of the system and method described in the document, calculates
Equipment 400,450 is as client or a server or multiple server.Calculating equipment 400 is intended to mean that various forms of
Digital computer, such as laptop computer, desktop computer, work station, personal digital assistant, server, blade type service
Device, main frame (mainframe) and other suitable computers.Calculating equipment 450 is intended to mean that various forms of mobile device, example
Calculating equipment as similar with other in personal digital assistant, cell phone, smart phone, intelligent watch, helmet.Show herein
The assembly, its connection and the relation that go out and its function are intended to exemplary only, rather than are intended to be limited in described in the document
And/or the implementation of the invention being claimed.
Calculating equipment 400 includes processor 402, memorizer 404, storage device 406, is connected to memorizer 404 and high speed
The high-speed interface 408 of ECP Extended Capabilities Port 410 and be connected to the low-speed interface 412 of low speed bus 414 and storage device 406.Assembly
402, each in 404,406,408,410 and 412 utilizes various bus to interconnect, and may be mounted at common mainboard
Above or the most otherwise install.Processor 402 can process the finger for performing in calculating equipment 400
Order, including being stored in memorizer 404 or thinking in storage device 406 that external input/output device (such as, is coupled at a high speed
The display 416 of interface 408) on GUI display graphical information instruction.In other implementations, in due course, can
To be used together multiple processor and/or multiple bus with multiple memorizeies and polytype memorizer.Furthermore it is possible to will be many
Individual calculating equipment 400 is connected (such as, as server array, a group blade type with each equipment providing necessary operation part
Server or multicomputer system).
Memorizer 404 stores the information in calculating equipment 400.In one implementation, memorizer 404 can for computer
Read medium.In one implementation, memorizer 404 is one or more volatile memory-elements.In another implementation
In, memorizer 404 is one or more Nonvolatile memery unit.
Storage device 406 can provide massive store for calculating equipment 400.In one implementation, storage device
406 is computer-readable medium.In various different implementations, storage device 406 can be floppy device, hard disc apparatus, light
Disc apparatus or tape unit, flash memory or other similar solid-state memory device or the array of equipment, including storage area network
Or the equipment in other configurations.In one implementation, computer program is tangibly embodied as information carrier.Computer
Program product comprises instruction, and described instruction performs one or more methods as described above when executed.Described information carries
Body is computer or machine readable media, such as the memorizer on memorizer 404, storage device 406 or processor 402.
High-speed controller 408 manages the operation of the bandwidth intensive of calculating equipment 400, and low speed manager 412 manages bandwidth
The operation that intensive is relatively low.This distribution of task is only exemplary.In one implementation, high-speed controller 408 coupling
Close memorizer 404, display 416 (such as, by graphic process unit or accelerator) and be coupled to high-speed expansion ports
410, high-speed expansion ports 410 can accept various expansion card (not shown).In this implementation, low speed controller 412 couples
To storage device 406 and low-speed expansion port 414.Can include various COM1 (such as, USB, bluetooth, Ethernet, wireless with
Too net) this low-speed expansion port can be coupled to one or more input-output apparatus, such as keyboard, sensing equipment, scanner
Or such as it is coupled to networked devices (such as switch or router) by network adapter.
Calculating equipment 400 can realize in many different forms, as shown in FIG..Such as, it can be embodied as standard clothes
Several times of the group of business device 420 or such server.It also can be embodied as a part for rack type version server system 424.Separately
Outward, during it may be implemented in personal computer (such as laptop computer 422).Alternatively, can from the assembly calculating equipment 400
To combine with other assembly (not shown) in mobile device (such as equipment 450).Each such equipment can include that calculating sets
One or more in standby 400,450, and whole system can be made up of the multiple calculating equipment 400,450 communicated with one another.
In the middle of other assemblies, calculating equipment 450 especially includes processor 452, memorizer 464, input-output apparatus
(such as display 454), communication interface 466 and transceiver 468.Equipment 450 may be provided for storage device, such as micro-move device
Device or other equipment, to provide extra storage.Each in assembly 450,452,464,454,466 and 468 utilize various always
Line interconnects, and several in described assembly may be mounted on public mainboard or the most otherwise enter
Row is installed.
Processor 452 can process the instruction for performing in calculating equipment 150, including being stored in memorizer 464
Instruction.Described processor may also include single analog-and digital-processor.Described processor can provide such as equipment 450
The coordination (such as, the control to user interface) of other assemblies, equipment 450 run application and the radio communication of equipment 150.
Processor can be by controlling interface 458 and telex network and can be with the display interface 456 being coupled to display 454
Communication.Display 454 can be such as TFT LCD display or OLED display or other suitable display technologies.Display
Interface 456 can include for driving display 454 so that figure and other information to be presented to the proper circuit of user.Control interface
458 can receive order from user and be converted for submitting to processor 452.It addition, external interface 462 can be set as with
Processor 452 communicates, in order to enabled device 450 and the near field communication of other equipment.External interface 462 can provide and such as be used for
Wire communication (such as, via docked (docking) process) or for radio communication (such as, via bluetooth or other are such
Technology).
Memorizer 464 stores the information in calculating equipment 450.In one implementation, memorizer 464 can for computer
Read medium.In one implementation, memorizer 464 is one or more volatile memory-elements.In another implementation
In, memorizer 464 is one or more Nonvolatile memery unit.Extended menory 474 can also pass through expansion interface 472
Being provided and be connected to equipment 450, expansion interface 472 can include such as SIMM card interface.Such extended menory 474 can
There is provided extra memory space for equipment 450, or can be also equipment 450 storage application or other information.Specifically, extension storage
Device 474 can include realizing or the instruction of supplementary said process, and also can include safety information.It is therefoie, for example, extension storage
Device 474 may be provided in the security module for equipment 450, and can be programmed with the license safe handling to equipment 450
Instruction.Furthermore it is possible to provide safety applications and extraneous information via SIMM card, such as will can not identify in the way of cracking
Information is placed on SIMM card.
As discussed above, memorizer can include such as flash memory and/or mram memory.In one implementation,
Computer program is tangibly embodied as information carrier.Computer program comprises instruction, and described instruction is when executed
Perform all one or more methods as described above.Described information carrier is computer or machine readable media, such as, store
Memorizer on device 464, extended menory 474 or processor 452.
Equipment 450 can carry out radio communication by communication interface 466, and communication interface 466 can include in case of need
Digital signal processing circuit.Communication interface 466 can support communication under various modes or protocols, and various patterns or agreement are such as
GSM voice call, SMS, EMS or MMS message, CDMA, TDMA, PDC, WCDMA, CDMA2000 or GPRS etc..Such logical
Letter can such as be occurred by RF transceiver 468.It addition, junction service can such as utilize bluetooth, WiFi or other are such
Transceiver (not shown) and occur.It addition, extra wireless data can be supplied to equipment 450, institute by GPS receiver module 470
State extra wireless data to be used in due course by the application run on equipment 450.
Equipment 450 can also utilize audio codec 460 audibly to communicate, audio codec 460 can from
Family receives the information said and converts thereof into available digital information.Audio codec 460 can be similarly user
Generate sub-audible sound, such as by (receiver in such as equipment 450) speaker.Such sound can include from voiceband telephone
The sound of calling, it may include the sound (such as, speech information, music file etc.) that is recorded and also can include being existed by operation
The sound that application on equipment 450 generates.
Calculating equipment 450 can realize, as shown in FIG. with multiple different form.Such as, it may be implemented as honeybee
Cellular telephone 480.It also can be implemented as smart phone 482, personal digital assistant or a part for other similar mobile devices.
Although this specification contains the details of many specific implementations, but these should not be read as being asked
Ask the restriction of the scope of protection, but should be read as can be specific to the description of the feature of specific embodiment.In this specification
In can also realize in combination in single embodiment in some feature described in the context of separate embodiment.On the contrary,
Various features described in the context of single embodiment can also be dividually or with any suitable sub-portfolio in multiple realities
Execute in example and realize.Even if although it addition, feature can be described above as with some combinations and be the most also so
It is claimed, but can pluck from this combination in some cases from one or more features of the combination being claimed
Remove, and the combination being claimed can be for sub-portfolio or the modification of sub-portfolio.
Similarly, although depicting operation with particular order in the accompanying drawings, but this should not be construed as, desirable in order to realize
Result require that such operation with the particular order illustrated or performs in a subsequent order, or the operation of all signals is all
It is performed.In some cases, multitask and parallel processing can be favourable.Additionally, the most various system modules and
The separation of assembly is not construed as being desirable that such separation in all embodiments, and should be appreciated that described journey
Generally speaking sequence assembly and system can be embodied by single software product or be encapsulated in multiple software product.
Systematic collection the most discussed herein, about in the information of user or the situation of available personal information, can be given
User provides control program or feature whether to collect user profile, and (such as, spokesman's model, the preference of user or user's is current
Position) or control whether and/or how from the chance of content server reception content.It addition, some data can deposited
Process in one or more modes, so that removing individual discernible information before storage or use.For example, it is possible to process
The identity of user is so that the discernible information of the individual for this user can not be determined, or the geographical position of user is permissible
Obtained the place of positional information by generalization, such as, general Hua Dao city, postcode code or state level, so that use can not be determined
The particular location at family.Therefore, user can have how to collect the information about this user or how to be used by content server
The control of information.
Have been described with the specific embodiment of theme.Other embodiments are in the range of appended claims.Such as, exist
But the action described in claim can be executed in different order and still realize desirable result.As an example,
In order to realize desirable result, the process described in the accompanying drawings may not require the particular order that illustrates or order in succession.One
In the case of Xie, multitask and parallel processing can be favourable.Such as, module (such as, spokesman's checking that similarity scores calculates is performed
A part for module) can realize with hardware, such as directly realize on Digital Signal Processing (DSP) unit.
Claims (20)
1. a computer implemented method, including:
The audio signal that language is encoded is received by first user equipment；
First spokesman's model of the first user for described first user equipment is obtained by described first user equipment；
By described first user equipment for corresponding with the second subscriber equipment that described first user equipment collaboration positions
Two users obtain for second spokesman's model of described second user or to indicate described language be to be said by described second user
The second mark of corresponding probability；And
By the described first spokesman's model of first user equipment utilization (i) and described second spokesman's model or (ii) described first
Spokesman's model and described second mark determine that described language is said by described first user.
Method the most according to claim 1, wherein, is assisted for described first user equipment by described first user equipment
Obtain with the second corresponding user of the second subscriber equipment of location and be used for second spokesman's model of described second user or refer to
Show that described language is that the second mark of the corresponding probability said by described second user includes: by described first user equipment
For described second subscriber equipment being co-located in the physical region near the physical location of described first user equipment
Described second user obtains for second spokesman's model of described second user or to indicate described language be to be used by described second
Described second mark of the corresponding probability that family is said.
Method the most according to claim 1, including:
A part and described first spokesman's model generation by audio signal described in described first user equipment utilization indicate institute
State the first mark that language is the probability said by described first user.
Method the most according to claim 3, including:
Described first mark and described second mark are compared to determine highest score, wherein determine that described language is by institute
Including of stating that first user says determine that described first mark is highest score.
Method the most according to claim 1, wherein, is assisted for described first user equipment by described first user equipment
Obtain with the second corresponding user of the second subscriber equipment of location and be used for second spokesman's model of described second user or refer to
Show that described language is that the second mark of the corresponding probability said by described second user includes:
Described second spokesman's model is obtained by described first user equipment；And
By described in the part of audio signal described in described first user equipment utilization and described second spokesman's model generation
Two marks.
Method the most according to claim 1, wherein, is assisted for described first user equipment by described first user equipment
Obtain with the second corresponding user of the second subscriber equipment of location and be used for second spokesman's model of described second user or refer to
Show that described language is that the second mark of the corresponding probability said by described second user includes:
Determined that described second subscriber equipment positions with described first user equipment collaboration by described first user equipment；
Determined that described first user equipment has the described first user equipment of permission and accesses described the by described first user equipment
The setting of two spokesman's models；
Described second spokesman's model is received by described first user equipment；And
By described in the part of audio signal described in described first user equipment utilization and described second spokesman's model generation
Two marks.
Method the most according to claim 6, wherein, is received described second spokesman's model bag by described first user equipment
Include:
The one or more 3rd spokesman's models being stored on described first user equipment by described first user equipment identification；
And
Determined that the subset of described 3rd spokesman's model includes described second spokesman's model by described first user equipment.
Method the most according to claim 7, including:
Removed from described first user equipment by described first user equipment and be not included in described in described 3rd spokesman's model
The 3rd spokesman's model in subset.
Method the most according to claim 7, wherein:
Received described second spokesman's model by described first user equipment to include by described first user equipment from described first
Second spokesman's model described in memory search in subscriber equipment；And
Generated described second mark by described first user equipment to include being stored in described the by described first user equipment utilization
Second spokesman's model and a part for described audio signal on one subscriber equipment and not from another user equipment requests second
Spokesman's model generates described second mark.
Method the most according to claim 6, wherein, described second subscriber equipment includes described second spokesman's model.
11. methods according to claim 10, wherein, are received described second spokesman's model by described first user equipment
Described second spokesman's model is received from described second subscriber equipment including by described first user equipment.
12. methods according to claim 1, wherein, by described first user equipment for described first user equipment
The second corresponding user of the second subscriber equipment of colocated obtain for described second user second spokesman's model or
Indicating described language is that the second mark of the corresponding probability said by described second user includes:
Determined that described second subscriber equipment positions with described first user equipment collaboration by described first user equipment；And
Described second mark is received by described first user equipment.
13. methods according to claim 12, wherein, by described first user equipment receive described second mark include by
Described first user equipment receives described second mark from described second subscriber equipment.
14. methods according to claim 12, including:
The device identifier for described second subscriber equipment is determined by described first user equipment；
By described first user equipment, described device identifier is supplied to server；And
Described second mark is received from server in response to described identifier being supplied to server.
15. methods according to claim 1, including:
Determine that by described first user equipment be stored on described first user equipment sets for can be located at described first user
Other people one or more 3rd spokesman's models in the standby physical region near physical location；And
By the described first spokesman's model of described first user equipment utilization (i), described second spokesman's model and the described 3rd
Spokesman's model or (ii) described first spokesman's model, described second mark and described 3rd spokesman's model determine described
Language is said by described first user.
16. methods according to claim 15, including:
A part and described first spokesman's model generation by audio signal described in described first user equipment utilization indicate institute
State the first mark that language is the probability said by described first user；
Corresponding 3rd spokesman's mould is utilized for each in described 3rd spokesman's model by described first user equipment
A part for type and described audio signal generates corresponding 3rd mark；And
By more described first mark of first user equipment, described second mark and described 3rd mark to determine highest score.
17. methods according to claim 15, including:
Determined that described 3rd subscriber equipment is positioned at described first user and sets by described first user equipment for the 3rd subscriber equipment
The standby frequency in the physical region near physical location；
Determined whether described frequency meets threshold frequency by described first user equipment；And
By described first user equipment in response to determining that described frequency meets threshold frequency and will be used for described 3rd subscriber equipment
The 3rd spokesman's model of the 3rd user be stored in the 3rd spokesman's model.
18. 1 kinds of systems, including:
One or more computers and storage can carry out one or more storage devices of the instruction operated, and described instruction is by institute
Stating when one or more computer performs makes the one or more computer perform operation, and described operation includes:
The audio signal that language is encoded is received by first user equipment；
By described first user equipment obtain indicate described language be by the first user of described first user equipment say can
First mark of energy property；
By described first user equipment for corresponding with the second subscriber equipment that described first user equipment collaboration positions
Two users obtain the second mark indicating described language to be the corresponding probability said by described second user；
Described first mark and the combination of described second mark is determined by described first user equipment；
First point is come described in normalization by the combination of the first mark described in described first user equipment utilization and described second mark
Number and described second mark；And
Determined that described language is by normalized first mark of described first user equipment utilization and normalized second mark
Said by first user.
19. 1 kinds of computer-readable mediums storing software, described software includes the finger that can be performed by one or more computers
Order, described instruction makes the one or more computer perform operation after so performing, and described operation includes:
The audio signal that language is encoded is received by least one computer；
Set for relative users for each acquisition in two or more subscriber equipmenies by least one computer
The identification of corresponding spokesman's model of standby relative users；And
The spokesman's model identified is utilized to determine that described language is by described subscriber equipment by least one computer
Individual specific user says.
20. computer-readable mediums according to claim 19, described operation includes:
Corresponding identification from being included at least one meter is utilized for each in subscriber equipment by least one computer
Memorizer in calculation machine is retrieved corresponding spokesman's model.
Priority Applications (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
CN201811329448.2A CN109598112B (en) | 2014-07-18 | 2015-05-13 | Speaker verification system, method, and computer-readable medium |
CN201811329425.1A CN109376521B (en) | 2014-07-18 | 2015-05-13 | Method and system for speaker verification |
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/335,380 | 2014-07-18 | ||
US14/335,380 US9257120B1 (en) | 2014-07-18 | 2014-07-18 | Speaker verification using co-location information |
PCT/US2015/030569 WO2016010616A1 (en) | 2014-07-18 | 2015-05-13 | Speaker verification using co-location information |
Related Child Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201811329448.2A Division CN109598112B (en) | 2014-07-18 | 2015-05-13 | Speaker verification system, method, and computer-readable medium |
CN201811329425.1A Division CN109376521B (en) | 2014-07-18 | 2015-05-13 | Method and system for speaker verification |
Publications (2)
Publication Number | Publication Date |
---|---|
CN106164921A true CN106164921A (en) | 2016-11-23 |
CN106164921B CN106164921B (en) | 2018-12-07 |
Family
ID=53268901
Family Applications (3)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201811329425.1A Active CN109376521B (en) | 2014-07-18 | 2015-05-13 | Method and system for speaker verification |
CN201811329448.2A Active CN109598112B (en) | 2014-07-18 | 2015-05-13 | Speaker verification system, method, and computer-readable medium |
CN201580018671.3A Active CN106164921B (en) | 2014-07-18 | 2015-05-13 | Spokesman verifies system, method and computer-readable medium |
Family Applications Before (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201811329425.1A Active CN109376521B (en) | 2014-07-18 | 2015-05-13 | Method and system for speaker verification |
CN201811329448.2A Active CN109598112B (en) | 2014-07-18 | 2015-05-13 | Speaker verification system, method, and computer-readable medium |
Country Status (6)
Country | Link |
---|---|
US (6) | US9257120B1 (en) |
EP (2) | EP3129982B1 (en) |
JP (4) | JP6509903B2 (en) |
KR (2) | KR101804388B1 (en) |
CN (3) | CN109376521B (en) |
WO (1) | WO2016010616A1 (en) |
Cited By (8)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN107993665A (en) * | 2017-12-14 | 2018-05-04 | 科大讯飞股份有限公司 | Spokesman role determines method, intelligent meeting method and system in multi-conference scene |
CN108605043A (en) * | 2016-12-30 | 2018-09-28 | 谷歌有限责任公司 | The certification of packetizing audio signal |
CN110326261A (en) * | 2017-02-14 | 2019-10-11 | 微软技术许可有限责任公司 | Determine that the speaker in audio input changes |
CN110600041A (en) * | 2019-07-29 | 2019-12-20 | 华为技术有限公司 | Voiceprint recognition method and device |
CN110797014A (en) * | 2018-07-17 | 2020-02-14 | 中兴通讯股份有限公司 | Voice recognition method and device and computer storage medium |
CN111448549A (en) * | 2017-12-08 | 2020-07-24 | 谷歌有限责任公司 | Distributed identification in a network system |
US11010601B2 (en) | 2017-02-14 | 2021-05-18 | Microsoft Technology Licensing, Llc | Intelligent assistant device communicating non-verbal cues |
US11100384B2 (en) | 2017-02-14 | 2021-08-24 | Microsoft Technology Licensing, Llc | Intelligent device user interactions |
Families Citing this family (170)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US8677377B2 (en) | 2005-09-08 | 2014-03-18 | Apple Inc. | Method and apparatus for building an intelligent automated assistant |
US9318108B2 (en) | 2010-01-18 | 2016-04-19 | Apple Inc. | Intelligent automated assistant |
US8977255B2 (en) | 2007-04-03 | 2015-03-10 | Apple Inc. | Method and system for operating a multi-function portable electronic device using voice-activation |
US10002189B2 (en) | 2007-12-20 | 2018-06-19 | Apple Inc. | Method and apparatus for searching using an active ontology |
US9330720B2 (en) | 2008-01-03 | 2016-05-03 | Apple Inc. | Methods and apparatus for altering audio output signals |
US20100030549A1 (en) | 2008-07-31 | 2010-02-04 | Lee Michael M | Mobile device having human language translation capability with positional feedback |
US8676904B2 (en) * | 2008-10-02 | 2014-03-18 | Apple Inc. | Electronic devices with voice command and contextual data processing capabilities |
US10706373B2 (en) | 2011-06-03 | 2020-07-07 | Apple Inc. | Performing actions associated with task items that represent tasks to perform |
US10276170B2 (en) | 2010-01-18 | 2019-04-30 | Apple Inc. | Intelligent automated assistant |
US8682667B2 (en) | 2010-02-25 | 2014-03-25 | Apple Inc. | User profiling for selecting user specific voice input processing information |
US9262612B2 (en) | 2011-03-21 | 2016-02-16 | Apple Inc. | Device access using voice authentication |
US10057736B2 (en) | 2011-06-03 | 2018-08-21 | Apple Inc. | Active transport based notifications |
US10134385B2 (en) | 2012-03-02 | 2018-11-20 | Apple Inc. | Systems and methods for name pronunciation |
US10417037B2 (en) | 2012-05-15 | 2019-09-17 | Apple Inc. | Systems and methods for integrating third party services with a digital assistant |
CN104969289B (en) | 2013-02-07 | 2021-05-28 | 苹果公司 | Voice trigger of digital assistant |
US10652394B2 (en) | 2013-03-14 | 2020-05-12 | Apple Inc. | System and method for processing voicemail |
US10748529B1 (en) | 2013-03-15 | 2020-08-18 | Apple Inc. | Voice activated device for use with a voice-based digital assistant |
WO2014197335A1 (en) | 2013-06-08 | 2014-12-11 | Apple Inc. | Interpreting and acting upon commands that involve sharing information with remote devices |
KR101959188B1 (en) | 2013-06-09 | 2019-07-02 | 애플 인크. | Device, method, and graphical user interface for enabling conversation persistence across two or more instances of a digital assistant |
US10176167B2 (en) | 2013-06-09 | 2019-01-08 | Apple Inc. | System and method for inferring user intent from speech inputs |
US10296160B2 (en) | 2013-12-06 | 2019-05-21 | Apple Inc. | Method for extracting salient dialog usage from live data |
US9633004B2 (en) | 2014-05-30 | 2017-04-25 | Apple Inc. | Better resolution when referencing to concepts |
US9430463B2 (en) | 2014-05-30 | 2016-08-30 | Apple Inc. | Exemplar-based natural language processing |
US10170123B2 (en) | 2014-05-30 | 2019-01-01 | Apple Inc. | Intelligent assistant for home automation |
US9966065B2 (en) | 2014-05-30 | 2018-05-08 | Apple Inc. | Multi-command single utterance input method |
US9715875B2 (en) | 2014-05-30 | 2017-07-25 | Apple Inc. | Reducing the need for manual start/end-pointing and trigger phrases |
US9338493B2 (en) | 2014-06-30 | 2016-05-10 | Apple Inc. | Intelligent automated assistant for TV user interactions |
US11942095B2 (en) * | 2014-07-18 | 2024-03-26 | Google Llc | Speaker verification using co-location information |
US11676608B2 (en) * | 2021-04-02 | 2023-06-13 | Google Llc | Speaker verification using co-location information |
US9257120B1 (en) * | 2014-07-18 | 2016-02-09 | Google Inc. | Speaker verification using co-location information |
US9818400B2 (en) | 2014-09-11 | 2017-11-14 | Apple Inc. | Method and apparatus for discovering trending terms in speech requests |
US10074360B2 (en) | 2014-09-30 | 2018-09-11 | Apple Inc. | Providing an indication of the suitability of speech recognition |
US10127911B2 (en) | 2014-09-30 | 2018-11-13 | Apple Inc. | Speaker identification and unsupervised speaker adaptation techniques |
US9668121B2 (en) | 2014-09-30 | 2017-05-30 | Apple Inc. | Social reminders |
US11275757B2 (en) | 2015-02-13 | 2022-03-15 | Cerner Innovation, Inc. | Systems and methods for capturing data, creating billable information and outputting billable information |
US9734682B2 (en) | 2015-03-02 | 2017-08-15 | Enovate Medical, Llc | Asset management using an asset tag device |
US10152299B2 (en) | 2015-03-06 | 2018-12-11 | Apple Inc. | Reducing response latency of intelligent automated assistants |
US10567477B2 (en) | 2015-03-08 | 2020-02-18 | Apple Inc. | Virtual assistant continuity |
US9886953B2 (en) | 2015-03-08 | 2018-02-06 | Apple Inc. | Virtual assistant activation |
US9721566B2 (en) | 2015-03-08 | 2017-08-01 | Apple Inc. | Competing devices responding to voice triggers |
US10133538B2 (en) * | 2015-03-27 | 2018-11-20 | Sri International | Semi-supervised speaker diarization |
US20160301691A1 (en) * | 2015-04-10 | 2016-10-13 | Enovate Medical, Llc | Layering in user authentication |
US10460227B2 (en) | 2015-05-15 | 2019-10-29 | Apple Inc. | Virtual assistant in a communication session |
US10083688B2 (en) | 2015-05-27 | 2018-09-25 | Apple Inc. | Device voice control for selecting a displayed affordance |
US10200824B2 (en) | 2015-05-27 | 2019-02-05 | Apple Inc. | Systems and methods for proactively identifying and surfacing relevant content on a touch-sensitive device |
US9578173B2 (en) | 2015-06-05 | 2017-02-21 | Apple Inc. | Virtual assistant aided communication with 3rd party service in a communication session |
US11025565B2 (en) | 2015-06-07 | 2021-06-01 | Apple Inc. | Personalized prediction of responses for instant messaging |
US20160378747A1 (en) | 2015-06-29 | 2016-12-29 | Apple Inc. | Virtual assistant for media playback |
US10331312B2 (en) | 2015-09-08 | 2019-06-25 | Apple Inc. | Intelligent automated assistant in a media environment |
US10740384B2 (en) | 2015-09-08 | 2020-08-11 | Apple Inc. | Intelligent automated assistant for media search and playback |
US10747498B2 (en) | 2015-09-08 | 2020-08-18 | Apple Inc. | Zero latency digital assistant |
US10671428B2 (en) | 2015-09-08 | 2020-06-02 | Apple Inc. | Distributed personal assistant |
US9542941B1 (en) * | 2015-10-01 | 2017-01-10 | Lenovo (Singapore) Pte. Ltd. | Situationally suspending wakeup word to enable voice command input |
US9571995B1 (en) * | 2015-10-07 | 2017-02-14 | Verizon Patent And Licensing Inc. | Call transfer initiation via near field communication (NFC) |
US10691473B2 (en) | 2015-11-06 | 2020-06-23 | Apple Inc. | Intelligent automated assistant in a messaging environment |
US10956666B2 (en) | 2015-11-09 | 2021-03-23 | Apple Inc. | Unconventional virtual assistant interactions |
US9860355B2 (en) | 2015-11-23 | 2018-01-02 | International Business Machines Corporation | Call context metadata |
US10049668B2 (en) | 2015-12-02 | 2018-08-14 | Apple Inc. | Applying neural network language models to weighted finite state transducers for automatic speech recognition |
US10223066B2 (en) | 2015-12-23 | 2019-03-05 | Apple Inc. | Proactive assistance based on dialog communication between devices |
JP2017138476A (en) * | 2016-02-03 | 2017-08-10 | ソニー株式会社 | Information processing device, information processing method, and program |
US10373612B2 (en) * | 2016-03-21 | 2019-08-06 | Amazon Technologies, Inc. | Anchored speech detection and speech recognition |
US11227589B2 (en) | 2016-06-06 | 2022-01-18 | Apple Inc. | Intelligent list reading |
US10049663B2 (en) | 2016-06-08 | 2018-08-14 | Apple, Inc. | Intelligent automated assistant for media exploration |
US10586535B2 (en) | 2016-06-10 | 2020-03-10 | Apple Inc. | Intelligent digital assistant in a multi-tasking environment |
DK179415B1 (en) | 2016-06-11 | 2018-06-14 | Apple Inc | Intelligent device arbitration and control |
DK201670540A1 (en) * | 2016-06-11 | 2018-01-08 | Apple Inc | Application integration with a digital assistant |
US10438583B2 (en) * | 2016-07-20 | 2019-10-08 | Lenovo (Singapore) Pte. Ltd. | Natural language voice assistant |
US10621992B2 (en) * | 2016-07-22 | 2020-04-14 | Lenovo (Singapore) Pte. Ltd. | Activating voice assistant based on at least one of user proximity and context |
US9972320B2 (en) | 2016-08-24 | 2018-05-15 | Google Llc | Hotword detection on multiple devices |
US10474753B2 (en) | 2016-09-07 | 2019-11-12 | Apple Inc. | Language identification using recurrent neural networks |
US10043516B2 (en) | 2016-09-23 | 2018-08-07 | Apple Inc. | Intelligent automated assistant |
US9741360B1 (en) | 2016-10-09 | 2017-08-22 | Spectimbre Inc. | Speech enhancement for target speakers |
GB2557375A (en) * | 2016-12-02 | 2018-06-20 | Cirrus Logic Int Semiconductor Ltd | Speaker identification |
US11281993B2 (en) | 2016-12-05 | 2022-03-22 | Apple Inc. | Model and ensemble compression for metric learning |
US10559309B2 (en) * | 2016-12-22 | 2020-02-11 | Google Llc | Collaborative voice controlled devices |
US10916243B2 (en) * | 2016-12-27 | 2021-02-09 | Amazon Technologies, Inc. | Messaging from a shared device |
US11204787B2 (en) | 2017-01-09 | 2021-12-21 | Apple Inc. | Application integration with a digital assistant |
CN117577099A (en) | 2017-04-20 | 2024-02-20 | 谷歌有限责任公司 | Method, system and medium for multi-user authentication on a device |
DK201770383A1 (en) | 2017-05-09 | 2018-12-14 | Apple Inc. | User interface for correcting recognition errors |
US10417266B2 (en) | 2017-05-09 | 2019-09-17 | Apple Inc. | Context-aware ranking of intelligent response suggestions |
DK180048B1 (en) | 2017-05-11 | 2020-02-04 | Apple Inc. | MAINTAINING THE DATA PROTECTION OF PERSONAL INFORMATION |
DK201770439A1 (en) | 2017-05-11 | 2018-12-13 | Apple Inc. | Offline personal assistant |
US10726832B2 (en) | 2017-05-11 | 2020-07-28 | Apple Inc. | Maintaining privacy of personal information |
US10395654B2 (en) | 2017-05-11 | 2019-08-27 | Apple Inc. | Text normalization based on a data-driven learning network |
DK179496B1 (en) * | 2017-05-12 | 2019-01-15 | Apple Inc. | USER-SPECIFIC Acoustic Models |
US11301477B2 (en) | 2017-05-12 | 2022-04-12 | Apple Inc. | Feedback analysis of a digital assistant |
DK201770427A1 (en) | 2017-05-12 | 2018-12-20 | Apple Inc. | Low-latency intelligent automated assistant |
DK179745B1 (en) | 2017-05-12 | 2019-05-01 | Apple Inc. | SYNCHRONIZATION AND TASK DELEGATION OF A DIGITAL ASSISTANT |
DK201770432A1 (en) | 2017-05-15 | 2018-12-21 | Apple Inc. | Hierarchical belief states for digital assistants |
DK201770431A1 (en) | 2017-05-15 | 2018-12-20 | Apple Inc. | Optimizing dialogue policy decisions for digital assistants using implicit feedback |
US10403278B2 (en) | 2017-05-16 | 2019-09-03 | Apple Inc. | Methods and systems for phonetic matching in digital assistant services |
US20180336892A1 (en) | 2017-05-16 | 2018-11-22 | Apple Inc. | Detecting a trigger of a digital assistant |
DK179560B1 (en) | 2017-05-16 | 2019-02-18 | Apple Inc. | Far-field extension for digital assistant services |
US10303715B2 (en) | 2017-05-16 | 2019-05-28 | Apple Inc. | Intelligent automated assistant for media exploration |
US10311144B2 (en) | 2017-05-16 | 2019-06-04 | Apple Inc. | Emoji word sense disambiguation |
US10664533B2 (en) | 2017-05-24 | 2020-05-26 | Lenovo (Singapore) Pte. Ltd. | Systems and methods to determine response cue for digital assistant based on context |
US10657328B2 (en) | 2017-06-02 | 2020-05-19 | Apple Inc. | Multi-task recurrent neural network architecture for efficient morphology handling in neural language modeling |
US11184184B2 (en) * | 2017-06-28 | 2021-11-23 | Optim Corporation | Computer system, method for assisting in web conference speech, and program |
WO2019005227A1 (en) | 2017-06-30 | 2019-01-03 | Google Llc | Methods, systems, and media for voice-based call operations |
EP3646567B1 (en) | 2017-06-30 | 2022-05-18 | Google LLC | Methods, systems, and media for connecting an iot device to a call |
US10445429B2 (en) | 2017-09-21 | 2019-10-15 | Apple Inc. | Natural language understanding using vocabularies with compressed serialized tries |
US10755051B2 (en) | 2017-09-29 | 2020-08-25 | Apple Inc. | Rule-based natural language processing |
US10749855B2 (en) * | 2017-10-30 | 2020-08-18 | Vmware, Inc. | Securely managing digital assistants that access third-party applications |
US10515640B2 (en) * | 2017-11-08 | 2019-12-24 | Intel Corporation | Generating dialogue based on verification scores |
US10482878B2 (en) * | 2017-11-29 | 2019-11-19 | Nuance Communications, Inc. | System and method for speech enhancement in multisource environments |
US10157611B1 (en) * | 2017-11-29 | 2018-12-18 | Nuance Communications, Inc. | System and method for speech enhancement in multisource environments |
US10636424B2 (en) | 2017-11-30 | 2020-04-28 | Apple Inc. | Multi-turn canned dialog |
US10733982B2 (en) | 2018-01-08 | 2020-08-04 | Apple Inc. | Multi-directional dialog |
US10733375B2 (en) | 2018-01-31 | 2020-08-04 | Apple Inc. | Knowledge-based framework for improving natural language understanding |
KR102513297B1 (en) * | 2018-02-09 | 2023-03-24 | 삼성전자주식회사 | Electronic device and method for executing function of electronic device |
US10789959B2 (en) | 2018-03-02 | 2020-09-29 | Apple Inc. | Training speaker recognition models for digital assistants |
US10592604B2 (en) | 2018-03-12 | 2020-03-17 | Apple Inc. | Inverse text normalization for automatic speech recognition |
US11127405B1 (en) * | 2018-03-14 | 2021-09-21 | Amazon Technologies, Inc. | Selective requests for authentication for voice-based launching of applications |
US10877637B1 (en) | 2018-03-14 | 2020-12-29 | Amazon Technologies, Inc. | Voice-based device operation mode management |
US10885910B1 (en) | 2018-03-14 | 2021-01-05 | Amazon Technologies, Inc. | Voice-forward graphical user interface mode management |
US11240057B2 (en) * | 2018-03-15 | 2022-02-01 | Lenovo (Singapore) Pte. Ltd. | Alternative output response based on context |
US10818288B2 (en) | 2018-03-26 | 2020-10-27 | Apple Inc. | Natural assistant interaction |
US10909331B2 (en) | 2018-03-30 | 2021-02-02 | Apple Inc. | Implicit identification of translation payload with neural machine translation |
US10928918B2 (en) | 2018-05-07 | 2021-02-23 | Apple Inc. | Raise to speak |
US11145294B2 (en) | 2018-05-07 | 2021-10-12 | Apple Inc. | Intelligent automated assistant for delivering content from user experiences |
US10984780B2 (en) | 2018-05-21 | 2021-04-20 | Apple Inc. | Global semantic word embeddings using bi-directional recurrent neural networks |
DK201870355A1 (en) | 2018-06-01 | 2019-12-16 | Apple Inc. | Virtual assistant operation in multi-device environments |
US10892996B2 (en) | 2018-06-01 | 2021-01-12 | Apple Inc. | Variable latency device coordination |
DK180639B1 (en) | 2018-06-01 | 2021-11-04 | Apple Inc | DISABILITY OF ATTENTION-ATTENTIVE VIRTUAL ASSISTANT |
US11386266B2 (en) | 2018-06-01 | 2022-07-12 | Apple Inc. | Text correction |
DK179822B1 (en) | 2018-06-01 | 2019-07-12 | Apple Inc. | Voice interaction at a primary device to access call functionality of a companion device |
US10496705B1 (en) | 2018-06-03 | 2019-12-03 | Apple Inc. | Accelerated task performance |
EP3816996B1 (en) * | 2018-06-27 | 2023-03-01 | NEC Corporation | Information processing device, control method, and program |
KR102563817B1 (en) | 2018-07-13 | 2023-08-07 | 삼성전자주식회사 | Method for processing user voice input and electronic device supporting the same |
US11010561B2 (en) | 2018-09-27 | 2021-05-18 | Apple Inc. | Sentiment prediction from textual data |
US11170166B2 (en) | 2018-09-28 | 2021-11-09 | Apple Inc. | Neural typographical error modeling via generative adversarial networks |
US10839159B2 (en) | 2018-09-28 | 2020-11-17 | Apple Inc. | Named entity normalization in a spoken dialog system |
US11462215B2 (en) | 2018-09-28 | 2022-10-04 | Apple Inc. | Multi-modal inputs for voice commands |
KR102621897B1 (en) * | 2018-10-10 | 2024-01-08 | 주식회사 케이티 | Speaker recognition apparatus and operation method thereof |
KR102623246B1 (en) * | 2018-10-12 | 2024-01-11 | 삼성전자주식회사 | Electronic apparatus, controlling method of electronic apparatus and computer readable medium |
WO2020085769A1 (en) * | 2018-10-24 | 2020-04-30 | Samsung Electronics Co., Ltd. | Speech recognition method and apparatus in environment including plurality of apparatuses |
US11475898B2 (en) | 2018-10-26 | 2022-10-18 | Apple Inc. | Low-latency multi-speaker speech recognition |
US11004454B1 (en) * | 2018-11-06 | 2021-05-11 | Amazon Technologies, Inc. | Voice profile updating |
US11024291B2 (en) | 2018-11-21 | 2021-06-01 | Sri International | Real-time class recognition for an audio stream |
WO2020111880A1 (en) | 2018-11-30 | 2020-06-04 | Samsung Electronics Co., Ltd. | User authentication method and apparatus |
US11062704B1 (en) | 2018-12-21 | 2021-07-13 | Cerner Innovation, Inc. | Processing multi-party conversations |
US11398232B1 (en) | 2018-12-21 | 2022-07-26 | Cerner Innovation, Inc. | Natural language understanding of conversational sources |
US11875883B1 (en) | 2018-12-21 | 2024-01-16 | Cerner Innovation, Inc. | De-duplication and contextually-intelligent recommendations based on natural language understanding of conversational sources |
US11410650B1 (en) | 2018-12-26 | 2022-08-09 | Cerner Innovation, Inc. | Semantically augmented clinical speech processing |
US11638059B2 (en) | 2019-01-04 | 2023-04-25 | Apple Inc. | Content playback on multiple devices |
US11348573B2 (en) | 2019-03-18 | 2022-05-31 | Apple Inc. | Multimodality in digital assistant systems |
US10923111B1 (en) | 2019-03-28 | 2021-02-16 | Amazon Technologies, Inc. | Speech detection and speech recognition |
US11475884B2 (en) | 2019-05-06 | 2022-10-18 | Apple Inc. | Reducing digital assistant latency when a language is incorrectly determined |
DK201970509A1 (en) | 2019-05-06 | 2021-01-15 | Apple Inc | Spoken notifications |
US11423908B2 (en) | 2019-05-06 | 2022-08-23 | Apple Inc. | Interpreting spoken requests |
US11307752B2 (en) | 2019-05-06 | 2022-04-19 | Apple Inc. | User configurable task triggers |
US11140099B2 (en) | 2019-05-21 | 2021-10-05 | Apple Inc. | Providing message response suggestions |
US11289073B2 (en) | 2019-05-31 | 2022-03-29 | Apple Inc. | Device text to speech |
US11496600B2 (en) | 2019-05-31 | 2022-11-08 | Apple Inc. | Remote execution of machine-learned models |
DK201970510A1 (en) | 2019-05-31 | 2021-02-11 | Apple Inc | Voice identification in digital assistant systems |
DK180129B1 (en) | 2019-05-31 | 2020-06-02 | Apple Inc. | User activity shortcut suggestions |
US11360641B2 (en) | 2019-06-01 | 2022-06-14 | Apple Inc. | Increasing the relevance of new available information |
US11227599B2 (en) | 2019-06-01 | 2022-01-18 | Apple Inc. | Methods and user interfaces for voice-based control of electronic devices |
KR102098237B1 (en) * | 2019-06-26 | 2020-04-07 | 네이버 주식회사 | Method for verifying speaker and system for recognizing speech |
JP7462634B2 (en) * | 2019-07-17 | 2024-04-05 | ホシデン株式会社 | Microphone unit |
US11721330B1 (en) * | 2019-09-04 | 2023-08-08 | Amazon Technologies, Inc. | Natural language input processing |
US11158329B2 (en) * | 2019-09-11 | 2021-10-26 | Artificial Intelligence Foundation, Inc. | Identification of fake audio content |
US11488406B2 (en) | 2019-09-25 | 2022-11-01 | Apple Inc. | Text detection using global geometry estimators |
US11145315B2 (en) * | 2019-10-16 | 2021-10-12 | Motorola Mobility Llc | Electronic device with trigger phrase bypass and corresponding systems and methods |
US11043220B1 (en) | 2020-05-11 | 2021-06-22 | Apple Inc. | Digital assistant hardware abstraction |
US11061543B1 (en) | 2020-05-11 | 2021-07-13 | Apple Inc. | Providing relevant data items based on context |
US11490204B2 (en) | 2020-07-20 | 2022-11-01 | Apple Inc. | Multi-device audio adjustment coordination |
US11438683B2 (en) | 2020-07-21 | 2022-09-06 | Apple Inc. | User identification using headphones |
US11798546B2 (en) * | 2020-08-14 | 2023-10-24 | Google Llc | Transient personalization mode for guest users of an automated assistant |
KR20220137437A (en) * | 2021-04-02 | 2022-10-12 | 삼성전자주식회사 | Electronic device and operation method thereof |
Citations (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP2000075954A (en) * | 1998-09-02 | 2000-03-14 | Sony Corp | Electronic equipment controller |
CN1722230A (en) * | 2004-07-12 | 2006-01-18 | 惠普开发有限公司 | Allocation of speech recognition tasks and combination of results thereof |
CN102859967A (en) * | 2010-03-01 | 2013-01-02 | 诺基亚公司 | Method and apparatus for estimating user characteristics based on user interaction data |
JP2014092777A (en) * | 2012-11-06 | 2014-05-19 | Magic Hand:Kk | Activation of mobile communication device via voice |
Family Cites Families (150)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4363102A (en) | 1981-03-27 | 1982-12-07 | Bell Telephone Laboratories, Incorporated | Speaker identification system using word recognition templates |
JPS59180599A (en) | 1983-03-31 | 1984-10-13 | 日本電気ホームエレクトロニクス株式会社 | Voice recognition controller to be carried on vehicle |
JPS59180599U (en) | 1983-05-19 | 1984-12-03 | 株式会社村田製作所 | piezoelectric sound device |
JPH0231896A (en) | 1988-07-21 | 1990-02-01 | Osaka Gas Co Ltd | Treating apparatus for waste water |
JPH0552976A (en) | 1991-08-22 | 1993-03-02 | Canon Inc | Electronic device |
US6081782A (en) * | 1993-12-29 | 2000-06-27 | Lucent Technologies Inc. | Voice command control and verification system |
US5659665A (en) | 1994-12-08 | 1997-08-19 | Lucent Technologies Inc. | Method and apparatus for including speech recognition capabilities in a computer system |
JP3522421B2 (en) * | 1995-10-31 | 2004-04-26 | 株式会社リコー | Speaker recognition system and speaker recognition method |
US6073101A (en) * | 1996-02-02 | 2000-06-06 | International Business Machines Corporation | Text independent speaker recognition for transparent command ambiguity resolution and continuous access control |
US5895448A (en) | 1996-02-29 | 1999-04-20 | Nynex Science And Technology, Inc. | Methods and apparatus for generating and using speaker independent garbage models for speaker dependent speech recognition purpose |
US6023676A (en) | 1996-12-12 | 2000-02-08 | Dspc Israel, Ltd. | Keyword recognition system and method |
SE511418C2 (en) | 1997-03-13 | 1999-09-27 | Telia Ab | Method of speech verification / identification via modeling of typical non-typical characteristics. |
US8209184B1 (en) * | 1997-04-14 | 2012-06-26 | At&T Intellectual Property Ii, L.P. | System and method of providing generated speech via a network |
US6076055A (en) | 1997-05-27 | 2000-06-13 | Ameritech | Speaker verification method |
US5897616A (en) | 1997-06-11 | 1999-04-27 | International Business Machines Corporation | Apparatus and methods for speaker verification/identification/classification employing non-acoustic and/or acoustic models and databases |
JPH1152976A (en) | 1997-07-29 | 1999-02-26 | Nec Home Electron Ltd | Voice recognition device |
JP3524370B2 (en) | 1998-02-19 | 2004-05-10 | 富士通テン株式会社 | Voice activation system |
US6141644A (en) | 1998-09-04 | 2000-10-31 | Matsushita Electric Industrial Co., Ltd. | Speaker verification and speaker identification based on eigenvoices |
US6499013B1 (en) * | 1998-09-09 | 2002-12-24 | One Voice Technologies, Inc. | Interactive user interface using speech recognition and natural language processing |
JP2000122678A (en) * | 1998-10-14 | 2000-04-28 | Nippon Telegr & Teleph Corp <Ntt> | Controller for speech recogniging equipment |
US6744860B1 (en) | 1998-12-31 | 2004-06-01 | Bell Atlantic Network Services | Methods and apparatus for initiating a voice-dialing operation |
US6671672B1 (en) | 1999-03-30 | 2003-12-30 | Nuance Communications | Voice authentication system having cognitive recall mechanism for password verification |
US6408272B1 (en) | 1999-04-12 | 2002-06-18 | General Magic, Inc. | Distributed voice user interface |
JP3357629B2 (en) | 1999-04-26 | 2002-12-16 | 旭化成株式会社 | Equipment control system |
GB9911971D0 (en) * | 1999-05-21 | 1999-07-21 | Canon Kk | A system, a server for a system and a machine for use in a system |
US8645137B2 (en) | 2000-03-16 | 2014-02-04 | Apple Inc. | Fast, language-independent method for user authentication by voice |
DE10015960C2 (en) | 2000-03-30 | 2003-01-16 | Micronas Munich Gmbh | Speech recognition method and speech recognition device |
US6567775B1 (en) | 2000-04-26 | 2003-05-20 | International Business Machines Corporation | Fusion of audio and video based speaker identification for multimedia information access |
US6826159B1 (en) | 2000-05-24 | 2004-11-30 | Cisco Technology, Inc. | System and method for providing speaker identification in a conference call |
EP1168736A1 (en) | 2000-06-30 | 2002-01-02 | Alcatel | Telecommunication system and method with a speech recognizer |
US7016833B2 (en) | 2000-11-21 | 2006-03-21 | The Regents Of The University Of California | Speaker verification system using acoustic data and non-acoustic data |
US6973426B1 (en) | 2000-12-29 | 2005-12-06 | Cisco Technology, Inc. | Method and apparatus for performing speaker verification based on speaker independent recognition of commands |
JP2002279245A (en) | 2001-03-19 | 2002-09-27 | Ntt Docomo Inc | Service center and order receiving method |
US20020194003A1 (en) * | 2001-06-05 | 2002-12-19 | Mozer Todd F. | Client-server security system and method |
US6701293B2 (en) | 2001-06-13 | 2004-03-02 | Intel Corporation | Combining N-best lists from multiple speech recognizers |
US7233933B2 (en) * | 2001-06-28 | 2007-06-19 | Microsoft Corporation | Methods and architecture for cross-device activity monitoring, reasoning, and visualization for providing status and forecasts of a users' presence and availability |
US20030171930A1 (en) * | 2002-03-07 | 2003-09-11 | Junqua Jean-Claude | Computer telephony system to access secure resources |
JP4224250B2 (en) | 2002-04-17 | 2009-02-12 | パイオニア株式会社 | Speech recognition apparatus, speech recognition method, and speech recognition program |
JP2003345391A (en) | 2002-05-23 | 2003-12-03 | Denso Corp | Terminal, voice recognition server, voice recognition system and computer program |
US20030231746A1 (en) | 2002-06-14 | 2003-12-18 | Hunter Karla Rae | Teleconference speaker identification |
US7224981B2 (en) | 2002-06-20 | 2007-05-29 | Intel Corporation | Speech recognition of mobile devices |
JP2004086356A (en) * | 2002-08-23 | 2004-03-18 | Fujitsu Ten Ltd | Authentication method and authentication system |
TW200409525A (en) | 2002-11-26 | 2004-06-01 | Lite On Technology Corp | Voice identification method for cellular phone and cellular phone with voiceprint password |
US7457745B2 (en) | 2002-12-03 | 2008-11-25 | Hrl Laboratories, Llc | Method and apparatus for fast on-line automatic speaker/environment adaptation for speech/speaker recognition in the presence of changing environments |
EP1429314A1 (en) | 2002-12-13 | 2004-06-16 | Sony International (Europe) GmbH | Correction of energy as input feature for speech processing |
US7533023B2 (en) | 2003-02-12 | 2009-05-12 | Panasonic Corporation | Intermediary speech processor in network environments transforming customized speech parameters |
US7222072B2 (en) | 2003-02-13 | 2007-05-22 | Sbc Properties, L.P. | Bio-phonetic multi-phrase speaker identity verification |
US8290603B1 (en) | 2004-06-05 | 2012-10-16 | Sonos, Inc. | User interfaces for controlling and manipulating groupings in a multi-zone media system |
US7571014B1 (en) | 2004-04-01 | 2009-08-04 | Sonos, Inc. | Method and apparatus for controlling multimedia players in a multi-zone system |
US20070198262A1 (en) | 2003-08-20 | 2007-08-23 | Mindlin Bernardo G | Topological voiceprints for speaker identification |
EP1511277A1 (en) | 2003-08-29 | 2005-03-02 | Swisscom AG | Method for answering an incoming event with a phone device, and adapted phone device |
US7305078B2 (en) | 2003-12-18 | 2007-12-04 | Electronic Data Systems Corporation | Speaker identification during telephone conferencing |
US20050165607A1 (en) | 2004-01-22 | 2005-07-28 | At&T Corp. | System and method to disambiguate and clarify user intention in a spoken dialog system |
US8214447B2 (en) | 2004-06-08 | 2012-07-03 | Bose Corporation | Managing an audio network |
US7720012B1 (en) | 2004-07-09 | 2010-05-18 | Arrowhead Center, Inc. | Speaker identification in the presence of packet losses |
US8412521B2 (en) | 2004-08-20 | 2013-04-02 | Multimodal Technologies, Llc | Discriminative training of document transcription system |
US8521529B2 (en) | 2004-10-18 | 2013-08-27 | Creative Technology Ltd | Method for segmenting audio signals |
JP4710331B2 (en) | 2005-01-27 | 2011-06-29 | ソニー株式会社 | Apparatus, method, program and recording medium for remote control of presentation application |
KR100679043B1 (en) | 2005-02-15 | 2007-02-05 | 삼성전자주식회사 | Apparatus and method for spoken dialogue interface with task-structured frames |
US8725514B2 (en) * | 2005-02-22 | 2014-05-13 | Nuance Communications, Inc. | Verifying a user using speaker verification and a multimodal web-based interface |
US8041570B2 (en) | 2005-05-31 | 2011-10-18 | Robert Bosch Corporation | Dialogue management using scripts |
US7603275B2 (en) | 2005-10-31 | 2009-10-13 | Hitachi, Ltd. | System, method and computer program product for verifying an identity using voiced to unvoiced classifiers |
JP4657097B2 (en) | 2005-12-21 | 2011-03-23 | 京セラミタ株式会社 | Electronic equipment and voice operation program |
JP2006227634A (en) * | 2006-03-29 | 2006-08-31 | Seiko Epson Corp | Equipment control method using voice recognition, equipment control system using voice recognition and recording medium which records equipment control program using voice recognition |
US8595007B2 (en) | 2006-06-15 | 2013-11-26 | NITV Federal Services, LLC | Voice print recognition software system for voice identification and matching |
US8073681B2 (en) * | 2006-10-16 | 2011-12-06 | Voicebox Technologies, Inc. | System and method for a cooperative conversational voice user interface |
CN1996847B (en) | 2006-12-27 | 2010-05-19 | 中国科学院上海技术物理研究所 | Cooperative network based image and multi-media data communication and storage system |
US8099288B2 (en) | 2007-02-12 | 2012-01-17 | Microsoft Corp. | Text-dependent speaker verification |
US20110060587A1 (en) | 2007-03-07 | 2011-03-10 | Phillips Michael S | Command and control utilizing ancillary information in a mobile voice-to-speech application |
US8838457B2 (en) | 2007-03-07 | 2014-09-16 | Vlingo Corporation | Using results of unstructured language model based speech recognition to control a system-level function of a mobile communications facility |
US8352264B2 (en) | 2008-03-19 | 2013-01-08 | Canyon IP Holdings, LLC | Corrective feedback loop for automated speech recognition |
US8503686B2 (en) | 2007-05-25 | 2013-08-06 | Aliphcom | Vibration sensor and acoustic voice activity detection system (VADS) for use with electronic systems |
US8385233B2 (en) | 2007-06-12 | 2013-02-26 | Microsoft Corporation | Active speaker identification |
GB2450886B (en) | 2007-07-10 | 2009-12-16 | Motorola Inc | Voice activity detector and a method of operation |
US8495727B2 (en) * | 2007-08-07 | 2013-07-23 | Microsoft Corporation | Spam reduction in real time communications by human interaction proof |
JP2009104020A (en) * | 2007-10-25 | 2009-05-14 | Panasonic Electric Works Co Ltd | Voice recognition device |
CN101140646A (en) * | 2007-11-05 | 2008-03-12 | 陆航程 | 'Data great tracking' tax controlling system and tax controlling terminal based on EPC, EBC article internet |
US8140335B2 (en) * | 2007-12-11 | 2012-03-20 | Voicebox Technologies, Inc. | System and method for providing a natural language voice user interface in an integrated voice navigation services environment |
US8423362B2 (en) * | 2007-12-21 | 2013-04-16 | General Motors Llc | In-vehicle circumstantial speech recognition |
JP5424173B2 (en) | 2008-01-31 | 2014-02-26 | ＢｉｚＭｏｂｉｌｅ株式会社 | Mobile service providing system and providing method |
GB2458461A (en) | 2008-03-17 | 2009-09-23 | Kai Yu | Spoken language learning system |
US8504365B2 (en) | 2008-04-11 | 2013-08-06 | At&T Intellectual Property I, L.P. | System and method for detecting synthetic speaker verification |
US8145482B2 (en) | 2008-05-25 | 2012-03-27 | Ezra Daya | Enhancing analysis of test key phrases from acoustic sources with key phrase training models |
KR101056511B1 (en) | 2008-05-28 | 2011-08-11 | (주)파워보이스 | Speech Segment Detection and Continuous Speech Recognition System in Noisy Environment Using Real-Time Call Command Recognition |
US8676586B2 (en) | 2008-09-16 | 2014-03-18 | Nice Systems Ltd | Method and apparatus for interaction or discourse analytics |
US8676904B2 (en) | 2008-10-02 | 2014-03-18 | Apple Inc. | Electronic devices with voice command and contextual data processing capabilities |
US9922640B2 (en) | 2008-10-17 | 2018-03-20 | Ashwin P Rao | System and method for multimodal utterance detection |
KR101519104B1 (en) | 2008-10-30 | 2015-05-11 | 삼성전자 주식회사 | Apparatus and method for detecting target sound |
US8326637B2 (en) | 2009-02-20 | 2012-12-04 | Voicebox Technologies, Inc. | System and method for processing multi-modal device interactions in a natural language voice services environment |
US8209174B2 (en) | 2009-04-17 | 2012-06-26 | Saudi Arabian Oil Company | Speaker verification system |
US9858925B2 (en) | 2009-06-05 | 2018-01-02 | Apple Inc. | Using context information to facilitate processing of commands in a virtual assistant |
CN101923853B (en) | 2009-06-12 | 2013-01-23 | 华为技术有限公司 | Speaker recognition method, equipment and system |
WO2011064938A1 (en) * | 2009-11-25 | 2011-06-03 | 日本電気株式会社 | Voice data analysis device, voice data analysis method, and program for voice data analysis |
US8311838B2 (en) | 2010-01-13 | 2012-11-13 | Apple Inc. | Devices and methods for identifying a prompt corresponding to a voice input in a sequence of prompts |
US8626511B2 (en) | 2010-01-22 | 2014-01-07 | Google Inc. | Multi-dimensional disambiguation of voice commands |
US8543402B1 (en) | 2010-04-30 | 2013-09-24 | The Intellisis Corporation | Speaker segmentation in noisy conversational speech |
US8306814B2 (en) * | 2010-05-11 | 2012-11-06 | Nice-Systems Ltd. | Method for speaker source classification |
KR101672212B1 (en) | 2010-06-15 | 2016-11-04 | 엘지전자 주식회사 | Mobile terminal and operation method thereof |
US8532994B2 (en) * | 2010-08-27 | 2013-09-10 | Cisco Technology, Inc. | Speech recognition using a personal vocabulary and language model |
US8719018B2 (en) | 2010-10-25 | 2014-05-06 | Lockheed Martin Corporation | Biometric speaker identification |
US8874773B2 (en) | 2010-11-30 | 2014-10-28 | Gary W. Grube | Obtaining group and individual emergency preparedness communication information |
CN102741918B (en) | 2010-12-24 | 2014-11-19 | 华为技术有限公司 | Method and apparatus for voice activity detection |
JP5636309B2 (en) * | 2011-02-18 | 2014-12-03 | 株式会社東芝 | Voice dialogue apparatus and voice dialogue method |
US9262612B2 (en) * | 2011-03-21 | 2016-02-16 | Apple Inc. | Device access using voice authentication |
US9444816B2 (en) * | 2011-03-30 | 2016-09-13 | Qualcomm Incorporated | Continuous voice authentication for a mobile device |
WO2012146627A1 (en) * | 2011-04-27 | 2012-11-01 | Right Brain Interface N.V. | Method and apparatus for collaborative upload of content |
US9159324B2 (en) | 2011-07-01 | 2015-10-13 | Qualcomm Incorporated | Identifying people that are proximate to a mobile device user via social graphs, speech models, and user context |
US20130024196A1 (en) * | 2011-07-21 | 2013-01-24 | Nuance Communications, Inc. | Systems and methods for using a mobile device to deliver speech with speaker identification |
US8660847B2 (en) | 2011-09-02 | 2014-02-25 | Microsoft Corporation | Integrated local and cloud based speech recognition |
US8340975B1 (en) * | 2011-10-04 | 2012-12-25 | Theodore Alfred Rosenberger | Interactive speech recognition device and system for hands-free building control |
CN102710732A (en) * | 2011-11-06 | 2012-10-03 | 李宗诚 | Internet holographic collaborative system information fusion foundation |
US9031847B2 (en) | 2011-11-15 | 2015-05-12 | Microsoft Technology Licensing, Llc | Voice-controlled camera operations |
WO2013078388A1 (en) | 2011-11-21 | 2013-05-30 | Robert Bosch Gmbh | Methods and systems for adapting grammars in hybrid speech recognition engines for enhancing local sr performance |
US8825020B2 (en) | 2012-01-12 | 2014-09-02 | Sensory, Incorporated | Information access and device control using mobile phones and audio in the home environment |
JP6221202B2 (en) * | 2012-02-03 | 2017-11-01 | ヤマハ株式会社 | Communications system |
US20130262873A1 (en) * | 2012-03-30 | 2013-10-03 | Cgi Federal Inc. | Method and system for authenticating remote users |
KR20130133629A (en) | 2012-05-29 | 2013-12-09 | 삼성전자주식회사 | Method and apparatus for executing voice command in electronic device |
US20140006825A1 (en) | 2012-06-30 | 2014-01-02 | David Shenhav | Systems and methods to wake up a device from a power conservation state |
US9536528B2 (en) | 2012-07-03 | 2017-01-03 | Google Inc. | Determining hotword suitability |
JP6131537B2 (en) | 2012-07-04 | 2017-05-24 | セイコーエプソン株式会社 | Speech recognition system, speech recognition program, recording medium, and speech recognition method |
TWI474317B (en) | 2012-07-06 | 2015-02-21 | Realtek Semiconductor Corp | Signal processing apparatus and signal processing method |
WO2014029099A1 (en) * | 2012-08-24 | 2014-02-27 | Microsoft Corporation | I-vector based clustering training data in speech recognition |
US9058806B2 (en) * | 2012-09-10 | 2015-06-16 | Cisco Technology, Inc. | Speaker segmentation and recognition based on list of speakers |
US8983836B2 (en) | 2012-09-26 | 2015-03-17 | International Business Machines Corporation | Captioning using socially derived acoustic profiles |
US8904498B2 (en) * | 2012-10-17 | 2014-12-02 | Ca, Inc. | Biometric identification for mobile applications |
WO2014064324A1 (en) | 2012-10-26 | 2014-05-01 | Nokia Corporation | Multi-device speech recognition |
US8996372B1 (en) | 2012-10-30 | 2015-03-31 | Amazon Technologies, Inc. | Using adaptation data with cloud-based speech recognition |
US9704486B2 (en) | 2012-12-11 | 2017-07-11 | Amazon Technologies, Inc. | Speech recognition power management |
US10134392B2 (en) * | 2013-01-10 | 2018-11-20 | Nec Corporation | Terminal, unlocking method, and program |
US9502038B2 (en) * | 2013-01-28 | 2016-11-22 | Tencent Technology (Shenzhen) Company Limited | Method and device for voiceprint recognition |
US9349386B2 (en) | 2013-03-07 | 2016-05-24 | Analog Device Global | System and method for processor wake-up based on sensor data |
US9361885B2 (en) | 2013-03-12 | 2016-06-07 | Nuance Communications, Inc. | Methods and apparatus for detecting a voice command |
US9312826B2 (en) | 2013-03-13 | 2016-04-12 | Kopin Corporation | Apparatuses and methods for acoustic channel auto-balancing during multi-channel signal extraction |
SG11201508437UA (en) * | 2013-04-12 | 2015-11-27 | Sciometrics Llc | The identity caddy: a tool for real-time determination of identity in the mobile environment |
US8768687B1 (en) | 2013-04-29 | 2014-07-01 | Google Inc. | Machine translation of indirect speech |
US9058805B2 (en) * | 2013-05-13 | 2015-06-16 | Google Inc. | Multiple recognizer speech recognition |
US9697831B2 (en) * | 2013-06-26 | 2017-07-04 | Cirrus Logic, Inc. | Speech recognition |
WO2015025330A1 (en) | 2013-08-21 | 2015-02-26 | Kale Aaditya Kishore | A system to enable user to interact with an electronic processing device using voice of the user |
US9865255B2 (en) | 2013-08-29 | 2018-01-09 | Panasonic Intellectual Property Corporation Of America | Speech recognition method and speech recognition apparatus |
US9343068B2 (en) | 2013-09-16 | 2016-05-17 | Qualcomm Incorporated | Method and apparatus for controlling access to applications having different security levels |
US8775191B1 (en) | 2013-11-13 | 2014-07-08 | Google Inc. | Efficient utterance-specific endpointer triggering for always-on hotwording |
US9373321B2 (en) | 2013-12-02 | 2016-06-21 | Cypress Semiconductor Corporation | Generation of wake-up words |
US8938394B1 (en) | 2014-01-09 | 2015-01-20 | Google Inc. | Audio triggers based on context |
US9639854B2 (en) | 2014-06-26 | 2017-05-02 | Nuance Communications, Inc. | Voice-controlled information exchange platform, such as for providing information to supplement advertising |
US9257120B1 (en) * | 2014-07-18 | 2016-02-09 | Google Inc. | Speaker verification using co-location information |
US9318107B1 (en) | 2014-10-09 | 2016-04-19 | Google Inc. | Hotword detection on multiple devices |
US9424841B2 (en) | 2014-10-09 | 2016-08-23 | Google Inc. | Hotword detection on multiple devices |
US9812126B2 (en) | 2014-11-28 | 2017-11-07 | Microsoft Technology Licensing, Llc | Device arbitration for listening devices |
JP6754184B2 (en) | 2014-12-26 | 2020-09-09 | パナソニック インテレクチュアル プロパティ コーポレーション オブ アメリカＰａｎａｓｏｎｉｃ Ｉｎｔｅｌｌｅｃｔｕａｌ Ｐｒｏｐｅｒｔｙ Ｃｏｒｐｏｒａｔｉｏｎ ｏｆ Ａｍｅｒｉｃａ | Voice recognition device and voice recognition method |
US9721566B2 (en) | 2015-03-08 | 2017-08-01 | Apple Inc. | Competing devices responding to voice triggers |
-
2014
- 2014-07-18 US US14/335,380 patent/US9257120B1/en active Active
-
2015
- 2015-05-13 WO PCT/US2015/030569 patent/WO2016010616A1/en active Application Filing
- 2015-05-13 KR KR1020167027999A patent/KR101804388B1/en active IP Right Grant
- 2015-05-13 CN CN201811329425.1A patent/CN109376521B/en active Active
- 2015-05-13 CN CN201811329448.2A patent/CN109598112B/en active Active
- 2015-05-13 EP EP15725176.0A patent/EP3129982B1/en active Active
- 2015-05-13 JP JP2016561322A patent/JP6509903B2/en active Active
- 2015-05-13 KR KR1020167033161A patent/KR101890377B1/en active IP Right Grant
- 2015-05-13 CN CN201580018671.3A patent/CN106164921B/en active Active
- 2015-05-13 EP EP22161101.5A patent/EP4047497A3/en active Pending
- 2015-07-22 US US14/805,687 patent/US9412376B2/en active Active
-
2016
- 2016-07-05 US US15/201,972 patent/US9792914B2/en active Active
-
2017
- 2017-09-06 US US15/697,052 patent/US10147429B2/en active Active
-
2018
- 2018-10-26 US US16/172,221 patent/US10460735B2/en active Active
-
2019
- 2019-04-03 JP JP2019071251A patent/JP7007320B2/en active Active
- 2019-09-17 US US16/573,581 patent/US10986498B2/en active Active
-
2021
- 2021-09-24 JP JP2021155665A patent/JP7384877B2/en active Active
-
2023
- 2023-11-08 JP JP2023190911A patent/JP2023184691A/en active Pending
Patent Citations (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP2000075954A (en) * | 1998-09-02 | 2000-03-14 | Sony Corp | Electronic equipment controller |
CN1722230A (en) * | 2004-07-12 | 2006-01-18 | 惠普开发有限公司 | Allocation of speech recognition tasks and combination of results thereof |
CN102859967A (en) * | 2010-03-01 | 2013-01-02 | 诺基亚公司 | Method and apparatus for estimating user characteristics based on user interaction data |
JP2014092777A (en) * | 2012-11-06 | 2014-05-19 | Magic Hand:Kk | Activation of mobile communication device via voice |
Cited By (18)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN108605043A (en) * | 2016-12-30 | 2018-09-28 | 谷歌有限责任公司 | The certification of packetizing audio signal |
US11100384B2 (en) | 2017-02-14 | 2021-08-24 | Microsoft Technology Licensing, Llc | Intelligent device user interactions |
CN110326261A (en) * | 2017-02-14 | 2019-10-11 | 微软技术许可有限责任公司 | Determine that the speaker in audio input changes |
US11194998B2 (en) | 2017-02-14 | 2021-12-07 | Microsoft Technology Licensing, Llc | Multi-user intelligent assistance |
US10984782B2 (en) | 2017-02-14 | 2021-04-20 | Microsoft Technology Licensing, Llc | Intelligent digital assistant system |
US11126825B2 (en) | 2017-02-14 | 2021-09-21 | Microsoft Technology Licensing, Llc | Natural language interaction for smart assistant |
US11004446B2 (en) | 2017-02-14 | 2021-05-11 | Microsoft Technology Licensing, Llc | Alias resolving intelligent assistant computing device |
US11010601B2 (en) | 2017-02-14 | 2021-05-18 | Microsoft Technology Licensing, Llc | Intelligent assistant device communicating non-verbal cues |
US11017765B2 (en) | 2017-02-14 | 2021-05-25 | Microsoft Technology Licensing, Llc | Intelligent assistant with intent-based information resolution |
CN111448549B (en) * | 2017-12-08 | 2024-01-23 | 谷歌有限责任公司 | Distributed identification in a network system |
US11683320B2 (en) | 2017-12-08 | 2023-06-20 | Google Llc | Distributed identification in networked system |
CN111448549A (en) * | 2017-12-08 | 2020-07-24 | 谷歌有限责任公司 | Distributed identification in a network system |
CN107993665B (en) * | 2017-12-14 | 2021-04-30 | 科大讯飞股份有限公司 | Method for determining role of speaker in multi-person conversation scene, intelligent conference method and system |
CN107993665A (en) * | 2017-12-14 | 2018-05-04 | 科大讯飞股份有限公司 | Spokesman role determines method, intelligent meeting method and system in multi-conference scene |
CN110797014A (en) * | 2018-07-17 | 2020-02-14 | 中兴通讯股份有限公司 | Voice recognition method and device and computer storage medium |
WO2021017982A1 (en) * | 2019-07-29 | 2021-02-04 | 华为技术有限公司 | Voiceprint recognition method, and device |
CN110600041B (en) * | 2019-07-29 | 2022-04-29 | 华为技术有限公司 | Voiceprint recognition method and device |
CN110600041A (en) * | 2019-07-29 | 2019-12-20 | 华为技术有限公司 | Voiceprint recognition method and device |
Also Published As
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN106164921B (en) | Spokesman verifies system, method and computer-readable medium | |
JP6474762B2 (en) | Dynamic threshold for speaker verification | |
US11223699B1 (en) | Multiple user recognition with voiceprints on online social networks | |
US20230222371A1 (en) | User Identification with Voiceprints on Online Social Networks | |
EP4293661A2 (en) | Multi-user authentication on a device | |
US20230267935A1 (en) | Speaker verification using co-location information | |
US11676608B2 (en) | Speaker verification using co-location information |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
C06 | Publication | ||
PB01 | Publication | ||
C10 | Entry into substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
CB02 | Change of applicant information | ||
CB02 | Change of applicant information |
Address after: American CaliforniaApplicant after: Google limited liability companyAddress before: American CaliforniaApplicant before: Google Inc. |
|
GR01 | Patent grant | ||
GR01 | Patent grant |