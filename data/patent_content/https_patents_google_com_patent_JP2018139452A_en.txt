JP2018139452A - Adaptive frame/field coding in macro block level of digital video content - Google Patents
Adaptive frame/field coding in macro block level of digital video content Download PDFInfo
- Publication number
- JP2018139452A JP2018139452A JP2018110961A JP2018110961A JP2018139452A JP 2018139452 A JP2018139452 A JP 2018139452A JP 2018110961 A JP2018110961 A JP 2018110961A JP 2018110961 A JP2018110961 A JP 2018110961A JP 2018139452 A JP2018139452 A JP 2018139452A
- Authority
- JP
- Japan
- Prior art keywords
- macroblock
- block
- picture
- mode
- skipped
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
Images
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/102—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or selection affected or controlled by the adaptive coding
- H04N19/103—Selection of coding mode or of prediction mode
- H04N19/105—Selection of the reference unit for prediction within a chosen coding or prediction mode, e.g. adaptive choice of position and number of pixels used for prediction
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/102—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or selection affected or controlled by the adaptive coding
- H04N19/103—Selection of coding mode or of prediction mode
- H04N19/112—Selection of coding mode or of prediction mode according to a given display mode, e.g. for interlaced or progressive display mode
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/134—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or criterion affecting or controlling the adaptive coding
- H04N19/136—Incoming video signal characteristics or properties
- H04N19/137—Motion inside a coding unit, e.g. average field, frame or block difference
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/50—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding
- H04N19/503—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding involving temporal prediction
- H04N19/51—Motion estimation or motion compensation
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/50—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding
- H04N19/503—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding involving temporal prediction
- H04N19/51—Motion estimation or motion compensation
- H04N19/573—Motion compensation with multiple frame prediction using two or more reference frames in a given prediction direction
Abstract
Description
本発明は、デジタルビデオコンテンツの符号化及び復号に関し、より具体的には、本発明は、ＭＰＥＧ−４ Ｐａｒｔ １０ ＡＶＣ／Ｈ．２６４ビデオ符号化規格において使用され、デジタルビデオコンテンツのマクロブロックレベルにおけるフレームモード符号化及びフィールドモード符号化に関する。
The present invention relates to encoding and decoding of digital video content, and more specifically, the present invention relates to MPEG-4
ビデオ圧縮は、多くの既存の製品及び新規の製品において使用されている。ビデオ圧縮は、デジタルテレビジョンセットトップボックス（set-top boxes：ＳＴＢ）、デジタル衛星放送システム（digital satellite systems：ＤＳＳ）、高精細度テレビジョン（high definition television：ＨＤＴＶ）デコーダ、デジタルバーサタイルディスク（digital versatile disk：ＤＶＤ）プレーヤ、テレビ会議、インターネットビデオ及びマルチメディアコンテンツ、及び他のデジタルビデオの用途において重要である。デジタルビデオコンテンツは、ビデオ圧縮しなければ、非常にデータ量が大きいため、効率よく保存し、伝送し、表示することは不可能又は困難である。 Video compression is used in many existing and new products. Video compression includes digital television set-top boxes (STB), digital satellite systems (DSS), high definition television (HDTV) decoders, digital versatile discs (digital). versatile disk (DVD) player, video conferencing, Internet video and multimedia content, and other digital video applications. Digital video content has a very large amount of data unless it is video-compressed, making it impossible or difficult to efficiently store, transmit, and display it.
デジタルビデオコンテンツは、テレビジョン受像機、コンピュータモニタ又はデジタルビデオコンテンツを表示可能な他の電子機器に画像として表示されるピクチャのストリームからなる。特定のピクチャの前に表示されるピクチャは、この特定のピクチャの「前方」にある。また、この特定のピクチャの後に表示されるピクチャは、この特定のピクチャの「後方」にある。 Digital video content consists of a stream of pictures that are displayed as images on a television receiver, computer monitor or other electronic device capable of displaying digital video content. The picture displayed before a particular picture is “in front” of this particular picture. Also, the picture displayed after this particular picture is “behind” this particular picture.
ビデオ圧縮は、各ピクチャを１つのフレーム又は２つのフィールドとして符号化するビデオ符号化処理、すなわちコーディング処理において行われる。各フレームは、空間情報の数多くのラインからなる。例えば、一般的なフレームは、４８０本の水平ラインを含む。各フィールドは、１フレームの半分のラインを含んでいる。例えば、フレームが４８０水平ラインからなるときには、各フィールドは２４０水平ラインからなる。代表的な構成では、一方のフィールドは、フレーム内の奇数ラインからなり、他方のフィールドは、フレーム内の偶数ラインからなる。以下及び特許請求の範囲では、特別に定義する場合を除いて、奇数ラインからなるフィールドを「トップ」フィールドと呼ぶ。また、以下及び特許請求の範囲では、特別に定義する場合を除いて、偶数ラインからなるフィールドを「ボトム」フィールドと呼ぶ。２つのフィールドは、互いにインタレースされ、インタレースされたフレーム（以下、インタレースフレームという。）が形成される。 Video compression is performed in a video encoding process that encodes each picture as one frame or two fields, that is, a coding process. Each frame consists of a number of lines of spatial information. For example, a typical frame includes 480 horizontal lines. Each field contains half the line of one frame. For example, if a frame consists of 480 horizontal lines, each field consists of 240 horizontal lines. In a typical configuration, one field consists of odd lines in the frame and the other field consists of even lines in the frame. In the following and the claims, a field consisting of odd lines is referred to as a “top” field, unless otherwise defined. Also, in the following and claims, a field consisting of even lines is referred to as a “bottom” field, unless otherwise defined. The two fields are interlaced with each other to form an interlaced frame (hereinafter referred to as an interlaced frame).
包括的に言えば、ビデオ符号化は、デジタルビデオコンテンツデータから「必須でない（non-essential）」データを除去することによって行われる。データ量を削減することにより、放送又は伝送時に必要とされる帯域幅が削減される。圧縮されたビデオデータは、伝送された後、復号又は伸長する必要がある。この処理では、伝送されてきたビデオデータを処理して、符号化処理において除去された「必須でない」データに代えてビデオデータに組み込むための近似データを生成する。 In general, video encoding is performed by removing “non-essential” data from the digital video content data. By reducing the amount of data, the bandwidth required during broadcasting or transmission is reduced. Compressed video data needs to be decoded or decompressed after being transmitted. In this process, the transmitted video data is processed to generate approximate data to be incorporated into the video data in place of the “non-essential” data removed in the encoding process.
ビデオ符号化は、圧縮されていないデジタルビデオコンテンツよりも少ない容量で保存できるように、又は狭い帯域幅で伝送できるように、デジタルビデオコンテンツを圧縮された形式に変換する。圧縮は、ビデオコンテンツのピクチャにおける時間的及び空間的な冗長を利用している。デジタルビデオコンテンツは、例えばハードディスク、ＤＶＤ、他の不揮発性記憶装置等のストレージ媒体に格納することができる。 Video encoding converts digital video content into a compressed format so that it can be stored in less capacity than uncompressed digital video content or transmitted over a narrow bandwidth. Compression takes advantage of temporal and spatial redundancy in pictures of video content. The digital video content can be stored in a storage medium such as a hard disk, DVD, or other non-volatile storage device.
デジタルビデオコンテンツを圧縮するビデオ符号化方法には数多くのものがある。そのため、ビデオエンコーダ及びビデオデコーダの大半が認識できる形式で圧縮デジタルビデオコンテンツを表現するように、様々なデジタルビデオ符号化方法を標準化するビデオ符号化規格が開発されている。例えば、モーションピクチャエキスパートグループ（Motion Picture Experts Group：以下、ＭＰＥＧという。）及び国際電気通信連合（International Telecommunication Union：以下、ＩＴＵ−Ｔという。）は、広く使われているビデオ符号化規格を開発している。これらの規格の例として、ＭＰＥＧ−１規格、ＭＰＥＧ−２規格、ＭＰＥＧ−４規格、ＩＴＵ−Ｔ勧告Ｈ．２６１、ＩＴＵ−Ｔ勧告Ｈ．２６３がある。 There are many video encoding methods for compressing digital video content. For this reason, video coding standards have been developed that standardize various digital video coding methods so that compressed digital video content is represented in a format that is recognizable by most video encoders and video decoders. For example, the Motion Picture Experts Group (hereinafter referred to as MPEG) and the International Telecommunication Union (hereinafter referred to as ITU-T) have developed a widely used video coding standard. ing. Examples of these standards include MPEG-1 standard, MPEG-2 standard, MPEG-4 standard, ITU-T recommendation H.264, etc. 261, ITU-T Recommendation H.264. 263.
ＭＰＥＧ及びＩＴＵ−Ｔによって開発された規格を始めとする大部分の最新のビデオ符号化規格は、１つには、動き補償（motion compensation：以下、ＭＣという。）アルゴリズムを有する時間的予測に基づいている。動き補償を有する時間的予測は、デジタルビデオ放送における連続するピクチャ間の時間的冗長を削減するために、用いられる。 Most modern video coding standards, including those developed by MPEG and ITU-T, are based in part on temporal prediction with a motion compensation (MC) algorithm. ing. Temporal prediction with motion compensation is used to reduce temporal redundancy between successive pictures in a digital video broadcast.
動き補償アルゴリズムを有する時間的予測では、通常、個々のピクチャを符号化するために１つ又は２つの参照ピクチャを用いる。参照ピクチャは、既に符号化されたピクチャである。動き補償アルゴリズムを有する時間的予測では、符号化する特定のピクチャと参照ピクチャとを比較することによって、参照ピクチャと符号化する特定のピクチャ間の時間的冗長を利用し、仮に動き補償アルゴリズムを有する時間的予測を用いなかった場合と比べて、より高い圧縮率でピクチャを符号化することができる。参照ピクチャの一方は、符号化する特定のピクチャの後方にある。他方の参照ピクチャは、符号化する特定のピクチャの前方にある。 Temporal prediction with motion compensation algorithms typically uses one or two reference pictures to encode individual pictures. A reference picture is a picture that has already been encoded. Temporal prediction with motion compensation algorithm takes advantage of temporal redundancy between the reference picture and the specific picture to be encoded by comparing the specific picture to be encoded with the reference picture, and has a motion compensation algorithm. Compared to the case where temporal prediction is not used, a picture can be encoded at a higher compression rate. One of the reference pictures is behind the specific picture to be encoded. The other reference picture is in front of the particular picture to be encoded.
しかしながら、より高い解像度、より複雑な画像コンテンツ、より速い伝送速度を実現する要求に応じて、より優れたビデオ圧縮方法が望まれている。このために、現在、国際標準化機構（International Organization for Standardization：以下、ＩＳＯという。）及び国際電気通信連合（International Telecommunication Union：以下、ＩＴＵ−Ｔという。）が協力して新たなビデオ符号化規格を開発している。この新たなビデオ符号化規格は、ＭＰＥＧ−４ Ｐａｒｔ１０ アドバンストビデオ符号化（Advanced Video Coding：以下、ＡＶＣという。）／Ｈ．２６４規格と呼ばれている。
However, better video compression methods are desired in response to the need to achieve higher resolution, more complex image content, and higher transmission rates. To this end, the International Organization for Standardization (hereinafter referred to as ISO) and the International Telecommunication Union (hereinafter referred to as ITU-T) have collaborated to establish a new video coding standard. We are developing. This new video coding standard is MPEG-4
本発明に係る符号化方法は、画像シーケンスのピクチャを符号化する符号化方法において、上記ピクチャを複数の小さい部分に分割するステップと、上記複数の小さい部分の少なくとも１つを選択的にフレーム符号化モードで一度に符号化し、及び該複数の小さい部分の少なくとも１つを選択的にフィールド符号化モードで一度に符号化し、符号化ピクチャを形成するステップと、上記ピクチャが前方予測符号化ピクチャ又は両方向予測符号化ピクチャである場合に、上記少なくとも一つの小さな部分内の少なくとも一つのマクロブロックの符号化をスキップするステップとを有し、上記複数の小さい部分のそれぞれは、１つのマクロブロックよりも大きなサイズを有する。 An encoding method according to the present invention includes a step of dividing the picture into a plurality of small parts, and selectively encoding at least one of the plurality of small parts in a coding method for encoding a picture of an image sequence. Encoding at a time in encoding mode, and selectively encoding at least one of the plurality of small portions at a time in field encoding mode to form an encoded picture, wherein the picture is a forward predictive encoded picture or Skipping encoding of at least one macroblock in the at least one small portion when the picture is a bi-directional predictive coded picture, each of the plurality of small portions being more than one macroblock. Have a large size.
本発明に係る符号化装置は、画像シーケンスのピクチャを符号化する符号化装置において、上記ピクチャを複数の小さい部分に分割する手段と、上記複数の小さい部分の少なくとも１つを選択的にフレーム符号化モードで一度に符号化し、及び該複数の小さい部分の少なくとも１つを選択的にフィールド符号化モードで一度に符号化し、符号化ピクチャを形成する手段と、上記ピクチャが前方予測符号化ピクチャ又は両方向予測符号化ピクチャである場合に、上記少なくとも一つの小さな部分内の少なくとも一つのマクロブロックの符号化をスキップする手段とを有し、上記複数の小さい部分のそれぞれは、１つのマクロブロックよりも大きなサイズを有する。 An encoding apparatus according to the present invention, in an encoding apparatus for encoding a picture of an image sequence, selectively divides the picture into a plurality of small parts, and selectively encodes at least one of the plurality of small parts. Means for encoding at one time in encoding mode and selectively encoding at least one of the plurality of small portions at once in field encoding mode to form an encoded picture; Means for skipping the encoding of at least one macroblock in the at least one small portion in the case of a bi-directional predictive coded picture, each of the plurality of small portions being more than one macroblock Have a large size.
本発明に係る復号方法は、ビットストリームからの複数の小さい部分を有する符号化ピクチャを復号する復号方法において、上記複数の小さい部分の少なくとも１つをフレーム符号化モードで一度に復号し、及び該複数の小さい部分の少なくとも１つをフィールド符号化モードで一度に復号するステップと、上記ピクチャが前方予測符号化ピクチャ又は両方向予測符号化ピクチャである場合に、符号化をスキップされた少なくとも一つのマクロブロックを検出するステップと、上記スキップされた少なくとも一つのマクロブロックを再構成するステップと、上記複数の復号された小さい部分と上記少なくとも一つの符号化をスキップされ再構成されたマクロブロックを用いて、復号ピクチャを構成するステップとを有し、上記複数の小さい部分のそれぞれは、１つのマクロブロックよりも大きなサイズを有する。 The decoding method according to the present invention is a decoding method for decoding an encoded picture having a plurality of small portions from a bitstream, wherein at least one of the plurality of small portions is decoded at a time in a frame encoding mode, and Decoding at least one of a plurality of small parts at once in the field coding mode, and at least one macro skipped when the picture is a forward predictive coded picture or a bidirectional predictive coded picture Detecting a block; reconstructing the skipped at least one macroblock; using the plurality of decoded small portions and the at least one encoding skipped and reconstructed macroblock Forming a decoded picture, and the plurality of small parts Each has a larger size than one macroblock.
本発明に係る復号装置は、ビットストリームからの複数の小さい部分を有する符号化ピクチャを復号する復号装置において、上記複数の小さい部分の少なくとも１つをフレーム符号化モードで一度に復号し、及び該複数の小さい部分の少なくとも１つをフィールド符号化モードで一度に復号する手段と、上記ピクチャが前方予測符号化ピクチャ又は両方向予測符号化ピクチャである場合に、符号化をスキップされた少なくとも一つのマクロブロックを検出する手段と、上記スキップされた少なくとも一つのマクロブロックを再構成する手段と、上記複数の復号された小さい部分と上記少なくとも一つの符号化をスキップされ再構成されたマクロブロックを用いて、復号ピクチャを構成する手段とを有し、上記複数の小さい部分のそれぞれは、１つのマクロブロックよりも大きなサイズを有する。 The decoding apparatus according to the present invention is a decoding apparatus that decodes an encoded picture having a plurality of small portions from a bitstream, decodes at least one of the plurality of small portions at a time in a frame encoding mode, and Means for decoding at least one of a plurality of small portions at once in a field coding mode, and at least one macro skipped when the picture is a forward predictive coded picture or a bidirectional predictive coded picture Means for detecting a block, means for reconstructing the skipped at least one macroblock, the plurality of decoded small parts and the at least one encoding skipped and reconstructed macroblock Each of the plurality of small portions includes: It has a larger size than One macroblock.
本発明は、複数のピクチャのストリーム（以下、ピクチャストリームという。）からなるデジタルビデオコンテンツのマクロブロックレベルでの適応フレーム／フィールド（以下、ＡＦＦという。）符号化方法を提供する。本発明は、ピクチャレベルのＡＦＦ符号化の概念をマクロブロックに拡張する。ピクチャレベルでのＡＦＦ符号化において、符号化するピクチャストリームの各ピクチャは、他のピクチャがフレームモード又はフィールドモードの何れで符号化されているかにかかわらず、フレームモード又はフィールドモードで符号化される。ピクチャをフレームモードで符号化する場合、インタレースされたフレームを構成する２つのフィールドを一緒に符号化する。一方、ピクチャをフィールドモードで符号化する場合、インタレースされたフレームを構成する２つのフィールドを別々に符号化する。エンコーダは、フレームモード符号化とフィールドモード符号化のうちの、どちらのタイプが各ピクチャに対してより有利であるかを判定し、ピクチャの符号化タイプを選択する。フレームモードとフィールドモードとから選択する完全な方法は、本発明において重要でないので、詳細は省略する。 The present invention provides an adaptive frame / field (hereinafter referred to as AFF) encoding method at a macroblock level of digital video content composed of a plurality of picture streams (hereinafter referred to as picture streams). The present invention extends the concept of picture level AFF coding to macroblocks. In AFF encoding at the picture level, each picture of the picture stream to be encoded is encoded in frame mode or field mode, regardless of whether other pictures are encoded in frame mode or field mode. . When coding a picture in frame mode, the two fields that make up the interlaced frame are coded together. On the other hand, when a picture is encoded in a field mode, two fields constituting an interlaced frame are encoded separately. The encoder determines which type of frame mode coding or field mode coding is more advantageous for each picture and selects the coding type of the picture. The complete method of selecting between frame mode and field mode is not important in the present invention and will not be described in detail.
上述のように、ＭＰＥＧ−４ Ｐａｒｔ１０ ＡＶＣ／Ｈ．２６４規格は、デジタルビデオコンテンツを符号化して圧縮する新たな規格である。引用により本願に援用されるＭＰＥＧ−４ Ｐａｒｔ１０ ＡＶＣ／Ｈ．２６４規格を制定している勧告書は、ジョイントビデオチーム（Joint Video Team：ＪＶＴ）によって２００２年８月１０日に発行された「ジョイントビデオ仕様の共同最終委員会草案（Joint Final Committee Draft (JFCD) of Joint Video Specification）」を包含している（ＩＴＵ−Ｔ勧告Ｈ．２６４＆ＩＳＯ／ＩＥＣ １４４９６−１０ ＡＶＣ）。ＪＶＴは、ＩＳＯ又はＭＰＥＧ及びＩＴＵ−Ｔの専門家らによって構成されている。ＭＰＥＧ−４ Ｐａｒｔ１０ ＡＶＣ／Ｈ．２６４規格は公に知られているので、本明細書では、ＭＰＥＧ−４ Ｐａｒｔ１０ ＡＶＣ／Ｈ．２６４ビデオ符号化規格の特徴を全て詳細に記載することはしないが、本発明は、この規格の仕様に基づいて実現される。
As described above, MPEG-4
ここに説明するＡＦＦ符号化方法は、ＭＰＥＧ−４ Ｐａｒｔ１０ ＡＶＣ／Ｈ．２６４規格の定めるガイドラインと互換性があり、これに則した説明を行うが、このＡＦＦ符号化方法は、特定の規格又は用途に応じて、適宜変更することができる。
The AFF encoding method described here is MPEG-4
以下、図面を参照して、本発明の好ましい実施例について説明する。 Hereinafter, preferred embodiments of the present invention will be described with reference to the drawings.
図１は、本発明を実現するために用いることができる３種類のピクチャのシーケンスの具体例を示しており、これらは、ＭＰＥＧ−４ Ｐａｒｔ１０ ＡＶＣ／Ｈ．２６４規格を始めとする代表的なビデオ符号化方法において定義されている。上述のように、エンコーダはピクチャを符号化し、デコーダはピクチャを復号する。エンコーダ又はデコーダは、プロセッサ、特定用途向け集積回路（application specific integrated circuit：ＡＳＩＣ）、フィールドプログラマブルゲートアレー（field programmable gate array：ＦＰＧＡ）、エンコーダ／デコーダ（coder/decoder：ＣＯＤＥＣ）、デジタルシグナルプロセッサ（digital signal processor：ＤＳＰ）、又はピクチャストリームを符号化できる他の電子回路等の何れであってもよいが、以下及び特許請求の範囲において、特別に定義する場合を除き、「エンコーダ」という用語は、ピクチャストリームからなるデジタルビデオコンテンツを符号化する全ての電子回路を含むものとする。また、「デコーダ」という用語は、ピクチャストリームからなるデジタルビデオコンテンツを復号する全ての電子回路を含むものとする。
FIG. 1 shows an example of a sequence of three types of pictures that can be used to implement the present invention, which are MPEG-4
ビデオ符号化方法に用いることができるピクチャの３つの種類を図１に示す。３つのピクチャタイプは、記憶されているデジタルビデオコンテンツのランダムアクセスをサポートし、動き補償を有する時間的予測を用いて、最大の冗長削減（the maximum redundancy reduction）を探索するように定義されている。３つのピクチャタイプには、イントラピクチャ（intra picture：以下、Ｉピクチャという。）（１００）と、前方予測ピクチャ（predicted picture：以下、Ｐピクチャという。）（１０２ａ、１０２ｂ）と、両方向予測ピクチャ（bi-predicted picture：以下、Ｂピクチャという。）（１０１ａ〜１０１ｄ）とがある。Ｉピクチャ（１００）は、記憶されているデジタルビデオコンテンツにランダムアクセスするためのアクセスポイントになっており、低い圧縮率で符号化される。Ｉピクチャ（１００）は、参照ピクチャを参照することなく符号化される。 Three types of pictures that can be used in the video encoding method are shown in FIG. Three picture types are defined to support random access of stored digital video content and search for the maximum redundancy reduction using temporal prediction with motion compensation. . The three picture types include an intra picture (hereinafter referred to as I picture) (100), a forward predicted picture (hereinafter referred to as P picture) (102a, 102b), and a bidirectional prediction picture (100). bi-predicted picture: hereinafter referred to as B picture) (101a to 101d). The I picture (100) is an access point for randomly accessing stored digital video content, and is encoded at a low compression rate. The I picture (100) is encoded without referring to the reference picture.
Ｐピクチャ（１０２ａ、１０２ｂ）は、既に符号化されたＩ、Ｐ、Ｂピクチャを参照ピクチャとして用いて符号化される。符号化するＰピクチャに対して時間的に前方又は後方のピクチャの何れも参照ピクチャとして用いることができる。Ｐピクチャ（１０２ａ、１０２ｂ）は、Ｉピクチャ（１００）よりも高い圧縮率で符号化することができる。 P pictures (102a, 102b) are encoded using already encoded I, P, B pictures as reference pictures. Any picture that is temporally forward or backward with respect to the P picture to be encoded can be used as a reference picture. P pictures (102a, 102b) can be encoded at a higher compression rate than I pictures (100).
Ｂピクチャ（１０１ａ〜１０１ｄ）は、前方参照ピクチャと後方参照ピクチャとの２つの時間的な参照ピクチャを用いて符号化される。前方参照ピクチャは過去参照ピクチャと呼ばれることもあり、後方参照ピクチャは未来参照ピクチャと呼ばれることもある。本発明の実施例では、前方参照ピクチャ及び後方参照ピクチャは、符号化するＢピクチャに対して時間的に同一方向にあってもよい。Ｂピクチャ（１０１ａ〜１０１ｄ）は、３つのピクチャタイプのうちで最も高い圧縮率で符号化することができる。 B pictures (101a to 101d) are encoded using two temporal reference pictures, a forward reference picture and a backward reference picture. The forward reference picture is sometimes called a past reference picture, and the backward reference picture is sometimes called a future reference picture. In the embodiment of the present invention, the forward reference picture and the backward reference picture may be temporally in the same direction with respect to the B picture to be encoded. B pictures (101a to 101d) can be encoded with the highest compression rate among the three picture types.
図１は、３つのピクチャタイプ間の参照関係（１０３）を示している。例えば、Ｐピクチャ（１０２ａ）は、符号化されたＩピクチャ（１００）を参照ピクチャとして用いて符号化することができる。Ｂピクチャ（１０１ａ〜１０１ｄ）は、図１に示すように、符号化されたＩピクチャ（１００）及び／又は符号化されたＰピクチャ（１０２ａ）を参照ピクチャとして用いて符号化することができる。本発明の原理に基づけば、符号化されたＢピクチャ（１０１ａ〜１０１ｄ）は、符号化する他のＢピクチャの参照ピクチャとして用いることもできる。例えば、図１に示すＢピクチャ（１０１ｃ）は、他の２つのＢピクチャ（１０１ｂ、１０１ｄ）を参照ピクチャとしている。 FIG. 1 shows a reference relationship (103) between three picture types. For example, the P picture (102a) can be encoded using the encoded I picture (100) as a reference picture. As shown in FIG. 1, the B pictures (101a to 101d) can be encoded using the encoded I picture (100) and / or the encoded P picture (102a) as a reference picture. Based on the principle of the present invention, the encoded B pictures (101a to 101d) can also be used as reference pictures for other B pictures to be encoded. For example, the B picture (101c) shown in FIG. 1 uses the other two B pictures (101b, 101d) as reference pictures.
図１に示すＩピクチャ（１００）、Ｂピクチャ（１０１ａ〜１０１ｄ）、Ｐピクチャ（１０２ａ、１０２ｂ）の各番号及び順序は、ピクチャの配置の一例を示しているに過ぎず、本発明を実現する上で必須要件ではない。特定の用途に応じて、どのような数のＩピクチャ、Ｂピクチャ、Ｐピクチャをどのような順序で用いてもよい。ＭＰＥＧ−４ Ｐａｒｔ １０ ＡＶＣ／Ｈ．２６４規格は、２つの参照ピクチャ間のＢピクチャの数又は２つのＩピクチャ間のピクチャの数に関して何の制約も課していない。
The numbers and order of the I picture (100), B picture (101a to 101d), and P picture (102a, 102b) shown in FIG. 1 merely show an example of the arrangement of pictures, and realize the present invention. Above is not a requirement. Any number of I-pictures, B-pictures, and P-pictures may be used in any order depending on the particular application. MPEG-4
図２に示すように、各ピクチャ（２００）は、好ましくは複数のスライス（２０２）に分割される。各スライス（２０２）は、一群のマクロブロック（２０１）を含んでいる。マクロブロック（２０１）は、一群の画素である。図２に示すように、好ましいマクロブロック（２０１）のサイズは、１６×１６画素である。 As shown in FIG. 2, each picture (200) is preferably divided into a plurality of slices (202). Each slice (202) includes a group of macroblocks (201). The macro block (201) is a group of pixels. As shown in FIG. 2, the preferred macroblock (201) size is 16 × 16 pixels.
図３（ａ）〜図３（ｆ）は、マクロブロックが更により小さいブロックに分割できることを示している。例えば、図３（ａ）〜図３（ｆ）に示すように、マクロブロックは、更に１６×８画素（図３ａの３００）、８×１６画素（図３ｂの３０１）、８×８画素（図３ｃの３０２）、８×４画素（図３ｄの３０３）、４×８画素（図３ｅの３０４）、４×４画素（図３ｆの３０５）等のブロックサイズに分割することができる。これらのより小さなブロックサイズは、好ましくは、動き補償アルゴリズムを有する時間的予測を行う幾つかの用途において用いられる。 FIGS. 3 (a) -3 (f) show that a macroblock can be divided into even smaller blocks. For example, as shown in FIGS. 3A to 3F, the macroblock is further divided into 16 × 8 pixels (300 in FIG. 3a), 8 × 16 pixels (301 in FIG. 3b), 8 × 8 pixels ( It can be divided into block sizes such as 302 in FIG. 3c, 8 × 4 pixels (303 in FIG. 3d), 4 × 8 pixels (304 in FIG. 3e), 4 × 4 pixels (305 in FIG. 3f), and the like. These smaller block sizes are preferably used in some applications that perform temporal prediction with motion compensation algorithms.
図４は、本発明の実施例として示す動き補償を有する時間的予測を用いたピクチャ構造の一例を示している。動き補償を有する時間的予測では、現在のピクチャであるピクチャＮ（４００）は、他のピクチャＮ−１（４０１）を移動することによって局所的に作る（model）ことができるとみなされる。ピクチャＮ−１（４０１）は、ピクチャＮ（４００）を符号化するための参照ピクチャであり、ピクチャＮ（４００）に対して時間的に前方にあっても後方にあってもよい。 FIG. 4 shows an example of a picture structure using temporal prediction with motion compensation shown as an embodiment of the present invention. In temporal prediction with motion compensation, it is assumed that the current picture, picture N (400), can be modeled locally by moving another picture N-1 (401). The picture N-1 (401) is a reference picture for encoding the picture N (400), and may be in front of or behind the picture N (400).
図４に示すように、各ピクチャは、好ましくは、マクロブロック（２０１ａ、２０１ｂ）を含むスライスに分割されている。ピクチャＮ−１（４０１）は、ピクチャＮ（４００）に示される画像（４０３）を含んでいる。図４に示すように、画像（４０３）は、ピクチャＮ（４００）では、ピクチャＮ−１（４０１）における位置とは異なる時間的位置（４０２）にある。ピクチャＮ（４００）の各マクロブロック（２０１ａ）の画像内容は、画像（４０３）がピクチャＮ（４００）における新たな時間的位置（４０２）に移動するために必要とされるピクチャＮ−１（４０１）の各マクロブロック（２０１ｂ）の画像内容の時間的動き量を推測することによって、ピクチャＮ−１（４０１）の対応するマクロブロック（２０１ｂ）の画像内容から予測符号化される。実際には、符号化している元の画像（４０２）ではなく、画像（４０２）とこの画像の予測画像（４０３）との間の予測誤差（４０４）が符号化されて、伝送される。 As shown in FIG. 4, each picture is preferably divided into slices containing macroblocks (201a, 201b). The picture N-1 (401) includes the image (403) shown in the picture N (400). As shown in FIG. 4, the picture (403) is in a temporal position (402) different from the position in the picture N-1 (401) in the picture N (400). The image content of each macroblock (201a) of picture N (400) is picture N-1 (needed for moving image (403) to a new temporal position (402) in picture N (400). 401), by predicting the amount of temporal motion of the image content of each macroblock (201b), predictive coding is performed from the image content of the corresponding macroblock (201b) of picture N-1 (401). Actually, the prediction error (404) between the image (402) and the predicted image (403) of this image is encoded and transmitted, not the original image (402) being encoded.
ピクチャＮ（４００）内の画像（４０２）に対して、時間的予測は、画像（４０３）がピクチャＮ（４００）内の新たな時間的位置（４０２）に移動するときに必要とされる時間的動き量を示す動きベクトルによって表すことができる。動き補償を有する時間的予測に使用される動きベクトル（４０６）は、符号化されて、伝送される必要がある。 For image (402) in picture N (400), temporal prediction is the time required when image (403) moves to a new temporal position (402) in picture N (400). It can be represented by a motion vector indicating the amount of target motion. The motion vector (406) used for temporal prediction with motion compensation needs to be encoded and transmitted.
図４は、ピクチャＮ（４００）内の画像（４０２）が、画像とこの画像の予測値間の予測誤差（４０４）と、関連する動きベクトル（４０６）とによって表現されることを示している。動きベクトルを用いた符号化の完全な方法は、特定の用途に応じて変更することができ、この変更は、当業者にとって容易である。 FIG. 4 shows that an image (402) in picture N (400) is represented by a prediction error (404) between the image and the predicted value of this image, and an associated motion vector (406). . The complete method of encoding with motion vectors can be modified depending on the specific application, and this modification is easy for those skilled in the art.
マクロブロックレベルのＡＦＦ符号化に関する理解を得るために、まず、ピクチャストリームにおけるピクチャレベルのＡＦＦ符号化の概要について説明する。インタレースシーケンスのフレームは、トップフィールドとボトムフィールドの２つのフィールドを含み、トップフィールドとボトムフィールドは、インタリーブされており、フィールド周期に対応する時間離れている。フィールド周期は、フレーム周期の半分である。ピクチャレベルのＡＦＦ符号化では、インタレースフレームの２つのフィールドを一緒に符号化してもよく、別々に符号化してもよい。これらの２つのフィールドを一緒に符号化する場合、フレームモード符号化を用いる。一方、これらの２つのフィールドを別々に符号化する場合は、フィールドモード符号化を用いる。 To gain an understanding of macroblock level AFF encoding, an overview of picture level AFF encoding in a picture stream will be described first. The frame of the interlace sequence includes two fields, a top field and a bottom field, and the top field and the bottom field are interleaved and are separated by a time corresponding to the field period. The field period is half the frame period. In picture level AFF coding, the two fields of an interlaced frame may be coded together or separately. If these two fields are encoded together, frame mode encoding is used. On the other hand, when these two fields are encoded separately, field mode encoding is used.
一方、固定フレーム／フィールド符号化では、ピクチャストリーム内のピクチャを１つのモードのみで符号化する。このモードは、フレームモードであってもフィールドモードであってもよい。多くの用途において、ピクチャレベルのＡＦＦ符号化では、エンコーダが、デジタルビデオ素材の内容に基づいて、フレームモード又はフィールドモードを選択して、ピクチャストリーム内の各ピクチャを符号化できるので、ピクチャレベルのＡＦＦ符号化は、固定フレーム／フィールド符号化よりも優れている。多くの場合、ＡＦＦ符号化は、固定フレーム／フィールド符号化に比べて、より良好な圧縮率を実現できる。 On the other hand, in fixed frame / field coding, a picture in a picture stream is coded in only one mode. This mode may be a frame mode or a field mode. In many applications, picture level AFF encoding allows an encoder to select a frame mode or a field mode based on the content of the digital video material to encode each picture in the picture stream, so that AFF coding is superior to fixed frame / field coding. In many cases, AFF coding can achieve a better compression rate than fixed frame / field coding.
本発明の実施例では、ピクチャにおけるより小さい部分に対して、ＡＦＦ符号化を行う。この小さい部分は、マクロブロックであってもよく、マクロブロックの対であってもよく、マクロブロックのグループであってもよい。各マクロブロック、マクロブロックの対、又はマクロブロックのグループ、若しくはスライスは、ピクチャ内の他のマクロブロックがどのようなモードで符号化されるかにかかわらず、フレームモードでもフィールドモードでも符号化することができる。これらの各ケースのＡＦＦ符号化について、以下に詳細に説明する。 In the embodiment of the present invention, AFF encoding is performed on a smaller part in a picture. This small portion may be a macroblock, a pair of macroblocks, or a group of macroblocks. Each macroblock, macroblock pair, or group of macroblocks, or slice is encoded in either frame mode or field mode, regardless of what mode the other macroblocks in the picture are encoded. be able to. AFF encoding in each of these cases will be described in detail below.
第１のケースでは、ＡＦＦ符号化を単一のマクロブロックに対して行う。マクロブロックをフレームモードで符号化する場合、マクロブロック内の２つのフィールドが一緒に符号化される。マクロブロックは、一旦フレームとして符号化されると、動き補償アルゴリズムを有する時間的予測に用いるために、図３ａ〜図３ｆに示すようなより小さなブロックに更に分割される。 In the first case, AFF encoding is performed on a single macroblock. When a macroblock is encoded in frame mode, the two fields within the macroblock are encoded together. Once the macroblock is encoded as a frame, it is further divided into smaller blocks as shown in FIGS. 3a-3f for use in temporal prediction with motion compensation algorithms.
なお、マクロブロックをフィールドモードで符号化する場合、図５に示すように、マクロブロック（５００）は、トップフィールド（５０１）とボトムフィールド（５０２）とに分割される。これらの２つのフィールドは、別々に符号化される。図５に示すマクロブロック（５００）は、Ｎ列Ｍ行の画素を有する。Ｎ及びＭの好ましい値は１６であり、この場合、マクロブロック（５００）は、１６×１６画素を含む。図５では、１行おきの画素にハッチングを施している。ハッチングされた領域は、マクロブロック（５００）のトップフィールドの画素の行を示し、ハッチングされていない領域は、マクロブロック（５００）のボトムフィールドの画素の行を示している。 When the macroblock is encoded in the field mode, the macroblock (500) is divided into a top field (501) and a bottom field (502) as shown in FIG. These two fields are encoded separately. The macroblock (500) shown in FIG. 5 has N columns and M rows of pixels. A preferred value for N and M is 16, in which case the macroblock (500) includes 16 × 16 pixels. In FIG. 5, every other row of pixels is hatched. The hatched area indicates a row of pixels in the top field of the macroblock (500), and the non-hatched area indicates a row of pixels in the bottom field of the macroblock (500).
図６ａ〜図６ｄに示すように、フィールドモードで符号化する画素は、４つの更なるブロックに分割することができる。１つのブロックは、単一のパリティを有する必要がある。この単一のパリティの要件のために、ブロックをトップフィールドとボトムフィールドから構成することができない。すなわち、ブロックは、単一のパリティのフィールドを含む必要がある。したがって、図６ａ〜図６ｄに示すように、フィールドモードマクロブロックは、１６×８画素（図６ａ：６００）、８×８画素（図６ｂ：６０１）、４×８画素（図６ｃ：６０２）、４×４画素（図６ｄ：６０３）に分割することができる。図６ａ〜図６ｄは、各ブロックが単一のパリティのフィールドを含んでいることを示している。 As shown in FIGS. 6a to 6d, the pixels to be encoded in the field mode can be divided into four further blocks. One block needs to have a single parity. Because of this single parity requirement, a block cannot be composed of a top field and a bottom field. That is, the block needs to contain a single parity field. Accordingly, as shown in FIGS. 6a to 6d, the field mode macroblock has 16 × 8 pixels (FIG. 6a: 600), 8 × 8 pixels (FIG. 6b: 601), and 4 × 8 pixels (FIG. 6c: 602). It can be divided into 4 × 4 pixels (FIG. 6d: 603). 6a-6d show that each block contains a single parity field.
次に、マクロブロックの対に対するＡＦＦ符号化について説明する。マクロブロックの対に対するＡＦＦ符号化は、対ベースのＡＦＦ符号化（pair based AFF coding）と呼ばれることもある。図６ａ〜図６ｄに示すブロックサイズと、図３ａ〜図３ｆに示すブロックサイズとを比較することにより、フィールドモードによって符号化するブロックは、フレームモードによって符号化するマクロブロックより、分割できるブロックパターンが少ないことがわかる。単一のパリティの要件のために、フィールドモードで符号化するマクロブロックでは、１６×１６画素、８×１６画素のブロックサイズを用いることができない。これは、単一マクロブロックベースのＡＦＦ符号化は、フィールドモード符号化が強く望まれる幾つかのシーケンス又は用途においては、好ましくないことを意味している。フィールドモードでのマクロブロックの符号化の性能を保証するために、幾つかの用途では、フィールドモードで符号化するマクロブロックが、フレームモードで符号化するマクロブロックと同じブロックサイズのブロックを有することが望まれる。これは、単一のマクロブロックに対してではなく、マクロブロックの対に対してＡＦＦ符号化を行うことによって実現することができる。 Next, AFF encoding for a pair of macroblocks will be described. AFF coding for a pair of macroblocks is sometimes referred to as pair based AFF coding. By comparing the block sizes shown in FIGS. 6a to 6d with the block sizes shown in FIGS. 3a to 3f, a block pattern that can be divided by a field mode can be divided from a macro block that is encoded by a frame mode. It can be seen that there are few. Due to the requirement of a single parity, a block size of 16 × 16 pixels or 8 × 16 pixels cannot be used in a macroblock coded in the field mode. This means that single macroblock based AFF coding is not preferred in some sequences or applications where field mode coding is highly desired. In order to guarantee the performance of encoding macroblocks in field mode, in some applications, the macroblocks encoded in field mode have blocks of the same block size as the macroblocks encoded in frame mode. Is desired. This can be achieved by performing AFF coding on a pair of macroblocks rather than on a single macroblock.
図７は、本発明の実施例に基づき、一対のマクロブロックに対するＡＦＦ符号化において用いることができる、マクロブロックの対（７００）を示している。マクロブロックの対（７００）をフレームモードで符号化する場合、この対（７００）は、２つのフレームベースのマクロブロックとして符号化される。ここでは、各マクロブロックにおいて、各マクロブロックの２つのフィールドを一緒に符号化する。マクロブロックは、一旦フレームとして符号化された後、動き補償アルゴリズムを有する時間的予測に用いるために図３ａ〜図３ｆに示すより小さなブロックに更に分割される。 FIG. 7 shows a macroblock pair (700) that can be used in AFF coding for a pair of macroblocks, according to an embodiment of the present invention. When a macroblock pair (700) is encoded in frame mode, the pair (700) is encoded as two frame-based macroblocks. Here, in each macroblock, the two fields of each macroblock are encoded together. Once the macroblock is encoded as a frame, it is further divided into smaller blocks as shown in FIGS. 3a-3f for use in temporal prediction with motion compensation algorithms.
一方、マクロブロックの対（７００）をフィールドモードで符号化する場合、図８に示すように、マクロブロックの対（７００）は、１６×１６画素のブロックである１つのトップフィールド（８００）と、１６×１６画素のブロックである１つのボトムフィールド（８０１）とに分割される。そして、２つのフィールドは、別々に符号化される。図８に示すように、マクロブロックの対（７００）における各マクロブロックは、それぞれＮ＝１６の列とＭ＝１６の行を有する。したがって、マクロブロックの対（７００）のサイズは、１６×３２画素となる。図８では、１行おきの画素にハッチングを施している。ハッチングされた領域は、マクロブロックのトップフィールド内の画素の行を示し、ハッチングされていない領域は、マクロブロックのボトムフィールド内の画素の行を示している。トップフィールドブロック（８００）と、ボトムフィールドブロック（８０１）は、図３ａ〜図３ｆに示すブロックサイズの何れかに分割することができる。 On the other hand, when the macroblock pair (700) is encoded in the field mode, as shown in FIG. 8, the macroblock pair (700) includes one top field (800) that is a block of 16 × 16 pixels. Are divided into one bottom field (801) which is a block of 16 × 16 pixels. The two fields are then encoded separately. As shown in FIG. 8, each macroblock in the macroblock pair (700) has N = 16 columns and M = 16 rows, respectively. Therefore, the size of the macroblock pair (700) is 16 × 32 pixels. In FIG. 8, every other row of pixels is hatched. The hatched area indicates a row of pixels in the top field of the macroblock, and the non-hatched area indicates a row of pixels in the bottom field of the macroblock. The top field block (800) and the bottom field block (801) can be divided into any of the block sizes shown in FIGS. 3a to 3f.
本発明の実施例では、マクロブロックの対（７００）のＡＦＦ符号化において、２つのスキャンパス（scanning path）が可能である。スキャンパスは、ピクチャにおけるマクロブロックの対（７００）に対する符号化の順序を決定する。図９は、マクロブロックの対（７００）に対するＡＦＦ符号化のための２つの可能なスキャンパスを示している。スキャンパスの１つは、水平スキャンパス（９００）である。水平スキャンパス（９００）では、ピクチャ（２００）のマクロブロックの対（７００）は、図９に示すように、まず、左から右へ、そして上から下へ符号化される。もう１つのスキャンパスは、垂直スキャンパス（９０１）である。垂直スキャンパス（９０１）では、ピクチャ（２００）のマクロブロックの対（７００）は、図９に示すように、まず、上から下へ、そして左から右へ符号化される。フレームモード符号化では、まず、マクロブロックの対（７００）のトップマクロブロックが符号化され、次に、ボトムマクロブロックが符号化される。フィールドモード符号化では、マクロブロックの対（７００）のトップフィールドマクロブロックが符号化され、次に、ボトムフィールドマクロブロックが符号化される。 In an embodiment of the present invention, two scanning paths are possible in AFF encoding of a macroblock pair (700). Scan campus determines the coding order for macroblock pairs (700) in a picture. FIG. 9 shows two possible scan paths for AFF encoding for a macroblock pair (700). One of the scan paths is the horizontal scan path (900). In the horizontal scan path (900), the macroblock pair (700) of the picture (200) is first encoded from left to right and from top to bottom as shown in FIG. Another scan path is a vertical scan path (901). In the vertical scan path (901), the macroblock pair (700) of the picture (200) is first encoded from top to bottom and from left to right as shown in FIG. In frame mode coding, first the top macroblock of a pair of macroblocks (700) is coded and then the bottom macroblock is coded. In field mode encoding, the top field macroblock of a macroblock pair (700) is encoded, and then the bottom field macroblock is encoded.
本発明の他の実施例では、一対のマクロブロックに対するＡＦＦ符号化を、図１０に示すように、４個以上の隣り合うマクロブロックのグループ（９０２）のＡＦＦ符号化に拡張する。マクロブロックのグループに対するＡＦＦ符号化は、グループベースのＡＦＦ符号化（pair based AFF coding）と呼ばれることもある。ここでは、マクロブロックの対のスキャンに用いたものと同様のスキャンパスである水平スキャンパス（９００）と垂直スキャンパス（９０１）を用いて、隣り合うマクロブロックのグループ（９０２）を符号化する。なお、図１０に示す実施例では、４個のマクロブロックを示しているが、これより多いマクロブロックによりマクロブロックのグループを構成してもよい。 In another embodiment of the present invention, AFF encoding for a pair of macroblocks is extended to AFF encoding for a group of four or more adjacent macroblocks (902), as shown in FIG. AFF coding for a group of macroblocks is sometimes referred to as group-based AFF coding. Here, a group (902) of adjacent macroblocks is encoded using a horizontal scan path (900) and a vertical scan path (901) that are the same scan paths used for scanning a pair of macroblocks. . In the embodiment shown in FIG. 10, four macroblocks are shown. However, a macroblock group may be configured by more macroblocks.
４個のマクロブロックのグループ（９０２）をフレームモードで符号化する場合、マクロブロックのグループは、４フレームベースのマクロブロック（four frame-based macroblocks）として符号化される。各マクロブロックにおいて、各マクロブロック内の２つのフィールドは一緒に符号化される。マクロブロックは、フレームとして符号化された後、動き補償アルゴリズムを有する時間的予測に用いるために図３ａ〜図３ｆに示すより小さなブロックに更に分割される。 When encoding a group of four macroblocks (902) in frame mode, the group of macroblocks is encoded as four frame-based macroblocks. In each macroblock, the two fields within each macroblock are encoded together. After being encoded as a frame, the macroblock is further divided into smaller blocks as shown in FIGS. 3a-3f for use in temporal prediction with motion compensation algorithms.
一方、例えば、４個のマクロブロックのグループ（９０２）をフィールドモードで符号化する場合、マクロブロックのグループ（９０２）は、３２×１６画素のブロックである１つのトップフィールドと、３２×１６画素のブロックである１つのボトムフィールドとに分割される。そして、２つのフィールドは、別々に符号化される。これにより、トップフィールドブロック及びボトムフィールドブロックは、マクロブロックに分割できるようになる。各マクロブロックは、図３ａ〜図３ｆに示す可能なブロックサイズの１つに分割することができる。この処理は、図８に示す処理と同様であるので、この実施例を説明する図は省略する。 On the other hand, for example, when a group of four macroblocks (902) is encoded in the field mode, the macroblock group (902) includes one top field that is a block of 32 × 16 pixels and 32 × 16 pixels. Are divided into one bottom field which is a block. The two fields are then encoded separately. As a result, the top field block and the bottom field block can be divided into macro blocks. Each macroblock can be divided into one of the possible block sizes shown in FIGS. 3a-3f. Since this process is the same as the process shown in FIG. 8, a diagram for explaining this embodiment is omitted.
マクロブロックレベルのＡＦＦ符号化において、好ましくは、ピクチャのビットストリームに、フレーム／フィールドフラグビットを設け、各マクロブロックを符号化する際に、フレームモードとフィールドモードの何れのモードを用いたかを示すようにする。このビットストリームは、図１１に示すように、各マクロブロックに関する情報をビットストリーム内に含んでいる。例えば、ビットストリームには、ピクチャヘッダ（１１０）と、ラン情報（１１１）と、マクロブロックタイプ情報（１１３）とを含ませることができる。ＡＦＦ符号化を個々のマクロブロックに対して行う場合は、ビットストリームにおける各マクロブロックの前にフレーム／フィールドフラグ（１１２）を設けることが好ましい。マクロブロックの対に対してＡＦＦ符号化を行う場合は、フレーム／フィールドフラグ（１１２）は、ビットストリームにおけるマクロブロックの各対の前に設けることが好ましい。そして、マクロブロックのグループに対してＡＦＦ符号化を行う場合は、フレーム／フィールドフラグ（１１２）は、ビットストリームにおけるマクロブロックの各グループの前に設けることが好ましい。一実施例においては、フレームモードを用いる場合、フレーム／フィールドフラグ（１１２）ビットを０とし、フィールドモードを用いる場合は、これを１とする。他の実施例として、フレームモードを用いる場合、フレーム／フィールドフラグ（１１２）ビットを１とし、フィールドモードを用いる場合は、これを０としてもよい。 In macroblock level AFF encoding, preferably, a frame / field flag bit is provided in a picture bitstream to indicate which mode of frame mode or field mode was used when encoding each macroblock. Like that. As shown in FIG. 11, this bit stream includes information on each macro block in the bit stream. For example, the bitstream can include a picture header (110), run information (111), and macroblock type information (113). When AFF encoding is performed on individual macroblocks, it is preferable to provide a frame / field flag (112) before each macroblock in the bitstream. When AFF encoding is performed on a pair of macroblocks, the frame / field flag (112) is preferably provided before each pair of macroblocks in the bitstream. When AFF encoding is performed on a group of macroblocks, the frame / field flag (112) is preferably provided before each group of macroblocks in the bitstream. In one embodiment, the frame / field flag (112) bit is set to 0 when the frame mode is used, and is set to 1 when the field mode is used. As another embodiment, the frame / field flag (112) bit may be set to 1 when the frame mode is used, and may be set to 0 when the field mode is used.
本発明の他の実施例として、マクロブロックレベルのＡＦＦ符号化において、エンコーダがマクロブロックを分割するためのブロックサイズを決定する方法を説明する。理想的なブロックサイズを決定する方法は、以下に限定されるものではないが、好ましくは、バイアス又はレート歪み（rate distortion：以下、ＲＤという。）による又はよらない予測誤差の絶対値和（sum absolute difference：以下、ＳＡＤという。）に基づいて行う。例えば、ＳＡＤにより、可能なブロックサイズの性能を調べ、その結果に基づいて理想的なブロックサイズを選択する。バイアス又はＲＤによるＳＡＤに基づく決定を行うことは、当業者には容易である。 As another embodiment of the present invention, a method of determining a block size for an encoder to divide a macro block in macro block level AFF coding will be described. The method for determining the ideal block size is not limited to the following, but is preferably a sum of absolute values of prediction errors (sum) that may or may not be due to bias or rate distortion (RD). absolute difference: hereinafter referred to as SAD). For example, the performance of a possible block size is examined by SAD, and an ideal block size is selected based on the result. It is easy for those skilled in the art to make a decision based on SAD by bias or RD.
本発明の実施例では、フレーム及びフィールドベースの各マクロブロックは、マクロブロックレベルのＡＦＦ符号化において、イントラ符号化又はインター符号化することができる。イントラ符号化では、マクロブロックは、他のマクロブロックを時間的に参照することなく符号化される。一方、インター符号化では、動き補償を有する時間的予測を用いて、マクロブロックを符号化する。 In an embodiment of the present invention, each frame and field-based macroblock can be intra-coded or inter-coded in macroblock level AFF coding. In intra coding, a macroblock is coded without reference to other macroblocks in time. On the other hand, in inter coding, a macroblock is coded using temporal prediction with motion compensation.
インター符号化を用いる場合、１６×１６画素、１６×８画素、８×１６画素又は８×８画素のサイズのブロックは、それ自体の参照ピクチャを有することができる。ブロックは、フレームベースのマクロブロックであっても、フィールドベースのマクロブロックであってもよい。ＭＰＥＧ−４ Ｐａｒｔ １０ ＡＶＣ／Ｈ．２６４規格では、２つの参照ピクチャではなく、複数の参照ピクチャを用いることができる。複数の参照ピクチャを用いることによって、エンコーダは、符号化するブロックに最も一致した参照ピクチャのブロックを検出することができ、動き補償アルゴリズムを有する時間的予測の性能を向上させることができる。参照ピクチャは、フレームバッファ及びフィールドバッファに記憶され、符号化する現在のピクチャからの時間的距離に基づいて、参照フレーム番号及び参照フィールド番号が割り当てられている。記憶されている参照ピクチャが現在のピクチャに近い程、その参照ピクチャが選択される可能性が高い。フィールドモード符号化では、ブロック用の参照ピクチャは、参照フレームバッファ又は参照フィールドバッファの何れかにおける、いかなる参照ピクチャのトップフィールド及びボトムフィールドの何れであってもよい。
When using inter coding, a block of
フレーム又はフィールドベースのマクロブロック内の各ブロックは、それ自体の動きベクトルを有することができる。動きベクトルは、空間的に予測符号化される。本発明の実施例では、インター符号化において、各ブロックに対して予測動きベクトル（prediction motion vector：以下、ＰＭＶという。）も算出する。そして、各ブロックのＰＭＶ間の代数的な差分と、そのブロックに関連した動きベクトルが算出され、符号化される。これにより、動きベクトルの圧縮ビットが生成される。 Each block within a frame or field-based macroblock can have its own motion vector. The motion vector is spatially predictive encoded. In the embodiment of the present invention, a prediction motion vector (hereinafter referred to as PMV) is also calculated for each block in inter coding. Then, an algebraic difference between the PMVs of each block and a motion vector related to the block are calculated and encoded. As a result, compressed bits of the motion vector are generated.
図１２を用いて、マクロブロック内のブロックに関するＰＭＶの様々な好ましい算出法を説明する。図１２に示す現在のブロックＥは、隣接するブロックＡ、Ｂ、Ｃ、Ｄと同様に、インター符号化される。以後、特に明示する場合を除いて、ブロックＥを現在のブロックと呼び、ブロックＡ、Ｂ、Ｃ、Ｄをこれに隣接するブロックと呼ぶ。ブロックＥのＰＭＶは、隣接するブロックの動きベクトルから導出される。図１２に示す実施例では、隣接するブロックは、ブロックＡ、Ｂ、Ｃ、Ｄである。ブロックＥのＰＭＶを算出する好ましい方法としては、ブロックＡ、Ｂ、Ｃ、Ｄの動きベクトルのメジアンを算出する方法、これらの動きベクトルの平均値を算出する方法、これらの動きベクトルの加重平均値を算出する方法等がある。ブロックＡ、Ｂ、Ｃ、Ｄの各ブロックは、フレームモードであってもフィールドモードであってもよい。 Various preferred methods for calculating the PMV relating to the blocks in the macroblock will be described with reference to FIG. The current block E shown in FIG. 12 is inter-coded in the same manner as the adjacent blocks A, B, C, and D. Hereinafter, unless otherwise specified, the block E is referred to as the current block, and the blocks A, B, C, and D are referred to as adjacent blocks. The PMV of block E is derived from the motion vector of the adjacent block. In the embodiment shown in FIG. 12, the adjacent blocks are blocks A, B, C, and D. As a preferable method of calculating the PMV of the block E, a method of calculating the median of the motion vectors of the blocks A, B, C, and D, a method of calculating an average value of these motion vectors, and a weighted average value of these motion vectors There is a method of calculating. Each of the blocks A, B, C, and D may be in frame mode or field mode.
ブロックＥのＰＭＶを算出する他の好ましい方法として、ＹＥＳ／ＮＯ法がある。ＹＥＳ／ＮＯ法の原理では、ブロックＥのＰＭＶの計算にその動きベクトルを含ませるために、ブロックは、ブロックＥと同じフレームモード又はフィールドモードである必要がある。例えば、図１２に示すブロックＥがフレームモードである場合、ブロックＥのＰＭＶの計算にブロックＡの動きベクトルを含ませるためには、ブロックＡもフレームモードである必要がある。ブロックＥに隣接するブロックの１つがブロックＥと異なる符号化モードで符号化されている場合は、そのブロックの動きベクトルは、ブロックＥのＰＭＶの計算においては用いられない。 Another preferred method for calculating the PMV of block E is the YES / NO method. The principle of the YES / NO method requires that the block be in the same frame mode or field mode as block E in order to include its motion vector in the calculation of block E's PMV. For example, when the block E shown in FIG. 12 is in the frame mode, the block A needs to be in the frame mode in order to include the motion vector of the block A in the calculation of the PMV of the block E. If one of the blocks adjacent to block E is encoded in a different encoding mode than block E, the motion vector of that block is not used in the calculation of block E's PMV.
また、ブロックＥのＰＭＶの計算には、「常時法（always method）」を用いることもできる。常時法では、ブロックＡ、Ｂ、Ｃ、Ｄは、フレームモード又はフィールドモードの何れによって符号化されているかにかかわらず、常にブロックＥのＰＭＶの計算に用いられる。ブロックＥがフレームモードであり、隣接するブロックがフィールドモードである場合、ブロックＥのＰＭＶの計算を行う前に、隣接するブロックの垂直成分を２倍にする。逆に、ブロックＥがフィールドモードであり、隣接するブロックがフレームモードである場合、ブロックＥのＰＭＶの計算を行う前に、隣接するブロックの垂直成分を２で除算する。 Also, an “always method” can be used to calculate the PMV of block E. In the regular method, blocks A, B, C, and D are always used to calculate the PMV of block E, regardless of whether they are encoded in frame mode or field mode. If block E is in frame mode and the adjacent block is in field mode, the vertical component of the adjacent block is doubled before calculating the block E PMV. Conversely, if block E is in field mode and the adjacent block is in frame mode, the vertical component of the adjacent block is divided by 2 before calculating the PMV of block E.
また、マクロブロックが対ベースのＡＦＦ符号化又はグループベースのＡＦＦ符号化を用いて符号化されている場合は、「選択法（selective method）」を用いて、ブロックＥのＰＭＶの計算を行うことができる。選択法では、フレームベースのブロックは、参照フレームを指すフレームベースの動きベクトルを有する。ブロックには、参照フィールドを指すフィールドベースの動きベクトルも割り当てられている。フィールドベースの動きベクトルは、そのブロックのフレームベースの動きベクトルの垂直動きベクトル成分を２で除算したものである。参照フィールド番号は、参照フレーム番号を２倍にしたものである。フィールドベースのブロックは、参照フィールドを指すフィールドベースの動きベクトルを有する。このブロックには、参照フレームを指すフレームベースの動きベクトルも割り当てられている。フレームベースの動きベクトルは、そのブロックのフィールドベースのベクトルの垂直動きベクトル成分を２倍にしたものである。参照フレーム番号は、参照フィールド番号を２で除算したものである。 Also, if the macroblock is encoded using pair-based AFF encoding or group-based AFF encoding, the “selective method” is used to calculate the PMV of block E Can do. In the selection method, the frame-based block has a frame-based motion vector that points to the reference frame. The block is also assigned a field-based motion vector that points to the reference field. A field-based motion vector is the vertical motion vector component of the block's frame-based motion vector divided by two. The reference field number is a doubled reference frame number. A field-based block has a field-based motion vector that points to a reference field. This block is also assigned a frame-based motion vector that points to the reference frame. A frame-based motion vector is a double of the vertical motion vector component of the field-based vector of the block. The reference frame number is the reference field number divided by two.
選択法によってブロックのＰＭＶを算出する方法について、図１２を用いて説明する。マクロブロックの対ベースのＡＦＦ符号化において、マクロブロック内の各ブロックは、マクロブロックの対における第２のマクロブロック内の同じ幾何学的位置にある相手方のブロック（companion block）に関連している。図１２において、ブロックＥに隣接するブロック（Ａ、Ｂ、Ｃ、Ｄ）は、ブロックＥと同じフレームモード又はフィールドモードで符号化されている場合もあり、そうでない場合もある。したがって、次のような規則が適用される。 A method for calculating the PMV of a block by the selection method will be described with reference to FIG. In a macroblock pair-based AFF encoding, each block in a macroblock is associated with a companion block in the same geometric position in a second macroblock in the macroblock pair. . In FIG. 12, the blocks (A, B, C, D) adjacent to the block E may or may not be encoded in the same frame mode or field mode as the block E. Therefore, the following rules apply:
ブロックＥがフレームモードであり、隣接するブロックもフレームモードである場合、隣接するブロックのフレームベースの動きベクトルがそのままブロックＥのＰＭＶの算出に用いられる。 When the block E is in the frame mode and the adjacent block is also in the frame mode, the frame-based motion vector of the adjacent block is directly used for calculating the PMV of the block E.
ブロックＥがフレームモードであり、隣接するブロックがフィールドモードである場合、ブロックＥのＰＭＶの算出には、次のような規則が適用される。隣接するブロック（例えば、ブロックＡ）及びその相手方のフィールドベースのブロックが同じ参照フィールドを有する場合、ブロックＥのＰＭＶの算出には、これらの２つのブロックに割り当てられたフレームベースの動きベクトルの平均値を用いる。ＰＭＶの算出に用いられる参照フレーム番号は、隣接するブロックの参照フィールド番号を２で除算したものである。一方、隣接するブロック及びその相手方のフィールドベースのブロックが異なる参照フィールドを有する場合、隣接するブロックは、ブロックＥのＰＭＶの算出には用いることができない。 When the block E is in the frame mode and the adjacent block is in the field mode, the following rules are applied to calculate the PMV of the block E. If an adjacent block (e.g., block A) and its counterpart field-based block have the same reference field, the calculation of the PMV for block E includes the average of the frame-based motion vectors assigned to these two blocks. Use the value. The reference frame number used for calculating the PMV is obtained by dividing the reference field number of an adjacent block by 2. On the other hand, if an adjacent block and its counterpart field-based block have different reference fields, the adjacent block cannot be used to calculate the PMV of block E.
ブロックＥがフィールドモードであり、隣接するブロックがフレームモードである場合、ブロックＥのＰＭＶの算出には、次のような規則を適用することができる。隣接するブロック（例えば、ブロックＡ）及びその相手方のフレームベースのブロックが同じ参照フレームを有する場合、ブロックＥのＰＭＶの算出には、これらの２つのブロックに割り当てられたフィールドベースの動きベクトルの平均値を用いる。ＰＭＶの算出に用いられる参照フィールド番号は、隣接するブロックの参照フレーム番号を２倍にしたものである。
一方、隣接するブロック及びその相手方のフィールドベースのブロックが異なる参照フレームを有する場合、隣接するブロックは、ブロックＥのＰＭＶの算出には用いることができない。
When the block E is in the field mode and the adjacent block is in the frame mode, the following rules can be applied to calculate the PMV of the block E. If an adjacent block (e.g., block A) and its counterpart frame-based block have the same reference frame, the calculation of the PMV for block E includes the average of the field-based motion vectors assigned to these two blocks Use the value. The reference field number used for calculating the PMV is a double of the reference frame number of the adjacent block.
On the other hand, if an adjacent block and its counterpart field-based block have different reference frames, the adjacent block cannot be used to calculate the PMV of block E.
ブロックＥがフィールドモードであり、隣接するブロックもフィールドモードである場合、隣接するブロックのフィールドベースの動きベクトルがそのままブロックＥのＰＭＶの算出に用いられる。 When the block E is in the field mode and the adjacent block is also in the field mode, the field-based motion vector of the adjacent block is directly used for calculating the PMV of the block E.
ブロックのＰＭＶの算出に選択法を用いる場合、別の好ましいオプションを用いることもできる。図１２において、ブロックＥに隣接するブロック（Ａ、Ｂ、Ｃ、Ｄ）は、ブロックＥと同じフレームモード又はフィールドモードで符号化されている場合もあり、そうでない場合もある。したがって、選択法における別の好ましいオプションでは、次のような規則が適用される。 If a selection method is used to calculate the block PMV, another preferred option may be used. In FIG. 12, the blocks (A, B, C, D) adjacent to the block E may or may not be encoded in the same frame mode or field mode as the block E. Thus, in another preferred option in the selection method, the following rules apply:
ブロックＥがフレームモードであり、隣接するブロックもフレームモードである場合、隣接するブロックのフレームベースの動きベクトルがそのままブロックＥのＰＭＶの算出に用いられる。 When the block E is in the frame mode and the adjacent block is also in the frame mode, the frame-based motion vector of the adjacent block is directly used for calculating the PMV of the block E.
ブロックＥがフレームモードであり、隣接するブロックがフィールドモードである場合、ブロックＥのＰＭＶの算出には、隣接するブロック及びその相手方のフレームベースのブロックの加重平均値を用いる。重み係数は、隣接するブロック及びその相手方のフィールドの参照フィールド番号に基づいて決定される。 When the block E is in the frame mode and the adjacent block is in the field mode, the weighted average value of the adjacent block and its counterpart frame-based block is used to calculate the PMV of the block E. The weighting factor is determined based on the reference field number of the adjacent block and its counterpart field.
ブロックＥがフィールドモードであり、隣接するブロックがフレームモードである場合、ブロックＥのＰＭＶの算出には、隣接するブロック及びその相手方のフレームベースのブロックの加重平均値を用いる。重み係数は、隣接するブロック及びその相手方のフィールドの参照フィールド番号に基づいて決定される。 When the block E is in the field mode and the adjacent block is in the frame mode, the weighted average value of the adjacent block and its counterpart frame-based block is used to calculate the PMV of the block E. The weighting factor is determined based on the reference field number of the adjacent block and its counterpart field.
ブロックＥがフィールドモードであり、隣接するブロックもフィールドモードである場合、隣接するブロックのフィールドベースの動きベクトルがそのままブロックＥのＰＭＶの算出に用いられる。 When the block E is in the field mode and the adjacent block is also in the field mode, the field-based motion vector of the adjacent block is directly used for calculating the PMV of the block E.
ブロックのＰＭＶを算出する他の好ましい方法としては、「代替選択法（alt selective method）」がある。この方法は、単一のマクロブロックに対するＡＦＦ符号化、対ベースのＡＦＦ符号化、グループベースのＡＦＦ符号化の何れにも適用することができる。この方法では、各ブロックに対し、そのブロックの水平座標及び垂直座標を表す水平インデックス番号及び垂直インデックス番号を割り当てる。各ブロックには、水平フィールド座標及び垂直フィールド座標も割り当てられる。ブロックの水平フィールド座標は、そのブロックの水平座標と同じである。また、トップフィールドマクロブロック内のブロックについては、垂直フィールド座標は、ブロックの垂直座標の１／２であり、トップフィールド極性（top field polarity）が割り当てられる。ボトムフィールドマクロブロック内のブロックについては、垂直フィールド座標は、ブロックの垂直座標から４を減算し、結果を２で除算することにより得られる。このブロックには、ボトムフィールド極性（bottom field polarity）も割り当てられる。２つのブロックに異なるフィールド極性を割り当てることにより、同じ水平フィールド座標及び垂直フィールド座標を有するがフィールド極性が異なる２つのブロックが存在することになる。したがって、所定のブロックの座標から、フィールド座標及びそのフィールド極性を算出でき、この逆の演算も行うことができる。 Another preferred method for calculating the PMV of a block is an “alt selective method”. This method can be applied to any of AFF encoding, pair-based AFF encoding, and group-based AFF encoding for a single macroblock. In this method, a horizontal index number and a vertical index number representing the horizontal coordinate and vertical coordinate of the block are assigned to each block. Each block is also assigned a horizontal field coordinate and a vertical field coordinate. The horizontal field coordinates of a block are the same as the horizontal coordinates of that block. For the blocks in the top field macroblock, the vertical field coordinates are ½ of the vertical coordinates of the blocks, and a top field polarity is assigned. For blocks within a bottom field macroblock, the vertical field coordinates are obtained by subtracting 4 from the block's vertical coordinates and dividing the result by 2. This block is also assigned a bottom field polarity. By assigning different field polarities to the two blocks, there will be two blocks with the same horizontal and vertical field coordinates but different field polarities. Therefore, the field coordinates and the field polarity can be calculated from the coordinates of a predetermined block, and the reverse operation can be performed.
代替選択法について、図１２を用いて説明する。ここでは、ブロックＥのＰＭＶを算出する。この具体例におけるブロックのサイズであるブロックＥの水平サイズを４で割った値をｂｘとする。ブロックＥがフレームモードであるかフィールドモードであるかに応じて、ブロックＥのＰＭＶは、次のようにして算出される。 The alternative selection method will be described with reference to FIG. Here, the PMV of block E is calculated. A value obtained by dividing the horizontal size of the block E, which is the size of the block in this specific example, by 4, is bx. Depending on whether the block E is in the frame mode or the field mode, the PMV of the block E is calculated as follows.
ブロックＥがフレームモードであるとし、ブロックＥの水平座標及び垂直座標を（ｘ，ｙ）とする。ブロックＥに隣接するブロックは、次のように定義することができる。ブロックＡは、座標（ｘ−１，ｙ）を有するブロックである。ブロックＢは、座標（ｘ，ｙ−１）を有するブロックである。ブロックＤは、座標（ｘ−１，ｙ−１）を有するブロックである。ブロックＣは、座標（ｘ＋ｂｘ＋１，ｙ−１）を有するブロックである。ブロックＡ、Ｂ、Ｃ、Ｄの何れかがフィールドモードである場合、その垂直動きベクトルは、予測に用いる前に２倍され、その参照フレーム番号は、その参照フィールド番号を２で除算することによって算出される。 Assume that the block E is in the frame mode, and the horizontal and vertical coordinates of the block E are (x, y). A block adjacent to block E can be defined as follows. Block A is a block having coordinates (x-1, y). Block B is a block having coordinates (x, y-1). The block D is a block having coordinates (x-1, y-1). Block C is a block having coordinates (x + bx + 1, y−1). If any of the blocks A, B, C, D is in field mode, its vertical motion vector is doubled before being used for prediction and its reference frame number is divided by 2 by its reference field number Calculated.
ここで、ブロックＥをトップフィールドモード又はボトムフィールドモードとし、ブロックＥの水平フィールド座標及び垂直フィールド座標を（ｘｆ，ｙｆ）と表すとする。この場合、ブロックＥに隣接するブロックは、次のように定義することができる。ブロックＡは、座標（ｘｆ−１，ｙｆ）を有するブロックである。ブロックＢは、座標（ｘｆ，ｙｆ−１）を有するブロックである。ブロックＤは、座標（ｘｆ−１，ｙｆ−１）を有するブロックである。ブロックＣは、座標（ｘｆ＋ｂｘ＋１，ｙｆ−１）を有するブロックである。ブロックＡ、Ｂ、Ｃ、Ｄの何れかがフレームモードである場合、その垂直動きベクトルは、予測に用いる前に２で除算され、その参照フィールド番号は、その参照フレーム番号を２倍にすることによって算出される。 Here, the block E is set to the top field mode or the bottom field mode, and the horizontal field coordinate and the vertical field coordinate of the block E are represented as (xf, yf). In this case, the block adjacent to the block E can be defined as follows. Block A is a block having coordinates (xf-1, yf). Block B is a block having coordinates (xf, yf-1). Block D is a block having coordinates (xf-1, yf-1). The block C is a block having coordinates (xf + bx + 1, yf−1). If any of blocks A, B, C, D is in frame mode, its vertical motion vector is divided by 2 before being used for prediction, and its reference field number doubles its reference frame number. Is calculated by
ブロックのＰＭＶを決定する上述した全ての方法においては、スキャンパスは、水平スキャンパスである。なお、スキャンパスは、垂直スキャンパスであってもよい。この場合、現在のブロックＥに隣接するブロックは、図１３に示すような構成となる。垂直スキャンパスでは、現在のブロックＥのＰＭＶの算出に隣接する全てのブロックの情報を用いることができるので、幾つかの用途においては、垂直スキャンパスを用いることが望ましい。 In all the methods described above for determining the PMV of a block, the scan path is a horizontal scan path. Note that the scan path may be a vertical scan path. In this case, the block adjacent to the current block E is configured as shown in FIG. In the vertical scan path, it is desirable to use the vertical scan path in some applications, since the information of all blocks adjacent to the current block E PMV calculation can be used.
本発明の他の実施例として、方向分割予測（directional segmentation prediction）を説明する。方向分割予測では、１６×８画素ブロック及び８×１６画素ブロックのみがそのＰＭＶの算出に適用されるという規則を有する。これらの規則は、全てのＰＭＶの算出法において、これらのブロックサイズに対して適用される。これらの規則について、図１２を用いて説明する。これらの規則のそれぞれにおいて、現在のブロックＥのＰＭＶが算出される。 As another embodiment of the present invention, directional segmentation prediction will be described. The direction division prediction has a rule that only the 16 × 8 pixel block and the 8 × 16 pixel block are applied to the calculation of the PMV. These rules are applied to these block sizes in all PMV calculation methods. These rules will be described with reference to FIG. In each of these rules, the PMV of the current block E is calculated.
まず、１６×１６画素のブロックは、上ブロック（upper block）と下ブロック（lower block）とから構成される。上ブロックは、上側の８行の画素を含む。下ブロックは、下側の８行の画素を含む。以下の説明では、図１２に示すブロックＥは、１６×８画素のブロックであるとする。１６×８画素ブロックを有する上ブロックについては、ブロックＢがブロックＥと同じ参照ピクチャを有している場合は、このブロックＢを用いて、ブロックＥのＰＭＶを予測する。これ以外の場合は、メジアン予測を用いて、ブロックＥのＰＭＶを予測する。１６×８画素ブロックを有する下ブロックについては、ブロックＡがブロックＥと同じ参照ピクチャを有している場合は、このブロックＡを用いて、ブロックＥのＰＭＶを予測する。これ以外の場合は、メジアン予測を用いて、ブロックＥのＰＭＶを予測する。 First, a 16 × 16 pixel block is composed of an upper block and a lower block. The upper block includes the upper eight rows of pixels. The lower block includes the lower eight rows of pixels. In the following description, it is assumed that the block E shown in FIG. 12 is a 16 × 8 pixel block. For the upper block having a 16 × 8 pixel block, when the block B has the same reference picture as the block E, the block B is used to predict the PMV of the block E. In other cases, the PMV of block E is predicted using median prediction. For the lower block having a 16 × 8 pixel block, when the block A has the same reference picture as the block E, the block A is used to predict the PMV of the block E. In other cases, the PMV of block E is predicted using median prediction.
８×１６画素のブロックは、右ブロック（right block）と左ブロックに（left block）に分割されている。右ブロック及び左ブロックは、何れも８×１６画素から構成される。以下での説明では、図１２に示すブロックＥは、８×１６画素のブロックであるとする。左ブロックについては、ブロックＡがブロックＥと同じ参照ピクチャを有している場合は、このブロックＡを用いて、ブロックＥのＰＭＶを予測する。これ以外の場合は、メジアン予測を用いて、ブロックＥのＰＭＶを予測する。右ブロックについては、ブロックＣがブロックＥと同じ参照ピクチャを有している場合は、このブロックＣを用いて、ブロックＥのＰＭＶを予測する。これ以外の場合は、メジアン予測を用いて、ブロックＥのＰＭＶを予測する。 The 8 × 16 pixel block is divided into a right block and a left block. Both the right block and the left block are composed of 8 × 16 pixels. In the following description, it is assumed that the block E shown in FIG. 12 is an 8 × 16 pixel block. For the left block, when block A has the same reference picture as block E, the block A is used to predict the PMV of block E. In other cases, the PMV of block E is predicted using median prediction. For the right block, when block C has the same reference picture as block E, the block C is used to predict the PMV of block E. In other cases, the PMV of block E is predicted using median prediction.
１６×８画素ブロック及び８×１６画素ブロックの両方について、ブロックＡ、Ｂ、Ｃは、現在のブロックＥとは異なる符号化モード（フレームモード又はフィールドモード）を有している可能性がある。両方のブロックサイズに対して、次のような規則が適用される。ブロックＥがフレームモードであり、ブロックＡ、Ｂ、Ｃの何れかがフィールドモードである場合、ブロックＡ、Ｂ、Ｃの何れかの参照フレーム番号は、その参照フィールド番号を２で除算することによって算出される。ブロックＥがフィールドモードであり、ブロックＡ、Ｂ、Ｃの何れかがフレームモードである場合、ブロックＡ、Ｂ、Ｃの何れかの参照フィールド番号は、その参照フレーム番号を２倍にすることによって算出される。 For both the 16 × 8 pixel block and the 8 × 16 pixel block, blocks A, B, and C may have a different encoding mode (frame mode or field mode) than the current block E. The following rules apply for both block sizes: When block E is in frame mode and any of blocks A, B, and C is in field mode, the reference frame number of any of blocks A, B, and C is obtained by dividing the reference field number by two. Calculated. When block E is in field mode and any of blocks A, B, and C is in frame mode, the reference field number of any of blocks A, B, and C is doubled by the reference frame number. Calculated.
本発明の他の実施例では、Ｐピクチャ内のマクロブロックは、ＡＦＦ符号化においてはスキップすることができる。マクロブロックをスキップすると、そのデータは、ピクチャの符号化では、伝送されない。Ｐピクチャ内のスキップされたマクロブロックは、フレームとして時間的に最も近く符号化された参照ピクチャの同じ位置（co-located）のマクロブロックをコピーすることによって復元される。同じ位置のマクロブロックは、上述したＰＭＶを用いた動き補償により、又は動きベクトルを用いずに定義されたマクロブロックである。Ｐピクチャ内のスキップされるマクロブロックには、次のような規則が適用される。ＡＦＦ符号化がマクロブロック毎に実行されている場合、スキップされるマクロブロックは、フレームモードである。ＡＦＦ符号化がマクロブロック対に対して行われている場合、及びこの対の両方のマクロブロックがスキップされる場合、これらのマクロブロックはフレームモードである。また、マクロブロック対における一方のマクロブロックのみがスキップされる場合、このブロックの符号化モードは、同じマクロブロック対におけるスキップされないマクロブロックと同じフレームモード又はフィールドモードである。ＡＦＦ符号化がマクロブロックのグループに対して行われ、グループ内の全てのマクロブロックがスキップされる場合、これらの全てのマクロブロックはフレームモードである。また、少なくとも１つのスキップされないマクロブロックがある場合、マクロブロックのグループ内のスキップされるマクロブロックは、同じグループ内のスキップされないマクロブロックと同じフレームモード又はフィールドモードである。 In another embodiment of the present invention, macroblocks in a P picture can be skipped in AFF coding. If a macroblock is skipped, the data is not transmitted in picture coding. A skipped macroblock in a P picture is recovered by copying the co-located macroblock of the reference picture that was most temporally encoded as a frame. The macroblock at the same position is a macroblock defined by the above-described motion compensation using PMV or without using a motion vector. The following rules are applied to the skipped macroblock in the P picture. When AFF encoding is performed for each macroblock, the skipped macroblock is in frame mode. These macroblocks are in frame mode if AFF encoding is being performed on the macroblock pair and if both macroblocks in this pair are skipped. When only one macroblock in a macroblock pair is skipped, the encoding mode of this block is the same frame mode or field mode as a macroblock not skipped in the same macroblock pair. If AFF encoding is performed on a group of macroblocks and all macroblocks in the group are skipped, all these macroblocks are in frame mode. Also, if there is at least one non-skipped macroblock, the skipped macroblock in the group of macroblocks is in the same frame mode or field mode as the non-skipped macroblock in the same group.
マクロブロックのスキップに関する他の方法を説明する。マクロブロック対をスキップする場合、これをフレームモードにするかフィールドモードにするかは、左側に隣接するマクロブロック対の符号化モードに従う。左側のマクロブロック対を用いることができない場合は、上側のマクロブロック対の符号化モードに従う。左側のマクロブロック対も上側のマクロブロック対も用いることができない場合は、スキップされるマクロブロックは、フレームモードに設定される。 Another method for skipping macroblocks will be described. When a macroblock pair is skipped, whether it is set to frame mode or field mode depends on the encoding mode of the macroblock pair adjacent on the left side. When the left macroblock pair cannot be used, the encoding mode of the upper macroblock pair is followed. If neither the left macroblock pair nor the upper macroblock pair can be used, the skipped macroblock is set to frame mode.
本発明の他の実施例では、Ｂピクチャ内のマクロブロックに対してダイレクトモード符号化（direct mode coding）を行う。ダイレクトモード符号化では、Ｂピクチャは、前方動きベクトル及び後方動きベクトルの２つの動きベクトルを有する。各動きベクトルは、参照ピクチャを指している。前方動きベクトルと後方動きベクトルの２つの動きベクトルは、同じ時間的方向を指すこともできる。Ｂピクチャ内のマクロブロックに対するダイレクトモード符号化では、マクロブロックの前方動きベクトル及び後方動きベクトルは、後方参照ピクチャにおいて同じ位置とされたブロックから算出される。後方参照ピクチャにおいて同じ位置とされたブロックは、フレームモードで符号化されていても、フィールドモードで符号化されていてもよい。Ｂピクチャ内のマクロブロックに対するダイレクトモード符号化では、次のような規則が適用される。 In another embodiment of the present invention, direct mode coding is performed on a macroblock in a B picture. In direct mode coding, a B picture has two motion vectors, a forward motion vector and a backward motion vector. Each motion vector points to a reference picture. The two motion vectors, the forward motion vector and the backward motion vector, can also point in the same temporal direction. In the direct mode encoding for the macroblock in the B picture, the forward motion vector and the backward motion vector of the macroblock are calculated from the blocks at the same position in the backward reference picture. The blocks at the same position in the backward reference picture may be coded in the frame mode or the field mode. In the direct mode coding for the macroblock in the B picture, the following rules are applied.
同じ位置とされたブロックがフレームモードであり、現在のダイレクトモードマクロブロックもフレームモードである場合、ダイレクトモードマクロブロック内のブロックに関する２つの動きベクトルは、この同じ位置とされたブロックから算出される。前方参照フレームは、同じ位置とされたブロックによって使用されるフレームの１つである。後方参照フレームは、同じ位置とされたブロックが存在するフレームと同じフレームである。 If the block at the same position is in frame mode and the current direct mode macroblock is also in frame mode, the two motion vectors for the blocks in the direct mode macroblock are calculated from this block at the same position. . The forward reference frame is one of the frames used by the same positioned block. The backward reference frame is the same frame as the frame in which the block at the same position exists.
同じ位置とされたブロックがフレームモードであり、現在のダイレクトモードマクロブロックがフィールドモードである場合、現在のダイレクトモードマクロブロックに関する２つの動きベクトルは、同じ位置とされたブロックの動きベクトルの垂直成分を２で除算することによって算出される。前方参照フィールドは、同じ位置とされたブロックによって用いられる参照フレームにおける同じパリティのフィールドである。後方参照フィールドは、同じ位置とされたブロックが存在する後方参照フレームにおける同じパリティのフィールドである。 If the block at the same position is in frame mode and the current direct mode macroblock is in field mode, the two motion vectors for the current direct mode macroblock are the vertical components of the motion vector of the block at the same position Is divided by two. The forward reference field is a field of the same parity in the reference frame used by the block located at the same position. The backward reference field is a field having the same parity in the backward reference frame in which a block at the same position exists.
同じ位置とされたブロックがフィールドモードであり、現在のダイレクトモードマクロブロックもフィールドモードである場合、現在のダイレクトモードマクロブロックに関する２つの動きベクトルは、同じフィールドのパリティを有する同じ位置とされたブロックから算出される。前方参照フィールドは、同じ位置とされたブロックによって用いられるフィールドである。後方参照フィールドは、同じ位置とされたブロックが存在する同じフィールドである。 If the block at the same position is in field mode and the current direct mode macroblock is also in field mode, the two motion vectors for the current direct mode macroblock are the same position block with the same field parity Is calculated from The forward reference field is a field used by blocks located at the same position. The backward reference field is the same field in which the block at the same position exists.
同じ位置とされたブロックがフィールドモードであり、現在のダイレクトモードマクロブロックがフレームモードである場合、現在のダイレクトモードマクロブロックに関する２つの動きベクトルは、同じ位置とされたブロックの動きベクトルの垂直成分を２倍にすることによって算出される。前方参照フレームは、同じ位置とされたブロックによって用いられるフィールドを含むフレームである。後方参照フィールドは、同じ位置とされたブロックが存在するフィールドを含むフレームである。 If the block at the same position is in field mode and the current direct mode macroblock is in frame mode, the two motion vectors for the current direct mode macroblock are the vertical components of the motion vector of the block at the same position Is calculated by doubling. A forward reference frame is a frame that includes fields used by blocks that are co-located. The backward reference field is a frame including a field in which a block at the same position exists.
変形例として、ダイレクトモードブロックの符号化モードを、強制的に、同じ位置とされたブロックのフレームモード又はフィールドモードと同じ符号化モードにしてもよい。この場合、ダイレクトモードブロックについて同じ位置とされたブロックがフレームモードである場合は、ダイレクトモードブロックも同様にフレームモードにされる。ダイレクトモードブロックのフレームベースの２つの動きベクトルは、同じ位置とされたブロックのフレームベースの前方動きベクトルから導出される。前方参照フレームは、同じ位置とされたブロックによって用いられる。後方参照フレームは、同じ位置とされたブロックが存在するフレームである。 As a modification, the encoding mode of the direct mode block may be forcibly set to the same encoding mode as the frame mode or the field mode of the block at the same position. In this case, when the block set to the same position with respect to the direct mode block is the frame mode, the direct mode block is similarly set to the frame mode. The two frame-based motion vectors of the direct mode block are derived from the frame-based forward motion vector of the block in the same position. The forward reference frame is used by the block at the same position. The backward reference frame is a frame in which blocks located at the same position exist.
ここで、ダイレクトモードブロックについて同じ位置とされたブロックがフィールドモードである場合、ダイレクトモードブロックもフィールドモードにされる。ダイレクトモードブロックのフィールドベースの２つの動きベクトルは、同じ位置とされたブロックのフィールドベースの前方動きベクトルから導出される。前方参照フィールドは、同じ位置とされたブロックによって用いられる。後方参照フィールドは、同じ位置とされたブロックが存在するフィールドである。 Here, when the block which is set to the same position with respect to the direct mode block is the field mode, the direct mode block is also set to the field mode. The two field-based motion vectors of the direct mode block are derived from the field-based forward motion vector of the co-located block. The forward reference field is used by the same co-located block. The backward reference field is a field in which blocks having the same position exist.
本発明の他の実施例においては、ＡＦＦ符号化において、Ｂピクチャ内のマクロブロックをスキップすることもできる。Ｂピクチャ内のスキップされるマクロブロックは、符号化変換係数情報を用いることなく、通常のダイレクトモードマクロブロックとして復元される。Ｂピクチャにおいてスキップされるマクロブロックには、次のような規則が適用される。ＡＦＦ符号化がマクロブロック毎に実行される場合、スキップされるマクロブロックは、フレームモードで符号化してもよく、そのブロックの後方参照ピクチャにおいて同じ位置とされたブロックと同じフィールドモード又はフレームモードで符号化してもよい。ＡＦＦ符号化がマクロブロック対に対して行われている場合、及びこの対の両方のマクロブロックがスキップされる場合、これらのマクロブロックは、フレームモードで符号化してもよく、そのブロックの後方参照ピクチャにおいて同じ位置とされたマクロブロックの対と同じフィールドモード又はフレームモードで符号化してもよい。また、マクロブロック対における一方のマクロブロックのみがスキップされる場合、このブロックの符号化モードは、同じマクロブロック対におけるスキップされないマクロブロックと同じフレームモード又はフィールドモードである。ＡＦＦ符号化がマクロブロックのグループに対して行われ、グループ内の全てのマクロブロックがスキップされる場合、これらの全てのマクロブロックはフレームモードで符号化してもよく、そのブロックの後方参照ピクチャにおいて同じ位置とされたマクロブロックのグループと同じフィールドモード又はフレームモードで符号化してもよい。また、少なくとも１つのスキップされないマクロブロックがある場合、マクロブロックのグループ内のスキップされるマクロブロックは、同じグループ内のスキップされないマクロブロックと同じフレームモード又はフィールドモードである。また、少なくとも１つのスキップされないマクロブロックがある場合、マクロブロックのグループ内のスキップされるマクロブロックは、同じグループ内のスキップされないマクロブロックと同じフレームモード又はフィールドモードである。 In another embodiment of the present invention, macroblocks in a B picture can be skipped in AFF encoding. The skipped macroblock in the B picture is restored as a normal direct mode macroblock without using encoded transform coefficient information. The following rules are applied to macroblocks that are skipped in a B picture. When AFF encoding is performed for each macroblock, the skipped macroblock may be encoded in frame mode and in the same field mode or frame mode as the block located at the same position in the back reference picture of that block. It may be encoded. If AFF encoding has been performed on a macroblock pair, and if both macroblocks in this pair are skipped, these macroblocks may be encoded in frame mode, and the back reference of that block Encoding may be performed in the same field mode or frame mode as a pair of macroblocks located at the same position in a picture. When only one macroblock in a macroblock pair is skipped, the encoding mode of this block is the same frame mode or field mode as a macroblock not skipped in the same macroblock pair. If AFF encoding is performed on a group of macroblocks and all macroblocks in the group are skipped, all these macroblocks may be encoded in frame mode and in the back reference picture of that block Encoding may be performed in the same field mode or frame mode as the group of macroblocks at the same position. Also, if there is at least one non-skipped macroblock, the skipped macroblock in the group of macroblocks is in the same frame mode or field mode as the non-skipped macroblock in the same group. Also, if there is at least one non-skipped macroblock, the skipped macroblock in the group of macroblocks is in the same frame mode or field mode as the non-skipped macroblock in the same group.
上述のように、ブロックは、イントラ符号化（intra coded）することもできる。イントラブロックは、空間予測符号化される。マクロブロックレベルのＡＦＦ符号化においては、マクロブロックについて２つの可能なイントラ符号化モードがある。第１のモードは、イントラ４×４モードであり、第２のモードは、イントラ１６×１６モードである。何れの場合も、各画素値は、隣接するブロックから実際に復元された画素値を用いて予測される。画素値を予測することにより、より高度な圧縮が実現できる。イントラ４×４モード及びイントラ１６×１６モードのそれぞれについて、以下に詳細に説明する。
As mentioned above, the block can also be intra coded. Intra blocks are spatially predictive encoded. In macroblock level AFF coding, there are two possible intra coding modes for a macroblock. The first mode is an
イントラ４×４モードでは、図１４に示すように、４×４画素ブロック内の画素の予測は、その画素の左側及び上側の画素に基づいて行われる。図１４では、４×４画素ブロック内の１６個の画素にａ〜ｐのラベルを付している。更に、図１４では、隣接する画素にＡ〜Ｐのラベルを付している。すなわち、隣接する画素は、大文字で表している。図１５に示すように、イントラ４×４符号化においては、９個の異なる予測方向が存在する。これらは、垂直方向（０）、水平方向１（１）、ＤＣ予測（モード２）、対角左下方向（３）、対角右下方向（４）、垂直寄り左方向（５）、水平寄り下方向（６）垂直寄り右方向（７）、及び水平寄り上方向（８）である。ＤＣ予測では、隣接する画素の全てを平均して、特定の画素値を予測する。
In the
一方、イントラ１６×１６モードでは、４個の異なる予測方向が存在する。予測方向は、予測モードとも呼ばれる。これらの予測方向とは、垂直予測（０）、水平予測（１）、ＤＣ予測、及び平面予測である。平面予測については、ここでは説明しない。 On the other hand, in the intra 16 × 16 mode, there are four different prediction directions. The prediction direction is also called a prediction mode. These prediction directions are vertical prediction (0), horizontal prediction (1), DC prediction, and plane prediction. Planar prediction will not be described here.
イントラブロック及びその隣接するブロックは、フレームモードで符号化してもフィールドモードで符号化してもよい。復元されたブロックに対しては、イントラ予測が実行される。復元されたブロックは、ブロックが実際にフレームモードで符号化されているか、フィールドモードで符号化されているかにかかわらず、フレームモードでもフィールドモードでも表現できる。イントラ予測では、復元されたブロックの画素のみが用いられるため、次のような規則が適用される。
The intra block and its adjacent blocks may be encoded in the frame mode or the field mode. Intra prediction is performed on the restored block. The recovered block can be expressed in either frame mode or field mode, regardless of whether the block is actually encoded in frame mode or field mode. In intra prediction, since only the pixels of the restored block are used, the following rules are applied.
４×４画素のブロック又は１６×１６画素のブロックがフレームモードである場合、そのブロックの画素値の予測に用いる隣接する画素は、フレーム構造内にある。４×４画素のブロック又は１６×１６画素のブロックがフィールドモードである場合、そのブロックの画素値の予測に用いる隣接する画素は、同じフィールドパリティを有するフィールドモードである。 When a 4 × 4 pixel block or a 16 × 16 pixel block is in frame mode, adjacent pixels used for prediction of the pixel value of the block are in the frame structure. When a 4 × 4 pixel block or a 16 × 16 pixel block is in the field mode, adjacent pixels used for prediction of the pixel value of the block are in the field mode having the same field parity.
４×４画素ブロックの選択されたイントラ予測モード（intra_prediction_mode）は、隣接したブロックの予測モードに対し、高い相関性を有している。これを図１６Ａに示す。図１６Ａでは、ブロックＡ及びブロックＢがブロックＣに隣接している。ここでは、ブロックＣの予測モードを決定しようとしている。図１６Ｂは、ビットストリーム内のイントラ予測情報の順序を示している。ブロックＡ及びブロックＢの予測モードが既知である（ブロックＡ又はブロックＢ、若しくはこの両方がスライスの外側（outside）にある場合を含む。）場合、ブロックＣの最も可能性が高い予測モード（most_probable_prediction mode）が与えられる。ブロックＡ又はブロックＢの何れかが「外側（outside）」にある場合、最も可能性が高い予測モードは、ＤＣ予測（モード２）である。これ以外の場合は、最も可能性が高い予測モードは、ブロックＡ及びブロックＢに用いた予測モードの最小値（minimum）である。隣接するブロックが１６×１６イントラモードで符号化されている場合、予測モードは、ＤＣ予測モードである。隣接するブロックがイントラマクロブロックではない場合、通常及び制約されたイントラ更新（constrained intra update）では、予測モードは「モード２：ＤＣ予測」である。 The selected intra prediction mode (intra_prediction_mode) of the 4 × 4 pixel block has high correlation with the prediction mode of the adjacent block. This is shown in FIG. 16A. In FIG. 16A, block A and block B are adjacent to block C. Here, the prediction mode of block C is to be determined. FIG. 16B shows the order of the intra prediction information in the bitstream. If the prediction modes of block A and block B are known (including when block A and / or block B are both outside the slice), the most likely prediction mode for block C (most_probable_prediction) mode) is given. If either block A or block B is “outside”, the most likely prediction mode is DC prediction (mode 2). In other cases, the most likely prediction mode is the minimum value (minimum) of the prediction modes used for block A and block B. When adjacent blocks are encoded in 16 × 16 intra mode, the prediction mode is a DC prediction mode. When the adjacent block is not an intra macroblock, the prediction mode is “mode 2: DC prediction” in normal and constrained intra update.
４×４画素ブロックのための予測モード番号を伝えるために、第１のパラメータuse_most_probable_modeが伝送される。このパラメータは、１ビットのコードワードによって表され、０又は１の値をとる。use_most_probable_modeが１の場合、最も可能性が高いモードが用いられる。これ以外の場合、０〜７の値をとることができる更なるパラメータremaining_mode_selectorが３ビットコードワードとして伝送される。このコードワードは、remaining_mode_selector値のバイナリ表現である。予測モード番号は、次のようにして算出される。
if(remaining_mode_selector < most_probable_mode)
intra_pred_mode = remaining_mode_selector ;
else
intra_pred_mode = remaining_mode_selector+1 ;
したがって、ブロックＣに割り当てられる予測モードの順序は、まず、最も可能性が高いモードであり、次に残りのモードが昇順（ascending order）に割り当てられる。
A first parameter use_most_probable_mode is transmitted to convey the prediction mode number for the 4 × 4 pixel block. This parameter is represented by a 1-bit code word and takes a value of 0 or 1. If use_most_probable_mode is 1, the most likely mode is used. Otherwise, a further parameter remaining_mode_selector that can take values from 0 to 7 is transmitted as a 3-bit codeword. This codeword is a binary representation of the remaining_mode_selector value. The prediction mode number is calculated as follows.
if (remaining_mode_selector <most_probable_mode)
intra_pred_mode = remaining_mode_selector;
else
intra_pred_mode = remaining_mode_selector + 1;
Therefore, the order of prediction modes assigned to block C is first the most likely mode, and then the remaining modes are assigned in ascending order.
本発明の実施例では、４×４画素ブロックのイントラ予測モード及び１６×１６画素ブロックのイントラ予測モードについて、次のような規則をイントラモード予測に適用する。ブロックＣ及びこれに隣接するブロックＡ、Ｂは、フレームモードであってもフィールドモードであってもよい。次の規則のうちの１つが適用される。以下に示す規則の説明では、図１６Ａ及び図１６Ｂを用いる。 In the embodiment of the present invention, the following rules are applied to intra mode prediction for the 4 × 4 pixel block intra prediction mode and the 16 × 16 pixel block intra prediction mode. Block C and adjacent blocks A and B may be in frame mode or field mode. One of the following rules applies: In the following description of the rules, FIGS. 16A and 16B are used.
規則１：ブロックＡ又はブロックＢがブロックＣと同じフレーム／フィールドモードである場合に限って、ブロックＡ又はブロックＢをブロックＣに隣接するブロックとして用いる。これ以外の場合、ブロックＡ及びブロックＢは、外側にあるとみなされる。 Rule 1: Block A or block B is used as a block adjacent to block C only if block A or block B is in the same frame / field mode as block C. Otherwise, block A and block B are considered outside.
規則２：ブロックＣがフィールド／フレーム符号化モードの何れであるかにかかわらず、ブロックＡ及びブロックＢをブロックＣに隣接するブロックとして用いる。 Rule 2: Block A and block B are used as blocks adjacent to block C regardless of whether the block C is in the field / frame coding mode.
規則３：ブロックＣがフレームモードで符号化され、座標（ｘ，ｙ）を有する場合、ブロックＡを座標（ｘ，ｙ−１）のブロックとし、ブロックＢを座標（ｘ−１，ｙ）のブロックとする。一方、ブロックＣがフィールドモードで符号化され、座標（ｘ，ｙ）を有する場合、ブロックＡを座標（ｘ，ｙ−１）を有し、ブロックＣと同じフィールド極性を有するフィールドとし、ブロックＢを座標（ｘ−１，ｙ）を有し、ブロックＣと同じフィールド極性を有するフィールドとする。 Rule 3: If block C is encoded in frame mode and has coordinates (x, y), block A is the block at coordinates (x, y-1) and block B is at the coordinates (x-1, y) Let it be a block. On the other hand, if block C is encoded in field mode and has coordinates (x, y), block A is a field having coordinates (x, y-1) and the same field polarity as block C, and block B Is a field having coordinates (x-1, y) and the same field polarity as block C.
規則４：この規則は、マクロブロック対のみに適用される。図１６Ｂに示す符号３、６、７、９、１２、１３、１１、１４、１５が付されたブロックの予測モードを復号する場合、上側及び左側に接するブロックは、現在のブロックＥと同じマクロブロック内にある。一方、符号１、４、５が付されたブロックの予測モードを復号する場合、上側のブロック（ブロックＡ）は、現在のマクロブロック対とは異なるマクロブロック対内にある。また、ブロック２、８、１０が付されたブロックの予測モードを復号する場合、左側のブロック（ブロックＢ）は、異なるマクロブロック対内にある。符号０が付されたブロックの予測モードを復号する場合、上側のブロックも左側のブロックも異なるマクロブロック対内にある。フィールド復号モードにおけるマクロブロックについては、符号０、１、４、５、２、８、１０が付されたブロックに隣接するブロックは、次のように定義される。
Rule 4: This rule applies only to macroblock pairs. When decoding the prediction modes of the blocks denoted by
図１７Ａに示すように、上側のマクロブロック対（１７０）がフィールドモードで復号されている場合、トップフィールドマクロブロック（１７３）における符号０、１、４、５が付されたブロックについては、上側のマクロブロック対（１７０）のトップフィールドマクロブロック（１７３）における符号１０、１１、１４、１５が付されたブロックのそれぞれを現在のマクロブロック対（１７１）の上側に隣接するブロックとみなす。また、図１７Ａに示すように、ボトムフィールドマクロブロック（１７４）における符号０、１、４、５が付されたブロックについては、上側のマクロブロック対（１７０）のボトムフィールドマクロブロック内の符号１０、１１、１４、１５が付されたブロックのそれぞれを現在のマクロブロック対（１７１）の上側に隣接するブロックとみなす。
As shown in FIG. 17A, when the upper macroblock pair (170) is decoded in the field mode, the upper field macroblock (173) is marked with the
また、上側のマクロブロック対（１７０）がフレームモードで復号されている場合、図１７Ｂに示すように、トップフィールドマクロブロック（１７３）における符号０、１、４、５が付されたブロックについては、上側のマクロブロック対（１７０）のボトムフレームマクロブロック（１７６）における符号１０、１１、１４、１５が付されたブロックのそれぞれを現在のマクロブロック対（１７１）の上側に隣接するブロックとみなす。また、図１７Ｂに示すように、ボトムフィールドマクロブロック（１７４）における符号０、１、４、５が付されたブロックについては、上側のマクロブロック対（１７０）のボトムフレームマクロブロック（１７６）内の符号１０、１１、１４、１５が付されたブロックのそれぞれを現在のマクロブロック対（１７１）の上側に隣接するブロックとみなす。
In addition, when the upper macroblock pair (170) is decoded in the frame mode, as shown in FIG. 17B, the blocks with the
マクロブロック対（１７２）がフィールドモードで復号されている場合、図１７Ｃに示すように、トップフィールドマクロブロック（１７３）における符号０、２、８、１０が付されたブロックについては、左側のマクロブロック対（１７２）のトップフィールドマクロブロック（１７３）における符号５、７、１３、１５が付されたブロックのそれぞれを現在のマクロブロック対（１７１）の左側に隣接するブロックとみなす。また、図１７Ｃに示すように、ボトムフィールドマクロブロック（１７４）における符号０、２、８、１０が付されたブロックについては、左側のマクロブロック対（１７２）のボトムフィールドマクロブロック（１７４）における符号５、７、１３、１５が付されたブロックのそれぞれを現在のマクロブロック対（１７１）の左側に隣接するブロックとみなす。
When the macroblock pair (172) is decoded in the field mode, as shown in FIG. 17C, the macros on the left side of the blocks with the
左側のマクロブロック対（１７２）がフレームモードで復号されている場合、図１７Ｄに示すように、トップフィールドマクロブロック（１７３）における符号０、２、８、１０が付されたブロックについては、左側のマクロブロック対（１７２）のトップフレームマクロブロック（１７５）における符号５、７、１３、１５が付されたブロックのそれぞれを現在のマクロブロック対（１７１）の左側に隣接するブロックとみなす。また、図１７Ｄに示すように、ボトムフィールドマクロブロック（１７４）における符号０、２、８、１０が付されたブロックについては、左側のマクロブロック対（１７２）のボトムフレームマクロブロック（１７６）における符号５、７、１３、１５が付されたブロックのそれぞれを現在のマクロブロック対（１７１）の左側に隣接するブロックとみなす。
When the left macroblock pair (172) is decoded in the frame mode, as shown in FIG. 17D, the blocks assigned with
スライスの上側の境界におけるマクロブロック対については、左側のマクロブロック対（１７２）がフレーム復号モードである場合、フィールドマクロブロックを予測するために用いられるイントラモード予測値は、ＤＣ予測に設定される。 For the macroblock pair at the upper boundary of the slice, if the left macroblock pair (172) is in frame decoding mode, the intra mode prediction value used to predict the field macroblock is set to DC prediction. .
上述したイントラ符号化及びイントラモード予測に関する説明は、適応ブロック変換に拡張することができる。 The above description regarding intra coding and intra mode prediction can be extended to adaptive block transform.
本発明の他の実施例では、復元されたブロックに対し、ループフィルタリングを行う。復元されたブロックは、ブロックのフレーム／フィールド符号化モードにかかわらず、フレーム構造でもフィールド構造でも表すことができる。ループ（逆ブロック化）フィルタリングは、隣接するブロックの画素の加重平均を求める処理である。図１２を用いて、ループフィルタリングを説明する。図１２に示すブロックＥを復元するブロックとし、ブロックＡ、Ｂ、Ｃ、Ｄを隣接する復元されたブロックとし、これらのブロック全てがフレーム構造で表されているとする。ブロックＡ、Ｂ、Ｃ、Ｄ、Ｅは、それぞれフレーム符号化されていてもフィールド符号化されていてもよいため、次のような規則が適用される。 In another embodiment of the present invention, loop filtering is performed on the restored block. The recovered block can be represented in either a frame structure or a field structure regardless of the frame / field coding mode of the block. Loop (deblocking) filtering is a process for obtaining a weighted average of pixels in adjacent blocks. The loop filtering will be described with reference to FIG. Assume that the block E shown in FIG. 12 is a restored block, the blocks A, B, C, and D are neighboring restored blocks, and all these blocks are represented in a frame structure. Since the blocks A, B, C, D, and E may be frame-encoded or field-encoded, the following rules are applied.
規則１：ブロックＥがフレーム符号化されている場合、ループフィルタリングは、ブロックＥ及びこれに隣接するブロックＡ、Ｂ、Ｃ、Ｄの画素に亘って実行される。 Rule 1: When block E is frame-encoded, loop filtering is performed across the pixels of block E and adjacent blocks A, B, C, D.
規則２：ブロックＥがフィールド符号化されている場合、ループフィルタリングは、ブロックＥ及びこれに隣接するブロックＡ、Ｂ、Ｃ、Ｄのトップフィールド画素及びボトムフィールド画素に対して別々に実行される。 Rule 2: When block E is field-encoded, loop filtering is performed separately on the top field pixels and bottom field pixels of block E and blocks A, B, C, D adjacent to it.
本発明の他の実施例として、境界の画素を繰り返すことにより、復元されたフレームに対してパディング処理（Padding）を施すこともできる。境界ブロックは、フレームモードで符号化されていてもフィールドモードで符号化されていてもよいため、次のような規則が適用される。 As another embodiment of the present invention, padding processing (Padding) can be performed on the restored frame by repeating the pixels at the boundary. Since the boundary block may be encoded in the frame mode or the field mode, the following rules are applied.
規則１：境界ブロックの左側の垂直ライン又は右側の垂直ライン上の画素を必要に応じて繰り返す。 Rule 1: Repeat pixels on the left vertical line or right vertical line of the boundary block as necessary.
規則２：境界ブロックがフレーム符号化されている場合、境界ブロックの上側の水平ライン又は下側の水平ライン上の画素を繰り返す。 Rule 2: When the boundary block is frame-encoded, the pixels on the upper horizontal line or the lower horizontal line of the boundary block are repeated.
規則３：境界ブロックがフィールド符号化されている場合、境界ブロックの２つの上側の又は２つの下側の水平ライン（２つのフィールド）の画素を交互に繰り返す。 Rule 3: When the boundary block is field-encoded, the pixels on the two upper or two lower horizontal lines (two fields) of the boundary block are alternately repeated.
本発明の他の実施例では、エントロピ符号化の前に、２次元変換係数を１次元の一連の係数に変換する。スキャンパスは、ジグザグ状であっても非ジグザグ状であってもよい。ジグザグスキャンは、プログレッシブシーケンスに用いることが好ましいが、これを遅い動きのインタレースシーケンスに用いてもよい。非ジグザグスキャンは、インタレースシーケンスに用いることが好ましい。マクロブロックレベルのＡＦＦ符号化では、次のようなオプションを使用できる。 In another embodiment of the invention, the two-dimensional transform coefficients are transformed into a one-dimensional series of coefficients before entropy coding. The scan campus may be zigzag or non-zigzag. Although zigzag scanning is preferably used for progressive sequences, it may also be used for slow motion interlaced sequences. Non-zigzag scanning is preferably used for interlaced sequences. In macroblock level AFF coding, the following options can be used.
オプション１：フレームモードのマクロブロックにジグザグスキャンを用い、フィールドモードのマクロブロックには非ジグザグスキャンを用いる。 Option 1: Zigzag scan is used for frame mode macroblocks and non-zigzag scan is used for field mode macroblocks.
オプション２：フィールドモード及びフレームモードの両方のマクロブロックにジグザグスキャンを用いる。 Option 2: Use zigzag scanning for both field mode and frame mode macroblocks.
オプション３：フィールドモード及びフレームモードの両方のマクロブロックにジグザグスキャンを用いる。 Option 3: Use zigzag scanning for both field mode and frame mode macroblocks.
上述の説明は、本発明の実施の形態の一例を例示的に示したものであって、発明を完全に包括し限定することを意図したものではない。上述した記載に基づいて、多くの変形及び変更が可能である。 The above description shows an example of an embodiment of the present invention by way of example, and is not intended to completely encompass and limit the invention. Many variations and modifications are possible based on the above description.
上述の実施の形態は、本発明の原理及び幾つかの実際的な用途を例示的に示すために選択されたものである。上述の説明により、当業者は、様々な形態で本発明を利用することができ、個々の用途に応じて様々な変形例を想到することができる。本発明は、特許請求の範囲によって定義される。 The above-described embodiments have been chosen to exemplify the principles of the invention and some practical applications. From the above description, those skilled in the art can use the present invention in various forms, and various modifications can be conceived depending on individual applications. The invention is defined by the claims.
Claims (17)
上記ピクチャを複数の小さい部分に分割するステップと、
上記複数の小さい部分の少なくとも１つを選択的にフレーム符号化モードで一度に符号化し、及び該複数の小さい部分の少なくとも１つを選択的にフィールド符号化モードで一度に符号化し、符号化ピクチャを形成するステップと、
上記ピクチャが前方予測符号化ピクチャ又は両方向予測符号化ピクチャである場合に、上記少なくとも一つの小さな部分内の少なくとも一つのマクロブロックの符号化をスキップするステップとを有し、
上記複数の小さい部分のそれぞれは、１つのマクロブロックよりも大きなサイズを有することを特徴とする符号化方法。 In an encoding method for encoding a picture of an image sequence,
Dividing the picture into a plurality of smaller parts;
Coding at least one of the plurality of small portions selectively in a frame coding mode at a time, and selectively coding at least one of the plurality of small portions in a field coding mode at a time; Forming a step;
Skipping the encoding of at least one macroblock in the at least one small portion when the picture is a forward predictive encoded picture or a bidirectional predictive encoded picture;
Each of the plurality of small portions has a larger size than one macroblock.
上記ピクチャを複数の小さい部分に分割する手段と、
上記複数の小さい部分の少なくとも１つを選択的にフレーム符号化モードで一度に符号化し、及び該複数の小さい部分の少なくとも１つを選択的にフィールド符号化モードで一度に符号化し、符号化ピクチャを形成する手段と、
上記ピクチャが前方予測符号化ピクチャ又は両方向予測符号化ピクチャである場合に、上記少なくとも一つの小さな部分内の少なくとも一つのマクロブロックの符号化をスキップする手段とを有し、
上記複数の小さい部分のそれぞれは、１つのマクロブロックよりも大きなサイズを有することを特徴とする符号化装置。 In an encoding device for encoding a picture of an image sequence,
Means for dividing the picture into a plurality of smaller parts;
Coding at least one of the plurality of small portions selectively in a frame coding mode at a time, and selectively coding at least one of the plurality of small portions in a field coding mode at a time; Means for forming
Means for skipping the coding of at least one macroblock in the at least one small portion when the picture is a forward predictive coded picture or a bidirectional predictive coded picture;
Each of the plurality of small portions has a size larger than one macroblock.
上記複数の小さい部分の少なくとも１つをフレーム符号化モードで一度に復号し、及び該複数の小さい部分の少なくとも１つをフィールド符号化モードで一度に復号するステップと、
上記ピクチャが前方予測符号化ピクチャ又は両方向予測符号化ピクチャである場合に、符号化をスキップされた少なくとも一つのマクロブロックを検出するステップと、
上記スキップされた少なくとも一つのマクロブロックを再構成するステップと、
上記複数の復号された小さい部分と上記少なくとも一つの符号化をスキップされ再構成されたマクロブロックを用いて、復号ピクチャを構成するステップとを有し、
上記複数の小さい部分のそれぞれは、１つのマクロブロックよりも大きなサイズを有することを特徴とする復号方法。 In a decoding method for decoding an encoded picture having a plurality of small parts from a bitstream,
Decoding at least one of the plurality of small portions at a time in a frame coding mode and decoding at least one of the plurality of small portions at a time in a field coding mode;
Detecting at least one macroblock whose coding is skipped when the picture is a forward predictive coded picture or a bidirectional predictive coded picture;
Reconstructing the skipped at least one macroblock;
Using the plurality of decoded small portions and the at least one encoding skipped and reconstructed macroblock to form a decoded picture;
Each of the plurality of small portions has a larger size than one macroblock.
上記複数の小さい部分の少なくとも１つをフレーム符号化モードで一度に復号し、及び該複数の小さい部分の少なくとも１つをフィールド符号化モードで一度に復号する手段と、
上記ピクチャが前方予測符号化ピクチャ又は両方向予測符号化ピクチャである場合に、符号化をスキップされた少なくとも一つのマクロブロックを検出する手段と、
上記スキップされた少なくとも一つのマクロブロックを再構成する手段と、
上記複数の復号された小さい部分と上記少なくとも一つの符号化をスキップされ再構成されたマクロブロックを用いて、復号ピクチャを構成する手段とを有し、
上記複数の小さい部分のそれぞれは、１つのマクロブロックよりも大きなサイズを有することを特徴とする復号装置。 In a decoding device for decoding an encoded picture having a plurality of small parts from a bitstream,
Means for decoding at least one of the plurality of small portions at a time in a frame coding mode and decoding at least one of the plurality of small portions at a time in a field coding mode;
Means for detecting at least one macroblock skipped in coding when the picture is a forward predictive coded picture or a bidirectional predictive coded picture;
Means for reconstructing the skipped at least one macroblock;
Means for constructing a decoded picture using the plurality of decoded small portions and the macroblock reconstructed by skipping the at least one encoding,
Each of the plurality of small portions has a larger size than one macroblock.
Applications Claiming Priority (10)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US33300401P | 2001-11-21 | 2001-11-21 | |
US60/333,004 | 2001-11-21 | ||
US33392101P | 2001-11-27 | 2001-11-27 | |
US60/333,921 | 2001-11-27 | ||
US39573402P | 2002-07-12 | 2002-07-12 | |
US60/395,734 | 2002-07-12 | ||
US39816102P | 2002-07-23 | 2002-07-23 | |
US60/398,161 | 2002-07-23 | ||
US10/301,290 | 2002-11-20 | ||
US10/301,290 US6980596B2 (en) | 2001-11-27 | 2002-11-20 | Macroblock level adaptive frame/field coding for digital video content |
Related Parent Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2016055783A Division JP6507114B2 (en) | 2001-11-21 | 2016-03-18 | Adaptive frame / field coding at macroblock level of digital video content |
Publications (2)
Publication Number | Publication Date |
---|---|
JP2018139452A true JP2018139452A (en) | 2018-09-06 |
JP2018139452A5 JP2018139452A5 (en) | 2018-11-29 |
Family
ID=27540869
Family Applications (9)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2003548553A Pending JP2005510985A (en) | 2001-11-21 | 2002-11-21 | Adaptive frame / field coding at the macroblock level of digital video content |
JP2008234061A Pending JP2008295111A (en) | 2001-11-21 | 2008-09-11 | Adaptive frame/field coding in macro block level of digital video content |
JP2009244955A Expired - Lifetime JP5320254B2 (en) | 2001-11-21 | 2009-10-23 | Adaptive frame / field coding at the macroblock level of digital video content |
JP2012014662A Expired - Lifetime JP5697614B2 (en) | 2001-11-21 | 2012-01-26 | Adaptive frame / field coding at the macroblock level of digital video content |
JP2014240175A Pending JP2015062314A (en) | 2001-11-21 | 2014-11-27 | Adaptive frame/field coding in macro block level of digital video content |
JP2016055782A Expired - Lifetime JP6681758B2 (en) | 2001-11-21 | 2016-03-18 | Adaptive frame / field coding at macroblock level for digital video content |
JP2016055781A Pending JP2016106504A (en) | 2001-11-21 | 2016-03-18 | Adaptive frame/field coding in macro block level of digital video content |
JP2016055783A Expired - Lifetime JP6507114B2 (en) | 2001-11-21 | 2016-03-18 | Adaptive frame / field coding at macroblock level of digital video content |
JP2018110961A Pending JP2018139452A (en) | 2001-11-21 | 2018-06-11 | Adaptive frame/field coding in macro block level of digital video content |
Family Applications Before (8)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2003548553A Pending JP2005510985A (en) | 2001-11-21 | 2002-11-21 | Adaptive frame / field coding at the macroblock level of digital video content |
JP2008234061A Pending JP2008295111A (en) | 2001-11-21 | 2008-09-11 | Adaptive frame/field coding in macro block level of digital video content |
JP2009244955A Expired - Lifetime JP5320254B2 (en) | 2001-11-21 | 2009-10-23 | Adaptive frame / field coding at the macroblock level of digital video content |
JP2012014662A Expired - Lifetime JP5697614B2 (en) | 2001-11-21 | 2012-01-26 | Adaptive frame / field coding at the macroblock level of digital video content |
JP2014240175A Pending JP2015062314A (en) | 2001-11-21 | 2014-11-27 | Adaptive frame/field coding in macro block level of digital video content |
JP2016055782A Expired - Lifetime JP6681758B2 (en) | 2001-11-21 | 2016-03-18 | Adaptive frame / field coding at macroblock level for digital video content |
JP2016055781A Pending JP2016106504A (en) | 2001-11-21 | 2016-03-18 | Adaptive frame/field coding in macro block level of digital video content |
JP2016055783A Expired - Lifetime JP6507114B2 (en) | 2001-11-21 | 2016-03-18 | Adaptive frame / field coding at macroblock level of digital video content |
Country Status (10)
Country | Link |
---|---|
EP (1) | EP1449385B1 (en) |
JP (9) | JP2005510985A (en) |
KR (1) | KR101033398B1 (en) |
AU (1) | AU2002365338A1 (en) |
CA (1) | CA2468087C (en) |
DK (1) | DK1449385T3 (en) |
ES (5) | ES2545177T3 (en) |
MX (1) | MXPA04004724A (en) |
PT (5) | PT2271115E (en) |
WO (1) | WO2003047272A2 (en) |
Families Citing this family (34)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5914671A (en) | 1997-02-27 | 1999-06-22 | Micron Communications, Inc. | System and method for locating individuals and equipment, airline reservation system, communication system |
TR201802625T4 (en) * | 2001-11-06 | 2018-03-21 | Panasonic Ip Corp America | Motion picture coding method and motion picture decoding method. |
CN100452883C (en) | 2001-12-17 | 2009-01-14 | 微软公司 | Skip macroblock coding |
US7003035B2 (en) | 2002-01-25 | 2006-02-21 | Microsoft Corporation | Video coding methods and apparatuses |
JP2004088722A (en) | 2002-03-04 | 2004-03-18 | Matsushita Electric Ind Co Ltd | Motion picture encoding method and motion picture decoding method |
HUE045566T2 (en) | 2002-04-19 | 2020-01-28 | Panasonic Ip Corp America | Motion vector calculating method |
EP3324624B1 (en) * | 2002-04-19 | 2019-06-12 | Panasonic Intellectual Property Corporation of America | Motion vector calculating method |
US20040001546A1 (en) | 2002-06-03 | 2004-01-01 | Alexandros Tourapis | Spatiotemporal prediction for bidirectionally predictive (B) pictures and motion vector prediction for multi-picture reference motion compensation |
KR100693669B1 (en) * | 2003-03-03 | 2007-03-09 | 엘지전자 주식회사 | Determination of a reference picture for processing a field macroblock |
US9210441B2 (en) * | 2003-06-25 | 2015-12-08 | Thomson Licensing | Fast mode-decision encoding for interframes |
US20050013498A1 (en) | 2003-07-18 | 2005-01-20 | Microsoft Corporation | Coding of motion vector information |
WO2005011286A1 (en) * | 2003-07-24 | 2005-02-03 | Matsushita Electric Industrial Co., Ltd. | Encoding mode deciding apparatus, image encoding apparatus, encoding mode deciding method, and encoding mode deciding program |
CN1843037B (en) | 2003-08-26 | 2010-09-22 | 汤姆森特许公司 | Method and apparatus for encoding hybrid intra-inter coded blocks |
US7599438B2 (en) * | 2003-09-07 | 2009-10-06 | Microsoft Corporation | Motion vector block pattern coding and decoding |
US7567617B2 (en) | 2003-09-07 | 2009-07-28 | Microsoft Corporation | Predicting motion vectors for fields of forward-predicted interlaced video frames |
US8064520B2 (en) * | 2003-09-07 | 2011-11-22 | Microsoft Corporation | Advanced bi-directional predictive coding of interlaced video |
US8085846B2 (en) | 2004-08-24 | 2011-12-27 | Thomson Licensing | Method and apparatus for decoding hybrid intra-inter coded blocks |
KR100679031B1 (en) * | 2004-12-03 | 2007-02-05 | 삼성전자주식회사 | Method for encoding/decoding video based on multi-layer, and apparatus using the method |
KR100667806B1 (en) * | 2005-07-07 | 2007-01-12 | 삼성전자주식회사 | Method and apparatus for video encoding and decoding |
US9077960B2 (en) | 2005-08-12 | 2015-07-07 | Microsoft Corporation | Non-zero coefficient block pattern coding |
KR100750128B1 (en) * | 2005-09-06 | 2007-08-21 | 삼성전자주식회사 | Method and apparatus for intra prediction of video |
KR100727972B1 (en) * | 2005-09-06 | 2007-06-14 | 삼성전자주식회사 | Method and apparatus for intra prediction of video |
FR2894423A1 (en) | 2005-12-05 | 2007-06-08 | Thomson Licensing Sas | METHOD FOR PREDICTING MOTION DATA AND TEXTURE |
FR2897213A1 (en) * | 2006-02-08 | 2007-08-10 | Thomson Licensing Sas | BLOCK ENCODING METHOD OF IMAGES OF A SEQUENCE OF VIDEO IMAGES |
JP4789719B2 (en) * | 2006-07-06 | 2011-10-12 | キヤノン株式会社 | Motion vector detection apparatus, motion vector detection method, computer program, and storage medium |
JP4763549B2 (en) * | 2006-08-18 | 2011-08-31 | 富士通セミコンダクター株式会社 | Inter-frame prediction processing apparatus, image encoding apparatus, and image decoding apparatus |
KR101365574B1 (en) * | 2007-01-29 | 2014-02-20 | 삼성전자주식회사 | Method and apparatus for video encoding, and Method and apparatus for video decoding |
JP4786612B2 (en) * | 2007-08-14 | 2011-10-05 | Ｋｄｄｉ株式会社 | Predicted motion vector generation apparatus for moving picture encoding apparatus |
KR101452859B1 (en) * | 2009-08-13 | 2014-10-23 | 삼성전자주식회사 | Method and apparatus for encoding and decoding motion vector |
KR101522850B1 (en) | 2010-01-14 | 2015-05-26 | 삼성전자주식회사 | Method and apparatus for encoding/decoding motion vector |
JP5341786B2 (en) * | 2010-01-20 | 2013-11-13 | 株式会社メガチップス | Image coding apparatus and image conversion apparatus |
KR20110113561A (en) * | 2010-04-09 | 2011-10-17 | 한국전자통신연구원 | Method and apparatus for intra prediction encoding and decoding using adaptive filter |
US8923395B2 (en) | 2010-10-01 | 2014-12-30 | Qualcomm Incorporated | Video coding using intra-prediction |
JP7145822B2 (en) * | 2019-07-18 | 2022-10-03 | ヤフー株式会社 | Information providing device, information providing method, and information providing program |
Family Cites Families (8)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP3125145B2 (en) * | 1990-08-29 | 2001-01-15 | 日立電子株式会社 | Method and apparatus for highly efficient encoding of image data |
DE4113505A1 (en) | 1991-04-25 | 1992-10-29 | Thomson Brandt Gmbh | METHOD FOR IMAGE SIGNAL CODING |
US6226327B1 (en) * | 1992-06-29 | 2001-05-01 | Sony Corporation | Video coding method and apparatus which select between frame-based and field-based predictive modes |
PT1098529E (en) * | 1993-03-24 | 2013-11-25 | Sony Corp | Method of coding and decoding motion vector and apparatus therefor, and method of coding and decoding picture signal and apparatus therefor |
US5974184A (en) * | 1997-03-07 | 1999-10-26 | General Instrument Corporation | Intra-macroblock DC and AC coefficient prediction for interlaced digital video |
JP3559419B2 (en) * | 1997-03-18 | 2004-09-02 | 松下電器産業株式会社 | Method and apparatus for decompressing compressed image data |
JP2001251627A (en) * | 2000-03-03 | 2001-09-14 | Matsushita Electric Ind Co Ltd | Coder, coding method and recording medium recorded with program |
FR2806570B1 (en) * | 2000-03-15 | 2002-05-17 | Thomson Multimedia Sa | METHOD AND DEVICE FOR CODING VIDEO IMAGES |
-
2002
- 2002-11-21 WO PCT/US2002/037739 patent/WO2003047272A2/en active Application Filing
- 2002-11-21 JP JP2003548553A patent/JP2005510985A/en active Pending
- 2002-11-21 ES ES02804054.1T patent/ES2545177T3/en not_active Expired - Lifetime
- 2002-11-21 ES ES10182624.6T patent/ES2548384T3/en not_active Expired - Lifetime
- 2002-11-21 PT PT101826543T patent/PT2271115E/en unknown
- 2002-11-21 PT PT101827269T patent/PT2268040E/en unknown
- 2002-11-21 AU AU2002365338A patent/AU2002365338A1/en not_active Abandoned
- 2002-11-21 DK DK02804054.1T patent/DK1449385T3/en active
- 2002-11-21 ES ES10182726.9T patent/ES2545213T3/en not_active Expired - Lifetime
- 2002-11-21 CA CA2468087A patent/CA2468087C/en not_active Expired - Lifetime
- 2002-11-21 PT PT101826246T patent/PT2268039E/en unknown
- 2002-11-21 PT PT2804054T patent/PT1449385E/en unknown
- 2002-11-21 KR KR1020047007762A patent/KR101033398B1/en active IP Right Grant
- 2002-11-21 PT PT101826295T patent/PT2285121E/en unknown
- 2002-11-21 EP EP02804054.1A patent/EP1449385B1/en not_active Expired - Lifetime
- 2002-11-21 ES ES10182629.5T patent/ES2548385T3/en not_active Expired - Lifetime
- 2002-11-21 ES ES10182654.3T patent/ES2545394T3/en not_active Expired - Lifetime
-
2004
- 2004-05-19 MX MXPA04004724A patent/MXPA04004724A/en active IP Right Grant
-
2008
- 2008-09-11 JP JP2008234061A patent/JP2008295111A/en active Pending
-
2009
- 2009-10-23 JP JP2009244955A patent/JP5320254B2/en not_active Expired - Lifetime
-
2012
- 2012-01-26 JP JP2012014662A patent/JP5697614B2/en not_active Expired - Lifetime
-
2014
- 2014-11-27 JP JP2014240175A patent/JP2015062314A/en active Pending
-
2016
- 2016-03-18 JP JP2016055782A patent/JP6681758B2/en not_active Expired - Lifetime
- 2016-03-18 JP JP2016055781A patent/JP2016106504A/en active Pending
- 2016-03-18 JP JP2016055783A patent/JP6507114B2/en not_active Expired - Lifetime
-
2018
- 2018-06-11 JP JP2018110961A patent/JP2018139452A/en active Pending
Also Published As
Publication number | Publication date |
---|---|
PT2271115E (en) | 2015-10-15 |
JP2016123131A (en) | 2016-07-07 |
WO2003047272A2 (en) | 2003-06-05 |
JP5320254B2 (en) | 2013-10-23 |
PT1449385E (en) | 2015-10-15 |
JP2008295111A (en) | 2008-12-04 |
KR101033398B1 (en) | 2011-05-09 |
JP2016106504A (en) | 2016-06-16 |
ES2545394T3 (en) | 2015-09-10 |
ES2548385T3 (en) | 2015-10-16 |
JP2010022058A (en) | 2010-01-28 |
EP1449385A2 (en) | 2004-08-25 |
CA2468087A1 (en) | 2003-06-05 |
EP1449385B1 (en) | 2015-07-22 |
JP2015062314A (en) | 2015-04-02 |
PT2268040E (en) | 2015-10-15 |
JP2012105348A (en) | 2012-05-31 |
MXPA04004724A (en) | 2004-07-30 |
ES2545177T3 (en) | 2015-09-09 |
ES2545213T3 (en) | 2015-09-09 |
KR20040070176A (en) | 2004-08-06 |
ES2548384T3 (en) | 2015-10-16 |
JP6681758B2 (en) | 2020-04-15 |
PT2285121E (en) | 2015-10-27 |
PT2268039E (en) | 2015-10-26 |
DK1449385T3 (en) | 2015-10-19 |
JP2016136765A (en) | 2016-07-28 |
JP6507114B2 (en) | 2019-04-24 |
AU2002365338A1 (en) | 2003-06-10 |
JP5697614B2 (en) | 2015-04-08 |
JP2005510985A (en) | 2005-04-21 |
CA2468087C (en) | 2013-06-25 |
WO2003047272A3 (en) | 2004-01-08 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
JP6507114B2 (en) | Adaptive frame / field coding at macroblock level of digital video content | |
JP2005510985A5 (en) | ||
DK2271115T3 (en) | Adaptive frame / field encoding at macro block level of digital video content | |
KR101076506B1 (en) | A method of encoding and decoding an image sequence having a plurality of pictures | |
JP2005510984A5 (en) |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
A521 | Written amendment |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20180613 |
|
A621 | Written request for application examination |
Free format text: JAPANESE INTERMEDIATE CODE: A621Effective date: 20180711 |
|
A521 | Written amendment |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20181012 |
|
A131 | Notification of reasons for refusal |
Free format text: JAPANESE INTERMEDIATE CODE: A131Effective date: 20190507 |
|
A521 | Written amendment |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20190802 |
|
A131 | Notification of reasons for refusal |
Free format text: JAPANESE INTERMEDIATE CODE: A131Effective date: 20191105 |
|
RD02 | Notification of acceptance of power of attorney |
Free format text: JAPANESE INTERMEDIATE CODE: A7422Effective date: 20191115 |
|
RD04 | Notification of resignation of power of attorney |
Free format text: JAPANESE INTERMEDIATE CODE: A7424Effective date: 20191125 |
|
RD03 | Notification of appointment of power of attorney |
Free format text: JAPANESE INTERMEDIATE CODE: A7423Effective date: 20200130 |
|
A521 | Written amendment |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20200131 |
|
RD04 | Notification of resignation of power of attorney |
Free format text: JAPANESE INTERMEDIATE CODE: A7424Effective date: 20200131 |
|
A521 | Written amendment |
Free format text: JAPANESE INTERMEDIATE CODE: A821Effective date: 20200131 |
|
A02 | Decision of refusal |
Free format text: JAPANESE INTERMEDIATE CODE: A02Effective date: 20200413 |