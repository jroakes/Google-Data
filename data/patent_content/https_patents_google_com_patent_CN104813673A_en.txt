CN104813673A - Sharing content-synchronized ratings - Google Patents
Sharing content-synchronized ratings Download PDFInfo
- Publication number
- CN104813673A CN104813673A CN201380060705.6A CN201380060705A CN104813673A CN 104813673 A CN104813673 A CN 104813673A CN 201380060705 A CN201380060705 A CN 201380060705A CN 104813673 A CN104813673 A CN 104813673A
- Authority
- CN
- China
- Prior art keywords
- content
- media content
- evaluation
- user
- equipment
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/47—End-user applications
- H04N21/475—End-user interface for inputting end-user data, e.g. personal identification number [PIN], preference data
- H04N21/4756—End-user interface for inputting end-user data, e.g. personal identification number [PIN], preference data for rating content, e.g. scoring a recommended movie
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/70—Information retrieval; Database structures therefor; File system structures therefor of video data
- G06F16/78—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/70—Information retrieval; Database structures therefor; File system structures therefor of video data
- G06F16/78—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually
- G06F16/783—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using metadata automatically derived from the content
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/70—Information retrieval; Database structures therefor; File system structures therefor of video data
- G06F16/78—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually
- G06F16/7867—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using information manually generated, e.g. tags, keywords, comments, title and artist information, manually generated time, location and usage information, user ratings
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/41—Structure of client; Structure of client peripherals
- H04N21/422—Input-only peripherals, i.e. input devices connected to specially adapted client devices, e.g. global positioning system [GPS]
- H04N21/42203—Input-only peripherals, i.e. input devices connected to specially adapted client devices, e.g. global positioning system [GPS] sound input device, e.g. microphone
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/43—Processing of content or additional data, e.g. demultiplexing additional data from a digital video stream; Elementary client operations, e.g. monitoring of home network or synchronising decoder's clock; Client middleware
- H04N21/4302—Content synchronisation processes, e.g. decoder synchronisation
- H04N21/4307—Synchronising the rendering of multiple content streams or additional data on devices, e.g. synchronisation of audio on a mobile phone with the video output on the TV screen
- H04N21/43079—Synchronising the rendering of multiple content streams or additional data on devices, e.g. synchronisation of audio on a mobile phone with the video output on the TV screen of additional data with content streams on multiple devices
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/43—Processing of content or additional data, e.g. demultiplexing additional data from a digital video stream; Elementary client operations, e.g. monitoring of home network or synchronising decoder's clock; Client middleware
- H04N21/436—Interfacing a local distribution network, e.g. communicating with another STB or one or more peripheral devices inside the home
- H04N21/43615—Interfacing a Home Network, e.g. for connecting the client to a plurality of peripherals
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/60—Network structure or processes for video distribution between server and client or between remote clients; Control signalling between clients, server and network components; Transmission of management data between server and client, e.g. sending from server to client commands for recording incoming content stream; Communication details between server and client
- H04N21/65—Transmission of management data between client and server
- H04N21/658—Transmission by the client directed to the server
- H04N21/6582—Data stored in the client, e.g. viewing habits, hardware capabilities, credit card number
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/80—Generation or processing of content or additional data by content creator independently of the distribution process; Content per se
- H04N21/85—Assembly of content; Generation of multimedia applications
- H04N21/854—Content authoring
- H04N21/8547—Content authoring involving timestamps for synchronizing content
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/20—Servers specifically adapted for the distribution of content, e.g. VOD servers; Operations thereof
- H04N21/23—Processing of content or additional data; Elementary server operations; Server middleware
- H04N21/237—Communication with additional data server
Abstract
Systems, methods and devices described herein enable sharing content-synchronized ratings, related to media content playing on a first device, using one or more second devices. For example, while a television program is playing on a television, a tablet computer acquires and sends content information derived from the video stream to a server. The server identifies the television program by matching the content information to a fingerprint. Then the server system generates a set of instructions, a time-marker, and one or more content-synchronized ratings collected from other user devices. The set of instructions includes instructions for synchronizing to the time -marker, enabling sharing of one or more content-synchronized ratings, and displaying content- synchronized ratings from other users. The set of instructions and content are sent to the tablet computer for execution and display.
Description
Technical field
The system and method that the content synchronization that the application is described through the media content that use second collaborative share first equipment presents is evaluated.
Background technology
By the random broadcasted content of the Internet to other users, such as by so-called " rubbish " Email etc., be generally be prevented from and be considered to molestation.The acceptable delivery of content based on the Internet of usual use publisher-follower's model construction is with shared.According to this model, content publisher is limited to content distributed to website, and restriction is to not having the random broadcasted content of the user connected.Social networks application and blog (as microblogging) apply be usually follow publisher-follower's model based on the delivery of content of the Internet and the example of shared medium.
Publisher-follower's model limits user and can how share information rapidly and whom share information with.This model finds based on follower the publisher announcing the interested content of publisher.In order to share information with public audience, first publisher must attract follower, such as, by regularly announcing the content of empathizing with niche audience, and wishes that they develop follower from spectators.But specific user may want to express impromptu suggestion, and do not attempt for niche audience or even without the need to having the good suggestion formed.The constraint of this model causes this random publisher outside themselves social networks, easily can not share their suggestion.
On the contrary, random publisher is difficult to determine the public about the particular topic occurred in real time or social suggestion, such as TV (TV) program.According to this model, user must find out each content publisher issued about the content of this theme.But from being distributed on the evaluation of website or microblogging application, to decipher about the public of this theme or social suggestion be time-consuming for article and/or comment.Such as, when TV program, involved research may need the time longer than the duration of TV program, and this makes to attempt when TV program occurs to determine to make a futile effort about the public of TV program or social suggestion.
Summary of the invention
Above-mentioned defect and other problem is reduced or eliminated by disclosed system, method and apparatus.The various implementations of the system in the scope of claim, method and apparatus all have some aspects, are wherein individual responsibility expectation attributes as herein described without single one.When not limiting right, some prominent features of sample implementation are described in this article.How to be configured such that one or more user can use the second equipment Real-Time Sharing accordingly with internet function about the suggestion of the content that first kind equipment is presenting considering the feature of understanding various implementation after this specification.
More specifically, system described herein, method and apparatus enable the content synchronization evaluation using one or more second collaborative share relevant to the media content that the first equipment is play.Such as, while the upper displaying video stream of the first client device (such as, television set), the second client device (such as, flat computer) acquisition stems from the content information of video flowing and sends it to server system.Server system is by mating the video flowing identifying and the first client device is play with user supplied video content using fingerprints by content information.Then, based on mated fingerprint, one or more content synchronization evaluations that server system generates instruction set, time mark and collects from other subscriber equipmenies.This instruction set comprises instruction synchronous with the time mark that server system provides for the local timer of the second client device maintenance, enable the instruction that shared one or more content synchronization is evaluated, and the instruction that display is evaluated from the content synchronization of other users.This instruction set is sent to the second client device for performing, and related content is sent to the second client device for display.Second client device performs one or more application according to this instruction set, and shows related content.
Some implementations comprise the system, method and/or the equipment that are activated to allow the shared content synchronization relevant to the media content that the first equipment is play to evaluate, and described first equipment comprises processor, memory and display, and described method comprises.In some implementations, the method sharing content synchronization evaluation is allowed to comprise: to use the media content that the first equipment Inspection is play to user; Receive from the second equipment at the first equipment place and synchronously evaluate with the first content that is associated of broadcasting media content; Display and the first content that is associated of broadcasting media content are synchronously evaluated over the display; Display can operate to receive the interface that user that user that instruction is associated with broadcasting media evaluates inputs over the display; And to communicate comprising the data structure that user evaluates the second equipment.In some implementations, the method sharing content synchronization evaluation is allowed to comprise: the time mark be associated with media content is transferred to multiple subscriber equipment; Synchronously evaluate from the corresponding contents that multiple subscriber equipment receives and media content is associated; Analysis content synchronization is evaluated, to generate evaluation subset; And evaluation subset is transferred at least one in multiple subscriber equipment.
Some implementations comprise and are activated to determine the system of audience emotion, method and/or equipment from the content synchronization evaluation relevant to media content on equipment, and described equipment comprises processor and memory.In some implementations, the method determined comprises from multiple subscriber equipment reception corresponding content synchronization evaluation relevant to media content; And analyze content synchronization evaluation, to generate one or more tolerance of instruction audience emotion.
Some implementations comprise the sold evaluation sowing system of audience emotion, method and/or the equipment that are activated with on use equipment, and described equipment comprises processor and memory.In some implementations, sow the method for audience emotion to comprise: by the optional evaluation regiments of advising that is associated with media content to multiple subscriber equipment; And receive the corresponding content synchronization evaluation relevant to media content from multiple subscriber equipment.
Some implementations comprise the system, method and/or the equipment that become content synchronization evaluation when being activated to show on the first device, and described first equipment comprises processor, memory and display.In some implementations, the method becoming content synchronization evaluation during display comprises: use the media content that the first equipment Inspection is play to user; Receive the content synchronization evaluation be associated with the broadcasting media content that other people provide from the second equipment (such as, server) at the first equipment place, wherein, each evaluation comprises the data structure of the corresponding characteristic that instruction is evaluated; And the content synchronization evaluation be associated with broadcasting media content is shown over the display according to the corresponding characteristic of each evaluation.
Accompanying drawing explanation
Fig. 1 is the block diagram of the client-server environment according to some implementations.
Fig. 2 is the block diagram of the client-server environment according to some implementations.
Fig. 3 A is the block diagram of the configuration of server system according to some implementations.
Fig. 3 B is the block diagram of the data structure according to some implementations.
Fig. 4 A is the block diagram of the configuration of client device according to some implementations.
Fig. 4 B is the block diagram of the configuration of another client device according to some implementations.
Fig. 5 represents according to the flow process of the method for some implementations.
Fig. 6 represents according to the flow process of the method for some implementations.
Fig. 7 is the schematic diagram of the sample screen shot according to some implementations.
Fig. 8 represents according to the flow process of the method for some implementations.
Fig. 9 represents according to the flow process of the method for some implementations.
Figure 10 represents according to the flow process of the method for some implementations.
Figure 11 be according to the equipment of some implementations between some transmission signaling diagram represent.
Figure 12 represents according to the flow chart of the method for some implementations.
Figure 13 represents according to the flow chart of the method for some implementations.
Figure 14 represents according to the flow chart of the method for some implementations.
By convention, illustrated various feature can not to scale (NTS) be drawn in the accompanying drawings.Therefore, in order to clear, the size of various feature can expand arbitrarily or reduce.In addition, some accompanying drawing may not described to all component of fixed system, method or equipment.Finally, in whole specification and accompanying drawing, same reference numerals is for representing same characteristic features.
Embodiment
Now with detailed reference to various implementation, its diagram is shown in the drawings.In following embodiment, set forth many details to provide the thorough understanding to implementation each side.But described also can be implemented when not having these details with this paper theme required for protection.In other instances, do not describe known method, process, assembly and circuit in detail, unnecessarily to make each side of disclosed implementation fuzzy.
System described herein, method and apparatus can use the content synchronization evaluation that one or more second collaborative share is relevant to the media content that the first equipment is play.Such as, when playing TV programme on TV, flat computer is obtaining the content information that obtains from video flowing and is sending it to server.Server is by identifying TV programme by content information and fingerprint matching.Then, server system generates instruction set, time mark and one or more content synchronization evaluations of collecting from other subscriber equipmenies.This instruction set comprises: for being synchronized to time mark, and one or more content synchronization evaluation is shared, and the instruction that display is evaluated from the content synchronization of other users.This instruction set and content are sent to flat computer for performing and display.
Fig. 1 is the block diagram of the example client end-server environment 100 according to the simplification of some implementations.Although illustrate some specific features, those skilled in the art will understand from the disclosure, for simplicity with in order to avoid the more related fields of fuzzy implementation disclosed herein, not illustrate various further feature.For this purpose, client-server environment 100 comprises client device 102, TV (TV) 110, second screen client end equipment 120, communication network 104, evaluates server 130, broadcast system 140 and content provider 150.Client device 102, second screen client end equipment 120, evaluate server 130, broadcast system 140 and content provider 150 can be connected to communication network 104, with each other and/or other equipment and systems exchange information.
In some implementations, evaluate server 130 and be implemented as individual server system, and in other implementations, evaluate the distributed system that server 130 is implemented as multiple server.Only for the ease of explaining, evaluation server 130 is described as realizing in individual server system below.Similarly, in some implementations, broadcast system 140 is implemented as individual server system, and in other implementations, broadcast system 140 is implemented as the distributed system of multiple server.Only for the ease of explaining, broadcast system 140 is described as realizing in individual server system below.Similarly, in some implementations, content provider 150 is implemented as individual server system, and in other implementations, content provider 150 is implemented as the distributed system of multiple server.Only for the ease of explaining, content provider 150 is described as realizing in individual server system below.In addition, the function of broadcast system 140 and content provider 150 can be combined into individual server system.In addition and/or alternately, although in order to for simplicity, only a broadcast system and only a content provider is illustrated in Fig. 1, but those skilled in the art will understand from the disclosure, less or more broadcast system and content provider can be there is in the implementation of client-server environment.
Communication network 104 can be the combination in any of wired and WLAN (wireless local area network) (LAN) and/or wide area network (WAN), such as Intranet, extranet, comprises the part of the Internet.The communication capacity that communication network 104 can provide the second screen client end equipment 120 and evaluate between server 130.In some implementations, communication network 104 uses HTML (Hypertext Markup Language) (HTTP) to transmit information to use transmission control protocol/Internet protocol (TCP/IP).HTTP allows client device 102 and 120 to visit available various resources via communication network 104.But various implementation described herein is not limited to use any specific protocol.
In some implementations, evaluate server 130 and comprise front-end server 134, it is convenient to evaluate the communication between server 130 and communication network 104.Front-end server 134 receives content information 164 from the second screen client end equipment 120.As described in more detail referring to Fig. 3 A-4B, in some implementations, content information 164 is parts of video flowing, video flowing, and/or the reference to a video flowing part.Time marker and/or the figure notation of the content of reference video flowing can be comprised to the reference of a video flowing part.In some implementations, the video flowing that the combination that content information 164 derives from TV 110 and client 102 presents (namely playing).
In some implementations, front-end server 134 is configured to send instruction set to the second screen client end equipment 120.In some implementations, front-end server 134 is configured to send content file and/or be linked to content file.Term " content file " comprises any document or the content of any form, includes but not limited to video file, image file, music file, webpage, email message, SMS message, content feeds, advertisement, reward voucher, playlist or XML document.In some implementations, front-end server 134 is configured to send or receive one or more video flowing.In some implementations, front-end server 134 is configured to directly receive content from broadcast system 140 and/or content provider 150 by communication network 104.
According to some implementations, video or video flowing represent the image of moving scene or the sequence of frame.Video can separate with image area.The multiple image of video display per second or frame.Such as, video display 30 per second or 60 continuous print picture frames.In contrast, image may not be associated with other image any.
Content feeds (or channel) be to provide current at feeding source place, add recently or the resource of list of content item of recent renewal or service.Content item in content feeds can comprise be associated with project itself content (actual content that this content item is specified), title (being sometimes referred to as exercise question) and/or the description of content, the network site of content or finger URL (such as, URL) or their combination in any.Such as, if content item identification article of text, then content item can comprise article itself inline, together with title (or exercise question), and finger URL.Alternately, content item can comprise title, description and finger URL, but does not comprise article content.Therefore, some content items can comprise the content be associated with those projects, and other cover the link of the content be associated, but do not comprise the complete content of project.Content item can also comprise the attaching metadata of the additional information provided about content.Such as, the metadata web site url selected that can comprise timestamp or be embedded into.The full release of content can be any machine-readable data, includes but not limited to webpage, image, digital audio, digital video, Portable Document format (PDF) file etc.
In some implementations, use content syndication format, such as RSS given content feeding.RSS is the abbreviation of representative " rich site summary ", " RDF site summary " or " simple and easy information consolidation "." RSS " can refer to any one of the gang's form based on the extend markup language (XML) being used to specify the content item that content feeds comprises with feeding.In some other implementations, other guide union pattern, such as Atom union pattern or VCALENDAR calendar format may be used for given content feeding.
In some implementations, evaluate server 130 to be configured to receive content information 164 from the second screen client end equipment 120, content information is mated with the user supplied video content using fingerprints in fingerprint database 132, generate instruction set based on mated fingerprint and formerly evaluate set, and this instruction and evaluation set are sent to the second screen client end equipment 120, for performing, show and/or selecting.For this reason, as more detailed description below, in some implementations, evaluate server 130 and comprise evaluation analysis module 139, it is configured to collect, analyze and share the evaluation provided by multiple user.In some implementations, evaluation analysis module 139 is distributed networks of element.In some implementations, evaluate server 130 and comprise content information extraction module 131, it is configured to operate with front-end server 134 and evaluation analysis module 139, to identify the media content that (namely fingerprinting) plays, and provides the information about the media content play.In some implementations, content information extraction module 131 is distributed networks of element.
In some implementations, evaluate server 130 and comprise customer data base 137, it stores user data.In some implementations, customer data base 137 is distributed data bases.In some implementations, evaluate server 130 and comprise content data base 136.In some implementations, content data base 136 evaluation that comprises advertisement, video, image, music, webpage, email message, SMS message, content feeds, advertisement, reward voucher, playlist, XML document and be associated with various media content or its any combination.In some implementations, content data base 136 is included in linking of advertisement, video, image, music, webpage, email message, SMS message, content feeds, advertisement, reward voucher, playlist, XML document and the evaluation that is associated with various media content.In some implementations, content data base 136 is distributed data bases.
As noted above, in some implementations, evaluate server 130 and comprise fingerprint database 132, it stores user supplied video content using fingerprints.User supplied video content using fingerprints comprises the condensation of any type of the content of video flowing and/or audio stream or compact representation or signature.In some implementations, fingerprint can represent video flowing or audio stream editing (such as some seconds, minute or hour).Or fingerprint can represent the single moment (fingerprint of the video such as, be associated with the frame of video or the single frame of audio frequency) of video flowing or audio stream.In addition, because video content can change in time, therefore the fingerprint of the correspondence of this video content also changes in time.In some implementations, fingerprint database 132 is distributed data bases.
In some implementations, evaluate server system 130 and comprise commentator's monitor module 135, it is configured to the fingerprint creating the media content of being broadcasted by broadcast system 140 and/or content provider 150.
In some implementations, client device 102 and display device (such as TV 110) combine and provide.Client device 102 is configured to from broadcast system 140 receiver, video stream 161 and video flowing is delivered to TV 110 be used for display.Although use TV in the example illustrated, but those skilled in the art will understand from the disclosure, any amount of display device can be used to carry out display of video streams, and described display device comprises computer, laptop computer, flat computer, smart phone etc.In addition and/or alternately, the function of client 102 and TV 110 can be combined into individual equipment.
In some implementations, client device 102 be can be connected to communication network 104, receiver, video stream, from video flowing information extraction with present video flowing and carry out for using TV 110 (or another display device) any suitable computer equipment shown.In some implementations, client device 102 is Set Top Box, and it comprises the assembly receiving and present video flowing.Such as, client device 102 can be any miscellaneous equipment of Set Top Box, digital video recorder (DVR), digital media receiver, TV tuner, computer and/or output TV signal for receiving wired TV and/or satellite TV.In some implementations, client device 102 display of video streams on TV 110.In some implementations, TV 110 can not be connected to the Internet and display connects traditional TV display of numeral and/or the analog TV content received via air broadcast or satellite or cable.
As typical television set, TV 110 comprises display 118 and loud speaker 119.In addition and/or alternately, TV 110 can be replaced by the display device 108 of the another kind of type for video content being presented to user.Such as, display device can be computer monitor, and it is configured to receive and the audio and video frequency signal shown from client 102 or other digital contents.In some implementations, display device is the electronic equipment with CPU, memory and display, and described display is configured to receive and the audio and video frequency signal shown from client 102 or other digital contents.Such as, display device can be the video display system of LCD screen, flat-panel devices, mobile phone, projecting apparatus or other type.Display device can be couple to client 102 via wireless or wired connection.
In some implementations, client device 102 is via TV signal 162 receiver, video stream 161.As used herein, TV signal comprises the data transmission media corresponding to the electricity of the audio frequency of TV channel and/or video component, light or other type.In some implementations, TV signal 162 is the symbol/broadcast of the distribution in terrestrial wireless TV broadcast singal or cable system or satellite system.In some implementations, transmission is connected as data TV signal 162 by network.Such as, client device 102 can connect receiver, video stream from the Internet.The Voice & Video component of TV signal is in this article sometimes referred to as audio signal and vision signal.In some implementations, TV signal corresponds to the TV channel that TV 110 is showing.
In some implementations, TV signal 162 carries the information of the sub-audible sound corresponding to the audio track on TV channel.In some implementations, sub-audible sound is that the loud speaker 119 comprised by TV 110 produces.
Second screen client end equipment 120 can be any suitable computer equipment that can be connected to communication network 104, such as computer, laptop computer, flat-panel devices, net book, online booth, personal digital assistant, mobile phone, game station or can carry out with evaluating server 130 any other equipment of communicating.In some implementations, the second screen client end equipment 120 comprises one or more processor 121, nonvolatile memory 122 (such as hard disk drive), display 128, loud speaker 129 and microphone 123.Second screen client end equipment 120 also can have input equipment, such as keyboard, mouse and/or Trackpad (not shown).In some implementations, the second screen client end equipment 120 comprises the ancillary equipment of touch-screen display, digital camera and/or any number, to increase function.
In some implementations, the second screen client end equipment 120 is connected to and/or comprises display device 128.Display device 128 can be any display for video content being presented to user.In some implementations, display device 128 is display or the computer monitor of TV, its be configured to receive and display from the audio and video frequency signal of the second screen client end equipment 120 or other digital contents.In some implementations, display device 128 is the electronic equipments with CPU 121, memory 122 and display, and described display is configured to receive and show audio and video frequency signal or other digital contents.In some implementations, display device 128 is video display systems of LCD screen, flat-panel devices, mobile phone, projecting apparatus or any other type.In some implementations, the second screen client end equipment 120 is connected to display device 128 and/or integrated with it.In some implementations, display device 128 comprises or is otherwise connected to, and can produce the loud speaker of listened to the stream of the audio component corresponding to TV signal or video flowing.
In some implementations, the second screen client end equipment 120 is connected to client device 102 via wireless or wired connection 103.In some implementations that there is this connection, the second screen client end equipment 120 can operate according to the instruction provided by client device 102, information and/or digital content (being referred to as below " the second screen message ") alternatively.In some implementations, client device 102 sends instruction to the second screen client end equipment 120, presents the supplementary or associated digital content of the digital content that client 102 is presenting on TV 110 to make the second screen client end equipment 120 at display 128 and/or loud speaker 129.
In some implementations, the second screen client end equipment 120 comprises microphone 123, and it makes client device can receive sound (audio content) from the loud speaker 119 of such as TV 110.Audio content/audio track that the video content that microphone 123 makes the second screen client end equipment 120 to store to present with it is associated.Second screen client end equipment 120 can store this information in this locality, and then sent to by content information 164 and evaluate server 130, content information 164 is following any one or multiple: the fingerprint of the audio content stored, audio content itself, the part/fragment of audio content, the fingerprint of a part for audio content or the reference to play content.
By this way, evaluate server 130 and can identify the content that TV is play, even if be not just the equipment with internet function at the electronic equipment of rendering content, such as older television set; Just be not connected to the Internet (temporary transient or permanent) at the electronic equipment of rendering content and therefore can not send content information 164; Or just not there is at the electronic equipment of rendering content the ability of record or the media information relevant to video content that fingerprint.This arrange (that is, the second screen client end equipment 120 content information stored 164 and send it to evaluate server 130) user just where watch TV all allow user from evaluate server 130 receive in response to content information 164 trigger the second screen content.
In some implementations, the second screen client end equipment 120 comprises the one or more application 125 being stored in memory 122.As discussed in more detail below, processor 121 performs one or more application according to from the instruction set evaluating server 130 reception.
Fig. 2 is the block diagram of the client-server environment 200 according to some implementations.Client-server environment 200 illustrated in Fig. 2 is similar to and is derived from the client-server environment 100 illustrated in Fig. 1.For for purpose of brevity, both share common reference marker by common element, and only describe the difference between client-server environment 100,200 in this article.
As non-limiting example, in client-server environment 200, client 102, TV 110 and the second screen client end equipment 120 are included in the first dwelling places 201.In operation, client device 102 receives streamed video signal or the audio signal of TV signal or some other types.Then signal received at least partially is communicated TV110 to be shown to user 221 by client device 102.As mentioned above, the second screen client end equipment 120 is configured to the upper media content play of detection first equipment (such as, TV 110), and enables the content synchronization evaluation shared and be associated with the media content that TV110 plays.Also can find similar layout in dwelling places 202,203,204,205 and 206, wherein, other user's (not shown) of similar equipment can provide and share the evaluation about same media content.In addition, although use dwelling places in this particular example, bot 502 includes, those skilled in the art will understand from the disclosure, and client device etc. can be positioned at the position of any type, comprise business, inhabitation and common point.The more specifically details of sharing content synchronization evaluation about how between users continues to be described with reference to Fig. 1 and 2 with reference to all the other accompanying drawings below.
Fig. 3 A is the block diagram of the configuration of evaluation server 130 according to some implementations.In some implementations, evaluate server 130 and comprise one or more processing unit (CPU) 302, one or more network or other communication interface 308, memory 306 and for the one or more communication buss 304 by these and other assembly interconnect various.Communication bus 304 comprises circuit (being sometimes referred to as chipset) alternatively, and it is by system component interconnection and communication between control system assembly.Memory 306 comprises high-speed random access memory, such as DRAM, SRAM, DDR RAM or other random access solid state memory devices; And can nonvolatile storage be comprised, such as one or more disk storage device, optical disc memory apparatus, flash memory device or other non-volatile solid-state memory devices.Memory 306 can comprise the one or more memory devices being positioned at CPU 302 distant place alternatively.Memory 306 (comprising the non-volatile and volatile memory devices in memory 306) comprises non-transitory computer-readable recording medium.In some implementations, the non-transitory computer-readable recording medium of memory 306 or memory 306 stores follow procedure, module and data structure or its subset, comprises operating system 316, network communication module 318, content information extraction module 131, content data base 136, fingerprint database 132, customer data base 137 and application 138.
Operating system 316 comprises for the treatment of various basic system services and the process for performing the task of depending on hardware.
Network communication module 318 is convenient to communicate with other equipment with one or more communication network (such as the Internet, other wide area network, local area network (LAN), metropolitan area network etc.) via one or more communications network interface 308 (wired or wireless).With further reference to Fig. 1, network communication module 318 can be incorporated into front-end server 134.
Content data base 136 comprises content file 328 and/or the link to content file 230.In some implementations, content data base 136 stores advertisement, video, image, music, webpage, email message, SMS message, content feeds, advertisement, reward voucher, playlist, XML document and their any combination.In some implementations, content data base 1376 is included in the link of advertisement, video, image, music, webpage, email message, SMS message, content feeds, advertisement, reward voucher, playlist, XML document and their any combination.Content file 328 is discussed in more detail by the discussion of Fig. 3 B.
Customer data base 137 comprises the user data 340 of one or more user.In some implementations, the user data of corresponding user 340-1 comprises user identifier 342, user personality 344 and user account information 345.User identifier 342 identifies user.Such as, user identifier 342 can be the alphanumeric values identifying user uniquely that is that the IP address that is associated with client device 102 or user select or server-assignment.User personality 344 comprises the characteristic of corresponding user.
Fingerprint database 132 stores one or more user supplied video content using fingerprints 332.Fingerprint 332 comprises title 334, fingerprint audio information 336 and/or fingerprint video information 338, and the list 339 of associated files.Title 334 identifies corresponding user supplied video content using fingerprints 332.Such as, title 334 can comprise be associated TV programme, film or advertisement title.In some implementations, fingerprint audio information 336 comprise the audio content of video flowing or audio stream editing (such as some seconds, minute or hour) fingerprint or other compression expressions.In some implementations, fingerprint video information 338 comprise video flowing editing (such as some seconds, minute or hour) fingerprint.Fingerprint 332 in regular update fingerprint database 132.
Content information extraction module 131 receives content information 164 from the second screen client end equipment 120, generates instruction set 132, and sends this instruction set 132 to the second screen client end equipment 120.Additionally and/or alternately, evaluate server 130 and can receive content information 164 from client device 102.Content information extraction module 131 comprises directive generation module 320 and fingerprint matching module 222.In some implementations, content information extraction module 131 also comprises fingerprint generation module 321, and its other media content preserved from content information 164 or server 130 generates fingerprint.
Content information 164 (or the fingerprint of the content information 164 generated by fingerprint generation module) at least partially mates with the fingerprint 332 of fingerprint database 132 by fingerprint matching module 322.Mated fingerprint 342 is sent to directive generation module 320.Fingerprint matching module 322 comprises the content information 164 received from least one client device 102 and the second screen client end equipment 120.Content information 164 comprises audio-frequency information 324, video information 326 and user identifier 329.User identifier 329 identifies and at least one user be associated in client device 102 and the second screen client end equipment 120.Such as, user identifier 329 can be the alphanumeric values identifying user uniquely that is that the IP address that is associated with client device 102 (or 120) or user select or server-assignment.In some implementations, contextual audio information 324 comprise video flowing or the audio stream that client device 102 presents editing (such as some seconds, minute or hour).In some implementations, audio content information 326 comprise on client device 102 play video flowing editing (such as some seconds, minute or hour).
Directive generation module 320 generates instruction set 332 based on mated fingerprint 342.In some implementations, directive generation module 320 generates instruction set 332 based on the information be associated with mated fingerprint 342 with corresponding to the user data 340 of user identifier 329.In some implementations, directive generation module 320 determines the one or more application 138 be associated with mated fingerprint 342, to be sent to the second screen client end equipment 120.In some implementations, directive generation module 320 determines one or more content file 328 based on mated fingerprint 342, and determined content file 328 is sent to the second screen client end equipment 320.
In some implementations, this instruction set 332 is included in and the second screen client end equipment 120 performs and/or shows the instruction of one or more application.Such as, when being performed by the second screen client end equipment 120, the second screen client end equipment 120 display can be made to be minimized for this instruction set 332 or as the application that background process runs, or this instruction set 132 can make the second screen client end equipment 120 perform application.In some implementations, this instruction set 332 comprises the instruction making the second screen client end equipment 120 download one or more content file 328 from server system 106.
Application 138 comprises one or more application that can perform on the second screen client end equipment 120.In some implementations, application comprises media application, feed reader application, browser application, advertisement applications, the application of reward voucher volume and self-defined application.
The each element identified above can be stored in one or more previously mentioned memory devices, and each module or program correspond to the instruction set for performing above-mentioned functions.This instruction set can be performed by one or more processor (such as, CPU 302).The module identified above or program (such as, igniter module 118) do not need to be implemented as independent software program, process or module, and therefore each subset of these modules can combine or rearrange with various implementation.In some implementations, memory 306 can store the subset of module and the data structure identified above.In addition, the add-on module that do not describe above can storing of memory 306 and data structure.
Although Fig. 3 A shows evaluation server, compared with the structural representation of implementation described here, Fig. 3 A is intended to more functional descriptions of various features as being presented on one group of server.In practice, and as known to persons of ordinary skill in the art, the project illustrated separately can combine, and some projects can be separated.Such as, some projects (such as, operating system 316 and network communication module 318) that Fig. 3 A illustrates separately can realize on a single server, and single project can be realized by one or more server.For the actual number of server that realizes evaluating server 130, how between which with assigned characteristics will be different and change with implementation, and during the peak operating period can be depended in part on and the data business volume that during mea life, system must process.
Fig. 3 B is the block diagram being stored in the example of the contents file data structure 328 in content data base 136 according to some implementations.Corresponding content file 328 comprises metadata 346 and content 354.The metadata 346 of corresponding content file 328 comprises content file identifier (file ID) 348, content file type 250, target information 352, one or more fingerprint 353, tolerance 355 and optional additional information be associated.In some implementations, file ID 348 identifies corresponding content file 328 uniquely.In other implementations, file ID 348 uniquely identifies the corresponding content file 328 in catalogue (such as, file directory) or the alternative document set in content data base 136.File type 350 identifies the type of content file 328.Such as, in content data base 136, the file type 350 of corresponding content file 328 indicates corresponding content file 328 to be video file, image file, music file, webpage, email message, SMS message, content feeds, advertisement, reward voucher, playlist and XML document.The fingerprint 353 be associated identifies one or more fingerprints that content file 328 in fingerprint database 136 with corresponding is associated.In some implementations, the fingerprint be associated of corresponding content file is determined by the broadcaster of document or creator.In some implementations, the module by being associated with evaluation server 130 or third party device/system extracts the fingerprint be associated.The data representation of target information 352 is for the target information of the document provider of content file 328.The data representation document provider of target information wishes that target is the crowd of this file.Tolerance 355 provides the measurement of the importance of file 328.In some implementations, measure 355 to be set by the founder of document or the owner.In some implementations, measure 355 and represent popularity, number of visits or bid.In some implementations, in many ways file is associated with user supplied video content using fingerprints, and each party places a bid, to show their file when the content corresponding to user supplied video content using fingerprints being detected.In some implementations, measure 355 and comprise click-through rate.Such as, webpage can be associated with user supplied video content using fingerprints.
Fig. 4 A is the block diagram of the configuration of client device 102 according to some implementations.Client device 102 generally includes one or more processing unit (CPU) 402, one or more network or other communication interface 408, memory 406 and for the one or more communication buss 404 by these and other assembly interconnect various.Communication bus 404 comprises circuit (being sometimes referred to as chipset) alternatively, and it is by system component interconnection and communication between control system assembly.Client device 102 can also comprise user interface, comprises display device 413 and keyboard and/or mouse (or other pointing device) 414.Memory 406 comprises high-speed random access memory, such as DRAM, SRAM, DDR RAM or other random access solid state memory devices; And can nonvolatile storage be comprised, such as one or more disk storage device, optical disc memory apparatus, flash memory device or other non-volatile solid-state memory devices.Memory 406 can comprise the one or more memory devices being positioned at CPU 402 distant place alternatively.Non-volatile memory device in memory 406 or optionally memory 406 comprises non-transitory computer-readable recording medium.In some implementations, the computer-readable recording medium of memory 406 or memory 406 stores following program, module and data structure, or its subset, comprises operating system 416, network communication module 418, video module 426 and data 420.
Client device 102 comprises video input/output 430, for receiving and outputting video streams.In some implementations, video input/output 430 is configured to from wireless radio transmission, satellite transmission, cable receiver, video stream.In some implementations, video input/output 430 is connected to Set Top Box.In some implementations, video input/output 430 is connected to satellite dish.In some implementations, video input/output 430 is connected to antenna.
In some implementations, client device 102 comprises TV tuner 432, for receiver, video stream or TV signal.
Operating system 416 comprises for the treatment of various basic system services and the process for performing the task of depending on hardware.
Network communication module 418 is convenient to communicate with other equipment with one or more communication network (such as the Internet, other wide area network, local area network (LAN), metropolitan area network etc.) via one or more communications network interface 404 (wired or wireless).
Data 420 comprise video flowing 161.
Video module 426 obtains content information 164 from video flowing 161.In some implementations, content information 161 comprises audio-frequency information 324, video information 326, user identifier 329 or their combination in any.The user of user identifier 329 identify customer end equipment 102.Such as, user identifier 329 can be the alphanumeric values identifying user uniquely that is that the IP address that is associated with client device 102 or user select or server-assignment.In some implementations, audio-frequency information 324 comprise video flowing or audio stream editing (such as some seconds, minute or hour).In some implementations, video information 326 can comprise video flowing editing (such as some seconds, minute or hour).In some implementations, video information 326 and audio-frequency information 324 derive from the video flowing 161 client 102 play or is playing.Some content informations 164 that video module 426 can generate corresponding video flowing 161 are gathered.
The each element identified above can be stored in one or more previously mentioned memory devices, and each module or program correspond to the instruction set for performing above-mentioned functions.This instruction set can be performed by one or more processor (such as, CPU 402).The module identified above or program (such as, instruction set) do not need to be implemented as independent software program, process or module, and therefore each subset of these modules can combine or rearrange with various implementation.In some implementations, memory 306 can store the subset of module and the data structure identified above.In addition, the add-on module that do not describe above can storing of memory 406 and data structure.
Although Fig. 4 A shows client device, compared with the structural representation of implementation described here, Fig. 4 A is intended to the functional description carrying out being presented on the various features of client device more.In practice, and as known to persons of ordinary skill in the art, the project illustrated separately can combine, and some projects can be separated.
Fig. 4 B is the block diagram of the configuration of the second screen client end equipment 120 according to some implementations.Second screen client end equipment 120 generally includes one or more processing unit (CPU) 121, one or more network or other communication interface 445, memory 122 and for the one or more communication buss 441 by these and other assembly interconnect various.Communication bus 441 comprises circuit (being sometimes referred to as chipset) alternatively, and it is by system component interconnection and communication between control system assembly.Second screen client end equipment 120 can also comprise user interface, and it comprises display device 128, loud speaker 129 and keyboard and/or mouse (or other pointing device) 444.Memory 122 comprises high-speed random access memory, such as DRAM, SRAM, DDR RAM or other random access solid state memory devices; And can nonvolatile storage be comprised, such as one or more disk storage device, optical disc memory apparatus, flash memory device or other non-volatile solid-state memory devices.Memory 122 can comprise the one or more memory devices being positioned at CPU 121 distant place alternatively.Memory 122, or alternately, the non-volatile memory devices in memory 122 comprises non-transitory computer-readable recording medium.In some implementations, the computer-readable recording medium of memory 122 or memory 122 stores following program, module and data structure, or its subset, comprise operating system 447, network communication module 448, figure module 449, instruction module 124 and application 125.
Operating system 447 comprises for the treatment of various basic system services and the program for performing the task of depending on hardware.
Network communication module 448 is convenient to communicate with other equipment with one or more communication network (such as the Internet, other wide area network, local area network (LAN), metropolitan area network etc.) via one or more communications network interface 445 (wired or wireless).
Instruction module 124 receives instruction set 432 and optional content file 428 and/or the link to content file 430.Instruction module 124 performs instruction set 432.In some implementations, instruction module 124 performs application 125 according to this instruction set 432.Such as, in some implementations, instruction module 124 performs the web browser 455-1 of display web page according to this instruction set 432.In some implementations, instruction module 124 shows the content in one or more content file 428.Such as, in some implementations, instruction module 124 can show advertisement.In some implementations, instruction module 124 retrieves one or more content files that (reference) is quoted in link 430.
Second screen client end equipment 120 comprises one or more application 125.In some implementations, apply 125 and comprise browser application 455-1, media application 455-2, reward voucher volume application 455-3, feed reader application 455-4, advertisement applications 455-5, self-defined application 455-6 and fingerprint module 455-7.Browser application 455-1 display web page.Media application 455-2 displaying video and music, display image and managing playlist 456.Feed reader application 355-4 displaying contents feeding 458.Reward voucher volume application 455-3 stores and retrieval reward voucher 457.Advertisement applications 455-5 shows advertisement.Self-defined application 455-6 is with the information of the form of easily viewing on mobile device display from website.Application 125 is not limited to application discussed above.
The each element identified above can be stored in one or more previously mentioned memory devices, and each module or program correspond to the instruction set for performing above-mentioned functions.This instruction set can be performed by one or more processor (such as, CPU 121).The module identified above or program (such as, instruction set) do not need to be implemented as independent software program, process or module, and therefore each subset of these modules can combine or rearrange with various implementation.In some implementations, memory 306 can store the subset of module and the data structure identified above.In addition, the add-on module that do not describe above can storing of memory 306 and data structure.
Although Fig. 4 B shows client device, compared with the structural representation of implementation described here, Fig. 4 B is intended to the functional description carrying out being presented on the various features of client device more.In practice, and as known to persons of ordinary skill in the art, the project illustrated separately can combine, and some projects can be separated.
Fig. 5 represents according to the flow chart of the method for some implementations.In some implementations, the method is performed by the second screen equipment (such as, the second screen client end equipment 120 of Fig. 1) or the equipment of similar configuration.In some implementations, also can at the identical equipment playing media content, such as notebook, flat computer, display monitor or have internet function device drives TV (such as, Google TV equipment) on perform the method.As shown in block 5-1, the method comprises: the second screen equipment detects the identity of the media content that first equipment of (namely fingerprinting) such as television set (such as TV 110) is play.Referring to Fig. 6, Fig. 9 and Figure 10, the example more specifically of the method for the identity of the media content that detection is play is described.As shown in block 5-2, the method comprises: become when evaluation server receives one or more and evaluate.As shown in block 5-3, the method comprises: become when showing one or more on the display of the equipment of the second screen equipment or similar configuration (may be integrated) and evaluate.As shown in block 5-4, the method comprises: the input receiving the instruction evaluation relevant to the media content that the first equipment is play from user.As shown in block 5-5, the method comprises: user is evaluated input and be synchronized to and the time scale play media content and be associated.Describe referring to Fig. 6 and user's input is synchronized to the more detailed embodiment playing media content.
As shown in block 5-6, the method comprises: determine that user evaluates when whether input corresponds to received and become one in evaluating.In some implementations, the evaluation evaluated and correspond to other users and provide into the same media content that the first equipment is play is provided time.Such as, with further reference to Fig. 2, in time, becomes and evaluates the evaluation that provides corresponding to some position user being arranged in position 202,203,204,205,206.Therefore, in other words, as shown in block 5-6, the method comprises: determine that user evaluates input and whether corresponds to the user repeated with the evaluation that another user that is identical or another location provides and/or the user agreeing to this evaluation.If user evaluates when input corresponds to received become one (the "Yes" path from block 5-6) in evaluating, as shown in block 5-9, the method comprises: user evaluated and be transferred to evaluation server.In some implementations, as being discussed in further detail below, user evaluates input and is included in data structure together with other information, with allow server to evaluate analyze separately and/or with receive from other users watching same media content other evaluate combination and analyze.In some implementations, user can be evaluated input and the user in particular range and evaluate and input relevant other and evaluate and mate, thus be polymerized evaluation.
On the other hand, if user evaluates when input does not correspond to received become one (the "No" path from block 5-6) in evaluating, as shown in block 5-7, the method comprises: determine that user evaluates input and whether corresponds to preset and evaluate.In some implementations, default evaluation comprises the evaluation that some second screen equipments can be used for giving tacit consent to selection.There is provided such evaluation be because a large number of users of viewing specific television program in history or estimate often to select such evaluation.Such as, in some implementations, evaluate " Love it! " and " Hate it! " can be preset to evaluate.
If user evaluates input and corresponds to default evaluation (the "Yes" path from block 5-7), as shown in block 5-9, the method comprises: with data structure, user's evaluation is transferred to evaluation server.On the other hand, if user evaluates input and does not correspond to default evaluation (the "No" path from block 5-7), as shown in block 5-8, the method comprises: determine that user evaluates input and is New Appraisement and this New Appraisement of local cache storage in the memory of the second screen equipment.Then, as mentioned above, as shown in block 5-9, the method comprises: with data structure, user's evaluation is transferred to evaluation server.
Fig. 6 represents according to the flow chart of the method for some implementations.In some implementations, the method is performed by the second screen equipment (such as, the second screen client end equipment 120 of Fig. 1) or the equipment of similar configuration.In some implementations, also can at the identical equipment playing media content, such as notebook, flat computer, display monitor or have internet function device drives TV (such as, Google TV equipment) on perform the method.As shown in by block 6-1, the method comprises: generate quoting of a part for the media content that the first equipment to such as TV is play.As mentioned above, quote and can comprise, except other information, the fingerprint of the fingerprint of the audio content stored, audio content itself, the part/fragment of audio content, the part of audio content, play media content audio recording, play the videograph of media content and/or a characteristic extracted from the audio or video record playing media content.As shown in block 6-2, the method comprises: quoting of the part to media content is transferred to evaluation server.As shown in block 6-3, the method comprises: receive from evaluating server the time mark be associated with broadcasting media content.In some implementations, time mark comprise following at least one: time started of instruction media content and for generate the transmitted media content quoted a part between the value of time migration, the absolute time value that the system clock safeguarded by server and/or broadcast system provides, and based on the relative time values of System Clock time.As shown in block 6-4, the method comprises: use the local timer that the time mark received synchronously is safeguarded by the second screen equipment.
Continuation is the schematic diagram comprising the sample screen shot of TV 110 and the second screen client end equipment 120 according to some implementations with reference to Fig. 1 and 2, Fig. 7.The display 118 of TV 110 shows the TV programme 502 about such as sports team.Although illustrate TV, those skilled in the art will understand from the disclosure, and system and method disclosed herein can use in conjunction with any media presentation devices.The user interface 520 of display 128 display application 125 of the second screen client end equipment 120, for sharing the content synchronization evaluation relevant to TV programme 502.
As mentioned above, when playing TV programme 502 on TV 110, the second screen client end equipment 120 obtains and/or generates and stems from quoting of TV programme 502.Then the second screen client end equipment 120 will be quoted to be transferred to and evaluate server 130.Evaluate server 130 content information to be mated with user supplied video content using fingerprints, to identify TV programme 502.After identifying the user supplied video content using fingerprints mated with content information, evaluate server 130 to generate and/or search instruction collection and the content that is associated with TV programme 502, and this instruction set and the content delivery that is associated are used for performing and display to the second screen client end equipment 120.
Second client device 120 performs this instruction set, and this instruction set comprises the instruction for showing the content received be associated with the TV programme 502 that TV 110 plays in user interface 520.In some implementations, user interface 520 is configured to comprise five parts 521,522,523,524,525.Although five parts are all included in the sample implementation described with reference to Fig. 7, it will be apparent to one skilled in the art that according to other implementation various, can comprise less or can the part of more more number in the user interface.
In some implementations, Part I 521 is configured to show the image be associated with TV programme 502, to show the content be associated with TV programme 502 especially to user's indicative user interface 520.Such as, Part I 521 can show from TV programme can periodically (such as, every 5-10 second) latest frame of upgrading.In addition and/or alternately, Part I 521 can show the mark be associated with TV programme or the mark (i.e. television channel, stand or the mark of network) in broadcasting station that broadcasting TV programme 502.
In some implementations, Part II 522 is configured to show Real time graph, the summary of the evaluation of content synchronization that this Real time graph graphically provides the user of diverse location (position 201,202,203,204,205,206 such as, in Fig. 2) viewing and comment TV programme 502 along with TV programme 502 is broadcasted.Chart is general will specifically to be evaluated and counterpart's gas of beholder's mood is summarised as its entirety or a part of because it is relevant to TV programme 502.In some embodiments, this chart is activated, to allow user to derive tolerance, such as, such as, and the comparison etc. of rolling average, different evaluation.
In some implementations, Part III 523 is configured to show the animation be associated with current viewer's mood.Such as, if most of beholder provides the evaluation of instruction to the negative emotions of TV programme 502, the suitable animation of reflection negative emotions may so be shown.More specifically, such as, if beholder's indication TV program 502 is boring, then animation can comprise cartoon figure's sleep.In another example, based on paralepsy or the significant change of current viewer, animation is understood suddenly and without early warning " bullet " out, is caused the concern of user.Such as, if most of user provides instruction to the cheer of special exercise team or the evaluation representing support in response to event (such as: score of scoring in play) suddenly, then the animation be associated of the paralepsy of reflection beholder may be ejected.Such as, animation can comprise sports team mascot and dance, and swings and/or to rotate and the other side sports team mascot is cryyed and waves in the mode of celebrating.Those skilled in the art will will understand from the disclosure, and the above-mentioned particular example of animation is only illustrative and not restrictive.
In some implementations, Part IV 524 is configured to display optional time change suggestion and evaluates, the evaluation that this evaluation provides based on other users in the process of TV programme 502.In some implementations, each optional time becomes icon (such as, balloon, bubble, the button etc.) display that the variable corresponding visual characteristic to have reflection Evaluation: Current popularity is evaluated in suggestion.Such as, the specific optional time that many users repeat more and more becomes suggestion evaluation and increases with size and the balloon display moving to the prospect of display.In addition and/or alternately, the color of balloon also may become brighter.On the other hand, the specific optional time that popularity reduces becomes suggestion evaluation and reduces, moves to the background of display with size and falling into the balloon display of finally breaking after under the threshold level of popularity.In some implementations, Part IV 524 is configured to allow user by using ancillary equipment (such as mouse or keyboard) and/or becoming suggestion evaluation by least one in touch display 128 (if enabling as touch-screen display) to select one or more optional time.
In some implementations, Part V 525 is configured to the multiple optional default suggestion evaluation of display.In some implementations, each optional default suggestion is evaluated with icon or button display.Such as, as shown in Figure 7, Part V 525 comprises three optional default suggestions evaluation button 525a, 525b, 525.In some implementations, optional default suggestion evaluation be a large number of users of viewing TV programme 502 in history or estimate the evaluation often selected.Such as, in some implementations, evaluate " Love it! " and " Hate it! " can be preset to evaluate.In some implementations, become advise compared with evaluation with optional time, optional default suggestion evaluation shows more greatly and/or more highlightedly.In some implementations, compared with optional default suggestion evaluation, optional time becomes suggestion evaluation and shows more greatly and/or more highlightedly.In some implementations, Part V 525 is configured to allow user by using ancillary equipment (such as mouse or keyboard) and/or being evaluated to select one or more optional default suggestion by least one in touch display 128 (if enabling as touch-screen display).
In some implementations, user interface 520 can be configured to use the keyboard of virtual display on keyboard or touch-screen display to receive user's evaluation.Like this, user can to evaluate and optional time becomes and advises non-existent New Appraisement among evaluation in the optional default suggestion of typing display.
In some implementations, user interface 520 can be configured to determine the emphasis when user selects or typing evaluates or " volume ".Such as, emphasis or volume can apply much pressure to determine to touch-screen or other input equipments based on user.Such as, concrete with reference to touch-screen, Petting Area and the ratio of key zone and/or the duration of touch may be used for providing evaluates with from the specific of user the emphasis or volume indicator that input and be associated.
In some implementations, apply the 125 each evaluation inputs be configured to user provides and generate tuple or data structure.Such as, except the field for evaluating input, such as, tuple or data structure comprise the field for flow identifier, wallclock timestamp, content time, emphasis or volume indicator and location pointer.In some implementations, flow identifier field comprises the value identifying the TV programme 502 that TV 110 plays.In some implementations, if user provides agreement, then wallclock timestamp field comprises the value (such as, the Pacific standard time of California, USA) of the local zone time of indicating user position.In some implementations, if user provides agreement, then content time field comprises the value of the time migration that instruction starts relative to TV programme 502.In some implementations, location pointer field comprises the value (such as, California, USA Palo Alto) of indicating user position.
Although described various non-limiting option, those skilled in the art from the disclosure by understanding other option various be also feasible.
Fig. 8 represents according to the flow chart of the method for some implementations.In some implementations, the method is performed by the second screen equipment (such as, the second screen client equipment 120 of Fig. 1).As shown in block 8-1, the method comprises: the identity detecting the media content play on the first equipment of such as TV (such as, TV 110).As shown in block 8-2, the method comprises: by local timer and broadcasting media content synchronization.As shown in block 8-3, the method comprises: receive the content synchronization evaluation be associated with the broadcasting media content provided by other users from server.As shown in block 8-4, the method comprises: at least evaluate according to showing to the corresponding characteristic that each received evaluation is associated.
Fig. 9 represents according to the flow chart of the method for some implementations.In some implementations, (such as, the evaluation analysis module 139 of Fig. 1) the method is performed by evaluation server.As shown in block 9-1, the method comprises: receive playing quoting of media content from least one second screen equipment.As shown in block 9-2, the method comprises: by quoting described the identity comparing with the information in fingerprint database and determine to play media content.As shown in block 9-3, the method comprises: generate and/or retrieve the time mark be associated with broadcasting media content based on determined identity.As shown in block 9-4, the method comprises: time mark is transferred at least one subscriber equipment.As shown in block 9-5, the method comprises: receive the corresponding content synchronization evaluation be associated to broadcasting media content from multiple subscriber equipment.As shown in block 9-6, the method comprises: analyze the evaluation received, and evaluates subset to send it back to multiple subscriber equipment to generate.As shown in block 9-7, the method comprises: evaluation subset is transferred to subscriber equipment.
Figure 10 represents according to the flow chart of the method for some implementations.In some implementations, the method is performed by evaluation server (such as, the evaluation analysis module 139 of Fig. 1).As shown in block 10-1, the method comprises: receive playing quoting of media content from least one second screen equipment.As shown in block 10-2, the method comprises: by quoting described the identity comparing with the information in fingerprint database and determine to play media content.As shown in block 10-3, the method comprises: generate and/or retrieve the time mark be associated with broadcasting media content based on determined identity.As shown in block 10-4, the method comprises: generate and/or retrieve the evaluation seed set be associated with broadcasting media content.In some implementations, the evaluation that during this evaluation seed set comprises the former collection of TV programme, user provides, the expectations be associated with the content of TV programme and the patronage evaluation bought by advertiser.Although described various non-limiting option, those skilled in the art from the disclosure by understanding other option various be also feasible.
As shown in block 10-5, the method comprises: time mark is transferred at least one subscriber equipment.As shown in block 10-6, the method comprises: receive the corresponding content synchronization evaluation be associated to broadcasting media content from multiple subscriber equipment.As shown in block 10-7, the method comprises: analyze the evaluation received, and evaluates subset to send it back to multiple subscriber equipment to generate.As shown in block 10-8, the method comprises: evaluation subset is transferred to subscriber equipment.
The simplified signaling figure of some example transmissions represented in client-server environment 100 between assembly with further reference to Fig. 1, Figure 11.As shown in block 1101, TV 110 plays TV programme, such as, but not limited to TV play, political wrangling, night news or competitive sports.Play TV programme and comprise display video use loud speaker output audio over the display.As shown in block 1102, the second screen client end equipment 120 generates quoting the TV program that TV 110 plays.For this reason, in some implementations, the second screen client end equipment 120 records at least one in the audio or video of TV 110 output.In some implementations, TV 110 and the second screen client end equipment 120 or client device 102 and the second screen client end equipment 120 share data cube computation, and it allows the second screen client end equipment 120 retrieval and the content that can be used for generating the broadcasting TV programme quoted and be associated.Then, the second screen client end equipment 120 will be quoted to be transferred to and evaluate server 130.As shown in block 1103, front-end server 134 receives from the second screen client end equipment 120 and quotes.As shown in block 1104, content information extraction module 131 is by comparing quoting the information comprised until find coupling to identify TV program with the information in fingerprint database.
As indicated by block 1105, in response to content information extraction module 131, evaluation analysis module 139 identifies that TV program provides and evaluates seed set.As shown in block 1106, after the identity determining TV program, content information extraction module 131 generates and/or retrieves the time mark be associated with identified TV program.
As shown in block 1107, instruction set, time mark and the set of evaluation seed are transferred to the second screen client end equipment 120 by front-end server.As shown in block 1108, the second screen equipment uses the synchronous local zone time of time mark received, and shows this evaluation seed set at least partially.In some implementations, show evaluation in a graphic format, and the user 221 of the second screen client end equipment 120 can select separately to evaluate.In some implementations, show evaluation in a graphic format, this graphical format has how many other users to select (if any) before representing each evaluation with the selection number etc. of percentage or each evaluation.
As shown in block 1109, the second screen client end equipment 120 receives user's input that instruction evaluation is selected/inputted, and inserts tuple or data structure, is then transferred to and evaluates server 130.As indicated by block 1110, front-end server 134 receives data structure from one or more second screen equipment.As shown in block 1111, the evaluation that evaluation analysis module 139 analysis is included in data structure.
As shown in block 1112, at least in the duration of TV program, assembly continuation exchanges the synchronizing information and evaluating data that are associated with TV program.Conversely, provide the various second screen client end equipment of evaluating data to receive and upgrade, this renewal at least comprises the result of the analysis of evaluating data.
Figure 12 represents according to the flow chart of the method for some implementations.In some implementations, the method is performed by evaluation server (such as, the evaluation analysis module 139 of Fig. 1).As shown in block 12-1, the method comprises: select to evaluate subset, this evaluation subset is the multiple evaluations the most frequently occurred that various second screen equipment provides.As shown in block 12-2, the method comprises: select to evaluate subset, and this evaluation subset has multiple evaluations that popularity upwards fluctuates.As shown in block 12-3, the method comprises: be confirmed as having from the removing of selected subset the evaluation that popularity fluctuates downwards.In some implementations, determine whether specific pricer gas changes, such as upwards fluctuate or fluctuate downwards, comprising and determine to input the number of users of this evaluation and the difference between the number of users inputting identical evaluation during current slot in the previous time period.In some implementations, fluctuate up or down, determine by described difference is compared with threshold level.If threshold value is broken, then there is fluctuation.As shown in block 12-4, the method comprises: by least selected subset evaluation being adjusted to based on the evaluation number that other rule reduces or increase subset comprises the evaluation of given number.
Figure 13 represents according to the flow chart of the method for some implementations.In some implementations, the method is performed by evaluation server (such as, the evaluation analysis module 139 of Fig. 1).As shown in block 13-1, the method comprises: identify which evaluates the specific emotional passing on basic simlarity.As shown in block 13-2, the method comprises: each identified evaluation be revised as the simplification with substantially identical specific emotional and/or jointly evaluate.As shown in block 13-3, the method comprises: classify to revised evaluation.As shown in block 13-4, the method comprises: select to evaluate subset based on classification/analysis at least partly.As shown in block 13-5, the method comprises: by least reducing or increase based on other rule the evaluation that given number is adjusted in selected subset evaluation by the number of evaluation that subset comprises.Such as, the evaluation that other rule can specify at least two not have a popularity must comprise in the subsets.
Figure 14 represents according to the flow chart of the method for some implementations.In some implementations, the method is performed by evaluation server (such as, the evaluation analysis module 139 of Fig. 1).As shown in block 14-1, the method comprises: identify which evaluates the specific emotional passing on basic simlarity.As shown in block 14-2, the method comprises: select the multiple evaluations the most frequently occurred.As shown in block 14-3, the method comprises: compared with some in the selected evaluation the most frequently occurred, selects at least some evaluation of passing on different mood.As shown in block 14-4, the method comprises: at least based on other rules, selected evaluation subset is adjusted to specified level.
For illustrative purposes, reference specific implementation mode describes description above.Aspect described above can realize in a variety of forms, and therefore, any ad hoc structure described herein and/or function are only illustrative.In addition, illustrative discussion is above not intended to detailed or method and system is restricted to disclosed precise forms.According to above-mentioned instruction, many modifications and variations can be carried out.Select and describe implementation, with the principle of means of interpretation and system best and practical application thereof, thus making those skilled in the art can utilize the various implementations with various amendment of the special-purpose being applicable to expection best.
Based on the disclosure, it will be understood by a person skilled in the art that an aspect described herein can realize independent of any other side, and the two or more of these aspects can combine in every way.Such as, aspect implement device and/or the implementation method of arbitrary number described in this paper can be used.In addition, one or more aspect described in this paper can be used to add other structure and/or this device of functional realiey and/or implement this method, or other structure except one or more aspect described in this paper and/or this device of functional realiey can be used and/or implement this method.
In addition, in description above, many specific detail are set forth to provide the thorough understanding to this implementation.But it is evident that those of ordinary skill in the art, method described herein can be put into practice when not having these specific detail.In other instances, do not describe the known method of those of ordinary skill in the art, process, assembly and network in detail, to avoid each side of fuzzy implementation.
Although it is also understood that and use term " first ", " second " etc. to describe various feature herein, these features should by the restriction of these terms.These terms are only for mutually distinguishing element.Such as, the first equipment can be called as the second equipment, and similarly, second equipment can be called as the first equipment, and do not change the implication of description, as long as " the first equipment " that occurs as one man is renamed, and " the second equipment " that occurs as one man is renamed.
In addition, technical term used herein is only the object in order to describe specific implementation mode, instead of is intended to limit claim.As what use in the description of implementation and claims, singulative " ", " one " and " being somebody's turn to do " are intended to also comprise plural form, unless context clearly indicates in addition.It is also understood that term "and/or" used herein refers to and comprises any and all possible combination of one or more listed project be associated.Will be further understood that, term " comprise " and/or " comprising " when using in this manual, specify state feature, integer, step, operation, element and/or assembly existence, but do not get rid of and exist or additional one or more further feature, integer, step, operation, element, assembly and/or its combination.
As used herein, depend on context, term " if " can be interpreted as representing the prerequisite of statement for genuine " when ... time " or " once " or " in response to determining " or " according to determining " or " in response to detection ".Similarly, depend on context, phrase " if determining (prerequisite of statement is true) " or " if (prerequisite of statement is true) " or " when ... time (prerequisite of statement is true) " can be interpreted as representing that the prerequisite of statement is for genuine " once determination " or " in response to determining " or " according to determining " or " once detecting " or " in response to detecting ".
Claims (26)
1. share and the method play the relevant content synchronization of media content evaluate on the first equipment comprising processor, memory and display, described method comprises:
Use the media content that described first equipment Inspection is play to user;
To receive from the second equipment at described first equipment place and the first content that is associated of described broadcasting media content is synchronously evaluated;
Display and the described first content that is associated of described broadcasting media content are synchronously evaluated on the display;
Display can operate to receive the interface that the user that indicates the user be associated with described broadcasting media to evaluate inputs on the display; And
Communicate the data structure comprising described user evaluation described second equipment.
2. the method for claim 1, wherein described broadcasting media content is play just on the second device.
3. the method for claim 1, wherein detect the described media content play to described user on said first device to comprise:
Quote a part for described broadcasting media content;
Quoting of a part to described media content is transferred to information extraction modules;
The time mark be associated with described broadcasting media content is received from described information extraction modules; And
Local timer is synchronous with described time mark.
4. method as claimed in claim 3, wherein, describedly display indicator can to comprise the image be associated with described broadcasting media content, the part of described broadcasting media content or third party and indicates.
5. method as claimed in claim 3, also comprise receive described broadcasting media content can display indicator.
6. method as claimed in claim 3, wherein, the part quoting described broadcasting media content comprises the part recording described broadcasting media content, and wherein, the part recorded comprises audio component or picture content.
7. the method for claim 1, wherein described display comprises touch-screen display, and described method also comprises the input of enabling and evaluating with typing indicating user with the user interactions of described touch-screen display.
8. the method for claim 1, wherein show the first content that receives synchronously to evaluate and comprise: show at least one in diagrammatic representation that described first content synchronously evaluates and the text representation that described first content is synchronously evaluated.
9. the method for claim 1, wherein shown interface becomes the optional evaluation of a touch, the optional evaluation of non-time-varying one touch or the keyboard for the self-defined evaluation of typing when comprising.
10. user's input of the method for claim 1, wherein indicating user evaluation has limited character length.
User's input of 11. the method for claim 1, wherein indicating user evaluations is static or at least one in motion animation.
12. the method for claim 1, wherein described data structure also comprise be associated with described broadcasting media content content time, with described user evaluate be associated tone designator, location pointer or media content identification.
13. 1 kinds are shared in the method comprising processor and evaluate with the content synchronization relevant to media content on the first equipment of memory, and described method comprises:
The time mark be associated with described media content is transferred to multiple subscriber equipment;
The corresponding content synchronization evaluation relevant to media content is received from described multiple subscriber equipment;
Analyze described content synchronization evaluation and evaluate subset to produce; And
Described evaluation subset is transferred at least one in described multiple subscriber equipment.
14. methods as claimed in claim 13, also comprise:
Receive quoting of a part for the media content that subtend user plays;
The described media content identifying and play to described user is quoted from described; And
Retrieval or generation are used for the described time mark of identified media content.
15. methods as claimed in claim 14, wherein, described in quote be the recording section of described media content.
16. methods as claimed in claim 15, wherein, described in quote be use and the subscriber equipment record of the corresponding device separates for playing described media content.
17. methods as claimed in claim 14, wherein, identify that described media content comprises and described quoting are compared with the database of media content identifier.
18. methods as claimed in claim 13, wherein, analyze described content synchronization evaluation and comprise:
Select multiple comparatively frequent evaluation occurred;
Selection has multiple evaluations that popularity upwards fluctuates compared with previous analysis; And
The multiple evaluations that there is popularity and fluctuate are removed downwards from described subset.
19. methods as claimed in claim 13, wherein, analyze described content synchronization evaluation and comprise:
Identify which evaluates in the mood passing on basic simlarity closely related;
By the simplification evaluation being identified as passing on each evaluation of the mood of basic simlarity to be revised as the mood passing on basic simlarity; And
When considering the evaluation revised, described evaluation is reclassified.
20. methods as claimed in claim 13, wherein, analyze described content synchronization evaluation and comprise:
Identify which is evaluated and pass on substantially different moods;
Select multiple comparatively frequent evaluation occurred; And
Select multiple evaluations of the mood that reception and registration is substantially different compared with selected multiple evaluations comparatively frequently occurred.
21. methods as claimed in claim 13, also comprise: by the optional evaluation regiments of advising that is associated with described media content to described multiple subscriber equipment.
22. methods as claimed in claim 21, wherein, that advises optionally evaluates set and comprises and relevant media content and the evaluation that is associated to the content that described user plays.
23. methods as claimed in claim 22, wherein, described relevant media content and described broadcasting media content comprise the collection of drama of same television program.
24. methods as claimed in claim 21, wherein, be associated with described media content advise optional evaluate gather at least one be associated with advertisement.
25. 1 kinds of non-transitory computer-readable mediums, comprise for being shared in the instruction comprising and processor, memory and the first equipment of display are play the relevant content synchronization evaluation of media content, described instruction, when being performed by described processor, makes described first equipment:
Use the media content that described first equipment Inspection is play to user;
To receive from the second equipment at described first equipment place and the first content that is associated of described broadcasting media content is synchronously evaluated;
Display and the described first content that is associated of described broadcasting media content are synchronously evaluated on the display;
Display can operate to receive the interface that the user that indicates the user be associated with described broadcasting media to evaluate inputs on the display; And
Communicate the data structure comprising described user evaluation described second equipment.
26. 1 kinds for sharing the system that the content synchronization relevant to playing media content is evaluated:
First equipment, described first equipment comprises processor, memory and display, and described memory comprises instruction, and described instruction, when being performed by described processor, makes described first equipment:
Use the media content that described first equipment Inspection is play to user;
To receive from the second equipment at described first equipment place and the first content that is associated of described broadcasting media content is synchronously evaluated;
Display and the described first content that is associated of described broadcasting media content are synchronously evaluated on the display;
Display can operate to receive the interface that the user that indicates the user be associated with described broadcasting media to evaluate inputs on the display; And
Communicate the data structure comprising described user evaluation described second equipment.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US13/624,780 US20140089815A1 (en) | 2012-09-21 | 2012-09-21 | Sharing Content-Synchronized Ratings |
US13/624,780 | 2012-09-21 | ||
PCT/US2013/061024 WO2014047503A2 (en) | 2012-09-21 | 2013-09-20 | Sharing content-synchronized ratings |
Publications (2)
Publication Number | Publication Date |
---|---|
CN104813673A true CN104813673A (en) | 2015-07-29 |
CN104813673B CN104813673B (en) | 2019-04-02 |
Family
ID=49305178
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201380060705.6A Active CN104813673B (en) | 2012-09-21 | 2013-09-20 | Shared content synchronization evaluation |
Country Status (5)
Country | Link |
---|---|
US (1) | US20140089815A1 (en) |
EP (1) | EP2898699A4 (en) |
KR (1) | KR101571678B1 (en) |
CN (1) | CN104813673B (en) |
WO (1) | WO2014047503A2 (en) |
Cited By (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN108549641A (en) * | 2018-04-26 | 2018-09-18 | 中国联合网络通信集团有限公司 | Song assessment method, device, equipment and storage medium |
CN111434119A (en) * | 2017-11-24 | 2020-07-17 | 多玩国株式会社 | Content providing server, content providing program, content providing system, and user program |
CN112422600A (en) * | 2019-08-22 | 2021-02-26 | 北京峰趣互联网信息服务有限公司 | Information synchronous publishing method, server, system and electronic equipment |
CN114501063A (en) * | 2017-03-29 | 2022-05-13 | 六科股份有限公司 | Targeted content placement using overlays |
Families Citing this family (25)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US8893168B2 (en) | 2012-02-07 | 2014-11-18 | Turner Broadcasting System, Inc. | Method and system for synchronization of dial testing and audience response utilizing automatic content recognition |
US9369670B2 (en) * | 2012-12-19 | 2016-06-14 | Rabbit, Inc. | Audio video streaming system and method |
US9154841B2 (en) | 2012-12-28 | 2015-10-06 | Turner Broadcasting System, Inc. | Method and system for detecting and resolving conflicts in an automatic content recognition based system |
US10070192B2 (en) * | 2013-03-15 | 2018-09-04 | Disney Enterprises, Inc. | Application for determining and responding to user sentiments during viewed media content |
FR3004047A1 (en) * | 2013-03-29 | 2014-10-03 | France Telecom | TECHNIQUE OF COOPERATION BETWEEN A PLURALITY OF CLIENT ENTITIES |
US20150135138A1 (en) * | 2013-11-13 | 2015-05-14 | Abraham Reichert | Rating an item with a communication device |
CN104093079B (en) * | 2014-05-29 | 2015-10-07 | 腾讯科技（深圳）有限公司 | Based on the exchange method of multimedia programming, terminal, server and system |
EP2955928A1 (en) * | 2014-06-12 | 2015-12-16 | Vodafone GmbH | Method for timely correlating a voting information with a TV program |
US9635440B2 (en) * | 2014-07-07 | 2017-04-25 | Immersion Corporation | Second screen haptics |
US9729912B2 (en) | 2014-09-22 | 2017-08-08 | Sony Corporation | Method, computer program, electronic device, and system |
US10762533B2 (en) * | 2014-09-29 | 2020-09-01 | Bellevue Investments Gmbh & Co. Kgaa | System and method for effective monetization of product marketing in software applications via audio monitoring |
US9363562B1 (en) | 2014-12-01 | 2016-06-07 | Stingray Digital Group Inc. | Method and system for authorizing a user device |
US9838571B2 (en) | 2015-04-10 | 2017-12-05 | Gvbb Holdings S.A.R.L. | Precision timing for broadcast network |
US10157333B1 (en) | 2015-09-15 | 2018-12-18 | Snap Inc. | Systems and methods for content tagging |
KR102424839B1 (en) | 2015-10-14 | 2022-07-25 | 삼성전자주식회사 | Display apparatus and method of controlling thereof |
US20170161382A1 (en) * | 2015-12-08 | 2017-06-08 | Snapchat, Inc. | System to correlate video data and contextual data |
US10691749B2 (en) | 2016-06-10 | 2020-06-23 | Understory, LLC | Data processing system for managing activities linked to multimedia content |
US11257171B2 (en) | 2016-06-10 | 2022-02-22 | Understory, LLC | Data processing system for managing activities linked to multimedia content |
US10102593B2 (en) | 2016-06-10 | 2018-10-16 | Understory, LLC | Data processing system for managing activities linked to multimedia content when the multimedia content is changed |
WO2017214605A1 (en) | 2016-06-10 | 2017-12-14 | Understory, LLC | Data processing system for managing activities linked to multimedia content |
US11334768B1 (en) | 2016-07-05 | 2022-05-17 | Snap Inc. | Ephemeral content management |
US10701438B2 (en) | 2016-12-31 | 2020-06-30 | Turner Broadcasting System, Inc. | Automatic content recognition and verification in a broadcast chain |
CN107690078B (en) | 2017-09-28 | 2020-04-21 | 腾讯科技（深圳）有限公司 | Bullet screen information display method, bullet screen information providing method and bullet screen information providing equipment |
TWI743418B (en) * | 2018-11-28 | 2021-10-21 | 緯創資通股份有限公司 | Display, method for monitoring played content and system using the same |
US11947563B1 (en) * | 2020-02-29 | 2024-04-02 | The Pnc Financial Services Group, Inc. | Systems and methods for collecting and distributing digital experience information |
Citations (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN101401081A (en) * | 2006-02-16 | 2009-04-01 | 戴尔产品有限公司 | Local transmission for content sharing |
CN101517550A (en) * | 2005-11-29 | 2009-08-26 | 谷歌公司 | Social and interactive applications for mass media |
US20090228947A1 (en) * | 2008-03-07 | 2009-09-10 | At&T Knowledge Ventures, L.P. | System and method for appraising portable media content |
CN102209273A (en) * | 2010-04-01 | 2011-10-05 | 微软公司 | Interactive and shared viewing experience |
CN102449636A (en) * | 2009-05-29 | 2012-05-09 | 牧乐咖股份有限公司 | Multimedia content file management system for and method of using genetic information |
Family Cites Families (22)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US8095949B1 (en) * | 1993-12-02 | 2012-01-10 | Adrea, LLC | Electronic book with restricted access features |
US8707185B2 (en) * | 2000-10-10 | 2014-04-22 | Addnclick, Inc. | Dynamic information management system and method for content delivery and sharing in content-, metadata- and viewer-based, live social networking among users concurrently engaged in the same and/or similar content |
US20060008256A1 (en) * | 2003-10-01 | 2006-01-12 | Khedouri Robert K | Audio visual player apparatus and system and method of content distribution using the same |
JP2009524273A (en) * | 2005-11-29 | 2009-06-25 | グーグル・インコーポレーテッド | Repetitive content detection in broadcast media |
US8519964B2 (en) * | 2007-01-07 | 2013-08-27 | Apple Inc. | Portable multifunction device, method, and graphical user interface supporting user navigations of graphical objects on a touch screen display |
US8285118B2 (en) * | 2007-07-16 | 2012-10-09 | Michael Bronstein | Methods and systems for media content control |
US8060227B2 (en) * | 2007-09-10 | 2011-11-15 | Palo Alto Research Center Incorporated | Digital media player and method for facilitating social music discovery through sampling, identification, and logging |
US20090144272A1 (en) * | 2007-12-04 | 2009-06-04 | Google Inc. | Rating raters |
US7953777B2 (en) * | 2008-04-25 | 2011-05-31 | Yahoo! Inc. | Method and system for retrieving and organizing web media |
US8370396B2 (en) * | 2008-06-11 | 2013-02-05 | Comcast Cable Holdings, Llc. | System and process for connecting media content |
US20120072593A1 (en) * | 2008-09-26 | 2012-03-22 | Ju-Yeob Kim | Multimedia content file management system for and method of using genetic information |
US8713017B2 (en) * | 2009-04-23 | 2014-04-29 | Ebay Inc. | Summarization of short comments |
US20100306232A1 (en) | 2009-05-28 | 2010-12-02 | Harris Corporation | Multimedia system providing database of shared text comment data indexed to video source data and related methods |
US20110078174A1 (en) * | 2009-09-30 | 2011-03-31 | Rovi Technologies Corporation | Systems and methods for scheduling recordings using cross-platform data sources |
US20110126019A1 (en) * | 2009-11-25 | 2011-05-26 | Kaleidescape, Inc. | Altering functionality for child-friendly control devices |
JP2011234198A (en) * | 2010-04-28 | 2011-11-17 | Sony Corp | Information providing method, content display terminal, mobile terminal, server device, information providing system, and program |
WO2012094247A2 (en) * | 2011-01-05 | 2012-07-12 | Rovi Technologies Corporation | Systems and methods for mixed-media content guidance |
US8806540B2 (en) * | 2011-05-10 | 2014-08-12 | Verizon Patent And Licensing Inc. | Interactive media content presentation systems and methods |
US20120290910A1 (en) * | 2011-05-11 | 2012-11-15 | Searchreviews LLC | Ranking sentiment-related content using sentiment and factor-based analysis of contextually-relevant user-generated data |
US8694253B2 (en) * | 2011-12-28 | 2014-04-08 | Apple Inc. | User-specified route rating and alerts |
US8869046B2 (en) * | 2012-07-03 | 2014-10-21 | Wendell Brown | System and method for online rating of electronic content |
US20140068433A1 (en) * | 2012-08-30 | 2014-03-06 | Suresh Chitturi | Rating media fragments and use of rated media fragments |
-
2012
- 2012-09-21 US US13/624,780 patent/US20140089815A1/en not_active Abandoned
-
2013
- 2013-09-20 EP EP13773997.5A patent/EP2898699A4/en not_active Withdrawn
- 2013-09-20 KR KR1020157010290A patent/KR101571678B1/en active IP Right Grant
- 2013-09-20 CN CN201380060705.6A patent/CN104813673B/en active Active
- 2013-09-20 WO PCT/US2013/061024 patent/WO2014047503A2/en active Application Filing
Patent Citations (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN101517550A (en) * | 2005-11-29 | 2009-08-26 | 谷歌公司 | Social and interactive applications for mass media |
CN101401081A (en) * | 2006-02-16 | 2009-04-01 | 戴尔产品有限公司 | Local transmission for content sharing |
US20090228947A1 (en) * | 2008-03-07 | 2009-09-10 | At&T Knowledge Ventures, L.P. | System and method for appraising portable media content |
CN102449636A (en) * | 2009-05-29 | 2012-05-09 | 牧乐咖股份有限公司 | Multimedia content file management system for and method of using genetic information |
CN102209273A (en) * | 2010-04-01 | 2011-10-05 | 微软公司 | Interactive and shared viewing experience |
Cited By (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN114501063A (en) * | 2017-03-29 | 2022-05-13 | 六科股份有限公司 | Targeted content placement using overlays |
CN111434119A (en) * | 2017-11-24 | 2020-07-17 | 多玩国株式会社 | Content providing server, content providing program, content providing system, and user program |
CN108549641A (en) * | 2018-04-26 | 2018-09-18 | 中国联合网络通信集团有限公司 | Song assessment method, device, equipment and storage medium |
CN112422600A (en) * | 2019-08-22 | 2021-02-26 | 北京峰趣互联网信息服务有限公司 | Information synchronous publishing method, server, system and electronic equipment |
Also Published As
Publication number | Publication date |
---|---|
EP2898699A4 (en) | 2016-08-31 |
KR20150052332A (en) | 2015-05-13 |
WO2014047503A2 (en) | 2014-03-27 |
US20140089815A1 (en) | 2014-03-27 |
CN104813673B (en) | 2019-04-02 |
KR101571678B1 (en) | 2015-11-25 |
WO2014047503A3 (en) | 2014-05-15 |
EP2898699A2 (en) | 2015-07-29 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN104813673A (en) | Sharing content-synchronized ratings | |
US10235025B2 (en) | Various systems and methods for expressing an opinion | |
US8843584B2 (en) | Methods for displaying content on a second device that is related to the content playing on a first device | |
AU2007336816B2 (en) | Tagging media assets, locations, and advertisements | |
US9134875B2 (en) | Enhancing public opinion gathering and dissemination | |
US8010657B2 (en) | System and method for tracking the network viral spread of a digital media content item | |
CN102696233B (en) | Multifunction multimedia device | |
CN1988576B (en) | Method for realizing mobile terminal dynamic cache memory multimedia interactive advertisement | |
CN104798346B (en) | For supplementing the method and computing system of electronic information relevant to broadcast medium | |
US20080083003A1 (en) | System for providing promotional content as part of secondary content associated with a primary broadcast | |
US20080082922A1 (en) | System for providing secondary content based on primary broadcast | |
US20070078832A1 (en) | Method and system for using smart tags and a recommendation engine using smart tags | |
US20100153848A1 (en) | Integrated branding, social bookmarking, and aggregation system for media content | |
US20100138292A1 (en) | Method for providing and searching information keyword and information contents related to contents and system thereof | |
CN104012100A (en) | Wearable computers as media exposure meters | |
US20130141459A1 (en) | Systems and methods for graphing user interactions through user generated content | |
CN104823454A (en) | Pushing of content to secondary connected devices | |
US20130238444A1 (en) | System and Method For Promotion and Networking of at Least Artists, Performers, Entertainers, Musicians, and Venues | |
KR20090101863A (en) | Method on making commercial tag sets for content match keyword advertisement of digital content | |
CN105230035A (en) | For the process of the social media of time shift content of multimedia selected | |
US20100205276A1 (en) | System and method for exploiting a media object by a fruition device | |
US9619123B1 (en) | Acquiring and sharing content extracted from media content | |
TW202139100A (en) | Method and system for matching location-based content | |
KR20090099439A (en) | Keyword advertising method and system based on meta information of multimedia contents information | |
KR20110043568A (en) | Keyword Advertising Method and System Based on Meta Information of Multimedia Contents Information like Ccommercial Tags etc. |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
C06 | Publication | ||
PB01 | Publication | ||
EXSB | Decision made by sipo to initiate substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
CB02 | Change of applicant information |
Address after: American CaliforniaApplicant after: Google limited liability companyAddress before: American CaliforniaApplicant before: Google Inc. |
|
CB02 | Change of applicant information | ||
GR01 | Patent grant | ||
GR01 | Patent grant |