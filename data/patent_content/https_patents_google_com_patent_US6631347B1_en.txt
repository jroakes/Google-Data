US6631347B1 - Vector quantization and decoding apparatus for speech signals and method thereof - Google Patents
Vector quantization and decoding apparatus for speech signals and method thereof Download PDFInfo
- Publication number
- US6631347B1 US6631347B1 US10/234,182 US23418202A US6631347B1 US 6631347 B1 US6631347 B1 US 6631347B1 US 23418202 A US23418202 A US 23418202A US 6631347 B1 US6631347 B1 US 6631347B1
- Authority
- US
- United States
- Prior art keywords
- speech signal
- klt
- codebook
- vector
- vector quantization
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Expired - Lifetime
Links
Images
Classifications
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L19/00—Speech or audio signals analysis-synthesis techniques for redundancy reduction, e.g. in vocoders; Coding or decoding of speech or audio signals, using source filter models or psychoacoustic analysis
- G10L19/04—Speech or audio signals analysis-synthesis techniques for redundancy reduction, e.g. in vocoders; Coding or decoding of speech or audio signals, using source filter models or psychoacoustic analysis using predictive techniques
- G10L19/08—Determination or coding of the excitation function; Determination or coding of the long-term prediction parameters
- G10L19/12—Determination or coding of the excitation function; Determination or coding of the long-term prediction parameters the excitation function being a code excitation, e.g. in code excited linear prediction [CELP] vocoders
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L19/00—Speech or audio signals analysis-synthesis techniques for redundancy reduction, e.g. in vocoders; Coding or decoding of speech or audio signals, using source filter models or psychoacoustic analysis
- G10L19/02—Speech or audio signals analysis-synthesis techniques for redundancy reduction, e.g. in vocoders; Coding or decoding of speech or audio signals, using source filter models or psychoacoustic analysis using spectral analysis, e.g. transform vocoders or subband vocoders
- G10L19/032—Quantisation or dequantisation of spectral components
- G10L19/038—Vector quantisation, e.g. TwinVQ audio
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L19/00—Speech or audio signals analysis-synthesis techniques for redundancy reduction, e.g. in vocoders; Coding or decoding of speech or audio signals, using source filter models or psychoacoustic analysis
- G10L2019/0001—Codebooks
- G10L2019/0004—Design or structure of the codebook
- G10L2019/0005—Multi-stage vector quantisation
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L19/00—Speech or audio signals analysis-synthesis techniques for redundancy reduction, e.g. in vocoders; Coding or decoding of speech or audio signals, using source filter models or psychoacoustic analysis
- G10L2019/0001—Codebooks
- G10L2019/0007—Codebook element generation
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L25/00—Speech or voice analysis techniques not restricted to a single one of groups G10L15/00 - G10L21/00
- G10L25/27—Speech or voice analysis techniques not restricted to a single one of groups G10L15/00 - G10L21/00 characterised by the analysis technique
Definitions
- the present invention relates to coding technology for speech signals, and more particularly, to a vector quantization and decoding apparatus providing high encoding efficiency for speech signals and method thereof.
- vector quantization is preferred over scalar quantization because the former has memory, space-filling and shape advantages.
- Conventional vector quantization technique for speech signals includes direct vector quantization (hereinafter, referred to as DVQ) and the code-excited linear prediction (hereinafter, referred to as CELP) coding technique.
- DVQ direct vector quantization
- CELP code-excited linear prediction
- DVQ provides the highest coding efficiency.
- the time-varying signal statistics of a speech signal require a very large number of codebooks. This makes the storage requirements of DVQ unmanageable.
- CELP uses a single codebook. Thus, CELP does not require large storage like DVQ.
- the CELP algorithm consists of extracting linear prediction (hereinafter, referred to as LP) coefficients from an input speech signal, constructing from the code vectors stored in the codebook trial speech signals using a synthesis filter whose filtering characteristic is determined by the extracted LP coefficients, and searching for the code vector with a trial speech signal most similar to that of the input speech signal.
- LP linear prediction
- the Voronoi-region shape of the code vectors stored in the codebooks may be nearly spherical, as shown in FIG. 1A for the two-dimensional case, while the trial speech signals constructed by a synthesis filter do not have a spherical Voronoi-region shape, as shown in FIG. 1 B. Therefore, CELP does not sufficiently utilize the space-filling and shape advantages of vector quantization.
- Another objective of the present invention is to provide a vector quantization and decoding apparatus and method in which an input speech is quantized with modest calculation and storage requirements, by vector-quantizing a speech signal using code vectors obtained by the Karhunen-Loéve Transform (KLT).
- KLT Karhunen-Loéve Transform
- Still another objective of the present invention is to provide a KLT-based classified vector and decoding apparatus by which the Voronoi-region shape for a speech signal is kept nearly spherical, and a method thereof.
- the present invention provides a vector quantization apparatus including a codebook group, a KLT unit, first and second selection units, and a transmission unit.
- the codebook-group has a plurality of codebooks that store the code vectors for a speech signal obtained by KLT, and the codebooks are classified according to KLT-domain statistics of the speech signal.
- the KLT unit transforms an input speech signal to a KLT domain.
- the first selection unit selects an optimal codebook from the codebooks on the basis of the eigenvalue set for the covariance matrix of the input speech signal obtained by the KLT.
- the second selection unit selects an optimal code vector on the basis of the distortion between each of the code vectors carried on the selected codebook and the speech signal transformed to a KLT domain by the KLT unit.
- the transmission unit transmits the index of the optimal code vector to the decoding side so that the optimal code vector is used as the data of vector quantization for the input speech signal.
- Each codebook is associated with a signal class on the basis of the eigenvalues of the covariance matrix of the speech signal.
- the KLT unit performs the following operations. First, the KLT unit calculates the linear prediction (LP) coefficient of the input speech signal, obtains a covariance matrix using the LP coefficients, and calculates a set of eigenvalues for the covariance matrix and eigenvectors corresponding to the eigenvalues. Then, the KLT unit obtains an eigenvalue matrix based on the eigenvalue set and also a unitary matrix on the basis of the eigenvectors. Thereafter, the KLT unit obtains a KLT domain representation for the input speech signal using the unitary matrix.
- LP linear prediction
- the first selection unit selects a codebook with an eigenvalue set similar to the eigenvalue set calculated by the KLT unit.
- the second selection unit selects a code vector having a minimum distortion value so that the code vector used is the optimal code vector.
- the present invention also provides a vector quantization method for speech signals in a system including a plurality of codebooks that store the code vectors for a speech signal.
- a vector quantization method for speech signals in a system including a plurality of codebooks that store the code vectors for a speech signal.
- an input speech signal is transformed to a KLT domain.
- a codebook corresponding to the input speech signal is selected from the codebooks on the basis of the eigenvalue set of the covariance matrix of the input speech signal detected according to the KLT of the input speech signal.
- An optimal code vector is selected on the basis of the distortion value between each of the code vectors stored in the selected codebook and the KL-transformed speech signal.
- the selected code vector is transmitted so that it is used as a vector quantization value for the input speech signal.
- the KLT-based transformation of an input speech signal is performed by the following steps. First, the LP coefficients of the input speech signal are estimated. Then, the covariance matrix for the input speech signal is obtained, and the eigenvalues for the covariance matrix and the eigenvectors for the eigenvalues are calculated. The unitary matrix for the speech signal is also obtained using the eigenvector set. The input speech signal is transformed to a KLT domain using the unitary matrix.
- the selected codebook is a codebook that corresponds to an eigenvalue set similar to the estimated eigenvalue set.
- a code vector having a minimum distortion is selected as the optimal code vector.
- FIG. 1A shows the Voronoi-region shape of an example CELP codebook in the residual domain
- FIG. 1B shows the Voronoi-region shape of the corresponding CELP codebook in the speech domain
- FIG. 2 is a block diagram showing a vector quantization apparatus according to the present invention.
- FIGS. 3A and 3B show examples of a Voronoi-region to explain KLT characteristics
- FIG. 4 is a block diagram showing a decoding apparatus corresponding to the vector quantization apparatus of FIG. 2;
- FIG. 5 is a flowchart illustrating the steps of a vector quantization method according to the present invention.
- a vector quantization apparatus for speech signals includes a codebook group 200 , a Karhunen-Loéve Transform (KLT) unit 210 , a codebook class selection unit 220 , an optimal code vector selection unit 230 and a data transmission unit 240 .
- KLT Karhunen-Loéve Transform
- the codebook group 200 is designed so that codebooks are classified according to the narrow class of KLT-domain statistics for a speech signal using the KLT energy concentration property in the training stage.
- FIG. 3A shows the distribution of code vectors for a 2-dimensional speech signal for each correlation coefficient a 1 .
- FIG. 3B shows the distribution code vectors for a KL-transformed signal corresponding to the 2-dimensional speech signal for a correlation coefficient a 1 as shown in FIG. 3 A.
- speech signals having different statistics have identical statistics in the KLT-domain. Having identical statistics in the KLT-domain implies that speech signals can be classified into an identical eigenvalue set. The eigenvalue corresponds to a variance of the component of a vector transformed to a KLT-domain.
- a distance measure can be used to classify the speech signal into one of n classes, corresponding to the first to n-th codebooks 201 _ 1 to 201 _n included in the codebook group 200 . This is done by finding the eigenvalue set having most similar statistics.
- ⁇ overscore ( ⁇ i j ) ⁇ is the i-th eigenvalue of the codebook in the j-th class and ⁇ i is the i-th eigenvalue of the input signal.
- one codebook has two eigenvalues if code vectors for a 2-dimensional signal are considered. If code vectors for a k-dimensional signal are considered, the corresponding codebook has k eigenvalues.
- the 2 eigenvalues and the k eigenvalues are referred to as eigenvalue sets corresponding to the respective codebooks. As described above, when codebooks are classified by eigenvalue sets, higher eigenvalues are more important.
- the class eigenvalue sets are estimated from the P-th order LP coefficients of actual speech data, and quantized using the Linde-Buzo-Gray (LBG) algorithm having a distance measuring function as shown in Equation 1.
- P can be 10, for example.
- the more classes of codebooks are included in the codebook group 200 the more the SNR efficiency of a vector quantization apparatus for speech signal improves.
- the KLT unit 210 transforms an input speech signal to the KLT-domain frame by frame.
- the KLT unit 210 obtains LP coefficients by analysing an input speech signal.
- the obtained LP coefficient is transmitted to the data transmission unit 240 .
- the LP coefficient of the input speech signal is obtained by one of conventional known methods.
- the covariance matrix E(x) of the input speech signal is obtained using the obtained LP coefficients.
- the covariance matrix E(x) is defined as the following Equation 3: [ 1 A 1 A 2 A 3 A 4 A 1 1 + A 1 2 A 1 + A 1 ⁇ A 2 A 2 + A 1 ⁇ A 3 A 3 + A 1 ⁇ A 4 A 2 A 1 + A 1 ⁇ A 2 1 + A 1 2 + A 2 2 A 1 + A 1 ⁇ A 2 + A 2 ⁇ A 3 A 2 + A 1 ⁇ A 3 + A 2 ⁇ A 4 A 3 A 2 + A 1 ⁇ A 3 A 1 + A 1 ⁇ A 2 + A 2 ⁇ A 3 1 + A 1 2 + A 2 + A 3 2 A 1 + A 1 ⁇ A 2 + A 2 ⁇ A 3 + A 3 ⁇ A 4 A 4 A 3 + A 1 ⁇ A 4 A 2 + A 1 ⁇ A 3 + A 2 ⁇ A 4 A 1 + A 1 ⁇ A 3 + A 2 ⁇ A 4 A 1 + A 1 ⁇ A 3 + A 2 ⁇ A 4 A 1 + A 1 ⁇ A 2 + A 2 ⁇ A 3 + A 3
- a 1 a 1
- a 2 a 1 2 +a 2
- a 3 a 1 3 +2a 1 a 2 +a 3
- a 4 a 1 4 +3a 1 2 a 2 +2a 1 a 3 +a 2 2 +a 4 .
- a 1 to a 4 are LP coefficients.
- the covariance matrix (E(x)) is calculated using the LP coefficients.
- the KLT unit 210 calculates the eigenvalue ⁇ i for the covariance matrix E(x) using Equation 4, and calculates eigenvector P i using Equation 5:
- I is an identity matrix in which the diagonal matrix values are all 1 and the other values are all 0.
- the eigenvector satisfying Equation 5 is normalized.
- the KLT unit 210 obtains a unitary matrix U using the obtained eigenvectors by Equation 6
- P 1 , P 2 and P k are k ⁇ 1matrices.
- the input speech signal is transformed to the KLT-domain through the multiplication of the input speech signal s k by U T , U T s k .
- S k can be a k-dimensional original speech itself or a zero state response (ZSR) of an LP synthesis filter.
- the speech signal transformed to the KLT-domain is provided to the optimal code vector selection unit 230 .
- the superscript T is the transpose, and s k is a k-dimensional vector of the speech signal.
- the codebook class selection unit 220 selects a corresponding codebook from the first to n-th codebooks 201 _ 1 to 201 _n on the basis of the matrix D received from the KLT unit 210 . That is, the codebook class selection unit 220 selects a codebook having eigenvalues (or an eigenvalue set) most similar to the matrix D received from the KLT unit 210 , according to Equation 1. If the selected codebook is the first codebook 201 _ 1 , the code vectors included in the first codebook 201 _ 1 are sequentially output to the optimal code vector selection unit 230 . If the codebook class selection unit 220 receives the eigenvalues instead of the matrix D from the KLT unit 210 , it may select an optimal codebook using Equation 1.
- the optimal code vector selection unit 230 calculates the distortion between U T s k received from the KLT unit 210 and each of the code vectors received from the codebook class selection unit 220 as shown in Equation 7:
- ⁇ ′ ( U T s k ⁇ ij k ) T ( U T s k ⁇ ij k ) (7)
- the optimal code vector selection unit 230 Based on the calculated distortion values, the optimal code vector selection unit 230 extracts the optimal code vector having a minimum distortion. The optimal code vector selection unit 230 transmits the index data of the selected code vector to the data transmission unit 240 .
- the data transmission unit 240 transmits the frame-by-frame LP coefficient from the KLT unit 210 and the index data of the selected code vector to a decoding system including a decoding apparatus shown in FIG. 4 .
- the decoding apparatus corresponding to the vector quantization apparatus of FIG. 2 includes a data detection unit 401 , a codebook group 410 , and an inverse KLT unit 420 .
- the data detection unit 401 detects the index data of a code vector from the data received from an encoding system including the vector quantization apparatus of FIG. 2, and obtains a matrix D and a unitary matrix U from a received LP coefficient using Equations 3 to 6.
- the matrix D and the detected code vector index data are transferred to the codebook group 410 , and the unitary matrix U is transferred to the inverse KLT unit 420 .
- the codebook group 410 selects a codebook class using the received matrix D and detects the optimal code vector from the selected codebook class using the received code vector index data.
- the codebook group 410 is composed of codebooks organized in the same fashion as the codebook group 200 of FIG. 2, and transfers the optimal code vector corresponding to the matrix D and the code vector index data to the inverse KLT unit 420 .
- the inverse KLT unit 420 restores the original speech signal corresponding to the selected code vector in the inverse way of the transformation by the KLT unit 210 using the unitary matrix U from the data detection unit 401 and the code vector from the codebook group 410 . That is, the code vector is multiplied by U, and the original speech signal is restored.
- the vector quantization apparatus and the decoding apparatus can exist within a system if a coding system and a decoding system are formed in one body.
- FIG. 5 is a flowchart illustrating the steps of KLT-based classified vector quantization.
- the LP coefficients for the. input speech signal are estimated frame by frame, in step 502 .
- the covariance matrix E(x) of the input speech signal is calculated as in Equation 3.
- an eigenvalue for the input speech signal is calculated using the calculated covariance matrix E(x), and an eigenvector is calculated using the obtained eigenvalue.
- a matrix D is obtained using the eigenvalues
- a matrix U is obtained using the eigenvectors.
- the matrices D and U are calculated in the same way as described above for the KLT unit 210 of FIG. 2 .
- the input speech signal is transformed to the KLT-domain using the matrix U
- the steps 502 to 506 can be defined as the process of transforming the input speech signal to the KLT-domain.
- a corresponding codebook is selected from a plurality of codebooks using the matrix D composed of eigenvalues.
- the plurality of codebooks are classified on the basis of the speech signal transformed to the KLT-domain as described above for the codebook group 200 of FIG. 2 .
- an optimal code vector is selected by substituting into Equation 7 the code vectors included in the selected codebook and the KL-transformed speech signal U T s k obtained through the steps 502 to 506 .
- the optimal code vector is a code vector having the minimum value out of the result values calculated through Equation 7.
- step 509 the index data of the selected code vector and the LP coefficients estimated in step 502 are transmitted to be the result values of vector quantization for the input speech signal.
- step 501 If it is determined in step 501 that there is no input signal, the process is not carried out.
- the index data of the code vector and the LP coefficients, which are transmitted to the decoder in step 509 , are decoded, and the decoded data is subject to an inverse KLT operation. Through such a process, the speech signalis restored.
- FIG. 5 shows an example of the selection of an optimal codebook class using the matrix D as described above in FIG. 2 .
- the optimal codebook class is selected using the eigenvalues of the matrix D and Equation 1.
- the LP coefficient and the code vector index data are both considered as the result of the vector quantization with respect to a speech signal.
- only the code vector index data may be transferred as the result of the vector quantization.
- a decoding side estimates the LP coefficient representing the spectrum characteristics of a current frame from a speech signal quantized at the previous frame. As a result, an encoding side does not need to transfer an LP parameter to the decoding side. Such LP estimation can be achieved because the speech spectrum characteristics change slowly.
- the LP coefficient applied to the data detection unit 401 of FIG. 4 is not received from the encoding system but estimated by the decoding side in the above-described backward adaptive manner.
- the present invention proposes a KLT-based classified vector quantization (CVQ), where the space-filling advantage can be utilized since the Voronoi-region shape is not affect by the KLT.
- the memory and shape advantage can be also used, since each codebook is designed based on a narrow class of KLT-domain statistics.
- the KLT-based classified vector quantization provides a higher SNR than CELP and DVQ.
- the KLT does not change the Voronoi-region shape (while the LP filter does)
- the input signal is transformed to a KLT-domain and the best code vector is found.
- This process does not require an additional LP synthesis filtering calculation of code vectors during the codebook search.
- the KLT-based classified vector quantization has a codebook search complexity similar to DVQ and much lower than CELP.
- the KLT results in relatively low variance for the smallest eigenvalue axes, which facilitates a reduced memory requirement to store the codebook and a reduced search complexity to find the proper code vector.
- This advantage is obtained by considering a subset dimension having only high eigenvalues.
- a subset dimension having only high eigenvalues As an illustrative example, for a 5-dimensional vector, by using the four largest eigenvalues axes, comparable performance with the usage of all axes can be obtained.
- the storage requirements and the search complexity can be reduced.
Abstract
Description
Claims (19)
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
KR10-2002-0025401A KR100446630B1 (en) | 2002-05-08 | 2002-05-08 | Vector quantization and inverse vector quantization apparatus for the speech signal and method thereof |
KR2002-25401 | 2002-05-08 |
Publications (1)
Publication Number | Publication Date |
---|---|
US6631347B1 true US6631347B1 (en) | 2003-10-07 |
Family
ID=28673112
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US10/234,182 Expired - Lifetime US6631347B1 (en) | 2002-05-08 | 2002-09-05 | Vector quantization and decoding apparatus for speech signals and method thereof |
Country Status (5)
Country | Link |
---|---|
US (1) | US6631347B1 (en) |
EP (1) | EP1361567B1 (en) |
JP (1) | JP2004029708A (en) |
KR (1) | KR100446630B1 (en) |
DE (1) | DE60232402D1 (en) |
Cited By (9)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20020041680A1 (en) * | 2000-02-08 | 2002-04-11 | George Cybenko | System and methods for encrypted execution of computer programs |
US20070097856A1 (en) * | 2005-10-28 | 2007-05-03 | Jibing Wang | Unitary precoding based on randomized fft matrices |
WO2007050861A2 (en) * | 2005-10-27 | 2007-05-03 | Qualcomm Incorporated | Linear precoding for spatially correlated channels |
WO2009059513A1 (en) * | 2007-11-05 | 2009-05-14 | Huawei Technologies Co., Ltd. | A coding method, an encoder and a computer readable medium |
US20090304296A1 (en) * | 2008-06-06 | 2009-12-10 | Microsoft Corporation | Compression of MQDF Classifier Using Flexible Sub-Vector Grouping |
US20100195715A1 (en) * | 2007-10-15 | 2010-08-05 | Huawei Technologies Co., Ltd. | Method and apparatus for adaptive frame prediction |
US20110040558A1 (en) * | 2004-09-17 | 2011-02-17 | Panasonic Corporation | Scalable encoding apparatus, scalable decoding apparatus, scalable encoding method, scalable decoding method, communication terminal apparatus, and base station apparatus |
US8473288B2 (en) | 2008-06-19 | 2013-06-25 | Panasonic Corporation | Quantizer, encoder, and the methods thereof |
US8670500B2 (en) | 2007-09-19 | 2014-03-11 | Lg Electronics Inc. | Data transmitting and receiving method using phase shift based precoding and transceiver supporting the same |
Families Citing this family (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
KR101056462B1 (en) * | 2009-07-02 | 2011-08-11 | 세종대학교산학협력단 | Voice signal quantization device and method |
EP2372699B1 (en) * | 2010-03-02 | 2012-12-19 | Google, Inc. | Coding of audio or video samples using multiple quantizers |
KR101348888B1 (en) * | 2012-01-04 | 2014-01-09 | 세종대학교산학협력단 | A method and device for klt based domain switching split vector quantization |
KR101413229B1 (en) * | 2013-05-13 | 2014-08-06 | 한국과학기술원 | DOA estimation Device and Method |
KR101428938B1 (en) | 2013-08-19 | 2014-08-08 | 세종대학교산학협력단 | Apparatus for quantizing speech signal and the method thereof |
WO2015092483A1 (en) * | 2013-12-17 | 2015-06-25 | Nokia Technologies Oy | Audio signal encoder |
Citations (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4907276A (en) * | 1988-04-05 | 1990-03-06 | The Dsp Group (Israel) Ltd. | Fast search method for vector quantizer communication and pattern recognition systems |
US5544277A (en) * | 1993-07-28 | 1996-08-06 | International Business Machines Corporation | Speech coding apparatus and method for generating acoustic feature vector component values by combining values of the same features for multiple time intervals |
US5950155A (en) * | 1994-12-21 | 1999-09-07 | Sony Corporation | Apparatus and method for speech encoding based on short-term prediction valves |
US6151414A (en) * | 1998-01-30 | 2000-11-21 | Lucent Technologies Inc. | Method for signal encoding and feature extraction |
US6389388B1 (en) * | 1993-12-14 | 2002-05-14 | Interdigital Technology Corporation | Encoding a speech signal using code excited linear prediction using a plurality of codebooks |
US6415254B1 (en) * | 1997-10-22 | 2002-07-02 | Matsushita Electric Industrial Co., Ltd. | Sound encoder and sound decoder |
Family Cites Families (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JPH05257492A (en) * | 1992-03-13 | 1993-10-08 | Toshiba Corp | Voice recognizing system |
KR100248072B1 (en) * | 1997-11-11 | 2000-03-15 | 정선종 | Image compression/decompression method and apparatus using neural networks |
DE10030105A1 (en) * | 2000-06-19 | 2002-01-03 | Bosch Gmbh Robert | Speech recognition device |
-
2002
- 2002-05-08 KR KR10-2002-0025401A patent/KR100446630B1/en active IP Right Grant
- 2002-09-04 EP EP02256142A patent/EP1361567B1/en not_active Expired - Lifetime
- 2002-09-04 DE DE60232402T patent/DE60232402D1/en not_active Expired - Lifetime
- 2002-09-05 US US10/234,182 patent/US6631347B1/en not_active Expired - Lifetime
- 2002-12-26 JP JP2002376122A patent/JP2004029708A/en active Pending
Patent Citations (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4907276A (en) * | 1988-04-05 | 1990-03-06 | The Dsp Group (Israel) Ltd. | Fast search method for vector quantizer communication and pattern recognition systems |
US5544277A (en) * | 1993-07-28 | 1996-08-06 | International Business Machines Corporation | Speech coding apparatus and method for generating acoustic feature vector component values by combining values of the same features for multiple time intervals |
US6389388B1 (en) * | 1993-12-14 | 2002-05-14 | Interdigital Technology Corporation | Encoding a speech signal using code excited linear prediction using a plurality of codebooks |
US5950155A (en) * | 1994-12-21 | 1999-09-07 | Sony Corporation | Apparatus and method for speech encoding based on short-term prediction valves |
US6415254B1 (en) * | 1997-10-22 | 2002-07-02 | Matsushita Electric Industrial Co., Ltd. | Sound encoder and sound decoder |
US6151414A (en) * | 1998-01-30 | 2000-11-21 | Lucent Technologies Inc. | Method for signal encoding and feature extraction |
Non-Patent Citations (2)
Title |
---|
Dony, R. D. and Haykin, S. "Neural network approaches to image compression," Proceedings of the IEEE, vol. 83, Issue 2, p 288-303, Feb. 1995.* * |
Kim, Tae-Yong et al. "KLT-based adaptive vector quantization using PCNN," IEEE International Conference on Systems, Ma and, Cybernetics, vol. 1, pp. 82-87, Oct. 1996. * |
Cited By (23)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7296163B2 (en) * | 2000-02-08 | 2007-11-13 | The Trustees Of Dartmouth College | System and methods for encrypted execution of computer programs |
US20020041680A1 (en) * | 2000-02-08 | 2002-04-11 | George Cybenko | System and methods for encrypted execution of computer programs |
US8712767B2 (en) * | 2004-09-17 | 2014-04-29 | Panasonic Corporation | Scalable encoding apparatus, scalable decoding apparatus, scalable encoding method, scalable decoding method, communication terminal apparatus, and base station apparatus |
US20110040558A1 (en) * | 2004-09-17 | 2011-02-17 | Panasonic Corporation | Scalable encoding apparatus, scalable decoding apparatus, scalable encoding method, scalable decoding method, communication terminal apparatus, and base station apparatus |
KR100952098B1 (en) * | 2005-10-27 | 2010-04-13 | 퀄컴 인코포레이티드 | Linear precoding for spatially correlated channels |
US20070174038A1 (en) * | 2005-10-27 | 2007-07-26 | Jibing Wang | Linear precoding for spatially correlated channels |
WO2007050861A3 (en) * | 2005-10-27 | 2007-06-14 | Qualcomm Inc | Linear precoding for spatially correlated channels |
WO2007050861A2 (en) * | 2005-10-27 | 2007-05-03 | Qualcomm Incorporated | Linear precoding for spatially correlated channels |
CN101346899B (en) * | 2005-10-27 | 2012-08-29 | 高通股份有限公司 | Linear precoding for spatially correlated channels |
US8385433B2 (en) | 2005-10-27 | 2013-02-26 | Qualcomm Incorporated | Linear precoding for spatially correlated channels |
US9106287B2 (en) | 2005-10-28 | 2015-08-11 | Qualcomm Incorporated | Unitary precoding based on randomized FFT matrices |
US8923109B2 (en) | 2005-10-28 | 2014-12-30 | Qualcomm Incorporated | Unitary precoding based on randomized FFT matrices |
US8760994B2 (en) * | 2005-10-28 | 2014-06-24 | Qualcomm Incorporated | Unitary precoding based on randomized FFT matrices |
US20070097856A1 (en) * | 2005-10-28 | 2007-05-03 | Jibing Wang | Unitary precoding based on randomized fft matrices |
US8670500B2 (en) | 2007-09-19 | 2014-03-11 | Lg Electronics Inc. | Data transmitting and receiving method using phase shift based precoding and transceiver supporting the same |
US20100195715A1 (en) * | 2007-10-15 | 2010-08-05 | Huawei Technologies Co., Ltd. | Method and apparatus for adaptive frame prediction |
US8600739B2 (en) | 2007-11-05 | 2013-12-03 | Huawei Technologies Co., Ltd. | Coding method, encoder, and computer readable medium that uses one of multiple codebooks based on a type of input signal |
US20090248406A1 (en) * | 2007-11-05 | 2009-10-01 | Dejun Zhang | Coding method, encoder, and computer readable medium |
WO2009059513A1 (en) * | 2007-11-05 | 2009-05-14 | Huawei Technologies Co., Ltd. | A coding method, an encoder and a computer readable medium |
US8077994B2 (en) * | 2008-06-06 | 2011-12-13 | Microsoft Corporation | Compression of MQDF classifier using flexible sub-vector grouping |
US20090304296A1 (en) * | 2008-06-06 | 2009-12-10 | Microsoft Corporation | Compression of MQDF Classifier Using Flexible Sub-Vector Grouping |
RU2486609C2 (en) * | 2008-06-19 | 2013-06-27 | Панасоник Корпорейшн | Quantiser, encoder and methods thereof |
US8473288B2 (en) | 2008-06-19 | 2013-06-25 | Panasonic Corporation | Quantizer, encoder, and the methods thereof |
Also Published As
Publication number | Publication date |
---|---|
KR100446630B1 (en) | 2004-09-04 |
EP1361567B1 (en) | 2009-05-20 |
JP2004029708A (en) | 2004-01-29 |
EP1361567A2 (en) | 2003-11-12 |
DE60232402D1 (en) | 2009-07-02 |
EP1361567A3 (en) | 2005-06-08 |
KR20030087373A (en) | 2003-11-14 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US6631347B1 (en) | Vector quantization and decoding apparatus for speech signals and method thereof | |
US7916958B2 (en) | Compression for holographic data and imagery | |
EP2207167B1 (en) | Multistage quantizing method | |
US20050114123A1 (en) | Speech processing system and method | |
US8422799B1 (en) | Complex image compression | |
US6807527B1 (en) | Method and apparatus for determination of an optimum fixed codebook vector | |
US9070356B2 (en) | Method and apparatus for generating a candidate code-vector to code an informational signal | |
EP2099025A1 (en) | Audio encoding device and audio encoding method | |
US7103101B1 (en) | Method and system for blind Karhunen-Loeve transform coding | |
Korse et al. | GMM-based iterative entropy coding for spectral envelopes of speech and audio | |
US9263053B2 (en) | Method and apparatus for generating a candidate code-vector to code an informational signal | |
Subramaniam et al. | Speech LSF quantization with rate independent complexity, bit scalability and learning | |
KR101056462B1 (en) | Voice signal quantization device and method | |
WO2011087333A2 (en) | Method and apparatus for processing an audio signal | |
Jiang | Vector-quantized speech separation | |
US8422798B1 (en) | Magnitude image compression | |
Chan et al. | In search of the optimal searching sequence for VQ encoding | |
KR101059925B1 (en) | Fast Speaker Adaptation Using Clustered EV | |
Perrinet | Sparse Spike Coding: applications of Neuroscience to the processing of natural images | |
Mathews | Vector quantization of images using the L/sub/spl infin//distortion measure | |
Bäckström et al. | Principles of Entropy Coding with Perceptual Quality Evaluation | |
Curila et al. | Decorrelation techniques for geometry coding of 3D mesh | |
JPH04288663A (en) | Composite self-organizing pattern classifying system | |
CN117672237A (en) | End-to-end speech coding method and system based on vector prediction and fusion technology | |
KR101052301B1 (en) | Voice signal quantization device and method |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GLOBAL IP SOUND AB, SWEDENFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:KIM, MOO YOUNG;KLEIJN, WILLEM BASTIAAN;REEL/FRAME:013264/0548Effective date: 20020904Owner name: SAMSUNG ELECTRONICS CO., LTD., KOREA, REPUBLIC OFFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:KIM, MOO YOUNG;KLEIJN, WILLEM BASTIAAN;REEL/FRAME:013264/0548Effective date: 20020904 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
FEPP | Fee payment procedure |
Free format text: PAYOR NUMBER ASSIGNED (ORIGINAL EVENT CODE: ASPN); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
AS | Assignment |
Owner name: AB GRUNDSTENEN 91089, SWEDENFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:GLOBAL IP SOUND AB;REEL/FRAME:014473/0825Effective date: 20031231Owner name: GLOBAL IP SOUND EUROPE AB, SWEDENFree format text: CHANGE OF NAME;ASSIGNOR:AB GRUNDSTENEN 91089;REEL/FRAME:014473/0682Effective date: 20031230Owner name: GLOBAL IP SOUND INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:GLOBAL IP SOUND AB;REEL/FRAME:014473/0825Effective date: 20031231 |
|
CC | Certificate of correction | ||
FPAY | Fee payment |
Year of fee payment: 4 |
|
FEPP | Fee payment procedure |
Free format text: PAYER NUMBER DE-ASSIGNED (ORIGINAL EVENT CODE: RMPN); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYFree format text: PAYOR NUMBER ASSIGNED (ORIGINAL EVENT CODE: ASPN); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
FPAY | Fee payment |
Year of fee payment: 8 |
|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:GLOBAL IP SOLUTIONS (GIPS) AB;GLOBAL IP SOLUTIONS, INC.;REEL/FRAME:028413/0177Effective date: 20120612 |
|
FEPP | Fee payment procedure |
Free format text: PAYER NUMBER DE-ASSIGNED (ORIGINAL EVENT CODE: RMPN); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYFree format text: PAYOR NUMBER ASSIGNED (ORIGINAL EVENT CODE: ASPN); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
AS | Assignment |
Owner name: GLOBAL IP SOLUTIONS, INC., SWEDENFree format text: CHANGE OF NAME;ASSIGNOR:GLOBAL IP SOUND, INC.;REEL/FRAME:029597/0445Effective date: 20070221Owner name: GLOBAL IP SOLUTIONS (GIPS) AB, SWEDENFree format text: CHANGE OF NAME;ASSIGNOR:GLOBAL IP SOUND EUROPE AB;REEL/FRAME:029597/0442Effective date: 20070314Owner name: GLOBAL IP SOUND, INC., CALIFORNIAFree format text: CORRECTIVE ASSIGNMENT TO CORRECT THE INCOMPLETE ASSIGNMENT BY RE-RECORDING AND REPLACING THE INCOMPLETE ASSIGNMENT PREVIOUSLY RECORDED ON REEL 014473 FRAME 0825. ASSIGNOR(S) HEREBY CONFIRMS THE ASSIGNMENT;ASSIGNOR:GLOBAL IP SOUND AB;REEL/FRAME:029983/0506Effective date: 20031231Owner name: GLOBAL IP SOUND EUROPE AB, SWEDENFree format text: CORRECTIVE ASSIGNMENT TO CORRECT THE INCOMPLETE ASSIGNMENT BY RE-RECORDING AND REPLACING THE INCOMPLETE ASSIGNMENT PREVIOUSLY RECORDED ON REEL 014473 FRAME 0825. ASSIGNOR(S) HEREBY CONFIRMS THE ASSIGNMENT;ASSIGNOR:GLOBAL IP SOUND AB;REEL/FRAME:029983/0506Effective date: 20031231 |
|
FEPP | Fee payment procedure |
Free format text: PAYER NUMBER DE-ASSIGNED (ORIGINAL EVENT CODE: RMPN); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYFree format text: PAYOR NUMBER ASSIGNED (ORIGINAL EVENT CODE: ASPN); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
FPAY | Fee payment |
Year of fee payment: 12 |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044695/0115Effective date: 20170929 |