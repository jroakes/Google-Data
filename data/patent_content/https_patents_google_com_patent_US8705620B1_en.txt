US8705620B1 - Method and apparatus for encoding anchor frame by encoding features using layers - Google Patents
Method and apparatus for encoding anchor frame by encoding features using layers Download PDFInfo
- Publication number
- US8705620B1 US8705620B1 US13/095,975 US201113095975A US8705620B1 US 8705620 B1 US8705620 B1 US 8705620B1 US 201113095975 A US201113095975 A US 201113095975A US 8705620 B1 US8705620 B1 US 8705620B1
- Authority
- US
- United States
- Prior art keywords
- pixels
- run
- encoding
- adjacent
- base layer
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Expired - Fee Related, expires
Links
Images
Classifications
-
- H04N7/26297—
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/20—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using video object coding
- H04N19/29—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using video object coding involving scalability at the object level, e.g. video object layer [VOL]
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/20—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using video object coding
- H04N19/27—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using video object coding involving both synthetic and natural picture components, e.g. synthetic natural hybrid coding [SNHC]
-
- H04N7/26265—
-
- H04N7/26276—
Definitions
- the present invention relates in general to video encoding and decoding.
- Digital video streams typically represent video using a sequence of frames (i.e. still images).
- An increasing number of applications today make use of digital video stream encoding for purposes other than traditional moving pictures (such as movies and video clips).
- screen capture and screen casting applications generally represent the output of a computer monitor over time as a digital video stream, irrespective of the specialized nature of the content of the monitor.
- screen capture and screen casting digital video streams are encoded using video encoding techniques like those used for traditional moving pictures.
- H.264 a standard promulgated by ITU-T Video Coding Experts Group (VCEG) and the ISO/IEC Moving Picture Experts Group (MPEG), including present and future versions thereof.
- VCEG Video Coding Experts Group
- MPEG Moving Picture Experts Group
- H.264 is also known as MPEG-4 Part 10 or MPEG-4 AVC (formally, ISO/IEC 14496-10).
- These compression schemes may use quantization and transform techniques on the frames of a digital video stream to reduce the bitrate (i.e. encoded data size) of the encoded digital video stream.
- bitrate i.e. encoded data size
- quantization techniques are used to discard part of a frame's data based on standard computations, thereby reducing the frame's bitrate.
- Quantization is a low-pass technique, which can cause blurring or other effects on a frame. These effects result in video artifacts around the edges in the frame's contents, such as ring artifacts. These artifacts are especially noticeable in digital video streams containing numerous edges, such as in screen capture and screen casting applications.
- a method for encoding a video frame having a plurality of pixels.
- the method includes identifying a plurality of sets of substantially identical adjacent pixels within the frame and determining a number of pixels in each set.
- the method includes assigning the pixels in each set to one of an enhancement layer or base layer based at least in part on the number of pixels in that set.
- the method further includes encoding the pixels assigned to the base layer using a first encoding technique and encoding the pixels assigned to the enhancement layer using a second encoding technique.
- an apparatus to encode a video signal.
- the apparatus includes a memory and a processor to encode a video signal.
- the processor is configured to execute instructions stored in the memory to (1) identify a plurality of sets of adjacent pixels within the frame, wherein each set includes pixels that are substantially identical, (2) determine a number of pixels in each set, (3) assign the pixels in each set to one of an enhancement layer or base layer based at least in part on the number of pixels in that set, (4) encode the pixels assigned to the base layer using a first encoding technique, and (5) encode the pixels assigned to the enhancement layer using a second encoding technique.
- a second embodiment of the apparatus aspect is for encoding a frame of video having a plurality of pixels.
- the apparatus includes means for identifying a plurality of sets of substantially identical adjacent pixels within the frame and means for determining a number of pixels in each set.
- the method includes means for assigning the pixels in each set to one of an enhancement layer or base layer based at least in part on the number of pixels in that set.
- the method further includes means for encoding the pixels assigned to the base layer using a first encoding technique and means for encoding the pixels assigned to the enhancement layer using a second encoding technique.
- FIG. 1 is a diagram of an encoder and decoder system in accordance with one embodiment
- FIG. 2 is an exemplary frame of a digital video stream in the system of FIG. 1 ;
- FIG. 3 is the base layer portion of the frame of FIG. 2 ;
- FIG. 4 is the enhancement layer portion of the frame of FIG. 2 ;
- FIG. 5 is a flowchart of a method of encoding an anchor frame by the encoder of FIG. 1 ;
- FIG. 6 is a flowchart of an enhancement layer determination method of assigning pixels of the frame as being either in the base layer or the enhancement layer;
- FIG. 7 is a flowchart of a method of optimizing the encoding of consecutive runs of pixels having matching runs of pixels in previous lines of pixels in the frame.
- FIG. 8 is a flowchart of a method of encoding a run of pixels.
- FIG. 1 is a diagram of an encoder and decoder system 10 for digital video streams.
- An exemplary transmitting station 12 may be, for example, a computer having an internal configuration of hardware including a central processing unit (CPU) 14 and memory 16 .
- the CPU 14 is a controller for controlling the operations of transmitting station 12 .
- the CPU 14 is connected to memory 16 by, for example, a memory bus.
- the memory 16 may be random access memory (RAM).
- RAM random access memory
- the memory 16 stores data and program instructions which are used by the CPU 14 .
- Other suitable implementations of transmitting station 12 are possible such as those explained later.
- a display 18 configured to display video output can be connected to transmitting station 12 .
- the display 18 can be implemented in various ways, including by a liquid crystal display (LCD) or a cathode-ray tube (CRT).
- the display 18 can also be configured for other uses, such as screen casting or screen capture.
- the display 18 can display, for example, a frame 20 of a digital video stream.
- the frame 20 may include output from the graphical user interface (GUI) of the transmitting station 12 . It may include, for example, visual elements such as a taskbar, one or more application windows, and a desktop background.
- the application windows may include text, images, or other graphics that may be scrolled within the application windows.
- the frame 20 may include any sequence of video frames containing any type of image, including movies, video clips, or still images.
- a network 22 connects the transmitting station 12 and a receiving station 24 .
- the network 22 may, for example, be what is commonly known as the Internet.
- the network 22 may also be a local area network (LAN), wide area network (WAN), virtual private network (VPN), or any other means of transferring data between transmitting station 12 and receiving station 24 .
- LAN local area network
- WAN wide area network
- VPN virtual private network
- the exemplary receiving station 24 may be a computer having an internal configuration of hardware include a central processing unit (CPU) 26 and a memory 28 .
- the CPU 26 is a controller for controlling the operations of transmitting station 12 .
- the CPU 26 is connected to memory 28 by, for example, a memory bus.
- the memory 28 may be random access memory (RAM).
- the memory 28 stores data and program instructions which are used by the CPU 26 .
- Other suitable implementations of receiving station 24 are possible such as those explained later.
- FIG. 2 is an exemplary frame 20 of the digital video stream as shown in FIG. 1 .
- the frame 20 has geometrical 30 , image 32 , and text 34 components.
- Each component has specific characteristics.
- the geometrical component 30 has pixels that are the same color.
- Each line of pixels that includes a part of the geometrical component 30 may contain a different number of pixels of the geometrical component 30 .
- the top of geometrical component 30 may only have one pixel in a line of pixels, whereas the bottom of geometrical component 30 may have hundreds of pixels in a line of pixels.
- the image 32 contains varying colors that together depict a building.
- the majority of the pixels in each letter of text 34 has the same exact color (black).
- text 34 may be anti-aliased.
- the edges of text 34 will be blurred and the pixels at the edges of text 34 will be various shades of color between the text (black) and the background (white).
- the frame 20 and its contents have been chosen purely for explanatory purposes. Practical applications of the methods herein are applicable to digital video streams that may be much more complex than frame 20 , and may contain frames that have aspects similar to or different than one or more of the aspects of the frame 20 .
- a frame could include a taskbar and application window(s) that are represented using geometrical shapes, images, text, and combinations or variations thereof.
- FIG. 3 is the base layer portion 40 of the exemplary frame 20 of FIG. 2 and FIG. 4 is the enhancement layer portion 50 of the exemplary frame 20 of FIG. 2 .
- the exemplary frame 20 can be divided into a base layer portion 40 and an enhancement layer portion 50 .
- the layers distinguish between high-frequency and low-frequency portions of the frame.
- the base layer portion is primarily composed of low frequency data
- the enhancement layer portion is primarily composed of high frequency data.
- frequency refers to the rate of change of the value of pixels in the frame.
- the geometrical component 30 ′, non anti-aliased text 34 ′ and white background could be considered as low frequency portions. Both have a very low rate of change in pixel values and each have substantially identical pixel values.
- the determination of whether a pixel is substantially identical can vary from implementation to implementation.
- the basic determination is whether or not the color value of spatially correspondent pixels in the reference frame and the non-anchor frame are exactly the same. In other words, the pixels are collocated between two blocks or two frames. However, in some instances, it may be preferable to include pixels in the static content area with substantially similar color value(s), for example, within a threshold. In this instance, the decoded version of the non-anchor frame would reference the color value of the pixel from the reference frame, even though it may be different than the color value of the pixel actually in the non-anchor frame.
- a difference between color value A and color value B represented using RGB values could be calculated as (R A ⁇ R B )+(G A ⁇ G B )+(B A ⁇ B B ). If the calculated difference is less than the threshold, then the two color values would be considered substantially identical.
- other schemes and methods of determining whether pixels are substantially identical may be used as well.
- a pixel may be substantially identical even if it is not very similar.
- An implementation may include a process for despeckling the static content area. For example, the process may determine that a pixel in the non-anchor frame is an error or an aberration in the non-anchor frame and may include that pixel in the static content area even though it is not similar to the spatially correspondent pixel in the reference frame. Also, a portion of pixels in a frame may be substantially identical to another portion if a majority of pixels in the portions are substantially identical.
- image 32 ′ is an example of a high frequency portion, with variations in pixel values over small areas of the frame.
- anti-aliased text 34 ′′ could be included in the enhancement layer portion 50 because of the variation in pixel values from black to white over a very small area.
- the base layer will typically include background areas and edges within a frame.
- the base layer would encompass GUI elements on a computer screen, such as the taskbar, application windows, or a constant color background.
- other types of video data can be included in the base layer, such as is found in presentation slideshows and line drawings or animated versions thereof.
- the base layer can be encoded using a high-quality encoding scheme, which can be, for example, a lossless encoding scheme.
- the high-quality encoding scheme can be a lossy encoding scheme that does not result in a significant visual loss.
- the high-quality encoding scheme can provide a better decoded digital video signal for the base layer by eliminating or greatly reducing the encoding artifacts that can be introduced using other techniques.
- the high quality encoding scheme can be implemented with high levels of compression with zero or little loss because the base layer is more repetitive in nature.
- the enhancement layer can be encoded using standard video or image encoding techniques, including los sy encoding schemes.
- Such techniques can include a high-quality encoding scheme or a low-quality encoding scheme (i.e. having a greater degree of loss than the high-quality encoding scheme).
- the low-quality encoding scheme while resulting in greater data loss, can be less noticeable to the end user when applied to the enhancement layer only, as opposed to being applied to the entire frame (including the base layer). This is because the data in the enhancement layer, being of primarily high frequency data, is more susceptible to standard encoding techniques at higher quantization levels than the data in the base layer.
- Encoding techniques that can be used include MJPEG, H.264, and VP8 encoding standards although any still or video image encoding technique may be used.
- An anchor frame is a frame that is encoded with reference to no other frames.
- a non-anchor frame is a frame that is encoded with reference to a previously encoded frame. In one implementation, the non-anchor frame refers to the frame immediately preceding the current frame.
- the encoder can determine that the current frame is an anchor frame using a number of different methodologies. For example, the current frame can be an anchor frame based upon the position of the current frame in the video data stream. If, for example, the current frame is the first frame in the video data stream, the current frame will be an anchor frame.
- the current frame can also become an anchor frame if it is requested by the receiving station 24 .
- the receiving station 24 might detect an error in a sequence of encoded non-anchor frames. In order to recover from the error, the receiving station 24 can request that the next frame be an anchor frame. More sophisticated methods of determining whether to use the current frame as an anchor frame can also be used. For example, the current frame may be deemed an anchor frame if the difference between the current frame and the immediately preceding frame is large. Or the encoder can strategically determine points in time to insert an anchor frame to prevent error propagation.
- FIG. 5 is a flowchart of a method 70 of encoding an anchor frame by the encoder of FIG. 1 .
- the anchor frame is first initialized ( 72 ).
- Initialization can include setting up initial values for variables needed during the encoding process. For example, a bitmask can be set up that can later be used to identify whether pixels are in the base layer or enhancement layer.
- Other counters and pointers can be initialized, including the current line of pixels being encoded, the number of lines available to be encoded, and the position and length of the current and last color runs that have been identified.
- the encoder determines whether any lines of pixels are available to be encoded ( 74 ). If not, all base layer pixels in the frame have been encoded, and the encoder will then encode the enhancement layer ( 75 ).
- the enhancement layer can be encoded using encoding techniques that are described above and in the referenced co-pending application.
- the next line is selected and initialized ( 76 ).
- the starting pixel of the current color run is set as the first pixel in the line and the last color run can be set to NULL.
- the current color run will then be counted, starting from the starting pixel ( 80 ).
- the counting of the color run will include all substantially identical pixels that are consecutively adjacent to the starting pixel. Once counted, the color run will have a pixel count equal to the number of pixels in the color run.
- Color runs can also be referred to as a run, a run of pixels, or as a set of adjacent pixels.
- the number of pixels is compared to a threshold ( 82 ). If the number of pixels is greater than the threshold, the color run is in the base layer. However, if the number of pixels is less than the threshold, an enhancement layer determination method will be performed ( 84 ). The enhancement layer determination method will determine whether the color run is in the base or enhancement layer. The enhancement layer determination method is described later with respect to FIG. 6 .
- the last color run is finalized with respect to the current run ( 86 ).
- the finalization process is described in more detail with respect to FIG. 7 .
- the current color run is finished being processed, and the starting pixel is set to the pixel immediately after the current color run ( 88 ).
- the encoder determines whether the last color run went to the end of the current line of pixels ( 78 ). In other words, the encoder determines if the next starting pixel is past the end of the line of pixels. If not, control returns to stage 80 where the next color run will be counted. However, if the last color run went to the end of the current line of pixels, the line will be finalized ( 90 ). Finalization of the line includes encoding the last color run in the line, which at this point would not have yet been encoded. Encoding a color run is described in more detail later with respect to FIG. 8 . Once the line is finalized, control returns to stage 74 , where the encoder will determine whether any additional lines of pixels are available for encoding.
- FIG. 6 is a flowchart of an enhancement layer determination method 100 of assigning pixels of the frame as being either in the base layer or the enhancement layer. This method is utilized if a color run in a line of pixels is smaller than the threshold. First, if any of the pixels in the color run were previously marked as being in the base or enhancement layer using this method, all pixels in that color run will be marked as being in that layer and the method will end ( 102 ).
- an iterative search of pixels in adjacent lines of pixels below the color run will be performed ( 104 ).
- the iterative search locates any consecutively adjacent substantially identical pixels that the color run can be expanded to encompass. However, the iterative search can be halted once the number of pixels in the color run exceeds the threshold to improve encoding efficiency.
- the search can be performed using a four-neighbor or eight-neighbor search method, but other search methods could also alternatively be used.
- the color run is expanded, it is checked to see if any pixel in the expanded color run is already marked as being in the base layer ( 106 ). And the number of pixels in the color run will be compared to the threshold ( 108 ). If either there was a pre-existing base layer pixel or if the number of pixels exceeds the threshold, the pixels in the expanded color run will be marked as being in the base layer ( 110 ). Otherwise, the pixels in the expanded color run will be marked as being in the enhancement layer ( 112 ).
- FIG. 7 is a flowchart of a method 120 of finalizing a last color run with optimization.
- the method 120 compares concatenated runs in the current line of pixels to the previous line of pixels to optimize encoding of lines of pixels that are repetitive in nature.
- the method 120 is performed after a current color run is identified and when there is a last run (i.e. the current color run is not the first color run in the line of pixels).
- the encoder concatenates the current and last runs into a concatenated run ( 122 ).
- the concatenated run is compared to pixels from the previous line of pixels starting with the same starting pixel location as the concatenated run ( 124 ).
- the encoder determines if the concatenated run and the pixels from the previous line of pixels are substantially identical ( 126 ). If so, the last color run is set to be the concatenated run ( 128 ).
- the last run is encoded ( 130 ).
- the encoding of color runs is described in more detail with respect to FIG. 8 .
- the current color run is set as the last run ( 132 ).
- FIG. 8 is a flowchart of a method 140 of encoding a color run.
- the encoder determines whether the color run is the same as the last line ( 142 ). The encoder makes the determination by comparing the pixels in the previous line starting with the starting pixel location (i.e. same column) of the color run to be encoded with the color run to be encoded. If the color run to be encoded is a concatenated run, then it will match the previous line because a prerequisite to concatenation is that the concatenated run be substantially identical to the previous line of pixels. If there is a match, the color run is encoded using the “REF_ALL” mode ( 144 ).
- This mode encodes the color run using the starting pixel of the color run and the length of the color run.
- This encoding mode implicitly references to a run of pixels having the same starting pixel location and run length in the previous line of pixels for the color value(s) of the color run.
- the encoder next determines if the color run's color value is found nearby ( 146 ). For this determination, the encoder examines color runs in the previous line of pixels above the color run to be encoded. If a substantially identical color value is found, then the color run is encoded using the “REF_COLOR” mode ( 148 ). This mode encodes the color run also by using the starting pixel of the color run and the length of the color run. In contrast to the previous mode, the color value of the color run is identified by an index of the matching color run in the previous line.
- the encoder next determines if the color run's color value has been used previously during the encoding of the frame ( 150 ). For this determination, the encoder keeps a color table of color values for each color value encountered while encoding the frame. The color table is constructed sequentially so that a decoder can reconstruct the color table simply by decoding the encoded color runs. By this method, each color value need only be encoded using its absolute value once per frame.
- the color run is encoded using the “REF_INDEX” mode ( 152 ). This mode also encodes the color run using the starting pixel of the color run and the length of the color run. In contrast to the previous modes, the color value of the color run is identified by an index of the color table that is constructed by the encoder. Otherwise, if the color run's color value is not found in the color table, the color run is encoded using the “REF_ABS” mode ( 154 ). This mode encodes an absolute representation of the color value at the full color depth used by the frame (i.e. 16, 24, or 32 bit RGB encoding). Alternately, other color representation schemes can be used, such as YUV encoding.
- Transmitting station 12 and receiving station 24 can be implemented in whole or in part by one or more computers, servers, processors or any other suitable computing device or system that can carry out any of the embodiments described herein.
- transmitting station 12 can be implemented using a general purpose computer/processor with a computer program that, when executed, carries out any of the respective methods, algorithms and/or instructions described herein.
- a special purpose computer/processor can be utilized which can contain specialized hardware for carrying out any of the methods, algorithms, or instructions described herein.
- Transmitting station 12 and receiving station 24 can, for example, be implemented on computers in a screen casting system.
- transmitting station 12 can be implemented on a server and receiving station 24 can be implemented on a device separate from the server, such as a hand-held communications device (i.e. a cell phone).
- transmitting station 12 can encode content and transmit an encoded video signal to the communications device.
- the communications device can then decode an encoded video signal.
- the communications device can decode content stored locally on the communications device (i.e. no transmission is necessary).
- Other suitable transmitting station 12 and receiving station 24 implementation schemes are available.
- receiving station 24 can be a personal computer rather than a portable communications device.
- encoding and decoding can be performed in many different ways and can produce a variety of encoded data formats.
- the above-described embodiments of encoding or decoding may illustrate some exemplary encoding techniques. However, in general, encoding and decoding are understood to include any transformation or any other change of data whatsoever.
- transmitting station 12 and/or receiving station 24 can be realized in hardware, software, or any combination thereof including, for example, IP cores, ASICS, programmable logic arrays, quantum or molecular processors, optical processors, programmable logic controllers, microcode, firmware, microcontrollers, servers, microprocessors, digital signal processors or any other suitable circuit.
- processor should be understood as encompassing any the foregoing devices, either singly or in combination.
- signal and “data” are used interchangeably. Further, portions of transmitting station 12 and receiving station 24 do not necessarily have to be implemented in the same manner.
- transmitting station 12 can be implemented using a general purpose computer/processor with a computer program that, when executed, carries out any of the respective methods, algorithms and/or instructions described herein.
- a special purpose computer/processor can be utilized which can contain specialized hardware for carrying out any of the methods, algorithms, or instructions described herein.
- inventions of the present invention can take the form of a computer program product accessible from, for example, a computer-usable or computer-readable medium.
- a computer-usable or computer-readable medium can be any device that can, for example, contain, store, communicate, or transport the program for use by or in connection with any computing system or device.
- the medium can be, for example, an electronic, magnetic, optical, electromagnetic, or a semiconductor device. Other suitable mediums are also available.
Abstract
Description
Claims (18)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US13/095,975 US8705620B1 (en) | 2011-04-28 | 2011-04-28 | Method and apparatus for encoding anchor frame by encoding features using layers |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US13/095,975 US8705620B1 (en) | 2011-04-28 | 2011-04-28 | Method and apparatus for encoding anchor frame by encoding features using layers |
Publications (1)
Publication Number | Publication Date |
---|---|
US8705620B1 true US8705620B1 (en) | 2014-04-22 |
Family
ID=50481884
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US13/095,975 Expired - Fee Related US8705620B1 (en) | 2011-04-28 | 2011-04-28 | Method and apparatus for encoding anchor frame by encoding features using layers |
Country Status (1)
Country | Link |
---|---|
US (1) | US8705620B1 (en) |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9225979B1 (en) | 2013-01-30 | 2015-12-29 | Google Inc. | Remote access encoding |
Citations (71)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4924310A (en) | 1987-06-02 | 1990-05-08 | Siemens Aktiengesellschaft | Method for the determination of motion vector fields from digital image sequences |
US5148269A (en) | 1990-07-20 | 1992-09-15 | U.S. Philips Corporation | Motion vector processing device |
US5337086A (en) | 1991-10-22 | 1994-08-09 | Sony Corporation | Image signal coding and decoding apparatus with multiple-process motion compensation |
EP0634873A2 (en) | 1993-07-15 | 1995-01-18 | NOKIA TECHNOLOGY GmbH | Method to determine the motion vectors in small picture segments of a television picture |
US5398068A (en) | 1993-09-02 | 1995-03-14 | Trustees Of Princeton University | Method and apparatus for determining motion vectors for image sequences |
US5512952A (en) | 1991-09-20 | 1996-04-30 | Sony Corporation | Picture signal encoding and/or decoding apparatus |
US5731840A (en) | 1995-03-10 | 1998-03-24 | Kabushiki Kaisha Toshiba | Video coding/decoding apparatus which transmits different accuracy prediction levels |
US5886742A (en) | 1995-01-12 | 1999-03-23 | Sharp Kabushiki Kaisha | Video coding device and video decoding device with a motion compensated interframe prediction |
US5916449A (en) * | 1995-12-28 | 1999-06-29 | Siemens Aktiengesellschaft | Method and arrangement for monitoring a separating liquid stream |
US5930387A (en) * | 1995-06-05 | 1999-07-27 | Apple Computer, Inc. | Method and apparatus for encoding color image data using dynamic color matching |
US5991447A (en) | 1997-03-07 | 1999-11-23 | General Instrument Corporation | Prediction and coding of bi-directionally predicted video object planes for interlaced digital video |
US6005980A (en) | 1997-03-07 | 1999-12-21 | General Instrument Corporation | Motion estimation and compensation of video object planes for interlaced digital video |
US6005625A (en) * | 1994-08-22 | 1999-12-21 | Nec Corporation | Method and system for processing data on motion pictures by motion compensation combined with image segmentation |
US6021213A (en) * | 1996-06-13 | 2000-02-01 | Eli Lilly And Company | Automatic contextual segmentation for imaging bones for osteoporosis therapies |
US6044166A (en) * | 1995-01-17 | 2000-03-28 | Sarnoff Corporation | Parallel-pipelined image processing system |
US6058211A (en) * | 1995-07-07 | 2000-05-02 | Imec Vzw | Data compression method and apparatus |
US6195391B1 (en) | 1994-05-31 | 2001-02-27 | International Business Machines Corporation | Hybrid video compression/decompression system |
US6272179B1 (en) | 1998-03-05 | 2001-08-07 | Matsushita Electric Industrial Company, Limited | Image coding apparatus, image decoding apparatus, image coding method, image decoding method, and data storage medium |
US6289049B1 (en) | 1997-07-30 | 2001-09-11 | Lg Electronics Inc. | Method for coding motion vector in moving picture |
US20020017565A1 (en) * | 1997-12-17 | 2002-02-14 | Ju Paul P. | Oblique access to image data for reading dataforms |
US20020031272A1 (en) | 1997-11-17 | 2002-03-14 | Daniele Bagni | Motion-compensated predictive image encoding and decoding |
US6359929B1 (en) | 1997-07-04 | 2002-03-19 | Matsushita Electric Industrial Co., Ltd. | Image predictive decoding method, image predictive decoding apparatus, image predictive coding apparatus, and data storage medium |
US6363119B1 (en) | 1998-03-05 | 2002-03-26 | Nec Corporation | Device and method for hierarchically coding/decoding images reversibly and with improved coding efficiency |
US6381277B1 (en) | 1997-12-12 | 2002-04-30 | Hyundai Electronics Ind. Co, Ltd. | Shaped information coding device for interlaced scanning video and method therefor |
US6462791B1 (en) | 1997-06-30 | 2002-10-08 | Intel Corporation | Constrained motion estimation and compensation for packet loss resiliency in standard based codec |
US20030215135A1 (en) * | 1999-08-17 | 2003-11-20 | Koninklijke Philips Electronics N.V. | System and method for performing region-based image retrieval using color-based segmentation |
US20040001634A1 (en) * | 2002-06-28 | 2004-01-01 | Microsoft Corporation | Text detection in continuous tone image segments |
US20040017939A1 (en) * | 2002-07-23 | 2004-01-29 | Microsoft Corporation | Segmentation of digital video and images into continuous tone and palettized regions |
US6735249B1 (en) | 1999-08-11 | 2004-05-11 | Nokia Corporation | Apparatus, and associated method, for forming a compressed motion vector field utilizing predictive motion coding |
US20040196902A1 (en) | 2001-08-30 | 2004-10-07 | Faroudja Yves C. | Multi-layer video compression system with synthetic high frequencies |
US20040252886A1 (en) * | 1999-12-21 | 2004-12-16 | Microsoft Corporation | Automatic video object extraction |
US20050185715A1 (en) | 2001-01-03 | 2005-08-25 | Marta Karczewicz | Video decoder architecture and method for using same |
US20050259729A1 (en) | 2004-05-21 | 2005-11-24 | Shijun Sun | Video coding with quality scalability |
US20050271140A1 (en) | 2000-11-27 | 2005-12-08 | Tsuyoshi Hanamura | Bit stream separating and merging system, apparatus, method and computer program product |
US20060039470A1 (en) | 2004-08-19 | 2006-02-23 | Korea Electronics Technology Institute | Adaptive motion estimation and mode decision apparatus and method for H.264 video codec |
US20060056689A1 (en) * | 2002-11-19 | 2006-03-16 | Koninklijke Philips Electronics N.V. | Image segmentation using template prediction |
US7114129B2 (en) | 2002-03-28 | 2006-09-26 | International Business Machines Corporation | Method and system for controlling an application displayed in an inactive window |
US20070036354A1 (en) * | 2001-05-04 | 2007-02-15 | Wee Susie J | Encoding and decoding methods for secure scalable streaming and related systems |
US20070065026A1 (en) | 2005-09-16 | 2007-03-22 | Industry-Academia Cooperation Group Of Sejong University | Method of and apparatus for lossless video encoding and decoding |
US7197070B1 (en) | 2001-06-04 | 2007-03-27 | Cisco Technology, Inc. | Efficient systems and methods for transmitting compressed video data having different resolutions |
US20070080971A1 (en) * | 2005-10-06 | 2007-04-12 | Sung Chih-Ta S | Method and apparatus of image buffer compression for display device |
US20070121100A1 (en) | 2003-12-10 | 2007-05-31 | Essilor International (Compagne General D'optique) | Device and a method of automatically detecting various characteristics of an ophthalmic lens |
US20070217701A1 (en) * | 2005-08-12 | 2007-09-20 | Che-Bin Liu | Systems and Methods to Convert Images into High-Quality Compressed Documents |
US20070216777A1 (en) * | 2006-03-17 | 2007-09-20 | Shuxue Quan | Systems, methods, and apparatus for exposure control |
US20080069440A1 (en) * | 2006-09-20 | 2008-03-20 | Qualcomm Incorporated | Automatic Color Removal In Digitally Captured Image Technical Field |
US7424056B2 (en) | 2003-07-04 | 2008-09-09 | Sigmatel, Inc. | Method for motion estimation and bandwidth reduction in memory and device for performing the same |
US20080239354A1 (en) * | 2007-03-28 | 2008-10-02 | Usui Daisuke | Image processing method, image processing apparatus, image forming apparatus, and recording medium |
US20080260042A1 (en) | 2007-04-23 | 2008-10-23 | Qualcomm Incorporated | Methods and systems for quality controlled encoding |
US20090122867A1 (en) | 2007-11-09 | 2009-05-14 | Mauchly J William | Coding Background Blocks in Video Coding that Includes Coding as Skipped |
US20090161763A1 (en) | 2007-12-20 | 2009-06-25 | Francois Rossignol | Motion estimation with an adaptive search range |
US20090232401A1 (en) * | 2005-10-12 | 2009-09-17 | Haruo Yamashita | Visual processing apparatus, display apparatus, visual processing method, program, and integrated circuit |
US20090237728A1 (en) | 2008-03-19 | 2009-09-24 | Canon Kabushiki Kaisha | Information processing apparatus and image processing apparatus |
US20090307428A1 (en) | 2008-06-06 | 2009-12-10 | Microsoft Corporation | Increasing remote desktop performance with video caching |
US20100021009A1 (en) * | 2007-01-25 | 2010-01-28 | Wei Yao | Method for moving targets tracking and number counting |
US20100026608A1 (en) | 2008-07-30 | 2010-02-04 | Research In Motion Limited | Remote desktop client peephole movement |
US20100034268A1 (en) | 2007-09-21 | 2010-02-11 | Toshihiko Kusakabe | Image coding device and image decoding device |
US20100104021A1 (en) | 2008-10-27 | 2010-04-29 | Advanced Micro Devices, Inc. | Remote Transmission and Display of Video Data Using Standard H.264-Based Video Codecs |
US20100235583A1 (en) | 2009-03-16 | 2010-09-16 | Gokaraju Ravi Kiran | Adaptive display caching |
US20110002541A1 (en) * | 2007-12-20 | 2011-01-06 | Koninklijke Philips Electronics N.V. | Segmentation of image data |
US20110010629A1 (en) | 2009-07-09 | 2011-01-13 | Ibm Corporation | Selectively distributing updates of changing images to client devices |
US20110026591A1 (en) | 2009-07-29 | 2011-02-03 | Judit Martinez Bauza | System and method of compressing video content |
US20110033125A1 (en) * | 2009-08-06 | 2011-02-10 | Ricoh Company, Limited | Image processing apparatus and method for image processing |
US20110069890A1 (en) * | 2009-09-22 | 2011-03-24 | Canon Kabushiki Kaisha | Fast line linking |
US20110158529A1 (en) * | 2009-12-28 | 2011-06-30 | Xerox Corporation | System and method for cleanup of mrc images for improved compression and image quality |
US20110219331A1 (en) | 2010-03-02 | 2011-09-08 | International Business Machines Corporation | Window resize on remote desktops |
US20110255592A1 (en) * | 2008-10-27 | 2011-10-20 | Lg Electronics Inc. | Virtual view image synthesis method and apparatus |
US20110268359A1 (en) * | 2004-08-16 | 2011-11-03 | Tessera Technologies Ireland Limited | Foreground/Background Segmentation in Digital Images |
US20120020408A1 (en) * | 2010-07-20 | 2012-01-26 | Wen-Hsiung Chen | Video compression using multiple variable length coding methods for multiple types of transform coefficient blocks |
US8111914B2 (en) | 2007-06-11 | 2012-02-07 | Samsung Electronics Co., Ltd. | Method and apparatus for encoding and decoding image by using inter color compensation |
US20120278433A1 (en) * | 2010-05-20 | 2012-11-01 | Zte Corporation | Method for transmitting and receiving multimedia information and terminal |
US20120314942A1 (en) * | 2011-06-10 | 2012-12-13 | Microsoft Corporation | Determining foreground regions and background regions in an image |
-
2011
- 2011-04-28 US US13/095,975 patent/US8705620B1/en not_active Expired - Fee Related
Patent Citations (71)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4924310A (en) | 1987-06-02 | 1990-05-08 | Siemens Aktiengesellschaft | Method for the determination of motion vector fields from digital image sequences |
US5148269A (en) | 1990-07-20 | 1992-09-15 | U.S. Philips Corporation | Motion vector processing device |
US5512952A (en) | 1991-09-20 | 1996-04-30 | Sony Corporation | Picture signal encoding and/or decoding apparatus |
US5337086A (en) | 1991-10-22 | 1994-08-09 | Sony Corporation | Image signal coding and decoding apparatus with multiple-process motion compensation |
EP0634873A2 (en) | 1993-07-15 | 1995-01-18 | NOKIA TECHNOLOGY GmbH | Method to determine the motion vectors in small picture segments of a television picture |
US5398068A (en) | 1993-09-02 | 1995-03-14 | Trustees Of Princeton University | Method and apparatus for determining motion vectors for image sequences |
US6195391B1 (en) | 1994-05-31 | 2001-02-27 | International Business Machines Corporation | Hybrid video compression/decompression system |
US6005625A (en) * | 1994-08-22 | 1999-12-21 | Nec Corporation | Method and system for processing data on motion pictures by motion compensation combined with image segmentation |
US5886742A (en) | 1995-01-12 | 1999-03-23 | Sharp Kabushiki Kaisha | Video coding device and video decoding device with a motion compensated interframe prediction |
US6044166A (en) * | 1995-01-17 | 2000-03-28 | Sarnoff Corporation | Parallel-pipelined image processing system |
US5731840A (en) | 1995-03-10 | 1998-03-24 | Kabushiki Kaisha Toshiba | Video coding/decoding apparatus which transmits different accuracy prediction levels |
US5930387A (en) * | 1995-06-05 | 1999-07-27 | Apple Computer, Inc. | Method and apparatus for encoding color image data using dynamic color matching |
US6058211A (en) * | 1995-07-07 | 2000-05-02 | Imec Vzw | Data compression method and apparatus |
US5916449A (en) * | 1995-12-28 | 1999-06-29 | Siemens Aktiengesellschaft | Method and arrangement for monitoring a separating liquid stream |
US6021213A (en) * | 1996-06-13 | 2000-02-01 | Eli Lilly And Company | Automatic contextual segmentation for imaging bones for osteoporosis therapies |
US5991447A (en) | 1997-03-07 | 1999-11-23 | General Instrument Corporation | Prediction and coding of bi-directionally predicted video object planes for interlaced digital video |
US6005980A (en) | 1997-03-07 | 1999-12-21 | General Instrument Corporation | Motion estimation and compensation of video object planes for interlaced digital video |
US6462791B1 (en) | 1997-06-30 | 2002-10-08 | Intel Corporation | Constrained motion estimation and compensation for packet loss resiliency in standard based codec |
US6359929B1 (en) | 1997-07-04 | 2002-03-19 | Matsushita Electric Industrial Co., Ltd. | Image predictive decoding method, image predictive decoding apparatus, image predictive coding apparatus, and data storage medium |
US6289049B1 (en) | 1997-07-30 | 2001-09-11 | Lg Electronics Inc. | Method for coding motion vector in moving picture |
US20020031272A1 (en) | 1997-11-17 | 2002-03-14 | Daniele Bagni | Motion-compensated predictive image encoding and decoding |
US6381277B1 (en) | 1997-12-12 | 2002-04-30 | Hyundai Electronics Ind. Co, Ltd. | Shaped information coding device for interlaced scanning video and method therefor |
US20020017565A1 (en) * | 1997-12-17 | 2002-02-14 | Ju Paul P. | Oblique access to image data for reading dataforms |
US6363119B1 (en) | 1998-03-05 | 2002-03-26 | Nec Corporation | Device and method for hierarchically coding/decoding images reversibly and with improved coding efficiency |
US6272179B1 (en) | 1998-03-05 | 2001-08-07 | Matsushita Electric Industrial Company, Limited | Image coding apparatus, image decoding apparatus, image coding method, image decoding method, and data storage medium |
US6735249B1 (en) | 1999-08-11 | 2004-05-11 | Nokia Corporation | Apparatus, and associated method, for forming a compressed motion vector field utilizing predictive motion coding |
US20030215135A1 (en) * | 1999-08-17 | 2003-11-20 | Koninklijke Philips Electronics N.V. | System and method for performing region-based image retrieval using color-based segmentation |
US20040252886A1 (en) * | 1999-12-21 | 2004-12-16 | Microsoft Corporation | Automatic video object extraction |
US20050271140A1 (en) | 2000-11-27 | 2005-12-08 | Tsuyoshi Hanamura | Bit stream separating and merging system, apparatus, method and computer program product |
US20050185715A1 (en) | 2001-01-03 | 2005-08-25 | Marta Karczewicz | Video decoder architecture and method for using same |
US20070036354A1 (en) * | 2001-05-04 | 2007-02-15 | Wee Susie J | Encoding and decoding methods for secure scalable streaming and related systems |
US7197070B1 (en) | 2001-06-04 | 2007-03-27 | Cisco Technology, Inc. | Efficient systems and methods for transmitting compressed video data having different resolutions |
US20040196902A1 (en) | 2001-08-30 | 2004-10-07 | Faroudja Yves C. | Multi-layer video compression system with synthetic high frequencies |
US7114129B2 (en) | 2002-03-28 | 2006-09-26 | International Business Machines Corporation | Method and system for controlling an application displayed in an inactive window |
US20040001634A1 (en) * | 2002-06-28 | 2004-01-01 | Microsoft Corporation | Text detection in continuous tone image segments |
US20040017939A1 (en) * | 2002-07-23 | 2004-01-29 | Microsoft Corporation | Segmentation of digital video and images into continuous tone and palettized regions |
US20060056689A1 (en) * | 2002-11-19 | 2006-03-16 | Koninklijke Philips Electronics N.V. | Image segmentation using template prediction |
US7424056B2 (en) | 2003-07-04 | 2008-09-09 | Sigmatel, Inc. | Method for motion estimation and bandwidth reduction in memory and device for performing the same |
US20070121100A1 (en) | 2003-12-10 | 2007-05-31 | Essilor International (Compagne General D'optique) | Device and a method of automatically detecting various characteristics of an ophthalmic lens |
US20050259729A1 (en) | 2004-05-21 | 2005-11-24 | Shijun Sun | Video coding with quality scalability |
US20110268359A1 (en) * | 2004-08-16 | 2011-11-03 | Tessera Technologies Ireland Limited | Foreground/Background Segmentation in Digital Images |
US20060039470A1 (en) | 2004-08-19 | 2006-02-23 | Korea Electronics Technology Institute | Adaptive motion estimation and mode decision apparatus and method for H.264 video codec |
US20070217701A1 (en) * | 2005-08-12 | 2007-09-20 | Che-Bin Liu | Systems and Methods to Convert Images into High-Quality Compressed Documents |
US20070065026A1 (en) | 2005-09-16 | 2007-03-22 | Industry-Academia Cooperation Group Of Sejong University | Method of and apparatus for lossless video encoding and decoding |
US20070080971A1 (en) * | 2005-10-06 | 2007-04-12 | Sung Chih-Ta S | Method and apparatus of image buffer compression for display device |
US20090232401A1 (en) * | 2005-10-12 | 2009-09-17 | Haruo Yamashita | Visual processing apparatus, display apparatus, visual processing method, program, and integrated circuit |
US20070216777A1 (en) * | 2006-03-17 | 2007-09-20 | Shuxue Quan | Systems, methods, and apparatus for exposure control |
US20080069440A1 (en) * | 2006-09-20 | 2008-03-20 | Qualcomm Incorporated | Automatic Color Removal In Digitally Captured Image Technical Field |
US20100021009A1 (en) * | 2007-01-25 | 2010-01-28 | Wei Yao | Method for moving targets tracking and number counting |
US20080239354A1 (en) * | 2007-03-28 | 2008-10-02 | Usui Daisuke | Image processing method, image processing apparatus, image forming apparatus, and recording medium |
US20080260042A1 (en) | 2007-04-23 | 2008-10-23 | Qualcomm Incorporated | Methods and systems for quality controlled encoding |
US8111914B2 (en) | 2007-06-11 | 2012-02-07 | Samsung Electronics Co., Ltd. | Method and apparatus for encoding and decoding image by using inter color compensation |
US20100034268A1 (en) | 2007-09-21 | 2010-02-11 | Toshihiko Kusakabe | Image coding device and image decoding device |
US20090122867A1 (en) | 2007-11-09 | 2009-05-14 | Mauchly J William | Coding Background Blocks in Video Coding that Includes Coding as Skipped |
US20110002541A1 (en) * | 2007-12-20 | 2011-01-06 | Koninklijke Philips Electronics N.V. | Segmentation of image data |
US20090161763A1 (en) | 2007-12-20 | 2009-06-25 | Francois Rossignol | Motion estimation with an adaptive search range |
US20090237728A1 (en) | 2008-03-19 | 2009-09-24 | Canon Kabushiki Kaisha | Information processing apparatus and image processing apparatus |
US20090307428A1 (en) | 2008-06-06 | 2009-12-10 | Microsoft Corporation | Increasing remote desktop performance with video caching |
US20100026608A1 (en) | 2008-07-30 | 2010-02-04 | Research In Motion Limited | Remote desktop client peephole movement |
US20100104021A1 (en) | 2008-10-27 | 2010-04-29 | Advanced Micro Devices, Inc. | Remote Transmission and Display of Video Data Using Standard H.264-Based Video Codecs |
US20110255592A1 (en) * | 2008-10-27 | 2011-10-20 | Lg Electronics Inc. | Virtual view image synthesis method and apparatus |
US20100235583A1 (en) | 2009-03-16 | 2010-09-16 | Gokaraju Ravi Kiran | Adaptive display caching |
US20110010629A1 (en) | 2009-07-09 | 2011-01-13 | Ibm Corporation | Selectively distributing updates of changing images to client devices |
US20110026591A1 (en) | 2009-07-29 | 2011-02-03 | Judit Martinez Bauza | System and method of compressing video content |
US20110033125A1 (en) * | 2009-08-06 | 2011-02-10 | Ricoh Company, Limited | Image processing apparatus and method for image processing |
US20110069890A1 (en) * | 2009-09-22 | 2011-03-24 | Canon Kabushiki Kaisha | Fast line linking |
US20110158529A1 (en) * | 2009-12-28 | 2011-06-30 | Xerox Corporation | System and method for cleanup of mrc images for improved compression and image quality |
US20110219331A1 (en) | 2010-03-02 | 2011-09-08 | International Business Machines Corporation | Window resize on remote desktops |
US20120278433A1 (en) * | 2010-05-20 | 2012-11-01 | Zte Corporation | Method for transmitting and receiving multimedia information and terminal |
US20120020408A1 (en) * | 2010-07-20 | 2012-01-26 | Wen-Hsiung Chen | Video compression using multiple variable length coding methods for multiple types of transform coefficient blocks |
US20120314942A1 (en) * | 2011-06-10 | 2012-12-13 | Microsoft Corporation | Determining foreground regions and background regions in an image |
Non-Patent Citations (45)
Title |
---|
"Implementors' Guide; Series H: Audiovisual and Multimedia Systems; Coding of moving video: Implementors Guide for H.264: Advanced video coding for generic audiovisual services". H.264. International Telecommunication Union. Version 12. Dated Jul. 30, 2010. |
"Overview; VP7 Data Format and Decoder". Version 1.5. On2 Technologies, Inc. Dated Mar. 28, 2005. |
"Series H: Audiovisual and Multimedia Systems; Infractructure of audiovisual services-Coding of moving video". H.264. Advanced video coding for generic audiovisual services. Version 8. International Telecommunication Union. Dated Nov. 1, 2007. |
"Series H: Audiovisual and Multimedia Systems; Infrastructure fo audiovisual services-Coding of moving video; Advanced video coding for generic audiovisual services". H.264. Amendment 1: Support of additional colour spaces and removal of the High 4:4:4 Profile. International Telecommunication Union. Dated Jun. 2006. |
"Series H: Audiovisual and Multimedia Systems; Infrastructure of audiovisual services-Coding of moving video". H.264. Advanced video coding for generic audiovisual services. International Telecommunication Union Version 11. Dated Mar. 2009. |
"Series H: Audiovisual and Multimedia Systems; Infrastructure of audiovisual services-Coding of moving video". H.264. Advanced video coding for generic audiovisual services. International Telecommunication Union. Version 12. Dated Mar. 2010. |
"Series H: Audiovisual and Multimedia Systems; Infrastructure of audiovisual services-Coding of moving video; Advanced video coding for generic audiovisual services". H.264. Version 1. International Telecommunication Union. Dated May 2003. |
"Series H: Audiovisual and Multimedia Systems; Infrastructure of audiovisual services-Coding of moving video; Advances Video coding generic audiovisual services". H.264. Version 3. International Telecommunication Union. Dated Mar. 2005. |
"Series H: Audiovisual and Multimedia Systems; Infrastructure of audiovisual servies-Coding of moving video". H.264. Amendment 2: New profiles for professional applications. International Telecommunicaiton Union. Dated Apr. 2007. |
"VP6 Bitsream & Decoder Specification". Version 1.02 On2 Technologies, Inc. Dated Aug. 17, 2006. |
"VP6 Bitstream & Decoder Specification". Version 1.03. On2 Technologies, Inc. Dated Oct. 29, 2007. |
"VP8 Data Format and Decoding Guide". WebM Project. Google On2. Dated: Dec. 1, 2010. |
Bankoski et al. "Technical Overview of VP8, An Open Source Video Codec for the Web". Dated Jul. 11, 2011. |
Bankoski et al. "VP8 Data Format and Decoding Guide; draft-bankoski-vp8-bitstream-02" Network Working Group. Dated May 18, 2011. |
Bankoski, J., Koleszar, J., Quillio, L., Salonen, J., Wilkins, P., and Y. Xu, "VP8 Data Format and Decoding Guide", RFC 6386, Nov. 2011. |
Chen, Michael C., et al.; "Design and Optimization of a Differentially Coded Variable Block Size Motion Compensation System", IEEE 1996, 4 pp. |
Chen, Xing C., et al.; "Quadtree Based Adaptive Lossy Coding of Motion Vectors", IEEE 1996, 4 pp. |
Ebrahimi, Touradj, et al.; "Joint motion estimation and segmentation for very low bitrate video coding", SPIE vol. 2501, 1995, 12 pp. |
Guillotel, Philippe, et al.; "Comparison of motion vector coding techniques", SPIE vol. 2308, 1994, 11 pp. |
Jun-Ren Ding et al.; "Two-Layer and adaptive entropy coding algorithms for H. 264-based lossless image coding", Acoustics, Speech and Signal Processing, 2008. ICASSP 2008. IEE International conference on IEEE, Piscatawa, NJ, USA Mar. 31, 2008. |
Karczewicz, Marta, et al.; "Video Coding Using Motion Compensation With Polynomial Motion Vector Fields", IEEE COMSOC EURASIP, First International Workshop on Wireless Image/Video Communications-Sep. 1996, 6 pp. |
Kim, Jong Won, et al.; "On the Hierarchical Variable Block Size Motion Estimation Technique for Motion Sequence Coding", SPIE Visual Communication and Image Processing 1993, Cambridge, MA, Nov. 8, 1993, 29 pp. |
Liu, Bede, et al.; "A simple method to segment motion field for video coding", SPIE vol. 1818, Visual Communications and Image Processing 1992, 10 pp. |
Liu, Bede, et al.; "New Fast Algorithms for the Estimation of Block Motion Vectors", IEEE Transactions on Circuits and Systems for Video Technology, vol. 3, No. 2, Apr. 1993, 10 pp. |
Luttrell, Max, et al.; "Simulation Results for Modified Error Resilient Syntax With Data Partitioning and RVLC", ITU-Telecommunications Standardization Sector, Study Group 16, Video Coding Experts Group (Question 15), Sixth Meeting: Seoul, South Korea, Nov. 2, 1998, 34 pp. |
Martin, Graham R., et al.; "Reduced Entropy Motion Compensation Using Variable Sized Blocks", SPIE vol. 3024, 1997, 10 pp. |
Mozilla, "Introduction to Video Coding Part 1: Transform Coding", Video Compression Overview, Mar. 2012, 171 pp. |
Nicolas, H., et al.; "Region-based motion estimation using deterministic relaxation schemes for image sequence coding", IEEE 1992, 4 pp. |
Nokia, Inc., Nokia Research Center, "MVC Decoder Description", Telecommunication Standardization Sector, Study Period 1997-2000, Geneva, Feb. 7, 2000, 99 pp. |
Office Action Mailed Jun. 5, 2013 in co-pending U.S. Appl. No. 13/095,971, filed Apr. 28, 2011. |
Office Action mailed May 30, 2013 in co-pending U.S. Appl. No. 13/089,383, filed Apr. 19, 2011. |
Orchard, Michael T.; "Exploiting Scene Structure in Video Coding", IEEE 1991, 5 pp. |
Orchard, Michael T.; "Predictive Motion-Field Segmentation for Image Sequence Coding", IEEE Transactions on Circuits and Systems for Video Technology, vol. 3, No. 1, Feb. 1993, 17 pp. |
Patent Cooperation Treaty Invitation to Pay Fees in related matter, International Searching Authority International Application No. PCT/US2013/063722 mailed on Dec. 9, 2013. |
Schiller, H., et al.; "Efficient Coding of Side Information in a Low Bitrate Hybrid Image Coder", Signal Processing 19 (1990) Elsevier Science Publishers B.V. 61-73, 13 pp. |
Schuster, Guido M., et al.; "A Video Compression Scheme With Optimal Bit Allocation Among Segmentation, Motion, and Residual Error", IEEE Transactions on Image Processing, vol. 6, No. 11, Nov. 1997, 16 pp. |
Schwarz H. et al.: "SNR-scalable extension of H.264/AVC" , Image Processing, 2004. ICIP 2004 International Conference on Singapore Oct. 24-27, 2004. |
Series H: Audiovisual and Multimedia Systems, "Infrastructure of audiovisual services-Coding of moving video, Video coding for low bit rate communication", International Telecommunication Union, ITU-T Recommendation H.263, Feb. 1998, 167 pp. |
Steliaros, Michael K., et al.; "Locally-accurate motion estimation for object-based video coding", SPIE vol. 3309, 1997, 11 pp. |
Stiller, Christoph; "Motion-Estimation for Coding of Moving Video at 8 kbit/s with Gibbs Modeled Vectorfield Smoothing", SPIE vol. 1360 Visual Communications and Image Processing 1990, 9 pp. |
Strobach, Peter; "Tree-Structured Scene Adaptive Coder", IEEE Transactions on Communications, vol. 38, No. 4, Apr. 1990, 10 pp. |
Wiegand, Thomas, et al.; "Long-Term Memory Motion-Compensated Prediction", Publication Unknown, Date Unknown, 15 pp. |
Wiegand, Thomas, et al.; "Rate-Distortion Optimized Mode Selection for Very Low Bit Rate Video Coding and the Emerging H.263 Standard", IEEE Transactions on Circuits and Systems for Video Technology, vol. 6, No. 2, Apr. 1996, 9 pp. |
Wright, R. Glenn, et al.; "Multimedia-Electronic Technical Manual for ATE", IEEE 1996, 3 pp. |
Zhang, Kui, et al.; "Variable Block Size Video Coding With Motion Prediction and Motion Segmentation", SPIE vol. 2419, 1995, 9 pp. |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9225979B1 (en) | 2013-01-30 | 2015-12-29 | Google Inc. | Remote access encoding |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US8780996B2 (en) | System and method for encoding and decoding video data | |
US10142652B2 (en) | Entropy coding motion vector residuals obtained using reference motion vectors | |
US9210420B1 (en) | Method and apparatus for encoding video by changing frame resolution | |
US8520734B1 (en) | Method and system for remotely communicating a computer rendered image sequence | |
US9094681B1 (en) | Adaptive segmentation | |
US9369706B1 (en) | Method and apparatus for encoding video using granular downsampling of frame resolution | |
US9460527B2 (en) | Pattern mode for frame buffer compression | |
US9866862B2 (en) | Motion vector reference selection through reference frame buffer tracking | |
US10757408B2 (en) | Restoration in video coding using domain transform recursive filters | |
US10506256B2 (en) | Intra-prediction edge filtering | |
US10681374B2 (en) | Diversified motion using multiple global motion models | |
US8780987B1 (en) | Method and apparatus for encoding video by determining block resolution | |
US11748854B2 (en) | Noise reduction method for high dynamic range videos | |
WO2019037471A1 (en) | Video processing method, video processing device and terminal | |
US9819957B2 (en) | Method and apparatus for decoding a progressive JPEG image | |
US9749638B1 (en) | Method and apparatus for encoding video with dynamic quality improvement | |
US8705620B1 (en) | Method and apparatus for encoding anchor frame by encoding features using layers | |
US8804819B1 (en) | Method and apparatus for encoding video using data frequency | |
US20130084003A1 (en) | Psychovisual Image Compression | |
US20200036989A1 (en) | Enhancing a chroma-subsampled video stream | |
US20210241426A1 (en) | Method for Denoising Omnidirectional Videos and Rectified Videos | |
US11445211B1 (en) | Psychovisually optimized dithering for image and video encoding | |
US10841549B2 (en) | Methods and apparatus to facilitate enhancing the quality of video | |
US9215458B1 (en) | Apparatus and method for encoding at non-uniform intervals | |
US11736730B2 (en) | Systems, methods, and apparatuses for video processing |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:JIA, WEI;REEL/FRAME:026194/0367Effective date: 20110425 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044277/0001Effective date: 20170929 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 4TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1551)Year of fee payment: 4 |
|
FEPP | Fee payment procedure |
Free format text: MAINTENANCE FEE REMINDER MAILED (ORIGINAL EVENT CODE: REM.); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
LAPS | Lapse for failure to pay maintenance fees |
Free format text: PATENT EXPIRED FOR FAILURE TO PAY MAINTENANCE FEES (ORIGINAL EVENT CODE: EXP.); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
STCH | Information on status: patent discontinuation |
Free format text: PATENT EXPIRED DUE TO NONPAYMENT OF MAINTENANCE FEES UNDER 37 CFR 1.362 |
|
FP | Lapsed due to failure to pay maintenance fee |
Effective date: 20220422 |