CN113260990A - Mobile-enabled voice search for media items displayed on alternative playback devices - Google Patents
Mobile-enabled voice search for media items displayed on alternative playback devices Download PDFInfo
- Publication number
- CN113260990A CN113260990A CN201980087634.6A CN201980087634A CN113260990A CN 113260990 A CN113260990 A CN 113260990A CN 201980087634 A CN201980087634 A CN 201980087634A CN 113260990 A CN113260990 A CN 113260990A
- Authority
- CN
- China
- Prior art keywords
- search
- user
- mobile device
- audio input
- playback device
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/16—Sound input; Sound output
- G06F3/167—Audio in a user interface, e.g. using voice commands for navigating, audio feedback
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/40—Information retrieval; Database structures therefor; File system structures therefor of multimedia data, e.g. slideshows comprising image and additional audio data
- G06F16/43—Querying
- G06F16/438—Presentation of query results
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/40—Information retrieval; Database structures therefor; File system structures therefor of multimedia data, e.g. slideshows comprising image and additional audio data
- G06F16/48—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/95—Retrieval from the web
- G06F16/953—Querying, e.g. by the use of web search engines
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0481—Interaction techniques based on graphical user interfaces [GUI] based on specific properties of the displayed interaction object or a metaphor-based environment, e.g. interaction with desktop elements like windows or icons, or assisted by a cursor's changing behaviour or appearance
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/22—Procedures used during a speech recognition process, e.g. man-machine dialogue
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/26—Speech to text systems
Abstract
A method includes detecting a session between a mobile device and an alternate playback device. The method further comprises the following steps: in response to detecting that the session has been established, presenting a Graphical User Interface (GUI) on a screen of a mobile device of a user, the GUI including a voice search GUI element representing a voice search; receiving a user selection of a voice search GUI element; receiving an audio input from a user requesting a search for one or more media items, the audio input specifying one or more search criteria for the search; and submitting a text search query derived from the audio input for processing, wherein results of the search are to be presented to the user on a screen of the alternate playback device.
Description
Technical Field
Aspects and implementations of the present disclosure relate to voice searching, and more particularly, to mobile-enabled voice searching for media items displayed on alternative playback devices.
Background
Various platforms may provide media content items that are shared by users (e.g., videos uploaded by users, live videos) and/or provided by various entities (e.g., movies and/or television shows produced by production studios). The media content items may include pre-recorded or live content presented to the user on a large screen client device via a user interface of the platform. A user may access the user interface and use the virtual keyboard to fill in a search query for a desired media content item to be consumed, particularly when a voice-enabled remote control may not be available. Entering characters with a conventional virtual keyboard using some electronic devices can be tedious and requires pressing inefficient numbers of key entries to fill in the desired characters.
Disclosure of Invention
The subject matter of the present disclosure relates to enabling voice searching of media items to be displayed on alternative playback devices on mobile devices using applications hosted on the mobile devices ("mobile applications"). Examples of alternative playback devices include Television (TV) systems (e.g., TV sets or smart TVs), personal computers, tablet computers, and the like. First, a session between the mobile device and an alternate playback device may be detected. In one implementation, the session may be a casting session. When a session is established, a Graphical User Interface (GUI) may be presented to the user on the screen of the mobile device. The GUI may include a voice search GUI element to enable the user to perform a voice search. Upon user selection of the voice search GUI element, the user may be prompted (e.g., via an on-screen search widget) to provide audio input requesting a search for one or more media items, the audio input specifying one or more search criteria for the search. When an audio input is received, a text search query derived from the audio input can be submitted to an alternative playback device to initiate a search and further present search results to the user on an alternative playback device screen. In other implementations, the text search query can be submitted by the mobile device to a server (e.g., search server, media server), and the search results can be displayed on an alternate playback device. The server or mobile device may transmit the search results to the alternate playback device. When the search results are received and displayed on the alternative playback device screen, the user will be further presented with a navigation GUI on the mobile device, with buttons representing "up," "down," "left," "right," and "select" to navigate the search results and further select search result items to be played on the alternative playback device screen.
An improved user interface is provided by enabling voice searching of media items using a microphone of a mobile device. For example, the user no longer needs to click on numerous keys on the virtual keyboard to form a search query. Eliminating the need to enter search queries may also reduce the processing resources (on all remote controls, alternative playback devices, and back-end servers) and network bandwidth resources incurred during the search. This is achieved because an error-free voice search query may result in fewer key presses and fewer media content item suggestion data payloads being transmitted. Furthermore, because the search query is submitted to the alternate playback device only when the user speaks the complete search term, processing resources are conserved because the server will no longer receive incomplete search terms, as is the case in conventional solutions that type in one character of the search query at a time. In addition, because the search query is submitted to the backend server by the alternative playback device, the search results presented to the user are optimized to include all relevant media items that are suitable for playing on the screen of the alternative playback device. Alternatively, in some implementations, the mobile device may submit the search query directly to the backend server and the search results may be displayed on the screen of the alternative playback device.
According to an aspect of the present disclosure, there is provided a method comprising: detecting a session between the mobile device and the alternate playback device; presenting a Graphical User Interface (GUI) on a screen of a mobile device of a user in response to detecting that a session has been established, the GUI including a voice search GUI element representing a voice search; receiving a user selection of a voice search GUI element; receiving an audio input from a user requesting a search for one or more media items, the audio input specifying one or more search criteria for the search; and submitting a text search query derived from the audio input for processing, wherein results of the search are to be presented to the user on a screen of the alternate playback device.
The method may further comprise: where the results of the search are not presented to the user on the screen of the mobile device.
Detecting a session between the mobile device and the alternate playback device may further include: a user request to initiate a session between a mobile device and an alternate playback device is received via the GUI.
The method may further comprise: wherein submitting the text search query for processing further comprises: the text search query is submitted for processing to at least one of an alternate playback device or a back-end server.
The method may further comprise: wherein one or more media items are selected from a plurality of media items hosted by a content sharing platform based on a text search query.
The GUI on the screen of the mobile device may be provided by a first application associated with the content sharing platform.
The results of the search may be presented on a screen of the alternate playback device via a GUI provided by a second application associated with the content sharing platform.
The alternative playback device may be a television system.
The method may further comprise: displaying a navigation GUI element on a screen of the mobile device to navigate results of the search on a screen of the alternative playback device in response to submitting a text search query to the alternative playback device.
The method may further include displaying a voice search widget on the GUI to prompt the user to provide audio input; and activating an audio input receiving feature of the mobile device to receive audio input from the user.
Initiating an audio input receiving feature of the mobile device may include: user permission to activate an audio input receiving feature of the mobile device is obtained.
The session between the mobile device and the alternate playback device may be a casting session, a mirroring session, a screen sharing session, and the like.
The method may further comprise: in response to failing to receive an audio input by the user requesting a search: deactivating an audio input reception feature of the mobile device; displaying a small suggestion on the GUI to prompt the user to make a selection of a voice search GUI element; and in response to receiving a selection of the voice search GUI element, activating an audio input receiving feature of the mobile device to receive audio input from the user.
The text search query can be received by the alternate playback device, and the text search query submitted to the content sharing platform by the alternate playback device.
The content sharing platform may select results of the search query based on a device type of the alternate playback device, and the content sharing platform transmits the results of the search query to the alternate playback device for display. For example, the content sharing platform may determine a device type of the alternate playback device. The content sharing platform may do this in any suitable manner. For example, the content sharing platform may determine the device type based on information contained in a user account associated with the alternate playback device. Alternatively, data may be transmitted from the alternative playback device to the content sharing platform that identifies the device type. Determining the device type allows the content sharing platform to provide only results that are optimized and/or can only be processed by that device type.
According to another aspect of the present disclosure, there is provided a system comprising one or more devices configured to implement the method described above. The system may include a client device and an alternate playback device. The system may also include a content sharing platform. The client device may be a mobile device, such as a smartphone. The alternative playback device may be a TV. The content sharing platform may include a server.
According to another aspect of the present disclosure, there is provided a non-transitory computer-readable medium for storing instructions that, when executed by one or more processing devices, cause the one or more processing devices to implement the above-described method.
According to another aspect of the present disclosure, there is provided a non-transitory computer-readable medium for storing instructions that, when executed by one or more processing devices, cause the one or more processing devices to receive an indication of a user request from an alternate playback device to perform a voice search on a mobile device, the one or more processing devices also presenting a voice search GUI element on a GUI presented on a screen of the mobile device, the voice search GUI element representing a voice search; prompting a user to provide audio input in response to receiving confirmation to perform the voice search; receiving an audio input from a user requesting a search for one or more media items, the audio input specifying one or more search criteria for the search; and submitting a textual search query derived from the audio input to the alternative playback device to initiate a search, wherein the search results are to be presented to the user on a screen of the alternative playback device.
To prompt the user to provide audio input, the one or more processing devices may also display a voice search widget on the GUI to prompt the user to provide audio input; and enabling the mobile device to receive audio input from the user in response to the initiation of the voice search GUI element.
To present the voice search GUI element on the screen of the mobile device, the one or more processing devices may also initiate a session between the mobile device and the alternate playback device.
The session between the mobile device and the alternate playback device may be a casting session.
The results of the search may not be presented to the user on the screen of the mobile device.
One or more media items may be selected from a plurality of media items hosted by a content sharing platform based on a text search query.
The GUI on the mobile device screen may be provided by a first application associated with the content sharing platform, and the results of the search presented on the screen of the alternate playback device via a GUI provided by a second application associated with the content sharing platform.
The alternative playback device may be a television system.
The one or more processing devices may also: in response to submitting a text search query to the alternative playback device, a navigation GUI element is displayed on a screen of the mobile device to navigate results of the search on the screen of the alternative playback device.
Optional features of each aspect may be combined with other aspects, where appropriate.
Drawings
Aspects and implementations of the present disclosure will be understood more fully from the detailed description given below and from the accompanying drawings of various aspects and implementations of the disclosure, which, however, should not be taken to limit the disclosure to the specific aspects or implementations, but are for explanation and understanding only.
FIG. 1 illustrates an example system architecture for mobile-enabled voice search of media content items according to one implementation of this disclosure.
FIG. 2 depicts a flow diagram of aspects of a method for performing a voice search on a media content item according to one implementation of the present disclosure.
FIG. 3 depicts a flow diagram of aspects of a method for performing a voice search on a media content item upon failure to attempt to receive an audio input according to one implementation of the present disclosure.
FIG. 4 depicts a flow diagram of aspects of a method for performing a voice search for a media content item initiated from a GUI element on a TV screen according to one implementation of the present disclosure.
Fig. 5 illustrates an example system including a mobile device initiating a casting session with an alternate playback device in accordance with some embodiments of the present disclosure.
Fig. 6 is an example system including a mobile device having a first GUI to record audio input from a user and to send a derived textual search query to an alternative playback device in accordance with some embodiments of the present disclosure.
Fig. 7 is an example system including a mobile device having a first GUI to navigate media items in search results displayed on a second GUI on a screen of an alternative playback device in accordance with some embodiments of the present disclosure.
Fig. 8 illustrates an example block diagram of a computing device operating in accordance with one or more implementations of the present disclosure.
Detailed Description
Embodiments of the present disclosure address technical problems in that unnecessary processing resources and poor user experience may occur when typing characters on a search user interface on a playback device such as a TV system when searching for media content items to be displayed on the TV. For example, when a user views media items on a TV using a remote control that does not support voice searching, the user may need to enter a search query to find a particular media item to consume. Typing a search query typically involves numerous key presses to navigate a virtual keyboard displayed on a TV screen and select characters using directional keys. Multiple key presses may undesirably consume processing resources on the remote control (if used) and the TV (which displays a virtual keyboard). In addition, this is particularly problematic because potentially tens of keys must be clicked to form a search query in order to find out an undesirable user experience for a certain media item that the user is interested in playing.
Further, each time a user fills in a character using the virtual keyboard, the character is transmitted from the TV to the server to find a media content item based on the filled in character. The server may transmit information related to the located media content item including the filled-in character in its title as a suggestion to the TV that is displaying the search user interface. The information related to the located media content items may include, for example, thumbnails, full video files of the media content items, metadata (e.g., titles and descriptions of the media content items), and so forth. Sending multiple data payloads with the above information may consume processing resources at the server for performing a lookup operation, consume processing resources at the TV by displaying a list of suggested media content items, consume network bandwidth resources by sending multiple data payloads when filling in characters, and so on, as the user fills in a search query.
Another technical problem addressed by embodiments of the present disclosure is that filling in a search query in a conventional manner by moving a cursor across multiple rows and columns of a virtual keyboard to find desired characters may be error prone for the user, resulting in an impaired user experience. The user must track the cursor around the virtual keyboard and stop it on the desired character to select that character. If the title includes a large number of characters, the greater the number of key presses required to fill in the title, the greater the chance of misselecting the wrong character, thus requiring the user to delete the wrong character and refill the correct character. This lengthy and error-prone process of searching for media items to be played on a TV is an undesirable and inconvenient experience for TV-watching users who wish to be able to quickly and efficiently find the media items they are looking for.
Another technical problem addressed by embodiments of the present disclosure relates to performing a search for media items using a mobile device (instead of a remote control and a virtual keyboard on a TV screen) and displaying search results on the mobile device for a user to select to play on the TV. Having to navigate through potentially many of the media items in the search results on a small screen of the mobile device, rather than utilizing a large TV screen to navigate and select the media items to be consumed, may not provide a desirable experience for the user. The ideal user experience is achieved when the user who needs to consume media items on the TV interacts with the mobile device as little as possible. More importantly, when the mobile device submits a search query to the backend server to render search results, the backend server may customize the search results to include media items suitable for consumption on the mobile device, and thus may miss media items suitable for consumption on a TV on which the user intends to consume the media items that they are seeking.
Technical solutions to one or more of the above-identified technical problems may include performing a voice search for media items hosted by a content sharing platform using a microphone of a mobile device while providing search results that include media items suitable for consumption on a TV, and displaying the search results on the TV. First, a user may request initiation of a casting session between the mobile device and the TV via a Graphical User Interface (GUI) presented on a screen of the mobile device. Alternatively, in some implementations, a casting session may already be established between the mobile device and the TV. A casting session refers to a communication mechanism that provides for sharing media items for display between devices, where one device sends a media item to another device via a wireless connection. When a casting session is initiated, a voice search GUI element can be presented to a user to enable the user to perform a voice search. Upon selection of the voice search GUI element by the user, the user may be prompted (e.g., via an on-screen search widget) to provide an audio input requesting a search for one or more media items, where the audio input may specify one or more search criteria for the search. When audio input is received, a text search query derived from the audio input can be submitted to the TV to initiate a search and further the search results presented to the user on the TV screen. Alternatively, in some implementations, the search query may be submitted by the mobile device directly to a server (e.g., search server, media server), and the results of the search may be received and displayed on a TV screen. When the search results are displayed on the TV, the user is further presented with a navigation GUI on the mobile device, where the buttons represent "up", "down", "left", "right", and "select" to navigate the search results and further select search result items to be played on the TV. In this way, improved control of the user interface is provided.
By enabling voice searching of media items using the microphone of the mobile device, the user no longer needs to click on numerous keys on the virtual keyboard to form a search query. Furthermore, because the search query is submitted to the TV only when the user speaks the complete search term, processing resources are conserved because the server will no longer receive incomplete search terms, as is the case in conventional solutions where one character of the search query is typed in at a time. In addition, because the search query is submitted by the TV to the backend server, the search results presented to the user are optimized to include all relevant media items suitable for playing on the TV screen.
Accordingly, technical effects may include improving user experience by eliminating the need to perform numerous key presses to fill in a search query to find a media content item by replacing the entered search query with a voice search. For example, a user may provide one or two key presses to initiate a casting session between a TV and a mobile device and initiate a voice search feature on the mobile device. Once the user provides audio input via the microphone of the mobile device, a text search query derived from the audio input is submitted to the TV without the user providing any further key presses. Eliminating the need to enter search queries may also reduce the processing resources (on all remote controls, TVs, and backend servers) and network bandwidth resources incurred during the search. This can be done because fewer key presses and fewer media content item suggestion data payloads are sent if the desired media content item is found based on an error-free voice search query.
FIG. 1 illustrates an example system architecture 100 for providing voice search capabilities for efficient use during a media content item search according to one implementation of this disclosure. System architecture 100 includes one or more client devices (e.g., mobile device 110 and alternate playback device 170), one or more networks 105, one or more data stores 106, and one or more platforms (e.g., content sharing platform 120, advertising platform 165, mobile platform 150, social network platform 160, search platform 145, and content provider platform 195). A platform may be one or more computing devices (such as a rack-mounted server, router computer, server computer, personal computer, mainframe computer, laptop computer, tablet computer, desktop computer, etc.), data stores (e.g., hard disks, memory, and databases), networks, software components, and/or hardware components.
The one or more networks 105 may include one or more public networks (e.g., the internet), one or more private networks (e.g., a Local Area Network (LAN) or one or more Wide Area Networks (WANs)), one or more wired networks (e.g., ethernet), one or more wireless networks (e.g., an 802.11 network or a Wi-Fi network), one or more cellular networks (e.g., a Long Term Evolution (LTE) network), routers, hubs, switches, server computers, and/or combinations thereof. In one implementation, some of the components of the architecture 100 are not directly connected to each other. In one implementation, the architecture 100 includes a separate network 105.
The one or more data stores 106 may be a memory (e.g., random access memory), a cache, a drive (e.g., a hard drive), a flash drive, a database system, or another type of component or device capable of storing data. One or more data stores 106 may include multiple storage components (e.g., multiple drives or multiple databases) that may also span multiple computing devices (e.g., multiple server computers). The data store 106 may be a persistent store capable of storing data. The persistent storage may be a local storage unit or a remote storage unit. The persistent storage may be a magnetic storage unit, an optical storage unit, a solid state storage unit, an electronic storage unit (main memory) or similar storage unit. The persistent storage may be a monolithic device or a collection of distributed devices. As used herein, "set" refers to any positive integer term.
Content items 121 (media content items) may be stored in one or more data stores 106. The data store 106 may be part of one or more platforms. Examples of content items 121 may include, but are not limited to, digital videos, digital movies, animated images, digital photographs, digital music, digital audio, website content, social media updates, electronic books (ebooks), electronic magazines, digital newspapers, digital audio books, electronic journals, web blogs, Really Simple Syndication (RSS) feeds, electronic comics, software applications, and so forth. Content item 121 is also referred to as a media item. The content item 121 may be pre-recorded or live. For brevity, media items are used as examples of content items 121 throughout this document.
The content item 121 may be provided by a content provider. The content provider may be a user, a company, an organization, etc. The content provider may provide content items 121 belonging to a video advertisement. The content provider that provides the video advertisement is hereinafter referred to as an advertiser. For example, content item 121 may be a video advertisement for a car provided by a car advertiser. For example, when a service provider provides an advertisement on a client device 110 and 170 to be viewed by a user, the service provider may charge a fee to the advertiser.
The mobile device 110 may include devices such as smart phones, cellular phones, Personal Digital Assistants (PDAs), tablet computers, portable media players, and the like.
Mobile device 110 may include a communication application 112. The content item 121 may be consumed via the communication application 112, the internet, or the like. As used herein, "media," "media item," "online media item," "digital media item," "content," "media content item," and "content item" may include electronic files that may be executed or loaded using software, firmware, or hardware configured to present the content item. In one implementation, the communication application 112 may be an application that allows a user to compose, send, and receive content items 121 (e.g., videos) via platforms (e.g., the content sharing platform 120, the advertising platform 165, the mobile platform 150, the social network platform 160, the search platform 145, and the content provider platform 195) and/or combinations of platforms and/or networks.
For example, the communication application 112 may be a social networking application, a video sharing application, a video streaming application, a video on demand application, a photo sharing application, a chat application, a mobile application of a content provider, or any combination of such applications. The communication application 112 in the mobile device may render, display, and/or present one or more content items 121 (e.g., videos) to one or more users. For example, the communication application 112 may provide one or more user interfaces (e.g., graphical user interfaces) to be rendered in a display of the client device for sending, receiving, and/or playing videos. The communication application 112 in the mobile device may also receive audio input via an audio receiving device (e.g., a microphone).
In one implementation, the communication application 112 may include a voice search component 117 and a content viewer 116 and may provide a user interface 114 that may be used to enable a voice search by receiving audio input representing one or more search criteria requesting a search of one or more content items 121. Audio input is received via a voice search GUI element presented in the content viewer 116 portion of the user interface 114. In one implementation, the content viewer 116 is embedded in an application (e.g., the communication application 112). In another implementation, the content viewer 116 may be a standalone application (e.g., a mobile application), such as the communication application 112, that allows a user to consume (e.g., play, display) a content item 121, such as a video, an image, a document (e.g., a web page), and so forth. For example, the content viewer 116 may be a web browser capable of accessing, retrieving, rendering, and/or navigating content (e.g., web pages such as hypertext markup language (HTML) pages, digital media items, etc.) served by a web server of the platform. In another example, the content viewer 116 may display an embedded media player (e.g.,
The content viewer 116 may be provided to the mobile device 110 by a server and/or platform. For example, the content viewer 116 may be an embedded media player embedded in a user interface 114 (e.g., a document (web page) or a screen of a stand-alone application) provided by the content sharing platform 120 or the content provider platform 195. In another example, the content viewer 116 may be an application downloaded from a platform (e.g., the content sharing platform 120, the advertising platform 165, the mobile platform 150, the social network platform 160, the search platform 145, and the content provider platform 195). In another example, content viewer 116 may be a stand-alone application that is pre-installed on mobile device 110.
The voice search section 117 can provide voice search capability by: an audio input representing one or more search criteria requesting a search of one or more media items is received, and a textual search query derived from the audio input is submitted to the alternative playback device 170 to initiate the search. The voice search component 117 can be implemented in computer instructions that are stored on one or more memory devices and executed by one or more processing devices. The voice search component 117 can receive a user request to initiate a casting session between the mobile device 110 and the alternate playback device 170 via the user interface 114. When initiating a casting session, the user interface 114 may present a GUI that includes a voice search GUI element (e.g., an icon for a microphone) representing a voice search. The user may select a voice search GUI element to begin a voice search by providing an audio input (e.g., via a microphone of the mobile device 110) to the user interface 114 of the communication application 112. The audio input may represent one or more search criteria that request a search of one or more content items 121 hosted by the content sharing platform 120. A text search query derived from the audio input may be submitted to the alternate playback device 170 to initiate a search.
In another implementation, the communication application 112 may include a D-pad component 118 that represents a virtual directional pad that includes keys corresponding to up, down, left, right, and fill (select) to navigate media items in search results displayed on the alternative playback device 170. When the user presses one or more of the virtual keys on the directional pad, D pad component 118 may receive a key input selection. The D-pad component 118 can transmit key inputs to the alternate playback device 170 for processing by one or more processors running the voice search component 177.
The alternate playback device 170 may include a communication application 172. The content item 121 may be consumed via the communication application 172, the internet, or the like. As used herein, "media," "media item," "online media item," "digital media item," "content," "media content item," and "content item" may include electronic files that may be executed or loaded using software, firmware, or hardware configured to present the content item. In one implementation, the communication application 172 may be an application that allows a user to compose, send, and receive content items 121 (e.g., videos) via platforms (e.g., the content sharing platform 120, the advertising platform 165, the mobile platform 150, the social network platform 160, the search platform 145, and the content provider platform 195) and/or combinations of platforms and/or networks.
For example, the communication application 172 may be a social networking application, a video sharing application, a video streaming application, a video on demand application, a photo sharing application, a chat application, a mobile application of a content provider, or any combination of such applications. The communication application 172 in the alternative playback device 170 may render, display, and/or present one or more content items 121 (e.g., videos) to one or more users. For example, the communication application 172 may provide one or more user interfaces (e.g., graphical user interfaces) to be rendered in a display of the alternative playback device for sending, receiving, and/or playing videos.
In one implementation, the communication application 172 may include a voice search component 177 and a content viewer 176 and may provide a user interface 174 that may be used to display results of a media item search, including one or more content items 121, in the content viewer 176 portion. The user interface 174 may also be used to display voice search GUI elements for transmission on the mobile device 110A voice search of the media content item 121 is initiated. Content viewer 176 may render, display, and/or present content item 121 (e.g., a video) to one or more users. In one implementation, the content viewer 176 is embedded in an application (e.g., the communication application 172). In another implementation, the content viewer 176 may be a standalone application (e.g., a desktop application, a television application, etc.), such as the communication application 172, that allows a user to consume (e.g., play, display) a content item 121, such as a video, an image, a document (e.g., a web page), etc. For example, the content viewer 176 may be a web browser capable of accessing, retrieving, rendering, and/or navigating content (e.g., web pages such as hypertext markup language (HTML) pages, digital media items, etc.) served by a web server of the platform. In another example, the content viewer 176 may display an embedded media player (e.g.,
The content viewer 176 may be provided by a server and/or platform to the alternate playback device 170. For example, the content viewer 176 may be an embedded media player embedded in a user interface 174 (e.g., a document (web page) or a screen of a stand-alone application) provided by the content sharing platform 120 or the content provider platform 195. In another example, the content viewer 176 may be an application downloaded from a platform (e.g., the content sharing platform 120, the advertising platform 165, the mobile platform 150, the social network platform 160, the search platform 145, and the content provider platform 195). In another example, the content viewer 176 may be a stand-alone application that is pre-installed on the alternate playback device 170.
The voice search component 177 can provide voice search GUI elements to initiate a voice search of media content items on the mobile device 110 and then display the search results for the media items in the content viewer 176 portion of the user interface 174. In some implementations, the voice search component 177 can provide voice search capabilities to allow media items to be searched quickly and efficiently without having to type search queries using a virtual keyboard displayed on the screen of the alternate playback device 170. The voice search component 177 can be implemented in computer instructions stored on one or more memory devices and executed by one or more processing devices. The voice search component 177 can receive a user request to initiate a voice search of a media item using the communication application 112 on the mobile device 110 via a voice search GUI element presented on the user interface 174.
The voice search component 177 can receive a text search query derived from audio input from the mobile device 110 that specifies one or more search criteria that request a search of one or more content items 121 hosted by the content sharing platform 120. The voice search component 177 can then submit a text search query to the content sharing platform 120 to perform a search and send the search results to the alternative playback device 170 for display to the user. In some implementations, the content sharing platform 120 can select the media items to be included in the search results based on the device type of the client device requesting the search results, in which case the alternative playback device 170 is requesting the search results. For example, media items that are more suitable for playing on a mobile device (e.g., hyperlinks to web pages) may not be included in search results sent to a television. Similarly, media items that are more suitable for playing on a television (e.g., live programming on a television network) may not be included in the search results sent to the mobile device.
The search results may be presented to the user in the content viewer 176 of the alternate playback device 170 rather than on the screen of the mobile device 110. The user may navigate the search results displayed on the alternate playback device 170 via the D-pad component 118 of the mobile device 110. The user may also select one of the media items in the search results to be played in the content viewer 176 of the alternate playback device 170.
The content provider platform 195 may provide a service and the content provider may be a service provider. For example, the content provider may be a video streaming service provider that provides media streaming services via the communication application 172 for users to play videos, TV shows, video clips, audio clips, and movies on the alternative playback device 170 via the content provider platform 195.
Social-networking platform 160 may provide online social-networking services. The social network platform 160 may provide the communication application 112 for users to create profiles and perform activities with their profiles. The activities may include: updating the profile; exchanging messages with other users; publish status updates, photos, videos, etc. to share with other users; evaluating (e.g., praise, comment, share, recommend) status updates, photos, videos, etc.; and receiving notifications of other user activities.
The search platform 145 may be one or more computing devices (such as a rack-mounted server, a router computer, a server computer, a personal computer, a mainframe computer, a laptop computer, a tablet computer, a desktop computer, etc.), data stores (e.g., hard disks, memory, databases), networks, software components, and/or hardware components operable to allow a user to query the one or more data stores 106 and/or one or more platforms, and receive query results.
The advertising platform 165 may be one or more computing devices (such as a rack server, router computer, server computer, personal computer, mainframe computer, laptop computer, tablet computer, desktop computer, etc.), data stores (e.g., hard disk, memory, database), networks, software components, and/or hardware components that may be used to provide video advertisements.
FIG. 2 depicts a flow diagram of aspects of a method 200 for performing a voice search on a media content item according to one implementation of the present disclosure. The method 200 is performed by a processing device that may comprise hardware (circuitry, dedicated logic, etc.), software (such as is run on a general purpose computer system or a dedicated machine), or a combination of both. In one implementation, method 200 is performed by voice search component 117 in mobile device 110 of FIG. 1. In one implementation, the processing device of the mobile device performs the method 200.
At block 210, the processing device may detect the presence of a session between the mobile device and the alternate playback device, such that the mobile device may communicate with the alternate playback device by sending media items to be played on a screen of the alternate playback device via the session. In one implementation, detecting the session may involve receiving a user request to initiate a session between the mobile device and the alternate playback device. In some implementations, the alternative playback device may be a Television (TV) system or other client device with a large screen, as compared to a mobile device with a small screen. In some implementations, a user request to initiate a session can be received via a Graphical User Interface (GUI) on a screen of the mobile device. The GUI on the screen of the mobile device may be provided by a first application associated with a content sharing platform (e.g., content sharing platform 120 of fig. 1). Further, in one implementation, the session between the mobile device and the alternate playback device may be a casting session. A casting session may provide for display media items shared between devices, where one device sends media items to another device via a wireless connection. In one implementation, a mobile device may initiate a casting session with an alternate playback device to send a text search query to the alternate playback device such that a search for media items in accordance with the search query may be initiated by the alternate playback device.
At block 220, in response to detecting that a casting session has been initiated between the mobile device and the TV, the processing device may present a GUI that includes a voice search GUI element (e.g., a button with a microphone image) representing a voice search. Upon successful initiation of the casting session, a notification can be displayed on a screen of the mobile device indicating that the casting session was initiated and that the media item can be cast (e.g., for display, play, or otherwise consumption) to the TV (e.g., "ready to be cast to TV"). Similarly, a notification can be displayed on the TV screen indicating that a casting session has been initiated with the mobile device (e.g., "successfully linked to the mobile device"). In one implementation, the processing device may display a voice search widget on a GUI of the mobile device to prompt the user to provide audio input. For example, the search suggestion may be "search on TV with voice".
At block 230, the processing device may receive a user selection of a voice search GUI element. When the user selects a voice search GUI element, for example by clicking on the voice search GUI element, the processing device may initiate an audio input receiving feature of the mobile device to receive audio input from the user. For example, the audio input receiving feature may be a microphone of the mobile device. In addition, the processing device may obtain user permission to activate an audio input receiving feature of the mobile device. For example, the user may be prompted to give permission to the processing device to access the microphone of the mobile device and have the option of allowing or denying access. If the user selects to allow access to the microphone, the processing device may activate the microphone of the mobile device and may record audio input from the user specifying the search query. On the other hand, if the user chooses to deny access to the microphone, the voice search function may be aborted. In one implementation, the user may be prompted to give permission for microphone access the first time a voice search capability is launched on the mobile device.
After the microphone is activated, the microphone may listen for audio input from the user. The user may be prompted to speak the search term to find the media item they want to consume. For example, a search suggestion might be presented on the screen of the mobile device stating "try to say 'please play some music'".
At block 250, the processing device may receive an audio input from a user requesting a search for a media item that the user wants to consume. The audio input may specify search criteria for searching on the media items. In some implementations, the media items may be selected from a plurality of media items hosted by a content sharing platform (e.g., content sharing platform 120 of fig. 1), and the selection may be based on search criteria provided by the user.
At block 260, the processing device may obtain a text search query derived from the audio input (e.g., via the search platform 145 of fig. 1). Processing logic may then submit the text search query to process the text search query. In some implementations, processing logic may submit a text search query to an alternate playback device via a casting session. An alternative playback device may receive a text search query and may initiate a search by submitting the text search query to a content sharing platform to perform a search. The content sharing platform may perform a search and may create search results by selecting media items that match the text search query and including the selected media items in the search results. In one implementation, the content sharing platform may select the media item based on a device type of the alternate playback device. For example, media items that are more suitable for playing on a mobile device (e.g., hyperlinks to web pages) may not be included in search results sent to a television. The content sharing platform may then transmit the search results to the alternate playback device for presentation to the user on the screen of the alternate playback device. In one example, the search results may be presented on a screen of the alternative playback device via a GUI provided by an application (e.g., a television application) associated with the content sharing platform. In some implementations, the search results may not be transmitted to the mobile device for display.
The processing device may display a navigation GUI element on the screen of the mobile device to navigate media items within the search results displayed on the screen of the alternate playback device and select the media items for display on the screen of the alternate playback device. In some implementations, the navigation GUI elements may represent a virtual directional pad that includes keys corresponding to up, down, left, right, and fill-in (selection). The navigation GUI element may receive a key input selection when the user presses one or more of the virtual keys on the directional pad. The processing device may then transmit the key input to the alternate playback device for processing.
FIG. 3 depicts a flow diagram of aspects of a method 300 for performing a voice search on a media content item upon failure to attempt to receive an audio input according to one implementation of the present disclosure. The method 300 is performed by a processing device that may comprise hardware (circuitry, dedicated logic, etc.), software (such as is run on a general purpose computer system or a dedicated machine), or a combination of both. In one implementation, method 230 is performed by voice search component 117 in mobile device 110 of FIG. 1. In one implementation, the processing device of the mobile device performs the method 300.
At block 310, the processing device may receive a user selection of a voice search GUI element on a screen of the mobile device, e.g., via a user click on the voice search GUI element. At block 315, the processing device may activate a microphone of the mobile device to receive audio input from the user, as explained in more detail above. The user may be prompted to speak the search term to find the media item the user is looking for.
At block 320, the processing device may wait a predetermined period of time to receive audio input from the user. In one example, the latency may be set to twenty seconds. The active microphone may receive a spoken phrase from the user representing an audio input specifying the search criteria, and may submit the audio input to the processing device for processing. If audio input is received during the wait period, the processing device may obtain a text search query derived from the audio input (e.g., via the search platform 145 of FIG. 1). Processing logic may then submit the text search query to an alternate playback device via the casting session to initiate a search at block 360.
On the other hand, if no audio input is received within the wait period, the processing device may deactivate the microphone of the mobile device at block 330. The microphone may not be able to receive audio input from the user for a number of reasons, including, for example, the user not speaking anything during the waiting period, or a high level of noise preventing the microphone from capturing audio input from the user. After deactivating the microphone, at block 345, the processing device may notify the user that no audio input was received and may also prompt the user to again attempt to provide audio input. For example, a message may be presented on the screen of the mobile device stating "not heard. Tap the microphone to retry ".
At block 350, the processing device may prompt the user to again attempt to provide audio input, which may require the user to again activate the microphone by selecting a voice search GUI element. If the user activates the microphone but then forgets or is distracted, providing no search criteria for the media item, it may be desirable to keep the microphone active for only a short period of time before automatically deactivating the microphone to eliminate accidental recording of speech from the user. As such, if the user clicks on the voice search GUI element but forgets to provide audio input, the microphone may only remain active for a brief moment and will then be deactivated, thus preventing the microphone from capturing the user speech after that point. If the user wishes to try again to perform a voice search, they may choose to activate the microphone again.
FIG. 4 depicts a flow diagram of aspects of a method 400 for performing a voice search for a media content item initiated from a GUI element on a TV screen according to one implementation of the present disclosure. The method 400 is performed by a processing device that may comprise hardware (circuitry, dedicated logic, etc.), software (such as is run on a general purpose computer system or a dedicated machine), or a combination of both. In one implementation, method 400 is performed by voice search component 117 in mobile device 110 of FIG. 1. In one implementation, a processing device of a mobile device performs the method 400.
At block 410, a processing device of a mobile device may receive an indication of a user request from a TV to perform a voice search on the mobile device. In some implementations, a voice search GUI element can be presented to a user on a media search page of a TV application. The media search page may also display a virtual keyboard to enable a user to provide search terms for the media item by typing the search terms using the virtual keyboard. In one implementation, the user may be presented with search suggestions on a TV screen indicating that the user may use a voice search from their mobile device rather than typing in search terms using a virtual keyboard. For example, a search suggestion might state "attempt a voice search. Open mobile application on your mobile device to search using microphone ". The user may select a voice search GUI element presented on the TV screen (e.g., by clicking on the voice search GUI element). In some implementations, a processing device of a TV application may broadcast a user request to initiate a voice search for media items on a mobile device. When a user launches a mobile application on a mobile device, the mobile application may receive a broadcast message indicating the user's request to initiate a voice search on the mobile device.
At block 420, the mobile application may present a voice search GUI element on a screen of the mobile device upon receiving an indication of a user request to initiate a voice search. In this case, the mobile application may also implicitly initiate a casting session between the TV and the mobile device, for example when the mobile application launches on the mobile device. The mobile application may then prompt the user to confirm the request to perform the voice search using the mobile device. For example, a mobile application might present a message on a mobile screen stating "search faster on TV with voice" and having an option to turn off or enable the voice search function. The user can confirm the voice search request by clicking the permission button.
At block 430, in response to receiving confirmation from the user to perform the voice search, the processing device may prompt the user to provide audio input (e.g., via a search widget indicating voice search functionality). In some implementations, the user may need to enable a microphone of the mobile device (e.g., by clicking on a voice search GUI element) to enable the mobile device to receive audio input from the user. The user may then speak the search phrase, which may be recorded by the microphone as audio input, and the processing device may receive the audio input recorded by the microphone.
At block 450, in response to receiving audio input from a user representing search criteria for one or more media items, the processing device may obtain a text search query derived from the audio input. The processing device may then submit a text search query to the TV via the casting session, as explained in more detail above. The search results may be presented to the user on a TV screen instead of on the mobile device screen.
Fig. 5 illustrates an example system 500 including a mobile device 602 initiating a casting session with an alternate playback device 610, the mobile device having a first GUI 605, according to some embodiments of the disclosure. Mobile device 602 may be mobile device 110 described in conjunction with fig. 1. The alternate playback device 610 may be the alternate playback device 170 described in conjunction with fig. 1. In some embodiments, the first UI 605 is presented on the mobile device 602 and the second UI611 is presented on the alternate playback device 610. The mobile device 602 and the alternate playback device 610 may communicate via the network 105 as described in connection with fig. 1.
The mobile device 602 may include a display for presenting a UI 605 including content 604, as described herein. Content 604 may be any content (e.g., search results, social media, web pages) that includes media items. The mobile device 602 can also present a voice search button 624 in the UI 605 and the first portion of the content 604. The voice search button 624 may be an interface tool that receives input from a user (e.g., by clicking on the voice search button 624) to initiate a voice search using the mobile device. Content 604 may also include search micro-suggestions 606 that indicate to the user that voice search capabilities may be performed via a voice search button. The content 604 may also include a notification message 607 that indicates to the user that the mobile device is ready to be projected to the TV when a projection session has been initiated via the projection session button 625.
A user of the mobile device 602 may initiate a casting session with the alternate playback device 610 via the casting session button 625. For example, the mobile device 602 may receive a casting session initiation request from a user in the form of a gesture. The user may touch the display area of the mobile device 602 represented by the area of the project session button 625. Upon receiving a request to initiate a casting session, the mobile device 602 may send a casting session request to the alternate playback device 610 via the network 105. In some implementations, after a successful initiation of a casting session between the mobile device 602 and the alternate playback device 610, the mobile device can display a notification message 607 that the mobile device 602 is ready to cast to the alternate playback device 610 (e.g., a TV). Further, the alternate playback device 610 may display a notification message 620 indicating to the user that the alternate playback device 610 has successfully linked to the mobile device 602. When the casting session has been successfully initiated, a voice search function may be performed on the mobile device, as explained in more detail above.
Fig. 6 is an example system 600 including a mobile device 602 having a first GUI 605 to record audio input from a user and to send a derived text search query to an alternative playback device 610 according to some embodiments of the disclosure. After the user selects a voice search GUI element (e.g., by clicking on voice search button 624 of fig. 5), content 604 may be modified to display voice search icon 626 indicating that the microphone of mobile device 602 is active and may be recording audio input from the user. The user may speak a phrase that represents search criteria for one or more media items. In some implementations, when a user speaks a search phrase, mobile device 602 can display a textual search query derived from the spoken search phrase in notification message 607. For example, the user may say "please see me the latest romance movie", which may be displayed in the notification message 607 of the mobile device 602 after a short processing time to receive the phrase from the microphone of the mobile device 602.
The mobile device 602 may then submit a text search query to the alternate playback device 610 via the casting session over the network 105, as explained in more detail above. In some implementations, to enable a user to match search results to search criteria, a text search query may also be displayed in the notification message portion 660 of the second GUI611 of the alternate playback device 610. For example, the notification message 660 may be "please see me the latest romance movie," representing a text search query received from the mobile device 602.
Fig. 7 is an example system 700 that includes a mobile device 602 with a first GUI 605 to navigate media items in search results displayed on a second GUI611 on a screen of an alternative playback device 610, according to some embodiments. The alternative playback device 610 may receive a text search query from the mobile device 602 via the casting session and may initiate a search by submitting the text search query to the content sharing platform to perform the search. The content sharing platform may perform the search and may then transmit the search results 720 to the alternate playback device 610 for presentation to the user on the second GUI 611. In one example, the search results may be presented on a second GUI611 of an application (e.g., a television application) associated with the content sharing platform. Search results 720 may be comprised of media items 721A-721N that include media items that match the search criteria specified by the user in the text search query. Media item 721 in this context may represent any media item that may be played on an application hosted by an alternative playback device (e.g., a television application). Examples of media items 721 may include, but are not limited to, digital videos, digital movies, animated images, digital photos, digital music, digital audio, etc., and the user may select one of the media items 721A-721N to be played on the second GUI611 of the alternative playback device 610.
While the second GUI611 on the alternate playback device 610 is displaying the search results 720, the first GUI 605 on the mobile device 602 may display a navigation GUI element 706 to navigate the media items 721A-721N within the search results 720 displayed on the second GUI 611. In some implementations, the navigation GUI element 706 may represent a virtual directional pad that includes keys corresponding to up, down, left, and right (e.g., as represented by up, down, left, and right arrows of the navigation GUI element 706). When the user presses one or more of the virtual keys on the directional pad, the navigation GUI element 706 may receive a key input selection. The mobile device 602 may then transmit the key input to the alternate playback device 610 for processing. When the user clicks an arrow of navigation GUI 706, the focus on one of media items 721A-721N of search result 720 may be moved in the direction of the clicked arrow such that one of media items 721A-721N may be selected at a given time. The navigation GUI element 706 may also include a selection button (e.g., a center circle button of the navigation GUI element 706) to select the media item 721A-721N that currently has focus. When the user clicks the select button, the media item that is currently in focus may be played in the second GUI611 of the alternate playback device 610. The first GUI 605 of the mobile device 602 may then be changed to display the voice search element 624 and the original content area 604 depicted in fig. 5.
Fig. 8 illustrates an example block diagram of a computing device operating in accordance with one or more implementations of the present disclosure. Computer system 800 may be server 106 or client devices 110 and 170 in fig. 1. The machine may operate in the capacity of a server or an endpoint machine in an endpoint server network environment or as a peer machine in a peer-to-peer (or distributed) network environment. The machine may be a television, a Personal Computer (PC), a tablet PC, a set-top box (STB), a Personal Digital Assistant (PDA), a cellular telephone, a web appliance, a server, a network router, switch or bridge, or any machine capable of executing a set of instructions (sequential or otherwise) that specify actions to be taken by that machine. Further, while only a single machine is illustrated, the term "machine" shall also be taken to include any collection of machines that individually or jointly execute a set (or multiple sets) of instructions to perform any one or more of the methodologies discussed herein.
Processor (processing device) 802 represents one or more general-purpose processing devices such as a microprocessor, central processing unit, or the like. More particularly, the processor 802 may be a Complex Instruction Set Computing (CISC) microprocessor, Reduced Instruction Set Computing (RISC) microprocessor, Very Long Instruction Word (VLIW) microprocessor, or a processor implementing other instruction sets or processors implementing a combination of instruction sets. Processor 802 may also be one or more special-purpose processing devices such as an Application Specific Integrated Circuit (ASIC), a Field Programmable Gate Array (FPGA), a Digital Signal Processor (DSP), network processor, or the like. The processor 802 is configured to execute the instructions 805 (e.g., of the communication application 112) to perform the operations discussed herein.
The computer system 800 may also include a network interface device 808. Computer system 800 may also include a video display unit 810 (e.g., a Liquid Crystal Display (LCD) or a Cathode Ray Tube (CRT)), an input device 812 (e.g., a keyboard and alphanumeric keyboard, a motion sensing input device, a touch screen), a cursor control device 814 (e.g., a mouse), and a signal generation device 820 (e.g., a speaker).
The data storage device 818 may include a non-transitory machine-readable storage medium 824 (also a computer-readable storage medium) on which is stored one or more sets of instructions 805 (e.g., of the communication application 112) embodying any one or more of the methodologies or functions described herein. The instructions may also reside, completely or at least partially, within the main memory 804 and/or within the processor 802 during execution thereof by the computer system 800, the main memory 804 and the processor 802 also constituting machine-readable storage media. The instructions may also be transmitted or received over a network 830 via the network interface device 808.
In one implementation, instructions 805 include instructions for voice search component 176 (e.g., voice search component 117 in FIG. 1) and/or a software library containing methods that invoke voice search component 117. In some implementations, the instructions 805 include instructions for the voice search component 117, the user interface 114, the content viewer 116, and/or the communication application 112. While the computer-readable storage medium 824 (machine-readable storage medium) is shown in an exemplary implementation to be a single medium, the terms "computer-readable storage medium" and "machine-readable storage medium" should be taken to include a single medium or multiple media (e.g., a centralized or distributed database, and/or associated caches and servers) that store the one or more sets of instructions. The terms "computer-readable storage medium" and "machine-readable storage medium" shall also be taken to include any medium that is capable of storing, encoding or carrying a set of instructions for execution by the machine and that cause the machine to perform any one or more of the methodologies of the present disclosure. The terms "computer-readable storage medium" and "machine-readable storage medium" shall accordingly be taken to include, but not be limited to, solid-state memories, optical media, and magnetic media.
Reference throughout this specification to "one implementation" or "an implementation" means that a particular feature, structure, or characteristic described in connection with the implementation is included in at least one implementation. Thus, the appearance of the phrases "in one implementation" or "in an implementation" in various places throughout this specification can, but do not necessarily, refer to the same implementation, depending on the particular situation. Furthermore, the particular features, structures, or characteristics may be combined in any suitable manner in one or more implementations.
To the extent that the terms "includes," "has," "includes," variants thereof, and other similar words are used in either the detailed description or the claims, these terms are intended to be inclusive in a manner similar to the term "comprising" as an open transition word without precluding any additional or other elements.
As used in this application, the terms "component," "module," "system," and the like are generally intended to refer to a computer-related entity, either hardware (e.g., circuitry), software, a combination of hardware and software, or an entity associated with an operating machine having one or more specific functionalities. For example, a component may be, but is not limited to being, a process running on a processor (e.g., a digital signal processor), a processor, an object, an executable, a thread of execution, a program, and/or a computer. For example, both an application running on a controller and the controller may be one component. One or more components can reside within a process and/or thread of execution and a component may be localized on one computer and/or distributed between two or more computers. Further, "device" may take the form of specially designed hardware; general purpose hardware specialized for enabling the hardware to perform specific functions (e.g., generating points of interest and/or descriptors) by executing software thereon; software on a computer readable medium; or a combination thereof.
The aforementioned systems, circuits, modules, and the like have been described with regard to interaction between several components and/or blocks. It will be appreciated that such systems, circuits, components, blocks, etc. may include these components or specified sub-components, some of which and/or additional components, and in accordance with various permutations and combinations of the foregoing. Sub-components may also be implemented as components communicatively coupled to other components rather than included within parent components (hierarchical). Additionally, it should be noted that one or more components may be combined into a single component to provide aggregate functionality, or divided into several separate sub-components, and any one or more middle layers (such as a management layer) may be provided to communicatively couple to such sub-components to provide integral functionality. Any components described herein may also interact with one or more other components not specifically described herein but known to those of skill in the art.
Moreover, the word "example" or "exemplary" is used herein to mean serving as an example, instance, or illustration. Any aspect or design described herein as "exemplary" is not necessarily to be construed as preferred or advantageous over other aspects or designs. Rather, use of the word "example" or "exemplary" is intended to present concepts in a concrete fashion. As used in this application, the term "or" is intended to mean an inclusive "or" rather than an exclusive "or". That is, unless specified otherwise, or clear from context, "X employs A or B" is intended to mean any of the natural inclusive permutations. That is, if X employs A; x is B; or X employs both A and B, then "X employs A or B" is satisfied under any of the foregoing instances. In addition, the articles "a" and "an" as used in this application and the appended claims should generally be construed to mean "one or more" unless specified otherwise or clear from context to be directed to a singular form.
Finally, implementations described herein include data collection that describes a user and/or user activity. In one implementation, such data is collected only if the user agrees to collect the data. In some implementations, the user is prompted to explicitly allow data collection. Further, the user may decide to join or decide not to participate in such data collection activities. In one implementation, the collected data is anonymized before performing any analysis to obtain any statistical patterns, such that the identity of the user cannot be determined from the collected data.
Claims (20)
1. A method, comprising:
detecting a session between the mobile device and the alternate playback device;
presenting a Graphical User Interface (GUI) on a screen of a mobile device of a user in response to detecting that the session has been established, the GUI including a voice search GUI element representing a voice search;
receiving a user selection of the voice search GUI element;
receiving audio input from the user requesting a search for one or more media items, the audio input specifying one or more search criteria for the search; and
submitting a text search query derived from the audio input for processing, wherein results of the search are to be presented to the user on a screen of the alternative playback device.
2. The method of claim 1, wherein results of the search are not presented to the user on a screen of the mobile device.
3. The method of claim 1 or 2, wherein detecting the session between the mobile device and the alternate playback device further comprises:
receiving, via the GUI, a user request to initiate a session between the mobile device and the alternate playback device.
4. The method of claim 1, wherein submitting the textual search query for processing further comprises:
submitting the text search query to at least one of the alternate playback device or a backend server for processing.
5. The method of any preceding claim, wherein the results of the search are presented on a screen of the alternative playback device.
6. The method of any preceding claim, wherein the alternative playback device is a television system.
7. The method of any preceding claim, further comprising:
in response to submitting the text search query, displaying a navigation GUI element on a screen of the mobile device to navigate results of the search on a screen of the alternative playback device.
8. The method of any preceding claim, further comprising:
displaying a voice search small suggestion on the GUI to prompt the user to provide the audio input; and
activating an audio input receiving feature of the mobile device to receive audio input from the user.
9. The method of any preceding claim, wherein the session between the mobile device and the alternative playback device is a casting session.
10. The method of any preceding claim, further comprising:
in response to failing to receive audio input by the user requesting the search:
deactivating an audio input receiving feature of the mobile device;
displaying a small suggestion on the GUI to prompt the user to make a selection of the voice search GUI element; and
in response to receiving a selection of the voice search GUI element, an audio input receiving feature of the mobile device is activated to receive audio input from the user.
11. The method of any preceding claim, wherein the results of the search query are selected by a content sharing platform based on a device type of the alternate playback device, and wherein the results of the search query are transmitted by the content sharing platform to the alternate playback device for display.
12. A system comprising one or more devices configured to perform the method of any preceding claim.
13. A non-transitory computer-readable medium for storing instructions that, when executed by one or more processing devices, cause the one or more processing devices to perform the method of any one of claims 1-11.
14. A non-transitory computer-readable medium for storing instructions that, when executed by one or more processing devices, cause the one or more processing devices to:
receiving an indication of a user request from an alternate playback device to perform a voice search on the mobile device;
presenting a voice search GUI element on a GUI presented on a screen of the mobile device, the voice search GUI element representing the voice search;
prompting the user to provide audio input in response to receiving confirmation to perform the voice search;
receiving audio input from the user requesting a search for one or more media items, the audio input specifying one or more search criteria for the search; and
submitting a text search query derived from the audio input for processing, wherein results of the search are to be presented to the user on a screen of the alternative playback device.
15. The computer-readable medium of claim 14, wherein to prompt the user to provide audio input, the one or more processing devices are further to:
displaying a voice search small suggestion on the GUI to prompt the user to provide the audio input; and is
Enabling the mobile device to receive audio input from the user in response to the initiation of the voice search GUI element.
16. The computer-readable medium of claim 14 or 15, wherein to present a voice search GUI element on the screen of the mobile device, the one or more processing devices are further to:
initiating a session between the mobile device and the alternate playback device.
17. The computer-readable medium of claims 14-16, wherein the session between the mobile device and the alternate playback device is a casting session.
18. The computer-readable medium of claims 14-17, wherein results of the search are not presented to the user on a screen of the mobile device.
19. The computer-readable medium of claims 14-18, wherein the alternative playback device is a television system.
20. The computer-readable medium of claims 14-19, wherein the one or more processing devices are further to:
in response to submitting the text search query, displaying a navigation GUI element on a screen of the mobile device to navigate results of the search on a screen of the alternative playback device.
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
PCT/US2019/040201 WO2021002846A1 (en) | 2019-07-01 | 2019-07-01 | Mobile-enabled voice search of media items for displaying on alternative playback devices |
Publications (1)
Publication Number | Publication Date |
---|---|
CN113260990A true CN113260990A (en) | 2021-08-13 |
Family
ID=67470651
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201980087634.6A Pending CN113260990A (en) | 2019-07-01 | 2019-07-01 | Mobile-enabled voice search for media items displayed on alternative playback devices |
Country Status (4)
Country | Link |
---|---|
US (1) | US20220113935A1 (en) |
EP (1) | EP3994591A1 (en) |
CN (1) | CN113260990A (en) |
WO (1) | WO2021002846A1 (en) |
Family Cites Families (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
KR20120010433A (en) * | 2010-07-26 | 2012-02-03 | 엘지전자 주식회사 | Method for operating an apparatus for displaying image |
JP5209808B2 (en) * | 2011-06-14 | 2013-06-12 | シャープ株式会社 | System, television receiver, information terminal, control method, program, and recording medium |
US9600474B2 (en) * | 2013-11-08 | 2017-03-21 | Google Inc. | User interface for realtime language translation |
JP5955299B2 (en) * | 2013-11-08 | 2016-07-20 | 株式会社ソニー・インタラクティブエンタテインメント | Display control apparatus, display control method, program, and information storage medium |
KR102307976B1 (en) * | 2016-05-10 | 2021-09-30 | 구글 엘엘씨 | Implementations for voice assistant on devices |
-
2019
- 2019-07-01 US US17/419,255 patent/US20220113935A1/en active Pending
- 2019-07-01 EP EP19745839.1A patent/EP3994591A1/en active Pending
- 2019-07-01 WO PCT/US2019/040201 patent/WO2021002846A1/en unknown
- 2019-07-01 CN CN201980087634.6A patent/CN113260990A/en active Pending
Also Published As
Publication number | Publication date |
---|---|
US20220113935A1 (en) | 2022-04-14 |
EP3994591A1 (en) | 2022-05-11 |
WO2021002846A1 (en) | 2021-01-07 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US11614859B2 (en) | Dynamic resizable media item player | |
US20200162413A1 (en) | Low-friction, instant, private, personalized video sharing widget | |
US11769529B2 (en) | Storyline experience | |
CN105659206B (en) | Generating playlists for a content sharing platform based on user actions | |
JP6367311B2 (en) | User history playlists and subscriptions | |
US11775152B2 (en) | Presenting content items and performing actions with respect to content items | |
US20180232121A1 (en) | Perpendicular autoplay video feed related navigation | |
CN107660334B (en) | Cross-application content player | |
US11435876B1 (en) | Techniques for sharing item information from a user interface | |
CN110140332B (en) | Handover feature for content sharing platform | |
JP2024056704A (en) | Dynamic integration of customized supplemental media content | |
US20160371737A1 (en) | Personalized and contextual notifications of content releases | |
US20230137957A1 (en) | Revolving on-screen virtual keyboard for efficient use during character input | |
CN113260990A (en) | Mobile-enabled voice search for media items displayed on alternative playback devices | |
US20230367538A1 (en) | Methods and systems for facilitating user participation in content engagement activities | |
US10127312B1 (en) | Mutable list resilient index for canonical addresses of variable playlists | |
KR20240064003A (en) | Dynamic integration of customized supplemental media content | |
KR20220090177A (en) | Server, system and computer readable storage medium to manage requests for performances |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination |