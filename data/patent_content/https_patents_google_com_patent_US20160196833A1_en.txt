US20160196833A1 - Detection and suppression of keyboard transient noise in audio streams with auxiliary keybed microphone - Google Patents
Detection and suppression of keyboard transient noise in audio streams with auxiliary keybed microphone Download PDFInfo
- Publication number
- US20160196833A1 US20160196833A1 US14/591,418 US201514591418A US2016196833A1 US 20160196833 A1 US20160196833 A1 US 20160196833A1 US 201514591418 A US201514591418 A US 201514591418A US 2016196833 A1 US2016196833 A1 US 2016196833A1
- Authority
- US
- United States
- Prior art keywords
- microphone
- transient noise
- audio signal
- contribution
- noise
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
- 230000001052 transient effect Effects 0.000 title claims abstract description 111
- 238000001514 detection method Methods 0.000 title description 8
- 230000001629 suppression Effects 0.000 title description 5
- 238000000034 method Methods 0.000 claims abstract description 58
- 238000013179 statistical model Methods 0.000 claims abstract description 11
- 230000005236 sound signal Effects 0.000 claims description 63
- 239000000284 extract Substances 0.000 claims description 5
- 230000003595 spectral effect Effects 0.000 abstract description 8
- 230000008569 process Effects 0.000 abstract description 7
- 230000004044 response Effects 0.000 abstract description 6
- 230000002708 enhancing effect Effects 0.000 abstract 1
- 238000009826 distribution Methods 0.000 description 21
- 238000013459 approach Methods 0.000 description 15
- 230000006870 function Effects 0.000 description 14
- 238000012545 processing Methods 0.000 description 11
- 238000012546 transfer Methods 0.000 description 8
- 238000004891 communication Methods 0.000 description 6
- 238000010586 diagram Methods 0.000 description 6
- 238000003860 storage Methods 0.000 description 6
- 230000006872 improvement Effects 0.000 description 5
- 230000000694 effects Effects 0.000 description 4
- 230000003993 interaction Effects 0.000 description 3
- 238000004458 analytical method Methods 0.000 description 2
- 230000006399 behavior Effects 0.000 description 2
- 230000001419 dependent effect Effects 0.000 description 2
- 238000009472 formulation Methods 0.000 description 2
- 238000012880 independent component analysis Methods 0.000 description 2
- 238000005259 measurement Methods 0.000 description 2
- 239000000203 mixture Substances 0.000 description 2
- 238000000926 separation method Methods 0.000 description 2
- 238000001228 spectrum Methods 0.000 description 2
- 230000001360 synchronised effect Effects 0.000 description 2
- AZFKQCNGMSSWDS-UHFFFAOYSA-N MCPA-thioethyl Chemical compound CCSC(=O)COC1=CC=C(Cl)C=C1C AZFKQCNGMSSWDS-UHFFFAOYSA-N 0.000 description 1
- 238000000342 Monte Carlo simulation Methods 0.000 description 1
- 230000003044 adaptive effect Effects 0.000 description 1
- 239000000654 additive Substances 0.000 description 1
- 230000000996 additive effect Effects 0.000 description 1
- 238000003491 array Methods 0.000 description 1
- 230000005540 biological transmission Effects 0.000 description 1
- 238000004590 computer program Methods 0.000 description 1
- 230000003247 decreasing effect Effects 0.000 description 1
- 230000001934 delay Effects 0.000 description 1
- 238000011161 development Methods 0.000 description 1
- 238000005516 engineering process Methods 0.000 description 1
- 230000002349 favourable effect Effects 0.000 description 1
- 239000000835 fiber Substances 0.000 description 1
- 238000007667 floating Methods 0.000 description 1
- 230000014509 gene expression Effects 0.000 description 1
- 230000001939 inductive effect Effects 0.000 description 1
- 230000010354 integration Effects 0.000 description 1
- 238000013507 mapping Methods 0.000 description 1
- 239000011159 matrix material Substances 0.000 description 1
- 230000007246 mechanism Effects 0.000 description 1
- 238000012986 modification Methods 0.000 description 1
- 230000004048 modification Effects 0.000 description 1
- 230000035772 mutation Effects 0.000 description 1
- 230000003287 optical effect Effects 0.000 description 1
- 238000005457 optimization Methods 0.000 description 1
- 230000010355 oscillation Effects 0.000 description 1
- 238000012805 post-processing Methods 0.000 description 1
- 230000009467 reduction Effects 0.000 description 1
- 238000005070 sampling Methods 0.000 description 1
- 238000013341 scale-up Methods 0.000 description 1
- 238000004088 simulation Methods 0.000 description 1
- 238000012360 testing method Methods 0.000 description 1
- 230000000007 visual effect Effects 0.000 description 1
Images
Classifications
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L21/00—Processing of the speech or voice signal to produce another audible or non-audible signal, e.g. visual or tactile, in order to modify its quality or its intelligibility
- G10L21/02—Speech enhancement, e.g. noise reduction or echo cancellation
- G10L21/0208—Noise filtering
- G10L21/0216—Noise filtering characterised by the method used for estimating noise
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L21/00—Processing of the speech or voice signal to produce another audible or non-audible signal, e.g. visual or tactile, in order to modify its quality or its intelligibility
- G10L21/02—Speech enhancement, e.g. noise reduction or echo cancellation
- G10L21/0208—Noise filtering
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04R—LOUDSPEAKERS, MICROPHONES, GRAMOPHONE PICK-UPS OR LIKE ACOUSTIC ELECTROMECHANICAL TRANSDUCERS; DEAF-AID SETS; PUBLIC ADDRESS SYSTEMS
- H04R29/00—Monitoring arrangements; Testing arrangements
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L21/00—Processing of the speech or voice signal to produce another audible or non-audible signal, e.g. visual or tactile, in order to modify its quality or its intelligibility
- G10L21/02—Speech enhancement, e.g. noise reduction or echo cancellation
- G10L21/0272—Voice signal separating
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04R—LOUDSPEAKERS, MICROPHONES, GRAMOPHONE PICK-UPS OR LIKE ACOUSTIC ELECTROMECHANICAL TRANSDUCERS; DEAF-AID SETS; PUBLIC ADDRESS SYSTEMS
- H04R3/00—Circuits for transducers, loudspeakers or microphones
- H04R3/002—Damping circuit arrangements for transducers, e.g. motional feedback circuits
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L21/00—Processing of the speech or voice signal to produce another audible or non-audible signal, e.g. visual or tactile, in order to modify its quality or its intelligibility
- G10L21/02—Speech enhancement, e.g. noise reduction or echo cancellation
- G10L21/0208—Noise filtering
- G10L21/0216—Noise filtering characterised by the method used for estimating noise
- G10L2021/02161—Number of inputs available containing the signal or the noise to be suppressed
- G10L2021/02165—Two microphones, one receiving mainly the noise signal and the other one mainly the speech signal
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04R—LOUDSPEAKERS, MICROPHONES, GRAMOPHONE PICK-UPS OR LIKE ACOUSTIC ELECTROMECHANICAL TRANSDUCERS; DEAF-AID SETS; PUBLIC ADDRESS SYSTEMS
- H04R2410/00—Microphones
- H04R2410/03—Reduction of intrinsic noise in microphones
Definitions
- the present disclosure generally relates to methods and systems for signal processing. More specifically, aspects of the present disclosure relate to suppressing transient noise in an audio signal using input from an auxiliary microphone as a reference signal.
- One embodiment of the present disclosure relates to a computer-implemented method for suppressing transient noise comprising: receiving an audio signal input from a first microphone of a user device, wherein the audio signal contains voice data and transient noise captured by the first microphone; receiving information about the transient noise from a second microphone of the user device, wherein the second microphone is located separately from the first microphone in the user device, and the second microphone is located proximate to a source of the transient noise; estimating a contribution of the transient noise in the audio signal input from the first microphone based on the information about the transient noise received from the second microphone; and extracting the voice data from the audio signal input from the first microphone based on the estimated contribution of the transient noise.
- the method for suppressing transient noise further comprises using a statistical model to map the second microphone onto the first microphone.
- the method for suppressing transient noise further comprises adjusting the estimated contribution of the transient noise in the audio signal based on the information received from the second microphone.
- the adjusting of the estimated contribution of the transient noise in the method for suppressing transient noise includes scaling-up or scaling-down the estimated contribution.
- the method for suppressing transient noise further comprises determining, based on the adjusted estimated contribution, an estimated power level for the transient noise at each frequency, in each time frame, in the audio signal input from the first microphone.
- the method for suppressing transient noise further comprises extracting the voice data from the audio signal captured by the first microphone based on the estimated power level for the transient noise at each frequency, in each time frame, in the audio signal from the first microphone.
- the estimating of the contribution of the transient noise in the method for suppressing transient noise includes determining a MAP (Maximum-a-Posteriori) estimate for a part of the audio signal containing the voice data using an Expectation-Maximization algorithm.
- MAP Maximum-a-Posteriori
- Another embodiment of the present disclosure relates to system for suppressing transient noise, the system comprising a least one processor and a non-transitory computer-readable medium coupled to the at least one processor having instructions stored thereon that, when executed by the at least one processor, causes the at least one processor to: receive an audio signal input from a first microphone of a user device, wherein the audio signal contains voice data and transient noise captured by the first microphone; obtain information about the transient noise from a second microphone of the user device, wherein the second microphone is located separately from the first microphone in the user device, and the second microphone is located proximate to a source of the transient noise; estimate a contribution of the transient noise in the audio signal input from the first microphone based on the information about the transient noise obtained from the second microphone; and extract the voice data from the audio signal input from the first microphone based on the estimated contribution of the transient noise.
- the at least one processor in the system for suppressing transient noise is further caused to map the second microphone onto the first microphone using a statistical model.
- the at least one processor in the system for suppressing transient noise is further caused to adjust the estimated contribution of the transient noise in the audio signal based on the information obtained from the second microphone.
- the at least one processor in the system for suppressing transient noise is further caused to adjust the estimated contribution of the transient noise by scaling-up or scaling-down the estimated contribution.
- the at least one processor in the system for suppressing transient noise is further caused to determine, based on the adjusted estimated contribution, an estimated power level for the transient noise at each frequency, in each time frame, in the audio signal input from the first microphone.
- the at least one processor in the system for suppressing transient noise is further caused to extract the voice data from the audio signal captured by the first microphone based on the estimated power level for the transient noise at each frequency, in each time frame, in the audio signal from the first microphone.
- the at least one processor in the system for suppressing transient noise is further caused to determine a MAP (Maximum-a-Posteriori) estimate for a part of the audio signal containing the voice data using an Expectation-Maximization algorithm.
- MAP Maximum-a-Posteriori
- Yet another embodiment of the present disclosure relates to one or more non-transitory computer readable media storing computer-executable instructions that, when executed by one or more processors, causes the one or more processors to perform operations comprising: receiving an audio signal input from a first microphone of a user device, wherein the audio signal contains voice data and transient noise captured by the first microphone; receiving information about the transient noise from a second microphone of the user device, wherein the second microphone is located separately from the first microphone in the user device, and the second microphone is located proximate to a source of the transient noise; estimating a contribution of the transient noise in the audio signal input from the first microphone based on the information about the transient noise received from the second microphone; and extracting the voice data from the audio signal input from the first microphone based on the estimated contribution of the transient noise.
- the computer-executable instructions stored in the one or more non-transitory computer readable media when executed by the one or more processors, cause the one or more processors to perform further operations comprising: adjusting the estimated contribution of the transient noise in the audio signal based on the information received from the second microphone; determining, based on the adjusted estimated contribution, an estimated power level for the transient noise at each frequency, in each time frame, in the audio signal input from the first microphone; and extracting the voice data from the audio signal captured by the first microphone based on the estimated power level for the transient noise at each frequency, in each time frame, in the audio signal from the first microphone.
- the methods and systems described herein may optionally include one or more of the following additional features: the information received from the second microphone includes spectrum-amplitude information about the transient noise; the source of the transient noise is a keybed of the user device; and/or the transient noise contained in the audio signal is a key click.
- FIG. 1 is a schematic diagram illustrating an example application for transient noise suppression using input from an auxiliary microphone as a reference signal according to one or more embodiments described herein.
- FIG. 2 is flowchart illustrating an example method for suppressing transient noise in an audio signal using an auxiliary microphone input signal as a reference signal according to one or more embodiments described herein.
- FIG. 3 is a set of graphical representations illustrating example simultaneously recorded waveforms for primary and auxiliary microphones according to one or more embodiments described herein.
- FIG. 4 is a set of graphical representations illustrating example performance results for a transient noise detection and restoration algorithm according to one or more embodiments described herein.
- FIG. 5 is a block diagram illustrating an example computing device arranged for suppressing transient noise in an audio signal by incorporating an auxiliary microphone input signal as a reference signal according to one or more embodiments described herein.
- one or more microphones associated with a user device records voice signals that are corrupted with ambient noise and also with transient noise from, for example, keyboard and/or mouse clicks.
- a synchronous reference microphone embedded in the keyboard of the user device (which may sometimes be referred to herein as the “keybed” microphone) allows for measurement of the key click noise, substantially unaffected by the voice signal and ambient noise.
- an algorithm for incorporating the keybed microphone as a reference signal in a signal restoration process used for the voice part of the signal.
- the problem addressed by the methods and systems described herein may be complicated by the potential presence of nonlinear vibrations in the hinge and casework of the user device, which may render a simple linear suppressor ineffective in some scenarios.
- the transfer functions between key clicks and voice microphones depend strongly upon which key is being clicked.
- the present disclosure provides a low-latency solution in which short-time transform data is processed sequentially in short frames and a robust statistical model is formulated and estimated using Bayesian inference procedures.
- example results from using the methods and systems of the present disclosure with real audio recordings demonstrate a significant reduction of typing artifacts at the expense of small amounts of voice distortion.
- the methods and systems described herein are designed to operate easily in real-time on standard hardware, and have very low latency so that there is no irritating delay in speaker response.
- Some existing approaches including, for example, model-based source separation and template-based methods have found some success in removing transient noise.
- the success of these existing approaches has been limited to more general audio restoration tasks, where real-time low-latency processing is of less concern.
- NMF non-negative matrix factorization
- ICA independent component analysis
- Another possible restoration approach is to include operating system (OS) messages that indicate which key has been pressed and when.
- OS operating system
- the methods and systems of the present disclosure utilize a reference microphone input signal for the keyboard noise and a new robust Bayesian statistical model for regressing the voice microphone on the keyboard reference microphone, which allows for direct inference about the desired voice signal while marginalizing the unwanted power spectral values of the voice and keystroke noise.
- the present disclosure provides a straightforward and efficient Expectation-maximization (EM) procedure for fast, on-line enhancement of the corrupted signal.
- EM Expectation-maximization
- the methods and systems of the present disclosure have numerous real-world applications.
- the methods and systems may be implemented in computing devices (e.g., laptop computers, tablet computers, etc.) that have an auxiliary microphone located beneath the keyboard (or at some other location on the device besides where the one or more primary microphones are located) in order to improve the effectiveness and efficiency of transient noise suppression processing that may be performed.
- computing devices e.g., laptop computers, tablet computers, etc.
- auxiliary microphone located beneath the keyboard (or at some other location on the device besides where the one or more primary microphones are located) in order to improve the effectiveness and efficiency of transient noise suppression processing that may be performed.
- FIG. 1 illustrates an example 100 of such an application, where a user device 140 (e.g., laptop computer, tablet computer, etc.) includes one or more primary audio capture devices 110 (e.g., microphones), a user input device 165 (e.g., a keyboard, keypad, keybed, etc.), and an auxiliary (e.g., secondary or reference) audio capture device 115 .
- a user device 140 e.g., laptop computer, tablet computer, etc.
- primary audio capture devices 110 e.g., microphones
- a user input device 165 e.g., a keyboard, keypad, keybed, etc.
- auxiliary audio capture device 115 e.g., secondary or reference
- the one or more primary audio capture devices 110 may capture speech/source signals ( 150 ) generated by a user 120 (e.g., an audio source), as well as background noise ( 145 ) generated from one or more background sources of audio 130 .
- transient noise ( 155 ) generated by the user 120 operating the user input device 165 e.g., typing on a keyboard while participating in an audio/video communication session via user device 140
- the combination of speech/source signals ( 150 ), background noise ( 145 ), and transient noise ( 155 ) may be captured by audio capture devices 110 and input (e.g., received, obtained, etc.) as one or more input signals ( 160 ) to a signal processor 170 .
- the signal processor 170 may operate at the client, while in accordance with at least one other embodiment the signal processor may operate at a server in communication with the user device 140 over a network (e.g., the Internet).
- the auxiliary audio capture device 115 may be located internally to the user device 140 (e.g., on, beneath, beside, etc., the user input device 165 ) and may be configured to measure interaction with the user input device 165 . For example, in accordance with at least one embodiment, the auxiliary audio capture device 115 measures keystrokes generated from interaction with the keybed. The information obtained by the auxiliary microphone 115 may then be used to better restore a voice microphone signal which is corrupted by key clicks (e.g., input signal ( 160 ), which may be corrupted by transient noises ( 155 )) resulting from the interaction with the keybed. For example, the information obtained by the auxiliary microphone 115 may be input as a reference signal ( 180 ) to the signal processor 170 .
- key clicks e.g., input signal ( 160 )
- transient noises ( 155 ) transient noises
- the signal processor 170 may be configured to perform a signal restoration algorithm on the received input signal ( 160 ) (e.g., voice signal) using the reference signal ( 180 ) from the auxiliary audio capture device 115 .
- the signal processor 170 may implement a statistical model for mapping the auxiliary microphone 115 onto the voice microphone 110 . For example, if a key click is measured on the auxiliary microphone 115 , the signal processor 170 may use the statistical model to transform the key click measurement into something that can be used to estimate the key click contribution in the voice microphone signal 110 .
- spectrum-amplitude information from the keybed microphone 115 may be used to scale up or scale down the estimation of the keystroke in the voice microphone. This results in an estimated power level for the key click noise at each frequency, in each time frame, in the voice microphone. The voice signal may then be extracted based on this estimated power level for the key click noise at each frequency, in each time frame, in the voice microphone.
- the methods and systems of the present disclosure may be used in mobile devices (e.g., mobile telephones, smartphones, personal digital assistants, (PDAs)) and in various systems designed to control devices by means of speech recognition.
- mobile devices e.g., mobile telephones, smartphones, personal digital assistants, (PDAs)
- PDAs personal digital assistants
- FIG. 2 illustrates an example high-level process 200 for suppressing transient noise in an audio signal using an Auxiliary microphone input signal as a reference signal.
- the details of blocks 205 - 215 in the example process 200 will be further described in the following.
- a reference microphone e.g., the keybed microphone
- synchronized recordings sampled at 44.1 kHz of the voice microphone waveform, X V and the keybed microphone waveform, X K .
- the keybed microphone is placed below the keyboard in the body of the user device, and is acoustically insulated from the surrounding environment.
- the signal captured by the keybed microphone may be reasonably assumed to contain very little of the desired speech and ambient noise, and thus serves as a good reference recording of the contaminating keystroke noise. From this point forward, it may be assumed that the audio data has been transformed into a time-frequency domain using any suitable method known to those skilled in the art (e.g., the short-time Fourier Transform (STFT)).
- STFT short-time Fourier Transform
- X V,j,t and X K,j,t will represent complex frequency coefficients at some frequency bin j and time frame t (although in the following description these indices may be omitted where no ambiguity is introduced as a result).
- One approach may model the voice waveform assuming a linear transfer function H j at frequency bin j between the reference microphone and the voice microphone, and assuming that no speech contaminates the keybed microphone:
- the present disclosure provides a robust signal-based approach, in which the random perturbations and nonlinearities in the transfer function are modelled as random effects in measured keystroke waveform K at the voice microphone:
- V is the desired voice signal and K is the undesired key click.
- statistical models may be formulated for both the voice and keyboard signals in the frequency domain. These models exhibit the known characteristics of speech signals in the time-frequency domain (e.g., sparsity and heavy-tailed (non-Gaussian) behavior).
- V j is modeled as a conditional complex normal distribution with random variance that is distributed as an inverted gamma distribution, which is known to be equivalent to modelling V j as a heavy-tailed Student-t distribution,
- ⁇ denotes that a random variable is drawn according to the distribution to the right
- N C is the complex normal distribution
- IG is the inverted-gamma distribution.
- the prior parameters ( ⁇ V , ⁇ V ) are tuned to match the spectral variability of speech and/or the previous estimated speech spectra from earlier frames, which will be described in greater detail below.
- Such a model has been found effective in a number of audio enhancement/separation domains, and is in contrast with other Gaussian or non-Gaussian statistical speech models known those skilled in the art.
- the keyboard component K is decomposed also in terms of a heavy-tailed distribution, but with its scaling regressed on the secondary reference channel X K,j :
- ⁇ being a random variable that scales the whole spectrum by a random gain factor
- the methods and systems of the present disclosure are at least partially motivated by the observation that the frequency response between keybed microphone and voice microphone has an approximately constant gain magnitude response across frequencies (this is modelled as the unknown gain ⁇ , but subject to random perturbations of both amplitude and phase (modelled by the IG distribution on ⁇ K,j 2 )).
- the prior maximum of ⁇ K,j 2 may be set to unity. The remaining prior values may be tuned to match the observed characteristics of the real recorded datasets, which is described in greater detail below.
- the methods and systems described herein aim to estimate the desired voice signal (V j ) based on the observed signals X V and X K .
- a suitable object for inference is the posterior distribution
- (o ⁇ K , ⁇ V ) is the collection of scale parameters ⁇ K,j , ⁇ V,j ⁇ across all frequency bins j in the current time frame.
- X V , X K ] for a MMSE (minimum mean square error) estimation scheme may be extracted, or some other estimate (e.g., based on a perceptual cost function) obtained in a manner known to those skilled in the art.
- Such expectations are often handled using, for example, Bayesian Monte Carlo methods. However, because Monte Carlo schemes are likely to render the processing non-real-time, the methods and systems provided herein avoid the use of such techniques. Instead, in accordance with one or more embodiments, the methods and systems of the present disclosure utilize a MAP (Maximum-a-Posteriori) estimation using a generalized Expectation-Maximization (EM) algorithm:
- latent variables to be integrated out are first defined.
- latent variables include ( ⁇ K , ⁇ V ).
- the algorithm then operates iteratively, starting with an initial estimate (V 0 , ⁇ 0 ).
- an expectation Q of the complete data log-likelihood may be computed as follows (it should be noted that the following is the Bayesian formulation of EM in which a prior distribution is included for the unknowns V and ⁇ ):
- K j (i) X V,j ⁇ V (i) is the current estimate of the unwanted keystroke coefficient at frequency j.
- log-conditional distribution may be expanded over frequency bins j using Bayes' Theorem as follows:
- this expectation may be computed numerically and stored, for example, in a look-up table.
- the maximization portion of the algorithm maximizes Q jointly with respect to (V, ⁇ ). Because of the complex structure of the model, such maximization is difficult to achieve in closed form for this Q function. Instead, in accordance with one or more embodiments described herein, the method of the present disclosure utilizes iterative formulae for maximizing V with a fixed, then maximizing ⁇ with V fixed at the new value, and repeating this several times within each EM iteration.
- Such an approach is a generalized EM, which, similar to standard EM, guarantees convergence to a maximum of the probability surface, since each iteration is guaranteed to increase the probability of the current iteration's estimate (e.g., this could be a local maximum, just like for standard EM). Therefore, the generalized EM algorithm described herein guarantees that the posterior probability is non-decreasing at each iteration, and thus can be expected to converge to the true MAP solution with increasing iteration number.
- V j ( i + 1 ) E ⁇ [ 1 ⁇ V j 2 ] E ⁇ [ 1 ⁇ V j 2 ] + E ⁇ [ 1 ⁇ K , j 2 ] ⁇ ( i + 1 ) 2 ⁇ ⁇ X K , j ⁇ 2 ⁇ ⁇ X V , j ( 6 )
- ⁇ ( i + 1 ) ⁇ ⁇ + ⁇ j ⁇ E ⁇ [ 1 ⁇ K , j 2 ] ⁇ 1 2 ⁇ ⁇ X k , j ⁇ 2 ⁇ ( ⁇ K j ( i + 1 ) ⁇ 2 ) ⁇ ⁇ + 1 + J ( 7 )
- the resulting spectral components V j may be transformed back to the time domain (e.g., via the inverse fast Fourier transform (FFT) in the short time Fourier transform (STFT) case) and reconstructed into a continuous signal by windowed overlap-add procedures.
- FFT inverse fast Fourier transform
- STFT short time Fourier transform
- the following describes some example results that may be obtained through experimentation. It should be understood that although the following provides example performance results in the context of a laptop computer containing an auxiliary microphone located beneath the keyboard, the scope of the present disclosure is not limited to this particular context or implementation. Instead, similar levels of performance may also be achieved using the methods and systems of the present disclosure in various other contexts and/or scenarios involving other types of user devices, including, for example, where the auxiliary microphone is at a location on the user device other than beneath the keyboard (but not at the same or similar location as one or more primary microphones of the device).
- the present example is based on audio files recorded from a laptop computer containing at least one primary microphone (e.g., voice microphone) and also an auxiliary microphone located beneath the keyboard (e.g., keybed microphone). Sampling is performed synchronously at 44.1 kHz from the voice and keybed microphones, and processing carried out using a generalized EM algorithm. Frame lengths of 1024 samples may be used for an STFT transform, with 50% overlap and Hanning analysis windows.
- the parameter ⁇ V,j may be set in a frequency-dependent manner as follows: (i) the final EM-estimated voice signal from the previous frame,
- 2 , for example, by setting ⁇ V,j
- a time-domain detector may be devised to flag corrupted frames, and processing may only be applied to frames for which detection was flagged, therefore avoiding unnecessary signal distortions and wasted computations through processing in uncorrupted frames.
- the time-domain detector comprises a rule-based combination of detections from the keybed microphone signal and two available (stereo) voice microphones. Within each audio stream, detections are based on an autoregressive (AR) error signal, and frames are flagged as corrupted when the maximum error magnitude exceeds a certain factor of the median error magnitude for that frame.
- AR autoregressive
- Performance may be evaluated using an average segmental signal-to-noise (SNR) measure
- v t,n is the true, uncorrupted, voice signal at the ith sample of the nth frame
- ⁇ circumflex over (v) ⁇ is the corresponding estimate of v. Performance is compared against a straightforward procedure which mutes the spectral components to zero in frames that are detected as corrupted.
- Results illustrate an improvement on average of approximately 3 dB when taken over the whole speech extract, and 6-10 dB when inducing just the frames detected as corrupted. These example results may be adjusted by tuning the prior parameters to trade-off perceived signal distortion against suppression levels of the noise. Although these example results may appear to be relatively small improvements, the perceptual effect of the EM approach, as used in accordance with the methods and systems of the present disclosure, is significantly improved compared with muting the signal and compared with the corrupted input audio.
- FIG. 4 illustrates an example detection and restoration in accordance with one or more embodiments described herein.
- the frames detected as corrupted are indicated by the zero-one waveform 440 .
- These example detections agree with a visual study of the keyclick data waveform.
- Graphical representation 410 shows the corrupted input from the voice microphone
- graphical representation 420 shows the restored output from the voice microphone
- graphical representation 430 shows the original voice signal without any corruption (available in the present example as “ground-truth”).
- the speech envelope and speech events are preserved around 125 k samples and 140 k samples, while the disturbance is suppressed well around 105 k samples.
- the audio is significantly improved in the restoration, leaving very little “click” residue, which can be removed by various post-processing techniques known to those skilled in the art.
- a favorable 10.1 dB improvement in segmental SNR is obtained for corrupted frames (as compared to using a “muting restoration”), and 2.5 dB improvement when all frames are considered (including the uncorrupted frames).
- FIG. 5 is a high-level block diagram of an exemplary computer ( 500 ) arranged for suppressing transient noise in an audio signal by incorporating an auxiliary microphone input signal as a reference signal, according to one or more embodiments described herein.
- the computer ( 500 ) may be configured to utilize spatial selectivity to separate direct and reverberant energy and account for noise separately, thereby considering the response of the beamformer to reverberant sound and the effect of noise.
- the computing device ( 500 ) typically includes one or more processors ( 510 ) and system memory ( 520 ).
- a memory bus ( 530 ) can be used for communicating between the processor ( 510 ) and the system memory ( 520 ).
- the processor ( 510 ) can be of any type including but not limited to a microprocessor ( ⁇ P), a microcontroller ( ⁇ C), a digital signal processor (DSP), or any combination thereof.
- the processor ( 510 ) can include one more levels of caching, such as a level one cache ( 511 ) and a level two cache ( 512 ), a processor core ( 513 ), and registers ( 514 ).
- the processor core ( 513 ) can include an arithmetic logic unit (ALU), a floating point unit (FPU), a digital signal processing core (DSP Core), or any combination thereof.
- a memory controller ( 515 ) can also be used with the processor ( 510 ), or in some implementations the memory controller ( 515 ) can be an internal part of the processor ( 510 ).
- system memory ( 520 ) can be of any type including but not limited to volatile memory (such as RAM), non-volatile memory (such as ROM, flash memory, etc.) or any combination thereof.
- System memory ( 520 ) typically includes an operating system ( 521 ), one or more applications ( 522 ), and program data ( 524 ).
- the application ( 522 ) may include Signal Restoration Algorithm ( 823 ) for suppressing transient noise in an audio signal containing voice data by using information about the transient noise received from a reference (e.g., auxiliary) microphone located in close proximity to the source of the transient noise, in accordance with one or more embodiments described herein.
- a reference e.g., auxiliary
- Program Data ( 524 ) may include storing instructions that, when executed by the one or more processing devices, implement a method for suppressing transient noise by using a statistical model to map a reference microphone onto a voice microphone (e.g., auxiliary microphone 115 and voice microphone 110 in the example system 100 shown in FIG. 1 ) so that information about a transient noise from the reference microphone can be used to estimate a contribution of the transient noise in the signal captured by the voice microphone, according to one or more embodiments described herein.
- a voice microphone e.g., auxiliary microphone 115 and voice microphone 110 in the example system 100 shown in FIG. 1
- program data ( 824 ) may include reference signal data ( 525 ), which may include data (e.g., spectrum-amplitude data) about a transient noise measured by a reference microphone (e.g., reference microphone 115 in the example system 100 shown in FIG. 1 ).
- reference signal data ( 525 ) may include data (e.g., spectrum-amplitude data) about a transient noise measured by a reference microphone (e.g., reference microphone 115 in the example system 100 shown in FIG. 1 ).
- the application ( 522 ) can be arranged to operate with program data ( 524 ) on an operating system ( 521 ).
- the computing device ( 500 ) can have additional features or functionality, and additional interfaces to facilitate communications between the basic configuration ( 501 ) and any required devices and interfaces.
- System memory ( 520 ) is an example of computer storage media.
- Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, digital versatile disks (DVD) or other optical storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can be accessed by computing device 500 . Any such computer storage media can be part of the device ( 500 ).
- the computing device ( 500 ) can be implemented as a portion of a small-form factor portable (or mobile) electronic device such as a cell phone, a smart phone, a personal data assistant (PDA), a personal media player device, a tablet computer (tablet), a wireless web-watch device, a personal headset device, an application-specific device, or a hybrid device that include any of the above functions.
- a small-form factor portable (or mobile) electronic device such as a cell phone, a smart phone, a personal data assistant (PDA), a personal media player device, a tablet computer (tablet), a wireless web-watch device, a personal headset device, an application-specific device, or a hybrid device that include any of the above functions.
- PDA personal data assistant
- tablet computer tablet computer
- wireless web-watch device a wireless web-watch device
- headset device an application-specific device
- hybrid device that include any of the above functions.
- hybrid device that include any of the above functions.
- the computing device ( 500 ) can also be implemented
- non-transitory signal bearing medium examples include, but are not limited to, the following: a recordable type medium such as a floppy disk, a hard disk drive, a Compact Disc (CD), a Digital Video Disk (DVD), a digital tape, a computer memory, etc.; and a transmission type medium such as a digital and/or an analog communication medium (e.g., a fiber optic cable, a waveguide, a wired communications link, a wireless communication link, etc.).
Abstract
Description
- In audio and/or video teleconferencing environments it is common to encounter annoying keyboard typing noise, both simultaneously present with speech and in the “silent” pauses between speech. Example scenarios are where someone participating in a conference call is taking notes on their laptop computer while the meeting is taking place, or where someone checks their emails during a voice call. Users report significant annoyance/distribution when this type of noise is present in audio data.
- This Summary introduces a selection of concepts in a simplified form in order to provide a basic understanding of some aspects of the present disclosure. This Summary is not an extensive overview of the disclosure, and is not intended to identify key or critical elements of the disclosure or to delineate the scope of the disclosure. This Summary merely presents some of the concepts of the disclosure as a prelude to the Detailed Description provided below.
- The present disclosure generally relates to methods and systems for signal processing. More specifically, aspects of the present disclosure relate to suppressing transient noise in an audio signal using input from an auxiliary microphone as a reference signal.
- One embodiment of the present disclosure relates to a computer-implemented method for suppressing transient noise comprising: receiving an audio signal input from a first microphone of a user device, wherein the audio signal contains voice data and transient noise captured by the first microphone; receiving information about the transient noise from a second microphone of the user device, wherein the second microphone is located separately from the first microphone in the user device, and the second microphone is located proximate to a source of the transient noise; estimating a contribution of the transient noise in the audio signal input from the first microphone based on the information about the transient noise received from the second microphone; and extracting the voice data from the audio signal input from the first microphone based on the estimated contribution of the transient noise.
- In another embodiment, the method for suppressing transient noise further comprises using a statistical model to map the second microphone onto the first microphone.
- In another embodiment, the method for suppressing transient noise further comprises adjusting the estimated contribution of the transient noise in the audio signal based on the information received from the second microphone.
- In yet another embodiment, the adjusting of the estimated contribution of the transient noise in the method for suppressing transient noise includes scaling-up or scaling-down the estimated contribution.
- In still another embodiment, the method for suppressing transient noise further comprises determining, based on the adjusted estimated contribution, an estimated power level for the transient noise at each frequency, in each time frame, in the audio signal input from the first microphone.
- In yet another embodiment, the method for suppressing transient noise further comprises extracting the voice data from the audio signal captured by the first microphone based on the estimated power level for the transient noise at each frequency, in each time frame, in the audio signal from the first microphone.
- In another embodiment, the estimating of the contribution of the transient noise in the method for suppressing transient noise includes determining a MAP (Maximum-a-Posteriori) estimate for a part of the audio signal containing the voice data using an Expectation-Maximization algorithm.
- Another embodiment of the present disclosure relates to system for suppressing transient noise, the system comprising a least one processor and a non-transitory computer-readable medium coupled to the at least one processor having instructions stored thereon that, when executed by the at least one processor, causes the at least one processor to: receive an audio signal input from a first microphone of a user device, wherein the audio signal contains voice data and transient noise captured by the first microphone; obtain information about the transient noise from a second microphone of the user device, wherein the second microphone is located separately from the first microphone in the user device, and the second microphone is located proximate to a source of the transient noise; estimate a contribution of the transient noise in the audio signal input from the first microphone based on the information about the transient noise obtained from the second microphone; and extract the voice data from the audio signal input from the first microphone based on the estimated contribution of the transient noise.
- In another embodiment, the at least one processor in the system for suppressing transient noise is further caused to map the second microphone onto the first microphone using a statistical model.
- In yet another embodiment, the at least one processor in the system for suppressing transient noise is further caused to adjust the estimated contribution of the transient noise in the audio signal based on the information obtained from the second microphone.
- In still another embodiment, the at least one processor in the system for suppressing transient noise is further caused to adjust the estimated contribution of the transient noise by scaling-up or scaling-down the estimated contribution.
- In another embodiment, the at least one processor in the system for suppressing transient noise is further caused to determine, based on the adjusted estimated contribution, an estimated power level for the transient noise at each frequency, in each time frame, in the audio signal input from the first microphone.
- In another embodiment, the at least one processor in the system for suppressing transient noise is further caused to extract the voice data from the audio signal captured by the first microphone based on the estimated power level for the transient noise at each frequency, in each time frame, in the audio signal from the first microphone.
- In still another embodiment, the at least one processor in the system for suppressing transient noise is further caused to determine a MAP (Maximum-a-Posteriori) estimate for a part of the audio signal containing the voice data using an Expectation-Maximization algorithm.
- Yet another embodiment of the present disclosure relates to one or more non-transitory computer readable media storing computer-executable instructions that, when executed by one or more processors, causes the one or more processors to perform operations comprising: receiving an audio signal input from a first microphone of a user device, wherein the audio signal contains voice data and transient noise captured by the first microphone; receiving information about the transient noise from a second microphone of the user device, wherein the second microphone is located separately from the first microphone in the user device, and the second microphone is located proximate to a source of the transient noise; estimating a contribution of the transient noise in the audio signal input from the first microphone based on the information about the transient noise received from the second microphone; and extracting the voice data from the audio signal input from the first microphone based on the estimated contribution of the transient noise.
- In another embodiment, the computer-executable instructions stored in the one or more non-transitory computer readable media, when executed by the one or more processors, cause the one or more processors to perform further operations comprising: adjusting the estimated contribution of the transient noise in the audio signal based on the information received from the second microphone; determining, based on the adjusted estimated contribution, an estimated power level for the transient noise at each frequency, in each time frame, in the audio signal input from the first microphone; and extracting the voice data from the audio signal captured by the first microphone based on the estimated power level for the transient noise at each frequency, in each time frame, in the audio signal from the first microphone.
- In one or more other embodiments, the methods and systems described herein may optionally include one or more of the following additional features: the information received from the second microphone includes spectrum-amplitude information about the transient noise; the source of the transient noise is a keybed of the user device; and/or the transient noise contained in the audio signal is a key click.
- Further scope of applicability of the present disclosure will become apparent from the Detailed Description given below. However, it should be understood that the Detailed Description and specific examples, while indicating preferred embodiments, are given by way of illustration only, since various changes and modifications within the spirit and scope of the disclosure will become apparent to those skilled in the art from this Detailed Description.
- These and other objects, features and characteristics of the present disclosure will become more apparent to those skilled in the art from a study of the following Detailed Description in conjunction with the appended claims and drawings, all of which form a part of this specification. In the drawings:
-
FIG. 1 is a schematic diagram illustrating an example application for transient noise suppression using input from an auxiliary microphone as a reference signal according to one or more embodiments described herein. -
FIG. 2 is flowchart illustrating an example method for suppressing transient noise in an audio signal using an auxiliary microphone input signal as a reference signal according to one or more embodiments described herein. -
FIG. 3 is a set of graphical representations illustrating example simultaneously recorded waveforms for primary and auxiliary microphones according to one or more embodiments described herein. -
FIG. 4 is a set of graphical representations illustrating example performance results for a transient noise detection and restoration algorithm according to one or more embodiments described herein. -
FIG. 5 is a block diagram illustrating an example computing device arranged for suppressing transient noise in an audio signal by incorporating an auxiliary microphone input signal as a reference signal according to one or more embodiments described herein. - The headings provided herein are for convenience only and do not necessarily affect the scope or meaning of what is claimed in the present disclosure.
- In the drawings, the same reference numerals and any acronyms identify elements or acts with the same or similar structure or functionality for ease of understanding and convenience. The drawings will be described in detail in the course of the following Detailed Description.
- Various examples and embodiments will now be described. The following description provides specific details for a thorough understanding and enabling description of these examples. One skilled in the relevant art will understand, however, that one or more embodiments described herein may be practiced without many of these details. Likewise, one skilled in the relevant art will also understand that one or more embodiments of the present disclosure can include many other obvious features not described in detail herein. Additionally, some well-known structures or functions may not be shown or described in detail below, so as to avoid unnecessarily obscuring the relevant description.
- As discussed above, users find it disruptive and annoying when keyboard typing noise is present during an audio and/or video conference. Therefore, it is desirable to remove such noise without introducing perceivable distortions to the desired speech.
- The methods and systems of the present disclosure are designed to overcome existing problems in transient noise suppression for audio streams in portable user devices (e.g., laptop computers, tablet computers, mobile telephones, smartphones, etc.). In accordance with one or more embodiments described herein, one or more microphones associated with a user device records voice signals that are corrupted with ambient noise and also with transient noise from, for example, keyboard and/or mouse clicks. As will be described in greater detail below, a synchronous reference microphone embedded in the keyboard of the user device (which may sometimes be referred to herein as the “keybed” microphone) allows for measurement of the key click noise, substantially unaffected by the voice signal and ambient noise.
- In accordance with at least one embodiment of the present disclosure, an algorithm is provided for incorporating the keybed microphone as a reference signal in a signal restoration process used for the voice part of the signal.
- It should be noted that the problem addressed by the methods and systems described herein may be complicated by the potential presence of nonlinear vibrations in the hinge and casework of the user device, which may render a simple linear suppressor ineffective in some scenarios. Moreover, the transfer functions between key clicks and voice microphones depend strongly upon which key is being clicked. In view of these recognized complications and dependencies, the present disclosure provides a low-latency solution in which short-time transform data is processed sequentially in short frames and a robust statistical model is formulated and estimated using Bayesian inference procedures. As will be further described in the following, example results from using the methods and systems of the present disclosure with real audio recordings demonstrate a significant reduction of typing artifacts at the expense of small amounts of voice distortion.
- The methods and systems described herein are designed to operate easily in real-time on standard hardware, and have very low latency so that there is no irritating delay in speaker response. Some existing approaches including, for example, model-based source separation and template-based methods have found some success in removing transient noise. However, the success of these existing approaches has been limited to more general audio restoration tasks, where real-time low-latency processing is of less concern. While other existing approaches such as non-negative matrix factorization (NMF) and independent component analysis (ICA) have proposed possible alternatives to the type of restoration performed by the methods and systems described herein, these other existing approaches are burdened by various latency and processing speed issues. Another possible restoration approach is to include operating system (OS) messages that indicate which key has been pressed and when. However, the uncertain delays involved with relying on OS messages on many systems make such an approach impractical.
- Other existing approaches that have attempted to address the keystroke removal problem have used single-ended methods in which the keyboard transients must be removed “blind” from the audio stream without access to any timing or amplitude information about the key strikes. Clearly, there are issues of reliability and signal fidelity with such approaches, and speech distortions may be audible and/or keystrokes left untouched.
- In contrast with existing approaches, including those described above, the methods and systems of the present disclosure utilize a reference microphone input signal for the keyboard noise and a new robust Bayesian statistical model for regressing the voice microphone on the keyboard reference microphone, which allows for direct inference about the desired voice signal while marginalizing the unwanted power spectral values of the voice and keystroke noise. In addition, as will be described in greater detail below, the present disclosure provides a straightforward and efficient Expectation-maximization (EM) procedure for fast, on-line enhancement of the corrupted signal.
- The methods and systems of the present disclosure have numerous real-world applications. For example, the methods and systems may be implemented in computing devices (e.g., laptop computers, tablet computers, etc.) that have an auxiliary microphone located beneath the keyboard (or at some other location on the device besides where the one or more primary microphones are located) in order to improve the effectiveness and efficiency of transient noise suppression processing that may be performed.
-
FIG. 1 illustrates an example 100 of such an application, where a user device 140 (e.g., laptop computer, tablet computer, etc.) includes one or more primary audio capture devices 110 (e.g., microphones), a user input device 165 (e.g., a keyboard, keypad, keybed, etc.), and an auxiliary (e.g., secondary or reference)audio capture device 115. - The one or more primary
audio capture devices 110 may capture speech/source signals (150) generated by a user 120 (e.g., an audio source), as well as background noise (145) generated from one or more background sources ofaudio 130. In addition, transient noise (155) generated by theuser 120 operating the user input device 165 (e.g., typing on a keyboard while participating in an audio/video communication session via user device 140) may also be captured byaudio capture devices 110. For example, the combination of speech/source signals (150), background noise (145), and transient noise (155) may be captured byaudio capture devices 110 and input (e.g., received, obtained, etc.) as one or more input signals (160) to asignal processor 170. In accordance with at least one embodiment thesignal processor 170 may operate at the client, while in accordance with at least one other embodiment the signal processor may operate at a server in communication with the user device 140 over a network (e.g., the Internet). - The auxiliary
audio capture device 115 may be located internally to the user device 140 (e.g., on, beneath, beside, etc., the user input device 165) and may be configured to measure interaction with the user input device 165. For example, in accordance with at least one embodiment, the auxiliaryaudio capture device 115 measures keystrokes generated from interaction with the keybed. The information obtained by theauxiliary microphone 115 may then be used to better restore a voice microphone signal which is corrupted by key clicks (e.g., input signal (160), which may be corrupted by transient noises (155)) resulting from the interaction with the keybed. For example, the information obtained by theauxiliary microphone 115 may be input as a reference signal (180) to thesignal processor 170. - As will be described in greater detail below, the
signal processor 170 may be configured to perform a signal restoration algorithm on the received input signal (160) (e.g., voice signal) using the reference signal (180) from the auxiliaryaudio capture device 115. In accordance with one or more embodiments, thesignal processor 170 may implement a statistical model for mapping theauxiliary microphone 115 onto thevoice microphone 110. For example, if a key click is measured on theauxiliary microphone 115, thesignal processor 170 may use the statistical model to transform the key click measurement into something that can be used to estimate the key click contribution in thevoice microphone signal 110. - In accordance with at least one embodiment of the present disclosure, spectrum-amplitude information from the
keybed microphone 115 may be used to scale up or scale down the estimation of the keystroke in the voice microphone. This results in an estimated power level for the key click noise at each frequency, in each time frame, in the voice microphone. The voice signal may then be extracted based on this estimated power level for the key click noise at each frequency, in each time frame, in the voice microphone. - In one or more other examples, the methods and systems of the present disclosure may be used in mobile devices (e.g., mobile telephones, smartphones, personal digital assistants, (PDAs)) and in various systems designed to control devices by means of speech recognition.
- The following provides details about the transient noise detection and signal restoration algorithm of the present disclosure, and also describes some example performance results of the algorithm.
FIG. 2 illustrates an example high-level process 200 for suppressing transient noise in an audio signal using an Auxiliary microphone input signal as a reference signal. The details of blocks 205-215 in theexample process 200 will be further described in the following. - Recording Setup
- To further illustrate various features of the methods and systems described herein, the following provides an example setup in accordance with one or more embodiments of the present disclosure. In the present scenario, a reference microphone (e.g., the keybed microphone) records the sounds made by key strikes directly, and uses this as an auxiliary audio stream to aid the restoration of the primary voice channel. Also available are synchronized recordings sampled at 44.1 kHz of the voice microphone waveform, XV and the keybed microphone waveform, XK. The keybed microphone is placed below the keyboard in the body of the user device, and is acoustically insulated from the surrounding environment. The signal captured by the keybed microphone may be reasonably assumed to contain very little of the desired speech and ambient noise, and thus serves as a good reference recording of the contaminating keystroke noise. From this point forward, it may be assumed that the audio data has been transformed into a time-frequency domain using any suitable method known to those skilled in the art (e.g., the short-time Fourier Transform (STFT)). For example, in the case of the STFT, XV,j,t and XK,j,t will represent complex frequency coefficients at some frequency bin j and time frame t (although in the following description these indices may be omitted where no ambiguity is introduced as a result).
- Modelling and Inference
- One approach may model the voice waveform assuming a linear transfer function Hj at frequency bin j between the reference microphone and the voice microphone, and assuming that no speech contaminates the keybed microphone:
-
X V,j =V j +H j X K,j, - omitting the time frame index, where V is the desired voice signal and H is the transfer function from the measured keybed microphone XK to the voice microphone. However, this formulation presents some difficult issues. For example, keystrokes from different keys will have different transfer functions, meaning that either a large library of transfer functions will need to be learned for each key, or the system will need to be very rapidly adaptive when a new key is pressed. In addition, significant random differences have been observed in experimentally measured transfer functions from a real system between repeated key strikes on the same key. One possible explanation for these significant differences is that they are caused by non-linear “rattle”-type oscillations that are set up in typical hardware systems.
- Therefore, while a linear transfer function approach may be useful in certain limited scenarios, such an approach is unable to completely remove the effects of keystroke disturbances in the majority of instances.
- In view of the issues described above, the present disclosure provides a robust signal-based approach, in which the random perturbations and nonlinearities in the transfer function are modelled as random effects in measured keystroke waveform K at the voice microphone:
-
X V,j =V j +K j, (1) - where V is the desired voice signal and K is the undesired key click.
- Robust Model and Prior Distributions
- In accordance with at least one embodiment of the present disclosure, statistical models may be formulated for both the voice and keyboard signals in the frequency domain. These models exhibit the known characteristics of speech signals in the time-frequency domain (e.g., sparsity and heavy-tailed (non-Gaussian) behavior). Vj is modeled as a conditional complex normal distribution with random variance that is distributed as an inverted gamma distribution, which is known to be equivalent to modelling Vj as a heavy-tailed Student-t distribution,
- where ˜ denotes that a random variable is drawn according to the distribution to the right, NC is the complex normal distribution and IG is the inverted-gamma distribution. The prior parameters (αV, βV) are tuned to match the spectral variability of speech and/or the previous estimated speech spectra from earlier frames, which will be described in greater detail below. Such a model has been found effective in a number of audio enhancement/separation domains, and is in contrast with other Gaussian or non-Gaussian statistical speech models known those skilled in the art.
- In accordance with one or more embodiments described herein, the keyboard component K is decomposed also in terms of a heavy-tailed distribution, but with its scaling regressed on the secondary reference channel XK,j:
- with α being a random variable that scales the whole spectrum by a random gain factor (it should be noted that in cases where an approximate spectral shape is known for the scaling (e.g., fj), which might, for example, be a low-pass filter response, the approximate spectral shape may be incorporated throughout the following simply by replacing α with αfj):
- The following conditional independence assumptions about the prior distributions may be made: (i) all voice and keyboard components, V and K, respectively, are drawn independently across frequencies and time conditional upon their scaling parameters σV/K; (ii) these scaling parameters are independently drawn from the above prior structures condition upon the overall gain factor α; and (iii) all of these components are a priori independent of the value of the input regressor variable XK. These assumptions are reasonable in most cases and simplify the form of the probability distributions.
- The methods and systems of the present disclosure are at least partially motivated by the observation that the frequency response between keybed microphone and voice microphone has an approximately constant gain magnitude response across frequencies (this is modelled as the unknown gain α, but subject to random perturbations of both amplitude and phase (modelled by the IG distribution on σK,j 2)). In order to remove an obvious scaling ambiguity in the product α2σK,j 2, the prior maximum of σK,j 2 may be set to unity. The remaining prior values may be tuned to match the observed characteristics of the real recorded datasets, which is described in greater detail below.
- In accordance with one or more embodiments, the methods and systems described herein aim to estimate the desired voice signal (Vj) based on the observed signals XV and XK. As such, a suitable object for inference is the posterior distribution,
-
p(P|X V ,X K)=∫α,σK ,σV p(V,α,σ K,σV |X V ,X K)dαdσ K dσ V, - where (oσK, σV) is the collection of scale parameters {σK,j, σV,j} across all frequency bins j in the current time frame. From the posterior distribution, the expected value E [V|XV, XK] for a MMSE (minimum mean square error) estimation scheme may be extracted, or some other estimate (e.g., based on a perceptual cost function) obtained in a manner known to those skilled in the art. Such expectations are often handled using, for example, Bayesian Monte Carlo methods. However, because Monte Carlo schemes are likely to render the processing non-real-time, the methods and systems provided herein avoid the use of such techniques. Instead, in accordance with one or more embodiments, the methods and systems of the present disclosure utilize a MAP (Maximum-a-Posteriori) estimation using a generalized Expectation-Maximization (EM) algorithm:
-
{circumflex over (V)},{circumflex over (α)}=argmaxV,α p(V,α|X V ,V K), - where α is included in the optimization to avoid an extra numerical integration.
- Development of EM Algorithm
- In the EM algorithm, latent variables to be integrated out are first defined. In the present model, such latent variables include (σK, σV). The algorithm then operates iteratively, starting with an initial estimate (V0, α0). At iteration i, an expectation Q of the complete data log-likelihood may be computed as follows (it should be noted that the following is the Bayesian formulation of EM in which a prior distribution is included for the unknowns V and α):
-
Q((V,α),(V (i),α(i)))=E[log(p((V,α)|X K ,X V,σV,σK))|(V (i),α(i))], - where (V(i)), α(i)) is the ith iteration estimate of (V, α). The expectation is taken with respect to p(σV, σK|α(i), V(i), XK, XV), which simplifies under the conditional independence assumptions (described above) to
-
- where Kj (i)=XV,j−V(i) is the current estimate of the unwanted keystroke coefficient at frequency j.
- Where the conditional independence assumptions are applied, the log-conditional distribution may be expanded over frequency bins j using Bayes' Theorem as follows:
-
- where the notation ± is understood to mean “left-hand side (LHS)=right-hand side (RHS) up to an additive constant,” which, in the present case, is a constant that does not depend on (V, α).
- The expectation portion of the algorithm thus simplifies to the following:
-
- where the expectations Eα, EV
j , and EKj are defined from the line above. The log-likelihood term and prior estimate for Vj may now be obtained from equations (1), (2), and (3) (presented above), leading to the following expressions for the expectations Eα, EVj , and EKj : -
- Now, consider
-
- Under the conjugate choice of prior density, as in equation (2), and again making use of the conditional independence assumptions, as in equation (5),
-
- Therefore, at the ith iteration:
-
- which is the mean of the corresponding gamma distribution for 1/σV
j 2. In accordance with at least one embodiment, for prior mixing distributions other than the simplest inverted-gamma, this expectation may be computed numerically and stored, for example, in a look-up table. - By similar reasoning, the conditional distribution for σK
j 2 in equation (5) may be obtained as: -
- Therefore, at the ith iteration:
-
- Substituting the computed expectations into Q, the maximization portion of the algorithm maximizes Q jointly with respect to (V, α). Because of the complex structure of the model, such maximization is difficult to achieve in closed form for this Q function. Instead, in accordance with one or more embodiments described herein, the method of the present disclosure utilizes iterative formulae for maximizing V with a fixed, then maximizing α with V fixed at the new value, and repeating this several times within each EM iteration. Such an approach is a generalized EM, which, similar to standard EM, guarantees convergence to a maximum of the probability surface, since each iteration is guaranteed to increase the probability of the current iteration's estimate (e.g., this could be a local maximum, just like for standard EM). Therefore, the generalized EM algorithm described herein guarantees that the posterior probability is non-decreasing at each iteration, and thus can be expected to converge to the true MAP solution with increasing iteration number.
- Omitting (for purposes of brevity) the algebraic steps in finding the maxima of Q with respect to V and α, the following maximization step updates may be arrived at. Notation is such that the generalized maximization step may be initialized at each iteration with Vj (i+1)=Vj (i), Kj (i+1)=XV,j−Vj (i), and αi+1)=α(i), the final values from the previous iteration, and iterating the following fixed point equations several times, which refine the estimates at the new iteration i+1. It should be noted that the update for Vj may be considered a Weiner filter gain, which is applied independently and in parallel for all frequencies j=1, . . . , J,
-
- and for α:
-
- where J is the total number of frequency bins.
- Once the EM process described above has run for a number of iterations, and is satisfactorily converged, the resulting spectral components Vj may be transformed back to the time domain (e.g., via the inverse fast Fourier transform (FFT) in the short time Fourier transform (STFT) case) and reconstructed into a continuous signal by windowed overlap-add procedures.
- To further illustrate the various features of the signal restoration methods and systems of the present disclosure, the following describes some example results that may be obtained through experimentation. It should be understood that although the following provides example performance results in the context of a laptop computer containing an auxiliary microphone located beneath the keyboard, the scope of the present disclosure is not limited to this particular context or implementation. Instead, similar levels of performance may also be achieved using the methods and systems of the present disclosure in various other contexts and/or scenarios involving other types of user devices, including, for example, where the auxiliary microphone is at a location on the user device other than beneath the keyboard (but not at the same or similar location as one or more primary microphones of the device).
- The present example is based on audio files recorded from a laptop computer containing at least one primary microphone (e.g., voice microphone) and also an auxiliary microphone located beneath the keyboard (e.g., keybed microphone). Sampling is performed synchronously at 44.1 kHz from the voice and keybed microphones, and processing carried out using a generalized EM algorithm. Frame lengths of 1024 samples may be used for an STFT transform, with 50% overlap and Hanning analysis windows.
- In the present example, it is possible to record extracts of voice alone, and then of key strokes alone, and then add together the signals recorded in order to obtain corrupted microphone signals for which “ground truth” restorations are available. Prior parameters for the Bayesian model may be fixed as follows:
- (1) Prior σV,j 2˜IG(αV, βV,j) (it should be noted that the scale parameter βV is made explicitly frequency-dependent). The degrees of freedom are fixed to αV=4 in order to allow a degree of flexibility and heavy-tailed behavior in the voice signal. The parameter βV,j may be set in a frequency-dependent manner as follows: (i) the final EM-estimated voice signal from the previous frame, |{circumflex over (V)}j|2, is used to give a prior estimate of σV,j 2 for the current frame; and (ii) βV,j is then fixed such that the mode of the IG distribution is equal to |{circumflex over (V)}j|2, for example, by setting βV,j =|{circumflex over (V)} j|2 (αV+1). This encourages some spectral continuity from previous frames, which reduces artifacts in the processed audio, and also allows for some reconstruction of heavily corrupted frames based on what has gone before.
- (2) Prior σK,j 2˜IG(αK, βK). This may be fixed across all frequencies to αK=3, βK=3, leading to a mode at σK,j 2=0.75.
- (3) Prior α˜IG(αα, βα): αα=4, βα=100,000 (αα +1), which places the prior mode for α2 at 100,000, which is tuned by hand from experimental analysis of data recorded with just keystroke noise present.
- In the present example, it is determined from testing various configurations for the EM that results converge with little further improvement after approximately ten iterations, with two sub-iterations of the generalized maximization-step of equations (6) and (7) per full EM iteration. These parameters may then be fixed for all subsequent simulations.
- It is important to note that, in accordance with one or more embodiments described herein, a time-domain detector may be devised to flag corrupted frames, and processing may only be applied to frames for which detection was flagged, therefore avoiding unnecessary signal distortions and wasted computations through processing in uncorrupted frames. In at least the present example, the time-domain detector comprises a rule-based combination of detections from the keybed microphone signal and two available (stereo) voice microphones. Within each audio stream, detections are based on an autoregressive (AR) error signal, and frames are flagged as corrupted when the maximum error magnitude exceeds a certain factor of the median error magnitude for that frame.
- Performance may be evaluated using an average segmental signal-to-noise (SNR) measure,
-
- where vt,n is the true, uncorrupted, voice signal at the ith sample of the nth frame, and {circumflex over (v)} is the corresponding estimate of v. Performance is compared against a straightforward procedure which mutes the spectral components to zero in frames that are detected as corrupted.
- Results illustrate an improvement on average of approximately 3 dB when taken over the whole speech extract, and 6-10 dB when inducing just the frames detected as corrupted. These example results may be adjusted by tuning the prior parameters to trade-off perceived signal distortion against suppression levels of the noise. Although these example results may appear to be relatively small improvements, the perceptual effect of the EM approach, as used in accordance with the methods and systems of the present disclosure, is significantly improved compared with muting the signal and compared with the corrupted input audio.
-
FIG. 4 illustrates an example detection and restoration in accordance with one or more embodiments described herein. In all threegraphical representations one waveform 440. These example detections agree with a visual study of the keyclick data waveform. -
Graphical representation 410 shows the corrupted input from the voice microphone,graphical representation 420 shows the restored output from the voice microphone, andgraphical representation 430 shows the original voice signal without any corruption (available in the present example as “ground-truth”). It should be noted that ingraphical representation 420, the speech envelope and speech events are preserved around 125 k samples and 140 k samples, while the disturbance is suppressed well around 105 k samples. It can be seen from the example performance results that the audio is significantly improved in the restoration, leaving very little “click” residue, which can be removed by various post-processing techniques known to those skilled in the art. In the present example, a favorable 10.1 dB improvement in segmental SNR is obtained for corrupted frames (as compared to using a “muting restoration”), and 2.5 dB improvement when all frames are considered (including the uncorrupted frames). -
FIG. 5 is a high-level block diagram of an exemplary computer (500) arranged for suppressing transient noise in an audio signal by incorporating an auxiliary microphone input signal as a reference signal, according to one or more embodiments described herein. In accordance with at least one embodiment, the computer (500) may be configured to utilize spatial selectivity to separate direct and reverberant energy and account for noise separately, thereby considering the response of the beamformer to reverberant sound and the effect of noise. In a very basic configuration (501), the computing device (500) typically includes one or more processors (510) and system memory (520). A memory bus (530) can be used for communicating between the processor (510) and the system memory (520). - Depending on the desired configuration, the processor (510) can be of any type including but not limited to a microprocessor (μP), a microcontroller (μC), a digital signal processor (DSP), or any combination thereof. The processor (510) can include one more levels of caching, such as a level one cache (511) and a level two cache (512), a processor core (513), and registers (514). The processor core (513) can include an arithmetic logic unit (ALU), a floating point unit (FPU), a digital signal processing core (DSP Core), or any combination thereof. A memory controller (515) can also be used with the processor (510), or in some implementations the memory controller (515) can be an internal part of the processor (510).
- Depending on the desired configuration, the system memory (520) can be of any type including but not limited to volatile memory (such as RAM), non-volatile memory (such as ROM, flash memory, etc.) or any combination thereof. System memory (520) typically includes an operating system (521), one or more applications (522), and program data (524). The application (522) may include Signal Restoration Algorithm (823) for suppressing transient noise in an audio signal containing voice data by using information about the transient noise received from a reference (e.g., auxiliary) microphone located in close proximity to the source of the transient noise, in accordance with one or more embodiments described herein. Program Data (524) may include storing instructions that, when executed by the one or more processing devices, implement a method for suppressing transient noise by using a statistical model to map a reference microphone onto a voice microphone (e.g.,
auxiliary microphone 115 andvoice microphone 110 in theexample system 100 shown inFIG. 1 ) so that information about a transient noise from the reference microphone can be used to estimate a contribution of the transient noise in the signal captured by the voice microphone, according to one or more embodiments described herein. - Additionally, in accordance with at least one embodiment, program data (824) may include reference signal data (525), which may include data (e.g., spectrum-amplitude data) about a transient noise measured by a reference microphone (e.g.,
reference microphone 115 in theexample system 100 shown inFIG. 1 ). In some embodiments, the application (522) can be arranged to operate with program data (524) on an operating system (521). - The computing device (500) can have additional features or functionality, and additional interfaces to facilitate communications between the basic configuration (501) and any required devices and interfaces.
- System memory (520) is an example of computer storage media. Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, digital versatile disks (DVD) or other optical storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can be accessed by computing
device 500. Any such computer storage media can be part of the device (500). - The computing device (500) can be implemented as a portion of a small-form factor portable (or mobile) electronic device such as a cell phone, a smart phone, a personal data assistant (PDA), a personal media player device, a tablet computer (tablet), a wireless web-watch device, a personal headset device, an application-specific device, or a hybrid device that include any of the above functions. The computing device (500) can also be implemented as a personal computer including both laptop computer and non-laptop computer configurations.
- The foregoing detailed description has set forth various embodiments of the devices and/or processes via the use of block diagrams, flowcharts, and/or examples. Insofar as such block diagrams, flowcharts, and/or examples contain one or more functions and/or operations, it will be understood by those within the art that each function and/or operation within such block diagrams, flowcharts, or examples can be implemented, individually and/or collectively, by a wide range of hardware, software, firmware, or virtually any combination thereof. In accordance with at least one embodiment, several portions of the subject matter described herein may be implemented via Application Specific Integrated Circuits (ASICs), Field Programmable Gate Arrays (FPGAs), digital signal processors (DSPs), or other integrated formats. However, those skilled in the art will recognize that some aspects of the embodiments disclosed herein, in whole or in part, can be equivalently implemented in integrated circuits, as one or more computer programs running on one or more computers, as one or more programs running on one or more processors, as firmware, or as virtually any combination thereof, and that designing the circuitry and/or writing the code for the software and or firmware would be well within the skill of one of skill in the art in light of the present disclosure.
- In addition, those skilled in the art will appreciate that the mechanisms of the subject matter described herein are capable of being distributed as a program product in a variety of forms, and that an illustrative embodiment of the subject matter described herein applies regardless of the particular type of non-transitory signal bearing medium used to actually carry out the distribution. Examples of a non-transitory signal bearing medium include, but are not limited to, the following: a recordable type medium such as a floppy disk, a hard disk drive, a Compact Disc (CD), a Digital Video Disk (DVD), a digital tape, a computer memory, etc.; and a transmission type medium such as a digital and/or an analog communication medium (e.g., a fiber optic cable, a waveguide, a wired communications link, a wireless communication link, etc.).
- With respect to the use of substantially any plural and/or singular terms herein, those having skill in the art can translate from the plural to the singular and/or from the singular to the plural as is appropriate to the context and/or application. The various singular/plural pet mutations may be expressly set forth herein for sake of clarity.
- Thus, particular embodiments of the subject matter have been described. Other embodiments are within the scope of the following claims. In some cases, the actions recited in the claims can be performed in a different order and still achieve desirable results. In addition, the processes depicted in the accompanying figures do not necessarily require the particular order shown, or sequential order, to achieve desirable results. In certain implementations, multitasking and parallel processing may be advantageous.
Claims (20)
Priority Applications (6)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/591,418 US10755726B2 (en) | 2015-01-07 | 2015-01-07 | Detection and suppression of keyboard transient noise in audio streams with auxiliary keybed microphone |
CN202010781730.5A CN112071327A (en) | 2015-01-07 | 2015-12-30 | Keyboard transient noise detection and suppression in audio streams with auxiliary keybed microphones |
EP15828807.6A EP3243202A1 (en) | 2015-01-07 | 2015-12-30 | Detection and suppression of keyboard transient noise in audio streams with auxiliary keybed microphone |
PCT/US2015/068045 WO2016111892A1 (en) | 2015-01-07 | 2015-12-30 | Detection and suppression of keyboard transient noise in audio streams with auxiliary keybed microphone |
CN201580072765.9A CN107113521B (en) | 2015-01-07 | 2015-12-30 | Keyboard transient noise detection and suppression in audio streams with auxiliary keybed microphones |
US16/934,801 US11443756B2 (en) | 2015-01-07 | 2020-07-21 | Detection and suppression of keyboard transient noise in audio streams with aux keybed microphone |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/591,418 US10755726B2 (en) | 2015-01-07 | 2015-01-07 | Detection and suppression of keyboard transient noise in audio streams with auxiliary keybed microphone |
Related Child Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US16/934,801 Continuation US11443756B2 (en) | 2015-01-07 | 2020-07-21 | Detection and suppression of keyboard transient noise in audio streams with aux keybed microphone |
Publications (2)
Publication Number | Publication Date |
---|---|
US20160196833A1 true US20160196833A1 (en) | 2016-07-07 |
US10755726B2 US10755726B2 (en) | 2020-08-25 |
Family
ID=55237909
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US14/591,418 Active 2037-03-07 US10755726B2 (en) | 2015-01-07 | 2015-01-07 | Detection and suppression of keyboard transient noise in audio streams with auxiliary keybed microphone |
US16/934,801 Active 2035-01-19 US11443756B2 (en) | 2015-01-07 | 2020-07-21 | Detection and suppression of keyboard transient noise in audio streams with aux keybed microphone |
Family Applications After (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US16/934,801 Active 2035-01-19 US11443756B2 (en) | 2015-01-07 | 2020-07-21 | Detection and suppression of keyboard transient noise in audio streams with aux keybed microphone |
Country Status (4)
Country | Link |
---|---|
US (2) | US10755726B2 (en) |
EP (1) | EP3243202A1 (en) |
CN (2) | CN107113521B (en) |
WO (1) | WO2016111892A1 (en) |
Cited By (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10468020B2 (en) * | 2017-06-06 | 2019-11-05 | Cypress Semiconductor Corporation | Systems and methods for removing interference for audio pattern recognition |
US10667069B2 (en) | 2016-08-31 | 2020-05-26 | Dolby Laboratories Licensing Corporation | Source separation for reverberant environment |
CN111696568A (en) * | 2020-06-16 | 2020-09-22 | 中国科学技术大学 | Semi-supervised transient noise suppression method |
EP3770907A1 (en) * | 2019-07-23 | 2021-01-27 | Bose Corporation | Systems and methods for estimating noise |
Families Citing this family (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10755726B2 (en) * | 2015-01-07 | 2020-08-25 | Google Llc | Detection and suppression of keyboard transient noise in audio streams with auxiliary keybed microphone |
CN108899043A (en) * | 2018-06-15 | 2018-11-27 | 深圳市康健助力科技有限公司 | The research and realization of digital deaf-aid instantaneous noise restrainable algorithms |
KR102570384B1 (en) * | 2018-12-27 | 2023-08-25 | 삼성전자주식회사 | Home appliance and method for voice recognition thereof |
KR102277952B1 (en) * | 2019-01-11 | 2021-07-19 | 브레인소프트주식회사 | Frequency estimation method using dj transform |
US11875811B2 (en) * | 2021-12-09 | 2024-01-16 | Lenovo (United States) Inc. | Input device activation noise suppression |
CN117202077B (en) * | 2023-11-03 | 2024-03-01 | 恩平市海天电子科技有限公司 | Microphone intelligent correction method |
Citations (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20070055508A1 (en) * | 2005-09-03 | 2007-03-08 | Gn Resound A/S | Method and apparatus for improved estimation of non-stationary noise for speech enhancement |
Family Cites Families (24)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6940540B2 (en) * | 2002-06-27 | 2005-09-06 | Microsoft Corporation | Speaker detection and tracking using audiovisual data |
KR100677126B1 (en) * | 2004-07-27 | 2007-02-02 | 삼성전자주식회사 | Apparatus and method for eliminating noise |
US20060083322A1 (en) * | 2004-10-15 | 2006-04-20 | Desjardins Philip | Method and apparatus for detecting transmission errors for digital subscriber lines |
US8019089B2 (en) | 2006-11-20 | 2011-09-13 | Microsoft Corporation | Removal of noise, corresponding to user input devices from an audio signal |
US7626889B2 (en) * | 2007-04-06 | 2009-12-01 | Microsoft Corporation | Sensor array post-filter for tracking spatial distributions of signals and noise |
NO328622B1 (en) * | 2008-06-30 | 2010-04-06 | Tandberg Telecom As | Device and method for reducing keyboard noise in conference equipment |
US8213635B2 (en) | 2008-12-05 | 2012-07-03 | Microsoft Corporation | Keystroke sound suppression |
GB0919672D0 (en) * | 2009-11-10 | 2009-12-23 | Skype Ltd | Noise suppression |
EP2362381B1 (en) * | 2010-02-25 | 2019-12-18 | Harman Becker Automotive Systems GmbH | Active noise reduction system |
EP2405634B1 (en) * | 2010-07-09 | 2014-09-03 | Google, Inc. | Method of indicating presence of transient noise in a call and apparatus thereof |
KR101176207B1 (en) * | 2010-10-18 | 2012-08-28 | (주)트란소노 | Audio communication system and method thereof |
US8577057B2 (en) * | 2010-11-02 | 2013-11-05 | Robert Bosch Gmbh | Digital dual microphone module with intelligent cross fading |
US8311817B2 (en) * | 2010-11-04 | 2012-11-13 | Audience, Inc. | Systems and methods for enhancing voice quality in mobile device |
EP2715972B1 (en) * | 2011-05-31 | 2016-02-24 | Google, Inc. | Muting participants in a communication session |
US9286907B2 (en) * | 2011-11-23 | 2016-03-15 | Creative Technology Ltd | Smart rejecter for keyboard click noise |
US20130253923A1 (en) * | 2012-03-21 | 2013-09-26 | Her Majesty The Queen In Right Of Canada, As Represented By The Minister Of Industry | Multichannel enhancement system for preserving spatial cues |
US9282405B2 (en) * | 2012-04-24 | 2016-03-08 | Polycom, Inc. | Automatic microphone muting of undesired noises by microphone arrays |
US9966067B2 (en) * | 2012-06-08 | 2018-05-08 | Apple Inc. | Audio noise estimation and audio noise reduction using multiple microphones |
US8989815B2 (en) * | 2012-11-24 | 2015-03-24 | Polycom, Inc. | Far field noise suppression for telephony devices |
CN103886863A (en) * | 2012-12-20 | 2014-06-25 | 杜比实验室特许公司 | Audio processing device and audio processing method |
US9520141B2 (en) * | 2013-02-28 | 2016-12-13 | Google Inc. | Keyboard typing detection and suppression |
US9633670B2 (en) * | 2013-03-13 | 2017-04-25 | Kopin Corporation | Dual stage noise reduction architecture for desired signal extraction |
US8867757B1 (en) | 2013-06-28 | 2014-10-21 | Google Inc. | Microphone under keyboard to assist in noise cancellation |
US10755726B2 (en) * | 2015-01-07 | 2020-08-25 | Google Llc | Detection and suppression of keyboard transient noise in audio streams with auxiliary keybed microphone |
-
2015
- 2015-01-07 US US14/591,418 patent/US10755726B2/en active Active
- 2015-12-30 EP EP15828807.6A patent/EP3243202A1/en not_active Withdrawn
- 2015-12-30 CN CN201580072765.9A patent/CN107113521B/en active Active
- 2015-12-30 CN CN202010781730.5A patent/CN112071327A/en active Pending
- 2015-12-30 WO PCT/US2015/068045 patent/WO2016111892A1/en active Application Filing
-
2020
- 2020-07-21 US US16/934,801 patent/US11443756B2/en active Active
Patent Citations (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20070055508A1 (en) * | 2005-09-03 | 2007-03-08 | Gn Resound A/S | Method and apparatus for improved estimation of non-stationary noise for speech enhancement |
Cited By (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10667069B2 (en) | 2016-08-31 | 2020-05-26 | Dolby Laboratories Licensing Corporation | Source separation for reverberant environment |
US10904688B2 (en) | 2016-08-31 | 2021-01-26 | Dolby Laboratories Licensing Corporation | Source separation for reverberant environment |
US10468020B2 (en) * | 2017-06-06 | 2019-11-05 | Cypress Semiconductor Corporation | Systems and methods for removing interference for audio pattern recognition |
EP3770907A1 (en) * | 2019-07-23 | 2021-01-27 | Bose Corporation | Systems and methods for estimating noise |
CN111696568A (en) * | 2020-06-16 | 2020-09-22 | 中国科学技术大学 | Semi-supervised transient noise suppression method |
Also Published As
Publication number | Publication date |
---|---|
CN112071327A (en) | 2020-12-11 |
CN107113521A (en) | 2017-08-29 |
WO2016111892A1 (en) | 2016-07-14 |
US10755726B2 (en) | 2020-08-25 |
CN107113521B (en) | 2020-08-21 |
US20200349964A1 (en) | 2020-11-05 |
US11443756B2 (en) | 2022-09-13 |
EP3243202A1 (en) | 2017-11-15 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US11443756B2 (en) | Detection and suppression of keyboard transient noise in audio streams with aux keybed microphone | |
CN108615535B (en) | Voice enhancement method and device, intelligent voice equipment and computer equipment | |
Balaji et al. | Combining statistical models using modified spectral subtraction method for embedded system | |
Martin | Bias compensation methods for minimum statistics noise power spectral density estimation | |
Smaragdis et al. | Missing data imputation for time-frequency representations of audio signals | |
AU2015240992B2 (en) | Situation dependent transient suppression | |
US9607627B2 (en) | Sound enhancement through deverberation | |
Cohen | Speech enhancement using super-Gaussian speech models and noncausal a priori SNR estimation | |
TW201248613A (en) | System and method for monaural audio processing based preserving speech information | |
US9520138B2 (en) | Adaptive modulation filtering for spectral feature enhancement | |
Khaldi et al. | Voiced/unvoiced speech classification‐based adaptive filtering of decomposed empirical modes for speech enhancement | |
Ozerov et al. | Uncertainty-based learning of acoustic models from noisy data | |
US10262680B2 (en) | Variable sound decomposition masks | |
Djendi et al. | Reducing over-and under-estimation of the a priori SNR in speech enhancement techniques | |
CN111696568A (en) | Semi-supervised transient noise suppression method | |
Jassim et al. | Enhancing noisy speech signals using orthogonal moments | |
Ram et al. | Performance analysis of adaptive variational mode decomposition approach for speech enhancement | |
WO2022218254A1 (en) | Voice signal enhancement method and apparatus, and electronic device | |
Godsill et al. | Detection and suppression of keyboard transient noise in audio streams with auxiliary keybed microphone | |
Sharma et al. | Weighted sigmoid-based frequency-selective noise filtering for speech denoising | |
Kantamaneni et al. | Speech enhancement with noise estimation and filtration using deep learning models | |
Zheng et al. | Noise-robust blind reverberation time estimation using noise-aware time–frequency masking | |
Une et al. | Musical-noise-free noise reduction by using biased harmonic regeneration and considering relationship between a priori SNR and sound quality | |
Ibarrola et al. | A Bayesian approach to convolutive nonnegative matrix factorization for blind speech dereverberation | |
Kim et al. | A subspace approach based on embedded prewhitening for voice activity detection |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:SKOGLUND, JAN;GODSILL, SIMON;BUCHNER, HERBERT;SIGNING DATES FROM 20141219 TO 20150106;REEL/FRAME:034670/0352 |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044129/0001Effective date: 20170929 |
|
STCV | Information on status: appeal procedure |
Free format text: ON APPEAL -- AWAITING DECISION BY THE BOARD OF APPEALS |
|
STCV | Information on status: appeal procedure |
Free format text: BOARD OF APPEALS DECISION RENDERED |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: NOTICE OF ALLOWANCE MAILED -- APPLICATION RECEIVED IN OFFICE OF PUBLICATIONS |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: NOTICE OF ALLOWANCE MAILED -- APPLICATION RECEIVED IN OFFICE OF PUBLICATIONS |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: PUBLICATIONS -- ISSUE FEE PAYMENT VERIFIED |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 4TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1551); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 4 |