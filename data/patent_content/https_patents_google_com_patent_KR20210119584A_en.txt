KR20210119584A - Hardware double buffering using a special purpose computational unit - Google Patents
Hardware double buffering using a special purpose computational unit Download PDFInfo
- Publication number
- KR20210119584A KR20210119584A KR1020217030911A KR20217030911A KR20210119584A KR 20210119584 A KR20210119584 A KR 20210119584A KR 1020217030911 A KR1020217030911 A KR 1020217030911A KR 20217030911 A KR20217030911 A KR 20217030911A KR 20210119584 A KR20210119584 A KR 20210119584A
- Authority
- KR
- South Korea
- Prior art keywords
- data
- buffer
- memory
- value
- buffer allocation
- Prior art date
Links
- 230000003139 buffering effect Effects 0.000 title description 13
- 239000000872 buffer Substances 0.000 claims abstract description 296
- 230000015654 memory Effects 0.000 claims abstract description 260
- 238000013500 data storage Methods 0.000 claims abstract description 47
- 238000000034 method Methods 0.000 claims abstract description 35
- 230000005540 biological transmission Effects 0.000 claims description 4
- 230000004044 response Effects 0.000 claims 6
- 238000013528 artificial neural network Methods 0.000 description 17
- 230000008569 process Effects 0.000 description 13
- 238000004364 calculation method Methods 0.000 description 9
- 238000004590 computer program Methods 0.000 description 8
- 239000011159 matrix material Substances 0.000 description 6
- 238000010586 diagram Methods 0.000 description 4
- 238000010801 machine learning Methods 0.000 description 3
- 230000003287 optical effect Effects 0.000 description 3
- 230000004913 activation Effects 0.000 description 2
- 238000003491 array Methods 0.000 description 2
- 238000013527 convolutional neural network Methods 0.000 description 2
- 230000006870 function Effects 0.000 description 2
- 238000000926 separation method Methods 0.000 description 2
- 230000004048 modification Effects 0.000 description 1
- 238000012986 modification Methods 0.000 description 1
- 230000000644 propagated effect Effects 0.000 description 1
- 230000009467 reduction Effects 0.000 description 1
- 239000004065 semiconductor Substances 0.000 description 1
- 239000007787 solid Substances 0.000 description 1
- 239000000758 substrate Substances 0.000 description 1
- 230000009466 transformation Effects 0.000 description 1
- 238000004148 unit process Methods 0.000 description 1
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/06—Digital input from, or digital output to, record carriers, e.g. RAID, emulated record carriers or networked record carriers
- G06F3/0601—Interfaces specially adapted for storage systems
- G06F3/0628—Interfaces specially adapted for storage systems making use of a particular technique
- G06F3/0655—Vertical data movement, i.e. input-output transfer; data movement between one or more hosts and one or more storage devices
- G06F3/0656—Data buffering arrangements
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F12/00—Accessing, addressing or allocating within memory systems or architectures
- G06F12/02—Addressing or allocation; Relocation
- G06F12/0207—Addressing or allocation; Relocation with multidimensional access, e.g. row/column, matrix
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F12/00—Accessing, addressing or allocating within memory systems or architectures
- G06F12/02—Addressing or allocation; Relocation
- G06F12/0223—User address space allocation, e.g. contiguous or non contiguous base addressing
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F12/00—Accessing, addressing or allocating within memory systems or architectures
- G06F12/02—Addressing or allocation; Relocation
- G06F12/08—Addressing or allocation; Relocation in hierarchically structured memory systems, e.g. virtual memory systems
- G06F12/10—Address translation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/06—Digital input from, or digital output to, record carriers, e.g. RAID, emulated record carriers or networked record carriers
- G06F3/0601—Interfaces specially adapted for storage systems
- G06F3/0602—Interfaces specially adapted for storage systems specifically adapted to achieve a particular effect
- G06F3/061—Improving I/O performance
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/06—Digital input from, or digital output to, record carriers, e.g. RAID, emulated record carriers or networked record carriers
- G06F3/0601—Interfaces specially adapted for storage systems
- G06F3/0668—Interfaces specially adapted for storage systems adopting a particular infrastructure
- G06F3/0671—In-line storage system
- G06F3/0683—Plurality of storage devices
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F5/00—Methods or arrangements for data conversion without changing the order or content of the data handled
- G06F5/06—Methods or arrangements for data conversion without changing the order or content of the data handled for changing the speed of data flow, i.e. speed regularising or timing, e.g. delay lines, FIFO buffers; over- or underrun control therefor
- G06F5/08—Methods or arrangements for data conversion without changing the order or content of the data handled for changing the speed of data flow, i.e. speed regularising or timing, e.g. delay lines, FIFO buffers; over- or underrun control therefor having a sequence of storage locations, the intermediate ones not being accessible for either enqueue or dequeue operations, e.g. using a shift register
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/30—Arrangements for executing machine instructions, e.g. instruction decode
- G06F9/30098—Register arrangements
- G06F9/30105—Register structure
- G06F9/30112—Register structure comprising data of variable length
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N20/00—Machine learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/06—Physical realisation, i.e. hardware implementation of neural networks, neurons or parts of neurons
- G06N3/063—Physical realisation, i.e. hardware implementation of neural networks, neurons or parts of neurons using electronic means
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F12/00—Accessing, addressing or allocating within memory systems or architectures
- G06F12/02—Addressing or allocation; Relocation
- G06F12/0215—Addressing or allocation; Relocation with look ahead addressing means
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F2212/00—Indexing scheme relating to accessing, addressing or allocation within memory systems or architectures
- G06F2212/10—Providing a specific technical effect
- G06F2212/1016—Performance improvement
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F2212/00—Indexing scheme relating to accessing, addressing or allocation within memory systems or architectures
- G06F2212/30—Providing cache or TLB in specific location of a processing system
- G06F2212/302—In image processor or graphics adapter
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F2212/00—Indexing scheme relating to accessing, addressing or allocation within memory systems or architectures
- G06F2212/45—Caching of specific data in cache memory
- G06F2212/454—Vector or matrix data
Abstract
방법, 시스템 및 장치로서 다수의 메모리 및 제2 데이터 저장 위치로 전송되는 제1 데이터 저장 위치에 저장된 데이터 엘리먼트들의 시퀀스에 대한 버퍼 메모리 어드레스들을 결정하도록 구성된 하나 이상의 처리 유닛을 포함하는, 다수의 버퍼를 사용하여 데이터를 전송하는 장치를 포함한다. 시퀀스 내의 하나 이상의 데이터 엘리먼트의 각각의 그룹에 대해, 메모리들 중 상이한 하나에 각각 대응하는 다수의 값들 사이에서 스위칭될 수있는 버퍼 할당 엘리먼트의 값이 식별된다. 하나 이상의 데이터 엘리먼트의 그룹에 대한 버퍼 메모리 어드레스는 버퍼 할당 엘리먼트의 값에 기초하여 결정된다. 버퍼 할당 엘리먼트의 값은 데이터 엘리먼트들의 시퀀스의 하나 이상의 데이터 엘리먼트의 후속 그룹에 대한 버퍼 메모리 어드레스를 결정하기 전에 스위칭된다.A method, system and apparatus comprising: a plurality of buffers comprising one or more processing units configured to determine buffer memory addresses for a plurality of memories and a sequence of data elements stored in a first data storage location transferred to a second data storage location It includes devices that use it to transmit data. For each group of one or more data elements in the sequence, a value of a buffer allocation element that can be switched between a plurality of values, each corresponding to a different one of the memories, is identified. The buffer memory address for the group of one or more data elements is determined based on the value of the buffer allocation element. The value of the buffer allocation element is switched prior to determining a buffer memory address for a subsequent group of one or more data elements in the sequence of data elements.
Description
본 명세서는 일반적으로 하드웨어 이중 버퍼를 갖는 특수 목적 연산 유닛을 사용하여 기계 학습 계산을 수행하는 것에 관한 것이다.This specification relates generally to performing machine learning computations using special purpose computational units with hardware double buffers.
신경망은 모델의 하나 이상의 계층을 사용하여 수신된 입력에 대한 출력, 예를 들어 분류를 생성하는 기계 학습 모델이다. 일부 신경 회로망은 외부 계층 외에도 하나 이상의 은닉 계층을 포함한다. 각각의 은닉 계층의 출력은 네트워크의 다음 계층, 즉 다음 은닉 계층 또는 네트워크의 출력 계층으로의 입력으로 사용된다. 네트워크의 각 계층은 개별 파라미터 세트의 현재 값에 따라 수신 입력으로부터 출력을 생성한다.A neural network is a machine learning model that uses one or more layers of the model to generate an output, e.g., a classification, on input received. Some neural networks contain one or more hidden layers in addition to the outer layers. The output of each hidden layer is used as input to the next layer of the network, that is, the next hidden layer or the output layer of the network. Each layer of the network generates an output from its incoming input according to the current values of its individual parameter sets.
일부 신경망은 하나 이상의 컨볼루션 신경망 계층을 포함한다. 각 컨볼루션 신경망 계층에는 관련 커널 세트가 있다. 커널들은 가중치 입력의 행렬 구조로 나타낼 수 있다. 각 컨볼루션 계층는 커널들을 사용하여 계층에 대한 입력을 처리한다. 계층에 대한 입력 세트는 또한 행렬 구조로 표현될 수 있다.Some neural networks include one or more convolutional neural network layers. Each convolutional neural network layer has an associated set of kernels. Kernels can be represented as a matrix structure of weighted inputs. Each convolutional layer uses kernels to process the input to the layer. The input set to a layer may also be represented as a matrix structure.
본 명세서는 N 차원 텐서의 이중 버퍼링 데이터를 위한 특수 목적 연산 유닛을 사용하는 것에 관한 기술을 설명한다.This specification describes a technique for using a special purpose arithmetic unit for double-buffered data of an N-dimensional tensor.
일반적으로, 본 명세서에서 기술된 주제의 하나의 혁신적인 양태는 데이터를 전송(transfer)하기 위한 장치에서 구현될 수 있다. 상기 장치는 적어도 제1 메모리 및 제2 메모리를 포함하는 다수의 메모리를 포함할 수 있다. 상기 장치는 또한 하나 이상의 처리 유닛을 포함할 수 있다. 하나 이상의 처리 유닛은 제2 데이터 저장 위치로 전송되는 제1 데이터 저장 위치에 저장된 데이터 엘리먼트들의 시퀀스에 대한 버퍼 메모리 어드레스들을 결정하도록 구성될 수 있다. 시퀀스 내의 하나 이상의 데이터 엘리먼트들의 각 그룹에 대해, 하나 이상의 처리 유닛은 메모리들 중 상이한 하나에 각각 대응하는 다수의 값들 간에 스위칭될 수 있는 버퍼 할당 엘리먼트의 값을 식별할 수 있다. 하나 이상의 처리 유닛은 버퍼 할당 엘리먼트의 값에 기초하여 하나 이상의 데이터 엘리먼트들의 그룹에 대한 버퍼 메모리 어드레스를 결정할 수 있다. 상기 버퍼 할당 엘리먼트의 값이 상기 제1 메모리에 대응하는 제1 값일 때, 하나 이상의 처리 유닛은 제1 메모리에 대한 베이스 어드레스와 하나 이상의 데이터 엘리먼트의 그룹에 대한 메모리 오프셋 값의 조합에 기초하여 상기 하나 이상의 데이터 엘리먼트의 그룹에 대한 상기 버퍼 메모리 어드레서를 결정함으로써 제1 메모리에 하나 이상의 데이터 엘리먼트의 그룹을 할당할 수 있다. 상기 버퍼 할당 엘리먼트의 값이 제1 값과 상이한 제2 값이고 제2 메모리에 대응할 때, 하나 이상의 처리 유닛은 제1 메모리에 대한 베이스 어드레스, 제2 메모리에 대한 메모리 어드레스 오프셋 값 및 하나 이상의 데이터 엘리먼트의 그룹을 제2 메모리에 할당하기 위한 하나 이상의 데이터 엘리먼트의 그룹에 대한 메모리 오프셋 값의 조합에 기초하여, 상기 하나 이상의 데이터 엘리먼트의 그룹에 대한 메모리 어드레스를 결정함으로써 제2 메모리에 데이터 엘리먼트를 할당할 수 있다. 하나 이상의 처리 유닛은 데이터 엘리먼트들의 시퀀스의 하나 이상의 데이터 엘리먼트의 후속 그룹에 대한 버퍼 메모리 어드레스를 결정하기 전에 상기 버퍼 할당 엘리먼트의 값을 스위칭할 수 있다. 하나 이상의 처리 유닛은 하나 이상의 데이터 엘리먼트의 각 그룹에 대해 상기 결정된 버퍼 메모리 어드레스를 사용하여 제1 또는 제2 메모리의 각각의 메모리 위치로 각 데이터 엘리먼트를 전송할 수 있다.In general, one innovative aspect of the subject matter described herein may be implemented in an apparatus for transferring data. The device may include a plurality of memories including at least a first memory and a second memory. The apparatus may also include one or more processing units. The one or more processing units may be configured to determine buffer memory addresses for the sequence of data elements stored at the first data storage location that is transferred to the second data storage location. For each group of one or more data elements in the sequence, the one or more processing units may identify a value of the buffer allocation element that may be switched between multiple values, each corresponding to a different one of the memories. The one or more processing units may determine a buffer memory address for the group of one or more data elements based on the value of the buffer allocation element. When the value of the buffer allocation element is a first value corresponding to the first memory, the one or more processing units are configured to configure the one or more processing units to configure the one or more processing units based on a combination of a base address for the first memory and a memory offset value for a group of one or more data elements. The group of one or more data elements may be allocated to the first memory by determining the buffer memory address for the group of one or more data elements. When the value of the buffer allocation element is a second value different from the first value and corresponds to a second memory, the one or more processing units configure the base address for the first memory, the memory address offset value for the second memory, and the one or more data elements. to allocate a data element to the second memory by determining a memory address for the group of one or more data elements based on a combination of memory offset values for the group of one or more data elements for allocating the group of data elements to the second memory. can The one or more processing units may switch the value of the buffer allocation element before determining a buffer memory address for a subsequent group of one or more data elements in the sequence of data elements. The one or more processing units may transfer each data element to a respective memory location in the first or second memory using the determined buffer memory address for each group of one or more data elements.
이들 및 다른 구현예는 각각 선택적으로 다음 특징들 중 하나 이상을 포함할 수 있다. 일부 양태들에서, 제1 메모리 및 제2 메모리는 각각 제1 데이터 저장 용량을 갖는 버퍼이다. 제1 데이터 저장 위치 및 제2 데이터 저장 위치는 각각 제1 데이터 저장 용량보다 큰 제2 데이터 저장 용량을 적어도 포함할 수 있다.Each of these and other embodiments may optionally include one or more of the following features. In some aspects, the first memory and the second memory are each a buffer having a first data storage capacity. The first data storage location and the second data storage location may each include at least a second data storage capacity greater than the first data storage capacity.
일부 양태에서, 제1 메모리 및 제2 메모리는 각각 제1 데이터 저장 용량을 갖는 버퍼들이다. 상기 데이터 엘리먼트들의 시퀀스는 제1 데이터 저장 용량을 초과하는 데이터 량을 포함할 수 있다.In some aspects, the first memory and the second memory are buffers each having a first data storage capacity. The sequence of data elements may include an amount of data that exceeds a first data storage capacity.
일부 양태에서, 버퍼 할당 엘리먼트의 값 및 제2 메모리에 대한 메모리 어드레스 오프셋 값에 기초하여 하나 이상의 데이터 엘리먼트의 그룹에 대한 버퍼 메모리 어드레스를 결정하는 단계는, 데이터 엘리먼트들의 시퀀스를 반복하는데 사용된 하나 이상의 루프의 반복 회수에 기초하여 하나 이상의 데이터 엘리먼트의 그룹에 대한 메모리 오프셋 값을 결정하는 단계를 포함할 수 있다. In some aspects, determining the buffer memory address for the group of one or more data elements based on the value of the buffer allocation element and the memory address offset value for the second memory comprises: one or more used to repeat the sequence of data elements. determining a memory offset value for the group of one or more data elements based on the number of iterations of the loop.
일부 양태에서, 버퍼 할당 엘리먼트의 값 및 제2 메모리에 대한 메모리 어드레스 오프셋 값에 기초하여 하나 이상의 데이터 엘리먼트의 그룹에 대한 버퍼 메모리 어드레스를 결정하는 단계는, 버퍼 할당 엘리먼트의 값이 제2 값일 때마다, 하나 이상의 데이터 엘리먼트의 그룹에 대한 버퍼 메모리 어드레스로서, (i) 제1 메모리에 대한 베이스 어드레스, (ii) 제2 메모리에 대한 메모리 어드레스 오프셋 값, (ⅲ) 하나 이상의 데이터 엘리먼트의 그룹에 대한 메모리 오프셋 값을 결정하는 단계를 포함할 수 있다. 상기 버퍼 할당 엘리먼트의 값이 제1 값일 때마다, 하나 이상의 데이터 엘리먼트의 그룹에 대한 버퍼 메모리 어드레스는, (i) 제1 메모리에 대한 베이스 어드레스 및 (ii) 제2 메모리에 대한 메모리 어드레스 값과 독립적인 하나 이상의 데이터 엘리먼트의 그룹에 대한 오프셋 값의 합산에 기초하여 결정될 수 있다. In some aspects, determining the buffer memory address for the group of one or more data elements based on the value of the buffer allocation element and the memory address offset value for the second memory comprises: whenever the value of the buffer allocation element is a second value , a buffer memory address for the group of one or more data elements, comprising (i) a base address for the first memory, (ii) a memory address offset value for the second memory, and (iii) a memory for the group of one or more data elements. determining an offset value. Whenever the value of the buffer allocation element is a first value, the buffer memory addresses for the group of one or more data elements are independent of (i) the base address for the first memory and (ii) the memory address values for the second memory. may be determined based on the summation of offset values for groups of one or more data elements.
일부 양태에서, 하나 이상의 데이터 엘리먼트의 그룹에 대한 메모리 오프셋 값은 상기 N 차원 텐서의 각 차원에 대한 루프의 반복 회수에 기초할 수 있다. 상기 제2 메모리에 대한 상기 메모리 어드레스 오프셋 값은 상기 제2 메모리의 상기 제1 메모리 어드레스의 메모리 어드레스 사이의 차이에 기초할 수 있다In some aspects, a memory offset value for a group of one or more data elements may be based on a number of iterations of a loop for each dimension of the N-dimensional tensor. The memory address offset value for the second memory may be based on a difference between memory addresses of the first memory address of the second memory.
본 명세서에서 기술된 주제는 다음의 이점들 중 하나 이상을 실현하도록 특정 실시예에서 구현될 수 있다. 다수의 메모리를 사용함으로써 단일 버퍼의 저장 용량을 초과하는 데이터를 더 빠르고 효율적으로 전송할 수 있다. 예를 들어, 8 메가 바이트(MB)의 데이터가 제1 데이터 저장 위치에서 제2 데이터 저장 위치로 전송되고 버퍼의 용량은 단지 4MB인 경우, 데이터는 2개의 4MB 버퍼간에 분할될 수 있다. 중첩 루프를 사용하여 다수의 버퍼에 대한 메모리 어드레스를 결정함으로써 어드레스를 결정하기 위한 명령의 수가 줄어들어, 인코딩 밀도가 높아지고 사용되는 메모리 리소스가 줄어 들고 및/또는 필요한 메모리 리소스가 줄어들게 된다. 각각의 버퍼 메모리 어드레스 결정 이후에 값들 사이에서 스위칭되는 버퍼 할당 엘리먼트(예를 들어, 1 비트 토글 카운터)를 사용함으로써 빠른 버퍼 할당 및 감소된 명령 카운트를 가능케 하여 다수의 버퍼에 데이터를 할당할 수 있다. 또한, 제2 버퍼에 데이터를 할당하기 전에 제1 버퍼가 가득 찼는지의 여부를 결정하기 보다, 버퍼 할당 엘리먼트의 값을 스위칭함으로써 처리 속도를 높이고 프로세서에 대한 계산 요구를 줄일 수 있다. 명령의 감소는 처리 유닛이 메모리 어드레스들을 결정하기 위해 더 적은 수의 명령을 처리함에 따라 더 높은 성능을 가져온다. 특수 목적 하드웨어 유닛에서 이중 버퍼 명령어를 인코딩함으로써 프로세서가 데이터를 버퍼에 할당하기 위해 수행하는 계산 사이클 수가 줄어 들어 다른 계산 작업들을 위한 프로세서 대역폭을 증가시킨다. The subject matter described herein may be implemented in certain embodiments to realize one or more of the following advantages. By using multiple memories, data that exceeds the storage capacity of a single buffer can be transferred faster and more efficiently. For example, if 8 megabytes (MB) of data are transferred from the first data storage location to the second data storage location and the capacity of the buffer is only 4MB, the data may be divided between two 4MB buffers. Determining memory addresses for multiple buffers using nested loops reduces the number of instructions to determine addresses, resulting in higher encoding density, fewer memory resources used and/or less memory resources required. The use of a buffer allocation element (e.g., a 1-bit toggle counter) that switches between values after each buffer memory address determination enables fast buffer allocation and reduced instruction count to allocate data to multiple buffers. . In addition, rather than determining whether the first buffer is full before allocating data to the second buffer, switching the value of the buffer allocation element may increase processing speed and reduce computational demands on the processor. The reduction in instruction results in higher performance as the processing unit processes fewer instructions to determine memory addresses. By encoding double-buffered instructions in a special-purpose hardware unit, the number of computational cycles the processor performs to allocate data to a buffer is reduced, increasing processor bandwidth for other computational tasks.
이러한 양태 및 다른 양태의 다른 구현은 대응하는 시스템, 장치 및 컴퓨터 저장 디바이스 상에 인코딩된 방법의 동작을 수행하도록 구성된 컴퓨터 프로그램을 포함한다. 하나 이상의 컴퓨터로 이루어진 시스템은 소프트웨어, 펌웨어, 하드웨어, 또는 이들이 조합으로 구성되어 동작시에 시스템으로 하여금 동작들을 수행하도록 구성될 수 있다. 하나 이상의 컴퓨터 프로그램은 데이터 처리 장치에 의해 실행될 때 상기 장치로 하여금 동작들을 수행하게 하는 명령을 갖도록 구성될 수 있다.Other implementations of these and other aspects include computer programs configured to perform operations of methods encoded on corresponding systems, apparatus, and computer storage devices. A system of one or more computers may be configured in software, firmware, hardware, or a combination thereof to cause the system to perform operations when operated. One or more computer programs may be configured to have instructions that, when executed by a data processing device, cause the device to perform operations.
본 명세서에서 설명된 주제의 하나 이상의 구현의 세부 사항은 첨부된 도면 및 이하의 설명에서 설명된다. 주제의 다른 잠재적인 특징, 양태 및 장점은 상세한 설명, 도면 및 청구 범위로부터 명백해질 것이다.The details of one or more implementations of the subject matter described herein are set forth in the accompanying drawings and the description below. Other potential features, aspects and advantages of the subject matter will become apparent from the detailed description, drawings and claims.
도 1은 예시적인 계산 시스템의 블록도이다.
도 2는 버퍼 및 예시적인 버퍼 할당 엘리먼트를 사용하여 전송되는 예시적인 데이터를 도시한다.
도 3은 이중 버퍼링을 사용하여 데이터를 전송하기 위한 예시적인 프로세스를 나타내는 흐름도이다.
다양한 도면에서 유사한 참조 번호 및 명칭은 동일한 엘리먼트를 나타낸다.1 is a block diagram of an exemplary computational system.
2 illustrates example data transmitted using a buffer and example buffer allocation elements.
3 is a flow diagram illustrating an exemplary process for transmitting data using double buffering.
Like reference numbers and designations in the various drawings indicate like elements.
일반적으로, 소프트웨어 알고리즘이 N 차원 텐서를 처리할 때, 중첩 (nested) 루프가 사용될 수 있다. 각 루프는 N 차원 텐서의 각각의 차원을 탐색 (traverse)하는 역할을 한다. 다차원 텐서는 행렬 또는 다차원 행렬일 수 있다. 예를 들어, 2 차원 텐서는 행렬이고 3 차원 텐서는 다수의 2 차원 행렬로 구성된 3 차원 행렬이다. N 차원 텐서의 각 차원은 하나 이상의 엘리먼트(element)를 포함할 수 있으며, 각 엘리먼트는 개별 데이터 값을 저장할 수 있다. 예를 들어, 텐서는 프로그램의 변수일 수 있는데, 여기서 변수는 3 차원이다. 첫 번째 차원은 300 개의 엘리먼트 길이를 가질 수 있고 두 번째 차원은 1000 개의 엘리먼트 길이를 가질 수 있으며 세 번째 차원은 20 개의 엘리먼트 길이를 가질 수 있다. 물론, 각 차원에서 다른 수의 엘리먼트가 가능하다.In general, when a software algorithm processes N-dimensional tensors, nested loops may be used. Each loop is responsible for traversing each dimension of the N-dimensional tensor. A multidimensional tensor may be a matrix or a multidimensional matrix. For example, a two-dimensional tensor is a matrix and a three-dimensional tensor is a three-dimensional matrix consisting of a number of two-dimensional matrices. Each dimension of the N-dimensional tensor may include one or more elements, and each element may store individual data values. For example, a tensor may be a variable in a program, where the variable is three-dimensional. The first dimension may have a length of 300 elements, the second dimension may have a length of 1000 elements and the third dimension may have a length of 20 elements. Of course, other numbers of elements in each dimension are possible.
중첩 루프에서 텐서를 탐색하는 것은 엘리먼트의 대응 데이터 값을 로드하거나 저장하기 위해 엘리먼트의 메모리 어드레스 값의 계산을 포함할 수 있다. for-loop는 3개의 루프 인덱스 변수(예를 들어, i, j 및 k)에 의해 추적된 3개의 루프를 중첩하여 3 차원 텐서를 통과할 수 있는 중첩 루프의 일 예이다. 신경망에서 엘리먼트의 값은 텐서와 관련된 하나 이상의 내적 계산에 사용될 수 있다. 예를 들어, 엘리먼트 값은 대응 파라미터 또는 가중치로 승산될 수 있다. 상기 텐서의 엘리먼트는 중첩된 for-loops를 사용하여 엘리먼트에 액세스하고 엘리먼트의 값을 사용하여 하나 이상의 계산을 수행하기 위해 순차적으로 탐색될 수 있다. 3 차원 텐서 예를 계속하면, 외부 for-loop는 변수 i에 의해 추적된 루프를 탐색하는데 사용될 수 있고, 중간 for-loop 루프는 변수 j에 의해 추적된 루프를 탐색하는데 사용될 수 있으며, 내부 for 루프는 변수 k에 의해 추적된 루프를 탐색하는데 사용된다. 이 예에서, 액세스되는 제1 엘리먼트는 (i = 0, j = 0, k = 0) 일 수 있고, 제2 엘리먼트는 (i = 0, j = 0, k = 1)일 수 있다.Navigating the tensor in a nested loop may include computing the element's memory address value to load or store the element's corresponding data value. The for-loop is an example of a nested loop that can pass through a three-dimensional tensor by overlapping three loops tracked by three loop index variables (eg, i, j, and k). In a neural network, an element's value can be used to compute one or more dot products associated with a tensor. For example, element values may be multiplied by corresponding parameters or weights. Elements of the tensor can be searched sequentially to access elements using nested for-loops and to perform one or more calculations using the values of the elements. Continuing the three-dimensional tensor example, the outer for-loop can be used to search the loop tracked by variable i, the middle for-loop loop can be used to search the loop tracked by variable j, and the inner for-loop can be used to search the loop tracked by variable j. is used to search the loop tracked by the variable k. In this example, the first element accessed may be (i = 0, j = 0, k = 0) and the second element may be (i = 0, j = 0, k = 1).
후술하는 바와 같이, 텐서 탐색 유닛은 중첩 루프를 사용하여 순서대로 각 엘리먼트에 대한 메모리 어드레스를 결정하여 처리 유닛이 엘리먼트 값에 액세스하고 엘리먼트 값을 사용하여 하나 이상의 계산을 수행할 수 있도록 사용될 수 있다. 가중치 또는 파라미터의 값은 또한 중첩된 for-loops를 사용하여 유사하게 액세스될 수 있다. 텐서 탐색 유닛은 신경망의 은닉 계층에 대한 입력으로 사용될 수 있는 계산들 및 상기 계산들의 출력에 사용되는 가중치 또는 파라미터의 어드레스를 결정하는데 사용될 수 있다.As described below, a tensor search unit can be used to determine the memory address for each element in order using nested loops so that the processing unit can access the element value and perform one or more calculations using the element value. Values of weights or parameters can also be accessed similarly using nested for-loops. The tensor search unit can be used to determine the addresses of calculations that can be used as input to the hidden layer of the neural network and weights or parameters used for the output of the calculations.
본 명세서에 기술된 기술들은 이중 버퍼링을 이용하여 데이터를 생성하고 소비하기 위해 루프 중첩(loop nests)이 인코딩되도록 한다. 예를 들어, 텐서 엘리먼트에 저장된 데이터는 이중 버퍼링 기술을 사용하여 하나의 데이터 저장 위치에서 다른 데이터 저장 위치로 전송(transfer)될 수 있다. 신경망 예에서, 하나의 은닉 계층의 출력으로 결정된 활성화는 다른 은닉 계층에 입력으로서 제공될 수 있고, 따라서 출력 위치, 즉 신경망 계층의 출력이 저장된 메모리 위치로부터 입력 위치, 즉 신경망 계층에 대한 입력이 저장되는 메모리 위치로 전달될 수 있다. 다른 예에서, 계산의 출력을 나타내는 데이터는 임시 메모리 위치로부터 보다 영구적인 메모리 위치로 전송될 수 있다. 이들 각각의 예에서, 데이터는 보다 신속하게 전달될 수 있으며, 데이터는 이중 버퍼링을 사용하여 보다 신속하게 후속 처리를 위해 준비될 수 있다.The techniques described herein use double buffering to allow loop nests to be encoded for generating and consuming data. For example, data stored in a tensor element may be transferred from one data storage location to another using a double buffering technique. In the neural network example, an activation determined as the output of one hidden layer may be provided as input to another hidden layer, so that the input location, ie, the input to the neural network layer, is stored from the output location, ie the memory location where the output of the neural network layer is stored. It can be passed to a memory location where In another example, data representing the output of a calculation may be transferred from a temporary memory location to a more permanent memory location. In each of these examples, the data can be transferred more quickly, and the data can be prepared for subsequent processing more quickly using double buffering.
버퍼링은 계산이 수행되기 전에 신경망 계산을 위한 데이터를 수집하는데 사용될 수 있다. 예를 들어, 신경망 계층으로의 입력은 계산을 수행하는 프로세서에 의한 검색을 위해 특정 위치에 저장될 수 있다. 특정 위치에 저장된 데이터가 신경망 계산을 수행하는데 사용되는 동안 다음 기계 학습 계산을 위한 데이터가 버퍼로 이동될 수 있다. 이전의 신경망 계산이 완료되면, 버퍼에 저장된 데이터는 프로세서에 의한 검색을 위해 특정 위치로 이동될 수 있다.Buffering can be used to collect data for neural network computation before computation is performed. For example, an input to a neural network layer may be stored in a particular location for retrieval by a processor performing a computation. While data stored in a specific location is used to perform neural network computations, data for the next machine learning computation may be moved to a buffer. When the previous neural network computation is complete, the data stored in the buffer can be moved to a specific location for retrieval by the processor.
루프 중첩 내의 하나 이상의 루프는 이중 버퍼를 사용하여 데이터가 생성되거나 소비되는 텐서 엘리먼트에 대한 버퍼 메모리 어드레스를 계산하는데 사용될 수 있다. 전송될 데이터의 양이 단일 버퍼의 저장 용량보다 클 경우 다중 버퍼가 사용될 수 있다. 예를 들어 전송되는 데이터의 양이 단일 버퍼의 저장 용량의 두 배인 경우 데이터는 두 개의 버퍼로 분할될 수 있다. 이 예에서, 데이터의 제1 부분은 제1 버퍼로 전송될 수 있고, 데이터의 제2 부분은 제2 데이터 저장 위치로 전송되기 전에 제2 버퍼로 전송될 수 있다. 이러한 방식으로, 모든 데이터가 제2 데이터 저장 위치로 전송되기 전에 버퍼링될 수 있다.One or more loops within loop nesting can be used to compute buffer memory addresses for tensor elements from which data is created or consumed using double buffers. Multiple buffers can be used when the amount of data to be transferred is larger than the storage capacity of a single buffer. For example, if the amount of data being transferred is twice the storage capacity of a single buffer, the data may be split into two buffers. In this example, a first portion of data may be transferred to a first buffer and a second portion of data may be transferred to a second buffer before being transferred to a second data storage location. In this way, all data can be buffered before being sent to the second data storage location.
예를 들어, 3 차원 텐서의 엘리먼트들은 신경망에 의해 분류되는 이미지의 특징을 나타낼 수 있다. 제1 차원(Z)은 이미지의 폭을 나타낼 수 있고, 제2 차원(Y)은 이미지의 높이를 나타낼 수 있고, 제3 차원(X)은 이미지의 픽셀에 대한 RGB 값을 나타낼 수 있다. 이미지를 분류하기 위해, 각 RGB 값은 컨벌루션 계층의 필터 값에 곱해져 활성화 맵을 생성할 수 있다.For example, elements of a 3D tensor may represent features of an image classified by a neural network. The first dimension (Z) may represent the width of the image, the second dimension (Y) may represent the height of the image, and the third dimension (X) may represent the RGB values for pixels of the image. To classify the image, each RGB value can be multiplied by the filter value of the convolutional layer to generate an activation map.
중첩 루프는 텐서의 각 RGB 값에 액세스하기 위한 메모리 어드레스를 결정하는데 사용될 수 있다. 중첩 루프에는 텐서의 각 차원에 대한 루프가 포함될 수 있다. 예를 들어, 외부 루프(z)는 Z 차원(이미지의 폭)을 탐색하는데 사용될 수 있고, 중간 루프(y)는 Y 차원(이미지의 높이)를 탐색하는데 사용될 수 있으며, 내부 loop(x)는 X 차원(각 픽셀의 세 RGB 값)을 탐색하는데 사용될 수 있다. 내부 루프의 각 반복에서, 메모리 어드레스는 외부 루프(z) 및 중간 루프(y)의 값에 의해 표현되는 이미지의 특정 픽셀에 대한 3개의 RGB 값 중 하나에 대해 결정된다. 예를 들어, Z=0 및 Y=0으로 표현되는 이미지 픽셀의 R 값에 대한 메모리 어드레스는 z=0 및 y=0일 때 내부 루프(x)의 제1 반복 동안 결정될 수 있다(예를 들어, z=0, y=0, x=0). 유사하게, Z=5 및 Y=2에 의해 표현되는 이미지 픽셀의 G 값에 대한 메모리 어드레스는 z=5 및 y=2일 때 내부 루프(x)의 제3 반복 동안 결정될 수 있다(예를 들어, z = 5 y = 2, x = 2). 이미지의 각 픽셀에 대한 3개의 RGB 값이 버퍼의 용량을 초과하면, 이미지의 각 픽셀에 대한 3개의 RGB 값을 나타내는 데이터를 둘 이상의 버퍼간에 분할될 수 있다.A nested loop can be used to determine the memory address for accessing each RGB value in the tensor. Nested loops can contain loops for each dimension of the tensor. For example, the outer loop (z) can be used to explore the Z dimension (width of the image), the middle loop (y) can be used to search the Y dimension (height of the image), and the inner loop (x) can be It can be used to explore the X dimension (the three RGB values of each pixel). At each iteration of the inner loop, a memory address is determined for one of the three RGB values for a particular pixel of the image represented by the values of the outer loop (z) and the middle loop (y). For example, the memory address for the R value of an image pixel represented by Z=0 and Y=0 may be determined during a first iteration of inner loop x when z=0 and y=0 (e.g. , z=0, y=0, x=0). Similarly, the memory address for the G value of an image pixel represented by Z=5 and Y=2 may be determined during the third iteration of inner loop x when z=5 and y=2 (e.g. , z = 5 y = 2, x = 2). If the three RGB values for each pixel of the image exceed the capacity of the buffer, data representing the three RGB values for each pixel of the image may be split between two or more buffers.
중첩 루프를 사용하는 다수의 버퍼에 대한 버퍼 메모리 어드레스를 결정하기 위해, 버퍼 할당 엘리먼트의 값은 버퍼 메모리 어드레스를 결정하는데 사용되는 루프의 각 반복 후에 (또는 그 전에) 스위칭될 수 있다. 예를 들어, 두 개의 버퍼가 사용되고 두 개의 버퍼간에 데이터가 분리되는 경우 상기 버퍼 할당 값은 두 값 사이에서 스위칭될 수 있다. 버퍼 할당 엘리먼트의 제1 값(예를 들어, 0)은 데이터 엘리먼트(또는 데이터 엘리먼트들의 그룹)를 제1 버퍼에 할당하는데 사용되고, 버퍼 할당 엘리먼트의 제2 값(예를 들어, 1)은 데이터 엘리먼트(또는 데이터 엘리먼트들의 그룹)를 제2 버퍼에 할당하는데 사용될 수 있다. 버퍼 할당 엘리먼트의 값이 루프의 반복에 대한 제1 값일 때, 루프의 이 반복에 대응하는 데이터 엘리먼트는 제1 버퍼의 버퍼 메모리 어드레스에 할당될 수 있다. 유사하게, 버퍼 할당 엘리먼트의 값이 루프의 반복에 대한 제2 값일 때, 루프의 이 반복에 대응하는 데이터 엘리먼트는 제2 버퍼의 버퍼 메모리 어드레스에 할당될 수 있다. 3개 이상의 버퍼가 사용되는 경우, 버퍼 할당 엘리먼트는 3개 이상의 값, 예를 들어 각 버퍼에 대한 값을 가질 수 있다.To determine buffer memory addresses for multiple buffers using nested loops, the value of the buffer allocation element may be switched after (or before) each iteration of the loop used to determine the buffer memory addresses. For example, when two buffers are used and data is separated between the two buffers, the buffer allocation value may be switched between the two values. A first value (eg, 0) of the buffer allocation element is used to allocate a data element (or group of data elements) to the first buffer, and a second value (eg, 1) of the buffer allocation element is the data element (or a group of data elements) can be used to allocate to the second buffer. When the value of the buffer assignment element is the first value for an iteration of the loop, the data element corresponding to this iteration of the loop may be assigned to the buffer memory address of the first buffer. Similarly, when the value of the buffer assignment element is the second value for an iteration of the loop, the data element corresponding to this iteration of the loop may be assigned to the buffer memory address of the second buffer. When three or more buffers are used, the buffer allocation element may have three or more values, for example, a value for each buffer.
도 1은 예시적인 컴퓨팅 시스템(100)의 블록도이다. 일반적으로, 컴퓨팅 시스템(100)은 출력(116)을 생성하기 위해 입력(104)을 처리한다. 컴퓨팅 시스템 (100)은 선형 대수(linear algebra) 계산, 신경망 계산 및 다른 계산을 수행하도록 구성될 수 있다. 입력 (104)은 컴퓨팅 시스템(100)에 의해 처리될 수 있는 임의의 적절한 데이터일 수 있다. 컴퓨팅 시스템(100)은 처리 유닛(102), 하나 이상의 저장 매체(104) 및 텐서 탐색 유닛(106)을 포함한다.1 is a block diagram of an
프로세싱 유닛(114)은 하나 이상의 프로세서들 및/또는 하나 이상의 유한 상태 머신(finite-state machine:FSM)을 포함할 수 있다. 프로세싱 유닛(114)의 프로세서는 텐서의 특정 엘리먼트에 액세스하기 위한 명령을 실행할 수 있다. 프로세서가 그러한 명령을 처리할 때, 텐서 탐색 유닛(106)은 처리 유닛이 저장 매체 (들)(104)에 액세스하여 특정 엘리먼트의 값을 나타내는 데이터를 판독할 수 있도록 텐서의 특정 엘리먼트의 메모리 어드레스를 결정한다.The
FSM을 포함하는 처리 유닛들에 대해, FSM은 텐서 탐색 유닛(106)으로부터 텐서 엘리먼트에 대한 메모리 어드레스를 질의할 수 있다. 일부 구현예에서, FSM (108)은 텐서 탐색 유닛(106)에 텐서의 특정 엘리먼트들에 대한 어드레스 값을 계속 질의한다. 그런 다음, FSM은 프로세서가 저장 매체(들)(104)에 액세스하여 특정 엘리먼트의 값을 나타내는 데이터를 판독할 수 있도록 처리 유닛(102)의 프로세서에 상기 수신된 어드레스 값을 제공할 수 있다.For processing units that include the FSM, the FSM may query the memory address for the tensor element from the
예를 들어, 프로그램은 중첩 루프를 포함할 수 있고, 처리 유닛(102)은 중첩 루프와 관련된 현재의 인덱스 변수 값에 따라 상기 중첩 루프 내의 2 차원 어레이 변수의 엘리먼트에 액세스하는 명령을 실행할 수 있다. 중첩 루프와 관련된 현재의 인덱스 변수 값에 기초하여, 텐서 탐색 유닛(106)은 2 차원 어레이 변수의 제1 엘리먼트에 대한 메모리 어드레스로부터의 오프셋을 나타내는 어드레스 오프셋 값을 결정할 수 있다. 그런 다음, 처리 유닛(102)은 어드레스 오프셋 값을 사용하여 저장 매체(104)로부터, 2 차원 어레이 변수의 특정 엘리먼트를 액세스할 수 있다.For example, a program may include a nested loop, and the
저장 매체(104)는 컴퓨팅 시스템(100) 내의 정보를 저장한다. 일부 구현예에서, 저장 매체(104)는 휘발성 메모리 유닛(들)이다. 일부 다른 구현예에서, 저장 매체(104)는 비-휘발성 메모리 유닛(들)이다. 저장 매체(104)는 저장 영역 네트워크 또는 다른 구성의 디바이스들을 포함하여, 플로피 디스크 디바이스, 하드 디스크 디바이스, 광학 디스크 디바이스 또는 테이프 디바이스, 플래시 메모리 또는 다른 유사한 고체 상태 메모리 디바이스, 또는 어레이와 같은 컴퓨터 판독 가능 매체의 다른 형태 일 수도 있다. 명령들은 처리 유닛(102)에 의해 실행될 때, 처리 유닛(102)으로 하여금 하나 이상의 작업을 수행하게 한다.The
일반적으로, 텐서 탐색 유닛(106)은 하나 이상의 텐서와 관련된 상태를 결정한다. 일부 구현예에서, 상태는 루프 경계값, 현재 루프 인덱스 변수 값, 메모리 어드레스 값을 결정하기 위한 부분(partial) 어드레스 오프셋 값 및/또는 브랜치 루프 경계들을 처리하기 위한 프로그램 카운터 값을 포함할 수 있다. 텐서 탐색 유닛(106)은 주문형 집적 회로로서 구현될 수 있다.In general, the
텐서 탐색 유닛(106)은 텐서 인덱스들을 메모리 어드레스로 변환할 수 있다. 예를 들어, 텐서 탐색 유닛(106)은 N 차원 텐서 인덱스들의 세트를 1 차원 어드레스 공간으로 변환할 수 있다. 텐서 탐색 유닛(106)은 텐서 엘리먼트의 메모리 어드레스를 엘리먼트의 차원 인덱스들의 조합(예를 들어, 선형 조합)으로 만들어서 이러한 변환을 수행할 수 있다.The
텐서 탐색 유닛(106)은 하나 이상의 텐서 상태 엘리먼트(122) 및 연산(Math) 유닛(124)을 포함할 수 있다. 텐서 상태 엘리먼트(122) 각각은 저장 엘리먼트, 예를 들어 레지스터 또는 임의의 적절한 저장 회로일 수 있다. 텐서 상태 엘리먼트(122)는 후술하는 버퍼 할당 엘리먼트를 포함할 수 있다. 연산 유닛(124)은 하나 이상의 산술 논리 유닛(ALU) 및/또는 하나 이상의 하드웨어 가산기를 포함할 수 있다. 연산 유닛(124)은 예를 들어 텐서 상태 엘리먼트에 저장된 값에 기초하여 텐서 엘리먼트에 대한 메모리 어드레스 또는 메모리 어드레스 오프셋 값을 계산하는데 사용될 수 있다. 텐서 탐색 유닛을 사용하여 메모리 어드레스를 결정하는 예시적인 기술은 "신경망 계산 타일"이라는 제목으로 2016년 10월 27일자로 출원된 미국 특허 출원 제15/335,769호 및 "다차원 텐서에서의 데이터 액세스"라는 제목으로 2016년 2월 3일자로 출원된 미국 특허 출원 제15/014,265호에 개시되어 있으며, 그 전체 내용은 참조로서 본 명세서에 포함된다. The
또한, 텐서 탐색 유닛(106)은 하나의 데이터 저장 위치로부터 다른 데이터 저장 위치로 데이터를 전송하기 위한 일시적인 메모리 위치, 예를 들어, 버퍼에 대한 메모리 어드레스를 결정하도록 구성될 수 있다. 예를 들어, 저장 매체(들)(104)는 저장 위치 A(112) 및 저장 위치 B(114)를 포함하는 다수의 데이터 저장 위치를 포함할 수 있다. 각각의 저장 위치는 공통 메모리 유닛 또는 상이한 메모리 유닛의 메모리 어드레스 범위일 수 있다. 저장 매체(들)(104)는 또한 버퍼 A(116) 및 버퍼 B(118)를 포함하여 다수의 임시 메모리들을 포함할 수 있다. 처리 유닛(102)은 데이터를 제2 데이터 저장 위치(예를 들어, 저장 위치 B(114))로 전송하기 전에 제1 데이터 저장 위치(예를 들어, 저장 위치 A(112))로부터 하나 이상의 버퍼(예를 들어, 버퍼 A(116) 및/또는 버퍼 B(118)로 데이터를 전송할 수 있다.Further, the
텐서 탐색 유닛(106)은 버퍼(예를 들어, 이중 버퍼)를 사용하여 데이터가 생성되거나 소비되는 텐서 엘리먼트들에 대한 버퍼 메모리 어드레스를 결정할 수 있다. 예를 들어, 텐서 탐색 유닛(106)은 "다차원 텐서에서의 데이터 액세스"라는 제목으로 2016년 2월 3일에 출원된 미국 특허 출원 제15/014,265호에 설명된 기술과 유사하게, 텐서 엘리먼트에 대한 텐서 인덱스들에 기초한 텐서에 대한 기본 버퍼 메모리 어드레스 및 각 텐서 엘리먼트에 대한 어드레스 오프셋을 사용하여 텐서 인덱스들을 버퍼 메모리 어드레스로 변환할 수있다.The
예를 들어, 미국 특허 출원 제15/014,265호에 기술된 바와 같이, 텐서 상태 엘리먼트들(122)은 텐서 인덱스 엘리먼트의 그룹, 텐서 경계 엘리먼트의 그룹 및 차원 승수 엘리먼트의 그룹을 포함할 수 있다. 각 엘리먼트 그룹은 M 행과 N 열을 갖는 2 차원 어레이로 배열될 수 있다. 그룹의 각 행은 텐서에 대한 텐서 인덱스 정보를 나타낼 수 있다. 그룹에 대한 각 열은 텐서와 관련된 중첩 루프 인덱스 변수 값들에 대한 정보(예를 들어, 텐서 인덱스 값, 텐서 경계 값 또는 차원 승수 값)를 나타낼 수 있다. 예를 들어, 텐서 인덱스 엘리먼트에 대한 2D 어레이의 한 열은 변수(i)에 대한 텐서 인덱스 정보를 나타낼 수 있고, 한 열은 변수(i)에 대한 텐서 인덱스 정보를 나타낼 수 있으며, 한 열은 변수(k)에 대한 텐서 인덱스 정보를 나타낼 수 있다.For example, as described in US Patent Application Serial No. 15/014,265, tensor state elements 122 may include a group of tensor index elements, a group of tensor boundary elements, and a group of dimension multiplier elements. Each element group can be arranged in a two-dimensional array with M rows and N columns. Each row of the group may indicate tensor index information for a tensor. Each column of the group may indicate information about nested loop index variable values related to the tensor (eg, a tensor index value, a tensor boundary value, or a dimension multiplier value). For example, one column of a 2D array for a tensor index element may indicate tensor index information for variable (i), one column may indicate tensor index information for variable (i), and one column may indicate tensor index information for variable (i). Tensor index information for (k) may be indicated.
각각의 텐서 인덱스 엘리먼트는 중첩 루프내의 루프에 대한 중첩 루프 변수를 추적할 수 있다. 예를 들어, 하나의 텐서 인덱스 엘리먼트는 중첩 루프 인덱스 변수(i)를 추적하도록 할당될 수 있고, 하나의 텐서 인덱스 엘리먼트는 중첩 루프 인덱스 변수(j)를 추적하도록 할당될 수 있으며, 하나의 텐서 인덱스 엘리먼트는 중첩 루프 인덱스 변수(k)를 추적하도록 할당될 수 있다. 각 텐서 경계 엘리먼트는 텐서 인덱스 엘리먼트에 대응하는 엘리먼트를 가지고 있다. 각 텐서 경계 엘리먼트는 텐서와 관련된 중첩 루프 인덱스 변수 값에 대한 텐서 경계 정보를 나타낼 수 있다. 예를 들어, 하나의 텐서 바운드 엘리먼트는 중첩 루프 인덱스 변수(i)에 대한 텐서 경계 정보를 나타낼 수 있고, 하나의 텐서 바운드 엘리먼트는 중첩 루프 인덱스 변수(j)에 대한 텐서 경계 정보를 나타낼 수 있으며, 하나의 텐서 바운드 엘리먼트는 중첩 루프 인덱스 변수(k)에 대한 텐서 경계 정보를 나타낼 수 있다.Each tensor index element can keep track of nested loop variables for loops within nested loops. For example, one tensor index element may be assigned to track a nested loop index variable (i), and one tensor index element may be assigned to track a nested loop index variable (j), and one tensor index element may be assigned to track a nested loop index variable (j). Elements can be assigned to keep track of the nested loop index variable (k). Each tensor boundary element has an element corresponding to the tensor index element. Each tensor boundary element may indicate tensor boundary information for a value of a nested loop index variable associated with the tensor. For example, one tensor-bound element may indicate tensor boundary information for the nested loop index variable (i), and one tensor-bound element may indicate tensor boundary information for the nested loop index variable (j), One tensor bound element may indicate tensor boundary information for the nested loop index variable (k).
각각의 차원 승수 엘리먼트는 텐서 인덱스 엘리먼트 내의 대응하는 엘리먼트가 승산되는 승수를 나타낼 수 있다. 엘리먼트에 대한 메모리 어드레스를 결정하기 위해, 텐서 탐색 유닛(106)은 중첩 루프 인덱스 변수에 대한 텐서 인덱스 엘리먼트에 저장된 값에 중첩 루프 인덱스 변수에 대한 승수를 곱함으로써 각 중첩 루프 인덱스 변수에 대한 메모리 어드레스 오프셋을 결정할 수 있다. 그런 다음, 텐서 탐색 유닛(106)은 액세스되는 엘리먼트에 대응하는 메모리 어드레스를 결정하기 위해 함께 승산된 도든 곱을 합산할 수 있다.Each dimension multiplier element may represent a multiplier by which a corresponding element in the tensor index element is multiplied. To determine the memory address for the element, the
텐서 탐색 유닛(106)은 중첩 루프의 내부 루프의 각 반복 후에 텐서 인덱스 엘리먼트를 업데이트할 수 있다. 내부 루프의 각 반복에 대해, 텐서 탐색 유닛(106)은, 예를 들어 내부 루프에 대한 텐서 인덱스 엘리먼트를 증가시킴으로써 텐서 인덱스 엘리먼트를 루프에 대해 업데이트할 수 있다. 내부 루프의 업데이트된 텐서 인덱스 엘리먼트가 내부 루프의 텐서 경계 엘리먼트에 저장된 값과 같으면, 텐서 인덱스 엘리먼트는 재설정될 수 있고 중첩된 내부 루프가 업데이트될 수 있는 다음 외부 루프에 대한 텐서 인덱스 엘리먼트가 재설정될 수 있다. 텐서 탐색 유닛(120)은 전술한 바와 같이, 텐서 인덱스 엘리먼트에 그들의 대응하는 승수를 곱하고 곱셈을 합산함으로써 내부 루프의 이 반복에 대응하는 다음 엘리먼트에 대한 메모리 어드레스를 결정할 수 있다.The
데이터를 전송하기 위해 2개 이상의 버퍼가 사용되는 경우, 텐서 탐색 유닛(106)은 또한 버퍼 할당 엘리먼트를 사용하여 각 텐서 엘리먼트 또는 텐서 엘리먼트 그룹을 버퍼들 중 하나에 할당할 수 있다. 일부 구현예에서, 텐서 탐색 유닛(106)은 버퍼 할당 엘리먼트의 값이 하나의 값일 때 버퍼 메모리 어드레스에 추가 오프셋을 부가함으로써 하나 이상의 텐서 엘리먼트들의 그룹을 버퍼들 중 하나에 할당할 수 있고, 버퍼 할당 엘리먼트의 값이 상이한 값일 때는 추가 오프셋 값을 버퍼 메모리 어드레스에 부가하지 않음으로써 하나 이상의 텐서 엘리먼트들의 그룹을 상이한 버퍼에 할당할 수 있다.When two or more buffers are used to transmit data, the
예를 들어, 베이스 메모리 어드레스는 제1 버퍼의 제1 메모리 어드레스에 대응할 수 있다. 제2 버퍼의 제1 메모리 어드레스는 베이스 메모리 어드레스로부터 특정 수의 어드레스만큼 오프셋될 수 있다. 이 예에서, 텐서 엘리먼트를 제1 버퍼의 메모리 어드레스에 할당하기 위해, 텐서 탐색 유닛(106)은 베이스 메모리 어드레스를 텐서 엘리먼트에 대한 메모리 오프셋 값과 결합(예를 들어, 가산)할 수 있다. 텐서 엘리먼트에 대한 메모리 오프셋 값은 "다차원 텐서에서의 데이터 액세스"라는 제목으로 2016년 2월 3일에 출원된 의 미국 특허 출원 제15/014,265호에 기술된 바와같이, 텐서를 탐색하는데 사용되는 중첩 루프의 텐서 인덱스들에 기초하여 결정될 수 있다.For example, the base memory address may correspond to the first memory address of the first buffer. The first memory address of the second buffer may be offset from the base memory address by a certain number of addresses. In this example, to assign the tensor element to a memory address of the first buffer, the
텐서 엘리먼트를 제2 버퍼의 메모리 어드레스에 할당하기 위해, 텐서 탐색 유닛(106)은 베이스 메모리 어드레스를 텐서 엘리먼트에 대한 메모리 오프셋 값 및 제2 버퍼에 대한 메모리 어드레스 오프셋 값(예를 들어, 제2 버퍼의 제1 메모리 어드레스가 제1 버퍼의 제1 메모리 어드레스로부터 오프셋되는 특정 어드레스 수)과 결합(예를 들어, 가산)할 수 있다. To assign the tensor element to a memory address of the second buffer, the
텐서 탐색 유닛(106)은 텐서 엘리먼트를 제2 버퍼에 할당할 시기를 결정하기 위해 버퍼 할당 엘리먼트의 값을 사용할 수 있으므로 제2 버퍼에 대한 메모리 어드레스 오프셋 값을 베이스 메모리 어드레스 및 텐서 엘리먼트에 대한 메모리 오프셋 값과 결합함으로써 텐서 엘리먼트에 대한 버퍼 메모리 어드레스를 결정할 수 있다. 예를 들어, 버퍼 할당 엘리먼트의 값이 제1 값일 때, 텐서 탐색 유닛(106)은 메모리 어드레스 오프셋 값을 베이스 메모리 어드레스 및 텐서 엘리먼트에 대한 메모리 오프셋 값과 결합하지 않음으로써 텐서 엘리먼트를 제1 버퍼에 할당할 수 있다. 버퍼 할당 엘리먼트의 값이 제1 값과 상이한 제2 값일 때, 텐서 탐색 유닛 (106)은 메모리 어드레스 오프셋 값을 베이스 메모리 어드레스 및 텐서 엘리먼트에 대한 메모리 오프셋 값과 결합함으로써 텐서 엘리먼트를 제2 버퍼에 할당할 수 있다.The
일부 구현예에서, 텐서 탐색 유닛(106)은 예를 들어 중첩 루프를 사용하여 시퀀스 내의 텐서 엘리먼트들의 시퀀스에 대한 버퍼 메모리 어드레스를 결정할 수 있다. 이 예에서, 처리 유닛(102)은 텐서 탬색 유닛(106)으로부터, 특정 루프의 각각의 반복에 대한 하나 이상의 텐서 엘리먼트들의 그룹에 대한 버퍼 메모리 어드레스, 예를 들어 최내(inner most loop) 루프의 각각의 반복을 요청할 수 있다. 텐서 탐색 유닛(106)은 루프 인덱스들에 기초하여 루프의 반복에 대응하는 텐서 엘리먼트들의 그룹에 대한 메모리 오프셋 값을 결정할 수 있다. 텐서 탐색 유닛(106)은 또한 상술한 바와 같이, 버퍼 할당 엘리먼트의 값에 기초하여 텐서 엘리먼트 그룹을 제1 버퍼 또는 제2 버퍼(또는 2개 이상인 경우 추가 버퍼)에 할당할지 여부를 결정할 수 있다. 텐서 탐색 유닛(106)은 베이스 메모리 어드레스, 텐서 엘리먼트들의 그룹에 대한 메모리 오프셋 값, 및 버퍼 할당 엘리먼트의 값에 따른, 제2 버퍼에 대한 메모리 오프셋 값에 기초하여 텐서 엘리먼트 그룹에 대한 버퍼 메모리 어드레스를 결정할 수 있다.In some implementations, the
시퀀스 내의 텐서 엘리먼트 그룹에 대한 버퍼 메모리 어드레스를 결정한 후, 텐서 탐색 유닛은 버퍼 할당 엘리먼트의 값을 스위칭할 수 있다. 예를 들어, 2 개의 버퍼가 있는 경우, 텐서 탐색 유닛(106)은 각각의 버퍼 메모리 어드레스 결정 이후에 2 개의 값 사이에서 값을 토글할 수 있다. 이 예에서, 텐서 탐색 유닛(106)은 버퍼 할당 엘리먼트의 값이 0일 때 제1 버퍼에 텐서 엘리먼트 그룹을 할당하고, 버퍼 할당 엘리먼트의 값이 1일 때 텐서 엘리먼트 그룹을 제2 버퍼에 할당할 수 있다. 제1 버퍼 메모리 어드레스 결정에 대해, 버퍼 할당 엘리먼트는 0의 값을 가질 수 있다. 이 예에서, 텐서 탐색 유닛(106)은 시퀀스 내의 제1 텐서 엘리먼트 그룹을 제1 버퍼에 할당할 수 있다. 그런 다음 텐서 탐색 유닛(106)은 버퍼 할당 엘리먼트의 값을 1로 스위칭할 수 있다. 따라서, 텐서 탐색 유닛(106)은 시퀀스 내의 제2 텐서 엘리먼트 그룹을 제2 버퍼에 할당할 수 있다. 텐서 탐색 유닛(106)은 모든 다른 텐서 엘리먼트 그룹이 제1 버퍼에 할당되도록 각 버퍼 메모리 어드레스 결정 후 값을 계속 스위칭할 수 있다.After determining the buffer memory address for the group of tensor elements in the sequence, the tensor search unit may switch the value of the buffer allocation element. For example, if there are two buffers, the
일부 구현예에서, 거친(coarse-grained) 토글링은 텐서 엘리먼트 그룹(예를 들어, 텐서의 서브텐서)이 각 버퍼 메모리 어드레스 결정을 위해 버퍼에 할당되도록 사용된다. 일부 구현예에서, 미세 토글링은 각각의 개별 텐서 엘리먼트가 각각의 메모리 어드레스 결정시에 버퍼에 할당되도록 사용된다.In some implementations, coarse-grained toggling is used such that a group of tensor elements (eg, a subtensor of a tensor) is assigned to a buffer for each buffer memory address determination. In some implementations, fine toggling is used such that each individual tensor element is assigned to a buffer upon each memory address determination.
텐서 탐색 유닛이 2 개의 1 킬로바이트(kB) 버퍼를 갖고 4 kB의 데이터가 상기 버퍼들을 사용하여 전송되는 예를 고려한다. 예시적인 루프 중첩은 2 개의 버퍼를 번갈아 사용하는 외부 루프를 포함할 수 있고, 내부 루프는 현재 버퍼에 포함할 데이터의 각 부분을 식별하는데 사용될 수 있다. 예를 들어 중첩 루프에는 다음이 포함될 수 있다.Consider an example in which a tensor search unit has two 1 kilobyte (kB) buffers and 4 kB of data is transmitted using the buffers. An example loop nesting may include an outer loop that alternates between the two buffers, and an inner loop may be used to identify each piece of data to include in the current buffer. For example, a nested loop could contain:
for(i=0; i<4, ++i)for(i=0; i<4, ++i)
for(j=0; j=1024; ++j) for(j=0; j=1024; ++j)
이 예에서, 내부 루프 "j"는 버퍼에 포함시킬 1 kB의 데이터를 식별하는데 사용되고, 외부 루프 "i"는 2 개의 버퍼 사이에서 스위칭하는데 사용된다. 예를 들어, "i"가 홀수 값을 갖는 경우, 1 kB의 데이터 엘리먼트 그룹이 제1 버퍼에 할당될 수 있다. "i"가 짝수 값을 갖는 경우 1kB의 데이터가 제2 버퍼에 할당될 수 있다. 따라서, 이 예에서, 루프 중첩은 "i"의 값에 따라 두 버퍼 사이에서 번갈아 나타난다.In this example, inner loop "j" is used to identify 1 kB of data to include in the buffer, and outer loop "i" is used to switch between the two buffers. For example, when “i” has an odd value, a data element group of 1 kB may be allocated to the first buffer. When “i” has an even value, 1 kB of data may be allocated to the second buffer. Thus, in this example, loop overlap alternates between the two buffers depending on the value of "i".
2개 이상의 버퍼가 있는 경우, 텐서 탐색 유닛(106)은 2개 이상의 상이한 값, 예를 들어 각 버퍼에 대한 고유값 사이에서 버퍼 할당 엘리먼트를 스위칭할 수 있다. 예를 들어, 3개의 버퍼가 있는 경우, 텐서 탐색 유닛(106)은 버퍼 할당 엘리먼트가 제1 값을 가질 때 제1 버퍼에 텐서 엘리먼트 그룹을 할당할 수 있고; 텐서 탐색 유닛(106)은 버퍼 할당 엘리먼트가 제2 값을 가질 때 텐서 엘리먼트 그룹을 제2 버퍼에 할당할 수 있으며; 텐서 탐색 유닛(106)은 버퍼 할당 엘리먼트가 제3 값을 가질 때 제3 버퍼에 텐서 엘리먼트 그룹을 할당할 수 있다.If there are more than two buffers, the
다른 예에서, 각각 1 MB의 저장 용량을 갖는 2 개의 버퍼가 있을 수 있으며, 3 MB의 데이터가 버퍼들를 통해 전송될 필요가 있을 수 있다. 이 예에서 첫 번째 1MB는 2 개의 버퍼 중 제1 버퍼에 할당되고 두 번째 1MB는 2 개의 버퍼 중 제2 버퍼에 할당될 수 있다. 그런 다음, 예를 들어 프로세서에 의해 처음 1MB가 소비된 후, 세 번째 1MB는 제1 버퍼로 이동될 수 있다.In another example, there may be two buffers, each with a storage capacity of 1 MB, and 3 MB of data may need to be transferred across the buffers. In this example, the first 1MB may be allocated to the first buffer among the two buffers, and the second 1MB may be allocated to the second buffer among the two buffers. Then, for example, after the first 1 MB is consumed by the processor, the third 1 MB may be moved to the first buffer.
일부 구현예에서, 텐서 탐색 유닛(106)은 각각의 버퍼 메모리 어드레스 결정 후에 버퍼 할당 엘리먼트의 값을 스위칭하는 것이 아니라 교번하는 버퍼 할당 값들의 시퀀스를 획득할 수 있다. 예를 들어, 교번하는 버퍼 할당 값들의 시퀀스는 0과 1의 교대 시퀀스일 수 있다. 각각의 메모리 어드레스 결정 후에, 텐서 탐색 유닛(106)은 시퀀스의 다음 값으로 이동하여 다음 값에 기초하여 텐서 엘리먼트 그룹을 적절한 버퍼에 할당할 수 있다.In some implementations, the
도 2는 버퍼들 및 예시적인 버퍼 할당 엘리먼트들을 사용하여 전송되는 예시적인 데이터를 도시한다. 이 예에서, 8 개의 그룹의 데이터 엘리먼트, 예를 들어, 텐서 엘리먼트의 시퀀스가 2 개의 버퍼를 사용하여 제1 데이터 저장 위치(205)에서 제2 데이터 저장 위치(215)로 전송된다. 버퍼 할당 값들(210)의 시퀀스는 각 데이터 엘리먼트 그룹을 2 개의 버퍼들 중 하나에 할당하는데 사용된다. 예를 들어, 데이터 엘리먼트 그룹이 0의 값을 갖는 버퍼 할당 엘리먼트와 동일한 시퀀스의 위치에 있다면, 데이터 엘리먼트 그룹은 제1 버퍼에 할당된다. 데이터 엘리먼트 그룹이 1의 값을 갖는 버퍼 할당 엘리먼트와 동일한 시퀀스의 위치에 있다면, 데이터 엘리먼트 그룹은 제1 버퍼와 다른 제2 버퍼에 할당된다.2 illustrates example data transmitted using buffers and example buffer allocation elements. In this example, a sequence of 8 groups of data elements, eg, tensor elements, is transferred from a first
따라서, 이 예에서, 제1, 제3, 제5 및 제7 버퍼 할당 값이 0일 때, 데이터 엘리먼트 그룹 "0", "2", "4" 및 "6"이 제1 버퍼에 할당된다. 마찬가지로, 제2, 제4, 제6 및 제8 버퍼 할당 값이 1이므로, 제2 버퍼에는 데이터 엘리먼트 그룹 "1", "3", "5" 및 "7"이 할당된다. 따라서, 각각 4 개의 데이터 엘리먼트 그룹을 저장하는 저장 용량을 갖는 2 개의 버퍼가 8 개의 데이터 엘리먼트 그룹을 버퍼링하는데 사용될 수 있다.Thus, in this example, when the first, third, fifth and seventh buffer allocation values are 0, the data element groups "0", "2", "4" and "6" are allocated to the first buffer . Similarly, since the second, fourth, sixth and eighth buffer allocation values are 1, the data element groups "1", "3", "5" and "7" are allocated to the second buffer. Accordingly, two buffers each having a storage capacity of storing four groups of data elements can be used to buffer groups of eight data elements.
도 3은 이중 버퍼링을 사용하여 데이터를 전송하기 위한 예시적인 프로세스 (300)를 도시하는 흐름도이다. 프로세스 (300)는 하나 이상의 컴퓨터, 예를 들어 도 1의 컴퓨팅 시스템 (110)의 시스템에 의해 수행될 수 있다.3 is a flow diagram illustrating an
시스템은 제1 버퍼 및 제2 버퍼를 사용하여 이중 버퍼링을 위해 지정된 데이터 엘리먼트들의 시퀀스를 식별한다(302). 데이터 엘리먼트들의 시퀀스는 이중 버퍼링을 위해 지정된 텐서 엘리먼트들의 시퀀스일 수 있다. 텐서 엘리먼트는 N 차원 텐서의 일부일 수 있다. 예를 들어, 텐서는 중첩 루프를 사용하여 탐색될 수 있으며, 여기서 각 루프는 N 차원 텐서의 각각의 차원을 탐색하는 역할을 한다.The system identifies a sequence of data elements designated for double buffering using the first buffer and the second buffer (302). The sequence of data elements may be a sequence of tensor elements designated for double buffering. A tensor element may be part of an N-dimensional tensor. For example, a tensor may be searched using nested loops, where each loop is responsible for traversing each dimension of an N-dimensional tensor.
데이터 엘리먼트들의 시퀀스는 이중 버퍼링을 위해 지정된 특정 차원의 모든 텐서 엘리먼트를 포함할 수 있다. 예를 들어, 중첩 루프를 포함하는 프로그램은 특정 차원에 해당하는 루프를 이중 버퍼링될 루프로 지정하는 코드를 포함할 수 있다. 특정 3 차원 텐서 예에서, 텐서는 인덱스 x, y 및 z를 갖는 3 개의 루프를 사용하여 탐색될 수 있다. 이 예에서, 텐서의 Z 차원은 인덱스 z를 갖는 외부 루프를 사용하여 탐색될 수 있으며, 텐서의 Y 차원은 인덱스 y를 갖는 중간 루프를 사용하여 탐색될 수 있고, 텐서의 X 차원은 내부 루프 인덱스 x를 사용하여 탐색될 수 있다. 내부 루프는 신경망 계산에 대해 신속하게 데이터를 버퍼링하기 위해 이중 버퍼링을 위해 지정될 수 있다.The sequence of data elements may include all tensor elements of a specific dimension designated for double buffering. For example, a program containing nested loops may include code that designates a loop corresponding to a specific dimension as a loop to be double-buffered. In a particular three-dimensional tensor example, the tensor can be searched using three loops with indices x, y and z. In this example, the Z dimension of the tensor may be searched using the outer loop with index z, the Y dimension of the tensor may be searched using the middle loop with index y, and the X dimension of the tensor may be searched using the inner loop index. It can be searched using x. An inner loop can be designated for double buffering to buffer data quickly for neural network computations.
시스템은 시퀀스 내의 각 데이터 엘리먼트 그룹에 대한 버퍼 메모리 어드레스를 결정한다(304). 각 그룹은 하나 이상의 데이터 엘리먼트를 포함할 수 있다. 예를 들어, 미세 토글링이 사용되는 경우 각 그룹에는 하나의 데이터 엘리먼트가 포함될 수 있다. 거친 토글링이 사용되는 경우, 각 그룹은 다수의 데이터 엘리먼트, 예를 들어, 지정된 양의 메모리 또는 지정된 수의 데이터 엘리먼트를 포함할 수 있다.The system determines (304) a buffer memory address for each group of data elements in the sequence. Each group may contain one or more data elements. For example, when fine toggling is used, each group may contain one data element. When coarse toggling is used, each group may contain a number of data elements, eg, a specified amount of memory or a specified number of data elements.
일부 구현예에서, 시스템은 버퍼 메모리 어드레스를 한번에 하나씩 결정한다. 이전의 예를 계속하면, 시스템은 내부 루프의 각 반복이 이중 버퍼링을 위해 지정된 특정 텐서 엘리먼트에 대응하므로 내부 루프 x의 각 반복에 대한 버퍼 메모리 어드레스를 결정할 수 있다. 시스템은 구성 동작들(306-314)을 사용하여 데이터 엘리먼트들의 시퀀스에 대한 버퍼 메모리 어드레스들을 결정할 수 있다.In some implementations, the system determines the buffer memory addresses one at a time. Continuing the previous example, the system can determine the buffer memory address for each iteration of the inner loop x as each iteration of the inner loop corresponds to a specific tensor element designated for double buffering. The system may determine buffer memory addresses for the sequence of data elements using the construct operations 306-314.
시스템은 데이터 엘리먼트들의 시퀀스에서 데이터 엘리먼트 그룹에 대한 버퍼 할당 엘리먼트의 값을 식별한다(306). 일부 구현예에서, 상술한 바와 같이, 시스템은 예를 들어, 이중 버퍼링을 위해 지정된 루프의 각각의 반복 후에, 각 버퍼 메모리 어드레스 결정 이후에 버퍼 할당 엘리먼트의 값을 스위칭할 수 있다. 이 예에서, 시스템은 이 데이터 엘리먼트에 대한 버퍼 할당 엘리먼트의 값으로서 버퍼 할당 엘리먼트의 현재 값을 식별할 수 있다. 버퍼 할당 엘리먼트의 값은 데이터 엘리먼트 그룹을 적절한 버퍼에 할당하는데 사용된다.The system identifies ( 306 ) a value of a buffer allocation element for a group of data elements in the sequence of data elements. In some implementations, as described above, the system may switch the value of the buffer allocation element after each buffer memory address determination, eg, after each iteration of a loop designated for double buffering. In this example, the system may identify the current value of the buffer allocation element as the value of the buffer allocation element for this data element. The value of the buffer allocation element is used to allocate a group of data elements to the appropriate buffer.
시스템은 버퍼 할당 엘리먼트의 값 및 제2 버퍼에 대한 메모리 어드레스 오프셋 값에 기초하여 데이터 엘리먼트 그룹에 대한 버퍼 메모리 어드레스 오프셋 값을 결정한다(308). 상술한 바와 같이, 버퍼들에 대한 베이스 메모리 어드레스는 제1 버퍼의 제1 메모리 어드레스에 대응할 수 있다. 제2 버퍼의 제1 메모리 어드레스는 베이스 메모리 어드레스로부터 특정 수의 어드레스만큼 오프셋될 수 있다. 제2 버퍼에 대한 메모리 어드레스 오프셋 값은 특정 어드레스 수와 동일할 수 있다.The system determines ( 308 ) a buffer memory address offset value for the group of data elements based on the value of the buffer allocation element and the memory address offset value for the second buffer. As described above, the base memory addresses for the buffers may correspond to the first memory addresses of the first buffers. The first memory address of the second buffer may be offset from the base memory address by a certain number of addresses. The memory address offset value for the second buffer may be equal to a specific number of addresses.
데이터 엘리먼트 그룹에 대한 버퍼 메모리 어드레스 오프셋 값을 결정하기 위해, 시스템은 버퍼 할당 엘리먼트의 값이 제1 값인지 또는 제2 값인지(또는 2 개 이상의 버퍼가 있는 경우 더 많은 값)를 결정한다. 버퍼 할당 엘리먼트가 제1 값인 경우, 시스템은 데이터 엘리먼트 그룹에 대한 버퍼 메모리 어드레스 값을 결정할 때 제2 버퍼에 대한 메모리 어드레스 오프셋 값을 사용하지 않음으로써 데이터 엘리먼트 그룹을 제1 버퍼에 할당할 수 있다. 대신에, 시스템은 전술한 바와 같이, 중첩 루프의 루프 인덱스들에 기초하여 결정된 데이터 엘리먼트에 대한 메모리 오프셋 값을 사용할 수 있다.To determine the buffer memory address offset value for the group of data elements, the system determines whether the value of the buffer allocation element is a first value or a second value (or more if there are two or more buffers). When the buffer allocation element is the first value, the system may allocate the group of data elements to the first buffer by not using the memory address offset value for the second buffer when determining the buffer memory address value for the group of data elements. Instead, the system may use the memory offset value for the data element determined based on the loop indices of the nested loop, as described above.
버퍼 할당 엘리먼트가 제2 값인 경우, 시스템은 데이터 엘리먼트 그룹에 대한 메모리 오프셋 값을 제2 버퍼에 대한 메모리 어드레스 오프셋 값과 결합함으로써 제2 버퍼에 데이터 엘리먼트 그룹을 할당할 수 있다. 예를 들어, 시스템은 데이터 엘리먼트 그룹에 대한 버퍼 메모리 어드레스 오프셋 값으로서, 데이터 엘리먼트 그룹에 대한 메모리 오프셋 값과 제2 버퍼에 대한 메모리 어드레스 오프셋 값의 합을 결정할 수 있다.When the buffer allocation element is the second value, the system may allocate the data element group to the second buffer by combining the memory offset value for the data element group with the memory address offset value for the second buffer. For example, the system may determine, as the buffer memory address offset value for the data element group, a sum of the memory offset value for the data element group and the memory address offset value for the second buffer.
일부 구현예에서, 시스템은 버퍼 할당 엘리먼트의 값을 1의 값으로 논리 곱하고 그 결과를 제2 버퍼에 대한 메모리 어드레스 오프셋 값으로 승산하고, 이 결과를 데이터 엘리먼트 그룹에 대한 메모리 오프셋 값에 가산함으로써 데이터 엘리먼트 그룹에 대한 버퍼 메모리 어드레스 오프셋 값을 계산할 수 있다. 이 예에서, 버퍼 할당 엘리먼트가 0의 값을 갖는다면, 데이터 엘리먼트 그룹에 대한 버퍼 메모리 어드레스 오프셋 값은 데이터 엘리먼트 그룹에 대한 메모리 오프셋 값과 동일하다. 버퍼 할당 엘리먼트가 1의 값을 갖으면, 데이터 엘리먼트 그룹에 대한 버퍼 메모리 어드레스 오프셋 값은 제2 버퍼에 대한 메모리 어드레스 오프셋 값과 데이터 엘리먼트 그룹에 대한 메모리 오프셋 값을 더한 값을 갖는다. 일부 구현예에서, 1 비트 토글 카운터가 어떤 버퍼를 사용할지를 결정하는데 사용될 수 있다.In some implementations, the system logically multiplies the value of the buffer allocation element by a value of one, multiplies the result by the memory address offset value for the second buffer, and adds the result to the memory offset value for the group of data elements by A buffer memory address offset value for a group of elements can be calculated. In this example, if the buffer allocation element has a value of 0, the buffer memory address offset value for the data element group is equal to the memory offset value for the data element group. If the buffer allocation element has a value of 1, the buffer memory address offset value for the data element group has a value obtained by adding the memory address offset value for the second buffer and the memory offset value for the data element group. In some implementations, a 1-bit toggle counter may be used to determine which buffer to use.
시스템은 버퍼들에 대한 베이스 어드레스 및 버퍼 메모리 어드레스 오프셋 값에 기초하여 데이터 엘리먼트 그룹에 대한 버퍼 메모리 어드레스를 결정한다(310). 예를 들어, 시스템은 버퍼들에 대한 베이스 어드레스(예를 들어, 제1 버퍼에 대한 제1 메모리 어드레스)를 버퍼 메모리 어드레스 오프셋 값에 가산함으로써 데이터 엘리먼트 그룹에 대한 버퍼 메모리 어드레스를 결정할 수 있다.The system determines ( 310 ) a buffer memory address for the group of data elements based on the buffer memory address offset values and the base address for the buffers. For example, the system can determine the buffer memory address for the group of data elements by adding the base address for the buffers (eg, the first memory address for the first buffer) to the buffer memory address offset value.
시스템은 버퍼 메모리 어드레스가 시퀀스 내의 각 데이터 엘리먼트에 대해 결정되었는지 여부를 결정한다(312). 그렇지 않은 경우, 시스템은 다음 데이터 엘리먼트에 대한 버퍼 할당 엘리먼트의 값을 스위칭한다. 이 방법으로 다음 데이터 엘리먼트는 현재의 데이터 엘리먼트와 다른 버퍼에 할당된다.The system determines (312) whether a buffer memory address has been determined for each data element in the sequence. Otherwise, the system switches the value of the buffer allocation element for the next data element. In this way, the next data element is allocated in a different buffer than the current data element.
시퀀스 내의 각 데이터 엘리먼트에 대해 버퍼 메모리 어드레스가 결정되면, 시스템은 상기 결정된 버퍼 메모리 어드레스들에 기초하여 데이터 엘리먼트들에 저장된 데이터를 버퍼들로 전송한다(314). 그 다음, 데이터는 예를 들어 신경망 계산에서 사용하기 위해 버퍼로부터 제2 데이터 저장 위치로 전송될 수 있다.When a buffer memory address is determined for each data element in the sequence, the system transfers the data stored in the data elements to the buffers based on the determined buffer memory addresses ( 314 ). The data may then be transferred from the buffer to a second data storage location for use in, for example, neural network computations.
본 명세서에 설명된 주제 및 기능 동작들의 실시예들은 본 명세서에 개시된 구조 및 그의 구조적 등가물 또는 이들 중 하나 이상의 조합을 포함하여, 디지털 전자 회로, 유형적으로 구현된 컴퓨터 소프트웨어 또는 펌웨어, 컴퓨터 하드웨어에 구현될 수 있다. 본 명세서에서 설명된 주제의 실시예는 하나 이상의 컴퓨터 프로그램, 즉 데이터 처리 장치에 의해 실행되거나 또는 데이터 처리 장치의 동작을 제어하기 위안 유형의 비 일시적 프로그램 매체 상에 인코딩된 컴퓨터 프로그램 명령의 하나 이상의 모듈로서 구현될 수 있다. 대안적으로 또는 부가적으로, 프로그램 명령은 데이터 처리 장치에 의한 실행을 위해 적절한 수신기 장치로의 송신을 위해 정보를 인코딩하기 위해 생성되는 인위적으로 생성된 전파된 신호, 예를 들어, 기계-생성의 전기, 광학 또는 전자기 신호에 인코딩될 수 있다. 컴퓨터 저장 매체는 기계 판독 가능 저장 디바이스, 기계 판독 가능 저장 기판, 랜덤 또는 직렬 액세스 메모리 디바이스 또는 이들 중 하나 이상의 조합일 수 있다.Embodiments of the subject matter and functional acts described herein may be implemented in digital electronic circuitry, tangibly embodied computer software or firmware, computer hardware, including the structures disclosed herein and structural equivalents thereof, or combinations of one or more thereof. can Embodiments of the subject matter described herein are one or more computer programs, namely one or more modules of computer program instructions executed by a data processing device or encoded on a tangible non-transitory program medium for controlling the operation of the data processing device. can be implemented as Alternatively or additionally, the program instructions may include an artificially generated propagated signal, eg, a machine-generated signal, generated to encode information for transmission to a receiver device suitable for execution by a data processing device. It can be encoded in electrical, optical or electromagnetic signals. The computer storage medium may be a machine-readable storage device, a machine-readable storage substrate, a random or serial access memory device, or a combination of one or more thereof.
본 명세서에서 설명되는 프로세스 및 논리 흐름은 입력 데이터를 조작하고 출력을 생성함으로써 기능을 수행하기 위해 하나 이상의 컴퓨터 프로그램을 실행하는 하나 이상의 프로그램 가능 컴퓨터에 의해 수행될 수 있다. 프로세스와 논리 흐름은 또한 FPGA(필트 프로그래머블 게이트 어레이), ASIC(주문형 집적 회로) 또는 GPGPU(범용 그래픽 처리 장치)와 같은 특수 목적의 논리 회로로 구현될 수 있다.The processes and logic flows described herein may be performed by one or more programmable computers executing one or more computer programs to perform functions by manipulating input data and generating output. Processes and logic flows can also be implemented in special purpose logic circuits such as field programmable gate arrays (FPGAs), application specific integrated circuits (ASICs), or general purpose graphics processing units (GPGPUs).
컴퓨터 프로그램의 실행에 적합한 컴퓨터는 예를 들어 범용 또는 특수 목적 마이크로 프로세서 또는 둘 모두, 또는 임의의 다른 종류의 중앙 처리 장치를 기반으로 할 수 있다. 일반적으로, 중앙 처리 장치는 판독 전용 메모리 또는 랜덤 액세스 메모리 또는 둘 모두로부터 명령 및 데이터를 수신할 것이다. 컴퓨터의 필수 구성 요소는 명령을 수행하거나 실행하기 위한 중앙 처리 장치 및 명령 및 데이터를 저장하기 위한 하나 이상의 메모리 디바이스이다. 중앙 처리 장치 및 메모리는 특수 목적 논리 회로에 의해 보충되거나 또는 그 안에 통합될 수 있다. 일반적으로, 컴퓨터는 데이터를 저장하기 위한 하나 이상의 대용량 저장 디바이스((예를 들어, 자기, 광 자기 디스크 또는 광 디스크)로부터 데이터를 수신하거나 전송하거나 둘 모두를 하기 위해 동작 가능하게 결합될 것이다. 그러나 컴퓨터에는 이러한 디바이스들이 있을 필요가 없다. 더욱이, 컴퓨터는 다른 디바이스, 예를 들어 이동 전화, 개인 휴대 정보 단말기(PDA), 모바일 오디오 또는 비디오 플레이어, 게임 콘솔, 위성 위치 확인 시스템(GPS) 수신기 또는 휴대용 저장 디바이스(예컨대, 범용 직렬 버스(USB) 플래시 드라이브)에 내장될 수 있다. A computer suitable for the execution of a computer program may be based, for example, on a general-purpose or special-purpose microprocessor or both, or any other kind of central processing unit. In general, the central processing unit will receive instructions and data from read-only memory or random access memory or both. The essential components of a computer are a central processing unit for performing or executing instructions and one or more memory devices for storing instructions and data. The central processing unit and memory may be supplemented by or integrated into special purpose logic circuitry. Generally, a computer will be operatively coupled to receive, transmit, or both data from one or more mass storage devices (eg, magnetic, magneto-optical disks, or optical disks) for storing data. The computer does not need to have these devices, moreover, the computer may be equipped with other devices, such as mobile phones, personal digital assistants (PDAs), mobile audio or video players, game consoles, global positioning system (GPS) receivers or handhelds. It may be embedded in a storage device (eg, a universal serial bus (USB) flash drive).
컴퓨터 프로그램 명령들 및 데이터를 저장하기에 적합한 컴퓨터 판독 가능 매체는 예를 들어 반도체 메모리 장치(예컨대, EPROM, EEPROM 및 플래시 메모리 디바이스)치, 자기 디스크(예컨대, 내부 하드 디스크 또는 이동식 디스크), 광 자기 디스크, 및 CD ROM 및 DVD-ROM 디스크를 포함하여, 모든 형태의 비 휘발성 메모리, 매체 및 메모리 디바이스를 포함한다. 프로세서와 메모리는 특수 목적 논리 회로에 의해 보충되거나 또는 그 안에 포함될 수 있다.Computer readable media suitable for storing computer program instructions and data include, for example, semiconductor memory devices (eg, EPROM, EEPROM, and flash memory devices), magnetic disks (eg, internal hard disks or removable disks), magneto-optical devices. disks, and all forms of non-volatile memory, media, and memory devices, including CD ROM and DVD-ROM disks. The processor and memory may be supplemented by or included in special purpose logic circuitry.
본 명세서에서 설명된 프로세스 및 논리 흐름은 입력 데이터를 조작하고 출력을 생성함으로써 기능을 수행하기 위해 하나 이상의 컴퓨터 프로그램을 실행하는 하나 이상의 프로그램 가능 컴퓨터에 의해 수행될 수 있다. 프로세스 및 논리 흐름은 또한 특수 목적 논리 회로에 의해 수행될 수 있고, 장치는 또한 특수 목적 논리 회로 예를 들어 FPGA(필드프로그래머블 게이트 어레이) 또는 ASIC(주문형 집적 회로) 또는 GPGPU(범용 그래픽 처리 유닛)로서 구현될 수 있다. The processes and logic flows described herein may be performed by one or more programmable computers executing one or more computer programs to perform functions by manipulating input data and generating output. Processes and logic flows may also be performed by special-purpose logic circuits, and the apparatus may also be implemented as special-purpose logic circuits such as FPGAs (Field Programmable Gate Arrays) or ASICs (Application-Specific Integrated Circuits) or GPGPUs (General Purpose Graphics Processing Units). can be implemented.
본 명세서는 많은 특정 구현 세부 내용을 포함하지만, 이들은 임의의 발명의 범위 또는 청구될 수 있는 범위에 대한 제한으로서 해석되어서는 안되며, 오히려 특정 발명의 특정 실시예에 특정할 수 있는 특징들의 설명으로서 해석되어야 한다. 별도의 실시예와 관련하여 본 명세서에서 기술되는 특정 특징들은 또한 단일 실시예에서 조합하여 구현될 수 있다. 반대로, 단일 실시예와 관련하여 기술된 다양한 특징들은 또한 다수의 실시예에서 개별적으로 또는 임의의 적합한 서브 조합으로 구현될 수 있다. 게다가, 특징들은 특정 조합으로 작용하는 것으로 상기에서 설멸될 수 있고 심지어 처음에는 그러한 것으로 청구될지라도, 청구된 조합으로부터의 하나 이상의 특징은 일부 경우, 조합으로부터 제거될 수 있고, 청구된 조합은 서브 조합 또는 서브 조합의 변형으로 유도될 수 있다.While this specification contains many specific implementation details, these should not be construed as limitations on the scope of any invention or on what may be claimed, but rather as descriptions of features that may be specific to particular embodiments of a particular invention. do. Certain features that are described herein in connection with separate embodiments may also be implemented in combination in a single embodiment. Conversely, various features that are described in the context of a single embodiment may also be implemented in multiple embodiments individually or in any suitable sub-combination. Moreover, although features may be described above as acting in a particular combination and even initially claimed as such, one or more features from a claimed combination may in some cases be eliminated from the combination, and the claimed combination may be a sub-combination or It can be induced by modification of sub-combinations.
유사하게, 동작들이 특정 순서로 도면에 도시되고 청구항들에 인용되어 있지만, 이는 바람직한 결과를 달성하기 위해 이러한 동작들이 도시된 순서 또는 시계열적 순서로 수행되거나 모든 도시된 동작이 수행될 것을 요구하는 것으로 이해되어서는 안된다. 특정 환경에서, 멀티태스킹과 병렬 처리가 유리할 수 있다. 게다가, 상술한 실시예에서 다양한 시스템 모듈들 및 컴포넌트들의 분리는 모든 실시예에서 그러한 분리가 필요한 것으로서 이해되어서는 안되며, 설명된 프로그램 컴포넌트들 및 시스템들은 일반적으로 단일의 소프트웨어 제품에 함께 포함되거나 다수의 소프트웨어 제품들에 패키징될 수 있음을 이해해야 한다.Similarly, although acts are shown in the drawings and recited in the claims in a particular order, this is to be interpreted as requiring that such acts be performed in the order shown or chronological order or that all shown acts be performed in order to achieve a desirable result. should not be understood In certain circumstances, multitasking and parallel processing can be advantageous. Moreover, the separation of various system modules and components in the above-described embodiments should not be construed as requiring such separation in all embodiments, and the described program components and systems are generally included together in a single software product or are It should be understood that they may be packaged into software products.
주제의 특정 실시예들이 설명되었다. 다른 실시예들도 다음의 청구항들의 범위 내에 있다. 예를 들면, 청구항들에 인용된 액션들은 상이한 순서로 수행되고 여전히 바림직한 결과를 달성할 수 있다. 일 예로, 첨부 도면들에 도시된 프로세스들은 바람직한 결과를 달성하기 위해 도시된 특정 순서 또는 시계열적 순서를 반드시 필요로 하지는 않는다. 특정 구현예에서, 멀티태스킹 및 병렬 처리가 유리할 수 있다.Certain embodiments of the subject matter have been described. Other embodiments are within the scope of the following claims. For example, the actions recited in the claims may be performed in a different order and still achieve a desired result. As an example, the processes shown in the accompanying drawings do not necessarily require the specific order shown or chronological order to achieve desirable results. In certain implementations, multitasking and parallel processing may be advantageous.
Claims (20)
복수의 메모리; 및
하나 이상의 프로세서를 포함하고, 상기 하나 이상의 프로세서는:
제2 데이터 저장 위치로 전송되는 제1 데이터 저장 위치에 저장된 N 차원 텐서의 데이터에 대한 버퍼 메모리 어드레스를 결정하고, N은 2 이상의 정수이고, 상기 결정하는 동작은:
복수의 메모리 중 다른 하나에 각각 대응하는 복수의 값 사이에서 스위칭될 수 있는 버퍼 할당 엘리먼트의 현재 값을 식별하는 동작; 및
버퍼 할당 엘리먼트의 현재 값에 대응하는 메모리가 가득 찰 때까지 버퍼 할당 엘리먼트의 현재 값에 대응하는 메모리에 N 차원 텐서의 데이터의 제1 부분을 할당하는 동작을 포함하고, 상기 할당하는 동작은:
적어도 (i) 복수의 메모리에 대한 기본(base) 어드레스, (ii) 버퍼 할당 엘리먼트의 현재 값에 대응하는 메모리에 대한 메모리 어드레스 오프셋 값, 및 (iii) 데이터 엘리먼트에 대한 메모리 오프셋 값의 조합에 기초하여 데이터의 제1 부분의 각 데이터 엘리먼트에 대한 버퍼 메모리 어드레스를 결정하는 동작을 포함하고, 각 데이터 엘리먼트에 대한 메모리 오프셋 값은 N 차원 텐서를 트래버스하는데 사용되는 루프 중첩(loop nest)내의 다중 루프의 현재 인덱스 값에 기초하고;
각 데이터 엘리먼트에 대해 상기 결정된 버퍼 메모리 어드레스를 사용하여 버퍼 할당 엘리먼트의 현재 값에 대응하는 메모리의 개별 메모리 위치로 N 차원 텐서의 데이터의 제1 부분을 전송하고; 그리고
N 차원 텐서의 데이터의 다음(next) 부분에 대한 버퍼 메모리 어드레스를 결정하기 전에 버퍼 할당 엘리먼트의 값을 스위칭하는 것을 특징으로 하는 데이터 전송 장치. A data transmission device comprising:
a plurality of memories; and
one or more processors, the one or more processors comprising:
Determine a buffer memory address for data of an N-dimensional tensor stored in a first data storage location to be transferred to a second data storage location, where N is an integer greater than or equal to 2, the determining operation includes:
identifying a current value of a buffer allocation element that can be switched between a plurality of values each corresponding to a different one of the plurality of memories; and
allocating a first portion of the data of the N-dimensional tensor in a memory corresponding to the current value of the buffer allocation element until the memory corresponding to the current value of the buffer allocation element is full, wherein the allocating operation comprises:
based on a combination of at least (i) a base address for the plurality of memories, (ii) a memory address offset value for the memory corresponding to the current value of the buffer allocation element, and (iii) a memory offset value for the data element. determining a buffer memory address for each data element of the first portion of data, wherein the memory offset value for each data element is used to traverse the N-dimensional tensor of multiple loops in a loop nest. based on the current index value;
transferring the first portion of the data of the N-dimensional tensor to a respective memory location in memory corresponding to the current value of the buffer allocation element using the determined buffer memory address for each data element; and
and switching the value of the buffer allocation element before determining the buffer memory address for the next portion of the data of the N-dimensional tensor.
상기 하나 이상의 프로세서는,
버퍼 할당 엘리먼트의 현재 값에 대응하는 메모리가 가득 찼다는 결정에 응답하여 버퍼 할당 엘리먼트의 값을 스위칭하도록 배열되는 것을 특징으로 하는 데이터 전송 장치.According to claim 1,
The one or more processors,
and switch the value of the buffer allocation element in response to determining that the memory corresponding to the current value of the buffer allocation element is full.
상기 메모리들 중 하나에 대한 메모리 어드레스 오프셋 값은 0이고, 각각의 다른 메모리에 대한 메모리 어드레스 오프셋 값은 0이 아닌 것을 특징으로 하는 데이터 전송 장치.According to claim 1,
and a memory address offset value for one of the memories is zero, and a memory address offset value for each other memory is non-zero.
상기 복수의 메모리의 각 메모리는 각각 제1 데이터 저장 용량을 갖는 버퍼이고; 그리고
상기 제1 데이터 저장 위치 및 제2 데이터 저장 위치 각각은 제1 데이터 저장 용량보다 큰 적어도 제2 데이터 저장 용량을 포함하는 것을 특징으로 하는 데이터 전송 장치.According to claim 1,
each memory of the plurality of memories is a buffer each having a first data storage capacity; and
and each of the first data storage location and the second data storage location includes at least a second data storage capacity greater than the first data storage capacity.
각 데이터 엘리먼트에 대한 메모리 오프셋 값은,
N 차원 텐서의 각 차원에 대한 루프의 반복 횟수에 기초하는 것을 특징으로 하는 데이터 전송 장치.According to claim 1,
The memory offset value for each data element is
A data transmission device, characterized in that it is based on the number of iterations of the loop for each dimension of the N-dimensional tensor.
상기 하나 이상의 프로세서는,
N 차원 텐서의 데이터의 제1 부분을 버퍼 할당 엘리먼트의 현재 값에 대응하는 메모리의 개별 메모리 위치로부터 제2 데이터 저장 위치로 전송하도록 배열되는 것을 특징으로 하는 데이터 전송 장치.According to claim 1,
The one or more processors,
and transferring the first portion of the data of the N-dimensional tensor from a respective memory location in the memory corresponding to the current value of the buffer allocation element to a second data storage location.
상기 버퍼 할당 엘리먼트의 값은 버퍼 할당 엘리먼트의 값을 스위칭하는데 사용되는 루프의 루프 변수이고; 그리고
상기 N 차원 텐서의 데이터의 다음 부분에 대한 버퍼 메모리 어드레스를 결정하기 전에 버퍼 할당 엘리먼트의 값을 스위칭하는 동작은,
버퍼 할당 엘리먼트의 현재 값에 대응하는 메모리가 가득 찼다는 결정에 응답하여 루프 변수를 반복하는 동작을 포함하는 것을 특징으로 하는 데이터 전송 장치. According to claim 1,
the value of the buffer allocation element is a loop variable of the loop used to switch the value of the buffer allocation element; and
The operation of switching the value of the buffer allocation element before determining the buffer memory address for the next part of the data of the N-dimensional tensor comprises:
and repeating the loop variable in response to determining that the memory corresponding to the current value of the buffer allocation element is full.
제2 데이터 저장 위치로 전송되는 제1 데이터 저장 위치에 저장된 N 차원 텐서의 데이터에 대한 버퍼 메모리 어드레스를 결정하는 단계와, N은 2 이상의 정수이고, 상기 결정하는 단계는:
복수의 메모리 중 다른 하나에 각각 대응하는 복수의 값 사이에서 스위칭될 수 있는 버퍼 할당 엘리먼트의 현재 값을 식별하는 단계; 및
버퍼 할당 엘리먼트의 현재 값에 대응하는 메모리가 가득 찰 때까지 버퍼 할당 엘리먼트의 현재 값에 대응하는 메모리에 N 차원 텐서의 데이터의 제1 부분을 할당하는 단계를 포함하고, 상기 할당하는 단계는:
적어도 (i) 복수의 메모리에 대한 기본 어드레스, (ii) 버퍼 할당 엘리먼트의 현재 값에 대응하는 메모리에 대한 메모리 어드레스 오프셋 값, 및 (iii) 데이터 엘리먼트에 대한 메모리 오프셋 값의 조합에 기초하여 데이터의 제1 부분의 각 데이터 엘리먼트에 대한 버퍼 메모리 어드레스를 결정하는 단계를 포함하고, 각 데이터 엘리먼트에 대한 메모리 오프셋 값은 N 차원 텐서를 트래버스하는데 사용되는 루프 중첩내의 다중 루프의 현재 인덱스 값에 기초하고;
각 데이터 엘리먼트에 대해 상기 결정된 버퍼 메모리 어드레스를 사용하여 버퍼 할당 엘리먼트의 현재 값에 대응하는 메모리의 개별 메모리 위치로 N 차원 텐서의 데이터의 제1 부분을 전송하는 단계와; 그리고
N 차원 텐서의 데이터의 다음 부분에 대한 버퍼 메모리 어드레스를 결정하기 전에 버퍼 할당 엘리먼트의 값을 스위칭하는 단계를 포함하는 것을 특징으로 하는 컴퓨팅 시스템에 의해 수행되는 방법. A method performed by a computing system for transmitting data, the method comprising:
determining a buffer memory address for data of an N-dimensional tensor stored in a first data storage location to be transferred to a second data storage location, wherein N is an integer greater than or equal to 2, the determining comprising:
identifying a current value of a buffer allocation element that can be switched between a plurality of values each corresponding to a different one of the plurality of memories; and
allocating a first portion of the data of the N-dimensional tensor in a memory corresponding to the current value of the buffer allocation element until the memory corresponding to the current value of the buffer allocation element is full, wherein the allocating comprises:
at least (i) a base address for the plurality of memories, (ii) a memory address offset value for the memory corresponding to the current value of the buffer allocation element, and (iii) a memory offset value for the data element. determining a buffer memory address for each data element of the first portion, wherein the memory offset value for each data element is based on a current index value of multiple loops in the loop overlap used to traverse the N-dimensional tensor;
transferring the first portion of the data in the N-dimensional tensor to a respective memory location in memory corresponding to the current value of the buffer allocation element using the determined buffer memory address for each data element; and
and switching the value of the buffer allocation element prior to determining the buffer memory address for the next portion of the data in the N-dimensional tensor.
상기 버퍼 할당 엘리먼트의 값은 버퍼 할당 엘리먼트의 현재 값에 대응하는 메모리가 가득 찼다는 결정에 응답하여 스위칭되는 것을 특징으로 하는 컴퓨팅 시스템에 의해 수행되는 방법.9. The method of claim 8,
and the value of the buffer allocation element is switched in response to determining that the memory corresponding to the current value of the buffer allocation element is full.
상기 메모리들 중 하나에 대한 메모리 어드레스 오프셋 값은 0이고, 각각의 다른 메모리에 대한 메모리 어드레스 오프셋 값은 0이 아닌 것을 특징으로 하는 컴퓨팅 시스템에 의해 수행되는 방법.9. The method of claim 8,
and a memory address offset value for one of said memories is zero and a memory address offset value for each other memory is non-zero.
상기 복수의 메모리의 각 메모리는 각각 제1 데이터 저장 용량을 갖는 버퍼이고; 그리고
상기 제1 데이터 저장 위치 및 제2 데이터 저장 위치 각각은 제1 데이터 저장 용량보다 큰 적어도 제2 데이터 저장 용량을 포함하는 것을 특징으로 하는 컴퓨팅 시스템에 의해 수행되는 방법.9. The method of claim 8,
each memory of the plurality of memories is a buffer each having a first data storage capacity; and
wherein each of the first data storage location and the second data storage location includes at least a second data storage capacity that is greater than the first data storage capacity.
각 데이터 엘리먼트에 대한 메모리 오프셋 값은,
N 차원 텐서의 각 차원에 대한 루프의 반복 횟수에 기초하는 것을 특징으로 하는 컴퓨팅 시스템에 의해 수행되는 방법.9. The method of claim 8,
The memory offset value for each data element is
A method performed by a computing system, wherein the method is based on the number of iterations of the loop for each dimension of the N-dimensional tensor.
N 차원 텐서의 데이터의 제1 부분을 버퍼 할당 엘리먼트의 현재 값에 대응하는 메모리의 개별 메모리 위치로부터 제2 데이터 저장 위치로 전송하는 단계를 더 포함하는 것을 특징으로 하는 컴퓨팅 시스템에 의해 수행되는 방법.9. The method of claim 8,
and transferring the first portion of the data of the N-dimensional tensor from a respective memory location in the memory corresponding to the current value of the buffer allocation element to a second data storage location.
상기 버퍼 할당 엘리먼트의 값은 버퍼 할당 엘리먼트의 값을 스위칭하는데 사용되는 루프의 루프 변수이고; 그리고
상기 N 차원 텐서의 데이터의 다음 부분에 대한 버퍼 메모리 어드레스를 결정하기 전에 버퍼 할당 엘리먼트의 값을 스위칭하는 단계는,
버퍼 할당 엘리먼트의 현재 값에 대응하는 메모리가 가득 찼다는 결정에 응답하여 루프 변수를 반복하는 단계를 포함하는 것을 특징으로 하는 컴퓨팅 시스템에 의해 수행되는 방법. 9. The method of claim 8,
the value of the buffer allocation element is a loop variable of the loop used to switch the value of the buffer allocation element; and
Switching the value of the buffer allocation element before determining the buffer memory address for the next portion of the data in the N-dimensional tensor comprises:
and iterating through the loop variable in response to determining that the memory corresponding to the current value of the buffer allocation element is full.
복수의 메모리; 및
하나 이상의 연산 유닛을 포함하는 하나 이상의 처리 유닛으로서, 상기 하나 이상의 처리 유닛은:
제2 데이터 저장 위치로 전송되는 제1 데이터 저장 위치에 저장된 N 차원 텐서의 데이터에 대한 버퍼 메모리 어드레스를 결정하고, N은 2 이상의 정수이고, 상기 결정하는 동작은:
복수의 메모리 중 다른 하나에 각각 대응하는 복수의 값 사이에서 스위칭될 수 있는 버퍼 할당 엘리먼트의 현재 값을 식별하는 동작; 및
버퍼 할당 엘리먼트의 현재 값에 대응하는 메모리가 가득 찰 때까지 버퍼 할당 엘리먼트의 현재 값에 대응하는 메모리에 N 차원 텐서의 데이터의 제1 부분을 할당하는 동작을 포함하고, 상기 할당하는 동작은:
적어도 (i) 복수의 메모리에 대한 기본 어드레스, (ii) 버퍼 할당 엘리먼트의 현재 값에 대응하는 메모리에 대한 메모리 어드레스 오프셋 값, 및 (iii) 데이터 엘리먼트에 대한 메모리 오프셋 값의 조합에 기초하여 데이터의 제1 부분의 각 데이터 엘리먼트에 대한 버퍼 메모리 어드레스를 결정하는 동작을 포함하고, 각 데이터 엘리먼트에 대한 메모리 오프셋 값은 N 차원 텐서를 트래버스하는데 사용되는 루프 중첩내의 다중 루프의 현재 인덱스 값에 기초하고;
각 데이터 엘리먼트에 대해 상기 결정된 버퍼 메모리 어드레스를 사용하여 버퍼 할당 엘리먼트의 현재 값에 대응하는 메모리의 개별 메모리 위치로 N 차원 텐서의 데이터의 제1 부분을 전송하고; 그리고
N 차원 텐서의 데이터의 다음 부분에 대한 버퍼 메모리 어드레스를 결정하기 전에 버퍼 할당 엘리먼트의 값을 스위칭하도록 구성되는 것을 특징으로 하는 데이터 전송 시스템. A data transmission system comprising:
a plurality of memories; and
One or more processing units comprising one or more computational units, the one or more processing units comprising:
Determine a buffer memory address for data of an N-dimensional tensor stored in a first data storage location to be transferred to a second data storage location, where N is an integer greater than or equal to 2, the determining operation includes:
identifying a current value of a buffer allocation element that can be switched between a plurality of values each corresponding to a different one of the plurality of memories; and
allocating a first portion of the data of the N-dimensional tensor in a memory corresponding to the current value of the buffer allocation element until the memory corresponding to the current value of the buffer allocation element is full, wherein the allocating operation comprises:
at least (i) a base address for the plurality of memories, (ii) a memory address offset value for the memory corresponding to the current value of the buffer allocation element, and (iii) a memory offset value for the data element. determining a buffer memory address for each data element of the first portion, wherein the memory offset value for each data element is based on a current index value of multiple loops in the loop overlap used to traverse the N-dimensional tensor;
transferring the first portion of the data of the N-dimensional tensor to a respective memory location in memory corresponding to the current value of the buffer allocation element using the determined buffer memory address for each data element; and
and switch the value of the buffer allocation element before determining the buffer memory address for the next portion of the data in the N-dimensional tensor.
상기 하나 이상의 처리 유닛은,
버퍼 할당 엘리먼트의 현재 값에 대응하는 메모리가 가득 찼다는 결정에 응답하여 버퍼 할당 엘리먼트의 값을 스위칭하도록 배열되는 것을 특징으로 하는 데이터 전송 시스템.16. The method of claim 15,
the one or more processing units,
and switch the value of the buffer allocation element in response to determining that the memory corresponding to the current value of the buffer allocation element is full.
상기 메모리들 중 하나에 대한 메모리 어드레스 오프셋 값은 0이고, 각각의 다른 메모리에 대한 메모리 어드레스 오프셋 값은 0이 아닌 것을 특징으로 하는 데이터 전송 시스템.16. The method of claim 15,
and a memory address offset value for one of said memories is zero and a memory address offset value for each other memory is non-zero.
상기 복수의 메모리의 각 메모리는 각각 제1 데이터 저장 용량을 갖는 버퍼이고; 그리고
상기 제1 데이터 저장 위치 및 제2 데이터 저장 위치 각각은 제1 데이터 저장 용량보다 큰 적어도 제2 데이터 저장 용량을 포함하는 것을 특징으로 하는 데이터 전송 시스템.16. The method of claim 15,
each memory of the plurality of memories is a buffer each having a first data storage capacity; and
wherein each of the first data storage location and the second data storage location includes at least a second data storage capacity greater than the first data storage capacity.
각 데이터 엘리먼트에 대한 메모리 오프셋 값은,
N 차원 텐서의 각 차원에 대한 루프의 반복 횟수에 기초하는 것을 특징으로 하는 데이터 전송 시스템.16. The method of claim 15,
The memory offset value for each data element is
A data transfer system, characterized in that it is based on the number of iterations of the loop for each dimension of the N-dimensional tensor.
상기 버퍼 할당 엘리먼트의 값은 버퍼 할당 엘리먼트의 값을 스위칭하는데 사용되는 루프의 루프 변수이고; 그리고
상기 N 차원 텐서의 데이터의 다음 부분에 대한 버퍼 메모리 어드레스를 결정하기 전에 버퍼 할당 엘리먼트의 값을 스위칭하는 동작은,
버퍼 할당 엘리먼트의 현재 값에 대응하는 메모리가 가득 찼다는 결정에 응답하여 루프 변수를 반복하는 동작을 포함하는 것을 특징으로 하는 데이터 전송 시스템.16. The method of claim 15,
the value of the buffer allocation element is a loop variable of the loop used to switch the value of the buffer allocation element; and
The operation of switching the value of the buffer allocation element before determining the buffer memory address for the next part of the data of the N-dimensional tensor comprises:
and repeating the loop variable in response to determining that the memory corresponding to the current value of the buffer allocation element is full.
Applications Claiming Priority (4)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US15/641,824 US10175912B1 (en) | 2017-07-05 | 2017-07-05 | Hardware double buffering using a special purpose computational unit |
US15/641,824 | 2017-07-05 | ||
PCT/US2018/038009 WO2019009993A1 (en) | 2017-07-05 | 2018-06-18 | Hardware double buffering using a special purpose computational unit |
KR1020197015789A KR102309522B1 (en) | 2017-07-05 | 2018-06-18 | Hardware double buffering using special-purpose compute units |
Related Parent Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
KR1020197015789A Division KR102309522B1 (en) | 2017-07-05 | 2018-06-18 | Hardware double buffering using special-purpose compute units |
Publications (2)
Publication Number | Publication Date |
---|---|
KR20210119584A true KR20210119584A (en) | 2021-10-05 |
KR102335909B1 KR102335909B1 (en) | 2021-12-06 |
Family
ID=62981308
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
KR1020217030911A KR102335909B1 (en) | 2017-07-05 | 2018-06-18 | Hardware double buffering using a special purpose computational unit |
KR1020197015789A KR102309522B1 (en) | 2017-07-05 | 2018-06-18 | Hardware double buffering using special-purpose compute units |
Family Applications After (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
KR1020197015789A KR102309522B1 (en) | 2017-07-05 | 2018-06-18 | Hardware double buffering using special-purpose compute units |
Country Status (7)
Country | Link |
---|---|
US (3) | US10175912B1 (en) |
EP (2) | EP3686743A1 (en) |
JP (3) | JP7062659B2 (en) |
KR (2) | KR102335909B1 (en) |
CN (2) | CN110036374B (en) |
TW (3) | TWI777442B (en) |
WO (1) | WO2019009993A1 (en) |
Families Citing this family (10)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10175912B1 (en) | 2017-07-05 | 2019-01-08 | Google Llc | Hardware double buffering using a special purpose computational unit |
US10936942B2 (en) * | 2017-11-21 | 2021-03-02 | Google Llc | Apparatus and mechanism for processing neural network tasks using a single chip package with multiple identical dies |
CN111324294B (en) * | 2018-12-17 | 2023-11-07 | 地平线(上海)人工智能技术有限公司 | Method and device for accessing tensor data |
US11748599B2 (en) * | 2019-02-21 | 2023-09-05 | Texas Instruments Incorporated | Super-tiling in neural network processing to enable analytics at lower memory speed |
CN111756940A (en) * | 2020-07-07 | 2020-10-09 | 广州威谱通信设备有限公司 | Simplified digital voice communication system with programmable addressing and double-input sound mixing |
US11954580B2 (en) | 2020-09-16 | 2024-04-09 | Meta Platforms, Inc. | Spatial tiling of compute arrays with shared control |
US11704562B1 (en) | 2020-11-04 | 2023-07-18 | Meta Platforms, Inc. | Architecture for virtual instructions |
US11709783B1 (en) | 2020-11-11 | 2023-07-25 | Meta Platforms, Inc. | Tensor data distribution using grid direct-memory access (DMA) controller |
US11972349B1 (en) | 2020-11-12 | 2024-04-30 | Meta Platforms, Inc. | Flexible compute array utilization in a tensor processor |
US11922306B2 (en) | 2020-12-28 | 2024-03-05 | Meta Platforms, Inc. | Tensor controller architecture |
Citations (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4910683A (en) * | 1988-12-20 | 1990-03-20 | Sun Microsystems, Inc. | Method and apparatus for fractional double buffering |
US5163132A (en) * | 1987-09-24 | 1992-11-10 | Ncr Corporation | Integrated controller using alternately filled and emptied buffers for controlling bi-directional data transfer between a processor and a data storage device |
US6332186B1 (en) * | 1998-05-27 | 2001-12-18 | Arm Limited | Vector register addressing |
EP1367493A1 (en) * | 2002-05-30 | 2003-12-03 | STMicroelectronics Limited | Prefetch buffer |
US20100281192A1 (en) * | 2009-04-30 | 2010-11-04 | Novafora, Inc. | Apparatus and method for transferring data within a data processing system |
US20130238821A1 (en) * | 2012-03-06 | 2013-09-12 | Lsi Corporation | Methods and apparatus for packing received frames in buffers in a serial attached scsi (sas) device |
Family Cites Families (21)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JPH02132566A (en) * | 1988-11-14 | 1990-05-22 | Toshiba Corp | Image data transferring device |
JPH03131951A (en) * | 1989-10-18 | 1991-06-05 | Fujitsu Ltd | Data transfer system |
JPH0553982A (en) * | 1991-08-28 | 1993-03-05 | Nec Corp | Memory control circuit |
DE69727465T2 (en) * | 1997-01-09 | 2004-12-23 | Hewlett-Packard Co. (N.D.Ges.D.Staates Delaware), Palo Alto | Computer system with memory control for burst mode transmission |
US6363470B1 (en) | 1998-10-06 | 2002-03-26 | Texas Instruments Incorporated | Circular buffer management |
JP2001022950A (en) | 1999-05-20 | 2001-01-26 | Mitsubishi Electric Inf Technol Center America Inc | Volume rendering graphic board |
US7155570B1 (en) | 2000-09-29 | 2006-12-26 | Intel Corporation | FIFO write/LIFO read trace buffer with software and hardware loop compression |
JP2002182925A (en) | 2000-12-12 | 2002-06-28 | Hitachi Ltd | Compiling method and computer readable recording medium |
JP2002254729A (en) | 2001-03-02 | 2002-09-11 | Sharp Corp | Dma controller for image data |
JP4004389B2 (en) | 2002-11-27 | 2007-11-07 | 富士通株式会社 | Buffer memory management method and system |
US6931497B2 (en) | 2003-01-09 | 2005-08-16 | Emulex Design & Manufacturing Corporation | Shared memory management utilizing a free list of buffer indices |
GB0313986D0 (en) | 2003-06-17 | 2003-07-23 | Zarlink Semiconductor Inc | Data memory extension for use in double buffered TDM switches |
US20080270332A1 (en) * | 2003-08-26 | 2008-10-30 | Paul Rudolf | Associative Memory Device and Method Based on Wave Propagation |
JP2006301724A (en) * | 2005-04-15 | 2006-11-02 | Seiko Epson Corp | Memory controller, image processing controller and electronic equipment |
US7864864B2 (en) | 2005-06-27 | 2011-01-04 | Intel Corporation | Context buffer address determination using a plurality of modular indexes |
JP2011039302A (en) | 2009-08-11 | 2011-02-24 | Seiko Epson Corp | Buffer control circuit, display controller and electronic apparatus |
US8458377B2 (en) * | 2010-03-05 | 2013-06-04 | Lsi Corporation | DMA engine capable of concurrent data manipulation |
US20140188961A1 (en) * | 2012-12-27 | 2014-07-03 | Mikhail Plotnikov | Vectorization Of Collapsed Multi-Nested Loops |
US10726328B2 (en) * | 2015-10-09 | 2020-07-28 | Altera Corporation | Method and apparatus for designing and implementing a convolution neural net accelerator |
US9875104B2 (en) | 2016-02-03 | 2018-01-23 | Google Llc | Accessing data in multi-dimensional tensors |
US10175912B1 (en) | 2017-07-05 | 2019-01-08 | Google Llc | Hardware double buffering using a special purpose computational unit |
-
2017
- 2017-07-05 US US15/641,824 patent/US10175912B1/en active Active
-
2018
- 2018-06-18 EP EP20162095.2A patent/EP3686743A1/en not_active Withdrawn
- 2018-06-18 KR KR1020217030911A patent/KR102335909B1/en active IP Right Grant
- 2018-06-18 JP JP2019530793A patent/JP7062659B2/en active Active
- 2018-06-18 KR KR1020197015789A patent/KR102309522B1/en active IP Right Grant
- 2018-06-18 WO PCT/US2018/038009 patent/WO2019009993A1/en unknown
- 2018-06-18 EP EP18743611.8A patent/EP3529701B1/en active Active
- 2018-06-18 CN CN201880004800.7A patent/CN110036374B/en active Active
- 2018-06-18 CN CN202310201075.5A patent/CN116303111A/en active Pending
- 2018-07-05 TW TW110108162A patent/TWI777442B/en active
- 2018-07-05 TW TW108128281A patent/TWI722526B/en active
- 2018-07-05 TW TW107123234A patent/TWI671633B/en active
-
2019
- 2019-01-04 US US16/240,459 patent/US10496326B2/en active Active
- 2019-12-02 US US16/700,385 patent/US11099772B2/en active Active
-
2022
- 2022-04-20 JP JP2022069548A patent/JP7379581B2/en active Active
-
2023
- 2023-11-01 JP JP2023187546A patent/JP2024020270A/en active Pending
Patent Citations (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5163132A (en) * | 1987-09-24 | 1992-11-10 | Ncr Corporation | Integrated controller using alternately filled and emptied buffers for controlling bi-directional data transfer between a processor and a data storage device |
US4910683A (en) * | 1988-12-20 | 1990-03-20 | Sun Microsystems, Inc. | Method and apparatus for fractional double buffering |
US6332186B1 (en) * | 1998-05-27 | 2001-12-18 | Arm Limited | Vector register addressing |
EP1367493A1 (en) * | 2002-05-30 | 2003-12-03 | STMicroelectronics Limited | Prefetch buffer |
US20100281192A1 (en) * | 2009-04-30 | 2010-11-04 | Novafora, Inc. | Apparatus and method for transferring data within a data processing system |
US20130238821A1 (en) * | 2012-03-06 | 2013-09-12 | Lsi Corporation | Methods and apparatus for packing received frames in buffers in a serial attached scsi (sas) device |
Non-Patent Citations (1)
Title |
---|
Xuechao Wei et al., "Automated systolic array architecture synthesis for high throughput CNN inference on FPGAs", 2017 ACM/EDAC/IEEE Design Automation Conference, pp. 1-6, 18 June 2017. * |
Also Published As
Publication number | Publication date |
---|---|
TWI671633B (en) | 2019-09-11 |
CN116303111A (en) | 2023-06-23 |
US20200183612A1 (en) | 2020-06-11 |
EP3686743A1 (en) | 2020-07-29 |
JP7062659B2 (en) | 2022-05-06 |
WO2019009993A1 (en) | 2019-01-10 |
KR20190073535A (en) | 2019-06-26 |
JP7379581B2 (en) | 2023-11-14 |
TWI722526B (en) | 2021-03-21 |
KR102335909B1 (en) | 2021-12-06 |
US20190012112A1 (en) | 2019-01-10 |
TW201908977A (en) | 2019-03-01 |
CN110036374A (en) | 2019-07-19 |
EP3529701A1 (en) | 2019-08-28 |
US20190138243A1 (en) | 2019-05-09 |
US11099772B2 (en) | 2021-08-24 |
US10496326B2 (en) | 2019-12-03 |
JP2024020270A (en) | 2024-02-14 |
TW201945937A (en) | 2019-12-01 |
EP3529701B1 (en) | 2020-03-11 |
JP2020506453A (en) | 2020-02-27 |
TW202131194A (en) | 2021-08-16 |
US10175912B1 (en) | 2019-01-08 |
CN110036374B (en) | 2023-03-10 |
JP2022106815A (en) | 2022-07-20 |
KR102309522B1 (en) | 2021-10-07 |
TWI777442B (en) | 2022-09-11 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
KR102335909B1 (en) | Hardware double buffering using a special purpose computational unit | |
KR102261768B1 (en) | Alternative loop limit | |
US11537687B2 (en) | Spatial locality transform of matrices | |
JP7051895B2 (en) | Accessing data in a multidimensional tensor using an adder | |
US11836971B2 (en) | Method and device with convolution neural network processing |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
A107 | Divisional application of patent | ||
E701 | Decision to grant or registration of patent right | ||
GRNT | Written decision to grant |