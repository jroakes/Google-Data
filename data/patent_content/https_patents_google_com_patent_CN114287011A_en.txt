CN114287011A - Non-coding machine learning pipeline - Google Patents
Non-coding machine learning pipeline Download PDFInfo
- Publication number
- CN114287011A CN114287011A CN202080059784.9A CN202080059784A CN114287011A CN 114287011 A CN114287011 A CN 114287011A CN 202080059784 A CN202080059784 A CN 202080059784A CN 114287011 A CN114287011 A CN 114287011A
- Authority
- CN
- China
- Prior art keywords
- machine learning
- user
- gui
- learning model
- receiving
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0481—Interaction techniques based on graphical user interfaces [GUI] based on specific properties of the displayed interaction object or a metaphor-based environment, e.g. interaction with desktop elements like windows or icons, or assisted by a cursor's changing behaviour or appearance
- G06F3/04817—Interaction techniques based on graphical user interfaces [GUI] based on specific properties of the displayed interaction object or a metaphor-based environment, e.g. interaction with desktop elements like windows or icons, or assisted by a cursor's changing behaviour or appearance using icons
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0481—Interaction techniques based on graphical user interfaces [GUI] based on specific properties of the displayed interaction object or a metaphor-based environment, e.g. interaction with desktop elements like windows or icons, or assisted by a cursor's changing behaviour or appearance
- G06F3/0482—Interaction with lists of selectable items, e.g. menus
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0484—Interaction techniques based on graphical user interfaces [GUI] for the control of specific functions or operations, e.g. selecting or manipulating an object, an image or a displayed text element, setting a parameter value or selecting a range
- G06F3/0486—Drag-and-drop
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F8/00—Arrangements for software engineering
- G06F8/30—Creation or generation of source code
- G06F8/34—Graphical or visual programming
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N20/00—Machine learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/045—Combinations of networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/10—Interfaces, programming languages or software development kits, e.g. for simulating neural networks
- G06N3/105—Shells for specifying net layout
Abstract
A method (500) includes receiving, by a GUI (200,400), a user selection of a mode button (226) displayed in the GUI, wherein the mode button, when selected, causes the GUI to display a first set of user-selectable buttons (402) corresponding to respective machine learning routines (308), and the mode button, when not selected, causes the GUI to display a second set of user-selectable buttons (208) corresponding to respective machine learning subroutines (310). In response to receiving a user selection of a mode button, the method further comprises: the method includes displaying a first set of user-selectable buttons, receiving a user selection of one or more of the first set of user-selectable buttons, displaying a graphical representation of a machine learning model (414), the machine learning model (414) defined by one or more machine learning routines corresponding to the user selection of the one or more of the first set of user-selectable buttons, generating a file representing the machine learning model.
Description
Technical Field
This specification relates to cloud computing.
Background
A cloud computing system may provide access to various computing resources. For example, a cloud computing system may store data for a client device that is accessible by multiple different devices, allow multiple different client devices to access a single application executing on the cloud, and provide access to other computer resources.
Disclosure of Invention
The present specification describes a cloud computing non-coded machine learning pipeline (pipeline) for building, executing and publishing machine learning models.
In general, one innovative aspect of the subject matter described in this specification can be embodied in a computer-implemented method that includes providing a Graphical User Interface (GUI) for generating a machine learning model; receiving, via the GUI, a user selection of a mode button displayed in the GUI, wherein the mode button, when selected, causes the GUI to display a first set of user-selectable buttons corresponding to respective machine learning subroutines (routines), and when not selected, causes the GUI to display a second set of user-selectable buttons corresponding to respective machine learning subroutines (sub-routines), wherein a machine learning routine comprises a respective plurality of connected machine learning subroutines; in response to receiving a user selection of a mode button, displaying a first set of user selectable buttons in the GUI; receiving, via the GUI, a user selection of one or more of the first set of user-selectable buttons; displaying, in the GUI, a graphical representation of a machine learning model defined by one or more machine learning routines corresponding to one or more of the first set of user-selectable buttons selected by the user, and generating a file representing the machine learning model.
Other embodiments of these aspects include corresponding computer systems, apparatus, and computer programs recorded on one or more computer storage devices, each configured to perform the actions of the described methods. A system of one or more classical and/or quantum computers may be configured to perform particular operations or actions by installing software, firmware, hardware, or a combination thereof on the system that in operation causes or causes the system to perform the actions. One or more computer programs may be configured to perform particular operations or actions by including instructions that, when executed by a data processing apparatus, cause the apparatus to perform the actions.
The foregoing embodiments and other embodiments may each optionally include one or more of the following features, either alone or in combination. In some embodiments, the machine learning subroutine includes a data formatting algorithm, a data splitting algorithm, a feature selection algorithm, a machine learning training algorithm, a machine learning evaluation algorithm, or a statistical algorithm.
In some implementations, each user-selectable button of the first set of user-selectable buttons represents a wrapper file corresponding to a machine learning routine and includes a respective plurality of connected machine learning subroutines.
In some embodiments, the method further includes receiving, via the GUI, a user selection of a source code button displayed in the GUI; in response to a user selection of a source code button, displaying source code representing a machine learning model in the GUI, wherein the generated file includes the source code; receiving, via the GUI, one or more user adjustments to the displayed source code; and generating an update file representing an updated machine learning model defined by (i) one or more machine learning routines corresponding to one or more of the first set of user-selectable buttons selected by the user, and (ii) adjustments to the displayed source code.
In some implementations, the adjustments to the source code that are displayed include adjustments to machine learning model parameters or functions included in the source code.
In some embodiments, the method further includes receiving, from the user through the GUI, a request to download a file representing the generation of the machine learning model; access to a file representing generation of a machine learning model is provided through a GUI.
In some implementations, the request to download the generated file representing the machine learning model includes a request to reformat the generated file according to the indicated type, and wherein the method further comprises: generating a reformatted file representing the indicated type of machine learning model; access to the reformatted file representing the machine learning model is provided through the GUI.
In some implementations, further comprising storing the generated file representing the machine learning model at a location associated with the user.
In some embodiments, the method further comprises receiving, via the GUI, a selection of the dataset; receiving, by the GUI, a request to execute a file representing generation of a machine learning model using the dataset; executing a file representing the generation of the machine learning model using the data set to generate a corresponding machine learning model output; the generated machine learning model output is displayed in the GUI.
In some implementations, receiving a selection of a data set includes receiving a selection of a sample data set or receiving a selection of a data set imported by the user.
In some embodiments, receiving, via the GUI, a request to execute the generated file representing the machine learning model using the dataset includes receiving, via the GUI, a user selection of a run button, wherein the run button is enabled for selection when a machine learning model input dataset is selected.
In some implementations, the method further includes receiving a request to publish a file representing the generation of the machine learning model; in response to receiving the request, the generated file is published as a new asset in the GUI.
In some implementations, a GUI provided for generating a machine learning model includes a drag-and-drop interface, wherein the GUI includes: a searchable list of a first set of user-selectable buttons or a second set of user-selectable buttons; editing the area; wherein a user may select, drag and drop user-selectable buttons from the first set of user-selectable buttons or the second set of user-selectable buttons into the editing region to define a machine learning model.
In some implementations, the machine learning subroutine or the machine learning routine that is frequently used is ranked higher than the machine learning subroutine or the machine learning routine that is less frequently used.
In some embodiments, the editing region includes a template graphic for assisting a user in selecting, dragging and dropping the user-selectable buttons into the editing region to define a machine learning model.
In some implementations, the GUI of the provision for generating a machine learning model includes a plurality of user-selectable tags including a machine learning model creation tag, a machine learning model release tag, and a machine learning model version tag.
The subject matter described in this specification can be implemented in particular ways to realize one or more of the following advantages.
A system implementing the non-coding machine learning conduit described in this specification provides the possibility for users who are unable to code or do not want to code to be able to quickly and easily generate, execute, and publish machine learning models. Furthermore, with the presently described easy mode functionality, users of the non-coded machine learning conduit do not need to understand basic or complex machine learning concepts. Thus, the presently described non-coded machine learning conduit is accessible to a large number of users and improves the interaction between users and the conduit because even inexperienced users can generate and run machine learning solutions quickly and with minimal effort.
Furthermore, a system implementing the non-coded machine learning pipeline described in this specification provides enhanced flexibility for the user, as the front end of the pipeline provides the possibility to directly modify the source code underneath the generated machine learning model. The user may generate the machine learning model more quickly using the provided easy mode, but increased control of the machine learning model may also be achieved. Furthermore, it is easy to reuse machine learning models or building blocks of machine learning models built by different users. Therefore, the efficiency of generating the personalized model can be improved. Furthermore, the computational efficiency of running the machine learning model may be improved, since users with experience with machine learning concepts have the possibility to simplify the provided machine learning routines.
A system implementing the non-coded machine learning pipeline described in this specification provides enhanced execution transparency and data security for users, as the machine learning model generated by the non-coded machine learning pipeline may be executed on resources provided for users in the system, or may be downloaded and run securely offline.
Furthermore, a system implementing the non-coding machine learning pipeline described in this specification provides type safety checks at design time, because a user cannot connect building blocks when the output of a block does not match the input of another block. Thus, errors may be identified or prevented during the build process, rather than just at runtime.
The details of one or more implementations of the subject matter described in this specification are set forth in the accompanying drawings and the description below. Other features, aspects, and advantages of the subject matter will become apparent from the description, the drawings, and the claims.
Drawings
FIG. 1 is a block diagram of an example system implementing a non-coded machine learning conduit.
FIG. 2 is a schematic diagram of an example graphical user interface for generating, executing, and publishing machine learning models using a non-coded machine learning conduit.
FIG. 3 is a schematic diagram of a wrapper file representing an example machine learning routine.
FIG. 4 is a schematic diagram of an example graphical user interface for generating, executing, and publishing machine learning models using easy mode functionality in a non-coded machine learning pipeline.
FIG. 5 is a flow diagram of an example process for generating a machine learning model using a non-coded machine learning conduit.
Fig. 6A and 6B are flow diagrams of example processes for executing a machine learning model that has been generated using a non-coded machine learning pipeline.
Like reference numbers and designations in the various drawings indicate like elements.
Detailed Description
SUMMARY
Machine learning is a study of algorithms and statistical models that computer systems use to efficiently perform specific tasks without explicit instructions, but rather relying on patterns and reasoning. Machine learning algorithms model training data to make predictions or decisions on unseen data without explicit programming to perform specific tasks.
This specification describes a cloud computing service for building machine learning models. The service includes a GUI, e.g., a web-based GUI, in which a user can drag and drop a graphical representation of a machine learning subroutine into an editing area. The user may link the machine learning subroutines that are put in to form a graph representing the machine learning model.
To assist the user with little knowledge of the concept of machine learning, the GUI provides an easy schema presentation in which machine learning subroutines are packed to form a "black box" representation of the complete machine learning routine that requires only specified data inputs and target outputs. The user may then drag and drop the graphical representation of these machine learning routines into the editing area to form a graph representing the machine learning model.
The cloud service may provide access to a machine learning engine, where the generated machine learning model may be trained and/or used for reasoning. Alternatively, the user may download a file representing the generated machine learning model and train and/or perform reasoning offline, e.g., on an open source stack.
Exemplary operating Environment
FIG. 1 is a block diagram of an example system 100 implementing a non-coded machine learning conduit. A computer network 102, such as a Local Area Network (LAN), Wide Area Network (WAN), the internet, or a combination thereof, connects the non-encoded machine learning conduit front end 104 to various components of the cloud computing environment 106.
A user may access the non-coded machine learning conduit front end 104 via a user device (e.g., user device 118). The user device 118 may comprise a computing device, such as a desktop computer, a laptop computer, a tablet computer, a smartphone, or any device capable of displaying a Graphical User Interface (GUI) of the non-encoded machine learning conduit front end provided by the non-encoded machine learning conduit back end 112.
The GUI provided by the non-coding machine learning pipeline backend 112 may be a web-based GUI and provide an interactive visual workspace for users to build, execute, and publish machine learning models. The GUI allows a user to drag and drop machine learning subroutines into an editing region where the machine learning subroutines can be connected to form a machine learning model-the user does not need programming skills to generate the machine learning model. The formed machine learning model may be trained in the data set by the cloud computing environment 106, or may be downloaded and trained offline by a third-party system. Similarly, once trained, the cloud computing environment 106 can perform inference on the data set using the machine learning model, or a third party system can download the trained machine learning model and perform inference using the trained machine learning model. An example GUI provided by the non-coding machine learning conduit back-end is shown and described below with reference to fig. 2 and 4. An example process for generating a machine learning model using a non-coded machine learning conduit is described below with reference to fig. 5, 6A, and 6B.
The various components of the cloud computing environment 106 include a cloud storage component 108, a relational or non-relational database 110, such as a new SQL database, a non-encoded machine learning conduit backend 112, a cloud machine learning engine 114, and an inventory backend 116.
The cloud machine learning engine 114 performs operations related to executing machine learning models generated by the non-encoded machine learning pipeline front end and back end. For example, the cloud machine learning engine 114 can execute machine learning routines or subroutines on specified datasets in a machine learning model to train the machine learning model and/or perform inference. The output (results) generated by the cloud machine learning engine 114 may be provided directly to the non-encoded machine learning conduit front end 104 or the non-encoded machine learning conduit back end 112.
The inventory back end 116 performs operations related to publishing the machine learning models generated by the non-coded machine learning pipeline front end and back end. For example, the inventory backend may include storage (with security checks) that is open to users of non-encoded ML pipes.
FIG. 2 is a schematic diagram of an example GUI 200 for generating, executing, and publishing machine learning models using a non-coded machine learning conduit.
The example GUI 200 includes a search box 202, where a user may search a list of machine learning subroutines in the search box 202. An example machine learning subroutine may include algorithms or functions such as: various data formatting algorithms; various data splitting algorithms; various feature selection algorithms; various machine learning training algorithms, various machine learning evaluation algorithms, or various statistical algorithms. Other example machine learning subroutines include data sets or machine learning commands such as inputs, outputs, or evaluations. In some implementations, the GUI 200 can also include a region 204 in which search options and filters can be set by the user. For example, the user may select the type of machine learning task as a search option.
In some implementations, prior to the user entering text into the search box 202, a default list of machine learning subroutines in box 206, e.g., a list of frequently used machine learning subroutines, may be displayed in the GUI, where the frequently used machine learning subroutines are listed higher than the infrequently used machine learning subroutines. Further, after the user begins entering text into the search box 202, the list of machine learning subroutines displayed in box 206 may be updated based on the entered text.
Each machine learning subroutine in the list of machine learning subroutines in block 206 is displayed as a user-selectable button 208, such as user-selectable buttons 208,208 a-c. By selecting the pointer tool button 216 to activate the pointer tool function, the user can select the button corresponding to the particular machine learning subroutine and drag and drop the button corresponding to the particular machine learning subroutine into the editing region 210. In the example GUI 200, the user has selected, dragged and dropped buttons corresponding to the machine learning subroutines "input < data >", "machine learning algorithm III", "data splitter IV", "training algorithm I", "evaluate", and "output < model >," output < visual > ".
The edit region 210 is used to define a machine learning model based on the selected machine learning subroutine. Once the user places the button corresponding to the machine learning subroutine into the editing region 210, the user may further connect the machine learning subroutines to form a graph representing the machine learning model. A connection between machine learning subroutines (e.g., connection 214) may be created by selecting connector button 212 to activate a connector function. In some implementations, the connector functionality may not allow for connections between incompatible machine learning subroutines, e.g., may not allow a user to directly connect an input subroutine to an output subroutine, and may automatically direct connections between connected machine learning subroutines, e.g., may connect a data splitting routine to a training algorithm even if the user first selects the training algorithm and then selects the data splitting routine. These aspects of connector functionality may increase the likelihood that the generated machine learning model will function properly and may perform without error.
In some embodiments, the editing region 210 may display a template graphic for assisting a user in selecting, dragging and dropping the user-selectable buttons associated with machine learning subroutines into the editing region to define a machine learning model. For example, when the GUI is first presented to the user, a template diagram showing connected building blocks of the exemplary machine learning model at 50% opacity may be shown in the editing area. In some implementations, the template graphic presented in the edit area can be updated based on search terms or search options entered by the user in the search box 202 or area 204. For example, if the user enters "image classification" into the area 204, the template graph displayed in the editing area 210 may show example graphs of a number of connected machine learning subroutines that together represent a convolutional neural network.
When the user operates in the editing area, i.e., drags, drops, and connects machine learning subroutines in the editing area, the system call providing the GUI has a back end that represents a prototype file of the graphic under construction. In some implementations, the system can store a complete or partial history of operations performed in the editing area.
The example GUI 200 also includes a plurality of user-selectable tabs, such as a machine learning model creation or design tab 218a, a machine learning model release tab 218b, an event tab 218c, and a machine learning model version tab 218 d. If the user selects the design tab 218a, the GUI presentation includes options and features for creating a machine learning model, as shown in the example GUI 200.
If the user selects the post tab 218b, the GUI presentation may alternatively or additionally present options and/or features related to post the created machine learning model. For example, the GUI presentation may include a user-selectable publish button that, when selected, allows the system to publish the graphic as an asset to other users of the system for editing, execution, and saving. Such published assets may be accessed by a user under design label 218a, for example, presented in a list in blocks 208 a-c.
If the user selects the event tab 218c, the GUI presentation may present a page listing an activity log for the particular item, where the user may view the timestamp and each revision of the machine learning model, e.g., corresponding to the user performing one or more steps of the model or storing a file in the cloud. The event tag 218c may also be used as a summary of the charges generated by the cloud service user, as the timestamp and revision may be matched to the corresponding charges appearing in the user's bill.
If the user selects the version tab 218d, the GUI presentation may include a history of edits made in the edit section, such as a list of selectable snapshots. The user may restore the snapshot by selecting the snapshot, which may automatically copy the snapshot into a new item or pipe, such as a second GUI presentation. In some implementations, the user can also view a summary of the execution history when operating the GUI under the design tab, for example, in region 222 of GUI 200.
The example GUI 200 also includes a run button 220. When the run button is enabled, the user may select the run button to execute the machine learning model generated in the editing region 210. When the run button is selected, the machine learning model is immediately executed in the cloud, e.g., by a cloud machine learning engine. The results from selecting the run button 220 and executing the machine learning model may be displayed directly in the editing area, or may be viewed by hovering over or selecting a corresponding output module in the editing area. However, in some implementations, the run button 220 may be disabled, for example, if the machine learning model generated in the editing area lacks routines or cannot be executed. In these implementations, the GUI may also present warning signs, for example, in the edit area 210 or next to the run button 220.
The example GUI 200 also includes a save button 224 and a download button 230. The user may select a save button 224 to save the machine learning model generated in the editing area locally to, for example, the cloud. Alternatively or additionally, the user may select the download button 230 to download a file representing the machine learning model generated in the editing area 210. The download button 230 may be selected prior to selecting the run button 220, i.e., prior to training and/or evaluating the machine learning model, or may be selected after selecting the run button 220, e.g., downloading the trained machine learning model. Execution and saving of a machine learning model generated using a GUI for generating a machine learning model is described in more detail below with reference to fig. 6A and 6B.
The example GUI also includes a view source code button 228. The user may select the view source code button to view source code corresponding to the machine learning model presented in the edit region 210. For example, in response to selecting the view source code button, the GUI may divide the editing region into two portions, with the machine learning model presented in one portion and the corresponding source code presented in the other portion. Alternatively, the source code may be presented in another portion of the GUI.
Displaying source code representing the machine learning model enables a user to adjust the machine learning model. For example, a user with some experience in machine learning may be able to identify adjustments that will simplify the machine learning model, e.g., reduce training time required for the machine learning model and/or reduce inference time, without compromising the accuracy of the solution. Such adjustments may include adjusting the number of neural network layers used by a particular machine learning subroutine or routine, or specifying different activation functions. As another example, a user with some experience in machine learning may wish to compare multiple machine learning models and their effectiveness in addressing a particular task in a particular data set. Thus, manually adjusting source code behind a machine learning model provides increased personalization and can enable a user to generate machine learning models that are more and more tailored to a particular task.
In some implementations, hovering over or pointing to a portion of the machine learning model may cause the GUI to highlight or otherwise indicate the relevant portion of the displayed source code. This may help the user and improve the accuracy of adjustments made to the source code.
The example GUI 200 also includes a simple mode button 226. The user may select the easy mode button 226 to change the presentation of the GUI 200. For example, selecting the easy mode button 226 may change the displayed lists 208a-c of machine learning subroutines. Instead of displaying only user-selectable buttons corresponding to machine learning subroutines, user-selectable buttons corresponding to one or more machine learning routines may be displayed. In this context, a machine learning routine is a process that accepts input data, processes the data according to a sequence of one or more machine learning subroutines, and outputs an evaluation result. The machine learning routine may represent a machine learning algorithm building block, or an entire machine learning algorithm. In either case, the machine learning routine appears to the user as a black box-the user does not need to build the machine learning routine itself from multiple machine learning subroutines. Thus, the user does not need to understand the machine learning concept or how to transform or split the data. By selecting the easy mode button 226, the presented GUI can be operated by more users (those with and those without machine learning experience).
For convenience, the example machine learning routine described in this specification represents the entire machine learning algorithm. However, as described above, the machine learning routine represented by the user selectable buttons displayed in the easy mode may represent a building block of a machine learning algorithm. In these cases, the user may have the flexibility to use one machine learning routine in the easy mode and another in the advanced or "normal" mode.
Each user-selectable button corresponding to a machine learning routine may represent a wrapper file that includes a plurality of connected machine learning subroutines that define the machine learning routine. For example, a wrapper file representing a machine learning routine may include one or more of (i) a data transformation algorithm, (ii) a machine learning training algorithm, or (iii) a machine learning assessment algorithm. The wrapping of the plurality of machine learning subroutines may be performed by a standard wrapping.
FIG. 3 is a schematic diagram of an example package document. For convenience, fig. 3 illustrates an example wrapper of an example machine learning model defined by a user in an edit area 210 in the GUI 200 of fig. 2.
In the standard mode 302, the example machine learning model includes specific data splitting routines (data splitting module IV)310,310a, training algorithms (training algorithm I)310,310b, machine learning algorithms (machine learning algorithm III)310,310c, and evaluation routines 310,310 d. This configuration of subroutines 310,310a-d together represents a corresponding machine learning routine 308, as shown by the dashed lines.
The configuration of the machine learning subroutine 310 shown in the standard schema 302 may be wrapped using a subroutine wrapper (wrapper file) 304, as shown by the dashed line representing the machine learning routine 308. This packaging produces a simple mode "black box" presentation 306. When the GUI is operated in the standard mode 302, the easy mode presentation 306 corresponds to the same machine learning model defined by the user. That is, the system generates the same file/source code that represents the machine learning model regardless of whether the user is operating the GUI in the standard mode or the easy mode.
FIG. 4 is a schematic diagram of an example graphical user interface 400 for generating, executing, and publishing a machine learning model using simple schema functionality. The example GUI 400 is built on the example GUI 200 of FIG. 2. In particular, FIG. 4 illustrates the differences in GUI presentation after the user selects the easy mode button 226.
For example, after selecting the simple mode button 226, the presented user-selectable list of buttons representing the plurality of machine learning subroutines is replaced with a simple mode list in block 206 (FIG. 2). The simple mode list includes at least one user selectable button 402, such as user selectable buttons 402a-c, the user selectable buttons 402a-c representing a machine learning routine, i.e., a wrapper file containing one or more machine learning subroutines. In some implementations, the easy mode list can include user-selectable buttons corresponding to both the machine learning subroutine and the machine learning routine. In other implementations, the easy mode list may include only user-selectable buttons that correspond to machine learning routines. As described above with reference to fig. 2, a user may drag and drop a button corresponding to a machine learning routine into the editing region 210 to generate a machine learning model.
Hardware programming: editing experience
FIG. 5 is a flow diagram of an example method 500 for a process of generating a machine learning model using a non-coded machine learning conduit. For convenience, process 500 will be described as being performed by a system of one or more computers located at one or more locations. For example, the process 500 may be performed by the system 100 of FIG. 1 suitably programmed in accordance with the present description.
The system provides a Graphical User Interface (GUI) for generating a machine learning model (step 502). For example, the system may provide the GUI 200 described above with reference to fig. 2. In some implementations, the GUI can be a web-based GUI, and providing the GUI can include providing the GUI through a web browser.
The system receives a user selection of a mode button displayed in the GUI via the provided GUI (step 504). The mode button is a button that, when selected, causes the GUI to display a first set of user-selectable buttons corresponding to the respective machine learning routine. When the mode button is not selected, the GUI displays a second set of user-selectable buttons corresponding to respective machine learning subroutines, wherein the machine learning routine includes a respective plurality of connected machine learning subroutines. For example, the mode button may correspond to the easy mode button described above with reference to fig. 2-4.
In some implementations, the machine learning routine includes a plurality of machine learning subroutines and corresponds to a respective wrapper file. Each wrapper file may include one or more machine learning subroutines, e.g., one or more of (i) a data transformation algorithm, (ii) a machine learning training algorithm, or (iii) a machine learning evaluation algorithm.
In response to receiving the user's selection of the easy mode button, the system displays a first set of user selectable buttons in the GUI (step 506). An example GUI presentation after selecting the mode button is shown with reference to fig. 4.
The system receives a user selection of one or more of the first set of user-selectable buttons via the GUI (step 508). The system displays a graphical representation of a machine learning model in the GUI, the machine learning model being defined by one or more machine learning routines corresponding to one or more of the first set of user-selectable buttons selected by the user (step 510). An example graphical representation is illustrated in an edit area of the example GUI 400 of FIG. 4. The system generates a file representing a machine learning model (step 512).
In some implementations, the system can also receive, through the GUI, a user selection of a source code button displayed in the GUI. In response to receiving the user selection of the source code button, the system may display, in the GUI, source code representing a machine learning model defined by the received user selection of one or more of the plurality of user-selectable buttons (e.g., the source code included in the file generated at step 510). In some implementations, when a user hovers over a selected button corresponding to a respective type of machine learning algorithm, a respective portion of the displayed source code is highlighted.
The system may then receive one or more adjustments to the displayed source code, such as adjustments to machine learning model parameters or functions included in the source code, via the GUI. The system may then generate an update file representing a machine learning model defined by (i) the received user selection of one or more of the plurality of user-selectable buttons, and (ii) the displayed source code adjustments.
In some implementations, the system can also store the generated file representing the machine learning model at a location associated with the user. In some implementations, the system can receive a request to publish a file representing a generation of a machine learning model through the GUI. In these embodiments, the system may publish the generated file as a new resource in the GUI.
Note that the optional step of receiving, via the GUI, a user selection of a source code button displayed in the GUI and displaying source code representing a machine learning model in the GUI defined by the received user selection of one or more of the plurality of user selectable buttons may be performed as part of a different process than that described in figure 5. For example, this optional step may be performed as part of a process of generating a machine learning model using the GUI in standard mode only.
Hardware programming: executive experience
FIG. 6A is a flow diagram of a first example process 600 for executing a machine learning model that has been generated using a non-coded machine learning conduit. For convenience, process 600 will be described as being performed by a system of one or more computers located at one or more locations. For example, the process 600 may be performed by the system 100 of FIG. 1 suitably programmed in accordance with the present description.
After the system generates a file representing the machine learning model, the system may also receive a request from the user to download the generated file representing the machine learning model through the GUI for generating the machine learning model (step 602), e.g., as described above with reference to step 510 of FIG. 5. In some implementations, for example, where a user wants to train a machine learning model offline, the generated file may represent an untrained machine learning model. In other implementations, for example, in embodiments where a user uploads a training data set to the system or selects a sample data set provided by the system for training via the GUI, the user may request that the system train the machine learning model to generate a file representing the trained machine learning model, and the user may further request that the generated file representing the trained machine learning model be downloaded so that reasoning may be performed offline.
In some implementations, the received request to download the generated file can include a request to reformat the generated file according to the indicated type (e.g., a third party streaming format). In these implementations, the system can generate a reformatted file representing the indicated type of machine learning model and provide access to the reformatted file representing the machine learning model through the GUI.
The system provides access to a production file representing the machine learning model via the GUI (step 604). The user may then provide the generated file to other system components or modules, or to a third party for execution.
The example process 600 decouples the GUI used by the user to generate the machine learning model from the execution process. This may provide enhanced execution transparency for the user, as well as enhanced security, as the user needs not to share their data.
Note that the example process 600 may also be performed after the system generates a file representing a machine learning model using a different process than that described in FIG. 5. For example, the example process 600 may be performed after the system generates a file representing a machine learning model that has been created by a user operating the example GUI 200 of fig. 2 (i.e., the user operating the GUI in a standard mode).
FIG. 6B is a flow diagram of a second example process 650 for executing a machine learning model that has been generated using a non-coded machine learning conduit. For convenience, process 650 will be described as being performed by a system of one or more computers located at one or more locations. For example, the process 650 may be performed by the system 100 of FIG. 1 appropriately programmed according to the present description.
After the system generates a file representing the machine learning model, the system receives a selection of a data set via the GUI (step 652), for example, as described above with reference to step 510 of FIG. 5. For example, the user may select a sample data set from one of a plurality of options displayed in the GUI, or may select a data set imported by the user.
The system receives a request through the GUI to execute a file representing the generation of the machine learning model using the data set (step 654). Receiving a request to perform a file representing generation of a machine learning model using a data set may include receiving a user selection of a run button. In some embodiments, when the machine learning model is selected to input the data set, i.e., after step 652, the system may enable a run button displayed in the GUI.
The system executes the file representing the generation of the machine learning model using the data set to generate a corresponding machine learning model output (step 656). The generated machine learning model output may include one or more trained machine learning models or solutions to machine learning tasks produced by the trained machine learning models. The system provides the generated machine learning model output for display in the GUI (step 658).
The embodiments and all of the functional operations described in this specification can be implemented in digital electronic circuitry, or in computer software, firmware, or hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them. Embodiments may be implemented as one or more computer program products, i.e., one or more modules of computer program instructions encoded on a computer-readable medium for execution by, or to control the operation of, data processing apparatus. The computer readable medium can be a machine-readable storage device, a machine-readable storage substrate, a memory device, a composition of matter effecting a machine-readable propagated signal, or a combination of one or more of them. The term "data processing apparatus" includes all apparatus, devices, and machines for processing data, including by way of example a programmable processor, a computer, or multiple processors or computers. The apparatus can include, in addition to hardware, code that creates an execution environment for the computer program in question, e.g., code that constitutes processor firmware, a protocol stack, a database management system, an operating system, or a combination of one or more of them. A propagated signal is an artificially generated signal, e.g., a machine-generated electrical, optical, or electromagnetic signal, that is generated to encode information for transmission to suitable receiver apparatus.
A computer program (also known as a program, software application, script, or code) can be written in any form of programming language, including compiled or interpreted languages, and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, or other unit suitable for use in a computing environment. A computer program does not necessarily correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data (e.g., one or more scripts stored in a markup language document), in a single file dedicated to the program in question, or in multiple coordinated files (e.g., files that store one or more modules, sub programs, or portions of code). A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network.
The processes and logic flows described in this specification can be performed by one or more programmable processors executing one or more computer programs to perform functions by operating on input data and generating output. The processes and logic flows can also be performed by, and apparatus can also be implemented as, special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit).
A processor adapted to execute a computer program comprises: such as a general purpose microprocessor, a special purpose microprocessor, and any one or more processors of any kind of digital computer. Generally, a processor will receive instructions and data from a read-only memory or a random access memory or both.
The essential elements of the computer are: a processor for executing instructions, and one or more memory devices for storing instructions and data. Generally, a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks. However, the computer need not have such devices. Further, the computer may be embedded in another device, e.g., a tablet computer, a mobile phone, a Personal Digital Assistant (PDA), a mobile audio player, a Global Positioning System (GPS) receiver, etc. Computer-readable media suitable for storing computer program instructions and data include all forms of non-volatile memory, media and storage devices, including, for example, semiconductor memory devices (e.g., EPROM, EEPROM, and flash memory devices), magnetic disks (e.g., an internal hard disk or a removable disk), magneto-optical disks, and CD-ROM and DVD-ROM disks. The processor and the memory can be supplemented by, or incorporated in, special purpose logic circuitry.
To provide for interaction with a user, embodiments may be implemented on a computer having: a display device, such as a CRT (cathode ray tube) or LCD (liquid crystal display) monitor, for displaying information to the user and a keyboard and a pointing device, such as a mouse or a trackball, by which the user can provide input to the computer. Other kinds of devices may be used to provide for interaction with a user; for example, feedback provided to the user can be any form of sensory feedback, e.g., visual feedback, auditory feedback, or tactile feedback; and input from the user may be received in any form, including acoustic, speech, or tactile input.
Embodiments may be implemented in a computing system that includes a back-end component, e.g., as a data server; or include middleware components, such as application servers; or include a front-end component, such as a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation; or any combination of one or more such back-end, middleware, or front-end components. The components of the system can be interconnected by any form or medium of digital data communication (e.g., a communication network). Examples of communication networks include a local area network ("LAN") and a wide area network ("WAN"), e.g., the Internet.
The computing system may include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other.
While this specification contains many specifics, these should not be construed as limitations on the scope of what is disclosed or claimed, but rather as descriptions of features of particular embodiments. Certain features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely, various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable subcombination. Moreover, although features may be described above as acting in certain combinations and even initially claimed as such, one or more features from a claimed combination can in some cases be excised from the combination, and the claimed combination may be directed to a subcombination or variation of a subcombination.
Similarly, while operations are depicted in the drawings in a particular order, this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order, or that all illustrated operations be performed, to achieve desirable results. In some cases, multitasking and parallel processing may be beneficial. Moreover, the separation of various system components in the embodiments described above should not be understood as requiring such separation in all embodiments, and it should be understood that the described program components and systems can generally be integrated in a single software product or packaged into multiple software products.
In each example referring to files, different file types or formats are contemplated, such as YAML, HTML, XML, JSON, plain text, or other types of files. Further, where tables are mentioned, different data structures (e.g., spreadsheets, relational databases, or structured files) are contemplated.
Thus, particular embodiments have been described. Other embodiments are within the scope of the following claims. For example, the actions recited in the claims can be performed in a different order and still achieve desirable results.
Claims (20)
1. A computer-implemented method (500), comprising:
providing a Graphical User Interface (GUI) (200,400) for generating a machine learning model (414);
receiving, by the GUI (200,400), a user selection of a mode button (226) displayed in the GUI (200,400), wherein the mode button (226), when selected, causes the GUI (200,400) to display a first set of user selectable buttons (402) corresponding to respective machine learning routines (308), and, when not selected, causes the GUI (200,400) to display a second set of user selectable buttons (208) corresponding to respective machine learning subroutines (310), wherein the machine learning routines (308) include a respective plurality of connected machine learning subroutines (310);
in response to receiving a user selection (226) of a mode button, displaying a first set of user selectable buttons (402) in the GUI (200, 400);
receiving, via the GUI (200,400), a user selection of one or more of the first set of user selectable buttons (402);
displaying a graphical representation of a machine learning model (414) in the GUI (200,400), the machine learning model (414) being defined by one or more machine learning routines (308), the one or more machine learning routines (308) corresponding to the user selection of one or more of the first set of user selectable buttons (402); and
a file representing the machine learning model is generated (414).
2. The method (500) of claim 1, wherein the machine learning subroutine (310) includes a data formatting algorithm, a data splitting algorithm, a feature selection algorithm, a machine learning training algorithm, a machine learning evaluation algorithm, or a statistical algorithm.
3. The method (500) of claim 1 or 2, wherein each of the user-selectable buttons (402) in the first set of user-selectable buttons (402) represents a wrapper file (304) corresponding to one machine learning routine (306) and including a respective plurality of connected machine learning subroutines (310).
4. The method (500) according to any one of claims 1-3, further comprising:
receiving, by the GUI (200,400), a user selection of a source code button (228) displayed in the GUI (200, 400);
in response to receiving the user selection of the source code button (228), displaying source code representing the machine learning model (414) in the GUI (200,400), wherein the generated file includes the source code;
receiving, by the GUI (200,400), one or more user adjustments to the displayed source code; and
generating an updated file representing an updated machine learning model (414) defined by (i) the one or more machine learning routines (308) corresponding to one or more of the first set of user-selectable buttons (402) selected by a user, and (ii) adjustments to the displayed source code.
5. The method (500) of claim 4, wherein the adjustments to the source code that are displayed include adjustments to machine learning model parameters or functions included in the source code.
6. The method (500) according to any one of claims 1-5, further comprising:
receiving a request (414) from a user to download the generated file representing the machine learning model through the GUI (200, 400); and
providing, by the GUI (200,400), access (414) to the generated file representing the machine learning model.
7. The method (500) of claim 6 wherein the request to download (230) the generated file representing a machine learning model (414) comprises a request to reformat the generated file according to the indicated type, and wherein the method further comprises:
generating a reformatted file representing the indicated type of machine learning model (414); and
providing access (414) to the reformatted file representing the machine learning model through the GUI (200, 400).
8. The method (500) of any of claims 1-7, further comprising storing the generated file representing the machine learning model (414) at a location associated with the user (108).
9. The method (500) according to any one of claims 1-8, further comprising:
receiving, via the GUI (200,400), a selection of a data set;
receiving, by the GUI (200,400), a request to execute a document representing the generation of the machine learning model (414) using the data set;
executing the generated file (414) representing the machine learning model using the dataset to generate a corresponding machine learning model output; and
providing the generated machine learning model (414) output for display in the GUI (200, 400).
10. The method (500) of claim 9, wherein receiving a selection of a data set comprises receiving a selection of a sample data set or receiving a selection of a data set imported by the user.
11. The method (500) of claim 9 or 10, wherein receiving, via the GUI (200,400), a request to execute the generated file representing the machine learning model (414) using the data set comprises receiving, via the GUI (200,400), a user selection of a run button (220), wherein the run button (220) is enabled for selection when the machine learning model input data set is selected.
12. The method (500) according to any one of claims 1-11, further comprising:
receiving a request to publish the generated file representing the machine learning model (414); and
in response to receiving the request, publishing the generated file as a new asset in the GUI (200, 400).
13. The method (500) according to any one of claims 1-12, wherein the GUI (200,400) for generating machine learning model (414) offers includes a drag-and-drop interface, wherein the GUI (200,400) includes: a searchable list of the first set of user-selectable buttons or the second set of user-selectable buttons (402,208); and
an editing area (210);
wherein a user may select a user selectable button from the first set of user selectable buttons (402-c) or the second set of user selectable buttons (208) and drag and drop it into the editing region (210) to define a machine learning model (414).
14. The method (500) of claim 13, wherein the machine learning subroutines (310) or the machine learning routines (308) that are frequently used are ranked higher than the machine learning subroutines (310) or the machine learning routines (308) that are less frequently used.
15. The method (500) of claim 13 or 14, wherein the editing region (210) comprises a template graphic for assisting a user in selecting and dragging and dropping the user selectable button (402,208) into the editing region (210) to define a machine learning model (414).
16. The method (500) of any of claims 1-15, wherein the GUI (200,400) for generating the provision of the machine learning model (414) comprises a plurality of user selectable tags (218a-c), the plurality of user selectable tags (218a-c) comprising a machine learning model creation tag (218a), a machine learning model publication tag (218b), and a machine learning model version tag (218 d).
17. A system (100) comprising one or more computers and one or more storage devices storing operational instructions that, when executed by the one or more computers, cause the one or more computers to:
providing a Graphical User Interface (GUI) (200,400) for generating a machine learning model (414);
receiving, by the GUI (200,400), a user selection of a mode button (226) displayed in the GUI (200,400), wherein the mode button (226), when selected, causes the GUI (200,400) to display a first set of user selectable buttons (402) corresponding to respective machine learning routines (308), and, when not selected, causes the GUI (200,400) to display a second set of user selectable buttons (208) corresponding to respective machine learning subroutines (310), wherein the machine learning routines (308) include a respective plurality of connected machine learning subroutines (310);
in response to receiving a user selection (226) of a mode button, displaying a first set of user selectable buttons (402) in the GUI (200, 400);
receiving, via the GUI (200,400), a user selection of one or more of a first set of user selectable buttons (402);
displaying a graphical representation of a machine learning model (414) in the GUI (200,400), the machine learning model (414) being defined by one or more machine learning routines (308), the one or more machine learning routines (308) corresponding to the user selection of one or more of the first set of user selectable buttons (402); and
a file representing the machine learning model is generated (414).
18. The system (100) of claim 17, wherein the machine learning subroutine (310) comprises a data formatting algorithm, a data splitting algorithm, a feature selection algorithm, a machine learning training algorithm, a machine learning evaluation algorithm, or a statistical algorithm.
19. The system (100) of claim 17 or 18, wherein each of the user-selectable buttons (402) of the first set of user-selectable buttons represents a wrapper file (304) corresponding to one machine learning routine (308) and including a respective plurality of connected machine learning subroutines (310).
20. A computer storage medium encoded with instructions that, when executed by one or more computers, cause the one or more computers to:
providing a Graphical User Interface (GUI) (200,400) for generating a machine learning model (414);
receiving, by the GUI (200,400), a user selection of a mode button (226) displayed in the GUI (200,400), wherein the mode button (226), when selected, causes the GUI (200,400) to display a first set of user selectable buttons (402) corresponding to respective machine learning routines (308), and, when not selected, causes the GUI (200,400) to display a second set of user selectable buttons (208) corresponding to respective machine learning subroutines (310), wherein the machine learning routines (308) include a respective plurality of connected machine learning subroutines (310);
in response to receiving a user selection (226) of a mode button, displaying a first set of user selectable buttons (402) in the GUI (200, 400);
receiving, via the GUI (200,400), a user selection of one or more of a first set of user selectable buttons (402);
displaying a graphical representation of a machine learning model (414) in the GUI (200,400), the machine learning model (414) being defined by one or more machine learning routines (308), the one or more machine learning routines (308) corresponding to the user selection of one or more of the first set of user selectable buttons (402); and
a file representing the machine learning model is generated (414).
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US16/549,675 US20210055915A1 (en) | 2019-08-23 | 2019-08-23 | No-coding machine learning pipeline |
US16/549,675 | 2019-08-23 | ||
PCT/US2020/047068 WO2021041131A1 (en) | 2019-08-23 | 2020-08-19 | No-coding machine learning pipeline |
Publications (1)
Publication Number | Publication Date |
---|---|
CN114287011A true CN114287011A (en) | 2022-04-05 |
Family
ID=72521694
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202080059784.9A Pending CN114287011A (en) | 2019-08-23 | 2020-08-19 | Non-coding machine learning pipeline |
Country Status (6)
Country | Link |
---|---|
US (2) | US20210055915A1 (en) |
EP (1) | EP4018381A1 (en) |
JP (2) | JP7297150B2 (en) |
KR (1) | KR20220050190A (en) |
CN (1) | CN114287011A (en) |
WO (1) | WO2021041131A1 (en) |
Families Citing this family (12)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11514361B2 (en) * | 2019-08-30 | 2022-11-29 | International Business Machines Corporation | Automated artificial intelligence radial visualization |
US20210081841A1 (en) * | 2019-09-12 | 2021-03-18 | Viani Systems, Inc. | Visually creating and monitoring machine learning models |
US11281975B1 (en) * | 2019-09-24 | 2022-03-22 | PerceptiLabs AB | Creating and modifying machine learning models in a model training engine |
US11574249B2 (en) * | 2020-06-02 | 2023-02-07 | International Business Machines Corporation | Streamlining data processing optimizations for machine learning workloads |
US11574175B2 (en) * | 2020-06-25 | 2023-02-07 | Intel Corporation | Security optimizing compute distribution in a hybrid deep learning environment |
US20220021953A1 (en) * | 2020-07-16 | 2022-01-20 | R9 Labs, Llc | Systems and methods for processing data proximate to the point of collection |
US11853292B2 (en) * | 2020-08-05 | 2023-12-26 | Woven By Toyota, U.S., Inc. | Evaluating driving data with a modular and configurable evaluation framework |
US11354597B1 (en) * | 2020-12-30 | 2022-06-07 | Hyland Uk Operations Limited | Techniques for intuitive machine learning development and optimization |
US20230161564A1 (en) * | 2021-11-22 | 2023-05-25 | Jpmorgan Chase Bank, N.A. | System and method for adding no-code machine learning and artificial intelligence capabilities to intelligence tools |
EP4332847A1 (en) * | 2022-05-11 | 2024-03-06 | Aizoth Inc. | Coupled learner formation device, coupled learner formation program, and non-transitory recording medium with a coupled learner formation program recorded therein |
KR102646762B1 (en) * | 2023-03-13 | 2024-03-12 | (주)빛과 수학 | A method for designing a machine learning model using a 3D user interface and a system using the same |
KR102629517B1 (en) * | 2023-07-18 | 2024-01-29 | 머플 주식회사 | Graphic resource expansion generation method using AI and game production platform using the same |
Family Cites Families (17)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7174534B2 (en) * | 2001-01-22 | 2007-02-06 | Symbol Technologies, Inc. | Efficient system and method for running and analyzing multi-channel, multi-modal applications |
US20140032606A1 (en) * | 2009-08-20 | 2014-01-30 | Adobe Systems Incorporated | Collapsible groups in graphical workflow models |
US8810576B2 (en) * | 2010-04-13 | 2014-08-19 | Microsoft Corporation | Manipulation and management of links and nodes in large graphs |
WO2013018204A1 (en) * | 2011-08-03 | 2013-02-07 | 株式会社日立製作所 | Image processing software development method, image processing software development apparatus, and image processing software development program |
US10649424B2 (en) * | 2013-03-04 | 2020-05-12 | Fisher-Rosemount Systems, Inc. | Distributed industrial performance monitoring and analytics |
JP2014186508A (en) * | 2013-03-22 | 2014-10-02 | Canon Inc | Programming apparatus, programming support method and program |
US9348563B1 (en) * | 2014-12-10 | 2016-05-24 | Sap Se | Bi-directional editing between visual screen designer and source code |
US11175910B2 (en) * | 2015-12-22 | 2021-11-16 | Opera Solutions Usa, Llc | System and method for code and data versioning in computerized data modeling and analysis |
US10466978B1 (en) * | 2016-11-30 | 2019-11-05 | Composable Analytics, Inc. | Intelligent assistant for automating recommendations for analytics programs |
CN108279890B (en) * | 2017-01-06 | 2021-12-24 | 阿里巴巴集团控股有限公司 | Component publishing method, component constructing method and graphical machine learning algorithm platform |
US10310821B2 (en) * | 2017-06-03 | 2019-06-04 | Apple Inc. | Integration of learning models into a software development system |
US10747941B2 (en) * | 2017-06-28 | 2020-08-18 | General Electric Company | Tag mapping process and pluggable framework for generating algorithm ensemble |
US20190303107A1 (en) * | 2018-03-30 | 2019-10-03 | Ca, Inc. | Automated software programming guidance |
US11367016B2 (en) * | 2018-10-25 | 2022-06-21 | The Boeing Company | Machine learning model development with interactive model building |
US20200193221A1 (en) * | 2018-12-17 | 2020-06-18 | At&T Intellectual Property I, L.P. | Systems, Methods, and Computer-Readable Storage Media for Designing, Creating, and Deploying Composite Machine Learning Applications in Cloud Environments |
US11783223B2 (en) * | 2019-06-01 | 2023-10-10 | Apple Inc. | Techniques for machine language model creation |
US11182049B2 (en) * | 2019-06-01 | 2021-11-23 | Sap Se | Guided drilldown framework for computer-implemented task definition |
-
2019
- 2019-08-23 US US16/549,675 patent/US20210055915A1/en active Pending
-
2020
- 2020-08-19 WO PCT/US2020/047068 patent/WO2021041131A1/en unknown
- 2020-08-19 EP EP20772457.6A patent/EP4018381A1/en active Pending
- 2020-08-19 KR KR1020227009334A patent/KR20220050190A/en unknown
- 2020-08-19 CN CN202080059784.9A patent/CN114287011A/en active Pending
- 2020-08-19 JP JP2022512427A patent/JP7297150B2/en active Active
-
2023
- 2023-06-13 JP JP2023096825A patent/JP2023120274A/en active Pending
- 2023-07-07 US US18/348,623 patent/US20230350648A1/en active Pending
Also Published As
Publication number | Publication date |
---|---|
WO2021041131A1 (en) | 2021-03-04 |
JP7297150B2 (en) | 2023-06-23 |
US20210055915A1 (en) | 2021-02-25 |
US20230350648A1 (en) | 2023-11-02 |
JP2023120274A (en) | 2023-08-29 |
EP4018381A1 (en) | 2022-06-29 |
JP2022545036A (en) | 2022-10-24 |
KR20220050190A (en) | 2022-04-22 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN114287011A (en) | Non-coding machine learning pipeline | |
US10755053B1 (en) | Applied artificial intelligence technology for story outline formation using composable communication goals to support natural language generation (NLG) | |
KR101688554B1 (en) | Managing and automatically linking data objects | |
US11281975B1 (en) | Creating and modifying machine learning models in a model training engine | |
US11972331B2 (en) | Visualization of training dialogs for a conversational bot | |
US11412031B2 (en) | Mechanism for webpage composition | |
US9170717B2 (en) | Graphically managing interactive analytic data | |
US8930831B2 (en) | User interface generation based on business process definition | |
WO2009045918A2 (en) | Intelligent editing of relational models | |
US20200150937A1 (en) | Advanced machine learning interfaces | |
Dorodnykh et al. | End-user development of knowledge bases for semi-automated formation of task cards. | |
US20240061653A1 (en) | Collaborative industrial integrated development and execution environment | |
Pelzetter | A declarative model for web accessibility requirements and its implementation | |
US20230384910A1 (en) | Using Attributes for Font Recommendations | |
US20210133282A1 (en) | Methods and apparatus for generating a platform-agnostic mobile application configuration data structure with a dynamic quiz | |
US10203939B2 (en) | Method and system for parameter model framework | |
US11768843B1 (en) | Results ranking with simultaneous searchee and searcher optimization | |
US11934852B1 (en) | Providing help content proactively | |
US20240126516A1 (en) | Computer-supported visual definition of conditional automatic order submissions | |
WO2023225264A1 (en) | Personalized text suggestions | |
Cohen et al. | Support for reusable explorations of linked data in the semantic web | |
Dao | Data Testing and Visualization Tool Integrated with Tableau for AI Service | |
EP2884433A1 (en) | Rule assignments and templating |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination |