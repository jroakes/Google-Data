EP2807588A1 - Sequencing electronic files - Google Patents
Sequencing electronic filesInfo
- Publication number
- EP2807588A1 EP2807588A1 EP13741008.0A EP13741008A EP2807588A1 EP 2807588 A1 EP2807588 A1 EP 2807588A1 EP 13741008 A EP13741008 A EP 13741008A EP 2807588 A1 EP2807588 A1 EP 2807588A1
- Authority
- EP
- European Patent Office
- Prior art keywords
- sequence
- file
- image
- user
- files
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Withdrawn
Links
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0481—Interaction techniques based on graphical user interfaces [GUI] based on specific properties of the displayed interaction object or a metaphor-based environment, e.g. interaction with desktop elements like windows or icons, or assisted by a cursor's changing behaviour or appearance
- G06F3/0482—Interaction with lists of selectable items, e.g. menus
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/40—Information retrieval; Database structures therefor; File system structures therefor of multimedia data, e.g. slideshows comprising image and additional audio data
- G06F16/43—Querying
- G06F16/438—Presentation of query results
- G06F16/4387—Presentation of query results by the use of playlists
- G06F16/4393—Multimedia presentations, e.g. slide shows, multimedia albums
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/40—Information retrieval; Database structures therefor; File system structures therefor of multimedia data, e.g. slideshows comprising image and additional audio data
- G06F16/48—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually
- G06F16/487—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using geographical or spatial information, e.g. location
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/50—Information retrieval; Database structures therefor; File system structures therefor of still image data
- G06F16/51—Indexing; Data structures therefor; Storage structures
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/50—Information retrieval; Database structures therefor; File system structures therefor of still image data
- G06F16/54—Browsing; Visualisation therefor
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0481—Interaction techniques based on graphical user interfaces [GUI] based on specific properties of the displayed interaction object or a metaphor-based environment, e.g. interaction with desktop elements like windows or icons, or assisted by a cursor's changing behaviour or appearance
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q10/00—Administration; Management
- G06Q10/10—Office automation; Time management
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q30/00—Commerce
- G06Q30/02—Marketing; Price estimation or determination; Fundraising
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N1/00—Scanning, transmission or reproduction of documents or the like, e.g. facsimile transmission; Details thereof
- H04N1/00127—Connection or combination of a still picture apparatus with another apparatus, e.g. for storage, processing or transmission of still picture signals or of information associated with a still picture
- H04N1/00132—Connection or combination of a still picture apparatus with another apparatus, e.g. for storage, processing or transmission of still picture signals or of information associated with a still picture in a digital photofinishing system, i.e. a system where digital photographic images undergo typical photofinishing processing, e.g. printing ordering
- H04N1/00185—Image output
- H04N1/00198—Creation of a soft photo presentation, e.g. digital slide-show
Definitions
- the present disclosure relates generally to sequencing electronic files.
- the present disclosure more specifically relates to generating multiple sequences of files based on the characteristics of a file, such as an image being displayed in a slideshow.
- One implementation is a computerized method for sequencing electronic images.
- the method includes receiving, at a processing circuit, a request to view a slideshow of digital images having a characteristic specified by a user.
- the method also includes generating, by the processing circuit, a first sequence of images having the specified characteristic based in part on whether a user profile of the user has access to the images.
- the method further includes selecting, by the processing circuit, a focus image for the slideshow from the first sequence of images.
- the method additionally includes determining, by the processing circuit, a second characteristic of the focus image.
- the method further includes generating, by the processing circuit, a second sequence of images, the second sequence including the focus image and one or more images having the second characteristic of the focus image.
- the method yet also includes providing webpage data to an electronic device, the webpage data being configured to display the requested slideshow with the focus image.
- the slideshow is configured to display the focus image in a larger area of the slideshow than other displayed images, the slideshow also including a first graphical user interface input to change the displayed focus image to another image in the first sequence and a second graphical user interface input to change the displayed focus image to another image in the second sequence.
- a further implementation is a computerized method for sequencing electronic files.
- the method includes generating, by a processing circuit, a first sequence of files for a sequential display of the files, the first sequence of files including a focus file.
- the method also includes determining, by the processing circuit, a characteristic of the focus file in the first sequence.
- the method further includes generating a second sequence of files having the characteristic.
- the method additionally includes providing display data to an electronic display, the display data being configured to display at least a portion of the contents of the focus file in the first sequence, an input configured to cause the display of at least a portion of the contents of another file in the first sequence, and an input configured to cause the display at least a portion of the contents of another file in the second sequence.
- FIG. 1 is an illustration of a digital slideshow, according to one implementation
- FIG. 3 is an illustration of image sequences being generated.
- FIG. 4 is a block diagram of an exemplary processing circuit configured to determine a sequence in which to present electronic files.
- electronic files may be presented on an electronic display across multiple sequences, allowing a user to seamlessly switch between sequences.
- the sequences may be used as part of a slideshow that displays electronic files in the sequences. For example, a user may use a slideshow to view an image of a boat in a first sequence of images taken during their recent trip to Bermuda. Based on the characteristics of the image (e.g., metadata associated with the image, the content of the image, etc.), other sequences of images may also be generated. For example, a second sequence of images may be generated devoted to images of boats and presented as part of the slideshow. The user may then opt to continue viewing images in the first sequence (e.g., images from their trip to Bermuda) or images in the second sequence (e.g., images of boats).
- images in the first sequence e.g., images from their trip to Bermuda
- images in the second sequence e.g., images of boats.
- any number of different file sequences may be presented to a user via a graphical user interface (GUI), based on the characteristics of a file in the current sequence. For example, a user may be presented with one, two, three, or more alternative file sequences. In some implementations, the number of alternative sequences may be preset by the user via a stored user preference. Similarly, which alternative sequences are generated and presented may be based on a user preference or may be automatically selected by the system without receiving input from the user.
- GUI graphical user interface
- the user may specify an order of preference for alternative sequences, such as “wedding photos,” “puppies,” and “sunsets.”
- the system may select alternative sequences based on characteristics predicted by the system to be of interest to the user (e.g., based on previous sequences selected by the user, based on the user's social networking groups, based on user profile data about the user, etc.).
- Display 100 may be any form of electronic display configured to provide visual data to a user.
- display 100 may be a liquid crystal display (LCD), light emitting diode (LED) display, plasma display panel (PDP), cathode ray tube (CRT) display, electronic paper, a combination thereof, or any other form of display configured to receive display data and to visually present data to a user.
- Display 100 may be located within the housing of the device that provides display data to display 100 or may be located externally, according to various implementations.
- display 100 may be a display integrated into an electronic device (e.g., a display of a laptop computer, a tablet computer, a cellular telephone, a portable digital assistant, a smart television set, a camera, etc.) or may be a standalone display (e.g., a computer monitor, a television, etc.).
- an electronic device e.g., a display of a laptop computer, a tablet computer, a cellular telephone, a portable digital assistant, a smart television set, a camera, etc.
- a standalone display e.g., a computer monitor, a television, etc.
- the display data that causes slideshow 102 to be displayed by display 100 may be provided by one or more processors that execute instructions stored in one or more electronic memories (i.e., provided by a processing circuit).
- slideshow 102 may be part of a slideshow application.
- slideshow 102 may be part of a webpage. That is, slideshow 102 may be executed within a web browser application.
- some or all of the data presented as part of slideshow 102 may be stored locally in a memory or may be received via a network from a remote device.
- some of the images presented as part of slideshow 102 may be stored locally in the memory of a mobile telephone, while other images may be received from a server via the Internet (e.g., from a server of a social networking system, from an image hosting service, etc.).
- One or more focus images may be displayed as part of slideshow 102.
- a focus image may be the current image in a sequence of images being displayed in slideshow 102.
- images that are not focus images may be displayed as thumbnails in slideshow 102.
- an image 104 may be the focus image for a sequence 106 of images.
- sequence 106 may correspond to all images taken by a particular camera and sorted in chronological order, i.e., a "camera sequence.”
- Sequence 106 may include any number of images ordered prior to, or after, that of image 104 in sequence 106.
- image 104 may be preceded by image 108 in sequence 106 (e.g., image 108 was captured prior to that of image 104).
- image 104 may be followed by image 110 in sequence 106 (e.g., image 110 was taken directly after that of image 104).
- Sequence 106 may be specified by a user or may be automatically generated by the system without input from a user. For example, the user may specify that they wish to view all images captured by a camera in chronological order. In another example, slideshow 102 may default to show all images in chronological order.
- one or more alternative or supplemental image sequences may be presented as part of slideshow 102 based on the characteristics of image 104.
- slideshow 102 may include three alternative sequences, in addition to that of sequence 106: a sequence based on the topic, "orchids," a sequence based on images located within a "wedding album,” and a sequence based on the "title" of an image.
- An alternative image sequence corresponds to a set of images that differs from those in the primary sequence.
- the alternative image sequence may include the one or more focus images, allowing a user to pivot between image sequences related to different image characteristics.
- image 104 may be part of sequence 106 that orders images from a camera
- image 104 may also be part of a second sequence devoted to the topic of "orchids," since image 104 contains an image of an orchid (e.g., image 104 may be preceded by an image 112 of an orchid and followed by an image 114 of an orchid in the sequence).
- Image 104 may also be part of a third sequence of images flagged as part of a "wedding album" (e.g., image 104 may be preceded by an image 116 and followed by an image 118), since image 104 was taken at a wedding.
- image 104 may be preceded by an image 120 and followed by an image 122 based on the titles of the images or keywords in the metadata of the images. For example, if image 104 is titled, "White Orchid,” it may be preceded by image 120, titled “White Nectarines,” and followed by image 122, titled “White Peacock.”
- Alternative image sequences allow a user to seamlessly transition from one set of images to another.
- slideshow 102 allows the order of presentation to be dynamic. In other words, a user may switch from one image sequence to another while viewing images within slideshow 102.
- slideshow 102 may be associated with a user profile. Such implementations allow for greater control over slideshow 102, such as how slideshow 102 is configured or what information is displayed as part of slideshow 102.
- a user may log into their profile while starting slideshow 102.
- the user may be automatically logged into their profile based on stored credentials (e.g., a stored user name and password) or based on a device ID. For example, the user may be automatically logged into their profile on a remote server based on the device ID of their mobile telephone.
- various configurations may be associated with the user profile that control how slideshow 102 is presented.
- the user profile may have associated user preferences. For example, a user may specify which image sequences are displayed via slideshow 102 (e.g., the user may have specified a preference for images of orchids). In some implementations, which sequences have been selected by the user in the past may be associated with their profile and used to determine which alternative sequences are presented via slideshow 102. For example, if the user of slideshow 102 had previously selected sequences devoted to "orchids," slideshow 102 may include such a sequence based on image 104.
- a user profile may be used to gain access to the images displayed by slideshow 102.
- a user may create one or more photo albums and slideshow 102 may be used to review the images (e.g., within an album or across multiple albums owned by the user).
- some or all of the images displayed by slideshow 102 may be owned by a different user that has granted access to the profile of the user viewing slideshow 102.
- slideshow 102 may include any number of different GUI effects.
- a focus image may be presented as part of a lightbox effect that dims the background behind the focus image, such as image 104.
- slideshow 102 may be configured to utilize a hover-over effect (e.g., by performing an action in response to a cursor being positioned above a certain area of slideshow 102). For example, positioning a cursor over a previous or subsequent image in a sequence (e.g., over images 108, 110, 112, 114, 116, 118, 120, or 122) may cause more information about the sequence to be displayed via slideshow 102.
- the characteristic used to generate the sequence may be displayed.
- positioning a cursor over image 114 may cause the topic, "orchids" to be displayed.
- additional images in the sequence may be displayed via a hover-over event.
- positioning a cursor over image 110 may cause additional images in sequence 106 to be displayed on a portion of slideshow 102 (e.g., on the bottom of slideshow 102 as shown in FIG. 1, on the top of slideshow 102, etc.).
- Selection of a previous or subsequent image in a sequence via slideshow 102 may cause the selected image to be displayed as the focus image.
- selection of image 122 may cause image 104 to be replaced on display 100 with image 122.
- selection of a previous or subsequent image in a sequence may cause one or more other sequences to be generated, based on the characteristics of the selected image.
- selection of image 122 may cause an alternative image sequence related to the topic of "birds" to be generated based on image 122 showing a peacock. In such a case, previous and/or subsequent images in the "birds" sequence may replace images 112 and 114 on slideshow 102.
- multiple sequences may be selected at the same time.
- a touchscreen display may allow the selection of images 114 and 118 at the same time. Selection of multiple sequences may cause a superset of images to be generated (e.g., containing the files of both sequences) or may cause a sequence of images having both characteristics to be generated. In one implementation, the sequence that is generated from selecting multiple sequences may be displayed on slideshow 102 (e.g., in the place of sequence 106 or in another area on display 100).
- slideshow 102 is shown in FIG. 1 with reference to digital images, it is to be appreciated that any number of different types of electronic files may be presented via slideshow 102.
- Non-limiting examples of electronic files that may be displayed via slideshow 102 include text files, spreadsheets, movie files, music files, or a combination of different types of files.
- a spreadsheet located in a user's "home finance" collection may be displayed via slideshow 102.
- possible sequences of files include other files in the user's collection, other files about home finance, files ordered by last modification time, or shared documents among a set of collaborators.
- FIG. 2 is an example process 200 for sequencing electronic files.
- Process 200 may be implemented by a user electronic device or by a server, according to various implementations.
- process 200 may be implemented by a user's home computer or may be implemented by a web server that provides a slideshow as part of a webpage to the home computer.
- process 200 may be implemented by a combination of devices.
- Process 200 includes generating a first sequence of files for a slideshow (block 202).
- a sequence of files may be generated based on one or more criteria selected by a user.
- a selected criterion used to generate the first sequence may be any characteristic of an electronic document. For example, the name of the file, the size of the file, when the file was created, when the file was modified, and/or the owner of the file may be used to generate a sequence.
- additional information may be associated with a file, such as metadata or data stored as part of the file's format.
- the exchangeable image file format may include date and time information for an image, camera settings used to capture the image (e.g., the make and model of the camera, the shutter speed, focal length, ISO speed, metering mode, orientation, etc.), information about where the image was captured, or other information about the image.
- the additional information may be associated with a social networking action (e.g., comments, ratings, suggestions, etc.). For example, a user may comment about an image, "Wow. There are some beautiful flowers at the Botanical Garden! In such a case, the topics "flowers" and “Botanical Garden” may be extracted from the comment and associated as a characteristic of the image.
- a social networking action e.g., comments, ratings, suggestions, etc.
- the criteria selected by the user may be stored as a user preference to control which sequence is first presented by the slideshow.
- the first sequence may be generated automatically without input from the user.
- the first sequence may be generated automatically based on a characteristic of a file already presented via the slideshow.
- the first sequence of process 200 may be an alternative sequence presented in the slideshow based on a characteristic of a document of focus.
- the first sequence may be generated automatically based on other information associated with a user profile (e.g., the user's demographics, social connections, Internet search history, etc.). For example, if the user's profile belongs to a social networking group devoted to quilting, files related to the topic of "quilting" may be
- a characteristic of a file may include the content of the file itself. For example, a text file of an article about baseball may be parsed to associate the topic of "baseball" with the file.
- image recognition may be used to identify a person, object, or location in an image. For example, persons A, B, and C may be identified in an image. In such a case, person A, B, and/or C may be used as a characteristic to generate sequences. For example, a sequence may include other images that also show person A.
- TF-IDF term frequency - inverse document frequency
- a sequence may be linear, i.e., one file has no previous file in the sequence and another file has no subsequent file in the sequence.
- the sequence may be continuous.
- a sequence that includes files A, B, C may transition from files A ⁇ B ⁇ C ⁇ A or vice-versa.
- Process 200 includes determining a characteristic of a file in the first sequence (block 204).
- the file in the sequence may correspond to a file being focused on by a slideshow (e.g., displayed in larger proportion than that of other files, centered on the display screen or window, etc.).
- characteristics of image 104 shown in FIG. 1 may be determined.
- the characteristic may be determined for another file in the first sequence.
- the characteristic may be any data in the file (e.g., the content of the file) or associated with the file (e.g., metadata, data in a social networking system, etc.), in various implementations.
- Process 200 includes identifying files sharing the determined characteristic (block 206).
- Files sharing the determined characteristic may be stored with the file in the sequence or may be stored in a separate location.
- the identified files may be part of the same album owned by a particular user, part of differing albums owned by the same user, or part of albums owned by different users.
- the identified files may be stored in different devices (e.g., one file is stored in a local device and another file is store by a remote device).
- the files may be of differing types.
- one file in the sequence may be an image of a penguin.
- Process 200 includes generating a new sequence containing some or all of the identified files sharing the characteristic (block 208).
- the slideshow may limit the number of files in a given sequence (e.g., based on a user preference, a hardcoded limit in the slideshow, etc.). For example, the slideshow may identify seventy files that share the characteristic, but only use fifty of the identified files to generate a new sequence.
- the order in which files appear in the sequence may be based on the order in which the files were identified, the relationship between the identified file and the file in the first sequence (e.g., located in the same folder, created around the same time, etc.), how strongly the characteristic applies to the file, etc.
- an article that is entirely devoted to the topic of penguins may have the characteristic more strongly than that of an article that briefly mentions penguins.
- an image in the same folder or album as that of the file in first sequence may receive a higher priority in the generated sequence than that of a file shared by another user.
- the file in the first sequence may be included in the new sequence.
- the position of the file in the new sequence may vary, depending on whether the sequence is linear or continuous. If the sequence is continuous, for example, the files may be ordered in both the preceding and subsequent directions from the file of the first sequence (e.g., the images immediately preceding and subsequent to the focus image may be the two images that most strongly match the characteristic, the images are the most related to the focus image, etc.). If the sequence is linear, the file from the first sequence may be positioned anywhere in the new sequence (e.g., at the start of the new sequence, at the end of the new sequence, at the median position in the new sequence, etc.).
- which characteristics are used to generate alternative sequences may be based on a user preference or may be automatically selected without further input from the user.
- the user may specify an order of preference for which types of alternative sequences are generated first for the slideshow.
- characteristics that may be of interest to a user may be determined and used to generate the alternative sequences. For example, a user may often select to view sequences that contain images of flowers, but never select to view sequences that contain images of clowns. In such a case, the topical characteristic of "flowers" may receive a higher priority than that of "clowns.” In other words, if the file in the first sequence is related to the topic of flowers, a sequence of files related to flowers may be generated before that of clowns.
- a sequence limit has not yet been reached, other characteristics may be determined and used to generate additional sequences (e.g., by repeating the processing of blocks 204, 206, 208). For example, if the sequence limit is four, four characteristics of the file in the first sequence may be determined and used to generate four alternative sequences. In some implementations, the processing of blocks 204, 206, 208 may be combined. In one example, all characteristics for the file in the first sequence may be determined at the same time, ordered, and used to generate new sequences up to the sequence limit.
- Process 200 includes providing a slideshow with the file sequences (block 212).
- the slideshow may be provided to an electronic display or to a device having an electronic display, in various implementations.
- the file sequences may be determined by a server and provided to client device operated by a user.
- the server may provide the slideshow with the sequences as part of a webpage to the client device.
- the sequences and/or the files of the sequences may be provided to the client device (e.g., the slideshow may be an application executed locally that receives the determined sequences from the server).
- the sequences may be determined by the same device that executes the slideshow.
- FIG. 3 is an illustration of image sequences being generated, according to one example.
- a first image sequence 302 may include any number of images, including image 304.
- Image 304 is preceded in image sequence 302 by image 306 and followed by image 308.
- image 304 may be a focus image in a slideshow (e.g., the slideshow
- Image sequence 302 may be generated using any number of criteria to select and order the images.
- the images in image sequence 302 may be located in the same memory location or photo album.
- image sequence 302 may contain images that are in a photo album of a user devoted to the user's latest vacation.
- the images in image sequence 302 may be selected based on one or more other characteristics of the images (e.g., metadata associated with the images, the content of the images, etc.). For example, the images in image sequence 302 may be selected based on the images being taken by the same camera. The number of images in image sequence 302 may be limited to a certain number of images, in some cases. For example, image sequence 302 may contain the first fifty images that match the selection criteria. In another example, image sequence 302 may include those images that most closely match the criteria. For example, if the selection criteria is a specific creation date or time, image sequence 302 may contain those images that were taken closest temporally to the specified date or time.
- the selection criteria is a specific creation date or time
- image sequence 302 may contain those images that were taken closest temporally to the specified date or time.
- the criteria used to generate image sequence 302 may be specified by a user.
- a user may manually specify that image sequence 302 is to contain images relating to a certain event, such as a friend's wedding.
- the user may specify the criteria when the slideshow is running or may save the criteria as a user preference.
- image sequence 302 may be automatically generated (e.g., without further input from the user) based on selection criteria stored as a user preference.
- image sequence 302 may be generated without the user specifying the selection criteria for the sequence.
- the sequence may be automatically generated based on which image sequences were previously selected by the user, based on criteria from the user's social networking profile (e.g., ratings by the user, comments by the user, groups to which the user belongs, etc.), or a user's Internet search requests.
- the images in image sequence 302 and/or their ordering may be manually specified by a user.
- a user e.g., a user viewing the slideshow, a user that owns the images, etc.
- images 304, 306, 308 are to be included in image sequence 302 and their ordering in image sequence 302.
- Characteristics of image 304 in image sequence 302 may be used to generate alternative image sequences, such as image sequences 318, 324, 330.
- the characteristics of an image may include the location of the image, the content of the image, and/or metadata associated with the image.
- image 304 of image sequence 302 may have characteristics 310.
- Characteristics 310 may include any number of characteristics of image 304, such as
- characteristic 312 may relate to the content of image 304 (e.g., that image 304 contains an image of a cowboy).
- the content of an image may be determined using image recognition.
- image 304 may be compared to other images of cowboys to determine that image 304 also has an image of a cowboy.
- the content of image 304 may be user- specified.
- a user may tag image 304 as including an image of a cowboy.
- the content of image 304 may be determined based in part on a comment about image 304. For example, a user of a social networking system may comment on image 304, "Wow. Great picture of a cowboy! Such a comment may be analyzed to determine that image 304 contains an image of a cowboy.
- characteristic 314 may relate to the physical location at which image 304 was taken (e.g., that image 304 was taken in San Antonio, Texas).
- the location at which an image was taken may be user-specified or may be associated with the image without user input.
- the device capturing image 304 may employ a location determining mechanism, such as cellular triangulation, a global positioning system, or the like, to associate location information as metadata with image 304.
- the location may be determined based on a user- specified tag, a comment about image 304 in a social networking system, the album or folder in which image 304 is located (e.g., an album titled "Pics from San Antonio"), or inferred based on other images (e.g., image 304 was taken one minute prior to image 304 and has metadata specifying that image 304 was taken in San Antonio, Texas).
- characteristic 316 may relate to a timestamp corresponding to when image 304 was taken (e.g., that image 304 was captured on June 4, 2014).
- the timestamp may be stored automatically (e.g., without input from a user).
- the device that captures image 304 may store a timestamp as metadata
- Timestamp information may include date information, time information, or a combination thereof.
- Characteristic 312 may be used to generate an alternative image sequence 318.
- image sequence 318 may contain other images of cowboys based in part on image 304 containing an image of a cowboy.
- image 304 may be included in image sequence 318.
- image 304 may be the focus image in the slideshow.
- images in image sequence 318 may be selected and/or ordered based on how well an image matches characteristic 312, in one implementation. For example, images 320 and 322 may precede and follow image 304 based on how well they match the topic of cowboys.
- image sequences 324, 330 may be generated based in part on characteristics 314, 316, respectively.
- image 304 in image sequence 324 may be preceded and followed by other images related to the topic of San Antonio (e.g., images 326, 328).
- Image 304 in image sequence 324 may be preceded and followed by other images also captured on June 4, 2014 (e.g., images 332, 334).
- alternative image sequences may be used in a slideshow to allow a user to navigate from a focus image in one sequence to another image in a related sequence.
- image 304 may be the current focus image in a slideshow application.
- the user may be able to navigate forward or backwards within the current image sequence (e.g., to image 306 or image 308 in image sequence 302). Navigating to another image may cause that image to become the new focus image in the slideshow, according to some implementations.
- the user may also be able to navigate forwards or backwards in image sequences 318, 324, 330, as well.
- the user may opt to begin viewing other images relating to cowboys by navigating to image 320 or image 322.
- characteristics 310 are used to generate alternative image sequences may be based on a user preference. For example, a user may specify an order of preference for characteristics used to generate alternative image sequences. In one implementation, which of characteristics 310 are used to generate alterative image sequences may be based on inferred user preferences (e.g., characteristics not specified by a user and predicted by the system to be of interest to the user). For example, if the user often selects to switch to an image sequence that contains images of cowboys, characteristic 312 may be used to generate image sequence 318 over that of other characteristics in characteristics 310. In various implementations, the number of alternative image sequences may be controlled by a user preference or may be hardcoded. For example, a user may specify that a total of four image sequences should be presented as part of a slideshow. In another example, the slideshow may be configured to limit the number of displayed image sequences to a maximum of four.
- FIG. 4 a detailed block diagram of processing circuit 400 is shown.
- Processing circuit 400 may be within, for example, a user electronic device, a web server, or another electronic computing device.
- Processing circuit 400 includes processor 402 and memory 404.
- Processor 402 may be, or include, one or more microprocessors, an application specific integrated circuit (ASIC), a circuit containing one or more processing components, a group of distributed processing components, circuitry for supporting a microprocessor, or other hardware configured for processing.
- ASIC application specific integrated circuit
- Processor 402 is also configured to execute computer code stored in memory 404 to complete and facilitate the activities described herein.
- Memory 404 can be any computer-readable medium capable of storing data or computer code relating to the activities described herein.
- memory 404 is shown to include sequence generator 418, which may be implemented using computer code (e.g., executable code, object code, source code, script code, machine code, etc.) configured for execution by processor 402.
- sequence generator 418 may be implemented using computer code (e.g., executable code, object code, source code, script code, machine code, etc.) configured for execution by processor 402.
- processing circuit 400 is configured to complete the activities described herein.
- Processing circuit may also include hardware circuitry for supporting the execution of the computer code sequence generator 418.
- processing circuit 400 may include hardware interfaces for communicating with other computing devices (e.g., another server, a client device, etc.).
- processing circuit 400 may include an input 406 for receiving requests for data from processing circuit 400 and for receiving data requested by processing circuit 400 from other devices.
- Processing circuit 400 may also include an output 408 for providing requests for data to other electronic devices and for providing requested data to other devices.
- processing circuit 400 may request an electronic file and/or metadata about the file from one or more other computing devices (e.g., a content source, a server, etc.) via output 408.
- processing circuit 400 may receive the requested data and store it in memory 404 in files 410 and/or metadata 412.
- input 406 may receive input from a user interface device (e.g., a keypad, a keyboard, a pointing device, a touch-activated device, a microphone, etc.) and output 408 may provide data to a user interface device (e.g., an electronic display, a speaker, etc.).
- processing circuit 400 may receive one or more user- specified preferences via input 406 and store them in memory 404 as user preferences 416.
- Files 410 may include one or more electronic files, such as digital images, files that contain text, spreadsheets, movies, audio files, webpages, or the like.
- files 410 may be stored using a directory structure of an operating system.
- files 410 may be stored in one or more hierarchical folders (e.g., images may be stored in the directory, /home/user/pics/vacation).
- files 410 may be grouped within an application, regardless of their directory location.
- an album of cowboy images may include the images /home/user/pics/vacation/T exas_Cowboy.jpg and
- files 410 may store the location of a file, instead of the actual file.
- files 410 may include a universal resource locator (URL) or other network address at which a file is located.
- URL universal resource locator
- Files 410 may have associated metadata 412, which may be stored as part of a file in files 410 or separately in memory 404, according to various implementations.
- a file in files 410 using the Exif format may include an image as well as metadata pertaining to the image.
- Metadata 412 may include one or more files associated with a file in files 410, in addition to, or in lieu of, the file itself containing metadata.
- an image in files 410 in Exif format may still have one or more associated files in metadata 412 that include additional information about the image (e.g., one or more topics based on the content of the image, comments about the image in a social networking system, etc.).
- Metadata 412 may include, but is not limited to, information about the contents of a file (e.g., a topic related to the file, a person identified in an image or movie, etc.), when the file was created, where the file was created, a title of a file, the owner of the file, social networking information (e.g., which user have access to the file, which users rated the file, which users commented on the file, which users are socially connected to the owner of the file, etc.), when the file was uploaded to memory 404, the device that uploaded the file to memory 404, when the file was last modified, the user that last modified the file, the memory location of the file, an album or other group of files to which the file belongs, the size of the file, or the device that created the file.
- information about the contents of a file e.g., a topic related to the file, a person identified in an image or movie, etc.
- social networking information e.g., which user have access to the file, which users rated the file, which
- memory 404 may include user profiles 414.
- User profiles 414 may be used to control access to files 410, determine metadata 412, and/or tailor the operation of the system to a particular user (e.g., by associating preferences stored in user preferences 416 with a user profile).
- user profiles 414 may be user profiles for a social networking system. In such a case, a user may associate their profile with one or more other user profiles (e.g., the user may specify which other users of the system are social connections).
- a file in files 410 may be associated with a user profile in user profiles 414, allowing the user to control how files 410 are presented (e.g., which users have access to the file, whether other users are able to modify the file, etc.).
- a user profile may include information about the user's demographics or interests. For example, a user may associate their profile with an interest group devoted to horticulture.
- memory 404 may also include user preferences 416.
- User preferences 416 are used to control the operation of processing circuit 400.
- User preferences 416 may include one or more data values that cause processing circuit 400 to operate differently, depending on the data values.
- user preferences 416 may include data values that control how many sequences are generated by sequence generator 418, which of user profiles 414 are able to access a file in files 410, and/or whether sequences are to be generated using user-specified file characteristics or automatically determined characteristics (e.g., without input from the user).
- user preferences 416 include values that control whether a generated sequence contains only files of a certain type (e.g., only image files, only text files, etc.), whether sequences are to be continuous or linear, how files are to be ordered in a sequence (e.g., based on relevance to a file characteristic, based on the order in which the files are identified, etc.), and/or whether sequence generator 418 is to even generate an alternative file sequence.
- Memory 404 includes sequence generator 418, which is configured to generate one or more file sequences containing files from files 410. According to various implementations, sequence generator 418 may be part of an application that provides a slideshow to an electronic display.
- sequence generator 418 may be part of a stand-alone slideshow application, part of a webserver application that provides a slideshow webpage via output 408, or may be part of a remote service that provides file sequences to another device running a standalone slideshow application.
- sequence generator 418 may generate a first file sequence containing some or all of files 410.
- the first file sequence may be based on one or more characteristics of files 410 (e.g., metadata 412 and other data related to files 410).
- a characteristic used by sequence generator 418 to generate a sequence may be specified by a user during execution of a slideshow and/or stored in user preferences 416. For example, a user may specify via user preferences 416 that they always want images of cats in files 410 to appear as a first sequence in a slideshow.
- the first file sequence may be determined by sequence generator 418 without user input and based on an inferred characteristic of interest for the user. For example, if a profile in user profiles 414 belongs to a social networking group devoted to funny pictures of cats, sequence generator 418 may use this information to generate a first file sequence devoted to cats.
- the files in the first file sequence and/or the order in which they appear may be entirely specified by a user.
- Sequence generator 418 may generate any number of alternative file sequences, in addition to generating a first file sequence.
- sequence generator 418 may generate an alternative file sequence based on one or more characteristics of a file in the first file sequence (e.g., the file of focus or another file). Similar to the first file sequence, the file characteristics used to generate an alternative file sequence may be based on user preferences 416 or inferred by sequence generator 418 based on information about user profiles 414 (e.g., a user's potential interests, a user's search requests, a user's social connections, etc.).
- a first file sequence may include those of files 410 that were created on August 11, 2012 and have a focus file that is an image of a woman standing in front of the Leaning Tower of Pisa. Accordingly, sequence generator 418 may generate alternative file sequences that contain those of files 410 related to Italy, the Leaning Tower of Pisa, the woman in the image, or were created around August 11, 2012.
- memory 404 may include content analyzer 420, which is configured to identify characteristics of files in files 410 based on their contents.
- content analyzer 420 may utilize image recognition to identify a person, place, or object in an image file.
- content analyzer 420 may use facial recognition to identify a person in an image as a characteristic of the image.
- Sequence generator 418 may use content analyzer 420 to identify other images that show the same person and generate a sequence of images of that person.
- content analyzer 420 may parse text in a file of files 410 to identify a topic discussed in the file.
- Content analyzer 420 may use any form of text mining technique to determine a topic of a text file (e.g., TF-IDF weighting or the like).
- content analyzer 420 may be configured to infer the content of a file based on metadata 412 and/or other files in files 410. For example, content analyzer 420 may base its determination on a comment associated with a file, a topic associated with other files located in the same directory or album as the file, etc.
- processing circuit 400 may be configured to serve a webpage that includes a slideshow.
- Processing circuit 400 may receive a login request from a remote device via input 406 to log into a profile in user profiles 414.
- processing circuit 400 may generate webpage data that causes a slideshow to be displayed on an electronic display of the requesting device.
- the slideshow may include one or more of files 410 that are selected and ordered in a first file sequence generated by sequence generator 418.
- the first file sequence may include a file of focus for the slideshow.
- Sequence generator 418 may use characteristics of the file of focus to generate alternative file sequences for the slideshow.
- the webpage data provided to the remote device via output 408 may include one or more GUI inputs to enable the user to switch between different file sequences (e.g., buttons to go forward or backward in a sequence). If an alternative file sequence is selected, a file in the alternative sequence may become the file of focus. In response, processing circuit 400 may determine new alternative file sequences, based on the characteristics of the new file of focus in the slideshow.
- Implementations of the subject matter and the operations described in this specification can be implemented in digital electronic circuitry, or in computer software embodied on a tangible medium, firmware, or hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them.
- Implementations of the subject matter described in this specification can be implemented as one or more computer programs, i.e., one or more modules of computer program instructions, encoded on one or more computer storage medium for execution by, or to control the operation of, data processing apparatus.
- the program instructions can be encoded on an artificially-generated propagated signal, e.g., a machine-generated electrical, optical, or electromagnetic signal, that is generated to encode information for transmission to suitable receiver apparatus for execution by a data processing apparatus.
- a computer storage medium can be, or be included in, a computer-readable storage device, a computer-readable storage substrate, a random or serial access memory array or device, or a combination of one or more of them.
- a computer storage medium is not a propagated signal, a computer storage medium can be a source or destination of computer program instructions encoded in an artificially-generated propagated signal.
- the computer storage medium can also be, or be included in, one or more separate components or media (e.g., multiple CDs, disks, or other storage devices). Accordingly, the computer storage medium may be tangible and non- transitory.
- client or “server” include all kinds of apparatus, devices, and machines for processing data, including by way of example a programmable processor, a computer, a system on a chip, or multiple ones, or combinations, of the foregoing.
- the apparatus can include special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC
- the apparatus can also include, in addition to hardware, code that creates an execution environment for the computer program in question, e.g., code that constitutes processor firmware, a protocol stack, a database management system, an opensocial networking system, a cross-platform runtime environment, a virtual machine, or a combination of one or more of them.
- the apparatus and execution environment can realize various different computing model infrastructures, such as web services, distributed computing and grid computing infrastructures.
- a computer program (also known as a program, software, software application, script, or code) can be written in any form of programming language, including compiled or interpreted languages, declarative or procedural languages, and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, object, or other unit suitable for use in a computing environment.
- a computer program may, but need not, correspond to a file in a file system.
- a program can be stored in a portion of a file that holds other programs or data (e.g., one or more scripts stored in a markup language document), in a single file dedicated to the program in question, or in multiple coordinated files (e.g., files that store one or more modules, sub-programs, or portions of code).
- a computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network.
- the processes and logic flows described in this specification can be performed by one or more programmable processors executing one or more computer programs to perform actions by operating on input data and generating output.
- the processes and logic flows can also be performed by, and apparatus can also be implemented as, special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application specific integrated circuit).
- processors suitable for the execution of a computer program include, by way of example, both general and special purpose microprocessors, and any one or more processors of any kind of digital computer.
- a processor will receive instructions and data from a read-only memory or a random access memory or both.
- the essential elements of a computer are a processor for performing actions in accordance with instructions and one or more memory devices for storing instructions and data.
- a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks.
- mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks.
- a computer need not have such devices.
- a computer can be embedded in another device, e.g., a mobile telephone, a personal digital assistant (PDA), a mobile audio or video player, a game console, a Global Positioning System (GPS) receiver, or a portable storage device (e.g., a USB flash drive), to name just a few.
- PDA personal digital assistant
- GPS Global Positioning System
- portable storage device e.g., a USB flash drive
- devices suitable for storing computer program instructions and data include all forms of non-volatile memory, media and memory devices, including by way of example semiconductor memory devices, e.g., EPROM, EEPROM, and flash memory devices; magnetic disks, e.g., internal hard disks or removable disks;
- magneto-optical disks and CD-ROM and DVD-ROM disks.
- the processor and the memory can be supplemented by, or incorporated in, special purpose logic circuitry.
- implementations of the subject matter described in this specification can be implemented on a computer having a display device, e.g., a CRT (cathode ray tube), LCD (liquid crystal display), OLED (organic light emitting diode), TFT (thin-film transistor), plasma, other flexible configuration, or any other monitor for displaying information to the user and a keyboard, a pointing device, e.g., a mouse, trackball, etc., or a touch screen, touch pad, etc., by which the user can provide input to the computer.
- a display device e.g., a CRT (cathode ray tube), LCD (liquid crystal display), OLED (organic light emitting diode), TFT (thin-film transistor), plasma, other flexible configuration, or any other monitor for displaying information to the user and a keyboard, a pointing device, e.g., a mouse, trackball, etc., or a touch screen, touch pad, etc., by which the user can provide input to the computer
- a computer can interact with a user by sending documents to and receiving documents from a device that is used by the user; for example, by sending websites to a web browser on a user's client device in response to requests received from the web browser.
- a computing system that includes a back-end component, e.g., as a data server, or that includes a middleware component, e.g., an application server, or that includes a front-end component, e.g., a client computer having a GUI or a Web browser through which a user can interact with an implementation of the subject matter described in this specification, or any combination of one or more such back-end, middleware, or front-end components.
- the components of the system can be interconnected by any form or medium of digital data communication, e.g., a communication network.
- Examples of communication networks include a local area network (“LAN”) and a wide area network (“WAN”), an inter-network (e.g., the Internet), and peer-to-peer networks (e.g., ad hoc peer-to-peer networks).
- LAN local area network
- WAN wide area network
- inter-network e.g., the Internet
- peer-to-peer networks e.g., ad hoc peer-to-peer networks.
- the features disclosed herein may be implemented on a smart television module (or connected television module, hybrid television module, etc.), which may include a processing circuit configured to integrate internet connectivity with more traditional television programming sources (e.g., received via cable, satellite, over-the-air, or other signals).
- the smart television module may be physically incorporated into a television set or may include a separate device such as a set-top box, Blu-ray or other digital media player, game console, hotel television system, and other companion device.
- a smart television module may be configured to allow viewers to search and find videos, movies, photos and other content on the web, on a local cable TV channel, on a satellite TV channel, or stored on a local hard drive.
- a set-top box (STB) or set-top unit (STU) may include an information appliance device that may contain a tuner and connect to a television set and an external source of signal, turning the signal into content which is then displayed on the television screen or other display device.
- a smart television module may be configured to provide a home screen or top level screen including icons for a plurality of different applications, such as a web browser and a plurality of streaming media services, a connected cable or satellite media source, other web "channels", etc.
- the smart television module may further be configured to provide an electronic programming guide to the user.
- a companion application to the smart television module may be operable on a mobile computing device to provide additional information about available programs to a user, to allow the user to control the smart television module, etc.
- the features may be implemented on a laptop computer or other personal computer, a smartphone, other mobile phone, handheld computer, a tablet PC, or other computing device.
Abstract
Description
Claims
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US13/357,316 US9542421B2 (en) | 2012-01-24 | 2012-01-24 | Sequencing electronic files |
PCT/US2013/023007 WO2013112750A1 (en) | 2012-01-24 | 2013-01-24 | Sequencing electronic files |
Publications (2)
Publication Number | Publication Date |
---|---|
EP2807588A1 true EP2807588A1 (en) | 2014-12-03 |
EP2807588A4 EP2807588A4 (en) | 2015-08-26 |
Family
ID=48798282
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
EP13741008.0A Withdrawn EP2807588A4 (en) | 2012-01-24 | 2013-01-24 | Sequencing electronic files |
Country Status (5)
Country | Link |
---|---|
US (2) | US9542421B2 (en) |
EP (1) | EP2807588A4 (en) |
CN (1) | CN104067275B (en) |
AU (1) | AU2013204983B2 (en) |
WO (1) | WO2013112750A1 (en) |
Families Citing this family (12)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US8803908B2 (en) * | 2010-01-15 | 2014-08-12 | Apple Inc. | Digital image transitions |
WO2013033458A2 (en) | 2011-08-30 | 2013-03-07 | Divx, Llc | Systems and methods for encoding and streaming video encoded using a plurality of maximum bitrate levels |
US8818171B2 (en) | 2011-08-30 | 2014-08-26 | Kourosh Soroushian | Systems and methods for encoding alternative streams of video for playback on playback devices having predetermined display aspect ratios and network connection maximum data rates |
US10452715B2 (en) * | 2012-06-30 | 2019-10-22 | Divx, Llc | Systems and methods for compressing geotagged video |
US9961721B2 (en) | 2013-01-17 | 2018-05-01 | Bsh Home Appliances Corporation | User interface for oven: info mode |
US9554689B2 (en) * | 2013-01-17 | 2017-01-31 | Bsh Home Appliances Corporation | User interface—demo mode |
US9342224B2 (en) * | 2014-01-20 | 2016-05-17 | Lenovo Enterprise Solutions (Singapore) Pte. Ltd. | Social networking web site picture album navigation path |
US10909170B2 (en) * | 2016-04-06 | 2021-02-02 | Baidu Usa Llc | Method for processing and rendering feed-like based images for mobile devices |
US10148989B2 (en) | 2016-06-15 | 2018-12-04 | Divx, Llc | Systems and methods for encoding video content |
US10733372B2 (en) * | 2017-01-10 | 2020-08-04 | Microsoft Technology Licensing, Llc | Dynamic content generation |
CN107092671B (en) * | 2017-04-13 | 2019-12-17 | 星环信息科技（上海）有限公司 | Method and equipment for managing meta information |
USD971945S1 (en) * | 2022-03-17 | 2022-12-06 | Hangzhou Ruisheng Software Co., Ltd. | Display screen with graphical user interface |
Family Cites Families (27)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP4325075B2 (en) | 2000-04-21 | 2009-09-02 | ソニー株式会社 | Data object management device |
US7594246B1 (en) * | 2001-08-29 | 2009-09-22 | Vulcan Ventures, Inc. | System and method for focused navigation within a user interface |
US7117453B2 (en) * | 2003-01-21 | 2006-10-03 | Microsoft Corporation | Media frame object visualization system |
US7509321B2 (en) * | 2003-01-21 | 2009-03-24 | Microsoft Corporation | Selection bins for browsing, annotating, sorting, clustering, and filtering media objects |
US7383497B2 (en) * | 2003-01-21 | 2008-06-03 | Microsoft Corporation | Random access editing of media |
US20050063613A1 (en) | 2003-09-24 | 2005-03-24 | Kevin Casey | Network based system and method to process images |
US7437005B2 (en) | 2004-02-17 | 2008-10-14 | Microsoft Corporation | Rapid visual sorting of digital files and data |
JP4639734B2 (en) * | 2004-09-30 | 2011-02-23 | 富士ゼロックス株式会社 | Slide content processing apparatus and program |
US20060112408A1 (en) * | 2004-11-01 | 2006-05-25 | Canon Kabushiki Kaisha | Displaying data associated with a data item |
US7715597B2 (en) * | 2004-12-29 | 2010-05-11 | Fotonation Ireland Limited | Method and component for image recognition |
AU2005203074A1 (en) * | 2005-07-14 | 2007-02-01 | Canon Information Systems Research Australia Pty Ltd | Image browser |
JP4774940B2 (en) * | 2005-11-14 | 2011-09-21 | ソニー株式会社 | Information processing apparatus, display method, and program thereof |
AU2006202063B2 (en) * | 2006-05-16 | 2009-03-12 | Canon Kabushiki Kaisha | Method for navigating large image sets using sort orders |
US8104048B2 (en) * | 2006-08-04 | 2012-01-24 | Apple Inc. | Browsing or searching user interfaces and other aspects |
WO2008133046A1 (en) | 2007-04-13 | 2008-11-06 | Nec Corporation | Photograph grouping device, photograph grouping method and photograph grouping program |
JP4433025B2 (en) | 2007-09-10 | 2010-03-17 | ソニー株式会社 | Image reproducing apparatus, image recording apparatus, image reproducing method, and image recording method |
US8190623B2 (en) * | 2008-06-05 | 2012-05-29 | Enpulz, L.L.C. | Image search engine using image analysis and categorization |
US8930817B2 (en) | 2008-08-18 | 2015-01-06 | Apple Inc. | Theme-based slideshows |
US20100058388A1 (en) * | 2008-08-28 | 2010-03-04 | Kabushiki Kaisha Toshiba | Display processing apparatus, display processing method, and computer program product |
GB0818089D0 (en) * | 2008-10-03 | 2008-11-05 | Eastman Kodak Co | Interactive image selection method |
JP5267149B2 (en) | 2009-01-19 | 2013-08-21 | ソニー株式会社 | Display control apparatus, display control method, and program |
US8907984B2 (en) | 2009-07-08 | 2014-12-09 | Apple Inc. | Generating slideshows using facial detection information |
US8078623B2 (en) | 2009-10-14 | 2011-12-13 | Cyberlink Corp. | Systems and methods for summarizing photos based on photo information and user preference |
US20110251990A1 (en) * | 2009-12-15 | 2011-10-13 | Yarvis Mark D | Techniques for template-based predictions and recommendations |
US8856656B2 (en) * | 2010-03-17 | 2014-10-07 | Cyberlink Corp. | Systems and methods for customizing photo presentations |
US20120030013A1 (en) * | 2010-07-27 | 2012-02-02 | Caroline Tsay | Slideshows in search |
US9286641B2 (en) * | 2011-10-19 | 2016-03-15 | Facebook, Inc. | Automatic photo capture based on social components and identity recognition |
-
2012
- 2012-01-24 US US13/357,316 patent/US9542421B2/en active Active
-
2013
- 2013-01-24 WO PCT/US2013/023007 patent/WO2013112750A1/en active Application Filing
- 2013-01-24 AU AU2013204983A patent/AU2013204983B2/en active Active
- 2013-01-24 CN CN201380006515.6A patent/CN104067275B/en active Active
- 2013-01-24 EP EP13741008.0A patent/EP2807588A4/en not_active Withdrawn
-
2017
- 2017-01-08 US US15/401,075 patent/US10545634B2/en active Active
Also Published As
Publication number | Publication date |
---|---|
CN104067275A (en) | 2014-09-24 |
US9542421B2 (en) | 2017-01-10 |
WO2013112750A1 (en) | 2013-08-01 |
AU2013204983B2 (en) | 2016-07-14 |
US20130191754A1 (en) | 2013-07-25 |
EP2807588A4 (en) | 2015-08-26 |
US20170235441A1 (en) | 2017-08-17 |
US10545634B2 (en) | 2020-01-28 |
CN104067275B (en) | 2017-08-25 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US10545634B2 (en) | Sequencing electronic files | |
AU2013204983A1 (en) | Sequencing electronic files | |
US11531442B2 (en) | User interface providing supplemental and social information | |
US9940693B2 (en) | Information processing for display of content based on importance level | |
US9407965B2 (en) | Interface for watching a stream of videos | |
US9235323B2 (en) | Techniques for management and presentation of content | |
KR101629588B1 (en) | Real-time mapping and navigation of multiple media types through a metadata-based infrastructure | |
US20230291975A1 (en) | Systems and methods for navigating media assets | |
CN104427376A (en) | Information display apparatus, information display method, and computer program | |
WO2013051014A1 (en) | A method and system for automatic tagging in television using crowd sourcing technique | |
KR20170044659A (en) | Method and apparatus for processing a file | |
US9607314B1 (en) | Expansion of high performing placement criteria | |
KR102408256B1 (en) | Method for Searching and Device Thereof | |
US20150221112A1 (en) | Emotion Indicators in Content | |
TW201330598A (en) | Real-time mapping and navigation of multiple media types through a metadata-based infrastructure | |
WO2016094206A1 (en) | Method and apparatus for processing information | |
JP2021520139A (en) | Importing media libraries using graphical interface analysis | |
Chen et al. | Teleoperation Augmented Reality System Based on Dual Vision | |
WO2012061877A1 (en) | A system, method and computer program for collating and presenting information |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PUAI | Public reference made under article 153(3) epc to a published international application that has entered the european phase |
Free format text: ORIGINAL CODE: 0009012 |
|
17P | Request for examination filed |
Effective date: 20140825 |
|
AK | Designated contracting states |
Kind code of ref document: A1Designated state(s): AL AT BE BG CH CY CZ DE DK EE ES FI FR GB GR HR HU IE IS IT LI LT LU LV MC MK MT NL NO PL PT RO RS SE SI SK SM TR |
|
DAX | Request for extension of the european patent (deleted) | ||
RA4 | Supplementary search report drawn up and despatched (corrected) |
Effective date: 20150728 |
|
RIC1 | Information provided on ipc code assigned before grant |
Ipc: G06F 17/30 20060101AFI20150722BHEP |
|
RAP1 | Party data changed (applicant data changed or rights of an application transferred) |
Owner name: GOOGLE LLC |
|
17Q | First examination report despatched |
Effective date: 20181015 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: THE APPLICATION HAS BEEN WITHDRAWN |
|
18W | Application withdrawn |
Effective date: 20191115 |
|
P01 | Opt-out of the competence of the unified patent court (upc) registered |
Effective date: 20230519 |