CN108292241A - Processing calculates figure - Google Patents
Processing calculates figure Download PDFInfo
- Publication number
- CN108292241A CN108292241A CN201680063236.7A CN201680063236A CN108292241A CN 108292241 A CN108292241 A CN 108292241A CN 201680063236 A CN201680063236 A CN 201680063236A CN 108292241 A CN108292241 A CN 108292241A
- Authority
- CN
- China
- Prior art keywords
- node
- subgraph
- calculating
- equipment
- represented
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
- 238000012545 processing Methods 0.000 title claims abstract description 32
- 238000000034 method Methods 0.000 claims description 51
- 238000013528 artificial neural network Methods 0.000 claims description 36
- 238000012549 training Methods 0.000 claims description 14
- 230000001537 neural effect Effects 0.000 claims description 12
- 238000010801 machine learning Methods 0.000 claims description 9
- 230000006872 improvement Effects 0.000 claims description 5
- 238000012544 monitoring process Methods 0.000 claims description 4
- 238000004590 computer program Methods 0.000 abstract description 12
- 230000015654 memory Effects 0.000 description 21
- 230000006870 function Effects 0.000 description 12
- 230000008569 process Effects 0.000 description 12
- 239000011159 matrix material Substances 0.000 description 11
- 238000004364 calculation method Methods 0.000 description 8
- 230000009471 action Effects 0.000 description 7
- 230000004044 response Effects 0.000 description 7
- 238000004891 communication Methods 0.000 description 6
- 230000004048 modification Effects 0.000 description 4
- 238000012986 modification Methods 0.000 description 4
- 238000005516 engineering process Methods 0.000 description 3
- 230000009897 systematic effect Effects 0.000 description 3
- 230000003321 amplification Effects 0.000 description 2
- 238000004458 analytical method Methods 0.000 description 2
- 230000000712 assembly Effects 0.000 description 2
- 238000000429 assembly Methods 0.000 description 2
- 230000008901 benefit Effects 0.000 description 2
- 230000005611 electricity Effects 0.000 description 2
- 230000003993 interaction Effects 0.000 description 2
- 238000003199 nucleic acid amplification method Methods 0.000 description 2
- 238000005457 optimization Methods 0.000 description 2
- 238000000926 separation method Methods 0.000 description 2
- 241000208340 Araliaceae Species 0.000 description 1
- 235000005035 Panax pseudoginseng ssp. pseudoginseng Nutrition 0.000 description 1
- 235000003140 Panax quinquefolius Nutrition 0.000 description 1
- 230000009118 appropriate response Effects 0.000 description 1
- 238000004422 calculation algorithm Methods 0.000 description 1
- 230000008878 coupling Effects 0.000 description 1
- 238000010168 coupling process Methods 0.000 description 1
- 238000005859 coupling reaction Methods 0.000 description 1
- 238000010586 diagram Methods 0.000 description 1
- 238000011156 evaluation Methods 0.000 description 1
- 238000005194 fractionation Methods 0.000 description 1
- 235000008434 ginseng Nutrition 0.000 description 1
- 210000003127 knee Anatomy 0.000 description 1
- 239000004973 liquid crystal related substance Substances 0.000 description 1
- 210000005036 nerve Anatomy 0.000 description 1
- 238000003012 network analysis Methods 0.000 description 1
- 230000003287 optical effect Effects 0.000 description 1
- 238000013515 script Methods 0.000 description 1
- 239000004065 semiconductor Substances 0.000 description 1
- 239000000758 substrate Substances 0.000 description 1
- 230000000007 visual effect Effects 0.000 description 1
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/098—Distributed learning, e.g. federated learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/46—Multiprogramming arrangements
- G06F9/50—Allocation of resources, e.g. of the central processing unit [CPU]
- G06F9/5005—Allocation of resources, e.g. of the central processing unit [CPU] to service a request
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/46—Multiprogramming arrangements
- G06F9/50—Allocation of resources, e.g. of the central processing unit [CPU]
- G06F9/5005—Allocation of resources, e.g. of the central processing unit [CPU] to service a request
- G06F9/5027—Allocation of resources, e.g. of the central processing unit [CPU] to service a request the resource being a machine, e.g. CPUs, Servers, Terminals
- G06F9/5038—Allocation of resources, e.g. of the central processing unit [CPU] to service a request the resource being a machine, e.g. CPUs, Servers, Terminals considering the execution order of a plurality of tasks, e.g. taking priority or time dependency constraints into consideration
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/46—Multiprogramming arrangements
- G06F9/50—Allocation of resources, e.g. of the central processing unit [CPU]
- G06F9/5061—Partitioning or combining of resources
- G06F9/5066—Algorithms for mapping a plurality of inter-dependent sub-tasks onto a plurality of physical CPUs
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N20/00—Machine learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/045—Combinations of networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/06—Physical realisation, i.e. hardware implementation of neural networks, neurons or parts of neurons
- G06N3/063—Physical realisation, i.e. hardware implementation of neural networks, neurons or parts of neurons using electronic means
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/084—Backpropagation, e.g. using gradient descent
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N5/00—Computing arrangements using knowledge-based models
- G06N5/04—Inference or reasoning models
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N5/00—Computing arrangements using knowledge-based models
- G06N5/04—Inference or reasoning models
- G06N5/048—Fuzzy inferencing
Abstract
Mthods, systems and devices include the computer program encoded on computer storage media, are used for：The request that processing calculates figure is received from client；It obtains and indicates the data for calculating figure, the calculating figure includes multiple nodes and directed edge, wherein, each node indicates corresponding operation, wherein, corresponding first node is connected to corresponding second node by each directed edge, and the corresponding second node indicates to receive the output operation as input of the operation represented by the corresponding first node；Identify multiple available devices for executing requested operation；The calculating figure is divided into multiple subgraphs, each subgraph includes one or more of calculating figure node；And it is directed to each subgraph, the operation represented by one or more of subgraph node is assigned to the corresponding available devices in the multiple available devices for operation.
Description
Background technology
This specification is related to processing and indicates the calculating figure of neural network and/or handle model using processed calculating figure
Input.
Neural network is machine learning model, and it is defeated to be directed to the input received generation using one or more layers model
Go out, such as one or more classifications.Some neural networks further include one or more hidden layers other than output layer.It is each hidden
Hide layer output be used as to next layer in network, the i.e. next hidden layer or output layer of network, input.Network it is each
Layer generates output according to the current value of the relevant parameter collection of this layer from the input received.
The layer of neural network can be handled by individual equipment.The equipment can have the processor for executing operation, example
Such as, output is generated from input at one layer, and in memory by the output of operation storage.It is defeated due to being generated in neural network
Go out to usually require quantity and operation in large scale, therefore an equipment may take a significant amount of time to handle neural network
Layer.
Invention content
In general, this specification describes a kind of to indicate based on neural network or another machine learning model by handling
The system and method for nomogram.
In general, one of theme described in this specification innovative aspect can be presented as including following action
Method：The request that processing calculates figure is received from client；It obtains and indicates the data for calculating figure, the calculating figure includes multiple
Node and directed edge, wherein each node indicates corresponding operation, wherein corresponding first node is connected to accordingly by each directed edge
Second node, the corresponding second node indicate to receive the output of the operation represented by the corresponding first node as input
Operation；Identify multiple available devices for executing requested operation；The calculating figure is divided into multiple subgraphs, each
Subgraph includes one or more of calculating figure node；And it is directed to each subgraph, it will be by one or more in the subgraph
Operation represented by a node is assigned to the corresponding available devices in the multiple available devices for operation.The method can be with
It is computer implemented method.
Embodiment can include one or more of following characteristics.The request refers to from one or more respective nodes
Fixed one or more specific output, further comprises：The equipment being assigned to from one or more of respective nodes receives institute
State one or more specific outputs；And one or more of specific outputs are supplied to the client.Pass through the meter
The operation of nomogram includes the reasoning or training operation for neural network.It is described request include the calculating figure is divided into it is multiple
The label of predetermined subgraph, and it includes that the calculating figure is divided into the multiple predetermined subgraph wherein to divide the calculating figure.
Each equipment is independently of the hardware resource that the other equipment in the multiple equipment executes operation.Each subgraph is assigned to phase
It includes that the subgraph is assigned to the calculating energy needed for the operation executed represented by the node in the subgraph to answer equipment
The equipment of power.The calculating figure is analyzed to identify the node group arranged with chain structure；Wherein, described divide includes being directed to each institute
The group of identification generates the corresponding subgraph for including identified node group.The calculating figure is analyzed to identify to being flowed on directed edge
The shared data of the node group carries out the node group of operation；Wherein, the division includes being generated for the group each identified
Corresponding subgraph including the node group identified.Determine subgraph to equipment original allocation；Monitor that the equipment is counted to determine
Data；The original allocation is adjusted using the statistical data；And it is based on adjusted original allocation, by the subgraph weight
Newly it is assigned to equipment.Repetition is monitored, adjusts and is redistributed, until having reached threshold value improvement.The statistical data includes needle
Corresponding operation time to each subgraph or respective free time.
In another embodiment, the method further includes：Receive mode input；And according to by processed
Operation represented by calculating figure handles the mode input.
Can be presented as in terms of another novelty of theme described in this specification may include following action side
Method：Machine learning model corresponding with the processed calculating figure obtained by first aspect is provided；And described in use
Machine learning model handles mode input.Processing mode input may be constructed the training of the machine learning model, Huo Zheqi
It may be constructed from the mode input and generate reasoning.
Can be presented as in terms of another novelty of theme described in this specification may include following action side
Method：The processed calculating figure obtained by first aspect is executed by multiple equipment.
In these aspects, the calculating figure can be the expression of machine learning model, for example, neural network.
It can be presented as the method for including following action in terms of another novelty of theme described in this specification：Make
Mode input is handled according to calculating figure with multiple equipment, the calculating figure includes multiple nodes and directed edge, wherein each section
Point indicates corresponding operation, wherein corresponding first node is connected to corresponding second node, corresponding second section by each directed edge
Point indicates to receive the output operation as input of the operation represented by the corresponding first node, wherein the method packet
It includes for each in the multiple equipment：The data of the subgraph for the calculating figure for indicating to be assigned to the equipment are received, it is described
Subgraph includes multiple nodes and directed edge from the calculating figure；And the fortune represented by the node in the execution subgraph
It calculates.
Embodiment in this respect can include one or more of following characteristics.It is described to ask from one or more phases
The specified one or more specific outputs of node are answered, are further comprised：It receives from one or more of subgraph respective nodes
The request of the one or more specific outputs of identification；And one or more of specific outputs are supplied to client.The side
Method further comprises monitoring statistical data；And the statistical data is supplied to client.The statistical data includes being directed to
The corresponding operation time or respective free time of each subgraph.Execute the operation represented by the node in the subgraph include with
Asynchronous system executes the operation.Execute in an asynchronous manner the operation include using queue, non-obstruction kernel or both come
Execute the operation.
Other aspects provide a kind of system corresponding with the either side in above-mentioned aspect and one kind is computer-readable
Medium.The computer-readable medium can be non-transitory computer-readable medium, however, the present invention is not limited thereto.
The specific embodiment that can implement theme described in this specification, to realize one or more in following advantages
It is a.The operation of neural network, such as from the operation of input generation reasoning, the calculating figure of node and directed edge can be represented as.
System handles this calculation chart and shows efficiently to execute the operation of neural network.The reason of system reaches this efficiency exists
In calculating figure has lower abstractness compared to the conventional neural networks for being expressed as series of layers.Particularly, with traditional neural net
Network expression is compared, and calculating figure is easier to be divided for concurrent operation.For example, the subgraph of calculating figure can be assigned
To unique equipment, for example, each subgraph can be assigned to the equipment different from other subgraphs, wherein each equipment executes phase
The operation in subgraph is answered, to reduce the overall time executed needed for neural network computing.
The one or more embodiments of the detail of theme described in this specification are illustrated in the accompanying drawings and the following description.Refering to saying
Bright book, drawings and claims, other features, aspect and the advantage of the theme will be evident.It will be appreciated that can be by this
A little aspects and embodiment combination, and the upper and lower feature described herein of one side or embodiment can be in other respects
Or it is realized in the context of embodiment.
Description of the drawings
Fig. 1 illustrates the example calculations drawing system of the operation for being distributed the neural network for being expressed as calculating figure.
Fig. 2 is the flow chart of the exemplary method for handling calculating figure.
Fig. 3 is example calculations figure.
Fig. 4 is the flow chart of the instantiation procedure for subgraph to be assigned to equipment.
Similar drawing reference numeral and label indicate similar element in the various figures.
Specific implementation mode
This specification generally describes a kind of calculating figure system executing the operation represented by calculating figure in a distributed fashion
System.
Calculating figure includes the node connected by directed edge.The each node calculated in figure indicates operation.Into the defeated of ingress
Enter the inlet flow that side indicates entry into node, that is, the input to the operation represented by node.The output side expression for leaving node will
It is used as the input to the operation represented by another node, operation represented by node output stream.Therefore, will scheme
In first node be connected to the directed edge of the second node in figure and indicate the output that operation represented by first node generates
It is used as the input to the operation represented by second node.
Usually, it is tensor along outputting and inputting for directed edge flowing in calculating figure.Tensor is number or other values
Multidimensional numerical, for example, character string, has particular order corresponding with array dimension.For example, scalar value is 0 rank tensor, numerical value
Vector is 1 rank tensor, and matrix is 2 rank tensors.
In some embodiments, operation represented in calculating figure is neural network computing or is used for different type machine
The operation of device learning model.Neural network is a kind of machine learning model, uses one or more layers non-linear unit to be directed to and connects
The input received is predicted to export.Some neural networks are in addition to output layer further include one or more hidden layers depth god
Through network.The output of each hidden layer is used as to another layer in network, i.e. another hidden layer, output layer or the two,
Input.Some layers of network generate output according to the current value of relevant parameter collection from the input received, and network is another
A little layers may not have parameter.
For example, the operation represented by calculating figure can be the operation needed for neural computing reasoning, that is, neural network
Processing is by the input of neural net layer to generate the operation being directed to needed for the neural network output of input.As a further example, by counting
Operation represented by nomogram can train god by executing neural network training process to adjust the parameter value of neural network
Through the operation needed for network, for example, to determine housebroken parameter value from initial parameter value.In some cases, for example, instructing
Can include the operation performed by multiple copies of neural network by calculating the operation represented by scheming during practicing neural network.
For example, from first layer receive input neural net layer can using parameter matrix come execute parameter matrix with
Matrix multiplication between input.In some cases, this matrix multiplication can be represented as multiple nodes in calculating figure.Example
Such as, matrix multiplication can be divided into multiple multiplication and add operation, and each operation can be by the different node tables in calculating figure
Show.Operation represented by each node can generate corresponding output, which flows on directed edge to subsequent node.
After the result of operation generator matrix multiplication represented by finish node, which flows to another node on directed edge.
The result is equal to the output for the neural net layer for executing matrix multiplication.
Under some other situation, matrix multiplication is represented as a node in figure.As input, represented by node
Operation can be received on the first directed edge input tensor and on the second directed edge receive weight tensor, for example, parameter
Matrix.Node can handle input tensor sum weight tensor, for example, the matrix multiplication of input tensor sum weight tensor is executed, with
Output is equal to the output tensor of the output of neural net layer on third directed edge.
Can include by other neural network computings of the expression of the node in calculating figure：Other mathematical operations, for example, subtracting
Method, division and gradient calculate；Array operation, for example, concatenation, splicing, fractionation or sequence；And neural network building blocks operation, example
Such as, SoftMax, Sigmoid, amendment linear unit (ReLU) or convolution.
For calculating figure provide Neural Networks Representation to a kind of flexible and careful mode efficiently to realize neural network,
Especially in the case where the operation of neural network is distributed across the multiple equipment with different hardware configurations file.
Fig. 1 illustrates the example calculations drawing system 100 of the operation for being distributed the neural network for being expressed as calculating figure.System
100 be the example for the system realized as computer program on one or more of one or more positions computer,
In can realize system as described below, component and technology.
The user of client 102 can ask to execute operation in the calculating figure for indicating neural network.Client 102 can be
The application run on computers.
As a part for request, client 102 provides the data that identification calculates figure to system 100, and it is specified will be
Calculate the type for the operation that figure executes.
For example, request, which can identify the calculating figure for the reasoning for indicating to be directed to specific neural network and can identify, copes with it
Execute the input of reasoning.
As a further example, request, which can identify, indicates the calculating figure for the training process of specific neural network and can know
It is not coped with executes the input of training, such as training data.In this example, when the calculating for receiving processing expression training process
When the request of figure, system 100 can be calculated for example using conventional backpropagation or other neural metwork training technologies to determine
The parameter modified values on one or more sides of figure.Modification parameter can be stored in the memory of equipment by system 100, and be held
Row device 106 can be retrieved at system 100 and store the address of modification weight.Reasoning, instruction are further being asked from client 102
After other operations experienced or that need modification weight, system 100 can access power of amendment weight using address.
In some cases, the response that request can should be sent with specified response request.For example, being directed to neural metwork training
Request, client 102 can ask to have completed the instruction of requested neural metwork training operation, and optionally, nerve
The parameter training value of network can be for the instruction of the storage location of the access trained values of client 102.As a further example, for god
It is asked through network reasoning, client 102 can ask to indicate the reasoning operation of one or more specific nodes from calculating figure
Output valve.
System 100 executes operation to generate spy by dividing the operation represented by calculating figure across multiple equipment 116 to 122
Fixed output.System 100 is by data communication network 114, for example, LAN (LAN) or wide area network (WAN)), operation is divided into
Multiple equipment 116 to 122.Equipment 116 to 122 executes operation, and if applicable, then will export or indicate a return to accordingly
System 100, system 100 can export or indicate a return to client 102 by requested.
Any equipment of neural network computing, such as equipment 116 to 122 are executed, it can be including sum number for storing instruction
According to memory, such as random access memory (RAM), and the processor for executing stored instruction.Usually, often
A equipment is that the hardware resource of operation is executed independently of other equipment.For example, each equipment can be with the processing of own
Unit.These equipment can be graphics processing unit (GPU) or central processing unit (CPU).For example, a machine can
Trustship one or more equipment, for example, multiple CPU and GPU.
Each equipment can also have corresponding computing capability.That is, equipment can have different memories to hold
Amount, processing speed or other architectural features.Therefore, some equipment are able to carry out the operation that other equipment can not execute.For example, one
A little operations need certain memory capacity or some equipment that only particular device just has to be configured to only execute certain kinds
The operation of type, for example, reasoning operation.
The request of the session since receiving client 102 of session manager 104 in system 100, holds in the ession for telecommunication
Row calculates the operation of figure.Session manager 104 manage be able to carry out calculating figure operation one group of equipment, such as equipment 116 to
122, and the one group of equipment that can be used for executing operation can be provided to layout device (placer) 108.
For each operation pending in figure is calculated, layout device 108 determines the respective objects equipment for executing the operation, example
Such as equipment 116, and in some embodiments, determine that respective objects equipment executes the time of operation.Some operations can be by
It is parallel to execute, and other operations then require to complete the first operation in calculating figure, such as the first operation of other calculation process is defeated
Go out as input.
After the operation that equipment execution layout device 108 is distributed is to generate output, actuator 106 being capable of search and output.
Actuator 106 can generate the appropriate response to request, such as complete the output or instruction of processing.Then, actuator 106
Client 102 can be returned a response to.
Operation set pending in calculating figure is also supplied to actuator 106 by session manager 104.Actuator 106 weeks
Phase property executes retrieval operation time statistical data in relevant equipment 116 to 122 from the figure of operation.Actuator 106 is by operation
Time statistical data is supplied to layout device 108, layout device 108 to be capable of layout and the scheduling of the further operation of re-optimization.Below
This re-optimization will be further described with reference to Fig. 2.
Fig. 2 is the flow chart of the instantiation procedure 200 for handling calculating figure.For the sake of convenient, process 200 is described as by position
One or more system for computer in one or more positions execute.For example, properly programmed calculating drawing system, such as scheme
1 calculating drawing system 100, is able to carry out process 200.
System receives the request (step 202) that processing calculates figure from client.For example, the request can be to specified defeated
Enter to execute the request of the ANN Reasoning represented by calculating figure, specified training dataset is executed represented by calculating is schemed
Neural metwork training operation request or execute request by calculating other represented neural network computings of figure, ginseng as above
Described in Fig. 1.
System obtains the data (step 204) for indicating to calculate figure.In some cases, the data and asking from client
It asks and sends together.In other circumstances, request identification calculating figure and system are retrieved from memory indicates identified figure
Data.For example, the data of expression figure can be the array of figure interior joint.Each node can include specified arithmetic type,
The information of the list of title and node input while with output.
System identification is used to execute multiple available devices (steps 206) of requested operation.System is connectable to number
A equipment, such as in the data center.System can keep the state of each equipment, such as the actuator 106 using Fig. 1.Often
A equipment is likely to be at occupancy or available.If equipment is currently just executing other operations and is being unable to be assigned further operation
Or figure processing operation can not be executed, then the equipment, which is in, occupies.If equipment can be assigned further operation, such as can
Enough further operation is lined up to carry out operation by equipment, then the equipment is in available.
Calculating figure is divided into multiple subgraph (steps 208) by system.Each subgraph includes calculating one or more of figure
Node.In some embodiments, the request from client includes label, specified that calculating figure should be divided into predetermined subgraph
Mode.For example, user can manually generate the label of calculating figure and include in the request by label.If request includes this
Label, then system calculating figure is divided into predetermined subgraph.
In some other implementations, system divides calculating figure based on the mode of arrangement calculating figure.Particularly, system
The figure can be analyzed to identify the directed edge for the one or more nodes arranged with chain structure in connection calculating figure.In chain structure
Node is by along a directed edge node connected with each other from node-to-node.Therefore, the node in chain is calculating it
The operation that first node in chain is had to wait for before the operation of oneself is completed to calculate.Division subgraph will be further described with reference to Fig. 3.
In yet other embodiment, system is by the node clustering in figure, then by the node in same cluster point
It is fitted on identical subgraph.Particularly, system can analyze the figure and be transported to the shared data flowed on directed edge with identifying
The node of calculation.For example, multiple nodes can receive identical data as input from first node.System can will be in identical son
This kind of node clustering that identical data is received in figure, so that when subgraph is assigned to particular device, equipment is able to reuse that
Memory stores the identical data for multiple operations represented by node.This point will be further described with reference to Fig. 3.
It is discussed in more detail below the mode of system spanning subgraph.
System is directed to each subgraph, and the operation represented by one or more of subgraph node is assigned to accordingly
Available devices (step 210).In some embodiments, each subgraph is assigned to execution by the node in subgraph by system
The equipment of computing capability needed for represented operation.In some embodiments, the request from client includes by user
Specified data, the data identify certain types of equipment to execute the operation of specific node.It should be incited somebody to action for example, user can specify
Specific node with a large amount of mathematical operations is assigned to GPU.Subgraph including specific node can be assigned to spy by system
Determine the equipment of type.
In some other implementations, system indicates that the maximum that the operation of the node in subgraph is consumed provides by estimation
It measures to determine the equipment for being assigned to subgraph in source.For example, system can calculate in subgraph any node by the maximum storage of consumption
Device capacity.Particularly, the tensor on each directed edge that system can traverse subgraph to calculate each node for travelling to and fro between subgraph
Dimension.The dimension indicating equipment of tensor executes the memory size that operation is consumed.Subgraph can be assigned to by system to be had
The equipment that the memory of the maximum tensor flowed in subgraph can be stored in.
The another embodiment that subgraph is assigned to equipment is further described below in reference to Fig. 4, and hereafter can be more
Add the system of being discussed in detail that subgraph is assigned to the mode of equipment.
System promote equipment execute be assigned to equipment node operation (step 212).In some embodiments, system
The request for starting operation is sent to each equipment.Equipment receives request, and in response, starts execution and is assigned to the equipment
The operation of node.In some embodiments, equipment executes the operation for the node for being assigned to equipment in an asynchronous manner.For example, setting
It is standby operation to be executed by using queue, non-obstruction kernel or the two in an asynchronous manner.It is described below and holds in an asynchronous manner
Row operation.
Fig. 3 illustrates example calculations figure.For example, drawing system, such as the system 100 of Fig. 1 are calculated, it can be from client
Request is received, one group of input is given, carrys out computational reasoning using the calculating figure.Particularly, client is capable of the defeated of requesting node 316
Go out.This group input can be supplied to node 302 on directed edge.
Calculating figure can be divided into three sub- Figure 31 8 to 322 by system.For spanning subgraph 318 to 322, system can
Analysis meter nomogram is with recognition node chain.For example, system is capable of the first chain of recognition node 304,316, node 302,306,310
The third chain of second chain and node 308,312,314.Although other possible node chains are also feasible, system can select to make
The minimized chain of subgraph number.Node chain can be grouped as corresponding subgraph by system.
In some embodiments, if the output phase of node 306 is same, node 306,308 and 310 is grouped as by system
One subgraph.The reason is that node 310 and 308 all receives identical output from node 306.In this case, identical
The operation represented by node 310 and 308 is executed in equipment so that memory consumption minimizes.That is, when being directed to node
When 310 and 308 execution operation, equipment is able to access that the same memory position of output of the storage from node 306.
Three sub- Figure 31 8 to 322 can be assigned to three corresponding available devices by system.System can start from distributing
First subgraph 322, because it includes any node in start node 302 and node all independent of the defeated of other subgraphs
Go out.Once being assigned with the first subgraph 322, system just can distribute the second subgraph 318.Node 304 in second subgraph 318 needs
The output of node 302, the output will be calculated by the equipment for distributing to the first subgraph 322.
In some embodiments, second subgraph 318 to be allocated such as system has completed 302 institute of node until receiving
The instruction of the operation of expression.This current information of permission system based on such as memory availability or equipment availability is come dynamically
Subgraph is distributed, this can improve efficiency.After receiving instruction, the second subgraph 318 can be assigned to by system can handle node
The equipment of 302 output size.In some other implementations, the network analysis figure is to determine from node 302 to 304
The dimension of the tensor flowed on directed edge.Then, system can distribute the second subgraph 318 based on tensor dimension.That is,
The equipment that second subgraph 318 is assigned to the storage requirement for the tensor that can be handled to the second subgraph 318 by system.
Similarly, the start node 308 of third subgraph 320 needs the output of node 306.System can wait third to be allocated
Subgraph 320, until the equipment that the first subgraph is assigned to completes the operation represented by node 306.Once completing 306 tables of node
The operation shown, system are just capable of the output of analysis node 306 so that third subgraph 320 is assigned to corresponding available devices.
Equipment can suspend operation at the node for needing still uncalculated input, such as into idle state.For example,
After the operation for executing node 308, the equipment for distributing to third subgraph 320 is able to carry out the operation of node 312.Then, it distributes
Determine whether that the input from node 310 has been received to the equipment of third subgraph 320.Equipment can wait pending node
312 operation, until equipment receives the input from node 310.
In the last one node, i.e. node 316, after executing operation, the equipment that node is assigned to can be by the node
What output or completion figure were handled indicates a return to system.Optionally, output can be returned to client by system again.
Fig. 4 is the flow chart of the instantiation procedure 400 for subgraph to be assigned to equipment.For the sake of convenient, process 400 is described
For by one or more system for computer execution positioned at one or more positions.For example, properly programmed calculating drawing system,
Such as the calculating drawing system 100 of Fig. 1, it is able to carry out process 200.
System determines subgraph to the original allocation (step 402) of equipment.System can be determined by using greedy algorithm
To the original allocation of equipment.That is, system determines subgraph point by analyzing one or more of subgraph start node
The equipment being fitted on.The node that start node, which is data, to be flowed in subgraph since it.
In some embodiments, system determines operation represented by start node or by being connected to start node
The memory capacity that operation represented by node is consumed.Described in Fig. 2 and Fig. 3, system can be analyzed to or be come from
The dimension of the tensor of start node, to determine by the memory capacity of consumption, as described above with reference to FIG. 2.
Based on identified capacity, subgraph is assigned at least equipment with identified memory capacity by system.It is logical
Consideration start node rather than subsequent node are crossed, subgraph rapidly can be assigned to equipment by system, but these distribution may not be
It is optimal, because subsequent node may need the resource that distributed equipment possibly can not be handled efficiently, for example, if dividing
The not enough memories of the equipment matched, it is therefore necessary to which subsequent arithmetic represented in subgraph could be executed by implementing paging.
System monitoring equipment is to the processing of figure to determine statistical data (step 404).For example, system can monitor each set
Standby operation time, free time or the two.Operation time is that equipment completes request the time it takes from client.
That is, each equipment of systematic survey completes the distributed subgraph operation time to be spent.System can also measure each
The time that equipment waits for subsequent arithmetic idle during the subgraph that equipment is distributed in processing.
System adjusts original allocation (step 406) by using statistical data.Particularly, system can adjust initial point
With so that operation time, free time or the two minimize.For example, based on the first subgraph and the second subgraph it is corresponding just
Beginning node, system can distribute the first equipment and execute second to execute the operation of the first subgraph and distribute the second equipment first
The operation of subgraph.After the time that tracking executes operation, system can compare the resource between the first equipment and the second equipment
Utilization rate.If the first equipment longer period more idle than the second equipment, but the first equipment has more than the second equipment
Processing capacity and memory are then directed to and carry out the subsequent request of operation using the first subgraph and the second subgraph, and system can be adjusted
Whole first subgraph is to the distribution of the second equipment and the distribution of the second subgraph to the first equipment.
Subgraph is re-assigned to equipment (step 408) by system according to adjusted distribution.That is, being stated on connecting
Bright, in response to using the first subgraph and the second subgraph to carry out the subsequent request of operation, the first subgraph is assigned to second and set by system
It is standby and the second subgraph is assigned to the first equipment.
System can repeat step 404 to 408, and performance is improved to be continually updated distribution.For example, system can determine
Adjustment distributes a variety of possibilities so that free time minimum.System can selectively by specific subgraph be assigned to it is numerous not
Same equipment.In the subsequent arithmetic of specific subgraph, the first possibility of Systematic selection and the first fortune for being measured operation
Evaluation time.In another subsequent arithmetic, system selects second of possibility and is measured during second of iteration
Second operation time.In another subsequent arithmetic, Systematic selection operation time shortest possibility and can be directed to difference
Subgraph select different distribution possibilities.In some embodiments, system can repeat these steps, until having reached threshold
It is worth improvement.
After equipment is assigned to corresponding subgraph, equipment executes the operation of corresponding subgraph, for example, using by calculation chart
The neural network (or other machines learning model) shown handles mode input.After completing operation, equipment can be logical to system
Know the output (if any) for completing operation or operation.In some cases, the request that system receives can specify sound
Should include the one or more outputs for calculating the specific node in figure.After completing operation, system can be from particular device point
The one or more equipment being fitted on receive the output of specific node.Then, system can provide output to client, as above join
Described in Fig. 1.
In some embodiments, user can specify such as subgraph of calculating figure, the node in calculating figure or calculating
Function of the calculating figure part of the different sets of multiple nodes as the component part that can be re-used as other calculating figures in figure.
Particularly, in these embodiments, after providing the data that identification calculates figure to system, user can submit request, with
The specific part of specified calculating figure is associated as reusable function and by the reusable function and function name, function name
Such as the identifier that generates of system or the logical name specified of user.Then, system, which can preserve, identifies in the specific part
The data at node and edge and the part and function name is associated.In later time, system can receive processing and include
The request of figure is calculated to the reference of function another, for example, should using the output of the specific node in another calculating figure as
Input is supplied to the function with the function name and should be fed as input to the output of the function in another calculating figure
Another specific node instruction.In response to the request, system can identify the associated figure part of and function name and energy
Enough generate the amplification calculating figure that appropriate position includes the figure part.Then, system can handle amplification calculating as described above
Figure.Therefore, user can be easy to include certain common reuse operations in its calculating figure, for example, to neural net layer
Specific configuration operation, without regenerate every time indicate those operations figure part.
The embodiment of theme and functional operation described in this specification can be in Fundamental Digital Circuit, the computer of tangible implementation
The computer hardware of software or firmware including structure disclosed in this specification and its structural equivalents or one of them or it is more
It is realized in a combination.The embodiment of theme described in this specification can be implemented as one or more computer programs, that is,
One or more modules of the computer program instructions encoded on tangible non-transitory program carrier, for data processing equipment
Execute or control its operation.Alternatively or additionally, program instruction can be coded on manually generated transmitting signal, example
Such as, electric signal, optical signal or the electromagnetic signal that machine generates, the signal are generated suitable to be transferred to for coding information
Receiver apparatus, for data processing equipment execute.Computer storage media can be that machine readable storage device, machine can
Read storage substrate, random or serial access storage device or combination of one or more of them.However, computer storage is situated between
Matter is not transmitting signal.
Term " data processing equipment " covers various types of device, equipment and machines for handling data, such as wraps
Include programmable processor, computer or multiple processors or computer.The device can include dedicated logic circuit, example
Such as, FPGA (field programmable gate array) or ASIC (application-specific integrated circuit).In addition to hardware, which can also be including being upper
The code that computer program creates performing environment is stated, for example, constituting processor firmware, protocol stack, data base management system, operation
The code of the combination of system or in which one or more.
(it can also be referred to as or be described as program, software, software application, module, software module, foot to computer program
This or code) can be in any form programming language write to write, including compiler language or interpretative code or declaratively
Language or process programming language, and it can be disposed in any form, including as stand-alone program or as module, group
Part, subroutine or other units suitable for computing environment.Computer program can with but do not need to correspond in file system
File.Program can be stored in the file part for preserving other programs or data, such as be stored in marking language document
One or more scripts, be exclusively used in the single file of above procedure or multiple coordinated files in, such as storage one or
The file of multiple modules, subprogram or code section.Computer program can be deployed on one computer or be located at
One website or across multiple websites be distributed and by communication network interconnect multiple stage computers on execute.
As used in this specification, " engine " or " software engine " refers to the software reality for providing the output different from input
Existing input/output.Engine can be encoded functional block, such as library, platform, Software Development Kit (" SDK ")
Or object.Each engine can realize with the computing device of any appropriate type, computing device such as server, mobile electricity
Words, Tablet PC, notebook computer, music player, E-book reader, on knee or desktop computer,
PDA, smart phone or including other of one or more processors and computer-readable medium are fixed or portable device.
In addition, two or more in these engines can be realized on identical computing device or different computing devices.
Process and logic flow described in this specification can be by executing the one of one or more computer programs
A or multiple programmable calculators execute, with by carrying out operation to input data and generating output to execute function.Process
It also can be by the special logic of such as FPGA (field programmable gate array) or ASIC (application-specific integrated circuit) electricity with logic flow
Road executes, and device can also be implemented as dedicated logic circuit.
For example, general purpose microprocessor, special microprocessor can be based on by being adapted for carrying out the computer of computer program
The central processing unit of device or the two or any other type.Usually, central processing unit will from read-only memory, with
Machine accesses memory or the two receives instruction and data.The basic element of computer is performed for or carries out the center of instruction
Processing unit and for storing instruction with one or more memory devices of data.Usually, computer will also include use
In one or more mass-memory units of storage data, for example, disk, magneto-optic disk or CD, or operationally with its
Coupling is had both with receiving from it data, transmitting data or both to it.However, computer need not have such equipment.And
And computer can be embedded into another equipment, for example, mobile phone, personal digital assistant (PDA), Mobile audio frequency or regarding
Frequency player, game console, global positioning system (GPS) receiver or portable memory apparatus, for example, universal serial bus
(USB) flash drive names just a few.
Computer-readable medium suitable for storing computer program instructions and data includes that the non-volatile of form of ownership is deposited
Reservoir, medium and memory devices, such as including：Semiconductor memory devices, for example, EPROM, EEPROM and flash memory device；
Disk, for example, built-in hard disk or removable disk；Magneto-optic disk；And CD-ROM disk and DVD-ROM disks.Processor and memory energy
Enough it is aided with dedicated logic circuit or is incorporated in.
In order to provide the interaction with user, the embodiment of the theme described in this specification can be real on computers
It is existing, there is the display equipment for showing information to user, for example, CRT (cathode-ray tube) monitor, LCD (liquid crystal displays
Device) monitor or OLED display, and the input equipment for providing input to computer, for example, keyboard, mouse or
There are sensitive display or other surfaces.Other kinds of equipment can also be used in offer and the interaction of user；For example, carrying
The feedback for supplying user can be any kind of sense feedback, for example, visual feedback, audio feedback or touch feedback；And
And input from the user, including sound, voice or sense of touch can be received in any form.In addition, computer capacity
Equipment enough by being used to user sends resource and interacts with user by receiving resource from it；For example, by response to from
Request that web browser receives and web page is sent to the web browser on the client device of user.
The embodiment of the theme described in this specification can realize that the computing system includes rear end in computing systems
Component, such as data server, which includes middleware component, such as application server or the calculating system
System includes front end assemblies, such as can be used so as to the figure to interact with the embodiment of theme described in this specification with user
Client computer or such aft-end assembly of family interface or web browser, middleware component or front end assemblies it is arbitrary
Combination.The component of system can be by any form or medium of digital data communications, such as communication network, to interconnect.It is logical
The example of communication network includes LAN (" LAN ") and wide area network (" WAN "), such as internet.
Computing system can include client and server.Client is generally remote from each other with server, and usually
It is interacted by communication network.Client has by the operation on corresponding calculate and each other visitor to the relationship of server
The computer program of family end-relationship server is realized.
Although this specification includes many specific implementation details, these are not necessarily to be construed as to any invention or may
It asks the range of the content of protection to limit, and should be understood retouching for the feature that may be directed to the specific embodiment of specific invention
It states.Certain features in this specification described in the context of separate embodiments can also combine real in single embodiment
It is existing.Conversely, the various features described in the context of single embodiment can also be implemented separately in various embodiments or
It is realized with any sub-portfolio appropriate.In addition, although can be described feature as above with certain combinations carry out action or even
Initially so claimed feature, but the one or more features from claimed combination in some cases can be from institute
It states and is excluded in combination, and combination claimed can be related to the modification of sub-portfolio or sub-portfolio.
Similarly, although being operated with certain order to describe in figure, this is understood not to require special shown in
Graded to execute such operation or execute the operation of all diagrams either sequentially to obtain desired result.Certain
In the case of, it may be advantageous for multitask and parallel processing.In addition, various system modules and component in above-described embodiment
Separation is understood not to all require such separation in all embodiments, and should be understood that the program assembly and system
It is generally possible in co-integration to single software product or is encapsulated into multiple software product.
The specific embodiment of the theme is described.Other embodiment falls into scope of the appended claims
It is interior.For example, the action that can be performed in a different order described in claim and remaining to obtain desired result.Citing and
It says, discribed process not necessarily requires the certain order shown in or sequence to obtain desired result in the accompanying drawings.
In certain embodiments, it may be advantageous for multitask and parallel processing.
Claims (28)
1. a kind of processing calculates the computer implemented method of figure, the method includes：
The request that processing calculates figure is received from client；
It obtains and indicates the data for calculating figure, the calculating figure includes multiple nodes and directed edge, wherein each node indicates
Corresponding operation, wherein corresponding first node is connected to corresponding second node by each directed edge, the corresponding second node indicates
Receive the output operation as input of the operation represented by the corresponding first node；
Identify multiple available devices for executing requested operation；
The calculating figure is divided into multiple subgraphs, each subgraph includes one or more of calculating figure node；And
For each subgraph, the operation represented by one or more of subgraph node is assigned to the multiple can be used and is set
Corresponding available devices in standby are for processing.
2. according to the method described in claim 1, wherein, the request is specified one or more from one or more respective nodes
Specific output, the method further includes：
The equipment being assigned to from one or more of respective nodes receives one or more of specific outputs；And
One or more of specific outputs are supplied to the client.
3. method according to claim 1 or 2, wherein represented by the one or more of nodes for calculating figure
Operation be for neural network reasoning or training operation.
4. method according to claim 1,2 or 3, wherein it is described request include the calculating figure is divided into it is multiple pre-
The label of stator figure, and wherein, it includes that the calculating figure is divided into the multiple predetermined subgraph to divide the calculating figure.
5. method according to any preceding claims, wherein each equipment in the multiple available devices is independent
Other equipment in the multiple available devices executes the hardware resource of operation.
6. method according to any preceding claims, wherein it is directed to each subgraph, it will be by one or more in the subgraph
It includes that the operation is assigned to execution by the node in the subgraph that operation represented by a node, which is assigned to relevant device,
The equipment of computing capability needed for represented operation.
7. method according to any preceding claims, further comprises：
The calculating figure is analyzed to identify the node group arranged with chain structure；
Wherein, the division includes that the corresponding subgraph for including identified node group is generated for the group each identified.
8. method according to any preceding claims, further comprises：
The calculating figure is analyzed to identify the node group for carrying out operation to the shared data for flowing to node group on directed edge；
Wherein, the division includes that the corresponding subgraph for including identified node group is generated for the group each identified.
9. method according to any preceding claims, further comprises：
Original allocation of the determining operation represented by one or more of subgraph node to equipment；
Monitor the equipment to determine statistical data；
The original allocation is adjusted using the statistical data；And
Based on adjusted original allocation, the operation of the subgraph is re-assigned to the equipment.
10. according to the method described in claim 9, further comprising：The monitoring is repeated, adjusts and redistributes, Zhi Daoyi
Reach threshold value improvement.
11. according to the method described in claim 9, wherein, the statistical data includes when being directed to the corresponding operation of each subgraph
Between or the respective free time.
12. method according to any preceding claims, further comprises：Receive mode input；And according to by through
Operation represented by the calculating figure of reason handles the mode input.
13. a kind of method, including：It provides and is obtained by the method according to any one of claim 1 to 11
Corresponding machine learning model is schemed in processed calculating；And handle mode input using the machine learning model.
14. a kind of system, including：
One or more computers；And
Computer-readable medium is coupled to one or more of computers and with the instruction being stored thereon, institute
State instruction promotes one or more of computers in neural net layer when being executed by one or more of computers
Each layer execute operation, the operation includes：
The request that distribution calculates figure is received from client；
It obtains and indicates the data for calculating figure, the calculating figure includes multiple nodes and directed edge, wherein each node indicates
Corresponding operation, wherein corresponding first node is connected to corresponding second node by each directed edge, the corresponding second node indicates
Receive the output operation as input of the operation represented by the corresponding first node；
Identify multiple available devices for executing requested operation；
The calculating figure is divided into multiple subgraphs, each subgraph includes one or more of calculating figure node；And
For each subgraph, the operation represented by one or more of subgraph node is assigned to the multiple can be used and is set
Corresponding available devices in standby are for processing.
15. system according to claim 14, the operation further comprises：
The calculating figure is analyzed to identify the node group for carrying out operation to the shared data for flowing to node group on directed edge；
Wherein, the division includes that the corresponding subgraph for including identified node group is generated for the group each identified.
16. the system according to claims 14 or 15, the operation further comprises：
Original allocation of the determining operation represented by one or more of subgraph node to equipment；
Monitor the equipment to determine statistical data；
The original allocation is adjusted using the statistical data；And
Based on adjusted original allocation, the operation of the subgraph is re-assigned to the equipment.
17. system according to claim 16, the operation further comprises：It repeats the monitoring, adjustment and divides again
Match, until having reached threshold value improvement.
18. system according to claim 16, wherein when the statistical data includes the corresponding operation for each subgraph
Between or the respective free time.
19. a kind of computer-readable medium being stored thereon with instruction, described instruction by one or more computers when being executed
One or more of computers are promoted to execute operation, the operation includes：
The request that distribution calculates figure is received from client；
It obtains and indicates the data for calculating figure, the calculating figure includes multiple nodes and directed edge, wherein each node indicates
Corresponding operation, wherein corresponding first node is connected to corresponding second node by each directed edge, the corresponding second node indicates
Receive the output operation as input of the operation represented by the corresponding first node；
Identify multiple available devices for executing requested operation；
The calculating figure is divided into multiple subgraphs, each subgraph includes one or more of calculating figure node；And
For each subgraph, the operation represented by one or more of subgraph node is assigned to the multiple can be used and is set
Corresponding available devices in standby are for processing.
20. computer-readable medium according to claim 21, the operation further comprises：
Original allocation of the determining operation represented by the node in subgraph to equipment；
Monitor the equipment to determine statistical data；
The original allocation is adjusted using the statistical data；And
Based on adjusted original allocation, the operation is re-assigned to the equipment.
21. the computer-readable medium according to claim 19 or 20, the operation further comprises：Repeat the prison
Depending on, adjust and redistribute, until having reached threshold value improvement.
22. the computer-readable medium described in claim 21 when according to claim 20 or reference claim 20, wherein
The statistical data includes the corresponding operation time or respective free time for each subgraph.
23. a kind of method handling mode input according to calculating figure using multiple equipment, the calculating figure includes multiple nodes
And directed edge, wherein each node indicates corresponding operation, wherein corresponding first node is connected to corresponding second by each directed edge
Node, the corresponding second node indicate to receive the output fortune as input of the operation represented by the corresponding first node
It calculates, wherein the method includes for each in the multiple equipment：
The data of the subgraph for the calculating figure for indicating to be assigned to the equipment are received, the subgraph includes from the calculating figure
Indicate the multiple nodes and directed edge of operation；And
Execute the operation represented by the node in the subgraph.
24. according to the method for claim 23, further comprising：
Receive the request that one or more specific outputs are identified from one or more of subgraph respective nodes；And
One or more of specific outputs are supplied to client.
25. the method according to claim 23 or 24, further comprises：
Monitor statistical data；And
The statistical data is supplied to client.
26. according to the method for claim 25, wherein when the statistical data includes the corresponding operation for each subgraph
Between or the respective free time.
27. the method according to any one of claim 23 to 26, wherein execute by the node institute table in the subgraph
The operation shown includes executing the operation in an asynchronous manner.
28. according to the method for claim 27, wherein it includes using queue, non-resistance to execute the operation in an asynchronous manner
Plug kernel or both execute the operation.
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
CN202210503891.7A CN115061810A (en) | 2015-10-28 | 2016-10-28 | Processing a computation graph |
Applications Claiming Priority (5)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201562247709P | 2015-10-28 | 2015-10-28 | |
US62/247,709 | 2015-10-28 | ||
US201562253009P | 2015-11-09 | 2015-11-09 | |
US62/253,009 | 2015-11-09 | ||
PCT/US2016/059449 WO2017075438A1 (en) | 2015-10-28 | 2016-10-28 | Processing computational graphs |
Related Child Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202210503891.7A Division CN115061810A (en) | 2015-10-28 | 2016-10-28 | Processing a computation graph |
Publications (2)
Publication Number | Publication Date |
---|---|
CN108292241A true CN108292241A (en) | 2018-07-17 |
CN108292241B CN108292241B (en) | 2022-05-24 |
Family
ID=57822016
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201680063236.7A Active CN108292241B (en) | 2015-10-28 | 2016-10-28 | Processing a computation graph |
CN202210503891.7A Pending CN115061810A (en) | 2015-10-28 | 2016-10-28 | Processing a computation graph |
Family Applications After (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202210503891.7A Pending CN115061810A (en) | 2015-10-28 | 2016-10-28 | Processing a computation graph |
Country Status (6)
Country | Link |
---|---|
US (3) | US10860925B2 (en) |
EP (2) | EP3705994B1 (en) |
JP (2) | JP6983154B2 (en) |
KR (4) | KR102433254B1 (en) |
CN (2) | CN108292241B (en) |
WO (1) | WO2017075438A1 (en) |
Cited By (27)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN108491259A (en) * | 2018-03-30 | 2018-09-04 | 北京航天宏图信息技术股份有限公司 | Remote sensing algorithm flow Method of Scheduling Parallel and device |
CN109508412A (en) * | 2018-11-20 | 2019-03-22 | 中科驭数（北京）科技有限公司 | A kind of the calculating flow graph construction method and device of time Series Processing |
CN109669772A (en) * | 2018-12-28 | 2019-04-23 | 第四范式（北京）技术有限公司 | Calculate the parallel execution method and apparatus of figure |
CN109902819A (en) * | 2019-02-12 | 2019-06-18 | Oppo广东移动通信有限公司 | Neural computing method, apparatus, mobile terminal and storage medium |
CN109919315A (en) * | 2019-03-13 | 2019-06-21 | 科大讯飞股份有限公司 | A kind of forward inference method, apparatus, equipment and the storage medium of neural network |
CN110188871A (en) * | 2019-05-31 | 2019-08-30 | 北京中科寒武纪科技有限公司 | Operation method, device and Related product |
CN110210614A (en) * | 2019-05-31 | 2019-09-06 | 北京中科寒武纪科技有限公司 | Operation method, device and Related product |
CN110689116A (en) * | 2019-09-24 | 2020-01-14 | 上海寒武纪信息科技有限公司 | Neural network pruning method and device, computer equipment and storage medium |
CN110689121A (en) * | 2019-09-24 | 2020-01-14 | 上海寒武纪信息科技有限公司 | Method for realizing neural network model splitting by using multi-core processor and related product |
CN110764744A (en) * | 2018-07-25 | 2020-02-07 | 赛灵思公司 | Intermediate representation generation method and device for neural network computation |
CN110765821A (en) * | 2018-07-27 | 2020-02-07 | 杭州海康威视数字技术股份有限公司 | Image recognition method and device |
CN110879744A (en) * | 2018-09-06 | 2020-03-13 | 第四范式（北京）技术有限公司 | Method and system for executing computation graph by multiple threads |
CN111563584A (en) * | 2019-02-14 | 2020-08-21 | 上海寒武纪信息科技有限公司 | Splitting method of neural network model and related product |
CN111667046A (en) * | 2019-03-08 | 2020-09-15 | 富泰华工业（深圳）有限公司 | Deep learning acceleration method and user terminal |
CN111694571A (en) * | 2019-03-15 | 2020-09-22 | 上海寒武纪信息科技有限公司 | Compiling method and device |
CN111708641A (en) * | 2020-07-14 | 2020-09-25 | 腾讯科技（深圳）有限公司 | Memory management method, device and equipment and computer readable storage medium |
CN111723935A (en) * | 2020-06-24 | 2020-09-29 | 湖北亿咖通科技有限公司 | Neural network computation graph processing method, computer storage medium and electronic device |
CN111832714A (en) * | 2019-04-19 | 2020-10-27 | 上海寒武纪信息科技有限公司 | Operation method and device |
WO2021012609A1 (en) * | 2019-07-24 | 2021-01-28 | 华为技术有限公司 | Neural network segmentation method, prediction method, and related apparatus |
WO2021052391A1 (en) * | 2019-09-18 | 2021-03-25 | 华为技术有限公司 | Method for constructing intermediate representation, compiler and server |
WO2021136512A1 (en) * | 2020-01-03 | 2021-07-08 | 深圳鲲云信息科技有限公司 | Method and device for scheduling on basis of deep learning node computation, and storage medium |
CN113767364A (en) * | 2019-05-03 | 2021-12-07 | 谷歌有限责任公司 | Reshaping and broadcast optimization to avoid unnecessary data movement |
WO2022022670A1 (en) * | 2020-07-31 | 2022-02-03 | 北京灵汐科技有限公司 | Neural network computation graph processing method and apparatus, and processing device |
CN114513770A (en) * | 2020-10-29 | 2022-05-17 | 伊姆西Ip控股有限责任公司 | Method, system and computer program product for deploying applications |
CN114840322A (en) * | 2022-05-17 | 2022-08-02 | 北京百度网讯科技有限公司 | Task scheduling method and device, electronic equipment and storage |
WO2023206889A1 (en) * | 2022-04-26 | 2023-11-02 | 北京百度网讯科技有限公司 | Model inference methods and apparatuses, devices, and storage medium |
WO2024041229A1 (en) * | 2022-08-26 | 2024-02-29 | 华为技术有限公司 | Method and apparatus for processing complex graph algorithm, and computing device |
Families Citing this family (66)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
KR102433254B1 (en) | 2015-10-28 | 2022-08-18 | 구글 엘엘씨 | Processing computational graphs |
US10506016B2 (en) | 2016-05-19 | 2019-12-10 | Oracle International Corporation | Graph analytic engine that implements efficient transparent remote access over representational state transfer |
US10275287B2 (en) | 2016-06-07 | 2019-04-30 | Oracle International Corporation | Concurrent distributed graph processing system with self-balance |
US11907760B2 (en) * | 2016-09-23 | 2024-02-20 | Apple Inc. | Systems and methods of memory allocation for neural networks |
US10656970B2 (en) * | 2016-09-28 | 2020-05-19 | Futurewei Technologies, Inc. | Scheduling graph computing on heterogeneous processing resources based on energy efficiency |
US11615285B2 (en) * | 2017-01-06 | 2023-03-28 | Ecole Polytechnique Federale De Lausanne (Epfl) | Generating and identifying functional subnetworks within structural networks |
US10318355B2 (en) * | 2017-01-24 | 2019-06-11 | Oracle International Corporation | Distributed graph processing system featuring interactive remote control mechanism including task cancellation |
US10534657B2 (en) | 2017-05-30 | 2020-01-14 | Oracle International Corporation | Distributed graph processing system that adopts a faster data loading technique that requires low degree of communication |
US11138516B2 (en) | 2017-06-30 | 2021-10-05 | Visa International Service Association | GPU enhanced graph model build and scoring engine |
EP3580698B1 (en) | 2017-07-21 | 2024-02-14 | Google LLC | Hierarchical device placement with reinforcement learning |
US10599482B2 (en) * | 2017-08-24 | 2020-03-24 | Google Llc | Method for intra-subgraph optimization in tuple graph programs |
US10642582B2 (en) | 2017-08-24 | 2020-05-05 | Google Llc | System of type inference for tuple graph programs method of executing a tuple graph program across a network |
US10887235B2 (en) | 2017-08-24 | 2021-01-05 | Google Llc | Method of executing a tuple graph program across a network |
EP3682379A1 (en) * | 2017-09-15 | 2020-07-22 | Google LLC | Augmenting neural networks |
US11620490B2 (en) * | 2017-10-17 | 2023-04-04 | Xilinx, Inc. | Multi-layer neural network processing by a neural network accelerator using host communicated merged weights and a package of per-layer instructions |
GB2569270B (en) * | 2017-10-20 | 2020-02-19 | Graphcore Ltd | Parallel computing |
EP3502975A1 (en) * | 2017-12-20 | 2019-06-26 | Fujitsu Limited | Methods and apparatus for model parallelism in artificial neural networks |
US11119808B2 (en) * | 2018-01-10 | 2021-09-14 | Mistnet.io, Inc. | Geo-distributed computation and analytics based on cost of transporting and computational cost |
US11551144B2 (en) | 2018-01-30 | 2023-01-10 | Deepmind Technologies Limited | Dynamic placement of computation sub-graphs |
US11514054B1 (en) * | 2018-06-04 | 2022-11-29 | Amazon Technologies, Inc. | Supervised graph partitioning for record matching |
WO2019235551A1 (en) * | 2018-06-05 | 2019-12-12 | Okinawa Institute Of Science And Technology School Corporation | Total stochastic gradient estimation method, device and computer program |
US11663478B2 (en) | 2018-06-11 | 2023-05-30 | Inait Sa | Characterizing activity in a recurrent artificial neural network |
US11972343B2 (en) | 2018-06-11 | 2024-04-30 | Inait Sa | Encoding and decoding information |
US11893471B2 (en) | 2018-06-11 | 2024-02-06 | Inait Sa | Encoding and decoding information and artificial neural networks |
US20190392287A1 (en) * | 2018-06-22 | 2019-12-26 | Samsung Electronics Co., Ltd. | Neural processor |
EP3629246B1 (en) * | 2018-09-27 | 2022-05-18 | Swisscom AG | Systems and methods for neural architecture search |
KR20200053318A (en) * | 2018-11-08 | 2020-05-18 | 삼성전자주식회사 | System managing calculation processing graph of artificial neural network and method managing calculation processing graph using thereof |
US20200184366A1 (en) * | 2018-12-06 | 2020-06-11 | Fujitsu Limited | Scheduling task graph operations |
US11714992B1 (en) * | 2018-12-13 | 2023-08-01 | Amazon Technologies, Inc. | Neural network processing based on subgraph recognition |
US20200293838A1 (en) * | 2019-03-13 | 2020-09-17 | Deepmind Technologies Limited | Scheduling computation graphs using neural networks |
US11569978B2 (en) | 2019-03-18 | 2023-01-31 | Inait Sa | Encrypting and decrypting information |
US11652603B2 (en) | 2019-03-18 | 2023-05-16 | Inait Sa | Homomorphic encryption |
US11423254B2 (en) * | 2019-03-28 | 2022-08-23 | Intel Corporation | Technologies for distributing iterative computations in heterogeneous computing environments |
US11671111B2 (en) | 2019-04-17 | 2023-06-06 | Samsung Electronics Co., Ltd. | Hardware channel-parallel data compression/decompression |
US11880760B2 (en) | 2019-05-01 | 2024-01-23 | Samsung Electronics Co., Ltd. | Mixed-precision NPU tile with depth-wise convolution |
US11790250B2 (en) | 2019-05-09 | 2023-10-17 | Intel Corporation | Using computational cost and instantaneous load analysis for intelligent deployment of neural networks on multiple hardware executors |
US11080200B2 (en) | 2019-05-31 | 2021-08-03 | Apple Inc. | Allocation of machine learning tasks into a shared cache |
US11687789B2 (en) | 2019-05-31 | 2023-06-27 | Apple Inc. | Decomposition of machine learning operations |
US11836635B2 (en) | 2019-05-31 | 2023-12-05 | Apple Inc. | Mutable parameters for machine learning models during runtime |
KR102325047B1 (en) | 2019-06-10 | 2021-11-11 | 포항공과대학교 산학협력단 | Grahp data processing methdo and apparatus thereof |
US11494237B2 (en) | 2019-06-26 | 2022-11-08 | Microsoft Technology Licensing, Llc | Managing workloads of a deep neural network processor |
CN114008594A (en) | 2019-07-17 | 2022-02-01 | 谷歌有限责任公司 | Scheduling operations on a computational graph |
KR102068277B1 (en) * | 2019-10-04 | 2020-02-11 | 주식회사 루닛 | Method and System for analysing image |
KR102601738B1 (en) * | 2019-10-04 | 2023-11-13 | 주식회사 루닛 | Method and System for analysing image |
KR102068279B1 (en) * | 2019-10-04 | 2020-01-20 | 주식회사 루닛 | Method and System for analysing image |
US11580401B2 (en) | 2019-12-11 | 2023-02-14 | Inait Sa | Distance metrics and clustering in recurrent neural networks |
US11816553B2 (en) | 2019-12-11 | 2023-11-14 | Inait Sa | Output from a recurrent neural network |
US11651210B2 (en) | 2019-12-11 | 2023-05-16 | Inait Sa | Interpreting and improving the processing results of recurrent neural networks |
US11797827B2 (en) | 2019-12-11 | 2023-10-24 | Inait Sa | Input into a neural network |
US20230027647A1 (en) * | 2019-12-20 | 2023-01-26 | Telefonaktiebolaget Lm Ericsson (Publ) | Dynamic distribution of a computational graph |
US11709059B2 (en) * | 2019-12-23 | 2023-07-25 | Waymo Llc | Asynchronous execution graphs for autonomous vehicles |
US11620502B2 (en) * | 2020-01-30 | 2023-04-04 | Alibaba Group Holding Limited | Hyper-square implementation of tree AllReduce algorithm for distributed parallel deep learning |
US20210248115A1 (en) * | 2020-02-10 | 2021-08-12 | Nvidia Corporation | Compute graph optimization |
CN111309479B (en) * | 2020-02-14 | 2023-06-06 | 北京百度网讯科技有限公司 | Method, device, equipment and medium for realizing task parallel processing |
CN111338635B (en) * | 2020-02-20 | 2023-09-12 | 腾讯科技（深圳）有限公司 | Graph compiling method, device, equipment and storage medium for calculation graph |
JP6834097B1 (en) | 2020-05-15 | 2021-02-24 | エッジコーティックス ピーティーイー． リミテッド | Hardware-specific partitioning of inference neural network accelerators |
US11461130B2 (en) | 2020-05-26 | 2022-10-04 | Oracle International Corporation | Methodology for fast and seamless task cancelation and error handling in distributed processing of large graph data |
CN114169491A (en) * | 2020-09-10 | 2022-03-11 | 阿里巴巴集团控股有限公司 | Model processing method, device, equipment and computer readable storage medium |
CN117501325A (en) * | 2021-06-10 | 2024-02-02 | 维萨国际服务协会 | System and method for hierarchical periodic detection of dynamic graphs |
KR102457152B1 (en) * | 2021-06-16 | 2022-10-20 | 주식회사 모레 | Method and system for determining optimization applicability on intermediate representation from program |
KR102457153B1 (en) * | 2021-06-16 | 2022-10-20 | 주식회사 모레 | Method and system for managing intermediate representation from program |
US11782706B1 (en) | 2021-06-29 | 2023-10-10 | Amazon Technologies, Inc. | Reconfigurable neural network processing based on subgraph recognition |
KR20230049468A (en) * | 2021-10-06 | 2023-04-13 | 삼성전자주식회사 | An artificial neural network module for performing an artificial neural network operation on a plurality of subgraphs and an operating method thereof |
JP7179237B1 (en) * | 2022-03-10 | 2022-11-28 | 三菱電機株式会社 | neural network device |
WO2024053910A1 (en) * | 2022-09-08 | 2024-03-14 | 삼성전자주식회사 | Apparatus and method for selecting accelerator suitable for machine learning model |
CN116795519B (en) * | 2023-08-25 | 2023-12-05 | 江苏盖睿健康科技有限公司 | Internet-based remote intelligent debugging method and system |
Citations (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20060095722A1 (en) * | 2004-10-20 | 2006-05-04 | Arm Limited | Program subgraph identification |
US20150007182A1 (en) * | 2013-06-27 | 2015-01-01 | Microsoft Corporation | Iteration support in a heterogeneous dataflow engine |
CN104683488A (en) * | 2015-03-31 | 2015-06-03 | 百度在线网络技术（北京）有限公司 | Flow-type calculation system as well as dispatching method and dispatching device of flow-type calculation system |
CN104820945A (en) * | 2015-04-17 | 2015-08-05 | 南京大学 | Online social network information transmision maximization method based on community structure mining algorithm |
Family Cites Families (28)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JPH04211858A (en) * | 1990-04-02 | 1992-08-03 | Mitsubishi Electric Corp | Device and method for dividing data flow graph |
JPH05108595A (en) * | 1991-10-17 | 1993-04-30 | Hitachi Ltd | Distributed learning device for neural network |
US5768594A (en) * | 1995-07-14 | 1998-06-16 | Lucent Technologies Inc. | Methods and means for scheduling parallel processors |
US6175957B1 (en) * | 1997-12-09 | 2001-01-16 | International Business Machines Corporation | Method of, system for, and computer program product for providing efficient utilization of memory hierarchy through code restructuring |
JP2001117900A (en) | 1999-10-19 | 2001-04-27 | Fuji Xerox Co Ltd | Neural network arithmetic device |
JP4073303B2 (en) * | 2002-12-03 | 2008-04-09 | 富士通株式会社 | Program division method and program for implementing the method |
US7961636B1 (en) * | 2004-05-27 | 2011-06-14 | Cisco Technology, Inc. | Vectorized software packet forwarding |
US7350055B2 (en) | 2004-10-20 | 2008-03-25 | Arm Limited | Tightly coupled accelerator |
US8490072B2 (en) | 2009-06-23 | 2013-07-16 | International Business Machines Corporation | Partitioning operator flow graphs |
US9262228B2 (en) * | 2010-09-23 | 2016-02-16 | Microsoft Technology Licensing, Llc | Distributed workflow in loosely coupled computing |
JP2014059862A (en) * | 2012-08-22 | 2014-04-03 | Canon Inc | Data flow resource allocation device and method |
JP6026236B2 (en) | 2012-11-16 | 2016-11-16 | 富士フイルム株式会社 | Metal complex dye, photoelectric conversion element, dye-sensitized solar cell, dye solution, dye-adsorbing electrode, and method for producing dye-sensitized solar cell |
JP2014102996A (en) | 2012-11-20 | 2014-06-05 | Hitachi Cable Ltd | Method of joining soft dilute copper alloy wire to connection terminal |
WO2014102917A1 (en) * | 2012-12-26 | 2014-07-03 | 株式会社日立製作所 | Parallel processing method and parallel computer system |
JP6036848B2 (en) * | 2012-12-28 | 2016-11-30 | 株式会社日立製作所 | Information processing system |
CN103970604B (en) * | 2013-01-31 | 2017-05-03 | 国际商业机器公司 | Method and device for realizing image processing based on MapReduce framework |
JP5987720B2 (en) * | 2013-02-13 | 2016-09-07 | 富士通株式会社 | Binary decision graph processing system and method |
KR20150007182A (en) * | 2013-07-10 | 2015-01-20 | 주식회사 포인트 | Device for measuring weight of freight car |
US9489639B2 (en) * | 2013-11-13 | 2016-11-08 | Microsoft Technology Licensing, Llc | Memory facilitation using directed acyclic graphs |
US9645575B2 (en) | 2013-11-27 | 2017-05-09 | Adept Ai Systems Inc. | Method and apparatus for artificially intelligent model-based control of dynamic processes using probabilistic agents |
US20150324690A1 (en) * | 2014-05-08 | 2015-11-12 | Microsoft Corporation | Deep Learning Training System |
CN104035751B (en) * | 2014-06-20 | 2016-10-12 | 深圳市腾讯计算机系统有限公司 | Data parallel processing method based on multi-graphics processor and device |
US10686869B2 (en) * | 2014-09-29 | 2020-06-16 | Microsoft Technology Licensing, Llc | Tool for investigating the performance of a distributed processing system |
US9984337B2 (en) * | 2014-10-08 | 2018-05-29 | Nec Corporation | Parallelized machine learning with distributed lockless training |
US9543980B2 (en) * | 2014-10-10 | 2017-01-10 | Massachusettes Institute Of Technology | Systems and methods for model-free compression and model-based decompression |
US10679145B2 (en) * | 2015-08-07 | 2020-06-09 | Nec Corporation | System and method for balancing computation with communication in parallel learning |
US20170091668A1 (en) * | 2015-09-30 | 2017-03-30 | Nec Laboratories America, Inc. | System and method for network bandwidth aware distributed learning |
KR102433254B1 (en) | 2015-10-28 | 2022-08-18 | 구글 엘엘씨 | Processing computational graphs |
-
2016
- 2016-10-28 KR KR1020207003263A patent/KR102433254B1/en active IP Right Grant
- 2016-10-28 KR KR1020227027727A patent/KR102628902B1/en active IP Right Grant
- 2016-10-28 CN CN201680063236.7A patent/CN108292241B/en active Active
- 2016-10-28 JP JP2018521825A patent/JP6983154B2/en active Active
- 2016-10-28 EP EP20164537.1A patent/EP3705994B1/en active Active
- 2016-10-28 US US15/337,744 patent/US10860925B2/en active Active
- 2016-10-28 WO PCT/US2016/059449 patent/WO2017075438A1/en active Application Filing
- 2016-10-28 KR KR1020247002275A patent/KR20240014612A/en active Application Filing
- 2016-10-28 EP EP16826785.4A patent/EP3353656B1/en active Active
- 2016-10-28 CN CN202210503891.7A patent/CN115061810A/en active Pending
- 2016-10-28 KR KR1020187014915A patent/KR102076257B1/en active IP Right Grant
-
2018
- 2018-04-27 US US15/965,742 patent/US10534997B2/en active Active
-
2020
- 2020-05-14 JP JP2020085262A patent/JP6898496B2/en active Active
- 2020-06-11 US US16/898,971 patent/US11769061B2/en active Active
Patent Citations (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20060095722A1 (en) * | 2004-10-20 | 2006-05-04 | Arm Limited | Program subgraph identification |
US20150007182A1 (en) * | 2013-06-27 | 2015-01-01 | Microsoft Corporation | Iteration support in a heterogeneous dataflow engine |
CN104683488A (en) * | 2015-03-31 | 2015-06-03 | 百度在线网络技术（北京）有限公司 | Flow-type calculation system as well as dispatching method and dispatching device of flow-type calculation system |
CN104820945A (en) * | 2015-04-17 | 2015-08-05 | 南京大学 | Online social network information transmision maximization method based on community structure mining algorithm |
Cited By (42)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN108491259A (en) * | 2018-03-30 | 2018-09-04 | 北京航天宏图信息技术股份有限公司 | Remote sensing algorithm flow Method of Scheduling Parallel and device |
CN110764744B (en) * | 2018-07-25 | 2023-12-08 | 赛灵思公司 | Intermediate representation generation method and device for neural network calculation |
CN110764744A (en) * | 2018-07-25 | 2020-02-07 | 赛灵思公司 | Intermediate representation generation method and device for neural network computation |
CN110765821A (en) * | 2018-07-27 | 2020-02-07 | 杭州海康威视数字技术股份有限公司 | Image recognition method and device |
CN110765821B (en) * | 2018-07-27 | 2022-08-16 | 杭州海康威视数字技术股份有限公司 | Image recognition method and device |
CN110879744A (en) * | 2018-09-06 | 2020-03-13 | 第四范式（北京）技术有限公司 | Method and system for executing computation graph by multiple threads |
CN109508412B (en) * | 2018-11-20 | 2019-12-20 | 中科驭数（北京）科技有限公司 | Method and device for constructing computation flow graph processed by time series |
CN109508412A (en) * | 2018-11-20 | 2019-03-22 | 中科驭数（北京）科技有限公司 | A kind of the calculating flow graph construction method and device of time Series Processing |
CN109669772A (en) * | 2018-12-28 | 2019-04-23 | 第四范式（北京）技术有限公司 | Calculate the parallel execution method and apparatus of figure |
CN111522640A (en) * | 2018-12-28 | 2020-08-11 | 第四范式（北京）技术有限公司 | Parallel execution method and equipment of computational graph |
CN109902819A (en) * | 2019-02-12 | 2019-06-18 | Oppo广东移动通信有限公司 | Neural computing method, apparatus, mobile terminal and storage medium |
WO2020164469A1 (en) * | 2019-02-12 | 2020-08-20 | Oppo广东移动通信有限公司 | Neural network calculation method and apparatus, mobile terminal and storage medium |
CN111563584A (en) * | 2019-02-14 | 2020-08-21 | 上海寒武纪信息科技有限公司 | Splitting method of neural network model and related product |
CN111667046A (en) * | 2019-03-08 | 2020-09-15 | 富泰华工业（深圳）有限公司 | Deep learning acceleration method and user terminal |
CN109919315A (en) * | 2019-03-13 | 2019-06-21 | 科大讯飞股份有限公司 | A kind of forward inference method, apparatus, equipment and the storage medium of neural network |
CN109919315B (en) * | 2019-03-13 | 2021-10-01 | 科大讯飞股份有限公司 | Forward reasoning method, device, equipment and storage medium of neural network |
CN111694571B (en) * | 2019-03-15 | 2022-11-01 | 上海寒武纪信息科技有限公司 | Compiling method and device |
CN111694571A (en) * | 2019-03-15 | 2020-09-22 | 上海寒武纪信息科技有限公司 | Compiling method and device |
CN111832714A (en) * | 2019-04-19 | 2020-10-27 | 上海寒武纪信息科技有限公司 | Operation method and device |
CN111832714B (en) * | 2019-04-19 | 2023-11-17 | 上海寒武纪信息科技有限公司 | Operation method and device |
CN113767364A (en) * | 2019-05-03 | 2021-12-07 | 谷歌有限责任公司 | Reshaping and broadcast optimization to avoid unnecessary data movement |
CN110210614A (en) * | 2019-05-31 | 2019-09-06 | 北京中科寒武纪科技有限公司 | Operation method, device and Related product |
CN110188871A (en) * | 2019-05-31 | 2019-08-30 | 北京中科寒武纪科技有限公司 | Operation method, device and Related product |
CN110188871B (en) * | 2019-05-31 | 2021-01-26 | 安徽寒武纪信息科技有限公司 | Operation method, device and related product |
WO2021012609A1 (en) * | 2019-07-24 | 2021-01-28 | 华为技术有限公司 | Neural network segmentation method, prediction method, and related apparatus |
CN112543918A (en) * | 2019-07-24 | 2021-03-23 | 华为技术有限公司 | Neural network segmentation method, prediction method and related device |
WO2021052391A1 (en) * | 2019-09-18 | 2021-03-25 | 华为技术有限公司 | Method for constructing intermediate representation, compiler and server |
US11789709B2 (en) | 2019-09-18 | 2023-10-17 | Huawei Technologies Co., Ltd. | Intermediate representation construction method, compiler, and server |
CN110689116B (en) * | 2019-09-24 | 2022-12-27 | 安徽寒武纪信息科技有限公司 | Neural network pruning method and device, computer equipment and storage medium |
CN110689116A (en) * | 2019-09-24 | 2020-01-14 | 上海寒武纪信息科技有限公司 | Neural network pruning method and device, computer equipment and storage medium |
CN110689121A (en) * | 2019-09-24 | 2020-01-14 | 上海寒武纪信息科技有限公司 | Method for realizing neural network model splitting by using multi-core processor and related product |
WO2021136512A1 (en) * | 2020-01-03 | 2021-07-08 | 深圳鲲云信息科技有限公司 | Method and device for scheduling on basis of deep learning node computation, and storage medium |
CN111723935A (en) * | 2020-06-24 | 2020-09-29 | 湖北亿咖通科技有限公司 | Neural network computation graph processing method, computer storage medium and electronic device |
CN111708641A (en) * | 2020-07-14 | 2020-09-25 | 腾讯科技（深圳）有限公司 | Memory management method, device and equipment and computer readable storage medium |
CN111708641B (en) * | 2020-07-14 | 2024-03-19 | 腾讯科技（深圳）有限公司 | Memory management method, device, equipment and computer readable storage medium |
WO2022022670A1 (en) * | 2020-07-31 | 2022-02-03 | 北京灵汐科技有限公司 | Neural network computation graph processing method and apparatus, and processing device |
CN114513770A (en) * | 2020-10-29 | 2022-05-17 | 伊姆西Ip控股有限责任公司 | Method, system and computer program product for deploying applications |
CN114513770B (en) * | 2020-10-29 | 2024-01-30 | 伊姆西Ip控股有限责任公司 | Method, system and medium for deploying application |
WO2023206889A1 (en) * | 2022-04-26 | 2023-11-02 | 北京百度网讯科技有限公司 | Model inference methods and apparatuses, devices, and storage medium |
CN114840322B (en) * | 2022-05-17 | 2022-12-09 | 北京百度网讯科技有限公司 | Task scheduling method and device, electronic equipment and storage |
CN114840322A (en) * | 2022-05-17 | 2022-08-02 | 北京百度网讯科技有限公司 | Task scheduling method and device, electronic equipment and storage |
WO2024041229A1 (en) * | 2022-08-26 | 2024-02-29 | 华为技术有限公司 | Method and apparatus for processing complex graph algorithm, and computing device |
Also Published As
Publication number | Publication date |
---|---|
CN115061810A (en) | 2022-09-16 |
EP3353656B1 (en) | 2020-05-06 |
EP3705994A1 (en) | 2020-09-09 |
KR102433254B1 (en) | 2022-08-18 |
US20200302302A1 (en) | 2020-09-24 |
KR20240014612A (en) | 2024-02-01 |
US11769061B2 (en) | 2023-09-26 |
JP2018538607A (en) | 2018-12-27 |
US10534997B2 (en) | 2020-01-14 |
JP2020129404A (en) | 2020-08-27 |
EP3353656A1 (en) | 2018-08-01 |
US20170124452A1 (en) | 2017-05-04 |
KR20200015829A (en) | 2020-02-12 |
JP6898496B2 (en) | 2021-07-07 |
US10860925B2 (en) | 2020-12-08 |
EP3705994B1 (en) | 2023-10-04 |
KR20220116573A (en) | 2022-08-23 |
CN108292241B (en) | 2022-05-24 |
KR102076257B1 (en) | 2020-02-11 |
JP6983154B2 (en) | 2021-12-17 |
WO2017075438A1 (en) | 2017-05-04 |
US20180247197A1 (en) | 2018-08-30 |
KR20180077218A (en) | 2018-07-06 |
KR102628902B1 (en) | 2024-01-24 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN108292241A (en) | Processing calculates figure | |
JP7094262B2 (en) | Correction of calculation graph | |
US10373053B2 (en) | Stream-based accelerator processing of computational graphs | |
US20210295161A1 (en) | Training neural networks represented as computational graphs | |
CN108885571A (en) | The input of batch machines learning model | |
US11763146B1 (en) | Processing loops in computational graphs | |
US20240160948A1 (en) | Processing computational graphs |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
GR01 | Patent grant | ||
GR01 | Patent grant |