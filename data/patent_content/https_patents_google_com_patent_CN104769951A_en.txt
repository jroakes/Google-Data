CN104769951A - Scalable robust live streaming system - Google Patents
Scalable robust live streaming system Download PDFInfo
- Publication number
- CN104769951A CN104769951A CN201380028673.1A CN201380028673A CN104769951A CN 104769951 A CN104769951 A CN 104769951A CN 201380028673 A CN201380028673 A CN 201380028673A CN 104769951 A CN104769951 A CN 104769951A
- Authority
- CN
- China
- Prior art keywords
- segmentation
- inlet flow
- stream
- pipeline
- memory
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
- 230000011218 segmentation Effects 0.000 claims abstract description 154
- 238000000034 method Methods 0.000 claims abstract description 60
- 230000008569 process Effects 0.000 claims abstract description 24
- 238000000926 separation method Methods 0.000 claims description 27
- 238000003860 storage Methods 0.000 claims description 27
- 230000000712 assembly Effects 0.000 claims description 24
- 238000000429 assembly Methods 0.000 claims description 24
- 230000009471 action Effects 0.000 claims description 8
- 238000004422 calculation algorithm Methods 0.000 claims description 8
- 230000003139 buffering effect Effects 0.000 claims description 6
- 230000004044 response Effects 0.000 claims description 5
- 230000000977 initiatory effect Effects 0.000 claims 1
- 238000009826 distribution Methods 0.000 abstract description 2
- 230000037406 food intake Effects 0.000 abstract 1
- 238000010586 diagram Methods 0.000 description 29
- 238000012545 processing Methods 0.000 description 14
- 230000006870 function Effects 0.000 description 9
- 238000004891 communication Methods 0.000 description 8
- 238000005516 engineering process Methods 0.000 description 7
- 238000013467 fragmentation Methods 0.000 description 6
- 238000006062 fragmentation reaction Methods 0.000 description 6
- 239000011469 building brick Substances 0.000 description 4
- 238000004364 calculation method Methods 0.000 description 4
- 230000006378 damage Effects 0.000 description 4
- 238000004519 manufacturing process Methods 0.000 description 4
- 230000005055 memory storage Effects 0.000 description 4
- 239000008186 active pharmaceutical agent Substances 0.000 description 3
- 238000004590 computer program Methods 0.000 description 3
- 238000013459 approach Methods 0.000 description 2
- 230000001427 coherent effect Effects 0.000 description 2
- 238000013461 design Methods 0.000 description 2
- 239000012634 fragment Substances 0.000 description 2
- 239000000463 material Substances 0.000 description 2
- RYGMFSIKBFXOCR-UHFFFAOYSA-N Copper Chemical compound [Cu] RYGMFSIKBFXOCR-UHFFFAOYSA-N 0.000 description 1
- 230000006399 behavior Effects 0.000 description 1
- 230000008901 benefit Effects 0.000 description 1
- 230000005540 biological transmission Effects 0.000 description 1
- 230000001413 cellular effect Effects 0.000 description 1
- 238000006243 chemical reaction Methods 0.000 description 1
- 230000002860 competitive effect Effects 0.000 description 1
- 238000010276 construction Methods 0.000 description 1
- 229910052802 copper Inorganic materials 0.000 description 1
- 239000010949 copper Substances 0.000 description 1
- 238000013500 data storage Methods 0.000 description 1
- 230000009977 dual effect Effects 0.000 description 1
- 230000000694 effects Effects 0.000 description 1
- 230000005611 electricity Effects 0.000 description 1
- 230000002349 favourable effect Effects 0.000 description 1
- 239000000835 fiber Substances 0.000 description 1
- 239000003999 initiator Substances 0.000 description 1
- 230000007774 longterm Effects 0.000 description 1
- 238000012423 maintenance Methods 0.000 description 1
- 230000014759 maintenance of location Effects 0.000 description 1
- 238000007726 management method Methods 0.000 description 1
- 238000010295 mobile communication Methods 0.000 description 1
- 230000002093 peripheral effect Effects 0.000 description 1
- 239000002096 quantum dot Substances 0.000 description 1
- 230000003068 static effect Effects 0.000 description 1
- 238000005728 strengthening Methods 0.000 description 1
- 230000001360 synchronised effect Effects 0.000 description 1
- 230000002123 temporal effect Effects 0.000 description 1
- 238000012546 transfer Methods 0.000 description 1
- 230000007704 transition Effects 0.000 description 1
- 238000013519 translation Methods 0.000 description 1
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L65/00—Network arrangements, protocols or services for supporting real-time applications in data packet communication
- H04L65/60—Network streaming of media packets
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/20—Servers specifically adapted for the distribution of content, e.g. VOD servers; Operations thereof
- H04N21/23—Processing of content or additional data; Elementary server operations; Server middleware
- H04N21/231—Content storage operation, e.g. caching movies for short term storage, replicating data over plural servers, prioritizing data for deletion
- H04N21/23116—Content storage operation, e.g. caching movies for short term storage, replicating data over plural servers, prioritizing data for deletion involving data replication, e.g. over plural servers
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L43/00—Arrangements for monitoring or testing data switching networks
- H04L43/16—Threshold monitoring
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L47/00—Traffic control in data switching networks
- H04L47/10—Flow control; Congestion control
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L65/00—Network arrangements, protocols or services for supporting real-time applications in data packet communication
- H04L65/60—Network streaming of media packets
- H04L65/61—Network streaming of media packets for supporting one-way streaming services, e.g. Internet radio
- H04L65/612—Network streaming of media packets for supporting one-way streaming services, e.g. Internet radio for unicast
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L65/00—Network arrangements, protocols or services for supporting real-time applications in data packet communication
- H04L65/60—Network streaming of media packets
- H04L65/75—Media network packet handling
- H04L65/765—Media network packet handling intermediate
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/20—Servers specifically adapted for the distribution of content, e.g. VOD servers; Operations thereof
- H04N21/23—Processing of content or additional data; Elementary server operations; Server middleware
- H04N21/234—Processing of video elementary streams, e.g. splicing of video streams, manipulating MPEG-4 scene graphs
- H04N21/2343—Processing of video elementary streams, e.g. splicing of video streams, manipulating MPEG-4 scene graphs involving reformatting operations of video signals for distribution or compliance with end-user requests or end-user device requirements
- H04N21/23439—Processing of video elementary streams, e.g. splicing of video streams, manipulating MPEG-4 scene graphs involving reformatting operations of video signals for distribution or compliance with end-user requests or end-user device requirements for generating different versions
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/60—Network structure or processes for video distribution between server and client or between remote clients; Control signalling between clients, server and network components; Transmission of management data between server and client, e.g. sending from server to client commands for recording incoming content stream; Communication details between server and client
- H04N21/63—Control signaling related to video distribution between client, server and network components; Network processes for video distribution between server and clients or between remote clients, e.g. transmitting basic layer and enhancement layers over different transmission paths, setting up a peer-to-peer communication via Internet between remote STB's; Communication protocols; Addressing
- H04N21/647—Control signaling between network components and server or clients; Network processes for video distribution between server and clients, e.g. controlling the quality of the video stream, by dropping packets, protecting content from unauthorised alteration within the network, monitoring of network load, bridging between two different networks, e.g. between IP and wireless
- H04N21/64723—Monitoring of network processes or resources, e.g. monitoring of network load
- H04N21/6473—Monitoring network processes errors
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/80—Generation or processing of content or additional data by content creator independently of the distribution process; Content per se
- H04N21/83—Generation or processing of protective or descriptive data associated with content; Content structuring
- H04N21/845—Structuring of content, e.g. decomposing content into time segments
- H04N21/8456—Structuring of content, e.g. decomposing content into time segments by decomposing the content in the time domain, e.g. in time segments
Abstract
A system and method for a live streaming platform that can redundantly process input streams in parallel ingestion pipelines is disclosed herein. Ingested input streams in the parallel pipelines can be segmented using a stable segmentation function that creates identical segments in each of the streams in the pipelines. If errors occur, or there are disruptions in one or more of the input streams or pipelines, the live streaming platform can switch between the input streams on a per segment basis to provide reliable streaming feeds to a content distribution network. A master stream can be constructed from each of the master segments per a time period based on a reliability of each of the input streams and segments. Practicing pipeline affinity by selecting subsequent master segments from the same pipeline can minimize glitches.
Description
This application claims the rights and interests being entitled as the U.S. Patent Application Serial Number 13/439678 of " SCALABLE ROBUSTLIVE STREAMING SYSTEM " submitted on April 4th, 2012.The full text of this application is incorporated herein by reference.
Technical field
The extendible live TV stream that the disclosure relates generally to robust send (live streaming), and particularly relates to the switching at runtime carried out between relevant redundancy live TV stream to improve reliability.
Background technology
By the Internet, live TV stream is carried out to current event and send the requirement that improve and reliable stream is sent to infrastructure.Live TV stream send to feed and generally uses in the situation of such as great political oration and event, competitive sports and other cultural activity and so on, and the live TV stream that wherein a large amount of spectators depend on normal work send feeds.But due to any process of this scale and the distributed nature of conveying system, the fault of assembly is unavoidable and output stream can be made to interrupt or otherwise affect its quality.
Nowadays, the homogeneous turbulence such as roughly by making discrete hardware and/or software encoder push will to be redundantly coded is set up redundancy and is sent with the live TV stream carrying out the task key on web.This coding carries out completely in discrete coding path, and it produces discrete main stream and minor flow.The standby (failover) automatically switching to redundancy stream is attempted destruction is minimized, but because they employ discrete and/or different assemblies, so usually cannot realize not having short-time pulse to disturb the standby of (glitch).
Summary of the invention
Below provide the simplified summary of disclosure various aspects to provide the basic comprehension to these aspects.This summary of the invention is not the autgmentability general introduction of all desired aspects, and itself and be not intended to indicate key or requisite item is also not defined the scope of these aspects.Its objective is and provide concepts more of the present disclosure in a simplified manner and as the preorder of description specifically given subsequently.
System and method disclosed herein relates to the switching between the redundancy stream that to carry out processing in concurrent intake pipeline.Disclosed herein is a kind of system, it comprises segmented assemblies, and it identifies section boundaries in the inlet flow that absorbs and carries out segmentation based on this section boundaries to inlet flow.Buffer Unit cushions the segmentation of multiple inlet flow, and wherein cushioned segmentation carries out index and storage in memory.Main separation assembly selects the host buffer segmentation of each time period to be delivered to content distributing network from cushioned segmentation.
This main separation assembly can select cushioned segmentation based on the reliability signal of cushioned segmentation from the segmentation cushioned of multiple inlet flow.This main separation assembly can also switch to different inlet flow in response to the reliability signal of inlet flow drops to below threshold value for follow-up host buffer segmentation.Also disclose a kind of transcoding assembly, inlet flow transcoding is multiple output streams with different bit rates and form by it.
There is also disclosed a kind of method, comprise the section boundaries in the inlet flow that identification absorbs and based on this section boundaries, segmentation carried out to inlet flow.The method can comprise the segmentation cushioning multiple inlet flow, wherein cushions to comprise and carries out index and storage in memory.The method can also comprise selects the host buffer segmentation of each time period to be delivered to content distributing network from cushioned segmentation.The method can also comprise in response to the instruction receiving time-out in inlet flow and select follow-up host buffer segmentation from different inlet flow.
Here a kind of non-emporary computer-readable medium comprising computer executable instructions is disclosed in addition, this computer executable instructions makes computing system executable operations in response to execution, this operation comprises the section boundaries in the inlet flow that identification absorbs and carries out segmentation based on this section boundaries to inlet flow.This operation can comprise the segmentation cushioning multiple inlet flow, wherein cushions to comprise and carries out index and storage in memory.This operation may further include selects the host buffer segmentation of each time period to be delivered to content distributing network from cushioned segmentation.
The following description and drawings illustrate some illustrative aspect of the present disclosure.But these aspects are only several instructions in the various modes that can be adopted principle of the present disclosure.The disclosure is intended to comprise all these aspects and equivalents thereof.Other advantage of the present disclosure and different characteristic will become apparent by following to detailed description of the present disclosure when considering by reference to the accompanying drawings.
Accompanying drawing explanation
The block diagram of Fig. 1 to be diagram according to the live TV stream of various aspects as described herein and execution mode send example, non-limiting embodiment of infrastructure.
Fig. 2 is the block diagram with the example, non-limiting embodiment of the redundancy capturing system of concurrent intake pipeline illustrated according to various aspects as described herein and execution mode.
Fig. 3 segmentation can be carried out to redundancy stream and selecting the block diagram of the example, non-limiting embodiment of the system of main segmentation according to various aspects as described herein and execution mode that be diagram.
Fig. 4 is the block diagram can selecting the example, non-limiting embodiment of the system of segmentation from each mirror image stream illustrated according to various aspects as described herein and execution mode.
What Fig. 5 was diagram according to various aspects as described herein and execution mode can the block diagram of the example, non-limiting embodiment of the system of the segmentation of buffering parallel stream in memory.
What Fig. 6 was diagram according to various aspects as described herein and execution mode can be the block diagram of the example, non-limiting embodiment of the system of multiple output stream by inlet flow transcoding.
Fig. 7 illustrate according to various aspects as described herein and execution mode for carrying out segmentation to inlet flow and selecting the flow chart of the example, non-limiting embodiment of segmentation.
Fig. 8 illustrate according to various aspects as described herein and execution mode for carrying out segmentation to inlet flow and selecting the flow chart of the example, non-limiting embodiment of segmentation.
Fig. 9 is diagram carries out the Example Computing Device arranged block diagram according to various aspects as described herein and execution mode.
Figure 10 is the block diagram of diagram according to the example network environment of various aspects of the present disclosure and execution mode.
Embodiment
general introduction
With reference now to accompanying drawing, be described various aspects of the present disclosure, wherein same Reference numeral is used to refer to all the time for same key element.In the following description, a lot of detail is given to provide the thorough understanding to one or more aspect for illustrative purposes.But should be understood that, some aspect of the present disclosure can be put into practice when not having these details, or utilizes other method, assembly, material etc. to put into practice.In other cases, show in block form known features and equipment to promote the description to one or more aspect.
It is to be appreciated that according to one or more execution modes described in the disclosure, live TV stream send inlet flow can carry out Coherent processing in concurrent intake pipeline.If made a mistake during the picked-up and/or process of inlet flow, then live TV stream send and absorbs infrastructure and can carry out switching between parallel inlet flow and feed to provide to content distributing network reliable live TV stream to send.
In an embodiment, live TV stream send platform to operate in " cloud " environment completely, and therefore this system can provide in the sightless mode of terminal use.In cloud environment, providing live TV stream to send platform to mean, picked-up infrastructure can be server, this server receive arrive multicast live TV stream, live TV stream to be processed and to various player conveying robusts and stable stream, above-mentioned player also carries live TV stream based on server to terminal use.Terminal use can visit live TV stream via web browser or lightweight application.Relevant stream can be created from multiple picked-up paths, and when the arbitrary portion of a stream breaks down, singlely can flow to line reconstruction from phase master stream to whole.
Can process the accurate copy of inlet flow in concurrent intake pipeline and can be the temporal information (timestamp) that desired (with different bit rates) output stream retains this stream simultaneously by inlet flow transcoding.Stable fragmentation feature convection current can be used to carry out coherent fragmentation, and this stable fragmentation feature identifies section boundaries based on making to minimize with the modulus of target segment duration to timestamp delivery.This such as by carrying out initialization to realize to segment processing at the Common key frame place across all subflows, can this generates by the redundant input stream of same segment.
For each time period, segmentation can be carried out selecting using as the main segmentation being used to build this single stream from redundancy stream.This distributed main flow is selected can based on the availability of the particular fragments for all bit rates or reliability.By selecting subsequent segment from identical picked-up pipeline, be used for selecting which segmentation can be used in next step algorithm can by any possible in all keep pipeline tightness and the discontinuity flowed minimized.
Main flow is selected to operate between reliable stream controller and every pipeline data block (chunk) manager, and this every pipeline data block manager regularly communicates with master control side (master) when receiving new segmentation set.Live data block manager is for being selected as master control side to constant current and selected live data block manager exports current fragment to next treatment step (index and storage).Can process at the non-perfect copy of input convection current by utilizing time continuity.In this case, some short-time pulse interference of flowing may be occurred during standby, but phase homogeneous turbulence tightness logic makes the appearance of these image (artifact) minimize.
With reference now to accompanying drawing, Fig. 1 illustrates the block diagram of the live approach system 100 of example of the various aspects shown in foundation and execution mode.Live TV stream send infrastructure 102 can be provided to picked-up and/or process live media is fed to and they are distributed to media player 112.Media player 112 can use the local media stack of each target platform to explain vision signal and display translation.Player 112 can also comprise integrated monetization module.
Live TV stream send infrastructure 102 can comprise picked-up infrastructure 104, starting base facility 106, content distributing network 108 and stream/event control API (" API ") 110.Picked-up infrastructure 104 can receive the media feeds of arrival and carry out redundancy process to live feeding in discrete pipeline.Initially establish basis to execute 106 live media stream can be saved to memory, and prepare live TV stream to be delivered to content distributing network 108, this live media stream is delivered to media player 112 by this content distributing network 108.Current control API 110 can give beginning and/or stopping event, configures monetization setting and manage the ability of broadcast event set and life cycle thereof generally for the partner carrying out broadcasting.
Turn to Fig. 2 now, show the block diagram with the example, non-limiting embodiment of the redundancy capturing system 200 of concurrent intake pipeline of diagram foundation various aspects and execution mode.In picked-up infrastructure 104, redundancy live media stream is received in picked-up entrance 202 and 212.Once received, before distributing via content distributing network 108, redundancy live media stream absorb by parallel pipeline 204,210,214 and 216 and process and the last memory 208 be saved in by live data block manager (such as, 206) in starting base facility 106.
Picked-up entrance 202 and 212 can receive by with broadcast initiator directly equity and the multicast signal that obtains or receive the signal obtained by the global network of ingest server via real-time messages agreement (" RMTP ").Picked-up entrance 202 and 212 can also receive inlet flow via recoverable POST request and as the stream (having the independent POST of session indicators) of segmentation in advance from the picked-up based on HTML (Hypertext Markup Language) (" HTTP ").Picked-up entrance 202 and 212 can also receive live media stream from other source being generally used for the feeding of conveying live media.Once receive redundancy live media stream, concurrent intake pipeline 204,210,214 and 216 just can absorb concurrently and process redundancy live media stream.It is to be appreciated that although Fig. 2 depicts process from the pipeline 204 and 210 of the live TV stream of entrance 202 and process from the pipeline 214 and 216 of the live TV stream of entrance 212, any combination of pipeline and entrance can be there is.In certain embodiments, more less than two, every entrance parallel pipeline or more parallel pipeline can be there is, and in other embodiments, can exist and be greater than or less than two entrances.
Picked-up pipeline 204,210,214 and 216 can process and prepare live TV stream to be delivered to content distributing network 108.The such as processing module of segmented assemblies, Buffer Unit and transcoding segmentation and so on can be included in picked-up pipeline 204,210,214 and 216.Picked-up pipeline can also comprise wrapper and/or encrypted component stream be encapsulated as Container Format and/or be encrypted it.This pipeline can also comprise Delay Element, and it can insert delay in live media stream.
Segmented assemblies in pipeline 204,210,214 and 216 can identify section boundaries in absorbed inlet flow and carry out segmentation based on this section boundaries to inlet flow.The segmentation of parallel inlet flow can cushion in memory by Buffer Unit, and the main separation assembly absorbed in infrastructure 104 can select the host buffer segmentation of each split time section to be saved and to be delivered to content distributing network 108.The live data block manager be associated with for the pipeline selected by each buffered segment exports segmentation to next step in starting base facility 106 to carry out index and storage before being delivered to content distributing network 108.This of concurrent intake pipeline is arranged in the robustness that the structure at all levels sent from the picked-up of source material to encode, store, be converted to assets, issue and stream as required weighs system.
In certain embodiments, in order to retention time continuity, if preferably there is no mistake or time-out in stream, then use the output from one of parallel pipeline to carry out index and storage thus carry via content distributing network 108 in memory 208.The quantity of the short-time pulse interference that this pipeline tightness is possible during can making to be switched to the standby of another pipeline minimizes.But, if there is mistake in stream, and have selected one of the redundancy stream from another parallel pipeline, then make stream parallel fragmentation that the destruction of live TV stream can be made to minimize.
Therefore, such as, with reference to figure 2, the inlet flow from picked-up pipeline 204 can be the main flow be written to by live data block manager 206 in memory 208.Pipeline 210,214 and 216 has the redundancy stream parallel with the inlet flow of pipeline 204, but unless the inlet flow of pipeline 204 destroyed its do not selected.When occurring destroying, the main separation assembly in picked-up infrastructure 104 can select one of one of pipeline 210,214 or 216 and their live data block managers of being associated its inlet flow is carried out index as main flow and stores.
Turn to Fig. 3 now, illustrate can carry out segmentation to redundancy stream and selecting the example, non-limiting embodiment of the system 300 of main segmentation to carry out illustrated block diagram according to various aspects and execution mode.System 300 can comprise the part of the picked-up infrastructure 104 with segmented assemblies 302 and main separation assembly 304.The concurrent intake pipeline with live media stream is illustrated in the different phase 306,308 and 310 of process.Although institute, it is to be appreciated that Fig. 3 has illustrated a segmented assemblies 302 and a main separation assembly 304 in picked-up infrastructure 104, this is done to simple and clear, and each concurrent intake pipeline can comprise segmented assemblies and main separation assembly.
Segmented assemblies 302 can identify section boundaries in absorbed inlet flow and then carry out segmentation based on this section boundaries to inlet flow.Segmented assemblies 302 also can carry out segmentation to each in the inlet flow of concurrent intake in each pipeline, or alternatively, discrete segmented assemblies can carry out segmentation to discrete inlet flow.
Segmented assemblies 302 receives unsegmented inlet flow 306 and identifies the segmentation in inlet flow.In certain embodiments, the section boundaries identified can based on the quantity of frame (that is, every n frame starts new segmentation).Alternatively, in other embodiments, section boundaries can based on the type of frame (that is, in each frame or interframe start new segmentation).Other fragmentation feature can identify section boundaries based on making to minimize with the modulus of target segment duration to timestamp delivery.
In one of the present disclosure, in order to keep the concurrency of inlet flow, segmented assemblies 302 be used for identifying the algorithm of section boundaries or function should on each inlet flow be stable and make identifies also segmentation section boundaries be identical for each inlet flow.In order to realize this object, in certain embodiments, segmented assemblies 302 and/or each individual segmented assemblies can start at common key frame to find section boundaries.In other embodiments, segmented assemblies 302 can start segmentation in the beginning of stream.
In another embodiment, segmented assemblies 302 can use the algorithm of the noncontinuity robust for stream.Therefore, under the fault or discontinuous situation of inlet flow, the concurrency of the segmentation of inlet flow can not be interrupted.
Once segmented assemblies 302 identifies segmentation, inlet flow 306 just can be segmented, and the inlet flow 308 of segmentation is the result of this segmentation.A segmentation can be had in each inlet flow of each time period.This time period can based on the length of this time period based on the length of the length of segmentation or segmentation.Each segmentation in the inlet flow 308 of segmentation is interchangeable, and relevant main flow can be selected from one of segmentation of one of the inlet flow from each time period.
Main separation assembly 304 selects the main segmentation of each time period to be delivered to content distributing network from segmentation.In certain embodiments, in order to keep pipeline tightness and make short-time pulse minimum interference, main separation assembly 304 will select contiguous segmentation as main segmentation from same pipeline (such as, 312).Picked-up pipeline 310 carries redundancy stream and main flow 312 is selected to be carried by live data block manager (such as, 206) thus carry out index and storage in memory (such as, 208).
In one of the present disclosure, main separation assembly 304 is by maintenance pipeline tightness and continuation selects segmentation until the reliability signal of main flow 312 drops to below threshold value from same pipeline, and main separation assembly 304 switches to the main segmentation from different inlet flow.The time-out received also can trigger main separation assembly 304 and be switched to different inlet flows.In other embodiments, main separation assembly 304 can select main segmentation based on the reliability signal of cushioned segmentation from all segmentations of each time period.In some cases, the segmentation the most reliably of each time period can be selected as main segmentation.
In the diagram, the block diagram can selecting the example, non-limiting embodiment of the system 400 of segmentation from each mirror image stream of diagram foundation various aspects and execution mode is shown.In certain embodiments, perhaps pipeline and/or stream tightness can not or undesirably be kept.Main separation assembly 404 can receive the concurrent intake pipeline 402 therefrom will selecting the segmentation of main segmentation.Parallel pipeline shown in 406 has the main segmentation selected by main separation assembly 404, and wherein this main segmentation is distributed among pipeline.Main separation assembly 404 can select a segmentation of this time period based on the reliability signal of these segmentations or this inlet flow reliability in this time period.Therefore, the main segmentation from multiple various flows can be used to build final main flow of being undertaken distributing by content distributing network (such as, 108).
Turn to Fig. 5 now, show diagram according to various aspects and execution mode can the block diagram of the example, non-limiting embodiment of the system 500 of the segmentation of buffering parallel stream in memory.Can Buffer Unit 502 be provided the segmentation of the multiple inlet flows from concurrent intake pipeline 504 to be buffered in memory 506 in picked-up infrastructure 104.Before or after selected by main separation assembly (such as, 304,404), the segmentation cushioned can carry out index and storage in memory.
Although it is to be appreciated that Fig. 5 depicts a Buffer Unit for all pipelines 504 and a memory stores, multiple Buffer Unit and memory storage can be there is in institute.Such as, often absorbing pipeline can have a Buffer Unit, and the segmentation of each inlet flow is buffered in discrete memory storage by it.
Turn to Fig. 6 now, showing diagram can be the block diagram of the example, non-limiting embodiment of the system 600 of multiple output stream by inlet flow transcoding according to various aspects and execution mode.Transcoding assembly 604 can be provided in picked-up infrastructure 104 with by inlet flow 602 transcoding and/or be encoded to each output stream 606,608,610 and 612.Inlet flow 602 can be received in original form (such as, mpeg 2 transport stream " M2TS "), and primary flow can be encoded to each output stream by transcoding assembly 604.Output stream can be in different Container Formats and/or bit rate.Transcoding assembly 604 can retain the timestamp information in each output stream.
In certain embodiments, inlet flow can be divided into multiple output stream by transcoding assembly 604 in each picked-up pipeline.Therefore each concurrent intake pipeline will have each stream with different bit rates and/or Container Format.These streams are segmented, and when main segmentation selected by main separation assembly (such as, 304,404), main segmentation by comprise in each stream of being exported by transcoding assembly 604 each.
In of the present disclosure, the time-out in the stream of any transcoding in segmentation or destruction can cause main separation assembly to select main segmentation from another redundancy picked-up pipeline.
Fig. 7 illustrate according to aspect of the present disclosure for carrying out segmentation to inlet flow and selecting the exemplary process diagram 700 of the example, non-limiting embodiment of the method for segmentation.For the ease of explaining, the method is described and is described as a series of action.But, can occur in sequence and/or occur simultaneously with various according to action of the present disclosure, and there is other action not providing here and describe.In addition, the method for the theme disclosed in implementation basis all illustrated actions of non-required.In addition, it will be understood to those of skill in the art that also it is appreciated that the method alternatively can be represented as a series of correlation behavior via state diagram or event.In addition, should be realized, method disclosed in this specification can be stored on manufacture to promote such method transported and transfer to computing equipment.Manufacture is intended to comprise the computer program that can conduct interviews from any computer readable device or medium as the term is used herein.
In addition, above in conjunction with corresponding system diagram, each action to be described in detail.It is to be appreciated that in Fig. 1-6 to the detailed description of such action can be and be intended to be embodied as method and/or according to following described method.
702, in absorbed inlet flow, identify section boundaries and (such as, by segmented assemblies 302) carries out segmentation based on this section boundaries to inlet flow.Section boundaries carries out identifying (that is, every n frame starts new segmentation) based on the quantity of frame.Alternatively, in other embodiments, section boundaries can based on the type of frame (that is, in each frame or interframe start new segmentation).Other fragmentation feature can identify section boundaries based on making to minimize with the modulus of target segment duration to timestamp delivery.
The section boundaries of multiple inlet flow can be identified.Be processed in parallel in order to ensure inlet flow, be used to identify the algorithm of section boundaries or function should on each inlet flow be stable and make identifies also segmentation section boundaries be identical for each inlet flow.In order to realize this object, more of the present disclosure in, segmentation and identifying processing can start at the common key frame across all inlet flows.Alternatively, can initiate to identify from the beginning of stream.
Once identify section boundaries, just segmentation can be carried out based on this boundary convection.A segmentation can be had in each inlet flow of each time period.This time period can based on the length of this time period based on the length of the length of this segmentation or this segmentation.The segmentation of each time period each can be carried out exchanging and reconstructed main flow can being made up of any segmentation in the inlet flow of each time period.
704, (such as, by Buffer Unit 502) cushions the segmentation of multiple inlet flow, and wherein this buffering comprises cushioned segmentation is carried out index and storage in memory.706, (such as, by main separation assembly 304 and 404) selects each time period host buffer segmentation to be delivered to content distributing network from cushioned segmentation.
In certain embodiments, in order to keep pipeline tightness and make short-time pulse minimum interference, contiguous segmentation from same pipeline can be selected as main segmentation until the reliability of this main flow drops to below threshold value or predetermined value, and main segmentation can be selected from different inlet flow.Time-out in segmentation or inlet flow also can trigger and switch to different inlet flow.In other embodiments, main segmentation can be selected based on the reliability signal of cushioned segmentation from all segmentations of each time period.In some cases, the segmentation the most reliably of each time period can be selected as main segmentation.
Fig. 8 illustrate according to various aspects described herein and execution mode for carrying out segmentation to inlet flow and selecting the flow chart of the example, non-limiting embodiment of segmentation.It is to be appreciated that in Fig. 1-6 to the detailed description of such action can be and be intended to be embodied as method and/or according to following described method.
802, in discrete picked-up pipeline, redundancy process can be carried out to absorbed inlet flow.The inlet flow absorbed can carry out mirror image between these discrete picked-up pipelines.These discrete inlet flows absorbed also can carry out processing and make several level of redundancy guarantee to alleviate the destruction for one or more pipeline in parallel pipeline.
804, the segmentation of multiple redundancy stream can be initiated at common key frame.Which ensure that inlet flow to be processed in parallel and make identified section boundaries be identical for each inlet flow.806, segmentation algorithm is adopted to identify section boundaries based on making to minimize with the modulus of target segment duration to timestamp delivery.
808, the reliability signal based on the selected segmentation cushioned selects host buffer segmentation.In order to keep pipeline tightness, follow-up host buffer segmentation can be selected until the reliability of this inlet flow or host buffer segmentation drops to below predetermined value from same pipeline and/or inlet flow.Alternatively, the segmentation cushioned with most high reliability of each time period can be selected as host buffer segmentation.
Example calculation equipment
With reference to figure 9, comprise computing equipment 912 for the suitable environment 900 implementing each side of the present disclosure.It is to be appreciated that computer 912 can to combine with Fig. 1-6 in conjunction with enforcement illustrate and the one or more system described or assembly use.Computing equipment 912 comprises processing unit 914, system storage 916 and system bus 918.The system component including but are not limited to: system storage 916 is coupled to processing unit 914 by system bus 918.Processing unit 914 can be arbitrary various available processors.Dual micro processor and other multiple processor structure also can be used as processing unit 914.
System bus 918 can be arbitrary some types (multiple) bus structures, comprise memory bus or Memory Controller, peripheral bus or external bus and/or use the local bus of any various available bus architectures, above-mentioned bus architecture includes but are not limited to: Industry Standard Architecture (ISA), Micro Channel Architecture (MSA), expansion ISA (EISA), Intelligent Drive Electronics (IDE), VESA local bus (VLB), periphery component interconnection (PCI), card bus, USB (USB), advanced graphics port (AGP), PCMCIA's bus (PCMCIA), live wire (IEEE 994) and small computer system interface (SCSI).
System storage 916 comprises volatile memory 920 and nonvolatile memory 922.The basic input/output (BIOS) comprising the basic routine of transmission information between the element such as between the starting period in computing equipment 912 is stored in nonvolatile memory 922.Unrestricted by explanation, nonvolatile memory (such as, 922) read-only memory (ROM), programming ROM (PROM), electrically programmable ROM (EPROM), electrically erasable ROM (EEPROM), flash memory or nonvolatile random access memory (RAM) (such as, ferroelectric RAM (FeRAM)) can be comprised.Volatile memory (such as, 920) comprises random access storage device (RAM), and it is used as external cache.Unrestricted by explanation, RAM can obtain in a variety of forms, such as static RAM (SRAM) (SRAM), dynamic ram (DRAM), synchronous dram (SDRAM), Double Data Rate SDRAM (DDRSDRAM), enhancement mode SDRAM (ESDRAM), Synchlink DRAM (SLDRAM), directly Rambus RAM (DRRAM), directly Rambus dynamic ram (DRDRAM) and Rambus dynamic ram.In addition, the memory assembly of system disclosed herein or method is intended to comprise and is not limited to the memory comprising these and other suitable type any.
Computing equipment 912 can also comprise the computer storage media of removable/non-removable, volatile, nonvolatile.Such as, Fig. 9 illustrates disk storage 924.Disk storage 924 includes but are not limited to: the equipment as disc driver, flash drive, floppy disk, belt drive, Jaz driver, Zip drive, LS-100 driver, flash card or memory stick.Disk storage 924 can also comprise independence or the medium in conjunction with other medium, other medium above-mentioned includes but are not limited to: CD drive, and such as compact disk ROM device (CD-ROM), CD can record driver (CD-R driver), CD recordable drive (CD-RW driver) or digital versatile disc ROM driver (DVD-ROM).In order to promote that disk storage device 924 is to the connection of system bus 918, uses removable or non-moveable interface, such as interface 926 usually.
The software of the medium between Fig. 9 further depict as the basic computer resources described in user and proper handling environment 900.Such software such as comprises operating system 928.The operating system 928 that can be stored in disk storage 924 is used for controlling and the resource of Distribution Calculation equipment 912.System application 930 operates operating system 928 by be such as stored in system storage 916 middle disc and to store program module 932 on 924 and routine data 934 and is used to the management of resource.It is to be appreciated that the disclosure can utilize the combination of various operating system or operating system to implement.
User passes through input equipment 936 to input command or information in computing equipment 912.Input equipment 936 includes but are not limited to: the indicating equipment, trace ball, input pen, touch pad, keyboard, microphone, joystick, game mat, satellite dish antenna, scanner, TV frequency modulation card, digital camera, Digital Video, web camera etc. of such as mouse.These and other input equipment is connected to processing unit 914 via interface port 938 by system bus 918.Interface port 938 such as comprises serial port, parallel port, game port and USB (USB).Output equipment 930 uses the port of some types identical with input equipment 936.Therefore, such as, USB port can be used to provide input to computing equipment 912, and from computing equipment 912 to output equipment 940 output information.There is provided o adapter 942 to illustrate that existence except other output equipment 940 is as some output equipments 940 needing special adapter of monitor, loud speaker and printer and so on.Unrestricted by explanation, o adapter 942 comprises video and audio cards, and it provides connection means between output equipment 940 and system bus 918.It should be noted that the miscellaneous equipment of such as remote computer 944 and so on and/or the system of equipment provide input and output ability simultaneously.
The logic that computing equipment 912 can use one or more remote computers of such as remote computer 944 connects and operates in networked environment.Remote computer 944 can be personal computer, server, router, network PC, work station, device, peer device or other common network node etc. based on microprocessor, and generally includes about the many or whole element described by computing equipment 912.For simple and clear object, only illustrate memory storage device 946 with remote computer 944.Remote computer 944 is connected to computing equipment 912 by network interface 948 logic and carries out physical connection via communication connection 950 subsequently.Network interface 948 comprises wired and/or cordless communication network, such as local area network (LAN) (LAN), wide area network (WAN), cellular network etc.Lan technology comprises Fiber Distributed Data Interface (FDDI), copper distributed data interface (CDDI), Ethernet, token ring etc.WAN technology includes but are not limited to: point-to-point link, as the circuit-switched network of Integrated Service Digital Network(ISDN) (ISDN) and version, packet switching network and digital subscriber line (DSL).
Communication connection 950 refers to the hardware/software for network interface 948 being connected to bus 918.Although communication connection 950 is shown within computing equipment 912 in order to illustrate clear, it also can be in outside computing equipment 912.Only for exemplary object, the necessary hardware/software of connection to network interface 948 comprises inside and outside technology, such as comprises the modulator-demodulator of routine call level modulator-demodulator, wire line MODEM and DSL modulator-demodulator, ISDN adapter, Ethernet card and wireless network card.
According to various aspects and execution mode, computing equipment 912 can be used to carry out segmentation to redundant input stream and select main segmentation from the inlet flow of each time period.Inlet flow transcoding can also be the output stream of the vicissitudinous bit rate of tool and/or Container Format by computing equipment 912.Disclosed in more complete here, in some embodiments, computing equipment 912 can comprise one or more processor (such as, 914), it can be used to deal with data, comprise deal with data with perform various task (such as, comprise identify section boundaries, based on section boundaries to inlet flow carry out segmentation, buffered segment and store the segmentation of buffering in memory and from cushioned segmentation, select the host buffer segmentation etc. of each time period).Computing equipment 912 can comprise program assembly 905, and it can be associated with one or more processor (such as, communicating to connect with it).Program assembly 905 such as can comprise segmented assemblies, Buffer Unit, main separation assembly and transcoding assembly, and/or can promote other assembly of disclosed embodiment as described herein respectively here as being used for disclosed in more complete.
Exemplary network and distributed environment
Figure 10 is the schematic block diagram of the sample-computing environment 1000 according to embodiment of the present disclosure.System 1000 comprises one or more client 1010.Client 1010 can be hardware and/or software (such as, thread, process, computing equipment).System 1000 also comprises one or more server 1030.Therefore, except other model, system 1000 can correspond to double-deck client-server model or multilayered model (such as, client, middle tier server, data server).Server 1030 also can be hardware and/or software (such as, thread, process, computing equipment).Such as, server 1030 can deposit thread to perform conversion by adopting the disclosure.A kind of may communication between client 1010 and server 1030 can be the form of carrying out the packet transmitted between two or more computer disposal.
System 1000 comprises communication construction 1050, and it can be used to promote the communication between client 1010 and server 1030.Client 1010 operation is connected to one or more client data and stores 1020, and this one or more client data stores the information that 1020 can be used to store client 1010 this locality.Similarly, server 1030 operation is connected to one or more server data and stores 1040, and this one or more server data stores the information that 1040 can be used to storage server 1030 this locality.
Recognize and understand be, as can comprise about the assembly described by particular system or method with about corresponding assembly (such as, the assembly of corresponding name or the assembly of similar name) the same or analogous function described by other system disclosed herein or method.
Institute it should be noted that aspect of the present disclosure or feature can use with any aerogram or radiotechnics substantially, such as Wi-Fi; Bluetooth; World Interoperability for Microwave Access, WiMax (WiMAX); Enhancement type general use grouping wireless electricity service (Enhanced General Packet Radio Service); Third generation partner program (3GPP) Long Term Evolution (LTE); Third generation partner program 2 (3GPP2) Ultra Mobile Broadband (UMB); 3GPP Universal Mobile Telecommunications System (UMTS); High-speed packet access (HSPA); High-speed downlink packet access (HSDPA); High Speed Uplink Packet access (HSUPA); GSM (global system for mobile communications) EDGE (strengthening data rate GSM evolution) radio access network (GERAN); UMTS Terrestrial Radio Access Network network (UTRAN); Advanced LTE (LTE-A) etc.In addition, some or all aspects as described herein can use with conventional telecommunications technology, such as GSM.In addition, mobile and non-moving network (such as, the Internet, the such as data services network etc. of IPTV (IPTV)) can use with aspect as described herein or feature.
Although below generally with the computer executable instructions of the computer program that computer and/or multiple computer run for background is described theme, but it will be recognized by those skilled in the art, the disclosure can also maybe can be implemented in conjunction with other program module.Usually, program module comprises the routine, program, assembly, data structure etc. that perform particular task and/or implement particular abstract data type.In addition, one of ordinary skill in the art would recognize that, the method of invention can utilize other computer system configurations to put into practice, comprise single process or multiprocessor computer system, Small computing devices, mainframe computer and personal computer, handheld computing device (such as, PDA, phone), based on microprocessors or programmable consumer or industrial electrical equipment, etc.Illustrated aspect can also be put into practice in a distributed computing environment, and wherein task is performed by the remote processing devices being undertaken linking by communication network.But (even if not being whole) more of the present disclosure aspect can be put into practice on stand-alone computers.In a distributed computing environment, program module can be positioned at local and remote memory storage device.
As used in this application, term " assembly ", " system ", " platform ", " interface " etc. can refer to and/or can comprise computer related entity or the entity relevant to the computing machine with one or more specific functions.Entity disclosed herein can be hardware, the combination of hardware and software, software or executory software.Such as, assembly can be but be not limited to run on a processor process, processor, object, executable program, execution thread, program and/or computer.By illustrating, the application and service device run on the server can as assembly.One or more assembly can reside in process and/or execution thread within and assembly and/or can be distributed between two or more computers on a computer.
In another example, corresponding assembly can perform from the various computer-readable medias with the various data structures be stored thereon.This assembly such as can according to having one or more packet (such as, carry out the data of a mutual assembly from another assembly in local system, distributed system, and/or carry out the data of a mutual assembly across the network of such as the Internet and so on via signal and other system) signal and communicate via local and/or teleprocessing.As another example, assembly can be the device with the specific function that the mechanical part that undertaken operating by electric or electronic circuit provides, and foregoing circuit is operated by the software that performed by processor or firmware application.Under these circumstances, can be in device inner or outside and can perform this software or firmware application at least partially for processor.As another example again, assembly can be the device being provided specific function when not having mechanical part by electronic building brick, and wherein this electronic building brick can comprise processor or other device to perform software or the firmware of giving the function of this electronic building brick at least in part.In one aspect, such as, in cloud computing system, assembly can emulate electronic building brick via virtual machine.In cloud computing system, calculating can be carried as service instead of product.Therefore, resource, software and information can be shared between computer and server by network.Terminal use visits the application based on cloud by web browser or other small table or mobile app, and business software and data are then stored on the server of remote location.
In addition, term "or" is intended to expression and comprises "or" and non-excluded "or".That is, unless otherwise noted or clear and definite from context institute, otherwise " X adopts A or B " be intended to represent and naturally comprise spread pattern arbitrarily.That is, if X adopts A; X adopts B; Or X adopts both A and B, then " X adopts A or B " is just met under any above-mentioned example., unless otherwise noted or be clearly instruction singulative from context, otherwise the article " " (" a " and " an ") used in this subject specification and accompanying drawing is generally appreciated that expression " one or more " in addition.
As used herein, term " example " and/or " exemplary " are here used to represent as example, example or explanation.In order to avoid query, theme disclosed herein not limit by such example.In addition, here be described to any aspect of " example " and/or " exemplary " or design and not necessarily is understood to relative to other side or design it is preferred or favourable, it also and be not intended to get rid of and well known to a person skilled in the art equivalent example arrangement and technology.
Run through this specification to mean to be included at least one execution mode or an embodiment in conjunction with special characteristic, structure or the characteristic described by this execution mode or embodiment quoting of " a kind of execution mode " or " execution mode " or " embodiment " or " embodiment ".Therefore, depend on situation, run through phrase " in one embodiment " that this specification occurs everywhere or " in embodiments " or " in one embodiment " or " in an embodiment " can but and not necessarily refers to identical execution mode or embodiment.In addition, specific feature, structure or characteristic can combine in one or more execution mode or embodiment in any suitable manner.
Various aspects as described herein or feature can use standard program or engineering to be implemented as method, device, system or manufacture.In addition, various aspects disclosed in the disclosure or feature can be realized by the program module implementing at least one disclosed herein or multiple method, and this program module stores in memory and performed by least one processor.Other combination of hardware and software or hardware and firmware can be enable or implement aspect as described herein, comprises disclosed (multiple) method." manufacture " can comprise the computer program that can conduct interviews from any computer readable device, carrier or medium as the term is used herein.Such as, computer-readable storage medium can include but are not limited to: magnetic storage apparatus (such as, hard disk, floppy disk, magnetic stripe), CD (such as, compact-disc (CD), digital versatile disc (DVD), Blu-ray disc (BD) ...), smart card and flash memory device (such as, card, rod, cipher key drivers), etc.
As in this specification adopt, term " processor " can refer to arbitrary calculation processing unit or equipment substantially, includes but are not limited to: single core processor; There is the single processor of software multithread executive capability; Polycaryon processor; There is the polycaryon processor of software multithread executive capability; There is the polycaryon processor of hardware multithread technology; Parallel tables; And there is the parallel tables of distributed shared memory.In addition, processor can refer to integrated circuit, application-specific integrated circuit (ASIC) (ASIC), digital signal processor (DSP), field programmable gate array (FPGA), programmable logic controller (PLC) (PLC), complex programmable logic equipment (CPLD), discrete gate or transistor logic, discrete hardware components or be designed to perform its combination in any of function as described herein.In addition, processor can adopt the framework of nanometer scale, such as but be not limited to based on the transistor of molecule and quantum dot, switch and gate circuit, so that the space of optimizing user equipment uses or promotes its performance.Processor can also be implemented as the combination of calculation processing unit.
In the disclosure, such as " storage ", " storage ", " data storing ", " data storage ", " database " and substantially the operation of concerned components and any out of Memory memory module of function be used to refer to generation " memory assembly ", the entity that embodies with " memory " or the assembly comprising memory.Institute it is to be appreciated that memory as described herein and/or memory assembly can be volatile memory or nonvolatile memory, or can comprise both volatibility and nonvolatile memory.
Content already described above comprises the example of system and method for the present disclosure.Obviously, and can not for description object of the present disclosure and being all described often kind of combination that can expect of assembly or method, but one skilled in the art will recognize that and may carry out many other combination and permutation of the present disclosure.In addition, term with regard to using in detailed description, claim, annex and accompanying drawing " comprises ", " having ", " having " etc. scope with regard to, such term be intended to be similar to when term " comprise " in the claims as during transition word to its similar mode made an explanation but inclusive.
Claims (22)
1. a system, comprising:
Memory, described memory has the computer that is stored thereon can executive module;
Processor, described processor performs the following computer that stores in which memory can executive module:
Segmented assemblies, the section boundaries in the inlet flow that described segmented assemblies identification is absorbed and segmentation is carried out to described inlet flow based on described section boundaries;
Buffer Unit, described Buffer Unit cushions the segmentation of multiple inlet flow, wherein cushioned segmentation indexed and store in memory; And
Main separation assembly, described main separation assembly selects the host buffer segmentation of each time period to be delivered to content distributing network from cushioned segmentation.
2. system according to claim 1, wherein absorbed inlet flow carries out redundancy process in discrete picked-up pipeline.
3. system according to claim 2, comprises redundant input stream further, described redundant input stream in the picked-up pipeline that second component is vertical by redundancy process.
4. system according to claim 1, comprises transcoding assembly further, and described inlet flow transcoding is multiple output streams with different bit rates and form by described transcoding assembly.
5. system according to claim 1, wherein each picked-up pipeline has a segmented assemblies.
6. system according to claim 5, wherein the shared key frame place of each segmented assemblies in described multiple inlet flow starts segmentation.
7. system according to claim 1, wherein said segmented assemblies uses segmentation algorithm to identify described section boundaries based on making to minimize with the modulus of target segment duration to timestamp delivery.
8. system according to claim 1, wherein said main separation assembly based on cushioned segmentation reliability signal and select described host buffer segmentation from the segmentation cushioned of multiple inlet flow.
9. system according to claim 1, wherein said main separation component responds drops to below threshold value in the reliability signal of described inlet flow and switches to different inlet flow for follow-up host buffer segmentation.
10. system according to claim 1, wherein said main separation component responds switches to different inlet flow in the instruction receiving time-out in described inlet flow for subsequent segment.
11. systems according to claim 1, wherein absorbed inlet flow is live TV stream.
12. 1 kinds of methods, comprising:
Purpose processor is made to perform storage computer executable instructions in memory to perform following action:
Identify section boundaries in the inlet flow that absorbs and based on described section boundaries, segmentation carried out to described inlet flow;
Cushion the segmentation of multiple inlet flow, wherein said buffering comprise to cushioned segmentation carry out index and store in memory; And
From cushioned segmentation, select the host buffer segmentation of each time period to be delivered to content distributing network.
13. methods according to claim 12, are included in the inlet flow that in discrete picked-up pipeline, redundancy process is absorbed further.
14. according to claim 13 method, be included in the inlet flow absorbed of redundancy process redundancy in the picked-up pipeline that second component stands further.
15. methods according to claim 12, comprising described inlet flow transcoding is further multiple output streams with different bit rates and form.
16. methods according to claim 13, are included in the segmentation of shared key frame place initiation to multiple redundancy stream further.
17. methods according to claim 12, wherein identify that the stream of described section boundaries comprises employing segmentation algorithm further, and described segmentation algorithm identifies described section boundaries based on making to minimize with the modulus of target segment duration to timestamp delivery.
18. methods according to claim 12, wherein the segmentation of selection host buffer is the reliability signal based on the selected segmentation cushioned.
19. methods according to claim 12, comprise further and select follow-up host buffer segmentation from identical inlet flow, unless the reliability of subsequent segment drops to below threshold value.
20. methods according to claim 12, comprise further in response to the instruction receiving time-out in described inlet flow and select follow-up host buffer segmentation from different inlet flow.
21. methods according to claim 12, the section boundaries in the inlet flow that wherein said identification is absorbed comprises the section boundaries identified in live TV stream further.
22. 1 kinds of non-transitory computer-readable storage medium comprising computer executable instructions, described computer executable instructions makes computer system executable operations in response to execution, described operation comprises:
Identify section boundaries in the inlet flow that absorbs and based on described section boundaries, segmentation carried out to described inlet flow;
Cushion the segmentation of multiple inlet flow, wherein said buffering comprise to cushioned segmentation carry out index and store in memory; And
From cushioned segmentation, select the host buffer segmentation of each time period to be delivered to content distributing network.
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
CN201811072893.5A CN109600351B (en) | 2012-04-04 | 2013-04-03 | Scalable robust live streaming system |
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US13/439,678 | 2012-04-04 | ||
US13/439,678 US8838826B2 (en) | 2012-04-04 | 2012-04-04 | Scalable robust live streaming system |
PCT/US2013/035139 WO2013152115A1 (en) | 2012-04-04 | 2013-04-03 | Scalable robust live streaming system |
Related Child Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201811072893.5A Division CN109600351B (en) | 2012-04-04 | 2013-04-03 | Scalable robust live streaming system |
Publications (2)
Publication Number | Publication Date |
---|---|
CN104769951A true CN104769951A (en) | 2015-07-08 |
CN104769951B CN104769951B (en) | 2018-10-12 |
Family
ID=48143377
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201811072893.5A Active CN109600351B (en) | 2012-04-04 | 2013-04-03 | Scalable robust live streaming system |
CN201380028673.1A Active CN104769951B (en) | 2012-04-04 | 2013-04-03 | Approach system is broadcast live in expansible robust |
Family Applications Before (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201811072893.5A Active CN109600351B (en) | 2012-04-04 | 2013-04-03 | Scalable robust live streaming system |
Country Status (5)
Country | Link |
---|---|
US (2) | US8838826B2 (en) |
EP (1) | EP2834983A1 (en) |
KR (2) | KR102051012B1 (en) |
CN (2) | CN109600351B (en) |
WO (1) | WO2013152115A1 (en) |
Families Citing this family (14)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9246741B2 (en) * | 2012-04-11 | 2016-01-26 | Google Inc. | Scalable, live transcoding with support for adaptive streaming and failover |
US9300578B2 (en) * | 2013-02-21 | 2016-03-29 | Applied Micro Circuits Corporation | Large receive offload functionality for a system on chip |
US9253484B2 (en) * | 2013-03-06 | 2016-02-02 | Disney Enterprises, Inc. | Key frame aligned transcoding using statistics file |
US9854260B2 (en) * | 2013-03-06 | 2017-12-26 | Disney Enterprises, Inc. | Key frame aligned transcoding using key frame list file |
US10567489B2 (en) * | 2013-03-15 | 2020-02-18 | Time Warner Cable Enterprises Llc | System and method for seamless switching between data streams |
KR102268052B1 (en) * | 2013-11-11 | 2021-06-22 | 삼성전자주식회사 | Display apparatus, server apparatus and user interface screen providing method thereof |
US9706509B2 (en) | 2013-12-05 | 2017-07-11 | Cisco Technology, Inc. | Synchronization of streaming data |
EP3171601A4 (en) * | 2014-07-14 | 2018-05-16 | SK TechX Co., Ltd. | Cloud streaming service system, data compressing method for preventing memory bottlenecking, and device for same |
CA2972818C (en) | 2014-12-31 | 2023-08-01 | Echostar Technologies Llc | Automated video content processing |
EP3241354A4 (en) * | 2014-12-31 | 2018-10-10 | Imagine Communications Corp. | Fragmented video transcoding systems and methods |
EP3220262B1 (en) * | 2016-03-15 | 2018-06-13 | Axis AB | Device which is operable during firmware upgrade |
US10673919B1 (en) * | 2016-06-29 | 2020-06-02 | Amazon Technologies, Inc. | Concurrent input monitor and ingest |
US10349108B2 (en) | 2017-08-24 | 2019-07-09 | Mobitv, Inc. | System and method for storing multimedia files using an archive file format |
CN111654724B (en) * | 2020-06-08 | 2021-04-06 | 上海纽菲斯信息科技有限公司 | Low-bit-rate coding transmission method of video conference system |
Citations (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20030079036A1 (en) * | 2001-10-22 | 2003-04-24 | Yoshihisa Terada | Data stream selection/output apparatus and control program for achieving the apparatus |
CN102118438A (en) * | 2011-01-17 | 2011-07-06 | 中兴通讯股份有限公司 | Method and device for live broadcasting apple media stream in Internet protocol television (IPTV) system |
Family Cites Families (31)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP2734386B2 (en) * | 1994-12-20 | 1998-03-30 | 日本電気株式会社 | String reader |
JP3165138B2 (en) * | 1998-09-14 | 2001-05-14 | 株式会社ナムコ | Communication game system |
TW444506B (en) * | 1999-09-16 | 2001-07-01 | Ind Tech Res Inst | Real-time video transmission method on wireless communication networks |
US6839865B2 (en) | 2000-12-29 | 2005-01-04 | Road Runner | System and method for multicast stream failover |
US7149189B2 (en) * | 2001-07-17 | 2006-12-12 | Mcafee, Inc. | Network data retrieval and filter systems and methods |
US7298746B1 (en) * | 2002-02-11 | 2007-11-20 | Extreme Networks | Method and system for reassembling and parsing packets in a network environment |
US7684568B2 (en) * | 2003-11-24 | 2010-03-23 | Intellon Corporation | Encrypting data in a communication network |
US7509390B1 (en) | 2005-06-01 | 2009-03-24 | Cisco Technology, Inc. | Methods and apparatus for controlling the transmission of data |
US8122144B2 (en) * | 2006-06-27 | 2012-02-21 | International Business Machines Corporation | Reliable messaging using redundant message streams in a high speed, low latency data communications environment |
US7733910B2 (en) * | 2006-12-29 | 2010-06-08 | Riverbed Technology, Inc. | Data segmentation using shift-varying predicate function fingerprinting |
US8166012B2 (en) * | 2007-04-11 | 2012-04-24 | Emc Corporation | Cluster storage using subsegmenting |
US8312356B1 (en) * | 2008-10-29 | 2012-11-13 | Cousins Robert E | Systems, methods and computer program products including features for coding and/or recovering data |
US8386630B1 (en) * | 2007-09-09 | 2013-02-26 | Arris Solutions, Inc. | Video-aware P2P streaming and download with support for real-time content alteration |
US8819288B2 (en) * | 2007-09-14 | 2014-08-26 | Microsoft Corporation | Optimized data stream compression using data-dependent chunking |
WO2010046722A1 (en) | 2008-10-24 | 2010-04-29 | Telefonaktiebolaget L M Ericsson (Publ) | Systems and methods for reducing loss of service using protocol redirect functions |
US8260877B2 (en) | 2008-12-31 | 2012-09-04 | Apple Inc. | Variant streams for real-time or near real-time streaming to provide failover protection |
US8184750B2 (en) * | 2009-01-22 | 2012-05-22 | Freescale Semiconductor, Inc. | Techniques for increasing decoding reliability in an adaptive minimum mean squared error with successive interference cancellation (MMSE/SIC) decoder |
CN101494655B (en) * | 2009-03-12 | 2012-06-27 | 中国电信股份有限公司 | RTP distributed stream media service system and method |
US8392748B2 (en) | 2009-10-06 | 2013-03-05 | Microsoft Corporation | Reliable media streaming |
WO2011068784A1 (en) | 2009-12-01 | 2011-06-09 | Azuki Systems, Inc. | Method and system for secure and reliable video streaming with rate adaptation |
US8954596B2 (en) * | 2010-04-02 | 2015-02-10 | Netflix, Inc. | Dynamic virtual chunking of streaming media content |
US8935270B1 (en) * | 2010-05-13 | 2015-01-13 | Netlogic Microsystems, Inc. | Content search system including multiple deterministic finite automaton engines having shared memory resources |
CN102300120B (en) * | 2010-06-23 | 2015-06-10 | 中兴通讯股份有限公司 | Switch and method for selectively outputting multiple signals |
KR20120010089A (en) * | 2010-07-20 | 2012-02-02 | 삼성전자주식회사 | Method and apparatus for improving quality of multimedia streaming service based on hypertext transfer protocol |
US8122142B1 (en) * | 2010-10-12 | 2012-02-21 | Lemi Technology, Llc | Obtaining and displaying status updates for presentation during playback of a media content stream based on proximity to the point of capture |
US20130018932A1 (en) * | 2011-07-12 | 2013-01-17 | Hughes Network Systems, Llc | System and method for long range and short range data compression |
CN102238434B (en) * | 2011-07-22 | 2017-12-19 | 中兴通讯股份有限公司 | A kind of IPTV files in stream media virtual segmentation and the method and system used |
US8751679B2 (en) * | 2011-10-07 | 2014-06-10 | Ericsson Television Inc. | HTTP adaptive streaming server with automatic rate shaping |
CN102325274B (en) * | 2011-10-13 | 2013-08-21 | 浙江万里学院 | Network bandwidth-adaptive video stream transmission control method |
US8977769B2 (en) * | 2012-01-17 | 2015-03-10 | Harman International Industries, Incorporated | System for managing lossless failover in an audio-bridging (AVB) network |
US8874634B2 (en) * | 2012-03-01 | 2014-10-28 | Motorola Mobility Llc | Managing adaptive streaming of data via a communication connection |
-
2012
- 2012-04-04 US US13/439,678 patent/US8838826B2/en active Active
-
2013
- 2013-04-03 WO PCT/US2013/035139 patent/WO2013152115A1/en active Application Filing
- 2013-04-03 CN CN201811072893.5A patent/CN109600351B/en active Active
- 2013-04-03 KR KR1020147030948A patent/KR102051012B1/en active IP Right Grant
- 2013-04-03 KR KR1020197034951A patent/KR102110098B1/en active IP Right Grant
- 2013-04-03 EP EP13717918.0A patent/EP2834983A1/en not_active Withdrawn
- 2013-04-03 CN CN201380028673.1A patent/CN104769951B/en active Active
-
2014
- 2014-08-18 US US14/462,214 patent/US9215260B2/en active Active
Patent Citations (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20030079036A1 (en) * | 2001-10-22 | 2003-04-24 | Yoshihisa Terada | Data stream selection/output apparatus and control program for achieving the apparatus |
CN102118438A (en) * | 2011-01-17 | 2011-07-06 | 中兴通讯股份有限公司 | Method and device for live broadcasting apple media stream in Internet protocol television (IPTV) system |
Also Published As
Publication number | Publication date |
---|---|
KR102110098B1 (en) | 2020-05-12 |
US20130268688A1 (en) | 2013-10-10 |
US20140359158A1 (en) | 2014-12-04 |
KR20190134829A (en) | 2019-12-04 |
KR20150042148A (en) | 2015-04-20 |
US9215260B2 (en) | 2015-12-15 |
US8838826B2 (en) | 2014-09-16 |
CN104769951B (en) | 2018-10-12 |
KR102051012B1 (en) | 2019-12-02 |
CN109600351B (en) | 2021-10-15 |
WO2013152115A1 (en) | 2013-10-10 |
EP2834983A1 (en) | 2015-02-11 |
CN109600351A (en) | 2019-04-09 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN104769951A (en) | Scalable robust live streaming system | |
US20220038724A1 (en) | Video stream decoding method and apparatus, terminal device, and storage medium | |
CN104380758A (en) | Scalable, live transcoding with support for adaptive streaming and failover | |
US8891939B2 (en) | Systems and methods for video-aware screen capture and compression | |
CN104365108A (en) | Live streaming video processing | |
CN106576182A (en) | Video quality enhancement | |
CN106464930A (en) | Method and system to combine multiple encoded videos for decoding via a video decoder | |
US11228801B2 (en) | Method and apparatus for providing multi-view streaming service | |
US9456230B1 (en) | Real time overlays on live streams | |
US20210168433A1 (en) | Client-server-based solutions for playing online video advertisements on different user devices | |
EP3267331B1 (en) | Method and apparatus for cloud streaming service | |
CN102981887B (en) | Data processing method and electronic equipment | |
US11109012B2 (en) | Carriage of PCC in ISOBMFF for flexible combination | |
CN110933482A (en) | Video loading method and device, computer readable storage medium and computer equipment | |
CN112165653B (en) | Video playing method, device and equipment | |
CN111327951A (en) | Multimedia data playing method, device, system and storage medium | |
CN105323593B (en) | A kind of multi-media transcoding dispatching method and device | |
CN106411996A (en) | Content negotiation in a content centric network | |
CN116600169A (en) | Method and device for preloading media files, electronic equipment and storage medium | |
CN108141618B (en) | Method and apparatus for random access of HEVC bitstream for MMT | |
KR102281217B1 (en) | Method for encoding and decoding, and apparatus for the same | |
KR102209783B1 (en) | Method for providing streaming data packet through streaming server and node linking with base station, and node using the same | |
CN112073727A (en) | Transcoding method and device, electronic equipment and storage medium | |
KR20160100048A (en) | Method for providing streaming data through node linking with base station, and node using the same | |
KR102313530B1 (en) | System for cloud streaming service, method of image cloud streaming service using split screen and apparatus for the same |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
C06 | Publication | ||
PB01 | Publication | ||
EXSB | Decision made by sipo to initiate substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
CB02 | Change of applicant information | ||
CB02 | Change of applicant information |
Address after: American CaliforniaApplicant after: Google limited liability companyAddress before: American CaliforniaApplicant before: Google Inc. |
|
GR01 | Patent grant | ||
GR01 | Patent grant |