CN115335825A - Privacy preserving machine learning for content distribution and analysis - Google Patents
Privacy preserving machine learning for content distribution and analysis Download PDFInfo
- Publication number
- CN115335825A CN115335825A CN202180025475.4A CN202180025475A CN115335825A CN 115335825 A CN115335825 A CN 115335825A CN 202180025475 A CN202180025475 A CN 202180025475A CN 115335825 A CN115335825 A CN 115335825A
- Authority
- CN
- China
- Prior art keywords
- mpc
- user
- demographic
- application
- computing system
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
- 238000010801 machine learning Methods 0.000 title claims description 257
- 238000004458 analytical method Methods 0.000 title claims description 12
- 238000009826 distribution Methods 0.000 title abstract description 93
- 238000000034 method Methods 0.000 claims abstract description 232
- 230000008569 process Effects 0.000 claims description 97
- 230000002776 aggregation Effects 0.000 claims description 68
- 238000004220 aggregation Methods 0.000 claims description 68
- 230000004044 response Effects 0.000 claims description 42
- 230000000694 effects Effects 0.000 claims description 31
- 238000004590 computer program Methods 0.000 claims description 15
- 238000013507 mapping Methods 0.000 claims description 13
- 230000008685 targeting Effects 0.000 abstract 1
- 239000013598 vector Substances 0.000 description 129
- 230000006870 function Effects 0.000 description 77
- 238000012549 training Methods 0.000 description 57
- 238000006243 chemical reaction Methods 0.000 description 47
- 238000010586 diagram Methods 0.000 description 30
- 239000011159 matrix material Substances 0.000 description 27
- 235000014510 cooky Nutrition 0.000 description 25
- 238000012545 processing Methods 0.000 description 25
- 238000003860 storage Methods 0.000 description 25
- 230000009466 transformation Effects 0.000 description 25
- 238000004422 calculation algorithm Methods 0.000 description 21
- 238000004364 calculation method Methods 0.000 description 19
- 238000013215 result calculation Methods 0.000 description 17
- 238000004891 communication Methods 0.000 description 14
- 238000013515 script Methods 0.000 description 13
- 239000002131 composite material Substances 0.000 description 9
- 230000003993 interaction Effects 0.000 description 9
- 238000005259 measurement Methods 0.000 description 9
- 239000000047 product Substances 0.000 description 9
- 238000011156 evaluation Methods 0.000 description 8
- 230000009471 action Effects 0.000 description 6
- 230000008901 benefit Effects 0.000 description 6
- 230000005540 biological transmission Effects 0.000 description 6
- 238000012795 verification Methods 0.000 description 6
- 230000009286 beneficial effect Effects 0.000 description 5
- 230000001965 increasing effect Effects 0.000 description 5
- 230000036961 partial effect Effects 0.000 description 5
- 238000007637 random forest analysis Methods 0.000 description 5
- 230000008859 change Effects 0.000 description 4
- 238000003066 decision tree Methods 0.000 description 4
- 238000013459 approach Methods 0.000 description 3
- 238000013528 artificial neural network Methods 0.000 description 3
- 238000013461 design Methods 0.000 description 3
- 230000003287 optical effect Effects 0.000 description 3
- 238000006116 polymerization reaction Methods 0.000 description 3
- 230000000644 propagated effect Effects 0.000 description 3
- 238000013519 translation Methods 0.000 description 3
- 239000000654 additive Substances 0.000 description 2
- 230000000996 additive effect Effects 0.000 description 2
- 230000004931 aggregating effect Effects 0.000 description 2
- 238000013500 data storage Methods 0.000 description 2
- 238000013503 de-identification Methods 0.000 description 2
- 230000003247 decreasing effect Effects 0.000 description 2
- 238000005516 engineering process Methods 0.000 description 2
- 238000004519 manufacturing process Methods 0.000 description 2
- 238000010295 mobile communication Methods 0.000 description 2
- 230000002829 reductive effect Effects 0.000 description 2
- 238000000926 separation method Methods 0.000 description 2
- 239000013589 supplement Substances 0.000 description 2
- 238000012360 testing method Methods 0.000 description 2
- 238000012546 transfer Methods 0.000 description 2
- 230000001131 transforming effect Effects 0.000 description 2
- 238000009827 uniform distribution Methods 0.000 description 2
- 101100478633 Escherichia coli O157:H7 stcE gene Proteins 0.000 description 1
- 230000003190 augmentative effect Effects 0.000 description 1
- 230000006399 behavior Effects 0.000 description 1
- FFBHFFJDDLITSX-UHFFFAOYSA-N benzyl N-[2-hydroxy-4-(3-oxomorpholin-4-yl)phenyl]carbamate Chemical compound OC1=C(NC(=O)OCC2=CC=CC=C2)C=CC(=C1)N1CCOCC1=O FFBHFFJDDLITSX-UHFFFAOYSA-N 0.000 description 1
- 239000006227 byproduct Substances 0.000 description 1
- 229960001948 caffeine Drugs 0.000 description 1
- 238000010411 cooking Methods 0.000 description 1
- 230000008878 coupling Effects 0.000 description 1
- 238000010168 coupling process Methods 0.000 description 1
- 238000005859 coupling reaction Methods 0.000 description 1
- 230000007123 defense Effects 0.000 description 1
- 230000001934 delay Effects 0.000 description 1
- 230000001419 dependent effect Effects 0.000 description 1
- 230000002708 enhancing effect Effects 0.000 description 1
- 235000013305 food Nutrition 0.000 description 1
- 239000011521 glass Substances 0.000 description 1
- 230000003116 impacting effect Effects 0.000 description 1
- 230000006872 improvement Effects 0.000 description 1
- 230000002427 irreversible effect Effects 0.000 description 1
- 238000005304 joining Methods 0.000 description 1
- 239000004973 liquid crystal related substance Substances 0.000 description 1
- 238000007726 management method Methods 0.000 description 1
- 238000003062 neural network model Methods 0.000 description 1
- 238000010606 normalization Methods 0.000 description 1
- 230000001737 promoting effect Effects 0.000 description 1
- 230000009467 reduction Effects 0.000 description 1
- 230000000717 retained effect Effects 0.000 description 1
- 230000002441 reversible effect Effects 0.000 description 1
- 230000011218 segmentation Effects 0.000 description 1
- 239000004065 semiconductor Substances 0.000 description 1
- 230000001953 sensory effect Effects 0.000 description 1
- 239000002904 solvent Substances 0.000 description 1
- 238000000638 solvent extraction Methods 0.000 description 1
- 238000007619 statistical method Methods 0.000 description 1
- 239000000758 substrate Substances 0.000 description 1
- 101150115529 tagA gene Proteins 0.000 description 1
- 238000000844 transformation Methods 0.000 description 1
- RYYVLZVUVIJVGH-UHFFFAOYSA-N trimethylxanthine Natural products CN1C(=O)N(C)C(=O)C2=C1N=CN2C RYYVLZVUVIJVGH-UHFFFAOYSA-N 0.000 description 1
- 230000000007 visual effect Effects 0.000 description 1
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/60—Protecting data
- G06F21/62—Protecting access to data via a platform, e.g. using keys or access control rules
- G06F21/6218—Protecting access to data via a platform, e.g. using keys or access control rules to a system of files or objects, e.g. local or distributed file system or database
- G06F21/6245—Protecting personal data, e.g. for financial or medical purposes
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/10—Protecting distributed programs or content, e.g. vending or licensing of copyrighted material ; Digital rights management [DRM]
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N20/00—Machine learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q30/00—Commerce
- G06Q30/01—Customer relationship services
- G06Q30/015—Providing customer assistance, e.g. assisting a customer within a business location or via helpdesk
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q30/00—Commerce
- G06Q30/02—Marketing; Price estimation or determination; Fundraising
- G06Q30/0201—Market modelling; Market analysis; Collecting market data
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q30/00—Commerce
- G06Q30/02—Marketing; Price estimation or determination; Fundraising
- G06Q30/0241—Advertisements
- G06Q30/0251—Targeted advertisements
- G06Q30/0269—Targeted advertisements based on user profile or attribute
- G06Q30/0271—Personalized advertisement
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q30/00—Commerce
- G06Q30/06—Buying, selling or leasing transactions
- G06Q30/0601—Electronic shopping [e-shopping]
- G06Q30/0631—Item recommendations
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L9/00—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols
- H04L9/08—Key distribution or management, e.g. generation, sharing or updating, of cryptographic keys or passwords
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L9/00—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols
- H04L9/08—Key distribution or management, e.g. generation, sharing or updating, of cryptographic keys or passwords
- H04L9/0816—Key establishment, i.e. cryptographic processes or cryptographic protocols whereby a shared secret becomes available to two or more parties, for subsequent use
- H04L9/0819—Key transport or distribution, i.e. key establishment techniques where one party creates or otherwise obtains a secret value, and securely transfers it to the other(s)
- H04L9/083—Key transport or distribution, i.e. key establishment techniques where one party creates or otherwise obtains a secret value, and securely transfers it to the other(s) involving central third party, e.g. key distribution center [KDC] or trusted third party [TTP]
- H04L9/0833—Key transport or distribution, i.e. key establishment techniques where one party creates or otherwise obtains a secret value, and securely transfers it to the other(s) involving central third party, e.g. key distribution center [KDC] or trusted third party [TTP] involving conference or group key
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L9/00—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols
- H04L9/08—Key distribution or management, e.g. generation, sharing or updating, of cryptographic keys or passwords
- H04L9/0816—Key establishment, i.e. cryptographic processes or cryptographic protocols whereby a shared secret becomes available to two or more parties, for subsequent use
- H04L9/085—Secret sharing or secret splitting, e.g. threshold schemes
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q2220/00—Business processing using cryptography
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L2209/00—Additional information or applications relating to cryptographic mechanisms or cryptographic arrangements for secret or secure communication H04L9/00
- H04L2209/46—Secure multiparty computation, e.g. millionaire problem
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L2209/00—Additional information or applications relating to cryptographic mechanisms or cryptographic arrangements for secret or secure communication H04L9/00
- H04L2209/60—Digital content management, e.g. content distribution
Abstract
The present disclosure relates to systems and techniques that can be implemented by a content platform to optimize: (a) Demographic-based digital component distribution for categorizing each user into a particular demographic for purposes of properly targeting that user for purposes of maximizing the efficacy of the digital components shown to that user, and (b) demographic reporting for reporting the effectiveness of the digital components to a digital component provider.
Description
Technical Field
The present specification relates to a privacy preserving machine learning platform that uses secure multi-party computing to train and use machine learning models.
Background
Some machine learning models are trained based on data collected from multiple sources (e.g., across multiple websites and/or native applications). However, the data may include private or sensitive data that should not be shared or allowed to be revealed to other parties.
Disclosure of Invention
Digital component providers often benefit from being able to limit the audience to which digital components are displayed. Such restrictions are beneficial to users in that they can be shown more relevant content. Such limits can be based on audience demographics. The content platform provides digital component providers the ability to distribute digital components of their activities to a particular group of users (e.g., users of a particular demographic group). The content platform often does so by associating a cookie (e.g., a third party cookie) for the user with one of the demographic groups, which can be performed even if the user is not logged into the website displaying the digital components. The content platform may facilitate display of the digital component on a content provider's website or other website (e.g., a third party website, which is a website hosted by an entity other than the content provider platform). To keep track of the user's browsing preferences, the content platform uses the same cookie to track the user's browsing history across different websites. The content platform uses the data extracted from the cookie to (a) categorize each user into a particular demographic to properly target the user for the purpose of maximizing the efficacy of the digital components shown to the user, and (b) report the effectiveness of the digital components to the digital component provider. However, the use of cookies is disadvantageous because other websites may be able to access the cookie, and thus user preferences across different websites can be accessed by each of those websites. Such access to user behavior through many websites may sometimes be viewed as intruding into the privacy of the user. To avoid such intrusiveness, there is a need to optimize the demographic-based digital component distribution and reporting performed by the content platform without the use of such cookies. In addition, some browsers prevent the use of third party cookies, so that browsing information that is typically collected across multiple websites is no longer available. Thus, any functionality that relies on information collected through third-party cookies (e.g., cookies from a domain different from the domain of the web page the user is currently viewing), such as adjusting the distribution of data to the client device, is no longer available.
The disclosure relates to a privacy preserving machine learning platform using secure multi-party computing to train and use machine learning models. In particular, the present disclosure describes systems and techniques for categorizing users into particular demographic groups and reporting the effectiveness of activities used to distribute digital components to groups of users based at least in part on demographic information without the use of third party cookies.
In one aspect, an application of a client device can receive, from one or more computers, data identifying inferred demographics of a user of the application. The application can display digital content that includes computer readable code for reporting events related to the digital content, data specifying a set of allowed demographic-based user group identifiers, and an activity identifier for the digital content. The application can determine that a given inferred characteristic matches a given allowed demographic-based user group identifier. In response to determining that the given inferred demographic characteristic matches the given allowed demographic-based user group identifier, the computer-readable code can be configured to generate and transmit a request to update one or more event counts for the digital content and the given allowed demographic-based user group identifier.
In some implementations, one or more of the following can additionally or alternatively be implemented in any suitable combination. Receiving data identifying inferred demographics of a user of the application can include receiving, at the client device, an inferred demographics-based user group identifier for a demographics-based user group to which the user is added. An inference request can be sent to one or more computers that includes a user profile of a user. An inferred demographic user group identifier can be received from the one or more computers in response to the inference request. The one or more computers can include a plurality of multi-party computing (MPC) servers. Sending the inference request to the one or more computers can include sending a respective secret share of the user profile to each of the plurality of MPC servers. The plurality of MPC servers can perform a secure MPC process using one or more machine learning models to generate and communicate secret shares of the inferred demographics-based user group identifier to an application.
The application can send, to one or more computers, an inference request for data identifying inferred demographics of a user of the application. The inference request can include a user profile of the user and contextual signals related to at least one of: either (i) a digital content slot in which the digital content is displayed or (ii) the digital content, wherein an inferred demographic user group identifier is received from the one or more computers in response to the inference request, or (iii) a Uniform Resource Locator (URL) of a resource comprising the digital content, a location of the client device, a spoken language setting of the application. Generating and sending, using computer readable code, a request to update one or more event counts for digital content and a given allowed demographic-based user group identifier can include: generating an aggregation key comprising an activity identifier and a given allowed demographic-based user group identifier; and transmitting the aggregated key with the request. Generating and transmitting, using computer readable code, a request to update one or more event counts for the digital content and the given allowed demographic-based user group identifier can include invoking an Application Programming Interface (API) of an application to send the request.
Methods, systems, apparatuses, computer-programmable products, etc., that implement the above-noted features are also within the scope of the present disclosure. For example, in some aspects, a system is described that includes: at least one programmable processor; and a machine-readable medium storing instructions that, when executed by at least one programmable processor, cause the at least one programmable processor to perform operations comprising: receiving, by an application of a client device from one or more computers, data identifying inferred demographics of a user of the application; displaying, by an application, digital content comprising computer-readable code for reporting events related to the digital content, and data specifying a set of allowed demographic-based user group identifiers, and an activity identifier for the digital content; determining, by the application, that a given inferred characteristic matches a given allowed demographic-based user group identifier; and in response to determining that the given inferred demographic characteristic matches the given allowed demographic-based user group identifier, generating and transmitting, using computer-readable code, a request to update one or more event counts for the digital content and the given allowed demographic-based user group identifier.
Similarly, in certain aspects, a non-transitory computer program product is described that is capable of storing instructions that, when executed by at least one programmable processor, cause the at least one programmable processor to perform operations that can include: receiving, by an application of a client device from one or more computers, data identifying inferred demographics of a user of the application; displaying, by an application, digital content comprising computer-readable code for reporting events related to the digital content, data specifying a set of allowed demographic-based user group identifiers, and an activity identifier for the digital content; determining, by the application, that a given inferred characteristic matches a given allowed demographic-based user group identifier; and in response to determining that the given inferred demographic characteristic matches the given allowed demographic-based user group identifier, generating and transmitting, using computer-readable code, a request to update one or more event counts for the digital content and the given allowed demographic-based user group identifier.
In some aspects, one or more processors are capable of performing operations comprising: receiving, from a first browser of a digital content provider, data identifying digital content and a first set of one or more demographic categories for which demographic reporting is to be performed; associating a user of a client device on which digital content is being displayed with a second set of one or more demographic categories; if the first set of one or more demographic categories and the second set of one or more demographic categories have at least one common demographic category, communicating the browsing event and the at least one common demographic category entered on the client device to an API, wherein the API combines the browsing event and the at least one common demographic category with at least one browsing event of other users and the associated at least one demographic category that is one of the first set of one or more demographic categories to generate aggregated data; receiving aggregated data from the API; and generating a report including the aggregated data.
Associating the user with the second set of one or more demographic categories can include: receiving a self-identification by the user of a second set of one or more demographic categories on the first browser; and mapping the user to a second set of one or more demographic categories. Associating the user with the second set of one or more demographic categories can include: transmitting a browsing history of a user to a multi-way computing cluster; receiving inferences output by the machine learning model from the machine learning model within the multi-party computing cluster, the inferences including a second set of demographic categories; and mapping the user to a second set of one or more demographic categories. Generating the report can include: arranging the aggregated data in a table; generating an analysis based on the aggregated data; and providing the tables and analysis in a report. The report can be generated automatically in response to a request for a report or at preset time intervals. The request for the report can be generated by one or more of a digital content provider, a content platform, a secure multi-party computing cluster, or a publisher that developed and provided the first browser. The request for a report can be generated at preset time intervals, automatically or after the count of events exceeds a preset threshold.
Data identifying the digital content and a first set of one or more demographic categories can be included in the aggregation key. The data identifying the digital content can include a Uniform Resource Locator (URL) of a resource displaying the digital content. The operations can further include: determining a third set of demographic categories relevant to the user; and restrict the first browser of the client device to display digital content indicated by the respective digital content provider as being associated with a category in the third set of demographic categories. Determining the third set of one or more demographic categories can include receiving a self-identification by the user of the third set of one or more demographic categories relevant to the user on the first browser. Determining the third set of one or more demographic categories can include: transmitting a browsing history of a user to a multi-directional computing cluster; and receiving data identifying a third set of demographic categories from the plurality of computing clusters.
Methods, systems, apparatuses, computer programmable products, etc., that implement the above-noted features are also within the scope of the present disclosure. For example, in some aspects, a system is described that can include: at least one programmable processor; and a machine-readable medium storing instructions that, when executed by at least one programmable processor, cause the at least one programmable processor to perform operations comprising: receiving, from a first browser of a digital content provider, data identifying digital content and a first set of one or more demographic categories for which demographic reporting is to be performed; associating a user of a client device on which digital content is being displayed with a second set of one or more demographic categories; if the first set of one or more demographic categories and the second set of one or more demographic categories have at least one common demographic category, communicating the browsing event and the at least one common demographic category entered on the client device to an API, wherein the API combines the browsing event and the at least one common demographic category with at least one browsing event of other users and the associated at least one demographic category that is one of the first set of one or more demographic categories to generate aggregated data; receiving aggregated data from the API; and generating a report including the aggregated data.
Similarly, in another aspect, a non-transitory computer program product is described that is capable of storing instructions that, when executed by at least one programmable processor, cause the at least one programmable processor to perform operations comprising: receiving, from a first browser of a digital content provider, data identifying digital content and a first set of one or more demographic categories for which demographic reporting is to be performed; associating a user of a client device on which digital content is being displayed with a second set of one or more demographic categories; if the first set of one or more demographic categories and the second set of one or more demographic categories have at least one common demographic category, transmitting the browsing event and the at least one common demographic category input on the client device to an API, wherein the API combines the browsing event and the at least one common demographic category with at least one browsing event of the other user and the associated at least one demographic category that is one demographic category in the first set of one or more demographic categories to generate aggregated data; receiving aggregated data from the API; and generating a report including the aggregated data.
The subject matter described in this specification can be implemented in particular embodiments to realize one or more of the following advantages. The digital component distribution techniques described in this document are capable of identifying users with similar interests and extending user group membership while protecting the privacy of the users, e.g., without revealing the users' online activities to any computing system. This protects user privacy and protects the security of data from corruption during transmission to or from the platform with respect to such platforms. Cryptographic techniques such as secure multi-party computing (MPC) enable the expansion of user groups based on similarities in user profiles without the use of third-party cookies, which protects user privacy without negatively impacting the ability to expand user groups, and in some cases provides better user group expansion based on a more complete profile than can be achieved using third-party cookies. MPC technology can ensure that as long as one computing system in an MPC cluster is honest, user data cannot be obtained in the clear by either computing system or the other. Thus, the methods described herein allow for the identification, grouping, and transmission of user data in a secure manner without the need to use third party cookies to determine any relationships between user data. This is a distinct approach from conventional approaches that typically require third party cookies to determine relationships between data. By grouping user data in this manner, the efficiency of transferring data content to user devices is improved, as data content not relevant to a particular user does not need to be transferred. In particular, third party cookies are not required, thereby avoiding storage of third party cookies and improving memory usage. Exponential decay techniques can be used to build a user profile at a client device to reduce the data size of the raw data required to build the user profile, thereby reducing data storage requirements.
Demographic reporting techniques involve generating reports to digital component providers to indicate how their digital components behave for a particular group of users based on their user group memberships. By using secure MPC machine learning techniques to predict user demographics, the reports can more accurately reflect the performance of a demographic-based user group without sacrificing user privacy. The process for generating such reports does not reveal the data of the individual user to any entity, thereby protecting user privacy. The structural design of the reporting framework does not use cookies and prevents leakage of user data.
Various features and advantages of the foregoing subject matter are described below with reference to the drawings. Additional features and advantages will be apparent from the subject matter described herein and the claims.
Drawings
FIG. 1 is a block diagram of an environment in which a secure MPC cluster trains a machine learning model and the machine learning model is used to extend a user group.
FIG. 2 is a swim lane diagram of an example process for training a machine learning model and using the machine learning model to add a user to a user group.
Fig. 3 is a flow diagram illustrating an example process for generating a user profile and sending shares of the user profile to an MPC cluster.
FIG. 4 is a flow diagram illustrating an example process for generating a machine learning model.
FIG. 5 is a flow diagram illustrating an example process for adding a user to a user group using a machine learning model.
FIG. 6 is a conceptual diagram of an exemplary framework for generating inference results for a user profile.
FIG. 7 is a conceptual diagram of an exemplary framework for generating inferences for a user profile with increased performance.
FIG. 8 is a flow diagram illustrating an example process for generating inferences for a user profile at an MPC cluster with increased performance.
FIG. 9 is a flow diagram illustrating an example process for preparing and performing training of a second machine learning model at an MPC cluster in order to promote inference performance.
FIG. 10 is a conceptual diagram of an exemplary framework for evaluating performance of a first machine learning model.
FIG. 11 is a flow diagram illustrating an example process for evaluating performance of a first machine learning model at an MPC cluster.
FIG. 12 is a flow diagram illustrating an example process for generating inference results for a user profile at a computing system of an MPC cluster with enhanced performance.
FIG. 13 is a flow diagram illustrating a demographic report, which is a process for reporting the validity of a digital component to a digital component provider.
Fig. 14 is a flow diagram illustrating an example process performed by a client device to facilitate demographic-based digital component distribution and demographic reporting.
FIG. 15 is a block diagram of an example computer system.
Like reference numbers and designations in the various drawings indicate like elements.
Detailed Description
In general, systems and techniques are described that allow users to be categorized into particular demographic groups without the use of third-party cookies and to report the effectiveness of activities for distributing digital components to groups of users based at least in part on demographic information.
Demographic based user group expansion
The machine learning platform described in this document enables a content platform to generate and extend groups of users based at least in part on demographic information (e.g., age range, geographic location, spoken language, etc.). These user groups enable the digital component provider to reach a particular set of users for which the user group was created. For example, a digital component provider operating a fitness studio specifically for women may benefit from distributing digital components to members of a woman's user group, which can help avoid showing digital components that are more relevant to men. To enable such targeted content distribution without the need or use of cookies, groups of users are formed and subsequently extended using privacy preserving machine learning systems and techniques. Such systems and techniques are used to train and use machine learning models to extend user group membership while protecting user privacy and ensuring data security.
In general, rather than creating and maintaining a user profile at a computing system of another entity, such as a content platform, a user profile is maintained at a client device of a user. To train the machine learning model, a user's client device can optionally send their encrypted user profile (e.g., as a secret share of the user profile) along with other data to multiple computing systems of a secure multi-party computing (MPC) cluster via a content platform. For example, each client device can generate two or more secret shares of the user profile and send the respective secret shares to each computing system. The computing systems of the MPC cluster can use MPC techniques to train machine-learned models to suggest groups of users for users based on their profiles in a manner that prevents any computing system of the MPC cluster (or other party other than the user itself) from obtaining any user's profile in the clear (which can also be referred to as plain text) to protect the user's privacy. The machine learning model may be a k-nearest neighbor (k-NN) model. In some implementations, the machine learning model can be a k-NN augmented (e.g., via gradient boosting) by other machine learning models (e.g., neural network models or gradient boosting decision trees).
After training the machine learning model, the machine learning model can be used to suggest one or more user groups for each user based on each user's profile. For example, a user's client device can query the MPC cluster for suggested groups of users for that user or determine whether the user should be added to a particular group of users. Various inference techniques, such as binary classification, regression (e.g., using arithmetic mean or root mean square), and/or multi-class classification can be used to identify groups of users. User group membership of a user can be used to provide content to the user in a privacy-preserving and secure manner.
Example System for generating and Using machine learning models
FIG. 1 is a block diagram of an environment 100 in which secure MPCs 130 cluster train machine learning models and the machine learning models are used to extend user groups. The example environment 100 includes a data communication network 105, such as a Local Area Network (LAN), a Wide Area Network (WAN), the internet, a mobile network, or a combination thereof. Network 105 connects client devices 110, secure MPC cluster 130, publishers 140, websites 142, and content platforms 150. Example environment 100 may include many different client devices 110, secure MPC clusters 130, publishers 140, websites 142, content platforms 150, digital component providers 160, and aggregation systems 180.
The client device 110 is an electronic device capable of communicating over the network 105. Example client devices 110 include personal computers, mobile communication devices (e.g., smart phones), and other devices capable of sending and receiving data over the network 105. Client devices 110 can also include digital assistant devices that accept audio input through a microphone and output audio output through a speaker. When the digital assistant detects a "hot word" or "hot phrase" that activates the microphone to accept audio input, the digital assistant can be placed in a listening mode (e.g., ready to accept audio input). The digital assistant device can also include a camera and/or a display to capture images and visually present information. The digital assistant can be implemented in different forms of hardware devices, including a wearable device (e.g., a watch or glasses), a smartphone, a speaker device, a tablet device, or another hardware device. Client devices 110 can also include digital media devices, such as streaming devices that plug into a television or other display to stream video to the television.
The client device 110 typically includes an application 112, such as a web browser and/or a native application, to facilitate sending and receiving data over the network 105. A native application is an application developed for a particular platform or a particular device (e.g., a mobile device with a particular operating system). The publisher 140 can develop and provide the native application to the client device 110, e.g., make the native application available for download. The Web browser can request the resource 145 from a Web server hosting the publisher's 140 website 142, for example, in response to a user of the client device 110 entering a resource address of the resource 145 in an address bar of the Web browser or selecting a link referencing the resource address. Similarly, the native application can request application content from a publisher's remote server.
Some resources, application pages, or other application content can include a digital component slot for presenting digital components with the resource 145 or application page. As used throughout this document, the phrase "digital component" refers to a discrete unit of digital content or digital information (e.g., a video clip, an audio clip, a multimedia clip, an image, text, or another unit of content). The digital component can be electronically stored in the physical memory device as a single file or in a collection of files, and the digital component can take the form of a video file, an audio file, a multimedia file, an image file, or a text file and include advertising information such that the advertisement is a type of digital component. For example, the digital component may be content intended to supplement the content of a web page or other resource presented by the application 112. More specifically, the digital components may include digital content related to the resource content (e.g., the digital components may relate to the same subject matter as the web page content, or to related topics). The provision of digital components can thus supplement and generally enhance web page or application content.
When application 112 loads a resource (or application content) that includes one or more digital component slots, application 112 can request a digital component for each slot. In some implementations, the digital component slot can include code (e.g., script) that causes the application 112 to request the digital component from a digital component distribution system that selects the digital component and provides the digital component to the application 112 for presentation to a user of the client device 110.
Some publishers 140 use SSPs to manage the process of obtaining digital components for their digital component slots of resources and/or applications. SSPs are technical platforms implemented in hardware and/or software that automate the process of obtaining digital components for resources and/or applications. Each publisher 140 can have a corresponding SSP or SSPs. Some publishers 140 may use the same SSP.
The digital component provider 160 can create (or otherwise publish) digital components that are presented in digital component slots of publishers' resources and applications. The digital component provider 160 can use the DSP to manage its provisioning of digital components for presentation in the digital component slots. A DSP is a technical platform implemented in hardware and/or software that automates the process of distributing digital components for presentation with resources and/or applications. The DSP can interact with multiple supply side platforms SSP on behalf of a digital component provider 160 to provide digital components for presentation with multiple different publisher 140 resources and/or applications. In general, the DSP is capable of receiving a request for a digital component (e.g., from the SSP), generating (or selecting) selection parameters for one or more digital components created by one or more digital component providers based on the request, and providing data related to the digital component (e.g., the digital component itself) and the selection parameters to the SSP. The SSP can then select a digital component for presentation at the client device 110 and provide the client device 110 with data that causes the client device 110 to present the digital component.
In some cases, it may be beneficial for a user to receive digital components related to a web page, application page, or other electronic resource previously accessed and/or interacted with by the user. To distribute such digital components to users, users can be assigned to groups of users, e.g., groups of user interests, groups of similar users, or other group types involving similar user data, when the user accesses a particular resource or performs a particular action at the resource (e.g., interacts with a particular item presented on a web page or adds the item to a virtual shopping cart). The user group can be generated by the digital component provider 160. That is, each digital component provider 160 is capable of assigning users to their group of users when they access electronic resources of the digital component provider 160. In some implementations, the publisher 140, the content platform 150, or the MPC cluster 130 can also assign users to selected groups of users.
To protect user privacy, group membership of a user can be maintained at the user's client device 110, e.g., by one of the applications 112 or the operating system of the client device 110, rather than by a digital component provider, content platform, or other party. In a particular example, a trusted program (e.g., a web browser or operating system can maintain a list of user group identifiers ("user group list") for users using the web browser or another application the user group list can include a group identifier for each user group to which a user has been added, a digital component provider 160 or content platform (e.g., a DSP) that creates the user group can specify the user group identifier for their user group.
When the application 112 presents resources or application content related to the digital component provider 160, or a web page on the website 142, the resource can request that the application 112 add one or more user group identifiers to the list of user groups. In response, the application 112 can add one or more user group identifiers to the user group list and securely store the user group list.
The content platform 150 can use the user group membership of the user to select digital components or other content that may be of interest to the user or that may otherwise be beneficial to the user/user device. For example, such digital components or other content may include data that improves the user experience, improves the operation of the user device, or benefits the user or user device in some other manner. However, the user group identifiers of the user's user group list can be provided in a manner that prevents the content platform 150 from correlating the user group identifiers with particular users, thereby protecting user privacy when using the user group membership data to select digital components. In some implementations, security and privacy protection can be even more powerful. For example, a computing system MPC 1 And MPC 2 May not be colluded and only the application 112 may be permitted to view the user group identifier in clear text.
The application 112 can provide the user group identifier from the user group list to a trusted computing system that interacts with the content platform 150 to select digital components for presentation at the client device 110 based on user group membership in a manner that prevents the content platform 150 or any other entity that is not the user himself from knowing any user's user group membership.
In some cases, it may be beneficial for the user and for the digital component provider to extend the user group to include users with similar interests or other similar data (e.g., similar demographics) as users who are already members of the user group. Usefully, this can be achieved without the use of third party cookies. For example, the first user may be interested in skiing and may be a member of a user group of a particular skiing resort. The second user may also be interested in skiing, but is not aware of this ski resort and is not a member of the user group of that particular ski resort. If the two users have similar interests or data, e.g., similar user profiles, the second user may be added to the group of users for that particular ski resort, such that the second user receives content, e.g., digital components, that are relevant to the ski resort and that may be of interest to or otherwise beneficial to the second user or its user device. In other words, a user group may be extended to include other users with similar user data. In particular examples, the demographic-based user group can be expanded to include other users having the same or similar demographics associated with the demographic-based user group.
The secure MPC cluster 130 can train a machine learning model that suggests user groups to a user (or application 112 thereof) based on the user's profile, or can be used to generate suggestions of user groups to a user (or application 112 thereof) based on the user's profile. The secure MPC cluster 130 includes two computing systems MPCs that perform secure MPC techniques to train machine learning models 1 And MPC 2 . Although the example MPC cluster 130 includes two computing systems, more computing systems can be used as long as MPC cluster 130 includes more than one computing system. For example, MPC cluster 130 can include three computing systems, four computing systems, or another suitable number of computing systems. Using more computing systems in the MPC cluster 130 can provide more security and fault tolerance, but may also increase the complexity of the MPC process.
Computing system MPC 1 And MPC 2 Can be operated by different entities. In this way, each entity may not have clear access to the user profile. In plain text, without the need for a keyOr text in the form of computationally infested, specially formatted, or written in code or data (including binary files) for viewing or use in the case of other decryption devices or other decryption processes. For example, a computing system MPC 1 Or MPC 2 One of which can be operated by a different trusted party than the user, publisher 140, content platform 150, and digital component provider 160. For example, an industry group, government group, or browser developer may maintain and operate a computing system MPC 1 And MPC 2 One of them. Another computing system may be operated by a different one of the groups, such that a different trusted party operates each computing system MPC 1 And MPC 2 . Preferably, the MPC of the different computing systems is operated 1 And MPC 2 Have no incentive to collude to compromise the privacy of the user. In some implementations, a computing system MPC 1 And MPC 2 Are architecturally separate and are monitored so as not to communicate with each other outside of performing the secure MPC process described in this document.
In some implementations, the MPC cluster 130 trains one or more k-NN models for each content platform 150 and/or for each digital component provider 160. For example, each content platform 150 can manage distribution of digital components for one or more digital component providers 160. The content platform 150 can request the MPC cluster 130 to train the k-NN model against one or more digital component providers 160 for which the content platform 150 manages the distribution of digital components. In general, the k-NN model represents the distance between the user profiles (and optionally additional information) of a group of users. Each k-NN model of a content platform can have a unique model identifier. An example process for training the k-NN model is illustrated in FIG. 4 and described below.
After training the k-NN model for the content platform 150, the content platform 150 can query or cause the application 112 of the client device 110 to query the k-NN model to identify one or more user groups for the user of the client device 110. For example, the content platform 150 can query the k-NN model to determine whether a threshold number of "k" user profiles that are closest to the user are members of a particular user group. If so, the content platform 150 may add the user to the group of users. If a user group is identified for the user, content platform 150 or MPC cluster 130 can request application 112 to add the user to the user group. If approved by the user and/or the application 112, the application 112 can add the user group identifier for the user group to a list of user groups stored at the client device 110.
In some implementations, the application 112 can provide a user interface that enables a user to manage the user group to which the user is assigned. For example, the user interface can enable the user to remove the user group identifier, preventing all or a particular resource 145, publisher 140, content platform 150, digital component provider 160, and/or MPC cluster 130 from adding the user to the user group (e.g., preventing an entity from adding the user group identifier to a list of user group identifiers maintained by the application 112). This provides better transparency, selection/consent, and control for the user.
In addition to the description throughout this document, a user may be provided with controls (e.g., user interface elements with which the user can interact) that allow the user to make selections regarding whether and when the systems, programs, or features described herein may enable gathering user information (e.g., information about the user's social network, social actions or activities, profession, the user's preferences, or the user's current location) and whether to send content or communications from a server to the user. In addition, certain data may be processed in one or more ways before it is stored or used, so that personally identifiable information is removed. For example, the identity of the user may be processed such that no personally identifiable information of the user can be determined, or the geographic location of the user may be generalized where location information is obtained (such as to a city, zip code, or state level) such that no particular location of the user can be determined. Thus, the user may control what information is collected about the user, how the information is used, and what information is provided to the user.
In some implementations, the example environment 100 can also facilitate reporting of data, such as browsing events, such as impressions, clicks, and/or conversions, by various users in respective demographic categories. In such cases, the content platform 150 (e.g., DSP or SSP, and in some implementations a separate reporting platform) can implement or communicate with a reporting API that can communicate with the aggregation system 180 that combines the browsing events (e.g., impressions, clicks and/or conversions, and/or lack/absence thereof) and demographic categories to generate aggregated data. Aggregation system 180 can transmit aggregated data to content platform 150 (or a separate reporting platform) in the form of reports or in the form of data that can be easily combined and inserted in reports.
Example Process for generating and Using machine learning models
FIG. 2 is a swim lane diagram of an example process 200 for training a machine learning model and using the machine learning model to add a user to a user group. The operation of the process 200 can be performed, for example, by a client device 110, a computing system MPC of an MPC cluster 130 1 And MPC 2 And a content platform 150. The operations of process 200 can also be implemented as instructions stored on one or more computer-readable media, which may be non-transitory, and execution of the instructions by one or more data processing apparatus can cause the one or more data processing apparatus to perform the operations of process 200. Although the process 200 and the following other processes are described in terms of two computing system MPC clusters 130, MPC clusters having more than two computing systems can also be used to perform similar processes.
The content platform 150 can initiate training and/or updating of one of its machine learning models by requesting that the application 112 running on the client device 110 generate a user profile for its respective user and upload a secret shared and/or encrypted version of the user profile to the MPC cluster 130. For the purposes of this document, a secret share of a user profile can be considered an encrypted version of the user profile because the secret share is not in the clear. In general, each application 112 is capable of storing data of a user profile and generating an updated user profile in response to receiving a request from the content platform 150. Since the content and machine learning models of the user profile are different for different content platforms 150, the application 112 running on the user's client device 110 is able to maintain data for multiple user profiles and generate multiple user profiles, each user profile specific to a particular content platform or a particular model owned by a particular content platform.
The application 112 running on the client device 110 builds a user profile for the user of the client device 110 (202). The user profile of the user can include data related to events initiated by the user and/or events that can have been initiated by the user with respect to an electronic resource (e.g., a web page or application content). The event can include a view of the electronic resource, a view of the digital component, a user interaction with (e.g., selection of) the electronic resource or the digital component, or a lack of user interaction with (e.g., selection of) the electronic resource or the digital component, a conversion that occurs after the user interacts with the electronic resource, and/or other suitable events related to the user and the electronic resource.
The user profile of the user can be specific to the content platform 150 or a selected machine learning model owned by the content platform 150. For example, as described in more detail below with reference to fig. 3, each content platform 150 can request that the application 112 generate or update a user profile specific to that content platform 150.
The user profile of the user can be in the form of a feature vector. For example, the user profile can be an n-dimensional feature vector. Each of the n dimensions can correspond to a particular feature and the value of each dimension can be a value of a feature for the user. For example, one dimension may be for whether a particular digital component is presented to (or interacted with by) the user. In this example, the value of the feature can be a "1" if the digital component is presented to (or interacted with by) the user, or a "0" if the digital component has not been presented to (or interacted with by) the user. An example process for generating a user profile for a user is illustrated in fig. 3 and described below.
In some implementations, content platform 150 may want to train a machine learning model based on additional signals, such as contextual signals, and featuresA signal related to a digital component, or a signal related to a user that may not be known to the application 112 or may not be accessible to the application 112, such as the current weather at the user's location. For example, content platform 150 may want to train a machine learning model to predict whether a user will interact with a particular digital component if presented to the user in a particular context. In this example, for each presentation of a digital component to the user, the context signals can include the then-current geographic location of client device 110 (if the user grants permission), signals describing the content of the electronic resource with which the digital component is presented, and signals describing the digital component, e.g., the content of the digital component, the type of the digital component, the location on the electronic resource at which the digital component is presented, and so forth. In another example, one dimension may be for whether a digital component presented to the user is of a particular type. In this example, the value can be 1 for travel, 2 for food, 3 for movie, etc. For convenience of subsequent description, P i Will represent both the user profile and additional signals (e.g., context signals and/or digital component level signals) associated with the ith user profile.
In some implementations, the application 112 can also provide one or more tags to the MPC cluster 130. Although the labels may not be used when training a machine learning model of some architecture (e.g., k-NN), the labels can be used to fine-tune hyper-parameters (e.g., the value of k) that control the model training process, or to evaluate the quality of the trained machine learning model, or to make predictions, i.e., to determine whether to suggest user groups for the user. The tags can include, for example, one or more of the user group identifiers for the users and accessible to the content platform 150. That is, the tag can include a user group identifier for a user group managed by the content platform 150 or accessible for reading by the content platform 150. In some implementations, a single tag includes multiple user group identifiers for a user. In some implementations, the tags for the users can be heterogeneous and include all user groups that contain the user as a member and additional information, e.g., whether the user interacts with a given digital component. This enables the k-NN model to be used to predict whether another user will interact with a given digital component. The label for each user profile can indicate a user group membership of the user corresponding to the user profile.
The tags for the user profile predict a group of users to which the user corresponding to the input will or should be added. For example, the tags corresponding to the k nearest neighbor user profiles of the input user profile predict a user group to which the user corresponding to the input user profile will or should join, e.g., based on similarities between the user profiles. These predictive tags can be used to suggest groups of users to the user or to request that the application add the user to the group of users corresponding to the tag.
If tags are included, the application 112 can also associate each label with i Splitting into portions, e.g. [ label ] i,1 ]And [ label i,2 ]. In this way, MPC is not present in a computing system 1 And MPC 2 In case of cross-talk between, the system MPC is calculated 1 And MPC 2 All can not get from [ P ] i,1 ]Or [ P i,2 ]Reconstruction of P i Or from [ label i,1 ]Or [ label i,2 ]Reconstructed label i 。
Application 112For user profile P i Fraction of (A) [ P ] i,1 ]Or [ P i,2 ]And/or each label i Fraction of (1) [ label i,1 ]Or [ label i,2 ]Encryption is performed (206). In some implementations, the application 112 generates a user profile P i First fraction [ P ] of i,1 ]And a label i First fraction of [ label ] i,1 ]And using a computing system MPC 1 The composite message is encrypted with the encryption key of (1). Similarly, application 112 generates user profile P i Second fraction [ P ] i,2 ]And a label i Second fraction of [ label ] i,2 ]And using a computing system MPC 2 The composite message is encrypted with the encryption key of (1). These functions can be expressed as PubKeyEncrypt ([ P ]) i,1 ]||[label i,1 ],MPC 1 ) And PubKeyEncrypt ([ P ] i,2 ]||[label i,2 ],MPC 2 ) Wherein PubKeyEncrypt indicates the use of MPC 1 Or MPC 2 A public key encryption algorithm corresponding to the public key. The symbol "|" represents a reversible method of composing a complex message from a plurality of simple messages, such as JavaScript object notation (JSON), compact binary object notation (CBOR), or a protocol buffer.
The content platform 150 can receive shares of the user profile and shares of the tags from a plurality of client devices. Content platform 150 can upload shares of a user profile to computing system MPC 1 And MPC 2 To initiate training of the machine learning model. Although the tags may not be used in the training process, content platform 150 can upload the share of tags to computing system MPC 1 And MPC 2 For use in optimizing the training process (e.g., hyper-parametric tuning), evaluating the quality of the model, or later querying the model.
The content platform 150 encrypts the first encrypted share (e.g., pubKeyEncrypt ([ P ]) received from each client device 110 i,1 ]||[label i,1 ],MPC 1 ) Upload to computing System MPC 1 (210). Similarly, the content platform 150 encrypts a second encrypted share (e.g., pubKeyEncrypt ([ P ]) i,2 ]||[label i,2 ],MPC 2 ) Upload to computing System MPC 2 (212). The two uploads can be in batch and can include encrypted shares of the user profile and the label received during a particular time period for training the machine learning model.
In some implementations, content platform 150 uploads the first encrypted share to computing system MPC 1 Must be in order with content platform 150 to upload the second encrypted share to computing system MPC 2 Match in order. This enables a computing system MPC 1 And MPC 2 Can be appropriately matched with two shares of the same secret (e.g., two shares of the same user profile).
In some implementations, the content platform 150 can explicitly assign the same pseudo-randomly or sequentially generated identifiers to shares of the same secret to facilitate matching. While some MPC techniques can rely on random shuffling of inputs or intermediate results, MPC techniques described in this document may not include such random shuffling and may instead rely on an upload order for matching.
In some implementations, operations 208, 210, and 212 can be performed by application 112 directly coupling [ P ] therein i,1 ]||[label i,1 ]Upload to MPC 1 And will [ P i,2 ]||[label i,2 ]Upload to MPC 2 Alternative processes of (3) replacement. This alternative process can reduce the infrastructure cost of the content platform 150 to support the operations 208, 210, and 212 and reduce the start-up in MPC 1 And MPC 2 The time delay of the machine learning model is trained or updated.
Computing system MPC 1 And MPC 2 A machine learning model is generated (214). Each time a new machine learning model is generated based on user profile data can be referred to as a training session. Computing system MPC 1 And MPC 2 The machine learning model can be trained based on the encrypted shares of the user profile received from the client device 110. For example, a computing system MPC 1 And MPC 2 MPC techniques can be used to train the k-NN model based on the share of the user profile.
In order to minimize or at least reduce cryptographic computations, and thus placement in a computing system MPC 1 And MPC 2 To protect user privacy and data during both model training and inference, the MPC cluster 130 can use stochastic projection techniques, such as SimHash, to quickly, securely, and probabilistically quantify the two user profiles P i And P j The similarity between them. By determining the representation of two user profiles P i And P j Determining two user profiles P by the Hamming distance between two bit vectors of the result of the SimHash i And P j The similarity between them. This hamming distance is inversely proportional, with high probability, to the cosine distance between the two user profiles.
Conceptually, for each training session, m randomly projected hyperplanes U = { U } can be generated 1 ,U 2 ,…,U m }. The random projection hyperplane can also be referred to as a random projection plane. Computing system MPC 1 And MPC 2 One goal of multi-step computation in between is for each user profile P used in the training of the k-NN model i Creating a bit vector B of length m i . Bit vector B here i In each bit B i,j One U representing the projection plane j And a user profile P i I.e. for all j e 1,m]Say B i，j ＝sign(U j ⊙P i ) Wherein, a indicates the dot product of two vectors of equal length. That is, each bit represents a user profile P i Located in plane U j Which side of the frame. A bit value of one represents a positive sign and a bit value of zero represents a negative sign. In some implementations, to protect user privacy, the above SimHash algorithm can be performed on an encrypted (e.g., in the form of secret shares) user profile and/or projected hyperplane, such that the MPC 1 And MPC 2 Neither the user profile nor the projection matrix can be accessed in the clear.
In some implementations, the MPC is adapted to perform a random projection based on the MPC's spatial information 1 And MPC 2 The average of all user profiles in the training dataset (which is also referred to as mean), mean P, is cooperatively calculated. For privacy protection, the calculation of mean _ P can be in secret shares. MPC 1 And MPC 2 And then from each user profile P i Subtract mean _ P and then project the result randomly, i.e., P i Mean _ P. The subtraction step can be referred to as "zero mean". For privacy protection, the zero-mean step can also be performed in secret shares. If zero mean is applied during training, MPC 1 And MPC 2 Zero mean will also be applied at the prediction time, i.e. for the user profile P, MPC in the request to be predicted 1 And MPC 2 P-mean _ P will be computed, i.e. the same mean _ P computed during training, and then random projections will be applied to P-mean _ P (using the same random projection matrix in the secret shares chosen during training).
At the end of each multi-step calculation, two calculation systems MPC 1 And each of the MPCs generates an intermediate result that includes the bit vector of each user profile, the share of each user profile, and the share of the label for each user profile in clear text. For example, a computing system MPC 1 The intermediate results of (a) can be the data shown in table 1 below. Computing system MPC 2 There will be similar intermediate results but the share per user profile and per label will be different. To add additional privacy protection, each of the two servers in the MPC cluster 130 can only get half of the m-dimensional bit vector in the clear, e.g., computing system MPC 1 Obtaining the first m/2 dimension of all m-dimensional bit vectors, and calculating the MPC of the system 2 The second m/2 dimension of all m-dimensional bit vectors is obtained. Plaintext is text that is either computationally infested, specially formatted, or written in code or data (including binary files) in a form that can be viewed or used without the need for keys or other decryption devices or other decryption processes.
Bit vector of plaintext | For P i MPC of 1 Portion(s) of | For label i MPC of 1 Portion(s) of |
… | … | … |
B i | … | … |
B i+1 | … | … |
… | … | … |
TABLE 1
Two arbitrary user profile vectors P of given unit length i ≠ j i And P j Two user profile vectors P have been shown i And P j Bit vector B of i And B j Hamming distance between with high probability and user profile vector P i And P j The cosine distance between them is proportional, assuming that the random number of projections m is sufficiently large.
Based on the intermediate results shown above and the results thereof As a bit vector B i Is in the clear, so each computing system MPC 1 And MPC 2 The corresponding k-NN models using the k-NN algorithm can be created independently, e.g., by training. Computing system MPC 1 And MPC 2 The same or different k-NN algorithms can be used. An example process for training the k-NN model is illustrated in FIG. 4 and described below. Once the k-NN model is trained, the application 112 can query the k-NN model to determine whether to add the user to the user group.
The application 112 submits an inference request to the MPC cluster 130 (216). In this example, application 112 communicates an inference request to computing system MPC 1 . In other examples, application 112 can communicate an inference request to computing system MPC 2 . The application 112 can submit the inference request in response to a request from the content platform 150 to submit the inference request. For example, the content platform 150 can request that the application 112 query the k-NN model to determine whether the user of the client device 110 should be added to a particular user group, e.g., to a demographic-based user group. This request can be referred to as an inference request that infers whether the user should be added to the user group.
To initiate an inference request, content platform 150 can send an inference request token M to application 112 infer . Inference request token M infer Enabling servers in the MPC cluster 130 to verify that the application 112 is authorized to query for a particular machine-learning model owned by a particular domain. If the model access control is optional, then the request token M is inferred infer Is optional. Inference request token M infer Can have the following items shown and described in table 2 below.
TABLE 2
In this example, the inference request token M infer Including seven items and a digital signature generated based on the seven items using a private key of the content platform 150. Tld + 1 is the valid top level field (tld) plus one level more than the common suffix. Example eTLD +1 is "examCom ", where". Com "is the top level domain.
To request inferences for a particular user, content platform 150 can generate an inference request token M infer And sends the token to the application 112 running on the user's client device 110. In some implementations, the content platform 150 uses the public key pair inference request token M of the application 112 infer Encryption is performed such that only the application 112 can use its secret private key corresponding to the public key to authenticate the inference request token M infer And performing decryption. That is, the content platform is able to send PubKeyEnc (M) to the application 112 infer ,application_public_key)。
Conceptually, the inference request can include a model identifier of the machine learning model, the current user profile P i K (number of nearest neighbors to be fetched), optionally additional signals (e.g., context signals or digital component signals), aggregation functions, and aggregation function parameters. However, to prevent the user profile P from being changed i Divulgence to computing system MPC in clear text form 1 Or MPC 2 To protect user privacy, application 112 can profile the user P i Splitting into separate pairs for MPC 1 And MPC 2 Two shares of [ P ] i,1 ]And [ P i,2 ]. Application 112 can then select, e.g., randomly or pseudo-randomly, two computing systems MPCs 1 Or MPC 2 One to query. If application 112 selects computing system MPC 1 Then the application 112 can read the toolHaving a first fraction [ P i,1 ]And an encrypted version of the second share (e.g., pubKeyEncrypt ([ P ]) i,2 ],MPC 2 ) MPC of a computing system 1 A single request is sent. In this example, application 112 uses a computing system MPC 2 To the second share P i,2 ]Encryption to prevent computing system MPC 1 Access [ P ] i,2 ]This will enable the computing system MPC 1 Can be selected from [ P ] i,1 ]And [ P i,2 ]Reconstructing a user profile P i 。
As described in more detail below, a computing system MPC 1 And MPC 2 Collaboratively computing to a user profile P i K nearest neighbors. Computing system MPC 1 And MPC 2 One of several possible machine learning techniques (e.g., binary classification, multi-class classification, regression, etc.) can then be used to determine whether to add the user to the user group based on the k nearest neighbor user profiles. For example, the aggregation function can identify machine learning techniques (e.g., binary, multi-class, regression) and the aggregation function parameters can be based on the aggregation function.
In some implementations, the aggregation function parameters can include a user group identifier for the user group for which the content platform 150 is querying the k-NN model for the user. For example, the content platform 150 may want to know whether to add a user to a group of users that are related to hiking and have a user group identifier of "hiking". In this example, the aggregation function parameters can include a "hiking" user group identifier. Generally speaking, computing system MPC 1 And MPC 2 Whether to add a user to a user group can be determined based on the number of k nearest neighbors that are members of the user group, e.g., based on their labels.
The MPC cluster 130 provides the inference result to the application 112 (218). In this example, the computing system MPC that received the query 1 The inference results are sent to application 112. The inference result can indicate whether the application 112 should add the user to zero or more user groups. For example, the user group result can specify a user group identifier for the user group. However, in this example, computing system MPC 1 The user group will be known. To prevent fromIn this regard, a computing system MPC 1 The share of the inference result can be calculated and the system MPC calculated 2 Another share of the same inference result may be computed. Computing system MPC 2 Enabling a computing system MPC 1 An encrypted version of its shares is provided, where the shares are encrypted using the public key of the application 112. Computing system MPC 1 Computing system MPC capable of providing shares of its inferred results and user group results to applications 112 2 An encrypted version of the share of (a). Application 112 can be directed to computing system MPC 2 Decrypts and computes the inference result from the two shares. An example process for querying the k-NN model to determine whether to add a user to a user group is illustrated in FIG. 5 and described below. In some implementations, to prevent computing system MPC 1 Counterfeit computing system MPC 2 Computing the system MPC 2 The results of the application 112 are digitally signed before or after being encrypted using its public key. Application 112 uses MPC 2 To verify a computing system MPC 2 The digital signature of (1).
The content platform 150 delivers the content to the application 112 (224). For example, the content platform 150 can select a digital component based on the user group identifier and provide the digital component to the application 112. In some implementations, the content platform 150 cooperates with the application 112 to select the digital component based on the user group identifier without revealing the user group identifier from the application 112.
The application 112 displays or otherwise implements the received content (226). For example, the application 112 can display the received digital component in a digital component slot of the electronic resource.
Example Process for generating a user Profile
Fig. 3 is a flow diagram illustrating an example process 300 for generating a user profile and sending shares of the user profile to an MPC cluster. The operations of process 300 can be implemented, for example, by client device 110 of fig. 1, for example, by application 112 running on client device 110. The operations of process 300 can also be implemented as instructions stored on one or more computer-readable media, which can be non-transitory, and execution of the instructions by one or more data processing apparatus can cause the one or more data processing apparatus to perform the operations of process 300.
An application 112 executing on a user's client device 110 receives data for an event (302). An event may be, for example, a presentation of an electronic resource at client device 110, a presentation of a digital component at client device 110, a user interaction with an electronic resource or digital component at client device 110, or a translation for a digital component, or a user interaction with or lack of a translation for a presented electronic resource or digital component. When an event occurs, the content platform 150, publisher 140, or digital component provider 160 can provide data related to the event to the application 112 for use in generating a user profile for the user.
The application 112 can generate a different user profile for each content platform 150. That is, the user profile of the user and for a particular content platform 150 may only include event data received from the particular content platform 150. This protects user privacy by not sharing data related to events of other content platforms with the content platform. In some implementations, the application 112 can generate a different user profile for each machine learning model owned by the content platform 150 as requested by the content platform 150. Different machine learning models may require different training data based on design goals. For example, the first model may be used to determine whether to add a user to a group of users. The second model may be used to predict whether the user will interact with the digital component. In this example, the user profile for the second model can include additional data that the user profile for the first model does not have, e.g., whether the user interacted with the digital component.
TABLE 3
The model identifiers identify machine learning models, e.g., k-NN models, for which the user profile is to be used for training or for user group inferences. A profile record is an n-dimensional feature vector that includes event-specific data, such as the type of event, electronic resources or digital components, the time at which the event occurred, and/or other suitable event data that the content platform 150 wants to use in training the machine learning model and making user group inferences. The digital signature is generated based on seven items using the private key of the content platform 150.
In some implementations, to protect the update token M during transmission update The content platform 150 is updating the token M update Update token M before sending to application 112 update Encryption is performed. For example, the content platform 150 can use the public key of the application toFor update token M update Encryption is performed, e.g. PubKeyEnc (M) update ,application_public_key)。
In some implementations, the content platform 150 can update the token M with the event data in a profile update Is sent to the application 112 without encoding the event data or the update request. For example, scripts originating from the content platform 150 running inside the application 112 may communicate event data and update requests directly to the application 112 via a script API, where the application 112 relies on a security model based on world wide web consortium (W3C) sources and/or (secure hypertext transfer protocol) HTTPS to protect the event data and update requests from forgery or leakage.
For each machine learning model, for example, for each unique model identifier, the application 112 can store event data for that model. For example, the application 112 can maintain a data structure including a set of n-dimensional feature vectors (e.g., profile records of update tokens) for each unique model identifier and an expiration time for each feature vector. An example data structure for the model identifier is shown in table 4 below.
Feature vector | Expiration date |
n-dimensional feature vector | Expiration time |
… | … |
TABLE 4
Upon receipt of a valid update token M update Thereafter, the application 112 can update the token M by update Is added to the data structure to update the update token M included in the update token update The data structure of the model identifier in (1). Periodically, the application 112 can clear outdated feature vectors from the data structure to reduce storage size.
Upload token M upload Can have and update token M update Similar structure, but with different operations (e.g., "update server" instead of "accumulate user profile"). On the upper part Pass token M upload Additional terms for operation delay can also be included. The operational delay can instruct the application 112 to delay computing and uploading shares of the user profile while the application 112 accumulates more event data, e.g., more feature vectors. This enables the machine learning model to capture user event data immediately before and after some critical events (e.g., joining a user group). The operational delay can specify a delay period. In this example, the digital signature can be generated based on the other seven items in table 3 and the operational delays using the private key of the content platform. The content platform 150 can use the application's public key to update the token M update Similar manner for uploading token M upload Encryption is performed, e.g. PubKeyEnc (M) upload Application _ public _ key) to protect the upload token M during transmission upload 。
In some implementations, the content platform 150 can request the application 112 to upload the token M with the profile upload Without encoding the upload request. For example, scripts originating from the content platform 150 running inside the application 112 may communicate the upload request directly to the application 112 via a script API, where the application 112 relies on a W3C source based security model and/or HTTPS to protect the upload request from forgery or leakage.
If a determination is made not to generate a user profile, the process 300 can return to operation 302 and wait for additional event data from the content platform 150. If a determination is made to generate a user profile, the application 112 generates a user profile (308).
The application 112 can generate a user profile based on the stored event data (e.g., data stored in the data structure shown in table 4). Application 112 can be based on a model identifier included in the request (e.g., upload token M) upload The content platform, tld +1, field of item 1 and the model identifier of item 2) to access the appropriate data structure.
The application 112 can compute the user profile by aggregating n-dimensional feature vectors in the data structure in learning periods that have not expired. For example, the user profile may be an average of n-dimensional feature vectors in a data structure in a learning period that has not expired. The result is an n-dimensional feature vector representing the user in profile space. Alternatively, the application 112 may normalize the n-dimensional feature vector to a unit length, for example, using L2 normalization. The content platform 150 may specify an optional learning period.
In some implementations, the decay rate can be used to calculate a user profile. Since there may be many content platforms 150 that use MPC cluster 130 to train machine learning models and each content platform 150 may have multiple machine learning models, storing user feature vector data may create significant data storage requirements. Using decay techniques can substantially reduce the amount of data stored at each client device 110 for the purpose of generating user profiles for training machine learning models.
Assume that for a given machine learning model, there are k feature vectors { F } 1 ,F 2 ,…F k And its corresponding age (record _ age _ in _ seconds) i ) Each feature vector is an n-dimensional vector. The application 112 can calculate the user profile using the following relation 1:
in this relation, the parameter record _ age _ in _ seconds i Is a profile record F i The amount of time in seconds that has been stored at the client device 110 and the parameter decay _ rate _ in _ seconds is the decay rate of the profile record in seconds (e.g., at the update token M) update Item 6 of (1). In this way, newer eigenvectors carry larger weights. This also enables the application 112 to avoid storing feature vectors and only store profile records with constant storage. Instead of storing multiple individual feature vectors for each model identifier, the application 112 only has to store an n-dimensional vector P and a timestamp user profile time for each model identifier.
To initialize the n-dimensional vector user profile P and timestamps, the application can set the vector P to a vector of n dimensions, with each dimension having a value of zero, and set user _ profile _ time to an epoch. To use a new feature vector F at any time x Updating user profile P, application 112 can use the following relation 2:
when updating the user profile using relation 2, the application 112 is also able to update the user profile time to the current time. Note that if the application 112 calculates the user profile using the above decay rate algorithm, operations 304 and 308 are omitted.
The application 112 generates shares of the user profile (310). The application 112 can use a pseudo-random function to profile the user P i (e.g., n-dimensional vector P) is split into shares. That is, application 112 can use a pseudo-random function PRF (P) i ) Generating a user profile P i Two shares of { [ Pi, 1 ],[P i,2 ]}. The exact split can depend on the secret sharing algorithm and the cryptographic library used by the application 112. In some implementations, the application uses a Shamir secret sharing scheme. In some implementations, the application uses an additive secret sharing scheme. If a share of one or more tags is being provided,the application 112 can also generate shares of the label as well.
Example Process for generating and Using machine learning models
FIG. 4 is a flow diagram illustrating an example process 400 for generating a machine learning model. The operations of the process 400 can be implemented, for example, by the MPC cluster 130 of fig. 1. The operations of process 400 can also be implemented as instructions stored on one or more computer-readable media, which may be non-transitory, and execution of the instructions by one or more data processing apparatus can cause the one or more data processing apparatus to perform the operations of process 400.
The MPC cluster 130 obtains a share of the user profile (402). The content platform 150 can request the MPC cluster 130 to train the machine learning model by communicating the share of the user profile to the MPC cluster 130. The content platform 150 can access encrypted shares received for the machine learning model from the client devices 110 over a given period of time and upload those shares to the MPC cluster 130.
For example, content platform 150 can send a MPC to a computing system 1 Communicating the encrypted first shares of the user profile and the encrypted first shares of its label (e.g., for each user profile P) i PubKeyEncrypt ([ P ]) i,1 ]||[label i,1 ],MPC 1 )). Tags as described herein and other procedures in this disclosure The graph can be or include a user group identifier or demographic. Similarly, content platform 150 can send a MPC to a computing system 2 Communicating the encrypted second shares of the user profile and the encrypted second shares of its label (e.g., for each user profile P) i PubKeyEncrypt ([ P ]) i,2 ]||[label i,2 ],MPC 2 ))。
In some implementations where the application 112 sends the secret share of the user profile directly to the MPC cluster 130, the content platform 150 can request the MPC cluster 130 to train the machine learning model by transmitting a training request to the MPC cluster 130.
Computing system MPC 1 And MPC 2 A random projection plane is created (404). Computing system MPC 1 And MPC 2 M random projection planes U = { U } can be created cooperatively 1 ,U 2 ,…,U m }. These random projection planes should be kept as two computing systems MPC 1 And MPC 2 Secret shares between. In some implementations, a computing system MPC 1 And MPC 2 A Diffie-Hellman key exchange technique is used to create a random projection plane and maintain its privacy.
As described in more detail below, a computing system MPC 1 And MPC 2 Projecting their share of each user profile onto each random projection plane and determining for each random projection plane whether the share of the user profile is on one side of the random projection plane. MPC for each computing system 1 And MPC 2 A bit vector in the secret shares can then be constructed from the secret shares of the user profile based on the results of each random projection. Partial knowledge of the bit vector by the user, e.g. user profile P i Whether or not on the projection plane U k On one side of (1) allow computing system MPC 1 Or MPC 2 Obtain information about P i Is some knowledge of the distribution of (A), this is for the user profile P i With an increase in a priori knowledge of unit length. To prevent computing system MPC 1 And MPC 2 Obtaining access to this information (e.g., in implementations where this is a need or preference for user privacy and/or data security), at oneIn some implementations, the random projection planes are in secret shares, so the computing system MPC is calculated 1 And MPC 2 None of the random projection planes can be accessed in the clear. In other implementations, a secret sharing algorithm can be used to apply a random bit flipping pattern on the random projection results, as described in optional operations 406-408.
To demonstrate how the bits are flipped via secret shares, assume that there are two secrets x and y whose values are zero or one with equal probability. Equality operation x]＝＝[y]The bit of x will be flipped if y = =0 and will be retained if y = = 1. In this example, the operation will randomly flip bit x with 50% probability. This operation can require two computing systems MPC 1 And MPC 2 Remote Procedure Calls (RPCs) in between, and the number of rounds depends on the selected data size and the secret sharing algorithm.
MPC for each computing system 1 And MPC 2 A secret m-dimensional vector is created (406). Computing system MPC 1 Capable of creating a secret m-dimensional vector S 1 ,S 2 ,…S m In which each element S i With equal probability having a value of zero or one. Computing system MPC 1 Splitting its m-dimensional vector into two shares, namely the first share { [ S ] 1,1 ],[S 2,1 ],…[S m,1 ]And a second share { [ S ] 1,2 ],[S 2,2 ],…[S m,2 ]}. Computing system MPC 1 Capable of keeping a first share secret and providing a second share to a computing system MPC 2 . Computing system MPC 1 The m-dimensional vector S can then be discarded 1 ,S 2 ,…S m }。
Computing system MPC 2 Capable of creating a secret m-dimensional vector T 1 ,T 2 ,…T m In which each element T i Have a value of zero or one. Computing system MPC 2 Splitting its m-dimensional vector into two shares, namely a first share { [ T { [ 1,1 ],[T 2,1 ],…[T m,1 ]A } and a second share { [ T { [ 1,2 ],[T 2,2 ],…[T m,2 ]}. Computing system MPC 2 Can keep the first share secret andand providing the second share to the computing system MPC 1 . Computing system MPC 2 The m-dimensional vector T can then be discarded 1 ,T 2 ,…T m }。
Two computing systems MPC 1 And MPC 2 A share of the bit flipping pattern is calculated using a secure MPC technique (408). Computing system MPC 1 And MPC 2 Can be used in a computing system MPC 1 And MPC 2 Secret-share MPC equality tests with multiple round trips in between to compute the shares of the bit-flipping pattern. The bit flipping pattern can be based on the above operation [ x ] ]＝＝[y]. That is, the bit flipping pattern can be S 1 ＝＝T 1 ,S 2 ＝＝T 2 ,…S m ＝＝T m }. Let each ST i ＝(S i ＝＝T i ). Each ST i Having a value of zero or one. After MPC operation is complete, computing system MPC 1 First share with bit flipping pattern { [ ST { [ 1,1 ],[ST 2,1 ],…[ST m,1 ]And computing the system MPC 2 Second share with bit flipping pattern { [ ST { [ 1,2 ],[ST 2,2 ],…[ST m,2 ]}. Each ST i Is such that two computing systems MPC 1 And MPC 2 Can be applied to two computing systems MPC 1 And MPC 2 The bits in the bit vector are flipped in such a way that any of them is opaque.
Each computing system MPC 1 And MPC 2 Its share of each user profile is projected onto each random projection plane (410). That is, for a computing system MPC 1 Receiving each user profile of the share, computing the system MPC 1 Can reduce the share [ P ] i,1 ]Projected onto each projection plane U j The above. For each share of the user profile and for each random projection plane U j Performing this operation produces a matrix R in the z x m dimension, where z is the number of available user profiles and m is the number of random projection planes. Capable of calculating the projection plane U j And fraction [ P i,1 ]To determine each element R in the matrix R i,j The amount of the solvent to be used is, for example,R i,j ＝U j ⊙[P i，1 ]. The operation |, indicates the dot product of two vectors of equal length.
Computing system MPC if bit flipping is used 1 Can be used in a computing system MPC 1 And MPC 2 Bit flipping patterns that are shared in secret between to modify one or more elements R in the matrix i,j The value of (c). For each element R in the matrix R i,j Computing system MPC 1 Can calculate [ ST j,1 ]＝＝sign(R i,j ) As the element R i,j The value of (c). Thus, the element R i,j Will be in its bit in the bit flip pattern ST j,1 ]Is flipped if the corresponding bit in (b) has a value of zero. This calculation can require a MPC to the computing system 2 Multiple RPCs were performed.
Similarly, for a computing system MPC 2 Receiving each user profile of the share, computing the system MPC 2 Can reduce the share [ P ] i,2 ]Projected onto each projection plane U j The above. For each share of the user profile and for each random projection plane U j Performing this operation yields a matrix R' in the z x m dimension, where z is the number of available user profiles and m is the number of random projection planes. Capable of calculating the projection plane U j And fraction [ P ] i,2 ]To determine each element R in the matrix R i,j ', e.g. R i, ’ j ＝U j ⊙[P i，2 ]. The operation |, indicates the dot product of two vectors of equal length.
If bit flipping is used, the computing system MPC 2 Can be used in a computing system MPC 1 And MPC 2 Bit flipping patterns secretly shared between to modify one or more elements R in the matrix i,j A value of. For each element R in the matrix R i,j ', computing system MPC 2 Can calculate [ ST j,2 ]＝＝sign(R i,j ') as element R i,j The value of. Thus, the element R i,j The sign of' will be at its bit ST in the bit flip pattern j Has a value of zeroThe lower is turned over. This calculation can require a MPC to the computing system 1 Multiple RPCs were performed.
Computing system MPC 1 And MPC 2 The bit vector is reconstructed (412). Computing system MPC 1 And MPC 2 The bit vectors can be reconstructed for the user profile based on matrices R and R' having exactly the same size. For example, a computing system MPC 1 Can send a portion of the columns of matrix R to the MPC 2 And computing system MPC 2 The remainder of the columns of matrix R' can be sent to the MPC 1 . In a particular example, a computing system MPC 1 The first half of the columns of matrix R can be sent to the computing system MPC 2 And computing system MPC 2 The second half of the columns of matrix R' can be sent to the MPC 1 . Although columns are used for horizontal reconstruction in this example and are preferred to protect user privacy, rows can be used for vertical reconstruction in other examples.
In this example, a computing system MPC 2 The first half of the columns of matrix R' can be coupled to slave computing system MPC 1 The first half of the columns of the received matrix R combine to reconstruct the first half of the bit vector in plaintext (i.e., m/2 dimensions). Similarly, computing system MPC 1 The second half of the columns of the matrix R can be coupled to the slave computing system MPC 2 The second half of the columns of the received matrix R' combine to reconstruct the second half of the bit vector (i.e., m/2 dimensions) in plaintext. Conceptually, computing system MPC 1 And MPC 2 The corresponding shares in the two matrices R and R' have now been combined to reconstruct the bit matrix B in plain text. This bit matrix B will include the bit vectors of the projection results (onto each projection plane) for each user profile whose share is received by the machine learning model from the content platform 150. Each of the two servers in the MPC cluster 130 has half of the bit matrix B in plaintext.
However, if bit flipping is used, the system MPC is calculated 1 And MPC 2 The bits of the elements in matrices R and R' have been flipped in a random pattern fixed for the machine learning model. This random bit flipping pattern is applied to two computing systems MPC 1 And MPC 2 Is opaque, such that the computing system MPC 1 And MPC 2 Neither is able to infer the original user profile from the bit vectors of the projected results. Cryptographic design further prevents MPC 1 Or MPC 2 Inferring the original user profile by splitting the bit vector horizontally, i.e. computing system MPC 1 The second half of the bit vector of the projection result is kept in plaintext and the system MPC is calculated 2 The first half of the bit vector of the projection result is kept in plaintext.
Computing system MPC 1 And MPC 2 A machine learning model is generated (414). Computing system MPC 1 The second half of the bit vector can be used to generate the k-NN model. Similarly, computing system MPC 2 The first half of the bit vector can be used to generate the k-NN model. The generation of a model using bit flipping and horizontal segmentation of a matrix applies the principles of depth defense to protect the privacy of the user profile used to generate the model.
In general, each k-NN model represents a cosine similarity (or distance) between user profiles of a group of users. By a computing system MPC 1 The generated k-NN model represents the similarity between the second half of the bit vector, and is used by the computing system MPC 2 The generated k-NN model represents the similarity between the first half of the bit vector. For example, each k-NN model can define a cosine similarity between half of its bit vector.
Can be MPCd by a computing system 1 And MPC 2 The two generated k-NN models are referred to as k-NN models, which have unique model identifiers as described above. Computing system MPC 1 And MPC 2 Their models can be stored, as well as the share of tags for each user profile used to generate the models. The content platform 150 can then query the model to infer groups of users for the user. In some implementations, to protect user privacy, the tags are encrypted, e.g., in the form of secret shares.
Example Process for inferring user groups Using machine learning models
FIG. 5 is a flow diagram illustrating an example process 500 for adding a user to a user group using a machine learning model. The operations of process 500 can be implemented, for example, by MPC cluster 130 and client device 110 of fig. 1 (e.g., application 112 running on client device 110). The operations of process 500 can also be implemented as instructions stored on one or more computer-readable media, which may be non-transitory, and execution of the instructions by one or more data processing apparatus can cause the one or more data processing apparatus to perform the operations of process 500.
The MPC cluster 130 receives an inference request for a given user profile (502). An application 112 running on a user's client device 110 can communicate an inference request to MPC cluster 130, for example, in response to a request from content platform 150. For example, the content platform 150 can communicate an inference request token M to the application 112 infer To request that the application 112 submit an inference request to the MPC cluster 130. The inference request can be a query as to whether the user should be added to any number of groups of users.
Inference request token M infer The share of a given user profile of the user, the model identifier of the machine learning model (e.g., k-NN model), and the owner domain to be used for inference, the number k of nearest neighbors of the given user profile to be used for inference, additional signals (e.g., contextual or digital component signals), the aggregation function to be used for inference and any aggregation function parameters to be used for inference, and signatures over all of the above information created by the owner domain using the owner domain secret privacy key can be included.
As described above, to prevent the given user profile P from being transferred i Divulging to computing system MPC in clear text form 1 Or MPC 2 To protect user privacy, the application 112 can assign a given user profile P i Splitting into separate pairs for MPC 1 And MPC 2 Two shares of [ P ] i,1 ]And [ P i,2 ]. The application 112 can then share P with the first share of the given user profile i,1 ]And an encrypted version of a second share of the given user profile (e.g., pubKeyEncrypt ([ P) i,2 ],MPC 2 ) To a computing system MPC together 1 A single inference request is sent. Inference requests may also be made Including inferring request token M infer Enabling the MPC cluster 130 to authenticate the inference request. By sending an inference request comprising the first share and the encrypted second share, the number of outgoing requests sent by the application 112 is reduced, resulting in computation, bandwidth, and battery savings at the client device 110.
In other implementations, the application 112 can share the first share [ P ] of a given user profile i,1 ]Sending to a computing System MPC 1 And a second share of the given user profile P i,2 ]Sending to a computing System MPC 2 . By not passing through the MPC computing system 1 Will give the second share of the user profile P i,2 ]Send to computing system MPC 2 The second share does not need to be encrypted to prevent the computing system MPC from being encrypted 1 Accessing a second share of a given user profile P i,2 ]。
Each computing system MPC 1 And MPC 2 The k nearest neighbors of a given user profile are identified in the secret share representation (504). Computing system MPC 1 Can use a first share P of a given user profile i,1 ]To calculate half of the bit vector for a given user profile. To generate bit vectors, a system MPC is computed 1 Operations 410 and 412 of the process 400 of fig. 4 can be used. That is, computing system MPC 1 The shares [ P ] of a given user profile can be projected using random projection vectors generated for the k-NN model i,1 ]And creates a secret share of the bit vector for a given user profile. Computing System MPC if bit flipping is used to generate k-NN model 1 The first share of the bit flipping pattern used to generate the k-NN model can then be used { [ ST ] 1,1 ],[ST 2,1 ],…[ST m,1 ]The secret share of the bit vector for a given user profile.
Similarly, computing system MPC 1 Capable of providing MPC to a computing system 2 Providing an encrypted second share of PubKeyEncrypt ([ P ] P) of a given user profile i,2 ],MPC 2 ). Computing system MPC 2 Second share P for a given user profile can be used with its private key i,2 ]Decrypt and use a second share of a given user profile P i,2 ]To calculate half of the bit vector for a given user profile. That is, computing system MPC 2 The shares [ P ] of a given user profile can be projected using random projection vectors generated for the k-NN model i,2 ]And creates a bit vector for a given user profile. Computing System MPC if bit flipping is used to generate a k-NN model 2 Then a second share of the bit flipping pattern used to generate the k-NN model can be used { [ ST ] 1,2 ],[ST 2,2 ],…[ST m,2 ]The elements of the bit vector for a given user profile. Computing system MPC 1 And MPC 2 The bit vector is then reconstructed using horizontal partitioning, as described in operation 412 in fig. 4. After reconstruction is complete, the system MPC is calculated 1 Computing a system MPC with a first half of an overall bit vector for a given user profile 2 With the second half of the overall bit vector for a given user profile.
Each computing system MPC 1 And MPC 2 Identifying k 'nearest neighbor user profiles using one half of a bit vector for a given user profile and a k-NN model thereof, wherein k' = a × k, wherein a is empirically determined based on actual production data and statistical analysis. For example a =3 or another suitable number. Computing system MPC 1 The hamming distance between the first half of the overall bit vector and the bit vector for each user profile of the k-NN model can be calculated. Computing system MPC 1 K 'nearest neighbors, e.g., k' user profiles with the lowest hamming distances, are then identified based on the calculated hamming distances. In other words, computing system MPC 1 A set of nearest neighbor user profiles is identified based on the shares of a given user profile and a k-nearest neighbor model trained using a plurality of user profiles. Table format example results are shown in table 5 below.
Line ID | Hamming distance (Ming dynasty) | User profile share | Share of label |
i | d i,1 | [P i,1 ] | [label i,1 ] |
… | … | … | … |
TABLE 5
In table 5, each row is for a particular nearest neighbor user profile and includes a first half of a bit vector for each user profile and for each user profile MPC 1 The hamming distance between the bit vectors of a given user profile is calculated. The row for a particular nearest neighbor user profile also includes a first share of the user profile and a first share of a label associated with the user profile. As described herein, a tag can be or include a user group identifier or demographic.
Similarly, computing system MPC 2 The hamming distance between the second half of the overall bit vector and the bit vector for each user profile of the k-NN model can be calculated. Computing system MPC 2 K 'nearest neighbors, e.g., k' user profiles with the lowest hamming distances, are then identified based on the calculated hamming distances. Table-format example results are shown in table 5 below.
Line ID | Hamming distance (Ming dynasty) | User profile share | Share of label |
j | d j,2 | [P j,2 ] | [label j,2 ] |
… | … | … | … |
TABLE 6
In table 6, each row is for a particular nearest neighbor user profile and includes that user profile with the MPC of the computing system 2 A hamming distance between the given user profiles calculated. The row for a particular nearest neighbor user profile also includes a second share of the user profile and a second share of a label associated with the user profile.
Computing system MPC 1 And MPC 2 A list of row identifiers (row IDs) and hamming distance pairs can be exchanged with each other. Thereafter, each computing system MPC 1 And MPC 2 The k nearest neighbors can be selected independently with the same algorithm and input data. For example, a computing system MPC 1 Can find a pair from a computing system MPC 1 And MPC 2 A row identifier common to both partial query results. For each i in the common row identifier, computing system MPC 1 Computing a combined Hamming distance d from two partial Hamming distances i E.g. d i ＝d i,1 +d i,2 . Computing system MPC 1 Then the Hamming distance d based on the combination can be determined i To sort the common row identifiers and select the k nearest neighbors. The line identifiers for the k nearest neighbors can be represented as ID = { ID = { [ d ] 1 ,…id k }. It can be demonstrated that the k nearest neighbors determined in the above algorithm are true k nearest neighbors with high probability if a is large enough. However, a large value of a results in high calculation cost. In some implementations, MPC 1 And MPC 2 Participating in a Private Set Intersection (PSI) algorithm to determine a private set from a computer system MPC 1 And MPC 2 A row identifier common to both partial query results. Furthermore, in some implementations, MPC 1 And MPC 2 Participating in an enhanced Private Set Intersection (PSI) algorithm to support traffic from a computer system MPC 1 And MPC 2 Calculation of line identifier d common to both partial query results i ＝d i,1 +d i,2 And not towards MPC 1 Or MPC 2 Disclosure of anything but i The first k nearest neighbors determined.
A determination is made whether to add the user to the user group (506). This determination can be made based on the k nearest neighbor profiles and their associated labels. The determination is also based on the aggregation function used and any aggregation parameters for that aggregation function. The aggregation function can be chosen based on the nature of the machine learning problem, such as binary classification, regression (e.g., using arithmetic mean or root mean square), multi-class classification, and weighted k-NN. Each way of determining whether to add a user to a user group can include different interactions between the MPC cluster 130 and the applications 112 running on the clients 110, as described in more detail below. Adding different users to a common group of users can advantageously ensure that users with similar demographics are categorized together.
If a determination is made not to add the user to the user group, the application 112 may not add the user to the user group (508). If a determination is made to add the user to the user group, the application 112 can add the user to the user group, for example, by updating a user group list stored at the client device 110 to include a user group identifier for the user group (510).
As noted above, the application 112 can submit an inference request to the MPC cluster 130, which MPC cluster 130 in response can query a machine learning model (e.g., a k-NN model) to send an inference result that can indicate whether the application 112 should add the user to zero or more user groups. In some implementations, where the inference results indicate that the application 112 should add the user to multiple user groups, the MPC cluster 130 can prevent the user from being added to (i.e., classified in) the opposite group before generating or communicating the inference results (e.g., if the user is self-declared or determined to be 30-35 years old, the user may not be classified in a user group for 50-60 years old).
Example binary class inference techniques
For binary classification, the inference request can include threshold, L true And L false As an aggregation function parameter. The tag value is of the boolean type, i.e., true or false. the threshold parameter can indicate that a user is to be added to the user group L true But must have a threshold percentage of k nearest neighbor profiles for the label of the true value. Otherwise the user will be added to the user group L false . In one approach, if the number of nearest neighbor user profiles with a tag value of true is greater than the product of threshold and k, the MPC cluster 130 can instruct the application 112 to add the user to the user group L true (otherwise L false ). However, computing system MPC 1 The inference results, e.g. the user group that the user should join, will be learned.
To protect user privacy, the inference request can include a clear text threshold, for the computing system MPC 1 First fraction of [ L ] true,1 ]And [ L false,1 ]And to a computing system MPC 2 The encrypted second share of PubKeyEncrypt (, [ 2 ]L true,2 ]||[L false,2 ]||application_public_key,MPC 2 ). In this example, application 112 can be run from [ L true,2 ]、[L fasle,2 ]And the public key of application 112, generates a composite message, as represented by the symbol | | |, and uses the computing system MPC 2 The public key of (a) to encrypt the composite message. Slave computing system MPC 1 The inferred response to the application 112 can include a calculation system MPC 1 First share [ L ] of the determined inference result result,1 ]And by a computing system MPC 2 Second share [ L ] of the determined inference result result,2 ]。
To prevent the second share from being calculated by the system MPC 1 Accessing and thus enabling a computing system MPC 1 Capable of obtaining inferences in clear text, computing system MPC 2 Capable of providing MPC to a computing system 1 Sending a second share of the inference result [ L result,2 ]E.g., pubKeySign (PubKeyEncrypt ([ L ]) in a digital signature format, e.g., a public key signature (public key signature) result,2 ],application_public_key),MPC 2 ) For inclusion in the inferred response sent to application 112. In this example, application 112 can use a computing system MPC for generating a digital signature 2 Computing system MPC corresponding to private key of 2 Verifies the digital signature using the public key of (2) and uses the second share [ L ] for the inference result result,2 ]The second share [ L ] of the inference result is applied by the private key of the application 112 corresponding to the encrypted public key (application _ public _ key) result,2 ]Decryption is performed.
The application 112 can then select from the first quota L result,1 ]And a second fraction [ L result,2 ]Reconstruction of the inference result L result . Using digital signatures to enable applications 112 to be executed, for example, by a computing system MPC 1 Detecting a signal from a computing system MPC 2 Forgery of the result of (1). Depending on the level of security desired, what parties operate the computing systems of the MPC cluster 130, and the assumed security model, a digital signature may not be required.
Computing system MPC 1 And MPC 2 The fraction [ L ] of binary classification results can be determined using MPC techniques result,1 ]And [ L result,2 ]. In binary classification, label for user profiles 1 Is zero (false) or one (true). Assume that the k nearest neighbors selected are identified by the identifier id 1 ,…id k Identification, computing system MPC 1 And MPC 2 The sum of labels (sum of labels) for the k nearest neighbor user profiles can be calculated, where the sum is represented by the following relation 3:
relation 3: sum of labels = ∑ Σ i∈{id1，...idk} label i
To determine the sum, the system MPC is calculated 1 Will ID (i.e., { ID }) 1 ，...id k }) to the computing system MPC 2 . Computing system MPC 2 It can be verified that the number of row identifiers in the ID is greater than a threshold to enforce k-anonymity. Computing system MPC 2 The sum of labels [ sum _ of _ labels ] can then be calculated using the following relation 4 2 ]Second fraction of (c):
relation 4: [ sum _ of _ labels 2 ]＝∑i∈ {id1，...iak} [label i，2 ]
Computing system MPC 1 The sum of labels [ sum _ of _ labels ] can also be calculated using the following relation 5 1 ]First share of (c):
relation 5: [ sum _ of _ labels 1 ]＝∑ i∈{id1，...idk} [label i，1 ]
If the sum of labels sum _ of _ labels is the computing system MPC 1 And MPC 2 Confidential information that should be known as little as possible, MPC 1 And MPC 2 Can perform cryptographic protocols to compute sum of labels 1 Whether < threshold x k, i.e. computing system MPC 1 The first share of the sum of labels can be calculated 1 ]Whether or not it is below a threshold, e.g., [ below _ threshold ] 1 ]＝[sum_of_labels 1 ]< threshold x k. Similarly, computing system MPC 2 The second share of the sum of labels can be calculated 2 ]Whether or not it is below a threshold, e.g., [ below _ threshold [ ] 2 ]＝[sum_of_labels 2 ]< threshold x k. Computing system MPC 1 Can continue to pass through below threshold 1 ]×[L false，1 ]+(1-[below_threshold 1 ])×[L true，1 ]To calculate an inference result [ L result，1 ]. Similarly, computing system MPC 2 Can pass through [ below _ threshold 2 ]×[L false，2 ]+(1-[below_threshold 2 ])×[L true，2 ]To calculate [ L ] result，2 ]。
If the sum of labels is not confidential information, the computing system MPC 1 And MPC 2 Can be selected from [ sum _ of _ labels 1 ]And [ sum _ of _ labels [ ] 2 ]Reconstruct sum _ of _ labels. Computing system MPC 1 And MPC 2 The parameter below _ threshold can then be set to sum _ of _ labels < threshold × k, e.g. a value of one if it is below the threshold or a value of zero if it is not below the threshold.
After calculating the parameter below _ threshold, the system MPC is calculated 1 And MPC 2 Can continue to determine the inference result L result . For example, a computing system MPC 2 Can be based on the value of below _ threshold to change [ L result,2 ]Is set to [ L true,2 ]Or [ L false,2 ]. For example, a computing system MPC 2 Can be set [ L ] if the sum of tags is not below a threshold result,2 ]Is set as [ L true,2 ]Or will [ L ] if the sum of tags is below a threshold result,2 ]Is set as [ L false,2 ]. Computing system MPC 2 An encrypted second share of the inference result (PubKeyEncrypt ([ L ") can then be inferred result,2 ]Application _ public _ key)) or a digitally signed version of the result is returned to the computing system MPC 1 。
Similarly, computing system MPC 1 Can be based on the value of below _ threshold to set [ L result,1 ]Is set as [ L true,1 ]Or [ L false,1 ]. For example, a computing system MPC 1 Can set [ L ] if the sum of tags is not less than the threshold result,1 ]Is set as [ L true,1 ]Or L if the sum of tags is below a threshold result,1 ]Is set to [ L false,1 ]. Computing system MPC 1 Can be used forWill infer a first share of the result L result,1 ]And an encrypted second share [ L ] of the inference result result,2 ]As an inference response to the application 112. The application 112 can then calculate an inference result based on the two shares as described above.
Example Multi-class Classification inference techniques
For multi-class classification, the labels associated with each user profile can be classification features. The content platform 150 can specify a lookup table that maps any possible classification value to a corresponding user group identifier. The look-up table can be one of the aggregation function parameters included in the inference request.
Within the k nearest neighbors found, the MPC cluster 130 finds the most frequent label value. The MPC cluster 130 can then find the user group identifier corresponding to the most frequent tag value in the lookup table and request the application 112 to add the user to the user group corresponding to the user group identifier, e.g., by adding the user group identifier to a user group list stored at the client device 110.
Similar to binary classification, it may be preferable to select from a computing system MPC 1 And MPC 2 Hidden inference results L result . To do so, the application 112 or the content platform 150 can create a mapping of the classification values to the inference results L, respectively result Two look-up tables of corresponding shares. For example, the application can create a mapping of the classification value to a first share [ L [ ] result1 ]And mapping the classification value to a second share L result2 ]The second lookup table of (1). MPC from application to computing system 1 Can include a request for inference of a computing system MPC 1 First look-up table of plain text for a computing system MPC 2 The encrypted version of the second lookup table. The second lookup table can use the computing system MPC 2 Is encrypted. For example, a composite message including a second lookup table and a public key of an application can use a computing system MPC 2 Encrypted with the public key of (MPC), e.g., pubKeyEncrypt (lookup table2| | application _ public _ key) 2 )。
By a computing system MPC 1 Push of sendingThe fault response can include a fault being initiated by the computing system MPC 1 First share [ L ] of the generated inference result result1 ]. Similar to binary classification, to prevent the second share from being calculated by the system MPC 1 Accessing and thus enabling a computing system MPC 1 Capable of obtaining inferences in clear text, computing system MPC 2 Enabling a computing system MPC 1 Sending a second share [ L ] of the inference result result,2 ]An encrypted (and optionally digitally signed) version of (e.g., pubKeySign ([ L ] L) result,2 ],application_public_key),MPC 2 ) For inclusion in the inference results sent to application 112. Application 112 can be selected from [ L ] result1 ]And [ L result2 ]Reconstructed inference result L result 。
Assume that there are w valid labels, { l }, for a multi-class classification problem 1 ,l 2 ,…l w }. To determine inference results L in multiple classes result Fraction of (A) [ L ] result1 ]And [ L result2 ]Computing system MPC 1 Will ID (i.e., { ID }) 1 ,…id k }) to the computing system MPC 2 . Computing system MPC 2 It can be verified that the number of row identifiers in the ID is greater than a threshold to enforce k-anonymity. In general, k in k-NN may be significantly larger than k in k-anonymity. Computing system MPC 2 Then, the jth tag [ l ] defined using the following relation 6 can be calculated j,2 ]Second frequency share of (1) j,2 ]。
similarly, computing system MPC 1 Calculate the jth tag [ l ] defined using the following relation 7 j,1 ]First frequency share of (1) j,1 ]。
assume the frequency (frequency) of tags within k nearest neighbors i ) Being insensitive, computing system MPC 1 And MPC 2 Can be derived from two shares [ frequency ] for the tag i，1 ]And [ frequency ] i，2 ]Reconstructing frequency i . Computing system MPC 1 And MPC 2 Frequency can then be determined index Index parameter (index) having maximum value, e.g., index = argmax i (frequency i )。
Computing system MPC 2 Then can look up the share corresponding to the label with the highest frequency in its look-up table result，2 ]And PubKeyEncrypt ([ L ] L) result，2 ]Application _ public _ key) back to the computing system MPC 1 . Computing system MPC 1 The share corresponding to the label with the highest frequency [ L ] can be similarly looked up in its look-up table result，1 ]. Computing system MPC 1 The include two shares (e.g., [ L ] can then be sent to the application 112 result，1 ]And PubKeyEncrypt ([ L) result，2 ]Application _ public _ key)). As described above, the second share can be determined by the MPC 2 Digital signature to prevent computing system MPC 1 Counterfeit computing system MPC 2 In response to (2). The application 112 can then calculate an inference result based on the two shares as described above, and add the user to the group of users identified by the inference result.
Example regression inference techniques
For regression, the label associated with each user profile P must be numeric. The content platform 150 can specify an ordered list of thresholds, e.g., (-infinity < t) 0 ＜t 1 ＜…＜t n < ∞) and a list of user group identifiers, e.g., { L 0 ，L 1 ，...L n ，L n+1 }. In addition, the content platform 150 can specify an aggregation function, such as an arithmetic mean or root mean square.
Within the k nearest neighbors found, the MPC cluster 130 computes the mean of the label values (result) and then uses the result to look up the mapping to find the inferred result L result . For example, the MPC cluster 130 can use the following relationshipsEquation 8 identifies the tag as a mean based on the tag values:
relation 8:
if result is less than t 0 Then L is result ←L 0 ；
If result > t n Then L is result ←L n+1 ；
If t is x ＜result≤t x+1 Then L is result ←L x+1
That is, if the result is less than or equal to the threshold t o Then conclude result L result Is L 0 . If the result is greater than the threshold t n Then conclude result L result Is L n+1 . Otherwise, if the result is greater than the threshold t x And is less than or equal to the threshold value t x+1 Then conclude the result L result Is L x+1 . Computing system MPC 1 The requesting application 112 then adds the user to the inferred result L result The corresponding group of users, e.g. by sending the application 112 a message including the inference result L result The inferred response of (1).
Similar to other classification techniques described above, MPC can be derived from a computing system 1 And MPC 2 Hiding inference result L result . To do so, the inference request from application 112 can include a request to a computing system MPC 1 First share of the label [ L ] i,1 ]And to computing systems MPC 2 Is encrypted second share L of the label i,2 ](e.g., pubKeyEncrypt ([ L) 0,2 ||…||L n+1,2 ||application_public_key,MPC 2 ))。
By a computing system MPC 1 The inference result sent can include the computing system MPC 1 First share [ L ] of the generated inference result result1 ]. Similar to binary classification, to prevent the second share from being calculated by the system MPC 1 Accessing and thus enabling a computing system MPC 1 Capable of obtaining inferences in plain text, computing system MPC 2 Enabling a computing system MPC 1 Sending a second share of the inference result [ L result,2 ]Encrypted (and optionally digitally signed) version of(e.g., pubKeySign (PubKeyEncrypt ([ L) result,2 ],application_public_key),MPC 2 ) For inclusion in the inference results sent to application 112. Application 112 can be selected from [ L ] result,1 ]And [ L result,2 ]Reconstruction of the inference result L result 。
Computing system MPC, like binary classification, when the aggregation function is an arithmetic mean 1 And MPC 2 The sum of the labels sum _ of _ labels is calculated. Computing system MPC if the sum of tags is insensitive 1 And MPC 2 Two shares can be calculated 1 ]And [ sum _ of _ labels 2 ]And then reconstruct sum _ of _ labels based on the two shares. Computing system MPC 1 And MPC 2 The average of the tags can then be calculated by dividing the sum of the tags by the number of nearest neighbor tags (e.g., by k).
Computing system MPC 1 The average can then be compared to a threshold using relation 8 to identify a first share of the label corresponding to the average and to compare the first share [ L result,1 ]Set to a first share of the identified tag. Similarly, computing system MPC 2 The relationship 8 can be used to compare the average value to a threshold value to identify a second share of the tag corresponding to the average value and to compare the second share [ L result,2 ]Set to a second share of the identifier tag. Computing system MPC 2 The second share L can be paired using the public key of the application 112 result,2 ]Encryption is performed, e.g., pubKeyEncrypt ([ L) result,2 ]Application _ public _ key) and sends the encrypted second share to the computing system MPC 1 . Computing system MPC 1 The first share and the encrypted second share (which can optionally be digitally signed as described above) can be provided to the application 112. The application 112 can then add the user to the user list L via a tag (e.g., user group identifier) result An identified group of users.
Computing System MPC if the sum of labels is sensitive 1 And MPC 2 It may not be possible to construct sum of labels in plaintext. Alternatively, the computing system MPC 1 Can be directed to
In addition, computing system MPC 1 Can calculate
the corresponding cryptographic implementation can be represented by the following relations 10 and 11.
these are calculated at L i Is plain text without the need for a computing system MPC 1 And MPC 2 Any round trip calculation between, and at L i Is that one round trip calculation is required in the case of secret shares. Computing system MPC 1 Two shares of the result (e.g., [ L ]) can be divided result,1 ]And [ L result,2 ]) Provided to the application 112, wherein the second share is provided by the MPC 2 Encrypted and optionally digitally signed as described above. In this manner, application 112 can be used without computing system MPC 1 Or MPC 2 Determining an inferred result L in the case of learning anything about intermediate or final results result 。
For root mean square, calculate system MPC 1 Will ID (i.e., { ID }) 1 ,…id k }) to the computing system MPC 2 . Computing system MPC 2 It can be verified that the number of row identifiers in the ID is greater than a threshold to enforce k-anonymity. Computing system MPC 2 The second share of the sum of square of the label value parameter (e.g., sum of squares of label values) is calculated using the following relation 12.
similarly, computing system MPC 1 The first contribution of the sum of square labels parameter can be calculated using the following relation 13.
assuming the sum of square labels parameter is insensitive, the meterCalculation system MPC 1 And MPC 2 Can be derived from two shares [ sum of square _ labels 1 ]And [ sum _ of _ square _ labels 2 ]Reconstruct the sum of _ square _ labels parameter. Computing system MPC 1 And MPC 2 The root mean square of the label can be calculated by dividing sum of squares labels by the number of nearest neighbor labels (e.g., by k) and then calculating the square root.
Computing system MPC regardless of whether the mean is computed via arithmetic mean or root mean square 1 The average can then be compared to a threshold using relation 8 to identify the label corresponding to the average and the first share L result,1 ]Set as the identified tag. Similarly, computing system MPC 2 The relationship 8 can be used to compare the average value to a threshold value to identify the tag (or secret share of the tag) corresponding to the average value and the second share L result,2 ]Set to (the secret share of) the identifier tag. Computing system MPC 2 The second share L can be paired using the public key of the application 112 result,2 ]Encryption is performed, e.g., pubKeyEncrypt ([ L) result,2 ]Application _ public _ key) and sends the encrypted second share to the computing system MPC 1 . Computing system MPC 1 The first share and the encrypted second share (which can optionally be digitally signed as described above) can be provided to the application 112 as an inference result. The application 112 can then add the user to the pass L result A tag (e.g., a user group identifier) identifies the user group. If the sum of square labels parameter is sensitive, the calculation System MPC 1 And MPC 2 A similar cryptographic protocol as used in the arithmetic mean example can be executed to calculate the share of the inferred result.
In the above technique for inferring the results of the classification and regression problem, all k nearest neighbors have equal influence, e.g., equal weight, on the final inference result. For many classification and regression problems, if each of the k neighbors is assigned a current neighbor and query parameters P i The monotonically decreasing weight as the hamming distance between increases can improve the model quality. Common kernel functions of this nature Is an Epanechnikov (parabolic) kernel function. Both hamming distance and weight can be calculated in plaintext.
Sparse feature vector user profiles
When features of the electronic resource are included in the user profile and used to generate the machine learning model, the resulting feature vector can include high cardinality classification features such as domains, URLs, and IP addresses. These feature vectors are sparse, with most elements having zero values. The application 112 can split the feature vector into two or more dense feature vectors, but the machine learning platform would consume too much client device upload bandwidth to be practical. To prevent this problem, the above-described systems and techniques can be adapted to better handle sparse feature vectors.
When providing the feature vector for the event to the client device, computer readable code (e.g., script) of the content platform 150 included in the electronic resource can call an application (e.g., browser) API to specify the feature vector for the event. This code or content platform 150 is able to determine whether (some portion of) the feature vectors are dense or sparse. If the feature vector (or some portion thereof) is dense, the code can pass into a vector of values as API parameters. If the feature vector (or some portion thereof) is sparse, the code can pass into a map, mapping, for example, index key/value pairs for those feature elements that have non-zero feature values, where the key is the name or index of such feature elements. If the feature vector (or some portion thereof) is sparse and the non-zero feature values are always the same value, e.g., 1, then the code can pass into a set of names or indices whose elements are such feature elements.
When aggregating feature vectors to generate a user profile, the application 112 can process dense feature vectors and sparse feature vectors differently. The user profile (or some portion thereof) computed from the dense vector is still a dense vector. The user profile (or some part of it) computed from the mapping is still the mapping until the fill rate is high enough that the mapping no longer saves storage costs. At that time, the application 112 converts the sparse vector representation to a dense vector representation.
If the aggregation function is a summation, the user profile (or some portion thereof) computed from the set can be a mapping. For example, each feature vector can have a classification feature "visited domain". The aggregation function, i.e., the summation, will count the number of times the user accessed the publisher domain. If the aggregation function is a logical OR, the user profile (OR some part of it) computed from the set can still be the set. For example, each feature vector can have a classification feature "visited domain". The aggregation function, i.e. the logical OR, will calculate all publisher domains that the user accesses, regardless of the frequency of access.
To send the user profile to the MPC cluster 130 for ML training and prediction, the application 112 may split the dense portion of the user profile using any standard cryptographic library that supports secret shares. To split the sparse portion of the user profile without significantly increasing the client device upload bandwidth and computational cost, a Functional Secret Sharing (FSS) technique can be used. In this example, the content platform 150 assigns a unique index to each possible element in the sparse portion of the user profile sequentially starting at 1. The valid range of indices is assumed to be inclusively within the range of [1, N ].
For a value P having a non-zero value in a user profile calculated by an application i 1 ≦ i ≦ N, the application 112 can create two pseudo-random functions (PRF) g with the following properties i And h i ：
For any j, g i (j)+h i (j) =0, where j is 1 ≦ N and j ≠ i
Otherwise g i (j)+h i (j)＝P i 。
Using FSS, g i Or h i Can for example pass log 2 (N) size _ of _ tag bits are concisely represented, and it is impossible to derive from g i Or h i Inferring i or P i . To prevent brute force security attacks, the size _ of _ tag is typically 96 bits or more. Among the N dimensions, it is assumed that there are N dimensions with non-zero values, where N < N. For each of the n dimensions, the application 112 can be as described aboveTwo pseudo-random functions g and h are constructed. Furthermore, the application 112 is able to pack all concise representations of n functions G into a vector G and n concise representations of functions H into another vector H in the same order.
In addition, the application 112 can split the dense portion of the user profile P into two additive secret shares [ P [ ] 1 ]And [ P 2 ]. Application 112 can then apply [ P ] 1 ]And G are sent to the computing system MPC 1 And will [ P 2 ]And H sends to MPC 2 . Log is required for transferring G 2 (N)×size_of_tag＝n×log 2 (N) x size _ of _ tag bits, which when N < N can be much smaller than the N bits needed if the application 112 transmits the sparse portion of the user profile in a dense vector.
While computing system MPC 1 Receives g 1 And computing a system MPC 2 Receives h 1 Time, two computing systems MPC 1 And MPC 2 Shamir secret shares can be created independently. For any j where 1 ≦ j ≦ N, the computing system MPC 1 In two-dimensional coordinates [1,2 Xg i (j)]Upper creation point and computing the system MPC 2 In two-dimensional coordinates [ -1,2 × h i (j)]Upper creation point. If two computing systems MPC 1 And MPC 2 Cooperatively constructing a line y = a passing through two points 0 +a 1 X, then the relationships 14 and 15 are formed.
Relation 14:2 Xg i (j)＝a 0 +a 1
Relation 15:2 x h i (j)＝a 0 -a 1
If these two relations are added together, they result in 2 × g i (j)+2×h i (j)＝(a 0 +a 1 )+(a 0 -a 1 ) Simplified as a 0 ＝g i (j)+h i (j) .1. The Thus, [1,2 Xg i (j)]And [ -1,2 XH i (j)]Is the ith non-zero element (i.e., P) in the sparse array i ) Two secret shares.
Computing system MPC during stochastic projection operation of machine learning training process 1 Can be selected from [ P ] 1 ]And G both independently assemble a vector of their secret shares for the user profile. As described above, | G | = n is known, where n is the number of non-zero elements in the sparse portion of the user profile. In addition, the sparse portion of the known user profile is N-dimensional, where N is<<N。
Suppose G = { G = 1 ,…g n }. For the jth dimension where 1 ≦ j ≦ N and 1 ≦ k ≦ N, let
Let [ SP) 1 ]＝{[SP 1,1 ],…[SP N,1 ]I.e. reconstructed secret shares in a dense representation of the sparse part of the user profile. By cascading [ P ] 1 ]And [ SP 1 ]Computing system MPC 1 The complete secret share of the original user profile can be reconstructed. Computing system MPC 1 Then can project [ P ] randomly 1 ]||[SP 1 ]. Similarly, computing system MPC 2 Capable of projecting [ P ] randomly 2 ]||[SP 2 ]. After projection, the techniques described above can be used to generate machine learning models in a similar manner.
FIG. 6 is a conceptual diagram of an exemplary framework for generating inference results for a user profile in system 600. More specifically, the figure depicts stochastic projection logic 610, a first machine learning model 620, and final result calculation logic 640, which collectively make up the system 600. In some implementations, the functionality of system 600 may be provided in a secure and distributed manner by multiple computing systems in an MPC cluster. For example, the techniques described with reference to system 600 may be similar to the techniques described above with reference to fig. 2-5. For example, the functionality associated with random projection logic 610 may Corresponding to the functionality of one or more of the stochastic projection techniques described above with reference to fig. 2 and 4. Similarly, in some examples, the first machine learning model 620 may correspond to one or more of the machine learning models described above with reference to fig. 2, 4, and 5, such as one or more of those described above with reference to steps 214, 414, and 504. In some examples, the encrypted tag data set 626, which may be maintained and utilized by the first machine learning model 620 and stored in one or more memory units, can include at least one real tag for each user profile used to generate or train or evaluate the quality of the training or to fine tune the process of training the first machine learning model 620, such as those that may be associated with the k nearest neighbor profiles as described above with reference to step 506 of fig. 5. That is, the encrypted tag data set 626 may include at least one authentic tag for each of n user profiles, where n is the total number of user profiles used to train the first machine learning model 620. For example, the encrypted tag data set 626 may include a data set for a jth user profile (P) of the n user profiles j ) At least one real label (L) j ) For the kth user profile (P) of the n user profiles k ) At least one real label (L) k ) For the l-th user profile (P) of the n user profiles l ) At least one real label (L) l ) Wherein j is more than or equal to 1, k, l is less than or equal to n, and so on. Such real tags as associated with the user profile used to generate or train the first machine learning model 620 and included as part of the encrypted tag data set 626 can be encrypted, e.g., represented as secret shares. Additionally, in some examples, final result calculation logic 640 may correspond to logic employed in connection with performing one or more operations for generating inferred results (such as one or more of those operations described above with reference to step 218 in fig. 2). The first machine learning model 620 and the final result calculation logic 640 can be configured to employ one or more inference techniques including binary classification, regression, and/or multi-class classification techniques.
In the example of FIG. 6, system 600 is depicted as being pushedThe time-out period performs one or more operations. Random projection logic 610 can be employed to align user profile 609 (P) i ) Applying a stochastic projection transform to obtain a transformed user profile 619 (P) i '). The transformed user profile 619, as obtained by employing the stochastic projection logic 610, can be in clear text. For example, random projection logic 610 may be employed, at least in part, to obfuscate feature vectors, such as feature vectors included or indicated in user profile 609 and other user profiles, with random noise to protect user privacy.
Capable of training and then utilizing a first machine learning model 620 to receive as input a transformed user profile 619 and generate in response thereto at least one predictive tag 629predictive tag 629 as obtained using the first machine learning model 620 can be encrypted. In some implementations, the first machine learning model 620 includes a k-nearest neighbor (k-NN) model 622 and a label predictor 624. In such implementations, the k-NN model 622 can be employed by the first machine learning model 620 to identify a number k of nearest neighbor user profiles that are considered most similar to the transformed user profile 619. In some examples, models other than the k-NN model, such as those rooted in one or more prototype methods, may be employed as model 622. The tag predictor 624 can then identify a real tag for each of the k nearest neighbor user profiles from among the real tags included in the encrypted tag data set 626 and determine at least one predicted tag 629 based on the identified tags. In some implementations, the tag predictor 624 can apply a softmax function to the data it receives and/or generates in determining the at least one predictive tag 629.
For implementations in which the first machine learning model 620 and the final result calculation logic 640 are configured to employ regression techniques, the at least one prediction label 629 may correspond to, for example, a single label representing an integer such as the sum of the true labels for the k nearest neighbor user profiles as determined by the label predictor 624. The sum of such real labels for k nearest neighbor user profiles as determined by the label predictor 624 is actually equivalent to the average of the real labels for k nearest neighbor user profiles as scaled by a factor of k. Similarly, for implementations in which the first machine learning model 620 and the final result calculation logic 640 are configured to employ binary classification techniques, the at least one prediction label 629 may correspond to, for example, a single label representing an integer determined by the label predictor 624 based at least in part on such a sum. In the case of binary classification, each of the true labels for the k nearest neighbor user profiles may be a binary value of zero or one, such that the aforementioned average may be an integer value between zero and one (e.g., 0.3, 0.8, etc.), which, for example, effectively represents a predicted probability that the true label for the user profile (e.g., transformed user profile 619) received as input by first machine learning model 620 is equal to one. Additional details regarding the following are provided below with reference to fig. 9-11: the nature of the at least one prediction label 629 and the manner in which the at least one prediction label 629 may be determined for implementations in which the first machine learning model 620 and the final result calculation logic 640 are configured to employ regression techniques and for implementations in which the first machine learning model 620 and the final result calculation logic 640 are configured to employ binary classification techniques.
For implementations in which the first machine learning model 620 and the final result calculation logic 640 are configured to employ multi-class classification techniques, at least one prediction label 629 may correspond to a vector or set of prediction labels as determined by the label predictor 624. Each predictive label in such a vector or set of predictive labels may correspond to a respective category and be determined by the label predictor 624 based at least in part on a majority vote or a frequency that the respective category in the vector or set of real labels corresponding to a user profile of the k nearest neighbor user profiles is a real label of a first value (e.g., one) as determined by the label predictor 624. Much like binary classification, in the case of multi-class classification, each real label in each vector or set of real labels for a user profile in the k nearest neighbor user profiles may be a binary value of zero or one. Additional details regarding the following are provided below with reference to fig. 9-11: the nature of the at least one predictive label 629 and the manner in which the at least one predictive label 629 may be determined for an implementation in which the first machine learning model 620 and the final result calculation logic 640 are configured to employ multi-class classification techniques.
The final Result calculation logic 640 can be employed to generate an inference Result 649 (Result) based on at least one prediction label 629 i ). For example, the final result calculation logic 640 can be employed to evaluate at least one predictive label 629 against one or more thresholds and determine an inference result 649 based on the evaluation result. In some examples, the inference result 649 may indicate whether a user associated with the user profile 609 is to be added to one or more user groups. In some implementations, at least one prediction tag 629 can be included or otherwise indicated in the inference results 649.
In some implementations, the system 600 as depicted in fig. 6 can represent a system as implemented by an MPC cluster such as the MPC cluster 130 of fig. 1. Thus, it should be understood that in at least some of these implementations, some or all of the functionality described herein with reference to the elements shown in fig. 6 may be provided in a secure and distributed manner by two or more computing systems of an MPC cluster. For example, each of the two or more computing systems of the MPC cluster may provide a respective share of the functionality described herein with reference to fig. 6. In this example, two or more computing systems may operate in parallel to implement the selected secret sharing algorithm to cooperatively perform operations similar or equivalent to those described herein with reference to fig. 6. In at least some of the foregoing implementations, the user profile 609 may represent a share of the user profile. In such implementations, one or more of the other pieces or quantities of data described herein with reference to fig. 6 may also represent secret shares thereof. It should be appreciated that in providing the functionality described herein with reference to fig. 6, additional operations may be performed by two or more computing systems for the purpose of protecting user privacy. Examples of one or more of the foregoing implementations are described in further detail below, e.g., with reference to fig. 12 and elsewhere herein. In general, in at least some implementations, "shares" as described below and elsewhere herein can correspond to secret shares.
While the training process for k-NN models, such as k-NN model 622, may be relatively fast and simple in that knowledge of the labels is not required, in some cases, there can be room for improvement in the quality of such models. Thus, in some implementations, the performance of the first machine learning model 620 can be enhanced with one or more systems and techniques described in further detail below.
FIG. 7 is a conceptual diagram of an exemplary framework for generating inferences for a user profile with increased performance in system 700. In some implementations, one or more of elements 609-629 as depicted in fig. 7 may be similar or equivalent to one or more of elements 609-629, respectively, as described above with reference to fig. 6. Much like system 600, system 700 includes random projection logic 610 and first machine learning model 620, and is depicted as performing one or more operations at inferred times.
However, unlike system 600, system 700 further includes a second machine learning model 730, which second machine learning model 730 is trained and subsequently utilized to generate prediction residual values 739 (residual) indicative of an amount of prediction error in at least one prediction label 629 by receiving transformed user profile 619 as input i ) As an output to improve the performance of the first machine learning model 620. The prediction residual value 739 as obtained using the second machine learning model 730 can be in the clear. Final Result calculation logic 740, included in system 700 in place of final Result calculation logic 640, can be employed to generate inference results 749 (Result) based on at least one prediction label 629 and further based on prediction residual values 739 i ). Taking into account that the prediction residual values 739 indicate an amount of prediction error in at least one prediction tag 629, relying on at least one prediction tag 629 and in cooperation with the prediction residual values 739 may enable the end result calculation logic 740 to effectively cancel or neutralizeAt least some of the errors expressed in the at least one predictive tag 629, thereby enhancing one or both of the accuracy and reliability of the inferences 749 produced by system 700.
For example, final result calculation logic 740 can be employed to calculate the sum of at least one prediction label 629 and prediction residual values 739. In some examples, final result calculation logic 740 can be further employed to evaluate the sum of such calculations against one or more threshold values and determine an inference result 749 based on the result of the evaluation. In some implementations, such a calculated sum of at least one prediction label 629 and prediction residual values 739 can be included or otherwise indicated in either inference 649 in fig. 6 or inference 749 in fig. 7.
The second machine learning model 730 may include or correspond to one or more of a Deep Neural Network (DNN), a gradient boosting decision tree, and a random forest model. That is, the first machine learning model 620 and the second machine learning model 730 may be architecturally different from each other. In some implementations, the second machine learning model 730 can be trained using one or more gradient boosting algorithms, one or more gradient decreasing algorithms, or a combination thereof.
The second machine learning model 730 can be trained using the same set of user profiles used to train the first machine learning model 620 and data indicating the difference between the real labels for such set of user profiles and the predicted labels for such set of user profiles as determined using the first machine learning model 620. Accordingly, the process of training the second machine learning model 730 is performed after at least a portion of the process of training the first machine learning model 620 is performed. Data used to train the second machine learning model 730, such as data indicative of the difference between the predicted label and the authentic label determined using the first machine learning model 620, may be generated or otherwise obtained by a process that evaluates the performance of the first machine learning model 620 as trained. Examples of such processes are described in further detail below with reference to fig. 10-11.
As mentioned above, the random projection logic 610, as included in the systems 600 and 700, may be employed, at least in part, to obfuscate feature vectors, such as feature vectors included or indicated in the user profile 609 and other user profiles, with random noise to protect user privacy. To enable machine learning training and prediction, the random projective transformation applied by random projection logic 610 needs to preserve some notion of distance between feature vectors. One example of a stochastic projection technique that can be employed in the stochastic projection logic 610 includes a SimHash technique. This and other techniques described above can be used to obfuscate feature vectors while preserving cosine distances between such feature vectors.
While maintaining cosine distances between feature vectors may prove sufficient for training and using a k-NN model such as the k-NN model 622 of the first machine learning model 620, it may be less than ideal for training and using other types of models such as one or more models of the second machine learning model 730. Thus, in some implementations, it may be desirable to employ a stochastic projection technique in the stochastic projection logic 610 that can be used to obfuscate feature vectors while preserving euclidean distances between such feature vectors. One example of such a stochastic projection technique includes the Johnson-Lindenstaus (J-L) technique or transform.
As mentioned above, one property of the J-L transform is that it preserves the euclidean distances between feature vectors with probabilities. In addition, the J-L transform is lossy, irreversible, and incorporates random noise. Thus, even if two or more servers or computing systems of an MPC cluster are in-line, they will not be able to derive a transformed version (P) of a user profile obtained using J-L transformation techniques i ') obtain an original user profile (P) i ) The exact reconstruction of (1). In this manner, employing J-L transformation techniques for the purpose of transforming user profiles in one or more systems described herein may be used to provide user privacy protection. Further, the J-L transform technique can be used as the dimension reduction technique. Thus, one advantageous byproduct of employing the J-L transformation technique for transforming user profiles in one or more systems described herein is that it can actually be used to significantly improve subsequent processing stepsSpeed that can be performed by such systems.
In general, given an arbitrarily small ε>0, there is a value that can be applied to P for any 1 ≦ i, j ≦ n i Transformation to P i ', will P j Transformation to P j The J-L transform of' wherein n is the number of training examples, and:
(1-ε)×|P i -P j | 2 ≤|P′ i -P′ j | 2 ≤(1+ε)×|P i -P j | 2
That is, applying the J-L transform may change the euclidean distance between two arbitrarily selected training examples by no more than a small fraction epsilon. For at least the foregoing reasons, in some implementations, J-L transform techniques may be employed in random projection logic 610 as described herein.
In some implementations, the system 700 as depicted in fig. 7 can represent a system as implemented by an MPC cluster, such as the MPC cluster 130 of fig. 1. Thus, it should be understood that in at least some of these implementations, some or all of the functionality described herein with reference to the elements shown in fig. 7 may be provided in a secure and distributed manner by two or more computing systems of an MPC cluster. For example, each of the two or more computing systems of the MPC cluster may provide a respective share of the functionality described herein with reference to fig. 7. In this example, two or more computing systems may operate in parallel to implement a selected secret sharing algorithm to cooperatively perform operations similar or equivalent to those described herein with reference to fig. 7. In at least some of the foregoing implementations, the user profile 609 may represent a secret share of the user profile. In such implementations, one or more of the other pieces or quantities of data described herein with reference to fig. 7 may also represent secret shares thereof. It should be appreciated that in providing the functionality described herein with reference to fig. 7, additional operations may be performed by two or more computing systems for the purpose of protecting user privacy. Examples of one or more of the foregoing implementations are described in further detail below, e.g., with reference to fig. 12 and elsewhere herein.
FIG. 8 is a flow diagram illustrating an example process 800 for generating inferences for a user profile at an MPC cluster with increased performance. For example, one or more of the operations described with reference to fig. 8 may be performed at inferred times. The operations of the process 800 can be implemented, for example, by an MPC cluster such as the MPC cluster 130 of fig. 1, and can also correspond to one or more of the operations described above with reference to fig. 7. For example, the operations described with reference to FIG. 8 may be performed at inferred times.
In some implementations, some or all of the functionality described herein with reference to the elements shown in fig. 8 may be provided in a secure and distributed manner by two or more computing systems of an MPC cluster, such as MPC cluster 130 of fig. 1. For example, each of the two or more computing systems of the MPC cluster may provide a respective share of the functionality described herein with reference to fig. 8. In this example, two or more computing systems may operate in parallel to implement a selected secret sharing algorithm to cooperatively perform operations similar or equivalent to those described herein with reference to fig. 8. It should be appreciated that in providing the functionality described herein with reference to fig. 8, additional operations may be performed by two or more computing systems for the purpose of protecting user privacy. Examples of one or more of the foregoing implementations are described in further detail below, e.g., with reference to fig. 12 and elsewhere herein. The operations of process 800 can also be implemented as instructions stored on one or more computer-readable media, which may be non-transitory, and execution of the instructions by one or more data processing apparatus can cause the one or more data processing apparatus to perform the operations of process 800.
The MPC cluster receives an inference request associated with a particular user profile (802). For example, this may correspond to one or more operations similar or equivalent to the one or more operations performed with respect to the MPC cluster 130 receiving the inference request from the application 112, as described above with reference to fig. 1.
The MPC cluster is based on a particular user profile, a first machine learning model trained using a plurality of user profiles, and one or more of a plurality of real labels for the plurality of user profilesA predictive label for a particular user profile is determined (804). Tags as described herein can be or include demographic-based user group identifiers or demographic characteristics. For example, this can correspond to a label 629 related to utilizing the first machine learning model 620 to obtain at least one prediction
In this example, the plurality of real tags for the plurality of user profiles may correspond to real tags included as part of the encrypted tag data 626 for the plurality of user profiles used to train the first machine learning model 620. For example, one or more real tags from among the plurality of real tags on which the predicted tag for the particular user profile is determined may include at least one real tag for each of the k nearest neighbor user profiles identified by the k-NN model 622 of the first machine learning model 620. In some examples, each of the plurality of authentic tags is encrypted, as is the case in the examples of fig. 6-7. Some of the various ways in which the predicted labels can be determined using the real labels for the k nearest neighbor user profiles are described in detail above. As becomes apparent above, the manner or method by which such true tags are utilized to determine predictive tags may depend, at least in part, on the type of inference technique employed (e.g., regression techniques, binary classification techniques, multi-class classification techniques, etc.).
The MPC cluster determines prediction residual values indicative of prediction errors in the prediction labels based on the particular user profile and a second machine learning model trained using the plurality of user profiles and data indicative of differences between the plurality of real labels for the plurality of users and the plurality of prediction labels as determined for the plurality of user profiles using the first machine learning model (806). For example, this may correspond to a prediction residual value 739 (residual) obtained with respect to utilizing the second machine learning model 730 i ) One or more operations performed analogouslyOr one or more equivalent operations, as described above with reference to fig. 7. Thus, in some implementations, the second machine learning model includes at least one of a deep neural network, a gradient boosting decision tree, and a random forest model.
The MPC cluster generates data representing the inference result based on the prediction labels and the prediction residual values (808). For example, this may correspond to a determination as to employing the final Result calculation logic 740 to generate the inference Result 749 (Result) i ) One or more operations performed similar or equivalent to one or more operations described above with reference to fig. 7. Thus, in some examples, the inference result includes or corresponds to a sum of the prediction tag and the prediction residual value.
The MPC cluster provides data representing the inference to the client device (810). For example, this may correspond to one or more operations similar or equivalent to one or more operations performed with respect to the MPC cluster 130 to provide the inference to the client device 110 on which the application 112 is running, as described above with reference to fig. 1-2.
In some implementations, the process 800 further includes one or more operations in which the MPC cluster applies a transformation to the particular user profile to obtain a transformed version of the particular user profile. In these implementations, to determine the predictive label, the MPC cluster determines the predictive label based at least in part on the transformed version of the particular user profile. For example, this may correspond to a user profile 609 (P) with respect to employing random projection logic 610 i ) Applying a stochastic projection transform to obtain a transformed user profile 619 (P) i ') one or more operations similar or equivalent to the one or more operations performed, as described above with reference to figures 6-7. Thus, in some examples, the aforementioned transformation may be a random projection. Further, in at least some of these examples, the aforementioned random projection may be a Johnson-lindenstruss (J-L) transform. In at least some of the foregoing implementations, to determine the prediction label, the MPC cluster provides a transformed version of the particular user profile as input to the first machine learning model to obtain the prediction label for the particular user profile As an output. For example, this may correspond to receiving a transformed user profile 619 (P) with respect to the first machine learning model 620 i ') as input and in response thereto generate at least one predictive tag 629
As mentioned above, in some implementations, the first machine learning model includes a k-nearest neighbor model. In at least some of these implementations, to determine the predictive label, the MPC cluster identifies a number k of nearest neighbor user profiles among the plurality of user profiles that are deemed most similar to the particular user profile based at least in part on the particular user profile and a k-nearest neighbor model, and determines the predictive label based at least in part on the true label for each of the k nearest neighbor user profiles. In some such implementations, to determine the predicted label based at least in part on the real labels for each of the k nearest neighbor user profiles, the MPC cluster determines a sum of the real labels for the k nearest neighbor user profiles. For example, this can correspond to information regarding utilizing the first machine learning model 620 to obtain the at least one predictive label 629 in one or more implementations in which one or more regression and/or binary classification techniques are employed
In some of the foregoing implementations, to determine the predicted label based at least in part on the real labels for each of the k nearest neighbor user profiles, the MPC cluster determines the predicted label based at least in part on a set of real labels for each of the k nearest neighbor user profiles respectively corresponding to a set of classesAnd, to determine a set of predicted labels, the MPC cluster performs an operation on each class in the set. Such operations can include one or more operations in which the MPC cluster determines a majority vote or frequency for a real label of the set of real labels of the user profile of the k nearest neighbor user profiles that corresponds to the category is a real label of the first value. For example, this can correspond to obtaining at least one predictive label 629 utilizing first machine learning model 620 in one or more implementations in which one or more multi-class classification techniques are employed
FIG. 9 is a flow diagram illustrating an example process 900 for preparing and performing training of a second machine learning model at an MPC cluster in order to boost inference performance. The operations of the process 900 can be implemented, for example, by an MPC cluster such as the MPC cluster 130 of fig. 1, and can also correspond to one or more of the operations described above with reference to fig. 2, 4, 6, and 7. In some implementations, some or all of the functionality described herein with reference to the elements shown in fig. 9 may be provided in a secure and distributed manner by two or more computing systems of an MPC cluster, such as MPC cluster 130 of fig. 1. For example, each of the two or more computing systems of the MPC cluster may provide a respective secret share of the functionality described herein with reference to fig. 9. In this example, two or more computing systems may operate in parallel to implement the selected secret sharing algorithm to cooperatively perform operations similar or equivalent to those described herein with reference to fig. 9. It should be appreciated that in providing the functionality described herein with reference to fig. 9, additional operations may be performed by two or more computing systems for the purpose of protecting user privacy. Examples of one or more of the foregoing implementations are described in further detail below, e.g., with reference to fig. 12 and elsewhere herein. The operations of process 900 can also be implemented as instructions stored on one or more computer-readable media, which may be non-transitory, and execution of the instructions by one or more data processing apparatus can cause the one or more data processing apparatus to perform the operations of process 900.
The MPC cluster trains a first machine learning model using a plurality of user profiles (910). For example, as described above, the first machine learning model may correspond to the first machine learning model 620. Similarly, the plurality of user profiles used in the training of the first machine learning model may correspond to the number n of user profiles used to train the first machine learning model 620 for which authentic tags may be included in the encrypted tag data set 626 as described above. As described herein, a tag can be or include a user group identifier or demographic.
The MPC cluster evaluates the performance of the first machine learning model as trained using multiple user profiles (920). Additional details regarding what such evaluations may require are provided below with reference to fig. 10-11.
In some implementations, the data generated in such evaluations can be utilized by the MPC cluster or another system in communication with the MPC cluster to determine whether the performance of a first machine learning model, such as the first machine learning model 620, warrants a boost, e.g., by a second machine learning model, such as the second machine learning model 730. Examples of data generated in such evaluations that can be utilized in this manner are described in further detail below with reference to the profile and residual data set 1070 of fig. 10 and step 1112 of fig. 11.
For example, in some cases, the MPC cluster or another system in communication with the MPC cluster may determine, based on data generated in such evaluations, that the performance (e.g., prediction accuracy) of the first machine learning model satisfies one or more thresholds, and thus does not guarantee a boost. In such cases, the MPC cluster may refrain from training and implementing the second machine learning model based on this determination. However, in other cases, the MPC cluster or another system in communication with the MPC cluster may determine, based on data generated in such evaluations, that the performance (e.g., prediction accuracy) of the first machine learning model meets one or more thresholds, and thus does warrant promotion. In these cases, based on this determination, the MPC cluster may receive a functionality upgrade comparable to the functionality upgrade that would be obtained in transitioning from system 600 to system 700, as described above with reference to fig. 6-7. To receive such a functionality upgrade, the MPC cluster may continue to train and implement a second machine learning model, such as second machine learning model 730, in order to improve the performance of the first machine learning model. In some examples, data generated in such evaluations may additionally or alternatively be provided to one or more entities associated with the MPC cluster. In some such examples, one or more entities may make their own determinations as to whether the performance of the first machine learning model warrants an increase, and proceed accordingly. Other configurations are possible.
The MPC cluster trains a second machine learning model using a set of data that includes data generated in evaluating performance of the first machine learning model (930). Examples of such data can include the data described below with reference to profile and residual data set 1070 of fig. 10 and step 1112 of fig. 11.
In some implementations, the process 900 further includes additional steps 912-916 described in further detail below. In such implementations, steps 912-916 are performed before steps 920 and 930, but can be performed after step 910.
FIG. 10 is a conceptual diagram of an exemplary framework for evaluating performance of a first machine learning model in system 1000. In some implementations, one or more of elements 609-629 as depicted in fig. 10 may be similar or equivalent to one or more elements 609-629 as described above with reference to fig. 6-7, respectively. In some examples, one or more of the operations described herein with reference to fig. 10 may correspond to one or more of those operations described above with reference to step 920 of fig. 9. Much like systems 600 and 700, system 1000 includes random projection logic 610 and first machine learning model 620.
However, unlike systems 600 and 700, system 1000 further includes residual calculation logic 1060. In addition, theIn the example of FIG. 10, user profile 609 (P) i ) Corresponding to one of the plurality of user profiles used to train the first machine learning model 620, however, in the examples of fig. 6 and 7, the user profile 609 (P) i ) May not necessarily correspond to one of the plurality of user profiles used to train the first machine learning model 620, but instead simply correspond to the user profile associated with the inference request received at the inference time. In some examples, the aforementioned plurality of user profiles used to train the first machine learning model 620 can correspond to the plurality of user profiles described above with reference to step 910 of fig. 9. Residual calculation logic 1060 can be employed to base at least one prediction tag 629 and at least one true tag 1059 (L) i ) Generate a residual value 1069 (residual) indicative of an amount of error in the at least one prediction tag 629 i ). Tags as described herein can be or include demographic-based user group identifiers or demographic characteristics. At least one predictive tag 629residual calculation logic 1060 can employ the secret share to calculate a difference in value between the at least one predictive tag 629 and the at least one real tag 1059. In some implementations, the residual value 1069 may correspond to a difference of the aforementioned values.
The residual values 1069 can be stored in association with the transformed user profile 619, e.g., in memory as part of the profile and residual data set 1070. In some examples, the data included in profile and residual data set 1070 may correspond to one or both of data as described above with reference to step 930 of fig. 9 and data as described below with reference to step 1112 of fig. 11. In some implementations, the residual value 1069 is in the form of a secret share to protect user privacy and data security.
In some implementations, the system 1000 as depicted in fig. 10 can represent a system implemented by an MPC cluster, such as the MPC cluster 130 of fig. 1. Thus, it should be understood that in at least some of these implementations, some or all of the functionality described herein with reference to the elements shown in fig. 10 may be provided in a secure and distributed manner by two or more computing systems of an MPC cluster. For example, each of the two or more computing systems of the MPC cluster may provide a respective share of the functionality described herein with reference to fig. 10. In this example, two or more computing systems may operate in parallel to implement the selected secret sharing algorithm to cooperatively perform operations similar or equivalent to those described herein with reference to fig. 10. In at least some of the foregoing implementations, the user profile 609 may represent a secret share of the user profile. In such implementations, one or more of the other pieces of data or quantities described herein with reference to fig. 10 may also represent its secret shares. It should be appreciated that in providing the functionality described herein with reference to fig. 10, additional operations may be performed by two or more computing systems for the purpose of protecting user privacy. Examples of one or more of the foregoing implementations are described in further detail below, e.g., with reference to fig. 12 and elsewhere herein.
FIG. 11 is a flow diagram illustrating an example process 1100 for evaluating performance of a first machine learning model at an MPC cluster. The operations of the process 1100 can be implemented, for example, by an MPC cluster such as the MPC cluster 130 of fig. 1, and can also correspond to one or more of the operations described above with reference to fig. 9-10. In some examples, one or more of the operations described herein with reference to fig. 11 may correspond to one or more of those operations described above with reference to step 920 of fig. 9. In some implementations, some or all of the functionality described herein with reference to the elements shown in fig. 11 may be provided in a secure and distributed manner by two or more computing systems of an MPC cluster, such as MPC cluster 130 of fig. 1. For example, each of the two or more computing systems of the MPC cluster may provide a respective share of the functionality described herein with reference to fig. 11. In this example, two or more computing systems may operate in parallel to implement the selected secret sharing algorithm to cooperatively perform operations similar or equivalent to those described herein with reference to fig. 11. It should be appreciated that in providing the functionality described herein with reference to fig. 11, additional operations may be performed by two or more computing systems for the purpose of protecting user privacy. Examples of one or more of the foregoing implementations are described in further detail below, e.g., with reference to fig. 12 and elsewhere herein. The operations of process 1100 can also be implemented as instructions stored on one or more computer-readable media, which can be non-transitory, and execution of the instructions by one or more data processing apparatus can cause the one or more data processing apparatus to perform the operations of process 1100.
The MPC cluster selects an ith user profile and at least one corresponding real label ([ P ]) i ，L i ]) Where i is initially set to a value of one (1102-1104) and incremented through the recursion until i equals n (1114-1116), where n is the total number of user profiles used to train the first machine learning model. The tags can be or include demographic based user group identifiers or demographic characteristics. In other words, the process 1100 includes performing steps 1106-1112 for each of the n user profiles used to train the first machine learning model as described below.
In some implementations, the ith user profile may represent a secret share of the user profile. In such implementations, one or more of the other pieces of data or quantities described herein with reference to fig. 11 may also represent a share thereof.
MPC cluster to ith user Profile (P) i ) Applying a random projection to obtain a transformed version (P) of the ith user profile i ') (1106). For example, this may correspond to a user profile 609 (P) with respect to employing random projection logic 610 i ) Applying a random projective transformation to obtain a transformed user profile 619 (P) i ') one or more operations similar or equivalent to the one or more operations performed, as described above with reference to FIG. 10.
MPC cluster converting version (P) of ith user profile i ') as input to a first machine learning model to obtain a transformed version (P) for an ith user profile i ') at least one predictive tagpredictive tag 629
MPC cluster based at least in part on a user profile (P) for the ith user i ) At least one real label (L) i ) And at least one predictive tagresidual calculation logic 1060 to base at least in part on at least one authentic tag 1059 (L) i ) And at least one predictive label 629
MPC cluster will calculate residual value (Residue) i ) Transformed version (P) with ith user profile i ') are stored in association (1112). For example, this may correspond to a correlation with the residual value 1069 (residual) i ) With the transformed user profile 619 (P) i ') store in association (e.g., in memory as part of the profile and residual data set 1070) one or more operations similar or equivalent to one or more operations performed as described above with reference to FIG. 10. In some examples, this data may correspond to data as described above with reference to step 930 of fig. 9. Thus, in these examples, some or all of the data stored in this step may be used as training dataData of a second machine learning model, such as second machine learning model 730, is utilized.
Referring again to steps 1108-1110, for at least some implementations in which the first machine learning model is configured to employ a regression technique, the MPC cluster obtains at least one predictive label at step 1108step 1108, the first machine learning model identifies a transformed version (P) deemed to be with the ith user profile i ') the most similar k nearest neighbor user profiles, identifying at least one real label for each of the k nearest neighbor user profiles, calculating a sum of the real labels for the k nearest neighbor user profiles, and using the sum as at least one predicted labelstep 1110 is given by:
similarly, for at least some implementations in which the first machine learning model is configured to employ a binary classification technique, the MPC cluster obtains at least one predictive label at step 1108
However, unlike implementations in which the first machine learning model is configured to employ regression techniques, in implementations in which the first machine learning model is configured to employ binary classification techniques, each of the true labels for the k nearest neighbor user profiles may be a binary value of zero or one, such that the aforementioned average value may be an integer value between zero and one (e.g., 0.3, 0.8, etc.). Although in implementations employing binary classification techniques, the MPC cluster can compute and use the sum of real labels (sum of labels) for the k nearest neighbor user profiles as at least one predicted label at step 1108machine learning model 730. More specifically, because each of the true labels for the k nearest neighbor user profiles may be a binary value of zero or one, in implementations that employ binary classification techniques, such residual values (Residue) are used i ) Can potentially indicate at least one genuine label (L) i ) And thus may potentially indicate a residual value (residual) by possibly being processed to some extent at or after step 1112 i ) Of one or more systems and/or entities of data.
For example, consider a case where a binary classification technique is to be employed and L i =1, k =15 and
To understand why from Residue i Deducing L i It is possible to consider that the residual satisfaction of the user profile for training the first machine learning model, where its true label is assumed to be equal to 0, has a representation
In view of the foregoing, as described belowIn some implementations, different methods can be taken to perform one or more operations associated with steps 1108-1110 for implementations in which binary classification techniques are employed. In some implementations, to force the residuals of the two classes of training examples to have the same normal distribution, the MPC cluster can apply the transformation f to the sum of true labels (sum _ of _ labels) for the k nearest neighbor user profiles, such that L-based i And
(i)f(μ 0 )＝0
(ii)f(μ 1 )＝1
(iii)σ 0 ×f′(μ 0 )＝σ 1 ×f′(μ 1 )
where f' is the derivative of f.
One example of a transform with the above properties that may be employed in such implementations is the shape f (x) = a 2 x 2 +a 1 x+a 0 Of (2), wherein f' (x) =2a 2 x+a 1 . In some examples, the MPC cluster can deterministically find the coefficients { a } based on three linear equations from three constraints 2 ，a 1 ，a 0 Value of }:
(i)a′ 2 ＝σ 0 -σ 1
(ii)a′ 1 ＝2(σ 1 μ 1 -σ 0 μ 0 )
(iii)a′ 0 ＝μ 0 (μ 0 σ 0 +μ 0 σ 1 -2μ 1 σ 1 )
In these examples, the MPC cluster can combine the coefficients { a } 2 ，a 1 ，a 0 The calculation is: { a 2 ，a 1 ，a 0 }＝D×{a 2 ′，a 1 ′，a 0 '}. MPC cluster can compute { a } using addition and multiplication operations, e.g., on secret shares 2 ′，a 1 ′，a 0 '}. Transformation f (x) = a 2 x 2 +a 1 x+a 0 Also surrounding:
To calculate the aforementioned coefficients and other values dependent thereon, the MPC cluster may first estimate values equal to zero, μ, respectively 0 And σ 0 And a mean and standard deviation of the probability distribution of the prediction error (e.g., residual value) of the true label and equal to one, mu, respectively 1 And σ 1 The mean and standard deviation of the probability distribution of the prediction error (e.g., residual value) of the true label. In some examples, as standard deviation σ 0 May determine the variance σ of the probability distribution of the prediction error of the real label equal to zero 0 2 And as standard deviation σ 1 May determine the variance σ of the probability distribution of the prediction error of a true tag equal to one 1 2 。
In some instances, the given probability distribution of the prediction error may correspond to a normal distribution, while in other instances, the given probability distribution of the prediction error may correspond to a probability distribution other than a normal distribution, such as a bernoulli distribution, a uniform distribution, a binomial distribution, a hypergeometric distribution, a geometric distribution, an exponential distribution, and so forth. In such other instances, the estimated distribution parameters may include parameters other than the mean, standard deviation, and variance in some examples, such as one or more parameters that are specific to the characteristics of a given probability distribution of prediction errors. For example, the distribution parameters estimated for a given probability distribution corresponding to uniformly distributed prediction errors may include a minimum value parameter and a maximum value parameter (a and b), while the distribution parameters estimated for a given probability distribution corresponding to exponentially distributed prediction errors may include at least one rate parameter (λ). In some implementations, one or more operations similar to those performed with respect to the process 1110 of fig. 11 may be performed such that data indicative of prediction error of the first machine learning model can be obtained and utilized to estimate such distribution parameters. In at least some of the foregoing implementations, data indicative of prediction errors of the first machine learning model can be obtained and utilized to (i) identify, from among several different types of probability distributions (e.g., a normal distribution, a bernoulli distribution, a uniform distribution, a binomial distribution, a hypergeometric distribution, a geometric distribution, an exponential distribution, etc.), a particular type of probability distribution that most closely corresponds to the shape of the probability distribution for a given subset of prediction errors indicated by the data, and (ii) estimate one or more parameters of the probability distribution for the given subset of prediction errors indicated by the data from the identified particular type of probability distribution. Other configurations are possible.
Referring again to examples where the estimated distribution parameters include mean and standard deviation, in these examples, to estimate such distribution parameters for a true tag equal to zero, the MPC cluster can compute:
wherein:
count 0 ＝∑ i (1-L i )
in some examples, the MPC cluster is based on variance σ 0 2 To calculate the standard deviation sigma 0 E.g. by calculating the variance σ 0 2 The square root of (a). Similarly, to estimate such distribution parameters for a true tag equal to one, the MPC cluster can compute:
wherein:
count 1 ＝∑L i
in some examples, the MPC cluster is based on variance σ 1 2 To calculate the standard deviation sigma 1 E.g. by calculating the variance σ 1 2 The square root of (a).
Once such distribution parameters are estimated, the coefficients { a } are 2 ，a 1 ，a 0 Can be computed, stored, and utilized later to apply the corresponding transformation f to the sum of the true labels (sum of labels) for the k nearest neighbor user profiles. In some examples, the first machine learning model is configured with the coefficients such that forward, the first machine learning model applies a corresponding transformation f to a sum of the true labels for the k nearest neighbor user profiles in response to the input.
Much like binary classification, in the case of multi-class classification, each real label in each vector or set of real labels for a user profile in the k nearest neighbor user profiles may be a binary value of zero or one. For this reason, methods similar to those described above with reference to binary classification may also be taken in the implementation of multi-class classification techniques, such that L is based on i And
For arbitrarily chosen jth label, MPC cluster can be based on/ j Whether it is a training label for the training example, to segment the training example into two groups. For l j Is a training example set of training labels, the MPC cluster can assume frequency j Is in a normal distribution and the mean value mu is calculated 1 Sum variance σ 1 . On the other hand, for l j Rather than training example sets of labels, MPC clusters can assume frequency j Is in a normal distribution and the mean value mu is calculated 0 Sum variance σ 0 。
Similar to binary classification, in the case of multi-class classification, the prediction of the k-NN model is likely to be biased (e.g., μ 0 >0, where it should already be 0, and μ 1 <k, where it should already be k). In addition, σ is not guaranteed 0 ＝＝σ 1 . Thus, similar to binary classification, in the case of multiclass classification, MPCs are clusteredPredicted frequency j The transformation f is applied up so that after transformation, the Residue of the two groups j Have substantially the same normal distribution. To achieve such a goal, the transform f needs to satisfy the following properties:
(i)f(μ 0 )＝0
(ii)f(μ 1 )＝k
(iii)σ 0 ×f′(μ 0 )＝σ 1 ×f′(μ 1 )
where f' is the derivative of f.
The above three properties are very similar to their counterparts in the binary classification case. In the case of multi-class classification, one example of a transformation having the above property that can be adopted is the shape f (x) = a 2 x 2 +a 1 x+a 0 Where f' (x) =2a 2 x+a 1 . In some examples, the MPC cluster can deterministically calculate the coefficients { a ] based on three linear equations from three constraints 2 ，a 1 ，a 0 Value of }:
(i)a′ 2 ＝σ 0 -σ 1
(ii)a′ 1 ＝2(σ 1 μ 1 -σ 0 μ 0 )
(iii)a′ 0 ＝μ 0 (μ 0 σ 0 +μ 0 σ 1 -2μ 1 σ 1 )
Note that the transformations for the binary and multiclass classifications are almost identical, the only difference being that in multiclass classifications with k-NN models, the value of D can be scaled up by a factor of k in some implementations.
Referring again to fig. 9, in some implementations, one or more of steps 912-916 may correspond to those described above with respect to defining enabling L-based adoption by an MPC cluster i And
The MPC cluster estimates a set of distribution parameters based on multiple real labels for multiple user profiles (912). For example, this may correspond to calculating the parameter μ as described above with respect to the MPC cluster based on the real label associated with the same user profile utilized in step 910 0 、σ 0 2 、σ 0 、μ 1 、σ 1 2 And σ 1 One or more operations performed by one or more of the above are similar or equivalent to one or more operations.
The MPC cluster derives a function based on the set of estimated distribution parameters (914). For example, this may correspond to a parameter or coefficient (such as { a } that effectively defines a function with respect to MPC cluster computations 2 ，a 1 ，a 0 }) of the first operation, one or more operations similar or equivalent to the first operation. Thus, in some implementations, to derive the function at step 914, the MPC cluster derives a set of parameters for the function, e.g., { a } 2 ，a 1 ，a 0 }。
The MPC cluster configures the first machine learning model to generate an initial prediction label given the user profile as input and applies the derived function to the initial prediction label to generate a prediction label for the user profile as output (916). For example, this may correspond to one or more operations similar or equivalent to one or more operations performed on the MPC cluster to configure the first machine learning model such that the forward first machine learning model application applies the corresponding transformation f to the sum of the true labels (in the case of binary classification) for the k nearest neighbor user profiles in response to the input. In the case of multiple classes, the transformation f may represent that the MPC cluster configures the first machine learning model as one of w different functions applied to a respective one of w different values in the vector or set corresponding to the w different classes. As described above, each of these w different values may correspond to a frequency value.
Where steps 912-916 have been performed and the first machine learning model has been configured in such a manner, the data generated in step 920 and subsequently utilized, for example, in step 930, may not be used to predict the true label (L) i )。
Referring again to fig. 8, in some implementations, process 800 may include one or more steps corresponding to one or more of the operations described above with reference to fig. 9-11.
In some implementations, the process 800 further includes one or more operations in which the MPC cluster evaluates performance of the first machine learning model. For example, this may correspond to one or more operations similar or equivalent to performing one or more operations with respect to the MPC cluster as performed at step 920 described above with reference to fig. 9. In these implementations, to evaluate performance of the first machine learning model, for each of the plurality of user profiles, the MPC cluster determines a prediction label for the user profile based at least in part on one or more of (i) the user profile, (ii) the first machine learning model, and (iii) a plurality of true labels for the plurality of user profiles, and determines a residual value for the user profile that indicates a prediction error in the prediction label based at least in part on the prediction label determined for the user profile and a true label for the user profile included in the plurality of true labels. For example, this may correspond to one or more operations similar or equivalent to performing one or more operations with respect to an MPC cluster as performed by steps 1108-1106 described above with reference to fig. 11. Additionally, in these implementations, the process 800 further includes one or more operations in which the MPC cluster trains a second machine learning model using data indicative of residual values determined for the plurality of user profiles in evaluating the performance of the first machine learning model. For example, this may correspond to one or more operations similar or equivalent to the one or more operations performed with respect to the MPC cluster to perform step 930 as described above with reference to fig. 9.
In at least some of the foregoing implementations, the residual value of the user profile indicates a difference in value between a predicted tag determined for the user profile and a true tag for the user profile. This may be the case, for example, for an example in which regression techniques are employed.
In at least some of the foregoing implementations, before the MPC cluster evaluates the performance of the first machine learning model, the process 800 further includes one or more operations in which the MPC cluster derives a function based at least in part on the plurality of real labels and configures the first machine learning model to use the function to generate a predicted label for the user profile as an output given the user profile as an input. For example, this may correspond to one or more operations similar or equivalent to performing one or more operations with respect to an MPC cluster as performed by steps 914-916 described above with reference to fig. 9. Thus, in some implementations, to derive the function at this step, the MPC cluster derives a set of parameters for the function, e.g., { a } 2 ，a 1 ，a 0 }。
In at least some of the foregoing implementations, the process 800 further includes one or more operations in which the MPC cluster estimates a set of distribution parameters based at least in part on the plurality of truth labels. In such implementations, to derive the function based at least in part on the plurality of real tags, the MPC cluster derives the function based at least in part on a set of estimates of the distribution parameters. This may correspond, for example, to one or more operations similar or equivalent to the one or more operations performed by the MPC cluster as described above with reference to fig. 9 by the steps 912-914. Thus, the aforementioned set of distribution parameters can include one or more parameters of a probability distribution of the prediction error of the real tag of the first value of the plurality of real tags, e.g., a mean (μ) of a normal distribution of the prediction error of the real tag of the first value of the plurality of real tags 0 ) Sum variance (σ) 0 ) And true of the second value in the plurality of genuine tagsOne or more parameters of the probability distribution of the prediction error of the real label, for example, a mean (μ) of a normal distribution of the prediction error of the real label of a second different value among the plurality of real labels 1 ) Sum variance (σ) 1 ). As described above, in some examples, the aforementioned set of distribution parameters can include other types of parameters. Further, in at least some of the foregoing implementations, the function is a quadratic polynomial function, e.g., f (x) = a 2 x 2 +a 1 x+a 0 Wherein f' (x) =2a 2 x+a 1 。
In at least some of the foregoing implementations, to configure the first machine learning model to use the function to generate as output a predictive label for the user profile given the user profile as input, the MPC cluster configures the first machine learning model to, given the user profile as input: (i) Generate an initial predictive tag for the user profile, and (ii) apply a function to the initial predictive tag for the user profile to generate as output the predictive tag for the user profile. For example, for an example in which a binary classification technique is employed, this may correspond to one or more of the following operations, where the MPC cluster configures the first machine learning model to take as input the user profile: (i) Calculating a sum of true labels (sum of labels) for k nearest neighbor user profiles, and (ii) applying a function (transform f) to the initial predicted labels for the user profiles to generate predicted labels for the user profiles
As mentioned above, in some of the foregoing implementations, to determine the predicted labels based at least in part on the real labels for each of the k nearest neighbor user profiles, the MPC cluster determines a set of predicted labels based at least in part on a set of real labels for each of the k nearest neighbor user profiles that respectively correspond to a set of classes, and to determine the set of predicted labels, the MPC cluster performs an operation on each class in the set. Such operations can include one or more operations in which the MPC cluster determines a frequency of real tags corresponding to a class, of the set of real tags for a user profile of the k nearest neighbor user profiles, to be real tags of a first value. For example, this can correspond to obtaining at least one predictive label 629 utilizing first machine learning model 620 in connection with one or more implementations in which one or more multi-class classification techniques are employed
FIG. 12 is a flow diagram illustrating an example process 1200 for generating inference results for a user profile at a computing system of an MPC cluster with enhanced performance. One or more of the operations described with reference to fig. 12 may be performed, for example, at inferred times. At least some of the operations of the process 1200 can be performed, for example, by an MPC such as the MPC cluster 130 of fig. 1 1 And can also correspond to one or more of the operations described above with reference to fig. 8. However, in process 1200, one or more operations can be performed on the secret share to provide user data privacy protection. In general, in at least some implementations, "shares" as described below and elsewhere herein can correspond to secret shares. Other configurations are possible. One or more of the operations described with reference to fig. 12 may be performed, for example, at inferred times.
A first computing system of the MPC cluster receives an inference request associated with a given user profile (1202). For example, this may correspond to MPC as related to MPC cluster 130 1 One or more operations similar or equivalent to the one or more operations that the inference request was received from application 112, as described above with reference to fig. 1. In some implementations, this may correspond to one or more operations similar or equivalent to one or more operations performed with respect to step 802 as described above with reference to fig. 8.
A first computing system of the MPC cluster determines a predictive label for a given user profile (1204-1208). The tags can be or include demographic-based user group identifiers or demographic characteristics associated with the user profile. In some implementations of the above-described embodiments,this may correspond to one or more operations similar or equivalent to one or more operations performed with respect to step 804 as described above with reference to fig. 8. However, in steps 1204-1208, the determination of the predictive tag for a given user profile can be performed on secret shares in order to provide user data privacy protection. To determine a predictive label for a given user profile, a first computing system of the MPC cluster (i) determines a first share of predictive labels based at least in part on a first share of the given user profile, a first machine learning model trained using a plurality of user profiles, and one or more real labels of a plurality of real labels for the plurality of user profiles (1204), (ii) receives, from a second computing system of the MPC cluster, data indicative of a second share of predictive labels determined by a second computing system of the MPC cluster based at least in part on a second share of the given user profile and a first set of one or more machine learning models, and (iii) determines the predictive label based at least in part on the first and second shares of predictive labels (1208). For example, the second computing system of the MPC cluster may correspond to the MPCs of MPC cluster 130 of fig. 1 2 。
In this example, the plurality of true tags for the plurality of user profiles may correspond to the true tags included as part of the encrypted tag data 626 for the plurality of user profiles used to train and/or evaluate the first machine learning model 620. In some examples, the plurality of real tags may correspond to shares of another set of real tags. One or more real tags from among the plurality of real tags on which the predicted tag for a given user profile is determined may include, for example, at least one real tag for each of the k nearest neighbor user profiles identified by the k-NN model 622 of the first machine learning model 620. In some examples, each of the plurality of authentic tags is encrypted, as is the case in the examples of fig. 6-7. Some of the various ways in which the predicted labels can be determined using the real labels for the k nearest neighbor user profiles are described in detail above. As becomes apparent above, the manner or method by which such true tags are utilized to determine predictive tags may depend, at least in part, on the type of inference technique employed (e.g., regression techniques, binary classification techniques, multi-class classification techniques, etc.). Additional details regarding the secret share exchange that may be performed in association with the k-NN computation are provided above with reference to fig. 1-5.
A first computing system of the MPC cluster determines prediction residual values indicative of prediction errors in the prediction labels (1210-1214). In some implementations, this may correspond to one or more operations similar or equivalent to one or more operations performed with respect to step 806 as described above with reference to fig. 8. However, in steps 1210-1214, the determination of the prediction residual values can be performed on secret shares in order to provide user data privacy protection. To determine the predicted residual values, a first computing system of the MPC cluster (i) determines a first share of predicted residual values for the given user profile based at least in part on the first share of the given user profile and a second machine learning model trained using the plurality of user profiles and data indicative of differences between a plurality of real labels for the plurality of user profiles and a plurality of predicted labels as determined for the plurality of user profiles using the first machine model (1210), (ii) receives data from a second computing system of the MPC cluster indicative of a second share of predicted residual values for the given user profile determined by the second computing system of the MPC cluster based at least in part on the second share of the given user profile and a second set of one or more machine learning models (1212), and (iii) determines the predicted residual values for the given user profile based at least in part on the first share and the second share of predicted residual values (1214).
The first computing system of the MPC cluster generates data representing the inference result based on the prediction labels and the prediction residual values (1216). In some implementations, this may correspond to one or more operations similar or equivalent to those performed with respect to step 808 as described above with reference to fig. 8. Thus, in some examples, the inference result includes or corresponds to a sum of the prediction tag and the prediction residual value.
The first computing system of the MPC cluster provides data representing the inference to the client device (1218). In some implementations, this may correspond to one or more operations similar or equivalent to one or more operations performed with respect to step 810 as described above with reference to fig. 8. For example, this may correspond to one or more operations similar or equivalent to one or more operations performed in connection with the MPC cluster 130 providing inferred results to the client devices 110 on which the applications 112 run, as described above with reference to fig. 1-2.
In some implementations, the process 1200 further includes one or more operations in which the first computing system of the MPC cluster applies a transformation to the first share of the given user profile to obtain a first transformed share of the given user profile. In these implementations, to determine the predictive label, the first computing system of the MPC cluster determines a first share of the predictive label based at least in part on the first transformed share of the given user profile. For example, this may correspond to a user profile 609 (P) with respect to employing random projection logic 610 i ) Applying a stochastic projection transform to obtain a transformed user profile 619 (P) i ') one or more operations similar or equivalent to the one or more operations performed, as described above with reference to figures 6-8.
In at least some of the foregoing implementations, to determine the first share of the predictive tag, the first computing system of the MPC cluster provides the first transformed share of the given user profile as input to the first machine learning model to obtain the first share of the predictive tag for the given user profile as output. For example, this may correspond to receiving a transformed user profile 619 (P) with respect to the first machine learning model 620 i ') as input and in response thereto generate at least one predictive tag 629
In some examples, the aforementioned transformation may be a random projection. Further, in at least some of these examples, the aforementioned stochastic projection may be a Johnson-Lindenstaus (J-L) transform.
In some implementations, to apply the J-L transform, the MPC cluster can generate the projection matrix R in ciphertext. To measure n dimension P i Projected into the k dimension, the MPC cluster can generate an n k random matrix R. For example, a first computing system (e.g., MPC) 1 ) Can create an n x k random matrix A, where A i,j With 50% probability =1 and a i,j With 50% probability =0. The first computing system can split A into two shares [ A 1 ]And [ A ] 2 ]Discard A, keep secret [ A 1 ]And will [ A ] 2 ]To a second computing system (e.g., MPC) 2 ). Similarly, the second computing system can create an n × k random matrix B whose elements have the same distribution of elements of a. The second computing system can split B into two shares [ B [ ] 1 ]And [ B 2 ]Discard B, keep secret [ B 2 ]And will [ B ] 1 ]To the first computing system.
The first computing system can then compare [ R 1 ]Calculated as 2 × ([ A ] 1 ]＝＝[B 1 ]) -1. Similarly, the second computing system can then compare [ R [ ] 2 ]Calculated as 2 × ([ A ] 2 ]＝＝[B 2 ]) -1. In this way, [ R ] 1 ]And [ R ] 2 ]Are two secret shares of R whose elements have equal probability of 1 or-1.
Actual random projection of P in dimension 1 × n i And the projection matrix R of dimension n × k to yield a 1 × k result. Assuming n > k, the J-L transform reduces the dimensionality of the training data from n to k. To perform the above projection in the encrypted data, the first computing system can calculate [ P [ ] i,1 ]⊙[R i,1 ]This requires multiplication between two shares and addition between two shares.
As mentioned above, in some implementations, the first machine learning model includes a k-nearest neighbor model maintained by a first computing system of the MPC cluster, and the first set of one or more machine learning models includes a k-nearest neighbor model maintained by a second computing system of the MPC cluster. In some examples, the two aforementioned k-nearest neighbor models may be the same or nearly the same as each other. That is, in some examples, the first computing system and the second computing system maintain copies of the same k-NN model and each store their own share of real tags. In some examples, models rooted in one or more prototype methods may be implemented in place of one or both of the aforementioned k-nearest neighbor models.
In at least some of these implementations, to determine the predictive label, the first computing system of the MPC cluster (i) identifies a first set of nearest neighbor user profiles based at least in part on the first share of the given user profile and a k-nearest neighbor model maintained by the first computing system of the MPC cluster, (ii) receives, from the second computing system of the MPC cluster, data indicative of a second set of nearest neighbor profiles identified by the second computing system of the MPC cluster based at least in part on the second share of the given user profile and the k-nearest neighbor model maintained by the second computing system of the MPC cluster, (iii) identifies k nearest neighbor user profiles deemed most similar to the given user profile among the plurality of user profiles based at least in part on the first set and the second set of nearest neighbor profiles, and determines the first share of the predictive label based at least in part on a true label for each of the k nearest neighbor user profiles. For example, this can correspond to obtaining the at least one predictive label 629 utilizing the first machine learning model 620 in connection with one or more implementations in which one or more regression and/or binary classification techniques are employed
In some of the foregoing implementations, to determine the first share of predicted labels, the first computing system of the MPC cluster (i) determines a first share of the sum of the real labels for the k nearest neighbor user profiles, (ii) receives a second share of the sum of the real labels for the k nearest neighbor user profiles from the second computing system of the MPC cluster, and (iii)Determining a sum of real tags for the k nearest neighbor user profiles based at least in part on the first share and the second share of the sum of real tags for the k nearest neighbor user profiles. For example, this can correspond to obtaining at least one predictive label 629 utilizing the first machine learning model 620 in connection with one or more implementations in which one or more multi-class classification techniques are employed
In some implementations, the second machine learning model includes at least one of a Deep Neural Network (DNN), a Gradient Boosting Decision Tree (GBDT), and a random forest model maintained by the first computing system of the MPC cluster, and the second set of one or more machine learning models includes at least one of a DNN, a GBDT, and a random forest model maintained by the second computing system of the MPC cluster. In some examples, the two models maintained by the first and second computing systems (e.g., DNNs, GBDTs, random forest models, etc.) may be the same or nearly the same as each other.
In some implementations, the process 1200 further includes one or more operations in which the MPC cluster evaluates performance of the first machine learning model and trains the second machine learning model using data indicative of the predicted residual values determined for the plurality of user profiles in evaluating performance of the first machine learning model. For example, this may correspond to one or more operations similar or equivalent to one or more operations performed with respect to the MPC cluster to perform step 920 as described above with reference to fig. 8-9. However, in such implementations, one or more operations can be performed on the secret shares to provide user data privacy protection. In these implementations, to evaluate the performance of the first machine learning model, for each of a plurality of user profiles, the MPC cluster determines a prediction label for the user profile and determines a residual value of the user profile indicative of a prediction error in the prediction label. To determine the predictive label for the user profile, the first computing system of the MPC cluster (i) determines a first share of the predictive label for the user profile based at least in part on the first share of the user profile, the first machine learning model, and one or more of the real labels for the plurality of user profiles, (ii) receives, from the second computing system of the MPC cluster, data indicative of a second share of the predictive label for the user profile determined by the second computing system of the MPC cluster based at least in part on the second share of the user profile and a first set of one or more machine learning models maintained by the second computing system of the MPC cluster, and (iii) determines the predictive label for the user profile based at least in part on the first share and the second share of the predictive label. To determine a residual value of the user profile indicative of an error in the prediction label, the first computing system of the MPC cluster (i) determines a first share of residual values of the user profile based at least in part on the prediction label determined for the user profile and a first share of real labels for the user profile included in the plurality of real labels, (ii) receives, from the second computing system of the MPC cluster, data indicative of a second share of residual values of the user profile determined by the second computing system of the MPC cluster based at least in part on the prediction label determined for the user profile and a second share of real labels for the user profile, and (iii) determines a residual value of the user profile based at least in part on the first and second shares of residual values. For example, this may correspond to one or more operations similar or equivalent to performing one or more operations with respect to an MPC cluster as performed by steps 1108-1106 described above with reference to fig. 11. Additionally, in these implementations, the process 1200 further includes one or more operations in which the MPC cluster trains a second machine learning model using data indicative of residual values determined for the plurality of user profiles in evaluating performance of the first machine learning model. For example, this may correspond to one or more operations similar or equivalent to the one or more operations performed with respect to the MPC cluster to perform step 930 as described above with reference to fig. 9.
In at least some of the foregoing implementations, the first share of residual values of the user profile indicates a difference in value between a predicted tag determined by the first machine learning model for the user profile and a first share of true tags for the user profile, and the second share of residual values of the user profile indicates a difference in value between a predicted tag determined by the first machine learning model for the user profile and a second share of true tags for the user profile. This may be the case, for example, for an example in which regression techniques are employed.
In at least some of the foregoing implementations, the process 1200 further includes one or more operations before the MPC cluster evaluates the performance of the first machine learning model, wherein the MPC cluster (i) derives a function and (ii) configures the first machine learning model to generate an initial prediction label for the user profile given the user profile as an input and applies the function to the initial prediction label for the user profile to generate a first share of the prediction label for the user profile as an output. For example, this may correspond to one or more operations similar or equivalent to the one or more operations performed with respect to the MPC cluster as performed by steps 914-916 described above with reference to fig. 8-9. To derive the function, a first computing system of the MPC cluster (i) derives a first share of the function based at least in part on the first share of each of the plurality of real tags, (ii) receives, from a second computing system of the MPC cluster, data indicative of a second share of the function derived by the second computing system of the MPC cluster based at least in part on the second share of each of the plurality of real tags, and (iii) derives the function based at least in part on the first share and the second share of the function. For example, for an example in which a binary classification technique is employed, this may correspond to one or more of the following operations, where the MPC cluster configures the first machine learning model to take as input the user profile: (i) Calculating a sum of true labels (sum of labels) for k nearest neighbor user profiles, and (ii) applying a function (transform f) to the initial predicted labels for the user profiles to generate predicted labels for the user profiles
When implemented on secret shares, a first computing system (e.g., MPC) 1 ) It is possible to calculate:
[count 0，1 ]＝∑ i (1-[L i，1 ])
similarly, when implemented on a secret share, a second computing system (e.g., MPC) 2 ) It is possible to calculate:
[count 0，2 ]＝∑ i (1-[L i，2 ])
the MPC cluster can then reconstruct sum as described above in the clear 0 、count 0 、sum_of_square 0 And calculating the distribution
Similarly, to calculate the distribution
[count 1，1 ]＝∑ i [L i，1 ]
and, a second computing system (e.g., MPC) 2 ) It is possible to calculate:
[count 1，2 ]＝∑ i [L i，2 ]
the MPC cluster can then reconstruct sum as described above in the clear 1 、count 1 、sum_of_square 1 And calculating the distribution
In at least some of the foregoing implementations, the MPC cluster can employ one or more fixed point computation techniques to determine the residual value for each user profile when evaluating the performance of the first machine learning model. More specifically, when evaluating the performance of the first machine learning model, to determine a first share of the residual values for each user profile, the first computing system of the MPC cluster scales the corresponding true label or share thereof by a particular scaling factor, scaling a coefficient { a } associated with the function by the particular scaling factor 2 ,a 1 ,a 0 And rounding the scaled coefficients to the nearest integer. In such implementations, a second computing system of the MPC cluster may perform similar operations to determine a second share of the residual values for each user profile. The MPC cluster can thus compute the residual values with the secret shares, reconstruct the plaintext residual values from the two secret shares, and divide the plaintext residual values by the scaling factor.
In at least some of the foregoing implementations, the process 1200 further includes one or more operations in which the first computing system of the MPC cluster estimates a first share of the set of distribution parameters based at least in part on the first share of each of the plurality of real tags. In some such implementations, to derive the first share of the function based at least in part on the first share of each of the plurality of real tags, the first computing system of the MPC cluster derives the first share of the function based at least on the first share of the set of distribution parameters. For example, this may correspond to one or more operations similar or equivalent to the one or more operations performed with respect to the MPC cluster as performed by steps 912-914 described above with reference to fig. 8-9. Thus, the aforementioned set of distribution parameters can comprise one or more parameters of a probability distribution of the prediction error of the real label of the first value of the plurality of real labels, e.g. the mean (μ) of a normal distribution of the prediction error of the real label of the first value of the plurality of real labels 0 ) Sum variance (σ) 0 ) And one or more parameters of a probability distribution of the prediction error of the genuine tag of a second value among the plurality of genuine tags, for example, a mean (μ) of a normal distribution of the prediction error of the genuine tag of a second different value among the plurality of genuine tags 1 ) Sum variance (σ) 1 ). As described above, in some examples, the aforementioned set of distribution parameters can include other types of parameters. Further, in at least some of the foregoing implementations, the function is a quadratic polynomial function, e.g., f (x) = a 2 x 2 +a 1 x+a 0 Wherein f' (x) =2a 2 x+a 1 However, in some examples, other functions may be employed.
In some examples, to determine the first share of predicted labels, the first computing system of the MPC cluster (i) determines a first share of the sum of real labels for the k nearest neighbor user profiles, (ii) receives, from the second computing system of the MPC cluster, a second share of the sum of real labels for the k nearest neighbor user profiles, and (iii) is based at least in part on the first share and the second share of the sum of real labels for the k nearest neighbor user profilesTwo shares to determine the sum of the true labels for the k nearest neighbor user profiles. This may be the case, for example, with implementations employing regression or binary classification techniques. In some of the foregoing examples, the first share of predicted labels may correspond to a sum of real labels for the k nearest neighbor user profiles. For example, this may be the case for implementations in which regression classification techniques are employed
As mentioned above, in some of the foregoing implementations, to determine the first share of the set of predicted labels based at least in part on the real labels for each of the k nearest neighbor user profiles, the first computing system of the MPC cluster determines the first share of the set of predicted labels based at least in part on the set of real labels for each of the k nearest neighbor user profiles corresponding to the set of categories. To determine a first share of a set of predicted labels, for each category in the set, a first computing system of the MPC cluster (i) determines a first share of frequencies of real labels of the set of real labels for a user profile of the k nearest neighbor user profiles that correspond to the category that are first values of real labels, (ii) receives a second share of frequencies of real labels of the set of real labels for a user profile of the k nearest neighbor user profiles that correspond to the category that are first values of real labels, and (iii) determines a first share of frequencies of real labels for the k nearest neighbor user profiles that correspond to the category that are first values based at least in part on the first and second shares of frequencies of real labels of the set of real labels for a user profile of the k nearest neighbor user profile that correspond to the category that are first values of real labels The real tag corresponding to the category in the set of real tags of the user profile in (1) is a frequency of the real tag of the first value. Such operations can include one or more operations in which a first computing system of the MPC cluster determines a frequency for which, for a set of real tags of a user profile of the k nearest neighbor user profiles, a real tag corresponding to the category is a real tag of a first value. For example, this can correspond to obtaining at least one predictive label 629 utilizing first machine learning model 620 in connection with one or more implementations in which one or more multi-class classification techniques are employed
In at least some of the foregoing implementations, to determine the first share of the set of predicted labels, for each category in the set, the first computing system of the MPC cluster applies a function corresponding to the category to a frequency of real labels in the set of real labels for the user profile in the k nearest neighbor user profiles that the real label corresponding to the category is a first value to generate the first share of predicted labels corresponding to the category for the given user profile. For example, the respective function may correspond to one of w different functions derived by the MPC cluster for w different classes as described above with reference to step 914 of fig. 8-9.
For a multiclass classification problem, when evaluating the performance (e.g., quality) of the first machine learning model, for each training example/query, the MPC cluster can find the k nearest neighbors and compute the frequency of its labels on secret shares.
For example, consider a case where it is assumed that there are w valid labels (e.g., classes) { l ] for a multi-class classification problem 1 ,l 2 ,...l w An example of (c). In the passing of { id 1 ,id 2 ,...id k Among the k neighbors identified, the first computing system (e.g., MPC) 1 ) Can be taken as [ l j , 1 ]The frequency of the jth tag of (a) is calculated as:
the first computing system can be enabled to determine a tag [ label ] from the real tag 1 ]The frequency is calculated as:
[expected_frequency j，1 ]＝k×([label 1 ]＝＝j)
thus, the first computing system is able to compute:
[Residue j，1 ]＝[expected_frequency j，1 ]-[frequency j，1 ]
and, [ Residue j,1 ]Equivalent to:
similarly, a second computing system (e.g., MPC) 2 ) It is possible to calculate:
in the case of binary classification and regression, the residual values may be an integer type of secret message for each inference. Conversely, in the case of multi-class classification, the residual values may be secret messages of integer vectors for each inference, as shown above.
Demographic reports
The digital component provider 160 may have several activities (e.g., digital component distribution activities) that may involve different digital components. For each activity and digital component displayed to various users on client device 110, digital component provider 160 may desire feedback indicating performance of the digital component or the activity that includes the digital component. To provide such feedback, the content platform 150 can implement demographic reports to generate and provide reports to the digital component providers 160 indicating the effectiveness of each activity and/or each digital component for various demographic-based user groups. In one example, the report can include a table, such as the table shown in table 7 below, and the analysis associated with the data shown in the table. Each content provider 160 is displayed one or more reports specific to the campaign and/or digital components for that particular content provider 160.
TABLE 7
Although the digital component providers 160 shown reporting are described as including a plurality of activities involving one or more digital components, in other implementations any digital component provider 160 may have any number of activities, any demographic category (e.g., age range, gender, parental identity, household income, lifestyle interests, such as hobbyists, sports fans, cooking enthusiasts, etc.), segment markets such as product purchasing interests, and/or any other category), and any type of event or any combination of events (e.g., show, click-through and/or conversion, and/or lack thereof). The analysis generated for each report can vary accordingly. The demographic categories can correspond to groups of users to which various users have been assigned by way of expansion or self-reporting.
Because the data in the table (e.g., table 7) is computed for all users collectively, rather than individually for individual users, the privacy of individual users is preserved.
In some implementations, additional or alternative privacy safeguards can be implemented for demographic reports, such as differential noise addition, de-identification of records, k-anonymization, granularity-based techniques, and so forth as explained below. For differential noise addition, the application 112, secure MPC cluster 130, content platform 150, and/or aggregation system 180 can add a controllable amount of differential noise from a preset distribution (e.g., laplacian or gaussian distribution) to one or more functions that relate to the user's private data (e.g., identifying information such as IP addresses and/or timestamps). For de-identification of records, the application 112 can simply send a set of records without any identifying information such as an IP address and/or a timestamp. To de-identify the record, the application 112 and/or the content platform 150 may remove the identification information. For k-anonymization, the application 112, secure MPC cluster 130, content platform 150, and/or aggregation system 180 can implement a k-anonymization technique in which at least "k" number of values of user attributes within user data can be anonymized to enhance privacy, and operations such as aggregation can be performed on the anonymized data. K-anonymity requires that reports be aggregated on a given key and only revealed if the key is shared with at least K records. For granularity-based technologies, the application 112 can be programmed to allow the digital component provider 160 to specify the granularity needed for reporting (e.g., time-based granularity such as a day or an hour, or geographic granularity such as a particular state, province, city, or country), and the application 112, secure MPC cluster 130, content platform 150, and/or aggregation system 180 can perform computations for the specified granularity.
System for demographic reporting
Data presented in the report (e.g., the number of impressions, clicks, and/or conversions within each of the various demographic categories and/or the absence/absence of impressions, clicks, and/or conversions) can be generated using a third party cookie. However, to avoid cookies in order to protect user privacy, reporting is performed using the system of the environment 100 (which can also be referred to as a framework).
The content platform 150 (e.g., a DSP or SSP, and in some implementations a separate reporting platform) can receive data from the digital component provider 160 identifying activities involving the digital component and a first set of one or more demographic categories for which the digital component provider 160 desires demographic reporting. The digital component provider 160 can input this data onto an application (e.g., a browser or native application). The first set of categories may include, for example, women and income greater than $ 100,000. In some implementations, the data identifying the activity and the first set of one or more demographic categories can be included in an aggregation key, which can be a composite or cascade key having a plurality of values or columns of values. These values can be data identifying activities, and each column can represent a different demographic category.
The content platform 150 (e.g., DSP or SSP, and in some implementations a separate reporting platform coupled to the content platform 150) can associate a user of the client device 110 on which the digital component is (or will be) displayed with a second set of one or more demographic categories. In one example, the second set of one or more demographic categories includes women, parents, and income greater than $ 100,000. The association can be performed in at least one of the following two ways. In a first manner, the content platform 150 (or a separate reporting platform in some implementations) can receive a self-identification of the second set of one or more demographic categories provided by the user on the application 112 implemented on the client device 110, and then the content platform 150 (or a separate reporting platform in some implementations) can map the user to the second set of one or more demographic categories to perform the association. In a second manner, the content platform 150 can communicate the user's browsing history to the MPC cluster 130 (e.g., the browsing history can be or include a user profile that the content platform 150 can communicate to the MPC cluster 130 at processes 210 and 212 of fig. 2); the content platform 150 (or a separate reporting platform in some implementations) can then receive an inference from a machine learning model within the MPC cluster 130 that includes a second set of demographic categories output by the machine learning model; and then the content platform 150 (or a separate reporting platform in some implementations) can map the user to a second set of one or more demographic categories to perform the association.
This machine learning model can be a k-nearest neighbor model, and can use the modeling techniques described above with respect to the demographic-based digital component distribution. However, this machine learning model for reporting can be trained using different data from one or more machine learning models for demographic-based digital component distribution, as machine learning is used for demographic-based digital component distribution and reporting for different purposes. For example, in the case of demographic-based digital component distribution, the purpose of machine learning is to propose groups of users to users or to users' applications (e.g., browsers) so that relevant digital components of interest to the users can be displayed to the users, whereas in the case of demographic reports, the purpose of machine learning is to determine in the report to the digital component provider 160 the categories (which can also be referred to as buckets) into which users that have displayed digital components can be placed. In view of these different objectives, machine learning models for demographic-based digital component distribution and reporting are trained differently, and therefore generate different outputs (i.e., categorizing the same probabilistic output into different categories — i.e., categorizing users differently). For example, a machine learning model for demographic-based digital component distribution may always classify an output as male with a 95% probability, but a reporting model may report 100 users as 95 males and 5 females with a total 95% probability of male; in such an example, the MPC cluster 130 may be softer (i.e., easier or less stringent) for reporting purposes than for demographic-based digital component distribution purposes in terms of commitment to a particular label. The content platform 150 can control or change this stringency for categorization for machine learning models implemented in the MPC cluster 130 for demographic-based digital component distribution and/or reporting. In some implementations, a separate reporting platform can control or change this strictness for classification for machine learning models implemented in the MPC cluster 130 for reporting.
While machine learning models are described as being trained differently for demographic-based digital component distribution and demographic reporting, in some implementations those machine learning models may be trained similarly or even in the same manner. Further, while the machine learning model for demographic-based digital component distribution and demographic reporting is shown as residing in the MPC cluster 130, in some other implementations, the machine learning model for demographic-based digital component distribution and/or reporting can be implemented on the client device 110 such that the categorization of users into demographic groups occurs on the client device 110 rather than the MPC cluster 130. These implementations are typically implemented where the client device 110 has sufficient storage capacity and computing power. Such alternative implementations can advantageously save bandwidth by preventing significant communication with the MPC cluster 130.
If a first set of one or more demographic categories (representing demographic categories for which the digital component provider 160 desires demographic reporting; e.g., women and income greater than $ 100,000 as data input by the digital component provider 160 onto the application 112) and a second set of one or more demographic categories (representing inferences about a user's group of users as generated by machine learning or a user group self-identified by the user on the application 112; e.g., women, parents, and income greater than $ 100,000) have at least one common demographic category (e.g., women and a demographic category with income greater than $ 100,000), the content platform 150 (or in some implementations a separate reporting platform) can communicate to the aggregation API the browsing events (e.g., presentation, clicks and/or conversions, and/or lack/absence thereof) input on the client device 110 and the at least one common demographic category. In the example given above for the first set of one or more demographic categories and the second set of one or more demographic categories, note that women and categories with income greater than $ X are common. Thus, in such an example, the content platform 150 (or a separate reporting platform in some implementations) communicates the browsing events (e.g., impressions, clicks and/or conversions, and/or lack/absence thereof) entered on the client device 110 and the data identifying the common demographic category to the aggregation API.
In some implementations, the report can be in response to a request made by the digital content provider 160. In some implementations, the report can be in response to a request from the content platform 150. In some implementations, the report can be in response to a particular type of user interaction (e.g., a display of particular digital content such as the content item, one or more clicks on the digital content item, a conversion associated with the digital content item, such as navigating to a product purchase webpage for purchasing a product promoted using the digital content item, etc.).
The aggregation API combines the browsing events (e.g., impressions, clicks and/or conversions, and/or lack/absence thereof) and the at least one common demographic category with at least one browsing event of the other user and a related at least one demographic category that is one demographic category in the first set of one or more demographic categories to generate aggregated data. In the example used above, the aggregation API combines data for browsing events for females and categories with a revenue greater than $ X with browsing events for other users within the females and categories with a revenue greater than $ X, as opposed to this digital component. In this example, aggregation does not account for a parental non-common category (i.e., not common between the first set of one or more demographic categories and the second set of one or more demographic categories) because the digital component provider expects reports for only females and a specified category that is more than $ X in revenue rather than a parental category. In some examples, the aggregated data can be the same or similar table as table 7 discussed above. The polymerization can polymerize the data for a predetermined amount of time (e.g., 1 hour, 12 hours, 1 day, 2 days, 5 days, 1 month, or any other period of time). For example, in table 7, the counts of impressions, clicks, and conversions are daily.
Aggregation is performed in a secure manner to prevent fraud and protect user privacy as follows. The aggregation API communicates with the aggregation system 180. Aggregation system 180 can be one or more computers communicatively coupled to content platform 150, a separate reporting platform, client device 110, website 142, publisher 140, and/or digital component provider 160. The aggregation system 180 can generate aggregated network measurements based on data received from the client devices 110. In some implementations, the data to be aggregated is sent to the aggregation system by an application 112, which application 112 can be a web browser or a native application. In several implementations, the data to be aggregated can be sent by the operating system of the client device 110 to the aggregation system; in such implementations, the web browser and/or native application on the client device 110 can be configured to report the presentation, click-through, and/or conversion to the operating system. The operating system is capable of performing each of the operations for report exposure and translation described below as being performed by the application 112.
The application 112 on the client device 110 can provide the aggregation system 180 with measurement data elements that include encrypted data representing network data. The network data can include data about the presentation, click-through, and/or conversion. For example, the application 112 can generate and send measurement data elements for each conversion for which conversion data is stored at the client device 110 to the aggregation system 180. For each of the one or more digital components, the aggregated network measurement can include a total number of impressions, clicks, and/or conversions of the digital component across the plurality of client devices 110.
The applications 112, secure MPC cluster 130, content platform 150, and/or aggregation system 180 can protect privacy by implementing various techniques such as a threshold scheme or two-party or other MPC computing system as described below.
In some implementations, the application 112 can use a (t, n) threshold scheme to generate data in the measurement data elements. In some implementations, when the application 112 detects a conversion or receives conversion data for a conversion, the application 112 generates a group key (e.g., a polynomial function) based on the data regarding the presentation, click, and/or conversion. The application 112 can then generate a group member key that represents a portion of the group key and can be used to regenerate the group key only when a sufficient number of group member keys are received for the same set of impressions, clicks, and conversions. In this example, the measurement data elements for a conversion can include a group membership key generated by the application 112 and tags corresponding to the set of impressions, clicks, and conversions. Each unique set of impressions, clicks, and conversions can have a corresponding unique tag such that the aggregation system 180 can use its tags to aggregate the measurement data elements for each set of impressions, clicks, and/or conversions.
In a (t, n) threshold encryption scheme, the aggregation server will need to receive at least t group membership keys for the same set of impressions, clicks and/or conversions in order to be able to decrypt the impressions and conversion data. If less than t group member keys are received, the aggregation server is unable to decrypt data regarding the presentation, click and/or conversion. Upon receiving at least t measurement data elements for the same exposure and conversion pair from the client device 110, the aggregation system 180 is able to determine a group key from the at least t group member keys and obtain the exposure and conversion data from the group key.
Threshold encryption techniques, such as (t, n) threshold encryption schemes, can use network data (e.g., presentation, click-and/or conversion data) or a portion or derivative thereof as a seed for generating a group key that is then split between multiple applications (e.g., web browsers or native applications) of multiple client devices reporting that network data is being measured. This enables each of the applications running on different client devices to generate the same group key that uses the same network data to encrypt the network data without cooperation between the applications (or client devices) and without requiring the central system to distribute the key to each application. Alternatively, each application at which a network event (e.g., a presentation and associated conversion) occurs can use the network data it receives, for example, from the digital component and/or a remote server to generate a group key that encrypts the network data.
Each application can use different information to generate a group member key that, when combined with a sufficient number of other group member keys, can be used to regenerate the group key or another representation of the group key. For example, each application can use the unique identifier of the application to generate its group membership key, such that each application generates a different group membership key than each other application without cooperation between the applications. This generation of different group member keys by each application enables the group key to be regenerated upon receipt of any combination of group member keys that add up to at least a threshold "t" number of group member keys. Thus, the network data can be decrypted when at least t group member keys are received, but cannot be decrypted if less than t group member keys are received. By enabling such secret sharing between applications without cooperation between the applications, user privacy is protected by excluding communications between the user's devices, bandwidth consumed by such communications is reduced, and metering fraud that can occur when a single private key is simply passed out to each application is prevented.
The aggregation system 180 can determine the number of clicks and/or conversions for a presentation based on the number of received measurement data elements that include data regarding the presentation, clicks and/or conversions for the set of presentations, clicks and/or conversions. For example, after obtaining the presentation, click and conversion data using at least t group member keys, the aggregation system 180 can determine a count of the number of group member keys received for the set of presentations, clicks and/or conversions as the number of conversions. The aggregation system 180 can report data regarding the impressions, clicks, and/or conversions to the content platform 150 (or a separate reporting platform in some implementations) via an aggregation API.
The content platform 150 (or a separate reporting platform in some implementations) can receive the syndication data from the syndication API. The content platform 150 (or a separate reporting platform in some implementations) can use the aggregated data to generate reports. To generate the report, content platform 150 (or a separate reporting platform in some implementations) can arrange the aggregated data in a table (e.g., the table of table 7 or a similar table), generate an analysis based on the aggregated data in the table, and combine and present the table and analysis in the report. Because the data in the tables (e.g., table 7) and reports is computed for all users collectively, rather than individually for individual users, and because such tables or reports are not controlled by the application 112, vendor, privacy expert, or any other such entity, such reports protect user privacy and prevent leakage of user data while avoiding the use of cookies. The content platform 150 (or a separate reporting platform in some implementations) can communicate reports of the aggregated data to an application (e.g., a browser or native application) of the digital component provider 160. The report can be presented on a user interface displayed by an application implemented on a computing device of the digital component provider 160.
The content platform 150 (or a separate reporting platform in some implementations) can generate reports in response to requests to generate reports. In some implementations, the content platform 150 (or a separate reporting platform in some implementations) can receive a request for a report from the digital content provider 160. In one example consistent with these implementations, the digital component provider 160 may request a report for a particular digital component of the digital component provider 160. In another example, the digital component provider may request reports for several digital components of the digital component provider 160. In yet another example, the digital component provider may request a report for one or more activities of the digital component provider 160. In some examples, the digital component provider 160 may request a report by specifying one or more campaign IDs, one or more digital component IDs, one or more demographic user group IDs, and/or one or more events for which a report is desired (e.g., impressions, click-throughs, and/or conversions, and/or lack/absence thereof). In other implementations, the request for generation of the report can be automatically generated. The automatic generation of the request by the script can occur at (a) a preset time interval and/or (b) when a count of one or more events associated with a digital component or activity of the content provider 160, such as a show, click and/or conversion, and/or lack/absence thereof, exceeds a particular threshold (e.g., when the number of clicks by women exceeds 1000). In some implementations, the script can (a) respond to requests from content providers and/or (b) automatically generate requests. In general, reports are not delay sensitive, and it may not be disadvantageous to take one minute or more to generate a report.
Although a threshold scheme is described above, in some implementations, aggregation system 180 can be a secure multi-party (e.g., two-party) computing system. The aggregation system 180 can allow information across multiple sites to be collapsed into a single privacy-preserving report, made possible by a write-only per-source data store that refreshes data to reporting endpoints after an aggregation threshold is reached across many client devices 110. That is, data is only reported when it is sufficiently aggregated across browsers (or other application users) using server-side aggregation services.
Techniques for demographic reporting
Fig. 13 is a diagram illustrating an example process 1300 for demographic reporting as performed by the content platform 150. While reporting is described as being performed by content platform 150, in some implementations reporting can be performed by a separate reporting platform, as also indicated above. The content platform 150 can receive, at 1302, data from an application (e.g., a browser or native application) of the digital component provider 160 identifying an activity involving the digital component and a first set of one or more demographic categories for which the digital component provider 160 desires demographic reporting. The digital component provider 160 can enter this data onto such applications. The first set of categories may include, for example, women and income greater than $ X. In some implementations, the data identifying the activity and the first set of one or more demographic categories can be included in an aggregation key, which can be a composite or cascade key having a plurality of values or columns of values.
The content platform 150 can associate the user of the client device 110 on which the digital component is (or will be) displayed with the second set of one or more demographic categories at 1304. In one example, the second set of one or more demographic categories includes women, parents, and income greater than $ X. The association can be performed in at least one of the following two ways. In a first manner, the content platform 150 can receive a self-identification of a second set of one or more demographic categories provided by the user on the application 112 implemented on the client device 110, and then the content platform 150 can map the user to the second set of one or more demographic categories to perform the association. In a second mode, content platform 150 can transmit the user's browsing history to MPC cluster 130; the content platform 150 can then receive, from a machine learning model within the MPC cluster 130, an inference output by the machine learning model that includes the second set of demographic categories; and then the content platform can map the user to a second set of one or more demographic categories to perform the association.
If the first set of one or more demographic categories (representing demographic categories for which the digital component provider 160 desires to demographically report; e.g., female and revenue greater than $ 100,000 as data input by the digital component provider 160 onto the application 112) and the second set of one or more demographic categories (representing inferences about the user's group of users as generated by machine learning or the user's group of users self-identified by the user on the application 112; e.g., female, parent, and revenue greater than $ 100,000) have at least one common demographic category (e.g., female and demographic categories for which revenue greater than $ 100,000), the content platform 150 can transmit the browsing events (e.g., presentation, clicks and/or conversions, and/or lack/absence thereof) and the at least one common demographic category to the aggregation API at 1306. In the example given above for the first set of one or more demographic categories and the second set of one or more demographic categories, note that women and categories with income greater than $ X are common. Thus, in such an example, the content platform 150 communicates to the aggregation API browsing events (e.g., impressions, clicks, and/or conversions, and/or lack/absence thereof) entered on the client device 110 and data identifying common demographic categories.
The aggregation API combines the browsing events (e.g., impressions, clicks and/or conversions, and/or lack/absence thereof) and the at least one common demographic category with at least one browsing event of the other user and a related at least one demographic category that is one of a first set of one or more demographic categories to generate aggregated data. In the example used above, the aggregation API combines data for browsing events for females and categories with a revenue greater than $ X with browsing events for other users within the females and categories with a revenue greater than $ X, as opposed to this digital component. In this example, the aggregation does not account for a parent's non-common category (i.e., not common between the first set of one or more demographic categories and the second set of one or more demographic categories) because the digital component provider expects reports for only females and a specified category that earns greater than $ X, rather than a parent's category. In some examples, the aggregated data can be a table the same as or similar to table 7 discussed above. The polymerization can polymerize the data for a predetermined amount of time (e.g., 1 hour, 12 hours, 1 day, 2 days, 5 days, 1 month, or any other period of time). For example, in table 7, the counts of impressions, clicks, and conversions are daily.
The polymerization API is described in detail above.
The content platform 150 can generate reports in response to requests to generate reports. In some implementations, the content platform 150 can receive a request for a report from the digital content provider 160. In one example consistent with these implementations, the digital component provider 160 may request a report for a particular digital component of the digital component provider 160. In another example, a digital component provider may request reports for several digital components of the digital component provider 160. In yet another example, the digital component provider may request a report for one or more activities of the digital component provider 160. In some examples, the digital component provider 160 may request a report by specifying one or more campaign IDs, one or more digital component IDs, one or more demographic user group IDs, and/or one or more events for which a report is desired (e.g., impressions, click-throughs, and/or conversions, and/or lack/absence thereof). In other implementations, the request for generation of the report can be automatically generated. The automatic generation of the request by the script can occur at (a) a preset time interval and/or (b) when a count of one or more events associated with a digital component or activity of the content provider 160, such as a show, click and/or conversion, and/or lack/absence thereof, exceeds a particular threshold (e.g., when the number of clicks by women exceeds 1000). In some implementations, the script can (a) respond to requests from the content provider and/or (b) automatically generate requests.
The content platform 150 can transmit the report of the aggregated data to an application (e.g., a browser or native application) of the digital component provider 160 at 1310. The report can be presented on a user interface displayed by an application implemented on a computing device of the digital component provider 160. Typically, the reporting is not delay sensitive. For example, it may not be disadvantageous to take one minute or more to generate a report.
Fig. 14 is a diagram illustrating an example process 1400 performed by the client device 110 to facilitate demographic-based digital component distribution and demographic reporting. The application 112 of the client device 110 can be executed 1402 from one or more computers (e.g., including two computing systems MPCs) 1 And MPC 2 MPC cluster 130) receives data identifying inferred demographics of users of the application. Application 112 can display digital content at 1404 that includes computer readable code for reporting events related to the digital components, and specifying allowable basesData for a set of demographic user group identifiers, and an activity identifier for a numeric component. The digital content for which the report is being executed can be content of an electronic resource, such as a web page or content of a native application. In another example, the digital content for which the report is being performed can be a digital component being displayed in a digital component slot of the electronic resource.
The application 112 can determine, at 1406, that a given inferred characteristic matches a given allowed demographic-based user group identifier from the allowed list of demographic-based user group identifiers. The allowed list of demographic-based user group identifiers can include demographic-based user group identifiers that are allowed to be reported for the digital content. For example, the list can include one or more user groups for which the owner of the user group has enabled reporting for digital content. The list can be included in a script of the digital content. To determine whether there is a match, the application 112 can compare the allowed demographics-based user group identifier to a list of user group identifiers for user groups that include the user as a member.
In response to determining that the given inferred demographic characteristics match the given allowed demographic-based user group identifier, the application 112 can use computer-readable code to generate and transmit a request to update one or more event counts for the digital component and the given allowed demographic-based user group identifier at 1408. For example, the request can be to increase (e.g., increment) the number of users in the demographic-based user group identified by the given allowed demographic-based user group identifier, who have been presented with and interacted with the digital content, e.g., selected the digital content, or performed some other action with respect to the digital content.
Receiving data identifying inferred demographic characteristics of the user of the application 112 at 1402 includes receiving, at the client device 110, an inferred demographics-based user group identifier for a demographics-based user group to which the user was added. In some implementations, an inference request can be transmitted to one or more computers that includes a user profile of a user. In some implementations, two or more computers are required to implement secure multiparty computing. Such an inference request can include a user profile of the user. An inferred demographic user group identifier can be received from the one or more computers in response to the inference request.
Inferring transmission of the request to the one or more computers can include sending a respective secret share of the user profile to each MPC computing system (e.g., MPC server) forming the one or more computers. The MPC cluster 130 performs a secure MPC process using one or more machine learning models to generate and communicate secret shares of the inferred demographics-based user group identifiers to the application 112.
In response to displaying the digital component, the application 112 can transmit, to one or more computers, an inference request for data identifying inferred demographics of a user of the application 112. The inference request can include a user profile of the user and contextual signals related to at least one of: (i) A digital component slot in which a digital component is displayed or (ii) a digital component, wherein an inferred demographic user group identifier is received from one or more computers in response to an inference request. In some examples, the context signals can include context level signals, such as a Uniform Resource Locator (URL) of the resource, a location of the client device 110, a spoken language setting of the application 112, a number of digital component slots, top or below top screen, and so forth. In some instances, the contextual signal for the digital component can include an authoring signal, such as information about the digital component, a format of the digital component (e.g., image, video, audio, etc.), a size of the digital component, and so forth.
Generating and transmitting, using computer readable code, a request to update one or more event counts for a numeric component and a given allowed demographic-based user group identifier can include (i) generating an aggregation key that includes an activity identifier and the given allowed demographic-based user group identifier, and (ii) transmitting the aggregation key with the request.
Generating and communicating, using computer readable code, a request to update one or more event counts for a digital component and a given allowed demographic-based user group identifier can include invoking an Application Programming Interface (API) of the application 112 to send the request.
In some implementations, the process 1400 can be used to update a potentially incorrect event count. For example, when reporting that a user is presented with digital content, the user may have been inferred as being a member of a first demographic-based user group. However, some time later, the user is inferred to be in a second demographic-based user group that is different from the first demographic-based user group. In this example, the request can be to decrement an event count for a first demographic-based user group and to increment an event count for a second demographic-based user group.
FIG. 15 is a block diagram of an example computer system 1500 that can be used to perform the operations described above. The system 1500 includes a processor 1510, a memory 1520, a storage device 1530, and an input/output device 1540. Each of the components 1510, 1520, 1530, and 1540 can be interconnected, for example, using a system bus 1550. The processor 1510 is capable of processing instructions for execution within the system 1500. In some implementations, the processor 1510 is a single-threaded processor. In another implementation, the processor 1510 is a multi-threaded processor. The processor 1510 is capable of processing instructions stored in the memory 1520 or on the storage device 1530.
The memory 1520 stores information within the system 1500. In one implementation, the memory 1520 is a computer-readable medium. In some implementations, the memory 1520 is a volatile memory unit or units. In another implementation, the memory 1520 is a non-volatile memory unit or units.
The storage device 1530 is capable of providing mass storage for the system 1500. In some implementations, the storage device 1530 is a computer-readable medium. In various different implementations, the storage device 1530 can include, for example, a hard disk device, an optical disk device, a storage device shared by multiple computing devices over a network (e.g., a cloud storage device), or some other mass storage device.
The input/output device 1540 provides input/output operations for the system 1500. In some implementations, the input/output devices 1540 can include one or more of a network interface device, such as an ethernet card, a serial communication device (e.g., an RS-232 port), and/or a wireless interface device (e.g., an 802.11 card). In another implementation, the input/output devices can include driver devices, e.g., keyboard, printer, and display devices, configured to receive input data and send output data to the external device 1560. However, other implementations can also be used, such as mobile computing devices, mobile communication devices, set-top box television client devices, and so forth.
Although an example processing system has been described in FIG. 15, implementations of the subject matter and the functional operations described in this specification can be implemented in other types of digital electronic circuitry, or in computer software, firmware, or hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them.
Embodiments of the subject matter and the operations described in this specification can be implemented in digital electronic circuitry, or in computer software, firmware, or hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them. Embodiments of the subject matter described in this specification can be implemented as one or more computer programs, i.e., one or more modules of computer program instructions encoded on a computer storage medium (or media) for execution by, or to control the operation of, data processing apparatus. Alternatively or in addition, the program instructions can be encoded on an artificially generated propagated signal, e.g., a machine-generated electrical, optical, or electromagnetic signal, that is generated to encode information for transmission to suitable receiver apparatus for execution by data processing apparatus. The computer storage medium can be or be included in a computer-readable storage device, a computer-readable storage substrate, a random or serial access memory array or device, or a combination of one or more of them. Further, although the computer storage medium is not a propagated signal, the computer storage medium can be a source or destination of computer program instructions encoded in an artificially generated propagated signal. The computer storage media can also be or be included in one or more separate physical components or media (e.g., multiple CDs, disks, or other storage devices).
The operations described in this specification can be implemented as operations performed by data processing apparatus on data stored on one or more computer-readable storage devices or received from other sources.
The term "data processing apparatus" encompasses all kinds of apparatus, devices, and machines for processing data, including by way of example a programmable processor, a computer, a system on a chip, or multiple programmable processors, computers, systems on a chip, or a combination of the foregoing. An apparatus can comprise special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit). The apparatus can include, in addition to hardware, code that creates an execution environment for the computer program in question, e.g., code that constitutes processor firmware, a protocol stack, a database management system, an operating system, a cross-platform runtime environment, a virtual machine, or a combination of one or more of them. The apparatus and execution environment are capable of implementing a variety of different computing model infrastructures, such as web services, distributed computing and grid computing infrastructures.
A computer program (also known as a program, software application, script, or code) can be written in any form of programming language, including compiled or interpreted languages, declarative or procedural languages, and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, object, or other unit suitable for use in a computing environment. A computer program may, but need not, correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data (e.g., one or more scripts stored in a markup language document), in a single file dedicated to the program in question, or in multiple coordinated files (e.g., files that store one or more modules, sub programs, or portions of code). A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network.
The processes and logic flows described in this specification can be performed by one or more programmable processors executing one or more computer programs to perform actions by operating on input data and generating output. The processes and logic flows can also be performed by, and apparatus can also be implemented as, special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit).
Processors suitable for the execution of a computer program include, by way of example, both general and special purpose microprocessors. Generally, a processor will receive instructions and data from a read-only memory or a random access memory or both. The essential elements of a computer are a processor for performing actions in accordance with the instructions and one or more memory devices for storing instructions and data. Generally, a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks. However, a computer need not have such devices. Further, the computer can be embedded in another device, e.g., a mobile telephone, a Personal Digital Assistant (PDA), a mobile audio or video player, a game console, a Global Positioning System (GPS) receiver, or a portable storage device (e.g., a Universal Serial Bus (USB) flash drive), to name a few. Devices suitable for storing computer program instructions and data include all forms of non-volatile memory, media and memory devices, including by way of example semiconductor memory devices, e.g., EPROM, EEPROM, and flash memory devices; magnetic disks, e.g., internal hard disks or removable disks; a magneto-optical disk; and CD-ROM and DVD-ROM disks. The processor and the memory can be supplemented by, or incorporated in, special purpose logic circuitry.
To provide for interaction with a user, embodiments of the subject matter described in this specification can be implemented on a computer having a display device, e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor, for displaying information to the user and a keyboard and a pointing device, e.g., a mouse or a trackball, by which the user can provide input to the computer. Other kinds of devices can also be used to provide for interaction with a user; for example, feedback provided to the user can be any form of sensory feedback, e.g., visual feedback, auditory feedback, or tactile feedback; and input from the user can be received in any form, including acoustic, speech, or tactile input. In addition, the computer is able to interact with the user by sending documents to and receiving documents from the device used by the user; for example, by sending a web page to a web browser on the user's client device in response to a request received from the web browser.
Embodiments of the subject matter described in this specification can be implemented in a computing system that includes a back-end component (e.g., as a data server), or that includes a middleware component (e.g., an application server), or that includes a front-end component (e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the subject matter described in this specification), or any combination of one or more such back-end, middleware, or front-end components. The components of the system can be interconnected by any form or medium of digital data communication (e.g., a communication network). Examples of communication networks include local area networks ("LANs") and wide area networks ("WANs"), the internet (e.g., the internet), and peer-to-peer networks (e.g., ad hoc peer-to-peer networks).
The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other. In some embodiments, the server transmits data (e.g., an HTML page) to the client device (e.g., for the purpose of displaying data to a user interacting with the client device and receiving user input from the user interacting with the client device). Data generated at the client device (e.g., a result of the user interaction) can be received at the server from the client device.
While this specification contains many specific implementation details, these should not be construed as limitations on the scope of any inventions or of what may be claimed, but rather as descriptions of features specific to particular embodiments of particular inventions. Certain features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely, various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable subcombination. Moreover, although features may be described above as acting in certain combinations and even initially claimed as such, one or more features from a claimed combination can in some cases be excised from the combination, and the claimed combination may be directed to a subcombination or variation of a subcombination.
Similarly, while operations are depicted in the drawings in a particular order, this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order, or that all illustrated operations be performed, to achieve desirable results. In some cases, multitasking and parallel processing may be advantageous. Moreover, the separation of various system components in the embodiments described above should not be understood as requiring such separation in all embodiments, and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.
Thus, particular embodiments of the subject matter have been described. Other embodiments are within the scope of the following claims. In some cases, the actions recited in the claims can be performed in a different order and still achieve desirable results. In addition, the processes depicted in the accompanying figures do not necessarily require the particular order shown, or sequential order, to achieve desirable results. In some implementations, multitasking and parallel processing may be advantageous.
Claims (22)
1. A method, comprising:
receiving, by an application of a client device from one or more computers, data identifying inferred demographics of a user of the application;
Displaying, by the application, digital content comprising computer-readable code for reporting events related to the digital content, data specifying a set of allowed demographic-based user group identifiers, and an activity identifier for the digital content;
determining, by the application, that a given inferred characteristic matches a given allowed demographic-based user group identifier; and
in response to determining that the given inferred demographic characteristic matches the given allowed demographic-based user group identifier, generating and sending, using the computer-readable code, a request to update one or more event counts for the digital content and the given allowed demographic-based user group identifier.
2. The method of claim 1, wherein receiving the data identifying inferred demographic characteristics of a user of the application comprises receiving, at the client device, an inferred demographic-based user group identifier for a demographic-based user group to which the user is added.
3. The method of claim 2, further comprising sending an inference request including a user profile of the user to the one or more computers, wherein the inferred demographic user group identifier is received from the one or more computers in response to the inference request.
4. The method of claim 3, wherein:
the one or more computers comprise a plurality of multi-party computing (MPC) servers; and
sending the inference request to the one or more computers comprises sending a respective secret share of the user profile to each of the plurality of MPC servers; and
the plurality of MPC servers perform a secure MPC process using one or more machine learning models to generate a secret share of the inferred demographics-based user group identifier and to communicate the secret share of the inferred demographics-based user group identifier to the application.
5. The method of any preceding claim, further comprising:
sending, by the application to the one or more computers, an inference request for the data identifying the inferred demographic characteristics of the user of the application, wherein the inference request includes a user profile of the user and contextual signals related to at least one of: (ii) a digital content slot to display the digital content, or (ii) the digital content, wherein the inferred demographic user group identifier is received from the one or more computers in response to the inference request, or (iii) a Uniform Resource Locator (URL) of a resource comprising the digital content, a location of the client device, a spoken language setting of the application.
6. The method of any preceding claim, wherein generating and transmitting, using the computer readable code, the request to update one or more event counts for the digital content and the given allowed demographics-based user group identifier comprises:
generating an aggregation key comprising the activity identifier and the given allowed demographic-based user group identifier; and
transmitting the aggregated key with the request.
7. The method of any preceding claim, wherein generating and communicating, using the computer readable code, the request to update one or more event counts for the digital content and the given allowed demographic-based user group identifier comprises invoking an Application Programming Interface (API) of the application to send the request.
8. A system, comprising:
at least one programmable processor; and
a machine-readable medium storing instructions that, when executed by the at least one programmable processor, cause the at least one programmable processor to perform operations comprising:
receiving, by an application of a client device from one or more computers, data identifying inferred demographics of a user of the application;
Displaying, by the application, digital content comprising computer-readable code for reporting events related to the digital content, data specifying a set of allowed demographic-based user group identifiers, and an activity identifier for the digital content;
determining, by the application, that a given inferred characteristic matches a given allowed demographic-based user group identifier; and
in response to determining that the given inferred demographic characteristics match the given allowed demographic-based user group identifier, generating and sending, using the computer-readable code, a request to update one or more event counts for the digital content and the given allowed demographic-based user group identifier.
9. A non-transitory computer program product storing instructions that, when executed by at least one programmable processor, cause the at least one programmable processor to perform operations comprising:
receiving, by an application of a client device from one or more computers, data identifying inferred demographics of a user of the application;
displaying, by the application, digital content comprising computer-readable code for reporting events related to the digital content, data specifying a set of allowed demographic-based user group identifiers, and an activity identifier for the digital content;
Determining, by the application, that a given inferred characteristic matches a given allowed demographic-based user group identifier; and
in response to determining that the given inferred demographic characteristics match the given allowed demographic-based user group identifier, generating and sending, using the computer-readable code, a request to update one or more event counts for the digital content and the given allowed demographic-based user group identifier.
10. A method, comprising:
receiving, from a first browser of a digital content provider, data identifying digital content and a first set of one or more demographic categories for which demographic reporting is to be performed;
associating a user of a client device on which the digital content is being displayed with a second set of one or more demographic categories;
if the first set of one or more demographic categories and the second set of one or more demographic categories have at least one common demographic category, communicating a browsing event and the at least one common demographic category input on the client device to an API, wherein the API combines the browsing event and the at least one common demographic category with at least one browsing event of other users and a related at least one demographic category that is one demographic category in the first set of one or more demographic categories to generate aggregated data;
Receiving the aggregated data from the API; and
generating a report including the aggregated data.
11. The method of claim 10, wherein associating the user with the second set of one or more demographic categories comprises:
receiving a self-identification of the second set of one or more demographic categories by the user on the first browser; and
mapping the user to the second set of one or more demographic categories.
12. The method of claim 10, wherein associating the user with the second set of one or more demographic categories comprises:
transmitting the user's browsing history to a multi-directional computing cluster; and
receiving, from a machine learning model within the multi-party computing cluster, an inference output by the machine learning model, the inference comprising the second set of demographic categories; and
mapping the user to the second set of one or more demographic categories.
13. The method of any of claims 10 to 12, wherein generating the report comprises:
arranging the aggregated data in a table;
Generating an analysis based on the aggregated data; and
providing the table and the analysis in the report.
14. The method of any of claims 10 to 13, wherein the report is generated automatically in response to a request for the report or at preset time intervals.
15. The method of claim 14, wherein the request for the report is generated by one or more of the digital content provider, content platform, secure multi-party computing cluster, or publisher that developed and provided the first browser.
16. The method of claim 14, wherein the request for the report is generated automatically at a preset time interval or after a count of events exceeds a preset threshold.
17. The method of any of claims 10 to 16, wherein the data identifying the digital content and the first set of one or more demographic categories are included in an aggregation key, wherein the data identifying the digital content includes a Uniform Resource Locator (URL) of a resource displaying the digital content.
18. The method of any of claims 10 to 17, further comprising:
Determining a third set of demographic categories related to the user; and
restricting the first browser of the client device to displaying digital content indicated by the respective digital content provider as being associated with a category of the third set of demographic categories.
19. The method of claim 18, wherein determining the third set of one or more demographic categories comprises:
receiving a self-identification by the user of the third set of one or more demographic categories relevant to the user on the first browser.
20. The method of claim 18, wherein determining the third set of one or more demographic categories comprises:
transmitting the user's browsing history to a multi-way computing cluster; and
receiving, from the multi-party computing cluster, data identifying the third set of demographic categories.
21. A system, comprising:
at least one programmable processor; and
a machine-readable medium storing instructions that, when executed by the at least one programmable processor, cause the at least one programmable processor to perform operations comprising:
Receiving, from a first browser of a digital content provider, data identifying digital content and a first set of one or more demographic categories for which demographic reporting is to be performed;
associating a user of a client device on which the digital content is being displayed with a second set of one or more demographic categories;
if the first set of one or more demographic categories and the second set of one or more demographic categories have at least one common demographic category, communicating a browsing event and the at least one common demographic category entered on the client device to an API, wherein the API combines the browsing event and the at least one common demographic category with at least one browsing event of other users and at least one demographic category that is a correlation of one of the first set of one or more demographic categories to generate aggregated data;
receiving the aggregated data from the API; and
generating a report including the aggregated data.
22. A non-transitory computer program product storing instructions that, when executed by at least one programmable processor, cause the at least one programmable processor to perform operations comprising:
Receiving, from a first browser of a digital content provider, data identifying digital content and a first set of one or more demographic categories for which demographic reporting is to be performed;
associating a user of a client device on which the digital content is being displayed with a second set of one or more demographic categories;
if the first set of one or more demographic categories and the second set of one or more demographic categories have at least one common demographic category, communicating a browsing event and the at least one common demographic category entered on the client device to an API, wherein the API combines the browsing event and the at least one common demographic category with at least one browsing event of other users and at least one demographic category that is a correlation of one of the first set of one or more demographic categories to generate aggregated data;
receiving the aggregated data from the API; and
generating a report including the aggregated data.
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
PCT/US2021/016479 WO2022169447A1 (en) | 2021-02-03 | 2021-02-03 | Privacy preserving machine learning for content distribution and analysis |
Publications (1)
Publication Number | Publication Date |
---|---|
CN115335825A true CN115335825A (en) | 2022-11-11 |
Family
ID=74845025
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202180025475.4A Pending CN115335825A (en) | 2021-02-03 | 2021-02-03 | Privacy preserving machine learning for content distribution and analysis |
Country Status (6)
Country | Link |
---|---|
US (1) | US20230205915A1 (en) |
EP (1) | EP4097618A1 (en) |
JP (1) | JP7471445B2 (en) |
KR (1) | KR20220145380A (en) |
CN (1) | CN115335825A (en) |
WO (1) | WO2022169447A1 (en) |
Families Citing this family (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11888825B1 (en) * | 2021-08-09 | 2024-01-30 | Google Llc | Privacy preserving user group expansion |
US20240095394A1 (en) * | 2022-09-16 | 2024-03-21 | Oracle International Corporation | Systems for design and implementation of privacy preserving ai with privacy regulations within intelligence pipelines |
Family Cites Families (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9003441B1 (en) * | 2005-04-13 | 2015-04-07 | Google Inc. | Probabilistic inference of demographic information from user selection of content |
JP2009008484A (en) | 2007-06-27 | 2009-01-15 | Mitsubishi Paper Mills Ltd | Formaldehyde detection reagent and formaldehyde detection sensor |
US9485537B1 (en) * | 2015-06-05 | 2016-11-01 | Canoe Ventures, Llc | Asset recommendations in a VOD system with asset effectiveness determinations |
US20190012700A1 (en) | 2017-07-05 | 2019-01-10 | Sathyender Nelakonda | Systems and methods for cookieless conversion measurement of online digital advertising |
-
2021
- 2021-02-03 US US17/908,284 patent/US20230205915A1/en active Pending
- 2021-02-03 KR KR1020227033024A patent/KR20220145380A/en unknown
- 2021-02-03 WO PCT/US2021/016479 patent/WO2022169447A1/en unknown
- 2021-02-03 EP EP21709202.2A patent/EP4097618A1/en active Pending
- 2021-02-03 JP JP2022559376A patent/JP7471445B2/en active Active
- 2021-02-03 CN CN202180025475.4A patent/CN115335825A/en active Pending
Also Published As
Publication number | Publication date |
---|---|
US20230205915A1 (en) | 2023-06-29 |
JP7471445B2 (en) | 2024-04-19 |
WO2022169447A1 (en) | 2022-08-11 |
KR20220145380A (en) | 2022-10-28 |
JP2023528140A (en) | 2023-07-04 |
EP4097618A1 (en) | 2022-12-07 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US20230214684A1 (en) | Privacy preserving machine learning using secure multi-party computation | |
US20230034384A1 (en) | Privacy preserving machine learning via gradient boosting | |
US20150371059A1 (en) | Privacy-sensitive ranking of user data | |
US20150372808A1 (en) | Private and distributed computation of probability density functions | |
US11843672B2 (en) | Privacy preserving centroid models using secure multi-party computation | |
JP7471445B2 (en) | Privacy-preserving machine learning for content delivery and analytics | |
US20230078704A1 (en) | Privacy preserving machine learning labelling | |
US20230274183A1 (en) | Processing of machine learning modeling data to improve accuracy of categorization | |
Elmisery et al. | Collaborative privacy framework for minimizing privacy risks in an IPTV social recommender service | |
Blundo et al. | Targeted advertising that protects the privacy of social networks users | |
US20150371241A1 (en) | User identification through subspace clustering | |
Elmisery et al. | Agent based middleware for private data mashup in IPTV recommender services | |
Elmisery | Private personalized social recommendations in an IPTV system | |
US20220405407A1 (en) | Privacy preserving cross-domain machine learning | |
US20240163341A1 (en) | Privacy preserving centroid models using secure multi-party computation | |
Gao et al. | A verifiable and privacy-preserving framework for federated recommendation system | |
JP7471450B2 (en) | Improving the performance of secure multiparty computation | |
JP7425222B2 (en) | Privacy Preserving Measurements Using Secure Multiparty Computation | |
Yang | Improving privacy preserving in modern applications |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination |