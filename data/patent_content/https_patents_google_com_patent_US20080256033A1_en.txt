US20080256033A1 - Method and apparatus for distributed voice searching - Google Patents
Method and apparatus for distributed voice searching Download PDFInfo
- Publication number
- US20080256033A1 US20080256033A1 US11/733,306 US73330607A US2008256033A1 US 20080256033 A1 US20080256033 A1 US 20080256033A1 US 73330607 A US73330607 A US 73330607A US 2008256033 A1 US2008256033 A1 US 2008256033A1
- Authority
- US
- United States
- Prior art keywords
- search
- coarse
- remote
- fine
- feature vectors
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
Images
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04M—TELEPHONIC COMMUNICATION
- H04M1/00—Substation equipment, e.g. for use by subscribers
- H04M1/72—Mobile telephones; Cordless telephones, i.e. devices for establishing wireless links to base stations without route selection
- H04M1/724—User interfaces specially adapted for cordless or mobile telephones
- H04M1/72403—User interfaces specially adapted for cordless or mobile telephones with means for local support of applications that increase the functionality
- H04M1/72445—User interfaces specially adapted for cordless or mobile telephones with means for local support of applications that increase the functionality for supporting Internet browser applications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/40—Information retrieval; Database structures therefor; File system structures therefor of multimedia data, e.g. slideshows comprising image and additional audio data
- G06F16/43—Querying
- G06F16/432—Query formulation
- G06F16/433—Query formulation using audio data
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/95—Retrieval from the web
- G06F16/957—Browsing optimisation, e.g. caching or content distillation
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/08—Speech classification or search
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/28—Constructional details of speech recognition systems
- G10L15/30—Distributed recognition, e.g. in client-server systems, for mobile phones or network applications
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/02—Feature extraction for speech recognition; Selection of recognition unit
- G10L2015/025—Phonemes, fenemes or fenones being the recognition units
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/22—Procedures used during a speech recognition process, e.g. man-machine dialogue
- G10L2015/221—Announcement of recognition results
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04M—TELEPHONIC COMMUNICATION
- H04M2250/00—Details of telephonic subscriber devices
- H04M2250/74—Details of telephonic subscriber devices with voice recognition means
Definitions
- the invention relates to mobile communication devices, and in particular, to voice searching using a mobile communication device.
- Mobile communication devices such as cellular phones are very pervasive communication devices used by people of all languages. The usage of the devices has expanded far beyond pure voice communication. User is able now to use the mobile communication devices to browse local multimedia content. User can also browse the multimedia content in web from the device.
- a method and apparatus for distributed voice searching using a mobile communication device may include receiving a search query from a user of the mobile communication device, generating a lattice of coarse linguistic representations from speech parts in the search query, extracting query features from the generated lattice of coarse linguistic representations, generating coarse search feature vectors based on the extracted query features, performing a coarse search using the generated coarse search feature vectors and transmitting the generated coarse search feature vectors to a remote voice search processing unit, receiving remote resultant web indices from the remote voice search processing unit based on the generated coarse search feature vectors, generating a lattice of fine linguistic representations from speech parts in the search query based on the coarse search results and the remote resultant web indices, generating fine search feature vectors from the lattice of fine linguistic representations, performing a fine search using the coarse search results, the remote resultant web indices and the generated fine search feature vectors, and displaying the fine search results to the user.
- FIG. 1 illustrates an exemplary diagram of a communications network environment in accordance with a possible embodiment of the invention
- FIG. 2 illustrates a block diagram of an exemplary mobile communication device in accordance with a possible embodiment of the invention
- FIG. 3 illustrates an exemplary block diagram of the voice search engine in accordance with a possible embodiment of the invention
- FIG. 4 illustrates a block diagram of an exemplary remote voice search processing unit in accordance with a possible embodiment of the invention
- FIG. 5 is an exemplary flowchart illustrating one possible voice search process in accordance with one possible embodiment of the invention.
- FIG. 6 is an exemplary flowchart illustrating one possible remote voice search process in accordance with one possible embodiment of the invention.
- the invention comprises a variety of embodiments, such as a method and apparatus and other embodiments that relate to the basic concepts of the invention.
- This invention concerns a language independent indexing and search process that can be used for the fast and seamless retrieval of multimedia content located on a mobile communication device and/or the Internet (web).
- a search automated speech recognizer may convert the speech part of a search query into phoneme (coarse linguistic representation) and/or word (fine linguistic representations) lattices. Then, the phoneme and word lattices may be converted into coarse search feature vectors and fine search feature vectors respectively, for example.
- Multimedia content on both the mobile communication device and web which have linguistic representations through metadata, may also be directly converted into phonemic and word representations and then into coarse search feature vectors and fine search feature vectors, respectively.
- This voice search process may be broken down in to two stages.
- a coarse search may be conducted to match the coarse search feature vectors of the speech query against the coarse search feature vectors of multimedia content on both mobile communication device and web to rapidly obtain a set of candidate results.
- a word lattice may be generated from the speech parts of the search query based on the candidate results, and then fine search vectors can be converted from the word lattice of the search query.
- the linguistic representation of candidate results of the coarse search may also be directly converted into word representations and then, fine search feature vectors.
- a fine search may be conducted to match the fine search feature vectors of speech query against fine search feature vectors of the candidate results of the coarse search to obtain final search results to display to user.
- FIG. 1 is an exemplary diagram of a communications network environment in accordance with a possible embodiment of the invention.
- the communications network environment 100 may include communications network 110 , a plurality of mobile communication devices 120 , a remote voice search processing unit 130 , the Internet (web) 140 , and a plurality of Internet browser/search engines 150 .
- communications network environment 100 may be any possible configuration in which a mobile communication device 120 may communicate with another mobile communications device 120 , as well as devices connected to the Internet 140 .
- communications network 110 may represent any possible communications that may be accessed by mobile communication devices 120 , such as a telephone network, a wireless network, a cable television network, a satellite television network, a satellite radio network, etc.
- the Internet (“web”) 140 may represent the World Wide Web (WWW), an intranet, or any other network system capable of hosting domains containing searchable text and media content that may be downloaded and/or played, for example.
- WWW World Wide Web
- intranet any other network system capable of hosting domains containing searchable text and media content that may be downloaded and/or played, for example.
- the mobile communication device 120 may represent any mobile or portable device having the ability to internally or externally record and or store audio, including a mobile telephone, cellular telephone, a wireless radio, a portable computer, a laptop, an MP3 player, a satellite radio, and a satellite television.
- the Internet browser/search engine 150 may represent any known web browser and/or search engine capable of searching and indexing content located on the Internet, such as Yahoo, Google, etc.
- FIG. 2 illustrates a block diagram of an exemplary mobile communication device 120 having a voice search engine 280 in accordance with a possible embodiment of the invention.
- the exemplary mobile communication device 120 may include a bus 210 , a processor 220 , a memory 230 , an antenna 240 , a transceiver 250 , a communication interface 260 , input/output (I/O) devices 270 , voice search engine 280 , and display 290 .
- Bus 210 may permit communication among the components of the mobile communication device 120 .
- Processor 220 may include at least one conventional processor or microprocessor that interprets and executes instructions.
- Memory 230 may be a random access memory (RAM) or another type of dynamic storage device that stores information and instructions for execution by processor 220 .
- Memory 230 may also include a read-only memory (ROM) which may include a conventional ROM device or another type of static storage device that stores static information and instructions for processor 220 .
- ROM read-only memory
- Transceiver 250 may include one or more transmitters and receivers.
- the transceiver 250 may include sufficient functionality to interface with any network or communication station and may be defined by hardware or software in any manner known to one of skill in the art.
- the processor 220 is cooperatively operable with the transceiver 250 to support operations within the communications network 110 .
- I/O devices 270 may include one or more conventional input mechanisms that permit a user to input information to the mobile communication device 120 , such as a microphone, touchpad, keypad, keyboard, mouse, pen, stylus, voice recognition device, buttons, etc.
- Output devices may include one or more conventional mechanisms that outputs information to the user, including a display, printer, one or more speakers, a storage medium, such as a memory, magnetic or optical disk, and disk drive, etc., and/or interfaces for the above.
- Display 290 may be a device cable of displaying information to the user of the mobile communication device 120 .
- Communication interface 260 may include any mechanism that facilitates communication via the communications network 110 .
- communication interface 260 may include a modem.
- communication interface 260 may include other mechanisms for assisting the transceiver 250 in communicating with other devices and/or systems via wireless connections.
- voice search engine 280 The functions of the voice search engine 280 will be discussed below in relation to FIGS. 3 and 5 in greater detail.
- the mobile communication device 120 may perform such functions in response to processor 220 by executing sequences of instructions contained in a computer-readable medium, such as, for example, memory 230 . Such instructions may be read into memory 230 from another computer-readable medium, such as a storage device or from a separate device via communication interface 260 .
- a computer-readable medium such as, for example, memory 230 .
- Such instructions may be read into memory 230 from another computer-readable medium, such as a storage device or from a separate device via communication interface 260 .
- FIG. 3 is a block diagram of an exemplary distributed voice search system 300 having a voice search engine 280 in accordance with a possible embodiment of the invention.
- Voice search engine 280 may include coarse search ASR 310 , coarse search feature vector generator 320 , coarse search module 330 , fine search ASR 340 , fine search feature vector generator 350 , fine search module 360 , and metadata database 370 .
- the voice search engine 280 is shown coupled to the remote voice search processing unit 130 directly, but as explained above, this coupling may occur through the communication network 110 and/or Internet 140 .
- the metadata database 370 may store multimedia content with linguistic metadata.
- the multimedia content may include audio files, audio recordings, emails, voice mails, recorded conversations, notes, messages, text messages, photos, video files, movie files, and television recordings, etc., for example.
- the voice search engine 280 and its corresponding process will be described in FIG. 5 below in relation to the block diagrams shown in FIGS. 1-3 .
- FIG. 4 illustrates a block diagram of an exemplary remote voice search processing unit 130 in accordance with a possible embodiment of the invention.
- the exemplary remote search processing unit 130 may include a bus 410 , a processor 420 , a memory 430 , a read only memory (ROM) 440 , a storage device 450 , an input device 460 , an output device 470 , a communication interface 480 , and web search processing module 490 .
- Bus 410 may permit communication among the components of the remote search processing unit 130 .
- Processor 420 may include at least one conventional processor or microprocessor that interprets and executes instructions.
- Memory 430 may be a random access memory (RAM) or another type of dynamic storage device that stores information and instructions for execution by processor 420 .
- Memory 430 may also store temporary variables or other intermediate information used during execution of instructions by processor 420 .
- ROM 440 may include a conventional ROM device or another type of static storage device that stores static information and instructions for processor 420 .
- Storage device 450 may include any type of media, such as, for example, magnetic or optical recording media and its corresponding drive.
- Input device 460 may include one or more conventional mechanisms that permit a user to input information to the remote search processing unit 130 , such as a keyboard, a mouse, a pen, a voice recognition device, etc.
- Output device 470 may include one or more conventional mechanisms that output information to the user, including a display, a printer, one or more speakers, or a medium, such as a memory, or a magnetic or optical disk and a corresponding disk drive.
- Communication interface 480 may include any transceiver-like mechanism that enables the remote search processing unit 130 to communicate via a network.
- communication interface 480 may include a modem, or an Ethernet interface for communicating via a local area network (LAN).
- LAN local area network
- communication interface 480 may include other mechanisms for communicating with other devices and/or systems via wired, wireless or optical connections. In some implementations of the communications network environment 100 , communication interface 480 may not be included in the exemplary remote search processing unit 130 when the remote search process is implemented completely within the remote search processing unit 130 .
- the remote search processing unit 130 may perform such functions in response to processor 420 by executing sequences of instructions contained in a computer-readable medium, such as, for example, memory 430 , a magnetic disk, or an optical disk. Such instructions may be read into memory 430 from another computer-readable medium, such as storage device 450 , or from a separate device via communication interface 480 .
- a computer-readable medium such as, for example, memory 430 , a magnetic disk, or an optical disk.
- Such instructions may be read into memory 430 from another computer-readable medium, such as storage device 450 , or from a separate device via communication interface 480 .
- FIG. 5 is an exemplary flowchart illustrating one possible voice search process as performed by the mobile communication device 120 including the voice search engine 280 in accordance with one possible embodiment of the invention.
- the process begins at step 5100 and continues to step 5150 where the voice search engine 280 receives a search query from the user of the mobile communication device 120 .
- the process will be described below in relation to the components of the voice search engine 280 .
- the coarse search ASR 310 of the voice search engine 280 generates a lattice of coarse linguistic representations, such as a phoneme lattice, from speech parts in the search query.
- a phoneme lattice may contain a series of connected nodes and edges, for example. Each edge may represent a phoneme with a score being the log of the probability of the hypothesis. The nodes on the two ends of each edge denote the start time and end time of the phoneme.
- the coarse search feature vector generator 320 extracts query features from the generated search phoneme lattice.
- the coarse search feature vector generator 320 extracts index terms or “features” from the generated phoneme lattices. These features may be extracted according to their probabilities (correctness), for example.
- the coarse search feature vector generator 320 generates coarse search feature vectors based on the extracted query features. In this manner, the coarse search feature vector generator 320 maps each of the extracted features to the generated phoneme lattices where the feature appears. The coarse search feature vector generator 320 also generates coarse search feature vectors based on linguistic metadata from the metadata database 370 .
- the coarse search module 330 performs a coarse search using the coarse search feature vectors. For a given search query, a set of top candidates, usually several times the amount of the final search results, will be returned for a more detailed search.
- the voice search engine 280 transmits the generated coarse search feature vectors to the remotes voice search processing unit 130 using transceiver 250 .
- the voice search engine 280 receives the remote resultant web indices along with the indices' linguistic representations from the remote voice search processing unit 130 through transceiver 250 . Please note that one of skill in the art may appreciate that steps 5400 and 5450 may be performed either simultaneously, in parallel, before or after step 5350 , but in general, should be completed before step 5500 .
- the fine search ASR 340 generates a lattice of fine linguistic representations, such as a word lattice, for example, from the speech parts of the search query based on the coarse search results and the received remote resultant web indices.
- the word lattice may contain a series of connected nodes and edges. Each edge may represent a word with a score being the log of the probability of the hypothesis. The nodes on the two ends of each edge denote the start time and end time of the word.
- the fine search feature vector generator 350 generates fine search feature vectors from the word lattice of the search query.
- the fine search feature vector generator 350 also directly generates fine search feature vectors based on linguistic representations of the coarse search results and the received remote resultant web indices.
- the fine search module 360 performs a fine search based on the fine search feature vectors generated for search query, the coarse search results, and the remote resultant web indices. In this manner, the fine search module 360 compares the fine search feature vectors of speech query and that of both the coarse search results and the received remote resultant web indices, for example.
- step 5650 the display 290 displays the fine search results to the user.
- the process goes to step 5700 , and ends.
- the display 290 may display the fine search results to the user and await a user selection of one particular result in response to a prompt for example.
- the selected result may be transmitted by the voice search engine 280 using the transceiver 250 to the remote voice search processing unit 130 information may be retrieved from the Internet 140 .
- the retrieved information on that user selection may then be received by the mobile communication device 120 for viewing on the display 290 .
- the voice search engine 280 may automatically transmit the best candidate from the fine search results to the remote voice search processing unit 130 .
- the voice search engine 280 would then receive information specific to the best candidate from the remote voice search processing unit 130 and display that information to the user on display 290 .
- FIG. 6 is an exemplary flowchart illustrating one possible remote voice search process in accordance with one possible embodiment of the invention. The process begins at step 6100 and goes to step 6200 where the web search processing module 490 in the remote voice search processing unit 130 receives generated coarse search feature vectors of the search query from the mobile communication device 120 .
- the web search processing module 490 performs an web search using one or more Internet browsers/search engines 150 .
- the web search processing module 490 receives the indexed web search results from the one or more Internet browsers/search engines 150 .
- the web search processing module 490 transmits the indexed web search results and their linguistic representations to the mobile communication device 120 . The process then goes to step 6600 and ends.
- Embodiments within the scope of the present invention may also include computer-readable media for carrying or having computer-executable instructions or data structures stored thereon.
- Such computer-readable media can be any available media that can be accessed by a general purpose or special purpose computer.
- Such computer-readable media can comprise RAM, ROM, EEPROM, CD-ROM or other optical disk storage, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to carry or store desired program code means in the form of computer-executable instructions or data structures.
- a network or another communications connection either hardwired, wireless, or combination thereof
- any such connection is properly termed a computer-readable medium. Combinations of the above should also be included within the scope of the computer-readable media.
- Computer-executable instructions include, for example, instructions and data which cause a general purpose computer, special purpose computer, or special purpose processing device to perform a certain function or group of functions.
- Computer-executable instructions also include program modules that are executed by computers in stand-alone or network environments.
- program modules include routines, programs, objects, components, and data structures, etc. that perform particular tasks or implement particular abstract data types.
- Computer-executable instructions, associated data structures, and program modules represent examples of the program code means for executing steps of the methods disclosed herein. The particular sequence of such executable instructions or associated data structures represents examples of corresponding acts for implementing the functions described in such steps.
Abstract
Description
- This application is related to U.S. patent application Ser. No. 11/566,832, filed Dec. 5, 2006, entitled “Content Selection Using Speech Recognition.”
- 1. Field of the Invention
- The invention relates to mobile communication devices, and in particular, to voice searching using a mobile communication device.
- 2. Introduction
- Mobile communication devices such as cellular phones are very pervasive communication devices used by people of all languages. The usage of the devices has expanded far beyond pure voice communication. User is able now to use the mobile communication devices to browse local multimedia content. User can also browse the multimedia content in web from the device.
- While these capabilities have been expanded, the ability to search the multimedia content in mobile device and web is limited. Due to the difficulty of navigating the contents with buttons, mobile communication device users may find it useful to be able to quickly find multimedia content on both mobile device and web seamlessly.
- A method and apparatus for distributed voice searching using a mobile communication device is disclosed. The method may include receiving a search query from a user of the mobile communication device, generating a lattice of coarse linguistic representations from speech parts in the search query, extracting query features from the generated lattice of coarse linguistic representations, generating coarse search feature vectors based on the extracted query features, performing a coarse search using the generated coarse search feature vectors and transmitting the generated coarse search feature vectors to a remote voice search processing unit, receiving remote resultant web indices from the remote voice search processing unit based on the generated coarse search feature vectors, generating a lattice of fine linguistic representations from speech parts in the search query based on the coarse search results and the remote resultant web indices, generating fine search feature vectors from the lattice of fine linguistic representations, performing a fine search using the coarse search results, the remote resultant web indices and the generated fine search feature vectors, and displaying the fine search results to the user.
- In order to describe the manner in which the above-recited and other advantages and features of the invention can be obtained, a more particular description of the invention briefly described above will be rendered by reference to specific embodiments thereof which are illustrated in the appended drawings. Understanding that these drawings depict only typical embodiments of the invention and are not therefore to be considered to be limiting of its scope, the invention will be described and explained with additional specificity and detail through the use of the accompanying drawings in which:
-
FIG. 1 illustrates an exemplary diagram of a communications network environment in accordance with a possible embodiment of the invention; -
FIG. 2 illustrates a block diagram of an exemplary mobile communication device in accordance with a possible embodiment of the invention; -
FIG. 3 illustrates an exemplary block diagram of the voice search engine in accordance with a possible embodiment of the invention; -
FIG. 4 illustrates a block diagram of an exemplary remote voice search processing unit in accordance with a possible embodiment of the invention; -
FIG. 5 is an exemplary flowchart illustrating one possible voice search process in accordance with one possible embodiment of the invention; and -
FIG. 6 is an exemplary flowchart illustrating one possible remote voice search process in accordance with one possible embodiment of the invention. - Additional features and advantages of the invention will be set forth in the description which follows, and in part will be obvious from the description, or may be learned by practice of the invention. The features and advantages of the invention may be realized and obtained by means of the instruments and combinations particularly pointed out in the appended claims. These and other features of the present invention will become more fully apparent from the following description and appended claims, or may be learned by the practice of the invention as set forth herein.
- Various embodiments of the invention are discussed in detail below. While specific implementations are discussed, it should be understood that this is done for illustration purposes only. A person skilled in the relevant art will recognize that other components and configurations may be used without parting from the spirit and scope of the invention.
- The invention comprises a variety of embodiments, such as a method and apparatus and other embodiments that relate to the basic concepts of the invention.
- This invention concerns a language independent indexing and search process that can be used for the fast and seamless retrieval of multimedia content located on a mobile communication device and/or the Internet (web).
- In this manner, a search automated speech recognizer (ASR) may convert the speech part of a search query into phoneme (coarse linguistic representation) and/or word (fine linguistic representations) lattices. Then, the phoneme and word lattices may be converted into coarse search feature vectors and fine search feature vectors respectively, for example. Multimedia content on both the mobile communication device and web, which have linguistic representations through metadata, may also be directly converted into phonemic and word representations and then into coarse search feature vectors and fine search feature vectors, respectively.
- This voice search process may be broken down in to two stages. In the first stage, a coarse search may be conducted to match the coarse search feature vectors of the speech query against the coarse search feature vectors of multimedia content on both mobile communication device and web to rapidly obtain a set of candidate results. Then, a word lattice may be generated from the speech parts of the search query based on the candidate results, and then fine search vectors can be converted from the word lattice of the search query. The linguistic representation of candidate results of the coarse search may also be directly converted into word representations and then, fine search feature vectors.
- In the second stage of the search process, a fine search may be conducted to match the fine search feature vectors of speech query against fine search feature vectors of the candidate results of the coarse search to obtain final search results to display to user.
-
FIG. 1 is an exemplary diagram of a communications network environment in accordance with a possible embodiment of the invention. Thecommunications network environment 100 may includecommunications network 110, a plurality ofmobile communication devices 120, a remote voicesearch processing unit 130, the Internet (web) 140, and a plurality of Internet browser/search engines 150. - One of skill in the art will appreciate that the
communications network environment 100 may be any possible configuration in which amobile communication device 120 may communicate with anothermobile communications device 120, as well as devices connected to the Internet 140. As such,communications network 110 may represent any possible communications that may be accessed bymobile communication devices 120, such as a telephone network, a wireless network, a cable television network, a satellite television network, a satellite radio network, etc. - The Internet (“web”) 140 may represent the World Wide Web (WWW), an intranet, or any other network system capable of hosting domains containing searchable text and media content that may be downloaded and/or played, for example.
- The
mobile communication device 120 may represent any mobile or portable device having the ability to internally or externally record and or store audio, including a mobile telephone, cellular telephone, a wireless radio, a portable computer, a laptop, an MP3 player, a satellite radio, and a satellite television. - The Internet browser/
search engine 150 may represent any known web browser and/or search engine capable of searching and indexing content located on the Internet, such as Yahoo, Google, etc. -
FIG. 2 illustrates a block diagram of an exemplarymobile communication device 120 having avoice search engine 280 in accordance with a possible embodiment of the invention. The exemplarymobile communication device 120 may include abus 210, aprocessor 220, amemory 230, anantenna 240, atransceiver 250, acommunication interface 260, input/output (I/O)devices 270,voice search engine 280, anddisplay 290.Bus 210 may permit communication among the components of themobile communication device 120. -
Processor 220 may include at least one conventional processor or microprocessor that interprets and executes instructions.Memory 230 may be a random access memory (RAM) or another type of dynamic storage device that stores information and instructions for execution byprocessor 220.Memory 230 may also include a read-only memory (ROM) which may include a conventional ROM device or another type of static storage device that stores static information and instructions forprocessor 220. -
Transceiver 250 may include one or more transmitters and receivers. Thetransceiver 250 may include sufficient functionality to interface with any network or communication station and may be defined by hardware or software in any manner known to one of skill in the art. Theprocessor 220 is cooperatively operable with thetransceiver 250 to support operations within thecommunications network 110. - Input/output devices (I/O devices) 270 may include one or more conventional input mechanisms that permit a user to input information to the
mobile communication device 120, such as a microphone, touchpad, keypad, keyboard, mouse, pen, stylus, voice recognition device, buttons, etc. Output devices may include one or more conventional mechanisms that outputs information to the user, including a display, printer, one or more speakers, a storage medium, such as a memory, magnetic or optical disk, and disk drive, etc., and/or interfaces for the above.Display 290 may be a device cable of displaying information to the user of themobile communication device 120. -
Communication interface 260 may include any mechanism that facilitates communication via thecommunications network 110. For example,communication interface 260 may include a modem. Alternatively,communication interface 260 may include other mechanisms for assisting thetransceiver 250 in communicating with other devices and/or systems via wireless connections. - The functions of the
voice search engine 280 will be discussed below in relation toFIGS. 3 and 5 in greater detail. - The
mobile communication device 120 may perform such functions in response toprocessor 220 by executing sequences of instructions contained in a computer-readable medium, such as, for example,memory 230. Such instructions may be read intomemory 230 from another computer-readable medium, such as a storage device or from a separate device viacommunication interface 260. -
FIG. 3 is a block diagram of an exemplary distributedvoice search system 300 having avoice search engine 280 in accordance with a possible embodiment of the invention.Voice search engine 280 may includecoarse search ASR 310, coarse searchfeature vector generator 320,coarse search module 330,fine search ASR 340, fine searchfeature vector generator 350,fine search module 360, andmetadata database 370. For ease of discussion, thevoice search engine 280 is shown coupled to the remote voicesearch processing unit 130 directly, but as explained above, this coupling may occur through thecommunication network 110 and/orInternet 140. - The
metadata database 370 may store multimedia content with linguistic metadata. The multimedia content may include audio files, audio recordings, emails, voice mails, recorded conversations, notes, messages, text messages, photos, video files, movie files, and television recordings, etc., for example. - For illustrative purposes, the
voice search engine 280 and its corresponding process will be described inFIG. 5 below in relation to the block diagrams shown inFIGS. 1-3 . -
FIG. 4 illustrates a block diagram of an exemplary remote voicesearch processing unit 130 in accordance with a possible embodiment of the invention. The exemplary remotesearch processing unit 130 may include abus 410, aprocessor 420, amemory 430, a read only memory (ROM) 440, astorage device 450, aninput device 460, anoutput device 470, acommunication interface 480, and websearch processing module 490.Bus 410 may permit communication among the components of the remotesearch processing unit 130. -
Processor 420 may include at least one conventional processor or microprocessor that interprets and executes instructions.Memory 430 may be a random access memory (RAM) or another type of dynamic storage device that stores information and instructions for execution byprocessor 420.Memory 430 may also store temporary variables or other intermediate information used during execution of instructions byprocessor 420.ROM 440 may include a conventional ROM device or another type of static storage device that stores static information and instructions forprocessor 420.Storage device 450 may include any type of media, such as, for example, magnetic or optical recording media and its corresponding drive. -
Input device 460 may include one or more conventional mechanisms that permit a user to input information to the remotesearch processing unit 130, such as a keyboard, a mouse, a pen, a voice recognition device, etc.Output device 470 may include one or more conventional mechanisms that output information to the user, including a display, a printer, one or more speakers, or a medium, such as a memory, or a magnetic or optical disk and a corresponding disk drive. -
Communication interface 480 may include any transceiver-like mechanism that enables the remotesearch processing unit 130 to communicate via a network. For example,communication interface 480 may include a modem, or an Ethernet interface for communicating via a local area network (LAN). - Alternatively,
communication interface 480 may include other mechanisms for communicating with other devices and/or systems via wired, wireless or optical connections. In some implementations of thecommunications network environment 100,communication interface 480 may not be included in the exemplary remotesearch processing unit 130 when the remote search process is implemented completely within the remotesearch processing unit 130. - The remote
search processing unit 130 may perform such functions in response toprocessor 420 by executing sequences of instructions contained in a computer-readable medium, such as, for example,memory 430, a magnetic disk, or an optical disk. Such instructions may be read intomemory 430 from another computer-readable medium, such asstorage device 450, or from a separate device viacommunication interface 480. - The operation of the
mobile communication device 130/voice search engine 280 and the remotesearch processing unit 130/websearch processing module 490 and their related processes will be described further below in relation to the flowchart inFIGS. 5 and 6 , respectively. -
FIG. 5 is an exemplary flowchart illustrating one possible voice search process as performed by themobile communication device 120 including thevoice search engine 280 in accordance with one possible embodiment of the invention. The process begins atstep 5100 and continues to step 5150 where thevoice search engine 280 receives a search query from the user of themobile communication device 120. The process will be described below in relation to the components of thevoice search engine 280. - At
step 5200, thecoarse search ASR 310 of thevoice search engine 280 generates a lattice of coarse linguistic representations, such as a phoneme lattice, from speech parts in the search query. A phoneme lattice may contain a series of connected nodes and edges, for example. Each edge may represent a phoneme with a score being the log of the probability of the hypothesis. The nodes on the two ends of each edge denote the start time and end time of the phoneme. - At
step 5250, the coarse searchfeature vector generator 320 extracts query features from the generated search phoneme lattice. The coarse searchfeature vector generator 320 extracts index terms or “features” from the generated phoneme lattices. These features may be extracted according to their probabilities (correctness), for example. - At
step 5300, the coarse searchfeature vector generator 320 generates coarse search feature vectors based on the extracted query features. In this manner, the coarse searchfeature vector generator 320 maps each of the extracted features to the generated phoneme lattices where the feature appears. The coarse searchfeature vector generator 320 also generates coarse search feature vectors based on linguistic metadata from themetadata database 370. - At
step 5350, thecoarse search module 330 performs a coarse search using the coarse search feature vectors. For a given search query, a set of top candidates, usually several times the amount of the final search results, will be returned for a more detailed search. - At
step 5400, thevoice search engine 280 transmits the generated coarse search feature vectors to the remotes voicesearch processing unit 130 usingtransceiver 250. Atstep 5450, thevoice search engine 280 receives the remote resultant web indices along with the indices' linguistic representations from the remote voicesearch processing unit 130 throughtransceiver 250. Please note that one of skill in the art may appreciate thatsteps step 5350, but in general, should be completed beforestep 5500. - At
step 5500 thefine search ASR 340 generates a lattice of fine linguistic representations, such as a word lattice, for example, from the speech parts of the search query based on the coarse search results and the received remote resultant web indices. The word lattice may contain a series of connected nodes and edges. Each edge may represent a word with a score being the log of the probability of the hypothesis. The nodes on the two ends of each edge denote the start time and end time of the word. - At
step 5550, the fine searchfeature vector generator 350 generates fine search feature vectors from the word lattice of the search query. The fine searchfeature vector generator 350 also directly generates fine search feature vectors based on linguistic representations of the coarse search results and the received remote resultant web indices. - At
step 5600, thefine search module 360 performs a fine search based on the fine search feature vectors generated for search query, the coarse search results, and the remote resultant web indices. In this manner, thefine search module 360 compares the fine search feature vectors of speech query and that of both the coarse search results and the received remote resultant web indices, for example. - At
step 5650, thedisplay 290 displays the fine search results to the user. The process goes to step 5700, and ends. - Alternatively, the
display 290 may display the fine search results to the user and await a user selection of one particular result in response to a prompt for example. The selected result may be transmitted by thevoice search engine 280 using thetransceiver 250 to the remote voicesearch processing unit 130 information may be retrieved from theInternet 140. The retrieved information on that user selection may then be received by themobile communication device 120 for viewing on thedisplay 290. - In another possible alternative, the
voice search engine 280 may automatically transmit the best candidate from the fine search results to the remote voicesearch processing unit 130. Thevoice search engine 280 would then receive information specific to the best candidate from the remote voicesearch processing unit 130 and display that information to the user ondisplay 290. -
FIG. 6 is an exemplary flowchart illustrating one possible remote voice search process in accordance with one possible embodiment of the invention. The process begins atstep 6100 and goes to step 6200 where the websearch processing module 490 in the remote voicesearch processing unit 130 receives generated coarse search feature vectors of the search query from themobile communication device 120. - At
step 6300, the websearch processing module 490 performs an web search using one or more Internet browsers/search engines 150. Atstep 6400, the websearch processing module 490 receives the indexed web search results from the one or more Internet browsers/search engines 150. - At
step 6500, the websearch processing module 490 transmits the indexed web search results and their linguistic representations to themobile communication device 120. The process then goes to step 6600 and ends. - Embodiments within the scope of the present invention may also include computer-readable media for carrying or having computer-executable instructions or data structures stored thereon. Such computer-readable media can be any available media that can be accessed by a general purpose or special purpose computer. By way of example, and not limitation, such computer-readable media can comprise RAM, ROM, EEPROM, CD-ROM or other optical disk storage, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to carry or store desired program code means in the form of computer-executable instructions or data structures. When information is transferred or provided over a network or another communications connection (either hardwired, wireless, or combination thereof) to a computer, the computer properly views the connection as a computer-readable medium. Thus, any such connection is properly termed a computer-readable medium. Combinations of the above should also be included within the scope of the computer-readable media.
- Computer-executable instructions include, for example, instructions and data which cause a general purpose computer, special purpose computer, or special purpose processing device to perform a certain function or group of functions. Computer-executable instructions also include program modules that are executed by computers in stand-alone or network environments. Generally, program modules include routines, programs, objects, components, and data structures, etc. that perform particular tasks or implement particular abstract data types. Computer-executable instructions, associated data structures, and program modules represent examples of the program code means for executing steps of the methods disclosed herein. The particular sequence of such executable instructions or associated data structures represents examples of corresponding acts for implementing the functions described in such steps.
- Although the above description may contain specific details, they should not be construed as limiting the claims in any way. Other configurations of the described embodiments of the invention are part of the scope of this invention. For example, the principles of the invention may be applied to each individual user where each user may individually deploy such a system. This enables each user to utilize the benefits of the invention even if any one of the large number of possible applications do not need the functionality described herein. In other words, there may be multiple instances of the
voice search engine 280 inFIGS. 2-3 each processing the content in various possible ways. It does not necessarily need to be one system used by all end users. Accordingly, the appended claims and their legal equivalents should only define the invention, rather than any specific examples given.
Claims (20)
Priority Applications (7)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US11/733,306 US7818170B2 (en) | 2007-04-10 | 2007-04-10 | Method and apparatus for distributed voice searching |
BRPI0809946-4A2A BRPI0809946A2 (en) | 2007-04-10 | 2008-03-31 | DISTRIBUTED VOICE SEARCH METHOD AND APPARATUS |
MX2009010844A MX2009010844A (en) | 2007-04-10 | 2008-03-31 | Method and apparatus for distributed voice searching. |
EP08744769A EP2135180A4 (en) | 2007-04-10 | 2008-03-31 | Method and apparatus for distributed voice searching |
PCT/US2008/058890 WO2008124368A1 (en) | 2007-04-10 | 2008-03-31 | Method and apparatus for distributed voice searching |
CN200880011544A CN101681365A (en) | 2007-04-10 | 2008-03-31 | Method and apparatus for distributed voice searching |
KR1020097020930A KR20090130028A (en) | 2007-04-10 | 2008-03-31 | Method and apparatus for distributed voice searching |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US11/733,306 US7818170B2 (en) | 2007-04-10 | 2007-04-10 | Method and apparatus for distributed voice searching |
Publications (2)
Publication Number | Publication Date |
---|---|
US20080256033A1 true US20080256033A1 (en) | 2008-10-16 |
US7818170B2 US7818170B2 (en) | 2010-10-19 |
Family
ID=39831324
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US11/733,306 Active 2029-05-21 US7818170B2 (en) | 2007-04-10 | 2007-04-10 | Method and apparatus for distributed voice searching |
Country Status (7)
Country | Link |
---|---|
US (1) | US7818170B2 (en) |
EP (1) | EP2135180A4 (en) |
KR (1) | KR20090130028A (en) |
CN (1) | CN101681365A (en) |
BR (1) | BRPI0809946A2 (en) |
MX (1) | MX2009010844A (en) |
WO (1) | WO2008124368A1 (en) |
Cited By (9)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20100153112A1 (en) * | 2008-12-16 | 2010-06-17 | Motorola, Inc. | Progressively refining a speech-based search |
US20100223056A1 (en) * | 2009-02-27 | 2010-09-02 | Autonomy Corporation Ltd. | Various apparatus and methods for a speech recognition system |
US20100312782A1 (en) * | 2009-06-05 | 2010-12-09 | Microsoft Corporation | Presenting search results according to query domains |
US20110307257A1 (en) * | 2010-06-10 | 2011-12-15 | Nice Systems Ltd. | Methods and apparatus for real-time interaction analysis in call centers |
CN102623010A (en) * | 2012-02-29 | 2012-08-01 | 北京百度网讯科技有限公司 | Method and device for establishing language model and method and device for recognizing voice |
US8655657B1 (en) | 2012-09-10 | 2014-02-18 | Google Inc. | Identifying media content |
US20140067373A1 (en) * | 2012-09-03 | 2014-03-06 | Nice-Systems Ltd | Method and apparatus for enhanced phonetic indexing and search |
US20140074466A1 (en) * | 2012-09-10 | 2014-03-13 | Google Inc. | Answering questions using environmental context |
US10777206B2 (en) | 2017-06-16 | 2020-09-15 | Alibaba Group Holding Limited | Voiceprint update method, client, and electronic device |
Families Citing this family (14)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN101510222B (en) * | 2009-02-20 | 2012-05-30 | 北京大学 | Multilayer index voice document searching method |
GB2468203B (en) * | 2009-02-27 | 2011-07-20 | Autonomy Corp Ltd | Various apparatus and methods for a speech recognition system |
US8229743B2 (en) | 2009-06-23 | 2012-07-24 | Autonomy Corporation Ltd. | Speech recognition system |
US8190420B2 (en) | 2009-08-04 | 2012-05-29 | Autonomy Corporation Ltd. | Automatic spoken language identification based on phoneme sequence patterns |
US9277021B2 (en) | 2009-08-21 | 2016-03-01 | Avaya Inc. | Sending a user associated telecommunication address |
US8898219B2 (en) | 2010-02-12 | 2014-11-25 | Avaya Inc. | Context sensitive, cloud-based telephony |
US8959030B2 (en) | 2010-02-12 | 2015-02-17 | Avaya Inc. | Timeminder for professionals |
US8959082B2 (en) | 2011-10-31 | 2015-02-17 | Elwha Llc | Context-sensitive query enrichment |
CN104008132B (en) * | 2014-05-04 | 2018-09-25 | 深圳市北科瑞声科技股份有限公司 | Voice map searching method and system |
US11423023B2 (en) | 2015-06-05 | 2022-08-23 | Apple Inc. | Systems and methods for providing improved search functionality on a client device |
US10360902B2 (en) | 2015-06-05 | 2019-07-23 | Apple Inc. | Systems and methods for providing improved search functionality on a client device |
US10769184B2 (en) | 2015-06-05 | 2020-09-08 | Apple Inc. | Systems and methods for providing improved search functionality on a client device |
CN105302925A (en) * | 2015-12-10 | 2016-02-03 | 百度在线网络技术（北京）有限公司 | Method and device for pushing voice search data |
US10482096B2 (en) | 2017-02-13 | 2019-11-19 | Microsoft Technology Licensing, Llc | Distributed index searching in computing systems |
Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6182938B1 (en) * | 1997-08-19 | 2001-02-06 | Guy B. Wright | Push button apparatus for wall hangings and calendars |
US6633846B1 (en) * | 1999-11-12 | 2003-10-14 | Phoenix Solutions, Inc. | Distributed realtime speech recognition system |
US6999932B1 (en) * | 2000-10-10 | 2006-02-14 | Intel Corporation | Language independent voice-based search system |
Family Cites Families (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
KR0183140B1 (en) * | 1995-12-23 | 1999-05-15 | 정선종 | Voice information service searching method using an initial consonant |
KR100336994B1 (en) | 1999-07-23 | 2002-05-17 | 이계철 | The system and method for speech recognition potal service using multi-step speech recognition |
US6625600B2 (en) * | 2001-04-12 | 2003-09-23 | Telelogue, Inc. | Method and apparatus for automatically processing a user's communication |
GB2399983A (en) * | 2003-03-24 | 2004-09-29 | Canon Kk | Picture storage and retrieval system for telecommunication system |
-
2007
- 2007-04-10 US US11/733,306 patent/US7818170B2/en active Active
-
2008
- 2008-03-31 MX MX2009010844A patent/MX2009010844A/en not_active Application Discontinuation
- 2008-03-31 CN CN200880011544A patent/CN101681365A/en active Pending
- 2008-03-31 KR KR1020097020930A patent/KR20090130028A/en active IP Right Grant
- 2008-03-31 EP EP08744769A patent/EP2135180A4/en not_active Withdrawn
- 2008-03-31 BR BRPI0809946-4A2A patent/BRPI0809946A2/en not_active IP Right Cessation
- 2008-03-31 WO PCT/US2008/058890 patent/WO2008124368A1/en active Application Filing
Patent Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6182938B1 (en) * | 1997-08-19 | 2001-02-06 | Guy B. Wright | Push button apparatus for wall hangings and calendars |
US6633846B1 (en) * | 1999-11-12 | 2003-10-14 | Phoenix Solutions, Inc. | Distributed realtime speech recognition system |
US6999932B1 (en) * | 2000-10-10 | 2006-02-14 | Intel Corporation | Language independent voice-based search system |
Cited By (16)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20100153112A1 (en) * | 2008-12-16 | 2010-06-17 | Motorola, Inc. | Progressively refining a speech-based search |
US20100223056A1 (en) * | 2009-02-27 | 2010-09-02 | Autonomy Corporation Ltd. | Various apparatus and methods for a speech recognition system |
US9646603B2 (en) * | 2009-02-27 | 2017-05-09 | Longsand Limited | Various apparatus and methods for a speech recognition system |
US20100312782A1 (en) * | 2009-06-05 | 2010-12-09 | Microsoft Corporation | Presenting search results according to query domains |
US9684741B2 (en) | 2009-06-05 | 2017-06-20 | Microsoft Technology Licensing, Llc | Presenting search results according to query domains |
US9015046B2 (en) * | 2010-06-10 | 2015-04-21 | Nice-Systems Ltd. | Methods and apparatus for real-time interaction analysis in call centers |
US20110307257A1 (en) * | 2010-06-10 | 2011-12-15 | Nice Systems Ltd. | Methods and apparatus for real-time interaction analysis in call centers |
CN102623010A (en) * | 2012-02-29 | 2012-08-01 | 北京百度网讯科技有限公司 | Method and device for establishing language model and method and device for recognizing voice |
US20140067373A1 (en) * | 2012-09-03 | 2014-03-06 | Nice-Systems Ltd | Method and apparatus for enhanced phonetic indexing and search |
US9311914B2 (en) * | 2012-09-03 | 2016-04-12 | Nice-Systems Ltd | Method and apparatus for enhanced phonetic indexing and search |
US20140074466A1 (en) * | 2012-09-10 | 2014-03-13 | Google Inc. | Answering questions using environmental context |
US8655657B1 (en) | 2012-09-10 | 2014-02-18 | Google Inc. | Identifying media content |
US9031840B2 (en) | 2012-09-10 | 2015-05-12 | Google Inc. | Identifying media content |
US9576576B2 (en) | 2012-09-10 | 2017-02-21 | Google Inc. | Answering questions using environmental context |
US9786279B2 (en) | 2012-09-10 | 2017-10-10 | Google Inc. | Answering questions using environmental context |
US10777206B2 (en) | 2017-06-16 | 2020-09-15 | Alibaba Group Holding Limited | Voiceprint update method, client, and electronic device |
Also Published As
Publication number | Publication date |
---|---|
WO2008124368A1 (en) | 2008-10-16 |
US7818170B2 (en) | 2010-10-19 |
MX2009010844A (en) | 2009-11-05 |
KR20090130028A (en) | 2009-12-17 |
EP2135180A4 (en) | 2011-04-27 |
CN101681365A (en) | 2010-03-24 |
BRPI0809946A2 (en) | 2014-10-07 |
EP2135180A1 (en) | 2009-12-23 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US7818170B2 (en) | Method and apparatus for distributed voice searching | |
US20220122580A1 (en) | Intent recognition and emotional text-to-speech learning | |
US20080162125A1 (en) | Method and apparatus for language independent voice indexing and searching | |
KR101770358B1 (en) | Integration of embedded and network speech recognizers | |
US7275049B2 (en) | Method for speech-based data retrieval on portable devices | |
US11049493B2 (en) | Spoken dialog device, spoken dialog method, and recording medium | |
JP5042799B2 (en) | Voice chat system, information processing apparatus and program | |
EP2252995B1 (en) | Method and apparatus for voice searching for stored content using uniterm discovery | |
US8019604B2 (en) | Method and apparatus for uniterm discovery and voice-to-voice search on mobile device | |
US8650031B1 (en) | Accuracy improvement of spoken queries transcription using co-occurrence information | |
US8290775B2 (en) | Pronunciation correction of text-to-speech systems between different spoken languages | |
US20080162472A1 (en) | Method and apparatus for voice searching in a mobile communication device | |
US20140358903A1 (en) | Search-Based Dynamic Voice Activation | |
US20090055185A1 (en) | Voice chat system, information processing apparatus, speech recognition method, keyword data electrode detection method, and program | |
KR20080068844A (en) | Indexing and searching speech with text meta-data | |
WO2022001888A1 (en) | Information generation method and device based on word vector generation model | |
CN100592385C (en) | Method and system for performing speech recognition on multi-language name | |
US8805871B2 (en) | Cross-lingual audio search | |
JP2019185737A (en) | Search method and electronic device using the same | |
JP2008216461A (en) | Speech recognition, keyword extraction, and knowledge base retrieval coordinating device | |
JPWO2005076259A1 (en) | Voice input system, voice input method, and voice input program | |
CN114840168A (en) | Man-machine interaction device and method | |
CN115410558A (en) | Out-of-set word processing method, electronic device and storage medium | |
KR20210053512A (en) | System and Method for providing Text-To-Speech service and relay server for the same | |
Chen | Spoken Document Recognition, Organization and Retrieval |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: MOTOROLA, INC., ILLINOISFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:CHENG, YAN MING;REEL/FRAME:019139/0623Effective date: 20070410 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
AS | Assignment |
Owner name: MOTOROLA MOBILITY, INC, ILLINOISFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:MOTOROLA, INC;REEL/FRAME:025673/0558Effective date: 20100731 |
|
AS | Assignment |
Owner name: MOTOROLA MOBILITY LLC, ILLINOISFree format text: CHANGE OF NAME;ASSIGNOR:MOTOROLA MOBILITY, INC.;REEL/FRAME:029216/0282Effective date: 20120622 |
|
FPAY | Fee payment |
Year of fee payment: 4 |
|
AS | Assignment |
Owner name: GOOGLE TECHNOLOGY HOLDINGS LLC, CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:MOTOROLA MOBILITY LLC;REEL/FRAME:034421/0001Effective date: 20141028 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 8TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1552)Year of fee payment: 8 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 12TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1553); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 12 |