EP2761502B1 - Selective feedback for text recognition systems - Google Patents
Selective feedback for text recognition systems Download PDFInfo
- Publication number
- EP2761502B1 EP2761502B1 EP12773185.9A EP12773185A EP2761502B1 EP 2761502 B1 EP2761502 B1 EP 2761502B1 EP 12773185 A EP12773185 A EP 12773185A EP 2761502 B1 EP2761502 B1 EP 2761502B1
- Authority
- EP
- European Patent Office
- Prior art keywords
- text string
- edit distance
- recognition system
- corrected
- text
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
- 238000000034 method Methods 0.000 claims description 111
- 230000015654 memory Effects 0.000 claims description 52
- 238000012549 training Methods 0.000 claims description 39
- 238000012545 processing Methods 0.000 claims description 28
- 238000012217 deletion Methods 0.000 claims description 15
- 230000037430 deletion Effects 0.000 claims description 15
- 238000003780 insertion Methods 0.000 claims description 13
- 230000037431 insertion Effects 0.000 claims description 13
- 238000006467 substitution reaction Methods 0.000 claims description 12
- 230000008569 process Effects 0.000 description 83
- 238000012937 correction Methods 0.000 description 36
- 238000004891 communication Methods 0.000 description 30
- 230000006870 function Effects 0.000 description 14
- 238000004590 computer program Methods 0.000 description 11
- 238000010586 diagram Methods 0.000 description 11
- 239000011159 matrix material Substances 0.000 description 10
- 230000001755 vocal effect Effects 0.000 description 10
- 230000003287 optical effect Effects 0.000 description 8
- 230000000694 effects Effects 0.000 description 6
- 230000001413 cellular effect Effects 0.000 description 5
- 230000003993 interaction Effects 0.000 description 5
- 238000012015 optical character recognition Methods 0.000 description 5
- 238000009877 rendering Methods 0.000 description 5
- 238000005516 engineering process Methods 0.000 description 4
- 238000001914 filtration Methods 0.000 description 4
- 239000004973 liquid crystal related substance Substances 0.000 description 4
- 238000013507 mapping Methods 0.000 description 4
- 238000010801 machine learning Methods 0.000 description 3
- 230000006855 networking Effects 0.000 description 3
- 230000002085 persistent effect Effects 0.000 description 3
- 230000004044 response Effects 0.000 description 3
- 230000009471 action Effects 0.000 description 2
- 230000008901 benefit Effects 0.000 description 2
- 230000005540 biological transmission Effects 0.000 description 2
- 238000004422 calculation algorithm Methods 0.000 description 2
- 238000007726 management method Methods 0.000 description 2
- 238000005259 measurement Methods 0.000 description 2
- 230000000644 propagated effect Effects 0.000 description 2
- 230000009466 transformation Effects 0.000 description 2
- 238000000844 transformation Methods 0.000 description 2
- 230000000007 visual effect Effects 0.000 description 2
- 230000006978 adaptation Effects 0.000 description 1
- 230000003044 adaptive effect Effects 0.000 description 1
- 238000013528 artificial neural network Methods 0.000 description 1
- 230000027455 binding Effects 0.000 description 1
- 238000009739 binding Methods 0.000 description 1
- 239000011230 binding agent Substances 0.000 description 1
- 238000004364 calculation method Methods 0.000 description 1
- 230000008859 change Effects 0.000 description 1
- 230000000295 complement effect Effects 0.000 description 1
- 239000000470 constituent Substances 0.000 description 1
- 238000013500 data storage Methods 0.000 description 1
- 230000001419 dependent effect Effects 0.000 description 1
- 238000011161 development Methods 0.000 description 1
- 238000006073 displacement reaction Methods 0.000 description 1
- VJYFKVYYMZPMAB-UHFFFAOYSA-N ethoprophos Chemical compound CCCSP(=O)(OCC)SCCC VJYFKVYYMZPMAB-UHFFFAOYSA-N 0.000 description 1
- 238000000605 extraction Methods 0.000 description 1
- 239000000835 fiber Substances 0.000 description 1
- 238000003384 imaging method Methods 0.000 description 1
- 230000006872 improvement Effects 0.000 description 1
- 238000012417 linear regression Methods 0.000 description 1
- 230000007774 longterm Effects 0.000 description 1
- 229910044991 metal oxide Inorganic materials 0.000 description 1
- 150000004706 metal oxides Chemical class 0.000 description 1
- 239000000203 mixture Substances 0.000 description 1
- 238000010295 mobile communication Methods 0.000 description 1
- 238000012986 modification Methods 0.000 description 1
- 230000004048 modification Effects 0.000 description 1
- 239000004065 semiconductor Substances 0.000 description 1
- 230000001953 sensory effect Effects 0.000 description 1
- 239000007787 solid Substances 0.000 description 1
- 230000005236 sound signal Effects 0.000 description 1
- 239000013589 supplement Substances 0.000 description 1
- 230000001360 synchronised effect Effects 0.000 description 1
- 239000010409 thin film Substances 0.000 description 1
- 210000003813 thumb Anatomy 0.000 description 1
- 230000007704 transition Effects 0.000 description 1
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/20—Natural language analysis
- G06F40/232—Orthographic correction, e.g. spell checking or vowelisation
Definitions
- the present disclosure relates to the recognition of text in various media.
- Voice recognition systems capable of detecting audio speech signals and converting them into related text have been deployed to allow users to interact with computers through voice commands. For example, voice recognition systems have been used to automate the answering and processing of customer service calls.
- OCR Optical Character Recognition
- Text recognition systems may use machine learning models that are trained using a large set of training data.
- the training data may include audio voice signals and paired text equivalents or labels. Generating the data set used to train a text recognition system may be expensive.
- US 2009/240488 A1 describes a method for facilitating the updating of a language model, which includes receiving, at a client device, via a microphone, an audio message corresponding to speech of a user; communicating the audio message to a first remote server; receiving, that the client device, a result, transcribed at the first remote server using an automatic speech recognition system ("ASR"), from the audio message; receiving, at the client device from the user, an affirmation of the result; storing, at the client device, the result in association with an identifier corresponding to the audio message; and communicating, to a second remote server, the stored result together with the identifier.
- ASR automatic speech recognition system
- one aspect of the subject matter described in this specification can be embodied in a method that includes receiving an input signal comprising data that corresponds to one or more words.
- the method may further include passing the input signal to a text recognition system that generates a recognized text string based on the input signal.
- the method may further include receiving the recognized text string from the text recognition system.
- the method may further include presenting the recognized text string to a user.
- the method may further include receiving a corrected text string based on input from the user.
- the method may further include checking if an edit distance between the corrected text string and the recognized text string is below a threshold.
- the method may further include if the edit distance is below the threshold, passing the corrected text string to the text recognition system for training purposes.
- one aspect of the subject matter described in this specification can be embodied in a system that includes a data processing apparatus and a memory coupled to the data processing apparatus.
- the memory having instructions stored thereon which, when executed by the data processing apparatus cause the data processing apparatus to perform operations including receiving an input signal comprising data that corresponds to one or more words.
- the operations may further include passing the input signal to a text recognition system that generates a recognized text string based on the input signal.
- the operations may further include receiving the recognized text string from the text recognition system.
- the operations may further include presenting the recognized text string to a user.
- the operations may further include receiving a corrected text string based on input from the user.
- the operations may further include checking if an edit distance between the corrected text string and the recognized text string is below a threshold.
- the operations may further include, if the edit distance is below the threshold, passing the corrected text string to the text recognition system for training purposes.
- a mobile device that includes a microphone configured to receive an input signal comprising data that corresponds to one or more words.
- the mobile device may further include a wireless network interface configured to transmit the input signal to a text recognition system that generates a recognized text string based on the input signal.
- the mobile device may further include a wireless network interface configured to receive the recognized text string from the text recognition system.
- the mobile device may further include a display configured to present the recognized text string to a user.
- the mobile device may further include a user interface configured to receive one or more edits to the recognized text string from the user.
- the mobile device may further include a module configured to determine a corrected text string based on the recognized text string and the edits.
- the mobile device may further include means for checking if an edit distance between the corrected text string and the recognized text string is below a threshold.
- the mobile device may further include a wireless network interface configured to, if the edit distance is below the threshold, pass the corrected text string to the text recognition system for training purposes.
- one aspect of the subject matter described in this specification can be embodied in a system that includes an interface configured to receive an input signal comprising data that corresponds to one or more words.
- the system may further include an interface configured to pass the input signal to a text recognition system that generates a recognized text string based on the input signal.
- the system may further include an interface configured to receive the recognized text string from the text recognition system.
- the system may further include an interface configured to present the recognized text string to a user.
- the system may further include an interface configured to receiving a corrected text string based on input from the user.
- the system may further include means for checking if an edit distance between the corrected text string and the recognized text string is below a threshold.
- the system may further include an interface configured to, if the edit distance is below the threshold, pass the corrected text string to the text recognition system for training purposes.
- one aspect of the subject matter described in this specification can be embodied in a computer readable medium storing software including instructions executable by a processing device that upon such execution cause the processing device to perform operations that include receiving an input signal comprising data that corresponds to one or more words.
- the operations may further include passing the input signal to the text recognition system that generates a recognized text string based on the input signal.
- the operations may further include receiving the recognized text string from the text recognition system.
- the operations may further include presenting the recognized text string to a user.
- the operations may further include receiving a corrected text string based on input from the user.
- the operations may further include checking if an edit distance between the corrected text string and the recognized text string is below a threshold.
- the operations may further include, if the edit distance is below the threshold, passing the corrected text string to the text recognition system for training purposes.
- the edit distance may represent a Levenshtein distance.
- the edit distance may represent the minimum number of single character insertion, deletion, or substitution operations required to transform the recognized text string into the corrected text string.
- the edit distance may be a minimum number of write operations, from a set of allowed operations, needed to produce the corrected text string from the recognized text string, wherein write operations include character insertion and character substitution, and wherein character deletion is allowed but not counted in the edit distance.
- the edit distance may be a maximum number of consecutive characters inserted.
- the input signal may be an auditory speech signal.
- the input signal may be an image signal.
- the text recognition system may be executed by a remotely located server.
- the text recognition system may be executed by a user device.
- Passing the input signal to a text recognition system may include transmitting a signal encoding the input signal through a network.
- Checking if an edit distance between the corrected text string and the recognized text string is below threshold may include determining the edit distance and comparing the edit distance to the threshold.
- Checking if an edit distance between the corrected text string and the recognized text string is below threshold may include computing intermediate edit distance values until the threshold is exceeded or the edit distance is determined.
- Receiving a corrected text string based on input from the user may include receiving data that represents one or more user edits to the recognized text string and determining a corrected text string based on the recognized text string and the edits.
- the units of the edit distance may represent a number of characters.
- the units of the edit distance may represent a number of phonemes.
- the units of the edit distance may represent a number of words.
- the threshold may depend on a length of the corrected text string.
- the threshold may be approximately fifty percent of the length of the corrected text string.
- Presenting the recognized text string to a user may include transmitting the recognized text to a user device for display to the user.
- Presenting the recognized text string to a user may include displaying the recognized text on a display.
- Some implementations may facilitate the training machine learning based text recognition systems. Some implementations may filter out less useful data from a set of training data collected from a user. Along with reducing the cost of text recognition services by providing low cost data for training purposes, some implementations may improve the quality of a text recognition service by providing more reliable data for training purposes. Some implementations may facilitate adaptation of text recognition systems to the characteristics of individual users.
- a text recognition system (e.g., a speech recognition system or OCR system) is used to extract text from input signals that reflect information including words or other symbols.
- a text recognition system may include a machine learning system (e.g., a hidden markov model, a feature based linear regression, an artificial neural network) that trains a model, used to detect text in input signals, by analyzing numerous example input signals that have each been paired with a known text string representing the words or symbols that are reflected in that input signal.
- a set of input signal and text string pairs used for this purpose may be considered training data.
- additional training data may be collected from one or more users of a text recognition system and used to further refine a model used by the text recognition system. When many users (e.g., thousands of users) access and utilize a text recognition system through a network, the users may collectively be a vast and cost efficient source of training data.
- the accuracy of text recognition systems may be improved by feeding back corrections that a user made to a given recognized text string.
- a user of a speech recognition service may say "pictures of the Golden Gate Bridge at sunset" as part of verbal search query.
- the speech recognition service may recognize "pictures of Golden Gate Bridge and sunset”.
- the user could then edit the text returned from the speech recognition service and correct the mistakes made by the service.
- the resulting corrected text string may then be paired with the input audio speech signal to form an example that may be used by the speech recognition system underling the service as training data.
- the user may make significant changes to the recognition text or even write a completely new text.
- This circumstance may arise due to, for example, a low signal to noise ratio in the input signal, user error, or a user who is making the edits for a primary purpose other than training the speech recognition system, i.e. inputting what the user intended to say rather than what the user actually said.
- it may not be helpful to feed the user's edits back into the speech recognition service for use as training data, since the new text is not necessarily closely related to the originally spoken query anymore.
- An edit distance between the recognized text string and a corrected text string that results from a user's edits may be used to measure the significance of user edits.
- the edit distance between two text strings may measure how many edit operations are required to change one text into another. For example, the Levenshtein distance between the two text strings is the minimum number of single character insertion, deletion, or substitution operations required to transform one text string into the other. Only user corrections with edit distances that are below a pre-defined threshold would typically be taken into account for future text recognition system training and improvements. All other changes may be deemed too significant to be useful. In this manner, edit distance calculation and thresholding may be used to filter corrected text strings collected from users to provide a more reliable set of training data.
- FIG. 1 is a block diagram of an example online environment 100 in which a text recognition corrections filter may be utilized to selectively collect training data for a text recognition system.
- a speech recognition system 108 is part of a verbal search server system 101 available to users through a network 104.
- the speech recognition system 108 may include training data 120 that it uses to determine model parameters 122. Model parameters may then be used to identify words occurring in an audio input signal.
- the set of training data may be large and may be stored in storage system 130.
- Users access the verbal search service from their devices 134, 136 (e.g., smart phones, tablet computing devices, computers, etc.). Users may use their devices to interact with the search server system 101 by submitting application commands 140. For example, a user of mobile device 136 may submit a verbal search term 142 to the search server system 101.
- the verbal search term may include an audio input signal and is received using the interface 102 and passed to the request processor 112.
- the request processor 112 may then send the audio portion of the received request to the speech recognition system 108, which identifies words in the audio and returns a recognized text string that may be used as a search query.
- the resulting formatted search query is then passed to the search engine 114, which searches its index 116 and outputs a set of search results to the response formatter 118.
- the response formatter 118 may generate a responsive webpage or other type of response (e.g., text, imagery, etc.).
- the responsive webpage may be transmitted by the interface 102 through the network 104 to mobile device 136.
- the responsive webpage may include a display of the text search term 144 derived from the recognized text string and search results 146. The user of mobile device may then perceive an error in the text search term that resulted from the user's verbal search term.
- the corrected search term 150 may be received, through interface 102, by both the request processor 112 and a text recognition corrections filter 110.
- the text recognition corrections filter 110 may have previously received the recognized text string that resulted from the verbal search term 142 from the speech recognition system 108.
- the text recognition corrections filter 110 may use one or more edit distances between the recognized text string that resulted from the verbal search term and the corrected search term to assess the likely value of the corrected search term as training data.
- the text recognition corrections filter 110 may apply thresholds to the edit distances to determine whether the corrected search term should be used as training data by the speech recognition system 108. Corrected search terms selected in this manner may be passed to the speech recognition system 108, possibly along with the corresponding verbal search term, and stored in the storage device 130 for use in future training to adjust the model parameters 122.
- the text recognition corrections filter 110 may be implemented as software, hardware or a combination of software and hardware that is executed on a processing apparatus, such as one or more computing devices (e.g., a computer system as illustrated in FIG. 7 ).
- a processing apparatus such as one or more computing devices (e.g., a computer system as illustrated in FIG. 7 ).
- FIG. 2A is a flow chart of an example process 200 for collecting and filtering text recognition system corrections from users of a text recognition system.
- a user interaction with a text recognition system is facilitated and results in a correction of recognized text string by the user.
- An edit distance between a recognized text string and the resulting corrected text string is checked to determine if the distance is below a threshold.
- corrected text strings with distances above the threshold are filtered out. Corrected text strings with distances below the threshold are passed to the text recognition system for use as training data to further adapt or refine the a text extraction model used by the text recognition system.
- the process 200 can be implemented, for example, by the text recognition correction filter 110 in the search server system 101 of FIG. 1 .
- the search server system 101 is a data processing apparatus that includes one or more processors that are configured to perform actions of the process 200.
- the data processing apparatus may be a computing device (e.g., as illustrated in FIG.7 ).
- the process 200 may be implemented by a text recognition correction filter that is executed by a user's mobile computing device (e.g., also illustrated in FIG. 7 ).
- process 200 may be implemented by the text recognition correction filter 552 that is executed by the mobile device described in FIGS. 3-6 .
- a computer readable medium can include instructions that when executed by a computing device (e.g., a computer system) cause the device to perform actions of the process 200.
- An input signal including information representing one or more words or symbols is received 202.
- the input signal may be an audio speech signal that is input to a verbal search service.
- the input signal may be an image file containing a picture of printed words, e.g., a sign or a page from a book.
- the words or symbols represented in the input signal may be in any language the text recognition system is capable of processing (e.g., English or Chinese).
- the input signal may be received 202 from a user device 134, 136 (e.g., a cell phone).
- the input signal may be received via a server system interface component 102 of the search server system 101.
- the input signal may be received 202 through a microphone on a user device (e.g. microphone 309).
- the input signal may be received 202 through a camera on a user device (e.g. camera 307).
- the input signal is passed 204 to a text recognition system.
- the text recognition system runs on a remote server.
- passing 204 the input signal may be accomplished by transmitting the input signal via a network, using a network interface (e.g., a wireless network interface including an antenna).
- the text recognition system is integrated with and runs on the same local device as process 200.
- passing 204 the input signal may be accomplished by storing the input signal in a particular memory location or passing a pointer to input signal into the text recognition system as an argument to an application programmer interface function.
- a recognized text string is received 206 from the text recognition server.
- the text recognition system may identify words or other symbols represented in the input signal and generate a recognized text string that is a text representation of the identified words or symbols.
- the recognized text string may be a sequence of characters encoded in accordance with a standard character-encoding scheme (e.g., American Standard Code for Information Interchange (ASCII)).
- ASCII American Standard Code for Information Interchange
- the recognized text string may be received 206 in a variety of ways (e.g., from a remote server through a network, by dereferencing a pointer to memory, etc.).
- the recognized text string may be presented 208 to a user.
- the recognized text string may be presented by rendering a visual representation of the recognized text string on the display (e.g., a liquid crystal display) of a user device.
- the recognized text string may be presented on display 301 of FIG.3 .
- presentation to a user may be accomplished by transmitting the recognized text string to a user device.
- the text recognition corrections filter 110 may present 208 the recognized text by transmitting the recognized text to a remote user device 136.
- a corrected text string based on input from the user may be received 210.
- the corrected text string may be a sequence of characters encoded in accordance with a standard character-encoding scheme (e.g., ASCII) that reflects user input.
- ASCII standard character-encoding scheme
- a user presented with the recognized string may input edits to the text through a user interface (e.g., a keypad or a touch-screen display).
- the corrected text string may be determined by interpreting the user's edit commands and applying them to a copy of the recognized text string.
- a corrected text string may be derived from user edits input through keyboard 302 on the mobile device of FIG. 3 .
- the corrected string is received 210 in a communication signal from a remote device through a network.
- the text recognition correction filter 110 may receive, through the interface 102, a corrected text string that has been transmitted through a network by a user device.
- a check 212 is performed to determine whether an edit distance between the recognized text string and the corrected text string is below a threshold.
- the edit distance may provide an indication of how similar the two text strings are.
- an edit distance is determined and then compared to a threshold, e.g., the data flow of FIG. 2B .
- a threshold e.g., the data flow of FIG. 2B .
- algorithms for calculating the edit distance exist that have monotonic properties, which may allow a determination of whether or not an edit distance will be below a threshold before the complete edit distance computation has been completed.
- intermediate values may be computed in an accordance with an edit distance computation algorithm until it is determined that the edit distance must exceed the threshold or until the edit distance is determined, e.g., the program listing of FIG. 2D .
- Levenshtein distance between two portions of text e.g., word, passage, etc.
- the allowed edit operations are typically insertion of a single character, deletion of a single character, and substitution of a single character.
- a modified Levenshtein distance may be used that counts the minimum number of insertions of single character and substitutions of a single character, while disregarding deletions of characters required to transform between the two texts.
- This modified Levenshtein distance may be a useful edit distance in a text recognition corrections filter, because noisy input signals (e.g., background noise in a speech audio signal) may cause extra characters in the recognized text when underlying words or symbols are not present (e.g., silence periods or pauses in speech). This circumstance may make deletions more common and less informative.
- a process for checking this edit distance is describe in relation to FIG. 2D .
- Another example of an edit distance is the maximum number of consecutive characters inserted to form the corrected text string.
- the maximum number of consecutive characters inserted is also checked by the process described in relation to FIG. 2D .
- multiple edit distances may be checked and a corrected text string may be selected for training if all of the edit distances are below their respective thresholds.
- Edit distances and their thresholds may be measured in a variety of units.
- speech recognition systems may return a sequence of coded phonemes or coded words, which in turn may be represented as sequences of characters.
- the edit distance used may define the set of allowable operations to be on insertion, deletions, or substitutions of single phonemes or of single words.
- the threshold may depend on properties of the recognized text string or the corrected text string.
- the threshold for the edit distance may be set to a percentage (e.g., 50%) of the length of the corrected text string.
- a different threshold may be used for each distance metric used.
- a fixed threshold e.g., 15 characters
- the exact value of the threshold may be determined iteratively and may remain flexible throughout the life of the system. Updates to the threshold, may depend in part on a performance metric differential for a text recognition system before and after training with corrections data collected using the previous value of the threshold.
- the edit distance may be checked 212 by the text recognition corrections filter module 110 of the search server system 101.
- the edit distance may be checked 212 by the text recognition correction filter 552 of the mobile device, illustrated in FIGS. 3-6 .
- the corrected text string is selected for use as training data for a text recognition system.
- the corrected text string may be passed 216 to the text recognition system for training purposes.
- the corrected text string may be passed 216 in a variety of ways (e.g., transmitting, copying to memory, etc.) that may depended on a nature of the system implementing process 200 is and its relationship to the text recognition system.
- a text recognition system may immediately update its model parameters based on the corrected text string.
- the text recognition system may store the corrected text string for later use in training.
- selected corrected text strings may be stored locally before being passed to the text recognition system in batches (e.g., periodically or after a certain number of strings have been selected).
- Process 200 may then terminate 218 or wait for new input signals for a text recognition system before restarting.
- FIG. 2B is a data flow diagram of an example module 220 for checking whether an edit distance between a recognized text string and a corrected text string is below a threshold.
- the diagram illustrates a check on exemplary data.
- the module 220 accepts a recognized text string ("Home") and a corresponding corrected text string ("House"). These two text strings are first passed into an edit distance module 222 that determines an edit distance between the two strings.
- the edit distance module 222 may implement a process 250 (illustrated in FIG. 2C ) to determine the Levenshtein distance between the two strings.
- the Levenshtein distance between Home and House is 2.
- the edit distance module 222 outputs an edit distance of 2 and passes the quantity to a threshold module 224 that compares the edit distance to a threshold and outputs a classification of the corrected text.
- the classification may be a binary output (e.g., yes or no, zero or one) indicating whether the edit distance was below the threshold, and by implication whether the corrected text string is likely to be useful for training.
- the threshold used by the threshold module 224 is 50% of the length of the corrected text string, in this case 2.5. Since the distance is below the threshold, the threshold module outputs a "yes" classification, which in turn is output by module 220.
- module 220 may be implemented as part of the text recognition correction filter 110 of the search server system 101.
- the module 220 may be implemented by the text recognition corrections filter 552 of the mobile device 300.
- FIG. 2C is a flow chart of an example process 250 for determining a Levenshtein distance between a recognized text string and a corrected text string.
- the process sequentially builds a matrix of distances, i.e. counts of edit operations. The value of each element will be set to the Levenshtein distance between prefixes of the two strings with lengths corresponding to the row and column numbers. The value of the last element of the matrix calculated (last row, last column) is the Levenshtein distance between the complete recognized text string and the complete corrected text string.
- process 250 may be implemented by the text recognition correction filter 110 of the search server system 101.
- the process 250 may be implemented by the text recognition corrections filter 552 of the mobile device 300.
- the corrected text string and the recognized text string are retrieved 252 and the distance matrix is initialized 254.
- the dimension of the distance matrix depends on the lengths of the two text strings and is equal to one plus the length of the corrected text string by one plus the length of the recognized text string.
- rows of the matrix correspond to characters of the corrected text string and columns correspond to characters of the recognized text string.
- the first row and first column of the distance matrix both correspond to null strings, i.e. strings with no characters.
- the element in the first row and column is set to the distance between two null strings, i.e. zero.
- the remaining elements in the first row are set to length of the prefix of the recognized text string that ends with the character corresponding to the element's column.
- the remaining elements in the first column are set to length of the prefix of the corrected text string that ends with the character corresponding to the element's row.
- the element values may be determined based on whether individual characters, corresponding to the row and column, match and the distance values for nearby elements in the matrix, i.e. for prefixes of the same length or one character less. Processing starts in second row 256, second column 258, which corresponds to the first character of the corrected text string and the first character of the recognized text string.
- the character of the corrected text string corresponding to the current row is compared 260 to the character of the recognized text string corresponding to the current column. If the two characters are equivalent, then the distance for this element is set 262 to the value stored for the element in the previous row, previous column. Otherwise, the distance will typically be set 264 to a value incremented from value stored in a previous element of the matrix.
- the current distance element may be set 264 to one plus the minimum of the distances stored in (previous row, previous column); (previous row, current column); and (current row, previous column).
- FIGS. 2D-G are a code listing for an example process for checking if an edit distance is below a threshold.
- the example process actually checks two edit distances.
- the first edit distance is a modified Levenshtein distance that allows deletion, insertion, and substitution edit operations in the transformations between the recognized text string and the corrected text string, but does not count deletion operations in the distance value, i.e. deletions are considered a free operation.
- other edit operations may be given different weights in an edit distance (e.g., a substitution operation counts as 2, an insertion operation counts as 1, and a deletion operation counts as zero).
- Elements of the distance matrix with values greater than the threshold need not be calculated and are considered as dead-ends because subsequent values derived from them can only be the same or higher.
- the check process may terminate, possibly without calculating the final edit distance for the two text strings, and return an indication that the edit distance was not below the threshold.
- the example code listing sets the threshold for the first edit distance to a percentage (e.g., 50%) of the length of the corrected text string.
- the second edit distance is a maximum number of consecutive character insertion operations used to derive the corrected text string from the recognized text string.
- the example code listing sets the threshold for the second edit distance to a fixed value (e.g., 15 characters).
- FIG. 2D provides a high level class definition in the C++ programing language for a module 270 that will check whether these two edit distances are both below their respective thresholds.
- the getDistance function 280 accepts a recognized text string and a corrected text string as inputs and returns an edit distance that may saturate at the threshold or just above the threshold.
- a full definition of the getDistance function 280 is provide in FIG. 2E .
- the DeltaTable class 290 distance matrices used by the module to check whether the edit distances are below the threshold. Due to the structure of the distances matrices rows before the previous row may be discarded while the check computations are ongoing, thus saving memory usage. A full definition of the DeltaTable class 290 is provide in FIG. 2F .
- the Delta class 295 defines the properties of objects that may be used to track the state of the module as it checks whether the edit distances are below their respective thresholds. A full definition of the Delta class 295 is provided in FIG. 2G .
- module 270 may be implemented by the text recognition corrections filter module 110 of the search server system 101.
- the module 270 may be implemented by the text recognition corrections filter 552 of the mobile device 300.
- the device 300 includes a processor configured to selectively collect user corrections to text recognition strings and pass them to a text recognition system for use as training data.
- the hardware environment of the device 300 includes a display 301 for displaying text, images, and video to a user; a keyboard 302 for entering text data and user commands into the device 300; a pointing device 304 for pointing, selecting, and adjusting objects displayed on the display 301; an antenna 305; a network connection 306; a camera 307; a microphone 309; and a speaker 310.
- the device 300 shows an external antenna 305, the device 300 can include an internal antenna, which is not visible to the user.
- the display 301 can display video, graphics, images, and text that make up the user interface for the software applications used by the device 300, and the operating system programs used to operate the device 300.
- a new mail indicator 311 that alerts a user to the presence of a new message
- an active call indicator 312 that indicates that a telephone call is being received, placed, or is occurring
- a data standard indicator 314 that indicates the data standard currently being used by the device 300 to transmit and receive data
- a signal strength indicator 315 that indicates a measurement of the strength of a signal received by via the antenna 305, such as by using signal strength bars
- a battery life indicator 316 that indicates a measurement of the remaining battery life
- a clock 317 that outputs the current time.
- the display 301 may also show application icons representing various applications available to the user, such as a web browser application icon 319, a phone application icon 320, a search application icon 321, a contacts application icon 322, a mapping application icon 324, an email application icon 325, or other application icons.
- the display 301 is a quarter video graphics array (QVGA) thin film transistor (TFT) liquid crystal display (LCD), capable of 16-bit or better color.
- QVGA quarter video graphics array
- TFT thin film transistor
- a user uses the keyboard (or "keypad”) 302 to enter commands and data to operate and control the operating system and applications that provide for interaction with text recognition systems.
- the keyboard 302 includes standard keyboard buttons or keys associated with alphanumeric characters, such as keys 326 and 327 that are associated with the alphanumeric characters "Q" and "W” when selected alone, or are associated with the characters "*" and "1” when pressed in combination with key 329.
- a single key may also be associated with special characters or functions, including unlabeled functions, based upon the state of the operating system or applications invoked by the operating system. For example, when an application calls for the input of a numeric character, a selection of the key 327 alone may cause a "1" to be input.
- the keyboard 302 also includes other special function keys, such as an establish call key 330 that causes a received call to be answered or a new call to be originated; a terminate call key 331 that causes the termination of an active call; a drop down menu key 332 that causes a menu to appear within the display 301; a backward navigation key 334 that causes a previously accessed network address to be accessed again; a favorites key 335 that causes an active web page to be placed in a bookmarks folder of favorite sites, or causes a bookmarks folder to appear; a home page key 336 that causes an application invoked on the device 300 to navigate to a predetermined network address; or other keys that provide for multiple-way navigation, application selection, and power and volume control.
- an establish call key 330 that causes a received call to be answered or a new call to be originated
- a terminate call key 331 that causes the termination of an active call
- a drop down menu key 332 that causes a menu to appear within the display 301
- a backward navigation key 334 that
- the user uses the pointing device 304 to select and adjust graphics and text objects displayed on the display 301 as part of the interaction with and control of the device 300 and the applications invoked on the device 300.
- the pointing device 304 is any appropriate type of pointing device, and may be a joystick, a trackball, a touch-pad, a camera, a voice input device, a touch screen device implemented in combination with the display 301, or any other input device.
- the antenna 305 which can be an external antenna or an internal antenna, is a directional or omni-directional antenna used for the transmission and reception of radiofrequency (RF) signals that implement point-to-point radio communication, wireless local area network (LAN) communication, or location determination.
- the antenna 305 may facilitate point-to-point radio communication using the Specialized Mobile Radio (SMR), cellular, or Personal Communication Service (PCS) frequency bands, and may implement the transmission of data using any number or data standards.
- SMR Specialized Mobile Radio
- PCS Personal Communication Service
- the antenna 305 may allow data to be transmitted between the device 300 and a base station using technologies such as Wireless Broadband (WiBro), Worldwide Interoperability for Microwave ACCess (WiMAX), 3GPP Long Term Evolution (LTE), Ultra Mobile Broadband (UMB), High Performance Radio Metropolitan Network (HIPERMAN), iBurst or High Capacity Spatial Division Multiple Access (HC-SDMA), High Speed OFDM Packet Access (HSOPA), High-Speed Packet Access (HSPA), HSPA Evolution, HSPA+, High Speed Upload Packet Access (HSUPA), High Speed Downlink Packet Access (HSDPA), Generic Access Network (GAN), Time Division-Synchronous Code Division Multiple Access (TD-SCDMA), Evolution-Data Optimized (or Evolution-Data Only)(EVDO), Time Division-Code Division Multiple Access (TD-CDMA), Freedom Of Mobile Multimedia Access (FOMA), Universal Mobile Telecommunications System (UMTS), Wideband Code Division Multiple Access (W-CDMA), Enhanced Data rates for G
- Communication via W-CDMA, HSUPA, GSM, GPRS, and EDGE networks may occur, for example, using a QUALCOMM MSM7200A chipset with a QUALCOMM RTR6285TM transceiver and PM7540TM power management circuit.
- the wireless or wired computer network connection 306 may be a modem connection, a local-area network (LAN) connection including the Ethernet, or a broadband wide-area network (WAN) connection such as a digital subscriber line (DSL), cable high-speed internet connection, dial-up connection, T-1 line, T-3 line, fiber optic connection, or satellite connection.
- the network connection 306 may connect to a LAN network, a corporate or government WAN network, the Internet, a telephone network, or other network.
- the network connection 306 uses a wired or wireless connector.
- Example wireless connectors include, for example, an INFRARED DATA ASSOCIATION (IrDA) wireless connector, a Wi-Fi wireless connector, an optical wireless connector, an INSTITUTE OF ELECTRICAL AND ELECTRONICS ENGINEERS (IEEE) Standard 802.11 wireless connector, a BLUETOOTH wireless connector (such as a BLUETOOTH version 1.2 or 3.0 connector), a near field communications (NFC) connector, an orthogonal frequency division multiplexing (OFDM) ultra wide band (UWB) wireless connector, a time-modulated ultra wide band (TM-UWB) wireless connector, or other wireless connector.
- IrDA INFRARED DATA ASSOCIATION
- Wi-Fi Wireless Fidelity
- Example wired connectors include, for example, an IEEE-1394 FIREWIRE connector, a Universal Serial Bus (USB) connector (including a mini-B USB interface connector), a serial port connector, a parallel port connector, or other wired connector.
- USB Universal Serial Bus
- the functions of the network connection 306 and the antenna 305 are integrated into a single component.
- the camera 307 allows the device 300 to capture digital images, and may be a scanner, a digital still camera, a digital video camera, or other digital input device.
- the camera 307 is a 3 mega-pixel (MP) camera that utilizes a complementary metal-oxide semiconductor (CMOS).
- CMOS complementary metal-oxide semiconductor
- the microphone 309 allows the device 300 to capture sound, and may be an omni-directional microphone, a unidirectional microphone, a bi-directional microphone, a shotgun microphone, or other type of apparatus that converts sound to an electrical signal.
- the microphone 309 may be used to capture sound generated by a user, for example when the user is speaking to another user during a telephone call via the device 300.
- the speaker 310 allows the device to convert an electrical signal into sound, such as a voice from another user generated by a telephone application program, or a ring tone generated from a ring tone application program.
- the device 300 is illustrated in FIG. 3 as a handheld device, in further implementations the device 300 may be a laptop, a workstation, a midrange computer, a mainframe, an embedded system, telephone, desktop PC, a tablet computer, a PDA, or other type of computing device.
- FIG. 4 is a block diagram illustrating an internal architecture 400 of the device 300.
- the architecture includes a central processing unit (CPU) 401 where the computer instructions that comprise an operating system or an application are processed; a display interface 402 that provides a communication interface and processing functions for rendering video, graphics, images, and texts on the display 301, provides a set of built-in controls (such as buttons, text and lists), and supports diverse screen sizes; a keyboard interface 404 that provides a communication interface to the keyboard 302; a pointing device interface 405 that provides a communication interface to the pointing device 304; an antenna interface 406 that provides a communication interface to the antenna 305; a network connection interface 407 that provides a communication interface to a network over the computer network connection 306; a camera interface 408 that provides a communication interface and processing functions for capturing digital images from the camera 307; a sound interface 409 that provides a communication interface for converting sound into electrical signals using the microphone 309 and for converting electrical signals into sound using the speaker 310; a random
- RAM random access memory
- ROM read-only memory
- PROM programmable read-only memory
- EPROM erasable programmable read-only memory
- EEPROM electrically erasable programmable read-only memory
- magnetic disks optical disks, floppy disks, hard disks, removable cartridges, flash drives
- application programs 415 including, for example, a web browser application, a widget or gadget engine, and or other applications, as necessary
- data files 416 are stored
- application programs 415 including, for example, a web browser application, a widget or gadget engine, and or other applications, as necessary
- EEPROM electrically erasable programmable read-only memory
- magnetic disks optical disks
- floppy disks hard disks, removable cartridges, flash drives
- a navigation module 417 that provides a real-world or relative position or geographic location of the device 300
- power source 419 that provides an appropriate alternating current (AC) or direct current (DC) to power components
- the CPU 401 can be one of a number of computer processors. In one arrangement, the computer CPU 401 is more than one processing unit.
- the RAM 410 interfaces with the computer bus 421 so as to provide quick RAM storage to the CPU 401 during the execution of software programs such as the operating system application programs, and device drivers. More specifically, the CPU 401 loads computer-executable process steps from the storage medium 412 or other media into a field of the RAM 410 in order to execute software programs. Data is stored in the RAM 410, where the data is accessed by the computer CPU 401 during execution.
- the device 300 includes at least 128MB of RAM, and 256MB of flash memory.
- the storage medium 412 itself may include a number of physical drive units, such as a redundant array of independent disks (RAID), a floppy disk drive, a flash memory, a USB flash drive, an external hard disk drive, thumb drive, pen drive, key drive, a High-Density Digital Versatile Disc (HD-DVD) optical disc drive, an internal hard disk drive, a Blu-Ray optical disc drive, or a Holographic Digital Data Storage (HDDS) optical disc drive, an external mini-dual in-line memory module (DIMM) synchronous dynamic random access memory (SDRAM), or an external micro-DIMM SDRAM.
- Such computer readable storage media allow the device 300 to access computer-executable process steps, application programs and the like, stored on removable and non-removable memory media, to off-load data from the device 300, or to upload data onto the device 300.
- a computer program product is tangibly embodied in storage medium 412, a machine-readable storage medium.
- the computer program product includes instructions that, when read by a machine, operate to cause a data processing apparatus to store image data in the mobile device.
- the computer program product includes instructions that cause a data processing apparatus to collect and filtering text recognition system corrections from users of a text recognition system.
- the operating system 414 may be a LINUX-based operating system such as a mobile device platform; APPLE MAC OS X; MICROSOFT WINDOWS NT/WINDOWS 2000/WINDOWS XP/WINDOWS MOBILE; a variety of UNIX-flavored operating systems; or a proprietary operating system for computers or embedded systems.
- LINUX-based operating system such as a mobile device platform; APPLE MAC OS X; MICROSOFT WINDOWS NT/WINDOWS 2000/WINDOWS XP/WINDOWS MOBILE; a variety of UNIX-flavored operating systems; or a proprietary operating system for computers or embedded systems.
- the application development platform or framework for the operating system 414 may be: BINARY RUNTIME ENVIRONMENT FOR WIRELESS (BREW); JAVA Platform, Micro Edition (JAVA ME) or JAVA 2 Platform, Micro Edition (J2ME) using the SUN MICROSYSTEMS JAVASCRIPT programming language; PYTHONTM, FLASH LITE, or MICROSOFT .NET Compact, or another appropriate environment.
- BREW BINARY RUNTIME ENVIRONMENT FOR WIRELESS
- JAVA ME JAVA ME
- J2ME JAVA 2 Platform, Micro Edition
- PYTHONTM FLASH LITE
- MICROSOFT .NET Compact or another appropriate environment.
- the device stores computer-executable code for the operating system 414, and the application programs 415 such as an email, instant messaging, a video service application, a mapping application word processing, spreadsheet, presentation, gaming, mapping, web browsing, JAVASCRIPT engine, or other applications.
- the application programs 415 may also include a widget or gadget engine, such as a TAFRITM widget engine, a MICROSOFT gadget engine such as the WINDOWS SIDEBAR gadget engine or the KAPSULESTM gadget engine, a YAHOO!
- widget engine such as the KONFABULTORTM widget engine, the APPLE DASHBOARD widget engine, a gadget engine, the KLIPFOLIO widget engine, an OPERATM widget engine, the WIDSETSTM widget engine, a proprietary widget or gadget engine, or other widget or gadget engine the provides host system software for a physically-inspired applet on a desktop.
- DLL dynamic link library
- Plug-in to other application programs such as an Internet web-browser such as the FOXFIRE web browser, the APPLE SAFARI web browser or the MICROSOFT INTERNET EXPLORER web browser.
- the navigation module 417 may determine an absolute or relative position of the device, such as by using the Global Positioning System (GPS) signals, the GLObal NAvigation Satellite System (GLONASS), the Galileo positioning system, the Beidou Satellite Navigation and Positioning System, an inertial navigation system, a dead reckoning system, or by accessing address, internet protocol (IP) address, or location information in a database.
- GPS Global Positioning System
- GLONASS GLObal NAvigation Satellite System
- Galileo positioning system Galileo positioning system
- Beidou Satellite Navigation and Positioning System Beidou Satellite Navigation and Positioning System
- IP internet protocol
- the navigation module 417 may also be used to measure angular displacement, orientation, or velocity of the device 300, such as by using one or more accelerometers.
- FIG. 5 is a block diagram illustrating exemplary components of the operating system 414 used by the device 300, in the case where the operating system 414 is a mobile device platform.
- the operating system 414 invokes multiple processes, while ensuring that the associated phone application is responsive, and that wayward applications do not cause a fault (or "crash") of the operating system.
- the operating system 414 allows for the switching of applications while on a telephone call, without losing the state of each associated application.
- the operating system 414 may use an application framework to encourage reuse of components, and provide a scalable user experience by combining pointing device and keyboard inputs and by allowing for pivoting.
- the operating system can provide a rich graphics system and media experience, while using an advanced, standards-based web browser.
- the operating system 414 can generally be organized into six components: a kernel 500, libraries 501, an operating system runtime 502, application libraries 504, system services 505, and applications 506.
- the kernel 500 includes a display driver 507 that allows software such as the operating system 414 and the application programs 415 to interact with the display 301 via the display interface 402, a camera driver 509 that allows the software to interact with the camera 307; a BLUETOOTH driver 510; a M-Systems driver 511; a binder (IPC) driver 512, a USB driver 514 a keypad driver 515 that allows the software to interact with the keyboard 302 via the keyboard interface 404; a WiFi driver 516; audio drivers 517 that allow the software to interact with the microphone 309 and the speaker 310 via the sound interface 409; and a power management component 519 that allows the software to interact with and manage the power source 519.
- a display driver 507 that allows software such as the operating system 414 and the application programs 415 to interact with the display 301 via the
- the BLUETOOTH driver which in one implementation is based on the BlueZ BLUETOOTH stack for LINUX-based operating systems, provides profile support for headsets and hands-free devices, dial-up networking, personal area networking (PAN), or audio streaming (such as by Advance Audio Distribution Profile (A2DP) or Audio/Video Remote Control Profile (AVRCP).
- the BLUETOOTH driver provides JAVA bindings for scanning, pairing and unpairing, and service queries.
- the libraries 501 include a media framework 520 that supports standard video, audio and still-frame formats (such as Moving Picture Experts Group (MPEG)-4, H.264, MPEG-1 Audio Layer-3 (MP3), Advanced Audio Coding (AAC), Adaptive Multi-Rate (AMR), Joint Photographic Experts Group (JPEG), and others) using an efficient JAVA Application Programming Interface (API) layer; a surface manager 521; a simple graphics library (SGL) 522 for two-dimensional application drawing; an Open Graphics Library for Embedded Systems (OpenGL ES) 524 for gaming and three-dimensional rendering; a C standard library (LIBC) 525; a LIBWEBCORE library 526; a FreeType library 527; an SSL 529; and an SQLite library 530.
- MPEG Moving Picture Experts Group
- MP3 MPEG-1 Audio Layer-3
- AAC Advanced Audio Coding
- AMR Adaptive Multi-Rate
- JPEG Joint Photographic Experts Group
- API Application Programming Interface
- the operating system runtime 502 includes core JAVA libraries 531, and a Dalvik virtual machine 532.
- the Dalvik virtual machine 532 is a custom, virtual machine that runs a customized file format (.DEX).
- the operating system 414 can also include Mobile Information Device Profile (MIDP) components such as the MIDP JAVA Specification Requests (JSRs) components, MIDP runtime, and MIDP applications as shown in FIG. 5 .
- MIDP Mobile Information Device Profile
- JSRs MIDP JAVA Specification Requests
- MIDP applications as shown in FIG. 5 .
- the MIDP components can support MIDP applications running on the device 300.
- a system-wide composer manages surfaces and a frame buffer and handles window transitions, using the OpenGL ES 524 and two-dimensional hardware accelerators for its compositions.
- the Dalvik virtual machine 532 may be used with an embedded environment, since it uses runtime memory very efficiently, implements a CPU-optimized bytecode interpreter, and supports multiple virtual machine processes per device.
- the custom file format (.DEX) is designed for runtime efficiency, using a shared constant pool to reduce memory, read-only structures to improve cross-process sharing, concise, and fixed-width instructions to reduce parse time, thereby allowing installed applications to be translated into the custom file formal at build-time.
- the associated bytecodes are designed for quick interpretation, since register-based instead of stack-based instructions reduce memory and dispatch overhead, since using fixed width instructions simplifies parsing, and since the 16-bit code units minimize reads.
- the application libraries 504 include a view system 534, a resource manager 535, content providers 537, and a text recognition corrections filter 552.
- the system services 505 includes a status bar 539; an application launcher 540; a package manager 541 that maintains information for all installed applications; a telephony manager 542 that provides an application level JAVA interface to the telephony subsystem 420; a notification manager 544 that allows all applications access to the status bar and on-screen notifications; a window manager 545 that allows multiple applications with multiple windows to share the display 301; and an activity manager 546 that runs each application in a separate process, manages an application life cycle, and maintains a cross-application history.
- the applications 506 include a home application 547, a dialer application 549, a contacts application 550, and a browser application 551.
- the telephony manager 542 provides event notifications (such as phone state, network state, Subscriber Identity Module (SIM) status, or voicemail status), allows access to state information (such as network information, SIM information, or voicemail presence), initiates calls, and queries and controls the call state.
- event notifications such as phone state, network state, Subscriber Identity Module (SIM) status, or voicemail status
- state information such as network information, SIM information, or voicemail presence
- initiates calls and queries and controls the call state.
- the browser application 551 renders web pages in a full, desktop-like manager, including navigation functions. Furthermore, the browser application 551 allows single column, small screen rendering, and provides for the embedding of HTML views into other applications.
- FIG. 6 is a block diagram illustrating exemplary processes implemented by the operating system kernel 600.
- applications and system services run in separate processes, where the activity manager 546 runs each application in a separate process and manages the application life cycle.
- the applications run in their own processes, although many activities or services can also run in the same process. Processes are started and stopped as needed to run an application's components, and processes may be terminated to reclaim resources.
- Each application is assigned its own process, whose name is the application's package name, and individual parts of an application can be assigned another process name.
- Some processes can be persistent. For example, processes associated with core system components such as the surface manager 616, the window manager 614, or the activity manager 610 can be continuously executed while the device 300 is powered. Additionally, some application-specific process can also be persistent. For example, processes associated with the dialer application 621, may also be persistent.
- the processes implemented by the operating system kernel 600 may generally be categorized as system services processes 601, dialer processes 602, browser processes 604, and maps processes 605.
- the system services processes 601 include status bar processes 606 associated with the status bar 539; application launcher processes 607 associated with the application launcher 540; package manager processes 609 associated with the package manager 541; activity manager processes 610 associated with the activity manager 546; resource manager processes 611 associated with a resource manager 611 that provides access to graphics, localized strings, and XML layout descriptions; notification manger processes 612 associated with the notification manager 544; window manager processes 614 associated with the window manager 545; core JAVA libraries processes 615 associated with the core JAVA libraries 531; surface manager processes 616 associated with the surface manager 521; Dalvik virtual machine processes 617 associated with the Dalvik virtual machine 532, LIBC processes 619 associated with the LIBC library 525; and text recognition correction filter processes 620 associated with the text recognition correction filter application library 552.
- the dialer processes 602 include dialer application processes 621 associated with the dialer application 549; telephony manager processes 622 associated with the telephony manager 542; core JAVA libraries processes 624 associated with the core JAVA libraries 531; Dalvik virtual machine processes 625 associated with the Dalvik Virtual machine 532; and LIBC processes 626 associated with the LIBC library 525.
- the browser processes 604 include browser application processes 627 associated with the browser application 551; core JAVA libraries processes 629 associated with the core JAVA libraries 531; Dalvik virtual machine processes 630 associated with the Dalvik virtual machine 532; LIBWEBCORE processes 631 associated with the LIBWEBCORE library 526; and LIBC processes 632 associated with the LIBC library 525.
- the maps processes 605 include maps application processes 634, core JAVA libraries processes 635, Dalvik virtual machine processes 636, and LIBC processes 637. Notably, some processes, such as the Dalvik virtual machine processes, may exist within one or more of the systems services processes 601, the dialer processes 602, the browser processes 604, and the maps processes 605.
- FIG. 7 shows an example of a generic computer device 700 and a generic mobile computer device 750, which may be used with the techniques described here.
- Computing device 700 is intended to represent various forms of digital computers, such as laptops, desktops, workstations, personal digital assistants, servers, blade servers, mainframes, and other appropriate computers.
- Computing device 750 is intended to represent various forms of mobile devices, such as personal digital assistants, cellular telephones, smartphones, and other similar computing devices.
- the components shown here, their connections and relationships, and their functions, are meant to be exemplary only, and are not meant to limit implementations of the inventions described and/or claimed in this document.
- Computing device 700 includes a processor 702, memory 704, a storage device 706, a high-speed interface 708 connecting to memory 704 and high-speed expansion ports 710, and a low speed interface 712 connecting to low speed bus 714 and storage device 706.
- Each of the components 702, 704, 706, 708, 710, and 712, are interconnected using various busses, and may be mounted on a common motherboard or in other manners as appropriate.
- the processor 702 can process instructions for execution within the computing device 700, including instructions stored in the memory 704 or on the storage device 706 to display graphical information for a GUI on an external input/output device, such as display 716 coupled to high speed interface 708.
- multiple processors and/or multiple buses may be used, as appropriate, along with multiple memories and types of memory.
- multiple computing devices 700 may be connected, with each device providing portions of the necessary operations (e.g., as a server bank, a group of blade servers, or a multi-processor system).
- the memory 704 stores information within the computing device 700.
- the memory 704 is a volatile memory unit or units.
- the memory 704 is a non-volatile memory unit or units.
- the memory 704 may also be another form of computer-readable medium, such as a magnetic or optical disk.
- the storage device 706 is capable of providing mass storage for the computing device 700.
- the storage device 706 may be or contain a computer-readable medium, such as a floppy disk device, a hard disk device, an optical disk device, or a tape device, a flash memory or other similar solid state memory device, or an array of devices, including devices in a storage area network or other configurations.
- a computer program product can be tangibly embodied in an information carrier.
- the computer program product may also contain instructions that, when executed, perform one or more methods, such as those described above.
- the information carrier is a computer- or machine-readable medium, such as the memory 704, the storage device 706, memory on processor 702, or a propagated signal.
- the high speed controller 708 manages bandwidth-intensive operations for the computing device 700, while the low speed controller 712 manages lower bandwidth-intensive operations.
- the high-speed controller 708 is coupled to memory 704, display 716 (e.g., through a graphics processor or accelerator), and to high-speed expansion ports 710, which may accept various expansion cards (not shown).
- low-speed controller 712 is coupled to storage device 706 and low-speed expansion port 714.
- the low-speed expansion port which may include various communication ports (e.g., USB, Bluetooth, Ethernet, wireless Ethernet) may be coupled to one or more input/output devices, such as a keyboard, a pointing device, a scanner, or a networking device such as a switch or router, e.g., through a network adapter.
- input/output devices such as a keyboard, a pointing device, a scanner, or a networking device such as a switch or router, e.g., through a network adapter.
- the computing device 700 may be implemented in a number of different forms, as shown in the figure. For example, it may be implemented as a standard server 720, or multiple times in a group of such servers. It may also be implemented as part of a rack server system 724. In addition, it may be implemented in a personal computer such as a laptop computer 722. Alternatively, components from computing device 700 may be combined with other components in a mobile device (not shown), such as device 750. Each of such devices may contain one or more of computing device 700, 750, and an entire system may be made up of multiple computing devices 700, 750 communicating with each other.
- Computing device 750 includes a processor 752, memory 764, an input/output device such as a display 754, a communication interface 766, and a transceiver 768, among other components.
- the device 750 may also be provided with a storage device, such as a microdrive or other device, to provide additional storage.
- a storage device such as a microdrive or other device, to provide additional storage.
- Each of the components 750, 752, 764, 754, 766, and 768, are interconnected using various buses, and several of the components may be mounted on a common motherboard or in other manners as appropriate.
- the processor 752 can execute instructions within the computing device 750, including instructions stored in the memory 764.
- the processor may be implemented as a chipset of chips that include separate and multiple analog and digital processors.
- the processor may provide, for example, for coordination of the other components of the device 750, such as control of user interfaces, applications run by device 750, and wireless communication by device 750.
- Processor 752 may communicate with a user through control interface 758 and display interface 756 coupled to a display 754.
- the display 754 may be, for example, a TFT LCD (Thin-Film-Transistor Liquid Crystal Display) or an OLED (Organic Light Emitting Diode) display, or other appropriate display technology.
- the display interface 756 may comprise appropriate circuitry for driving the display 754 to present graphical and other information to a user.
- the control interface 758 may receive commands from a user and convert them for submission to the processor 752.
- an external interface 762 may be provide in communication with processor 752, so as to enable near area communication of device 750 with other devices.
- External interface 762 may provide, for example, for wired communication in some implementations, or for wireless communication in other implementations, and multiple interfaces may also be used.
- the memory 764 stores information within the computing device 750.
- the memory 764 can be implemented as one or more of a computer-readable medium or media, a volatile memory unit or units, or a non-volatile memory unit or units.
- Expansion memory 774 may also be provided and connected to device 750 through expansion interface 772, which may include, for example, a SIMM (Single In Line Memory Module) card interface.
- SIMM Single In Line Memory Module
- expansion memory 774 may provide extra storage space for device 750, or may also store applications or other information for device 750.
- expansion memory 774 may include instructions to carry out or supplement the processes described above, and may include secure information also.
- expansion memory 774 may be provide as a security module for device 750, and may be programmed with instructions that permit secure use of device 750.
- secure applications may be provided via the SIMM cards, along with additional information, such as placing identifying information on the SIMM card in a non-hackable manner.
- the memory may include, for example, flash memory and/or NVRAM memory, as discussed below.
- a computer program product is tangibly embodied in an information carrier.
- the computer program product contains instructions that, when executed, perform one or more methods, such as those described above.
- the information carrier is a computer- or machine-readable medium, such as the memory 764, expansion memory 774, memory on processor 752, or a propagated signal that may be received, for example, over transceiver 768 or external interface 762.
- Device 750 may communicate wirelessly through communication interface 766, which may include digital signal processing circuitry where necessary. Communication interface 766 may provide for communications under various modes or protocols, such as GSM voice calls, SMS, EMS, or MMS messaging, CDMA, TDMA, PDC, WCDMA, CDMA2000, or GPRS, among others. Such communication may occur, for example, through radio-frequency transceiver 768. In addition, short-range communication may occur, such as using a Bluetooth, WiFi, or other such transceiver (not shown). In addition, GPS (Global Positioning System) receiver module 770 may provide additional navigation- and location-related wireless data to device 750, which may be used as appropriate by applications running on device 750.
- GPS Global Positioning System
- Device 750 may also communicate audibly using audio codec 760, which may receive spoken information from a user and convert it to usable digital information. Audio codec 760 may likewise generate audible sound for a user, such as through a speaker, e.g., in a handset of device 750. Such sound may include sound from voice telephone calls, may include recorded sound (e.g., voice messages, music files, etc.) and may also include sound generated by applications operating on device 750.
- Audio codec 760 may receive spoken information from a user and convert it to usable digital information. Audio codec 760 may likewise generate audible sound for a user, such as through a speaker, e.g., in a handset of device 750. Such sound may include sound from voice telephone calls, may include recorded sound (e.g., voice messages, music files, etc.) and may also include sound generated by applications operating on device 750.
- the computing device 750 may be implemented in a number of different forms, as shown in the figure. For example, it may be implemented as a cellular telephone 780. It may also be implemented as part of a smartphone 782, personal digital assistant, or other similar mobile device.
- implementations of the systems and techniques described here can be realized in digital electronic circuitry, integrated circuitry, specially designed ASICs (application specific integrated circuits), computer hardware, firmware, software, and/or combinations thereof.
- ASICs application specific integrated circuits
- These various implementations can include implementation in one or more computer programs that are executable and/or interpretable on a programmable system including at least one programmable processor, which may be special or general purpose, coupled to receive data and instructions from, and to transmit data and instructions to, a storage system, at least one input device, and at least one output device.
- the systems and techniques described here can be implemented on a computer having a display device (e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor) for displaying information to the user and a keyboard and a pointing device (e.g., a mouse or a trackball) by which the user can provide input to the computer.
- a display device e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor
- a keyboard and a pointing device e.g., a mouse or a trackball
- Other kinds of devices can be used to provide for interaction with a user as well; for example, feedback provided to the user can be any form of sensory feedback (e.g., visual feedback, auditory feedback, or tactile feedback); and input from the user can be received in any form, including acoustic, speech, or tactile input.
- the systems and techniques described here can be implemented in a computing system that includes a back end component (e.g., as a data server), or that includes a middleware component (e.g., an application server), or that includes a front end component (e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the systems and techniques described here), or any combination of such back end, middleware, or front end components.
- the components of the system can be interconnected by any form or medium of digital data communication (e.g., a communication network). Examples of communication networks include a local area network ("LAN”), a wide area network (“WAN”), and the Internet.
- LAN local area network
- WAN wide area network
- the Internet the global information network
- the computing system can include clients and servers.
- a client and server are generally remote from each other and typically interact through a communication network.
- the relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other.
- text recognition system may be implemented on a mobile device (e.g., mobile device 300) along with a text recognition corrections filter.
- the local text recognition system may be adapted to speech or handwriting patterns of a particular user, in part, by training with corrections selected using the text recognition corrections filter.
Description
- The present disclosure relates to the recognition of text in various media.
- Voice recognition systems capable of detecting audio speech signals and converting them into related text have been deployed to allow users to interact with computers through voice commands. For example, voice recognition systems have been used to automate the answering and processing of customer service calls.
- Optical Character Recognition (OCR) systems capable of extracting text from images have been deployed to facilitate copying and searching of text stored in image files. For example, OCR systems have been used to extract text from images stored as portable document files (PDFs).
- Text recognition systems (e.g., voice recognition systems or OCR systems) may use machine learning models that are trained using a large set of training data. For example, the training data may include audio voice signals and paired text equivalents or labels. Generating the data set used to train a text recognition system may be expensive.
-
US 2009/240488 A1 describes a method for facilitating the updating of a language model, which includes receiving, at a client device, via a microphone, an audio message corresponding to speech of a user; communicating the audio message to a first remote server; receiving, that the client device, a result, transcribed at the first remote server using an automatic speech recognition system ("ASR"), from the audio message; receiving, at the client device from the user, an affirmation of the result; storing, at the client device, the result in association with an identifier corresponding to the audio message; and communicating, to a second remote server, the stored result together with the identifier. - The invention is defined by the
independent claims - In general, one aspect of the subject matter described in this specification can be embodied in a system that includes a data processing apparatus and a memory coupled to the data processing apparatus. The memory having instructions stored thereon which, when executed by the data processing apparatus cause the data processing apparatus to perform operations including receiving an input signal comprising data that corresponds to one or more words. The operations may further include passing the input signal to a text recognition system that generates a recognized text string based on the input signal. The operations may further include receiving the recognized text string from the text recognition system. The operations may further include presenting the recognized text string to a user. The operations may further include receiving a corrected text string based on input from the user. The operations may further include checking if an edit distance between the corrected text string and the recognized text string is below a threshold. The operations may further include, if the edit distance is below the threshold, passing the corrected text string to the text recognition system for training purposes.
- In general, one aspect of the subject matter described in this specification can be embodied in a mobile device that includes a microphone configured to receive an input signal comprising data that corresponds to one or more words. The mobile device may further include a wireless network interface configured to transmit the input signal to a text recognition system that generates a recognized text string based on the input signal. The mobile device may further include a wireless network interface configured to receive the recognized text string from the text recognition system. The mobile device may further include a display configured to present the recognized text string to a user. The mobile device may further include a user interface configured to receive one or more edits to the recognized text string from the user. The mobile device may further include a module configured to determine a corrected text string based on the recognized text string and the edits. The mobile device may further include means for checking if an edit distance between the corrected text string and the recognized text string is below a threshold. The mobile device may further include a wireless network interface configured to, if the edit distance is below the threshold, pass the corrected text string to the text recognition system for training purposes.
- In general, one aspect of the subject matter described in this specification can be embodied in a system that includes an interface configured to receive an input signal comprising data that corresponds to one or more words. The system may further include an interface configured to pass the input signal to a text recognition system that generates a recognized text string based on the input signal. The system may further include an interface configured to receive the recognized text string from the text recognition system. The system may further include an interface configured to present the recognized text string to a user. The system may further include an interface configured to receiving a corrected text string based on input from the user. The system may further include means for checking if an edit distance between the corrected text string and the recognized text string is below a threshold. The system may further include an interface configured to, if the edit distance is below the threshold, pass the corrected text string to the text recognition system for training purposes.
- In general, one aspect of the subject matter described in this specification can be embodied in a computer readable medium storing software including instructions executable by a processing device that upon such execution cause the processing device to perform operations that include receiving an input signal comprising data that corresponds to one or more words. The operations may further include passing the input signal to the text recognition system that generates a recognized text string based on the input signal. The operations may further include receiving the recognized text string from the text recognition system. The operations may further include presenting the recognized text string to a user. The operations may further include receiving a corrected text string based on input from the user. The operations may further include checking if an edit distance between the corrected text string and the recognized text string is below a threshold. The operations may further include, if the edit distance is below the threshold, passing the corrected text string to the text recognition system for training purposes.
- These and other embodiments can each optionally include one or more of the following features. The edit distance may represent a Levenshtein distance. The edit distance may represent the minimum number of single character insertion, deletion, or substitution operations required to transform the recognized text string into the corrected text string The edit distance may be a minimum number of write operations, from a set of allowed operations, needed to produce the corrected text string from the recognized text string, wherein write operations include character insertion and character substitution, and wherein character deletion is allowed but not counted in the edit distance. The edit distance may be a maximum number of consecutive characters inserted. The input signal may be an auditory speech signal. The input signal may be an image signal. The text recognition system may be executed by a remotely located server. The text recognition system may be executed by a user device. Passing the input signal to a text recognition system may include transmitting a signal encoding the input signal through a network. Checking if an edit distance between the corrected text string and the recognized text string is below threshold may include determining the edit distance and comparing the edit distance to the threshold. Checking if an edit distance between the corrected text string and the recognized text string is below threshold may include computing intermediate edit distance values until the threshold is exceeded or the edit distance is determined. Receiving a corrected text string based on input from the user may include receiving data that represents one or more user edits to the recognized text string and determining a corrected text string based on the recognized text string and the edits. The units of the edit distance may represent a number of characters. The units of the edit distance may represent a number of phonemes. The units of the edit distance may represent a number of words. The threshold may depend on a length of the corrected text string. The threshold may be approximately fifty percent of the length of the corrected text string. Presenting the recognized text string to a user may include transmitting the recognized text to a user device for display to the user. Presenting the recognized text string to a user may include displaying the recognized text on a display.
- Particular embodiments of the invention can be implemented to realize none, one or more of the following advantages. Some implementations may facilitate the training machine learning based text recognition systems. Some implementations may filter out less useful data from a set of training data collected from a user. Along with reducing the cost of text recognition services by providing low cost data for training purposes, some implementations may improve the quality of a text recognition service by providing more reliable data for training purposes. Some implementations may facilitate adaptation of text recognition systems to the characteristics of individual users.
- The details of one or more embodiments of the invention are set forth in the accompanying drawings and the description below. Other features, aspects, and advantages of the invention will become apparent from the description, the drawings, and the claims.
-
-
FIG. 1 is a block diagram of an example online environment. -
FIG. 2A is a flow chart of an example process for collecting and filtering text recognition training data from users of a text recognition system. -
FIG. 2B is a data flow diagram of an example module for checking whether an edit distance between a recognized text string and a corrected text string is below a threshold. -
FIG. 2C is a flow chart of an example process for determining an edit distance between a recognized text string and a corrected text string. -
FIGS. 2D-G are a code listing for an example process for checking if an edit distance is below a threshold. -
FIG. 3 is a schematic representation of an exemplary mobile device that implements embodiments of the text recognition corrections filter described herein. -
FIG. 4 is a block diagram illustrating the internal architecture of the device ofFIG. 3 . -
FIG. 5 is a block diagram illustrating exemplary components of the operating system used by the device ofFIG. 3 . -
FIG. 6 is a block diagram illustrating exemplary processes implemented by the operating system kernel ofFIG. 5 . -
FIG. 7 shows an example of a computer device and a mobile computer device that can be used to implement the techniques described here. - Like reference numbers and designations in the various drawings indicate like elements.
- A text recognition system (e.g., a speech recognition system or OCR system) is used to extract text from input signals that reflect information including words or other symbols. A text recognition system may include a machine learning system (e.g., a hidden markov model, a feature based linear regression, an artificial neural network) that trains a model, used to detect text in input signals, by analyzing numerous example input signals that have each been paired with a known text string representing the words or symbols that are reflected in that input signal. A set of input signal and text string pairs used for this purpose may be considered training data. In some implementations, additional training data may be collected from one or more users of a text recognition system and used to further refine a model used by the text recognition system. When many users (e.g., thousands of users) access and utilize a text recognition system through a network, the users may collectively be a vast and cost efficient source of training data.
- The accuracy of text recognition systems may be improved by feeding back corrections that a user made to a given recognized text string. For example, a user of a speech recognition service may say "pictures of the Golden Gate Bridge at sunset" as part of verbal search query. The speech recognition service may recognize "pictures of Golden Gate Bridge and sunset". The user could then edit the text returned from the speech recognition service and correct the mistakes made by the service. The resulting corrected text string may then be paired with the input audio speech signal to form an example that may be used by the speech recognition system underling the service as training data.
- However, in some cases, the user may make significant changes to the recognition text or even write a completely new text. This circumstance may arise due to, for example, a low signal to noise ratio in the input signal, user error, or a user who is making the edits for a primary purpose other than training the speech recognition system, i.e. inputting what the user intended to say rather than what the user actually said. In such cases it may not be helpful to feed the user's edits back into the speech recognition service for use as training data, since the new text is not necessarily closely related to the originally spoken query anymore.
- An edit distance between the recognized text string and a corrected text string that results from a user's edits may be used to measure the significance of user edits. The edit distance between two text strings may measure how many edit operations are required to change one text into another. For example, the Levenshtein distance between the two text strings is the minimum number of single character insertion, deletion, or substitution operations required to transform one text string into the other. Only user corrections with edit distances that are below a pre-defined threshold would typically be taken into account for future text recognition system training and improvements. All other changes may be deemed too significant to be useful. In this manner, edit distance calculation and thresholding may be used to filter corrected text strings collected from users to provide a more reliable set of training data.
-
FIG. 1 is a block diagram of an exampleonline environment 100 in which a text recognition corrections filter may be utilized to selectively collect training data for a text recognition system. In this example, aspeech recognition system 108 is part of a verbalsearch server system 101 available to users through anetwork 104. Thespeech recognition system 108 may includetraining data 120 that it uses to determinemodel parameters 122. Model parameters may then be used to identify words occurring in an audio input signal. The set of training data may be large and may be stored instorage system 130. - Users access the verbal search service from their
devices 134, 136 (e.g., smart phones, tablet computing devices, computers, etc.). Users may use their devices to interact with thesearch server system 101 by submitting application commands 140. For example, a user ofmobile device 136 may submit averbal search term 142 to thesearch server system 101. The verbal search term may include an audio input signal and is received using theinterface 102 and passed to therequest processor 112. Therequest processor 112 may then send the audio portion of the received request to thespeech recognition system 108, which identifies words in the audio and returns a recognized text string that may be used as a search query. The resulting formatted search query is then passed to thesearch engine 114, which searches itsindex 116 and outputs a set of search results to theresponse formatter 118. Theresponse formatter 118 may generate a responsive webpage or other type of response (e.g., text, imagery, etc.). The responsive webpage may be transmitted by theinterface 102 through thenetwork 104 tomobile device 136. The responsive webpage may include a display of thetext search term 144 derived from the recognized text string and search results 146. The user of mobile device may then perceive an error in the text search term that resulted from the user's verbal search term. - At this point the user may input corrective edits to the text search term and resubmit the query as a corrected
search term 150. The correctedsearch term 150 may be received, throughinterface 102, by both therequest processor 112 and a text recognition corrections filter 110. The text recognition corrections filter 110 may have previously received the recognized text string that resulted from theverbal search term 142 from thespeech recognition system 108. The text recognition corrections filter 110 may use one or more edit distances between the recognized text string that resulted from the verbal search term and the corrected search term to assess the likely value of the corrected search term as training data. The text recognition corrections filter 110 may apply thresholds to the edit distances to determine whether the corrected search term should be used as training data by thespeech recognition system 108. Corrected search terms selected in this manner may be passed to thespeech recognition system 108, possibly along with the corresponding verbal search term, and stored in thestorage device 130 for use in future training to adjust themodel parameters 122. - The text recognition corrections filter 110 may be implemented as software, hardware or a combination of software and hardware that is executed on a processing apparatus, such as one or more computing devices (e.g., a computer system as illustrated in
FIG. 7 ). -
FIG. 2A is a flow chart of anexample process 200 for collecting and filtering text recognition system corrections from users of a text recognition system. A user interaction with a text recognition system is facilitated and results in a correction of recognized text string by the user. An edit distance between a recognized text string and the resulting corrected text string is checked to determine if the distance is below a threshold. In this arrangement, corrected text strings with distances above the threshold are filtered out. Corrected text strings with distances below the threshold are passed to the text recognition system for use as training data to further adapt or refine the a text extraction model used by the text recognition system. - The
process 200 can be implemented, for example, by the textrecognition correction filter 110 in thesearch server system 101 ofFIG. 1 . In some implementations, thesearch server system 101 is a data processing apparatus that includes one or more processors that are configured to perform actions of theprocess 200. For example, the data processing apparatus may be a computing device (e.g., as illustrated inFIG.7 ). In some implementations, theprocess 200 may be implemented by a text recognition correction filter that is executed by a user's mobile computing device (e.g., also illustrated inFIG. 7 ). For example,process 200 may be implemented by the textrecognition correction filter 552 that is executed by the mobile device described inFIGS. 3-6 . In some implementations, a computer readable medium can include instructions that when executed by a computing device (e.g., a computer system) cause the device to perform actions of theprocess 200. - An input signal including information representing one or more words or symbols is received 202. For example, the input signal may be an audio speech signal that is input to a verbal search service. In some implementations, the input signal may be an image file containing a picture of printed words, e.g., a sign or a page from a book. The words or symbols represented in the input signal may be in any language the text recognition system is capable of processing (e.g., English or Chinese).
- The input signal may be received 202 from a
user device 134, 136 (e.g., a cell phone). The input signal may be received via a serversystem interface component 102 of thesearch server system 101. In some implementations, the input signal may be received 202 through a microphone on a user device (e.g. microphone 309). In some implementations, the input signal may be received 202 through a camera on a user device (e.g. camera 307). - The input signal is passed 204 to a text recognition system. In some implementations, the text recognition system runs on a remote server. For example, passing 204 the input signal may be accomplished by transmitting the input signal via a network, using a network interface (e.g., a wireless network interface including an antenna). In some implementations, the text recognition system is integrated with and runs on the same local device as
process 200. For example, passing 204 the input signal may be accomplished by storing the input signal in a particular memory location or passing a pointer to input signal into the text recognition system as an argument to an application programmer interface function. - A recognized text string is received 206 from the text recognition server. The text recognition system may identify words or other symbols represented in the input signal and generate a recognized text string that is a text representation of the identified words or symbols. For example, the recognized text string may be a sequence of characters encoded in accordance with a standard character-encoding scheme (e.g., American Standard Code for Information Interchange (ASCII)). The recognized text string may be received 206 in a variety of ways (e.g., from a remote server through a network, by dereferencing a pointer to memory, etc.).
- The recognized text string may be presented 208 to a user. The recognized text string may be presented by rendering a visual representation of the recognized text string on the display (e.g., a liquid crystal display) of a user device. For example the recognized text string may be presented on
display 301 ofFIG.3 . In some implementations, presentation to a user may be accomplished by transmitting the recognized text string to a user device. For example, the text recognition corrections filter 110 may present 208 the recognized text by transmitting the recognized text to aremote user device 136. - A corrected text string based on input from the user may be received 210. The corrected text string may be a sequence of characters encoded in accordance with a standard character-encoding scheme (e.g., ASCII) that reflects user input. For example, a user presented with the recognized string may input edits to the text through a user interface (e.g., a keypad or a touch-screen display). The corrected text string may be determined by interpreting the user's edit commands and applying them to a copy of the recognized text string. For example, a corrected text string may be derived from user edits input through
keyboard 302 on the mobile device ofFIG. 3 . In some implementations, the corrected string is received 210 in a communication signal from a remote device through a network. For example, the textrecognition correction filter 110 may receive, through theinterface 102, a corrected text string that has been transmitted through a network by a user device. - A
check 212 is performed to determine whether an edit distance between the recognized text string and the corrected text string is below a threshold. The edit distance may provide an indication of how similar the two text strings are. In some implementations, an edit distance is determined and then compared to a threshold, e.g., the data flow ofFIG. 2B . For some edit distances (e.g., the Levenshtein distance), algorithms for calculating the edit distance exist that have monotonic properties, which may allow a determination of whether or not an edit distance will be below a threshold before the complete edit distance computation has been completed. In some implementations, intermediate values may be computed in an accordance with an edit distance computation algorithm until it is determined that the edit distance must exceed the threshold or until the edit distance is determined, e.g., the program listing ofFIG. 2D . - Many possible edit distances may be defined and used to assess the similarity of the strings and thus the likely utility of the corrected text string as training data for a text recognition system. One example is the Levenshtein distance between two portions of text (e.g., word, passage, etc.), which is defined as the minimum number of allowed edit operations required to transform a one of the text portions into the other. For the Levenshtein distance, the allowed edit operations are typically insertion of a single character, deletion of a single character, and substitution of a single character. An example process for determining the Levenshtein distance between the recognized text string and the corrected text string is describe in relation to
FIG. 2C . - In some implementations, a modified Levenshtein distance may be used that counts the minimum number of insertions of single character and substitutions of a single character, while disregarding deletions of characters required to transform between the two texts. This modified Levenshtein distance may be a useful edit distance in a text recognition corrections filter, because noisy input signals (e.g., background noise in a speech audio signal) may cause extra characters in the recognized text when underlying words or symbols are not present (e.g., silence periods or pauses in speech). This circumstance may make deletions more common and less informative. A process for checking this edit distance is describe in relation to
FIG. 2D . - Another example of an edit distance is the maximum number of consecutive characters inserted to form the corrected text string. The maximum number of consecutive characters inserted is also checked by the process described in relation to
FIG. 2D . In some implementations, multiple edit distances may be checked and a corrected text string may be selected for training if all of the edit distances are below their respective thresholds. - Edit distances and their thresholds may be measured in a variety of units. For example, speech recognition systems may return a sequence of coded phonemes or coded words, which in turn may be represented as sequences of characters. The edit distance used may define the set of allowable operations to be on insertion, deletions, or substitutions of single phonemes or of single words.
- The threshold may depend on properties of the recognized text string or the corrected text string. For example, the threshold for the edit distance may be set to a percentage (e.g., 50%) of the length of the corrected text string. In some implementations, a different threshold may be used for each distance metric used. For example, a fixed threshold (e.g., 15 characters) may be used for the maximum consecutive characters inserted edit distance. The exact value of the threshold may be determined iteratively and may remain flexible throughout the life of the system. Updates to the threshold, may depend in part on a performance metric differential for a text recognition system before and after training with corrections data collected using the previous value of the threshold.
- For example, the edit distance may be checked 212 by the text recognition
corrections filter module 110 of thesearch server system 101. The edit distance may be checked 212 by the textrecognition correction filter 552 of the mobile device, illustrated inFIGS. 3-6 . - If the edit distance is below the
threshold 215, then the corrected text string is selected for use as training data for a text recognition system. In this case, the corrected text string may be passed 216 to the text recognition system for training purposes. As with the input signal, the corrected text string may be passed 216 in a variety of ways (e.g., transmitting, copying to memory, etc.) that may depended on a nature of thesystem implementing process 200 is and its relationship to the text recognition system. In some implementations, a text recognition system may immediately update its model parameters based on the corrected text string. In some implementations, the text recognition system may store the corrected text string for later use in training. In some implementations, selected corrected text strings may be stored locally before being passed to the text recognition system in batches (e.g., periodically or after a certain number of strings have been selected). - If the edit distance is not below the
threshold 215, then the corrected text string may be disregarded for training purposes.Process 200 may then terminate 218 or wait for new input signals for a text recognition system before restarting. -
FIG. 2B is a data flow diagram of anexample module 220 for checking whether an edit distance between a recognized text string and a corrected text string is below a threshold. The diagram illustrates a check on exemplary data. Themodule 220 accepts a recognized text string ("Home") and a corresponding corrected text string ("House"). These two text strings are first passed into anedit distance module 222 that determines an edit distance between the two strings. For example, theedit distance module 222 may implement a process 250 (illustrated inFIG. 2C ) to determine the Levenshtein distance between the two strings. The Levenshtein distance between Home and House is 2. For example, "home" may be transformed to "house" by inserting a "u" character and substituting an "s" character for the "m" character. There are no transformations that use less than two of the allowed single character edit operations to map from "home" to "house". Thus, theedit distance module 222 outputs an edit distance of 2 and passes the quantity to athreshold module 224 that compares the edit distance to a threshold and outputs a classification of the corrected text. For example the classification may be a binary output (e.g., yes or no, zero or one) indicating whether the edit distance was below the threshold, and by implication whether the corrected text string is likely to be useful for training. In this example, the threshold used by thethreshold module 224 is 50% of the length of the corrected text string, in this case 2.5. Since the distance is below the threshold, the threshold module outputs a "yes" classification, which in turn is output bymodule 220. - For example,
module 220 may be implemented as part of the textrecognition correction filter 110 of thesearch server system 101. Themodule 220 may be implemented by the text recognition corrections filter 552 of themobile device 300. -
FIG. 2C is a flow chart of anexample process 250 for determining a Levenshtein distance between a recognized text string and a corrected text string. The process sequentially builds a matrix of distances, i.e. counts of edit operations. The value of each element will be set to the Levenshtein distance between prefixes of the two strings with lengths corresponding to the row and column numbers. The value of the last element of the matrix calculated (last row, last column) is the Levenshtein distance between the complete recognized text string and the complete corrected text string. - For example,
process 250 may be implemented by the textrecognition correction filter 110 of thesearch server system 101. Theprocess 250 may be implemented by the text recognition corrections filter 552 of themobile device 300. - The corrected text string and the recognized text string are retrieved 252 and the distance matrix is initialized 254. The dimension of the distance matrix depends on the lengths of the two text strings and is equal to one plus the length of the corrected text string by one plus the length of the recognized text string. In the example, rows of the matrix correspond to characters of the corrected text string and columns correspond to characters of the recognized text string. The first row and first column of the distance matrix both correspond to null strings, i.e. strings with no characters. The element in the first row and column is set to the distance between two null strings, i.e. zero. The remaining elements in the first row are set to length of the prefix of the recognized text string that ends with the character corresponding to the element's column. Similarly, the remaining elements in the first column are set to length of the prefix of the corrected text string that ends with the character corresponding to the element's row.
- After initialization, the element values may be determined based on whether individual characters, corresponding to the row and column, match and the distance values for nearby elements in the matrix, i.e. for prefixes of the same length or one character less. Processing starts in
second row 256,second column 258, which corresponds to the first character of the corrected text string and the first character of the recognized text string. - The character of the corrected text string corresponding to the current row is compared 260 to the character of the recognized text string corresponding to the current column. If the two characters are equivalent, then the distance for this element is set 262 to the value stored for the element in the previous row, previous column. Otherwise, the distance will typically be set 264 to a value incremented from value stored in a previous element of the matrix. The current distance element may be set 264 to one plus the minimum of the distances stored in (previous row, previous column); (previous row, current column); and (current row, previous column).
- If there are more columns in the current row to be processed 265, then go 258 to the next column corresponding to the next character of the recognized text string. If not 265, then check if there are more rows to be processed 267. If so, go 256 to the next row corresponding to the next character. Finally when all rows have been processed, the value in the last row, last column may be returned 268 as the Levenshtein distance between the recognized text string and the corrected text string.
-
FIGS. 2D-G are a code listing for an example process for checking if an edit distance is below a threshold. The example process actually checks two edit distances. The first edit distance is a modified Levenshtein distance that allows deletion, insertion, and substitution edit operations in the transformations between the recognized text string and the corrected text string, but does not count deletion operations in the distance value, i.e. deletions are considered a free operation. In some implementations, other edit operations may be given different weights in an edit distance (e.g., a substitution operation counts as 2, an insertion operation counts as 1, and a deletion operation counts as zero). Elements of the distance matrix with values greater than the threshold need not be calculated and are considered as dead-ends because subsequent values derived from them can only be the same or higher. When all the values in the current row of the distance matrix are above the threshold, then the check process may terminate, possibly without calculating the final edit distance for the two text strings, and return an indication that the edit distance was not below the threshold. The example code listing sets the threshold for the first edit distance to a percentage (e.g., 50%) of the length of the corrected text string. - The second edit distance is a maximum number of consecutive character insertion operations used to derive the corrected text string from the recognized text string. The example code listing sets the threshold for the second edit distance to a fixed value (e.g., 15 characters).
-
FIG. 2D provides a high level class definition in the C++ programing language for amodule 270 that will check whether these two edit distances are both below their respective thresholds. - The
getDistance function 280 accepts a recognized text string and a corrected text string as inputs and returns an edit distance that may saturate at the threshold or just above the threshold. A full definition of thegetDistance function 280 is provide inFIG. 2E . - The
DeltaTable class 290 distance matrices used by the module to check whether the edit distances are below the threshold. Due to the structure of the distances matrices rows before the previous row may be discarded while the check computations are ongoing, thus saving memory usage. A full definition of theDeltaTable class 290 is provide inFIG. 2F . - The
Delta class 295 defines the properties of objects that may be used to track the state of the module as it checks whether the edit distances are below their respective thresholds. A full definition of theDelta class 295 is provided inFIG. 2G . - For example,
module 270 may be implemented by the text recognitioncorrections filter module 110 of thesearch server system 101. Themodule 270 may be implemented by the text recognition corrections filter 552 of themobile device 300. - Referring now to
FIG. 3 , the exterior appearance of an exemplarymobile device 300 that implements the text recognition correction filter 110 (shown inFIG. 1 ) is illustrated. Briefly, and among other things, thedevice 300 includes a processor configured to selectively collect user corrections to text recognition strings and pass them to a text recognition system for use as training data. - In more detail, the hardware environment of the
device 300 includes adisplay 301 for displaying text, images, and video to a user; akeyboard 302 for entering text data and user commands into thedevice 300; apointing device 304 for pointing, selecting, and adjusting objects displayed on thedisplay 301; an antenna 305; anetwork connection 306; acamera 307; amicrophone 309; and aspeaker 310. Although thedevice 300 shows an external antenna 305, thedevice 300 can include an internal antenna, which is not visible to the user. - The
display 301 can display video, graphics, images, and text that make up the user interface for the software applications used by thedevice 300, and the operating system programs used to operate thedevice 300. Among the possible elements that may be displayed on thedisplay 301 are anew mail indicator 311 that alerts a user to the presence of a new message; anactive call indicator 312 that indicates that a telephone call is being received, placed, or is occurring; a datastandard indicator 314 that indicates the data standard currently being used by thedevice 300 to transmit and receive data; asignal strength indicator 315 that indicates a measurement of the strength of a signal received by via the antenna 305, such as by using signal strength bars; abattery life indicator 316 that indicates a measurement of the remaining battery life; or aclock 317 that outputs the current time. - The
display 301 may also show application icons representing various applications available to the user, such as a webbrowser application icon 319, aphone application icon 320, asearch application icon 321, acontacts application icon 322, amapping application icon 324, anemail application icon 325, or other application icons. In one example implementation, thedisplay 301 is a quarter video graphics array (QVGA) thin film transistor (TFT) liquid crystal display (LCD), capable of 16-bit or better color. - A user uses the keyboard (or "keypad") 302 to enter commands and data to operate and control the operating system and applications that provide for interaction with text recognition systems. The
keyboard 302 includes standard keyboard buttons or keys associated with alphanumeric characters, such askeys key 329. A single key may also be associated with special characters or functions, including unlabeled functions, based upon the state of the operating system or applications invoked by the operating system. For example, when an application calls for the input of a numeric character, a selection of the key 327 alone may cause a "1" to be input. - In addition to keys traditionally associated with an alphanumeric keypad, the
keyboard 302 also includes other special function keys, such as an establishcall key 330 that causes a received call to be answered or a new call to be originated; a terminatecall key 331 that causes the termination of an active call; a drop downmenu key 332 that causes a menu to appear within thedisplay 301; abackward navigation key 334 that causes a previously accessed network address to be accessed again; a favorites key 335 that causes an active web page to be placed in a bookmarks folder of favorite sites, or causes a bookmarks folder to appear; a home page key 336 that causes an application invoked on thedevice 300 to navigate to a predetermined network address; or other keys that provide for multiple-way navigation, application selection, and power and volume control. - The user uses the
pointing device 304 to select and adjust graphics and text objects displayed on thedisplay 301 as part of the interaction with and control of thedevice 300 and the applications invoked on thedevice 300. Thepointing device 304 is any appropriate type of pointing device, and may be a joystick, a trackball, a touch-pad, a camera, a voice input device, a touch screen device implemented in combination with thedisplay 301, or any other input device. - The antenna 305, which can be an external antenna or an internal antenna, is a directional or omni-directional antenna used for the transmission and reception of radiofrequency (RF) signals that implement point-to-point radio communication, wireless local area network (LAN) communication, or location determination. The antenna 305 may facilitate point-to-point radio communication using the Specialized Mobile Radio (SMR), cellular, or Personal Communication Service (PCS) frequency bands, and may implement the transmission of data using any number or data standards. For example, the antenna 305 may allow data to be transmitted between the device 300 and a base station using technologies such as Wireless Broadband (WiBro), Worldwide Interoperability for Microwave ACCess (WiMAX), 3GPP Long Term Evolution (LTE), Ultra Mobile Broadband (UMB), High Performance Radio Metropolitan Network (HIPERMAN), iBurst or High Capacity Spatial Division Multiple Access (HC-SDMA), High Speed OFDM Packet Access (HSOPA), High-Speed Packet Access (HSPA), HSPA Evolution, HSPA+, High Speed Upload Packet Access (HSUPA), High Speed Downlink Packet Access (HSDPA), Generic Access Network (GAN), Time Division-Synchronous Code Division Multiple Access (TD-SCDMA), Evolution-Data Optimized (or Evolution-Data Only)(EVDO), Time Division-Code Division Multiple Access (TD-CDMA), Freedom Of Mobile Multimedia Access (FOMA), Universal Mobile Telecommunications System (UMTS), Wideband Code Division Multiple Access (W-CDMA), Enhanced Data rates for GSM Evolution (EDGE), Enhanced GPRS (EGPRS), Code Division Multiple Access-2000 (CDMA2000), Wideband Integrated Dispatch Enhanced Network (WiDEN), High-Speed Circuit-Switched Data (HSCSD), General Packet Radio Service (GPRS), Personal Handy-Phone System (PHS), Circuit Switched Data (CSD), Personal Digital Cellular (PDC), CDMAone, Digital Advanced Mobile Phone System (D-AMPS), Integrated Digital Enhanced Network (IDEN), Global System for Mobile communications (GSM), DataTAC, Mobitex, Cellular Digital Packet Data (CDPD), Hicap, Advanced Mobile Phone System (AMPS), Nordic Mobile Phone (NMP), Autoradiopuhelin (ARP), Autotel or Public Automated Land Mobile (PALM), Mobiltelefonisystem D (MTD), Offentlig Landmobil Telefoni (OLT), Advanced Mobile Telephone System (AMTS), Improved Mobile Telephone Service (IMTS), Mobile Telephone System (MTS), Push-To-Talk (PTT), or other technologies. Communication via W-CDMA, HSUPA, GSM, GPRS, and EDGE networks may occur, for example, using a QUALCOMM MSM7200A chipset with a QUALCOMM RTR6285™ transceiver and PM7540™ power management circuit.
- The wireless or wired
computer network connection 306 may be a modem connection, a local-area network (LAN) connection including the Ethernet, or a broadband wide-area network (WAN) connection such as a digital subscriber line (DSL), cable high-speed internet connection, dial-up connection, T-1 line, T-3 line, fiber optic connection, or satellite connection. Thenetwork connection 306 may connect to a LAN network, a corporate or government WAN network, the Internet, a telephone network, or other network. Thenetwork connection 306 uses a wired or wireless connector. Example wireless connectors include, for example, an INFRARED DATA ASSOCIATION (IrDA) wireless connector, a Wi-Fi wireless connector, an optical wireless connector, an INSTITUTE OF ELECTRICAL AND ELECTRONICS ENGINEERS (IEEE) Standard 802.11 wireless connector, a BLUETOOTH wireless connector (such as a BLUETOOTH version 1.2 or 3.0 connector), a near field communications (NFC) connector, an orthogonal frequency division multiplexing (OFDM) ultra wide band (UWB) wireless connector, a time-modulated ultra wide band (TM-UWB) wireless connector, or other wireless connector. Example wired connectors include, for example, an IEEE-1394 FIREWIRE connector, a Universal Serial Bus (USB) connector (including a mini-B USB interface connector), a serial port connector, a parallel port connector, or other wired connector. In another implementation, the functions of thenetwork connection 306 and the antenna 305 are integrated into a single component. - The
camera 307 allows thedevice 300 to capture digital images, and may be a scanner, a digital still camera, a digital video camera, or other digital input device. In one example implementation, thecamera 307 is a 3 mega-pixel (MP) camera that utilizes a complementary metal-oxide semiconductor (CMOS). - The
microphone 309 allows thedevice 300 to capture sound, and may be an omni-directional microphone, a unidirectional microphone, a bi-directional microphone, a shotgun microphone, or other type of apparatus that converts sound to an electrical signal. Themicrophone 309 may be used to capture sound generated by a user, for example when the user is speaking to another user during a telephone call via thedevice 300. Conversely, thespeaker 310 allows the device to convert an electrical signal into sound, such as a voice from another user generated by a telephone application program, or a ring tone generated from a ring tone application program. Furthermore, although thedevice 300 is illustrated inFIG. 3 as a handheld device, in further implementations thedevice 300 may be a laptop, a workstation, a midrange computer, a mainframe, an embedded system, telephone, desktop PC, a tablet computer, a PDA, or other type of computing device. -
FIG. 4 is a block diagram illustrating aninternal architecture 400 of thedevice 300. The architecture includes a central processing unit (CPU) 401 where the computer instructions that comprise an operating system or an application are processed; a display interface 402 that provides a communication interface and processing functions for rendering video, graphics, images, and texts on the display 301, provides a set of built-in controls (such as buttons, text and lists), and supports diverse screen sizes; a keyboard interface 404 that provides a communication interface to the keyboard 302; a pointing device interface 405 that provides a communication interface to the pointing device 304; an antenna interface 406 that provides a communication interface to the antenna 305; a network connection interface 407 that provides a communication interface to a network over the computer network connection 306; a camera interface 408 that provides a communication interface and processing functions for capturing digital images from the camera 307; a sound interface 409 that provides a communication interface for converting sound into electrical signals using the microphone 309 and for converting electrical signals into sound using the speaker 310; a random access memory (RAM) 410 where computer instructions and data are stored in a volatile memory device for processing by the CPU 401; a read-only memory (ROM) 411 where invariant low-level systems code or data for basic system functions such as basic input and output (I/O), startup, or reception of keystrokes from the keyboard 302 are stored in a non-volatile memory device; a storage medium 412 or other suitable type of memory (e.g. such as RAM, ROM, programmable read-only memory (PROM), erasable programmable read-only memory (EPROM), electrically erasable programmable read-only memory (EEPROM), magnetic disks, optical disks, floppy disks, hard disks, removable cartridges, flash drives), where the files that comprise an operating system 414, application programs 415 (including, for example, a web browser application, a widget or gadget engine, and or other applications, as necessary) and data files 416 are stored; a navigation module 417 that provides a real-world or relative position or geographic location of the device 300; a power source 419 that provides an appropriate alternating current (AC) or direct current (DC) to power components; and a telephony subsystem 420 that allows the device 300 to transmit and receive sound over a telephone network. The constituent devices and theCPU 401 communicate with each other over abus 421. - The
CPU 401 can be one of a number of computer processors. In one arrangement, thecomputer CPU 401 is more than one processing unit. TheRAM 410 interfaces with thecomputer bus 421 so as to provide quick RAM storage to theCPU 401 during the execution of software programs such as the operating system application programs, and device drivers. More specifically, theCPU 401 loads computer-executable process steps from thestorage medium 412 or other media into a field of theRAM 410 in order to execute software programs. Data is stored in theRAM 410, where the data is accessed by thecomputer CPU 401 during execution. In one example configuration, thedevice 300 includes at least 128MB of RAM, and 256MB of flash memory. - The
storage medium 412 itself may include a number of physical drive units, such as a redundant array of independent disks (RAID), a floppy disk drive, a flash memory, a USB flash drive, an external hard disk drive, thumb drive, pen drive, key drive, a High-Density Digital Versatile Disc (HD-DVD) optical disc drive, an internal hard disk drive, a Blu-Ray optical disc drive, or a Holographic Digital Data Storage (HDDS) optical disc drive, an external mini-dual in-line memory module (DIMM) synchronous dynamic random access memory (SDRAM), or an external micro-DIMM SDRAM. Such computer readable storage media allow thedevice 300 to access computer-executable process steps, application programs and the like, stored on removable and non-removable memory media, to off-load data from thedevice 300, or to upload data onto thedevice 300. - A computer program product is tangibly embodied in
storage medium 412, a machine-readable storage medium. The computer program product includes instructions that, when read by a machine, operate to cause a data processing apparatus to store image data in the mobile device. In some embodiments, the computer program product includes instructions that cause a data processing apparatus to collect and filtering text recognition system corrections from users of a text recognition system. - The
operating system 414 may be a LINUX-based operating system such as a mobile device platform; APPLE MAC OS X; MICROSOFT WINDOWS NT/WINDOWS 2000/WINDOWS XP/WINDOWS MOBILE; a variety of UNIX-flavored operating systems; or a proprietary operating system for computers or embedded systems. The application development platform or framework for theoperating system 414 may be: BINARY RUNTIME ENVIRONMENT FOR WIRELESS (BREW); JAVA Platform, Micro Edition (JAVA ME) orJAVA 2 Platform, Micro Edition (J2ME) using the SUN MICROSYSTEMS JAVASCRIPT programming language; PYTHON™, FLASH LITE, or MICROSOFT .NET Compact, or another appropriate environment. - The device stores computer-executable code for the
operating system 414, and theapplication programs 415 such as an email, instant messaging, a video service application, a mapping application word processing, spreadsheet, presentation, gaming, mapping, web browsing, JAVASCRIPT engine, or other applications. For example, one implementation may allow a user to access the GMAIL email application, an instant messaging application, a video service application, a mapping application, or an imaging editing and presentation application. Theapplication programs 415 may also include a widget or gadget engine, such as a TAFRI™ widget engine, a MICROSOFT gadget engine such as the WINDOWS SIDEBAR gadget engine or the KAPSULES™ gadget engine, a YAHOO! widget engine such as the KONFABULTOR™ widget engine, the APPLE DASHBOARD widget engine, a gadget engine, the KLIPFOLIO widget engine, an OPERA™ widget engine, the WIDSETS™ widget engine, a proprietary widget or gadget engine, or other widget or gadget engine the provides host system software for a physically-inspired applet on a desktop. - Although it is possible to provide for filtering of text recognition corrections using the above-described implementation, it is also possible to implement the functions according to the present disclosure as a dynamic link library (DLL), or as a plug-in to other application programs such as an Internet web-browser such as the FOXFIRE web browser, the APPLE SAFARI web browser or the MICROSOFT INTERNET EXPLORER web browser.
- The
navigation module 417 may determine an absolute or relative position of the device, such as by using the Global Positioning System (GPS) signals, the GLObal NAvigation Satellite System (GLONASS), the Galileo positioning system, the Beidou Satellite Navigation and Positioning System, an inertial navigation system, a dead reckoning system, or by accessing address, internet protocol (IP) address, or location information in a database. Thenavigation module 417 may also be used to measure angular displacement, orientation, or velocity of thedevice 300, such as by using one or more accelerometers. -
FIG. 5 is a block diagram illustrating exemplary components of theoperating system 414 used by thedevice 300, in the case where theoperating system 414 is a mobile device platform. Theoperating system 414 invokes multiple processes, while ensuring that the associated phone application is responsive, and that wayward applications do not cause a fault (or "crash") of the operating system. Using task switching, theoperating system 414 allows for the switching of applications while on a telephone call, without losing the state of each associated application. Theoperating system 414 may use an application framework to encourage reuse of components, and provide a scalable user experience by combining pointing device and keyboard inputs and by allowing for pivoting. Thus, the operating system can provide a rich graphics system and media experience, while using an advanced, standards-based web browser. - The
operating system 414 can generally be organized into six components: akernel 500,libraries 501, anoperating system runtime 502,application libraries 504,system services 505, andapplications 506. Thekernel 500 includes adisplay driver 507 that allows software such as theoperating system 414 and theapplication programs 415 to interact with thedisplay 301 via thedisplay interface 402, acamera driver 509 that allows the software to interact with thecamera 307; aBLUETOOTH driver 510; a M-Systems driver 511; a binder (IPC)driver 512, a USB driver 514 akeypad driver 515 that allows the software to interact with thekeyboard 302 via thekeyboard interface 404; aWiFi driver 516;audio drivers 517 that allow the software to interact with themicrophone 309 and thespeaker 310 via thesound interface 409; and apower management component 519 that allows the software to interact with and manage thepower source 519. - The BLUETOOTH driver, which in one implementation is based on the BlueZ BLUETOOTH stack for LINUX-based operating systems, provides profile support for headsets and hands-free devices, dial-up networking, personal area networking (PAN), or audio streaming (such as by Advance Audio Distribution Profile (A2DP) or Audio/Video Remote Control Profile (AVRCP). The BLUETOOTH driver provides JAVA bindings for scanning, pairing and unpairing, and service queries.
- The
libraries 501 include a media framework 520 that supports standard video, audio and still-frame formats (such as Moving Picture Experts Group (MPEG)-4, H.264, MPEG-1 Audio Layer-3 (MP3), Advanced Audio Coding (AAC), Adaptive Multi-Rate (AMR), Joint Photographic Experts Group (JPEG), and others) using an efficient JAVA Application Programming Interface (API) layer; asurface manager 521; a simple graphics library (SGL) 522 for two-dimensional application drawing; an Open Graphics Library for Embedded Systems (OpenGL ES) 524 for gaming and three-dimensional rendering; a C standard library (LIBC) 525; aLIBWEBCORE library 526; aFreeType library 527; anSSL 529; and anSQLite library 530. - The
operating system runtime 502 includescore JAVA libraries 531, and a Dalvikvirtual machine 532. The Dalvikvirtual machine 532 is a custom, virtual machine that runs a customized file format (.DEX). - The
operating system 414 can also include Mobile Information Device Profile (MIDP) components such as the MIDP JAVA Specification Requests (JSRs) components, MIDP runtime, and MIDP applications as shown inFIG. 5 . The MIDP components can support MIDP applications running on thedevice 300. - With regard to graphics rendering, a system-wide composer manages surfaces and a frame buffer and handles window transitions, using the
OpenGL ES 524 and two-dimensional hardware accelerators for its compositions. - The Dalvik
virtual machine 532 may be used with an embedded environment, since it uses runtime memory very efficiently, implements a CPU-optimized bytecode interpreter, and supports multiple virtual machine processes per device. The custom file format (.DEX) is designed for runtime efficiency, using a shared constant pool to reduce memory, read-only structures to improve cross-process sharing, concise, and fixed-width instructions to reduce parse time, thereby allowing installed applications to be translated into the custom file formal at build-time. The associated bytecodes are designed for quick interpretation, since register-based instead of stack-based instructions reduce memory and dispatch overhead, since using fixed width instructions simplifies parsing, and since the 16-bit code units minimize reads. - The
application libraries 504 include aview system 534, aresource manager 535,content providers 537, and a text recognition corrections filter 552. The system services 505 includes astatus bar 539; anapplication launcher 540; apackage manager 541 that maintains information for all installed applications; atelephony manager 542 that provides an application level JAVA interface to thetelephony subsystem 420; anotification manager 544 that allows all applications access to the status bar and on-screen notifications; awindow manager 545 that allows multiple applications with multiple windows to share thedisplay 301; and anactivity manager 546 that runs each application in a separate process, manages an application life cycle, and maintains a cross-application history. - The
applications 506 include ahome application 547, adialer application 549, acontacts application 550, and abrowser application 551. - The
telephony manager 542 provides event notifications (such as phone state, network state, Subscriber Identity Module (SIM) status, or voicemail status), allows access to state information (such as network information, SIM information, or voicemail presence), initiates calls, and queries and controls the call state. Thebrowser application 551 renders web pages in a full, desktop-like manager, including navigation functions. Furthermore, thebrowser application 551 allows single column, small screen rendering, and provides for the embedding of HTML views into other applications. -
FIG. 6 is a block diagram illustrating exemplary processes implemented by theoperating system kernel 600. Generally, applications and system services run in separate processes, where theactivity manager 546 runs each application in a separate process and manages the application life cycle. The applications run in their own processes, although many activities or services can also run in the same process. Processes are started and stopped as needed to run an application's components, and processes may be terminated to reclaim resources. Each application is assigned its own process, whose name is the application's package name, and individual parts of an application can be assigned another process name. - Some processes can be persistent. For example, processes associated with core system components such as the
surface manager 616, thewindow manager 614, or theactivity manager 610 can be continuously executed while thedevice 300 is powered. Additionally, some application-specific process can also be persistent. For example, processes associated with thedialer application 621, may also be persistent. - The processes implemented by the
operating system kernel 600 may generally be categorized as system services processes 601, dialer processes 602, browser processes 604, and maps processes 605. The system servicesprocesses 601 include status bar processes 606 associated with thestatus bar 539; application launcher processes 607 associated with theapplication launcher 540; package manager processes 609 associated with thepackage manager 541; activity manager processes 610 associated with theactivity manager 546; resource manager processes 611 associated with aresource manager 611 that provides access to graphics, localized strings, and XML layout descriptions; notification manger processes 612 associated with thenotification manager 544; window manager processes 614 associated with thewindow manager 545; core JAVA libraries processes 615 associated with thecore JAVA libraries 531; surface manager processes 616 associated with thesurface manager 521; Dalvik virtual machine processes 617 associated with the Dalvikvirtual machine 532, LIBC processes 619 associated with theLIBC library 525; and text recognition correction filter processes 620 associated with the text recognition correctionfilter application library 552. - The dialer processes 602 include dialer application processes 621 associated with the
dialer application 549; telephony manager processes 622 associated with thetelephony manager 542; core JAVA libraries processes 624 associated with thecore JAVA libraries 531; Dalvik virtual machine processes 625 associated with the DalvikVirtual machine 532; and LIBC processes 626 associated with theLIBC library 525. The browser processes 604 include browser application processes 627 associated with thebrowser application 551; core JAVA libraries processes 629 associated with thecore JAVA libraries 531; Dalvik virtual machine processes 630 associated with the Dalvikvirtual machine 532; LIBWEBCORE processes 631 associated with theLIBWEBCORE library 526; and LIBC processes 632 associated with theLIBC library 525. - The maps processes 605 include maps application processes 634, core JAVA libraries processes 635, Dalvik virtual machine processes 636, and LIBC processes 637. Notably, some processes, such as the Dalvik virtual machine processes, may exist within one or more of the systems services processes 601, the dialer processes 602, the browser processes 604, and the maps processes 605.
-
FIG. 7 shows an example of a generic computer device 700 and a genericmobile computer device 750, which may be used with the techniques described here. Computing device 700 is intended to represent various forms of digital computers, such as laptops, desktops, workstations, personal digital assistants, servers, blade servers, mainframes, and other appropriate computers.Computing device 750 is intended to represent various forms of mobile devices, such as personal digital assistants, cellular telephones, smartphones, and other similar computing devices. The components shown here, their connections and relationships, and their functions, are meant to be exemplary only, and are not meant to limit implementations of the inventions described and/or claimed in this document. - Computing device 700 includes a processor 702,
memory 704, astorage device 706, a high-speed interface 708 connecting tomemory 704 and high-speed expansion ports 710, and alow speed interface 712 connecting tolow speed bus 714 andstorage device 706. Each of thecomponents memory 704 or on thestorage device 706 to display graphical information for a GUI on an external input/output device, such asdisplay 716 coupled tohigh speed interface 708. In other implementations, multiple processors and/or multiple buses may be used, as appropriate, along with multiple memories and types of memory. Also, multiple computing devices 700 may be connected, with each device providing portions of the necessary operations (e.g., as a server bank, a group of blade servers, or a multi-processor system). - The
memory 704 stores information within the computing device 700. In one implementation, thememory 704 is a volatile memory unit or units. In another implementation, thememory 704 is a non-volatile memory unit or units. Thememory 704 may also be another form of computer-readable medium, such as a magnetic or optical disk. - The
storage device 706 is capable of providing mass storage for the computing device 700. In one implementation, thestorage device 706 may be or contain a computer-readable medium, such as a floppy disk device, a hard disk device, an optical disk device, or a tape device, a flash memory or other similar solid state memory device, or an array of devices, including devices in a storage area network or other configurations. A computer program product can be tangibly embodied in an information carrier. The computer program product may also contain instructions that, when executed, perform one or more methods, such as those described above. The information carrier is a computer- or machine-readable medium, such as thememory 704, thestorage device 706, memory on processor 702, or a propagated signal. - The
high speed controller 708 manages bandwidth-intensive operations for the computing device 700, while thelow speed controller 712 manages lower bandwidth-intensive operations. Such allocation of functions is exemplary only. In one implementation, the high-speed controller 708 is coupled tomemory 704, display 716 (e.g., through a graphics processor or accelerator), and to high-speed expansion ports 710, which may accept various expansion cards (not shown). In the implementation, low-speed controller 712 is coupled tostorage device 706 and low-speed expansion port 714. The low-speed expansion port, which may include various communication ports (e.g., USB, Bluetooth, Ethernet, wireless Ethernet) may be coupled to one or more input/output devices, such as a keyboard, a pointing device, a scanner, or a networking device such as a switch or router, e.g., through a network adapter. - The computing device 700 may be implemented in a number of different forms, as shown in the figure. For example, it may be implemented as a
standard server 720, or multiple times in a group of such servers. It may also be implemented as part of a rack server system 724. In addition, it may be implemented in a personal computer such as alaptop computer 722. Alternatively, components from computing device 700 may be combined with other components in a mobile device (not shown), such asdevice 750. Each of such devices may contain one or more ofcomputing device 700, 750, and an entire system may be made up ofmultiple computing devices 700, 750 communicating with each other. -
Computing device 750 includes aprocessor 752,memory 764, an input/output device such as adisplay 754, acommunication interface 766, and atransceiver 768, among other components. Thedevice 750 may also be provided with a storage device, such as a microdrive or other device, to provide additional storage. Each of thecomponents - The
processor 752 can execute instructions within thecomputing device 750, including instructions stored in thememory 764. The processor may be implemented as a chipset of chips that include separate and multiple analog and digital processors. The processor may provide, for example, for coordination of the other components of thedevice 750, such as control of user interfaces, applications run bydevice 750, and wireless communication bydevice 750. -
Processor 752 may communicate with a user throughcontrol interface 758 anddisplay interface 756 coupled to adisplay 754. Thedisplay 754 may be, for example, a TFT LCD (Thin-Film-Transistor Liquid Crystal Display) or an OLED (Organic Light Emitting Diode) display, or other appropriate display technology. Thedisplay interface 756 may comprise appropriate circuitry for driving thedisplay 754 to present graphical and other information to a user. Thecontrol interface 758 may receive commands from a user and convert them for submission to theprocessor 752. In addition, anexternal interface 762 may be provide in communication withprocessor 752, so as to enable near area communication ofdevice 750 with other devices.External interface 762 may provide, for example, for wired communication in some implementations, or for wireless communication in other implementations, and multiple interfaces may also be used. - The
memory 764 stores information within thecomputing device 750. Thememory 764 can be implemented as one or more of a computer-readable medium or media, a volatile memory unit or units, or a non-volatile memory unit or units.Expansion memory 774 may also be provided and connected todevice 750 throughexpansion interface 772, which may include, for example, a SIMM (Single In Line Memory Module) card interface.Such expansion memory 774 may provide extra storage space fordevice 750, or may also store applications or other information fordevice 750. Specifically,expansion memory 774 may include instructions to carry out or supplement the processes described above, and may include secure information also. Thus, for example,expansion memory 774 may be provide as a security module fordevice 750, and may be programmed with instructions that permit secure use ofdevice 750. In addition, secure applications may be provided via the SIMM cards, along with additional information, such as placing identifying information on the SIMM card in a non-hackable manner. - The memory may include, for example, flash memory and/or NVRAM memory, as discussed below. In one implementation, a computer program product is tangibly embodied in an information carrier. The computer program product contains instructions that, when executed, perform one or more methods, such as those described above. The information carrier is a computer- or machine-readable medium, such as the
memory 764,expansion memory 774, memory onprocessor 752, or a propagated signal that may be received, for example, overtransceiver 768 orexternal interface 762. -
Device 750 may communicate wirelessly throughcommunication interface 766, which may include digital signal processing circuitry where necessary.Communication interface 766 may provide for communications under various modes or protocols, such as GSM voice calls, SMS, EMS, or MMS messaging, CDMA, TDMA, PDC, WCDMA, CDMA2000, or GPRS, among others. Such communication may occur, for example, through radio-frequency transceiver 768. In addition, short-range communication may occur, such as using a Bluetooth, WiFi, or other such transceiver (not shown). In addition, GPS (Global Positioning System)receiver module 770 may provide additional navigation- and location-related wireless data todevice 750, which may be used as appropriate by applications running ondevice 750. -
Device 750 may also communicate audibly usingaudio codec 760, which may receive spoken information from a user and convert it to usable digital information.Audio codec 760 may likewise generate audible sound for a user, such as through a speaker, e.g., in a handset ofdevice 750. Such sound may include sound from voice telephone calls, may include recorded sound (e.g., voice messages, music files, etc.) and may also include sound generated by applications operating ondevice 750. - The
computing device 750 may be implemented in a number of different forms, as shown in the figure. For example, it may be implemented as acellular telephone 780. It may also be implemented as part of asmartphone 782, personal digital assistant, or other similar mobile device. - Various implementations of the systems and techniques described here can be realized in digital electronic circuitry, integrated circuitry, specially designed ASICs (application specific integrated circuits), computer hardware, firmware, software, and/or combinations thereof. These various implementations can include implementation in one or more computer programs that are executable and/or interpretable on a programmable system including at least one programmable processor, which may be special or general purpose, coupled to receive data and instructions from, and to transmit data and instructions to, a storage system, at least one input device, and at least one output device.
- These computer programs (also known as programs, software, software applications or code) include machine instructions for a programmable processor, and can be implemented in a high-level procedural and/or object-oriented programming language, and/or in assembly/machine language. As used herein, the terms "machine-readable medium" "computer-readable medium" refers to any computer program product, apparatus and/or device (e.g., magnetic discs, optical disks, memory, Programmable Logic Devices (PLDs)) used to provide machine instructions and/or data to a programmable processor, including a machine-readable medium that receives machine instructions as a machine-readable signal. The term "machine-readable signal" refers to any signal used to provide machine instructions and/or data to a programmable processor.
- To provide for interaction with a user, the systems and techniques described here can be implemented on a computer having a display device (e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor) for displaying information to the user and a keyboard and a pointing device (e.g., a mouse or a trackball) by which the user can provide input to the computer. Other kinds of devices can be used to provide for interaction with a user as well; for example, feedback provided to the user can be any form of sensory feedback (e.g., visual feedback, auditory feedback, or tactile feedback); and input from the user can be received in any form, including acoustic, speech, or tactile input.
- The systems and techniques described here can be implemented in a computing system that includes a back end component (e.g., as a data server), or that includes a middleware component (e.g., an application server), or that includes a front end component (e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the systems and techniques described here), or any combination of such back end, middleware, or front end components. The components of the system can be interconnected by any form or medium of digital data communication (e.g., a communication network). Examples of communication networks include a local area network ("LAN"), a wide area network ("WAN"), and the Internet.
- The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other.
- A number of embodiments have been described. Nevertheless, it will be understood that various modifications may be made without departing from the scope of the invention. For example, text recognition system may be implemented on a mobile device (e.g., mobile device 300) along with a text recognition corrections filter. The local text recognition system may be adapted to speech or handwriting patterns of a particular user, in part, by training with corrections selected using the text recognition corrections filter.
- In addition, the logic flows depicted in the figures do not require the particular order shown, or sequential order, to achieve desirable results. In addition, other steps may be provided, or steps may be eliminated, from the described flows, and other components may be added to, or removed from, the described systems. Accordingly, other embodiments are within the scope of the following claims.
Claims (15)
- A computer-implemented method performed by a data processing apparatus, the method comprising:receiving an input signal comprising data that corresponds to one or more words (202);passing the input signal to a text recognition system (204) that generates a recognized text string based on the input signal;receiving the recognized text string (206) from the text recognition system;presenting the recognized text string (208) to a user;receiving a corrected text string (210) based on input from the user;determining an edit distance andchecking if the edit distance between the corrected text string and the recognized text string is below a threshold (212); andif the edit distance is below the threshold, passing the corrected text string to the text recognition system for training purposes (216).
- The method of claim 1, wherein the edit distance is a minimum number of write operations, from a set of allowed operations, needed to produce the corrected text string from the recognized text string, wherein write operations include character insertion and character substitution, and wherein character deletion is allowed but not counted in the edit distance.
- The method of claim 1, wherein checking if an edit distance between the corrected text string and the recognized text string is below threshold comprises:computing intermediate edit distance values until the threshold is exceeded or the edit distance is determined.
- The method of claim 1, wherein the edit distance represents the minimum number of single character insertion, deletion, or substitution operations required to transform the recognized text string into the corrected text string.
- The method of claim 1, wherein the edit distance is a maximum number of consecutive characters inserted.
- The method of claim 1, wherein the text recognition system is executed by a remotely located server (101).
- The method of claim 1, wherein the text recognition system is executed by a user device (134).
- The method of claim 1, wherein passing the input signal to a text recognition system (204) comprises:transmitting a signal encoding the input signal through a network.
- A system, comprising:a data processing apparatus; anda memory coupled to the data processing apparatus having instructions stored thereon which, when executed by the data processing apparatus cause the data processing apparatus to perform operations comprising:receiving an input signal comprising data that corresponds to one or more words (202);passing the input signal to a text recognition system (204) that generates a recognized text string based on the input signal;receiving the recognized text string (206) from the text recognition system;presenting the recognized text string (208) to a user;receiving a corrected text string (210) based on input from the user;determining an edit distance and checking if the edit distance between the corrected text string and the recognized text string is below a threshold (212); andif the edit distance is below the threshold, passing the corrected text string to the text recognition system for training purposes (216).
- The system of claim 9, wherein the edit distance represents the minimum number of single character insertion, deletion, or substitution operations required to transform the recognized text string into the corrected text string.
- The system of claim 9, wherein the edit distance is a minimum number of write operations, from a set of allowed operations, needed to produce the corrected text string from the recognized text string, wherein write operations include character insertion and character substitution, and wherein character deletion is allowed but not counted in the edit distance.
- The system of claim 9, wherein the text recognition system is executed by a remotely located server (101).
- The system of claim 9, wherein the text recognition system is executed by a user device (134).
- The system of claim 9, wherein passing the input signal to a text recognition system (204) comprises:transmitting a signal encoding the input signal through a network.
- A Computer readable medium storing software comprising instructions executable by a processing device that upon such execution cause the processing device to perform operations according to any one of claims 1 to 8.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201161540381P | 2011-09-28 | 2011-09-28 | |
US13/627,744 US8515751B2 (en) | 2011-09-28 | 2012-09-26 | Selective feedback for text recognition systems |
PCT/US2012/057916 WO2013049569A1 (en) | 2011-09-28 | 2012-09-28 | Selective feedback for text recognition systems |
Publications (2)
Publication Number | Publication Date |
---|---|
EP2761502A1 EP2761502A1 (en) | 2014-08-06 |
EP2761502B1 true EP2761502B1 (en) | 2015-09-16 |
Family
ID=47912242
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
EP12773185.9A Active EP2761502B1 (en) | 2011-09-28 | 2012-09-28 | Selective feedback for text recognition systems |
Country Status (5)
Country | Link |
---|---|
US (1) | US8515751B2 (en) |
EP (1) | EP2761502B1 (en) |
CN (1) | CN103959282B (en) |
AU (1) | AU2012315749B2 (en) |
WO (1) | WO2013049569A1 (en) |
Families Citing this family (43)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9098487B2 (en) * | 2012-11-29 | 2015-08-04 | Hewlett-Packard Development Company, L.P. | Categorization based on word distance |
US20150073790A1 (en) * | 2013-09-09 | 2015-03-12 | Advanced Simulation Technology, inc. ("ASTi") | Auto transcription of voice networks |
US9286526B1 (en) * | 2013-12-09 | 2016-03-15 | Amazon Technologies, Inc. | Cohort-based learning from user edits |
US10395645B2 (en) * | 2014-04-22 | 2019-08-27 | Naver Corporation | Method, apparatus, and computer-readable recording medium for improving at least one semantic unit set |
WO2015179493A1 (en) * | 2014-05-23 | 2015-11-26 | Centrillion Technology Holding Corporation | Methods for generating and decoding barcodes |
US9520128B2 (en) * | 2014-09-23 | 2016-12-13 | Intel Corporation | Frame skipping with extrapolation and outputs on demand neural network for automatic speech recognition |
US10609475B2 (en) | 2014-12-05 | 2020-03-31 | Stages Llc | Active noise control and customized audio system |
CN104572627B (en) * | 2015-01-30 | 2018-01-23 | 深圳市华傲数据技术有限公司 | Object oriented editing distance computational methods and matching process based on comentropy |
US9959069B2 (en) * | 2015-02-12 | 2018-05-01 | Microsoft Technology Licensing, Llc | Externalized execution of input method editor |
US10354006B2 (en) * | 2015-10-26 | 2019-07-16 | International Business Machines Corporation | System, method, and recording medium for web application programming interface recommendation with consumer provided content |
CN105653517A (en) * | 2015-11-05 | 2016-06-08 | 乐视致新电子科技（天津）有限公司 | Recognition rate determining method and apparatus |
US20170269688A1 (en) * | 2016-03-18 | 2017-09-21 | Elwha Llc | Systems and methods for providing haptic feedback regarding software-initiated changes to user-entered text input |
US20170337923A1 (en) * | 2016-05-19 | 2017-11-23 | Julia Komissarchik | System and methods for creating robust voice-based user interface |
US9980042B1 (en) | 2016-11-18 | 2018-05-22 | Stages Llc | Beamformer direction of arrival and orientation analysis system |
US10945080B2 (en) | 2016-11-18 | 2021-03-09 | Stages Llc | Audio analysis and processing system |
US9980075B1 (en) | 2016-11-18 | 2018-05-22 | Stages Llc | Audio source spatialization relative to orientation sensor and output |
KR102457811B1 (en) * | 2016-11-21 | 2022-10-24 | 삼성전자주식회사 | Device and method for sending money using voice |
US11605081B2 (en) * | 2016-11-21 | 2023-03-14 | Samsung Electronics Co., Ltd. | Method and device applying artificial intelligence to send money by using voice input |
US10607463B2 (en) * | 2016-12-09 | 2020-03-31 | The Boeing Company | Automated object and activity tracking in a live video feed |
US10296788B1 (en) * | 2016-12-19 | 2019-05-21 | Matrox Electronic Systems Ltd. | Method and system for processing candidate strings detected in an image to identify a match of a model string in the image |
US10217020B1 (en) * | 2016-12-19 | 2019-02-26 | Matrox Electronic Systems Ltd. | Method and system for identifying multiple strings in an image based upon positions of model strings relative to one another |
CN106847288B (en) * | 2017-02-17 | 2020-12-25 | 上海创米科技有限公司 | Error correction method and device for voice recognition text |
US10861476B2 (en) * | 2017-05-24 | 2020-12-08 | Modulate, Inc. | System and method for building a voice database |
CN108417205B (en) * | 2018-01-19 | 2020-12-18 | 苏州思必驰信息科技有限公司 | Semantic understanding training method and system |
US10811007B2 (en) * | 2018-06-08 | 2020-10-20 | International Business Machines Corporation | Filtering audio-based interference from voice commands using natural language processing |
CN109447081B (en) * | 2018-11-14 | 2021-07-23 | 广东小天才科技有限公司 | Method and system for acquiring optical character recognition data set |
CN109767081B (en) * | 2018-12-25 | 2023-08-25 | 云南电网有限责任公司信息中心 | Method and device for generating power worksheet |
CN109783811B (en) * | 2018-12-26 | 2023-10-31 | 东软集团股份有限公司 | Method, device, equipment and storage medium for identifying text editing errors |
CN110377885B (en) * | 2019-06-14 | 2023-09-26 | 北京百度网讯科技有限公司 | Method, device, equipment and computer storage medium for converting PDF file |
CN110610001B (en) * | 2019-08-12 | 2024-01-23 | 大箴(杭州)科技有限公司 | Short text integrity recognition method, device, storage medium and computer equipment |
CN110458918B (en) * | 2019-08-16 | 2023-05-09 | 北京百度网讯科技有限公司 | Method and device for outputting information |
CN110473523A (en) * | 2019-08-30 | 2019-11-19 | 北京大米科技有限公司 | A kind of audio recognition method, device, storage medium and terminal |
WO2021045793A1 (en) * | 2019-09-03 | 2021-03-11 | Google Llc | Using corrections, of predicted textual segments of spoken utterances, for training of on-device speech recognition model |
CN114664306A (en) * | 2020-12-22 | 2022-06-24 | 华为技术有限公司 | Method, electronic equipment and system for editing text |
CN111985491A (en) * | 2020-09-03 | 2020-11-24 | 深圳壹账通智能科技有限公司 | Similar information merging method, device, equipment and medium based on deep learning |
CN112382289B (en) * | 2020-11-13 | 2024-03-22 | 北京百度网讯科技有限公司 | Speech recognition result processing method and device, electronic equipment and storage medium |
CN112508541A (en) * | 2020-12-30 | 2021-03-16 | 贵州人和致远数据服务有限责任公司 | Portable mobile phone acquisition software system based on training trainee information data acquisition |
CN113052156B (en) * | 2021-03-12 | 2023-08-04 | 北京百度网讯科技有限公司 | Optical character recognition method, device, electronic equipment and storage medium |
US20220358152A1 (en) * | 2021-05-10 | 2022-11-10 | International Business Machines Corporation | Model performance through text-to-text transformation via distant supervision from target and auxiliary tasks |
CN113361253B (en) * | 2021-05-28 | 2024-04-09 | 北京金山数字娱乐科技有限公司 | Recognition model training method and device |
US11379542B1 (en) * | 2021-06-25 | 2022-07-05 | metacluster lt, UAB | Advanced response processing in web data collection |
US11861923B2 (en) * | 2021-12-31 | 2024-01-02 | Huawei Technologies Co., Ltd. | Methods, apparatuses, and computer-readable storage media for image-based sensitive-text detection |
CN115361454B (en) * | 2022-10-24 | 2023-03-24 | 北京智芯微电子科技有限公司 | Message sequence coding, decoding and transmitting method and coding and decoding equipment |
Family Cites Families (9)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6253177B1 (en) * | 1999-03-08 | 2001-06-26 | International Business Machines Corp. | Method and system for automatically determining whether to update a language model based upon user amendments to dictated text |
CN1207664C (en) * | 1999-07-27 | 2005-06-22 | 国际商业机器公司 | Error correcting method for voice identification result and voice identification system |
US7113950B2 (en) * | 2002-06-27 | 2006-09-26 | Microsoft Corporation | Automated error checking system and method |
US8019602B2 (en) * | 2004-01-20 | 2011-09-13 | Microsoft Corporation | Automatic speech recognition learning using user corrections |
US8275618B2 (en) * | 2004-12-22 | 2012-09-25 | Nuance Communications, Inc. | Mobile dictation correction user interface |
US8352264B2 (en) | 2008-03-19 | 2013-01-08 | Canyon IP Holdings, LLC | Corrective feedback loop for automated speech recognition |
CN101295293B (en) * | 2007-04-29 | 2010-06-02 | 摩托罗拉公司 | Automatic error correction method for input character string of ideographic character |
US8644488B2 (en) | 2008-10-27 | 2014-02-04 | Nuance Communications, Inc. | System and method for automatically generating adaptive interaction logs from customer interaction text |
CN101655837B (en) * | 2009-09-08 | 2010-10-13 | 北京邮电大学 | Method for detecting and correcting error on text after voice recognition |
-
2012
- 2012-09-26 US US13/627,744 patent/US8515751B2/en active Active
- 2012-09-28 WO PCT/US2012/057916 patent/WO2013049569A1/en active Application Filing
- 2012-09-28 CN CN201280056889.4A patent/CN103959282B/en active Active
- 2012-09-28 AU AU2012315749A patent/AU2012315749B2/en not_active Ceased
- 2012-09-28 EP EP12773185.9A patent/EP2761502B1/en active Active
Also Published As
Publication number | Publication date |
---|---|
AU2012315749B2 (en) | 2014-05-22 |
WO2013049569A1 (en) | 2013-04-04 |
CN103959282A (en) | 2014-07-30 |
CN103959282B (en) | 2016-05-18 |
EP2761502A1 (en) | 2014-08-06 |
AU2012315749A1 (en) | 2014-04-10 |
US8515751B2 (en) | 2013-08-20 |
US20130080164A1 (en) | 2013-03-28 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
EP2761502B1 (en) | Selective feedback for text recognition systems | |
EP2579251B1 (en) | Interactive text editing | |
US20100114887A1 (en) | Textual Disambiguation Using Social Connections | |
US8775407B1 (en) | Determining intent of text entry | |
US10747944B1 (en) | Unified web and application framework | |
US20230072352A1 (en) | Speech Recognition Method and Apparatus, Terminal, and Storage Medium | |
US8296445B1 (en) | Software testing harness | |
US9332101B1 (en) | Contact cropping from images | |
US7960945B1 (en) | Estimating remaining use time of a mobile device | |
US8843895B2 (en) | Debugger connection | |
US8510743B2 (en) | Terminating computer applications | |
US8384686B1 (en) | Constrained keyboard organization | |
US9356792B1 (en) | Recording events for social media | |
US20150287406A1 (en) | Estimating Speech in the Presence of Noise | |
CN109427331B (en) | Speech recognition method and device | |
US8150429B1 (en) | Cost-effective voting | |
CN111787154A (en) | Information processing method and electronic equipment | |
US8910240B1 (en) | Mapping content using uniform resource identifiers | |
US8817050B1 (en) | N-patch image resizing | |
US20200372113A1 (en) | Log file meaning and syntax generation system | |
US10437887B1 (en) | Determining intent of text entry | |
WO2022135199A1 (en) | Information processing method, electronic device, and system |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PUAI | Public reference made under article 153(3) epc to a published international application that has entered the european phase |
Free format text: ORIGINAL CODE: 0009012 |
|
17P | Request for examination filed |
Effective date: 20140331 |
|
AK | Designated contracting states |
Kind code of ref document: A1Designated state(s): AL AT BE BG CH CY CZ DE DK EE ES FI FR GB GR HR HU IE IS IT LI LT LU LV MC MK MT NL NO PL PT RO RS SE SI SK SM TR |
|
DAX | Request for extension of the european patent (deleted) | ||
GRAP | Despatch of communication of intention to grant a patent |
Free format text: ORIGINAL CODE: EPIDOSNIGR1 |
|
INTG | Intention to grant announced |
Effective date: 20150402 |
|
GRAS | Grant fee paid |
Free format text: ORIGINAL CODE: EPIDOSNIGR3 |
|
GRAA | (expected) grant |
Free format text: ORIGINAL CODE: 0009210 |
|
AK | Designated contracting states |
Kind code of ref document: B1Designated state(s): AL AT BE BG CH CY CZ DE DK EE ES FI FR GB GR HR HU IE IS IT LI LT LU LV MC MK MT NL NO PL PT RO RS SE SI SK SM TR |
|
REG | Reference to a national code |
Ref country code: GBRef legal event code: FG4D |
|
REG | Reference to a national code |
Ref country code: CHRef legal event code: EP |
|
REG | Reference to a national code |
Ref country code: IERef legal event code: FG4D |
|
REG | Reference to a national code |
Ref country code: ATRef legal event code: REFRef document number: 750295Country of ref document: ATKind code of ref document: TEffective date: 20151015 |
|
REG | Reference to a national code |
Ref country code: DERef legal event code: R096Ref document number: 602012010769Country of ref document: DE |
|
PGFP | Annual fee paid to national office [announced via postgrant information from national office to epo] |
Ref country code: IEPayment date: 20150929Year of fee payment: 4 |
|
REG | Reference to a national code |
Ref country code: NLRef legal event code: MPEffective date: 20150916 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: LTFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20150916Ref country code: GRFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20151217Ref country code: LVFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20150916Ref country code: NOFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20151216Ref country code: FIFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20150916 |
|
REG | Reference to a national code |
Ref country code: LTRef legal event code: MG4D |
|
REG | Reference to a national code |
Ref country code: ATRef legal event code: MK05Ref document number: 750295Country of ref document: ATKind code of ref document: TEffective date: 20150916 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: RSFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20150916Ref country code: HRFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20150916Ref country code: SEFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20150916 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: NLFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20150916 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: SKFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20150916Ref country code: EEFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20150916Ref country code: CZFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20150916Ref country code: ISFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20160116Ref country code: ITFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20150916Ref country code: ESFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20150916 |
|
REG | Reference to a national code |
Ref country code: CHRef legal event code: PL |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: PTFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20160118Ref country code: ROFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20150916Ref country code: PLFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20150916Ref country code: ATFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20150916 |
|
REG | Reference to a national code |
Ref country code: DERef legal event code: R097Ref document number: 602012010769Country of ref document: DE |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: MCFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20150916 |
|
PLBE | No opposition filed within time limit |
Free format text: ORIGINAL CODE: 0009261 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: NO OPPOSITION FILED WITHIN TIME LIMIT |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: LIFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20150930Ref country code: CHFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20150930 |
|
26N | No opposition filed |
Effective date: 20160617 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: DKFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20150916 |
|
REG | Reference to a national code |
Ref country code: FRRef legal event code: PLFPYear of fee payment: 5 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: SIFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20150916 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: MTFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20150916 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: SMFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20150916Ref country code: BGFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20150916Ref country code: HUFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMIT; INVALID AB INITIOEffective date: 20120928 |
|
REG | Reference to a national code |
Ref country code: IERef legal event code: MM4A |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: CYFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20150916 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: IEFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20160928Ref country code: BEFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20150930 |
|
REG | Reference to a national code |
Ref country code: FRRef legal event code: PLFPYear of fee payment: 6 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: LUFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20150928 |
|
REG | Reference to a national code |
Ref country code: DERef legal event code: R082Ref document number: 602012010769Country of ref document: DERepresentative=s name: MARKS & CLERK (LUXEMBOURG) LLP, LURef country code: DERef legal event code: R081Ref document number: 602012010769Country of ref document: DEOwner name: GOOGLE LLC (N.D.GES.D. STAATES DELAWARE), MOUN, USFree format text: FORMER OWNER: GOOGLE, INC., MOUNTAIN VIEW, CALIF., US |
|
REG | Reference to a national code |
Ref country code: FRRef legal event code: CDOwner name: GOOGLE INC., USEffective date: 20180213Ref country code: FRRef legal event code: CJEffective date: 20180213 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: TRFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20150916Ref country code: MKFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20150916 |
|
REG | Reference to a national code |
Ref country code: FRRef legal event code: PLFPYear of fee payment: 7 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: ALFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20150916 |
|
REG | Reference to a national code |
Ref country code: DERef legal event code: R079Ref document number: 602012010769Country of ref document: DEFree format text: PREVIOUS MAIN CLASS: G06F0017270000Ipc: G06F0040200000 |
|
P01 | Opt-out of the competence of the unified patent court (upc) registered |
Effective date: 20230505 |
|
PGFP | Annual fee paid to national office [announced via postgrant information from national office to epo] |
Ref country code: GBPayment date: 20230927Year of fee payment: 12 |
|
PGFP | Annual fee paid to national office [announced via postgrant information from national office to epo] |
Ref country code: FRPayment date: 20230925Year of fee payment: 12Ref country code: DEPayment date: 20230927Year of fee payment: 12 |