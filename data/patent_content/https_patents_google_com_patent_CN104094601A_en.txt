CN104094601A - Devices and methods for sample adaptive offset coding and/or signaling - Google Patents
Devices and methods for sample adaptive offset coding and/or signaling Download PDFInfo
- Publication number
- CN104094601A CN104094601A CN201280054893.7A CN201280054893A CN104094601A CN 104094601 A CN104094601 A CN 104094601A CN 201280054893 A CN201280054893 A CN 201280054893A CN 104094601 A CN104094601 A CN 104094601A
- Authority
- CN
- China
- Prior art keywords
- sao
- type
- video
- coding
- skew
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
- 238000000034 method Methods 0.000 title claims abstract description 52
- 230000011664 signaling Effects 0.000 title claims description 61
- 230000003044 adaptive effect Effects 0.000 title claims description 7
- 238000005070 sampling Methods 0.000 claims description 20
- 230000006978 adaptation Effects 0.000 claims description 16
- 238000005452 bending Methods 0.000 claims description 16
- 238000004891 communication Methods 0.000 claims description 3
- 238000000638 solvent extraction Methods 0.000 abstract 1
- 238000006243 chemical reaction Methods 0.000 description 26
- 238000011002 quantification Methods 0.000 description 20
- 238000013139 quantization Methods 0.000 description 15
- 230000006870 function Effects 0.000 description 14
- 238000012545 processing Methods 0.000 description 14
- 238000001914 filtration Methods 0.000 description 10
- 238000007906 compression Methods 0.000 description 8
- 230000006835 compression Effects 0.000 description 8
- 238000005516 engineering process Methods 0.000 description 7
- 238000003860 storage Methods 0.000 description 7
- 239000011159 matrix material Substances 0.000 description 6
- 230000008569 process Effects 0.000 description 5
- 241000196324 Embryophyta Species 0.000 description 4
- 230000000712 assembly Effects 0.000 description 4
- 238000000429 assembly Methods 0.000 description 4
- 230000005012 migration Effects 0.000 description 4
- 238000013508 migration Methods 0.000 description 4
- 230000009466 transformation Effects 0.000 description 4
- 238000005520 cutting process Methods 0.000 description 3
- 230000008030 elimination Effects 0.000 description 3
- 238000003379 elimination reaction Methods 0.000 description 3
- 230000006872 improvement Effects 0.000 description 3
- 230000009467 reduction Effects 0.000 description 3
- 230000002123 temporal effect Effects 0.000 description 3
- 230000007704 transition Effects 0.000 description 3
- 230000000903 blocking effect Effects 0.000 description 2
- 239000002131 composite material Substances 0.000 description 2
- 238000010586 diagram Methods 0.000 description 2
- 238000009826 distribution Methods 0.000 description 2
- 239000000203 mixture Substances 0.000 description 2
- 235000017060 Arachis glabrata Nutrition 0.000 description 1
- 241001553178 Arachis glabrata Species 0.000 description 1
- 235000010777 Arachis hypogaea Nutrition 0.000 description 1
- 235000018262 Arachis monticola Nutrition 0.000 description 1
- 230000002411 adverse Effects 0.000 description 1
- 238000004458 analytical method Methods 0.000 description 1
- 230000006399 behavior Effects 0.000 description 1
- 230000005540 biological transmission Effects 0.000 description 1
- 238000004364 calculation method Methods 0.000 description 1
- 230000015556 catabolic process Effects 0.000 description 1
- 230000008859 change Effects 0.000 description 1
- 238000012937 correction Methods 0.000 description 1
- 230000008878 coupling Effects 0.000 description 1
- 238000010168 coupling process Methods 0.000 description 1
- 238000005859 coupling reaction Methods 0.000 description 1
- 238000013144 data compression Methods 0.000 description 1
- 238000013500 data storage Methods 0.000 description 1
- 238000006731 degradation reaction Methods 0.000 description 1
- 238000013461 design Methods 0.000 description 1
- 230000000694 effects Effects 0.000 description 1
- 230000002349 favourable effect Effects 0.000 description 1
- 238000009472 formulation Methods 0.000 description 1
- 230000005764 inhibitory process Effects 0.000 description 1
- 230000010354 integration Effects 0.000 description 1
- 238000002156 mixing Methods 0.000 description 1
- 238000009828 non-uniform distribution Methods 0.000 description 1
- 238000005457 optimization Methods 0.000 description 1
- 235000020232 peanut Nutrition 0.000 description 1
- 238000011160 research Methods 0.000 description 1
- 230000004044 response Effects 0.000 description 1
- 239000004576 sand Substances 0.000 description 1
- 238000000844 transformation Methods 0.000 description 1
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/102—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or selection affected or controlled by the adaptive coding
- H04N19/117—Filters, e.g. for pre-processing or post-processing
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/169—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding
- H04N19/17—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding the unit being an image region, e.g. an object
- H04N19/176—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding the unit being an image region, e.g. an object the region being a block, e.g. a macroblock
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/102—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or selection affected or controlled by the adaptive coding
- H04N19/119—Adaptive subdivision aspects, e.g. subdivision of a picture into rectangular or non-rectangular coding blocks
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/102—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or selection affected or controlled by the adaptive coding
- H04N19/13—Adaptive entropy coding, e.g. adaptive variable length coding [AVLC] or context adaptive binary arithmetic coding [CABAC]
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/134—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or criterion affecting or controlling the adaptive coding
- H04N19/146—Data rate or code amount at the encoder output
- H04N19/147—Data rate or code amount at the encoder output according to rate distortion criteria
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/70—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals characterised by syntax aspects related to video coding, e.g. related to compression standards
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/80—Details of filtering operations specially adapted for video compression, e.g. for pixel interpolation
- H04N19/82—Details of filtering operations specially adapted for video compression, e.g. for pixel interpolation involving filtering within a prediction loop
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/85—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using pre-processing or post-processing specially adapted for video compression
- H04N19/86—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using pre-processing or post-processing specially adapted for video compression involving reduction of coding artifacts, e.g. of blockiness
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/90—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using coding techniques not provided for in groups H04N19/10-H04N19/85, e.g. fractals
- H04N19/91—Entropy coding, e.g. variable length coding [VLC] or arithmetic coding
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/44—Decoders specially adapted therefor, e.g. video decoders which are asymmetric with respect to the encoder
Abstract
In one embodiment, a method for decoding a video bitstream comprises the steps of: (a) receiving a video bitstream; (b) deriving processed video data from the bitstream; (c) partitioning the processed video data into blocks, wherein each of the blocks is equal to or smaller than a picture; (d) deriving an SAO type from the video bitstream for each of the blocks, wherein the SAO type is associated with a specific nonbiased coding scheme; (e) determining an SAO sub-class associated with the SAO type for each of the pixels in each of the blocks; (f) deriving intensity offset from the video bitstream for the sub-class associated with the SAO type; and (g) applying SAO compensation to each of the pixels in a processed video block, wherein the SAO compensation is based on the intensity offset of step (f).
Description
Technical field
Disclosure relate generally to field of video encoding, and relate more specifically to system, device and the method for sample self adaptation skew (SAO) coding and/or signaling.
The cross reference of related application
The application requires the title submitted on November 8th, 2011 for the U.S. Provisional Patent Application of " Coding and Selectionof SAO Parameters " number 61/557,409, the title of submitting on November 14th, 2011 is the U.S. Provisional Patent Application number 61/559 of " Coding and Selection of SAO Parameters ", the title of submitting on April 25th, 714 and 2012 is the U.S. Provisional Patent Application number 61/638 of " SAOType Coding Syntax ", 480 rights and interests, it is integrally included in this by reference.
Background technology
Video compression is used piece processing for many operations.In piece is processed, the piece of neighborhood pixels is grouped into coding unit, and squeeze operation is considered as a unit to utilize the correlation between the neighborhood pixels in this coding unit by this group pixel.Block-based processing usually comprises predictive coding and transition coding.The transition coding that adopts quantification is the data compression of a type, it normally " damages ", usually abandon because take from the quantification of the transform block of source picture the data that are associated with transform block in the photo of source, thereby reduce its bandwidth requirement but usually equally reproducing original transform piece and produce mass loss from source picture.
MPEG-4AVC (being also called as H.264) is the formulation video compression standard that uses transition coding in piece is processed.In H.264, picture is divided into the macro block (MB) of 16x16 pixel.Each MB is usually become less piece by Further Division.The piece that is equal to or less than in size MB uses in frame/and inter picture prediction is predicted, and spatial alternation is together with quantizing to be applied to prediction residual.The conversion coefficient through quantizing of residual error uses entropy coding method (for example, variable length code or arithmetic coding) to encode conventionally.The set that context adaptive binary arithmetic coding (CABAC) is introduced into by making adaptive binary arithmetic coding technology and context model in H.264 combines to provide harmless substantially compression efficiency.Context model is chosen in when the adaptation that provides to a certain degree and redundancy reduce and works in CABAC.H.264 on 2D piece, specify two kinds of scan patterns.Scanning is used to the picture that utilizes gradual video compression technology coded in a zigzag, and alternative scanning is used to the picture that utilizes interlaced video compress technique coded.
Be developed to take over the international video encoding standard of HEVC (high efficiency video coding) H.264 transform block size is expanded to 16x16 and 32x32 pixel so that high definition (HD) Video coding is benefited.
Brief description of the drawings
Can partly understand by the research to accompanying drawing about its structure and both disclosure details of operation, identical Reference numeral refers to identical part in the accompanying drawings.Accompanying drawing may not be drawn in proportion, and emphasis is alternatively placed in diagram principle of the present disclosure.
Figure 1A is video system, and wherein various embodiment of the present disclosure can be used;
Figure 1B is computer system, and embodiment of the present disclosure can be implemented thereon;
Fig. 2 A, 2B, 3A and 3B illustrate according to the particular video frequency coding principle of embodiment of the present disclosure;
Fig. 4 A and 4B illustrate the possible framework for encoder according to embodiment of the present disclosure;
Fig. 5 A and 5B illustrate according to the other Video coding principle of embodiment of the present disclosure;
Fig. 6 illustrates example variable length code (VLC) signaling of edge offset/band bending (EO/BO) sampling self adaptation skew (SAO) type according to embodiment of the present disclosure;
Fig. 7 illustrates according to the example CABAC signaling of the EO/BO SAO type of embodiment of the present disclosure;
Fig. 8 illustrates the example bands skew specification according to embodiment of the present disclosure; And
Fig. 9 illustrates the exemplary architecture for the coding that is offset according to embodiment of the present disclosure.
Summary of the invention
Therefore, provide at this system and method that improves video quality by selection in sampling self adaptation skew (SAO) is processed, coding and signaling parameter.The Video processing of method and system relate generally to described herein such as video encoder and decoder.
In first aspect, method for the video bit stream with multiple pictures is decoded is provided, described bit stream is generated by video coding system utilization sampling self adaptation skew (SAO), said method comprising the steps of: (a) receiver, video bit stream; (b) obtain treated video data from described bit stream; (c) described treated video data is divided into piece, wherein, each in described is equal to or less than picture; (d) be that each described obtains SAO type from described video bit stream, wherein, described SAO type is associated without inclined to one side encoding scheme with specific; (e) for each in the pixel in each in described is determined the SAO subclass being associated with described SAO type; (f) be that the subclass being associated with described SAO type obtains intensity skew from described video bit stream; And (g) to each the application SAO compensation in the pixel in treated video block, wherein, described SAO compensation is the intensity skew based on step (f).In the embodiment of first aspect, described SAO type of coding is selected from the group being made up of one or more edge offset (EO) type and one or more band bending (BO) type.In the embodiment of first aspect, described EO type comprises at least four edge offset types.In the embodiment of first aspect, described BO type comprises at least one band bending type.In the embodiment of first aspect, the described specific binary coding scheme in each code word with at least 2 unit that is included in without inclined to one side encoding scheme being associated with described SAO type.In the embodiment of first aspect, each code word is associated with independent SAO type.In the embodiment of first aspect, described code word comprises different first modules, opens or closes to identify described SAO type.In the embodiment of first aspect, described code word further comprises different second units, is BO type or EO type to identify described SAO type.In the embodiment of first aspect, described code word further comprises different Unit the 3rd, to identify any EO type.In the embodiment of first aspect, at least one in the unit that use context adaptive binary arithmetic coding (CABAC) is encoded in described code word.In the embodiment of first aspect, different Unit the 3rd forms to identify in four EO types by two binary digits.In the embodiment of first aspect, what be associated with described SAO type described specificly comprises and each one or more mark that are associated in described SAO type of coding without inclined to one side encoding scheme.In the embodiment of first aspect, can come BO type and EO type described in signaling with SAO band designation.In the embodiment of first aspect, can carry out SAO subclass type described in signaling with SAO edge type mark.In the embodiment of first aspect, for coloud coding component can signaling described in SAO type of coding.In the embodiment of first aspect, described method is implemented in to be had processor and is coupled on the computer of memory of described processor, and wherein, at least some in step (a) to (g) are carried out with described processor.
In second aspect, equipment for the video bit stream with multiple pictures is decoded is provided, described bit stream is generated by video coding system utilization sampling self adaptation skew (SAO), described equipment comprises Video Decoder, and described Video Decoder is configured to: (a) receiver, video bit stream; (b) obtain treated video data from described bit stream; (c) described treated video data is divided into piece, wherein, each in described is equal to or less than picture; (d) be that each described obtains SAO type from described video bit stream, wherein, described SAO type is associated without inclined to one side encoding scheme with specific; (e) for each in the pixel in each in described is determined the SAO subclass being associated with described SAO type; (f) be that the subclass being associated with described SAO type obtains intensity skew from described video bit stream; And (g) to each the application SAO compensation in the pixel in treated video block, wherein, described SAO compensation is the intensity skew based on step (f).In the embodiment of second aspect, described equipment comprises with lower at least one: integrated circuit; Microprocessor; And comprise the radio communication device of described Video Decoder.In the embodiment of second aspect, described SAO type of coding is selected from the group being made up of one or more edge offset (EO) type and one or more band bending (BO) type.In the embodiment of second aspect, the described specific binary coding scheme in each code word with at least 2 unit that is included in without inclined to one side encoding scheme being associated with described SAO type.In the embodiment of second aspect, described EO type and BO type are represented by the code word of same size.
In the third aspect, provide and used sampling self adaptation skew (SAO) to thering is the method for coding video data of multiple pictures, said method comprising the steps of: (a) video data is divided into piece, wherein, each in described is equal to or less than picture; (b) be that each video data in described is selected SAO type, wherein, described SAO type is associated without inclined to one side encoding scheme with specific; (c) for each in the pixel in each in described is selected the SAO subclass being associated with described SAO type; (d) for the video data of the described subclass that is associated with described SAO type is determined intensity skew; And (e) to each the application SAO compensation in the pixel in treated video block, wherein, described SAO compensation is the intensity skew based on step (d).In the embodiment of the third aspect, described method is implemented in to be had processor and is coupled on the computer of memory of described processor, and wherein, at least some in step (a) to (e) are carried out with described processor.
Embodiment
In the disclosure, term " coding " refers to the coding occurring at encoder place or the decoding occurring at decoder place.Similarly, term code device refers to the encoder/decoder (CODEC) of encoder, decoder or combination.Term code device, encoder, decoder and CODEC all refer to the particular machine of the coding (coding and/or decoding) that be designed to video data consistent with the disclosure.
The disclosure is from the very concise and to the point summary of some terms known in digital image compression field and technology.This summary is not intended to instruct known art in any details.Skilled in the art will recognize that and how in textbook and in related standards, to find more details.
Now will the example of the video system that wherein embodiment of the present disclosure can be used be described.It should be understood that the key element that is depicted as in the drawings functional block may be implemented as hardware, software or its combination.In addition, embodiment of the present disclosure can be deployed in other system, such as on personal computer, smart phone or flat computer.
With reference to Figure 1A, video system (being usually labeled as 10) can comprise the head end 100 of cable TV network.Head end 100 can be configured to video content to be delivered to neighborhood 129,130 and 131.Head end 100 can operate in the layering of head end, and wherein in layering, higher head end usually has larger functional.Head end 100 can be linked to communicatedly satellite antenna 112 and be received the vision signal of non-local broadcast program from it.Head end 100 can also be linked to the local station 114 that local broadcast programs is delivered to head end 100 communicatedly.The receipts that head end 100 can comprise the decoder 104 of the decoding video signal to receiving from satellite antenna 112, receive local broadcast programs from local station 114 broadcast receiver 106, between the various assemblies of head end 100 routing of data traffic switch 102, to encoding video signal for being delivered to client's encoder 116, signal being modulated the modulator 118 for being delivered to client and various signal combination are become to combiner 120 single, multi-channel transmission.
Head end 100 can also be linked to composite cable (HFC) network 122 communicatedly.Hfc plant 122 can be linked to multiple nodes 124,126 and 128 communicatedly.Each in node 124,126 and 128 can be linked in neighborhood 129,130 and 131 and cable TV signal is delivered to neighborhood by coaxial cable.One of field 130 of Figure 1A is illustrated in more detail.Neighborhood 130 can comprise many houses, comprises the family 132 shown in Figure 1A.Can be the Set Top Box 134 that is linked to communicatedly video display 136 in family 132.Set Top Box 134 can comprise the first decoder 138 and the second decoder 140.The first decoder 138 and the second decoder 140 can be linked to user interface 142 and mass storage device 144 communicatedly.User interface 142 can be linked to video display 136 communicatedly.
During operation, head end 100 can receive local and non-local broadcast program video signal from satellite antenna 112 and local station 114.Can receive non-local broadcast program video signal with the form of digital video frequency flow, and that local broadcast programs vision signal can be used as analog video stream is received.In certain embodiments, it is received that local broadcast programs can also be served as digital video frequency flow.Can be decoded by decoder 104 and send to switch 102 in response to client requests digital video frequency flow.Head end 100 can also comprise the server 108 that is linked to communicatedly mass storage device 110.Mass storage device 110 can be stored various types of video contents, comprises that server 108 can retrieve and offer the video request program (VOD) of switch 102.Switch 102 can directly be routed to local broadcast programs the modulator 118 that local broadcast programs is modulated, and non-local broadcast program (comprising any VOD) is routed to encoder 116.Encoder 116 can carry out digital coding to non-local broadcast program.Then encoded non-local broadcast program can be sent to modulator 118.Combiner 120 can be configured to receive modulated analog video data and modulated digital of digital video data, composite video data and it is sent to hfc plant 122 via multiple radio frequencies (RF) channel.
Hfc plant 122 can will be sent to node 124,126 and 128 through the video data of combination, and described node 124,126 and 128 can be sent to data their corresponding neighborhoods 129,130 and 131 again.Family 132 can more specifically receive this video data at the first decoder 138 and the second decoder 140 places at Set Top Box 134 places.The first decoder 138 and the second decoder 140 can be decoded and will offer user interface 142 through the data of decoding the numerical portion of video data, and then described user interface 142 can will offer video display 136 through the data of decoding.
The encoder 116 of Figure 1A and decoder 138 and 140 (and in other step described herein and function whole) may be implemented as and comprise the computer code that is stored in the computer-readable instruction in computer readable storage means (such as the storage device of memory or another type).Computer code can be carried out by processor in computer system, the circuit of described processor such as application-specific integrated circuit (ASIC) (ASIC) or other type.For example, the upper computer code of carrying out for realizing encoder 116 of computer system (such as server) that can be resident in head end 100.On the other hand, can in Set Top Box 134, carry out the computer code for decoder 138 and 140, described Set Top Box 134 forms the computer system of a type.Code can exist as the software program that comprises program command using source code, object code, executable code or other form.Will be appreciated that for the computer code of the various assemblies shown in Figure 1A and can reside in any place of system 10 or (such as in cloud network) elsewhere, this is confirmed as desirable or favourable.In addition,, if instruction can be carried out effectively by one or more assemblies, computer code can be arranged in one or more assemblies.
Figure 1B illustrates the example that can carry out for the computer system of the computer code of encoder 116 and decoder 138 and 140 thereon.Computer system (being usually labeled as 400) comprises processor 401 or treatment circuit, and it can realize or carry out some or all the software instruction in method described herein, function and other step.For example, can communicate order and the data of carrying out self processor 401 by communication bus 403.Computer system 400 can also comprise the computer readable storage means 402 that wherein software and the data for the treatment of device 401 can be resident at run duration, such as random access memory (RAM).Storage device 402 can also comprise non-volatile data storage.Computer system 400 can comprise for being connected to network of network interface 404.Other known electronic assembly can be added or replace the assembly of describing in computer system 400.Computer system 400 can reside in head end 100 and carry out encoder 116, and can also be embodied in Set Top Box 134 to carry out decoder 138 and 140.Additionally, computer system 400 can reside in the place except head end 100 and Set Top Box 134, and can be miniaturized to be integrated in smart phone or flat computer.
Video coding system by remove redundancy in video data (for example, by remove can be dropped and adversely impact reproduce those key elements of fidelity) realize compression.Because vision signal occurs on time and space, so time redundancy and spatial redundancy that most of video coding system utilization exists in these signals.Typically, between successive frame, there is high temporal correlation.This also sets up for approximating pixel in spatial domain.Therefore, by carefully utilizing these temporal correlations to realize high compression gains.
Now in embodiment of the present disclosure, provide video data how to be able to by the senior description of encoder 116 and decoder 138 and 140 Code And Decode.In this embodiment, encoder is according to the operation of high efficiency video coding (HEVC) method.HEVC is block-based blending space and time prediction coding method.In HEVC, first input picture is divided into square block, and it is known as LCU (maximum coding unit) or CTU (code tree unit), as shown in Figure 2 A.Be other video encoding standard of the macro block of 16x16 pixel unlike basic coding unit wherein, in HEVC, LCU can be the same with 128x128 pixel large.LCU can be divided into four square blocks, and it is called CU (coding unit), and it is the big or small by 1/4th of LCU.Each CU can both be further divided into four less CU, and described less CU is the big or small by 1/4th of original CU.Dividing processing can be repeated until meet specified criteria.Fig. 3 A illustrates the example of the LCU that is divided into CU.
How specific LCU is divided into CU can be represented by quaternary tree.At each Nodes of quaternary tree, if node is further divided into child node, mark is set to " 1 ".Otherwise mark is reset " 0 ".For example, the LCU subregion of Fig. 3 A can be represented by the quaternary tree of Fig. 3 B.These " are cut apart mark " and can jointly be encoded with together with other mark in video bit stream, and described other mark comprises dancing mode mark, merging patterns mark and predicting unit (PU) mode flags etc.In the case of the quaternary tree of Fig. 3 B, cutting apart mark 10100 can be encoded as expense together with other mark.Can recursively be defined for the syntactic information of given CU, and can be depending on this CU and whether be divided into sub-CU.
Not divided CU (for example, corresponding to the CU of terminal, or " leaf " node in given quaternary tree) can comprise one or more predicting unit (PU).Generally speaking, PU represents all or part of in corresponding CU, and comprises for the data of searching PU of sampling for the object retrieving reference of CU being carried out to prediction.Therefore,, at each leaf place of quaternary tree, the last CU of 2Nx2N can have in four possible patterns (NxN, Nx2N, 2NxN and 2Nx2N), as shown in Figure 2 B.For example, although be illustrated for 2Nx2N CU, can use and there is different dimensions and corresponding pattern other PU of (, square or rectangle).CU can be spatially or upper predictive coding of time.If CU is encoded under frame mode, each PU of CU can both have its spatial prediction direction.If CU is encoded under inter-frame mode, each PU of CU can both have its (one or more) motion vector and (one or more) reference picture of being associated.The data of definition motion vector can describe grade component, the motion vector of for example motion vector vertical component, motion vector resolution (for example, / 4th pixel precisions or 1/8th pixel precisions), the reference frame of motion vector points and/or the reference listing of motion vector (for example, list 0 or list 1).The data of the CU of one or more PU of definition CU can also be described and for example CU are divided into one or more PU.Cut apart pattern can CU be whether uncoded, intra prediction mode coding or inter-frame forecast mode coding between can be different.
Generally speaking,, in intraframe predictive coding, between the contiguous block of high-grade spatial coherence in frame, exist.Therefore, can predict piece according near the piece with rebuilding of coding, thereby infra-frame prediction is occurred.In certain embodiments, prediction can be by being positioned on current block and the weighted average of the sampling of the previous coding of left part forms.Encoder can select to minimize difference between original and prediction or the pattern of cost, and controlling this selection of signaling in data.
Generally speaking, in inter prediction encoding, video sequence can have high temporal correlation between frame, and the piece in present frame can be described exactly by the region in the frame of previous coding, and the frame of described previous coding is called as reference frame.Inter prediction utilizes the reference frame with rebuilding of previous coding to use block-based estimation and compensation technique to develop prediction.
Follow infra-frame prediction or inter prediction encoding and produce prediction data and residual error data and follow any conversion (such as 4x4 or 8x8 integer transform or discrete cosine transform (DCT) used in H.264/AVC) coefficient that changes, can carry out the quantification of conversion coefficient.Quantize usually to refer to wherein conversion coefficient and be quantized the next processing that may for example reduce the data volume for representing coefficient by converting high accuracy conversion coefficient to a limited number of probable value.To discuss below these steps in more detail.
Each CU can also be divided into converter unit (TU) by application block map function.Piece map function is tending towards making the pixel decorrelation in piece and makes the low order coefficient of the compact one-tenth of piece energy transform block.In certain embodiments, can apply a conversion of 8x8 or 4x4.In other embodiments, the pieces conversion set of different sizes can be applied to CU, as shown in Figure 5 A wherein left be that to be divided into the CU of PU and right be the relation integration of converter unit (TU).The size of each conversion in CU and position are described by the independent quaternary tree that is called RQT.Fig. 5 B illustrates the Quadtrees for Representing for the TU of the CU in the example of Fig. 5 A.In this example, 11000 are encoded and transmit the part as expense.
The TU of any given CU and PU can be used to different objects.TU is typically used to conversion, quantification and encoding operation, and PU is typically used to spatial prediction and time prediction.Between the number of PU and the number of TU, may not there is direct relation for given CU.
For example, after application immediately following conversion, video block can comprise the piece of the conversion coefficient in piece or the transform domain of the pixel data in pixel domain, described conversion such as discrete cosine transform (DCT), integer transform, wavelet transformation or for given video block and the conceptive similar conversion of residual error data, the pixel between the prediction data that wherein residual error data represents to generate for the video data of piece and for this piece is poor.In some cases, video block can comprise the piece of the quantization transform coefficient in transform domain, and wherein, after for given video block, to residual error data, application converts, the conversion coefficient that result obtains is quantized equally.In Video coding, quantification is the step of introducing loss, to can set up the balance between bit rate and reconstruction quality.Will be discussed further below these steps.
Piece is segmented in block-based video coding technique and serves free-revving engine.Can produce the better prediction of data for the position of the frame of video that comprises high-grade details to coding video data with less piece, and therefore can reduce the error obtaining (for example, the deviation of prediction data and source video data) that is expressed as residual error data.Generally speaking, prediction is by utilizing space or the time redundancy in video sequence to the correlation modeling between the sampling block of various dimensions, and actual signal only and the little difference between signal through predicting need to be encoded.That sampling from being encoded creates to the prediction of current block.Although reduced potentially residual error data, but such technology may require additional syntactic information to indicate less piece how divided with respect to frame of video, and may produce the encoded video bit rate of increase.Therefore,, in some technology, piece is cut apart the increase that the result of the bit rate of the coding video frequency data that can depend on that contrast causes due to additional syntactic information obtains makes desirable reduction balance in residual error data.
Generally speaking, piece and various subregion thereof (for example, sub-block) can be considered to video block.In addition, chip (slice) can be considered to multiple video blocks (for example, macro block or coding unit) and/or sub-block (subregion of macro block, or sub-coding unit).Each chip can be the decodable unit independently of frame of video.Alternatively, frame itself can be decodable unit, or the other parts of frame can be defined as decodable unit.In addition, GOP (being also called as picture group) can be defined as decodable unit.
According to embodiment of the present disclosure, encoder 116 (Figure 1A) can be made up of some functional modules, shown in 4A.These modules may be implemented as hardware, software or both any combinations.Consider current PU, x, prediction PU, first x' can obtain by spatial prediction or time prediction.This spatial prediction or time prediction can be carried out by spatial prediction module 129 or time prediction module 130 respectively.
Existential Space prediction module 129 can be every the some possible spatial prediction direction carried out of PU, comprise grade, vertical, 45 degree diagonal, 135 degree diagonal, DC, plane etc.Comprise luminance frame internal schema, additional modes (being known as IntraFromLuma) can be used to chrominance frames inner estimation mode.The spatial prediction direction of every PU indicated in grammer.
Encoder 116 (Figure 1A) can carry out running time prediction by motion estimation operation.Particularly, time prediction module 130 (Fig. 4 A) can spread all over the prediction of reference picture search optimum Match and search current PU.Optimum Match prediction can be described with associated reference picture (refIdx) by motion vector (MV).Usually, the PU in B picture can have nearly two MV.In bit stream, MV and refIdx can be both parts for grammer.
Then can deduct prediction PU from current PU, produce residual error PU, e.Residual error PU, then e can be transformed module 117 1 next converter unit (TU) conversion, produces the residual error PU in transform domain, E.In order to realize this task, conversion module 117 can use for example square or non-square block conversion.
Back, with reference to figure 4A, then conversion coefficient E can be quantized device module 118 and quantize, thereby converts high accuracy conversion coefficient to a limited number of probable value.Quantification treatment can reduce and some or all bit depth that are associated in coefficient.For example, n-place value can be m-place value by round down during quantizing, and wherein n is greater than m.In certain embodiments, external boundary condition is used to produce one or more conversion coefficients of amendment.For example, can be determining whether conversion coefficient is endowed nonzero value or only uses lower scope or value when zero setting.As should be understood, quantification is to damage operation and usually can not recover the loss causing by quantizing.
Then can be coded by entropy module 120 entropy codings through the coefficient quantizing, thereby produce final compressed-bit.The particular step of being carried out by entropy coding module 120 will be discussed in more detail below.
For the ease of time prediction and spatial prediction, encoder 116 can also obtain the conversion coefficient E through quantizing and spend quantizer module 122 and make them go to quantize, thereby produces the conversion coefficient E' quantizing through going.Through going the conversion coefficient quantizing to be then inversely transformed module 124 inverse transformations, produce the residual error PU through rebuilding, e'.Through the residual error PU rebuilding, that then e' is added to corresponding prediction x'(space or the time), to form the PU of reconstruction, x ".
Still with reference to figure 4A, can " carry out block elimination filtering (DBF) operation to reduce blocking effect first to the PU through rebuilding, x.Can process for carrying out conditionally sampling self adaptation skew (SAO) after completing block elimination filtering processing through the picture of decoding, it compensates the pixel value skew between pixel and the original pixels rebuild.In certain embodiments, DBF operation and SAO process and are both realized by auto-adaptive loop filter function, and described auto-adaptive loop filter function can be carried out by loop filter module 126 conditionally on the PU through rebuilding.In certain embodiments, the coding distortion of auto-adaptive loop filter function minimization between input picture and output picture.In certain embodiments, loop filter module 126 is in inter picture predictive loop manipulate.If be reference picture through the picture of rebuilding, they can be stored in reference buffer 128 for time prediction in the future.
HEVC specifies two loop filters, and the order that first it applied with block elimination filtering (DBF) and self adaptation skew (SAO) filtering of sampling was applied is afterwards employed.DBF is similar to by the DBF that H.264/MPEG-4AVC used, but has better simply design and better support for parallel processing.In HEVC, DBF is only applicable to 8x8 sampling grid, and DBF is applicable to 4x4 sampling grid in situation H.264/MPEG-4AVC.DBF uses 8x8 sampling grid, because it does not cause significant degradation and improve significantly parallel processing, mutual because DBF no longer causes with the cascade of other operation.Another change is that HEVC only allows three DBF intensity of 0 to 2.HEVC requires DBF first for the perpendicular edge application level filtering of picture and only after that for the grade limit application vertical filtering of picture equally.This allows multiple parallel threads to be used to DBF.
SAO filtering is processed and after DBF, is employed and is caught by using for example look-up table to allow the better reconstruction of original signal amplitude, and described look-up table comprises some parameters of the histogram analysis based on being made by encoder.SAO filtering has two fundamental types for edge offset (EO) type and band bending (BO) type.Each code tree piece (CTB) can both be applied in SAO type.Edge offset (EO) type for example, has and processes four corresponding subtypes along four possible directions (, grade, vertical, 135 degree and 45 degree).For given EO subtype, edge offset (EO) is processed by pixel value being compared to operate with in its neighbours two with one in four different gradient pattern.Skew is applied to the pixel in each in four gradient pattern.For the pixel value in gradient pattern not, skew is not employed.It is the amplitude of samples based on being divided into 32 frequency bands directly that band bending (BO) is processed.Skew is applied to the pixel in 16 in 32 frequency bands, and wherein one group of 16 frequency band is corresponding to BO subtype.SAO filtering processing is designed to reduce the distortion compared with primary signal by skew being added to sampled value.It can improve limit acutance and reduce ring-type and pulse effects.Be discussed below the further details of processing about SAO with reference to Fig. 6-9.
In embodiment of the present disclosure, in frame, picture (such as I picture) and inter picture (such as P picture or B picture) are supported by encoder 116 (Figure 1A).Can be need not be with reference to other picture in the situation that to frame in picture encode.Therefore, spatial prediction can be used to the CU/PU of picture inside in frame.What picture provided that wherein decoding can start in frame may point.On the other hand, inter picture is usually for high compression.Inter picture is supported infra-frame prediction and inter prediction.CU/PU in frame in picture is by spatially or upper predictive coding of time.Time reference is in the frame of previous coding or inter picture.
Now will the operation of the entropy coding module 120 (Fig. 4 A) according to embodiment be described in more detail.Entropy coding module 120 adopts the quantization matrix of the coefficient receiving from quantizer module 118 and generates and represent the sign matrix of the whole symbol quantization parameter and generate effective bitmap with it.Effectively bitmap can be the matrix of (one or more) non-zero quantized coefficients (one or more) position of each element assignment in quantization parameter matrix wherein.Particularly, the 2D transformation matrix of given quantification, if the value of locating quantization parameter at position (y, x) is non-zero, it can be considered to effectively and distribute " 1 " for the position (y, x) in associated effective bitmap.Otherwise " 0 " is assigned to the position (y, x) in effective bitmap.
Once entropy coding module 120 has created effective bitmap, it just can be encoded to this effective bitmap.In one embodiment, this realizes based on contextual adaptive binary arithmetic coding (CABAC) technology by using.In doing so, entropy coding module 120 scans effective bitmap along scan line, and for the each entry in effective bitmap, and coding module is chosen context model for this entry.The entropy coding module 120 then context model based on selected is encoded to entry.That is to say the context model (mathematics probabilistic model) of each entry based on just being used and distributed probability.Probability is accumulated until whole effective bitmap is encoded.
Symbol, effectively bitmap and the nonzero coefficient of the value of being exported by entropy coding module 120 and entropy coding can be inserted in bit stream by encoder 116 (Figure 1A).Can this bit stream be sent to decoder 138 and 140 by hfc plant 122.
It should be noted, depend on specified coding standard, can for example, carry out prediction described above, conversion and quantification for any of video data (, the PU to CU and/or TU, or to macro block).
In the time that decoder 138 and 140 (Figure 1A) receives bit stream, they carry out for example function shown in Fig. 4 B.The entropy decoder module 146 of decoder 145 can decode to re-create the coefficient through quantizing and converting to value of symbol, effectively bitmap and nonzero coefficient.In the time that effective bitmap is decoded, entropy decoder module 146 can carry out in conjunction with entropy coding module 120 described processes contrary-along the scan pattern being formed by scan line, effective bitmap is decoded.Then entropy decoder module 146 can offer coefficient quantizer module 147, described in go quantizer module 147 make the matrix of coefficient go quantize, thereby produce E'.Go quantization modules 147 will offer inverse transform module 149 through the coefficient that goes quantification.Thereby inverse transform module 149 can be carried out inverse transformation operation to coefficient and produce e'.Can be with in conjunction with Fig. 4 A described mode application filtering and spatial prediction.
Sampling self adaptation skew (SAO)
In SAO processes, skew is added to each pixel to reduce pixel through rebuilding with respect to the distortion of original pixels.In one embodiment, for the subregion in brightness or chromatic component, pixel is categorized into one (type and subtype are both jointly called type) in six possible types here by encoder: four edge offset (EO) type E0, E1, E2, E3 and two band bendings (BO) type B 0, B1.For EO type, the local behavior of pixel based on along EO type direction and become in five possible subclasses by further disaggregated classification.For BO type, pixel is become in 16 possible subclasses based on intensity by further disaggregated classification.In certain embodiments, for the given subclass of the pixel in SAO type, applied identical skew.For example,, if the skew of subclass i is o
i, with p
ithe corresponding SAO of input output will be p
i+ o
i.Encoder typically selects the SAO type of every subclass to minimize cost function.For example,, if given type t and offset collection o
t,idistortion be D
t,iand corresponding bit rate is R
t,i, cost function can be J
t,i=D
t,i+ λ * R
t,i, wherein λ is weighted factor.Encoder can be to the corresponding skew of the SAO type of the every subregion of decoder signaling and every subclass, and decoder every subclass of skew can carry out classification and each pixel be applied to to(for) this SAO type.Can every chrominance component signaling SAO type, or given type can be sent out signaling and for more than one chrominance component.In certain embodiments, encoder can not use or turn off SAO equally, and it can also be by signaling to decoder.
The coding of SAO type
For the coding of SAO type, usually there are two coding methods: high efficiency (HE) and low-complexity (LC).In LC, variable length codeword (VLC) or binaryzation code word are assigned to SAO type; And in HE, typically distributing to after the binaryzation code word of type is based on contextual adaptive binary arithmetic coding (CABAC).For HE situation, encoder can carry out signaling SAO type with monobasic code, for example as shown in table 1 go out (0 and 1 can be exchanged):
Table 1
SAO type | Code |
Close | 0 |
E0 | 10 |
E1 | 110 |
E2 | 1110 |
E3 | 11110 |
B0 | 111110 |
B1 | 1111110 |
In table 1, when SAO type is while closing, do not have SAO to be employed and corresponding code word is 0.Other code word is corresponding to other EO and BO type.
Can notice, the unit in code word or numeral can be called as " position " for LC, and are called as " bit " for HE.The difference of term is the result to code word application CABAC in HE method.As used in this article, in code word " unit " comprise bit and position both.
Note for the assignment of code of table 1, can remove last in code 0 to obtain code 111111, because known that it is last possible SAO type for SAO B1.In addition, because BO type compared with long code word, so can select be partial to partially band bending type (B0 and B1) for the rate distortion in best type (RD).This deflection can be the result than another skew type with the particular offset type of longer code word size.
Therefore, in certain embodiments, the alternative assignment of code for signaling SOA type has been shown in table 2:
Table 2
SAO type | Code |
Close | 0 |
E0 | 1000 |
E1 | 1001 |
E2 | 1010 |
E3 | 1011 |
B0 | 110 |
B1 | 111 |
In table 2, if the first binary digit in two inhibition and generation of code word or bit is 0, SAO type is close and do not have SAO to be employed.Otherwise, the first bit be 1 and EO or BO by signaling.If the second bit is 0, EO type is by signaling; Otherwise, the second bit be 1 and BO type by signaling.For the situation of EO, two other bit by signaling to indicate in four EO types, and for the situation of BO, another one bit by signaling to indicate in two BO types.This assignment of code is given and is given more fair position weight for different SAO types, because the code word size in EO and BO type is uniformly, means that encoding scheme is without inclined to one side between different SAO types.And this code word binaryzation allows for closing, the better probabilistic Modeling of EO and BO type.
For low-complexity (LC) situation, encoder can carry out signaling SAO type with coulomb code index, for example as shown in table 3 go out (0 and 1 can be exchanged):
Table 3
SAO type | Code |
Close | 1 |
E0 | 010 |
E1 | 011 |
E2 | 00100 |
E3 | 00101 |
B0 | 00110 |
B1 | 00111 |
The alternative code that identical code word size is given to all EO types (E0, E1, E2, E3) has been shown in table 4:
Table 4
SAO type | Code |
Close | 1 |
E0 | 00100 |
E1 | 00101 |
E2 | 00110 |
E3 | 00111 |
B0 | 010 |
B1 | 011 |
Note, can exchange the code word of EO type (or BO type).Equally can by with as with as shown in table 5 go out the similar code of HE situation realize than the more efficient code shown in table 4.
Table 5
SAO type | Code |
Close | 1 |
E0 | 0000 |
E1 | 0001 |
E2 | 0010 |
E3 | 0011 |
B0 | 010 |
B1 | 011 |
Alternatively, in certain embodiments, the same code in HE can be used to LC.For example, in each code word first exchanged, table 5 is similar to table 2.In table 5, if first is 1, SAO type is close and do not have SAO to be employed.Otherwise, first be 0 and EO or BO be sent out signaling.If second is 0, EO type is sent out signaling; Otherwise, second be 1 and BO type be sent out signaling.For the situation of EO, two other is sent out signaling to indicate in four EO types, and for the situation of BO, another one position is sent out signaling to indicate in two BO types.Except using in HE and LC identical code word, some in the binary digit in code word can use CABAC (as in HE) or in the situation that there is no CABAC (as in LC) processed.
In certain embodiments, a position can be used to the difference (for example, position=0 signaling EO type, and position=1 signaling BO type) between signaling EO type and BO type, as shown in the example in table 2-5.
In certain embodiments, may be greater than or less than the number of EO and/or BO type, as shown at above-mentioned table.For example, for the situation of four EO types and a BO type, for LC, this can be sent out signaling, as shown in Figure 6.It is not the sequence of closing position afterwards that Fig. 6 is shown in signaling SAO.Can carry out for each chrominance component this sequence of signaling position, or type can be used to more than one chrominance component (for example, brightness or the first colourity or the second chromatic component).In Fig. 6, if first is 1, BO is sent out signaling.Otherwise first is 0 and with carrying out in four EO types of signaling in two additional positions.
When sending when signaling for chrominance component, can (possibility) repeat to send signaling for each in three chrominance components.Alternatively, identical parameter can be used to more than one chrominance component.
Still in other embodiments, can use sao_band mark (for example, 1) to carry out signaling EO/BO type, wherein SAO type is BO and in the time that sao_band equals 0, is EO in the time that sao_band equals 1.Can use sao_edge_type (for example, 2) to carry out signaling SAO EO type.Encode for CABAC, (for example can also use its specific context, every chrominance component) carry out signaling EO/BO type with sao_band mark, and can use and there is a context monobasic binaryzation of (for example, every chrominance component) is encoded to EO type.The example of this figure 7 illustrates.
In certain embodiments, can use VLC (LC) and CABAC (HE) shown in table 6 and 7 to specify for the grammer of sao_band and sao_edge_type:
Table 6
sao_offset_vlc(rx,ry,cIdx){ | Descriptor |
sao_band[cIdx][rx][ry] | u(1) |
if(sao_band[cIdx][rx][ry]){ | |
… | … |
}else{ | |
sao_edge_idx[cIdx][rx][ry] | u(2) |
… | … |
} | |
} |
Table 7
sao_offset_cabac(rx,ry,cIdx){ | Descriptor |
sao_band[cIdx][rx][ry] | ae(v) |
if(sao_band[cIdx][rx][ry]){ | |
… | … |
}else{ | |
sao_edge_idx[cIdx][rx][ry] | ae(v) |
… | … |
} | |
} |
As presented in table 6 and 7, equaling 1 syntactic element sao_band[cIdx] [rx] [ry] assigned frequency band skew (BO) sampling self adaptation migration processing is applied to chrominance component cldx and sets piece in the present encoding at position rx and ry place.By contrast, equaling 0 syntactic element sao_band[cIdx] [rx] [ry] designated edge skew (EO) sampling self adaptation migration processing is applied to chrominance component cldx and sets piece in the present encoding at position rx and ry place.In certain embodiments, sao_edge_idx[cIdx] [rx] [ry] instruction for chrominance component cldx one in four EO directions (subtype or class) of the current SAO unit at position rx and ry place.In table 6 and 7, u () represents that monobasic binary conversion treatment and ae () represent the processing of CABAC arithmetic coding.In certain embodiments, the combination of VLC (LC) and CABAC (HE) can be used to syntactic element to encode.
In certain embodiments, can from contiguous CTU SAO parameter (such as from current C TU or the neighbours of left part) infer the SAO parameter such as sao_band and sao_edge_idx.Whether can signaling mark carry out indication parameter infers from particular neighbor.In certain embodiments, sao_band and sao_edge_idx can be encoded with signaling to the decoder that uses CABAC.
As disclosed herein, can realize improvement for the coding of SAO parameter for carrying out Code And Decode to being provided for the more SAO type of efficient signaling (for example,, in Table 2-5) by code word.Additional improvement can comprise: can be better with the quantification of the skew of some distribution of offsets couplings, how to specify single band bending type, how in the time there is many gap classes efficiently to being the rate-distortion optimisation that useful skew is encoded and is offset.
The quantification of skew
For example, as described above, the selection of SAO type/parameter allows skew to be applied to each pixel to improve the quality of the image through rebuilding.Current, the skew of every subclass is confirmed as the average distortion of every pixel.That is to say, the total distortion d of every subclass is the number n divided by pixel in such, or d/n.With specifying distortion and deviant d/n to be rounded off to emplacement depth precision, for example, deviant o=round (d/n).Then deviant o can be tailored to minimum value and maximum, for example [min, max].
In certain embodiments, amendment can comprise that blocking deviant o replacement rounds off, for example, o=int (d/n), wherein o retains integer value.
In other embodiments, amendment can comprise quantification deviant o.Generally speaking, can use the nonlinear quantization of (one or more) offset level (x) that can distribute near weight exists the place of larger generation of skew.In one embodiment, can in the time determining offset level, use equal interval quantizing, for example, x=round (o/ scale), wherein scale is that parameter and the round () of the grade of control quantification are the operations of rounding off to nearest integer.Offset level x can be by signaling to decoder, and decoder can be carried out contrary calibration to generate the deviant o'=scale * x through rebuilding.If scale is greater than one, for the reconstruction grade of given number, can generate than be less than or equal to for the moment wider reconstruction offset value in scale.Alternatively, this can be contained and require less position to encode to skew with the skew that allows given range compared with the offset level of peanut.
As understood, quantification is to damage operation, thereby causes the reduction of precision.Although can reduce the precision of skew, the quantification of deviant can be closer and statistic and the commensurate in scope of data.For example, be the unitary Item QP value (for example, low bitrate) damaging very much for coding wherein, it may be useful being greater than one scale value, because can carry out the larger error in correction pixels value by larger deviant.
In certain embodiments, the another way of effective quantification that is used for realizing skew is to use x=round (d/ (n* scale)).Here, can be determined to decoder and for example every subclass, type, subregion, LCU, chip (or other unit), picture, picture group or sequence by signaling for the scale value quantizing.Can in encoder, send or agree to maximum scale value (or skew) for code efficiency object and/or fault-tolerant object.For example, and mark can be used to refer to and be shown in whether scale value under some grades (LCU, chip or picture) is one, and if it be not one, can transmit it.
As explained above, rate distortion (RD) performance can be mated and improve to the quantification of skew better with the distribution of offset data.In the linear optimization of all skews as described above, offset level can be calculated by x=round (d/ (n* scale)), wherein d is the total distortion in subclass, and n is the number of pixel in subclass, and scale is to control the parameter of the step sizes quantizing.Can be calculated as o'=x* scale at both places of encoder at encoder place cutting offset level x and through the deviant of rebuilding.
For the non-homogeneous or nonlinear quantization of skew, the interval quantizing between deviant needs not be uniform.For example, offset level can be passed through x=f (d, n, scale,) calculate, wherein f () is certain function, and can pass through o'=g (x through the deviant of rebuilding, scale ...) calculate, wherein g () is certain function.Especially, allow x'=round (d/ (n* scale)) become Input Offset Value.In the time of scale=1, if b
i<=x'<=B
ireconstruction offset grade x can be set to x=i, wherein I
min<=i<=I
max, and can be confirmed as o'=g (x=i)=v through the deviant o' rebuilding
i.Value b
iand B
irepresent lower quantization boundary and the upper quantization boundary of reconstruction offset grade i, and v
irepresent the deviant through rebuilding.At b
i, B
ibetween and at v
ibetween interval need not be uniform.In one example, work as I
max=-I
min=6 o'clock, in the time of x'>=0, b
0=0, B
0=0, b
1=1, B
1=1, b
2=2, B
2=2, b
3=3, B
3=5, b
4=6, B
4=11, b
5=12, B
5=23, b
6=24, B
6=255, and in the time of x'<0, b
-6=-255, B
-6=-24, b
-5=-23, B
-5=-12, b
-4=-11, B
-4=-6, b
-3=-5, B
-3=-3, b
-2=-2, B
-2=-2, b
-1=-1, B
-1=-1.For this situation, the deviant quantity through rebuilding can be set to v during at i>=0
0=0, and in the time of i>0 v
i=2^ (i-1).For the negative value of offset level i, have and grade through the deviant of rebuilding | the equal number that i| is corresponding, and identical with the symbol of offset level i through the symbol of deviant of rebuilding.
For this sample table 8 and 9 diagram reconstruction offset grade i, quantization boundary b
iand B
iand the deviant v rebuilding
i.
Table 8
i | 0 | 1 | 2 | 3 | 4 | 5 | 6 |
b i | 0 | 1 | 2 | 3 | 6 | 12 | 24 |
B i | 0 | 1 | 2 | 5 | 11 | 23 | 255 |
v i | 0 | 1 | 2 | 4 | 8 | 16 | 32 |
Table 9
i | -6 | -5 | -4 | -3 | -2 | -1 |
b i | -255 | -23 | -11 | -5 | -2 | -1 |
B i | -24 | -12 | -6 | -3 | -2 | -1 |
v i | -32 | -16 | -8 | -4 | -2 | -1 |
Because above-mentioned paragraph has presented example, so will be appreciated that, the quantization parameter value b that existence can be selected
i, B
iand v
iother combination.For the offset level of given number, non-uniform Distribution can provide better rate distortion balance for the scope of skew.Different values can be used to different sequences, credit rating, bit rate etc.And, can be different for various SAO type quantification parameters.For example, for EO type, can use uniform quantization, and for BO type, non-uniform quantizing may be applicable to.In addition, can choose different quantized values for the scope of different deviants.For example, little (quantity) deviant can be used the uniform quantization with given scale value, and larger deviant can be used non-uniform quantizing or the uniform quantization with another scale value.
The merging of B0 and B1
In certain embodiments, SAO uses two the fixed frequency band type B 0 and the B1 that cover whole strength range, and wherein each frequency band is further divided into corresponding strength range 16 equal subclasses.Can carry out signaling skew for each in subclass.Because the statistic of given picture can fall into one of two existing band type B0 and B1 inexactly, so can preferred compositions or merging frequency band.In certain embodiments, can use a band type, wherein for example use even son to cut apart, can specify the scope of the value of application skew, and can specify the number for the subclass of this scope.In Fig. 8, illustrate the such example of cutting apart that uses single band type.
In certain embodiments, can consider to determine the wherein scope of the value of application skew based on data and based on rate distortion.Skew usually can be applied to the value that wherein distortion can be lowered.
In certain embodiments, such as in the time there is single band type and there is no other SAO type, do not need to carry out SAO Selective type.In such example, single band type is not in the case of being used the additional step of selecting to be associated with SAO.
As shown in Figure 8, the beginning of frequency band is by b
sspecify, and can use width w
sn
sindividual subclass.Fig. 8 illustrates wherein equal wide (w
s) four (N
s=4) embodiment that subclass is adjoined each other, wherein the first subclass is at b
splace starts.In this case, can be for four subclasses to four skews of decoder signaling.In one example, if last subclass exceedes maximum intensity scope, last subclass can finish at maximum place or rap around to zero.
Alternatively, can be at decoder and/or the appointment of decoder place and agreement b
s, N
sand/or w
sthe fixed set of value.In such embodiments, only some parameters (for example, unspecified value) may need to be sent to decoder from encoder.For example, these parameters can be by signaling to decoder and can be determined for such as every subregion, LCU, chip (or other unit), picture, picture group, sequence etc.In other embodiments, specify the identical processing of single frequency band can specify more than one frequency band by being recycled and reused for.
In certain embodiments, b
sbe sent to decoder from encoder.In certain embodiments, N
sbe sent to decoder from encoder.In certain embodiments, w
sbe sent to decoder from encoder.
The coding of skew
In certain embodiments, for existing B0 and B1 band bending type and/or for the band bending type of single merging, in corresponding strength range, can exist and there is no many subclasses of pixel (for example, being also called as gap class).Although can encode to these subclasses with zero offset, in certain embodiments, be only encoded and send signaling for the deviant of those classes with pixel intensity value.Such coding with the subclass of pixel intensity value can be by additionally encoding and realize with signaling deviant no longer escape code or skew end code.This escape code can be the value that is for example greater than peak excursion value used.This method may be useful in the time there is many gap classes; But, do not exist therein in the situation of many gap classes, can realize only to thering is the combination that the subclass of intensity pixel value is encoded and encode to having the subclass of zero offset.The signaling that the method can be used to the skew in band bending and edge offset type sends.For the situation of edge offset type, gap class is corresponding to the situation that does not wherein have the pixel with corresponding gradient pattern.
As understood, decoder receives the information about all types of band bending specification as shown in Figure 8 in one embodiment.Decoder will be categorized into subclass through the pixel value of rebuilding according to their intensity.In the time that decoder receives the sequence of deviant, each subclass is distributed in skew by the place that it can be present in subclass according to pixel intensity.
In certain embodiments, wherein do not exist the subclass of pixel intensity will not allow skew by signaling.This is illustrated as example by Fig. 9.Fig. 9 illustrates the example of the BO with eight subclass 0-7.Can use previous described method to the position of eight subclasses of decoder signaling or the scope of pixel amplitudes.In this example, only in subclass 1 and 6, there is pixel intensity, and do not have pixel intensity in subclass 0,2,3,4,5 and 7.So class is below empty and does not need signaling skew.Can the deviant 2 of signaling subclass 1 and deviant-1 of subclass 6, after be the optional escape value of no longer signaling deviant.If escape value is not sent out signaling, suppose that decoder carries out pixel before deviant and be categorized into subclass resolving.After decoder receives and specifies the information of BO subclass by all methods as described earlier, it can be classified to pixel intensity.After pixel intensity is classified, decoder is distributed to the first deviant 2 the first non-NULL subclass 1 and the second non-NULL subclass 6 is distributed to in the second deviant-1.
The rate-distortion optimisation of skew
As discussed above, if for the skew (o of given type t and class i
t,i) distortion between initial data and data reconstruction is D
t,iand transmit o
t,idesired corresponding position is R
t,i, can be J to distortion and a corresponding cost function that both are weighted
t,i=D
t,i+ λ * R
t,i, wherein λ is Lagrangian weighted factor.For given type t and subclass i, optimized migration o
t,ican selectedly fetch and minimize cost J
t,i.This optimized migration for given type and subclass can have minimum cost value J by the calculations of offset cost function for difference possible and selection
t,iskew determine.
In certain embodiments, can choose initial offset, and the scope that then can search near the skew this initial offset is to obtain least cost.For example, initial offset can be set to one of minimal distortion only, and then can check that additional skew is for minimizing cost.The scope of the skew of searching in certain embodiments, comprises those skews that are less than initial offset.Will be appreciated that the search that minimizes cost can spread all over deviant or offset level, and given offset level is corresponding to deviant.
As described above, have four possible EO type or classes, and there are five possible subclasses in every type.As used herein, EO type or class refer to along pixel wherein processed direction, and subclass refers to pixel value according to the classification of the gradient pattern along EO type or class direction.In certain embodiments, the number of EO subclass can be expanded as nine subclasses altogether, and wherein each pixel depends on that it is noly less than, equals or be greater than along two neighborhood pixels by EO type or the indicated direction of class and be classified.
For example, although will be appreciated that the number of EO subclass is described to comprise nine, can use any applicable increase number (, being greater than five).Because the subclass of additional number, so more skews may need to be sent to decoder.Although may need to send more skews for additional subclass, the reduction of distortion can reduce overall cost and improve performance.
As described in this article, comprise signaling EO and BO type, the quantification of skew, the specification of BO parameter and coding and the rate-distortion optimisation being offset for the coding of SAO parameter and some improvement of selection.
The foregoing description of the disclosed embodiments is provided to make any technical staff of this area can make or use the disclosure.To be apparent to this in those skilled in the art for the various amendments of these embodiment, and general principle described herein can be applied to other embodiment and not deviate from spirit or scope of the present disclosure.Therefore, should be understood that, the description that presented herein and accompanying drawing represent exemplary embodiment of the present disclosure, and therefore represent the theme being susceptible to widely by the disclosure.Should further be appreciated that the scope of the present disclosure fully comprises other embodiment, and the scope of the present disclosure is not limited by thing except as by the appended claims therefore.
Claims (23)
1. the method for the video bit stream with multiple pictures is decoded, described bit stream is generated by video coding system utilization sampling self adaptation skew (SAO), said method comprising the steps of:
(a) receiver, video bit stream;
(b) obtain treated video data from described bit stream;
(c) described treated video data is divided into piece, each in wherein said is equal to or less than picture;
(d) be that each described obtains SAO type from described video bit stream, wherein said SAO type is associated without inclined to one side encoding scheme with specific;
(e) for each pixel in piece described in each is determined the SAO subclass being associated with described SAO type;
(f) be that the described subclass being associated with described SAO type obtains intensity skew from described video bit stream; And
(g) to each the pixel application SAO compensation in treated video block, the intensity skew of wherein said SAO compensation based on step (f).
2. method according to claim 1, wherein, described SAO type of coding is selected from the group being made up of one or more edge offset (EO) type and one or more band bending (BO) type.
3. method according to claim 2, wherein, described EO type comprises at least four edge offset types.
4. method according to claim 2, wherein, described BO type comprises at least one band bending type.
5. method according to claim 2, wherein, the described specific binary coding scheme in each code word with at least 2 unit that is included in without inclined to one side encoding scheme being associated with described SAO type.
6. method according to claim 5, wherein, each code word is associated with independent SAO type.
7. method according to claim 6, wherein, described code word comprises different first modules, opens or closes to identify described SAO type.
8. method according to claim 7, wherein, described code word further comprises different second units, is BO type or EO type to identify described SAO type.
9. method according to claim 8, wherein, described code word further comprises different Unit the 3rd, to identify any EO type.
10. method according to claim 5, wherein, at least one in the unit that use context adaptive binary arithmetic coding (CABAC) is encoded in described code word.
11. methods according to claim 9, wherein, different Unit the 3rd forms to identify in four EO types by two binary digits.
12. methods according to claim 2, wherein, what be associated with described SAO type described specificly comprises and each one or more mark that are associated in described SAO type of coding without inclined to one side encoding scheme.
13. methods according to claim 12, wherein, can come BO type and EO type described in signaling with SAO band designation.
14. methods according to claim 12, wherein, can carry out SAO subclass type described in signaling with SAO edge type mark.
15. methods according to claim 2, wherein, for coloud coding component can signaling described in SAO type of coding.
16. methods according to claim 1, wherein, described method is implemented in to be had processor and is coupled on the computer of memory of described processor, and wherein, at least some in step (a) to (g) are carried out with described processor.
17. 1 kinds of equipment for the video bit stream with multiple pictures is decoded, described bit stream is generated by video coding system utilization sampling self adaptation skew (SAO), and described equipment comprises Video Decoder, and described Video Decoder is configured to:
(a) receiver, video bit stream;
(b) obtain treated video data from described bit stream;
(c) described treated video data is divided into piece, wherein, each in described is equal to or less than picture;
(d) be that each described obtains SAO type from described video bit stream, wherein said SAO type is associated without inclined to one side encoding scheme with specific;
(e) for each pixel in piece described in each is determined the SAO subclass being associated with described SAO type;
(f) be that the subclass being associated with described SAO type obtains intensity skew from described video bit stream; And
(g) to each the pixel application SAO compensation in treated video block, the intensity skew of wherein said SAO compensation based on step (f).
18. equipment according to claim 17, wherein, described equipment comprises with lower at least one:
Integrated circuit;
Microprocessor; And
Comprise the radio communication device of described Video Decoder.
19. equipment according to claim 17, wherein, described SAO type of coding is selected from the group being made up of one or more edge offset (EO) type and one or more band bending (BO) type.
20. equipment according to claim 17, wherein, the described specific binary coding scheme in each code word with at least 2 unit that is included in without inclined to one side encoding scheme being associated with described SAO type.
21. equipment according to claim 20, wherein, described EO type and BO type are represented by the code word of same size.
22. 1 kinds use sampling self adaptation skew (SAO) to having the method for coding video data of multiple pictures, said method comprising the steps of:
(a) video data is divided into piece, each in wherein said is equal to or less than picture;
(b) be that the video data of piece described in each is selected SAO type, wherein said SAO type is associated without inclined to one side encoding scheme with specific;
(c) the SAO subclass being associated with described SAO type for each pixel selection in piece described in each;
(d) for the video data of the described subclass that is associated with described SAO type is determined intensity skew; And
(e) to each the application SAO compensation in the pixel in treated video block, the intensity skew of wherein said SAO compensation based on step (d).
23. methods according to claim 22, wherein, described method is implemented in to be had processor and is coupled on the computer of memory of described processor, and wherein, at least some in step (a) to (e) are carried out with described processor.
Applications Claiming Priority (9)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201161557409P | 2011-11-08 | 2011-11-08 | |
US61/557,409 | 2011-11-08 | ||
US201161559714P | 2011-11-14 | 2011-11-14 | |
US61/559,714 | 2011-11-14 | ||
US201261638480P | 2012-04-25 | 2012-04-25 | |
US61/638,480 | 2012-04-25 | ||
US13/672,476 US9774853B2 (en) | 2011-11-08 | 2012-11-08 | Devices and methods for sample adaptive offset coding and/or signaling |
PCT/US2012/064208 WO2013070955A2 (en) | 2011-11-08 | 2012-11-08 | Devices and methods for sample adaptive offset coding and/or signaling |
US13/672,476 | 2012-11-08 |
Publications (2)
Publication Number | Publication Date |
---|---|
CN104094601A true CN104094601A (en) | 2014-10-08 |
CN104094601B CN104094601B (en) | 2018-01-19 |
Family
ID=48223672
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201280054893.7A Active CN104094601B (en) | 2011-11-08 | 2012-11-08 | Apparatus and method for sampling adaptive skew coding and/or signaling |
CN201280054971.3A Active CN104221373B (en) | 2011-11-08 | 2012-11-08 | The apparatus and method notified for sample adaptive skew code and/or signal |
Family Applications After (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201280054971.3A Active CN104221373B (en) | 2011-11-08 | 2012-11-08 | The apparatus and method notified for sample adaptive skew code and/or signal |
Country Status (6)
Country | Link |
---|---|
US (2) | US9774853B2 (en) |
EP (2) | EP2777272B1 (en) |
KR (2) | KR101674777B1 (en) |
CN (2) | CN104094601B (en) |
BR (2) | BR112014011149A2 (en) |
WO (2) | WO2013070960A2 (en) |
Cited By (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN109644274A (en) * | 2016-08-30 | 2019-04-16 | 交互数字Vc控股公司 | Utilize the method and apparatus for the video coding that sample adaptively deviates |
CN113382257A (en) * | 2021-04-19 | 2021-09-10 | 浙江大华技术股份有限公司 | Encoding method, encoding device, electronic equipment and computer readable storage medium |
Families Citing this family (53)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
EP2724534A2 (en) | 2011-06-24 | 2014-04-30 | Motorola Mobility LLC | Selection of phase offsets for interpolation filters for motion compensation |
JP5727673B2 (en) | 2011-07-01 | 2015-06-03 | モトローラ モビリティ エルエルシーＭｏｔｏｒｏｌａ Ｍｏｂｉｌｉｔｙ Ｌｌｃ | Joint subpixel interpolation filter for temporal prediction |
US9277194B2 (en) | 2011-11-08 | 2016-03-01 | Texas Instruments Incorporated | Method and apparatus for image and video coding using hierarchical sample adaptive band offset |
EP2777272B1 (en) | 2011-11-08 | 2019-01-09 | Google Technology Holdings LLC | Devices and methods for sample adaptive offset coding and/or signaling |
WO2013103892A1 (en) | 2012-01-05 | 2013-07-11 | General Instrument Corporation | Devices and methods for sample adaptive offset coding and/or selection of edge offset parameters |
WO2013103893A1 (en) | 2012-01-05 | 2013-07-11 | General Instrument Corporation | Devices and methods for multipass sample adaptive offset coding |
WO2013109879A1 (en) * | 2012-01-19 | 2013-07-25 | Cisco Technology Inc. | Digital video compression system, method and computer readable medium |
KR20160118365A (en) | 2012-02-06 | 2016-10-11 | 노키아 테크놀로지스 오와이 | Method for coding and an apparatus |
US9591331B2 (en) * | 2012-03-28 | 2017-03-07 | Qualcomm Incorporated | Merge signaling and loop filter on/off signaling |
ES2637166T3 (en) * | 2012-04-05 | 2017-10-11 | Telefonaktiebolaget Lm Ericsson (Publ) | Adaptive sample filtering with slides |
WO2013152356A1 (en) | 2012-04-06 | 2013-10-10 | Motorola Mobility Llc | Devices and methods for signaling sample adaptive offset (sao) parameters |
EP2839661A4 (en) * | 2012-04-16 | 2015-12-02 | Mediatek Inc | Method and apparatus for sample adaptive offset coding with separate sign and magnitude |
US10623759B2 (en) * | 2012-06-13 | 2020-04-14 | Sony Corporation | Decoupling enhancements in sample adaptive offset (SAO) for high efficiency video encoder (HEVC) |
CN104704831B (en) * | 2012-08-06 | 2019-01-04 | Vid拓展公司 | The sampling grids information of space layer is used in multi-layer video coding |
US9800884B2 (en) * | 2013-03-15 | 2017-10-24 | Qualcomm Incorporated | Device and method for scalable coding of video information |
KR102164698B1 (en) * | 2013-03-25 | 2020-10-14 | 광운대학교 산학협력단 | Apparatus of processing sample adaptive offset of reusing input buffer and method of the same |
US9674538B2 (en) | 2013-04-08 | 2017-06-06 | Blackberry Limited | Methods for reconstructing an encoded video at a bit-depth lower than at which it was encoded |
WO2014165958A1 (en) * | 2013-04-08 | 2014-10-16 | Blackberry Limited | Methods for reconstructing an encoded video at a bit-depth lower than at which it was encoded |
FI3005696T3 (en) | 2013-05-30 | 2023-08-08 | Huawei Tech Co Ltd | Offset dynamic range constraints for edge offset sao filtering |
WO2015007200A1 (en) * | 2013-07-15 | 2015-01-22 | Mediatek Inc. | Method of sample adaptive offset processing for video coding |
US9294766B2 (en) | 2013-09-09 | 2016-03-22 | Apple Inc. | Chroma quantization in video coding |
US11109036B2 (en) | 2013-10-14 | 2021-08-31 | Microsoft Technology Licensing, Llc | Encoder-side options for intra block copy prediction mode for video and image coding |
RU2666635C2 (en) | 2013-10-14 | 2018-09-11 | МАЙКРОСОФТ ТЕКНОЛОДЖИ ЛАЙСЕНСИНГ, ЭлЭлСи | Features of base colour index map mode for video and image coding and decoding |
MX2016004705A (en) * | 2013-10-14 | 2016-07-18 | Microsoft Technology Licensing Llc | Features of intra block copy prediction mode for video and image coding and decoding. |
TWI496456B (en) | 2013-11-19 | 2015-08-11 | Ind Tech Res Inst | Method and apparatus for inter-picture cost computation |
CN111263150B (en) * | 2013-12-12 | 2021-10-26 | 三星电子株式会社 | Video encoding apparatus and video decoding apparatus |
US10390034B2 (en) | 2014-01-03 | 2019-08-20 | Microsoft Technology Licensing, Llc | Innovations in block vector prediction and estimation of reconstructed sample values within an overlap area |
US9872022B2 (en) * | 2014-01-03 | 2018-01-16 | Mediatek Inc. | Method and apparatus for sample adaptive offset processing |
WO2015100726A1 (en) | 2014-01-03 | 2015-07-09 | Microsoft Corporation | Block vector prediction in video and image coding/decoding |
US11284103B2 (en) | 2014-01-17 | 2022-03-22 | Microsoft Technology Licensing, Llc | Intra block copy prediction with asymmetric partitions and encoder-side search patterns, search ranges and approaches to partitioning |
US9628822B2 (en) * | 2014-01-30 | 2017-04-18 | Qualcomm Incorporated | Low complexity sample adaptive offset encoding |
US20150237378A1 (en) * | 2014-02-20 | 2015-08-20 | Mediatek Inc. | Method for controlling sample adaptive offset filtering applied to different partial regions in one frame based on different weighting parameters and related sample adaptive offset filter |
US10542274B2 (en) | 2014-02-21 | 2020-01-21 | Microsoft Technology Licensing, Llc | Dictionary encoding and decoding of screen content |
JP2017512026A (en) | 2014-03-04 | 2017-04-27 | マイクロソフト テクノロジー ライセンシング，エルエルシー | Block inversion and skip mode in intra block copy prediction |
US9716884B2 (en) * | 2014-03-20 | 2017-07-25 | Hfi Innovation Inc. | Method of signaling for mode selection in 3D and multi-view video coding |
CN105493505B (en) | 2014-06-19 | 2019-08-06 | 微软技术许可有限责任公司 | Unified intra block duplication and inter-frame forecast mode |
EP3202150B1 (en) | 2014-09-30 | 2021-07-21 | Microsoft Technology Licensing, LLC | Rules for intra-picture prediction modes when wavefront parallel processing is enabled |
CN104486630B (en) * | 2014-12-16 | 2017-10-20 | 北京金山云网络技术有限公司 | H.265 in Video coding under SAO patterns offset statistical method |
US9591325B2 (en) | 2015-01-27 | 2017-03-07 | Microsoft Technology Licensing, Llc | Special case handling for merged chroma blocks in intra block copy prediction mode |
US9877024B2 (en) * | 2015-03-06 | 2018-01-23 | Qualcomm Incorporated | Low complexity sample adaptive offset (SAO) coding |
CN106664405B (en) | 2015-06-09 | 2020-06-09 | 微软技术许可有限责任公司 | Robust encoding/decoding of escape-coded pixels with palette mode |
WO2016204479A1 (en) * | 2015-06-16 | 2016-12-22 | 엘지전자(주) | Method for encoding/decoding image, and device therefor |
US10009622B1 (en) * | 2015-12-15 | 2018-06-26 | Google Llc | Video coding with degradation of residuals |
US10841581B2 (en) * | 2016-07-14 | 2020-11-17 | Arris Enterprises Llc | Region specific encoding and SAO-sensitive-slice-width-adaptation for improved-quality HEVC encoding |
EP3280143A1 (en) * | 2016-08-04 | 2018-02-07 | Thomson Licensing | A method and an apparatus for image block encoding and decoding |
KR101873993B1 (en) * | 2016-11-18 | 2018-07-05 | 전자부품연구원 | Method and apparatus for predicting sample adaptive offset parameter |
KR20180074150A (en) * | 2016-12-23 | 2018-07-03 | 삼성전자주식회사 | Method and apparatus for video data encoding with sao filtering |
US11412218B2 (en) | 2017-01-20 | 2022-08-09 | Industry Academy Cooperation Foundation Of Sejong University | Image encoding method/device, image decoding method/device and recording medium having bitstream stored thereon |
CN108702521B (en) * | 2017-10-17 | 2020-03-31 | 北京金山云网络技术有限公司 | Encoding and decoding method, apparatus, encoder, decoder and storage medium |
US10986349B2 (en) | 2017-12-29 | 2021-04-20 | Microsoft Technology Licensing, Llc | Constraints on locations of reference blocks for intra block copy prediction |
CN110830801B (en) * | 2018-08-13 | 2021-10-01 | 华为技术有限公司 | Video coding rate control method and related device |
CN113994679A (en) * | 2019-06-21 | 2022-01-28 | 北京字节跳动网络技术有限公司 | Limitation on the number of context codec bits |
CN110121069B (en) * | 2019-06-27 | 2021-06-11 | 上海富瀚微电子股份有限公司 | HEVC loop filtering method based on cross word boundary |
Family Cites Families (31)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5446806A (en) | 1993-11-15 | 1995-08-29 | National Semiconductor Corporation | Quadtree-structured Walsh transform video/image coding |
US5574934A (en) | 1993-11-24 | 1996-11-12 | Intel Corporation | Preemptive priority-based transmission of signals using virtual channels |
US7305034B2 (en) * | 2002-04-10 | 2007-12-04 | Microsoft Corporation | Rounding control for multi-stage interpolation |
DE602004002455T2 (en) * | 2004-04-30 | 2007-01-11 | Matsushita Electric Industrial Co., Ltd., Kadoma | Motion vector estimation through adaptive temporal prediction |
JP2008059686A (en) | 2006-08-31 | 2008-03-13 | Canon Inc | Method of adjusting spherical aberration and focus offset and information recording and reproducing device using the same |
US8259808B2 (en) | 2010-03-25 | 2012-09-04 | Mediatek Inc. | Low complexity video decoder |
WO2011127961A1 (en) | 2010-04-13 | 2011-10-20 | Fraunhofer-Gesellschaft zur Förderung der angewandten Forschung e. V. | Adaptive image filtering method and apparatus |
US8660174B2 (en) | 2010-06-15 | 2014-02-25 | Mediatek Inc. | Apparatus and method of adaptive offset for video coding |
TWI406275B (en) | 2010-08-20 | 2013-08-21 | Sunplus Technology Co Ltd | Method and apparatus for searching an optimal focus bias and spherical aberration compensating value in an optical disc drive |
US8902988B2 (en) | 2010-10-01 | 2014-12-02 | Qualcomm Incorporated | Zero-out of high frequency coefficients and entropy coding retained coefficients using a joint context model |
US8861617B2 (en) | 2010-10-05 | 2014-10-14 | Mediatek Inc | Method and apparatus of region-based adaptive loop filtering |
US9001883B2 (en) | 2011-02-16 | 2015-04-07 | Mediatek Inc | Method and apparatus for slice common information sharing |
US9008170B2 (en) | 2011-05-10 | 2015-04-14 | Qualcomm Incorporated | Offset type and coefficients signaling method for sample adaptive offset |
US20120294353A1 (en) | 2011-05-16 | 2012-11-22 | Mediatek Inc. | Apparatus and Method of Sample Adaptive Offset for Luma and Chroma Components |
US10484693B2 (en) | 2011-06-22 | 2019-11-19 | Texas Instruments Incorporated | Method and apparatus for sample adaptive offset parameter estimation for image and video coding |
CN107105305B (en) * | 2011-06-24 | 2020-04-03 | Lg 电子株式会社 | Image information encoding and decoding method |
US8710809B2 (en) | 2011-06-28 | 2014-04-29 | Stmicroelectronics International N.V. | Voltage regulator structure that is operationally stable for both low and high capacitive loads |
WO2013006310A1 (en) * | 2011-07-01 | 2013-01-10 | Vidyo, Inc. | Loop filter techniques for cross-layer prediction |
US20130003829A1 (en) | 2011-07-01 | 2013-01-03 | Kiran Misra | System for initializing an arithmetic coder |
US10051289B2 (en) | 2011-11-04 | 2018-08-14 | Qualcomm Incorporated | Adaptive center band offset filter for video coding |
EP2777272B1 (en) | 2011-11-08 | 2019-01-09 | Google Technology Holdings LLC | Devices and methods for sample adaptive offset coding and/or signaling |
US9679061B2 (en) | 2011-12-08 | 2017-06-13 | Google Technology Holdings LLC | Method and apparatus that collect and uploads implicit analytic data |
WO2013103893A1 (en) | 2012-01-05 | 2013-07-11 | General Instrument Corporation | Devices and methods for multipass sample adaptive offset coding |
WO2013103892A1 (en) | 2012-01-05 | 2013-07-11 | General Instrument Corporation | Devices and methods for sample adaptive offset coding and/or selection of edge offset parameters |
US9161035B2 (en) | 2012-01-20 | 2015-10-13 | Sony Corporation | Flexible band offset mode in sample adaptive offset in HEVC |
US20130188741A1 (en) | 2012-01-21 | 2013-07-25 | General Instrument Corporation | Devices and methods for sample adaptive offset coding and/or selection of band offset parameters |
US9282328B2 (en) | 2012-02-10 | 2016-03-08 | Broadcom Corporation | Sample adaptive offset (SAO) in accordance with video coding |
US9380302B2 (en) | 2012-02-27 | 2016-06-28 | Texas Instruments Incorporated | Sample adaptive offset (SAO) parameter signaling |
WO2013152356A1 (en) | 2012-04-06 | 2013-10-10 | Motorola Mobility Llc | Devices and methods for signaling sample adaptive offset (sao) parameters |
US10694214B2 (en) | 2012-12-21 | 2020-06-23 | Qualcomm Incorporated | Multi-type parallelized sample adaptive offset in video coding |
US20140348222A1 (en) * | 2013-05-23 | 2014-11-27 | Mediatek Inc. | Method of Sample Adaptive Offset Processing for Video Coding and Inter-Layer Scalable Coding |
-
2012
- 2012-11-08 EP EP12795172.1A patent/EP2777272B1/en active Active
- 2012-11-08 KR KR1020147014200A patent/KR101674777B1/en active IP Right Grant
- 2012-11-08 CN CN201280054893.7A patent/CN104094601B/en active Active
- 2012-11-08 WO PCT/US2012/064214 patent/WO2013070960A2/en active Application Filing
- 2012-11-08 BR BR112014011149A patent/BR112014011149A2/en not_active Application Discontinuation
- 2012-11-08 CN CN201280054971.3A patent/CN104221373B/en active Active
- 2012-11-08 WO PCT/US2012/064208 patent/WO2013070955A2/en active Application Filing
- 2012-11-08 US US13/672,476 patent/US9774853B2/en active Active
- 2012-11-08 KR KR1020147014994A patent/KR101671381B1/en active IP Right Grant
- 2012-11-08 BR BR112014012351A patent/BR112014012351A2/en not_active Application Discontinuation
- 2012-11-08 EP EP12787333.9A patent/EP2777259A2/en not_active Withdrawn
- 2012-11-08 US US13/672,484 patent/US9392270B2/en active Active
Non-Patent Citations (5)
Title |
---|
CHIH-MING FU ET AL.: "Sample Adaptive Offset for Chroma", 《JCT-VC OF ITU-T SG16 WP3 AND ISO/IEC JTC1/SC29/WG11,6TH MEETING: TORINO,IT》 * |
CHIH-MING FU ET AL.: "Sample adaptive offset for HEVC", 《MULTIMEDIA SIGNAL PROCESSING (MMSP), 2011 IEEE 13TH INTERNATIONAL WORKSHOP ON》 * |
CHIH-MING FU ET AL.: "TE10 Subtest 3: Quadtree-based Adaptive Offset", 《JCT-VC OF ITU-T SG16 WP3 AND ISO/IEC JTC1/SC29/WG11，3RD MEETING: GUANGZHOU》 * |
CHIH-MING FU: "CE8 Subset3: Picture Quadtree Adaptive Offset", 《JCT-VC OF ITU-T SG16 WP3 AND ISO/IEC JTC1/SC29/WG11,4TH MEETING: DAEGU,KR》 * |
KEN MCCANN: "HM4: High Efficiency Video Coding (HEVC) Test Model 4 Encoder Description", 《JCT-VC OF ITU-T SG16 WP3 AND ISO/IEC JTC1/SC29/WG11,6TH MEETING: TORINO,IT》 * |
Cited By (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN109644274A (en) * | 2016-08-30 | 2019-04-16 | 交互数字Vc控股公司 | Utilize the method and apparatus for the video coding that sample adaptively deviates |
CN113382257A (en) * | 2021-04-19 | 2021-09-10 | 浙江大华技术股份有限公司 | Encoding method, encoding device, electronic equipment and computer readable storage medium |
CN113382257B (en) * | 2021-04-19 | 2022-09-06 | 浙江大华技术股份有限公司 | Encoding method, encoding device, electronic device and computer-readable storage medium |
Also Published As
Publication number | Publication date |
---|---|
CN104094601B (en) | 2018-01-19 |
KR101671381B1 (en) | 2016-11-01 |
EP2777272A2 (en) | 2014-09-17 |
WO2013070955A3 (en) | 2013-09-12 |
CN104221373A (en) | 2014-12-17 |
EP2777272B1 (en) | 2019-01-09 |
WO2013070960A3 (en) | 2013-10-10 |
KR20140090652A (en) | 2014-07-17 |
US20130114678A1 (en) | 2013-05-09 |
KR101674777B1 (en) | 2016-11-09 |
BR112014012351A2 (en) | 2017-05-30 |
US9774853B2 (en) | 2017-09-26 |
EP2777259A2 (en) | 2014-09-17 |
KR20140090646A (en) | 2014-07-17 |
US9392270B2 (en) | 2016-07-12 |
US20130114677A1 (en) | 2013-05-09 |
CN104221373B (en) | 2017-10-27 |
WO2013070960A2 (en) | 2013-05-16 |
BR112014011149A2 (en) | 2017-05-16 |
WO2013070955A2 (en) | 2013-05-16 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN104094601B (en) | Apparatus and method for sampling adaptive skew coding and/or signaling | |
US9888249B2 (en) | Devices and methods for sample adaptive offset coding and/or selection of edge offset parameters | |
CN104685874B (en) | For handling the device and method of compartment model in high efficiency coding and decoding video | |
CN104995919B (en) | For most end significant coefficient it is position encoded in context reduction device and method | |
CN104956674B (en) | Device and method for the context reduction in the position encoding and decoding of most end significant coefficient | |
CN105379270A (en) | Inter-color component residual prediction | |
CN103563378A (en) | Memory efficient context modeling | |
CN103621082A (en) | Quantization in video coding | |
WO2013103893A1 (en) | Devices and methods for multipass sample adaptive offset coding | |
CN103270754A (en) | Mode dependent scanning of coefficients of a block of video data | |
US11483562B2 (en) | Method and apparatus for video encoding and decoding based on context switching | |
CN103140877A (en) | Video coding using intra-prediction | |
CN103460699A (en) | In-loop filtering method and apparatus for same | |
WO2014055231A1 (en) | Devices and methods for using base layer motion vector for enhancement layer motion vector prediction | |
WO2013152356A1 (en) | Devices and methods for signaling sample adaptive offset (sao) parameters | |
US20210274220A1 (en) | Multi-layer video encoder/decoder with base layer intra mode used for enhancement layer intra mode prediction | |
KR20230029717A (en) | Method for decoding a video partitioned block |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
C06 | Publication | ||
PB01 | Publication | ||
C10 | Entry into substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
C41 | Transfer of patent application or patent right or utility model | ||
TA01 | Transfer of patent application right |
Effective date of registration: 20160311Address after: American CaliforniaApplicant after: Technology Holdings Co., Ltd of GoogleAddress before: Illinois StateApplicant before: Motorola Mobility, Inc. |
|
GR01 | Patent grant | ||
GR01 | Patent grant |