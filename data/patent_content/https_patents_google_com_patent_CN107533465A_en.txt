CN107533465A - Auxiliary layer with automation extraction - Google Patents
Auxiliary layer with automation extraction Download PDFInfo
- Publication number
- CN107533465A CN107533465A CN201680019339.3A CN201680019339A CN107533465A CN 107533465 A CN107533465 A CN 107533465A CN 201680019339 A CN201680019339 A CN 201680019339A CN 107533465 A CN107533465 A CN 107533465A
- Authority
- CN
- China
- Prior art keywords
- field lens
- computing device
- user interface
- lens data
- module
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/44—Arrangements for executing specific programs
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/44—Arrangements for executing specific programs
- G06F9/451—Execution arrangements for user interfaces
- G06F9/453—Help systems
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/903—Querying
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0484—Interaction techniques based on graphical user interfaces [GUI] for the control of specific functions or operations, e.g. selecting or manipulating an object, an image or a displayed text element, setting a parameter value or selecting a range
- G06F3/04842—Selection of displayed objects or displayed text elements
Abstract
In general, this disclosure relates to the graphic user interface of application and the technology for being shown at the display module coupled with the computing device operation are exported by computing device.The computing device determines field lens data from the content being included in the graphic user interface.The computing device is at least partially based on the field lens data, further determines that the help related to the content field lens that the graphic user interface includes indicates.The computing device output help indicates.
Description
Background technology
Computing device (for example, smart mobile phone, tablet personal computer, intelligent watch, movable tracker, head-up display component etc.) can
It is used to show with output screen content.For example, computing device can export the graphical user for including one or more graphic elements
Interface (GUI).Computing device can allow user to be based on a variety of inputs, such as single-point touch and multi-point touch gesture,
Information exchange on phonetic entry, pointing device and keyboard, with the equipment.In order to help user to search information or perform various
Task, some computing devices can be as the personal assistant operations of automation.For example, the computing device can export suggestion with
Just reduce location information or perform the amount of user effort of required by task.However, there may be the phase with user for some computing devices
The limited suggestion of closing property.In this case, user may need to spend extra work to carry out location information or perform task.
Brief description of the drawings
Fig. 1 is the one or more aspects according to the disclosure, shows the concept map of example system for including computing device,
The screen field lens of determination of the computing device based on display module provides help and indicated.
Fig. 2 is the one or more aspects according to the disclosure, shows the block diagram of exemplary computer device.
Fig. 3 is one or more technologies according to the disclosure, shows output screen content to show at remote equipment
The block diagram of exemplary computer device.
Fig. 4 is the one or more aspects according to the disclosure, shows the concept of example system for including server apparatus
Figure, the screen field lens of determination of the server apparatus based on long-range display module provide help and indicated.
Fig. 5 is the one or more aspects according to the disclosure, shows to realize the calculating for being used for the technology that determination help indicates
The flow chart of the exemplary operation of equipment.
Embodiment
Generally speaking, this disclosure relates to based on the screen field lens of the graphic user interface shown by display module come to user
Output helps the technology indicated.For example, computing device can extract or otherwise determine the current screen for reflecting display module
The screen field lens data of curtain content, and generated based on the screen field lens data and help to indicate for the one or more of declaration.
By capturing screen field lens data from the immediately visible screen content of user, the technology of the disclosure can improve exported help
The correlation of instruction.That is, because the content shown at display module is probably the prime focus of user, this is used
The content of sample can improve the field lens correlation for helping to indicate.
In operation, the computing device can include the module performed with operating system authority, the module walks
The view level of individual application is related to the required content in graphic user interface to determine which of application particular figure
Connection.Alternatively, the computing device can capture the screenshot capture of graphic user interface and by performing the figure to screenshot capture
Screen field lens data are determined as analysis.In some instances, the computing device can assess the graphic user interface
For one or more user interface elements to determine the respective value of the element, the computing device can be used as field lens data.
Field lens data are determined by the screen content based on the graphic user interface, computing device can be that user's generation is more relevant
It is recommended that and/or determine ensuing action more likely.Therefore the technology of the disclosure can reduce or eliminate application developer will
Field lens data are clearly encoded to using the needs for helping to indicate for use in generation in itself.By this way, the disclosure
Technology can provide the general approach that field lens data are obtained from any graphic user interface for being output for display.
Fig. 1 is the one or more aspects according to the disclosure, shows the concept map of example system for including computing device, institute
The screen field lens offer help for stating determination of the computing device based on display module indicates.As described further below, at least portion
Point based on from be included in be output for the foreground for being shown in display module or user selection position in graphic user interface
Content determined by field lens data, computing device is with can determining the content field lens included to graphic user interface related
Help indicates.
As shown in figure 1, system 102 includes computing device 104.In the example of fig. 1, computing device 104 is described as moving
Mobile phone.However, in some instances, computing device 104 can be computerization wrist-watch (for example, intelligent watch), computer
Change glasses, computerization headwear, other kinds of wearable computing devices, tablet PC, personal digital assistant (PDA), knee
Laptop computer, games system, media player, E-book reader, TV platform, auto-navigation system, digital camera,
Or it is configured to movement and/or the stationary computing devices of any other type of Control Items.As will be described later,
The display module can be integrated with computing device 104 or long-range.
In this embodiment, computing device 104 includes display module 106, is one or more using 108, auxiliary mould
Block 110 and field lens module 111.Module 108,110 and 111, which can utilize, to be resident in computing device 104 and/or performs soft
The mixture of part, hardware, firmware or hardware, software and/or firmware performs operation described herein.Computing device
104 can use one or more processors execution module 108,110 and 111.In some instances, computing device 104 can incite somebody to action
Module 108,110 and 111 performs as the one or more virtual machines performed on the bottom hardware of computing device 104.Module
108th, 110 and 111 can be performed as 104 operating system or one or more services of calculating platform or component.Module
108th, 110 and 111 can be grasped as one or more executable programs in the application layer of the calculating platform of computing device 104
Make System Privileges or access the run-time library execution of computing device 104.In some instances, display module 106, using 108
And/or module 110 and 111 can remote arrangement to and computing device 104 can be remotely accessed, for example, via computing device 104 and one
The interaction of individual or multiple remote network equipments.
The display module 106 of computing device 104 can include corresponding input and/or the output group for computing device 104
Part.In some instances, display module 106, which can utilize, has responsive type input module such as resistive touch screen, surface sound
Ripple touch-screen, capacitive touch screen, projection capacitance touch screen, pressure-sensitive screen, acoustic pulse recognition touch-screen or other display modules
Technology plays a part of input module.Display module 106 can also include according to one or more technologies of the disclosure being existed
The display module of content, such as liquid crystal display (LCD), matrix display, light emitting diode are exported in graphic user interface
(LED) display, Organic Light Emitting Diode (OLED) display, electric ink or can to computing device 104 user export
The similar monochrome or color monitor of visual information.
In some instances, the presence sensitizing input component of display module 106 receives tactile from the user of computing device 104
Input.The presence sensitizing input component of display module 106 can by detect from user one or more gestures (for example,
User is with finger or stylus touch-control or clicks on one or more positions of display module 106) receive the instruction of sense of touch.
The display module of display module 106 can be presented to user and exported.The display module of display module 106 can make the output
Presented for graphic user interface (for example, the user interface of alarm is checked based on notice data), it can be carried with computing device 104
The connection that is functionally correlated supplied.For example, the display module of display module 106 can present with computing device 104 perform or can
Calculating platform, operating system, application and/or the service of access are (for example, notice service, electronic information application, Internet-browser
Using, mobile or desktop operating system etc.) the various user interfaces being functionally correlated.User can with display module 106
Locate the user interface interaction presented, to cause computing device 104 to perform the operation related to function.
As shown in figure 1, computing device 104, which can include one or more, applies 108A-108C, it can be by field lens module
111 tissues are otherwise constructed in list of application 118.List of application 118 can be the list, queue, collection using 108
Close etc..In some instances, list of application 118 can be to wherein they can be by the application application one of cyclic access (iterated)
Individual order is to be shown.In order to determine the current activity of which application and/or storage, (and be included in should in memory
With in list 118), field lens module 111 can in the user space perform and access the group of the operating system on computing device 104
Part, such as plan or scheduler.In other examples, field lens module 111 can be included in operating system as component.
In other other examples, field lens module 111 can be with the single manager module of searching and managing list of application 118, so as to from should
Foreground application is determined with list 118.The application 108 being currently running can be created and changed to be shown for controlling by display 106
Graphic user interface at least one of view level 130.
Field lens module 111 can analyze the view level for the application 108 being each currently running, wherein the view layer time can
To be realized as list or other suitable data structures.Each view level can include the specific screen to graphic user interface
One group of reference of each element of curtain.For example, the view level of application can include the text view object to showing text
Quote so that each attribute (for example, view object identifier, view object placement etc.) of the text view object can be by field
Mirror module 111 accesses.In order to illustrate, user can enter with currently rendering the first of the first graphic user interface using 108A
Row interaction.Then user can perform the first action, and first is responded using 108A by rendering different screens.
According to one or more technologies of the disclosure, the display module 106 of computing device 104 can export is answered by being included in
With the graphic user interface 112 instructed using 108A in 108.It is included in the list of application 118 of computing device 104 using 108A
In one group apply 108 in.In order to illustrate, in the example of fig. 1, the display module 106 of computing device 104 can be with output pattern
User interface 112, it can show the information of user's request on restaurant, bar or event.In the example of fig. 1, figure
User interface 112 is included on the Allison's positioned at Tennessee State (TN) Nashville 1234Crunch streets
The information in Bistro dining rooms.The Miranda Lambert concerts that will be also held on graphic user interface 112 on Saturday
Publicity.
The field lens module 111 of computing device 104 can analyze the graphic user interface 112 of display module 106.So doing
When, field lens module 111 can access view level 130.As described above, field lens module 111 can use operating system limiting operation
Or the run-time library is realized or accessed in the run-time library of computing device 104, the run-time library allows field lens module 111
Access view level 130 and receive the view object on the part as the graphic user interface 112 currently shown
Information.In some instances, view object can be any item for being output for being shown by computing device.View object is shown
Example can include but is not limited to text message, image information, frame information, linear information, pattern information or button information, Yi Jiqi
His attribute.In the example of fig. 1, field lens module 111 determines three pieces of key contents be present from view level 130：Content 114A (comes
View object from entitled " restaurant _ title _ text (restaurant_name_text) "), content 114B (from it is entitled " meal
The view object in shop _ address _ text (restaurant_address_text) ") and content 114C (come from entitled " event _ letter
The view object of breath _ text (event_information_text) ").Although content 114A-14C is shown respectively as text,
But content 114A-14C bottom level view object can be any kind of view object as described above, and can contain non-
Content of text, content of text or the two.
Pair determine to be output for being shown in the foreground of display module 106 using 108A graphic user interface 112
Row response, the field lens module 111 of computing device 104 can be true from the content 114A-114C being included in graphic user interface 112
Determine field lens data, and optionally employ related view object attribute so that additional field lens is confirmed or extracted from content 114A-114C
Data.In the example of fig. 1, field lens module 111 can be each determination field lens data in three view objects.Example
Such as, field lens module 111 can determine that content 114A includes the title in restaurant.Field lens module 111 can determine that content 114B includes
Address.In addition, field lens module 111 can determine that content 114C includes appropriate title and date.
The supplementary module 110 of computing device 104 can be at least partially based on field lens data identified above to determine and scheme
The help for the content 114A-114C field lenses correlation that shape user interface 112 includes indicates.In some instances, help that indicate can
To be to be at least partially based on the possible action that field lens data and content carry out.In some instances, help indicate it can is not
Only related to the field lens data of the content of shown screen and with any bottom level view object properties field lens data are related
Additional information.The example for helping to indicate can include but is not limited to, checking, being more specifically based on based on content of text 114A
Examined including word " bistro " and/or relevant view object oriented for the content of text 114A in " restaurant _ title _ text " restaurant
Read, based on including content of text 114A that word " bistro " and/or relevant view object oriented are " restaurant _ title _ text "
Content of text 114A it is predetermined, content of text 114C information is " event _ letter more specifically based on relevant view object oriented
The ticket information of breath _ text ", call taxi or means of transport to take user to and be based on being formatted according to content of text 114C
For address and/or content of text 114B that relevant view object oriented is " restaurant _ address _ text " position, based in text
The direction of appearance 114B position, the calendar event of the content of text 114C based on event view object, or for any text
Or the search result of image views object, to name just a few.
In order to further illustrate, in Fig. 1, content 114A reflects the text for indicating its view object for being restaurant name
This.Based on such view object and its content, it is useful that supplementary module 110 can determine that user may like or find
Various help forms, including go to the predetermined restaurant in website or check the menu in restaurant.It should be noted that because view object indicates
" Allison's Bistro " are restaurant name rather than movie name, and supplementary module 110 can be come using additional field lens data
Confirm that " Allison's Bistro " " Bistro " partly refers to restaurant.If the title of content 114A view object is
" film _ title _ text (movie_name_text) ", then supplementary module 110 can be additional to or instead of the predetermined instruction in restaurant,
Cinema screening persond eixis is provided.In another example, content 114B reflects the view pair for indicating that it is restaurant address
The text of elephant.Based on such content and field lens, supplementary module 110 can determine user may need address direction or
Request taxi takes him or she to the position.As counter-example, if the title of content 114B view object is " film _ ground
Location _ text (movie_address_text) ", then supplementary module 110 can be additional to or instead of navigation or taxi request refer to
Show, the instruction of cinema screening time is provided at the address shown on display module 106.In another example, content
114C reflects the view object text with event information.Based on such content, supplementary module 110 can determine to use
It or may wish that ticketing service purchase website checks the remaining ticket situation of the event in family.Based on the content type, supplementary module 110
It can determine that the help on one or more crucial 114A-114C content blocks indicates.
Supplementary module 110 can be indicated using the display module 106 of computing device 104 to export help.The help refers to
Show it can is any suitable appearance form, such as the coverage diagram on screen, the coverage diagram near the content on screen, figure are used
Pop-up window or audio instruction in the interface of family, are named just a few.For example, as described above, supplementary module 110 can be based on comprising
The content 114A generations or issue help for being covered in the user interface element of the top edge of graphic user interface 112 indicate 116,
It includes allowing content of text of the user based on restaurant name to carry out predetermined web site url.Indicating 116 with help, interact can be with
Start predetermined application, start the Internet browser application of the website to the restaurant, or cause supplementary module 110 directly to meal
Shop, for example send predetermined request message to the remote server in restaurant.In another example, supplementary module 110 can generate
Or the content 114B help that issue includes user interface element indicates, it surrounds or highlighted content 114B and when selecting
Shi Qidong taxis are applied to call the address that vehicle takes user in content 114B to.In another example, supplementary module
110 helps that can generate or issue the content 114C including user interface element indicate that it surrounds or highlighted content
114C and start calendar application upon selection so that the event is put into the electronic calendar of user.
User can ask supplementary module 110 to export in various manners.For example, user can be by lower key, execution touch-control hand
Gesture such as long-press or voice command is provided asks supplementary module to indicate.Carry out the application of circular flow for example, by button, lead to
Cross pull and remove from selected window or content blocks to continue initial touch control gesture, by selected window or
Rapped on content blocks and perform the second touch control gesture or provide voice command instruction including the use of pronoun such as "the" or " it "
Application or content blocks are asked to indicate the application on graphic user interface 112 or content blocks, user can also be specified for field lens
Data, content module 111 should check which application and optionally which content blocks.Supplementary module 110 can ask calculating to set
Standby 104 other modules, which perform, can aid in user to complete inferred action or the information search of task.Supplementary module 110 can
With provide information to other modules with complete action described in task or other one or more computing devices of commission with
Now give user's (for example, user interface as networked computing device).
User's " demand " as mentioned can be based on user action system observation (for example, example in action log
Such as search history, purchasing history, using history and other field lens history), the user being defined as in given field lens
The semantic group mode of action.Pay attention to, this is only the exemplary fixed of the model that simplification discussion is used by supplementary module 110
Justice.Therefore, needs may be not necessarily by this example definitions, the task or action, the observation taken on the contrary is moved
Work or performed task can be the more typically demands that supplementary module 110 can use it to infer the user of computing device 104
Substitution value (proxy).
In a word, supplementary module 110 can perform one or more machine learning techniques to learn the user of computing device 104
For the demand of different field lenses.In other words, because supplementary module 110 possibly directly can not learn that calculating is set by performing application
The demand of standby 104 user, therefore the analog subscriber demand of supplementary module 110.Supplementary module 110 can connect from field lens module 111
Wind up mirror information, and the information is fed as input to the model, for training the model to learn user for given
The demand of field lens.After training, the model can receive specific field lens as input, and as response, output indication one
It is individual or it is multiple before by other users be specific field lens perform tasks, action or other observables action instruction (for example,
Data).The current field lens of computing device 104 can be input in model by supplementary module 110, be inferred using supplementary module 110
The one or more actions generally performed by the other users for the computing device 104 for providing similar field lens.In brief, mould is aided in
Block 110 can be defined as the possibility (for example, probability, count etc.) for the task that specific field lens performs degree whether well beyond
The possibility degree of being performed for wider field lens for task.By this way, if the task pair that user may have to carry out
It is especially distinguished or unique for particular case, then supplementary module 110 can only export demand information.
Although Fig. 1 technology, supplementary module are described according to one or more operations to computing device 104
110 one or more operations can perform on the remote server.Field lens data can be sent to determination by field lens module 111
The possible remote server for helping to indicate, is then sent to supplementary module 110, and supplementary module 110 is responsible for formatting institute
State result and the result is output to screen by (such as coverage diagram) in a particular form.
Field lens is determined by the content based on the graphic user interface shown on display module, computing device can be right
Suggestion is made in the possible next action of user, and clearly provides field lens information from the application independent of application developer.
By this way, the technology of the disclosure can be provided for mobile device for determining the possible ability next acted, and right
Any application that computing device can be run provides help and indicated, includes any extracode without application developer, from
And simplify the code of the application run on the computing device.By extracting text message and/or figure from the screen by application display
As information, the content is supplied to supplementary module by the technology of the disclosure, and supplementary module uses the field lens, based on graphical user
The content rather than the content that is clearly provided by hard coded field lens information of application developer that interface 112 is shown, come provide on
The possible help next acted indicates.In determining content providing feature for computing device and field lens be provided, application
Coding is simplified, and can be applied with reliable way in main developer and help is generally provided between third-party application.
In addition, the technology of the disclosure can allow help more extensive for the screen content for being output for display.
In the whole disclosure, following example is described, wherein computing device and/or computing system can calculated only
Equipment could analyze described information (for example, position when receiving the license of user to analyze the information associated with the computing device
Put, speed etc.).For example, the computing device being discussed below can be collected or can utilize the letter associated with user
In the case of breath, the chance that user can be provided input controls whether the program of the computing device or feature can be received
Collect and utilize user profile (for example, information on user current location, present speed etc.), or the instruction computing device
Whether and/or how content that may to user related can be received.In addition, some data at it by computing device and/or meter
Calculation system is stored or use can be handled with one or more modes before, so as to eliminate personally identifiable information.For example, it can locate
Manage the identity of user so that not can determine that the personally identifiable information on user, or obtain positional information (such as city,
Postcode or state level) in the case of, the geographical position of user can generally be changed so that not can determine that the specific position of user
Put.Thus, user can be for controlling how the information collected on user and used by the computing device.
Fig. 2 is the one or more aspects according to the disclosure, shows the block diagram of exemplary computer device.Fig. 2 illustrate only
One particular example of computing device 204, and many other examples of computing device 204 can be used in the case of other.
As shown in Fig. 2 specific example, computing device 204 includes one or more processors 205, one or more inputs
Component 220, one or more communication units 222, one or more output precisions 224, one or more storage devices 230, one
Individual or multiple sensors 226, and display module 206.In the figure 2 example, computing device 204 includes list of application 208, auxiliary
Module 210, field lens module 211, run-time library 232, operating system 234 and I/O modules 236.Component 205,206,220,222,
224 and 226 can each interconnect (physical, communicativeness and/or operability) for inter-component communication.In some instances, lead to
Letter channel 228 can include system bus, network connection, interprocess communication data structure or for exchange data it is any its
Its channel.As an example in Fig. 2, component 205,206,220,222,224 and 226 can be communicated by one or more
Channel 228 couples.List of application 208, supplementary module 210, field lens module 211, run-time library 232, operating system 234 and I/O
Module 236 can also each other and with the other assemblies exchange of information in computing device 204.
In one example, processor 205 is configured as realizing feature and/or process instruction with computing device 204
Interior execution.For example, processor 205 can handle the instruction being stored in storage device 230.The example of processor 205 can
With including microprocessor, controller, digital signal processor (DSP), application specific integrated circuit (ASIC), field programmable gate array
Or any one or more of equivalent discrete or integrated logic circuit (FPGA).
One or more storage devices 230 can be configured as during operation in the inner storag information of computing device 204.
In some examples, storage device 230 is described as computer-readable recording medium.In some instances, storage device 230 is to face
When memory, it means that the main purpose of storage device 230 is not to store for a long time.In some instances, the quilt of storage device 230
It is described as volatile memory, it means that when computing device is closed, storage device 230 does not retain the content of storage.Easily
The example of the property lost memory includes random access memory (RAM), dynamic random access memory (DRAM), static random-access
The volatile memory of memory (SRAM) and other forms known in the art.In some instances, storage device 230 is used
In the programmed instruction that storage is performed by processor 205.In one example, storage device 230 on computing device 204 by running
Software or application (for example, list of application 208) be used for program perform during interim storage information.
In some instances, storage device 230 also includes one or more computer-readable recording mediums.Storage device
230 are configurable to store a greater amount of information than volatile memory.Storage device 230 can be further configured to for a long time
Storage information.In some instances, storage device 230 includes non-volatile memory device.This non-volatile memory device
Example includes magnetic hard-disk, CD, floppy disk, flash memory or electrically-programmable memory (EPROM) or electric erasable and can
Program the form of (EEPROM) memory.
In some instances, computing device 204 also includes one or more communication units 222.In one example, calculate
Equipment 204 is set using communication unit 222 via for example one or more wired or wireless networks of one or more networks with outside
Standby communication.Communication unit 222 can be NIC, such as Ethernet card, optical transceiver, RF transceiver or can send out
Send the equipment with any other type of receive information.The example of such network interface can include bluetooth, infrared signaling,
3G, LTE and Wi-Fi radio and USB (USB) and Ethernet.In some instances, computing device 204 utilizes
Communication unit 222 and another computing device progress radio communication for being operatively coupled to computing device 204.
In one example, computing device 204 also includes one or more input modules 220.In some instances, input
Component 220 is configured as receiving and inputting from user by tactile, audio or video feedback.The example of input module 220 includes aobvious
Show the equipment of component, mouse, keyboard, camera, microphone or any other type for detecting the input from user.
In some instances, display module includes touch sensitive screen.
One or more output precisions 224 can also be included in computing device 204.In some instances, output precision
224 are configured to, with tactile, audio or video stimulates and provides a user output.In one example, output precision 224 includes
Electronic console, loudspeaker or any other type for converting the signal into people or machine understandable appropriate format
Equipment.The electronic console can be LCD the or OLED parts of touch-screen, can look at display module straight for example with right and wrong touch screen
CRT, LED, LCD or OLED.The display module can also be projecting apparatus rather than straight watching display.
In some instances, display module 206 can include input module 220 and/or output precision 224 and/or display
The feature of component 218.In the figure 2 example, display module 206 can be display module.In some instances, sensitivity be present
Display can detect object at the screen of the display module and/or neighbouring.As an example ranges, display module can
With detect 2 inches of the entity screen of the display module (Centimetre) in or closer to object, such as finger or touch-control
Pen.The display module can determine to detect the position (for example, (x, y) coordinate) of the display module of the object.
In another example ranges, display module can detect from 6 inches of the entity screen of the display module (Centimetre) or
Closer to object, and other exemplary scopes are also possible.The display module can utilize electric capacity, inductance and/or
Optical recognition come determine by user finger selection the display position.In some instances, exist sensitive aobvious
Show that device is stimulated using the tactile as described by for output precision 224, audio or video and provide a user output.
Computing device 204 can include operating system 234.In some instances, operating system 234 controls computing device
The operation of 204 component.For example, in one example, operating system 234 promotes using 208, supplementary module 210, field lens module
211st, run-time library 232 and I/O modules 236 and processor 205, communication unit 222, storage device 230, input module 220, defeated
Go out the communication of component 224 and display module 206.Including application 208, supplementary module 210, field lens module 211, run-time library 232,
The one or more assemblies of the storage device 230 of operating system 234 and I/O modules 236 can each include can be by computing device 204
The programmed instruction and/or data of execution.As an example, display module 206 can include causing computing device 204 to perform one
The instruction of operation and action described in individual or multiple disclosure.In some instances, one shown in storage device 230
Or multiple components can be implemented as the combination of hardware and/or software and hardware.
In some instances, computing device 204 can include one or more sensors 226.One or more sensors
226 can measure one or more measurands.The example of one or more sensors 226 can include one or more positions
Sensor (for example, global positioning system (GPS) sensor, indoor positioning sensor etc.), one or more motion/orientation sensings
Device (such as accelerometer, gyroscope etc.), optical sensor, temperature sensor, pressure (or grip) sensor, physical switch, connect
The biology sensor of nearly sensor and one or more measurable skin/blood properties such as alcohol, blood glucose.
I/O modules 236 can receive and explain the input detected at display module 206 (for example, when user is in user
When the one or more positions of the shown display module 206 in interface provide one or more postures) and in computing device 204
The input that detects of other input module (for example, microphone, camera, sensor, physical button etc.) places.I/O modules 236
The information of input on being detected at computing device 204 can be relayed to one or more performed at computing device 204
Individual associated platform, application and/or service, to cause the perform function of computing device 204.For example, based on the input received,
I/O modules 236 can start technology described herein.In one example, user, which can perform, starts graphical user circle
The action of technology in face in all the elements.In another example, user can select what is shown in graphical user interfaces
The certain content block of the technology will be performed for it.
I/O modules 236 can also be from the one or more performed from computing device 204 (for example, supplementary module 210 etc.)
Associated platform, using/or service reception information and instruction, for generating graphic user interface or for providing body-sensing type
User interface.Put down in addition, I/O modules 236 can serve as the one or more of associated of execution at computing device 204
Platform, operating system, application and/or service and the various output precisions of computing device 204 (for example, display module 206, one or
Multiple sensors 226, storage device 230, loudspeaker, LED indicator, other output precisions etc.) between corresponding intermediary, with
Computing device 204 produces output (for example, figure, flash of light, sound, body-sensing response, haptic response etc.).
According to one or more technologies of the disclosure, the display module 206 of computing device 204 will can be being applied in 208
Including the graphic user interface (such as Fig. 1 graphic user interface 112) of application export for showing.The application is included in
In application group in the list of application 218 of computing device 204.In order to illustrate, in the figure 2 example, the display of computing device 204
Component 206 can be with output pattern user interface, and it can show the electronics for the Possible event that weekend is discussed from some contact person
Mail.For example, the graphic user interface can include name, time and the organization names of the contact person.
The field lens module 211 of computing device 204 can determine to show graphical user circle of the application of the Email
Face is output to be shown in display module 206.In doing so, field lens module 211 can access is managed by field lens module 211
List of application 208.Before which application is field lens module 211 can determine and currently be output to be shown in display module 206
Graphic user interface 212 in platform is associated.For example, field lens module 211 can be determined using 208A and graphic user interface 212
It is associated or otherwise generates for the graphic user interface 212 using 208A.In some instances, current output is with aobvious
Show that the graphic user interface 212 in display module 206 can be associated with the application checked or accessed recently.As described above,
Field lens module 211 can use operating system limiting operation, or access view in the permission field lens module 211 of computing device 204
Realized in the run-time library 232 of level 230 or the run-time library 232 can be accessed.Field lens module 211 can access current display
View content.In some instances, view object can be any project exported by computing device, such as be used in figure
Any project in the interface of family.The example of view object can include but is not limited to text message, image information, frame information, line
Property information, pattern information or button information, etc..Field lens module 211 can identify the view in graphical user interfaces
The view object of level.Field lens module 211 can further extract at least one attribute of the view object, and at least portion
Divide based at least one attribute to determine the field lens data.In the figure 2 example, field lens module 211 is from graphical user
Interface determines three view objects be present：Name of contact person, time, and mechanism.
In some instances, it is determined that showing that the graphic user interface of the application of the Email is output with aobvious
When showing in the foreground of display module 218, field lens module 211 can access the application of the application operated at computing device 204
List 208, to select the application associated with the graphic user interface in the foreground of display module 218.For example, on Fig. 2
Example, field lens module 211 can access list of application 208 and select e-mail applications, because the Email
Using being application currently associated with the graphic user interface in the foreground of display module 218, because it is currently to show
Show the application shown on component 218.Field lens module 211 can further in traversal applications list 208 list of application because institute
The time sequencing for stating access of the list of application with computing device 204 is listed in the one group of application run on computing device 204, wherein
Access recently apply in an end of the level and at most before access apply in another end.
Pair determine that the graphic user interface of the e-mail applications is output to be shown in the foreground of display module 206
Carry out responsively, the field lens module 211 of computing device 204 can determine field lens number from the content that graphic user interface includes
According to.In the figure 2 example, field lens module 211 can determine three critical chunks each on field lens data.Example
Such as, field lens module 111 can determine that content includes name of contact person, time and organization names.In some instances, field lens data
It can be the general description of the determination of the content.The example of field lens data can include but is not limited to, and the content is meal
The determination of shop title, the rank of video-game, attached perigean address, singer's name or calendar event etc..
In some instances, it is determined that during the field lens data, field lens module 211 can be captured in display module 218
The screenshot capture of the graphic user interface of the application shown in foreground.Field lens module 211 can be entered to the screenshot capture
Row graphical analysis.Described image analysis is at least partially based on, field lens module 211 can determine the field lens data.For example, field lens
Module 211 can perform optical character recognition process to determine one or more of described screenshot capture to the screenshot capture
Character, one or more of characters are thus at least partially based on to determine field lens data.In the figure 2 example, it is because described
Using being e-mail applications, therefore field lens module 211 can perform optical character to the screenshot capture of the Email and know
Other places are managed, to determine the content of the Email, so as to export field lens data.In other examples, described image point
Analysis can be that the graph image in the screenshot capture is determined using the web search of described image, such as the example institute with Fig. 4
Show.
In other examples, it is determined that during the field lens data, field lens module 211 can analyze the view layer using 208
Secondary 230.For being included in the view object in view level, field lens module 211 can identify view object.Field lens module 211
The information associated with the view object identified can also be determined, and is at least partially based on identified information to determine field
Mirror data., can be with for the particular figure or graphic user interface of application for example, the view level of the graphic user interface
The structure for the user interface element being included in the particular figure or graphic user interface.Based on this of user interface element
Kind structure, field lens module 211 can determine content, such as text or image.For example, in the figure 2 example, field lens module 211
The view level of the graphic user interface of display Email can be traveled through, thus shows user interface element, such as application
Background, the sender of Email, the text of the theme of Email and Email., can based on these user interface elements
To determine respective content.For example, field lens module 211 can determine name of contact person based on the sender of Email, and
Field lens module 211 can determine time and mechanism based on the text of Email.Content based on the determination, field lens module
211 can determine field lens data.
The supplementary module 210 of computing device 204 can be at least partially based on the field lens data being determined above, to determine and institute
The help for stating the key content field lens correlation that graphic user interface includes indicates.Help indicates can be at least partially based on institute
State field lens data and the content possible action to be carried out.The example for helping to indicate can include but is not limited to, and check machine
The comment of structure, bill that is predetermined, obtaining event, the calling taxi of obtaining means take user to address, obtain the side of address
To, search for some artistical music, event is added to calendar, obtain to the help of video-game or search on people,
Information of point or object etc..For example, content can include the name of contact person in restaurant.Based on such content, auxiliary
Module 210 can determine that user may like or find useful various help forms, be included between user and contact person and show
The ejection image of text message for showing the contact card of given contact person or exchanging recently.In another example, content can
With including the appointment time asked.Based on such content, supplementary module 210 can determine that user may be to asking
The time asked checks their current Almanac, event is added to that time of your calendar or checks list of television programmes
To check user because participating in what program is the event may miss together with the contact person.It is interior in another example
Appearance can include organization names.Based on such content, supplementary module 210 can determine that user may or wish to pair
The comment of the mechanism, checks the menu of the mechanism if it is restaurant, or sees the position of the mechanism.
Type based on content, and in some examples including secondary field lens data, supplementary module 210 can determine
Help to one or more key content blocks indicates.For example, above-mentioned field lens data, including from the foreground of display module 218
In content derived from any field lens data, be considered main field lens data.When it is determined that the help indicates, auxiliary
Module 210 can be based on the main field lens data and one group of secondary field lens data or can be from the collected outside of the application
Any field lens data on content further make the determination.For example, secondary field lens data can include current location, when
The preceding time, user identity, cloud computing data, calendar information, associated person information, formerly application and current time and formerly should
With the time relationship between the time of operation.For example, user can have present arrangement in the time proposed in the e-mail
In event.Supplementary module 210 can be based on the time described in Email main field lens data and currently in user's calendar
The secondary field lens data of the event of middle arrangement determine that help indicates, it includes responding the electronics postal with the standby appointment time
Part, the standby appointment time are consistent with the free time in the user's calendar perceived.In another example, electronics is being accessed
Before mail applications, user may check different mechanisms using network browser application.Supplementary module 210 can be with base
Show that web browser applications are that the first of user's access is applied to determine this point in list of application.In current time and
Between the time of the web browser applications operation, i.e., user is in the web browser applications and the e-mail applications
Between time for changing, it is also possible to small time relationship (that is, almost instantaneous) be present.This can be shown that user studies
Mechanism with contact person to meet.Therefore, supplementary module 210 can the main field lens data based on mechanism described in Email with
And include the secondary field lens data set of the mechanism in web browser applications and access the time between the two applications
Relation, to determine that help indicates, it includes responding the contact person, proposes standby mechanism as meeting place.
Supplementary module 210 can utilize the display module 206 of computing device 204 to export help and indicate.The help indicates
Can be any suitable appearance form, such as the coverage diagram on screen, the coverage diagram near the content on screen, graphical user
Pop-up window or audio instruction in interface etc..
For example, as described above, in order to show, supplementary module 210 can be generated for including being covered in graphic user interface
Top edge at the help of content of user interface element indicate that it includes in the event at given mechanism to be added to
The link of the preset time of user's calendar.Indicate to interact with the help and can also start other application, including address book application,
Restaurant review application, TV programme or online Media stream application can be helped based on shown content in next action
Help any other application of user.
Although Fig. 2 technology, supplementary module are described according to one or more operations to computing device 204
210 one or more operations can perform on the remote server.Field lens module 211 can indicate to possible help is determined
Remote server send the field lens data.The remote server can send the field lens data to supplementary module 210,
The latter is responsible for formatting the result and the result is output to screen by (such as coverage diagram) in a particular form.
Fig. 3 is one or more technologies according to the disclosure, shows output screen content to show at remote equipment
The block diagram of exemplary computer device.Generally, screen content can include that any visual information for display can be exported, such as
Text, image, one group of mobile image etc..Example shown in Fig. 3 includes computing device 304, display module 306, communication unit
322nd, projecting apparatus 356, projection screen 358, mobile device 362 and visual display component 366.Although in fig. 1 and 2 for example
And independent computing device 104 and 204 is respectively indicated as, but computing device such as computing device 304 generally can be to include using
In the processor or any component or system of other suitable computing environment that perform software instruction, also, for example, need not wrap
Include display module.
As shown by example in fig. 3, computing device 304 can include the work(as described by for the processor 205 in Fig. 2
The processor of energy property.In such an example, computing device 304 can be operated by communication channel 346A and display module 306
Property coupling, communication channel 346A can be system bus or other suitable are connected.Computing device 304 can also be believed by communicating
Road 346B couples with the operability of communication unit 322 being described further below, communication channel 346B can also be system bus or
Other are suitably connected.Although individually being shown as example in Fig. 3, computing device 304 can pass through any amount of one kind
Or a variety of communication channels couple with display module 306 and the operability of communication unit 322.
In other examples, illustrated by the computing device 204 in computing device 104 and Fig. 2 such as in previously passed Fig. 1
, computing device can refer to portable or mobile device such as mobile phone (including smart phone), laptop computer, intelligence
Wrist-watch etc..In some instances, computing device can be desktop computer, tablet PC, intelligent television platform, game machine,
Remote control, Electrofax, personal digital assistant (PDA), server, main frame etc..
Display module 306, as display module 106 as shown in Figure 1, display module 340 can be included and existed sensitive defeated
Enter component 342.Display module 340 can be with for example, receive data and display screen content from computing device 304.In some examples
In, sensitizing input component 342 be present can be determined at display module 306 using electric capacity, inductance and/or optical recognition
One or more users input (for example, continuous gesture, multi-point touch gesture, single-point touch gesture etc.), and utilize communication channel
346A sends the instruction of such user's input to computing device 304.In some instances, sensitizing input component 342 be present can
With physical positioning at the top of display module 340 so that when input block is positioned at the figure shown by display module 340 by user
When on shape element, the position that wherein shows graphic element of the position correspondence in display module 340 of sensitizing input component 342 be present
Put.In other examples, sensitizing input component 342 be present and may be located remotely from the physical positioning of display module 340, and exist sensitive defeated
The position for entering component 342 can correspond to the position of display module 340 so that can exist it is complete at sensitizing input component 342
Into input to be interacted with the graphic element shown in the corresponding position of display module 340.
As shown in figure 3, computing device 304 can also include communication unit 322 and/or be coupled with its operability.Communication unit
Member 322 can include the feature of communication unit 222 as described in Figure 2.The example of communication unit 322 can include network interface
Card, Ethernet card, optical transceiver, RF transceiver or can send and receive information any other type equipment.So
Communication unit other examples can include bluetooth, 3G and Wi-Fi radio, USB (USB) interface etc..Calculate
Equipment 304 can also include one or more of the other equipment, such as input module, output precision, memory, storage device etc.
And/or coupled with its operability, the other equipment is not shown in figure 3 for succinct and explanation purpose.
Fig. 3 also show projecting apparatus 356 and projection screen 358.Other such examples of projector equipment can include electronics
Blank, holographic display module and any other suitable equipment for display screen content.Projecting apparatus 356 and projection screen 358
One or more communication units can be included, it enables corresponding equipment to be communicated with computing device 304.In some instances,
One or more of communication units can make communicate between projecting apparatus 356 and projection screen 358.Projecting apparatus 356 can be from
Computing device 304 including screen content receives data.Projecting apparatus 356, can be by screen content in response to receiving the data
Project on projection screen 358.In some instances, projecting apparatus 356 can utilize optical identification or other suitable technologies throwing
Determine that one or more users input (for example, continuous gesture, multi-point touch gesture, single-point touch gesture etc.) at shadow screen, and profit
Such user input instruction is sent to computing device 304 with one or more communication units.In such an example, project
Screen 358 can be unnecessary, and projecting apparatus 356 can project screen content on any suitable medium, and utilize light
Knowledge is other or other such proper technologies input to detect one or more users.
In some instances, projection screen 358 can include sensitive display 360 being present.Sensitive display 360 be present can be with
Functional subset or all functionality including display module 106 as described in this disclosure.In some instances, exist quick
Additional feature can be included by feeling display 360.Projection screen 358 (for example, electronic whiteboard) can receive from computing device 304
Data and display screen content.In some instances, sensitive display 360 be present can utilize electric capacity, inductance and/or optics to know
Other technology determines one or more user's inputs (for example, continuous gesture, multi-point touch gesture, single-point touch at projection screen 358
Gesture etc.), and the instruction of such user's input is sent using one or more communication units to computing device 304.
Fig. 3 also show mobile device 362 and visual display component 366.Mobile device 362 and visual display component 366
Calculating and concatenation ability can each be included.The example of mobile device 362 can include electronic reader devices, convertible notes
This equipment, a mixing flat board equipment etc..The example of visual display component 366 can include other semifixed equipment such as television sets,
Computer monitor etc..As shown in figure 3, mobile device 362 can include sensitive display 364 being present.Visual display component 366
It can include sensitive display 368 being present.Sensitive display 364,368 be present can be including display group as described in this disclosure
The functional subset or all functionality of part 306.In some instances, exist sensitive display 364,368 can include it is attached
The feature added.Under any circumstance, sensitive display 364 be present, for example, data can be received from computing device 304 and shown
Show screen content.In some instances, sensitive display 368 be present can be existed using electric capacity, inductance and/or optical recognition
Determine that one or more users input (for example, continuous gesture, multi-point touch gesture, single-point touch gesture etc.) at projection screen, and
The instruction of such user's input is sent to computing device 304 using one or more communication units.
As described above, in some instances, computing device 304 can be with output screen content to show at display module 306
Show, the display module is coupled by system bus or other suitable communication channels with computing device 304.Computing device 304
It can also export for showing in one or more remote equipments such as projecting apparatus 356, projection screen 358, mobile device 362 and visually
Show the screen content shown at component 366.For example, according to the technology of the disclosure, computing device 304 can perform one or more
Instruct to generate and/or change screen content.Computing device 304 can be by the data output including screen content to computing device
304 communication unit, such as communication unit 322.Communication unit 322 can transmit data to one or more remote equipments,
Such as projecting apparatus 356, projection screen 358, mobile device 362 and/or visual display component 366.By this way, computing device
304 can be with output screen content to be shown on one or more remote equipments.In some instances, it is one or more described remote
Journey equipment can at display module output screen content, the display module be included in corresponding remote equipment and/or with
Its operability coupling.
In some instances, computing device 304 can not be in the display module 306 coupled with the operability of computing device 304
Locate output screen content.In other examples, computing device 304 can be with output screen content both to pass through communication channel 346A
Shown again at one or more remote equipments at the display module 306 coupled with computing device 304.In such an example,
The screen content can substantially simultaneously be shown at each relevant device.For example, it can be introduced by communication delay
Data including the screen content are sent to the remote equipment by delay.In some instances, by computing device 304
Generate and export to can be differently configured from the screen content shown at display module 306 and be output for one or more long-range
The screen content shown in equipment is shown.
Computing device 304 can utilize any suitable communication technology to send and receive data.For example, computing device 304
Network link 348A can be utilized to be coupled with the operability of external network 350.The each remote equipment shown in Fig. 3 can pass through phase
One of network link 348B, 348C and 348D for answering couple with the operability of external network 350.External network 350 can include net
Network hub, the network switch, network router etc., their operational mutual coupling, so as to provide shown in computing device 304 and Fig. 3
Remote equipment between information exchange.In some instances, network link 348A-348D can be Ethernet, ATM or other
Network connection.Such connection can be wireless and/or wired connection.
In some instances, computing device 304 can utilize direct equipment communication 354, one or more included with Fig. 3
The individual remote equipment operability coupling.Direct equipment communication 354 can utilize wired or wireless communication including computing device 304
The communication of data is directly sent and received with remote equipment.That is, in some examples of direct equipment communication 354, meter
Calculate the data that equipment 304 is sent not forwarded by one or more optional equipments before receiving at remote equipment, instead
It is as the same.The example of direct equipment communication 354 can include bluetooth, near-field communication, USB, WiFi, infrared ray etc..
One or more remote equipments shown in Fig. 3 can pass through communication link 352A-352D and 304 operational coupling of computing device
Close.In some instances, communication link 352A-352D can utilize bluetooth, near-field communication, USB, infrared ray
Deng connection.Such connection can be wireless and/or wired connection.
As described above, the graphic user interface that computing device 304 can export application is used in display module (for example, throwing
Shadow instrument 356, mobile device 362 or visual display component 366) place shows.The application can be included in the computing device
In one group of application for locating operation.Pair determine that the graphic user interface of the application is output with the foreground of the display module
Display is responded, and computing device 304 can determine field lens data from the content that graphic user interface includes.At least part base
In the field lens data, the related side of computing device 304 can determine to the graphic user interface includes content field lens
Help instruction.Computing device 304 can export the help and indicate.
Fig. 4 is the one or more aspects according to the disclosure, shows the concept map of example system for including server apparatus,
The screen field lens of determination of the server apparatus based on long-range display module provides help and indicated.Fig. 4 technology can be by counting
The one or more processors for calculating equipment perform, such as distinguish computing device 104 and 204 shown in fig. 1 and 2.In order to
The purpose of explanation, Fig. 4 technology describe in the field lens of Fig. 1 computing device 104, but have and be different from computing device 104
The computing device of configuration can perform Fig. 4 technology.
According to the technology of the disclosure, the display module (for example, display module 106) of computing device 104 can export application
Graphic user interface 470.In the example of fig. 4, the display module 106 of computing device 104 can export description video-game
Rank, such as " jump people (Jumping Man) " the game application 108B fabricated 3 grades of graphic user interface 470.
The field lens module 111 of computing device 104 can determine that the graphic user interface 470 of application is output with display group
Shown in the foreground of part 118.In doing so, field lens module 111 can access the view level by the application management.Field lens
Which application is module 111 can determine with currently exporting graphic user interface 470 phase for being shown in display module 106
Association.For example, field lens module 111 can determine that the application is associated with the graphic user interface 470 of the application or with it
His mode generates the graphic user interface 470 of the application.As described above, field lens module 111 can use operating system authority to grasp
Make, or realize or can visit in the permission field lens module 111 of computing device 104 accesses the run-time library of the list of application
The run-time library is asked, to determine the application associated with the graphic user interface in foreground.Field lens module 111, which can be analyzed, to be worked as
The view level of preceding display screen and view object are to determine content and field lens data.In some instances, content can be by
Any project that computing device exports in such as graphic user interface.The example of view object can include but is not limited to text
Information, image information, frame information, linear information, pattern information or button information, etc..
Pair determine to be output to show progress in the foreground of display module 106 using 108B graphic user interface 470
Response, the field lens module 111 of computing device 104 can determine field lens data from the content being included in graphic user interface 470.
In some instances, field lens data can be the general description of the determination of the content.The example of field lens data can include
But it is not limited to, the content is restaurant name, the rank of video-game, attached perigean address, singer's name or calendar thing
The determination of part etc..
In the example of fig. 4, graphic user interface 470 only includes graph image.So, it is determined that during field lens data, meter
The field lens module 111 of calculation equipment 104 can capture the graphic user interface 470 of the application shown in the foreground of display module
Screenshot capture.Field lens module 111 can carry out graphical analysis to the screenshot capture.For example, field lens module 111 can interconnect
It is online to perform picture search to determine the content described in graphic user interface 470.In the example of fig. 4, on internet
Picture search the content of image can be provided with field lens module 111 include 3 grades of information of fictive play " jump people ".It is based on
The graphical analysis, field lens module 111 can determine field lens data.
Supplementary module 110 can be at least partially based on the field lens data that are determined above to determine and graphic user interface 470
The help of the content field lens correlation included indicates.Help indicates can be at least partially based on field lens data and described interior
Hold the possible action to be carried out.Help the example that indicates to include but is not limited to, check the comment of mechanism, obtaining means
Bill that is predetermined, obtaining event, calling taxi are by user takes address, the direction for obtaining address to, to search for some artistical
Music, event is added to calendar, obtains to the help of video-game or searches for information on people, place or thing etc..
In the example of fig. 4, supplementary module 110 can operate on remote server 474.So, field lens module 111 can
So that field lens data are sent into remote server 474, remote server 474 determines the information for helping to indicate.Remote service
Device 474 can be set by using the calculating of the computing device operation connection of the network and client that wiredly and/or wirelessly connect
It is standby.For example, remote server 474 can be server computing device or desk-top computing device.Auxiliary on remote server 474
Module 110 can determine that the help indicates, and field lens module 111 can receive the help from supplementary module 110 and indicate
Information.
In the example of fig. 4, the main field lens data can include 3 DBMSs of game " jump people ".Other are secondary
Field lens data, if you are using, can be including the general of 3 grades of the time quantum of user in this application or game " jump people "
Difficulty.Based on the field lens data, supplementary module 110 can determine user will be brought to for how to win game " jump people "
3 grades of strategy instruction, or user drill the video for being brought to this rank.
Field lens module 111 can utilize the display module 106 of computing device 104 to export help and indicate 472.The help refers to
Show it can is any suitable appearance form, such as the coverage diagram on screen, the coverage diagram near the content on screen, figure are used
Pop-up window or audio instruction in the interface of family etc..In the example of fig. 4, help to indicate that 472 be graphic user interface 470
Interior pop-up window.With helping to indicate that 472 interact and can start web page browsing application, it is loaded with how discussion wins game
3 grades of the website of " jump people ".In other examples, with helping to indicate that 472 interact and can start with to the specific level
The video stream application of Video tutorials.
Fig. 5 is the one or more aspects according to the disclosure, shows to realize the calculating for being used for the technology that determination help indicates
The flow chart of the exemplary operation of equipment.Fig. 5 technology can be by computing device, such as distinguishes meter shown in fig. 1 and 2
The one or more processors for calculating equipment 104 and 204 perform.For illustrative purposes, computing device of Fig. 5 technology in Fig. 1
Described in 104 field lens, but the computing device with the configuration different from computing device 104 can also perform Fig. 5 technology.
According to the technology of the disclosure, the display module (for example, display module 106) of computing device 104 can export application
The graphic user interface (for example, graphic user interface 112) (582) of (for example, using 118A) is used to grasp with computing device 104
Shown on the display module (for example, display module 118) of the property made coupling.Field lens module 111 can access the application being currently running
108 view level, and identify the view object that the view level shows in graphical user interfaces.Field lens module 111
It can determine which application is related for the graphic user interface 112 that is shown in the foreground of display module 106 to currently exporting
Connection.For example, field lens module 111 can determine using 108A with for apply 108A graphic user interface 112 it is associated or with
Other modes are generated for the graphic user interface 112 using 108A.In some instances, currently export with display module
The graphic user interface 112 shown on 106 can be associated with the application checked or accessed recently.As described above, field lens module
111 can use operating system limiting operation, or access the list of application in the permission field lens module 111 of computing device 104
Run-time library in realize or can access the run-time library, so as to determine the application associated with the graphic user interface and
The view level of the application.Field lens module 111 can access the content of current display view.In some instances, content can
To be any project exported by computing device in such as graphic user interface.The example of view object can include but unlimited
In text message, image information, frame information, linear information, pattern information or button information, etc..Field lens module 111 can be entered
At least one attribute of view object described in onestep extraction, and at least one attribute is at least partially based on to determine field lens
Data.
Pair determine to be output to show progress in the foreground of display module 106 using 108A graphic user interface 112
Response, the field lens module 111 of computing device 104 can be from the content being included in graphic user interface 112 (for example, content
114A-114C) determine field lens data (584).The content of the graphic user interface 112 can not only include screenshot capture can be with
The content visible of the type of capture, the additional content for being available from view object and view level can also be included.In some examples
In, field lens data can be the general description by the determination of content determined by following any one：(i) by display module 106
The analysis of the text of display, icon, image and video；And/or (b) supports the visible text, icon, image and video
The analysis of the attribute of view object.The example of field lens data can include but is not limited to, and the content is restaurant name, video trip
The determination of the rank of play, attached perigean address, singer's name or calendar event etc..
The supplementary module 110 of computing device 104 can be at least partially based on field lens data determined above to determine and scheme
The help for the content 114A-114C field lenses correlation that shape user interface 112 includes indicates (586).Help indicates it can is at least
It is based partially on the field lens data and the content possible action to be carried out.Helping the example that indicates can include but unlimited
In checking the comment of mechanism, bill that is predetermined, obtaining event, the calling taxi of obtaining means take user to address, obtained
The direction of address, search for some artistical music, the help or search of event, acquisition to video-game are added to calendar
Information on people, place or thing etc..
Supplementary module 110 can utilize the display module 106 of computing device 104 to export help and indicate (588).The help
Indicate it can is any suitable appearance form, such as the coverage diagram on screen, the coverage diagram near the content on screen, figure
Pop-up window or audio instruction in user interface etc..
Although Fig. 1 technology, supplementary module are described for one or more operations on computing device 104
110 one or more operations can perform on the remote server.Field lens data can be sent to determination by field lens module 111
The possible remote server for helping to indicate, is then sent to supplementary module 110, and supplementary module 110 is responsible for formatting institute
State result and the result is output to screen by (such as coverage diagram) in a particular form.
Field lens, computing device are determined by the content based on the graphic user interface shown in the foreground of display module
Can next action possible to user make suggestion, and not against application developer in the application code of itself it is bright
Really include field lens information.By this way, the technology of the disclosure can provide for mobile device determines possible next action
Ability, and any application that can be run for computing device provide help indicate without application developer include it is any attached
Add code, so as to simplify the code of the application run on the computing device.By being extracted from the screen just shown by the application
Text and/or image, the content is supplied to the supplementary module for utilizing the field lens by the technology of the disclosure, to be existed based on user
The content that content rather than application developer are clearly provided by hard coded field lens information done in any possible application, come
Offer indicates on the possible help next acted.Determine content providing feature for computing device and field lens is provided
When, it is simplified using coding, and can be applied in main developer with reliable way and generally be carried between third-party application
For helping.In addition, the technology of the disclosure can allow more widely to help to the screen content for being output display.
A kind of 1. method of embodiment, it is included：By computing device and for being coupled with the computing device operation
Display module at show, export the graphic user interface of application；Determined from the content being included in the graphic user interface
Field lens data；The field lens data are at least partially based on, it is determined that related to the content field lens that the graphic user interface includes
Help indicate；And the help is exported by the computing device and indicated.
Embodiment 2. is according to the method for embodiment 1, wherein determining that the field lens packet contains：Access at the computing device
View level；And the view object that the identification view level shows in the graphic user interface.
Embodiment 3. also includes according to the method for embodiment 2：Extract at least one attribute of the view object；And
At least one attribute is at least partially based on to determine at least a portion of the field lens data.
Embodiment 4. is according to any one of embodiment 1-3 method, wherein in including from the graphic user interface
The field lens data of appearance are main field lens data, and wherein determine that the help indicates to include：It is at least partially based on the figure
The main field lens data and secondary field lens data of user interface come determine it is described help indicate, wherein the secondary field lens data
Comprising position, the time, user identity, cloud computing data, calendar information, associated person information, formerly application and current time and
It is at least one in time relationship between the time of the previously application operation.
Embodiment 5. is according to any one of embodiment 1-4 method, wherein determining that the field lens packet contains：Capture is described should
The screenshot capture of graphic user interface；Graphical analysis is performed to screenshot capture；And it is at least partially based on described image point
Analyse to determine the field lens data.
Embodiment 6. contains according to the method for embodiment 5 wherein performing described image analysis bag：The screenshot capture is performed
Optical character recognition process is to determine one or more of screenshot capture character；And it is at least partially based on one
Or multiple characters determine the field lens data.
Embodiment 7. is according to any one of embodiment 1-6 method, wherein determining that the field lens packet contains：Analysis is described should
View level；The view object included for the view level：Identify the view object；It is determined that with being identified
The associated information of view object；And identified information is at least partially based on to determine at least a portion field lens number
According to.
Embodiment 8. is according to any one of embodiment 1-7 method, wherein determining that the help indicates also to include：To long-range meter
Calculate equipment and send the field lens data, wherein the remote computing device determines that being used for the help indicates from the field lens data
Information；Received from the remote computing device for the information for helping to indicate；And described information is at least partially based on,
Generate and indicated for the help of declaration.
A kind of 9. computing device of embodiment, it is included：At least one processor；With at least one module, it can be by described
At least one processor operation, to：The graphic user interface of output application is used to couple with the computing device operation
Display module on show；Field lens data are determined from the content being included in the graphic user interface；It is at least partially based on institute
Field lens data are stated, it is determined that the help related to the content field lens that the graphic user interface includes indicates；And described in output
Help indicates.
Embodiment 10. according to the computing device of embodiment 9, wherein at least one module on said computing device with
Operating system authority is performed, and wherein described at least one module can be operated by least one processor, to：Extraction
At least one attribute of the view object；And at least one attribute is at least partially based on to determine at least a portion institute
State field lens data.
Embodiment 11. is according to any one of embodiment 9-10 computing device, wherein can be grasped by least one processor
At least one module made can be operated further, to：The field lens data are sent to remote computing device, wherein described
Remote computing device determines the information for helping to indicate from the field lens data；Received from the remote computing device for institute
State the information for helping to indicate；And it is at least partially based on described information and generates and indicated for the help of declaration.
Embodiment 12. is according to any one of embodiment 9-11 computing device, wherein being wrapped in the graphic user interface
The field lens data of the content included are main field lens data, and wherein described at least one module can be operated further, to：Extremely
Be at least partly based on the graphic user interface main field lens data and secondary field lens data come determine it is described help indicate, its
Described in secondary field lens packet containing position, the time, user identity, cloud computing data, calendar information, associated person information, formerly
Using and current time and it is described previously application operation time between time relationship in it is at least one.
Embodiment 13. is according to any one of embodiment 9-12 computing device, wherein at least one module can be by described
At least one processor operation, to：Capture the screenshot capture of the graphic user interface；Image is performed to the screenshot capture
Analysis；And it is at least partially based on described image analysis and determines the field lens data.
Embodiment 14. is according to the computing device of embodiment 13, wherein at least one module can be by described at least one
Processor operates, to：Optical character recognition process is performed on the screenshot capture to determine one in the screenshot capture
Individual or multiple characters；And one or more of characters are at least partially based on to determine the field lens data.
Embodiment 15. is according to any one of embodiment 9-14 computing device, wherein at least one module can be by described
At least one processor operation determines field lens data with the content included from the graphic user interface, to：In the meter
Calculate the view level of the analysis application at equipment；Figure use that identification includes in the view level, in the application
The view object showed in the current screen image at family interface；For being included in the view object in the view level：It is determined that
The information associated with the view object；And identified information is at least partially based on to determine the field lens data.
A kind of computer-readable recording medium with instruction encoding of embodiment 16., the instruction is when implemented so that calculates
At least one processor of equipment：The graphic user interface of output application is used for aobvious what is coupled with the computing device operation
Show and shown at component；Field lens data are determined from the content being included in the graphic user interface；It is at least partially based on the field
Mirror data determine that the help related to the content field lens that the graphic user interface includes indicates；And the output help refers to
Show.
Embodiment 17. is according to the computer-readable recording medium of embodiment 16, wherein causing at least one processor
Determine that the instruction for helping to indicate includes following instructions, it causes the described of the computing device upon being performed
At least one processor：The field lens data are sent to remote computing device, wherein the remote computing device determines to be used for
The information for helping to indicate；Received from the remote computing device for the information for helping to indicate；And at least partly
Based on described information, generate from the field lens data and indicated for the help of declaration.
Embodiment 18. is according to any one of embodiment 16-17 computer-readable recording medium, wherein causing described at least one
Individual processor determines that the instruction of the field lens data includes following instructions, and it causes the computing device upon being performed
At least one processor：Access the view level at the computing device；Identify that the view level is used in the figure
The view object showed in the interface of family；Extract at least one attribute of the view object；And described in being at least partially based on extremely
Lack an attribute to determine at least a portion field lens data.
Embodiment 19. is according to the computer-readable recording medium of any one of embodiment 17 or 18, wherein from the figure
The field lens data for the content that user interface includes are main field lens data, and wherein cause at least one processor true
The fixed instruction for helping to indicate includes following instructions, its upon being performed, cause the computing device it is described extremely
A few processor is at least partially based on the main field lens data and secondary field lens data set to determine that the help indicates,
The collection of wherein described secondary field lens data includes position, time, user identity, cloud computing data, calendar information, contact person's letter
It is at least one in time relationship between the time of breath, formerly application and current time and the previously application operation.
Embodiment 20. is according to any one of embodiment 17-19 computer-readable recording medium, wherein causing described at least one
Individual processor determines that the instruction of the field lens data includes following instructions, and it causes the calculating to set upon being performed
Standby at least one processor：Capture the screenshot capture of the graphic user interface；Image is performed to the screenshot capture
Analysis；And it is at least partially based on described image analysis and determines the field lens data.
In one or more examples, described function can be real in hardware, software, firmware or its any combinations
It is existing.If realized in software, the function can be used as one or more instructions or code to be stored in computer-readable Jie
Transmit in matter or through computer computer-readable recording medium, and performed by hardware based processing unit.Computer-readable medium can include
Computer-readable recording medium, it corresponds to tangible medium such as data storage medium, or communication media, including is easy to calculate
Machine program is for example sent to any medium of another place according to communication protocol from a place.By this way, computer
Computer-readable recording medium can correspond generally to (1) tangible computer-readable recording medium, and it is nonvolatile, or (2) communication media
Such as signal or carrier wave.Data storage medium can be can be accessed by one or more computers or one or more processors with
Retrieve any usable medium of instruction, code and/or the data structure for realizing the technology described in the disclosure.Computer journey
Sequence product can include computer-readable medium.
A kind of 21. equipment of embodiment, it includes the mechanism for being used for performing any combination of method according to embodiment 1-8.
A kind of computer-readable recording medium with instruction encoding of embodiment 22., the instruction upon being performed, cause meter
At least one computing device of equipment is calculated according to embodiment 1-8 any combination of method.
In the whole disclosure, example is described, wherein computing device and/or computing system only can be set in the calculating
It is standby receive user license analysis described information when, could analyze the information associated with the computing device (for example, position,
Speed etc.).For example, the computing device being discussed below can be collected or can utilize the information associated with user
In the case of, user can be provided the chance of input control the program of the computing device or feature whether can collect and
Using user profile (for example, information on user current location, present speed etc.), or whether indicate the computing device
And/or how can receive may be related to user content.In addition, some data by computing device and/or calculate system at it
It can be handled before system storage or use with one or more modes, so as to eliminate personally identifiable information.For example, use can be handled
The identity at family so that not can determine that the personally identifiable information on user, or obtaining positional information (such as city, postal service
Coding or state level) in the case of, the geographical position of user can generally be changed so that not can determine that the particular location of user.Cause
And user can be for controlling how collect on the user and the information that is used by the computing device.
Unrestricted as example, such computer-readable recording medium can include RAM, ROM, EEPROM, CD-
ROM or other disk storages, magnetic disk storage or other magnetic storage apparatus, flash memory or available for instruct or number
According to the required program code of the form storage of structure and any other medium that can be accessed by computer.Further, any connection quilt
It is properly termed as computer-readable medium.If for example, utilize coaxial cable, fiber optic cables, twisted-pair feeder, Digital Subscriber Line
(DSL) or wireless technology such as infrared ray, radio and microwave send from website, server or other remote sources and instructed, then institute
State coaxial cable, fiber optic cables, twisted-pair feeder, DSL or wireless technology such as infrared ray, radio and microwave and be included in determining for medium
In justice.It will be appreciated, however, that computer-readable recording medium and data storage medium include connection, carrier wave, signal or other
Fugitive medium, and it is directed to the tangible media of non-transitory.Used disk and CD include compact disk (CD),
Laser-optical disk, optical compact disks, digital versatile disc (DVD), floppy disc and Blu-ray Disc, wherein disk are generally magnetically again
Existing data, and CD reproduce data by laser optics.Combinations of the above should also be included in the scope of computer-readable medium
It is interior.
Instruction can be performed by one or more processors, such as one or more digital signal processors (DSP), general
Microprocessor, application specific integrated circuit (ASIC), FPGA (FPGA) or other equivalent integrated or discrete patrol
Collect circuit.Therefore, term " processor " can refer to any foregoing structure or be adapted for carrying out any of the technology when in use
Other structures.In addition, in some respects, described feature can provide in specialized hardware and/or software module.These
Technology can also fully achieve in one or more circuits or logic element.
The technology of the disclosure can be realized in diversified device or equipment, including wireless phone, integrated circuit
Or IC groups (for example, chipset) (IC).Various assemblies, module or unit are described in the disclosure to emphasize to be configured to perform
In terms of the function of the equipment of disclosed technology, but it is not necessarily required to by different hardware cell realizations.On the contrary, as described above,
Various units can be combined in hardware cell or by many interoperability including one or more processors as described above
Property hardware cell is combined to provide with appropriate software and/or firmware.
It should be appreciated that depend on the embodiment, some actions of any method described herein or event can be by
Different order performs, and can add, merges or omit completely that (to be described action or event be all to put into practice for example, no
Necessary to methods described).In addition, in some embodiments, action or event can for example pass through multiple threads, interruption
Processing or multiple processors perform simultaneously, rather than perform successively.
In some instances, computer-readable recording medium can include non-transitory medium.Term " non-transitory " can
To indicate that the storage medium is not included in carrier wave or transmitting signal.In some examples, non-transitory storage medium can be with
Store the data (for example, in RAM or cache) that can change with the time.
The various examples of the disclosure have been described.Any group of described system, operation or function is thought over
Close.These and other examples are within the scope of the appended claims.
Claims (15)
1. a kind of method, comprising：
The graphic user interface of application is exported and in the display coupled with the computing device operation by computing device
Shown at component；
Field lens data are determined from the content included in the graphic user interface for being output for display；
The field lens data are at least partially based on, it is determined that related to the content field lens included in the graphic user interface
Help indicate；And
The help is exported by the computing device to indicate.
2. according to the method for claim 1, wherein determining that the field lens packet contains：
Access the view level at the computing device；And
Identify the view object that the view level shows in the graphic user interface.
3. according to the method for claim 2, also include：
Extract at least one attribute of the view object；And
At least one attribute is at least partially based on, determines at least a portion of the field lens data.
4. according to the method described in any one of claim 1-3, wherein coming what the comfortable graphic user interface included
The field lens data of content are main field lens data, and wherein determine that the help indicates to include：
Be at least partially based on the graphic user interface main field lens data and secondary field lens data come determine it is described help refer to
Show, wherein the secondary field lens packet containing position, the time, user identity, cloud computing data, calendar information, associated person information,
It is formerly at least one in the time relationship between application and current time and the time that application is run described formerly.
5. according to the method described in any one of claim 1-4, wherein determining that the field lens packet contains：
Capture the screenshot capture of the graphic user interface of the application；
Graphical analysis is carried out to the screenshot capture；And
It is at least partially based on described image analysis and determines the field lens data.
6. according to the method for claim 5, contain wherein carrying out described image analysis bag：
Optical character recognition process is carried out to the screenshot capture to determine one or more of screenshot capture character；With
And
It is at least partially based on one or more of characters and determines the field lens data.
7. according to the method described in any one of claim 1-6, wherein determining that the field lens packet contains：
Analyze the view level of the application；
The view object included for the view level：
Identify the view object；
It is determined that the information associated with the view object identified；And
Identified information is at least partially based on to determine at least a portion of the field lens data.
8. according to the method described in any one of claim 1-7, wherein determining that the help indicates also to include：
The field lens data are sent to remote computing device, wherein the remote computing device determines to be used for from the field lens data
The information for helping to indicate；
Received from the remote computing device for the described information for helping to indicate；And
Described information is at least partially based on, generates and is indicated for the help of declaration.
9. a kind of computing device, comprising：
At least one processor；With
At least one module, it can be operated by least one processor, to：
The graphic user interface of application is exported, for being shown at the display module coupled with the computing device operation；
Field lens data are determined from the content being included in the graphic user interface；
The field lens data are at least partially based on, it is determined that related to the content field lens that the graphic user interface includes
Help indicates；And
The help is exported to indicate.
10. computing device according to claim 9, wherein at least one module is on said computing device with operation
System Privileges are performed, and wherein described at least one module can be operated by least one processor, to：
Extract at least one attribute of the view object；And
At least one attribute is at least partially based on to determine at least a portion of the field lens data.
11. according to the computing device described in any one of claim 9 or 10, wherein can be by least one processor
At least one module of operation can be operated further, to：
The field lens data are sent to remote computing device, wherein the remote computing device determines to be used for from the field lens data
The information for helping to indicate；
Received from the remote computing device for the described information for helping to indicate；And
It is at least partially based on described information and generates and is indicated for the help of declaration.
12. according to the computing device described in any one of claim 9-11, wherein coming in the comfortable graphic user interface
Including the field lens data of content be main field lens data, and wherein described at least one module can be grasped further
Make, to：
Be at least partially based on the graphic user interface main field lens data and secondary field lens data come determine it is described help refer to
Show, wherein the secondary field lens packet containing position, the time, user identity, cloud computing data, calendar information, associated person information,
It is at least one in formerly application and the time relationship between current time and the time that application is run described formerly.
13. according to the computing device described in any one of claim 9-12, wherein at least one module can be by institute
At least one processor operation is stated, to：
Capture the screenshot capture of the graphic user interface；
Graphical analysis is carried out to the screenshot capture；
Optical character recognition process is carried out to the screenshot capture to determine one or more of screenshot capture character；With
And
One or more of characters are at least partially based on to determine the field lens data.
14. according to the computing device described in any one of claim 9-13, wherein at least one module can be by institute
At least one processor operation is stated to determine field lens data from the content included in the graphic user interface, to：
The view level of the application is analyzed at the computing device；
It is that identification shows in the current screen image of the graphic user interface of the application, include in the view level
View object；
For the view object included in the view level：
It is determined that the information associated with the view object；And
Identified information is at least partially based on to determine the field lens data.
15. a kind of computer-readable recording medium with instruction encoding, the instruction upon being performed, causes computing device extremely
A few processor carries out any of the method according to claim 1-8 method.
Applications Claiming Priority (5)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201562167257P | 2015-05-27 | 2015-05-27 | |
US62/167,257 | 2015-05-27 | ||
US14/804,861 US20160350136A1 (en) | 2015-05-27 | 2015-07-21 | Assist layer with automated extraction |
US14/804,861 | 2015-07-21 | ||
PCT/US2016/033240 WO2016191188A1 (en) | 2015-05-27 | 2016-05-19 | Assist layer with automated extraction |
Publications (1)
Publication Number | Publication Date |
---|---|
CN107533465A true CN107533465A (en) | 2018-01-02 |
Family
ID=56101795
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201680019339.3A Pending CN107533465A (en) | 2015-05-27 | 2016-05-19 | Auxiliary layer with automation extraction |
Country Status (6)
Country | Link |
---|---|
US (1) | US20160350136A1 (en) |
EP (1) | EP3304287A1 (en) |
CN (1) | CN107533465A (en) |
DE (1) | DE112016002384T5 (en) |
GB (1) | GB2553443A (en) |
WO (1) | WO2016191188A1 (en) |
Families Citing this family (8)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN105955618B (en) * | 2016-04-29 | 2019-07-05 | 北京小米移动软件有限公司 | Information display method and device |
US10810278B2 (en) | 2017-04-18 | 2020-10-20 | Google Llc | Contextual deep bookmarking |
US10824293B2 (en) * | 2017-05-08 | 2020-11-03 | International Business Machines Corporation | Finger direction based holographic object interaction from a distance |
JP6858885B2 (en) * | 2018-03-20 | 2021-04-14 | 深▲セン▼前▲海▼▲達▼▲闥▼▲雲▼端智能科技有限公司Ｃｌｏｕｄｍｉｎｄｓ （Ｓｈｅｎｚｈｅｎ） Ｒｏｂｏｔｉｃｓ Ｓｙｓｔｅｍｓ Ｃｏ．， Ｌｔｄ． | Guest operating system screenshots on computer devices Methods and equipment |
EP3788509A1 (en) | 2018-06-28 | 2021-03-10 | Google LLC | Annotation and retrieval of contextual deep bookmarks |
US11165786B2 (en) * | 2018-12-18 | 2021-11-02 | International Business Machines Corporation | Remote assistance controller that provides control over what a remote assistor can access |
CN110018827B (en) * | 2019-04-03 | 2020-10-30 | 拉扎斯网络科技（上海）有限公司 | Method and device for automatically generating code, electronic equipment and readable storage medium |
US11782569B2 (en) * | 2021-07-26 | 2023-10-10 | Google Llc | Contextual triggering of assistive functions |
Citations (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20020118220A1 (en) * | 1999-05-07 | 2002-08-29 | Philip Lui | System and method for dynamic assistance in software applications using behavior and host application models |
US20090112832A1 (en) * | 2007-10-30 | 2009-04-30 | International Business Machines Corporation | Intelligent content assistance |
US20120233567A1 (en) * | 2011-03-11 | 2012-09-13 | Microsoft Corporation | Providing item specific functionality via service-assisted applications |
CN102725729A (en) * | 2009-12-29 | 2012-10-10 | 国际商业机器公司 | Analyzing objects from a graphical interface for standards verification |
Family Cites Families (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7000187B2 (en) * | 1999-07-01 | 2006-02-14 | Cisco Technology, Inc. | Method and apparatus for software technical support and training |
US8151192B2 (en) * | 2008-02-01 | 2012-04-03 | Microsoft Corporation | Context sensitive help |
US8918739B2 (en) * | 2009-08-24 | 2014-12-23 | Kryon Systems Ltd. | Display-independent recognition of graphical user interface control |
US9436274B2 (en) * | 2011-06-30 | 2016-09-06 | International Business Machines Corporation | System to overlay application help on a mobile device |
US20130346347A1 (en) * | 2012-06-22 | 2013-12-26 | Google Inc. | Method to Predict a Communicative Action that is Most Likely to be Executed Given a Context |
WO2015034826A1 (en) * | 2013-09-06 | 2015-03-12 | Smugmug, Inc. | Contextual help system |
US20150248651A1 (en) * | 2014-02-28 | 2015-09-03 | Christine E. Akutagawa | Social networking event planning |
-
2015
- 2015-07-21 US US14/804,861 patent/US20160350136A1/en not_active Abandoned
-
2016
- 2016-05-19 CN CN201680019339.3A patent/CN107533465A/en active Pending
- 2016-05-19 WO PCT/US2016/033240 patent/WO2016191188A1/en active Application Filing
- 2016-05-19 GB GB1715439.4A patent/GB2553443A/en not_active Withdrawn
- 2016-05-19 EP EP16727266.5A patent/EP3304287A1/en not_active Withdrawn
- 2016-05-19 DE DE112016002384.7T patent/DE112016002384T5/en not_active Withdrawn
Patent Citations (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20020118220A1 (en) * | 1999-05-07 | 2002-08-29 | Philip Lui | System and method for dynamic assistance in software applications using behavior and host application models |
US20090112832A1 (en) * | 2007-10-30 | 2009-04-30 | International Business Machines Corporation | Intelligent content assistance |
CN102725729A (en) * | 2009-12-29 | 2012-10-10 | 国际商业机器公司 | Analyzing objects from a graphical interface for standards verification |
US20120233567A1 (en) * | 2011-03-11 | 2012-09-13 | Microsoft Corporation | Providing item specific functionality via service-assisted applications |
Also Published As
Publication number | Publication date |
---|---|
GB201715439D0 (en) | 2017-11-08 |
GB2553443A (en) | 2018-03-07 |
EP3304287A1 (en) | 2018-04-11 |
DE112016002384T5 (en) | 2018-03-15 |
WO2016191188A1 (en) | 2016-12-01 |
US20160350136A1 (en) | 2016-12-01 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN112416484B (en) | Accelerating task execution | |
CN109328381B (en) | Detect the triggering of digital assistants | |
CN107533465A (en) | Auxiliary layer with automation extraction | |
CN107491285B (en) | Smart machine arbitration and control | |
Emmanouilidis et al. | Mobile guides: Taxonomy of architectures, context awareness, technologies and applications | |
CN104364753B (en) | Method for highlighting active interface element | |
CN110364148A (en) | Natural assistant's interaction | |
CN108733438A (en) | Application program is integrated with digital assistants | |
CN110019752A (en) | Multi-direction dialogue | |
CN110021301A (en) | The far field of digital assistants service extends | |
CN107493374A (en) | Application integration with digital assistants | |
CN107608998A (en) | Application integration with digital assistants | |
CN110457000A (en) | For delivering the intelligent automation assistant of content according to user experience | |
CN107949823A (en) | Zero-lag digital assistants | |
CN108874766A (en) | Method and system for the voice match in digital assistants service | |
CN107924313A (en) | Distributed personal assistant | |
CN108205376A (en) | It is predicted for the legend of dialogue | |
CN108292203A (en) | Active assistance based on equipment room conversational communication | |
CN107491258A (en) | For the equipment, method and graphic user interface in span mode lower-pilot window | |
CN107615276A (en) | Virtual assistant for media playback | |
CN107257950A (en) | Virtual assistant continuity | |
CN107430626A (en) | The Action query based on speech suggested is provided | |
CN106233312A (en) | The auto-action replied based on context | |
CN107533360A (en) | A kind of method for showing, handling and relevant apparatus | |
CN103858073A (en) | Touch free interface for augmented reality systems |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
CB02 | Change of applicant information | ||
CB02 | Change of applicant information |
Address after: American CaliforniaApplicant after: Google limited liability companyAddress before: American CaliforniaApplicant before: Google Inc. |
|
WD01 | Invention patent application deemed withdrawn after publication | ||
WD01 | Invention patent application deemed withdrawn after publication |
Application publication date: 20180102 |