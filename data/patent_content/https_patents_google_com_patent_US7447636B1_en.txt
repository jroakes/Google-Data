US7447636B1 - System and methods for using transcripts to train an automated directory assistance service - Google Patents
System and methods for using transcripts to train an automated directory assistance service Download PDFInfo
- Publication number
- US7447636B1 US7447636B1 US11/129,270 US12927005A US7447636B1 US 7447636 B1 US7447636 B1 US 7447636B1 US 12927005 A US12927005 A US 12927005A US 7447636 B1 US7447636 B1 US 7447636B1
- Authority
- US
- United States
- Prior art keywords
- grammar
- directory assistance
- module
- loose
- transcript
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
Images
Classifications
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/08—Speech classification or search
- G10L15/18—Speech classification or search using natural language modelling
- G10L15/183—Speech classification or search using natural language modelling using context dependencies, e.g. language models
- G10L15/19—Grammatical context, e.g. disambiguation of the recognition hypotheses based on word sequence rules
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/08—Speech classification or search
- G10L15/18—Speech classification or search using natural language modelling
- G10L15/183—Speech classification or search using natural language modelling using context dependencies, e.g. language models
Definitions
- the present invention relates generally to communication systems and, more particularly, to systems and methods that provide automated directory assistance.
- Conventional telephone directory assistance requires a large number of people at great expense.
- Conventional systems have attempted to automate some of the calls for the most frequently requested listings using speech recognition.
- a typical system requires a large effort on the part of experts to set up and maintain the system. For example, the experts first determine the few most frequently requested listings (FRLs) and then record and transcribe calls to human operators.
- FTLs most frequently requested listings
- the experts group the grammars for each of the FRLs to make a grammar for all of them. This makes it possible to recognize requests for any of the FRLs as long as the request is phrased in one of the ways anticipated by the experts. Most requests, however, are not for one of the FRLs, but for some other listing. In this case, the conventional systems detect that the requested number is not one of the FRLs and route the call to a human directory assistance operator.
- Systems and methods consistent with the present invention address this need by providing automated directory assistance that uses large vocabulary speech recognition and information retrieval techniques to automate a large number of listings, and mechanisms for setting up and maintaining the automated directory assistance.
- an automated directory assistance system includes a speech recognition module, a listing retrieval module, and an accept/reject module.
- the speech recognition module receives an audible request for a telephone number from a caller and generates a transcript from the audible request.
- the listing retrieval module retrieves at least one listing corresponding to the audible request from a database using the transcript.
- the accept/reject module determines whether to accept one or more of the listings retrieved by the listing retrieval module and presents a telephone number corresponding to the accepted listing to the caller.
- One mode of operation for this system relies on having transcriptions of actual telephone calls to directory assistance. These calls may be used to derive the language model for recognition, to retrieve the appropriate telephone number, and to allow estimation of acoustic models. In one implementation consistent with the present invention, the actual telephone calls are transcribed by humans.
- a system for generating transcripts used by an automated directory assistance service includes a grammar creation component and a speech recognition component.
- the grammar creation component creates a loose grammar for multiple telephone numbers using grammar rules and general phrases.
- the speech recognition component generates a transcript of a directory assistance call using the loose grammar.
- a method for generating transcripts used to configure an automated directory assistance service includes creating a loose grammar for multiple telephone numbers using grammar rules and general phrases; generating a transcript of a directory assistance call using the loose grammar and knowledge of a telephone number that was given out by a human operator for the directory assistance call; producing a confidence score for the generated transcript; and determining whether the generated transcript is acceptable based on the confidence score for the generated transcript.
- a system for training an automated directory assistance service includes a transcription module, a speech grammar estimation module, a listings statistics estimation module, and a required words determination module.
- the transcription module obtains transcripts relating to directory service requests.
- the speech grammar estimation module creates an n-gram grammar for multiple telephone numbers from the transcripts.
- the listings statistics estimation module identifies words used to refer to each of the telephone numbers from the transcripts.
- the required words determination module identifies at least one word that is required to request each of the telephone numbers from the transcripts.
- a directory assistance system includes a training system and a directory assistance system.
- the training system includes a transcription module, a speech grammar estimation module, a listings statistics estimation module, and a required words determination module.
- the transcription module obtains training transcripts relating to directory service requests.
- the speech grammar estimation module creates an n-gram grammar for multiple telephone numbers from the training transcripts.
- the listings statistics estimation module identifies words used to refer to each of the telephone numbers from the training transcripts and stores the words as listings in a database.
- the required words determination module identifies at least one word that is required to request each of the telephone numbers from the training transcripts.
- the directory assistance system includes a speech recognition module, a listing retrieval module, and an accept/reject module.
- the speech recognition module receives an audible request for a telephone number from a caller and generates a transcript from the audible request using the n-gram grammar.
- the listing retrieval module retrieves at least one listing corresponding to the audible request from the database using the transcript.
- the accept/reject module determines whether to accept the listing retrieved by the listing retrieval module based on the at least one required word of sufficiently high confidence and presents a telephone number corresponding to the accepted listing to the caller.
- a method for providing a directory assistance service includes receiving a request for a telephone number from a caller, the request being spoken by the caller and including a location and listing corresponding to the telephone number; using large vocabulary speech recognition to recognize at least one word spoken by the caller when making the request; using statistical information retrieval to identify a listing corresponding to the recognized word; determining whether the listing is likely to be correct; and providing a telephone number corresponding to the listing to the caller.
- a method for providing a directory assistance service includes receiving a request for a telephone number from a caller, the request being spoken by the caller and including a location and listing corresponding to the telephone number; using large vocabulary speech recognition to recognize at least one word spoken by the caller when making the request; using statistical information retrieval to identify a listing corresponding to the recognized word; and connecting the caller to a called party corresponding to the listing.
- FIG. 1 is an exemplary diagram of a network in which systems and methods consistent with the present invention may be implemented
- FIG. 2 is an exemplary diagram of the automated directory assistance of FIG. 1 in an implementation consistent with the present invention
- FIG. 3 is an exemplary diagram of the training system of FIG. 2 in an implementation consistent with the present invention
- FIG. 4 is an exemplary diagram of an automatic transcription module that may be used by the training system of FIG. 3 in an implementation consistent with the present invention
- FIG. 5 is an exemplary diagram of the directory assistance system of FIG. 2 in an implementation consistent with the present invention
- FIG. 6 is a flowchart of exemplary processing for training a directory assistance system according to an implementation consistent with the present invention
- FIG. 7 is a flowchart of exemplary processing for automatically generating transcripts according to an implementation consistent with the present invention.
- FIG. 8 is an exemplary flowchart of directory assistance processing according to an implementation consistent with the present invention.
- Systems and methods consistent with the present invention automate directory assistance using large vocabulary speech recognition and information retrieval techniques to service a wide range of telephone number requests.
- the systems and methods also provide mechanisms for automatically generating transcripts used to train and maintain the automated directory assistance.
- FIG. 1 is a diagram of an exemplary network 100 in which systems and methods consistent with the present invention may be implemented.
- the network 100 may include caller device 110 connected to operator directory assistance 120 and automated directory assistance 130 via a network 140 .
- the network 140 may include one or more networks, such as the public switched telephone network (PSTN), the Internet, an intranet, a local area network (LAN), a wide area network (WAN), etc., that permit the caller device 110 , the operator directory assistance 120 , and the automated directory assistance 130 to communicate.
- PSTN public switched telephone network
- LAN local area network
- WAN wide area network
- the caller device 110 may include a conventional communications device capable of communicating over the network 140 via a wired, wireless, or optical connection.
- the caller device 110 may include a wired or wireless telephone, a personal or portable computer, a personal digital assistant (PDA), or a similar device.
- PDA personal digital assistant
- the operator directory assistance 120 may include one or more communications devices operated by one or more human operators.
- the communications devices may include a telephone device 122 , a computer device 124 , or a similar device. While only a single caller device and two exemplary operator directory assistance devices have been shown in FIG. 1 , one of ordinary skill in the art would recognize that the network 100 may include additional and/or different devices.
- the automated directory assistance 130 may include one or more computer devices, or the like, that operate upon a request for a telephone number from a caller device, such as the caller device 110 , to provide the telephone number and/or a connection to the desired called party.
- FIG. 2 is an exemplary diagram of the automated directory assistance 130 according to an implementation consistent with the present invention.
- the automated directory assistance 130 may include a training system 210 and a directory assistance system 220 .
- the training system 210 trains and configures the directory assistance system 220 .
- the directory assistance system 220 services telephone number requests from caller devices.
- FIG. 3 is an exemplary diagram of the training system 210 according to an implementation consistent with the present invention.
- the training system 210 may include a transcription module 310 , an acoustic model training module 320 , a speech grammar estimation module 330 , a listing statistics estimation module 340 , and a required words determination module 350 . These modules may be implemented in hardware, software, or a combination of hardware and software.
- the transcription module 310 provides transcripts corresponding to recorded requests for telephone numbers.
- the transcription module 310 may obtain these transcripts in at least two different ways.
- the transcription module 310 uses human transcribers to create the transcripts from previously-recorded calls or from a phone book.
- the transcription module 310 automatically generates the transcripts.
- the transcription module 310 may also use a combination of human and automatic processing.
- FIG. 4 is an exemplary diagram of the transcription module 310 in accordance with these alternate implementations consistent with the present invention.
- the transcription module 310 may include a grammar creation component 410 , a speech recognition component 420 , optionally an accept/reject component 430 , and optionally a verification/correction component 440 . These components may be implemented in hardware, software, or a combination of hardware and software.
- the verification/correction component 440 may take the form of one or more human parties.
- the grammar creation component 410 operates upon at least three sources of information: a phone book, grammar rules, and general phrases.
- the grammar creation component 410 may use the phone book to obtain listings corresponding to telephone numbers in the phone book.
- the grammar creation component 410 may use conventional manual or automatic techniques to translate the listings.
- the transcription module 310 needs phonetic spellings for all of the words that will be recognized.
- One automatic technique predicts phonetic spellings for words included in the listings, aligns the predicted spelling with the manual spelling, and creates a confusion matrix therefrom. From the confusion matrix, the technique expands the predicted spelling of new words into a network of possible spellings and recognizes the most likely phonemes.
- the grammar rules may include a very broad set of rules (e.g., anything that is plausible) for possible words and/or phrases that might be used to refer to a listing.
- the grammar rules may include alternate words, such as “DMV” for a listing for the “Department of Motor Vehicles.”
- the general phrases may include additional or extraneous words that may be provided when referring to any listing, such as “I want the number for,” “Please give me the number for,” “I need,” etc.
- the grammar creation component 410 may use the phone book, grammar rules, and general phrases to create a loose grammar for each telephone number.
- the grammar is loose because it may include all of the ways that someone may plausibly request the listing.
- the grammar creation component 410 may store this loose grammar in a database accessible by the speech recognition component 420 .
- the speech recognition component 420 may include a conventional speech recognizer, such as BYBLOS or HARK manufactured by GTE Corporation, to generate a hypothesized transcript based on the spoken (audio) request from a caller, the telephone, number given by a human directory assistance operator, and the loose grammar created by the grammar creation component 410 .
- the speech recognition component 420 may convert the audio request to digital form and use the loose grammar corresponding to the telephone number given by the human operator to recognize the words spoken by the caller. From this, the speech recognition component 420 may generate the hypothesized transcript.
- the speech recognition component 420 provides the hypothesized transcript to the accept/reject component 430 .
- the accept/reject component 430 may operate upon a set of criteria to determine whether the hypothesized transcript is accurate or meets some threshold of accuracy.
- the accept/reject component 430 may generate a confidence value based on its determination.
- the transcription module 310 does not yet have transcriptions for how people ask for these telephone numbers, so the confidence values may be based on acoustic measures and other mechanisms.
- the accept/reject component 430 may compare the confidence scores of each of the recognized words with the scores for an arbitrary sequence of phonemes. The accept/reject component 430 may also consider other information, such as the length of each word or the amount of training for each word.
- the transcription module 310 may use the information provided by the telephone number given out by the operator to narrow down the possibilities, and then also try to determine when the recognized transcript is correct.
- the verification/correction component 440 may verify all of the transcripts that were produced automatically and make corrections, as necessary. The verification/correction may be performed quickly by one or more human parties to eliminate the errors present in the automatically-produced transcripts.
- the acoustic model training module 320 may estimate acoustic models, such as Hidden Markov Models (HMMs) that are used in speech recognition.
- HMMs Hidden Markov Models
- the acoustic model training module 320 analyzes examples of speech waveforms to compute the statistics of the spectral parameters therefrom. Using the spectral parameters and the corresponding transcripts, the acoustic model training module 320 gathers the speech and the corresponding text of what was said.
- the acoustic model training module 320 expands the text using a phonetic dictionary into phonemes and then estimates the acoustic models (i.e., the parameters of the HMMs) that are used in speech recognition.
- the speech grammar estimation module 330 may create a statistical n-gram grammar using transcripts (i.e., words and phrases) from the transcription module 310 . In other words, the speech grammar estimation module 330 takes all of the words/phrases that callers have used for all of the listings and estimates an n-gram grammar. The statistical n-gram grammar estimates the likelihood of each single word, each pair of words, each triplet of words, etc. For a tri-gram grammar, for example, the speech grammar estimation module 330 determines, given any two preceding words, the probability of each possible third word.
- transcripts i.e., words and phrases
- the listing statistics estimation module 340 may generate a city/listings database from the transcripts from the transcription module 310 .
- the listing statistics estimation module 340 uses the transcripts to identify all of the words and phrases that have been used to refer to a particular telephone number.
- the listing statistics estimation module 340 concatenates these words and phrases to form a document or file relating to the particular telephone number.
- the listing statistics estimation module 340 then stores the document in a database, such as the city/listings database.
- the city/listings database stores a separate document for each telephone number and these documents are searchable using a word or phrase from a transcript (as described later).
- One technique that the training system 210 may use to determine whether the retrieved listing was correct is to compare the recognized utterance with a set of “required words.”
- the technique allows for multiple sets of required words and requires that the recognized utterance match one of the sets to some degree. For example, for the Department of Motor Vehicles, the training system 210 might accept the words “Department, Motor, Vehicles,” or “Registry, Vehicles,” or it might also accept “DMV” as an alternative.
- the training system 210 may allow the user to say other words as well, as long as the required words are spoken.
- the required words determination module 350 may identify one or more words or lists of words, using the transcripts, that must be used to request a particular telephone number and store the word or words in a required words database. To generate this word or list of words, the required words determination module 350 may remove all of the “stop” words from transcripts of requests for each listing. Stop words are words that are considered useless, such as “Please,” “I want,” etc.
- the required words determination module 350 may then count the number of times that each distinct word or phrase was used and identify which of these words or phrases are required based on some pre-established criteria. For example, the criteria may require that a word or phrase occur at least some minimum number of times (e.g., 2) and/or that the word or phrase account for at least some minimum percentage (e.g., 10%) of the transcripts to constitute a required word or phrase. These required minimums may be modified to trade off false rejection against false acceptance. If the minimums are raised, there will be fewer required words or phrases, resulting in higher false rejection with correspondingly lower false acceptance.
- the training system 210 uses the above modules to train and configure the directory assistance system 220 .
- the directory assistance system 220 services telephone number requests from caller devices, such as the caller device 110 .
- FIG. 5 is an exemplary diagram of the directory assistance system 220 in an implementation consistent with the present invention.
- the directory assistance system 220 may include a speech recognition module 510 , a listing retrieval module 520 , and an accept/reject module 530 .
- the speech recognition module 510 may include a conventional large vocabulary recognizer, such as BYBLOS or HARK, that receives speech from a caller and generates a recognized transcript therefrom.
- the speech recognition module 510 may convert the audible speech from the caller to a digital format, record it, and use the acoustic models and speech grammar to recognize the word or phrase (i.e., sequence of words) spoken by the caller.
- the speech recognition module 510 uses the recognized word or phrase to generate a recognized transcript corresponding to the word(s) spoken by the caller.
- the speech recognition module 510 may also produce a confidence score for each word in the recognized transcript as well as a confidence score for the whole transcript. This confidence score reflects the likelihood that this word or utterance has been recognized correctly. If the confidence score for the whole transcript is sufficiently low, the entire utterance may be rejected.
- the word confidence scores may be used by the accept/reject module 530 as described below.
- the listing retrieval module 520 may include a statistical information retrieval system, such as the statistical document retrieval system described in U.S. patent application Ser. No. 09/127,685, filed Jul. 31, 1998, that uses the recognized transcript from the speech recognition module 510 as a query into the city/listings database.
- the listing retrieval module 520 finds the most likely listing(s) in the city/listings database given the recognized transcript and generates a list of hypothesized listings.
- the listing retrieval module 520 may use the prior probability of a request for a particular telephone number as well as the probability that a request for that telephone number would result in the words that were spoken. If the listing retrieval module 520 finds more than one potential listing, the listing retrieval module 520 may rank them based on their potential relevance. Conversely, the listing retrieval module 520 may reject the transcript if no listings are above a specified threshold.
- the accept/reject module 530 uses the recognized transcript, the hypothesized listing, and the required words database to determine whether to accept or reject a hypothesized listing.
- the accept/reject module 530 may use the hypothesized listing as a query or index into the required words database to determine what word or list of words are required for the particular listing.
- the accept/reject module 530 determines whether the recognized transcript from the speech recognition module 510 contains the required word or list of words.
- the accept/reject module 530 For the accept/reject module 530 to accept the hypothesized listing, the accept/reject module 530 must find one or more of the required word lists in the recognized transcript. The accept/reject module 530 may ignore other words in the transcript, as well as the order of the words. If the accept/reject module 530 finds none of the required words in the transcript, it rejects the hypothesized listing. If the listing is rejected, the accept/reject module 530 may forward a recording of the caller's request to a human operator, such as an operator in the operator directory assistance 120 ( FIG. 1 ), to service the request.
- a human operator such as an operator in the operator directory assistance 120 ( FIG. 1 )
- the accept/reject module 530 may reject the listing if the word confidence score produced by the speech recognition module 510 for any of the required words is below a specified threshold.
- FIG. 6 is a flowchart of exemplary processing for training a directory assistance system according to an implementation consistent with the present invention. While a series of steps are shown, the steps may be performed in a different order and/or concurrently.
- Transcripts of user requests are used at several stages of the training system 210 . Processing begins with the transcription module 310 obtaining transcripts corresponding to requests for telephone numbers [step 610 ]. These requests may be actual, previously-recorded calls from callers serviced by human directory assistance operators. Because these calls are prior calls that were already serviced, the transcription module 310 knows not only what the callers said, but what telephone numbers were given out by the directory assistance operators.
- the transcription module 310 may obtain the transcripts either manually or automatically. In the manual process, human transcribers create the transcripts from previously-recorded calls or from a phone book. It can be expensive, however, to transcribe a large number of utterances manually. Therefore, to produce transcripts at reduced cost, the transcription module 310 may use an automatic procedure or a semi-automatic one in which the automatic procedure is followed by a human verification stage.
- FIG. 7 is a flowchart of exemplary processing for automatically generating transcripts according to an implementation consistent with the present invention.
- the grammar creation component 410 ( FIG. 4 ) may obtain listings from a phone book and translate them [step 710 ].
- the grammar creation component 410 may use one of several conventional techniques to translate the listings to electronic form.
- the grammar creation component 410 may use the translated listing, a broad set of grammar rules, and a set of general phrases to create a loose grammar for each telephone number in the phone book [step 720 ].
- the grammar is loose because it may include all of the ways that someone may plausibly request the corresponding telephone number.
- the speech recognition component 420 may receive a recorded request from a caller, along with the telephone number provided by a human directory assistance operator.
- the caller request may be one of many examples that the speech recognition component 420 uses to create a transcript.
- the speech recognition component 420 may convert the audio request to digital form using a conventional conversion technique:
- the speech recognition component 420 may then generate a hypothesized transcript corresponding to the recorded caller request [step 730 ].
- the speech recognition component 420 uses the loose grammar, corresponding to the telephone number provided by the human operator for this request, to recognize the word(s) spoken by the caller.
- the speech recognition component 420 produces the hypothesized transcript, which is the recognized sequence of words. It may also produce a confidence score for each word and/or for the whole utterance.
- the accept/reject component 430 may determine the accuracy of the hypothesized transcript(s) [step 740 ].
- the accept/reject component 430 may determine whether a transcript is accurate or meets some threshold of accuracy by determining whether the transcript contains one or more words that are required for the particular listing. Other techniques may alternatively be used. For example, it may also reject a transcript based on the word or utterance confidence scores.
- the accept/reject component 430 may use the statistical confidences produced by the speech recognition component 420 to accept or reject the transcript. If the confidence scores are sufficiently high, the transcript may be accepted.
- the grammar creation component 410 may create a loose grammar for telephone number 703-555-1212 that includes words, such as “department, “motor,” “vehicles,” “DMV,” “state,” “driver,” “license,” “plate,” “registration,” “driving,” etc., along with general phrases, such as “I want the number for,” “please give me the number for,” etc.
- the speech recognition component 420 receives the recorded call (i.e., “Please give me the number for the DMV”) and the telephone number (i.e., 703-555-1212) given out by the operator.
- the speech recognition component 420 converts the recorded call to digital form and identifies the loose grammar corresponding to the telephone number 763-555-1212.
- the speech recognition component 420 may use the telephone number as an index into a database of loose grammars created by the grammar creation component 410 .
- the speech recognition component 420 uses the loose grammar in a conventional manner to recognize the words spoken by the caller and includes these words in a hypothesized transcript. Suppose, for example, that the hypothesized transcript includes the word “DMV.”
- the accept/reject component 430 may then determine the accuracy of the hypothesized transcript.
- the accept/reject component 430 may compare the hypothesized transcript to the required words. In this case, the word “DMV” appears in both the transcript and the required words. Therefore, the accept/reject component 430 accepts the transcript.
- the automatic transcription process may reject sentences for which the confidence scores are not high enough. This may result in many utterances being rejected even though the automatic transcription was correct or nearly correct. In addition, the automatic transcription process might produce some incorrect transcripts that are accepted by the accept/reject component 430 . These problems may be alleviated by human verification/correction component 440 .
- the verification/correction component 440 may use three ranges of confidence scores. If the confidence scores produced by the speech recognition module 420 are sufficiently high (i.e., above a high threshold), the transcript is accepted automatically. If they are sufficiently low (i.e., below a low threshold), the transcript may be rejected without human intervention. If they are in between the high and low thresholds, the recorded speech may be played to a human as the transcript of the recognized transcript is displayed. The human may also be shown the phone book entry for the telephone number that was given out by the operator.
- the human merely accepts or rejects the transcript. This requires a very small fraction of the time that would have been required for the human to transcribe the utterance manually. Yet, it avoids discarding any utterance that has been automatically transcribed correctly or keeping any transcripts that are incorrect. In another implementation consistent with the present invention, the human may choose to make some corrections to the recognized transcript. This can still be much faster than a manual transcription process. Depending on how the two thresholds are set, the amount of human intervention can be controlled. For example, if the two thresholds are very close together, the human will examine very few transcripts.
- the acoustic model training module 320 estimates acoustic models using examples of recorded caller requests and the transcripts from the transcriptions module 310 [step 620 ].
- the acoustic model training module 320 may analyze the speech waveforms of the caller requests and use the corresponding transcripts to estimate the acoustic models used in speech recognition,
- the speech grammar estimation module 330 may create a statistical n-gram grammar using the transcripts from the transcriptions module 310 [step 630 ].
- the speech grammar estimation module 330 may estimate the likelihood of each word, each pair of words, each triplet of words, etc. from all of the words and phrases callers have used to refer to any of the listings.
- the listing statistics estimation module 340 uses the transcripts to gather all of the words and phrases that have been used to refer to a particular telephone number [step 640 ].
- the listing statistics estimation module 340 may concatenate these words and phrases to form a document and store them in a city/listings database.
- the required words determination module 350 uses the transcripts to identify word(s) or phrase(s) that are required for each telephone number [step 650 ]. For example, the required words determination module 350 may count the number of times that each distinct word or phrase was used to request a particular telephone number and identify those words or phrases that are required based on some preestablished criteria.
- FIG. 8 is an exemplary flowchart of directory assistance processing according to an implementation consistent with the present invention. Processing begins with a caller making a call to the automated directory assistance 130 ( FIG. 1 ) to request a telephone number.
- the caller may use a caller device, such as the caller device 110 , to contact the automated directory assistance 130 .
- the automated directory assistance 130 may use interactive voice response (IVR) technology to prompt the caller for the city and listing the caller desires. When prompted for the city and listing, the caller may provide the information by speaking into the caller device 110 .
- the directory assistance system 220 ( FIG. 2 ) within the automated directory assistance 130 may record the caller's spoken request [step 810 ].
- the speech recognition module 510 within the directory assistance system 220 may convert the recorded request to digital form and, using the acoustic models and speech grammar, recognize the word or phrase spoken by the caller.
- the speech recognition module 510 uses the recognized word or phrase to generate a recognized transcript corresponding to the request from the caller [step 820 ].
- the listing retrieval module 520 may use the recognized transcript as a query into the city/listings database to obtain one or more hypothesized listings corresponding to the caller's request [step 830 ].
- the listing retrieval module 520 may use conventional information retrieval techniques to retrieve the hypothesized listings from the database or it may use the statistical information retrieval technique described in U.S. patent application Ser. No. 09/127,685, filed Jul. 31, 1998.
- the accept/reject module 530 may determine whether to accept or reject each of the hypothesized listings [step 840 ]. The accept/reject module 530 may make this determination based on the estimated accuracy of the listings and the confidence scores associated with the listings. The accept/reject module 530 may use each of the hypothesized listings to identify the word(s) that are required for the particular listing. The accept/reject module 530 then determines whether the recognized transcript includes the required word(s). If the recognized transcript contains the required word(s) corresponding to one or more of the hypothesized listings with a sufficiently high confidence score, the accept/reject module 530 accepts the listing. If the confidence score falls in a middle range, the accept/reject module 530 may confirm the listing with the caller [step 850 ]. The accept/reject module 530 may use IVR technology to provide the listing audibly to the caller and the caller may confirm the listing with an audible response or through manipulation of the caller device 110 [step 860 ].
- the accept/reject module 530 may provide the recorded request from the caller to a human operator for service [step 870 ]. If the caller indicates that the listing is correct, processing ends. In this case, the automated directory assistance 130 may automatically provide the telephone number associated with the listing or it may connect the caller to the called party associated with the listing.
- Systems and methods consistent with the present invention provide automated directory assistance that uses large vocabulary speech recognition and information retrieval techniques to service a wide range of telephone number requests.
- the systems and methods also provide mechanisms for automatically generating transcripts for training and maintaining the automated directory assistance.
- the automated directory assistance consistent with the present invention has several advantages over conventional systems. First, it facilitates the automation of a large number of listings in a large number of locations by using large vocabulary recognition techniques for both recognition and rejection. Second, it automates grammar creation for each listing, thereby eliminating extensive labor to determine the grammar for each listing. Third, it provides flexibility in that it permits automation even when the request is phrased in a slightly novel way. Fourth, it is more lenient to recognition errors by using probabilistic information retrieval techniques to choose among multiple listings when several are possible. Fifth, it may be unimplemented with a few or no examples of transcripts.
- the transcription module 310 and the directory assistance system 220 have been described as part of the same automated directory assistance 130 , this need not be the case. In other implementations consistent with the present invention, the transcription module 310 and the directory assistance system 220 are implemented separately within different systems.
Abstract
Description
Claims (17)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US11/129,270 US7447636B1 (en) | 2005-05-12 | 2005-05-12 | System and methods for using transcripts to train an automated directory assistance service |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US11/129,270 US7447636B1 (en) | 2005-05-12 | 2005-05-12 | System and methods for using transcripts to train an automated directory assistance service |
Publications (1)
Publication Number | Publication Date |
---|---|
US7447636B1 true US7447636B1 (en) | 2008-11-04 |
Family
ID=39916561
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US11/129,270 Active US7447636B1 (en) | 2005-05-12 | 2005-05-12 | System and methods for using transcripts to train an automated directory assistance service |
Country Status (1)
Country | Link |
---|---|
US (1) | US7447636B1 (en) |
Cited By (11)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20060265221A1 (en) * | 2005-05-20 | 2006-11-23 | Dictaphone Corporation | System and method for multi level transcript quality checking |
US20080103761A1 (en) * | 2002-10-31 | 2008-05-01 | Harry Printz | Method and Apparatus for Automatically Determining Speaker Characteristics for Speech-Directed Advertising or Other Enhancement of Speech-Controlled Devices or Services |
US20090060156A1 (en) * | 2007-08-28 | 2009-03-05 | Burckart Erik J | System for Recording Spoken Phone Numbers During a Voice Call |
US8213966B1 (en) * | 2007-03-12 | 2012-07-03 | Tellme Networks, Inc. | Text messages provided as a complement to a voice session |
US8645136B2 (en) | 2010-07-20 | 2014-02-04 | Intellisist, Inc. | System and method for efficiently reducing transcription error using hybrid voice transcription |
WO2014158239A1 (en) * | 2013-03-14 | 2014-10-02 | Google Inc. | Language modeling of complete language sequences |
US8954325B1 (en) * | 2004-03-22 | 2015-02-10 | Rockstar Consortium Us Lp | Speech recognition in automated information services systems |
US10152298B1 (en) * | 2015-06-29 | 2018-12-11 | Amazon Technologies, Inc. | Confidence estimation based on frequency |
US20200081939A1 (en) * | 2018-09-11 | 2020-03-12 | Hcl Technologies Limited | System for optimizing detection of intent[s] by automated conversational bot[s] for providing human like responses |
US10665231B1 (en) * | 2019-09-06 | 2020-05-26 | Verbit Software Ltd. | Real time machine learning-based indication of whether audio quality is suitable for transcription |
US10847149B1 (en) * | 2017-09-01 | 2020-11-24 | Amazon Technologies, Inc. | Speech-based attention span for voice user interface |
Citations (21)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4959855A (en) | 1986-10-08 | 1990-09-25 | At&T Bell Laboratories | Directory assistance call processing and calling customer remote signal monitoring arrangements |
US5185781A (en) * | 1990-10-12 | 1993-02-09 | At&T Bell Laboratories | Automation of telephone operator assistance calls |
US5638425A (en) * | 1992-12-17 | 1997-06-10 | Bell Atlantic Network Services, Inc. | Automated directory assistance system using word recognition and phoneme processing method |
US5642519A (en) * | 1994-04-29 | 1997-06-24 | Sun Microsystems, Inc. | Speech interpreter with a unified grammer compiler |
US5799065A (en) * | 1996-05-06 | 1998-08-25 | Matsushita Electric Industrial Co., Ltd. | Call routing device employing continuous speech |
US5839107A (en) * | 1996-11-29 | 1998-11-17 | Northern Telecom Limited | Method and apparatus for automatically generating a speech recognition vocabulary from a white pages listing |
US5839106A (en) | 1996-12-17 | 1998-11-17 | Apple Computer, Inc. | Large-vocabulary speech recognition using an integrated syntactic and semantic statistical language model |
US5987414A (en) | 1996-10-31 | 1999-11-16 | Nortel Networks Corporation | Method and apparatus for selecting a vocabulary sub-set from a speech recognition dictionary for use in real time automated directory assistance |
US5995929A (en) * | 1997-09-12 | 1999-11-30 | Nortel Networks Corporation | Method and apparatus for generating an a priori advisor for a speech recognition dictionary |
US6018708A (en) | 1997-08-26 | 2000-01-25 | Nortel Networks Corporation | Method and apparatus for performing speech recognition utilizing a supplementary lexicon of frequently used orthographies |
US6021384A (en) * | 1997-10-29 | 2000-02-01 | At&T Corp. | Automatic generation of superwords |
US6052693A (en) * | 1996-07-02 | 2000-04-18 | Harlequin Group Plc | System for assembling large databases through information extracted from text sources |
US6122614A (en) * | 1998-11-20 | 2000-09-19 | Custom Speech Usa, Inc. | System and method for automating transcription services |
US6122361A (en) * | 1997-09-12 | 2000-09-19 | Nortel Networks Corporation | Automated directory assistance system utilizing priori advisor for predicting the most likely requested locality |
US6138100A (en) * | 1998-04-14 | 2000-10-24 | At&T Corp. | Interface for a voice-activated connection system |
US6199087B1 (en) * | 1998-06-25 | 2001-03-06 | Hewlett-Packard Company | Apparatus and method for efficient arithmetic in finite fields through alternative representation |
US6397179B2 (en) | 1997-12-24 | 2002-05-28 | Nortel Networks Limited | Search optimization system and method for continuous speech recognition |
US6615172B1 (en) | 1999-11-12 | 2003-09-02 | Phoenix Solutions, Inc. | Intelligent query engine for processing voice based queries |
US6665640B1 (en) | 1999-11-12 | 2003-12-16 | Phoenix Solutions, Inc. | Interactive speech based learning/training system formulating search queries based on natural language parsing of recognized user queries |
US6668044B1 (en) | 2000-07-19 | 2003-12-23 | Xtend Communications Corp. | System and method for recording telephonic communications |
US6789060B1 (en) | 1999-11-01 | 2004-09-07 | Gene J. Wolfe | Network based speech transcription that maintains dynamic templates |
-
2005
- 2005-05-12 US US11/129,270 patent/US7447636B1/en active Active
Patent Citations (21)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4959855A (en) | 1986-10-08 | 1990-09-25 | At&T Bell Laboratories | Directory assistance call processing and calling customer remote signal monitoring arrangements |
US5185781A (en) * | 1990-10-12 | 1993-02-09 | At&T Bell Laboratories | Automation of telephone operator assistance calls |
US5638425A (en) * | 1992-12-17 | 1997-06-10 | Bell Atlantic Network Services, Inc. | Automated directory assistance system using word recognition and phoneme processing method |
US5642519A (en) * | 1994-04-29 | 1997-06-24 | Sun Microsystems, Inc. | Speech interpreter with a unified grammer compiler |
US5799065A (en) * | 1996-05-06 | 1998-08-25 | Matsushita Electric Industrial Co., Ltd. | Call routing device employing continuous speech |
US6052693A (en) * | 1996-07-02 | 2000-04-18 | Harlequin Group Plc | System for assembling large databases through information extracted from text sources |
US5987414A (en) | 1996-10-31 | 1999-11-16 | Nortel Networks Corporation | Method and apparatus for selecting a vocabulary sub-set from a speech recognition dictionary for use in real time automated directory assistance |
US5839107A (en) * | 1996-11-29 | 1998-11-17 | Northern Telecom Limited | Method and apparatus for automatically generating a speech recognition vocabulary from a white pages listing |
US5839106A (en) | 1996-12-17 | 1998-11-17 | Apple Computer, Inc. | Large-vocabulary speech recognition using an integrated syntactic and semantic statistical language model |
US6018708A (en) | 1997-08-26 | 2000-01-25 | Nortel Networks Corporation | Method and apparatus for performing speech recognition utilizing a supplementary lexicon of frequently used orthographies |
US6122361A (en) * | 1997-09-12 | 2000-09-19 | Nortel Networks Corporation | Automated directory assistance system utilizing priori advisor for predicting the most likely requested locality |
US5995929A (en) * | 1997-09-12 | 1999-11-30 | Nortel Networks Corporation | Method and apparatus for generating an a priori advisor for a speech recognition dictionary |
US6021384A (en) * | 1997-10-29 | 2000-02-01 | At&T Corp. | Automatic generation of superwords |
US6397179B2 (en) | 1997-12-24 | 2002-05-28 | Nortel Networks Limited | Search optimization system and method for continuous speech recognition |
US6138100A (en) * | 1998-04-14 | 2000-10-24 | At&T Corp. | Interface for a voice-activated connection system |
US6199087B1 (en) * | 1998-06-25 | 2001-03-06 | Hewlett-Packard Company | Apparatus and method for efficient arithmetic in finite fields through alternative representation |
US6122614A (en) * | 1998-11-20 | 2000-09-19 | Custom Speech Usa, Inc. | System and method for automating transcription services |
US6789060B1 (en) | 1999-11-01 | 2004-09-07 | Gene J. Wolfe | Network based speech transcription that maintains dynamic templates |
US6615172B1 (en) | 1999-11-12 | 2003-09-02 | Phoenix Solutions, Inc. | Intelligent query engine for processing voice based queries |
US6665640B1 (en) | 1999-11-12 | 2003-12-16 | Phoenix Solutions, Inc. | Interactive speech based learning/training system formulating search queries based on natural language parsing of recognized user queries |
US6668044B1 (en) | 2000-07-19 | 2003-12-23 | Xtend Communications Corp. | System and method for recording telephonic communications |
Cited By (31)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US8862596B2 (en) | 2002-10-31 | 2014-10-14 | Promptu Systems Corporation | Method and apparatus for generation and augmentation of search terms from external and internal sources |
US20080103761A1 (en) * | 2002-10-31 | 2008-05-01 | Harry Printz | Method and Apparatus for Automatically Determining Speaker Characteristics for Speech-Directed Advertising or Other Enhancement of Speech-Controlled Devices or Services |
US20080126089A1 (en) * | 2002-10-31 | 2008-05-29 | Harry Printz | Efficient Empirical Determination, Computation, and Use of Acoustic Confusability Measures |
US9626965B2 (en) | 2002-10-31 | 2017-04-18 | Promptu Systems Corporation | Efficient empirical computation and utilization of acoustic confusability |
US10121469B2 (en) | 2002-10-31 | 2018-11-06 | Promptu Systems Corporation | Efficient empirical determination, computation, and use of acoustic confusability measures |
US8959019B2 (en) * | 2002-10-31 | 2015-02-17 | Promptu Systems Corporation | Efficient empirical determination, computation, and use of acoustic confusability measures |
US11587558B2 (en) | 2002-10-31 | 2023-02-21 | Promptu Systems Corporation | Efficient empirical determination, computation, and use of acoustic confusability measures |
US9305549B2 (en) | 2002-10-31 | 2016-04-05 | Promptu Systems Corporation | Method and apparatus for generation and augmentation of search terms from external and internal sources |
US8793127B2 (en) | 2002-10-31 | 2014-07-29 | Promptu Systems Corporation | Method and apparatus for automatically determining speaker characteristics for speech-directed advertising or other enhancement of speech-controlled devices or services |
US10748527B2 (en) | 2002-10-31 | 2020-08-18 | Promptu Systems Corporation | Efficient empirical determination, computation, and use of acoustic confusability measures |
US8954325B1 (en) * | 2004-03-22 | 2015-02-10 | Rockstar Consortium Us Lp | Speech recognition in automated information services systems |
US8655665B2 (en) | 2005-05-20 | 2014-02-18 | Nuance Communications, Inc. | System and method for multi level transcript quality checking |
US8380510B2 (en) * | 2005-05-20 | 2013-02-19 | Nuance Communications, Inc. | System and method for multi level transcript quality checking |
US20060265221A1 (en) * | 2005-05-20 | 2006-11-23 | Dictaphone Corporation | System and method for multi level transcript quality checking |
US8213966B1 (en) * | 2007-03-12 | 2012-07-03 | Tellme Networks, Inc. | Text messages provided as a complement to a voice session |
US8374316B2 (en) * | 2007-08-28 | 2013-02-12 | International Business Machines Corporation | System for recording spoken phone numbers during a voice call |
US20090060156A1 (en) * | 2007-08-28 | 2009-03-05 | Burckart Erik J | System for Recording Spoken Phone Numbers During a Voice Call |
US8972261B2 (en) | 2010-07-20 | 2015-03-03 | Intellisist, Inc. | Computer-implemented system and method for voice transcription error reduction |
US9218808B2 (en) | 2010-07-20 | 2015-12-22 | Intellisist, Inc. | Computer-implemented system and method for reducing voice transcription error |
US8645136B2 (en) | 2010-07-20 | 2014-02-04 | Intellisist, Inc. | System and method for efficiently reducing transcription error using hybrid voice transcription |
US9633658B2 (en) | 2010-07-20 | 2017-04-25 | Intellisist, Inc. | Computer-implemented system and method for transcription error reduction during a live call |
US9392108B2 (en) | 2010-07-20 | 2016-07-12 | Intellisist, Inc. | Computer-implemented system and method for efficiently reducing transcription error during a call |
US9858929B2 (en) | 2010-07-20 | 2018-01-02 | Intellisist, Inc. | Computer-implemented system and method for transcription error reduction |
US10083691B2 (en) | 2010-07-20 | 2018-09-25 | Intellisist, Inc. | Computer-implemented system and method for transcription error reduction |
US9786269B2 (en) | 2013-03-14 | 2017-10-10 | Google Inc. | Language modeling of complete language sequences |
WO2014158239A1 (en) * | 2013-03-14 | 2014-10-02 | Google Inc. | Language modeling of complete language sequences |
CN105229723A (en) * | 2013-03-14 | 2016-01-06 | 谷歌公司 | The Language Modeling of complete language sequence |
US10152298B1 (en) * | 2015-06-29 | 2018-12-11 | Amazon Technologies, Inc. | Confidence estimation based on frequency |
US10847149B1 (en) * | 2017-09-01 | 2020-11-24 | Amazon Technologies, Inc. | Speech-based attention span for voice user interface |
US20200081939A1 (en) * | 2018-09-11 | 2020-03-12 | Hcl Technologies Limited | System for optimizing detection of intent[s] by automated conversational bot[s] for providing human like responses |
US10665231B1 (en) * | 2019-09-06 | 2020-05-26 | Verbit Software Ltd. | Real time machine learning-based indication of whether audio quality is suitable for transcription |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US7447636B1 (en) | System and methods for using transcripts to train an automated directory assistance service | |
US7401023B1 (en) | Systems and methods for providing automated directory assistance using transcripts | |
US6925154B2 (en) | Methods and apparatus for conversational name dialing systems | |
US8694316B2 (en) | Methods, apparatus and computer programs for automatic speech recognition | |
US7949517B2 (en) | Dialogue system with logical evaluation for language identification in speech recognition | |
US7974843B2 (en) | Operating method for an automated language recognizer intended for the speaker-independent language recognition of words in different languages and automated language recognizer | |
KR101120716B1 (en) | Automatic identification of telephone callers based on voice characteristics | |
US6487530B1 (en) | Method for recognizing non-standard and standard speech by speaker independent and speaker dependent word models | |
US7401017B2 (en) | Adaptive multi-pass speech recognition system | |
US7711105B2 (en) | Methods and apparatus for processing foreign accent/language communications | |
US7415411B2 (en) | Method and apparatus for generating acoustic models for speaker independent speech recognition of foreign words uttered by non-native speakers | |
US20130110511A1 (en) | System, Method and Program for Customized Voice Communication | |
US20060215821A1 (en) | Voice nametag audio feedback for dialing a telephone call | |
EP1739546A2 (en) | Automobile interface | |
US20030149566A1 (en) | System and method for a spoken language interface to a large database of changing records | |
Li et al. | Automatic verbal information verification for user authentication | |
WO2000068933A1 (en) | Adaptation of a speech recognition system across multiple remote sessions with a speaker | |
KR19980070329A (en) | Method and system for speaker independent recognition of user defined phrases | |
US20040034518A1 (en) | Automatic dialog system with database language model | |
US20070129945A1 (en) | Voice quality control for high quality speech reconstruction | |
Natarajan et al. | A scalable architecture for directory assistance automation | |
KR100622019B1 (en) | Voice interface system and method | |
JPH06161488A (en) | Speech recognizing device | |
JP2002532763A (en) | Automatic inquiry system operated by voice | |
JP2002082691A (en) | Automatic recognition method of company name included in uttering |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
AS | Assignment |
Owner name: BANK OF AMERICA, N.A., MASSACHUSETTSFree format text: INTELLECTUAL PROPERTY SECURITY AGREEMENT SUPPLEMENT;ASSIGNOR:BBN TECHNOLOGIES CORP.;REEL/FRAME:021924/0279Effective date: 20081124 |
|
AS | Assignment |
Owner name: BBNT SOLUTIONS LLC, MASSACHUSETTSFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:SCHWARTZ, RICHARD MARK;SHU, HAN;MAKHOUL, JOHN;AND OTHERS;REEL/FRAME:022813/0712;SIGNING DATES FROM 20000919 TO 20000920 |
|
AS | Assignment |
Owner name: BBN TECHNOLOGIES CORP., MASSACHUSETTSFree format text: CHANGE OF NAME;ASSIGNOR:BBNT SOLUTIONS LLC;REEL/FRAME:023119/0645Effective date: 20060103 |
|
AS | Assignment |
Owner name: BBN TECHNOLOGIES CORP. (AS SUCCESSOR BY MERGER TOFree format text: RELEASE OF SECURITY INTEREST;ASSIGNOR:BANK OF AMERICA, N.A. (SUCCESSOR BY MERGER TO FLEET NATIONAL BANK);REEL/FRAME:023427/0436Effective date: 20091026 |
|
FEPP | Fee payment procedure |
Free format text: PAYOR NUMBER ASSIGNED (ORIGINAL EVENT CODE: ASPN); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
AS | Assignment |
Owner name: BBNT SOLUTIONS LLC, MASSACHUSETTSFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:BBNT SOLUTIONS LLC;REEL/FRAME:023574/0861Effective date: 20040326Owner name: VERIZON PATENT AND LICENSING INC., NEW JERSEYFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:VERIZON CORPORATE SERVICES GROUP INC.;REEL/FRAME:023586/0084Effective date: 20091125Owner name: VERIZON CORPORATE SERVICES GROUP INC., NEW YORKFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:BBNT SOLUTIONS LLC;REEL/FRAME:023574/0861Effective date: 20040326 |
|
AS | Assignment |
Owner name: RAYTHEON BBN TECHNOLOGIES CORP.,MASSACHUSETTSFree format text: CHANGE OF NAME;ASSIGNOR:BBN TECHNOLOGIES CORP.;REEL/FRAME:024523/0625Effective date: 20091027Owner name: RAYTHEON BBN TECHNOLOGIES CORP., MASSACHUSETTSFree format text: CHANGE OF NAME;ASSIGNOR:BBN TECHNOLOGIES CORP.;REEL/FRAME:024523/0625Effective date: 20091027 |
|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:VERIZON PATENT AND LICENSING INC.;REEL/FRAME:025328/0910Effective date: 20100916 |
|
FPAY | Fee payment |
Year of fee payment: 4 |
|
FPAY | Fee payment |
Year of fee payment: 8 |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044101/0610Effective date: 20170929 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 12TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1553); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 12 |