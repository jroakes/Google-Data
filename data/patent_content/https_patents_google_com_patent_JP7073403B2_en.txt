JP7073403B2 - Image processor with high throughput internal communication protocol - Google Patents
Image processor with high throughput internal communication protocol Download PDFInfo
- Publication number
- JP7073403B2 JP7073403B2 JP2019559364A JP2019559364A JP7073403B2 JP 7073403 B2 JP7073403 B2 JP 7073403B2 JP 2019559364 A JP2019559364 A JP 2019559364A JP 2019559364 A JP2019559364 A JP 2019559364A JP 7073403 B2 JP7073403 B2 JP 7073403B2
- Authority
- JP
- Japan
- Prior art keywords
- data
- data packet
- processor
- receiver
- transmitter circuit
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T1/00—General purpose image data processing
- G06T1/20—Processor architectures; Processor configuration, e.g. pipelining
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F12/00—Accessing, addressing or allocating within memory systems or architectures
- G06F12/02—Addressing or allocation; Relocation
- G06F12/08—Addressing or allocation; Relocation in hierarchically structured memory systems, e.g. virtual memory systems
- G06F12/0802—Addressing of a memory level in which the access to the desired data or data block requires associative addressing means, e.g. caches
- G06F12/0806—Multiuser, multiprocessor or multiprocessing cache systems
- G06F12/0813—Multiuser, multiprocessor or multiprocessing cache systems with a network or matrix configuration
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F15/00—Digital computers in general; Data processing equipment in general
- G06F15/76—Architectures of general purpose stored program computers
- G06F15/80—Architectures of general purpose stored program computers comprising an array of processing units with common control, e.g. single instruction multiple data processors
- G06F15/8007—Architectures of general purpose stored program computers comprising an array of processing units with common control, e.g. single instruction multiple data processors single instruction multiple data [SIMD] multiprocessors
- G06F15/8023—Two dimensional arrays, e.g. mesh, torus
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L25/00—Baseband systems
- H04L25/38—Synchronous or start-stop systems, e.g. for Baudot code
- H04L25/40—Transmitting circuits; Receiving circuits
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L47/00—Traffic control in data switching networks
- H04L47/10—Flow control; Congestion control
- H04L47/39—Credit based
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L49/00—Packet switching elements
- H04L49/90—Buffering arrangements
- H04L49/9063—Intermediate storage in different physical parts of a node or terminal
- H04L49/9078—Intermediate storage in different physical parts of a node or terminal using an external memory or storage device
Description
発明の分野
本発明の分野は、概して、コンピューティングサイエンスに関し、より具体的には、高スループット内部通信プロトコルを用いる画像処理プロセッサに関する。
Field of Invention The field of the invention generally relates to computing science, and more specifically to image processing processors using high throughput internal communication protocols.
背景
画像処理には、通常、アレイに編成された画素値の処理が伴う。ここで、空間的に編成された２次元アレイは、画像の２次元の特性をキャプチャする（さらなる次元として、時間（たとえば、一続きの２次元画像）およびデータ型（たとえば、色）を含み得る）。通常のシナリオでは、配列された画素値は、静止画像または動きを撮影するための一続きのフレームを生成したカメラによって提供される。従来の画像処理プロセッサは、通常、両極端に分かれる。
Background image processing usually involves processing pixel values organized in an array. Here, the spatially organized two-dimensional array may include time (eg, a series of two-dimensional images) and data type (eg, color) as additional dimensions to capture the two-dimensional properties of the image. ). In a typical scenario, the arrayed pixel values are provided by the camera that generated a series of frames for capturing a still image or motion. Traditional image processors are usually divided into two extremes.
第１の極端な側面として、汎用プロセッサまたは汎用のようなプロセッサ（たとえば、ベクトル命令が強化された汎用プロセッサ）上で実行されるソフトウェアプログラムとして、画像処理タスクが実行される。第１の極端な側面は、通常、高度の多目的アプリケーションソフトウェア開発プラットフォームを提供するが、細粒度のデータ構造を、関連するオーバーヘッド（たとえば、命令フェッチおよびデコード、オンチップデータおよびオフチップデータの処理、投機的実行）と組み合わせて利用することによって、最終的には、プログラムコードの実行時にデータの単位当たりに消費されるエネルギーの量が多くなってしまう。 As a first extreme aspect, the image processing task is performed as a software program running on a general purpose processor or a general purpose processor such as a general purpose processor (eg, a general purpose processor with enhanced vector instructions). The first extreme aspect usually provides a highly versatile application software development platform, but with fine-grained data structures, associated overheads (eg instruction fetch and decode, on-chip and off-chip data processing, etc.). When used in combination with speculative execution), the amount of energy consumed per unit of data when executing the program code will eventually increase.
正反対の第２の極端な側面として、より大きな単位のデータに、固定関数結線回路が適用される。カスタム設計された回路に直接適用される（細粒度とは対照的な）より大きな単位のデータを利用することによって、データの単位当たりの消費電力が大幅に抑えられる。しかしながら、カスタム設計された固定関数回路を利用することによって、一般に、プロセッサが実行できるタスクのセットが限られてしまう。このように、第２の極端な側面では、（第１の極端な側面に関連する）広く多目的なプログラミング環境がない。 As the opposite second extreme aspect, fixed function wiring circuits are applied to larger units of data. By utilizing larger units of data (as opposed to fine-grained) that are applied directly to custom-designed circuits, the power consumption per unit of data is significantly reduced. However, the use of custom-designed fixed-function circuits generally limits the set of tasks a processor can perform. Thus, in the second extreme aspect, there is no broad and versatile programming environment (related to the first extreme aspect).
高度の多目的アプリケーションソフトウェア開発機会およびデータの単位当たりの電力効率の向上を可能にするテクノロジープラットフォームが依然として望まれているが、いまだ解決策が見つかっていない。 Technology platforms that enable advanced multipurpose application software development opportunities and improved power efficiency per unit of data are still desired, but no solution has yet been found.
概要
プロセッサを記載する。プロセッサはネットワークを含む。複数の処理コアが当該ネットワークに連結されている。当該プロセッサは、当該ネットワークに連結されたトランスミッタ回路（transmitter circuit）を含む。当該トランスミッタ回路は、当該複数の処理コアのうちの１つによって生成される出力データを当該ネットワーク内に送信するためのものである。当該トランスミッタ回路は制御論理回路を含む。当該制御論理回路は、当該トランスミッタ回路が出力データのうち先行の第１のパケットの送信を完了する前に、当該トランスミッタ回路に、出力データのうち第２のパケットを送信するための要求を送信させる。
Outline Describes the processor. The processor includes the network. A plurality of processing cores are connected to the network. The processor includes a transmitter circuit connected to the network. The transmitter circuit is for transmitting output data generated by one of the plurality of processing cores into the network. The transmitter circuit includes a control logic circuit. The control logic circuit causes the transmitter circuit to transmit a request for transmitting the second packet of the output data before the transmitter circuit completes the transmission of the first packet preceding the output data. ..
以下の説明および添付の図面を用いて、本発明の実施形態を説明する。 Embodiments of the present invention will be described with reference to the following description and accompanying drawings.
詳細な説明
１．０ 固有の画像処理プロセッサのアーキテクチャ
当技術分野において公知であるように、プログラムコードを実行するための基本的な回路構造は、実行ステージとレジスタ空間とを含む。実行ステージは、命令を実行するための実行部を含んでいる。実行される命令のための入力オペランドがレジスタ空間から実行ステージに提供される。実行ステージが命令を実行することによって生成される結果は、レジスタ空間に書き戻される。
Detailed explanation
1.0 Unique Image Processing Processor Architecture As is known in the art, the basic circuit structure for executing program code includes an execution stage and a register space. The execution stage contains an execution unit for executing an instruction. Input operands for the instructions to be executed are provided from the register space to the execution stage. The result produced by the execution stage executing the instruction is written back to the register space.
従来のプロセッサ上でのソフトウェアスレッドの実行には、実行ステージによる、一連の命令の順次実行が伴う。最も一般的には、１つの入力オペランドセットから１つの結果が生成されるという意味では、演算は、「スカラー」である。しかしながら、「ベクトル」プロセッサの場合、実行ステージによる命令の実行によって、入力オペランドのベクトルから結果のベクトルが生成されることになる。 Execution of a software thread on a conventional processor involves the sequential execution of a series of instructions by the execution stage. Most commonly, an operation is a "scalar" in the sense that one result is produced from one set of input operands. However, in the case of a "vector" processor, the execution of an instruction by the execution stage results in the resulting vector being generated from the vector of the input operands.
図１は、２次元シフトレジスタアレイ１０２に連結された実行レーン（execution lane）のアレイ１０１を含む固有の画像処理プロセッサのアーキテクチャ１００を示す高レベル図である。ここで、実行レーンアレイに含まれる各実行レーンは、プロセッサ１００がサポートする命令セットを実行するために必要な実行部を含んだ離散実行ステージとして見ることができる。さまざまな実施形態では、プロセッサが２次元ＳＩＭＤ（Single Instruction Multiple Data）プロセッサとして動作するよう、各実行レーンは、同じマシンサイクルで実行する同じ命令を受け付ける。
FIG. 1 is a high-level
各実行レーンは、２次元シフトレジスタアレイ１０２内の対応する位置に専用のレジスタ空間を有する。たとえば、隅にある実行レーン１０３は、隅にあるシフトレジスタ位置１０４に専用のレジスタ空間を有し、隅にある実行レーン１０５は、隅にあるシフトレジスタ位置１０６に専用のレジスタ空間を有する。
Each execution lane has a dedicated register space at a corresponding position in the two-dimensional
加えて、前のマシンサイクル時に別の実行レーンのレジスタ空間にあった値を各実行レーンが自分のレジスタ空間から直接操作できるよう、シフトレジスタアレイ１０２はコンテンツをシフトさせることができる。たとえば、ａ＋１水平シフトによって、各実行レーンのレジスタ空間に、その左端の隣接するレジスタ空間から値を受け付けさせる。水平軸に沿って左右両方向に値をシフトさせ、垂直軸に沿って上下両方向に値をシフトさせることができる機能のおかげで、プロセッサは、画像データのステンシルを効率よく処理することができる。
In addition, the
ここで、当技術分野において公知であるように、ステンシルとは、基本的データ単位として利用される画像表面領域のスライスである。たとえば、出力画像における特定の画素位置の新しい値が、この特定の画素位置が中心にある入力画像における領域の画素値の平均として算出されてもよい。たとえば、ステンシルが縦に３画素、横に３画素の大きさを有している場合、特定の画素位置は、３×３画素アレイの中央の画素に対応してもよく、３×３画素アレイ内の９つすべての画素の平均が算出されてもよい。 Here, as is known in the art, a stencil is a slice of an image surface region used as a basic data unit. For example, a new value for a particular pixel position in the output image may be calculated as the average of the pixel values in the region of the input image centered on this particular pixel position. For example, if the stencil has a size of 3 pixels vertically and 3 pixels horizontally, the particular pixel position may correspond to the central pixel of the 3x3 pixel array. The average of all nine pixels may be calculated.
図１のプロセッサ１００のさまざまな動作の実施形態によると、実行レーンアレイ１０１の各実行レーンは、出力画像における特定の位置についての画素値を算出する役割を果たす。よって、上記３×３ステンシルを平均する例で引き続き説明すると、入力画素データ、およびシフトレジスタ内の８つのシフト演算からなる調整されたシフトシーケンスを最初にロードした後、実行レーンアレイに含まれる各実行レーンは、対応する画素位置についての平均を算出するのに必要な９つすべての画素値をローカルレジスタ空間に受け付けさせる。つまり、プロセッサは、たとえば、隣接する出力画像の画素位置の中心に存在する複数の重なり合うステンシルを同時に処理することができる。図１のプロセッサのアーキテクチャは、特に画像ステンシルの処理に長けているので、ステンシルプロセッサとも称され得る。
According to various operational embodiments of the
図２は、複数のステンシルプロセッサ２０２＿１～２０２＿Ｎを有する画像処理プロセッサのためのアーキテクチャ２００の一実施形態を示す。このため、画像処理プロセッサは、個々のステンシルプロセッサが画像処理コア、処理コア、プロセッサコア、コアなどのような語として、より一般的に特徴付けられ得るマルチコアプロセッサと称してもよい。図２に見られるように、アーキテクチャ２００は、ネットワーク２０４（たとえば、オンチップスイッチネットワーク、オンチップリングネットワークまたはその他の種類のネットワークを含むＮＯＣ（Network On Chip））を通して複数のステンシルプロセッサユニット２０２＿１～２０２＿Ｎおよび対応するシート生成部２０３＿１～２０３＿Ｎと互いに接続された複数のラインバッファ部２０１＿１～２０１＿Ｍを含む。一実施形態では、いずれのラインバッファ部２０１＿１～２０１＿Ｍも、ネットワーク２０４を通していずれのシート生成部２０３＿１～２０３＿Ｎおよび対応するステンシルプロセッサ２０２＿１～２０２＿Ｎに接続してもよい。
FIG. 2 shows an embodiment of
プログラムコードがコンパイルされ、対応するステンシルプロセッサ２０２上にロードされて、ソフトウェア開発者が以前に定義した画像処理演算が実行される（また、プログラムコードは、たとえば、設計および実装に応じて、ステンシルプロセッサの関連するシート生成部２０３にロードされてもよい）。少なくともいくつかの例では、第１のパイプラインステージ用の第１カーネルプログラムを第１のステンシルプロセッサ２０２＿１にロードし、第２のパイプラインステージ用の第２のカーネルプログラムを第２のステンシルプロセッサ２０２＿２にロードするなどして画像処理パイプラインが実現されてもよい。この場合、第１カーネルがパイプラインの第１のステージの関数を実行し、第２カーネルがパイプラインの第２のステージの関数を実行する等々であって、パイプラインのあるステージからパイプラインの次のステージに出力画像データを渡すためのさらなる制御フロー方法がインストールされている。
The program code is compiled and loaded onto the corresponding
その他の構成では、画像処理プロセッサは、同じカーネルプログラムコードを動作させる２つ以上のステンシルプロセッサ２０２＿１、２０２＿２を有する並列マシンとして実現されてもよい。たとえば、高密度かつ高データ転送速度の画像データストリームを、各々が同じ関数を実行する複数のステンシルプロセッサ間にフレームを分散させることによって処理してもよい。 In other configurations, the image processor may be implemented as a parallel machine with two or more stencil processors 202_1, 202_1 running the same kernel program code. For example, a high density, high data transfer rate image data stream may be processed by distributing frames among multiple stencil processors, each performing the same function.
さらに他の構成では、カーネルの本質的にいずれの有向非巡回グラフ（ＤＡＧ：Directed Acyclic Graph）も、それぞれのステンシルプロセッサを自身のプログラムコードのカーネルで構成し、ＤＡＧ設計において、あるカーネルからの出力画像を次のカーネルの入力に向けるよう適切な制御フローフックをハードウェアに構成することによって、画像処理プロセッサ上にロードされてもよい。 In yet other configurations, essentially any directed acyclic graph (DAG) in the kernel consists of each stencil processor in its own program code kernel, from one kernel in the DAG design. It may be loaded onto the image processing processor by configuring the hardware with appropriate control flow hooks to direct the output image to the input of the next kernel.
一般的なフローとして、画像データのフレームは、マクロ入出力部２０５によって受け付けられ、フレーム単位でラインバッファ部２０１のうちの１つ以上に渡される。特定のラインバッファ部は、画像データのそのフレームを、「ライングループ」と呼ばれる、画像データよりも小さな領域に解析し、その後、当該ライングループを、ネットワーク２０４を通して特定のシート生成部に渡す。完成した、または「完全な」１つのライングループは、たとえば、複数の連続した完全な行または列からなるフレームのデータで構成されてもよい（わかりやすくするために、本明細書では、主に、連続した行を例に用いる）。シート生成部は、さらに、画像データのライングループを、「シート」と呼ばれる、画像データのさらに小さな領域に解析し、このシートを対応するステンシルプロセッサに提示する。
As a general flow, a frame of image data is accepted by the macro input /
１つの入力を有する画像処理パイプラインまたはＤＡＧフローの場合、一般に、入力フレームは、同じラインバッファ部２０１＿１に向けられ、ラインバッファ部２０１＿１は、画像データをライングループに解析し、これらのライングループをシート生成部２０３＿１に向ける。シート生成部２０３＿１の対応するステンシルプロセッサ２０２＿１は、パイプライン／ＤＡＧにおいて第１カーネルのコードを実行している。ステンシルプロセッサ２０２＿１が処理するライングループに対する処理が完了すると、シート生成部２０３＿１は、出力ライングループを「下流」ラインバッファ部２０１＿２に送る（場合によっては、出力ライングループは、以前に入力ライングループを送ったのと同じラインバッファ部２０１＿１に送り返してもよい）。 In the case of an image processing pipeline or DAG flow with one input, the input frames are generally directed to the same line buffer section 201_1, which analyzes the image data into line groups and extracts these line groups. It faces the sheet generation unit 203_1. The corresponding stencil processor 202_1 of the sheet generator 203_1 is executing the code of the first kernel in the pipeline / DAG. When the processing for the line group processed by the stencil processor 202_1 is completed, the sheet generator 203_1 sends the output line group to the “downstream” line buffer unit 201_2 (in some cases, the output line group previously sent the input line group). It may be sent back to the same line buffer unit 201_1).
次に、自身の各々のその他のシート生成部およびステンシルプロセッサ（たとえば、シート生成部２０３＿２およびステンシルプロセッサ２０２＿２）上で実行されるパイプライン／ＤＡＧにおける次のステージ／演算を表す１つ以上の「コンシューマ」カーネルが、第１のステンシルプロセッサ２０２＿１によって生成された画像データを下流ラインバッファ部２０１＿２から受け取る。このように、第１のステンシルプロセッサ上で動作する「プロデューサ」カーネルが、第２のステンシルプロセッサ上で動作する「コンシューマ」カーネルに出力データを転送する。第２のステンシルプロセッサでは、コンシューマカーネルが、パイプラインまたはＤＡＧ全体の設計と整合性のあるプロデューサカーネルの後に次のタスクセットを実行する。 Next, one or more "consumers" representing the next stage / operation in the pipeline / DAG running on their respective other sheet generators and stencil processors (eg, sheet generator 203_2 and stencil processor 202_2). The kernel receives the image data generated by the first stencil processor 202_1 from the downstream line buffer unit 201_2. Thus, the "producer" kernel running on the first stencil processor transfers the output data to the "consumer" kernel running on the second stencil processor. In the second stencil processor, the consumer kernel performs the following task set after the producer kernel, which is consistent with the design of the pipeline or the entire DAG.
図１で上述したように、各ステンシルプロセッサ２０２＿１～２０２＿Ｎは、画像データの複数の重なり合うステンシルを同時に処理するように設計されている。複数の重なり合うステンシルおよびステンシルプロセッサの内蔵ハードウェア処理能力によって、シートのサイズが効果的に決定される。ここでも、上述したように、任意のステンシルプロセッサ２０２＿１～２０２＿Ｎ内で、実行レーンのアレイが一斉に動作し、複数の重なり合うステンシルで覆われた画像データ表面領域を同時に処理する。 As described above in FIG. 1, each stencil processor 202_1 to 202_N is designed to simultaneously process a plurality of overlapping stencils of image data. The built-in hardware processing power of multiple overlapping stencils and stencil processors effectively determines the size of the sheet. Again, as described above, within any stencil processor 202_1 to 202_N, the arrays of execution lanes operate simultaneously to simultaneously process image data surface areas covered by multiple overlapping stencils.
加えて、さまざまな実施形態では、ステンシルプロセッサ２０２の対応する（たとえば、ローカルの）シート生成部２０３によって、当該ステンシルプロセッサの２次元シフトレジスタアレイに画像データのシートがロードされる。シートおよび２次元シフトレジスタアレイ構造の使用によって、たとえば、実行レーンアレイによってその直後に大量のデータに対して直接実行される処理タスクを用いた１つのロード動作として当該データを大量のレジスタ空間に移動することによって、消費電力が効果的に改善されると考えられている。これに加えて、実行レーンアレイおよび対応するレジスタアレイの使用によって、簡単にプログラム可能／構成可能なそれぞれ異なるステンシルサイズが可能になる。ラインバッファ部、シート生成部、およびステンシルプロセッサの動作についてのさらなる詳細を下記のセクション３．０でさらに説明する。
In addition, in various embodiments, the corresponding (eg, local) sheet generator 203 of the
図３は、図２の画像処理プロセッサの特定のハードウェア実装の一実施形態をより詳細に示す。図３に見られるように、図２のネットワーク２０４は、ラインバッファ部３０１とシート生成部／ステンシルプロセッサコア３０２との各交点に４×４ネットワークノード３１４を有するリングトポロジー３０４で実現される。わかりやすくするために、図３は、ラインバッファ部３０１＿４とシート生成部／ステンシルプロセッサコア３０２＿４との間に存在するネットワークノード３１４のみをラベル付けしている。
FIG. 3 shows in more detail an embodiment of a particular hardware implementation of the image processor of FIG. As can be seen in FIG. 3, the
ここで、シート生成部／ステンシルプロセッサコア３０２＿１～３０２＿８の各々がステンシルプロセッサおよび対応するシート生成部の両方を含んでいることが分かる。わかりやすくするために、以下、シート生成部／ステンシルプロセッサコア３０２＿１～３０２＿８の各々を、単に、ステンシルプロセッサコアまたはコアと称す。８つのラインバッファ部３０１＿１～３０１＿８および８つのコア３０２＿１～４０２＿８を図３の特定の実施形態に図示しているが、異なる数のラインバッファ部および／またはコアを有する異なるアーキテクチャが可能であると理解すべきである。リングトポロジー以外のネットワークトポロジーも可能である。 Here, it can be seen that each of the sheet generator / stencil processor cores 302_1 to 302_8 includes both the stencil processor and the corresponding sheet generator. For the sake of clarity, each of the sheet generator / stencil processor cores 302_1 to 302_8 will be simply referred to as a stencil processor core or a core. Eight line buffers 301_1 to 301_8 and eight cores 302_1 to 402_8 are illustrated in the particular embodiment of FIG. 3, but it is understood that different architectures with different numbers of line buffers and / or cores are possible. Should. Network topologies other than ring topologies are also possible.
図３の画像処理プロセッサに関して、リングネットワーク３０４によって、（１）入出力部３０５が入力データを任意のラインバッファ部３０１＿１～３０１＿８（または、任意のコア３０２＿１～３０２＿８）に渡すことができ、（２）任意のラインバッファ部３０１＿１～３０１＿８が任意のコア３０２＿１～３０２＿８にライングループを転送することができ、（３）任意のコア３０２＿１～３０２＿８がその出力データを任意のラインバッファ部３０１＿１～３０１＿８に渡すことができ、（４）任意のラインバッファ部３０１＿１～３０１＿８が、画像処理プロセッサの出力データを入出力部３０５に渡すことができる。このように、異なるソフトウェアカーネルをロードする豊富なオプションおよび内部ネットワーク構成が可能である。つまり、理論上は、プロセッサのさまざまなコア３０２上で実行される複数のカーネルから構成されるソフトウェアアプリケーションのいずれについても、任意のコアに任意のカーネルをロードすることができ、ラインバッファ部のいずれも、任意のコアに入出力データをソース入力し、任意のコアから入出力データをシンク出力するように構成できる。
With respect to the image processing processor of FIG. 3, the
図４は、図３の画像処理プロセッサ上にロードされ得る、例示的なアプリケーションソフトウェアプログラムまたはその一部を示す。図４に見られるように、プログラムコードを実行して入力画像データ４０１の１つ以上のフレームを処理し、何らかの全変換をこの入力画像データ４０１に対して実行してもよい。変換は、入力画像データ上でアプリケーションソフトウェア開発者が明示するうまく組み立てられたシーケンスで動作するプログラムコード４０２の１つ以上のカーネルの動作で実現される。
FIG. 4 shows an exemplary application software program or portion thereof that may be loaded onto the image processor of FIG. As can be seen in FIG. 4, the program code may be executed to process one or more frames of the
図４の例では、全変換は、まず、第１カーネルＫ１を用いて各入力画像を処理することによって生じる。次に、カーネルＫ１によって生成された出力画像は、カーネルＫ２によって処理される。次に、カーネルＫ２によって生成された出力画像の各々は、カーネルＫ３＿１またはＫ３＿２によって処理され、次に、カーネル（複数可）Ｋ３＿１／Ｋ３＿２によって生成された出力画像は、カーネルＫ４によって処理される。図３の特定の例では、カーネルＫ３＿１およびＫ３＿２は、たとえば、異なる画像処理演算を行う異なるカーネルであってもよい（たとえば、カーネルＫ３＿１は、第１の特定の種類の入力画像を処理し、カーネルＫ３＿２は、第２の異なる種類の入力画像を処理する）。 In the example of FIG. 4, the full transformation occurs by first processing each input image using the first kernel K1. Next, the output image generated by kernel K1 is processed by kernel K2. Next, each of the output images produced by kernel K2 is processed by kernel K3_1 or K3_2, and then the output images produced by kernel (s) K3_1 / K3_1 are processed by kernel K4. In the particular example of FIG. 3, kernels K3_1 and K3_1 may be, for example, different kernels performing different image processing operations (eg, kernel K3_1 processes a first particular type of input image and the kernel. K3_2 processes a second different type of input image).
わかりやすくするために、４つのカーネルＫ１～Ｋ４のみを図示している。図３の画像処理プロセッサハードウェアアーキテクチャの実施形態を参照すると、各カーネルが異なるステンシルプロセッサ上で動作するという基本的な構成において、おそらく、プロセッサのコア３０２のすべてが対応するカーネル（図４の４つのカーネルのフローは、図３のプロセッサのコアのうちの半数しか利用していない）を有する前に、カーネルＫ４からさらに４つのカーネルが生じ得ることが分かる。
For clarity, only the four kernels K1 through K4 are shown. Referring to an embodiment of the image processing processor hardware architecture of FIG. 3, in a basic configuration in which each kernel runs on a different stencil processor, perhaps all of the
２．０ トランザクションを効率的に実現するトランシーバ
上述のとおり、１つのステンシルプロセッサ上で実行されているプログラムコードの生成カーネル（producing kernel）は、その出力データを（たとえば、複数ラインのグループとして）ラインバッファ部に送信する。ラインバッファ部は、当該データを（たとえば、複数ラインのグループとして）待ち行列に入れる（queue）かまたは格納して、１つ以上の他のステンシルプロセッサに転送する。１つ以上の他のステンシルプロセッサは、プログラムコードのうち、生成カーネルの出力データを消費するそれぞれのカーネルを実行している。画像処理プロセッサ全体の内部において、複数のラインバッファ部に相互接続された複数のステンシルプロセッサが存在しているので、たとえば、多数の生成／消費カーネル接続が実現され得る。
2.0 Transistor for Efficient Transactions As mentioned above, the producing kernel of program code running on a single stencil processor lines its output data (eg, as a group of multiple lines). Send to the buffer section. The line buffer unit queues or stores the data (eg, as a group of multiple lines) and transfers it to one or more other stencil processors. One or more other stencil processors are running each kernel of the program code that consumes the output data of the generated kernel. Since there are a plurality of stencil processors interconnected to a plurality of line buffers within the entire image processing processor, for example, a large number of generation / consumption kernel connections can be realized.
さまざまな実施形態においては、特定の生成／消費カーネル関係のための格納および転送待ち行列（store and forward queue）は、「バッファ」または「ラインバッファ」と称されてもよく、「ラインバッファ部」は、複数のバッファを同時にサポートすることができるハードウェア構成要素である。ここで、ラインバッファ部は、メモリリソースおよび関連する論理を含んでいてもよい。ラインバッファ部によってサポートされるさまざまなバッファは、それぞれの格納および転送アクティビティのためのメモリリソースのうち異なる部分に割当てられる。 In various embodiments, the store and forward queue for a particular create / consume kernel relationship may be referred to as a "buffer" or "line buffer" and is a "line buffer portion". Is a hardware component that can support multiple buffers at the same time. Here, the line buffer section may include memory resources and related logic. The various buffers supported by the line buffer section are allocated to different parts of the memory resources for their respective storage and transfer activities.
画像処理プロセッサの内部ネットワークは、画像処理プロセッサ内に同時に存在する、ラインバッファ部の通信／接続に対するさまざまな生成カーネルと、消費カーネル通信／接続に対するさまざまなラインバッファ部とをサポートする。ここで、一実施形態においては、各々のステンシルプロセッサは、内部ネットワークに連結されているトランスミッタおよびレシーバからなるトランシーバを含む。同様に、各々のラインバッファ部は、内部ネットワークに連結されたトランシーバを含む。 The internal network of the image processor supports various generation kernels for communication / connection of the line buffer unit and various line buffer units for communication / connection of the consumption kernel unit, which are simultaneously present in the image processor. Here, in one embodiment, each stencil processor includes a transceiver consisting of a transmitter and a receiver connected to an internal network. Similarly, each line buffer section contains a transceiver connected to an internal network.
ステンシルプロセッサとラインバッファ部との組合せによって内部ネットワークに対してどの時点においても提供され得る潜在的に大量のトラフィックがあれば、さまざまな実施形態において、クレジット制御メカニズム（credit control mechanism）は、（ネットワークならびに／または他のリソース、たとえば、ラインバッファ部のメモリリソースおよび／もしくはステンシルプロセッサのローカルメモリリソースなどを含む）画像処理プロセッサ内におけるリソースの過負荷を防ぐために利用される。 In various embodiments, the credit control mechanism is (network), given the potentially large amount of traffic that can be provided to the internal network at any given time by the combination of the stencil processor and the line buffer section. And / or other resources, such as the memory resource of the line buffer section and / or the local memory resource of the stencil processor) are used to prevent overloading of resources in the image processing processor.
たとえば、一実施形態においては、生成ステンシルプロセッサ（生成カーネルを実行しているステンシルプロセッサ、以下、送信プロセッサとする）からラインバッファ部への通信用のラインバッファ部メモリリソースおよび／またはネットワークの過負荷を防ぐために、クレジット制御メカニズムは、生成カーネルからその関連するラインバッファ部までの出力画像データの流れを制御するように、ラインバッファ部の各々において実現される。ここで、ラインバッファ部は、いくつかのクレジットに対する制御を維持するとともに、ラインバッファ部に出力画像データを送信することを所望する送信プロセッサに対してクレジットを発行する。各々のクレジットは、送信プロセッサが送信できるデータ量に相当する。 For example, in one embodiment, the line buffer unit memory resource and / or network overload for communication from the generation stencil processor (stencil processor executing the generation kernel, hereinafter referred to as transmission processor) to the line buffer unit. To prevent this, a credit control mechanism is implemented in each of the line buffer sections to control the flow of output image data from the generation kernel to its associated line buffer section. Here, the line buffer unit maintains control over some credits and issues credits to the transmission processor that wants to transmit the output image data to the line buffer unit. Each credit corresponds to the amount of data that the transmit processor can transmit.
このため、送信プロセッサは、それが有するクレジットの数に相当するデータ量しか送信することができない。ステンシルプロセッサが実際にラインバッファ部にその出力データを送信すると、当該ステンシルプロセッサは、そのクレジットカウントを相当する量にまで減らす。たとえば、各々のクレジットが１ＭＢのデータに相当する場合、送信プロセッサは、それがラインバッファ部に送信するデータの１ＭＢごとに、１ずつ、そのクレジット量（credit amount）を減らす（なお、実際のプロセッサ実現例においては、パケットおよび対応するデータ転送がはるかに細粒化されていること、たとえば、各パケットが典型的には数１０バイトまたは数１００バイトであって、各クレジットが数１０バイト（たとえば３２バイト）に相当することに留意されたい）。ラインバッファ部は、送信プロセッサがデータを送信し続けることができるように、（たとえば、リソースがラインバッファ部内において空になると）送信プロセッサに追加のクレジットを送信し続けてもよい。しかしながら、如何なる場合であっても、送信プロセッサのクレジットカウントがゼロにまで減らされる場合、ラインバッファ部から追加のクレジットを受信するまでラインバッファ部にデータをさらに送信することができない。 Therefore, the transmission processor can transmit only the amount of data corresponding to the number of credits it has. When the stencil processor actually sends its output data to the line buffer section, the stencil processor reduces its credit count to a corresponding amount. For example, if each credit corresponds to 1 MB of data, the transmit processor reduces its credit amount by 1 for each 1 MB of data it sends to the line buffer section (note that the actual processor). In the embodiment, the packet and the corresponding data transfer are much finer, for example, each packet is typically tens or hundreds of bytes and each credit is tens of bytes (eg,). Note that it corresponds to 32 bytes)). The line buffer unit may continue to transmit additional credits to the transmit processor (eg, when resources are empty in the line buffer unit) so that the transmit processor can continue to transmit data. However, in any case, if the credit count of the transmit processor is reduced to zero, further data cannot be transmitted to the line buffer unit until additional credits are received from the line buffer unit.
図５ａは、上述の原理に従って作用する先行技術の設計についての例示的なシナリオを示す。ここで、ラインバッファ部５０２は、送信プロセッサ５０１から受取ったいくつかの単位のデータを保持するための、固定サイズの内部待ち行列（単純化のために図５ａには示されない）を含む。特に、待ち行列がＮ＝５のエントリを有すると想定すると、各々のエントリは特定量のデータ（たとえば、Ｍバイト）を保持することができる。基本的構成においては、送信プロセッサ５０１は、ラインバッファ部５０２との特定の通信セッションまたは「接続」（たとえば、各々がＭバイトを含むデータ単位を複数含んでいるパケットの送信）の際に、各々がＭバイトを含むデータ単位を１つ以上、送信する。送信プロセッサ５０１がラインバッファ部５０２にＭバイトを含む次のデータ単位を送信するたびに、次のデータ単位が待ち行列に入力される。 FIG. 5a shows an exemplary scenario for the prior art design that operates according to the principles described above. Here, the line buffer unit 502 includes a fixed size internal queue (not shown in FIG. 5a for simplification) for holding some units of data received from the transmit processor 501. In particular, assuming that the queue has N = 5 entries, each entry can hold a certain amount of data (eg, M bytes). In a basic configuration, the transmit processor 501 is each during a particular communication session or "connection" (eg, transmission of a packet containing multiple data units, each containing M bytes) with the line buffer unit 502. Transmits one or more data units containing M bytes. Each time the transmit processor 501 transmits the next data unit containing M bytes to the line buffer unit 502, the next data unit is input to the queue.
（たとえば、ラインバッファ部５０２がこれをそのメモリリソースに書込むことができるので）Ｍバイトのデータ単位が待ち行列から供給されると、ラインバッファ部５０２は１つのクレジットを送信プロセッサ５０１に送信する。ここで、待ち行列からＭバイトのデータ単位を供給することで、送信プロセッサ５０１から送信される次のＭバイト単位で満たすことができる１つの待ち行列エントリが実質的に空になる。たとえば、ラインバッファ部５０２が待ち行列から複数のＭバイト単位を高速で供給することができる場合、対応するクレジット量が送信プロセッサ５０１に送信し返される。たとえば、ラインバッファ部５０２が待ち行列から３のＭバイト単位を高速で供給する場合、ラインバッファ部５０２は３つのクレジットを送信プロセッサ５０１に送信し返す。
When M bytes of data units are supplied from the queue (for example, because the line buffer section 502 can write this to its memory resource), the line buffer section 502 sends one credit to the transmit processor 501. .. Here, by supplying M-byte data units from the queue, one queue entry that can be filled by the next M-byte unit transmitted from the transmission processor 501 becomes substantially empty. For example, if the line buffer unit 502 can supply a plurality of Mbyte units from the queue at high speed, the corresponding credit amount is transmitted back to the transmission processor 501. For example, when the line buffer unit 502
このため、図５ａを参照すると、初期状態では、送信プロセッサ５０１は、たとえば、ラインバッファ部５０２に送信するべき出力画像データの次のパケットを有している場合、要求ＲＴＳ＿１を送信するようにとの要求をラインバッファ部５０２に送信する。ラインバッファ部の待ち行列は初めは空であるので、受取り確認（acknowledgement）ＡＣＫ＿１で要求を承諾する際に、ラインバッファ部５０２は、待ち行列のサイズ（Ｎ＝５）と等しいクレジットの量を送信する。送信プロセッサ５０１は、次いで、Ｄ１、Ｄ２、…の順でいくつかのＭバイトデータ単位を送信し始める。データ単位の送信からプロセッサのクレジットカウントの削減までが図５ａのシナリオのプロセッサ側に示されている。 Therefore, referring to FIG. 5a, in the initial state, the transmission processor 501 is requested to transmit the request RTS_1 when it has the next packet of the output image data to be transmitted to the line buffer unit 502, for example. Is transmitted to the line buffer unit 502. Since the queue in the line buffer section is initially empty, the line buffer section 502 sends an amount of credit equal to the size of the queue (N = 5) when accepting a request with acquisition ACK_1. do. The transmission processor 501 then begins transmitting several Mbyte data units in the order D1, D2, .... From the transmission of data units to the reduction of the credit count of the processor is shown on the processor side of the scenario of FIG. 5a.
ラインバッファ部５０２側では、ラインバッファ部５０２が、Ｍのデータ単位を送信プロセッサ５０１から連続して受信し、これらを受信すると待ち行列に入力し、さらに、（たとえば、メモリに書込むために）ラインバッファ部の能力に応じて待ち行列からこれらＭのデータ単位を供給する。待ち行列からＭバイトデータ単位が供給されるたびに、ラインバッファ部５０２は、追加クレジットを送信プロセッサ５０１に送信し、送信プロセッサ５０１が、新しく受信したクレジットをそのクレジットカウントに追加する。 On the line buffer unit 502 side, the line buffer unit 502 continuously receives data units of M from the transmission processor 501, inputs them to the queue when they are received, and further (for example, to write to memory). These M data units are supplied from the queue according to the capacity of the line buffer unit. Each time an Mbyte data unit is supplied from the queue, the line buffer unit 502 sends additional credits to the transmit processor 501, which adds the newly received credits to its credit count.
最終的に、送信プロセッサは、その時点での接続のためにＭバイトデータ単位をすべて送信することとなる（たとえば、或るパケットのうちＭバイトデータ単位がすべて送信されてしまっている）。図５ａのシナリオにおいては、その時点での接続は、６のＭバイトデータ単位でできている（たとえば、パケットが６のＭバイトデータ単位で構成されている）と想定される。そのため、送信プロセッサ５０１は、パケットのためのその最後のデータ単位を送信するとともに、Ｄ６データ単位を送信した。さらに、最終的に、ラインバッファ部５０２は、その待ち行列からＭバイト単位をすべて供給して、対応するクレジットを送信プロセッサ５０１に送信し返してしまっているだろう。そのため、送信プロセッサ５０１は、セッションのためのデータ単位をすべて送信し終えてそのクレジットカウントがラインバッファ部の待ち行列のサイズ（Ｎ＝５）と等しくなると、接続の完了を認識するだろう。ここで、送信プロセッサ５０１はフルセットのクレジットを有しているが、たとえば第２の以降のパケットのために、これらクレジットを用いることは許可されていない。なぜなら、送信プロセッサ５０１が、このような以降のパケットについて、まだ要求を送信していないかまたは如何なる受取り確認も受信していないからである。 Eventually, the transmit processor will send all Mbytes of data for the connection at that point in time (eg, all of the Mbytes of data in a packet have been sent). In the scenario of FIG. 5a, it is assumed that the connection at that time is made up of 6 Mbytes of data (for example, the packet is made up of 6 Mbytes of data). Therefore, the transmit processor 501 transmitted its last data unit for the packet and also transmitted the D6 data unit. Further, finally, the line buffer unit 502 will supply all the M-byte units from the queue and send the corresponding credits back to the transmission processor 501. Therefore, the transmission processor 501 will recognize the completion of the connection when all the data units for the session have been transmitted and the credit count becomes equal to the queue size (N = 5) of the line buffer unit. Here, the transmit processor 501 has a full set of credits, but it is not allowed to use these credits, for example for the second and subsequent packets. This is because the transmit processor 501 has not yet transmitted a request or received any receipt confirmation for such subsequent packets.
図５ａの先行技術の設計においては、送信プロセッサ５０１が現在のセッションの完了前に（たとえば、シナリオの第１のパケットのデータ単位を送信している間）ラインバッファ部５０２に送信するべき別のパケットを有している場合、前のパケットの送信が完了したとみなされた後にしか、第２の以降のパケットについての要求を送信することができない。上述のとおり、送信プロセッサが接続のためのデータをすべて送信して、そのクレジットカウント量がラインバッファ部の待ち行列のサイズ（Ｎ＝５）と等しくなるまで、送信プロセッサによって、接続が完了しているとはみなされない。 In the prior art design of FIG. 5a, another transmission processor 501 should transmit to the line buffer unit 502 before the completion of the current session (eg, while transmitting the data unit of the first packet of the scenario). If it has a packet, it can send a request for a second and subsequent packet only after it is considered that the transmission of the previous packet is complete. As described above, the transmit processor completes the connection until the transmit processor sends all the data for the connection and its credit count equals the size of the queue in the line buffer section (N = 5). Not considered to be.
このアプローチに関する問題は、先行パケットの最後のデータ単位の送信と、後続パケットの第１のデータ単位の送信との間に浪費される可能性のある時間５０４の量である。ここで、図５ａにおいて見られるように、Ｄ６データ単位の送信の時点で第１のパケットの送信が完了しているが、接続は時間５０３までに完了しているとは見なされないことに留意されたい。浪費された時間５０４は、大部分が、第２のパケットについてのＲＴＳ＿２／ＡＣＫ＿２伝搬遅延と連動する待ち行列のサイズと等しくなるように、生成プロセッサがラインバッファ部５０２からのクレジットの返却を待っていた結果、生じるものである。長い待ち時間は、結果として、トラフィックが（他の態様では送信され得たものの）ネットワークを介しては送信されていないという点で、プロセッサが非効率になってしまう可能性がある。
The problem with this approach is the amount of
先行技術の設計に従うと、パケットの最後のデータ単位（たとえばＤ６）が特にマーク付けされるか、または、側波帯信号が、パケットの最後のデータ単位の送信に応じてラインバッファ部５０２に送信される。このため、ラインバッファ部５０２は、それが特定のパケット／接続のためにいつ最後のデータ単位を受信したかが分かるようになる。ここで、パケット／接続の最後のデータ単位（Ｄ６）がラインバッファ部の待ち行列から供給されると、ラインバッファ部５０２は、ＡＣＫ＿２を次の要求ＲＴＳ＿２と認めることが許可される。ここで、完了直後（またはそれよりも前）の第１のパケット／接続の処理中に、ラインバッファ部５０２を用いる他の生成部／消費部カーネル関係についての他の生成プロセッサからの要求は、ラインバッファ部５０２によって受信されていたかもしれない。ラインバッファ部５０２は、完了直後の接続から最後のデータ単位（Ｄ６）を供給した後に次のパケット転送を開始するように、これらの要求のうちの１つ（たとえば、最も古いペンディング中の要求）を自由に承認することができる。 According to the prior art design, the last data unit of the packet (eg D6) is specifically marked, or the sideband signal is transmitted to the line buffer unit 502 in response to the transmission of the last data unit of the packet. Will be done. This allows the line buffer section 502 to know when it received the last data unit for a particular packet / connection. Here, when the last data unit (D6) of the packet / connection is supplied from the queue of the line buffer unit, the line buffer unit 502 is allowed to recognize ACK_2 as the next request RTS_2. Here, during the processing of the first packet / connection immediately after completion (or earlier), the request from the other generation processor regarding the other generation / consumption kernel relation using the line buffer unit 502 is. It may have been received by the line buffer unit 502. The line buffer unit 502 is one of these requests (eg, the oldest pending request) to start the next packet transfer after supplying the last data unit (D6) from the connection immediately after completion. Can be freely approved.
パケット転送がちょうど完了したところの送信プロセッサ５０１は、その先行パケットの転送が完了すると直ちに（図５ａの時間５０３に）、上述のとおり、次の要求ＲＴＳ＿２を自由に送信することができる。他の生成ステンシル・プロセッサからの他の競合する要求がいずれもラインバッファ部５０２でペンディング中でない場合、ラインバッファ部５０２は、先行パケットの転送がちょうど完了したところの送信プロセッサ５０１によって送信された要求ＲＴＳ＿２の受け取り確認をするだろう。第１のパケットに関して上述されたプロセスが繰り返される。
As soon as the transfer of the preceding packet is completed (at
図５ｂは、図５ａの先行技術の設計に対する第１の改善例を示す。この場合、送信プロセッサ５０１が、現在のパケットの送信完了前に次のパケットについての要求ＲＥＱ＿２を送信することが許可されている。すなわち、たとえば、期間５１５は、送信されたパケットが第１のパケットの送信に関与している期間としてみなすことができる（第１のパケットの通信セッションまたは接続が期間５１５にわたっている）。図５ｂの改善された設計においては、送信プロセッサは、送信プロセッサが第１のパケットの送信に関与している間（すなわち、期間５１５内）に、第２のパケットについての要求ＲＥＱ＿２を送信することができる。
FIG. 5b shows a first improvement over the prior art design of FIG. 5a. In this case, the transmit processor 501 is allowed to transmit the request EQU_2 for the next packet before the transmission of the current packet is completed. That is, for example,
図５ｂの特定の例においては、送信プロセッサ５０１は、送信すべき別のパケットを有していることを認識すると直ちに、要求を送信することが許可される。図から分かるように、送信プロセッサ５０１は、それが、第１のパケットについての要求ＲＴＳ＿１を送信したほとんど直ぐ後に送信するべき別のパケットを有していることを認識する（ＲＴＳ＿２はＲＴＳ＿１の直後に送信される）。 In the particular example of FIG. 5b, the transmit processor 501 is allowed to transmit the request as soon as it recognizes that it has another packet to be transmitted. As can be seen from the figure, the transmit processor 501 recognizes that it has another packet to be transmitted almost immediately after transmitting the request RTS_1 for the first packet (RTS_1 immediately after RTS_1). Will be sent).
同様に、改善された設計においては、ラインバッファ部５０２は、たとえその時点で処理しているパケット転送がまだ完了していなくても、要求に自由に応えることができる。たとえば、ラインバッファ部５０２が他の送信プロセッサからの他の競合する要求を有していない（または、ＲＥＱ＿２が、このような競合する要求よりも前にラインバッファ部５０２によって受信されていた）状況においては、ラインバッファ部５０２は自由に第２の要求ＡＣＫ＿２の受け取り確認をすることができる。ここで、第２の受取り確認ＡＣＫ＿２に関連付けられているクレジットはない。なぜなら、すべてのクレジットがその時点でアクティブなパケット（第１のパケット）の転送に充てられているからである。加えて、第２の受取り確認ＡＣＫ＿２が、転送中の現在のパケットを送信している同じ送信プロセッサ５０１に発行されている場合、送信プロセッサ５０１およびラインバッファ部５０２はともに、現在のパケットの転送が完了した後に、現在の送信プロセッサ５０１がラインバッファ部５０２に次のパケットを送信するであろうことを理解する。 Similarly, in the improved design, the line buffer unit 502 is free to respond to the request even if the packet transfer being processed at that time is not yet completed. For example, a situation in which line buffer unit 502 does not have other competing requests from other transmit processors (or EQU_2 was received by line buffer unit 502 prior to such competing requests). In, the line buffer unit 502 can freely confirm the receipt of the second request ACK_2. Here, there is no credit associated with the second receipt confirmation ACK_2. This is because all credits are devoted to the transfer of the currently active packet (first packet). In addition, if the second receipt confirmation ACK_2 is issued to the same transmit processor 501 transmitting the current packet being forwarded, both the transmit processor 501 and the line buffer section 502 will forward the current packet. It is understood that after completion, the current transmit processor 501 will transmit the next packet to the line buffer section 502.
これらの状況下では、送信プロセッサ５０１が、転送されるべき第２のパケットについての受取り確認ＡＣＫ＿２を既に受信していた場合、送信プロセッサ５０１は、第２の次のパケットの送信のために、第１のパケット転送の終端を示す、蓄積されたクレジットを用いることができる。すなわち、図５ａの説明を再び参照すると、送信プロセッサ５０１は、パケットの最後のデータ単位Ｄ６を送信した後に第１のパケット転送の完了を認識する。そのクレジットカウントはラインバッファ部の待ち行列のサイズ（Ｎ＝５）に対応している。 Under these circumstances, if the transmit processor 501 has already received a receipt confirmation ACK_2 for the second packet to be forwarded, the transmit processor 501 has a second packet for transmission of the second next packet. Accumulated credits can be used to indicate the end of one packet transfer. That is, with reference to the description of FIG. 5a again, the transmission processor 501 recognizes the completion of the first packet transfer after transmitting the last data unit D6 of the packet. The credit count corresponds to the size of the queue in the line buffer section (N = 5).
したがって、図５ａの先行技術の設計に従うと、第２のパケットＡＣＫ＿２についての受取り確認がまだ受信されていなかったので、このようなクレジットを直ちに利用することはできなかった。対照的に、図５ｂの改善されたアプローチによれば、送信プロセッサ５０１は、第２のパケットＡＣＫ＿２についての受取り確認を既に受信しているので、第２のパケットの転送のためにこれらのクレジットを直ちに用いることができる。ラインバッファ部５０２は、（図５ａに関連付けて上述された）データ単位Ｄ６を受信することで第１のパケットの完了を認識したので、受信されるべき次のデータ単位が第２のパケットのためのものであることを理解するだろう。 Therefore, according to the prior art design of FIG. 5a, such credits could not be used immediately because the receipt confirmation for the second packet ACK_2 had not yet been received. In contrast, according to the improved approach of FIG. 5b, the transmit processor 501 has already received confirmation of receipt for the second packet ACK_2, so these credits are credited for the transfer of the second packet. It can be used immediately. Since the line buffer unit 502 recognizes the completion of the first packet by receiving the data unit D6 (described above in association with FIG. 5a), the next data unit to be received is the second packet. You will understand that it is.
また、先行技術設計の送信プロセッサ５０１は、現在のラインバッファ部５０２による現在の転送が完了するまで、別のラインバッファ部に次のパケットを転送するようにとの要求を送信することが許可されない（生成カーネルは、２以上のラインバッファ部に出力画像データを送信することができる）。そのため、図５ａの第２のパケットが別のラインバッファ部に送信されることになっていたとしても、浪費された時間５０４が依然として存在することとなるだろう。
Also, the prior art-designed transmit processor 501 is not allowed to send a request to forward the next packet to another line buffer unit until the current transfer by the current line buffer unit 502 is complete. (The generation kernel can send output image data to two or more line buffers). Therefore, even if the second packet of FIG. 5a is to be transmitted to another line buffer unit, the wasted
図５ｂの改善された設計に関連付けて説明されるように、送信プロセッサ５０１はその現在のパケットの完了前に第２のパケットについての要求を送信することが許可されている。さまざまな実施形態においては、これは、送信プロセッサがその時点でそれ自体とのトランザクションに関与しているラインバッファ部とは異なるラインバッファ部に要求を送信することを含む。図５ｂに明確に示されていないが、ＲＴＳ＿２がラインバッファ部５０２以外の他のラインバッファ部に送信されるとともに、ＡＣＫ＿２が当該他のラインバッファ部５０２から受信されると想定する。ここでは、割当てられたクレジット量がラインバッファ部ごとにラインバッファ部上に提供されているので、他のラインバッファ部が認識ＡＣＫ＿２を送信することによって要求を承認すると、送信プロセッサ５０１は、第１のパケットをラインバッファ部５０１に転送している間、他のラインバッファ部から関連するクレジットを受信する。 As described in association with the improved design of FIG. 5b, the transmit processor 501 is allowed to send a request for a second packet before the completion of that current packet. In various embodiments, this includes sending the request to a line buffer unit that is different from the line buffer unit that is currently involved in the transaction with itself. Although not explicitly shown in FIG. 5b, it is assumed that RTS_2 is transmitted to a line buffer unit other than the line buffer unit 502 and ACK_2 is received from the other line buffer unit 502. Here, since the allocated credit amount is provided on the line buffer unit for each line buffer unit, when another line buffer unit approves the request by transmitting the recognition ACK_2, the transmission processor 501 is the first. While forwarding the packet to the line buffer unit 501, it receives related credits from another line buffer unit.
そのため、一実施形態においては、送信プロセッサのトランシーバは複数のクレジットカウンタを維持している。この場合、異なるクレジットカウンタを用いて異なるラインバッファ部からのクレジットを追跡している。第２のパケットが第１のパケットとは異なる宛先に送信されるべき場合、トランスミッタは、複数の宛先のうちの１つの宛先についてのクレジットカウンタのうち第１のクレジットカウンタを用いるとともに、複数の宛先のうち別の宛先についてのクレジットカウンタのうち第２のクレジットカウンタを用いて、第１のパケットおよび第２のパケットを交互にそれぞれの宛先に同時に送信することができる（第１のパケットが完了するまで第２のパケットの送信を待つ必要はない）。さまざまな実施形態においては、どのクレジットカウンタがどの宛先に対応しているのかは、送信プロセッサによって送信されているトラフィックパターンに応じて変化する可能性がある。 Therefore, in one embodiment, the transceiver of the transmit processor maintains a plurality of credit counters. In this case, different credit counters are used to track credits from different line buffers. If the second packet should be sent to a different destination than the first packet, the transmitter will use the first credit counter of the credit counters for one of the destinations and the destinations. The second of the credit counters for another destination can be used to alternately send the first packet and the second packet to their respective destinations at the same time (the first packet is completed). There is no need to wait for the second packet to be sent). In various embodiments, which credit counter corresponds to which destination can vary depending on the traffic pattern being transmitted by the transmit processor.
図５ｃに一例が示されている。図５ｃに見られるように、第１の時間間隔５２１中に、送信プロセッサは第１のパケットを第１のラインバッファ部（ＬＢＵ＿１）に送信している。そのクレジットカウントは第１のクレジットカウンタ５３１に保持される。次いで、第２の時間間隔５２２中、送信プロセッサは、依然として第１のパケットを第１のラインバッファ部に送信しているが、第２のパケットも第２のラインバッファ部（ＬＢＵ＿２）に送信している。第２のパケットについてのクレジットカウントは、第２の異なるクレジットカウンタ５３２において保持されている。なぜなら、第２のパケットについてのクレジットカウントは、第１のクレジットカウンタ５３１に応じてそのトランザクションが進行しているラインバッファ部とは異なるラインバッファ部に送信されているからである。
An example is shown in FIG. 5c. As seen in FIG. 5c, during the
次いで、第３の時間間隔５２３中に、第１のパケットの送信が完了したが、第２のパケットは依然として送信されている。次いで、第４の時間間隔５２４中に、送信プロセッサは、第１のラインバッファ部および第２のラインバッファ部とは異なる第３のラインバッファ（ＬＢＵ＿３）部に第３のパケットを送信する。第３のパケットのクレジットカウントは第１のクレジットカウンタ５３１に保持される。次いで、第５の時間間隔５２５中に、第２のパケットの転送が完了すると、第２のラインバッファ部または他のラインバッファ部に送信するべき次のパケットはなくなる。
Then, during the
次いで、第６の時間間隔５２６中に、送信プロセッサは、第１のラインバッファ部に送信するべき別のパケットを有している。この場合、第２のクレジットカウンタ５３２は、第１のラインバッファ部に送信されるべきこの新しいパケットについてのクレジットを保持するのに用いられる。なお、第１のラインバッファ部についてのクレジットカウンタが、第１のラインバッファ部に送信されるべきパケット対の間でなされるのと同様に、実質的に交換されていたことに留意されたい。すなわち、第１の時間間隔５２１および第２の時間間隔５２２中に、第１のクレジットカウンタ５３１は第１のラインバッファ部についてのクレジットを追跡するために用いられたのに対して、第６の間隔５２６中、第２のクレジットカウンタ５３２は、第１のラインバッファ部についてのクレジットを追跡するために用いられる。
Then, during the
上述の説明がラインバッファ部にデータを送信している処理コアに関係するものであったが、上述の画像処理プロセッサにおいては、同じプロトコルシナリオが、或るラインバッファ部から、消費カーネルを実行する処理コアへのパケット転送のために存在し得ることを指摘することは適切である。この場合、ラインバッファ部は、図５ａから図５ｃの送信機の動作を想定しており、処理コアは、図５ａおよび図５ｂの受信機の動作を想定している。そのため、さまざまな実施形態においては、処理コア（および／または、それらの対応するシート生成部）ならびにラインバッファ部はともに、送信機回路および受信機回路の両方を含む。 The above description was related to the processing core sending data to the line buffer section, but in the image processing processor described above, the same protocol scenario executes the consumption kernel from a line buffer section. It is appropriate to point out that it may exist for packet forwarding to the processing core. In this case, the line buffer unit assumes the operation of the transmitter of FIGS. 5a to 5c, and the processing core assumes the operation of the receiver of FIGS. 5a and 5b. Therefore, in various embodiments, both the processing core (and / or their corresponding sheet generators) and the line buffer unit include both transmitter and receiver circuits.
図６ａおよび図６ｂは、それぞれ、送信機回路および受信機回路の実施形態を示す。図６ａに見られるように、送信機回路６０１は、上述のプロトコルに従ってデータ単位またはＲＴＳ要求を送信するトランスミッタを含む。送信の準備ができているデータ単位は出力待ち行列６０４に入れられる。ＲＴＳおよびクレジット制御論理回路６０５は、クレジットカウンタ６０６＿１および６０６＿２のうちの一方における宛先を備えた現在のセッションのために維持されるクレジットカウントに従って、次のデータ単位のその宛先への送信を認可する。制御論理６０５はまた、適切な宛先を備えた転送セッションを開始するためのＲＴＳ要求を発行する。次のＲＴＳを送信すべき宛先のアイデンティティは、たとえば、アウトバウンド（outbound）待ち行列６０４におけるアウトバウンドパケットに関連付けられた宛先アドレスから判断されてもよい。
6a and 6b show embodiments of a transmitter circuit and a receiver circuit, respectively. As seen in FIG. 6a, the
受信回路６１１は、受取り確認およびクレジット量を受信して、これらを制御論理６０５に転送する。なお、２つのクレジットカウンタ６０６＿１および６０６＿２が６０５の制御論理において観察されることに留意されたい。さまざまな実施形態におけるクレジットカウント６０６＿１および６０６＿２は、図５ｃに関連付けて上述されたように、アウトバウンドトラフィックフローに依拠するために、クレジットを保持するいずれの宛先をも交換し得るように、たとえば通信セッションごとに、特定の宛先についてのクレジットを保持するために割当てられる。 The receiving circuit 611 receives the receipt confirmation and the credit amount and transfers them to the control logic 605. Note that the two credit counters 606_1 and 606_2 are observed in the control logic of 605. The credit counts 606_1 and 606_2 in the various embodiments, as described above in connection with FIG. 5c, are such that, for example, a communication session can be exchanged for any destination holding credits in order to rely on outbound traffic flows. Each is assigned to hold credit for a particular destination.
他の実施形態においては、送信回路６０２が３つ以上の異なる宛先を備える３つ以上の転送セッションを同時に維持することができるように、３つ以上のクレジットカウンタが存在する可能性もある。すなわち、異なる宛先で同時にいくつのトランザクションが行われるかについては、たとえば、ネットワークの能力／容量に応じて、実施形態ごとに異なる可能性がある。一実施形態においては、送信機回路６０１は、第１の先行パケットが送信されている間、第２のパケットについてのＲＴＳを送信することが許可されている。第２のパケットについてのＲＴＳが送信される宛先は、第１の先行パケットが送信されている宛先または他の何らかの宛先であってもよい。
In other embodiments, there may be three or more credit counters so that the transmit
図６ｂは受信機側回路６０２を示す。ここで、受信機回路６２０によって受信される受信データ単位は、インバウンド待ち行列（inbound queue）６０７に入れられている（さまざまな実施形態においては、未処理のクレジットの数がインバウンド待ち行列６０７のサイズに対応していることが想起される）。受信データ単位が待ち行列６０７から供給されると、制御論理６０８は、対応するクレジット量を伝送回路６２１を介してデータ単位の送信機に送信し返す。制御論理６０８はまた、ＲＴＳ要求を受信機６０２に向けて送り出した可能性のある複数の送信機のうちいずれが、受信機６０２が受信するであろうパケットを送信する次の送信機として選ばれるべきであるかを判断する。複数のペンディング中のＲＴＳ要求は、（図６ｂには示されない）制御論理６０８内の待ち行列に存在し得るとともに、論理は、何らかの（たとえば、公平性）アルゴリズムに従って待ち行列からＲＴＳ要求のうちの１つを選択する（たとえば、さまざまな送信機（受信機６０２はこれら送信機から受信するように構成されている）にわたるラウンドロビン、待ち行列における最も古いＲＴＳ、など）。複数の要求送信機のうちどの送信機が受信機へのパケットの送信を許可されるべきであるかを制御論理６０８が判断すると、制御論理６０８は、伝送回路６２１を介して送信機に受取り確認を送信する。
FIG. 6b shows the
さまざまな実施形態においては、受信機がその時点で受信しているパケットの送信元と同じ送信機に送信される受取り確認についてのクレジットは送信されない。加えて、さまざまな実施形態においては、待ち行列６０７のサイズに相当するクレジット量は、受信機６０２がその時点で受信していないパケットの送信元である送信機に送信される受取り確認と共に送信される。さまざまな実施形態においては、受信機６０２は、同じ送信機または異なる送信機からの複数のパケットをインタリーブしない（受信機６０２による受信が許可されるのは、１つの送信機からの１つのパケットだけである）。
In various embodiments, no credit is sent for receipt confirmation sent to the same transmitter as the source of the packet that the receiver is currently receiving. In addition, in various embodiments, the amount of credit corresponding to the size of
制御論理回路６０５および６０８は、制御論理関数またはこれらのアプローチのいずれかの組合せを実行するために、専用のハードウェア論理回路、プログラマブル論理回路（たとえば、フィールドプログラマブルゲートアレイ（field programmable gate array：ＦＰＧＡ）論理回路、プログラマブルロジックデバイス（programmable logic device：ＰＬＤ）論理回路、プログラマブルロジックアレイ（programmable logic array：ＰＬＡ）論理回路）、プログラムコードを実行する埋込み型プロセッサ回路として実現されてもよい。
The
図７は、上述された方法を示す。当該方法は、プロセッサの処理コアの出力データを生成するために処理コア上でプログラムコードを処理するステップ７０１を含む。当該方法は、プロセッサ内のネットワークに連結されているトランスミッタ回路によって、当該トランスミッタ回路が先行の第１のパケットの送信を完了する前に第２のパケットについての送信のための要求を送信するステップ７０２を含む。第２のパケットは、処理コアによって生成される第２の出力データを含み、第１のパケットは、処理コアによって生成される第１の出力データを含む。当該方法はまた、ネットワークに連結されているプロセッサのうち１つ以上の他の処理コアで第１の出力データおよび第２の出力データを処理するステップ７０３を含む。 FIG. 7 shows the method described above. The method comprises processing program code on the processing core to generate output data for the processing core of the processor, step 701. In the method, a transmitter circuit connected to a network in the processor transmits a request for transmission of a second packet before the transmitter circuit completes transmission of the preceding first packet. Step 702 including. The second packet contains the second output data produced by the processing core, and the first packet contains the first output data produced by the processing core. The method also includes step 703 of processing the first output data and the second output data on one or more other processing cores of the processors connected to the network.
３．０ 画像処理プロセッサ実装の実施形態
図８ａ～図８ｅ～図１２は、上述した画像処理プロセッサおよび関連するステンシルプロセッサのさまざまな実施形態のより詳細な動作および設計を提供する。ラインバッファ部がライングループをステンシルプロセッサの関連するシート生成部に送るという図２の説明を思い返すと、図８ａ～図８ｅは、ラインバッファ部２０１の解析アクティビティ、シート生成部２０３の細粒度の解析アクティビティ、およびシート生成部２０３に連結されるステンシルプロセッサ７０２のステンシル処理アクティビティの実施形態を高レベルで示している。
3.0 Embodiments of an image processor implementation FIGS. 8a-8e-12 provide more detailed operation and design of various embodiments of the image processor and related stencil processors described above. Recalling the explanation of FIG. 2 that the line buffer unit sends the line group to the related sheet generation unit of the stencil processor, FIGS. 8a to 8e show the analysis activity of the
図８ａは、画像データ８０１の入力フレームの一実施形態を示す。また、図８ａは、ステンシルプロセッサが処理するように設計された、３つの重なり合うステンシル８０２（各々の寸法は、３画素×３画素である）の輪郭も示している。各ステンシルが出力画像データを生成する出力画素を、黒い実線で強調表示している。わかりやすくするために、３つの重なり合うステンシル８０２は、垂直方向にのみ重なり合うよう示されている。ステンシルプロセッサは、実際には、垂直方向および水平方向の両方に重なり合うステンシルを有するように設計されてもよいことを認識することが適切である。
FIG. 8a shows an embodiment of an input frame of
ステンシルプロセッサ内でステンシル８０２が縦に重なり合っているために、図８ａに見られるように、フレーム内に１つのステンシルプロセッサが処理できる幅広い帯状の画像データが存在する。以下により詳細に説明されているが、一実施形態では、ステンシルプロセッサは、重なり合うステンシル内のデータを、画像データの端から端まで左から右へ処理する（さらに、次のラインセットに対して上から下の順に繰り返す）。このため、ステンシルプロセッサがこの動作で前進を続けると黒い実線の出力画素ブロックの数が水平右方向に増える。上述したように、ラインバッファ部２０１は、ステンシルプロセッサが以降の多くの周期数にわたって処理するのに十分な受信フレームからの入力画像データのライングループを解析する役割を果たす。ライングループの例を、影付き領域８０３として示している。一実施形態では、ラインバッファ部２０１は、シート生成部にライングループを送信／シート生成部からライングループを受信するためのそれぞれ異なる力学を理解できる。たとえば、「グループ全体」と称するあるモードによると、画像データの完全な全幅のラインがラインバッファ部とシート生成部との間で渡される。「実質上縦長」と称する第２モードによると、最初に１つのライングループが全幅の行のサブセットとともに渡される。その後、残りの行がより小さい（全幅未満の）一部として順番に渡される。
Due to the vertical overlap of the
入力画像データのライングループ８０３がラインバッファ部によって規定されてシート生成部に渡されると、シート生成部は、さらに、このライングループを、ステンシルプロセッサのハードウェア制約により正確に適合するより細かいシートに解析する。より具体的には、以下にさらにより詳細に説明されているが、一実施形態では、各ステンシルプロセッサは、２次元シフトレジスタアレイから構成される。２次元シフトレジスタアレイは、本質的に、画像データを実行レーンのアレイの「下」にシフトさせる。シフトパターンは、各実行レーンに、レーン自体の個々のステンシル内のデータを処理させる（つまり、各実行レーンは、それ自体の情報のステンシルを処理し、そのステンシルの出力を生成する）。一実施形態では、シートは、２次元シフトレジスタアレイを「埋める」または２次元シフトレジスタアレイにロードされる入力画像データの表面領域である。
When the
さらにより詳細に後述されているように、さまざまな実施形態では、実際には、任意の周期でシフトさせることができる２次元レジスタデータから構成されるレイヤは複数ある。便宜上、本明細書のほとんどでは、シフトさせることができる２次元レジスタデータから構成される１つ以上のこのようなレイヤを有する構造を指すのに、単に、用語「２次元シフトレジスタ」などを用いている。 As will be described in more detail below, in various embodiments, there are actually a plurality of layers composed of two-dimensional register data that can be shifted at arbitrary intervals. For convenience, most of this specification simply uses the term "two-dimensional shift register" or the like to refer to a structure having one or more such layers composed of two-dimensional register data that can be shifted. ing.
よって、図８ｂに見られるように、シート生成部は、ライングループ８０３からの最初のシート８０４を解析し、ステンシルプロセッサに提供する（ここで、データのシートは、参照番号８０４で全体的に識別される陰影領域に対応する）。図８ｃおよび図８ｄに見られるように、ステンシルプロセッサは、重なり合うステンシル８０２を入力画像データのシートの左から右へ効果的に移動させることによって当該シートを処理する。図８ｄの時点では、シート内のデータから出力値を算出できる画素数はなくなっている（他の画素位置では、シート内の情報から決定される出力値を有し得るものはない）。わかりやすくするために、画像の境界領域は無視している。
Thus, as seen in FIG. 8b, the sheet generator analyzes the
図８ｅに見られるように、次に、シート生成部は、ステンシルプロセッサに引き続き処理させるために次のシート８０５を提供する。なお、次のシートに対する処理を開始するときのステンシルの初期位置は、（すでに図８ｄで示したように）第１シートの画素数がなくなっている箇所から右隣に進んだ場所であることが分かる。新しいシート８０５では、ステンシルプロセッサが第１シートの処理と同じ方法でこの新しいシートを処理するのに従って、ステンシルは、右に移動し続けるだけである。
As seen in FIG. 8e, the sheet generator then provides the
なお、出力画素位置を囲むステンシルの境界領域のために、第１シート８０４のデータと第２シート８０５のデータとの間に重なりがある。この重なりは、シート生成部が重なり合うデータを２回再送信するだけで処理できる。代替的な実装形態では、次のシートをステンシルプロセッサに送るために、シート生成部は、新しいデータをステンシルプロセッサに送るだけであってもよく、ステンシルプロセッサは、重なり合うデータを前のシートから再利用する。
It should be noted that there is an overlap between the data of the
図９は、ステンシルプロセッサのアーキテクチャ９００の一実施形態を示す。図９に見られるように、ステンシルプロセッサは、データ演算部９０１と、スカラープロセッサ９０２および関連するメモリ９０３と、入出力部９０４とを備える。データ演算部９０１は、実行レーン９０５のアレイと、２次元シフトアレイ構造９０６と、アレイの特定の行または列に対応付けられた別個のＲＡＭ９０７とを含む。
FIG. 9 shows an embodiment of the stencil processor architecture 900. As can be seen in FIG. 9, the stencil processor includes a
入出力部９０４は、シート生成部から受け付けたデータの「入力」シートをデータ演算部９０１にロードして、ステンシルプロセッサからのデータの「出力」シートをシート生成部に格納する役割を果たす。一実施形態では、シートデータをデータ演算部９０１にロードすることは、受け付けたシートを画像データの行／列に解析し、画像データの行／列を２次元シフトレジスタ構造９０６または実行レーンアレイ（より詳細に後述される）の行／列のＲＡＭ９０７のそれぞれにロードすることを伴う。シートがメモリ９０７に最初にロードされた場合、実行レーンアレイ９０５内の個々の実行レーンは、適宜、シートデータを（たとえば、シートのデータを処理する直前のロード命令として）ＲＡＭ９０７から２次元シフトレジスタ構造９０６にロードしてもよい。（シート生成部から直接であろうと、メモリ９０７からであろうと）レジスタ構造９０６ほのデータのシートのロードが完了すると、実行レーンアレイ９０５のうちの実行レーンが当該データを処理し、最終的には、仕上がったデータをシートとしてシート生成部またはＲＡＭ９０７に直接「書き戻す」。後者の場合、入出力部９０４がデータをＲＡＭ９０７からフェッチして出力シートを形成し、その後、出力シートはシート生成部に転送される。
The input /
スカラープロセッサ９０２は、プログラムコントローラ９０９を含む。プログラムコントローラ９０９は、ステンシルプロセッサのプログラムコードの命令をスカラーメモリ９０３から読み出し、実行レーンアレイ９０５内の実行レーンにこの命令を発行する。一実施形態では、１つの同じ命令がアレイ９０５内のすべての実行レーンに一斉送信され、データ演算部９０１がＳＩＭＤのような動作を行う。一実施形態では、スカラーメモリ９０３から読み出されて実行レーンアレイ９０５の実行レーンに発行される命令の命令フォーマットは、命令あたり２つ以上のオペコードを含むＶＬＩＷ（Very-Long-Instruction-Word）型フォーマットを含む。さらなる実施形態では、ＶＬＩＷフォーマットは、（後述するが、一実施形態では、２つ以上の従来のＡＬＵ演算を指定し得る）各実行レーンのＡＬＵによって実行される数学関数を指示するＡＬＵオペコード、および（特定の実行レーンまたは特定の実行レーンセットについてのメモリ操作を指示する）メモリオペコードの両方を含む。
The
用語「実行レーン」とは、１つの命令を実行可能な１つ以上の実行部からなるセットを指す（たとえば、命令を実行できる論理回路）。しかしながら、実行レーンは、さまざまな実施形態では、単なる実行部ではなく、よりプロセッサのような機能を含み得る。たとえば、１つ以上の実行部以外に、実行レーンは、受け付けた命令をデコードする論理回路、または、よりＭＩＭＤのような設計の場合、命令をフェッチおよびデコードする論理回路を含んでもよい。ＭＩＭＤのような手法に関しては、本明細書では集中プログラム制御手法が大まかに説明してきたが、さまざまな代替的実施形態（たとえば、アレイ９０５の各実行レーン内にプログラムコードとプログラムコントローラとを含む）では、より分散した手法が実施されてもよい。 The term "execution lane" refers to a set of one or more execution units capable of executing an instruction (eg, a logic circuit capable of executing an instruction). However, in various embodiments, the execution lane may include more processor-like functions than just an execution unit. For example, in addition to one or more execution units, the execution lane may include a logic circuit that decodes the received instruction, or, in the case of a design more like MIMD, a logic circuit that fetches and decodes the instruction. For techniques such as MIMD, centralized program control techniques have been broadly described herein, but various alternative embodiments (eg, including program code and program controller within each execution lane of array 905). Then, a more distributed method may be implemented.
実行レーンアレイ９０５と、プログラムコントローラ９０９と、２次元シフトレジスタ構造９０６とを組み合わせることによって、広範囲のプログラム可能な機能のための広く適合可能／構成可能なハードウェアプラットフォームが提供される。たとえば、個々の実行レーンが多種多様な機能を実行でき、かつ、任意の出力アレイ位置に近接した入力画像データに容易にアクセスできるならば、アプリケーションソフトウェア開発者は、広範囲にわたるさまざまな機能能力および寸法（たとえば、ステンシルサイズ）を有するカーネルをプログラミングすることができる。
The combination of the execution lane array 905, the
実行レーンアレイ９０５によって処理されている画像データ用のデータストアとして機能すること以外に、ＲＡＭ９０７は、１つ以上のルックアップテーブルを保持してもよい。さまざまな実施形態では、１つ以上のスカラールックアップテーブルもスカラーメモリ９０３内でインスタンス化されてもよい。
In addition to acting as a data store for the image data being processed by the execution lane array 905, the
スカラールックアップでは、同じインデックスからの同じルックアップテーブルからの同じデータ値を実行レーンアレイ９０５内の実行レーンの各々に渡すことを伴う。さまざまな実施形態では、スカラープロセッサによって行われるスカラールックアップテーブルの検索動作を指示するスカラーオペコードも含むよう、上述したＶＬＩＷ命令フォーマットが拡大される。オペコードとともに使用するために指定されるインデックスは、即値オペランドであってもよく、または、他のデータ記憶位置からフェッチされてもよい。いずれにせよ、一実施形態では、スカラーメモリ内のスカラールックアップテーブルの検索は、本質的に、同じクロック周期の間に実行レーンアレイ９０５内のすべての実行レーンに同じデータ値を一斉送信することを伴う。ルックアップテーブルの使用および操作のさらなる詳細を以下においてさらに説明する。 Scalar lookup involves passing the same data values from the same lookup table from the same index to each of the execution lanes in the execution lane array 905. In various embodiments, the VLIW instruction format described above is extended to include scalar opcodes that direct the search operation of the scalar lookup table performed by the scalar processor. The index specified for use with the opcode may be an immediate operand or may be fetched from another data storage location. In any case, in one embodiment, the search for the scalar look-up table in the scalar memory essentially broadcasts the same data value to all the execution lanes in the execution lane array 905 during the same clock period. Accompanied by. Further details on the use and operation of look-up tables are described below.
図９ｂは、上述したＶＬＩＷ命令語の実施形態（複数可）を要約している。図９ｂに見られるように、ＶＬＩＷ命令語フォーマットは、次の３つの別個の命令についてのフィールドを含む。（１）スカラープロセッサによって実行されるスカラー命令９５１、（２）実行レーンアレイ内のそれぞれのＡＬＵによってＳＩＭＤ式で一斉送信および実行されるＡＬＵ命令９５２、（３）部分ＳＩＭＤ式で一斉送信および実行されるメモリ命令９５３（たとえば、実行レーンアレイの同じ行にある実行レーンが同じＲＡＭを共有する場合、異なる行の各々からの１つの実行レーンが実際に命令を実行する（メモリ命令９５３のフォーマットは、各行のどの実行レーンが命令を実行するのかを識別するオペランドを含み得る）。
FIG. 9b summarizes embodiments (s) of the VLIW instructions described above. As can be seen in FIG. 9b, the VLIW instruction word format includes fields for three separate instructions: (1)
１つ以上の即値オペランド用のフィールド９５４も含まれている。命令９５１、９５２、９５３のうちのいずれがどの即値オペランド情報を使用するかは、命令フォーマットで識別されてもよい。また、命令９５１、９５２、９５３の各々は、それら自体の入力オペランドおよび結果情報も含む（たとえば、ＡＬＵ演算のためのローカルレジスタ、ならびにメモリアクセス命令のためのローカルレジスタおよびメモリアドレス）。一実施形態では、スカラー命令９５１は、実行レーンアレイ内の実行レーンがその他２つの命令９５２、９５３を実行する前に、スカラープロセッサによって実行される。つまり、ＶＬＩＷ語の実行は、スカラー命令９５１が実行される第１周期を含み、その次にその他の命令９５２、９５３が実行され得る第２周期を含む（なお、さまざまな実施形態では、命令９５２および９５３は、並列で実行されてもよい）。
It also contains
一実施形態では、スカラープロセッサによって実行されるスカラー命令は、データ演算部のメモリまたは２Ｄシフトレジスタからシートをロードする／データ演算部のメモリまたは２Ｄシフトレジスタにシートを格納するためにシート生成部に発行されるコマンドを含む。ここで、シート生成部の動作は、ラインバッファ部の動作によって、または、スカラープロセッサが発行したコマンドをシート生成部が完了させるのにかかる周期の数を実行時前に理解することを防ぐその他の変数によって、異なり得る。このように、一実施形態では、シート生成部に発行されるコマンドにスカラー命令９５１が対応するまたはスカラー命令９５１がコマンドをシート生成部に対して発行させるＶＬＩＷ語は、いずれも、その他の２つの命令フィールド９５２、９５３にＮＯＯＰ（no-operation）命令も含む。次に、シート生成部がデータ演算部へのロード／データ演算部からの格納を完了するまで、プログラムコードは、命令フィールド９５２、９５３のＮＯＯＰ命令のループに入る。ここで、シート生成部にコマンドを発行すると、スカラープロセッサは、コマンドが完了するとシート生成部がリセットするインターロックレジスタのビットを設定してもよい。ＮＯＯＰループの間、スカラープロセッサは、インターロックビットのビットを監視する。シート生成部がそのコマンドを完了したことをスカラープロセッサが検出すると、通常の実行が再び開始される。
In one embodiment, the scalar instruction executed by the scalar processor loads the sheet from the memory of the data calculation unit or the 2D shift register / the sheet generation unit to store the sheet in the memory of the data calculation unit or the 2D shift register. Includes issued commands. Here, the operation of the sheet generator is by the operation of the line buffer, or by the operation of the scalar processor, or by preventing the sheet generator from understanding the number of cycles required to complete the command issued by the scalar processor before execution time. It can vary depending on the variable. As described above, in one embodiment, the VLIW language in which the
図１０は、データ演算コンポーネント１００１の一実施形態を示す。図１０に見られるように、データ演算コンポーネント１００１は、２次元シフトレジスタアレイ構造１００６の「上方」に論理的に位置する実行レーンのアレイ１００５を含む。上述したように、さまざまな実施形態では、シート生成部が提供する画像データのシートが２次元シフトレジスタ１００６にロードされる。次に、実行レーンがレジスタ構造１００６からのシートデータを処理する。
FIG. 10 shows an embodiment of the
実行レーンアレイ１００５およびシフトレジスタ構造１００６は、互いに対して定位置に固定されている。しかしながら、シフトレジスタアレイ１００６内のデータは、戦略的かつ調整された方法でシフトし、実行レーンアレイ内の各実行レーンにデータ内の異なるステンシルを処理させる。このように、各実行レーンは、生成された出力シートに含まれる異なる画素の出力画像値を判断する。図１０のアーキテクチャから、実行レーンアレイ１００５が上下に隣接する実行レーンおよび左右に隣接する実行レーンを含むので、重なり合うステンシルは、縦方向だけでなく、横方向にも配置されていることは明らかである。 The execution lane array 1005 and the shift register structure 1006 are fixed in place with respect to each other. However, the data in the shift register array 1006 shifts in a strategic and coordinated manner, causing each execution lane in the execution lane array to process a different stencil in the data. In this way, each execution lane determines the output image values of the different pixels included in the generated output sheet. From the architecture of FIG. 10, it is clear that the overlapping stencil is arranged not only vertically but also horizontally because the execution lane array 1005 includes the execution lanes adjacent vertically and the execution lanes adjacent to the left and right. be.
データ演算部１００１のいくつかの注目すべきアーキテクチャ上の特徴として、シフトレジスタ構造１００６の寸法は、実行レーンアレイ１００５よりも広い。つまり、実行レーンアレイ１００５の外側にレジスタ１００９の「ハロー（ｈａｌｏ）」が存在する。ハロー１００９は、実行レーンアレイの２つの側面に存在するように図示されているが、実装によっては、ハローは、実行レーンアレイ１００５のより少ない（１つ）またはより多い（３つまたは４つの）側面に存在してもよい。ハロー１００５は、実行レーン１００５の「下」をデータがシフトすると実行レーンアレイ１００５の境界の外側にこぼれ出るデータの「スピルオーバ」空間を提供する役割を果たす。簡単な例として、ステンシルの左端の画素が処理されると、実行レーンアレイ１００５の右端の中心にある５×５ステンシルは、さらに右側に４つのハローレジスタ位置を必要とすることになる。図をわかりやすくするために、図１０は、標準的な実施形態において、いずれの側面（右、下）のレジスタも横接続および縦接続の両方を有し得る場合、ハローの右側のレジスタを横方向にのみシフト接続しているように示しており、ハローの下側のレジスタを縦方向にのみシフト接続しているように示している。さまざまな実施形態では、ハロー領域は、画像処理命令を実行するための対応する実行レーン論理を含まない（たとえば、ＡＬＵは存在しない）。しかしながら、個々のハローレジスタ位置がメモリから個々にデータをロードし、データをメモリに格納できるよう、個々のメモリアクセスユニット（Ｍ）がハロー領域位置の各々に存在する。
As some notable architectural features of the
アレイの各行および／または各列、またはそれらの一部に連結されたさらなるスピルオーバ空間がＲＡＭ１００７によって提供される（たとえば、行方向に４つの実行レーン、列方向に２つの実行レーンにまたがる実行レーンアレイの「領域」に１つのＲＡＭが割り当てられてもよい。わかりやすくするために、残りの明細書では、主に、行ベースおよび／または列ベースの割り当て方式について言及する）。ここで、実行レーンのカーネル動作は、（いくつかの画像処理ルーチンが必要とし得る）２次元シフトレジスタアレイ１００６の外側の画素値を処理する必要がある場合、画像データの面は、たとえば、ハロー領域１００９からＲＡＭ１００７にさらにこぼれ出る（スピルオーバする）ことができる。たとえば、実行レーンアレイの右端の実行レーンの右側に４つのストレージ要素のみから構成されるハロー領域をハードウェアが含む、６×６ステンシルについて考える。この場合、ステンシルを完全に処理するために、データは、さらに右にシフトされてハロー１００９の右端からはみ出る必要がある。ハロー領域１００９の外にシフトされるデータは、その後、ＲＡＭ１００７にこぼれ出る。ＲＡＭ１００７および図９のステンシルプロセッサのその他の適用例をさらに以下に説明する。
Additional spillover space connected to each row and / or column of the array, or parts thereof, is provided by RAM 1007 (eg, an execution lane array that spans four execution lanes in the row direction and two execution lanes in the column direction). One RAM may be allocated to the "area" of. For the sake of clarity, the rest of the specification primarily refers to row-based and / or column-based allocation schemes). Here, if the kernel operation of the execution lane needs to process the pixel values outside the two-dimensional shift register array 1006 (which may be required by some image processing routines), the surface of the image data may be, for example, halo. Further spills (spill over) from the
図１１ａ～図１１ｋは、上述したように実行レーンアレイの「下」の２次元シフトレジスタアレイ内で画像データがシフトされる方法の例を説明する。図１１ａに見られるように、２次元シフトアレイのデータコンテンツが第１アレイ１１０７に図示され、実行レーンアレイがフレーム１１０５によって図示されている。また、実行レーンアレイ内の２つの隣接する実行レーン１１１０を簡略化して図示している。この単純化した図示１１１０では、各実行レーンはレジスタＲ１を含む。レジスタＲ１は、シフトレジスタからデータを受け付けることができるか、（たとえば、周期間の累算器として動作するために）ＡＬＵ出力からデータを受け付けることができるか、または、出力データを出力宛先に書き込むことができる。
11a-11k illustrate an example of how the image data is shifted within the "bottom" two-dimensional shift register array of the execution lane array as described above. As seen in FIG. 11a, the data content of the two-dimensional shift array is illustrated in the
また、各実行レーンは、ローカルレジスタＲ２において、その「下」のコンテンツを２次元シフトアレイにおいて利用可能である。よって、Ｒ１は、実行レーンの物理レジスタであるのに対して、Ｒ２は、２次元シフトレジスタアレイの物理レジスタである。実行レーンは、Ｒ１および／またはＲ２が提供するオペランドを処理できるＡＬＵを含む。以下においてさらに詳細に記載するが、一実施形態では、シフトレジスタは、実際には、アレイ位置ごとに複数のストレージ／レジスタ要素（の「深度」）を有して実装されるが、シフトアクティビティは、ストレージ要素の１つの面に限られる（たとえば、ストレージ要素の１つの面のみが周期ごとにシフトできる）。図１１ａ～１１ｋは、これらの深度がより深いレジスタ位置のうちの１つを、それぞれの実行レーンからの結果Ｘを格納するのに用いられるものとして示している。図をわかりやすくするために、深度がより深い結果レジスタは、対応するレジスタＲ２の下ではなく、横に並べて図示されている。 Also, each execution lane has its "below" content available in the 2D shift array in the local register R2. Therefore, R1 is the physical register of the execution lane, while R2 is the physical register of the two-dimensional shift register array. The execution lane contains an ALU capable of processing the operands provided by R1 and / or R2. As described in more detail below, in one embodiment the shift register is actually implemented with multiple storage / register elements (the "depth") per array position, but the shift activity is , Limited to one aspect of the storage element (eg, only one aspect of the storage element can be shifted per period). 11a-11k show one of these deeper register positions as being used to store the result X from each execution lane. For the sake of clarity, the deeper result registers are shown side by side rather than under the corresponding register R2.
図１１ａ～１１ｋは、実行レーンアレイ内に図示された実行レーン位置１１１１のペアと中央位置が揃えられた２つのステンシルの算出に焦点を当てている。図をわかりやすくするために、実行レーン１１１０のペアは、実際には下記の例によると縦方向に隣接している場合に、横方向に隣接するものとして示されている。
FIGS. 11a-11k focus on the calculation of two stencils aligned with the pair of
最初に、図１１ａに見られるように、実行レーンは、その中央のステンシル位置の中心に位置決めされる。図１１ｂは、両方の実行レーンによって実行されるオブジェクトコードを示す。図１１ｂに見られるように、両方の実行レーンのプログラムコードによって、シフトレジスタアレイ内のデータは、位置を下に１つシフトさせられ、位置を右に１つシフトさせられる。これにより、両方の実行レーンがそれぞれのステンシルの左上隅に揃えられる。次に、プログラムコードは、（Ｒ２において）それぞれの位置にあるデータをＲ１にロードさせる。 First, as seen in FIG. 11a, the execution lane is positioned at the center of its central stencil position. FIG. 11b shows the object code executed by both execution lanes. As can be seen in FIG. 11b, the program code in both execution lanes causes the data in the shift register array to be shifted one position down and one position to the right. This aligns both run lanes in the upper left corner of each stencil. The program code then loads the data at each position (in R2) into R1.
図１１ｃに見られるように、次に、プログラムコードは、実行レーンのペアに、シフトレジスタアレイ内のデータを１単位だけ左にシフトさせ、これによって、各実行レーンのそれぞれの位置の右にある値が、各実行レーンの位置にシフトされる。次に、（Ｒ２における）実行レーンの位置までシフトされた新しい値がＲ１の値（前の値）に加算される。その結果がＲ１に書き込まれる。図１１ｄに見られるように、図１１ｃで説明したのと同じ処理が繰り返され、これによって、結果Ｒ１は、ここで、上部実行レーンにおいて値Ａ＋Ｂ＋Ｃを含み、下部実行レーンにおいてＦ＋Ｇ＋Ｈを含む。この時点で、両方の実行レーンは、それぞれのステンシルの上側の行を処理済みである。なお、データは、実行レーンアレイの左側のハロー領域（左側に存在する場合）にこぼれ出るが、ハロー領域が実行レーンアレイの左側に存在しない場合はＲＡＭにこぼれ出る。 As can be seen in FIG. 11c, the program code then shifts the data in the shift register array to the left by one unit to the pair of execution lanes, thereby to the right of each position in each execution lane. The value is shifted to the position of each run lane. Next, the new value shifted to the position of the execution lane (in R2) is added to the value of R1 (previous value). The result is written in R1. As seen in FIG. 11d, the same process as described in FIG. 11c is repeated, whereby the result R1 now includes the values A + B + C in the upper execution lane and F + G + H in the lower execution lane. At this point, both run lanes have processed the upper row of their respective stencils. Note that the data spills into the halo area on the left side of the execution lane array (if it exists on the left side), but spills into the RAM if the halo area does not exist on the left side of the execution lane array.
図１１ｅに見られるように、次に、プログラムコードは、シフトレジスタアレイ内のデータを１単位だけ上にシフトさせ、これによって、両方の実行レーンがそれぞれのステンシルの中央行の右端に揃えられる。両方の実行レーンのレジスタＲ１は、このとき、ステンシルの最上行および中央行の右端の値の総和を含む。図１１ｆおよび図１１ｇは、両方の実行レーンのステンシルの中央行を左方向に移動する続きの進行を説明する図である。図１１ｇの処理の終わりに両方の実行レーンがそれぞれのステンシル最上行および中央行の値の総和を含むよう、累積加算が続く。 As can be seen in FIG. 11e, the program code then shifts the data in the shift register array up by one unit, thereby aligning both execution lanes to the right edge of the center row of each stencil. Register R1 in both execution lanes then contains the sum of the values at the rightmost of the top and center rows of the stencil. 11f and 11g are diagrams illustrating a continuation of the movement to the left in the center row of the stencils of both execution lanes. Cumulative addition is continued at the end of the process of FIG. 11g so that both execution lanes contain the sum of the values in the top and center rows of the respective stencil.
図１１ｈは、各実行レーンを対応するステンシルの最下行に揃えるための別のシフトを示す。図１１ｉおよび図１１ｊは、両方の実行レーンのステンシルに対する処理を完了するための、続きのシフト処理を示す。図１１ｋは、データ配列において各実行レーンをその正しい位置に揃えて結果をそこに書き込むためのさらなるシフト処理を示す。 FIG. 11h shows another shift to align each execution lane to the bottom row of the corresponding stencil. 11i and 11j show subsequent shift processing to complete the processing for the stencils of both execution lanes. FIG. 11k shows a further shift process for aligning each execution lane to its correct position in the data array and writing the result there.
なお、図１１ａ～図１１ｋの例では、シフト演算用のオブジェクトコードは、（Ｘ，Ｙ）座標で表されるシフトの方向および大きさを識別する命令フォーマットを含んでもよい。たとえば、位置を１つ上にシフトさせるためのオブジェクトコードは、ＳＨＩＦＴ０、＋１というオブジェクトコードで表されてもよい。別の例として、位置を右に１つシフトすることは、ＳＨＩＦＴ＋１、０というオブジェクトコードで表現されてもよい。また、さまざまな実施形態では、より大きなシフトも、オブジェクトコード（たとえば、ＳＨＩＦＴ０、＋２）で指定されてもよい。ここで、２Ｄシフトレジスタハードウェアが周期あたり位置１つ分のシフトしかサポートしない場合、命令は、マシンによって、複数周期の実行を必要とすると解釈されてもよく、または、周期あたり位置２つ分以上のシフトをサポートするよう２Ｄシフトレジスタハードウェアが設計されてもよい。後者の実施形態をより詳細にさらに後述する。 In the example of FIGS. 11a to 11k, the object code for the shift operation may include an instruction format for identifying the direction and magnitude of the shift represented by the (X, Y) coordinates. For example, the object code for shifting the position up by one may be represented by the object code SHIFT0, +1. As another example, shifting the position by one to the right may be represented by the object code SHIFT + 1,0. Also, in various embodiments, larger shifts may also be specified in the object code (eg, SHIFT0, +2). Here, if the 2D shift register hardware supports only one position shift per cycle, the instruction may be interpreted by the machine as requiring execution of multiple cycles, or two positions per cycle. 2D shift register hardware may be designed to support these shifts. The latter embodiment will be described in more detail later.
図１２は、実行レーンおよび対応するシフトレジスタ構造（ハロー領域のレジスタは、対応する実行レーンを含まないが、さまざまな実施形態のメモリを含む）の単位セルをより詳細に示す別の図である。実行レーン、および実行レーンアレイの各位置に対応付けられたレジスタ空間は、一実施形態では、図１２に見られる回路を実行レーンアレイの各ノードにおいてインスタンス化することによって実現される。図１２に見られるように、単位セルは、４つのレジスタＲ２～Ｒ５から構成されるレジスタファイル１２０２に連結された実行レーン１２０１を含む。いずれの周期の間も、実行レーン１２０１は、レジスタＲ１～Ｒ５のうちのいずれかから読み出されたり、書き込まれたりしてもよい。２つの入力オペランドを必要とする命令については、実行レーンは、両方のオペランドをＲ１～Ｒ５のうちのいずれかから取り出してもよい。
FIG. 12 is another diagram showing in more detail the unit cells of the execution lane and the corresponding shift register structure (registers in the halo region do not include the corresponding execution lane but include memory of various embodiments). .. The register space associated with each position of the execution lane and the execution lane array is realized in one embodiment by instantiating the circuit seen in FIG. 12 at each node of the execution lane array. As can be seen in FIG. 12, the unit cell includes an
一実施形態では、２次元シフトレジスタ構造は、１つの周期の間、レジスタＲ２～Ｒ４のうちのいずれか１つ（のみ）のコンテンツを出力マルチプレクサ１２０３を通してその隣接するレジスタのレジスタファイルのうちの１つにシフト「アウト」させ、隣接するレジスタ間のシフトが同じ方向になるよう、レジスタＲ２～Ｒ４のうちのいずれか１つ（のみ）のコンテンツを対応するレジスタファイルから入力マルチプレクサ１２０４を通してシフト「イン」されるコンテンツと置き換えることによって実現される（たとえば、すべての実行レーンが左にシフトする、すべての実行レーンが右にシフトする、など）。同じレジスタのコンテンツがシフトアウトされて、同じ周期上でシフトされるコンテンツと置き換えられることは一般的であり得るが、マルチプレクサ配列１２０３、１２０４は、同じ周期の間、同じレジスタファイル内で異なるシフト元および異なるシフト対象のレジスタを可能にする。
In one embodiment, the two-dimensional shift register structure transfers the contents of any one (only) of registers R2 to R4 (only) through the
図１２に示すように、シフトシーケンスの間、実行レーンは、そのレジスタファイル１２０２からその左隣、右隣、上隣、および下隣の各々にコンテンツをシフトアウトすることになることが分かる。同じシフトシーケンスと連動して、実行レーンは、そのレジスタファイルに左隣、右隣、上隣、および下隣のうちの特定のレジスタファイルからコンテンツをシフトする。ここでも、シフトアウトする対象およびシフトインする元は、すべての実行レーンについて同じシフト方向に一致していなければならない（たとえば、右隣にシフトアウトする場合、シフトインは左隣からでなければならない）。
As shown in FIG. 12, it can be seen that during the shift sequence, the execution lane will shift out content from its
一実施形態において、周期あたり実行レーン１つにつき１つのレジスタのコンテンツのみをシフトさせることが可能であるが、その他の実施形態は、２つ以上のレジスタのコンテンツをシフトイン／アウトさせることが可能であってもよい。たとえば、図１２に見られるマルチプレクサ回路１２０３、１２０４の第２インスタンスが図１２の設計に組み込まれている場合、同じ周期で２つのレジスタのコンテンツをシフトアウト／インしてもよい。当然、周期ごとに１つのレジスタのコンテンツのみをシフトさせることができる実施形態では、数値演算間のシフトのためにより多くのクロック周期を消費することによって複数のレジスタからのシフトが数値演算間で生じてもよい（たとえば、数値演算間の２つのシフト演算を消費することによって２つのレジスタのコンテンツが当該数値演算間でシフトされてもよい）。
In one embodiment, it is possible to shift only the contents of one register per execution lane per cycle, while in other embodiments it is possible to shift in / out the contents of two or more registers. May be. For example, if a second instance of the
なお、シフトシーケンス時に実行レーンのレジスタファイルのすべてのコンテンツよりも少ない数のコンテンツがシフトアウトされた場合、各実行レーンのシフトアウトされなかったレジスタのコンテンツは、所定の位置に留まっている（シフトしない）ことが分かる。このように、シフトインされたコンテンツに置き換えられないシフトされなかったコンテンツは、いずれも、シフト周期にわたって、実行レーンにローカルに留まる。各実行レーンに見られるメモリユニット（「Ｍ」）を使用して、実行レーンアレイ内の実行レーンの行および／または列に対応付けられたランダムアクセスメモリ空間からデータをロード／またはそれに格納する。ここで、Ｍユニットは、標準Ｍユニットとして機能し、標準Ｍユニットは、実行レーン自体のレジスタ空間からロード／またはそれに格納できないデータをロード／格納するために利用される場合が多い。さまざまな実施形態では、Ｍユニットの主な動作は、ローカルレジスタからのデータをメモリに書き込み、メモリからデータを読み出してローカルレジスタに書き込むことである。 If a smaller number of contents than all the contents of the register file of the execution lane are shifted out during the shift sequence, the contents of the unshifted registers of each execution lane remain in a predetermined position (shift). I don't know). Thus, any unshifted content that is not replaced by shifted-in content remains local to the execution lane over the shift cycle. The memory unit (“M”) found in each run lane is used to load / or store data from the random access memory space associated with the rows and / or columns of the run lanes in the run lane array. Here, the M unit functions as a standard M unit, and the standard M unit is often used to load / store data that cannot be loaded / or stored in the register space of the execution lane itself. In various embodiments, the main operation of the M unit is to write data from the local register to memory, read data from memory and write to the local register.
ハードウェア実行レーン１２０１のＡＬＵユニットがサポートするＩＳＡオペコードに関して、さまざまな実施形態では、ハードウェアＡＬＵがサポートする数値演算オペコードは、（たとえば、ＡＤＤ、ＳＵＢ、ＭＯＶ、ＭＵＬ、ＭＡＤ、ＡＢＳ、ＤＩＶ、ＳＨＬ、ＳＨＲ、ＭＩＮ／ＭＡＸ、ＳＥＬ、ＡＮＤ、ＯＲ、ＸＯＲ、ＮＯＴ）を含む。上述したように、実行レーン１２０１によって、関連するＲＡＭからデータをフェッチ／当該ＲＡＭにデータを格納するためのメモリアクセス命令が実行され得る。これに加えて、ハードウェア実行レーン１２０１は、２次元シフトレジスタ構造内でデータをシフトさせるためのシフト演算命令（右、左、上、下）をサポートする。上述したように、プログラム制御命令は、主に、ステンシルプロセッサのスカラープロセッサによって実行される。
With respect to the ISA opcodes supported by the ALU unit in the
４．０ 実装の実施形態
上述したさまざまな画像処理プロセッサのアーキテクチャの特徴は、必ずしも従来の意味での画像処理に限られないため、画像処理プロセッサを新たに特徴付け得る（または、させ得ない）その他のアプリケーションに適用され得ることを指摘することが適切である。たとえば、上述したさまざまな画像処理プロセッサのアーキテクチャの特徴のうちのいずれかが、実際のカメラ画像の処理とは対照的に、アニメーションの作成ならびに／または生成および／もしくは描画に使用される場合、画像処理プロセッサは、ＧＰＵ（Graphics Processing Unit）として特徴付けられてもよい。加えて、上述した画像処理プロセッサアーキテクチャの特徴を、映像処理、視野処理、画像認識および／または機械学習など、その他の技術用途に適用してもよい。このように適用すると、画像処理プロセッサは、（たとえば、コプロセッサとして）、（たとえば、コンピューティングシステムのＣＰＵ（Central Processing Unit）もしくはその一部である）より汎用的なプロセッサと統合されてもよく、または、コンピューティングシステム内のスタンドアロン型のプロセッサであってもよい。
4.0 Implementation Embodiments The various image processing processor architectures described above are not necessarily limited to image processing in the conventional sense, and thus can (or cannot) newly characterize the image processing processor. It is appropriate to point out that it can be applied to other applications. For example, if any of the architectural features of the various image processor described above are used to create and / or generate and / or draw an animation, as opposed to processing the actual camera image, the image. The processing processor may be characterized as a GPU (Graphics Processing Unit). In addition, the features of the image processing processor architecture described above may be applied to other technical applications such as video processing, visual field processing, image recognition and / or machine learning. When applied in this way, the image processor may be integrated (eg, as a coprocessor) with a more general purpose processor (eg, the CPU (Central Processing Unit) of a computing system or part thereof). , Or it may be a stand-alone processor in the computing system.
上述したハードウェア設計の実施形態は、半導体チップ内に実施されてもよく、および／または、最終的に半導体製造プロセスに向けての回路設計の記述として実施されてもよい。後者の場合、このような回路記述は、（たとえば、ＶＨＤＬまたはＶｅｒｉｌｏｇ）レジスタ転送レベル（ＲＴＬ：Register Transfer Level）回路記述、ゲートレベル回路記述、トランジスタレベル回路記述もしくはマスク記述、またはそれらのさまざまな組合せなどの形態をとり得る。回路記述は、通常、コンピュータ読み取り可能な記憶媒体（ＣＤ－ＲＯＭまたはその他の種類のストレージ技術など）上で実施される。 The hardware design embodiment described above may be implemented in a semiconductor chip and / or may finally be implemented as a description of a circuit design for a semiconductor manufacturing process. In the latter case, such circuit descriptions may be (eg, VHDL or Verilog) register transfer level (RTL) circuit descriptions, gate level circuit descriptions, transistor level circuit descriptions or mask descriptions, or various combinations thereof. It can take the form of. Circuit description is typically performed on a computer-readable storage medium (such as a CD-ROM or other type of storage technology).
上記段落から、後述する画像処理プロセッサをコンピュータシステム上のハードウェアで（たとえば、ハンドヘルド端末のカメラからのデータを処理するハンドヘルド端末のＳＯＣ（System On Chip）の一部として）実施してもよいことを認識することが適切である。なお、画像処理プロセッサがハードウェア回路として実施された場合、画像処理プロセッサによって処理される画像データをカメラから直接受け付けてもよいことが分かる。ここで、画像処理プロセッサは、単品カメラの一部、またはカメラを内蔵したコンピューティングシステムの一部であってもよい。後者の場合、カメラからまたはコンピューティングシステムのシステムメモリから画像データを直接受け付けてもよい（たとえば、カメラは、その画像データを、画像処理プロセッサではなくシステムメモリに送る）。また、上記段落に記載の特徴の多くは、（アニメーションを描画する）ＧＰＵに適用可能である。 From the above paragraph, the image processor described below may be implemented in hardware on a computer system (for example, as part of the SOC (System On Chip) of a handheld terminal that processes data from the camera of the handheld terminal). It is appropriate to recognize. When the image processor is implemented as a hardware circuit, it can be seen that the image data processed by the image processor may be directly received from the camera. Here, the image processing processor may be a part of a single camera or a part of a computing system having a built-in camera. In the latter case, the image data may be received directly from the camera or from the system memory of the computing system (for example, the camera sends the image data to the system memory instead of the image processor). Also, many of the features described in the paragraph above are applicable to the GPU (which draws the animation).
図１３は、コンピューティングシステムを例示的に示している。上述したコンピューティングシステムの構成要素のうちの多くは、内蔵カメラおよび関連する画像処理プロセッサ（たとえば、スマートフォンまたはタブレットコンピュータなどのハンドヘルド端末）を有するコンピューティングシステムに適用可能である。当業者は、これら２つの違いを容易に明確にするであろう。これに加えて、図１３のコンピューティングシステムは、ワークステーションまたはスーパーコンピュータなどの高性能なコンピューティングシステムの多くの特徴も含んでいる。 FIG. 13 illustrates an exemplary computing system. Many of the components of the computing system described above are applicable to computing systems with built-in cameras and associated image processing processors (eg, handheld terminals such as smartphones or tablet computers). Those skilled in the art will easily clarify the difference between the two. In addition to this, the computing system of FIG. 13 also includes many features of a high performance computing system such as a workstation or supercomputer.
図１３に見られるように、基本的なコンピューティングシステムは、ＣＰＵ１３０１（たとえば、マルチコアプロセッサまたはアプリケーションプロセッサ上に配置された複数の汎用処理コア１３１５＿１～１３１５＿Ｎおよびメインメモリコントローラ１３１７を含んでもよい）と、システムメモリ１３０２と、ディスプレイ１３０３（たとえば、タッチスクリーン、フラットパネル）と、ローカル有線ポイントツーポイントリンク（たとえば、ＵＳＢ）インタフェース１３０４と、さまざまなネットワーク入出力機能部１３０５（Ｅｔｈｅｒｎｅｔ（登録商標）インタフェースおよび／またはセルラーモデムサブシステムなど）と、無線ローカルエリアネットワーク（たとえば、WiFi）インタフェース１３０６と、無線ポイントツーポイントリンク（たとえば、Bluetooth（登録商標））インタフェース１３０７およびＧＰＳ（Global Positioning System）インタフェース１３０８と、さまざまなセンサ１３０９＿１～１３０９＿Ｎと、１つ以上のカメラ１３１０と、バッテリー１３１１と、電力管理制御部１３１２と、スピーカ／マイクロフォン１３１３と、オーディオコーダ／デコーダ１３１４とを含んでもよい。
As seen in FIG. 13, a basic computing system may include a CPU 1301 (eg, a plurality of general purpose processing cores 1315_1 to 1315_N and a
アプリケーションプロセッサまたはマルチコアプロセッサ１３５０は、そのＣＰＵ１２０１内に１つ以上の汎用処理コア１３１５と、１つ以上のＧＰＵ１３１６と、メモリ管理機能部１３１７（たとえば、メモリコントローラ）と、入出力制御機能部１３１８と、画像処理部１３１９とを含んでもよい。汎用処理コア１３１５は、通常、コンピューティングシステムのオペレーティングシステムおよびアプリケーションソフトウェアを実行する。ＧＰＵ１３１６は、通常、グラフィックスを多く使う機能を実行して、たとえば、ディスプレイ１３０３上に提示されるグラフィックス情報を生成する。メモリ制御機能部１３１７は、システムメモリ１３０２とインタフェース接続され、システムメモリ１３０２にデータを書き込む／システムメモリ１３０２からデータを読み出す。電力管理制御部１３１２は、一般に、システム１３００の消費電力を制御する。
The application processor or
画像処理部１３１９は、上記段落で詳細に記載された画像処理部の実施形態のいずれかに従って実現されてもよい。代替的には、またはこれと組み合わせて、ＩＰＵ１３１９がＧＰＵ１３１６およびＣＰＵ１３０１のいずれかまたは両方に、そのコプロセッサとして連結されてもよい。これに加えて、さまざまな実施形態では、ＧＰＵ１３１６は、詳細に上述した画像処理プロセッサの特徴のいずれかを用いて実現されてもよい。画像処理部１３１９、またはデータを送信するコンピューティングシステムの他の部は、詳細に上述されたように、効率的な通信シーケンスを実現するトランシーバで構成されてもよい。
The
タッチスクリーンディスプレイ１３０３、通信インタフェース１３０４～１３０７、ＧＰＳインタフェース１３０８、センサ１３０９、カメラ１３１０、およびスピーカ／マイクロフォンコーデック１３１３、１３１４の各々は、すべて、内蔵型周辺機器（たとえば、１つ以上のカメラ１３１０）も適宜備えたコンピュータシステム全体に対するさまざまな形態のＩ／Ｏ（入力部および／または出力部）として見ることができる。実現例によっては、これらのＩ／ＯコンポーネントのうちのさまざまなＩ／Ｏコンポーネントがアプリケーションプロセッサ／マルチコアプロセッサ１３５０上に集積されてもよく、ダイからずれて配置されてもよく、またはアプリケーションプロセッサ／マルチコアプロセッサ１３５０のパッケージの外に配置されてもよい。
Each of the touch screen display 1303, communication interface 1304-1307,
一実施形態では、１つ以上のカメラ１３１０は、カメラと視野に存在するオブジェクトとの間の奥行きを測定可能な深度カメラを含む。アプリケーションプロセッサまたはその他のプロセッサの汎用ＣＰＵコア（または、プログラムコードを実行するための命令実行パイプラインを有するその他の機能ブロック）上で実行されるアプリケーションソフトウェア、オペレーティングシステムソフトウェア、デバイスドライバソフトウェア、および／またはファームウェアが、上述した機能のいずれかを実行してもよい。
In one embodiment, the one or
本発明の実施形態は、上述したさまざまな処理を含んでもよい。処理は、機械によって実行可能な命令に含まれてもよい。命令を用いて、汎用プロセッサまたは特定用途向けプロセッサに特定の処理を実行させることができる。代替的には、これらの処理は、処理を実行するための結線ロジックおよび／またはプログラム可能なロジックを含んだ専用のハードウェア部品によって実行されてもよく、プログラムを組み込まれたコンピュータ構成要素とカスタムハードウェア部品との任意の組み合わせによって実行されてもよい。 Embodiments of the present invention may include the various treatments described above. The processing may be included in the instructions that can be executed by the machine. Instructions can be used to cause a general purpose processor or a special purpose processor to perform a particular process. Alternatively, these processes may be performed by dedicated hardware components that include wiring logic and / or programmable logic to perform the processes, with embedded computer components and custom programs. It may be performed in any combination with hardware components.
また、本発明の要素は、機械によって実行可能な命令を格納するための機械読み取り可能な媒体として提供されてもよい。機械読み取り可能な媒体は、フロッピー（登録商標）ディスク、光ディスク、ＣＤ－ＲＯＭ、および光磁気ディスク、ＦＬＡＳＨメモリ、ＲＯＭ、ＲＡＭ、ＥＰＲＯＭ、ＥＥＰＲＯＭ、磁気カードまたは光カード、電子命令を格納するのに適した伝播媒体またはその他の種類の媒体／機械読み取り可能な媒体などを含み得るが、これらに限定されない。たとえば、本発明は、コンピュータプログラムとしてダウンロードされてもよく、コンピュータプログラムは、搬送波またはその他の伝播媒体において具体化されるデータ信号として、通信リンク（たとえば、モデムまたはネットワーク接続）を介してリモートコンピュータ（たとえば、サーバ）から要求元コンピュータ（たとえば、クライアント）に転送され得る。 The elements of the invention may also be provided as machine readable media for storing machine-executable instructions. Machine-readable media are suitable for storing floppy (registered trademark) disks, optical disks, CD-ROMs, and magneto-optical disks, FLASH memory, ROM, RAM, EPROM, EEPROM, magnetic or optical cards, and electronic instructions. May include, but are not limited to, propagation media or other types of media / machine readable media. For example, the invention may be downloaded as a computer program, which may be a remote computer (eg, a modem or network connection) via a communication link (eg, a modem or network connection) as a data signal embodied in a carrier or other propagation medium. For example, it can be transferred from the server) to the requesting computer (eg client).
上記の明細書において、具体的、例示的な実施形態を用いて本発明を説明したが、特許請求の範囲に記載の本発明のより広義の趣旨および範囲から逸脱することなく、さまざまな変形および変更が実施可能であることは明らかであろう。したがって、明細書および添付の図面は、限定的ではなく例示的なものとみなされるべきである。 In the above specification, the present invention has been described with reference to specific and exemplary embodiments, but various modifications and variations and variations thereof are made without departing from the broader meaning and scope of the present invention described in the claims. It will be clear that the changes are feasible. Therefore, the specification and accompanying drawings should be regarded as exemplary rather than limiting.
以下において、いくつかの例示的な実施形態が記載される。
例１：プロセッサであって、
ネットワークと、
当該ネットワークに連結された複数の処理コアと、
当該ネットワークに連結されたトランスミッタ回路とを備え、当該トランスミッタ回路は、当該複数の処理コアのうちの１つによって生成された出力データを当該ネットワーク内に送信し、当該トランスミッタ回路は制御論理回路を含み、当該制御論理回路は、当該トランスミッタ回路が出力データのうち先行の第１のパケットの送信を完了する前に、当該トランスミッタ回路に、出力データのうち第２のパケットの送信のための要求を送信させる、プロセッサ。
In the following, some exemplary embodiments are described.
Example 1: Processor
With the network
Multiple processing cores connected to the network and
A transmitter circuit connected to the network is provided, the transmitter circuit transmits output data generated by one of the plurality of processing cores into the network, and the transmitter circuit includes a control logic circuit. , The control logic circuit transmits a request for transmission of the second packet of the output data to the transmitter circuit before the transmitter circuit completes the transmission of the first packet preceding the output data. Let the processor.
例２：当該要求は、
当該第２のパケットを当該第１のパケットが送信されつつあるのと同じ宛先へ送信すべき場合に当該同じ宛先、または、
当該第２のパケットを異なる宛先に送信すべき場合に当該異なる宛先、
に送信されることになる、例１に記載のプロセッサ。
Example 2: The request is
If the second packet should be sent to the same destination as the first packet is being sent, then the same destination, or
If the second packet should be sent to a different destination, the different destination,
The processor according to Example 1, which will be transmitted to.
例３：当該制御論理回路は、
当該第１のパケットおよび当該第２のパケットが同じ宛先に送信されている場合、当該第１のパケットおよび当該第２のパケットのために同じクレジットカウンタを用いることになるか、または、
当該第１のパケットおよび当該第２のパケットが異なる宛先に送信されている場合、当該第１のパケットのために第１のクレジットカウンタを用いることになるとともに当該第２のパケットのために第２のクレジットカウンタを用いることになる、例１または例２に記載のプロセッサ。
Example 3: The control logic circuit is
If the first packet and the second packet are sent to the same destination, the same credit counter will be used for the first packet and the second packet, or
If the first packet and the second packet are sent to different destinations, the first credit counter will be used for the first packet and the second for the second packet. The processor according to Example 1 or Example 2, wherein the credit counter of the above will be used.
例４：制御論理は、異なる宛先に対する複数のパケットの同時送信を制御するための複数のクレジットカウンタを含む、上述の例のうち少なくとも１つの例に記載のプロセッサ。 Example 4: The processor according to at least one of the above examples, wherein the control logic comprises a plurality of credit counters for controlling the simultaneous transmission of a plurality of packets to different destinations.
例５：当該クレジットカウンタの各々は、いずれかの特定の宛先に対する送信を制御するために永久的に割当てられるものではない、例２から例４のうち少なくとも１つの例に記載のプロセッサ。 Example 5: The processor according to at least one of Examples 2-4, wherein each of the credit counters is not permanently assigned to control transmission to any particular destination.
例６：当該プロセッサは画像処理プロセッサであり、当該第１のパケットおよび当該第２のパケットはデータの画像の複数ラインを含む、上述の例のうち少なくとも１つの例に記載のプロセッサ。 Example 6: The processor according to at least one of the above examples, wherein the processor is an image processing processor, wherein the first packet and the second packet include multiple lines of images of data.
例７：当該第１のパケットおよび当該第２のパケットのデータ単位は、前記トランスミッタによって送信された後、および、当該データ単位が当該複数の処理コアのうち別の１つ以上の処理コアによって処理される前に、当該プロセッサのメモリ回路によって待ち行列に入れられる、上述の例のうち少なくとも１つの例に記載のプロセッサ。 Example 7: The data unit of the first packet and the second packet is transmitted by the transmitter, and the data unit is processed by another one or more processing cores among the plurality of processing cores. The processor according to at least one of the above examples, which is queued by the memory circuit of the processor before it is done.
例８：当該画像処理プロセッサは、２次元シフトレジスタアレイに連結された、実行レーンのアレイを含む、例６または例７に記載のプロセッサ。 Example 8: The processor according to Example 6 or Example 7, wherein the image processing processor comprises an array of execution lanes coupled to a two-dimensional shift register array.
例９：当該画像処理プロセッサは、画像データのステンシルを処理するための複数のステンシルプロセッサを含む、例６から例８のうち少なくとも１つの例に記載のプロセッサ。 Example 9: The processor according to at least one of Examples 6 to 8, wherein the image processing processor includes a plurality of stencil processors for processing a stencil of image data.
例１０：部分的に重なっているステンシル上で動作するように構成される、例９に記載のプロセッサ。 Example 10: The processor of Example 9, configured to operate on partially overlapping stencils.
例１１：当該実行レーンのアレイの外側にレジスタの「ハロー」が存在するように、当該実行レーンのアレイよりも広い寸法を有するシフトレジスタ構造を備えたデータ演算部を含むかまたは当該データ演算部に連結される、上述の例のうち少なくとも１つの例に記載のプロセッサ。 Example 11: A data calculation unit having a shift register structure having a wider dimension than the array of the execution lane is included or the data calculation unit is included so that a register "halo" exists outside the array of the execution lane. The processor according to at least one of the above examples concatenated with.
例１２：コンピューティングシステムであって、
複数の汎用処理コアと、
システムメモリと、
当該システムメモリと当該汎用処理コアとの間で連結されるメモリコントローラと、
画像処理プロセッサとを備え、当該画像処理プロセッサは、
ａ）ネットワークと、
ｂ）当該ネットワークに連結された複数の画像処理コアと、
ｃ）当該ネットワークに連結されたトランスミッタ回路とを含み、当該トランスミッタ回路は、当該画像処理コアのうちの１つによって生成された出力データを当該ネットワーク内に送信し、当該トランスミッタ回路は制御論理回路を含み、当該制御論理回路は、当該トランスミッタ回路が出力データのうち先行の第１のパケットの送信を完了する前に、当該トランスミッタ回路に、出力データのうち第２のパケットの送信のための要求を送信させる、コンピューティングシステム。
Example 12: A computing system
With multiple general-purpose processing cores
System memory and
A memory controller connected between the system memory and the general-purpose processing core,
It is equipped with an image processing processor, and the image processing processor is
a) Network and
b) Multiple image processing cores connected to the network,
c) Including a transmitter circuit connected to the network, the transmitter circuit transmits output data generated by one of the image processing cores into the network, and the transmitter circuit is a control logic circuit. Including, the control logic circuit makes a request to the transmitter circuit for transmission of the second packet of the output data before the transmitter circuit completes the transmission of the first packet of the output data. A computing system to send.
例１３：当該要求は、
当該第２のパケットを当該第１のパケットが送信されつつあるのと同じ宛先へ送信すべき場合に当該同じ宛先、または、
当該第２のパケットを異なる宛先に送信すべき場合に当該異なる宛先、
に送信されることになる、例１２に記載のコンピューティングシステム。
Example 13: The request is
If the second packet should be sent to the same destination as the first packet is being sent, then the same destination, or
If the second packet should be sent to a different destination, the different destination,
The computing system according to Example 12, which will be transmitted to.
例１４：当該制御論理回路は、
当該第１のパケットおよび当該第２のパケットが同じ宛先に送信されている場合、当該第１のパケットおよび当該第２のパケットのために同じクレジットカウンタを用いることになるか、または、
当該第１のパケットおよび当該第２のパケットが異なる宛先に送信されている場合、当該第１のパケットのために第１のクレジットカウンタを用いることになるとともに当該第２のパケットのために第２にクレジットカウンタを用いることになる、例１２または例１３に記載のコンピューティングシステム。
Example 14: The control logic circuit is
If the first packet and the second packet are sent to the same destination, the same credit counter will be used for the first packet and the second packet, or
If the first packet and the second packet are sent to different destinations, the first credit counter will be used for the first packet and the second for the second packet. The computing system according to Example 12 or Example 13, wherein a credit counter will be used for the calculation.
例１５：制御論理は、異なる宛先に対する複数のパケットの同時送信を制御するための複数のクレジットカウンタを含む、例１２から例１４のうち少なくとも１つの例に記載のコンピューティングシステム。 Example 15: The computing system according to at least one of Examples 12 to 14, wherein the control logic comprises a plurality of credit counters for controlling the simultaneous transmission of a plurality of packets to different destinations.
例１６：当該クレジットカウンタの各々は、いずれかの特定の宛先に対する送信を制御するために永久的に割当てられるものではない、例１２から例１５のうち少なくとも１つの例に記載のコンピューティングシステム。 Example 16: The computing system according to at least one of Examples 12 to 15, wherein each of the credit counters is not permanently assigned to control transmission to any particular destination.
例１７：当該第１のパケットおよび当該第２のパケットはデータの画像の複数ラインを含む、例１２から例１６のうち少なくとも１つの例に記載コンピューティングシステム。 Example 17: The computing system according to at least one of Examples 12 to 16, wherein the first packet and the second packet include multiple lines of images of data.
例１８：当該第１のパケットおよび第２のパケットのデータ単位は、前記トランスミッタによって送信された後、および、当該データ単位が当該複数の画像処理コアのうち別の１つ以上の画像処理コアによって処理される前に、当該画像処理プロセッサのメモリ回路によって待ち行列に入れられる、例１２から例１７のうち少なくとも１つの例に記載のコンピューティングシステム。 Example 18: The data unit of the first packet and the second packet is transmitted by the transmitter, and the data unit is by another one or more image processing cores of the plurality of image processing cores. The computing system according to at least one of Examples 12 to 17, which is queued by the memory circuit of the image processing processor before being processed.
例１９：当該画像処理プロセッサは、２次元シフトレジスタアレイに連結された、実行レーンのアレイを含む、例１２から例１８のうち少なくとも１つの例に記載のコンピューティングシステム。 Example 19: The computing system according to at least one of Examples 12 to 18, wherein the image processor comprises an array of execution lanes coupled to a two-dimensional shift register array.
例２０：当該画像処理プロセッサは、画像データのステンシルを処理するための複数のステンシルプロセッサを含む、例１２から例１９のうち少なくとも１つの例に記載のコンピューティングシステム。 Example 20: The computing system according to at least one of Examples 12 to 19, wherein the image processing processor comprises a plurality of stencil processors for processing a stencil of image data.
例２１：部分的に重なっているステンシル上で動作するように構成される、例２０に記載のコンピューティングシステム。 Example 21: The computing system of Example 20, configured to operate on partially overlapping stencils.
例２２：当該実行レーンのアレイの外側にレジスタの「ハロー」が存在するように、当該実行レーンのアレイよりも広い寸法を有するシフトレジスタ構造を備えたデータ演算部を含むかまたは当該データ演算部に連結される、例１２から例２１のうち少なくとも１つの例に記載のコンピューティングシステム。 Example 22: A data calculation unit having a shift register structure having a wider dimension than the array of the execution lane is included or the data calculation unit is included so that a register "halo" exists outside the array of the execution lane. The computing system according to at least one of Examples 12 to 21 linked to.
例２３：プロセッサによって実行される方法であって、
当該プロセッサの処理コアの出力データを生成するために当該処理コア上でプログラムコードを処理するステップと、
当該プロセッサ内のネットワークに連結されているトランスミッタ回路によって、当該トランスミッタ回路が先行の第１のパケットの送信を完了する前に、第２のパケットについての送信のための要求を送信するステップとを含み、当該第２のパケットは、当該処理コアによって生成された第２の出力データを含み、当該第１のパケットは、当該処理コアによって生成された第１の出力データを含み、前記方法はさらに、
当該ネットワークに連結されている当該プロセッサのうち１つ以上の他の処理コアで当該第１の出力データおよび当該第２の出力データを処理するステップを含む、方法。
Example 23: A method performed by a processor,
Steps to process program code on the processing core to generate output data for the processing core of the processor,
A transmitter circuit connected to a network within the processor includes a step of transmitting a request for transmission of a second packet before the transmitter circuit completes transmission of the preceding first packet. , The second packet contains the second output data generated by the processing core, the first packet contains the first output data generated by the processing core, and the method further comprises.
A method comprising processing the first output data and the second output data on one or more other processing cores of the processor connected to the network.
例２４：当該トランスミッタ回路によって当該第１の出力データを送信した後であって、当該１つ以上の処理コアによって当該第１の出力データを処理する前に、当該第１の出力データを待ち行列に入れるステップをさらに含む、例２３に記載の方法。 Example 24: Queuing the first output data after the transmitter circuit has transmitted the first output data and before the first output data has been processed by the one or more processing cores. 23. The method of Example 23, further comprising the step of putting in.
例２５：当該待ち行列に入れるステップは、当該ネットワークに連結されているバッファによって画像データの複数ラインを待ち行列に入れるステップを含む、例２３または例２４に記載の方法。 Example 25: The method of Example 23 or 24, wherein the queuing step comprises queuing a plurality of lines of image data by a buffer connected to the network.
例２６：当該トランスミッタ回路が、当該第１のパケットの送信に関与するとともに、第２のパケットの送信に関与するステップをさらに含み、当該第２のパケットは当該第１のパケットとは異なる宛先に送信される、例２３から例２５のうち少なくとも１つの例に記載の方法。 Example 26: The transmitter circuit is involved in the transmission of the first packet and further includes a step involved in the transmission of the second packet, the second packet being addressed to a different destination than the first packet. The method according to at least one of Examples 23 to 25, which is transmitted.
例２７：当該第１のパケットおよび当該第２のパケットが同じ宛先に送信される場合、前記トランスミッタからの当該第１のパケットおよび当該第２のパケットの送信を制御するために同じクレジットカウンタを用いるステップをさらに含む、例２３から例２６のうち少なくとも１つの例に記載の方法。 Example 27: If the first packet and the second packet are sent to the same destination, the same credit counter is used to control the transmission of the first packet and the second packet from the transmitter. The method according to at least one of Examples 23 to 26, further comprising a step.
例２８：当該トランスミッタからの第３のパケットの送信を制御するために当該同じクレジットカウンタを用いるステップをさらに含み、当該第３のパケットは、当該第１のパケットおよび当該第２のパケットを送信するとき以外の期間中に当該第１のパケットおよび当該第２のパケットとは異なる宛先に送信される、例２３から例２７のうち少なくとも１つに記載の方法。 Example 28: Further comprising the step of using the same credit counter to control the transmission of the third packet from the transmitter, the third packet transmitting the first packet and the second packet. The method according to at least one of Examples 23 to 27, which is transmitted to a destination different from the first packet and the second packet during a period other than the time.
例２９：当該画像処理プロセッサは、２次元シフトレジスタアレイに連結された、実行レーンのアレイを含む、例２３から例２８のうち少なくとも１つの例に記載の方法。 Example 29: The method according to at least one of Examples 23 to 28, wherein the image processor comprises an array of execution lanes coupled to a two-dimensional shift register array.
例３０：当該画像処理プロセッサは、画像データのステンシルを処理するための複数のステンシルプロセッサを含む、例２３から例２９のうち少なくとも１つの例に記載の方法。 Example 30: The method according to at least one of Examples 23 to 29, wherein the image processor comprises a plurality of stencil processors for processing a stencil of image data.
例３１：部分的に重なっているステンシル上で動作するように構成される、例３０に記載の方法。 Example 31: The method of Example 30, configured to operate on partially overlapping stencils.
例３２：当該実行レーンのアレイの外側にレジスタの「ハロー」が存在するように、当該実行レーンのアレイよりも広い寸法を有するシフトレジスタ構造を備えたデータ演算部を含むかまたは当該データ演算部に連結される、例２３から例３１のうち少なくとも１つの例に記載の方法。 Example 32: A data calculation unit having a shift register structure having a wider dimension than the array of the execution lane is included or the data calculation unit is included so that a register "halo" exists outside the array of the execution lane. The method according to at least one of Examples 23 to 31, which is linked to.
Claims (26)
ネットワークと、
前記ネットワークに連結された複数の処理コアと、
前記複数の処理コアのうちの第１の処理コアを前記ネットワークに連結するトランスミッタ回路とを備え、前記トランスミッタ回路は、前記第１の処理コアによって出力された複数のデータ単位を含むデータパケットを前記ネットワーク内に送信し、前記トランスミッタ回路は制御論理回路を含み、前記制御論理回路は、
前記プロセッサの第１のレシーバに向けた第１のデータパケットの送信を、前記トランスミッタ回路に開始させ、
前記第１のレシーバに向けた前記第１のデータパケットの最後のデータ単位の送信を完了する前に、前記トランスミッタ回路に、前記第１のレシーバに向けた第２のデータパケットの送信のための要求を送信させ、
前記第１のデータパケットの前記最後のデータ単位の送信を完了する前に、前記トランスミッタ回路に、前記第２のデータパケットの送信のために予め発行された受取り確認を受信させ、
前記第１のデータパケットの前記最後のデータ単位が前記第１のレシーバによって消費されたことを示す表示を、前記トランスミッタ回路に受信させ、
前記第１のデータパケットの前記最後のデータ単位が前記第１のレシーバによって消費されたことを示す前記表示を受信したことに応答して、前記トランスミッタ回路に、前記第１のレシーバに割り当てられた第１のクレジットカウンタを増加させ、前記第１のクレジットカウンタのクレジットは、前記トランスミッタ回路によって前記第１のレシーバに送信可能なデータ量に対応し、前記制御論理回路は、さらに、
前記第１のデータパケットの前記最後のデータ単位が前記第１のレシーバによって消費されたことを示す前記表示を受信したことで増加した前記第１のクレジットカウンタの前記クレジットの１つ以上を使用することにより、前記トランスミッタ回路に、前記第１のレシーバに向けて前記第２のデータパケットの最初のデータ単位を送信させる、プロセッサ。 It ’s a processor,
With the network
With multiple processing cores connected to the network,
A data packet including a plurality of data units output by the first processing core is provided with a transmitter circuit for connecting the first processing core of the plurality of processing cores to the network. Is transmitted within the network, the transmitter circuit includes a control logic circuit, and the control logic circuit includes a control logic circuit.
The transmitter circuit is initiated to transmit the first data packet to the first receiver of the processor.
For transmission of a second data packet to the first receiver to the transmitter circuit before completing transmission of the last data unit of the first data packet to the first receiver. Send the request ,
Prior to completing the transmission of the last data unit of the first data packet, the transmitter circuit is made to receive a pre-issued receipt confirmation for the transmission of the second data packet.
The transmitter circuit is made to receive a display indicating that the last data unit of the first data packet has been consumed by the first receiver.
The transmitter circuit was assigned to the first receiver in response to receiving the indication that the last data unit of the first data packet was consumed by the first receiver. The first credit counter is incremented, the credit of the first credit counter corresponds to the amount of data that can be transmitted by the transmitter circuit to the first receiver, and the control logic circuit further comprises.
Use one or more of the credits of the first credit counter increased by receiving the indication that the last data unit of the first data packet has been consumed by the first receiver. Thereby, a processor that causes the transmitter circuit to transmit the first data unit of the second data packet toward the first receiver .
前記第１のレシーバに向けた前記第１のデータパケットの前記最後のデータ単位の送信を完了する前に、前記トランスミッタ回路に、前記プロセッサの第２のレシーバに向けた第３のデータパケットの送信のための要求を送信させ
前記第１のデータパケットの前記最後のデータ単位の送信を完了する前に、前記トランスミッタ回路に、前記第３のデータパケットの送信のために予め発行された受取り確認を受信させ、
前記第３のデータパケットの送信のために前記予め発行された受取り確認を受信したことに応答して、前記トランスミッタ回路に、前記第２のレシーバに割り当てられた第２のクレジットカウンタを増加させ、前記第２のクレジットカウンタのクレジットは、前記トランスミッタ回路によって前記第２のレシーバに送信可能なデータ量に対応し、前記制御論理回路は、さらに、
前記第３のデータパケットの送信のための前記予め発行された受取り確認を受信したことで増加した前記第２のクレジットカウンタの前記クレジットの１つ以上を使用することにより、前記トランスミッタ回路に、前記第２のレシーバに向けて前記第３のデータパケットの最初のデータ単位を送信させる、請求項１に記載のプロセッサ。 The control logic circuit further
Transmission of a third data packet to a second receiver of the processor to the transmitter circuit before completing transmission of the last data unit of the first data packet to the first receiver. Send a request for
Prior to completing the transmission of the last data unit of the first data packet, the transmitter circuit is made to receive a pre-issued receipt confirmation for the transmission of the third data packet.
In response to receiving the pre-issued receipt confirmation for the transmission of the third data packet, the transmitter circuit is incremented by a second credit counter assigned to the second receiver. The credit of the second credit counter corresponds to the amount of data that can be transmitted by the transmitter circuit to the second receiver, and the control logic circuit further comprises.
By using one or more of the credits of the second credit counter increased by receiving the pre-issued receipt confirmation for the transmission of the third data packet, the transmitter circuit may have the said. The processor according to claim 1, wherein the first data unit of the third data packet is transmitted to the second receiver .
前記複数のクレジットカウンタの各々は、いずれかの特定の宛先に対する送信を制御するために永久的に割当てられるものではない、請求項２に記載のプロセッサ。 The control logic circuit includes a plurality of credit counters including the first credit counter and the second credit counter for controlling the simultaneous transmission of a plurality of data packets to different destinations.
The processor of claim 2 , wherein each of the plurality of credit counters is not permanently assigned to control transmission to any particular destination .
複数の汎用処理コアと、
システムメモリと、
前記システムメモリと前記汎用処理コアとの間で連結されるメモリコントローラと、
画像処理プロセッサとを備え、前記画像処理プロセッサは、
ａ）ネットワークと、
ｂ）前記ネットワークに連結された複数の画像処理コアと、
ｃ）前記複数の画像処理コアのうちの第１の画像処理コアを前記ネットワークに連結するトランスミッタ回路とを含み、前記トランスミッタ回路は、前記第１の画像処理コアによって出力された複数のデータ単位を含むデータパケットを前記ネットワーク内に送信し、前記トランスミッタ回路は制御論理回路を含み、前記制御論理回路は、
前記画像処理プロセッサの第１のレシーバに向けた第１のデータパケットの送信を、前記トランスミッタ回路に開始させ、
前記第１のレシーバに向けた前記第１のデータパケットの最後のデータ単位の送信を完了する前に、前記トランスミッタ回路に、前記第１のレシーバに向けた第２のデータパケットの送信のための要求を送信させ、
前記第１のデータパケットの前記最後のデータ単位の送信を完了する前に、前記トランスミッタ回路に、前記第２のデータパケットの送信のために予め発行された受取り確認を受信させ、
前記第１のデータパケットの前記最後のデータ単位が前記第１のレシーバによって消費されたことを示す表示を、前記トランスミッタ回路に受信させ、
前記第１のデータパケットの前記最後のデータ単位が前記第１のレシーバによって消費されたことを示す表示を受信したことに応答して、前記トランスミッタ回路に、前記第１のレシーバに割り当てられた第１のクレジットカウンタを増加させ、前記第１のクレジットカウンタのクレジットは、前記トランスミッタ回路によって前記第１のレシーバに送信可能なデータ量に対応し、前記制御論理回路は、さらに、
前記第１のデータパケットの前記最後のデータ単位が前記第１のレシーバによって消費されたことを示す前記表示を受信したことで増加した前記第１のクレジットカウンタの前記クレジットの１つ以上を使用することにより、前記トランスミッタ回路に、前記第１のレシーバに向けて前記第２のデータパケットの最初のデータ単位を送信させる、コンピューティングシステム。 It ’s a computing system,
With multiple general-purpose processing cores
System memory and
A memory controller connected between the system memory and the general-purpose processing core,
The image processing processor is provided with an image processing processor.
a) Network and
b) Multiple image processing cores connected to the network,
c) The transmitter circuit includes a transmitter circuit that connects a first image processing core among the plurality of image processing cores to the network, and the transmitter circuit has a plurality of data output by the first image processing core. A data packet containing a unit is transmitted into the network, the transmitter circuit includes a control logic circuit, and the control logic circuit includes a control logic circuit.
The transmitter circuit is initiated to transmit the first data packet to the first receiver of the image processor.
For transmission of a second data packet to the first receiver to the transmitter circuit before completing transmission of the last data unit of the first data packet to the first receiver. Send the request ,
Prior to completing the transmission of the last data unit of the first data packet, the transmitter circuit is made to receive a pre-issued receipt confirmation for the transmission of the second data packet.
The transmitter circuit is made to receive a display indicating that the last data unit of the first data packet has been consumed by the first receiver.
A first assigned to the transmitter circuit to the first receiver in response to receiving an indication that the last data unit of the first data packet has been consumed by the first receiver. The credit counter of 1 is increased, the credit of the 1st credit counter corresponds to the amount of data that can be transmitted by the transmitter circuit to the 1st receiver, and the control logic circuit further comprises.
Use one or more of the credits of the first credit counter increased by receiving the indication that the last data unit of the first data packet has been consumed by the first receiver. Thereby, a computing system that causes the transmitter circuit to transmit the first data unit of the second data packet toward the first receiver .
前記第１のデータパケットの前記最後のデータ単位の送信を完了する前に、前記トランスミッタ回路に、前記画像処理プロセッサの第２のレシーバに向けた第３のデータパケットの送信のための要求を送信させ
前記第１のレシーバに向けた前記第１のデータパケットの前記最後のデータ単位の送信を完了する前に、前記トランスミッタ回路に、前記第３のデータパケットの送信のために予め発行された受取り確認を受信させ、
前記第３のデータパケットの送信のために前記予め発行された受取り確認を受信したことに応答して、前記トランスミッタ回路に、前記第２のレシーバに割り当てられた第２のクレジットカウンタを増加させ、前記第２のクレジットカウンタのクレジットは、前記トランスミッタ回路によって前記第２のレシーバに送信可能なデータ量に対応し、前記制御論理回路は、さらに、
前記第３のデータパケットの送信のための前記予め発行された受取り確認を受信したことで増加した前記第２のクレジットカウンタの前記クレジットの１つ以上を使用することにより、前記トランスミッタ回路に、前記第２のレシーバに向けて前記第３のデータパケットの最初のデータ単位を送信させる、請求項１０に記載のコンピューティングシステム。 The control logic circuit further
Before completing the transmission of the last data unit of the first data packet, a request for transmission of the third data packet to the second receiver of the image processor is transmitted to the transmitter circuit. Let
A pre-issued receipt confirmation to the transmitter circuit for transmission of the third data packet prior to completing transmission of the last data unit of the first data packet to the first receiver. To receive,
In response to receiving the pre-issued receipt confirmation for the transmission of the third data packet, the transmitter circuit is incremented by a second credit counter assigned to the second receiver. The credit of the second credit counter corresponds to the amount of data that can be transmitted by the transmitter circuit to the second receiver, and the control logic circuit further comprises.
By using one or more of the credits of the second credit counter increased by receiving the pre-issued receipt confirmation for the transmission of the third data packet, the transmitter circuit may have the said. The computing system according to claim 10 , wherein the first data unit of the third data packet is transmitted to the second receiver .
前記複数のクレジットカウンタの各々は、いずれかの特定の宛先に対する送信を制御するために永久的に割当てられるものではない、請求項１１に記載のコンピューティングシステム。 The control logic circuit includes a plurality of credit counters including the first credit counter and the second credit counter for controlling the simultaneous transmission of a plurality of data packets to different destinations.
11. The computing system of claim 11 , wherein each of the plurality of credit counters is not permanently assigned to control transmission to any particular destination .
前記複数の処理コアのうちの第１の処理コアが、第１のデータパケットおよび第２のデータパケット内で送信される、前記プロセッサの前記第１の処理コアの出力データを生成するためのプログラムコードを処理するステップを備え、前記第１のデータパケットおよび前記第２のデータパケットの各々は複数のデータ単位を含み、前記方法はさらに、
前記ネットワークに前記第１の処理コアを連結するトランスミッタ回路が、前記プロセッサの第１のレシーバに向けた前記第１のデータパケットの送信を開始するステップと、
前記トランスミッタ回路が、前記第１のデータパケットの最後のデータ単位の送信を完了する前に、前記第２のデータパケットの送信のための要求を送信するステップと、
前記トランスミッタ回路が、前記第１のデータパケットの前記最後のデータ単位の送信を完了する前に、前記第２のデータパケットの送信のために予め発行された受取り確認を受信するステップと、
前記トランスミッタ回路が、前記第１のデータパケットの前記最後のデータ単位が前記第１のレシーバによって消費されたことを示す表示を受信するステップと、
前記トランスミッタ回路が、前記第１のデータパケットの前記最後のデータ単位が前記第１のレシーバによって消費されたことを示す前記表示を受信したことに応答して、前記第１のレシーバに割り当てられた第１のクレジットカウンタを増加させるステップとを備え、前記第１のクレジットカウンタのクレジットは、前記トランスミッタ回路によって前記第１のレシーバに送信可能なデータ量に対応し、前記方法はさらに、
前記トランスミッタ回路が、前記第１のデータパケットの前記最後のデータ単位が前記第１のレシーバによって消費されたことを示す前記表示を受信したことで増加した前記第１のクレジットカウンタの前記クレジットの１つ以上を使用することにより、前記第１のレシーバに向けて前記第２のデータパケットの最初のデータ単位を送信するステップとを備える、方法。 A method performed by a processor having a network and a plurality of processing cores connected to the network .
A program for generating output data of the first processing core of the processor , in which the first processing core of the plurality of processing cores is transmitted in the first data packet and the second data packet. Each of the first data packet and the second data packet comprises a plurality of data units, the method further comprising a step of processing the code.
A step in which a transmitter circuit connecting the first processing core to the network initiates transmission of the first data packet to the first receiver of the processor.
A step of transmitting a request for transmission of the second data packet before the transmitter circuit completes transmission of the last data unit of the first data packet .
A step of receiving a pre-issued receipt confirmation for transmission of the second data packet before the transmitter circuit completes transmission of the last data unit of the first data packet.
A step in which the transmitter circuit receives an indication that the last data unit of the first data packet has been consumed by the first receiver.
The transmitter circuit was assigned to the first receiver in response to receiving the indication that the last data unit of the first data packet was consumed by the first receiver. A step of increasing the first credit counter is provided, the credit of the first credit counter corresponds to the amount of data that can be transmitted by the transmitter circuit to the first receiver, and the method further comprises.
One of the credits of the first credit counter increased by the transmitter circuit receiving the indication that the last data unit of the first data packet has been consumed by the first receiver. A method comprising the use of one or more to transmit the first data unit of the second data packet towards the first receiver .
前記トランスミッタ回路が、前記第１のレシーバに向けた前記第１のデータパケットの前記最後のデータ単位の送信を完了する前に、前記プロセッサの第２のレシーバに向けた第３のデータパケットの送信のための要求を送信するステップと、Transmission of a third data packet to a second receiver of the processor before the transmitter circuit completes transmission of the last data unit of the first data packet to the first receiver. And the steps to send a request for
前記トランスミッタ回路が、前記第１のデータパケットの前記最後のデータ単位の送信を完了する前に、前記第３のデータパケットの送信のために予め発行された受取り確認を受信するステップと、A step of receiving a receipt confirmation previously issued for transmission of the third data packet before the transmitter circuit completes transmission of the last data unit of the first data packet.
前記トランスミッタ回路が、前記第３のデータパケットの送信のために前記予め発行された受取り確認を受信したことに応答して、前記第２のレシーバに割り当てられた第２のクレジットカウンタを増加させるステップとを備え、前記第２のクレジットカウンタのクレジットは、前記トランスミッタ回路によって前記第２のレシーバに送信可能なデータ量に対応し、前記方法はさらに、The step of increasing the second credit counter assigned to the second receiver in response to the transmitter circuit receiving the pre-issued receipt confirmation for the transmission of the third data packet. The credit of the second credit counter corresponds to the amount of data that can be transmitted by the transmitter circuit to the second receiver, and the method further comprises.
前記トランスミッタ回路が、前記第３のデータパケットの送信のための前記予め発行された受取り確認を受信したことで増加した前記第２のクレジットカウンタの前記クレジットの１つ以上を使用することにより、前記第２のレシーバに向けて前記第３のデータパケットの最初のデータ単位を送信するステップを備える、請求項１９に記載の方法。The transmitter circuit uses one or more of the credits of the second credit counter increased by receiving the pre-issued receipt confirmation for the transmission of the third data packet. 19. The method of claim 19, comprising transmitting the first data unit of the third data packet to a second receiver.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US15/595,242 | 2017-05-15 | ||
US15/595,242 US10872393B2 (en) | 2017-05-15 | 2017-05-15 | Image processor with high throughput internal communication protocol |
PCT/US2018/012521 WO2018212793A1 (en) | 2017-05-15 | 2018-01-05 | Image processor with high throughput internal communication protocol |
Publications (3)
Publication Number | Publication Date |
---|---|
JP2020519996A JP2020519996A (en) | 2020-07-02 |
JP2020519996A5 JP2020519996A5 (en) | 2020-10-01 |
JP7073403B2 true JP7073403B2 (en) | 2022-05-23 |
Family
ID=61094589
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2019559364A Active JP7073403B2 (en) | 2017-05-15 | 2018-01-05 | Image processor with high throughput internal communication protocol |
Country Status (7)
Country | Link |
---|---|
US (1) | US10872393B2 (en) |
EP (1) | EP3625755A1 (en) |
JP (1) | JP7073403B2 (en) |
KR (1) | KR102284078B1 (en) |
CN (1) | CN110574068B (en) |
TW (1) | TWI718359B (en) |
WO (1) | WO2018212793A1 (en) |
Families Citing this family (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10489878B2 (en) * | 2017-05-15 | 2019-11-26 | Google Llc | Configurable and programmable image processor unit |
Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP2010218351A (en) | 2009-03-18 | 2010-09-30 | Ricoh Co Ltd | Data transfer system and data transfer method |
JP2010218415A (en) | 2009-03-18 | 2010-09-30 | Olympus Corp | Hardware switch and distributed processing system |
US20160314555A1 (en) | 2015-04-23 | 2016-10-27 | Google Inc. | Architecture for high performance, power efficient, programmable image processing |
Family Cites Families (16)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JPH11203192A (en) * | 1998-01-16 | 1999-07-30 | Sony Corp | Parallel processor and arithmetic processing method |
US7453878B1 (en) * | 2000-07-21 | 2008-11-18 | Silicon Graphics, Inc. | System and method for ordering of data transferred over multiple channels |
US7966661B2 (en) * | 2004-04-29 | 2011-06-21 | Microsoft Corporation | Network amplification attack mitigation |
US7478811B2 (en) | 2004-08-02 | 2009-01-20 | Garrett Johnson | Wave driven gaming apparatus |
US7793074B1 (en) * | 2006-04-14 | 2010-09-07 | Tilera Corporation | Directing data in a parallel processing environment |
US8463843B2 (en) * | 2006-05-26 | 2013-06-11 | Riverbed Technology, Inc. | Throttling of predictive ACKs in an accelerated network communication system |
US8478834B2 (en) * | 2007-07-12 | 2013-07-02 | International Business Machines Corporation | Low latency, high bandwidth data communications between compute nodes in a parallel computer |
US8700877B2 (en) | 2009-09-25 | 2014-04-15 | Nvidia Corporation | Address mapping for a parallel thread processor |
US20110249744A1 (en) * | 2010-04-12 | 2011-10-13 | Neil Bailey | Method and System for Video Processing Utilizing N Scalar Cores and a Single Vector Core |
US9021237B2 (en) * | 2011-12-20 | 2015-04-28 | International Business Machines Corporation | Low latency variable transfer network communicating variable written to source processing core variable register allocated to destination thread to destination processing core variable register allocated to source thread |
JP5966561B2 (en) * | 2012-04-20 | 2016-08-10 | 富士通株式会社 | Communication apparatus and communication method |
US9489322B2 (en) | 2013-09-03 | 2016-11-08 | Intel Corporation | Reducing latency of unified memory transactions |
US20160188519A1 (en) * | 2014-12-27 | 2016-06-30 | Intel Corporation | Method, apparatus, system for embedded stream lanes in a high-performance interconnect |
US9792044B2 (en) * | 2016-02-12 | 2017-10-17 | Oracle International Corporation | Decompression history buffer read/write pipelines |
US10437616B2 (en) * | 2016-12-31 | 2019-10-08 | Intel Corporation | Method, apparatus, system for optimized work submission to an accelerator work queue |
US10764209B2 (en) * | 2017-03-28 | 2020-09-01 | Mellanox Technologies Tlv Ltd. | Providing a snapshot of buffer content in a network element using egress mirroring |
-
2017
- 2017-05-15 US US15/595,242 patent/US10872393B2/en active Active
-
2018
- 2018-01-05 EP EP18702376.7A patent/EP3625755A1/en active Pending
- 2018-01-05 KR KR1020197031167A patent/KR102284078B1/en active IP Right Grant
- 2018-01-05 JP JP2019559364A patent/JP7073403B2/en active Active
- 2018-01-05 WO PCT/US2018/012521 patent/WO2018212793A1/en unknown
- 2018-01-05 CN CN201880028900.3A patent/CN110574068B/en active Active
- 2018-02-07 TW TW107104241A patent/TWI718359B/en active
Patent Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP2010218351A (en) | 2009-03-18 | 2010-09-30 | Ricoh Co Ltd | Data transfer system and data transfer method |
JP2010218415A (en) | 2009-03-18 | 2010-09-30 | Olympus Corp | Hardware switch and distributed processing system |
US20160314555A1 (en) | 2015-04-23 | 2016-10-27 | Google Inc. | Architecture for high performance, power efficient, programmable image processing |
Non-Patent Citations (1)
Title |
---|
Nicola Concer et al.，"CTC: an End-To-End Flow Control Protocol for Multi-Core Systems-on-Chip"，2009 3rd ACM/IEEE International Symposium on Networks-on-Chip，米国，IEEE，2009年05月10日，pp.1-10 |
Also Published As
Publication number | Publication date |
---|---|
TW201901609A (en) | 2019-01-01 |
EP3625755A1 (en) | 2020-03-25 |
US20180330465A1 (en) | 2018-11-15 |
KR20190133028A (en) | 2019-11-29 |
CN110574068A (en) | 2019-12-13 |
CN110574068B (en) | 2023-06-27 |
US10872393B2 (en) | 2020-12-22 |
WO2018212793A1 (en) | 2018-11-22 |
JP2020519996A (en) | 2020-07-02 |
KR102284078B1 (en) | 2021-07-30 |
TWI718359B (en) | 2021-02-11 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
JP7066732B2 (en) | Configurable and programmable image processor unit | |
JP6571790B2 (en) | High-performance, power-efficient, programmable image processing architecture | |
JP6612403B2 (en) | Energy efficient processor core architecture for image processors | |
JP6389571B2 (en) | Two-dimensional shift array for image processor. | |
US10685423B2 (en) | Determination of per line buffer unit memory allocation | |
JP2019507922A (en) | Compiler management memory for image processors | |
US10998070B2 (en) | Shift register with reduced wiring complexity | |
JP6967597B2 (en) | An image processor with a configurable number of active cores and an internal network that supports it | |
US11030005B2 (en) | Configuration of application software on multi-core image processor | |
CN110574067A (en) | Image processor I/O unit | |
JP7073403B2 (en) | Image processor with high throughput internal communication protocol |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20200819 |
|
A621 | Written request for application examination |
Free format text: JAPANESE INTERMEDIATE CODE: A621Effective date: 20200819 |
|
A977 | Report on retrieval |
Free format text: JAPANESE INTERMEDIATE CODE: A971007Effective date: 20210921 |
|
A131 | Notification of reasons for refusal |
Free format text: JAPANESE INTERMEDIATE CODE: A131Effective date: 20211005 |
|
A601 | Written request for extension of time |
Free format text: JAPANESE INTERMEDIATE CODE: A601Effective date: 20220104 |
|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20220307 |
|
TRDD | Decision of grant or rejection written | ||
A01 | Written decision to grant a patent or to grant a registration (utility model) |
Free format text: JAPANESE INTERMEDIATE CODE: A01Effective date: 20220412 |
|
A61 | First payment of annual fees (during grant procedure) |
Free format text: JAPANESE INTERMEDIATE CODE: A61Effective date: 20220511 |
|
R150 | Certificate of patent or registration of utility model |
Ref document number: 7073403Country of ref document: JPFree format text: JAPANESE INTERMEDIATE CODE: R150 |