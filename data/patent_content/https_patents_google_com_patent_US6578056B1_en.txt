US6578056B1 - Efficient data transfer mechanism for synchronization of multi-media databases - Google Patents
Efficient data transfer mechanism for synchronization of multi-media databases Download PDFInfo
- Publication number
- US6578056B1 US6578056B1 US10/135,344 US13534402A US6578056B1 US 6578056 B1 US6578056 B1 US 6578056B1 US 13534402 A US13534402 A US 13534402A US 6578056 B1 US6578056 B1 US 6578056B1
- Authority
- US
- United States
- Prior art keywords
- data
- query
- database
- user
- computer program
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Expired - Lifetime
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/95—Retrieval from the web
- G06F16/951—Indexing; Web crawling techniques
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/25—Integrating or interfacing systems involving database management systems
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/27—Replication, distribution or synchronisation of data between databases or within a distributed database system; Distributed database system architectures therefor
- G06F16/273—Asynchronous replication or reconciliation
-
- Y—GENERAL TAGGING OF NEW TECHNOLOGICAL DEVELOPMENTS; GENERAL TAGGING OF CROSS-SECTIONAL TECHNOLOGIES SPANNING OVER SEVERAL SECTIONS OF THE IPC; TECHNICAL SUBJECTS COVERED BY FORMER USPC CROSS-REFERENCE ART COLLECTIONS [XRACs] AND DIGESTS
- Y10—TECHNICAL SUBJECTS COVERED BY FORMER USPC
- Y10S—TECHNICAL SUBJECTS COVERED BY FORMER USPC CROSS-REFERENCE ART COLLECTIONS [XRACs] AND DIGESTS
- Y10S707/00—Data processing: database and file management or data structures
- Y10S707/99931—Database or file accessing
- Y10S707/99937—Sorting
-
- Y—GENERAL TAGGING OF NEW TECHNOLOGICAL DEVELOPMENTS; GENERAL TAGGING OF CROSS-SECTIONAL TECHNOLOGIES SPANNING OVER SEVERAL SECTIONS OF THE IPC; TECHNICAL SUBJECTS COVERED BY FORMER USPC CROSS-REFERENCE ART COLLECTIONS [XRACs] AND DIGESTS
- Y10—TECHNICAL SUBJECTS COVERED BY FORMER USPC
- Y10S—TECHNICAL SUBJECTS COVERED BY FORMER USPC CROSS-REFERENCE ART COLLECTIONS [XRACs] AND DIGESTS
- Y10S707/00—Data processing: database and file management or data structures
- Y10S707/99941—Database schema or data structure
- Y10S707/99944—Object-oriented database structure
- Y10S707/99945—Object-oriented database structure processing
-
- Y—GENERAL TAGGING OF NEW TECHNOLOGICAL DEVELOPMENTS; GENERAL TAGGING OF CROSS-SECTIONAL TECHNOLOGIES SPANNING OVER SEVERAL SECTIONS OF THE IPC; TECHNICAL SUBJECTS COVERED BY FORMER USPC CROSS-REFERENCE ART COLLECTIONS [XRACs] AND DIGESTS
- Y10—TECHNICAL SUBJECTS COVERED BY FORMER USPC
- Y10S—TECHNICAL SUBJECTS COVERED BY FORMER USPC CROSS-REFERENCE ART COLLECTIONS [XRACs] AND DIGESTS
- Y10S707/00—Data processing: database and file management or data structures
- Y10S707/99941—Database schema or data structure
- Y10S707/99948—Application of database or data structure, e.g. distributed, multimedia, or image
Definitions
- This application generally relates to data transfers in computer systems, and more specifically to transferring different types of data in computer systems.
- data transmissions may be required to move data from one storage location to another.
- the data to be transferred may include different data types, such as text and non-text data.
- non-text data may include audio data, image data, and other data that may also be characterized as multi-media data.
- Different mechanisms may exist to facilitate the transferring of different data. types. For example, one mechanism provided for data transfers between two databases includes support within databases for transferring text data. However, the mechanism for data transfer, as in databases, may not provide a mechanism for non-text or multi-media data transfers. In the latter case, an alternative technique may be used to facilitate the transfer of multi-media data, for example, in data transfers between databases.
- This alternative data channel is generally external to the database and does not use database-provided mechanisms in data transfers.
- both text and multi-media data may be transferred using the alternative data channel.
- a problem with this technique is that it is generally not an efficient mechanism for transferring both text and multi-media data.
- the external mechanism may not be the most efficient mechanism by which to transfer text data, as existing database-provided routines may be more efficient and tuned for database data transfers.
- Data is selected to be transferred from a first location to a second location in which the data includes a text portion and a non-text portion.
- the text portion is transferred using a first data channel from the first location to the second location storing the text portion in a temporary location.
- the non-text portion is transferred using a second data channel from the first location to the second location.
- the steps of transferring the text portion and non-text portion are performed asynchronously, and initially the text and non-text portions are copied to a temporary location, and then merged with other data from another data transfer.
- An advertising page is selected to be transferred from a first location to a second location, advertising data of the advertising page being represented by a relational mapping table describing the relationship between data entities associated with the advertising data, and a data table including the advertising data represented by the relational mapping table, the relational mapping table including only text data and the data table including text and multimedia data.
- the text data of the relational mapping table is transferred using a first communication channel to a temporary relational mapping table located at the second location.
- the text data of said data table is transferred to a temporary data table located at the second location.
- the multimedia data is transferred to a repository at the second location, the repository being a location which includes other multimedia data from other data transfer operations associated with other advertising pages.
- the temporary data table is merged into another data table by copying the text data from the temporary data table to the other data table at the second location.
- a matching entry in said repository is identified in which the global identifier of the temporary data table matches a global identifier of the repository.
- a repository identifier of said matching entry is copied from the repository to the entry in the other data table, the repository identifier being a pointer to the multimedia data located in the repository and being a link between an associated entry in the other data table describing the matching entry in the repository.
- FIG. 1 is an example of an embodiment of a system that includes an on-line query tool
- FIG. 2 is an example of a block diagram of a hardware view of an embodiment of an on-line query tool
- FIG. 3 is an example of an embodiment of a user interface displayed with an on-line query tool
- FIG. 4 is an example of a block diagram of a software view of an online query tool of FIG. 2;
- FIG. 5 is an example of an embodiment of a table illustrating data storage for denormalized objects in the databases.
- FIG. 6 is an example of an embodiment of a table representing data stored in the generic object dictionary
- FIG. 7 is an example of an embodiment of a portion 440 of a PHTML execution tree
- FIG. 8 is an example of an embodiment showing more detail of the parse driver
- FIGS. 9 and 10 are an example of a user interface displayed in response to a user request with an online query tool
- FIG. 11 is an example of an embodiment of a user interface displayed with user query information
- FIG. 12 is an example of the query results displayed in response to performing a user query of FIG. 11;
- FIG. 13 is an example of a user interface which includes user-specified query information
- FIG. 14 is an example of a resulting display page in response to the query performed with information specified in FIG. 13;
- FIG. 15 is a more detailed display in response to choosing a particular category of FIG. 14;
- FIGS. 16 and 17 are an example of a user interface displayed in response to selecting an option from the menu of FIG. 3 to add or change a listing;
- FIG. 18 is an example of a display screen in response to updating the business listing specified in FIGS. 16 and 17;
- FIGS. 19 and 20 are an example of a user interface screen display results in response to a user request with regard to FIG. 18;
- FIG. 21 is an example of a screen display to a user with more information with regard to the business listing selected from screen 20 ;
- FIG. 22 is the business information displayed with regard to the business in FIG. 21;
- FIG. 23 is an example of an embodiment of the processes included in the request router of FIG. 22;
- FIG. 24 is an example of a block diagram of an embodiment of the Backoffice component
- FIG. 25 is an example of the flow process representing the processing of normalized data to the various data forms included in the Front End Server;
- FIG. 26 is an example of normalized data as may be included in an embodiment of the invention.
- FIG. 27 is an example of denormalized data form as may be included in an embodiment of the invention.
- FIG. 28 is a flowchart of an example of an embodiment of a method for performing request processing in the system of FIGS. 2 and 4;
- FIG. 29 is a flowchart of an example of an embodiment of the method steps for performing parser processing in the system of FIGS. 2 and 4;
- FIG. 30 is a flowchart of an example of a method with steps for performing query engine processing in the system of FIGS. 2 and 4;
- FIG. 31 is an example of a dependency graph as may be included in one embodiment of the invention for performing incremental update
- FIG. 32 is an example of a flowchart of the method steps for performing different update techniques in accordance with the number of transactions
- FIG. 33 is a flowchart of an example of method steps of one embodiment for performing data query cache lookup as used in performing a data query;
- FIG. 34 represents an example of applying the minimum cost derivation sequence as applied in the step of FIG. 33;
- FIG. 35 is a flowchart of an embodiment of method with steps for forming a name and determining if the corresponding data set is located in the query cache;
- FIG. 36 is an example of an entity as stored in the data query cache
- FIG. 37 is a flowchart of an embodiment of a method including steps for performing an additional total-city cache lookup
- FIGS. 37 and 38 are flowcharts for a method in one embodiment for performing total-city and multi-city cache searches
- FIG. 39 is an example of more details that may be included in a embodiment of the query engine.
- FIG. 40 is an example of an embodiment of method steps by which the information retrieval software may obtain results
- FIG. 41 is a flow chart showing an example of an embodiment of method steps for obtaining results
- FIG. 42 is a flow chart showing an example of method steps for classifying results for queries using common terms
- FIG. 43 depicts an example of a user interface for an on-line query tool, including a screen for initiating a user query;
- FIG. 44 depicts an example of a user interface for an on-line query tool, including categories that may be retrieved in response to initiation of a user query;
- FIG. 45 is a block diagram of an embodiment of the database as may be included in the Backoffice component
- FIGS. 46 through 52 are flowcharts depicting processing steps in a method of one embodiment for performing foreign source data integration
- FIGS. 53 through 58 are flowcharts of a method of one embodiment for performing native source data integration processing.
- FIG. 59 is an example of an embodiment of data tables included on a sending node for a multi-media data transfer
- FIG. 60 is an example of an embodiment of the tables as appearing on the sending side and the receiving side in the multi-media data transfer
- FIG. 61 is an example of a representation of a tree structure representing the relationships between entitites used in the multi-media transfer
- FIG. 62 is a snapshot of the tables that may be included in a preferred embodiment in sending data in a multi-media data transfer;
- FIG. 63 is a snapshot of an example of an embodiment of the tables on the sending and receiving side at another point when performing a multi-media data transfer;
- FIG. 64 is an example of an embodiment of tables and external processes on the sending and receiving side using the multi-media data transfer
- FIG. 65 is an example of an embodiment of the tables resulting from the text data integration
- FIG. 66 is an example of a block diagram of an embodiment of the data table whose contents have been transferred to the receiving side;
- FIG. 67 is a flowchart of a method of the steps of one embodiment for assembling blob data into a repository table when performing a multi-media data transfer;
- FIG. 68 is a flow chart setting forth method steps for establishing super-category term lists and for matching advertisements to super-categories, to assist in targeting an advertisement to a user of an on-line query tool;
- FIG. 69 is a flow chart setting forth method steps for mapping categories to super-categories
- FIG. 70 is a flow chart setting forth method steps for executing a modified query in an on-line query tool designed to assist in targeting an advertisement to a user of an on-line query tool;
- FIG. 71 is a diagram showing an example of a linked super-category term list.
- an on-line query tool 1910 shown is an embodiment of an on-line query tool 1910 .
- one or more users 1900 - 1904 may connect to the on-line query tool 1910 via a network 1906 .
- Users may interact with the query tool using conventional hardware and software, such as, in an embodiment, a web browser through the Internet.
- FIG. 2 shown is an embodiment of a hardware view of an on-line query tool.
- this on-line query tool may be the GTE Superpages SM query tool.
- FIG. 2 shows a hardware view of the components that may be included in one embodiment of the query tool in typical operation as being accessed by a user through a network.
- the user 800 enters a query request which is sent via a network 802 , such as the Internet, to the GTE Superpages Front End Server 804 .
- the GTE Superpages Front End Server 804 includes a hardware router 806 for receiving incoming query requests.
- the hardware router routes the request, using a simple hardware-based technique, to one of the server nodes 808 - 810 which may be designated to service the request by performing the requested query.
- the Primary Database 812 interacts with the Backoffice component 818 at times, as will be described in paragraphs elsewhere herein, to obtain data used in performing the queries.
- the Backoffice component 818 performs data filtering and other processing, for example, to combine information that may be obtained from various data sets producing a resultant data set.
- the resultant data set is subsequently transferred to the Primary Database for use by the various server nodes 808 through 810 .
- the process of data integration and updating the data may be performed at a time other than peak demand time.
- These processes and data transfer techniques are generally performed “off-line” and not in response to user query requests. Rather, these techniques may be performed as part of a data maintenance and update process performed in accordance with the system load and the number and type of update transactions.
- FIG. 2 depicts a Superpages Front End Server 804 which includes a varying number of server nodes 808 - 810 to respond to the various query requests as made by a user 800 .
- the techniques and concepts which are described in paragraphs that follow may be used in a variety of different systems which include one or more server systems. Additionally, a single database or other datastore may be used. The techniques described herein may generally be applied to a large distributed system. Additionally, these same concepts and techniques may be applied in a single user system performing data queries and searches upon a local database.
- FIG. 3 shown is an example of a user interface screen as included in one embodiment of the system of FIG. 2 .
- FIG. 3 is the initial screen 1800 that may be displayed to a user entering a URL corresponding to the GTE Superpages Internet site.
- FIG. 3 includes fields for query information 1802 - 1808 , hyperlinks to other tools 1810 , such as on-line shopping or placing advertisements, and other links 1812 , for performing other tasks such as modifying an existing business listing.
- the GTE Superpages Internet site is related to on-line yellow pages, similar to those included in a paper phone book.
- various business services and user services may be provided.
- a user may query the on-line yellow page information for various businesses in the United States based on particular search criteria.
- On-line shopping information regarding products and business services may be provided to a user performing a data query.
- Advertisers, such as the business providers of the various products and services, may also purchase advertisements similar to those that may be purchased in the paper copy of a phone book that includes yellow page listings of businesses.
- the interface 1800 may include links to various services and functions.
- one service provided permits businesses to advertise in the on-line yellow pages.
- Functions associated with this service may include, for example, purchasing advertisements and adding or changing a business listing that an advertiser or business includes in the yellow pages.
- some of these functions are included in the interface portion 1812 , with links to other tools in the screen portion 1810 .
- a user may connect with any of these tools or functions to perform tasks related to the yellow pages advertising by selecting an option from the user interface 1800 , such as by left-clicking with a mouse.
- FIG. 4 shown is an embodiment of the various software components for an on-line query system.
- One embodiment may be the on-line query tool of the GTE Superpages system.
- FIG. 4 depicts a software view of the typical operation of the system as being accessed by a user 800 through a network 802 using the hardware as described in conjunction with FIG. 2 .
- the user may enter a request, as through a browser.
- This request is communicated through the GTE Superpages Front End Server 804 over the network 802 .
- the Front End Server 804 includes server node 808 that includes a web server engine 852 .
- the web server engine 852 is a NetscapeTM engine which serves as a central coordinating task for accessing files and displaying information to the user on the browser 824 .
- the server node 808 also includes a request router 854 , a monitor process 856 and a parser 866 .
- the parser 866 generally includes a parse driver 858 , a generic object dictionary 860 , a query engine 862 , and a data manager 864 .
- the parse driver 858 operates upon data from a constructed ad repository 842 and the PHTML files 844 . Additionally, the parse driver 858 stores and retrieves data from the PHTML execution tree 846 and the page cache 848 .
- the data manager 864 included in the parser 866 is responsible for interacting with the database, which in the FIG. 4 is the Primary Database 812 . It should also be noted that the data manager 864 may also obtain data from a Secondary Database as previously shown in FIG. 4 . If there are multiple databases other than a Primary and Secondary Database, the data manager may also interact with these to obtain the necessary data upon which data queries are performed.
- the query engine 862 operates upon data from, and writes data to, the data query cache 850 . Additionally, the query engine uses data from the term lists 836 to obtain identifiers and possibly other retrievable data in accordance with various key terms upon which a data query is being performed.
- the request router 854 generally interacts with the parser and reads data from the configuration file 830 and load file 834 .
- the monitor process 856 also reads and writes data to and from respectively the load file 834 .
- the web server engine 852 in this embodiment the Netscape engine 852 , obtains data from the HTML repository 838 and the image repository 840 in accordance with various requests from the browser for different types of files.
- the monitor process 856 is generally responsible for indicating the availability of server nodes 808 - 810 in performing data queries.
- the monitor is also generally responsible for receiving incoming messages from other server nodes as to their availability for servicing requests.
- the load file 834 upon which the monitor process 856 reads and writes data, is a dynamic file in that its contents are updated in response to incoming messages indicating machine availability and the current load of the corresponding machine.
- the load file also includes static information components, such as the maximum load of each system. Generally, the actual executing load (current load) of a system is less than or equal to the maximum load (max load) as indicated in accordance with the load file.
- Each server has its own unique copy of the load file which is updated in accordance with messages which it receives from the other nodes. Below is an example of an entry that may be included in the load file representing the information described above:
- the configuration file 830 may be a static file physically located on one of the server nodes 808 - 810 with a copy replicated on each other server node. Generally, this file is created prior to use of the system. It may specify which servers may service requests based on weighted parameters of a particular search domain associated with a particular server. Below is an example of an entry in a configuration file:
- the domain weight may be a normalized value representing costs (e.g., time) associated with processing a request for this associated search domain or partition. This domain weight is based on the median time to service a request in that domain based on the analysis of past data logs, for example, as normalized by the number of listings in the domain. Similarly, server weights may represent the cost associated with processing a request on a particular server.
- the domain/partition indicates a portion of the search domain upon which a user query may be performed that is associated with a particular server.
- load and configuration files may include additional or different information in accordance with the particular policies and data required to implement the policies, such as request routing.
- an incoming request may be processed by one of a plurality of parsers 858 on each of the server nodes.
- the parser 858 generally transforms the user input query into a form used by other components, such as the request router.
- the request router generally receives an incoming request as forwarded by the hardware router 806 of FIG. 2 .
- the request router subsequently uses the load file and the configuration file to decide which server node 808 - 810 a request is routed to based on the load and the availability of the server node, and the designated server for each partition or domain.
- the query is performed producing data query information that may be cached, for example, in the memory of a data query cache 850 .
- a superset or composition query is one which is a boolean composite of several querying terms.
- a composition query may be determined by the parser 866 , and the request router 854 may decide to which server node 808 - 810 the composition query or other query is sent for processing in accordance with domain weights as indicated in the configuration file.
- Reallocation of requests when a server is unavailable may be performed generally with a bias toward the initial allocation scheme as indicated also by the configuration file. There is an assumption that reallocation of a request is on a transient basis, and that the initial allocation scheme is the one to be maintained. This concept will be described in paragraphs that follow in accordance with request routing and data query caching.
- the PHTML execution tree 846 includes an expanded version of a PHTML file requested from the PHTML file 844 as the result, for example, of a user query.
- PHTML generally is a modified version of the HTML language, which is a markup language according to the Standardized General Markup Language (SGML) standard, capable of interpretation by browsers, such as a Netscape browser.
- SGML Standardized General Markup Language
- PHTML generally is a scripted version of HTML with conditional statements that provide for alternate inclusion of blocks of HTML code in a resulting HTML page transmitted to a browser in accordance with certain run time query conditions.
- the expanded version of a PHTML file may be described as a parse tree representing parsed and expanded PHTML files.
- a PHTML file conditionally includes accesses to other PHTML files or various portions of HTML commands
- the parse tree structure reflects this in its representation of the parse tree which is cached in the PHTML execution tree 846 .
- the cached, expanded version is retrieved from the PHTML execution tree 846 to increase system efficiency, thereby decreasing user response time for the subsequent query.
- a request is received by the webserver engine 852 which interacts with the parser 866 .
- a PHTML file is obtained and executed from the PHTML file store 844 .
- the expanded version of the PHTML file is cached in the PHTML execution tree 846 .
- an HTML page is generally constructed and cached in the page cache 848 .
- constructed HTML pages are stored in the page cache 848 if the amount of time taken to produce the resulting HTML page is greater than a predetermined threshold. Implementations of the page cache may implement different replacement schemes. In one preferred embodiment, the page cache implements an LRU replacement scheme. Additionally, the threshold, the amount of time used to determine which pages are stored in the page cache, may vary with system and response time requirements.
- a particular search order of the previously described caches and file systems may be performed. Initially, it is determined whether the HTML page to be displayed to the user is located in the page cache 848 . If not, search results are obtained from the query cache and the resulting HTML page is constructed and itself may be placed in the page cache 848 . If a PHTML file is required to be executed in constructing the resulting HTML file, the PHTML execution tree 846 may be accessed to determine if there is a parsed version of the required PHTML file already expanded in the PHTML execution tree. If no such file is located in the PHTML execution tree 846 , the PHTML file 844 is accessed to obtain the required PHTML file. The order in which these caches and file systems are searched is generally in accordance with a graduated processing state of producing the resulting HTML file. Caches associated with a later state of processing are generally searched prior to ones associated with an earlier processing state in producing the resulting HTML file.
- the constructed ad repository generally includes constructed advertisement pages which may include, for example, text and non-text data, such as audio and graphic images to be displayed in response to a user query which represent, for example, a yellow pages ad.
- the webserver engine 852 accesses information from the image repository 840 and HTML repository 838 .
- the image repository 840 includes various graphic images and other non-text data which may also be directly accessed by the webserver engine 852 in response to a user request, as by a user request for a specific URL.
- the HTML repository 838 includes various HTML files which may be provided to the user, for example, in response to a user request with a specific URL which indicates a file.
- each of the server nodes 808 - 810 includes one or more parsers 866 which perform, for example, parsing of the text of a user data query request.
- FIG. 4 includes some of the software components as included in the parser 866 .
- the components of the parser 866 which are described in more detail in the following paragraphs, generally communicate using a generic object dictionary 860 .
- the parser may include a parse driver 858 which performs the actual parsing of a user query.
- the parse driver 858 interacts with the query engine 862 once a request has been parsed to formulate a data query which is further passed to the data manager 864 .
- the data manager 864 generally interacts with a database to actually retrieve the data to be included in the resultant data query as displayed to the user.
- the parse driver 858 generally uses a data schema description to interpret various data fields of the generic data objects.
- abstraction of the data interpretation into the data schema description enables different components of the parser 866 to operate upon and use generic data objects without requiring these components require code changes or recompilation in cases of the introduction of new data presentation types.
- This technique insulates code as included in the parser 866 from the introduction of new presentation types which may be represented as generic data objects.
- data field 1802 is a category query field by which queries may be performed in accordance with specified search categories that may be associated with business listings included in the yellow pages database. Additionally, field 1802 also includes predetermined top categories, as may be determined by examining log files in accordance with user query selections and search criteria. In this embodiment, selection of the “top categories” of the field 1802 , as by left-clicking with a mouse button, causes the interface 1820 of FIG. 9 to be displayed in a user's browser.
- FIGS. 9 and 10 shown is one embodiment of a user interface for displaying a first page of the top query categories 1820 .
- these categories are associated with the various business listings and are tags by which a user may perform queries.
- the user may select the “top categories” from the initial interface as included in the field 1802 .
- this user interface screen may be displayed by selecting “detailed search” from the field 1808 from the initial user interface 1800 .
- the user interface 1830 may be displayed if the user wants to perform a data query for specified categories and certain distance criteria.
- a data query may be performed for restaurants within five (5) miles of Boston, Mass. This query is performed when the user selects the “Find It” button 1832 as included in the user interface 1830 .
- a first screen 1840 of the data query results is shown in FIG. 12 .
- FIG. 13 shown is an example of one embodiment of a user interface display 1850 for performing a user query in accordance with user-specified search criteria.
- User interface 1850 of FIG. 13 is the interface 1800 of FIG. 3, but with user-specified data query information included in various data fields.
- a data query is performed for “shoes” as the category 1802 for “Boston, Mass.” in field 1804 .
- the query is performed by selecting the “Find It” button of field 1806 .
- the resulting screen displayed in response to selection of the “Find It” button is included in FIG. 14 .
- the screen results 1860 may include displayed summarized business listing information in accordance with the search criteria previously specified in FIG. 14 .
- Various business listings may be grouped together in categories. In this example, relating to “shoes”, are 154 business listings included in thirteen (13) categories. From this listing of thirteen (13) categories, the user may select one of these relating to shoes. For example, selection, as by using a mouse, of “custom made shoes” 1862 results in the screen display of FIG. 15 .
- FIGS. 16 and 17 shown is one embodiment of a user interface that may be displayed when a business or advertiser updates a business listing.
- This screen may be displayed, for example, by selection of the “add or change your listing” option 1812 of FIG. 3 of the initial user interface.
- a user interface 1880 provides data fields which allow a user to enter in information, such as a telephone number corresponding to a business listing. Corresponding business listing information is then updated. In this example, a phone number 617-832-5000 is entered, into field 1882 to retrieve business listing information corresponding to this phone number. By selecting the phone number field that is filled in with this phone number, the resulting screen of FIG. 18 is subsequently displayed to the user in this embodiment. The phone number corresponds to a business as displayed in FIG.
- FIG. 18 If this is the correct business, a user may select a displayed business, for example, by clicking on the “matching business” information of FIG. 18 . In response to selecting the “matching business” information, the screen display of FIGS. 19 and 20 may be displayed to a user. To update the basic listing information associated with the business, selection of field 1890 of FIG. 20 results in display of the screen of FIG. 21 where the user has the option to either update the business information or change categories. If business information is selected, FIG. 22 may be displayed. FIG. 22 includes the business listing information that may be updated, such as a street address or e-mail address associated with this business listing.
- a section of the displayed interface 1883 indicates options for creating a website linked to a particular business listing. Note also that in some embodiments, it is possible to enhance a business listing and/or link a listing to a pre-existing website or to one that is created.
- the request router 854 may be executed within a Netscape server process. space and may be invoked when a user, via a browser, makes a request which results in a PHTML file being executed.
- the PHTML files as generally included in the PHTML file store 844 , are in the form of a script activated when a server node 808 - 10 is forwarded a user request.
- the request router 854 is generally responsible for routing a request to the proper server node in accordance with data stored in the configuration and load files. The request is also forwarded to one of the plurality of parsers for processing once the proper server node has been located.
- the request router 854 may include several threads of execution as shown in FIG. 23, which operate under the control of, and in the same process space as, the Netscape browser.
- the request router 854 generally includes a housekeeping thread 880 , a router thread 882 , and one or more worker threads 884 .
- the housekeeping thread 880 is responsible for maintaining a parser status table 886 and a parser queue 888 , both of which are further described below.
- the router thread 882 generally responds to the monitor process changes as recorded in the various data files with regard to server node availability.
- the router thread 882 reads data from the configuration and load files, and maintains an in-memory copy for use by the various threads of the request router 854 .
- the router thread 882 updates the in-memory copy of the configuration and load files in accordance with predetermined node fail-over and reallocation-of-request policies. For example, if in reading the configuration and load files, the router thread 882 determines that a first server node is at maximum utilization the router thread updates its in-memory, server-node, local version of the files. The router thread determines not to forward requests to the first server. When the first server node's actual utilization decreases and is now available for processing additional requests, the router thread accordingly updates its in-memory copy.
- Each of the worker threads 884 is initially forwarded a request which arrives at a server node.
- the worker thread 884 makes the decision whether the request should be routed to another node.
- the worker thread 884 makes this decision generally in accordance with the contents of the configuration and load files as previously described. If a request is determined to be routed to another server, the worker thread forwards the request to another worker thread on another server node. If the worker thread does not forward the request to another server, the worker thread determines which parser to send the request to for further processing.
- the list of available parsers is stored in the parser queue 888 , which in this particular embodiment is implemented as an AT&T System 5 TM with a system message queue.
- the parser queue is generally maintained by the housekeeping thread 880 .
- the parser status table 886 includes information about use, availability and location of each of the plurality of parsers on each server node. The parser status information may be used in determining where to route requests for example, as performed by the worker thread 884 . The parser status information as included in the parser status table 886 may be used to route requests based on an adaptive technique similar to the adaptive caching technique which will be described in paragraphs that follow.
- This may be particularly useful in systems with multiple processors, for example, those in which certain CPUs are dedicated processors associated with predetermined parsers. For example, as particular requests are processed by particular parsers, each associated with a particular CPU, the parsing results may be stored in the PHTML execution tree accessed by the particular processor. Subsequent requests which are also processed by the same parser may access the cache parsing results stored in the PHTML execution tree.
- the request processing model includes a plurality of parsers and a plurality of worker threads.
- an incoming request is associated with a particular worker thread which then forwards the request to a parser for processing.
- the worker thread is disassociated with the request, and is then available for use in the pool of worker threads.
- the number of parsers and worker threads may be tuned in accordance with the number of user requests.
- One point to note using this model is that the worker thread and the parser are disassociated and thought of as distinct processing units rather than as a unit in which a worker thread is associated with a particular parser for processing an entire life of a request.
- the Backoffice component includes a database 892 which provides data, for example, to the Front End Server 804 through connection 822 .
- the database 892 may be updated, as through a webserver via a connection to a user.
- Such a connection as 896 may be used, for example, when a modification is made to an entry to correct typographical error.
- a user may connect, such as via a browser, using connection 896 , to the webserver 894 included in the Backoffice component.
- the database 892 is then accessed and updated in accordance with requests or updates made by the user.
- Backoffice component may include other software components than those displayed in FIG. 24 .
- a user may update entries included in database 892 using techniques other than by a connection 896 via a webserver to the database 892 .
- different types of updates to database 892 may be performed in different embodiments of the invention.
- the database 892 may be updated on a per-entry basis by a variety of users connecting via multiple webserver connections.
- periodic updates, for example, for particular data set may be provided from a particular vendor, and accordingly integrated into database 892 through a database integration technique rather than having a user manually enter these updates such as via a connection to the webserver 894 .
- the connection to the Front End Server 822 may be used, for example, to load a new copy of the database 892 into the Front End Server Primary and Secondary Databases 812 , 814 as shown in FIG. 2 .
- the way in which these updates may be sent across the connection 822 to the Front End Server may be as previously described in terms of database operational commands which perform updates from the computer system which include database 892 .
- the database 892 included in the Backoffice component and both the Primary and Secondary Databases, as included in FIG. 24, are OracleTM databases.
- Oracle provides remote database update and access commands which allow for remote database access and updating, such as update requests from the database server node 892 to update the Primary Database 812 as stored in the Front End Server 804 .
- updates as made to the database 892 are “pushed” to the Front End Server 804 via the connection 822 . These modifications are pushed via database-provided update techniques such as those included when sending the operational table commands to the Front End Server 804 .
- error messages and other status codes may be sent back to the Backoffice component 818 in accordance with an indication as to whether a data transfer, for example, has been successfully completed.
- FIG. 25 shown is an embodiment of a general process by which data that is transferred from the Backoffice 818 to the Front End Server 804 is further integrated into other data stores within the Front End Server 804 .
- Data is stored in the Backoffice component in this particular embodiment in a normalized dataform, as will be further described in paragraphs that follow.
- These normalized data changes are transfered to the Front End Server 804 from the Backoffice component in one of several forms. For example, the entire database may be transferred to the Front End Server 804 . Additionally, changes or updates to particular entries may also be transmitted to the Front End Server 804 from the Backoffice component rather than updating or overwriting the entire copy of the database as stored in the Front End Server 804 .
- Each of these types of database updates from the Backoffice component to the Front End Server 804 may be done in accordance with the number of transactions or updates to be performed. This is further described in other sections of this description.
- a markup language file generally includes tags which represent commands or text identifiers for processing the contents of the file.
- Structured Generalized Markup Language SGML
- SGML Structured Generalized Markup Language
- the process depicted in FIG. 25 is performed once data has been received in the Primary Database 812 , and is first stored in the Primary Database 812 in normalized data form, as in the normalized data store 900 .
- Extraction routines 902 examine the normalized data store 900 and rearrange the information to place it in the denormalized data form, also included in the Primary Database 812 of this embodiment. These changes or updates for the normalized data which are transformed into the denormalized data form are integrated into the denormalized data store 904 .
- the extraction routines 902 produce markup language files 906 which are primarily used by the information retrieval software to produce identifiers and corresponding words or terms upon which a query may be performed. These lists of key words or terms which may be searchable or retrievable and the corresponding record identifiers as included in the denormalized data store 904 may be stored in a list structure as included in the term list data store 836 .
- the markup language files include one file or document per business for which there is an advertisement, for example, in this particular embodiment.
- Each of the markup language files 906 includes markup language statements, such as SGML-like statements, with tags identifying key data items in the document for each business.
- the information retrieval software is Verity software which uses as input markup language files 906 . Additionally, Verity uses its own schema file by which a user indicates what key words or terms as indicated in the markup language files are searchable and which of the data fields contain retrievable information.
- Searchable as used herein means fields or key words and terms upon which searches may be performed, like index searching keys.
- “Retrievable” as used herein generally means fields or categories with associated data that may be retrieved.
- Identifiers are generally produced by the information retrieval software 908 .
- VerityTM in this particular embodiment, produces term lists 836 in which there exists a list for each particular key word, term or category followed by a chain of identifiers that indicate the record number in the denormalized data store 904 . Additionally, associated with each element in the term list which indicates a record in the denormalized data, retrievable data associated with that record may also be included.
- the term list, and the term list data store 836 contain a list corresponding to the key word “zip code”.
- Attached to each key word “zip code” and the particular value may be a list or a chain of identifiers. Associated with each identifier on the chain may be associated data, such as the city and state, which may be retrieved when a particular zip code is searched.
- data included in the term lists may be data that is also needed in performing search optimizations, weighted searches, or different types of searches, such as proximity searches.
- This data may further be stored in the various data files and caches of the Front End Server as needed in accordance with each implementation, for example in accordance with the types of searches and data upon which queries may be performed or otherwise operated upon by the Front End Server.
- the Primary Database 812 includes both normalized and denormalized data form
- the Secondary Database 814 includes only denormalized data form.
- Normalized data is that representation of the data in which each data relation is represented independent of other relations.
- denormalized data is the antithesis of a normalized data in which one data relation represents all relations.
- Different databases may be of different degrees of normalized and denormalized data.
- the Backoffice component 818 generally stores the data in normalized data form of a certain degree.
- the databases used in this server store the data in a form of a normalized form also of a certain degree and additionally in a denormalized form for search performance optimizations on performing data queries.
- the data is stored in third degree normal form.
- sets of data may be stored together within a single field, such as multiple mailing addresses. Other embodiments may have one field per address. This may prove to be advantageous, for example, for high performance and better flexibility in systems subject to multiple and diverse data sources, and a high rate of modifications.
- each particular business entry may have a unique identifier, (ID). Additionally, three pieces of information may be stored for each particular business.
- the normalized data form may look as in FIG. 26 . In this particular example, there may be a separate table for each ID corresponding to a business and its business address 910 . Additionally, there may be two other data tables of information also indexed by each particular business ID, such as email address 912 and telephone number 914 . Generally, as indicated in FIG. 26, the normalized data representation for each business associated with a particular ID is represented as a separate data relation independent of the other relations.
- denormalized data The conceptual opposite of normalized data is denormalized data, as depicted in FIG. 27 .
- FIG. 27 shown is an example of denormalized data stored in table 916 .
- the business address, email and telephone number may be stored in a single record.
- one data relation which is a single record in the table 916 , represents all relations for one particular data set, such as the ID corresponding to a business.
- Various degrees of denormalized and normalized data as known to those skill in the art, may be used.
- the optimal degree of normalized and denormalized data forms may vary with each particular implementation and embodiment.
- the Backoffice component 818 may include one or more database servers 892 .
- a user may directly interact with the web server 894 included in the Backoffice component via connection 896 which, for example, may be a network connection of a user accessing the web server through the Internet.
- the user may also interact directly with the Backoffice component through the Front End Server Connection 822 .
- the particular type and number of data fields may vary with embodiment. Additional structure may also be imparted to data fields, such as a telephone number may include an area code and exchange component. Additionally, interactions between the Primary Database 812 of the Front End Server 822 and the Backoffice component may be driven or controlled by the Backoffice component. For example, when there is an update to be performed to the Primary Database server 820 , an automatic transfer of the new information may be transmitted to the Primary Database 812 by the Backoffice component. Data may be transmitted to the Primary Database 812 using connection 822 . Additionally, connection 822 may be used to provide feedback or status information to the back office component 818 , for example, regarding success or failure of a data transfer using connection 822 .
- the PHTML files 844 of FIG. 4 are generally HTML instructions as interpreted generally by a browser with additional embedded processing instructions.
- the PHTML execution tree 846 may be implemented as a C++ applet class with various execute methods which are conditionally performed based upon the evaluation of certain conditions as indicated in the PHTML scripting language statements.
- Each of the PHTML files 844 may be expanded and evaluated in accordance with the particular conditions of the user request. The first time a PHTML file is accessed, it is expanded and the expanded version is placed in the PHTML execution tree 846 of FIG. 4 . Subsequent accesses to the same PHTML file result in the conditional evaluation of the stored and expanded PHTML file in accordance with the run time performance and evaluation of a user request, as from browser 824 .
- An HTML page is generally formed and displayed to the user.
- the HTML page may be formed by the parser after interaction with the data manager and query engine to select a specific number of items to be displayed to the user.
- the HTML page may be stored in the page cache 848 .
- the page cache generally includes a naming convention such as a file system in which the name of the file corresponds to the arguments and parameters of the query. The technique for forming the name is described in other paragraphs of this application.
- the query engine 862 is generally responsible for performing any required sorting of the query information or subsetting and supersetting of information. Generally, the query engine 862 retrieves various identifiers which act as keys into the Primary Database 812 or Secondary Database 814 for accessing particular pieces of information in response to a user query. After the query engine 862 formulates and retrieves various identifiers, for example as from the term lists, which correspond to a particular user query, this query information in the form of term list and retrieved information may be stored in the data query cache 850 .
- a technique similar to the page cache query-to-filename mapping technique may be used to map a particular query request to a naming scheme by which data is accessed in the data query cache. The technique for forming this name is described in other sections of this application.
- data which is stored in the data query cache 850 may be compressed or stored in a particular format which facilitates easy retrieval as well as attempting to optimize storage of the various data queries which are cached, as discussed in other portions of this application.
- FIGS. 28-30 shown are flowcharts of method steps of embodiments for performing processing in various components of the previously described, system of FIGS. 2 and 4.
- the Webserver engine invokes the Request Router in accordance with the PHTML MIME (Multipurpose Internet Mail Extension).
- the Worker thread as included in the Request Router is initially forwarded the request for processing.
- a determination is made as to whether or not this request is serviced by this node in accordance with the information included in the configuration and load files. If, at step 924 a determination is made that the request is not to be serviced by this node, the request is forwarded to another server node in accordance with the load and configuration file information.
- step 924 If, at step 924 , a determination is made that this request is to be serviced by this node, control proceeds to step 926 where the Worker thread allocates an available parser from the parser queue to process the incoming request. At step 928 , the incoming request is passed to the designated parser for processing.
- the parse driver of the parser parses the incoming request.
- the query request that is parsed is included as a URL parameter that is processed by the parse driver. For example, if the query includes syntax errors, the parse driver will detect and report out such errors.
- a unique file name is determined in accordance with the query request. This filename corresponds to the display results that may be included in the page cache. It should be noted that this filename is unique for a particular user query and in accordance with “look and feel” parameters of the display results.
- look and feel refers to parameters that describe the displayed results, such as number of business listings displayed in an HTML page, the particular starting point of the displayed results with regard to the resulting data set. For a given resulting data set corresponding to a user query, on a particular type of user display window, 15 items may be displayed. The same query performed by a second user from a different display window may display 17 items. Thus, the resulting HTML page in both cases is different even though the resulting data set used in forming each of the HMTL pages is different.
- the page cache may include a different HTML page for each of the 15 and 17 item displays.
- step 944 A determination is made at step 944 as to whether the page cache includes the data in the filename determined at step 942 . If a determination is made that the data is included in the page cache by the existence of the file, control proceeds to step 946 where the data in the filename is retrieved from the page cache. Control proceeds to step 956 where the resulting HTML including the data in display format is delivered to the user's browser.
- step 944 determines whether or not there is a PHTML file in the PHTML execution tree. If a determination is made that the expanded PHTML representation for this request is included in the PHTML execution tree, control proceeds to step 950 where the expanded PHTML representation is retrieved. Control proceeds to step 954 where portions of the PHTML file are executed in accordance with the user query to obtain data to produce the resulting HTML page by invoking the Query engine for data results. The data results are returned to the parse driver that creates a resulting HTML file returned to the user's browser at step 956 .
- the resulting HTML file may be cached in the Page cache in accordance with predetermined criteria, as previously described.
- the resulting HTML file is communicated directly to the user's browser. If a determination is made at step 948 that the PHTML file is not in the PHTML cache, control proceeds to step 952 where the PHTML file is retrieved from the PHTML file storage and subsequently expanded. The expanded PHTML file is stored in the PHTML cache. Control proceeds to step 954 , which is described above.
- the query engine receives an incoming request, as forwarded by the parse driver in step 954 .
- the data is retrieved for the “normal” search results as appropriate from the data query cache, or using an alternate technique. Details of this step are described in more detail in following paragraphs describing the use of the data query cache.
- “normal” search results refers to the resulting data set formed by business listing data associated with a well-defined geographic area.
- “normal” search result data are other search result data that may not be associated with a single well-defined geographic area, such as virtual businesses in the Internet.
- search results that may not be associated with a single well-defined geographic area are described in more detail in paragraphs relating to the data query cache and its use.
- other search data in addition to the “normal” search data may be retrieved and integrated into the resulting data set.
- the result data set is formulated in accordance with the user query request, such as displaying results in a particular order or beginning at a particular point.
- the resulting data set is returned to the parse driver for formatting in a display format in an HTML file.
- the Standard Industry Classification may be used to indicate various name categories and synonyms. These various name categories and synonyms are produced, for example, by the extraction routines which produce the markup files, as used in this particular embodiment by the information retrieval software. Other techniques may be used to facilitate name categories, and equivalents thereof, for searching in other preferred embodiments.
- the architecture described in FIGS. 2 and 4 is a highly optimized, distributed, fault tolerant, collaborative architecture.
- the primary purpose of this architecture is to support a high volume of searches, which may be performed for example, through the Internet.
- the databases may include business information, such as for specific businesses or classifications of businesses. Additionally, data queries may be performed based on characteristics of the various businesses, such as location, name, or category.
- the architecture described herein supports a flexible presentation of these businesses, based on business agreements and service offerings. The architecture described herein uses various techniques and combinations to achieve high performance while maintaining flexibility and scaleability.
- the architecture as depicted in FIGS. 2 and 4 includes a set of fully redundant server nodes in which each node is capable of responding to any search request.
- Each server node communicates with all the other nodes, as previously described, establishing the health and availability of each server node.
- Incoming requests are classified by each node, as routed by the hardware router, using a classification scheme held in common and by consensus.
- the nodes agree to a disjoint partitioning of requests to each of the server nodes in which one server node will service a set of classes of requests that no other node will generally service.
- a number of complimentary techniques including Subsumption and Highly Redundant Caching, may be then used to adapt a particular node to a particular class of requests.
- the latency for request servicing by that node decreases as additional user queries are performed for each particular class of requests.
- Adaptive techniques may be most effective when dealing with repeated requests or queries similar to those previously performed.
- an initial search request may be the most costly in terms of system resources and search time. Therefore, other techniques are used in conjunction with the adaptive techniques to further facilitate performing an optimal query in response to a user request.
- common term optimization is one technique which is used that generally takes advantage of a statistical bias in both submitted queries and result sets towards particular words or combinations of words. By anticipating particular word combinations or precalculated result lists that match, the CTO matches the initiating search problem.
- the Front End Server 804 has a data set domain which includes electronic yellow pages and advertising requiring a high degree of flexibility in the presentation of data.
- Data is generally presented using the look and feel of business partners in each business listing which may have distinct requirements for presentation. Additionally, new modes of data presentation may be defined on a monthly basis requiring updates to large numbers of data stored in the back office component in the primary and secondary database.
- the architecture described uses several techniques that also support performance requirements of the particular data domain in this embodiment and application. Generally, techniques such as the generic object and the generic presentation language may be used to facilitate rapid introduction of new services and additional presentation data in a variety of forms to a user.
- each server may be fully redundant, and there are two additional servers that are designated database servers which have additional supporting software and hardware for facilitating database access.
- Other embodiments of the invention may include additional configurations of servers and databases in their particular implementation.
- the PHTML files 844 that are provided to the parse driver 858 are scripts that direct the parse driver 858 to perform queries, view the results of queries, and provide information to the browser 824 .
- the PHTML files 844 are expanded into the PHTML execution trees 846 the first time the parser 866 accesses the PHTML files 844 .
- the parse driver 858 accesses the PHTML execution trees 846 during operation in a manner described in more detail below.
- the scripts that are stored in the PHTML files 844 may include commands that are interpreted by the parse driver 858 , C++ objects that are executed, blocks of HTML code that are provided by the parse driver 858 to the browser 824 , and any other appropriate data and/or executable statements.
- the PHTML scripts perform operations of objects in a way that is somewhat independent of specific attributes of the objects and thus, as described in more detail below, provide a generic mechanism for displaying and presenting many types of objects.
- the PHTML scripts include conventional commands to include other files (such as other PHTML files), conditional files/text inclusion commands, switch statements, loop statements, variable assignments, random number generation, string operations, commands to sort and iterate on attributes/fields of an object according to aspects thereof, such as the name, and logging values to files.
- the specific syntax used for the PHTML scripting commands is implementation-dependant but includes conventional key words (such as “if” and “then”) and conventional arrangements of parts of the various types of statements.
- the scripts provided in the PHTML files 844 are used to construct the PHTML execution trees 846 that control the operation of the parse driver 858 .
- Each business listing may be represented as a document stored in the primary and secondary databases 812 , 814 .
- the documents may be manipulated as generic objects. As discussed in more detail below, representing each business listing as a generic object facilitates subsequent handling of the business listings.
- a table 400 illustrates data storage for a plurality of denormalized objects in the databases 812 , 814 .
- the differences between normalized and denormalized data is discussed in more detail elsewhere herein.
- the denormalized data format is optimized for fast performance while, perhaps, foregoing some storage compaction.
- a plurality of rows 402 , 404 , 406 represent a plurality of denormalized generic objects, each of which corresponds to a business listing.
- a plurality of columns 412 , 414 , 416 , 418 represent various attributes of the denormalized objects.
- the first attribute 412 corresponds to an identifier for the objects 402 , 404 , 406 and thus identifies a particular listing.
- Each of the attributes contains a number of fields and contains descriptor information identifying the type, size, and number of fields.
- Attributes may be added to the normalized objects, or only to a specific subset thereof.
- a denormalized representation of any one of the objects 402 , 404 , 406 contains the same number of attributes as any of the other one of the objects 402 , 404 , 406 . This allows the denormalized objects to be transferred from the primary or secondary databases to the data manager 864 in a string format wherein each object can be identified. Accordingly, if values for a new attribute are added to only a subset of the objects, then the other objects, outside the subset, will contain a null value or some other conventional marker indicating that the particular attribute is not defined (or contains no data) for the objects in question. For example, assume that a new attribute 420 is added.
- the new attribute 420 only contains values for the object 402 , but is not defined for the objects 404 , 406 . In that case, data space for the attribute 420 is still added to the denormalized version of the objects 404 , 406 , but no value is provided in the attribute 420 for the objects 404 , 406 .
- a table 430 represents data stored in the generic object dictionary 860 corresponding to results of a search query provided by the query engine 862 or from the data query cache 850 in the case of a previous search having been performed.
- a search returns a plurality of objects corresponding to n categories and up to m listings for each of the categories.
- the annotation o jk means the object corresponding to the jth category and the kth listing.
- the objects may be object identifiers.
- the field 412 may correspond to an object identifier of each of the objects 402 , 404 , 406 .
- the parse driver 858 uses the table 430 provided by the generic object dictionary 860 along with the PHTML execution trees 846 , to provide specific HTML code from the parse driver 858 to the browser 824 of the user 802 .
- a diagram illustrates a portion 440 of the PHTML execution trees 846 .
- the portion 440 is constructed using the scripts in the PHTML files 844 and consists of a plurality of nodes corresponding to the decision points set forth in the PHTML scripts and a plurality of C++ objects and HTML pages that are executed and/or passed to the browser in response to reaching a node corresponding thereto.
- a node 442 can correspond to a PHTML if-then-else statement having two possible outcomes wherein one branch from the node 442 corresponds to one outcome (i.e., the conditional statement evaluates to true) and another branch from the node 442 corresponds to another outcome (i.e., the conditional statement evaluates to false).
- Such a structure may be implemented in a conventional manner given a scripting language such as that described above in connection with the PHTML language. That is, implementing such a tree structure using a scripting language is straightforward to one of ordinary skill in the art using conventional techniques in a straightforward manner.
- Representing the documents (business listings) of the databases 812 , 814 as generic objects facilitates modifying the documents, or a subset thereof, without modifying the parser 866 .
- an attribute is added to some of the objects, then it is only necessary to modify the objects (schema and data) that will contain that attribute and to also modify the PHTML files 844 to include new scripting to handle that new attribute.
- the scripting may include statements to determine if the particular attribute exists for each object. For example, suppose the business listings were in black and white and then color was added to some of the listings. The color attribute could be added to some, but not all, of the objects only in normalized form.
- the denormalized versions of all of the objects would contain a data space for the attribute, but the objects that do not possess a color attribute will have a null marker.
- the PHTML files 844 can be modified to test if the color attribute is available in a particular object (e.g., to test for a null value) and to perform particular operations (such as displaying the color) if the attribute exists or, if the attribute does not exist for a particular object, displaying the object in black and white. In this way, the color attribute is added to some of the objects without modifying the parser 866 and without modifying existing objects that do not contain the attribute.
- the query engine 862 determines whether the query is found in the data query cache 850 or whether it is necessary to perform a query operation using the Verity software (discussed elsewhere herein) and the term list 836 . In either instance, the results of the query are provided by the query engine 862 to the generic object dictionary 860 in a form set forth above in connection with the description of FIG. 6 .
- the parse driver 858 and PHTML execution trees 846 then operate on the generic object dictionary 860 to determine what data is displayed to the user by the browser 824 . In some instances, the PHTML execution trees 846 may require the parse driver 858 to obtain additional data from the databases 812 , 814 through the data manager 864 .
- the PHTML execution trees 846 may cause the parse driver 858 to obtain information from the generic object dictionary 860 that identifies each category and the number of listing corresponding to each category. Then, the portion of the PHTML execution trees 846 may cause the parse driver 858 to use the data manager 864 to access additional information from the databases 812 , 814 , such as the names of the categories corresponding to the category identifiers provided in the generic object dictionary 860 .
- An instantiator 452 creates the PHTML files 844 and constructs the PHTML execution trees 846 from the PHTML scripts the first time the PHTML is invoked by the parse driver 858 .
- Instantiation includes reading the PHTML files and constructing trees, such as that shown in FIG. 7, based on the PHTML scripts provided in the PHTML files 844 . As discussed above, constructing such trees from a scripting language is generally known in the art.
- An interpreter 454 accesses the PHTML execution trees 846 and, based on the information provided therein, provides HTML data to the browser 824 and/or executes a C++ object.
- the interpreter 454 also accesses a configuration file 456 and a state file 458 which keeps track of the state of various values during traversal of the PHTML execution trees 846 .
- the interpreter 454 also receives other data that is used to traverse the PHTML execution trees 846 and to provide information to the browser 824 .
- the other data may include, for example, data from the data manager 864 and data from the generic object dictionary 860 .
- the state data 854 includes information such as the number of iterations (in the case of an iterative loop), the values of various environment and other variables from the PHTML execution trees 846 , and the values of other variables and data necessary for performing the operations set forth in the PHTML execution trees 846 .
- the technique disclosed herein relates to a new data type which abstracts the data interpretation from the data typing by using data schemas.
- a novel approach is the use of this data typing for rapid service deployment in search engines for advertising services on the Internet.
- new presentation types may be introduced by an advertiser due to the large number of possible ways to present data to a user.
- An advertiser may wish to change the information displayed when a user performs a query that results in displaying information regarding the advertiser's business. If there are tens of thousands of advertisers which perform this task on a monthly basis, this implies a very high rate of new presentation types which an online advertising service must be able to accommodate.
- Use of this generic data type in GTE SuperpagesTM provides a flexible and efficient approach to incorporate these additional and new presentation types for large numbers of advertisers.
- this technique provides for rapid integration of new data types without requiring recompilation or code changes in source code which uses instances of data that include the additional data types. This provides for the flexible and efficient introduction of data changes.
- the generic data typing is optimized for performing multiple data operations by providing a small subset of possible operations or accesses upon any data of the generic data type. Therefore, these small subset of operations which are known may be optimized wherever there is a data access, for example, within the parser. This is in contrast to a non-generic data typing scheme which requires the introduction of a new data type and additional associated access patterns. In a non-generic data typing scheme there is an unlimited and unknown number of access patterns for which optimizations must be performed on an ad-hoc basis as new data types are introduced. Thus, when a new data type is introduced, the possible accesses need to be analyzed and optimized. In addition, the technique described herein provides for denormalized, flat, representations of the objects that facilitate rapid and efficient handling thereof.
- the parse driver 858 uses a data schema description to interpret the various data attributes and fields of the generic data objects.
- the abstraction of the data interpretation into the data schema description enables different components of the parse driver to operate upon and use generic data objects without having these components require code changes or recompilation due to the introduction of new presentation types.
- existing systems may perform request routing to a particular server in a distributed computer system without reference to certain available factors, such as an initial partitioning of the entire domain, or an assumption that data queries will be cached in a data query cache and subsequently reused for additional searches.
- certain available factors such as an initial partitioning of the entire domain, or an assumption that data queries will be cached in a data query cache and subsequently reused for additional searches.
- the larger the number of queries that are performed when routed to a particular node in accordance with an initial allocation scheme the quicker subsequent searches on this same particular node may be performed due to the use of the data query cache.
- This embodiment relates to concepts that may be included in a variety of applications.
- One embodiment that includes these is the GTE Super Pages on-line Internet tool that may be used to perform data queries.
- GTE Super Pages performs this query returning search results to an on-line user.
- Concepts which will be described in paragraphs that follow may be generally used and adapted for use in querying any search domain.
- a worker thread classifies a request and performs query partitioning in accordance with the URL information. For example, this may include data from the query request such as a specified state, zip code, or area code.
- the request router 854 receives an incoming request as forwarded by the hardware router.
- FIG. 4 is generally machine-executable code which embodies the concepts of an adaptive and partitioning scheme with regard to routing requests. Use of this technique allows for high performance search optimizations that leverage and ensure server node adaption to a particular class of requests.
- the technique of adaptive query partitioning generally increases the performance in terms of high throughput and low latency where queries include Boolean search terms.
- This search optimization technique may include three components: query partitioning, highly redundant caching, and subsumption.
- Query partitioning is the strict classification and routing of a particular query based on its input term characteristics to a node or a particular set of nodes. This information is stored in the various configuration and load files, as described in other sections of this application. Query partitioning ensures that any adaption a node undergoes based on the characteristics of queries that it processes is maintained. Specific nodes may serve specific query partitions. Caching and result set manipulation techniques may then be used on each particular node to bias each particular node to the query partition to which it has been assigned.
- Highly redundant caching is generally a technique that trades storage space against time by storing result sets along with subsets of these result sets.
- the highly redundant caching technique generally relies on the fact that the search time to locate an existing result is generally less than that amount of time which would result in creating the query result from a much larger search space.
- Subsumption is generally the derivation of query results from previous results, which can be either a superset of the requested result or subsets of the requested result. Subsumption is also the recognition of the relationship between queries and the determination of the shorted derivation path to a result set. That derivation may be the composition of several subsets resulting in a superset, or the extraction of a subset from a recognized result set.
- the presence of an additional conjunctive (“and”) search term corresponds to the formation of a subset from the superset described without the additional term.
- the presence of an additional disjunctive (“or”) search term corresponds to the identification and composition of existing subsets each described by one of the disjunctive clauses.
- the data included in the data query cache is placed in nonvolatile storage such that if the node were to become unavailable, data from the data cache may be fully restored once the node resumes service.
- composition query also uses the data in the data query cache.
- a composition query may generally be referred to as one which is a composition of several queries, for example, when using several conjunctive search terms. For example, a request of all the French restaurants in Massachusetts, Texas and California is a composition query that may reuse any existing cached data from previous queries stored individually regarding restaurants in Massachusetts, Texas and California.
- a composition query is generally determined by the Parse Driver, and the request router decides to which server node 808 - 810 within the Front End Server the composition query is sent for processing in accordance with domain weights of the configuration file.
- the Request Router may route the composition request to either server 1 or 2 . If the request is routed to server 1 , data may be cached regarding MA and TX for reuse and a new query may be performed for the CA information. If the request is routed to server 2 , data may be cached for reuse regarding CA and new queries performed for the MA and TX information. The Request Router, based on the weights, sends the request to server 2 since the cost associated with performing the MA and TX queries is less than the cost of performing the CA query.
- a particular domain is associated with a particular server node upon which data query caching is performed for designated domains.
- the domain and server weights reflect the cost associated with processing a request on each node using the data query cache. Accordingly, routing a request in accordance with these weights results in faster subsequent query times for those requests.
- Reallocation of the requests when a server is unavailable is performed with a bias toward the initial allocation scheme as indicated by the Configuration File. There is an assumption that reallocation is on a transient basis and that the initial allocation scheme is the one to be maintained.
- server nodes M 1 -M 4
- domains initially allocated to each node as indicated below:
- node M 1 becomes unavailable and the routers reallocate Domain D 1 to node M 2 and D 2 to node M 3 .
- node M 2 also becomes unavailable. Domains D 1 and D 3 are reallocated to node M 3 in addition to domains D 5 and D 6 .
- Domain D 4 is reallocated to node M 4 in addition to domains D 7 and D 8 .
- node M 1 is restored and node M 2 is still unavailable.
- Domains D 1 and D 2 are reallocated to M 1 in addition to Domain D 3 .
- Domains D 5 , D 6 and D 4 are allocated to node M 3 .
- Domains D 7 and D 8 are allocated to node M 4 .
- bias toward restoring the initial allocation scheme when a node becomes available This bias contributes to faster subsequent query times upon re-entry of a server node due to the use of the data query cache, and routing of subsequent requests to the particular nodes in accordance with this bias.
- step 200 a determination is made as to whether a data set in the data query cache corresponds to the current query being made. If so, control proceeds to step 202 where this data is retrieved and used by the query engine in formulating the query results that are displayed to the user. At this point, the processing stops at step 216 .
- parents of the current query are determined.
- parents of the current query are determined by dropping one of the terms. For example, if the query being made for “MA AND RESTAURANTS AND FLOWERSHOPS”, each of the three terms is sequentially dropped to form all combinations of two possible terms. In this instance, the set of parents is the following:
- a search is made for only the parent terms.
- other embodiments may go further in searching for results in the data query cache by also forming grandparent terms, as by dropping two terms. This process can be repeated for any number of terms being dropped and subsequently determining if any data sets in the data query cache correspond to the resulting terms.
- preprocessing insures that ancestor-based geography exists.
- that ancestor is a Verity term list associated with a particular state. This implementation uses API calls to retrieve the data identifiers corresponding to the resulting data to be included in the query results.
- step 205 If, at step 205 , it is determined that there are one or more data sets in the data query cache that correspond to one or more of the parent terms, control proceeds to step 206 where a cost is associated with each parent.
- a cost is associated with each parent.
- One embodiment associates a cost with each parent term in accordance with the number of listings of each parent term. This may also be normalized and used in a percentage form by dividing the number of listings in the parent domain by the total number of listings in the query domain. This percentage represents the probability of a business listing belonging to the parent data set appearing in the database.
- Control proceeds to step 208 where the parent with the minimum cost is chosen as the starting data set for formulating the data results.
- the minimum cost derivation sequence is applied to produce the resulting data query. Generally, the minimum cost derivation sequence is obtained by operating upon the least probability terms first.
- the determination of the start data set in step 208 may be the data set with is closest in terms of parentage and with the least number of listings in the data set.
- the proximity in parentage is the primary ranking basis and the number of listings being secondary in determining ranking.
- the query is for MA AND RESTAURANTS AND FLOWERSHOPS.
- MA is the starting data set which is located in the data query cache.
- the parentage has been extended to grandparents, and MA has been determined to be the first ranking data set in terms of parentage and number of listings in the data set.
- control proceeds to one of two states, 232 representing “MA AND RESTAURANTS”, or 234 representing “MA AND FLOWERSHOPS”.
- the state to which control is advanced depends generally on choosing the path with the minimum associated cost at each step.
- the number of elements in the data sets “FLOWERSHOPS” (state 234 ) and “RESTAURANTS” (state 232 ) may be considered in determining cost. If the number of elements in FLOWERSHOPS is less than the number of elements in the data set RESTAURANTS, control proceeds to state 234 where each business listing in the data set FLOWERSHOP is examined to determine if it is also in MA. The resulting data set forms the set of all business listings in MA AND FLOWERSHOPS. In contrast, if the number of elements in the data set RESTAURANTS is less than FLOWERSHOPS, state 232 is entered and similar searching of the data set is performed.
- searching of the data set elements is performed to produce the final resulting data set representing “MA AND RESTAURANTS AND FLOWERSHOPS”.
- the approach just described is to advance to the next state which has the minimum cost associated until the final resulting data set is determined.
- the data is partitioned by states.
- the adaptive techniques as described with regard to the GTE Superpages application described herein include partitioning the data sets based on geography, particularly within each state. In this instance, particular server nodes are designated as primary query servers based on geographic location by state. Additionally, as part of this partitioning of requests, the data query caches and term lists of identifiers are also partitioned according to state. In this embodiment, this partitioning is done as a preprocessing step prior to servicing a request in that the identifiers are formed and placed on each dedicated server node.
- partitioning may also be performed as part of a preprocessing step. Generally, this partitioning may be determined based on expected data queries and data sets formed accordingly, for example, by examining log files with recorded data query search histories to determine frequently searched categories or combinations of categories.
- a query request is generally the combination of boolean operators and search terms.
- the general form of a term in a query request is:
- the “key” represents some category or search term, such as STATE.
- “Value” represents the value which this key has in this particular query.
- Key-value pairs or terms may be joined by the logical boolean AND operation, represented, for example, as “&”.
- the logical boolean OR operation may also be represented, for example, by another symbolic operator such as a”,”. For example, when looking for either cities of ACTON or BOSTON, this may be represented as:
- keys include: (T) City, (B) Business Listing, (S) State, (R) Sort Order, (LT) Latitude, (LO) Longitude, and (A) Area Code.
- LT and LO may be used to calculate data sets relating to proximity searches, such as restaurants within thirty (30) miles of Boston.
- the Data Query Cache 850 in this embodiment, generally includes a “hot” and “cold” cache.
- the caching technique implemented is the LRU (Least Recently Used) policy by which elements of the cache are selected for replacement in accordance with time from last use. These and other policies are generally known to those skilled in the art.
- the “hot” cache may include the most recently used items and the cold cache the remaining items.
- each of the data query caches and other caching elements as depicted in FIG. 2 may be fast memory access devices, as known to those skilled in the art, used generally for caching.
- the “hot” cache is implemented as storing the data in random access memory. This may be distinguished from the storage medium associated with the “cold” cache representing those items which are determined, in accordance with caching policies such as the LRU, to be least likely to be accessed when compared with the items in the hot cache which are determined to be more likely to be accessed.
- a double ended queue structure is used to store cached objects, but other data structures known to those skilled in the art may be used in accordance with each implementation.
- Data sets that are stored in the data query cache and page cache each correspond to a particular search query.
- a mapping technique may be used to map a particular query to corresponding data as stored in the data query cache and the page cache.
- this mapping uniquely maps a data query to a name referring to the data set of the data query. In this embodiment, this allows quick access of the data set associated with a particular query and quick determination if such a data set exists, for example, in the data query cache.
- a subset of query terms is determined such that a string representing a particular query is uniquely mapped to a name corresponding to a data set.
- the subset of keys that are used in mapping a string corresponding to a query to a name of a data set include:
- Proximity City, State, Street, Zip, Category, Category Identifier, Business name, Area code, Phone number, Keywords, and National Account.
- “Proximity” represents the proximity in physical distance to/from a geographic entity, such as a city. “City”, “State. Street”, “Zip”, “Area Code’, “Phone Number”, and “Business Name” represent what the keys semantically describe as pertaining to a business listing. “Category” represents a classification as associated with each business, such as representing a type of business service. “Category Identifier” is an integer identifier representing a category id. “Keywords” indicate an ordering priority for the resulting data set. “National Account” represents a business or service level parent-child relationship where the national account indicates the parent. An example is a parent-child relationship between a parent corporation and its franchises.
- a query string corresponding to a particular user query is formed using the original string as formed, for example, by the Parser of FIG. 2 .
- the query string includes only those terms which are included in the subset as identified in step 240 . If the original string does not include an item that is in the subset, for example, since the user query does not include the item as a search term, that item is omitted in forming the query string corresponding to the data set.
- this query string is used to determine if a data set is located in the data query cache that corresponds to the current user query request. In this embodiment, the data sets each correspond to a filename.
- a lookup as to whether a data set corresponding to a particular user query exists may be determined by performing a directory lookup, for example, using file system services as may be included in an operating system upon a device which serves as a fast memory access or other caching device.
- this technique may be used generally within the Superpages Front End Server and Backoffice to form unique names that correspond to particular search terms.
- one embodiment may include services for operating upon the original query string as formed by the Parser to produce parents and grandparents of the terms included in a query when performing the method steps of FIG. 33 and 34 if there is no exact data set match in the data query cache.
- This may provide the advantage of insulating other code, such as in data encapsulation, from knowing the internal structure of the query string.
- this is a common programming technique to minimize code portions from changes in data types and structures to minimize, for example, the amount of recompilation when a new data type is introduced or existing data type modified.
- Other techniques such as hashing, may be used to generate a unique identifier for the input string, as known to those skilled in the art.
- a similar mapping technique is used in forming a Page Cache name.
- the technique used is as described for forming the Query Cache filename with additional qualifying terms in accordance with the “look and feel”, such as display features, used to produce the Page Cache name. For example, if the displayed resulting HTML page includes 15 listings/page, the Page Cache name includes a parameter in forming the name uniquely identifying the filename including the result set for a query in this particular display format.
- the data query cache includes cache objects in which each cache object corresponds to a particular cached query resulting data set.
- FIG. 36 shown is a block diagram of one embodiment of a data set as stored in the data query cache.
- each data set 250 includes header information 252 and information corresponding to one or more business listings.
- header information may include information describing the data query set, such as the number of business listings in the data set. Other types of information may be included in accordance with each particular application and implementation.
- Each business listing 254 generally includes information that describes the business listing. More particularly, this information includes data that is cached as needed by other components in the Front End Server, for example, in performing various searches, data retrieval, and other operations upon data in accordance with functionality provided by the embodiment. In this instance, the following types of fields of information are stored for each business listing 254 :
- relevance information is Verity-specific information as it relates to the query. For example, this generally represents the frequency of words or terms in a document.
- the advertiser priority indicates a service level that may be used in presenting business listings, for example, in a particular order to a user. For example, if a first advertiser purchases “gold” level advertising services, and a second advertiser purchases “silver” level advertising services, when a user requests only 15 listings to be displayed, the “gold” level advertisements may be displayed prior to the other advertisements by other advertisers, such as the “silver” level service purchaser. Thus, a higher level of service may guarantee an advertisement be placed earlier in the displayed results.
- the technique used to store the data in the data cache from memory includes object serialization and deserialization techniques, as known to those of ordinary skill in the art. These techniques transform an internal storage format, as may be stored in random access memory, to a format suitable for persistent storage in a file system, as in the data query cache.
- the complementary operation is also performed from persistent storage to the in-memory copy.
- object serialization i.e., from memory to persistent storage device in cache, is performed by storing the data type, its length, and the data itself. It should be noted that the length may not be needed for each data field, for example, in fixed length data types.
- the complementary operation of object deserialization is generally performed by reading the fields in the same order as written to the cache.
- the Page Cache may be implemented as HTML files in a file structure located on a disk or other storage device.
- the PHTML execution tree may be implemented as an in-memory linked list or other abstract data structure representation of the C++ objects.
- the data query cache may include different types of cached geographical data as may be used in performing different data queries.
- the type of data cached described in the prior paragraphs is the “normal” business listing data as associated with a well-defined geographic area.
- Other businesses for example, such as a florist or an airline, may not be associated with a single well-defined geographic location.
- a business may not have any geographic bounds, such as if it is an Internet business with a virtual storefront accessible on the Internet.
- other businesses may be located in a particular well-defined geographic area, such as an airline with a physical presence in a particular city, but the service area which corresponds to the service offered does not correspond to the location of the business itself.
- the concepts of multi-city and total-city placements have been included in this embodiment.
- multi-city placement may be described as representing a business' service area in multiple cities when data queries are performed.
- An example may be a plumbing service located in three (3) cities with service areas in ten (10) cities.
- the total-city placement may generally be described as representing a business' service area in all cities when searches are performed.
- An airline is generally an example of this which services all major U.S. cities.
- the total city and multi-city search results are cached separately from the “normal” query results, but are composited with the normal search results prior to retrieving the data from the database.
- the total and multi-city query results are retrievable independent of the “normal” search results.
- the storage format for this information in this embodiment, may be as described for “normal” query results.
- other embodiments may use a different format for storage than the “normal” search results, for example, if other information is deemed to be important in accordance with each implementation.
- a total-city cache name corresponding to the data query is formed.
- category category id, business name, street address, keywords, longitude, latitude
- these functions of extracting the information from the original query string and forming the total-city cache name may be performed by the same software as forming the name for the data query cache “normal” query name, such as by API calls to the same routines with parameters, as known to those of ordinary skill in the art of programming.
- step 262 it is determined if the total-city query data set corresponding to the total-city cache name for the current query exists. If it does, control proceeds to step 264 where the total-city data set cached item is moved to the hot cache, if not all ready in the hot cache. A reference to this data set is saved for later retrieval in other processing steps. If at step 262 , a determination is made that the total-city query cached data set corresponding to the total-city cache name does not exist, control proceeds to step 266 where a search is performed for the total-city query. At step 268 , the search results are cached, as in the “hot” cache. A reference to these search results are stored for use in later processing steps. Generally, an empty or null search results stored in cache may be just as important for performance as a non-null search results that is cached.
- a multi-city cache name is constructed representing the multi-city cache corresponding to the current data query.
- this multi-city cache name may be constructed by forming a string using the same fields extracted from the original data query string as formed by the parser in conjunction with forming the total-city name. Similar to forming the data query name for the “normal” cached search results, the string corresponding to the cached data set for a given query uniquely identifies the data set.
- the total-city and multi-city data cache results are integrated with the “normal” query results. After the “normal” query is performed, but before sorting the search results, the total-city-cached results, if any, may be combined with the “normal” query results. If there are no total-city cached results, the multi-city results may be included, if any.
- the combined search results are then sorted such that any redundant listings are removed. Any additional processing is performed, as in accordance with the user query, for example, as producing the listings which begin with “B”, or only listing the top ranked fifteen (15) listings as ranked in accordance with other user specified criteria.
- a garbage collection technique may be included to remove or delete cached objects that have been determined to be “old” in accordance with predetermined criteria. For example, in one embodiment using the LRU caching scheme, whenever the amount of free cache space falls below a threshold level, the garbage collection routine is invoked.
- the threshold level includes parameters relating to a predetermined number of cache objects and the accumulated size of the objects in the cache.
- the cached results may physically reside in the same “hot” and “cold” caching devices.
- the different types of caching results may be accessed independent of the other caching results.
- Other embodiments may have other organizations of the caches in accordance with other implementation and associated data requirements.
- the query engine 862 may, in an embodiment of the invention, include information retrieval software 908 to retrieve records from the Primary Database 812 that correspond to the user's query.
- the query engine 862 may include more than one form of information retrieval software.
- the query engine in addition including the information retrieval software 908 that is to be used to obtain listings in response to user queries, may further include banner ad retrieval software 909 for retrieving advertisements that relate to the user's query.
- the information retrieval software 908 may include functionality of software such as the Information Server Version 3.6 software commercially available from a company known as Verity. Other commercial packages of information retrieval software are available, and the techniques described herein could also be employed using proprietary software coded by the user.
- the information retrieval software 908 includes the Information Server Version 3.6 software and additional extensions provided by the host of the GTE Superpages system.
- the information retrieval software 908 may at a step 82 access markup language files 906 , as depicted in FIG. 25, which are produced by the extraction routines 902 from the normalized data 900 .
- the markup language files consist of business listings that are stored in the Primary Database 812 .
- the information retrieval software 908 may then, at a step 84 produce term lists 836 that are further used by the information retrieval software 908 to handle queries that are delivered to the query engine 862 .
- the term lists 836 may consist of a linked list for each term that appears in one of the business listings, with the elements of the linked list including a document identifier for the business listing and certain statistics regarding the frequency of occurrence of the particular term in each document and in the document set as a whole.
- the banner ad retrieval software 909 may similarly generate and use banner ad term lists 837 that are further used by the banner ad retrieval software 909 to handle generation of appropriate banner ads.
- the term lists which in an embodiment are generated using Verity software, may be expanded at a step 86 to include synonyms for the terms appearing in the business listing.
- the term “diner” appears in a business listing, then the term “restaurant” might be assigned to the file for that business listing as stored in the Primary Database 812 .
- the expansion of the listings to include synonyms of the words included in the listings may be accomplished by execution of PHTML scripts or other programming techniques.
- the expansion may establish a hierarchical structure; for example, the term “restaurant” may be stored in a tree that includes the sub-category of “ethnic restaurant,” which may further include the sub-category “greek restaurant.”
- PHTML scripts may be provided to establish the tree structure and to operate on the tree structure to retrieve results that will be provided to the user.
- the steps 82 , 84 and 86 may be accomplished at initialization of the system, thus establishing and expanding the term lists 836 , 837 for later use.
- the system may operate to obtain results that are to be displayed to the user.
- the steps for obtaining results may be seen in a flow chart 88 displayed in FIG. 41 .
- the parse driver 858 may at a step 20 parse a user query and deliver the parsed query in suitable form for handling by the query engine 862 .
- the query engine may include the information retrieval software 908 .
- the query engine 862 may operate the information retrieval software 908 to take the parsed user request and expand the query, turning the user request into a detailed query.
- the information retrieval software may operate on the expanded term lists 836 by identifying documents associated with the terms identified in the expanded query.
- the term lists 836 are the business listings described in connection with steps 82 , 84 and 86 above, expanded to include synonyms and terms that are determined to be related to the words in the business listing.
- Identification of documents may be accomplished by a variety of information retrieval techniques. Documents may also be associated with queries by sorted relevancy ranking, clustering (automated grouping of related documents), automated document, summarization (creation of content abstracts, not simply the first few sentences of the document) and query-by-example (turning an individual document into a query in order to retrieve “more documents like this”). These functions may be accomplished by software techniques, such as having a table of pointers having as an argument a tokenized version of each possible term from the expanded user query from the step 22 .
- the table of pointers may point to the location of a term list 836 for each such term.
- the term list may be a linked list of documents that include the term.
- the linked list may include information about each document, such as the number of occurrences of the term in the document, the inverse frequency of the term in the entire set of documents, the association of the document with other documents, the association of the document with categories, and the like.
- an indexing architecture such as that provided by Verity allows for incremental indexing, so that only new, updated or deleted documents require changes, avoiding the need for a complete re-index each time a document changes.
- Online identifiers may be provided, so that searches can continue while the identifiers are modified. This function is also provided by the Verity software.
- a variety of weighting algorithms can be used to rank documents identified in the step 24 according to the information stored in the term lists 836 .
- a simple weighting algorithm might take a single term query, such as a category of information, and rank each document in a term list 836 in numerical order according to the product of the term frequency (the number of times a term appears in the document) and the inverse document frequency (the inverse of the number of times the term appears in the entire document set).
- a list of the ranked documents may be further processed by the information retrieval software to provide a results page.
- the information retrieval software 908 may determine categories into which the retrieved documents fall.
- the categories are yellow pages categories, which have been previously assigned to the documents, which are business listings, prior to entry of the business listings in the Primary Database 812 .
- the information retrieval software 908 determines what categories are associated with the business listings retrieved by the ranking at the step 28 .
- the information retrieval software 908 may compare the categories identified at the step 30 to the terms in the user query.
- categories are present that do not include any of the terms in the user query, then, at a step 92 , such categories may be discarded. Thus, the user will not retrieve categories that are unrelated to the user query. Such categories might otherwise appear, for example, if the information retrieval software 908 retrieves a business listing that is associated with two unrelated categories, only one of which is relevant to the user query. For example, a query for a restaurant might retrieve a listing for “Joe's restaurant and bowling alley.” The information retrieval software 908 might then retrieve the categories “restaurants” and “bowling” that would have been associated with that listing. The “bowling” category would be discarded, because the user query for a restaurant is unrelated to the “bowling” category.
- the term comparison may use an expanded version of the terms in the query and in the categories. Thus, a category would not be discarded if it includes a synonym of a query term, even if the category does not include an exact term match.
- the information retrieval software may, at a step 94 , determine whether there are any remaining categories. If not, then control proceeds to a step 96 , at which the user is informed that there are no matching categories. The user may then be returned to the query screen. If, at the step 94 , at least one category remains, then, at a step 98 , the information retrieval software determines whether there is more than one category. If not, then at a step 100 the system may display the actual business listings that appear in that one category to the user. If at the step 98 it is determined that more than one category remains, then at a step 102 the system may display a results page that consists of a list of the remaining categories. The results page may further include an indication of the number of listings that are associated with each category.
- the document identifiers established for information retrieval software 908 may maintain pointers to other documents or to sources of the documents, such as URLs or file names. Thus, the identifiers may be stored apart from the documents allowing separate, non-invasive use of the identifiers, while maintaining the integrity of the data.
- common terms may be identified in order to optimize the retrieval of information in cases where user queries employ such terms.
- a series of steps may be performed as pre-processing operations in order to classify and establish query result sets for common queries.
- common terms may be identified prior to system initialization. Designation of common terms may be performed based on a number of different factors. For example, a single word might in theory be designated a common term, if it appears with a high frequency in result sets obtained by users. It is noted that a single word common term may offer relatively little benefit in search efficiency, because the term lists 836 already permit searching based on individual terms.
- common terms might consist of multiple word combinations of any length, whether bi-grams, tri-grams, or n-grams. Thus, words that co-occur in high frequency can be designated as common terms, such as in a bi-gram format. For example, the bi-gram “Boston-restaurant” might be designated a common term.
- terms may be linked to specific contexts; that is, terms may be designated or classified as common terms in part according to their context.
- the term “Boston,” might be considered a common term if entered in the “city” field, but it might not be considered a common term if entered in a “business name” field or a “category” field.
- the term “restaurant” might be a common term in the “category” field, but would not be considered a common term in the “city” field;
- the common term sets may be structured to reflect context.
- each term might be expanded to include both synonyms for the term and other terms that are semantically related to the common term in the established context for the term.
- the pre-processing steps 32 , 33 and 35 might be accomplished in a different order, and other steps might be included in embodiments of the invention.
- Once common terms are identified, linked to contexts, and expanded at the pre-processing steps 32 , 33 and 35 it is possible to establish lists or identifiers at a step 46 that include the expanded common term n-grams.
- One way of dealing with common term combinations would be to generate in advance term lists 836 that are predicted to be used with some frequency (e.g., restaurants, Boston, New York, etc.) and to pre-calculate the intersection of the likely combinations. This approach requires substantial processing and would have to be performed frequently, given frequent changes in the identifiers.
- a term list 836 might consist of a linked list of documents, such as business listings, that contain the terms “Boston” and “restaurant,” (or synonyms thereof) in the contexts in which those terms are common.
- the term lists 836 may, like other term lists 836 described elsewhere herein, may further include information as to the term frequency of each term, synonym or related term, and the inverse document frequency of the term, synonym or related term in all documents in the set.
- the synonyms and related terms may be included in the actual business listings that are used to generate term lists 836 , so that those listings will be included in the generation of common term lists.
- the listings themselves may be classified as to common terms and synonyms or related terms of those terms.
- Listings may be further classified as to sub-contexts, depending on the search context. Listings using identical terms should also be included in term lists, because they use identical token identifiers for such terms. For example, the term “Boston” should be understood in a nationwide search to include listing in both Boston, Massachusetts and Boston, Kentucky, because the token for the term “Boston” will be the same in each case. Result sets must be identified as tokenwise semantically related to the classifications that are possible in a search. Results are thus classified into common term groups on a listing-by-listing basis.
- the common term lists 836 for combined terms can be stored in a designated area of the primary database 812 , front end server 804 , or server node 808 - 810 that allows a rapid search in the event common term combinations are included in the user query.
- the common term lists are thus assigned to a special results area for common term searches.
- the steps 46 and 48 may be performed upon initialization of the system.
- result sets are established for common term searches, and the result sets are stored in a special location in memory for rapid retrieval.
- query rules may be established that direct appropriate user queries to the special location in memory established at the step 48 .
- the user might enter a query on a template 34 that is displayed as a page, such as markup language page, on the user's browser 824 .
- the template might include fields 36 , such as a category field 38 , a business name field 40 , a city field 42 and a state field 44 .
- fields 36 such as a category field 38 , a business name field 40 , a city field 42 and a state field 44 .
- the query is then used, as described above in connection with FIG. 41, to retrieve documents.
- the documents that are retrieved at the step 28 and displayed at the step 30 of FIG. 41 are a set of matching categories for the query.
- the information retrieval software 908 may retrieve a set of matching categories that relate to art supplies.
- the retrieved categories may be ordered alphabetically, by order of significance, or grouped by sub-categories.
- the user then may select categories among the matching categories to receive either further sub-categories or documents, such as advertisements or other markup language pages, that correspond to the categories.
- the information retrieval software 908 may immediately retrieve matching documents, such as specific advertisements or other markup language pages, rather than categories of documents. This direct retrieval step may be accomplished, for example, when one of the user-entered categories is an exact match to one of the categories included in the term lists 836 .
- the information retrieval software 908 retrieves documents from the term lists 836 that correspond to a ranking of an expansion of the user-entered query.
- the information retrieval software 908 may, in a conventional manner, retrieve term lists 836 that correspond to each of the terms of the query, such as a list corresponding to the category “restaurant” and a list corresponding to the city field “Boston.” The information retrieval software 908 could then perform an intersection of the two sets and perform a ranking of the related categories (e.g., Italian restaurants in Boston, French restaurants in Boston, etc.) or related listings (for specific Boston restaurants).
- the related categories e.g., Italian restaurants in Boston, French restaurants in Boston, etc.
- related listings for specific Boston restaurants.
- the information retrieval software 908 may be programmed to execute the search for the user's query in the special area of memory that was established for storage of the special common term lists 836 at the step 48 of FIG. 42 .
- data updates .included in the database come from three different sources in this particular embodiment.
- One source is on-line updates, as provided by users making updates or entering new information for business listing via network connections through the Backoffice component as through the Front End Server.
- a second source of data updates is based on foreign source updates.
- foreign source updates are those update records which come from a different data source than the original existing database.
- a third type of data integration or update source is referred to as a native source update.
- a native source update is when an updated version of the existing database having the same source as the existing database is provided.
- a database copy may be provided as an update on a monthly basis using full sets of data where a data provider provides an updated version of the same data set.
- the native source data integration procedure integrates those changes in the new data set into the existing database. This is in contrast to a foreign source update, for example, where the existing database is provided by one vendor, and the update records for example, are provided by a different vendor.
- the update vendors being from a foreign source are called foreign source data integration or updates.
- the native source update records are provided using full sets of data.
- the existing database is a complete database.
- the native source updates are provided in the form of a complete database as opposed to only providing update records.
- the foreign source update records are generally records obtained from a source different from the working database and are merged into the existing database.
- Shown in FIG. 45 is a native source update database 1500 which is integrated into the unfiltered database 1504 .
- this is done by performing comparisons of the records of the native source update database 1500 and the unfiltered database records 1504 in determining the various types of operations that need to be performed to integrate the changes from the native source update into the unfiltered database. This will be described in more detail in paragraphs that follow.
- Applying data enhancement techniques to the unfiltered database these record changes are integrated into the working database 1508 .
- the unfiltered database 1504 is a complete version equivalent to the working database.
- the records included in the unfiltered database 1504 generally include raw data which has not had the benefit of the data enhancement techniques as applied to the working database records 1508 .
- the on-line update records 1506 and the foreign source update records 1510 are integrated directly into the working database copy 1508 . It should generally be noted that the foreign source update records 1510 are integrated or merged into the working database records 1508 by applying data merging techniques that will be described in more detail in paragraphs that follow.
- the denormalized data as included in the Backoffice component and the Front End Server, include in this particular embodiment, three tables or components of data.
- the three components of data include a category file, a fact file, and a business listing file.
- the business listing file has been previously described in conjunction with the architecture in other sections of this description.
- the fact file includes information additionally provided by various advertisers or business services which are generally static in nature.
- the fact file may contain information such as hours of operation and extra attributes such as brand names or products produced by a business.
- This file generally does not change with updates.
- the third file is a category file may include a category identifier and a corresponding heading.
- the category identifier is a numeric quantity or other identifier that may be used in performing queries.
- the heading is a textual description of the various category identifiers which may be used either for performing data queries.
- the business listing file is generally what is updated when considering the techniques which will be described.
- the category file is also updated as part of the native source update, as will also be described in paragraphs that follow.
- a business listing is the atomic unit of granularity by which updates are performed. Any information and data such a phone number, name and address associated with a particular business entity is considered to be part of one logical piece of information or record. Thus, in the descriptions that follow, updates are made with regard to the information associated with one particular business listing or entity.
- the techniques which will be described regarding the foreign source update generally assume that an existing database and update records are provided, and that each originate from different or foreign sources. It should generally be noted that since the sources are different, there is no general assumption made as to particular data fields or the structure of the foreign records as compared to the existing database. It is first determined whether there is a matching entry in the existing database for an entry in the updated version of the database. If no match is found in the existing database for an entry or business listing which appears in the updated version of the database, this new entry is added and integrated into the existing database.
- the techniques which will be described in paragraphs that follow may be adaptable, as known to those skilled in the art, to update situations in which an implementation uses something other than two complete sets of data when performing a system update.
- this process of foreign source update is performed in the Backoffice component 818 in which the existing database to be updated is generally in normalized form.
- the updated version of the database may be in normalized or denormalized form.
- additional processing steps may be needed to retrieve and update the actual files that include the data, for example, associated with a particular business entity or record.
- each business listing generally includes the following data items: business name, zip code, and at least one of a primary phone number or toll-free phone number.
- the foreign source integration technique is based on the premise that a phone number and zip code of a business are sufficiently unique to significantly reduce the matching problem to comparisons of a few listings.
- the matching technique described for foreign source update determines a correspondence between the foreign source update records 1510 and the records in the existing working database 1508 .
- the matching technique generally includes: 1) determining which records in the existing working database match which update records; 2) if more than one record in the existing database correspond to the same record in the existing working database, determining which record in the existing database is the closest match for the update record; and 3) if the foreign source update records include duplicate records such that multiple update records correspond to the same set of one or more existing database records, collapsing the duplicate foreign source update records into a single update record that is matched to a single record in the existing database.
- an update to an existing record is performed so as not to lose any existing information while also incorporating the new additional information or updated information.
- an existing listing includes a business name and address, and phone number, but no e-mail address.
- a foreign source update record includes a business name and address, e-mail address, and phone number. The information from the foreign source update record is included in the existing database in union with the fields that are blank in the update record such that the e-mail address in the existing database is not removed when the updated information from the update record is applied.
- no delete operations are performed with the foreign source update data integration due to the nature of combining data originating from different sources.
- other embodiments may include delete operations in addition to update and modify operations in foreign source data integration.
- a comparison is made between the phone number of an update record and the phone number field of each entry in the existing database.
- a determination is made as to whether or not the record in the latest version of the database copy is an 800 phone number. If a determination is made at step 1000 that the phone number of the current update entry is not an 800 number, control proceeds to step 1008 .
- the procedure “match phone number” is performed to produce a subset of one or more entries of the existing database which match the existing phone number. Control proceeds to step 1010 where the procedure “name match” is performed. Generally, “name match” will be described in paragraphs that follow to determine whether there is a business name match for a particular entry.
- Control proceeds to step 1012 where “derive score” is performed based on the zip code and the name match score. Generally, the result of step 1012 produces a score representing a statistic relative to determining whether two entries in a particular database and an updated version of the database match.
- step 1046 this maximum scoring entry in the existing database is determined to be the matching entry for the updated version. If at step 1036 there are multiple entries with the same maximum score, control proceeds to step 1038 where additional processing is required to determine which is the matching entry, if any.
- score threshold of 50% may be tuned and varied for each particular implementation and embodiment.
- This value is generally a configurable threshold value that may be defined heuristically, for example, by examining data samples.
- step 1038 The processing of step 1038 is generally performed off-line. It may be done manually or in an automated fashion in accordance with the types of data in the existing database. For example, at step 1038 , having multiple entries with the same maximum score may indicate that there is an error or corruption in data. For example, in one embodiment, an alternate technique is used where if any record has the same zip code, that record is considered as being a matching record.
- step 1020 determines whether or not the score is less than or equal to 50%. If at step 1020 a determination is made that the score is less than or equal to 50%, control proceeds to step 1022 .
- step 1022 a determination is made as to whether or not the difference in the name length is less than or equal to three. If the difference in the name length field is not less than or equal to three, control proceeds to step 1028 where a determination is made in that no matching entry exists in the database. It should be generally be noted that the decision process and the comparison process performed in steps 1020 and 1022 are performed for each matching entry in the subset as produced from step 1008 . It should generally be noted that the threshold length of three for the name length used in step 1022 may be varied and tuned for each particular embodiment and implementation.
- step 1022 if a determination is made that there is at least one entry in the existing database with a name length difference less than or equal to three, control proceeds to step 1024 , where the name edit distance heuristic may be used to compute the name distance.
- the name edit distance is the minimum number of insertions, deletions, and substitutions at the character level to turn one name entry or string into a second name entry or string.
- the number of states that string A must pass through to be transformed into String B is an entry or quantity referred to herein as the name edit distance.
- the textbook entitled “Text Algorithms”, by Maxime Crochemore and Wojciech Rytter generally describe a technique for the name edit distance heuristic.
- the name edit distance is computed, for example, using dynamic programming techniques known to those skilled in the art, such as using a finite state machine, for each matching entry as in the subset produced by step 1008 .
- control proceeds to step 1100 of FIG. 52 where a determination is made at step 1100 as to whether or not there is only one matching entry in the subset as derived from the Step 1008 .
- step 1100 determines whether there is only one matching entry. If at step 1100 a determination is made that there is more than one matching entry in the existing database for a foreign source update record, control proceeds to step 1102 , where a determination is made as to whether or not there is only one matching entry with a minimum distance. If a determination is made that there is only one matching entry with a minimum at a distance, control proceeds to step 1108 where it is determined that an entry in the existing database with the minimum distance is considered a match to the update record in the foreign source update.
- step 1102 If at step 1102 a determination is made that there is more than one matching entry with a minimum distance, control proceeds to step 1104 where additional processing may be required in accordance with the types of data included in the database.
- the additional processing required is generally the same types of processing that may be performed in accordance with the previously described step 1038 of FIG. 47 .
- step 1000 if at step 1000 a determination is made that the phone number of the updated record is an 800 phone number, control proceeds to step 1002 where a determination is made as to whether or not the phone number, including the area code, and the zip code match one or more entries in the existing database.
- step 1002 if there is a determination that one or more entries in the existing database match the phone number and zip code of the update record, control proceeds to step 1006 where a subset of one or more matching entries is found. Control then proceeds to point B indicated at step 1010 in FIG. 46 where execution continues.
- step 1002 If a determination is made at step 1002 that the phone number and zip code do not match any entries in the existing database, a determination is made at step 1004 that no match exists in the database for the current update record.
- a table is used with old and new area codes and exchanges to determine if there are one or more matching entries in the existing database which match the phone number of the current update entry.
- the processing step of 1050 and the decision made at step 1052 may be used, for example, where area codes have changed due to the increased volume of phone numbers which require additional area codes to a particular locality to be added.
- the 508 area code may be expanded to include the 781 area code.
- an existing phone number may be included in the database with either the 781 or the 508 area code depending on the age of the data in the database.
- step 1052 If a determination is made at step 1052 that either an old area code and exchange, or a new area code and exchange match, control proceeds to step 1054 where a subset of one or more matching entries is formed. Control proceeds to step 1056 where control returns to the calling procedure. In this instance, control returns to step 1008 where subsequent control proceeds to step 1010 of FIG. 46 .
- step 1052 If at step 1052 a determination is made that there is no old or new area code and exchange in the existing database which match the current entry in the updated version of the database, control proceeds to node C of the “secondary search” in FIG. 51 at step 1086 .
- the processing which occurs in the steps of FIG. 51 attempt to find semantic equivalents of the name fields indicating a possible match.
- the name of the update record is tokenized.
- stop words are removed from the name field. Generally, stop words may be words which may be ignored when doing a name comparison.
- the words “and”, “or”, “the”,“a”, “an”, “to”, “in”, and “at” are considered “stop words” for which a matching entry may contain any number or combination of these and the match should still succeed.
- these words are removed and not considered when performing a name comparison.
- a search of the existing database is performed on the conjunction of the tokenized name field components and the zip code. Generally, the search is being performed for entries in the existing database which match zip code and the different components of the name field.
- a determination is made as to whether or not there are more than 5 matching entries in the existing database for the current update record. If at step 1092 a determination is made that there are more than five matching entries in the existing database, control proceeds to step 1094 where a determination is made that no match has been found. If at step 1092 , a determination is made that there is not more than five matching entries, control proceeds to point B in the processing which is shown in FIG. 46, step 1010 where these name matching entries are used as the subset upon which subsequent processing is performed.
- FIG. 49 shown is a flow chart of the steps of one embodiment performing a “name match” as part of a routine processing as invoked from step 1010 of FIG. 46 .
- the steps of FIG. 49 attempt to perform and find semantic equivalents of the names of a business in this particular instance.
- the name entries are canonized.
- canonization rules are a set of transformations which occur, for example, transforming abbreviations and the like to semantic equivalents allowing for a common denominator of terms to be searched for.
- Control proceeds to step 1062 where the name field is tokenized into components.
- step 1064 a setwise contents comparison of the name components of each entry is determined against the current update entry.
- step 1066 a score is computed for each name comparison of the existing database entry with a record of the updated version of the database. The score is computed as one point per matching component.
- step 1068 control returns to step 1010 where subsequent processing resumes with step 1012 .
- the processing steps of FIG. 49 attempt to formulate a numeric quantity or metric for determining whether two name entries match. This weighted value or concatenation is used in further comparison in combination with other field, such as the zip code, and arriving at a final quantity in determining whether or not name fields of an existing database entry and an update record match.
- step 1080 the score previously derived from name match for each entry is updated by one if the zip codes of an existing database entry match an updated entry.
- this score is normalized by taking the score computed thus far and dividing it by the number of tokens in the foreign source entry name field. It should be noted that other techniques may be used to produced a normalized score as in step 1082 .
- step 1084 control returns to the point of call. In this particular instance, control returns to step 1012 where processing resumes with step 1020 of FIG. 47 .
- FIGS. 46 through 52 processing techniques for determining matching entries for foreign data. What will now be described are techniques which provide for data enhancements where the two databases or two data sources being integrated are from the same source. Generally, where there is this native source processing, there will be fewer differences between the data entries due to the fact that both data sets come from the same source. Thus, the techniques which are described in paragraphs that follow may generally be referred to as data enhancements. However, similar to the processing just described with regard to foreign source integration and processing, the concepts and processing steps which will be described may be readily adaptable to other types of data updates in accordance with other particular implementation and data sets.
- the update techniques for native source assumes that two full sets of data are used—the updated database version, and an unfiltered or raw version 1504 of the existing working database.
- the techniques that are described below with regard to native source processing are data enhancement techniques applied to the unfiltered database 1504 to produce the working database 1508 of FIG. 45 .
- step 1400 the computation of the data update is performed using two complete sets of data from native sources.
- the latest set of data received such as from a data provider is submitted into the database and compared against the set that is in the existing database. All of the records in the data set are loaded in the following form.
- record ID For comparison purposes, in the steps that follow there is a distinct record ID followed by a string where the string is all the fields from the record concatenated together for comparison purposes in steps that follow.
- record I.D.s are unique against the set and indexed.
- the delta or difference between the two data sets is produced.
- Each entry in this delta or difference is classified as an insert, delete, or update operation.
- a record is inserted into the existing database in which identifiers are in the new version of the data set but not in the existing database. All records which have identifiers in the existing database, but not in the new version, are slated for deletion from the existing database. Records in which identifiers are in both sets, but, however have associated strings that differ are considered update records having data contents in the string that is updated for the corresponding identifiers.
- the update records which include inserts and update transactions are applied to the existing database.
- certain data post processing is performed as will be described further in the paragraphs that follow.
- FIGS. 46-54 generally describe data integration of the native source updates which are applied to the database of business listings and categories. In summary, for both business listings and categories, comparisons are made between records of the native source unfiltered database and native source update.
- step 1406 a comparison is made between the existing database copy with the updated database copy by comparing the record identifiers and the string concatenation which represents the remainder of the records.
- each update record is classified as one of a matching entry, an insertion, a deletion, or an update with respect to the existing database.
- step 1416 a record is determined to be matching if the record identifier and string field in the existing and updated data base copies match.
- a record has been classified as one to be inserted if there is a record with a record identifier in the update database which is not in the existing database.
- data enhancements are performed and the record is integrated into the working database. It should be noted that the data enhancements also performed in step 1428 is described in more detail in paragraphs that follow.
- a record has been classified as one to be deleted from the existing database if there is a record with the record identifier in the existing database not in the updated database. Subsequently, at step 1422 , the data operation is performed integrating the data updates into the existing working database.
- a record is considered an update transaction to an existing record in the existing database if the record identifiers match, but the remainder of the record represented as a string does not match.
- the longitude and latitude of a record may be updated if the address has been modified.
- data enhancements may be performed to the record, and the data update is applied to the existing working database as well as the unfiltered database.
- step 1416 where matching entries are found, no further processing may be required for existing database or the updated database record.
- steps 1420 , 1424 , 1430 update records or transactions are generated to modify the existing database.
- a protection or locking technique may be included in the database, for example, which prevents a deletion or modification of a particular business listing included in the database regardless of the processing classifications of FIG. 54 .
- the data enhancements are generally data filtering steps prior to integrating the data update into the working database 1508 .
- the data filtering techniques generally facilitate matching corresponding records when performing updates.
- Data enhancements may include, for example, upper/lower case justification, detection of synonyms and/or acronyms, transformation of abbreviations as may be used in business names (e.g., corp., inc.), street addresses (e.g., st., pl.), and city and state names.
- Other embodiments may include other enhancements in accordance with the type of data and the various applications.
- the category file in one embodiment includes a category identifier and a corresponding header that is a text description of the associated category identifier. It should generally be noted that these updates are applied in a model similar to that of the business listing files for native source updates. The updates are first applied to a “raw” or unfiltered version of the category file, followed by data enhancements as appropriate, an then integration of the data updates into a working copy of the category file included in the working database 1508 .
- each update record is classified as one of several types of transactions.
- a record in the updated category file is considered matching if the record identifier and the associated header match an entry in the current category file.
- an record is inserted into the existing unfiltered database and working database if the record identifier is not in the existing unfiltered database copy of the categories.
- data enhancements may be performed and the resulting filtered data further integrated into the existing category file in the working database 1508 .
- the data enhancements, as included in steps 1468 and 1476 are described in more detail in paragraphs that follow.
- a record in the existing category file is deleted if the record identifier of an existing record is not in the updated version.
- this deletion operation may be performed to the working copy of categories included in the working database 1508 .
- an update record is used to update the database copies if the record identifier of an existing an update records match, but the heading names differ.
- data enhancements are performed and the update operation is integrated into the working copy of the categories includes in working database 1508 .
- the data enhancements may include processing of the headings.
- the processing to enhance the text of the headings may include text transformations such as: upper/lower case justification, consolidation of abbreviations, and removal of idiosynchratic and slang terminology.
- the function of these data enhancements is to generally filter the data to provide more accurate determination of matching or corresponding categories.
- FIG. 56 shown are general post processing steps for one embodiment of expanding more detailed steps of step 1404 of FIG. 53 . Generally, these steps may be performed to the category file as included in the working database 1508 .
- new categories may be added.
- a data vendor may not provide an integrated version of all business categories. It may be possible to enhance some record categories as additional data is added.
- a restaurant may be a particular type of category and there may be other subdata organized in the structure of the record indicating that there is a particular type of restaurant in accordance with the various ethnic cuisines, such as French or Italian.
- Post-processing as in step 1440 may be written to search the data file in accordance with recognized structural format and add additional categories in accordance with any categories and subcategories. For example, if a determination is made that there is a large number of restaurants with a subcategory of French, a new record category may be added which is “French restaurant”. Similarly, an Italian restaurant category may be added. This is generally performed in accordance with the data organization and categories of the particular data being examined in each implementation.
- step 1442 redundant categories as stored by business are collapsed and detected by removing the equivalent categories.
- semantically equivalent categories are determined. Generally, this includes locating equivalent categories for which the spelling might be slightly different, or those fields which may be subsets or equivalents of other fields. For example, “animal doctor” may be interpreted as a semantic equivalent for “vet”, or “veterinarian”.
- this step may be done in an automated fashion using any programming language which is commercially available and may be used with the existing database.
- the technique involves dropping or not including special non-alpha-numeric characters or other words, similar to the stop words.
- White space may be compressed and comparison may be done on a case insensitive manner. The comparison may further be done by requiring an exact character match or with some at-a-distance technique similar to those previously described with other data processing.
- the duplicate categories and records may be removed from the existing version as stored in the working database 1508 .
- step 1442 where there is a collapse of redundant categories by detecting and removing equivalent categories
- different rules may be used to decide which category of several duplicates identified as the one to keep. For example, maybe the longest name, the shortest name, or simply the first name.
- duplicate categories are determined.
- a technique for determining duplicate categories is described in paragraphs that follow in conjunction with FIG. 58 .
- duplicate categories in the unfiltered database may be examined as a group and one of the category names or headings is chosen to be the heading included in the collapsed category record. One technique for choosing the heading is be determining which category name is most frequently used, such as by examining the business listing files for frequency determination.
- the business listing files, as included in the unfiltered database may be patched with the new heading and identifier corresponding to the collapsed resulting record.
- the category file is also updated to reflect the collapsed entry. It should be noted that these are made to the existing working database.
- step 1500 a first category name in the category file of the unfiltered database is tokenized. In other words, each word included in the heading or category name is associated with a token.
- step 1504 the next record of a category is examined and also tokenized.
- step 1506 a comparison of the two tokenized names is performed to derive a score in accordance with the number of matching name components. This may also be normalized, as described in accordance with the foreign source update processing techniques.
- step 1508 If it is determined at step 1508 that the score is not greater than the threshold, no match is found and control proceeds to step 1510 where the next category is advanced to.
- step 1514 a determination is made as to whether all the categories have been processed in the category file. If they have, control proceeds to step 1516 where processing stops. Otherwise, control proceeds to step 1504 for further comparisons and determinations of equivalent categories.
- the category table or file may be used by the query engine when processing a data query.
- the category file may be used to identify valid categories specified in a user query. It may also be used to categorize information displayed to a user.
- a resulting data set may be partitioned in accordance with the categories as included in business listings for the resulting query. For example, if a resulting data set includes 10 listings, these listings may be categorized or grouped in accordance with whether or not particular categories are associated with each listing. The information displayed to the user for these 10 listing may be 5 listings included in category A, and 5 listings included in category B.
- the category table or file is updated, the table is propagated as part of the update data to the Front End Server and subsequently, further to the query engine.
- An efficient data transfer technique is used to transfer data between databases, such as between the Backoffice component 818 and the Primary Database 812 of FIG. 4 .
- the types of data that are transferred generally relate to advertisements such as those displayed to the user 800 of FIG. 2 .
- advertisement data includes text data and non-text data.
- the non-text data may be referred to as “blob” data which includes, for example, image and audio data, as well as machine-executable programs, JAVA bytecode, and the like.
- the technique which will be described in paragraphs that follow, generally uses different data channels depending on the type of data. For example, text data is transferred from the Backoffice component to the Front End Server 804 using a different data channel than blob data that is also transferred between the two components.
- a sending component may be located within the Backoffice component 818 which includes software that decides the type of data, the channel used to transfer the data, and how to break up the data into portions which are transferred to a receiving component located in the Front End Server 804 , such as the primary database 812 .
- Located on the receiving component, as may be included in the Primary Database 812 is software which decides how to synchronize or assemble data received from the Backoffice component 818 .
- the advertisement data is generally data that is displayed in response to a user query.
- the text data included in this data transfer may be characterized as structured data, as included in text which is displayed to the user.
- the second type of data generally transferred is denoted as “blob” data which is generally not able to be decomposed or operated upon in different portions.
- blob data may include a machine-executable program which is generally binary data type.
- the technique uses two separate data channels in which each channel transfers a different type of data.
- one data channel is used to transfer the text data
- Database LinkTM software as included in the commercially available OracleTM database, is used to facilitate database communication of text data. Therefore the database routines, such as those included in the Database Link software, may be used in transferring text data between databases.
- the Oracle database does not support direct non-text manipulation, such as for transferring data of different types, such as blob data. Therefore, a second different data channel is used to transfer the blob data from one database to another in which the second channel is external to the database since the version of the Oracle database software used in this embodiment does not provide the needed support for direct non-text data manipulation.
- the blob data which may also generally be characterized as multi-media data, is transferred asynchronously from the text data between databases.
- the blob data in this embodiment is copied from one database to another using a C++ program with calls to vendor-supplied library routines.
- This is in contrast to the text data transfer which is done by a separate data channel, and the software used performs remote database copies as if they were local.
- the text data transfer may be performed by calls to the Oracle procedures executed under the control of the Oracle database software.
- the data channels used to transfer both the text and the blob or multi-media data may be network connections between the databases. Other types of connections between the databases may also be possible, such as a dedicated hard line to facilitate database communication, as known to those skilled in the art.
- data is organized and associated with a particular advertisement that may be displayed to a user.
- FIG. 59 is a block diagram of two tables in a preferred embodiment depicting one technique for storing the advertisement data.
- the advertisement data and the relation between the different components of the advertisement data are described in two tables stored in the sending databases.
- Table 1200 is a relational mapping table which generally describes the relation between the various data entities as included in a particular advertisement page.
- the relational mapping data describes a parent/child relationship between various data entities of an advertisement page forming a tree-like structure.
- the data table 1220 includes the actual data as described by the relational mapping table 1200 .
- the data included in the data table 1220 includes a variety of data types as may be displayed with regard to an advertisement.
- the data included in table 1220 may be text data, machine executable code, or a JAVA program.
- one restriction is that each row of the data table 1220 may contain at most one field of blob data.
- an advertisement in this particular embodiment, requires the use of multiple blob files, they must be stored in different rows of the data table 1220 .
- Other implementations and embodiments may have similar or other restrictions that may effect the particular organization of the data as required for advertisements or other data displayed to the user. It should generally be noted that the structure of the tables depicted in FIG. 59 are particular to this implementation and embodiment of the invention. Other embodiments of the invention may include different table structures in accordance with various implementation restrictions.
- the relational mapping table 1200 includes two columns of data.
- the first column 1204 is the record ID of the child data entity.
- the second column 1206 is the record ID of the parent data entity.
- the data table 1220 generally includes multiple columns depending on how many data fields are required for a particular implementation.
- a record identifier 1208 is used to uniquely identify a particular data entity in a table.
- data fields data-l 1210 through data-n 1214 in which each of these data fields includes one particular type of data entity as may be displayed to the user in response to a data query.
- FIG. 60 shown is a more detailed diagram of the tables as used in a data transfer on a sending and receiving side using this data transfer technique.
- Shown in FIG. 60 is an example of a relational mapping table 1200 which includes multiple advertisement pages.
- one tree-like structure is used to represent one advertisement page.
- two tree structures may be produced using the data described in the relational mapping table 1200 .
- What will be described in paragraphs that follow is the data transfer of the advertisement page associated with the root node with the identifier 104 which includes identifiers 104 , 105 and 106 in its tree-like structure.
- FIG. 61 shown is the tree-like structure described by the relational mapping table 1200 for the advertisement page with the root node identifier 104 shown in FIG. 60 .
- the two tables of data on the receiver side depict tables after the transfer of the ad page with the root node of the identifier 101 and prior to the transfer of the data associated with the advertisement page with the root node beginning with the root node of identifier 104 .
- Generally created on the receiver side for each advertisement page is a separate ad page table 1218 .
- the temporary table 1216 is filled with data during the data transfer and after the data is properly assembled on the receiver side, the temporary table 1216 is not used until the next data transfer operation. In this particular embodiment, the table ends in a state such that no data from the data transfer having just occurred is located in the table 1216 .
- each identifier is associated with only blob data.
- this general technique and the data included in the data table 1220 may additionally include text data associated with each identifier or row in the table.
- An entry in the table 1220 may also include only text data.
- the limitation is that only one field entry of blob data may be associated with each row in table 1220 .
- blob data On the receiving side three tables are associated with transferring data which is blob data from the data table 1220 . These three tables include a blob temporary table 1222 , a blob table 1224 and a repository table 1226 . It should generally be noted that any text data included in table 1220 on the sender side may be transferred using the data transfer channel. What is described in FIG. 62 is that portion of the data included in the data table 1220 which is blob data. In this example, only blob data is included in the advertisement page with the root node 104 which will be described.
- the blob temporary table 1222 is a temporary table used in the transfer of text information associated with blobs from the sending node to the receiving node.
- the blob table 1224 in this particular embodiment, is an aggregate blob table which includes the blob data for multiple advertisement pages.
- the snapshot of the data tables of FIG. 62 shows that data associated with one advertisement page with the root node identifier 101 .
- the blob table 1224 will also include information to retrieve the blob data associated with identifiers 104 through 106 . It should be noted that the contents of the blob table 1224 do not include the actual blob data itself.
- the fields included in the blob table 1224 point to and further describe the actual blob data which is contained in the repository table 1226 .
- the blob table 1224 in this embodiment includes three fields per each entry associated with a blob data entity. It includes a sending record identifier 1228 , a size 1230 , and a pointer 1232 to the actual blob data.
- the sending record identifier 1228 identifies a particular blob uniquely within a particular table or advertising page in this particular embodiment. Thus, each of the entries in the record identifier column 1228 may not be unique for all of the advertisement pages or data.
- the purpose of the record identifier is to map or identify the particular blob pointer associated with a unique record identifier from the sending database.
- the size 1230 indicates the size in bytes of the blob described by the blob pointer field 1232 .
- the size field may include other units to identify the size of the particular blob data.
- the blob pointer field 1232 acts as an identifier or pointer into the repository 1226 to uniquely identify within the repository a particular piece of blob data. It should be noted that other embodiments or implementations may include additional fields in the blob table 1224 as well as in the repository 1226 in accordance with other pieces of data that may be required in order to enable the transfer to occur in a particular implementation.
- FIGS. 62 through 66 show the block diagrams of an embodiment of transferring the data associated with an advertisement from the sending side to the receiving side.
- FIG. 63 depicts a snapshot of the tables associated with the text or Database Link transfer channel as included in the sending and receiving sides.
- the data table 1200 on the sending side has no modifications from the previously described initial table as depicted in FIG. 60 .
- the tables on the receiving side have been modified from those previously described in FIG. 60 .
- the temporary table 1216 serves as a temporary placeholder for the data involved in the data transfer of the particular ad page described beginning with root node identifier 104 .
- the data associated with a particular advertisement page is extracted from the relational mapping table 1200 and is temporarily copied to and stored in the temporary table 1216 on the receiving side.
- Shown in FIG. 64 are the tables associated with transferring the actual data from the sending side to the receiving side.
- the data included in the data table 1220 is segregated into text data and non-text data.
- the text data is transferred using the text channel.
- the non-text, multimedia data, or blob data is transferred using an external process which creates a second multimedia data transfer channel in order to send data from the sending side to the receiving side.
- the id and the size fields are copied to the blob temporary table 1222 .
- a global id (Gid) is generated on the sending side prior to transmitting these fields to the receiving side. This global id is transferred to the receiving side and included in each associated entry of the temporary table 1222 .
- the Gid is a unique identifier associated with each record uniquely identifying the record among all tables associated with database information.
- the blob data from table 1202 and the associated information in table 1242 are transferred to an external process 1240 located on the sending side.
- an OracleTM pipe is the communication means used to transfer the data from the data table 1220 to the external process 1240 .
- the external process 1240 further transmits the data via a multimedia data channel to the receiving side.
- Table 1242 may also be viewed as a temporary table which serves as a placeholder for that data which is transferred by the external process 1240 to the receiving side.
- Located in temporary table 1242 are four pieces of information including a table name, a field name, an identifier, and a global identifier associated with each blob data entity.
- the table name generally describes or identifies the particular table within which a piece of blob data is located or associated.
- each table is associated with a particular advertisement or advertisement name.
- the field name identifies the type of non-text data.
- the field name is “Blob” referring to blob or multi-media data.
- the identifier field (Id) of table 1242 is the unique record identifier copied from table 1220 .
- the global identifier (Gid) is a unique global identifier, identical to that which is produced on the sending side prior to sending the text data to the temporary blob table 1222 . This information is passed or transferred to the external process 1240 which copies the actual blob data to the receiving side as well as the additional information described in temporary table 1222 .
- the external process 1240 is a C++ program with library calls to facilitate the transfer of data between the databases.
- this is an external process with regard to the database.
- the facilities used to transfer the data from the sending side to the receiving side are external with respect to the database.
- “external” generally refers to the fact that the external process 1240 executes outside of the Oracle process space. Certain tasks must be performed by the external process in order to transfer the data from the sending side to the receiving side. For example, the external process must connect to each of the databases in order to access and transfer the data. This is in contrast to the Database Link or text channel which is internal to the database and no such connections are implied.
- routines which perform the data transfer of the text are internal to the database and data copying, for example, in this embodiment, is performed between remote databases as if they were local copies.
- the precise way in which both the text and blob data transfers are performed within other preferred embodiments may vary with implementation and facilities available for communication and data transfer.
- the external process may copy blob data from multiple tables in which the associated field name may differ with each table. Therefore, the field name may also be included in table 1242 . The external process uses this field name to retrieve blob data to be copied. Other embodiments may communicate this field name using other mechanisms.
- the external process 1240 uses the data included in the temporary table 1242 to fetch or access the blob data associated with a particular table name and field name to subsequently index into each particular table name using the identifier to extract the actual blob data.
- This blob data is copied to the repository table 1226 on the receiving node by process 1240 .
- the repository table 1226 includes the blob data associated with advertisement identifier 104 . This data is appended to already existing data in the repository 1226 .
- table 1224 includes a blob pointer field which acts as an index into the repository table 1226
- table 1220 includes the actual blob data in a field.
- the use of the blob pointer field in table 1224 which acts as an index into the repository table 1226 performs the same function as the actual data in the blob data field of the data table 1220 .
- FIG. 65 shown is a block diagram of an embodiment of the tables resulting from the text data integration.
- table 1200 on the sending side remains the same as in previously described figures.
- table 1216 data has been integrated and copied into the table 1218 .
- the function of temporary table 1216 is generally to hold that text data associated with the relational mapping table which is transferred from the sending side to the receiving side until all of the data entities associated with the particular advertising page or table being transferred have arrived on the receiving side.
- the software on the receiving side performs a state integration process.
- the previously described task of integrating the data from temporary table 1216 into table 1218 is one such task performed by this integration software.
- FIG. 66 shown is a block diagram of an embodiment of the data table 1220 whose contents have been transferred to the receiving side.
- the assembling software on the receiver side integrates the data from temporary table 1222 into table 1224 . Additionally, a link is established in table 1224 to the data in table 1226 and the associated global identifier removed. Each entry in table 1222 is copied into table 1224 . In particular, the Id and Size fields are copied into table 1224 for identifiers 104 , 105 , and 106 .
- the integration software uses the global Id obtained from temporary table 1222 to index into the repository 1226 in search for a matching global identifier entry.
- table 1226 When a matching global identifier is found in table 1226 , the repository Id from table 1226 is copied into the blob pointer field (Blob Ptr) of table 1224 . Subsequently, the global Id in table 1226 for the corresponding entry is reinitialized to an empty field. The resulting table 1226 shows this process as repeated for each entry in the previously described table 1222 from FIG. 64 .
- FIG. 67 shown are method steps of one embodiment for assembling the blob data into the repository table.
- the steps described in FIG. 67 generalize the method previously described in conjunction with FIGS. 64 and 66 wherein the data shown in FIG. 64 is integrated and assembled into the tables on the receiving side resulting in those as displayed in FIG. 66 .
- the record identifier and table size are copied from the temporary blob table to the blob table.
- the global identifier from the temporary blob table is used as an index into the repository table to finding a matching global identifier.
- the repository identifier is copied from the repository table to the blob pointer field of the blob table.
- the global identifier field of the repository table is reinitialized.
- table 1200 and table 1218 are “mirror images” of each other.
- the temporary table 1216 is used in performing the transfer as a temporary table until all of the data for this particular data transfer has arrived on the receiving side. At that point, the data is integrated from the temporary table into the final resulting table 1218 resulting in a table 1218 which mirrors that on the receiving side which is on the sending side in table 1200 .
- the resulting tables 1224 and 1226 are functionally equivalent to the data described in the sending side in table 1220 .
- one of the reasons for not further merging the data of tables 1224 and 1226 is due to the fact that transferring blob data, including a copy of the blob data from table 1226 to be integrated into table 1224 , requires the use of an external program in order to compress the tables further.
- an external program similar to external program 1240 , is generally used since a version of the database software, as in this embodiment, may not be capable of copying and directly manipulating non-text data as needed in performing data operations.
- the overall technique is generally to copy the text and blob or multi-media data asynchronously on two separate channels.
- This data is copied from a first database to a second database.
- the data is located on the second database in a temporary location until all of the portions of the data associated with a particular data transfer arrive at the second database.
- the assembly process of copying the data from the temporary locations and merging the information into other data tables is performed on the second database.
- the foregoing technique for data transfer may be used in a variety of applications, such as for the data transfer between databases.
- this technique is included in a system for online Interactive Yellow Pages, GTE Superpages for the publication of multimedia advertisement content of GTE Superpages business customers.
- the GTE Superpages system includes two major components: the server component which serves versatile user requests for the information of more than 11 million businesses in the United States and (2) the Backoffice component that facilitates advertisement content, creation management and publication. Both these subsystems include databases where advertisement business information is persistently stored.
- the advertisement content produced or modified in the back office is published in the Superpages by virtue of its transfer from the persistent storage in the back office to the persistent storage in the server.
- the business advertisement includes an integrated set of structured textual information, such as business name, address, and multimedia or blob data, such as graphics, video, audio, job applets.
- the data transfer technique described is generally a technique for transferring data using two data links between two databases.
- One of these data links is an internal data link with respect to the database
- the second data link is an external data link with respect to the database.
- the internal data link is optimized for the structured text data transfer while the external one is optimized for the multimedia data transfer, such as the transference of data stored in binary objects in the database.
- This technique for data transfer generally alleviates the limitations of the existing database technology which does not provide for the transferring of multimedia objects using the internal data link.
- performance and stability are improved over an alternative prior art approach which uses only the external link for transferring both text and multimedia or blob data.
- the transfer technique includes four collaborative processes: a process on a sending component which decomposes data structures and the like into text and non-text components assigning transient tags to the non-text components; two asynchronous transfer processes, one per data type, that each transfer, respectively, text and non-text components to a receiving component; and a process on the receiving component that reassembles transferred data and replaces transient tags with persistent unique tags.
- This technique uses a multimedia data repository cable which is created and maintained in the receiving component, such as the receiving database in this embodiment. Once the data is transferred, the non-text or multimedia data items are stored in this repository with transient tags. Using the transient tags, the reassembly process correlates the text tables with the multimedia objects and replaces them with persistent unique tags, thus leading to the reintegration of the transferred data.
- the previously described technique includes features which provide for efficient decomposition and reassembly of data for efficient data transfer, as between two databases. Additionally, the multimedia repository serves as a vehicle for the reassembly of decomposed data items which are reassembled on a receiving component, such as a receiving database.
- this update technique is used to provide data updates for both native and foreign sources, and on-line updates, as described in accordance with data processing techniques in other sections of this application.
- data updates to the databases included in the Front End Server may first be integrated into the Backoffice component. Subsequently, these data modifications may be “pushed” to the Front End Server and integrated into the various data stores included therein, as will be further described in more detail in following sections.
- data updates may originate from several sources, including native and foreign source updates, and on-line data entry, such as through an Internet connection via a browser.
- the native and foreign source updates may generally be characterized as larger updates or data integration efforts. These are generally described in other sections of this application.
- the on-line data entry technique for updating information that may be included in the Backoffice component may be performed as previously described through the menus initially displayed to a user, such as at the GTE Superpages Internet site, that provide access to the Backoffice component data information.
- the data integration techniques are generally more detailed and involved than the integration of the on-line specified modifications.
- the data updates may generally be a large number of data modifications requiring more computer resources than in the latter case.
- the on-line modifications may be incorporated on a daily or other predetermined time period using some data enhancement techniques as described in other sections of this application.
- Other data updates may require additional time and computer resources and not be able to be completed, for example during non-peak usage, such as overnight on a daily basis.
- additional planning and different processing techniques may be used with the various types and volume of data updates as included each embodiment.
- the data updates including the updates to advertisement data and other data associated with each business listing, may be propagated to the Front End Server component.
- the non-text or multimedia data for example, as included in advertisements with image files, may be transferred to the Front End Server from the Backoffice using multimedia transfer techniques, as generally described in other sections of this description.
- the updates to the Primary Database included in the Front End Server may be communicated as a table of commands created in the Backoffice component and transferred, as by a network connection, to the Front End Server.
- the table created in the Backoffice includes an application developed command language corresponding to the various types of record updates and modifications that may be included in this particular embodiment.
- Each of these commands may be further translated in the Front End Server into one or more actual database commands that perform the table operation.
- an entry in the table of database update commands may be specified as follows:
- a Command field specifies the type of data command.
- the Record # field identifies which records in the Primary Database this command applies.
- the Optional Data includes data that may be related to the specified command. For example, if the command were update, the data field may specify the data which is to be included in the records specified. In the above example, the command is to delete records 1 - 5 .
- This single table command may be translated, for example, by software included in the Primary Database, into 5 database commands in accordance with the particular database software.
- the software which builds the table in the Backoffice and translates the commands into one or more database commands may be developed using a commercially available software system that is capable of communicating with the underlying database to perform the required operations.
- each command may be sent as a separate message in other embodiments in accordance with the number of updates and other associated computer resources and costs for each data transaction. This may vary with implementation.
- the Backoffice data transfer must complete prior to beginning the update to the database in the Front End Server component.
- the Backoffice data transfers is complete when multimedia and text data has been transferred from the Backoffice component, such as data required when updating an advertisement page.
- other information from the Backoffice component is transferred to the Front End Server component 804 , such as in the form of an operational table.
- the operational table may include information about the updated normalized data, which has been applied to the Backoffice component, and which is now to be applied in this incremental update procedure to the Primary Database copy of the normalized data.
- an initialization procedure may be executed to synchronize the beginning of the update procedure for the steps that will be described in paragraphs that follow.
- steps 1604 , 1606 , and 1608 may be performed independently and at the same time as steps 1610 through 1620 .
- the coordinating point labeled DB Prep at step 1622 serves as the coordinating point for the different procedures performed in updating the database on the Primary Database, and the local copies of necessary files, such as the Term list identifiers, located on each of the server nodes.
- the various advertisements are extracted from the data tables, such as those transferred from the Backoffice component in the multimedia and text data transfer.
- the various advertisement pages are packaged and made into a complete advertisement page to be stored in the Constructed Ad Repository 842 .
- the constructed ads are transferred and included in the Constructed Ad Repository. It should be noted that in this embodiment the existing copy of the Constructed Ad Repository is updated in accordance with those particular ads which have changed. Thus, the Constructed Ad Repository is updated on a delta or change basis.
- steps 1610 through 1620 may be performed in conjunction with steps 1604 through 1608 . This may be done, for example, in a parallel fashion. Steps 1610 through 1620 indicate that process by which the various identifiers and other files associated with the Primary and Secondary database are updated. Steps 1604 through 1608 reflect the updating of the Constructed Ad Repository 842 on an as needed basis in accordance with changes which have occurred in the advertisements.
- step 1610 various changes to the Term lists identifiers are extracted. In other words, it is determined at step 1610 what identifiers in the Term lists need to be updated in accordance with the changes transferred from the Backoffice component. This is described in more detail in paragraphs that follow.
- these various identifier updates are packaged.
- these various identifier changes are transferred to each of the server nodes. In this embodiment, the actual data transferred at step 1614 are the raw operational commands as may be supplied by the Backoffice component to be applied to the existing Term lists.
- step 1616 at each node, a working copy is made of the existing Term lists.
- the changes are made to the working copy local to each server node.
- the updated term list is installed.
- the updated term list is not yet available for public use in the sense that it is published.
- a new version of the Term lists has been created which includes the updated information as supplied in the transfer step 1614 .
- Step 1622 database preparation steps are performed.
- Step 1622 serves several purposes. One is a coordination point for the updates of the various ads, as well as the various term list identifiers.
- step 1622 serves as a step within which the normalized Primary Database information is propagated from the normalized copy of the Primary Database to a denormalized form in the Primary database and the denormalized form in the Secondary Database. In other words, the changes which are transmitted from the Backoffice component and reflected in the normalized Primary Database copy are now further propagated to the denormalized Primary database and the denormalized Secondary database copy.
- the validity of the transactions and updates are verified such that at step 1626 the database knows it may fully commit to performing the update to the denormalized copies as used in performing user queries.
- Steps 1624 , and 1630 , and, respectively, step 1626 may be performed in parallel.
- the ads may actually be published as in step 1624 in which the updated copies of the Constructed Ad Repository are actually made available for use. Additionally, any updated images as stored in the Image Repository are also available for use.
- the previously installed identifiers included in the Term lists, as installed in step 1620 are published in step 1630 .
- the publication of the various identifiers included in the Term lists generally means that the Term lists are available for use, as by the Query Engine.
- the database commits to performing the update.
- steps 1614 through 1620 are performed independently for each server node in this embodiment. Additionally, the actual amount of processing performed on the Term lists varies in accordance with the number of updates or transactions, as will be described in conjunction with FIG. 32 .
- THRESHOLD 1 describes a relatively small number of transactions.
- a relatively small number of updates generally refers to less than 30,000 update transactions.
- THRESHOLD 2 value which generally represents a second, larger number of transactions.
- THRESHOLD 2 represents approximately half a million transactions or update entries which corresponds to approximately five to ten percent of the number of records included in the Primary Database.
- step 1636 the normalized Primary Database is updated. Generally, this is performed at step 1602 of FIG. 31 in which the copy of the normalized Primary Database is updated in accordance with the operational table as transferred from the Backoffice component indicating the actual database update operations.
- step 1638 due to a relatively small number of transactions required, the actual identifiers of the Term lists are updated. In other words, the Term lists are updated as opposed to being rebuilt.
- steps 1640 and 1642 are executed.
- the Primary Database is updated, as previously described in conjunction with step 1602 in which the normalized copy of the Primary Database is updated.
- all of the identifiers as included in the Term lists are rebuilt. In this particular embodiment, both identifiers and markup files are rebuilt due to the use of the mark-up files by the Verity Information Retrieval software. As previously described in conjunction with FIG.
- step 1642 the Information Retrieval software is executed to produce entire new sets of the Term lists. Step 1642 is in contrast to step 1638 . Rather than rebuild the Term lists as in step 1642 , the Term lists are updated in step 1638 .
- step 1634 If a determination is made at step 1634 that the number of update transactions is greater than or equal to the larger threshold, THRESHOLD 2 , step 1644 is executed. At this point, a determination has been made that the number of update transactions is so large that it has been deemed more efficient to rebuild the entire database and associated files, rather than update or patch the existing database and associated files, as in updating the identifiers of the Term lists of step 1638 .
- the previously described procedure of performing a multimedia data transfer is used to transfer, for example, the multimedia and text data associated with ads, as may be included in the Constructed Ad Repository 642 and Image Repository 842 of FIG. 4 .
- the granularity which indicates that an advertisement page has changed requiring the entire advertisement page to be replaced in the Constructed Ad Repository is if a single component within an ad page has changed. In this case, the entire ad page is reconstructed and replaced in the Constructed Ad Repository 842 .
- a different granularity of change may be used.
- the various markup files and Term lists are built as needed in accordance with the number of transactions as described in conjunction with FIG. 32 .
- the actual threshold values may be determined in accordance with tuning of a particular system and the size of the database the number of transactions in each particular system.
- the database as included in both the Front End Server and the Backoffice component are OracleTM databases.
- the OracleTM procedural language, PL/SQL may be used to read the operational table and perform the updates as needed to the normalized form of the data as stored in the Primary Database included in the Front End Server component.
- the same procedural language in files may also used to update the denormalized Primary Database copy and the denormalized form of the data as stored in the Secondary Database.
- Other embodiments may employ other techniques to update both the Primary and Secondary databases in accordance with a particular implementation.
- the previously described incremental update procedure is one that is generally used to perform daily updates.
- the same procedure may be used on a larger time period of transactions or updates. Due to the volume and size of the previously described embodiment, this procedure is one which performs well when performed on a daily basis. For other systems which may perform a similar number of transactions for a larger time period, the previously described techniques may also be used.
- the various updates to a particular record or for a particular business or service may be collapsed before actually issuing the various database commands to perform the updates.
- a certain amount of time such as within five hours, a single record may be inserted, deleted and modified dozens of times. The end result of these modifications for the small time interval may result in no net modification or amendment to a particular record.
- one optimization as may be included in the Backoffice component in a preferred embodiment, may collapse various updates associated with a particular record or business before actually issuing commands which perform a database update as applied to the copies in the Backoffice 818 and Front End Server 804 components.
- this may be determined by using a finite state machine with the states of “insert”, “delete”, and “modify”. If the same record, for example, is modified twice and then deleted, the net result is that only a “delete” database command should be issued rather than issue two updates followed by a delete.
- the contents of the Page Cache 848 and the Query Cache 850 are reinitialized when an update is performed, as in performing the incremental update procedures described in conjunction with FIGS. 31 and 32.
- the data included in the PHTML execution tree is also reinitialized.
- a failure may occur when performing any of the steps associated with FIGS. 31 and 32. If a failure occurs when performing certain steps, then a recovery procedure may be performed. In this particular embodiment, a failure may occur for example, when using the Information Retrieval software, as depicted in conjunction with FIG. 25 . This may be due, for example, to a problem, such as a software bug, with the Information Retrieval software 908 . For example, an error may occur when extracting the identifiers associated with step 1610 . Generally, step 1610 as previously described includes building the Term lists as determined in accordance with the number of update transactions in accordance with FIG. 32 .
- an error may be a recoverable error if another node has successfully built the identifier files, for example.
- a recovery procedure may be to copy the updated version of the Term lists from one node to another node which has been unsuccessful in the building the Term lists. This copy may occur, for example, after a predetermined number of builds of the Term lists on a particular node have failed. In this particular embodiment, this has been determined to be a recoverable error with which an alternative step or technique may be applied to also achieve the end result of the updated Term lists.
- Other embodiments of the invention may also include other alternative techniques in accordance with those steps associated with a particular system which it determines to be recoverable.
- the update techniques may be included in a distributed computing system having multiple data representations as stored in a plurality of server nodes.
- the foregoing techniques provide for synchronized updates of the various data stores in the plurality of server nodes.
- User query information may be used to influence the displays shown to the user by the browser 824 .
- the information retrieval software 908 can be used to assist in selecting other information to be displayed to the user, based on the nature of the user's query.
- a banner ad 50 can be displayed to the user. Based on the user's query, the banner ad 50 may be targeted to characteristics of the user that are inferred from the user's query. For example, an advertiser might conclude that a user who has entered a query with the category “art supplies” is interested in art, so that an advertisement for an art show or related matter would be an appropriate banner ad 50 .
- Banner ads 50 can also be targeted geographically, so that ads for businesses from a selected geographical area can be associated with search queries that include that geographical area as a search term.
- a system for targeting banner ads using user queries can use a range of information retrieval techniques, such as the Verity techniques described above in connection with processing of information retrieval requests using the term lists 836 .
- a separate banner ad retrieval program 909 is part of the query engine 862 .
- Initialization steps that permit execution of a banner ad retrieval program 909 are set forth in a flow chart 52 on FIG. 68 .
- the system initiates the banner ad retrieval software 909 .
- the banner ad retrieval software 909 in a manner similar to the information retrieval software 908 , uses extraction routines to access markup language files and extract data.
- the banner ad retrieval software then generates banner ad term lists 837 .
- the banner ad retrieval software retrieves a list of all yellow pages categories.
- the categories are all of the available categories of business listings, such as all available yellow pages categories.
- the system establishes a set of super-categories.
- the super-categories may consist of a sub-set of the categories, or other categories.
- the system may map categories to super categories in a step 70 .
- the mapping at the step 70 many be a many-to-many mapping.
- a variety of techniques may be used to map categories to super-categories. One such technique uses a combination of automatic and manual mapping. Steps for accomplishing such a technique are set forth in a flow chart 73 depicted in FIG. 69 .
- a step 104 it is determined for a first yellow pages category whether the category is to be manually assigned. If so, then at a step 106 the category is assigned to a super-category. This may be accomplished by user input in a conventional form.
- a step 108 it is determined whether any unassigned categories remain. If at the step 108 additional categories remain, then control returns to the step 104 , where it is determined whether the next category is to be manually assigned. If at the step 108 no categories remain to be assigned, then control is control is returned, as represented by off-page connector B, to the flow chart 52 of FIG. 68 .
- step 104 it is determined that the category will not be assigned manually, then it is determined, at a step 110 , whether there remain any additional categories to be assigned. If so, then at a step 112 , the category is skipped and processing proceeds to the next category at the step 104 . Thus, all categories that are to be assigned manually may be assigned prior to automatic assignment of categories.
- step 110 If at the step 110 it is determined that no additional categories exist, then all categories to be assigned manually have been assigned, and control proceeds to a step 114 , where the system returns to the first category that was not manually assigned, and it is determined whether the category will be assigned automatically based on the manual assignments. If at the step 114 it is determined that the category will be assigned automatically based on the manual assignments, then, at a step 116 , the system may compare terms that appear in the category to terms that appear in each of the manually assigned categories. The system may thus obtain a ranking of the manually assigned categories in order of the degree of co-occurrence of terms. Next, at a step 118 , the system may assign the same super-category as was assigned the highest-ranked of the manually assigned categories.
- the system may determine whether there are any additional categories. If not, then control passes, as depicted by off-page connector B, to the flow chart 52 of FIG. 68 . If additional categories remain, then control proceeds to the step 114 for the next category.
- step 114 If at the step 114 for a particular category it is determined that a category will not be automatically assigned based on the manual assignments, then at a step 122 a determination is made whether additional categories remain to be assigned. If so, then at a step 124 processing skips to the next category and control is returned to the step 114 for the next category.
- all categories that are to be automatically assigned based on the manual assignments may be completed at the steps 115 through 118 before control proceeds to the step 126 .
- processing returns to the first remaining category that was not previously assigned.
- the system may determine certain statistics regarding the co-occurrence of terms between the category and one of the super-categories (perhaps also including the terms in the categories assigned to the super-categories). A variety of co-occurrence techniques can be used.
- the system may assign the category to the super-category for which the highest co-occurrence is found.
- it is determined whether additional categories remain to be assigned If not, then control proceeds, represented by off-page connector B, to the flow chart 52 of FIG. 68 . If so, then control proceeds to the step 126 for processing of the next un-assigned category.
- an embodiment of a technique for mapping categories to super-categories is disclosed herein, it should be understood that other techniques are available. For example, manual mapping could be executed after all automatic mapping is completed, or the system could rely entirely on automatic mapping.
- the banner ad retrieval software 909 may index the various super-categories in a banner ad term list 837 .
- the banner ad term list 837 may take the form of a linked list of the super-categories, with each element in the list consisting of all of the terms that appear in the super-category, as well as all of the terms that appear in each of the categories that was matched to the super-category. It should be understood that these terms may be expanded, as described in connection with FIG. 40 above, so that synonyms and related terms are also stored with each super-category element. Storage of these terms may be in a hierarchical structure that is capable of execution using PHTML scripts or similar techniques.
- the system may match one or more banner advertisements to each super-category. Thus, if that super-category is found to be the appropriate super-category, the matching banner ad or ads will be displayed.
- the system may generate a banner ad for display to the user.
- the banner ads may be stored on a server, which in an embodiment is a separate banner ad server 809 .
- the banner ads may be either conventional banner ads or targeted banner ads.
- the banner ad server 809 may store the banner ads in a conventional manner and cycle between different ads according to a predetermined routine, such as a round-robin routine, so that when the system calls for a banner ad (such as via an appropriate URL for the banner ad server), the current banner ad is sent to the front end server 804 for further processing and display to the user in a banner on the user's browser 824 .
- the banner ad retrieval software 909 may be initiated. Steps that may accomplished by an embodiment of the banner ad retrieval software 909 are depicted in a flow chart 132 as shown in FIG. 70 .
- the banner ad retrieval software 909 obtains the user's query.
- the banner ad retrieval software obtains the categories that match the user's query. These categories may be the categories that are obtained by the information retrieval software 909 in response to a user query. For example, if the user enters a query for “art supplies,” as depicted in FIG.
- the user might retrieve a list of matching categories, such as the eight matching categories depicted in FIG. 44 .
- the categories are those that were displayed as a results page in the flow chart 88 at the step 102 in FIG. 41 . That is, the categories are yellow pages categories of each of the business listings retrieved in the information retrieval query that was executed by the system.
- a variety of techniques could in theory be used to identify a banner ad for the category. For example, an advertisement could be assigned to each category.
- an advertisement could be assigned to each category.
- the category “Arts & Crafts” could be assigned a particular banner ad (or set of scrolling banner ads), while the category “Artists Materials & Supplies” could be assigned a different banner ad or ads.
- This approach presents a number of problems. First, the number of actual yellow pages categories is very large, more than seventeen thousand in an embodiment of the system disclosed herein, so that the process of assigning ads to categories on a one-to-one basis would be extremely time consuming and laborious.
- advertisements often include time-sensitive material, they are changed frequently, meaning that the ongoing process of assigning ads to category could be very difficult. Since many of the categories are quite similar to each other, as in the above example of “Arts & Crafts” and “Artists Materials & Supplies” it is instead preferable to assign ads to super-categories, as was disclosed in connection with FIG. 68 .
- Another problem with an approach of matching advertisements directly to categories is that additional information about the user's preferences may be available from the user query.
- a system that relies only on the categories ignores any information from the user query that might permit further refinement of the advertisement selection.
- the banner ad retrieval software 909 may be weighted or normalized by the number of occurrences of the terms and the number of listings in which a term occurs in a step 74 .
- the banner ad retrieval software 909 may locate the particular terms that appear in the user query and in the categories obtained at the steps 60 and 62 in the banner ad term lists 837 .
- Location of a relevant term list 837 may be accomplished through use of a table of pointers or other conventional technique.
- the argument of the table may consist of a tokenized version of the term and the table may point to the location of the linked term list 837 for that term in the database that stores the banner ad term lists 837 .
- a structure for a linked banner ad term list 837 is depicted, in which a linked list of super-categories is depicted.
- One linked list may be established for each term that appears in a user's query or in a category, such as a yellow pages category, retrieved by the information retrieval software 909 .
- a linked list 837 of super-categories was established at the initialization step 77 depicted in the flow chart 52 of FIG. 68 .
- the linked list may link elements 74 , with each element 74 corresponding to a document (a document in this case consisting of all of the words in a particular super-category, plus all words in the categories mapped to the super-category) that includes the term.
- the elements 74 may include sub-elements, including a document identifier 76 for identifying the category and certain statistics regarding the document, including the term frequency 78 , TF, which indicates the number of times the term appears in the document, and the inverse document frequency 80 , IDF, which indicates the inverse of the number of times the term appears in the entire set of documents that are being searched.
- the banner ad retrieval software 909 may at a step 81 rank the super-categories.
- the system at the step 81 may rank the documents, i.e., the super-categories, according to the appearance of the words occurring in the user query and in the categories.
- the ranking may be performed by a variety of techniques.
- One such technique obtains a number for each term that appears in the user query and in the categories that consists of the product of the term frequency for that term and the inverse document frequency for that term.
- the sum of all the resulting numbers may be calculated for all super-categories, and the super-category with the highest sum may be the highest ranked document.
- the banner ad that was assigned to that highest ranked super-category at the step 72 of the flow chart 52 can then be displayed upon completion of the ranking step 81 of the flow chart 132 .
- IDF log ( N ⁇ IDF t )/log ( N )
- N is the number of documents in the document set and IDF is raw inverse document frequency number.
- TF term frequency
- TF is the raw frequency of a term in a document
- DL is the length of the document
- ADL is the average length of a document in the search.
- each category is given a weight corresponding to the number of listings that are associated with the category, normalized by dividing the total number of listings.
- the user query terms are each given a weight of one.
- the weight may be multiplied by the term element in performing the sum of the product of term frequency and inverse document frequency over all terms for all documents in the super-category linked list.
- the highest ranked super-category is selected, and a banner ad that was assigned to that super-category at the step 72 of the flow chart 52 of FIG. 68 is selected.
- the banner ad may be retrieved, such as via a URL, from the banner ad server 809 , for display to the user via the browser 824 .
Abstract
Description
DOMAIN | SERVER | |
MA | ||
1 | 1000 | |
|
1 | 2000 |
|
2 | 4000 |
Claims (24)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US10/135,344 US6578056B1 (en) | 1999-03-31 | 2002-04-30 | Efficient data transfer mechanism for synchronization of multi-media databases |
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US09/283,816 US6421683B1 (en) | 1999-03-31 | 1999-03-31 | Method and product for performing data transfer in a computer system |
US10/135,344 US6578056B1 (en) | 1999-03-31 | 2002-04-30 | Efficient data transfer mechanism for synchronization of multi-media databases |
Related Parent Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US09/283,816 Continuation US6421683B1 (en) | 1999-03-31 | 1999-03-31 | Method and product for performing data transfer in a computer system |
Publications (1)
Publication Number | Publication Date |
---|---|
US6578056B1 true US6578056B1 (en) | 2003-06-10 |
Family
ID=23087680
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US09/283,816 Expired - Lifetime US6421683B1 (en) | 1999-03-31 | 1999-03-31 | Method and product for performing data transfer in a computer system |
US10/135,344 Expired - Lifetime US6578056B1 (en) | 1999-03-31 | 2002-04-30 | Efficient data transfer mechanism for synchronization of multi-media databases |
Family Applications Before (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US09/283,816 Expired - Lifetime US6421683B1 (en) | 1999-03-31 | 1999-03-31 | Method and product for performing data transfer in a computer system |
Country Status (1)
Country | Link |
---|---|
US (2) | US6421683B1 (en) |
Cited By (54)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20030004943A1 (en) * | 2001-06-27 | 2003-01-02 | Hitachi, Ltd. | Method of relating information systems |
US20030022665A1 (en) * | 2001-07-26 | 2003-01-30 | Gowri Rajaram | System and method for organizing field upgradable wireless communication device software |
US20030120628A1 (en) * | 2001-12-21 | 2003-06-26 | International Business Machines Corporation | Decentralized many-to-many relationship management in an object persistence management system |
US20030191693A1 (en) * | 2002-04-08 | 2003-10-09 | Itamar Aphek | System and method for conducting an advertising business |
US6718351B2 (en) * | 2000-10-31 | 2004-04-06 | Hewlett-Packard Development Company, L.P. | Electronic record storage |
US20040122841A1 (en) * | 2002-12-19 | 2004-06-24 | Ford Motor Company | Method and system for evaluating intellectual property |
US20040214560A1 (en) * | 2001-07-26 | 2004-10-28 | Kyocera Wireless Corp. | Modular software components for wireless communication devices |
US20040214561A1 (en) * | 2001-07-26 | 2004-10-28 | Kyocera Wireless Corp. | Dynamic interface software for wireless communication devices |
US6826559B1 (en) * | 1999-03-31 | 2004-11-30 | Verizon Laboratories Inc. | Hybrid category mapping for on-line query tool |
US20050064847A1 (en) * | 2001-07-26 | 2005-03-24 | Bilhan Kirbas | System and method for over the air area code update |
US20050071389A1 (en) * | 2003-09-29 | 2005-03-31 | International Business Machines Corporation | High availability data replication of smart large objects |
US20050086104A1 (en) * | 2003-10-17 | 2005-04-21 | Mcfadden Jeffrey A. | Delivery of advertising to telephone users |
US20050097513A1 (en) * | 2003-10-29 | 2005-05-05 | International Business Machines Corporation | Method and system for archiving and retrieving a markup language document |
US20050108325A1 (en) * | 1999-07-30 | 2005-05-19 | Ponte Jay M. | Page aggregation for Web sites |
US20050216478A1 (en) * | 2000-05-08 | 2005-09-29 | Verizon Laboratories Inc. | Techniques for web site integration |
US20050245248A1 (en) * | 2001-07-26 | 2005-11-03 | Gowri Rajaram | System and method for field diagnosis of wireless communications device system software |
US20060004806A1 (en) * | 2004-06-01 | 2006-01-05 | Kraft Frank M | Updating data in a multi-system network that utilizes asynchronous message transfer |
US20060063519A1 (en) * | 2001-08-10 | 2006-03-23 | Gowri Rajaram | System and method for peer-to-peer handset communication |
US7024416B1 (en) * | 1999-03-31 | 2006-04-04 | Verizon Laboratories Inc. | Semi-automatic index term augmentation in document retrieval |
US20060155703A1 (en) * | 2005-01-10 | 2006-07-13 | Xerox Corporation | Method and apparatus for detecting a table of contents and reference determination |
US20060223517A1 (en) * | 2001-07-26 | 2006-10-05 | Kyocera Wireless Corp. | Field downloading of wireless device software |
US20070005576A1 (en) * | 2005-06-29 | 2007-01-04 | Microsoft Corporation | Search engine user interface |
US7197302B2 (en) | 2001-07-26 | 2007-03-27 | Kyocera Wireless Corp. | System and method for interchangeable modular hardware components for wireless communication devices |
US20070099637A1 (en) * | 2005-10-31 | 2007-05-03 | Microsoft Corporation | Voice instant messaging between mobile and computing devices |
US20070115917A1 (en) * | 2005-10-31 | 2007-05-24 | Microsoft Corporation | MTOM data transfer via TCP |
US20070135836A1 (en) * | 2005-12-14 | 2007-06-14 | Mcewen James A | Low-cost disposable tourniquet cuff |
US7254386B2 (en) | 2001-08-10 | 2007-08-07 | Kyocera Wireless Corp. | System and method for improved security in handset reprovisioning and reprogramming |
US20070192348A1 (en) * | 2001-04-14 | 2007-08-16 | Robert Brodersen | Data adapter |
US20070239648A1 (en) * | 2006-03-20 | 2007-10-11 | Microsoft Corporation | Adaptive engine for processing geographic data |
US20070276920A1 (en) * | 2006-05-12 | 2007-11-29 | Daniel Buchmann | Consistency of routing rules in distributed system landscapes |
US7331058B1 (en) * | 1999-12-16 | 2008-02-12 | International Business Machines Corporation | Distributed data structures for authorization and access control for computing resources |
US7383289B2 (en) | 2003-12-02 | 2008-06-03 | Sap Aktiengesellschaft | Updating and maintaining data in a multi-system network using asynchronous message transfer |
US7386846B2 (en) | 2001-07-26 | 2008-06-10 | Kyocera Wireless Corp. | System and method for the management of wireless communications device system software downloads in the field |
US20080140763A1 (en) * | 2002-10-08 | 2008-06-12 | Greg Gershman | Coordination of data received from one or more sources over one or more channels into a single context |
US20090030901A1 (en) * | 2007-07-23 | 2009-01-29 | Agere Systems Inc. | Systems and methods for fax based directed communications |
US7725424B1 (en) | 1999-03-31 | 2010-05-25 | Verizon Laboratories Inc. | Use of generalized term frequency scores in information retrieval systems |
US7899796B1 (en) * | 2004-11-23 | 2011-03-01 | Andrew Borthwick | Batch automated blocking and record matching |
US20110153615A1 (en) * | 2008-07-30 | 2011-06-23 | Hironori Mizuguchi | Data classifier system, data classifier method and data classifier program |
US20110264692A1 (en) * | 2010-04-23 | 2011-10-27 | MobileRealtyApps.com, LLC | System for searching property listings based on location |
US8275661B1 (en) | 1999-03-31 | 2012-09-25 | Verizon Corporate Services Group Inc. | Targeted banner advertisements |
US20120317642A1 (en) * | 2011-06-09 | 2012-12-13 | Barracuda Networks, Inc. | Parallel Tracing Apparatus For Malicious Websites |
US8392472B1 (en) * | 2009-11-05 | 2013-03-05 | Adobe Systems Incorporated | Auto-classification of PDF forms by dynamically defining a taxonomy and vocabulary from PDF form fields |
US8479180B2 (en) | 2001-07-26 | 2013-07-02 | Kyocera Corporation | Maintenance of over the air upgradeable wireless communication device software |
US8572069B2 (en) | 1999-03-31 | 2013-10-29 | Apple Inc. | Semi-automatic index term augmentation in document retrieval |
US8645399B2 (en) | 2012-01-03 | 2014-02-04 | Intelius Inc. | Dynamic record blocking |
US8650307B2 (en) | 2001-09-17 | 2014-02-11 | Michael J. Miller | System for automated device-to-device transfer |
US8655883B1 (en) * | 2011-09-27 | 2014-02-18 | Google Inc. | Automatic detection of similar business updates by using similarity to past rejected updates |
US8825869B2 (en) | 2000-11-13 | 2014-09-02 | Roussillon Llc | Method and system for deploying content to wireless devices |
CN104881450A (en) * | 2005-10-20 | 2015-09-02 | 甲骨文国际公司 | Managing Relationships Between Resources Stored Within A Repository |
US9361367B2 (en) | 2008-07-30 | 2016-06-07 | Nec Corporation | Data classifier system, data classifier method and data classifier program |
US9554268B2 (en) | 2001-07-26 | 2017-01-24 | Kyocera Corporation | System and method for updating persistent data in a wireless communications device |
US10579442B2 (en) | 2012-12-14 | 2020-03-03 | Microsoft Technology Licensing, Llc | Inversion-of-control component service models for virtual environments |
US10628396B1 (en) * | 2005-11-23 | 2020-04-21 | Open Invention Network Llc | Batch automated blocking and record matching |
US11126609B2 (en) * | 2015-08-24 | 2021-09-21 | Palantir Technologies Inc. | Feature clustering of users, user correlation database access, and user interface generation system |
Families Citing this family (46)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6393415B1 (en) * | 1999-03-31 | 2002-05-21 | Verizon Laboratories Inc. | Adaptive partitioning techniques in performing query requests and request routing |
US7539628B2 (en) | 2000-03-21 | 2009-05-26 | Bennett James D | Online purchasing system supporting buyer affordability screening |
US20040122731A1 (en) * | 1999-09-23 | 2004-06-24 | Mannik Peeter Todd | System and method for using interactive electronic representations of objects |
US8429005B2 (en) | 1999-09-23 | 2013-04-23 | Activ8Now, Llc | Method for determining effectiveness of display of objects in advertising images |
AU1953401A (en) * | 1999-12-07 | 2001-06-18 | Actioneer, Inc. | A method and apparatus for receiving information in response to a request from an email client |
US7428500B1 (en) | 2000-03-30 | 2008-09-23 | Amazon. Com, Inc. | Automatically identifying similar purchasing opportunities |
US6708162B1 (en) * | 2000-05-08 | 2004-03-16 | Microsoft Corporation | Method and system for unifying search strategy and sharing search output data across multiple program modules |
US6681298B1 (en) * | 2000-07-12 | 2004-01-20 | Powertv, Inc. | Hypertext markup language cache system and method |
US7213069B2 (en) * | 2001-02-28 | 2007-05-01 | Microsoft Corporation | Category name service able to override the category name based on requestor privilege information |
US7716141B2 (en) * | 2002-02-22 | 2010-05-11 | Dun And Bradstreet Corporation | Method for providing an industry report |
US7107280B2 (en) * | 2002-05-14 | 2006-09-12 | Haestad Methods, Inc. | Method and system for the storage and use of engineering modeling alternatives with unitized data |
US20040133441A1 (en) * | 2002-09-04 | 2004-07-08 | Jeffrey Brady | Method and program for transferring information from an application |
US7617154B1 (en) | 2003-06-09 | 2009-11-10 | Legal Systems Holding Company | Ensuring the accurateness and currentness of information provided by the submitter of an electronic invoice throughout the life of a matter |
US9767435B1 (en) | 2003-06-09 | 2017-09-19 | Thomson Reuters Global Resources | Ensuring the entry of certain data in a matter management system by leveraging another process |
US8108428B1 (en) | 2004-11-30 | 2012-01-31 | Legal Systems Holding Company | Vendor/client information system architecture |
US8140499B2 (en) * | 2005-04-08 | 2012-03-20 | International Business Machines Corporation | Context based cache infrastructure to enable subset query over a cached object |
US7519776B2 (en) * | 2005-07-26 | 2009-04-14 | Invensys Systems, Inc. | Method and system for time-weighted cache management |
US7908190B2 (en) * | 2005-08-30 | 2011-03-15 | Sap Ag | Systems and methods for applying tax legislation |
US7822749B2 (en) * | 2005-11-28 | 2010-10-26 | Commvault Systems, Inc. | Systems and methods for classifying and transferring information in a storage network |
US7801864B2 (en) * | 2005-11-28 | 2010-09-21 | Commvault Systems, Inc. | Systems and methods for using metadata to enhance data identification operations |
US8930496B2 (en) | 2005-12-19 | 2015-01-06 | Commvault Systems, Inc. | Systems and methods of unified reconstruction in storage systems |
US20200257596A1 (en) | 2005-12-19 | 2020-08-13 | Commvault Systems, Inc. | Systems and methods of unified reconstruction in storage systems |
JP2007188352A (en) * | 2006-01-13 | 2007-07-26 | National Institute Of Information & Communication Technology | Page reranking apparatus, and page reranking program |
US8676785B2 (en) * | 2006-04-06 | 2014-03-18 | Teradata Us, Inc. | Translator of statistical language programs into SQL |
US7676492B2 (en) * | 2006-04-07 | 2010-03-09 | International Business Machines Corporation | Migration of database using serialized objects |
US7882077B2 (en) * | 2006-10-17 | 2011-02-01 | Commvault Systems, Inc. | Method and system for offline indexing of content and classifying stored data |
US8370442B2 (en) | 2008-08-29 | 2013-02-05 | Commvault Systems, Inc. | Method and system for leveraging identified changes to a mail server |
US20080228771A1 (en) | 2006-12-22 | 2008-09-18 | Commvault Systems, Inc. | Method and system for searching stored data |
US8095618B2 (en) * | 2007-03-30 | 2012-01-10 | Microsoft Corporation | In-memory caching of shared customizable multi-tenant data |
EP1986109A1 (en) * | 2007-04-26 | 2008-10-29 | Hewlett-Packard Development Company, L.P. | Obtaining feedback for an accessed information item |
US7836174B2 (en) | 2008-01-30 | 2010-11-16 | Commvault Systems, Inc. | Systems and methods for grid-based data scanning |
US8296301B2 (en) | 2008-01-30 | 2012-10-23 | Commvault Systems, Inc. | Systems and methods for probabilistic data classification |
WO2011082113A1 (en) | 2009-12-31 | 2011-07-07 | Commvault Systems, Inc. | Asynchronous methods of data classification using change journals and other data structures |
US8504419B2 (en) * | 2010-05-28 | 2013-08-06 | Apple Inc. | Network-based targeted content delivery based on queue adjustment factors calculated using the weighted combination of overall rank, context, and covariance scores for an invitational content item |
US8954425B2 (en) * | 2010-06-08 | 2015-02-10 | Microsoft Corporation | Snippet extraction and ranking |
US8458115B2 (en) | 2010-06-08 | 2013-06-04 | Microsoft Corporation | Mining topic-related aspects from user generated content |
US8719264B2 (en) | 2011-03-31 | 2014-05-06 | Commvault Systems, Inc. | Creating secondary copies of data based on searches for content |
US8892523B2 (en) | 2012-06-08 | 2014-11-18 | Commvault Systems, Inc. | Auto summarization of content |
US10540516B2 (en) | 2016-10-13 | 2020-01-21 | Commvault Systems, Inc. | Data protection within an unsecured storage environment |
US10922189B2 (en) | 2016-11-02 | 2021-02-16 | Commvault Systems, Inc. | Historical network data-based scanning thread generation |
US10389810B2 (en) | 2016-11-02 | 2019-08-20 | Commvault Systems, Inc. | Multi-threaded scanning of distributed file systems |
US10984041B2 (en) | 2017-05-11 | 2021-04-20 | Commvault Systems, Inc. | Natural language processing integrated with database and data storage management |
US10642886B2 (en) | 2018-02-14 | 2020-05-05 | Commvault Systems, Inc. | Targeted search of backup data using facial recognition |
US11159469B2 (en) | 2018-09-12 | 2021-10-26 | Commvault Systems, Inc. | Using machine learning to modify presentation of mailbox objects |
US10922229B2 (en) | 2019-03-11 | 2021-02-16 | Microsoft Technology Licensing, Llc | In-memory normalization of cached objects to reduce cache memory footprint |
US11494417B2 (en) | 2020-08-07 | 2022-11-08 | Commvault Systems, Inc. | Automated email classification in an information management system |
Citations (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5734887A (en) | 1995-09-29 | 1998-03-31 | International Business Machines Corporation | Method and apparatus for logical data access to a physical relational database |
US5809261A (en) * | 1995-11-20 | 1998-09-15 | Advanced Micro Devices, Inc. | System and method for transferring data streams simultaneously on multiple buses in a computer system |
-
1999
- 1999-03-31 US US09/283,816 patent/US6421683B1/en not_active Expired - Lifetime
-
2002
- 2002-04-30 US US10/135,344 patent/US6578056B1/en not_active Expired - Lifetime
Patent Citations (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5734887A (en) | 1995-09-29 | 1998-03-31 | International Business Machines Corporation | Method and apparatus for logical data access to a physical relational database |
US5809261A (en) * | 1995-11-20 | 1998-09-15 | Advanced Micro Devices, Inc. | System and method for transferring data streams simultaneously on multiple buses in a computer system |
Cited By (91)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7725424B1 (en) | 1999-03-31 | 2010-05-25 | Verizon Laboratories Inc. | Use of generalized term frequency scores in information retrieval systems |
US8095533B1 (en) | 1999-03-31 | 2012-01-10 | Apple Inc. | Automatic index term augmentation in document retrieval |
US9275130B2 (en) | 1999-03-31 | 2016-03-01 | Apple Inc. | Semi-automatic index term augmentation in document retrieval |
US8275661B1 (en) | 1999-03-31 | 2012-09-25 | Verizon Corporate Services Group Inc. | Targeted banner advertisements |
US8572069B2 (en) | 1999-03-31 | 2013-10-29 | Apple Inc. | Semi-automatic index term augmentation in document retrieval |
US6826559B1 (en) * | 1999-03-31 | 2004-11-30 | Verizon Laboratories Inc. | Hybrid category mapping for on-line query tool |
US7024416B1 (en) * | 1999-03-31 | 2006-04-04 | Verizon Laboratories Inc. | Semi-automatic index term augmentation in document retrieval |
US20050108325A1 (en) * | 1999-07-30 | 2005-05-19 | Ponte Jay M. | Page aggregation for Web sites |
US8244795B2 (en) | 1999-07-30 | 2012-08-14 | Verizon Laboratories Inc. | Page aggregation for web sites |
US7331058B1 (en) * | 1999-12-16 | 2008-02-12 | International Business Machines Corporation | Distributed data structures for authorization and access control for computing resources |
US8862565B1 (en) | 2000-05-08 | 2014-10-14 | Google Inc. | Techniques for web site integration |
US8756212B2 (en) | 2000-05-08 | 2014-06-17 | Google Inc. | Techniques for web site integration |
US20050216478A1 (en) * | 2000-05-08 | 2005-09-29 | Verizon Laboratories Inc. | Techniques for web site integration |
US8015173B2 (en) | 2000-05-08 | 2011-09-06 | Google Inc. | Techniques for web site integration |
US6718351B2 (en) * | 2000-10-31 | 2004-04-06 | Hewlett-Packard Development Company, L.P. | Electronic record storage |
US8825869B2 (en) | 2000-11-13 | 2014-09-02 | Roussillon Llc | Method and system for deploying content to wireless devices |
US9418053B2 (en) | 2000-11-13 | 2016-08-16 | Zhigu Holdings Limited | Method and system for deploying content to wireless devices |
US7370272B2 (en) * | 2001-04-14 | 2008-05-06 | Siebel Systems, Inc. | Data adapter |
US20070192348A1 (en) * | 2001-04-14 | 2007-08-16 | Robert Brodersen | Data adapter |
US20030004943A1 (en) * | 2001-06-27 | 2003-01-02 | Hitachi, Ltd. | Method of relating information systems |
US6877004B2 (en) * | 2001-06-27 | 2005-04-05 | Hitachi, Ltd. | Method of relating information systems |
US20070143749A1 (en) * | 2001-07-26 | 2007-06-21 | Date Umesh M | System and method for expiring modular software components for wireless communication devices |
US7542758B2 (en) | 2001-07-26 | 2009-06-02 | Kyocera Wireless Corp. | Field downloading of wireless device software |
US7184759B2 (en) | 2001-07-26 | 2007-02-27 | Kyocera Wireless Corp. | Modular software components for wireless communication devices |
US7184793B2 (en) * | 2001-07-26 | 2007-02-27 | Kyocera Wireless Corp. | System and method for over the air area code update |
US7197302B2 (en) | 2001-07-26 | 2007-03-27 | Kyocera Wireless Corp. | System and method for interchangeable modular hardware components for wireless communication devices |
US7200389B2 (en) | 2001-07-26 | 2007-04-03 | Kyocera Wireless Corp. | Dynamic interface software for wireless communication devices |
US20040214560A1 (en) * | 2001-07-26 | 2004-10-28 | Kyocera Wireless Corp. | Modular software components for wireless communication devices |
US20060223517A1 (en) * | 2001-07-26 | 2006-10-05 | Kyocera Wireless Corp. | Field downloading of wireless device software |
US20040214561A1 (en) * | 2001-07-26 | 2004-10-28 | Kyocera Wireless Corp. | Dynamic interface software for wireless communication devices |
US8032865B2 (en) | 2001-07-26 | 2011-10-04 | Kyocera Corporation | System and method for field diagnosis of wireless communications device system software |
US20050064847A1 (en) * | 2001-07-26 | 2005-03-24 | Bilhan Kirbas | System and method for over the air area code update |
US7386846B2 (en) | 2001-07-26 | 2008-06-10 | Kyocera Wireless Corp. | System and method for the management of wireless communications device system software downloads in the field |
US20030022665A1 (en) * | 2001-07-26 | 2003-01-30 | Gowri Rajaram | System and method for organizing field upgradable wireless communication device software |
US20050245248A1 (en) * | 2001-07-26 | 2005-11-03 | Gowri Rajaram | System and method for field diagnosis of wireless communications device system software |
US7970375B2 (en) | 2001-07-26 | 2011-06-28 | Kyocera Corporation | System and method for expiring modular software components for wireless communication devices |
US9554268B2 (en) | 2001-07-26 | 2017-01-24 | Kyocera Corporation | System and method for updating persistent data in a wireless communications device |
US8479180B2 (en) | 2001-07-26 | 2013-07-02 | Kyocera Corporation | Maintenance of over the air upgradeable wireless communication device software |
US7328007B2 (en) | 2001-07-26 | 2008-02-05 | Kyocera Wireless Corp. | System and method for organizing wireless communication device system software |
US7254386B2 (en) | 2001-08-10 | 2007-08-07 | Kyocera Wireless Corp. | System and method for improved security in handset reprovisioning and reprogramming |
US7359699B2 (en) | 2001-08-10 | 2008-04-15 | Kyocera Wireless Corp. | System and method for peer-to-peer handset communication |
US20060063519A1 (en) * | 2001-08-10 | 2006-03-23 | Gowri Rajaram | System and method for peer-to-peer handset communication |
US8650307B2 (en) | 2001-09-17 | 2014-02-11 | Michael J. Miller | System for automated device-to-device transfer |
US7421436B2 (en) * | 2001-12-21 | 2008-09-02 | International Business Machines Corporation | Decentralized many-to-many relationship management in an object persistence management system |
US20030120628A1 (en) * | 2001-12-21 | 2003-06-26 | International Business Machines Corporation | Decentralized many-to-many relationship management in an object persistence management system |
US20030191693A1 (en) * | 2002-04-08 | 2003-10-09 | Itamar Aphek | System and method for conducting an advertising business |
US20190372921A1 (en) * | 2002-10-08 | 2019-12-05 | Iii Holdings 2, Llc | Coordination of data received from one or more sources over one or more channels into a single context |
US10742575B2 (en) * | 2002-10-08 | 2020-08-11 | Iii Holdings 2, Llc | Coordination of data received from one or more sources over one or more channels into a single context |
US9081844B2 (en) * | 2002-10-08 | 2015-07-14 | Iii Holdings 2, Llc | Coordination of data received from one or more sources over one or more channels into a single context |
US10397151B2 (en) * | 2002-10-08 | 2019-08-27 | Iii Holdings 2, Llc | Coordination of data received from one or more sources over one or more channels into a single context |
US20150288631A1 (en) * | 2002-10-08 | 2015-10-08 | Iii Holdings 2, Llc | Coordination of data received from one or more sources over one or more channels into a single context |
US10341273B2 (en) * | 2002-10-08 | 2019-07-02 | Iii Holdings 2, Llc | Coordination of data received from one or more sources over one or more channels into a single context |
US20180077094A1 (en) * | 2002-10-08 | 2018-03-15 | Iii Holdings 2, Llc | Coordination of data received from one or more sources over one or more channels into a single context |
US11290401B2 (en) | 2002-10-08 | 2022-03-29 | Iii Holdings 2, Llc | Coordination of data received from one or more sources over one or more channels into a single context |
US20080140763A1 (en) * | 2002-10-08 | 2008-06-12 | Greg Gershman | Coordination of data received from one or more sources over one or more channels into a single context |
US20040122841A1 (en) * | 2002-12-19 | 2004-06-24 | Ford Motor Company | Method and system for evaluating intellectual property |
US20050071389A1 (en) * | 2003-09-29 | 2005-03-31 | International Business Machines Corporation | High availability data replication of smart large objects |
US7200620B2 (en) * | 2003-09-29 | 2007-04-03 | International Business Machines Corporation | High availability data replication of smart large objects |
US20050086104A1 (en) * | 2003-10-17 | 2005-04-21 | Mcfadden Jeffrey A. | Delivery of advertising to telephone users |
CN100351840C (en) * | 2003-10-29 | 2007-11-28 | 国际商业机器公司 | A method and system for archiving and retrieving a markup language data stream |
US7206777B2 (en) * | 2003-10-29 | 2007-04-17 | International Business Machines Corporation | Method and system for archiving and retrieving a markup language document |
US20050097513A1 (en) * | 2003-10-29 | 2005-05-05 | International Business Machines Corporation | Method and system for archiving and retrieving a markup language document |
US7383289B2 (en) | 2003-12-02 | 2008-06-03 | Sap Aktiengesellschaft | Updating and maintaining data in a multi-system network using asynchronous message transfer |
US20060004806A1 (en) * | 2004-06-01 | 2006-01-05 | Kraft Frank M | Updating data in a multi-system network that utilizes asynchronous message transfer |
US7899796B1 (en) * | 2004-11-23 | 2011-03-01 | Andrew Borthwick | Batch automated blocking and record matching |
US20060155703A1 (en) * | 2005-01-10 | 2006-07-13 | Xerox Corporation | Method and apparatus for detecting a table of contents and reference determination |
US8706475B2 (en) * | 2005-01-10 | 2014-04-22 | Xerox Corporation | Method and apparatus for detecting a table of contents and reference determination |
US7703040B2 (en) * | 2005-06-29 | 2010-04-20 | Microsoft Corporation | Local search engine user interface |
US20070005576A1 (en) * | 2005-06-29 | 2007-01-04 | Microsoft Corporation | Search engine user interface |
CN104881450B (en) * | 2005-10-20 | 2019-02-15 | 甲骨文国际公司 | Manage the relationship between the resource being stored in warehouse |
CN104881450A (en) * | 2005-10-20 | 2015-09-02 | 甲骨文国际公司 | Managing Relationships Between Resources Stored Within A Repository |
US20070115917A1 (en) * | 2005-10-31 | 2007-05-24 | Microsoft Corporation | MTOM data transfer via TCP |
US7738887B2 (en) | 2005-10-31 | 2010-06-15 | Microsoft Corporation | Voice instant messaging between mobile and computing devices |
US20070099637A1 (en) * | 2005-10-31 | 2007-05-03 | Microsoft Corporation | Voice instant messaging between mobile and computing devices |
US10628396B1 (en) * | 2005-11-23 | 2020-04-21 | Open Invention Network Llc | Batch automated blocking and record matching |
US20070135836A1 (en) * | 2005-12-14 | 2007-06-14 | Mcewen James A | Low-cost disposable tourniquet cuff |
US20070239648A1 (en) * | 2006-03-20 | 2007-10-11 | Microsoft Corporation | Adaptive engine for processing geographic data |
US7415448B2 (en) * | 2006-03-20 | 2008-08-19 | Microsoft Corporation | Adaptive engine for processing geographic data |
US20070276920A1 (en) * | 2006-05-12 | 2007-11-29 | Daniel Buchmann | Consistency of routing rules in distributed system landscapes |
US20090030901A1 (en) * | 2007-07-23 | 2009-01-29 | Agere Systems Inc. | Systems and methods for fax based directed communications |
US9361367B2 (en) | 2008-07-30 | 2016-06-07 | Nec Corporation | Data classifier system, data classifier method and data classifier program |
US20110153615A1 (en) * | 2008-07-30 | 2011-06-23 | Hironori Mizuguchi | Data classifier system, data classifier method and data classifier program |
US9342589B2 (en) * | 2008-07-30 | 2016-05-17 | Nec Corporation | Data classifier system, data classifier method and data classifier program stored on storage medium |
US8392472B1 (en) * | 2009-11-05 | 2013-03-05 | Adobe Systems Incorporated | Auto-classification of PDF forms by dynamically defining a taxonomy and vocabulary from PDF form fields |
US8346796B2 (en) * | 2010-04-23 | 2013-01-01 | MobileRealtyApps.com, LLC | System for searching property listings based on location |
US20110264692A1 (en) * | 2010-04-23 | 2011-10-27 | MobileRealtyApps.com, LLC | System for searching property listings based on location |
US20120317642A1 (en) * | 2011-06-09 | 2012-12-13 | Barracuda Networks, Inc. | Parallel Tracing Apparatus For Malicious Websites |
US8655883B1 (en) * | 2011-09-27 | 2014-02-18 | Google Inc. | Automatic detection of similar business updates by using similarity to past rejected updates |
US8645399B2 (en) | 2012-01-03 | 2014-02-04 | Intelius Inc. | Dynamic record blocking |
US10579442B2 (en) | 2012-12-14 | 2020-03-03 | Microsoft Technology Licensing, Llc | Inversion-of-control component service models for virtual environments |
US11126609B2 (en) * | 2015-08-24 | 2021-09-21 | Palantir Technologies Inc. | Feature clustering of users, user correlation database access, and user interface generation system |
Also Published As
Publication number | Publication date |
---|---|
US6421683B1 (en) | 2002-07-16 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US6578056B1 (en) | Efficient data transfer mechanism for synchronization of multi-media databases | |
US6496843B1 (en) | Generic object for rapid integration of data changes | |
US6493721B1 (en) | Techniques for performing incremental data updates | |
US6408294B1 (en) | Common term optimization | |
US6374241B1 (en) | Data merging techniques | |
US6397228B1 (en) | Data enhancement techniques | |
US6519592B1 (en) | Method for using data from a data query cache | |
US6484161B1 (en) | Method and system for performing online data queries in a distributed computer system | |
US7047242B1 (en) | Weighted term ranking for on-line query tool | |
US6826559B1 (en) | Hybrid category mapping for on-line query tool | |
WO2000058863A1 (en) | Techniques for performing a data query in a computer system | |
US7783626B2 (en) | Pipelined architecture for global analysis and index building | |
US8214359B1 (en) | Detecting query-specific duplicate documents | |
US8849693B1 (en) | Techniques for advertising in electronic commerce | |
US6012053A (en) | Computer system with user-controlled relevance ranking of search results | |
US7039622B2 (en) | Computer-implemented knowledge repository interface system and method | |
Haveliwala et al. | Evaluating strategies for similarity search on the web | |
JP4873813B2 (en) | Indexing system and method | |
US6772150B1 (en) | Search query refinement using related search phrases | |
US6928446B2 (en) | System and method for data storage and retrieval | |
US11163802B1 (en) | Local search using restriction specification | |
US8276065B2 (en) | System and method for classifying electronically posted documents | |
US8332422B2 (en) | Using text search engine for parametric search | |
US6983287B1 (en) | Database build for web delivery | |
US8275661B1 (en) | Targeted banner advertisements |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
FPAY | Fee payment |
Year of fee payment: 4 |
|
FEPP | Fee payment procedure |
Free format text: PAYOR NUMBER ASSIGNED (ORIGINAL EVENT CODE: ASPN); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
AS | Assignment |
Owner name: GTE LABORATORIES INCORPORATED, MASSACHUSETTSFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:LAMBURT, LEONID;REEL/FRAME:023556/0087Effective date: 19990408 |
|
AS | Assignment |
Owner name: VERIZON PATENT AND LICENSING INC., NEW JERSEYFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:VERIZON LABORATORIES INC.;REEL/FRAME:023574/0995Effective date: 20091125 |
|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:VERIZON PATENT AND LICENSING INC.;REEL/FRAME:025328/0910Effective date: 20100916 |
|
FPAY | Fee payment |
Year of fee payment: 8 |
|
AS | Assignment |
Owner name: VERIZON LABORATORIES INC., MASSACHUSETTSFree format text: CORRECTIVE ASSIGNMENT TO CORRECT THE PATENT NUMBER FROM 5,678,056 TO 6,578,056 PREVIOUSLY RECORDED ON REEL 023565 FRAME 0423. ASSIGNOR(S) HEREBY CONFIRMS THE CHANGE OF NAME;ASSIGNOR:GTE LABORATORIES INCORPORATED;REEL/FRAME:028342/0990Effective date: 20000628 |
|
FPAY | Fee payment |
Year of fee payment: 12 |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044127/0735Effective date: 20170929 |