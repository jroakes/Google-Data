JP2021501926A - Graphical user interface rendering management with voice-driven computing infrastructure - Google Patents
Graphical user interface rendering management with voice-driven computing infrastructure Download PDFInfo
- Publication number
- JP2021501926A JP2021501926A JP2020516510A JP2020516510A JP2021501926A JP 2021501926 A JP2021501926 A JP 2021501926A JP 2020516510 A JP2020516510 A JP 2020516510A JP 2020516510 A JP2020516510 A JP 2020516510A JP 2021501926 A JP2021501926 A JP 2021501926A
- Authority
- JP
- Japan
- Prior art keywords
- responses
- data processing
- processing system
- component
- computing device
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/30—Information retrieval; Database structures therefor; File system structures therefor of unstructured textual data
- G06F16/33—Querying
- G06F16/332—Query formulation
- G06F16/3329—Natural language query formulation or dialogue systems
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/16—Sound input; Sound output
- G06F3/167—Audio in a user interface, e.g. using voice commands for navigating, audio feedback
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/44—Arrangements for executing specific programs
- G06F9/451—Execution arrangements for user interfaces
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/23—Updating
- G06F16/2365—Ensuring data consistency and integrity
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/95—Retrieval from the web
- G06F16/953—Querying, e.g. by the use of web search engines
- G06F16/9535—Search customisation based on user profiles and personalisation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/44—Arrangements for executing specific programs
- G06F9/451—Execution arrangements for user interfaces
- G06F9/453—Help systems
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/02—Feature extraction for speech recognition; Selection of recognition unit
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/08—Speech classification or search
- G10L15/18—Speech classification or search using natural language modelling
- G10L15/1815—Semantic context, e.g. disambiguation of the recognition hypotheses based on word meaning
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/08—Speech classification or search
- G10L15/18—Speech classification or search using natural language modelling
- G10L15/1822—Parsing for meaning understanding
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/22—Procedures used during a speech recognition process, e.g. man-machine dialogue
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/26—Speech to text systems
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L67/00—Network arrangements or protocols for supporting network services or applications
- H04L67/50—Network services
- H04L67/53—Network services using third party service providers
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N20/00—Machine learning
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L51/00—User-to-user messaging in packet-switching networks, transmitted according to store-and-forward or real-time protocols, e.g. e-mail
- H04L51/02—User-to-user messaging in packet-switching networks, transmitted according to store-and-forward or real-time protocols, e.g. e-mail using automatic reactions or user delegation, e.g. automatic replies or chatbot-generated messages
Abstract
グラフィカルユーザインターフェースのレンダリングを管理することが提供される。システムは、入力オーディオ信号を含むデータパケットを受信する。システムは、アプリケーション識別子とクエリとを決定する。システムは、サードパーティサーバに送信するための第2のクエリをアプリケーションに生成させ、クエリに対する応答を識別させるために、クエリをアプリケーションに提供する。システムは、応答を傍受し、応答に基づいてキーワードを生成する。システムは、キーワードを使用してデジタル構成要素を選択し、重複排除プロセスを実行し、デジタル構成要素を応答に追加することを決定する。システムは、アプリケーションによって生成された複数の応答をデジタル構成要素と統合するグラフィカルユーザインターフェーステンプレートを使用して表示出力を構築し、レンダリングのためにコンピューティングデバイスに表示出力を提供する。It is provided to manage the rendering of the graphical user interface. The system receives a data packet containing an input audio signal. The system determines the application identifier and query. The system causes the application to generate a second query to send to a third-party server and provides the query to the application to identify the response to the query. The system intercepts the response and generates keywords based on the response. The system uses keywords to select digital components, performs a deduplication process, and decides to add the digital components to the response. The system builds the display output using a graphical user interface template that integrates multiple responses generated by the application with digital components and provides the display output to the computing device for rendering.
Description
本発明は、音声駆動コンピューティングインフラストラクチャによるグラフィカルユーザインターフェースレンダリング管理に関する。 The present invention relates to graphical user interface rendering management with a voice-driven computing infrastructure.
コンピューティングデバイスは、コンピュータネットワークを介して送信されたデータを受信することができる。デバイスは、データを提示することができる。過剰なデータ送信のため、複数のソースからのデータを効率的に提示することは、困難である場合がある。 The computing device can receive data transmitted over the computer network. The device can present the data. Due to excessive data transmission, it can be difficult to efficiently present data from multiple sources.
本開示は、全体として、音声駆動コンピューティングインフラストラクチャによるグラフィカルユーザインターフェースレンダリング管理を対象とする。複数の異なるソースからの応答または出力が受信される可能性がある。各ソースは、フォーマットにおいて出力を提供する可能性がある。異なるソースからの出力の複数のレンダリングを実行することは、非効率またはプロセッサ集約的である場合がある。 The present disclosure is intended as a whole for graphical user interface rendering management by a voice-driven computing infrastructure. Responses or outputs from multiple different sources may be received. Each source may provide output in the format. Performing multiple renderings of output from different sources can be inefficient or processor intensive.
少なくとも1つの態様は、グラフィカルユーザインターフェースのレンダリングを管理するシステムを対象とする。システムは、1つまたは複数のプロセッサとメモリとを有するデータ処理システムを含むことができる。データ処理システムは、自然言語プロセッサ構成要素と、インターフェースと、出力合併構成要素と、コンテンツセレクタ構成要素とを実行することができる。データ処理システムは、インターフェースを介して、コンピューティングデバイスのセンサによって検出された入力オーディオ信号を備えるデータパケットを受信することができる。データ処理システムは、入力オーディオ信号から、アプリケーション識別子と、アプリケーション識別子に対応するアプリケーションに入力されるべきクエリとを決定することができる。データ処理システムは、アプリケーションにサードパーティサーバへの送信のための第2のクエリを生成させるためにアプリケーションにクエリを提供し、コンピューティングデバイスを介する表示のためのクエリに対する複数の応答を識別することができる。データ処理システムは、コンピューティングデバイスにおける表示の前にアプリケーションから、サードパーティサーバに送信された第2のクエリに応答してアプリケーションによって識別された複数の応答を取得することができる。データ処理システムは、複数の応答に基づいてキーワードを生成するために、複数の応答を構文解析することができる。データ処理システムは、キーワードの生成に応答して、アプリケーションから取得された複数の応答に基づいて生成されたキーワードを用いてリアルタイムコンテンツ選択を実行することができる。データ処理システムは、リアルタイムコンテンツ選択プロセスに基づいて、コンテンツプロバイダデバイスによって提供されるデジタル構成要素を識別することができる。データ処理システムは、デジタル構成要素とアプリケーションによって生成された複数の応答とを用いて重複排除プロセスを実行することができる。データ処理システムは、デジタル構成要素とアプリケーションによって生成された複数の応答とを用いて実行された重複排除プロセスに応答して、デジタル構成要素を複数の応答に追加することを決定することができる。データ処理システムは、アプリケーションに対して、複数の応答をレンダリングするためにフォント、色、およびレイアウトを定義するグラフィカルユーザインターフェーステンプレートを検索することができる。データ処理システムは、アプリケーションによって生成された複数の応答をリアルタイムコンテンツ選択プロセスに基づいて識別されたデジタル構成要素と統合するグラフィカルユーザインターフェーステンプレートを使用して表示出力を構築することができる。データ処理システムは、コンピューティングデバイスに通信可能に結合されたディスプレイデバイスを介する表示のための表示出力をコンピューティングデバイスにレンダリングさせるために、コンピューティングデバイスに表示出力を提供することができる。 At least one aspect is intended for a system that manages the rendering of a graphical user interface. The system can include a data processing system having one or more processors and memory. The data processing system can execute a natural language processor component, an interface, an output merge component, and a content selector component. The data processing system can receive a data packet with an input audio signal detected by a sensor of a computing device via an interface. From the input audio signal, the data processing system can determine the application identifier and the query to be input to the application corresponding to the application identifier. The data processing system queries the application to generate a second query for sending to a third-party server and identifies multiple responses to the query for display through the computing device. Can be done. The data processing system can get multiple responses identified by the application in response to a second query sent to the third party server from the application prior to display on the computing device. The data processing system can parse multiple responses in order to generate keywords based on the multiple responses. In response to keyword generation, the data processing system can perform real-time content selection with keywords generated based on multiple responses obtained from the application. The data processing system can identify the digital components provided by the content provider device based on the real-time content selection process. The data processing system can perform a deduplication process using digital components and multiple responses generated by the application. The data processing system can decide to add the digital component to the multiple responses in response to a deduplication process performed with the digital component and the application-generated response. The data processing system can search the application for graphical user interface templates that define fonts, colors, and layouts to render multiple responses. Data processing systems can build display output using graphical user interface templates that integrate multiple responses generated by the application with digital components identified based on the real-time content selection process. A data processing system can provide a display output to a computing device in order for the computing device to render the display output for display through a display device communicatively coupled to the computing device.
少なくとも1つの態様は、グラフィカルユーザインターフェースのレンダリングを管理する方法を対象とする。方法は、1つまたは複数のプロセッサとメモリとを有するデータ処理システムによって実行され得る。方法は、データ処理システムが、インターフェースを介して、コンピューティングデバイスのセンサによって検出された入力オーディオ信号を備えるデータパケットを受信することを含むことができる。方法は、データ処理システムが、データ処理システムによって、入力オーディオ信号から、アプリケーション識別子と、アプリケーション識別子に対応するアプリケーションに入力されるべきクエリとを決定することを含むができる。方法は、データ処理システムが、アプリケーションにサードパーティサーバへの送信のための第2のクエリを生成させるためにアプリケーションにクエリを提供し、コンピューティングデバイスを介する表示のためのクエリに対する複数の応答を識別することを含むことができる。方法は、データ処理システムが、コンピューティングデバイスにおける表示の前にアプリケーションから、サードパーティサーバに送信された第2のクエリに応答してアプリケーションによって識別された複数の応答を取得することを含むことができる。方法は、データ処理システムが、複数の応答に基づいてキーワードを生成するために、複数の応答を構文解析することを含むことができる。方法は、データ処理システムが、キーワードの生成に応答して、アプリケーションから取得された複数の応答に基づいて生成されたキーワードを用いてリアルタイムコンテンツ選択を実行することを含むことができる。方法は、データ処理システムが、リアルタイムコンテンツ選択プロセスに基づいて、コンテンツプロバイダデバイスによって提供されるデジタル構成要素を識別することを含むことができる。方法は、データ処理システムが、デジタル構成要素とアプリケーションによって生成された複数の応答とを用いて重複排除プロセスを実行することを含むことができる。方法は、データ処理システムが、デジタル構成要素とアプリケーションによって生成された複数の応答とを用いて実行された重複排除プロセスに応答して、デジタル構成要素を複数の応答に追加することを決定することを含むことができる。方法は、データ処理システムが、アプリケーションに対して、複数の応答をレンダリングするためにフォント、色、およびレイアウトを定義するグラフィカルユーザインターフェーステンプレートを検索することを含むことができる。方法は、データ処理システムが、アプリケーションによって生成された複数の応答をリアルタイムコンテンツ選択プロセスに基づいて識別されたデジタル構成要素と統合するグラフィカルユーザインターフェーステンプレートを使用して表示出力を構築することを含むことができる。方法は、データ処理システムが、コンピューティングデバイスに通信可能に結合されたディスプレイデバイスを介する表示のための表示出力をコンピューティングデバイスにレンダリングさせるために、コンピューティングデバイスに表示出力を提供することを含むことができる。 At least one aspect relates to a method of managing the rendering of a graphical user interface. The method can be performed by a data processing system with one or more processors and memory. The method can include the data processing system receiving a data packet with an input audio signal detected by a sensor of a computing device via an interface. The method can include the data processing system determining from the input audio signal the application identifier and the query to be entered into the application corresponding to the application identifier by the data processing system. The method is that the data processing system queries the application to generate a second query for sending to a third-party server, and multiple responses to the query for display through the computing device. Can include identifying. The method may include the data processing system getting multiple responses identified by the application in response to a second query sent from the application to a third party server prior to display on the computing device. it can. The method can include the data processing system parsing multiple responses in order to generate keywords based on the multiple responses. The method can include the data processing system performing real-time content selection with keywords generated based on multiple responses obtained from the application in response to keyword generation. The method can include the data processing system identifying the digital components provided by the content provider device based on the real-time content selection process. The method can include the data processing system performing a deduplication process with digital components and multiple responses generated by the application. The method is to determine that the data processing system adds the digital component to the multiple responses in response to the deduplication process performed with the digital components and the multiple responses generated by the application. Can be included. The method can include the data processing system searching the application for a graphical user interface template that defines fonts, colors, and layouts to render multiple responses. The method involves the data processing system constructing the display output using a graphical user interface template that integrates multiple responses generated by the application with digital components identified based on the real-time content selection process. Can be done. The method comprises providing the computing device with display output for the data processing system to render the display output for display through the display device communicably coupled to the computing device. be able to.
少なくとも1つの態様は、デジタルアシスタントデバイスを対象とする。デジタルアシスタントデバイスは、ディスプレイデバイスと、グラフィックスドライバと、センサと、プリプロセッサ構成要素とを含むことができる。センサは、入力オーディオ信号を検出することができる。プリプロセッサ構成要素は、ディスプレイデバイス、グラフィックスドライバ、およびセンサに結合され得る。プリプロセッサ構成要素は、フィルタリングされた入力オーディオ信号を作成するために入力オーディオ信号をフィルタリングすることができる。プリプロセッサ構成要素は、フィルタリングされた入力オーディオ信号をデータパケットに変換することができる。プリプロセッサ構成要素は、データパケットをデータ処理システムに送信することができる。データ処理システムは、自然言語プロセッサ構成要素とインターフェースと出力合併構成要素とコンテンツセレクタ構成要素とを実行する、1つまたは複数のプロセッサとメモリとを有することができる。データ処理システムは、インターフェースを介して、コンピューティングデバイスのセンサによって検出された入力オーディオ信号を備えるデータパケットを受信することができる。データ処理システムは、入力オーディオ信号から、アプリケーション識別子と、アプリケーション識別子に対応するアプリケーションに入力されるべきクエリとを決定することができる。データ処理システムは、アプリケーションにサードパーティサーバへの送信のための第2のクエリを生成させるためにアプリケーションにクエリを提供し、コンピューティングデバイスを介する表示のためのクエリに対する複数の応答を識別することができる。データ処理システムは、コンピューティングデバイスにおける表示の前にアプリケーションから、サードパーティサーバに送信された第2のクエリに応答してアプリケーションによって識別された複数の応答を取得することができる。データ処理システムは、複数の応答に基づいてキーワードを生成するために、複数の応答を構文解析することができる。データ処理システムは、キーワードの生成に応答して、アプリケーションから取得された複数の応答に基づいて生成されたキーワードを用いてリアルタイムコンテンツ選択を実行することができる。データ処理システムは、リアルタイムコンテンツ選択プロセスに基づいて、コンテンツプロバイダデバイスによって提供されるデジタル構成要素を識別することができる。データ処理システムは、デジタル構成要素とアプリケーションによって生成された複数の応答とを用いて重複排除プロセスを実行することができる。データ処理システムは、デジタル構成要素とアプリケーションによって生成された複数の応答とを用いて実行された重複排除プロセスに応答して、デジタル構成要素を複数の応答に追加することを決定することができる。データ処理システムは、アプリケーションに対して、複数の応答をレンダリングするためにフォント、色、およびレイアウトを定義するグラフィカルユーザインターフェーステンプレートを検索することができる。データ処理システムは、アプリケーションによって生成された複数の応答をリアルタイムコンテンツ選択プロセスに基づいて識別されたデジタル構成要素と統合するグラフィカルユーザインターフェーステンプレートを使用して表示出力を構築することができる。データ処理システムは、デジタルアシスタントデバイスに通信可能に結合されたディスプレイデバイスを介する表示のための表示出力をデジタルアシスタントデバイスにレンダリングさせるために、デジタルアシスタントデバイスに表示出力を提供することができる。デジタルアシスタントデバイスのグラフィックスドライバは、表示出力に対応する視覚的指示をディスプレイデバイスに提示させるために表示出力をレンダリングすることができる。 At least one aspect is intended for digital assistant devices. The digital assistant device can include a display device, a graphics driver, a sensor, and a preprocessor component. The sensor can detect the input audio signal. Preprocessor components can be coupled to display devices, graphics drivers, and sensors. The preprocessor component can filter the input audio signal to create a filtered input audio signal. The preprocessor component can convert the filtered input audio signal into data packets. The preprocessor component can send data packets to the data processing system. A data processing system can have one or more processors and memory that execute natural language processor components, interfaces, output merged components, and content selector components. The data processing system can receive a data packet with an input audio signal detected by a sensor of a computing device via an interface. From the input audio signal, the data processing system can determine the application identifier and the query to be input to the application corresponding to the application identifier. The data processing system queries the application to generate a second query for sending to a third-party server and identifies multiple responses to the query for display through the computing device. Can be done. The data processing system can get multiple responses identified by the application in response to a second query sent to the third party server from the application prior to display on the computing device. The data processing system can parse multiple responses in order to generate keywords based on the multiple responses. In response to keyword generation, the data processing system can perform real-time content selection with keywords generated based on multiple responses obtained from the application. The data processing system can identify the digital components provided by the content provider device based on the real-time content selection process. The data processing system can perform a deduplication process using digital components and multiple responses generated by the application. The data processing system can decide to add the digital component to the multiple responses in response to a deduplication process performed with the digital component and the application-generated response. The data processing system can search the application for graphical user interface templates that define fonts, colors, and layouts to render multiple responses. Data processing systems can build display output using graphical user interface templates that integrate multiple responses generated by the application with digital components identified based on the real-time content selection process. The data processing system can provide the digital assistant device with the display output for rendering the display output through the display device communicatively coupled to the digital assistant device. The graphics driver of the digital assistant device can render the display output to cause the display device to present visual instructions corresponding to the display output.
これらおよび他の態様および実装形態は、以下で詳細に論じられる。前述の情報および以下の詳細な説明は、様々な態様および実装形態の例示的な例を含み、特許請求された態様および実装形態の性質および特徴を理解するための概要または骨組みを提供する。図面は、様々な態様および実装形態の実例およびさらなる理解を提供し、本明細書に組み込まれ、本明細書の一部を構成する。 These and other aspects and implementations are discussed in detail below. The information described above and the detailed description below include exemplary examples of various aspects and implementations, and provide an overview or skeleton for understanding the nature and characteristics of the claimed aspects and implementations. The drawings provide examples and further understanding of various aspects and implementations, which are incorporated herein and form part of this specification.
添付図面は、縮尺通りに描かれることを意図していない。様々な図面における同様の参照番号および名称は、同様の要素を示す。明瞭にするために、すべての構成要素がすべての図面においてラベル付けされているわけではない。 The accompanying drawings are not intended to be drawn to scale. Similar reference numbers and names in various drawings indicate similar elements. For clarity, not all components are labeled in all drawings.
以下は、コンピュータネットワークを介してパケット化されたアクションをルーティングする方法、装置、およびシステムに関連する様々な概念、およびそれらの実装形態のより詳細な説明である。上記で紹介し、以下でより詳細に論じる様々な概念は、多数の方法のいずれかにおいて実装されてもよい。 The following is a more detailed description of how to route packetized actions over a computer network, various concepts related to devices, and systems, and their implementations. The various concepts introduced above and discussed in more detail below may be implemented in any of a number of ways.
本開示は、全体として、グラフィカルユーザインターフェースのレンダリングを管理することを対象とする。複数の異なるソースからの応答または出力が受信される可能性がある。各ソースは、フォーマットにおいて出力を提供する可能性がある。異なるソースからの出力の複数のレンダリングを実行することは、非効率またはプロセッサ集約的である場合がある。 The present disclosure is intended to manage the rendering of graphical user interfaces as a whole. Responses or outputs from multiple different sources may be received. Each source may provide output in the format. Performing multiple renderings of output from different sources can be inefficient or processor intensive.
本解決策のシステムおよび方法は、全体として、サードパーティのユーザ体験と統合することを対象とする。コンピューティングシステムは、複数のソースからのデジタル構成要素を提供することができる。しかしながら、単一のインターフェースを介して異なるソースからのデジタル構成要素を効率的に提示することは、困難である場合がある。本解決策のシステムおよび方法は、デジタルアシスタントをサードパーティのユーザ体験と統合することを対象とする。例えば、本開示は、チャットボットのインターフェースと一致するユーザ体験およびインターフェースを提供するために、デジタルアシスタントがチャットボットと統合することを可能にし、それによって、デジタルアシスタントによって駆動される視覚ディスプレイ内でサードパーティのルックアンドフィールを提供することができる。チャットボットアプリケーションは、オーディオ出力または表示テキストを使用して会話をシミュレートするコンピュータプログラムを指すことができる。場合によっては、デジタルアシスタントは、サードパーティコンテンツとともに提示するための追加のソースからのコンテンツを追加することができる。例えば、「チャットボット、近くのいくつかのレストランを提案して」という音声クエリを提出することができ、デジタルアシスタントは、統合されたスポンサー付きデジタルコンテンツを加えたチャットボットからの有機コンテンツで応答することができる。 The systems and methods of this solution, as a whole, are intended to be integrated with third-party user experiences. Computing systems can provide digital components from multiple sources. However, it can be difficult to efficiently present digital components from different sources through a single interface. The systems and methods of this solution are intended to integrate digital assistants with third-party user experiences. For example, the disclosure allows a digital assistant to integrate with a chatbot to provide a user experience and interface that matches the chatbot's interface, thereby third within a visual display driven by the digital assistant. It can provide a party look and feel. A chatbot application can refer to a computer program that uses audio output or display text to simulate a conversation. In some cases, the Digital Assistant may add content from additional sources for presentation with third-party content. For example, you can submit a voice query "Chatbot, suggest some restaurants nearby" and the digital assistant will respond with organic content from the chatbot with integrated sponsored digital content. be able to.
図1は、グラフィカルユーザインターフェースのレンダリングを管理する例示的なシステム100を示す。システム100は、コンテンツ選択インフラストラクチャを含むことができる。システム100は、データ処理システム102を含むことができる。データ処理システム102は、ネットワーク105を介して、コンテンツプロバイダコンピューティングデバイス106、チャットボットプロバイダデバイス108、またはクライアントコンピューティングデバイス104のうちの1つまたは複数と通信することができる。ネットワーク105は、インターネット、ローカル、ワイド、メトロ、または他のエリアネットワークのようなコンピュータネットワークと、音声またはデータモバイル電話ネットワークのような他の通信ネットワークとを含むことができる。ネットワーク105は、ラップトップ、デスクトップ、タブレット、デジタルアシスタント、携帯情報端末、スマートウォッチ、ウェアラブルデバイス、スマートフォン、ポータブルコンピュータ、またはスピーカのような少なくとも1つのコンピューティングデバイス104上で提示、出力、レンダリング、または表示され得るウェブページ、ウェブサイト、ドメイン名、またはユニフォームリソースロケータのような情報リソースにアクセスするために使用され得る。例えば、ネットワーク105を介して、コンピューティングデバイス104のユーザは、チャットボットプロバイダ108またはコンテンツプロバイダコンピューティングデバイス106によって提供される情報またはデータにアクセスすることができる。コンピューティングデバイス104は、ディスプレイを含んでも含まなくてもよく、例えば、コンピューティングデバイスは、マイクロフォンおよびスピーカのような限定されたタイプのユーザインターフェースを含んでもよい。場合によっては、コンピューティングデバイス104の主要なユーザインターフェースは、マイクロフォンおよびスピーカであってもよい。
FIG. 1 shows an
ネットワーク105は、ディスプレイネットワーク、例えば、コンテンツ配置もしくは検索エンジン結果システムに関連付けられた、または、デジタル構成要素配置キャンペーンの一部としてサードパーティデジタルコンテンツを含むのに適格な、インターネット上で利用可能な情報リソースのサブセットを含むかまたは構成することができる。ネットワーク105は、クライアントコンピューティングデバイス104によって提示、出力、レンダリング、または表示され得るウェブページ、ウェブサイト、ドメイン名、またはユニフォームリソースロケータのような情報リソースにアクセスするためにデータ処理システム102によって使用され得る。例えば、ネットワーク105を介して、クライアントコンピューティングデバイス104のユーザは、コンテンツプロバイダコンピューティングデバイス106またはチャットボットプロバイダコンピューティングデバイス108によって提供される情報またはデータにアクセスすることができる。
ネットワーク105は、ネットワークのいずれかのタイプもしくは形式であり、以下、すなわち、ポイントツーポイントネットワーク、ブロードキャストネットワーク、ワイドエリアネットワーク、ローカルエリアネットワーク、電気通信ネットワーク、データ通信ネットワーク、コンピュータネットワーク、ATM(非同期転送モード)ネットワーク、SONET(同期光ネットワーク)、SDH(同期デジタル階層)ネットワーク、ワイヤレスネットワーク、および有線ネットワークのうちのいずれかを含み得る。ネットワーク105は、赤外線チャネルまたは衛星帯域のようなワイヤレスリンクを含んでもよい。ネットワーク105のトポロジーは、バス、スター、またはリングネットワークトポロジーを含んでもよい。ネットワークは、高度モバイル電話プロトコル(「AMPS(advanced mobile phone protocol)」)、時分割多元接続(「TDMA(time division multiple access)」)、符号分割多元接続(「CDMA(code-division multiple access)」)、モバイル通信用グローバルシステム(「GSM(global system for mobile communication)」)、汎用パケット無線サービス(「GPRS(general packet radio services)」)、またはユニバーサルモバイルテレコミュニケーションズシステム(「UMTS(universal mobile telecommunications system)」)を含む、モバイルデバイス間で通信するために使用される任意のプロトコルを使用するモバイル電話ネットワークを含んでもよい。異なるプロトコルを介して異なるタイプのデータが送信されてもよく、または、異なるプロトコルを介して同じタイプのデータが送信されてもよい。
システム100は、少なくとも1つのデータ処理システム102を含むことができる。データ処理システム102は、ネットワーク105を介して、例えば、コンピューティングデバイス104、コンテンツプロバイダデバイス106(コンテンツプロバイダコンピューティングデバイス106)、またはチャットボットプロバイダデバイス108(またはチャットボットプロバイダ108)と通信するために、プロセッサを有するコンピューティングデバイスのような少なくとも1つの論理デバイスを含むことができる。データ処理システム102は、少なくとも1つの計算リソース、サーバ、プロセッサ、またはメモリを含むことができる。例えば、データ処理システム102は、少なくとも1つのデータセンタ内に配置された複数の計算リソースまたはサーバを含むことができる。データ処理システム102は、複数の論理的にグループ化されたサーバを含み、分散コンピューティング技法を促進することができる。サーバの論理グループは、データセンタ、サーバファーム、またはマシンファームと呼ばれる場合がある。サーバはまた、地理的に分散され得る。データセンタまたはマシンファームは、単一のエンティティとして管理されてもよく、または、マシンファームは、複数のマシンファームを含むことができる。各サーバファーム内のサーバは、異種であり得、サーバまたはマシンのうちの1つまたはそれ以上は、1つまたは複数のタイプのオペレーティングシステムプラットフォームに従って動作することができる。
マシンファーム内のサーバは、関連する記憶システムとともに高密度ラックシステム内に格納され得、企業データセンタ内に配置され得る。例えば、このようにサーバを統合することは、局所的な高性能ネットワーク上にサーバと高性能記憶システムとを配置することによって、システム管理性、システムの物理的セキュリティ、およびシステム性能を改善する場合がある。サーバおよび記憶システムのデータ処理システム102の構成要素のすべてまたはいくつかの集中化、ならびに、それらを高度なシステム管理ツールと結合することは、サーバリソースのより効率的な使用を可能にし、それは、電力および処理要件を節約し、帯域幅の利用を低減する。 Servers in a machine farm can be stored in a high density rack system with associated storage systems and can be located in a corporate data center. For example, this integration of servers improves system manageability, system physical security, and system performance by placing servers and high-performance storage systems on a local high-performance network. There is. Centralization of all or some of the components of the server and storage system data processing system 102, as well as combining them with advanced system management tools, allows for more efficient use of server resources. Saves power and processing requirements and reduces bandwidth utilization.
コンピューティングデバイス104は、少なくとも1つのディスプレイ132、少なくとも1つのセンサ134、少なくとも1つのトランスデューサ136、少なくとも1つのオーディオドライバ138、または少なくとも1つのプリプロセッサ140を含むか、それらとインターフェースするか、または他の方法で通信することができる。ディスプレイ132は、発光ダイオード、有機発光ダイオード、液晶ディスプレイ、レーザ、またはディスプレイ535などの、視覚的指示または光出力を提供するように構成された1つまたは複数のハードウェアまたはソフトウェア構成要素を含むことができる。センサ134は、例えば、カメラ、周囲光センサ、近接センサ、温度センサ、加速度計、ジャイロスコープ、動き検出器、GPSセンサ、位置センサ、マイクロフォン、ビデオ、画像検出、またはタッチセンサを含むことができる。トランスデューサ136は、スピーカまたはマイクロフォンを含むか、またはその一部であり得る。オーディオドライバ138は、ハードウェアトランスデューサ136へのソフトウェアインターフェースを提供することができる。オーディオドライバは、対応する音響波または音波を生成するようにトランスデューサ136を制御するためにデータ処理システム102によって提供されるオーディオファイルまたは他の命令を実行することができる。プリプロセッサ140は、1つまたは複数のプロセッサ(例えば、プロセッサ510)、論理アレイ、またはメモリを含むことができる。プリプロセッサ140は、キーワードを検出し、キーワードに基づいてアクションを実行することができる。プリプロセッサ140は、さらなる処理のためにデータ処理システム102に用語を送信する前に1つまたは複数の用語を除去するか、または用語を修正することができる。プリプロセッサ140は、マイクロフォンによって検出されたアナログオーディオ信号をデジタルオーディオ信号に変換し、デジタルオーディオ信号を搬送する1つまたは複数のデータパケットを、ネットワーク105を介してデータ処理システム102に送信することができる。場合によっては、プリプロセッサ140は、そのような送信を実行する命令を検出することに応答して、入力オーディオ信号の一部またはすべてを搬送するデータパケットを送信することができる。命令は、例えば、入力オーディオ信号を含むデータパケットをデータ処理システム102に送信するトリガキーワードまたは他のキーワードまたは承認を含むことができる。
The
プリプロセッサ140は、オーディオの特定の周波数を除去するために、入力オーディオ信号に対して事前フィルタリングまたは前処理を実行することができる。事前フィルタリングは、ローパスフィルタ、ハイパスフィルタ、またはバンドパスフィルタなどのフィルタを含むことができる。フィルタは、周波数領域において適用され得る。フィルタは、デジタル信号処理技法を使用して適用され得る。フィルタは、人間の音声または人間の発話に対応する周波数を維持しながら、人間の発話の典型的な周波数の範囲外の周波数を除去するように構成され得る。例えば、バンドパスフィルタは、第1のしきい値(例えば、70Hz、75Hz、80Hz、85Hz、90Hz、95Hz、100Hz、または105Hz)未満で、第2のしきい値(例えば、200Hz、205Hz、210Hz、225Hz、235Hz、245Hz、または255Hz)を超える周波数を除去するように構成され得る。バンドパスフィルタを適用することは、下流の処理においてコンピューティングリソースの利用を低減することができる。場合によっては、コンピューティングデバイス104におけるプリプロセッサ140は、入力オーディオ信号をデータ処理システム102に送信する前にバンドパスフィルタを適用することができ、それによってネットワーク帯域幅の利用を低減する。しかしながら、コンピューティングデバイス104に利用可能なコンピューティングリソースと利用可能なネットワーク帯域幅とに基づいて、データ処理システム102がフィルタリングを実行することを可能にするために入力オーディオ信号をデータ処理システム102に提供することがより効率的であり得る。
The preprocessor 140 can perform prefiltering or preprocessing on the input audio signal to remove certain frequencies of audio. Pre-filtering can include filters such as low-pass filters, high-pass filters, or band-pass filters. The filter can be applied in the frequency domain. Filters can be applied using digital signal processing techniques. The filter may be configured to remove frequencies outside the typical frequencies of human speech while maintaining frequencies corresponding to human voice or human speech. For example, a bandpass filter is below the first threshold (eg 70Hz, 75Hz, 80Hz, 85Hz, 90Hz, 95Hz, 100Hz, or 105Hz) and the second threshold (eg 200Hz, 205Hz, 210Hz). , 225Hz, 235Hz, 245Hz, or 255Hz) can be configured to remove frequencies above. Applying a bandpass filter can reduce the use of computing resources in downstream processing. In some cases, the preprocessor 140 in the
プリプロセッサ140は、自然言語プロセッサに干渉する可能性がある周囲ノイズレベルを低減するために、ノイズ低減技法などの追加の前処理または事前フィルタリング技法を用いることができる。ノイズ低減技法は、自然言語プロセッサの精度および速度を改善し、それによって、データ処理システム102のパフォーマンスを改善することができ、ディスプレイ132を介して提供されるグラフィカルユーザインターフェースのレンダリングを管理することができる。
The preprocessor 140 can use additional preprocessing or prefiltering techniques, such as noise reduction techniques, to reduce ambient noise levels that can interfere with natural language processors. Noise reduction techniques can improve the accuracy and speed of natural language processors, thereby improving the performance of the data processing system 102 and managing the rendering of the graphical user interface provided through the
クライアントコンピューティングデバイス104(またはコンピューティングデバイス104と呼ばれる)は、オーディオ入力として音声クエリをクライアントコンピューティングデバイス104に(センサ134を介して)入力し、トランスデューサ136(例えば、スピーカ)から出力されるデータ処理システム102(または、コンテンツプロバイダコンピューティングデバイス106またはチャットボットプロバイダコンピューティングデバイス108)からクライアントコンピューティングデバイス104に提供され得るコンピュータ生成音声の形態においてオーディオ出力を受信するエンドユーザに関連付けられ得る。コンピュータ生成音声は、実際の人物またはコンピュータ生成言語からの録音を含むことができる。クライアントコンピューティングデバイス104は、コンピューティングデバイス104に通信可能に結合されたディスプレイデバイス132を介して視覚出力を提供することができる。
The client computing device 104 (or referred to as the computing device 104) inputs a voice query to the client computing device 104 (via the sensor 134) as audio input and outputs data from the transducer 136 (eg, speaker). It can be associated with an end user receiving audio output in the form of computer-generated audio that can be provided from processing system 102 (or content provider computing device 106 or chatbot provider computing device 108) to
クライアントコンピューティングデバイス104は、(センサ134を介して)クライアントコンピューティングデバイス104への入力としてクエリを示すことができる画像またはビデオを提供するエンドユーザに関連付けられ得る。エンドユーザは、トランスデューサ136(例えば、スピーカ)から出力されるデータ処理システム102(または、コンテンツプロバイダコンピューティングデバイス106またはチャットボットプロバイダコンピューティングデバイス108)からクライアントコンピューティングデバイス104に提供され得るコンピュータ生成音声の形態において入力に応答するオーディオ出力を受信することができる。エンドユーザは、ディスプレイデバイス132に出力されるデータ処理システム102(または、コンテンツプロバイダコンピューティングデバイス106またはチャットボットプロバイダコンピューティングデバイス108)からクライアントコンピューティングデバイス104に提供され得るコンピュータ生成グラフィカルユーザインターフェースの形態において入力に応答する視覚出力を受信することができる。1つまたは複数のセンサ134によって検出される入力は、オーディオ入力(例えば、音響信号)、視覚入力(例えば、画像またはビデオデータ)、動き入力、または他の入力のうちの1つまたは複数を含むことができる。コンピューティングデバイス104への入力(オーディオ、画像、視覚、または動き入力のうちの1つまたは複数)は、デジタルファイルに変換され、さらなる処理のためまたはアクションを生成するためにデータ処理システム102に提供され得る。例えば、コンピューティングデバイス104への入力(オーディオ、画像、視覚、または動き入力のうちの1つまたは複数)は、チャットボットを備えるコンピュータプログラムの選択をトリガし、チャットボットに入力されるべきクエリの生成をトリガすることができ、チャットボットは、生成されたクエリに応答する、または入力(オーディオ、画像、視覚、または動き入力のうちの1つまたは複数)に対応する出力をコンピューティングデバイス104に提供することができる。
The
コンピューティングデバイス104は、コンピューティングデバイス104のセンサ134(例えば、マイクロフォン)によって検出された入力オーディオ信号を受信することができる。入力オーディオ信号は、例えば、クエリ、質問、コマンド、命令、または言語において提供される他のステートメントを含むことができる。入力オーディオ信号は、質問またはクエリが向けられるチャットボットの識別子または名前を含むことができる。例えば、クエリは、指定されたチャットボットにクエリを入力するようにデータ処理システム102に指示するために、クエリが後に続くチャットボットの名前を含むことができる。例えば、入力オーディオ信号は、「フードボット、近くのいくつかのよいレストランを提案して」を含むことができる。入力オーディオ信号は、チャットボットの識別子を含んでも含まなくてもよい。
The
システム100は、少なくとも1つのサードパーティチャットボットプロバイダデバイス108を含むか、それにアクセスするか、または他の方法で対話することができる。サードパーティチャットボットプロバイダ108は、1つまたは複数のサーバを含むことができ、サードパーティチャットボットサーバと呼ばれる場合がある。サードパーティチャットボットプロバイダデバイス108は、データ処理システム102と統合され得、またはデータ処理システム102によって少なくとも部分的に実行され得る。サードパーティチャットボットプロバイダデバイス108は、ネットワーク150を介して、例えば、コンピューティングデバイス104、データ処理システム102、またはコンテンツプロバイダコンピューティングデバイス106と通信するために、プロセッサを有するコンピューティングデバイスのような少なくとも1つの論理デバイスを含むことができる。チャットボットプロバイダデバイス108は、少なくとも1つの計算リソース、サーバ、プロセッサ、またはメモリを含むことができる。例えば、チャットボットプロバイダデバイス108は、少なくとも1つのセンタ内に配置された複数の計算リソースまたはサーバを含むことができる。チャットボットプロバイダデバイス108は、データ処理システム102の1つまたは複数の構成要素または機能を含むことができる。
チャットボットプロバイダデバイス108は、1つまたは複数のチャットボットを形成または提供するコンピュータプログラムを設計、開発、管理、または維持するエンティティのようなチャットボット開発者を含むか、またはそれを指すことができる。チャットボットは、聴覚、画像、またはテキストの方法を介して会話を行うコンピュータプログラムを含むことができる。チャットボットは、人間が会話パートナーとしてどのように振る舞うかをシミュレートするように設計され得る。チャットボットは、顧客サービスまたは情報取得のための対話システム内で使用され得る。チャットボットは、自然言語処理システム(例えば、自然言語プロセッサ構成要素112)を含むかまたは使用することができる。チャットボットは、入力内のキーワードをスキャンし、次いで、データベースから最も一致するキーワードまたは最も類似する言葉遣いパターンを有する返事を引き出すことができる。チャットボットは、事前定義された対話データ構造を検索するためにパターンマッチングを利用する手順を用いてプログラムされ得る。チャットボットは、入力の文法と構文とを識別するため、入力をトークン化するため、または、応答を決定するために入力を他の方法で処理するために、自然言語処理技法を用いてプログラムされ得る。
チャットボットプロバイダデバイス108は、少なくとも1つのチャットボットプロバイダ自然言語プロセッサ構成要素142およびチャットボットプロバイダインターフェース144を含むか、それらとインターフェースするか、またはそれらと他の方法で通信することができる。チャットボットプロバイダコンピューティングデバイス108は、少なくとも1つのチャットボットプロバイダ自然言語プロセッサ(NLP)構成要素142と、少なくとも1つのチャットボットプロバイダインターフェース144とを含むことができる。チャットボットプロバイダNLP構成要素142(または、チャットボットプロバイダコンピューティングデバイス108のような他の構成要素)は、クライアントコンピューティングデバイス104とチャットボットプロバイダコンピューティングデバイス108との間の往復のリアルタイムの音声またはオーディオベースの会話(例えば、セッション)を作成するために、(データ処理システム102を介して、またはデータ処理システム102をバイパスして)クライアントコンピューティングデバイス104と連動することができる。チャットボットプロバイダNLP142は、データ処理システム102のNLP構成要素112として1つまたは複数の機能または特徴を含むことができる。例えば、チャットボットプロバイダインターフェース144は、データ処理システム102のインターフェース110へのメッセージを受信または提供することができる。チャットボットプロバイダコンピューティングデバイス108およびコンテンツプロバイダコンピューティングデバイス106は、同じエンティティに関連付けられ得る。例えば、コンテンツプロバイダコンピューティングデバイス106は、チャットボットのためのデジタル構成要素を作成、記憶、または利用可能にすることができ、チャットボットプロバイダコンピューティングデバイス108は、クライアントコンピューティングデバイス104を介してチャットボットを介して通信するために、クライアントコンピューティングデバイス106とのセッションを確立することができる。データ処理システム102は、インターフェース110、チャットボット構成要素114、または他の構成要素を介して、チャットボットプロバイダコンピューティングデバイス104を含むまたはバイパスするクライアントコンピューティングデバイス104とのセッションを確立することもできる。
The
サードパーティチャットボットプロバイダデバイス108は、データ処理システム102を管理または提供するエンティティとは異なるエンティティの1つまたは複数のサーバを指すことができる。サードパーティチャットボットデバイス108は、チャットボットのためのコンピュータプログラムを受信することができる。サードパーティチャットボットデバイス108は、自然言語処理および他の機能を提供することができる。サードパーティチャットボットデバイス108は、チャットボット機能を提供するコンピューティングデバイス104とインターフェースまたは通信することができる。例えば、サードパーティチャットボットデバイス108は、コンピューティングデバイス104のユーザとの変換に従事するために、チャットボットを実行することができる。サードパーティチャットボットデバイス108は、データ処理システム102およびコンピューティングデバイス104から離れたサーバ上で実行することができる。場合によっては、サードパーティチャットボットデバイス108は、コンピューティングデバイス上で(例えば、プリプロセッサ140の一部として)少なくとも部分的に実行することができる。
The third-party
データ処理システム102は、少なくとも1つの計算リソースまたはサーバを有するコンテンツ配置システムを含むことができる。データ処理システム102は、少なくとも1つのインターフェース110とインターフェースするか、または他の方法で通信することができる。データ処理システム102は、少なくとも1つの自然言語プロセッサ構成要素112とインターフェースするか、または他の方法で通信することができる。データ処理システム102は、少なくとも1つのチャットボット構成要素114とインターフェースするか、または他の方法で通信することができる。データ処理システム102は、少なくとも1つのフック構成要素116とインターフェースするか、または他の方法で通信することができる。データ処理システム102は、少なくとも1つのコンテンツセレクタ構成要素118とインターフェースするか、または他の方法で通信することができる。データ処理システム102は、少なくとも1つの出力合併構成要素120とインターフェースするか、または他の方法で通信することができる。データ処理システム102は、少なくとも1つのデータリポジトリ122を含むか、それとインターフェースするか、または他の方法で通信することができる。少なくとも1つのデータリポジトリ122は、1つまたは複数のデータ構造またはデータベースにおいて、テンプレート124、履歴データ126、コンテンツデータ128、またはチャットボットデータ130を含むかまたは記憶することができる。データリポジトリ122は、コンピュータストレージまたはメモリを含むことができ、数あるデータの中で、1つもしくは複数のテンプレート124、履歴データ126、コンテンツデータ128、またはチャットボットデータ130を記憶することができる。テンプレート124は、表示出力を生成することを容易にする情報を含むことができる。テンプレート124は、グラフィカルユーザインターフェーステンプレートを含むことができる。グラフィカルユーザインターフェーステンプレートは、チャットボットインターフェースを介する表示出力などの表示出力を生成するために、フォント、色、またはレイアウトを定義することができる。テンプレート124は、例えば、データ構造、写真エディタファイル、またはスタイルシートとして記憶され得る。
The data processing system 102 can include a content placement system having at least one computational resource or server. The data processing system 102 can interface with at least one interface 110 or communicate in other ways. The data processing system 102 can interface with or otherwise communicate with at least one natural
履歴データ126は、1つまたは複数のデータ構造において記憶され得る。履歴データ126は、コンピューティングデバイス104に関連する履歴ネットワークアクティビティ、コンピューティングデバイス104によって利用されるチャットボットの識別子、コンピューティングデバイス104の構成、デバイス機能、選好、または、コンテンツ選択、もしくは、デジタル構成要素を挿入するチャットボット結果間の位置を選択することを容易にすることができるコンピューティングデバイス104に関連付けられた他の情報を含むことができる。コンテンツデータ130は、例えば、コンテンツキャンペーン情報、コンテンツグループ、コンテンツ選択基準、デジタル構成要素オブジェクト、または、コンテンツプロバイダコンピューティングデバイス106によって提供されるか、もしくは、コンテンツ選択を容易にするためにデータ処理システムによって取得もしくは決定される他の情報を含むことができる。コンテンツデータ130は、例えば、コンテンツキャンペーンの過去のパフォーマンスを含むことができる。コンテンツデータ128は、オーディオ出力、表示出力、または関連するメタデータに関するデジタル構成要素、ならびに、クライアントコンピューティングデバイス104との1つまたは複数の通信セッションの一部であり得る入力オーディオメッセージを含むことができる。デジタル構成要素(またはデジタル構成要素オブジェクト)は、例えば、コンテンツアイテム、オンラインドキュメント、オーディオ、画像、ビデオ、マルチメディアコンテンツ、またはスポンサー付きコンテンツを含むことができる。
チャットボットデータ130は、チャットボットに関する識別子、チャットボットのタイプに関する情報(例えば、カテゴリ、制限、またはトピック)を含むことができる。チャットボットデータ130は、データ構造内に記憶され得、チャットボットの識別子に基づいてインデックス付けされ得る。チャットボットデータ130は、コンピューティングデバイス104に関連付けられた識別子に基づいてさらにインデックス付けされ得る。データリポジトリ122は、1つまたは複数のローカルデータベースまたは分散データベースを含むことができ、データベース管理システムを含むことができる。
The
インターフェース110、自然言語プロセッサ112、チャットボット構成要素114、フック構成要素116、コンテンツセレクタ構成要素118、または出力合併構成要素120は、各々、プログラマブル論理アレイエンジン、またはデータベースリポジトリもしくはデータベース122と通信するように構成されたモジュールのような、少なくとも1つの処理ユニットまたは他の論理デバイスを含むことができる。インターフェース110、自然言語プロセッサ構成要素112、チャットボット構成要素114、フック構成要素116、コンテンツセレクタ構成要素118、出力合併構成要素120、およびデータリポジトリ122は、別個の構成要素、単一の構成要素、またはデータ処理システム102の一部であり得る。データ処理システム102のようなシステム100およびその構成要素は、1つまたは複数のプロセッサ、論理デバイス、または回路のようなハードウェア要素を含むことができる。
Interface 110,
データ処理システム102は、複数のコンピューティングデバイス104に関連付けられた匿名のコンピュータネットワークアクティビティ情報を取得することができる。コンピューティングデバイス104のユーザは、データ処理システム102が、ユーザのコンピューティングデバイス104に対応するネットワークアクティビティ情報を取得することを肯定的に承認することができる。例えば、データ処理システム102は、コンピューティングデバイス104のユーザに1つまたは複数のタイプのネットワークアクティビティ情報を取得するための同意を促すことができる。コンピューティングデバイス104のユーザの識別情報は、匿名のままであり得、コンピューティングデバイス104は、一意の識別子(例えば、データ処理システムまたはコンピューティングデバイスのユーザによって提供されるユーザまたはコンピューティングデバイスの一意の識別子)と関連付けられ得る。データ処理システムは、各観測を対応する一意の識別子に関連付けることができる。
The data processing system 102 can acquire anonymous computer network activity information associated with the plurality of
コンテンツプロバイダコンピューティングデバイス106は、オーディオ出力デジタル構成要素または視覚出力構成要素としてクライアントコンピューティングデバイス104によって提示するためのオーディオ、視覚、またはマルチメディアベースのデジタル構成要素を提供することができる。デジタル構成要素は、デジタル構成要素であるかまたはそれを含むことができる。デジタル構成要素は、デジタルオブジェクトであるかまたはそれを含むことができる。デジタル構成要素は、商品またはサービスのブランド名または会社名を含むことができる。デジタル構成要素は、パラメータ的に駆動されるテキスト読み上げ技法のために構成され得る。デジタル構成要素は、通常の言語テキストをスピーチに変換するテキスト読み上げ(TTS)実装形態のために構成され得る。デジタル構成要素は、テキストを様々な言語、アクセント、および音声における自然に聞こえるスピーチに合成するためにスピーチ合成能力を利用するアプリケーションプログラミングインターフェースに入力され得る。デジタル構成要素は、プレーンテキストまたはスピーチ合成マークアップ言語(SSML)としてコーディングされる。SSMLは、音声の音響指紋またはネイティブ音声を形成することができる発音、音量、ピッチ、レートのような、スピーチの態様を制御するために設定され得るパラメータを含むことができる。
The content provider computing device 106 can provide an audio, visual, or multimedia-based digital component for presentation by the
コンテンツプロバイダコンピューティングデバイス106は、コンテンツ選択プロセスを容易にするために、値、キーワード、概念、または他のメタデータもしくは情報のようなデジタル構成要素のためのコンテンツ選択基準を提供することができる。コンテンツプロバイダコンピューティングデバイス106は、オーディオベースのデジタル構成要素(または他のデジタル構成要素)をデータ処理システム102に提供することもでき、そこでそれらは、データリポジトリ122内に記憶され得る。データ処理システム102は、オーディオデジタル構成要素(または、パラメータ的に駆動される、テキスト、画像、またはビデオからスピーチへの技法のために構成されたデジタル構成要素)を選択し、オーディオデジタル構成要素をクライアントコンピューティングデバイス104に提供する(または、提供するようにコンテンツプロバイダコンピューティングデバイス106に指示する)ことができる。オーディオベースのデジタル構成要素は、オーディオのみであり得、または、テキスト、画像、もしくはビデオデータと組み合わされ得る。 The content provider computing device 106 can provide content selection criteria for digital components such as values, keywords, concepts, or other metadata or information to facilitate the content selection process. The content provider computing device 106 can also provide audio-based digital components (or other digital components) to the data processing system 102, where they can be stored in the data repository 122. The data processing system 102 selects an audio digital component (or a parameter-driven digital component configured for text, image, or video-to-speech techniques) and selects the audio digital component. It can be provided to the client computing device 104 (or instruct the content provider computing device 106 to provide it). Audio-based digital components can be audio alone or combined with text, image, or video data.
コンテンツプロバイダコンピューティングデバイス106は、コンテンツデータデータ構造128におけるデータリポジトリ122内に記憶するために、デジタル構成要素をデータ処理システム102に提供することができる。データ処理システム102は、コンテンツに対する要求に応答してデジタル構成要素を検索することができ、またはデジタル構成要素を提供することを他の方法で決定する。
The content provider computing device 106 can provide digital components to the data processing system 102 for storage in the data repository 122 in the content
コンテンツプロバイダコンピューティングデバイス106は、電子コンテンツキャンペーンを確立することができる。電子コンテンツキャンペーンは、データリポジトリ122内にコンテンツデータ128として記憶され得る。電子コンテンツキャンペーンは、共通のテーマに対応する1つまたは複数のコンテンツグループを指すことができる。コンテンツキャンペーンは、コンテンツグループと、デジタル構成要素データオブジェクト(例えば、デジタル構成要素またはデジタルオブジェクト)と、コンテンツ選択基準とを含むことができる。コンテンツキャンペーンを作成するために、コンテンツプロバイダコンピューティングデバイス106は、コンテンツキャンペーンのキャンペーンレベルパラメータの値を指定することができる。キャンペーンレベルパラメータは、例えば、キャンペーン名、デジタル構成要素オブジェクトを配置するための好ましいコンテンツネットワーク、コンテンツキャンペーンのために使用されるべきリソースの値、コンテンツキャンペーンの開始日および終了日、コンテンツキャンペーンの持続時間、デジタル構成要素オブジェクトの配置のスケジュール、言語、地理的位置、デジタル構成要素オブジェクトを提供するコンピューティングデバイスのタイプを含むことができる。場合によっては、インプレッションは、デジタル構成要素オブジェクトがそのソース(例えば、データ処理システム102またはコンテンツプロバイダコンピューティングデバイス106)からフェッチされるときを指すことができ、カウント可能である。場合によっては、クリック詐欺の可能性のため、ロボットアクティビティは、インプレッションとしてフィルタリングされ、除外され得る。したがって、場合によっては、インプレッションは、ブラウザからのページ要求に対するウェブサーバからの応答の尺度を指すことができ、それは、ロボットアクティビティおよびエラーコードからフィルタリングされ、コンピューティングデバイス104における表示のためにデジタル構成要素オブジェクトをレンダリングする機会にできるだけ近い時点で記録される。場合によっては、インプレッションは、可視または可聴のインプレッションを指すことができ、例えば、デジタル構成要素オブジェクトまたはデジタル構成要素は、クライアントコンピューティングデバイス104のディスプレイデバイスにおいて少なくとも部分的に(例えば、20%、30%、40%、50%、60%、70%、またはそれよりも上)見ることが可能であり、または、コンピューティングデバイス104のスピーカ136を介して可聴である。クリックまたは選択は、可聴インプレッションへの音声応答、マウスクリック、タッチインタラクション、ジェスチャ、シェイク、オーディオインタラクション、またはキーワードクリックのような、デジタル構成要素オブジェクトとのユーザインタラクションを指すことができる。コンバージョンは、ユーザがデジタル構成要素オブジェクションに関して所望のアクションを行うこと、例えば、製品もしくはサービスを購入すること、調査を完了すること、デジタル構成要素に対応する実店舗を訪問すること、または電子取引を完了することを指すことができる。
The content provider computing device 106 can establish an electronic content campaign. The electronic content campaign may be stored as
コンテンツプロバイダコンピューティングデバイス106は、コンテンツキャンペーンのための1つまたは複数のコンテンツグループをさらに確立することができる。コンテンツグループは、1つまたは複数のデジタル構成要素オブジェクトと、キーワード、単語、用語、フレーズ、地理的位置、コンピューティングデバイスのタイプ、時刻、関心、トピック、またはバーティカルのような、対応するコンテンツ選択基準とを含む。同じコンテンツキャンペーンの下のコンテンツグループは、同じキャンペーンレベルパラメータを共有することができるが、キーワード、除外キーワード(例えば、除外キーワードが存在するときにメインコンテンツにおけるデジタル構成要素の配置をブロックする)、キーワードの入札(bid)、または、入札もしくはコンテンツキャンペーンに関連付けられたパラメータのようなコンテンツグループレベルパラメータに合うように仕様を調整していてもよい。 Content Provider Computing Device 106 can further establish one or more content groups for content campaigns. Content groups are one or more digital component objects and corresponding content selection criteria, such as keywords, words, terms, phrases, geographic locations, computing device types, times, interests, topics, or verticals. And include. Content groups under the same content campaign can share the same campaign level parameters, but for keywords, negative keywords (for example, blocking the placement of digital components in the main content when negative keywords are present), keywords. Specifications may be tailored to meet content group level parameters such as bids or parameters associated with bids or content campaigns.
新しいコンテンツグループを作成するために、コンテンツプロバイダコンピューティングデバイス106は、コンテンツグループのコンテンツグループレベルパラメータに関する値を提供することができる。コンテンツグループレベルパラメータは、例えば、コンテンツグループ名またはコンテンツグループテーマと、異なるコンテンツ配置の機会(例えば、自動配置または管理された配置)または結果(例えば、クリック、インプレッション、またはコンバージョン)に関する入札とを含む。コンテンツグループ名またはコンテンツグループテーマは、コンテンツプロバイダが、コンテンツグループのデジタル構成要素オブジェクトが表示のために選択されるべきトピックまたは主題を取り込むために使用することができる1つまたは複数の用語であり得る。例えば、飲食品会社は、それが取り扱う食品または飲料品の各ブランドについて異なるコンテンツグループを作成することができ、それを運ぶ車両のモデルごとに異なるコンテンツグループをさらに作成してもよい。飲食品会社が使用することができるコンテンツグループテーマの例は、「ブランドAコーラ」、「ブランドBジンジャーエール」、「ブランドCオレンジジュース」、「ブランドDスポーツドリンク」、または「ブランドE精製水」を含む。コンテンツキャンペーンテーマの例は、「ソーダ」であり得、例えば、「ブランドAコーラ」と「ブランドBジンジャーエール」の両方に関するコンテンツグループを含むことができる。デジタル構成要素(またはデジタル構成要素オブジェクトもしくはデジタル構成要素)は、「ブランドA」、「ブランドB」、「ブランドC」、「ブランドD」、または「ブランドE」を含むことができる。デジタル構成要素オブジェクトまたはデジタル構成要素は、パラメータ的に駆動されるテキスト読み上げ技法のために構成されたデジタル構成要素を指すことができる。 To create a new content group, the content provider computing device 106 can provide values for the content group level parameters of the content group. Content group level parameters include, for example, a content group name or content group theme and bids for different content placement opportunities (eg, automatic placement or managed placement) or results (eg, clicks, impressions, or conversions). .. The content group name or content group theme can be one or more terms that the content provider can use to capture the topic or subject that the digital component object of the content group should be selected for display. .. For example, a food and beverage company may create different content groups for each brand of food or beverage it handles, and may further create different content groups for each model of vehicle carrying it. Examples of content group themes that can be used by food and beverage companies are "Brand A Cola," "Brand B Ginger Ale," "Brand C Orange Juice," "Brand D Sports Drink," or "Brand E Purified Water." including. An example of a content campaign theme can be "soda" and can include, for example, content groups for both "brand A cola" and "brand B ginger ale". A digital component (or digital component object or digital component) can include "Brand A", "Brand B", "Brand C", "Brand D", or "Brand E". A digital component object or digital component can refer to a digital component constructed for a parameter-driven text-to-speech technique.
コンテンツプロバイダコンピューティングデバイス106は、1つまたは複数のキーワードおよびデジタル構成要素オブジェクトを各コンテンツグループに提供することができる。キーワードは、デジタル構成要素オブジェクトに関連付けられるかまたはそれによって識別される製品またはサービスに関連する用語を含むことができる。キーワードは、1つまたは複数の用語またはフレーズを含むことができる。例えば、飲食品会社は、ブランドが提供する商品またはサービスを記述することができるコンテンツグループまたはコンテンツキャンペーンのためのキーワードとして、「ソーダ」、「コーラ」、「ソフトドリンク」を含むことができる。場合によっては、特定の用語またはキーワードにおけるコンテンツの配置を回避、防止、ブロック、または無効にするために、コンテンツプロバイダによって除外キーワードが指定され得る。コンテンツプロバイダは、デジタル構成要素オブジェクトを選択するために使用される、完全一致、フレーズ一致、または部分一致のような、マッチングのタイプを指定することができる。 The content provider computing device 106 can provide one or more keywords and digital component objects to each content group. Keywords can include terms related to the product or service associated with or identified by the digital component object. Keywords can include one or more terms or phrases. For example, a food and beverage company may include "soda," "cola," and "soft drink" as keywords for a content group or content campaign that can describe a product or service offered by a brand. In some cases, negative keywords may be specified by the content provider to avoid, prevent, block, or disable the placement of content in a particular term or keyword. Content providers can specify the type of matching used to select digital component objects, such as exact match, phrase match, or partial match.
コンテンツプロバイダコンピューティングデバイス106は、コンテンツプロバイダコンピューティングデバイス106によって提供されるデジタル構成要素オブジェクトを選択するためにデータ処理システム102によって使用されるべき1つまたは複数のキーワードを提供することができる。コンテンツプロバイダコンピューティングデバイス106は、入札する1つまたは複数のキーワードを識別し、様々なキーワードの入札額をさらに提供することができる。コンテンツプロバイダコンピューティングデバイス106は、デジタル構成要素オブジェクトを選択するためにデータ処理システム102によって使用されるべき追加のコンテンツ選択基準を提供することができる。複数のコンテンツプロバイダ106は、同じまたは異なるキーワードに入札することができ、データ処理システム102は、電子メッセージのキーワードの指示の受信に応答してコンテンツ選択プロセスまたは広告オークションを実行することができる。 The content provider computing device 106 can provide one or more keywords that should be used by the data processing system 102 to select the digital component objects provided by the content provider computing device 106. The content provider computing device 106 can identify one or more keywords to bid on and further offer bids for various keywords. The content provider computing device 106 can provide additional content selection criteria that should be used by the data processing system 102 to select digital component objects. The plurality of content providers 106 can bid on the same or different keywords, and the data processing system 102 can perform a content selection process or an advertising auction in response to receiving an instruction for a keyword in an electronic message.
コンテンツプロバイダコンピューティングデバイス106は、データ処理システム102による選択のために1つまたは複数のデジタル構成要素オブジェクトを提供することができる。データ処理システム102は、リソース割り当て、コンテンツスケジュール、最大入札、キーワード、および、コンテンツグループについて指定された他の選択基準に一致するコンテンツ配置機会が利用可能になると、(例えば、コンテンツセレクタ構成要素118を介して)デジタル構成要素オブジェクトを選択することができる。音声デジタル構成要素、オーディオデジタル構成要素、テキストデジタル構成要素、画像デジタル構成要素、ビデオデジタル構成要素、マルチメディアデジタル構成要素、またはデジタル構成要素リンクのような様々なタイプのデジタル構成要素オブジェクトがコンテンツグループ内に含まれ得る。デジタル構成要素を選択すると、データ処理システム102は、コンピューティングデバイス104またはコンピューティングデバイス104のディスプレイデバイスにおいてレンダリングするためにデジタル構成要素オブジェクトを送信することができる。レンダリングすることは、ディスプレイデバイスにおいてデジタル構成要素を表示すること、または、コンピューティングデバイス104のスピーカを介してデジタル構成要素を再生することを含むことができる。データ処理システム102は、デジタル構成要素オブジェクトを提示するために、コンピューティングデバイス104もしくはチャットボット構成要素114、またはサードパーティチャットボットプロバイダデバイス108に命令を提供することができる。データ処理システム102は、オーディオ信号、音響波、または視覚出力を生成するようにコンピューティングデバイス104、ディスプレイ132、またはコンピューティングデバイス104のオーディオドライバ138に命令することができる。
The content provider computing device 106 can provide one or more digital component objects for selection by the data processing system 102. When data processing system 102 makes available content placement opportunities that match resource allocation, content schedules, maximum bids, keywords, and other selection criteria specified for content groups (eg, content selector component 118). Digital component objects can be selected (via). Content groups are various types of digital component objects such as audio digital components, audio digital components, text digital components, image digital components, video digital components, multimedia digital components, or digital component links. Can be included in. When a digital component is selected, the data processing system 102 can transmit a digital component object for rendering on the
データ処理システム102は、例えば、データパケットを使用して情報を受信および送信するように設計された、構成された、構築された、または動作可能なインターフェース構成要素110を含むことができる。インターフェース110は、ネットワークプロトコルのような1つまたは複数のプロトコルを使用して情報を受信および送信することができる。インターフェース110は、ハードウェアインターフェース、ソフトウェアインターフェース、有線インターフェース、またはワイヤレスインターフェースを含むことができる。インターフェース110は、データをあるフォーマットから別のフォーマットに変換またはフォーマットすることを容易にすることができる。例えば、インターフェース110は、ソフトウェア構成要素のような様々な構成要素間で通信するための定義を含むアプリケーションプログラミングインターフェースを含むことができる。 The data processing system 102 can include, for example, an interface component 110 that is configured, constructed, or operational to receive and transmit information using data packets. Interface 110 can receive and transmit information using one or more protocols, such as network protocols. Interface 110 can include a hardware interface, a software interface, a wired interface, or a wireless interface. Interface 110 can facilitate the conversion or formatting of data from one format to another. For example, interface 110 can include an application programming interface that includes definitions for communicating between various components, such as software components.
データ処理システム102は、入力オーディオ信号をデータ処理システム102のインターフェース110に通信して、出力オーディオ信号または視覚出力をレンダリングするためにクライアントコンピューティングデバイスの構成要素を駆動するアプリケーションのような、クライアントコンピューティングデバイス104においてインストールされたアプリケーション、スクリプト、またはプログラムを含むことができる。データ処理システム102は、データパケット、デジタルファイル、または、オーディオ入力信号(または入力オーディオ信号)を含むかもしくは識別する他の信号を受信することができる。コンピューティングデバイス104は、トランスデューサ136を介してオーディオ信号を検出し、アナログデジタル変換器を介してアナログオーディオ信号をデジタルファイルに変換することができる。例えば、オーディオドライバ138は、アナログデジタル変換器構成要素を含むことができる。場合によっては、プリプロセッサ構成要素140は、オーディオ信号を、ネットワーク105を介してデータパケットによって送信され得るデジタルファイルに変換することができる。
The data processing system 102 communicates the input audio signal with the interface 110 of the data processing system 102 to drive the components of the client computing device to render the output audio signal or visual output. It can include applications, scripts, or programs installed on the
データ処理システム102は、コンピューティングデバイス104のセンサ134によって検出された入力オーディオ信号を含むデータパケットを受信または取得するために、NLP構成要素112を実行することができる。データパケットは、デジタルファイルを提供することができる。NLP構成要素112は、オーディオ信号を含むデータファイルまたはデータパケットを受信または取得し、オーディオ信号を構文解析することができる。例えば、NLP構成要素112は、人間とコンピュータとの間の対話を提供することができる。NLP構成要素112は、自然言語を理解し、データ処理システム102が人間または自然言語入力から意味を導出することを可能にするための技法を用いて構成され得る。NLP構成要素112は、統計的機械学習のような機械学習に基づく技法を含むか、またはそれを用いて構成され得る。NLP構成要素112は、入力オーディオ信号を構文解析するために、決定木、統計モデル、または確率モデルを利用することができる。NLP構成要素112は、例えば、名前付きエンティティ認識(例えば、テキストのストリームが与えられた場合、テキスト内のどのアイテムが人または場所のような適切な名前にマッピングされるか、および各々のそのような名前が人、場所、組織のようなどんなタイプであるかを判定する)、自然言語生成(例えば、コンピュータデータベースまたは意味論的意図(semantic intent)からの情報を理解可能な人間の言語に変換する)、自然言語理解(例えば、テキストを、コンピュータモジュールが操作することができる1階論理(first-order logic)構造のようなより正式な表現に変換する)、機械翻訳(例えば、ある人間の言語から別の人間の言語に自動的に翻訳する)、形態論的分割(morphological segmentation)(例えば、単語を個々の形態素に分離し、形態素のクラスを識別し、これは、考慮されている言語の形態論の複雑さおよび単語の構造に基づいて困難になる可能性がある)、質問応答(例えば、明確なまたは自由回答であり得る人間の言語の質問への回答を決定する)、意味処理(例えば、単語を識別し、識別された単語を同様の意味を有する他の単語に関連付けるためにその意味を符号化した後に生じ得る処理)のような機能を実行することができる。
The data processing system 102 can execute the
NLP構成要素112は、入力信号を(例えば、データリポジトリ122内の)記憶されたオーディオ波形の代表的なセットと比較し、最も近い一致を選択することによって、オーディオ入力信号を認識されたテキストに変換することができる。オーディオ波形のセットは、データリポジトリ122、または、データ処理システム102にアクセス可能な他のデータベース内に記憶され得る。代表的な波形は、ユーザの大規模なセット全体で生成され、次いで、ユーザからの音声サンプルで補強されてもよい。オーディオ信号が認識されたテキストに変換された後、NLP構成要素112は、例えば、ユーザ全体のトレーニングを介してまたは手動の仕様を介してデータ処理システム102が提供することができるアクションに関連付けられた単語にテキストを一致させる。NLP構成要素112は、画像またはビデオ入力をテキストまたはデジタルファイルに変換することができる。NLP構成要素112は、アクションを実行するため、要求を生成するため、またはデータ構造を選択もしくは識別するために、画像またはビデオ入力を処理、分析、または解釈することができる。
The
オーディオ入力信号は、クライアントコンピューティングデバイス104のセンサ134またはトランスデューサ136(例えば、マイクロフォン)によって検出され得る。トランスデューサ136、オーディオドライバ138、または他の構成要素を介して、クライアントコンピューティングデバイス104は、オーディオ入力信号を(例えば、ネットワーク105を介して)データ処理システム102に提供し、そこで、オーディオ入力信号は、デジタルファイルまたはデジタルフォーマットとして(例えば、インターフェース110によって)受信され、NLP構成要素112に提供されるか、データリポジトリ122内に記憶され得る。場合によっては、データ処理システム102は、入力音響信号に加えて、またはその代わりに、画像またはビデオ入力信号を受信することができる。データ処理システム102は、例えば、画像解釈技法、コンピュータビジョン、機械学習エンジン、または、画像またはビデオをデジタルファイルに変換するために画像またはビデオを認識または解釈する他の技法を使用して、画像またはビデオ入力信号を処理することができる。1つまたは複数の画像解釈技法、コンピュータビジョン技法、機械学習技法は、画像技法と総称され得る。データ処理システム102(例えば、NLP構成要素112)は、オーディオ処理技法に加えて、またはその代わりに、画像技法を用いて構成され得る。
The audio input signal can be detected by the
NLP構成要素112は、入力オーディオ信号を取得することができる。入力オーディオ信号から、NLP構成要素112は、少なくとも1つの要求または要求に対応する少なくとも1つのトリガキーワードを識別することができる。要求は、入力オーディオ信号の意図または主題を示すことができる。トリガキーワードは、とられる可能性が高いアクションのタイプを示すことができる。例えば、NLP構成要素112は、夕食および映画に行くために夕方に家を出るための少なくとも1つの要求を識別するために入力オーディオ信号を構文解析することができる。トリガキーワードは、とるべきアクションを示す少なくとも1つの単語、フレーズ、基語もしくは部分単語、または派生語を含むことができる。例えば、入力オーディオ信号からのトリガキーワード「行く」または「〜に行くために」は、移動の必要性を示すことができる。この例において、入力オーディオ信号(または識別された要求)は、移動の意図を直接表現していないが、トリガキーワードは、移動が要求によって示される少なくとも1つの他のアクションへの付随的なアクションであることを示す。
The
NLP構成要素112は、要求およびトリガキーワードを識別、決定、検索、または他の方法で取得するために、入力オーディオ信号を構文解析することができる。例えば、NLP構成要素112は、トリガキーワードまたは要求を識別するために、入力オーディオ信号に意味論的処理技法を適用することができる。NLP構成要素112は、第1のトリガキーワードおよび第2のトリガキーワードのような1つまたは複数のトリガキーワードを含むトリガフレーズを識別するために、入力オーディオ信号に意味論的処理技法を適用することができる。例えば、入力オーディオ信号は、「フードボット、近くのいくつかのよいレストランを提案して」という文を含むことができる。NLP構成要素112は、入力オーディオ信号がアプリケーション識別子とクエリとを含むことを決定することができる。アプリケーション識別子は、チャットボット識別子または名前を指すことができる。NLP構成要素112は、「フードボット」というアプリケーション識別子と「近くのいくつかのよいレストランを提案して」というクエリとを識別するために、文を含むデータパケットに意味論的処理技法、または他の自然言語処理技法を適用することができる。NLP構成要素112は、アプリケーションに入力するクエリを生成するために使用され得る「よい」、「レストラン」、および「近くの」などの複数のキーワードをさらに識別することができる。例えば、NLP構成要素112は、トリガフレーズがトリガキーワードと、クエリを形成するために使用され得る複数の追加キーワードとを含むと判定することができる。
NLP構成要素112は、アプリケーション識別子とクエリとを識別するために入力オーディオ信号をフィルタリングすることができる。場合によっては、入力オーディオ信号は、クエリを含むことができるが、アプリケーション識別子またはチャットボットの名前を含まない場合がある。例えば、入力オーディオ信号を搬送するデータパケットは、「It would be great if I could get help finding some good restaurants nearby」を含むことができ、その場合、NLP構成要素112は、以下の、「it」、「would」、「be」、「great」、「if」、「I」、「could」、「get」、または「help」のように1つまたは複数の用語を除去することができる。これらの用語を除去することによって、NLP構成要素112は、「finding」、「good」、「restaurants」、「nearby」のようなクエリまたはキーワードをより正確かつ確実に識別し、これがレストランチャットボットを起動する要求であると判定することができる。
The
入力オーディオ信号は、所望のチャットボットの識別子などのアプリケーション識別子を含むことができる。入力オーディオ信号は、チャットボットの一意の識別子、チャットボットの名前、またはチャットボットが起動するもしくは呼び出される他の指示を含むことができる。例えば、入力オーディオ信号は、「フードボット」などのチャットボットの名前を含むことができる。アプリケーション識別子は、英数字の識別子であり得る。 The input audio signal can include an application identifier, such as the desired chatbot identifier. The input audio signal can include a unique identifier for the chatbot, the name of the chatbot, or other instructions that the chatbot is activated or called. For example, the input audio signal can include the name of a chatbot, such as "food bot." The application identifier can be an alphanumeric identifier.
したがって、データ処理システム102は、コンピューティングデバイス104のセンサ134またはトランスデューサ136によって検出された音声コンテンツを搬送する入力オーディオ信号に対応するデータパケットを受信することができる。入力オーディオ信号は、コンピューティングデバイス104のアナログデジタル変換器(例えば、オーディオドライバ138)によってデジタルファイルに変換され得る。データ処理システム102は、ネットワーク105を介してデジタルファイルに対応するデータパケットを受信することができ、次いで、チャットボットを備えるコンピュータプログラムを選択するためにデータパケットまたはデジタルファイルを構文解析することができる。例えば、データ処理システム102は、データパケットまたはデジタルファイルに応答して、例えば、データ処理システム102は、データパケットまたはデジタルファイルに応答して、データ処理システム102またはコンピューティングデバイス104またはサードパーティチャットボットプロバイダデバイス108による実行のためのチャットボットを含むコンピュータプログラムを選択するように設計され構築されたチャットボット構成要素114を含むことができる。
Therefore, the data processing system 102 can receive the data packet corresponding to the input audio signal carrying the audio content detected by the
チャットボット構成要素114は、デジタルファイル内のキーワード、トークン、用語、概念、または他の情報を識別することができる。チャットボット構成要素114は、デジタルファイル内のキーワード、トークン、用語、概念、または他の情報を識別するために、自然言語プロセッサ構成要素112を利用することができる。自然言語プロセッサ構成要素112は、構文解析されたキーワード、トークン、用語、または概念をチャットボット構成要素114に提供することができる。チャットボット構成要素114は、デジタルファイルのキーワードまたは概念に応答するチャットボットを選択することができる。チャットボット構成要素114は、入力オーディオ信号において提供されるアプリケーション識別子にマッピングするチャットボットを選択することができる。
データ処理システム102は(例えば、NLP構成要素112またはチャットボット構成要素114を介して)、入力オーディオ信号がアプリケーション識別子「フードボット」を含むと判定することができる。NLP構成要素112またはチャットボット構成要素114は、入力オーディオ信号内のクエリをさらに識別することができる。NLP構成要素112は、アプリケーション識別子をチャットボット構成要素114に提供することができる。チャットボット構成要素114は、アプリケーション識別子「フードボット」にマッピングするチャットボットを識別するためにチャットボットデータ構造130における探索を実行することができる。場合によっては、入力オーディオ信号は、チャットボット識別子を含まない場合があるが、クエリへの応答を提供することができるチャットボットのタイプを示すクエリを含む場合がある。例えば、チャットボットデータ構造130は、チャットボットごとにチャットボットが提供することができる商品、サービス、または機能(例えば、レストラン検索)を記述するキーワードまたは他の情報を含むことができる。チャットボット構成要素114は、対応するチャットボットを起動、開始、実行、または他の方法でアクティブにするために、チャットボットデータ構造130を介して決定される識別子を使用することができる。場合によっては、識別子は、ファイル名もしくはファイルパス、ポインタ、ウェブアドレス、インターネットプロトコルアドレス、ユニフォームリソースロケータ、またはチャットボットを識別するための他のものを含むか、またはそれに関連付けられ得る。例えば、データ処理システム102は、レシピチャットボットがサードパーティチャットボットプロバイダデバイス108を介して提供されると判定し、サードパーティチャットボットプロバイダデバイス108に、レストラン検索チャットボットを起動し、直接またはデータ処理システム102を介して(例えば、チャットボット構成要素114を介して)コンピューティングデバイス104と連動するように指示することができる。
The data processing system 102 (eg, via
したがって、データ処理システム102は、入力オーディオ信号から、アプリケーション識別子と、アプリケーション識別子に対応するアプリケーションに入力されるべきクエリとを決定することができる。データ処理システム102は、アプリケーションにサードパーティサーバへの送信のための第2のクエリを生成させるためにアプリケーションまたはチャットボットにクエリを提供し、コンピューティングデバイス104を介する表示のためのクエリに対する複数の応答を識別することができる。例えば、チャットボット構成要素114は、チャットボットを少なくとも部分的に実行するか、または、チャットボットとコンピューティングデバイス104との間のインターフェースを容易にすることができる。データ処理システム102は、チャットボットを呼び出し、入力オーディオ信号を介して受信されたクエリを入力することができる。チャットボットは、実行時に、クエリを識別し、次いで、サードパーティチャットボットプロバイダデバイス108に送信する第2のクエリを生成することができる。サードパーティチャットボットプロバイダデバイス108は、サードパーティチャットボットプロバイダデバイス108は、第2のクエリを受信し、探索を実行し、次いで、クエリに対応する1つまたは複数の応答を生成することができる。
Therefore, the data processing system 102 can determine the application identifier and the query to be input to the application corresponding to the application identifier from the input audio signal. The data processing system 102 queries the application or chatbot to cause the application to generate a second query for sending to a third-party server, and multiple queries for the query for display through the
場合によっては、チャットボットの起動または起動もしくは実行を引き起こす前に、データ処理システム102は、コンピューティングデバイス104がチャットボットにアクセスする許可を与えられるかどうかを判定することができる。データ処理システム102は、コンピューティングデバイス104がチャットボットを備えるコンピュータプログラムにアクセスする許可を与えられるかどうかを判定するために、コンピューティングデバイス104の識別子を用いて(例えば、チャットボット構成要素114を介して)データリポジトリ122(例えば、チャットボットデータ130)内を探索することができる。許可は、サブスクリプション、計画、制限、リソース要件、バージョン管理、またはデバイス機能に基づくことができる。例えば、データ処理システム102は、データ処理システム102は、コンピューティングデバイス104がオペレーティングシステムの事前定義されたバージョンを用いて構成されている場合、コンピューティングデバイス104にチャットボットへのアクセスを許すことができる。別の例において、データ処理システム102は、コンピューティングデバイス104が有効なアカウントまたはプロファイルに関連付けられている場合、コンピューティングデバイス104にチャットボットへのアクセスを許すことができる。場合によっては、データ処理システム102が、コンピューティングデバイス104がチャットボットへのアクセスを許可されていないと判定した場合、データ処理システム102は、スレッドを終了するか、ユーザに促すか、または、コンピューティングデバイス104がアクセスを許可されている別のチャットボットを識別することができる。したがって、データ処理システム102は、コンピューティングデバイス104がチャットボットへのアクセスを許可されているとの判定に応答してチャットボットを選択することができる。
In some cases, the data processing system 102 may determine whether the
インターフェース110は、チャットボット自体を起動することができ、または、サードパーティチャットボットプロバイダデバイス108に、チャットボットに関連付けられた会話アプリケーションプログラミングインターフェース(例えば、NLP構成要素142)を呼び出させ、データ処理システム102またはサードパーティチャットボットプロバイダデバイス108とクライアントコンピューティングデバイス104との間の通信セッションを確立させるようにサードパーティチャットボットプロバイダデバイス108に命令を送信することができる。データ処理システム102またはサードパーティチャットボットプロバイダデバイス108とクライアントコンピューティングデバイス104との間の通信セッションを確立することに応答して、データ処理システム102またはサードパーティチャットボットプロバイダデバイス108は、ネットワーク105を介してクライアントコンピューティングデバイス104にデータパケットを直接送信することができる。場合によっては、サードパーティチャットボットプロバイダデバイス108は、データ処理システム102およびネットワーク105を介してクライアントコンピューティングデバイス104にデータパケットを送信することができる。
Interface 110 can launch the chatbot itself, or causes a third-party
チャットボットプロバイダデバイス108またはデータ処理システム102は、チャットボットプロバイダNLP構成要素142の少なくとも一部を実行することができる。例えば、サードパーティチャットボットプロバイダデバイス108は、通信セッションの特定の態様またはクエリのタイプを処理することができる。サードパーティチャットボットデバイス108は、通信セッションに関連するオーディオ信号を処理することと、クエリに対する応答を生成することとを容易にするために、データ処理システム102によって実行されるNLP構成要素112を活用してもよい。場合によっては、データ処理システム102は、サードパーティチャットボットデバイス108のために構成された会話API142を含むことができる。場合によっては、データ処理システムは、通信セッションを確立するためにクライアントコンピューティングデバイスとサードパーティプロバイダデバイス108との間でデータパケットをルーティングする。データ処理システム102は、サードパーティチャットボットデバイス108から、サードパーティデバイスがクライアントデバイス104との通信セッションを確立したという指示を受信することができる。指示は、クライアントコンピューティングデバイス104の識別子、通信セッションが確立されたときに対応するタイムスタンプ、または、通信セッションに関連付けられたデータ構造のような、通信セッションに関連付けられた他の情報を含むことができる。
The
チャットボットプロバイダNLP構成要素142は、第1のNLP112の1つまたは複数の構成要素または機能を含む第2のNLPであり得る。チャットボットプロバイダNLP構成要素142は、第1のNLP112と対話するか、またはそれを活用することができる。場合によっては、システム100は、データ処理システム102によって実行される単一のNLP112を含むことができる。単一のNLP112は、データ処理システム102とチャットボットの両方をサポートすることができる。場合によっては、インターフェース110は、サービスを実行することを容易にするためにデータ構造を生成または構築し、会話APIは、エンドユーザとの通信セッションを進めるために、または、エンドユーザの体験もしくはサービスのパフォーマンスを改善または強化するために追加の情報を取得するために、応答またはクエリを生成する。
The chatbot
チャットボットを備えるコンピュータプログラムは、データ処理システム102、チャットボットプロバイダデバイス108、またはコンピューティングデバイス104において実行することができる。チャットボットは、応答を決定するために、1つもしくは複数のデジタルファイルまたは1つもしくは複数のデジタルファイルの一部を受信して処理することができる。例えば、チャットボットは、データ処理システム102上のチャットボット構成要素114として実行することができる。
A computer program with a chatbot can run on a data processing system 102, a
チャットボットは、実行時に、入力クエリを識別することができる。データ処理システム102は、チャットボットを呼び出し、実行し、または起動し、コンピューティングデバイス104からの入力オーディオ信号に基づいて受信または決定されたクエリを入力することができる。例えば、コンピューティングデバイス104からデータ処理システム102によって受信されたデータパケットは、アプリケーション識別子とクエリとを含むことができる。データ処理システム102は(例えば、チャットボット構成要素114を介して)アプリケーション識別子に対応するチャットボットを呼び出し、次いで、「近くのよいレストラン」というクエリを入力することができる。チャットボット構成要素114は、探索を実行し、1つまたは複数の応答を生成するために、チャットボットに入力されるべき、またはサードパーティチャットボットプロバイダデバイス108に提供されるべき第2のクエリを生成することができる。
Chatbots can identify input queries at run time. The data processing system 102 can call, execute, or activate the chatbot and enter a query received or determined based on the input audio signal from the
チャットボット構成要素114は、入力オーディオ信号内の入力クエリに基づいて第2のクエリを生成することができる。第2のクエリは、サードパーティチャットボットプロバイダデバイス108に送信され得る。第2のクエリは、サードパーティチャットボットプロバイダデバイス108による処理を容易にするためにフォーマットされ得る。第2のクエリは、入力オーディオ信号において受信された第1のクエリに対して異なる情報を含むことができる。第2のクエリは、第1のクエリに対して追加の情報、または第1のクエリに対してより少ない情報を含むことができる。チャットボット構成要素112は、サードパーティチャットボットプロバイダデバイス108が実行する必要があり得る処理の量を低減するために、入力クエリに対して初期処理または前処理を実行することができる。チャットボット構成要素112は、サードパーティチャットボットプロバイダデバイス108と、データ処理システム102と、コンピューティングデバイス104との間のリモートプロシージャコールの数を低減するために、入力クエリに対して初期処理または前処理を実行することができる。
The
例えば、コンピューティングデバイス104から入力オーディオ信号において受信された入力クエリは、「フードボット、近くのいくつかのよいレストランを提案して」であり得る。チャットボット構成要素114は、「近くの」という用語に基づいて、入力クエリの位置構成要素が存在すると判定することができる。サードパーティチャットボットプロバイダデバイス108に位置情報についてデータ処理システム102またはコンピューティングデバイス104に問い合わさせ得るクエリをそのままサードパーティチャットボットプロバイダデバイス108に渡すのではなく、チャットボット構成要素114は、第2のクエリを構築し、コンピューティングデバイス104に対応する位置情報を入力することができる。データ処理システム102は(例えば、チャットボット構成要素114を介して)、コンピューティングデバイス104の位置を決定することができる。データ処理システム102は、コンピューティングデバイス104のプロファイルにおいて確立された場所の好みを決定することができる。場所の好みは、例えば、場所の送信をブロックすること、または送信する場所の許容分解能(例えば、半径100メートル、200メートル、300メートル、500メートル、1000メートル、1マイル、郵便番号、市、町、群内の住所)を含むことができる。場所の好みに基づいて、データ処理システム102は、コンピューティングデバイス104の現在の位置を識別し、以下の、「アメリカ合衆国のAnytown、123メインストリートの近くにあるよいレストランを識別する」のように位置情報を含むように第2のクエリを構築することができる。したがって、欠落情報を特定するために入力クエリを前処理し、次いで、欠落情報を決定し、決定された情報を含む第2のクエリを生成することによって、データ処理システム102は、サードパーティチャットボットプロバイダデバイス108によって実行される過剰なリモートプロシージャコールを低減することによって、全体的なシステム効率を改善することができ、それによって、コンピューティングデバイス104のコンピューティングリソースの利用またはバッテリ消費を低減する。
For example, an input query received in an input audio signal from
チャットボット構成要素114は、生成された第2のクエリをサードパーティチャットボットプロバイダデバイス108に提供することができる。サードパーティチャットボットプロバイダデバイス108は、自然言語処理技法、検索エンジン技法、パターンマッチング技法、または意味論的分析技法を使用して、クエリに対する1つまたは複数の応答を識別することができる。例えば、チャットボットは、クエリを使用して検索を実行し、次いで、検索結果を含む応答を生成することができる。
サードパーティチャットボットプロバイダデバイス108は、チャットボット構成要素114によって提供された第2のクエリを使用して検索を実行することができる。サードパーティチャットボットプロバイダデバイス108は、サードパーティチャットボットプロバイダデバイス108の内部または外部の1つまたは複数のデータベースにアクセスすることができる。場合によっては、サードパーティチャットボットプロバイダデバイス108は、検索を実行するために、データ処理システム102の1つまたは複数の構成要素、機能、リソース、またはデータベースを利用することができる。サードパーティチャットボットプロバイダデバイス108は、第2のクエリに対する複数の応答を識別することができる。複数の応答は、検索結果を含むことができる。複数の応答は、例えば、第2のクエリによって定義された検索基準を満たすレストランのリストを含むことができる。例えば、レストランのリストは、コンピューティングデバイス104の現在の位置の半径内にあり、4つ星以上のレストランの評価に基づいて「よい」レストランを含むことができる。
The third-party
データ処理システム102は、コンピューティングデバイス104における表示の前に、チャットボットアプリケーション(または、チャットボットアプリケーションを少なくとも部分的に実行するか、もしくは第2のクエリに対する応答を生成するサードパーティチャットボットプロバイダデバイス108)から、第2のクエリに対する1つまたは複数の応答を取得するために、フック構成要素116を含むか、実行するか、またはそれと他の方法で通信することができる。データ処理システム102が第2のクエリに対する応答を識別するためにチャットボットアプリケーションを実行する場合、フック構成要素116は、チャットボットアプリケーションがコンピューティングデバイス104に応答を送信する前に応答を取得することができる。場合によっては、応答がチャットボットアプリケーションまたは表示のためにコンピューティングデバイス104のいずれかに向けられ得るように、フック構成要素116は、サードパーティチャットボットプロバイダデバイス108からの応答を傍受することができる。傍受することは、フック構成要素116が応答を取得し、それらをチャットボット構成要素114とは対象的にコンテンツセレクタ構成要素118、または表示のためにコンピューティングデバイス104に転送することを指すことができる。
The data processing system 102 runs the chatbot application (or the chatbot application, at least partially, or generates a response to a second query before display on the
チャットボットアプリケーションは、データ処理システム102、チャットボット構成要素114、またはサードパーティチャットボットプロバイダデバイス108のうちの少なくとも1つにおいて実行することによって第2のクエリに対する応答を生成することができる。第2のクエリに対する応答を生成または識別すると、チャットボットアプリケーション(データ処理システム102、サードパーティチャットボットプロバイダデバイス108、またはコンピューティングデバイス114のうちの1つまたは複数において少なくとも部分的に実行されるかどうかにかかわらず)は、コンピューティングデバイス104のディスプレイ132を介する提示に対する応答を送信または提供することができる。しかしながら、表示のために結果を提示する前に、フック構成要素116は、第2のクエリに対する応答を取得または傍受することができる。フック構成要素116は、データ処理システム102、サードパーティチャットボットプロバイダデバイス108、またはコンピューティングデバイス104の構成要素からの応答を取得または傍受することができる。
The chatbot application can generate a response to a second query by running on at least one of the data processing system 102, the
システム100は、コンピューティングデバイス104における表示のために応答が提供される前に、第2のクエリに対する応答を取得または傍受するために、データ処理システム102またはクライアントコンピューティングデバイス104のうちの1つまたは複数において実行するフック構成要素118を含むことができる。フック構成要素114は、応答を取得または傍受し、応答を出力合併構成要素120にリダイレクトすることができる。
フック構成要素116は、データ処理システム102の構成要素間、データ処理システム102とコンピューティングデバイス104との間、データ処理システム102とサードパーティプロバイダデバイス108との間、またはサードパーティプロバイダデバイス108とコンピューティングデバイス104との間で渡される機能呼び出し、応答、デジタル構成要素、メッセージ、またはイベントを取得または傍受することができる。フック構成要素116は、応答を傍受するように構成されたチャットボットアプリケーションの実行時にイベントフックを挿入することができる。いくつかの実装形態において、フック構成要素118は、例えば、スタックのアプリケーション層へのデータの送達の前に、ネットワークスタック内で実行することができる。他の実装形態において、フック構成要素118は、オペレーティングシステムのカーネルレベル、ユーザレベル内で実行することができ、または、1つまたは複数の仮想マシンとは無関係にハイパーバイザーによって実行され得る。
The
例えば、データ処理システム102またはコンピューティングデバイス104において実行するフック構成要素118は、チャットボットアプリケーションまたはサードパーティチャットボットプロバイダデバイス108を介して提供された応答を取得または傍受し、応答をコンテンツセレクタ構成要素118に転送することができる。フック構成要素は、応答をコンテンツセレクタ構成要素118に再ルーティングまたはリダイレクトするように構成され得る。傍受は、応答がサンドボックスメディア環境のためのメモリまたはバッファに書き込まれた後、しかし、サンドボックスメディア環境の処理スレッドがデジタル構成要素を読み取る前、などに、ネットワークスタック内など、処理の任意の便利なまたは適切な部分において(例えば、アプリケーション層以下において)発生してもよい。
For example, a hook component 118 running on a data processing system 102 or a
データ処理システム102は、チャットボットアプリケーションから第2のクエリに対する応答を受信し、デジタル構成要素を選択するために、コンテンツセレクタ構成要素118を含むか、実行するか、またはそれと他の方法で通信することができる。コンテンツセレクタ構成要素118は、チャットボットアプリケーションから受信された応答を構文解析し、キーワードを生成することができる。コンテンツセレクタ構成要素118は、フック構成要素116によって傍受された応答に基づいて生成されたキーワードを用いてリアルタイムコンテンツ選択プロセスを実行することができる。コンテンツセレクタ構成要素118は、リアルタイムコンテンツ選択プロセスを使用してデジタル構成要素を識別することができる。デジタル構成要素は、コンテンツプロバイダデバイス106によって提供され得る。
The data processing system 102 receives the response to the second query from the chatbot application and includes, executes, or otherwise communicates with the content selector component 118 to select the digital component. be able to. Content selector component 118 can parse the response received from the chatbot application and generate keywords. Content selector component 118 can perform a real-time content selection process with keywords generated based on the response intercepted by
コンテンツセレクタ構成要素118は、チャットボット構成要素118からの応答に基づいて1つまたは複数のキーワードを生成することができる。コンテンツセレクタ構成要素118は、1つまたは複数のキーワードを識別するために応答を構文解析することができる。コンテンツセレクタ構成要素118は、1つまたは複数のキーワードを識別または生成するために、意味論的分析技法、機械学習モデル、パターンマッチング技法、または他のキーワード生成技法を使用することができる。コンテンツセレクタ構成要素118は、キーワードを生成するために、応答に関連するトピックバーティカル(topic vertical)、概念、カテゴリ、商品、サービス、またはエンティティを識別することができる。例えば、「近くのよいレストラン」というクエリに対する応答は、以下の3つの結果、i)レストランA、ii)レストランB、およびiii)レストランCを含むことができる。結果は、レストランの各々において提供される食品のタイプの説明をさらに含むことができる。食品のタイプは、レストランAにおけるハンバーガーおよびフライドポテトと、レストランBにおけるピザおよびパスタと、レストランCにおけるパンケーキおよびワッフルとを含むことができる。コンテンツセレクタ構成要素118は、以下のキーワード、ハンバーガー、フライドポテト、ピザ、パスタ、パンケーキ、およびワッフルを生成するためにこれらの結果を構文解析することができる。コンテンツセレクタ構成要素118は、スポンサー付きデジタル構成要素を選択するために、自動的に生成されたこれらのキーワードをリアルタイムコンテンツ選択プロセスに入力することができる。 Content selector component 118 can generate one or more keywords based on the response from chatbot component 118. Content selector component 118 can parse the response to identify one or more keywords. Content selector component 118 can use semantic analysis techniques, machine learning models, pattern matching techniques, or other keyword generation techniques to identify or generate one or more keywords. Content selector component 118 can identify the topic vertical, concept, category, product, service, or entity associated with the response to generate the keyword. For example, a response to the query "good restaurants nearby" can include the following three results: i) restaurant A, ii) restaurant B, and iii) restaurant C. The results can further include a description of the type of food offered at each of the restaurants. Food types can include burgers and french fries in Restaurant A, pizza and pasta in Restaurant B, and pancakes and waffles in Restaurant C. Content selector component 118 can parse these results to generate the following keywords, hamburgers, french fries, pizza, pasta, pancakes, and waffles. Content selector component 118 can enter these automatically generated keywords into the real-time content selection process to select sponsored digital components.
リアルタイムコンテンツ選択プロセスは、サードパーティコンテンツプロバイダ106によって提供されるスポンサー付きデジタル構成要素を選択することを指すまたは含むことができる。リアルタイムコンテンツ選択プロセスは、コンピューティングデバイス104に提供する1つまたは複数のデジタル構成要素を選択するために、複数のコンテンツプロバイダによって提供されるデジタル構成要素が、構文解析、処理、重み付け、またはマッチングされるサービスを含むことができる。コンテンツセレクタ構文解析118は、リアルタイムでコンテンツ選択プロセスを実行することができる。リアルタイムでコンテンツ選択プロセスを実行することは、クライアントコンピューティングデバイス104を介して受信されるコンテンツに対する要求に応答してコンテンツ選択プロセスを実行することを指すことができる。リアルタイムコンテンツ選択プロセスは、要求を受信する時間間隔(例えば、5秒、10秒、20秒、30秒、1分、2分、3分、5分、10分、または20分)内に実行(例えば、開始または完了)され得る。リアルタイムコンテンツ選択プロセスは、クライアントコンピューティングデバイス104との通信セッション中に、または、通信セッションが終了した後の時間間隔内で実行され得る。
The real-time content selection process can refer to or include the selection of sponsored digital components provided by third-party content provider 106. The real-time content selection process parses, processes, weights, or matches the digital components provided by multiple content providers to select one or more digital components to provide to the
例えば、データ処理システム102は、デジタル構成要素オブジェクトを選択するように設計された、構築された、構成された、または動作可能なコンテンツセレクタ構成要素118を含むことができる。コンテンツセレクタ構成要素118は、画像処理技法、文字認識技法、自然言語処理技法、またはデータベース検索を使用して、候補デジタル構成要素の音声、オーディオ、用語、テキスト、記号、または画像を識別、分析、または認識することができる。候補デジタル構成要素は、候補デジタル構成要素の主題を示すメタデータを含むことができ、その場合、コンテンツセレクタ構成要素118は、候補デジタル構成要素の主題が入力オーディオ信号に対応するかどうかを判定するためにメタデータを処理することができる。 For example, the data processing system 102 can include a content selector component 118 that is designed, constructed, configured, or operational to select digital component objects. Content Selector Component 118 uses image processing techniques, character recognition techniques, natural language processing techniques, or database searches to identify and analyze candidate digital components audio, audio, terminology, text, symbols, or images. Or can be recognized. The candidate digital component can include metadata indicating the subject of the candidate digital component, in which case content selector component 118 determines whether the subject of the candidate digital component corresponds to an input audio signal. You can process the metadata for it.
コンテンツプロバイダ106は、デジタル構成要素を含むコンテンツキャンペーンを設定するときに追加のインジケータを提供することができる。コンテンツプロバイダコンピューティングデバイス106は、コンテンツセレクタ構成要素118が候補デジタル構成要素に関する情報を使用して検索を実行することによって識別できるコンテンツキャンペーンまたはコンテンツグループレベルにおいて情報を提供することができる。例えば、候補デジタル構成要素は、コンテンツグループ、コンテンツキャンペーン、またはコンテンツプロバイダにマッピングすることができる一意の識別子を含んでもよい。コンテンツセレクタ構成要素118は、データリポジトリ122内のコンテンツキャンペーンデータ構造内に記憶された情報に基づいて、コンテンツプロバイダコンピューティングデバイス106に関する情報を判定することができる。 Content provider 106 can provide additional indicators when setting up content campaigns that include digital components. Content provider computing device 106 can provide information at the content campaign or content group level that content selector component 118 can identify by performing a search using information about candidate digital components. For example, a candidate digital component may include a unique identifier that can be mapped to a content group, content campaign, or content provider. The content selector component 118 can determine information about the content provider computing device 106 based on the information stored in the content campaign data structure in the data repository 122.
データ処理システム102は、チャットアプリケーションから第2のクエリに対する応答を傍受することに応答して、コンテンツに対する要求を自動的に生成することができる。データ処理システム102は、コンピューティングデバイス104を介して提供するためのコンテンツに対する要求を受信することができる。要求は、デバイスタイプ、場所、および要求に関連付けられたキーワードのような、要求の選択基準を含むことができる。
The data processing system 102 can automatically generate a request for content in response to intercepting the response to the second query from the chat application. The data processing system 102 can receive a request for content to be provided via the
要求に応答して、データ処理システム102は、データリポジトリ122、またはコンテンツプロバイダコンピューティングデバイス106に関連付けられたデータベースからデジタル構成要素オブジェクトを選択し、ネットワーク105を介して、コンピューティングデバイス104を介して提示するためのデジタル構成要素を提供することができる。デジタル構成要素オブジェクトは、チャットボットプロバイダデバイス108とは異なるコンテンツプロバイダデバイス106によって提供され得る。コンピューティングデバイス104は、デジタル構成要素オブジェクトと対話することができる。コンピューティングデバイス104は、デジタル構成要素に対するオーディオ応答を受信することができる。コンピューティングデバイス104は、コンピューティングデバイス104が、コンテンツプロバイダコンピューティングデバイス106を識別し、コンテンツプロバイダコンピューティングデバイス106からのサービスを要求し、サービスを実行するようにコンテンツプロバイダコンピューティングデバイス106に指示し、情報をコンテンツプロバイダコンピューティングデバイス106に送信し、または、コンテンツプロバイダコンピューティングデバイス106に関連付けられた商品もしくはサービスを他の方法で識別することを行わせるかまたは許可するデジタル構成要素オブジェクトに関連付けられたハイパーリンクまたは他のボタンを選択するための指示を受信することができる。
In response to the request, the data processing system 102 selects a digital component object from the database associated with the data repository 122 or the content provider computing device 106, over the
コンテンツに対する要求は、コンテンツのフォーマット、キーワード、概念、プロファイル情報、または、コンテンツ選択を容易にすることができる他の情報を含むことができる。コンテンツ選択構成要素118は、リアルタイムコンテンツ選択プロセスを実行することができる。リアルタイムコンテンツ選択は、コンテンツに対する要求に応答してコンテンツ選択を実行することを指すことができる。コンテンツに対する要求は、チャットボットが音声入力に応答する対話データ構造を識別した後に生成されるか、送信されるか、または他の方法で提供され得る。 Requests for content can include content formats, keywords, concepts, profile information, or other information that can facilitate content selection. Content selection component 118 can perform a real-time content selection process. Real-time content selection can refer to performing content selection in response to a request for content. Requests for content may be generated, transmitted, or otherwise provided after the chatbot has identified an interactive data structure that responds to voice input.
コンテンツセレクタ構成要素118は、テキスト読み上げシステムによって処理され得るまたはディスプレイを介して提示可能であり得るテキスト、文字列、または文字を含むデジタル構成要素を選択することができる。コンテンツセレクタ構成要素118は、パラメータ的に駆動されるテキスト読み上げ技法のために構成されたパラメータ化フォーマットであるデジタル構成要素を選択することができる。場合によっては、対話データ構造は、SSMLフォーマットであるか、または音声パラメータを用いて構成され得る。データ処理システム102は、デジタル構成要素がネイティブ音声、画像、または音響指紋を用いてコンピューティングデバイス104のユーザに提供され得る(例えば、デジタル構成要素がデジタル構成要素なしの対話データ構造と比較して同じまたは類似の音響特性を有する)ように、チャットボットによって識別された対話データ構造の音声パラメータと一致するようにデジタル構成要素の音声パラメータを構成することができる。
Content selector component 118 can select a digital component containing text, strings, or characters that can be processed by a text-to-speech system or presented through a display. Content selector component 118 can select digital components, which are parameterized formats configured for parameterized text-to-speech techniques. In some cases, the interactive data structure may be in SSML format or constructed using audio parameters. The data processing system 102 may provide digital components to users of
コンテンツセレクタ構成要素118は、オーディオファイルフォーマットであるデジタル構成要素の代わりに、テキスト読み上げのために構成されたパラメータ化フォーマットであるデジタル構成要素を選択することができる。例えば、すでにオーディオファイルフォーマットであるデジタル構成要素は、チャットボットコンピュータプログラムによって識別された対話データ構造のプレースホルダ領域にシームレスに挿入されるように構成されていない場合があるので、コンテンツセレクタ構成要素118は、.WAV、.AIFF、または.AUのようなオーディオファイルフォーマットまたはオーディオコーディングフォーマットであるオーディオファイル内のデジタル構成要素を選択しなくてもよい。オーディオファイルフォーマットにおけるデジタル構成要素は、コンピューティングデバイスのネイティブ音声、またはチャットボットのための音響指紋セットと比較して、異なる音響指紋を有する場合がある。デジタル構成要素オーディオファイルがチャットボットまたは対話データ構造のネイティブ音声または音響指紋と比較して異なる音響指紋を有する(例えば、単語が異なるレートにおいて、異なる周波数、異なるピッチ、異なるトーン、異なる音量、または異なるアクセントにおいて話される)場合、デジタル構成要素オーディオファイルを対話データ構造内のプレースホルダ領域に挿入または統合することは、シームレス、スムーズ、または連続的ではない場合がある。例えば、異なる音響指紋を有するデジタル構成要素オーディオファイルは、ぎこちない遷移または不均衡の表示を引き起こす可能性がある。したがって、チャットボットまたはコンピューティングデバイスがチャットボットまたはコンピューティングデバイスの音響指紋またはネイティブ音声に対応する方法でデジタル構成要素を再生することができるテキスト読み上げ技法のために構成されたデジタル構成要素を提供することによって、データ処理システム102は、チャットボットコンピュータプログラム出力のシームレスな修正の提供を容易にすることができる。 The content selector component 118 can select a digital component which is a parameterized format configured for reading aloud instead of the digital component which is an audio file format. For example, a digital component that is already in an audio file format may not be configured to be seamlessly inserted into the placeholder area of the interactive data structure identified by the chatbot computer program, so the content selector component 118 Does not have to select digital components in an audio file that is an audio file format or audio coding format such as .WAV, .AIFF, or .AU. Digital components in an audio file format may have different acoustic fingerprints as compared to the native voice of a computing device, or an acoustic fingerprint set for a chatbot. Digital component audio files have different acoustic fingerprints compared to native audio or acoustic fingerprints in chatbots or interactive data structures (eg, words at different rates, different frequencies, different pitches, different tones, different volumes, or different Inserting or integrating digital component audio files into placeholder areas within interactive data structures may not be seamless, smooth, or continuous (spoken in accents). For example, digital component audio files with different acoustic fingerprints can cause awkward transitions or imbalances. Therefore, it provides a digital component configured for a text-to-speech technique that allows a chatbot or computing device to reproduce the digital component in a manner that corresponds to the acoustic fingerprint or native voice of the chatbot or computing device. Thereby, the data processing system 102 can facilitate the provision of seamless modifications to the chatbot computer program output.
コンテンツセレクタ構成要素118は、ディスプレイデバイス132を介して表示するように構成されたフォーマットであるデジタル構成要素を選択することができる。コンテンツセレクタ構成要素118は、チャットボットアプリケーションのネイティブ出力フォーマットに一致するように再フォーマットされ得るデジタル構成要素を選択することができる。
The content selector component 118 can select a digital component that is a format configured to be displayed via the
コンテンツセレクタ構成要素118は、リアルタイムコンテンツ選択プロセスを介して複数のデジタル構成要素を選択することができる。コンテンツセレクタ構成要素118は、デジタル構成要素を採点またはランク付けし、出力合併構成要素120が最も高いランキングのデジタル構成要素を選択することを可能にするために、複数のデジタル構成要素を出力合併構成要素120に提供することができる。
Content selector component 118 can select a plurality of digital components via a real-time content selection process. Content selector component 118 outputs multiple digital components to allow digital components to be scored or ranked and
コンテンツセレクタ構成要素118は、選択されたデジタル構成要素を出力合併構成要素120に提供することができる。データ処理システム102は、選択されたデジタル構成要素を、コンピューティングデバイス104を介して提示するためにチャットボットアプリケーションから受信された応答と結合または統合するために、出力合併構成要素120を含むか、実行するか、またはそれと他の方法で通信することができる。出力合併構成要素120は、オーディオ出力または視覚出力のために結合されたデジタル構成要素および応答を提供することができる。
The content selector component 118 can provide the selected digital component to the
冗長エントリを低減し、それによって、コンピューティングデバイス104によるネットワーク帯域幅利用またはプロセッサ利用を防止または低減するために、出力合併構成要素120は、デジタル構成要素とチャットボットアプリケーションによって生成された複数の応答とを用いて重複排除プロセスを実行することができる。重複排除は、コンピュータデータ内の重複または冗長エントリの排除または除去を指すことができる。重複排除技法は、データの1つの一意のインスタンスのみが出力内に保持されることを保証することができる。冗長データエントリは、新しいデータエントリに置き換えられ得る。
In order to reduce redundant entries and thereby prevent or reduce network bandwidth utilization or processor utilization by the
例えば、コンテンツセレクタ構成要素118によって選択されたデジタル構成要素は、レストランAに関するデジタル構成要素を含むことができ、これは、第2のクエリに応答してチャットボットアプリケーションによって生成された応答のうちの1つでもある。この場合、出力合併構成要素120は、デジタル構成要素を削除または除去し、第2のデジタル構成要素(例えば、リアルタイムコンテンツ選択プロセスから出力された第2のランキングのデジタル構成要素)を選択することができる。したがって、重複排除プロセスの結果に基づいて、データ処理システム102は、追加のデジタル構成要素を要求し、デジタル構成要素の挿入をブロックし、またはデジタル構成要素が重複エントリではない場合、デジタル構成要素を追加することができる。
For example, the digital component selected by content selector component 118 can include a digital component for restaurant A, which is one of the responses generated by the chatbot application in response to the second query. There is also one. In this case, the
出力合併構成要素120は、デジタル構成要素とチャットボットアプリケーションによる複数の応答とを用いて実行された重複排除プロセスに応答して、デジタル構成要素を応答に追加することを決定することができる。出力合併構成要素120は、デジタル構成要素が一意であるかまたは応答と異なると判定することができる。出力合併構成要素120は、次いで、デジタル構成要素とチャットボットアプリケーションからの応答とを含む表示出力を構築することができる。
The
グラフィカルユーザインターフェースを介する表示出力のレンダリングを管理し、グラフィックスプロセッサの利用、CPUの利用、またはメモリの利用、ならびに、デジタル構成要素と結果とを送信するときのネットワーク帯域幅の利用を低減するために、出力合併構成要素120は、統一されたグラフィカルレイアウトを使用して表示出力を構築することができる。例えば、応答のための第1のグラフィカルテーマと、異なるレイアウト、スタイル、色、グラフィックスを必要とするデジタル構成要素のための第2の異なるグラフィカルテーマとを使用するのではなく、出力合併構成要素120は、合併されたデータセットのための単一の統一されたグラフィカルテーマおよびレイアウトを使用することを決定することができる。
To manage the rendering of display output through the graphical user interface and reduce the use of graphics processors, CPUs, or memory, as well as network bandwidth usage when transmitting digital components and results. In addition, the
表示出力を構築するために、出力合併構成要素120は、データリポジトリ122内に記憶されたテンプレートデータ構造124から、グラフィカルユーザインターフェーステンプレートを検索することができる。グラフィカルユーザインターフェーステンプレートは、出力合併構成要素120が表示出力を生成するために使用することができるフォント、色、およびレイアウトを定義、提供、設定、または他の方法で示すことができる。出力合併構成要素120は、チャットボットアプリケーションのアプリケーション識別子に基づいて、グラフィカルユーザインターフェーステンプレートを選択することができる。例えば、各アプリケーション識別子(例えば、各チャットボットアプリケーション)は、グラフィカルユーザインターフェーステンプレートを用いて確立され得る。サードパーティチャットボットプロバイダデバイス108は、グラフィカルユーザインターフェーステンプレートを設定、構成、確立、または設計することができる。グラフィカルユーザインターフェーステンプレートは、テキストのためのフォント、色、レイアウト、または他のグラフィカルユーザインターフェース要素もしくは表示要素を含むことができる。場合によっては、グラフィカルユーザインターフェーステンプレートは、アニメーション、透明度、位置決め、サイズ、または音を含むまたは定義することができる。
To build the display output, the
出力合併構成要素120は、テンプレートデータ構造124における探索を実行することによって、テンプレートデータ構造からグラフィカルユーザテンプレートを検索することができる。テンプレートデータ構造124は、グラフィカルユーザインターフェーステンプレートをインデックスデータ構造内に記憶することができる。場合によっては、コンピューティングデバイス104は、好ましいテーマ、レイアウト、応答の数、またはフォントを含むことができる、コンピューティングデバイス104のためのカスタムグラフィカルユーザインターフェースを確立することができる。出力合併構成要素120は、アプリケーション識別子とコンピューティングデバイス104の識別子とから形成されたタプルを生成し、特定のチャットボットアプリケーションのために確立され、コンピューティングデバイス104による使用のためにカスタマイズされたグラフィカルユーザインターフェーステンプレートを検索するためにテンプレートデータ構造124内の探索を実行するためにタプルを使用することができる。
The
場合によっては、出力合併構成要素120は、サードパーティチャットボットプロバイダデバイス108からのグラフィカルユーザインターフェーステンプレートを要求することができる。例えば、出力合併構成要素120は、テンプレートデータ構造124がチャットボットのアプリケーション識別子に対応するグラフィカルユーザテンプレートを含まないこと、または記憶されたグラフィカルユーザテンプレートが期限切れであるか、古いか、もしくは時代遅れであることを判定することができる。出力合併構成要素120は、アプリケーション識別子に対応するサードパーティチャットプロバイダデバイス108に要求を送信し、次いで、要求に応答して、表示出力を構築するために使用するグラフィカルユーザインターフェーステンプレートを受信することができる。出力合併構成要素120は、次いで、受信されたグラフィカルユーザインターフェーステンプレートを用いてデータリポジトリ122内のテンプレートデータ構造124を更新し、後続の表示出力を構築するためにそれを使用することができる。
In some cases, the
出力合併構成要素120は、デジタル構成要素を挿入または配置する、チャットボットアプリケーションから受信された応答間の位置を選択することができる。チャットボットアプリケーションのためのグラフィカルユーザインターフェーステンプレートは、デジタル構成要素を挿入する位置を示すことができる。グラフィカルユーザインターフェーステンプレートは、デジタル構成要素を応答のリストに付加するように指示することができる。グラフィカルユーザインターフェーステンプレートは、応答のリストの前、または応答のリストの中(例えば、第1の応答の後、第2の応答の後、または第3の応答の後)にデジタル構成要素を追加するように指示することができる。応答およびデジタル構成要素がチャットボットアプリケーションなどの同じソースによって提供される外観を提供するために、グラフィカルユーザインターフェーステンプレートは、デジタル構成要素が応答と均一であるようにまたは類似しているように見えるような位置にデジタル構成要素を追加するように指示することができる。
The
場合によっては、出力合併構成要素120は、位置を動的に選択することができる。例えば、出力合併構成要素120は、デジタル構成要素との過去の相互作用を使用して、パフォーマンス情報に基づいて位置を決定することができる。出力合併構成要素120は、デジタル構成要素を挿入する場所を決定するために、機械学習モデルを使用することができる。機械学習モデルは、チャットボットアプリケーションの複数のインスタンスから収集された過去のパフォーマンスデータを用いて生成され得る。パフォーマンスデータは、クリック、選択、またはコンバージョンに関連する特徴を示すことができる。データ処理システム102は、デジタル構成要素との相互作用の指示を受信することができる。デジタル構成要素との相互作用は、コンピューティングデバイス104のインターフェースまたは構成要素を介して起こり得る。データ処理システム102は、デジタル構成要素との相互作用と、相互作用に関するまたは相互作用に関連付けられた情報とを記録、記憶、または他の方法で監視および追跡することができる。
In some cases, the
機械学習モデルは、デジタル構成要素におけるクリック、選択、またはコンバージョンに関連する位置により重く重み付けすることができ、同時に、クリック、選択、またはコンバージョンを受信しない位置に関連する重みを低減する。機械学習モデルは、デジタル構成要素を挿入する位置を決定するために機械学習モデルをカスタマイズするために、異なるタイプのデジタル構成要素、トピック、キーワード、コンピューティングデバイス、または他のパラメータに対して異なるモデルを生成することができる。 Machine learning models can be weighted more heavily on click, selection, or conversion-related positions in digital components, while at the same time reducing weights associated with positions that do not receive clicks, selections, or conversions. Machine learning models are different models for different types of digital components, topics, keywords, computing devices, or other parameters to customize the machine learning model to determine where to insert the digital components. Can be generated.
出力合併構成要素120は、検索されたグラフィカルユーザインターフェーステンプレートを使用して表示出力を構築することができる。出力合併構成要素120は、リアルタイムコンテンツ選択プロセスを介して選択されたデジタル構成要素をチャットボットアプリケーションによって生成された応答と統合することによって、表示出力を構築することができる。出力合併構成要素120は、コンピューティングデバイス104によって表示出力をレンダリングする際の効率を改善するために、グラフィカルユーザテンプレートをデジタル構成要素と応答の両方に均一に適用することができる。表示出力を構築するために、出力合併構成要素120は、デジタル構成要素を応答と統合するために、デジタル構成要素のフォントまたは色を変更することができる。出力合併構成要素120は、コンピューティングデバイス104にディスプレイ132を介して提示するための表示出力をレンダリングさせるために、表示出力をコンピューティングデバイス104に提供することができる。
コンピューティングデバイス104は、デジタルアシスタントデバイスを含む、実行する、またはそれと呼ばれ得る。デジタルアシスタントデバイス(またはコンピューティングデバイス104)は、ディスプレイデバイス132と、グラフィックスドライバ146と、入力オーディオ信号を検出するセンサと、ディスプレイデバイス、グラフィックスドライバ、およびセンサに結合されたプリプロセッサ構成要素140とを含むことができる。グラフィックスドライバ146は、データ処理システム102からの表示出力を受信し、ディスプレイデバイス132において表示出力をレンダリングすることができる。グラフィックスドライバ146は、グラフィックスまたは視覚出力がディスプレイ132上にどのように表示されるかを制御または強化するハードウェアまたはソフトウェアを含むことができる。グラフィックスドライバ146は、例えば、グラフィックス構成要素がコンピューティングデバイス104(またはデジタルアシスタント)の残りの部分とどのように機能するかを制御するプログラムを含むことができる。プリプロセッサ構成要素140は、フィルタリングされた入力オーディオ信号を作成するために入力オーディオ信号をフィルタリングし、フィルタリングされた入力オーディオ信号をデータパケットに変換し、データパケットを、1つまたは複数のプロセッサとメモリとを備えるデータ処理システムに送信する。
The
デジタルアシスタントデバイスは、オーディオドライバ138とスピーカ構成要素(例えば、トランスデューサ136)とを含むことができる。プリプロセッサ構成要素140は、表示出力の指示を受信し、スピーカ構成要素(例えば、トランスデューサ136)に表示出力の指示に対応するオーディオ出力を送信させるために出力オーディオ信号を生成するようにオーディオドライバ138に指示する。オーディオ出力は、例えば、図3におけるテキストボックス312内に描かれたテキストのテキスト読み上げ表現を含むことができる。
The digital assistant device can include an
図2は、グラフィカルユーザインターフェースのレンダリングを管理するシステム200の動作の図である。システム200の動作は、図1に示すシステム100の1つまたは複数の構成要素または機能を含むことができる。例えば、システム200の動作は、データ処理システム102、コンピューティングデバイス104、サードパーティチャットボットプロバイダデバイス108、またはコンテンツプロバイダデバイス106によって実行され得る。ACT202において、コンピューティングデバイス104は、入力オーディオ信号を検出または受信することができる。入力オーディオ信号は、エンドユーザによって話された音声入力を含むことができる。入力オーディオ信号は、第1のクエリを含むことができる。入力オーディオ信号は、アプリケーション識別子を含んでも含まなくてもよい。入力オーディオ信号は、クエリを実行するチャットボットアプリケーションの識別子を含むことができる。入力オーディオ信号は、アプリケーション識別子を含まなくてもよいが、データ処理システム102は、クエリを実行するために呼び出すチャットボットアプリケーションを自動的に決定することができる。場合によっては、入力オーディオ信号がアプリケーション識別子を含まない場合、コンピューティングデバイス104またはデータ処理システム102は、クエリを実行するために使用するチャットボットアプリケーションの指示を提供するようにエンドユーザに要求するオーディオまたは視覚的プロンプトを提供することができる。
FIG. 2 is a diagram of the operation of the
ACT204において、コンピューティングデバイス104は、第1のクエリを示すデータパケットを送信する。データ処理システム102は、第1のクエリを受信することができる。データ処理システム102のNLP構成要素112は、第1のクエリまたはアプリケーション識別子を識別するためにデータパケットを処理することができる。データ処理システム102は、第1のクエリをチャットボット構成要素114に提供することができ、または第1のクエリをサードパーティチャットボットプロバイダサーバ108に直接提供することができる。
In the ACT 204, the
ACT206において、データ処理システム102は、第1のクエリをチャットボット構成要素114に提供することができる。チャットボット構成要素114は、クエリと、応答を生成するためにクエリを実行することができるチャットボットアプリケーションに対応するアプリケーション識別子とを識別することができる。チャットボット構成要素114は、第1のクエリに基づいて第2のクエリを生成することができる。第2のクエリは、チャットボットアプリケーションが第1のクエリに対する応答を生成するのを容易にするフォーマットであり得る。第2のクエリは、クエリに対する応答を生成するためにチャットボットアプリケーションによって必要とされない可能性がある情報を除去することができる。チャットボット構成要素14は、第2のクエリを生成するために、第1のクエリに関する情報を追加することができる。チャットボット構成要素114は、リモートプロシージャコールを低減しながら、サードパーティチャットボットアプリケーションがクエリに対する応答を生成するのを容易にするために、第2のクエリを他の方法構築または生成することができる。例えば、第1のクエリは、コンピューティングデバイス104の位置情報を含まなくてもよいが、位置情報は、応答を生成するために役立つかまたは必要とされる場合がある。チャットボット構成要素114は、位置情報が第1のクエリにおいて欠落していることを検出し、第2のクエリを生成するときに位置情報を含めることをさらに決定することができる。チャットボット構成要素114は、第2のクエリ内の位置情報の欠如が、チャットボットアプリケーションまたはサードパーティチャットボットプロバイダ108がエラーを返すかまたは位置情報に対するプロンプトを生成することを引き起こす可能性があると決定することができるので、チャットボット構成要素114は、位置情報を含めることを決定することができる。したがって、チャットボットアプリケーションまたはサードパーティチャットボットプロバイダ108が、実行時エラーを有するか、または追加の情報に対する後続のプロンプトを生成することを防ぐために、チャットボット構成要素114は、コンピューティングデバイスのための位置情報を積極的かつ自動的に決定し、位置情報を含む第2のクエリを生成することができる。情報を欠落することなく完全な第2のクエリを生成することによって、チャットボット構成要素114は、入力オーディオ信号に対する応答を生成する際の待ち時間または遅延を低減することを容易にすることができる。
In ACT206, the data processing system 102 can provide a first query to the
ACT208において、チャットボット構成要素114は、第2のクエリをサードパーティチャットボットプロバイダ108に提供する。場合によっては、NLP構成要素112またはチャットボット構成要素114は、第1のクエリを変更、修正、または他の方法で調整することなく、第1のクエリをサードパーティチャットボットプロバイダサーバ108に転送することができる。例えば、チャットボット構成要素114は、サードパーティチャットボットプロバイダ108が応答を生成することを可能にするのに十分な情報を第1のクエリが含むと判定することができる。場合によっては、チャットボット構成要素114は、第1のクエリをサードパーティチャットボットプロバイダ108に転送することができ、サードパーティチャットボットプロバイダは、応答を識別することを容易にするために追加情報に対する要求を生成することができる。サードパーティチャットボットプロバイダ108は、追加情報に対する要求をチャットボット構成要素114、データ処理システム102、または直接コンピューティングデバイス104に送信することができる。要求された追加情報を受信すると、サードパーティチャットボットプロバイダ108は、第2のクエリを生成し、第1のクエリにも応答し得る第2のクエリに対する応答を識別することができる。
In ACT208,
サードパーティチャットボットプロバイダデバイス108は、応答を識別するために第2のクエリを実行し、次いで、ACT210において、応答をデータ処理システム102に提供することができる。フック構成要素116は、応答を傍受することができる。例えば、応答は、直接出力合併構成要素122に、または直接コンピューティングデバイス104に行くように意図されている場合がある。フック構成要素116は、応答を傍受し、次いで、ACT212において、応答をコンテンツセレクタ構成要素118に提供することができる。コンテンツセレクタ構成要素118は、応答を構文解析し、応答に基づいて1つまたは複数のキーワードを生成し、次いで、1つまたは複数のキーワードを用いてリアルタイムコンテンツ選択プロセスを実行することができる。コンテンツセレクタ構成要素118は、ACT214において、選択された1つまたは複数のデジタル構成要素を出力合併構成要素122に提供することができる。出力合併構成要素122は、重複排除処理を実行し、グラフィカルユーザインターフェーステンプレートを検索し、デジタル構成要素をサードパーティチャットボットプロバイダデバイス108からの応答と組み合わせる均一の表示出力を構築することができる。出力合併構成要素122は、ACT216において、表示出力をコンピューティングデバイス104に送信または提供することができる。コンピューティングデバイス104は、入力オーディオ信号を提供したエンドユーザに出力を視覚的に提示するために、ディスプレイデバイス132を介して表示出力をレンダリングすることができる。
The third-party
図3は、グラフィカルユーザインターフェースのレンダリングを管理するシステムによって提供されるグラフィカルユーザインターフェースの実装形態の図である。グラフィカルユーザインターフェース300は、図1、図2、または図5に示す1つまたは複数の構成要素またはシステムによって提供され得る。ユーザは、デジタルアシスタント306(例えば、コンピューティングデバイス102によって実行されるデジタルアシスタント)にオーディオ信号を入力することができる。コンピューティングデバイス102によって実行されるデジタルアシスタント306によって提供されるグラフィカルユーザインターフェース300は、ユーザのためのアイコン302を示し、以下の「フードボット、近くのいくつかのよいレストランを提案して」のようにテキストボックス304内に入力オーディオ信号のテキストを視覚的に提示することができる。入力オーディオ信号は、アプリケーション識別子とクエリとを含むことができる。この例では、アプリケーション識別子は、「フードボット」であり、クエリは、「近くのいくつかのよいレストランを提案して」である。デジタルアシスタント306は、アプリケーション識別子を識別することができる。デジタルアシスタント306は、入力オーディオ信号をローカルで後部解析することによって、またはデータパケットをデジタル処理システム102送信し、次いで、アプリケーション識別子の指示を有するデータ処理システム102からの応答を受信することによって、アプリケーション識別子を識別することができる。デジタルアシスタント306は、テキストボックス308内の「フードボットに接続しています」などのステータス指示を提供することができる。場合によっては、デジタルアシスタント306は、ステータスのオーディオ指示を提供することができる。
FIG. 3 is a diagram of a graphical user interface implementation provided by a system that manages the rendering of the graphical user interface. The graphical user interface 300 may be provided by one or more components or systems shown in FIG. 1, FIG. 2, or FIG. The user can input an audio signal to the digital assistant 306 (eg, the digital assistant performed by the computing device 102). The graphical user interface 300 provided by the
データ処理システム102またはデジタルアシスタント306は、クエリに対する応答を取得するために、サードパーティチャットボットプロバイダデバイス108と対話することができる。デジタルアシスタント306またはデータ処理システム102は、受信されたクエリをそのままサードパーティチャットボットプロバイダデバイス108に送信するか、または、サードパーティチャットボットプロバイダデバイス108が応答を識別するのを容易にすることができる第1のクエリに基づく第2のクエリを生成することができる。
The data processing system 102 or
データ処理システム102は、サードパーティチャットボットプロバイダデバイス108からの応答の指示を受信し、キーワードを生成し、デジタル構成要素を識別するためにキーワードを用いてリアルタイムコンテンツ選択プロセッサを実行し、次いで、グラフィカルユーザインターフェーステンプレートを使用してデジタル構成要素を応答と合併することができる。データ処理システム102は、応答と統合されたデジタル構成要素を含む表示出力を提供することができる。
The data processing system 102 receives a response instruction from the third-party
デジタルアシスタント306は、表示出力を受信し、表示出力314をレンダリングすることができる。デジタルアシスタント306は、フードボットのアイコン310を表示し、応答を示すテキストボックス312を含むことができる。例えば、テキストボックス312は、「以下のレストランをお勧めします。3つすべてが4つ星以上で、あなたの位置から5マイル以内です。」を提示することができる。このテキストは、入力クエリ304に対応することができる。例えば、「よい」という入力用語は、フードボット310に4つ星以上のレストランを識別させた可能性がある。「近くの」という入力用語は、フードボット310にコンピューティングデバイス104の現在の位置の5マイル以内のレストランを識別させた可能性がある。
The
表示出力314は、フードボット310のためのグラフィカルユーザインターフェーステンプレートを使用して構築され得る。表示出力314は、サードパーティチャットボットプロバイダデバイス108からの応答と、スポンサー付きデジタル構成要素とを含むことができる。グラフィカルユーザインターフェーステンプレートは、応答およびデジタル構成要素のためのレイアウト、色、およびフォントを定義することができる。例えば、グラフィカルユーザインターフェーステンプレートは、i)応答ごとに別個の行(例えば、4行、レストランごとに1行)を有する単一の列を含むレイアウト、ii)行の左側に配置された応答のためのアイコン320、iii)応答ごとに2行のテキスト、ここで、テキストの第1の行は、太字で下線が引かれたレストランの名前を含み、コロンが続き、レストランで提供される食品の説明が続き、テキストの第2の行は、レストランの住所を含む、を定義することができる。
デジタル構成要素をサードパーティチャットボットサーバからの応答と統合するために、データ処理システム102は、表示出力314を生成するために、チャットボットによって提供された応答と、リアルタイムコンテンツ選択プロセスを介して選択されたデジタル構成要素の両方にグラフィカルユーザテンプレートを適用することができる。デジタル構成要素を応答と統合することは、ルックアンドフィールまたは他のユーザインターフェースの特徴を保存または維持する方法で、デジタル構成要素を応答に追加することを指すことができる。デジタル構成要素を応答と統合することは、ルックアンドフィールまたは他のユーザインターフェースの特徴を保存または維持する方法で、デジタル構成要素を応答と結合することを指すことができる。
To integrate the digital components with the response from the third-party chatbot server, the data processing system 102 selects through the response provided by the chatbot and the real-time content selection process to generate
データ処理システムは、グラフィカルユーザインターフェーステンプレートを使用してデジタル構成要素を応答と統合することができる。グラフィカルユーザインターフェーステンプレートは、デジタル構成要素を応答に付加するように指示することができる。したがって、表示出力314は、i)第1のテキスト行における「ハンバーガーおよびフライドポテト」という説明を第2のテキスト行における「123メインストリート」という住所とともに含むレストランAについての第1の応答314aと、ii)第1のテキスト行における「ピザおよびパスタ」という説明を第2のテキスト行における「456メインストリート」という住所とともに含むレストランBについての第2の応答314bと、iii)第1のテキスト行における「パンケーキおよびワッフル」という説明を第2のテキスト行における「321メインストリート」という住所とともに含むレストランBについての第3の応答314cとを含むことができる。データ処理システム102は、応答314a〜cのために使用されたのと同じグラフィカルユーザインターフェーステンプレートを使用して、レストランDについてのデジタル構成要素314dを付加することができる。データ処理システム102は、応答314a〜cに基づいてキーワードを生成し、キーワードをリアルタイムコンテンツ選択プロセスに入力することによって、レストランDについてのデジタル構成要素を選択することができる。データ処理システム102は、デジタル構成要素が応答314a〜cの同じグラフィカルユーザインターフェース要素と一致するように、デジタル構成要素を応答と統合するために表示出力を構築することができる。例えば、デジタル構成要素は、2行のテキストとアイコン322とを有するレイアウトと一致することができる。デジタル構成要素のためのテキストは、コロンと「ピザおよびサブ」という説明が続く、太字で下線が引かれたレストラン318の名前を含むことができ、第2のテキスト行は、住所を含む。テキスト318は、スタイルと一致するように、レストランAについてのテキスト316と同様に太字にされ、下線を引かれ得る。しかしながら、デジタル構成要素の表示は、それがスポンサー付きデジタル構成要素324であることの指示を含むことによって変化し得る。
Data processing systems can use graphical user interface templates to integrate digital components with responses. Graphical user interface templates can be instructed to attach digital components to the response. Therefore, the display output 314 i) includes the description "hamburgers and french fries" in the first line of text with the address "123 Main Street" in the second line of text, and the
図4は、グラフィカルユーザインターフェースのレンダリングを管理する方法の図である。方法400は、図1、図2、または図5に示す1つまたは複数の構成要素またはシステムによって実行され得る。方法400は、402において、データ処理システムがデータパケットを受信することを含むことができる。データ処理システムは、インターフェースを介してデータパケットを受信することができる。データパケットは、コンピューティングデバイスのセンサによって検出された入力オーディオ信号を含むことができる。例えば、デジタルアシスタントデバイスのマイクロフォンが入力オーディオ信号を検出することができる。
FIG. 4 is a diagram of how to manage the rendering of the graphical user interface.
ACT404において、データ処理システムは、識別子およびクエリを決定することができる。データ処理システムは、アプリケーション識別子と、アプリケーション識別子に対応するアプリケーションに入力されるべき第1のクエリとを決定することができる。データ処理システムは、入力オーディオ信号を処理または構文解析することに基づいて、アプリケーション識別子と第1のクエリとを決定することができる。データ処理システムは、アプリケーション識別子と第1のクエリとを識別するために、自然言語処理技法または意味論的分析技法を適用することができる。アプリケーション識別子は、チャットボットアプリケーションを識別または示すことができる。チャットボットアプリケーションは、クエリを実行または処理するために呼び出され得る。チャットボットアプリケーションは、クエリを処理するように構成された会話アプリケーションプログラミングインターフェースを含むことができる。 In ACT404, the data processing system can determine identifiers and queries. The data processing system can determine the application identifier and the first query that should be entered into the application corresponding to the application identifier. The data processing system can determine the application identifier and the first query based on processing or parsing the input audio signal. The data processing system can apply natural language processing techniques or semantic analysis techniques to distinguish between the application identifier and the first query. The application identifier can identify or indicate the chatbot application. Chatbot applications can be called to execute or process queries. Chatbot applications can include conversational application programming interfaces that are configured to handle queries.
ACT406において、データ処理システムは、第2のクエリを生成および提供することができる。データ処理システムは、第1のクエリに基づいて第2のクエリを生成することができる。データ処理システムは、第1のクエリと、入力オーディオ信号を検出したコンピューティングデバイスに関連する情報とに基づいて第2のクエリを生成することができる。データ処理システムは、第2のクエリを生成するために、第1のクエリを追加情報で補うことができる。例えば、第1のクエリは、「私の近くの」、「近くの」、「すぐ近くの」、「徒歩圏内の」、または「近所の」などの位置関連用語の指示を含むことができる。データ処理システムは(例えば、チャットボット構成要素を介して)、この位置関連用語を識別するために、第1のクエリを構文解析することができる。データ処理システムは、コンピューティングデバイスの現在の位置など、この用語に関連する情報を決定することができる。データ処理システムは、位置情報を含む第2のクエリを生成することができる。例えば、第1のクエリが「私の近くのレストランを見つけて」である場合、第2のクエリは、「カリフォルニア州サンノゼのレストランを見つけて」であり得る。データ処理システムは、チャットボットアプリケーションまたはサードパーティチャットボットプロバイダサーバに第2のクエリを送信または提供することができる。 In ACT406, the data processing system can generate and serve a second query. The data processing system can generate a second query based on the first query. The data processing system can generate a second query based on the first query and the information related to the computing device that detected the input audio signal. The data processing system can supplement the first query with additional information to generate the second query. For example, the first query can include instructions for location-related terms such as "near me," "near," "nearby," "walking distance," or "neighborhood." The data processing system (eg, via a chatbot component) can parse the first query to identify this location-related term. The data processing system can determine information related to this term, such as the current location of the computing device. The data processing system can generate a second query that includes location information. For example, if the first query is "find a restaurant near me", the second query could be "find a restaurant in San Jose, CA". The data processing system can send or serve a second query to the chatbot application or a third-party chatbot provider server.
場合によっては、データ処理システムは、第1のクエリをサードパーティチャットボットプロバイダサーバに直接提供することができる。サードパーティチャットボットプロバイダサーバは、第1のクエリを構文解析し、第1のクエリに対する関連する応答を生成するために追加情報が必要とされる可能性があると判定することができる。第1のクエリを構文解析し、欠落情報を識別すること、または、追加情報が応答を生成することを容易にする可能性があることに応答して、サードパーティサーバは、追加情報に対するプロンプトまたは要求を生成し、プロンプトまたは要求をデータ処理システムまたはコンピューティングデバイスに送信することができる。データ処理システムまたはコンピューティングデバイスは、要求された追加情報を用いてサードパーティサーバからの要求に応答することができる。 In some cases, the data processing system can serve the first query directly to the third-party chatbot provider server. The third-party chatbot provider server can parse the first query and determine that additional information may be needed to generate the relevant response to the first query. In response to syntactically parsing the first query to identify missing information, or in response that additional information may facilitate the generation of a response, the third-party server prompts for additional information or You can generate a request and send a prompt or request to a data processing system or computing device. The data processing system or computing device can respond to requests from third-party servers with additional information requested.
場合によっては、データ処理システムは、クエリをチャットボットアプリケーションに提供することができる。チャットボットアプリケーションは、第1のクエリを受信し、第1のクエリに基づいて第2のクエリを生成することができる。チャットボットアプリケーションは、データ処理システム上で少なくとも部分的に実行することができる。チャットボットアプリケーションは、入力クエリまたは第1のクエリを受信し、応答を生成することを容易にする第2のクエリを生成するために欠落情報を特定するか、または第1のクエリを他の方法で前処理するクエリ入力インターフェースクエリ処理構成要素(例えば、チャットボット構成要素)を含むことができる。チャットボットアプリケーションは、第2のクエリに対する応答を取得するために、第2のクエリをサードパーティチャットボットプロバイダに送信することができる。データ処理システムは、コンピューティングデバイスを介して表示するために、第2のクエリに対する応答を受信することができる。 In some cases, the data processing system can serve the query to the chatbot application. The chatbot application can receive the first query and generate a second query based on the first query. Chatbot applications can run at least partially on a data processing system. The chatbot application receives an input query or a first query and identifies missing information to generate a second query that makes it easier to generate a response, or the first query is another way. Can include query input interface query processing components (eg, chatbot components) that are preprocessed in. The chatbot application can send a second query to a third-party chatbot provider to get a response to the second query. The data processing system can receive a response to the second query for display through the computing device.
ACT408において、データ処理システムは、応答を取得することができる。データ処理システムは、サードパーティチャットボットプロバイダサーバから応答を取得または受信することができる。場合によっては、データ処理システムは、応答がコンピューティングデバイス上で表示される前に、応答を傍受することができる。データ処理システムは、フック構成要素を使用して応答を傍受することができる。応答は、サードパーティチャットボットプロバイダによって、データ処理システムまたはコンピューティングデバイス上で実行されているチャットボットアプリケーションに送信され得る。フック構成要素は、データ処理システムまたはコンピューティングデバイス上で実行されているチャットボットアプリケーション宛の応答を傍受することができる。フック構成要素は、応答を傍受すると、応答をコンテンツセレクタ構成要素にリダイレクトまたは転送することができる。 In ACT408, the data processing system can get the response. The data processing system can get or receive a response from a third-party chatbot provider server. In some cases, the data processing system can intercept the response before it is displayed on the computing device. Data processing systems can use hook components to intercept responses. The response may be sent by a third-party chatbot provider to a chatbot application running on a data processing system or computing device. Hook components can intercept responses destined for chatbot applications running on data processing systems or computing devices. When the hook component intercepts the response, it can redirect or forward the response to the content selector component.
ACT410において、データ処理システムは、キーワードを生成し、デジタル構成要素を識別することができる。データ処理システムは、応答に基づいてキーワードを生成するために、傍受された応答を構文解析することができる。データ処理システムは、キーワードとして使用するために応答内の用語を選択することができる。データ処理システムは、応答に関するトピックを識別するために、応答に意味論的処理を適用することができる。データ処理システムは、コンテンツプロバイダによって提供されたデジタル構成要素を識別するために、自動的に生成されたキーワードを使用してリアルタイムコンテンツ選択プロセスを実行することができる。 In the ACT410, the data processing system can generate keywords and identify digital components. The data processing system can parse the intercepted response to generate keywords based on the response. The data processing system can select terms in the response for use as keywords. The data processing system can apply semantic processing to the response to identify topics related to the response. Data processing systems can use automatically generated keywords to perform a real-time content selection process to identify the digital components provided by the content provider.
ACT412において、データ処理システムは、応答との統合のためにデジタル構成要素を検証するために、応答を用いてデジタル構成要素を重複排除することができる。データ処理システムは、デジタル構成要素がサードパーティコンテンツプロバイダデバイスによって提供された有機的応答のうちの1つと一致しないことを確認するために、重複排除を実行することができる。デジタル構成要素が応答と異なる場合、データ処理システムは、デジタル構成要素を応答に追加することを決定することができる。デジタル構成要素が応答のうちの1つと一致する場合、データ処理システムは、デジタル構成要素の追加をブロックすることを決定し、次いで、第2のデジタル構成要素(例えば、コンテンツ選択プロセスに基づいて2番目に高いランキングのデジタル構成要素)を選択することができる。 In ACT412, the data processing system can use the response to deduplication the digital component in order to verify the digital component for integration with the response. The data processing system can perform deduplication to ensure that the digital components do not match one of the organic responses provided by the third-party content provider device. If the digital component is different from the response, the data processing system can decide to add the digital component to the response. If the digital component matches one of the responses, the data processing system decides to block the addition of the digital component, and then a second digital component (eg, based on the content selection process 2). The highest ranking digital component) can be selected.
ACT414において、データ処理システムは、テンプレートを検索し、応答と統合されたデジタル構成要素を含む表示出力を構築することができる。データ処理システムは、複数の応答をレンダリングするためにフォント、色、およびレイアウトを定義するテンプレート(例えば、ユーザインターフェーステンプレート)を検索することができる。テンプレートは、「Times New Roman」などのフォントの識別子、またはフォントの英数字の識別子を含むことができる。テンプレートは、フォントサイズ、フォントスタイル、文字間隔、または行間隔の指示をさらに含むことができる。テンプレートは、フォントの色、テキストの色、前景色、背景色、アイコンの色、または表示出力を構築するときに使用する他の色のテーマを含むまたは定義することができる。テンプレートは、テキスト、アイコン、応答、境界線、行、または列などのグラフィカル要素の位置などのレイアウトを定義することができる。 In ACT414, the data processing system can search the template and build a display output containing digital components integrated with the response. The data processing system can search for templates that define fonts, colors, and layouts (eg, user interface templates) to render multiple responses. The template can include a font identifier, such as "Times New Roman," or an alphanumeric identifier for the font. Templates can further include instructions for font size, font style, character spacing, or line spacing. Templates can include or define font colors, text colors, foreground colors, background colors, icon colors, or other color themes to use when building display output. Templates can define layouts such as the location of graphical elements such as text, icons, responses, borders, rows, or columns.
グラフィカルユーザインターフェーステンプレートは、様々なフォーマットにおいて提供され得る。例えば、グラフィカルユーザインターフェーステンプレートは、要素が表示画面上にどのように表示されるべきかを定義するために、階層式スタイルシートまたはその要素を使用して提供され得る。グラフィカルユーザインターフェーステンプレートは、ユーザインターフェースキットを使用することができる。グラフィカルユーザインターフェースは、*.PSDファイル(例えば、フォトショップ(登録商標)エディタプログラムファイルフォーマット)を使用することができる。 Graphical user interface templates may be provided in various formats. For example, a graphical user interface template may be provided using a hierarchical style sheet or its elements to define how the elements should be displayed on the display screen. Graphical user interface templates can use user interface kits. The graphical user interface can use * .PSD files (eg, Photoshop® editor program file format).
ACT416において、データ処理システムは、表示出力を提供することができる。データ処理システムは、コンピューティングデバイスに通信可能に結合されたディスプレイデバイスを介して表示するための表示出力をコンピューティングデバイスにレンダリングさせるために、生成された表示出力をコンピューティングデバイスに送信することができる。 In ACT416, the data processing system can provide display output. The data processing system may send the generated display output to the computing device in order for the computing device to render the display output for display through the display device communicatively coupled to the computing device. it can.
図5は、例示的なコンピュータシステム500のブロック図である。コンピュータシステムまたはコンピューティングデバイス500は、システム100、またはデータ処理システム102のようなその構成要素を含むことができ、またはそれらを実装するために使用され得る。データ処理システム102は、インテリジェントパーソナルアシスタントまたは音声ベースのデジタルアシスタントを含むことができる。コンピューティングシステム500は、情報を通信するためのバス505または他の通信構成要素と、情報を処理するためにバス505に結合された処理回路とを含む。コンピューティングシステム500は、情報を処理するためにバスに結合された1つまたは複数のプロセッサ510または処理回路も含むことができる。コンピューティングシステム500は、情報と、プロセッサによって実行されるべき命令とを記憶するためにバス505に結合された、ランダムアクセスメモリ(RAM)または他のダイナミック記憶デバイスのようなメインメモリ515も含む。メインメモリ515は、データリポジトリ122であるか、またはそれを含むことができる。メインメモリ515は、プロセッサ510による命令の実行中に、位置情報、一時変数、または他の中間情報を記憶するためにも使用され得る。コンピューティングシステム500は、プロセッサ510のための静的情報および命令を記憶するためにバス505に結合された読み出し専用メモリ(ROM)520または他のスタティック記憶デバイスをさらに含んでもよい。ソリッドステートデバイス、磁気ディスク、または光ディスクのような記憶デバイス525が、情報および命令を永続的に記憶するためにバス505に結合され得る。記憶デバイス525は、データリポジトリ122を含むか、またはその一部であり得る。
FIG. 5 is a block diagram of an
コンピューティングシステム500は、バス505を介して、ユーザに情報を表示するための液晶ディスプレイまたはアクティブマトリクスディスプレイのようなディスプレイ535に結合されてもよい。英数字と他のキーとを含むキーボードのような入力デバイス530が、情報およびコマンドの選択をプロセッサ510に通信するためにバス505に結合されてもよい。入力デバイス530は、タッチスクリーンディスプレイ535を含むことができる。入力デバイス530は、方向情報およびコマンドの選択をプロセッサ510に通信するため、ならびにディスプレイ535上のカーソル移動を制御するための、マウス、トラックボール、またはカーソル方法キーのようなカーソル制御も含むことができる。ディスプレイ535は、例えば、データ処理システム102、クライアントコンピューティングデバイス150、または図1の他の構成要素の一部であり得る。
The
本明細書で説明するプロセス、システム、および方法は、プロセッサ510がメインメモリ515内に含まれる命令の配列を実行することに応答してコンピューティングシステム500によって実施され得る。そのような命令は、記憶デバイス525のような別のコンピュータ可読媒体からメインメモリ515に読み込まれ得る。メインメモリ515内に含まれる命令の配列の実行は、コンピューティングシステム500に本明細書で説明される例示的なプロセスを実行させる。メインメモリ515内に含まれる命令を実行するために、マルチプロセッシング構成における1つまたは複数のプロセッサが使用されてもよい。ハードワイヤード回路が、本明細書で説明されるシステムおよび方法とともに、ソフトウェア命令の代わりに、またはそれと組み合わせて使用され得る。本明細書で説明されるシステムおよび方法は、ハードウェア回路およびソフトウェアのいかなる特定の組合せにも限定されない。
The processes, systems, and methods described herein may be performed by the
例示的なコンピューティングシステムが図5において説明されているが、本明細書で説明される動作を含む主題は、他のタイプのデジタル電子回路において、または、本明細書で開示される構造およびそれらの構造的等価物を含むコンピュータソフトウェア、ファームウェア、もしくはハードウェアにおいて、またはそれらのうちの1つもしくは複数の組合せにおいて実施され得る。 Although an exemplary computing system is described in FIG. 5, the subject matter including the operations described herein is in other types of digital electronic circuits, or in the structures disclosed herein and them. It can be performed in computer software, firmware, or hardware, including structural equivalents of, or in one or more combinations thereof.
本明細書で開示されるシステムがユーザに関する個人情報を収集するか、または個人情報を使用する場合がある状況について、ユーザは、プログラムもしくは機能が個人情報(例えば、ユーザのソーシャルネットワーク、ソーシャルアクションもしくはアクティビティ、ユーザの好み、またはユーザの場所に関する情報)を収集してもよいかどうかを制御する機会、または、ユーザにより関連する可能性があるコンテンツサーバまたは他のデータ処理システムからのコンテンツを受信するかどうかもしくはその方法を制御する機会が提供されてもよい。加えて、パラメータを生成するときに個人を特定できる情報が除去されるように、特定のデータが、記憶または使用される前に、1つまたは複数の方法で匿名化されてもよい。例えば、個人を特定できる情報がユーザについて決定され得ないように、ユーザの身元が匿名化されてもよく、または、ユーザの特定の位置が決定され得ないように、ユーザの地理的位置が取得されるユーザの地理的位置が(都市、郵便番号、または州レベルのように)一般化されてもよい。したがって、ユーザは、情報がどのように自分に関して収集され、コンテンツサーバによって使用されるかについて制御してもよい。 In situations where the systems disclosed herein may collect or use personal information about the user, the user may have a program or function with the personal information (eg, the user's social network, social action or Opportunity to control whether activity, user preferences, or information about the user's location) may be collected, or receive content from a content server or other data processing system that may be more relevant to the user Opportunities may be provided to control whether or not. In addition, certain data may be anonymized in one or more ways before being stored or used so that personally identifiable information is removed when generating parameters. For example, the user's identity may be anonymized so that personally identifiable information cannot be determined for the user, or the user's geographic location is acquired so that the user's specific location cannot be determined. The geographic location of the user to be used may be generalized (such as at the city, zip code, or state level). Therefore, the user may control how the information is collected about him and used by the content server.
本明細書で説明される主題および動作は、デジタル電子回路において、または、本明細書で開示される構造およびそれらの構造的等価物を含むコンピュータソフトウェア、ファームウェア、もしくはハードウェアにおいて、またはそれらのうちの1つもしくは複数の組合せにおいて実施され得る。本明細書で説明される主題は、データ処理装置による実行のため、またはデータ処理装置の動作を制御するために1つまたは複数のコンピュータ記憶媒体上に符号化された1つまたは複数のコンピュータプログラム、例えば、コンピュータプログラム命令の1つまたは複数の回路として実装され得る。代替的には、または加えて、プログラム命令は、データ処理装置による実行のために適切な受信機装置への送信のために情報を符号化するために生成される人工的に生成された信号、例えば、機械的に生成された電気、光、または電磁信号上に符号化され得る。コンピュータ記憶媒体が、コンピュータ可読記憶媒体、コンピュータ可読記憶基板、ランダムもしくはシリアルアクセスメモリアレイもしくはデバイス、またはそれらのうちの1つまたは複数の組合せであるか、またはそれらの中に含まれ得る。コンピュータ記憶媒体は、伝搬信号ではないが、コンピュータ記憶媒体は、人工的に生成された伝搬信号内に符号化されたコンピュータプログラム命令の発信元または宛先であり得る。コンピュータ記憶媒体はまた、1つまたは複数の別個の構成要素または媒体(例えば、複数のCD、ディスク、または他の記憶デバイス)であるか、またはそれに含まれ得る。本明細書で説明される動作は、1つまたは複数のコンピュータ可読記憶媒体上に記憶されるか、または他のソースから受信されるデータに対してデータ処理装置によって実行され動作として実施され得る。 The subjects and operations described herein are in digital electronic circuits, or in computer software, firmware, or hardware, including the structures disclosed herein and their structural equivalents, or of them. Can be performed in one or more combinations of. The subject matter described herein is one or more computer programs encoded on one or more computer storage media for execution by a data processor or to control the operation of the data processor. , For example, can be implemented as one or more circuits of computer program instructions. Alternatively, or in addition, a program instruction is an artificially generated signal, which is generated to encode information for transmission to a receiver device suitable for execution by a data processor. For example, it can be encoded on a mechanically generated electric, optical, or electromagnetic signal. The computer storage medium may be, or be contained within, a computer-readable storage medium, a computer-readable storage board, a random or serial access memory array or device, or one or a combination thereof. The computer storage medium is not a propagating signal, but the computer storage medium can be the source or destination of a computer program instruction encoded in an artificially generated propagating signal. Computer storage media can also be, or include, one or more distinct components or media (eg, multiple CDs, disks, or other storage devices). The operations described herein may be performed by a data processor and performed as operations on data stored on one or more computer-readable storage media or received from other sources.
「データ処理システム」、「コンピューティングデバイス」、「構成要素」、または「データ処理装置」という用語は、例として、プログラマブルプロセッサ、コンピュータ、システムオンチップ、またはそれらのうちの複数もしくは組合せを含む、様々な装置、デバイス、およびマシンを包含する。装置は、専用論理回路、例えば、FPGA(フィールドプログラマブルゲートアレイ)またはASIC(特定用途向け集積回路)を含むことができる。装置は、ハードウェアに加えて、問題のコンピュータプログラムのための実行環境を作成するコード、例えば、プロセッサファームウェア、プロトコルスタック、データベース管理システム、オペレーティングシステム、クロスプラットフォームランタイム環境、仮想マシン、またはそれらのうちの1つもしくは複数の組合せを構成するコードも含むことができる。装置および実行環境は、ウェブサービス、分散コンピューティング、およびグリッドコンピューティングインフラストラクチャのような、様々な異なるコンピューティングモデルインフラストラクチャを実現することができる。例えば、インターフェース110、チャットボット構成要素114、コンテンツセレクタ構成要素118、出力合併構成要素120、またはNLP構成要素112、および他のデータ処理システム102の構成要素は、1つまたは複数のデータ処理装置、システム、コンピューティングデバイス、またはプロセッサを含むまたは共有することができる。
The terms "data processing system", "computing device", "component", or "data processing device" include, by way of example, programmable processors, computers, system-on-chips, or a plurality or combinations thereof. Includes various devices, devices, and machines. The device can include dedicated logic circuits, such as FPGAs (field programmable gate arrays) or ASICs (application specific integrated circuits). The device, in addition to the hardware, is code that creates an execution environment for the computer program in question, such as processor firmware, protocol stacks, database management systems, operating systems, cross-platform runtime environments, virtual machines, or among them. It can also include code that constitutes one or more combinations of. Equipment and execution environments can implement a variety of different computing model infrastructures, such as web services, distributed computing, and grid computing infrastructures. For example, interface 110,
コンピュータプログラム(プログラム、ソフトウェア、ソフトウェアアプリケーション、アプリ、スクリプト、またはコードとしても知られる)は、コンパイラ型またはインタープリタ型言語、宣言型または手続き型言語を含む任意の形式のプログラミング言語において書かれ得、スタンドアロンプログラムとして、または、モジュール、構成要素、サブルーチン、オブジェクト、もしくはコンピューティング環境における使用に適した他のユニットとしてを含む、任意の形態において展開され得る。コンピュータプログラムは、ファイルシステム内のファイルに対応することができる。コンピュータプログラムは、他のプログラムもしくはデータ(例えば、マークアップ言語文書内に記憶された1つまたは複数のスクリプト)を保持するファイルの一部内に、問題のプログラム専用の単一のファイル内に、または、複数の連携ファイル(例えば、1つまたは複数のモジュール、サブプログラム、またはコードの一部を記憶するファイル)内に記憶され得る。コンピュータプログラムは、1つのコンピュータ上で、または、1つのサイトにおいて配置されるか、もしくは複数のサイトにわたって分散されて通信ネットワークによって相互接続された複数のコンピュータ上で実行されるように展開され得る。 Computer programs (also known as programs, software, software applications, apps, scripts, or code) can be written in any form of programming language, including compiler or interpreted languages, declarative or procedural languages, and stand alone. It can be deployed in any form, including as a program or as a module, component, subroutine, object, or other unit suitable for use in a computing environment. Computer programs can accommodate files in the file system. A computer program may be in a part of a file that holds other programs or data (eg, one or more scripts stored in a markup language document), in a single file dedicated to the program in question, or , Can be stored in multiple linked files (eg, a file that stores one or more modules, subprograms, or parts of code). Computer programs may be deployed to run on one computer, at one site, or on multiple computers distributed across multiple sites and interconnected by communication networks.
本明細書で説明されるプロセスおよび論理フローは、入力データに対して動作して出力を生成することによってアクションを実行するために1つまたは複数のコンピュータプログラム(例えば、データ処理システム102の構成要素)を実行する1つまたは複数のプログラマブルプロセッサによって実行され得る。プロセスおよび論理フローは、専用論理回路、例えば、FPGA(フィールドプログラマブルゲートアレイ)またはASIC(特定用途向け集積回路)によっても実行され得、装置は、専用論理回路、例えば、FPGA(フィールドプログラマブルゲートアレイ)またはASIC(特定用途向け集積回路)としても実装され得る。コンピュータプログラム命令およびデータを記憶するのに適したデバイスは、例として、半導体デバイス、例えば、EPROM、EEPROM、およびフラッシュメモリデバイス、磁気ディスク、例えば、内部ハードディスクまたはリムーバブルディスク、光磁気ディスク、ならびに、CD ROMディスクおよびDVD-ROMディスクを含む、すべての形態の不揮発性メモリ、媒体、およびメモリデバイスを含む。プロセッサおよびメモリは、専用論理回路によって補完され得、またはその中に組み込まれ得る。 The processes and logical flows described herein are components of one or more computer programs (eg, data processing system 102) to perform actions by acting on input data and producing output. ) Can be run by one or more programmable processors. Processes and logic flows can also be performed by dedicated logic circuits such as FPGAs (Field Programmable Gate Arrays) or ASICs (Application Specific Integrated Circuits) and devices are dedicated logic circuits such as FPGAs (Field Programmable Gate Arrays). Alternatively, it can be implemented as an ASIC (application specific integrated circuit). Suitable devices for storing computer program instructions and data include, for example, semiconductor devices such as EPROM, EEPROM, and flash memory devices, magnetic disks such as internal hard disks or removable disks, magneto-optical disks, and CDs. Includes all forms of non-volatile memory, media, and memory devices, including ROM disks and DVD-ROM disks. Processors and memory can be complemented by or incorporated into dedicated logic circuits.
本明細書で説明される主題は、バックエンド構成要素を、例えば、データサーバとして含む、または、ミドルウェア構成要素、例えば、アプリケーションサーバを含む、または、フロントエンド構成要素、例えば、ユーザが本明細書で説明される主題の実装形態と対話することができるグラフィカルユーザインターフェースもしくはウェブブラウザを有するクライアントコンピュータを含む、または、1つまたは複数のそのようなバックエンド、ミドルウェア、またはフロントエンド構成要素の組合せを含むコンピューティングシステムにおいて実装され得る。システムの構成要素は、任意の形態または媒体のデジタルデータ通信、例えば、通信ネットワークによって相互接続され得る。通信ネットワークの例は、ローカルエリアネットワーク(「LAN」)およびワイドエリアネットワーク(「WAN」)、インターネットワーク(例えば、インターネット)、およびピアツーピアネットワーク(例えば、アドホックピアツーピアネットワーク)を含む。 The subject matter described herein includes a back-end component, eg, as a data server, or a middleware component, eg, an application server, or a front-end component, eg, a user. Includes a client computer with a graphical user interface or web browser capable of interacting with the subject implementations described in, or a combination of one or more such backends, middleware, or frontend components. It can be implemented in including computing systems. The components of the system can be interconnected by digital data communication in any form or medium, such as a communication network. Examples of communication networks include local area networks (“LAN”) and wide area networks (“WAN”), internetworks (eg, the Internet), and peer-to-peer networks (eg, ad hoc peer-to-peer networks).
システム100またはシステム500のようなコンピューティングシステムは、クライアントとサーバとを含むことができる。クライアントおよびサーバは、一般に互いに離れており、典型的には通信ネットワーク(例えば、ネットワーク105)を介して対話する。クライアントおよびサーバの関係は、それぞれのコンピュータ上で実行され、互いにクライアント-サーバ関係を有するコンピュータプログラムによって発生する。いくつかの実装形態において、サーバは、データ(例えば、デジタル構成要素を表すデータパケット)をクライアントデバイスに(例えば、クライアントデバイスと対話するユーザにデータを表示し、そのユーザからユーザ入力を受信する目的のために)送信する。クライアントデバイスにおいて生成されたデータ(例えば、ユーザ対話の結果)が、サーバにおいてクライアントデバイスから受信(例えば、コンピューティングデバイス104またはクライアントプロバイダコンピューティングデバイス106またはチャットボットプロバイダコンピューティングデバイス108からデータ処理システム102によって受信)され得る。
A computing system such as
動作が特定の順序において図面中に描かれているが、そのような動作は、図示された特定の順序において、または連続した順序において実行される必要はなく、すべての図示された動作が実行される必要はない。本明細書で説明されるアクションは、異なる順序において実行され得る。 Although the actions are depicted in the drawing in a particular order, such actions need not be performed in the particular order shown or in a contiguous order, and all the illustrated actions are performed. There is no need to The actions described herein can be performed in a different order.
様々なシステム構成要素の分離は、すべての実装形態において分離を必要とせず、説明されたプログラム構成要素は、単一のハードウェアまたはソフトウェア製品内に含まれ得る。例えば、NLP構成要素112またはコンテンツセレクタ構成要素118は、単一の構成要素、アプリ、もしくはプログラム、または、1つもしくは複数の処理回路を有する論理デバイス、または、データ処理システム102の1つまたは複数のサーバの一部であり得る。
Separation of various system components does not require separation in all implementations, and the described program components can be contained within a single hardware or software product. For example,
ここで、いくつかの例示的な実装形態について説明してきたが、上記は、例示であり、限定ではなく、例として提示されたことは、明らかである。具体的には、本明細書で提示される例の多くは、方法の行為またはシステムの要素の特定の組合せを含むが、それらの行為およびそれらの要素は、同じ目的を達成するために他の方法において組み合わされてもよい。1つの実装形態に関連して論じられた行為、要素、および特徴は、他の実装形態または実施形態における同様の役割から除外されることを意図していない。 Although some exemplary implementations have been described here, it is clear that the above are examples, not limitations, and are presented as examples. Specifically, many of the examples presented herein include specific combinations of method actions or elements of the system, but those actions and those elements are other to achieve the same purpose. They may be combined in a method. Actions, elements, and features discussed in connection with one implementation are not intended to be excluded from similar roles in other implementations or embodiments.
本明細書で使用される表現法および用語法は、説明の目的のためのものであり、限定とみなされるべきではない。本明細書における「含む」、「備える」、「有する」、「含有する」、「伴う」、「によって特徴付けられる」、「ことを特徴とする」、およびそれらの変形の使用は、その後に列挙されたアイテム、その等価物、および追加のアイテムを、排他的にその後に列挙されたアイテムからなる代替の実装形態と同様に包含することを意味する。一実装形態では、本明細書で説明されるシステムおよび方法は、説明されている要素、行為、または構成要素のうちの1つ、2つ以上の各組合せ、またはすべてからなる。 The expressions and terminology used herein are for explanatory purposes only and should not be considered limiting. The use of "contains", "provides", "has", "contains", "accompanied", "characterized by", "characterized by", and variants thereof herein follows. It is meant to include the enumerated items, their equivalents, and additional items exclusively, as well as an alternative implementation consisting of the enumerated items thereafter. In one implementation, the systems and methods described herein consist of one, two or more combinations, or all of the elements, actions, or components described.
単数形において言及される本明細書におけるシステムおよび方法の実装形態または要素または行為への任意の参照は、複数のこれらの要素を含む実装形態も包含してもよく、本明細書における任意の実装形態または要素または行為への複数形における任意の言及は、単一の要素のみを含む実装形態も包含してもよい。単数形または複数形における言及は、現在開示されているシステムまたは方法、それらの構成要素、行為、または要素を単数形または複数形に限定することを意図していない。任意の情報、行為、または要素に基づく任意の行為または要素への言及は、行為または要素が任意の情報、行為、または要素に少なくとも部分的に基づく実装形態を含んでもよい。 Any reference to an implementation or element or action of a system and method herein referred to in the singular may also include an implementation that includes more than one of these elements, and any implementation herein. Any reference to a form or element or act in the plural may also include an implementation that includes only a single element. References in the singular or plural are not intended to limit the currently disclosed systems or methods, their components, actions, or elements to the singular or plural. References to any action or element based on any information, action, or element may include an implementation in which the action or element is at least partially based on any information, action, or element.
本明細書で開示される任意の実装形態は、任意の他の実装形態または実施形態と組み合わされてもよく、「実装形態」、「いくつかの実装形態」、「1つの実装形態」などへの言及は、必ずしも相互に排他的ではなく、実装形態に関連して本明細書で説明される特定の特徴、構造、または特性が少なくとも1つの実装形態または実施形態内に含まれてもよいことを示すことを意図している。本明細書で使用されるそのような用語は、必ずしもすべてが同じ実装形態を指すというわけではない。任意の実装形態は、本明細書で開示される態様および実装形態と一致する任意の方法において、包括的または排他的に任意の他の実装形態と組み合わされてもよい。 Any of the embodiments disclosed herein may be combined with any other implementation or embodiment to "implementation", "several implementations", "one implementation", etc. References are not necessarily mutually exclusive and that specific features, structures, or properties described herein in relation to an implementation may be included within at least one implementation or embodiment. Is intended to show. Such terms as used herein do not necessarily refer to the same implementation. Any implementation may be comprehensively or exclusively combined with any other implementation in any manner consistent with the aspects and implementations disclosed herein.
「または」への言及は、「または」を使用して説明される任意の用語が説明される用語のうちの1つ、2つ以上、およびすべてのいずれかを示してもよいように、包括的と解釈されてもよい。例えば、「「A」および「B」のうちの少なくとも1つ」は、「A」のみ、「B」のみ、ならびに「A」と「B」の両方を含むことができる。「備える」または他の開いた用語法(open terminology)と組み合わせて使用されるそのような言及は、追加のアイテムを含むことができる。 References to "or" are inclusive so that any term described using "or" may indicate one, two or more, and all of the terms described. It may be interpreted as a target. For example, "at least one of" A "and" B "" can include only "A", only "B", and both "A" and "B". Such references used in combination with "provide" or other open terminology may include additional items.
図面、詳細な説明、または任意の請求項における技術的特徴の後に参照符号が続く場合、参照符号は、図面、詳細な説明、および特許請求の範囲の明瞭さを高めるために含まれている。したがって、参照符号もそれらの不在も、どのようなクレーム要素の範囲に対しても何ら限定的な影響を持たない。 If a drawing, detailed description, or technical feature in any claim is followed by a reference code, the reference code is included to enhance the clarity of the drawings, detailed description, and claims. Therefore, neither the reference codes nor their absence have any limiting effect on the scope of any claim element.
本明細書で説明されるシステムおよび方法は、その特徴から逸脱することなく、他の特定の形態において具体化されてもよい。例えば、データ処理システム102は、入力オーディオ信号に基づいて第1のクエリを識別し、第2のクエリを生成することなく、第1のクエリに対する応答を生成するために、第1のクエリをサードパーティチャットボットプロバイダデバイスに送信することができる。前述の実装形態は、説明されたシステムおよび方法を制限するのではなくて例示的である。したがって、説明されたシステムおよび方法の範囲は、前述の説明ではなく、添付の特許請求の範囲によって示され、特許請求の範囲と同等の意味および範囲内に入る変更は、その中に取り入れられる。 The systems and methods described herein may be embodied in other particular forms without departing from their characteristics. For example, the data processing system 102 identifies the first query based on the input audio signal and thirds the first query to generate a response to the first query without generating the second query. Can be sent to a party chatbot provider device. The implementations described above are exemplary rather than limiting the systems and methods described. Therefore, the scope of the described system and method is indicated by the appended claims rather than the aforementioned description, and changes that fall within the meaning and scope of the claims are incorporated therein.
100 システム
102 データ処理システム
104 クライアントコンピューティングデバイス、コンピューティングデバイス
105 ネットワーク
106 コンテンツプロバイダコンピューティングデバイス、コンテンツプロバイダ、コンテンツプロバイダデバイス
108 チャットボットプロバイダデバイス、チャットボットプロバイダ、チャットボットプロバイダコンピューティングデバイス、サードパーティチャットボットプロバイダデバイス、サードパーティチャットボットプロバイダ
110 インターフェース
112 自然言語プロセッサ構成要素、NLP構成要素
114 チャットボット構成要素
116 フック構成要素
118 コンテンツセレクタ構成要素
120 出力合併構成要素
122 データリポジトリ
124 テンプレート、テンプレートデータ構造
126 履歴データ
128 コンテンツデータ
130 チャットボットデータ、チャットボットデータ構造
132 ディスプレイ、ディスプレイデバイス
134 センサ
136 トランスデューサ
138 オーディオドライバ
140 プリプロセッサ
142 チャットボットプロバイダ自然言語プロセッサ構成要素、チャットボットプロバイダ自然言語プロセッサ(NLP)構成要素、チャットボットプロバイダNLP構成要素、チャットボットプロバイダNLP、NLP構成要素、会話API
144 チャットボットプロバイダインターフェース
146 グラフィックスドライバ
200 システム
300 グラフィカルユーザインターフェース
302 アイコン
304 テキストボックス、入力クエリ
306 デジタルアシスタント
308 テキストボックス
310 アイコン、フードボット
312 テキストボックス
314 表示出力
314a 応答
314b 応答
314c 応答
314d デジタル構成要素
316 テキスト
318 レストラン、テキスト
320 アイコン
322 アイコン
324 スポンサー付きデジタル構成要素
400 方法
500 コンピュータシステム、コンピュータシステムまたはコンピューティングデバイス、システム、コンピューティングシステム
505 バス
510 プロセッサ
515 メインメモリ
520 読み出し専用メモリ(ROM)
525 記憶デバイス
530 入力デバイス
535 ディスプレイ
100 systems
102 Data processing system
104 Client Computing Device, Computing Device
105 network
106 Content Provider Computing Devices, Content Providers, Content Provider Devices
108 Chatbot Provider Device, Chatbot Provider, Chatbot Provider Computing Device, Third Party Chatbot Provider Device, Third Party Chatbot Provider
110 interface
112 Natural Language Processor Components, NLP Components
114 Chatbot components
116 Hook components
118 Content Selector Component
120 Output merger component
122 Data repository
124 Template, template data structure
126 Historical data
128 content data
130 Chatbot data, chatbot data structure
132 Display, display device
134 sensor
136 Transducer
138 Audio driver
140 preprocessor
142 Chatbot Provider Natural Language Processor Component, Chatbot Provider Natural Language Processor (NLP) Component, Chatbot Provider NLP Component, Chatbot Provider NLP, NLP Component, Conversation API
144 Chatbot Provider Interface
146 graphics driver
200 system
300 graphical user interface
302 icon
304 textbox, input query
306 Digital Assistant
308 text box
310 icon, food bot
312 text box
314 display output
314a response
314b response
314c response
314d Digital component
316 text
318 restaurant, text
320 icons
322 icon
324 Sponsored Digital Components
400 methods
500 Computer system, computer system or computing device, system, computing system
505 bus
510 processor
515 main memory
520 Read-only memory (ROM)
525 storage device
530 input device
535 display
Claims (20)
自然言語プロセッサ構成要素とインターフェースと出力合併構成要素とコンテンツセレクタ構成要素とを実行するために、1つまたは複数のプロセッサとメモリとを有するデータ処理システムを備え、前記データ処理システムが、
前記インターフェースを介して、コンピューティングデバイスのセンサによって検出された入力オーディオ信号を備えるデータパケットを受信し、
前記入力オーディオ信号から、アプリケーション識別子と第1のクエリとを決定し、
前記第1のクエリと前記コンピューティングデバイスに関連する情報とに基づいて第2のクエリを生成し、
前記コンピューティングデバイスを介する表示のための前記第2のクエリに対する複数の応答をアプリケーションに識別させるために、前記アプリケーション識別子に対応する前記アプリケーションを提供するサードパーティサーバに前記第2のクエリを提供し、
前記コンピューティングデバイスにおける表示の前に前記アプリケーションから、前記サードパーティサーバに送信された前記第2のクエリに応答して前記アプリケーションによって識別された前記複数の応答を取得し、
前記複数の応答に基づいてキーワードを生成するために、前記複数の応答を構文解析し、
前記キーワードの生成に応答して、前記サードパーティサーバから取得された前記複数の応答に基づいて生成された前記キーワードを用いてリアルタイムコンテンツ選択プロセスを実行し、
前記リアルタイムコンテンツ選択プロセスに基づいて、コンテンツプロバイダデバイスによって提供されるデジタル構成要素を識別し、
前記デジタル構成要素と前記アプリケーションによって生成された前記複数の応答とを用いて重複排除プロセスを実行し、
前記デジタル構成要素と前記アプリケーションによって生成された前記複数の応答とを用いて実行された前記重複排除プロセスに応答して、前記デジタル構成要素を前記複数の応答に追加することを決定し、
前記アプリケーションに対して、前記複数の応答をレンダリングするためにフォント、色、およびレイアウトを定義するグラフィカルユーザインターフェーステンプレートを検索し、
前記アプリケーションによって生成された前記複数の応答を前記リアルタイムコンテンツ選択プロセスに基づいて識別された前記デジタル構成要素と統合する前記グラフィカルユーザインターフェーステンプレートを使用して表示出力を構築し、
前記コンピューティングデバイスに通信可能に結合されたディスプレイデバイスを介する表示のための前記表示出力を前記コンピューティングデバイスにレンダリングさせるために、前記コンピューティングデバイスに前記表示出力を提供する、
システム。 A system that manages the rendering of graphical user interfaces in a voice-driven computing environment.
A data processing system comprising one or more processors and memory for executing a natural language processor component, an interface, an output merged component, and a content selector component.
Through the interface, a data packet containing an input audio signal detected by a sensor of a computing device is received and
From the input audio signal, the application identifier and the first query are determined.
Generate a second query based on the first query and information related to the computing device.
The second query is provided to a third party server that provides the application corresponding to the application identifier in order to allow the application to identify multiple responses to the second query for display through the computing device. ,
Obtaining the plurality of responses identified by the application in response to the second query sent from the application to the third party server prior to display on the computing device.
To generate keywords based on the plurality of responses, the plurality of responses are parsed and
In response to the keyword generation, a real-time content selection process is performed using the keywords generated based on the plurality of responses obtained from the third party server.
Based on the real-time content selection process, identify the digital components provided by the content provider device and
The deduplication process is performed using the digital components and the plurality of responses generated by the application.
In response to the deduplication process performed with the digital component and the plurality of responses generated by the application, it was decided to add the digital component to the plurality of responses.
Search for a graphical user interface template that defines fonts, colors, and layouts for the application to render the multiple responses.
Display output is constructed using the graphical user interface template that integrates the plurality of responses generated by the application with the digital components identified based on the real-time content selection process.
To provide the computing device with the display output for display via a display device communicatively coupled to the computing device.
system.
位置関連用語を識別するために前記第1のクエリを構文解析し、
前記位置関連用語の識別に基づいて、前記コンピューティングデバイスの位置を決定し、
前記第2のクエリを生成するために、前記コンピューティングデバイスの前記位置を前記第1のクエリに挿入する、
請求項1に記載のシステム。 The data processing system
Parsing the first query to identify location-related terms
Based on the identification of the position-related terms, the position of the computing device is determined.
Insert the position of the computing device into the first query to generate the second query.
The system according to claim 1.
前記アプリケーションを提供する前記サードパーティサーバに、前記グラフィカルユーザインターフェーステンプレートに対する要求を送信し、
前記要求に応答して、前記グラフィカルユーザインターフェーステンプレートを受信し、
前記グラフィカルユーザインターフェーステンプレートを前記データ処理システムのデータリポジトリ内に記憶する、
請求項1に記載のシステム。 The data processing system
Send a request for the graphical user interface template to the third party server that provides the application.
In response to the request, the graphical user interface template is received and
Store the graphical user interface template in the data repository of the data processing system.
The system according to claim 1.
前記デジタル構成要素を前記表示出力のための前記複数の応答と統合するために、前記デジタル構成要素の前記フォントおよび前記色のうちの少なくとも1つを変更する、
請求項1に記載のシステム。 The data processing system
Modifying at least one of the font and the color of the digital component to integrate the digital component with the plurality of responses for the display output.
The system according to claim 1.
前記複数の応答間の位置を選択し、
前記表示出力を構築するために、前記デジタル構成要素を前記複数の応答間の前記位置に追加する、
請求項1に記載のシステム。 The data processing system
Select the position between the multiple responses and
To build the display output, add the digital component to the position between the responses.
The system according to claim 1.
前記アプリケーションの複数のインスタンスから収集された過去のパフォーマンスデータを用いて生成された機械学習モデルに基づいて、前記複数の応答間の位置を選択し、
前記表示出力を構築するために、前記デジタル構成要素を前記複数の応答間の前記位置に追加する、
請求項1に記載のシステム。 The data processing system
Based on a machine learning model generated using historical performance data collected from multiple instances of the application, the position between the multiple responses is selected.
To build the display output, add the digital component to the position between the responses.
The system according to claim 1.
請求項1に記載のシステム。 The data processing system parses each of the plurality of responses using semantic analysis techniques to identify the keyword.
The system according to claim 1.
前記アプリケーション識別子と前記コンピューティングデバイスの識別子とから形成されたタプルを生成し、
前記アプリケーション識別子と前記コンピューティングデバイスの識別子とから形成された前記タプルに基づいて、前記グラフィカルユーザインターフェーステンプレートを選択する、
請求項1に記載のシステム。 The data processing system
Generates a tuple formed from the application identifier and the computing device identifier.
Select the graphical user interface template based on the tuple formed from the application identifier and the computing device identifier.
The system according to claim 1.
前記コンピューティングデバイスの前記センサによって検出された第2の入力信号に基づいて選択された第2の複数の応答に応答して第2のデジタル構成要素を受信し、
前記第2のデジタル構成要素と、前記アプリケーションによって生成された前記第2の複数の応答とを用いて第2の重複排除プロセスを実行し、
前記デジタル構成要素と、前記アプリケーションによって生成された前記複数の応答とを用いて実行された前記第2の重複排除プロセスに応答して、前記第2のデジタル構成要素が前記第2の複数の応答のうちの1つと一致すると判定し、
前記第2の複数の応答への前記第2のデジタル構成要素の追加をブロックする、
請求項1に記載のシステム。 The data processing system
The second digital component is received in response to a second plurality of responses selected based on the second input signal detected by the sensor of the computing device.
A second deduplication process is performed using the second digital component and the second plurality of responses generated by the application.
The second digital component responds to the second deduplication process performed using the digital component and the plurality of responses generated by the application. Judged to match one of
Block the addition of the second digital component to the second plurality of responses.
The system according to claim 1.
前記コンピューティングデバイスの前記センサによって検出された第2の入力信号に基づいて選択された第2の複数の応答に応答して第2のデジタル構成要素を受信し、
前記第2のデジタル構成要素と、前記アプリケーションによって生成された前記第2の複数の応答とを用いて第2の重複排除プロセスを実行し、
前記デジタル構成要素と、前記アプリケーションによって生成された前記複数の応答とを用いて実行された前記第2の重複排除プロセスに応答して、前記第2のデジタル構成要素が前記第2の複数の応答のうちの1つと一致すると判定し、
前記第2のデジタル構成要素が前記第2の複数の応答のうちの1つと一致するという判定に応答して、第3のデジタル構成要素を選択し、
前記ディスプレイデバイスを介する表示のための前記第3のデジタル構成要素を前記第2の複数の応答に追加する、
請求項1に記載のシステム。 The data processing system
The second digital component is received in response to a second plurality of responses selected based on the second input signal detected by the sensor of the computing device.
A second deduplication process is performed using the second digital component and the second plurality of responses generated by the application.
The second digital component responds to the second deduplication process performed using the digital component and the plurality of responses generated by the application. Judged to match one of
In response to the determination that the second digital component matches one of the second plurality of responses, the third digital component is selected.
Adding the third digital component for display through the display device to the second plurality of responses.
The system according to claim 1.
1つまたは複数のプロセッサを備えるデータ処理システムのインターフェースを介して、コンピューティングデバイスのセンサによって検出された入力オーディオ信号を備えるデータパケットを受信するステップと、
前記データ処理システムによって、前記入力オーディオ信号から、アプリケーション識別子と、前記アプリケーション識別子に対応するアプリケーションに入力するための第1のクエリとを決定するステップと、
前記データ処理システムによって、前記第1のクエリに基づいて第2のクエリを生成するステップと、
前記データ処理システムによって、前記コンピューティングデバイスを介する表示のための前記第2のクエリに対する複数の応答をサードパーティサーバに識別させるために、前記第2のクエリを前記サードパーティサーバに提供するステップと、
前記データ処理システムによって、前記コンピューティングデバイスにおける表示の前に前記アプリケーションから、前記サードパーティサーバに送信された前記第2のクエリに応答して前記アプリケーションによって識別された前記複数の応答を取得するステップと、
前記データ処理システムによって、前記複数の応答に基づいてキーワードを生成するために、前記複数の応答を構文解析するステップと、
前記データ処理システムによって、前記キーワードの生成に応答して、前記アプリケーションから傍受された前記複数の応答に基づいて生成された前記キーワードを用いてリアルタイムコンテンツ選択プロセスを実行するステップと、
前記データ処理システムによって、前記リアルタイムコンテンツ選択プロセスに基づいて、コンテンツプロバイダデバイスによって提供されるデジタル構成要素を識別するステップと、
前記データ処理システムによって、前記デジタル構成要素と前記アプリケーションによって生成された前記複数の応答とを用いて重複排除プロセスを実行するステップと、
前記データ処理システムによって、前記デジタル構成要素と前記アプリケーションによって生成された前記複数の応答とを用いて実行された前記重複排除プロセスに応答して、前記デジタル構成要素を前記複数の応答に追加することを決定するステップと、
前記データ処理システムによって、前記アプリケーションに対して、前記複数の応答をレンダリングするためにフォント、色、およびレイアウトを定義するグラフィカルユーザインターフェーステンプレートを検索するステップと、
前記データ処理システムによって、前記アプリケーションによって生成された前記複数の応答を前記リアルタイムコンテンツ選択プロセスに基づいて識別された前記デジタル構成要素と統合する前記グラフィカルユーザインターフェーステンプレートを使用して表示出力を構築するステップと、
前記データ処理システムによって、前記コンピューティングデバイスに通信可能に結合されたディスプレイデバイスを介する表示のための前記表示出力を前記コンピューティングデバイスにレンダリングさせるために、前記コンピューティングデバイスに前記表示出力を提供するステップと
を含む、方法。 A way to manage the rendering of graphical user interfaces in a voice-driven computing environment.
A step of receiving a data packet with an input audio signal detected by a sensor in a computing device through the interface of a data processing system with one or more processors.
A step of determining an application identifier and a first query for inputting to an application corresponding to the application identifier from the input audio signal by the data processing system.
A step of generating a second query based on the first query by the data processing system.
With the step of providing the second query to the third party server in order for the data processing system to identify the plurality of responses to the second query for display through the computing device. ,
The step of obtaining the plurality of responses identified by the application in response to the second query sent from the application to the third party server before the display on the computing device by the data processing system. When,
A step of parsing the plurality of responses in order to generate a keyword based on the plurality of responses by the data processing system.
In response to the generation of the keyword by the data processing system, a step of executing a real-time content selection process using the keyword generated based on the plurality of responses intercepted by the application.
A step of identifying the digital components provided by the content provider device by the data processing system based on the real-time content selection process.
A step of performing a deduplication process by the data processing system using the digital components and the plurality of responses generated by the application.
Adding the digital component to the plurality of responses in response to the deduplication process performed by the data processing system using the digital component and the plurality of responses generated by the application. And the steps to decide
A step of searching the application for a graphical user interface template that defines fonts, colors, and layouts for rendering the plurality of responses by the data processing system.
A step of constructing a display output using the graphical user interface template that integrates the plurality of responses generated by the application by the data processing system with the digital components identified based on the real-time content selection process. When,
The data processing system provides the computing device with the display output in order for the computing device to render the display output for display via a display device communicatively coupled to the computing device. Methods, including steps.
前記表示出力を構築するために、前記デジタル構成要素を前記複数の応答間の前記位置に追加するステップと
を含む、請求項12に記載の方法。 The step of selecting the position between the plurality of responses and
12. The method of claim 12, comprising adding the digital component to the position between the plurality of responses in order to construct the display output.
前記表示出力を構築するために、前記デジタル構成要素を前記複数の応答間の前記位置に追加するステップと
を含む、請求項12に記載の方法。 A step of selecting a position between the multiple responses based on a machine learning model generated using historical performance data collected from multiple instances of the application.
12. The method of claim 12, comprising adding the digital component to the position between the plurality of responses in order to construct the display output.
前記アプリケーション識別子と前記コンピューティングデバイスの識別子とから形成された前記タプルに基づいて、前記グラフィカルユーザインターフェーステンプレートを選択するステップと
を含む、請求項12に記載の方法。 A step of generating a tuple formed from the application identifier and the computing device identifier,
12. The method of claim 12, comprising the step of selecting the graphical user interface template based on the tuple formed from the application identifier and the identifier of the computing device.
グラフィックスドライバと、
入力オーディオ信号を検出するセンサと、
前記ディスプレイデバイス、前記グラフィックスドライバ、および前記センサに結合されたプリプロセッサ構成要素と
を備えるデジタルアシスタントデバイスであって、前記プリプロセッサ構成要素が、
フィルタリングされた入力オーディオ信号を作成するために前記入力オーディオ信号をフィルタリングし、
前記フィルタリングされた入力オーディオ信号をデータパケットに変換し、
自然言語プロセッサ構成要素とインターフェースと出力合併構成要素とコンテンツセレクタ構成要素とを実行する1つまたは複数のプロセッサとメモリとを備えるデータ処理システムに前記データパケットを送信し、前記データ処理システムが、
前記インターフェースを介して、コンピューティングデバイスの前記センサによって検出された前記入力オーディオ信号を備えるデータパケットを受信し、
前記入力オーディオ信号から、アプリケーション識別子と第1のクエリとを決定し、
前記第1のクエリと前記コンピューティングデバイスに関連する情報とに基づいて第2のクエリを生成し、
前記コンピューティングデバイスを介する表示のための前記第2のクエリに対する複数の応答をアプリケーションに識別させるために、前記アプリケーション識別子に対応する前記アプリケーションを提供するサードパーティサーバに前記第2のクエリを提供し、
前記コンピューティングデバイスにおける表示の前に前記アプリケーションから、前記サードパーティサーバに送信された前記第2のクエリに応答して前記アプリケーションによって識別された前記複数の応答を取得し、
前記複数の応答に基づいてキーワードを生成するために、前記複数の応答を構文解析し、
前記キーワードの生成に応答して、前記アプリケーションから傍受された前記複数の応答に基づいて生成された前記キーワードを用いてリアルタイムコンテンツ選択プロセスを実行し、
前記リアルタイムコンテンツ選択プロセスに基づいて、コンテンツプロバイダデバイスによって提供されるデジタル構成要素を識別し、
前記デジタル構成要素と前記アプリケーションによって生成された前記複数の応答とを用いて重複排除プロセスを実行し、
前記デジタル構成要素と前記アプリケーションによって生成された前記複数の応答とを用いて実行された前記重複排除プロセスに応答して、前記デジタル構成要素を前記複数の応答に追加することを決定し、
前記アプリケーションに対して、前記複数の応答をレンダリングするためにフォント、色、およびレイアウトを定義するグラフィカルユーザインターフェーステンプレートを検索し、
前記アプリケーションによって生成された前記複数の応答を前記リアルタイムコンテンツ選択プロセスに基づいて識別された前記デジタル構成要素と統合する前記グラフィカルユーザインターフェーステンプレートを使用して表示出力を構築し、
前記デジタルアシスタントデバイスに通信可能に結合されたディスプレイデバイスを介する表示のための前記表示出力を前記デジタルアシスタントデバイスにレンダリングさせるために、前記デジタルアシスタントデバイスに前記表示出力を提供し、
前記グラフィックスドライバが、前記表示出力に対応する視覚的指示を前記ディスプレイデバイスに提示させるために前記表示出力をレンダリングする、
デジタルアシスタントデバイス。 With display devices
Graphics driver and
A sensor that detects the input audio signal and
A digital assistant device comprising the display device, the graphics driver, and a preprocessor component coupled to the sensor, wherein the preprocessor component is:
Filtering the input audio signal to create a filtered input audio signal,
The filtered input audio signal is converted into a data packet and
The data packet is transmitted to a data processing system comprising one or more processors and memory that executes a natural language processor component, an interface, an output merger component, and a content selector component.
Through the interface, a data packet containing the input audio signal detected by the sensor of the computing device is received.
From the input audio signal, the application identifier and the first query are determined.
Generate a second query based on the first query and information related to the computing device.
The second query is provided to a third party server that provides the application corresponding to the application identifier in order to allow the application to identify multiple responses to the second query for display through the computing device. ,
Obtaining the plurality of responses identified by the application in response to the second query sent from the application to the third party server prior to display on the computing device.
To generate keywords based on the plurality of responses, the plurality of responses are parsed and
In response to the keyword generation, a real-time content selection process is performed using the keywords generated based on the plurality of responses intercepted by the application.
Based on the real-time content selection process, identify the digital components provided by the content provider device and
The deduplication process is performed using the digital components and the plurality of responses generated by the application.
In response to the deduplication process performed with the digital component and the plurality of responses generated by the application, it was decided to add the digital component to the plurality of responses.
Search for a graphical user interface template that defines fonts, colors, and layouts for the application to render the multiple responses.
Display output is constructed using the graphical user interface template that integrates the plurality of responses generated by the application with the digital components identified based on the real-time content selection process.
To provide the digital assistant device with the display output for display via a display device communicatively coupled to the digital assistant device, the digital assistant device is provided with the display output.
The graphics driver renders the display output to cause the display device to present visual instructions corresponding to the display output.
Digital assistant device.
スピーカ構成要素と
を備え、
前記プリプロセッサ構成要素が、前記表示出力の指示を受信し、前記表示出力の前記指示に対応するオーディオ出力を前記スピーカ構成要素に送信させるために出力オーディオ信号を生成するように前記オーディオドライバに指示する、
請求項19に記載のデバイス。 With an audio driver
With speaker components
The preprocessor component receives an instruction of the display output and instructs the audio driver to generate an output audio signal for transmitting the audio output corresponding to the instruction of the display output to the speaker component. ,
The device of claim 19.
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
JP2022025694A JP7459153B2 (en) | 2017-12-08 | 2022-02-22 | Graphical user interface rendering management with voice-driven computing infrastructure |
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US15/836,746 | 2017-12-08 | ||
US15/836,746 US10558426B2 (en) | 2017-12-08 | 2017-12-08 | Graphical user interface rendering management by voice-driven computing infrastructure |
PCT/US2018/037858 WO2019112646A1 (en) | 2017-12-08 | 2018-06-15 | Graphical user interface rendering management by voice-driven computing infrastructure |
Related Child Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2022025694A Division JP7459153B2 (en) | 2017-12-08 | 2022-02-22 | Graphical user interface rendering management with voice-driven computing infrastructure |
Publications (2)
Publication Number | Publication Date |
---|---|
JP2021501926A true JP2021501926A (en) | 2021-01-21 |
JP7032523B2 JP7032523B2 (en) | 2022-03-08 |
Family
ID=62916751
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2020516510A Active JP7032523B2 (en) | 2017-12-08 | 2018-06-15 | Graphical user interface rendering management with voice-driven computing infrastructure |
JP2022025694A Active JP7459153B2 (en) | 2017-12-08 | 2022-02-22 | Graphical user interface rendering management with voice-driven computing infrastructure |
Family Applications After (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2022025694A Active JP7459153B2 (en) | 2017-12-08 | 2022-02-22 | Graphical user interface rendering management with voice-driven computing infrastructure |
Country Status (6)
Country | Link |
---|---|
US (3) | US10558426B2 (en) |
EP (1) | EP3665567A1 (en) |
JP (2) | JP7032523B2 (en) |
KR (2) | KR102477073B1 (en) |
CN (1) | CN111108476B (en) |
WO (1) | WO2019112646A1 (en) |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP7434560B2 (en) | 2019-12-13 | 2024-02-20 | ライブパーソン， インコーポレイテッド | Functional cloud chatbot as a service for two-way communication systems |
Families Citing this family (13)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP6966979B2 (en) * | 2018-06-26 | 2021-11-17 | 株式会社日立製作所 | Dialogue system control methods, dialogue systems and programs |
CN108958844B (en) * | 2018-07-13 | 2021-09-03 | 京东方科技集团股份有限公司 | Application program control method and terminal |
US20200244604A1 (en) * | 2019-01-30 | 2020-07-30 | Hewlett Packard Enterprise Development Lp | Application program interface documentations |
US11113475B2 (en) * | 2019-04-15 | 2021-09-07 | Accenture Global Solutions Limited | Chatbot generator platform |
US11637792B2 (en) * | 2019-04-19 | 2023-04-25 | Oracle International Corporation | Systems and methods for a metadata driven integration of chatbot systems into back-end application services |
CN110297685B (en) * | 2019-06-28 | 2022-09-16 | 百度在线网络技术（北京）有限公司 | User interface description file generation method, device, equipment and storage medium |
KR20220010034A (en) * | 2019-10-15 | 2022-01-25 | 구글 엘엘씨 | Enter voice-controlled content into a graphical user interface |
US11321058B2 (en) | 2020-03-30 | 2022-05-03 | Nuance Communications, Inc. | Development system and method |
US11893589B2 (en) * | 2020-09-15 | 2024-02-06 | International Business Machines Corporation | Automated support query |
WO2022086519A1 (en) * | 2020-10-21 | 2022-04-28 | Google Llc | Delivery of compatible supplementary content via a digital assistant |
US11693874B2 (en) * | 2020-11-25 | 2023-07-04 | Sap Se | Framework to facilitate data access |
CN114067797A (en) * | 2021-11-19 | 2022-02-18 | 杭州逗酷软件科技有限公司 | Voice control method, device, equipment and computer storage medium |
US20240020570A1 (en) * | 2022-07-13 | 2024-01-18 | Capital One Services, Llc | Systems and methods for using machine learning models to organize and select access-restricted components for user interface templates based on characteristics of access token types |
Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP2003521039A (en) * | 2000-01-21 | 2003-07-08 | ソーセロン インコーポレイテッド | System and method for delivering rich media content over a network |
US20140244266A1 (en) * | 2013-02-22 | 2014-08-28 | Next It Corporation | Interaction with a Portion of a Content Item through a Virtual Assistant |
JP2014525103A (en) * | 2011-07-27 | 2014-09-25 | クアルコム，インコーポレイテッド | Improved web browsing with cloud computing |
Family Cites Families (21)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP2007122525A (en) * | 2005-10-29 | 2007-05-17 | National Institute Of Information & Communication Technology | Paraphrase processing method and device |
IL174107A0 (en) | 2006-02-01 | 2006-08-01 | Grois Dan | Method and system for advertising by means of a search engine over a data network |
US9251520B2 (en) * | 2006-02-22 | 2016-02-02 | Google Inc. | Distributing mobile advertisements |
US7962464B1 (en) * | 2006-03-30 | 2011-06-14 | Emc Corporation | Federated search |
JP2010538762A (en) | 2007-09-13 | 2010-12-16 | モレキュラ インサイト ファーマシューティカルズ インコーポレイテッド | Infusion and transfer systems for use with radioactive materials |
US8140335B2 (en) * | 2007-12-11 | 2012-03-20 | Voicebox Technologies, Inc. | System and method for providing a natural language voice user interface in an integrated voice navigation services environment |
US8255224B2 (en) * | 2008-03-07 | 2012-08-28 | Google Inc. | Voice recognition grammar selection based on context |
US8145521B2 (en) * | 2008-07-15 | 2012-03-27 | Google Inc. | Geographic and keyword context in embedded applications |
CN104969289B (en) | 2013-02-07 | 2021-05-28 | 苹果公司 | Voice trigger of digital assistant |
US9767198B2 (en) * | 2014-08-25 | 2017-09-19 | Excalibur Ip, Llc | Method and system for presenting content summary of search results |
KR101662399B1 (en) * | 2014-10-27 | 2016-10-04 | 포항공과대학교 산학협력단 | Apparatus and method for question-answering using user interest information based on keyword input |
US10331312B2 (en) * | 2015-09-08 | 2019-06-25 | Apple Inc. | Intelligent automated assistant in a media environment |
US20170092278A1 (en) | 2015-09-30 | 2017-03-30 | Apple Inc. | Speaker recognition |
US9928840B2 (en) | 2015-10-16 | 2018-03-27 | Google Llc | Hotword recognition |
US9747926B2 (en) | 2015-10-16 | 2017-08-29 | Google Inc. | Hotword recognition |
US10691473B2 (en) | 2015-11-06 | 2020-06-23 | Apple Inc. | Intelligent automated assistant in a messaging environment |
US11294908B2 (en) * | 2015-11-10 | 2022-04-05 | Oracle International Corporation | Smart search and navigate |
CN106855771A (en) * | 2015-12-09 | 2017-06-16 | 阿里巴巴集团控股有限公司 | A kind of data processing method, device and intelligent terminal |
KR20170076199A (en) * | 2015-12-24 | 2017-07-04 | 오드컨셉 주식회사 | Method, apparatus and computer program for providing commercial contents |
US10747758B2 (en) * | 2016-04-29 | 2020-08-18 | Rovi Guides, Inc. | Methods and systems for identifying an information resource for answering natural language queries |
US10192552B2 (en) | 2016-06-10 | 2019-01-29 | Apple Inc. | Digital assistant providing whispered speech |
-
2017
- 2017-12-08 US US15/836,746 patent/US10558426B2/en active Active
-
2018
- 2018-06-15 WO PCT/US2018/037858 patent/WO2019112646A1/en unknown
- 2018-06-15 CN CN201880061283.7A patent/CN111108476B/en active Active
- 2018-06-15 JP JP2020516510A patent/JP7032523B2/en active Active
- 2018-06-15 KR KR1020227001311A patent/KR102477073B1/en active IP Right Grant
- 2018-06-15 EP EP18740948.7A patent/EP3665567A1/en active Pending
- 2018-06-15 KR KR1020207008090A patent/KR102353286B1/en active IP Right Grant
-
2020
- 2020-02-03 US US16/780,256 patent/US11074039B2/en active Active
-
2021
- 2021-06-30 US US17/363,566 patent/US11429346B2/en active Active
-
2022
- 2022-02-22 JP JP2022025694A patent/JP7459153B2/en active Active
Patent Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP2003521039A (en) * | 2000-01-21 | 2003-07-08 | ソーセロン インコーポレイテッド | System and method for delivering rich media content over a network |
JP2014525103A (en) * | 2011-07-27 | 2014-09-25 | クアルコム，インコーポレイテッド | Improved web browsing with cloud computing |
US20140244266A1 (en) * | 2013-02-22 | 2014-08-28 | Next It Corporation | Interaction with a Portion of a Content Item through a Virtual Assistant |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP7434560B2 (en) | 2019-12-13 | 2024-02-20 | ライブパーソン， インコーポレイテッド | Functional cloud chatbot as a service for two-way communication systems |
Also Published As
Publication number | Publication date |
---|---|
KR102477073B1 (en) | 2022-12-13 |
WO2019112646A1 (en) | 2019-06-13 |
JP7459153B2 (en) | 2024-04-01 |
CN111108476B (en) | 2024-03-26 |
CN111108476A (en) | 2020-05-05 |
US20200174746A1 (en) | 2020-06-04 |
US10558426B2 (en) | 2020-02-11 |
US11074039B2 (en) | 2021-07-27 |
US20210326106A1 (en) | 2021-10-21 |
JP2022071013A (en) | 2022-05-13 |
KR20200042927A (en) | 2020-04-24 |
KR102353286B1 (en) | 2022-01-20 |
KR20220010070A (en) | 2022-01-25 |
US20190179608A1 (en) | 2019-06-13 |
JP7032523B2 (en) | 2022-03-08 |
US11429346B2 (en) | 2022-08-30 |
EP3665567A1 (en) | 2020-06-17 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
JP7032523B2 (en) | Graphical user interface rendering management with voice-driven computing infrastructure | |
US11907363B2 (en) | Data transfer in secure processing environments | |
KR102603717B1 (en) | Generation of domain-specific models in networked systems | |
US11640822B2 (en) | Dynamic sequence-based adjustment of prompt generation | |
JP6968897B2 (en) | Establishing an audio-based network session with unregistered resources | |
GB2563302A (en) | Balance modifications of audio-based computer program output | |
US20210358489A1 (en) | Interfacing with applications via dynamically updating natural language processing | |
US20210050008A1 (en) | Platform selection for performing requested actions in audio-based computing environments | |
JP7368425B2 (en) | Modifying audio-based computer program output | |
US11605382B2 (en) | Platform selection for performing requested actions in audio-based computing environments | |
US20240160723A1 (en) | Data Transfer in Secure Processing Environments | |
JP2022009571A (en) | Establishment of audio-based network session with unregistered resource |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20200428 |
|
A621 | Written request for application examination |
Free format text: JAPANESE INTERMEDIATE CODE: A621Effective date: 20200428 |
|
A131 | Notification of reasons for refusal |
Free format text: JAPANESE INTERMEDIATE CODE: A131Effective date: 20210705 |
|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20210927 |
|
TRDD | Decision of grant or rejection written | ||
A01 | Written decision to grant a patent or to grant a registration (utility model) |
Free format text: JAPANESE INTERMEDIATE CODE: A01Effective date: 20220124 |
|
A61 | First payment of annual fees (during grant procedure) |
Free format text: JAPANESE INTERMEDIATE CODE: A61Effective date: 20220224 |
|
R150 | Certificate of patent or registration of utility model |
Ref document number: 7032523Country of ref document: JPFree format text: JAPANESE INTERMEDIATE CODE: R150 |