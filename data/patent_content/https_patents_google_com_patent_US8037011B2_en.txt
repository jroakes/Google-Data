US8037011B2 - Method and apparatus for recommending content items - Google Patents
Method and apparatus for recommending content items Download PDFInfo
- Publication number
- US8037011B2 US8037011B2 US12/210,359 US21035908A US8037011B2 US 8037011 B2 US8037011 B2 US 8037011B2 US 21035908 A US21035908 A US 21035908A US 8037011 B2 US8037011 B2 US 8037011B2
- Authority
- US
- United States
- Prior art keywords
- preference
- response
- user
- duration
- value
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active, expires
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q30/00—Commerce
- G06Q30/02—Marketing; Price estimation or determination; Fundraising
Definitions
- the invention relates to recommendation of content items and in particular, but not exclusively, to recommendation of television or radio programs.
- DVRs Digital Video Recorders
- PVRs Personal Video Recorders
- VCRs Video Cassette Recorders
- DVRs are typically based on storing the recorded television programs in a digital format on a hard disk or optical disc.
- DVRs can be used both for analogue television transmissions (in which case a conversion to a digital format is performed as part of the recording process) as well as for digital television transmissions (in which case the digital television data can be stored directly).
- televisions or DVRs provide new and enhanced functions and features which provide an improved user experience.
- televisions or DVRs can comprise functionality for providing recommendations of television programs to the user.
- such devices can comprise functionality for monitoring the viewing/recording preferences of a user. These preferences can be stored in a user preference profile and subsequently can be used to autonomously select and recommend suitable television programs for viewing or recording.
- Such functionality may substantially improve the user experience. Indeed, with hundreds of broadcast channels diffusing thousands of television programs per day, the user may quickly become overwhelmed by the offering and therefore may not fully benefit from the availability of content. Furthermore, the task of identifying and selecting suitable content becomes increasingly difficult and time-consuming. The ability of devices to provide recommendations of television programs of potential interest to the user substantially facilitates this process.
- the recommendation procedure includes predicting how much a user may like a particular content item and recommending it if it is considered of sufficient interest.
- the process of generating recommendations requires that user preferences have been captured so that they can be used as input by the prediction algorithm.
- the first approach is to explicitly obtain user preferences by the user(s) manually inputting their preferences, for example by manually providing feedback on content items that the user(s) particularly liked or disliked.
- the other approach is to implicitly obtain user preferences by the system monitoring user actions to infer their preferences.
- Explicit feedback tends to require substantial input by the user(s) and is often considered cumbersome and inconvenient by the users. This approach is therefore not ideal in the context of e.g. television viewing which is characterized by being a low effort and highly passive activity. Accordingly, it is desirable that the generation of a user preference profile or mode for the user(s) is at least partly based on implicit feedback.
- Implicit preference systems acquire information indicative of user preferences by observing the user's behaviour when consuming content.
- a set of positive and negative preference examples is typically identified and used to train a learning algorithm which then creates a model of the user preferences.
- the recommendation system may then use this preference model to generate personalized recommendations.
- an improved system for content item recommendation would be advantageous.
- a system allowing an improved user experience, increased flexibility, reduced complexity, improved user preference models, reduced need for user inputs, improved accuracy and/or improved performance would be advantageous.
- the Invention seeks to preferably mitigate, alleviate or eliminate one or more of the above mentioned disadvantages singly or in any combination.
- a recommendation apparatus for recommending content items to at least one user, the recommendation apparatus comprising: a monitoring processor for monitoring presentation of content items; a sample processor arranged to, for a plurality of content items: determine a preference value for a presented content item in response to a first duration for a first section of the content item being presented relative to a total duration of the content item; if the first duration is less than the total duration, determining if a second section of the content item not being presented corresponds to at least one of an end section and a begin section of the content item; and if so, determining a confidence value for the preference value in response to a second duration of the second section; and a model processor for determining a user preference model in response to preference values and confidence values for the plurality of content items; and a recommendation processor for generating recommendations of content items in response to the user preference model.
- the invention may allow an improved user preference model to be generated resulting in improved recommendations. Specifically, by basing a user preference model on implicit information that does not only reflect a preference value but also a confidence value of that preference value, a more accurate user preference model can be determined. In particular, the combination of determining preference values in response to the duration presented relative to the total duration and determining the associated confidence value based on the duration of a missed beginning or end section provides accurate preference information that has been demonstrated to allow more accurate user preference models and thus recommendations to be generated.
- the preference value of a content item may be determined in response to a ratio of the first duration divided by the total duration.
- the preference value may simply correspond to the ratio or may e.g. be considered as a positive preference if the ratio exceeds a specific threshold.
- the plurality of content items may specifically be provided in one or more sequences of content items.
- the content items may be content items that are broadcasted sequentially in one or more channels.
- the content items may be television or radio programs.
- the presentation of the content items is at least partly user controlled.
- the user may select the content items being presented, e.g. by selecting a current channel providing real time content items and/or simply by switching the presentation on or off.
- a method of recommending content items to at least one user comprising: monitoring presentation of content items; for a plurality of content items performing the steps of: determine a preference value for a presented content item in response to a first duration for a first section of the content item being presented relative to a total duration of the content item, if the first duration is less than the total duration, determining if a second section of the content item not being presented corresponds to at least one of an end section and a begin section of the content item, and if so, determining a confidence value for the preference value in response to a second duration of the second section; and determining a user preference model in response to preference values and confidence values for the plurality of content items; and generating recommendations of content items in response to the user preference model.
- FIG. 1 illustrates an example of elements of a recommendation apparatus in accordance with some embodiments of the invention
- FIG. 2 illustrates an example of a performance comparison for a recommendation apparatus in accordance with some embodiments of the invention
- FIG. 3 illustrates an example of a performance comparison for a recommendation apparatus in accordance with some embodiments of the invention.
- FIG. 4 illustrates a method of recommending content items to at least one user in accordance with some embodiments of the invention.
- FIG. 1 illustrates an example of elements of a recommendation apparatus in accordance with some embodiments of the invention.
- the recommendation apparatus is a television receiver which furthermore comprises storage means for storing received television programs.
- the recommendation apparatus may be a DVR.
- the recommendation apparatus comprises a receiver 101 which receives television broadcasts from a suitable television broadcast transmitter.
- the receiver 101 may thus receive sequential content items corresponding to television programs in a plurality of parallel channels or streams corresponding to the different television channels.
- the receiver 101 is coupled to a program store 103 in which individual programs may be stored for example in response to a user selection of programs to record.
- the receiver 101 and the program store 103 are coupled to a presentation controller 105 which controls the selection and presentation of television programs.
- the presentation controller 105 is coupled to a user output 107 wherein the television programs can be presented to one or more users.
- the user output 107 may for example comprise an interface for coupling the recommendation apparatus to a conventional television or may itself e.g. comprise a display.
- the presentation controller 105 is further coupled to a user input 109 which may receive inputs from a user controlling the operation of the recommendation apparatus.
- the user input 109 may for example comprise a keyboard or a wireless interface to a remote control.
- a user may provide an input to the recommendation apparatus selecting either stored or real time television programs and in response the presentation controller 105 may select the appropriate real time channel or stored television program and feed this to the user output.
- the present example describes a recommendation apparatus comprising the functionality for receiving, storing and presenting content items
- some or all of this functionality may in other embodiments be external to the recommendation apparatus.
- the receiver 101 , program store 103 , presentation controller 105 , user input 109 and user output 107 may be comprised in a DVR which is external to the recommendation apparatus.
- the PVR may provide presentation information to the recommendation apparatus which may process this to generate a user preference model and recommendations as will be described in the following.
- a user preference model is based on implicit preference information derived by monitoring characteristics of the presentations. As these are controlled by the user, the presentation characteristics may provide useful information of the user preferences.
- the presentation of a given program is detected and a preference value is associated therewith depending on specific presentation characteristics.
- These preference values may be positive and negative and accordingly a substantial number of examples of content items and associated preference values can be generated. These examples are then used as training data for generating a user preference model.
- implicit preference information is acquired by observing user behaviours.
- a set of positive and negative preference examples is then constructed and used to train a learning algorithm which then creates a model of the user preferences so that the system can make personalized recommendations.
- a two-step mechanism is used to infer implicit preferences.
- a preference value is determined for a program based on a duration of the part of the program which has been presented relative to a total duration.
- a confidence value is calculated for the preference value dependent on a duration of a begin or end section of the program which has been missed.
- the information of a start or end part being missed provides a reliable indication of the reliability and accuracy of a preference value that is based on a duration of the presentation relative to a total duration of the program.
- the durations are related and can be used to differentiate between different examples of user behaviour reflecting different preference indications. For example the consideration may be used to differentiate between scenarios wherein the behaviour is due to a specific user preference for the program and scenarios where the behaviour is a coincidental consequence of user behaviour due to other reasons (e.g. a preference for a subsequent program).
- the information of any missed section of the beginning or end of a program is then considered (potentially together with other factors) to generate a confidence value for each implicit preference being considered. Implicit preferences with low confidence values can then be discarded and not used as input for training the user preference model.
- the confidence values can be used to determine the impact that the different implicit preference examples should have on the user preference model so that examples with less reliability have less impact than those with more reliability.
- the confidence values can be used to determine which examples should be taken into account (selective approach) or how the implicit preference value for this particular example should be calculated (combination approach).
- preference values and closely related confidence values allow a more accurate user preference model to be generated thereby resulting in improved recommendations.
- specific characteristics being considered for the preference and confidence values provide particularly useful and accurate information resulting in an improved accuracy of the user preference model and of the generated recommendations.
- the presentation controller 105 is coupled to a monitoring processor 111 which monitors the presentation of programs by the presentation controller 105 .
- the monitoring processor 111 retrieves information relating to the program from the presentation controller 105 .
- This information may include characterizing data that describes the content item.
- This data may be meta-data describing e.g. a title, genre, description, total duration, etc of the program.
- the information includes data describing the duration and specific timing of the section that has been presented.
- the monitoring processor 111 then feeds this information to the sample processor 113 which proceeds to generate a training example for the content item.
- the training example comprises characterizing data describing the program as well as a preference value and an associated confidence value.
- the sample processor 113 accordingly first determines a preference value for the television program in response to the duration of the presented section of the program relative to the total duration of the program.
- the program is considered as a positive preference example and otherwise it is considered a negative preference example, e.g.:
- the preference value may be (e.g. linearly) linked to the actual amount of the program that the user has watched, e.g:
- the sample processor 113 then proceeds to determine a confidence value which is dependent on a duration of a beginning or end section that has not been presented (if any).
- the sample processor 113 may first determine if the whole program has been presented. If so, the confidence value may be set to a high value. However, if only part of the program has been presented, the sample processor 115 may determine whether a beginning section or an end section has been missed. If so, the confidence value may be set dependent on the duration of this section.
- a positive preference value may be determined for a program for which 95% has been presented. If the missing 5% were at the start of the program, it is relatively likely that the user possibly selected the program randomly and then liked it sufficiently to watch the entire remaining part of the program. Accordingly, the confidence value for the positive preference value is set to a high value. However, if the last 5% was missed, this indicates that the user may not like the program enough to watch it to completion. However, it may also be due to the user being unable to continue to watch the program due to other commitments. Thus, it is less likely that the positive preference value actually reflects the user's underlying positive preference value for the underlying concept and accordingly the confidence value is set to a lower value.
- the sample processor 113 may generate a user preference example with a preference value and associated confidence value for some or all programs that is (partially or fully) presented to the user with the values reflecting the amount of the program that has been presented.
- the user preference examples are then fed to a model processor 115 which proceeds to use these examples as training data for a learning algorithm that generates a user preference model reflecting the user(s) preferences.
- the model processor 115 generates the user preference model in response to the preference values and confidence values for the programs (as well as the characterizing data).
- model processor 115 may initially discard all examples having a confidence value less than a given threshold and then use the remaining examples as training data for a learning algorithm considering only preference values and characterizing data.
- the model processor 115 may generate the user preference model by using a probabilistic approach such as e.g. a na ⁇ ve Bayes classifier (ref. e.g. http://en.wikipedia.org/wiki/Naive_Bayes_classifier).
- a probabilistic approach such as e.g. a na ⁇ ve Bayes classifier (ref. e.g. http://en.wikipedia.org/wiki/Naive_Bayes_classifier).
- the model processor 115 is coupled to a recommendation processor 117 which is arranged to generate recommendations for television programs using the user preference model generated by the model processor 115 . It will be appreciated that many different methods and algorithms for generating recommendations based on a user preference model will be known to the skilled person and that any suitable approach may be used without detracting from the invention.
- the recommendation processor 117 is coupled to the user input 109 and the user output 107 , and may generate recommendations and present them via the user output 107 in response to e.g. receiving a user generated recommendation request from the user input 109 .
- the recommendation apparatus of FIG. 1 may generate recommendations with improved accuracy based on a more accurate user preference model.
- the user preference information comprises both preference and confidence values based on specific and correlated characteristics that provide improved implicit indications of user preferences.
- the user preference information is based on the presentations selected by the user rather than e.g. on the selection of programs to record. This may provide improved accuracy as the fact that a user records a program is not an indication that the user necessarily likes it.
- the preference example is only generated if the user actually selects the program to be presented (whether this is a live real time program or a previously recorded program) thereby reflecting a specific interest or preference.
- the sample processor 113 may detect that an end section of a program has been missed and the confidence value may be set dependent on the duration of this missed section.
- the confidence value may be set higher.
- the sample processor 113 biases the confidence value towards an indication of a reduced confidence if the preference value is indicative of a negative preference and the duration of the missed section is higher than a threshold. Also, the sample processor 113 biases the confidence value towards an indication of an increased confidence if the preference value is indicative of a positive preference and the second duration is lower than a threshold.
- the confidence value is set both in response to the duration of the missed section but also in dependence on the preference value itself.
- a bias of the confidence value may be in one direction (e.g. higher confidence value) for a positive preference value and in the other direction (e.g. lower confidence value) for a negative preference value (or vice versa).
- the confidence value may specifically be determined by evaluating the duration of the watched duration and the duration of the missed section relative to various thresholds. For example, a confidence value may be determined as:
- the confidence value may alternatively or additionally be set dependent on the duration of this missed section. Specifically, the sample processor 113 of FIG. 1 biases the confidence value towards an indication of reduced confidence if the duration of the start section being missed is higher than a threshold.
- the confidence value for a given program is determined by considering a number of different aspects. For example, a contribution may be determined by considering the duration presented, a second contribution may be determined from a duration of any missed start section and a third contribution may be determined from a duration of any missed begin section. In some embodiments, other characteristics may also be considered and provide a contribution as will be described later.
- each of these contributions is determined as a numerical value, v, which may be positive (biasing the confidence value towards a higher confidence) or negative (biasing the confidence value towards a lower confidence) and the confidence value for the program is determined as the sum of the individual contributions:
- the confidence value may then e.g. be used to either filter out examples with low reliability from the training set or may be used to determine the impact that each example should have on the construction of the user preference model (e.g. to determine a weighting of each example in the training process).
- the model processor 115 can generate a training set for training the user preference model which includes all the examples having confidence values that are above a given threshold. This may provide an improved accuracy of the generated user preference model.
- a more complex approach may be used wherein the significance of each example when training the user preference model is dependent on the confidence value.
- the higher the confidence value the higher the impact of the example on the model.
- the features of each example may be weighted by the confidence for the example.
- some of the content items are duplicates of each other.
- the same program e.g. film
- the preference information for the duplicates may be combined to facilitate and improve the generation and training of the user preference model.
- any suitable similarity criterion may be used to determine if content items are duplicates. For example, two television programs may be considered to be duplicates if they have the same title and a length which is within, say, 10% of each other.
- the model processor 115 can specifically combine the duplicate preference information into a single preference example.
- a combined preference value can be generated for all the duplicate programs.
- the preference value may for example be generated as an average preference value for the duplicate examples.
- a single confidence value may be generated e.g. by averaging the confidence values of the different duplicates.
- the combined preference value is generated in response to the confidence values of the duplicates.
- the model processor 115 may discard all preferences that have a value below a given threshold (and e.g. average the rest) or may simply select the preference value corresponding to the highest confidence value.
- the confidence value is useful in dealing with duplicate (and possibly inconsistent) preference examples that may appear in the training set. For instance, a user may have almost entirely watched a program on one day but barely half or none of it on another day. Selecting the preference examples with the highest confidence helps to easily solve this conflict. So considering that there are n examples regarding the same user and program that have preference values p 1 , p 2 , . . . p n and confidence values c 1 , c 2 , . . . , c n , the system can e.g. combine those into a single example with preference p and confidence c such that:
- the preference value itself can be used when combining.
- the highest preference value may be selected corresponding to a reasoning that if the user has watched the program fully at least once, then he/she must like it.
- Another alternative is to have the different ratings combined taking into account their relative reliability:
- the training sets are made up by implicit preference examples that meet different requirements.
- IP0 is a reference example that simply generates a positive preference if a user is presented with at least 90% of a program and a negative preference otherwise. No confidence value is generated and all examples are included in the preference set.
- IP1 uses the same preference value as IP0. However, a confidence value is set to +100 if the duration watched is above 90% and to +50 if the duration watched is below 10%. All other confidence values are set to zero. All examples having a confidence values of zero or below are then removed from the training set.
- IP2 uses the same preference value as IP0 and IP1.
- a confidence value contribution is set to +100 if the duration watched is above 90%, to +50 if the duration watched is below 10% and to ⁇ 50 if the duration of a missed end section is less than 10%.
- the confidence value for an example is then determined by summing the individual confidence value contributions (and setting the value to zero if there are no suitable contributions). All examples having a confidence value of zero or below are then removed from the training set.
- Experiment 4 is referred to as IP3 and uses the same preference value as IP0, IP1, and IP2.
- a confidence value contribution is set to +100 if the duration watched is above 90%, to +50 if the duration watched is below 10%, and to ⁇ 50 if the duration of a missed start section is less than 10%.
- the confidence value for an example is then determined by summing the individual confidence value contributions (and setting the value to zero if there are no suitable contributions). All examples having a confidence value of zero or below are then removed from the training set.
- Evaluation metric Definition Precision Measures the proportion of items in the recommendations that actually match user preferences. Recall Measures the proportion of items that match user preferences which have actually been included in the recommendation list. Breese It measures how well sorted the recommendation Score list is (i.e., whether the most relevant items are being presented first), as defined in Breese, J., Heckerman, D., and Kadie, C. Empirical analysis of predictive algorithms for collaborative filtering. In Proceedings of the Fourteenth Annual Conference on Uncertainty in Artificial Intelligence (Madison, WI, USA, July 1998), Morgan Kaufmann, pp. 43-52.
- FIGS. 2 and 3 clearly demonstrate an improvement (about 6%) both in precision and accuracy.
- the confidence value may take into account a number of other factors and characteristics. Each of these may for example provide a contribution I which is combined with other contributions to generate the confidence value, e.g. by a simple summation of numeric contributions, v:
- the sample processor 113 may generate a contribution in response to a time elapsed since a previous user input.
- the recommendation apparatus may detect how long it has been since a user input was last received and may use this to set the confidence value. For example, it is often the case that a television is left on by itself or is used as background noise. This may be differentiated to a more active user selection and reflected in the confidence value. Specifically, preference examples that are very distant to a user action will be given a lower confidence.
- the sample processor 113 may generate a contribution in response to a duration of a presentation of a following content item relative to a total duration of a following content item.
- the confidence value (of either a negative or positive preference value) may be reduced to reflect that the current user action is more related to the following program than the current program.
- sample processor 113 may generate a contribution in response to the presentation time for the content item relative to a presentation time preference profile for the at least one user.
- the content item may be a real time content item which has not been stored.
- it may be a broadcast content item, such as a television program, and should therefore be watched in real time. If this time is outside the user's normal time for watching television, the confidence value may be set higher for a positive preference value and lower for a negative preference value as it indicates that the user has made a special effort to consume the program. Thus, the perceived inconvenience of the program's time slot can be taken into account when determining the confidence value.
- the sample processor 113 may generate a contribution in response to at least one other simultaneous real time content item. For example, two programs may be broadcast at the same time and the user may actively select which of these to watch.
- the sample processor 113 may generate a contribution in response to a similarity measure for a group of users being presented the content item.
- the recommendation apparatus may comprise functionality for individual users to log-on and off thereby providing information of which users are currently consuming the presented content.
- the characteristics of the individual users may be pre-stored in the apparatus. For example, upon initialization, the users may provide information on age, gender, etc to the recommendation apparatus and subsequently the operation of the recommendation apparatus may be personalized to the specific group of users currently logged-on.
- the more different the current viewers are e.g. age groups, genders
- the confidence value for a preference value for an individual user may be reduced if the preference value is generated for a program that is viewed by a diverse group of users.
- the sample processor may generate a contribution in response to the frequency of associated/similar content items. For example, for a television application, television programs may be frequently repeated or frequent programs of a series may be transmitted. In such a system, the sample processor may take into account the ratio of positive viewing examples to viewing opportunities. E.g. users may have a strong preference for a type of content which is only infrequently transmitted and therefore is only infrequently represented by an example being generated. In contrast, the user may have less preference for a program which has more examples due to it frequently being transmitted. Accordingly, a small number to positive viewing examples might have more significance than the same amount of positive examples for types of content which are broadcast everyday. The sample processor may take this into account, e.g. by reducing the confidence value for programs that are frequently transmitted.
- programs may be considered to be associated or similar if they are indicated to belong to the same series (e.g. all episodes of a sitcom series may be considered to the similar).
- Live-viewing Preference examples linked to recorded or time- programs may be given higher confidence shifted due to the extra investment involved in viewing recording the program.
- Number of The most captivating programs are often interruptions watched in one go (except maybe for ad breaks).
- boredom can easily be a trigger to temporarily interrupt viewing and switch to other channels to find something more interesting to watch. So if a program viewing is repeatedly interrupted by zapping, it is probably because the user interest is not high. Pausing a If during the viewing of a program this is channel paused (typically, the program is recorded so that it its viewing can be resumed later from the same point) then this can be seen as an indication of special preference for this program.
- FIG. 4 illustrates a method of recommending content items to at least one user in accordance with some embodiments of the invention.
- the method initiates in step 401 wherein presentations of content items is being monitored.
- Step 401 is followed by step 403 wherein a preference value and confidence value is determined for each content item of a plurality of content items.
- the values are determined by performing the steps of: determining a preference value for a content item presented by the presentation unit in response to a first duration for a first section of the content item being presented relative to a total duration of the content item, if the first duration is less than the total duration, determining if a second section of the content item not being presented corresponds to at least one of an end section and a begin section of the content item, and if so determining a confidence value for the preference value in response to a second duration of the second section.
- Step 403 is followed by step 405 wherein a user preference model is determined in response to preference values and confidence values for the plurality of content items.
- Step 405 is followed by step 407 wherein recommendations of content items are generated in response to the user preference model.
- the invention can be implemented in any suitable form including hardware, software, firmware or any combination of these.
- the invention may optionally be implemented at least partly as computer software running on one or more data processors and/or digital signal processors.
- the elements and components of an embodiment of the invention may be physically, functionally and logically implemented in any suitable way. Indeed the functionality may be implemented in a single unit, in a plurality of units or as part of other functional units. As such, the invention may be implemented in a single unit or may be physically and functionally distributed between different units and processors.
Abstract
Description
p=f p(d w ,d p)
where dw represents the duration of the presented section, dp represents the duration of the program and dm represents the duration of the missed end section.
c=f c(I)
Discarded | |||
Exp. | Positive examples | Negative examples | examples |
IP0 | Percentage | Percentage | None |
watched is at | watched is less | ||
least 90% | than 90% | ||
IP1 | Percentage | Percentage | Percentage |
watched is at | watched is less | watched is more | |
least 90% | than 10% | than 10% and less | |
than 90% | |||
IP2 | Percentage | Percentage | All other |
watched is at | watched is less | ||
least 90% | than 10% and | ||
percentage missed | |||
at the end is | |||
more than 10% | |||
IP3 | Percentage | Percentage | All other |
watched is at | watched is less | ||
least 90% | than 10% and | ||
percentage missed | |||
at the start is | |||
less than 90% | |||
Evaluation | |||
metric | Definition | ||
Precision | Measures the proportion of items in the | ||
recommendations that actually match user | |||
preferences. | |||
Recall | Measures the proportion of items that match | ||
user preferences which have actually been | |||
included in the recommendation list. | |||
Breese | It measures how well sorted the recommendation | ||
Score | list is (i.e., whether the most relevant items | ||
are being presented first), as defined in | |||
Breese, J., Heckerman, D., and Kadie, C. | |||
Empirical analysis of predictive algorithms | |||
for collaborative filtering. In Proceedings of | |||
the Fourteenth Annual Conference on | |||
Uncertainty in Artificial Intelligence | |||
(Madison, WI, USA, July 1998), Morgan | |||
Kaufmann, pp. 43-52. | |||
Experiment | Precision | Recall | Breese score | ||
IP0 | 0.63 ± 0.09 | 0.37 ± 0.07 | 0.47 ± 0.10 | ||
IP1 | 0.86 ± 0.06 | 0.43 ± 0.07 | 0.51 ± 0.09 | ||
IP2 | 0.91 ± 0.05 | 0.42 ± 0.07 | 0.51 ± 0.09 | ||
IP3 | 0.91 ± 0.05 | 0.43 ± 0.07 | 0.51 ± 0.09 | ||
-
- If percentage watched p is above 90%, confidence is set to (p−90)+10.
- If percentage watched is below 10%, confidence is set to (10−p).
- All other examples have confidence set to 0.
- In case there are two or more preference examples for the same program, the preference value with the highest confidence value is kept with other examples being discarded.
Live-viewing | Preference examples linked to recorded | ||
or time- | programs may be given higher confidence | ||
shifted | due to the extra investment involved in | ||
viewing | recording the program. | ||
Number of | The most captivating programs are often | ||
interruptions | watched in one go (except maybe for ad | ||
breaks). Conversely, boredom can easily be | |||
a trigger to temporarily interrupt viewing | |||
and switch to other channels to find | |||
something more interesting to watch. So if | |||
a program viewing is repeatedly | |||
interrupted by zapping, it is probably | |||
because the user interest is not high. | |||
Pausing a | If during the viewing of a program this is | ||
channel | paused (typically, the program is recorded | ||
so that it its viewing can be resumed | |||
later from the same point) then this can | |||
be seen as an indication of special | |||
preference for this program. Most | |||
probably, the user had to make an | |||
interruption and wants to make sure he/she | |||
does not miss any part of the program. | |||
Upgrading of | Users who repeatedly watch an anticipated | ||
repetitive | program at the same time each week in a | ||
instances of | pattern, are likely to have a stronger | ||
positive | preference for that program than a program | ||
examples | they have watched the same amount of | ||
times, but in an irregular opportunist | |||
fashion (e.g. when they happened to notice | |||
it was being broadcast). | |||
Claims (20)
Priority Applications (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US12/210,359 US8037011B2 (en) | 2008-09-15 | 2008-09-15 | Method and apparatus for recommending content items |
PCT/US2009/052537 WO2010030452A2 (en) | 2008-09-15 | 2009-08-03 | Method and apparatus for recommending content items |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US12/210,359 US8037011B2 (en) | 2008-09-15 | 2008-09-15 | Method and apparatus for recommending content items |
Publications (2)
Publication Number | Publication Date |
---|---|
US20100070436A1 US20100070436A1 (en) | 2010-03-18 |
US8037011B2 true US8037011B2 (en) | 2011-10-11 |
Family
ID=42005690
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US12/210,359 Active 2030-06-27 US8037011B2 (en) | 2008-09-15 | 2008-09-15 | Method and apparatus for recommending content items |
Country Status (2)
Country | Link |
---|---|
US (1) | US8037011B2 (en) |
WO (1) | WO2010030452A2 (en) |
Cited By (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20100070454A1 (en) * | 2008-09-08 | 2010-03-18 | Hiroyuki Masuda | Apparatus, method and computer program for content recommendation and recording medium |
US20100290699A1 (en) * | 2009-05-15 | 2010-11-18 | Google Inc. | Landmarks from Digital Photo Collections |
US20110276680A1 (en) * | 2010-05-06 | 2011-11-10 | Noam Rimon | Method and system of manipulating data based on user-feedback |
US8898344B2 (en) | 2012-10-14 | 2014-11-25 | Ari M Frank | Utilizing semantic analysis to determine how to measure affective response |
US20150040149A1 (en) * | 2012-10-14 | 2015-02-05 | Ari M. Frank | Reducing transmissions of measurements of affective response by identifying actions that imply emotional response |
US9014511B2 (en) | 2008-05-12 | 2015-04-21 | Google Inc. | Automatic discovery of popular landmarks |
US10311510B2 (en) * | 2014-09-05 | 2019-06-04 | Apple Inc. | System and method for providing sequential media items |
Families Citing this family (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US8001056B2 (en) * | 2008-09-19 | 2011-08-16 | Yahoo! Inc. | Progressive capture of prospect information for user profiles |
US9317812B2 (en) * | 2012-11-30 | 2016-04-19 | Facebook, Inc. | Customized predictors for user actions in an online system |
US20150039549A1 (en) * | 2013-07-30 | 2015-02-05 | Reccosend LLC | System and method for computerized recommendation delivery, tracking, and prioritization |
CN112449217B (en) * | 2019-09-02 | 2022-12-27 | 北京京东尚科信息技术有限公司 | Method and device for pushing video, electronic equipment and computer readable medium |
Citations (15)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP2000269840A (en) | 1999-03-17 | 2000-09-29 | Sharp Corp | Device for reproducing/receiving contents |
US20010028603A1 (en) * | 2000-04-07 | 2001-10-11 | Nec Corporation | Usage history registering apparatus and automatic database retrieval statement generating apparatus |
WO2002025938A2 (en) | 2000-09-20 | 2002-03-28 | Koninklijke Philips Electronics N.V. | Method and apparatus for generating recommendation scores using implicit and explicit viewing preference |
US20020054062A1 (en) * | 1998-02-04 | 2002-05-09 | George Gerba | Method and system for providing user interface for electronic program guide |
WO2002037851A2 (en) | 2000-10-30 | 2002-05-10 | Koninklijke Philips Electronics N.V. | Method and apparatus for generating television program recommendations based on prior queries |
WO2004002129A2 (en) | 2002-06-21 | 2003-12-31 | Thomson Licensing S.A. | Method for media popularity determination by a media playback device |
US20040068741A1 (en) | 2001-07-09 | 2004-04-08 | Hitoshi Kimura | Content preference calculation method and content reception apparatus |
US20050022239A1 (en) | 2001-12-13 | 2005-01-27 | Meuleman Petrus Gerardus | Recommending media content on a media system |
US20050076365A1 (en) | 2003-08-28 | 2005-04-07 | Samsung Electronics Co., Ltd. | Method and system for recommending content |
US20050193002A1 (en) * | 2004-02-26 | 2005-09-01 | Yahoo! Inc. | Method and system for generating recommendations |
US20060047678A1 (en) * | 2002-12-12 | 2006-03-02 | Sony Corporation | Information processing device and method, recording medium, and program |
US20060212904A1 (en) | 2000-09-25 | 2006-09-21 | Klarfeld Kenneth A | System and method for personalized TV |
US20080082633A1 (en) * | 2006-08-24 | 2008-04-03 | Kabushiki Kaisha Toshiba | Recommending system, recommending server, content recommending method, and recommending program product |
US20080250312A1 (en) * | 2007-04-05 | 2008-10-09 | Concert Technology Corporation | System and method for automatically and graphically associating programmatically-generated media item recommendations related to a user's socially recommended media items |
US20090222392A1 (en) * | 2006-02-10 | 2009-09-03 | Strands, Inc. | Dymanic interactive entertainment |
-
2008
- 2008-09-15 US US12/210,359 patent/US8037011B2/en active Active
-
2009
- 2009-08-03 WO PCT/US2009/052537 patent/WO2010030452A2/en active Application Filing
Patent Citations (15)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20020054062A1 (en) * | 1998-02-04 | 2002-05-09 | George Gerba | Method and system for providing user interface for electronic program guide |
JP2000269840A (en) | 1999-03-17 | 2000-09-29 | Sharp Corp | Device for reproducing/receiving contents |
US20010028603A1 (en) * | 2000-04-07 | 2001-10-11 | Nec Corporation | Usage history registering apparatus and automatic database retrieval statement generating apparatus |
WO2002025938A2 (en) | 2000-09-20 | 2002-03-28 | Koninklijke Philips Electronics N.V. | Method and apparatus for generating recommendation scores using implicit and explicit viewing preference |
US20060212904A1 (en) | 2000-09-25 | 2006-09-21 | Klarfeld Kenneth A | System and method for personalized TV |
WO2002037851A2 (en) | 2000-10-30 | 2002-05-10 | Koninklijke Philips Electronics N.V. | Method and apparatus for generating television program recommendations based on prior queries |
US20040068741A1 (en) | 2001-07-09 | 2004-04-08 | Hitoshi Kimura | Content preference calculation method and content reception apparatus |
US20050022239A1 (en) | 2001-12-13 | 2005-01-27 | Meuleman Petrus Gerardus | Recommending media content on a media system |
WO2004002129A2 (en) | 2002-06-21 | 2003-12-31 | Thomson Licensing S.A. | Method for media popularity determination by a media playback device |
US20060047678A1 (en) * | 2002-12-12 | 2006-03-02 | Sony Corporation | Information processing device and method, recording medium, and program |
US20050076365A1 (en) | 2003-08-28 | 2005-04-07 | Samsung Electronics Co., Ltd. | Method and system for recommending content |
US20050193002A1 (en) * | 2004-02-26 | 2005-09-01 | Yahoo! Inc. | Method and system for generating recommendations |
US20090222392A1 (en) * | 2006-02-10 | 2009-09-03 | Strands, Inc. | Dymanic interactive entertainment |
US20080082633A1 (en) * | 2006-08-24 | 2008-04-03 | Kabushiki Kaisha Toshiba | Recommending system, recommending server, content recommending method, and recommending program product |
US20080250312A1 (en) * | 2007-04-05 | 2008-10-09 | Concert Technology Corporation | System and method for automatically and graphically associating programmatically-generated media item recommendations related to a user's socially recommended media items |
Non-Patent Citations (5)
Title |
---|
S. Gadanho, "TV Recommendations based on Implicit Information," Proceedings of the 17th European Conference on Artificial intelligence (ECAI 2006) Workshop on Recommender Systems, Riva del Garda, Italy, Aug. 28-29, 2006, 3 pages. |
S. Gadanho, et al, "Addressing Uncertainty in Implicit Preferences," Proceedings of the 2007 ACM Conference on Recommender Systems, Minneapolis, MN, USA, 2007, pp. 97-104. |
Sung Woo Park, "Corresponding Application PCT/US2009/052537-PCT International Search Report and Written Opinion," WIPO, ISA/KR, Korean Intellectual Property Office, Daejeon, Republic of Korea, Mar. 16, 2010, 10 pages, most relevant pp. 6-7 and 10. |
Z. Yu, et al., A Hybrid Learning Approach for TV Program Personalization,' The 8th International Conference on Knowledge-Based Intelligent Information & Engineering Systems (KES 2004), Lecture Notes in Computer Science, Springer-Verlag, pp. 630-636, Sep. 20-24, 2004, Wellington, New Zealand. |
Z. Yu, et al., A Hybrid Learning Approach for TV Program Personalization,′ The 8th International Conference on Knowledge-Based Intelligent Information & Engineering Systems (KES 2004), Lecture Notes in Computer Science, Springer-Verlag, pp. 630-636, Sep. 20-24, 2004, Wellington, New Zealand. |
Cited By (25)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10289643B2 (en) | 2008-05-12 | 2019-05-14 | Google Llc | Automatic discovery of popular landmarks |
US9014511B2 (en) | 2008-05-12 | 2015-04-21 | Google Inc. | Automatic discovery of popular landmarks |
US9483500B2 (en) | 2008-05-12 | 2016-11-01 | Google Inc. | Automatic discovery of popular landmarks |
US20100070454A1 (en) * | 2008-09-08 | 2010-03-18 | Hiroyuki Masuda | Apparatus, method and computer program for content recommendation and recording medium |
US8214318B2 (en) * | 2008-09-08 | 2012-07-03 | Sony Corporation | Apparatus, method and computer program for content recommendation and recording medium |
US20100290699A1 (en) * | 2009-05-15 | 2010-11-18 | Google Inc. | Landmarks from Digital Photo Collections |
US8396287B2 (en) * | 2009-05-15 | 2013-03-12 | Google Inc. | Landmarks from digital photo collections |
US10303975B2 (en) | 2009-05-15 | 2019-05-28 | Google Llc | Landmarks from digital photo collections |
US9020247B2 (en) | 2009-05-15 | 2015-04-28 | Google Inc. | Landmarks from digital photo collections |
US9721188B2 (en) | 2009-05-15 | 2017-08-01 | Google Inc. | Landmarks from digital photo collections |
US20110276680A1 (en) * | 2010-05-06 | 2011-11-10 | Noam Rimon | Method and system of manipulating data based on user-feedback |
US8296422B2 (en) * | 2010-05-06 | 2012-10-23 | Sony Computer Entertainment Inc. | Method and system of manipulating data based on user-feedback |
US9086884B1 (en) | 2012-10-14 | 2015-07-21 | Ari M Frank | Utilizing analysis of content to reduce power consumption of a sensor that measures affective response to the content |
US9104467B2 (en) | 2012-10-14 | 2015-08-11 | Ari M Frank | Utilizing eye tracking to reduce power consumption involved in measuring affective response |
US9104969B1 (en) | 2012-10-14 | 2015-08-11 | Ari M Frank | Utilizing semantic analysis to determine how to process measurements of affective response |
US9224175B2 (en) | 2012-10-14 | 2015-12-29 | Ari M Frank | Collecting naturally expressed affective responses for training an emotional response predictor utilizing voting on content |
US9239615B2 (en) | 2012-10-14 | 2016-01-19 | Ari M Frank | Reducing power consumption of a wearable device utilizing eye tracking |
US9292887B2 (en) * | 2012-10-14 | 2016-03-22 | Ari M Frank | Reducing transmissions of measurements of affective response by identifying actions that imply emotional response |
US9477290B2 (en) | 2012-10-14 | 2016-10-25 | Ari M Frank | Measuring affective response to content in a manner that conserves power |
US9477993B2 (en) | 2012-10-14 | 2016-10-25 | Ari M Frank | Training a predictor of emotional response based on explicit voting on content and eye tracking to verify attention |
US9058200B2 (en) | 2012-10-14 | 2015-06-16 | Ari M Frank | Reducing computational load of processing measurements of affective response |
US9032110B2 (en) | 2012-10-14 | 2015-05-12 | Ari M. Frank | Reducing power consumption of sensor by overriding instructions to measure |
US20150040149A1 (en) * | 2012-10-14 | 2015-02-05 | Ari M. Frank | Reducing transmissions of measurements of affective response by identifying actions that imply emotional response |
US8898344B2 (en) | 2012-10-14 | 2014-11-25 | Ari M Frank | Utilizing semantic analysis to determine how to measure affective response |
US10311510B2 (en) * | 2014-09-05 | 2019-06-04 | Apple Inc. | System and method for providing sequential media items |
Also Published As
Publication number | Publication date |
---|---|
WO2010030452A2 (en) | 2010-03-18 |
US20100070436A1 (en) | 2010-03-18 |
WO2010030452A3 (en) | 2010-05-06 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US8037011B2 (en) | Method and apparatus for recommending content items | |
US20220156792A1 (en) | Systems and methods for deducing user information from input device behavior | |
US10123082B2 (en) | Content delivery system for key moment identification from audience data | |
US8661462B2 (en) | Information processing apparatus and method, computer program thereof, and recording medium | |
US20090150340A1 (en) | Method and apparatus for content item recommendation | |
US11750895B2 (en) | Crowd-sourced program boundaries | |
US7877765B2 (en) | Viewing pattern data collection | |
US8526784B2 (en) | Digital video recorder collaboration and similar media segment determination | |
US20080115166A1 (en) | Digital video recorder processing system | |
US20090178071A1 (en) | Intelligent automatic digital video recorder | |
US20120278330A1 (en) | Systems and methods for deducing user information from input device behavior | |
US11968424B2 (en) | System and method for selection of supplemental content according to skip likelihood | |
JP4586343B2 (en) | Information processing apparatus and method, recording medium, and program | |
WO2012148770A2 (en) | Systems and methods for deducing user information from input device behavior | |
US20240089535A1 (en) | System and method for selection of supplemental content according to skip likelihood | |
US11647262B2 (en) | Content summaries for upcoming media assets | |
GB2438646A (en) | System for content item recommendation | |
US20120254906A1 (en) | Movie recommendation system and movie recommendation method | |
JP4609244B2 (en) | Content playback apparatus and content playback method | |
US11985395B2 (en) | Content summaries for upcoming media assets | |
US20240147003A1 (en) | Systems and methods for providing media content | |
KR102569660B1 (en) | Display apparatus and the control method thereof | |
GB2438645A (en) | System for content item recommendation | |
JP4305863B2 (en) | Program ranking apparatus, program ranking method, and program ranking program | |
JP4712319B2 (en) | Program viewing device |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: MOTOROLA, INC.,ILLINOISFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:GADANHO, SANDRA C.;LHUILLIER, NICOLAS;MERCER, KEVIN C.;SIGNING DATES FROM 20080829 TO 20080909;REEL/FRAME:021528/0841Owner name: MOTOROLA, INC., ILLINOISFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:GADANHO, SANDRA C.;LHUILLIER, NICOLAS;MERCER, KEVIN C.;SIGNING DATES FROM 20080829 TO 20080909;REEL/FRAME:021528/0841 |
|
AS | Assignment |
Owner name: MOTOROLA MOBILITY, INC, ILLINOISFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:MOTOROLA, INC;REEL/FRAME:025673/0558Effective date: 20100731 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
AS | Assignment |
Owner name: MOTOROLA MOBILITY LLC, ILLINOISFree format text: CHANGE OF NAME;ASSIGNOR:MOTOROLA MOBILITY, INC.;REEL/FRAME:029216/0282Effective date: 20120622 |
|
AS | Assignment |
Owner name: GOOGLE TECHNOLOGY HOLDINGS LLC, CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:MOTOROLA MOBILITY LLC;REEL/FRAME:034421/0001Effective date: 20141028 |
|
FPAY | Fee payment |
Year of fee payment: 4 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 8TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1552); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 8 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 12TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1553); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 12 |