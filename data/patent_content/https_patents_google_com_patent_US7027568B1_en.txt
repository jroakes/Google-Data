US7027568B1 - Personal message service with enhanced text to speech synthesis - Google Patents
Personal message service with enhanced text to speech synthesis Download PDFInfo
- Publication number
- US7027568B1 US7027568B1 US08/948,328 US94832897A US7027568B1 US 7027568 B1 US7027568 B1 US 7027568B1 US 94832897 A US94832897 A US 94832897A US 7027568 B1 US7027568 B1 US 7027568B1
- Authority
- US
- United States
- Prior art keywords
- instructions
- server
- data
- speech
- messages
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Expired - Fee Related
Links
Images
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04M—TELEPHONIC COMMUNICATION
- H04M3/00—Automatic or semi-automatic exchanges
- H04M3/42—Systems providing special services or facilities to subscribers
- H04M3/487—Arrangements for providing information services, e.g. recorded voice services or time announcements
- H04M3/493—Interactive information services, e.g. directory enquiries ; Arrangements therefor, e.g. interactive voice response [IVR] systems or voice portals
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L13/00—Speech synthesis; Text to speech systems
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04M—TELEPHONIC COMMUNICATION
- H04M1/00—Substation equipment, e.g. for use by subscribers
- H04M1/72—Mobile telephones; Cordless telephones, i.e. devices for establishing wireless links to base stations without route selection
- H04M1/724—User interfaces specially adapted for cordless or mobile telephones
- H04M1/72403—User interfaces specially adapted for cordless or mobile telephones with means for local support of applications that increase the functionality
- H04M1/7243—User interfaces specially adapted for cordless or mobile telephones with means for local support of applications that increase the functionality with interactive means for internal management of messages
- H04M1/72436—User interfaces specially adapted for cordless or mobile telephones with means for local support of applications that increase the functionality with interactive means for internal management of messages for text messaging, e.g. SMS or e-mail
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04M—TELEPHONIC COMMUNICATION
- H04M3/00—Automatic or semi-automatic exchanges
- H04M3/42—Systems providing special services or facilities to subscribers
- H04M3/487—Arrangements for providing information services, e.g. recorded voice services or time announcements
- H04M3/493—Interactive information services, e.g. directory enquiries ; Arrangements therefor, e.g. interactive voice response [IVR] systems or voice portals
- H04M3/4938—Interactive information services, e.g. directory enquiries ; Arrangements therefor, e.g. interactive voice response [IVR] systems or voice portals comprising a voice browser which renders and interprets, e.g. VoiceXML
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04M—TELEPHONIC COMMUNICATION
- H04M2201/00—Electronic components, circuits, software, systems or apparatus used in telephone systems
- H04M2201/60—Medium conversion
Definitions
- the present invention relates to communication systems and terminal devices for providing personalized information delivery services.
- the present invention relates to such a service utilizing one or more network servers to perform personalized information selection and partial conversion of text information to a speech instruction set, various forms of communication to and from a subscriber's terminal, and storage and conversion circuitry in the terminal to provide audible outputs of the information on demand in the form of synthesized human speech.
- U.S. Pat. No. 4,554,418 to Toy discloses a system that continuously monitors a stream of input data, such as financial or stock information.
- the subscriber submits a list of specific information, such as names of securities of interest.
- a subscriber-specified contact process occurs.
- Such a specified process may be updating a historical file maintained on the selected subject matter, notification by telephone or computer, or performance of predetermined functional calculations. While this type of system does provide customers with desired information, the ability to receive the information is limited to some type of hardwired (fixed) access, by the need to call in from a normal telephone or communicate via a computer.
- U.S. Pat. No. 4,812,843 to Champion, III et al. describes a communication system capable of continuously updating information on a variety of subscriber selected subjects.
- the patent deals with updated traffic information, although the text suggests application to other types of information, including the news.
- a subscriber inputs DTMF tone codes to select particular information of interest, such as a desired route.
- the communications system provides the subscriber with updated information reports from information gathered in a database.
- the system supplies the updated information to the subscriber, in one embodiment by playing pre-recorded voice messages for reception via mobile or landline telephone.
- the patent discloses alternate embodiments which send data for display on a computer system or a pager.
- U.S. Pat. No. 5,398,021 to Moore teaches transmission of sports, stock, weather and other news-like data through a paging system.
- a subscriber database stores records identifying the communication services subscribed to by the party associated with each paging receiver.
- Prior systems such as those suggested to by Champion and Moore, do provide services to send information on subscriber selected topics and some mobility, but the information is transmitted and presented in text form on a computer or a pager display. This is quite adequate in some applications, for example when the subscriber is sitting at a terminal at home or in the office or the subscriber is waiting in a lounge at a transportation terminal.
- the subscriber would like to receive the information but can not use her hands to activate the terminal or look at the terminal for an extended period to read a display. For example, while driving a car a subscriber can not read long news messages presented on a pager display. However, if presented in a convenient form, the subscriber may still want to receive the information at such times.
- Devices also have been developed to present users information in audible form. In many situations, a user can listen to the audible presentation while engaged in other activities.
- U.S. Pat. No. 5,444,768 to Lemaire et al. discloses a portable computer device for audio reproduction of messages.
- the device includes a telephone line interface, such as a modem, for receiving digitized messages from a central facility.
- the central facility downloads textual data messages through the telephone network and the interface, for storage in random access memory.
- a microprocessor executes text-to-speech conversion rules to provide amplitude and pitch information to excite a digital filter within a speech processor, to create synthetic speech output from the textual data messages.
- the Lemaire et al. device includes a limited number of tape recorder like switches to activate start/stop, scan and rewind functions for message playback. Portability of the device is limited by the need for a physical connection to the telephone line.
- the program for converting text to speech, using the stored vocabulary of phonemes, diphones and triphones, requires additional memory. Although this approach provides adequate speech for computer applications, the memory requirements for the program and the vocabulary are too large for incorporation in a small portable terminal device. As such, systems like that disclosed by Lemaire et al. or the AccuVoice system are not readily adaptable to personal communication services, which sometimes require communications to small portable terminal devices.
- U.S. Pat. No. 5,594,779 to Goodman discloses a mobile audio on demand system. Users transmit program selections to a service provider, and the service provider transmits selected audio program information to the users' mobile terminals.
- the system utilizes cellular telephone communications to transmit the selected audio information in digitized, compressed form.
- the terminal device may receive the audio data via a high data rate channel and store the compressed information in memory. The compressed audio data may then be retrieved and decoded by a decoder/encoder, and presented to the user at a selected time.
- the Goodman system does enable some mobility, but there is no provision for receiving and processing text messages.
- the network transmits digitized speech messages, which requires large amounts of storage in the terminal and may require a relatively large bandwidth if there is a desire to send the messages in real time or at rates faster than real time.
- the terminal devices should provide a high quality speech type audible output of the information.
- the bandwidth and memory requirements must be kept low to make the service economical and to minimize the cost of the portable terminal.
- the processing that the terminal must perform on the received information to produce the speech output also should be minimized, thereby eliminating the need for complex and expensive text to speech conversion equipment and/or software in the typical end user's terminal.
- the present invention addresses the above noted needs and provides advances over the existing technology by logically dividing the functionalies involved in text to speech conversion between a server in a network and the subscribers terminals.
- the equipment and software of the server is shared by many subscribers, thus distributing the cost.
- the hardware and software of the terminal becomes relatively simple and inexpensive.
- the server performs most of the complex text to speech algorithm and then generates instructions for a synthesized speech generator, preferably a concatenative speech synthesizer having a relatively small vocabulary of stored sounds. Although the instructions require transmission and storage of more data than a pure text message, they still require significantly less data than digitized and compressed voice messages.
- the circuitry in the terminal receives instructions to play selected sounds from a small stored vocabulary. The instructions specify the sound and a number of playback parameters, such as attack, duration, decay and pitch.
- the synthesizer in the customer terminal device does not need to perform complex text to speech conversion operations.
- the terminal device may be implemented in a variety of forms.
- the terminal may be a computer, such as a personal computer (PC) coupled to a data network.
- PC personal computer
- the invention also encompasses portable terminal implementations utilizing wireless communication.
- the customer's portable terminal device is much less complex and therefore cheaper to manufacture than would otherwise be the case. It also is easier to manufacture the terminal device in a small form factor.
- the terminal devices can produce upgraded synthesized speech outputs, without the need to upgrade the hardware or software of the terminal devices.
- aspects of the invention relate to systems, servers terminal devices and methodologies relating to message services utilizing the synthesizer instruction set to communicate information for synthesized speech reproduction.
- a system in accord with the invention comprises a server and at least one subscriber terminal.
- the server is coupled to a data communication network.
- the server is programmed to execute sequences of program instructions. The programming enables the server to obtain textual information to form messages for a plurality of subscribers.
- the server performs a significant portion of a text to speech process to convert the textual information of at least one of the messages to speech synthesizer instructions.
- the server transmits the speech synthesizer instructions over a data communication network.
- the subscriber terminal receives the speech synthesizer instructions via the data communication network.
- the terminal includes a speech synthesizer for synthesizing an audible speech representation of the message from the speech synthesizer instructions.
- the server comprises a programmed computer coupled to a data communication network, such as the Internet.
- a data communication network such as the Internet.
- Each speech synthesizer instruction generated by the server identifies a fundamental sound and at least one control parameter for controlling generation of a waveform corresponding to the fundamental sound.
- the preferred implementation of the terminal includes a data interface for receiving data from a communication network.
- the interface may couple the terminal to the Internet, or the interface may comprise a wireless modem (e.g. a CDPD modem) for communication via a wireless packet data network.
- the terminal also includes a programmable central processing unit for processing received data to capture the speech synthesizer instructions.
- a memory in the terminal stores the set of fundamental sound samples, in digitized form.
- a concatentative speech synthesizer processes samples from the memory in an order specified by the instructions and controls parameters of each of the processed samples in a manner specified in the instructions.
- the synthesizer generates a speech waveform signal representative of the text information from which the sequence of instructions originally were generated in the server.
- the server may receive news items from a number of sources to obtain the text messages for processing.
- the server may principally function to perform the text to synthesizer instruction processing.
- the server receives text mail type messages from other elements of the system, such as a mail server or a unified message management platform.
- an information provider would operate an independent system for processing news materials and for profile matching. The provider's system would supply selected news items as textual mail messages to the mail server or the unified message management platform.
- FIG. 1 is a high level functional diagram of a system implementing the present invention.
- FIG. 2 is a block diagram of the operations involved in converting input text to speech, and illustrates the division of these functions between the network server and the terminal device.
- FIG. 3 is a simplified block diagram illustrating the significant functional components of a portable terminal for use with the system of FIG. 1 .
- FIG. 4 is a simplified block diagram illustrating the significant functional components of a desk-top personal computer (PC) for use as another type of subscriber's terminal in the system of FIG. 1 .
- PC personal computer
- FIG. 5 is a high level functional diagram of a somewhat modified system for implementing the present invention.
- the present invention utilizes one or more servers in a network to receive textual information and from that information develop or identify text messages for delivery to individual subscribers.
- the invention involves text to speech conversion.
- the present invention relies on a division of the conversion processing between a server and the terminal.
- the same server that accumulates the text messages or another server in the network converts the textual information in each message to a sequence of speech synthesizer instructions. That server transmits converted messages, containing the sequences of speech synthesizer instructions, to each identified subscriber's terminal device.
- a synthesizer in the terminal generates an audio waveform signal, representing the speech information, in response to the instructions.
- the system of the present invention could use a variety of different types of speech synthesizer.
- the format of the instructions corresponds to the type of synthesizer utilized.
- the presently preferred embodiment utilizes a concatenative speech synthesizer with and associated vocabulary of stored fundamental sound samples.
- the instructions identify the sound samples, in the desired playback order.
- the instructions also provide parameters for controlling characteristics of the signal generated during synthesizer processing of each sound sample in each sequence. For example, the instructions may specify the pitch, duration, attack envelope and decay envelope, for each sample.
- FIG. 1 shows a first embodiment of an overall system implementing a personalized message service in accord with the present invention.
- a service provider will operate one or more network servers 10 .
- the server 10 comprises a computer system having one or more data communication interfaces 11 for obtaining information from a number of sources 20 .
- the sources may provide a wide range of information, although for purposes of discussion here it is assumed that the sources provide various types of news information. Examples of the sources 20 include API, UPI, Nexus, Dow Jones and the like.
- the server receives text information from the sources 20 and processes and/or parses the text into messages.
- the text messages may include E-mail, news-group postings and web page information.
- the messages comprise individual news items.
- the messages are classified and stored in a database 12 .
- the computer server 10 runs an operating system, and various applications run on that operating system.
- the computer operating as the server 10 runs an application program (not shown) for controlling the physical elements of the interfaces 11 and for processing, classifying and storing the input text messages.
- An associated application program 13 develops, stores and maintains subscriber profile records. This program receives subscriber inputs from various sources discussed below to develop each customer's profile and stores the profiles in a database 14 .
- the personal message service provides highly specific selection options, allowing each subscriber to establish a very personalized profile to control the selection of those news items each finds particularly interesting.
- the program software classifies news items received from various sources into a large number of different subject mater categories.
- the server may receive usenet or newsgroup messages as text, based on the user's profile and preferences.
- the user could fill out essentially a card marking various categories and mail or fax that card to a service bureau. Personnel at the service bureau would input data from the card, either manually or using appropriate scanner, to provide the profile information for use by search engine software.
- a user might call in and talk to an agent who would enter the profile data into the system.
- the user could call in and listen to a series of menus and input selections as keypad signals on a telephone.
- Another way is to use a PC 40 to communicate with a WEB page site (not shown) on the Internet 21 . In this manner, the user could pick topics from a menu or put in key words relating to topics of interest.
- the input profile information is entered into a file in the database 14 , for use by the server 10 that receives and processes the incoming news information from the various sources 20 .
- the program 13 When messages come in to the server 10 from the sources 20 and are stored in database 12 , the program 13 also compares the classification and/or the content of each message or news item to the profiles of the various subscribers 14 . When a text message matches a subscriber's profile, the program 13 forwards the message to another application program 15 , for the initial portion of the text to speech conversion.
- To forward messages to individual subscribers involves a number of network operations relating to a conversion from text to synthesizer instructions as well as instruction formatting and transmission. These operations may be performed in a separate server communicating with the server which receives the input text messages and processes the messages in accord with the profile information.
- one computer server system coupled between the news sources 20 and a data network 21 performs the message accumulation and processing as well as the functions relating to conversion, formatting and transmission.
- Each of the terminal devices 30 or 40 implement a concatenative type speech synthesizer.
- This type of synthesizer uses a database (stored vocabulary) of recorded natural speech sound samples.
- the synthesizer concatenates coded speech segments together in a specified sequence and performs some signal processing to provide inflection or intonation and to thereby smooth transitions between segments, to produce an electrical speech waveform signal.
- the server 10 in the network, determines the appropriate stored sounds and the parameters of the playback of those sounds, needed to produce a high quality speech output corresponding to the input text.
- the synthesizer in the terminal plays back the sounds selected by the server and in the manner specified by the server to reproduce the information from the original text message in a spoken language form.
- the application 15 converts the text to the high level speech parameters (sound sample identifications and waveform control parameters) and a succeeding application 17 formats the speech parameters into an instruction set.
- a number of instruction sets and protocols may be used.
- the preferred implementation utilizes MIDI (Musical Instrument Digital Interface) commands, where the receiving terminal interprets the commands to control the speech synthesizer instead of a music synthesizer.
- the resulting instructions identify sequences of individual sounds for waveform synthesis and certain control parameters for each sound sample, which a synthesizer can use to ultimately synthesize a voice waveform to drive an audible output.
- the application 15 may store the sequences of instructions for the converted messages in another database (not shown).
- the text to speech conversion process and the preferred instruction set are discussed in more detail below. However, at this point, it should be noted that the instruction set is specifically tailored for control of a synthesizer.
- the information is neither a digitized and compressed audio waveform nor a text message.
- the instructions require more bits to transmit information than if the message was sent as text, but the instructions require significantly less data than a digitized voice message, even if the voice message were compressed.
- the computer operating as the server 10 also runs an application 19 to packetize the synthesizer instructions in a common packet protocol, preferably Transmission Control Protocol/Internet Protocol (TCP/IP), although a proprietary protocol may be used.
- the computer server 10 also includes a router (not separately shown). The router provides a two-way data communication connection to a packet switched data network 21 providing connectionless transport for TCP/IP packetized communications.
- This data network 21 may comprise the public network referred to as the Internet. Alternatively, a private data network may be used.
- the TCP/IP protocol processing and the router enable the server 10 to transmit packets, containing the synthesizer instructions and related signaling information over the data network 21 .
- the server can signal any data device coupled to the network and then send news items or other messages as sequences of synthesizer instructions, over the data network 21 and any other networks coupled thereto.
- subscribers to the information service provided by the server 10 will have a variety of terminal devices.
- the terminal devices will have some means to communicate data, preferably via the network 21 to and from the server 10 .
- Such terminals also will have a concatenative speech synthesizer capable of acting upon the sequences of instructions to produce synthetic speech outputs of the message information.
- Examples of the terminals include a personal computer (PC) 40 and a portable wireless terminal device, identified as a personal message terminal 30 in the drawing.
- the subscriber terminals may be implemented in other forms, for example, in a set-top terminal device for use with a digital broadband network.
- the PC 40 here is an example of a data terminal device coupled to the data network 21 and capable of two-way data communication over that network.
- a PC might include a modem and access the Internet through a dial-up telephone connection through the Public Switched Telephone Network (PSTN) and an Internet Service Provider (ISP).
- PSTN Public Switched Telephone Network
- ISP Internet Service Provider
- the PC may connect to a local area network, having a coupling to the network of an ISP.
- the subscriber operates the PC 40 to send requests for specific messages and/or profile definition information through the network 21 to the server 10 .
- the PC 40 receives a series of packets representing news or other types of messages from the server 10 .
- the PC performs a synthesis operation to convert the entire message to a voice waveform, for audible output or for storage on an analog recording device.
- the data network 21 also provides two-way data communications to a wireless data network.
- the present invention could utilize a number of existing wireless service networks, such as paging networks (preferably two-way), to provide the data communications from the server 10 to the customers' terminal devices.
- the wireless data network could use wireless relay transceivers and wireline access points of the type marketed by Metricom (Los Gatos, Calif.) as part of the Ricochet wireless network.
- Digital cellular networks such as CMA, TDMA, and GSM, also can carry data, for example, for the personal message service.
- Satellite based data networks such as that operated by RAM Mobile Data, also are contemplated.
- the presently preferred embodiment utilizes a cellular digital packet data (CDPD) network 23 as the wireless data network for communication with the personal message terminals 30 .
- CDPD digital packet data
- the CDPD network 23 provides two-way wireless data services to a portable or mobile terminal device, such as the personal data device (PDD) 35 and the personal message terminal 30 .
- PPD personal data device
- CDPD Cellular Digital Packet Data
- AMPS advanced mobile phone system
- TCP/IP Transmission Control Protocol/Internet Protocol
- a local CDPD network 23 comprises one or more mobile data intermediate systems (MD-IS) 25 , each of which has a TCP/IP connection to the landline data network 21 .
- MD-IS 25 also has data connections to a number of CDPD base stations 27 , only two of which appear in FIG. 1 .
- the intermediate system (MD-IS) 25 has a primary role of forwarding data from one sub-network to another, for example between the base stations 27 and the link(s) to the Internet 21 .
- the mobile data intermediate system MD-IS 25 performs data packet routing based on knowledge of the current location of each wireless subscriber station within the range of the mobile data base stations 27 , which are under the control of the particular MD-IS 25 .
- a number of mobile data base stations 27 can be under the control of a single mobile data intermediate system 25 .
- a number of mobile data intermediate systems are connected to each other through intermediate systems (not shown).
- the overall CDPD network is controlled by a network management system (NMS) 29 having an interface with at least one of the mobile data intermediate systems 25 .
- NMS network management system
- the typical base unit or mobile data base station 27 in a CDPD system utilizes an available channel within an AMPS cell to establish a link and communicate with a user's wireless station, such as the PDD 35 or the terminal 30 .
- the CDPD system employs connectionless network services (CLNS) in which the network routes each data packet individually based on the destination address carried in the packet, knowledge of current network topology and the location of the user's wireless station in the network.
- CLNS connectionless network services
- the packetized nature of the data transmissions from each CDPD terminal device allows many CDPD users to share a common channel, accessing the channel only when they have data to send and otherwise leaving the channel available to other CDPD users.
- the packet data service through this network 23 enables users to transmit and receive TCP/IP packet data at 19.2 Kbps over the cellular network channels, using any portable computing device and a CDPD modem.
- the CDPD network will support packet data services for a large number of users, many of whom many be simultaneously registered on the network. Some of the CDPD subscribers will be subscribers to the personal message service of the present invention.
- CDPD terminals such as 30 and 35 register through a base station 27 with the MD-IS 25 , when active. Once registered as active on the wireless network, a CDPD terminal such as 30 or 35 can communicate packets of data in two directions, to transmit data upstream through the air link and a public data network (e.g. coupled to the Internet) and to receive data sent downstream from the public packet data network through the air link to the terminal.
- a CDPD terminal When not engaged in actual data communication, the CDPD terminal waits in an idle state until it receives data from the network or it needs to send data upstream through the network, for example in response to a user input.
- the portable message terminal 30 includes a standard CDPD modem.
- the two-way CDPD communication enables the user to sign-on to the network 23 , and through the networks 21 , 23 , to communicate with the server 10 providing the message service.
- the terminal 30 can send service control data upstream, for example to input selections or new or updated profile information.
- the server 10 When the server 10 has new information corresponding to the subscriber's profile, the server 10 initiates a transmission through the public data network (e.g. the Internet) 21 and the CDPD wireless network 23 to the subscriber's terminal 30 .
- the public data network e.g. the Internet
- the server 10 initially sends a notification message identifying the subject matter of the item.
- the terminal 30 or 40 stores this message and provides a beep tone or other alert to the subscriber, indicating receipt.
- the terminal either displays or delivers, as synthesized speech, information regarding the item from the notice message, in response to an appropriate user activation of the terminal.
- the actual delivery of the packets containing the synthesizer instructions may operate in several different modes, depending on how the service provider elects to program the server 10 and the terminals 30 , 40 .
- the server may send the entire item through the network(s) for immediate storage in the memory of the terminal. With such an operation, the terminal would notify the subscriber upon completion of the download operation and would provide playback in response to a subsequent user activation.
- the terminal 30 or 40 may wait for a user activation to request downloading of the news item identified in the notice message.
- the terminal typically would initiate a playback upon complete reception of the actual news item through the network.
- the terminal may, as above, provide a beep tone or other alert to the subscriber indicating receipt.
- the subscriber can wait to request the download until she desires to listen to the newscast or other personal messages. Alternatively, if the subscriber is no longer interested in the subject matter indicated in the initial notice message, the subscriber can activate a key on the terminal 30 or 40 , causing the terminal to send an instruction upstream to the server 10 telling the server to delete the news item from those currently stored for this subscriber.
- the communications for the personal message service tend to be asymmetrical.
- the upstream transmissions typically consist of short bursts of data representing identification and registration information and the subscriber's selection and control inputs.
- the total data transmission is somewhat larger.
- 1 kbyte of text converts into approximately one minute of synthesized speech output.
- To transmit and store a twenty minute newscast for example would require approximately 20 kbytes of data if transmitted as text data.
- the synthesizer instruction format increases the amount of data needed to convey the information somewhat.
- the terminal receives and stores the synthesizer instructions from the TCP/IP packets and then processes the instructions to synthesize an audio waveform. Consequently, the transmissions from the server 10 to the terminal 30 or 40 need not occur in real-time, as transmission of speech in a two-way conversation must do.
- the subscriber can operate the keypad on the terminal device to input information for transmission upstream to the server regarding the particular item.
- the input information may indicate how the subscriber rated the item in comparison to the subscriber's desired profile, i.e. as a match to the subscriber's desired news information or as not matching the subscriber's needs. This causes the profile 13 of the subscriber to be updated and, therefore, improved in its ability to correctly match content to the subscriber's needs.
- Another example of a subscriber input might be an instruction to the server 10 to forward the item to one or more identified persons. If the message presented relates to an advertisement or offer, the subscriber input may initiate a purchase or other transaction related to the message.
- a significant feature of the invention relates to the allocation of the functions involved in converting text messages to synthesized speech waveforms for audible presentation to the subscribers. To better understand this aspect of the invention, a high level explanation of these functions with reference to FIG. 2 may be helpful.
- the process of text to speech conversion involves three major operations.
- the first operation involves the computation of linguistic parameter specifications, such as phoneme sequences and accent parameters, from the input text data.
- the second operation involves the conversion of the linguistic parameters into actual synthesizer control parameters, such as concatenative unit indices, pitch and duration.
- a concatenative synthesizer receives the control parameters, and in response, concatenates and processes sequences of sound samples from its vocabulary database to generate the actual sound waveform.
- FIG. 2 depicts the functions involved and the breakdown of these functions between the network server 10 and the terminal device 30 or 40 .
- function 51 receives the text input and generates the linguistic parameter specifications, including identification of phonemes in sequence and various prosodic information.
- the generation process 51 uses a grammar 55 for parsing the text and dictionary information 53 relating to the lexicon of the particular text language (e.g. English). English is only used as an example, and not meant to exclude any language.
- the operation of the process 51 to generate the phoneme and prosody information from the input text corresponds to the first basic function of text to speech conversion.
- the process 51 supplies the indices of the phonemes together with the prosodic information to a prosody control function 61 .
- the function 61 applies a set of prosody control rules 67 to generate fundamental frequency, amplitude and duration data.
- the prosody control process also interacts with a spectrum generation operation 63 .
- the operation 63 uses stored speech sequence data 65 to generate spectrum information characterizing the speech.
- the prosody control function 61 and the spectrum generation operation 63 perform the second major function of the text to speech conversion, i.e. the conversion of the linguistic parameters into actual synthesizer control parameters.
- the outputs from the prosody control function 61 and the spectrum generation operation 63 need to go to the actual waveform generation process. In accord with the invention, the operations to this point all are performed in the server 10 , within the network.
- the outputs from the prosody control function 61 and the spectrum generation operation 63 go to a transmit operation 69 , which formats the information for transmission through the network(s) 21 and 23 .
- a process 71 receives the formatted synthesis information via the network(s) 21 and 23 .
- the receive process 71 forwards the fundamental frequency, amplitude and duration data and the spectral information to the speech synthesizer 73 .
- the speech synthesizer 73 uses this information to control the generation of an analog waveform, which provides a synthesized representation of the input text in speech form.
- the preferred embodiment utilizes a concatenative speech synthesizer 73 .
- the received information identifies sequences of specific sound samples (phonemes, and a number of diphones and/or triphones) stored in digital form, as a vocabulary 75 .
- the received information also provides control parameters, such as frequency (or pitch), attack or decay and duration, which the synthesizer 73 uses to adjust playback of each individual sound sample.
- control parameters such as frequency (or pitch), attack or decay and duration, which the synthesizer 73 uses to adjust playback of each individual sound sample.
- the synthesizer 73 concatenates and processes sequences of sound samples from its stored vocabulary 75 to generate the actual sound waveform in accord with the sequence of instructions from the server 10 .
- the subscriber's terminal device 30 or 40 includes a memory storing a small vocabulary of speech sounds. This vocabulary includes all of the basic phonemes found in human speech as well as the most common diphones and triphones.
- a microprocessor in the terminal retrieves a selected sound sample from memory and supplies the sound sample to the appropriate digital signal processor operating as the synthesizer.
- the microprocessor also sends parameter control instructions to the synthesizer.
- the control instructions specify the manner in which the digital signal processor (synthesizer) processes each digitized sound sample for waveform signal synthesis, for example by modifying the digital values of the sample to adjust the attack and decay, the pitch, and/or the duration of the sample.
- the microprocessor selects the sample and generates the instructions for playback in response to the synthesizer instructions received from the server 10 .
- the data representing the synthesizer instructions for communicating the information content from the textual news item message takes the form of a reduced instruction set for controlling the speech reproduction operations of the terminal device.
- the reduced instruction set provides more information than pure text, but less information than digitized and compressed speech.
- Each text message is translated into a series or sequence of instructions relating to the sounds that the synthesizer in the terminal needs to reproduce.
- Each of the transmitted message instructions will specify one of the stored samples and the manner of synthesis of the signal for that sample.
- a variety of protocols could be used to carry the reduced set of instructions for the news item messages. The presently preferred embodiment utilizes the MIDI protocol.
- the Musical Instrument Digital Interface or ‘MIDI’ protocol is designed to enable electronic devices, such as music synthesizers and computers, to interact and work in synchronization to produce audible musical outputs. Communication may be one-way (send only or receive only), or communication may be two-way (send and receive).
- the MIDI protocol defines messages for sending control information from a source, typically a MIDI controller, to a destination via a data stream.
- the typical MIDI commands translate human gestures, such as key presses and releases on a keyboard, into MIDI messages.
- the typical destination is a tone module of a synthesizer, but there are now many different types of devices that use MIDI to communicate.
- the MIDI protocol is used to identify the sound samples for synthesis and to specify aspects of the manner of waveform synthesis. A summary explanation of the message formats of this preferred protocol may be helpful.
- MIDI communications utilize multibyte messages consisting of one status byte followed by one or more data bytes.
- the status byte determines what operation the MIDI destination should perform.
- the data bytes define the information necessary for that operation to take place. Since MIDI messages can contain either one or two bytes of data the receiver must scan the incoming stream of MIDI bytes for discrete messages of different lengths.
- the protocol facilitates this by byte type recognition by insuring that status bytes and data bytes are “partitioned” into unique value ranges, such that no status byte can be confused with a data byte and vice versa.
- Status bytes have their most significant bit (MSB) set to differentiate them from data bytes.
- MSB most significant bit
- the status bytes range in value from 128 to 255, which means that there are one hundred twenty-eight possible values of the status bytes.
- the data bytes range in value from 0 to 127, which means that there also are one hundred twenty-eight possible values of the data bytes. Since the two types of bytes are partitioned it is easy for the MIDI receiver to assemble incoming messages from the byte stream, by spotting status bytes and treating all bytes until the next status byte as data bytes for the same message.
- a device receiving a series of bytes assumes that data bytes relate to the most recent status byte until it detects another status byte.
- the MIDI message data is transmitted in 10-bit packets each consisting of a “start bit” followed by 8 information bits (the byte) followed by a “stop bit”.
- the MIDI receiver accepts the incoming data stream at its MIDI interface and assembles the regular flow of O's and 1's (bits) back into the byte-size MIDI messages.
- the MIDI protocol is capable of separating information into sixteen logical channels.
- the protocol standard specifies the format of Channel Messages and System Messages.
- Channel Messages apply to a specific channel identified by a 4-bit number included in a status byte of each of these messages.
- System messages are not channel specific, and no channel number is indicated in their status bytes.
- Channel Messages and many of the System Messages consist of one status byte followed by one or two data bytes, except for system exclusive messages, which have an arbitrary number of data bytes.
- the Note On message begins with a status byte containing the “note on” operation code (1001 binary, or 9 decimal) together with the 4-bit identifier of the relevant channel affected.
- the Note On message also includes two data bytes. When used with an instrument, the first data byte of this message defines the key that was depressed on the controller, whereas the second data byte defines the velocity at which the user pressed the key.
- the Channel Messages typically will comprise a status byte and two data bytes.
- the status byte identifies the relevant action.
- the Note On command indicates a start of sample synthesis
- Note Off indicates a termination of synthesis of a particular sample.
- the speech synthesis process does not utilize separate channels as such, therefore the 4-bit channel identifier in the status byte can be used to represent a first control parameter, for example a frequency offset for the beginning or end of a sample to identify sets of samples, or to specify different voice fonts.
- the synthesizer might adjust the beginning or ending pitch of a sample, to achieve a desired inflection and/or blending with a preceding or succeeding sound sample.
- the first data byte of a Channel Message is used to identify the sound sample for playback.
- the MIDI protocol uses data bytes having a range of 128 different values, this enables selection of 128 sound samples from the stored vocabulary.
- This vocabulary includes all of the basic phonemes found in human speech as well as a number of the most common diphones and triphones.
- the second data byte specifies another control parameter, such as angle of attack or decay.
- the MIDI standard also specifies a format for a MIDI Time Code (allowing synchronization).
- Each of the files containing a news item message in MIDI protocol form will also include replay time-stamp messages, to enable the microprocessor in the terminal device to synchronize the playback.
- the timing information in the file will enable the microprocessor to determine the timing between Note On and Note Off messages for a particular sound sample, and thus calculate the appropriate duration of the sound output for the identified sample.
- FIG. 3 is a functional block diagram of the elements of a preferred embodiment of a portable, wireless terminal device that may serve as the terminal 30 in the system of FIG. 1 .
- the terminal is an intelligent device, with a microprocessor 131 acting as the programmable central processing unit (CPU), to control all operations of the terminal 30 .
- CPU programmable central processing unit
- ROM read only memory
- the terminal also may include a non-volatile memory (EEPROM or Flash memory) storing programming code that may be modified to upgrade the operations of the terminal.
- EEPROM non-volatile memory
- the portable terminal 30 also includes one or more working memories, such as the random access memory (RAM) 137 , cache memory (not shown) and the like.
- the personal message terminal 30 includes a display driver (not shown) and a small display such as a liquid crystal display 141 .
- a user operates a keypad or keyboard 139 to input various information to the microprocessor 131 .
- the keyboard and display represent elements providing a user interface.
- the terminal may incorporate elements providing other user interfaces, such as a touch sensitive LCD screen and/or “soft key” interface.
- the terminal includes an antenna 132 and wireless data modem, for example a CDPD modem 133 .
- the modem 133 is coupled to the microprocessor 131 , for two-way wireless packet data communication via the network 23 .
- the two-way data communication via the network 23 and modem 133 may enable a variety of data communication services.
- these communications allow the terminal 30 to send relatively low speed data upstream, such as user inputs of selection and profile information and these communications allows the terminal 30 to receive TCP/IP packets containing control signaling information as well as the packets carrying the actual speech synthesizer instructions.
- the microprocessor 131 stores received sequences of instructions, e.g. in MIDI form in RAM 137 .
- the microprocessor 131 also is coupled to a speech synthesizer 143 .
- the preferred implementation of the portable terminal device 30 utilizes a concatenative type synthesizer.
- a non-volatile memory device 145 stores a vocabulary of digitized sound samples.
- the non-volatile memory 145 may be a flash memory, an EPROM or a ROM, depending on whether or not it is desirable to allow reprogramming of the vocabulary.
- the synthesizer 143 provides an audio frequency analog signal, representing the synthesized speech waveform, to one or more audio drivers 147 .
- the drivers 147 amplify or attenuate the analog signal level, as necessary, to provide the appropriate power for particular outputs.
- the drivers 147 provide an output to a loudspeaker 148 and well as an output to a jack 149 for headphones or a connection to a stereo system.
- the control program for the microprocessor 131 at least includes the routines necessary for providing the user interface, e.g., through the keyboard 139 and the LCD 141 , the routine for controlling the CDPD modem 133 for data communication, and the routines for specifically sending and receiving the various messages relating to the personal message service.
- the program facilitates processing of user inputs to provide display, and when appropriate, to send input information through the networks to the server 10 .
- the program also includes one or more subroutines for message receipt and playback through the synthesizer 143 .
- the communication processing routine For speech synthesis messages received from the server 10 , the communication processing routine processes the TCP/IP packets supplied to the PC through the modem 133 to recover the sequences of synthesis instructions. In the preferred embodiment, the communication processing routine in the terminal 30 recovers the MIDI instructions, discussed above.
- the microprocessor 131 may run a routine to process these instructions to identify the sound samples and pass the identities of the samples, in the specified sequence, to the synthesizer 143 .
- the microprocessor 131 also processes the synthesizer instructions, for example in MIDI form, to convert the playback parameter information to an instruction set for the particular model of the synthesizer 143 .
- the synthesizer 143 retrieves the digital samples from memory 145 , in the sequence specified in the received instructions.
- the synthesizer 143 processes the digital sound samples to adjust the playback parameters, such as attack, duration, amplitude, pitch and decay, as instructed by the microprocessor 131 .
- the synthesizer 143 converts the processed digital signals to at least one audio signal and supplies that signal to the audio drivers 147 .
- the output device such as the loudspeaker 148 produces an audible acoustic signal representing the synthetic speech interpretation of the text message originally received and processed in the server 10 .
- the programming run by the microprocessor 131 may be downloaded into storage.
- the various applications including the application for the messaging service may be received via the network 23 and the modem 133 .
- the data reception may be useful in downloading upgraded versions of the fundamental sound sample vocabulary, for storage in memory 145 .
- the subscriber's personal terminal device 30 may take a variety of forms.
- the presently preferred embodiment is a form similar to a Walkman cassette player or CD player with a speaker and/or earphones and a jack for connection to a stereo system, for example in a car.
- the subscriber's portable terminal device would utilize a form factor compatible with operation in a cassette player.
- the device would receive and store the messages from the wireless CDPD link.
- motion sensors in the device would detect operation of the tape drive spindles to derive appropriate control signals for synthesis, program selection and audio output operations.
- the device would include a transducer to output audio signals to the tape head of the cassette player for reproduction via the audio system of the player, e.g. through the stereo system of an automobile.
- the personal message terminal is a wireless terminal device implementing a user interface, receiving and storing instructions and providing speech output in response to the synthesizer instructions transmitted by the server 10 .
- the embodiment of FIG. 3 is a representative example of such a terminal, however, other implementations may be used.
- the personal message service terminal 30 may be implemented as a portable PC (laptop or palmtop) having a wireless data modem and a sound card.
- the functionality may also be integrated into an “Internet telephone”, “cellscape phone” or “smart phone”, capable of both sending and receiving live voice conversations and of sending and receiving text over a TCP/IP net using CDPD.
- FIG. 4 is a block diagram of the functional components of a PC type implementation of a data terminal capable of receiving voice synthesis instructions from the server 10 .
- the main processing element of the PC 40 is a programmable central processing unit (CPU).
- the CPU is a microprocessor 231 .
- the control code for certain basic functions of the microprocessor 231 are stored in a read only memory (ROM) 233 .
- the PC terminal 40 also includes one or more working memories, such as the dynamic random access memory (DRAM) 235 , cache memory (not shown) and the like.
- the microprocessor 231 runs programs loaded into the DRAM 235 from other storage devices.
- DRAM dynamic random access memory
- the PC 40 includes a number of different bulk storage systems.
- the PC 40 includes a hard disk drive 237 and one or more floppy disk drives 239 ; and the PC may include other storage media 241 , such as a CD ROM drive, a Jazz or Zip drive, a digital tape drive, or the like.
- An internal bus system 243 provides two way data communications between the various elements of the PC 40 .
- the microprocessor 231 receives digital signals from and sends a variety of digital signals to the other computer components via the bus 243 .
- the PC 40 typically connects through a display driver 245 to a display 247 , such as a color cathode ray tube (CRT) type monitor.
- a display 247 such as a color cathode ray tube (CRT) type monitor.
- a laptop or palmtop implementation of the PC typically utilizes a flat panel display.
- a user operates a keyboard 249 or another type of input device 251 , such as a mouse, trackball, touch screen, or joystick, to input various information to the terminal 40 .
- the input devices 249 , 251 connect to the PC 40 through appropriate input ports, represented generically by the block 253 in the drawing.
- the PC 40 includes one or more systems enabling communication with other data systems, such as a printer port 255 coupled to the bus 244 .
- the PC 40 also includes one or more data interfaces, to facilitate the communications via the public packet switched data network 21 .
- LAN local area network
- ISP Internet Service Provider
- the data interface in the PC 40 may be a modem 259 .
- the modem 259 provides a two-way data communication coupling to a telephone line or other communication network link.
- the modem sends and receives electrical, electromagnetic or optical signals which carry digital data streams representing various types of information in the format appropriate to the particular link.
- the dial-up telephone link may go to an information service provider, such as America Online or Compuserve.
- the PC may use a dial-up telephone link direct to an ISP or private TCP/IP network.
- the data interface and associated network link provide data communication through one or more networks to other data devices.
- the modem 259 may provide a connection through the local telephone network to a host computer or to data equipment operated by an Internet Service Provider (ISP).
- ISP Internet Service Provider
- the ISP equipment in turn provides data communication services through the world wide packet data communication network now commonly referred to as the ‘Internet’ 21 .
- the local telephone network and the Internet both use electrical, electromagnetic or optical signals which carry digital data streams.
- the data communication interface 257 or 259 thus enables the PC 40 to send and receive digitized data over the network 21 .
- the data communications may relate to a variety of applications or services. In accord with the invention, one application that utilizes this data communication capability is the personal message service.
- the LAN interface 257 or modem 259 enables the PC terminal 40 to send data messages through the network 21 to the server 10 , for example to input profile information.
- the LAN interface 257 or modem 259 also enables the PC terminal 40 to receive data relating to this service.
- the data received by the PC 40 via the network 21 includes signaling information, for example notices indicating when news items or other messages are ready for transmission to the particular terminal.
- the data received by the PC 40 via the network 21 also includes the sequences of speech synthesizer instructions forming the converted messages.
- the microprocessor 231 recaptures the MIDI instructions from the received packets and accumulates a data file containing the entire set of MIDI synthesizer instructions corresponding to at least one message.
- the microprocessor stores this data file, for example on one of the disk drives 237 , 239 .
- the PC 40 stores application programs including the routines for receiving an processing the signaling messages and converted messages for the personal message service.
- Such applications may be loaded into storage on the PC in several ways, e.g. by transfer from a floppy disk or CD ROM.
- the various applications, including the application for the messaging service may be received via the network 21 and the data interface 257 or 259 . This capability may be particularly useful in downloading upgraded versions of the fundamental sound sample vocabulary.
- the PC 40 also includes a sound card 261 coupled to the bus 243 .
- the sound card receives instructions over the bus 243 from the microprocessor 231 and receives digital sound samples from a storage device. The samples may come from long term storage on the hard drive 237 , but preferably, during actual synthesis, the sound card receives the sound samples from temporary storage in the DRAM 235 . In response, the sound card 261 generates analog audio output signals.
- the sound card 261 includes a digital signal processor that processes the digital sound samples to adjust the playback parameters, such as attack, duration, amplitude, pitch and decay, and converts the processed digital signals to one or more (e.g. stereo) audio signals.
- the sound card 261 also includes one or more audio driver circuits for amplifying or attenuating the analog signal level, as necessary, to provide the appropriate power for particular outputs.
- the sound card provides an output for two loudspeakers 263 as well as an output to a jack 265 for headphones.
- the microprocessor 231 runs an operating system program, which controls operations of application programs.
- the programs define how the microprocessor 231 respond to signals from the input devices 249 , 251 and produces signals through the driver 245 , to effectuate a desired user interface.
- a computer running a Windows type operating system and Windows compatible application programs provides a graphical user interface, for the operating system functions as well as for most of the applications running on the operating system.
- One of the application programs facilitates the personal message service provided by the operator of the server 10 .
- This program may enable two-way graphic and text communication, similar to a web browser, to allow the user to control the service and to input profile information.
- the personal message service application program also includes one or more subroutines for message receipt through the data interface 257 or 259 and playback through the sound card 261 .
- the program typically stored on the hard disk 237 , has an associated database which contains the fundamental sound vocabulary for use by the synthesizer on the sound card 261 . However, because of the relatively small size of the vocabulary, this database can be loaded into the DRAM 235 with the program for use during program execution, i.e. during actual playback.
- the communication processing routine For messages containing synthesizer instructions received from the server 10 , the communication processing routine processes the TCP/IP packets supplied to the PC 40 by the network 21 , to recover the synthesis instructions. In the preferred embodiment, the communication processing routine in the PC recovers the MIDI instructions, discussed above.
- the microprocessor 231 may run a routine to process these instructions to identify the sound samples and cause the transfer of the samples, in the sequence specified in the instructions of the converted message. The samples are sequentially transferred from memory 235 to the sound card 261 over the bus 243 .
- the microprocessor 231 also processes the synthesizer instructions, for example in MIDI form, to convert the playback parameter information to an instruction set for the particular synthesizer functionality of the sound card 261 , to enable the sound card to adjust the parameters of each sample during waveform synthesis.
- the sound card 261 receives the sound samples and appropriately formatted playback instructions over the bus 243 .
- the sound card processes the samples per the instructions to produce the desired synthetic speech output signal.
- the output signal may go to an audio transducer such as loudspeakers 261 for immediate presentation of the playback, or to an analog storage device for later playback.
- the above discussion of the terminals 30 , 40 assumed use of generic synthesizer equipment to process sound samples and produce synthesized speech outputs.
- the MIDI processing generally was implemented in software.
- An alternative approach might implement the synthesizers in the terminals using MIDI compatible chips and move all MIDI processing to those chips.
- Existing MIDI chips process digital samples from memory, normally to produce musical outputs.
- a MIDI chip in the terminal 30 acting as the synthesizer or a MIDI chip on the sound card 261 would utilize the stored vocabulary as its sound samples.
- the MIDI chip would process the vocabulary sound samples in direct response to the synthesizer instructions received via the networks 21 , 23 , to thereby synthesize the desired speech output.
- FIG. 5 illustrates a somewhat different network implementation of the present invention.
- this version of the overall system depicts elements for providing news messages and the like as well as other types of messages, such as mail.
- this implementation utilizes elements of a CDPD wireless network 23 , and to the extent that such elements are similar to those in the earlier embodiment, further explanation thereof should be unnecessary.
- This implementation utilizes the personal message terminals 30 , each of which has CDPD communication capabilities and a synthesizer for producing speech outputs from files containing the reduced set of speech reproduction instructions, as discussed above.
- This network implementation also supplies messages to a PC 40 , which may be essentially the same as discussed above, but there may be some differences in how the information provider(s) offer service to those and other terminal devices directly coupled to the Internet 21 , as will be discussed later.
- the communication service provider operates a server 311 for performing the conversion of text to speech instructions.
- the server 311 receives text messages addressed to individual subscribers from a number of sources discussed more below.
- the server 311 converts each text message to the appropriate speech instructions, for example in MIDI format, and packetizes and addresses the instructions for transmission through the CDPD network 23 to the terminals as in the earlier embodiment.
- the server 311 operated by the communication service provider does not itself process new information inputs and formulate or select text messages for individual subscribers. This particular server only processes messages from other sources. Preferably, the server 311 receives messages in the form of mail from another level of server.
- the illustrated examples of the sources supplying mail to the server 311 include a post office protocol (POP) server 313 and a unified message management platform 315 .
- POP post office protocol
- the subscriber would subscribe to the CDPD network service, to the text to speech instruction conversion service and to a mail service, such as provided by the POP 313 or the unified platform 315 .
- the appropriate mail service POP 313 or platform 315 receives E-mail and/or other mail from a variety of sources and forwards the mail as text messages to the text to speech instruction server 311 .
- One source of the mail messages might be an information service provider operating on the data network 21 .
- the provider would operate a normal data server 317 coupled to the Internet 21 .
- the server 317 would receive and store profile data from customers, similar to the earlier embodiments.
- This server also would receive text data inputs from various sources operated by content creators 319 .
- the source or input information may be virtually any type of information capable of expression in a text format and preferably includes at least types of information similar to those discussed above relative to the first embodiment.
- the information provider's server 317 accumulates news reports or other messages of interest to particular subscribers.
- the server 317 transmits selected news reports based on the subscribers profile information to the subscribers, as E-mail messages, through the Internet 21 .
- the information provider's server 317 transmits the E-mail messages to a server providing the E-mail service for each subscriber, such as the POP server 313 or the platform 315 .
- the mail server 313 or platform 315 provides mail access enabling the subscriber to receive the message. For example, if the subscriber has a data terminal with access to the Internet 21 , such as a PC 40 , the subscriber may elect to receive the messages as textual E-mail messages, in the normal manner.
- the E-mail messages go to the particular POP 313 or platform 315 that is coupled to the text to speech instruction server 311 .
- the E-mail message goes to the POP 313 .
- the POP server 313 Upon receiving appropriate commands from the speech server 311 , the POP server 313 transmits all of the E-mail messages for the subscribers using the wireless personal message terminals, including the news reports from the information provider's server 317 , to the text to speech instruction server 311 . In response to each message, the text to speech instruction server 311 in turn generates the speech instructions, formats the instructions for CDPD transmission and sends the converted message through the CDPD network 23 to the particular subscriber's terminal device 30 , essentially as in the earlier embodiment.
- the POP server 313 may be a normal E-mail server that the subscriber uses for his regular E-mail, for example provided by the subscriber's Internet Service Provider or the subscriber's employer. In such a case, the POP 313 forwards E-mail messages to the portable terminal when the subscriber's terminal has registered as on-line through the CDPD network 23 . At other times, the subscriber can retrieve E-mail messages in the normal manner, for example using a desk-top PC 40 .
- the subscriber has a PC 40 capable of synthesized speech presentation, as in the earlier embodiment, the subscriber also may elect to receive the news and/or other mail messages in synthesized speech form.
- the POP server 313 would obtain a conversion of each text message to the speech instruction format, from the server 311 .
- the POP server 313 would then provide the message, containing the speech synthesizer instructions, to the PC 40 through the Internet 21 for speech synthesis as in the earlier embodiment.
- the POP server 313 is operated by the service provider that operates the text to speech instruction server 311 .
- the E-mail address of the terminal 30 or 40 for that service may be different than the subscriber's public E-mail address. In this case, the E-mail addresses for the messaging service would be kept relatively secure. In some cases, the subscriber may not even know the address.
- the personal message service provider and/or subscriber may give the E-mail address only to selected information service providers, such as provider 317 , who forward news messages or the like to the subscriber. The subscriber also may choose to give the address of the terminal 30 only to important customers, vendors, coworkers or associates.
- the unified message management platform 315 normally receives mail messages as voice messages over the telephone network, as facsimile messages, as E-mail messages over the Internet 21 , etc.
- the platform also provides conversion between the formats, for example, from facsimile to text as selected by the subscriber, to facilitate a subscriber select form of delivery.
- the platform 315 provides a single point of contact or a single mail box, if you will, which receives and stores all these different types of messages and from which the subscriber can directly retrieve the various types of messages or direct them to another terminal device.
- a variety of message types may come to a subscriber on the one unified message platform 315 , e.g. as E-mail, as voice mail, or as fax, and the subscriber can access all of these messages through the one platform.
- the platform 315 provides an indication to the subscriber that it has received a message, for example by providing notice over a telephone link or pager or on-screen notification on a PC 40 that is connected and registered on the platform 315 . Then either using a telephone as a control device, or a computer as a control device, the subscriber controls that platform to deliver the message in a desired manner.
- the platform includes certain conversion capabilities, for example to convert text to speech for playback of E-mail over the telephone, to convert text messages to facsimile format, or to perform character recognition on a facsimile message to convert it to text.
- These capabilities for example might enable a user to select to have E-mail and voice mail messages both delivered as speech information over a telephone line.
- a subscriber might use the telephone to direct the facsimile message or a facsimile representation of an E-mail message to a fax machine in his office.
- the subscriber also could use a computer as a control device to direct those messages, and also she could use the computer as a delivery device.
- the subscriber could select to read her E-mail on her computer, hear voice mail through the computer or see faxes on the computer. Alternately, the subscriber could, for instance, select to direct faxes to a laser printer, forward voice mail with text annotation to another destination or send E-mail to a terminal device for resolution.
- another option of the unified message platform 315 is to send text based messages to the subscribers portable terminal device 30 , for synthesized speech reproduction.
- Any message that the platform receives as text or can convert to text can be sent as a text message to the conversion server 311 .
- the text to speech instruction server 311 converts each text message to the appropriate speech instructions and packetizes and addresses the instructions for transmission through the CDPD network to the terminal 30 .
- the subscriber can receive synthesized speech reproductions of text (e.g. E-mail) and facsimile messages at his terminal 30 through control of the unified platform 315 .
- the subscriber also can respond to the mail messages, for example to instruct the unified platform 315 to redirect a mail message to other parties or to respond to the message originator using a finite set of predefined responses.
- the system of FIG. 5 preferably delivers messages to the portable terminals 30 using a ‘push’ type delivery process.
- the news is accumulated for the subscriber and sent as an E-mail message to a mail server 313 or 315 .
- the appropriate mail server relays the news messages and/or other text messages to the text to speech instruction server 311 . That server in turn relays the speech synthesizer instructions for the converted messages, in appropriate format, to the Mobile Data Intermediate System (MD-IS) 25 .
- MD-IS Mobile Data Intermediate System
- the MD-IS 25 knows which base station 27 is serving the receiving terminal 30 , that the receiving terminal 30 is turned on and how to communicate with it via the air link.
- the MD-IS 25 pushes the packetized information out through the air link to the personal message terminal 30 , where it is stored so that the user can choose to play it immediately or play it later.
- the CDPD modem in the terminal and the CDPD wireless network permit two-way communication.
- the terminal will have at least a limited keyboard and a display, for example to provide a soft key functionality, and will send input data upstream through the CDPD network 23 to the appropriate server(s).
- a menu on the display may offer the user several options, such as requesting more messages regarding similar topics, changing the subscriber's profile, etc.
- the software in the terminal 30 causes the transmitter of the CDPD modem to send a corresponding coded message through the CDPD network 23 and back to the mail server, POP 313 or platform 315 .
- the upstream message would identify the related downstream message and the selected option.
- the mail server 313 or 315 runs appropriate software to interpret the response message and forward it as necessary to the appropriate point on the data network (e.g. Internet) 21 .
- the mail server 313 or 315 formulates an appropriate E-mail message and transmits that message through the Internet 21 to the server 317 operated by the customer's information provider for further action, for example, to update the user's profile.
- the upstream message may indicate that the user wants the next message or wants to get more messages.
- the upstream message may indicate a request for a more detailed message regarding the topic of the last message reviewed.
- the information provider's server 317 receives this command code for more information, formulates another E-mail message containing the information and sends it back through the network(s) to the terminal as in the earlier example of operation of the system of FIG. 5 .
- the upstream message may relate to a change in the user's profile.
- the information provider's server 317 updates the appropriate profile record.
- the server 317 may send a confirmation message back to the terminal 30 .
- the two-way interactive communication system using the CDPD wireless data network is preferred.
- other wireless communication techniques may carry the news items or other messages to the terminal devices.
- a headend may broadcast a stream of news items over an RF channel.
- Each item would include a header identifying the type or subject matter of the information in the associated message.
- the terminal would review the headers of all broadcast messages.
- the terminal would capture only those messages corresponding to the subscriber's profile.
- the terminal could store the profile and compare profile selection information to the message identifying data in the headers.
- each message would include an identifier, and the terminal could receive an addressed message from the headend instructing it which news item messages to capture from the broadcast channel.
- the profile could be created on-line and “pushed” into the terminal.
- the above discussed implementation of the terminal device includes a memory for storing the MIDI bytes of the news messages. That implementation of the terminal processes the MIDI information to produce an audio output signal, during actual playback.
- One alternative is to convert each message to an audio signal as it is received or shortly after reception.
- the terminal would supply the audio signal to an audio recorder, such as a cassette or micro-cassette type tape recorder or a solid-state tapeless recorder. After transfer to the recorder, the terminal could reuse the memory for the next new message.
- the subscriber plays messages back from the audio tape by appropriate operation of the recorder or some other tape unit.
- the tape could store larger numbers of messages, and the amount of memory in the terminal is lower. This is particularly significant in the portable terminal.
- the various messages sent through the system to the subscribers terminal devices often have been referred to as news items or newscast messages, in the discussion above. It is understood, however, that the actual information in each of the messages may be any type of information that the network server and the terminal together can convert from text to speech. Typical examples include news-wire service reports, stock ticker reports and the like, but the inventive system can transport other information such as E-mail or text data obtained from the Internet to the terminals for presentation as speech to the subscribers.
- the subscriber would send text upstream through the network and thus to the other parties, whereas the terminal would provide a spoken output to the subscriber (who may be blind). Reception of text from selected Usenet news groups is also contemplated.
Abstract
Description
Claims (27)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US08/948,328 US7027568B1 (en) | 1997-10-10 | 1997-10-10 | Personal message service with enhanced text to speech synthesis |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US08/948,328 US7027568B1 (en) | 1997-10-10 | 1997-10-10 | Personal message service with enhanced text to speech synthesis |
Publications (1)
Publication Number | Publication Date |
---|---|
US7027568B1 true US7027568B1 (en) | 2006-04-11 |
Family
ID=36127802
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US08/948,328 Expired - Fee Related US7027568B1 (en) | 1997-10-10 | 1997-10-10 | Personal message service with enhanced text to speech synthesis |
Country Status (1)
Country | Link |
---|---|
US (1) | US7027568B1 (en) |
Cited By (159)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20020025036A1 (en) * | 2000-08-11 | 2002-02-28 | Trinity Communication Inc. | Modem device, data communications system, method of and device for protecting data, and computer product |
US20040076274A1 (en) * | 2001-02-28 | 2004-04-22 | Pierpaolo Anselmetti | System and method for access to multimedia structures |
US20050047558A1 (en) * | 2003-09-02 | 2005-03-03 | Canon Kabushiki Kaisha | Communication terminal apparatus and transfer method therefor |
US20050216267A1 (en) * | 2002-09-23 | 2005-09-29 | Infineon Technologies Ag | Method and system for computer-aided speech synthesis |
US20060179467A1 (en) * | 2004-02-04 | 2006-08-10 | Hsiao-Chieh Chung | Stock information broadcast device |
US20070078656A1 (en) * | 2005-10-03 | 2007-04-05 | Niemeyer Terry W | Server-provided user's voice for instant messaging clients |
US7243067B1 (en) * | 1999-07-16 | 2007-07-10 | Bayerische Motoren Werke Aktiengesellschaft | Method and apparatus for wireless transmission of messages between a vehicle-internal communication system and a vehicle-external central computer |
US20070254684A1 (en) * | 2001-08-16 | 2007-11-01 | Roamware, Inc. | Method and system for sending and creating expressive messages |
US20080008301A1 (en) * | 2005-06-22 | 2008-01-10 | Inventec Multimedia & Telecom Corporation | Network telephone device |
WO2008008992A2 (en) * | 2006-07-14 | 2008-01-17 | Qualcomm Incorporated | Improved methods and apparatus for delivering audio information |
US20080045216A1 (en) * | 1998-05-29 | 2008-02-21 | Research In Motion Limited | System and Method for Redirecting Message Attachments Between a Host System and a Mobile Data Communication Device |
US20080045194A1 (en) * | 2002-06-26 | 2008-02-21 | Research In Motion Limited | System and Method for Pushing Information Between a Host System and a Mobile Data Communication Device |
US20080052365A1 (en) * | 1998-05-29 | 2008-02-28 | Research In Motion Limited | System and Method for Pushing Information from a Host System to a Mobile Data Communication Device |
US20080051120A1 (en) * | 2001-10-22 | 2008-02-28 | Riccardo Vieri | Mobile device for sending text messages |
US20080077707A1 (en) * | 2004-10-20 | 2008-03-27 | Research In Motion Limited | System and Method for Bundling Information |
US7433874B1 (en) | 1997-11-17 | 2008-10-07 | Wolfe Mark A | System and method for communicating information relating to a network resource |
US20080281928A1 (en) * | 2005-01-11 | 2008-11-13 | Teles Ag Informationstechnologien | Method For Transmitting Data to at Least One Communications End System and Communications Device For Carrying Out Said Method |
US20080307074A1 (en) * | 1998-01-12 | 2008-12-11 | Lextron Systems, Inc. | Customizable Media Player with Online/Offline Capabilities |
US20090048831A1 (en) * | 2007-08-16 | 2009-02-19 | Lamar John Van Wagenen | Scripting support for data identifiers, voice recognition and speech in a telnet session |
US20090048838A1 (en) * | 2007-05-30 | 2009-02-19 | Campbell Craig F | System and method for client voice building |
US20090110158A1 (en) * | 2007-10-25 | 2009-04-30 | Yen-Fu Chen | Method and apparatus of automated message conversion based on availability of bandwidth |
US20090196405A1 (en) * | 2005-07-01 | 2009-08-06 | At & T Intellectual Property I, Lp. (Formerly Known As Sbc Knowledge Ventures, L.P.) | Ivr to sms text messenger |
US20090254349A1 (en) * | 2006-06-05 | 2009-10-08 | Yoshifumi Hirose | Speech synthesizer |
US7624017B1 (en) * | 2002-06-05 | 2009-11-24 | At&T Intellectual Property Ii, L.P. | System and method for configuring voice synthesis |
US20100194582A1 (en) * | 1998-06-22 | 2010-08-05 | Petite Thomas D | Systems and methods for monitoring and controlling remote devices |
US20100222098A1 (en) * | 2009-02-27 | 2010-09-02 | Research In Motion Limited | Mobile wireless communications device for hearing and/or speech impaired user |
US20100286986A1 (en) * | 1999-04-30 | 2010-11-11 | At&T Intellectual Property Ii, L.P. Via Transfer From At&T Corp. | Methods and Apparatus for Rapid Acoustic Unit Selection From a Large Speech Corpus |
US20100305949A1 (en) * | 2007-11-28 | 2010-12-02 | Masanori Kato | Speech synthesis device, speech synthesis method, and speech synthesis program |
US20100324710A1 (en) * | 2001-03-29 | 2010-12-23 | Delacruz Cedric G | Method for providing enhanced electronic mail return receipts |
US20110202597A1 (en) * | 1998-05-29 | 2011-08-18 | Research In Motion Limited | System and Method for Pushing Information from a Host System to a Mobile Data Communication Device |
GB2481992A (en) * | 2010-07-13 | 2012-01-18 | Sony Europe Ltd | Updating text-to-speech converter for broadcast signal receiver |
US8359234B2 (en) | 2007-07-26 | 2013-01-22 | Braintexter, Inc. | System to generate and set up an advertising campaign based on the insertion of advertising messages within an exchange of messages, and method to operate said system |
US8423365B2 (en) | 2010-05-28 | 2013-04-16 | Daniel Ben-Ezri | Contextual conversion platform |
US20130096921A1 (en) * | 2010-07-13 | 2013-04-18 | Fujitsu Ten Limited | Information providing system and vehicle-mounted apparatus |
US20130144624A1 (en) * | 2011-12-01 | 2013-06-06 | At&T Intellectual Property I, L.P. | System and method for low-latency web-based text-to-speech without plugins |
US20130282375A1 (en) * | 2007-06-01 | 2013-10-24 | At&T Mobility Ii Llc | Vehicle-Based Message Control Using Cellular IP |
US8583744B2 (en) | 1998-05-29 | 2013-11-12 | Blackberry Limited | System and method for pushing information from a host system to a mobile data communication device |
US8595016B2 (en) | 2011-12-23 | 2013-11-26 | Angle, Llc | Accessing content using a source-specific content-adaptable dialogue |
US20140320204A1 (en) * | 2009-12-28 | 2014-10-30 | Nxp B.V. | Adjustable mos resistor |
US8892446B2 (en) | 2010-01-18 | 2014-11-18 | Apple Inc. | Service orchestration for intelligent automated assistant |
EP2910963A1 (en) | 2014-02-21 | 2015-08-26 | Danaher (Shanghai) Industrial Instrumentation Technologies R&D Co Ltd | Methods and instruments for testing batteries |
US20150302854A1 (en) * | 2009-01-30 | 2015-10-22 | Altorr Corporation | Smartphone control of electrical devices |
US9262612B2 (en) | 2011-03-21 | 2016-02-16 | Apple Inc. | Device access using voice authentication |
US9300784B2 (en) | 2013-06-13 | 2016-03-29 | Apple Inc. | System and method for emergency calls initiated by voice command |
US9330720B2 (en) | 2008-01-03 | 2016-05-03 | Apple Inc. | Methods and apparatus for altering audio output signals |
US9338493B2 (en) | 2014-06-30 | 2016-05-10 | Apple Inc. | Intelligent automated assistant for TV user interactions |
US9368114B2 (en) | 2013-03-14 | 2016-06-14 | Apple Inc. | Context-sensitive handling of interruptions |
US9430463B2 (en) | 2014-05-30 | 2016-08-30 | Apple Inc. | Exemplar-based natural language processing |
US9483461B2 (en) | 2012-03-06 | 2016-11-01 | Apple Inc. | Handling speech synthesis of content for multiple languages |
US9495129B2 (en) | 2012-06-29 | 2016-11-15 | Apple Inc. | Device, method, and user interface for voice-activated navigation and browsing of a document |
US9502031B2 (en) | 2014-05-27 | 2016-11-22 | Apple Inc. | Method for supporting dynamic grammars in WFST-based ASR |
US9535906B2 (en) | 2008-07-31 | 2017-01-03 | Apple Inc. | Mobile device having human language translation capability with positional feedback |
US9576574B2 (en) | 2012-09-10 | 2017-02-21 | Apple Inc. | Context-sensitive handling of interruptions by intelligent digital assistant |
US9582608B2 (en) | 2013-06-07 | 2017-02-28 | Apple Inc. | Unified ranking with entropy-weighted information for phrase-based semantic auto-completion |
US9620105B2 (en) | 2014-05-15 | 2017-04-11 | Apple Inc. | Analyzing audio input for efficient speech and music recognition |
US9620104B2 (en) | 2013-06-07 | 2017-04-11 | Apple Inc. | System and method for user-specified pronunciation of words for speech synthesis and recognition |
US9626955B2 (en) | 2008-04-05 | 2017-04-18 | Apple Inc. | Intelligent text-to-speech conversion |
US9633674B2 (en) | 2013-06-07 | 2017-04-25 | Apple Inc. | System and method for detecting errors in interactions with a voice-based digital assistant |
US9633660B2 (en) | 2010-02-25 | 2017-04-25 | Apple Inc. | User profiling for voice input processing |
US9633004B2 (en) | 2014-05-30 | 2017-04-25 | Apple Inc. | Better resolution when referencing to concepts |
US9646614B2 (en) | 2000-03-16 | 2017-05-09 | Apple Inc. | Fast, language-independent method for user authentication by voice |
US9646609B2 (en) | 2014-09-30 | 2017-05-09 | Apple Inc. | Caching apparatus for serving phonetic pronunciations |
US9668121B2 (en) | 2014-09-30 | 2017-05-30 | Apple Inc. | Social reminders |
US9697822B1 (en) | 2013-03-15 | 2017-07-04 | Apple Inc. | System and method for updating an adaptive speech recognition model |
US9697820B2 (en) | 2015-09-24 | 2017-07-04 | Apple Inc. | Unit-selection text-to-speech synthesis using concatenation-sensitive neural networks |
US9711141B2 (en) | 2014-12-09 | 2017-07-18 | Apple Inc. | Disambiguating heteronyms in speech synthesis |
US9715875B2 (en) | 2014-05-30 | 2017-07-25 | Apple Inc. | Reducing the need for manual start/end-pointing and trigger phrases |
US9721566B2 (en) | 2015-03-08 | 2017-08-01 | Apple Inc. | Competing devices responding to voice triggers |
US9734193B2 (en) | 2014-05-30 | 2017-08-15 | Apple Inc. | Determining domain salience ranking from ambiguous words in natural speech |
US9760559B2 (en) | 2014-05-30 | 2017-09-12 | Apple Inc. | Predictive text input |
US9785630B2 (en) | 2014-05-30 | 2017-10-10 | Apple Inc. | Text prediction using combined word N-gram and unigram language models |
US9798393B2 (en) | 2011-08-29 | 2017-10-24 | Apple Inc. | Text correction processing |
US9818400B2 (en) | 2014-09-11 | 2017-11-14 | Apple Inc. | Method and apparatus for discovering trending terms in speech requests |
US9842105B2 (en) | 2015-04-16 | 2017-12-12 | Apple Inc. | Parsimonious continuous-space phrase representations for natural language processing |
US9842101B2 (en) | 2014-05-30 | 2017-12-12 | Apple Inc. | Predictive conversion of language input |
US9858925B2 (en) | 2009-06-05 | 2018-01-02 | Apple Inc. | Using context information to facilitate processing of commands in a virtual assistant |
US9865280B2 (en) | 2015-03-06 | 2018-01-09 | Apple Inc. | Structured dictation using intelligent automated assistants |
US9886432B2 (en) | 2014-09-30 | 2018-02-06 | Apple Inc. | Parsimonious handling of word inflection via categorical stem + suffix N-gram language models |
US9886953B2 (en) | 2015-03-08 | 2018-02-06 | Apple Inc. | Virtual assistant activation |
US9899019B2 (en) | 2015-03-18 | 2018-02-20 | Apple Inc. | Systems and methods for structured stem and suffix language models |
US9922642B2 (en) | 2013-03-15 | 2018-03-20 | Apple Inc. | Training an at least partial voice command system |
US9934775B2 (en) | 2016-05-26 | 2018-04-03 | Apple Inc. | Unit-selection text-to-speech synthesis based on predicted concatenation parameters |
US9953088B2 (en) | 2012-05-14 | 2018-04-24 | Apple Inc. | Crowd sourcing information to fulfill user requests |
US9959870B2 (en) | 2008-12-11 | 2018-05-01 | Apple Inc. | Speech recognition involving a mobile device |
US9966068B2 (en) | 2013-06-08 | 2018-05-08 | Apple Inc. | Interpreting and acting upon commands that involve sharing information with remote devices |
US9966065B2 (en) | 2014-05-30 | 2018-05-08 | Apple Inc. | Multi-command single utterance input method |
US9972304B2 (en) | 2016-06-03 | 2018-05-15 | Apple Inc. | Privacy preserving distributed evaluation framework for embedded personalized systems |
US9971774B2 (en) | 2012-09-19 | 2018-05-15 | Apple Inc. | Voice-based media searching |
US10033797B1 (en) | 2014-08-20 | 2018-07-24 | Ivanti, Inc. | Terminal emulation over HTML |
US10043516B2 (en) | 2016-09-23 | 2018-08-07 | Apple Inc. | Intelligent automated assistant |
US10049663B2 (en) | 2016-06-08 | 2018-08-14 | Apple, Inc. | Intelligent automated assistant for media exploration |
US10049668B2 (en) | 2015-12-02 | 2018-08-14 | Apple Inc. | Applying neural network language models to weighted finite state transducers for automatic speech recognition |
US10057736B2 (en) | 2011-06-03 | 2018-08-21 | Apple Inc. | Active transport based notifications |
US10067938B2 (en) | 2016-06-10 | 2018-09-04 | Apple Inc. | Multilingual word prediction |
US10074360B2 (en) | 2014-09-30 | 2018-09-11 | Apple Inc. | Providing an indication of the suitability of speech recognition |
US10078631B2 (en) | 2014-05-30 | 2018-09-18 | Apple Inc. | Entropy-guided text prediction using combined word and character n-gram language models |
US10079014B2 (en) | 2012-06-08 | 2018-09-18 | Apple Inc. | Name recognition system |
US10083688B2 (en) | 2015-05-27 | 2018-09-25 | Apple Inc. | Device voice control for selecting a displayed affordance |
US10089072B2 (en) | 2016-06-11 | 2018-10-02 | Apple Inc. | Intelligent device arbitration and control |
US10101822B2 (en) | 2015-06-05 | 2018-10-16 | Apple Inc. | Language input correction |
US10127220B2 (en) | 2015-06-04 | 2018-11-13 | Apple Inc. | Language identification from short strings |
US10127911B2 (en) | 2014-09-30 | 2018-11-13 | Apple Inc. | Speaker identification and unsupervised speaker adaptation techniques |
US10134385B2 (en) | 2012-03-02 | 2018-11-20 | Apple Inc. | Systems and methods for name pronunciation |
US10170123B2 (en) | 2014-05-30 | 2019-01-01 | Apple Inc. | Intelligent assistant for home automation |
US10176167B2 (en) | 2013-06-09 | 2019-01-08 | Apple Inc. | System and method for inferring user intent from speech inputs |
US10186254B2 (en) | 2015-06-07 | 2019-01-22 | Apple Inc. | Context-based endpoint detection |
US10185542B2 (en) | 2013-06-09 | 2019-01-22 | Apple Inc. | Device, method, and graphical user interface for enabling conversation persistence across two or more instances of a digital assistant |
US10192552B2 (en) | 2016-06-10 | 2019-01-29 | Apple Inc. | Digital assistant providing whispered speech |
US10199051B2 (en) | 2013-02-07 | 2019-02-05 | Apple Inc. | Voice trigger for a digital assistant |
US10223066B2 (en) | 2015-12-23 | 2019-03-05 | Apple Inc. | Proactive assistance based on dialog communication between devices |
US10241644B2 (en) | 2011-06-03 | 2019-03-26 | Apple Inc. | Actionable reminder entries |
US10241752B2 (en) | 2011-09-30 | 2019-03-26 | Apple Inc. | Interface for a virtual digital assistant |
US10249300B2 (en) | 2016-06-06 | 2019-04-02 | Apple Inc. | Intelligent list reading |
US10255907B2 (en) | 2015-06-07 | 2019-04-09 | Apple Inc. | Automatic accent detection using acoustic models |
US10269345B2 (en) | 2016-06-11 | 2019-04-23 | Apple Inc. | Intelligent task discovery |
US10276170B2 (en) | 2010-01-18 | 2019-04-30 | Apple Inc. | Intelligent automated assistant |
US10283110B2 (en) | 2009-07-02 | 2019-05-07 | Apple Inc. | Methods and apparatuses for automatic speech recognition |
US10289433B2 (en) | 2014-05-30 | 2019-05-14 | Apple Inc. | Domain specific language for encoding assistant dialog |
US10297253B2 (en) | 2016-06-11 | 2019-05-21 | Apple Inc. | Application integration with a digital assistant |
US10318871B2 (en) | 2005-09-08 | 2019-06-11 | Apple Inc. | Method and apparatus for building an intelligent automated assistant |
US10354011B2 (en) | 2016-06-09 | 2019-07-16 | Apple Inc. | Intelligent automated assistant in a home environment |
US10356243B2 (en) | 2015-06-05 | 2019-07-16 | Apple Inc. | Virtual assistant aided communication with 3rd party service in a communication session |
US10366158B2 (en) | 2015-09-29 | 2019-07-30 | Apple Inc. | Efficient word encoding for recurrent neural network language models |
US10410637B2 (en) | 2017-05-12 | 2019-09-10 | Apple Inc. | User-specific acoustic models |
US10446143B2 (en) | 2016-03-14 | 2019-10-15 | Apple Inc. | Identification of voice inputs providing credentials |
US10446141B2 (en) | 2014-08-28 | 2019-10-15 | Apple Inc. | Automatic speech recognition based on user feedback |
US10482874B2 (en) | 2017-05-15 | 2019-11-19 | Apple Inc. | Hierarchical belief states for digital assistants |
US10490187B2 (en) | 2016-06-10 | 2019-11-26 | Apple Inc. | Digital assistant providing automated status report |
US10496753B2 (en) | 2010-01-18 | 2019-12-03 | Apple Inc. | Automatically adapting user interfaces for hands-free interaction |
US10509862B2 (en) | 2016-06-10 | 2019-12-17 | Apple Inc. | Dynamic phrase expansion of language input |
US10521466B2 (en) | 2016-06-11 | 2019-12-31 | Apple Inc. | Data driven natural language event detection and classification |
US10553209B2 (en) | 2010-01-18 | 2020-02-04 | Apple Inc. | Systems and methods for hands-free notification summaries |
US10552013B2 (en) | 2014-12-02 | 2020-02-04 | Apple Inc. | Data detection |
US10568032B2 (en) | 2007-04-03 | 2020-02-18 | Apple Inc. | Method and system for operating a multi-function portable electronic device using voice-activation |
US10567477B2 (en) | 2015-03-08 | 2020-02-18 | Apple Inc. | Virtual assistant continuity |
US10593346B2 (en) | 2016-12-22 | 2020-03-17 | Apple Inc. | Rank-reduced token representation for automatic speech recognition |
US10592095B2 (en) | 2014-05-23 | 2020-03-17 | Apple Inc. | Instantaneous speaking of content on touch devices |
US10607141B2 (en) | 2010-01-25 | 2020-03-31 | Newvaluexchange Ltd. | Apparatuses, methods and systems for a digital conversation management platform |
CN111078427A (en) * | 2019-12-04 | 2020-04-28 | 上海肇观电子科技有限公司 | Message reminding method, electronic device and storage medium |
US20200135169A1 (en) * | 2018-10-26 | 2020-04-30 | Institute For Information Industry | Audio playback device and audio playback method thereof |
US10659851B2 (en) | 2014-06-30 | 2020-05-19 | Apple Inc. | Real-time digital assistant knowledge updates |
US10671428B2 (en) | 2015-09-08 | 2020-06-02 | Apple Inc. | Distributed personal assistant |
US10679605B2 (en) | 2010-01-18 | 2020-06-09 | Apple Inc. | Hands-free list-reading by intelligent automated assistant |
US10691473B2 (en) | 2015-11-06 | 2020-06-23 | Apple Inc. | Intelligent automated assistant in a messaging environment |
US10706373B2 (en) | 2011-06-03 | 2020-07-07 | Apple Inc. | Performing actions associated with task items that represent tasks to perform |
US10705794B2 (en) | 2010-01-18 | 2020-07-07 | Apple Inc. | Automatically adapting user interfaces for hands-free interaction |
US10733993B2 (en) | 2016-06-10 | 2020-08-04 | Apple Inc. | Intelligent digital assistant in a multi-tasking environment |
US10747498B2 (en) | 2015-09-08 | 2020-08-18 | Apple Inc. | Zero latency digital assistant |
US10755703B2 (en) | 2017-05-11 | 2020-08-25 | Apple Inc. | Offline personal assistant |
US10762293B2 (en) | 2010-12-22 | 2020-09-01 | Apple Inc. | Using parts-of-speech tagging and named entity recognition for spelling correction |
US10791216B2 (en) | 2013-08-06 | 2020-09-29 | Apple Inc. | Auto-activating smart responses based on activities from remote devices |
US10791176B2 (en) | 2017-05-12 | 2020-09-29 | Apple Inc. | Synchronization and task delegation of a digital assistant |
US10789041B2 (en) | 2014-09-12 | 2020-09-29 | Apple Inc. | Dynamic thresholds for always listening speech trigger |
US10810274B2 (en) | 2017-05-15 | 2020-10-20 | Apple Inc. | Optimizing dialogue policy decisions for digital assistants using implicit feedback |
US11010550B2 (en) | 2015-09-29 | 2021-05-18 | Apple Inc. | Unified language modeling framework for word prediction, auto-completion and auto-correction |
US11025565B2 (en) | 2015-06-07 | 2021-06-01 | Apple Inc. | Personalized prediction of responses for instant messaging |
US11100278B2 (en) | 2016-07-28 | 2021-08-24 | Ivanti, Inc. | Systems and methods for presentation of a terminal application screen |
US11217255B2 (en) | 2017-05-16 | 2022-01-04 | Apple Inc. | Far-field extension for digital assistant services |
US11587559B2 (en) | 2015-09-30 | 2023-02-21 | Apple Inc. | Intelligent device identification |
Citations (38)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4479124A (en) | 1979-09-20 | 1984-10-23 | Texas Instruments Incorporated | Synthesized voice radio paging system |
US4554418A (en) | 1983-05-16 | 1985-11-19 | Toy Frank C | Information monitoring and notification method and apparatus |
US4627093A (en) | 1979-12-27 | 1986-12-02 | Sharp Kabushiki Kaisha | One-chip LSI speech synthesizer |
US4769642A (en) | 1985-12-31 | 1988-09-06 | Motorola, Inc. | Paging receiver with LPC speech synthesizer |
US4812843A (en) | 1987-05-04 | 1989-03-14 | Champion Iii C Paul | Telephone accessible information system |
US4821021A (en) | 1987-01-13 | 1989-04-11 | Nec Corporation | Selective calling radio display pager having a message recalling algorithm which simplifies operations |
US4885577A (en) | 1988-03-02 | 1989-12-05 | Motorola, Inc. | Paging system for providing a data message and a voice message to a unique address of a paging receiver |
US4942616A (en) | 1985-09-09 | 1990-07-17 | Thomas Linstroth | Interactive synthesized speech quotation system for brokers |
US4996707A (en) | 1989-02-09 | 1991-02-26 | Berkeley Speech Technologies, Inc. | Text-to-speech converter of a facsimile graphic image |
US5144648A (en) | 1989-08-30 | 1992-09-01 | Mobile Telecommunication Technologies | Method and apparatus for processing pages |
US5189632A (en) | 1990-08-20 | 1993-02-23 | Oy Nokia Ab | Portable personal computer and mobile telephone device |
US5283638A (en) * | 1991-04-25 | 1994-02-01 | Compuadd Corporation | Multimedia computing and telecommunications workstation |
US5327486A (en) * | 1993-03-22 | 1994-07-05 | Bell Communications Research, Inc. | Method and system for managing telecommunications such as telephone calls |
US5398021A (en) | 1993-07-19 | 1995-03-14 | Motorola, Inc. | Reliable information service message delivery system |
US5444768A (en) | 1991-12-31 | 1995-08-22 | International Business Machines Corporation | Portable computer device for audible processing of remotely stored messages |
US5455579A (en) | 1987-06-30 | 1995-10-03 | Motorola, Inc. | Digitized stored voice paging receiver |
US5463713A (en) | 1991-05-07 | 1995-10-31 | Kabushiki Kaisha Meidensha | Synthesis of speech from text |
US5530852A (en) * | 1994-12-20 | 1996-06-25 | Sun Microsystems, Inc. | Method for extracting profiles and topics from a first file written in a first markup language and generating files in different markup languages containing the profiles and topics for use in accessing data described by the profiles and topics |
US5568540A (en) * | 1993-09-13 | 1996-10-22 | Active Voice Corporation | Method and apparatus for selecting and playing a voice mail message |
US5572643A (en) * | 1995-10-19 | 1996-11-05 | Judson; David H. | Web browser with dynamic display of information objects during linking |
US5594779A (en) | 1995-01-12 | 1997-01-14 | Bell Atlantic | Mobile audio program selection system using public switched telephone network |
US5600703A (en) | 1995-02-24 | 1997-02-04 | Motorola, Inc. | Method and apparatus for remotely retrieving messages intended for an acknowledge-back pager in a selective call communication system |
US5608786A (en) * | 1994-12-23 | 1997-03-04 | Alphanet Telecom Inc. | Unified messaging system and method |
US5610821A (en) * | 1994-11-18 | 1997-03-11 | Ibm Corporation | Optimal and stable route planning system |
US5768513A (en) * | 1996-06-27 | 1998-06-16 | At&T Corp. | Multimedia messaging using the internet |
US5774859A (en) * | 1995-01-03 | 1998-06-30 | Scientific-Atlanta, Inc. | Information system having a speech interface |
US5835087A (en) * | 1994-11-29 | 1998-11-10 | Herz; Frederick S. M. | System for generation of object profiles for a system for customized electronic identification of desirable objects |
US5848397A (en) * | 1996-04-19 | 1998-12-08 | Juno Online Services, L.P. | Method and apparatus for scheduling the presentation of messages to computer users |
US5889860A (en) * | 1996-11-08 | 1999-03-30 | Sunhawk Corporation, Inc. | Encryption system with transaction coded decryption key |
US5915237A (en) * | 1996-12-13 | 1999-06-22 | Intel Corporation | Representing speech using MIDI |
US5918013A (en) * | 1996-06-03 | 1999-06-29 | Webtv Networks, Inc. | Method of transcoding documents in a network environment using a proxy server |
US5924068A (en) * | 1997-02-04 | 1999-07-13 | Matsushita Electric Industrial Co. Ltd. | Electronic news reception apparatus that selectively retains sections and searches by keyword or index for text to speech conversion |
US5928330A (en) * | 1996-09-06 | 1999-07-27 | Motorola, Inc. | System, device, and method for streaming a multimedia file |
US5943648A (en) * | 1996-04-25 | 1999-08-24 | Lernout & Hauspie Speech Products N.V. | Speech signal distribution system providing supplemental parameter associated data |
US5945989A (en) * | 1997-03-25 | 1999-08-31 | Premiere Communications, Inc. | Method and apparatus for adding and altering content on websites |
US5983190A (en) * | 1997-05-19 | 1999-11-09 | Microsoft Corporation | Client server animation system for managing interactive user interface characters |
US6035273A (en) * | 1996-06-26 | 2000-03-07 | Lucent Technologies, Inc. | Speaker-specific speech-to-text/text-to-speech communication system with hypertext-indicated speech parameter changes |
US6115384A (en) * | 1996-06-20 | 2000-09-05 | Fourelle Systems, Inc | Gateway architecture for data communication bandwidth-constrained and charge-by-use networks |
-
1997
- 1997-10-10 US US08/948,328 patent/US7027568B1/en not_active Expired - Fee Related
Patent Citations (38)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4479124A (en) | 1979-09-20 | 1984-10-23 | Texas Instruments Incorporated | Synthesized voice radio paging system |
US4627093A (en) | 1979-12-27 | 1986-12-02 | Sharp Kabushiki Kaisha | One-chip LSI speech synthesizer |
US4554418A (en) | 1983-05-16 | 1985-11-19 | Toy Frank C | Information monitoring and notification method and apparatus |
US4942616A (en) | 1985-09-09 | 1990-07-17 | Thomas Linstroth | Interactive synthesized speech quotation system for brokers |
US4769642A (en) | 1985-12-31 | 1988-09-06 | Motorola, Inc. | Paging receiver with LPC speech synthesizer |
US4821021A (en) | 1987-01-13 | 1989-04-11 | Nec Corporation | Selective calling radio display pager having a message recalling algorithm which simplifies operations |
US4812843A (en) | 1987-05-04 | 1989-03-14 | Champion Iii C Paul | Telephone accessible information system |
US5455579A (en) | 1987-06-30 | 1995-10-03 | Motorola, Inc. | Digitized stored voice paging receiver |
US4885577A (en) | 1988-03-02 | 1989-12-05 | Motorola, Inc. | Paging system for providing a data message and a voice message to a unique address of a paging receiver |
US4996707A (en) | 1989-02-09 | 1991-02-26 | Berkeley Speech Technologies, Inc. | Text-to-speech converter of a facsimile graphic image |
US5144648A (en) | 1989-08-30 | 1992-09-01 | Mobile Telecommunication Technologies | Method and apparatus for processing pages |
US5189632A (en) | 1990-08-20 | 1993-02-23 | Oy Nokia Ab | Portable personal computer and mobile telephone device |
US5283638A (en) * | 1991-04-25 | 1994-02-01 | Compuadd Corporation | Multimedia computing and telecommunications workstation |
US5463713A (en) | 1991-05-07 | 1995-10-31 | Kabushiki Kaisha Meidensha | Synthesis of speech from text |
US5444768A (en) | 1991-12-31 | 1995-08-22 | International Business Machines Corporation | Portable computer device for audible processing of remotely stored messages |
US5327486A (en) * | 1993-03-22 | 1994-07-05 | Bell Communications Research, Inc. | Method and system for managing telecommunications such as telephone calls |
US5398021A (en) | 1993-07-19 | 1995-03-14 | Motorola, Inc. | Reliable information service message delivery system |
US5568540A (en) * | 1993-09-13 | 1996-10-22 | Active Voice Corporation | Method and apparatus for selecting and playing a voice mail message |
US5610821A (en) * | 1994-11-18 | 1997-03-11 | Ibm Corporation | Optimal and stable route planning system |
US5835087A (en) * | 1994-11-29 | 1998-11-10 | Herz; Frederick S. M. | System for generation of object profiles for a system for customized electronic identification of desirable objects |
US5530852A (en) * | 1994-12-20 | 1996-06-25 | Sun Microsystems, Inc. | Method for extracting profiles and topics from a first file written in a first markup language and generating files in different markup languages containing the profiles and topics for use in accessing data described by the profiles and topics |
US5608786A (en) * | 1994-12-23 | 1997-03-04 | Alphanet Telecom Inc. | Unified messaging system and method |
US5774859A (en) * | 1995-01-03 | 1998-06-30 | Scientific-Atlanta, Inc. | Information system having a speech interface |
US5594779A (en) | 1995-01-12 | 1997-01-14 | Bell Atlantic | Mobile audio program selection system using public switched telephone network |
US5600703A (en) | 1995-02-24 | 1997-02-04 | Motorola, Inc. | Method and apparatus for remotely retrieving messages intended for an acknowledge-back pager in a selective call communication system |
US5572643A (en) * | 1995-10-19 | 1996-11-05 | Judson; David H. | Web browser with dynamic display of information objects during linking |
US5848397A (en) * | 1996-04-19 | 1998-12-08 | Juno Online Services, L.P. | Method and apparatus for scheduling the presentation of messages to computer users |
US5943648A (en) * | 1996-04-25 | 1999-08-24 | Lernout & Hauspie Speech Products N.V. | Speech signal distribution system providing supplemental parameter associated data |
US5918013A (en) * | 1996-06-03 | 1999-06-29 | Webtv Networks, Inc. | Method of transcoding documents in a network environment using a proxy server |
US6115384A (en) * | 1996-06-20 | 2000-09-05 | Fourelle Systems, Inc | Gateway architecture for data communication bandwidth-constrained and charge-by-use networks |
US6035273A (en) * | 1996-06-26 | 2000-03-07 | Lucent Technologies, Inc. | Speaker-specific speech-to-text/text-to-speech communication system with hypertext-indicated speech parameter changes |
US5768513A (en) * | 1996-06-27 | 1998-06-16 | At&T Corp. | Multimedia messaging using the internet |
US5928330A (en) * | 1996-09-06 | 1999-07-27 | Motorola, Inc. | System, device, and method for streaming a multimedia file |
US5889860A (en) * | 1996-11-08 | 1999-03-30 | Sunhawk Corporation, Inc. | Encryption system with transaction coded decryption key |
US5915237A (en) * | 1996-12-13 | 1999-06-22 | Intel Corporation | Representing speech using MIDI |
US5924068A (en) * | 1997-02-04 | 1999-07-13 | Matsushita Electric Industrial Co. Ltd. | Electronic news reception apparatus that selectively retains sections and searches by keyword or index for text to speech conversion |
US5945989A (en) * | 1997-03-25 | 1999-08-31 | Premiere Communications, Inc. | Method and apparatus for adding and altering content on websites |
US5983190A (en) * | 1997-05-19 | 1999-11-09 | Microsoft Corporation | Client server animation system for managing interactive user interface characters |
Non-Patent Citations (2)
Title |
---|
"Survey of the State of the Art in Human Language Technology: Chapter 5: Spoken Output Technologies", Aug. 12, 1997, http://www.cse.ogi.edu/CSLU/HLTsurvey. |
From Text to Speech with SRS, J. Acoust. Soc. Am., vol. 72, Mar. 16, 1982. * |
Cited By (262)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7536385B1 (en) | 1997-11-17 | 2009-05-19 | Wolfe Mark A | System and method for communicating information relating to a network resource |
US7433874B1 (en) | 1997-11-17 | 2008-10-07 | Wolfe Mark A | System and method for communicating information relating to a network resource |
US9934516B1 (en) | 1997-11-17 | 2018-04-03 | Google Llc | Communicating information relating to a network resource |
US9467529B2 (en) * | 1998-01-12 | 2016-10-11 | Ol Security Limited Liability Company | Customizable media player with online/offline capabilities |
US20080307074A1 (en) * | 1998-01-12 | 2008-12-11 | Lextron Systems, Inc. | Customizable Media Player with Online/Offline Capabilities |
US20080045216A1 (en) * | 1998-05-29 | 2008-02-21 | Research In Motion Limited | System and Method for Redirecting Message Attachments Between a Host System and a Mobile Data Communication Device |
US8583744B2 (en) | 1998-05-29 | 2013-11-12 | Blackberry Limited | System and method for pushing information from a host system to a mobile data communication device |
US9298793B2 (en) | 1998-05-29 | 2016-03-29 | Blackberry Limited | System and method for pushing information from a host system to a mobile data communication device |
US20110202597A1 (en) * | 1998-05-29 | 2011-08-18 | Research In Motion Limited | System and Method for Pushing Information from a Host System to a Mobile Data Communication Device |
US8050661B2 (en) | 1998-05-29 | 2011-11-01 | Research In Motion Limited | System and method for redirecting message attachments between a host system and a mobile data communication device |
US20080052365A1 (en) * | 1998-05-29 | 2008-02-28 | Research In Motion Limited | System and Method for Pushing Information from a Host System to a Mobile Data Communication Device |
US8964708B2 (en) * | 1998-06-22 | 2015-02-24 | Sipco Llc | Systems and methods for monitoring and controlling remote devices |
US20100194582A1 (en) * | 1998-06-22 | 2010-08-05 | Petite Thomas D | Systems and methods for monitoring and controlling remote devices |
US9691376B2 (en) | 1999-04-30 | 2017-06-27 | Nuance Communications, Inc. | Concatenation cost in speech synthesis for acoustic unit sequential pair using hash table and default concatenation cost |
US8086456B2 (en) * | 1999-04-30 | 2011-12-27 | At&T Intellectual Property Ii, L.P. | Methods and apparatus for rapid acoustic unit selection from a large speech corpus |
US9236044B2 (en) | 1999-04-30 | 2016-01-12 | At&T Intellectual Property Ii, L.P. | Recording concatenation costs of most common acoustic unit sequential pairs to a concatenation cost database for speech synthesis |
US8315872B2 (en) | 1999-04-30 | 2012-11-20 | At&T Intellectual Property Ii, L.P. | Methods and apparatus for rapid acoustic unit selection from a large speech corpus |
US8788268B2 (en) | 1999-04-30 | 2014-07-22 | At&T Intellectual Property Ii, L.P. | Speech synthesis from acoustic units with default values of concatenation cost |
US20100286986A1 (en) * | 1999-04-30 | 2010-11-11 | At&T Intellectual Property Ii, L.P. Via Transfer From At&T Corp. | Methods and Apparatus for Rapid Acoustic Unit Selection From a Large Speech Corpus |
US7243067B1 (en) * | 1999-07-16 | 2007-07-10 | Bayerische Motoren Werke Aktiengesellschaft | Method and apparatus for wireless transmission of messages between a vehicle-internal communication system and a vehicle-external central computer |
US9646614B2 (en) | 2000-03-16 | 2017-05-09 | Apple Inc. | Fast, language-independent method for user authentication by voice |
US20020025036A1 (en) * | 2000-08-11 | 2002-02-28 | Trinity Communication Inc. | Modem device, data communications system, method of and device for protecting data, and computer product |
US8155970B2 (en) * | 2001-02-28 | 2012-04-10 | Telecom Italia S.P.A. | System and method for access to multimedia structures |
US20040076274A1 (en) * | 2001-02-28 | 2004-04-22 | Pierpaolo Anselmetti | System and method for access to multimedia structures |
US20110178801A1 (en) * | 2001-02-28 | 2011-07-21 | Telecom Italia S.P.A. | System and method for access to multimedia structures |
US7885815B2 (en) * | 2001-02-28 | 2011-02-08 | Telecom Italia S.P.A. | System and method for access to multimedia structures |
US8682987B2 (en) * | 2001-03-29 | 2014-03-25 | Chanyu Holdings, Llc | Electronic return messages with non-textual information |
US20100324710A1 (en) * | 2001-03-29 | 2010-12-23 | Delacruz Cedric G | Method for providing enhanced electronic mail return receipts |
US20070254684A1 (en) * | 2001-08-16 | 2007-11-01 | Roamware, Inc. | Method and system for sending and creating expressive messages |
US20080051120A1 (en) * | 2001-10-22 | 2008-02-28 | Riccardo Vieri | Mobile device for sending text messages |
US7649877B2 (en) * | 2001-10-22 | 2010-01-19 | Braintexter, Inc | Mobile device for sending text messages |
US20100049523A1 (en) * | 2002-06-05 | 2010-02-25 | At&T Corp. | System and method for configuring voice synthesis |
US7624017B1 (en) * | 2002-06-05 | 2009-11-24 | At&T Intellectual Property Ii, L.P. | System and method for configuring voice synthesis |
US9460703B2 (en) * | 2002-06-05 | 2016-10-04 | Interactions Llc | System and method for configuring voice synthesis based on environment |
US8086459B2 (en) * | 2002-06-05 | 2011-12-27 | At&T Intellectual Property Ii, L.P. | System and method for configuring voice synthesis |
US20140081642A1 (en) * | 2002-06-05 | 2014-03-20 | At&T Intellectual Property Ii, L.P. | System and Method for Configuring Voice Synthesis |
US8620668B2 (en) | 2002-06-05 | 2013-12-31 | At&T Intellectual Property Ii, L.P. | System and method for configuring voice synthesis |
US20080045194A1 (en) * | 2002-06-26 | 2008-02-21 | Research In Motion Limited | System and Method for Pushing Information Between a Host System and a Mobile Data Communication Device |
US8230026B2 (en) | 2002-06-26 | 2012-07-24 | Research In Motion Limited | System and method for pushing information between a host system and a mobile data communication device |
US7558732B2 (en) * | 2002-09-23 | 2009-07-07 | Infineon Technologies Ag | Method and system for computer-aided speech synthesis |
US20050216267A1 (en) * | 2002-09-23 | 2005-09-29 | Infineon Technologies Ag | Method and system for computer-aided speech synthesis |
US7280641B2 (en) * | 2003-09-02 | 2007-10-09 | Canon Kabushiki Kaisha | Communication terminal apparatus and transfer method therefor |
US20050047558A1 (en) * | 2003-09-02 | 2005-03-03 | Canon Kabushiki Kaisha | Communication terminal apparatus and transfer method therefor |
US20060179467A1 (en) * | 2004-02-04 | 2006-08-10 | Hsiao-Chieh Chung | Stock information broadcast device |
US8024416B2 (en) | 2004-10-20 | 2011-09-20 | Research In Motion Limited | System and method for bundling information |
US20080077707A1 (en) * | 2004-10-20 | 2008-03-27 | Research In Motion Limited | System and Method for Bundling Information |
US20080281928A1 (en) * | 2005-01-11 | 2008-11-13 | Teles Ag Informationstechnologien | Method For Transmitting Data to at Least One Communications End System and Communications Device For Carrying Out Said Method |
US9565051B2 (en) * | 2005-01-11 | 2017-02-07 | Teles Ag Informationstechnologien | Method for transmitting data to at least one communications end system and communications device for carrying out said method |
US20080008301A1 (en) * | 2005-06-22 | 2008-01-10 | Inventec Multimedia & Telecom Corporation | Network telephone device |
US8229091B2 (en) | 2005-07-01 | 2012-07-24 | At&T Intellectual Property I, L.P. | Interactive voice response to short message service text messenger |
US20090196405A1 (en) * | 2005-07-01 | 2009-08-06 | At & T Intellectual Property I, Lp. (Formerly Known As Sbc Knowledge Ventures, L.P.) | Ivr to sms text messenger |
US10318871B2 (en) | 2005-09-08 | 2019-06-11 | Apple Inc. | Method and apparatus for building an intelligent automated assistant |
US8428952B2 (en) | 2005-10-03 | 2013-04-23 | Nuance Communications, Inc. | Text-to-speech user's voice cooperative server for instant messaging clients |
US20070078656A1 (en) * | 2005-10-03 | 2007-04-05 | Niemeyer Terry W | Server-provided user's voice for instant messaging clients |
US8224647B2 (en) * | 2005-10-03 | 2012-07-17 | Nuance Communications, Inc. | Text-to-speech user's voice cooperative server for instant messaging clients |
US9026445B2 (en) | 2005-10-03 | 2015-05-05 | Nuance Communications, Inc. | Text-to-speech user's voice cooperative server for instant messaging clients |
US20090254349A1 (en) * | 2006-06-05 | 2009-10-08 | Yoshifumi Hirose | Speech synthesizer |
US7822606B2 (en) | 2006-07-14 | 2010-10-26 | Qualcomm Incorporated | Method and apparatus for generating audio information from received synthesis information |
WO2008008992A3 (en) * | 2006-07-14 | 2008-11-06 | Qualcomm Inc | Improved methods and apparatus for delivering audio information |
WO2008008992A2 (en) * | 2006-07-14 | 2008-01-17 | Qualcomm Incorporated | Improved methods and apparatus for delivering audio information |
US20080015860A1 (en) * | 2006-07-14 | 2008-01-17 | Frank Lane | Methods and apparatus for delivering audio information |
US9117447B2 (en) | 2006-09-08 | 2015-08-25 | Apple Inc. | Using event alert text as input to an automated assistant |
US8942986B2 (en) | 2006-09-08 | 2015-01-27 | Apple Inc. | Determining user intent based on ontologies of domains |
US8930191B2 (en) | 2006-09-08 | 2015-01-06 | Apple Inc. | Paraphrasing of user requests and results by automated digital assistant |
US10568032B2 (en) | 2007-04-03 | 2020-02-18 | Apple Inc. | Method and system for operating a multi-function portable electronic device using voice-activation |
US8311830B2 (en) | 2007-05-30 | 2012-11-13 | Cepstral, LLC | System and method for client voice building |
US8086457B2 (en) * | 2007-05-30 | 2011-12-27 | Cepstral, LLC | System and method for client voice building |
US20090048838A1 (en) * | 2007-05-30 | 2009-02-19 | Campbell Craig F | System and method for client voice building |
US20130282375A1 (en) * | 2007-06-01 | 2013-10-24 | At&T Mobility Ii Llc | Vehicle-Based Message Control Using Cellular IP |
US9478215B2 (en) * | 2007-06-01 | 2016-10-25 | At&T Mobility Ii Llc | Vehicle-based message control using cellular IP |
US8909545B2 (en) | 2007-07-26 | 2014-12-09 | Braintexter, Inc. | System to generate and set up an advertising campaign based on the insertion of advertising messages within an exchange of messages, and method to operate said system |
US8359234B2 (en) | 2007-07-26 | 2013-01-22 | Braintexter, Inc. | System to generate and set up an advertising campaign based on the insertion of advertising messages within an exchange of messages, and method to operate said system |
US8930177B2 (en) * | 2007-08-16 | 2015-01-06 | Crimson Corporation | Scripting support for data identifiers, voice recognition and speech in a telnet session |
US9648083B2 (en) | 2007-08-16 | 2017-05-09 | Crimson Corporation | Scripting support for data identifiers, voice recognition and speech in a telnet session |
US8635069B2 (en) * | 2007-08-16 | 2014-01-21 | Crimson Corporation | Scripting support for data identifiers, voice recognition and speech in a telnet session |
US8930193B2 (en) * | 2007-08-16 | 2015-01-06 | Crimson Corporation | Scripting support for data identifiers, voice recognition and voice input in a telnet session |
US10148734B2 (en) | 2007-08-16 | 2018-12-04 | Ivanti, Inc. | Scripting support for data identifiers, voice recognition and speech in a telnet session |
US20090048831A1 (en) * | 2007-08-16 | 2009-02-19 | Lamar John Van Wagenen | Scripting support for data identifiers, voice recognition and speech in a telnet session |
US20120221340A1 (en) * | 2007-08-16 | 2012-08-30 | Wavelink Corporation | Scripting support for data identifiers, voice recognition and voice input in a telnet session |
US20120226499A1 (en) * | 2007-08-16 | 2012-09-06 | Wavelink Corporation | Scripting support for data identifiers, voice recognition and speech in a telnet session |
US10938886B2 (en) | 2007-08-16 | 2021-03-02 | Ivanti, Inc. | Scripting support for data identifiers, voice recognition and speech in a telnet session |
US8213580B2 (en) * | 2007-10-25 | 2012-07-03 | International Business Machines Corporation | Automated message conversion based on availability of bandwidth |
US20090110158A1 (en) * | 2007-10-25 | 2009-04-30 | Yen-Fu Chen | Method and apparatus of automated message conversion based on availability of bandwidth |
US20100305949A1 (en) * | 2007-11-28 | 2010-12-02 | Masanori Kato | Speech synthesis device, speech synthesis method, and speech synthesis program |
US9330720B2 (en) | 2008-01-03 | 2016-05-03 | Apple Inc. | Methods and apparatus for altering audio output signals |
US10381016B2 (en) | 2008-01-03 | 2019-08-13 | Apple Inc. | Methods and apparatus for altering audio output signals |
US9626955B2 (en) | 2008-04-05 | 2017-04-18 | Apple Inc. | Intelligent text-to-speech conversion |
US9865248B2 (en) | 2008-04-05 | 2018-01-09 | Apple Inc. | Intelligent text-to-speech conversion |
US9535906B2 (en) | 2008-07-31 | 2017-01-03 | Apple Inc. | Mobile device having human language translation capability with positional feedback |
US10108612B2 (en) | 2008-07-31 | 2018-10-23 | Apple Inc. | Mobile device having human language translation capability with positional feedback |
US9959870B2 (en) | 2008-12-11 | 2018-05-01 | Apple Inc. | Speech recognition involving a mobile device |
US20150302854A1 (en) * | 2009-01-30 | 2015-10-22 | Altorr Corporation | Smartphone control of electrical devices |
US8280434B2 (en) | 2009-02-27 | 2012-10-02 | Research In Motion Limited | Mobile wireless communications device for hearing and/or speech impaired user |
US9172790B2 (en) | 2009-02-27 | 2015-10-27 | Blackberry Limited | Mobile wireless communications device for hearing and/or speech impaired user |
US20100222098A1 (en) * | 2009-02-27 | 2010-09-02 | Research In Motion Limited | Mobile wireless communications device for hearing and/or speech impaired user |
US11080012B2 (en) | 2009-06-05 | 2021-08-03 | Apple Inc. | Interface for a virtual digital assistant |
US10795541B2 (en) | 2009-06-05 | 2020-10-06 | Apple Inc. | Intelligent organization of tasks items |
US9858925B2 (en) | 2009-06-05 | 2018-01-02 | Apple Inc. | Using context information to facilitate processing of commands in a virtual assistant |
US10475446B2 (en) | 2009-06-05 | 2019-11-12 | Apple Inc. | Using context information to facilitate processing of commands in a virtual assistant |
US10283110B2 (en) | 2009-07-02 | 2019-05-07 | Apple Inc. | Methods and apparatuses for automatic speech recognition |
US20140320204A1 (en) * | 2009-12-28 | 2014-10-30 | Nxp B.V. | Adjustable mos resistor |
US9178492B2 (en) * | 2009-12-28 | 2015-11-03 | Nxp B.V. | Adjustable MOS resistor |
US8892446B2 (en) | 2010-01-18 | 2014-11-18 | Apple Inc. | Service orchestration for intelligent automated assistant |
US10705794B2 (en) | 2010-01-18 | 2020-07-07 | Apple Inc. | Automatically adapting user interfaces for hands-free interaction |
US10706841B2 (en) | 2010-01-18 | 2020-07-07 | Apple Inc. | Task flow identification based on user intent |
US11423886B2 (en) | 2010-01-18 | 2022-08-23 | Apple Inc. | Task flow identification based on user intent |
US9548050B2 (en) | 2010-01-18 | 2017-01-17 | Apple Inc. | Intelligent automated assistant |
US10553209B2 (en) | 2010-01-18 | 2020-02-04 | Apple Inc. | Systems and methods for hands-free notification summaries |
US10679605B2 (en) | 2010-01-18 | 2020-06-09 | Apple Inc. | Hands-free list-reading by intelligent automated assistant |
US10276170B2 (en) | 2010-01-18 | 2019-04-30 | Apple Inc. | Intelligent automated assistant |
US8903716B2 (en) | 2010-01-18 | 2014-12-02 | Apple Inc. | Personalized vocabulary for digital assistant |
US10496753B2 (en) | 2010-01-18 | 2019-12-03 | Apple Inc. | Automatically adapting user interfaces for hands-free interaction |
US9318108B2 (en) | 2010-01-18 | 2016-04-19 | Apple Inc. | Intelligent automated assistant |
US10607140B2 (en) | 2010-01-25 | 2020-03-31 | Newvaluexchange Ltd. | Apparatuses, methods and systems for a digital conversation management platform |
US10984326B2 (en) | 2010-01-25 | 2021-04-20 | Newvaluexchange Ltd. | Apparatuses, methods and systems for a digital conversation management platform |
US10607141B2 (en) | 2010-01-25 | 2020-03-31 | Newvaluexchange Ltd. | Apparatuses, methods and systems for a digital conversation management platform |
US11410053B2 (en) | 2010-01-25 | 2022-08-09 | Newvaluexchange Ltd. | Apparatuses, methods and systems for a digital conversation management platform |
US10984327B2 (en) | 2010-01-25 | 2021-04-20 | New Valuexchange Ltd. | Apparatuses, methods and systems for a digital conversation management platform |
US9633660B2 (en) | 2010-02-25 | 2017-04-25 | Apple Inc. | User profiling for voice input processing |
US10049675B2 (en) | 2010-02-25 | 2018-08-14 | Apple Inc. | User profiling for voice input processing |
US9196251B2 (en) | 2010-05-28 | 2015-11-24 | Daniel Ben-Ezri | Contextual conversion platform for generating prioritized replacement text for spoken content output |
US8423365B2 (en) | 2010-05-28 | 2013-04-16 | Daniel Ben-Ezri | Contextual conversion platform |
US8918323B2 (en) | 2010-05-28 | 2014-12-23 | Daniel Ben-Ezri | Contextual conversion platform for generating prioritized replacement text for spoken content output |
US20130096921A1 (en) * | 2010-07-13 | 2013-04-18 | Fujitsu Ten Limited | Information providing system and vehicle-mounted apparatus |
US9070292B2 (en) * | 2010-07-13 | 2015-06-30 | Fujitsu Ten Limited | Information providing system and vehicle-mounted apparatus |
GB2481992A (en) * | 2010-07-13 | 2012-01-18 | Sony Europe Ltd | Updating text-to-speech converter for broadcast signal receiver |
US9263027B2 (en) | 2010-07-13 | 2016-02-16 | Sony Europe Limited | Broadcast system using text to speech conversion |
US10762293B2 (en) | 2010-12-22 | 2020-09-01 | Apple Inc. | Using parts-of-speech tagging and named entity recognition for spelling correction |
US9262612B2 (en) | 2011-03-21 | 2016-02-16 | Apple Inc. | Device access using voice authentication |
US10102359B2 (en) | 2011-03-21 | 2018-10-16 | Apple Inc. | Device access using voice authentication |
US10057736B2 (en) | 2011-06-03 | 2018-08-21 | Apple Inc. | Active transport based notifications |
US10241644B2 (en) | 2011-06-03 | 2019-03-26 | Apple Inc. | Actionable reminder entries |
US11120372B2 (en) | 2011-06-03 | 2021-09-14 | Apple Inc. | Performing actions associated with task items that represent tasks to perform |
US10706373B2 (en) | 2011-06-03 | 2020-07-07 | Apple Inc. | Performing actions associated with task items that represent tasks to perform |
US9798393B2 (en) | 2011-08-29 | 2017-10-24 | Apple Inc. | Text correction processing |
US10241752B2 (en) | 2011-09-30 | 2019-03-26 | Apple Inc. | Interface for a virtual digital assistant |
US9799323B2 (en) | 2011-12-01 | 2017-10-24 | Nuance Communications, Inc. | System and method for low-latency web-based text-to-speech without plugins |
US20130144624A1 (en) * | 2011-12-01 | 2013-06-06 | At&T Intellectual Property I, L.P. | System and method for low-latency web-based text-to-speech without plugins |
US9240180B2 (en) * | 2011-12-01 | 2016-01-19 | At&T Intellectual Property I, L.P. | System and method for low-latency web-based text-to-speech without plugins |
US8595016B2 (en) | 2011-12-23 | 2013-11-26 | Angle, Llc | Accessing content using a source-specific content-adaptable dialogue |
US10134385B2 (en) | 2012-03-02 | 2018-11-20 | Apple Inc. | Systems and methods for name pronunciation |
US9483461B2 (en) | 2012-03-06 | 2016-11-01 | Apple Inc. | Handling speech synthesis of content for multiple languages |
US9953088B2 (en) | 2012-05-14 | 2018-04-24 | Apple Inc. | Crowd sourcing information to fulfill user requests |
US10079014B2 (en) | 2012-06-08 | 2018-09-18 | Apple Inc. | Name recognition system |
US9495129B2 (en) | 2012-06-29 | 2016-11-15 | Apple Inc. | Device, method, and user interface for voice-activated navigation and browsing of a document |
US9576574B2 (en) | 2012-09-10 | 2017-02-21 | Apple Inc. | Context-sensitive handling of interruptions by intelligent digital assistant |
US9971774B2 (en) | 2012-09-19 | 2018-05-15 | Apple Inc. | Voice-based media searching |
US10978090B2 (en) | 2013-02-07 | 2021-04-13 | Apple Inc. | Voice trigger for a digital assistant |
US10199051B2 (en) | 2013-02-07 | 2019-02-05 | Apple Inc. | Voice trigger for a digital assistant |
US9368114B2 (en) | 2013-03-14 | 2016-06-14 | Apple Inc. | Context-sensitive handling of interruptions |
US9697822B1 (en) | 2013-03-15 | 2017-07-04 | Apple Inc. | System and method for updating an adaptive speech recognition model |
US9922642B2 (en) | 2013-03-15 | 2018-03-20 | Apple Inc. | Training an at least partial voice command system |
US9633674B2 (en) | 2013-06-07 | 2017-04-25 | Apple Inc. | System and method for detecting errors in interactions with a voice-based digital assistant |
US9966060B2 (en) | 2013-06-07 | 2018-05-08 | Apple Inc. | System and method for user-specified pronunciation of words for speech synthesis and recognition |
US9620104B2 (en) | 2013-06-07 | 2017-04-11 | Apple Inc. | System and method for user-specified pronunciation of words for speech synthesis and recognition |
US9582608B2 (en) | 2013-06-07 | 2017-02-28 | Apple Inc. | Unified ranking with entropy-weighted information for phrase-based semantic auto-completion |
US10657961B2 (en) | 2013-06-08 | 2020-05-19 | Apple Inc. | Interpreting and acting upon commands that involve sharing information with remote devices |
US9966068B2 (en) | 2013-06-08 | 2018-05-08 | Apple Inc. | Interpreting and acting upon commands that involve sharing information with remote devices |
US10185542B2 (en) | 2013-06-09 | 2019-01-22 | Apple Inc. | Device, method, and graphical user interface for enabling conversation persistence across two or more instances of a digital assistant |
US10176167B2 (en) | 2013-06-09 | 2019-01-08 | Apple Inc. | System and method for inferring user intent from speech inputs |
US9300784B2 (en) | 2013-06-13 | 2016-03-29 | Apple Inc. | System and method for emergency calls initiated by voice command |
US10791216B2 (en) | 2013-08-06 | 2020-09-29 | Apple Inc. | Auto-activating smart responses based on activities from remote devices |
US10393815B2 (en) * | 2014-02-21 | 2019-08-27 | Fluke Precision Measurement Ltd. | Voice counting of each battery under test |
EP2910963A1 (en) | 2014-02-21 | 2015-08-26 | Danaher (Shanghai) Industrial Instrumentation Technologies R&D Co Ltd | Methods and instruments for testing batteries |
US20150241522A1 (en) * | 2014-02-21 | 2015-08-27 | Danaher (Shanghai) Industrial Instrumentation Technologies R&D Co., Ltd. | Voice counting of each battery under test |
US9620105B2 (en) | 2014-05-15 | 2017-04-11 | Apple Inc. | Analyzing audio input for efficient speech and music recognition |
US10592095B2 (en) | 2014-05-23 | 2020-03-17 | Apple Inc. | Instantaneous speaking of content on touch devices |
US9502031B2 (en) | 2014-05-27 | 2016-11-22 | Apple Inc. | Method for supporting dynamic grammars in WFST-based ASR |
US9760559B2 (en) | 2014-05-30 | 2017-09-12 | Apple Inc. | Predictive text input |
US9785630B2 (en) | 2014-05-30 | 2017-10-10 | Apple Inc. | Text prediction using combined word N-gram and unigram language models |
US9734193B2 (en) | 2014-05-30 | 2017-08-15 | Apple Inc. | Determining domain salience ranking from ambiguous words in natural speech |
US11257504B2 (en) | 2014-05-30 | 2022-02-22 | Apple Inc. | Intelligent assistant for home automation |
US10170123B2 (en) | 2014-05-30 | 2019-01-01 | Apple Inc. | Intelligent assistant for home automation |
US10169329B2 (en) | 2014-05-30 | 2019-01-01 | Apple Inc. | Exemplar-based natural language processing |
US10497365B2 (en) | 2014-05-30 | 2019-12-03 | Apple Inc. | Multi-command single utterance input method |
US10083690B2 (en) | 2014-05-30 | 2018-09-25 | Apple Inc. | Better resolution when referencing to concepts |
US10078631B2 (en) | 2014-05-30 | 2018-09-18 | Apple Inc. | Entropy-guided text prediction using combined word and character n-gram language models |
US9633004B2 (en) | 2014-05-30 | 2017-04-25 | Apple Inc. | Better resolution when referencing to concepts |
US9842101B2 (en) | 2014-05-30 | 2017-12-12 | Apple Inc. | Predictive conversion of language input |
US10289433B2 (en) | 2014-05-30 | 2019-05-14 | Apple Inc. | Domain specific language for encoding assistant dialog |
US9715875B2 (en) | 2014-05-30 | 2017-07-25 | Apple Inc. | Reducing the need for manual start/end-pointing and trigger phrases |
US9430463B2 (en) | 2014-05-30 | 2016-08-30 | Apple Inc. | Exemplar-based natural language processing |
US11133008B2 (en) | 2014-05-30 | 2021-09-28 | Apple Inc. | Reducing the need for manual start/end-pointing and trigger phrases |
US9966065B2 (en) | 2014-05-30 | 2018-05-08 | Apple Inc. | Multi-command single utterance input method |
US9338493B2 (en) | 2014-06-30 | 2016-05-10 | Apple Inc. | Intelligent automated assistant for TV user interactions |
US10659851B2 (en) | 2014-06-30 | 2020-05-19 | Apple Inc. | Real-time digital assistant knowledge updates |
US10904611B2 (en) | 2014-06-30 | 2021-01-26 | Apple Inc. | Intelligent automated assistant for TV user interactions |
US9668024B2 (en) | 2014-06-30 | 2017-05-30 | Apple Inc. | Intelligent automated assistant for TV user interactions |
US10033797B1 (en) | 2014-08-20 | 2018-07-24 | Ivanti, Inc. | Terminal emulation over HTML |
US10873621B1 (en) | 2014-08-20 | 2020-12-22 | Ivanti, Inc. | Terminal emulation over html |
US10446141B2 (en) | 2014-08-28 | 2019-10-15 | Apple Inc. | Automatic speech recognition based on user feedback |
US9818400B2 (en) | 2014-09-11 | 2017-11-14 | Apple Inc. | Method and apparatus for discovering trending terms in speech requests |
US10431204B2 (en) | 2014-09-11 | 2019-10-01 | Apple Inc. | Method and apparatus for discovering trending terms in speech requests |
US10789041B2 (en) | 2014-09-12 | 2020-09-29 | Apple Inc. | Dynamic thresholds for always listening speech trigger |
US10127911B2 (en) | 2014-09-30 | 2018-11-13 | Apple Inc. | Speaker identification and unsupervised speaker adaptation techniques |
US9668121B2 (en) | 2014-09-30 | 2017-05-30 | Apple Inc. | Social reminders |
US10074360B2 (en) | 2014-09-30 | 2018-09-11 | Apple Inc. | Providing an indication of the suitability of speech recognition |
US9886432B2 (en) | 2014-09-30 | 2018-02-06 | Apple Inc. | Parsimonious handling of word inflection via categorical stem + suffix N-gram language models |
US9646609B2 (en) | 2014-09-30 | 2017-05-09 | Apple Inc. | Caching apparatus for serving phonetic pronunciations |
US9986419B2 (en) | 2014-09-30 | 2018-05-29 | Apple Inc. | Social reminders |
US11556230B2 (en) | 2014-12-02 | 2023-01-17 | Apple Inc. | Data detection |
US10552013B2 (en) | 2014-12-02 | 2020-02-04 | Apple Inc. | Data detection |
US9711141B2 (en) | 2014-12-09 | 2017-07-18 | Apple Inc. | Disambiguating heteronyms in speech synthesis |
US9865280B2 (en) | 2015-03-06 | 2018-01-09 | Apple Inc. | Structured dictation using intelligent automated assistants |
US9721566B2 (en) | 2015-03-08 | 2017-08-01 | Apple Inc. | Competing devices responding to voice triggers |
US10311871B2 (en) | 2015-03-08 | 2019-06-04 | Apple Inc. | Competing devices responding to voice triggers |
US11087759B2 (en) | 2015-03-08 | 2021-08-10 | Apple Inc. | Virtual assistant activation |
US9886953B2 (en) | 2015-03-08 | 2018-02-06 | Apple Inc. | Virtual assistant activation |
US10567477B2 (en) | 2015-03-08 | 2020-02-18 | Apple Inc. | Virtual assistant continuity |
US9899019B2 (en) | 2015-03-18 | 2018-02-20 | Apple Inc. | Systems and methods for structured stem and suffix language models |
US9842105B2 (en) | 2015-04-16 | 2017-12-12 | Apple Inc. | Parsimonious continuous-space phrase representations for natural language processing |
US10083688B2 (en) | 2015-05-27 | 2018-09-25 | Apple Inc. | Device voice control for selecting a displayed affordance |
US10127220B2 (en) | 2015-06-04 | 2018-11-13 | Apple Inc. | Language identification from short strings |
US10101822B2 (en) | 2015-06-05 | 2018-10-16 | Apple Inc. | Language input correction |
US10356243B2 (en) | 2015-06-05 | 2019-07-16 | Apple Inc. | Virtual assistant aided communication with 3rd party service in a communication session |
US11025565B2 (en) | 2015-06-07 | 2021-06-01 | Apple Inc. | Personalized prediction of responses for instant messaging |
US10255907B2 (en) | 2015-06-07 | 2019-04-09 | Apple Inc. | Automatic accent detection using acoustic models |
US10186254B2 (en) | 2015-06-07 | 2019-01-22 | Apple Inc. | Context-based endpoint detection |
US11500672B2 (en) | 2015-09-08 | 2022-11-15 | Apple Inc. | Distributed personal assistant |
US10747498B2 (en) | 2015-09-08 | 2020-08-18 | Apple Inc. | Zero latency digital assistant |
US10671428B2 (en) | 2015-09-08 | 2020-06-02 | Apple Inc. | Distributed personal assistant |
US9697820B2 (en) | 2015-09-24 | 2017-07-04 | Apple Inc. | Unit-selection text-to-speech synthesis using concatenation-sensitive neural networks |
US11010550B2 (en) | 2015-09-29 | 2021-05-18 | Apple Inc. | Unified language modeling framework for word prediction, auto-completion and auto-correction |
US10366158B2 (en) | 2015-09-29 | 2019-07-30 | Apple Inc. | Efficient word encoding for recurrent neural network language models |
US11587559B2 (en) | 2015-09-30 | 2023-02-21 | Apple Inc. | Intelligent device identification |
US10691473B2 (en) | 2015-11-06 | 2020-06-23 | Apple Inc. | Intelligent automated assistant in a messaging environment |
US11526368B2 (en) | 2015-11-06 | 2022-12-13 | Apple Inc. | Intelligent automated assistant in a messaging environment |
US10049668B2 (en) | 2015-12-02 | 2018-08-14 | Apple Inc. | Applying neural network language models to weighted finite state transducers for automatic speech recognition |
US10223066B2 (en) | 2015-12-23 | 2019-03-05 | Apple Inc. | Proactive assistance based on dialog communication between devices |
US10446143B2 (en) | 2016-03-14 | 2019-10-15 | Apple Inc. | Identification of voice inputs providing credentials |
US9934775B2 (en) | 2016-05-26 | 2018-04-03 | Apple Inc. | Unit-selection text-to-speech synthesis based on predicted concatenation parameters |
US9972304B2 (en) | 2016-06-03 | 2018-05-15 | Apple Inc. | Privacy preserving distributed evaluation framework for embedded personalized systems |
US10249300B2 (en) | 2016-06-06 | 2019-04-02 | Apple Inc. | Intelligent list reading |
US11069347B2 (en) | 2016-06-08 | 2021-07-20 | Apple Inc. | Intelligent automated assistant for media exploration |
US10049663B2 (en) | 2016-06-08 | 2018-08-14 | Apple, Inc. | Intelligent automated assistant for media exploration |
US10354011B2 (en) | 2016-06-09 | 2019-07-16 | Apple Inc. | Intelligent automated assistant in a home environment |
US10733993B2 (en) | 2016-06-10 | 2020-08-04 | Apple Inc. | Intelligent digital assistant in a multi-tasking environment |
US11037565B2 (en) | 2016-06-10 | 2021-06-15 | Apple Inc. | Intelligent digital assistant in a multi-tasking environment |
US10490187B2 (en) | 2016-06-10 | 2019-11-26 | Apple Inc. | Digital assistant providing automated status report |
US10509862B2 (en) | 2016-06-10 | 2019-12-17 | Apple Inc. | Dynamic phrase expansion of language input |
US10067938B2 (en) | 2016-06-10 | 2018-09-04 | Apple Inc. | Multilingual word prediction |
US10192552B2 (en) | 2016-06-10 | 2019-01-29 | Apple Inc. | Digital assistant providing whispered speech |
US10269345B2 (en) | 2016-06-11 | 2019-04-23 | Apple Inc. | Intelligent task discovery |
US10297253B2 (en) | 2016-06-11 | 2019-05-21 | Apple Inc. | Application integration with a digital assistant |
US10521466B2 (en) | 2016-06-11 | 2019-12-31 | Apple Inc. | Data driven natural language event detection and classification |
US11152002B2 (en) | 2016-06-11 | 2021-10-19 | Apple Inc. | Application integration with a digital assistant |
US10089072B2 (en) | 2016-06-11 | 2018-10-02 | Apple Inc. | Intelligent device arbitration and control |
US11100278B2 (en) | 2016-07-28 | 2021-08-24 | Ivanti, Inc. | Systems and methods for presentation of a terminal application screen |
US10553215B2 (en) | 2016-09-23 | 2020-02-04 | Apple Inc. | Intelligent automated assistant |
US10043516B2 (en) | 2016-09-23 | 2018-08-07 | Apple Inc. | Intelligent automated assistant |
US10593346B2 (en) | 2016-12-22 | 2020-03-17 | Apple Inc. | Rank-reduced token representation for automatic speech recognition |
US10755703B2 (en) | 2017-05-11 | 2020-08-25 | Apple Inc. | Offline personal assistant |
US10791176B2 (en) | 2017-05-12 | 2020-09-29 | Apple Inc. | Synchronization and task delegation of a digital assistant |
US11405466B2 (en) | 2017-05-12 | 2022-08-02 | Apple Inc. | Synchronization and task delegation of a digital assistant |
US10410637B2 (en) | 2017-05-12 | 2019-09-10 | Apple Inc. | User-specific acoustic models |
US10810274B2 (en) | 2017-05-15 | 2020-10-20 | Apple Inc. | Optimizing dialogue policy decisions for digital assistants using implicit feedback |
US10482874B2 (en) | 2017-05-15 | 2019-11-19 | Apple Inc. | Hierarchical belief states for digital assistants |
US11217255B2 (en) | 2017-05-16 | 2022-01-04 | Apple Inc. | Far-field extension for digital assistant services |
US11049490B2 (en) * | 2018-10-26 | 2021-06-29 | Institute For Information Industry | Audio playback device and audio playback method thereof for adjusting text to speech of a target character using spectral features |
US20200135169A1 (en) * | 2018-10-26 | 2020-04-30 | Institute For Information Industry | Audio playback device and audio playback method thereof |
CN111078427A (en) * | 2019-12-04 | 2020-04-28 | 上海肇观电子科技有限公司 | Message reminding method, electronic device and storage medium |
CN111078427B (en) * | 2019-12-04 | 2024-02-06 | 上海肇观电子科技有限公司 | Message reminding method, electronic equipment and storage medium |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US7027568B1 (en) | Personal message service with enhanced text to speech synthesis | |
JP3086368B2 (en) | Broadcast communication equipment | |
KR100303411B1 (en) | Singlecast interactive radio system | |
JP5033756B2 (en) | Method and apparatus for creating and distributing real-time interactive content on wireless communication networks and the Internet | |
US6289085B1 (en) | Voice mail system, voice synthesizing device and method therefor | |
EP0378694B1 (en) | Response control system | |
EP2390783B1 (en) | Method and apparatus for annotating a document | |
KR100841026B1 (en) | Dynamic content delivery responsive to user requests | |
US6993290B1 (en) | Portable personal radio system and method | |
US6510438B2 (en) | Electronic mail system, method of sending and receiving electronic mail, and storage medium | |
US20070082711A1 (en) | Method and apparatus for creating and wirelessly communicating original multimedia content | |
US20050010633A1 (en) | Methods and apparatuses for programming user-defined information into electronic devices | |
US20030019347A1 (en) | Tele-karaoke | |
JP2009112000A6 (en) | Method and apparatus for creating and distributing real-time interactive content on wireless communication networks and the Internet | |
US8594651B2 (en) | Methods and apparatuses for programming user-defined information into electronic devices | |
WO1998039901A1 (en) | Telephone call transcription with electronic delivery | |
JP2001503236A (en) | Personal voice message processor and method | |
US5613038A (en) | Communications system for multiple individually addressed messages | |
JP2001236205A (en) | Device and method for processing information and computer readable recording medium with recorded information processing program | |
US20090034754A1 (en) | Apparatus for Automatically Mixing Audio Signals in a Predetermined Manner | |
JP4357175B2 (en) | Method and apparatus for creating and distributing real-time interactive content on wireless communication networks and the Internet | |
WO1997014222A1 (en) | Personal audio message processor and method | |
JP3073293B2 (en) | Audio information output system | |
JP3999078B2 (en) | Voice data distribution device and client terminal | |
KR100359529B1 (en) | Terminal device for real-time playing and storaging of internet audio |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: BELL ATLANTIC NETWORK SERVICES, INC., VIRGINIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:SIMPSON, DAVID;CURRY, JAMES E.;MCALLISTER, ALEXANDER I.;REEL/FRAME:008980/0260;SIGNING DATES FROM 19971121 TO 19971215 |
|
AS | Assignment |
Owner name: VERIZON SERVICES CORP., VIRGINIAFree format text: CHANGE OF NAME;ASSIGNOR:BELL ATLANTIC NETWORK SERVICES, INC.;REEL/FRAME:017538/0882Effective date: 20000601 |
|
FPAY | Fee payment |
Year of fee payment: 4 |
|
FEPP | Fee payment procedure |
Free format text: PAYOR NUMBER ASSIGNED (ORIGINAL EVENT CODE: ASPN); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
AS | Assignment |
Owner name: VERIZON PATENT AND LICENSING INC., NEW JERSEYFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:VERIZON SERVICES CORP.;REEL/FRAME:023586/0095Effective date: 20091125 |
|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:VERIZON PATENT AND LICENSING INC.;REEL/FRAME:025328/0910Effective date: 20100916 |
|
FPAY | Fee payment |
Year of fee payment: 8 |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044144/0001Effective date: 20170929 |
|
FEPP | Fee payment procedure |
Free format text: MAINTENANCE FEE REMINDER MAILED (ORIGINAL EVENT CODE: REM.) |
|
LAPS | Lapse for failure to pay maintenance fees |
Free format text: PATENT EXPIRED FOR FAILURE TO PAY MAINTENANCE FEES (ORIGINAL EVENT CODE: EXP.) |
|
STCH | Information on status: patent discontinuation |
Free format text: PATENT EXPIRED DUE TO NONPAYMENT OF MAINTENANCE FEES UNDER 37 CFR 1.362 |
|
FP | Lapsed due to failure to pay maintenance fee |
Effective date: 20180411 |