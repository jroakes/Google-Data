CN110945498A - Map uncertainty and observation model - Google Patents
Map uncertainty and observation model Download PDFInfo
- Publication number
- CN110945498A CN110945498A CN201980003382.4A CN201980003382A CN110945498A CN 110945498 A CN110945498 A CN 110945498A CN 201980003382 A CN201980003382 A CN 201980003382A CN 110945498 A CN110945498 A CN 110945498A
- Authority
- CN
- China
- Prior art keywords
- vehicle
- uncertainty
- entity
- map
- model
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/29—Geographical information databases
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/21—Design, administration or maintenance of databases
- G06F16/211—Schema design and management
- G06F16/212—Schema design and management with details for data modelling support
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/23—Updating
- G06F16/2365—Ensuring data consistency and integrity
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/28—Databases characterised by their database models, e.g. relational or object models
- G06F16/284—Relational databases
- G06F16/288—Entity relationship models
Abstract
Systems and methods are described that provide a measure of uncertainty of map features provided in association with a vehicle map service. The vehicle map service may include a vehicle map model configured to provide map data for a geographic area in association with the vehicle map service. The vehicle map model may have an entity schema that includes a first address space configured to represent a plurality of entities associated with the vehicle map model. The vehicle map service may include an uncertainty model configured to represent a plurality of uncertainties associated with a plurality of entities. The uncertainty model may have an uncertainty pattern that includes a second address space separate from the first address space. The uncertainty in the second address space may point to one or more entities in the first address space.
Description
RELATED APPLICATIONS
This application claims priority to U.S. provisional application No.62/702,570, filed 24.7.2018, the disclosure of which is incorporated herein by reference in its entirety for all purposes.
Technical Field
The present disclosure relates generally to a system for accessing and processing data including data associated with a vehicle map service.
Background
Operations associated with geographic information may be implemented on a variety of computing devices. These operations may include processing geographic information for access and use by a user or computing system. Further, these operations may include sending and receiving data to a remote computing system. However, the types of operations and the manner in which the operations are performed may vary over time, as may the underlying hardware implementing the operations. Thus, there are different ways to utilize the computing resources associated with geographic information.
Disclosure of Invention
Aspects and advantages of embodiments of the present disclosure will be set forth in part in the description which follows or may be learned by practice of the embodiments.
One example aspect of the present disclosure is directed to a computing system comprising one or more non-transitory computer-readable media collectively storing a vehicle map model configured to provide map data for a geographic area in association with a vehicle map service and an uncertainty model configured to represent a plurality of uncertainties associated with a plurality of entities. The vehicle map model has an entity schema that includes a first address space configured to represent a plurality of entities associated with the vehicle map model. The uncertainty model has an uncertainty pattern that includes a second address space separate from the first address space. At least one of the plurality of ambiguities in the second address space is configured to point to one or more of the plurality of entities in the first address space.
Another example aspect of the present disclosure is directed to a computer-implemented method of operating a vehicle map service. The method includes accessing, by one or more computing devices, a map model configured to provide map data for a geographic area in association with a map service. The map model includes a first address space configured to represent an entity associated with the map model. The method includes accessing, by one or more computing devices, an uncertainty model configured to represent a plurality of uncertainties associated with map data for the geographic area. The uncertainty model includes a second address space separate from the first address space. The method includes generating, by one or more computing devices, map data including information associated with a geographic area. Generating the map data includes: generating a plurality of entities defined in a first address space based at least in part on a map model according to an entity model of the map model; and generating one or more uncertainty relationships with respect to one or more of the plurality of entities based at least in part on the uncertainty model. The one or more uncertainty relationships are defined in the second address space according to an uncertainty pattern of an uncertainty model.
Other example aspects of the disclosure are directed to systems, apparatuses, computer program products (such as tangible, non-transitory computer-readable media, but also such as software downloadable through a communication network without necessarily being stored in a non-transitory form), user interfaces, storage devices, and electronic devices for providing map data and uncertainty data.
These and other features, aspects, and advantages of various embodiments will become better understood with reference to the following description and appended claims. The accompanying drawings, which are incorporated in and constitute a part of this specification, illustrate embodiments of the disclosure and together with the description, serve to explain the relevant principles.
Drawings
A detailed discussion of embodiments directed to one of ordinary skill in the art is set forth in the specification, which makes reference to the appended figures, in which:
FIG. 1 depicts a block diagram of an example computing environment in which a vehicle map service according to an example embodiment of the present disclosure may be implemented;
FIG. 2 depicts an example of a data structure for vehicle map service data in accordance with an example embodiment of the present disclosure;
FIG. 3 depicts a block diagram of an example of a vehicle map service data layer, according to an example embodiment of the present disclosure;
FIG. 4 depicts a block diagram of an example vehicle service system, according to an example embodiment of the present disclosure;
FIG. 5 depicts a block diagram of an example computing environment including a vehicle service system, according to an example embodiment of the present disclosure;
FIG. 6 depicts a block diagram of an example vehicle service system, according to an example embodiment of the present disclosure;
FIG. 7 depicts a flowchart describing an example method of operating a vehicle map service system in accordance with an example embodiment of the present disclosure;
FIG. 8 depicts a block diagram illustrating an example of a vehicle map service agreement defining a vehicle map model and an uncertainty model in accordance with an example embodiment of the present disclosure;
FIG. 9 depicts a block diagram of an example vehicle map model, according to an example embodiment of the present disclosure;
FIG. 10 depicts a block diagram of an example uncertainty model, according to an example embodiment of the present disclosure;
FIG. 11 depicts a flowchart describing an example method of generating vehicle map service data in accordance with an example embodiment of the present disclosure;
FIG. 12 depicts a block diagram of example vehicle map service data including entities defined according to an entity pattern of a vehicle map model and uncertainty relationships defined according to an uncertainty pattern of an uncertainty model, according to an example embodiment of the present disclosure;
FIG. 13 depicts a block diagram of example vehicle map service data including entities defined based on observations generated from multiple images, in accordance with an example embodiment of the present disclosure;
FIG. 14 depicts a block diagram of example vehicle map service data including entities and cluster relationships defined between the entities, according to an example embodiment of the disclosure;
FIG. 15 depicts a block diagram of example vehicle map service data including a vehicle location entity and a road segment entity, according to an example embodiment of the disclosure; and
FIG. 16 depicts a block diagram of an example computing device that may be used to implement example embodiments in accordance with the present disclosure.
Detailed Description
Reference will now be made in detail to embodiments, one or more examples of which are illustrated in the drawings. Each example is provided by way of illustration of the embodiments and not limitation of the present disclosure. Indeed, it will be apparent to those skilled in the art that various modifications and variations can be made to the embodiments without departing from the scope or spirit of the disclosure. For instance, features illustrated or described as part of one embodiment, can be used with another embodiment to yield a still further embodiment. It is therefore intended that aspects of the present disclosure cover such modifications and variations.
In general, systems and methods according to example embodiments of the present disclosure are directed to observation and uncertainty modeling for maps (such as digital maps that may be provided by a geographic information service). More specifically, the uncertainty model may be provided as part of a vehicle map service configured to transmit maps and related data between client systems of the vehicle and between the client systems and remote geographic information systems and/or remote vehicle service systems. The uncertainty model may be configured separately and independently from a base map model of the vehicle map service. For example, the uncertainty model may define an uncertainty address space that is separate from a physical address space defined by the map model. In this manner, uncertainty relationships defined using uncertainty patterns of uncertainty models may point to entities defined using entity patterns of map models and may associate entities within an entity address space. Such techniques may support fusing raw observations of multiple, possibly incomplete sub-maps and/or map elements into a single comprehensive map. The uncertainty model may provide sufficient confidence and error information so that statistical inferences can be made and combined to represent the score maps (e.g., possibly from sensors of the vehicle) and provide the ability to meaningfully fuse the score maps.
According to example embodiments of the present disclosure, a vehicle map service may provide a model of the real world from the perspective of multiple entities. For example, the model may include data or observations provided by sensors, map models, fused observations, and the like. Entities associated with a vehicle map service may include sensors, map models, and observations inferred from outputs of the sensors and/or the map models. Examples of entities associated with a vehicle map service may include observations (e.g., signs, lanes, other vehicles, pedestrians, buildings, etc.), map features (also referred to as map elements), vehicles from which map data is obtained or to which map data is provided, or any other entity that may be associated with or represented by the vehicle map service. The vehicle map service may provide a local on-board service that enables the transmission of map data and sensor-derived map relative views around the vehicle. Map data in the vicinity may enable the vehicle to learn more about its surroundings, thereby driving more safely, efficiently, comfortably, and intelligently. In some examples, a data communication protocol may be defined for data communication between various systems. The in-vehicle navigation experience may enable a driver to search for and select a destination, select an optimal route, and navigate to the destination. Backend cloud support may be provided to assist in analyzing vehicle data and planning. For example, a vehicle map service may provide an in-vehicle service that includes real-time data services that may be implemented within one or more computing devices of the vehicle. The data service may be capable of downloading map data and software updates from a remote map service system, uploading collected information to a remote map service system and/or a vehicle service system. Map viewing may be shared with other applications, such as navigation applications.
Entities associated with the vehicle map service may be associated with multiple types of uncertainty. For example, there may be uncertainty about object detection (e.g., the likelihood of the observed entity actually being present). Uncertainty can be expressed using a joint probability model. The uncertainty may be represented using parameters derived from a joint probability model or any probability model or simplified form of a density function. A simplified likelihood or covariance between variances representing a more general probability density function or probability model may be used. Any suitable parameter or value may be used to express uncertainty. For example, the uncertainty may be expressed using a mean, a variance, and/or a covariance. As a specific example, consider an identical marker that may be located in one of three positions, and for each position, the sum of all three probabilities may be between 0.0 and 1.0. Uncertainties may also exist with respect to certain observations (e.g., X, Y or the Z coordinate) of parameters of an entity or model. The uncertainty may be what the error envelope about the value looks like (which may be a function of other values such as covariance).
According to some aspects of the present disclosure, a vehicle map service may include or otherwise utilize an uncertainty model that defines an uncertainty pattern of uncertainty relationships that is separate from an entity pattern defined by the vehicle map model of the vehicle map service. The physical schema of the vehicle map model may use a physical address space to represent multiple entities of the vehicle map service. Uncertainty patterns of the uncertainty model may use an uncertainty address space to represent a plurality of uncertainties associated with a plurality of entities. The uncertain address space may be separate from the physical address space. The uncertainty represented in the uncertainty address space may point to one or more entities represented in the entity address space and/or entities within the associated entity address space.
Systems and methods are described that provide a measure of uncertainty of a map entity, such as features provided in association with a vehicle map service. In an example embodiment, the data indicative of the measure of uncertainty may be overlaid in a map layer separate from the one or more map layers containing the underlying data to which the uncertainty measure is applied. In some cases, the uncertainty measure may be provided separately from the data to which the uncertainty applies. According to some embodiments, uncertainty information may be defined using relative coordinates that are not necessarily tied to a real-world coordinate system. In some examples, the relative coordinates may be relative to a plurality of map entities (also referred to as map elements or map features). A first entity may define local relative coordinates to describe the relative uncertainty of another entity with respect to the first entity. This allows providing multiple uncertainty measures for a single map entity, each with a different reference point.
The first map entity may define a first uncertainty for the reference map entity using local coordinates relative to the first map entity, and the second map entity may define a second uncertainty for the reference map entity using local coordinates relative to the second map entity. The multiple uncertainty relationships may come from different sources (e.g., camera, GPS, LIDAR, etc.), at different times, with respect to different base features, or any combination of these. The described method recognizes that a so-called global uncertainty can be characterized as a relative uncertainty to earth. As one specific example, the distance between lane lines of a road may be referred to as a low level of uncertainty even though the location of each lane line in absolute space may have a high level of uncertainty. A measure of uncertainty about the distance between lane lines may be provided. Another uncertainty measure may be provided with respect to the position of each lane line in space. Furthermore, a static object having a known position in space relative to another feature may be difficult to identify with high accuracy relative to absolute space (e.g., as described by GPS). For example, the GPS coordinates of certain features typically have only a meter-level accuracy represented by latitude and longitude coordinates, while the same features may have centimeter-level accuracy positions relative to each other from sensors (e.g., cameras) that can be seen from a close distance. The relative coordinates with respect to other objects may be used to provide a measure of uncertainty for the static object, such that multiple measures of uncertainty can be provided for the static object. In addition, an absolute measure of uncertainty may be provided.
By publishing the uncertainty information in a manner that separates the uncertainty data from the underlying map data, the device may digest and combine the uncertainty information to determine more accurate information about the location, status, etc. of the object. In addition, because uncertainty is separated from the data itself, the client system may choose to consider any or all of the associated uncertainty measures according to its ability to process each particular uncertainty measure. Furthermore, the uncertainty pattern may evolve independently of the entity pattern. For example, a new error model may be added to the uncertainty pattern without having to force a client that modifies an existing pattern as with an embedded uncertainty model. Thus, for example, the uncertainty associated with a map entity may be defined separately from the map entity in a separate layer above a particular map schema. In this way, multiple uncertainties may be defined for map entities, clients may choose to ignore entities they do not know, relative uncertainties may be expressed, and uncertainty patterns may be extended independently of feature description patterns.
According to some aspects, the uncertainty model may be or otherwise include an external model of uncertainty patterns defining uncertainty relationships separate from entity patterns provided by the map model. An entity schema of a map model may represent an entity based on attributes of the entity on a map. For example, the map model may represent unique entities (also referred to as "best guess" entities) using entity patterns. The map model may then be considered to be or otherwise define an address space containing such basic entities.
According to an example embodiment, the plurality of entities associated with the vehicle map service may include a plurality of unique entities and a plurality of hypothetical entities. In this way, the basic entities in the address space of the map model can be divided into two groups. The first group may include a plurality of unique entities that are considered to be the current best estimates of existing objects that are unique among other unique entities, while the second group may include a plurality of hypothetical entities that cannot be guaranteed to be unique among other unique entities or hypothetical entities. According to some aspects, the physical address space of the vehicle map model may include a unique physical address space and a separate hypothetical physical address space.
In an example embodiment, the use of an external uncertainty model enables client devices interested only in unique entity maps to consider only unique entities, while client devices interested in all possible entities are assumed to consider the address spaces of both unique entities and assumed entities. In an example embodiment, the unique physical space may correspond to a converged physical layer of the vehicle map service model, while the hypothetical physical space may correspond to a set of non-converged intermediate layers of the vehicle map service model.
In accordance with some aspects of the disclosed technology, the uncertainty pattern of the uncertainty model may be or otherwise include a separate address space of uncertainty relationships. The individual address spaces of the uncertainty pattern may point to entities in a unique physical address space of a unique entity or entities in a hypothetical physical address space of a hypothetical entity. Additionally or alternatively, the uncertainty pattern may associate entities within the unique physical address space or the hypothetical physical address space, and associate entities between the unique physical address space and the hypothetical physical address space.
According to an example embodiment, the uncertainty may be associated with an attribute of a single entity. In this case, one or more external uncertainty relationships may point to attributes of the entity that describe an error function on or between the attributes of the entity. In other examples, the uncertainty may be associated with attributes of multiple entities. In yet another example, the uncertainty relationship may model a joint presence relationship between hypotheses in addition to a joint probability model of the associated parameters.
According to an example embodiment, the uncertainty relationship may have a context. The context can include a unique Identification (ID) space attached to the relationship to indicate where the relationship came from. For example, if two relationships have the same contextual ID, they may be indicated to be from the same source (e.g., the same image, the same scan, the same vehicle location, etc.). The context can also be used to associate confidence levels with the source of the relationship.
In accordance with some aspects of the disclosed technology, uncertainty patterns of the uncertainty model may define relationship patterns. For example, pose relationships, clustering (also referred to as confidence) relationships, and/or mutual exclusion relationships may be defined as part of the uncertainty pattern to associate entities within the entity pattern map model. Other types of relationships may be defined as part of a relationship schema.
According to example embodiments of the present disclosure, the pose relationships may be defined as part of a relationship pattern of the uncertainty model. The gestural relationship can include a plurality of entity references that reference a plurality of entities of the map model. For example, a gestural relationship can include a reference to a base entity and a reference to a counter entity. The basic entity may remain unchanged. For example, in an example embodiment, the base entity may establish the origin of the local coordinate system. The basic entity may be another entity in the map model, which may be, for example, a vehicle position for relative measurement of the vehicle. As another example, the underlying entity may be the earth, for example, which bases uncertainty on earth-centered earth-fixed (ECEF) coordinates. The opposing entity may have a pose that is indeterminate relative to the underlying entity. In an example embodiment, the pose relationship may also contain the pose model itself, such as a gaussian pose model (e.g., the mean and variance of all coordinate values). The pose relationships may additionally or alternatively include a velocity model. The velocity model may model the velocity vector and/or tensor of the opposing entity relative to the underlying entity.
According to example embodiments of the present disclosure, clustering relationships or confidence relationships may be defined as part of an uncertainty pattern of an uncertainty model. Clustering relationships may address common cases of hypothetical clusters with presence and/or attribute states for a particular real-world entity. If relative weights are known, the clustering relationships may reference two or more hypotheses treated as the same entity, and a weight may potentially be assigned to each hypothesis. Such relationships may include implicit "null hypotheses," i.e., where none of the specific hypotheses referenced are correct.
According to an example embodiment of the present disclosure, a mutual exclusion relationship may be defined as part of an uncertainty pattern of an uncertainty model. Mutually exclusive relationships may be associated with multiple hypothetical entities. A mutually exclusive relationship may reference two or more hypothetical entities and indicate that the two or more hypothetical entities are not the same real-world entity. In some examples, the mutually exclusive relationship may assert negation. For example, a mutually exclusive relationship may indicate a hypothesis that two or more hypothetical entities cannot be the same real-world entity. In some examples, mutually exclusive relationships may be used to associate observations of similar types (e.g., signs, vehicles, etc.) made from the same image and thus considered to be different real entities. In some cases, clustering relationships between entities may fundamentally indicate that multiple hypotheses are for the same real-world entity. Rather, mutually exclusive relationships may fundamentally indicate that multiple hypotheses are for different entities. In some examples, the mutually exclusive relationship may explicitly represent a constraint implied by the sharing context. In an example embodiment, when the confidence relationship indicates that the hypotheses are for the same real-world entity, the mutual exclusion relationship may indicate that the hypotheses are for different entities. In an example embodiment, the intent of the mutually exclusive relationship may explicitly represent one of the constraints implied by the sharing context. For example, all landmark observations taken from a single image may be associated with mutually exclusive relationships, as they may not represent the same real-world landmark.
Embodiments of the disclosed technology provide a number of technical effects and benefits, particularly in the areas of geographic information services for mapping, local sensor-based vehicle mapping, and integration of geographic information with local vehicle observations. In addition, one or more aspects of the disclosed technology may address problems that may arise in seeking to provide a practical system and method for merging locally obtained sensor data and observations therefrom into an existing map that includes a fused sub-map to obtain a comprehensive and useful map. Such maps may be used for autonomous driving, semi-autonomous driving, and/or for various driver assistance systems, such as breakage assistance systems, blind spot detection systems, speed management systems, and the like.
Uncertainty models according to example embodiments of the disclosed technology can provide uncertainty representations of individual observations in a schema at a level of detail such that the acquirers' knowledge of the observations can be reasonably extracted from the content of the observations. For example, rather than simply storing the sensor model "X" for observation (e.g., detection of an object), the system may directly apply the known error features of the sensor model "X" to the raw observations directly, and generate generic observations using joint probability models on the attribute values representing these features. Additionally, in example embodiments unrefined and/or inconsistent observations (treating the complete map as a set of consistent observations) can be meaningfully combined into a more refined, more consistent set of observations (relying on recursive application of this process to steadily advance toward and maintain a fully refined and consistent map). By constructing the uncertainty model in this manner, a more reliable and up-to-date map may be provided for vehicle map services or other applications.
According to example embodiments of the disclosed technology, the use of an uncertainty model separate from the base map model may enable the addition of new uncertainty models to the uncertainty pattern as the uncertainty pattern evolves. In this way, the vehicle map service may provide some concepts of generally useful uncertainty relationships (e.g., joint gaussian envelopes between poses), and may add more complex special purpose relationships to uncertainty patterns where greater accuracy may be required. In this way, the vehicle map service agreement may be able to add additional models over time to provide further improvements without having to redesign the system.
Using an uncertainty model separate from the base map model may additionally provide an uncertainty pattern that is independent of the base entity pattern. For example, some clients receiving map data from a vehicle map service may want to know a full uncertainty model for each aspect of the map. In contrast, other clients may not want to know the full uncertainty model for each aspect of the map. For example, some clients may want a current, completely coherent, unique entity map that represents the highest probability projection of an uncertain map onto a self-consistent map without any uncertainty at all. However, other clients may want to receive uncertainty information as map data from the vehicle map service. Such personal clients may ingest certain types of uncertainty information. For example, some client devices may only ingest the highest likelihood hypothesis for the location of the vehicle for which the map is generated, but may still want an error envelope around the single highest likelihood hypothesis. In fact, some applications may not be able to cope with or merge every possible uncertainty quality function between every possible hypothesis attribute value for every possible hypothesis entity. While the vehicle map service may maintain this data in a map database, some clients may choose to only ingest a subset of the data at any given time.
In an example embodiment, a vehicle map model and a separate uncertainty model may provide version control and update history for a vehicle map service. For example, a particular client device may understand certain versions of certain types of relationships, but not others. By separating the uncertainty model from the map model, customers can ignore any relationships they do not understand. In this way, in the event that map data is generated with newer version relationships and the old client is not updated to understand those relationships, the old client device can understand the base map without adding uncertainty information. Additionally and/or alternatively, a trapdoor (trapdoor) may be provided if the current set of modeling relationships does not form well. The current set of modeled relationships may not be used and new relationships may be defined without corrupting older or newer clients.
According to an example embodiment of the present disclosure, a simple and scalable solution for modeling uncertainty is provided. In an example embodiment, the uncertainty model may not be annoying to simple clients that do not wish to or choose not to receive or otherwise understand the uncertainty information. For example, a basic map entity or entity record may not be plagued by a large number of uncertainty modeling fields that must be filtered or ignored for a simple map data provider or user. This may enable clients to ignore (and possibly even not load) portions that they do not know or select to receive. Such an approach may improve the operational efficiency of the vehicle map service, including reducing the computing resource usage of various computing devices within the vehicle map service.
In some examples, the uncertainty model may be scaled without corrupting the base map model or changing the entity pattern. For example, when an uncertainty relationship is added, the size of existing records in the map model may not continue to increase. Further, the uncertainty model can evolve over time without corrupting the underlying map model or changing the entity pattern. For example, if a relationship or model is disfavored for use, the underlying objects of the map model may not become unsuitable for use with fields that are disfavored for use, nor the uncertainty model itself may become unsuitable for those fields.
According to some example embodiments, the uncertainty model can represent relative accuracy and absolute accuracy. In some cases, the uncertainty model may consider all error relationships to be relative. For example, the uncertainty model may consider what may be referred to as absolute accuracy to be relative accuracy with respect to the earth itself as the map entity. Thus, the uncertainty model may be a relative model with some specifically defined entities. For example, a specifically defined entity may include the earth, a particular vehicle pose at a particular time, or a state plane origin of coordinates at a particular geographic location (e.g., state).
In an example embodiment, the relative accuracy may provide an improvement to the idea of the absolute position of a feature in earth coordinate space. The idea of absolute position may be problematic in situations where high accuracy is required due to, for example, natural forces. Many situations may introduce error terms such as plate motion, tidal motion, thermal expansion of bridge and road materials, etc. Thus, example embodiments may provide local relative accuracy.
The use of an uncertainty model separate from a base map model may improve the safety of operating a vehicle (e.g., an autonomous, semi-autonomous, and/or manually driven vehicle) by providing a consistent and accurate map based on integration of observations from multiple sources in a safe manner. An indication of uncertainty may be provided such that a client system receiving map data based on a map model may utilize uncertainty in performing vehicle-level operations.
Referring now to the drawings, example aspects of the disclosure will be disclosed in greater detail. FIG. 1 depicts an example computing environment 100 in which a vehicle map service according to an example embodiment of the present disclosure may be implemented. Example computing environment 100 is one example of a system that may be used to perform operations associated with geographic information in accordance with example embodiments of the present disclosure. As shown in fig. 1, the example computing environment 100 may include a network 102, a vehicle 110, vehicle map service data 112, a vehicle map service data service 113, a vehicle map service system 114, one or more vehicle map service clients 115, one or more vehicle systems 116, one or more base map (basemap) service systems 118, a remote map service system 120, a map information service 121, vehicle map service data 122, map data 124, sensor data 126, uncertainty data 128, a remote vehicle service system 130, a vehicle information service 131, vehicle map service data 132, map data 134, sensor data 136, and uncertainty data 138.
Vehicle 110 may include any device for carrying or transporting personnel or cargo, including an automobile, a bus, a freight truck, an aircraft (e.g., an airplane and/or helicopter), and/or a watercraft (e.g., a boat or a submersible vehicle). The vehicle 110 may include one or more computing systems (e.g., a computing system including one or more computing devices, at least one of which includes one or more processors and one or more memory devices including tangible, non-transitory computer-readable media) including a vehicle map service system 114 that may perform one or more actions or operations, including sending, receiving, processing, generating, and/or storing data (e.g., vehicle map service data).
The vehicle map service system 114 may communicate (e.g., send or receive one or more signals or data) with one or more client systems, including: one or more vehicle systems 116 (e.g., a navigation system that can receive vehicle map service data and output local maps via a graphical user interface displayed on a display device); and/or a vehicle map service client 115 that may subscribe to and/or publish vehicle map service data. Further, the vehicle map service system 114 may include a vehicle map service data service 113, and the vehicle map service data service 113 may be configured to manage and provide information associated with the vehicle 110 to clients and/or other subscribing entities. The vehicle map service system 114 may also manage, transmit, and/or receive information associated with one or more base map service systems 118, which base map service systems 118 may include one or more computing devices and/or software applications that may perform one or more actions and/or operations related to providing a base map (e.g., a base map of an area through which a vehicle passes).
Further, the vehicle map service system 114 may activate and/or communicate with one or more vehicle map service clients 115 and/or one or more vehicle systems 116 of the vehicle 110 to perform vehicle-related functions. For example, the vehicle map service system 114 may send one or more signals or data used by the vehicle control system to cause the vehicle steering system to change the position of the wheels of the vehicle 110 and change the direction of travel of the vehicle 110.
The vehicle client system may include various systems of the vehicle 110 that may perform one or more operations or functions, including processing vehicle map service data including map data (e.g., one or more maps) associated with a state of a geographic area, sensor data associated with an environmental state external to the vehicle 110, and/or one or more machine learning model data associated with a machine learning model that may be used to detect and/or identify objects external to the vehicle 110. Further, client systems (e.g., vehicle map service client 115 and/or one or more vehicle systems 116) may include one or more display devices (e.g., an LCD monitor) that may be used to output information including information associated with vehicle map service data and/or vehicle map service system 114. Further, the vehicle client system may include one or more input devices (e.g., a touch screen, a keyboard, and/or a microphone) that may be used to input information for use by the vehicle map service system 114.
The vehicle 110, the vehicle map service system 114, the remote map service system 120, and/or the remote vehicle service system 130 may communicate (e.g., transmit and/or receive one or more signals or data including vehicle map service data) via the network 102. Network 102 may include any type of communication network, including a local area network (e.g., an intranet), a wide area network (e.g., the internet), a cellular network, or some combination thereof. Additionally, the network 102 may also include one or more direct connections that may be used for direct communications between the vehicle 110, the vehicle map service system 114, the remote map service system 120, and/or the remote vehicle service system 130. Communications may be carried over network 102 using any type of wired and/or wireless connection, using various communication protocols (e.g., TCP/IP, HTTP, SMTP, and/or FTP), encoding or formatting (e.g., HTML or XML), and/or protection schemes (e.g., VPN, secure HTTP, or SSL).
The remote map service system 120 (e.g., a geographic information system provider) may include one or more computing systems (e.g., a computing system including one or more computing devices, at least one of which includes one or more processors and one or more memory devices (including tangible, non-transitory computer-readable media) that may perform one or more actions or operations, including sending, receiving, processing, generating, and/or storing data (e.g., vehicle map service data).
The remote map service system 120 may store and/or perform operations on vehicle map service data 122, which vehicle map service data 122 may include map data 124, sensor data 126, and/or uncertainty data 128. The remote map service system 120 may include a map information service 121 configured to manage and provide map information to clients or other subscribing entities. Map data 124 may be associated with and/or include geographic data that includes one or more maps indexed according to geographic coordinates (e.g., latitude, longitude, and/or altitude) of their constituent elements (e.g., locations). The map data associated with the remote map service system 120 may also include route data, geographic images, and/or data associated with various waypoints (e.g., addresses and/or geographic coordinates).
Sensor data 126 may include data associated with one or more sensor outputs of vehicle 110. For example, the sensor data may include one or more outputs from one or more LIDAR devices, one or more cameras, one or more microphones, one or more sonar devices, and/or one or more radar devices. The machine learning model data (not shown) may include one or more machine learning models or training data associated with one or more machine learning models that may be used by the vehicle 110 to detect and/or identify environmental conditions external to the vehicle 110. For example, the machine learning model data may include a plurality of machine learning models that may be used by the vehicle map service system 114 to detect and/or identify one or more objects, scenes, and/or events. Further, the machine learning model data may include live-collected data (e.g., image data, radar data, sonar data, LIDAR point cloud data, and/or audio data) associated with sensor observations from one or more sensors (e.g., one or more cameras, one or more radar devices, one or more sonar devices, one or more microphones, and/or one or more LIDAR devices). In some embodiments, the remote map service system 120 may communicate directly with the vehicle 110, the vehicle map service system 114, and/or the remote vehicle service system 130.
The remote vehicle service system 130 may store and/or perform operations on vehicle map service data 132, the vehicle map service data 132 may include map data 134, sensor data 136, and/or sensor data 136. The remote vehicle service system 130 may include a vehicle information service 131, the vehicle information service 131 configured to manage and provide vehicle information to clients or other subscribing entities. Map data 134 may be associated with and/or include geographic data that includes one or more maps indexed according to geographic coordinates (e.g., latitude, longitude, and/or altitude) of their constituent elements (e.g., locations). The map data associated with the remote vehicle service system 130 may also include route data, geographic images, and/or data associated with various waypoints (e.g., addresses and/or geographic coordinates).
Sensor data 136 may include data associated with one or more sensor outputs of vehicle 110. For example, the sensor data may include one or more outputs from one or more LIDAR devices, one or more cameras, one or more microphones, one or more sonar devices, and/or one or more radar devices. In some embodiments, the remote vehicle service system 130 may communicate directly with the vehicle 110, the vehicle map service system 114, and/or the remote map service system 120.
Uncertainty data 128 and/or uncertainty data 138 may include, for example, uncertainty measures provided for any entity or observation, such as road signs, vehicles, pedestrians, objects, and so forth. The signature may be statistically modeled and is one example of a feature that may be acquired from a vehicle mapping service view from a source (e.g., a sensor view from a sensor). For example, the pose error of the markers may be modeled. For example, the base model of the posing error may be a joint Gaussian model with joint probabilities on coordinates. The error envelope may be defined relative to a particular vehicle pose or in its context. For example, the confidence with which the marker exists may be modeled. Additionally or alternatively, the confidence of the meaning/transcription/qualifier of the token may be modeled.
Vehicle 110 may include software and/or data including vehicle services, which may include mapping applications and services, which may be arranged in a stack from a high level to a low level. The vehicle service may include: a service providing a user-oriented map application; mobile services utilizing mobile APIs and/or frameworks (e.g., Maps APIs); data services, including framework-level management of data caches containing maps and/or other data, and communication with other devices or systems via a network (e.g., network 102) and/or interconnections in vehicle 110. Further, the vehicle services may include an embedded version of the vehicle services that may be employed by the vehicle that is otherwise incompatible with the vehicle map service data. Vehicle 110 may also include a real-time operating system that may manage systems closer to the hardware of vehicle 110.
The remote map service system 120 may include various software and/or services. The remote map service system 120 may include map data including semantic map data and traffic data. The remote vehicle service system 130 may include any service maintained by a vehicle service provider (e.g., an automobile manufacturer or an automobile service provider). Further, the remote vehicle service system may utilize a distributed computing platform (e.g., a cloud platform) to provide vehicle services. In some embodiments, the remote vehicle service system 130 may include a local copy of the map maintained by the remote map service system 120. Further, in some embodiments, various other computing systems may interact directly with the vehicle 110, the remote map service system 120, and/or the remote vehicle service system 130.
The remote map service system 120 and the vehicle 110 may transmit and/or receive data including: map data updates to vehicle 110, which may include map data and traffic data synchronized to local memory and cache by vehicle services. Some of the map data transmitted and/or received by the remote map service system 120 and the vehicle 110 may be communicated to the real-time operating system of the vehicle 110 as part of the vehicle internal protocol. Further, the remote map service system 120 and the vehicle 110 may transmit and/or receive data from the vehicle 110 including sensor observations, which may be communicated from the real-time operating system to the remote map service system 120 via vehicle internal protocols. The sensor observations may include a local map representation of the environment detected by the vehicle 110. The local map may include objects and/or markers that are observed by the sensors of the vehicle and may be provided in a format that matches the format of the data provided to the remote map service system 120 or the vehicle 110. In some embodiments, the sensor observations may include deltas (e.g., differences or changes in state or value) from previously provided data including anomalies and new observations. Further, the remote map service system 120 and the vehicle 110 may transmit and/or receive data including track information, which may include information associated with the location and route tracking of the vehicle (in some embodiments, location data communicated from the vehicle 110 to the remote vehicle service system 130). The location contained in the location data may include raw location data (GPS) and/or map-matching data related to maps and routes known to vehicle 110 (e.g., progress along a current road, lane, or route). The service data transmitted and/or received between the remote map service system 120 and the remote vehicle service system 130 may include navigation, which may include searches and directions.
The remote map service system 120 and the remote vehicle service system 130 transmit and/or receive data, including data provided through APIs including map APIs, and may include directions, locations, tiles, and/or roads. Further, the data flow between the remote map service system 120 and the remote vehicle service system 130 may include: updates that can be synchronized to the remote vehicle service system 130 for analysis; editing, which includes any corrections and/or additions to the vehicle map service data that the third party computing system may submit to the remote vehicle service system 130 based on analysis or their own feedback. Further, the remote map service system 120 may include a pipeline that can evaluate and receive those edits, and provide credits to third party services for quality improvement.
The remote vehicle service system 130 and the vehicle 110 may send and/or receive data associated with a service that may be used to transfer opaque data in both directions between the remote vehicle service system 130 and the vehicle 110, and may use networking in an operating system and the following data usage policies. Further, the remote vehicle service system 130 and the vehicle 110 may send and/or receive data including software updates and/or sensor data.
FIG. 2 depicts a schematic diagram including an example of vehicle map service data, according to an example embodiment of the present disclosure. One or more portions of the vehicle map service data 200 may be executed or implemented on one or more computing devices or computing systems, including, for example, the vehicle map service system 114, the remote map service system 120, and/or the remote vehicle service system 130. Also, one or more portions of the vehicle map service data 200 may be executed or implemented as algorithms on hardware components of the devices disclosed herein.
As shown in FIG. 2, the vehicle map service data 200 may include a message type 202, a layer ID204, a layer version 206, and a payload 208. The message type 202 may include one or more portions of data that may be used to identify a type of message associated with a portion of the vehicle map service data 300. For example, the message type 202 may indicate whether the vehicle map service data 200 is being used to: subscribing one or more portions of the vehicle map service data to a vehicle map service client system and/or a subscription status; publishing, by a vehicle map service client system, one or more portions of vehicle map service data 200 and/or a status associated with publishing one or more portions of vehicle map service data 200; and/or communicate (e.g., send or transmit) a portion of the vehicle map service data 200 to the vehicle map service client system. Further, the message type portion may indicate an intent or target associated with the layer (e.g., a target to subscribe, unsubscribe, or update data), for example, as a request to subscribe to the layer or an intent to send data about the layer. For messages for publication, the provider ID, layer and/or layer version may be provided with the payload so that the payload may be routed correctly.
The layer ID204 may include one or more portions of data that may be used to identify a layer associated with the vehicle map service data 300 and/or a source of the vehicle map service data 200 (e.g., a vehicle map service client system). For example, the layer ID204 may include information indicating that the vehicle map service data is associated with a road center line layer, and in this manner, a client system subscribing to the road center line layer may access the vehicle map service data 200.
The layer version 206 may include one or more portions of data that may be used to identify the layer version associated with the vehicle map service data 200. For example, the tier version may indicate whether the version of the vehicle map service data 200 is compatible with a vehicle map service client system that is attempting to access the vehicle map service data 200.
The payload 208 may include one or more portions of the vehicle map service data 200 being transmitted. Payload 208 may include any information associated with one or more signals or data including one or more maps, one or more sensor outputs, and/or one or more machine learning models. For example, payload 208 may include information associated with traffic conditions in an area currently traversed by a vehicle (e.g., vehicle 110).
FIG. 3 depicts a schematic diagram including an example of a vehicle map service data layer, according to an example embodiment of the present disclosure. One or more portions of the vehicle map service data 300 may be stored on one or more computing devices using any suitable memory. In an example embodiment, the vehicle map service data 300 may be implemented using a vehicle map service protocol and/or schema. In some examples, the vehicle map service data 300 may be executed or implemented on one or more computing devices or computing systems including, for example, the vehicle map service system 114, the remote map service system 120, and/or the remote vehicle service system 130. Further, one or more portions of the vehicle map service data 300 may be executed or implemented as algorithms on hardware components of the devices disclosed herein.
As shown in fig. 34, the vehicle map service data 300 includes a plurality of layers, examples of which may include a local coordinate system layer 302, a vehicle location layer 304, a road center line layer 406, a road layer 308, a lane layer 310, a plane layer 312, a road attribute layer 314, a lane attribute layer 316, a sign layer 318, a physical lane element layer 320, a traffic control device layer 322, a parking attribute layer 324, a landmark layer 326, a real-time speed layer (live speed layer)328, a danger layer 330, and/or a real-time parking layer (live parking layer) 332.
The multiple layers in the vehicle map service data 300 may be accessed by one or more computing systems and/or one or more computing devices including the vehicle map service system 114, the remote map service system 120, and/or the remote vehicle service system 130. Further, each of the plurality of layers may be associated with information including a message type (e.g., message type 202 in fig. 2), a layer ID (e.g., layer ID204 in fig. 3), and a layer version (e.g., layer version 206 in fig. 2).
Further, multiple service systems (e.g., the vehicle map service system 114, the remote map service system 120, and/or the remote vehicle service system 130) may selectively subscribe to different layers (e.g., layers that include vehicle map service data to be used by the respective vehicle map service client systems) and ignore layers that do not contain the required information. The service system may also publish vehicle map service data associated with the layer. The published layers may then be used by other service systems subscribing to the respective layer.
Vehicle map service protocols may be used to implement vehicle map data. The vehicle map service agreement may include a shared featureless base model of the world (e.g., a base map) and a local coordinate system that may be used as a reference. The vehicle map service protocol may include data layers (which may be stacked on top of other data layers) and may be used to form a world model. Various clients (e.g., client systems and/or service systems) may be subscribed to certain layers (e.g., layers of interest) and may ignore certain other layers that include information that is not of interest. These layers may include pre-mapped data (e.g., maps based on previously collected satellite images) and dynamic sensor observations from various data sources (e.g., client systems including vehicle systems; and/or various remote computing systems including remote map service systems and/or remote vehicle service systems) that may share a common reference system around the vehicle (e.g., different data sources concentrated in the same geographic area around the vehicle).
Each layer of the map may include data associated with various types of entities and attributes of the entities. The layers may represent data flowing between multiple service systems, including data flowing between a remote map service system (e.g., a geographic information system service provider (GIS) running on a computing system) and a vehicle (e.g., a vehicle including one or more vehicle client systems), between a remote map service system and a remote vehicle service system (e.g., a vehicle service provider providing services to a vehicle), and between a remote vehicle service system and a vehicle.
The data of each layer may be distributed in the form of a packet of a predetermined type. The pattern of these packets may be versioned such that the data packets for version X of layer a are protocol messages. New versions of layer packets may evolve over time. In one implementation, once a version is released, modifications to the version may be limited or restricted.
In some embodiments, the layers may operate independently, and the layers may also cross-reference each other. Further, the multiple layers may include a common local coordinate system definition. If an object is described in multiple layers within a consistent time period, for example if the attributes and geometry layers of a given road segment, they may reference the object using a shared object ID. For example, the object ID may include an identifier for identifying the object.
In some embodiments, the layers may be ordered by complexity. This may provide forward compatibility. For example, earlier layers may represent simple and common scenarios that current maps and vehicles may already implement. Subsequent layers may then be added, which may be related to updated data, different data, or higher level data forms, as the requisite new map data and/or new vehicle technologies become available (e.g., new versions of data and/or different data protocols).
A portion (e.g., a packet) of the vehicle map service data may include a message type portion, a layer ID portion, a layer version portion, and a payload portion. The message type section may indicate the type of data that may be used to determine how to interpret the message content. For example, the message type may be associated with an API call type that the message is making. For messages for publication, the provider ID, layer and/or layer version may be provided with the payload so that the payload may be routed correctly. In addition, different message types may be used to add subscriptions, delete subscriptions, or provide information about the status of subscriptions. The payload of the message may also be associated with the message type. The layer ID portion may include an identifier for a particular layer. The layer version section may include an identifier of the version of the particular layer. The payload may include data transmitted for a particular layer (e.g., sensor data associated with one or more sensor observations of the vehicle).
The local coordinate system layer may include data and/or information associated with a coordinate system (e.g., x, y, and z coordinates corresponding to latitude, longitude, and altitude, respectively) that includes a current coordinate system used by the vehicle. The local coordinate system layer may be used to convert any local geometry and/or set of locations to a global coordinate system (e.g., a coordinate system used to describe locations on earth) or to convert a global coordinate system to a local geometry and/or set of locations.
The vehicle location layer may include data and/or information associated with a self-consistent description of the vehicle's instantaneous location (e.g., the vehicle's location at the current time). The location may be associated with aspects including a physical location of the vehicle (e.g., pose, absolute speed, and/or acceleration on a world or local coordinate system) or a semantic location of the vehicle (e.g., which road segment the vehicle is currently on and where the vehicle is on the road segment, a scalar speed along the road segment, and/or a lane in which the vehicle is located). The vehicle location layer may include atomic information (i.e., sensor data, including raw sensor measurements from one or more sensors of the vehicle) or fused/derived information (e.g., map matching including vehicle location on a map and/or fused locations of vehicles based on multiple sources) that is dependent on a remote data source (e.g., a map provider) that generates data associated with the vehicle location layer (e.g., a location packet).
While the vehicle location layer may be a substrate on which location information for the current vehicle is broadcast, observations and information regarding the presence and location of other vehicles may also be included on the vehicle location layer. The vehicle location layer grouping may describe the view of the current vehicle or other vehicles by referencing different object identifiers (e.g., object IDs), allowing the vehicle location layer to generalize to the status of vehicles in the area that includes the current vehicle. Other clients may add (e.g., publish) locations of other vehicles derived from vehicle sensors, vehicle to vehicle, and/or vehicle to infrastructure clients associated with the vehicle.
The centerline geometry of the road centerline layer may be used as a reference to compare the location of the object to the road (e.g., for map matching the vehicle location). The (x, y) sequence may be used to learn the curvature of the road to predict an upcoming turn.
The road map layer may be extended on the road centerline layer by associating each road segment with a description of the connectivity of that road segment with adjacent road segments. This information may be combined with a road center line layer to create a complete view of the road map in the area around the vehicle.
The lane map layer may be used to describe the lane configuration for each road segment and to subdivide the roadmap into lanes and lane connections. The lane layer may focus on the logical map of the lane network, and may describe lane attributes or physical geometry in subsequent layers.
The planning layer may be used to annotate local road and lane maps according to a current plan or route. The planning layer may cause the vehicle to determine a forward road or lane to be followed by the current navigation route.
The road attribute layer may be used to describe the relatively static attributes of the road segment. These attributes may be derived from road segment attributes in a database associated with a remote map service system (e.g., a GIS service provider system), and may be focused on attributes for vehicle perception and safety or on attributes for navigation or presentation.
The lane attribute layer may include data and/or information associated with lane specific attributes, for example, as an additional level of detail to the road attribute layer. The attributes of the lane attribute layer may be based on lane attributes in a remote map service system (e.g., a geographic information system service provider database).
The marker layer may include data and/or information associated with physical markers visible from the road segment, including marker type, content, and three-dimensional location information. For example, the signs may include speed limit signs observed while traveling on a road, including speed limit text on the signs. Signs may be classified into sign types including speed limit or road name. In some embodiments, the signs may be selectively modeled with priority given to describing driving-related signs (including those that define traffic regulations). Further, the three-dimensional position of the lane, road segment, and/or vehicle may be an absolute position or a relative position (e.g., relative to the lane or road segment). The relative position may include cartesian coordinates (e.g., { x, y, z } offset from the lane or road segment) or parameters (e.g., distance along the lane or road segment, distance across the track to the left or right side of the lane or road segment, or height above or below the lane or road segment).
The physical lane element layer may describe physical attributes of the lane. Furthermore, the road geometry layer may be used as a supplementary and optional layer in addition to the semantic lane map and attributes. Previous semantic lane data may be used when looking for lane information for route planning, guidance, or lane-level traffic. Physical lane elements may be used to assist in lane recognition and more tactical decisions.
The traffic control device layer may be used to describe the location, attributes, and status of traffic control devices, including traffic lights and/or stop signs. The traffic control device layer may include an indication (e.g., operational, non-operational, or faulty) of an operational status for the traffic control device.
The parking attribute layer may describe parking attributes for the road, including locations of attractions, whether the parking location is public or private, whether the parking is related to payment, or parking rules. In some implementations, real-time parking availability may be provided.
The landmark layer may be used to describe landmarks that are visible from the road and may include a three-dimensional position of each landmark. Further, a landmark layer may be used for positioning. The attributes of the landmark layer include: a location that includes coordinates (e.g., x, y, z, i.e., coordinates corresponding to latitude, longitude, and altitude) that can be used to determine the location of the landmark; and visibility, which can be used to determine a distance at which a landmark is visible based on a vantage point (e.g., a vantage point of a vehicle at a particular location). The real-time speed layer may be used to annotate roads and lanes with real-time speed estimates derived from objects including other vehicles or other reference points. The properties of the real-time speed layer may include: a location attribute comprising coordinates (e.g., x, y, z, which corresponds to latitude, longitude, and altitude) that may be used to determine a location, the coordinates comprising a location of one or more vehicles on a road and a lane; a speed attribute, which may be expressed as a rate of movement of the vehicle on roads and lanes, and which may be associated with a vehicle position at a particular location (e.g., speed in kilometers per hour of vehicle at location x, y, z); and a time including a time associated with the real-time velocity tier update (e.g., a time associated with a particular velocity of the vehicle in kilometers per hour at a particular location).
The danger layer may include data and/or information associated with annotations of roads and lanes having traffic accidents, dangers, and/or obstacles. For example, hazards may include areas being constructed, natural disasters (e.g., flood, fire, heavy rain, and/or heavy snow), and other potentially harmful events that may impede or delay vehicle movement.
The real-time parking layer may be associated with annotations of roads and/or parking lots that include information regarding real-time parking availability (e.g., parking availability at the current time). Further, the real-time parking layer may be updated in real-time (e.g., the vehicle may receive a continuous data stream regarding parking availability from one or more remote data sources, including other vehicles, remote geographic information service providers). The vehicle map service data may include sensor data associated with one or more sensor outputs from one or more sensors. The one or more sensor outputs from the one or more sensors may include information associated with one or more states of one or more areas (e.g., geographic areas) detected by the one or more sensors. In some embodiments, the one or more sensors may include one or more image sensors (e.g., one or more cameras), one or more acoustic sensors (e.g., one or more microphones), one or more light detection and ranging devices (e.g., LIDAR devices), one or more infrared sensors, radar, sonar, one or more thermal sensors, and/or one or more radar devices. Further, one or more sensors may be configured to detect a status (e.g., physical status) of one or more geographic regions that includes one or more attributes of the one or more geographic regions. The vehicle map service system may also associate the one or more sensor outputs with a time at which the one or more sensor outputs were received. The one or more attributes of the one or more geographic areas may include one or more (e.g., time of day, geographic location (e.g., latitude, longitude, and altitude), size (e.g., altitude, length, and/or width), mass, volume, color), and one or more semantic attributes (e.g., semantic information related to road markings, road signs, road segments, and/or intersections) that may be determined by the vehicle map service computing system based at least in part on the one or more sensor outputs.
For example, a vehicle map service system may include: a vehicle having sensors (e.g., three cameras) that issue sign information (e.g., three cameras reporting different portions from a set of signs on a highway); a remote map service system (e.g., a map data provider) that publishes what signs are expected; and a token fuser client that uses data from the camera and the remote map service system and publishes fused token information. In this way, a vehicle map service client system that consumes logo information may subscribe to logo messages, receive messages from various sources, and may determine logo messages to use and how to resolve conflicts.
In some embodiments, the vehicle map service data may be formatted according to a vehicle map service protocol. In addition, new fields may be added to the layer protocol for identifying the fusion layer. In addition, the layer protocol may include fields for a layer identifier, a layer version, and a fusion level. The fusion level field may identify a fusion level of the subscribed information.
Fig. 4 depicts an example of a service system according to an example embodiment of the present disclosure. Computing system 400 (e.g., a computing system comprising one or more computing devices, at least one of which comprises one or more processors and one or more memory devices comprising a tangible, non-transitory computer-readable medium) may perform one or more actions or operations including sending, receiving, processing, generating, and/or storing data (e.g., vehicle map service data) in accordance with example embodiments of the present disclosure. Further, one or more of the instructions executed or implemented on system 400 may be executed or implemented on one or more computing devices or computing systems, including, for example, vehicle map service system 114, remote map service system 120, and/or remote vehicle service system 130. Further, one or more of the ten instructions stored in the memory device may be executed or implemented as an algorithm on a hardware component of the device disclosed herein.
As shown in fig. 4, computing system 400 includes a vehicle map service system 410, a map base provider client system 412, a local coordinate system provider client system 414, a map base data collector 416, a dynamic data collector 418, a map service client system 422, a vehicle service client system 424, a navigation client system 426, and a fusion client system 428.
In some embodiments, the vehicle map service system 114 may include one or more data service client systems that may be used to bridge a local map in a vehicle (e.g., vehicle 110) with map data stored remotely (e.g., in a cloud computing system). One or more data service client systems may manage downloading and caching of base map data over a vehicle connection (e.g., WAN), dynamic distribution of local map data via VMS services, and capturing and uploading sensors and automated vehicle system observations for processing. These data service client systems may be used to determine the dynamic position of the vehicle, for example, converting local map data used by the vehicle into a frame of reference for the vehicle and publishing the data for the user by the service system.
The data service clients may include, for example, a floor plan provider client system 412, a local coordinate system provider client system 414, a floor plan data collector 416, and a dynamic data collector 418. The local coordinate system provider may provide a shared local rectangular coordinate system in the vicinity of the vehicle to simplify processing of the local map data. The data service client system may publish a continuously updated coordinated local reference frame for other client systems of the vehicle map service system.
In some embodiments, another remote map service system may manage local caching of map data provided by the geographic information system cloud computing system and download dynamic data input including traffic or dynamic local maps and incorporate it into the VMS core around the vehicle's current location, which may then be rebroadcast to the subscribed service systems.
The base graph data collector 416 can listen for VMS services for world changes observed by other service systems from locally published base graph data, buffering, or processing as needed, and can send to remote services for central integration when connectivity is available. The base map data collector 416 may be used to update a fairly static map by correcting for road properties and geometry. For example, if the map provider broadcasts an intersection of two output roads and the vehicle's driving engine rebroadcasts a sensor-fused map (which shows a third output road observed by the sensor), this service may compute the difference and store evidence of the new road segment for later upload to a remote map service system (e.g., a geographic information system cloud computing system).
In addition, the dynamic data collector 418 may receive dynamic observations (including location tracking and/or hazards/events) from other client systems of the vehicle map service system 114 and may ensure that these observations are shared with real-time services in a timely manner. In addition to current GPS-based location tracking, the dynamic data collector 418 may also receive map registration information derived from the fusion of sensors with the geographic information system service provider map, such as locations associated with identified roads or lanes.
Various clients of the vehicle map service system 410 may communicate with data service clients, including: map service client system 422, vehicle service client system 424, navigation client system 426, data fusion client system 428, and/or other client systems associated with other vehicle client systems (e.g., dashboard camera client systems). For example, vehicle service client system 424 may receive local map data related to vehicle safety, efficiency, and/or autonomy. The vehicle service client system 424, in turn, may use on-board recognition and reasoning to convert the sensor data to semantic map registration data, thereby providing map observations from the sensors. Vehicle services client system 424 may run on a separate real-time operating system and communicate with the vehicle operating system via the in-vehicle network.
The navigation client system 426 may communicate with various navigation applications, including other navigation client systems running on other remote map service systems. Data and/or information managed by the navigation application may annotate the local map according to the current route intent and may also provide enhanced location tracking and map matching support to improve turn guidance and route tracking.
FIG. 5 depicts a block diagram of an example computing environment 500 including a vehicle service system, according to an example embodiment of the present disclosure. The computing environment 500 may include one or more computing systems at a vehicle 502 and a remote map service system 504. The computing environment 500 includes an in-vehicle sensor and inference system 505, a navigation system 506, a base map data provider 510, a map data collector 512, a data aggregation and anonymization system 514, map data 516, a communications manager 518, a map provider 520, a local coordinate system provider 522, a dynamic data provider 524, a dynamic data service 526, traffic data 528, a local map cache 530, a Vehicle Map Service (VMS) data service 531, and a vehicle map service agreement 532.
The VMS data service 531 may manage data flow between clients by capturing data from a provider and rebroadcasting the data to subscribers using the vehicle map service protocol 532. The Vehicle Map Service (VMS) protocol may be a data protocol that allows for the construction and sharing of a dynamic model of a map around a vehicle (e.g., vehicle 502). The VMS protocol 532 can provide a common language and world model for map data providers and users, ranging from base maps and traffic providers to sensors and real-time operating systems of the vehicle 502.
The vehicle may include on-board sensors and inferencing systems 505 and a navigation system 506, and the vehicle may use the navigation system 506 to send or receive data including vehicle map service data. On-board sensor and inference system 505 may include one or more sensors (e.g., one or more LIDAR devices, cameras, sonar, and/or radar) that may be used to generate sensor data based on environmental conditions external to vehicle 502. The on-board sensor and inference system 505 may also determine an environmental state external to the vehicle 502 based at least in part on the sensor data. The navigation system 506 may include one or more devices (e.g., a GPS system and/or proximity sensors) that may be used to determine a local or global position of the vehicle 502.
The base map data provider 510 may transmit and/or receive vehicle map service data to and/or from the vehicle 502. The vehicle map service data managed by the base map data provider 510 may include a local map of an area within a predetermined distance of the vehicle 502. The map provider may publish a dynamic map associated with the location of the vehicle 502, which may be subscribed to by a client system of the vehicle 502 (e.g., a vehicle system).
The map data collector 512 may listen for different changes in the area provided by other service systems (e.g., other vehicles) and may receive data associated with a change in the status of the area (e.g., a change in road segments or lane segments), which may be compared and stored for later use by the other service systems. Further, the map data collector 512 may send the data to a data aggregation and anonymization system 651414.
The data aggregation and anonymization system 514 may receive data from a plurality of vehicle map service clients including the map data collector 512. Further, the data aggregation and anonymization system 651414 may aggregate data received from various vehicle map service clients and remove personally identifying information from the vehicle map service data. In this way, the privacy of the service system may be enhanced.
The data from the data aggregation and anonymization system 614 may include map data 516, which may include anonymous information about a map of the area in which the vehicle 502 is located. The map data 516 may be used by the communication manager 518. The communication manager 518 may manage copying of map data from a remote system (e.g., a remote vehicle service system and/or a remote map service system) to a local system (e.g., a vehicle map service system) of the vehicle. For example, the communication manager 518 may include services associated with map data for a determined area (e.g., an area of interest) having been transmitted from a remote map service system to a client system (e.g., a vehicle) in communication with the remote map service system. Thus, the recipient of the map data does not lack the map data.
Data from the communication manager 518 can be sent to the map provider 520, and the map provider 520 can send map data to the local map cache 530 and receive map data from the local map cache 530. The local map cache 530 may include data associated with a local map of an area (e.g., the area in which the vehicle 502 is traveling). Further, the map provider 520 may send data to the map data provider 510, which may then be sent to the vehicle 502.
Local coordinate system provider 522 may transmit and/or receive data including vehicle map service data to vehicle 502 and may include vehicle map service data associated with a local cartesian coordinate system proximate to vehicle 502. The local coordinate system provider 522 may publish a continuously updated coordinated local reference system by using the rest of the system.
The dynamic data provider 524 may send and/or receive data including vehicle map service data associated with dynamic observations including location tracking, hazards, and/or traffic events (e.g., road closures). Additionally, the dynamic data provider 524 may exchange data with the dynamic data service 526, and the dynamic data service 526 may provide one or more services associated with the data provided to the dynamic data provider 524. In addition, the dynamic data providers 524 may exchange data including traffic data 528, which may include information associated with road conditions on one or more road segments (e.g., intersections, direction of flow of vehicles through lanes, traffic speed, traffic density, and/or traffic signal status on various roads).
In some embodiments, vehicle 502 may include on-board sensors and inference systems 505, navigation systems 506, map data providers 510522, map data collectors 512, map providers 520, local coordinate system providers 622, dynamic data providers 524, and local map caches 530. Further, in some embodiments, the remote map service system 504 may include a data aggregation and anonymization system 514, map data 516, a communications manager 518, a dynamic data service 526, and traffic data 528.
In alternative embodiments, the vehicle 502 and the remote map service system 504 may include different combinations of on-board sensors and inference systems 505, navigation systems 506, map data providers 510, map data collectors 512, data aggregation and anonymization systems 514, map data 516, communications managers 518, map providers 520, local coordinate frame providers 522, dynamic data providers 524, dynamic data services 526528, traffic data 628, and/or local map caches 530.
FIG. 6 depicts a block diagram of an example vehicle service system, according to an example embodiment of the disclosure. The computing system 650 includes a client system 652, a remote map service system 654, a vehicle map service system 656, fused data 658, and the client system 650.
Further, one or more sensors associated with client system 652 may generate one or more sensor outputs that may be received by vehicle map service system 906. For example, client system 652 may include a camera located in a front center portion of a vehicle (e.g., vehicle 110) that may generate sensor data including one or more images of a camera visible area. The one or more images may include an image of a road sign at the intersection. The client system 652 may then send the sensor data to a vehicle map service system 656, which may be a computing system located in the same vehicle as the client system 652. The vehicle map service system 656 may determine, based at least in part on the sensor data received from the client system 652, that the road sign at the intersection indicates the school district of the school that the area was recently open.
The remote map service system 654 may include a geographic information system service provider (e.g., the remote map service system 120) that may generate data (e.g., vehicle map service data) that may include one or more maps associated with an area in which a vehicle associated with the vehicle map service system 656 is present. Further, the remote map service system 654 may transmit vehicle map service data including one or more maps of the area to the vehicle map service system 656. The vehicle map service data transmitted from the remote map service system 654 may include data associated with a school built in the area based on satellite images received by the remote map service system 654 two weeks ago.
The vehicle map service system 656 may fuse sensor data received from the client system 652 and vehicle map service data received from the remote map service system 654 into vehicle map service data including fused data 658, which fused data 658 may include information associated with the sensor data (e.g., scholarly area information) from the client system 652 and the vehicle map service data including satellite images of the area from the remote map service system 654. Vehicle map service data including the fused data may be included in the fused data 658, which is transmitted to the client system 660, which client system 660 may be a remote computing device that may receive and/or distribute the vehicle map service data. In some embodiments, the vehicle map service system 656 may send the fused data 658 to the remote map service system 654, which remote map service system 654 may update its map with new information about the school zone indicated in the flag detected by the client system 652.
FIG. 7 depicts a flowchart describing an example method 700 of operating a vehicle map service system in accordance with an example embodiment of the present disclosure. One or more portions of method 700 may be performed or implemented on one or more computing devices or computing systems including, for example, vehicle map service system 114, remote map service system 120, and/or remote vehicle service system 130, and further, one or more portions of method 700 may be performed or implemented as algorithms on hardware devices or systems disclosed herein. For purposes of illustration and discussion, FIG. 7 depicts steps performed in a particular order. Those of ordinary skill in the art having access to the disclosure provided herein will appreciate that various steps of any of the methods disclosed herein may be adapted, modified, rearranged, omitted, and/or expanded without departing from the scope of the present disclosure.
At 702, the method 700 may include receiving vehicle map service data from at least one map service system. In some examples, vehicle map service data may be received from a plurality of client systems of a vehicle map service system associated with a vehicle. For example, vehicle map service data may be received from sensors, a tachograph, and the like. In some examples, vehicle map service data may be received from a plurality of service systems. For example, vehicle map service data may be received from a remote map service system, a remote client service system, and/or a vehicle map service system. The vehicle map service data may include information associated with a geographic area. For example, the vehicle map service system 114 may receive vehicle map service data via an internal interconnection of vehicle map service client systems or a communication network (e.g., a wireless or wired network including a LAN, WAN, or the internet), over which one or more signals (e.g., electronic signals) and/or data may be sent or received.
In some embodiments, the vehicle map service data may be in accordance with a vehicle map service agreement associated with sending and/or receiving information between a plurality of service systems. For example, a vehicle map service agreement may specify one or more data formats or data rules associated with vehicle map service data. Further, the vehicle map service agreement may specify a hierarchical scheme for the vehicle map service data that may be used to control access to various portions of the vehicle map service data.
In some embodiments, the vehicle map service data may include a plurality of map layers. Each of the multiple layers may be associated with one or more states, features, or characteristics of the geographic area. For example, different portions of the vehicle map service data associated with different aspects of the local map may be associated with different layers, including layers associated with signs, vehicle location, and/or road attributes.
In some embodiments, each of the one or more portions of the vehicle map service data may be associated with a confidence value, a probability envelope, and/or a probability distribution that indicates the accuracy of the respective portion of the vehicle map service data. For example, the confidence values may include numerical values, wherein a higher confidence value correlates to a higher accuracy of various portions of the vehicle map service data.
Further, in some embodiments, one or more states of a geographic area may be associated with a plurality of attributes including a location of the vehicle (e.g., a latitude, longitude, and/or altitude of the vehicle), one or more road segment locations, one or more lane locations, and/or one or more sign locations (e.g., a location of a sign and data associated with the sign type).
In some embodiments, the vehicle map service data may include information associated with one or more sensor outputs of multiple client systems (e.g., sensor outputs of one or more vehicle sensors from multiple client systems including camera outputs, microphone outputs, and/or tactile sensor outputs), one or more maps provided by multiple service systems (e.g., one or more maps of an area traveled by a vehicle), and/or one or more machine learning models provided by multiple service systems (e.g., one or more machine learning models trained to detect and/or identify one or more objects).
In some embodiments, the plurality of service systems may include one or more geographic information systems (e.g., remote map service system 120) and/or one or more vehicle service systems (e.g., vehicle map service systems). One or more geographic information systems may be associated with vehicle map service data that includes one or more maps (e.g., one or more maps that include an identification and location of road segments, lane markers, traffic signs, traffic signals, and/or indications of landmarks). One or more vehicle service systems may be associated with vehicle map service data that includes information associated with a plurality of client systems (e.g., status of client systems including navigation systems, in-vehicle graphical user interface systems, and/or vehicle communication systems).
Further, in some embodiments, receiving vehicle map service data may include receiving first vehicle map service data including one or more maps from one or more geographic information systems. Additionally, in some embodiments, receiving the vehicle map service data may include receiving second vehicle map service data from one or more vehicle map service systems, the second vehicle map service data including information associated with a plurality of client systems.
At 704, method 700 may include: a local map of a geographic area within the vehicle field of view associated with a distance from the vehicle is generated based at least in part on the vehicle map service data. In some embodiments, the vehicle field of view may be associated with a map of an area within a predetermined distance from the vehicle; a map of an area within a distance that the vehicle can reach within a predetermined time period; a map of an area within a predetermined distance or spatial relationship of a currently planned navigation path of the vehicle; and/or a map within a predetermined distance or spatial relationship of the alternate navigation path of the vehicle. For example, the vehicle map service system 114 may receive vehicle map service data, which may include one or more maps from the service system and one or more sensor outputs from different vehicle sensors associated with the client system. The multiple sensor outputs may be used to determine the position of the vehicle relative to landmarks, which may then be used with one or more maps to generate a local map, which may include features and aspects of different portions of the vehicle map service data.
In some embodiments, the local map may include a dynamic model of a geographic area surrounding the vehicle. The dynamic model may include a real-time location of the vehicle (e.g., vehicle 110) relative to one or more objects external to the vehicle. For example, the vehicle map service system 114 may generate a local map of an area that includes the current location of the vehicle and the current locations of other vehicles, cyclists and/or pedestrians around the vehicle. Further, the dynamic model may include real-time indications of road closures, hazards, construction areas, and other types of events that may occur in the area.
At 706, method 700 may include determining, for each client system (e.g., vehicle system) of a plurality of client systems, one or more portions of a local map to which each client system subscribes. For example, the vehicle map service system 114 may receive vehicle map service data including subscription data from a plurality of client systems. The subscription data may include information associated with one or more portions of the local map to which each of the plurality of client systems subscribes. The one or more portions of the local map subscribed to by each of the plurality of client systems may be based on information associated with a tier of the local map subscribed to by the client system. For example, a vehicle navigation system may subscribe to a layer of vehicle map service data associated with displaying a location of a vehicle and objects within two kilometers of the vehicle. Other client systems, such as dynamic data provider clients of a vehicle map service system, may subscribe to all layers.
At 708, method 700 may include determining a vehicle field of view based at least in part on a geographic location of the vehicle. The vehicle field of view may be associated with one or more portions of a local map provided to the vehicle client system. Further, the vehicle field of view may be associated with a quantity and/or rate of vehicle map service data provided to the plurality of client systems. For example, the vehicle map service system 114 may determine that the vehicle 110 is entering an area associated with a high level of signal interference or signal blockage, which will reduce the amount of vehicle map service data that the vehicle may receive from the remote service system. Prior to entering the area, the vehicle may expand the vehicle field of view so that the vehicle may use the stored vehicle map service data when new vehicle map service data is not available from the remote source.
At 710, method 700 may include sending one or more portions of the local map subscribed to by each client system to respective client systems of the plurality of client systems. For example, the vehicle map service system 114 may send one or more portions of the local map associated with the current traffic conditions to a client system that includes a route planning system. The route planning system may subscribe to one or more portions of vehicle map service data associated with traffic conditions (e.g., the location of roads in an area and/or the speed, location, and direction at which the vehicle is traveling in the same area), and may continuously receive vehicle map service data associated with traffic conditions in the area.
At 712, the method 700 may include generating a graphical user interface associated with the local map. The graphical user interface may display the local map using one or more symbols that include text or images (e.g., a combination of text or graphics that may display a representation of data including vehicle map service data to a user of the software application). The graphical user interface component may be generated on a computing device (e.g., an in-vehicle display device) having a physical interface that may receive input (e.g., touch input and/or voice input) from a user to view various portions of the representations of the local map and vehicle map service data. Further, the graphical user interface component may receive input (e.g., user input) to send, receive, generate, modify, and/or process data associated with the local map and/or vehicle map service data. For example, the vehicle map service system 114 may generate a graphical user interface that is displayed on a display device of the vehicle 110.
In an example embodiment, unrefined and/or inconsistent observations may be meaningfully combined into a set of more refined and consistent observations. For example, a complete map may be considered a collection of consistent observations that may be received from multiple sources, including multiple sensors of multiple vehicles, various base map sources, and any number of fused representations of entities defined in the map as representations of map features, sources, etc. In an example embodiment, recursive application of such a process may be used to steadily advance toward and maintain a fully refined and consistent map.
FIG. 8 depicts a block diagram that illustrates an example vehicle map service agreement 800, according to an example embodiment of the present disclosure. The vehicle map service agreement 800 may be implemented by any computing device described herein to provide vehicle map service data including map data and uncertainty data according to a vehicle map service. The vehicle map service agreement 800 includes a vehicle map model 802 and a separate uncertainty model 832. The vehicle map model 802 may include object records that hold averages or estimates (e.g., best estimates) of the entities 808 and their attributes, while the uncertainty model 832 provides an external model (e.g., external record) that includes an uncertainty relationship 838 that references the underlying object records of the vehicle map model 802. In some examples, the external record of the uncertainty model may effectively add a "blur" (fuzz), such as a variance term, to the average of the object records of the vehicle map model 802.
The vehicle map model 802 includes a physical schema 804, the physical schema 804 including a physical address space 806. An individual uncertainty model 832 includes an uncertainty pattern 834, the uncertainty pattern 834 comprising an uncertainty address space 836. In this manner, the uncertainty model 832 provides a model of uncertainty relationships that is separate from the entity model of the vehicle map model 802. In some examples, the entity pattern may represent entity 808 as an estimate of its attributes on the map (also referred to as a "best guess"). Uncertainty pattern 834 may comprise a separate uncertainty address space 836 of uncertainty relationships 838. The uncertainty pattern 834 may point to entities in the entity address space 806 and may associate entities within the entity address space 806.
According to example embodiments of the present disclosure, an uncertainty model may provide an extensible uncertainty relationship pattern. For example, the uncertainty relationship between two single real-valued attributes of a single entity may be an arbitrary probability density function. Multiplication of an arbitrary function is considered by the fact that it may also have a separate cross-correlation function with each other attribute of the entity or any other entity. The set of possible relationships grows as the square of the number of attributes in the entire model, where the model itself may consist of any number of hypothetical states of the same real-world entity.
In an example embodiment, the uncertainty model 832 may be selected for modeling uncertainty in entity attributes using an extensible uncertainty relationship model. In an example embodiment, as the uncertainty model 832 evolves, the uncertainty model 832 may be extended by adding new uncertainty models thereto. In this way, some generally useful notion of uncertainty relationships (such as joint gaussian envelopes between poses) may be provided, and more complex special purpose relationships may be added to patterns where greater accuracy may be required. This approach may provide an improvement to modeling uncertainty in entity attributes by selecting a useful model (e.g., a gaussian model or some form of joint gaussian model) and imposing uncertainty into the model (e.g., any probability mass function may be converted to a gaussian model by taking the mean and variance and then replacing the gaussian with the mean and variance). This approach may provide improvements over providing a small set of highly specific models that may be selected and customized for a particular use case. For example, a particular uncertainty model for "landmark observation of a car" may specify the manufacturer and model of the car, for which any complex model specific to each manufacturer and model may be defined. For example, a model for marker observation may specify a particular form of LIDAR that captures the marker, where one uncertainty attribute is a reflectivity attribute of the marker or a cross-correlation between the angle of the marker relative to the beam source and the variance of the distance measurement.
In an example embodiment, as the uncertainty model 832 evolves, the uncertainty model 832 may adapt and grow as new uncertainty models are added to the pattern. In this way, generic uncertainty relationships can be provided for simple cases, and more complex special-purpose relationships can be added to patterns where greater accuracy may be required.
According to an example embodiment, uncertainty relationship and confidence data may be provided independent of entity schema 804. For example, some client devices may not receive a complete uncertainty model for each aspect of a map. For example, some client devices of a map may choose to receive a current, fully consistent, unique entity map that shows the highest probability projection of an uncertainty map into a self-consistent map that is completely free of uncertainty. Other client devices may choose to receive uncertainty information. Some individual client devices may choose to receive a particular type of uncertainty, while other individual client devices may not. For example, some client devices may choose to receive only the highest likelihood hypothesis for the location of the vehicle, but may still envelope the error around this single highest likelihood hypothesis. Some applications may be able to utilize or merge all possible uncertainty quality functions between each possible hypothesis attribute value for each possible hypothesis entity. The map database of the vehicle map service may contain all of the uncertainty information that each client device may choose to receive, without requiring the client to always extract all of the uncertainty information.
Thus, in some example embodiments, the vehicle map service may provide an uncertainty model, wherein uncertainty relationships may be separated from the base map itself, as represented by the map model and the entity model. For example, a set of objects having certain attributes may be provided using a solid model of a map model. However, the uncertainty relationships may be added and understood or not understood by a particular customer depending on the uncertainty relationships they choose to receive or otherwise process. These uncertainty relationships may be specified using an uncertainty model and an uncertainty address space separate from the physical address space of the map model.
In certain aspects, a representation of a shared context may be provided. The shared context in which the observation is obtained can be tracked. For example, the fact that all N marker observations are made simultaneously from one image or one vehicle pose can be tracked. An implicit set of uncertainty relationships can be inferred, which may facilitate clustering and fusion. For example, it may be known that these observations should be for different signs, and that the relative accuracy between those observations is independent of the then-current precise vehicle attitude, even though the absolute accuracy is based on the vehicle attitude.
In some examples, the vehicle map service agreement 800 may provide complete viewing expressiveness to other systems. The uncertainty model can be used to extract feature observations with uncertainty to a geographic information service provider (e.g., a remote map service system) to update the base map. For example, a geographic information system may be provided with a model of the fully formed observations of the entities that it supports. According to an example embodiment of the present disclosure, uncertainty information may be added via an external record pointing back to the main record containing the average.
Example embodiments may use external modeling, where the object records hold only the mean or estimated specific values of the entities and their attributes, and the uncertainty model is purely an external record that references the underlying object records, effectively adding the "fuzzy" and other variance terms to the mean. This is to serve some desired attributes such as independence and extensibility.
According to an example embodiment of the present disclosure, data indicating relative accuracy may be provided. In an example embodiment, the model may represent relative accuracy (e.g., "the segments are within 3 meters to 0.1cm of each other"). In an example embodiment, the model may represent relative accuracy with respect to the earth as a map feature (e.g., "the landmark has an error envelope with respect to the earth at latitude X longitude Y"). In this way, all error relationships can be considered relative. For example, what someone might call absolute accuracy may actually be the accuracy relative to the earth itself as an entity. Thus, in one embodiment, the model may be a relative model with some specially defined entities (e.g., the earth, the pose of vehicle X at time T, the state plane origin of coordinates of texas, etc.).
According to some aspects, a vehicle location may be modeled using a vehicle map model and an uncertainty model. In some examples, the vehicle location may be statistically modeled using a particle filter approach. For example, at any instant in time, a probability map of a vehicle location may involve multiple hypotheses of the vehicle state. For example, the vehicle state may include an assumed attitude and velocity in an earth-based (e.g., WGS84) coordinate space. The global coordinates may use the world geodetic system, which is referenced to the world geodetic system (WGS84) standard in 1984. Using the world geodetic system, coordinates can be described by latitude, longitude and altitude. Altitude may be referred to in terms of the geohorizon, which is the distance above sea level in a direction perpendicular to the WGS84 ellipsoid. Other coordinate systems may be used. In some embodiments, the vehicle map service agreement may describe a location and/or geometry in local coordinates (e.g., cartesian coordinates). The local coordinates may be simpler and more compact than the global coordinates. However, in some implementations, determining the local coordinates may include the use of a global reference.
The vehicle state may include a variance and covariance of attitude and velocity (e.g., a joint gaussian model) or other joint probability model. The vehicle state may contain, for example, a confidence that the observation is a correct hypothesis, which may be interpreted as a probabilistic mass function of the joint gaussians of the pose. In some examples, these confidences may be scaled to add up to 1.0 across all hypotheses. A single state of the vehicle may be provided to certain clients, for example to client devices requesting only a single best observation without uncertainty information. For example, the most likely assumption may be given, e.g., the average of the division by the confidence.
In some examples, a complete description of the observation model from the geographic information tracking system and the observation model from the standard particle filter model of all observed entities may be provided, such as by collection. The features may be modeled in an observation protocol of a geographic information tracking system.
According to an example embodiment, general individual feature detection and fusion may be provided. Many features can be modeled as entities (e.g., buildings, guideboards, placards and billboards, street lights, mailboxes, lampposts, other vehicles, events, etc.) with a single specific pose that can typically be detected from a single sensor image (of various types of sensors). In general, these observations may be similar in nature to the described observations of the mark. In an example embodiment, the pose uncertainty may be modeled, including cross-correlations between pose elements and potential correlations between pose elements and other attributes. In some implementations, uncertainties in the states of physical attributes and/or features may be modeled, including relative probabilities and mutual exclusions between states from different sensors. In an example embodiment, uncertainty and confidence may be modeled. The uncertainty and confidence may be between the basic observations that can be clustered (e.g., for other vehicles, what is likely that two observations of a vehicle from different sensors are the same vehicle).
According to an example aspect, linear feature (e.g., lane striping, curbs, etc.) detection and fusion is provided. Some features, such as linear road marking features (e.g., lane stripes and curbs), large scale "features" (e.g., traffic and weather), etc., may be substantially long linear extrusions. In some cases, a single sensor image may not be able to fully capture a feature. Thus, a partial probabilistic roadmap may comprise a partial local model of roads and lanes. These partial local models may be fused into larger parts when creating the master map, and the partial road portions may be merged with the larger base map to identify and encode deltas that may be returned as change detections to the remote map service system.
In some cases, a report may be provided of the detection of physical features (e.g., streak portions) that were not present in the prior map. In some examples, the detection may involve classification of the type, color, or other identifying attribute of the feature. In some examples, the detection may involve an error attribute relative to the frame and/or the orientation feature. For example, uncertainty in stripe width, distance from the vehicle, or orientation relative to the vehicle may be provided. Additionally or alternatively, variations and cross-correlations between physical attributes (e.g., pose, width, etc.) may be provided. In some examples, the detection may include a confidence in the classification of the attribute of the feature. In some examples, detection may involve relative uncertainty and joint presence in measurements made in the context of a single sensor. For example, uncertainty in the spacing between features from a particular detection may be provided. It may be provided to identify mutually exclusive features detected in the same image.
In some examples, complex graphical relationships and fusions may be provided. These complex graphical relationships may be correlated to identify, for example, that an intersection has been observed in the middle of a road segment that has not previously been intersected. In an example embodiment, complex graphical relationships may be associated to identify complex likelihood relationships of connections. For example, it may be identified which strips may be connected to which other strips, or which strips may be the same strips as other strips. In an example embodiment, complex graphical relationships may be correlated to identify the likelihood of which point features (e.g., signs, lights, obstacles) are associated with which road or lane elements (e.g., signs between freeways and frontlines).
FIG. 9 depicts a block diagram showing additional details of a vehicle map service agreement, according to an example embodiment of the present disclosure. As shown in FIG. 9, the physical address space of the physical schema 804 may include two separate address spaces. In particular, the physical address space of the entity schema 804 can include a unique physical address space 810 and a hypothetical physical address space 820. In this way, the vehicle map model can be viewed as an address space containing basic entities, which are divided into two groups. Unique entity 812 can be considered a current estimate or best guess representation of an existing object that is unique among other unique entities. Hypothetical entity 822 can be considered a non-unique entity that cannot be guaranteed to be unique among unique entities or hypothetical entities. A hypothetical entity may lack uniqueness between multiple unique entities and multiple hypothetical entities.
With the vehicle map model 802, only the client devices interested in estimating or best guessing a map may only consider the unique entity 812. Rather, a client device interested in assuming all possible entities may consider the assumed entity 822 in the assumed entity address space 820 in addition to the unique entity address space 810.
Accordingly, the uncertainty pattern 834 may point to entities in the unique entity address space 810 of a unique entity or the hypothetical entity address space 820 of a hypothetical entity. Additionally, uncertainty pattern 834 can associate unique entities within unique entity address space 810 and/or can associate hypothetical entities within hypothetical entity address space 820. Further, uncertainty pattern 834 can associate unique and hypothetical entities between unique entity address space 810 and hypothetical entity address space 820.
Fig. 10 depicts a block diagram illustrating additional details of the uncertainty model 832 according to an example embodiment of the present disclosure. As shown in fig. 10, according to an example embodiment of the disclosure, an uncertainty pattern 834 (including uncertainty address space 836) may be used to define pose relationships 840, cluster relationships 850, and/or mutual exclusion relationships 860 in association with one or more entities of the vehicle map model 802. Note that although a single pose relationship 840, a single cluster relationship 850, and a single mutual exclusion relationship 860 are described, multiple uncertainty relationships may be provided according to example embodiments.
In an example embodiment, the pose relationship 840 may reference a single rigid entity whose pose may be described by a single 6DOF basic framework, providing a joint gaussian model of X, Y, Z and angle, and explicitly representing covariance. The pose relationships may be similar to observations in certain geographic information tracking systems. In an example embodiment, a gestural relationship may contain entity references 842 to more than one entity. For example, the base entity reference 843 may reference a base entity. A relative entity reference 844 whose pose is indeterminate relative to the base entity may reference a relative entity. The underlying entity may be an entity that remains unchanged and thus establishes the origin of the local coordinate system. For example, the underlying entity may comprise another entity in the model. Examples of underlying entities include vehicle position and/or EARTH for vehicle relative measurements, which bases uncertainty in ECEF (or other EARTH-fixed) coordinates. For example, the relative entity pose may be indeterminate relative to the underlying entity. In an example embodiment, the pose relationship may include a gaussian pose model 845 (e.g., mean and variance of coordinate values). Additionally and/or alternatively, the average may be omitted if the pose of the opposing entity has already been described with respect to the base entity. For example, in some examples, it may be assumed that the pose of the relative entity has been set to a mean value. In an example embodiment, the pose relationship may contain a velocity model 846 of the velocity vectors and/or tensors of the opposing entities relative to the underlying entity. The velocity model 1984646 is optional.
In an example embodiment, the pose relationship 840 may be reversible. For example, if the base entity is the vehicle attitude and the opposing entity is the sign, the envelope may be reversed to obtain uncertainty in the vehicle attitude of the sign that remains fixed relative to the sign attitude.
Since the joint Gaussian model is usually a backup to the point-to-point relationship, and many uncertainties attempt to model the relative pose uncertainty between rigid objects, it can be expected that the pose relationship is a very general and very useful relationship. In some examples, the gestural relationships can take a specific definition in each referencing entity. Fields in the referenced entity may represent gestures that are affected by gesture relationships. The use of a relationship context may be useful when a relationship is derived from a particular observation. In an example embodiment, the pose relationships may be derived from particular observations. For example, the relationship may be derived from a landmark (e.g., a landmark for a vehicle, a landmark for the earth, etc.) or from a vehicle location (e.g., a vehicle for the earth, etc.).
In an example embodiment, the clustering relationships 850 (also referred to as confidence relationships) may handle the case of clusters with assumptions for the presence and/or attribute states of particular real-world entities. The confidence relationship may include an entity reference 852, the entity reference 852 referencing two or more hypotheses considered to be the same entity. The entity references 852 include any number of entity references 852-1 through 852. The confidence relationship may optionally assign weights 855-1 through 855-N to the entity references 852-1 through 852-N, respectively, if the relative weights are known. The confidence relationship may include an implicit "null hypothesis" 858, i.e., that the particular hypothesis referenced is incorrect.
In an example embodiment, each hypothetical entity may have a weight associated with the hypothetical entity if a weight is included. In some examples, if used in a univariate manner and with weights of a single concrete hypothesis and a null hypothesis, this may represent a simple confidence, i.e., the likelihood that a feature exists in a ratio of weights. In an example embodiment, if used for multiple specific hypotheses, this may represent a cluster of hypotheses for the attributes of the same entity. For example, multiple hypothetical entities may be clustered into observations of a particular actual entity, whether or not each observation is known to be a relative probability of the true state of that entity. With weight and pose uncertainty relationships on each entity, this can represent a particle filter model that marks the observation cluster or vehicle location.
In an example embodiment, the mutually exclusive relationship 860 may reference multiple hypothetical entities. The mutually exclusive relationship 860 may relate to multiple hypothetical entities, and thus include two or more entity references 862-1 through 862-N that reference a hypothetical entity and indicate that the two or more hypothetical entities are not the same real-world entity. In some examples, a mutually exclusive relationship may state negation. For example, a mutually exclusive relationship may indicate a hypothesis that two or more hypothetical entities cannot be the same real-world entity. Thus, the mutually exclusive relationship 860 may include a negative relationship indication 864 indicating a shared context. In some examples, mutually exclusive relationships may be used to associate observations of similar types (e.g., signs, vehicles, etc.) made from the same image and thus considered to be different real entities. In some cases, the confidence relationships between entities may fundamentally indicate that multiple hypotheses are for the same real-world entity. Rather, mutually exclusive relationships may fundamentally indicate that multiple hypotheses are for different entities. In some examples, the mutually exclusive relationship may explicitly represent a constraint implied by the sharing context. In an example embodiment, when the confidence relationship indicates that the hypotheses are for the same real entity at all, the mutual exclusion relationship may indicate that the hypotheses are for different entities at all. In an example embodiment, the intent of the mutually exclusive relationship may be to explicitly represent one of the constraints implied by the shared context. For example, all landmark observations acquired from a single image may be related to a mutually exclusive relationship, as they do not represent the same real-world landmark.
FIG. 11 depicts a flowchart describing an example method 1100 of operating a vehicle map service system in accordance with an example embodiment of the present disclosure. One or more portions of the method 1100 may be performed or implemented on one or more computing devices or computing systems, including, for example, the vehicle map service system 114, the remote map service system 120, and/or the remote vehicle service system 130. Further, one or more portions of method 1100 may be performed or implemented as algorithms on a hardware device or system disclosed herein, for example, to generate vehicle map service data including map data and uncertainty data. FIG. 11 depicts steps performed in a particular order for purposes of illustration and discussion. Those of ordinary skill in the art having access to the disclosure provided herein will appreciate that various steps of any of the methods disclosed herein may be adapted, modified, rearranged, omitted, and/or expanded without departing from the scope of the present disclosure.
At 1102, method 1100 may include obtaining map data, such as map data 124, map data 134, and/or map data at vehicle 110. Note that 1102 is optional because method 1100 can be used to generate map data from sensor data or other sources without the need to obtain existing map data. The map data may be associated with the status of a geographic area (e.g., one or more maps).
At 1104, method 1100 may include acquiring sensor data, such as sensor data 126, sensor data 136, and/or sensor data at vehicle 110. In an example embodiment, sensor data may be acquired from one or more sensors at vehicle 110. For example, the sensor data may include LIDAR data, RADAR data, image data, or other sensor data acquired from one or more LIDAR sensors, RADAR sensors, image sensors (e.g., cameras), etc. of the vehicle.
At 1106, method 1100 can include accessing a vehicle map model having a solid model. The vehicle map model may be configured to provide map data for a geographic area in association with a vehicle map service. The vehicle map model may include a first address space configured to represent an entity associated with the vehicle map model.
At 1108, the method 1100 may include generating map data that includes entities defined in an entity address space of the vehicle map model. The entities may be generated from an entity model of the vehicle map model.
At 1110, method 1100 can include accessing an uncertainty model having an uncertainty pattern. The uncertainty model may be configured to represent a plurality of uncertainties associated with entities generated using the vehicle map model. The uncertainty model may include a second address space separate from the first address space.
At 1112, the method 1100 may include generating uncertainty data including uncertainty relationships defined in an uncertainty address space of the vehicle map model. An uncertainty relationship may be generated with respect to one or more entity definitions defined in the first address space. One or more uncertainty relationships may be defined in the uncertainty address space according to an uncertainty pattern of the uncertainty model.
FIG. 12 depicts a block diagram of example vehicle map service data including a vehicle map model and an uncertainty model, according to an example embodiment of the disclosure. According to an example embodiment of the present disclosure, a vehicle map model includes entities defined according to an entity pattern of the vehicle map model and uncertainty relationships defined according to an uncertainty pattern of the uncertainty model. FIG. 12 depicts one example of layers of uncertainty modeling for a set of road signs on a map. In an example embodiment, the uncertainty relationships may be provided in a manner such that they are separable from the base graph itself. The simplest view may be of a set of objects with certain properties. From a set of objects with certain attributes, uncertainty relationships may be added and understood or not understood by a particular client device, depending on the relationships they can handle.
An external model of uncertainty patterns is provided in which there is a separate uncertainty relationship from the entity patterns. An entity pattern represents an entity as an estimate (also referred to as a "best guess" or guess) of its attributes on a map. The vehicle map model includes a physical address space containing basic entities, which are divided into two groups: the unique entity that is considered to be the current estimate of an existing object that is unique among other unique entities and the hypothetical entity that cannot be guaranteed to be unique among the unique entities or hypothetical entities. In an example embodiment, only the unique entities may be considered by the client device interested in only maps representing the unique entities that the system currently best estimates. In an example embodiment, a client device interested in all possible entity hypotheses may consider the address spaces of both the unique entity and the hypothesized entity. In an example embodiment, the physical address space may correspond to a converged physical layer, and the hypothetical physical space may correspond to a set of non-converged intermediate layers. In some implementations, the uncertainty address space may be a space of entities belonging to a separate uncertainty model layer of a vehicle map service model or protocol.
In FIG. 12, the unique entities include a first unique flag entity 802-1, a unique vehicle position entity 802-2, and a second unique flag entity 802-3. The unique entity may represent the highest likelihood assumption for each possible entity (e.g., a sign or vehicle location). The attributes of the unique entity may contain attributes such as a gesture that contains a specific single value. A simple client or other client accesses or simply sees the highest likelihood assumption for each possible sign or vehicle location represented by a unique entity.
The hypothetical entities include a first hypothetical flag entity 1204-1, a second hypothetical flag entity 1204-2, a third hypothetical flag entity 1204-3, and a fourth hypothetical flag entity 1204-4. The hypothetical entities can represent the entire set of possible hypothetical tokens, which can represent the same actual real-world entity seen from different sensors or other sources. Some clients (e.g., more complex clients) may select or otherwise see the entire set of possible hypothesis flags.
The vehicle map data depicted in fig. 12 also includes a set of uncertainty relationships. In some examples, the uncertainty relationship may describe an error envelope around the pose of each hypothesis. Additionally or alternatively, the uncertainty relationship may describe relative uncertainty/confidence/condition presence information about a subset of hypotheses that may represent the same physical landmark or vehicle location. In the example of FIG. 12, the uncertainty relationships include: a cluster likelihood relationship 1206-1, which may represent a cluster likelihood relationship between the first unique token entity 1202-1, the first hypothetical token entity 1204-1, and the second hypothetical token entity 1204-2. Cluster likelihood relationship 1206-1 is an example of cluster relationship 850 shown in fig. 10. The second uncertainty relationship includes a relative pose uncertainty relationship 1206-2. Relative attitude uncertainty relationship 1206-2 may represent a relative attitude uncertainty relationship between second hypothetical landmark entity 1204-2 and unique vehicle position entity 12802-2. Relative attitude uncertainty relationship 1206-2 is an example of attitude relationship 840 shown in FIG. 10. The third uncertainty relationship 1206 includes a cluster likelihood relationship 1206-3. Cluster likelihood relation 1206-3 is an example of cluster relation 850 shown in fig. 10. Cluster likelihood relationship 1206-3 may represent a cluster likelihood relationship between third hypothetical token entity 1204-3, second unique token entity 1202-3, and fourth hypothetical token entity 1204-4.
A subset of client devices, such as more complex client devices, may also acquire or otherwise see an uncertainty relationship that describes an error envelope around the pose of the respective hypothesis, or relative certainty/confidence/condition existence information about the subset of hypotheses that may represent the same physical token.
In an example embodiment, if the uncertainty is in a property of a single entity, one or more external uncertainty relationships may point to the property of the entity, which describes an error function on or between the properties of the entity. For example, a marker may have a 3D location in the world. The uncertainty relationship may reference the location field of the marker, providing variance and covariance between coordinates describing the joint gaussian envelope on the X, Y, Z coordinates of the marker relative to the EARTH. For example, a coordinate system centered on earth, fixed on earth (ECEF), or a specified fixed frame in ECEF may be used. Consider an example sign that might be associated with road X, but there might be reason to believe that the sign might be associated with road Y or Z. The uncertainty relationship may point to the "belongings _ to _ segment" field of the entity and include a joint distribution that gives a probability distribution. For example: the confidence percentage for the X road is P, the confidence percentage for the Y road is Q, and the confidence percentage for the Z road is R.
In an example embodiment, the uncertainty relationship may relate attributes of multiple entities. For example, consider two landmarks S1 and S2 that may be observed in the same LIDAR scan. An uncertainty relationship may reference the positions of two landmarks, reflecting the same basic joint gaussian position error model, but instead of relating it to the earth, it may be related to the average coordinates of the other landmark. Another uncertainty relationship may indicate that two hypothesized entities may be observed together in the same context, indicating that they are almost certainly different tokens (for clustering). For example, both of the signature observations S1 and S2 may be described as having a joint gaussian position error relative to the vehicle observation entity V1. This may indicate that the error is strictly within the local framework of the vehicle attitude.
Therefore, if S1 and S2 were taken from the same camera image, they also have a joint contextual relationship as described above. However, if S1 was taken from LIDAR and S2 was taken from video, they have no joint context because they may be the same sign. V1 may itself have a joint gaussian uncertainty relationship with respect to the earth; this is uncertain in its pose. Derivations can be derived by combining the marker relationships S1 through V1 and V1 through EARTH to model the marker position (with poor accuracy) of the marker relative to the EARTH.
In an example embodiment, the relationship may model a joint presence relationship between hypotheses in addition to a joint probability model of the associated parameters. For example, for the case of vehicle map matching, there may be three vehicle position hypotheses V1, V2, and V3, each of which may have its own pose relative to the earth and its own position uncertainty relationship. From the above relationships, there may also be relationships on V1, V2, and V3, indicating that they are mutually exclusive hypotheses about the same vehicle, with probabilities P, Q, and R associated with each, respectively. This may then represent a complete particle filter model of the vehicle position.
As an example, consider an example of a landmark entity having a confidence value associated therewith as provided by a vehicle map model. The uncertainty model may define a pose relationship 840 entity for each marker referencing the marker location. In another example, each marker may have a confidence and the pose attributes of the marker may have an uncertainty envelope provided by the vehicle map model. The uncertainty model may define a pose relationship 840 entity for each token that references the token. In addition, a clustering relation 850 can be defined that references each marker, with a weight associated with each marker that describes the relative probability of that marker being the actual real-world marker.
Another example is depicted in fig. 13, which illustrates a block diagram of example vehicle map service data including a vehicle map model and an uncertainty model, according to an example embodiment of the present disclosure. In fig. 13, an entity is defined based on observations generated from a plurality of images, according to an example embodiment of the present disclosure. Two signs can be viewed twice from two different images, each taken from a different vehicle position. An indication may be provided as to constraints and pose error envelopes that may not be identical for the observations. The vehicle map service may receive sensor data including image data for image 1302 and image 1312. The vehicle map service may generate four sign views based on the sensor data. The vehicle map service may generate a first landmark entity 1304 and a second landmark entity 1306 from the first image 1302. Further, the vehicle map service may generate a third landmark entity 1314 and a fourth landmark entity 1316 from the second image 1312. The first and third landmark entities 1304, 1314 may represent the same actual real-world landmark. Similarly, the second marker entity 1306 and the fourth marker entity 1316 may represent the same actual real world marker. The vehicle map service may generate a first vehicle location entity 1340 indicating the location of the vehicle obtained at the time image 1302 and a second vehicle location entity 1342 indicating the location of the vehicle obtained at the time image 1312.
The vehicle map service may generate a mutually exclusive relationship 1320 that relates the landmark entity 1304 and the landmark entity 1306. Because the landmark entity 1304 and the landmark entity 1306 are captured from the same image 1302, the mutually exclusive relationship may indicate that the landmark entities correspond to different real-world landmarks. The first attitude relationship 1322 defines an attitude uncertainty of the first flag entity 1304 with respect to a particular attitude of the vehicle as the base entity indicated by the vehicle position entity 1340. The second pose relationship 1324 defines a pose uncertainty of the second landmark entity 1306 relative to a particular pose of the vehicle as a base entity indicated by the vehicle position entity 1340. The pose relationship 1322, pose relationship 1324, and mutual exclusion relationship 1320 may include a shared context 1352.
The vehicle map service may generate a mutually exclusive relationship 1330 relating the signpost entity 1314 and the signpost entity 1316. Because the landmark entity 1314 and the landmark entity 1316 are captured from the same image 1312, the mutually exclusive relationship may indicate that the landmark entities correspond to different real-world landmarks. The first pose relationship 1332 defines a pose uncertainty of the third landmark entity 1314 relative to a particular pose of the vehicle as a base entity as indicated by the vehicle position entity 1342. The second pose relationship 1334 defines a pose uncertainty of the fourth flag entity 1316 relative to the particular pose of the vehicle as the base entity as indicated by the vehicle position entity 1342. Pose relationship 1332, pose relationship 1334, and mutual exclusion relationship 1330 may include shared context 1354.
In a variation of the example shown in fig. 13, there may also be a module that can determine which entities are the same real world markers and use confidence weights to reflect the hypothetical clusters on the map based on the confidence of the original marker entities.
FIG. 14 depicts a block diagram of example vehicle map service data including a vehicle map model and an uncertainty model, according to an example embodiment of the disclosure. FIG. 14 depicts a vehicle map model and uncertainty model similar to FIG. 13, but in addition to the base model, a separate provider adds two clustering relationships that correlate observations of the same physical sign.
The first clustering relationship 1362 defines a clustering relationship that associates the first flag entity 1304 with the third flag entity 1314. The first clustering relationship 1362 may indicate that marker entity 1304 and marker entity 1314 correspond to the same real-world marker (1). The second clustering relationship 1364 defines a clustering relationship that associates the second flag entity 1306 with the fourth flag entity 1316. The second clustering relationship 1364 may indicate that marker entity 1306 and marker entity 1316 correspond to the same real-world marker (2).
As a further example, consider an example of vehicle location entities that may each have an attitude uncertainty envelope relative to earth (e.g., as determined from a GPS sensor). The vehicle location entity object identifier from the vehicle map model may be referenced from a pose relationship defined using the uncertainty model. As another example, consider four hypotheses of current vehicle position, two of which are assumed on a first road and two of which are assumed on another road. Four kalman filter hypotheses for the current vehicle position may be defined using the uncertainty model.
FIG. 15 depicts a block diagram of example vehicle map service data including a vehicle map model and an uncertainty model describing an example of a vehicle location entity. Vehicle position entities 1512, 1514, 1516, and 1518 have been defined using a vehicle map model. Two link entities 1522 and 1524 have also been defined using a vehicle map model.
The vehicle position entity 1512 has a reference pose relationship 1532 that indicates a pose uncertainty associated with the vehicle position entity 1512. The vehicle position entity 1514 has a reference pose relationship 1534 that indicates a pose uncertainty associated with the vehicle position entity 1514. The vehicle position entity 1516 has a reference attitude relationship 1536 that indicates an attitude uncertainty associated with the vehicle position entity 1516. Vehicle position entity 1518 has a reference attitude relationship 1538 that indicates an attitude uncertainty associated with vehicle position entity 1518.
The first road segment entity 1522 matches the vehicle position entity 1512 and the vehicle position entity 1514 to the same road segment entity. The second segment entity 1524 matches the vehicle position entity 1516 and the vehicle position entity 1518 to the same segment entity of the road that is separate from the first segment entity 1522. The clustering relationships 1542 may correlate or otherwise associate the vehicle position entities 1512, 1514, 1516, and 1518. The clustering relationship 1542 may reference each token and associate a weight with each token that describes the relative probability of that token as an actual real-world token.
In another example, two different kalman filter systems may be used to track vehicle position. Two sets of assumptions from the filter system can be represented in the original map model. In such an example, the vehicle map model and uncertainty model may double the relationship shown in fig. 15. Potentially, another meta-cluster relationship may be defined that references the two lowest-level cluster relationships.
According to some aspects of the present disclosure, a fusion of entities across era is provided. In the vehicle map service mode, the provider may declare an epoch when a change occurs in the map. In an example embodiment, the era may start with a new object ID space completely independent of the last, entirely new map. For example, the entity in the new map may be a real world entity in the old map with the new object ID. In the basic mode, it cannot be represented that the example entity Ia in the epoch E and the example entity Ib in the epoch F are the same real world entities. In the uncertainty pattern, it may be represented that entities in different times are the same entity.
In an example embodiment, clustering relationships may be used. The clustering relationship may not have a limitation on the form of the object ID being clustered; they may come from different ages (e.g., if a provider wants to broadcast the fact that a real-world sign has appeared on a map in multiple ages, they may broadcast an unweighted clustering relationship that indicates that the signs in the age are the same sign).
In an example embodiment, relational composition may be used. The pose relationship may represent an uncertainty in a particular hypothesis. Other relationships may be stacked to represent uncertainty in the uncertainty relationship itself. For example, if there are multiple vehicle location cluster relationships (each from a different particle filter model), then if each cluster is represented by a cluster relationship, these cluster relationships may be associated by a cluster relationship that gives relative weight to each model and represents an assumption that both models attempt to track the same vehicle.
Example implementations in vehicle map service modes and protocols are described, according to example embodiments of the present disclosure. For example, three different address spaces may be provided for map entities. The first address space may be for a unique entity. The domain of the space may also be a map entity model, and the space may typically be a subset of a hypothetical entity space. These entities may have references (relationships) to other entities in this space. The second address space may be used for a hypothetical entity. The domain of the space may also be a map entity pattern (e.g., sign, road, vehicle, etc.). These entities may have references (i.e., relationships) to other entities in this or a unique entity space. A third address space may be used for uncertainty relationships. The domain for this may be an uncertainty relationship pattern, and these entities may have references (i.e., relationships) to entities in all spaces.
Mapping these different spaces onto VMS layer modes may be provided according to example embodiments of the present disclosure. The unique entities may be those at all generic map architecture layers on the convergence sub-layer. It is assumed that the entities may be those at a common map architecture level among all sub-levels (including the original or un-fused sub-levels). Uncertainty relationships may naturally exist in their own uncertainty relationship layer, which may be: client subscribed to uncertainty information about the generic map layer; and published to or by publishers who wish to share uncertainty models about map entities published on fused or unfused map layers.
In an example embodiment, certain relationships may be semantically excluded from certain layers by the nature of the layers. For example, a clustering relationship may not reference multiple entities on a fusion layer, because by definition, anything on a fusion layer should be the only assumption of a single entity, and thus there should be no cluster of assumptions associated with it on that layer. A simple pose uncertainty relationship may reference the fusion layer entities, or a hypothesis cluster may have exactly one reference at the fusion layer, but multiple additional hypotheses at other layers.
Version control of uncertainty relationships may be provided according to example embodiments of the present disclosure. An advantage of having the uncertainty relationship at one level of the vehicle map service model is that full access to the vehicle map service version system is obtained. Thus, the "1.0 version" of the relational schema may be represented as the primary vehicle map service schema version of the relational schema. New relationships can be added via the minor version of the schema (1.1, 1.2) without destroying existing relationships, or only new properties can be added to existing relationships. If the use of relationships is not recommended, the main version of the uncertain relationship schema (version 2.0) may allow users to start with "white space" towards future clients while still maintaining older client compatibility.
Embodiments in accordance with the present disclosure may allow an uncertainty relationship to reference a target entity. The target entities may all be referenced by a vehicle map service object identifier (ObjectId). Since the relationships themselves are vehicle map service entities, the relationships can be referenced to each other in a completely uniform manner via the vehicle map service ObjectId to reference the physical entity assumptions.
Context-related information can be stored in different locations and in different manners. The relationships may have contextual identifiers that serve as a grouping mechanism to allow the relationships to be identified as coming from the same source (e.g., image, instantaneous vehicle pose, etc.). A specific mechanism for providing a context description will be described. For example, an image context (e.g., a picture) may have a time at which the picture was taken or data about the device that took the picture. It may provide uniformity for those entities to have a vehicle map service object identifier, but there may not always be a layer or pattern to represent a context element. If simple grouping of relationships according to context was required in the past, the patterns could be placed in the appropriate locations. For example, an image entity may contain meta-information about the image context and be broadcast and addressed via an object identifier.
According to certain aspects, all relationships of an entity may be provided. For example, a vehicle map service may provide a loosely coupled format in which a client may not determine whether the client knows all uncertainty relationships that reference a particular hypothetical entity. Although this problem exists to some extent on other layers, the problem may be less because, for example, the client may know a priori that there should be exactly one segment connection packet and one segment geometry packet associated with a segment, so it knows if there is. For the sake of uncertainty, there may be any number of relationships that reference a particular entity, or there may be no relationships that reference a particular entity.
The client may be able to use a meta-layer replay request for any entity (e.g., using the entity's object ID, such as the object ID of a segment, etc.). A request to the uncertainty relationship layer may result in a replay of all relationships from all providers that reference the entity.
Some examples include a generic map (e.g., a layer-to-object ID map) that may be provided in the vehicle map service grouping itself, which inversely indexes a set of known entities on other layers that reference the entities in the grouping. If a particular provider is providing entities that are cross-referenced to each other at various levels, this may allow it to indicate which complete set of entities cross-reference which other entities, and may apply this general mechanism to uncertain relationships. It may also allow for explicit representation of the inverse of other one-to-many mappings (e.g., segment-to-lane).
According to an example embodiment of the present disclosure, a specific vehicle map service mode is provided. In the layer definition, there may be a new uncertainty model layer on which uncertainty relationships may be subscribed to and/or published.
In an example embodiment, a scalable uncertainty relationship schema may be utilized. Scalability may be provided by any suitable method. In particular, the vehicle map service model version control mechanism may allow new relationships to be added to model specific probabilistic models that are missing from existing relationships without destroying those existing relationships. The primary versioning may also remove or completely modify older relationships if they are poorly formed relative to future use cases.
In an example embodiment, independence from the underlying entity patterns may be incorporated. These uncertainty relationships may be extensions to the underlying unique entity modeling schema; there may not be any fields or modifications to existing mockups, so these models may remain easy to interpret. Clients that are not interested in uncertainty measures may ignore the uncertainty layer altogether and have a specific map available for use.
In an example embodiment, simplicity and scalability may be combined. Relationships in the first version may be relatively straightforward and easy to interpret, but the set of relationships may be extended or modified when new use cases arise.
In an example embodiment, relative and absolute accuracies may be combined. Since all pose relationships can be specified relative to the global earth frame or the local frame of some entity in the model (including the moving vehicle entity), both relative and absolute accuracy can be represented within the same model.
In an example embodiment, representations of shared contexts may be merged. The shared context may be represented as a general concept about uncertainty relationships.
In an example embodiment, full observation expressiveness for third party services (e.g., geographic information tracking services and other services) is provided. The first version pose uncertainty relationship may be a third party representation based on a joint gaussian pose uncertainty. Additionally or alternatively, the first version pose uncertainty may be based on its relationship to the base pose of the vehicle, and may be implemented by correlating the pose with a particular vehicle position grouping at some point in time. By extending the fundamental pose uncertainty relationship, the model can also be extended to other attributes (e.g., height, width, etc.) modeled in third party systems.
The uncertainty relationship context may relate to entities that do not currently exist in the vehicle map service mode. For example, if the context is "an image taken by a particular camera," the image may have attributes such as location, orientation, and the like. However, this camera image entity may not have a location or presence in the vehicle map service mode to point to by contextual reference.
In an example of a vehicle map service agreement/schema implementation, a technique is provided that, given a base map entity, a client device may know all uncertainty relationships related to that entity. Other elements may be modeled as separate parts across layers. These elements can typically be directly indexed or known a priori (e.g., a segment has only one entry at the connectivity, geometry, and attribute levels; but does not know whether it has an associated uncertainty relationship of 0, 1, or more).
Given the exponential explosive nature of any uncertainty relationship, there may be a large amount of traffic on the uncertainty layer in some systems. For clients that are only interested in a very specific type of uncertainty (e.g., attitude uncertainty relationship on the vehicle), they may encounter full-range traffic. In some examples, techniques are provided such that if a client chooses not to process or cannot process such information, the client may not be exposed to a complete traffic layer.
To model a partial view of an entity (e.g., a view of a portion of a lane marker without viewing the entire object), the client may be made aware that the end point of a particular linear feature is not necessarily the end point of real life, and that a portion of the feature may be outside of the modeled portion. Linear lane characteristics may be considered. The overall problem may be to model the partial observations of what is effectively an "atomic" feature on the base graph (e.g., a building) in fact. In some examples, this may be provided in an entity mode. In other examples, this may be provided in an uncertainty relationship pattern or in a combination of patterns. For example, a linear feature may be contained in a particular endpoint, but have an uncertainty relationship pointing to it that indicates that the linear feature has an unknown continuation forward, backward, or both.
According to example embodiments of the present disclosure, the described generic model may be used not only for vehicle map services, but also for other services such as those that provide map services. In some examples, the "uncertainty relationship" may be added as a type of feature that references other specific features, or individual features may be labeled as a hypothesis-pair best guess. Observations can be modeled on a large scale to return to a remote map service system or vehicle service system. According to an example embodiment, the described model may be employed in a core mode. In an example embodiment, the uncertainty relationships may be indexed by which entities they refer to or what type of relationship they are, allowing efficient access by various processing pipelines to known relationship types. For example, if a person adds an explicit contextual reference to a relationship, they can also refer back to the particular observation from which the relationship was obtained.
Fig. 16 depicts a schematic diagram of an example computing device 1600, according to an example embodiment of the present disclosure. The vehicle map service device may be implemented using the computing device 1600. According to example embodiments, a vehicle map service device may perform one or more actions and/or operations.
As shown in fig. 16, the computing device 1600 may include one or more memory devices 1602, vehicle map service data 1604, one or more interconnects 1632, one or more processors 1620, a network interface, one or more mass storage devices 1624, one or more output devices 1626, a sensor array 1628, and one or more input devices 1630.
The one or more memory devices 1602 may store information and/or data (e.g., vehicle map service data 1604) including information associated with processing of one or more instructions for performing one or more actions and/or operations including sending data, receiving data, generating data (e.g., vehicle map service data associated with a local map), and/or determining a data state.
The vehicle map service data 1604 may include one or more portions of the vehicle map service data 112 used by the vehicle 110 shown in fig. 1, and as a further example, may include one or more portions of the vehicle map service data 122 used by the remote map service system 120, and/or may include one or more portions of the vehicle map service data 132 used by the remote map service system 130, as also shown in fig. 1. The vehicle map service data 1604 may include information associated with one or more maps, sensor outputs, and/or machine learning models.
The one or more interconnects 1610 may include one or more interconnects or buses operable to transmit and/or receive one or more signals (e.g., electronic signals) and/or data (e.g., vehicle map service data) between components of the computing device 1600, including the one or more memory devices 1602, the one or more processors 1620, the network interface 1622, the one or more mass storage devices 1624, the one or more output devices 1626, the sensor array 1628, and/or the one or more input devices 1630. The one or more interconnects 1610 may be arranged or configured in different ways including in parallel or in series. Further, the one or more interconnects 1610 may include one or more internal buses for connecting internal components of the computing device 1600; alternatively, one or more external buses may be used to connect internal components of the computing device 1600 to one or more external devices. For example, one or more interconnects 1610 may include different interfaces including an Industry Standard Architecture (ISA), an extended ISA, a Peripheral Component Interconnect (PCI), PCI Express, serial AT attachment (SATA), Hypertransport (HT), USB (universal serial bus), Thunderbolt, and/or IEEE 1394 interface (FireWire).
The one or more processors 1620 may include one or more computer processors configured to execute one or more instructions stored in the one or more memory devices 1602. For example, the one or more processors 1620 may include, for example, one or more general purpose Central Processing Units (CPUs), Application Specific Integrated Circuits (ASICs), and/or one or more Graphics Processing Units (GPUs). Further, the one or more processors 1620 may perform one or more actions and/or operations including one or more actions and/or operations associated with the vehicle map service data 1604. For example, the one or more processors 1620 may include single or multiple core devices, including microprocessors, microcontrollers, integrated circuits, and/or logic devices.
One or more memory devices 1602 and one or more mass storage devices 1624 are shown separately, however, one or more memory devices 1602 and one or more mass storage devices 1624 may be regions within the same memory module. The vehicle map service device 1600 may include one or more additional processors, memory devices, network interfaces, which may be provided separately or on the same chip or board. The one or more memory devices 1602 and the one or more mass storage devices 1624 may include one or more computer-readable media including, but not limited to, non-transitory computer-readable media, RAM, ROM, hard drives, flash drives, and/or other memory devices.
The one or more memory devices 1602 may store a set of instructions for an application that includes an operating system, which may be associated with various software applications or data. The one or more memory devices 1602 may be used to operate various applications including a mobile operating system developed specifically for mobile devices. As such, the one or more memory devices 1602 can store instructions that allow software applications to access data including wireless network parameters (e.g., identity of a wireless network, quality of service) and invoke various services including telephony, location determination (e.g., via Global Positioning Service (GPS) or WLAN), and/or wireless network data call initiation services. In other embodiments, the one or more memory devices 1602 may be used to operate or execute a general-purpose operating system running on mobile and fixed devices (e.g., smart phones and desktop computers).
Software applications that may be operated or executed by the computing device 1600 may include applications associated with the computing environment 100 shown in fig. 1. Further, software applications that may be operated or executed by the computing device 1600 may include native applications or network-based applications.
In some embodiments, computing device 1600 may be associated with or include a positioning system (not shown). The positioning system may include one or more devices or circuits for determining the location of the computing device 1600. For example, the positioning device may determine the actual or relative position by using a satellite navigation positioning system (e.g., GPS system, galileo positioning system, GLObal navigation satellite system (GLONASS), beidou satellite navigation and positioning system), inertial navigation system, dead reckoning system based on the IP address, by using triangulation and/or distance from cellular towers or Wi-Fi hotspots and beacons, etc., and/or other suitable techniques for determining position.
The techniques discussed herein make reference to servers, databases, software applications, and other computer-based systems and actions taken and information sent with respect to such systems. Those of ordinary skill in the art will recognize that the inherent flexibility of computer-based systems allows for a variety of possible configurations, combinations, and divisions of tasks and functions between components. For example, the server processes discussed herein may be implemented using a single server or multiple servers operating in combination. The database and applications may be implemented on a single system or may be distributed across multiple systems. The distributed components may run sequentially or in parallel.
While the present subject matter has been described in detail with respect to specific exemplary embodiments thereof, it will be appreciated that those skilled in the art, upon attaining an understanding of the foregoing, may readily produce alterations to, variations of, and equivalents to such embodiments. Accordingly, the scope of the present disclosure is by way of example rather than by way of limitation, and the subject disclosure does not preclude inclusion of such modifications, variations and/or additions to the present subject matter as would be readily apparent to one of ordinary skill in the art.
Claims (20)
1. A computing system, comprising:
one or more processors; and
one or more non-transitory computer-readable media collectively storing:
a vehicle map model configured to provide map data for a geographic area in association with a vehicle map service, the vehicle map model having a physical schema including a first address space configured to represent a plurality of entities associated with the vehicle map model; and
an uncertainty model configured to represent a plurality of uncertainties associated with the plurality of entities, the uncertainty model having an uncertainty pattern comprising a second address space separate from the first address space;
wherein at least one of the plurality of uncertainties in the second address space is configured to point to one or more of the plurality of entities in the first address space.
2. The computing system of claim 1, wherein the one or more non-transitory computer-readable media collectively store instructions that, when executed by the one or more processors, cause the one or more processors to perform operations comprising:
obtaining sensor data from one or more sensors of a first vehicle, the sensor data associated with the geographic area; and
generating map data based at least in part on the sensor data, wherein generating the map data comprises:
generating a first entity of the plurality of entities based at least in part on the vehicle map model and the sensor data, wherein the first entity is defined in the first address space according to the entity pattern of the vehicle map model; and
generating one or more uncertainty relationships with respect to the first entity based at least in part on the uncertainty model and the sensor data, wherein the one or more uncertainty relationships are defined in the second address space according to the uncertainty pattern of the uncertainty model.
3. The computing system of claim 1 or 2, wherein:
the plurality of entities includes a plurality of unique entities and a plurality of hypothetical entities.
4. The computing system of claim 3, wherein:
at least one of the plurality of ambiguities in the second address space correlates a first unique entity of the plurality of unique entities with a first hypothetical entity of the plurality of hypothetical entities.
5. The computing system of claim 3 or 4, wherein:
each of the plurality of unique entities is guaranteed to be unique among the plurality of unique entities; and
each of the plurality of hypothetical entities can lack uniqueness among the plurality of unique entities and the plurality of hypothetical entities.
6. The computing system of claim 3, 4, or 5, wherein:
the uncertainty pattern is configured to point to unique entities in the first address space and to hypothesize entities in the first address space.
7. The computing system of claim 3, 4, 5, or 6, wherein:
the first address space includes a unique entity address space corresponding to the plurality of unique entities and a hypothetical entity address space corresponding to the plurality of hypothetical entities.
8. The computing system of any of claims 3 to 7, wherein:
the plurality of hypothetical entities comprises a first hypothetical entity and a second hypothetical entity; and
the uncertainty model includes one or more uncertainty relationships that model one or more co-existence relationships between the first hypothetical entity and the second hypothetical entity.
9. The computing system of any of claims 3 to 8, wherein:
the uncertainty pattern includes a clustering relationship configured to reference two or more hypothetical entities that are considered to be the same real-world entity.
10. The computing system of claim 9, wherein:
the clustering relationship includes a respective weight for each of the two or more hypothetical entities.
11. The computing system of any of claims 3 to 10, wherein:
the uncertainty pattern includes mutually exclusive relationships configured to reference two or more hypothetical entities that are not the same real-world entity.
12. The computing system of any of the preceding claims, wherein:
the entity pattern comprises a plurality of attributes associated with at least one entity of the plurality of entities; and
the uncertainty pattern includes one or more uncertainty relationships that point to one or more of the plurality of attributes of the at least one entity to describe one or more error functions on or between the one or more of the plurality of attributes associated with the at least one entity.
13. The computing system of any of the preceding claims, wherein:
the plurality of entities includes a first entity and a second entity; and
the uncertainty model includes one or more uncertainty relationships that associate one or more attributes of the first entity with one or more attributes of the second entity.
14. The computing system of any of the preceding claims, wherein:
the uncertainty model comprises one or more uncertainty relationships associated with at least one of the plurality of entities;
the one or more uncertainty relationships comprise context; and
the context of the one or more uncertainty relationships includes a unique address space that is appended to the one or more uncertainty relationships to indicate a source of the one or more uncertainty relationships.
15. The computing system of any of the preceding claims, wherein:
at least one of the plurality of ambiguities in the second address space is associated with two or more of the plurality of entities in the first address space.
16. The computing system of any of the preceding claims, wherein:
the uncertain mode comprises an attitude relationship;
the gestural relationship includes a reference to at least a first entity of the plurality of entities that is a base entity; and
the pose relationship includes a reference to at least a second entity of the plurality of entities that is a relative entity whose pose is indeterminate relative to the base entity.
17. The computing system of claim 16, wherein:
the pose relationship is a first pose relationship and the base entity is a first base entity;
the uncertain mode comprises a second posture relationship;
the second pose relationship comprises a reference to at least a third entity of the plurality of entities that is a second base entity; and
the gestural relationship includes a reference to at least a second entity of the plurality of entities that is a relative entity whose pose is indeterminate relative to the second base entity.
18. The computing system of claim 17, wherein:
the pose relationship includes a velocity model of a velocity vector or a velocity tensor of the opposing entity relative to the base entity.
19. A computer-implemented method of operating a vehicle map service, the method comprising:
accessing, by one or more computing devices, a map model configured to provide map data for a geographic area in association with a map service, the map model including a first address space configured to represent an entity associated with the map model;
accessing, by the one or more computing devices, an uncertainty model configured to represent a plurality of uncertainties associated with the map data of the geographic area, the uncertainty model comprising a second address space separate from the first address space; and
generating, by the one or more computing devices, map data comprising information associated with a geographic area, wherein generating the map data comprising information associated with the geographic area comprises generating a plurality of entities defined in the first address space based at least in part on the map model according to an entity model of the map model; and
generating one or more uncertainty relationships with respect to one or more of the plurality of entities based at least in part on the uncertainty model, wherein the one or more uncertainty relationships are defined in the second address space according to an uncertainty pattern of the uncertainty model.
20. One or more non-transitory computer-readable media storing instructions that, when executed by one or more processors, cause the one or more processors to perform operations comprising:
accessing, by one or more computing devices, a map model configured to provide map data for a geographic area in association with a map service, the map model including a first address space configured to represent an entity associated with the map model;
accessing, by the one or more computing devices, an uncertainty model configured to represent a plurality of uncertainties associated with the map data of the geographic area, the uncertainty model comprising a second address space separate from the first address space; and
generating, by the one or more computing devices, map data comprising information associated with a geographic area, wherein generating the map data comprising information associated with the geographic area comprises generating a plurality of entities defined in the first address space based at least in part on the map model according to an entity model of the map model; and
generating one or more uncertainty relationships with respect to one or more of the plurality of entities based at least in part on the uncertainty model, wherein the one or more uncertainty relationships are defined in the second address space according to an uncertainty pattern of the uncertainty model.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201862702570P | 2018-07-24 | 2018-07-24 | |
US62/702,570 | 2018-07-24 | ||
PCT/US2019/043009 WO2020023495A1 (en) | 2018-07-24 | 2019-07-23 | Map uncertainty and observation modeling |
Publications (1)
Publication Number | Publication Date |
---|---|
CN110945498A true CN110945498A (en) | 2020-03-31 |
Family
ID=67660800
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201980003382.4A Pending CN110945498A (en) | 2018-07-24 | 2019-07-23 | Map uncertainty and observation model |
Country Status (4)
Country | Link |
---|---|
US (3) | US11068515B2 (en) |
EP (1) | EP3628085B1 (en) |
CN (1) | CN110945498A (en) |
WO (1) | WO2020023495A1 (en) |
Cited By (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN113963027A (en) * | 2021-10-28 | 2022-01-21 | 广州文远知行科技有限公司 | Uncertainty detection model training method and device, and uncertainty detection method and device |
WO2022052283A1 (en) * | 2020-09-08 | 2022-03-17 | 广州小鹏自动驾驶科技有限公司 | Vehicle positioning method and device |
Families Citing this family (10)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11068515B2 (en) * | 2018-07-24 | 2021-07-20 | Google Llc | Map uncertainty and observation modeling |
US20220001858A1 (en) * | 2018-11-13 | 2022-01-06 | Nec Corporation | Dangerous scene prediction device, dangerous scene prediction method, and dangerous scene prediction program |
US20210073662A1 (en) * | 2019-09-11 | 2021-03-11 | Insurance Services Office, Inc. | Machine Learning Systems and Methods for Performing Entity Resolution Using a Flexible Minimum Weight Set Packing Framework |
DE102019214603A1 (en) * | 2019-09-24 | 2021-03-25 | Robert Bosch Gmbh | Method and device for creating a localization map |
US11734473B2 (en) * | 2019-09-27 | 2023-08-22 | Zoox, Inc. | Perception error models |
US11625513B2 (en) * | 2019-09-27 | 2023-04-11 | Zoox, Inc. | Safety analysis framework |
US11351995B2 (en) | 2019-09-27 | 2022-06-07 | Zoox, Inc. | Error modeling framework |
US11694089B1 (en) * | 2020-02-04 | 2023-07-04 | Rockwell Collins, Inc. | Deep-learned photorealistic geo-specific image generator with enhanced spatial coherence |
US11126910B1 (en) | 2021-03-10 | 2021-09-21 | Samsara Inc. | Models for stop sign database creation |
US20220414068A1 (en) * | 2021-06-10 | 2022-12-29 | Aras Corporation | Federated service live data integration using a self-describing data model |
Citations (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN101952688A (en) * | 2008-02-04 | 2011-01-19 | 电子地图北美公司 | Method for map matching with sensor detected objects |
EP2721374B1 (en) * | 2011-06-14 | 2016-08-10 | Crown Equipment Limited | Method and apparatus for sharing map data associated with automated industrial vehicles |
US20170254665A1 (en) * | 2016-03-04 | 2017-09-07 | GM Gobal Technology Operations LLC | Progressive map maintenance at a mobile navigation unit |
CN107228676A (en) * | 2016-03-23 | 2017-10-03 | 赫力环球有限公司 | The map rejuvenation of vehicle platoon from connection |
CN107850453A (en) * | 2015-08-11 | 2018-03-27 | 大陆汽车有限责任公司 | Road data object is matched to generate and update the system and method for accurate transportation database |
Family Cites Families (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11113320B2 (en) * | 2014-12-19 | 2021-09-07 | Here Global B.V. | Versioned change propagation |
US11024160B2 (en) * | 2016-11-07 | 2021-06-01 | Nio Usa, Inc. | Feedback performance control and tracking |
US10031521B1 (en) * | 2017-01-16 | 2018-07-24 | Nio Usa, Inc. | Method and system for using weather information in operation of autonomous vehicles |
US10657804B2 (en) * | 2017-08-11 | 2020-05-19 | Here Global B.V. | Updating maps and road status |
US11068515B2 (en) * | 2018-07-24 | 2021-07-20 | Google Llc | Map uncertainty and observation modeling |
US11157007B2 (en) * | 2019-06-28 | 2021-10-26 | Lyft, Inc. | Approaches for encoding environmental information |
-
2019
- 2019-07-23 US US16/626,445 patent/US11068515B2/en active Active
- 2019-07-23 EP EP19755719.2A patent/EP3628085B1/en active Active
- 2019-07-23 CN CN201980003382.4A patent/CN110945498A/en active Pending
- 2019-07-23 WO PCT/US2019/043009 patent/WO2020023495A1/en unknown
-
2021
- 2021-06-21 US US17/352,783 patent/US11768863B2/en active Active
-
2023
- 2023-08-15 US US18/450,126 patent/US20230385310A1/en active Pending
Patent Citations (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN101952688A (en) * | 2008-02-04 | 2011-01-19 | 电子地图北美公司 | Method for map matching with sensor detected objects |
EP2721374B1 (en) * | 2011-06-14 | 2016-08-10 | Crown Equipment Limited | Method and apparatus for sharing map data associated with automated industrial vehicles |
CN107850453A (en) * | 2015-08-11 | 2018-03-27 | 大陆汽车有限责任公司 | Road data object is matched to generate and update the system and method for accurate transportation database |
US20170254665A1 (en) * | 2016-03-04 | 2017-09-07 | GM Gobal Technology Operations LLC | Progressive map maintenance at a mobile navigation unit |
CN107228676A (en) * | 2016-03-23 | 2017-10-03 | 赫力环球有限公司 | The map rejuvenation of vehicle platoon from connection |
Cited By (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
WO2022052283A1 (en) * | 2020-09-08 | 2022-03-17 | 广州小鹏自动驾驶科技有限公司 | Vehicle positioning method and device |
CN113963027A (en) * | 2021-10-28 | 2022-01-21 | 广州文远知行科技有限公司 | Uncertainty detection model training method and device, and uncertainty detection method and device |
CN113963027B (en) * | 2021-10-28 | 2022-09-09 | 广州文远知行科技有限公司 | Uncertainty detection model training method and device, and uncertainty detection method and device |
Also Published As
Publication number | Publication date |
---|---|
US20210311972A1 (en) | 2021-10-07 |
US20210133218A1 (en) | 2021-05-06 |
EP3628085A1 (en) | 2020-04-01 |
US20230385310A1 (en) | 2023-11-30 |
US11768863B2 (en) | 2023-09-26 |
EP3628085B1 (en) | 2021-07-07 |
WO2020023495A1 (en) | 2020-01-30 |
US11068515B2 (en) | 2021-07-20 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US11768863B2 (en) | Map uncertainty and observation modeling | |
US20230004874A1 (en) | Vehicle Map Service System | |
US11250051B2 (en) | Method, apparatus, and system for predicting a pose error for a sensor system | |
Wong et al. | Mapping for autonomous driving: Opportunities and challenges | |
US11501104B2 (en) | Method, apparatus, and system for providing image labeling for cross view alignment | |
US11590989B2 (en) | Training data generation for dynamic objects using high definition map data | |
US11024054B2 (en) | Method, apparatus, and system for estimating the quality of camera pose data using ground control points of known quality | |
US11170485B2 (en) | Method, apparatus, and system for automatic quality assessment of cross view feature correspondences using bundle adjustment techniques | |
US10949707B2 (en) | Method, apparatus, and system for generating feature correspondence from camera geometry | |
US20220028262A1 (en) | Systems and methods for generating source-agnostic trajectories | |
US11682124B2 (en) | Systems and methods for transferring map data between different maps | |
US11885625B1 (en) | Data fusion system | |
US20240013554A1 (en) | Method, apparatus, and system for providing machine learning-based registration of imagery with different perspectives | |
US20230358558A1 (en) | Method, apparatus, and system for determining a lane marking confusion index based on lane confusion event detections |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination |