KR20230169321A - Programmable accelerator for data-dependent and irregular operations - Google Patents
Programmable accelerator for data-dependent and irregular operations Download PDFInfo
- Publication number
- KR20230169321A KR20230169321A KR1020237038980A KR20237038980A KR20230169321A KR 20230169321 A KR20230169321 A KR 20230169321A KR 1020237038980 A KR1020237038980 A KR 1020237038980A KR 20237038980 A KR20237038980 A KR 20237038980A KR 20230169321 A KR20230169321 A KR 20230169321A
- Authority
- KR
- South Korea
- Prior art keywords
- memory
- data
- tile
- stream
- core
- Prior art date
Links
- 230000001419 dependent effect Effects 0.000 title claims abstract description 70
- 230000001788 irregular Effects 0.000 title claims abstract description 19
- 230000015654 memory Effects 0.000 claims abstract description 487
- 238000012545 processing Methods 0.000 claims description 182
- 239000013598 vector Substances 0.000 claims description 130
- 239000000872 buffer Substances 0.000 claims description 47
- 238000012546 transfer Methods 0.000 claims description 40
- 238000013528 artificial neural network Methods 0.000 claims description 24
- 238000010801 machine learning Methods 0.000 claims description 16
- 230000006399 behavior Effects 0.000 abstract description 4
- 238000013461 design Methods 0.000 abstract description 4
- 238000004519 manufacturing process Methods 0.000 abstract description 3
- 238000000034 method Methods 0.000 description 43
- 238000012384 transportation and delivery Methods 0.000 description 34
- 230000004044 response Effects 0.000 description 33
- 230000008569 process Effects 0.000 description 31
- 238000010586 diagram Methods 0.000 description 27
- 238000003860 storage Methods 0.000 description 16
- 239000011159 matrix material Substances 0.000 description 14
- 238000012549 training Methods 0.000 description 14
- 230000001133 acceleration Effects 0.000 description 12
- 230000006870 function Effects 0.000 description 12
- 238000011144 upstream manufacturing Methods 0.000 description 12
- 238000001914 filtration Methods 0.000 description 11
- 238000007792 addition Methods 0.000 description 10
- 238000004891 communication Methods 0.000 description 9
- 238000007667 floating Methods 0.000 description 9
- 241001522296 Erithacus rubecula Species 0.000 description 7
- 230000008901 benefit Effects 0.000 description 7
- 238000005516 engineering process Methods 0.000 description 7
- 230000000295 complement effect Effects 0.000 description 6
- 230000009471 action Effects 0.000 description 5
- 230000004888 barrier function Effects 0.000 description 5
- 238000004590 computer program Methods 0.000 description 4
- 238000005192 partition Methods 0.000 description 4
- 238000012358 sourcing Methods 0.000 description 4
- 230000008685 targeting Effects 0.000 description 4
- 230000003139 buffering effect Effects 0.000 description 3
- 238000004364 calculation method Methods 0.000 description 3
- 238000009826 distribution Methods 0.000 description 3
- 238000013459 approach Methods 0.000 description 2
- 238000003491 array Methods 0.000 description 2
- 230000005540 biological transmission Effects 0.000 description 2
- 238000004422 calculation algorithm Methods 0.000 description 2
- 238000012937 correction Methods 0.000 description 2
- 230000001934 delay Effects 0.000 description 2
- 230000000977 initiatory effect Effects 0.000 description 2
- 238000007726 management method Methods 0.000 description 2
- 238000013507 mapping Methods 0.000 description 2
- 238000003058 natural language processing Methods 0.000 description 2
- 230000009467 reduction Effects 0.000 description 2
- 238000000926 separation method Methods 0.000 description 2
- 239000007787 solid Substances 0.000 description 2
- 238000000638 solvent extraction Methods 0.000 description 2
- 208000004605 Persistent Truncus Arteriosus Diseases 0.000 description 1
- 208000037258 Truncus arteriosus Diseases 0.000 description 1
- 230000004913 activation Effects 0.000 description 1
- 239000008186 active pharmaceutical agent Substances 0.000 description 1
- 230000004931 aggregating effect Effects 0.000 description 1
- 238000004458 analytical method Methods 0.000 description 1
- 230000000903 blocking effect Effects 0.000 description 1
- 230000008859 change Effects 0.000 description 1
- 230000006835 compression Effects 0.000 description 1
- 238000007906 compression Methods 0.000 description 1
- 125000004122 cyclic group Chemical group 0.000 description 1
- 238000013499 data model Methods 0.000 description 1
- 230000003111 delayed effect Effects 0.000 description 1
- 238000012938 design process Methods 0.000 description 1
- 230000006872 improvement Effects 0.000 description 1
- 239000003999 initiator Substances 0.000 description 1
- 238000003780 insertion Methods 0.000 description 1
- 238000011835 investigation Methods 0.000 description 1
- 230000000873 masking effect Effects 0.000 description 1
- 230000007246 mechanism Effects 0.000 description 1
- 230000004048 modification Effects 0.000 description 1
- 238000012986 modification Methods 0.000 description 1
- 238000010606 normalization Methods 0.000 description 1
- 230000003287 optical effect Effects 0.000 description 1
- 230000008520 organization Effects 0.000 description 1
- 230000002085 persistent effect Effects 0.000 description 1
- 238000011176 pooling Methods 0.000 description 1
- 238000013515 script Methods 0.000 description 1
- 238000012163 sequencing technique Methods 0.000 description 1
- 230000003068 static effect Effects 0.000 description 1
- 230000001360 synchronised effect Effects 0.000 description 1
- 238000013519 translation Methods 0.000 description 1
- 230000000007 visual effect Effects 0.000 description 1
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F15/00—Digital computers in general; Data processing equipment in general
- G06F15/76—Architectures of general purpose stored program computers
- G06F15/80—Architectures of general purpose stored program computers comprising an array of processing units with common control, e.g. single instruction multiple data processors
- G06F15/8007—Architectures of general purpose stored program computers comprising an array of processing units with common control, e.g. single instruction multiple data processors single instruction multiple data [SIMD] multiprocessors
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F15/00—Digital computers in general; Data processing equipment in general
- G06F15/16—Combinations of two or more digital computers each having at least an arithmetic unit, a program unit and a register, e.g. for a simultaneous processing of several programs
- G06F15/163—Interprocessor communication
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/042—Knowledge-based neural networks; Logical representations of neural networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/045—Combinations of networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/0464—Convolutional networks [CNN, ConvNet]
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/098—Distributed learning, e.g. federated learning
Abstract
본 개시내용의 양태들은 데이터 의존적, 불규칙적 및/또는 메모리 바운드 오퍼레이션들을 가속화할 수 있는 가속기를 제공한다. 본원에 설명된 가속기는 설계 및 제작 동안 코프로세서에 대한 컴퓨팅 로드 및 거동을 예측할 수 있는 오퍼레이션들을 가속화하도록 구성된 코프로세서와 함께, 동적, 불규칙적 및/또는 메모리 바운드되는 컴퓨팅들을 칩 내에서 효율적으로 실행하기 위한 프로그래밍 가능한 엔진을 포함한다.Aspects of the present disclosure provide an accelerator that can accelerate data-dependent, irregular, and/or memory-bound operations. The accelerators described herein are designed to efficiently execute dynamic, irregular, and/or memory-bound computations within a chip, with a coprocessor configured to accelerate operations that can predict the computational load and behavior of the coprocessor during design and fabrication. Includes a programmable engine for
Description
[0001] 본 출원은 2022년 11월 7일에 출원된 미국 특허 출원 제17/981,617호의 연속 출원으로서, 이 출원은 2022년 6월 30일에 출원된 미국 가특허 출원 제63/357,281호, 2022년 3월 22일에 출원된 제63/322,285호, 2021년 11월 22일에 출원된 제63/281,960호, 2021년 11월 15일에 출원된 제63/279,262호의 출원일들의 이익을 주장하고, 그 개시내용들은 참조로 본원에 포함된다. 본 출원은 2022년 10월 25일에 출원된 미국 특허 출원 제17/972,681호, 2022년 10월 25일에 출원된 제17/972,663호, 및 2022년 4월 18일에 출원된 제17/722,782호에 관련되어 있으며, 그 개시내용들은 참조로 본원에 포함된다.[0001] This application is a continuation of U.S. Patent Application No. 17/981,617, filed on November 7, 2022, which is a continuation of U.S. Provisional Patent Application No. 63/357,281, filed on June 30, 2022 Claiming the benefit of the filing dates of No. 63/322,285 filed on March 22, 2021, No. 63/281,960 filed on November 22, 2021, and No. 63/279,262 filed on November 15, 2021, The disclosures are incorporated herein by reference. This application is related to U.S. Patent Application Nos. 17/972,681, filed on October 25, 2022, 17/972,663, filed on October 25, 2022, and 17/722,782, filed on April 18, 2022 and the disclosures thereof are incorporated herein by reference.
[0002] 하드웨어 가속은 소정 유형들의 오퍼레이션(operation)들을 보다 효율적으로 수행하기 위한 컴퓨터 하드웨어의 사용이다. 가속화될 수 있는 오퍼레이션들의 예시적인 유형들은 행렬 대 행렬 또는 행렬 대 벡터 곱셈과 같은 선형 대수 오퍼레이션들을 포함한다. 하드웨어 가속 오퍼레이션들을 수행하도록 구축된 디바이스들 또는 프로세서들은 가속기들로 지칭될 수 있다.[0002] Hardware acceleration is the use of computer hardware to perform certain types of operations more efficiently. Exemplary types of operations that can be accelerated include linear algebra operations such as matrix-to-matrix or matrix-to-vector multiplication. Devices or processors built to perform hardware accelerated operations may be referred to as accelerators.
[0003] 가속기들은 원하는 오퍼레이션들의 작은 서브세트를 가속화하도록 설계 및 제작되었다. 가속기의 설계 및 제작 프로세스 동안, 가속기가 수신하는 입력들의 크기 및 유형, 입력들이 가속기에 의해 수신되는 규칙성, 또는 오퍼레이션들을 수행하기 위한 컴퓨팅 요건들 같은 가속되어야 하는 오퍼레이션들의 성격에 대해 가정들이 이루어진다. 결과적으로, 가속기들은 고도로 전문화된 경우가 많고 미리 결정된 작은 클래스의 오퍼레이션들만이 가속될 수 있고, 있더라도 다른 오퍼레이션들을 효율적으로 실행할 수 없다.[0003] Accelerators are designed and built to accelerate a small subset of desired operations. During the design and manufacturing process of an accelerator, assumptions are made about the nature of the operations to be accelerated, such as the size and type of inputs the accelerator receives, the regularity with which inputs are received by the accelerator, or the computational requirements to perform the operations. As a result, accelerators are often highly specialized and can only accelerate a small, predetermined class of operations and, if present, cannot execute other operations efficiently.
[0004] 이 클래스 외부의 오퍼레이션들은 오퍼레이션이 실행되기 전에 가속기의 컴퓨팅 로드를 결정할 수 없는 데이터 의존 오퍼레이션들을 포함한다. 이러한 종류의 가속 오퍼레이션들의 다수의 인스턴스들은 다양한 요인들에 따라 달라질 수 있으므로, 미리 결정된 가속기 설계는 이러한 인스턴스들 중 적어도 일부를 가속하는 데 비효율적이다. 가속화하기 어려운 다른 종류들의 오퍼레이션들은 오퍼레이션 강도가 낮고 데이터 재사용이 제한된 메모리 바운드 오퍼레이션(memory-bound operation)들을 포함한다. 가속화하기 어려운 또 다른 종류의 오퍼레이션은 불규칙한 오퍼레이션들이고, 이는 랜덤 메모리 액세스들, 복잡한 코드 패턴들, 및 동시에 다수의 서브오퍼레이션들의 병렬 실행의 가변 사용을 특징으로 할 수 있다.[0004] Operations outside this class include data-dependent operations for which the computing load of the accelerator cannot be determined before the operation is executed. Since the multiple instances of these types of acceleration operations may depend on various factors, a predetermined accelerator design is ineffective in accelerating at least some of these instances. Other types of operations that are difficult to accelerate include memory-bound operations, which have low operation intensity and limited data reuse. Another type of operation that is difficult to accelerate is irregular operations, which can be characterized by variable use of random memory accesses, complex code patterns, and parallel execution of multiple suboperations simultaneously.
[0005] 실제로, 기계 학습 모델 훈련 또는 배치와 같은 프로세싱 파이프라인들은 다양한 상이한 종류들의 오퍼레이션들을 수행하는 것을 포함한다. 일부 종류들의 오퍼레이션들만 가속화하기 위해 파이프라인에 가속기들을 통합하고 하드웨어 가속 없이 디바이스들에 의존하여 다른 종류들의 오퍼레이션을 수행하는 것은 가속기들과 비가속기들 간의 링크들과 상호연결들에 허용할 수 없는 지연과 메모리 대역폭 스트레스를 부과하여, 전반적인 성능을 제한시킨다. 모든 유형들의 오퍼레이션들을 커버하는 가속기들을 설계하고 제작하는 것은 대부분의 경우들에서 불가능하거나 가능하지 않다. 데이터 의존적 오퍼레이션들은 가속화에 도움이 되지 않고 다른 유형들의 오퍼레이션들을 가속화하기 위한 물류 노력은 대응 가속기들을 설계, 제작 및 배치하는 데 투자할 가치가 없을 수 있다.[0005] In practice, processing pipelines, such as machine learning model training or deployment, involve performing a variety of different types of operations. Integrating accelerators in the pipeline to accelerate only some types of operations and relying on devices to perform other types of operations without hardware acceleration results in unacceptable delays in the links and interconnections between accelerators and non-accelerators. and imposes memory bandwidth stress, limiting overall performance. Designing and building accelerators that cover all types of operations is not possible or feasible in most cases. Data-dependent operations are not conducive to acceleration, and the logistics effort to accelerate other types of operations may not be worth the investment in designing, building, and deploying responsive accelerators.
[0006] 본 개시내용의 양태들은 데이터 의존적, 불규칙적 및/또는 메모리 바운드 오퍼레이션들을 가속화할 수 있는 가속기를 제공한다. 본원에 설명된 가속기는 설계 및 제작 동안 코프로세서에 대한 컴퓨팅 로드 및 거동을 예측할 수 있는 오퍼레이션들을 가속화하도록 구성된 코프로세서와 함께, 동적, 불규칙적 및/또는 메모리 바운드되는 컴퓨팅들을 칩 내에서 효율적으로 실행하기 위한 프로그래밍 가능한 엔진을 포함한다.[0006] Aspects of the present disclosure provide an accelerator that can accelerate data-dependent, irregular, and/or memory-bound operations. The accelerators described herein are designed to efficiently execute dynamic, irregular, and/or memory-bound computations within a chip, with a coprocessor configured to accelerate operations that can predict the computational load and behavior of the coprocessor during design and fabrication. Includes a programmable engine for
[0007] 동적 오퍼레이션들은 수행되는 컴퓨팅들이 데이터 또는 입력에 의존하는 오퍼레이션들이고, 이는 오퍼레이션들을 실행하기 전에 입력을 알 수 없는 것을 의미한다. 오퍼레이션들의 불규칙성은 랜덤 메모리 액세스들, 복잡한 코드 패턴들, 다양한 수량들의 컴퓨팅 자원들 및 상이한 입력 데이터에 대해 상이한 오퍼레이션들의 인스턴스들을 수행하는 데 필요한 병렬화로부터 발생할 수 있다. 메모리 바운드 오퍼레이션들은 종종 오퍼레이션 강도가 낮고, 예를 들어, 오퍼레이션들의 가속화 동안 전달된 데이터 단위당 수행되는 오퍼레이션들의 개수가 적고, 데이터 재사용이 제한되는 오퍼레이션들이다.[0007] Dynamic operations are operations in which the computations performed depend on data or input, meaning that the input is not known before executing the operations. Irregularity in operations may arise from random memory accesses, complex code patterns, varying quantities of computing resources, and the parallelism needed to perform instances of different operations on different input data. Memory bound operations are operations that often have low operation intensity, for example, the number of operations performed per unit of data delivered during acceleration of operations is small, and data reuse is limited.
[0008] 본원에 설명된 가속기는 다수의 가속기들 및 다른 프로세서들을 구현하는 호스트 디바이스 또는 데이터센터에서 가속을 스케일링하기 위해 상이한 크기들의 데이터의 칩 간 데이터 스캐터 및 수집 오퍼레이션(scatter and gather operation)들을 조율하고 분산할 수 있다. 본원에 설명된 바와 같이, 가속기는 가속기 자체를 구현하는 하드웨어 회로에 대한 물리적 재설계 또는 변경들을 요구하지 않고, 다양한 유형들의 데이터 의존적, 불규칙적 및/또는 메모리 바운드 오퍼레이션들의 가속에 적응하기 위해 구성 가능한 아키텍처 기본(primitive)들을 활용한다.[0008] The accelerator described herein uses inter-chip data scatter and gather operations of data of different sizes to scale acceleration in a data center or host device implementing multiple accelerators and other processors. It can be coordinated and distributed. As described herein, an accelerator is an architecture that is configurable to adapt to the acceleration of various types of data-dependent, irregular, and/or memory-bound operations without requiring physical redesign or changes to the hardware circuitry that implements the accelerator itself. Use primitives.
[0009] 본 개시내용의 양태들은 예를 들어 임베딩들 형태로 희소성을 나타내는 신경망 계층들의 컴퓨팅을 가속화할 수 있는 가속기를 제공한다. 희소 컴퓨팅은 컴퓨팅된 데이터 값들, 예를 들어, 입력, 출력 또는 중간의 분율이 0인 컴퓨팅을 의미한다. 분율은 예를 들어 0.1% 내지 50%로 다양할 수 있다. 본 개시내용의 양태들은 기계 학습 프로세싱 파이프라인의 일부로서 임베딩들의 훈련 및 프로세싱을 가속화하는 것을 제공한다.[0009] Aspects of the present disclosure provide an accelerator that can accelerate computing of neural network layers that exhibit sparsity, for example in the form of embeddings. Sparse computing refers to computing where the fraction of computed data values, e.g. input, output or intermediate, is zero. The fraction may vary, for example from 0.1% to 50%. Aspects of the present disclosure provide for accelerating training and processing of embeddings as part of a machine learning processing pipeline.
[0010] 본 개시내용의 양태는 프로세서를 제공한다. 프로세서는 복수의 타일(tile)들을 포함하고, 복수의 타일들 각각은 벡터 코어와 공유 소프트웨어 제어 스크래치패드 메모리(shared software-controlled scratchpad memory)의 슬라이스를 포함한다. 프로세서는 복수의 타일들에 태스크들을 디스패치(dispatch)하도록 구성된 스칼라 코어를 더 포함한다. 프로세서는 또한 복수의 타일들 및 스칼라 코어에 결합된 메모리를 포함한다.[0010] Aspects of the present disclosure provide a processor. The processor includes a plurality of tiles, each of which includes a vector core and a slice of shared software-controlled scratchpad memory. The processor further includes a scalar core configured to dispatch tasks to a plurality of tiles. The processor also includes memory coupled to a plurality of tiles and a scalar core.
[0011] 예에서, 각각의 타일은 독립적인 컴퓨팅들을 실행하도록 구성된다. 다른 예에서, 복수의 타일들 각각의 벡터 코어는 복수의 SIMD(single Instruction, Multiple Data: 단일 명령, 다중 데이터) 프로세싱 레인들을 포함한다. 또 다른 예에서, 복수의 타일들 중 다수의 타일들은 메인 메모리에 병렬로 메모리 요청들을 발행한다.[0011] In an example, each tile is configured to perform independent computations. In another example, the vector core of each of the plurality of tiles includes a plurality of SIMD (single instruction, multiple data) processing lanes. In another example, multiple tiles of the plurality of tiles issue memory requests to main memory in parallel.
[0012] 또 다른 예에서, 복수의 타일들 각각의 벡터 코어는 데이터 의존 어드레스 스트림들을 임의의 레벨의 메모리 계층에 생성하도록 구성된다. 또 다른 예에서, 각각의 데이터 의존 어드레스 스트림은 어드레스들의 시퀀스에 대응하며, 시퀀스의 어드레스들의 길이와 지정 값들은 데이터 의존적이며 런타임에만 알려진다. 또 다른 예에서, 복수의 타일들 각각의 벡터 코어는 마이크로아키텍처에 대한 데이터 의존 어드레스 스트림들의 성능 서비스를 분리하면서 데이터 의존 어드레스 스트림들을 표현하도록 구성된다. 또 다른 예에서, 마이크로아키텍처는 데이터 의존 어드레스 스트림들의 성능 서비스를 위한 스캐터-수집 엔진을 포함한다. 또 다른 예에서, 데이터 의존 어드레스 스트림들은 다중 어드레싱 모드, 런타임 구성가능 전달 크기 및 원자 산술 업데이트들을 사용한 간접 메모리 액세스를 포함한다.[0012] In another example, the vector core of each of the plurality of tiles is configured to generate data dependent address streams at any level of the memory hierarchy. In another example, each data-dependent address stream corresponds to a sequence of addresses, and the length and specification values of the addresses of the sequence are data-dependent and known only at run time. In another example, a vector core of each of the plurality of tiles is configured to represent data-dependent address streams while decoupling performance services of the data-dependent address streams for the microarchitecture. In another example, the microarchitecture includes a scatter-collect engine for performance servicing of data dependent address streams. In another example, data dependent address streams include indirect memory access using multiple addressing modes, runtime configurable transfer size, and atomic arithmetic updates.
[0013] 또 다른 예에서, 복수의 타일들 각각의 벡터 코어는 정적 크기 메모리 구역들에서 동적 크기 데이터 스트림들의 전달 및 액세스를 가능하게 하는 순환 버퍼 명령들을 포함한다. 또 다른 예에서, 프로세서는 동적 크기 데이터 스트림들의 런타임 버퍼 크기를 추적하도록 구성된 마이크로아키텍처를 더 포함한다. 또 다른 예에서, 복수의 타일들 각각의 벡터 코어는 타일-로컬 스크래치패드 메모리의 동일한 구역에 순서 없는 액세스들을 배제하지 않고 순차적 순환 선입선출(FIFO) 액세스들로서 로컬 스크래치패드 메모리의 런타임 구성 및 액세싱 구역들을 제공하도록 구성된다. 또 다른 예에서, 마이크로아키텍처와 연관하여 순차적 순환 FIFO 액세스들은 타일-로컬 스크래치패드 메모리의 정적 크기 구역들에서 동적 크기 데이터 의존 어드레스 스트림들을 가능하게 한다.[0013] In another example, the vector core of each of the plurality of tiles includes circular buffer instructions that enable transfer and access of dynamically sized data streams in statically sized memory regions. In another example, the processor further includes a microarchitecture configured to track runtime buffer size of dynamically sized data streams. In another example, the vector core of each of the plurality of tiles performs runtime configuration and accessing of the local scratchpad memory as sequential circular first-in-first-out (FIFO) accesses without excluding out-of-order accesses to the same region of the tile-local scratchpad memory. It is designed to provide areas. In another example, sequential cyclic FIFO accesses in conjunction with the microarchitecture enable dynamically sized data dependent address streams in static sized regions of tile-local scratchpad memory.
[0014] 또 다른 예에서, 각각의 타일은 데이터 스트림들의 발행, 페치(fetching), 추적 및 순서화를 관리하도록 구성된 스캐터-수집 엔진을 포함한다. 또 다른 예에서, 각각의 스캐터-수집 엔진은 타일당 이동 중인 적어도 256 개의 미해결 판독 요청들을 유지하도록 추가로 구성된다. 또 다른 예에서, 각각의 스캐터-수집 엔진은 흐름 제어를 관리하기 위해 버퍼 점유를 추적하고 업데이트하도록 추가로 구성된다.[0014] In another example, each tile includes a scatter-collect engine configured to manage publishing, fetching, tracking, and ordering of data streams. In another example, each scatter-collect engine is further configured to maintain at least 256 outstanding read requests in transit per tile. In another example, each scatter-collection engine is further configured to track and update buffer occupancy to manage flow control.
[0015] 또 다른 예에서, 복수의 타일들의 서브세트는 각각 데이터 스트림 명령들을 협력적으로 프리페치하도록 구성된 프리페치 유닛을 더 포함한다. 또 다른 예에서, 프로세서는 불규칙적 제어 흐름 시퀀스 또는 벡터 내 의존 오퍼레이션들 중 적어도 하나를 가속화하도록 구성된 교차 레인 프로세싱 유닛을 더 포함한다. 또 다른 예에서, 각각의 타일은 오프칩 메모리들에서 스크래치패드 메모리로의 스캐터들을 지원하고 스크래치패드 메모리에서 오프칩 메모리로 수집하도록 구성된다.[0015] In another example, the subset of the plurality of tiles each further includes a prefetch unit configured to cooperatively prefetch data stream instructions. In another example, the processor further includes a cross-lane processing unit configured to accelerate at least one of an irregular control flow sequence or dependent operations within the vector. In another example, each tile is configured to support and collect scatters from off-chip memories to scratchpad memory.
[0016] 또 다른 예에서, 복수의 타일들의 서브세트들은 논리적으로 구성 가능한 벡터 폭들에 기반하여 그룹화된다. 또 다른 예에서, 논리적으로 구성 가능한 벡터 폭들은 논리적 SIMD 폭을 포함한다.[0016] In another example, subsets of a plurality of tiles are grouped based on logically configurable vector widths. In another example, logically configurable vector widths include logical SIMD widths.
[0017] 또 다른 예에서, 프로세서는 의미론적 희소성을 나타내는 신경망 계층들을 실행하도록 구성된 기계 학습 가속기의 일부이다. 또 다른 예에서, 신경망 계층은 임베딩 또는 그래프 신경망을 포함한다. 또 다른 예에서, 프로세서는 동적, 불규칙적, 및 메모리 바운드인 신경망 계층 컴퓨팅들에 의해 요구되는 분산된 스캐터-수집 및 컴퓨팅을 수행하도록 구성된 네트워크를 통해 다수의 다른 프로세서들에 연결된다.[0017] In another example, the processor is part of a machine learning accelerator configured to execute neural network layers representing semantic sparsity. In another example, the neural network layer includes an embedding or graph neural network. In another example, a processor is coupled to a number of other processors through a network configured to perform distributed scatter-gathering and computing required by dynamic, random, and memory-bound neural network layer computations.
[0018] 도 1a는 본 개시내용의 양태들에 따라 데이터 의존 오퍼레이션들을 가속화하기 위한 하드웨어 회로의 블록도이다.
[0019] 도 1b는 본 개시내용의 양태들에 따라 하드웨어 회로의 일부로서 구현된 예시적인 데이터 경로들의 블록도이다.
[0020] 도 2는 본 개시내용의 양태들에 따른 하드웨어 회로를 구현하기 위한 예시적인 환경의 블록도이다.
[0021] 도 3a는 본 개시내용의 양태들에 따른 예시적인 타일의 블록도이다.
[0022] 도 3b는 본 개시내용의 양태들에 따라 스트림 전달들을 위한 XPU를 구현하는 다른 예시적인 타일의 블록도이다.
[0023] 도 4는 본 개시내용의 양태들에 따른 타일 시퀀서의 블록도이다.
[0024] 도 5는 본 개시내용의 양태들에 따른, 희소 가속기의 복수의 타일들에 걸쳐 메모리를 갖는 예시적인 스크래치패드 메모리의 블록도이다.
[0025] 도 6은 본 개시내용의 양태들에 따른 타일 시퀀서의 스칼라 코어 콤플렉스(complex)의 예시적인 블록도이다.
[0026] 도 7은 본 개시내용의 양태들에 따른 예시적인 XPU의 블록도이다.
[0027] 도 8은 본 개시내용의 양태들에 따른 스캐터-수집 엔진의 예시적인 기능 다이어그램이다.
[0028] 도 9는 본 개시내용의 양태들에 따라 스트림 디스크립터를 구성 오프-타일 스트림 요청 또는 타일-로컬 스트림 요청으로 언롤링(unrolling)하기 위한 예시적인 프로세스의 흐름도이다.
[0029] 도 10은 본 개시내용의 양태들에 따라 스트림 전송을 주문하기 위한 예시적인 프로세스의 흐름도이다.
[0030] 도 11은 본 개시내용의 양태들에 따른 스트림 순서의 예시적인 다이어그램이다.
[0031] 도 12는 본 개시내용의 양태들에 따른, 타일들 사이의 연결성과 예시적인 희소 가속기의 논리적 뷰를 예시한다.
[0032] 도 13은 본 개시내용의 양태들에 따른 명령 라우터의 추가적인 예시적인 양태들을 예시한다.[0018] FIG. 1A is a block diagram of a hardware circuit for accelerating data dependent operations in accordance with aspects of the present disclosure.
[0019] FIG. 1B is a block diagram of example data paths implemented as part of a hardware circuit in accordance with aspects of the present disclosure.
[0020] Figure 2 is a block diagram of an example environment for implementing hardware circuitry in accordance with aspects of the present disclosure.
[0021] Figure 3A is a block diagram of an example tile according to aspects of the present disclosure.
[0022] FIG. 3B is a block diagram of another example tile implementing an XPU for stream delivery in accordance with aspects of the present disclosure.
[0023] Figure 4 is a block diagram of a tile sequencer in accordance with aspects of the present disclosure.
[0024] Figure 5 is a block diagram of an example scratchpad memory with memory across a plurality of tiles of a sparse accelerator, in accordance with aspects of the present disclosure.
[0025] Figure 6 is an example block diagram of a scalar core complex of a tile sequencer in accordance with aspects of the present disclosure.
[0026] Figure 7 is a block diagram of an example XPU in accordance with aspects of the present disclosure.
[0027] Figure 8 is an example functional diagram of a scatter-collect engine in accordance with aspects of the present disclosure.
[0028] FIG. 9 is a flow diagram of an example process for unrolling a stream descriptor into a configured off-tile stream request or tile-local stream request in accordance with aspects of the present disclosure.
[0029] Figure 10 is a flow diagram of an example process for ordering stream transmission in accordance with aspects of the present disclosure.
[0030] Figure 11 is an example diagram of stream ordering according to aspects of the present disclosure.
[0031] Figure 12 illustrates a logical view of an example sparse accelerator and connectivity between tiles, in accordance with aspects of the disclosure.
[0032] Figure 13 illustrates additional example aspects of a command router in accordance with aspects of the present disclosure.
개요outline
[0033] 본 개시내용의 양태들은 데이터 의존적, 불규칙적 및/또는 메모리 바운드 오퍼레이션들을 가속화할 수 있는 가속기를 제공한다. 희소 입력에 대한 데이터 의존 오퍼레이션을 가속화하도록 구성된 가속기는 본원에서 희소 가속기라고 지칭될 수 있다. 희소 가속기는 임베딩들 또는 그래프 신경망(GNN)들과 같은 의미론적 희소성을 나타내는 신경망 계층들을 효율적이고 효과적으로 실행하도록 구성될 수 있다. 그래프 신경망들은 그래프들로 표현될 수 있는 데이터를 프로세싱하는 신경망들에 대응할 수 있다.[0033] Aspects of the present disclosure provide an accelerator that can accelerate data-dependent, irregular, and/or memory-bound operations. An accelerator configured to accelerate data-dependent operations on sparse input may be referred to herein as a sparse accelerator. A sparse accelerator may be configured to efficiently and effectively execute neural network layers that exhibit semantic sparsity, such as embeddings or graph neural networks (GNNs). Graph neural networks may correspond to neural networks that process data that can be represented as graphs.
[0034] 희소 가속기는 타일형 프로세서로 구성될 수 있다. 희소 가속기는 타일에 태스크들을 디스패치하는 데 사용되는 타일 시퀀서를 포함할 수 있다. 희소 가속기의 각각의 타일은 교차 레인 프로세싱 유닛(XPU)으로 강화된 벡터 코어와, 공유 소프트웨어 제어 스크래치패드 메모리의 슬라이스를 갖는다. 타일들과 시퀀서는 함께 고대역폭 메인 메모리에 연결될 수 있다.[0034] A sparse accelerator may be configured as a tiled processor. The sparse accelerator may include a tile sequencer used to dispatch tasks to tiles. Each tile of the sparse accelerator has a vector core powered by a cross-lane processing unit (XPU) and a slice of shared software-controlled scratchpad memory. Tiles and sequencer can be connected together to high bandwidth main memory.
[0035] 희소 가속기의 조직 및 구조는 본원에 설명된 상이한 특징들의 다양한 조합을 통해 데이터 의존적, 불규칙적 및/또는 메모리 바운드 오퍼레이션들의 개선을 제공한다. 가속기의 타일들은 데이터 의존적, 불규칙적 및/또는 메모리 바운드 오퍼레이션들이 있는 경우 이용 가능한 컴퓨팅을 보다 효율적으로 활용하기 위해 다음 특징들 중 하나 이상을 포함할 수 있다. 각각 타일의 교차 레인 프로세싱 유닛(XPU)은 일반적인 불규칙한 제어 흐름 시퀀스들 및/또는 벡터 내 의존 오퍼레이션들을 가속화한다. 각각의 XPU는 일반적인 벡터 내 의존 오퍼레이션들을 위한 맞춤형 빠른 데이터 경로들을 제공할 수 있다.[0035] The organization and structure of the sparse accelerator provides improvement of data dependent, irregular and/or memory bound operations through various combinations of different features described herein. Tiles of an accelerator may include one or more of the following features to more efficiently utilize available compute in the presence of data-dependent, irregular, and/or memory-bound operations. A cross-lane processing unit (XPU) in each tile accelerates common irregular control flow sequences and/or dependent operations within the vector. Each XPU can provide custom fast data paths for common intra-vector dependent operations.
[0036] 본원에 설명된 바와 같이 가속기에서 구현될 수 있는 다른 특징들은 협력적 프리페치, 스트림 명령들 및 순서화를 포함될 수 있다. 협력적 프리페치는 타일들에 걸쳐 명령 페치 대역폭 요건들을 감소시켜, 성능과 에너지 효율성을 향상시킨다. 본원에 설명된 스트림 명령들은 높은 대역폭에서 데이터 의존 스캐터-수집을 가능하게 한다. 가속기의 각각의 벡터 프로세싱 유닛은 높은 대역폭에서 메모리 계층의 모든 레벨에 대한 데이터 의존 어드레스를 생성할 수 있다.[0036] Other features that may be implemented in an accelerator as described herein may include cooperative prefetching, stream instructions, and ordering. Cooperative prefetching reduces instruction fetch bandwidth requirements across tiles, improving performance and energy efficiency. The stream instructions described herein enable data dependent scatter-collection at high bandwidth. Each vector processing unit in the accelerator can generate data-dependent addresses for all levels of the memory hierarchy at high bandwidth.
[0037] 타일-로컬 스캐터들 및 수집들은 데이터 불규칙성이 있는 경우에도 중단 없는 컴퓨팅을 가능하게 할 수 있다. 각각의 가속기 타일은 기본적으로 간접 벡터 로드들, 저장들 및 저장 추가들에 이용 가능한 명령들과 함께 명령 세트 아키텍처(ISA)에 의해 노출되는, 로컬 메모리에 대한 고성능 스캐터들 및 수집들을 지원할 수 있다.[0037] Tile-local scatters and collections can enable uninterrupted computing even in the presence of data irregularities. Each accelerator tile can support high-performance scatters and gathers to local memory, exposed by the Instruction Set Architecture (ISA), with instructions available for indirect vector loads, stores, and store additions by default.
[0038] 구현된 XPU들의 소프트웨어 제어 타일 그룹화는 제어 오버헤드들의 유연한 상각(amortization)을 제공할 수 있다. 소프트웨어는 타일들을 유연하게 그룹화하여 논리적으로 구성 가능한 벡터 폭들, 예를 들어, 논리적 SIMD 폭을 제시할 수 있다. 이는 동일한 그룹의 타일들에 걸쳐 중복 명령 페치를 방지하고, 타일들에 걸쳐 통합된 메모리 액세스를 인에이블하는 것과 같이 제어 오버헤드를 상각하는 데 도움이 될 수 있다. 이는 더 나은 대역폭 효율성을 초래할 수 있고, 예를 들어 고대역폭 메모리(HBM)는 상이한 액세스 입도들에서 상이한 대역폭 효율성을 가질 수 있다. 데이터 의존 오퍼레이션(또한 "입력 의존 오퍼레이션"으로 지칭됨)은 오퍼레이션을 수행하기 위한 컴퓨팅 작업량이 미리 알려지지 않지만 데이터의 특성에 의존하는 오퍼레이션이다. 데이터 의존 오퍼레이션들은 데이터 의존 어드레스 스트림으로 표현될 수 있고, 이는 시퀀스에 있는 어드레스들의 길이와 지정 값이 런타임에 알려진 어드레스들의 시퀀스에 대응한다. 예를 들어, 컴퓨팅 작업은 데이터 의존 오퍼레이션을 수행하는 데 필요한 오퍼레이션들의 개수 또는 프로세싱 사이클들로 측정될 수 있다. 예시적인 데이터 의존 오퍼레이션들은 벡터 정렬 오퍼레이션, 벡터 내의 중복 값들 카운팅, 다양한 길이들의 벡터들의 모양이나 크기를 조작하는 오퍼레이션들을 포함한다. 데이터 의존 오퍼레이션들은 불규칙한 데, 이는 적어도 상이한 입력들에 대해 동일한 유형의 오퍼레이션을 수행하기 위한 랜덤 메모리 액세스 패턴들의 차이들 때문이다. 결과적으로, 데이터 의존 오퍼레이션들은 컴퓨팅 작업이 입력 데이터의 모양, 정도 또는 희소성과 같은 특성에 기반하여 달라지지 않는 다른 유형들의 오퍼레이션들과 달리 성능을 최적화하기가 어렵다.[0038] Software-controlled tile grouping of implemented XPUs can provide flexible amortization of control overheads. Software can flexibly group tiles to present logically configurable vector widths, for example, logical SIMD widths. This can help amortize control overhead, such as avoiding redundant instruction fetches across tiles in the same group, and enabling unified memory accesses across tiles. This may result in better bandwidth efficiency, for example high bandwidth memory (HBM) may have different bandwidth efficiency at different access granularity. A data-dependent operation (also referred to as an “input-dependent operation”) is an operation in which the amount of computing work to perform the operation is not known in advance, but depends on the characteristics of the data. Data-dependent operations can be expressed as a data-dependent address stream, which corresponds to a sequence of addresses where the length and assignment values of the addresses in the sequence are known at runtime. For example, computing work can be measured by the number of operations or processing cycles required to perform a data-dependent operation. Exemplary data dependent operations include vector sorting operations, counting duplicate values within a vector, and operations manipulating the shape or size of vectors of various lengths. Data dependent operations are irregular, at least due to differences in random memory access patterns for performing the same type of operation on different inputs. As a result, data-dependent operations are difficult to optimize for performance, unlike other types of operations where the computing task does not vary based on characteristics such as the shape, extent, or sparsity of the input data.
[0039] 데이터 의존 오퍼레이션들은 희소 데이터에 대해 수행되는 오퍼레이션들을 포함한다. 데이터 구조의 희소성은 비어 있지 않은 엘리먼트와 비어 있는 엘리먼트의 비율 측정이다. 데이터 구조에 따라, 빈 엘리먼트는 0 이고, 엘리먼트에 대한 값이 없음을 나타내는 예약어이거나 또는 데이터 구조를 입력으로 사용하여 수행되는 오퍼레이션에 크게 기여하지 않는 것으로 간주될 정도로 작은 값을 가질 수 있다. 비어 있지 않은 엘리먼트들보다 비어 있는 엘리먼트가 더 많으면 데이터 구조는 희소하다. 일부 데이터 구조는 다른 데이터 구조들보다 다소 희소할 수 있다.[0039] Data-dependent operations include operations performed on sparse data. Sparsity of a data structure is a measure of the ratio of non-empty elements to empty elements. Depending on the data structure, an empty element may be 0, a reserved word indicating that there is no value for the element, or it may have a value so small that it is not considered to contribute significantly to the operation performed using the data structure as input. A data structure is sparse if it has more empty elements than non-empty elements. Some data structures may be more sparse than others.
[0040] 예시적인 데이터 의존 오퍼레이션들은 입력 훈련 예에 대한 임베딩을 생성하는 것을 포함한다. 임베딩은 벡터일 수 있거나, 임베딩보다 더 높은 차원을 갖는 입력으로부터 매핑된 일부 다른 데이터 구조일 수 있다. 임베딩 생성은 파이프라인에 따라 프로세싱되는 워크로드(workload)의 일부로 수행될 수 있다.[0040] Example data dependent operations include generating an embedding for an input training example. The embedding may be a vector, or some other data structure mapped from the input that has a higher dimension than the embedding. Embedding generation may be performed as part of the workload processed according to the pipeline.
[0041] 희소 가속기의 각각의 타일의 XPU는 또한 벡터 스캐터 또는 수집 오퍼레이션들, 세그먼트 합들 및/또는 텐서들과 같은 희소 데이터 구조들을 파티셔닝과 같은 다른 데이터 의존 오퍼레이션들을 수행할 수 있다. 본원에 설명된 XPU는 SIMD 병렬 프로세싱 패러다임에 따라 구축된 벡터 프로세싱 유닛과 같은 프로세서의 다른 컴포넌트들 또는 연결된 컴포넌트들에 대한 상보적 프로세싱 유닛일 수 있다. 하나 이상의 XPU들은 더 큰 프로세서의 각자의 프로세서 코어들에 연결될 수 있고, XPU 자체는 신경망들 훈련과 같은 소정 워크로드들의 성능을 가속화하기 위한 다른 컴포넌트들을 포함할 수 있다.[0041] The XPU of each tile of a sparse accelerator may also perform other data-dependent operations, such as vector scatter or gather operations, segment sums, and/or partitioning sparse data structures such as tensors. The XPU described herein may be a complementary processing unit to other components of the processor or connected components, such as a vector processing unit built according to the SIMD parallel processing paradigm. One or more XPUs may be connected to respective processor cores of a larger processor, and the XPU itself may include other components to accelerate performance of certain workloads, such as training neural networks.
[0042] 게다가, XPU는 소정 유형의 데이터 의존 오퍼레이션을 수행하는 것으로 제한되지 않으므로, 프로세서는 다수의 상이한 파이프라인들에 대한 다른 유형들의 프로세싱 유닛들을 보완하기 위해 XPU를 포함하도록 설계될 수 있다. XPU가 워크로드에 기반하여 구성될 수 있기 때문에, XPU의 물리적 풋프린트는 특수 회로들이 희소 데이터 컴퓨팅을 위한 보완 유닛들로서 프로세서에 물리적으로 제작되는 다른 접근법에 비해 감소된다. XPU의 기능은 또한 명령 세트의 사용 또는 호스트 프로세서의 기존 명령 세트에 대한 확장을 통해 확장될 수 있고, 파이프라인 데이터가 변경사항들을 수신함에 따라 상이한 데이터 의존 오퍼레이션들의 적응성을 더욱 개선시킬 수 있다. 명령들은 XPU의 개별 프로세싱 셀들과 크로스바들을 구성하기 위한 명령들의 변환을 담당하는 XPU의 컴포넌트들에 신호로 제공될 수 있다. XPU는 XPU를 구현하는 하드웨어 회로에 대해 대응 컴파일러에서 컴파일된 프로그램을 사용하여 구성될 수 있다.[0042] Furthermore, since an XPU is not limited to performing certain types of data-dependent operations, a processor may be designed to include an XPU to complement other types of processing units for multiple different pipelines. Because the XPU can be configured based on the workload, the physical footprint of the The functionality of the Instructions may be provided as signals to components of the XPU that are responsible for converting the instructions to configure the XPU's individual processing cells and crossbars. An XPU can be configured using programs compiled in a corresponding compiler for the hardware circuitry that implements the XPU.
[0043] 본 개시내용의 양태들은 적어도 다음과 같은 기술적 장점을 제공한다. 본원에 설명된 가속기는 일반적으로 런타임까지 피연산자들을 알 수 없는 데이터 의존 오퍼레이션들의 성능을 요구하는 대규모 기계 학습 모델의 스케일링 가능하고 분산된 훈련을 제공한다.[0043] Aspects of the present disclosure provide at least the following technical advantages. The accelerator described herein provides scalable, distributed training of large-scale machine learning models that require performance of data-dependent operations whose operands are typically unknown until runtime.
[0044] 가속기는 단독으로 또는 다른 프로세서들과 결합하여, 가속기에서 XPU를 구현하는 타일들의 유연한 오퍼레이션 구성들을 가능하게 하여, 태스크, 데이터, 파이프라인 및 모델 병렬화와 같은 다양한 형태의 병렬화를 달성한다. 태스크 레벨 병렬화에서, 각각의 타일은 독립적인 컴퓨팅(태스크)들을 병렬로 실행할 수 있다. 메모리 레벨 병렬화의 경우, 타일들은 고대역폭과 병렬로 메모리 요청들을 발행하여 이용 가능한 메모리 대역폭을 흡수할 수 있다. 이것은 희소 가속기가 상이한 태스크들에서 다양한 수량들의 작업을 핸들링하게 한다.[0044] The accelerator, alone or in combination with other processors, enables flexible operational configurations of tiles implementing an XPU in the accelerator, thereby achieving various forms of parallelization such as task, data, pipeline, and model parallelization. In task-level parallelism, each tile can execute independent computations (tasks) in parallel. In the case of memory-level parallelism, tiles can absorb available memory bandwidth by issuing memory requests in parallel with high bandwidth. This allows the sparse accelerator to handle varying quantities of work in different tasks.
[0045] 본원에 설명된 가속기는 데이터 의존 오퍼레이션들을 가속하도록 구성되지 않은 다른 가속기 또는 범용 프로세서와 함께 전용 코프로세서일 수 있다. 본원에 설명된 가속기는 데이터 의존 오퍼레이션들을 수행하기 위해 데이터를 검색하기 위해 호스트 메모리에 의존하는 접근법들에 비해, 예를 들어 증가된 프로세싱 속도로 성능 이득들을 실현하기 위해 희소 또는 다른 데이터 의존 컴퓨팅을 가속화할 수 있다.[0045] The accelerator described herein may be a dedicated coprocessor in conjunction with a general-purpose processor or another accelerator not configured to accelerate data-dependent operations. The accelerator described herein accelerates sparse or other data-dependent computing to realize performance gains, e.g., at increased processing speed, compared to approaches that rely on host memory to retrieve data to perform data-dependent operations. can do.
[0046] 본원에 설명된 가속기는 조밀하고 규칙적인 컴퓨팅을 수행하도록 구성된 코프로세서에 대한 아키텍처적 동맹자로서 기능할 수 있다. 별도의 프로세서에 통신 가능하게 결합된 본원에 설명된 프로그래밍 가능한 희소 가속기를 구현하는 것은 컴파일 시간에 예측할 수 없는 복잡성으로 오퍼레이션들을 가속화하기 위한 유연한 수단을 제공할 수 있다. 본원에 설명된 가속기는 복잡한 데이터 이동, 셔플링 및 요약을 통해 메모리 바운드 오퍼레이션들을 타겟으로 할 수 있다. 이런 유형의 오퍼레이션들은 스캐터-수집 오퍼레이션들, 필터링, 정렬, 유니쿼피케이션(uniquification) 등을 포함할 수 있다. 가속기는 컴파일러 스택, 예를 들어, 소스 코드를 가속기 및 그 코프로세서에 의해 실행 가능한 명령들로 변환하도록 구성된 컴파일러에 따라 타겟화될 수 있다. [0046] The accelerator described herein can function as an architectural ally to a coprocessor configured to perform dense, ordered computing. Implementing the programmable sparse accelerator described herein communicatively coupled to a separate processor can provide a flexible means for accelerating operations with unpredictable complexity at compile time. The accelerator described herein can target memory bound operations through complex data movement, shuffling and summarization. These types of operations may include scatter-collect operations, filtering, sorting, uniquification, etc. An accelerator may be targeted according to a compiler stack, e.g., a compiler configured to convert source code into instructions executable by the accelerator and its coprocessor.
[0047] 본원에 설명된 가속기는 임베딩 생성을 가속화할 수 있다. 임베딩 생성은 일반적으로 오퍼레이션 강도가 낮은 불규칙한 메모리 액세스들을 포함하는 것으로 특징지어질 수 있다. 이는 적어도 임베딩 생성을 위한 입력 벡터들의 희소하고 불규칙한 특성을 고려할 때, 임베딩 맵들 및 가변 폭 벡터 컴퓨팅을 나타내는 테이블들의 온칩 테이블 조회를 수행해야 하기 때문이다. 임베딩은 벡터 또는 다른 값들의 데이터 구조와 같은 이산 객체를 실수 값들과 같은 숫자 값들의 벡터에 매핑하는 것이다. 임베딩들은 일반적으로 대응 사전 임베딩 객체보다 차원과 복잡성이 낮다. 예를 들어, 영어로 된 하나 이상의 워드들에 대한 임베딩은 실수 값들의 벡터일 수 있다. 임베딩들은 사전 임베딩 입력의 잠재적으로 중요한 특징들을 나타내고 식별하는 데 사용될 수 있고, 예를 들어 2 개의 사전 임베딩 입력들 간의 유사성을 정량화하기 위해 상이한 워드들의 임베딩 사이의 거리를 측정하여 비교될 수 있다.[0047] The accelerator described herein can accelerate embedding generation. Embedding generation can generally be characterized as involving irregular memory accesses with low operation intensity. This is because, at least considering the sparse and irregular nature of the input vectors for embedding generation, on-chip table lookup of tables representing embedding maps and variable-width vector computing must be performed. Embedding is the mapping of a discrete object, such as a vector or other data structure of values, to a vector of numeric values, such as real values. Embeddings are generally of lower dimensionality and complexity than the corresponding dictionary embedding object. For example, the embedding for one or more words in English may be a vector of real values. Embeddings can be used to represent and identify potentially important features of a pre-embedding input and can be compared, for example by measuring the distance between embeddings of different words to quantify the similarity between two pre-embedding inputs.
[0048] 본원에 설명된 협력적 프리페치는 타일들에 걸쳐 명령 페치 대역폭 요건들을 감소시켜, 성능과 에너지 효율성을 향상시킨다. 가속기의 타일 아키텍처는 다중 프로그램, 다중 데이터 프로그래밍 모델을 노출하는 동시에, 단일 프로그램, 다중 데이터 모델에서 오퍼레이팅하는 구성 가능한 타일들의 서브세트를 추가로 제공한다.[0048] Cooperative prefetching described herein reduces instruction fetch bandwidth requirements across tiles, improving performance and energy efficiency. The accelerator's tile architecture exposes a multi-program, multi-data programming model while providing an additional configurable subset of tiles that operate on a single-program, multi-data model.
[0049] 본원에 설명된 스트림 명령들은 높은 대역폭에서 데이터 의존 스캐터 수집을 가능하게 한다. 가속기 각각의 벡터 프로세싱 유닛은 높은 대역폭에서 메모리 계층의 모든 레벨에 대한 데이터 의존 어드레스를 생성할 수 있다. 본원에 설명된 스트림 명령들은 소프트웨어에서 데이터 의존 액세스 패턴 표현을 허용하는 구조적으로, 예를 들어 ISA-, 가시적 구성을 제공한다. 이러한 액세스 패턴들은 다중 어드레싱 모드들, 구성 가능한 전달 크기 및 원자 오퍼레이션들을 포함한 간접 메모리 액세스를 포함한다. 스트림 명령들은 소프트웨어가 메모리 액세스들에 대한 "시작" 어드레스들, "크기들" 및 "시퀀스 패턴들"을 지정하게 한다. 이는 본 개시내용의 양태들에 따라 가속기의 각각의 타일이 데이터에 액세스하고 스캐터-수집 엔진을 사용하여 요청들을 서비스하기 위한 별도의 코어들을 구현하는 동안의 모든 것이다.[0049] The stream instructions described herein enable data dependent scatter collection at high bandwidth. Each vector processing unit in the accelerator can generate data-dependent addresses for all levels of the memory hierarchy at high bandwidth. The stream instructions described herein provide an architecturally, e.g., ISA-, visible construct that allows for the expression of data-dependent access patterns in software. These access patterns include multiple addressing modes, configurable transfer sizes and indirect memory access including atomic operations. Stream instructions allow software to specify “starting” addresses, “sizes” and “sequence patterns” for memory accesses. This is all while each tile of the accelerator implements separate cores to access data and service requests using a scatter-collect engine in accordance with aspects of the present disclosure.
[0050] 데이터는 어드레스 스트림의 어드레스들에 대응하는 데이터 값들인 데이터 스트림을 통해 프로세서의 상이한 컴포넌트들과 다른 오프칩 컴포넌트들을 통해 흐를 수 있다. 데이터 스트림은 스트림을 특성화하는 메타데이터를 제공하는 스트림 디스크립터를 가질 수 있다. 메타데이터의 일부로서, 데이터 스트림은 스트림이 현재 프로세싱되고 있는 프로세서의 실행 스레드를 식별하는 데 사용될 수 있는 스트림 식별자를 가질 수 있다. 다중 스트림들, 예를 들어, 8 개, 16 개 또는 32 개의 스트림들은 활성화되어 동시에 프로세서를 통해 흐를 수 있다.[0050] Data may flow through different components of the processor and other off-chip components through a data stream, where data values correspond to addresses in the address stream. A data stream may have a stream descriptor that provides metadata characterizing the stream. As part of the metadata, a data stream may have a stream identifier that can be used to identify the execution thread of the processor on which the stream is currently being processed. Multiple streams, for example 8, 16 or 32 streams, may be active and flowing through the processor simultaneously.
[0051] 본원에 설명된 순환 버퍼 명령들은 가변 크기 동적 데이터 스트림들을 가능하게 할 수 있다. 순환 버퍼 명령들은 컴파일 시간에 버퍼를 명시적으로 할당하지 않고, 소프트웨어가 정적으로 알 수 없는 크기의 데이터 스트림들을 페치하게 하는 아키텍처적으로, 예를 들어, ISA-, 가시적 구성들이다. 따라서 순환 버퍼 명령들은 정적 크기 메모리 구역들에서 동적 크기 데이터 스트림들의 전달 및 액세스를 가능하게 할 수 있다. 스캐터-수집 엔진은 상이한 데이터 스트림들의 런타임 버퍼 크기를 추적하고 흐름 제어를 관리한다. 순환 버퍼 명령들은 비FIFO 액세스 패턴들에서 소프트웨어를 배제하지 않고, 빠른 일반적인 경우를 위한 아키텍처 선입선출(FIFO) 추상화를 제공하는 데, 그 이유는 기본 메모리가 또한 표준 로드들 및 저장들을 통해서 액세스할 수 있기 때문이다. 다른 예에서, 복수의 타일들 각각의 벡터 코어는 타일-로컬 스크래치패드 메모리의 동일한 구역에 순서 없는 액세스들을 배제하지 않고 순차적 순환 선입선출(FIFO) 액세스들로서 로컬 스크래치패드 메모리의 런타임 구성 및 액세싱 구역들을 제공하도록 구성된다.[0051] The circular buffer instructions described herein may enable variable size dynamic data streams. Circular buffer instructions are architecturally, e.g., ISA-, visible constructs that allow software to statically fetch data streams of unknown size, without explicitly allocating a buffer at compile time. Circular buffer instructions may therefore enable transfer and access of dynamically sized data streams in statically sized memory regions. The scatter-collection engine tracks runtime buffer sizes of different data streams and manages flow control. Circular buffer instructions provide an architectural first-in-first-out (FIFO) abstraction for the general case that is fast, without precluding software from non-FIFO access patterns, since main memory can also be accessed via standard loads and stores. Because there is. In another example, the vector core of each of the plurality of tiles may perform runtime configuration and accessing regions of the local scratchpad memory as sequential circular first-in-first-out (FIFO) accesses without excluding out-of-order accesses to the same region of the tile-local scratchpad memory. It is designed to provide
[0052] 스트림 및 순환 버퍼 명령들은 필요한 경우 및 필요할 때 소프트웨어가 메모리에 "랜덤" 액세스하는 것을 방지하지 않으면서 일반적인 경우 FIFO 추상화를 허용한다. 소프트웨어는 버퍼들을 FIFO 페치할 수 있지만 필요한 경우 및 필요한 때 페치된 버퍼/창들 내에서 재사용하여 데이터에 다수 번 액세스할 수 있다. 이는 다수의 팝들을 요구하고 데이터를 재사용하기 위해 큐에 푸시하는 소프트웨어의 접근법과 대조된다. 이 제어는 소프트웨어가 프리페치들을 발행할 때와 스캐터-수집 엔진이 세부적으로 흐름 제어를 페치하고 수행하는 경우 사이의 균형을 유지한다. 소프트웨어는 스트림을 대략적으로 발행할 시기에 관하여 더 상위 비트 권한을 가지며, 본원에 설명된 바와 같이 스트림 순서 및 명령들을 구현하는 스캐터-수집 엔진은 지연시간, 버퍼 점유 등의 세부적인 변동들에 응답한다.[0052] Stream and circular buffer instructions allow for a FIFO abstraction in the general case without preventing software from “random” accessing memory when and where needed. Software can fetch buffers FIFO but access data multiple times by reusing within the fetched buffers/windows as and when needed. This contrasts with the software's approach of requiring multiple pops and pushing data to a queue for reuse. This control maintains a balance between when the software issues prefetches and when the scatter-collect engine fetches and performs detailed flow control. Software has higher-bit authority as to when to roughly publish a stream, and the scatter-collect engine, which implements stream ordering and instructions as described herein, responds to detailed variations in latency, buffer occupancy, etc. do.
[0053] 본원에 설명된 스캐터-수집 엔진과 같은 마이크로아키텍처는 성능이 불규칙한 메모리 액세스를 가능하게 한다. 스캐터-수집 엔진은 각각의 타일에서 구현되고 소프트웨어 정의 어드레스 스트림, 예를 들어, 스트림 명령들 및 순환 버퍼 명령들의 발행, 페치, 추적 및 순서화를 관리한다. 엔진은 타일당 이동 중인 판독 메모리 요청들의 개수, 예를 들어, 256 개의 요청들을 유지할 수 있다. 스캐터-수집 엔진은 레이트 제어 어드레스 요청들에 대한 버퍼 점유를 추적하고 업데이트한다. 소프트웨어는 개별 어드레스 요청들을 서비스할 때 지연시간 변동들을 명시적으로 관리할 필요 없이 아키텍처적으로 버퍼 점유를 조사할 수 있다.[0053] Microarchitectures such as the scatter-gather engine described herein enable memory accesses with erratic performance. A scatter-collect engine is implemented in each tile and manages issuing, fetching, tracking and ordering of software-defined address streams, such as stream instructions and circular buffer instructions. The engine can maintain a number of in-flight read memory requests per tile, for example 256 requests. The scatter-collect engine tracks and updates buffer occupancy for rate control address requests. Software can architecturally inspect buffer occupancy without having to explicitly manage latency variations when servicing individual address requests.
[0054] 스트림 명령들, 순환 버퍼 명령들 및 스캐터-수집 엔진의 조합은 분리된 액세스-실행을 가능하게 하고 불규칙한 메모리 액세스 스트림들을 포함하여 긴 메모리 액세스 지연시간을 효과적으로 높일 수 있다. 이것은 소프트웨어는 흐름 제어 및 요청들을 서비스하도록 구성된 스캐터-수집 엔진을 사용하여, 데이터 의존 메모리를 생성할 수 있는 유연성과 "대략적인" 입도로 메모리의 스케줄링 선택권을 제공한다.[0054] The combination of stream instructions, circular buffer instructions and scatter-collect engine enables decoupled access-execution and can effectively increase long memory access latency including irregular memory access streams. This provides the software the flexibility to create data-dependent memory using flow control and a scatter-gather engine configured to service requests, and the option of scheduling memory at a "coarse" granularity.
[0055] 본 개시내용의 양태들은 컴퓨팅 타일들의 세트에 걸쳐 동적 소형 벡터 태스크들의 다중 스레드들을 실행하도록 구성된 가속기를 제공한다. 동적 태스크들은 데이터 의존 제어 및 메모리 액세스와 관련된 태스크들을 포함한다. 작은 벡터 태스크들은 상대적으로 작은 벡터들, 예를 들어, 8 개의 엘리먼트 벡터들에서 수행되는 태스크들을 포함할 수 있다. 타일들은 시퀀서로 지칭되는 단일 태스크 관리 코어에 의해 관리된다. 가속기의 컴퓨팅 및 대역폭 비율들은 불규칙하고 희소한 액세스와 오프-프로세서 고대역폭 메모리에 저장된 대규모 데이터세트들의 컴퓨팅에 맞게 조정된다.[0055] Aspects of the present disclosure provide an accelerator configured to execute multiple threads of dynamic small vector tasks across a set of computing tiles. Dynamic tasks include tasks related to data dependent control and memory access. Small vector tasks may include tasks performed on relatively small vectors, for example, 8 element vectors. Tiles are managed by a single task management core called the sequencer. The accelerator's compute and bandwidth rates are tuned for irregular, sparse access and computing of large datasets stored in off-processor high-bandwidth memory.
[0056] 가속기는 각자의 액세스 코어와 실행 코어를 각각 포함하는 다중 타일들을 포함할 수 있다. 액세스 코어는 컴퓨팅에서 데이터 이동을 분리하는 데 사용되는 스칼라 유닛일 수 있다. 실행 코어는 대응 액세스 코어에 의해 페치된 데이터를 프로세싱하도록 구성된 다중 SIMD 레인들을 갖는 벡터 유닛에 첨부된 다른 스칼라 유닛일 수 있다. 각각의 타일은 또한 교차 레인 감소, 셔플, 정렬, 프리픽스-합계 등을 수행하기 위한 각자의 XPU를 포함할 수 있다. 가속기는 또한 타일들에 걸쳐 태스크 관리 및 다른 코일들과의 통신을 위한 스칼라 유닛일 수 있는 시퀀서를 포함할 수 있다. 가속기는 또한 스크래치패드 메모리, 예를 들어, 8 메가바이트의 공유 메모리를 포함할 수 있지만, 상이한 예들에서, 공유 메모리의 크기는 다를 수 있다. 본원에 설명된 바와 같이, 가속기는 스트리밍 메모리 액세스 인터페이스를 구현하여, 오프-타일 메모리에 대해 뛰어난 트랜잭션들을 유지할 수 있다. 가속기는 또한 타일들을 공유 스크래치패드 메모리뿐 아니라, 서로 연결하는 고대역폭 크로스바를 포함할 수 있다.[0056] An accelerator may include multiple tiles, each containing its own access core and execution core. An access core can be a scalar unit used to separate data movement from computing. An execution core may be another scalar unit attached to a vector unit with multiple SIMD lanes configured to process data fetched by a corresponding access core. Each tile may also include its own XPU to perform cross-lane reduction, shuffle, sort, prefix-sum, etc. The accelerator may also include a sequencer, which may be a scalar unit for task management across tiles and communication with other coils. The accelerator may also include scratchpad memory, for example 8 megabytes of shared memory, although in different examples the size of the shared memory may vary. As described herein, an accelerator implements a streaming memory access interface to be able to maintain superior transactions to off-tile memory. The accelerator may also include a high-bandwidth crossbar connecting the tiles to each other, as well as to a shared scratchpad memory.
예시적인 시스템들Exemplary Systems
[0057] 도 1a는 본 개시내용의 양태들에 따라 데이터 의존 오퍼레이션들을 가속화하기 위한 하드웨어 회로(101)의 블록도이다. 하드웨어 회로(101)는 희소 가속기(103), 코프로세서(104), 고대역폭 메모리(107) 및 온칩 상호연결(108)을 포함할 수 있다. 희소 가속기(103)는 하나 이상의 타일들(102A-F)을 포함할 수 있고, 각각의 타일은 각자의 벡터 프로세싱 유닛(VPU)을 구현하고 각자의 교차 레인 프로세싱 유닛(XPU)(101A-F)을 포함한다. 희소 가속기(103)는 타일들(102A-F)에 걸쳐 입력 및 출력 데이터를 조정하도록 구성된 타일 시퀀서(106)를 포함할 수 있다. 희소 가속기(103)의 일부로서 구현되는 예시적인 타일 개수들은 8 개, 16 개 또는 32 개 타일들을 포함할 수 있다.[0057] FIG. 1A is a block diagram of a hardware circuit 101 for accelerating data dependent operations in accordance with aspects of the present disclosure. Hardware circuitry 101 may include sparse accelerator 103, coprocessor 104, high-bandwidth memory 107, and on-chip interconnect 108. Sparse accelerator 103 may include one or more tiles 102A-F, each tile implementing a respective vector processing unit (VPU) and a respective cross-lane processing unit (XPU) 101A-F. Includes. Sparse accelerator 103 may include a tile sequencer 106 configured to coordinate input and output data across tiles 102A-F. Example tile numbers implemented as part of sparse accelerator 103 may include 8, 16, or 32 tiles.
[0058] 타일들(102A-F)은 예를 들어 다차원 링들 또는 토리(torii)와 같이 다양한 상이한 토폴로지들에 따라 상호연결될 수 있다. 상호연결은 예를 들어 크로스바를 포함할 수 있고, 이는 도 1b를 참조하여 더 상세히 설명된다. 프로세서에 대한 크로스바 또는 상호연결은 예를 들어 타일들(102A-F), 온칩 메모리 및 오프칩 메모리로부터 및 이들로 각각의 클록 사이클에 대한 데이터를 수신하고 방출할 수 있다.[0058] Tiles 102A-F may be interconnected according to a variety of different topologies, such as multidimensional rings or torii. The interconnection may include, for example, a crossbar, which is described in more detail with reference to FIG. 1B. A crossbar or interconnect to the processor may receive and emit data for each clock cycle to and from tiles 102A-F, on-chip memory, and off-chip memory, for example.
[0059] 타일 시퀀서(106)는 조율된 방식으로 타일들(102A-F)에 대한 오퍼레이션들을 수행하기 위한 명령들을 수신하고 분산하도록 구성된 희소 가속기(103)의 컴포넌트이다. 저율은 예를 들어, 상이한 유형들의 데이터 또는 명령 병렬화를 활용하기 위해 희소 가속기(103)의 프로세싱 컴포넌트들의 분산 관계를 활용함으로써 적어도 부분적으로 제어될 수 있다. 타일 시퀀서(106)는 도 4를 참조하여 더 상세히 설명된다.[0059] Tile sequencer 106 is a component of sparse accelerator 103 configured to receive and distribute instructions to perform operations on tiles 102A-F in a coordinated manner. The low rate can be controlled at least in part by exploiting the distributed relationships of the processing components of the sparse accelerator 103, for example, to exploit different types of data or instruction parallelism. Tile sequencer 106 is described in more detail with reference to FIG. 4 .
[0060] 희소 가속기(103)는 타일들(102A-F)을 사용하여 데이터 의존 오퍼레이션들을 수행하도록 구성된다. 도 3a를 참조하여 더 상세히 도시되고 설명된 바와 같이, 각각의 타일은 벡터 프로세싱 유닛(VPU)들 및 교차 레인 프로세싱 유닛(XPU)들을 통해 데이터를 스트리밍하기 위한 다수의 데이터 프로세싱 레인을 구현할 수 있다. 타일은 온칩 메모리(105)로부터 스트리밍된 데이터를 검색할 수 있고, 이는 메인 메모리, 캐시 또는 솔리드 스테이트 또는 하드 디스크 스토리지와 같은 영구 스토리지를 포함하는 다양한 상이한 메모리 디바이스들 중 임의의 메모리 디바이스일 수 있다. 스트리밍된 데이터는 또한 코프로세서(104), 코프로세서들(103 및 104) 중 하나 또는 둘 모두를 서비스하는 고대역폭 메모리(107), 및/또는 온칩을 상호연결(108)을 통해 하드웨어 회로(101)에 연결된 다른 데이터 소스로부터 검색될 수 있다.[0060] Sparse accelerator 103 is configured to perform data dependent operations using tiles 102A-F. As shown and described in more detail with reference to FIG. 3A, each tile may implement multiple data processing lanes for streaming data through vector processing units (VPUs) and cross lane processing units (XPUs). A tile may retrieve data streamed from on-chip memory 105, which may be any of a variety of different memory devices including main memory, cache, or persistent storage such as solid state or hard disk storage. Streamed data may also be transmitted to hardware circuitry 101 via coprocessor 104, high-bandwidth memory 107 serving one or both of coprocessors 103 and 104, and/or on-chip interconnection 108. ) can be retrieved from other data sources linked to the
[0061] 온칩 메모리(105)는 각각의 타일(102A-F)에 걸쳐 물리적으로 분산된 스크래치패드 메모리일 수 있다. 스크래치패드 메모리는 하드웨어 캐시와 달리, 소프트웨어 명령들에 따라 데이터를 저장하는 것과 같이 프로그래밍 방식으로 관리될 수 있다. 온칩 메모리(105)는 직접 메모리 액세스 및/또는 스트림 인터페이스들과 같은 다양한 상이한 인터페이스들을 통해 전역적으로 어드레싱될 수 있다.[0061] On-chip memory 105 may be scratchpad memory physically distributed across each tile 102A-F. Unlike hardware caches, scratchpad memory can be managed programmatically, storing data according to software instructions. On-chip memory 105 may be globally addressed through a variety of different interfaces, such as direct memory access and/or stream interfaces.
[0062] 코프로세서(104)는 CPU, 고밀도 코어 등과 같은 임의의 코어일 수 있다. 예를 들어, 코프로세서(104)는 행렬-행렬 곱셈, 행렬-벡터 곱셈 등과 같은 소정 오퍼레이션들의 가속을 위해 구성될 수 있다. 오퍼레이션들의 예들은 곱셈된 행렬들의 엘리먼트들 중 대부분, 예를 들어 일부 예들에서 50% 초과가 0이 아닌 값들을 갖는 조밀 행렬-행렬 컴퓨팅들을 포함할 수 있다. 컴퓨팅 복잡성은 곱셈된 행렬들의 차원들의 함수로 근사화될 수 있다. 일부 예들에서, 코프로세서(104)는 하드웨어 회로(101)의 나머지와 상이한 디바이스에 있고 온칩 상호연결(108)을 통해 하드웨어 회로에 데이터를 통신한다. 온칩 상호연결(108)은 데이터 버스 또는 다양한 통신 표준들 중 임의의 것, 예를 들어 PCIe에 따른 임의의 형태의 상호연결일 수 있다. 온칩 상호연결은 또한 코어 메모리 네트워크를 구현할 수 있다. 코어 메모리 네트워크는 코프로세서(104)와 희소 가속기(103)를 연결하는 온칩 네트워크일 수 있다.[0062] Coprocessor 104 may be any core, such as a CPU, high-density core, etc. For example, coprocessor 104 may be configured for acceleration of certain operations such as matrix-matrix multiplication, matrix-vector multiplication, etc. Examples of operations may include dense matrix-matrix computations where most, for example, in some examples more than 50%, of the elements of the multiplied matrices have non-zero values. Computational complexity can be approximated as a function of the dimensions of the multiplied matrices. In some examples, coprocessor 104 is in a different device than the remainder of hardware circuitry 101 and communicates data to the hardware circuitry via on-chip interconnect 108. The on-chip interconnect 108 may be a data bus or any form of interconnect according to any of a variety of communication standards, such as PCIe. On-chip interconnects can also implement core memory networks. The core memory network may be an on-chip network connecting the coprocessor 104 and the sparse accelerator 103.
[0063] 희소 가속기(103)의 예시적인 특징들은 희소 오퍼레이션들, 예를 들어 일반적으로 0이 아닌 값의 엘리먼트들보다 0의 값이 더 많은 피연산자들 또는 입력들에 대한 오퍼레이션들의 컴퓨팅을 개선하는 데 관한 것이다. 이러한 유형의 특징들은 여기에 더 상세히 설명된 바와 같이 프로그래밍 가능한 XPU(101A-101F)들, 협력 메모리 프리페치 및/또는 명령 스트림들 또는 명령 순서화를 사용하여 희소 오퍼레이션들을 수행하는 것의 조합을 포함할 수 있다.[0063] Exemplary features of sparse accelerator 103 are used to improve computing of sparse operations, e.g., operations on operands or inputs that typically have more zero-valued elements than non-zero-valued elements. It's about. Features of this type may include a combination of programmable XPUs 101A-101F, cooperative memory prefetching, and/or performing sparse operations using instruction streams or instruction ordering as described in more detail herein. there is.
[0064] 예들이 희소 컴퓨팅들의 맥락에서 제공되지만, 일부 예들에서 희소 가속기(103)가 벡터/행렬과 같은 선형 대수 오퍼레이션들, 활성화 함수 출력들의 계산, 계층 출력들의 풀링(pooling), 계층 출력들 정규화 등을 포함하여 기계 학습 모델 프로세싱의 가속화와 일반적으로 연관된 다른 유형들의 오퍼레이션들을 가속화하는 데 사용될 수 있음이 이해된다. 공통 하드웨어 회로(101)의 일부로 구현된 코프로세서(104) 및 희소 가속기(103)는 제한 없이, 2 가지 중 하나에 적합한 상이한 태스크들의 분산을 용이하게 할 수 있다. 비희소 오퍼레이션 가속화(non-sparse operation acceleration)는 비희소 입력에 대한 컴퓨팅들과 같은 조밀 컴퓨팅을 포함할 수 있다. 예시적인 조밀 컴퓨팅들은 어레이의 선형 또는 스트라이디드 액세스(strided access)를 포함할 수 있다. 다른 예들은 조밀 행렬 곱셈들, 완전 연결 계층들, 심층 신경망의 콘벌루션 계층들을 포함한다.[0064] Although examples are provided in the context of sparse computing, in some examples sparse accelerator 103 may perform linear algebra operations such as vector/matrix, computation of activation function outputs, pooling of layer outputs, and normalization of layer outputs. It is understood that it may be used to accelerate other types of operations commonly associated with acceleration of machine learning model processing, including, but not limited to, etc. Coprocessor 104 and sparse accelerator 103 implemented as part of a common hardware circuit 101 may facilitate distribution of different tasks suitable for either, without limitation. Non-sparse operation acceleration may include dense computing, such as computing on non-sparse input. Exemplary dense computing may include linear or strided access of the array. Other examples include dense matrix multiplications, fully connected layers, and convolutional layers of deep neural networks.
[0065] 하드웨어 회로(101)에 대한 예시적인 입력은 텐서로 구성된 데이터일 수 있다. 예를 들어, 텐서는 하드웨어 회로(101)를 사용하여 실행될 기계 학습 모델의 입력 데이터 및/또는 모델 파라미터 값들을 나타낼 수 있다. 텐서는 상이한 차원들의 다양한 다른 공통 데이터 구조 유형들을 일반화한 데이터 구조이다. 텐서는 0 개 이상의 엘리먼트들을 포함할 수 있고, 이는 정수들, 부동 소수점 값들, 부울 값들 등과 같은 하나 이상의 상이한 데이터 유형들일 수 있다. 각각의 데이터 유형 내에서, 데이터 유형은 소정 레벨의 정밀도, 예를 들어, 8 비트, 16 비트, 또는 32 비트 정수 또는 부동 소수점 값에 따라 파라미터화될 수 있다. 텐서의 차원은 "랭크"로 지칭된다. 랭크 0의 텐서는 또한 스칼라로 칭해지는 단일 엘리먼트이다. 랭크 1의 텐서는 또한 벡터로 칭해진다. 랭크 2의 텐서는 또한 행렬로 칭해진다. 벡터들과 행렬들은 또한 상이한 랭크들을 갖는 것으로 지칭될 수 있다. 예를 들어, 랭크 2의 벡터는 행렬과 동등하다. 0이 아닌 랭크의 텐서는 하나의 랭크 낮은 텐서들의 컬렉션으로 설명될 수 있다. 예를 들어, 벡터 또는 랭크 1은 스칼라 값들의 컬렉션이고, 랭크 2의 행렬은 랭크 1의 벡터들의 컬렉션이다.[0065] An exemplary input to the hardware circuit 101 may be data comprised of tensors. For example, a tensor may represent input data and/or model parameter values of a machine learning model to be executed using hardware circuitry 101. A tensor is a data structure that is a generalization of a variety of other common data structure types of different dimensions. A tensor may contain zero or more elements, which may be one or more different data types such as integers, floating point values, Boolean values, etc. Within each data type, the data type may be parameterized according to some level of precision, for example, an 8-bit, 16-bit, or 32-bit integer or floating point value. The dimension of a tensor is referred to as its "rank". A tensor of rank 0 is a single element, also called a scalar. A tensor of rank 1 is also called a vector. A tensor of rank 2 is also called a matrix. Vectors and matrices may also be referred to as having different ranks. For example, a vector of rank 2 is equivalent to a matrix. A non-zero rank tensor can be described as a collection of lower rank tensors. For example, a vector or rank 1 is a collection of scalar values, and a matrix of rank 2 is a collection of vectors of rank 1.
[0066] 하드웨어 회로(101)는 신경망을 훈련하기 위한 프로세싱 파이프라인을 적어도 부분적으로 구현할 수 있다. 파이프라인은 입력 훈련 예들에 대한 임베딩들의 생성을 포함할 수 있다. 상이한 입력 훈련 예들에 대한 특징 텐서들은 상이한 희소성 정도를 가질 것이고, 이는 대응 임베딩을 생성하는 데 필요한 컴퓨팅 작업량에 영향을 미친다. 희소 가속기(103)는 훈련 입력 예를 나타내는 특징 값들의 텐서를 수신하고 특징 텐서보다 낮은 랭크를 갖는 텐서로서 임베딩을 생성하도록 구성될 수 있다.[0066] The hardware circuit 101 may at least partially implement a processing pipeline for training a neural network. The pipeline may include generation of embeddings for input training examples. Feature tensors for different input training examples will have different degrees of sparsity, which affects the amount of computing work required to generate the corresponding embeddings. Sparse accelerator 103 may be configured to receive a tensor of feature values representing training input examples and generate an embedding as a tensor with a lower rank than the feature tensor.
[0067] 임베딩들을 생성하기 위해, 희소 가속기(103)는 XPU(101A-F)들, 또는 더 일반적으로는 VPU들에서 효율적인 희소 데이터 컴퓨팅을 위한 다양한 데이터 의존 오퍼레이션들을 구현하도록 구성된다. 이러한 오퍼레이션들은 희소 벡터들 정렬 또는 합산, 입력 벡터들의 콘텐츠를 요약하는 오퍼레이션들, 하나의 희소 행렬 저장 포맷에서 다른 희소 행렬 저장 포맷으로 변환하는 오퍼레이션들을 포함한다.[0067] To generate embeddings, sparse accelerator 103 is configured to implement various data-dependent operations for efficient sparse data computing on XPUs 101A-F, or more generally on VPUs. These operations include sorting or summing sparse vectors, operations summarizing the content of input vectors, and operations converting from one sparse matrix storage format to another sparse matrix storage format.
[0068] 데이터 의존 오퍼레이션들의 성능을 가속화하기 위한 물리적으로 미리 결정된 회로들 대신, XPU들(101A-F)을 포함하는 VPU들은 다양한 상이한 데이터 의존 오퍼레이션들을 수행하도록 구성, 예를 들어 프로그래밍될 수 있다. 희소 가속기(103)는 희소 데이터 프로세싱의 일반화된 지원을 허용함과 동시에, 상보적 코프로세서(104)가 다른 유형들의 오퍼레이션들을 여전히 수행하게 한다.[0068] Instead of physically predetermined circuits to accelerate performance of data-dependent operations, VPUs, including XPUs 101A-F, may be configured, eg, programmed, to perform a variety of different data-dependent operations. Sparse accelerator 103 allows generalized support of sparse data processing while still allowing complementary coprocessor 104 to perform other types of operations.
[0069] 하드웨어 회로(101)는 중앙 프로세싱 유닛(CPU), 그래픽 프로세싱 유닛(GPU), 필드 프로그래밍 가능 게이트 어레이(FPGA) 또는 텐서 프로세싱 유닛(TPU)과 같은 주문형 집적 회로(ASIC)와 같은 다양한 상이한 유형들의 프로세싱 유닛들 중 어느 하나일 수 있다. 하드웨어 회로(101)는 컴퓨팅 디바이스에서 구현될 수 있고, 그 자체는 하나 이상의 디바이스들의 시스템의 일부일 수 있다.[0069] Hardware circuitry 101 may be implemented with a variety of different components, such as a central processing unit (CPU), a graphics processing unit (GPU), an application specific integrated circuit (ASIC), such as a field programmable gate array (FPGA), or a tensor processing unit (TPU). It may be any one of the types of processing units. Hardware circuit 101 may be implemented in a computing device and may itself be part of a system of one or more devices.
[0070] 도 1b는 본 개시내용의 양태들에 따라 하드웨어 회로의 일부로서 구현된 예시적인 데이터 경로들의 블록도이다. 스크래치패드 메모리(162B) 및 태스크 명령 메모리(160B)는 온칩 메모리(105)의 일부를 형성할 수 있다.[0070] FIG. 1B is a block diagram of example data paths implemented as part of a hardware circuit in accordance with aspects of the present disclosure. Scratchpad memory 162B and task instruction memory 160B may form part of on-chip memory 105.
[0071] 다양한 데이터 경로들(150B, 152B, 154B, 및 156B)이 예시되어 있다. 이러한 데이터 경로들은 스크래치패드 메모리(162B)의 DMA를 위해 타일 시퀀서(106)와 타일들(102A-F) 사이의 회로 상호연결들을 포함하는 직접 메모리 액세스(DMA) 경로(150B)를 물리적으로 공유하거나 공유하지 않을 수 있다. 명령 데이터 경로(152B)는 타일들(102A-F), 태스크 명령 메모리(160B), 스크래치패드 메모리(162B) 및 메모리 전송 인터페이스(163B) 사이의 회로 상호연결들을 포함한다. 스크래치패드(spmem) 데이터 경로(154B)는 태스크 명령 메모리(160B)에서 타일들(102A-F)까지의 데이터에 대한 잠재적인 경로를 도시한다. 타일 시퀀서(106)와 타일들(102A-F) 사이의 제어 데이터 경로는 타일 시퀀서(106)에 의해 생성된 제어 신호들에 대한 예시적인 경로를 도시한다. 제어 신호들은 타일들(102A-F)에 의해 수신될 때, 타일들이 제어 신호들에 의해 지정된 하나 이상의 함수들에 따라 데이터 판독, 데이터 쓰기 및/또는 데이터 프로세싱과 같은 하나 이상의 기본 또는 복합 오퍼레이션들을 수행하게 할 수 있다.[0071] Various data paths 150B, 152B, 154B, and 156B are illustrated. These data paths either physically share a direct memory access (DMA) path 150B that includes circuit interconnections between tiles 102A-F and tile sequencer 106 for DMA of scratchpad memory 162B. You may not share it. Instruction data path 152B includes circuit interconnections between tiles 102A-F, task instruction memory 160B, scratchpad memory 162B, and memory transfer interface 163B. Scratchpad (spmem) data path 154B illustrates a potential path for data from task instruction memory 160B to tiles 102A-F. The control data path between tile sequencer 106 and tiles 102A-F shows an example path for control signals generated by tile sequencer 106. When the control signals are received by the tiles 102A-F, the tiles perform one or more basic or complex operations, such as reading data, writing data, and/or processing data, according to one or more functions specified by the control signals. You can do it.
[0072] 태스크 명령 메모리(160B)는 타일들(102A-F)에 의해 공유된다. 태스크 명령 메모리(160B)는 타일 액세스 코어 및 타일 실행 코어에 의해 실행될 수 있는 프로그램들을 보유한다. 일부 예들에서, 태스크 명령 메모리(160B)는 468 비트 폭이고 16,000 워드 깊이이고, 예를 들어 에러 정정 코드들을 포함하여 2,000 워드의 뱅크들로 구성될 수 있다. 다수의 뱅크들은 블록 사이클당 태스크 명령 메모리(160B)에 대한 다수의 판독들 또는 쓰기들을 허용한다. 태스크 명령 메모리(160B)에 대한 DMA 디스크립터는 64 바이트들의 배수들의 길이 필드를 포함할 수 있다. 명령 번들들은 고대역폭 메모리에 저장될 때 최상위 비트부터 512 비트 경계까지 제로 패딩될 수 있다. 희소 가속기(103)는 태스크 명령 메모리(160B)에 쓰기 전에 패딩된 비트를 드롭할 수 있다. 각각의 DMA 디스크립터는 하나의 태스크 명령 메모리 번들을 전달할 수 있다.[0072] Task instruction memory 160B is shared by tiles 102A-F. Task instruction memory 160B holds programs that can be executed by the tile access core and tile execution core. In some examples, task instruction memory 160B may be 468 bits wide and 16,000 words deep, and may be comprised of banks of 2,000 words, including error correction codes, for example. Multiple banks allow multiple reads or writes to task instruction memory 160B per block cycle. The DMA descriptor for task instruction memory 160B may include a length field in multiples of 64 bytes. Instruction bundles can be zero-padded from the most significant bit to a 512-bit boundary when stored in high-bandwidth memory. Sparse accelerator 103 may drop padded bits before writing to task instruction memory 160B. Each DMA descriptor can carry one task instruction memory bundle.
[0073] 타일 시퀀서(106)는 태스크들을 타일에 디스패치하고/하거나 DMA 전달을 개시하는 것을 주로 담당하는 스칼라 코어일 수 있다. 예를 들어, 타일 시퀀서는 명령들을 번들들로 수신할 수 있다. 번들의 명령들은 타일들(102A-F)에 걸쳐 병렬로 실행될 수 있고 아키텍처 상태를 동시에 업데이트할 수 있다. 번들이 실행되면, 번들의 명령들이 실행되기 전에 스칼라 또는 벡터 문제를 겪는다. 스칼라 또는 벡터 문제는 각각의 스칼라 명령에 대한 홀드 스칼라 문제 또는 각각의 벡터 명령에 대한 홀드 벡터 문제 하에 문서화된 다양한 조건들로 인해 하나 이상의 사이클들 동안 보류될 수 있다. 희소 가속기(103)에 대한 ISA는 번들들을 무조건적으로 홀딩할 수 있는 글로벌 스칼라 홀드 문제 조건들 또는 글로벌 벡터 홀드 문제 조건들의 개수를 정의할 수 있다. 스칼라 문제 또는 벡터 문제 동안, 다수의 조치들이 수행될 수 있다. 번들에 대한 조건자가 평가되고 업데이트된다. 사용될 레지스터들의 값을 기록될 수 있다. 명령의 분기가 수행될 수 있고, 레지스터들은 업데이트된다.[0073] The tile sequencer 106 may be a scalar core primarily responsible for dispatching tasks to tiles and/or initiating DMA transfers. For example, a tile sequencer can receive instructions in bundles. The instructions in the bundle may be executed in parallel across tiles 102A-F and update the architectural state simultaneously. When a bundle is executed, the instructions in the bundle experience scalar or vector problems before they are executed. A scalar or vector problem may be held for one or more cycles due to various conditions documented under Hold Scalar Problem for Each Scalar Instruction or Hold Vector Problem for Each Vector Instruction. The ISA for the sparse accelerator 103 may define the number of global scalar hold problem conditions or global vector hold problem conditions that can unconditionally hold bundles. During a scalar or vector problem, a number of actions can be performed. Predicates for the bundle are evaluated and updated. The values of the registers to be used can be recorded. A branch of an instruction can be performed and registers updated.
[0074] 태스크 명령 메모리의 뱅크들은 다음 인터페이스들 중 하나 이상을 구현할 수 있다. 각각의 뱅크는 프리페치 요청과 프리페치 응답 브로드캐스트 버스를 포함할 수 있다. 프리페치 요청 및 응답 버스 아키텍처는 SPMD(단일 프로그램, 다중 데이터) 오퍼레이션 모드에 맞게 조정된다. 판독 응답은 프리페치 응답 브로드캐스트 버스의 모든 타일들에 브로드캐스트될 수 있다. 번들 브로드캐스트는 하드웨어가 가능한 경우 다른 타일에서 발생하는 요청들을 복제하고 전체 대역폭 수요를 줄일 수 있다.[0074] Banks of task instruction memory may implement one or more of the following interfaces. Each bank may include a prefetch request and prefetch response broadcast bus. The prefetch request and response bus architecture is tailored to the SPMD (single program, multiple data) mode of operation. The read response may be broadcast to all tiles on the prefetch response broadcast bus. Bundle broadcasts can duplicate requests originating from different tiles if the hardware is capable and reduce overall bandwidth demand.
[0075] 도 2는 하드웨어 회로(101)를 구현하기 위한 예시적인 환경(200)의 블록도이다. 하드웨어 회로(101)는 서버 컴퓨팅 디바이스(215)와 같이 하나 이상의 위치들에 하나 이상의 프로세서들을 갖는 디바이스에서 구현될 수 있다. 사용자 컴퓨팅 디바이스(212) 및 서버 컴퓨팅 디바이스(215)는 네트워크(260)를 통해 하나 이상의 저장 디바이스들(230)에 통신 가능하게 결합될 수 있다. 저장 디바이스(들)(230)는 휘발성 및 비휘발성 메모리의 조합일 수 있고 컴퓨팅 디바이스들(212, 215)과 동일하거나 다른 물리적 위치들에 있을 수 있다. 예를 들어, 저장 디바이스(들)(230)는 하드 드라이브, 솔리드 스테이트 드라이브, 테이프 드라이브, 광학 스토리지, 메모리 카드, ROM, RAM, DVD, CD-ROM, 쓰기 가능 및 판독 전용 메모리 같은 정보를 저장할 수 있는 임의의 유형의 비일시적 컴퓨터 판독가능 매체를 포함할 수 있다.[0075] Figure 2 is a block diagram of an example environment 200 for implementing hardware circuit 101. Hardware circuit 101 may be implemented in a device having one or more processors in one or more locations, such as server computing device 215. User computing device 212 and server computing device 215 may be communicatively coupled to one or more storage devices 230 via network 260 . Storage device(s) 230 may be a combination of volatile and non-volatile memory and may be in the same or different physical locations as computing devices 212, 215. For example, storage device(s) 230 may store information such as hard drives, solid state drives, tape drives, optical storage, memory cards, ROM, RAM, DVD, CD-ROM, writable and read-only memory. It may include any type of non-transitory computer-readable media.
[0076] 서버 컴퓨팅 디바이스(215)는 하나 이상의 프로세서들(213) 및 메모리(214)를 포함할 수 있다. 메모리(214)는 프로세서(들)(213)에 의해 실행될 수 있는 명령들(221)을 포함하여 프로세서(들)(213)에 의해 액세스 가능한 정보를 저장할 수 있다. 메모리(214)는 또한 프로세서(들)(213)에 의해 검색, 조작 또는 저장될 수 있는 데이터(223)를 포함할 수 있다. 메모리(214)는 휘발성 및 비휘발성 메모리와 같이 프로세서(들)(213)에 의해 액세스 가능한 정보를 저장할 수 있는 비일시적 컴퓨터 판독가능 매체 유형일 수 있다. 프로세서(들)(213)는 하나 이상의 중앙 프로세싱 유닛(CPU)들, 그래픽 프로세싱 유닛(GPU)들, 필드 프로그래밍 가능 게이트 어레이(FPGA)들, 및/또는 텐서 프로세싱 유닛(TPU)들과 같은 주문형 집적 회로(ASIC)들을 포함할 수 있다. 프로세서(들)(213)는 도 1a-도 1b를 참조하여 본원에 설명된 바와 같이 하드웨어 회로의 일부로서 구현된 코프로세서 및 희소 가속기를 포함할 수 있다.[0076] Server computing device 215 may include one or more processors 213 and memory 214. Memory 214 may store information accessible by processor(s) 213, including instructions 221 that may be executed by processor(s) 213. Memory 214 may also include data 223 that can be retrieved, manipulated, or stored by processor(s) 213. Memory 214 may be any type of non-transitory computer-readable media that can store information accessible by processor(s) 213, such as volatile and non-volatile memory. Processor(s) 213 may include one or more custom integrated processors, such as central processing units (CPUs), graphics processing units (GPUs), field programmable gate arrays (FPGAs), and/or tensor processing units (TPUs). May include circuits (ASIC). Processor(s) 213 may include a sparse accelerator and a coprocessor implemented as part of hardware circuitry as described herein with reference to FIGS. 1A-1B.
[0077] 명령들(221)은 프로세서(들)(213)에 의해 실행될 때, 하나 이상의 프로세서들이 명령들에 의해 정의된 액션들을 수행하게 하는 하나 이상의 명령들을 포함할 수 있다. 명령들(221)은 프로세서(들)(213)에 의한 직접 프로세싱을 위한 객체 코드 포맷으로 저장될 수 있거나, 요구 시 해석되거나 미리 컴파일되는 해석 가능한 스크립트들 또는 독립적인 소스 코드 모듈들의 컬렉션을 포함하는 다른 포맷들로 저장될 수 있다. 명령들(221)은 본 개시내용의 양태들과 일치하는 스트림 전달을 구성하기 위한 명령들을 포함할 수 있다. 서버 컴퓨팅 디바이스(215) 및/또는 사용자 컴퓨팅 디바이스(212)는 회로의 타일들을 구성하기 위한 제어 신호들로서 명령들을 생성하여 하드웨어 회로(101)에 전송하기 위한 컴파일러 또는 다른 프로그램을 구현할 수 있다.[0077] Instructions 221 may include one or more instructions that, when executed by processor(s) 213, cause one or more processors to perform actions defined by the instructions. Instructions 221 may be stored in object code format for direct processing by processor(s) 213, or may include a collection of interpretable scripts or independent source code modules that are interpreted on demand or precompiled. Can be saved in different formats. Instructions 221 may include instructions for configuring stream delivery consistent with aspects of the present disclosure. Server computing device 215 and/or user computing device 212 may implement a compiler or other program to generate and transmit instructions to hardware circuit 101 as control signals for configuring tiles of the circuit.
[0078] 데이터(223)는 명령들(221)에 따라 프로세서(들)(213)에 의해 검색, 저장 또는 수정될 수 있다. 데이터(223)는 컴퓨터 레지스터들에 저장될 수 있고, 관계형 또는 비관계형 데이터베이스에 복수의 상이한 필드들 및 기록들을 갖는 테이블로 저장되거나, JSON, YAML, proto 또는 XML 문서들로 저장될 수 있다. 데이터(223)는 또한 이진 값들, ASCII 또는 유니코드와 같은(이에 제한되지 않음) 컴퓨터 판독가능 포맷으로 포맷화될 수 있다. 게다가, 데이터(223)는 숫자들, 설명 텍스트, 독점 코드들, 포인터들, 다른 네트워크 위치들을 포함하여 다른 메모리들에 저장된 데이터에 대한 참조, 또는 관련 데이터를 계산하기 위해 기능에 의해 사용되는 정보와 같은 관련 정보를 식별하는 데 충분한 정보를 포함할 수 있다.[0078] Data 223 may be retrieved, stored, or modified by the processor(s) 213 according to instructions 221. Data 223 may be stored in computer registers, as a table with multiple different fields and records in a relational or non-relational database, or as JSON, YAML, proto, or XML documents. Data 223 may also be formatted in a computer-readable format, such as, but not limited to, binary values, ASCII, or Unicode. Additionally, data 223 may contain numbers, descriptive text, proprietary codes, pointers, references to data stored in other memories, or information used by a function to calculate related data, including other network locations. It may contain sufficient information to identify the same related information.
[0079] 사용자 컴퓨팅 디바이스(212)는 또한 하나 이상의 프로세서들(216), 메모리(217), 명령들(218) 및 데이터(219)를 갖는 서버 컴퓨팅 디바이스(215)와 유사하게 구성될 수 있다. 사용자 컴퓨팅 디바이스(212)는 또한 사용자 출력(226) 및 사용자 입력(224)을 포함할 수 있다. 사용자 입력(224)은 키보드, 마우스, 기계식 액추에이터들, 소프트 액추에이터들, 터치스크린들, 마이크들 및 센서들과 같이 사용자로부터 입력을 수신하기 위한 임의의 적절한 메커니즘 또는 기법을 포함할 수 있다.[0079] User computing device 212 may also be configured similarly to server computing device 215 with one or more processors 216, memory 217, instructions 218, and data 219. User computing device 212 may also include user output 226 and user input 224. User input 224 may include any suitable mechanism or technique for receiving input from a user, such as a keyboard, mouse, mechanical actuators, soft actuators, touch screens, microphones, and sensors.
[0080] 서버 컴퓨팅 디바이스(215)는 데이터를 사용자 컴퓨팅 디바이스(212)에 송신하도록 구성될 수 있고, 사용자 컴퓨팅 디바이스(212)는 수신된 데이터의 적어도 일부를 사용자 출력(226)의 일부로서 구현되는 디스플레이 상에 디스플레이하도록 구성될 수 있다. 사용자 출력(226)은 또한 사용자 컴퓨팅 디바이스(212)와 서버 컴퓨팅 디바이스(215) 사이의 인터페이스를 디스플레이하는 데 사용될 수 있다. 사용자 출력(226)은 대안적으로 또는 추가적으로 사용자 컴퓨팅 디바이스(212)의 플랫폼 사용자에게 비시각적 및 비가청적 정보를 제공하는 하나 이상의 스피커들, 트랜듀서들 또는 다른 오디오 출력들, 햅틱 인터페이스 또는 다른 촉각 피드백을 포함할 수 있다.[0080] Server computing device 215 can be configured to transmit data to user computing device 212, wherein user computing device 212 implements at least a portion of the received data as part of user output 226. It may be configured to display on a display. User output 226 may also be used to display an interface between user computing device 212 and server computing device 215. User output 226 may alternatively or additionally include one or more speakers, transducers or other audio outputs, a haptic interface or other tactile feedback that provide non-visual and non-audible information to the platform user of user computing device 212. may include.
[0081] 비록 도 2가, 프로세서들(213, 216) 및 메모리들(214, 217)이 컴퓨팅 디바이스들(215, 212) 내에 있는 것으로 예시하지만, 프로세서들(213, 216) 및 메모리들(214, 217)을 포함하여 본 명세서에 설명된 컴포넌트들은 상이한 물리적 위치들에서 오퍼레이팅할 수 있고 동일한 컴퓨팅 디바이스 내에 없을 수 있는 다중 프로세서들 및 메모리들을 포함할 수 있다. 예를 들어, 명령들(221, 218) 및 데이터(223, 219) 중 일부는 이동식 SD 카드에 저장되고 다른 것들은 판독 전용 컴퓨터 칩 내에 저장될 수 있다. 명령들 및 데이터의 일부 또는 전부는 프로세서들(213, 216)로부터 물리적으로 멀리 떨어져 있지만, 여전히 액세스 가능한 위치에 저장될 수 있다. 유사하게, 프로세서들(213, 216)은 동시 및/또는 순차 오퍼레이션을 수행할 수 있는 프로세서들의 컬렉션을 포함할 수 있다. 컴퓨팅 디바이스들(215, 212)은 각각 컴퓨팅 디바이스들(215, 212)에 의해 실행되는 오퍼레이션들 및 프로그램들에 대한 시간 측정에 사용될 수 있는 타이밍 정보를 제공하는 하나 이상의 내부 클록들을 포함할 수 있다.[0081] Although Figure 2 illustrates processors 213, 216 and memories 214, 217 as being within computing devices 215, 212, processors 213, 216 and memories 214 , 217), the components described herein may operate at different physical locations and may include multiple processors and memories that may not be within the same computing device. For example, some of the instructions 221, 218 and data 223, 219 may be stored on a removable SD card and others within a read-only computer chip. Some or all of the instructions and data may be stored in a location that is physically remote from the processors 213, 216, but still accessible. Similarly, processors 213, 216 may include a collection of processors capable of performing concurrent and/or sequential operations. Computing devices 215 and 212 may include one or more internal clocks that provide timing information that can be used to time operations and programs executed by computing devices 215 and 212, respectively.
[0082] 서버 컴퓨팅 디바이스(215)는 사용자 컴퓨팅 디바이스(212)로부터 데이터를 프로세싱하라는 요청을 수신하도록 구성될 수 있다. 예를 들어, 환경(200)은 플랫폼 서비스들을 노출하는 다양한 사용자 인터페이스들 및/또는 API들을 통해 사용자들에게 다양한 서비스들을 제공하도록 구성된 컴퓨팅 플랫폼의 일부일 수 있다. 하나 이상의 서비스들은 지정된 태스크 및 훈련 데이터에 따라 신경망들 또는 다른 기계 학습 모델들을 생성하기 위한 기계 학습 프레임워크 또는 도구들의 세트일 수 있다. 사용자 컴퓨팅 디바이스(212)는 희소 가속기(103)의 XPU들이 수행하도록 구성되어야 하는 구성된 오퍼레이션의 유형 또는 워크로드를 지정하는 데이터를 수신 및 송신할 수 있다. 사용자 컴퓨팅 디바이스(212)는 본원에 설명된 바와 같이 명령들을 하드웨어 회로(101)에 직접 전송하거나, 서버 컴퓨팅 디바이스(215)가 명령들을 생성하여 제어 신호들로서 하드웨어 회로(101)에 전송하게 할 수 있다.[0082] Server computing device 215 may be configured to receive a request to process data from user computing device 212. For example, environment 200 may be part of a computing platform configured to provide various services to users through various user interfaces and/or APIs that expose platform services. One or more services may be a machine learning framework or set of tools for creating neural networks or other machine learning models according to specified tasks and training data. User computing device 212 may receive and transmit data specifying the workload or type of configured operation that the XPUs of sparse accelerator 103 should be configured to perform. User computing device 212 may send commands directly to hardware circuitry 101 as described herein, or may cause server computing device 215 to generate commands and send them to hardware circuitry 101 as control signals. .
[0083] 디바이스들(212, 215)은 네트워크(260)를 통해 직접 및 간접 통신이 가능할 수 있다. 디바이스들(215, 212)은 정보 전송 및 수신을 위한 개시 연결을 수락할 수 있는 청취 소켓들을 셋업할 수 있다. 네트워크(260) 자체는 인터넷, 월드 와이드 웹(World Wide Web), 인트라넷들, 가상 사설망들, 광역 네트워크들, 로컬 네트워크들 및 하나 이상의 회사들 전용 통신 프로토콜들을 사용하는 사설 네트워크들을 포함하는 다양한 구성들 및 프로토콜들을 포함할 수 있다. 네트워크(260)는 다양한 단거리 및 장거리 연결들을 지원할 수 있다. 단거리 및 장거리 연결들은 일반적으로 Bluetooth® 표준과 연관된 2.402 GHz 내지 2.480 GHz, 일반적으로 Wi-Fi® 통신 프로토콜과 연관된 2.4 GHz 및 5 GHz와 같은 상이한 대역폭들; 또는 무선 광대역 통신을 위한 LTE® 표준과 같은 다양한 통신 표준들을 통해 이루어질 수 있다. 추가적으로 또는 대안적으로, 네트워크(260)는 또한 다양한 유형들의 이더넷 연결을 포함하여 디바이스들(212, 215) 간의 유선 연결을 지원할 수 있다.[0083] Devices 212 and 215 may be capable of direct and indirect communication through the network 260. Devices 215, 212 can set up listening sockets that can accept initiating connections for sending and receiving information. Network 260 itself may be of various configurations, including the Internet, the World Wide Web, intranets, virtual private networks, wide area networks, local networks, and private networks using communications protocols proprietary to one or more companies. and protocols. Network 260 may support a variety of short and long range connections. Short- and long-range connections have different bandwidths, such as 2.402 GHz to 2.480 GHz, typically associated with the Bluetooth® standard, and 2.4 GHz and 5 GHz, typically associated with the Wi-Fi® communication protocol; Alternatively, it may be achieved through various communication standards, such as the LTE® standard for wireless broadband communication. Additionally or alternatively, network 260 may also support wired connections between devices 212 and 215, including various types of Ethernet connections.
[0084] 단일 서버 컴퓨팅 디바이스(215) 및 사용자 컴퓨팅 디바이스(212)가 도 2에 도시되어 있지만, 본 개시내용의 양태들이 순차 또는 병렬 프로세싱을 위한 패러다임을 포함하여, 또는 다수의 디바이스들의 분산 네트워크를 통해 컴퓨팅 디바이스들의 다양한 상이한 구성들 및 수량들에 따라 구현될 수 있다는 것이 이해된다. 일부 구현들에서, 본 개시내용의 양태들은 단일 디바이스, 및 이들의 임의의 조합에서 수행될 수 있다.[0084] Although a single server computing device 215 and a user computing device 212 are shown in FIG. 2, aspects of the disclosure include paradigms for sequential or parallel processing, or distributed networks of multiple devices. It is understood that implementations may occur in a variety of different configurations and quantities of computing devices. In some implementations, aspects of the disclosure can be performed on a single device, and any combination thereof.
[0085] 도 3a는 예시적인 타일(102)의 블록도이다. XPU(101)는 교차 레인 제어기(310)에 결합된다. 교차 레인 제어기(310)는 XPU(101)에서 교차 레인 명령들을 허용하기 위해 별도의 제어 스레드를 제공한다. 본원에 설명된 바와 같이, XPU(101)는 예를 들어 하나 이상의 제어 신호들을 통해 제1 명령을 수신할 수 있고, 이는 하나 이상의 제2 및 제3 명령들로 변환되어 제1 명령에 의해 지정된 구성된 오퍼레이션을 수행하기 위해 각각 XPU(101)의 프로세싱 셀들 및 크로스바들에 제공될 수 있다. XPU(101)에 대한 명령들은 제어 신호들을 통해 반송될 수 있고, 제어 신호들에서, XPU(101)의 프로세싱 셀들 및 크로스바들은 대응 기본 오퍼레이션을 수행하도록 해석하도록 구성된다. 예시적인 명령은 명령 세트 아키텍처(ISA)의 연산부호일 수 있다.[0085] Figure 3A is a block diagram of an example tile 102. XPU 101 is coupled to cross lane controller 310. Cross-lane controller 310 provides a separate control thread to allow cross-lane instructions in XPU 101. As described herein, the It may be provided to the processing cells and crossbars of the XPU 101, respectively, to perform the operation. Commands to the XPU 101 may be carried via control signals, in which the processing cells and crossbars of the An example instruction may be an instruction set architecture (ISA) opcode.
[0086] 타일(102)은 도 1a를 참조하여 설명된 바와 같이 온칩 상호연결(108)뿐만 아니라 온칩 메모리(105)로부터 데이터를 수신할 수 있다. XPU는 또한 명령 인터페이스(324)로부터, 예를 들어 타일 시퀀서(106)로부터 스칼라 코어(312) 또는 스칼라 코어(320)를 통해 명령들을 수신할 수 있다. 타일(102)의 스캐터-수집 엔진(322)은 인입 데이터를 수신하고, 메모리 스케줄러(314)를 통해 메모리(306)에 전달되는 데이터를 제어할 수 있다. 일부 예들에서, 스캐터-수집 엔진 대신에, 스캐터-수집 엔진(322)은 판독-쓰기 엔진(322)으로 지칭될 수 있다.[0086] Tile 102 may receive data from on-chip memory 105 as well as on-chip interconnect 108 as described with reference to FIG. 1A. The XPU may also receive instructions from command interface 324, for example from tile sequencer 106, via scalar core 312 or scalar core 320. Scatter-collect engine 322 of tile 102 may receive incoming data and control data delivered to memory 306 via memory scheduler 314. In some examples, instead of a scatter-collect engine, scatter-collect engine 322 may be referred to as read-write engine 322.
[0087] 메모리 스케줄러(314)는 데이터가 메모리(306)에서 액세스되고 검색되는 방법을 조정할 수 있다. 메모리(306)는 타일(102) 전용이고, 다른 타일들과 같이 타일(102)에 연결된 다른 컴포넌트들에 의해 액세스 가능하지 않다. 중재기(304)는 벡터 프로세싱 유닛(VPU)들(302A-H) 중 어느 것이 예를 들어 클록 사이클 단위로 메모리(306)에 액세스하는지 관리하도록 구성된다. 타일(102)은 스칼라 코어(320)를 통해 스캐터-수집 엔진(322)으로 전송되는 타일(102)에 의해 수행될 태스크의 태스크 큐(308)를 유지할 수 있다. 타일(102)은 또한 타일(102)을 하드웨어 회로 및 메모리(306)의 다른 타일들과 각각 동기화하기 위해 타일 동기화 플래그들(318) 및/또는 메모리 플래그들(316)의 레지스터들을 유지할 수 있다.[0087] Memory scheduler 314 may coordinate how data is accessed and retrieved from memory 306. Memory 306 is dedicated to tile 102 and is not accessible by other components connected to tile 102 like other tiles. Arbiter 304 is configured to manage which of vector processing units (VPUs) 302A-H accesses memory 306, for example on a clock cycle basis. Tile 102 may maintain a task queue 308 of tasks to be performed by tile 102 that are transmitted via scalar core 320 to scatter-collect engine 322. Tile 102 may also maintain registers of tile synchronization flags 318 and/or memory flags 316 to synchronize tile 102 with hardware circuitry and other tiles in memory 306, respectively.
[0088] VPU들(302A-H)은 XPU(101)와 VPU들(302A-H) 사이에 실선으로 표시된 데이터 프로세싱 레인들을 통해 XPU(101)에 연결된다. XPU(101)와 VPUS(302A-H) 사이의 파선들은 제어 신호들을 나타내고, 이는 수신된 제어 신호들에 대응하는 구성 오퍼레이션을 수행하도록 XPU(101)를 구성하기 위해 XPU(101)의 제어 셀들에 의해 수신될 수 있다. 벡터 프로세싱 유닛은 입력 벡터들에 대한 효율적인 오퍼레이션을 위해 구성된다. 한 번에 타일(102)에 의해 프로세싱되는 벡터들의 길이는 타일에 의해 구현되는 VPU들의 개수 또는 폭에 따를 수 있다. 예를 들어, 8 개의 VPU들(302A-H)은 8 폭이다. VPU들(302A-H)은 동일한 데이터 프로세싱 레인을 따라 데이터를 프로세싱할 수 있다. VPU들(302A-H)은 메모리(306)로부터 인입하는 벡터들의 엘리먼트들에 대해 스칼라 오퍼레이션들을 수행하도록 구성될 수 있다. VPU들(302A-H)은 XPU(101)로부터 데이터를 수신할 수 있고, XPU(101)는 본원에 설명된 바와 같이 각각의 VPU(302A-H)에 의해 수행되는 레인들을 따라서만 수행되는 것이 아니라, 데이터 프로세싱 레인들을 통해 데이터를 프로세싱할 수 있다.[0088] VPUs 302A-H are connected to XPU 101 through data processing lanes indicated by solid lines between XPU 101 and VPUs 302A-H. The dashed lines between the XPU 101 and the VPUS 302A-H represent control signals, which are transmitted to control cells of the XPU 101 to configure the can be received by The vector processing unit is configured for efficient operations on input vectors. The length of vectors processed by a tile 102 at a time may depend on the number or width of VPUs implemented by the tile. For example, 8 VPUs 302A-H are 8 wide. VPUs 302A-H may process data along the same data processing lane. VPUs 302A-H may be configured to perform scalar operations on elements of vectors incoming from memory 306. VPUs 302A-H may receive data from XPU 101, with XPU 101 performing only along the lanes performed by each VPU 302A-H as described herein. Rather, data can be processed through data processing lanes.
[0089] 도 3b는 스트림 전달들을 위해 XPU(101)를 구현하는 다른 예시적인 타일(392)의 블록도이다. 타일(392)은 도 1을 참조하여 설명된 바와 같이 온칩 상호연결(108)뿐만 아니라 온칩 메모리(105)로부터 데이터를 수신할 수 있다. XPU(101)는 또한 명령 인터페이스(324), 예를 들어 타일 시퀀서(106)로부터 명령들을 수신할 수 있다. 타일(392)의 스캐터-수집 엔진(322)은 인입 데이터를 수신하고 어떤 데이터가 메모리(306)에 전달되는지를 제어할 수 있다.[0089] Figure 3B is a block diagram of another example tile 392 implementing XPU 101 for stream transfers. Tile 392 may receive data from on-chip memory 105 as well as on-chip interconnect 108 as described with reference to FIG. 1 . XPU 101 may also receive commands from command interface 324, such as tile sequencer 106. The scatter-collection engine 322 of tile 392 may receive incoming data and control which data is passed to memory 306.
[0090] 이 예시적인 타일(392)은 프로그램(및 연관된 명령들의 시퀀스)이 2 개의 스트림들로 분리될 수 있는 분리된 액세스/실행 아키텍처에 기반한다. 제1 스트림은 피연산자들을 페치하고 결과들을 저장하는 액세스 스트림일 수 있다. 제2 스트림은 피연산자들을 사용하고, 컴퓨팅들을 수행하고, 결과들을 생성하는 실행 스트림일 수 있다. 이들 스트림들은 2 개의 개별 코어들, 즉 타일 액세스 코어(TAC)(332) 및 타일 실행 코어(TEC)(330)에서 실행되고, 이는 분리된 액세스/실행 아키텍처의 일부를 형성한다. TAC(332)는 데이터 컴퓨팅에서 데이터 이동을 분리, 예를 들어 메모리에서 데이터를 페치하는 것과 페치된 메모리를 프로세싱하는 것을 분리하는 하는 데 사용되는 스칼라 유닛이다. TEC(330)는 벡터들을 프로세싱하는 데 사용되는 다중 SIMD 레인들, 예를 들어, 8 개의 SIMD 레인들을 갖는 VPU에 첨부된 스칼라 유닛이다.[0090] This example tile 392 is based on a separated access/execution architecture in which a program (and associated sequence of instructions) can be separated into two streams. The first stream may be an access stream that fetches operands and stores results. The second stream may be an execution stream that uses operands, performs computations, and produces results. These streams run on two separate cores, tile access core (TAC) 332 and tile execution core (TEC) 330, forming part of a separate access/execution architecture. TAC 332 is a scalar unit used in data computing to separate data movement, for example, fetching data from memory and processing the fetched memory. TEC 330 is a scalar unit attached to a VPU with multiple SIMD lanes, for example, eight SIMD lanes, used to process vectors.
[0091] 타일 액세스 코어(332)는 스칼라 코어 콤플렉스(scalar core complex)(320)에 기반하고 메모리(306) 또는 타일(392) 외부의 고대역폭 메모리로부터 실행하기 위한 피연산자들을 프리페치하는 역할을 할 수 있다. 타일 실행 코어(330)는 스칼라 코어 콤플렉스(312)에 기반하고 XPU들(101) 및 VPU들(302)을 포함하고 결과들을 생성하기 위해 프리페치된 피연산자들에 대한 컴퓨팅 오퍼레이션들을 수행하는 역할을 할 수 있다. VPU들(302)은 로드 저장 유닛(328)을 통해 메모리(306)에 연결된다. 로드 저장 유닛(328)은 타일(303)을 통과하는 데이터에 대한 수집 및 스캐터 오퍼레이션들을 수행하도록 구성된다. 수집-스캐터 오퍼레이션들은 예를 들어 4 바이트 입도로 세부적으로 수행될 수 있다. 로드 저장 유닛(328)은 뱅크 충돌들을 관리하기 위한 로드 및 저장 큐들을 구현할 수 있다. LSU(328)는 스크래치패드 메모리의 서브세트에 대한 로드/저장 액세스를 제공할 수 있다.[0091] The tile access core 332 is based on the scalar core complex 320 and may be responsible for prefetching operands for execution from memory 306 or high-bandwidth memory external to the tile 392. You can. The tile execution core 330 is based on the scalar core complex 312 and includes XPUs 101 and VPUs 302 and is responsible for performing computing operations on prefetched operands to generate results. You can. VPUs 302 are coupled to memory 306 via load store unit 328. Load storage unit 328 is configured to perform collection and scatter operations on data passing through tile 303. Gather-scatter operations can be performed in detail, for example at 4 byte granularity. Load store unit 328 may implement load and store queues to manage bank conflicts. LSU 328 may provide load/store access to a subset of scratchpad memory.
[0092] TAC(332) 및 TEC(330)는 독립적인 명령 스트림들을 가지며 함께 생산자-소비자 쌍을 형성한다. 타일(102)은 TAC(332) 및 TEC(330)에 전송되는 타일(102)에 의해 수행될 태스크의 태스크 큐(308)를 유지할 수 있다.[0092] TAC 332 and TEC 330 have independent instruction streams and together form a producer-consumer pair. Tile 102 may maintain a task queue 308 of tasks to be performed by tile 102 that are transmitted to TAC 332 and TEC 330.
[0093] 태스크 큐(308)는 푸시 및 팝핑 명령들을 위한 하나 이상의 큐들을 포함할 수 있다. 예를 들어, 태스크 큐(308)는 TAC(332)로부터 TEC(330)로 값들을 푸시하기 위한 선입선출(FIFO) 큐와 같은 제1 큐를 가질 수 있다. TEC(330)는 인큐(enqueue)된 값들을 팝핑하고 프로세싱할 수 있다. 다른 예로서, 태스크 큐(308)는 TAC(332)와 TEC(330)를 반대 방향으로 연결하기 위한 추가 큐들을 포함할 수 있다.[0093] Task queue 308 may include one or more queues for pushing and popping instructions. For example, task queue 308 may have a first queue, such as a first-in-first-out (FIFO) queue, for pushing values from TAC 332 to TEC 330. TEC 330 may pop and process enqueued values. As another example, task queue 308 may include additional queues to connect TAC 332 and TEC 330 in opposite directions.
[0094] TAC(332)와 TEC(330)는 메모리(306)와 같은 타일-로컬 스크래치패드 메모리(SpMEM)를 통해 서로 통신한다. TAC(332) 및 TEC(330)는 또한 스칼라 메모리(334), 명령 버퍼(326) 및 타일 동기화 플래그(318)를 통해 통신할 수 있다. 메모리(306)는 데이터를 교환하기 위해 TAC(332) 및 TEC(330)에 의해 사용될 수 있고 선입선출 순서로 TAC(332)와 TEC(330) 사이에서 데이터를 전달하기 위한 소프트웨어 관리 순환 버퍼로서 사용될 수 있다. 타일 동기화 플래그들(318)은 TAC(332)와 TEC(330) 사이의 카운팅 세마포어(semaphore)로 사용될 수 있다. 예를 들어, 두 코어 사이에 순환 선입선출 순서가 2 개의 코어들 사이에 사용되는 경우, 생산자 코어는 푸시할 때마다 동기화 플래그(318)를 바이트들의 개수만큼 증분시키고, 카운트가 선입선출 순서의 최대 크기에 도달하면 멈춘다. 유사하게, 소비자는 매 팝핑 후에 동기화 플래그(318)를 감분시켜, 버퍼에 데이터가 없을 때 멈춘다. 프리페치되는 데이터의 수량이 동적일 수 있으므로, 완료 비트는 스트림의 끝을 나타내는 데 사용된다.[0094] TAC 332 and TEC 330 communicate with each other through a tile-local scratchpad memory (SpMEM), such as memory 306. TAC 332 and TEC 330 may also communicate via scalar memory 334, command buffer 326, and tile synchronization flag 318. Memory 306 may be used by TAC 332 and TEC 330 to exchange data and may be used as a software-managed circular buffer to transfer data between TAC 332 and TEC 330 in a first-in-first-out order. You can. Tile synchronization flags 318 may be used as a counting semaphore between TAC 332 and TEC 330. For example, if a circular first-in-first-out order is used between two cores, the producer core increments the synchronization flag 318 by the number of bytes each time it pushes, and the count increases to the maximum of the first-in-first-out order. It stops when it reaches size. Similarly, the consumer decrement the synchronization flag 318 after every popping, stopping when there is no data in the buffer. Because the amount of data being prefetched can be dynamic, the completion bit is used to indicate the end of the stream.
[0095] 타일 동기화 플래그(318)는 일부 예들에서 32 개의 동기화 플래그 레지스터들의 세트를 포함할 수 있다. 각각의 레지스터는 32 비트의 데이터 더하기 "완료" 비트 및 "enable_public_access" 비트를 저장할 수 있다. 타일 동기화 플래그(318) 레지스터들은 모놀리식 플롭 어레이(monolithic flop array)로 구현되어, 모든 소스들로부터의 동시 액세스들을 허용할 수 있다. 어드레스가 쓰기(write)들 간 충돌하는 경우, 소스들 간 액세스들의 우선순위가 지정될 수 있다. 예를 들어, 스칼라 기타 명령들은 절대적인 우선순위를 가질 수 있다. 일부 예들에서, 스칼라 기타 명령들 중 하나만이 발행될 수 있다. 판독-수정-쓰기 오퍼레이션들은 파이프라인화되므로, 모든 동기화 플래그들에 대한 연이은 판독-수정-쓰기 오퍼레이션들이 지원될 수 있다.[0095] Tile synchronization flag 318 may include a set of 32 synchronization flag registers in some examples. Each register can store 32 bits of data plus a "completion" bit and an "enable_public_access" bit. The tile synchronization flag 318 registers may be implemented as a monolithic flop array to allow simultaneous accesses from all sources. If addresses conflict between writes, accesses between sources may be prioritized. For example, scalar other instructions can have absolute priority. In some examples, only one of the scalar miscellaneous instructions may be issued. Since read-modify-write operations are pipelined, consecutive read-modify-write operations for all synchronization flags can be supported.
[0096] DMA 업데이트들, 스트림 업데이트들 및 원격 쓰기들은 라운드 로빈 중재를 사용하여 단일(외부) 인터페이스에 결합될 수 있다. 예를 들어, 타일에서 외부 소스로의 외부 인터페이스는 동기화 플래그들에 대한 별도의 액세스 경로, 예를 들어 도 1b를 참조하여 도시되고 설명된 데이터 경로를 가질 수 있다.[0096] DMA updates, stream updates and remote writes can be combined on a single (external) interface using round robin arbitration. For example, the external interface from the tile to the external source may have a separate access path to the synchronization flags, such as the data path shown and described with reference to FIG. 1B.
[0097] 태스크 명령 메모리(160B)의 뱅크들 각각은 뱅크들에 저장된 타일 요청 데이터 사이에서 사이클별 중재를 수행할 수 있다. 뱅크들은 뱅크에 액세스하는 희소 가속기(103) 내에서 TAC(332) 및 TEC(330)에 걸쳐 승자를 선택하기 위해 분산 중재 방식을 사용할 수 있다. 중재는 요청 대역폭이 요청 타일들 간에 동일하게 분할되도록 할 수 있다. 요청들은 예를 들어 각각의 타일에 대한 각자의 TAC들에 의해 데이터를 프리페치하는 것일 수 있다. 예를 들어, 승리한 프리페치 요청은 액세스된 뱅크들 중 하나에 대한 액세스 우선순위가 가장 높다.[0097] Each of the banks of the task command memory 160B may perform cycle-by-cycle arbitration between tile request data stored in the banks. Banks may use a distributed arbitration scheme to select a winner across TAC 332 and TEC 330 within the sparse accelerator 103 accessing the bank. Arbitration may ensure that the requested bandwidth is split equally between the requested tiles. Requests may be to prefetch data, for example by respective TACs for each tile. For example, a winning prefetch request has the highest access priority to one of the accessed banks.
[0098] 제어 상태 레지스터들을 통한 희소 가속기(103)로부터의 액세스들은 다음으로 높은 우선순위를 가질 수 있고, 이는 프리페치 판독 요청에 의해서만 지연된다. 제어 상태 레지스터(CSR)들은 희소 가속기(103)에 의해 실행되는 기계 명령들의 추가 정보 결과들을 저장하기 위한 프로세서의 일부로 구현될 수 있다. 희소 가속기(103)는 CSR 액세스가 완료되는 것이 방지되는지 여부를 결정하기 위해 간접 CSR 타임아웃 상태 비트를 유지할 수 있다. 뱅크 액세스들 및 CSR 액세스들 후, DMA 판독들 또는 쓰기들이 마지막에 우선순위 지정될 수 있다. 판독 또는 쓰기와 같은 DMA 오퍼레이션은 사용 중인 뱅크에 액세스할 때 지연될 수 있다. 일부 예들에서, 액세스 오퍼레이션들이 희소 가속기(103)에서 중재되고 해결되는 방법의 우선순위는 다를 수 있다.[0098] Accesses from sparse accelerator 103 through control status registers may have the next highest priority, and are delayed only by prefetch read requests. Control status registers (CSRs) may be implemented as part of the processor to store additional information results of machine instructions executed by sparse accelerator 103. Sparse accelerator 103 may maintain an indirect CSR timeout status bit to determine whether a CSR access is prevented from completing. After bank accesses and CSR accesses, DMA reads or writes may be prioritized last. DMA operations such as reads or writes may experience delays when accessing busy banks. In some examples, the priority of how access operations are arbitrated and resolved in sparse accelerator 103 may differ.
[0099] 데이터 실행으로부터 데이터 액세스를 분리하는 것은 적어도 다음과 같은 이점들을 갖는다. TAC(332)가 어드레스 계산을 수행하고 필요한 데이터를 프리페치할 수 있으므로 긴, 예를 들어, 600 사이클들의 메모리 지연시간이 더 효과적으로 허용된다. 설명된 아키텍처는 또한 제어 지연시간에 대한 증가된 허용 오차를 갖는다. 동적 의존성들은 루프 조건들을 해결하기 어렵게 하고, 이는 효과적인 소프트웨어 언롤링을 방해될 수 있다. 조건이 TEC(330) 외부에서 결정될 수 있는 경우, TAC(332)는 이러한 의존성들을 해결하기 위해 미리 실행되어, 제어 지연시간을 숨길 수 있는 방식을 제공한다.[0099] Separating data access from data execution has at least the following advantages. Long memory latencies, e.g., 600 cycles, are more effectively tolerated because TAC 332 can perform address calculations and prefetch necessary data. The described architecture also has increased tolerance for control latency. Dynamic dependencies make loop conditions difficult to resolve, which can prevent effective software unrolling. If conditions can be determined outside of TEC 330, TAC 332 can be run ahead of time to resolve these dependencies, providing a way to hide control latency.
[0100] 도 4는 본 개시내용의 양태들에 따른 타일 시퀀서(400)의 블록도이다. 시퀀서 메모리(410)(Simem)는 VLIW 명령 번들의 폭을 갖고, 대략 8,000 개 번들의 깊이를 가질 수 있지만, 시퀀서 메모리(410)의 번들의 폭과 개수는 구현마다 다를 수 있다. 시퀀서 메모리(410)는 직접적인 메모리 액세스 또는 간접 액세스를 통해 판독되거나 쓰여질 수 있다. 이는 시퀀서(400)가 현재 실행 중인지 여부에 관계없이 행해질 수 있다. 시퀀서 메모리 DMA 메모리 디스크립터는 32 바이트들의 배수의 길이 필드를 가질 수 있다. 각각의 번들은 고대역폭 메모리에 저장될 때 최상위 비트부터 256 비트 경계까지 제로 패딩될 수 있다. 패딩된 비트들은 0으로 판독 및 쓰기 무시(RAZ/WI)된다. 각각의 메모리 디스크립터는 하나의 명령 번들을 전달할 수 있다.[0100] Figure 4 is a block diagram of a tile sequencer 400 in accordance with aspects of the present disclosure. Sequencer memory 410 (Simem) has a width of VLIW instruction bundles and may have a depth of approximately 8,000 bundles, but the width and number of bundles of sequencer memory 410 may vary from implementation to implementation. Sequencer memory 410 can be read or written through direct memory access or indirect access. This can be done regardless of whether sequencer 400 is currently running. The sequencer memory DMA memory descriptor may have a length field that is a multiple of 32 bytes. Each bundle can be zero-padded from the most significant bit to a 256-bit boundary when stored in high-bandwidth memory. Padded bits are read and written to 0 and are ignored (RAZ/WI). Each memory descriptor can carry one instruction bundle.
[0101] 시퀀서 메모리(410)는 뱅크들 사이에 순차적인 어드레스들을 갖는 2 개의 뱅크들로 구성될 수 있다. 각각의 뱅크는 클록 사이클당 하나의 판독 또는 하나의 쓰기를 수행할 수 있다. 인터리빙은 순차적 명령 시퀀스들이 각각의 뱅크 대역폭의 절반만 소비하게 한다. 병적으로 최소 크기의 루프는 주어진 뱅크 대역폭의 4분의 3만 소비할 수 있고, 이는 여전히 액세스들이 진행되는 데 충분한 대역폭을 남긴다.[0101] The sequencer memory 410 may be composed of two banks with sequential addresses between the banks. Each bank can perform one read or one write per clock cycle. Interleaving ensures that sequential command sequences consume only half of each bank's bandwidth. Pathologically, the smallest loop can consume only three-quarters of a given bank's bandwidth, which still leaves enough bandwidth for accesses to proceed.
[0102] 시퀀서 메모리(410)의 각각의 시퀀서 메모리 뱅크는 다음 인터페이스들을 따를 수 있다: 시퀀서 메모리(410)는 명령 데이터 경로, 예를 들어 도 1b를 참조하여 도시되고 설명된 명령 데이터 경로로부터 판독 요청을 수신할 수 있다. 시퀀서 메모리(410)의 뱅크들은 또한 DMA 쓰기들 및 판독들을 수신할 수 있을 뿐만 아니라, 간접 레지스터 인터페이스를 통해 상태 레지스터 액세스를 제어할 수 있다. 명령 데이터 경로로부터의 판독들은 시퀀서 메모리(410)의 각각의 뱅크에 대한 최고 우선순위 액세스를 가질 수 있다. DMA 판독들, 쓰기들 및 CSR 액세스는 동일한 우선순위를 가지며 명령 페치를 수행 중이지 않은 뱅크에 대해 LRU(least recently used) 중재를 거칠 수 있다.[0102] Each sequencer memory bank of sequencer memory 410 may follow the following interfaces: Sequencer memory 410 may receive a read request from an instruction data path, e.g., the instruction data path shown and described with reference to FIG. 1B. can receive. Banks of sequencer memory 410 may also receive DMA writes and reads, as well as control status register access via an indirect register interface. Reads from the instruction data path may have highest priority access to each bank of sequencer memory 410. DMA reads, writes and CSR accesses have the same priority and may undergo least recently used (LRU) arbitration for a bank that is not performing an instruction fetch.
[0103] 시퀀서(400)는 시퀀서 메모리(410)로부터 명령들을 페치할 수 있다. 시퀀서(400)는 디스크립터 디스패치 유닛(413)(태스크 및 스트림 디스크립터들용) 및 DMA 유닛(414)(DMA 디스크립터용)에 의해 각각 디스패치되는 디스크립터들 생성을 수반하는 프로그램의 제어 스레드를 실행한다. 태스크 디스크립터들은 타일 FIFO들(416)에 제공되고, 이어서 이는 각각의 타일들에 의해 수행된다. DMA 디스크립터들은 하드웨어 회로(101)의 다른 컴포넌트들 및 다른 오프칩 컴포넌트들에 전달될 수 있다. 시퀀서는 시스템의 다른 코어들과 통신하고 가속기의 타일들에 걸쳐 태스크들을 조정한다.[0103] Sequencer 400 may fetch instructions from sequencer memory 410. Sequencer 400 executes a control thread of the program that involves generating descriptors that are dispatched by descriptor dispatch unit 413 (for task and stream descriptors) and DMA unit 414 (for DMA descriptors), respectively. Task descriptors are provided to tile FIFOs 416, which are then performed by the respective tiles. DMA descriptors may be passed to other components of hardware circuitry 101 and other off-chip components. The sequencer communicates with other cores in the system and coordinates tasks across the accelerator's tiles.
[0104] 시퀀서(400)의 현재 상태는 대응 상태 레지스터를 판독하여 결정될 수 있다. 명령 번들 페치 및 실행과 관련된 다른 레지스터들은 프로그램 카운터와 분기 상태이다. 타일 시퀀서(400)는 하드웨어에 의해 스로틀링될 수 있는 DMA 디스크립터를 발행할 수 있다. 하드웨어는 동기화 플래그들(418) 사이에 저장된 동기화 플래그를 갖는 시퀀서에 의해 발행된 미리 결정된 개수의 DMA들이 미해결 상태가 되게 한다. 스로틀링은 필요에 따라 인에이블되거나 디스에이블될 수 있다.[0104] The current state of sequencer 400 can be determined by reading the corresponding status register. Other registers involved in instruction bundle fetching and execution are the program counter and branch status. The tile sequencer 400 may issue a DMA descriptor that may be throttled by hardware. The hardware causes a predetermined number of DMAs issued by the sequencer with the synchronization flag stored among the synchronization flags 418 to be outstanding. Throttling can be enabled or disabled as needed.
[0105] 동기화 플래그들은 2 개 이상의 유형들로 나타날 수 있다. 동기화 플래그들(418)은 타일 시퀀서(400)에 나타날 수 있다. 다른 동기화 플래그들은 각각의 타일의 TAC 및 TEC에 저장될 수 있다. 전체적으로, 모든 동기화 플래그들은 단일 어드레스 공간에 배치될 수 있고, DMA 오퍼레이션들, 원자 원격 세트/추가 명령들 및 원자 타일 세트/추가 명령들에 액세스할 수 있다. 타일의 동기화 플래그들과 시퀀서(400)의 동기화 플래그들 사이에 구현될 수 있는 다수의 인터페이스들이 있다. DMA 오퍼레이션은 실행 동안 동기화 플래그에 원자적으로 값들을 추가할 수 있고 완료 시 "완료" 비트를 세팅할 수 있다. 스트림 오퍼레이션은 실행 동안 동기화 플래그에 원자적으로 값들을 추가할 수 있고 완료 시 "완료" 비트를 세팅할 수 있다. 원격 쓰기 명령들은 동기화 플래그에 값을 원자적으로 세팅하거나 추가할 수 있는 단일 워드 제어 쓰기를 생성한다. 이들은 원격 동기화 플래그를 업데이트하는 데 사용되는 원자 원격 세트/추가 명령들에서 비롯될 수 있다. 이들은 또한 희소 가속기 내에서 동기화 플래그들을 업데이트하는 데 사용되는 원자 타일 세트/추가 명령들에서 비롯될 수 있다. 구현될 수 있는 다른 인터페이스는 쓰기 인터페이스이고, 여기에서 동기화 플래그 세트 및 동기화 플래그 추가 명령들은 선택적으로 "완료" 비트 수정을 포함하여 동기화 플래그에 대한 원자적 업데이트를 수행한다. 구현될 수 있는 다른 인터페이스는 판독 인터페이스이다.[0105] Synchronization flags may appear in two or more types. Synchronization flags 418 may appear in tile sequencer 400. Other synchronization flags may be stored in the TAC and TEC of each tile. Overall, all synchronization flags can be placed in a single address space and can be accessed by DMA operations, atomic remote set/append instructions and atomic tile set/append instructions. There are a number of interfaces that can be implemented between the synchronization flags of the tile and the synchronization flags of the sequencer 400. DMA operations can atomically add values to the synchronization flag during execution and set the "done" bit upon completion. Stream operations can atomically add values to synchronization flags during execution and set the "done" bit upon completion. Remote write commands produce single word control writes that can atomically set or add values to synchronization flags. These can come from atomic remote set/append instructions used to update remote sync flags. These may also come from atomic tile set/append instructions used to update synchronization flags within the sparse accelerator. Another interface that may be implemented is a write interface, where the set sync flag and add sync flag instructions perform atomic updates to the sync flag, optionally including modifying the "done" bit. Another interface that can be implemented is a read interface.
[0106] 동기화 플래그들(418)은 다수의 뱅크들로서 메모리에 구성될 수 있다. 각각의 엔트리는 다수의 데이터 비트들, 예를 들어, 32 데이터 비트들 더하기 "완료" 비트 및 "enable_public_access" 비트를 포함할 수 있다. 뱅크들은 예를 들어 DMA, 스트림 및 원격 쓰기 업데이트들보다 스칼라 기타 명령들을 우선순위화하기 위해, 판독 및 쓰기 포트들에 대해 개별적으로 사이클별 중재를 구현할 수 있다. TAC 및 TEC의 동기화 플래그 레지스터들은 또한 비트들의 개수, "완료" 비트 및 "enable_public_access" 비트를 저장할 수 있다.[0106] The synchronization flags 418 may be organized in memory as multiple banks. Each entry may include a number of data bits, for example, 32 data bits plus a “complete” bit and an “enable_public_access” bit. Banks can implement cycle-by-cycle arbitration for read and write ports separately, for example, to prioritize scalar other commands over DMA, stream and remote write updates. The synchronization flag registers of TAC and TEC may also store the number of bits, the “complete” bit and the “enable_public_access” bit.
[0107] TAC 또는 TEX의 동기화 플래그들은 모놀리식 플롭 어레이로 구현되어 모든 소스들에서 동시에 액세스할 수 있다. 시퀀서 동기화 플래그들과 마찬가지로, 타일 동기화 플래그들은 쓰기들 간의 충돌들을 피하기 위해 우선순위 방식에 따라 관리될 수 있다.[0107] The synchronization flags of TAC or TEX are implemented as a monolithic flop array and can be accessed simultaneously from all sources. Like sequencer synchronization flags, tile synchronization flags can be managed according to a priority scheme to avoid conflicts between writes.
[0108] 도 5는 본 개시내용의 양태들에 따른, 희소 가속기의 복수의 타일들에 걸쳐 메모리를 갖는 예시적인 스크래치패드 메모리(500)의 블록도이다. 각각의 타일은 타일 스크래치패드 메모리 또는 TileSpmem으로 지칭되는 스크래치패드 메모리(502)의 각자의 부분을 포함할 수 있다. 타일 스크래치패드 메모리(502)는 하나 이상의 회로들로 구현된 로드/저장 인터페이스를 통해 타일에 의해 액세스될 수 있다. 타일 스크래치패드 메모리(502)는 또한 스트림 명령 전달들을 사용하여 타일 안팎으로 데이터를 이동시키기 위해 각자의 타일에 로컬인 버퍼로서 사용될 수 있다.[0108] Figure 5 is a block diagram of an example scratchpad memory 500 with memory across multiple tiles of a sparse accelerator, in accordance with aspects of the present disclosure. Each tile may include a respective portion of scratchpad memory 502, referred to as Tile Scratchpad Memory or TileSpmem. Tile scratchpad memory 502 may be accessed by tiles through a load/store interface implemented with one or more circuits. Tile scratchpad memory 502 can also be used as a buffer local to each tile to move data in and out of the tile using stream command transfers.
[0109] 도 5에 도시된 바와 같이, 각각의 타일 스크래치패드 메모리(502)는 다수의 뱅크들, 예를 들어 각각 뱅크 0-31로 라벨링된 32 개의 뱅크들을 포함할 수 있다. 각각의 뱅크는 균일한 양의 데이터, 예를 들어, 16 킬로바이트들을 보유할 수 있다. 각각의 뱅크는 4 바이트 워드들과 7 비트 에러 정정 코드 같은 다수의 워드들을 보유할 수 있다. 일부 예들에서, 뱅크들은 4096 개의 워드들을 보유할 수 있다. 스크래치패드 메모리(500)가 상이한 개수들의 타일 스크래치패드 메모리들(502)로 구현될 수 있고, 각각은 상이한 크기들의 상이한 뱅크들을 보유할 수 있다는 것이 이해된다. 각각의 뱅크는 또한 다양한 예들에서 상이한 크기들을 갖는 상이한 개수들의 워드를 저장하도록 구현될 수 있는 것으로 이해된다.[0109] As shown in FIG. 5, each tile scratchpad memory 502 may include multiple banks, for example, 32 banks, each labeled banks 0-31. Each bank can hold a uniform amount of data, for example 16 kilobytes. Each bank can hold multiple words, such as 4-byte words and a 7-bit error correction code. In some examples, banks may hold 4096 words. It is understood that scratchpad memory 500 may be implemented with different numbers of tiled scratchpad memories 502, each holding different banks of different sizes. It is understood that each bank may also be implemented to store different numbers of words with different sizes in various examples.
[0110] 타일 스크래치패드 메모리 내의 워드와 뱅크들은 17 비트 명령과 스트림 어드레스를 통해 액세스될 수 있지만, 어드레스의 정확한 크기와 포맷은 구현마다 다를 수 있다. 각각의 뱅크는 다음 인터페이스들 중 하나 이상을 구현할 수 있다. 타일 스크래치패드 메모리(502)는 수신된 어드레스 또는 어드레스 범위에 의해 지정된 뱅크 및 워드에 데이터를 로드 또는 저장하고 추가하라는 수신된 명령에 응답하여 뱅크별 로드 큐(도시되지 않음)에 액세스 요청을 인큐한다. 데이터를 저장하기 위해, 타일 스크래치패드 메모리(502)는 수신 저장 또는 저장-추가 명령으로부터 뱅크별 로드 큐에 액세스 요청을 인큐한다. 각각의 뱅크는 또한 데이터 판독/쓰기에 대한 DMA 또는 스트림 요청과 같은 하나 이상의 외부 소스들로부터 판독 액세스를 수신할 수 있다. 타일 스크래치패드 메모리들(502)에 대한 예시적인 명령들은 벡터 로드 및 벡터 저장 명령들을 포함한다. 이러한 명령 및 다른 명령은 하드웨어 회로(101)에 대한 ISA에 지정될 수 있고, 이는 하드웨어 회로(101)가 명령들의 수신에 응답하여 소정 미리 결정된 오퍼레이션들을 수행하게 하는 명령들을 정의한다. 벡터 로드 명령들은 뱅크 로드 큐로 발행될 수 있다. 유사하게, 벡터 저장 명령이 뱅크 저장 큐에 발행될 수 있다. 벡터 저장-추가 명령은 하드웨어 회로(101)가 타일 스크래치패드 메모리들(502)의 하나 이상의 뱅크들 내의 어드레스들의 타겟 범위에서 판독-수정-쓰기 오퍼레이션을 수행하게 하는 명령 유형을 지칭할 수 있다.[0110] Words and banks within the tile scratchpad memory can be accessed through 17-bit command and stream addresses, but the exact size and format of the addresses may vary between implementations. Each bank may implement one or more of the following interfaces: Tile scratchpad memory 502 enqueues access requests in a per-bank load queue (not shown) in response to received commands to load or store and append data to banks and words specified by the received address or address range. . To store data, tile scratchpad memory 502 enqueues access requests from incoming store or store-add commands to a per-bank load queue. Each bank may also receive read accesses from one or more external sources, such as DMA or stream requests to read/write data. Example instructions for tile scratchpad memories 502 include vector load and vector store instructions. These and other instructions may be assigned to an ISA for hardware circuitry 101, which defines instructions that cause hardware circuitry 101 to perform certain predetermined operations in response to receipt of the instructions. Vector load instructions can be issued to the bank load queue. Similarly, a vector store command may be issued to the bank store queue. A vector store-add instruction may refer to a type of instruction that causes hardware circuitry 101 to perform a read-modify-write operation on a target range of addresses within one or more banks of tile scratchpad memories 502.
[0111] 타일 스크래치패드 메모리들의 뱅크들에 대한 로드 및 저장의 우선순위를 핸들링하기 위해, 뱅크별 저장 큐의 헤드에서의 저장 액세스는 각자의 뱅크의 쓰기 포트에 액세스하는 데 가장 높은 우선순위를 가질 수 있다(도 5에 도시되지 않음). 뱅크별 로드 큐의 헤드에서의 로드 액세스는 뱅크의 판독 포트에 액세스하는 데 가장 높은 우선순위를 가질 수 있다. 로드가 큐잉된 저장소와 동일한 어드레스로 이루어지고, 저장소가 로드 전에 발행된 명령 번들에서 온 경우, 뱅크는 데이터를 로드하는 대신, 저장소 큐에서 데이터를 판독할 수 있다.[0111] To handle the priorities of loads and stores for banks of tile scratchpad memories, store access at the head of the bank-specific store queue will have the highest priority to access the write port of the respective bank. (not shown in Figure 5). Load accesses at the head of the per-bank load queue may have the highest priority over accesses to the bank's read ports. If the load is to the same address as the queued store, and the store comes from an instruction bundle issued before the load, the bank may read data from the store queue instead of loading the data.
[0112] 뱅크를 호스팅하는 타일의 외부 소스로부터의 액세스들은 액세스가 뱅크에 제시되기 전에 다단계 중재를 거칠 수 있다. 예를 들어, 상이한 소스들로부터의 쓰기들 또는 추가들은 먼저 타겟 뱅크의 뱅크별 쓰기 큐에 인큐잉되는 이들 사이에서 뱅크별 LRU(least recently used) 중재를 거칠 수 있다. 쓰기 큐는 예로서 4 개 엔트리 깊이일 수 있다. 유사하게, 상이한 소스들의 판독 액세스 요청들은 또한 LRU 중재를 거칠 수 있다. 이어서 승리한 판독 요청은 스트림 추가 액세스 및 뱅크 판독을 위한 로드 액세스에서 발생하는 판독 요청과 함께 제2 레벨 중재를 거칠 수 있다. 스트림 추가 액세스는 판독-수정-쓰기 오퍼레이션을 수행하며, 이 오퍼레이션은 또한 뱅크별 쓰기 큐에 인큐잉된다. 뱅크의 쓰기 큐 헤드가 스트림 추가 액세스인 경우, 자신의 판독 요청은 승리한 외부 판독 요청들과 함께 라운드 로빈 중재를 거칠 수 있다. 승리한 판독 요청은 로드 액세스들 다음으로 뱅크의 판독 포트에서 두 번째로 높은 우선순위를 갖는다. 뱅크별 쓰기 큐의 헤드에서의 쓰기 요청은 저장소 액세스 다음으로 뱅크 쓰기 포트에 대해 두 번째로 높은 우선순위를 가질 수 있다. 뱅크 충돌이 없는 경우, 뱅크는 사이클당 적어도 하나의 스트림 추가 오퍼레이션의 처리량을 유지할 수 있다.[0112] Accesses from sources external to the tile hosting the bank may undergo multi-step arbitration before the access is presented to the bank. For example, writes or additions from different sources may first undergo per-bank least recently used (LRU) arbitration between them, where they are enqueued in the per-bank write queue of the target bank. The write queue may be 4 entries deep, for example. Similarly, read access requests from different sources may also undergo LRU arbitration. The winning read request may then undergo second level arbitration along with read requests arising from stream add accesses and load accesses for bank reads. Stream append accesses perform read-modify-write operations, which are also enqueued in the per-bank write queue. If the bank's write queue head is a stream append access, its own read request may undergo round-robin arbitration with winning external read requests. The winning read request has the second highest priority on the bank's read port after load accesses. Write requests at the head of the per-bank write queue may have the second highest priority for a bank write port after storage access. In the absence of bank conflicts, a bank can sustain a throughput of at least one stream append operation per cycle.
[0113] 타일 스크래치패드 메모리(502)의 각각의 뱅크는 뱅크로부터 및 뱅크로의 판독 및 쓰기 위한 포트들을 포함한다(도 5에 도시되지 않음). 이러한 포트들은 부족을 검출하기 위한 경고들을 생성할 수 있다. 소스들이 로드들, 저장들 또는 저장-추가들에 의해 지속적으로 액세스되는 뱅크에 액세스하는 경우 판독 및 쓰기 요청들의 외부 소스들은 부족해질 수 있다. 부족 가능성은 타일 스크래치패드 메모리(502)의 총 뱅크들 개수의 최대 액세스를 지정함으로써 완화될 수 있고, 예를 들어 주어진 클록 사이클에서 32 개 뱅크들 중 최대 8 개의 액세스만 허용한다.[0113] Each bank of tile scratchpad memory 502 includes ports for reading and writing to and from the bank (not shown in Figure 5). These ports can generate alerts to detect shortages. External sources of read and write requests can become starved if the sources access a bank that is continuously accessed by loads, stores, or store-adds. The possibility of a shortage can be mitigated by specifying a maximum access of the total number of banks of tile scratchpad memory 502, for example allowing access to only a maximum of 8 of the 32 banks in a given clock cycle.
[0114] 부족에 대해 생성된 경고들은 미리 결정된 임계치들에 기반할 수 있다. 예를 들어, 미리 결정된 임계치들은 외부 소스가 판독 또는 쓰기 요청을 위해 뱅크에 액세스하지 않는 동안 연속적인 클록 사이클의 개수일 수 있다.[0114] Alerts generated for shortages may be based on predetermined thresholds. For example, predetermined thresholds may be the number of consecutive clock cycles during which an external source does not access the bank for a read or write request.
[0115] 판독 포트 부족이 타일 스크래치패드 메모리(502)의 뱅크에 의해 검출되면, 하나 이상의 조치들은 스캐터/수집 엔진에 의해 수행될 수 있다. 번들이 로드, 저장 또는 저장-추가 명령들을 갖는 경우, 홀드 문제가 실행될 수 있다. 뱅크별 로드 및 저장 큐들은 정상적으로 비워질 수 있다. 홀드 문제는 판독 요청들의 미리 결정된 최대 개수가 스캐터-수집 엔진에 의해 서비스될 때까지, 또는 스캐터-수집 엔진 판독 큐가 비어 있는 경우 계속될 수 있다.[0115] If a read port shortage is detected by the bank of tile scratchpad memory 502, one or more actions may be performed by the scatter/collect engine. If the bundle has load, store or store-append instructions, a hold problem may occur. Load and store queues for each bank can be emptied normally. The hold problem may continue until a predetermined maximum number of read requests are serviced by the scatter-collect engine, or when the scatter-collect engine read queue is empty.
[0116] 쓰기 포트 부족이 타일 스크래치패드 메모리(502)의 뱅크에 의해 검출되면, 다음 시퀀스가 실행된다. 명령 번들이 저장 또는 저장-추가 명령을 갖는 경우 문제가 홀딩된다. 각각의 뱅크별 저장소 큐는 정상적으로 비워진다. 문제는 홀딩된 문제 요청들의 최대 임계치가 스캐터-수집 엔진에 의해 서비스될 때까지 계속 홀딩될 수 있다. 임계치들 및 사이클 카운트들은 구현마다 다를 수 있다.[0116] If a write port shortage is detected by the bank of tile scratchpad memory 502, the following sequence is executed. The problem is held if the instruction bundle has a store or store-append instruction. The storage queue for each bank is normally emptied. A problem may remain held until the maximum threshold of held problem requests has been serviced by the scatter-collection engine. Thresholds and cycle counts may vary from implementation to implementation.
[0117] 일부 예들에서 동기화 플래그 메모리(412)는 4 개의 뱅크들(도시되지 않음)로 구성될 수 있다. 각각의 엔트리는 32 비트의 데이터를 가질 수 있다. 동기화 플래그 메모리(412)의 각각의 뱅크는 다음 소스들 중에서 판독 및 쓰기 포트들에 대해 개별적으로 사이클별 중재를 수행할 수 있다: 스칼라 기타 명령들은 절대 우선순위를 갖는다. 일부 예들에서, 스칼라 기타 명령들 중 하나만이 임의의 주어진 사이클에서 발행될 수 있다. 판독-수정-쓰기 오퍼레이션들은 파이프라인화될 수 있으므로, 모든 위치에 대한 연이은 판독-수정-쓰기 오퍼레이션들이 지원될 수 있다. 스칼라 기타 명령들 이후, DMA 업데이트들, 스트림 업데이트들 및 원격 쓰기들은 라운드 로빈 중재를 통해 단일(외부) 인터페이스로 결합될 수 있고 다음으로 높은 우선 순위를 가질 수 있다. 제어 상태 레지스터를 통해 호스트에서 하드웨어 회로(101)로의 액세스들은 가장 낮은 우선순위를 갖는다.[0117] In some examples, synchronization flag memory 412 may be comprised of four banks (not shown). Each entry can have 32 bits of data. Each bank of synchronization flag memory 412 can perform cycle-by-cycle arbitration separately for read and write ports from among the following sources: Scalar Other instructions have absolute priority. In some examples, only one of the scalar other instructions may be issued in any given cycle. Read-modify-write operations can be pipelined, so that consecutive read-modify-write operations for all locations can be supported. After scalar other instructions, DMA updates, stream updates and remote writes can be combined into a single (external) interface through round-robin arbitration and have the next highest priority. Accesses from the host to hardware circuit 101 via the control status register have the lowest priority.
[0118] 뱅크들에 대한 액세스 요청은 다수의 소스들에서 이루어질 수 있다. 코어 메모리 네트워크 판독은 DMA 또는 스트림 요청에 의해 비롯될 수 있는 코어 메모리 네트워크에서 나가는 판독 액세스이다. 액세스 요청은 DMA 또는 스트림 요청에 의해 발생하는 코어 메모리 네트워크로부터의 쓰기 액세스를 위한 코어 메모리 네트워크 쓰기일 수 있다. 액세스 요청은 스트림 어드레스, 예를 들어, 로컬 타일에서 판독된 간접 어드레스에서 이루어질 수 있다. 액세스 요청은 내부 스트림 판독 또는 쓰기에서 이루어질 수 있다.[0118] Access requests to banks may come from multiple sources. A core memory network read is a read access going out of the core memory network that can be originated by a DMA or stream request. The access request may be a core memory network write for a write access from the core memory network caused by a DMA or stream request. The access request may be made at a stream address, for example an indirect address read from a local tile. Access requests can be made on internal stream reads or writes.
[0119] 도 6은 본 개시내용의 양태들에 따른 타일 시퀀서의 스칼라 코어 콤플렉스(600)의 예시적인 블록도이다. 스칼라 코어 콤플렉스는 32 비트 스칼라 VLIW 코어일 수 있다. 스칼라 실행 파이프라인(601)은 스칼라 및 페치, 디코딩 및 실행과 같은 기타 명령들을 실행하도록 구성된 하나 이상의 회로들일 수 있다. 스칼라 코어 콤플렉스(600)는 프리페치된 명령 번들들을 실행한다. 실행 동안, 하나의 번들은 다음 PC 레지스터의 어드레스에 따라 블록당 페치된다. 각각의 번들은 2 개의 스칼라 명령들과 동시에 디코딩되어 실행되는 하나의 기타 명령을 포함할 수 있다.[0119] Figure 6 is an example block diagram of a scalar core complex 600 of a tile sequencer in accordance with aspects of the present disclosure. The scalar core complex may be a 32-bit scalar VLIW core. The scalar execution pipeline 601 may be one or more circuits configured to execute scalars and other instructions such as fetch, decode, and execute. The scalar core complex 600 executes prefetched instruction bundles. During execution, one bundle is fetched per block according to the address of the next PC register. Each bundle may contain two scalar instructions and one other instruction that is decoded and executed simultaneously.
[0120] 스칼라 실행 파이프라인(601)은 레지스터들(604) 및 ALU들(606)을 포함하는 32 비트 컴퓨팅 유닛들을 포함할 수 있다. 컴퓨팅 유닛들은 디스크립터들을 구성하는 데 사용되는 어드레스 계산, 루프 제어 및 스칼라 피연산자들을 제공한다. 콤플렉스(600)는 로드/저장 인터페이스를 통해 액세스될 수 있는 메모리(608)를 가진다. 메모리(608)는 프로그램 실행 동안 중간 스칼라 값들을 저장하기 위해 콤플렉스(601)에 의해 사용된다. 코어 유형은 예를 들어 그것이 타일 시퀀서의 일부인지, 타일의 TAC 또는 TEC의 일부인지에 따라 메모리(608)의 깊이를 정한다.[0120] The scalar execution pipeline 601 may include 32-bit computing units including registers 604 and ALUs 606. Computing units provide address calculation, loop control, and scalar operands used to construct descriptors. Complex 600 has memory 608 that can be accessed through a load/store interface. Memory 608 is used by complex 601 to store intermediate scalar values during program execution. The core type determines the depth of memory 608, for example, depending on whether it is part of a tile sequencer, a TAC or TEC of a tile.
[0121] 콤플렉스(600)는 디스크립터들(609)을 구성하고 디스크립터 스크래치패드 레지스터들(610)을 사용할 수 있다. 명령이 디스크립터 스크래치패드 레지스터들(610)을 사용하는 경우, 문제가 되는, 콤플렉스(600)는 명령의 지정된 디스크립터 스크래치 레지스터 어드레스에서 시작하여 N x 32비트 워드들을 페치한다. N의 값은 특정 디스크립터 유형에 따른다. 이어서 디스크립터들은 디스크립터 문제 FIFO(612)에 인큐잉된다.[0121] The complex 600 may configure descriptors 609 and use descriptor scratchpad registers 610. If the instruction uses descriptor scratchpad registers 610, then complex 600, which matters, fetches N x 32-bit words starting at the instruction's designated descriptor scratch register address. The value of N depends on the specific descriptor type. The descriptors are then enqueued into the descriptor issue FIFO 612.
교차 레인 프로세싱 유닛(XPU)Cross Lane Processing Unit (XPU)
[0122] 다음 설명과 도면들에 대한 참조는 XPU의 예시적인 구현들을 설명한다. 분산된 임베딩 훈련은, 효과적인 가속이 프로비저닝된 컴퓨팅, 이용 가능한 온칩 메인 메모리 대역폭(HBM) 및 칩 간 통신 대역폭의 활용에 달려 있기 때문에 가속화하기가 어렵다. 이들 컴퓨팅들을 활용하는 것은 컴퓨팅들이 동적이고 불규칙하기 때문에 어렵다. 추가로, 성능 병목 현상들은 모델마다 크게 다르고, 문제 공간은 새로운 알고리즘, 최적화기들, 모델 아키텍처들 등을 통해 빠르게 진화하고 있다. 새로운 알고리즘들을 표현하고 상이한 성능 병목 현상들을 최적화하는 유연성이 중요하다.[0122] The following description and reference to the drawings describe example implementations of an XPU. Distributed embedding training is difficult to accelerate because effective acceleration depends on utilization of provisioned compute, available on-chip main memory bandwidth (HBM), and inter-chip communication bandwidth. Exploiting these computations is difficult because they are dynamic and irregular. Additionally, performance bottlenecks vary greatly from model to model, and the problem space is rapidly evolving with new algorithms, optimizers, and model architectures. The flexibility to express new algorithms and optimize different performance bottlenecks is important.
[0123] 임베딩들은 기계 학습 태스크, 예를 들어, 자연어 프로세싱 태스크 또는 임베딩들의 사용으로 이점을 얻을 수 있는 다른 태스크들을 수행하기 위해 기계 학습 모델, 예를 들어, 신경망에 공급될 수 있다. 임베딩 계층들은 입력에서 임베딩들을 생성하도록 훈련된 신경망의 계층들이다. 생성 후에, 임베딩들은 다운스트림, 예를 들어 임베딩 계층들을 구현하는 신경망의 이후 계층들에 의해 프로세싱될 수 있다. 임베딩 계층들을 갖는 모델들은 낮은 컴퓨팅 밀도, 메모리 대역폭에 대한 상당한 스트레스, 큰 메모리 풋프린트로 인해 고유한 컴퓨팅 문제들을 제기한다. 추가로, 이러한 유형들의 모델들을 가속화하기 위해, 모델마다 성능 병목 현상들이 크게 다를 수 있다.[0123] Embeddings may be fed to a machine learning model, e.g., a neural network, to perform a machine learning task, e.g., a natural language processing task, or other tasks that may benefit from the use of the embeddings. Embedding layers are layers of a neural network that are trained to generate embeddings from input. After generation, the embeddings can be processed downstream, for example by later layers of a neural network implementing the embedding layers. Models with embedding layers pose unique computational challenges due to low computing density, significant stress on memory bandwidth, and large memory footprint. Additionally, to accelerate these types of models, performance bottlenecks can vary greatly from model to model.
[0124] 예를 들어 임베딩 함수 또는 맵은 조회 테이블이나, 희소 벡터, 조밀 행렬 곱셈으로 구현될 수 있다. 예를 들어, 임베딩 함수는 입력 벡터와 곱셈될 때, 입력 벡터에 대한 대응 임베딩을 생성하는 행렬로 구현될 수 있다. 예를 들어, 입력 벡터는 기계 학습 모델에 대한 입력 문장에 상이한 자연어 워드들의 유무를 나타내는 비트 벡터일 수 있다. 비트 벡터는 일반적으로 희소 벡터, 예를 들어 0 값들을 갖는 벡터의 50% 미만 또는 그 이상의 엘리먼트들일 것이고, 그 이유는 비트 벡터가 입력 문장을 형성할 수 있는 잠재적인 자연 워드들의 대규모 어휘에 대한 엘리먼트들을 포함할 것이기 때문이다. 입력 벡터와 임베딩 함수 행렬을 곱한 출력 벡터는 입력 문장을 나타내는 임베딩이다.[0124] For example, an embedding function or map can be implemented as a lookup table, sparse vector, or dense matrix multiplication. For example, an embedding function can be implemented as a matrix that, when multiplied by an input vector, produces a corresponding embedding for the input vector. For example, the input vector may be a bit vector indicating the presence or absence of different natural language words in the input sentence to the machine learning model. A bit vector will typically be a sparse vector, i.e., less than or more than 50% of the elements of the vector have zero values, because the bit vector has only a few elements of a large vocabulary of potential natural words that can form the input sentence. Because it will include them. The output vector, which is the product of the input vector and the embedding function matrix, is an embedding representing the input sentence.
[0125] 임베딩 함수는 예를 들어 수백 기가바이트 크기의 매우 큰 테이블일 수 있다. 결과적으로, 임베딩 함수는 단일 가속기 또는 프로세서의 메인 메모리에 맞지 않을 수 있으므로, 임베딩 생성은 각각 하나 이상의 가속기들을 갖는 다수의 노드들에 걸쳐 분산된다. 임베딩 테이블은 다수의 디바이스들, 예를 들어, 데이터센터 포드의 다수의 가속기들에 걸쳐 파티셔닝될 수 있다.[0125] The embedding function may be a very large table, for example hundreds of gigabytes in size. As a result, the embedding function may not fit in the main memory of a single accelerator or processor, so embedding generation is distributed across multiple nodes, each with one or more accelerators. The embedding table may be partitioned across multiple devices, for example multiple accelerators in a data center pod.
[0126] 분산은 이러한 임베딩 함수들을 구현하는 이러한 임베딩 계층들을 프로세싱하는 데 복잡성을 생성한다. 본 개시내용의 양태들은 입력 샘플들의 개별 또는 배치(batch)들에 대한 임베딩들의 생성을 용이하게 하기 위해 상이한 입력 값들을 산란, 수집, 유니쿼파잉(uniquifying) 및 합산하기 위한 상이한 오퍼레이션들을 가속화하는 것을 제공한다. 대규모 임베딩 테이블은 다수의 가속기들에 걸쳐 파티셔닝될 수 있다. 설명의 편의를 위해, 다음 설명은 단일 가속기, 예를 들어 하드웨어 회로(101)에 중점을 둘 것이다. 추가로, 본원에 제공된 예들은 기계 번역과 같은 자연어 프로세싱 태스크들을 위한 임베딩을 설명할 것이지만, 본 개시내용의 양태들이 각자의 기계 학습 태스크를 수행하기 위한 임베딩 생성에 적어도 부분적으로 의존하는 임의의 유형의 기계 학습 모델을 가속화할 수 있다는 것이 이해된다. 다른 예들은 예를 들어 멀티미디어 추천, 검색 결과 랭킹 및 광고와 같은 도메인들에서 볼 수 있는 콘텐츠 추천 시스템들과 같은 추천 시스템들을 포함한다.[0126] Distribution creates complexity in processing these embedding layers that implement these embedding functions. Aspects of the present disclosure provide for accelerating different operations for scattering, collecting, uniqifying and summing different input values to facilitate the generation of embeddings for individual or batches of input samples. to provide. Large embedding tables can be partitioned across multiple accelerators. For convenience of explanation, the following description will focus on a single accelerator, for example hardware circuit 101. Additionally, although examples provided herein will illustrate embeddings for natural language processing tasks such as machine translation, aspects of the present disclosure may be used to describe any type of embedding that relies at least in part on generating embeddings to perform the respective machine learning task. It makes sense that machine learning models can be accelerated. Other examples include recommendation systems, such as multimedia recommendation, search result ranking, and content recommendation systems found in domains such as advertising.
[0127] 예들이 임베딩 생성에 관하여 제공되지만, 본원에 설명된 동일한 기본 오퍼레이션들이 희소 행렬 곱셈과 같은 다른 희소 문제들을 해결하기 위해 다른 방식으로 어셈블리될 수 있다는 것이 이해된다. 이러한 유연성은 다양한 희소 문제들을 가속화할 수 있다. 희소 컴퓨팅은 과학 컴퓨팅 및/또는 그래프 분석과 같은 기계 학습 및 심층 신경망들 외에 다른 문제 공간들에 이용될 수 있다.[0127] Although examples are provided with respect to embedding generation, it is understood that the same basic operations described herein can be assembled in other ways to solve other sparse problems, such as sparse matrix multiplication. This flexibility can accelerate a variety of sparse problems. Sparse computing can be used in problem spaces other than machine learning and deep neural networks, such as scientific computing and/or graph analysis.
[0128] 본원에 설명된 하나 이상의 가속기들에 따라 프로세싱된 신경망의 순방향 전달에서, 입력은 하나 이상의 입력 샘플들의 배치일 수 있다. 입력 샘플들은 신경망의 하나 이상의 임베딩 계층들의 오퍼레이션들을 수행하는 하나 이상의 가속기들에 의해 프로세싱될 수 있다. 임베딩 계층들의 출력은 입력 배치의 각각의 샘플에 대해 하나씩, 하나 이상의 임베딩들로 구성된 배치이다. 입력 샘플들이 공통 길이, 예를 들어, 각각의 입력 샘플에 귀속되는 잠재적 특징들의 개수를 공유하더라도, 입력 샘플들이 다수의 비어 있거나 값이 0인 특징 값들을 가질 수 있다는 것이 유의된다.[0128] In a forward pass of a neural network processed according to one or more accelerators described herein, the input may be a batch of one or more input samples. Input samples may be processed by one or more accelerators that perform operations of one or more embedding layers of the neural network. The output of the embedding layers is a batch of one or more embeddings, one for each sample of the input batch. It is noted that although the input samples share a common length, e.g., the number of potential features attributed to each input sample, the input samples may have a number of empty or zero-valued feature values.
[0129] 순방향 전달에서, 입력 배치는 예를 들어, 하나 이상의 호스트 디바이스들에 걸쳐 다수의 상이한 가속기들로 파티셔닝된다.[0129] In forward forwarding, the input batch is partitioned into multiple different accelerators, for example, across one or more host devices.
[0130] 입력 배치는 값들의 벡터와 인덱스들의 벡터라는 2 개의 벡터들로 표현될 수 있다. 값들의 벡터는 배치의 입력 샘플들에 있는 각각의 식별자의 값들에 대응한다. 인덱스들은 입력 배치를 나타내는 텐서의 각각의 식별자 값들의 포지션을 지칭할 수 있다. 입력 배치는 파티셔닝되어, 입력 배치의 부분들은 상이한 가속기들로 전송된다. 파티셔닝된 입력 배치를 수신 시, 가속기는 입력을 "유니쿼파이"하여 입력 배치에 걸쳐 중복 식별자들을 제거할 수 있다. 입력을 유니쿼파잉하는 것은 동일한 식별자의 다중 인스턴스들을 제거하는 것을 지칭한다. 그렇게 하는 한 가지 이유는 칩 간 네트워크 사용량을 줄이고, 동일한 식별자에 대해 중복 액세스들을 하지 않음으로써 대역폭을 보존하는 것이다. 유니쿼피케이션은 임베딩 테이블에서 중복된 조회들을 방지한다. 유니쿼피케이션 후, 유니쿼파이된 입력 배치는 출력 임베딩을 생성하기 위해 임베딩 테이블의 각자의 부분들을 갖는 디바이스들에 배포된다. 분산 후, 생성된 임베딩들은 다양한 디바이스들에서 수집되어 임베딩을 요청하는 다른 디바이스로 반환될 수 있다.[0130] An input batch can be represented by two vectors: a vector of values and a vector of indices. The vector of values corresponds to the values of each identifier in the input samples of the batch. Indexes may refer to the position of each identifier value in the tensor representing the input batch. The input batch is partitioned, so parts of the input batch are sent to different accelerators. Upon receiving a partitioned batch of inputs, the accelerator can “unique” the input to remove duplicate identifiers across the batch of inputs. Uniqueizing input refers to removing multiple instances of the same identifier. One reason for doing so is to reduce inter-chip network usage and conserve bandwidth by not making duplicate accesses to the same identifier. Uniquification prevents duplicate lookups in the embedding table. After uniqification, the uniqubiated input batch is distributed to devices with their respective parts of the embedding table to generate output embeddings. After distribution, the generated embeddings can be collected from various devices and returned to other devices requesting the embedding.
[0131] 훈련 동안, 실측 임베딩과 예측 임베딩 사이의 에러율을 나타내는 기울기들은 각자의 파티션들을 업데이트하기 위해 임베딩 테이블의 파티션들을 저장하는 디바이스들에 유사하게 분산될 수 있다.[0131] During training, gradients representing the error rate between ground truth and predicted embeddings can be similarly distributed across devices storing partitions of the embedding table to update their respective partitions.
[0132] 본 개시내용의 양태들은 프로세서의 다수의 데이터 프로세싱 레인들에 걸쳐 데이터 의존 오퍼레이션들을 수행하기 위한 XPU에 관한 것이다. 각각의 데이터 의존 오퍼레이션을 위해 물리적으로 제작된 오퍼레이션별 회로들을 구현하는 대신, XPU는 XPU에 스택형 네트워크로 배열된 프로세싱 셀들과 크로스바들에 의해 수행되는 개별 오퍼레이션들을 구성하는 입력 신호들에 응답하여 상이한 오퍼레이션들을 수행하도록 구성될 수 있다. XPU는 다수의 SIMD 데이터 프로세싱 레인들의 값들에 걸쳐 오퍼레이팅한다. XPU는 SIMD 병렬 프로세싱을 위해 구성된 제2 코프로세서를 상보하는 코프로세서의 일부로 구현될 수 있다. XPU를 구현하는 코프로세서는 데이터 의존 오퍼레이션들을 수행하도록 구성될 수 있다.[0132] Aspects of the present disclosure relate to an XPU for performing data dependent operations across multiple data processing lanes of a processor. Instead of implementing physically manufactured operation-specific circuits for each data-dependent operation, the Can be configured to perform operations. The XPU operates across multiple SIMD data processing lanes. The XPU may be implemented as part of a coprocessor that complements a second coprocessor configured for SIMD parallel processing. A coprocessor implementing an XPU may be configured to perform data-dependent operations.
[0133] 본 개시내용의 양태들은 XPU가 XPU 없이 이전에 가능했던 것보다 효율적인 컴퓨팅을 위해 더 넓은 워크로드들을 가능하게 하는 프로세싱 파이프라인의 다운스트림 코프로세서에 데이터를 전달하기 전에 희소 데이터를 먼저 프로세싱하도록 제공한다. XPU가 다양한 데이터 의존 오퍼레이션들을 핸들링할 수 있기 때문에, 프로세싱 파이프라인들과 대응 프로세서들은 기존 SIMD 아키텍처에서 프로세싱하기 위해 입력 데이터를 미리 정의하는 제한 없이 설계될 수 있다. XPU 없이, 기존 SIMD 아키텍처들은 희소한 특징들의 컬렉션에서 생성을 기계 학습 모델에 임베딩하는 것과 같은 데이터 의존 오퍼레이션들을 효율적으로 가속화할 수 없다.[0133] Aspects of the present disclosure allow the Provided to do so. Because the XPU can handle a variety of data-dependent operations, processing pipelines and corresponding processors can be designed without the limitations of predefining input data for processing in existing SIMD architectures. Without an XPU, existing SIMD architectures cannot efficiently accelerate data-dependent operations, such as generating from a collection of sparse features and embedding them in a machine learning model.
[0134] 예시적인 데이터 의존 오퍼레이션들은 입력 훈련 예에 대한 임베딩을 생성하는 것을 포함한다. 임베딩은 벡터일 수 있거나, 임베딩보다 더 높은 차원을 갖는 입력으로부터 매핑된 일부 다른 데이터 구조일 수 있다. 임베딩 생성은 파이프라인에 따라 프로세싱되는 워크로드의 일부로 수행될 수 있다. 다른 예들로서, XPU는 벡터 분산 또는 수집 오퍼레이션들을 수행하고, 합들을 세그먼트화하고, 그리고/또는 희소 특징 텐서들을 파티셔닝할 수 있다. 본원에 설명된 XPU는 SIMD 병렬 프로세싱 패러다임에 따라 구축된 벡터 프로세싱 유닛과 같은 프로세서의 다른 컴포넌트들 또는 연결된 컴포넌트들에 대한 상보적 프로세싱 유닛일 수 있다. 하나 이상의 XPU들은 더 큰 프로세서의 각자의 프로세서 코어들에 연결될 수 있고, XPU 자체는 신경망들 훈련과 같은 소정 워크로드들의 성능을 가속화하기 위한 다른 컴포넌트들을 포함할 수 있다.[0134] Example data dependent operations include generating an embedding for an input training example. The embedding may be a vector, or some other data structure mapped from the input that has a higher dimension than the embedding. Embedding generation can be performed as part of the workload processed along the pipeline. As other examples, the XPU may perform vector spread or gather operations, segment sums, and/or partition sparse feature tensors. The XPU described herein may be a complementary processing unit to other components of the processor or connected components, such as a vector processing unit built according to the SIMD parallel processing paradigm. One or more XPUs may be connected to respective processor cores of a larger processor, and the XPU itself may include other components to accelerate performance of certain workloads, such as training neural networks.
[0135] 게다가, XPU는 소정 유형의 데이터 의존 오퍼레이션을 수행하는 것으로 제한되지 않으므로, 프로세서는 다수의 상이한 파이프라인들에 대한 다른 유형들의 프로세싱 유닛들을 보완하기 위해 XPU를 포함하도록 설계될 수 있다. XPU가 워크로드에 기반하여 구성될 수 있기 때문에, XPU의 물리적 풋프린트는 특수 회로들이 희소 데이터 컴퓨팅을 위한 보완 유닛들로서 프로세서에 물리적으로 제작되는 다른 접근법에 비해 감소된다. XPU의 기능은 또한 명령 세트의 사용 또는 호스트 프로세서의 기존 명령 세트에 대한 확장을 통해 확장될 수 있고, 파이프라인 데이터가 변경사항들을 수신함에 따라 상이한 데이터 의존 오퍼레이션들의 적응성을 더욱 개선시킬 수 있다. 명령들은 XPU의 개별 프로세싱 셀들과 크로스바들을 구성하기 위한 명령들의 변환을 담당하는 XPU의 컴포넌트들에 신호로 제공될 수 있다. XPU는 XPU를 구현하는 하드웨어 회로에 대해 대응 컴파일러에서 컴파일된 프로그램을 사용하여 구성될 수 있다.[0135] Furthermore, since an XPU is not limited to performing certain types of data-dependent operations, a processor may be designed to include an XPU to complement other types of processing units for multiple different pipelines. Because the XPU can be configured based on the workload, the physical footprint of the The functionality of the Instructions may be provided as signals to components of the XPU that are responsible for converting the instructions to configure the XPU's individual processing cells and crossbars. An XPU can be configured using programs compiled in a corresponding compiler for the hardware circuitry that implements the XPU.
[0136] XPU는 개별 프로세싱 셀들의 네트워크를 포함하고, 각각의 셀은 프로세싱 셀들 간의 크로스바 연결들을 통해 하나 이상의 데이터 프로세싱 레인들을 통과하는 데이터를 프로세싱한다. 각각의 데이터 프로세싱 레인은 프로세싱 동안 데이터를 임시로 저장하기 위한 하나 이상의 레지스터들을 포함할 수 있다. 각각의 프로세싱 셀은 다수의 피연산자들의 세트에 대해 하나 이상의 기본 오퍼레이션들을 수행하도록 구성된다. 제1 피연산자들의 세트는 프로세싱 셀에 의해 공유되는 프로세서의 데이터 프로세싱 레인으로부터의 입력으로 제공된다. 제2 피연산자들의 세트는 XPU의 다수의 데이터 프로세싱 레인들을 통한 데이터 송신을 조정하도록 구성된 크로스바에서 제공된다.[0136] The XPU includes a network of individual processing cells, each cell processing data passing through one or more data processing lanes through crossbar connections between the processing cells. Each data processing lane may include one or more registers for temporarily storing data during processing. Each processing cell is configured to perform one or more basic operations on a number of sets of operands. A first set of operands is provided as input from a data processing lane of the processor that is shared by the processing cells. A second set of operands is provided in a crossbar configured to coordinate data transmission through multiple data processing lanes of the XPU.
[0137] XPU는 다수의 파이프라인 스테이지들로 나눌 수 있고, 각각의 스테이지는 크로스바, 하나 이상의 프로세싱 셀들 및 각각의 프로세싱 셀에 대응하는 제어 셀을 포함한다. 스테이지들의 개수는 예를 들어 XPU가 현재 워크로드에 대해 수행하도록 구성된 구성 오퍼레이션에 기반하여 달라질 수 있다.[0137] The XPU can be divided into multiple pipeline stages, each stage including a crossbar, one or more processing cells, and a control cell corresponding to each processing cell. The number of stages may vary based, for example, on the configuration operation the XPU is currently configured to perform for the workload.
[0138] XPU는 프로세싱 엘리먼트들과 크로스바들의 적층형 네트워크의 파이프라인 스테이지들에 걸쳐 다수의 기본 오퍼레이션들을 수행하여 구성된 오퍼레이션을 수행한다. 구성된 오퍼레이션은 출력을 생성하기 위해 XPU에 의해 입력에 대해 수행되는 오퍼레이션이다. 기본 오퍼레이션들은XPU의 개별 프로세싱 셀들이 수행하도록 구성된 오퍼레이션들이고, 이는 XPU에 의해 실행될 때 XPU가 구성된 오퍼레이션을 수행하게 한다. 구성된 오퍼레이션을 수행하는 것은 다른 구성된 오퍼레이션들을 수행하는 것을 요구할 수 있다. 예를 들어, 벡터 정렬을 수행하기 위해, XPU는 다수의 기본 오퍼레이션들로 구성된 다른 오퍼레이션인 프리픽스 합산을 수행할 수 있다. 예시적인 기본 오퍼레이션들은 비교, 산술 또는 입력 데이터 바이패싱을 위한 오퍼레이션들을 포함한다. XPU는 XPU에 대한 다수의 파이프라인 스테이지들 중 하나에 따라 배열된 다수의 개별 프로세싱 셀들과 크로스바들 각각을 구성하여 구성된 오퍼레이션을 수행한다.[0138] The XPU performs the configured operation by performing a number of basic operations across pipeline stages of a stacked network of processing elements and crossbars. A composed operation is an operation performed on an input by the XPU to produce an output. Basic operations are operations that the individual processing cells of an XPU are configured to perform, which, when executed by the XPU, cause the XPU to perform the configured operation. Performing a configured operation may require performing other configured operations. For example, to perform vector sorting, the XPU can perform prefix sum, another operation consisting of multiple basic operations. Exemplary basic operations include operations for comparison, arithmetic, or bypassing input data. The XPU performs the configured operation by configuring each of a plurality of individual processing cells and crossbars arranged according to one of a plurality of pipeline stages for the XPU.
[0139] XPU의 각각의 스테이지에서 수행되는 기본 오퍼레이션들은 프로그래밍 방식으로 정의될 수 있고 워크로드마다 다를 수 있다. 프로세싱 셀이 수행하도록 구성된 기본 오퍼레이션은 프로세싱 셀에 대한 각자의 제어 셀에 의해 수신된 하나 이상의 제어 신호들 또는 명령들에 의해 결정된다. 프로세싱 셀에 의해 수행되는 정확한 기본 오퍼레이션들은 예를 들어 XPU가 현재 수행하도록 구성된 구성 오퍼레이션에 따를 수 있다. 다른 예들에서, XPU의 상이한 레인들 또는 상이한 스테이지들에 있는 프로세싱 셀들은 항상 하나 이상의 미리 결정된 기본 오퍼레이션들을 수행하도록 구성될 수 있다. XPU가 출력을 생성한 후, 출력은 다수의 데이터 프로세싱 레인들을 따라 XPU를 구현하는 프로세서의 다른 프로세싱 유닛 또는 메모리 유닛으로 전달될 수 있다.[0139] The basic operations performed at each stage of the XPU can be defined programmatically and may vary for each workload. The basic operation that a processing cell is configured to perform is determined by one or more control signals or commands received by the respective control cell for the processing cell. The exact basic operations performed by a processing cell may depend, for example, on the configuration operations the XPU is currently configured to perform. In other examples, processing cells in different lanes or different stages of an XPU may be configured to always perform one or more predetermined basic operations. After the XPU generates output, the output may be passed along multiple data processing lanes to another processing unit or memory unit of the processor implementing the XPU.
[0140] XPU가 실행할 수 있는 2 개의 예시적인 구성된 오퍼레이션들은 벡터 정렬과 벡터 중복 카운트를 실행할 수 있다. 벡터 정렬은 키에 의해 정렬된 입력 벡터의 (키, 값) 튜플(tuple)들의 제자리 안정적 정렬이다. 벡터 중복 카운트는 입력 벡터의 (키, 값) 튜플들의 값들의 실행 중복 카운트를 반환한다. XPU는 본원에 설명된 바와 같이 셀들 및 크로스바들을 프로세싱하는 동일한 구성에 따라 벡터 정렬 및 중복 카운트 둘 모두를 수행하도록 구성된다. 동일한 구성을 사용함으로써, XPU는 둘 모두의 구성된 오퍼레이션들을 더 효율적으로 수행할 수 있고, 이는 적어도 XPU가 주어진 입력 벡터에 대해 벡터 정렬과 벡터 중복 카운트를 수행하는 것 사이에 재구성될 필요가 없기 때문이다. XPU가 수행하도록 구성된 다른 구성된 오퍼레이션들은 병렬 프리픽스 합, 벡터 파티션, 벡터 히스토그램, 벡터 컴팩트, 벡터 치환, 벡터 축소, 벡터 시프트-삽입, 벡터 수집, 벡터 분산 등을 포함한다. 벡터 중복 카운트를 수행하는 것은 벡터 입력을 유니쿼파이하고 중복 프로세싱을 방지하는 데 사용될 수 있는 중복 값들의 존재를 식별하게 한다.[0140] Two example configured operations that an XPU can perform are vector sort and vector duplicate count. Vector sorting is an in-place stable sorting of (key, value) tuples of an input vector sorted by key. Vector duplicate count returns the execution duplicate count of the values of the (key, value) tuples of the input vector. The XPU is configured to perform both vector alignment and duplicate count according to the same configuration for processing cells and crossbars as described herein. By using the same configuration, the XPU can perform both configured operations more efficiently, at least because the . Other configured operations that the XPU is configured to perform include parallel prefix sum, vector partition, vector histogram, vector compact, vector permutation, vector reduction, vector shift-insertion, vector gather, vector spread, etc. Performing a vector duplicate count allows you to unequify the vector input and identify the presence of duplicate values, which can be used to prevent duplicate processing.
[0141] 본 개시내용의 양태들은 다음과 같은 기술적 장점들을 제공할 수 있다. XPU를 구현하는 하드웨어 회로는 임베딩 클래스 워크로드들 및 효율적으로 병렬화할 수 없는 다른 데이터 의존 오퍼레이션들을 위한 보다 유연하고 프로그래밍 가능한 하드웨어를 제공할 수 있다. XPU는 XPU가 소정 오퍼레이션들만 효율적으로 수행하도록 고정될 필요 없이, 워크로드별로 상이한 클래스들의 데이터 의존 오퍼레이션들에 대한 가속 경로를 제공한다. 본원에 설명된 바와 같이 프로그래밍 가능한 유닛을 제공함으로써, 하드웨어 회로를 구현하는 것은 상이한 워크로드들의 수요들에 견고하게 적응하여, 병렬화 가능한 데이터 독립적인 SIMD 오퍼레이션들을 보완할 수 있고, 그렇지 않으면 이는 데이터 의존 오퍼레이션들을 요구하는 워크로드들에 대해 비효율적이거나 비효과적일 수 있다.[0141] Aspects of the present disclosure may provide the following technical advantages. Hardware circuitry implementing an XPU can provide more flexible and programmable hardware for embedded class workloads and other data-dependent operations that cannot be efficiently parallelized. The XPU provides an acceleration path for data-dependent operations of different classes for each workload, without the XPU needing to be fixed to efficiently perform only certain operations. By providing programmable units as described herein, implementing hardware circuitry can be robustly adapted to the demands of different workloads, complementing parallelizable data-independent SIMD operations, which would otherwise be data-dependent operations. They may be inefficient or ineffective for workloads that require them.
[0142] 애플리케이션별 집적 회로와 같은 하드웨어 회로는 상이한 수량들의 XPU로 설계되어 워크로드들을 대규모로 조정하고 분산할 수 있다. 본원에 설명된 XPU는 또한 동일한 구성을 사용하여 다수의 오퍼레이션들의 효율적인 수행을 허용하여, 프로세싱 시간과 구성 시간을 더 줄인다. 예를 들어, XPU는 XPU의 별도 구성들 및/또는 이러한 오퍼레이션들을 가속화하기 위한 특수 회로들의 별도 인스턴스들 대신, 벡터 정렬 및 벡터 중복 카운팅 둘 모두를 수행하도록 구성될 수 있다.[0142] Hardware circuits, such as application-specific integrated circuits, can be designed with different quantities of XPUs to scale and distribute workloads. The XPU described herein also allows efficient performance of multiple operations using the same configuration, further reducing processing time and configuration time. For example, an XPU may be configured to perform both vector sorting and vector duplicate counting, instead of separate components of the XPU and/or separate instances of special circuits to accelerate these operations.
[0143] 도 7은 예시적인 XPU(700)의 블록도이다. XPU(700)는 프로세싱 셀들(701-709), 크로스바들(703-711), 제어 셀들(750)(도 7의 블록도에서 빗금친 블록들로 표시됨)을 포함한다. 데이터는 데이터 프로세싱 레인들(700A-H)을 따라 아래에서 위로 흐르고, 스테이지 1에서 시작하여 스테이지 6에서 끝난다. 스테이지 1은 프로세싱 셀들(701)과 크로스바(702)를 포함한다. 스테이지 2는 프로세싱 셀들(703)과 크로스바(704)를 포함한다. 스테이지 3은 프로세싱 셀들(705)과 크로스바(706)를 포함한다. 스테이지 4는 프로세싱 셀들(707)과 크로스바(708)를 포함한다. 스테이지 5는 프로세싱 셀들(709)과 크로스바(711)를 포함한다. 스테이지 6은 프로세싱 셀들(711)과 크로스바(712)를 포함한다. 상이한 예들에서, XPU는 더 많거나 더 적은 스테이지들을 포함할 수 있다. XPU는 또한 크로스바(799)를 포함할 수 있다. [0143] Figure 7 is a block diagram of an example XPU 700. XPU 700 includes processing cells 701-709, crossbars 703-711, and control cells 750 (represented by shaded blocks in the block diagram of FIG. 7). Data flows from bottom to top along data processing lanes 700A-H, starting at stage 1 and ending at stage 6. Stage 1 includes processing cells 701 and crossbar 702. Stage 2 includes processing cells 703 and crossbar 704. Stage 3 includes processing cells 705 and crossbar 706. Stage 4 includes processing cells 707 and crossbar 708. Stage 5 includes processing cells 709 and crossbar 711. Stage 6 includes processing cells 711 and crossbar 712. In different examples, an XPU may include more or fewer stages. The XPU may also include a crossbar 799.
[0144] 설명을 위해 이전 스테이지들은 이후 스테이지에 대한 "업스트림"으로 간주되고, 이후 스테이지들은 이전 스테이지들에 대한 "다운스트림"으로 간주된다. 예를 들어, 스테이지 1은 스테이지 5의 업스트림이고, 스테이지 4는 스테이지 3의 다운스트림이다.[0144] For purposes of explanation, earlier stages are considered “upstream” of later stages, and later stages are considered “downstream” of earlier stages. For example, stage 1 is upstream of stage 5, and stage 4 is downstream of stage 3.
[0145] XPU의 각각의 스테이지에 있는 크로스바는 크로스바의 현재 구성에 따라 각자의 레인들의 상이한 입력 값들을 상이한 다른 프로세싱 레인들로 치환하도록 구성된 모든 유형의 회로일 수 있다. 크로스바는 크로스바와 동일한 스테이지의 각각의 프로세싱 셀에 대한 제어 셀들로부터 하나 이상의 제어 신호들을 수신할 수 있다. 크로스바는 고정된 패턴에 따라 동일한 스테이지의 각각의 프로세싱 셀에서 입력 값들을 치환하도록 구성된다. 패턴은 XPU가 현재 수행하도록 구성된 구성 오퍼레이션에 따르고 반드시 크로스바가 모든 프로세싱 셀 출력을 치환하게 하지 않는다. 즉, 일부 프로세싱 셀 출력은 크로스바를 바이패스하여 동일한 프로세싱 레인을 따라 다음 스테이지로 진행될 수 있다.[0145] The crossbar in each stage of the The crossbar may receive one or more control signals from control cells for each processing cell of the same stage as the crossbar. The crossbar is configured to replace input values in each processing cell of the same stage according to a fixed pattern. The pattern follows the configuration operation the XPU is currently configured to perform and does not necessarily cause the crossbar to replace all processing cell outputs. That is, some processing cell outputs can bypass the crossbar and proceed to the next stage along the same processing lane.
[0146] 프로세싱 셀을 구성하기 위해, XPU(700)의 각각의 프로세싱 셀은 프로세싱 셀이 상주하는 각자의 프로세싱 레인을 따라 하나 이상의 제어 신호들을 수신하도록 구성된 각자의 제어 셀(750)을 갖는다. 프로세싱 셀은 도 7을 참조하여 더 상세히 설명된 바와 같이, 다양한 상이한 기본 오퍼레이션들을 수행하고 수신된 제어 신호들 또는 명령들에 따라 이러한 오퍼레이션들을 수행하는 회로로 구성된다. 제어 셀은 예를 들어 대응하는 프로세싱 셀이 어떤 기본 오퍼레이션을 수행할지 결정하기 위해 제어 셀에 의해 해석될 수 있는 하나 이상의 신호들로서 데이터 프로세싱 레인을 따라 명령들을 수신한다. 제어 셀은 제어 신호(들)를 프로세싱 셀에 포워딩할 수 있거나, 수신된 명령들 또는 신호들을 프로세싱하고 프로세싱 셀이 지정된 기본 오퍼레이션들의 실행을 인에이블 또는 디스에이블하기 위해 수신하도록 구성된 생성된 제어 신호들을 포워딩할 수 있다.[0146] To configure a processing cell, each processing cell of XPU 700 has a respective control cell 750 configured to receive one or more control signals along the respective processing lane on which the processing cell resides. The processing cell is comprised of circuitry that performs a variety of different basic operations and performs these operations in accordance with received control signals or commands, as described in more detail with reference to FIG. 7. A control cell receives instructions along the data processing lane as one or more signals that can be interpreted by the control cell, for example, to determine what basic operation the corresponding processing cell will perform. The control cell may forward control signal(s) to the processing cell or generate control signals that the processing cell is configured to receive to process the received instructions or signals and enable or disable execution of specified basic operations. Forwarding is possible.
[0147] 프로세싱 셀들은 또한 프로세싱 셀에 대한 각자의 프로세싱 레인으로부터 수신된 입력 데이터를 바이패스하도록 구성될 수 있다. 바이패스되면, 수신된 입력은 수정 없이 프로세싱 셀로부터 프로세싱 셀과 동일한 스테이지의 크로스바로 전달된다. 바이패스 프로세싱 셀에 의해 이전 스테이지의 크로스바로부터 수신된 입력은 0에 결부되거나 무시될 수 있다. 바이패스 프로세싱 셀의 실제 거동은 셀이 있는 파이프라인 스테이지 및/또는 프로세싱 셀이 있는 프로세싱 레인에 따를 수 있다. 본원에 설명된 도 7은 비교, 산술 및/또는 기본 오퍼레이션들의 바이패스를 수행하도록 구성된 예시적인 프로세싱 셀을 도시한다.[0147] Processing cells may also be configured to bypass input data received from the respective processing lane for the processing cell. When bypassed, received input is passed without modification from the processing cell to the crossbar in the same stage as the processing cell. Input received from the crossbar of the previous stage by the bypass processing cell may be tied to 0 or ignored. The actual behavior of a bypass processing cell may depend on the pipeline stage on which the cell resides and/or on the processing lane on which the processing cell resides. FIG. 7 described herein illustrates an example processing cell configured to perform comparison, arithmetic and/or bypass basic operations.
[0148] XPU(700)는 명령 세트 아키텍처의 일부로서 정의된 명령들 또는 XPU(700)를 구현하는 프로세서가 적용 및 실행하도록 구성된 명령 세트 아키텍처에 대한 확장을 수신하도록 구성될 수 있다. 명령들은 XPU 및 개별 프로세싱 셀들이 각각 대응 오퍼레이션들로 실행하도록 구성된 상이한 구성 및/또는 기본 오퍼레이션들을 지정할 수 있다. 제어 셀들(750)은 명령 세트 또는 확장의 일부로서 정의된 명령들을 나타내는 데이터를 수신하고/하거나 명령들을 대응하는 프로세싱 셀을 구성하기 위한 제어 신호들로 변환하도록 구성된다. 예를 들어, 제어 셀들(750)은 XPU(700)를 구현하는 프로세서 또는 하드웨어 회로에 대응하는 명령 세트의 연산부호들 ― XPU가 수행하도록 구성된 오퍼레이션들에 대한 코드 워드 ―로서 신호들을 수신할 수 있다. XPU(700)가 벡터 정렬 또는 벡터 중복 카운팅과 같은 구성 오퍼레이션들을 수행하기 위한 명령들을 수신하는 경우, XPU(700)는 XPU가 명령된 구성 오퍼레이션을 수행하게 하는 미리 결정된 각자의 기본 오퍼레이션을 수행하도록 각각의 프로세싱 셀을 구성할 수 있다.[0148] XPU 700 may be configured to receive instructions defined as part of an instruction set architecture or extensions to the instruction set architecture that a processor implementing XPU 700 is configured to apply and execute. The instructions may specify different configurations and/or basic operations that the XPU and individual processing cells are each configured to execute with corresponding operations. Control cells 750 are configured to receive data representing instructions defined as part of an instruction set or extension and/or convert the instructions into control signals for configuring a corresponding processing cell. For example, control cells 750 may receive signals as opcodes of an instruction set corresponding to a processor or hardware circuit implementing XPU 700—code words for operations that the XPU is configured to perform. . When the XPU 700 receives instructions to perform configuration operations such as vector sorting or vector redundancy counting, the processing cells can be configured.
[0149] XPU에 의해 수행되는 오퍼레이션들은 클록 사이클에 의해 동기화될 수 있다. 예를 들어, 각각의 스테이지의 셀들을 프로세싱하여 수행되는 오퍼레이션들은 하나 이상의 사이클들로 수행될 수 있다. 예를 들어, 각각의 스테이지의 오퍼레이션들은 단일 사이클로 수행될 수 있다. XPU에 의해 수행되는 상이한 구성 오퍼레이션들은 수행하는 데 상이한 양의 클록 사이클들을 취할 수 있다. 예를 들어, 벡터 정렬은 XPU에 의해 6 사이클들로 수행되고, 벡터 프리픽스 합산은 4 사이클들로, 벡터 압축은 2 사이클들로 수행될 수 있다.[0149] Operations performed by the XPU may be synchronized by clock cycles. For example, operations performed by processing cells of each stage may be performed in one or more cycles. For example, the operations of each stage can be performed in a single cycle. Different configuration operations performed by the XPU may take different amounts of clock cycles to perform. For example, vector sorting may be performed by the XPU in 6 cycles, vector prefix summing in 4 cycles, and vector compression in 2 cycles.
[0150] 도 7과 관련하여 더 상세히 설명된 바와 같이, 프로세싱 셀들은 부동 소수점 값들 및 부호 있는 또는 부호 없는 정수들을 포함하여 상이한 유형들의 피연산자들 간의 덧셈과 같은 산술 오퍼레이션들을 수행하도록 구성될 수 있다. 덧셈과 같은 산술 오퍼레이션들은 스캐닝 오퍼레이션들을 위해 XPU에 의해 수행되는 구성 오퍼레이션들의 일부를 형성할 수 있다.[0150] As described in more detail with respect to Figure 7, processing cells may be configured to perform arithmetic operations, such as addition between different types of operands, including floating point values and signed or unsigned integers. Arithmetic operations such as addition may form part of the configuration operations performed by the XPU for scanning operations.
[0151] 예시적인 명령들은 XPU를 리셋하고 XPU에 의해 수행되는 클록 동기화 및 기본 오퍼레이션들에 대한 정보를 검색하기 위한 명령들을 포함한다. 다른 명령들은 각각의 프로세싱 레인에서 하나 이상의 피연산자들, 마스크 값들 및/또는 세그먼트 마커들을 검색하기 위한 명령들을 포함한다. 명령들은 XPU에 의해 지원되는 다양한 상이한 구성 오퍼레이션들 각각을 지정하는 제어 정보와 함께 XPU에 의해 저장된 데이터 구조에 액세스하기 위한 명령들을 포함할 수 있다. 또 다른 예들에서, 명령들은 XPU가 데이터를 다양한 레지스터들, 래치들 또는 플립플롭들에 푸시하게 하고, 전술한 내용들이 유효한지 여부를 결정하기 위한 명령들을 포함할 수 있다. 푸시된 데이터는 예를 들어 구성 오퍼레이션 수행의 일부로 프로세싱되는 값들 및/또는 마스크 값들을 포함할 수 있다.[0151] Example instructions include instructions for resetting the XPU and retrieving information about clock synchronization and basic operations performed by the XPU. Other instructions include instructions for retrieving one or more operands, mask values, and/or segment markers in each processing lane. The instructions may include instructions for accessing data structures stored by the XPU along with control information specifying each of the various different configuration operations supported by the XPU. In still other examples, the instructions may include instructions to cause the XPU to push data to various registers, latches, or flip-flops, and to determine whether the foregoing is valid. Pushed data may include mask values and/or values that are processed as part of performing a configuration operation, for example.
[0152] 구성된 XPU(700)는 특정 구성 오퍼레이션을 수행하기 위한 프로세싱 네트워크를 구현한다고 말해진다. 예를 들어, XPU(700)는 48 개의 XPU 셀들을 포함하고, 이는 다음과 같이 구성될 수 있다: 18 개의 셀들은 산술 오퍼레이션들을 위해 구성될 수 있고, 38 개의 셀들은 입력 값들을 비교하기 위해 구성될 수 있고(하나의 셀은 산술 오퍼레이션과 비교 오퍼레이션 둘 모두를 위해 구성될 수 있음), 10 개의 셀들은 입력을 바이패스하도록 구성될 수 있다. 새로운 명령들에 응답하여, XPU(700)는 새로운 프로세싱 네트워크로 자체를 재구성하여, 상이한 구성 오퍼레이션을 수행할 수 있다.[0152] A configured XPU 700 is said to implement a processing network for performing specific configuration operations. For example, XPU 700 includes 48 XPU cells, which may be configured as follows: 18 cells may be configured for arithmetic operations and 38 cells may be configured for comparing input values. (one cell can be configured for both arithmetic and comparison operations), and 10 cells can be configured to bypass the input. In response to new instructions, XPU 700 may reconfigure itself with a new processing network and perform different configuration operations.
[0153] XPU는 다양한 상이한 오퍼레이팅 모드들에서 오퍼레이팅하도록 구성될 수 있고, 이는 명령 세트 또는 확장에서 상이한 명령들로서 지정될 수 있다. 상이한 오퍼레이팅 모드들은 정렬, 중복 카운팅, 스캐닝, 파티셔닝 및/또는 XPU에 입력된 데이터의 고유 값들의 식별을 위해 상이한 구성 오퍼레이션들을 포함할 수 있다. 추가로, 명령들은 정렬이나 스캐닝을 위한 부호 없는 정수 비교 또는 부동 소수점 덧셈과 같이 수행할 비교 또는 산술 오퍼레이션의 유형을 지정하는 피연산자들을 포함할 수 있다. 구성 오퍼레이션들을 수행하기 위한 명령들에 대한 다른 피연산자들은 구성 오퍼레이션의 출력이 XPU(700)에서 나오는 프로세싱 레인을 지정하는 것을 포함한다. 수신된 다른 피연산자들은 예를 들어 데이터 프로세싱 레인들에 걸쳐 XPU(700)에 의해 수신된 데이터의 다수의 세그먼트들 각각을 정렬하기 위해 입력 데이터의 세그먼트들에 대해 구성된 오퍼레이션을 수행하기 위한 세그먼트 마커들을 포함할 수 있다.[0153] An XPU may be configured to operate in a variety of different operating modes, which may be specified as different instructions in an instruction set or extension. Different operating modes may include different configuration operations for sorting, duplicate counting, scanning, partitioning and/or identification of unique values of data input to the XPU. Additionally, instructions may include operands that specify the type of comparison or arithmetic operation to be performed, such as unsigned integer comparison or floating point addition for sorting or scanning. Other operands to instructions for performing configuration operations include specifying the processing lane on which the output of the configuration operation comes from XPU 700. Other operands received include segment markers for performing configured operations on segments of input data, for example, to align each of the multiple segments of data received by XPU 700 across data processing lanes. can do.
[0154] 벡터 정렬 및/또는 벡터 중복 카운트를 수행할 때, XPU(700)는 홀수/짝수 병합 네트워크와, 값 셔플 네트워크를 포함하도록 구성된다. 네트워크 구성들은 XPU의 하나 이상의 스테이지들을 포함하고, 각각의 스테이지의 각자의 셀들과 크로스바들은 하나 이상의 기본 오퍼레이션들을 수행하도록 구성된다.[0154] When performing vector sorting and/or vector duplicate count, the XPU 700 is configured to include an odd/even merge network and a value shuffle network. Network configurations include one or more stages of an XPU, and respective cells and crossbars of each stage are configured to perform one or more basic operations.
[0155] XPU(700)는 레지스터 파일들(760A 및 760B)을 포함할 수 있다. 레지스터 파일들(760A-B)은 상이한 스테이지들 사이의 데이터 프로세싱 레인들(700A-H)에 결합되고 데이터를 저장하고 검색하는 데 사용될 수 있다. 예를 들어, 일부 데이터는 스테이지 4의 프로세싱 셀들(707) 이후에 레지스터 파일(760B)에 저장될 수 있는 반면, XPU(700)에 의해 출력된 데이터는 레지스터 파일(760A)에 저장된다.[0155] XPU 700 may include register files 760A and 760B. Register files 760A-B are coupled to data processing lanes 700A-H between different stages and may be used to store and retrieve data. For example, some data may be stored in register file 760B after processing cells 707 of Stage 4, while data output by XPU 700 is stored in register file 760A.
스트림 명령들 및 순서화 Stream instructions and sequencing
[0156] 본 개시내용의 양태들은 오프-코어 메모리와 코어-로컬 메모리 사이의 비동기 데이터 이동, 즉 "스트림 전달(stream transfer)"으로 지칭되는 메모리들 사이의 이동을 위한 하드웨어 또는 소프트웨어 인터페이스를 제공한다. 스트림 전달은 소프트웨어가 희소 워크로드들에서 볼 수 있는 것들과 같은 일반적인 데이터 이동 패턴을 표현하게 하는 스트림 디스크립터를 포함할 수 있다. 데이터는 스트림 또는 데이터 스트림으로 지칭될 수 있다. 스트림 전달은 스트림 명령들에 의해 개시될 수 있다. 스트림 명령들은 스트림 전달 실행에 필요한 정보를 인코딩할 수 있다. 각각의 스트림은 스트림 명령들과 연관된 데이터 동기화 플래그("sync flag")에 의해 표시되는 연관된 스트림 식별자(ID)를 가질 수 있다. 동일한 스트림 ID를 가진 코어에 의해 발행된 스트림 명령들은 적어도 부분적으로 단일 스트림을 형성할 수 있다.[0156] Aspects of the present disclosure provide a hardware or software interface for asynchronous data movement between off-core memory and core-local memory, i.e., movement between memories, referred to as “stream transfer.” . Stream delivery may include a stream descriptor that allows software to express common data movement patterns, such as those seen in sparse workloads. Data may be referred to as a stream or data stream. Stream delivery can be initiated by stream commands. Stream instructions can encode information necessary for stream delivery execution. Each stream may have an associated stream identifier (ID) indicated by a data synchronization flag (“sync flag”) associated with stream commands. Stream instructions issued by cores with the same stream ID may at least partially form a single stream.
[0157] 스트림 디스크립터는 스트림 전달 실행에 필요한 정보를 나타낼 수 있는 내부 데이터 구조이다. 예를 들어, 정보는 소스 어드레스, 목적지 어드레스, 스트림 오퍼레이션 코드, 선형 또는 순환 버퍼들과 같은 제어 정보를 포함할 수 있다.[0157] A stream descriptor is an internal data structure that can represent information necessary for stream delivery execution. For example, the information may include control information such as source address, destination address, stream operation code, linear or circular buffers.
[0158] 스트림 전달은 코어-로컬 메모리 간에만 데이터를 이동할 수 있다. 추가로, 코어-로컬 동기화 플래그들은 스트림 진행을 추적하는 데 사용될 수 있다. 동기화 플래그들은 스트림 전달의 부분적인 진행을 추적할 수 있다. 예를 들어, 플래그들이 미리 결정된 구성에 따라 지워지거나 설정되는지 여부에 따라, 동기화 플래그들은 코어-로컬 메모리가 소스일 때 코어-로컬 메모리에서 판독들을 추적하거나, 코어-로컬 메모리가 목적일 때 코어-로컬 메모리에 대한 쓰기들을 추적한다. 오프-코어 메모리에 대한 판독들 및 쓰기들의 진행은 추적되지 않을 수 있지만, 오프-코어 메모리에 대한 미해결 쓰기들이 커밋(commit)되었는지를 보장하기 위해, 스칼라 펜스 명령들은 장벽에 액세스하는 메모리를 선택하는 데 사용될 수 있다.[0158] Stream delivery can only move data between core-local memory. Additionally, core-local synchronization flags can be used to track stream progress. Synchronization flags can track partial progress of stream delivery. For example, synchronization flags track reads from core-local memory when core-local memory is the source, or core-local memory when core-local memory is the destination, depending on whether the flags are cleared or set according to a predetermined configuration. Tracks writes to local memory. The progress of reads and writes to off-core memory may not be tracked, but to ensure that outstanding writes to off-core memory are committed, scalar fence instructions select memory accessing barriers. can be used to
[0159] 스트림 전달은 오프 코어 또는 코어 로컬 메모리에 대한 간접 스캐터-수집 메모리 액세스를 포함할 수 있다. 액세스의 소스 또는 목적지에 대한 어드레스는 먼저 판독된 어드레스와 관련된 다른 메모리 위치에 저장될 수 있다. 예로서, 간접 어드레스들은 마스킹 지원과 함께 레지스터 파일에서 소싱되거나 메모리에서 소싱된다. 간접 스캐터-수집 메모리 액세스들은 예들로서 행 어드레스 또는 워드 어드레스와 같은 상이한 어드레싱 모드들을 더 포함할 수 있다. 스트림 전달은 메모리 워드에 직접적으로 ScatterAdd/GatherAdd 모드에 대한 지원을 포함할 수 있다. 메모리 워드는 원자적으로 업데이트될 수 있다. 예들로서, 32 비트 부동 소수점, 32 비트 정수, 16 비트 부동 소수점 및 16 비트 정수 데이터 유형들은 지원될 수 있다.[0159] Stream delivery may involve indirect scatter-collect memory access to off-core or core local memory. The address for the source or destination of the access may be stored in another memory location associated with the address read earlier. As an example, indirect addresses may be sourced from a register file or from memory with masking support. Indirect scatter-gather memory accesses may further include different addressing modes, such as row address or word address, as examples. Stream delivery can include support for ScatterAdd/GatherAdd modes directly on memory words. Memory words can be updated atomically. As examples, 32-bit floating point, 32-bit integer, 16-bit floating point, and 16-bit integer data types may be supported.
[0160] 스트림 전달은 소스 또는 목적지 버퍼의 순환 버퍼들에 대한 지원을 포함할 수 있으며, 이는 소프트웨어 컴파일 동안 버퍼 크기들을 알 수 없으므로 소프트웨어에 대한 버퍼 할당 문제들을 단순화할 수 있다.[0160] Stream delivery may include support for circular buffers, either source or destination buffer, which may simplify buffer allocation issues for the software since buffer sizes are not known during software compilation.
[0161] 추가로 본원에 일반적으로 개시된 것은 스트림 순서화 모델이다. 이러한 전달들에 대한 동기화 기본들은 실제 데이터 전달이 순서를 벗어나는 동안 데이터 전달이 순서대로 취급되게 한다. 동일한 스트림 ID를 가진 코어에 의해 발행된 개별 스트림 명령들은 단일 스트림을 형성한다. 하드웨어는 다수의 스트림 명령들에 걸쳐 있을 수 있는 단일 스트림 내 전달들에 대한 순서화 보장을 제공한다.[0161] Additionally generally disclosed herein is a stream ordering model. The synchronization primitives for these deliveries ensure that the data delivery is treated as in-order while the actual data delivery is out of order. Individual stream instructions issued by cores with the same stream ID form a single stream. The hardware provides ordering guarantees for deliveries within a single stream, which may span multiple stream instructions.
[0162] 스트림에 속한 스트림 명령들은 순서대로 프로세싱된다. 간접 스트림 명령들의 경우, 오프셋 목록이 정렬된다. 예를 들어 오프셋 목록의 오프셋 엘리먼트들은 순서대로 프로세싱된다. 쓰기들은 목적지 메모리에 순서대로 실행되고 목적지 메모리에 의해 순서 없이 커밋될 수 있다. 판독들은 소스 메모리에 순서대로 실행되고 소스 메모리에 의해 순서 없이 서비스될 수 있다.[0162] Stream commands belonging to the stream are processed in order. For indirect stream instructions, the offset list is sorted. For example, offset elements in an offset list are processed in order. Writes are executed in order to the destination memory and can be committed out of order by the destination memory. Reads may be executed in order and serviced by the source memory out of order.
[0163] 동기화 플래그는 스트림의 단조로운 증분 진행을 나타내기 위해 업데이트된다. 코어-로컬 메모리가 소스인 경우, 동기화 플래그는 코어-로컬 메모리에 관련하여 판독들을 추적한다. 코어-로컬 메모리가 판독 소스일 때 N의 동기화 플래그 값은 제1 N개의 데이터 청크들이 코어-로컬 메모리에서 덮어쓰여질 수 있음을 나타내고, 여기서 데이터 청크는 코어-로컬 메모리의 데이터를 측정하기 위해 미리 결정된 크기 단위이다. 코어-로컬 메모리가 목적지인 경우, 코어-로컬 메모리에 대한 쓰기들은 동기화 플래그에 의해 추적된다. 코어-로컬 메모리가 목적지인 예에서 동기화 플래그 값(N)은 코어-로컬 메모리의 제1 N개 데이터 청크들에 대한 후속 판독들이 요청된 데이터를 반환함을 나타낸다.[0163] The synchronization flag is updated to indicate monotonous incremental progress of the stream. If core-local memory is the source, the synchronization flag tracks reads relative to core-local memory. When core-local memory is the read source, a synchronization flag value of N indicates that the first N data chunks may be overwritten in core-local memory, where the data chunks are predetermined for measuring data in core-local memory. It is a size unit. If core-local memory is the destination, writes to core-local memory are tracked by the synchronization flag. In the example where core-local memory is the destination, the synchronization flag value (N) indicates that subsequent reads for the first N data chunks of core-local memory will return the requested data.
[0164] 마지막 스트림 디스크립터를 포함하여 선행하는 요청들에 대한 데이터가 메모리에 완전히 커밋되면 스트림은 종료될 수 있다. 예로서, 코어-로컬 메모리가 소스인 경우, 스트림은 모든 판독들이 완료되면 종료될 수 있다. 코어-로컬 메모리가 목적지인 경우, 스트림은 모든 쓰기들이 커밋되면 종료될 수 있다.[0164] A stream may be terminated when data for preceding requests, including the last stream descriptor, are fully committed to memory. As an example, if core-local memory is the source, the stream may end when all reads are complete. If core-local memory is the destination, the stream can be terminated when all writes are committed.
[0165] 본 개시내용의 양태들은 소프트웨어가 일반적인 데이터 이동 패턴들, 특히 희소 워크로드들에서 볼 수 있는 패턴을 보다 효율적으로 표현하게 한다. 본 개시내용의 양태들은 또한 순서대로 코어의 컴퓨팅 코어 및 소프트웨어 프로그래밍 모델을 유지하면서 긴 메모리 액세스 지연시간을 숨기는 복잡성 효과적 솔루션을 제공할 수 있다.[0165] Aspects of the present disclosure allow software to more efficiently represent common data movement patterns, particularly those seen in sparse workloads. Aspects of the present disclosure may also provide a complexity-effective solution that hides long memory access latencies while maintaining the core's computing core and software programming model in order.
[0166] 스트림 전달들은 타일들(102)과 타일 시퀀서(106)가 메모리(306) 또는 스칼라 메모리(334)와 같은 타일-로컬 메모리와 메모리(105) 또는 고대역폭 메모리(107)와 같은 오프-타일 메모리 사이에서 데이터를 이동하게 한다. 타일-로컬 메모리는 메모리(306) 스칼라 메모리(334)와 같이 희소 가속기(103)에 물리적으로 로컬인 메모리로서 코어-로컬 메모리의 예이다. 오프-타일 메모리는 오프 코어 메모리의 예인데, 그 이유는 TEC(330) 또는 TAC(332)에 물리적으로 멀리 떨어진 메모리가 메모리(105) 및/또는 고대역폭 메모리(107)를 포함할 수 있기 때문이다. 각각의 스트림은 스트림 명령과 연관된 동기화 플래그(318)에 의해 표시되는 연관된 스트림 ID를 갖는다. 동일한 스트림 ID를 가진 개별 스트림 명령들은 공유 스트림 ID를 가진 단일 스트림을 형성한다.[0166] Stream transfers allow tiles 102 and tile sequencer 106 to interact with tile-local memory, such as memory 306 or scalar memory 334, and off-local memory, such as memory 105 or high-bandwidth memory 107. Moves data between tile memories. Tile-local memory is memory that is physically local to the sparse accelerator 103, such as memory 306 and scalar memory 334, and is an example of core-local memory. Off-tile memory is an example of off-core memory because memory that is physically distant to TEC 330 or TAC 332 may include memory 105 and/or high-bandwidth memory 107. am. Each stream has an associated stream ID indicated by a synchronization flag 318 associated with the stream command. Individual stream instructions with the same stream ID form a single stream with a shared stream ID.
[0167] 스트림 전달은 타일-로컬 메모리 간에 데이터를 이동할 수 있다. 타일-로컬 동기화 플래그들(318)은 스트림의 진행을 추적하는 데 사용된다. 동기화 플래그(318)는 타일(102)을 통해 상이한 메모리들로/로부터 전달되는 스트림들의 부분 진행을 추적한다. 예를 들어, 동기화 플래그(318)는 타일-로컬 메모리가 소스일 때 타일-로컬 메모리로부터 판독 오퍼레이션들(또는 "판독들")을 추적하거나, 동기화 플래그(318)는 타일-로컬 메모리가 목적지인 경우 타일-로컬 메모리에 대한 쓰기 오퍼레이션들(또는 "쓰기들")을 추적한다. 오프-타일 메모리들에 대한 판독들 및 쓰기들의 진행은 추적되지 않을 수 있다. 오프-타일 메모리에 대한 모든 미해결 쓰기들이 커밋되는 것을 보장하기 위해, 스칼라 펜스 명령들은 장벽에 액세스하는 메모리를 선택하기 위해 사용될 수 있다. 스캐터-수집 엔진(322)은 각각의 특정 메모리에 대해 발행된 스트림 전달들의 상태를 추적하고 이 상태를 스칼라 코어(320)에 통신한다. 스칼라 펜스가 특정 메모리의 장벽에 발행되면, 스캐터-수집 엔진(322)은 그 메모리(판독 또는 쓰기)를 타겟으로 하는 모든 미해결 스트림 전달들이 완전히 커밋되었음을 나타내는 상태를 기다린다. 그 조건이 충족되면, 펜스 대기는 스칼라 코어(320)에 대해 해제된다.[0167] Stream delivery can move data between tile-local memories. Tile-local synchronization flags 318 are used to track the progress of the stream. Synchronization flag 318 tracks the partial progression of streams passing through tile 102 to and from different memories. For example, synchronization flag 318 tracks read operations (or “reads”) from tile-local memory when tile-local memory is the source, or synchronization flag 318 tracks read operations (or “reads”) from tile-local memory when tile-local memory is the destination. Tracks write operations (or "writes") to tile-local memory. The progress of reads and writes to off-tile memories may not be tracked. To ensure that all outstanding writes to off-tile memory are committed, scalar fence instructions can be used to select memory accessing barriers. Scatter-collect engine 322 tracks the status of stream deliveries issued for each specific memory and communicates this status to scalar core 320. When a scalar fence is issued to a barrier of a particular memory, the scatter-collect engine 322 waits for a state indicating that all outstanding stream transfers targeting that memory (read or write) have been fully committed. If that condition is met, the fence wait is released for the scalar core 320.
[0168] 스트림 전달들은 스트라이드된 스트림을 사용하여 오프-타일 메모리에 액세스하고 간접 스트림을 사용하여 타일-로컬 메모리 또는 레지스터 파일에서 오프-타일 메모리들에 액세스하는 효율적인 스캐터-수집 오퍼레이션들을 지원할 수 있다. 스트라이드된 스트림인지 간접 스트림인지 여부는 소프트웨어 액세스 패턴에 기반할 수 있다. 소프트웨어가 텐서의 매 N번째 엘리먼트에 액세스하려는 경우, 간접 스트림이 여전히 작동할 수 있지만 스트라이드된 스트림이 바람직하다. 그러나, 소프트웨어가 텐서의 랜덤 엘리먼트들의 세트에 액세스하려는 경우, 간접 스트림이 사용되어야 한다. 스트림 전달들은 또한 타일-로컬 메모리에서 순환 버퍼 의미론을 지원할 수 있다.[0168] Stream deliveries can support efficient scatter-collect operations that access off-tile memory using a strided stream and access off-tile memories in tile-local memory or a register file using an indirect stream. . Whether it is a strided or indirect stream may be based on software access patterns. If software wants to access every Nth element of a tensor, strided streams are preferred, although indirect streams may still work. However, if software wants to access a set of random elements in a tensor, an indirect stream must be used. Stream deliveries can also support circular buffer semantics in tile-local memory.
[0169] 스트림 전달들은 데이터 이동의 입도 및 정렬이 소스-목적지 메모리들의 쌍에 따르는 다음과 같은 데이터 이동들을 지원한다. 데이터는 메모리(306)에서 온칩 메모리(105)로 전달될 뿐만 아니라, 온칩 메모리(105)에서 메모리(306)로 전송될 수 있다. 데이터는 메모리(306)로부터 고대역폭 오프칩 메모리(107)로 뿐만 아니라 오프칩 메모리(107)에서 메모리(306)로 추가로 전달될 수 있다. 데이터는 또한 스칼라 메모리(334)에서 온칩 메모리(105)로 전달될 수 있을 뿐만 아니라 온칩 메모리(105)에서 스칼라 메모리(334)로 전송될 수 있다. 예로서, 최소 입도, 소스 정렬 및 목적지 정렬은 4 바이트들일 수 있다. 다른 예로서, 32 바이트 액세스들은 오프칩 메모리(107)에 대한 4 바이트 액세스들을 지원하는 데 사용될 수 있다. 또 다른 예로서, 32 바이트 정렬 및 128 바이트의 최소 길이는 오프칩 메모리(107)로 또는 오프칩 메모리(107)로부터의 스트림 성능을 보장할 수 있다.[0169] Stream deliveries support the following data movements, where the granularity and ordering of the data movement depends on the pair of source-destination memories. Data may be transferred from memory 306 to on-chip memory 105 as well as from on-chip memory 105 to memory 306. Data may be further transferred from memory 306 to high bandwidth off-chip memory 107 as well as from off-chip memory 107 to memory 306. Data may also be transferred from scalar memory 334 to on-chip memory 105 as well as from on-chip memory 105 to scalar memory 334. As an example, the minimum granularity, source alignment and destination alignment may be 4 bytes. As another example, 32 byte accesses may be used to support 4 byte accesses to off-chip memory 107. As another example, a 32 byte alignment and a minimum length of 128 bytes can ensure stream performance to or from off-chip memory 107.
[0170] 프로세서의 각각의 타일은 개개의 스캐터-수집 엔진(SGE)을 구현하여 타일에서 스크래치패드 메모리로의 데이터 이동 및/또는 상이한 메모리들 간의 데이터 이동을 조율할 수 있다. 이러한 상이한 메모리들은 스크래치패드 메모리, 고대역폭 메모리를 포함한 오프-타일 메모리, 온-타일 메모리를 포함할 수 있다. SGE는 SGE를 구현하는 타일의 TEC 및 TAC 중 하나 또는 둘 모두에서 발생할 수 있는 다수의 미해결 스트림 요청들을 지원할 수 있다. 데이터 판독 요청들은 SGE에 의해 수집 오퍼레이션들로 취급될 수 있는 반면, 데이터 쓰기 요청들은 스캐터 오퍼레이션들로 취급될 수 있다. SGE는 또한 시퀀서와 타일들 및/또는 메모리들 사이의 데이터 스트림에 대한 판독들 및 쓰기들을 핸들링하기 위해 타일 시퀀서에서 구현될 수 있다.[0170] Each tile of the processor may implement a respective scatter-gather engine (SGE) to coordinate data movement from the tile to scratchpad memory and/or between different memories. These different memories may include scratchpad memory, off-tile memory, including high bandwidth memory, and on-tile memory. SGE may support multiple outstanding stream requests that may originate from one or both the TEC and TAC of a tile implementing SGE. Data read requests may be treated by the SGE as gather operations, while data write requests may be treated as scatter operations. SGE may also be implemented in a tile sequencer to handle reads and writes to the data stream between the sequencer and tiles and/or memories.
[0171] 도 8은 스캐터-수집 엔진(1500)의 예시적인 기능 다이어그램이다. SGE(1500)는 상이한 개수들의 실행 스레드들, 예를 들어, 8 개의 스레드들을 지원할 수 있다. 스레드들은 인입 요청에 대한 스트림 식별자와 어드레스 생성기 스레드 및 스트림 유형, 예를 들어, 고대역폭 메모리 및/또는 스크래치패드 메모리의 가용성에 기반하여 선택될 수 있다. 일부 예들에서, 어드레스 생성기 스레드에서 이동 중인 스트림 식별자를 갖는 스트림 요청은 동일한 스레드에 매핑되어야 한다.[0171] Figure 8 is an example functional diagram of the scatter-collect engine 1500. SGE 1500 may support different numbers of execution threads, for example, eight threads. Threads may be selected based on the stream identifier for the incoming request and the address generator thread and stream type, eg, availability of high-bandwidth memory and/or scratchpad memory. In some examples, a stream request with a stream identifier moving in an address generator thread should be mapped to the same thread.
[0172] SGE(1500)는 동일한 스트림에 속하고 동일한 타일 코어에서 발생하는 동일한 외부 인터페이스, 예를 들어 프로세서의 크로스바 또는 다른 상호연결을 타겟으로 하는 다수의 스트림들에 걸쳐 동일한 유형의 소정 요청들, 예를 들어, 수집 요청들 또는 스캐터 요청들에 대해 순서 보장을 시행할 수 있다. 요청들은 동일한 스트림 식별자를 갖는 경우 동일한 스트림에 속하는 것으로 식별될 수 있다. 타일들에서 관리되는 동기화 플래그들은 본원에 설명된 대로 요청들 간의 순서를 추적하는 데 사용될 수 있다.[0172] The SGE 1500 is configured to: For example, ordering guarantees can be enforced on collection requests or scatter requests. Requests can be identified as belonging to the same stream if they have the same stream identifier. Synchronization flags managed in tiles can be used to track order between requests as described herein.
[0173] SGE(1500)는 스캐터/수집 요청들을 수신하고, 요청들을 언롤링하고, 프로세서 상호연결의 데이터를 원격 Spmem 슬라이스들로 이동하거나, 코어 메모리 네트워크(CMN)를 고대역폭 메모리로 이동하고, 동기화 플래그 업데이트들을 트랜잭션의 진행을 업데이트하도록 코어들 중 하나의 타일 동기화 플래그 메모리로 전송한다.[0173] SGE 1500 receives scatter/collect requests, unrolls the requests, moves data on the processor interconnect to remote Spmem slices or moves the core memory network (CMN) to high-bandwidth memory, and , send synchronization flag updates to the tile synchronization flag memory of one of the cores to update the progress of the transaction.
[0174] SGE(1500)는 또한 Tile Spmem 슬라이스 및 이로부터 쓰고 판독하기 위해 CMN 인터페이스에서 인입되는 DMA 요청들을 서비스하고, 이 타일에 로컬인 Spmem 슬라이스를 타겟으로 하는 원격 타일의 SGE에 의해 발생된 판독들 및 쓰기들을 핸들링한다.[0174] SGE 1500 also services DMA requests coming in on the CMN interface for writing and reading from and to Tile Spmem slices, and reads generated by the SGE of remote tiles targeting Spmem slices local to this tile. Handles fields and writes.
[0175] 스트림 요청은 다수의 상이한 유형들 중 하나일 수 있다. 스트림 요청들은 타일 및/또는 타일 시퀀서에서 자체적으로 구현될 수 있는 스캐터-수집 엔진에 의해 프로세싱될 수 있는 타일들의 코어들의 스캐터/수집 요청들을 포함할 수 있다. 스트림 요청의 하나의 유형은 SGE가 스트림 요청의 길이에 기반하여, 요청을 다수의 작은 요청들로 언롤링할 수 있는 선형 요청이다. 다른 유형의 스트림 요청은 스트라이드된 요청이고, SGE는 스트라이드와 길이에 기반하여 요청을 다수의 요청으로 언롤링한다. 다른 유형의 스트림 요청은 SGE가 별도의 요청들로 언롤링되는, 동일한 길이의 어드레스들의 목록들을 언롤링하는 간접 요청이다. 다른 유형의 스트림 요청은 SGE가 어드레스들의 목록을 수신하는 간접 요청이다.[0175] A stream request can be one of a number of different types. Stream requests may include scatter/collect requests for cores of tiles and/or tiles, which may be processed by a scatter-collect engine, which may be implemented natively in the tile sequencer. One type of stream request is a linear request in which the SGE can unroll the request into multiple smaller requests, based on the length of the stream request. Another type of stream request is a strided request, where SGE unrolls a request into multiple requests based on stride and length. Another type of stream request is an indirect request in which the SGE unrolls lists of addresses of the same length, which are then unrolled into separate requests. Another type of stream request is an indirect request where the SGE receives a list of addresses.
[0176] SGE(1500)는 다수의 스테이지들, 예를 들어 디스크립터 디스패치 스테이지(1500A), 어드레스 생성기 스테이지(1500B) 및 데이터 전달 스테이지(1500C)를 구현할 수 있다. 각각의 스테이지는 차례로 설명된다.[0176] SGE 1500 may implement multiple stages, such as a descriptor dispatch stage 1500A, an address generator stage 1500B, and a data transfer stage 1500C. Each stage is explained in turn.
[0177] SGE는 각각의 타일 코어, 예를 들어, TAC 및 TEC의 디스크립터 생성기와 직접 인터페이스할 수 있다. 디스크립터 생성기는 코어들에 의해 생성된 스트림 디스크립터들을 인큐잉하도록 구성된다. 스트림 디스크립터들은 디스크립터에 관련된 메타데이터가 디스크립터 문제 FIFO에 인큐잉되는 디스크립터 생성기로 전송될 수 있고, 실제 디스크립터는 디스크립터 RAM에 쓰여진다. FIFO의 내용들은 디스크립터가 상주하는 디스크립터 RAM의 포인터, 메모리 유형 및 대응 스트림에 첨부된 스트림 식별자를 포함할 수 있다. 유효한 스트림 디스크립터 메타데이터가 TAC 또는 TEC FIFO의 헤드에서 이용 가능하면, 다음 시퀀스가 발생할 수 있다.[0177] The SGE may interface directly with the descriptor generator of each tile core, e.g., TAC and TEC. The descriptor generator is configured to enqueue stream descriptors generated by cores. Stream descriptors can be sent to a descriptor generator where metadata related to the descriptor is enqueued in a descriptor issue FIFO, and the actual descriptor is written to the descriptor RAM. The contents of the FIFO may include a pointer to the descriptor RAM in which the descriptor resides, the memory type, and a stream identifier attached to the corresponding stream. If valid stream descriptor metadata is available at the head of the TAC or TEC FIFO, the following sequence may occur.
[0178] 첫째, SGE는 각각의 코어의 메타데이터에 대한 자원 조사들을 수행할 수 있다. 다음으로, SGE는 자원 조사에 의해 결정된 바와 같은 요구된 자원들을 2 개의 코어가 가지고 있다고 가정하여, 2 개의 코어 사이에서 선택하기 위한 가장 최근에 사용된 중재를 수행할 수 있다. 코어들 중 하나만이 필요한 자원들을 갖고 있는 경우, 이것은 서비스될 다음 코어가 된다. 메타데이터에 첨부된 스트림 식별자는 어드레스 생성기 맵에 대한 스트림 식별자에서 조회되고 연관된 카운터는 증분되거나, 새로운 엔트리는 디스크립터를 전송하기 위해 어드레스 생성기 스테이지에서 어드레스 생성기 스레드를 선택하기 위해 맵에 생성된다. 이어서, 메타데이터는 선택된 스레드와 연관된 디스크립터 메타데이터 큐에 큐잉된다. 자원 조사들은 디스크립터 메타데이터 큐와 연관된 디스크립터 FIFO에서 수행될 수 있다. 가장 최근에 사용된 중재는 디스크립터 메타데이터 큐들 중 하나를 선택하며, 승리한 엔트리는 팝핑되고 대응 메타데이터는 디스크립터 RAM 요청 FIFO로 포워딩된다. 요청은 팝핑되어 디스크립터 RAM으로 전송되고 데이터 응답은 디스크립터 FIFO에 저장되어 어드레스 생성기 스테이지로 포워딩된다.[0178] First, SGE can perform resource searches on the metadata of each core. Next, the SGE may perform the most recently used arbitration to select between the two cores, assuming that both cores have the required resources as determined by the resource survey. If only one of the cores has the necessary resources, it becomes the next core to be serviced. The stream identifier attached to the metadata is looked up in the stream identifier to address generator map and the associated counter is incremented, or a new entry is created in the map to select an address generator thread in the address generator stage to transmit the descriptor. The metadata is then queued in the descriptor metadata queue associated with the selected thread. Resource looks may be performed in the descriptor FIFO associated with the descriptor metadata queue. The most recently used arbitration selects one of the descriptor metadata queues, the winning entry is popped and the corresponding metadata is forwarded to the descriptor RAM request FIFO. The request is popped and sent to the descriptor RAM and the data response is stored in the descriptor FIFO and forwarded to the address generator stage.
[0179] 어드레스 생성기 맵에 대한 스트림 식별자는 디스크립터 메타데이터를 전송하기 위해 어드레스 생성기 스테이지(1500B)의 어드레스 생성기 스레드를 파악하고 동일한 스트림에 속하는 후속 스트림 요청들 간의 순서 보장들을 유지하는 데 사용된다. 이 구조는 다음을 보유할 수 있다: 활성 스트림 식별자들, 매핑된 어드레스 생성기 스레드, 스레드 식별자 항목에 매핑된 스트림 식별자가 유효함을 나타내는 비트 및 스트림 FIFO의 큐로부터 파이프라인의 이 스트림에 속하는 디스크립터 개수의 카운트.[0179] The stream identifier for the address generator map is used to identify the address generator thread of the address generator stage 1500B to transmit descriptor metadata and to maintain ordering guarantees between subsequent stream requests belonging to the same stream. This structure may hold: the active stream identifiers, the mapped address generator thread, a bit indicating that the stream identifier mapped to the thread identifier entry is valid, and the number of descriptors belonging to this stream in the pipeline from the queue in the stream FIFO. count of.
[0180] 구조는 상이한 최대 스트림 식별자들, 예를 들어, 16을 보유하도록 크기가 지정될 수 있다. 현재 비활성 스트림 식별자, 디스크립터 메타데이터 큐들에서 이용 가능한 공간 및/또는 생성기 맵을 어드레싱하기 위해 스트림 식별자에서 이용 가능한 공간과 함께 스트림 디스크립터가 발행될 때마다, SGE(1500)은 하나 이상의 조치들을 수행할 수 있다. SGE는 다음 이용 가능한 스레드를 고르고, 생성기 맵을 어드레싱하도록 이 값을 스트림 식별자에 저장하고, 이 스레드와 연관된 카운터를 1씩 증분시킨다. 동일한 스트림에 대한 모든 후속 결과들은 이제 동일한 어드레스 생성기 스레드로 전송되고 카운터를 증분시킬 것이다.[0180] The structure may be sized to hold different maximum stream identifiers, for example 16. Whenever a stream descriptor is issued with a currently inactive stream identifier, space available in the descriptor metadata queues, and/or space available in the stream identifier for addressing the generator map, SGE 1500 may perform one or more actions. there is. SGE picks the next available thread, stores this value in the stream identifier to address the generator map, and increments the counter associated with this thread by 1. All subsequent results for the same stream will now be sent to the same address generator thread and increment the counter.
[0181] 그 어드레스 생성기 스레드의 디스크립터 메타데이터 큐에 이 요청에 이용 가능한 공간이 없거나, 스트림 식별자의 새로운 엔트리를 어드레스 생성기 맵에 할당할 공간이 없거나(이것이 새로운 스트림 식별자인 경우), 맵의 카운터가 거의 가득 차면, FIFO는 필요한 모든 자원들에 공간이 생길 때까지 디큐잉(dequeue)되지 않을 것이다. 이 조사는 2 개의 코어 FIFO들 간의 중재 이전에 수행된다.[0181] There is no space available for this request in the descriptor metadata queue of that address generator thread, or there is no space to allocate a new entry for the stream identifier in the address generator map (if this is a new stream identifier), or the counter in the map is When nearly full, the FIFO will not be dequeued until all needed resources have space. This investigation is performed prior to arbitration between the two core FIFOs.
[0182] 어드레스 생성기 스테이지의 어드레스 생성기 스레드에 걸쳐, 4는 CMN 인터페이스와 연관되고 다른 2는 SC 데이터 크로스바와 연관된다. CMN 인터페이스 어드레스 생성기 스레드들은 HBM을 타겟으로 하는 요청들을 언롤링하고 SC 데이터 크로스바 인터페이스 어드레스 생성기 스레드들은 원격 Spmem 또는 Tile Spmem N을 타겟으로 한다. 스트림 ID와 함께 저장할 다음 이용 가능한 스레드를 결정하기 위해, 스트림 인터페이스 메타데이터는 선택할 어드레스 생성기 스레드를 결정하고 LRU 중재는 대응 디스크립터 메타데이터 큐에 또한 공간을 갖는 연관된 스레드에 걸쳐 사용된다.[0182] Over the address generator thread of the address generator stage, 4 are associated with the CMN interface and the other 2 are associated with the SC data crossbar. CMN interface address generator threads unroll requests targeting HBM and SC data crossbar interface address generator threads target remote Spmem or Tile Spmem N. To determine the next available thread to store with the stream ID, the stream interface metadata determines which address generator thread to select and LRU arbitration is used across associated threads that also have space in the corresponding descriptor metadata queue.
[0183] 스트림 요청이 어드레스 생성기 스테이지의 어드레스 생성기 스레드에 의해 언롤링되고 데이터 전달 스테이지의 동기화 플래그 추적 구조가 업데이트되면, 어드레스 생성기 맵에 대한 스트림 식별자의 카운터는 감분될 수 있다. 데이터 전달 스테이지에서 이 카운터에 대한 감분 업데이트들은 데이터 전달 파이프라인의 4 개의 부분들에서 비롯된다. 코어 메모리 네트워크(x1)에 대한 스트리밍 스캐터들; 코어 메모리 네트워크(x1)에 대한 스트림 수집; 프로세서 데이터 크로스바(x2)에 대한 스트림 스캐터들; 프로세서 데이터 크로스바(x2)에 대한 스트림 수집. 이는 어드레스 생성기 스레드에 의해 디스크립터에서 언롤링되는 마지막 요청에 의해 수행된다.[0183] When a stream request is unrolled by an address generator thread in the address generator stage and the synchronization flag tracking structure in the data transfer stage is updated, the counter of the stream identifier for the address generator map may be decremented. Incremental updates to this counter in the data transfer stage come from four parts of the data transfer pipeline. Streaming scatters to the core memory network (x1); Stream collection to core memory network (x1); Stream scatters to processor data crossbar (x2); Stream collection for processor data crossbar (x2). This is done by the last request being unrolled from the descriptor by the address generator thread.
[0184] 어드레스 생성기 맵에 대한 스트림 식별자의 스트림 식별자와 연관된 카운터가 0이 되면, 이 맵 엔트리는 무효화될 수 있고, 동일한 스트림에 대한 모든 후속 요청들은 결국 이들 사이의 순서를 유지하는 동일한 동기화 플래그 추적 구조에 도달하게 되기 때문에 대응 인터페이스에 대해 이용 가능한 어드레스 생성기 스레드(CMN/데이터 크로스바) 중 임의의 것으로 다시 매핑될 수 있다.[0184] If the counter associated with the stream identifier of the stream identifier for the address generator map becomes 0, this map entry can be invalidated, and all subsequent requests for the same stream will eventually track the same synchronization flag maintaining order between them. As the structure is reached, it can be remapped to any of the available address generator threads (CMN/data crossbar) for the corresponding interface.
[0185] 예를 들어, 스트림 ID는 처음에 디스크립터들이 이동 중인 시간 창 동안(데이터 전달 스테이지까지) thread_id #2에 매핑된다. 매핑된 엔트리는, 새로운 디스크립터들이 한동안 동일한 스트림 ID를 사용하여 더 이상 생성되지 않으면(연관된 카운터가 0이 됨) 무효화될 것이다. 매핑된 엔트리의 무효화 이후, 새로운 디스크립터가 이제 동일한 스트림 ID를 사용하여 생성되면, 생성된 새로운 맵은 스트림 ID 매핑 thread_id #1을 가질 수 있고 공간이 이미 순서 유지를 담당하는 데이터 전달 스테이지의 동기화 플래그 추적 구조에 할당되었기 때문에 문제가 되지 않는다. 이것이 thread_id #1과 #2가 동일한 스트림 인터페이스 유형(CMN/데이터 크로스바)에 속하고 동일한 메모리(스캐터 대 수집)에 대한 업데이트들을 추적한다고 가정한다는 것이 유의된다.[0185] For example, the stream ID is initially mapped to thread_id #2 during the time window during which the descriptors are being moved (until the data transfer stage). A mapped entry will become invalid when new descriptors are no longer created using the same stream ID for some time (the associated counter becomes 0). After invalidation of the mapped entry, if a new descriptor is now created using the same stream ID, the new map created may have the stream ID mapping thread_id #1 and space is already tracked by the synchronization flag of the data delivery stage responsible for maintaining order. This is not a problem since it is assigned to the structure. Note that this assumes thread_id #1 and #2 belong to the same stream interface type (CMN/data crossbar) and track updates to the same memory (scatter vs. gather).
[0186] 스트림 FIFO로부터의 모든 정보는 그 중 일부가 디스크립터 디스패치 스테이지(1500A)의 초기 부분에서만 사용되기 때문에 디스크립터 메타데이터 큐들에 인큐잉될 필요가 없다. 디스크립터 램에 대한 어드레스만이 디스크립터 램에 대한 판독을 전송하기 위해 스테이지의 후반부에서 필요하다. FIFO에 전달되는 다른 모든 메타데이터는 디스크립터를 특정 어드레스 생성기에 매핑하는 데에만 사용된다. 이 시점 이후, 이 메타데이터는 폐기될 수 있다. 디스크립터 메타데이터 큐들은 디스크립터 램에 대한 포인터만 전달한다.[0186] All information from the stream FIFO does not need to be enqueued in descriptor metadata queues since some of it is only used in the initial part of the descriptor dispatch stage 1500A. Only the address to the descriptor RAM is needed later in the stage to transmit a read to the descriptor RAM. All other metadata passed to the FIFO is only used to map descriptors to specific address generators. After this point, this metadata may be discarded. Descriptor metadata queues only carry pointers to descriptor RAM.
[0187] 디스크립터 메타데이터 큐들의 출력에서, 공정성을 유지하기 위해 디스크립터 RAM에 액세스할 수 있도록 모든 어드레스 생성기 스레드에 걸쳐 LRU 중재가 있다.[0187] At the output of the descriptor metadata queues, there is LRU arbitration across all address generator threads to ensure access to the descriptor RAM to maintain fairness.
[0188] 어드레스 생성기 스테이지(1500B)로 돌아가면, 디스크립터 FIFO의 디스크립터는 어드레스 생성기 스테이지의 스트림 디스크립터 관리자 로직에 의해 팝핑되고 이어서 원격 메모리들에 대한 요청들로 추가 언롤링을 위해 어드레스 언롤링 상태 기계로 전달된다. 어드레스 생성기의 각각의 서브블록은 아래에서 더 상세히 설명된다.[0188] Returning to the address generator stage 1500B, the descriptor in the descriptor FIFO is popped by the address generator stage's stream descriptor manager logic and then into the address unrolling state machine for further unrolling with requests to remote memories. It is delivered. Each subblock of the address generator is described in more detail below.
[0189] 스트림 디스크립터 관리자 로직은 디스크립터들을 어드레스 언롤링 상태 기계에 전달하기 전에 간접 스트림의 어드레스 목록들을 언롤링하는 상태 기계이다. 본 명세서가 상태 기계의 형태로 논리를 설명하지만, 실제 구현이 상태들을 명시적으로 라벨링하지 않는 것이 유의된다. 이는 코드 구조를 단순화하기 위해 수행되었다. 그러나, 로직에 의해 수행되는 실제 기능은 변경되지 않고 여기서 설명하는 내용과 동일하다. 각각의 상태에서 다음 태스크들을 수행한다.[0189] The stream descriptor manager logic is a state machine that unrolls the address lists of the indirect stream before passing the descriptors to the address unrolling state machine. It is noted that although this specification describes the logic in the form of a state machine, the actual implementation does not explicitly label the states. This was done to simplify the code structure. However, the actual function performed by the logic remains unchanged and is the same as described here. Perform the following tasks in each state.
[0190] 유휴 상태: 이 상태에서, 로직은 디스크립터 데이터 FIFO에서 팝핑되고 디스크립터의 off_tile_stream_type 필드를 조사한다. 언롤링 어드레스 목록 상태에서, 이 상태는 예를 들어 간접 스트림의 어드레스 목록에 언롤링할 어드레스가 4 개보다 많은 경우에만 도달된다.[0190] Idle state: In this state, logic pops out of the descriptor data FIFO and examines the off_tile_stream_type field of the descriptor. In the unrolling address list state, this state is only reached if, for example, there are more than 4 addresses to unroll in the address list of the indirect stream.
[0191] 어드레스 언롤링 상태 기계는 제시된 각각의 스트림 디스크립터를 코어 메모리 네트워크 인터페이스(HBM으로 향함) 또는 데이터 크로스바 인터페이스(원격 Spmem으로 향함)에 대한 하나 이상의 판독/쓰기 요청들로 언롤링하는 데 사용된다.[0191] The address unrolling state machine is used to unroll each presented stream descriptor into one or more read/write requests to the core memory network interface (to HBM) or the data crossbar interface (to remote Spmem). .
[0192] 어드레스 언롤링 상태 기계가 각각의 스트림 디스크립터에서 언롤링되는 마지막 요청인 스트림 스캐터 또는 수집을 데이터 전달 스테이지에 나타내야 하는 것이 유의된다. 이 정보는 특정 스트림 디스크립터와 관련된 어드레스 언롤링 입력 FIFO의 마지막 엔트리를 나타냄으로써 디스크립터 메타데이터의 일부로서 스트림 디스크립터 관리자 논리에서 어드레스 언롤링 상태 기계로 전달된다. 이 정보는 펜스 명령들에 대한 디스크립터 "커밋됨(committed)" 및 "폐기됨(retired)" 상태들을 추적하기 위해 데이터 전달 스테이지에서 필요하다.[0192] It is noted that the address unrolling state machine must indicate to the data delivery stage which stream scatter or gather is the last request to be unrolled in each stream descriptor. This information is passed from the stream descriptor manager logic to the address unrolling state machine as part of the descriptor metadata, indicating the last entry in the address unrolling input FIFO associated with a particular stream descriptor. This information is needed in the data transfer stage to track descriptor "committed" and "retired" statuses for fence instructions.
[0193] 데이터 전달 스테이지(1500C)에서, SGE(1500)는 CMN 및 데이터 크로스바의 인터페이스 요건들과 일치하도록 인출되는 스트림 스캐터들 및 수집들의 포맷화를 처리한다. 이는 미해결 스트림 수집들 및 스캐터들을 위해 Spmem 및 동기화 플래그 추적에 대한 DMA 액세스를 관리한다. 이 파이프라인 스테이지는 또한 원격 타일들에서 인입되는 판독 및 쓰기 액세스들을 서비스한다.[0193] In the data transfer stage 1500C, SGE 1500 processes formatting of the fetched stream scatters and collections to match the interface requirements of the CMN and data crossbar. This manages DMA access to Spmem and synchronization flag tracking for outstanding stream collections and scatters. This pipeline stage also services read and write accesses coming from remote tiles.
[0194] SGE(1500)는 소스 코어 ID와 타겟 원격 메모리에 기반하여 펜스 명령의 상태를 추적하기 위해 트랜잭션 카운터들을 증분시킨다. 펜스의 경우, 예를 들어 코어 유형당 6 개의 카운터들[총 12개]- Spmem(쓰기 폐기, 쓰기 커밋, 판독 폐기), HBM(쓰기 폐기, 쓰기 커밋, 판독 폐기)이 있을 수 있다. 데이터 전달 스테이지에서 중재에서 승리한 각각의 트랜잭션은 연관된 메모리 및 코어 유형의 폐기 및 커밋 카운터 둘 모두를 증분시킬 것이다.[0194] SGE 1500 increments transaction counters to track the status of the fence instruction based on the source core ID and target remote memory. For a fence, there may be, for example, 6 counters per core type [12 total] - Spmem (write discard, write commit, read discard), HBM (write discard, write commit, read discard). Each transaction that wins arbitration in the data delivery stage will increment both the discard and commit counters of the associated memory and core type.
[0195] SGE(1500)는, 이것이 언롤링되는 디스크립터와 연관되는 마지막 트랜잭션인 경우, 자신에게 존재하는 펜스 디스크립터 카운터들에 대한 디스크립터 디스패치 스테이지에 감분(decrement)을 전송한다. 이는 또한 디스크립터와 관련된 제1 전달에 대해서도 수행될 수 있지만 "마지막 전달(last transfer)" 상태가 이미 이용 가능하므로, 감분이 마지막 전달에 기반하여 수행되는 경우 추가 정보는 추적될 필요가 없다. 이는 또한 잘못된 상태가 코어 콤플렉스에 제공되지 않도록 보장한다. 감분들은 다음 인터페이스 전달들에 대해 세분적으로 수행된다.[0195] SGE 1500, if this is the last transaction associated with the descriptor being unrolled, sends a decrement to the descriptor dispatch stage for its existing fence descriptor counters. This can also be done for the first transfer associated with the descriptor, but since the "last transfer" status is already available, no additional information needs to be tracked if the decrement is done based on the last transfer. This also ensures that incorrect state is not provided to the core complex. Decrements are performed granularly for the following interface passes:
[0196] SGE(1500)는 이것이 언롤링되는 디스크립터와 연관된 마지막 트랜잭션인 경우 생성기 맵을 어드레싱하기 위해 동기화 플래그 id에 대한 디스크립터 디스패치 스테이지에 감분을 전송한다.[0196] SGE 1500 sends a decrement to the descriptor dispatch stage for the synchronization flag id to address the generator map if this is the last transaction associated with the descriptor being unrolled.
[0197] 스트림 수집들에 대한 디스크립터 커밋 상태는 디스크립터 폐기 상태와 동일하므로 스트림 수집들은 한 가지 유형의 상태 카운터로만 추적되어야 한다. 스트림 스캐터들의 경우, 2 개의 카운터들은 흐름의 상이한 지점에서 업데이트될 것이다. 또한, 동기화 플래그들을 업데이트하는 파이프라인의 업데이트들의 입도가, 요청들이 원격 메모리로 추적되는 입도와 상이할 수 있으므로, 논리는 데이터 전달 스테이지의 이들 2 개의 상이한 부분들에서 상태를 유지해야 한다.[0197] The descriptor commit status for stream collections is the same as the descriptor discard status, so stream collections should be tracked with only one type of status counter. For stream scatters, two counters will be updated at different points in the flow. Additionally, since the granularity of updates in the pipeline that updates synchronization flags may be different from the granularity at which requests are tracked to remote memory, logic must maintain state in these two different parts of the data transfer stage.
[0198] 데이터 전달 스테이지(1500C)는 동기화 플래그 추적 로직의 각각의 인스턴스에 의해 증분되는 원격 메모리 유형당 소스 코어당 카운터를 유지한다. 카운터는, 동기화 플래그 메시지가 동기화 플래그 추적기에 의해 메시지 라우터 인터페이스에 인큐잉될 때 증분된다. 메시지 라우터로 전송된 동기화 플래그 업데이트는 동기화 플래그 업데이트가 데이터 전달 스테이지에서 이들 카운터들을 감분하기 위해 완료되면 SGE에 다시 전송되는, 업데이트가 속한 트랜잭션과 연관된 원격 메모리와 소스 코어를 갖는다.[0198] Data transfer stage 1500C maintains a per source core per remote memory type counter that is incremented by each instance of synchronization flag tracking logic. The counter is incremented when a sync flag message is enqueued to the message router interface by the sync flag tracker. Synchronization flag updates sent to the Message Router have the source core and remote memory associated with the transaction to which the update belongs sent back to the SGE once the synchronization flag update is complete to decrement these counters in the data delivery stage.
[0199] 각각의 동기화 플래그 추적기는 또한 추적 중인 임의의 라이브 트랜잭션이 있는지 여부에 대한 상태를 유지한다(메모리 유형별 소스 코어별).[0199] Each synchronization flag tracker also maintains state as to whether there are any live transactions being tracked (per source core per memory type).
[0200] 특정 인터페이스에 대한 스트림 스캐터들에 대한 동기화 플래그 추적기에 무엇이든 "라이브"가 있는 한, 그 메모리 유형에 대한 모든 디스크립터들은 아직 "커밋"되거나 "폐기"되지 않았다. 특정 메모리 유형에 대한 스트림 스캐터 "폐기" 카운터가 0이지만 연관된 동기화 플래그 추적기가 여전히 "라이브" 트랜잭션들을 갖는 경우, 그 메모리에 대한 펜스 상태가 여전히 모든 것이 "커밋" 또는 "폐기"되지 않은 것으로 도시할 것이라는 것이 유의된다.[0200] As long as there is anything "live" in the synchronization flag tracker for stream scatters for a particular interface, all descriptors for that memory type have not yet been "committed" or "discarded." If the stream scatter "discarded" counter for a particular memory type is 0, but the associated synchronization flag tracker still has "live" transactions, then the fence state for that memory still shows that everything is not "committed" or "discarded". It is important to note that this will be done.
[0201] 스트림 수집들의 경우, "폐기된" 카운터들 모두가 감분되었더라도, 동기화 플래그 추적기에 "라이브" 트랜잭션들이 있는 한 디스크립터 디스패치 스테이지에 대한 현재 상태는 "커밋됨" 또는 "폐기"로 설정될 수 없다. 특정 메모리에 대한 동기화 플래그 추적기가 그곳에서 아무것도 추적되지 않는다고 보고하면, 상태는 디스크립터 디스패치 스테이지로 업데이트될 수 있다.[0201] For stream collections, the current state for the descriptor dispatch stage can be set to "committed" or "abandoned" as long as there are "live" transactions in the synchronization flag tracker, even if all "discarded" counters have been decremented. does not exist. If the synchronization flag tracker for a particular memory reports that nothing is being tracked there, the state can be updated to the descriptor dispatch stage.
[0202] 데이터 전달 스테이지(1500C)의 디스크립터 추적 로직은 라이브 펜스 상태를 디스크립터 디스패치 스테이지(1500A)로 설정한다.[0202] The descriptor tracking logic of the data transfer stage 1500C sets the live fence state to the descriptor dispatch stage 1500A.
[0203] 본원에 설명된 바와 같이, SGE(1500)는 타일 시퀀서의 일부로서 뿐만 아니라 각각의 타일에서도 구현될 수 있다. 타일 시퀀서의 스캐터 수집 엔진은 이 섹션에서 상세히 설명되는 일부 차이점들을 갖는 위에서 설명된 SGE 서브시스템의 파라미터화된 버전일 것이다. 타일 시퀀서의 경우 "로컬" 메모리는 항상 스크래치패드 메모리에 비해 판독/쓰기 대역폭 요건이 낮은 공유 메모리이다.[0203] As described herein, SGE 1500 may be implemented in each tile as well as part of a tile sequencer. The tile sequencer's scatter collection engine will be a parameterized version of the SGE subsystem described above with some differences detailed in this section. For tile sequencers, “local” memory is always shared memory with lower read/write bandwidth requirements than scratchpad memory.
[0204] 스트림 디스크립터는 스캐터-수집 엔진(322)이 스트림 전달을 실행하기 위한 모든 정보를 나타낼 수 있는 데이터 구조이다. 스트림 명령들은 스트림 디스크립터의 필드들을 완전히 인코딩할 수 있다. 다음은 스트림 디스크립터의 예시적인 필드들이다.[0204] The stream descriptor is a data structure that can represent all information for the scatter-collection engine 322 to execute stream delivery. Stream instructions can fully encode the fields of a stream descriptor. The following are example fields of a stream descriptor.
[0205] 스트림 오퍼레이션 코드의 경우, 수집 스트림은 오프-타일 메모리를 판독하고 데이터를 타일-로컬 메모리에 저장하거나 데이터를 추가한다. 스캐터 스트림은 타일-로컬 메모리에서 판독하고 데이터를 오프-타일 메모리에 저장하거나 데이터를 추가한다. 오프-타일 메모리 및 타일-로컬 메모리는 각각 오프-타일 메모리 유형 및 타일-로컬 메모리 유형과 같은 필드들에 의해 결정된다.[0205] For stream operation code, the gather stream reads off-tile memory and stores data in tile-local memory or appends data. The scatter stream reads from tile-local memory and stores or appends data to off-tile memory. Off-tile memory and tile-local memory are determined by fields such as off-tile memory type and tile-local memory type, respectively.
[0206] 스트림 명령들의 추가 변형은 부동 소수점 및 부호 있는 정수 추가 오퍼레이션 둘 모두를 지원할 수 있다. 부호 있는 정수 추가 수집 및 부동 소수점 추가 수집 변형들은 타일-로컬 메모리에 대해 지원될 수 있다. 부호 있는 정수 추가 스캐터와 부동 소수점 추가 스캐터 변형들은 오프-타일 메모리와 타일-로컬 메모리에 대해 지원될 수 있다. 잘못된 조합이 검출되면, 프로그램 에러는 엔진에 의해 발생될 수 있다.[0206] Additional variants of the stream instructions may support both floating point and signed integer addition operations. Signed integer addition collection and floating point addition collection variants may be supported for tile-local memory. Signed integer addition scatter and floating point addition scatter variants can be supported for off-tile memory and tile-local memory. If an incorrect combination is detected, a program error may be generated by the engine.
[0207] 타일-로컬 스트림 유형은 타일-로컬 메모리에 액세스하는 데 사용되는 어드레스 패턴을 나타낸다. 예를 들어, 선형 스트림은 타일-로컬 시작 오프셋에서 시작하는 다수의 연속 워드들을 용이하게 한다. 연속된 워드들의 개수는 4 바이트 길이를 가질 수 있다. 다른 예로서, 순환 버퍼 스트림은 소프트웨어가 타일-로컬 메모리에 논리적 순환 버퍼들을 구축하게 한다. 이 예시적인 액세스 패턴에서, 순환 버퍼 메타데이터의 베이스, 크기 및 오프셋 필드들은 다수의 워드들에 대한 어드레스들을 생성하는 데 사용된다. 워드들의 개수는 4 바이트 길이를 가질 수 있다. 프로그램 에러는, 입도의 유효 길이가 순환 버퍼 메타데이터의 크기 필드보다 크면 발생될 수 있다.[0207] The tile-local stream type represents the address pattern used to access tile-local memory. For example, a linear stream facilitates multiple consecutive words starting at a tile-local start offset. The number of consecutive words can be 4 bytes long. As another example, circular buffer streams allow software to build logical circular buffers in tile-local memory. In this example access pattern, the base, size and offset fields of the circular buffer metadata are used to generate addresses for multiple words. The number of words can be 4 bytes long. A program error may occur if the effective length of the granularity is greater than the size field of the circular buffer metadata.
[0208] 오프-타일 스트림 유형은 오프-타일 메모리에 액세스하는 데 사용되는 어드레스 패턴을 나타낸다. 선형 스트림은 오프-타일 시작 오프셋에서 시작하는 다수의 연속 위치들에 대한 액세스를 용이하게 한다. 실제 워드 크기는 오프-타일 메모리 유형에 따른다. 스트라이드된 스트림은 스트라이드된 액세스 패턴을 오프-타일 메모리 유형에 저장된 다차원 어레이로 변환하는 것을 용이하게 한다. 스트림 전달들은 단일 레벨의 스트라이드를 지원할 수 있다. 간접 스트림들은 테이블에 임의의 스캐터-수집 액세스 패턴들을 가능하게 한다. 목록의 각각의 항목이 동일한 길이의 데이터에 액세스하는 간접 오프셋 목록이 여기에 사용된다.[0208] The off-tile stream type represents the address pattern used to access off-tile memory. A linear stream facilitates access to multiple consecutive positions starting at an off-tile start offset. The actual word size depends on the off-tile memory type. Strided streams facilitate converting strided access patterns into multidimensional arrays stored in off-tile memory types. Stream deliveries can support a single level of stride. Indirect streams enable arbitrary scatter-gather access patterns on the table. An indirect offset list is used here where each item in the list accesses data of the same length.
[0209] 간접 오프셋 목록의 소스는 타일-로컬 메모리 또는 레지스터 파일일 수 있다. 소스가 타일-로컬 메모리인 경우, 간접 오프셋 필드는 다수의 오프셋들이 저장되는 타일-로컬 메모리에 시작 오프셋을 갖는다. 소스가 레지스터 파일인 경우, 간접 오프셋 필드는 레지스터 파일을 가지며 유효한 오프셋들을 포함하는 레인들의 개수 표시된다. 이러한 오프셋들은 스트림 오퍼레이션 코드에 의해 표시된 대로 스캐터 또는 수집 오퍼레이션을 수행하는 데 사용된다.[0209] The source of the indirect offset list may be tile-local memory or a register file. If the source is tile-local memory, the indirect offset field has the starting offset in tile-local memory where multiple offsets are stored. If the source is a register file, the Indirect Offset field indicates the number of lanes that have a register file and contain valid offsets. These offsets are used to perform scatter or gather operations as indicated by the stream operation code.
[0210] 코어 유형은 타일 실행기 코어(330) 또는 타일 액세스 코어(332)와 같이 스트림 디스크립터를 생성한 타일(102)의 코어 유형을 나타낸다. 동기화 플래그 코어 유형은 스트림의 진행을 추적하는 동기화 플래그(318)의 코어 유형을 나타낸다. 인코딩은 타일 액세스 코어에 의해 개시된 스트림들이 타일 실행기 코어에 의해 추적될 뿐만 아니라 타일 실행기 코어가 타일 액세스 코어에 의해 추적되게 하도록 코어 유형과 동일할 수 있다.[0210] The core type indicates the core type of the tile 102 that created the stream descriptor, such as the tile executor core 330 or the tile access core 332. The synchronization flag core type indicates the core type of the synchronization flag 318 that tracks the progress of the stream. The encoding may be the same as the core type so that streams initiated by the tile access core are tracked by the tile executor core as well as the tile executor core is tracked by the tile access core.
[0211] 동기화 플래그 ID는 타겟 동기화 플래그 메모리 내의 오프셋을 나타낸다. 동기화 플래그 ID는 또한 아래에 더 설명될 바와 같이, 스트림 ID으로 사용될 수 있고 순서가 보장될 수 있다. 설정된 완료 비트는 현재 디스크립터가 스트림의 마지막임을 나타낸다. 완료 비트는 스트림의 현재 디스크립터 및 이전 디스크립터들에 대한 모든 데이터가 타일-로컬 메모리에 완전히 커밋된 후에 설정된다.[0211] The synchronization flag ID indicates an offset within the target synchronization flag memory. The synchronization flag ID can also be used as a stream ID and ordering can be guaranteed, as will be explained further below. A set completion bit indicates that the current descriptor is the end of the stream. The completion bit is set after all data for the stream's current descriptor and previous descriptors have been fully committed to tile-local memory.
[0212] 동기화 플래그 카운트 유형은 워드 개수이든 디스크립터들의 개수이든 동기화 플래그(318)가 추적하고 있는 카운트 유형을 나타낸다. 둘 모두의 경우들에서, 동기화 플래그(318)는 스트림에 대한 단조로운 증분 진행을 추적하지만 입도가 상이하다.[0212] The synchronization flag count type indicates the count type that the synchronization flag 318 is tracking, whether the number of words or the number of descriptors. In both cases, the synchronization flag 318 tracks monotonous incremental progress over the stream, but the granularity is different.
[0213] 타일-로컬 메모리 유형은 스트림 전달에 참여하는 타일-로컬 메모리의 유형을 나타내며, 이는 스칼라 메모리(334) 또는 메모리의 로컬 뱅크들(306)을 포함할 수 있다. [0213] The tile-local memory type indicates the type of tile-local memory participating in stream delivery, which may include scalar memory 334 or local banks of memory 306.
[0214] 타일-로컬 시작 오프셋 필드는 타일-로컬 스트림 유형이 선형인 경우 사용된다. 이는 이 전달에 의해 액세스되는 타일-로컬 메모리 내에서 정렬된 시작 오프셋 워드, 이를 테면 4 바이트 워드를 나타낸다. 실제 액세스 유형은 스트림 오퍼레이션 코드에 따른다.[0214] The tile-local start offset field is used when the tile-local stream type is linear. This represents the aligned start offset word, say a 4-byte word, within the tile-local memory accessed by this transfer. The actual access type depends on the stream operation code.
[0215] 타일-로컬 스트라이드는 각각의 스트라이드에서 액세스되는 스트라이드 크기와 바이트들의 개수를 인코딩하며, 이는 타일-로컬 메모리 유형에 의해 선택된 타일-로컬 메모리에 액세스하는 데 사용된다. 예로서 4 바이트들일 수 있는 길이는 각각의 스트라이드에서 액세스되는 바이트들의 개수의 배수일 필요는 없다. 스트라이드된 액세스의 마지막 요청은 스트라이드당 길이보다 작을 수 있는 나머지 전달 워드들에 액세스한다. 스트라이드 계산은 선형 및 순환 버퍼 스트림 유형들 둘 모두에서 동일할 수 있다.[0215] Tile-local strides encode the number of bytes and the stride size accessed at each stride, which is used to access the tile-local memory selected by the tile-local memory type. The length, which can be 4 bytes for example, need not be a multiple of the number of bytes accessed in each stride. The last request of a strided access accesses the remaining transferred words, which may be less than the length per stride. Stride calculation can be the same for both linear and circular buffer stream types.
[0216] 순환 버퍼 메타데이터 필드는 타일-로컬 스트림 유형이 순환 버퍼인 경우 사용된다. 순환 버퍼의 크기는 오프-타일 메모리 유형의 입도의 배수가 될 수 있으며 오프셋들은 정렬될 수 있다. 순환 버퍼가 래핑(wrap)되면, 요청들은 다수의 요청들로 나뉘며, 에러는 결과 요청들이 오프-타일 메모리 유형의 입도의 배수가 아닌 경우 발생될 수 있다. 에러는 또한 스트림 전달의 총 길이가 순환 버퍼의 크기보다 큰 경우 발생될 수 있다.[0216] The circular buffer metadata field is used when the tile-local stream type is circular buffer. The size of the circular buffer can be a multiple of the granularity of the off-tile memory type and the offsets can be aligned. If the circular buffer is wrapped, requests are split into multiple requests, and errors may occur if the resulting requests are not a multiple of the granularity of the off-tile memory type. An error may also occur if the total length of the stream transfer is greater than the size of the circular buffer.
[0217] 오프-타일 메모리 유형은 전달에 참여하는 오프-타일 메모리 유형을 나타낸다. 이것은 온칩 메모리(105)와 고대역폭 메모리(107)를 포함한다. 4 바이트 입도 및 4 바이트 정렬로 액세스할 수 있는 고대역폭 메모리 뷰는 또한 사용될 수 있다. 시퀀서(106)가 스트림 전달의 개시자인 경우, 이 필드는 고대역폭 메모리(107)가 인코딩되지 않을 수 있다.[0217] The off-tile memory type indicates the off-tile memory type participating in the transfer. This includes on-chip memory 105 and high-bandwidth memory 107. High-bandwidth memory views that can be accessed with 4-byte granularity and 4-byte alignment can also be used. If sequencer 106 is the initiator of stream delivery, this field may not be encoded in high-bandwidth memory 107.
[0218] 타일 ID 필드는 메모리 슬라이스의 타일 ID를 선택하는 데 사용될 수 있다. 오프-타일 시작 오프셋은 연관된 오프-타일 메모리 유형에 의해 표시된 오프 타임 메모리(105) 내의 시작 오프셋 워드를 포함한다. 오프셋의 단위는 오프-타일 메모리 유형의 오프셋 정렬 컬럼에 표시된 값들과 동일할 수 있다. 예를 들어, 고대역폭 메모리(107)의 경우, 1의 오프셋 값은 바이트 어드레스(32)로 변환된다. 오프-타일 스트림 유형이 간접인 경우, 이 필드는 메모리에 액세스하기 전에 간접 오프셋 목록에서 판독된 오프셋에 추가되는 기본 어드레스 역할을 할 수 있다.[0218] The tile ID field can be used to select the tile ID of a memory slice. The off-tile start offset includes the start offset word in off time memory 105 indicated by the associated off-tile memory type. The unit of offset may be the same as the values displayed in the offset sort column of the off-tile memory type. For example, for high bandwidth memory 107, an offset value of 1 is translated into byte address 32. If the off-tile stream type is indirect, this field can serve as a base address that is added to the offset read from the indirect offset list before accessing memory.
[0219] 간접 오프셋은 오프-타일 스트림 유형이 간접인 경우 사용될 수 있다. 소스가 타일-로컬 메모리인 경우, 간접 오프셋은 간접 오프셋 목록을 저장하는 타일-로컬 메모리에 워드 시작 오프셋을 제공한다. 소스가 레지스터 파일인 경우, 간접 오프셋은 간접 오프셋 목록을 소싱하는 파일 레지스터 인덱스를 제공한다. 레지스터 파일은 스트림 명령들이 발행되는 시간에 판독될 수 있다.[0219] Indirect offset can be used when the off-tile stream type is indirect. If the source is tile-local memory, indirect offset provides the word start offset to tile-local memory, which stores the indirect offset list. If the source is a register file, indirect offset provides the file register index sourcing the list of indirect offsets. The register file can be read at the time stream instructions are issued.
[0220] 간접 목록 크기는 오프-타일 스트림 유형이 간접인 경우 사용될 수 있다. 소스가 타일-로컬 메모리인 경우, 오프셋 목록의 엘리먼트들의 개수는 타일-로컬 메모리에 저장된다. 소스가 레지스터 파일인 경우, 유효한 오프셋들을 포함하는 레인들의 개수가 저장된다. 전달 완료는 스트림의 나머지 디스크립터들과 순서대로 유지된다.[0220] The indirect list size can be used when the off-tile stream type is indirect. If the source is tile-local memory, the number of elements in the offset list is stored in tile-local memory. If the source is a register file, the number of lanes containing valid offsets is stored. Delivery completion is maintained in order with the remaining descriptors of the stream.
[0221] 간접 목록 유형은 오프-타일 스트림 유형이 간접이고 오프셋 목록에 저장된 오프셋 유형을 나타내는 경우 사용될 수 있다. 이것은 워드 오프셋과 행 오프셋을 포함할 수 있다. 간접 목록 스트라이드는 오프-타일 스트림 유형이 간접이고 타일-로컬 메모리에 저장된 오프셋 목록의 2 개의 어드레스 워드들 사이의 거리를 나타내는 경우 사용된다. 이는 부호 있는 정수일 수 있다.[0221] The indirect list type can be used when the off-tile stream type is indirect and indicates the offset type stored in the offset list. This may include word offset and row offset. Indirect list stride is used when the off-tile stream type is indirect and represents the distance between two address words in the offset list stored in tile-local memory. This can be a signed integer.
[0222] 간접 필터 필드는 오프-타일 스트림 유형이 간접인 경우 사용되고, 이 필드가 설정된 경우, 간접 필터 값과 일치하는 간접 메모리 어드레스는 필터링된다. 간접 필터 값은 필터링되어야 하는 간접 액세스 목록의 엘리먼트 값을 나타낸다. 값은 간접 목록 유형이 표현되는 유형이다. 필터링은 간접 스트림에 대해 간접 필터 필드가 설정되거나 간접 오프셋 목록의 엘리먼트 값이 이 필드와 일치하는 경우 인에이블될 수 있다. 필터링된 엘리먼트에 대응하는 오프-타일 및 타일-로컬 액세스는 드롭되지만 타일-로컬 버퍼는 필터링된 액세스의 크기만큼 계속 진행된다.[0222] The indirect filter field is used when the off-tile stream type is indirect, and when this field is set, indirect memory addresses matching the indirect filter value are filtered. The indirect filter value represents the element value of the indirect access list that must be filtered. The value is the type for which the indirect list type is expressed. Filtering can be enabled if the indirect filter field is set for an indirect stream or if the value of an element in the indirect offset list matches this field. Off-tile and tile-local accesses corresponding to filtered elements are dropped, but the tile-local buffer continues to be the size of the filtered access.
[0223] 4 바이트 또는 512 바이트의 배수들의 길이와 같은 길이는 예들로서, 스트림에 의해 액세스되는 총 워드들의 개수를 나타낸다. 오프-타일 스트림 유형이 선형 또는 스트라이드된 경우, 이 필드는 스트림에 의해 액세스되는 총 워드 개수를 나타낸다. 오프-타일 스트림 유형이 간접인 경우, 이 필드는 간접 오프셋 목록의 각각의 어드레스에서 액세스되는 워드들의 개수를 나타낸다. 프로그램 에러는 이 필드의 실제 값이 오프-타일 메모리 유형의 입도의 배수가 아닌 경우 발생될 수 있다. 프로그램 에러는 또한 생성된 어드레스가 오프-타일 메모리(105)의 범위들을 초과하는 경우 발생될 수 있다.[0223] A length, such as a length of multiples of 4 bytes or 512 bytes, as examples, indicates the total number of words accessed by the stream. If the off-tile stream type is linear or strided, this field indicates the total number of words accessed by the stream. If the off-tile stream type is indirect, this field indicates the number of words accessed at each address in the indirect offset list. Program errors may occur if the actual value of this field is not a multiple of the granularity of the off-tile memory type. Program errors may also occur if the generated address exceeds the ranges of off-tile memory 105.
[0224] 스트라이드 크기 필드는 오프-타일 메모리 유형의 입도 단위로 스트라이드 크기를 나타낸다. 이는 부호 있는 정수일 수 있다. 예들로서, 4 바이트 또는 512 바이트의 배수들의 스트라이드당 길이와 같은 스트라이드당 길이는 각각의 스트라이드에서 액세스되는 워드들의 개수를 나타낸다. 이는 부호 있는 필드이지만 음수가 아닌 값들을 포함해야 한다. 길이는 이 필드의 배수일 필요가 없다. 이 필드는 이 스트림 디스크립터에 의해 선택된 오프-타일 메모리 유형의 입도의 배수여야 한다. 스트라이드된 액세스의 마지막 요청은 스트라이드당 길이보다 작을 수 있는 나머지 전달 워드들에 액세스한다. 프로그램 에러는 스트라이드당 길이가 0이거나, 음수이거나, 오프-타일 메모리 액세스 입도의 배수가 아닌 경우 발생될 수 있다. 프로그램 에러는 또한 생성된 어드레스가 오프-타일 메모리(105)의 범위들을 초과하는 경우 발생될 수 있다.[0224] The stride size field indicates the stride size in granularity units of the off-tile memory type. This can be a signed integer. By way of example, the length per stride, such as the length per stride in multiples of 4 bytes or 512 bytes, indicates the number of words accessed in each stride. This is a signed field, but must contain non-negative values. The length need not be a multiple of this field. This field must be a multiple of the granularity of the off-tile memory type selected by this stream descriptor. The last request of a strided access accesses the remaining transferred words, which may be less than the length per stride. Program errors may occur if the length per stride is zero, negative, or is not a multiple of the off-tile memory access granularity. Program errors may also occur if the generated address exceeds the ranges of off-tile memory 105.
[0225] 추적 필드는 스트림 전달을 추적해야 하는지 여부를 나타낸다. 추적은 디버깅의 일부로 스트림 전달 동안 취해진 조치들에 대한 로깅 정보를 포함할 수 있다.[0225] The tracking field indicates whether stream delivery should be tracked. The trace may include logging information about actions taken during stream delivery as part of debugging.
[0226] 도 9는 스트림 디스크립터를 구성 오프-타일 스트림 요청 또는 타일-로컬 스트림 요청으로 언롤링하기 위한 예시적인 프로세스(1600)의 흐름도이다. 예시적인 프로세스(1600)는 하나 이상의 위치들에 있는 하나 이상의 프로세서들의 시스템에서 수행될 수 있다. 예를 들어, 하드웨어 회로(101)는 전술한 바와 같이, 프로세스(1600)를 수행할 수 있다.[0226] Figure 9 is a flow diagram of an example process 1600 for unrolling a stream descriptor into a configured off-tile stream request or tile-local stream request. Example process 1600 may be performed on a system of one or more processors at one or more locations. For example, hardware circuit 101 may perform process 1600, as described above.
[0227] 블록(1610)에 도시된 바와 같이, 프로세스는 4 바이트 단위로 크기를 수신하는 것과 같이 오프-타일 메모리의 크기를 수신하는 것을 포함한다. 추가로, 프로세스는 오프-타일 메모리 유형을 타겟으로 하는 스트림 요청의 최대 청크 크기를 수신하는 것을 포함한다. 블록(1620)에 도시된 바와 같이, 프로세스는 간접 리스트 유형에 기반하여 오프-타일 메모리에, 파일 레지스터 또는 타일-로컬 메모리로부터 판독된 간접 오프셋을 4 바이트 오프셋과 같은 오프셋으로 변환하는 것을 더 포함한다.[0227] As shown at block 1610, the process includes receiving the size of the off-tile memory, such as receiving the size in units of 4 bytes. Additionally, the process includes receiving the maximum chunk size of a stream request targeting an off-tile memory type. As shown at block 1620, the process further includes converting an indirect offset read from a file register or tile-local memory to an offset, such as a 4-byte offset, to off-tile memory based on the indirect list type. .
[0228] 블록(1630)에 도시된 바와 같이, 프로세스는 또한 스트라이드 및/또는 간접 요청들을 생성하는 것을 포함한다. 스트라이드된 요청들의 경우, 프로세스는 스트라이드된 스트림 디스크립터를 각각이 오프-타일 메모리의 연속 어드레스들에 액세스하는 요청들의 세트로 부분적으로 언롤링하는 것을 포함할 수 있다. 간접 타일-로컬 메모리 요청의 경우, 프로세스는 간접 스트림 디스크립터를 취하고 디스크립터에 의해 선택된 오프-타일 메모리 유형에 오프셋들의 목록을 생성하는 것을 포함할 수 있다. 간접 파일 레지스터 메모리 요청들의 경우, 프로세스는 간접 스트림 명령 발행 시 판독된 파일 레지스터로부터 오프셋들의 목록을 생성하는 것을 포함할 수 있다.[0228] As shown at block 1630, the process also includes generating strides and/or indirect requests. For strided requests, the process may include partially unrolling the strided stream descriptor into a set of requests, each accessing consecutive addresses of off-tile memory. For an indirect tile-local memory request, the process may include taking an indirect stream descriptor and generating a list of offsets in the off-tile memory type selected by the descriptor. For indirect file register memory requests, the process may include generating a list of offsets from the file register read when issuing an indirect stream instruction.
[0229] 블록(1640)에 도시된 바와 같이, 프로세스는 언롤링된 오프-타일 메모리 요청의 목록을 생성하는 것을 포함하며, 여기서 각각의 언롤링된 요청은 오프-타일 메모리의 연속 어드레스 세트에 액세스한다. 이러한 요청들은 타일-로컬 메모리 요청과 오프-타일 메모리 요청들 둘 모두를 생성하는 데 사용된다. 타일-로컬 스트라이드, 타일-로컬 스트림 유형 및 정렬은 요청들을 언롤링하는 동안 고려된다. 프로세스는 부분적으로 언롤링된 요청들의 목록을 생성하는 것을 더 포함하며, 여기서 각각의 부분적으로 언롤링된 요청은 오프-타일 메모리의 연속 어드레스들의 세트에 액세스한다. 이러한 요청들은 추가로 언롤링되어 오프-타일 메모리 유형에 의해 선택된 메모리의 입도로 정렬된 요청들의 세트를 생성한다.[0229] As shown at block 1640, the process includes generating a list of unrolled off-tile memory requests, where each unrolled request accesses a contiguous set of addresses of off-tile memory. do. These requests are used to generate both tile-local memory requests and off-tile memory requests. Tile-local stride, tile-local stream type and alignment are considered while unrolling requests. The process further includes generating a list of partially unrolled requests, where each partially unrolled request accesses a set of contiguous addresses of off-tile memory. These requests are further unrolled to create a set of requests sorted by the granularity of memory selected by the off-tile memory type.
[0230] 블록(1650)에 도시된 바와 같이, 프로세스는 스트림 디스크립터들을 오프-타일 메모리 요청들 및 타일-로컬 메모리 요청들의 세트로 언롤링하는 것을 포함한다.[0230] As shown at block 1650, the process includes unrolling stream descriptors into a set of off-tile memory requests and tile-local memory requests.
[0231] 도 10은 스트림 전달을 순서화하기 위한 예시적인 프로세스(1700)의 흐름도이다. 예시적인 프로세스(1700)는 하나 이상의 위치들에 있는 하나 이상의 프로세서들의 시스템에서 수행될 수 있다. 예를 들어, 하드웨어 회로(101)는 전술한 바와 같이, 프로세스(1700)를 수행할 수 있다. 동일한 스트림 ID를 가진 코어에 의해 발행되는 개별 스트림 명령들은 단일 스트림을 형성하지만, 순서화는 상이한 스트림들에 걸쳐 보장되지 않을 수 있다. 스캐터 수집 엔진(1722)은 이러한 요청들을 병렬로 프로세싱할 수 있는 다중 스레드들을 포함한다. 순서화는 다수의 스트림 명령들에 걸쳐 있을 수 있는 단일 스트림 내 전달들에 대해 보장될 수 있다.[0231] Figure 10 is a flow diagram of an example process 1700 for ordering stream delivery. Example process 1700 may be performed on a system of one or more processors at one or more locations. For example, hardware circuit 101 may perform process 1700, as described above. Individual stream instructions issued by a core with the same stream ID form a single stream, but ordering may not be guaranteed across different streams. Scatter collection engine 1722 includes multiple threads that can process these requests in parallel. Ordering may be guaranteed for deliveries within a single stream, which may span multiple stream instructions.
[0232] 블록(1710)에 도시된 바와 같이, 스트림에 속하는 스트림 명령들은 순서대로 프로세싱된다. 이에 대응하는 요청들은 스캐터 수집 엔진(322)에 의해 순서대로 발행될 것이다.[0232] As shown at block 1710, stream instructions belonging to the stream are processed in order. The corresponding requests will be issued in order by the scatter collection engine 322.
[0233] 블록(1720)에 도시된 바와 같이, 간접 스트림 명령들의 경우, 오프셋 목록이 순서화된다. 오프셋 목록의 오프셋 엘리먼트들은 순서대로 프로세싱된다. 쓰기들은 목적지 메모리에 순서대로 발행되지만, 쓰기들은 목적지 메모리에 의해 순서 없이 커밋될 수 있다. 판독들은 소스 메모리에 순서대로 발행되지만, 판독들은 소스 메모리에 의해 순서 없이 서비스될 수 있다.[0233] As shown at block 1720, for indirect stream instructions, the offset list is ordered. Offset elements in the offset list are processed in order. Writes are issued to the destination memory in order, but writes may be committed out of order by the destination memory. Reads are issued to the source memory in order, but reads may be serviced out of order by the source memory.
[0234] 블록(1730)에 도시된 바와 같이, 스캐터-수집 엔진(322)은 스트림에 대한 단조로운 증분 진행을 나타내기 위해 동기화 플래그(318)를 업데이트한다. 타일-로컬 메모리가 소스인 경우, 동기화 플래그(318)는 그것으로부터의 판독을 추적한다. 동기화 플래그 값은 타일-로컬 메모리에서 덮어쓰여질 수 있는 데이터 청크들 중 제1 청크를 나타낸다. 타일-로컬 메모리가 목적지인 경우, 동기화 플래그(318)는 그것으로의 쓰기를 추적한다. 여기서 동기화 플래그 값은 타일-로컬 메모리의 제1 데이터 청크들에 대한 후속 판독들이 요청된 데이터로 반환됨을 나타낸다.[0234] As shown at block 1730, the scatter-collect engine 322 updates the synchronization flag 318 to indicate monotonic incremental progress for the stream. If tile-local memory is the source, synchronization flag 318 tracks reads from it. The synchronization flag value indicates the first chunk among data chunks that can be overwritten in tile-local memory. If tile-local memory is the destination, synchronization flag 318 tracks writes to it. Here the synchronization flag value indicates that subsequent reads of the first data chunks of tile-local memory will return the requested data.
[0235] 블록(1740)에 도시된 바와 같이, 동기화 플래그(318)의 완료 비트는 스트림의 끝에서 업데이트될 수 있다. 이는 스트림 디스크립터에 설정된 완료 비트로 표시된다. 완료 비트는 마지막 스트림 디스크립터를 포함하여 이전 요청에 대한 모든 데이터가 메모리에 완전히 커밋된 후에 설정될 수 있다. 모든 판독들은 타일-로컬 메모리가 소스인 경우 완료되고 모든 쓰기들은 타일-로컬 메모리가 목적인 경우 커밋된다.[0235] As shown at block 1740, the completion bit of synchronization flag 318 may be updated at the end of the stream. This is indicated by a completion bit set in the stream descriptor. The completion bit may be set after all data for the previous request, including the last stream descriptor, has been fully committed to memory. All reads are completed if tile-local memory is the source and all writes are committed if tile-local memory is the destination.
[0236] 도 11은 스트림 순서화의 예시도이다. 단일 스트림을 형성하기 위해 스트림 디스크립터들 A와 B를 고려한다. 스트림 디스크립터 B는 설정된 완료 비트 세트를 갖는다. 스트림의 부분 진행은 동기화 플래그로 추적된다. A0이 판독 또는 쓰기로 메모리에 커밋되면, 동기화 플래그는 1의 값으로 업데이트된다. A0보다 먼저 A2와 B1이 커밋되더라도, 동기화 플래그 값은 3으로 업데이트되지 않는다. A1이 메모리에 커밋되면, 스트림의 5 개의 연속 데이터 청크들(A0, A1, A2, B0, B1)은 커밋되고, 이는 5의 동기화 플래그 값으로 표시된다. 완료 비트는 스트림 디스크립터 A가 스트림의 마지막이 아니기 때문에 이 시점에서 설정되지 않는다. B2가 커밋되면, 동기화 플래그 값은 6으로 설정된다. 완료 비트는 이제 스트림의 모든 데이터 청크들이 커밋되고 스트림 디스크립터 B가 스트림의 끝이므로 설정될 수 있다.[0236] Figure 11 is an example diagram of stream ordering. Consider stream descriptors A and B to form a single stream. Stream descriptor B has the completion bit set. Partial progress of the stream is tracked with synchronization flags. When A0 is committed to memory with a read or write, the synchronization flag is updated to a value of 1. Even if A2 and B1 are committed before A0, the synchronization flag value is not updated to 3. When A1 is committed to memory, the five consecutive data chunks of the stream (A0, A1, A2, B0, B1) are committed, indicated by a synchronization flag value of 5. The completion bit is not set at this point because stream descriptor A is not the end of the stream. When B2 is committed, the synchronization flag value is set to 6. The completion bit can now be set since all data chunks in the stream have been committed and stream descriptor B is the end of the stream.
협력적인 프리페칭Collaborative Prefetching
[0237] 개시된 기술의 양태들은 희소 가속기의 타일들에 의해 사용될 수 있는 명령 프리페치 파이프라인 아키텍처를 제공하며, 이는 기존 CPU들에 배포된 전체 캐시 일관성 솔루션의 복잡성 없이 우수한 성능을 제공한다.[0237] Aspects of the disclosed technology provide an instruction prefetch pipeline architecture that can be used by tiles of a sparse accelerator, providing superior performance without the complexity of a full cache coherence solution deployed in existing CPUs.
[0238] 개시된 기술의 양태들은 콜드 캐시 미스 오버헤드(cold cache miss overhead)들을 줄이기 위해 프로그래밍 모델의 SPMD 양태 주위에 프리페치 파이프라인을 생성하는 것과 관련된 방법들 및 시스템들을 제공한다. 모든 코어의 프리페치 응답들은 희소 가속기의 모든 코어들로 브로드캐스트된다. 이러한 프리페치 응답들은 코어의 로컬 캐시에 커밋된다. 이것은 다른 비-요청 코어들이, 코어들이 명령들이나 데이터를 프로세싱하기 위해 이용 가능할 시간보다 앞서 명령들이나 데이터 번들들을 얻게 하고, 이는 프로세스 사이클들의 누락을 완전히 방지할 수 있다. 게다가, 요청들 간 중재를 위한 논리적 및/또는 하드웨어 기반 경로인 중재 경로에 프리페치 요청 필터링이 있을 수 있고, 이는 중복된 요청 페치들을 방지하여 태스크 명령 메모리 대역폭을 부스팅하는 태스크 명령 메모리로 이어진다.[0238] Aspects of the disclosed technology provide methods and systems related to creating a prefetch pipeline around the SPMD aspect of a programming model to reduce cold cache miss overheads. Prefetch responses from all cores are broadcast to all cores in the sparse accelerator. These prefetch responses are committed to the core's local cache. This allows other non-requesting cores to obtain instructions or data bundles ahead of the time the cores would be available to process the instructions or data, which can completely prevent missing process cycles. Additionally, there may be prefetch request filtering in the arbitration path, which is a logical and/or hardware-based path for arbitration between requests, which leads to task instruction memory boosting task instruction memory bandwidth by preventing duplicate request fetches.
[0239] 태스크 명령 메모리는 타일 액세스 코어(TAC) 및 타일 실행 코어(TEC)에 의해 실행될 수 있는 프로그램들의 세트를 보유할 수 있다. 각각의 코어의 프로그램 카운터(PC)는 태스크 명령 메모리에 대한 물리적 오프셋이다. 태스크 명령 메모리는 직접 메모리 액세스 시스템에 노출되는 소프트웨어 관리 메모리이다. 소프트웨어는 직접 메모리 액세스를 사용하여 태스크 명령 메모리에 프로그램들을 파퓰레이팅(populate)하고 타일들에 태스크들을 발행하는 동안 적절한 프로그램 카운터를 사용할 수 있다. 타일들이 단일 프로그램 다중 데이터 모드에서 오퍼레이팅하므로, 희소 가속기 실행의 어느 시점에서, 통계적으로 대부분의 타일들은 동일한 프로그램을 실행할 수 있다. 이들 프로그램들은 추가로 하나 또는 컴팩트 명령 루프들로 구성될 수 있다. 컴팩트 명령 루프는 타일 메모리에 맞추어지도록 충분히 작은 메모리 내 명령들의 크기를 지칭할 수 있다. 프로그램 자체들은 크기가 작을 수 있고, 예를 들어, 수백 개의 명령 번들들일 수 있고, 프로그램들은 루프 내의 분기들 또는 다른 루프들로의 분기들을 통해 발산될 수 있는 다수의 분기들을 가질 수 있다.[0239] The task instruction memory may hold a set of programs that can be executed by a tile access core (TAC) and a tile execution core (TEC). Each core's program counter (PC) is a physical offset into task instruction memory. Task instruction memory is software managed memory exposed to the direct memory access system. Software can use direct memory access to populate programs in task instruction memory and use an appropriate program counter while issuing tasks to tiles. Because the tiles operate in a single program multiple data mode, at any point in the sparse accelerator execution, statistically most tiles can be executing the same program. These programs may further consist of single or compact instruction loops. A compact instruction loop can refer to the size of instructions in memory that is small enough to fit into tile memory. The programs themselves can be small in size, for example bundles of hundreds of instructions, and programs can have multiple branches that can emanate through branches within a loop or branches to other loops.
[0240] 이들 및 다른 잠재적인 특성은 예를 들어 도 12-도 13을 참조하여 본원에 설명된 명령 파이프라인에 의해 이용될 수 있다. 명령 번들이 희소 가속기에 의해 수신되면, 희소 가속기는 수신된 명령에 대한 프리페치 응답을 희소 가속기의 모든 타일들에 브로드캐스팅하도록 구성된다. 프리페치 응답들은 각각의 코어의 로컬 캐시에 커밋되어, 비-요청 타일들이 미리 번들들을 얻을 수 있도록 하여, 누락들을 완전히 방지한다. 게다가, 태스크 명령 메모리로 이어지는 중재 경로에 대한 프리페치 요청 필터링은 일부 예들에서 구현될 수 있고, 중복된 요청 페치들을 피함으로써 태스크 명령 메모리 대역폭을 부스팅할 수 있다.[0240] These and other potential features may be exploited by the instruction pipeline described herein, for example, with reference to FIGS. 12-13. When an instruction bundle is received by a sparse accelerator, the sparse accelerator is configured to broadcast a prefetch response for the received instruction to all tiles of the sparse accelerator. Prefetch responses are committed to each core's local cache, allowing non-requested tiles to obtain bundles in advance, completely preventing misses. Additionally, prefetch request filtering on the arbitration path leading to task instruction memory may be implemented in some examples, boosting task instruction memory bandwidth by avoiding duplicate request fetches.
[0241] 도 12는 개시된 기술의 양태들에 따른 예시적인 희소 가속기의 타일들(1901 및 1902) 사이의 연결성의 논리적 뷰를 예시한다. 명확하게 하기 위해, 도 12와 관련하여 모든 컴포넌트, 모듈 또는 소프트웨어 블록이 라벨링되지 않는다. 일반적으로, 아래의 설명에서 명백해질 바와 같이, 명령들 프리페치, 명령들에 대한 요청들의 집계, 필터링, 명령들이나 참조들 유지를 통해 요청 프로세싱 유닛에 가장 가까운 메모리 위치에, 명령들이 더 빠르게 프로세싱 유닛들 또는 프로세싱 코어들에 제공될 수 있어서, 시스템 효율성을 높인다. 도 12와 관련된 컴포넌트들의 추가적인 양태들은 도 13과 관련하여 아래에서 더 설명된다.[0241] Figure 12 illustrates a logical view of the connectivity between tiles 1901 and 1902 of an example sparse accelerator in accordance with aspects of the disclosed technology. For clarity, not all components, modules or software blocks are labeled with respect to FIG. 12 . In general, as will become clear from the discussion below, prefetching instructions, aggregating requests for instructions, filtering them, and maintaining instructions or references to the memory location closest to the request processing unit allows the instructions to be moved to the processing unit more quickly. or processing cores, increasing system efficiency. Additional aspects of the components associated with FIG. 12 are further described below with respect to FIG. 13 .
[0242] 광범위한 개요에서, 도 12는 태스크 명령 메모리(Timem 또는 Timem 뱅크), 명령 버퍼들("iBuf"), 프리페치 유닛들 및 명령 라우터들의 양태들을 예시한다. 도 12에는 타일 액세스 코어(TAC)(1910) 및 타일 실행 코어(TEC)(1920)를 포함하는 타일(1901)이 예시된다. TAC(1910)는 프리페치(1911) 및 iBuf(1912)를 포함할 수 있다. 유사하게, TEC는 프리페치 유닛(1921)과 iBuf(1922)를 포함할 수 있다. 또한 도 12에는 각각 프리페치(1911) 및 iBuf(1932)와 프리페치 유닛(1941) 및 iBuf(342)를 포함하는 TAC(1930) 및 TEC(1940)를 포함하는 타일 코어(1902)가 예시된다.[0242] In broad overview, Figure 12 illustrates aspects of task instruction memory (Timem or Timem bank), instruction buffers (“iBuf”), prefetch units, and instruction routers. 12 illustrates a tile 1901 that includes a tile access core (TAC) 1910 and a tile execution core (TEC) 1920. TAC 1910 may include prefetch 1911 and iBuf 1912. Similarly, the TEC may include a prefetch unit 1921 and an iBuf 1922. Also illustrated in Figure 12 is a tile core 1902 that includes a TAC 1930 and a TEC 1940 that include a prefetch 1911 and an iBuf 1932 and a prefetch unit 1941 and an iBuf 342, respectively. .
[0243] 도 12에는 평면도 블록(1999) 내에 논리적으로 또는 물리적으로 포함될 수 있는 Timem(1951, 1952) 및 명령 라우터(1960)가 추가로 예시된다. Timem(1951 및 1952)은 Timem보다 더 다운스트림인 위치에서 명령들을 요청하는 타일 코어에 비해 각각의 타일 코어의 더 빠른 액세스를 위한 명령들을 로컬로 저장할 수 있다. 또한 풋프린트 블록(1999) 및 그 내부의 Timem 뱅크들로 다운스트림으로 명령 번들들을 브로드캐스팅할 수 있는 명령 브로드캐스트 버스가 예시된다. 명령 요청 버스(1992)는 이들을 명령들을 요청하기 전에 다양한 컴포넌트들로부터의 명령들에 대한 요청들을 집계할 수 있다. 병렬화기 및 직렬화기는 다양한 버스들을 따라 명령들을 송신하기 위해, 예를 들어 명령 브로드캐스트 버스(1991)로부터 수신되거나 명령 요청 버스(1992)로 전송되는 명령들을 직렬화하기 위해 명령들을 병렬화 또는 직렬화할 수 있다.[0243] Figure 12 further illustrates Timem (1951, 1952) and Command Router (1960), which may be logically or physically included within floor plan block (1999). Timem (1951 and 1952) can store instructions locally for faster access on each tile core compared to tile cores requesting instructions from a location further downstream than Timem. Also illustrated is an instruction broadcast bus capable of broadcasting instruction bundles downstream to the footprint block 1999 and Timem banks therein. Command request bus 1992 may aggregate requests for commands from various components before requesting them. Parallelizers and serializers may parallelize or serialize instructions to transmit instructions along various buses, for example, to serialize instructions received from the instruction broadcast bus 1991 or sent to the instruction request bus 1992. .
[0244] 코어에 대응하는 프리페치 유닛(1911) 또는 프리페치 유닛(1912)과 같은 프리페치 유닛은 미스 프로그램 카운터(PC)(및 오버레이/태스크 ID)로부터 시작하여 프리페치 창의 종료까지 Timem에 판독 요청을 할 수 있다. 프리페치 창은 레지스터나 다른 메모리 영역을 사용하여 소프트웨어에 의해 선택할 수 있는 시간 기간이다. 예를 들어, 프리페치 창은 프리페치 깊이 변수에 정의될 수 있다. 다른 타일들의 프리페치 판독 요청들은 인접한 평면도 블록(1999)으로 포워딩될 수 있다. 이러한 포워딩된 요청들은 인접한 타일 코어의 프리페치 유닛들에 의해 생성된 프리페치 요청들로 중재될 수 있다. 예를 들어, 타일(1901)과 타일(1902)은 서로 인접할 수 있다. 일부 예들에서, 한 쌍의 코어들은 단일 명령 요청 버스 또는 단일 명령 브로드캐스트 버스에 할당될 수 있다.[0244] A prefetch unit, such as a prefetch unit 1911 or a prefetch unit 1912 corresponding to a core, reads Timem starting from the miss program counter (PC) (and overlay/task ID) until the end of the prefetch window. You can make a request. A prefetch window is a period of time that can be selected by software using registers or other memory areas. For example, a prefetch window can be defined in the prefetch depth variable. Prefetch read requests for other tiles may be forwarded to the adjacent floor plan block 1999. These forwarded requests may be arbitrated with prefetch requests generated by prefetch units of adjacent tile cores. For example, tile 1901 and tile 1902 may be adjacent to each other. In some examples, a pair of cores may be assigned to a single command request bus or a single command broadcast bus.
[0245] 다수의 프리페치 명령 요청 뱅크들은 타일에는 있을 수 있다. 일부 예들에서, Timem 뱅크당 하나의 버스가 있을 수 있고, 이는 서로 독립적으로 중재될 수 있다. 버스들의 독립적 중재는 독립 뱅크들에 걸쳐 헤드 선 차단을 피하게 할 수 있다.[0245] There may be multiple prefetch instruction request banks in a tile. In some examples, there may be one bus per Timem bank, which may be arbitrated independently of each other. Independent arbitration of buses can avoid head line blocking across independent banks.
[0246] 프리페치 창에서 전송된 요청들은 명령 라우터(1960)에서 수신될 수 있다. 명령 라우터(1960)는 선택된 요청들을 필터링하여 다른 명령 라우터 또는 타겟 Timem 뱅크로 포워딩하기 전에 중복들을 제거할 수 있다. 필터링은 코어들이 SPMD 모드에서 오퍼레이팅하는 경우 명령 요청 대역폭을 잠재적으로 증가시킬 수 있다.[0246] Requests sent in the prefetch window may be received at command router 1960. Command router 1960 may filter selected requests to remove duplicates before forwarding them to another command router or target Timem bank. Filtering can potentially increase instruction request bandwidth when cores are operating in SPMD mode.
[0247] Timem 뱅크에서 판독된 명령들은 명령 브로드캐스트 버스의 모든 타일들에 브로드캐스트될 수 있다. 예를 들어, Timem 뱅크들만큼 많은 교육 브로드캐스트 버스들이 있을 수 있다. 일부 예들에서, 명령들은 명령 번들들로 전송될 수 있다. 명령 그룹들은 번들들에 포함된 명령들로 구성된다. 번들은 정렬된 "경계"에서 시작되는 일련의 명령들일 수 있다. 명령 번들은 프로세서 또는 코어의 고정된 사이클들의 개수에 걸쳐 대응 명령 브로드캐스트 버스에서 직렬화될 수 있다. 시스템의 "정상 상태" 오퍼레이션과 같은 일부 예들에서, 명령 브로드캐스트 버스들의 총 대역폭은 사이클당 2 개의 번들들일 수 있다. 이런 방식으로, 명령 브로드캐스트 버스(1992)는 결코 역압을 받지 않는다.[0247] Commands read from the Timem bank may be broadcast to all tiles of the command broadcast bus. For example, there may be as many educational broadcast buses as Timem banks. In some examples, commands may be sent in command bundles. Command groups consist of commands included in bundles. A bundle can be a series of instructions starting from an aligned "boundary". A bundle of instructions may be serialized on a corresponding instruction broadcast bus over a fixed number of cycles of the processor or core. In some examples, such as “steady state” operation of the system, the total bandwidth of the command broadcast buses may be two bundles per cycle. In this way, the command broadcast bus 1992 is never backpressured.
[0248] 브로드캐스트 버스에서 수신된 명령들은 명령 라우터에 의해 병렬화될 수 있으며 하나의 명령은 iBuf 각각으로 포워딩된다. 정상 상태에서, 시스템은 프리페치 인터페이스에서 최대 2 개의 쓰기들과 명령 페치 인터페이스에서 최대 1 개의 판독을 유지해야 할 수 있다. 프리페치는 인입 명령을 프로세싱하고 ibuf에 커밋할지 아니면 드롭되어야할지 정한다.[0248] Commands received on the broadcast bus can be parallelized by the command router and one command is forwarded to each iBuf. Under normal conditions, the system may need to sustain up to two writes on the prefetch interface and up to one read on the instruction fetch interface. Prefetch processes the incoming instruction and determines whether it should be committed to ibuf or dropped.
[0249] 도 13은 명령 라우터(1960)의 추가적인 예시적인 양태들을 예시한다. 도 13에는 라운드 로빈(RR) 중재자(1910), 데이지 체인 라운드 로빈 중재자(1920), 라운드 로빈 임의 중재자(1930), 필터(1940), 직렬화기들(1950 및 1951), 디멀티플렉서들(demux)(1960) 및 병렬화기들(1971 및 1972)이 예시된다. 다른 양태들과 컴포넌트들은 단순성을 위해 표시되지 않은 도 13에 예시된다.[0249] Figure 13 illustrates additional example aspects of command router 1960. 13 shows a round robin (RR) arbiter (1910), a daisy chain round robin arbiter (1920), a round robin random arbiter (1930), a filter (1940), serializers (1950 and 1951), and demultiplexers (demux) ( 1960) and Parallelizers (1971 and 1972) are examples. Other aspects and components are illustrated in Figure 13 not shown for simplicity.
[0250] 명령 라우터(1960)는 시스템의 각각의 Timem 뱅크에 대해 독립적인 판독 요청 버스를 가질 수 있다. 라우터(1960)는 인접한 명령 라우터로 포워딩되기 전에 명령 브로드캐스트 버스의 대역폭과 일치하는 레이트로 명령 번들들을 스로틀링할 수 있다. 아래 설명에서, 병렬화 및 직렬화가, 요청이 명령 라우터(1960)에 제시되기 전에 수행될 수 있다고 가정될 수 있다.[0250] The command router 1960 may have an independent read request bus for each Timem bank in the system. Router 1960 may throttle command bundles at a rate consistent with the bandwidth of the command broadcast bus before being forwarded to an adjacent command router. In the description below, it may be assumed that parallelization and serialization may be performed before the request is presented to the command router 1960.
[0251] 명령 라우터(1960)가 중재하는 것은 Timem 뱅크에 대한 코어의 포지션에 따를 수 있다. 명령 라우터(1960)는 명령 라우터(1960)가 중재하는 인스턴스들에 기반하여 소스들과 목적지들을 선택하도록 파라미터화될 수 있다. 도 13에 예시된 디멀티플렉서(1960)는 통신 중인 타임뱅크들 또는 직렬화기들의 수에 따라 설계될 수 있다.[0251] The arbitration by the command router 1960 may depend on the core's position relative to the Timem bank. Command router 1960 may be parameterized to select sources and destinations based on the instances over which command router 1960 mediates. The demultiplexer 1960 illustrated in FIG. 13 can be designed depending on the number of time banks or serializers in communication.
[0252] 명령 라우터(1860)는 다음의 예시적인 소스들에 걸쳐 중재할 수 있다: 명령 라우터(1860)의 업스트림 또는 위의 명령 라우터에 의해 포워딩된 프리페치 판독; 명령 라우터(1860)로부터 다운스트림으로 명령 라우터에 의해 포워딩된 프리페치 판독; 및 명령 라우터(1860)에 연결된 코어들에 의해 시작되는 프리페치 판독들.[0252] Command router 1860 may arbitrate across the following example sources: prefetch reads forwarded by command routers upstream of or above command router 1860; Prefetch reads forwarded by the command router downstream from command router 1860; and prefetch reads initiated by cores connected to instruction router 1860.
[0253] demux(선택은 설계 파라미터임)는 명령 라우터에 연결된 코어들에서 발생하는 요청을 중재하기 위해 top_pre_req 또는 Bottom_pre_req를 선택한다. 이 중재는 데이지 체인 RR 중재 체계를 사용한다. 데이지 체인 라운드 로빈 중재자(1920)는 명령 브로드캐스트 버스의 대역폭과 일치하도록 "x" 사이클들마다 승인을 제공할 수 있다. 중재 대기 중인 요청은 PC가 명령 브로드캐스트 버스에 표시된 PC와 일치하면 드롭될 수 있다. 이는 필터링의 제1 레벨로 간주될 수 있다.[0253] The demux (the choice is a design parameter) selects top_pre_req or Bottom_pre_req to arbitrate requests originating from cores connected to the command router. This arbitration uses a daisy chain RR arbitration scheme. The daisy chain round robin arbiter 1920 may provide an acknowledgment every "x" cycles to match the bandwidth of the command broadcast bus. Requests pending arbitration may be dropped if the PC matches the PC represented on the command broadcast bus. This can be considered the first level of filtering.
[0254] 데이지 체인 중재의 승자는 Timem 뱅크에 대한 명령 라우터(1860)의 포지션에 기반하여 다르게 프로세싱될 수 있다. 예를 들어, Timem 뱅크가 명령 라우터 아래에 있는 경우, 데이지 체인 중재의 승자는 필터(1940)를 통과한 후 "하단"의 명령 라우터로 포워딩될 수 있다. Timem 뱅크가 명령 라우터(1860) 위에 있으면, 데이지 체인 중재의 승자는 필터(1940)를 통과한 후 상단에 있는 명령 라우터(1860)로 포워딩된다.[0254] The winner of the daisy chain arbitration may be processed differently based on the position of the command router 1860 relative to the Timem bank. For example, if the Timem bank is below the command router, the winner of the daisy chain arbitration may be forwarded to the “bottom” command router after passing filter 1940. If the Timem bank is above the command router 1860, the winner of the daisy chain arbitration is passed through the filter 1940 and then forwarded to the command router 1860 on top.
[0255] Timem 뱅크가 명령 라우터(1860) 내에 있는 경우, 데이지 체인 중재의 승자는 하단의 명령 라우터에 의해 포워딩된 요청을 사용하여 하나 초과의 중재 레벨을 겪는다. 이 경우, Timem 뱅크에 도달하기 위해 중재하는 2 개의 데이지 체인 네트워크들이 있을 수 있다. 명령 라우터(1860)의 포지션에 따라, 체인들은 균형이 맞지 않을 수 있다. 체인 양쪽의 코어들에 대한 공정한 액세스를 보장하기 위해, 수정된 RR 중재자가 사용될 수 있다. 제1 레벨 중재와 유사하게, 브로드캐스트 버스의 PC와 일치하는 임의의 요청은 여기에서 드롭될 것이다. 이는 필터링의 제2 레벨로 간주될 수 있다.[0255] If the Timem bank is within the command router 1860, the winner of the daisy chain arbitration undergoes more than one level of arbitration using requests forwarded by the lower command router. In this case, there may be two daisy chain networks interceding to reach the Timem bank. Depending on the position of the command router 1860, the chains may be unbalanced. To ensure fair access to cores on both sides of the chain, a modified RR arbiter can be used. Similar to first level arbitration, any request that matches the PC on the broadcast bus will be dropped here. This can be considered a second level of filtering.
[0256] 위의 전체 승자는 필터(440)로 전달되며, 필터(440)는 인입 요청을 다른 미해결 요청들 중 하나와 비교한다. 요청은 요청이 미해결 요청들 중 임의의 요청과 일치하면 드롭된다. 이는 필터링의 제3 레벨로 간주될 수 있다.[0256] The above overall winner is passed to filter 440, which compares the incoming request to one of the other outstanding requests. A request is dropped if it matches any of the outstanding requests. This can be considered a third level of filtering.
[0257] 추가로, 이 시스템의 프로그램 가능성은 각각의 지점의 필터링이 개별 프로그래밍 가능 또는 소프트웨어 제어 가능 스위치를 사용하여 인에이블/디스에이블될 수 있으므로 보장될 수 있다. Timem 액세스 버스는 시스템을 모든 Timem 뱅크들에 연결하는 버스일 수 있고, 이는 Timem 뱅크에 대한 명령 번들들을 판독 및 쓰게할 수 있다. Timem 액세스 버스는 아래에 더 상세히 설명된 바와 같이, 판독 요청 버스, 판독 응답 버스, 쓰기 요청 버스, 쓰기 응답 버스 같은 4 개의 버스들을 가질 수 있다.[0257] Additionally, the programmability of this system can be ensured as filtering at each point can be enabled/disabled using individually programmable or software controllable switches. The Timem access bus may be a bus that connects the system to all Timem banks, allowing it to read and write command bundles for the Timem banks. The Timem access bus may have four buses: a read request bus, a read response bus, a write request bus, and a write response bus, as described in more detail below.
[0258] 판독 요청 버스는 Timem 뱅크들로 이어질 수 있는 데이지 체인 버스일 수 있다. 각각의 Timem 뱅크는 요청이 이를 어드레싱하지 않는 경우 인접한 Timem 뱅크로 요청을 포워딩할 수 있다. 요청이 Timem 뱅크를 어드레싱하는 경우, Timem 뱅크에 의해 서비스된다.[0258] The read request bus may be a daisy chain bus that may lead to Timem banks. Each Timem bank can forward a request to an adjacent Timem bank if the request does not address it. If the request addresses a Timem bank, it is serviced by the Timem bank.
[0259] 판독 응답 버스는 Timem 뱅크에서 판독된 명령 번들들을 송신할 수 있는 데이지 체인 버스일 수 있다. 각각의 Timem 뱅크에는 인접한 뱅크에서 인입하는 명령과 현재 뱅크에서 오는 명령 번들 사이에 라운드 로빈 중재가 있을 수 있다. 명령 번들들이 "n" 개의 사이클에 걸쳐 직렬화되므로, 버스 승인은 "n" 개의 사이클들 동안 유지된다.[0259] The read response bus may be a daisy chain bus capable of transmitting command bundles read from the Timem bank. Each Timem bank may have round-robin arbitration between incoming instructions from adjacent banks and instruction bundles from the current bank. Since the instruction bundles are serialized over “n” number of cycles, the bus acknowledgment is maintained for “n” number of cycles.
[0260] 쓰기 요청 버스는 Timem 뱅크들로 이어질 수 있는 데이지 체인 버스일 수 있다. 예를 들어 쓰기 요청들은 2 개의 사이클들에 걸쳐 직렬화될 수 있다. 각각의 Timem 뱅크는 요청이 이를 어드레싱하지 않는 경우 인접한 뱅크들로 플릿(flit)들을 포워딩한다. 요청이 Timem 뱅크를 어드레싱하는 경우, 요청은 Timem 뱅크에 쓰여지기 전에 뱅크에 의해 병렬화된다.[0260] The write request bus may be a daisy chain bus that may lead to Timem banks. For example, write requests may be serialized over two cycles. Each Timem bank forwards flits to neighboring banks if a request does not address it. If a request addresses a Timem bank, the request is parallelized by the bank before being written to the Timem bank.
[0261] 쓰기 응답 버스는 Timem 뱅크들의 쓰기 응답을 중계하는 데이지 체인 버스일 수 있다. 각각의 Timem 뱅크에는 인입 응답과 현재 뱅크의 응답 사이에 중재가 있다. 간단한 라운드 로빈 중재는 응답들 중 하나가 승인되거나 제공되게 하는 데 사용될 수 있다. [0261] The write response bus may be a daisy chain bus that relays the write response of Timem banks. Each Timem bank has arbitration between the incoming response and the current bank's response. Simple round robin arbitration can be used to ensure that one of the responses is accepted or provided.
[0262] 판독 및 쓰기 요청들은 최대 2^q 개의 미해결 판독 및 쓰기 요청들을 인코딩하기 위한 "q" 비트 태그를 가질 수 있고, 이 요청은 뱅크들에 의한 응답들로 다시 전달되고 응답들에 대응하는 요청을 식별하기 위한 명령들을 제공하는 전체 시스템 또는 컴포넌트에 의해 사용될 수 있다.[0262] Read and write requests may have a "q" bit tag to encode up to 2^q outstanding read and write requests, which are passed back to responses by banks and It can be used by the entire system or component to provide instructions for identifying requests.
[0263] 엔드포인트가 요청이나 응답을 수락할 수 없다면, 버스는 버스가 포함된 명령들이나 데이터를 전달할 수 없고 버스를 통해 전송될 백로그가 쌓이는 경우에 "역압"을 수행할 수 있다. 게다가, 버스는 중재 손실로 인해 역압을 받을 수 있다. 이것은 Timem 액세스들이 일반적으로 낮은 대역폭 액세스들이므로 전체 시스템에서 허용될 수 있다.[0263] If an endpoint is unable to accept a request or response, the bus may undergo “back pressure” where the bus cannot carry the commands or data contained therein and a backlog of what to be transmitted over the bus builds up. Additionally, the bus may be subject to back pressure due to arbitration losses. This can be tolerated in the overall system since Timem accesses are generally low bandwidth accesses.
[0264] 타일 명령 메모리(Timem)는 도 12에서 설명한 타일 코어들에 의해 공유될 수 있다.[0264] The tile instruction memory (Timem) may be shared by the tile cores described in FIG. 12.
[0265] 본 개시내용의 양태들은 디지털 회로들, 컴퓨터 판독가능 저장 매체, 하나 이상의 컴퓨터 프로그램들, 또는 전술한 것 중 하나 이상의 조합으로 구현될 수 있다. 컴퓨터 판독가능 저장 매체는 예를 들어 클라우드 컴퓨팅 플랫폼에 의해 실행 가능하고 유형의 저장 디바이스에 저장되는 하나 이상의 명령들로서 비일시적일 수 있다.[0265] Aspects of the disclosure may be implemented in digital circuits, computer-readable storage media, one or more computer programs, or a combination of one or more of the foregoing. A computer-readable storage medium may be non-transitory, for example, one or more instructions stored in a tangible storage device and executable by a cloud computing platform.
컴퓨팅 개요Computing Overview
[0266] 본 명세서에서, "~로 구성된"이라는 문구는 컴퓨터 시스템들, 하드웨어 또는 컴퓨터 프로그램, 엔진 또는 모듈의 일부와 관련된 상이한 상황들에서 사용된다. 시스템이 하나 이상의 오퍼레이션들을 수행하도록 구성되었다고 말해질 때, 이는 동작 중일 때, 시스템이 하나 이상의 오퍼레이션들을 수행하도록 하는 시스템에 설치된 적절한 소프트웨어, 펌웨어 및/또는 하드웨어를 시스템이 가짐을 의미한다. 일부 하드웨어가 하나 이상의 오퍼레이션들을 수행하도록 구성되었다고 할 때, 이는 하드웨어가 동작 시, 입력을 수신하고 입력에 따르고 하나 이상의 오퍼레이션들에 대응하는 출력을 생성하는 하나 이상의 회로들을 포함한다는 것을 의미한다. 컴퓨터 프로그램, 엔진 또는 모듈이 하나 이상의 오퍼레이션들을 수행하도록 구성되었다고 할 때, 이는 컴퓨터 프로그램이 하나 이상의 프로그램 명령들을 포함하고 있음을 의미하고, 프로그램 명령들은, 하나 이상의 컴퓨터들에 의해 실행될 때, 하나 이상의 컴퓨터들이 하나 이상의 오퍼레이션들을 수행하게 한다.[0266] In this specification, the phrase “consisting of” is used in different contexts relating to computer systems, hardware or portions of a computer program, engine or module. When a system is said to be configured to perform one or more operations, it means that the system has appropriate software, firmware and/or hardware installed on the system that causes the system, when in operation, to perform one or more operations. When we say that some hardware is configured to perform one or more operations, this means that when the hardware operates, it includes one or more circuits that receive input, follow the input, and produce output corresponding to one or more operations. When a computer program, engine or module is said to be configured to perform one or more operations, this means that the computer program contains one or more program instructions, which, when executed by one or more computers, are Allows them to perform one or more operations.
[0267] 도면들에 도시되고 청구범위에 인용된 오퍼레이션들이 특정 순서로 도시되지만, 오퍼레이션들이 도시된 순서들과 다른 순서로 수행될 수 있고, 일부 오퍼레이션들이 생략되거나, 두 번 이상 수행될 수 있고/있거나, 다른 오퍼레이션들과 병렬로 수행될 수 있다는 것이 이해된다. 추가로, 상이한 오퍼레이션들을 수행하도록 구성된 상이한 시스템 컴포넌트들의 분리는 컴포넌트들의 분리를 요구하는 것으로 이해되어서는 안 된다. 설명된 컴포넌트들, 모듈들, 프로그램들 및 엔진들은 단일 시스템으로 함께 통합되거나 다수의 시스템들의 일부가 될 수 있다.[0267] Although the operations shown in the drawings and recited in the claims are shown in a particular order, the operations may be performed in a different order than the sequences shown, and some operations may be omitted or performed more than once/ It is understood that, or may be performed in parallel with other operations. Additionally, the separation of different system components configured to perform different operations should not be understood as requiring separation of the components. The described components, modules, programs and engines may be integrated together into a single system or be part of multiple systems.
[0268] 본원에서 실질적으로 임의의 복수 및/또는 단수 용어, 예를 들어("엘리먼트"라는 용어는 임의의 시스템, 컴포넌트, 데이터 등을 대신하는 용어임) "엘리먼트", "하나 이상의 엘리먼트들", "다중 엘리먼트들", "복수의 엘리먼트들", "적어도 하나의 엘리먼트" 등의 사용과 관련하여, 통상의 기술자들은 설명된 상황 및/또는 적용에 적절할 때 복수에서 단수로 및/또는 단수에서 복수로 번역할 수 있다. 다양한 단수/복수 순열들은, 명시적으로 표시되지 않는 한 명확성을 위해 그리고 제한 없이, 본원에서 명시적으로 설명될 수 있다.[0268] Any plural and/or singular term substantially used herein, such as "element", "one or more elements" (the term "element" is intended to replace any system, component, data, etc.) , “multiple elements”, “plural elements”, “at least one element”, etc., those skilled in the art will change the plural from the singular and/or from the singular to the plural as appropriate to the described situation and/or application. It can be translated as Various singular/plural permutations may be explicitly described herein for clarity and without limitation unless explicitly indicated.
[0269] 본 개시내용의 양태들은 종래의 CPU들에 배치된 전체 캐시 일관성 솔루션의 복잡성 없이 우수한 성능을 제공하는 명령 프리페치 파이프라인 아키텍처를 사용하는 방법들, 시스템들 및 장치들을 포함한다.[0269] Aspects of the present disclosure include methods, systems, and apparatus that use an instruction prefetch pipeline architecture that provides superior performance without the complexity of full cache coherence solutions deployed in conventional CPUs.
[0270] 개시된 기술의 양태들은 명령 메모리(TiMem), 명령 버퍼(iBuf), 프리페치 유닛 및 명령 라우터를 포함하여 명령 프리페치 파이프라인을 구성하는 데 사용될 수 있는 컴포넌트들에 관한 것이다.[0270] Aspects of the disclosed technology relate to components that can be used to configure an instruction prefetch pipeline, including an instruction memory (TiMem), an instruction buffer (iBuf), a prefetch unit, and an instruction router.
[0271] 본 개시내용의 양태들은 예를 들어 다음과 같이 XPU들의 타일들의 예상되거나 알려진 거동과 함께 존재할 수 있는 소정 속성들과 관련될 수 있다: 타일들은 SPMD(Single Program Multiple Data) 모드에서 실행될 것으로 예상되거나; 통계적으로 임의의 주어진 시점에 대부분의 타일들은 동일한 프로그램을 실행할 것으로 예상될 수 있거나; 프로그램들은 하나 이상의 컴팩트 루프들로 구성될 수 있거나; 프로그램들은 수백 개의 번들들과 같이 크기가 작을 수 있거나; 또는 프로그램들은 발산될 수 있는 다수의 분기들을 가질 수 있다. 개시된 기술은 이러한 또는 관련된 특성들을 이용할 수 있고 전체 캐시 기반 솔루션보다 복잡성이 낮다.[0271] Aspects of the present disclosure may relate to certain properties that may be present with the expected or known behavior of tiles of XPUs, for example: Tiles are expected to run in Single Program Multiple Data (SPMD) mode. expected; Statistically, at any given time, most tiles can be expected to run the same program; Programs may consist of one or more compact loops; Programs may be small in size, such as hundreds of bundles; Or programs can have multiple branches from which they can branch. The disclosed techniques can take advantage of these or related features and have lower complexity than full cache-based solutions.
[0272] 개시된 기술의 양태들은 하드웨어 회로를 포함한다. 하드웨어 회로는 복수의 타일들 ― 각각의 타일은 복수의 타일들 내의 다른 타일들과 병렬로 오퍼레이팅하도록 구성되고, 복수의 타일들의 각각의 타일은 프로세싱 코어; 프리페치 유닛; 및 명령 버퍼를 포함함 ―; 각자의 데이터를 업스트림 입력으로부터 다운스트림 목적지로 스트리밍하도록 구성된 복수의 데이터 프로세싱 레인들; 및 복수의 태스크 명령 메모리들 ― 복수의 태스크 명령 메모리들 중 각각의 태스크 명령 메모리는 순차적으로 배열되고 명령 라우터를 통해 복수의 타일들로부터 하나 이상의 타일들에 결합됨 ―을 포함할 수 있다. 태스크 명령 메모리는 다운스트림 시퀀스로 배열될 수 있다. 각각의 타일은 타일 액세스 코어를 포함할 수 있고, 각각의 타일에 포함된 프리페치 유닛은 타일 액세스 코어 내에 포함될 수 있다. 각각의 타일은 타일 실행 코어를 포함할 수 있고, 각각의 타일에 포함된 프리페치 유닛은 타일 실행 코어 내에 포함될 수 있다. 하드웨어 회로는 명령 브로드캐스트 버스와 명령 요청 버스를 포함할 수 있다. 명령 브로드캐스트 버스는 독립적인 데이터 레인들을 포함할 수 있고, 여기서 독립적인 데이터 레인들의 개수는 태스크 명령 메모리들의 개수에 대응할 수 있다.[0272] Aspects of the disclosed technology include hardware circuitry. The hardware circuit may include a plurality of tiles, each tile configured to operate in parallel with other tiles within the plurality of tiles, each tile of the plurality of tiles comprising a processing core; prefetch unit; and command buffer -; a plurality of data processing lanes configured to stream respective data from an upstream input to a downstream destination; and a plurality of task instruction memories, each of which is sequentially arranged and coupled to one or more tiles from a plurality of tiles through a command router. Task instruction memories may be arranged in a downstream sequence. Each tile may include a tile access core, and a prefetch unit included in each tile may be included in the tile access core. Each tile may include a tile execution core, and a prefetch unit included in each tile may be included in the tile execution core. The hardware circuit may include a command broadcast bus and a command request bus. The command broadcast bus may include independent data lanes, where the number of independent data lanes may correspond to the number of task command memories.
[0273] 명령 요청 버스는 독립적인 데이터 레인들을 포함할 수 있고, 여기서 독립 데이터 레인들의 개수는 태스크 명령 메모리들의 개수에 대응한다. 태스크 명령 메모리에 의해 수신된 명령들은 명령 브로드캐스트 버스에 링크된 모든 타일들에 브로드캐스트될 수 있다. 프리페치는 프리페치 창 동안 적어도 하나의 태스크 명령 메모리에 요청하도록 구성될 수 있다. 프리페치 창은 소프트웨어에 의해 선택하거나 조정할 수 있다. 하드웨어 회로는 명령 라우터를 더 포함할 수 있다. 명령 라우터는 프리페치 판독 요청을 포함한 요청을 중재하도록 구성된 라운드 로빈 중재자를 포함할 수 있다. 명령 버퍼는 타일 액세스 코어 또는 타일 실행 코어에 대한 명령들을 저장할 수 있다. 하드웨어 회로는 단일 명령 다중 데이터 프로세서로 구성될 수 있다. 하드웨어 회로는 다중 명령 다중 데이터 프로세서로 구성될 수 있다. 하드웨어 회로는 태스크 명령 메모리 액세스 버스를 포함할 수 있다. 태스크 명령 메모리 액세스 버스는 판독 요청 버스, 판독 응답 버스, 쓰기 요청 버스, 쓰기 응답 버스를 포함할 수 있다.[0273] The command request bus may include independent data lanes, where the number of independent data lanes corresponds to the number of task instruction memories. Commands received by the task instruction memory may be broadcast to all tiles linked to the command broadcast bus. Prefetching may be configured to request at least one task instruction memory during a prefetch window. The prefetch window can be selected or adjusted by software. The hardware circuit may further include a command router. The command router may include a round robin arbiter configured to arbitrate requests, including prefetch read requests. The instruction buffer may store instructions for the tile access core or tile execution core. The hardware circuit may consist of a single instruction multiple data processor. The hardware circuit may consist of a multi-instruction multi-data processor. The hardware circuit may include a task instruction memory access bus. The task instruction memory access bus may include a read request bus, a read response bus, a write request bus, and a write response bus.
[0274] 개시된 기술의 양태들은 TPU를 포함한다. TPU는 하드웨어 회로 및 하드웨어 회로에 결합된 명령 브로드캐스트 버스를 포함할 수 있고, 명령 브로드캐스트 버스는 명령들을 하드웨어 회로에 푸시하도록 구성된다. 하드웨어 회로는 복수의 타일들 ― 각각의 타일은 복수의 타일들 내의 다른 타일들과 병렬로 오퍼레이팅하도록 구성되고, 복수의 타일들의 각각의 타일은 프로세싱 코어; 프리페치 유닛; 및 명령 버퍼를 포함할 수 있음 ―; 각자의 데이터를 업스트림 입력으로부터 다운스트림 목적지로 스트리밍하도록 구성된 복수의 데이터 프로세싱 레인들; 및 복수의 태스크 명령 메모리들 ― 복수의 태스크 명령 메모리들 중 각각의 태스크 명령 메모리는 순차적으로 배열되고 명령 라우터를 통해 복수의 타일들로부터 하나 이상의 타일들에 결합됨 ―을 포함할 수 있다. TPU는 하드웨어 회로에 결합된 명령 요청 버스를 더 포함할 수 있고 명령 요청 버스는 명령들에 대한 요청들을 수신하도록 구성될 수 있다.[0274] Aspects of the disclosed technology include TPU. The TPU may include hardware circuitry and a command broadcast bus coupled to the hardware circuitry, where the command broadcast bus is configured to push commands to the hardware circuitry. The hardware circuit may include a plurality of tiles, each tile configured to operate in parallel with other tiles within the plurality of tiles, each tile of the plurality of tiles comprising a processing core; prefetch unit; and may contain command buffers -; a plurality of data processing lanes configured to stream respective data from an upstream input to a downstream destination; and a plurality of task instruction memories, each of which is sequentially arranged and coupled to one or more tiles from a plurality of tiles through a command router. The TPU may further include a command request bus coupled to hardware circuitry and the command request bus may be configured to receive requests for commands.
[0275] 개시된 기술의 양태들은 단일 명령 다중 데이터(SIMD) 프로세싱 유닛에 의해 명령들을 프리페치하거나 제공하는 방법을 포함한다. 방법은 명령들에 대한 요청들을 SIMD 프로세싱 유닛의 복수의 타일들로부터 수신하는 단계; 제1 요청들의 세트를 생성하기 위해 동일한 명령들에 대한 요청들을 중복 제거하기 위한 명령들에 대한 요청들을 필터링하는 단계; 제1 요청들의 세트에 응답하여 명령들의 세트를 생성하는 단계; 명령들의 세트를 컴퓨팅 유닛으로부터 SIMD 프로세싱 유닛의 태스크 명령 메모리에 제공하는 단계; 태스크 명령 메모리에 명령들의 세트를 저장하는 단계; 및 명령들의 세트로부터의 명령을 명령 라우터를 통해 프리페치 유닛에 의해 액세스하는 단계를 포함할 수 있다. SIMD 프로세싱 유닛은 복수의 타일들을 포함할 수 있고, 각각의 타일은 복수의 타일들 내의 다른 타일들과 병렬로 오퍼레이팅하도록 구성되고, 복수의 타일들의 각각의 타일은, 프로세싱 코어; 프리페치 유닛; 및 명령 버퍼를 포함한다. 수신하는 단계는 제1 프로세싱 클록 사이클에서 발생할 수 있고 제공하는 단계는 제2 프로세싱 클록 사이클에서 발생한다. 제1 프로세싱 클록 사이클은 제2 프로세싱 클록 사이클 이전에 발생할 수 있다. [0275] Aspects of the disclosed technology include a method for prefetching or providing instructions by a single instruction multiple data (SIMD) processing unit. The method includes receiving requests for instructions from a plurality of tiles of a SIMD processing unit; filtering requests for instructions to deduplicate requests for identical instructions to create a first set of requests; generating a set of instructions in response to the first set of requests; providing a set of instructions from a computing unit to a task instruction memory of the SIMD processing unit; storing a set of instructions in a task instruction memory; and accessing an instruction from the set of instructions by the prefetch unit through an instruction router. A SIMD processing unit may include a plurality of tiles, each tile configured to operate in parallel with other tiles within the plurality of tiles, each tile of the plurality of tiles comprising: a processing core; prefetch unit; and a command buffer. The receiving step may occur in a first processing clock cycle and the providing step may occur in a second processing clock cycle. The first processing clock cycle may occur before the second processing clock cycle.
[0276] "스트림 전달들"로 지칭되는 오프-코어 메모리와 코어-로컬 메모리 사이의 비동기 데이터 이동을 위한 하드웨어/소프트웨어 인터페이스, 및 스트림 순서화 모델이 본원에 일반적으로 개시된다. 스트림 전달들은 소프트웨어가 일반적인 데이터 이동 패턴들, 특히 희소 워크로드들에서 볼 수 있는 패턴들을 보다 효율적으로 표현하게 한다. 스트림에 속한 스트림 명령들은 순서대로 프로세싱된다. 간접 스트림 명령들의 경우, 오프셋 목록의 오프셋 엘리먼트들은 순서대로 프로세싱된다. 동기화 플래그는 스트림의 단조로운 증분 진행을 나타내기 위해 업데이트된다.[0276] Disclosed generally herein is a hardware/software interface for asynchronous data movement between off-core memory and core-local memory, referred to as “stream transfers”, and a stream ordering model. Stream deliveries allow software to more efficiently represent common data movement patterns, especially those seen in sparse workloads. Stream instructions belonging to a stream are processed in order. For indirect stream instructions, offset elements in the offset list are processed in order. The synchronization flag is updated to indicate monotonous incremental progress of the stream.
[0277] 본 개시내용의 양태는 하나 이상의 프로세서들을 사용하여, 오프-코어 메모리와 코어-로컬 메모리 사이에서 전달되는 데이터의 진행을 식별하는 단계; 하나 이상의 프로세서들을 사용하여, 코어-로컬 메모리가 데이터의 소스일 때 코어-로컬 메모리로부터의 판독들을 식별하는 단계 ― 판독들은 순서대로 소스에 발행되고 순서 없이 소스에 의해 서비스됨 ―; 하나 이상의 프로세서들을 사용하여, 코어-로컬 메모리가 데이터의 목적지일 때 코어-로컬 메모리에 대한 쓰기들을 식별하는 단계 ― 쓰기들은 순서대로 목적지에 발행되고 순서 없이 목적지에 의해 커밋됨 ―; 및 하나 이상의 프로세서들을 사용하여, 오프-코어 메모리가 데이터의 소스일 때 오프-코어 메모리로부터의 판독들 및 오프-코어 메모리가 데이터의 목적지일 때 오프-코어 메모리에 대한 쓰기들을 위해 간접 스캐터/수집 메모리 액세스들에 기반하여 오프-코어 메모리에 액세스하는 단계를 포함하는 방법을 제공한다.[0277] An aspect of the disclosure includes identifying, using one or more processors, the progression of data being transferred between an off-core memory and a core-local memory; Using one or more processors, identifying reads from core-local memory when the core-local memory is the source of data, wherein reads are issued to the source in order and are serviced by the source out of order; Using one or more processors, identifying writes to core-local memory when core-local memory is the destination of the data—writes are issued to the destination in order and committed by the destination out of order; and indirect scatter/write using one or more processors for reads from off-core memory when the off-core memory is the source of data and writes to off-core memory when the off-core memory is the destination of data. A method is provided including accessing off-core memory based on aggregate memory accesses.
[0278] 예에서, 전달되는 데이터의 진행을 식별하는 단계는 코어-로컬 동기화 플래그를 사용하는 단계를 더 포함한다. 다른 예에서, 방법은 하나 이상의 프로세서들을 사용하여, 스칼라 펜스 명령들에 기반하여 장벽에 대한 메모리 액세스들을 선택하는 단계를 더 포함한다. 또 다른 예에서, 간접 스캐터/수집 메모리 액세스에 기반하여 오프-코어 메모리에 액세스하는 단계는 레지스터 파일 또는 코어-로컬 메모리로부터 간접 어드레스들을 소싱하는 단계를 더 포함한다. 또 다른 예에서, 방법은 하나 이상의 프로세서들을 사용하여, 코어-로컬 메모리에 순환 버퍼링하는 단계를 더 포함한다.[0278] In an example, identifying the progression of data being transferred further includes using a core-local synchronization flag. In another example, the method further includes selecting memory accesses to the barrier based on scalar fence instructions, using one or more processors. In another example, accessing off-core memory based on indirect scatter/gather memory access further includes sourcing indirect addresses from a register file or core-local memory. In another example, the method further includes circular buffering in core-local memory, using one or more processors.
[0279] 또 다른 예에서, 방법은 하나 이상의 프로세서들을 사용하여, 데이터 전달에 대한 단조로운 증분 진행을 나타내기 위해 코어-로컬 동기화 플래그를 업데이트하는 단계를 더 포함한다. 또 다른 예에서, 방법은 하나 이상의 프로세서들을 사용하여, 코어-로컬 메모리로부터의 모든 판독들이 발행될 때 데이터 전달을 종료하는 단계를 더 포함한다. 또 다른 예에서, 방법은 하나 이상의 프로세서들을 사용하여, 코어-로컬 메모리에 대한 모든 쓰기들이 커밋되었을 때 데이터 전달을 종료하는 단계를 더 포함한다.[0279] In another example, the method further includes updating a core-local synchronization flag to indicate monotonic incremental progress for data transfer, using one or more processors. In another example, the method further includes terminating data transfer when all reads from core-local memory have been issued, using one or more processors. In another example, the method further includes terminating data transfer when all writes to core-local memory have committed, using one or more processors.
[0280] 본 개시내용의 다른 양태는 하나 이상의 프로세서들; 및 하나 이상의 프로세서들에 결합되고 명령들을 저장하는 하나 이상의 저장 디바이스들을 포함하는 시스템을 제공하고, 명령들은, 하나 이상의 프로세서들에 의해 실행될 때, 하나 이상의 프로세서들로 하여금 오프-코어 메모리와 코어-로컬 메모리 사이에서 데이터를 전달하기 위한 오퍼레이션들을 수행하게 한다. 오퍼레이션들은 오프-코어 메모리와 코어-로컬 메모리 사이에 전달되는 데이터의 진행을 식별하는 것; 코어-로컬 메모리가 데이터의 소스일 때 코어-로컬 메모리로부터의 판독들을 식별하는 것 ― 판독들은 순서대로 소스에 발행되고 순서 없이 소스에 의해 서비스됨 ―; 코어-로컬 메모리가 데이터의 목적지일 때 코어-로컬 메모리에 대한 쓰기들을 식별하는 것 ― 쓰기들은 순서대로 목적지에 발행되고 순서 없이 목적지에 의해 커밋됨 ―; 및 오프-코어 메모리가 데이터의 소스일 때 오프-코어 메모리로부터의 판독들 및 오프-코어 메모리가 데이터의 목적지일 때 오프-코어 메모리에 대한 쓰기들을 위해 간접 스캐터/수집 메모리 액세스들에 기반하여 오프-코어 메모리에 액세스하는 것을 포함한다.[0280] Another aspect of the disclosure includes one or more processors; and one or more storage devices coupled to one or more processors and storing instructions, which, when executed by the one or more processors, cause the one or more processors to access off-core memory and core-local memory. It performs operations to transfer data between memories. Operations identify the progression of data being transferred between off-core memory and core-local memory; Identifying reads from core-local memory when core-local memory is the source of data—reads are issued to the source in order and are serviced by the source out of order; Identifying writes to core-local memory when core-local memory is the destination for data—writes are issued to the destination in order and committed by the destination out of order; and based on indirect scatter/gather memory accesses for reads from off-core memory when the off-core memory is the source of data and writes to off-core memory when the off-core memory is the destination of data. Includes accessing off-core memory.
[0281] 예에서, 전달되는 데이터의 진행을 식별하는 것은 코어-로컬 동기화 플래그를 사용하는 것을 더 포함한다. 다른 예에서, 오퍼레이션들은 스칼라 펜스 명령들에 기반하여 장벽에 대한 메모리 액세스들을 선택하는 것을 더 포함한다. 또 다른 예에서, 간접 스캐터/수집 메모리 액세스에 기반하여 오프-코어 메모리에 액세스하는 것은 레지스터 파일 또는 코어-로컬 메모리로부터 간접 어드레스들을 소싱하는 것을 더 포함한다. 또 다른 예에서, 오퍼레이션들은 코어-로컬 메모리에 순환 버퍼링하는 것을 더 포함한다.[0281] In an example, identifying the progression of data being transferred further includes using a core-local synchronization flag. In another example, the operations further include selecting memory accesses to the barrier based on scalar fence instructions. In another example, accessing off-core memory based on indirect scatter/gather memory access further includes sourcing indirect addresses from a register file or core-local memory. In another example, the operations further include circular buffering in core-local memory.
[0282] 또 다른 예에서, 오퍼레이션들은 데이터 전달에 대한 단조로운 증분 진행을 나타내기 위해 코어-로컬 동기화 플래그를 업데이트하는 것을 더 포함한다. 또 다른 예에서, 오퍼레이션들은 코어-로컬 메모리로부터의 모든 판독들이 발행될 때 데이터 전달을 종료하는 것을 더 포함한다. 또 다른 예에서, 오퍼레이션들은 코어-로컬 메모리에 대한 모든 쓰기들이 커밋되었을 때 데이터 전달을 종료하는 것을 더 포함한다.[0282] In another example, the operations further include updating a core-local synchronization flag to indicate monotonic incremental progress for data transfer. In another example, the operations further include terminating data transfer when all reads from core-local memory have been issued. In another example, the operations further include terminating data transfer when all writes to core-local memory have committed.
[0283] 본 개시내용의 또 다른 양태는 명령들을 저장하는 비일시적 컴퓨터 판독가능 저장 매체를 제공하고, 명령들은, 하나 이상의 프로세서들에 의해 실행될 때, 하나 이상의 프로세서들로 하여금 오프-코어 메모리와 코어-로컬 메모리 사이에서 데이터를 전달하기 위한 오퍼레이션들을 수행하게 한다. 오퍼레이션들은 오프-코어 메모리와 코어-로컬 메모리 사이에 전달되는 데이터의 진행을 식별하는 것; 코어-로컬 메모리가 데이터의 소스일 때 코어-로컬 메모리로부터의 판독들을 식별하는 것 ― 판독들은 순서대로 소스에 발행되고 순서 없이 소스에 의해 서비스됨 ―; 코어-로컬 메모리가 데이터의 목적지일 때 코어-로컬 메모리에 대한 쓰기들을 식별하는 것 ― 쓰기들은 순서대로 목적지에 발행되고 순서 없이 목적지에 의해 커밋됨 ―; 및 오프-코어 메모리가 데이터의 소스일 때 오프-코어 메모리로부터의 판독들 및 오프-코어 메모리가 데이터의 목적지일 때 오프-코어 메모리에 대한 쓰기들을 위해 간접 스캐터/수집 메모리 액세스들에 기반하여 오프-코어 메모리에 액세스하는 것을 포함한다.[0283] Another aspect of the disclosure provides a non-transitory computer-readable storage medium storing instructions, which, when executed by one or more processors, cause the one or more processors to store off-core memory and core memory. -Performs operations to transfer data between local memories. Operations identify the progression of data being transferred between off-core memory and core-local memory; Identifying reads from core-local memory when core-local memory is the source of data—reads are issued to the source in order and are serviced by the source out of order; Identifying writes to core-local memory when core-local memory is the destination for data—writes are issued to the destination in order and committed by the destination out of order; and based on indirect scatter/gather memory accesses for reads from off-core memory when the off-core memory is the source of data and writes to off-core memory when the off-core memory is the destination of data. Includes accessing off-core memory.
[0284] 예에서, 간접 스캐터/수집 메모리 액세스에 기반하여 오프-코어 메모리에 액세스하는 것은 레지스터 파일 또는 코어-로컬 메모리로부터 간접 어드레스들을 소싱하는 것을 더 포함한다. 다른 예에서, 오퍼레이션들은 코어-로컬 메모리에 순환 버퍼링하는 것을 더 포함한다. 또 다른 예에서, 오퍼레이션들은 데이터 전달에 대한 단조로운 증분 진행을 나타내기 위해 동기화 플래그를 업데이트하는 것을 더 포함한다.[0284] In an example, accessing off-core memory based on an indirect scatter/gather memory access further includes sourcing indirect addresses from a register file or core-local memory. In another example, operations further include circular buffering in core-local memory. In another example, the operations further include updating a synchronization flag to indicate monotonic incremental progress for data transfer.
[0285] 본 개시내용의 양태들은 프로세서의 다수의 데이터 프로세싱 레인들에 걸쳐 단일 명령, 다중 데이터(SIMD) 데이터 의존 오퍼레이션들을 수행하기 위한 교차 레인 프로세싱 유닛(XPU)에 관한 것이다. 각각의 데이터 의존 오퍼레이션을 위해 오퍼레이션별 회로들을 물리적으로 제작하는 대신, XPU는 XPU의 적층형 네트워크로서 배열된 크로스바들 및 개별 오퍼레이션들을 수행하도록 프로세싱 셀을 구성하는 입력 신호들에 응답하여 상이한 오퍼레이션들을 수행하도록 구성될 수 있다. 각각의 프로세싱 셀은 다수의 데이터 프로세싱 레인들에서 데이터를 수신하고 프로세싱할 수 있다. 본 개시내용의 양태들은 벡터 정렬을 수행하도록 XPU를 구성하는 것과 동시에, 또한 정렬을 위해 수신된 입력 벡터들에서 중복 엘리먼트들의 중복 카운트를 컴퓨팅하는 것을 포함하여, 정렬 및 중복 카운팅을 위해 XPU를 별도로 구성할 필요성을 제거한다. XPU는 하드웨어 회로의 일부로 구현되어, 희소 벡터들 또는 행렬들과 같은 희소 데이터 구조들의 프로세싱을 가속화하여 조밀 행렬들과 같은 조밀 데이터 구조들의 컴퓨팅을 보완할 수 있다.[0285] Aspects of the present disclosure relate to a cross-lane processing unit (XPU) for performing single instruction, multiple data (SIMD) data dependent operations across multiple data processing lanes of a processor. Instead of physically fabricating operation-specific circuits for each data-dependent operation, the It can be configured. Each processing cell can receive and process data in multiple data processing lanes. Aspects of the disclosure include configuring an XPU to perform vector sorting while also separately configuring the eliminates the need to The XPU may be implemented as part of hardware circuitry to accelerate the processing of sparse data structures, such as sparse vectors or matrices, to complement computing of dense data structures, such as dense matrices.
[0286] 본 개시내용의 양태들은 각각의 스테이지가 크로스바 및 2 개 이상의 셀들을 포함하는 복수의 스테이지들을 포함하는 하드웨어 회로; 복수의 스테이지들의 복수의 셀들과 복수의 크로스바들을 통해 업스트림 입력으로부터 다운스트림 목적지로 각자의 데이터를 스트리밍하는 복수의 데이터 프로세싱 레인들을 포함하고; 하드웨어 회로는: 복수의 데이터 프로세싱 레인들을 따라 업스트림 입력으로부터 입력 데이터, 및 제1 오퍼레이션을 수행하기 위한 제1 명령을 수신하고; 제1 명령의 수신에 응답하여, 각각의 스테이지에 대해: 각자의 제2 명령을 스테이지의 각자의 프로세싱 셀들에 전송하고 ― 각각의 셀은 각자의 데이터 프로세싱 레인으로부터 입력의 수신에 응답하여 각자의 제2 오퍼레이션을 수행하도록 구성됨 ―, 그리고 각자의 제3 명령을 스테이지에 대한 각자의 크로스바에 전송하고 ― 크로스바는 스테이지의 각각의 셀로부터의 출력을 복수의 데이터 프로세싱 레인들을 따라 다음 스테이지의 셀들로 치환하도록 구성됨 ―; 그리고 각자의 제2 오퍼레이션을 수행하도록 구성된 복수의 데이터 프로세싱 레인들 및 복수의 셀들을 따라 수신된 입력 데이터를 프로세싱함으로써 제1 오퍼레이션을 수행하도록 구성된다. [0286] Aspects of the present disclosure include a hardware circuit comprising a plurality of stages, each stage comprising a crossbar and two or more cells; comprising a plurality of data processing lanes streaming respective data from an upstream input to a downstream destination via a plurality of cells in a plurality of stages and a plurality of crossbars; The hardware circuitry: receives input data from an upstream input along a plurality of data processing lanes, and a first instruction to perform a first operation; In response to receipt of the first command, for each stage: transmit a respective second command to the respective processing cells of the stage, each cell in response to receipt of input from its respective data processing lane, 2 configured to perform the operation - and transmit respective third instructions to respective crossbars for the stage - such that the crossbar displaces the output from each cell of the stage to the cells of the next stage along the plurality of data processing lanes. configured ―; and configured to perform the first operation by processing input data received along a plurality of data processing lanes and a plurality of cells configured to perform their respective second operations.
[0287] 본 개시내용의 양태들은, 각각의 스테이지가 크로스바 및 2 개 이상의 셀들을 포함하는 복수의 스테이지들을 포함하는 하드웨어 회로; 및 복수의 스테이지들의 복수의 셀들과 복수의 크로스바들을 통해 업스트림 입력으로부터 다운스트림 목적지로 각자의 데이터를 스트리밍하는 복수의 데이터 프로세싱 레인들을 포함하는 시스템을 포함하고, 하드웨어 회로는 복수의 데이터 프로세싱 레인들을 따라 업스트림 입력으로부터 입력 데이터, 및 제1 오퍼레이션을 수행하기 위한 제1 명령을 수신하고; 제1 명령의 수신에 응답하여, 각각의 스테이지에 대해: 각자의 제2 명령을 스테이지의 각자의 프로세싱 셀들에 전송하고 ― 각각의 셀은 각자의 데이터 프로세싱 레인으로부터 입력의 수신에 응답하여 각자의 제2 오퍼레이션을 수행하도록 구성됨 ―; 그리고 각자의 제3 명령을 스테이지에 대한 각자의 크로스바에 전송하고 ― 크로스바는 스테이지의 각각의 셀로부터의 출력을 복수의 데이터 프로세싱 레인들을 따라 다음 스테이지의 셀들로 치환하도록 구성됨 ―; 그리고 각자의 제2 오퍼레이션을 수행하도록 구성된 복수의 데이터 프로세싱 레인들 및 복수의 셀들을 따라 수신된 입력 데이터를 프로세싱함으로써 제1 오퍼레이션을 수행하도록 구성된다.[0287] Aspects of the present disclosure include a hardware circuit comprising a plurality of stages, each stage comprising a crossbar and two or more cells; and a plurality of data processing lanes streaming respective data from an upstream input to a downstream destination via a plurality of cells in a plurality of stages and a plurality of crossbars, wherein the hardware circuitry comprises a plurality of data processing lanes along the plurality of data processing lanes. receive input data from an upstream input and a first instruction to perform a first operation; In response to receipt of the first command, for each stage: transmit a respective second command to the respective processing cells of the stage, each cell in response to receipt of input from its respective data processing lane, 2 Configured to perform operations ―; and transmitting a respective third command to a respective crossbar for the stage, the crossbar being configured to displace the output from each cell of the stage to cells of the next stage along the plurality of data processing lanes; and configured to perform the first operation by processing input data received along a plurality of data processing lanes and a plurality of cells configured to perform their respective second operations.
[0288] 본 개시내용의 양태들은: 각각의 스테이지가 크로스바 및 2 개 이상의 셀들을 포함하는 복수의 스테이지들을 포함하는 하드웨어 회로 및 복수의 스테이지들의 복수의 셀들과 복수의 크로스바들을 통해 업스트림 입력으로부터 다운스트림 목적지로 각자의 데이터를 스트리밍하는 복수의 데이터 프로세싱 레인들에 의해, 복수의 데이터 프로세싱 레인들을 따라 업스트림 입력으로부터 입력 데이터, 및 제1 오퍼레이션을 수행하기 위한 제1 명령을 수신하는 단계; 제1 명령의 수신에 응답하여, 각각의 스테이지에 대해, 하드웨어 회로에 의해, 각자의 제2 명령을 스테이지의 각자의 프로세싱 셀들에 전송하고 ― 각각의 셀은 각자의 데이터 프로세싱 레인으로부터 입력의 수신에 응답하여 각자의 제2 오퍼레이션을 수행하도록 구성됨 ―, 그리고 하드웨어 회로에 의해, 각자의 제3 명령을 스테이지에 대한 각자의 크로스바에 전송하는 단계 ― 크로스바는 스테이지의 각각의 셀로부터의 출력을 복수의 데이터 프로세싱 레인들을 따라 다음 스테이지의 셀들로 치환하도록 구성됨 ―; 그리고 하드웨어 회로에 의해, 각자의 제2 오퍼레이션을 수행하도록 구성된 복수의 데이터 프로세싱 레인들 및 복수의 셀들을 따라 수신된 입력 데이터를 프로세싱함으로써 제1 오퍼레이션을 수행하는 단계를 포함하는 컴퓨터 구현 방법을 포함한다.[0288] Aspects of the present disclosure include: a hardware circuit comprising a plurality of stages, each stage comprising a crossbar and two or more cells, and a downstream input from an upstream input via a plurality of cells of the plurality of stages and a plurality of crossbars. Receiving input data from an upstream input along a plurality of data processing lanes, and a first instruction to perform a first operation, by the plurality of data processing lanes streaming the respective data to a destination; In response to receipt of the first command, for each stage, by hardware circuitry, transmit a respective second command to the respective processing cells of the stage, each cell being responsive to the receipt of input from its respective data processing lane. in response configured to perform the respective second operation, and transmitting, by hardware circuitry, the respective third command to the respective crossbar for the stage, wherein the crossbar transmits the output from each cell of the stage to a plurality of data configured to replace cells of the next stage along the processing lanes; and performing, by hardware circuitry, the first operation by processing received input data along a plurality of cells and a plurality of data processing lanes configured to perform the respective second operation. .
[0289] 본 개시내용의 양태들은 다음 특징들 중 하나 이상을 포함할 수 있다. 일부 예들에서, 본 개시내용의 양태들은 다음 특징들 모두를 조합하여 포함한다.[0289] Aspects of the present disclosure may include one or more of the following features. In some examples, aspects of the disclosure include combinations of all of the following features.
[0290] 각각의 셀은 셀을 통과하는 각자의 데이터 프로세싱 레인으로부터 각자의 제1 입력 피연산자를 수신하고, 셀 업스트림 스테이지의 각자의 크로스바로부터 각자의 제2 입력 피연산자를 수신하도록 구성된다.[0290] Each cell is configured to receive a respective first input operand from a respective data processing lane passing through the cell and to receive a respective second input operand from a respective crossbar of a cell upstream stage.
[0291] 복수의 데이터 프로세싱 레인들의 데이터의 다운스트림 목적지는 벡터 프로세싱 유닛이고, 벡터 프로세싱 유닛은 하드웨어 회로의 출력 데이터에 대해 단일 명령, 다중 데이터 벡터 오퍼레이션들을 수행하도록 구성된다.[0291] The downstream destination of the data of the plurality of data processing lanes is a vector processing unit, and the vector processing unit is configured to perform single instruction, multiple data vector operations on output data of the hardware circuit.
[0292] 셀들 각각은 수신된 하나 이상의 명령들에 응답하여 복수의 미리 결정된 기본 오퍼레이션들 중 하나 이상을 수행하도록 구성되고; 하드웨어 회로는 복수의 제어 셀들을 더 포함하고, 각자의 제2 명령을 각자의 프로세싱 셀들에 전송할 때, 하드웨어 회로는 각각의 제어 셀에 의해, 제1 명령에 의해 지정된 제1 오퍼레이션에 기반하여 각자의 제어 신호를 생성하여 각각의 프로세싱 셀에 전송하도록 구성된다.[0292] Each of the cells is configured to perform one or more of a plurality of predetermined basic operations in response to one or more commands received; The hardware circuit further includes a plurality of control cells, and when transmitting the respective second commands to the respective processing cells, the hardware circuit is configured to perform the respective processing cells based on the first operation specified by the first command by each control cell. It is configured to generate a control signal and transmit it to each processing cell.
[0293] 각각의 제어 셀에 의해, 각자의 제어 신호를 생성하고 전송할 때, 하드웨어 회로는 각각의 프로세싱 셀이, 프로세싱 셀이 있는 스테이지 중 적어도 하나와 프로세싱 셀을 통과하는 데이터 프로세싱 레인에 기반하여, 각자의 산술, 비교 및 바이패스 오퍼레이션 중 하나를 수행하게 하기 위한 각자의 제어 신호를 생성하도록 구성된다.[0293] When generating and transmitting, by each control cell, a respective control signal, the hardware circuitry is configured to: It is configured to generate respective control signals to perform one of the respective arithmetic, comparison and bypass operations.
[0294] 복수의 셀들과 복수의 크로스바들은 복수의 스테이지들과 복수의 데이터 프로세싱 레인들에 걸쳐 연결된 셀들의 프로세싱 네트워크를 형성하고, 연결된 셀들의 프로세싱 네트워크는 입력 데이터를 수신하고 입력 데이터에 대한 제1 오퍼레이션을 수행하는 것에 따라 각자의 출력 데이터를 생성하도록 구성된다.[0294] The plurality of cells and the plurality of crossbars form a processing network of cells connected across a plurality of stages and a plurality of data processing lanes, and the processing network of connected cells receives input data and provides a first processing response to the input data. It is configured to generate its own output data according to the operation performed.
[0295] 연결된 셀들의 프로세싱 네트워크는 결합된 벡터 정렬 및 중복 카운트 오퍼레이션을 수행하도록 구성되고, 결합된 오퍼레이션은 프로세싱 네트워크에 의해, 엘리먼트들의 입력 벡터를 수신하는 것; 및 프로세싱 네트워크에 의해 출력으로서, 정렬된 출력 벡터 및 입력 벡터의 중복 엘리먼트들의 카운트들을 지정하는 데이터를 생성하는 것을 포함한다. 입력 데이터는 희소 벡터 데이터를 포함하고, 각자의 제2 및 제3 명령들을 전송한 후, 하드웨어 회로는 벡터 스캔들, 벡터 합산, 벡터 정렬 또는 벡터 중복 카운트 중 하나를 수행하도록 구성된다.[0295] The processing network of connected cells is configured to perform a combined vector sort and duplicate count operation, the combined operation comprising: receiving, by the processing network, an input vector of elements; and generating, as output by the processing network, data specifying counts of duplicate elements of the sorted output vector and the input vector. The input data includes sparse vector data, and after sending the respective second and third instructions, the hardware circuitry is configured to perform one of vector scan, vector sum, vector sort or vector duplicate count.
[0296] 달리 언급되지 않는 한, 전술한 대체 예들은 상호 배타적이지 않고, 고유한 이점들을 달성하기 위해 다양한 조합들로 구현될 수 있다. 위에서 논의된 특징들의 이들 및 다른 변형들 및 조합들이 청구범위에 의해 정의된 청구범위를 벗어나지 않고 활용될 수 있기 때문에, 예들의 전술한 설명은 청구범위에 의해 정의된 청구범위를 제한하는 방식이 아니라 예시의 방식으로 취해져야 한다. 게다가, "~와 같은", "포함하는" 등으로 표현된 절들뿐만 아니라, 본원에 설명된 예들의 제공은 청구범위의 주제를 특정 예들로 제한하는 것으로 해석되어서는 안 되고; 오히려 예들은 많은 가능한 구현들 중 하나만 예시하기 위한 것이다. 추가로, 상이한 도면들에서 동일한 참조번호들은 동일하거나 유사한 엘리먼트들을 식별할 수 있다.[0296] Unless otherwise noted, the above-described alternatives are not mutually exclusive and may be implemented in various combinations to achieve unique advantages. The foregoing description of examples is not intended to limit the scope of the claims, since these and other variations and combinations of the features discussed above may be utilized without departing from the scope defined by the claims. It should be taken by way of example. Moreover, the provision of examples described herein, as well as clauses expressed as “such as,” “comprising,” etc., should not be construed as limiting the subject matter of the claims to those specific examples; Rather, the examples are intended to illustrate only one of many possible implementations. Additionally, the same reference numbers in different drawings may identify the same or similar elements.
Claims (24)
복수의 타일들을 포함하고, 상기 복수의 타일들 각각은,
벡터 코어; 및
공유된 소프트웨어 제어 스크래치패드 메모리(scratchpad memory)의 슬라이스를 포함하고,
상기 프로세서는,
상기 복수의 타일들에 태스크들을 디스패치(dispatch)하도록 구성된 스칼라 코어(scalar core); 및
상기 복수의 타일들 및 상기 스칼라 코어에 결합된 메모리를 더 포함하는, 프로세서.As a processor,
Includes a plurality of tiles, each of the plurality of tiles,
vector core; and
Contains a slice of shared software-controlled scratchpad memory,
The processor,
a scalar core configured to dispatch tasks to the plurality of tiles; and
The processor further comprising a memory coupled to the plurality of tiles and the scalar core.
각각의 타일은 독립적인 컴퓨팅들을 실행하도록 구성되는, 프로세서.According to claim 1,
A processor, where each tile is configured to perform independent computations.
상기 복수의 타일들 각각의 상기 벡터 코어는 복수의 SIMD(single instruction, multiple data: 단일 명령, 다중 데이터) 프로세싱 레인들을 포함하는, 프로세서.According to claim 1,
The vector core of each of the plurality of tiles includes a plurality of single instruction, multiple data (SIMD) processing lanes.
상기 복수의 타일들 중 다수의 타일들은 상기 메인 메모리에 병렬로 메모리 요청들을 발행하는, 프로세서.According to claim 1,
wherein multiple tiles of the plurality of tiles issue memory requests in parallel to the main memory.
상기 복수의 타일들 각각의 상기 벡터 코어는 데이터 의존 어드레스 스트림들을 임의의 레벨의 메모리 계층에 생성하도록 구성되는, 프로세서.According to claim 1,
wherein the vector core of each of the plurality of tiles is configured to generate data dependent address streams at any level of a memory hierarchy.
각각의 데이터 의존 어드레스 스트림은 어드레스들의 시퀀스에 대응하고, 상기 시퀀스의 어드레스들의 길이와 지정 값들은 데이터 의존적이며 런타임(runtime)에만 알려지는, 프로세서.According to clause 5,
A processor, wherein each data dependent address stream corresponds to a sequence of addresses, wherein the length and designation values of the addresses of the sequence are data dependent and known only at runtime.
상기 복수의 타일들 각각의 상기 벡터 코어는 마이크로아키텍처에 대한 상기 데이터 의존 어드레스 스트림들의 성능 서비스를 분리하면서 상기 데이터 의존 어드레스 스트림들을 표현하도록 구성되는, 프로세서.According to clause 5,
wherein the vector core of each of the plurality of tiles is configured to represent the data dependent address streams while decoupling performance services of the data dependent address streams for a microarchitecture.
상기 마이크로아키텍처는 상기 데이터 의존 어드레스 스트림들의 성능 서비스를 위한 스캐터-수집 엔진(scatter-gather engine)을 포함하는, 프로세서.According to clause 7,
The processor of claim 1, wherein the microarchitecture includes a scatter-gather engine for performance servicing of the data dependent address streams.
상기 데이터 의존 어드레스 스트림들은 다중 어드레싱 모드들, 런타임 구성가능 전달 크기 및 원자 산술 업데이트들을 사용한 간접 메모리 액세스를 포함하는, 프로세서.According to clause 7,
The processor of claim 1, wherein the data dependent address streams include multiple addressing modes, runtime configurable transfer size, and indirect memory access using atomic arithmetic updates.
상기 복수의 타일들 각각의 상기 벡터 코어는 정적 크기 메모리 구역들에서 동적 크기 데이터 스트림들의 전달 및 액세스를 가능하게 하는 순환 버퍼 명령들을 포함하는, 프로세서.According to claim 1,
The processor of claim 1, wherein the vector core of each of the plurality of tiles includes circular buffer instructions that enable transfer and access of dynamically sized data streams in statically sized memory regions.
상기 동적 크기 데이터 스트림들의 런타임 버퍼 크기를 추적하도록 구성된 마이크로아키텍처를 더 포함하는, 프로세서.According to claim 10,
The processor further comprising a microarchitecture configured to track runtime buffer size of the dynamically sized data streams.
상기 복수의 타일들 각각의 상기 벡터 코어는 타일-로컬 스크래치패드 메모리의 동일한 구역에 순서 없는 액세스들을 배제하지 않고 순차적 순환 선입선출(FIFO) 액세스들로서 타일-로컬 스크래치패드 메모리의 런타임 구성 및 액세싱 구역들을 제공하도록 구성되는, 프로세서.According to claim 10,
The vector core of each of the plurality of tiles performs sequential circular first-in-first-out (FIFO) accesses without excluding out-of-order accesses to the same region of the tile-local scratchpad memory. Runtime configuration and accessing regions of the tile-local scratchpad memory. A processor configured to provide.
상기 마이크로아키텍처와 연관하여 상기 순차적 순환 FIFO 액세스들은 상기 타일-로컬 스크래치패드 메모리의 정적 크기 구역들에서 상기 동적 크기 데이터 스트림들을 가능하게 하는, 프로세서.According to claim 12,
wherein the sequential circular FIFO accesses in conjunction with the microarchitecture enable the dynamically sized data streams in statically sized regions of the tile-local scratchpad memory.
각각의 타일은 데이터 스트림들의 발행, 페치(fetching), 추적 및 순서화를 관리하도록 구성된 스캐터-수집 엔진을 포함하는, 프로세서.According to claim 1,
A processor, wherein each tile includes a scatter-collect engine configured to manage publishing, fetching, tracking, and ordering of data streams.
각각의 스캐터-수집 엔진은 타일당 이동 중인 적어도 256 개의 미해결 판독 요청들을 유지하도록 추가로 구성되는, 프로세서.According to claim 14,
wherein each scatter-collect engine is further configured to maintain at least 256 outstanding read requests in transit per tile.
각각의 스캐터-수집 엔진은 흐름 제어를 관리하기 위해 버퍼 점유를 추적하고 업데이트하도록 추가로 구성되는, 프로세서.According to claim 14,
Each scatter-collect engine is further configured to track and update buffer occupancy to manage flow control.
상기 복수의 타일들의 서브세트는 각각 데이터 스트림 명령들을 협력적으로 프리페치하도록 구성된 프리페치 유닛을 더 포함하는, 프로세서.According to claim 1,
and each subset of the plurality of tiles further comprises a prefetch unit configured to cooperatively prefetch data stream instructions.
불규칙적 제어 흐름 시퀀스들 또는 벡터 내 의존 오퍼레이션(operation)들 중 적어도 하나를 가속화하도록 구성된 교차 레인 프로세싱 유닛을 더 포함하는, 프로세서.According to claim 1,
The processor further comprising a cross-lane processing unit configured to accelerate at least one of irregular control flow sequences or dependent operations in the vector.
각각의 타일은 오프칩 메모리들에서 자신의 스크래치패드 메모리로의 스캐터들을 지원하고 자신의 스크래치패드 메모리에서 오프칩 메모리들로 수집하도록 구성된, 프로세서.According to claim 1,
A processor, wherein each tile is configured to support scatters from off-chip memories to its scratchpad memory and collect from its scratchpad memory to off-chip memories.
상기 복수의 타일들의 서브세트들은 논리적으로 구성 가능한 벡터 폭들에 기반하여 그룹화되는, 프로세서.According to claim 1,
and wherein subsets of the plurality of tiles are grouped based on logically configurable vector widths.
상기 논리적으로 구성 가능한 벡터 폭들은 논리적 SIMD 폭을 포함하는, 프로세서.According to claim 20,
The processor of claim 1, wherein the logically configurable vector widths include a logical SIMD width.
상기 프로세서는 의미론적 희소성을 나타내는 신경망 계층들을 실행하도록 구성된 기계 학습 가속기의 일부인, 프로세서.According to claim 1,
The processor of claim 1, wherein the processor is part of a machine learning accelerator configured to execute neural network layers representing semantic sparsity.
신경망 네트워크 계층들은 임베딩(embedding) 또는 그래프 신경망들을 포함하는, 프로세서.According to clause 22,
A processor, wherein the neural network network layers include embedding or graph neural networks.
상기 프로세서는 동적, 불규칙적, 및 메모리 바운드(memory-bound)인 신경망 계층 컴퓨팅들에 의해 요구되는 분산된 스캐터-수집 및 컴퓨팅을 수행하도록 구성된 네트워크를 통해 다수의 다른 프로세서들에 연결되는, 프로세서.According to clause 22,
The processor is coupled to a plurality of other processors through a network configured to perform distributed scatter-collection and computing required by dynamic, random, and memory-bound neural network layer computations.
Applications Claiming Priority (11)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US202163279262P | 2021-11-15 | 2021-11-15 | |
US63/279,262 | 2021-11-15 | ||
US202163281960P | 2021-11-22 | 2021-11-22 | |
US63/281,960 | 2021-11-22 | ||
US202263322285P | 2022-03-22 | 2022-03-22 | |
US63/322,285 | 2022-03-22 | ||
US202263357281P | 2022-06-30 | 2022-06-30 | |
US63/357,281 | 2022-06-30 | ||
US17/981,617 US20230153116A1 (en) | 2021-11-15 | 2022-11-07 | Programmable Accelerator for Data-Dependent, Irregular Operations |
US17/981,617 | 2022-11-07 | ||
PCT/US2022/049353 WO2023086353A1 (en) | 2021-11-15 | 2022-11-09 | Programmable accelerator for data-dependent, irregular operations |
Publications (1)
Publication Number | Publication Date |
---|---|
KR20230169321A true KR20230169321A (en) | 2023-12-15 |
Family
ID=84537639
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
KR1020237038980A KR20230169321A (en) | 2021-11-15 | 2022-11-09 | Programmable accelerator for data-dependent and irregular operations |
Country Status (4)
Country | Link |
---|---|
EP (1) | EP4323882A1 (en) |
JP (1) | JP2024518587A (en) |
KR (1) | KR20230169321A (en) |
WO (1) | WO2023086353A1 (en) |
Family Cites Families (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10700968B2 (en) * | 2016-10-19 | 2020-06-30 | Rex Computing, Inc. | Optimized function assignment in a multi-core processor |
US10963300B2 (en) * | 2018-12-06 | 2021-03-30 | Raytheon Company | Accelerating dataflow signal processing applications across heterogeneous CPU/GPU systems |
-
2022
- 2022-11-09 KR KR1020237038980A patent/KR20230169321A/en unknown
- 2022-11-09 JP JP2023570416A patent/JP2024518587A/en active Pending
- 2022-11-09 EP EP22826505.4A patent/EP4323882A1/en active Pending
- 2022-11-09 WO PCT/US2022/049353 patent/WO2023086353A1/en active Application Filing
Also Published As
Publication number | Publication date |
---|---|
EP4323882A1 (en) | 2024-02-21 |
JP2024518587A (en) | 2024-05-01 |
WO2023086353A1 (en) | 2023-05-19 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
Mittal et al. | A survey of techniques for optimizing deep learning on GPUs | |
Fowers et al. | A configurable cloud-scale DNN processor for real-time AI | |
CN109215728B (en) | Memory circuit and method for distributed memory hazard detection and error recovery | |
US11681650B2 (en) | Execution engine for executing single assignment programs with affine dependencies | |
Rahman et al. | Graphpulse: An event-driven hardware accelerator for asynchronous graph processing | |
Dongarra et al. | High-performance computing systems: Status and outlook | |
TWI742048B (en) | Processors, methods, and systems to allocate load and store buffers based on instruction type | |
US20080250227A1 (en) | General Purpose Multiprocessor Programming Apparatus And Method | |
US10691597B1 (en) | Method and system for processing big data | |
US10997102B2 (en) | Multidimensional address generation for direct memory access | |
Vilim et al. | Aurochs: An architecture for dataflow threads | |
Cheng et al. | Accelerating end-to-end deep learning workflow with codesign of data preprocessing and scheduling | |
EP3108358B1 (en) | Execution engine for executing single assignment programs with affine dependencies | |
KR20230169321A (en) | Programmable accelerator for data-dependent and irregular operations | |
US20230153116A1 (en) | Programmable Accelerator for Data-Dependent, Irregular Operations | |
Li | Acceleration of Deep Learning on FPGA | |
Skliarova et al. | Hardware/software co-design | |
US11977499B2 (en) | Streaming transfers and ordering model | |
Zeng | FPGA-based high throughput merge sorter | |
US11972263B2 (en) | Cooperative instruction prefetch on multicore system | |
Wang et al. | Observer-controller stabilization of a class of manipulators with a single flexible link | |
WO2023183015A1 (en) | Streaming transfers and ordering model | |
Xiong | FPGA acceleration of high performance computing communication middleware | |
Sun | Harnessing GPU computing in system-level software | |
KR20230162120A (en) | Cooperative instruction prefetching in multicore systems |