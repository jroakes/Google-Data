US20090063462A1 - Word decompounder - Google Patents
Word decompounder Download PDFInfo
- Publication number
- US20090063462A1 US20090063462A1 US11/849,728 US84972807A US2009063462A1 US 20090063462 A1 US20090063462 A1 US 20090063462A1 US 84972807 A US84972807 A US 84972807A US 2009063462 A1 US2009063462 A1 US 2009063462A1
- Authority
- US
- United States
- Prior art keywords
- substrings
- word
- substring
- splittings
- morpheme
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/30—Information retrieval; Database structures therefor; File system structures therefor of unstructured textual data
- G06F16/33—Querying
- G06F16/3331—Query processing
- G06F16/3332—Query translation
- G06F16/3338—Query expansion
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/20—Natural language analysis
- G06F40/232—Orthographic correction, e.g. spell checking or vowelisation
Definitions
- This disclosure relates to information retrieval.
- Content items can be identified by a search engine in response to a query.
- the query can include one or more search terms, and a search engine can identify and rank the content items based on, for example, the search terms, e.g., keywords, in the query and one or more parameters associated with the content item.
- Some online advertising systems are used in countries where the language includes compound words.
- a compound word includes two or more words merged together.
- the word for “flower bouquet” is the compound word “Blumenstraeusse” made up of Blumen (flower) and Straeusse (bouquet).
- Online advertising systems can be used in countries such as Germany where the language, German, includes compound words. Therefore, the search terms used in these queries can include these compound words.
- Determining the appropriate advertisements to be displayed when a query is performed with search terms that are compound words can result in higher advertising revenue and a better user experience.
- Some advertising systems identify advertisements using the entire compound word as a keyword. However, other processes can be used to select advertisements associated with these compound words.
- a substring of a word is identified and a determination is made as to whether the substring appears in a query log.
- a score is generated for the substring based on the determination that the substring appears in a query log and one or more properties associated with the substring.
- the substring is selected as a keyword.
- one or more first substrings of a word are identified.
- a first morpheme is added to the one or more first substrings to create one or more second substrings, and a second morpheme is removed from the one or more first substrings to create one or more third substrings.
- One or more of the one or more first, second, and third substrings are selected as one or more splittings of the word, and a determination is made as to whether the one or more first, second, or third substrings appear in a query log.
- a score is generated for each of the one or more splittings based on a determination that the one or more first, second, or third substrings appear in the query log and one or more properties associated with each of the one or more first, second, and third substrings that are selected as part of each of the one or more splittings.
- a splitting selected from among the one or more splittings with a score higher than the other one or more splittings is selected as a keyword.
- a word is split into one or more first substrings.
- a morpheme is applied to the one or more first substrings to create one or more second substrings.
- a determination is made as to whether the one or more first, second, or third substrings appear in a query log, and one or more of the one or more first, second, and third substrings are selected as one or more splittings of the word.
- a score is generated for each of the one or more splittings based on a determination that the one or more first, second, or third substrings appear in the query log and one or more properties associated with each of the one or more first, second, and third substrings.
- a splitting selected from among the one or more splittings is selected based on the score.
- a system in another implementation, includes a splitting engine that splits a word into one or more first substrings, applies a morpheme to the one or more first substrings to create one or more second and one or more third substrings, determines whether the one or more first, second, or third substrings appear in a query log, and selects one or more of the one or more first, second, and third substrings as one or more splittings of the word.
- the system also includes a scoring engine that generates a score for each of the one or more splittings based on a determination that the one or more first, second, or third substrings appear in the query log and one or more properties associated with each of the one or more first, second, and third substrings, and selects a splitting selected from among the one or more splittings based on the score.
- FIG. 1 is a block diagram of an example implementation of an online advertising system.
- FIG. 2 is a block diagram of an example word splitting system.
- FIG. 3 is flow diagram of an example process for splitting a word.
- FIG. 4 is a flow diagram of another example process for splitting a word.
- FIG. 5 is a flow diagram of another example process for splitting a word.
- FIG. 6 is a flow diagram of another example process for splitting a word.
- FIG. 7 is a flow diagram of applying a morpheme to one or more first substrings.
- FIG. 8 is a schematic diagram of an example computer system that can be utilized to implement the systems and methods described herein.
- FIG. 1 is a block diagram of an example implementation of an online advertising system 100 .
- one or more advertisers 102 can directly, or indirectly, enter, maintain, and track advertisement (“ad”) information in an advertisement system 104 .
- the advertisements may be in the form of graphical advertisements, such as banner advertisements, text only advertisements, image advertisements, audio advertisements, video advertisements, advertisements combining one of more of any of such components, etc.
- the advertisements may also include embedded information, such as a links, meta-information, and/or machine executable instructions.
- One or more publishers 106 may submit requests for advertisements to the system 104 .
- the system 104 responds by sending advertisements (e.g., when an associated publication is rendered) to the requesting publisher 106 (or a browser associated with a requesting user) for placement/co-location on one or more of the publisher's rendered web properties (e.g., websites and other network-distributed content). While reference is made to advertisements, other content items can be provided by the system 104 .
- advertisements e.g., when an associated publication is rendered
- the requesting publisher 106 or a browser associated with a requesting user
- the publisher's rendered web properties e.g., websites and other network-distributed content
- a click-through can occur, for example, when a user of a user device, selects or “clicks” on an advertisement.
- the click-through rate can be a performance metric that is obtained by dividing the number of users that clicked on the advertisement or a link associated with the advertisement by the number of times the advertisement was delivered.
- a “conversion” occurs when a user, for example, consummates a transaction related to a previously served advertisement. What constitutes a conversion may vary from case to case and can be determined in a variety of ways.
- This usage information can include measured or observed user behavior related to advertisements that have been served.
- the system 104 performs financial transactions, such as crediting the publishers 106 and charging the advertisers 102 based on the usage information.
- a computer network 110 such as a local area network (LAN), wide area network (WAN), the Internet, or a combination thereof, connects the advertisers 102 , the system 104 , the publishers 106 , and the users 108 .
- LAN local area network
- WAN wide area network
- the Internet or a combination thereof, connects the advertisers 102 , the system 104 , the publishers 106 , and the users 108 .
- a publisher 106 is a general content server that receives requests for content (e.g., articles, discussion threads, music, video, graphics, search results, web page listings, information feeds, etc.), and retrieves the requested content in response to the request.
- the content server may submit a request for advertisements to an advertisement server in the system 104 .
- the advertisement request may include a number of advertisements desired.
- the advertisement request may also include content request information.
- This information can include the content itself (e.g., page or other content document), a category corresponding to the content or the content request (e.g., arts, business, computers, arts-movies, arts-music, etc.), part or all of the content request, content age, content type (e.g., text, graphics, video, audio, mixed media, etc.), geo-location information, etc.
- content e.g., page or other content document
- category corresponding to the content or the content request e.g., arts, business, computers, arts-movies, arts-music, etc.
- content age e.g., text, graphics, video, audio, mixed media, etc.
- geo-location information e.g., geo-location information, etc.
- the content server can combine the requested content with one or more of the advertisements provided by the system 104 .
- This combined content and advertisements can be sent to the user 108 that requested the content for presentation in a viewer (e.g., a browser or other content display system).
- the content server can transmit information about the advertisements back to the advertisement server, including information describing how, when, and/or where the advertisements are to be rendered (e.g., in HTML or JavaScriptTM).
- search service can receive queries for search results. In response, the search service can retrieve relevant search results from an index of documents (e.g., from an index of web pages).
- An exemplary search service is described in the article S. Brin and L. Page, “The Anatomy of a Large-Scale Hypertextual Search Engine,” Seventh International World Wide Web Conference, Brisbane, Australia and in U.S. Pat. No. 6,285,999, both of which are incorporated herein by reference each in their entirety.
- Search results can include, for example, lists of web page titles, snippets of text extracted from those web pages, and hypertext links to those web pages, and may be grouped into a predetermined number of (e.g., ten) search results.
- the search service can submit a request for advertisements to the system 104 .
- the request may include a number of advertisements desired. This number may depend on the search results, the amount of screen or page space occupied by the search results, the size and shape of the advertisements, etc. In some implementations, the number of desired advertisements will be from one to ten, or from three to five.
- the request for advertisements may also include the query (as entered or parsed), information based on the query (such as geo-location information, whether the query came from an affiliate and an identifier of such an affiliate), and/or information associated with, or based on, the search results.
- Such information may include, for example, identifiers related to the search results (e.g., document identifiers or “docIDs”), scores related to the search results (e.g., information retrieval (“IR”) scores), snippets of text extracted from identified documents (e.g., web pages), full text of identified documents, feature vectors of identified documents, etc.
- IR scores can be computed from, for example, dot products of feature vectors corresponding to a query and a document, page rank scores, and/or combinations of IR scores and page rank scores, etc.
- the search service can combine the search results with one or more of the advertisements provided by the system 104 . This combined information can then be forwarded to the user 108 that requested the content.
- the search results can be maintained as distinct from the advertisements, so as not to confuse the user between paid advertisements and presumably neutral search results.
- the search service can transmit information about the advertisement and when, where, and/or how the advertisement was to be rendered back to the system 104 .
- the advertising management system 104 can serve publishers 106 , such as content servers and search services.
- the system 104 permits serving of advertisements targeted to content (e.g., documents) served by content servers or in response to search queries provided by users.
- content e.g., documents
- a network or inter-network may include an advertisement server serving targeted advertisements in response to requests from a search service with advertisement spots for sale.
- the inter-network is the World Wide Web.
- the search service crawls much or all of the content.
- Some of this content will include advertisement spots (also referred to as “inventory”) available.
- one or more content servers may include one or more documents.
- Documents may include web pages, email, content, embedded information (e.g., embedded media), meta-information and machine executable instructions, and advertisement spots available.
- the advertisements inserted into advertisement spots in a document can vary each time the document is served or, alternatively, can have a static association with a given document.
- the requests that the general content servers receive and the queries the search services receive may be in languages that use compound words. Therefore, the terms in the requests and the queries can include compound words.
- the Germanic languages ISBNs, Danish, Dutch-Flemish, English, Faroese, Frisian, High German, Gutnish, Icelandic, Low German, Norwegian, Swedish, and Yiddish all include compound words to some extent.
- the compound words can be created by merging simpler words together. For example, the German word “Blumenstraeusse” (flower bouquet) is made up of Blumen (flower) and Straeusse (bouquet).
- the advertisement system 104 can decompose the compound words into splittings, or substrings, and select one or more of the decomposed words, or substrings, as keywords to search for advertisements.
- FIG. 2 is a block diagram of an example word splitting system 200 .
- the word splitting system 200 can, for example, be implemented in a computer device or one or more computer devices connected through a network, e.g., a local area network (LAN) or a wide area network (WAN), such as the Internet.
- the word splitting system 200 can, for example be implemented in the advertisement system 104 , which can be implemented in a computing system.
- the one or more computing devices can, for example, include memory devices storing processing instructions and processing devices for executing the processing instructions.
- An example computing system is shown and described with reference to FIG. 8 . Other implementations, however, can also be used.
- the word splitting system 200 can assign a score to each substring and select one or more of the substrings as a keyword.
- the score can be calculated based on parameters associated with each substring.
- the highest scoring substring can be selected as the keyword to use in selecting advertisements.
- the word splitting system 200 can, for example, include a splitting engine 202 , a data store 204 , and a scoring engine 206 .
- the data store 204 can comprise a unitary data store, such as a hard drive.
- the data store 204 can comprise a distributed data store, such as a storage system that is distributed over a network. Other implementations, however, can also be used.
- the data store 204 can store one or more words, e.g., compound words, and one or more content items, e.g., advertisements. Each word in the data store 204 can be associated with one or more first substrings 208 , 210 , 212 , one or more second substrings 214 , 216 , 218 , and one or more third substrings 220 , 222 , 224 .
- the one or more first substrings 208 , 210 , 212 , one or more second substrings 214 , 216 , 218 , and one or more third substrings 220 , 222 , 224 can be identified by the splitting engine 202 , as will be described further below.
- the one or more first substrings 208 , 210 , 212 , one or more second substrings 214 , 216 , 218 , and one or more third substrings 220 , 222 , 224 all combine to form the one or more word splittings 226 , 228 , and 230 .
- the splitting engine 202 can identify one or more first substrings 208 , 210 , 212 of a word.
- the word can, for example, be a compound word that includes one or more simpler words merged together.
- the splitting engine 202 can identify possible ways of splitting the word into the one or more first substrings 208 , 210 , 212 .
- Each of the first substrings 208 , 210 , 212 can include one or more consecutive letters of the word. The consecutive letters can, for example, be located in any part of the word. For example, suppose the German compound word “kontrollfunktion” is used in a query.
- the splitting engine 202 can split the word into the following first substrings (hereinafter “exemplary first substrings”):
- the splitting engine 202 can add a first morpheme 232 to the one or more first substrings 208 , 210 , 212 to create one or more second substrings 214 , 216 , 218 .
- the splitting engine 202 can also, for example, remove a second morpheme 234 from the one or more first substrings 208 , 210 , 212 to create one or more third substrings 220 , 222 , 224 .
- a morpheme is the smallest meaningful unit in the grammar of a language.
- a morpheme can include one or more letters.
- the first morpheme 232 and the second morpheme 234 include Germanic language morphemes.
- the Germanic languages as described above, include intimidans, Danish, Dutch-Flemish, English, Faroese, Frisian, High German, Gutnish, Icelandic, Low German, Norwegian, Swedish, and Yiddish.
- Each of these languages can include one or more morphemes.
- “e” and “s” are morphemes.
- German, “e”, “en”, “nen”, “s”, “ens”, “es”, “ns” or “er” are morphemes.
- the other Germanic languages also include morphemes that consist of one or more letters, as can be appreciated by one skilled in the art.
- the first morpheme 232 and the second morpheme 234 can include morphemes from other compound languages that may not be Germanic, for example, Finnish.
- the splitting engine 202 can add a first morpheme 232 to the beginning and end of each of the one or more first substrings 208 , 210 , 212 to create the one or more second substrings 214 , 216 , 218 .
- the splitting engine 202 can add any of the German morphemes “e”, “en”, “nen”, “s”, “ens”, “es”, “ns” and “er” to the exemplary first substrings.
- the splitting engine 202 can remove the second morpheme 234 from the beginning or end of each of the one or more first substrings 208 , 210 , 212 to create the one or more third substrings 220 , 222 , 224 .
- the splitting engine 202 can remove any of the German morphemes “e”, “en”, “nen”, “s”, “ens”, “es”, “ns” and “er” to any of the exemplary first substrings if the substring ends in any of those.
- the splitting engine 202 can select one or more of the one or more first substrings 208 , 210 , 212 , the one or more second substrings 214 , 216 , 218 , and the one or more third substrings 220 , 222 , and 224 as the one or more word splittings 226 , 228 , 230 of the word.
- the splitting engine 202 can, for example, select any of the first, second, or third substrings 208 , 210 , 212 , 214 , 216 , 218 , 220 , 222 , and 224 as the one or more splittings 226 , 228 , 230 by determining which of the substrings 208 , 210 , 212 , 214 , 216 , 218 , 220 , 222 , and 224 together combine to form the closest version of the original word.
- the closest version can, for example, be determined by the character count of the word.
- the one or more splittings 226 , 228 , 230 can, for example, have the same number of characters as the original word.
- the one or more splittings 226 , 228 , 230 can have a predetermined number of characters greater or less than the original word. For example, for the word “kontrollfunktion,” the splitting engine 202 can select “kontroll funktion” as one of the splittings 226 , 228 , 230 . In this example, the number of characters of “kontrollfunktion,” e.g., 16, equals the number of characters of “kontroll funktion,” e.g., 16.
- the splitting engine 202 can determine whether the one or more first, second, or third substrings 208 , 210 , 212 , 214 , 216 , 218 , 220 , 222 , and 224 appear in a log 236 .
- the log can, for example, include a query log that includes keywords of previously submitted queries publishers 106 such as search services received in the advertisement system 104 .
- the query log can also include previous keywords used in the requests that publishers 106 , such as the general content servers, received in the advertisement system 104 .
- the splitting engine 202 can determine whether the one or more first, second, or third substrings 208 , 210 , 212 , 214 , 216 , 218 , 220 , 222 , and 224 have been used before as keywords by searching for the substrings in the log 236 .
- splitting engine 202 added the morphemes “e”, “en”, “nen”, “s”, “ens”, “es”, “ns” and “er” to each of the first substrings 208 , 210 , 212 of the word “kontrollfunktion” to create the one or more second substrings 214 , 216 , 218 , as well as removed the morphemes “e”, “en”, “nen”, “s”, “ens”, “es”, “ns” and “er” from each of the first substrings 208 , 210 , 212 to create one or more third substrings 220 , 222 , 224 .
- the splitting engine 202 then determined that the second substring “kontrolle,” which is the first substring “kontroll” with the morpheme “e” added, appears in the log 236 . Therefore the second substring “kontrolle” was used previously as a keyword.
- the splitting engine 202 also determined that the first substrings “funktion,” “funkt,” and “ion” also appeared in the log 236 . Therefore, the first substrings “funktion,” “funkt,” and “ion” were also previously used as keywords.
- the splitting engine 202 can combine the second substring “kontrolle,” as well as the first substrings “funktion,” “funkt,” and “ion” to generate the splittings “kontroll funktion”, “kontrolle function”, “kontroll funkt ion” and “kontrolle funkt ion” as the one or more word splittings 226 , 228 , 230 .
- the scoring engine 206 can generate a score 238 , 240 , 242 for each of the one or more word splittings 226 , 228 , 230 .
- the scoring engine 206 can generate the score 238 , 240 , 242 based on the determination that the one or more first, second, or third substrings 208 , 210 , 212 , 214 , 216 , 218 , 220 , 222 , and 224 appear in the query log 236 and also based on one or more properties associated with each of the one or more first, second, and third substrings 208 , 210 , 212 , 214 , 216 , 218 , 220 , 222 , and 224 that are selected as part of each of the one or more splittings 226 , 228 , 230 .
- the scoring engine 206 can then calculate the score 238 , 240 , 242 based on one or more parameters associated with each of the substrings in the word splittings 226 , 228 , 230 . For example, suppose the splitting engine 202 selected “kontroll funktion” as a splitting. If both of the substrings “kontroll” and “funktion” are in the query log 236 , then the scoring engine 206 can calculate a score for the splitting.
- the frequency of each substring as a keyword can be one of one or more parameters associated with each substring in the word splittings 226 , 228 , 230 .
- the splitting engine 202 can measure the frequency of the substring “kontrolle” as a keyword in the log 236 by determining how often the substring “kontrolle” appears in the log 236 .
- the probability that a substring appears as a keyword can be one of the parameters associated with each substring in the word splittings 226 , 228 , 230 .
- the probability can, for example, be calculated by taking the frequency of each substring appearing as a keyword in the query log 236 and dividing by the total frequency. For example, if the frequency of the substring “kontrolle” is 20, and the total frequency of all the keywords is 100, then the probability that the substring “kontrolle” appears as a query keyword is 20%.
- the co-occurrence frequency of every possible substring pair in the same query can be one of the parameters associated with each substring in the word splittings 226 , 228 , 230 .
- the splitting engine 202 can measure the number of times that “kontrolle” appears in a query, the number of times that “funktion” appears in a query and the number of times that “kontrolle” and “funktion” appear in the same query.
- the queries in the log 236 show the following substrings appeared with the following frequency:
- the frequencies can be calculated as: “kontrolle”: 6 (this substring appeared in 6 queries) “funktion”: 5 (this substring appeared in 5 queries), “funkt”: 4 (this substring appeared in 4 queries), “kontrolle funktion”: 4 (the substring pair appeared in the same query 4 times), “funktion ion”: 2 (this substring pair appeared in the same query 2 times), and “kontrolle ion”: 2 (this substring pair appeared in the same query 2 times).
- the co-occurrence frequency of every possible substring pair, in the same query and in consecutive positions can be one of the parameters associated with each substring in the word splittings 226 , 228 , 230 .
- the splitting engine 202 can, for example, measure the number of times that both substrings are consecutive in a query in the log 236 .
- the substring pairs and frequencies are: kontrolle funktion: 4 (2 in “kontrolle funktion”, 2 in “kontrolle funktion ion”)
- the mutual information of each substring pair can be one of the parameters associated with each substring in the word splittings 226 , 228 , 230 .
- the mutual information can be estimated from the substring frequencies and their co-occurrence frequencies.
- the mutual information, or transinformation, of two random variables e.g., substring frequencies and their co-occurrence frequencies, is a quantity that measures the mutual dependence of the two variables.
- the mutual information of two random variables can be calculated as follows:
- I ⁇ ( X ; Y ) ⁇ y ⁇ Y ⁇ ⁇ x ⁇ X ⁇ p ⁇ ( x , y ) ⁇ log ⁇ ( p ⁇ ( x , y ) p ⁇ ( x ) ⁇ p ⁇ ( y ) ) ,
- p(x) is the frequency of substring “x” in the query logs divided by the sum of the frequencies of all substrings.
- the probability p(x,y) is the frequency of substrings “x” and “y” co-occurring in the same query divided by the sum of frequencies of occurrences of every possible pair of substrings.
- the probabilities of each substring can be one of the parameters associated with each substring in the word splittings 226 , 228 , 230 .
- the co-occurrence frequencies of a compound word and the decompounded form of that word in anchor texts from hyperlinks pointing to a same web document can be parameters associated with each substring in the word splittings 226 , 228 , 230 .
- Anchor text is the text that appears in a hyperlink on the web. If, for example, two web pages have a hyperlink to the same document, then the texts in those hyperlinks can be related, because the anchor texts usually describes the place where a user is directed if the user clicks on the link.
- the anchor text of a hyperlink to a web page contains the substring “kontrollfunktion,” and in the anchor text of a hyperlink to the same web page exists “kontrolle funktion,” then a good indication exists that all substrings, e.g., “kontrollfunktion,” and “kontrolle funktion” are the same, written as a compound or separately.
- the frequency of each substring as an advertiser keyword can be one of the parameters associated with each substring in the word splittings 226 , 228 , 230 .
- the splitting engine 202 can, for example, measure the number of times each substring was previously used as a keyword by searching the log 236 .
- the co-occurrence frequencies of substrings as the same advertiser keyword, the co-occurrence frequencies of substrings in different keywords from the same advertisement, and the co-occurrence of a compound word and the decompounded form of that word (with blank spaces between the parts) as different keywords for the same advertisement can be parameters associated with each substring in the word splittings 226 , 228 , 230 .
- advertisers can bid on particular keywords for their advertisements to be shown.
- an advertiser may bid on keywords such as “kontrolle,” “funkt,” or “funktion.” If a word “kontrollfunktion” exists that can be decomposed in two parts, or substrings, “kontrolle” and “funktion,” and many advertisers that bid on “kontrolle” are also bidding on “funktion,” or on both, that is also an indication that “kontrollfunktion” is probably a compound word and “kontrolle funktion” is the correct way to split it.
- the scoring engine 206 can determine the percentage of times that w 1 and w 2 appear together in the same keyword or campaign (of any advertisers), indicating that w 1 and w 2 exist as substrings and their meanings are related.
- a campaign as defined herein, is a list of all keywords selected by an advertiser for one or more advertisements associated with the advertiser. The scoring engine 206 can evaluate and look for advertisers having an advertisement campaign that is targeted both for “kontrolle” and for “funktion.”
- the scoring engine 206 can determine the percentage of advertisers that bid for w and w 1 as different keywords in the same campaign, the percentage of advertisers that bid for w and w 2 as different keywords in the same campaign, and the percentage of advertisers that bid for w, w 1 and w 2 as different keywords in the same campaign. In one implementation, these three metrics indicate that w is probably a compound, and either w 1 , w 2 , or both can replace the compound word as keywords in an ad campaign, so they are probably related to each other.
- the scoring engine 206 can evaluate the percentage of advertisers that bid on “kontrollfunktion” and “kontrolle funktion” as different keywords in the same campaign, e.g., the compound and the phrase containing both words separately.
- the scoring engine 206 would evaluate advertisers bidding on “kontrollfunktion” and “kontrolle funktion.”
- the scoring engine 206 can apply a machine learning algorithm to the parameters of each substring in the word splitting to calculate a score 238 , 240 , 242 for each word splitting 226 , 228 , 230 .
- the scoring engine 206 can determine which word splitting 226 , 228 , 230 is the word splitting that would yield the highest score.
- the machine learning algorithm can, for example, be a support vector machine as described in J. Platt, Fast Training of Support Vector Machines using Sequential Minimal Optimization , in Advances in Kernel Methods—Support Vector Learning, B. Schölkopf, C. Burges, and A. Smola, eds., MIT Press (1998).
- the support vector machine can use any of the one or more parameters described above to calculate the scores 238 , 240 , 242 , and determine which one of the one or more word splittings 226 , 228 , 230 is the splitting with the highest score.
- the support vector machine can, for example, train on a model built from previous data.
- the model can includes previous words as well as whether these words are compounds or not and, in the case that they are compounds, how the words should be decompounded, or split into substrings. Therefore, for each of these words, any possible way of splitting the words into substrings has been indicated, and for each possible substring of each word, all the above parameters have been calculated, and the correct substring, e.g., the substring with the highest score, has been indicated.
- the splitting engine 202 can generate every possible way of splitting this word into substrings as described above, and apply the support vector machine to score the substrings, and score the splittings.
- the scoring engine 206 can then select one of the one or more word splittings 226 , 228 , 230 with the highest score as calculated by the support vector machine.
- the scoring engine 206 can rank the one or more word splittings 226 , 228 , 230 based on the scores 238 , 240 , 242 .
- the scoring engine 206 can rank the word splittings 226 , 228 , 230 by decreasing score.
- one or more of these parameters can be directly applied to rank the substrings without calculating a score for the substrings.
- the mutual information metric, the geometric mean of the frequencies of the compound parts, or a product of the probabilities of the compound parts are all functions that can be used to rank the word splittings 226 , 228 , 230 .
- outside sources can be considered in determining whether the splitting engine 202 should split a compound word.
- outside sources such as dictionaries from several languages, lists and gazetteers of locations, proper nouns of people (first names and family names), organizations, trademarks, and suffixes of the words can be considered by the splitting engine 202 .
- These outside sources can contain words that the splitting engine 202 may not want split. For example, German words ending by “strasse” or “dorf” are usually place names and should be considered as proper nouns and not decompounded or split into substrings.
- the substring selected from the one or more word splittings 226 , 228 , 230 with the highest score 238 , 240 , 242 can be selected as a keyword 244 .
- the scoring engine 206 can select one or more advertisements associated with the keyword 244 . For example, suppose the scoring engine 206 uses the support vector machine and determines the scores for the one or more word splittings 226 , 228 , 230 “kontrolle funktion,” “kontroll funktion” “kontrolle funkt ion,” and “kontroll funkt ion” are 50, 40, 30, and 20, respectively.
- the scoring engine 206 can select the highest scoring substring “kontrolle funktion,” with the high score of 50, as the keyword to use in selecting advertisements.
- the splitting engine 202 split the word into substrings, and scoring engine 206 selected the highest scoring splitting “kontrolle function” as the keyword.
- the scoring engine 206 can select one or more advertisements associated with the keywords “kontrolle” and “function” in response to a search query using the word “kontrollfunktion.”
- FIG. 3 is a flow diagram of an example process 300 for splitting a compound word.
- the process 300 can, for example, be implemented in a system such as the word splitting system 200 of FIG. 2 .
- Stage 302 identifies a substring of a word.
- the splitting engine 202 can identify a substring of a word.
- Stage 304 determines whether the substring appears in a query log.
- the splitting engine 202 can determine whether the substring appears in a query log.
- Stage 306 generates a score for the substring based on a determination that the substring appears in a query log and one or more properties associated with the substring.
- the scoring engine 206 can generate a score for the substring based on a determination that the substring appears in a query log and one or more properties associated with the substring.
- Stage 308 selects the substring as a keyword.
- the scoring engine 206 can select the substring as a keyword.
- FIG. 4 is a flow diagram of another example process 400 for splitting a word.
- the process 400 can, for example, be implemented in a system such as the word splitting system 200 of FIG. 2 .
- Stage 402 identifies second or more substrings of a word.
- the splitting engine 402 can identify second or more substrings of a word.
- Stage 404 determines whether the second or more substrings appear in a query log.
- the splitting engine 202 can determine whether the second or more substrings appear in a query log.
- Stage 406 generates a score for each of the substrings based on a determination that each of the substrings appears in a query log and one or more properties associated with the substring.
- the scoring engine 206 can generate a score for each of the substrings based on a determination that each of the substrings appears in a query log and one or more properties associated with the substring.
- Stage 408 identifies one of the second or more substrings with a score higher than the other substrings.
- the scoring engine 206 can identify one of the second or more substrings with a score higher than the other substrings.
- FIG. 5 is a flow diagram of another example process 500 for splitting a word.
- the process 500 can, for example, be implemented in a system such as the word splitting system 200 of FIG. 2 .
- Stage 502 identifies one or more first substrings of a word.
- the splitting engine 202 can identify one or more first substrings of a word.
- Stage 504 adds a first morpheme to the one or more first substrings to create one or more second substrings.
- the splitting engine 202 can add a first morpheme to the one or more first substrings to create one or more second substrings.
- Stage 506 removes a second morpheme from the one or more first substrings to create one or more third substrings.
- the splitting engine 202 can remove a second morpheme from the one or more first substrings to create one or more third substrings.
- Stage 508 can select one or more of the one or more first, second, and third substrings as one or more splittings of the word.
- the splitting engine 202 can select one or more of the one or more first, second, and third substrings as one or more splittings of the word.
- Stage 510 determines whether the one or more first, second, or third substrings appear in a query log.
- the splitting engine 202 can determine whether the one or more first, second, or third substrings appear in a query log.
- Stage 512 generates a score for each of the one or more splittings based on a determination that the one or more first, second, or third substrings appear in the query log and one or more properties associated with each of the one or more first, second, and third substrings that are selected as part of each of the one or more splittings.
- the scoring engine 206 can generate a score for each of the one or more splittings based on a determination that the one or more first, second, or third substrings appear in the query log and one or more properties associated with each of the one or more first, second, and third substrings that are selected as part of each of the one or more splittings.
- Stage 514 selects a splitting selected from among the one or more splittings with a score higher than the other one or more splittings as a keyword.
- the scoring engine 206 can select a splitting selected from among the one or more splittings with a score higher than the other one or more splittings as a keyword.
- FIG. 6 is a flow diagram of another example process 600 for splitting a word.
- the process 600 can, for example, be implemented in a system such as word splitting system 200 of FIG. 2 .
- Stage 602 splits a word into one or more first substrings.
- the splitting engine 202 can split a word into one or more first substrings.
- Stage 604 applies a morpheme to the one or more first substrings to create one or more second substrings.
- the splitting engine 202 can apply a morpheme with the one or more first substrings to create one or more second and one or more third substrings.
- Stage 606 determines whether the one or more first, second, or third substrings appear in a query log.
- the splitting engine 202 can determine whether the one or more first, second, or third substrings appear in a query log.
- Stage 608 selects one or more of the one or more first, second, and third substrings as one or more splittings of the word.
- the splitting engine 202 can select one or more of the one or more first, second, and third substrings as one or more splittings of the word.
- Stage 610 generates a score for each of the one or more splittings based on a determination that the one or more first, second, or third substrings appear in the query log and one or more properties associated with each of the one or more first, second, and third substrings.
- the splitting engine 202 can generate a score for each of the one or more splittings based on a determination that the one or more first, second, or third substrings appear in the query log and one or more properties associated with each of the one or more first, second, and third substrings.
- Stage 612 selects a splitting selected from among the one or more splittings based on the score.
- the scoring engine 206 can select a splitting selected from among the one or more splittings based on the score.
- FIG. 7 is a flow diagram of an example process 700 for applying a morpheme to one or more first substrings.
- the process 700 can, for example, be implemented in a system such as the word splitting system 200 of FIG. 2 .
- Stage 702 adds a first morpheme to the one or more first substrings to create the one or more second substrings.
- the splitting engine 202 can add a first morpheme to the one or more first substrings to create one or more second substrings.
- Stage 704 removes a second morpheme from the one or more first substrings to create the one or more third substrings.
- the splitting engine 202 can remove a second morpheme from the one or more first substrings to create one or more third substrings.
- FIG. 8 is block diagram of an example computer system 800 .
- the system 800 includes a processor 810 , a memory 820 , a storage device 830 , and an input/output device 840 .
- Each of the components 810 , 820 , 830 , and 840 can, for example, be interconnected using a system bus 850 .
- the processor 810 is capable of processing instructions for execution within the system 800 .
- the processor 810 is a single-threaded processor.
- the processor 810 is a multi-threaded processor.
- the processor 810 is capable of processing instructions stored in the memory 820 or on the storage device 830 .
- the memory 820 stores information within the system 800 .
- the memory 820 is a computer-readable medium.
- the memory 820 is a volatile memory unit.
- the memory 820 is a non-volatile memory unit.
- the storage device 830 is capable of providing mass storage for the system 800 .
- the storage device 830 is a computer-readable medium.
- the storage device 830 can, for example, include a hard disk device, an optical disk device, or some other large capacity storage device.
- the input/output device 840 provides input/output operations for the system 800 .
- the input/output device 840 can include one or more of a network interface devices, e.g., an Ethernet card, a serial communication device, e.g., and RS-232 port, and/or a wireless interface device, e.g., and 802.11 card.
- the input/output device can include driver devices configured to receive input data and send output data to other input/output devices, e.g., keyboard, printer and display devices 860 .
- Other implementations, however, can also be used, such as mobile computing devices, mobile communication devices, set-top box television client devices, etc.
- a content item such as an advertisement
- content items such as video and/or audio files, web pages for particular subjects, news articles, etc.
- the implementations can be used with other compound words such as for example, Finnish, as well as other languages that include compound words.
- online advertisements the implementation described can also be used with other possible applications such as, for example, machine translation, speech recognition, information retrieval, etc.
- the apparatus, methods, flow diagrams, and structure block diagrams described in this patent document may be implemented in computer processing systems including program code comprising program instructions that are executable by the computer processing system. Other implementations may also be used. Additionally, the flow diagrams and structure block diagrams described in this patent document, which describe particular methods and/or corresponding acts in support of steps and corresponding functions in support of disclosed structural means, may also be utilized to implement corresponding software structures and algorithms, and equivalents thereof.
Abstract
Description
- This disclosure relates to information retrieval.
- Content items, e.g., advertisements, can be identified by a search engine in response to a query. The query can include one or more search terms, and a search engine can identify and rank the content items based on, for example, the search terms, e.g., keywords, in the query and one or more parameters associated with the content item.
- Some online advertising systems are used in countries where the language includes compound words. A compound word includes two or more words merged together. For example, in German, the word for “flower bouquet” is the compound word “Blumenstraeusse” made up of Blumen (flower) and Straeusse (bouquet). Online advertising systems can be used in countries such as Germany where the language, German, includes compound words. Therefore, the search terms used in these queries can include these compound words.
- Determining the appropriate advertisements to be displayed when a query is performed with search terms that are compound words can result in higher advertising revenue and a better user experience. Some advertising systems identify advertisements using the entire compound word as a keyword. However, other processes can be used to select advertisements associated with these compound words.
- Disclosed herein are systems, methods and computer program products for splitting a word into one or more substrings. In one implementation, a substring of a word is identified and a determination is made as to whether the substring appears in a query log. A score is generated for the substring based on the determination that the substring appears in a query log and one or more properties associated with the substring. The substring is selected as a keyword.
- In another implementation, one or more first substrings of a word are identified. A first morpheme is added to the one or more first substrings to create one or more second substrings, and a second morpheme is removed from the one or more first substrings to create one or more third substrings. One or more of the one or more first, second, and third substrings are selected as one or more splittings of the word, and a determination is made as to whether the one or more first, second, or third substrings appear in a query log. A score is generated for each of the one or more splittings based on a determination that the one or more first, second, or third substrings appear in the query log and one or more properties associated with each of the one or more first, second, and third substrings that are selected as part of each of the one or more splittings. A splitting selected from among the one or more splittings with a score higher than the other one or more splittings is selected as a keyword.
- In another implementation, a word is split into one or more first substrings. A morpheme is applied to the one or more first substrings to create one or more second substrings. A determination is made as to whether the one or more first, second, or third substrings appear in a query log, and one or more of the one or more first, second, and third substrings are selected as one or more splittings of the word. A score is generated for each of the one or more splittings based on a determination that the one or more first, second, or third substrings appear in the query log and one or more properties associated with each of the one or more first, second, and third substrings. A splitting selected from among the one or more splittings is selected based on the score.
- In another implementation, a system includes a splitting engine that splits a word into one or more first substrings, applies a morpheme to the one or more first substrings to create one or more second and one or more third substrings, determines whether the one or more first, second, or third substrings appear in a query log, and selects one or more of the one or more first, second, and third substrings as one or more splittings of the word. The system also includes a scoring engine that generates a score for each of the one or more splittings based on a determination that the one or more first, second, or third substrings appear in the query log and one or more properties associated with each of the one or more first, second, and third substrings, and selects a splitting selected from among the one or more splittings based on the score.
-
FIG. 1 is a block diagram of an example implementation of an online advertising system. -
FIG. 2 is a block diagram of an example word splitting system. -
FIG. 3 is flow diagram of an example process for splitting a word. -
FIG. 4 is a flow diagram of another example process for splitting a word. -
FIG. 5 is a flow diagram of another example process for splitting a word. -
FIG. 6 is a flow diagram of another example process for splitting a word. -
FIG. 7 is a flow diagram of applying a morpheme to one or more first substrings. -
FIG. 8 is a schematic diagram of an example computer system that can be utilized to implement the systems and methods described herein. -
FIG. 1 is a block diagram of an example implementation of anonline advertising system 100. In some implementations, one ormore advertisers 102 can directly, or indirectly, enter, maintain, and track advertisement (“ad”) information in anadvertisement system 104. The advertisements may be in the form of graphical advertisements, such as banner advertisements, text only advertisements, image advertisements, audio advertisements, video advertisements, advertisements combining one of more of any of such components, etc. The advertisements may also include embedded information, such as a links, meta-information, and/or machine executable instructions. One ormore publishers 106 may submit requests for advertisements to thesystem 104. Thesystem 104 responds by sending advertisements (e.g., when an associated publication is rendered) to the requesting publisher 106 (or a browser associated with a requesting user) for placement/co-location on one or more of the publisher's rendered web properties (e.g., websites and other network-distributed content). While reference is made to advertisements, other content items can be provided by thesystem 104. - Other entities, such as users 108 and the
advertisers 102, can provide usage information to thesystem 104, such as, for example, whether or not a conversion or click-through related to an advertisement has occurred. A click-through can occur, for example, when a user of a user device, selects or “clicks” on an advertisement. The click-through rate can be a performance metric that is obtained by dividing the number of users that clicked on the advertisement or a link associated with the advertisement by the number of times the advertisement was delivered. A “conversion” occurs when a user, for example, consummates a transaction related to a previously served advertisement. What constitutes a conversion may vary from case to case and can be determined in a variety of ways. - This usage information can include measured or observed user behavior related to advertisements that have been served. The
system 104 performs financial transactions, such as crediting thepublishers 106 and charging theadvertisers 102 based on the usage information. - A
computer network 110, such as a local area network (LAN), wide area network (WAN), the Internet, or a combination thereof, connects theadvertisers 102, thesystem 104, thepublishers 106, and the users 108. - One example of a
publisher 106 is a general content server that receives requests for content (e.g., articles, discussion threads, music, video, graphics, search results, web page listings, information feeds, etc.), and retrieves the requested content in response to the request. The content server may submit a request for advertisements to an advertisement server in thesystem 104. The advertisement request may include a number of advertisements desired. The advertisement request may also include content request information. This information can include the content itself (e.g., page or other content document), a category corresponding to the content or the content request (e.g., arts, business, computers, arts-movies, arts-music, etc.), part or all of the content request, content age, content type (e.g., text, graphics, video, audio, mixed media, etc.), geo-location information, etc. - In some implementations, the content server can combine the requested content with one or more of the advertisements provided by the
system 104. This combined content and advertisements can be sent to the user 108 that requested the content for presentation in a viewer (e.g., a browser or other content display system). The content server can transmit information about the advertisements back to the advertisement server, including information describing how, when, and/or where the advertisements are to be rendered (e.g., in HTML or JavaScript™). - Another
example publisher 106 is a search service. A search service can receive queries for search results. In response, the search service can retrieve relevant search results from an index of documents (e.g., from an index of web pages). An exemplary search service is described in the article S. Brin and L. Page, “The Anatomy of a Large-Scale Hypertextual Search Engine,” Seventh International World Wide Web Conference, Brisbane, Australia and in U.S. Pat. No. 6,285,999, both of which are incorporated herein by reference each in their entirety. Search results can include, for example, lists of web page titles, snippets of text extracted from those web pages, and hypertext links to those web pages, and may be grouped into a predetermined number of (e.g., ten) search results. - The search service can submit a request for advertisements to the
system 104. The request may include a number of advertisements desired. This number may depend on the search results, the amount of screen or page space occupied by the search results, the size and shape of the advertisements, etc. In some implementations, the number of desired advertisements will be from one to ten, or from three to five. The request for advertisements may also include the query (as entered or parsed), information based on the query (such as geo-location information, whether the query came from an affiliate and an identifier of such an affiliate), and/or information associated with, or based on, the search results. Such information may include, for example, identifiers related to the search results (e.g., document identifiers or “docIDs”), scores related to the search results (e.g., information retrieval (“IR”) scores), snippets of text extracted from identified documents (e.g., web pages), full text of identified documents, feature vectors of identified documents, etc. In some implementations, IR scores can be computed from, for example, dot products of feature vectors corresponding to a query and a document, page rank scores, and/or combinations of IR scores and page rank scores, etc. - The search service can combine the search results with one or more of the advertisements provided by the
system 104. This combined information can then be forwarded to the user 108 that requested the content. The search results can be maintained as distinct from the advertisements, so as not to confuse the user between paid advertisements and presumably neutral search results. Finally, the search service can transmit information about the advertisement and when, where, and/or how the advertisement was to be rendered back to thesystem 104. - As can be appreciated from the foregoing, the
advertising management system 104 can servepublishers 106, such as content servers and search services. Thesystem 104 permits serving of advertisements targeted to content (e.g., documents) served by content servers or in response to search queries provided by users. For example, a network or inter-network may include an advertisement server serving targeted advertisements in response to requests from a search service with advertisement spots for sale. Suppose that the inter-network is the World Wide Web. The search service crawls much or all of the content. Some of this content will include advertisement spots (also referred to as “inventory”) available. More specifically, one or more content servers may include one or more documents. Documents may include web pages, email, content, embedded information (e.g., embedded media), meta-information and machine executable instructions, and advertisement spots available. The advertisements inserted into advertisement spots in a document can vary each time the document is served or, alternatively, can have a static association with a given document. - In one implementation, the requests that the general content servers receive and the queries the search services receive may be in languages that use compound words. Therefore, the terms in the requests and the queries can include compound words. For example, the Germanic languages Afrikaans, Danish, Dutch-Flemish, English, Faroese, Frisian, High German, Gutnish, Icelandic, Low German, Norwegian, Swedish, and Yiddish all include compound words to some extent. The compound words can be created by merging simpler words together. For example, the German word “Blumenstraeusse” (flower bouquet) is made up of Blumen (flower) and Straeusse (bouquet).
- In some implementations, to create a wider coverage for advertisements, the
advertisement system 104 can decompose the compound words into splittings, or substrings, and select one or more of the decomposed words, or substrings, as keywords to search for advertisements. -
FIG. 2 is a block diagram of an exampleword splitting system 200. Theword splitting system 200 can, for example, be implemented in a computer device or one or more computer devices connected through a network, e.g., a local area network (LAN) or a wide area network (WAN), such as the Internet. Theword splitting system 200 can, for example be implemented in theadvertisement system 104, which can be implemented in a computing system. The one or more computing devices can, for example, include memory devices storing processing instructions and processing devices for executing the processing instructions. An example computing system is shown and described with reference toFIG. 8 . Other implementations, however, can also be used. - In addition to splitting a compound word into one or more substrings, the
word splitting system 200 can assign a score to each substring and select one or more of the substrings as a keyword. The score can be calculated based on parameters associated with each substring. In one implementation, the highest scoring substring can be selected as the keyword to use in selecting advertisements. - The
word splitting system 200 can, for example, include asplitting engine 202, adata store 204, and ascoring engine 206. In one implementation, thedata store 204 can comprise a unitary data store, such as a hard drive. In another implementation, thedata store 204 can comprise a distributed data store, such as a storage system that is distributed over a network. Other implementations, however, can also be used. - In one implementation, the
data store 204 can store one or more words, e.g., compound words, and one or more content items, e.g., advertisements. Each word in thedata store 204 can be associated with one or morefirst substrings second substrings third substrings first substrings second substrings third substrings splitting engine 202, as will be described further below. The one or morefirst substrings second substrings third substrings - In one implementation, the
splitting engine 202 can identify one or morefirst substrings first substrings splitting engine 202 can identify possible ways of splitting the word into the one or morefirst substrings first substrings splitting engine 202 can split the word into the following first substrings (hereinafter “exemplary first substrings”): - “k,” “ko,” “kon,” “kont,” “kontr,” “kontro,” “kontrol,” “kontroll,” “kontrollf,” “kontrollfu,” “kontrollfun,” “kontrollfunk,” “kontrollfunkt,” “kontrollfunkti,” “kontrollfunktio,” “kontrollfunktion,” “o,” “on,” “ont,” “ontr,” “ontro,” “ontrol,” “ontroll,” “ontrollf,” “ontrollfu,” “ontrollfun,” “ontrollfunk,” “ontrollfunkt,” “ontrollfunkti,” “ontrollfunktio,” “ontrollfunktion,” “n”, “nt,” “ntr,” “ntro,” “ntrol,” “ntroll,” “ntrollf,” “ntrollfu,” “ntrollfun,” “ntrollfunk,” “ntrollfunkt,” “ntrollfunkti,” “ntrollfunktio,” “ntrollfunktion,” “t,” “tr,” “tro,” “trol,” “troll,” “trollf,” “trollfu,” “trollfun,” “trollfunk,” “trollfunkt,” “trollfunkti,” “trollfunktio,” “trollfunktion,” “r,” “ro,” “rol,” “roll,” “rollf,” “rollfu,” “rollfun,” “rollfunk,” “rollfunkt,” “rollfunkti,” “rollfunktio,” “rollfunktion,” “o,” “ol,” “oll,” “ollf,” “ollfu,” “ollfun,” “ollfunk,” “ollfunkt,” “ollfunkti,” “ollfunktio,” “ollfunktion,” “l,” “ll,” “llf” “llfu,” “llfun,” “llfunk,” “llfunkt,” “llfunkti,” “llfunktio,” “llfunktion,” “f,” “fu,” “fun,” “funk,” “funkt,” “funkti,” “funktio,” “funktion,” “u,” “un,” “unk,” “unkt,” “unkti,” “unktio,” “unktion,” “n,” “nk,” “nkt,” “nkti,” “nktio,” “nktion,” “k,” “kt,” “kti,” “ktio,” “ktion,” “t,” “ti,” “tio,” “tion,” “i,” “io,” “ion,” “on” and “n.” In one implementation, a minimum length can be set to the length of the first substring, for example only considering those with at least three letters.
- In one implementation, the
splitting engine 202 can add afirst morpheme 232 to the one or morefirst substrings second substrings splitting engine 202 can also, for example, remove asecond morpheme 234 from the one or morefirst substrings third substrings - In one implementation, the
first morpheme 232 and thesecond morpheme 234 include Germanic language morphemes. The Germanic languages, as described above, include Afrikaans, Danish, Dutch-Flemish, English, Faroese, Frisian, High German, Gutnish, Icelandic, Low German, Norwegian, Swedish, and Yiddish. Each of these languages can include one or more morphemes. For example, in Dutch, “e” and “s” are morphemes. In German, “e”, “en”, “nen”, “s”, “ens”, “es”, “ns” or “er” are morphemes. The other Germanic languages also include morphemes that consist of one or more letters, as can be appreciated by one skilled in the art. In one implementation, thefirst morpheme 232 and thesecond morpheme 234 can include morphemes from other compound languages that may not be Germanic, for example, Finnish. - In one implementation, the
splitting engine 202 can add afirst morpheme 232 to the beginning and end of each of the one or morefirst substrings second substrings splitting engine 202 can add any of the German morphemes “e”, “en”, “nen”, “s”, “ens”, “es”, “ns” and “er” to the exemplary first substrings. - In one implementation, the
splitting engine 202 can remove thesecond morpheme 234 from the beginning or end of each of the one or morefirst substrings third substrings splitting engine 202 can remove any of the German morphemes “e”, “en”, “nen”, “s”, “ens”, “es”, “ns” and “er” to any of the exemplary first substrings if the substring ends in any of those. - In one implementation, the
splitting engine 202 can select one or more of the one or morefirst substrings second substrings third substrings splitting engine 202 can, for example, select any of the first, second, orthird substrings substrings splitting engine 202 can select “kontroll funktion” as one of thesplittings - In one implementation, the
splitting engine 202 can determine whether the one or more first, second, orthird substrings log 236. The log can, for example, include a query log that includes keywords of previously submittedqueries publishers 106 such as search services received in theadvertisement system 104. The query log can also include previous keywords used in the requests thatpublishers 106, such as the general content servers, received in theadvertisement system 104. Thesplitting engine 202 can determine whether the one or more first, second, orthird substrings log 236. - For example, suppose the
splitting engine 202 added the morphemes “e”, “en”, “nen”, “s”, “ens”, “es”, “ns” and “er” to each of thefirst substrings second substrings first substrings third substrings splitting engine 202 then determined that the second substring “kontrolle,” which is the first substring “kontroll” with the morpheme “e” added, appears in thelog 236. Therefore the second substring “kontrolle” was used previously as a keyword. Suppose also that thesplitting engine 202 also determined that the first substrings “funktion,” “funkt,” and “ion” also appeared in thelog 236. Therefore, the first substrings “funktion,” “funkt,” and “ion” were also previously used as keywords. In one implementation, thesplitting engine 202 can combine the second substring “kontrolle,” as well as the first substrings “funktion,” “funkt,” and “ion” to generate the splittings “kontroll funktion”, “kontrolle function”, “kontroll funkt ion” and “kontrolle funkt ion” as the one or more word splittings 226, 228, 230. - In one implementation, the
scoring engine 206 can generate ascore scoring engine 206 can generate thescore third substrings query log 236 and also based on one or more properties associated with each of the one or more first, second, andthird substrings query log 236, thescoring engine 206 can then calculate thescore splitting engine 202 selected “kontroll funktion” as a splitting. If both of the substrings “kontroll” and “funktion” are in thequery log 236, then thescoring engine 206 can calculate a score for the splitting. - In one implementation, the frequency of each substring as a keyword can be one of one or more parameters associated with each substring in the word splittings 226, 228, 230. For example, the
splitting engine 202 can measure the frequency of the substring “kontrolle” as a keyword in thelog 236 by determining how often the substring “kontrolle” appears in thelog 236. - In one implementation, the probability that a substring appears as a keyword can be one of the parameters associated with each substring in the word splittings 226, 228, 230. The probability can, for example, be calculated by taking the frequency of each substring appearing as a keyword in the
query log 236 and dividing by the total frequency. For example, if the frequency of the substring “kontrolle” is 20, and the total frequency of all the keywords is 100, then the probability that the substring “kontrolle” appears as a query keyword is 20%. - In one implementation, the co-occurrence frequency of every possible substring pair in the same query can be one of the parameters associated with each substring in the word splittings 226, 228, 230. For example, the
splitting engine 202 can measure the number of times that “kontrolle” appears in a query, the number of times that “funktion” appears in a query and the number of times that “kontrolle” and “funktion” appear in the same query. Suppose for example, the queries in thelog 236 show the following substrings appeared with the following frequency: - kontrolle (frequency 2)
- funktion (frequency 1)
- funkt (frequency 4)
- ion (frequency 1)
- kontrolle funktion (frequency 2)
- kontrolle funkt ion (frequency 2).
- The frequencies can be calculated as: “kontrolle”: 6 (this substring appeared in 6 queries) “funktion”: 5 (this substring appeared in 5 queries), “funkt”: 4 (this substring appeared in 4 queries), “kontrolle funktion”: 4 (the substring pair appeared in the same query 4 times), “funktion ion”: 2 (this substring pair appeared in the same query 2 times), and “kontrolle ion”: 2 (this substring pair appeared in the same query 2 times).
- In one implementation, the co-occurrence frequency of every possible substring pair, in the same query and in consecutive positions, can be one of the parameters associated with each substring in the word splittings 226, 228, 230. The
splitting engine 202 can, for example, measure the number of times that both substrings are consecutive in a query in thelog 236. With the previous example, the substring pairs and frequencies are: kontrolle funktion: 4 (2 in “kontrolle funktion”, 2 in “kontrolle funktion ion”) - In one implementation, the mutual information of each substring pair can be one of the parameters associated with each substring in the word splittings 226, 228, 230. The mutual information can be estimated from the substring frequencies and their co-occurrence frequencies. The mutual information, or transinformation, of two random variables e.g., substring frequencies and their co-occurrence frequencies, is a quantity that measures the mutual dependence of the two variables. The mutual information of two random variables can be calculated as follows:
-
- Where p(x) is the frequency of substring “x” in the query logs divided by the sum of the frequencies of all substrings. The probability p(x,y) is the frequency of substrings “x” and “y” co-occurring in the same query divided by the sum of frequencies of occurrences of every possible pair of substrings.
- In one implementation, the probabilities of each substring can be one of the parameters associated with each substring in the word splittings 226, 228, 230. The probability of each substring is the frequency that the substring appears in the
log 236 divided by the total number of substrings in the search queries in thelog 236. If, for example, a substring “w” appears 20 times in the queries in thelog 236, and a total of 1000 substrings exist in the queries in thelog 236, the probability of “w” is 20/1000=0.02. - In one implementation, the co-occurrence frequencies of a compound word and the decompounded form of that word in anchor texts from hyperlinks pointing to a same web document can be parameters associated with each substring in the word splittings 226, 228, 230. Anchor text is the text that appears in a hyperlink on the web. If, for example, two web pages have a hyperlink to the same document, then the texts in those hyperlinks can be related, because the anchor texts usually describes the place where a user is directed if the user clicks on the link. Therefore, if the anchor text of a hyperlink to a web page contains the substring “kontrollfunktion,” and in the anchor text of a hyperlink to the same web page exists “kontrolle funktion,” then a good indication exists that all substrings, e.g., “kontrollfunktion,” and “kontrolle funktion” are the same, written as a compound or separately.
- In one implementation, the frequency of each substring as an advertiser keyword can be one of the parameters associated with each substring in the word splittings 226, 228, 230. The
splitting engine 202 can, for example, measure the number of times each substring was previously used as a keyword by searching thelog 236. - In one implementation, the co-occurrence frequencies of substrings as the same advertiser keyword, the co-occurrence frequencies of substrings in different keywords from the same advertisement, and the co-occurrence of a compound word and the decompounded form of that word (with blank spaces between the parts) as different keywords for the same advertisement can be parameters associated with each substring in the word splittings 226, 228, 230. For example, in the
advertisement system 104, advertisers can bid on particular keywords for their advertisements to be shown. Therefore, an advertiser may bid on keywords such as “kontrolle,” “funkt,” or “funktion.” If a word “kontrollfunktion” exists that can be decomposed in two parts, or substrings, “kontrolle” and “funktion,” and many advertisers that bid on “kontrolle” are also bidding on “funktion,” or on both, that is also an indication that “kontrollfunktion” is probably a compound word and “kontrolle funktion” is the correct way to split it. - Therefore, given a word w=“kontrollfunktion,” and the possible split w1+w2=“kontrolle”+“funktion,” the
scoring engine 206 can determine the percentage of times that w1 and w2 appear together in the same keyword or campaign (of any advertisers), indicating that w1 and w2 exist as substrings and their meanings are related. A campaign, as defined herein, is a list of all keywords selected by an advertiser for one or more advertisements associated with the advertiser. Thescoring engine 206 can evaluate and look for advertisers having an advertisement campaign that is targeted both for “kontrolle” and for “funktion.” - In one implementation, the
scoring engine 206 can determine the percentage of advertisers that bid for w and w1 as different keywords in the same campaign, the percentage of advertisers that bid for w and w2 as different keywords in the same campaign, and the percentage of advertisers that bid for w, w1 and w2 as different keywords in the same campaign. In one implementation, these three metrics indicate that w is probably a compound, and either w1, w2, or both can replace the compound word as keywords in an ad campaign, so they are probably related to each other. - Suppose, for example, advertisers are bidding both for “kontrollfunktion” and “kontrolle funktion.” The
scoring engine 206 can evaluate the percentage of advertisers that bid on “kontrollfunktion” and “kontrolle funktion” as different keywords in the same campaign, e.g., the compound and the phrase containing both words separately. Here, thescoring engine 206 would evaluate advertisers bidding on “kontrollfunktion” and “kontrolle funktion.” - In one implementation, the
scoring engine 206 can apply a machine learning algorithm to the parameters of each substring in the word splitting to calculate ascore scoring engine 206 can determine which word splitting 226, 228, 230 is the word splitting that would yield the highest score. The machine learning algorithm can, for example, be a support vector machine as described in J. Platt, Fast Training of Support Vector Machines using Sequential Minimal Optimization, in Advances in Kernel Methods—Support Vector Learning, B. Schölkopf, C. Burges, and A. Smola, eds., MIT Press (1998). The support vector machine can use any of the one or more parameters described above to calculate thescores - The support vector machine can, for example, train on a model built from previous data. The model can includes previous words as well as whether these words are compounds or not and, in the case that they are compounds, how the words should be decompounded, or split into substrings. Therefore, for each of these words, any possible way of splitting the words into substrings has been indicated, and for each possible substring of each word, all the above parameters have been calculated, and the correct substring, e.g., the substring with the highest score, has been indicated.
- Using the support vector machine that has been trained with the model described above, when the
splitting engine 202 receives a word, thesplitting engine 202 can generate every possible way of splitting this word into substrings as described above, and apply the support vector machine to score the substrings, and score the splittings. Thescoring engine 206 can then select one of the one or more word splittings 226, 228, 230 with the highest score as calculated by the support vector machine. - In one implementation, the
scoring engine 206 can rank the one or more word splittings 226, 228, 230 based on thescores scoring engine 206 can rank the word splittings 226, 228, 230 by decreasing score. In another implementation, one or more of these parameters can be directly applied to rank the substrings without calculating a score for the substrings. For example, the mutual information metric, the geometric mean of the frequencies of the compound parts, or a product of the probabilities of the compound parts are all functions that can be used to rank the word splittings 226, 228, 230. - In one implementation, outside sources can be considered in determining whether the
splitting engine 202 should split a compound word. For example, outside sources such as dictionaries from several languages, lists and gazetteers of locations, proper nouns of people (first names and family names), organizations, trademarks, and suffixes of the words can be considered by thesplitting engine 202. These outside sources can contain words that thesplitting engine 202 may not want split. For example, German words ending by “strasse” or “dorf” are usually place names and should be considered as proper nouns and not decompounded or split into substrings. - In one implementation, the substring selected from the one or more word splittings 226, 228, 230 with the
highest score keyword 244. Thescoring engine 206 can select one or more advertisements associated with thekeyword 244. For example, suppose thescoring engine 206 uses the support vector machine and determines the scores for the one or more word splittings 226, 228, 230 “kontrolle funktion,” “kontroll funktion” “kontrolle funkt ion,” and “kontroll funkt ion” are 50, 40, 30, and 20, respectively. Thescoring engine 206 can select the highest scoring substring “kontrolle funktion,” with the high score of 50, as the keyword to use in selecting advertisements. Therefore, even though the initial word used in the query was “kontrollfunktion,” thesplitting engine 202 split the word into substrings, andscoring engine 206 selected the highest scoring splitting “kontrolle function” as the keyword. Thescoring engine 206 can select one or more advertisements associated with the keywords “kontrolle” and “function” in response to a search query using the word “kontrollfunktion.” -
FIG. 3 is a flow diagram of anexample process 300 for splitting a compound word. Theprocess 300 can, for example, be implemented in a system such as theword splitting system 200 ofFIG. 2 . -
Stage 302 identifies a substring of a word. For example, thesplitting engine 202 can identify a substring of a word.Stage 304 determines whether the substring appears in a query log. For example, thesplitting engine 202 can determine whether the substring appears in a query log.Stage 306 generates a score for the substring based on a determination that the substring appears in a query log and one or more properties associated with the substring. For example, thescoring engine 206 can generate a score for the substring based on a determination that the substring appears in a query log and one or more properties associated with the substring.Stage 308 selects the substring as a keyword. For example, thescoring engine 206 can select the substring as a keyword. -
FIG. 4 is a flow diagram of anotherexample process 400 for splitting a word. Theprocess 400 can, for example, be implemented in a system such as theword splitting system 200 ofFIG. 2 .Stage 402 identifies second or more substrings of a word. For example, thesplitting engine 402 can identify second or more substrings of a word.Stage 404 determines whether the second or more substrings appear in a query log. For example, thesplitting engine 202 can determine whether the second or more substrings appear in a query log.Stage 406 generates a score for each of the substrings based on a determination that each of the substrings appears in a query log and one or more properties associated with the substring. For example, thescoring engine 206 can generate a score for each of the substrings based on a determination that each of the substrings appears in a query log and one or more properties associated with the substring.Stage 408 identifies one of the second or more substrings with a score higher than the other substrings. For example, thescoring engine 206 can identify one of the second or more substrings with a score higher than the other substrings. -
FIG. 5 is a flow diagram of anotherexample process 500 for splitting a word. Theprocess 500 can, for example, be implemented in a system such as theword splitting system 200 ofFIG. 2 .Stage 502 identifies one or more first substrings of a word. For example, thesplitting engine 202 can identify one or more first substrings of a word.Stage 504 adds a first morpheme to the one or more first substrings to create one or more second substrings. For example, thesplitting engine 202 can add a first morpheme to the one or more first substrings to create one or more second substrings.Stage 506 removes a second morpheme from the one or more first substrings to create one or more third substrings. For example, thesplitting engine 202 can remove a second morpheme from the one or more first substrings to create one or more third substrings.Stage 508 can select one or more of the one or more first, second, and third substrings as one or more splittings of the word. For example, thesplitting engine 202 can select one or more of the one or more first, second, and third substrings as one or more splittings of the word.Stage 510 determines whether the one or more first, second, or third substrings appear in a query log. For example, thesplitting engine 202 can determine whether the one or more first, second, or third substrings appear in a query log. -
Stage 512 generates a score for each of the one or more splittings based on a determination that the one or more first, second, or third substrings appear in the query log and one or more properties associated with each of the one or more first, second, and third substrings that are selected as part of each of the one or more splittings. For example, thescoring engine 206 can generate a score for each of the one or more splittings based on a determination that the one or more first, second, or third substrings appear in the query log and one or more properties associated with each of the one or more first, second, and third substrings that are selected as part of each of the one or more splittings.Stage 514 selects a splitting selected from among the one or more splittings with a score higher than the other one or more splittings as a keyword. For example, thescoring engine 206 can select a splitting selected from among the one or more splittings with a score higher than the other one or more splittings as a keyword. -
FIG. 6 is a flow diagram of anotherexample process 600 for splitting a word. Theprocess 600 can, for example, be implemented in a system such asword splitting system 200 ofFIG. 2 .Stage 602 splits a word into one or more first substrings. For example, thesplitting engine 202 can split a word into one or more first substrings.Stage 604 applies a morpheme to the one or more first substrings to create one or more second substrings. For example, thesplitting engine 202 can apply a morpheme with the one or more first substrings to create one or more second and one or more third substrings.Stage 606 determines whether the one or more first, second, or third substrings appear in a query log. For example, thesplitting engine 202 can determine whether the one or more first, second, or third substrings appear in a query log. -
Stage 608 selects one or more of the one or more first, second, and third substrings as one or more splittings of the word. For example, thesplitting engine 202 can select one or more of the one or more first, second, and third substrings as one or more splittings of the word.Stage 610 generates a score for each of the one or more splittings based on a determination that the one or more first, second, or third substrings appear in the query log and one or more properties associated with each of the one or more first, second, and third substrings. For example, thesplitting engine 202 can generate a score for each of the one or more splittings based on a determination that the one or more first, second, or third substrings appear in the query log and one or more properties associated with each of the one or more first, second, and third substrings.Stage 612 selects a splitting selected from among the one or more splittings based on the score. For example, thescoring engine 206 can select a splitting selected from among the one or more splittings based on the score. -
FIG. 7 is a flow diagram of anexample process 700 for applying a morpheme to one or more first substrings. Theprocess 700 can, for example, be implemented in a system such as theword splitting system 200 ofFIG. 2 .Stage 702 adds a first morpheme to the one or more first substrings to create the one or more second substrings. For example, thesplitting engine 202 can add a first morpheme to the one or more first substrings to create one or more second substrings.Stage 704 removes a second morpheme from the one or more first substrings to create the one or more third substrings. For example, thesplitting engine 202 can remove a second morpheme from the one or more first substrings to create one or more third substrings. -
FIG. 8 is block diagram of anexample computer system 800. Thesystem 800 includes aprocessor 810, amemory 820, astorage device 830, and an input/output device 840. Each of thecomponents system bus 850. Theprocessor 810 is capable of processing instructions for execution within thesystem 800. In one implementation, theprocessor 810 is a single-threaded processor. In another implementation, theprocessor 810 is a multi-threaded processor. Theprocessor 810 is capable of processing instructions stored in thememory 820 or on thestorage device 830. - The
memory 820 stores information within thesystem 800. In one implementation, thememory 820 is a computer-readable medium. In one implementation, thememory 820 is a volatile memory unit. In another implementation, thememory 820 is a non-volatile memory unit. - The
storage device 830 is capable of providing mass storage for thesystem 800. In one implementation, thestorage device 830 is a computer-readable medium. In various different implementations, thestorage device 830 can, for example, include a hard disk device, an optical disk device, or some other large capacity storage device. - The input/
output device 840 provides input/output operations for thesystem 800. In one implementation, the input/output device 840 can include one or more of a network interface devices, e.g., an Ethernet card, a serial communication device, e.g., and RS-232 port, and/or a wireless interface device, e.g., and 802.11 card. In another implementation, the input/output device can include driver devices configured to receive input data and send output data to other input/output devices, e.g., keyboard, printer anddisplay devices 860. Other implementations, however, can also be used, such as mobile computing devices, mobile communication devices, set-top box television client devices, etc. - Although the above description refers to a content item such as an advertisement, content items such as video and/or audio files, web pages for particular subjects, news articles, etc. can also be used. Also, the implementations can be used with other compound words such as for example, Finnish, as well as other languages that include compound words. Furthermore, while the above description refers to online advertisements, the implementation described can also be used with other possible applications such as, for example, machine translation, speech recognition, information retrieval, etc.
- The apparatus, methods, flow diagrams, and structure block diagrams described in this patent document may be implemented in computer processing systems including program code comprising program instructions that are executable by the computer processing system. Other implementations may also be used. Additionally, the flow diagrams and structure block diagrams described in this patent document, which describe particular methods and/or corresponding acts in support of steps and corresponding functions in support of disclosed structural means, may also be utilized to implement corresponding software structures and algorithms, and equivalents thereof.
- This written description sets forth the best mode of the invention and provides examples to describe the invention and to enable a person of ordinary skill in the art to make and use the invention. This written description does not limit the invention to the precise terms set forth. Thus, while the invention has been described in detail with reference to the examples set forth above, those of ordinary skill in the art may effect alterations, modifications and variations to the examples without departing from the scope of the invention.
Claims (21)
Priority Applications (4)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US11/849,728 US8046355B2 (en) | 2007-09-04 | 2007-09-04 | Word decompounder |
PCT/US2008/075275 WO2009032940A1 (en) | 2007-09-04 | 2008-09-04 | Word decompounder |
EP08799178A EP2195756A4 (en) | 2007-09-04 | 2008-09-04 | Word decompounder |
US13/246,755 US8380734B2 (en) | 2007-09-04 | 2011-09-27 | Word decompounder |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US11/849,728 US8046355B2 (en) | 2007-09-04 | 2007-09-04 | Word decompounder |
Related Child Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US13/246,755 Continuation US8380734B2 (en) | 2007-09-04 | 2011-09-27 | Word decompounder |
Publications (2)
Publication Number | Publication Date |
---|---|
US20090063462A1 true US20090063462A1 (en) | 2009-03-05 |
US8046355B2 US8046355B2 (en) | 2011-10-25 |
Family
ID=40409068
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US11/849,728 Active 2030-04-11 US8046355B2 (en) | 2007-09-04 | 2007-09-04 | Word decompounder |
US13/246,755 Active US8380734B2 (en) | 2007-09-04 | 2011-09-27 | Word decompounder |
Family Applications After (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US13/246,755 Active US8380734B2 (en) | 2007-09-04 | 2011-09-27 | Word decompounder |
Country Status (3)
Country | Link |
---|---|
US (2) | US8046355B2 (en) |
EP (1) | EP2195756A4 (en) |
WO (1) | WO2009032940A1 (en) |
Cited By (13)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20090299998A1 (en) * | 2008-02-15 | 2009-12-03 | Wordstream, Inc. | Keyword discovery tools for populating a private keyword database |
US20110208715A1 (en) * | 2010-02-23 | 2011-08-25 | Microsoft Corporation | Automatically mining intents of a group of queries |
US20120265756A1 (en) * | 2010-12-08 | 2012-10-18 | S.L.I. Systems, Inc. | Method for determining relevant search results |
US8650173B2 (en) | 2010-06-23 | 2014-02-11 | Microsoft Corporation | Placement of search results using user intent |
US20140188894A1 (en) * | 2012-12-27 | 2014-07-03 | Google Inc. | Touch to search |
US20150012560A1 (en) * | 2013-07-03 | 2015-01-08 | Google Inc. | Methods and systems for providing potential search queries that may be targeted by one or more keywords |
US9043409B2 (en) | 2009-06-11 | 2015-05-26 | Qualcomm Incorporated | Methods and apparatus for a plug-in model for publishing structured meta-data based discovery |
US9152652B2 (en) | 2013-03-14 | 2015-10-06 | Google Inc. | Sub-query evaluation for image search |
US9679043B1 (en) * | 2013-06-24 | 2017-06-13 | Google Inc. | Temporal content selection |
US20170277679A1 (en) * | 2016-03-23 | 2017-09-28 | Kabushiki Kaisha Toshiba | Information processing device, information processing method, and computer program product |
US20200065378A1 (en) * | 2018-02-27 | 2020-02-27 | International Business Machines Corporation | Technique for automatically splitting words |
US20220198159A1 (en) * | 2020-12-22 | 2022-06-23 | Yandex Europe Ag | Methods and systems for creating a training dataset for training a machine learning algorithm (mla) for a machine-translation task |
US11546376B2 (en) * | 2019-09-25 | 2023-01-03 | Citrix Systems, Inc. | Systems and methods for securing user domain credentials from phishing attacks |
Families Citing this family (10)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7958136B1 (en) * | 2008-03-18 | 2011-06-07 | Google Inc. | Systems and methods for identifying similar documents |
US8364718B2 (en) * | 2008-10-31 | 2013-01-29 | International Business Machines Corporation | Collaborative bookmarking |
US8156111B2 (en) * | 2008-11-24 | 2012-04-10 | Yahoo! Inc. | Identifying and expanding implicitly temporally qualified queries |
WO2011100573A1 (en) * | 2010-02-12 | 2011-08-18 | Google Inc. | Compound splitting |
JP2012027722A (en) * | 2010-07-23 | 2012-02-09 | Sony Corp | Information processing unit, information processing method and information processing program |
KR101850886B1 (en) * | 2010-12-23 | 2018-04-23 | 네이버 주식회사 | Search system and mehtod for recommending reduction query |
US10430806B2 (en) | 2013-10-15 | 2019-10-01 | Adobe Inc. | Input/output interface for contextual analysis engine |
US10235681B2 (en) | 2013-10-15 | 2019-03-19 | Adobe Inc. | Text extraction module for contextual analysis engine |
US9990422B2 (en) | 2013-10-15 | 2018-06-05 | Adobe Systems Incorporated | Contextual analysis engine |
US10952457B2 (en) | 2015-11-16 | 2021-03-23 | Whitewave Services, Inc. | Taste characteristics in soy-based food products using high-protein soybeans |
Citations (15)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5223924A (en) * | 1992-05-27 | 1993-06-29 | North American Philips Corporation | System and method for automatically correlating user preferences with a T.V. program information database |
US6349282B1 (en) * | 1999-04-20 | 2002-02-19 | Larnout & Hauspie Speech Products N.V. | Compound words in speech recognition systems |
US6393399B1 (en) * | 1998-09-30 | 2002-05-21 | Scansoft, Inc. | Compound word recognition |
US20020194173A1 (en) * | 2001-03-22 | 2002-12-19 | Bjornson Robert D. | Method and apparatus for high-performance sequence comparison |
US20030074353A1 (en) * | 1999-12-20 | 2003-04-17 | Berkan Riza C. | Answer retrieval technique |
US20030158725A1 (en) * | 2002-02-15 | 2003-08-21 | Sun Microsystems, Inc. | Method and apparatus for identifying words with common stems |
US20040254920A1 (en) * | 2003-06-16 | 2004-12-16 | Brill Eric D. | Systems and methods that employ a distributional analysis on a query log to improve search results |
US20050033565A1 (en) * | 2003-07-02 | 2005-02-10 | Philipp Koehn | Empirical methods for splitting compound words with application to machine translation |
US20050149514A1 (en) * | 2004-01-06 | 2005-07-07 | Takashi Tsuzuki | Information retrieval apparatus and information retrieval support apparatus |
US20050197829A1 (en) * | 2004-03-03 | 2005-09-08 | Microsoft Corporation | Word collection method and system for use in word-breaking |
US20050222998A1 (en) * | 2004-03-31 | 2005-10-06 | Oce-Technologies B.V. | Apparatus and computerised method for determining constituent words of a compound word |
US20050262050A1 (en) * | 2004-05-07 | 2005-11-24 | International Business Machines Corporation | System, method and service for ranking search results using a modular scoring system |
US20060248076A1 (en) * | 2005-04-21 | 2006-11-02 | Case Western Reserve University | Automatic expert identification, ranking and literature search based on authorship in large document collections |
US7254774B2 (en) * | 2004-03-16 | 2007-08-07 | Microsoft Corporation | Systems and methods for improved spell checking |
US7577643B2 (en) * | 2006-09-29 | 2009-08-18 | Microsoft Corporation | Key phrase extraction from query logs |
Family Cites Families (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6285999B1 (en) | 1997-01-10 | 2001-09-04 | The Board Of Trustees Of The Leland Stanford Junior University | Method for node ranking in a linked database |
US7249121B1 (en) | 2000-10-04 | 2007-07-24 | Google Inc. | Identification of semantic units from within a search query |
US7818315B2 (en) * | 2006-03-13 | 2010-10-19 | Microsoft Corporation | Re-ranking search results based on query log |
-
2007
- 2007-09-04 US US11/849,728 patent/US8046355B2/en active Active
-
2008
- 2008-09-04 WO PCT/US2008/075275 patent/WO2009032940A1/en active Application Filing
- 2008-09-04 EP EP08799178A patent/EP2195756A4/en not_active Ceased
-
2011
- 2011-09-27 US US13/246,755 patent/US8380734B2/en active Active
Patent Citations (15)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5223924A (en) * | 1992-05-27 | 1993-06-29 | North American Philips Corporation | System and method for automatically correlating user preferences with a T.V. program information database |
US6393399B1 (en) * | 1998-09-30 | 2002-05-21 | Scansoft, Inc. | Compound word recognition |
US6349282B1 (en) * | 1999-04-20 | 2002-02-19 | Larnout & Hauspie Speech Products N.V. | Compound words in speech recognition systems |
US20030074353A1 (en) * | 1999-12-20 | 2003-04-17 | Berkan Riza C. | Answer retrieval technique |
US20020194173A1 (en) * | 2001-03-22 | 2002-12-19 | Bjornson Robert D. | Method and apparatus for high-performance sequence comparison |
US20030158725A1 (en) * | 2002-02-15 | 2003-08-21 | Sun Microsystems, Inc. | Method and apparatus for identifying words with common stems |
US20040254920A1 (en) * | 2003-06-16 | 2004-12-16 | Brill Eric D. | Systems and methods that employ a distributional analysis on a query log to improve search results |
US20050033565A1 (en) * | 2003-07-02 | 2005-02-10 | Philipp Koehn | Empirical methods for splitting compound words with application to machine translation |
US20050149514A1 (en) * | 2004-01-06 | 2005-07-07 | Takashi Tsuzuki | Information retrieval apparatus and information retrieval support apparatus |
US20050197829A1 (en) * | 2004-03-03 | 2005-09-08 | Microsoft Corporation | Word collection method and system for use in word-breaking |
US7254774B2 (en) * | 2004-03-16 | 2007-08-07 | Microsoft Corporation | Systems and methods for improved spell checking |
US20050222998A1 (en) * | 2004-03-31 | 2005-10-06 | Oce-Technologies B.V. | Apparatus and computerised method for determining constituent words of a compound word |
US20050262050A1 (en) * | 2004-05-07 | 2005-11-24 | International Business Machines Corporation | System, method and service for ranking search results using a modular scoring system |
US20060248076A1 (en) * | 2005-04-21 | 2006-11-02 | Case Western Reserve University | Automatic expert identification, ranking and literature search based on authorship in large document collections |
US7577643B2 (en) * | 2006-09-29 | 2009-08-18 | Microsoft Corporation | Key phrase extraction from query logs |
Cited By (18)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20090299998A1 (en) * | 2008-02-15 | 2009-12-03 | Wordstream, Inc. | Keyword discovery tools for populating a private keyword database |
US9043409B2 (en) | 2009-06-11 | 2015-05-26 | Qualcomm Incorporated | Methods and apparatus for a plug-in model for publishing structured meta-data based discovery |
US20110208715A1 (en) * | 2010-02-23 | 2011-08-25 | Microsoft Corporation | Automatically mining intents of a group of queries |
US8650173B2 (en) | 2010-06-23 | 2014-02-11 | Microsoft Corporation | Placement of search results using user intent |
US9460161B2 (en) | 2010-12-08 | 2016-10-04 | S.L.I. Systems, Inc. | Method for determining relevant search results |
US20120265756A1 (en) * | 2010-12-08 | 2012-10-18 | S.L.I. Systems, Inc. | Method for determining relevant search results |
US9990442B2 (en) | 2010-12-08 | 2018-06-05 | S.L.I. Systems, Inc. | Method for determining relevant search results |
US20140188894A1 (en) * | 2012-12-27 | 2014-07-03 | Google Inc. | Touch to search |
US9152652B2 (en) | 2013-03-14 | 2015-10-06 | Google Inc. | Sub-query evaluation for image search |
US9679043B1 (en) * | 2013-06-24 | 2017-06-13 | Google Inc. | Temporal content selection |
US10628453B1 (en) | 2013-06-24 | 2020-04-21 | Google Llc | Temporal content selection |
US9378517B2 (en) * | 2013-07-03 | 2016-06-28 | Google Inc. | Methods and systems for providing potential search queries that may be targeted by one or more keywords |
US20150012560A1 (en) * | 2013-07-03 | 2015-01-08 | Google Inc. | Methods and systems for providing potential search queries that may be targeted by one or more keywords |
US20170277679A1 (en) * | 2016-03-23 | 2017-09-28 | Kabushiki Kaisha Toshiba | Information processing device, information processing method, and computer program product |
US20200065378A1 (en) * | 2018-02-27 | 2020-02-27 | International Business Machines Corporation | Technique for automatically splitting words |
US10909316B2 (en) * | 2018-02-27 | 2021-02-02 | International Business Machines Corporation | Technique for automatically splitting words |
US11546376B2 (en) * | 2019-09-25 | 2023-01-03 | Citrix Systems, Inc. | Systems and methods for securing user domain credentials from phishing attacks |
US20220198159A1 (en) * | 2020-12-22 | 2022-06-23 | Yandex Europe Ag | Methods and systems for creating a training dataset for training a machine learning algorithm (mla) for a machine-translation task |
Also Published As
Publication number | Publication date |
---|---|
US8380734B2 (en) | 2013-02-19 |
EP2195756A1 (en) | 2010-06-16 |
EP2195756A4 (en) | 2012-11-28 |
US20120023111A1 (en) | 2012-01-26 |
WO2009032940A1 (en) | 2009-03-12 |
US8046355B2 (en) | 2011-10-25 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US8046355B2 (en) | Word decompounder | |
JP5281405B2 (en) | Selecting high-quality reviews for display | |
US8825571B1 (en) | Multiple correlation measures for measuring query similarity | |
US8799260B2 (en) | Method and system for generating web pages for topics unassociated with a dominant URL | |
US9251206B2 (en) | Generalized edit distance for queries | |
US7657514B2 (en) | Content identification expansion | |
US7689554B2 (en) | System and method for identifying related queries for languages with multiple writing systems | |
US20090287676A1 (en) | Search results with word or phrase index | |
US20120303444A1 (en) | Semantic advertising selection from lateral concepts and topics | |
CA2534062C (en) | Methods and systems for determining a meaning of a document to match the document to content | |
US20070050389A1 (en) | Advertisement placement based on expressions about topics | |
US20060287920A1 (en) | Method and system for contextual advertisement delivery | |
US20070078671A1 (en) | Selecting high quality text within identified reviews for display in review snippets | |
US20090006207A1 (en) | Using Previous User Search Query To Target Advertisements | |
US20070078845A1 (en) | Identifying clusters of similar reviews and displaying representative reviews from multiple clusters | |
US20110258054A1 (en) | Automatic Generation of Bid Phrases for Online Advertising | |
US20080270364A1 (en) | Expansion rule evaluation | |
US20180060921A1 (en) | Augmenting visible content of ad creatives based on documents associated with linked to destinations | |
US20080065620A1 (en) | Recommending advertising key phrases | |
US11609943B2 (en) | Contextual content distribution | |
US9129306B1 (en) | Tie breaking rules for content item matching | |
Dinsoreanu et al. | A layered approach for enabling context-sensitive content |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:ALFONSECA, ENRIQUE;PHARIES, STEFAN H.;REEL/FRAME:019907/0125Effective date: 20070904 |
|
AS | Assignment |
Owner name: AT&T INTELLECTUAL PROPERTY I, L.P., F/K/A AT&T BLSFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:RAUBA, RIMAS;SALAZAR, GONZALO;REEL/FRAME:024147/0645Effective date: 20070824 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
CC | Certificate of correction | ||
FPAY | Fee payment |
Year of fee payment: 4 |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044101/0405Effective date: 20170929 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 8TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1552); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 8 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 12TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1553); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 12 |