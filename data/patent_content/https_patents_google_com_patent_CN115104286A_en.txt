CN115104286A - Encrypted search system design for e-mail client encryption - Google Patents
Encrypted search system design for e-mail client encryption Download PDFInfo
- Publication number
- CN115104286A CN115104286A CN202080096337.0A CN202080096337A CN115104286A CN 115104286 A CN115104286 A CN 115104286A CN 202080096337 A CN202080096337 A CN 202080096337A CN 115104286 A CN115104286 A CN 115104286A
- Authority
- CN
- China
- Prior art keywords
- encrypted
- count
- storage device
- key
- untrusted storage
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/60—Protecting data
- G06F21/602—Providing cryptographic facilities or services
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L63/00—Network architectures or network communication protocols for network security
- H04L63/04—Network architectures or network communication protocols for network security for providing a confidential data exchange among entities communicating through data packet networks
- H04L63/0428—Network architectures or network communication protocols for network security for providing a confidential data exchange among entities communicating through data packet networks wherein the data content is protected, e.g. by encrypting or encapsulating the payload
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L9/00—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols
- H04L9/006—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols involving public key infrastructure [PKI] trust models
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L9/00—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols
- H04L9/06—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols the encryption apparatus using shift registers or memories for block-wise or stream coding, e.g. DES systems or RC4; Hash functions; Pseudorandom sequence generators
- H04L9/0643—Hash functions, e.g. MD5, SHA, HMAC or f9 MAC
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L9/00—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols
- H04L9/06—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols the encryption apparatus using shift registers or memories for block-wise or stream coding, e.g. DES systems or RC4; Hash functions; Pseudorandom sequence generators
- H04L9/065—Encryption by serially and continuously modifying data stream elements, e.g. stream cipher systems, RC4, SEAL or A5/3
- H04L9/0656—Pseudorandom key sequence combined element-for-element with data sequence, e.g. one-time-pad [OTP] or Vernam's cipher
- H04L9/0662—Pseudorandom key sequence combined element-for-element with data sequence, e.g. one-time-pad [OTP] or Vernam's cipher with particular pseudorandom sequence generator
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L9/00—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols
- H04L9/08—Key distribution or management, e.g. generation, sharing or updating, of cryptographic keys or passwords
- H04L9/0894—Escrow, recovery or storing of secret information, e.g. secret key escrow or cryptographic key storage
Abstract
A method (900) for providing an encrypted search system comprising: a search query (122) for a keyword (32) is received, the keyword (32) appearing in one or more encrypted emails (152) stored on an untrusted storage device (150), and a count table (210) is accessed to obtain a count (212) of unique emails that include the keyword. The method also includes generating a delegated pseudo-random function (DPRF) based on the key, a private encryption key (124), and a count of the unique emails that include the key (126), and delegating at least a portion of the DPRF (126) to an untrusted storage device (150), causing the storage device to evaluate the delegated DPRF, accessing an encrypted search index associated with the email (160), and determining one or more encrypted emails associated with the delegated DPRF. The storage device also returns to the user device an identifier for each encrypted email associated with the delegated DPRF (154).
Description
Technical Field
The present disclosure relates to an encrypted search system design for email client encryption.
Background
Searchable encryption (i.e., encrypted searching) is also becoming increasingly popular as the storage of large amounts of data in the cloud becomes more prevalent. More and more users or clients have a large corpus of encrypted documents that are stored on a server that is not under the control of the client (i.e., the server is not trusted). With searchable encryption, clients can store their encrypted documents on untrusted servers, yet retain the ability to search for documents and, for example, retrieve identifiers for all documents that include a particular keyword. However, such searchable encryption is generally associated with security and privacy drawbacks.
Disclosure of Invention
One aspect of the present disclosure provides a method for providing an encrypted search system design for email client encryption. The method includes receiving, at data processing hardware of a user device associated with a user, a search query for keywords that appear in one or more encrypted emails within a corpus of encrypted emails stored on an untrusted storage device. The method also includes accessing, by the data processing hardware, the count table to obtain a count of unique emails within the corpus of encrypted emails that include the keyword. The method further includes generating a delegateable pseudo-random function (DPRF) based on the key, the private encryption key, and a count of unique emails that include the key, and delegating at least a portion of the DPRF to an untrusted storage device, at least a portion of the delegated DPRF upon receipt by the untrusted storage device, causing the untrusted storage device to evaluate at least a portion of the delegated DPRF. The untrusted storage device further includes accessing an encrypted search index associated with a corpus of encrypted emails stored on the untrusted storage device, determining, based on the encrypted search index, one or more encrypted emails within the corpus of encrypted emails that are associated with at least a portion of the delegated DPRF. The untrusted storage device returns to the user device an identifier for each of at least a portion of the one or more encrypted emails associated with at least a portion of the delegated DPRF.
Embodiments of the present disclosure may include one or more of the following optional features. In some embodiments, the count table is encrypted using a second private encryption key that is only available to the user, and the encrypted count table is stored on an untrusted storage device. In some examples, the encrypted count table includes a plurality of buckets, each bucket storing one or more counts of unique emails within the corpus of encrypted emails that include a respective key, accessing the count table to obtain a count of unique emails within the corpus of encrypted emails that include a key may include sending a bucket request to the untrusted storage device indicating a particular bucket of the plurality of buckets, the bucket request, when received by the untrusted storage device, causing the untrusted storage device to return each count stored within the particular bucket to the user device.
Optionally, as the untrusted storage device returns each count stored within a particular bucket, the untrusted storage device also returns each count associated with one or more other buckets that are dynamically associated with the particular bucket. In some embodiments, the untrusted storage device returns each count associated with one or more other buckets that are dynamically associated with the particular bucket based on a total number of counts in the particular bucket.
In some embodiments, the method further comprises assigning, by the data processing hardware, each count to a respective bucket based on an output of the second DPRF. Accessing the count table to obtain a count of unique emails including the key within the corpus of encrypted emails includes downloading at least a portion of the count table from an untrusted storage device. In some examples, for each unique key of a new encrypted email uploaded by a user into a corpus of encrypted emails stored on an untrusted storage device, determining whether to add the new key to a count table based on probabilities, the new key not currently existing in the count table, when the data processing hardware determines to add the new key, adding the new key and the new key count to the count table, generating a unique key hash based on the private encryption key, the corresponding unique key, and the new key count, generating a hash pair, the hash pair comprising the unique key hash and an encrypted email identifier associated with the new encrypted email uploaded by the user, sending the hash pair to the untrusted storage device.
When the data processing hardware determines not to add a new key, a unique key hash is generated based on the private encryption key, a corresponding unique key, and the random key count, a hash pair is generated, the hash pair including the unique key hash and an encrypted email identifier associated with the new encrypted email uploaded by the user, the hash pair is sent to the untrusted storage device. The probability that a new key will be added to the count table is one fiftieth.
Another aspect of the disclosure provides a system for providing an encrypted search system design for email client encryption. The system includes data processing hardware of a user device associated with a user, memory hardware in communication with the data processing hardware, the memory hardware storing instructions that, when executed on the data processing hardware, cause the data processing hardware to perform operations comprising receiving a search query for a keyword that appears in one or more encrypted emails stored within a corpus of encrypted emails on an untrusted storage device. The count table is accessed to obtain a count of unique emails within the corpus of encrypted emails that include the keyword. A trusted pseudo-random function (DPRF) is generated based on the key, the private encryption key, and a count of unique emails that include the key. Delegating at least a portion of the DPRF to an untrusted memory device, the delegated at least a portion of the DPRF upon receipt by the untrusted memory device, causing the untrusted memory device to evaluate the delegated at least a portion of the DPRF. An encrypted search index associated with a corpus of encrypted emails stored on an untrusted storage device is accessed. Based on the encrypted search index, one or more encrypted emails within a corpus of encrypted emails that are associated with at least a portion of the delegated DPRF are determined. An identifier of each of at least a portion of the one or more encrypted emails associated with at least a portion of the delegated DPRF is returned to the user device.
This aspect may include one or more of the following optional features. In some embodiments, the count table is encrypted using a second private encryption key that is only available to the user, the encrypted count table being stored on an untrusted storage device. In some examples, the encrypted count table includes a plurality of buckets, each bucket storing one or more counts of unique emails within the corpus of encrypted emails that include a respective key, accessing the count table to obtain the counts of unique emails within the corpus of encrypted emails that include keys includes sending a bucket request indicating a particular bucket of the plurality of buckets to the untrusted storage device, the bucket request, when received by the untrusted storage device, causing the untrusted storage device to return each count stored within the particular bucket to the user device.
Optionally, as the untrusted storage device returns each count stored within a particular bucket, the untrusted storage device also returns each count associated with one or more other buckets that are dynamically associated with the particular bucket. In some embodiments, the untrusted storage device returns each count associated with one or more other buckets that are dynamically associated with the particular bucket based on the total number of counts in the particular bucket.
In some embodiments, the operations further comprise assigning each count to a respective bucket based on an output of the second DPRF. Accessing the count table to obtain a count of unique emails including the key within the corpus of encrypted emails includes downloading at least a portion of the count table from an untrusted storage device. In some examples, for each unique keyword of a new encrypted email uploaded by a user into a corpus of encrypted emails stored on an untrusted storage device, determining whether to add the new keyword to a count table based on a probability, the new keyword not currently present in the count table; when the data processing hardware determines that a new keyword is to be added, adding the new keyword and the new keyword count into the count table; generating a unique keyword hash based on the private encryption key, the corresponding unique keyword and the new keyword count; a hash pair is generated that includes the unique key hash and an encrypted email identifier associated with the new encrypted email uploaded by the user, the hash pair is sent to the untrusted storage device.
When the data processing hardware determines that no new keyword is added, generating a unique keyword hash based on the private encryption key, the corresponding unique keyword and the random keyword count; generating a hash pair comprising a unique key hash and an encrypted email identifier associated with a new encrypted email uploaded by a user; the hash pair is sent to the untrusted storage device. The probability that a new key will be added to the count table is one fiftieth.
Drawings
Further advantages, features and details of the invention emerge from the following description of an embodiment with the aid of the dependent claims and the drawings. Wherein:
FIG. 1 is a schematic diagram of an example system that provides encrypted searches without zero-day leakage;
FIG. 2 is a diagram of exemplary components of a searchable encryption manager;
FIG. 3 is a schematic diagram of a binary tree;
FIG. 4 is a schematic diagram of a searchable encryption manager and a high-level query;
FIG. 5 is a schematic view of an example system that adds documents to a corpus of encrypted documents;
FIG. 6 is a schematic diagram of an example system that deletes documents from a corpus of encrypted documents;
FIG. 7 is a schematic diagram of an untrusted storage device and count table bucketing;
FIG. 8 is a schematic diagram of a plot of probabilities of inserting a key into a count table;
FIG. 9 is a flowchart of an example arrangement of operations of a method for providing an encrypted search system with client-side encrypted email;
FIG. 10 is a schematic diagram of an example computing device that can be used to implement the systems and methods herein;
like reference symbols in the various figures indicate like elements.
Detailed Description
Searchable encryption (which may also be referred to as encrypted searching) has become increasingly popular. The goal of searchable encryption is to enable a client to outsource storage of a corpus of encrypted documents to an untrusted server. For example, a customer may wish to securely store a large number of documents (or any other items uploaded to a server, such as pictures, emails, etc.) in a cloud-based storage solution. The term "document" is used generically and may represent any kind of digital file (e.g., a picture, a song, a database entry, etc.). Typically, clients wish to maintain the ability to efficiently search for documents (i.e., search for specific keywords) while maintaining the privacy and security of documents provided by encryption. To maintain this privacy, information associated with document content or queries from clients must remain hidden from untrusted servers. A common approach to solving this problem is to create a separate encrypted search index that indexes the keywords and related document identifiers of all documents stored on an untrusted server.
This search index is encrypted using a key that is not accessible by the untrusted server and then stored with the document. The client may then generate a search query and the server may evaluate against the encrypted search index. The result of the evaluation is an encrypted document identifier associated with the keyword of the search query, which the untrusted server returns to the client. In this manner, the client receives a list of document identifiers for documents that include keywords, while minimizing information leakage (e.g., to untrusted servers).
As an untrusted server evaluates the search index in response to a user's query, the index will gradually reveal the information of the search pattern, and through deployment frequency analysis or other attacks, the server may eventually make an informed guess at the historically searched items with a non-negligible probability. This leakage is not effectively prevented because it is an inherent problem due to repeated searches on the same index.
However, in addition to this slow leakage of using search indexes, many searchable encryption schemes present some additional security or privacy issues. In one example, some schemes are vulnerable to zero-day attacks. A zero-day attack refers to an attack that reveals or reveals information to an adversary (e.g., an untrusted storage server) before the storage server has processed any queries. That is, a search query (i.e., searching for keywords in encrypted documents) typically reveals at least some information to the server. However, a successful zero-day attack does not require any search query at all to obtain information about the encrypted document.
For example, some searchable encryption schemes hash each keyword in a document into one or more small values attached to each encrypted document. To search for a key, each associated hash value may be searched. However, this scheme reveals to the server a frequency table of the number of documents (and identifiers of the documents) that include a particular hash value. For example, hash values associated with many documents are likely to be more common words than hash values associated with fewer documents. This information is revealed to the server prior to any search query being made. Research has shown that frequency tables can reveal a large number of keywords. While these schemes may attempt to mitigate this weakness (e.g., by adding random terms), a significant amount of noise must be added to ensure that the frequency problem is overcome, which greatly reduces the efficiency of the scheme.
Another common security problem that many searchable encryption schemes are susceptible to is a document injection attack. A prerequisite for these attacks is that an adversary may send an encrypted document (e.g., an email) to the target. These emails will include specific keywords. When the target queries for these specific keywords, the adversary can see which injected emails are returned, thereby determining the keywords of the query. In some cases, an adversary may even hide the identity of injected emails by hiding keywords that may inform the target through, for example, invisible hypertext markup language (HTML). Such an attack may become more complex if the adversary is able to save the target executed queries (or retrieve executed queries from the log). An adversary may then apply all of these historical queries to recently injected emails (i.e., injected after the query is executed) to compromise the privacy of the keywords of the historical queries. Thus, when the scheme uses the same hash for all emails in the past or future, the scheme is easily applied by an adversary to all previous queries into recently injected files.
To mitigate zero-day attacks and file injection attacks of encrypted documents while maintaining search functionality and efficiency, embodiments herein are directed to an encrypted search scheme using a trusted pseudo-random function (DPRF) to completely hide the frequency table before any search query is executed.
Referring now to FIG. 1, in some embodiments, an example system 100 includes a user device 10, the user device 10 being associated with a respective user or client 12 and communicating with an untrusted remote system 111 over a network 112. The user device 10 may correspond to any computing device, such as a desktop workstation, a laptop workstation, or a mobile device (i.e., a smartphone). The user device 10 includes computing resources 18 (e.g., data processing hardware) and/or storage resources 16 (e.g., memory hardware).
The remote system 111 may be a single computer, multiple computers, or a distributed system (e.g., a cloud environment) having extensible/resilient computing resources 118 (e.g., data processing hardware) and/or storage resources 116 (e.g., memory hardware). An untrusted document data store 150 (i.e., remote storage device 150) is overlaid on storage resources 116 to allow for extensible use of storage resources 116 by one or more clients or computing resources 118. Document data store 150 is configured to store a corpus of documents 152, 152 a-n. Each document 152 includes a document identifier 154 (e.g., a document name) that uniquely identifies the associated document 152. Each document 152 also includes a set of keywords 32. The set of keywords 32 includes all keywords that appear in the relevant encrypted documents 152 and that can be searched by the user 12. As used herein, document 152 may refer to any item uploaded to remote system 111 for storage within document data store 150, such as, without limitation, an email, a calendar event, a note, a database entry, a picture, an audio document, and so forth. In some examples, untrusted storage device 150 stores a corpus 152 of emails, and user 12 accesses an inbox via user device 10 to receive and compose emails. In some embodiments, user device 10 executes a Searchable Encryption (SE) manager 120 for managing access to encrypted documents 152 within data store 150.
The SE manager 120 receives a search query 122 from a user 12 for one or more keywords 32, which keywords 32 appear in one or more encrypted documents 152 stored on the untrusted storage device 150. The SE manager 120 accesses the count table 210 to obtain a count 212 of unique documents 152 that include the keyword 32 in the corpus of encrypted documents 152. That is, the count 212 represents the number of unique documents 152 in which the keyword 32 appears. For example, when the keyword 32 of the query is "cat" and "cat" appears in 526 different documents 152 stored on the storage device 150 and associated with the user 12, the count 212 would be 526.
Referring now to fig. 2, an illustrative view 200 shows SE manager 120 receiving a keyword count 212 for a queried keyword 32 from a count table 210. The count table 210 includes counts 212 of how many different documents 152 the keyword 32 appears in. In the illustrated example, the keyword "cat" appears in 526 documents 152, the keyword "dog" appears in 128 different documents 152, and the keyword "yak" appears in 12 different documents 152. In some examples, count table 210 may be encrypted and SE manager 120 may decrypt count table 210 and/or count 212 using the encryption key. As discussed in more detail below with reference to fig. 7, the count table 210 may be stored locally at the user device 10 or remotely (e.g., at the untrusted storage device 150). To maintain privacy, the count table 210 must be kept secret and therefore will generally be encrypted, particularly when stored remotely from the user device 10.
Referring to fig. 1, SE manager 120 also obtains a private encryption key 124. In some examples, SE manager 120 generates private key 124. In other examples, SE manager 120 retrieves or receives private key 124 from user device 10 or from a third party (e.g., a third party key management service). The SE manager 120 generates a trusted pseudo-random function 126(DPRF) based on the key 32, the private encryption key 124, and a count 212 of unique documents 152 that include the key 32. When a user 12 queries more than one keyword 32, the SE manager 120 may generate a separate DPRF126 for each keyword 32.
As shown here, DPRF is a function that uses an input encryption key K and an input x to generate an output F (K, x) that is random to anyone without access to the key K. In particular, DPRF126 allows for delegation of evaluation of a strict subset of a domain of functions to untrusted agents without requiring the agents to be able to evaluate functions outside the strict subset.
As an example, assume that a user wishes to retrieve values stored on a server that are associated with a large number of outputs of function F. That is, the user wants the server to retrieve or evaluate a value associated with F (K, x1),.., F (K, xm) stored on the server. The user can simply send the value ranges of the function F, the key K, and the x to the server, and the server can evaluate the value range of the x to obtain an output. However, in this case, the server may evaluate the function F for any value of x, since the server has access to the key K. Another possible approach for the user is to evaluate each x's own value and then send each output to the server. While this limits the information received by the server, it requires m outputs to be sent, which is inefficient.
Ideally, users want to minimize the amount of information that users must send to the server, as well as minimize the amount of information learned by the server. DPRF126, as described in detail below with respect to FIG. 3, is a function that limits the amount of information that the server can obtain by evaluating x values outside of a specified range. For example, when a user sends a range of x1 to xm for server evaluation, the server will not be able to evaluate function F for x values less than x1 and x values greater than xm. To establish these bounds, the SE manager 120 evaluates the first portion 126A of the DPRF126 and delegates the remaining second portion 126B of the DPRF to the untrusted storage device 150.
Referring again to fig. 2, in some embodiments, SE manager 120 includes DPRF generator 218 and DPRF evaluator 220. The DPRF generator 218 generates the DPRF126 for the queried key 32 based on the private key 124, the key 32, and the key count 212 received from the count table 210. The DPRF generator 218 passes the DPRF126 to the DPRF evaluator 220. DPRF evaluator 220, as described in more detail below with reference to fig. 3, evaluates at least a portion (e.g., first portion 126a) of DPRF126 and, based on the evaluated portion, delegates (i.e., sends) the remaining second portion 126B to untrusted remote storage device 150.
Referring to fig. 1, untrusted storage device 150 (i.e., document data store 150 storing encrypted documents 152), in response to receiving the remaining second portion 126B of DPRF126 delegated by the DPRF evaluator of SE manager 120, evaluates the remaining second portion 126B of DPRF and accesses encrypted search index 160 associated with the corpus of encrypted documents 152 stored on untrusted storage device 150. The storage device 150 determines one or more encrypted documents 152 in the corpus of encrypted documents that are related to the remaining second portion 126B of the DPRF based on the encrypted search index 160.
The encrypted search index 160, in some embodiments, includes a list of entries 162, 162a-n, where each entry 162 includes an association between a keyword 32 and at least one encrypted document identifier 154 in which the keyword 32 occurs. The evaluation of the remaining second portion 126B provides the untrusted storage device 150 with the one or more encryption keys 32 associated with the one or more encryption document identifiers 154 without revealing the clear text key or the document identifier to the storage device 150. The storage device 150 returns to the user device 10 an identifier 154 for each encrypted document of at least a portion of the one or more encrypted documents 152 associated with the remaining second portion 126B of the DPRF. That is, in some embodiments, the storage device 150 does not return each identifier 154 associated with the document 152 that includes the queried keyword 32, but only returns a portion (e.g., fifty) of the document identifiers 154. Subsequent queries 122 by the user 12 may return additional results (e.g., the next fifty document identifiers 154). In some examples, the storage device 150 returns an empty set (i.e., no document identifier 154 is returned) to the user device 10 when, for example, the queried keyword 32 does not appear in any document 152.
In some embodiments, when the untrusted storage device 150 returns at least a portion of the document identifiers 154 associated with the encrypted documents 152 that include the queried keywords 32, the untrusted storage device also returns encrypted metadata 156 associated with each returned identifier 154. Metadata 156 may include additional relevant or contextual information of user 12. For example, the metadata 156 may include a date (e.g., the date the document 152 was created or uploaded), an author of the document 152, a size of the document 152, a sentence including the keywords 32, and so forth.
Referring now to fig. 3, as previously described, SE manager 120 generates DPRF126 to resolve a range of values from F (K, x 1). In some examples, key K is associated with a particular keyword 32, and each x value of DPRF126 represents one of the documents 152 in which the selected keyword 32 appears. For example, if the selection keyword 32 is "cat" and the count value 212 associated with "cat" is 526, then cats appear in 526 unique documents 152. In this example, the maximum size of x is 526 (e.g., 1 to 526), each x representing one document 152 in which the keyword 32 appears. Each value of F (K, x) is then associated with a value stored in the encrypted search index 160 that represents the document identifier 154 in which the selection key 32 appears.
Thus, for SE manager 120 to retrieve all documents 152 with the keyword "cat," SE manager 120 and/or untrusted storage device 150 may evaluate DPRF126 from F (K, 1). Each of the 526 results is associated with a different value stored in the encrypted search index 160. In another example, SE manager 120 may retrieve only a portion of the 526 documents 152 that include the keyword "cat". In this example, SE manager 120 and/or untrusted storage device 150 will only evaluate a portion of DPRF 126. For example, to retrieve fifty documents 152, SE manager 120 and/or untrusted storage device 150 may evaluate F (K, 1),. Each of these fifty results, in turn, is associated with a different value stored in the encrypted search index 160. Similarly, to retrieve the next fifty documents, SE manager 120 and/or untrusted storage device 150 may evaluate F (K, 51),.., F (K, 100), and so on. In this way, SE manager 120 and untrusted storage device 150 may evaluate DPRF126 to obtain results (i.e., entries 162) associated with values within encrypted search index 160. Untrusted store 150 may return all or a portion of the values associated with the results to SE manager 120.
In some embodiments, SE manager 120, in response to receiving search query 122, generates DPRF126 associated with queried keyword 32 by generating binary tree 300. In other embodiments, SE manager 120 generates binary tree 300 for each key 32 in count table 210 prior to receiving search query 122. A binary tree is a tree-like data structure having a plurality of nodes, each node in the structure having at most two child nodes. Binary tree 300 includes a set of nodes 310 that includes a root node 310R and a plurality of other nodes 310. Other nodes 310 are non-leaf nodes 310NL or leaf nodes 310L. Each input value of x is uniquely assigned to a leaf node 310L in ascending order. The number of leaf nodes 310L of the binary tree 300 may be equal to or greater than the number of unique documents 152 that include the relevant keywords 32. For example, if count value 212 for the key "cat" is 526, SE manager 120 may generate binary tree 300 for the key "cat" with at least 526 leaf nodes 310L. Each of the 526 instances of "cats" is associated with a particular leaf node 310L.
Each node 310 is also associated with a value 330, 330A-N, where the values 330, 330A-N may be generally referred to as "tokens". In some embodiments, the value 330 of each leaf node 310L is associated with a value within an entry 162 of the encrypted search index 160. That is, each value 330 of each leaf node 310L of the binary tree 300 is associated with a value within the encrypted search index 160 that is associated with a corresponding key 32. Returning to the example of the keyword 32 "cat," each of the 526 leaf nodes 310L in the binary tree 300 generated for the keyword 32 "cat" may be associated with a value stored in the encrypted search index 160, and each value associated with the encrypted search index 160 corresponds to a document identifier 154 of a document 152 that includes the keyword 32 "cat.
In some embodiments, the value 330 of the root node 310R of the binary tree 300 is the value of the private encryption key 124 and the first hash 340 of the key 32 associated with the binary tree 300. Thus, for each root node 310R of each binary tree 300 generated for a corresponding key 32, each binary tree 300 will have a unique value 330R. Each root node 310R is associated with a first child node (e.g., node 'B' in fig. 3) and a second child node (e.g., node 'C' in fig. 3). The first child node includes the private encryption key 124 and a first portion 330B of the second hash 342, 342a of the first hash 340 of the key 32, and the second child node includes the private encryption key 124 and a second portion 330C of the first hash 340 of the key 32. That is, in some examples, the value 330A of the root node 310R is the first hash 340 of the key 124 and the key 32. This value (labeled 'a' in fig. 3) is then hashed (e.g., using SHA256), and the resulting second hash 342a is split into a first portion 330B and a second portion 330C. As used herein, the terms "hash" and "hash function" are used to denote any one-way function (i.e., a function that cannot determine an input from an output), and thus, in addition to hash operations, apply equally to encryption operations (e.g., Advanced Encryption Standard (AES)).
In some examples, the first portion 330B of the second hash 342 concatenated with the second portion 330C of the second hash 342 corresponds to the second hash 342 of the first hash 340 of the key 32 and the private encryption key 124. As shown in fig. 3, second hash 342 (e.g., SHA256 hash) is a hash of 330A (i.e., root node 310R value 330A) and is equal to 'B' | 'C' (i.e., value 330B is concatenated with value 330C). For example, the output of the SHA256 hash is a 256-bit number. The value 330B may correspond to the first 128 bits of the SHA256 output and the value 330C may correspond to the last 128 bits of the SHA256 output. Thus, the value 330B, which is concatenated with the value 330C, corresponds to the hash 342 of the value of 330A.
In some embodiments, each other node 310 of the binary tree 300 includes a portion of the hash 342 of the parent node 310 associated with the respective other node 310. That is, for each non-root node 310R (i.e., all non-leaf nodes 310NL and all leaf nodes 310L) of the binary tree 300, the value 330 of the node 310 may be part of the hash 342 of the parent node. With continued reference to FIG. 3, node 'B' (like root node 310R node 'A') has two child nodes 310, node 'D' and node 'E'. Node 'C' also has two child nodes 310, node 'F' and node 'G'. In this example, since node 'D', node 'E', node 'F', and node 'G' do not have child nodes 310, each of the four nodes is a leaf node 310L. As previously described, the value 330B of node 'B' may be the first part of the hash 342A of the value 330A of node 'A'. Likewise, the value 330B of node 'B' may be hashed (again using, for example, SHA256), and the resulting hash 342B may be divided into a first portion 330D and a second portion 330E, each assigned to the value 330 of one of the two child nodes 310 (node 'D' and node 'E'). Also as previously described, the value 330C of node 'C' may be the second part of the hash 342A of the value 330A of node 'a'. Likewise, the value 330C of node 'C' may be hashed (e.g., with SHA256), and the resulting hash 342C may be divided into a first portion 330F and a second portion 330G, each assigned to the value 330 of one of the two child nodes 310 (node 'F' and node 'G'). Although in the illustrated example, the binary tree 300 stops at these nodes, the binary tree may continue for any number of nodes 310 until there are a sufficient number of leaf nodes 310L to account for the count value 212 of the associated key 32.
To retrieve all document identifiers 154 associated with each leaf node 310L (i.e., each document identifier 154 associated with a document 152 that includes the queried key 32), the SE manager 120 may simply send the token (e.g., the key 124 and the hash value of the key 32) and the count value 212 for node 'a' and allow the untrusted storage device 150 to determine the value of each leaf node 310L. In examples where SE manager 120 only needs to retrieve a portion of document identifier 154 associated with key 32, SE manager 120 may evaluate first portion 126A and delegate second portion 126B only to untrusted storage devices 150 to limit information that is leaked to untrusted storage devices 150. For example, when the document 152 includes an email, the user 12, when querying the keywords 32, may receive 50 recent emails including the queried keywords 32, and return additional emails only when the user indicates that more results are desired.
In some embodiments, the document identifiers 154 are arranged in a chronological order (e.g., the document identifier 154 associated with the first leaf node 310L is the oldest document and the document identifier 154 associated with the last leaf node 310L is the newest document, or vice versa), and the range of leaf nodes 310L from the bottom left or bottom right of the binary tree may be related to the newest or oldest document 152 associated with the keyword 32. This allows returning only a portion of the document identifiers 154 (e.g., the 50 most recent documents 152) associated with the queried keyword 32 without having to look up each keyword 32 instance in the search index 160. This may greatly reduce the total amount of calculations required. Although in this example, chronological ordering is illustrated, the document identifiers 154 may of course be ordered based on any other desired criteria.
With continued reference to FIG. 3, in examples where SE manager 120 need only retrieve the document identifiers 154 associated with the tokens 330D, 330E of node 'D' and node 'E', it may be desirable to not determine the necessary information for the values of node 'F' and node 'G' for untrusted storage devices, as these nodes are not necessary for query 122. In this case, the SE manager 120 may evaluate a first subset of the nodes 310 of the binary tree 300, and the untrusted storage device 150 may evaluate a second subset of the nodes 310 of the binary tree 300, the second subset being different from the subset evaluated by the SE manager 120.
For example, when the SE manager 120 provides the value 330A of the root node 310R to the untrusted storage device 150, but instead provides the value 330B of node 'B' to the untrusted storage device 150, the untrusted storage device 150 may evaluate the DPRF126 (e.g., the binary tree 300) using the token 330B of node 'B' to obtain the values 330D, 330E of the leaf node 310L, node 'D', and node 'E'. Because the hash function used to obtain token 330B is a one-way function, untrusted storage device 150 cannot use the value to obtain value 330A for root node 310R, thereby obtaining tokens 330C, 330F, 330G for node 'C', node 'F', and node 'G'. Thus, by determining the minimum number of nodes 310 whose union of leaf nodes 310L exactly (and only) covers the set of values 330 corresponding to the range of document identifiers 154 to be retrieved, the amount of information provided to the untrusted storage device 150 is minimized while the bandwidth requirements are kept low. To return the additional document identifier 154, the SE manager 120 can follow by sending an additional value 330 (e.g., the value 330C for node 'C' to obtain the values 330F, 330G for node 'F' and node 'G') to the untrusted storage device.
In some embodiments, each entry 162 of the encryption index 160 is exactly an association between one key 32 and one document identifier 154. However, in some embodiments, search index 160 may be optimized without reducing privacy. Rather than each entry 162 of the encrypted index 160 including an association between one keyword 32 and one document identifier 154, each entry 162 may include an association between one keyword 32 and a plurality of document identifiers 154. That is, each entry 162 associates a keyword 32 with a plurality of document identifiers 154 in which the keyword 32 occurs. Note that if there is no limit to how many document identifiers 154 can be associated with a keyword 32 per entry 162, the search index will risk revealing frequency table information. To mitigate this risk, each entry 162 may be limited to a maximum number of document identifiers. For example, each entry 162 may be limited to 50 or 100 document identifiers 154. In practice, this ensures that keywords with a large frequency (i.e., appearing in many documents 152) will be segmented into many different entries 162 in the search index 160.
In some examples, the maximum number of document identifiers may change dynamically based on the frequency of keywords 32. As the frequency of keywords 32 increases (i.e., keywords 32 are more common in documents 154), the size of the maximum number of document identifiers may increase. Thus, the untrusted storage device 150 does not have to process as many hashes. The count table 210 may be used to track the maximum number of document identifiers for each key 32, as well as the number of document identifiers 154 currently associated with each entry 162. Alternatively, rather than the count table 210 tracking the number of document identifiers 154 currently associated with each entry 162, the SE manager 120, each time a new key 32 is added, the SE manager 120 can create a new entry 162 and add the key 32 to the new entry 162 based on the key probabilities. This results in, on average, the expected number of document identifiers 154 being added to the entry 1622 before another new entry 162 is created. In this way, the count table 210 need not track the number of document identifiers 154 assigned to each entry 162, thereby reducing the size of the count table 210.
Referring now to schematic view 400 of fig. 4, in some examples, SE manager 120 receives an extract, conjunctive or negative search query 122D, 122C, 122N. Extracted query 122D comprises a query of two OR more keywords 32 combined with a logical OR. For example, the extracted query 122D may include a query for "cat" or "dog" and should result in the return of any document identifiers 154 associated with the documents 152 including the keyword "cat" and the keyword "dog". For the extracted query 122D, the SE manager 120 can generate a DPRF126 and corresponding sections 126B, 126Ba-n, respectively, for each keyword 32. Upon receiving the document identifier 154 for each keyword 32 at the user device 10, the SE manager 120 can combine the results and, in some embodiments, sort the results using any metadata 156 returned with the document identifier 154.
The conjunction query 122C includes a query of two or more keywords 32 combined with a logical AND. For example, the conjunction query 122C may include a query for "cat" and "dog" and should result in the return of any document identifiers 154 associated with the documents 152 including "cat" and "dog". Similar to disjunct query 122D, for conjunct query 122C, SE manager 120 may generate a DPRF126 and a corresponding portion 126B, respectively, for each keyword 32. Upon receiving the document identifier 154 for each keyword 32 at the user device 10, the SE manager 120 may return to the user 12 only the document identifiers 154 returned for each keyword 32.
Referring now to fig. 5, in some examples, system 100 displays user 12 adding/uploading a new document 152N to a corpus of encrypted documents 152 stored on untrusted storage device 150. In this case, the encrypted search index 160 is updated to the keywords 32 existing in the newly added document 152. The new document 152N is associated with a new document identifier 154N. In some embodiments, for each unique keyword 32 of a new encrypted document 152 uploaded by the user 12 into the corpus of encrypted documents 152 stored on the untrusted storage device 150, the SE manager 120 increases the count 212 of the unique documents 152 in the corpus of encrypted documents 152 that include the corresponding unique keyword 32 in the count table 210. For example, when the new document 152N includes the keyword "cat" and the current count 212 associated with the keyword "cat" is 526, the count 212 is incremented to 527.
In some examples, SE manager 120 generates unique key hash 520 based on private encryption key 124, the corresponding unique key 32, and an incremented count 212 of unique documents 152 in a corpus of encrypted documents that include the corresponding unique key 32. For example, SE manager 120 may use hash function 510 to calculate H kw ＝F(K||kw,cnt kw ) In which H kw Represents a hash value 520, K represents the private key 126, kw represents the key 32, and cnt kw Representing an incremented count 212. Any suitable one-way function or algorithm may be used to hash or encrypt the key 32 (e.g., SHA 256).
The SE manager 120 may also generate a hash pair 522, the hash pair 522 including the unique key hash 520 and the encrypted document identifier 154N associated with the new encrypted document 152 uploaded by the user 12 (i.e., the SE manager 120 hashes or encrypts the new document identifier 154N). SE manager 120 sends hash pair 522 to untrusted storage device 150. The SE manager 120 may generate a separate and unique hash pair 522 for each unique keyword 32 within the newly uploaded document 152N.
Draft documents 152 (e.g., emails that are saved without being sent or are being actively composed) are typically saved frequently (e.g., every few seconds) by user device 10. The SE manager 120 may update the search index 160 at the same frequency or at a different frequency when the draft is saved. For example, when the draft is saved every 5 seconds, the SE manager 120 may update the encrypted search index 160 every 5 minutes. In some embodiments, SE manager 120 may update encrypted search index 160 the same frequency as draft saves, but update count table 210 at a slower frequency. In this case, token 330 may be temporarily reused for updating search index 160 until count table 210 is updated at a future time.
When the document 152 stored on the untrusted storage device 150 is an email, the SE manager 120 may automatically add the email received at the user device 10 to the corpus of encrypted emails on the untrusted storage device. In some examples, emails that have been received but not yet opened are not added to the search index 160. That is, in some examples, SE manager 120 automatically adds the opened email to search index 160. In this manner, emails may be revoked by the sender without the SE manager 120 and/or the untrusted storage device 150 inferring the content of the revoked email from the keywords 32.
Referring now to FIG. 6, similar to adding document 152, in some embodiments, system 100 displays that SE manager 120 receives a delete request 630 to delete document 152 from untrusted storage device 150. In this case, SE manager 120 retrieves each key 32 (e.g., from untrusted storage 150) that exists in document 152 to be deleted and, for each key 32, decrements the corresponding count 212 in count table 210. The SE manager then instructs the untrusted storage device to delete the value within the encrypted search index associated with deleted document 152D. For example, the SE manager 120 may generate a hash value 620 of the private key 124, the key 32, and the appropriate count 212 (or other identifier) using a hash function 610 to generate a hash pair 622 with the document identifier 154. SE manager 120 may send hash pair 622 to untrusted storage 150 to indicate to the untrusted storage which entries within encrypted search index 160 are to be deleted. The untrusted storage device 150 may run a periodic task to periodically update the search index 160. In some embodiments, the untrusted storage device 150 maintains a list of all document identifiers 154 of the deleted documents 152 and deletes any document identifiers 154 associated with the deleted documents 152 before returning results from the search query 122.
Optionally, untrusted storage device 150 may periodically compress (e.g., perform garbage collection) search index 160 after one or more documents 152 are deleted. After a document is deleted, the deleted document may create a "hole" at the count 212 associated with the deleted document 152. The untrusted store 150 may move or shift entries in the search index 160 with higher counts 212 to entries with lower counts because lower counts become available from document deletions. The resulting empty high-count entry may then be deleted from the search index 160.
In some cases, user 12 may wish to delete portions of the content of document 152 without deleting the entire document 152. In this case, some keywords 32 are removed from the document 152, and the encrypted search index 160 no longer accurately reflects the keywords 32 present in the modified document 152. In some embodiments, deletion index 660 includes references to keywords 32 deleted from documents 152 in the corpus of encrypted documents stored on untrusted data store 150. The deletion index 660 may be similar to that generated and maintained when new document keywords 32 are added to the search index 160. Before the untrusted storage device 150 returns the document identifiers 154 associated with the queried keywords, the untrusted storage device may reference the deletion index 660 to determine whether the deletion index 660 indicates that any document identifiers 154 include keywords 32 that have been deleted. The untrusted storage device 150 may remove the document identifier 154 from which the deletion index indicates that the queried keyword 32 was deleted.
To prevent zero-day leakage (e.g., frequency table attacks), it is important that the plaintext of count table 210 is not available to someone other than user 12. However, it is also desirable that the user 12 easily access the count table 210 from various user devices 10 at the same time. There are a variety of ways to store the count table 210 that can address these issues to varying degrees. For example, the count table may be stored only locally at the user device 10. However, this implementation has the great disadvantage that the user is limited to the user device 10 storing the count table 210 and that it is difficult or even impossible to restore the count table 210 if the user device 10 is lost (e.g. the user device 10 crashes).
Another embodiment is to store the count table 210 in an encrypted format on the untrusted storage device 150. The count table 210 may be encrypted with a second private encryption key that is different from the private encryption key 124, or the count table 210 may be encrypted with the same private key 124. User device 10 may then, when executing the query, first download encrypted count table 210 from untrusted repository server 150, decrypt it, and execute the query. The user device 10 may send an updated count table 210 to the untrusted storage device 150 each time a document 152 is added or deleted from the corpus of encrypted documents. This allows synchronisation between a plurality of user devices 10 and ensures that a backup is made in case of a user device crash, however, the bandwidth requirements can be high, especially for some user devices (e.g. mobile phones). At the cost of greatly increased complexity, untrusted storage device 150 may replace the incremental backup of store count table 210. For example, backups may be uploaded periodically (e.g., once per day or once every few hours). The user device may upload changes to count table 210 (e.g., add or delete documents 152) and untrusted storage device 150 may track these changes to count table 210 until the next backup upload.
Yet another embodiment for storing count table 210 involves storing encrypted count table 210 on untrusted storage device 150 and accessing encrypted entries of count table 210. For example, for each key 32, the untrusted storage device 150 may store an identifier encrypted with a unique key that points to the encryption of the count 212 for that key. When user 12 adds document 152, user 12 requests that the untrusted storage device return an encryption count 212 associated with the identifier. The user device 10 may then perform a search as described above using the recovered count 212 and then send the encrypted delta count back to the untrusted storage device 150 for the untrusted storage device 150 to update. This implementation provides protection for a crashed user equipment and minimizes the required bandwidth. However, accessing the log of encrypted counts may reveal frequency information if improperly deleted. Such frequency information may allow for the generation of a frequency table that may be used for attacks.
In another embodiment, the count table 210 is replaced with a single maximum count integer. The max count integer may be set to the max count 212. That is, the maximum count integer may be set to the count 212 of the keyword 32 having the highest count 212 (i.e., appearing in the most documents 152). When searching for keys 32, SE manager 120 may delegate DPRFs 126 up to a maximum count integer in the entire range to untrusted storage devices 150. The untrusted storage device may perform a search (e.g., a binary search) on the encrypted search index 160 to obtain the actual count 212 of the queried keyword 32. For example, the untrusted storage device 150 may determine that the maximum count value that matches the results in the encrypted search index 160 is the actual count 212 of the key. This implementation eliminates the need for a count table 210, but increases the number of lookups that the untrusted storage device 150 must perform on the encrypted search index 160, while also potentially reducing privacy, as the log of searches may reveal the count frequency of the keywords 32.
In another embodiment, the count table 210 is divided into a plurality of different access buckets. Here, partitioning may use k-anonymity, where k-anonymity refers to an attribute of anonymized data where a particular member of a community cannot be easily identified or distinguished from the data.
Referring now to schematic view 700 of FIG. 7, in some embodiments, SE manager 120 divides count table 210 into a plurality of buckets 710, 710a-n, and stores buckets 710 on untrusted storage devices 150. Here, each bucket 710 stores one or more counts 212 of unique documents 152, including respective keywords 32, in the corpus of encrypted documents 152. That is, each key 32 and associated count 212 pair 712, 712a-n (e.g., "cats" and 526) is encrypted and assigned to bucket 710, each bucket being stored on untrusted storage device 150. The untrusted store 150 may host any number of buckets 710, and each bucket 710 may store any number of key-count pairs 712, however each key-count pair 712 is assigned to only a single bucket 710. SE manager 120 may request a particular pair 712 (e.g., count 212 for a particular key 32) by generating a bucket request 720 indicating a particular bucket of the plurality of buckets 710 and sending bucket request 720 to untrusted storage 150. In response, the untrusted storage device 150 returns each pair 712 stored in a particular bucket 710. In this manner, untrusted storage 150 cannot discern the particular pair 712 from the pair buckets that are returned to SE manager 120 from untrusted storage 150. The SE manager 120 may determine to which bucket 710a pair 712 is allocated by generating a second DPRF 726, the output domain of the second DPRF 726 being the number of buckets 710 only.
The bandwidth required for the barreling is balanced with the strength of anonymity provided by the barreling. That is, the greater the number of key and count pairs 712 per bucket 710 (i.e., when the total number of buckets 710 is small), the greater the number of pairs 712 returned for each query 122, the greater the anonymity and the greater the bandwidth consumption. Conversely, the fewer the number of key and count pairs 712 per bucket 710 (i.e., when the total number of buckets 710 is large), the fewer the number of pairs 712 returned for each query 122, the lower the anonymity, and the less bandwidth consumed. This implementation ensures that even if logs produced by untrusted storage devices are not deleted, the leakage is mitigated by the K-anonymization technique. In particular, the leakage of frequency occurs at the granularity of a bucket (which would typically include k encryption pairs 712), and thus the leakage of frequency only leaks about the frequency of the k key 32 groups.
In some examples, the total number of buckets 710 is fixed. That is, the number of buckets 710 in use does not change, and new key count pairs 712 are continually added to the same buckets 710. Over time, as the number of key count pairs 712 per bucket increases, the overall bandwidth consumption of the bucketization technique also increases. In other examples, the number of buckets 710 is not fixed (i.e., dynamic bucketing). In this case, the output domain of the second DPRF 726 is the maximum number of buckets (e.g., 1024) that can be deployed. As with the fixed bucket implementation, a second DPRF 726 is used to assign the key count pairs 712 to the buckets 710. To reduce the number of buckets 710 from the maximum number allocated by the second DPRF 726 to the required number, different possible outputs of the second DPRF 726 may be combined into a single bucket 710. That is, two or more buckets 710 may be dynamically linked together.
For example, if 1,024 is the maximum number of buckets, but the target number of buckets is 64, then every 16 buckets 710 may be combined so that when a key-count pair 712 from one of the 16 buckets is requested, the untrusted storage device 150 will return all pairs 712 from each of the 16 buckets. Note that each set of buckets 710 does not necessarily constitute the same number of buckets 710. For example, one group may be 16 buckets, while another group is 32 buckets. To increase or decrease the number of buckets 710, SE manager 120 may simply change the number of buckets 710 that are combined. This allows SE manager 120 to dynamically change the number of buckets 710 in use without physically changing base count table 210. Dynamic binning also ensures that counts 212 placed into the same bucket 710 are logically close when count table 210 is stored in a sorted manner to improve efficiency.
Fig. 8 shows a graph 800 of the likelihood of inserting a new key 32 into the count table 210 when the probability 810 of inputting a key is 0.02. The X-axis of the graph 800 represents the number of documents 152 having the same new key 32, and the Y-axis represents the probability or likelihood that the new key 32 is added to the count table 210. As can be seen from the graph 800, as the number of documents 152 with new keywords 32 approaches 200, the probability of the keywords 32 being input approaches 100%. In some embodiments, the size of the count table 210 is reduced by adding new keys 32 to the count table 210 based on the probabilities. That is, when a new document 152N (fig. 5) is added to the corpus of encrypted documents stored on the untrusted storage device 150, the SE manager 120 may determine whether to add a keyword 32 to the count table 210 based on the probability 810 when the new document 152N includes a keyword 32 that is not already in the count table 210. For example, the probability 810 that the new key 32 is added to the count table 210 may be 1/50 (i.e., 2%). When the SE manager 120 determines that a key 32 is to be added to the count table 210 based on the probability 810 (e.g., 2% of the time), the key 32 is added, as described with respect to FIG. 5. When the SE manager 120 determines that a key 32 is not added to the count table 210 based on the probability 810, the SE manager 120 may instead randomly assign the key 32 to tokens 330 within the threshold range. In some examples, the threshold range may be a default number (e.g., fifty) of document identifiers 154 retrieved in response to the search query.
For example, when the SE manager 120 determines not to add a new key 32 to the count table 210, the SE manager 120 may instead generate a hash pair 522 as described with respect to fig. 5 using a random count value 212 of between one and fifty. The new keyword 32, as it is used in other documents, will eventually be added to the count table 210 (i.e., eventually, the keyword 32 will be added to the count table 210 based on the probabilities 810).
While some tokens 330 may be used for multiple documents 152, i.e., the same number is randomly selected more than once when randomly selecting a count value 212 between 1 and 50, the amount of information leaked from the shared token 330 is minimal due to the nature of the infrequently occurring key 32 and the strong likelihood that the key 32 will eventually be added to the count table 210. At most, the untrusted store 150 may learn that each document 152 sharing the same token 300 has a common keyword 32. The untrusted storage device 150 does not know what the keywords 32 are, nor the total number of documents 152 that include the keywords 32. This technique may greatly reduce the size of the count table 210 because rarely used keys (e.g., symbols, abbreviations, names, etc.) will not be included. This reduces both the storage cost of storing count table 210 and the communication cost during count table operation (e.g., with respect to FIG. 7).
FIG. 9 is a flow diagram of an exemplary operational arrangement for a method 900 of providing an encrypted search system with client-side encrypted email. The method 900 includes, at step 902, receiving a search query 122 for keywords 32 at data processing hardware 18 of a user device 10 associated with a user 12. The keywords 32 appear in one or more encrypted emails in a corpus of encrypted emails 152 stored on the untrusted storage device 150. Method 900 includes, at step 904, accessing, by data processing hardware 18, count table 210 to obtain a count 212 of unique emails 152 in the corpus of encrypted emails 152 that include keyword 32, and, at step 906, generating, by data processing hardware 18, a delegateable pseudo-random function (DPRF)126 based on keyword 32, private encryption key 124, and count 212 of unique emails 152 that include keyword 32.
At step 908, the method 900 includes delegating, by the data processing hardware 18, at least a portion of the DPRF126 to the untrusted storage device 150. When received by the untrusted storage device 150, at least a portion of the DPRF126 causes the untrusted storage device 150 to evaluate at least a portion of the DPRF126, access an encrypted search index 160 associated with the corpus of encrypted emails 152 stored on the untrusted storage device 150, and determine one or more encrypted emails 152 in the corpus of encrypted emails associated with at least a portion of the DPRF126 based on the encrypted search index 160. The untrusted storage device 150 also returns to the user device 10 an identifier 154 for each of at least a portion of the one or more encrypted emails 152 associated with at least a portion of the DPRF 126B.
FIG. 10 is a schematic diagram of an example computing device 1000 that can be used to implement the systems and methods described herein. Computing device 1000 is intended to represent various forms of digital computers, such as laptops, desktops, workstations, personal digital assistants, servers, blade servers, mainframes, and other appropriate computers. The components shown herein, their coupling and relationships, and their functions, are meant to be exemplary only, and are not meant to limit implementations of the inventions described and/or claimed herein.
The memory 1020 stores information non-stridely within the computing device 1000. The memory 1020 may be a computer-readable medium, a volatile memory unit, or a nonvolatile memory unit. Non-volatile memory 1020 may be physical means for temporarily or permanently storing programs (e.g., sequences of instructions) or data (e.g., program state information) for use by computing device 1000. Examples of non-volatile memory include, but are not limited to, flash memory and read-only memory (ROM)/programmable read-only memory (PROM)/erasable programmable read-only memory (EPROM)/electrically erasable programmable read-only memory (EEPROM) (e.g., typically used for firmware, such as boot programs). Examples of volatile memory include, but are not limited to: random Access Memory (RAM), Dynamic Random Access Memory (DRAM), Static Random Access Memory (SRAM), Phase Change Memory (PCM), and magnetic disks or tapes.
The storage device 1030 is capable of providing mass storage for the computing device 1000. In some embodiments, storage 1030 is a computer-readable medium. In various different embodiments, the storage device 1030 may be a floppy disk device, a hard disk device, an optical disk device, or a tape device, a flash memory or other similar solid state memory device, or an array of devices, including devices in a storage area network or other configurations. In other embodiments, the computer program product is embodied in an information carrier. The computer program product comprises instructions which, when executed, perform one or more methods, such as the methods described above. The information carrier is a computer-or machine-readable medium, such as the memory 1020, the storage device 1030, or memory on processor 1010.
The high speed controller 1040 manages bandwidth-intensive operations for the computing device 1000, while the low speed controller 1060 manages lower bandwidth-intensive operations. Such allocation of duties is exemplary only. In some embodiments, high-speed controller 1040 is coupled to memory 1020, display 1080 (e.g., through a graphics processor or accelerator), and high-speed expansion ports 1050, which may accept various expansion cards (not shown). In some embodiments, low-speed controller 1060 is coupled to storage device 1030 and low-speed expansion port 1090. The low-speed expansion port 1090 may include various communication ports (e.g., USB, bluetooth, ethernet, wireless ethernet), may be coupled to one or more input/output devices, such as a keyboard, a pointing device, a scanner, or a network device, such as a switch or router, for example, through a network adapter.
As shown, the computing device 1000 may be implemented in a number of different forms. For example, it may be implemented as a standard server 1000a or multiple times in a group of such servers 1000a, as a notebook computer 1000b, or as part of a rack server system 1000 c.
Various implementations of the systems and techniques described here can be realized in digital electronic and/or optical circuits, integrated circuits, specially designed ASICs (application specific integrated circuits), computer hardware, firmware, software, and/or combinations thereof. These various implementations can include implementation in one or more computer programs that are executable and/or interpretable on a programmable system including at least one programmable processor, which may be special or general purpose, coupled to receive data and instructions from, and to transmit data and instructions to, a storage system, at least one input device, and at least one output device.
These computer programs (also known as programs, software applications or code) include machine instructions for a programmable processor, and can be implemented in a high-level procedural and/or object-oriented programming language, and/or in assembly/machine language. As used herein, the terms "machine-readable medium" and "computer-readable medium" refer to any computer program product, non-transitory computer-readable medium, apparatus and/or device (e.g., magnetic discs, optical disks, memory, Programmable Logic Devices (PLDs)) used to provide machine instructions and/or data to a programmable processor, including a machine-readable medium that receives machine instructions as a machine-readable signal. The term "machine-readable signal" refers to any signal used to provide machine instructions and/or data to a programmable processor.
The processes and logic flows described in this specification can be performed by one or more programmable processors, also referred to as data processing hardware, executing one or more computer programs to perform functions by operating on input data and generating output. The processes and logic flows can also be performed by, special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit). Processors suitable for the execution of a computer program include, by way of example, both general and special purpose microprocessors, and any one or more processors of any kind of digital computer. Generally, a processor will receive instructions and data from a read-only memory or a random access memory or both. The essential elements of a computer are a processor for executing instructions and one or more memory devices for storing instructions and data. Generally, a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks. However, a computer need not have such a device. Computer readable media suitable for storing computer program instructions and data include all forms of non-volatile memory, media and memory devices, including by way of example semiconductor memory devices, e.g., EPROM, EEPROM, and flash memory devices; magnetic disks, e.g., internal hard or removable disks, magneto-optical disks; and CDROM and DVD-ROM disks. The processor and the memory can be supplemented by, or incorporated in, special purpose logic circuitry.
To provide for interaction with a user, one or more aspects of the disclosure can be implemented on a computer having a display device, e.g., a CRT (cathode ray tube), LCD (liquid crystal display), or touch screen, for displaying information to the user and optionally a keyboard and a pointing device, e.g., a mouse or a trackball, by which the user can provide input to the computer. Other kinds of devices may also be used to provide for interaction with the user; for example, feedback provided to the user can be any form of sensory feedback, such as visual feedback, auditory feedback, or tactile feedback; and input from the user may be received in any form, including acoustic, speech, or tactile input. Further, the computer may interact with the user by sending and receiving documents to and from the device used by the user; for example, a web page is sent to a web browser on the user's client device in response to a request received from the web browser.
Some embodiments have been described. Nevertheless, it will be understood that various modifications may be made without departing from the spirit and scope of the disclosure. Accordingly, other embodiments are within the scope of the following claims.
Claims (20)
1. A computer-implemented method (900) that, when executed by data processing hardware (18) of a user device (10) associated with a user (12), causes the data processing hardware (18) to perform operations comprising:
receiving a search query (122) for keywords (32), the keywords (32) appearing in one or more encrypted emails (152) within a corpus of encrypted emails (152) stored on an untrusted storage device (150);
accessing a count table (210) to obtain a count (212) of unique emails (152) within the corpus of the encrypted emails (152) that include the keyword (32);
generating a trusted pseudo-random function (DPRF) (126) based on the key (32), a private encryption key (124), and the count (212) of the unique email (152) that includes the key (32); and
delegating at least a portion of the DPRF (126) to the untrusted storage device (150), the at least a portion of the DPRF (126) being delegated when received by the untrusted storage device (150), causing the untrusted storage device (150) to:
evaluating the at least a portion of the DPRF (126) that is delegated;
accessing an encrypted search index (160) associated with the corpus of encrypted emails (152) stored on the untrusted storage device (150);
determining, based on the encrypted search index (160), one or more encrypted emails (152) within the corpus of the encrypted emails (152) that are associated with the at least a portion of the DPRF (126) that was delegated; and
returning an identifier (154) of each encrypted email (152) of at least a portion of the one or more encrypted emails (152) associated with the at least a portion of the DPRF (126) that was delegated to the user equipment (10).
2. The method (900) of claim 1, wherein:
encrypting the count table (210) using a second private encryption key only available to the user (12), and
the encrypted count table (210) is stored on the untrusted storage device (150).
3. The method (900) of claim 2, wherein:
the encrypted count table (210) includes a plurality of buckets (710), each bucket (710) storing one or more counts (212) of unique emails (152) within the corpus of the encrypted emails (152) including a corresponding keyword (32), and
accessing the count table (210) to obtain the count (212) of the unique email (152) including the keyword (32) within the corpus of the encrypted email (152), including sending a bucket request (720) to the untrusted storage device (150) indicating a particular bucket (710) of the plurality of buckets (710), the bucket request (720), when received by the untrusted storage device (150), causing the untrusted storage device (150) to return each count (212) stored within the particular bucket (710) to the user device (10).
4. The method (900) of claim 3, wherein when the untrusted storage device (150) returns each count (212) stored within the particular bucket (710), the untrusted storage device (150) also returns each count (212) associated with one or more other buckets (710), the one or more other buckets (710) being dynamically associated with the particular bucket (710).
5. The method (900) of claim 4, wherein the untrusted storage device (150) returns each count (212) associated with the one or more other buckets (710) based on a total number of counts (212) in the particular bucket (710), the one or more other buckets (710) being dynamically associated with the particular bucket (710).
6. The method (900) of any of claims 2-5, wherein the operations further comprise assigning each count (212) to a respective bucket (710) based on an output of the second DPRF (726).
7. The method (900) of any of claims 1-6, wherein accessing the count table (210) to obtain the count (212) of the unique email (152) including the keyword (32) within the corpus of the encrypted email (152) comprises downloading at least a portion of the count table (210) from the untrusted storage device (150).
8. The method (900) of any of claims 1-7, wherein the operations further comprise, for each unique keyword (32) of a new encrypted email (152N) uploaded by the user (12) into the corpus of encrypted emails (152) stored on the untrusted storage device (150):
determining, based on a probability (810), whether to add a new key (32) to the count table (210), the new key (32) not currently present in the count table (210); and
when the data processing hardware (18) determines that the new keyword (32) is to be added:
adding the new key (32) and a new key count (212) to the count table (210);
generating a unique key hash (520) based on the private encryption key (124), the corresponding unique key (32), and the new key count (212);
generating a hash pair (522), the hash pair (522) comprising the unique key hash (520) and an encrypted email identifier (154N) associated with the new encrypted email (152N) uploaded by the user (12); and
sending the hash pair (522) to the untrusted storage device (150).
9. The method (900) of claim 8, wherein the operations further comprise, when the data processing hardware (18) determines not to add the new key (32):
generating a unique key hash (520) based on the private encryption key (124), the corresponding unique key (32), and a random key count (212);
generating a hash pair (522), the hash pair (522) comprising the unique key hash (520) and an encrypted email identifier (154N) associated with the new encrypted email (152N) uploaded by the user (12); and
sending the hash pair (522) to the untrusted storage device (150).
10. The method (900) of claim 8 or 9, wherein the probability (810) that the new key (32) will be added to the count table (210) is one fiftieth.
11. A system (100), comprising:
data processing hardware (18) of a user device (10) associated with a user (12); and
memory hardware (16) in communication with the data processing hardware (18), the memory hardware (16) storing instructions that, when executed on the data processing hardware (18), cause the data processing hardware (18) to perform operations comprising:
receiving a search query (122) for keywords (32), the keywords (32) appearing in one or more encrypted emails (152) within a corpus of encrypted emails (152) stored on an untrusted storage device (150);
accessing a count table (210) to obtain a count (212) of unique emails (152) within the corpus of the encrypted emails (152) that include the keyword (32);
generating a trusted pseudo-random function (DPRF) (126) based on the key (32), a private encryption key (124), and the count (212) of the unique email (152) that includes the key (32); and
delegating at least a portion of the DPRF (126) to the untrusted storage device (150), the at least a portion of the DPRF (126) being delegated when received by the untrusted storage device (150), causing the untrusted storage device (150) to:
evaluating the at least a portion of the DPRF (126) that is delegated;
accessing an encrypted search index (160) associated with the corpus of encrypted emails (152) stored on the untrusted storage device (150);
determining, based on the encrypted search index (160), one or more encrypted emails (152) within the corpus of the encrypted emails (152) that are associated with the at least a portion of the DPRF (126) that was delegated; and
returning an identifier (154) of each of at least a portion of the one or more encrypted emails (152) associated with the at least a portion of the DPRF (126) that was delegated to the user device (10).
12. The system (100) of claim 11, wherein:
encrypting the count table (210) using a second private encryption key only available to the user (12), and
the encrypted count table (210) is stored on the untrusted storage device (150).
13. The system (100) of claim 12, wherein:
the encrypted count table (210) includes a plurality of buckets (710), each bucket (710) storing one or more counts (212) of unique emails (152) within the corpus of the encrypted emails (152) including a corresponding keyword (32), and
accessing the count table (210) to obtain the count (212) of the unique email (152) within the corpus of the encrypted email (152) that includes the keyword (32) includes sending a bucket request (720) to the untrusted storage device (150) that indicates a particular bucket (710) of the plurality of buckets (710), the bucket request (720), when received by the untrusted storage device (150), causing the untrusted storage device (150) to return each count (212) stored within the particular bucket (710) to the user device (10).
14. The system (100) of claim 13, wherein when the untrusted storage device (150) returns each count (212) stored within the particular bucket (710), the untrusted storage device (150) also returns each count (212) associated with one or more other buckets (710), the one or more other buckets (710) being dynamically associated with the particular bucket (710).
15. The system (100) of claim 14, wherein the untrusted storage device (150) returns each count (212) associated with the one or more other buckets (710) based on a total number of counts (212) in the particular bucket (710), the one or more other buckets (710) being dynamically associated with the particular bucket (710).
16. The system (100) of any of claims 12-15, wherein the operations further comprise assigning each count (212) to a respective bucket (710) based on an output of the second DPRF (726).
17. The system (100) of any of claims 11-16, wherein accessing the count table (210) to obtain the count (212) of the unique email (152) including the keyword (32) within the corpus of the encrypted email (152) comprises downloading at least a portion of the count table (210) from the untrusted storage device (150).
18. The system (100) according to any one of claims 11-17, wherein the operations further include: for each unique key (32) of a new encrypted email (152N) uploaded by the user (12) into the corpus of encrypted emails (152) stored on the untrusted storage device (150):
determining, based on a probability (810), whether to add a new key (32) to the count table (210), the new key (32) not currently present in the count table (210); and
when the data processing hardware (18) determines that the new key (32) is to be added:
adding the new key (32) and a new key count (212) to the count table (210);
generating a unique key hash (520) based on the private encryption key (124), the corresponding unique key (32), and the new key count (212);
generating a hash pair (522), the hash pair (522) comprising the unique key hash (520) and an encrypted email identifier (154N) associated with the new encrypted email (152N) uploaded by the user (12); and
sending the hash pair (522) to the untrusted storage device (150).
19. The system (100) of claim 18, wherein the operations further comprise, when the data processing hardware (18) determines not to add the new key (32):
generating a unique key hash (520) based on the private encryption key (124), the corresponding unique key (32), and a random key count (212);
generating a hash pair (522), the hash pair (522) comprising the unique key hash (520) and an encrypted email identifier (154N) associated with the new encrypted email (152N) uploaded by the user (12); and
sending the hash pair (522) to the untrusted storage device (150).
20. The system (100) of claim 18 or 19, wherein the probability (810) that the new key (32) will be added to the count table (210) is one-fiftieth.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US16/713,872 US11308224B2 (en) | 2019-12-13 | 2019-12-13 | Encrypted search system design for email client-side encryption |
US16/713,872 | 2019-12-13 | ||
PCT/US2020/064708 WO2021119553A1 (en) | 2019-12-13 | 2020-12-11 | Encrypted search system design for email client-side encryption |
Publications (2)
Publication Number | Publication Date |
---|---|
CN115104286A true CN115104286A (en) | 2022-09-23 |
CN115104286B CN115104286B (en) | 2023-08-29 |
Family
ID=74184877
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202080096337.0A Active CN115104286B (en) | 2019-12-13 | 2020-12-11 | Encryption searching method and system for encrypting E-mail client |
Country Status (4)
Country | Link |
---|---|
US (1) | US11308224B2 (en) |
EP (1) | EP4074003B1 (en) |
CN (1) | CN115104286B (en) |
WO (1) | WO2021119553A1 (en) |
Families Citing this family (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11250151B2 (en) * | 2020-05-05 | 2022-02-15 | Google Llc | Encrypted search over encrypted data with reduced volume leakage |
Citations (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US8281125B1 (en) * | 2009-02-12 | 2012-10-02 | Symantec Corporation | System and method for providing secure remote email access |
US9342705B1 (en) * | 2014-01-13 | 2016-05-17 | Symantec Corporation | Systems and methods for searching shared encrypted files on third-party storage systems |
US9712320B1 (en) * | 2013-06-11 | 2017-07-18 | EMC IP Holding Company LLC | Delegatable pseudorandom functions and applications |
US20180314847A1 (en) * | 2017-04-27 | 2018-11-01 | Google Llc | Encrypted Search Cloud Service with Cryptographic Sharing |
CN110110163A (en) * | 2018-01-18 | 2019-08-09 | Sap欧洲公司 | Safe substring search is with filtering enciphered data |
Family Cites Families (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US8442994B1 (en) | 2007-09-14 | 2013-05-14 | Google Inc. | Custom search index data security |
CN105450387A (en) | 2014-08-20 | 2016-03-30 | 江苏威盾网络科技有限公司 | Network distributed storage method based on hybrid encryption |
US9894042B2 (en) * | 2015-07-24 | 2018-02-13 | Skyhigh Networks, Inc. | Searchable encryption enabling encrypted search based on document type |
US9633219B2 (en) | 2015-08-26 | 2017-04-25 | International Business Machines Corporation | Providing secure indexes for searching encrypted data |
WO2017094009A1 (en) | 2015-12-03 | 2017-06-08 | Dyadic Security Ltd | Securing sql based databases with cryptographic protocols |
CN109522681A (en) | 2018-09-19 | 2019-03-26 | 北京非对称区块链科技有限公司 | Digital content really weighs method, apparatus and storage medium |
-
2019
- 2019-12-13 US US16/713,872 patent/US11308224B2/en active Active
-
2020
- 2020-12-11 CN CN202080096337.0A patent/CN115104286B/en active Active
- 2020-12-11 EP EP20842069.5A patent/EP4074003B1/en active Active
- 2020-12-11 WO PCT/US2020/064708 patent/WO2021119553A1/en unknown
Patent Citations (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US8281125B1 (en) * | 2009-02-12 | 2012-10-02 | Symantec Corporation | System and method for providing secure remote email access |
US9712320B1 (en) * | 2013-06-11 | 2017-07-18 | EMC IP Holding Company LLC | Delegatable pseudorandom functions and applications |
US9342705B1 (en) * | 2014-01-13 | 2016-05-17 | Symantec Corporation | Systems and methods for searching shared encrypted files on third-party storage systems |
US20180314847A1 (en) * | 2017-04-27 | 2018-11-01 | Google Llc | Encrypted Search Cloud Service with Cryptographic Sharing |
CN110110163A (en) * | 2018-01-18 | 2019-08-09 | Sap欧洲公司 | Safe substring search is with filtering enciphered data |
Also Published As
Publication number | Publication date |
---|---|
CN115104286B (en) | 2023-08-29 |
US20210182408A1 (en) | 2021-06-17 |
US11308224B2 (en) | 2022-04-19 |
EP4074003A1 (en) | 2022-10-19 |
WO2021119553A1 (en) | 2021-06-17 |
EP4074003B1 (en) | 2023-04-05 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US11645256B2 (en) | Encrypted search with no zero-day leakage | |
US20230254126A1 (en) | Encrypted search with a public key | |
US20230274007A1 (en) | Response-Hiding Searchable Encryption | |
CN115104286B (en) | Encryption searching method and system for encrypting E-mail client | |
US11250151B2 (en) | Encrypted search over encrypted data with reduced volume leakage | |
Avni et al. | SSSDB: database with private information search | |
US11909861B2 (en) | Privately querying a database with private set membership using succinct filters | |
Krishna et al. | Dynamic cluster based privacy-preserving multi-keyword search over encrypted cloud data | |
Waage et al. | Searchable encryption in apache cassandra | |
US10691828B2 (en) | Method for securing access to a relation | |
WO2019227217A1 (en) | Systems and methods for indexing and searching data | |
Ahmed et al. | Conjunctive keyword forward secure ranked dynamic searchable encryption over outsourced encrypted data | |
Balasubramaniam et al. | A survey on data retrieval techniques in cloud computing | |
Pramanick et al. | Searchable encryption with pattern matching for securing data on cloud server | |
Chebrolu et al. | An efficiency and privacy-preserving biometric identification scheme in cloud computing | |
Pinkas et al. | A simple recursive tree oblivious ram | |
CN115422237A (en) | Data query method and device, computer equipment and storage medium | |
Ulusoy et al. | Analysis of heuristic based access pattern obfuscation |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
GR01 | Patent grant | ||
GR01 | Patent grant |