CN118056203A - Scalable hardware architecture template for processing streaming input data - Google Patents
Scalable hardware architecture template for processing streaming input data Download PDFInfo
- Publication number
- CN118056203A CN118056203A CN202180102947.1A CN202180102947A CN118056203A CN 118056203 A CN118056203 A CN 118056203A CN 202180102947 A CN202180102947 A CN 202180102947A CN 118056203 A CN118056203 A CN 118056203A
- Authority
- CN
- China
- Prior art keywords
- hardware
- hardware architecture
- streaming
- input data
- matrix
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
- 238000012545 processing Methods 0.000 title claims description 116
- 238000000034 method Methods 0.000 claims abstract description 138
- 238000013461 design Methods 0.000 claims abstract description 125
- 230000008569 process Effects 0.000 claims abstract description 66
- 238000003860 storage Methods 0.000 claims abstract description 13
- 239000011159 matrix material Substances 0.000 claims description 102
- 239000013598 vector Substances 0.000 claims description 91
- 238000010801 machine learning Methods 0.000 claims description 20
- 238000005070 sampling Methods 0.000 claims description 9
- 238000004088 simulation Methods 0.000 claims description 8
- 238000010845 search algorithm Methods 0.000 claims description 7
- 230000004044 response Effects 0.000 claims description 6
- 238000004458 analytical method Methods 0.000 claims description 4
- 238000004422 calculation algorithm Methods 0.000 claims description 3
- 230000002068 genetic effect Effects 0.000 claims description 3
- 238000004590 computer program Methods 0.000 abstract description 14
- 238000004519 manufacturing process Methods 0.000 description 16
- 238000003491 array Methods 0.000 description 12
- 230000009471 action Effects 0.000 description 5
- 238000013528 artificial neural network Methods 0.000 description 5
- 238000004364 calculation method Methods 0.000 description 5
- 238000004891 communication Methods 0.000 description 5
- 239000003623 enhancer Substances 0.000 description 5
- 239000000872 buffer Substances 0.000 description 4
- 238000013473 artificial intelligence Methods 0.000 description 3
- 230000003993 interaction Effects 0.000 description 3
- 238000000638 solvent extraction Methods 0.000 description 3
- 230000002411 adverse Effects 0.000 description 2
- 230000005540 biological transmission Effects 0.000 description 2
- 238000001514 detection method Methods 0.000 description 2
- 230000018109 developmental process Effects 0.000 description 2
- 230000006870 function Effects 0.000 description 2
- 238000005259 measurement Methods 0.000 description 2
- 230000003287 optical effect Effects 0.000 description 2
- 238000013515 script Methods 0.000 description 2
- 238000000926 separation method Methods 0.000 description 2
- 230000003068 static effect Effects 0.000 description 2
- 238000012549 training Methods 0.000 description 2
- 238000012546 transfer Methods 0.000 description 2
- 230000015572 biosynthetic process Effects 0.000 description 1
- 230000000903 blocking effect Effects 0.000 description 1
- 230000008859 change Effects 0.000 description 1
- 230000006835 compression Effects 0.000 description 1
- 238000007906 compression Methods 0.000 description 1
- 125000004122 cyclic group Chemical group 0.000 description 1
- 230000001934 delay Effects 0.000 description 1
- 238000011161 development Methods 0.000 description 1
- 238000010586 diagram Methods 0.000 description 1
- 230000009977 dual effect Effects 0.000 description 1
- -1 e.g. Substances 0.000 description 1
- 239000004973 liquid crystal related substance Substances 0.000 description 1
- 238000005457 optimization Methods 0.000 description 1
- 238000005192 partition Methods 0.000 description 1
- 238000005498 polishing Methods 0.000 description 1
- 230000000644 propagated effect Effects 0.000 description 1
- 230000009467 reduction Effects 0.000 description 1
- 230000011218 segmentation Effects 0.000 description 1
- 239000004065 semiconductor Substances 0.000 description 1
- 230000001953 sensory effect Effects 0.000 description 1
- 230000005236 sound signal Effects 0.000 description 1
- 239000000126 substance Substances 0.000 description 1
- 239000000758 substrate Substances 0.000 description 1
- 238000003786 synthesis reaction Methods 0.000 description 1
- 230000000007 visual effect Effects 0.000 description 1
Abstract
Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for generating an enhanced hardware architecture to process streaming input data are described. In one aspect, a method includes receiving data (195, 810) representing a hardware architecture template. The hardware architecture template includes a set of configurable design parameters. Values of the set of design parameters are determined based on characteristics of the streaming input data (820). The determining process comprises the following steps: generating a plurality of candidate hardware architectures (840) based on the search space for the configurable set of design parameters, each candidate hardware architecture comprising a respective design parameter value; determining a respective performance value associated with each candidate hardware architecture (850); selecting a hardware architecture (860) based on the corresponding performance values; and determining a value based on parameter values associated with the selected candidate hardware architecture (870). Output data including values is generated for instantiating the hardware architecture using the hardware architecture template.
Description
Technical Field
The present description relates to using a scalable hardware architecture template to generate hardware design parameters for hardware components, e.g., machine learning processors, that perform operations on streaming input data, and using the parameters to fabricate the processors.
Background
Artificial Intelligence (AI) is the intelligence demonstrated by a machine and represents the ability of a computer program or machine to think and learn. One or more computers may be used to perform AI calculations to train the machine to perform the corresponding tasks. The AI computation may include computation represented by one or more machine learning models.
Neural networks belong to the sub-domain of machine learning models. The neural network may employ one or more layers of nodes that represent multiple operations, e.g., vector or matrix operations. The one or more computers may be configured to perform operations or computations of the neural network to generate an output, e.g., classification, prediction, or segmentation, for the received input. Some neural networks include one or more hidden layers in addition to the output layer. The output of each hidden layer serves as an input to the next layer in the network, i.e., the next hidden layer or output layer. Each layer of the network generates an output from the received input based on the current values of the respective sets of network parameters.
Disclosure of Invention
The techniques described in the following specification relate to generating hardware design parameters of a hardware component, e.g., a machine learning processor, using a scalable hardware architecture template, the hardware component performing operations on streaming input data and using the parameters to fabricate the processor. The hardware architecture templates may include a set of configurable design parameters for manufacturing hardware components that may be configured to perform operations on streaming input data such that the architecture may be scaled up or down based on characteristics of the streaming input data. The techniques may be used to determine values for a set of design parameters and instantiate a hardware architecture using the hardware architecture templates and the determined values.
A hardware architecture, also referred to as a hardware architecture representation, generally refers to a representation of an engineered (or to be engineered) electronic or electromechanical hardware block, component, or system. The hardware architecture may contain data for identifying, prototyping, and/or manufacturing such hardware blocks, components, or systems. The hardware architecture may be encoded with data representing the structure of a block, component or system, e.g., data identifying sub-components or sub-systems included in the hardware block, component or system and their interrelationships. The hardware architecture may also include data representing a process of manufacturing the hardware block, component, or system, or representing disciplines of design for efficiently implementing the hardware block, component, or system, or both.
The term "hardware architecture template" herein refers to data representing a template having a set of design parameters for hardware components, such as a machine learning processor configured to perform machine learning calculations on streaming inputs. The hardware architecture templates may be a pre-set generic design for a hardware architecture with aspects that are customized or personalized based on a set of design parameters, e.g., the type, number, or hierarchy of different computing units to be included in the hardware architecture.
The hardware architecture templates may be abstract and not instantiated until the values of the set of design parameters are determined. After determining the values of the design parameters, for example, using the various processes described in this document, a hardware architecture template may be used to instantiate a hardware architecture based on the determined values of the design parameter set. In some implementations, the hardware architecture templates may represent data encoded in a high-level computer language, which may be synthesized to hardware circuitry and programmed in an object-oriented manner (e.g., C or c++). For simplicity, the term "hardware architecture template" is sometimes referred to as a "template" in this document.
The set of design parameters may be formed in multiple dimensions or have a "search space" within which to perform a search for corresponding values for the set of design parameters given a particular design requirement or criteria. The values of the design parameters may be determined by exploring the search space using one or more algorithms or techniques. In this document, the term "search space" refers to a solution space that contains all or at least one set of possible solutions (e.g., values) for a given set of design parameters of available resources, e.g., all possible types and numbers of different computing units included in a hardware architecture.
The templates may be reconfigured based on the characteristics of the data used to perform the computing operation. In some cases, the hardware architecture generated by the templates may be re-instantiated on the fly due to changes in the input data, e.g., different input matrices with different sparsity levels.
The term "hardware component" refers to a hardware component for performing computing operations, such as machine learning computations, including, for example, suitable hardware computing units or clusters of computing units configured to perform vector reduction, tensor multiplication, basic arithmetic operations, and logical operations based on streaming input data. For example, a hardware component may include one or more tiles (e.g., multiply-accumulate operation (MAC) units), one or more processing elements including multiple MAC units, one or more clusters including multiple processing elements, and processing units such as Graphics Processing Units (GPUs) and Tensor Processing Units (TPUs).
The term "streaming input data" refers to data that is continuously provided to a hardware component to process the data. For example, the data may include a plurality of data frames, where each frame is generated at a particular time interval, and each data frame is provided to a hardware component for processing at a particular rate. The terms "time interval" and "rate" refer to the time period or frequency used to generate or receive a data frame and the next data frame. For example, the rate for streaming input data may be one frame of data every few milliseconds, seconds, minutes, or other suitable period of time.
The streaming input data may be streaming image frames or video frames acquired by the image sensor according to a time sequence. The image sensor may comprise a camera or a recorder. Streaming image frames may be collected by an image sensor at a particular rate or provided to a hardware component at a particular arrival rate.
Each frame of streaming input data may have a particular size. For example, each streaming image frame may include a respective image resolution, e.g., 50×50 pixels, 640×480 pixels, 1440×1080 pixels, or 4096×2160 pixels.
The hardware component may be configured to process streaming input data received at a particular rate. As described above, streaming input data may be generated continuously, e.g., from one or more sources, frame by frame, and provided to hardware components at a particular arrival rate. For example, the rate may be a frame per unit time or a number of pixels per unit time. Ideally, the hardware component can process each frame of streaming input data before the next frame of input data arrives, and generate output data in time. However, if the hardware component cannot process the next frame before it arrives, the hardware component may cause backpressure for processing subsequent frames of streaming input data. Backpressure may cause interrupts or time delays for generating output data, increasing overhead, particularly when other hardware components in the system are configured to process output data generated by the hardware components, or cause errors in the operation of the hardware components and/or the computation by the hardware components.
In some implementations, the system can use new streaming input data with a larger frame size or at a higher frequency or both (e.g., more image frames with higher resolution per unit time) to generate output data with higher accuracy. An initially suitable hardware component may not be able to process every frame of new streaming input data before the arrival of the next frame, which results in backpressure for processing later arriving frames of streaming input data.
The technique of performing generalized matrix multiplication (GEMM) and generalized matrix vector multiplication (GEMV) cannot be applied to process streaming input data because each frame of streaming input data is received in sequence. For example, each frame of streaming input data may be represented by an input matrix, and the input matrix received by the hardware component row by row during a particular time window. An example of GEMM or GEMV technique, also known as loop-partitioning, also known as loop-nested optimization, divides the iteration space of a loop into smaller chunks or blocks for performing matrix-matrix or matrix-vector computations, so that each smaller chunk or block of input can be computed in parallel. However, cyclic blocking techniques are unlikely to be suitable for processing streaming input data because the input is received row by row according to a sequence. It is not possible or at least impractical to pre-store the last line of the current frame or a line of the next frame and perform operations on these lines while processing different lines in the current frame in parallel.
Some techniques solve the backpressure problem by including more Processing Elements (PEs) or computing units as the size or frequency of the streaming input data increases. However, this may be inefficient, not scalable, and may quickly reach the maximum power requirements of the hardware components as the frame size or arrival rate is scaled up. For example, edge devices (e.g., smartphones, tablets, laptops, and watches) configured to process streaming input data (e.g., perform calculations using each frame of input data) may have an upper limit on the power consumption rate. Thus, the total number or number of computing units integrated within the hardware components of the edge device may be limited by the maximum power requirements, or the battery life requirements for each charge, or both.
To more efficiently and robustly process streaming input data at high throughput, the techniques described in this document implement a hardware architecture template with a set of design parameters. A system executing the described techniques may determine values of a set of design parameters based on characteristics of streaming input data and instantiate a hardware architecture using a hardware architecture template having the determined design parameter values. The hardware architecture includes a specific arrangement of computing units specified by design parameter values and represents hardware components suitable for processing streaming input data. The hardware architecture may be used to fabricate hardware components.
According to one aspect, the document describes a method for generating a hardware architecture based on specific streaming input data. The hardware architecture may be used to fabricate hardware components that can satisfactorily process certain streaming input data. The method includes receiving data representing a hardware architecture template having a configurable set of design parameters, wherein the set of design parameters may include two or more of a number of clusters, a number of processing units in each cluster, and a size of an array of hardware units in each processing unit.
The method also includes determining a value of the set of configurable design parameters based at least in part on characteristics of streaming input data to be processed by the hardware component. The determining process comprises the following steps: generating a plurality of candidate hardware architectures using a search space of configurable design parameters; determining a respective value of a set of performance metrics associated with each candidate hardware architecture; selecting a candidate hardware architecture from all of the plurality of candidate hardware architectures based at least in part on the respective values of the set of performance metrics; and determining a value of the design parameter based on the selected candidate hardware architecture.
The output data generated by the method may include at least design parameter values for manufacturing the hardware architecture.
In some implementations, the method includes providing output data to a hardware architecture template, instantiating a hardware architecture based on the determined design parameter values, and manufacturing a hardware component using the hardware architecture.
In some implementations, the characteristics of the streaming input data may include the arrival rate of each frame and the size of each frame. The set of performance metrics may include metrics of at least one of latency, power consumption, resource usage, or throughput for processing the respective streaming input data for the given hardware component. The performance model may include at least one of an analysis cost model, a machine learning cost model, or a hardware simulation model. The streaming input data may be streaming image frames acquired by the image sensor according to a time sequence. The characteristics of the streaming image frames may include a particular arrival rate, where each frame of the streaming image frames may have a corresponding image resolution. In some implementations, the characteristics of the streaming image frames may include respective image resolutions of the image frames. Characteristics of streaming image frames may include blanking periods (e.g., vertical blanking periods and/or horizontal blanking periods), pixel or color formats (e.g., RGB or YUV color formats), and the order of arrival of the image frames. The streaming input data may be streaming audio from which the audio sensor collects. The characteristics of the audio streaming data may include at least one of a particular sampling rate of the streaming audio, a bit depth of the streaming audio, a bit rate of the streaming audio, or an audio format of the streaming audio.
In some implementations, the streaming input data may be received in a matrix or vector form. The method further includes partitioning an input frame from the matrix into a plurality of vectors, decomposing the matrix by matrix into a plurality of vector by matrix multiplications, determining a sparseness level of the matrix (e.g., a matrix stored in a memory unit and used for multiplication with streaming input data), and/or determining non-zero values in the stored matrix to improve computational efficiency.
Particular embodiments of the subject matter described in this specification can be implemented to realize one or more of the following advantages. The techniques described in this document may be robust to generate hardware components, such as machine learning processors, capable of processing different streaming data with different frame sizes and arrival rates. More specifically, a system executing the described techniques may customize a hardware architecture for particular streaming input data by determining design parameter values for a hardware architecture template. The technique can quickly determine parameter values to enable flexible hardware development. The hardware architecture templates may be used to instantiate a hardware architecture based on the determined design parameter values, allowing for a scalable and customizable hardware architecture capable of supporting streaming input data with wide variations in data rates, data sizes, and/or other characteristics. The instantiated hardware architecture may be enhanced to reduce or even eliminate backpressure when processing specific streaming input data. The hardware architecture may be configured to be re-instantiated on the fly to handle different matrices that are non-streaming and have different sparsity levels up to 50% sparsity levels.
Furthermore, the techniques described in this document improve the efficiency of processing streaming input data. More specifically, the described techniques may perform computations, such as machine learning computations, on streaming input data using less computing resources, less power, and less memory. The design parameter values for the templates are determined based on one or more factors, requirements, or criteria, e.g., the design parameter values may be determined to minimize power usage and maintain a particular input arrival rate. For example, design parameters may be determined such that streaming input data may be processed without backpressure while still meeting power and/or size requirements of hardware components. Systems performing the described techniques may also perform certain processing on sparse matrices to reduce memory usage. For example, the system may avoid storing zero values of the non-streaming matrix for processing streaming input data and perform operations only on input values associated with the non-zero values of the non-streaming matrix, which reduces computing resources for performing the operations and reduces memory bandwidth for data transmission and memory size for storage.
Furthermore, the techniques described in this document may process streaming input data with high throughput and performance. The described techniques may reduce latency in processing streaming input data by balancing processing speed and computing unit idle time according to different processing requirements. For example, a hardware component generated by a template may process each frame of streaming input data at a faster rate and may result in more idle time for one or more computing units in the hardware component. Alternatively, the hardware component may process each frame at a reduced speed, but still be able to process each frame in time. The described techniques may also guarantee high throughput by avoiding potential logic congestion or reduced hardware clock rates. For example, the described techniques may explore only a subset of the set of design parameters until the generated hardware architecture reaches a scalability limit, where further increasing the values of the subset of design parameters would result in logic congestion or adversely affect the hardware clock rate.
The details of one or more embodiments of the subject matter of this specification are set forth in the accompanying drawings and the description below. Other features, aspects, and advantages of the subject matter will become apparent from the description, the drawings, and the claims.
Drawings
FIG. 1 illustrates an example architectural design system.
Fig. 2 illustrates an example scenario for processing frames of streaming input data.
Fig. 3 illustrates another example scenario for processing frames of streaming input data.
Fig. 4 illustrates another example scenario for processing frames of streaming input data.
Fig. 5 illustrates another example scenario for processing frames of streaming input data.
FIG. 6 illustrates an example data access pattern for a non-streaming matrix.
Fig. 7 is an example process of processing a sparse non-streaming matrix.
FIG. 8 is a flow chart of an example process for generating output data using a hardware architecture template.
Like reference numbers and designations in the various drawings indicate like elements.
Detailed Description
FIG. 1 illustrates an example architectural design system 100. Architecture design system 100 is an example of a system implemented on one or more computers in one or more locations, in which the systems, components, and techniques described below may be implemented. Some components of architecture design system 100 may be implemented as computer programs configured to run on one or more computers.
As shown in fig. 1, the architecture design system 100 may include an architecture enhancer system 120 configured to process input data 110 to generate output data 170 associated with an enhanced hardware architecture of a hardware component.
More specifically, the output data 170 may be used to instantiate a hardware architecture, and the hardware architecture may be used to fabricate hardware components configured to handle streaming of streaming input data, e.g., streaming of images. The hardware components may be configured to perform different operations to process the streaming input data, e.g., operations using a matrix or vector stored by the components and machine learning computations of the streaming input data. The streaming input data may be in vector, matrix, or tensor form. The hardware component may be a Graphics Processing Unit (GPU), a Tensor Processing Unit (TPU), an Application Specific Integrated Circuit (ASIC), or another suitable processing unit or circuit configured to satisfactorily process streaming of images.
As an example, the hardware component may be part of a client device or edge device, such as a smart phone, computer, portable tablet, etc., designed with one or more computing units configured to process streaming input data, e.g., streaming of images or video. Streaming input data may be received by the hardware component frame by frame at defined time intervals and processed by the edge device according to the order of reception, e.g., using other data stored at the edge device. For example, the edge device may perform an inference operation of the neural network to process the input video frame-by-frame to identify faces using network weights stored at the edge device.
The input data 110 may include data representing characteristics of streaming input data to be processed by a hardware component having a particular hardware architecture. Characteristics may include a particular reception rate of streaming input data. For example, the reception rate may be one frame per millisecond, second, minute, or other suitable unit of time. In some implementations, the streaming input data may include a plurality of image frames, such as video. The characteristics may also include a particular data size for each frame received at the time step. For example, when each frame is an image frame, the data size may be 720×480 pixels, 1280×720 pixels, 1920×1080 pixels, 4096×2160 pixels, or a pixel resolution of greater. In another example, the data size of each frame may be the number of bits or bytes of each frame. For example, when a frame is other types of data, the data size may be represented in bits or bytes.
The input data may also include other characteristics. One example of a characteristic may be a blanking period of a sensor configured to receive streaming input data. The blanking period may include a vertical blanking period, a horizontal blanking period, or both. The blanking period generally refers to the period of time between the time the sensor receives the end of the final visible line (e.g., bottom or left line) of a frame or field and the time the sensor receives the beginning of the first visible line (e.g., top or right line) of the next frame. In one particular example, the frequency of the blanking period (i.e., the inverse of the time period) may be 60Hz for the vertical blanking period and 15,750Hz for the horizontal blanking period. Other frequencies may also be used. Thus, the processing rate of the hardware components is ideally adapted to the blanking period of the streaming image frame.
Another example characteristic may be a pixel format (or color format) of streaming input image data, such as RGB or YUV. Further, the characteristics of the streaming input data may include an order of arrival of each frame of the streaming input data.
The streaming input data may also be audio data or signals. For example, the audio data may include a recording of one or more voices, sounds, background noise, or other suitable types of audio data produced by one or more individuals. The streaming audio data may include audio captured by a smart speaker or other type of digital assistant device. Streaming audio input may include podcasts, radio broadcasts, and/or other types of audio that may be captured by an audio sensor such as a microphone.
Streaming input data may include different characteristics of streaming audio input data. For example, the characteristics of streaming audio may include a sampling rate. The sampling rate generally refers to the sampling frequency of an analog signal sampled from an audio signal using an audio sensor, i.e., the number of sampled analog signals acquired per unit time. The sampling rate may be 44.1kHz, 48 kHz, 88.2kHz, 96kHz, 192kHz or more. As another example, the characteristics of the streaming audio input data may include bit depth. Bit depth generally refers to the bit size of each audio sample, which is sometimes referred to as the audio resolution of the audio sample. The bit depth may be 4 bits, 16 bits, 24 bits, 64 bits, or other suitable bit depth. In some implementations, the characteristics of the streaming audio input data may include a bit rate. Bit rate generally refers to the number of bits transmitted or processed per unit time. The bit rate may be calculated based on the sampling rate and bit depth, for example, when a digital audio compact disc audio (CD) has a sampling rate of 44.1kHz, a bit depth of 16 bits, and a dual track, the CD may have a bit rate of 1.4 Mbit/s. Ideally, the processing rate of the hardware component is faster than the bit rate of the audio streaming input data to avoid backlog when the hardware component processes the streaming input audio.
Other characteristics of the audio streaming input data may include the audio format of the data. For example, the audio streaming input data may be encoded in Pulse Code Modulation (PCM), MPEG-1 audio layer 3 (MP 3), windows Media Audio (WMA) audio format, or other suitable audio format.
In some implementations, the input data 110 may include streaming input data to be processed by a hardware component, e.g., a machine learning processor that performs machine learning calculations. The architecture enhancer system 120 may be configured to analyze the streaming input data to generate data representative of characteristics of the streaming input data, such as a reception rate or arrival rate of each frame and a size of each frame.
Optionally, the input data 110 may also include data representing initial values of a set of configurable design parameters for instantiating the hardware architecture template. The initial values may be used to instantiate a default architecture, e.g., an architecture that includes one MAC unit per cluster. The default architecture may include, for example, a Static Random Access Memory (SRAM) -based row buffer unit in a cluster, where the row buffer unit has a single memory bank and is configured to store an entire row of input pixels for each frame. As another example, the initial value may include data indicating a zero accumulator array in a default architecture.
Although the streaming input data in the above examples is a stream of image frames, it should be understood that the streaming input data may include different types of data, such as audio recordings, data structures such as vectors and tensors, to name a few examples.
The output data 170 may include at least one enhanced parameter value set for instantiating or re-instantiating the hardware architecture using the architecture template. An enhanced parameter value set is determined for a design parameter set of an architecture template. The design parameters may include at least the number of clusters in the hardware architecture, the number of PEs in each cluster, the size of the MAC array in each Processing Element (PE), or any combination of two or more of these parameters. For example, the size of the MAC array may be 1, 4, 10, or more. As another example, the number of PEs in each cluster may be 1, 4, 7, 20, 50, or more. As another example, the number of clusters in the hardware architecture may be 1, 2, 8, 15, 30, or more. In some implementations, the output data 170 may include data defining an enhanced hardware architecture, including a set of enhanced parameter values and any other data defining how the hardware components should be manufactured.
The output data 170 may be encoded in a high-level computer language that may be synthesized into hardware circuitry and programmed in an object-oriented manner such as C or C++, as described above. In other examples, the output data 170 may be a list of enhancement parameter values.
The output data 170 may be provided to the manufacturing system 175 to produce a hardware component having a hardware architecture that is instantiated by the template using the parameter values in the output data. Manufacturing system 175 may be any suitable system for manufacturing hardware components, such as a manufacturing system or a chemical mechanical polishing system.
The architecture enhancer system 120 may include an enhancement engine 130 configured to generate output data 170 by processing the architecture template 195 based on the input data 110. For example, architecture enhancer system 120 may include a memory unit 190 configured to store and provide data representing architecture template 195 to enhancement engine 130. Alternatively, the enhancement engine 130 may receive the architecture template 195 from a server or memory unit external to the architecture enhancement subsystem 120.
The architecture template 195 may be high-level program code having a plurality of configurable design parameters. The architecture template 195 is configured to receive a set of design parameter values and, once executed by the system, may generate output data representing a hardware architecture for manufacturing hardware components for processing a particular type of streaming input data. For example, the enhancement engine 130 may provide a plurality of sets of design parameter values to the architecture template 195 and generate a plurality of candidate architectures 145.
The enhancement engine 130 includes a candidate generator 140 configured to generate a plurality of candidate architectures 145. Candidate generator 140 may process input data 110 and architecture template 195 to generate a plurality of candidate architectures 145. The candidate generator 140 is configured to explore a plurality of parameter values in a search space formed by a set of design parameters given the available resources for a particular period of time. The search space may have a size ranging from ten, hundreds, tens of thousands of design points (e.g., tuples each including corresponding values of all design parameters), or other suitable number of design points, depending on the target computing requirements for processing the streaming input data. For each set of candidate design parameter values obtained through exploration, candidate generator 140 may use architecture templates 195 to instantiate a corresponding hardware architecture. Details of the exploration of the search space are described below.
The enhancement engine 130 also includes an analysis engine 150 configured to analyze the candidate architectures 145 and generate performance values 155 for each candidate architecture 145 using one or more performance models 185. For example, the performance value may comprise any suitable value, such as a scalar value ranging from 0 to 100, that indicates the performance of the candidate architecture 145 in processing streaming input data. For example, the performance value 155 of the candidate architecture 145 may indicate the efficiency of the candidate hardware architecture 145 when used to process streaming input data. For example, for those architectures that meet data processing rate requirements to avoid backpressure, efficiency may be based on computational speed, percentage of time in the case of backpressure, data processing rate, or power or space consumption relative to data processing rate. It is not uncommon for a hardware architecture to be predicted to have a high performance value (e.g., 90 in 100) when processing first streaming input data, and to have a low performance value (e.g., 30 in 100) when processing second streaming input data that has different characteristics than the first streaming input data. Thus, by generating performance values associated with multiple, e.g., all, candidate architectures for processing particular streaming input data, system 100 can efficiently obtain one or more best performance candidate architecture designs for processing particular streaming input data using architecture template 195.
The performance model 185 may be an analytical model, a machine learning based model, or a simulation model configured to access different aspects of the performance of the hardware architecture to process specific types of streaming input data. The performance metrics may measure different aspects of the hardware architecture, such as power consumption, resource usage, throughput, or whether there will be any backpressure when processing streaming input data having characteristics indicated by the input data 110.
The performance model 185 may be represented in data stored in a memory unit 190 in the architecture enhancer system 120 or provided by an external memory unit or server.
As shown in fig. 1, the selection engine 160 may be configured to select a candidate architecture from a plurality of candidate architectures 145 as an enhanced hardware architecture based on the performance values 155. For example, the selection engine 160 may select the candidate architecture with the highest performance value 155 as the enhanced candidate architecture. As another example, the selection engine 160 may select a candidate architecture having a performance value 155 above a specified-e.g., predefined-threshold and use the minimum power or resources or both. For example, the selection engine 160 may filter each candidate architecture from the candidate architectures 145 that has a performance value 155 that does not meet or exceed a specified threshold. The selection engine 160 may then select a particular candidate architecture from among the remaining candidate architectures based on its performance values, power consumption estimates, required resources and/or space on the circuit board, and the like. For example, the selection engine 160 may select the remaining candidate architectures 145 that consume the least power and/or require the least space.
In another example, the selection engine 160 may filter the candidate architectures 145 based on power consumption and/or space required. For example, a device for which a hardware component is designed may have limited available power and/or space, e.g., especially if the device is a smart phone or other mobile device. In this example, the selection engine 160 may filter each candidate architecture 145 from among the candidate architectures 145 that would exceed the available power or space. The selection engine 160 may then select from the remaining candidate architectures 145 based on the performance values 155, for example, by selecting the remaining candidate architecture having the highest performance value 155.
The selection engine 160 may encode the enhanced hardware architecture or enhanced parameter values or both into the output data 170 for further operation. For example, the enhanced parameter values may be provided to multiple computers to instantiate the enhanced hardware architecture in parallel. As another example, the enhanced hardware architecture may be provided to one or more manufacturing devices to manufacture corresponding hardware components based on the enhanced hardware architecture, e.g., in parallel.
Fig. 2-5 illustrate example scenarios in which example hardware components having different designs process frames of streaming input data. For convenience, the above-described processes are described as being performed by hardware components of one or more computers located at one or more locations. For example, appropriately programmed hardware components manufactured using the architectural design system 100 of FIG. 1 may perform these processes.
The described hardware components fabricated using templates are configured to process streaming input data with different design levels. For example, a hardware architecture may have a first level design for a cluster, a second level design for a processing element (also referred to herein as a processing unit), and a third level design for an array of hardware units (also referred to herein as an array of hardware computing units, or below an array of hardware computing units, such as an array of MAC units). The described hardware architecture may be instantiated from the template after each design level is determined. For example, the design parameters may include the number and/or arrangement of clusters, the number and/or arrangement of PEs in each cluster, and/or the number of arrays of hardware units in each PE. As another example, the design parameters correspond to dimensions of each hardware cell array, such as dimensions or numbers of hardware cells (e.g., MAC cells) in the hardware cell array.
As shown in fig. 2, the example hardware architecture 200 may include a cluster 230, where the cluster 230 includes a processing unit 240. The processing unit 240 may include an array of hardware computing units 250. As another example of the hardware architecture 300 shown in FIG. 3, each cluster 330 may include a plurality of processing units 340a-c, each processing unit 340a-c having a respective hardware cell array 350a-c. In addition, another example of the hardware architecture 400 may include multiple clusters 430a, 430b. Each cluster 430a and 430b may include a processing unit 440a and 440b. Each processing unit 440a and 440b may include an array of hardware units 450a and 450b, respectively. Further, another example of the hardware architecture 500 may include a plurality of clusters 530a-x, each cluster having a plurality of processing units 540a-x, each processing unit 540a-x including an array of hardware units 550a-z. Although for each hardware architecture 200-500, for ease of illustration, there are only two, three, or four clusters, processing units, or arrays of hardware units depicted in fig. 2-5, it should be understood that a hardware architecture may include other numbers of clusters, processing units, and arrays of hardware units.
The hardware architecture may be configured to process frames of streaming input data per unit time, e.g., in time steps per frame. Each frame of streaming input data may be received in the form of a vector having multiple dimensions, e.g., a vector of 2, 5, 10, or 20 items. The dimension of the input vector may be 1 x input dim. Alternatively, each frame of streaming input data may be received in a matrix form, which may be processed as a vector by dividing the input matrix into a plurality of vectors.
In general, a hardware architecture may perform operations on input vectors using pre-stored matrices or vectors. The pre-stored matrix may be constructed as a matrix having dimensions, such as input dim×outputdim. In some implementations, the operations include vector or matrix multiplication, so the output data generated by the hardware architecture may be in the form of a vector having the dimension 1 x output dim. Or the output may be in matrix form, for example, if the operation includes matrix-matrix multiplication.
After determining a hardware architecture based on design parameter values using the described templates, a hardware component or system manufactured based on the described hardware architecture may divide per frame streaming input data (e.g., input vectors) into one or more partial tiles based on the dimensions of the hardware unit array, e.g., the number of MAC units in the array. For example, assuming that the array of MAC units includes D MAC units in the array, the dimension of each input tile may be dimension D. The partial segments are also referred to as partial segments in the following description. Each partial tile includes non-overlapping values of the input vector.
Referring back to fig. 2-5, the streaming input may be received frame by frame in a matrix or vector form. If the streaming input of the frame is received in matrix form, the controller or scheduler may remap or reshape the input matrix into an elongated vector or vectors for further processing by the hardware component. For example, if each frame of streaming input data is received in a matrix form, the controller or scheduler may treat each row of the matrix as a vector and transform the computation from matrix-by-matrix multiplication to vector-by-matrix multiplication. Another matrix multiplied by the input matrix or vector is a matrix stored in a memory unit, for example, instead of additional streaming input data, for example.
The streaming input vector 210 may be divided into a plurality of non-overlapping partial segments 215a-215c, each segment having a dimension D corresponding to the size of the hardware unit array 250. A controller or scheduler (e.g., a hardware hierarchical state machine) in the system may generate these segments 215a-c and use the segments to schedule operations to be performed in different clusters, PEs, and MAC unit arrays. Similarly, streaming input vectors 310, 410, and 510 may be divided into a plurality of partial segments 315a-c, 415a-c, and 515a-c, respectively. Although only three partial segments are shown in fig. 2-5, it should be appreciated that each frame of the input vector for a time step may be divided into more than 3 partial segments, such as 4, 8, 12, 24, 51, or another suitable number of partial segments.
In general, dimension D may be the same as or less than the column or row length input dim of the input matrix stored in the hardware component. For example, a frame streaming input data may have an input dimension of 100. Each partial tile and corresponding hardware cell array may have a size of 1, 10, 20, 50, 100 or another suitable size.
The component or system may store all partial segments in one or more buffers, e.g., buffers in a processing unit comprising an array of hardware units.
The hardware component or system may be configured to perform an operation on each input partial tile based on a vector of size D extracted or pre-extracted from a corresponding row or column of the pre-stored matrix (e.g., a partial row or column corresponding to the partial tile). Referring back to fig. 2 through 5, the pre-stored matrices may be matrix data 220, 320, 420, and 520, respectively. Operations may include, for example, dot-product and other suitable element-by-element arithmetic operations. The hardware component or system may generate partial outputs (e.g., partial sums) by performing the above operations at the time step and store the partial outputs in an accumulator array, such as accumulator arrays 260, 360, 460, and 560 shown in fig. 2-5, respectively.
The hardware component or system may repeatedly perform the above operations for each input portion tile and corresponding portion row or column of the pre-stored matrix. The total time of repetition may be based on design parameters such as different numbers of clusters, PEs, arrays of hardware units, and dimension D of each array of hardware units.
For example and referring back to fig. 2, the hardware component or system may repeat the above operation output dim times for each frame of streaming input data. Thus, the accumulator array may be sized as output dim for storing all partial outputs. Accumulator array 260 may aggregate the stored partial outputs and provide the aggregated outputs for further operation.
As another example and referring back to fig. 3, the hardware architecture 300 may include a plurality of processing units 340a-c in a cluster 330. Assuming that each processing unit 340a-c may have an array of hardware units 350a-c (MAC array) of size 1, e.g., only a single MAC unit in each array of hardware units 350a-c, the number of MAC arrays is equal to the number of processing units 340a-c in cluster 330. The described hardware component or system may divide an input vector into a plurality of partial tiles, each partial tile having a dimension of one element, because the hardware cell array has a dimension of one element.
Assuming the output dimension is greater than or equal to the number of processing units, one or more processing units may be used to execute more than one partial tile, i.e., multiplePart of the block. Each processing unit may have a size/>Is provided. For example, with an output dimension of 10 and a number of processing units 350 per cluster of 5, each processing unit 350 is for processing two partial input tiles, respectively, and each processing unit 350 may have an accumulator array 360 of size 2. The processing unit in fig. 3 is designed to be equal to or less than the output dimension of the computational resource efficiency.
Referring to fig. 4, an example hardware architecture 400 may include multiple clusters, e.g., two clusters 430a and 430b. The streaming input vector 410 is divided into a plurality of partial segments 415a-c. Each of the plurality of segments 415a-c has the same dimensions as the hardware element arrays 450a and 450 b.
The plurality of segments 415a-c may be evenly distributed to each of the two clusters 430a and 430b. For example, as shown in FIG. 4, partial segments 415a and 415c are assigned to cluster 430a, and partial segment 415b and another partial segment (not shown) are assigned to cluster 430b.
Each of clusters 430a and 430b may be configured to process the assigned partial segments using a corresponding partial row or column of matrix data 420. The processes and operations performed in each cluster are similar to those described with respect to fig. 2. Each cluster 430a and 430b may generate a corresponding partial sum by processing the assigned partial segments, where the partial sum may have a dimension of 1 x output dim. Each cluster 430a and 430b may also be configured to provide a respective portion and vector to accumulator unit 455. The accumulator unit 455 may be configured to combine the partial sum vectors from the different clusters to generate an output vector and provide the output vector to the accumulator array 460. In some embodiments, the accumulator array may have a size of 1 x output dim.
Referring to FIG. 5 and as described above, the example hardware architecture 500 may include a plurality of clusters 530a-x, each having a plurality of processing units 540a-x, each having a corresponding array of hardware units 550a-y.
Similar to the process of FIG. 4, the described hardware component or system may be configured to divide a frame of an input vector at a time step into a plurality of partial segments 5151a-c. For example, as shown in FIG. 5, partial segments 515a and 515c are assigned to cluster 530a, and partial segment 515b and another partial segment (not shown) are assigned to cluster 530x.
Each cluster 530a-x performs corresponding processes and operations similar to those described with respect to fig. 3. Each cluster 530a-x may generate a respective partial sum vector having a dimension of 1 x output dim and provide the respective partial sum to accumulator unit 555. Accumulator unit 555 is configured to combine the corresponding partial sum vectors and generate an output vector to be provided to accumulator array 560 for further operation. Accumulator array 560 may include a size.
Referring back to fig. 1 in conjunction with fig. 2-5, the architecture design system 100 may generate the hardware architectures 200, 300, 400, and 500 according to the characteristics of different streaming input data. For example, when streaming input data has a slower arrival rate (e.g., every second) or each frame has a small size (e.g., 120 pixels of an image frame), the architectural design system 100 may generate a hardware architecture similar to the hardware architecture 200 using a single processing unit in a cluster. As another example, when streaming input data has a faster arrival rate (e.g., every millisecond), or each frame has a large size (e.g., 4000 pixels of an image frame) similar to the hardware architecture 300, 400, or 500, there are multiple processing elements in a cluster, or there are multiple clusters.
As described above, an example hardware architecture may have a set of design parameter values associated with at least one of a dimension of an array of hardware units, a number of arrays of hardware units in a processing unit, a number of processing units in a cluster, and a number of clusters in the hardware architecture. The system is configured to determine a set of design parameter values using a search space formed from the set of design parameters given constraints on input data arrival rate, throughput, power consumption, and requirements of available area or space. Details of determining the set of design parameter values are described in connection with fig. 8.
Turning to a pre-stored matrix for processing the input vector. The pre-memory matrix, also referred to as a non-streaming matrix, is fetched or pre-fetched to on-device memory, such as an on-chip Static Random Access Memory (SRAM) cell. Because the size of the pre-memory matrix corresponds to the size of the input vector at the time step, a larger vector input requires a larger pre-memory matrix, which results in a larger on-chip SRAM consumption.
Fig. 6 illustrates an example data access pattern for a non-streaming matrix 600. For convenience, the data access patterns are associated with processes performed by a system of one or more computers located at one or more locations. For example, a properly programmed hardware component manufactured based on a hardware architecture generated from the architecture design system 100 of fig. 1 may perform the process of generating the data access patterns.
In connection with fig. 5, assuming that the hardware architecture includes two clusters, e.g., clusters 630a and 630b, each with three PEs (or processing units) 640a-c, each PE2 having a MAC array of size 4, the system may divide the example non-streaming matrix 600 into two portions as shown in the two rectangles shown in fig. 6. The top may be assigned to cluster 630a and the bottom may be assigned to cluster 630b.
The system may access respective portions of the non-streaming matrix 600 to process corresponding partial segments. The non-streaming matrix 600 has dimensions of 8 x 9. For example, when cluster 630a receives a partial segment 615a of size 4 at PE 640 a. The cluster may also access a first column at the top (e.g., a partial column of the non-streaming matrix 600) and perform an element-by-element operation on each element of the partial segment 615a with a corresponding element in the partial column at PE 640a to generate a first partial sum. Similarly, cluster 630a may receive segment 615a at PE 640b and access the second column at the top, and perform operations of segment 615a and the second column at the top using PE 640b to generate a second partial sum. Cluster 630a may receive segment 615a at PE 640c and access the third column at the top and perform operations of segment 615a and the third column at the top using PE 640c to generate a third partial sum. The first, second and third partial sums may be arranged in a partial sum vector of dimension 3.
The PEs 640a-c may then repeat the operation by accessing the fourth through sixth columns of the top to generate the second portion of dimension 3 and the vector, and accessing the seventh through ninth columns of the top to generate the third portion of dimension 3 and the vector. Cluster 630a may provide the first, second, and third partial sum vectors to an accumulator unit (e.g., accumulator unit 555 of fig. 5) to form a middle partial sum vector of dimension 1 x 9.
Turning to the bottom portion of the non-streaming matrix 600, cluster 630b and its corresponding PEs 640d-f may access each column of the bottom portion to generate another middle portion and vector of dimension 1 x 9. In some implementations, the system may provide two intermediate portions and a vector as output data. Alternatively, the system may combine the portions and vectors to generate output data having a dimension of 1 x 9.
When the frames of streaming input data are in matrix form, the system may perform operations to process the frames of streaming input data following a process similar to the techniques described above. For example, if the input frame has dimensions of M rows and K columns and is received row by row at a hardware component or system, and the non-streaming matrix has dimensions of K rows and N columns. The system may process each row of the input matrix and load the non-streaming matrix M times.
However, when the size of the input frame is large and the non-streaming matrix is a sparse matrix with a certain level of sparsity (i.e., a matrix with a certain percentage of zero elements), loading or prefetching the large size of the non-streaming matrix multiple times is inefficient in terms of power consumption and computational resources. A technique of processing a sparse non-streaming matrix is described in connection with fig. 7.
Fig. 7 is an example process 700 of processing a sparse non-streaming matrix. For convenience, process 700 is described as being performed by a system of one or more computers located at one or more locations. For example, a suitably programmed hardware component manufactured in accordance with a hardware architecture generated from the architecture design system 100 of fig. 1 may perform the process 700.
Because the non-streaming matrix is predetermined and stored in on-chip memory, the system may determine the sparse level of the matrix and the zero elements of the matrix. The sparsity level may be 10%, 20%, 50% or another suitable sparsity level.
In some implementations, the sparsity level may be a block sparsity of K non-zero elements in a block defined as a1 by N vector. The block sparsity of the non-streaming matrix may be adjusted for a corresponding task such as face detection, gaze detection, or depth map generation. Because the sparsity level may be predetermined, the hardware components or systems described in this specification may pre-process and compress the sparse matrix offline.
In addition, the described techniques may also determine a partition size (dimension size D) for partitioning the input vector based on each determined sparsity level and characteristics of the streaming input data. After determining the dimension size D, the system may access the non-streaming matrix at a granularity of D elements and encode non-zero elements for each partial column or row of the non-streaming matrix. In this manner, the described techniques may maximize utilization of the hardware cell array and reduce metadata storage overhead and complexity of decoding hardware indexes as compared to using existing compression formats, e.g., compressed Sparse Row (CSR) format or Compressed Sparse Column (CSC) format.
As shown in fig. 7, the example non-streaming matrix (e.g., matrix data 720) includes non-zero elements 735 depicted in the shaded region and zero elements 740 depicted in the white region. For example, each of vector data 735a-d includes four elements. The first and third elements of vector data 735a are non-zero and the second and fourth elements of vector data 735a are zero. The first and fourth elements of vector data 735b are non-zero and the second and third elements of vector data 735b are zero. The second and third elements of vector data 735c are non-zero and the first and fourth elements of vector data 735c are zero.
The system may process each vector data 735a-d to generate corresponding compressed data 750a-d, where each compressed data includes only non-zero elements, where the identifier 760 indicates a relative position with respect to the original vector data 735 a-d. The identifier 760 may be generated based on an index map or bitmap. After receiving the partial segment at the PE, the system may process the partial segment using the identifier to select a value from the partial segment. The value selected from the partial segment corresponds to a non-zero element in the corresponding compressed data 750 a-d.
For example, the compressed data 750 generated based on the vector data 735a may include only non-zero data, i.e., the first element and the third element, and the identifier 760 associated with the first element and the third element. The identifier 760 is configured to indicate that a first element of the compressed data 750 corresponds to a first location of the vector data 735a and that a second element of the compressed data 750a corresponds to a third location of the vector data 735 a. When vector data 735a is processed with a corresponding input segment, the system may select values from only the partial segments located in the first and third positions of the input segment and perform element-by-element operations of the selected values with corresponding non-zero elements in compressed data 750 a.
Furthermore, the described techniques may support both dense and sparse computations. More specifically, the described techniques may switch a mode in which a hardware component processes streaming input data between a dense mode and a sparse mode in response to determining a change in an input matrix stored in the hardware component while the hardware component is performing an operation to process the streaming input data. For example, a manufactured hardware component may include a Control and Status Register (CSR) to switch the hardware component to process streaming input data with new non-streaming data from dense matrix mode to sparse matrix mode in response to determining a threshold sparseness value for the new non-streaming matrix defined sparse matrix mode. Note that the identifier is only used for sparse matrix mode.
FIG. 8 is a flow diagram of an example process 800 for generating output data using a hardware architecture template. For convenience, process 800 is described as being performed by a system of one or more computers located at one or more locations. For example, a suitably programmed system (e.g., the architecture design system 100 of fig. 1) may perform the process 800.
The system receives data representing a hardware architecture template (810). As described above, the hardware architecture template is configured to include a set of configurable design parameters and instantiate a hardware architecture based on the determined design parameter values. The hardware architecture may be used to fabricate hardware components configured to process specific streaming input data. The set of design parameters includes two or more of the following: (i) the number of clusters in the hardware architecture, (ii) the number of processing units in each cluster, and (iii) the size of the array of hardware units in each processing unit.
The system determines values of a set of configurable design parameters for a hardware architecture used to fabricate the hardware component (820). The determination of the value is based at least in part on characteristics of the respective streaming input data of the given hardware component. Details of the determination process are described in connection with steps 840-870.
The system generates output data (830) including the values. In some implementations, the output data may include an instantiated hardware architecture generated by setting the set of configurable design parameters with the determined values of the hardware templates. Alternatively, the output data may include both the obtained design parameter values and corresponding hardware architectures generated based on the values from the templates. The system may also provide output data for manufacturing the hardware component based on the hardware architecture.
To generate values for the set of configurable design parameters, the system first generates a plurality of candidate hardware architectures based on a search space for the set of configurable design parameters (840). As described above, the search space is based on the set of configurable design parameters and is defined by possible parameter values based on available computing resources, power consumption, and on-chip area usage. The system may generate a plurality of candidate hardware architectures having respective sets of design parameter values among one or more sets of possible design parameter values.
One or more different search algorithms may be used to determine one or more possible sets of design parameter values. For example, the system may perform a random search, an exhaustive search, or a genetic search algorithm.
One example range of the set of design parameters may be 5 clusters, 20 PEs, and 100 MAC unit arrays for manufacturing hardware components. In other words, the candidate hardware components may have a number of clusters ranging from 1 to 5, each cluster may have a number of PEs ranging from 1 to 20, and each PE may have 1-100 MAC unit arrays of corresponding size. The system may use the search algorithm described above to generate a plurality of candidate hardware architectures to search for a plurality of possible values from an example scope, and apply each set to instantiate a corresponding hardware component using the templates. For example, the system may start with a minimum value for the set of design parameters and gradually increase the value of one or more design parameters. Once the set of design parameter values appropriate for the throughput requirements is obtained, the system may stop the search.
In some embodiments, the system may search for parameter values associated with the size of the hardware element array, the number of hardware element arrays in the PE, and the number of PEs in the cluster, but not search or increase the number of clusters until a turning point is determined, wherein further increasing the size of the hardware element array or the number of PEs per cluster would adversely affect the computational clock rate or cause logic congestion, i.e., the size of the hardware element array and the number of processing elements per cluster are in the scalability limit of the cluster. In this way, the system can arrange more hardware units and PEs and minimize the number of clusters used to instantiate the hardware architecture to meet the required throughput.
The system determines a respective value of a set of performance measurements for each of a plurality of candidate hardware architectures (850). A performance model (or cost model) is used to determine a respective value of the set of performance values for each candidate hardware architecture. The performance values are each associated with a numerical value representing a cost or a combination of multiple costs. Cost may represent a level of latency, throughput, power consumption, on-chip area usage, computing resource usage, or any suitable combination thereof.
The performance model may be any suitable model for handling a hardware architecture having a set of design parameter values. The performance model may be an analytical model, a machine learning based model, or a hardware simulation model, to name a few examples.
The analytical model may generally determine a topology of the hardware architecture, such as interfaces, wiring, number of computing units such as multipliers, adders, and logic units, and determine performance values of the hardware architecture based on the topology. One example analytical model may be a roof line based model that generates performance values for a hardware architecture from machine peak performance, machine peak bandwidth, and arithmetic strength. The output of the roof line based model may be a function curve representing the upper performance limit (e.g., "ceiling") of the hardware architecture under specific computing requirements or resource limitations. As described above, the roof line based model may automatically determine a "bottleneck" factor for overall performance and output a performance value representing the level of latency, throughput, or power consumption, or both.
Alternatively, the performance model may be a machine learning model (e.g., supervised learning) trained with labeled training samples. Training samples may be generated using advanced synthesis and register transfer level simulation. The trained machine learning model is configured to generate predictions of performance values, and may be any suitable machine learning model, such as a multi-layer perceptron model.
Furthermore, the performance model may be a simulation model. The simulation model may generate power calculations and estimates of throughput based on characteristics of the hardware architecture given the one or more randomized input stimuli.
The system selects a candidate hardware architecture as the hardware architecture of the hardware component (860). More specifically, the system may select an enhanced hardware architecture based at least in part on the performance value. As described above, the hardware architecture may be the candidate hardware architecture having the highest performance value. Alternatively, the hardware architecture may have the most recent performance values, but require the least computational resources.
The system determines a value based on design parameter values associated with the selected candidate hardware architecture (870). The determined values may be included in output data provided for instantiating the hardware architecture using the templates or for manufacturing the hardware components.
Embodiments of the subject matter and the functional operations described in this specification can be implemented in digital electronic circuitry, in tangibly embodied computer software or firmware, in computer hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them. Embodiments of the subject matter described in this specification can be implemented as one or more computer programs, e.g., one or more modules of computer program instructions encoded on a tangible, non-transitory storage medium, for execution by, or to control the operation of, data processing apparatus. The computer storage medium may be a machine-readable storage device, a machine-readable storage substrate, a random or serial access memory device, or a combination of one or more of them. Alternatively or additionally, the program instructions may be encoded on an artificially generated propagated signal, e.g., a machine-generated electrical, optical, or electromagnetic signal, that is generated to encode information for transmission to suitable receiver apparatus for execution by data processing apparatus.
The term "data processing apparatus" refers to data processing hardware and encompasses all kinds of apparatus, devices, and machines for processing data, including by way of example a programmable processor, a computer, or multiple processors or computers. The apparatus may also be or further comprise a dedicated logic circuit, such as an FPGA (field programmable gate array) or an ASIC (application specific integrated circuit). In addition to hardware, the apparatus may optionally include code that creates an execution environment for the computer program, e.g., code that constitutes processor firmware, a protocol stack, a database management system, an operating system, or a combination of one or more of them.
A computer program, which may also be referred to or described as a program, software application, module, software module, script, or code, can be written in any form of programming language, including compiled or interpreted languages, or declarative or procedural languages, and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, or other unit suitable for use in a computing environment. A program may, but need not, correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data, such as one or more scripts stored in a markup language document, in a single file dedicated to the program in question, or in multiple coordinated files, such as files that store one or more modules, sub programs, or portions of code. A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a data communication network.
For a system of one or more computers to be configured to perform a particular operation or action, meaning that the system has installed thereon, software, firmware, hardware, or a combination thereof, in operation causes the system to perform the operation or action. By one or more computer programs to be configured to perform a particular operation or action is meant that the one or more programs include instructions that, when executed by a data processing apparatus, cause the apparatus to perform the operation or action.
As used in this specification, "engine" or "software engine" refers to a software implemented input/output system that provides an output that is different from an input. The engine may be an encoded block of functionality, such as a library, platform, software development kit ("SDK"), or object. Each engine may be implemented on any suitable type of computing device, such as a server, mobile phone, tablet computer, notebook computer, music player, electronic book reader, laptop or desktop computer, PDA, smart phone, or other fixed or portable device that includes one or more processors and computer readable media. In addition, two or more engines may be implemented on the same computing device or on different computing devices.
The processes and logic flows described in this specification can be performed by one or more programmable computers executing one or more computer programs to perform functions by operating on input data and generating output. The processes and logic flows can also be performed by, or combination of, special purpose logic circuitry, e.g., an FPGA or ASIC, and one or more programmed computers.
A computer adapted to execute a computer program may be based on a general purpose or special purpose microprocessor or both, or any other type of central processing unit. Typically, a central processing unit will receive instructions and data from a read only memory or a random access memory or both. The essential elements of a computer are a central processing unit for carrying out or executing instructions and one or more memory devices for storing instructions and data. The central processing unit and the memory may be supplemented by, or incorporated in, special purpose logic circuitry. Generally, a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks. However, the computer need not have such a device. Furthermore, the computer may be embedded in another device, such as a mobile phone, a Personal Digital Assistant (PDA), a mobile audio or video player, a game console, a Global Positioning System (GPS) receiver, or a portable storage device, such as a Universal Serial Bus (USB) flash drive, to name a few.
Computer readable media suitable for storing computer program instructions and data include all forms of non-volatile memory, media and memory devices, including by way of example semiconductor memory devices, e.g., EPROM, EEPROM, and flash memory devices; magnetic disks, such as internal hard disks or removable disks; magneto-optical disk; CD-ROM and DVD-ROM discs.
To provide for interaction with a user, embodiments of the subject matter described in this specification can be implemented on a computer having a display device, e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor, for displaying information to the user and a keyboard and a pointing device, e.g., a mouse, a trackball or other surface by which the user can provide input to the computer. Other kinds of devices may also be used to provide for interaction with a user; for example, feedback provided to the user may be any form of sensory feedback, such as visual feedback, auditory feedback, or tactile feedback; and input from the user may be received in any form, including acoustic, speech, or tactile input. In addition, the computer may interact with the user by sending and receiving documents to and from the device used by the user; for example, by sending web pages to a web browser on a user's device in response to requests received from the web browser. Further, a computer may interact with a user by sending text messages or other forms of messages to a personal device, such as a smart phone, running a messaging application, and receiving a response message from the user as a return.
Embodiments of the subject matter described in this specification can be implemented in a computing system that includes a back-end component, e.g., as a data server, or that includes a middleware component, e.g., an application server, or that includes a front-end component, e.g., a client computer having a graphical user interface, a web browser, or an application through which a user can interact with an implementation of the subject matter described in this specification, or any combination of one or more such back-end, middleware, or front-end components. The components of the system can be interconnected by any form or medium of digital data communication, e.g., a communication network. Examples of communication networks include Local Area Networks (LANs) and Wide Area Networks (WANs), such as the internet.
The computing system may include clients and servers. The client and server are typically remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other. In some embodiments, the server transmits data, e.g., HTML pages, to the user device, e.g., for displaying data to and receiving user input from a user interacting with the device acting as a client. Data generated at the user device, such as the results of a user interaction, may be received at the server from the device.
In addition to the embodiments described above, the following embodiments are also innovative:
Embodiment 1 is a method comprising: receiving data representing a hardware architecture template for generating a hardware architecture of a hardware component configured to perform operations on respective streaming input data, wherein the hardware architecture template comprises a set of configurable design parameters comprising two or more of: (i) the number of clusters in the hardware architecture, (ii) the number of processing units in each cluster, and (iii) the size of the array of hardware units in each processing unit; for a given hardware architecture of a given hardware component, determining a value of the set of configurable design parameters based at least in part on characteristics of respective streaming input data of the given hardware component, the determining comprising: generating a plurality of candidate hardware architectures for the given hardware component using the hardware architecture template based on the search space of the configurable set of design parameters, wherein each candidate hardware architecture includes a respective design parameter value of the configurable set of design parameters; for each candidate hardware architecture of the plurality of candidate hardware architectures, determining a respective value of a set of performance metrics associated with the candidate hardware architecture based on a performance model and characteristics of the respective streaming input data of the given hardware component; selecting a candidate hardware architecture from the plurality of candidate hardware architectures as the given hardware architecture based at least in part on the respective values of the set of performance metrics; and determining design parameter values associated with the selected candidate hardware architecture as values of the set of configurable design parameters for the given hardware architecture; and generating output data indicative of values of the set of design parameters for the given hardware architecture.
Embodiment 2 is the method of embodiment 1, further comprising: providing the output data to a hardware architecture template; instantiating the given hardware architecture based on the values of the set of design parameters for the given hardware architecture; and manufacturing the given hardware component based on the given hardware architecture.
Embodiment 3 is the method of embodiment 1 or 2, wherein the characteristics of the respective streaming input data for the given hardware component include an arrival rate of each frame and a size of each frame of the respective streaming input data for the given hardware component.
Embodiment 4 is the method of any one of embodiments 1-3, wherein the set of performance measurements includes at least one of latency, power consumption, resource usage, or throughput for processing the respective streaming input data of the given hardware component, wherein the performance model includes at least one of an analysis cost model, a machine learning cost model, or a hardware simulation model.
Embodiment 5 is the method of any one of embodiments 1 to 4, wherein the respective streaming input data for the given hardware component includes streaming image frames collected by the image sensor according to a time sequence.
Embodiment 6 is the method of embodiment 5, wherein the characteristics of the streamed image frames include at least one of a particular arrival rate of the image frames and a respective image resolution of each of the image frames.
Embodiment 7 is the method of embodiment 5, wherein the characteristic of the streaming image frame includes a blanking period including at least one of a vertical blanking period or a horizontal blanking period.
Embodiment 8 is the method of embodiment 5, wherein the characteristics of the streamed image frame comprise a pixel format, wherein the pixel format comprises an RGB or YUV color format.
Embodiment 9 is the method of any one of embodiments 1 to 8, wherein the respective streaming input data for the given hardware component includes streaming audio collected by an audio sensor,
Embodiment 10 is the method of claim 9 wherein the characteristics of the streaming input data include at least one of a particular sampling rate of the streaming audio, a bit depth of the streaming audio, a bit rate of the streaming audio, or an audio format of the streaming audio.
Embodiment 11 is the method of any one of embodiments 1 to 10, wherein performing operations on the respective streaming input data using a given hardware component comprises: for each frame of streaming input data: dividing an input vector of a frame into a plurality of partial vectors, each partial vector comprising non-overlapping values of the input vector; and for each partial vector of the plurality of partial vectors, assigning the partial vector to a respective cluster of the plurality of clusters, each cluster having a respective number of processing units, and each processing unit having an array of hardware units of a respective size corresponding to a value of the set of design parameters for the given hardware architecture; multiplying, by the respective clusters, each value of the partial vector with a corresponding value of a partial row of the matrix stored in memory to generate a respective partial sum; and storing the corresponding partial sums in an accumulator array.
Embodiment 12 is the method of embodiment 11, wherein performing operations on the respective streaming input data of the given hardware component using the given hardware component includes performing the operations based on a sparseness level of a matrix stored in memory.
Embodiment 13 is the method of any one of embodiments 1 to 12, wherein performing operations switches between dense matrix mode and sparse matrix mode, wherein the switching process is controlled by a Control and Status (CSR) register.
Embodiment 14 is the method of embodiment 11, wherein the performing in sparse matrix mode when generating the corresponding values of the partial rows of the matrix stored in memory, and wherein the generating further comprises: determining non-zero values in partial rows of a matrix stored in memory; generating an identifier indicating a location of non-zero values of a portion of the rows in the matrix, wherein the identifier comprises an index or a bitmap; and generating a compressed vector of non-zero values associated with the corresponding identifier as the corresponding value of the partial row of the matrix.
Embodiment 15 is the method of embodiment 14, further comprising: selecting a value of a partial vector corresponding to the compressed vector based on the corresponding identifier; and multiplying each of the selected values of the partial vector with a corresponding non-zero value of the compressed vector.
Embodiment 16 is the method of any one of embodiments 1-15, wherein the given hardware architecture includes data indicative of an upper limit sparseness level of one or more matrices stored in the memory, wherein the given hardware architecture is configured to dynamically re-instantiate to process the streaming input data with a second matrix of the one or more matrices, the second matrix having a different sparseness level than a first matrix of the one or more matrices.
Embodiment 17 is the method of any one of embodiments 1-16, wherein generating the plurality of candidate hardware architectures using the hardware architecture template based on the search space for the set of configurable design parameters comprises: exploring the search space for the set of design parameters using at least one of: random search algorithms, exhaustive search algorithms, or genetic algorithms.
Embodiment 18 is the method of any one of embodiments 1-17, wherein exploring the search space for the set of configurable design parameters comprises: exploring design parameter values corresponding to the size of the array of hardware units in each processing unit and the number of processing units in the cluster; determining that design parameter values corresponding to a size of the array of hardware units and a number of processing units in the cluster are at scalability limits for the cluster; and in response, exploring design parameter values corresponding to the number of clusters.
Embodiment 19 is a system comprising one or more computers and one or more storage devices storing instructions that are operable when executed by the one or more computers to cause the one or more computers to perform the method according to any one of embodiments 1 to 18.
Embodiment 20 is a computer storage medium encoded with a computer program comprising instructions that, when executed by data processing apparatus, are operable to cause the data processing apparatus to perform a method according to any of embodiments 1 to 18.
While this specification contains many specifics, these should not be construed as limitations on the scope of any invention or of what may be claimed, but rather as descriptions of features that may be specific to particular embodiments of particular inventions. Certain features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely, various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable subcombination. Furthermore, although features may be described above as acting in certain combinations and even initially claimed as such, one or more features from a claimed combination can in some cases be excised from the combination, and the claimed combination may be directed to a subcombination or variation of a subcombination.
Similarly, although operations are depicted in the drawings in a particular order, this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order, or that all illustrated operations be performed, to achieve desirable results. In some cases, multitasking and parallel processing may be advantageous. Moreover, the separation of various system modules and components in the embodiments described above should not be understood as requiring such separation in all embodiments, and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.
Specific embodiments of the subject matter have been described. Other embodiments are within the scope of the following claims. For example, the actions recited in the claims can be performed in a different order and still achieve desirable results. As one example, the processes depicted in the accompanying drawings do not necessarily require the particular order shown, or sequential order, to achieve desirable results. In some cases, multitasking and parallel processing may be advantageous.
Claims (20)
1. A method, comprising:
Receiving data representing a hardware architecture template for generating a hardware architecture of a hardware component configured to perform operations on respective streaming input data, wherein the hardware architecture template comprises a set of configurable design parameters including two or more of: (i) the number of clusters in the hardware architecture, (ii) the number of processing units in each cluster, and (iii) the size of the array of hardware units in each processing unit;
For a given hardware architecture of a given hardware component, determining a value of the set of configurable design parameters based at least in part on characteristics of respective streaming input data of the given hardware component, the determining comprising:
Generating a plurality of candidate hardware architectures for the given hardware component using the hardware architecture template based on a search space of the set of configurable design parameters, wherein each candidate hardware architecture includes a respective design parameter value of the set of configurable design parameters;
For each of the plurality of candidate hardware architectures, determining a respective value of a set of performance metrics associated with the candidate hardware architecture based on a performance model and the characteristics of the respective streaming input data of the given hardware component;
Selecting a candidate hardware architecture from the plurality of candidate hardware architectures as the given hardware architecture based at least in part on respective values of the set of performance metrics; and
Determining a design parameter value associated with the selected candidate hardware architecture as a value of the set of configurable design parameters for the given hardware architecture; and
Output data is generated that indicates values of the set of design parameters for the given hardware architecture.
2. The method of claim 1, further comprising:
providing the output data to the hardware architecture template;
Instantiating the given hardware architecture based on values of the set of design parameters of the given hardware architecture; and
The given hardware component is manufactured based on the given hardware architecture.
3. The method of claim 1, wherein the characteristics of the respective streaming input data of the given hardware component comprise an arrival rate of each frame and a size of each frame of the respective streaming input data of the given hardware component.
4. The method of claim 1, wherein the set of performance metrics comprises at least one of: latency, power consumption, resource usage, or throughput for processing the respective streaming input data for the given hardware component, wherein the performance model comprises at least one of an analysis cost model, a machine learning cost model, or a hardware simulation model.
5. The method of claim 1, wherein the respective streaming input data for the given hardware component comprises streaming image frames collected by an image sensor according to a time sequence.
6. The method of claim 5, wherein the characteristics of the streaming image frames include at least one of a particular arrival rate of an image frame and a corresponding image resolution of each of the image frames.
7. The method of claim 5, wherein the characteristic of the streaming image frame comprises a blanking period comprising at least one of a vertical blanking period or a horizontal blanking period.
8. The method of claim 5, wherein the characteristics of the streaming image frame comprise a pixel format, wherein the pixel format comprises an RGB or YUV color format.
9. The method of claim 1, wherein the respective streaming input data of the given hardware component comprises streaming audio collected by an audio sensor.
10. The method of claim 9, wherein the characteristics of the streaming input data comprise at least one of a particular sampling rate of the streaming audio, a bit depth of the streaming audio, a bit rate of the streaming audio, or an audio format of the streaming audio.
11. The method of claim 1, wherein performing an operation on the respective streaming input data using the given hardware component comprises:
for each frame of the streaming input data:
Dividing an input vector of the frame into a plurality of partial vectors, each partial vector comprising non-overlapping values of the input vector; and
For each of the plurality of partial vectors,
Assigning the partial vectors to respective ones of a plurality of clusters, each cluster having a respective number of processing units, and each processing unit having a respective size hardware unit array corresponding to a value of the set of design parameters of the given hardware architecture;
multiplying, by the respective clusters, each value of the partial vector with a corresponding value of a partial row of a matrix stored in memory to generate a respective partial sum; and
The corresponding partial sums are stored in an accumulator array.
12. The method of claim 11, wherein performing an operation on the respective streaming input data of the given hardware component using the given hardware component comprises performing the operation based on a sparseness level of a matrix stored in memory.
13. The method of claim 1, wherein the performing operation switches between dense matrix mode and sparse matrix mode, wherein the switching process is controlled by a control and status CSR register.
14. The method of claim 11, wherein when generating the corresponding values of the partial rows of the matrix stored in memory is performed in a sparse matrix mode, and wherein the generating further comprises:
Determining non-zero values in the partial rows of the matrix stored in memory;
Generating an identifier indicating a location of the non-zero values of the partial row in the matrix, wherein the identifier comprises an index or a bitmap; and
A compressed vector of non-zero values associated with a corresponding identifier is generated as the corresponding value for the portion of rows of the matrix.
15. The method of claim 14, further comprising:
selecting a value of the partial vector corresponding to the compressed vector based on the corresponding identifier; and
Each of the selected values of the partial vectors is multiplied with a corresponding non-zero value of the compressed vector.
16. The method of claim 1, wherein the given hardware architecture comprises data indicative of an upper bound sparsity level of one or more matrices stored in memory, wherein the given hardware architecture is configured to dynamically re-instantiate to process the streaming input data with a second matrix of the one or more matrices, the second matrix having a different sparsity level than a first matrix of the one or more matrices.
17. The method of claim 1, wherein generating the plurality of candidate hardware architectures using the hardware architecture template based on the search space for the set of configurable design parameters comprises exploring the search space for the set of design parameters using at least one of: random search algorithms, exhaustive search algorithms, or genetic algorithms.
18. The method of claim 1, wherein exploring the search space for the set of configurable design parameters comprises:
exploring design parameter values corresponding to the size of the array of hardware units in each processing unit and the number of processing units in the cluster;
determining that the design parameter value corresponding to the size of the array of hardware units and the number of the processing units in the cluster is at a scalability limit for the cluster; and
In response, values of the design parameters corresponding to the number of clusters are explored.
19. One or more computer-readable storage media storing instructions that, when executed by one or more computers, cause the one or more computers to perform the respective operations of any one of claims 1-18.
20. A system comprising one or more computers and one or more storage devices storing instructions that, when executed by the one or more computers, cause the one or more computers to perform the respective operations of any one of claims 1-18.
Publications (1)
Publication Number | Publication Date |
---|---|
CN118056203A true CN118056203A (en) | 2024-05-17 |
Family
ID=
Similar Documents
Publication | Publication Date | Title |
---|---|---|
KR102208989B1 (en) | Device placement optimization through reinforcement learning | |
CN109313722B (en) | Memory efficient time-based back propagation | |
CN108351984B (en) | Hardware-efficient deep convolutional neural network | |
US20200104640A1 (en) | Committed information rate variational autoencoders | |
WO2020167490A1 (en) | Incremental training of machine learning tools | |
US20230359865A1 (en) | Modeling Dependencies with Global Self-Attention Neural Networks | |
US11385864B2 (en) | Counter based multiply-and-accumulate circuit for neural network | |
US20230223035A1 (en) | Systems and methods for visually guided audio separation | |
CN114041141A (en) | Systems, methods, and apparatus for early exit from convolution | |
US11593628B2 (en) | Dynamic variable bit width neural processor | |
CN115104108A (en) | Method and system for partitioning and bit width allocation of deep learning model for distributed system reasoning | |
US20200302283A1 (en) | Mixed precision training of an artificial neural network | |
US11429394B2 (en) | Efficient multiply-accumulation based on sparse matrix | |
US11836628B2 (en) | Method and apparatus with neural network operation processing | |
Liu et al. | AdaSpring: Context-adaptive and runtime-evolutionary deep model compression for mobile applications | |
CN114051618A (en) | System and method for pipeline parallelism for accelerated distributed processing | |
US20230267307A1 (en) | Systems and Methods for Generation of Machine-Learned Multitask Models | |
CN113994347A (en) | System and method for asymmetric scale factor support for negative and positive values | |
WO2022154829A1 (en) | Neural architecture scaling for hardware accelerators | |
CN118056203A (en) | Scalable hardware architecture template for processing streaming input data | |
CN111788582A (en) | Electronic device and control method thereof | |
TWI829208B (en) | Method and system for determining design parameter values of hardware architectures for processing streaming input data, and computer-readable storage medium | |
WO2023146613A1 (en) | Reduced power consumption analog or hybrid mac neural network | |
CN117063208A (en) | Unsupervised multi-model joint reasoning system and method | |
Debelee et al. | Deep Learning Models for Audio Processing Applications Under Resource-Constrained Devices: A Survey |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication |