DE202015009182U1 - Aligning panoramic and aerial photography - Google Patents
Aligning panoramic and aerial photography Download PDFInfo
- Publication number
- DE202015009182U1 DE202015009182U1 DE202015009182.2U DE202015009182U DE202015009182U1 DE 202015009182 U1 DE202015009182 U1 DE 202015009182U1 DE 202015009182 U DE202015009182 U DE 202015009182U DE 202015009182 U1 DE202015009182 U1 DE 202015009182U1
- Authority
- DE
- Germany
- Prior art keywords
- image
- aerial
- panoramic
- aerial image
- plane
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
- 230000001131 transforming effect Effects 0.000 claims abstract description 11
- 230000009466 transformation Effects 0.000 claims description 18
- 238000000034 method Methods 0.000 description 51
- 238000013480 data collection Methods 0.000 description 9
- 238000000605 extraction Methods 0.000 description 5
- 238000012545 processing Methods 0.000 description 5
- 230000002452 interceptive effect Effects 0.000 description 4
- 238000004891 communication Methods 0.000 description 3
- 239000002131 composite material Substances 0.000 description 3
- 238000013507 mapping Methods 0.000 description 3
- 238000012986 modification Methods 0.000 description 3
- 230000004048 modification Effects 0.000 description 3
- 230000008859 change Effects 0.000 description 2
- 230000008569 process Effects 0.000 description 2
- 238000007792 addition Methods 0.000 description 1
- 238000004458 analytical method Methods 0.000 description 1
- 239000003086 colorant Substances 0.000 description 1
- 238000004590 computer program Methods 0.000 description 1
- 238000013479 data entry Methods 0.000 description 1
- 238000005516 engineering process Methods 0.000 description 1
- 239000000284 extract Substances 0.000 description 1
- 238000002156 mixing Methods 0.000 description 1
- 230000003287 optical effect Effects 0.000 description 1
- 238000013450 outlier detection Methods 0.000 description 1
- 238000007670 refining Methods 0.000 description 1
- 238000009877 rendering Methods 0.000 description 1
- 230000000007 visual effect Effects 0.000 description 1
Images
Classifications
-
- G06T3/14—
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T11/00—2D [Two Dimensional] image generation
- G06T11/60—Editing figures and text; Combining figures or text
-
- G06T3/18—
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T7/00—Image analysis
- G06T7/30—Determination of transform parameters for the alignment of images, i.e. image registration
Abstract
Computersystem, das Folgendes umfasst: einen oder mehrere Prozessor(en); und ein oder mehrere computerlesbare Medien, die computerlesbare Anweisungen speichern, die bewirken, wenn sie vom einen oder den mehreren Prozessoren ausgeführt werden, dass der eine oder die mehreren Prozessoren Vorgänge durchführt, wobei die Vorgänge Folgendes umfassen: Zugreifen auf ein Panoramabild, das aus einer Perspektive auf oder nahe Bodenhöhe erfasst wurde, bei das Panoramabild mit einer ersten Pose und ersten geometrischen Daten assoziiert ist; Erkennen einer Fassadenebene im Panoramabild zumindest teilweise auf Basis der ersten geometrischen Daten; Identifizieren eines Luftbilds zumindest teilweise auf Basis der erkannten Fassadenebene, wobei das Luftbild die Fassadenebene zeigt und das Luftbild mit einer zweiten Pose und zweiten geometrischen Daten assoziiert ist; Transformieren des Panoramabilds in ein verzerrtes Bild durch Projizieren einer Bildebene des Panoramabilds auf eine mit dem Luftbild assoziierte Bildebene zumindest teilweise auf Basis der ersten geometrischen Daten; Identifizieren einer oder mehrerer Merkmalsübereinstimmungen zwischen dem verzerrten Bild und dem Luftbild; Ausrichten des Panoramabilds am Luftbild zumindest teilweise auf Basis der einen oder mehreren Merkmalsübereinstimmungen.A computer system comprising: one or more processors; and one or more computer-readable media storing computer-readable instructions that, when executed by the one or more processors, cause the one or more processors to perform operations, the operations comprising: accessing a panoramic image consisting of a Perspective at or near ground level, where the panoramic image is associated with a first pose and first geometric data; Detecting a façade plane in the panoramic image based at least in part on the first geometric data; Identifying an aerial image based at least in part on the detected façade plane, wherein the aerial image shows the façade plane and the aerial image is associated with a second pose and second geometric data; Transforming the panoramic image into a distorted image by projecting an image plane of the panoramic image onto an image plane associated with the aerial image based at least in part on the first geometric data; Identifying one or more feature matches between the distorted image and the aerial image; Aligning the panoramic image on the aerial image based at least in part on the one or more feature matches.
Description
TECHNISCHES GEBIETTECHNICAL AREA
Die vorliegende Offenbarung betrifft allgemein die Bildverarbeitung und insbesondere das Ausrichten von Panoramaaufnahmen und Luftaufnahmen. Unter Schutz gestellt werden und Gegenstand des Gebrauchsmusters sind dabei, entsprechend den Vorschriften des Gebrauchsmustergesetzes, lediglich Vorrichtungen wie in den beigefügten Schutzansprüchen definiert, jedoch keine Verfahren. Soweit nachfolgend in der Beschreibung gegebenenfalls auf Verfahren Bezug genommen wird, dienen diese Bezugnahmen lediglich der beispielhaften Erläuterung der in den beigefügten Schutzansprüchen unter Schutz gestellten Vorrichtung oder Vorrichtungen.The present disclosure relates generally to image processing, and more particularly to the alignment of panoramic and aerial photographs. Be provided under protection and subject of the utility model are, according to the provisions of the utility model law, only devices as defined in the appended claims, but no method. Wherever in the description, if appropriate, reference is made to methods, these references are merely illustrative of the device or devices set forth in the appended claims.
HINTERGRUNDBACKGROUND
Panoramaaufnahmen eines geografischen Bereichs können von mobilen Datenerhebungseinheiten von einer Perspektive auf oder nahe Bodenhöhe erfasst werden. Diese Bilder können eine wertvolle Ressource zum Verfeinern von Darstellungen eines geografischen Bereichs sein, die zum Beispiel von einem geografischen Informationssystem wie einem Kartografiedienst oder einem virtuellen Globus bereitgestellt werden. Panoramaaufnahmen können zum Beispiel verwendet werden, um hochauflösende dreidimensionale Modelle verschiedener Sehenswürdigkeiten, Gebäude, Objekte, verschiedenem Gelände usw. in einem geografischen Informationssystem zu verfeinern oder zu generieren. Die Panoramaaufnahmen können auch verwendet werden, um interaktive dreidimensionale Aufnahmen eines geografischen Bereichs von einer Straßen- oder Bodenhöhe bereitzustellen. Die Panoramaaufnahmen können assoziierte Kameraparameter aufweisen, wie eine Bildpose und geometrische Informationen in Bezug auf den in den Aufnahmen gezeigten geografischen Bereich.Panoramic images of a geographic area can be captured by mobile data collection units from a perspective at or near ground level. These images can be a valuable resource for refining geographic area representations provided by, for example, a geographic information system such as a mapping service or a virtual globe. For example, panoramic images can be used to refine or generate high-resolution three-dimensional models of various landmarks, buildings, objects, various terrain, etc. in a geographic information system. The panoramic images may also be used to provide interactive three-dimensional images of a geographic area from a road or ground level. The panoramic images may have associated camera parameters, such as an image pose, and geometric information relating to the geographic area shown in the images.
Panoramaaufnahmen können in einer geografischen Informationssystemdatenbank gespeichert werden. Geografische Informationssystemdatenbanken können auch Luftaufnahmen eines geografischen Bereichs speichern. Die Luftaufnahmen können zum Beispiel von einem Flugzeug erfasst werden und können zum Beispiel eine geneigte Perspektive des geografischen Bereichs von einem von mehreren kanonischen Blickwinkeln, wie den kanonischen Blickwinkeln Nord, Süd, Ost und West bereitstellen. Die Datenbank der Luftaufnahmen kann mit Poseninformationen assoziiert sein. Zusätzlich kann die Datenbank der Luftaufnahmen eine assoziierte dreidimensionale Geometrie des in den Bildern dargestellten Gegenstands aufweisen.Panoramic images can be stored in a geographic information system database. Geographic Information System databases can also store aerial photographs of a geographical area. For example, the aerial photographs may be captured by an aircraft and may, for example, provide a tilted perspective of the geographical area from one of several canonical viewing angles, such as canonical angles north, south, east, and west. The database of aerial photographs may be associated with pose information. In addition, the database of aerial photographs may have an associated three-dimensional geometry of the subject depicted in the images.
KURZDARSTELLUNGSUMMARY
Aspekte und Vorteile von Ausführungsformen der vorliegenden Erfindung werden teilweise in der folgenden Beschreibung dargelegt werden oder können aus der Beschreibung erlernt werden oder können durch die Praxis der Ausführungsformen erlernt werden.Aspects and advantages of embodiments of the present invention will be set forth in part in the description which follows, or may be learned from the description, or may be learned by practice of the embodiments.
Ein exemplarischer Aspekt der vorliegenden Offenbarung richtet sich auf ein computerimplementiertes Verfahren des Ausrichtens von Panoramaaufnahmen an Luftbildern. Das Verfahren beinhaltet ein Zugreifen, durch ein oder mehrere Computergeräte, auf ein Panoramabild, das von einer Perspektive auf oder nahe Bodenhöhe erfasst wurde. Das Panoramabild kann mit einer ersten Pose und ersten geometrischen Daten assoziiert sein. Das Verfahren beinhaltet ferner ein Erkennen, durch das eine oder die mehreren Computergeräte, einer Fassadenebene im Panoramabild zumindest teilweise auf Basis der ersten geometrischen Daten. Das Verfahren beinhaltet ferner ein Identifizieren, durch das eine oder die mehreren Computergeräte, eines Luftbilds zumindest teilweise auf Basis der erkannten Fassadenebene. Das Luftbild zeigt die Fassadenebene und ist mit einer zweiten Pose und zweiten geometrischen Daten assoziiert. Das Verfahren beinhaltet ferner ein Transformieren, durch das eine oder die mehreren Computergeräte, des Panoramabilds in ein verzerrtes Bild durch Projizieren einer Bildebene des Panoramabilds auf eine mit dem Luftbild assoziierte Bildebene zumindest teilweise auf Basis der ersten geometrischen Daten. Das Verfahren ferner beinhaltet ein Identifizieren, durch das eine oder die mehreren Computergeräte, einer oder mehrerer Merkmalsübereinstimmungen zwischen dem verzerrten Bild und dem Luftbild, und ein Ausrichten, durch das eine oder die mehreren Computergeräte, des Panoramabilds am Luftbild zumindest teilweise auf Basis der einen oder mehreren Merkmalsübereinstimmungen.An exemplary aspect of the present disclosure is directed to a computer-implemented method of aligning panoramic images on aerial images. The method includes accessing, through one or more computing devices, a panoramic image captured from a perspective at or near ground level. The panoramic image may be associated with a first pose and first geometric data. The method further includes detecting, by the one or more computing devices, a facade plane in the panoramic image based at least in part on the first geometric data. The method further includes identifying, by the one or more computing devices, an aerial image based at least in part on the detected facade level. The aerial image shows the façade plane and is associated with a second pose and second geometric data. The method further includes transforming, by the one or more computing devices, the panoramic image into a distorted image by projecting an image plane of the panoramic image onto an image plane associated with the aerial image based at least in part on the first geometric data. The method further includes identifying, by the one or more computing devices, one or more feature matches between the distorted image and the aerial image, and aligning, by the one or more computing devices, the panoramic image on the aerial image based at least partially on the one or more aerial images several feature matches.
Andere Aspekte der vorliegenden Offenbarung richten sich auf Systeme, Vorrichtungen, greifbare, nicht-transitorische computerlesbare Medien, Benutzeroberflächen und Geräte zum Ausrichten von Panoramaaufnahmen und Luftaufnahmen.Other aspects of the present disclosure are directed to systems, devices, tangible, non-transitory computer-readable media, user interfaces, and devices for aligning panoramic and aerial photography.
Diese und andere Merkmale, Aspekte und Vorteile verschiedener Ausführungsformen werden besser in Bezug auf die folgende Beschreibung und angefügten Ansprüche verstanden werden. Die beigefügten Zeichnungen, die in diese Beschreibung einbezogen sind und einen Teil dieser darstellen, illustrieren Ausführungsformen der vorliegenden Offenbarung und dienen zusammen mit der Beschreibung dazu, die damit verbundenen Prinzipien zu erklären.These and other features, aspects, and advantages of various embodiments will become better understood with regard to the following description and appended claims. The accompanying drawings, which are incorporated in and constitute a part of this specification, illustrate embodiments of the present disclosure and, together with the description, serve to explain the principles associated therewith.
KURZE BESCHREIBUNG DER ZEICHNUNGEN BRIEF DESCRIPTION OF THE DRAWINGS
Eine ausführliche Erörterung der Ausführungsformen, die auf Fachleute auf dem Gebiet gerichtet sind, wird in der Beschreibung dargelegt, die Bezug auf die beigefügten Figuren nimmt, in denen:A detailed discussion of the embodiments directed to those skilled in the art will be set forth in the description which makes reference to the accompanying drawings, in which:
DETAILLIERTE BESCHREIBUNGDETAILED DESCRIPTION
Bezug wird nun im Detail auf Ausführungsformen genommen werden, von denen ein oder mehrere Beispiele in den Zeichnungen dargestellt sind. Jedes Beispiel wird zur Erläuterung der Ausführungsformen bereitgestellt, nicht zur Beschränkung der Erfindung. Tatsächlich ist für Fachleute ersichtlich, dass diverse Modifikationen und Variationen an den Ausführungsformen durchgeführt werden können, ohne vom Umfang oder Geist der vorliegenden Offenbarung abzuweichen. Zum Beispiel können Merkmale, die als Teil einer Ausführungsform veranschaulicht oder beschrieben werden, mit einer anderen Ausführungsform verwendet werden, um eine noch weitere Ausführungsform zu erreichen. Deshalb ist beabsichtigt, dass Aspekte der vorliegenden Offenbarung solche Modifikationen und Variationen abdecken.Reference will now be made in detail to embodiments, one or more examples of which are illustrated in the drawings. Each example is provided to illustrate the embodiments, not for the purpose of limiting the invention. Indeed, it will be apparent to those skilled in the art that various modifications and variations can be made to the embodiments without departing from the scope or spirit of the present disclosure. For example, features that are illustrated or described as part of one embodiment may be used with another embodiment to achieve still another embodiment. Therefore, it is intended that aspects of the present disclosure cover such modifications and variations.
Überblickoverview
Beispielhafte Aspekte der vorliegenden Offenbarung richten sich auf ein Ausrichten von Panoramaaufnahmen, die von einer Perspektive auf oder nahe Bodenhöhe erfasst wurde, mit Luftaufnahmen, die zum Beispiel aus einer schrägen Perspektive erfasst wurden. Wie hierin verwendet, können Panoramaaufnahmen ein Bild, das eine Panoramaansicht (z. B. eine Weitwinkelansicht) eines geografischen Bereichs bereitstellt, und/oder ein oder mehrere Bilder (z. B. nicht zusammengesetzte Bilder) beinhalten, die beim Generieren von Bildern verwendet werden, die eine Panoramaansicht eines geografischen Bereichs bereitstellen. Das Ausrichten eines Panoramabilds mit einem Luftbild kann schwierig sein, da die Bilder oft drastisch unterschiedliche Blickwinkel besitzen. Dies kann Unterschiede in den Darstellungen in den Bildern verursachen. Obwohl zum Beispiel ein Panoramabild und ein Luftbild beide die gleiche Gebäudefassade darstellen können, kann die Ansicht der Fassade wie im Luftbild gezeigt verkürzt, verdeckt oder anderweitig unscharf sein, wenn sie mit der Ansicht der Fassade wie im Panoramabild gezeigt verglichen wird. Eine andere Schwierigkeit beim Ausrichten eines Panoramabilds an einem Luftbild tritt auf, wenn die Bilder zu verschiedenen Zeiten erfasst werden. Die Bilder können zum Beispiel zu verschiedenen Tageszeiten oder zu verschiedenen Jahreszeiten erfasst werden. Dies kann bewirken, dass die Bilder verschiedene Schattierungen und Farben aufweisen. Zusätzlich kann sich die Geografie selbst zwischen den Zeiten verändern, zu denen die Bilder erfasst wurden, was bewirkt, dass die Bilder verschiedene Geografien zeigen. Eine Gebäudefassade kann zum Beispiel umgebaut werden, nachdem ein erstes Bild erfasst wurde, aber bevor ein zweites Bild erfasst wurde, was bewirkt, dass die Bilder verschiedene Variationen der gleichen Fassade zeigen.Exemplary aspects of the present disclosure are directed to aligning panoramas captured from a perspective at or near ground level with aerial photographs acquired, for example, from an oblique perspective. As used herein, panoramic images may include an image providing a panoramic view (eg, a wide angle view) of a geographic area and / or one or more images (eg, non-composite images) used in generating images that provide a panoramic view of a geographic area. Aligning a panoramic image with an aerial image can be difficult, as the images often have drastically different viewing angles. This can cause differences in the representations in the pictures. For example, although a panoramic image and an aerial view may both represent the same building facade, the facade's view may be shortened, obscured, or otherwise blurred as compared to the aerial view when compared to the view of the facade as shown in the panoramic image. Another difficulty in aligning a panoramic image with an aerial image occurs when the images are captured at different times. The images can be captured, for example, at different times of the day or at different seasons. This can cause the images to have different shades and colors. In addition, the geography itself may change between the times the images were captured, causing the images to show different geographies. For example, a building facade can be reconstructed after a first image has been captured but before a second image is captured which causes the images to show different variations of the same facade.
Angesichts der oben beschriebenen einzigartigen Herausforderungen stellen die offenbarten Ausführungsformen Merkmale zur effizienten und genauen Ausrichtung von Panoramaaufnahmen und Luftaufnahmen bereit. Spezifische Algorithmen werden implementiert, um Kameraparameter und mit sowohl Panoramabildern als auch Luftbildern assoziierte geometrische Daten in einem Bemühen einzusetzen, die Bilder abzugleichen. Verbesserte dreidimensionale Modelle, die aus der Implementierung der offenbarten Merkmale und Algorithmen resultieren, sind zur allgemeinen Bezugnahme und Analyse von städtischen Szenen nützlich. Insbesondere kann ein genaues und effizientes Abgleichen von Panorama- und Luftbildern für eine genauere Ausrichtung der Bilder sorgen. Die genaue Ausrichtung dieser Bilder kann zum Beispiel helfen, geografische Informationssysteme wie Kartografiedienste oder virtuelle Globen besser aufzufüllen.In view of the unique challenges described above, the disclosed embodiments provide features for efficiently and accurately aligning panoramic and aerial photographs. Specific algorithms are implemented to employ camera parameters and geometric data associated with both panoramic and aerial images in an effort to match the images. Improved three-dimensional models resulting from the implementation of the disclosed features and algorithms are useful for general reference and analysis of urban scenes. In particular, accurate and efficient blending of panoramic and aerial images can provide more accurate alignment of the images. For example, the precise alignment of these images can help refill geographic information systems such as mapping services or virtual globes.
Nach exemplarischen Aspekten der vorliegenden Offenbarung werden mit einer ersten Perspektive assoziierte Bilder und mit einer zweiten Perspektive assoziierte Bilder ausgerichtet. Panoramaaufnahmen, die aus einer Perspektive auf oder nahe Bodenhöhe erfasst wurden, können zum Beispiel mit Luftaufnahmen ausgerichtet werden. In einem bestimmten Beispiel kann auf ein Panoramabild, das aus einer Perspektive auf oder nahe Bodenhöhe erfasst wurde, zur Ausrichtung mit Luftaufnahmen zugegriffen werden. Das Panoramabild kann mit einer Pose assoziiert sein. Wie hierin verwendet, bezeichnet die Pose eines Bilds die Position und/oder Orientierung einer Kamera, wenn sie ein Bild erfasst, relativ zu einem Bezugspunkt. Das Panoramabild kann auch mit einer dreidimensionalen Geometrie der im Panoramabild gezeigten Aufnahme assoziiert sein. Die dreidimensionale Geometrie kann zum Beispiel durch Daten bestimmt werden, die durch einen Laser-Entfernungsmesser gesammelt wurden, wie LIDAR-Daten. Die dreidimensionale Geometrie kann zum Beispiel auch durch Structure-from-Motion-Techniken bestimmt werden.According to exemplary aspects of the present disclosure, images associated with a first perspective and images associated with a second perspective are aligned. For example, panoramic images captured from a perspective at or near ground level can be aligned with aerial photography. In one particular example, a panoramic image captured from a perspective at or near ground level may be accessed for aerial photography. The panoramic image may be associated with a pose. As used herein, the pose of an image refers to the position and / or orientation of a camera when capturing an image relative to a reference point. The panoramic image may also be associated with a three-dimensional geometry of the photograph shown in the panoramic image. For example, the three-dimensional geometry may be determined by data collected by a laser rangefinder, such as LIDAR data. The three-dimensional geometry can also be determined, for example, by structure-from-motion techniques.
Sobald auf das Panoramabild zugegriffen wurde, kann eine Fassadenebene im Panoramabild erkannt werden. Die Fassadenebene kann zumindest teilweise auf Basis der dreidimensionalen Geometrie der im Bild gezeigten Aufnahmen erkannt werden. Ein Luftbild kann dann zumindest teilweise auf Basis der erkannten Fassadenebene identifiziert werden. Das Luftbild kann die gleiche Gebäudefassade wie das Panoramabild zeigen und kann zum Beispiel aus einer schrägen Perspektive erfasst werden. Das identifizierte Luftbild kann das Luftbild mit der am wenigsten verkürzten, am geringsten verdeckten Ansicht der im Panoramabild gezeigten Gebäudefassade sein. Das Luftbild kann eine assoziierte Kamerapose aufweisen. Das Luftbild kann auch mit einer dreidimensionalen Geometrie der im Luftbild gezeigten Aufnahme assoziiert sein, wie der Stadt oder dem Ort, in dem sich die Gebäudefassade befindet. Die dreidimensionale Geometrie kann zum Beispiel eine stereobasierte Tiefenkarte beinhalten.Once the panoramic image has been accessed, a facade level in the panoramic image can be detected. The façade plane can be recognized at least in part based on the three-dimensional geometry of the images shown in the picture. An aerial photograph can then be identified, at least in part, on the basis of the detected façade level. The aerial image can show the same building facade as the panoramic image and can be captured, for example, from an oblique perspective. The identified aerial image may be the aerial image with the least shortened, least hidden view of the building facade shown in the panoramic image. The aerial image may have an associated camera pose. The aerial image may also be associated with a three-dimensional geometry of the photograph shown in the aerial photograph, such as the city or the location in which the building facade is located. The three-dimensional geometry may include, for example, a stereobased depth map.
Sobald auf das Panoramabild zugegriffen wurde und das Luftbild identifiziert wurde, kann das Panoramabild in ein verzerrtes Bild transformiert werden, das eine mit dem Luftbild assoziierte Perspektive aufweist. Das Panoramabild kann zum Beispiel zum Luftbild verzerrt werden, indem die Pose des Luftbilds, die Pose des Panoramabilds und die Position der erkannten Fassadenebene verwendet werden, um eine Bildebene des Panoramabilds auf eine mit dem Luftbild assoziierte Bildebene zu projizieren.Once the panoramic image has been accessed and the aerial image identified, the panoramic image can be transformed into a distorted image that has a perspective associated with the aerial image. For example, the panoramic image may be distorted to the aerial image by using the pose of the aerial image, the pose of the panoramic image, and the location of the detected facade plane to project an image plane of the panoramic image onto an image plane associated with the aerial image.
Eine oder mehrere Merkmalsübereinstimmungen zwischen dem verzerrten Bild und dem Luftbild können dann unter Verwendung einer Merkmalsabgleichstechnik identifiziert werden. Die Merkmalsabgleichstechnik kann zum Beispiel ein Extrahieren einer oder mehrerer Deskriptoren des verzerrten Bilds und des Luftbilds und ein Abgleichen der entsprechenden Deskriptoren im verzerrten Bild und im Luftbild umfassen. Die abgeglichenen Merkmale können dann verwendet werden, um eine geometrische Transformation zu finden, die das verzerrte Bild und das Luftbild in Beziehung setzen.One or more feature matches between the distorted image and the aerial image may then be identified using a feature matching technique. The feature matching technique may include, for example, extracting one or more descriptors of the distorted image and the aerial image and matching the corresponding descriptors in the distorted image and in the aerial image. The matched features can then be used to find a geometric transformation that relates the distorted image and the aerial image.
Sobald die geometrische Transformation gefunden ist, kann das Panoramabild am Luftbild auf Basis der geometrischen Transformation ausgerichtet werden. Die Ausrichtung kann zum Beispiel durch Erstellen von Randbedingungen durchgeführt werden, die dreidimensionale Fassadenpunkte, die mit der erfassten Fassadenebene assoziiert sind, und ihre zweidimensionale Lage im Panoramabild in Beziehung setzen. Als ein weiteres Beispiel kann die Ausrichtung durch Erstellen von Randbedingungen durchgeführt werden, die zweidimensionale Lagen in den Panorama- und Luftbildern in Beziehung setzen. Die Ausrichtung kann verbessert werden, indem die mit dem Panoramabild assoziierte Pose unter Verwendung der einen oder mehreren Merkmalsübereinstimmungen justiert wird. Ein Bündelausgleichungsalgorithmus kann zum Beispiel verwendet werden, um die Pose des Panoramabilds zu justieren und im Panoramabild gezeigte Objekte zumindest teilweise auf Basis der abgeglichenen Merkmale zwischen dem verzerrten Bild und dem Luftbild zu georeferenzieren.Once the geometric transformation is found, the panoramic image on the aerial image can be aligned based on the geometric transformation. Alignment may be accomplished, for example, by creating constraints that relate three-dimensional facade points associated with the detected facade plane and their two-dimensional location in the panoramic image. As another example, alignment may be accomplished by creating constraints that relate two-dimensional plies in the panoramic and aerial images. The alignment can be improved by adjusting the pose associated with the panoramic image using the one or more feature matches. For example, a beam-balancing algorithm may be used to adjust the pose of the panoramic image and to georeference objects shown in the panoramic image based at least in part on the matched features between the distorted image and the aerial image.
Sobald das Panoramabild und das Luftbild ausgerichtet worden sind, kann ein dreidimensionales Modell des in den Bildern gezeigten geografischen Bereichs zumindest teilweise auf Basis der Ausrichtung der Bilder aktualisiert werden. Das aktualisierte dreidimensionale Modell kann dann zum Beispiel in einem geografischen Informationssystem gespeichert werden, wo es von einem Benutzer zum Beispiel eines mobilen Computergeräts angefordert und an diesen übertragen werden kann.Once the panoramic and aerial images have been aligned, a three-dimensional model of the geographic area shown in the images may be updated based at least in part on the orientation of the images. The For example, an updated three-dimensional model may then be stored in a geographic information system where it may be requested and transmitted to a user of, for example, a mobile computing device.
Verschiedene Implementierungen der vorliegenden Offenbarung können zum Beispiel ein Ausschließen der Extrahierung von Deskriptoren an mit Vegetation assoziierten Pixeln von der offenbarten Merkmalsabgleichstechnik beinhalten. Weitere Implementierungen können ein Ausschließen der Extrahierung von Deskriptoren an Pixeln beinhalten, die nicht mit der Fassadenebene assoziiert sind.For example, various implementations of the present disclosure may include excluding the extraction of descriptors on vegetation associated pixels from the disclosed feature matching technique. Other implementations may include excluding the extraction of descriptors on pixels that are not associated with the facade plane.
Eine weitere Implementierung der vorliegenden Offenbarung kann die Extrahierung von Deskriptoren an Pixelbereichen des verzerrten Bilds ausschließen, die große Mengen an Unschärfe besitzen. Große Streifen von unscharfen Pixeln in einem Bild können bewirken, dass dieser Bereich unerkennbar ist, was Schwierigkeiten beim Merkmalsabgleich herstellt. In einer alternativen Ausführungsform können Unschärfen durch Transformieren eines nicht zusammengesetzten Bilds einer Fassadenebene anstatt eines vollständigen Panoramabilds in ein verzerrtes Bild reduziert werden. Verzerrte Bilder, die aus nicht zusammengesetzten Bildern resultieren, können geringere Unschärfe als entsprechende verzerrte Bilder aufweisen, die aus vollständigen Panoramabildern resultieren.Another implementation of the present disclosure may preclude extracting descriptors at pixel areas of the distorted image that have large amounts of blur. Large streaks of blurred pixels in an image may cause this region to be unrecognizable, causing difficulty in feature matching. In an alternative embodiment, blurring can be reduced by transforming a non-composite image of a facade plane into a distorted image rather than a full panorama image. Distorted images resulting from non-composite images may have less blur than corresponding distorted images resulting from complete panoramic images.
Nach einer exemplarischen Ausführungsform erhebt eine auf einem Transportgerät bereitgestellte mobile Datenerhebungseinheit Panoramaaufnahmen auf Straßenhöhe. Die mobile Datenerhebungseinheit erhebt ferner dreidimensionale Geometriedaten, die mit den Panoramaaufnahmen assoziiert sind. Auf ein bestimmtes Panoramabild auf Straßenhöhe wird zugegriffen, zusammen mit der Bildpose und den mit dem Bild assoziierten dreidimensionalen Geometriedaten. Auf Basis der Geometriedaten wird eine Fassadenebene im Bild auf Straßenhöhe erkannt. Sobald eine Fassadenebene erkannt wurde, wird ein Luftbild identifiziert, das die gleiche Fassadenebene zeigt. Das identifizierte Luftbild weist die am wenigsten verkürzte und am geringsten verdeckte Ansicht der erkannten Fassadenebene auf. Das Panoramabild wird dann durch Projizieren einer Bildebene des Panoramabilds auf eine mit dem Luftbild assoziierte Bildebene in ein verzerrtes Bild transformiert. Merkmalsübereinstimmungen zwischen dem verzerrten Bild und dem Luftbild werden dann unter Verwendung einer Merkmalsabgleichstechnik identifiziert. Sobald die Merkmalsübereinstimmungen identifiziert wurden, kann das Panoramabild am Luftbild ausgerichtet werden. Die Bilder werden durch Erstellen von Randbedingungen ausgerichtet, die dreidimensionale Fassadenpunkte, die mit der Fassadenebene assoziiert sind, und ihre zweidimensionale Lage im Panoramabild in Beziehung setzen. Alternativ können die Bilder durch Erstellen von Randbedingungen ausgerichtet werden, die zweidimensionale Lagen im Panoramabild und im Luftbild in Beziehung setzen.According to an exemplary embodiment, a mobile data collection unit provided on a transport device elevates panoramic images at street level. The mobile data collection unit also collects three-dimensional geometry data associated with the panoramic images. A particular panorama image at street level is accessed, along with the image pose and the three-dimensional geometry data associated with the image. Based on the geometry data, a façade level is detected in the image at street level. Once a façade level is detected, an aerial image is identified that shows the same façade level. The identified aerial image has the least shortened and least obscured view of the detected façade plane. The panoramic image is then transformed into a distorted image by projecting an image plane of the panoramic image onto an image plane associated with the aerial image. Feature matches between the distorted image and the aerial image are then identified using a feature matching technique. Once the feature matches have been identified, the panoramic image can be aligned with the aerial image. The images are aligned by creating boundary conditions that relate three-dimensional facade points associated with the facade plane and their two-dimensional location in the panoramic image. Alternatively, the images may be aligned by creating constraints that relate two-dimensional layers in the panoramic image and in the aerial image.
Beispielhafte Panoramaaufnahmen und LuftaufnahmenExemplary panorama shots and aerial photographs
Das Luftbild
Insbesondere kann ein geografisches Informationssystem Luftaufnahmen eines geografischen Bereichs beinhalten, die entlang verschiedener kanonischer Blickwinkel des geografischen Bereichs erfasst wurden, wie entlang der Nord-, Süd, Ost- und Westrichtungen. Die Luftaufnahmen können gespeichert und nach geografischen Koordinaten indiziert werden. Die Luftaufnahmen können verwendet werden, um einem Benutzer des geografischen Informationssystems eine interaktive Darstellung des geografischen Bereichs aus einer schrägen Perspektive bereitzustellen.In particular, a geographic information system may include aerial photographs of a geographic area captured along various canonical viewing angles of the geographical area, such as along the north, south, east and west directions. The aerial photographs can be stored and indexed according to geographic coordinates. The aerial photographs can be used to provide a geographic area user with an interactive view of the geographic area from an oblique perspective.
Die Tiefenkarte
Beispielhafte Verfahren zum Ausrichten von Panoramaaufnahmen mit LuftaufnahmenExemplary methods for aligning panoramic images with aerial photographs
Bei (
Bei (
Unter erneuter Bezugnahme auf
Aus dem Satz von Kandidaten-Luftbildern kann das Luftbild mit der am wenigsten verkürzten und am geringsten verdeckten Ansicht der Gebäudefassade, die im Panoramabild gezeigt wird, zur Ausrichtung mit dem Panoramabild identifiziert werden. In einer alternativen Ausführungsform kann das Luftbild mit der am wenigsten verkürzten und am wenigsten verdeckten Ansicht des bestimmten Bereichs der Gebäudefassade, die im Panoramabild erkennbar ist, zur Ausrichtung mit dem Panoramabild identifiziert werden. In noch einer anderen alternativen Ausführungsform kann das Luftbild zumindest teilweise auf Basis einer Ähnlichkeit der Ansichtsrichtung des Panoramabilds identifiziert werden. Das Identifizieren eines Luftbilds auf Basis der Ansichtsrichtung kann eine Bildähnlichkeit in der Azimutrichtung ermöglichen, was zu einem effizienteren und genaueren Merkmalsabgleich führen kann.From the set of candidate aerial photographs, the aerial image with the least shortened and least obscured view of the building facade shown in the panoramic image can be identified for alignment with the panoramic image. In an alternative embodiment, the aerial image with the least shortened and least obscured view of the particular area of the building façade seen in the panoramic image may be identified for alignment with the panoramic image. In yet another alternative embodiment, the aerial image may be identified based at least in part on a similarity of the viewing direction of the panoramic image. Identifying an aerial image based on the viewing direction may allow image similarity in the azimuth direction, which may result in more efficient and accurate feature matching.
Bei (
Obwohl ein verzerrtes Bild, wie durch
In einer bestimmten Implementierung können mit Vegetation assoziierte Pixel aus der Extrahierung ausgeschlossen werden. Dies kann zum Beispiel unter Verwendung von LIDAR-Daten oder anderen geometrischen Daten durchgeführt werden, um mit Vegetation assoziierte Pixel zu erkennen und diese Pixel aus der Extrahierung in den verzerrten und Luftbildern auszuschließen. In einer anderen bestimmten Ausführungsform können Deskriptoren, die sich nicht auf der im verzerrten und im Luftbild gezeigten Fassade befinden, aus der Extrahierung ausgeschlossen werden.In a particular implementation, pixels associated with vegetation may be excluded from the extraction. This can be, for example using LIDAR data or other geometric data to detect pixels associated with vegetation and exclude these pixels from extraction in the distorted and aerial images. In another particular embodiment, descriptors that are not on the façade shown in the distorted and aerial photographs may be excluded from the extraction.
Bei (
Obwohl extrahierte Deskriptoren zwischen dem verzerrten und dem Luftbild robust abgeglichen werden können, können dennoch Probleme auftreten. Ein Deskriptor auf einem wiederholten Fassadenelement (z. B. einem Fenster) kann zum Beispiel gleich gut mit einer beliebigen Kopie dieses Elements im anderen Bild übereinstimmen. Angesichts dieses Problems kann die Merkmalsabgleichsgenauigkeit durch Aufbewahren der mehreren besten Deskriptoren und Verwenden dieser Deskriptoren als Übereinstimmungskandidaten verbessert werden.Although extracting descriptors between the distorted and aerial images can be robustly balanced, problems can nevertheless arise. For example, a descriptor on a repeated facade element (eg, a window) may equally well match any copy of that element in the other image. In view of this problem, the feature matching accuracy can be improved by keeping the several best descriptors and using these descriptors as match candidates.
Bei (
In einer alternativen Ausführungsform kann eine Transformation unter Verwendung mehrerer angrenzender Panoramabilder gefunden werden. Falls es zum Beispiel nur eine kleine Anzahl von Übereinstimmungen in einem Bild gibt, kann ein Finden einer Transformation durch Verwendung mehrerer angrenzender Panoramabilder die Genauigkeit der Transformation verbessern. Eine Wohnfassade kann zum Beispiel oft kleiner und weniger planar als eine innerstädtische Fassade sein, was zu weniger Merkmalsübereinstimmungen führen kann. Dieses Problem kann durch Identifizieren einer konsistenten Transformation über mehrere angrenzende Panoramabilder hinweg im Gegensatz zu einem einzigen Panoramabild kompensiert werden.In an alternative embodiment, a transformation may be found using multiple contiguous panoramic images. For example, if there are only a small number of matches in an image, finding a transform by using multiple contiguous panoramic images can improve the accuracy of the transformation. For example, a residential façade can often be smaller and less planar than an inner-city façade, resulting in fewer feature matches. This problem can be compensated for by identifying a consistent transformation across multiple contiguous panoramic images as opposed to a single panoramic image.
Zusätzlich kann es für Fassaden, die 3D-Elemente aufweisen, wie Erkerfenster oder Säulen, keine einzelne Transformation geben, die Merkmale zwischen einem verzerrten Bild und einem Luftbild richtig abgleicht. In diesem Fall können die nicht planaren Bereiche zum Beispiel unter Verwendung von LIDAR-Daten modelliert werden. In einer alternativen Ausführungsform können Übereinstimmungen in nicht planaren Bereichen abgelehnt werden.In addition, for facades that have 3D elements, such as bay windows or columns, there can be no single transformation that properly balances features between a distorted image and an aerial image. In this case, the non-planar regions may be modeled using LIDAR data, for example. In an alternative embodiment, matches in non-planar areas may be rejected.
Die Art der bei (
Unter erneuter Bezugnahme auf
In einer anderen bestimmten Implementierung kann die Ausrichtung des Panoramabilds am Luftbild durch Erstellen von Randbedingungen durchgeführt werden, die 2D-Lagen im Panoramabild und im Luftbild durchgeführt werden. In dieser bestimmten Implementierung wird der dreidimensionale Fassadenpunkt nicht benötigt. Die Randbedingung wird durch Transformieren des Fassadenpunkts im Luftbild in das Panoramabild unter Verwendung der geometrischen Transformation, wie in Bezug auf (
Die Randbedingungen können verwendet werden, um die Pose des Panoramabilds zu verfeinern. Ein Bündelausgleichungsalgorithmus kann zum Beispiel implementiert werden, um die Pose des Panoramabilds zu justieren und im Panoramabild gezeigte Objekte zumindest teilweise auf Basis der erstellten Randbedingungen zwischen dem Panoramabild und dem Luftbild zu georeferenzieren.The boundary conditions can be used to refine the pose of the panorama image. For example, a beam-balancing algorithm may be implemented to adjust the pose of the panoramic image and to georeference objects shown in the panoramic image based, at least in part, on the established boundary conditions between the panoramic image and the aerial image.
Beispielhafte Systeme zum Ausrichten von Panoramaaufnahmen und LuftaufnahmenExemplary systems for aligning panoramic and aerial photographs
Das System
Der eine oder die mehreren Prozessoren
Das Ausrichtungsmodul
Es versteht sich von selbst, dass der Begriff „Modul” sich auf eine Computerlogik bezieht, die verwendet wird, um die erwünschte Funktionalität bereitzustellen. Somit kann ein Modul in Hardware, anwendungsspezifischen Schaltungen, Firmware und/oder Software implementiert werden, mittels der denen ein Allzweckprozessor gesteuert wird. In einer Ausführungsform sind die Module Programmcode-Dateien, die auf dem Speichergerät gespeichert sind, in einen Speicher geladen werden und von einem Prozessor ausgeführt werden oder können von Computerprogramm-Produkten bereitgestellt werden, zum Beispiel computerausführbare Anweisungen, die in einem greifbaren computerlesbaren Speichermedium, wie RAM, Festplatte oder optischen oder magnetischen Medien, gespeichert sind. Wenn Software verwendet wird, kann eine beliebige geeignete Programmiersprache oder Plattform verwendet werden, um das Modul zu implementieren.It will be understood that the term "module" refers to computer logic used to provide the desired functionality. Thus, a module may be implemented in hardware, application specific circuitry, firmware, and / or software by which a general purpose processor is controlled. In one embodiment, the modules are program code files stored on the storage device in FIG a memory may be loaded and executed by a processor or may be provided by computer program products, for example, computer-executable instructions stored in a tangible computer readable storage medium such as RAM, hard disk or optical or magnetic media. If software is used, any suitable programming language or platform can be used to implement the module.
Der Speicher
Der Server
Ähnlich wie der Server
Das Clientgerät
Das Clientgerät
Das Netzwerk kann ein beliebiger Typ von Kommunikationsnetzwerk sein, wie ein lokales Netzwerk (z. B. Intranet), Weitverkehrsnetz (z. B. Internet), Funknetzwerk oder eine Kombination davon. Das Netzwerk
Die hier besprochene Technologie nimmt Bezug auf Server, Datenbanken, Softwareanwendungen, und sonstige computergestützte Systeme, sowie auch unternommene Handlungen und die an und von derartigen Systemen und gesendeten Informationen. Der Durchschnittsfachmann auf diesem Gebiet wird erkennen, dass die naturgemäße Flexibilität computergestützter Systeme eine große Vielfalt an möglichen Konfigurationen, Kombinationen und der Aufteilung von Aufgaben und Funktionalitäten zwischen und unter den Komponenten ermöglicht. Die hierin diskutierten Serverprozesse können beispielsweise unter Verwendung eines einzelnen Servers oder mehrerer in Kombination betriebener Server umgesetzt werden. Datenbanken und Anwendungen können auf einem einzigen System oder auf mehrere Systeme verteilt, implementiert werden. Verteilte Komponenten können sequenziell oder parallel betrieben werden.The technology discussed herein refers to servers, databases, software applications, and other computerized systems, as well as actions taken and the information sent to and from such systems. One of ordinary skill in the art will recognize that the inherent flexibility of computerized systems enables a wide variety of possible configurations, combinations, and the sharing of tasks and functionality between and among the components. For example, the server processes discussed herein may be implemented using a single server or multiple servers operating in combination. Databases and applications can be deployed on a single system or across multiple systems. Distributed components can be operated sequentially or in parallel.
Während der vorliegende Gegenstand im Detail unter Bezugnahme auf spezifische Ausführungsbeispiele beschrieben wurde, versteht es sich, dass Fachleute auf dem Gebiet nach Erlangen eines Verständnisses des Vorstehenden leicht Veränderungen an, Variationen von und Äquivalente zu solchen Ausführungsformen anfertigen können. Demgemäß ist der Umfang der vorliegenden Offenlegung nur exemplarisch und nicht begrenzend, und die betroffene Offenbarung schließt die Einbeziehung solcher Modifizierungen, Varianten und/oder Hinzufügungen des vorliegenden Gegenstands nicht aus, die für Fachleute problemlos offensichtlich sind.While the present subject matter has been described in detail with reference to specific embodiments, it will be understood that those skilled in the art, having gained an understanding of the foregoing, are readily able to make changes, variations, and equivalents to such embodiments. Accordingly, the scope of the present disclosure is exemplary only and not limiting, and the disclosure contemplated does not exclude the inclusion of such modifications, variations and / or additions of the present subject matter which will be readily apparent to those skilled in the art.
Claims (7)
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/546,217 | 2014-11-18 | ||
US14/546,217 US9530235B2 (en) | 2014-11-18 | 2014-11-18 | Aligning panoramic imagery and aerial imagery |
Publications (1)
Publication Number | Publication Date |
---|---|
DE202015009182U1 true DE202015009182U1 (en) | 2016-12-01 |
Family
ID=54292920
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
DE112015005191.0T Pending DE112015005191T5 (en) | 2014-11-18 | 2015-09-22 | Aligning panoramic and aerial photography |
DE202015009182.2U Active DE202015009182U1 (en) | 2014-11-18 | 2015-09-22 | Aligning panoramic and aerial photography |
Family Applications Before (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
DE112015005191.0T Pending DE112015005191T5 (en) | 2014-11-18 | 2015-09-22 | Aligning panoramic and aerial photography |
Country Status (5)
Country | Link |
---|---|
US (1) | US9530235B2 (en) |
CN (1) | CN106462943A (en) |
DE (2) | DE112015005191T5 (en) |
GB (1) | GB2547517B (en) |
WO (1) | WO2016081062A1 (en) |
Families Citing this family (17)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9934222B2 (en) | 2014-04-22 | 2018-04-03 | Google Llc | Providing a thumbnail image that follows a main image |
USD780777S1 (en) | 2014-04-22 | 2017-03-07 | Google Inc. | Display screen with graphical user interface or portion thereof |
USD781317S1 (en) | 2014-04-22 | 2017-03-14 | Google Inc. | Display screen with graphical user interface or portion thereof |
US9972121B2 (en) * | 2014-04-22 | 2018-05-15 | Google Llc | Selecting time-distributed panoramic images for display |
USD781318S1 (en) | 2014-04-22 | 2017-03-14 | Google Inc. | Display screen with graphical user interface or portion thereof |
US9803985B2 (en) * | 2014-12-26 | 2017-10-31 | Here Global B.V. | Selecting feature geometries for localization of a device |
AU2017267983B2 (en) * | 2016-05-20 | 2022-03-31 | Magic Leap, Inc. | Method and system for performing convolutional image transformation estimation |
US10784134B2 (en) * | 2017-05-03 | 2020-09-22 | Applied Materials, Inc. | Image based substrate mapper |
US10670725B2 (en) * | 2017-07-25 | 2020-06-02 | Waymo Llc | Determining yaw error from map data, lasers, and cameras |
CN111164958A (en) * | 2017-09-29 | 2020-05-15 | 深圳市大疆创新科技有限公司 | System and method for processing and displaying image data based on pose information |
US11074752B2 (en) * | 2018-02-23 | 2021-07-27 | Sony Group Corporation | Methods, devices and computer program products for gradient based depth reconstructions with robust statistics |
US10704918B2 (en) | 2018-11-26 | 2020-07-07 | Ford Global Technologies, Llc | Method and apparatus for improved location decisions based on surroundings |
US11127162B2 (en) | 2018-11-26 | 2021-09-21 | Ford Global Technologies, Llc | Method and apparatus for improved location decisions based on surroundings |
US11175156B2 (en) | 2018-12-12 | 2021-11-16 | Ford Global Technologies, Llc | Method and apparatus for improved location decisions based on surroundings |
CN110096922B (en) * | 2019-05-08 | 2022-07-12 | 深圳市易尚展示股份有限公司 | Method and device for processing coding points, computer equipment and storage medium |
US10841483B1 (en) * | 2019-07-11 | 2020-11-17 | Denso International America, Inc. | System and method for calibrating at least one camera and a light detection and ranging sensor |
CN111797123A (en) * | 2020-07-13 | 2020-10-20 | 贵州电网有限责任公司 | Method for forming multi-dimensional panoramic data structure facing to event |
Family Cites Families (27)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6597818B2 (en) | 1997-05-09 | 2003-07-22 | Sarnoff Corporation | Method and apparatus for performing geo-spatial registration of imagery |
KR20070086037A (en) * | 2004-11-12 | 2007-08-27 | 목3, 인크. | Method for inter-scene transitions |
US8160400B2 (en) | 2005-11-17 | 2012-04-17 | Microsoft Corporation | Navigating images using image based geometric alignment and object based controls |
US7860280B2 (en) | 2006-06-09 | 2010-12-28 | Samsung Electronics Co., Ltd. | Facial feature detection method and device |
JP5012000B2 (en) * | 2006-12-15 | 2012-08-29 | ソニー株式会社 | Verification device, verification method, and program |
JP2008269471A (en) * | 2007-04-24 | 2008-11-06 | Sony Corp | Similar image decision device, similar image decision method, program, and recording medium |
US20090110267A1 (en) * | 2007-09-21 | 2009-04-30 | The Regents Of The University Of California | Automated texture mapping system for 3D models |
US8116596B2 (en) | 2008-01-30 | 2012-02-14 | Eastman Kodak Company | Recognizing image environment from image and position |
CN101639858A (en) * | 2009-08-21 | 2010-02-03 | 深圳创维数字技术股份有限公司 | Image search method based on target area matching |
US20140125667A1 (en) * | 2009-11-11 | 2014-05-08 | Google Inc. | Roof Generation And Texturing Of 3D Models |
CN101706793B (en) * | 2009-11-16 | 2012-09-26 | 中兴通讯股份有限公司 | Method and device for searching picture |
US9129432B2 (en) * | 2010-01-28 | 2015-09-08 | The Hong Kong University Of Science And Technology | Image-based procedural remodeling of buildings |
US8295589B2 (en) * | 2010-05-20 | 2012-10-23 | Microsoft Corporation | Spatially registering user photographs |
AU2011362799B2 (en) * | 2011-03-18 | 2016-02-25 | Apple Inc. | 3D streets |
CN102164298B (en) * | 2011-05-18 | 2012-10-03 | 长春理工大学 | Method for acquiring element image based on stereo matching in panoramic imaging system |
US20120300020A1 (en) * | 2011-05-27 | 2012-11-29 | Qualcomm Incorporated | Real-time self-localization from panoramic images |
US8989483B2 (en) * | 2011-06-10 | 2015-03-24 | Sri International | Method and apparatus for inferring the geographic location of captured scene depictions |
CN102289304B (en) * | 2011-08-17 | 2014-05-07 | Tcl集团股份有限公司 | Method and system for realizing mouse movement simulation of remote controller as well as remote controller |
US9977978B2 (en) | 2011-11-14 | 2018-05-22 | San Diego State University Research Foundation | Image station matching, preprocessing, spatial registration and change detection with multi-temporal remotely-sensed imagery |
US9501700B2 (en) * | 2012-02-15 | 2016-11-22 | Xactware Solutions, Inc. | System and method for construction estimation using aerial images |
US20140192050A1 (en) * | 2012-10-05 | 2014-07-10 | University Of Southern California | Three-dimensional point processing and model generation |
US9251433B2 (en) * | 2012-12-10 | 2016-02-02 | International Business Machines Corporation | Techniques for spatial semantic attribute matching for location identification |
US20140301645A1 (en) * | 2013-04-03 | 2014-10-09 | Nokia Corporation | Method and apparatus for mapping a point of interest based on user-captured images |
US9904852B2 (en) * | 2013-05-23 | 2018-02-27 | Sri International | Real-time object detection, tracking and occlusion reasoning |
US8761457B1 (en) | 2013-11-27 | 2014-06-24 | Google Inc. | Aligning ground based images and aerial imagery |
US9165361B1 (en) * | 2014-03-13 | 2015-10-20 | Raytheon Company | Video tracking with jitter, slewing, or zoom |
US20150371440A1 (en) * | 2014-06-19 | 2015-12-24 | Qualcomm Incorporated | Zero-baseline 3d map initialization |
-
2014
- 2014-11-18 US US14/546,217 patent/US9530235B2/en active Active
-
2015
- 2015-09-22 GB GB1621359.7A patent/GB2547517B/en active Active
- 2015-09-22 DE DE112015005191.0T patent/DE112015005191T5/en active Pending
- 2015-09-22 WO PCT/US2015/051466 patent/WO2016081062A1/en active Application Filing
- 2015-09-22 CN CN201580032140.XA patent/CN106462943A/en active Pending
- 2015-09-22 DE DE202015009182.2U patent/DE202015009182U1/en active Active
Also Published As
Publication number | Publication date |
---|---|
DE112015005191T5 (en) | 2017-08-24 |
US9530235B2 (en) | 2016-12-27 |
US20160140744A1 (en) | 2016-05-19 |
GB2547517A (en) | 2017-08-23 |
WO2016081062A1 (en) | 2016-05-26 |
GB2547517B (en) | 2021-10-27 |
GB201621359D0 (en) | 2017-02-01 |
CN106462943A (en) | 2017-02-22 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
DE202015009182U1 (en) | Aligning panoramic and aerial photography | |
DE202014010843U1 (en) | Align ground based images with aerial images | |
DE112020004813B4 (en) | System for expanding sensor systems and imaging systems with polarization | |
DE112011103221T5 (en) | Extend image data based on related 3D point cloud data | |
CN109598794B (en) | Construction method of three-dimensional GIS dynamic model | |
DE102020214863A1 (en) | SELF-MONITORED PROCEDURE AND SYSTEM FOR DEPTH ESTIMATION | |
DE112016001830T5 (en) | Discovering companies from images | |
DE202015009198U1 (en) | Selection of temporally distributed panoramic images for display | |
DE112013002200T5 (en) | Automatic adjustment of images | |
EP3550516A1 (en) | Environmental parameter based selection of a data model for recognizing an object of a real environment | |
DE202010018498U1 (en) | Matching an approximately localized request image with a reference image sentence | |
EP2923333B1 (en) | Method for the automatic creation of two- or three-dimensional building models | |
DE112019002080T5 (en) | POSITIONING SYSTEMS AND METHODS | |
DE202016008004U1 (en) | Automatically associate images using visual property references to related applications | |
DE202014010922U1 (en) | Generation of depth maps | |
DE102017012116A1 (en) | Preview production from panoramic pictures | |
DE112016006213T5 (en) | System and method for fusing outputs from sensors having different resolutions | |
DE112020000590T5 (en) | MAP AND PROCEDURE FOR CREATING A MAP | |
DE102021204765A1 (en) | Rendering augmented reality with masking | |
DE202015009139U1 (en) | image modification | |
DE112016003134T5 (en) | Display objects based on a variety of models | |
DE102020100230A1 (en) | RECONSTRUCTION OF LANDMARK POSITIONS IN AUTONOMOUS MACHINE APPLICATIONS | |
AT511460B1 (en) | METHOD FOR DETERMINING THE POSITION OF AN AIRCRAFT | |
EP3539085B1 (en) | 3d localization | |
EP2879090B1 (en) | Aligning ground based images and aerial imagery |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
R207 | Utility model specification | ||
R081 | Change of applicant/patentee |
Owner name: GOOGLE LLC (N.D.GES.D. STAATES DELAWARE), MOUN, USFree format text: FORMER OWNER: GOOGLE INC., MOUNTAIN VIEW, CALIF., US |
|
R082 | Change of representative |
Representative=s name: BETTEN & RESCH PATENT- UND RECHTSANWAELTE PART, DE |
|
R150 | Utility model maintained after payment of first maintenance fee after three years | ||
R151 | Utility model maintained after payment of second maintenance fee after six years | ||
R152 | Utility model maintained after payment of third maintenance fee after eight years |