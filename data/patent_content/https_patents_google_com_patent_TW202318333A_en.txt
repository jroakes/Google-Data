TW202318333A - Efficiently performing inference computations of a fully convolutional network for inputs with different sizes - Google Patents
Efficiently performing inference computations of a fully convolutional network for inputs with different sizes Download PDFInfo
- Publication number
- TW202318333A TW202318333A TW111140154A TW111140154A TW202318333A TW 202318333 A TW202318333 A TW 202318333A TW 111140154 A TW111140154 A TW 111140154A TW 111140154 A TW111140154 A TW 111140154A TW 202318333 A TW202318333 A TW 202318333A
- Authority
- TW
- Taiwan
- Prior art keywords
- size
- fixed
- input
- output
- pixel
- Prior art date
Links
- 238000000034 method Methods 0.000 claims abstract description 136
- 238000012545 processing Methods 0.000 claims abstract description 41
- 238000013527 convolutional neural network Methods 0.000 claims abstract description 33
- 238000003860 storage Methods 0.000 claims abstract description 11
- 230000002093 peripheral effect Effects 0.000 claims description 2
- 230000008569 process Effects 0.000 abstract description 37
- 238000004590 computer program Methods 0.000 abstract description 14
- 238000004422 calculation algorithm Methods 0.000 description 57
- 230000006870 function Effects 0.000 description 19
- 238000013528 artificial neural network Methods 0.000 description 9
- 238000013507 mapping Methods 0.000 description 9
- 238000004458 analytical method Methods 0.000 description 8
- 230000009471 action Effects 0.000 description 7
- 238000004364 calculation method Methods 0.000 description 6
- 238000004891 communication Methods 0.000 description 6
- 238000011176 pooling Methods 0.000 description 5
- 230000003993 interaction Effects 0.000 description 4
- 230000004913 activation Effects 0.000 description 3
- 230000008901 benefit Effects 0.000 description 3
- 230000014509 gene expression Effects 0.000 description 3
- 238000003709 image segmentation Methods 0.000 description 3
- 238000010801 machine learning Methods 0.000 description 3
- 230000000644 propagated effect Effects 0.000 description 3
- 230000004044 response Effects 0.000 description 3
- 238000012549 training Methods 0.000 description 3
- 239000013598 vector Substances 0.000 description 3
- 238000001514 detection method Methods 0.000 description 2
- 230000003287 optical effect Effects 0.000 description 2
- 238000000926 separation method Methods 0.000 description 2
- 238000013519 translation Methods 0.000 description 2
- 230000005540 biological transmission Effects 0.000 description 1
- 230000001413 cellular effect Effects 0.000 description 1
- 230000008859 change Effects 0.000 description 1
- 238000012512 characterization method Methods 0.000 description 1
- 238000004040 coloring Methods 0.000 description 1
- 238000007796 conventional method Methods 0.000 description 1
- 230000001186 cumulative effect Effects 0.000 description 1
- 238000013500 data storage Methods 0.000 description 1
- 238000009826 distribution Methods 0.000 description 1
- 230000000694 effects Effects 0.000 description 1
- 238000005516 engineering process Methods 0.000 description 1
- 238000002372 labelling Methods 0.000 description 1
- 239000004973 liquid crystal related substance Substances 0.000 description 1
- 238000007726 management method Methods 0.000 description 1
- 239000000463 material Substances 0.000 description 1
- 239000011159 matrix material Substances 0.000 description 1
- 230000007246 mechanism Effects 0.000 description 1
- 230000001537 neural effect Effects 0.000 description 1
- 238000005457 optimization Methods 0.000 description 1
- 230000008707 rearrangement Effects 0.000 description 1
- 230000001953 sensory effect Effects 0.000 description 1
- 239000000758 substrate Substances 0.000 description 1
- 238000012360 testing method Methods 0.000 description 1
- 238000012546 transfer Methods 0.000 description 1
- 230000017105 transposition Effects 0.000 description 1
- 230000000007 visual effect Effects 0.000 description 1
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/06—Physical realisation, i.e. hardware implementation of neural networks, neurons or parts of neurons
- G06N3/063—Physical realisation, i.e. hardware implementation of neural networks, neurons or parts of neurons using electronic means
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/0464—Convolutional networks [CNN, ConvNet]
Abstract
Description
本說明書係關於神經網路。特定言之，本說明書係關於執行接收不同大小之輸入之一全卷積網路之推論運算。This manual is about neural networks. In particular, this specification is concerned with performing inference operations on fully convolutional networks that receive inputs of varying sizes.
神經網路係採用一或多個非線性單元層來預測一經接收輸入之一輸出之機器學習模型。除了一輸出層之外，一些神經網路亦包含一或多個隱藏層。各隱藏層之輸出係用作網路中之下一層(即，下一隱藏層或輸出層)之輸入。網路之各層根據各自一組網路參數之當前值自一經接收輸入產生一輸出。A neural network is a machine learning model that employs one or more layers of nonlinear units to predict an output given an input. In addition to an output layer, some neural networks also contain one or more hidden layers. The output of each hidden layer is used as the input to the next layer in the network (ie, the next hidden or output layer). Each layer of the network generates an output from a received input based on the current value of a respective set of network parameters.
一全卷積網路係僅包含卷積神經網路層及(視需要)僅由僅在局部輸入區域上操作之組件組成之其他層(例如，匯集層及逐元素層，例如，應用一逐元素非線性激活函數之彼等)之一神經網路。明確言之，不同於其他類型之卷積神經網路，一全卷積網路不具有任何全連接層。一全卷積網路可經組態以對一輸入(例如，具有複數個像素之一影像)進行逐像素預測。換言之，全卷積網路可用於對該輸入之各像素進行一各自預測。需要進行逐像素預測之一任務之一實例係影像分割，其中一神經網路經組態以針對輸入影像之各像素產生多個類別之各者之一各自評分。A fully convolutional network consists of only convolutional neural network layers and (optionally) other layers consisting only of components that operate only on local input regions (e.g., pooling layers and element-wise layers, e.g., applying a One of the element nonlinear activation functions) neural network. Specifically, unlike other types of convolutional neural networks, a fully convolutional network does not have any fully connected layers. A fully convolutional network can be configured to perform pixel-by-pixel prediction on an input (eg, an image with a plurality of pixels). In other words, a fully convolutional network can be used to make an individual prediction for each pixel of the input. An example of a task that requires pixel-by-pixel prediction is image segmentation, where a neural network is configured to produce a respective score for each of a plurality of classes for each pixel of an input image.
本說明書大體上描述用於執行一神經網路之推論運算之技術。This specification generally describes techniques for performing inference operations of a neural network.
根據一態樣，所描述技術係關於一種由一或多個電腦執行之方法。該方法包括：接收待由部署於一硬體加速器上之一全卷積神經網路處理之一新輸入；自該新輸入判定一或多個固定大小輸入；將該一或多個固定大小輸入之各者提供至該硬體加速器以用於使用該全卷積神經網路執行推論運算；自該硬體加速器獲得藉由該全卷積神經網路針對該一或多個固定大小輸入之各者而產生之一各自固定大小輸出；及自該等各自固定大小輸出產生等效於將藉由使用該全卷積神經網路處理該新輸入而產生之一輸出之一最終輸出。該新輸入具有不同於該全卷積神經網路經組態以在部署於該硬體加速器上時處理之一固定大小之一第一大小。該一或多個固定大小輸入之各者具有該固定大小。該等各自固定大小輸出具有一或多個不準確的逐像素結果。According to one aspect, the described technology relates to a method performed by one or more computers. The method includes: receiving a new input to be processed by a fully convolutional neural network deployed on a hardware accelerator; determining one or more fixed-size inputs from the new input; each of which is provided to the hardware accelerator for performing an inference operation using the fully convolutional neural network; each of the one or more fixed-size inputs by the fully convolutional neural network is obtained from the hardware accelerator producing a respective fixed-size output; and producing from the respective fixed-size outputs a final output equivalent to an output that would be produced by processing the new input using the fully convolutional neural network. The new input has a first size different from a fixed size that the fully convolutional neural network is configured to handle when deployed on the hardware accelerator. Each of the one or more fixed-size inputs has the fixed size. These respective fixed-size outputs have one or more inaccurate pixel-by-pixel results.
本說明書中所描述之標的物可在特定實施例中實施以便實現以下優點之一或多者。The subject matter described in this specification can be implemented in particular embodiments so as to realize one or more of the following advantages.
所描述技術容許部署於一硬體加速器上之一靜態編譯之全卷積網路模型處理具有未知或變化大小之輸入資料。一般而言，雖然一全卷積神經網路原則上可處理任何任意大小之輸入，但已部署於一硬體加速器上之一靜態編譯之神經網路無法處理變化大小之輸入。此外，難以編譯用於部署於一硬體加速器上之能夠動態地處理未知或變化大小之輸入資料之一神經網路。然而，所描述技術可有效地將輸入資料平鋪成複數個較小固定大小輸入並提供該等輸入用於執行一靜態編譯之全卷積網路之推論運算。The described technique allows a statically compiled fully convolutional network model deployed on a hardware accelerator to process input data with unknown or varying sizes. In general, a statically compiled neural network deployed on a hardware accelerator cannot handle inputs of varying sizes, although a fully convolutional neural network can in principle handle inputs of any arbitrary size. Furthermore, it is difficult to compile a neural network for deployment on a hardware accelerator that can dynamically process input data of unknown or varying size. However, the described technique effectively flattens the input data into a plurality of smaller fixed-size inputs and provides these inputs for performing inference operations of a statically compiled fully convolutional network.
所描述技術亦可將所產生之固定大小輸出拼接在一起以針對一隨機大小之一給定輸入產生一最終輸出，該最終輸出等效於原本由處理該隨機大小之輸入之全卷積網路產生之輸出。因此，所描述技術容許一全卷積網路在部署於一硬體加速器上時僅經編譯以接受一固定大小之輸入，以針對不同大小之輸入產生準確輸出，而無需修改經編譯模型或該硬體加速器之操作。The described technique can also concatenate the generated fixed-size outputs together to produce a final output for a given input of a random size that is equivalent to what would otherwise be done by a fully convolutional network processing the random-sized input generated output. Thus, the described technique allows a fully convolutional network, when deployed on a hardware accelerator, to be compiled only to accept an input of a fixed size, to produce accurate output for inputs of different sizes, without modifying the compiled model or the Operation of hardware accelerators.
此外，所描述技術可基於一全卷積網路之特性自動產生用於平鋪及拼接網路之輸入及輸出之最佳化之參數。使用此等最佳化之參數，所描述技術可改良針對未知或變化大小之輸入資料執行推論運算之運算效率。Furthermore, the described technique can automatically generate parameters for optimization of the input and output of the tiling and tiling network based on the properties of a fully convolutional network. Using such optimized parameters, the described techniques can improve the computational efficiency of performing inference operations on input data of unknown or varying magnitude.
所描述技術可並行執行不同區塊(tile) (例如，固定大小輸入)之推論操作，從而利用相鄰加速器之間的資料共用性質來減少記憶體使用。例如，所描述技術可根據各種大小之輸入或輸出資料最佳化跨相鄰固定大小輸入之重疊區域之資料傳送。The described techniques can perform inference operations on different tiles (eg, fixed-size inputs) in parallel, thereby reducing memory usage by exploiting the nature of data sharing between adjacent accelerators. For example, the described techniques may optimize data transfer across overlapping regions of adjacent fixed-size inputs based on input or output data of various sizes.
此外，所描述技術對於不同輸入大小及硬體加速器架構係穩健的。所描述技術可自動識別硬體約束或要求(諸如系統記憶體頻寬)。所描述技術可基於所識別之硬體約束或要求有效地平鋪任意大尺寸輸入以適合部署於硬體加速器上之一全卷積網路。系統亦可藉由在輸入周圍填補零以達到固定大小而穩健地處理具有小於全卷積網路之固定大小之大小之輸入。Furthermore, the described techniques are robust to different input sizes and hardware accelerator architectures. The described techniques can automatically identify hardware constraints or requirements, such as system memory bandwidth. The described technique can efficiently tile arbitrarily large-sized inputs to fit a fully convolutional network deployed on hardware accelerators based on identified hardware constraints or requirements. The system can also robustly handle inputs with a size smaller than the fixed size of a full convolutional network by padding zeros around the input to achieve a fixed size.
例如，對於具有高級記憶體定址能力之加速器(例如，包含直接記憶體存取(DMA)引擎之加速器)，所描述技術可減少或消除與用於平鋪輸入及拼接固定大小輸出之資料操縱有關之額外耗用時間。作為另一實例，對於具有更簡單架構或更小記憶體頻寬之加速器，所描述技術可一次對一單個模型執行操作。在一些實施方案中，所描述技術可判定一運算系統中是否存在加速器陣列，且回應於判定存在加速器陣列，所描述技術可並行執行不同區塊之推論操作，從而利用相鄰加速器之間的資料共用性質來減少記憶體使用。For example, for accelerators with advanced memory addressing capabilities (e.g., accelerators including direct memory access (DMA) engines), the described techniques can reduce or eliminate data manipulations associated with tiling input and concatenating fixed-size output additional time-consuming. As another example, for accelerators with simpler architectures or smaller memory bandwidth, the described techniques can perform operations on a single model at a time. In some implementations, the described techniques can determine whether an accelerator array is present in a computing system, and in response to determining that an accelerator array is present, the described techniques can perform inference operations on different blocks in parallel, thereby utilizing data between adjacent accelerators Share properties to reduce memory usage.
此外，本說明書中所描述之技術係與習知資料並行化技術相異的且優於習知資料並行化技術。一般而言，資料並行化技術可將輸入資料(例如，一輸入影像)劃分成多個不相交部分(例如，輸入影像之片段)並將該多個部分指派至多個硬體組件(例如，硬體加速器)以獨立且並行地處理該等部分以產生部分輸出。在由硬體組件處理所有部分之後，經組態以執行資料並行化技術之一系統可藉由彙總部分輸出來產生一最終輸出。只要由各硬體組件對分別指定之部分正確地執行操作，系統就不需要考量部分輸出之任何部分對於產生最終輸出是否不合適或不準確。Furthermore, the techniques described in this specification are distinct from and superior to conventional data parallelization techniques. In general, data parallelization techniques divide input data (e.g., an input image) into multiple disjoint parts (e.g., segments of the input image) and assign the multiple parts to multiple hardware components (e.g., hardware volume accelerator) to process the parts independently and in parallel to generate part outputs. After all parts are processed by hardware components, a system configured to perform data parallelization techniques can generate a final output by summing the part outputs. The system need not consider whether any portion of the partial output is inappropriate or inaccurate for producing the final output, as long as the operations are performed correctly by the respective hardware components on the respectively designated portions.
然而，一般而言，一全卷積網路通常不利用資料並行化技術，此係因為由該全卷積網路處理一輸入影像之一部分(例如，如本說明書中所描述之一輸入影像之一區塊)而產生之一輸出可包含一或多個不正確或不準確的逐像素值。此係因為處理輸入之一區塊之系統之運算可涉及「相鄰像素」，使得輸出像素之一部分可為不準確的。In general, however, a fully convolutional network usually does not utilize data parallelization techniques because a portion of an input image (eg, a portion of an input image as described in this specification) is processed by the fully convolutional network. A block) resulting in an output may contain one or more incorrect or inaccurate pixel-by-pixel values. This is because the operation of the system processing a block of input may involve "neighboring pixels", so that a portion of the output pixels may be inaccurate.
貫穿本說明書之術語「相鄰像素」表示圍繞全卷積網路模型之一輸入之一邊界之像素。相鄰像素可包含透過由全卷積網路模型之一或多個層指定之零填補添加至輸入之邊界的像素。對於全卷積網路模型之固定大小輸入(例如，自一完整輸入資料提取之區塊)，相鄰像素亦可包含最初圍繞該完整輸入資料中之固定大小輸入之像素。The term "neighboring pixels" throughout this specification means pixels surrounding a boundary of an input to a fully convolutional network model. Neighboring pixels may include pixels added to the boundary of the input by zero padding specified by one or more layers of the fully convolutional network model. For a fixed-size input to a fully convolutional network model (eg, a block extracted from a full input), adjacent pixels may also include pixels that originally surrounded the fixed-size input in the full input.
圍繞全卷積網路模型之輸入或固定大小輸入且包含相鄰像素之區域貫穿本說明書被稱為「相鄰像素區域」。相鄰像素區域可包含一或多個像素之一寬度。在一些實施方案中，可基於全卷積網路模型之特性來判定相鄰像素區域之寬度。在運算期間，相鄰像素可具有零像素值或用零像素值替換，從而致使透過全卷積網路模型處理相鄰像素之輸出不準確。The region surrounding the input of a fully convolutional network model or the input of a fixed size and containing adjacent pixels is referred to as a "neighboring pixel region" throughout this specification. Adjacent pixel regions may include a width of one or more pixels. In some implementations, the width of adjacent pixel regions can be determined based on the characteristics of the fully convolutional network model. During operation, adjacent pixels may have or be replaced with zero pixel values, making the output of processing adjacent pixels through the fully convolutional network model inaccurate.
在一些實施方案中，相鄰像素最初在完整輸入資料中。當自完整輸入資料提取一固定大小輸入時，系統可能需要一或多個相鄰像素來處理該固定大小輸入。然而，系統可能將一或多個非零相鄰像素之值更改為零，從而致使一些像素位置處之運算不準確。In some embodiments, neighboring pixels are initially in the full input data. When extracting a fixed-size input from the full input data, the system may require one or more adjacent pixels to process the fixed-size input. However, the system may change the value of one or more non-zero neighboring pixels to zero, resulting in inaccurate calculations at some pixel locations.
例如，系統可包含具有大於一之一濾波器大小之一或多個卷積層。為處理固定大小輸入之邊界像素，系統可使用該等邊界像素外之一或多個相鄰像素來運算對應逐像素輸出。在運算期間，非零相鄰像素可用零值替換。藉由使用零值相鄰像素而非與相鄰像素相關聯之真實像素值用於處理固定大小輸入，固定大小輸出中之一或多個像素值可為不準確的。For example, a system may include one or more convolutional layers with a filter size greater than one. To process boundary pixels of a fixed-size input, the system may use one or more adjacent pixels outside the boundary pixels to compute the corresponding pixel-by-pixel output. During operation, non-zero adjacent pixels may be replaced with zero values. By using zero-valued neighboring pixels instead of the true pixel values associated with neighboring pixels for processing the fixed size input, one or more pixel values in the fixed size output may be inaccurate.
作為另一實例，系統可包含具有大於一之一濾波器大小之一或多個轉置卷積層。若轉置卷積層之一者之運算使用零值來替換非零相鄰像素，則輸出像素值可為不準確的。As another example, a system may include one or more transposed convolutional layers with a filter size greater than one. If the operation to transpose one of the convolutional layers replaces non-zero neighboring pixels with zero values, the output pixel values may be inaccurate.
換言之，零值相鄰像素(例如，用零值替換之最初非零像素)可致使輸出區塊中之一或多個像素值不準確。因此，一系統在一全卷積網路中執行操作以處理固定大小輸入以藉由在不判定及摒棄不準確資料的情況下組合固定大小輸出來產生一最終輸出係有問題的。當處理固定大小輸入時，系統需要基於全卷積網路中之網路層之特性來判定準確資料(例如，有效值)及不準確資料(例如，虛設像素值)兩者。In other words, a zero-valued neighboring pixel (eg, an originally non-zero pixel replaced with a zero value) may cause one or more pixel values in the output block to be inaccurate. Therefore, it is problematic for a system to perform operations in a fully convolutional network to process fixed-size inputs to produce a final output by combining fixed-size outputs without deciding and discarding inaccurate data. When processing fixed-size inputs, the system needs to determine both accurate data (eg, valid values) and inaccurate data (eg, dummy pixel values) based on the characteristics of the network layers in a fully convolutional network.
本說明書中所描述之技術可藉由分析一全卷積網路中之網路層之特性及判定層或整體對準資訊及合適的固定大小以編譯全卷積網路模型及區塊輸入資料來判定固定大小輸出中哪些逐像素值係不準確的。對準資訊及合適的固定大小可用於採用所描述技術之一系統以透過全卷積網路模型針對最終輸出中之各像素產生一準確值。各像素之準確值係在至少一個固定大小輸出中至少產生一次且系統可自至少一個固定大小輸出獲得像素之準確值。The techniques described in this specification can compile fully convolutional network models and block input data by analyzing the characteristics of the network layers in a fully convolutional network and determining layer or global alignment information and appropriate fixed sizes to determine which pixel-by-pixel values in the fixed-size output are inaccurate. The alignment information and appropriate fixed size can be used in a system employing the described techniques to produce an accurate value for each pixel in the final output through a fully convolutional network model. The exact value of each pixel is generated at least once in at least one fixed-size output and the system can obtain the exact value of the pixel from the at least one fixed-size output.
本說明書中所描述之技術可藉由減少且甚至避免計算不同固定大小輸出之間的無效或重疊像素值來進一步減少記憶體訊務。在其中判定一固定大小之一些情況下，技術可藉由最小化不同固定大小輸出區塊之準確像素之重疊來最佳化加速器與主機之間的記憶體訊務，使得可基於該最小化之重疊產生一有效最終輸出。在其中尚未判定固定大小之一些情況下，所描述技術可基於輸入資料及硬體加速器之特性來選擇複數個候選固定大小之一者作為固定大小，使得最小化或甚至消除用於產生不準確或重疊像素值之計算。The techniques described in this specification can further reduce memory traffic by reducing and even avoiding the calculation of invalid or overlapping pixel values between different fixed-size outputs. In some cases where a fixed size is determined, the technique can optimize the memory traffic between the accelerator and the host by minimizing the pixel-exact overlap of output blocks of different fixed sizes, so that based on this minimization Overlap produces a valid final output. In some cases where a fixed size has not been decided, the described technique can select one of a plurality of candidate fixed sizes as the fixed size based on the input data and the characteristics of the hardware accelerator, so that the use for generating inaccuracies or Calculation of overlapping pixel values.
在隨附圖式及下文描述中闡述本說明書之標的物之一或多項實施例之細節。將自描述、圖式及發明申請專利範圍明白標的物之其他特徵、態樣及優點。The details of one or more embodiments of the subject matter of this specification are set forth in the accompanying drawings and the description below. Other features, aspects, and advantages of the subject matter will be apparent from the description, drawings, and patent claims.
一全卷積網路(FCN)可包含至少一或多個卷積神經網路層，及視需要匯集層、轉置卷積層及逐元素層(例如，應用逐元素激活函數之層)。一FCN可部署於一硬體加速器上以產生一輸入(例如，具有複數個像素之一輸入影像)之逐像素預測。特定言之，一FCN經組態以產生具有與輸入影像之對應一或多個像素相關聯之像素之一輸出，並對輸入影像之各像素進行預測。在一些實施方案中，FCN亦可將一輸出像素與一輸入像素及一固定大小鄰域中之相鄰像素相關聯。由於FCN模型可處理輸入之像素，因此FCN原則上能夠處理任意大小之輸入。A fully convolutional network (FCN) may comprise at least one or more convolutional neural network layers, and optionally pooling layers, transposed convolutional layers, and element-wise layers (eg, layers applying element-wise activation functions). An FCN can be deployed on a hardware accelerator to generate pixel-by-pixel predictions of an input (eg, an input image having a plurality of pixels). In particular, an FCN is configured to produce an output having pixels associated with corresponding one or more pixels of an input image, and to make a prediction for each pixel of the input image. In some implementations, the FCN can also associate an output pixel with an input pixel and neighboring pixels in a fixed-size neighborhood. Since the FCN model can process pixels of the input, the FCN can in principle process an input of any size.
雖然一FCN相較於典型神經網路之優勢在於，其可針對以不同大小提供之輸入資料產生逐像素預測，但一些硬體限制致使難以或甚至不可能在一硬體加速器上動態地部署一FCN (即，處理具有變化大小輸入之輸入)。While the advantage of an FCN over typical neural networks is that it can generate pixel-by-pixel predictions for input data provided at different sizes, some hardware limitations make it difficult or even impossible to dynamically deploy a FCN on a hardware accelerator. FCN (i.e., handles inputs with varying size inputs).
動態地部署一FCN以能夠連續處理不同大小之輸入可引起運算成本方面之問題。首先，包含資料結構之網路參數(例如，用於運算之矩陣維度、或用於網路層之填補、步幅、濾波器大小及縮放因數)隨著輸入之大小而縮放且輸入大小之變化可能需要對當前網路參數進行重排，此可導致包含多個硬體加速器之一系統之停機時間(例如，額外耗用)之增加。此外，為容許一動態輸入大小，一主機需要發送指令以使用更一般的執行機制執行推論運算。例如，主機可分配一較大記憶體用於資料儲存(代價為較慢，且可能不使用該大記憶體之一部分)，對向量或張量大小執行更多檢查，或更頻繁地且動態地更改用於在並行運算期間執行計算之運算單元之數目。因此，在實踐中，一FCN通常在一或多個硬體加速器上靜態地部署(例如，用固定網路超參數編譯)且經組態以接收一固定大小之輸入，以避免由動態部署引起之問題。Dynamically deploying an FCN to be able to continuously process inputs of different sizes can cause problems in terms of computational cost. First, network parameters including data structures (e.g., matrix dimensions for operations, or padding, strides, filter sizes, and scaling factors for network layers) scale with the size of the input and changes in the input size A rearrangement of current network parameters may be required, which may result in increased downtime (eg, overhead) for a system including multiple hardware accelerators. Furthermore, to allow for a dynamic input size, a host needs to send commands to perform inference operations using more general execution mechanisms. For example, the host could allocate a larger memory for data storage (at the expense of being slower and possibly not using a portion of that large memory), perform more checks on vector or tensor sizes, or more frequently and dynamically Changes the number of arithmetic units used to perform calculations during parallel computing. Thus, in practice, an FCN is usually statically deployed (e.g., compiled with fixed network hyperparameters) on one or more hardware accelerators and configured to accept a fixed-size input to avoid question.
下文描述之技術可藉由容許已部署(或待部署)於一硬體加速器上之一靜態編譯之FCN有效地處理不同大小之輸入來解決上述問題。The techniques described below can address the above-mentioned problems by allowing a statically compiled FCN deployed (or to be deployed) on a hardware accelerator to efficiently process inputs of different sizes.
所描述技術可將一特定大小之輸入資料平鋪成各具有一固定大小之複數個較小輸入。一硬體加速器上之一靜態編譯之FCN可處理複數個固定大小輸入之各者並產生對應固定大小輸出。所描述技術可相應地將固定大小輸出拼接在一起以產生一最終輸出，如同輸入完全由針對輸入大小編譯之一FCN處理一般。The described technique can tile input data of a certain size into a plurality of smaller inputs each having a fixed size. A statically compiled FCN on a hardware accelerator can process each of a plurality of fixed-size inputs and generate corresponding fixed-size outputs. The described technique can accordingly stitch together fixed-size outputs to produce a final output, as if the input were fully processed by an FCN compiled for the input size.
一般而言，所描述技術可提供一方法以判定用於將一特定大小之一輸入平鋪成多個固定大小輸入，及拼接自該多個固定大小輸入產生之多個固定大小輸出以產生等效於藉由由針對特定大小編譯之一FCN完全處理輸入而產生之一輸出之一最終輸出的特定「平鋪及拼接」參數。更明確言之，根據FCN模型之特性，所描述技術可藉由透過FCN模型處理一固定大小輸入區塊而產生具有不同區域之一固定大小輸出。不同區域可包含一虛設區域及一有效區域。所描述技術可藉由分析FCN模型之特性(例如，用於FCN模型中之所有層之填補、步幅、濾波器大小、縮放因數及層類型)來判定固定大小輸出中之其中逐像素值準確之有效區域，即，非零值相鄰像素係用於產生輸出像素值，及固定大小輸出中之其中逐像素值至少不「完全」準確之虛設區域，即，逐像素值係由FCN藉由利用至少一個零值相鄰像素來產生。所描述技術可組合(例如，「拼接」)來自所有固定大小輸出之準確逐像素值以產生最終輸出，並確保對應於最終輸出中之一像素之各準確逐像素值係至少自一個固定大小輸出中產生及獲得。此係與習知並行化技術相反，在習知並行化技術中，輸入資料易於被劃分以用於獨立地產生輸出資料且不需要考量由相鄰像素引起之不準確性。In general, the described techniques may provide a method to decide what to use for tiling an input of a particular size into multiple fixed-size inputs, and concatenate multiple fixed-size outputs produced from the multiple fixed-size inputs to produce, etc. Specific "tiling and tiling" parameters that apply to a final output that produces an output by fully processing the input by an FCN compiled for a specific size. More specifically, according to the characteristics of the FCN model, the described technique can generate a fixed-size output with different regions by processing a fixed-size input block through the FCN model. Different regions may include a dummy region and a valid region. The described technique can determine which pixel-by-pixel values in a fixed-size output are accurate by analyzing the characteristics of the FCN model, such as padding, strides, filter sizes, scaling factors, and layer types used for all layers in the FCN model. The active region, i.e., the non-zero-valued neighboring pixels are used to generate the output pixel value, and the dummy region in the fixed-size output where the pixel-by-pixel value is at least not "perfectly" accurate, i.e., the pixel-wise value is determined by the FCN by Generated with at least one zero-valued neighbor pixel. The described technique combines (e.g., "stitches") the exact pixel-wise values from all fixed-size outputs to produce the final output, and ensures that each exact pixel-wise value corresponding to a pixel in the final output is derived from at least one fixed-size output produced and obtained. This is in contrast to conventional parallelization techniques in which input data is easily partitioned for independently generating output data without taking into account inaccuracies caused by neighboring pixels.
所描述技術亦可在FCN被編譯及部署於一硬體加速器上之前藉由各種方式判定一固定大小。首先，所描述技術可基於一FCN模型及其上部署FCN之硬體加速器之特性提出複數個候選大小。該複數個候選大小係有效的且適於藉由所描述技術執行之平鋪及拼接程序。例如，若FCN包含一或多個轉置層，則可基於輸出區塊之對準資訊來判定複數個候選大小。貫穿本說明書之術語「對準資訊」表示資料，該資料表示對固定大小輸出之配置之約束或要求。對準資訊係由系統獲得，使得可將一固定大小輸出正確地投射至一固定大小輸入，或反之亦然。The described techniques can also determine a fixed size by various means before the FCN is compiled and deployed on a hardware accelerator. First, the described technique can propose a plurality of candidate sizes based on an FCN model and the characteristics of the hardware accelerator on which the FCN is deployed. The plurality of candidate sizes are valid and suitable for tiling and tiling procedures performed by the described techniques. For example, if the FCN includes one or more transposition layers, a plurality of candidate sizes may be determined based on the alignment information of the output blocks. The term "alignment information" throughout this specification means data representing constraints or requirements on the configuration of a fixed-size output. Alignment information is obtained by the system so that a fixed size output can be correctly projected to a fixed size input, or vice versa.
系統亦可基於對準資訊判定一固定大小輸出與一對應固定大小輸入之間的座標移位，以獲得一合適平鋪圖案。平鋪圖案可包含一或多個固定大小(例如，待自動選擇或由一使用者選擇之一或多個候選大小)、一特定固定大小之固定大小輸入之重疊大小及視需要，固定大小輸入及輸出之座標，特別是固定大小輸出之虛設及有效區域之座標。The system can also determine a coordinate shift between a fixed-size output and a corresponding fixed-size input based on the alignment information to obtain a suitable tiling pattern. The tiling pattern may comprise one or more fixed sizes (e.g., one or more candidate sizes to be automatically selected or selected by a user), overlapping sizes of fixed size inputs of a particular fixed size, and optionally, fixed size input And the coordinates of the output, especially the coordinates of the dummy and valid areas of the fixed-size output.
所判定之平鋪圖案必須滿足至少兩個準則：(i)對準資訊應為正確的，即，平鋪圖案應具有正確配置之固定大小輸出，使得各固定大小輸出可被正確地投射回至一固定大小輸入，或反之亦然；及(ii)完整輸出資料之各像素值應自一個固定大小輸出之至少一有效區域產生及提取。視需要，系統可判定最小化固定大小輸入之重疊區域以改良運算效能及最佳化運算資源使用之一平鋪圖案。基於對準資訊判定一平鋪圖案之細節將在下文描述。The determined tile pattern must satisfy at least two criteria: (i) the alignment information should be correct, i.e., the tile pattern should have fixed-size outputs configured correctly such that each fixed-size output can be correctly projected back into a fixed size input, or vice versa; and (ii) each pixel value of the complete output data should be generated and extracted from at least one valid area of a fixed size output. Optionally, the system may determine a tiling pattern that minimizes overlapping regions of fixed-size inputs to improve computing performance and optimize computing resource usage. The details of determining a tiling pattern based on the alignment information will be described below.
在一些實施方案中，所描述技術可視需要基於效能度量(例如，總執行時間或額外耗用)來選擇包含於一合適平鋪圖案中之候選大小之一者作為固定大小。所描述技術亦可產生用於在一硬體加速器上部署FCN模型之一候選大小範圍，並提供該候選大小範圍以供使用者之選擇。一使用者可根據(例如) FCN模型、硬體加速器之特性或根據任務之特定運算要求從候選大小範圍中挑選出一個大小作為固定大小。In some implementations, the described techniques may optionally select one of the candidate sizes included in an appropriate tiling pattern as the fixed size based on a performance metric (eg, total execution time or overhead). The described technique can also generate a candidate size range for deploying an FCN model on a hardware accelerator, and provide the candidate size range for user selection. A user can select a size from a range of candidate sizes as the fixed size based on, for example, the FCN model, the characteristics of the hardware accelerator, or based on the specific computational requirements of the task.
如上文描述之一平鋪圖案可包含用於將完整輸入資料平鋪成一或多個固定大小輸入之一固定大小，及用於產生固定大小輸入之重疊區域之大小。一般而言，系統可平鋪固定大小輸入，使得固定大小輸入經常彼此重疊以確保獲得與最終輸出中之所有像素相關聯之準確或正確的逐像素值，即，各準確值係自至少一個固定大小輸出產生及獲得。如上文描述之一平鋪圖案可進一步包含表示一固定大小輸出之一有效區域及一虛設區域之資料。由於用於產生輸出像素值之一或多個零值相鄰像素，固定大小輸出通常可包含一顯著大小之一虛設區域。系統可採用一或多種演算法以基於FCN模型之特性來判定對準資訊，並應用額外演算法來判定一固定大小輸出之座標與一對應固定大小輸入之座標之間的一關係(例如，一映射)，判定固定大小輸出之有效區域，及基於上述映射及有效區域來判定固定大小輸出之一座標移位。此等演算法之細節將在下文描述。A tiling pattern as described above may include a fixed size for tiling the complete input data into one or more fixed-size inputs, and the size of the overlapping region for generating the fixed-size inputs. In general, the system can tile fixed-size inputs such that the fixed-size inputs often overlap each other to ensure accurate or correct pixel-by-pixel values associated with all pixels in the final output, i.e., each accurate value is derived from at least one fixed The size output is generated and obtained. A tiling pattern as described above may further include data representing a valid area and a dummy area for a fixed size output. Fixed-size outputs can often contain a dummy region of a significant size due to one or more zero-valued neighboring pixels used to generate the output pixel value. The system may employ one or more algorithms to determine alignment information based on characteristics of the FCN model, and apply additional algorithms to determine a relationship between the coordinates of a fixed-size output and the coordinates of a corresponding fixed-size input (e.g., a mapping), determine the valid area of the fixed-size output, and determine a coordinate shift of the fixed-size output based on the above-mentioned mapping and the valid area. The details of these algorithms are described below.
在判定平鋪圖案之後，系統可藉由組合各固定大小輸出之有效區域來將固定大小輸出拼接在一起。應注意，平鋪圖案係基於FCN模型之對準資訊產生。由於系統可針對固定大小輸入產生一合適的平鋪圖案，因此拼接程序非常有效，此係因為系統具有固定大小輸出之有效區域中之所有像素之座標資訊。在一些實施方案中，系統可針對定位於完整輸出資料中之各像素至少一次獲取固定大小輸出之有效區域中之像素值，以產生完整輸出資料。拼接之細節係結合特定演算法及下文圖3A至圖3D進行描述。After determining the tiling pattern, the system can stitch the fixed-size outputs together by combining the active areas of each fixed-size output. It should be noted that the tiling pattern is generated based on the alignment information of the FCN model. Since the system can generate a suitable tiling pattern for a fixed-size input, the mosaic procedure is very efficient because the system has coordinate information for all pixels in the active area of the fixed-size output. In some implementations, the system may obtain the pixel value in the active area of the fixed-size output at least once for each pixel positioned in the complete output data to generate the complete output data. The details of stitching are described in conjunction with specific algorithms and Figures 3A-3D below.
此外，所描述技術可即線上又離線執行「平鋪及拼接」分析。為以類似於先前使用所描述技術進行部署之方式之一方式將一經編譯FCN部署於一硬體加速器上，一主機處理器可藉由重新使用用於「平鋪」完整輸入資料及「拼接」輸出區塊之先前保存參數來離線執行分析以產生具有未知或變化大小之完整輸出資料。先前保存參數可包含至少一平鋪圖案(諸如FCN之對準資訊)、用於平鋪之一固定大小、固定大小輸入或固定大小輸出或兩者之重疊區域，及固定大小輸出之虛設及有效區域。系統可重新使用此等參數以處理一新的完整輸入資料並產生一完整輸出資料，如同該新的完整輸入係直接由針對新的完整輸入資料之大小編譯之一FCN模型處理一般。主機處理器可產生用於在其中待部署一新FCN之情況下處理輸入資料之一組新的「平鋪及拼接」參數。Furthermore, the described technique can perform "tile and stitch" analysis both online and offline. To deploy a compiled FCN on a hardware accelerator in a manner similar to that previously deployed using the described techniques, a host processor can be used to "til" the entire input data and "stitch" by reusing Previously saved parameters of output blocks to perform analysis offline to produce complete output data with unknown or varying sizes. Previously saved parameters may include at least one tiling pattern (such as alignment information for FCN), a fixed size for tiling, fixed size input or fixed size output or overlapping regions of both, and dummy and valid regions for fixed size output . The system can reuse these parameters to process a new complete input and generate a complete output as if the new complete input were processed directly by an FCN model compiled for the size of the new complete input. The host processor can generate a new set of "tiling and tiling" parameters for processing input data in the case where a new FCN is to be deployed.
圖1展示用於針對不同大小之輸入執行一全卷積網路之推論運算之一實例性推論系統100。推論系統100係實施為一或多個位置中之一或多個電腦上之電腦程式之一系統的一實例，其中可實施下文描述之系統、組件及技術。FIG. 1 shows an example inference system 100 for performing inference operations of a fully convolutional network on inputs of different sizes. Inference system 100 is an example of a system implemented as a computer program on one or more computers in one or more locations, in which the systems, components and techniques described below may be implemented.
如圖1中所展示，系統100包含互相通信之一主機130及一硬體加速器110。一般而言，系統100可使用部署於硬體加速器110上之一經訓練之FCN 115接收輸入資料150並產生輸出資料170。一般而言，輸出資料170可具有小於、大於或等於輸入資料150之大小之一大小。As shown in FIG. 1 , the system 100 includes a host 130 and a hardware accelerator 110 in communication with each other. In general, system 100 may receive
更明確言之，系統100可使用經部署之FCN 115用於(僅舉幾例)諸如物件偵測及分類(例如，人臉偵測)、影像分割、影像產生、影像超解析、影像完成或影像著色之任務。例如，當任務係影像分割時，輸入資料150可為一影像輸入，系統100可產生具有逐像素預測，即，對輸入影像之各像素或對由FCN 115產生之一輸出影像之各像素之一各自預測的輸出資料170。輸出資料170亦可包含用於各像素之將一各自評分指派至多個類別之各者之一各自評分分佈。鑑於此，系統100可自一輸入影像偵測一物件之一存在、一形狀及一位置。當任務係影像超解析時，作為另一實例，系統100可使用經部署之FCN 115以藉由預測待在各輸入像素周圍添加之像素來增加一輸入影像之影像解析度。鑑於此，輸出影像170可具有高於輸入影像150之一解析度，且一或多個輸出像素可與輸入影像中之各像素相關聯。More specifically, the system 100 may use the deployed FCN 115 for applications such as object detection and classification (e.g., face detection), image segmentation, image generation, image super-resolution, image completion, or Image coloring task. For example, when the task is image segmentation, the
系統100可在包含於主機130中之一編譯引擎160上編譯一FCN以用於處理一固定大小之輸入並將該經編譯之FCN部署於硬體加速器110上。為編譯FCN，主機130可接收表示編譯引擎160上之一經訓練之FCN模型之資料155，編譯該經訓練之FCN模型，及產生將經訓練之FCN模型部署於硬體加速器110上之指令(例如，二進位資料)。在一些實施方案中，編譯引擎160可重新編譯經訓練之FCN模型以用於處理具有變化輸入大小之不同輸入資料。重新編譯一經訓練之FCN模型及將經重新編譯之FCN模型部署於硬體加速器110上之細節係在下文描述。The system 100 can compile a FCN on a compilation engine 160 included in the host 130 for processing a fixed-size input and deploy the compiled FCN on the hardware accelerator 110 . To compile the FCN, host 130 may receive
一般而言，經編譯之FCN 115可處理具有相同大小之任何合適輸入(例如，固定大小輸入138)。因此，硬體加速器110可使用經編譯之FCN模型115針對所提供之固定大小輸入138執行推論運算。In general, compiled FCN 115 can handle any suitable input of the same size (eg, fixed-size input 138). Thus, the hardware accelerator 110 can perform inference operations on the provided fixed-
編譯引擎160可應用習知編譯技術用於編譯硬體加速器110上之一FCN。一般而言，編譯引擎160可將用任何合適高階語言撰寫並用表示FCN之特性之資料編碼之程式碼解碼成一硬體加速器上之機器可讀二進位程式碼。表示FCN之特性之資料可包含定義FCN之結構之超參數(例如，輸入大小、層數、各層中之節點之數目、層類型及位置，及用於一或多個層之填補、步幅、濾波器大小及縮放因數)，及自訓練程序獲得之層權重。在編譯期間，系統100需要基於FCN之特性來分配各自運算資源。例如，系統100需要分配各自資料結構以適應用於執行推論運算之各自計算。作為另一實例，系統需要分配各自記憶體以用於在執行經部署之FCN之推論操作期間儲存各自資料結構及相關聯之運算結果。The compiling engine 160 can apply conventional compiling techniques for compiling an FCN on the hardware accelerator 110 . In general, the compilation engine 160 can decode code written in any suitable high-level language and encoded with data representing characteristics of the FCN into machine-readable binary code on a hardware accelerator. Data representing characteristics of an FCN may include hyperparameters that define the structure of the FCN (e.g., input size, number of layers, number of nodes in each layer, layer type and position, and padding, stride, filter size and scaling factor), and layer weights obtained from the training procedure. During compilation, the system 100 needs to allocate respective computing resources based on the characteristics of the FCN. For example, system 100 needs to allocate respective data structures to accommodate respective computations for performing inference operations. As another example, the system needs to allocate respective memory for storing respective data structures and associated computation results during execution of the inference operations of the deployed FCN.
習知地，系統100需要根據輸入大小分配各自資料結構及記憶體。例如，針對層權重矩陣、激活輸入及輸出分配之資料結構係至少基於輸入大小。經分配以用於儲存資料結構及相關聯運算結果之各自記憶體亦係基於輸入大小。因此，經部署之FCN一旦被部署，就經組態以接收一固定大小之輸入。又，系統(例如，系統100)通常相應地靜態編譯FCN以用於接收一固定大小輸入，使得系統可在運算期間有效地且一次性地分配運算資源。Conventionally, the system 100 needs to allocate respective data structures and memory according to the input size. For example, data structures for layer weight matrices, activation inputs, and output assignments are based at least on input size. The respective memory allocated for storing data structures and associated operation results is also based on the input size. Thus, once deployed, the deployed FCN is configured to receive a fixed size input. Also, the system (eg, system 100 ) typically statically compiles the FCN accordingly for receiving a fixed-size input, so that the system can allocate computing resources efficiently and at once during computation.
在一些實施方案中，主機130可執行平鋪圖案分析以基於FCN模型及相關聯硬體加速器之特性來判定用於編譯FCN 115之平鋪參數(例如，一合適固定大小)。應注意，不同於主機130之一或多個主機(例如，離線分析/編譯主機)可離線或提前於主機130執行平鋪圖案分析。接著，一或多個主機可在主機130 (例如，一或多個通信耦合之電腦)上編譯及部署FCN 115，或將FCN 115作為一「應用程式」部署於一或多個邊緣裝置(例如，蜂巢式電話或平板電腦)上以用於處理隨機或未知大小之輸入。判定固定大小之細節係在下文描述。In some implementations, the host 130 may perform tiling pattern analysis to determine tiling parameters (eg, an appropriate fixed size) for compiling the FCN 115 based on the FCN model and characteristics of the associated hardware accelerator. It should be noted that one or more hosts other than host 130 (eg, an offline analysis/compilation host) may perform tile pattern analysis offline or in advance of host 130 . One or more hosts may then compile and deploy FCN 115 on host 130 (e.g., one or more communicatively coupled computers), or deploy FCN 115 as an "application" on one or more edge devices (e.g., , cellular phone or tablet) for random or unknown-sized input. The details of determining the fixed size are described below.
系統100可包含用於執行一FCN模型之推論運算之任何合適類型之硬體加速器110。例如，硬體加速器110可為一CPU、GPU或TPU。硬體加速器110可包含組件，諸如用於儲存FCN模型之參數之記憶體。此外，硬體加速器110可包含用於並行運算之一或多個運算單元。System 100 may include any suitable type of hardware accelerator 110 for performing inference operations of an FCN model. For example, the hardware accelerator 110 can be a CPU, GPU or TPU. The hardware accelerator 110 may include components such as memory for storing parameters of the FCN model. In addition, the hardware accelerator 110 may include one or more computing units for parallel computing.
輸入資料150可具有不同於經編譯之FCN 115經組態以處理之輸入之固定大小之一或多個大小。例如，輸入資料150可包含複數個影像圖框，各影像圖框具有不同於固定大小之一各自大小。The
所產生之輸出資料170係由系統100針對輸入資料150執行一經訓練及靜態部署之FCN模型115之推論運算而產生之輸出。所產生之輸出資料170可各具有與一對應輸入資料之大小相關聯之一各自大小。The generated
作為一簡單實例，若輸入資料(例如，一輸入影像)具有500x500像素之一大小，則所產生之輸出170可具有50x50像素、500x500像素或1000x1000像素之一大小，其中基於FCN模型之特性(例如，用於FCN模型之各層之濾波器大小、步幅大小、填補大小及縮放因數)，輸出資料之各像素與輸入影像之一8x8、10x10或20x20像素鄰域內之像素相關聯。一般而言，由一經訓練之FCN自一輸入產生之一輸出之大小係依據FCN模型之特性而變化。As a simple example, if the input data (e.g., an input image) has a size of 500x500 pixels, the generated
例如且便於說明，一原生FCN模型可包含各具有2x2像素之一濾波器大小、1像素之一步幅大小及1x1零填補之兩個網路層，使得該兩個層之各層可藉由處理3x3像素之一輸入而產生4x4像素之一輸出。當一3x3輸入行進通過網路之兩個層時，產生一5x5輸出，且類似地，一5x5輸入透過原生FCN模型產生一7x7輸出。For example and for illustration, a native FCN model may contain two network layers each with a filter size of 2x2 pixels, a stride size of 1 pixel, and 1x1 zero padding, such that each of the two layers can be processed by 3x3 One of the pixels is input and one of the 4x4 pixels is output. When a 3x3 input is passed through the two layers of the network, a 5x5 output is generated, and similarly, a 5x5 input is passed through the native FCN model to generate a 7x7 output.
假定原生FCN模型經編譯以接收自輸入資料150平鋪之5x5像素之一區塊。系統可藉由分析FCN模型之特性來產生7x7像素之一固定大小輸出。系統接著可判定固定大小輸出之一有效區域及一虛設區域且藉由針對所有固定大小輸出將該有效區域中之逐像素值與一最終輸出170中之對應像素相關聯來產生該最終輸出。參考上述實例，由原生FCN模型產生之固定大小輸出之有效區域可具有擁有使用5x5像素輸入區塊中之值運算之逐像素值之3x3像素之一大小(即，有效區域中之逐像素值並非基於任何經填補零產生)。Assume that a native FCN model is compiled to receive a 5x5 pixel block of 150 tiles from the input data. The system can generate a fixed size output of 7x7 pixels by analyzing the characteristics of the FCN model. The system can then determine an active area and a dummy area for fixed-size outputs and generate a
作為另一實例，一FCN模型可包含兩個卷積層，各層具有3x3像素之一濾波器大小、1之一步幅大小及無零填補。對於50x50像素之一固定大小輸入，由FCN模型處理固定大小輸入而產生之固定大小輸出可具有46x46像素。系統100可判定固定大小輸出中不存在虛設區域，且固定大小輸出之有效區域係46x46像素。As another example, an FCN model may include two convolutional layers, each with a filter size of 3x3 pixels, a stride size of 1, and no zero padding. For a fixed size input of 50x50 pixels, the fixed size output produced by the FCN model processing the fixed size input may have 46x46 pixels. The system 100 can determine that there is no dummy area in the fixed size output, and the valid area of the fixed size output is 46x46 pixels.
作為另一實例，一FCN模型可包含兩個卷積層，各層具有3x3像素之一濾波器大小、1之一步幅大小及一單個像素之零填補。由FCN模型處理50x50像素之一固定大小輸入之固定大小輸出可具有50x50像素之一大小。系統100可判定在輸出資料(例如，一輸出影像)之所有側上具有2像素之一寬度之一虛設區域，且固定大小輸出之有效區域係46x46像素。判定一固定大小輸出之虛設及有效區域之程序係在下文結合 FirstValidPixelOffset()演算法更詳細描述。 As another example, an FCN model may include two convolutional layers, each with a filter size of 3x3 pixels, a stride size of 1, and zero padding of a single pixel. The fixed size output processed by the FCN model for a fixed size input of 50x50 pixels may have a size of 50x50 pixels. The system 100 may determine that there is a dummy area with a width of 2 pixels on all sides of the output data (eg, an output image), and that the active area of the fixed size output is 46x46 pixels. The procedure for determining the dummy and valid regions of a fixed-size output is described in more detail below in conjunction with the FirstValidPixelOffset() algorithm.
一般而言，若一FCN模型包含具有大於1之一步幅大小之一或多個卷積層，則輸入及輸出大小可為多對一映射，而不再是一對一映射。例如，一FCN模型可包含具有3x3像素之一濾波器大小、1之一步幅大小及一單個像素之零填補之一第一卷積層，且包含具有5x5之一濾波器大小、2之一步幅大小及1之零填補之一第二卷積層。FCN模型可藉由處理不同大小之輸入(例如，一50x50像素輸入及一49x49像素輸入)而產生相同大小(例如，24x24像素)之一輸出。此係因為第二卷積層中之步幅大小2在透過各網路層處理輸入時可能觸發一捨入程序。In general, if an FCN model includes one or more convolutional layers with a stride size greater than 1, the input and output sizes can be many-to-one mappings instead of one-to-one mappings. For example, an FCN model may include a first convolutional layer with a filter size of 3x3 pixels, a stride size of 1, and zero padding of a single pixel, and include a filter size of 5x5, a stride size of 2 and a second convolutional layer of zero padding. The FCN model can generate an output of the same size (eg, 24x24 pixels) by processing inputs of different sizes (eg, a 50x50 pixel input and a 49x49 pixel input). This is because a stride size of 2 in the second convolutional layer may trigger a rounding procedure as the input is processed through the network layers.
另外，一FCN模型可包含一或多個轉置卷積層。例如，FCN模型可包含具有5像素之濾波器大小、無零填補及2像素之一步幅之一轉置卷積層。該轉置卷積層可附加至具有2像素之一步幅大小之第二層。一般而言，一轉置卷積層經組態以基於該轉置卷積層之步幅大小將來自由一先前層提供之一輸入之輸出大小增加(例如，放大)一倍。結合以上實例，轉置卷積層可藉由處理來自第二卷積層之24x24像素輸出產生51x51像素之一輸出。即，FCN模型可處理50x50像素或49x49像素之一輸入以產生一51x51像素輸出。Additionally, an FCN model may contain one or more transposed convolutional layers. For example, an FCN model may include a transposed convolutional layer with a filter size of 5 pixels, no zero padding, and a stride of 2 pixels. The transposed convolutional layer can be appended to a second layer with a stride size of 2 pixels. In general, a transposed convolutional layer is configured to double (eg, amplify) the output size of an input provided by a previous layer based on the stride size of the transposed convolutional layer. Combining the above example, a transposed convolutional layer can generate an output of 51x51 pixels by processing the 24x24 pixel output from the second convolutional layer. That is, the FCN model can process an input of either 50x50 pixels or 49x49 pixels to produce a 51x51 pixel output.
轉置卷積層可產生或加寬一虛設區域，即使填補大小係零。虛設區域之大小可基於轉置卷積層之特性，例如，一濾波器大小與一步幅大小之間的一關係。例如，若一轉置卷積層具有小於一濾波器大小之一步幅大小，則輸出可包含虛設區域，此係因為當自一完整輸入提取一固定大小輸入時，計算涉及相鄰像素區域。如上文所描述，藉由自一完整輸入資料提取一固定大小輸入，FCN可將一或多個零值相鄰像素而非真實像素值引入一或多個運算中，此致使固定大小輸入中之邊界像素之運算不準確，且產生具有包含不準確像素值之一虛設區域，及由該虛設區域圍繞之真實像素值之一有效區域之一輸出。Transposed convolutional layers can create or widen a dummy region even if the padding size is zero. The size of the dummy region may be based on properties of the transposed convolutional layer, eg, a relationship between a filter size and a stride size. For example, if a transposed convolutional layer has a stride size smaller than a filter size, the output may contain dummy regions because the computation involves adjacent pixel regions when a fixed-size input is extracted from a full input. As described above, by extracting a fixed-size input from a complete input data, FCN can introduce one or more zero-valued neighboring pixels instead of real pixel values into one or more operations, which results in The calculation of boundary pixels is inaccurate and produces an output having a dummy region containing inaccurate pixel values, and a valid region of real pixel values surrounded by the dummy region.
返回參考以上實例，當自一完整輸入資料(例如，輸入資料150)提取一固定大小輸入時，產生虛設區域。否則，若FCN經編譯以用於直接處理該完整輸入資料，則不產生虛設區域。例如，包含一或多個轉置卷積層之FCN模型可產生具有一虛設區域之一輸出。此係因為當自一完整輸入資料提取一固定大小輸入時，引起促成一輸出之一或多個非零相鄰像素之像素值用零值替換。Referring back to the above example, when a fixed-size input is extracted from a full input data (eg, input data 150), dummy regions are generated. Otherwise, if the FCN is compiled for directly processing the full input data, no dummy region is generated. For example, an FCN model comprising one or more transposed convolutional layers may produce an output with a dummy region. This is because when a fixed-size input is extracted from a complete input data, pixel values resulting in one or more non-zero neighboring pixels of an output are replaced with zero values.
為判定一固定大小輸出之有效區域及虛設區域，系統100可藉由分析一FCN模型之特性及一輸出像素之座標來追蹤輸入影像中之用於該輸出像素之一或多個像素，或反之亦然。例如，系統100可定位一輸入區塊中之50x50像素以用於產生51x51像素之一固定大小輸出。如上文所描述，由具有合適運算能力之主機130或硬體加速器110自輸入資料150產生之區塊可在一或多個像素上彼此重疊，因此系統可採用特定演算法(例如，如下文更詳細描述之
ProjectBackwards()演算法)來反向追蹤用於透過經部署之FCN模型產生固定大小輸出中之輸出像素之對應輸入像素。
To determine valid and dummy regions for a fixed-size output, the system 100 can track one or more pixels in the input image for the output pixel by analyzing the properties of an FCN model and the coordinates of the output pixel, or vice versa The same is true. For example, system 100 may locate 50x50 pixels in an input block for generating a fixed size output of 51x51 pixels. As described above, the blocks generated from the
返回參考圖1，主機130可藉由傳送資料或指令或兩者而與硬體加速器110通信。主機130與硬體加速器110可透過有線或無線連接通信且在一些情況下，可彼此遠端地定位。例如，主機130可為在不同於加速器110所處之位置之一實體位置處之一伺服器。Referring back to FIG. 1 , the host 130 can communicate with the hardware accelerator 110 by transmitting data or instructions or both. Host 130 and hardware accelerator 110 may communicate over a wired or wireless connection and, in some cases, may be located remotely from each other. For example, host 130 may be a server at a physical location different from where accelerator 110 is located.
主機130可接收大於固定大小之大小之輸入資料150，且產生各具有小於輸入資料150之一大小之複數個固定大小輸入138。主機130可將固定大小輸入138提供至硬體加速器110並接收來自硬體加速器110之複數個對應固定大小輸出133。經接收之固定大小輸出133係由硬體加速器110針對所提供之複數個固定大小輸入130執行經部署之FCN 115之推論運算而產生。The host 130 can receive
在一些實施方案中，如上文所描述，包含硬體組件(諸如CPU)之硬體加速器可執行平鋪程序以將輸入資料150平鋪成多個固定大小輸入138。In some implementations, a hardware accelerator including a hardware component, such as a CPU, may execute a tiling procedure to tile
在其中輸入資料150具有小於固定大小之一大小之情況下，系統100可在輸入資料150周圍填補零以達到固定大小，並將其提供至硬體加速器110以用於執行推論運算。In cases where the
為產生輸出資料170，主機130可進一步包含經組態以組合經接收之固定大小輸出133之一拼接引擎140。拼接引擎140可藉由基於固定大小及經部署之FCN模型之特性判定固定大小輸出133之各者之對準資訊來執行拼接程序，並產生一最終輸出170，該最終輸出170係如同藉由直接處理輸入資料150而無需平鋪及使用相同FCN模型但其經部署以用於處理具有輸入資料150之大小之輸入一般而獲得之一等效輸出。To generate
在一些實施方案中，包含能夠執行拼接程序之硬體組件之硬體加速器可基於固定大小輸出133而在硬體加速器上產生最終輸出170，並將最終輸出170提供至主機130或一使用者介面之一顯示器上。In some embodiments, a hardware accelerator including hardware components capable of performing the stitching process may generate
在一些實施方案中，貫穿本說明書之平鋪及拼接程序不必離開一主機執行。例如，包含合適硬體組件(諸如CPU)之任何合適加速器可在加速器上執行平鋪及拼接程序。此外，平鋪及拼接程序可在不同於主機之實體位置處執行。例如，可藉由一第一位置處之一第一組加速器執行平鋪，可藉由一第二位置處之一第二組加速器執行拼接程序，且主機可定位於一第三位置處且經組態以接收來自該第二組加速器之一最終輸出。加速器及主機在一或多個位置處通信地連接(實體或無線地連接)。In some implementations, the tiling and tiling procedures throughout this specification need not be performed away from a host. For example, any suitable accelerator including suitable hardware components, such as a CPU, can perform tiling and tiling procedures on the accelerator. Furthermore, the tiling and tiling process can be performed at a physical location different from the host. For example, tiling can be performed by a first set of accelerators at a first location, the tiling process can be performed by a second set of accelerators at a second location, and the host can be positioned at a third location and via Configure to receive final output from one of the second set of accelerators. The accelerator and host are communicatively connected (either physically or wirelessly) at one or more locations.
圖2A繪示使用一習知系統之一實例性推論程序200。FIG. 2A illustrates an
如圖2A中所展示，一習知推論系統200可接收輸入資料150 (如圖1中所展示)，並藉由執行處理輸入資料150之一經部署之FCN 215之推論運算來產生輸出資料225。輸出資料225可實質上類似於如圖1中所展示之輸出資料170。輸入資料150可為如上文所描述之輸入影像。As shown in FIG. 2A , a
輸入資料150之各者可具有一不同大小，使得習知系統需要重新編譯硬體加速器之FCN 215以用於處理不同輸入大小。例如，若第一輸入資料具有50x50像素之一大小，則系統可將FCN 215部署於硬體加速器上以經組態以處理大小50x50像素之輸入。然而，若第二輸入資料具有不同於第一輸入資料之一大小(例如，100x100像素)，則系統必須重新編譯FCN 215以經組態以處理大小100x100大小之輸入。Each of the
對於具有不同大小之輸入資料，習知系統需要首先判定一特定輸入之大小，且接著判定是否需要重新編譯FCN 215以用於處理該特定輸入。此外，系統200需要執行額外運算檢查以監測記憶體及資料結構是否被正確地分配。鑑於此，用於執行推論運算之習知技術可引起大量額外耗用，從而降低在給定變化大小輸入之情況下產生推論輸出之運算效率。For input data having different sizes, conventional systems need to first determine the size of a particular input, and then determine whether the FCN 215 needs to be recompiled for processing the particular input. In addition,
圖2B繪示使用圖1之實例性推論系統100之一實例性推論程序250。FIG. 2B illustrates an
如圖2B中所展示且結合圖1，採用所描述技術之推論系統100可避免針對不同大小之輸入重新編譯一經部署之FCN。此減少額外耗用並改良運算效率。更明確言之，系統100首先將一FCN模型235靜態地部署於一硬體加速器上。系統100可基於該FCN模型之特性判定對準資訊，及判定包含平鋪之一固定大小、固定大小輸出之虛設區域及有效區域之一平鋪圖案，使得可自至少一個固定大小輸出獲得各有效像素。FCN模型235經編譯用於處理固定大小之輸入。系統100可基於平鋪圖案平鋪輸入資料150以產生複數個固定大小輸入230，並提供固定大小輸入230以使用經部署之FCN 235執行推論運算。系統100可自經部署之FCN 235獲得固定大小輸出240，且將固定大小輸出240拼接在一起以用於產生一最終輸出資料170。輸出資料170等效於輸出資料225，該輸出資料225係藉由使用經編譯用於處理完整輸入資料150之一FCN 215直接處理完整輸入資料150而獲得。平鋪及拼接之細節係在下文描述。As shown in FIG. 2B and in conjunction with FIG. 1 , an inference system 100 employing the described techniques can avoid recompiling a deployed FCN for inputs of different sizes. This reduces overhead and improves computational efficiency. More specifically, the system 100 first statically deploys an FCN model 235 on a hardware accelerator. System 100 may determine alignment information based on characteristics of the FCN model, and determine a tiling pattern comprising a fixed size of tiles, dummy regions of fixed-size outputs, and valid regions, such that each valid pixel can be obtained from at least one fixed-size output . The FCN model 235 is compiled to handle fixed-size inputs. The system 100 can tile the
在一些實施方案中，系統100可判定適於FCN模型處理一隨機大小輸入之一組候選大小。系統100可基於FCN模型之特性(例如，層性質，諸如一濾波器大小、一步幅側等)自所有區塊大小判定該組候選大小。應注意，根據特性不能使用一些區塊大小。例如，一特定輸入大小無法基於FCN模型之濾波器大小及步幅大小產生一輸出大小。例如，系統100可自所有可能大小移除不適於FCN模型產生候選大小之大小。In some implementations, the system 100 may determine a set of candidate sizes suitable for the FCN model to process a random sized input. The system 100 can determine the set of candidate sizes from all block sizes based on characteristics of the FCN model (eg, layer properties, such as a filter size, stride side, etc.). It should be noted that some block sizes cannot be used by nature. For example, a certain input size cannot produce an output size based on the filter size and stride size of the FCN model. For example, the system 100 may remove sizes from all possible sizes that are not suitable for FCN model generation candidate sizes.
在一些實施方案中，系統100可自複數個候選大小選擇一固定大小以用於部署一FCN模型。例如，系統100可基於效能選擇固定大小。In some implementations, the system 100 can select a fixed size from a plurality of candidate sizes for deploying an FCN model. For example, system 100 may choose a fixed size based on performance.
在一些實施方案中，對於候選大小之各者，系統100可將FCN模型之一各自複本部署於一各自硬體加速器上以用於處理具有候選大小之一者之輸入。系統100可量測效能之一位準，例如，使用處理不同固定大小輸入之FCN網路之不同複本執行推論運算之一總執行時間，或作為另一實例，在用於執行一分別部署之FCN之推論運算之包含多個硬體加速器之系統100中之額外耗用。基於效能量測，系統100可選擇候選大小之一者作為固定大小以用於將FCN模型部署於一特定硬體加速器上。例如，系統100可選擇導致最少總執行時間之候選大小。作為另一實例，系統100可選擇引起最少額外耗用之候選大小。視情況，系統100可選擇具有執行推論運算之令人滿意的執行時間及額外耗用之候選大小。In some implementations, for each of the candidate sizes, the system 100 may deploy a respective replica of the FCN model on a respective hardware accelerator for processing the input of the one of the candidate sizes. The system 100 may measure a level of performance, for example, the total execution time of an inference operation performed using different replicas of the FCN network handling different fixed-size inputs, or as another example, when used to perform a separately deployed FCN The overhead of the inference computation in the system 100 including multiple hardware accelerators. Based on performance metrics, the system 100 can select one of the candidate sizes as a fixed size for deploying the FCN model on a specific hardware accelerator. For example, system 100 may select the candidate size that results in the least total execution time. As another example, the system 100 may select the candidate size that causes the least overhead. Optionally, system 100 may select a candidate size that has a satisfactory execution time and overhead for performing inference operations.
候選大小之選擇可基於經訓練之FCN模型之特性。例如，假定用於平鋪(或用於經部署之FCN模型)之一候選大小太小，則自候選大小之固定大小輸入產生之固定大小輸出亦可為小且甚至不包含任何有效區域(即，固定大小輸出中之所有逐像素值係在虛設區域中)。The selection of the candidate size can be based on the characteristics of the trained FCN model. For example, given that the candidate size for tiling (or for the deployed FCN model) is too small, the fixed-size output generated from the fixed-size input of the candidate size may also be small and not even contain any valid regions (i.e. , all pixel-wise values in the fixed-size output are in the dummy region).
視情況，系統100可向一使用者提供一離散候選大小範圍以用於在該範圍內選擇一個候選大小作為固定大小。基於FCN之特性(例如，一或多個轉置層之數目及位置，及包含於FCN中之各層之特性)，該離散候選大小範圍可為非連續的。例如，候選大小範圍可為來自10x10像素至30x30像素之偶數個像素。一使用者可在所提供範圍內選擇16x16像素作為固定大小。Optionally, the system 100 can provide a user with a range of discrete candidate sizes for selecting a candidate size within the range as the fixed size. The discrete candidate size ranges may be non-contiguous based on the characteristics of the FCN (eg, the number and location of the one or more transposed layers, and the characteristics of the layers included in the FCN). For example, the candidate size range may be an even number of pixels from 10x10 pixels to 30x30 pixels. A user can choose 16x16 pixels as a fixed size within the range provided.
此外，固定大小不必為一純量。代替性地，固定大小可為表示二維空間中之一矩形或三維空間中之一方塊之一向量。更明確言之，固定大小可包含一各自維度中之一各自值。例如，若輸入影像係二維的，則系統100可判定具有第一維度(例如，水平維度)之一第一大小及不同於第一維度之一第二維度(例如，垂直維度)之一第二大小之一固定大小向量。系統100可自具有300x100像素之一大小之一輸入影像產生30x10像素之複數個固定大小輸入。Also, the fixed size need not be a scalar. Alternatively, the fixed size may be a vector representing a rectangle in two-dimensional space or a square in three-dimensional space. More specifically, fixed sizes may contain a respective value in a respective dimension. For example, if the input imagery is two-dimensional, the system 100 may determine a first size with a first dimension (eg, horizontal dimension) and a second dimension (eg, vertical dimension) different from the first dimension. One of two fixed-size vectors of size. The system 100 can generate a plurality of fixed size inputs of 30x10 pixels from an input image having a size of 300x100 pixels.
參考圖1及圖2B，在接收到輸入資料150之後，系統100可自經接收之輸入資料判定複數個固定大小輸入。對於具有大於固定大小之一大小之一輸入資料，系統100可分析該輸入資料並將該輸入資料平鋪成具有或不具有任何重疊之複數個固定大小輸入。對於具有小於固定大小之一大小之一輸入資料，系統100可在該輸入資料周圍填補零以達到固定大小，並將經填補輸入(現亦具有固定大小)提供至經部署之FCN模型以用於執行推論運算。Referring to FIGS. 1 and 2B , after receiving
為將經接收之輸入資料150平鋪成複數個固定大小輸入138，主機130可包含一平鋪引擎135，該平鋪引擎135經組態以接收輸入資料150，並基於一平鋪圖案產生複數個固定大小輸入138。替代性地，合適硬體加速器110可將輸入150平鋪成固定大小之多個區塊。更明確言之，主機130可將包含表示一經編譯之FCN模型之二進位資料及儲存輸入資料150之記憶體位址之指令發送至一硬體加速器110。硬體加速器110可包含合適運算組件(諸如CPU)且經組態以藉由存取(例如，直接記憶體存取)儲存一或多個區塊之逐像素值之對應記憶體位址來獲得該一或多個區塊。例如，硬體加速器可藉由存取儲存5x5像素之一區塊之逐像素值之對應記憶體位址來獲得該區塊，而無需存取儲存該區塊外之像素值之記憶體位址。以此方式，系統100可減少記憶體訊務並改良運算效率，如上文所描述。To tile the received
系統100可判定用於將輸入資料150平鋪成複數個固定大小輸入138之一平鋪圖案。例如，平鋪引擎135可將輸入資料150平鋪成具有一特定重疊大小之一特定大小之固定大小輸入，例如，經平鋪之固定大小輸入不具有任何重疊，或各具有一特定大小之一共用重疊區域，或各以一各自大小彼此重疊。自一輸入資料產生之固定大小輸入之總數相應地取決於平鋪圖案。The system 100 may determine a tiling pattern for tiling the
應注意，若FCN模型包含具有大於1之步幅大小之一或多個轉置卷積層，則進一步基於對準資訊來判定一平鋪圖案。It should be noted that if the FCN model contains one or more transposed convolutional layers with a stride size greater than 1, then a tiling pattern is further determined based on the alignment information.
平鋪圖案之重疊大小可為小於固定大小之任何合適大小。例如，各固定大小輸入可具有依該固定大小輸入之一個像素之一寬度及一邊緣之一長度之一共用重疊大小。作為另一實例，重疊大小可依兩個像素、三個像素及五個像素之一寬度。用於平鋪之固定大小及重疊大小係至少基於對準資訊來判定。The overlapping size of the tiled pattern may be any suitable size smaller than the fixed size. For example, each fixed-size input may have a common overlap size of a width of one pixel and a length of an edge in terms of the fixed-size input. As another example, the overlap size may be one of two pixels, three pixels, and five pixels wide. Fixed size and overlapping size for tiling are determined based at least on alignment information.
系統100可基於一FCN模型之特性或使用者指令自動地判定一平鋪圖案。例如，系統100可將100x100像素之一輸入影像平鋪成各60x60像素之四個固定大小輸入。固定大小輸入之各者可具有彼此20x60像素、60x20像素或20x20像素之一重疊區域。The system 100 can automatically determine a tiling pattern based on properties of an FCN model or user commands. For example, the system 100 can tile an input image of 100x100 pixels into four fixed-size inputs of 60x60 pixels each. Each of the fixed-size inputs may have an overlapping area of one of 20x60 pixels, 60x20 pixels, or 20x20 pixels with each other.
視情況，系統100亦可產生一平鋪圖案使得固定大小輸入具有彼此之各自重疊區域。例如，70x30像素之輸入影像可被平鋪成與經部署之FCN模型相容之具有30x30像素之固定大小輸入。在一種情況下，四個固定大小輸入在20x30像素之一區域中彼此重疊。應注意，最後固定大小輸入可具有在輸入影像外之10x30像素之一區域，且此區域可被擴展或用零填補。在一些實施方案中，系統可使最後固定大小輸入與其他輸入之重疊區域移位以減少及甚至消除經填補零以改良運算效率。Optionally, system 100 may also generate a tiling pattern such that fixed-size inputs have respective overlapping regions of each other. For example, an input image of 70x30 pixels can be tiled into a fixed-size input of 30x30 pixels compatible with the deployed FCN model. In one case, four fixed-size inputs overlap each other in an area of one of 20x30 pixels. It should be noted that the final fixed size input may have an area of 10x30 pixels outside the input image, and this area may be expanded or zero-filled. In some implementations, the system can shift the overlap region of the last fixed-size input with other inputs to reduce and even eliminate zero-padded to improve operational efficiency.
在一些實施方案中，系統100可基於在各種訓練資料上進行訓練之合適機器學習模型來判定一平鋪圖案。訓練資料可為針對相同輸入複本但各基於不同平鋪圖案平鋪之各自組固定大小輸入。機器學習模型可輸出一或多個平鋪圖案以用於系統100或供使用者選擇以用於系統100。In some implementations, the system 100 can determine a tiling pattern based on a suitable machine learning model trained on various training data. The training data may be respective sets of fixed-size inputs for the same input replica but each tiled based on a different tiling pattern. The machine learning model can output one or more tile patterns for use in the system 100 or for user selection for use in the system 100 .
系統100可藉由使用一拼接引擎140拼接固定大小輸出來產生一輸出170。由於系統100已獲得包含有效區域中之像素之座標之平鋪圖案，因此系統100可有效地拼接來自有效區域之像素以產生一完整輸出資料。系統可採用一演算法用於拼接程序，此將在下文更詳細描述。The system 100 can generate an
系統100可對於各固定大小輸出獲得特定固定大小輸出之座標，及一對應固定大小輸入之座標以用於產生特定固定大小輸出。一特定固定大小輸入之座標表示該固定大小輸入相對於原始輸入150之位置，且類似地，一特定固定大小輸出之座標表示該固定大小輸出相對於對應最終輸出170之位置。系統100可判定一各自座標系(例如，笛卡爾座標系，或任何適當離散座標系)，及各輸入及對應輸出資料之座標系之一原點。系統100可在平鋪程序期間判定固定大小輸入之座標，並根據經部署之FCN模型115之特性判定對應固定大小輸出之座標。同樣地，系統100可首先判定固定大小輸出之座標，且接著基於FCN模型115之特性判定對應固定大小輸入之座標。系統100可應用一或多種演算法以產生對準資訊，產生一固定大小輸入及一固定大小輸出之座標之間的一關係，及基於該關係拼接固定大小輸出。對準資訊之細節係在下文描述。The system 100 can obtain, for each fixed-size output, the coordinates of the specific fixed-size output, and the coordinates of a corresponding fixed-size input for generating the specific fixed-size output. The coordinates of a particular fixed-size input represent the position of the fixed-size input relative to the
一旦滿足FCN模型之對準約束，系統100便可在將固定大小輸出及對應固定大小輸入之座標相關聯之後進一步判定各固定大小輸出之一中心有效區域及一周邊虛設區域。該中心有效區域包含使用來自對應固定大小輸入之有效像素產生之像素。虛設區域包含使用一或多個零值相鄰像素(例如，自本應對於固定大小輸入外之完整輸入影像之像素非零之零值)產生之像素。Once the alignment constraints of the FCN model are met, the system 100 can further determine a central valid area and a peripheral dummy area for each fixed-size output after associating the fixed-size output with the coordinates of the corresponding fixed-size input. The central active area includes pixels generated using active pixels from a corresponding fixed-size input. A dummy region includes pixels that are generated using one or more zero-valued neighboring pixels (eg, zero-values from pixels that would otherwise be non-zero for a full input image other than a fixed-size input).
系統100可判定固定大小輸出之間的一或多個重疊區域。視情況，系統亦可判定重疊區域之至少一部分是否屬於固定大小輸出之一有效區域。在一些實施方案中，系統100可判定一或多個重疊固定大小之輸出之一座標偏移，使得不同固定大小輸出之有效區域定位成彼此鄰接或毗連而不重疊。System 100 may determine one or more regions of overlap between fixed-size outputs. Optionally, the system may also determine whether at least a portion of the overlapping region belongs to a valid region of the fixed-size output. In some implementations, the system 100 may determine a coordinate offset for one or more overlapping fixed-size outputs such that active regions of different fixed-size outputs are positioned adjacent or adjacent to each other without overlapping.
圖3A繪示具有相鄰像素區域310之一實例性固定大小輸入138及具有虛設區域320之一實例性固定大小輸出133。FIG. 3A illustrates an example fixed-
如上文所描述，系統100可將完整輸入資料150平鋪成對於經部署之FCN模型相容之一固定大小之複數個固定大小輸入。系統150可判定輸入資料150之平鋪圖案，且藉由將輸入資料150從上至下、從左至右平鋪來產生固定大小輸入。平鋪圖案可包含重疊區域，及固有地由各固定大小輸入之各自座標界定之位置。例如，如圖3中所展示，一個固定大小輸入138定位於完整輸入資料150之一特定位置中。平鋪圖案之細節係在下文結合圖3B及圖3C描述。As described above, the system 100 can tile the
固定大小輸入138之位置可使用一或多個邊角像素相對於完整輸入資料150之一原點之座標來表示。例如，系統可將完整輸入資料150之左上邊角像素判定為原點(0, 0)。各固定大小輸入之座標係相對於該原點來判定。例如，系統100可使用固定大小輸入138之左上邊角像素及右下邊角像素之座標來表示輸入138之位置及大小。The location of the fixed-
固定大小輸入可由任何合適座標系表示。例如，各固定大小輸入138之座標可在一笛卡爾座標系、一圓柱座標系或任何其他合適座標系中表示。Fixed-size inputs may be represented by any suitable coordinate system. For example, the coordinates of each fixed-
平鋪圖案可以任何合適方式定義各固定大小輸入138之一位置。例如，固定大小輸入可以列及行定位。作為另一實例，固定大小輸入可經散佈且未對準。換言之，固定大小輸入138不必在列及行中彼此成一線，例如，一z字形圖案。The tiling pattern may define the position of one of the fixed-
系統100可用任何合適符號來標註一固定大小輸入之一位置。例如，系統100可使用(i, j)符號來表示在沿著一第一維度之第 i位置及沿著一第二維度之第 j位置中之一固定大小輸入。為簡潔起見且在以下說明書中，系統100在一平鋪柵格中標註固定大小輸入。即，各固定大小輸入係用沿著一列及一行之一序號表示。各固定大小輸入可以一實質上矩形形狀進行考量。然而，應瞭解，平鋪圖案及標註可基於平鋪要求而改變。 System 100 may label a position of a fixed-size input with any suitable notation. For example, system 100 may use (i, j) notation to represent a fixed-size input in an i-th position along a first dimension and a j-th position along a second dimension. For brevity and in the following description, system 100 labels fixed size inputs in a tiled grid. That is, each fixed-size input is represented by a serial number along a column and a row. Each fixed-size input may be considered a substantially rectangular shape. However, it should be appreciated that the tiling pattern and labeling may vary based on tiling requirements.
系統100可將左上邊角像素之座標表示為
The system 100 can express the coordinates of the upper left corner pixel as
作為另一實例，假定輸入影像具有100x100像素，且系統100將輸入影像平鋪成具有各自重疊大小之一3x3柵格(即，9個固定大小輸入)。該3x3柵格之第一列之固定大小輸入可包含：定位於第一柵格處之一第一固定大小輸入，其可具有 As another example, assume an input image has 100x100 pixels, and the system 100 tiles the input image into a 3x3 grid with one of the respective overlapping sizes (ie, 9 fixed-size inputs). The fixed-size input of the first column of the 3x3 grid may include: a first fixed-size input positioned at the first grid, which may have
為避免冗餘地計數或計算多個固定大小輸入138之各者之邊緣像素，在一些實施方案中，在平鋪期間，系統100可針對固定大小輸入138之各者判定，一固定大小輸入之頂部及左邊緣上之像素被視為包含於該固定大小輸入中，而位於該固定大小輸入之底部及右邊緣上之像素不被視為包含於該固定大小輸入中。To avoid redundantly counting or computing edge pixels for each of the multiple fixed-
在將輸入資料150平鋪成複數個固定大小輸入之前，系統100可判定輸入資料是否小於針對系統100設定之固定大小。回應於判定輸入資料150小於固定大小，系統100可圍繞輸入資料150之周邊填補零以達到固定大小。Before tiling the
應注意，如上文描述之術語「相鄰像素區域310」表示包含藉由使用零值來替換相鄰像素之原始非零值而產生之相鄰像素之一區域。例如，相鄰像素區域310可包含如圖3A中所展示之一區域，該區域包含完整輸入資料150中之固定大小輸入138之一或多個相鄰像素。相鄰像素區域310之寬度315可表示包含於相鄰像素區域310中之相鄰像素之一數目。系統100可基於經部署之FCN 115模型之特性來判定相鄰像素區域310之寬度315。It should be noted that the term "neighboring pixel region 310" as described above means a region comprising neighboring pixels generated by replacing the original non-zero values of neighboring pixels with zero values. For example, adjacent pixel region 310 may include a region as shown in FIG. 3A that includes one or more adjacent pixels of fixed-
系統100可獲得各固定大小輸入133相對於最終輸出資料170之座標。例如，系統100可選擇最終輸出資料170之左上邊角像素作為原點，且將固定大小輸出之左上邊角像素之座標表示為
The system 100 can obtain the coordinates of each fixed-
如上文所描述，系統可基於FCN模型之特性進一步判定各固定大小輸出133之一有效區域330及一虛設區域320。一般而言，有效區域330可定位於固定大小輸出133之中心處且虛設區域320可以一寬度335圍繞有效區域330之周邊。寬度335判定虛設區域320之各維度中之像素之一特定數目。有效區域包含使用對應固定大小輸入138中之有效逐像素值運算的在有效區域中之像素之逐像素值，且虛設區域320包含在平鋪程序期間或透過在FCN模型中之一或多個層中特性化之操作使用至少一或多個相鄰像素運算的在虛設區域中之像素之逐像素值。有效區域330中之像素之逐像素值貢獻最終輸出170之至少一部分，而虛設像素在拼接程序期間將被消除或摒棄。As described above, the system can further determine a valid region 330 and a dummy region 320 of each fixed-
系統100可藉由根據FCN模型之特性自固定大小輸出中之一像素通過FCN模型反向追蹤至對應固定大小輸入中之一或多個像素來判定有效區域330及虛設區域320。更明確言之，系統100可執行如下文描述之 FirstValidPixelOffset()演算法以判定一虛設區域之一寬度，且有效區域係輸出中之區域之其餘部分。 The system 100 can determine the valid region 330 and the dummy region 320 by backtracking from a pixel in the fixed-size output to one or more pixels in the corresponding fixed-size input through the FCN model according to the characteristics of the FCN model. More specifically, the system 100 may execute the FirstValidPixelOffset() algorithm as described below to determine the width of a dummy region, and the valid region is the remainder of the region in the output.
更明確言之， FirstValidPixelOffset()演算法經組態以逐層傳播無效資訊以判定FCN輸出之一最終虛設區域。在FCN之第一層上，該層歸因於將相鄰像素區域中之像素用於第一層而在其輸出上產生一虛設區域。然而，自第二層開始，層輸出之虛設區域歸因於使用相鄰像素及自先前層產生並傳播之虛設像素值而增長。 More specifically, the FirstValidPixelOffset() algorithm is configured to propagate invalidation information layer by layer to determine one of the final dummy regions output by the FCN. On the first layer of the FCN, this layer produces a dummy region on its output due to the use of pixels in adjacent pixel regions for the first layer. However, starting from the second layer, the dummy area of the layer output grows due to the use of neighboring pixels and dummy pixel values generated and propagated from previous layers.
藉由執行
FirstValidPixelOffset()演算法，系統100可基於FCN模型之特性(例如，用於FCN模型中之所有層之各自濾波器大小、零填補大小、步幅大小及縮放因數)判定寬度335及固有地寬度335內之像素之數目。應注意，虛設區域之寬度335可包含所有虛設像素。然而，在一些實施方案中，寬度335足夠大以包含所有虛設像素及一或多個有效像素。
By executing the FirstValidPixelOffset() algorithm, the system 100 can determine the
若FCN模型包含一或多個轉置層，則系統100可基於該一或多個轉置層之數目及位置來判定虛設區域320之寬度335。結合圖3D，其繪示使用一FCN模型中之一轉置卷積層340、345產生一輸出之一實例性程序，該FCN模型可為圖1之經編譯之全卷積網路115之一等效物。為簡潔起見，經正確組態之一系統(例如，圖1之推論系統100)可執行圖3D之程序。If the FCN model includes one or more transposed layers, the system 100 can determine the
如圖3D中所展示，一FCN模型可包含經組態以接收來自該FCN模型中之一先前層之2x2像素之一輸出341之一轉置卷積層340。系統可執行與轉置卷積層340相關聯之操作以產生4x4像素之一輸出342。轉置卷積層340包含3x3像素之一濾波器大小與一步幅大小1。轉置卷積層340不包含任何零填補。輸入像素A係與輸出像素A1、A2、A3、C1、C2、C3、D1、D2及D3相關聯，且輸入像素B係與輸出像素C1、C2、C3、D1、D2、D3、B1、B2及B3相關聯。與輸入像素A及B相關聯之輸出像素之重疊區域包含像素C1、C2、C3、D1、D2及D3。As shown in Figure 3D, an FCN model may include a transposed
應注意，像素C1、C2及C3亦係與輸出341中之像素A左側之一輸入像素(未展示)相關聯。類似地，像素A1、A2及A3係與像素A左側之兩個輸入像素相關聯，且像素D1、D2及D3係與輸入像素A及B以及像素B右側之另一輸入像素相關聯。It should be noted that pixels C1 , C2 and C3 are also associated with an input pixel (not shown) to the left of pixel A in output 341 . Similarly, pixels Al, A2, and A3 are associated with two input pixels to the left of pixel A, and pixels Dl, D2, and D3 are associated with input pixels A and B and another input pixel to the right of pixel B.
假定完整輸入影像可透過先前層產生一中間輸出，該中間輸出包含像素A左側之第一像素、像素A及像素B，則A1、A2、A3、C1、C2及C3之像素值係不準確的，此係因為固定大小輸入不產生第一像素之像素值，因此系統100使用零值相鄰像素來表示第一像素以產生像素A1、A2、A3、C1、C2及C3之一部分輸出。然而，D1、D2、D3、B1、B2及B3之像素值係準確的，此係因為完整輸入及固定大小輸入兩者使用零像素值用於像素B右側之像素。Assuming that the complete input image can be passed through the previous layer to produce an intermediate output that includes the first pixel to the left of pixel A, pixel A, and pixel B, the pixel values of A1, A2, A3, C1, C2, and C3 are inaccurate , this is because a fixed size input does not produce a pixel value for the first pixel, so the system 100 uses zero-valued neighboring pixels to represent the first pixel to produce a partial output of pixels A1, A2, A3, C1, C2, and C3. However, the pixel values of Dl, D2, D3, Bl, B2, and B3 are accurate because both the full input and the fixed-size input use zero pixel values for pixels to the right of pixel B.
類似地，轉置卷積層345包含在兩個方向上之2個像素之一步幅大小及3x3像素之一濾波器大小，且經組態以接收來自一先前層之一輸出344，並產生5x5像素之一輸出345。輸入像素A係與像素A1、A2、A3、C1、C2、C3、D1、D2及D3相關聯，且輸入像素B係與像素D1、D2、D3、B1、B2、B3、E1、E2及E3相關聯。重疊區域包含像素D1、D2及D3，其等係準確的，此係因為此等像素並未使用相鄰像素計算。Similarly, a transposed
雖然圖3D僅表示針對一唯一轉置卷積層判定準確及不準確的像素值，但系統100可藉由如上文所描述分析FCN模型之所有層之輸入與輸出之間的關係來判定固定大小輸出之虛設區域及有效區域。While FIG. 3D only shows determining accurate and inaccurate pixel values for a single transposed convolutional layer, system 100 can determine fixed-size outputs by analyzing the relationship between the inputs and outputs of all layers of the FCN model as described above. The virtual area and effective area.
另外，系統100可基於FCN模型之各層之輸入與輸出之間的關係來判定對準資訊。Additionally, the system 100 can determine alignment information based on the relationship between the inputs and outputs of the layers of the FCN model.
例如且如圖3D中所展示，不同於轉置卷積層340，轉置卷積層345具有2個像素之一步幅。因此，包含C1、C2、C3、D1、D2、D3、B1、B2及B3之一輸出不具有輸出344中之一對應像素。系統100可將轉置卷積層345之對準資訊判定為2個像素的整數倍。2個像素的整數倍可為(例如) 2個、4個、8個及10個像素，其包含於用於保證轉置卷積層處之一有效映射之對準資訊中。For example and as shown in FIG. 3D , unlike transposed
若FCN模型包含兩個或更多個轉置層，則系統100可基於所有轉置層之特性(例如，轉置層之一數目、位置及步幅)判定整個FCN模型之整體對準資訊(例如，所有層之經累積對準值，或整體對準值)。在一些實施方案中，系統100可將整體對準資訊判定為所有轉置層之各自步幅大小之乘積。If the FCN model includes two or more transposed layers, the system 100 may determine global alignment information for the entire FCN model based on characteristics of all transposed layers (e.g., one of the number, positions, and strides of the transposed layers) ( For example, the cumulative alignment value of all layers, or the overall alignment value). In some implementations, the system 100 may determine global alignment information as the product of the respective stride sizes of all transposed layers.
系統100可基於最終輸出之正確性、運算期間之記憶體訊務及運算效率而自多個候選對準值判定對準資訊。特定言之，關於最終輸出之正確性，系統100可選擇保證最終輸出之各像素可自固定大小輸出之一者之一有效區域獲得之整體對準值。The system 100 can determine alignment information from multiple candidate alignment values based on correctness of final output, memory traffic during computation, and computation efficiency. In particular, with regard to the correctness of the final output, the system 100 may choose an overall alignment value that guarantees that each pixel of the final output can be obtained from an active area of one of the fixed-size outputs.
對於包含其他類型之層(諸如匯集層)之FCN模型，系統100可將其他類型之層視為用於分析平鋪及拼接程序之一形式之卷積層。例如，一最大匯集2x2層可被視為用於分析平鋪及拼接程序之具有2個像素之一步幅、2x2像素之一濾波器大小及無零填補之一卷積層。For FCN models that include other types of layers, such as pooling layers, the system 100 can treat the other types of layers as convolutional layers for one form of analytical tiling and concatenation procedures. For example, a max pool 2x2 layer can be viewed as a convolutional layer with a stride of 2 pixels, a filter size of 2x2 pixels, and no zero padding for analytical tiling and tiling procedures.
應注意，為便於說明，在輸出341及344之大小係2x2像素時，輸出342之大小係4x4像素，且輸出346之大小係5x5像素，輸入及輸出通常可具有任何合適大小。類似地，轉置卷積層340及341之濾波器大小、步幅及零填補可包含任何合適大小。It should be noted that, for ease of illustration, while
一般而言，若FCN模型包含一或多個轉置層，則一固定大小輸出中之一虛設區域之判定可變得明顯複雜。然而，執行本說明書中所描述之技術之系統可判定虛設區域自一先前層至一後繼層之傳播，無論一層是否係一卷積層或一轉置卷積層，及在給定一固定大小輸入的情況下基於FCN模型之特性理論上判定固定大小輸出之虛設區域，無論FCN模型包含多少個網路層。In general, the determination of a dummy region in a fixed-size output can become significantly complicated if the FCN model contains one or more transposed layers. However, a system implementing the techniques described in this specification can determine the propagation of dummy regions from a previous layer to a subsequent layer, regardless of whether a layer is a convolutional layer or a transposed convolutional layer, and given a fixed-size input In this case, based on the characteristics of the FCN model, theoretically determine the dummy area of the fixed-size output, no matter how many network layers the FCN model contains.
一FCN模型之一或多個層可具有沿著不同維度(例如，二維層之一高度及寬度維度)之不同性質。例如，一網路層之濾波器大小、步幅大小或填補大小沿著高度及寬度維度可為不同的(例如，3x2像素之一濾波器大小、2x1像素之一步幅大小及0x1像素之一零填補大小)。本說明書中之所描述技術可沿著各維度獨立地計算對準資訊、虛設區域及平鋪圖案，此可能產生沿著不同維度之非均勻固定大小輸出。例如，系統100可產生虛設區域320之一非均勻寬度，即，寬度335對於虛設區域320可為非均勻的。例如，虛設區域320之左及右部分之寬度335可大於頂部及底部部分。One or more layers of an FCN model may have different properties along different dimensions (eg, a height and width dimension of a two-dimensional layer). For example, the filter size, stride size, or padding size of a network layer may be different along the height and width dimensions (e.g., a filter size of 3x2 pixels, a stride size of 2x1 pixels, and a zero of 0x1 pixels fill size). The techniques described in this specification can compute alignment information, dummy regions, and tiling patterns independently along each dimension, which can result in non-uniform fixed-size outputs along different dimensions. For example, system 100 may generate a non-uniform width of dummy region 320 , ie,
通常，一FCN模型可在多個維度上接收輸入張量並產生輸出張量。例如，除了如上文所描述之高度H及寬度W維度之外，一輸入張量亦可具有多個通道C及多個批次B。In general, an FCN model can receive input tensors and produce output tensors in multiple dimensions. For example, an input tensor may also have multiple channels C and multiple batches B in addition to the height H and width W dimensions as described above.
FCN模型可經調適以處理一輸入之多個維度之各者，只要該維度係全卷積的。例如，一FCN模型可處理具有 FCN models can be adapted to process each of multiple dimensions of an input, as long as that dimension is fully convolutional. For example, an FCN model can handle
系統100亦可判定固定大小輸出133之有效區域330之座標。類似地，系統可相對於固定大小輸出133之原點將有效區域之左上邊角像素表示為
The system 100 can also determine the coordinates of the valid area 330 of the fixed
對於不具有轉置卷積層之一經部署之FCN模型，系統100可透過下文描述之第一演算法拼接固定大小輸出。作為另一實例，對於具有轉置卷積層之一經部署FCN模型，系統100可基於使用下文描述之第二演算法產生之對準資訊來拼接固定大小輸出。For a deployed FCN model without transposed convolutional layers, the system 100 can concatenate fixed-size outputs through a first algorithm described below. As another example, for a deployed FCN model with transposed convolutional layers, system 100 may concatenate a fixed-size output based on alignment information generated using a second algorithm described below.
第一演算法可保證固定大小輸出之有效區域不重疊，且第二演算法將潛在地引起固定大小輸出之有效區域重疊，此需要額外步驟來正確地組合固定大小輸出。該等額外步驟可包含固定大小輸出之各有效區域，或固定大小輸出之各者或兩者之座標移位，且座標移位之細節係在下文描述。The first algorithm can ensure that the valid areas of the fixed-size outputs do not overlap, and the second algorithm will potentially cause the valid areas of the fixed-size outputs to overlap, requiring additional steps to correctly assemble the fixed-size outputs. These additional steps may include coordinate shifting of each active area of the fixed-size output, or of each or both of the fixed-size outputs, and the details of the coordinate shifting are described below.
當使用第一演算法時，系統100可將虛設區域之寬度335表示為
When using the first algorithm, the system 100 can represent the
系統100可使用動態程式化以根據固定大小輸出之各自座標從左至右及從頂部至底部掃描來執行以下第一演算法以用於產生最終輸出170。第一演算法內容如下：
初始化：
The system 100 may perform the following first algorithm for generating the
根據上文描述之第一演算法，系統100可產生具有彼此靠近而不重疊之有效區域之有效固定大小輸出。更明確言之，系統100可摒棄虛設區域中之像素並組合固定大小輸出中之有效區域以產生最終輸出。此外，由於固定大小輸出之間的有效區域不重疊，因此使用第一演算法之系統幾乎可僅一次運算有效區域中之每個像素，此最佳化不具有轉置卷積層之FCN模型之運算效率。此實施方案之一項實例係結合圖3B更詳細描述。According to the first algorithm described above, the system 100 can generate an effective fixed-size output with active areas that are close to each other without overlapping. More specifically, system 100 may discard pixels in dummy regions and combine valid regions in fixed-size output to produce the final output. In addition, since the active area between fixed-size outputs does not overlap, the system using the first algorithm can operate almost only once for each pixel in the active area, which optimizes the operation of the FCN model without transposed convolutional layers. efficiency. An example of this implementation is described in more detail in connection with Figure 3B.
對於包含轉置卷積層之FCN模型，系統100需要執行解決對準資訊之第二演算法。使用第二演算法產生之有效區域可潛在地重疊且可引起有效區域中之一或多個像素之冗餘運算。For FCN models that include transposed convolutional layers, the system 100 needs to implement a second algorithm that addresses the alignment information. The active areas generated using the second algorithm can potentially overlap and can result in redundant computation of one or more pixels in the active area.
系統100可根據由FCN模型中之轉置卷積層闡述之運算要求獲得固定大小輸出之對準資訊。例如，要求可為，自固定大小輸出中之一或多個像素追蹤之固定大小輸入中之一或多個像素的像素索引應為整數。The system 100 can obtain the alignment information of a fixed size output according to the operation requirements stated by the transposed convolution layer in the FCN model. For example, a requirement may be that the pixel index of one or more pixels in the fixed-size input tracked from one or more pixels in the fixed-size output should be an integer.
第二演算法內容如下： 初始化： The content of the second algorithm is as follows: Initialization:
第二演算法係第一演算法之一經修改版本。特定言之，系統100可獲得不考量對準要求之一「未對準」固定大小輸出之座標。固定大小輸出具有一虛設區域及有效區域兩者，其中左及頂部虛設區域被省略，表示為 The second algorithm is a modified version of one of the first algorithms. In particular, system 100 may obtain coordinates for an "unaligned" fixed-size output regardless of alignment requirements. The fixed-size output has both a dummy region and a valid region, where the left and top dummy regions are omitted, denoted as
藉由執行第二演算法，系統100可確保可自固定大小輸出之至少一者獲得與最終輸出相關聯之各像素值，且固定大小輸出之對準值可保證各對應固定大小輸入具有相對於輸入影像之積分像素座標。系統100接著可藉由使用第二演算法減去虛設區域來獲得有效區域之座標。By executing the second algorithm, the system 100 can ensure that each pixel value associated with the final output can be obtained from at least one of the fixed-size outputs, and that the alignment values of the fixed-size outputs can ensure that each corresponding fixed-size input has a relative The integral pixel coordinates of the input image. The system 100 can then obtain the coordinates of the valid area by subtracting the dummy area using the second algorithm.
使用第一及第二演算法之平鋪及拼接程序之細節係分別結合圖3B及圖3C描述。Details of the tiling and mosaic procedures using the first and second algorithms are described in conjunction with Figures 3B and 3C, respectively.
系統100亦可使用經部署之FCN模型之特性基於一對應固定大小輸出之座標來獲得一固定大小輸入之座標。更明確言之，系統100可基於一層輸出之座標，及該層之填補、步幅、濾波器大小及縮放因數來獲得一層輸入之座標。一種實例性演算法被稱為「 ProjectBackwards()」，其內容如下： The system 100 can also use the properties of the deployed FCN model to obtain the coordinates of a fixed-size input based on the coordinates of a corresponding fixed-size output. More specifically, the system 100 can obtain the coordinates of a layer's input based on the coordinates of a layer's output, and the layer's padding, stride, filter size, and scaling factor. An example algorithm is called " ProjectBackwards ()", which reads as follows:
ProjectBackwards()演算法呼叫 Validate()函數來查看一固定大小輸入之座標是否可自一層之一輸出正確地投射至該層之一輸入。此 Validate()函數可判定(例如)由系統100選擇之輸出位置(例如，像素座標)是否不適於一或多個轉置卷積層之對準約束或對準資訊(即，經投射之座標包含非整數值)，且因此系統100試圖投射回至固定大小輸入位置之輸出位置係無效的且無法被使用。 The ProjectBackwards() algorithm calls the Validate() function to see if the coordinates of a fixed-size input can be correctly projected from an output of a layer to an input of that layer. This Validate() function can determine, for example, whether the output positions (e.g., pixel coordinates) selected by the system 100 are not suitable for the alignment constraints or alignment information of one or more transposed convolutional layers (i.e., the projected coordinates include non-integer value), and thus output locations that the system 100 attempts to project back to fixed-size input locations are invalid and cannot be used.
在一些實施方案中，系統100亦可基於一對應固定大小輸入之座標及經部署之FCN模型之特性來獲得一固定大小輸出之座標。一種實例性演算法被稱為「 ProjectForward()」，其內容如下： In some implementations, the system 100 can also obtain coordinates of a fixed-size output based on a coordinate corresponding to a fixed-size input and characteristics of the deployed FCN model. An example algorithm is called " ProjectForward ()" and it reads as follows:
類似地， Validate()函數可由 ProjectForwards()演算法使用以驗證一固定大小輸入位置至其對應輸出位置之投射，且可判定(例如)具有大於1之一步幅大小之一卷積層之固定大小輸入位置是否不合適。 Similarly, the Validate() function can be used by the ProjectForwards() algorithm to validate the projection of a fixed-size input location to its corresponding output location, and can determine, for example, the fixed-size input of a convolutional layer with a stride size greater than 1 Is the location inappropriate.
返回參考圖3A及圖3D，系統可判定一虛設區域之一寬度 b，使得寬度 b之區域應至少包含所有不準確像素。在一些實施方案中，虛設區域可包含所有不準確像素及一或多個準確像素。然而，寬度 b不應太大而損害運算效能，此係因為一大寬度 b可導致系統100在平鋪及拼接程序期間產生更大數目個重疊固定大小輸出及固定大小輸入。系統100可藉由計算各層之層輸出之第一有效像素偏移來判定寬度 b之一最小值。當前層之第一有效像素係由系統100計算，而未使用來自一先前層之輸出之任何零值相鄰像素。系統100執行函數 FirstValidPixelOffset()之操作如下： Referring back to FIG. 3A and FIG. 3D , the system can determine a width b of a dummy region, so that the region of width b should at least include all inaccurate pixels. In some implementations, a dummy region may include all inaccurate pixels and one or more accurate pixels. However, the width b should not be so large as to impair computational performance because a large width b can cause the system 100 to generate a larger number of overlapping fixed-size outputs and fixed-size inputs during the tiling and tiling process. The system 100 can determine a minimum value of the width b by calculating the first effective pixel offset of the layer output of each layer. The first valid pixel of the current layer is computed by system 100 without using any zero-valued neighboring pixels from the output of a previous layer. The operation of the system 100 to execute the function FirstValidPixelOffset () is as follows:
應注意，一般而言，用於自一固定大小輸出之左側及右側計算之第一有效像素之準則並不完全對稱，即，一些像素可保留於無法應用濾波器之固定大小輸入之右側上，此使固定大小輸出之右側上之有效像素比左側多一個。 FirstValidPixelOffset()函數之輸出(例如，第一有效偏移)係自左側計算，且此值對於右側亦應為正確的。類似地，上述分析亦應適用於自固定大小輸出之頂部或底部之計算。 It should be noted that, in general, the criteria for the first significant pixel computed from the left and right sides of a fixed-size output are not perfectly symmetrical, i.e. some pixels may remain on the right side of a fixed-size input where the filter cannot be applied, This causes one more pixel to be active on the right side of the fixed size output than on the left side. The output of the FirstValidPixelOffset () function (eg, first valid offset) is calculated from the left, and this value should also be correct for the right. Similarly, the above analysis should also apply to calculations from the top or bottom of a fixed-size output.
返回參考第二演算法中之 AlignOutputTile()函數並結合 ProjectBackwards()函數，系統100可獲得各自固定大小輸出之各者之一各自座標移位，且藉由基於各自座標移位組合各自固定大小輸出來產生一最終輸出。 Referring back to the AlignOutputTile () function in the second algorithm and in conjunction with the ProjectBackwards () function, the system 100 can obtain a respective coordinate shift of each of the respective fixed-size outputs, and combine the respective fixed-size outputs by combining the respective fixed-size outputs based on the respective coordinate shifts to produce a final output.
系統100可使用不同方法實施 AlignOutputTile()函數。僅舉幾例，系統100可對各自座標移位執行一局部搜尋，或獲得各自座標移位之分析表達式。 AlignOutputTile()內容如下： System 100 may implement the AlignOutputTile () function using different methods. The system 100 may perform a local search for the respective coordinate shifts, or obtain an analytical expression for the respective coordinate shifts, to name a few. AlignOutputTile () content is as follows:
當使用局部搜尋方法時，系統100可在各維度上提供複數個試驗移位值。針對一座標移位，試驗移位值可在零像素至一座標移位之一預定最大值(例如，最終輸出之大小)之範圍內。系統100需要判定一「未對準」固定大小輸出之座標與相關聯固定大小輸入之座標之間的一關係。作為一實例，系統100可將「未對準」固定大小輸出133之座標及試驗移位值提供至
ProjectBarckwards()函數中以搜尋一經驗證固定大小輸入(即，表示固定大小輸入之座標應落在積分像素上)。一旦系統100成功地找到經驗證之固定大小輸入，系統100便可基於特定試驗移位值返回經移位之固定大小輸出。
When using the local search method, the system 100 can provide a plurality of trial shift values in each dimension. For a coordinate shift, the trial shift value may range from zero pixels to a predetermined maximum value for the coordinate shift (eg, the size of the final output). The system 100 needs to determine a relationship between the coordinates of a "misaligned" fixed-size output and the coordinates of the associated fixed-size input. As an example, the system 100 may provide the coordinates of the "misaligned" fixed-
當使用分析方法時，系統100可藉由分析經部署之FCN模型之特性來判定一恆定對準值。分析表達式之一個實例性演算法被稱為內容如下之「 CalculateAnalyticalAlignment()」： When using the analysis method, the system 100 can determine a constant alignment value by analyzing the characteristics of the deployed FCN model. An example algorithm for analytical expressions is called " CalculateAnalyticalAlignment ()" as follows:
系統100基於FCN模型之各層之特性來判定恆定對準值。例如，特性可為一層類型(例如，卷積、轉置卷積層或諸如匯集層之其他層)，或用於層之填補、濾波器及步幅之一大小。如先前所描述，FCN模型中之其他類型之層(例如，匯集層)在整個說明書中被視為一卷積層。The system 100 determines a constant alignment value based on the characteristics of each layer of the FCN model. For example, a characteristic can be a layer type (eg, convolution, transposed convolutional layer, or other layer such as a pooling layer), or a size of padding, filters, and strides for a layer. As previously described, other types of layers in FCN models (eg, pooling layers) are treated throughout this specification as a convolutional layer.
圖3B繪示由圖1之實例性推論系統100執行之平鋪及拼接程序399之一實例。系統100可經組態以使用第一演算法執行平鋪及拼接程序355。FIG. 3B illustrates an example of a tiling and
系統100可產生具有各自大小之多個固定大小輸入350a、350b、350c及350d。例如，固定大小輸入350a至350d可各具有一不同大小。作為另一實例，固定大小輸入350a至350d可具有如圖3B中所展示之相同大小。為便於說明，固定大小輸入350a至350d係用具有實線之正方形表示。System 100 may generate multiple fixed-
如圖3B中所展示，各固定大小輸入350a至350d可具有一各自相鄰像素區域360a、360b、360c或360d。相鄰像素區域之大小或寬度可為一個像素、三個像素及五個像素。為便於說明，相鄰像素區域係用具有虛線之正方形呈現。應注意，零像素值區域360a之左區域不包含任何零值相鄰像素，此係因為固定大小輸入350a之左邊緣亦係完整輸入資料150之左邊緣之一部分，使得固定大小輸入350a之左區域中之像素之運算處理不引入對應固定大小輸出之不準確性。As shown in FIG. 3B, each fixed-
在一些實施方案中，固定大小輸入350a至350d及各自相關聯之相鄰像素區域360a至360d可相對於完整輸入資料150均勻地間隔且彼此均勻地重疊。如圖3B中所展示，固定大小輸入350a及350b在重疊區域353a中彼此重疊，固定大小輸入350b及350c在區域353b中彼此重疊，且固定大小輸入350c及350d在區域353c中彼此重疊。重疊區域353a及353b具有相同大小，但重疊區域353c可大於重疊區域353a及353b。此係歸因於第一演算法之特性。如第一演算法中所展示，右邊界及底部邊界上之固定大小輸入不能超過一輸入資料之邊界。例如，假定固定大小輸入350d以與其他固定大小輸入350a至350c相同之方式配置，則固定大小輸入350d係在右邊界上且可具有超過完整輸入資料150之右邊界之一部分。系統100可使用第一演算法將固定大小輸入350d向左「平移」(即，重新平鋪)幾個像素，使得固定大小輸入350d之像素完全定位於完整輸入資料150內部。然而，由於固定大小輸入350d之配置不再與其他固定大小輸入相同，因此固定大小輸入350d與350c之間的重疊區域353c可大於重疊區域353a及353c。當右及底部邊界上之固定大小輸入不超過完整輸入資料150之對應邊界時，固定大小輸入可經配置以具有相同重疊區域。In some implementations, the fixed-
在基於線上或離線計算之一固定大小將完整輸入資料150平鋪成多個固定大小輸入之後，系統100可處理隨機大小輸入並至少基於第一演算法及將在下文更詳細描述之一拼接演算法產生具有彼此不重疊且在邊緣像素上彼此鄰接之各自有效區域之固定大小輸出。After tiling the
系統100可在完整輸出資料170中產生具有大體上彼此不重疊之有效區域之固定大小輸出。然而，在一些情況下，一或多個固定大小輸出可彼此重疊。如圖3B中所展示，有效區域370a、370b及370c彼此不重疊。然而，有效區域370d在一重疊區域373中與有效區域370c重疊。此係因為第一演算法可使用第一演算法將右邊界固定大小輸入350a向左「平移」幾個像素，使得固定大小輸出370d與相鄰固定大小輸出370c重疊。與一對應有效區域相關聯之虛設區域375a、375b、375c及375d可重疊。為便於說明，固定大小輸出之有效區域係用具有實線之正方形表示，且固定大小輸出之虛設區域係用具有虛線之正方形表示。The system 100 can generate a fixed size output in the
虛設區域375a之左區域不包含任何無效值，此係因為固定大小輸出375a之左邊緣亦係完整輸出資料170之左邊緣之一部分。類似地，虛設區域375d之右邊緣不包含任何無效值。The left area of
在拼接程序期間，系統100可摒棄虛設區域中之逐像素值，並連接有效區域中之逐像素值以產生完整輸出資料170。完整輸出資料(或最終輸出)中之各像素值係自有效區域中之所有逐像素值至少提供一次。During the stitching process, the system 100 may discard the pixel-by-pixel values in the dummy area and concatenate the pixel-by-pixel values in the valid area to produce the
圖3C繪示由圖1之實例性推論系統100執行之平鋪及拼接程序355之另一實例。系統100可經組態以使用第二演算法執行平鋪及拼接程序399。FIG. 3C illustrates another example of the tiling and
相較於第一演算法，如上文所描述，系統100使用第二演算法執行一些額外步驟，例如，判定FCN模型之對準資訊及藉由基於對準資訊計算固定大小輸出之座標移位來判定有效區域。此係因為當一FCN模型包含特定層(例如，轉置卷積層)時，系統需要驗證自一固定大小輸出中之像素至一固定大小輸入中之對應像素之映射(例如，整數座標)。Compared to the first algorithm, as described above, the system 100 uses the second algorithm to perform some additional steps, such as determining the alignment information of the FCN model and calculating the coordinate shift of the fixed-size output based on the alignment information. Determine the valid area. This is because when an FCN model contains certain layers (eg, transposed convolutional layers), the system needs to verify the mapping (eg, integer coordinates) from a pixel in a fixed-size output to a corresponding pixel in a fixed-size input.
另外，第二演算法因不需要在完整輸入資料150之右或底部邊界上執行固定大小輸出之「平移」而與第一演算法不同。Additionally, the second algorithm differs from the first algorithm in that it does not need to perform a fixed-size output "translation" on the right or bottom border of the
如圖3C中所展示，系統100可基於一平鋪圖案自完整輸入資料150產生多個固定大小輸入(例如，固定大小輸入380a至380d)。固定大小輸入380a至380d可以一各自大小或相同大小彼此重疊。例如，固定大小輸入380a及第二固定大小輸入380b可在一重疊區域385a中彼此重疊，第二固定大小輸入380b與第三固定大小輸入380c可在一重疊區域385b中彼此重疊，且第三固定大小輸入380c與第四固定大小輸入380d可在一重疊區域385c中彼此重疊。重疊區域385a至385c之大小實質上相同，如圖3C中所展示。在一些實施方案中，重疊區域385a至385c可略大於使用第一演算法產生之重疊區域。此係因為使用第二演算法之系統需要基於對準資訊來平鋪固定大小輸入。As shown in FIG. 3C, system 100 may generate multiple fixed-size inputs (eg, fixed-
系統100亦可判定及配置類似於上文描述之彼等之零值相鄰像素區域390a至390d。如圖3C中所展示且為便於說明，固定大小輸入380a、380b、380c及380d係由實線之正方形表示，且相鄰像素區域390a、390b、390c及390d係由虛線之正方形表示。System 100 may also determine and configure zero-valued
系統100可使用第二演算法判定完整輸入資料150外之一區域，且可能不需要「平移」固定大小輸入380d。如圖3C中所展示，固定大小輸入380d具有在完整輸入資料150外之一區域381。重疊區域385a至385c可維持相同，此係因為固定大小輸入380d未被「平移」。當處理其中不允許「平移」操作之特定輸入時，第二演算法比第一演算法更穩健。The system 100 may use the second algorithm to determine a region outside the
在透過經編譯之FCN模型處理所有固定大小輸入之後，系統100可判定所有固定大小輸出之有效區域395a、395b、395c及395d及對應虛設區域397a、397b及397c，根據第二演算法計算有效區域中之像素之座標移位，摒棄虛設區域中之像素，並組合有效區域中之像素以產生完整輸出資料170。有效區域395a至395d亦可在各自重疊區域393a至393c中彼此重疊。當固定大小輸入之間的重疊區域385a至385c係實質上相同時，各自重疊區域393a至393c可為實質上相同的。After processing all fixed-size inputs through the compiled FCN model, the system 100 can determine
類似地，為便於說明，固定大小輸出之有效區域395a至395d係由實線之正方形表示，且固定大小輸出之虛設區域397a至397d係由虛線之正方形表示。Similarly, for ease of illustration, the
應注意，雖然圖3B及圖3C中僅展示四個固定大小輸入及四個固定大小輸出，但應瞭解，系統100可產生用於平鋪完整輸入資料150之多於四個固定大小輸入，例如，5個、10個、20個、50個及更多。系統亦可產生包含完整輸出資料170中之各像素之有效逐像素值之多於四個固定大小輸出，例如，5個、10個、20個、50個及更多。在完整輸出資料170中相關聯之一像素之各逐像素值係至少在自一對應固定大小輸入產生之一固定大小輸出中表示。對於跨兩個或更多個固定大小輸出之重疊區域中之一像素之一逐像素值，系統100可自重疊固定大小輸出之任一者選擇一對應像素值作為像素之逐像素值。It should be noted that although only four fixed-size inputs and four fixed-size outputs are shown in FIGS. 3B and 3C, it should be appreciated that the system 100 may generate more than four fixed-size inputs for tiling the
在透過FCN模型運算所有固定大小輸出之後，系統可應用 After computing all fixed-size outputs through the FCN model, the system can apply
圖4繪示用於針對不同大小之輸入執行一全卷積網路之推論運算之一實例性程序400。為方便起見，程序400被描述為由定位於一或多個位置中之一或多個電腦之一系統執行。例如，經適當程式化之一神經推論系統(例如，圖1之系統100)可執行程序400。FIG. 4 illustrates an example procedure 400 for performing inference operations of a fully convolutional network on inputs of different sizes. For convenience, process 400 is described as being performed by a system located on one or more computers in one or more locations. For example, a suitably programmed neural inference system (eg, system 100 of FIG. 1 ) may execute procedure 400 .
系統接收待由部署於一硬體加速器上之一全卷積神經網路處理之一新輸入。(410)該新輸入可具有不同於該全卷積神經網路經組態以在部署於該硬體加速器上時處理之一固定大小之一第一大小。如上文所描述，新輸入可具有大於該固定大小或小於該固定大小之一大小。The system receives a new input to be processed by a fully convolutional neural network deployed on a hardware accelerator. (410) The new input can have a first size different from a fixed size that the fully convolutional neural network is configured to handle when deployed on the hardware accelerator. As described above, the new input may have a size that is either larger than the fixed size or smaller than the fixed size.
系統自新輸入判定一或多個固定大小輸入。(420)一或多個固定大小輸入之各固定大小輸入具有固定大小。更明確言之，系統可至少基於經部署之FCN模型之特性(例如，對準資訊、填補大小、步幅大小、濾波器大小及縮放因數)來判定用於平鋪新輸入之一平鋪圖案。The system evaluates one or more fixed-size inputs from the new input. (420) Each of the one or more fixed-size inputs has a fixed size. More specifically, the system can determine a tiling pattern for tiling the new input based at least on characteristics of the deployed FCN model (eg, alignment information, padding size, stride size, filter size, and scaling factor).
系統將一或多個固定大小輸入之各者提供至硬體加速器以用於使用全卷積神經網路執行推論運算。(430)The system provides each of one or more fixed-size inputs to a hardware accelerator for performing inference operations using a fully convolutional neural network. (430)
系統自硬體加速器獲得藉由全卷積神經網路針對一或多個固定大小輸入之各者而產生之一各自固定大小輸出。(440)各自固定大小輸出可包含一或多個不準確的逐像素結果。如上文所描述，系統可包含一主機以對硬體加速器上之經部署FCN提供固定大小輸入，及接收來自硬體加速器之固定大小輸出。系統在處理固定大小輸入時可使用圍繞固定大小輸入之相鄰像素，並判定各固定大小輸出之一有效區域及一虛設區域。The system obtains from the hardware accelerator a respective fixed-size output generated by the fully convolutional neural network for each of the one or more fixed-size inputs. (440) The respective fixed-size outputs may contain one or more inaccurate pixel-by-pixel results. As described above, the system may include a host to provide fixed size input to a deployed FCN on a hardware accelerator, and to receive fixed size output from the hardware accelerator. The system can use adjacent pixels surrounding the fixed-size input when processing the fixed-size input, and determine a valid area and a dummy area for each fixed-size output.
系統自各自固定大小輸出產生等效於將藉由使用全卷積神經網路處理新輸入而產生之一輸出之一最終輸出。(450)From the respective fixed-size outputs, the system produces a final output equivalent to one that would be produced by processing new inputs using a fully convolutional neural network. (450)
如上文所描述，系統可使用不同演算法基於經部署FCN之特性組合固定大小輸出。若FCN模型不包含任何轉置卷積層，則系統可使用第一演算法組合各固定大小輸出之有效區域。若FCN模型包含一或多個轉置卷積層，則系統可藉由獲得各固定大小輸出之座標移位，及基於該等座標移位使各固定大小輸出之座標移位來組合固定大小輸出。As described above, the system can use different algorithms to combine fixed-size outputs based on the characteristics of the deployed FCN. If the FCN model does not contain any transposed convolutional layers, the system can use the first algorithm to combine the effective regions of each fixed-size output. If the FCN model includes one or more transposed convolutional layers, the system can combine fixed-size outputs by obtaining a coordinate shift of each fixed-size output, and shifting the coordinates of each fixed-size output based on the coordinate shifts.
系統可使用不同方法判定一座標移位。例如，系統可使用局部搜尋判定一座標移位。系統可藉由使用 ProjectBackwards()函數測試複數個試驗移位值來產生一固定大小輸出之一座標移位。替代性地，系統可基於分析一經部署FCN之特性來產生一座標移位，並藉由使用「 CalculateAnalyticalAlignment()」函數之分析表達式獲得座標移位之恆定值。 The system can use different methods to determine a coordinate shift. For example, the system may use a local search to determine coordinate shifts. The system can generate a coordinate shift of a fixed size output by testing a plurality of trial shift values using the ProjectBackwards () function. Alternatively, the system can generate a coordinate shift based on analyzing the characteristics of a deployed FCN, and obtain a constant value of the coordinate shift by an analytical expression using the " CalculateAnalyticalAlignment ()" function.
可在數位電子電路系統、有形體現之電腦軟體或韌體、電腦硬體(包含本說明書中所揭示之結構及其等之結構等效物)或其等之一或多者之組合中實施本說明書中所描述之標的物及動作以及操作之實施方案。本說明書中所描述之標的物之實施方案可經實施為一或多個電腦程式，例如，在一電腦程式載體上編碼以藉由資料處理設備執行或控制資料處理設備之操作之電腦程式指令之一或多個模組。載體可為一有形非暫時性電腦儲存媒體。替代性地或此外，載體可為一人為產生之傳播信號(例如，一機器產生之電、光學或電磁信號)，其經產生以編碼資訊用於傳輸至合適接收器設備以藉由一資料處理設備執行。電腦儲存媒體可為一機器可讀儲存裝置、一機器可讀儲存基板、一隨機或串列存取記憶體裝置或其等之一或多者之一組合，或為其等之部分。一電腦儲存媒體並非一傳播信號。The present invention may be implemented in one or more combinations of digital electronic circuit systems, tangibly embodied computer software or firmware, computer hardware (including the structures disclosed in this specification and their structural equivalents) Embodiments of the subject matter and acts and operations described in the specification. Embodiments of the subject matter described in this specification can be implemented as one or more computer programs, for example, computer program instructions encoded on a computer program carrier for execution by or to control the operation of data processing equipment One or more mods. A carrier can be a tangible, non-transitory computer storage medium. Alternatively or in addition, the carrier may be an artificially generated propagated signal (for example, a machine-generated electrical, optical or electromagnetic signal) generated to encode information for transmission to suitable receiver equipment for processing by a data device execution. The computer storage medium can be a machine-readable storage device, a machine-readable storage substrate, a random or serial access memory device, or a combination of one or more of them, or a part thereof. A computer storage medium is not a propagated signal.
術語「資料處理設備」涵蓋用於處理資料之全部種類的設備、裝置及機器，藉由實例，包含一可程式化處理器、一電腦或多個處理器或電腦。資料處理設備可包含專用邏輯電路系統，例如，一FPGA (場可程式化閘陣列)、一ASIC (特定應用積體電路)或一GPU (圖形處理單元)。除硬體之外，設備亦可包含針對電腦程式創建一執行環境之程式碼，例如，構成處理器韌體、一協定堆疊、一資料庫管理系統、一作業系統或其等之一或多者之一組合的程式碼。The term "data processing equipment" covers all kinds of equipment, devices and machines for processing data, including by way of example a programmable processor, a computer or a plurality of processors or computers. The data processing device may comprise special purpose logic circuitry such as, for example, an FPGA (Field Programmable Gate Array), an ASIC (Application Specific Integrated Circuit) or a GPU (Graphics Processing Unit). In addition to hardware, devices may also contain code that creates an execution environment for computer programs, for example, making up one or more of processor firmware, a protocol stack, a database management system, an operating system, or the like The code for one of the combinations.
可以任何形式之程式設計語言(包含編譯或解譯語言、或宣告式或程序性語言)撰寫一電腦程式(其亦可被稱為或描述為一程式、軟體、一軟體應用程式、一應用程式、一模組、一軟體模組、一引擎、一指令檔或程式碼)；且其可以任何形式部署，包含作為一獨立程式或作為一模組、組件、引擎、副常式或適合在一運算環境中執行之其他單元，該環境可包含藉由一資料通信網路在一或多個位置中互連之一或多個電腦。A computer program (which may also be called or described as a program, software, a software application, an application) may be written in any form of programming language (including compiled or interpreted languages, or declarative or procedural languages) , a module, a software module, an engine, a script, or code); and it may be deployed in any form, including as a stand-alone program or as a module, component, engine, subroutine, or suitable in a Other units execute in a computing environment, which may include one or more computers interconnected in one or more locations by a data communications network.
一電腦程式可(但不需要)對應於一檔案系統中之一檔案。一電腦程式可儲存於保存其他程式或資料(例如，儲存於一標記語言文件中之一或多個指令檔)之一檔案之一部分中、專用於所討論之程式之一單一檔案中或多個協調檔案(例如，儲存程式碼之一或多個模組、子程式或部分的檔案)中。A computer program may (but need not) correspond to a file in a file system. A computer program may be stored in a portion of a file that holds other programs or data (for example, in one or more script files in a markup language file), in a single file dedicated to the program in question, or in multiple In a coordination file (for example, a file that stores one or more modules, subroutines, or sections of code).
可藉由執行一或多個電腦程式以藉由對輸入資料進行操作及產生輸出而執行操作之一或多個電腦來執行本說明書中所描述之程序及邏輯流程。亦可藉由專用邏輯電路系統(例如，一FPGA、一ASIC或一GPU)或藉由專用邏輯電路系統與一或多個經程式化電腦之一組合來執行該等程序及邏輯流程。The procedures and logic flows described in this specification can be performed by one or more computers executing one or more computer programs to perform operations by operating on input data and generating output. The programs and logic flows can also be executed by special purpose logic circuitry (eg, an FPGA, an ASIC, or a GPU) or by a combination of special purpose logic circuitry and one or more programmed computers.
適合於一電腦程式之執行之電腦可基於通用微處理器或專用微處理器或兩者或任何其他種類之中央處理單元。通常，一中央處理單元將接收來自一唯讀記憶體或一隨機存取記憶體或兩者之指令及資料。一電腦之關鍵元件係用於執行指令之一中央處理單元及用於儲存指令及資料之一或多個記憶體裝置。中央處理單元及記憶體可由專用邏輯電路系統增補或併入於專用邏輯電路系統中。A computer suitable for the execution of a computer program may be based on a general purpose microprocessor or a special purpose microprocessor or both or any other kind of central processing unit. Typically, a central processing unit will receive instructions and data from a read only memory or a random access memory or both. The key components of a computer are the central processing unit for executing instructions and one or more memory devices for storing instructions and data. The central processing unit and memory may be supplemented by or incorporated in special purpose logic circuitry.
通常，一電腦亦將包含一或多個大容量儲存裝置，或可操作耦合以接收來自該一或多個大容量儲存裝置之資料或將資料傳送至該一或多個大容量儲存裝置。例如，大容量儲存裝置可為磁碟、磁光碟或光碟，或固態碟機。然而，一電腦不需要具有此等裝置。此外，一電腦可嵌入於另一裝置中，僅舉幾例，例如，一行動電話、一個人數位助理(PDA)、一行動音訊或視訊播放器、一遊戲控制台、一全球定位系統(GPS)接收器或一可攜式儲存裝置(例如，一通用串列匯流排(USB)快閃隨身碟)。Typically, a computer will also include, or be operably coupled to receive data from or transmit data to, one or more mass storage devices. For example, a mass storage device may be a magnetic, magneto-optical or optical disk, or a solid-state drive. However, a computer need not have such devices. Additionally, a computer may be embedded in another device, such as a mobile phone, a personal digital assistant (PDA), a mobile audio or video player, a game console, a global positioning system (GPS), to name a few receiver or a portable storage device (eg, a Universal Serial Bus (USB) flash drive).
為提供與一使用者之互動，本說明書中所描述之標的物之實施方案可在一電腦上實施或經組態以與該電腦通信，該電腦具有用於向使用者顯示資訊之一顯示裝置(例如，一LCD (液晶顯示器)監視器)及該使用者可藉由其提供輸入至該電腦之一輸入裝置(例如，一鍵盤及一指標裝置(例如，一滑鼠、一軌跡球或觸控墊))。其他種類之裝置亦可用於提供與一使用者之互動；例如，提供給該使用者之回饋可為任何形式之感覺回饋，例如，視覺回饋、聽覺回饋或觸覺回饋；且來自該使用者之輸入可以任何形式接收，包含聲音、語音或觸覺輸入。另外，一電腦可藉由發送文件至由一使用者使用之一裝置及自該裝置接收文件而與該使用者互動；例如，藉由回應於自一使用者之裝置上之一網頁瀏覽器接收之請求而將網頁發送至該網頁瀏覽器，或藉由與在一使用者裝置(例如，一智慧型電話或電子平板電腦)上運行之一應用程式互動。又，一電腦可藉由將文字訊息或其他形式之訊息發送至一個人裝置(例如，運行一訊息傳遞應用程式之一智慧型電話)，及作為回報接收來自一使用者之回應訊息而與該使用者互動。To provide for interaction with a user, implementations of the subject matter described in this specification can be implemented on or configured to communicate with a computer having a display device for displaying information to the user (e.g., an LCD (liquid crystal display) monitor) and an input device (e.g., a keyboard and a pointing device (e.g., a mouse, a trackball, or touchscreen) through which the user can provide input to the computer control pad)). Other types of devices can also be used to provide interaction with a user; for example, the feedback provided to the user can be any form of sensory feedback, such as visual feedback, auditory feedback, or tactile feedback; and input from the user Can be received in any form, including sound, speech or tactile input. Additionally, a computer can interact with a device used by a user by sending and receiving files to and from a device used by the user; for example, by responding to messages received from a web browser on a user's device or by interacting with an application running on a user device (eg, a smartphone or electronic tablet). Also, a computer can communicate with the user by sending text messages or other forms of information to a personal device (e.g., a smartphone running a messaging application), and in return receiving a response message from a user. interaction.
本說明書結合系統、設備及電腦程式組件使用術語「經組態以」。對於一或多個電腦之一系統經組態以執行特定操作或動作，意謂該系統已在其上安裝在操作中引起系統執行操作或動作之軟體、韌體、硬體或其等之一組合。對於一或多個電腦程式經組態以執行特定操作或動作，意謂該一或多個程式包含在由資料處理設備執行時引起設備執行操作或動作之指令。對於專用邏輯電路系統經組態以執行特定操作或動作，意謂電路系統具有執行操作或動作之電子邏輯。This specification uses the term "configured to" in conjunction with system, device, and computer program components. A system of one or more computers configured to perform a specific operation or action means that the system has installed thereon software, firmware, hardware, or one of the others that in operation causes the system to perform the operation or action combination. For one or more computer programs to be configured to perform specific operations or actions, it is meant that the one or more programs contain instructions that, when executed by data processing equipment, cause the equipment to perform the operations or actions. For application specific logic circuitry to be configured to perform a particular operation or action, it is meant that the circuitry has electronic logic to perform the operation or action.
可在一運算系統中實施本說明書中所描述之標的物之實施方案，該運算系統包含一後端組件(例如，作為一資料伺服器)，或包含一中介軟體組件(例如，一應用程式伺服器)，或包含一前端組件(例如，具有一使用者可透過其與本說明書中所描述之標的物之一實施方案互動之一圖形使用者介面、一網頁瀏覽器或一應用程式之一用戶端電腦)，或一或多個此等後端、中介軟體或前端組件之任何組合。該系統之該等組件可藉由數位資料通信之任何形式或媒體(例如，一通信網路)互連。通信網路之實例包含一區域網路(「LAN」)及一廣域網路(「WAN」)，例如，網際網路。Implementations of the subject matter described in this specification can be implemented in a computing system that includes a backend component (eg, as a data server), or that includes a middleware component (eg, as an application server browser), or include a front-end component (for example, a user interface having a graphical user interface through which a user interacts with an implementation of the subject matter described in this specification, a web browser, or an application program) end computer), or any combination of one or more of such backend, middleware, or frontend components. The components of the system can be interconnected by any form or medium of digital data communication (eg, a communication network). Examples of communication networks include a local area network ("LAN") and a wide area network ("WAN"), eg, the Internet.
運算系統可包含用戶端及伺服器。一用戶端及伺服器一般彼此遠離且通常透過一通信網路互動。用戶端與伺服器之關係憑藉運行於各自電腦上及彼此具有一用戶端-伺服器關係之電腦程式而發生。在一些實施方案中，一伺服器將資料(例如，一HTML頁面)傳輸至一使用者裝置，例如，用於向與充當一用戶端之裝置互動之一使用者顯示資料及接收來自該使用者之使用者輸入的目的。在使用者裝置處產生之資料(例如，使用者互動之一結果)可在伺服器處自裝置接收。The computing system may include clients and servers. A client and server are generally remote from each other and usually interact through a communication network. The relationship between client and server occurs by virtue of computer programs running on the respective computers and having a client-server relationship to each other. In some embodiments, a server transmits data (e.g., an HTML page) to a user device, e.g., for displaying data to a user interacting with the device acting as a client and receiving information from the user The purpose of user input. Data generated at a user device (eg, as a result of a user interaction) may be received at a server from the device.
雖然本說明書含有許多特定實施方案細節，但此等不應被解釋為限制正在主張或可主張之內容之範疇，而是被解釋為描述可特定於特定發明之特定實施方案之特徵。本說明書中在分開的實施方案之背景內容中所描述之特定特徵亦可組合實施於一單個實施方案中。相反地，在一單個實施方案之背景內容中描述之各種特徵亦可分開地實施於多個實施方案中或以任何合適子組合實施。此外，儘管特徵在上文可被描述為依特定組合起作用且甚至最初如此主張，然來自一所主張之組合之一或多個特徵在一些情況中可自該組合免除，且該主張可係關於一子組合或一子組合之變型。While this specification contains many specific implementation details, these should not be construed as limitations on the scope of what is claimed or of what may be claimed, but rather as descriptions of features that may be specific to particular implementations of particular inventions. Certain features that are described in this specification in the context of separate implementations can also be implemented in combination in a single implementation. Conversely, various features that are described in the context of a single implementation can also be implemented in multiple implementations separately or in any suitable subcombination. Furthermore, although features may be described above as functioning in particular combinations, and even initially claimed to be so, one or more features from a claimed combination may in some cases be exempt from that combination, and the claim may be Regarding a subcombination or a variation of a subcombination.
類似地，雖然在圖式中依一特定順序描繪操作且在發明申請專利範圍中依一特定順序敘述操作，但此不應被理解為需要依所展示之特定順序或依循序順序來執行此等操作或需要執行所有經繪示之操作以達成所要結果。在特定境況中，多任務處理及平行處理可為有利的。此外，上文所描述之實施方案中之各種系統模組及組件之分離不應被理解為在所有實施方案中需要此分離，且應理解，所描述之程式組件及系統可大體上一起整合於一單個軟體產品中或封裝於多個軟體產品中。Similarly, while operations are depicted in a particular order in the drawings and recited in a particular order in the claims, this should not be construed as requiring that their performance be performed in the particular order shown or in a sequential order Operations All illustrated operations may be performed to achieve the desired result. In certain circumstances, multitasking and parallel processing may be advantageous. Furthermore, the separation of the various system modules and components in the embodiments described above should not be understood as requiring such separation in all embodiments, and it should be understood that the described program components and systems may generally be integrated together in a In a single software product or packaged in multiple software products.
已描述標的物之特定實施方案。其他實施方案係在以下發明申請專利範圍之範疇內。例如，發明申請專利範圍中所敘述之動作可依一不同順序執行且仍達成所要結果。作為一實例，附圖中所描繪之程序並不一定需要所展示之特定順序，或循序順序來達成所要結果。在一些情況下，多任務處理及平行處理可為有利的。Certain implementations of the subject matter have been described. Other embodiments are within the scope of the following invention claims. For example, the actions recited in the claims can be performed in a different order and still achieve desirable results. As one example, the procedures depicted in the accompanying figures do not necessarily require the particular order shown, or sequential order, to achieve desirable results. In some circumstances, multitasking and parallel processing may be advantageous.
100:推論系統/系統 110:硬體加速器 115:經訓練之全卷積網路(FCN)/經部署之全卷積網路(FCN)/ 經編譯之全卷積網路(FCN)模型/經部署之全卷積網路(FCN)模型 130:主機 133:固定大小輸出 135:平鋪引擎 138:固定大小輸入/輸入 140:拼接引擎 150:輸入資料/原始輸入/完整輸入資料 155:資料 160:編譯引擎 170:輸出資料/所產生之輸出/最終輸出/最終輸出資料/完整輸出資料 200:推論程序/習知推論系統/系統 215:經部署之全卷積網路(FCN)/全卷積網路(FCN) 225:輸出資料 230:固定大小輸入 235:全卷積網路(FCN)模型/經部署之全卷積網路(FCN) 240:固定大小輸出 250:推論程序 310:相鄰像素區域 315:寬度 320:虛設區域 330:有效區域 335:寬度 340:轉置卷積層 341:輸出 342:輸出 344:輸出 345:轉置卷積層 346:輸出 350a:固定大小輸入 350b:固定大小輸入 350c:固定大小輸入 350d:固定大小輸入 353a:重疊區域 353b:重疊區域 353c:重疊區域 355:平鋪及拼接程序 360a:相鄰像素區域/零像素值區域 360b:相鄰像素區域 360c:相鄰像素區域 360d:相鄰像素區域 370a:有效區域 370b:有效區域 370c:有效區域/固定大小輸出 370d:有效區域/固定大小輸出 373:重疊區域 375a:虛設區域 375b:虛設區域 375c:虛設區域 375d:虛設區域 380a:固定大小輸入 380b:固定大小輸入/第二固定大小輸入 380c:固定大小輸入/第三固定大小輸入 380d:固定大小輸入/第四固定大小輸入 381:區域 385a:重疊區域 385b:重疊區域 385c:重疊區域 390a:零值相鄰像素區域 390b:零值相鄰像素區域 390c:零值相鄰像素區域 390d:零值相鄰像素區域 393a:重疊區域 393b:重疊區域 393c:重疊區域 395a:有效區域 395b:有效區域 395c:有效區域 395d:有效區域 397a:虛設區域 397b:虛設區域 397c:虛設區域 397d:虛設區域 399:平鋪及拼接程序 400:程序 410:步驟 420:步驟 430:步驟 440:步驟 450:步驟 100: Inference Systems/Systems 110:Hardware Accelerator 115:Trained Fully Convolutional Network (FCN)/Deployed Fully Convolutional Network (FCN)/Compiled Fully Convolutional Network (FCN) Model/Deployed Fully Convolutional Network (FCN) Model 130: Host 133:Fixed size output 135:Tiling engine 138:Fixed size input/input 140: Stitching engine 150: Input Data/Original Input/Complete Input Data 155: data 160:Compile engine 170: Output data/generated output/final output/final output data/complete output data 200: Deduction program/knowledge inference system/system 215: Deployed Fully Convolutional Network (FCN) / Fully Convolutional Network (FCN) 225: Output data 230:Fixed size input 235: Fully Convolutional Network (FCN) Model / Deployed Fully Convolutional Network (FCN) 240: Fixed size output 250: Deduction procedure 310: Adjacent pixel area 315: width 320: False area 330: effective area 335: width 340:Transpose Convolutional Layer 341: output 342: output 344: output 345:Transpose Convolutional Layer 346: output 350a: Fixed size input 350b: fixed size input 350c: Fixed size input 350d: fixed size input 353a: Overlapping area 353b: overlapping area 353c: overlapping area 355: Tiling and splicing procedures 360a: adjacent pixel area/zero pixel value area 360b: adjacent pixel area 360c: adjacent pixel area 360d: adjacent pixel area 370a: effective area 370b: effective area 370c: Valid Area/Fixed Size Output 370d: Valid Area/Fixed Size Output 373: Overlapping area 375a: False area 375b: False area 375c: False area 375d: False area 380a: Fixed size input 380b: fixed size input/second fixed size input 380c: fixed size input/third fixed size input 380d: fixed size input/fourth fixed size input 381: area 385a: Overlapping area 385b: Overlapping area 385c: overlapping area 390a: Neighboring pixel area with zero value 390b: Neighboring pixel area with zero value 390c: Neighboring pixel regions with zero values 390d: Neighboring pixel area with zero value 393a: Overlapping area 393b: Overlapping area 393c: Overlapping area 395a: effective area 395b: effective area 395c: effective area 395d: effective area 397a: False area 397b: False area 397c: False area 397d: False area 399: Tiling and splicing procedures 400: Procedure 410: Step 420: Step 430: Step 440: step 450: step
圖1展示用於針對不同大小之輸入而執行一全卷積網路之推論運算之一實例性推論系統。 圖2A繪示使用一習知系統之一實例性推論程序。 圖2B繪示使用圖1之實例性推論系統之一實例性推論程序。 圖3A繪示具有相鄰像素區域之一實例性固定大小輸入及具有虛設區域之一實例性固定大小輸出。 圖3B繪示由圖1之實例性推論系統執行之平鋪及拼接程序之一實例。 圖3C繪示由圖1之實例性推論系統執行之平鋪及拼接程序之另一實例。 圖3D繪示使用一FCN模型中之一轉置卷積層產生一輸出之一實例性程序。 圖4繪示用於針對不同大小之輸入執行一全卷積網路之推論運算之一實例性程序。 FIG. 1 shows an example inference system for performing inference operations of a fully convolutional network on inputs of different sizes. Figure 2A illustrates an exemplary inference process using a conventional system. FIG. 2B illustrates an example inference process using the example inference system of FIG. 1 . 3A illustrates an example fixed size input with adjacent pixel regions and an example fixed size output with dummy regions. 3B depicts an example of a tiling and stitching procedure performed by the example inference system of FIG. 1 . 3C illustrates another example of a tiling and stitching procedure performed by the example inference system of FIG. 1 . FIG. 3D illustrates an example procedure for generating an output using a transposed convolutional layer in an FCN model. FIG. 4 illustrates an exemplary procedure for performing inference operations of a fully convolutional network on inputs of different sizes.
100:推論系統/系統 100: Inference Systems/Systems
110:硬體加速器 110:Hardware Accelerator
115:經訓練之全卷積網路(FCN)/經部署之全卷積網路(FCN)/經編譯之全卷積網路(FCN)模型/經部署之全卷積網路(FCN)模型 115: Trained Fully Convolutional Network (FCN) / Deployed Fully Convolutional Network (FCN) / Compiled Fully Convolutional Network (FCN) Model / Deployed Fully Convolutional Network (FCN) Model
130:主機 130: Host
133:固定大小輸出 133:Fixed size output
135:平鋪引擎 135:Tiling engine
138:固定大小輸入/輸入 138:Fixed size input/input
140:拼接引擎 140: Stitching engine
150:輸入資料/原始輸入/完整輸入資料 150: Input Data/Original Input/Complete Input Data
155:資料 155: data
160:編譯引擎 160:Compile engine
170:輸出資料/所產生之輸出/最終輸出/最終輸出資料/完整輸出資料 170: Output data/generated output/final output/final output data/complete output data
Claims (14)
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
PCT/US2021/056418 WO2023075742A1 (en) | 2021-10-25 | 2021-10-25 | Efficiently performing inference computations of a fully convolutional network for inputs with different sizes |
WOPCT/US21/56418 | 2021-10-25 |
Publications (1)
Publication Number | Publication Date |
---|---|
TW202318333A true TW202318333A (en) | 2023-05-01 |
Family
ID=78650094
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
TW111140154A TW202318333A (en) | 2021-10-25 | 2022-10-24 | Efficiently performing inference computations of a fully convolutional network for inputs with different sizes |
Country Status (2)
Country | Link |
---|---|
TW (1) | TW202318333A (en) |
WO (1) | WO2023075742A1 (en) |
Family Cites Families (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11113553B2 (en) * | 2018-11-15 | 2021-09-07 | Brown University | Iris recognition using fully convolutional networks |
-
2021
- 2021-10-25 WO PCT/US2021/056418 patent/WO2023075742A1/en active Application Filing
-
2022
- 2022-10-24 TW TW111140154A patent/TW202318333A/en unknown
Also Published As
Publication number | Publication date |
---|---|
WO2023075742A1 (en) | 2023-05-04 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US11893454B1 (en) | Quantum computing in a three-dimensional device lattice | |
CN108615072B (en) | Performing average pooling in hardware | |
JP7186891B2 (en) | Quantum error correction decoding method, device, chip, computer equipment, and computer program based on neural network | |
KR102232722B1 (en) | Convolutional Neural Network on a Programmable Two-Dimensional Image Processor | |
KR102107709B1 (en) | Spatial transformer modules | |
KR101973733B1 (en) | Architecture for high performance, power efficient, programmable image processing processing | |
JP6848071B2 (en) | Repetitive multi-scale image generation using neural networks | |
KR101734449B1 (en) | Structured grids for label propagation on a finite number of layers | |
CN113627086B (en) | Method, device, medium and program product for optimizing horizontal federal learning modeling | |
JP7403638B2 (en) | Fast sparse neural network | |
CN104813318A (en) | Techniques for context-based grouping of messages for translation | |
JP2021507345A (en) | Fusion of sparse kernels to approximate the complete kernel of convolutional neural networks | |
CN110580478B (en) | Active segmentation of scanned images based on depth-enhanced learning for OCR applications | |
Goudarzi et al. | Design of a universal logic block for fault-tolerant realization of any logic operation in trapped-ion quantum circuits | |
CN103871086B (en) | FPGA (Field Programmable Gata Array) construction-based layered raster-to-vector processing method | |
CN114241524A (en) | Human body posture estimation method and device, electronic equipment and readable storage medium | |
CN114398080A (en) | Data processing method, device and equipment and computer storage medium | |
TW202318333A (en) | Efficiently performing inference computations of a fully convolutional network for inputs with different sizes | |
Copty et al. | A data parallel algorithm for solving the region growing problem on the connection machine | |
CN111488280B (en) | Data processing method, data processing device, storage medium and electronic equipment | |
Perez et al. | Task-based crowd simulation for heterogeneous architectures | |
Gupta et al. | Self-attention-Based Efficient U-Net for Crack Segmentation | |
CN115965736A (en) | Image processing method, device, equipment and storage medium | |
US20230206629A1 (en) | Arranging a set of images for presentation to a user | |
CN111194451B (en) | Parallel execution of gated active unit operations |