Embodiment
Before the embodiment below describing in detail, should observe, said embodiment mainly be with frame in the space method step relevant and the combination of equipment unit with gradable video encoding.Therefore; Equipment unit and method step are represented as conventional symbols in the accompanying drawings in due course; Accompanying drawing only shows those details relevant with understanding embodiments of the invention, so as not with for benefit from this description, the conspicuous details of those of ordinary skills obscures the disclosure.
In this article; Only be used for an entity or behavior and another entity or behavior are distinguished mutually with the relational terms of upper and lower grade such as first and second, and needn't require or hint such relation or order in such entity or any reality between the behavior.Term " comprises ", " comprising " or its any other version are intended to contain non-exclusive comprising; The process, method, project or the equipment that comprise series of elements thus not only comprise those elements, and comprise and do not list clearly or such other intrinsic elements of process, method, project or equipment.Before " comprising ... one " arranged element under the situation that do not having more restrictions, be not precluded within and have other identical element in process, method, project or the equipment that comprises said element.
A. gradable spatial is encoded
Referring to Fig. 3, presented high level block diagram, it illustrates the gradable spatial coded system 400 that is used for legacy system and is used to have the specific embodiment of three layers of resolution, and it is used to provide the introduction for general gradable spatial coded system framework.The frame of video signal 401 that is used for the highest resolution version of frame of video is coupled to two dimension (2-D) down-sampler 404 and enhancement layer encoder 450.The 2-D down-sampler produces the downsampled version 402 of frame of video, and the downsampled version 402 of frame of video is coupled to two-dimentional down-sampler 405 and enhancement layer encoder 430.Can produce the lowest resolution version of the frame of video that is coupled to Base layer encoder 410 with two-dimentional down-sampler 404 different two-dimentional down-samplers 405.Base layer encoder 410 produces as being coupled to the base layer bit stream 415 of the output of multiplexer 420.Enhancement layer encoder 430 uses the recovering information 435 from basal layer to remove interlayer redundancy, and produces as the enhancement layer bit-stream 438 that is used for the output of presentation code input video frame 402.Enhancement layer bit-stream 438 also is coupled to multiplexer 420.Enhancement layer encoder 450 uses the recovering information 445 from inferior low layer to remove interlayer redundancy, and produces the enhancement layer bit-stream 455 as the output of the input video frame 401 that is used for presentation code.Enhancement layer bit-stream 455 also is coupled to multiplexer 420.Multiplexer 420 multiplexing base layer bit stream and two enhancement layer bit-stream 438,455; To produce gradable bit streams 440, gradable bit streams 440 transmits low-definition version, the higher resolution version of frame of video or the needed coded message of highest resolution version of bit stream of recovering frame of video.
Referring to Fig. 4, presented high level block diagram, it illustrates the gradable spatial decode system 500 that is used for legacy system and is used to have the specific embodiment of two layers of resolution, and it is used to provide the introduction for general gradable spatial decode system framework.Be appreciated that this high level block diagram high level block diagram of encoder 400 that has been close to mirror image.Demodulation multiplexer 510 is base layer bit stream 515 that is received and the enhancement layer bit-stream 520 that is received with the version that is received 505 demultiplexings of gradable bit streams 440.The base layer bit stream 515 that 525 decodings of basal layer decoder are received, and produce the low-definition version 530 of the recovery of original video frame.The enhancement layer bit-stream 520 that el decoder 540 decoding is received, and use information 535 to produce the high-resolution version 545 of the recovery of encoded video frame from the recovery of basal layer.How making up the high level block diagram of the embodiment that is used to have three layers of resolution, should be obvious for those of ordinary skills.
Referring to Fig. 5, block diagram shows the gradable spatial coded system 600 of the specific embodiment that is proposed that is used to have two layers of resolution.The frame of video signal 601 that is used for the highest resolution version of frame of video is coupled to the Subband Analysis Filter group 631 of two dimension (2-D) down-sampler 605 and enhancement layer encoder 630.The lowest resolution version 603 of 2-D down-sampler 605 generation source frame of video.Lowest resolution version 603 is coupled to Base layer encoder, and Base layer encoder comprises a layer interior frame texture encoder 610.Frame texture encoder 610 produces as being coupled to the base layer bit stream 615 of the output of multiplexer 620 in the layer.Subband Analysis Filter group 631 produce frame of video highest resolution version 601 subband (small echo) coefficient---these normally are called the subband of LL, LH, HL and HH subband in the art.Interlayer frame texture encoder 633 is used from the information 635 of basal layer removing interlayer redundancy, and produces the enhancement layer bit-stream 638 of representing 632 output as the input subband that is used for presentation code.Enhancement layer bit-stream 638 also is coupled to multiplexer 620.Multiplexer 620 multiplexing base layer bit stream 615 and enhancement layer bit-stream 638, to produce gradable bit streams 640, this gradable bit streams 640 transmits the low-definition version of recovery frame of video or the needed coded message of highest resolution version of bit stream.Be appreciated that; In having the embodiment of more enhancement layers; The Subband Analysis Filter group of each enhancement layer encoder is used to the subband of the specified resolution version of generation source frame of video to be represented, and the sub-band coefficients of resultant expression is by the interlayer texture frame encoder encodes of each enhancement layer.
Referring to Fig. 6, block diagram shows the gradable spatial decode system 700 of the specific embodiment that is used to have two layers of resolution.Be appreciated that this block diagram block diagram of encoder 600 that has been close to mirror image.Demodulation multiplexer 710 is base layer bit stream 715 that is received and the enhancement layer bit-stream 720 that is received with the version that is received 705 demultiplexings of gradable bit streams 440.Comprise layer base layer bit stream 715 that the basal layer decoder decode of interior frame texture decoder device 725 is received, and produce the low-definition version 730 of the recovery of encoded video frame.The enhancement layer bit-stream 720 that interlayer frame texture decoder device 743 decoding is received, and the subband that uses information 735 from the recovery of basal layer to produce the recovery of enhancement layer representes 745.Subband synthesis filter group 747 is handled the subband that recovers then and is represented 745, and produces the synthetic high-resolution version 750 of encoded video frame.The synthetic high-resolution version 750 of encoded video frame is coupled to delimiter 755 at last, and delimiter 755 cuts out operation for synthetic frame execution according to the pixel value scope.How making up and be used to have three or the high level block diagram of the embodiment of multiresolution layer more, should be obvious for those of ordinary skills.
Referring to Fig. 7, block diagram illustration according to the block diagram of down-sampling operation separable couple of embodiment of specific 2-D, that carry out by 2-D down-sampler 404,405 and 605.Frame of video information 810 (also being called frame of video more simply) is accepted as input by first one dimension (1-D) filter 810; First one dimension (1-D) filter 810 is carried out vertical filtering for each row of input video frame, and by the frame of filtering then through factor 2 by further down-sampling vertically.Next this result 825 is handled by the 2nd 1-D filter 830; The 2nd 1-D filter 830 is for each row executive level filtering of input signal 825; And by the signal of filtering then through factor 2 by further down-sampling flatly; Produce the low-definition version of incoming frame 845, it has and on each Spatial Dimension, is reduced into 1/2 size.Usually, filter 810 and 830 uses same 1-D low pass filter.In a particular embodiment; The operation of just described down-sampling is used for producing through following manner the version of the source frame of video except the version of source frame of video with highest resolution: the highest resolution version with the source frame of video begins; And the separable filtering of two dimension (2-D) through carrying out cascade recursively produces the source frame of video of each inferior low resolution with the down-sampling operation from current version, and separable filtering of the two dimension of cascade (2-D) and down-sampling are manipulated the low pass filter of the one dimension that is associated with each version.In a particular embodiment, as described in the version of on October 20th, 2006 or named file before, each low pass filter can be one of following: be used for the MPEG-2 decimation filter of the separable filtering of 2-D, it has filter coefficient (29; 0,88,138; 88,0 ,-29)/256; And, the MPEG-4 decimation filter, it has filter coefficient (2,0 ,-4 ,-3,5,19,26,19,5 ,-3 ,-4,0,2)/64.In specific alternate embodiment, each low pass filter is the low pass filter that has by the Subband Analysis Filter group of the value of the further convergent-divergent filter coefficient of scale factor.In these embodiment, the low pass filter that is used to produce the lowest resolution version of frame of video can be different between each layer, and can directly carry out from the highest resolution version of frame of video.The down-sampler design that is characterized as of this uniqueness provides flexibility to set up the best low-definition version of frame of video.
Referring to Fig. 8, block diagram illustration according to the Subband Analysis Filter group 631 (Fig. 5) of separable couple of embodiment of specific 2-D.Input video frame is carried out the down-sampling operation along vertical direction subsequently at first respectively by low pass filter and high pass filter, processes, produces M signal 910.M signal 910 carries out the down-sampling operation along horizontal direction subsequently then respectively by low pass filter and high pass filter, processes, and generation is used in four subbands of the version of the frame of video of specified resolution (LL 921, and HL 922, LH 923 and HH 924).This processing is commonly called small echo/sub-band division.The subband synthesis filter group is the image release of the Subband Analysis Filter group of correspondence.The filter that in Substrip analysis/synthetic filtering device group, uses can belong to the family of wavelet filter or the family of QMF filter.For system, be used to represent that every group of subband of current stage resolution ratio can be synthesized to form the LL subband of next high-resolution level with a plurality of stage resolution ratios.Fig. 9 illustrates this aspect, and wherein, with the subband of suffix-1 indication highest resolution layer, and wherein, basis or lowermost layer are LL-2.H and W partly represent the height and the width of full resolution frame of video.
Referring to Figure 10, flow chart 1100 show at least in part based on top description with reference to figure 3-9, according to some steps of the gradable spatial video coding method that is used for the pressure source frame of video of specific embodiment.Method 1100 is concluded the frame of video that is used to use any amount of frame of video version, and wherein, each version has unique resolution.In step 1105, the version of reception sources frame of video, wherein, each version has unique resolution.In step 1110, produce base layer bit stream through the version that uses the Base layer encoder coding to have the source frame of video of lowest resolution.Produce one group of enhancement layer bit-stream in step 1115, wherein, one of the correspondence of each enhancement layer bit-stream in the group through the version of coding source frame of video produces.In group, an enhancement layer bit-stream possibly only arranged.For each version of source frame of video, coding comprises: one the subband of correspondence that 1) of the correspondence of the version of source frame of video is decomposed into the version of source frame of video through the Subband Analysis Filter group is represented; 2) prediction signal between cambium layer, it is the expression in the recovery source of inferior low resolution frame of video; And, 3) represent to produce enhancement layer bit-stream through using the interlayer frame texture encoder subband of encoding, interlayer frame texture encoder is used the inter-layer prediction signal.In step 1120, use bit stream multiplexer to form gradable bit streams with base layer bit stream and one group of enhancement layer bit-stream.
Referring to Figure 11, flow chart 1200 show at least in part based on top description with reference to figure 3-9, according to specific embodiment to be used for the encoded video frame decompress(ion) be some steps of the gradable spatial video encoding/decoding method of decoded video frames.In step 1205, use bit stream demultiplexer to extract base layer bit stream and one group of enhancement layer bit-stream.In step 1210, use the basal layer decoder to recover the lowest resolution version of decoded video frames from base layer bit stream.In step 1215, recover the subband of one group of decoding and represent.The subband of each decoding in the group representes that through the correspondence of the one group of enhancement layer bit-stream of decoding recovers.For each enhancement layer bit-stream, decoding comprises: 1) prediction signal between cambium layer, and it is the expression in the decoded video frames of the recovery of inferior low resolution; And, 2) recover subband through the interlayer frame texture decoder device decoding enhancement layer that uses the inter-layer prediction signal and represent.Use the subband synthesis filter group to represent synthetic decoded video frames with the lowest resolution version of decoded video frames and the subband of one group of decoding.In step 1225, can carry out decoded frame according to the pixel value scope of representing for pixel to adopt and cut out operation.
Though be appreciated that according to the Code And Decode frame of video and described method 1100 and 1200, identical method is applicable to that Code And Decode is not the image of a video sequence part.
Base layer videos 603 in the gradable spatial coded system 600 that is proposed can be by traditional individual layer intraframe video coding device coding, and wherein, each frame of video is by frame texture encoder coding in traditional layer.Referring to Figure 12, the block diagram according to frame texture encoder 1300 in the layer of specific embodiment is shown.Frame texture encoder 1300 is can be as the example of frame texture encoder 610 (Fig. 5) in the layer in the gradable spatial coded system 600 (Fig. 5) in the layer.Frame texture encoder 1300 comprises the traditional function piece in the layer; They are intercoupled in a conventional manner; And frame texture encoder 1300 uses conventional block transcriber 1310 to carry out the macroblock coding of input signal 1305 especially in the layer, to produce output signal 1315 and inter-layer prediction signal 1320.When input signal was the lowest resolution version of source frame of video, just as such in the embodiment of Fig. 5, the output signal was the base layer bit stream of coding.
Referring to Figure 13, the block diagram according to frame texture decoder device 1400 in the layer of specific embodiment is shown.Frame texture decoder device 1400 is can be as the example of frame texture decoder device 725 (Fig. 6) in the layer in the gradable spatial decode system 700 (Fig. 6) in the layer.Frame texture decoder device 1400 comprises the traditional function piece in the layer; They are intercoupled in a conventional manner; And frame texture decoder device 1400 uses conventional block switch decoders 1410 to carry out the macro block decoding of input signal 1405 especially in the layer, to produce output signal 1415.
Is the characteristic of expectation from the base layer bit stream of graduated encoding system with non-gradable bit streams compatibility from the conventional monolayers coded system.In a particular embodiment, in the layer frame texture decoder device 1400 be standard version MPEG-1, MPEG-2, MPEG-4, H.261, H.263, MPEG-4AVC/H.264 and JPEG (as on October 20th, 2006 or announce before) in the intraframe decoder device of description.
In document, appeared and be used to compress the whole bag of tricks by the sub-band/wavelet coefficient of converted image.For example, the algorithm based on zero tree is used by MPEG-4 small echo visual texture coding (VTC) instrument (as on October 20th, 2006 or announcement before).JPEG2000 adopts EBCOT algorithm (on October 20th, 2006 or the version announced before), and it is the how logical content-adaptive encoding scheme of the wavelet coefficient bit plane that is used to encode independent.A uniqueness of our specific embodiment and useful aspect are to use effective realization of the sub-band/wavelet graduated encoding system that the conventional video instrument is used for being proposed effectively.Particularly, in these embodiment, the DCT macroblock coding instrument of the pixel sampling in the current video encoding standard that is designed to the to encode sub-band/wavelet coefficient that is used to encode.By this way, can reuse graduated encoding technology through the maximum of existing video frequency tool so that implemented with low cost was proposed.
Referring to Figure 14, show according to specific embodiment the block diagram of interlayer frame texture encoder 1500.Interlayer frame texture encoder 1500 is the examples that can be used at traditional gradable video encoding system encoding enhancement layer frame.It is used as the interlayer frame texture encoder 633 (Fig. 5) of frame gradable spatial coded system 600 (Fig. 5), that be used for the encoding enhancement layer sub-band division that is proposed.Interlayer frame texture encoder 1500 comprises the conventional block transcriber 1510 of traditional function piece-particularly---be used to carry out the macroblock coding of input signal 1505, to produce output signal 1515.Input signal 1505 normally has the subband of version of the source frame of the resolution except lowest resolution and representes that for example the subband of the full resolution signal 601 in gradable spatial coded system 600 representes 632.Subband is represented to be divided in regular turn a plurality of subbands that are used for non overlapping blocks and is represented, also comprises through the encode piece subband of each non overlapping blocks of interlayer frame texture encoder representing.Piece can be commonly referred to as those pieces of macro block.Output signal 1515 is enhancement layer bit-stream, and it comprises that subband representes the predicated error of 632 and 1505 block encoding.Can form the predicated error of block encoding through following manner: block encoding representes and poor with the prediction signal 1520 that to serve as the basis select from inter-layer prediction device 1525 and one of spatial predictors 1530 of piece one by one at the subband of the input 1505 of interlayer frame texture encoder 1500, and using frame buffer 1535 storages is the frame of rebuilding during the encoding process on basis with the piece.Be designated as the type of the prediction signal of each piece selection through the mode identifier in the syntactic element of bit stream 1,515 1540.In the specific embodiment of these embodiment, for highest frequency sub-bands, inter-layer prediction signal 1526 is set to zero.
Referring to Figure 15, show block diagram according to the interlayer frame texture decoder device 1600 of specific embodiment.Interlayer frame texture decoder device 1600 is can be as the example of the interlayer frame texture decoder device 743 (Fig. 6) in the gradable spatial decode system 700 (Fig. 6).Interlayer frame texture decoder device 1600 comprises that traditional functions piece-particularly traditional piece switch decoders 1610-is used to carry out the macro block decoding of input signal 1605, to produce output signal 1615.Input signal 1605 is normally as above with reference to the described enhancement layer bit-stream 1515 of Figure 14.Bit stream is applied to piece switch decoders 1610, the predicated error of the piece decoding that piece switch decoders 1610 generation subbands are represented.Piece can be commonly referred to as those pieces of macro block.The pattern indication 1640 that use obtains from the syntactic element of bit stream, it serves as that the basis produces the prediction signal 1620 that subband is represented adaptively that interlayer frame texture decoder device 1600 comes with piece one by one through inter-layer prediction device 1625 and one of spatial predictors 1630.Prediction signal is that the basis is added on the subband predicated error with the piece, and the subband of decoding of version that has the source frame of the resolution except lowest resolution with generation is represented.In the specific embodiment of these embodiment, for highest frequency sub-bands, the inter-layer prediction signal is set to zero.
In the specific embodiment of these embodiment; Interlayer frame texture decoder device 1600 is included in the enhancement layer frame inner demoder of describing in one of modification 3 (gradable video expansion) standard of MPEG-2, MPEG-4, version 2 H.263 and MPEG-4 the 10th part A VC/H.264, but in intra encoder, does not cut out operation for what decoded signal was carried out.In the specific embodiment of these embodiment, the modification 3 of one group of enhancement layer bit-stream and MPEG-4 the 10th part A VC/H.264 standard (gradable video expansion) compatibility.
Referring to Figure 16, block diagram show according to specific embodiment the block diagram of another interlayer frame texture encoder 1700.Compare with interlayer frame texture encoder 1500, the interior frame texture encoder 1300 (Figure 12) of layer that can be used for the application of conventional video coding more widely is used to set up interlayer frame texture encoder.In these embodiment, in the layer frame texture encoder 1300 coding as represent at subband 1705 and inter-layer prediction signal 1720 between residue (predicated error) signal 1725 of difference, to produce output bit flow 1715.
Referring to Figure 17, block diagram shows the interlayer frame texture decoder device 1800 according to specific embodiment.Interlayer frame texture decoder device 1800 the has had mirror image framework of interlayer frame texture encoder 1700.Interlayer frame texture decoder device 1800 comprises a layer interior texture decoder device 1400 (Figure 13), and it produces residual signals 1825 (predicated error) from enhancement layer 1805, and subband representes that 1815 produce through inter-layer prediction signal 1820 is increased to residual signal 1825.
In a particular embodiment, enhancement layer bit-stream comprises syntactic element, and syntactic element is used to indicate the quantity of the sub-band division grade that is used to represent enhancement layer video frames.By this way, can optimize the quantity of subband grade individually, to obtain best coding efficiency for each enhancement layer.
Referring to Figure 18, this figure uses the expression of encoding layer to illustrate the relation according to frame of video specific embodiment, for the example of the frame of video of using three gradable spatial layer n=0, n=1 and n=2 coding of the embodiment that is proposed.When normalized subband lowpass analysis filter being used image down sampling that acts on basal layer and the low pass filter 800 (Fig. 7) that is used as the analysis filter in the analysis filterbank 900; The zoom version of output signal (Fig. 8 921 with Fig. 7 846) substantially the same, and low pass residual signal 1506 (Figure 14) is reduced into quantization error.Then; If from the average scaled distortion of ensuing more low layer (two low layers in the example of Figure 18) near or less than being used in the institute's allocation bit rate of current enhancement layer or the best level of distortion of quantization parameter, then we can omit the texture coding of the residual signal on the low pass subband area L L 310,315 in Figure 18 simply.Therefore, the threshold sampling characteristic that keeps the sub-band/wavelet coding is to realize the best compression efficiency and the complexity overhead of reduction.However; Unlike traditional sub-band/wavelet image encoding system; Graduated encoding embodiment in the frame that is proposed; Be similar to the pyramid coding, still have the freedom that is used for being used for generation expectation source intended application, that reduced resolution video at the best downsampling filter of encoder design.Resultantly between the base layer frame 921 (Fig. 8) of original low pass subband signal 846 (Fig. 8) and convergent-divergent differ from low pass subband residual signal 310,315 (Figure 18) compensation that 1506 (Figure 14) can be encoded.
Can Figure 18 be compared with Fig. 1 and 2, with the difference between the code signal of observing the graduated encoding means use of encoding by pyramid coding, sub-band/wavelet respectively and being proposed.Figure 18 illustrates and can compensate poor between the base layer frame of original low pass subband signal and convergent-divergent through the low pass subband residual signal of coding.In the embodiment that is proposed, as shown in the dashed region among the said figure, the residue of low pass subband coding only is available.The residue coding of low pass subband can be used for further reducing from the quantization error of lower level feedback.The residue of low pass subband coding can be used for compensation poor between the base layer frame 921 (Fig. 8) of original low pass subband signal 846 (Fig. 8) and convergent-divergent, this difference be by at the downsampling filter of the low resolution version of generation source frame and the difference that produces between the lowpass analysis filter that the subband of current enhancement layer representes cause.
In certain embodiments; Produce the version of the source frame of video except the version of source frame of video with highest resolution through following manner: the highest resolution version with the source frame of video begins; And recursively produce the source frame of video of each inferior low resolution with the down-sampling operation and from current version through the separable filtering of two dimension (2-D) of carrying out cascade; Wherein, The low pass filter of one dimension is associated with each version; And at least one downsampling filter is different with the low pass filter of Subband Analysis Filter group, and the subband of the resolution version of the source frame of the next resolution that the low pass filter generation of Subband Analysis Filter group is higher than lowest resolution is represented.In these embodiment, as stated, can use the residue coding of low pass subband, with compensation poor between the base layer frame 921 (Fig. 8) of original low pass subband signal 846 (Fig. 7) and convergent-divergent.
Used JVT JSVM reference software version JSVM 6_8_1 to come to realize fully as above ad hoc approach with reference to the described method of figure 3-18.The interior encoded test condition that is limited the JVT core of the inter-layer texture prediction that is used for spatial scalability experiment (CE) is used to assess the algorithm that is proposed.Coding four cycle tests buses (BUS), rugby (FOOTBALL), foreman (FOREMAN) and mobile thing (MOBILE) in a plurality of bases and enhancement layer QP (quantization parameter) combination.The CE telegon uses reference software JSVM 6_3 that CE benchmark result is provided.
For among Figure 19 by the test result shown in the JVT-Uxxx, the Daub.9/7 filter is used for the wavelet analysis of higher level frame/synthetic (the identical floating-point wavelet filter that is adopted by JPEG 2000).Encoder uses same low pass filter to be used for the interior frame of two down-sampling inputs.Omit the coding of whole low pass subband.Each curve segmentation has shown the result by the same foundation QP enhancing QP value coding different with four.On the implication of the rate distortion of given basal layer QP, second test point in each segmentation by chance corresponding to best basis with strengthen the QP combination.Can find out that put when not far when enhance encoding rate and optimal operations, the algorithm that is proposed surpasses relevant JSVM result widely.
In order to be created in the test result among Figure 20, with the identical bank of filters setting of use in previous experiments, still, low pass subband is encoded to refine further and to proofread and correct low-pass signal.Can find out that the method that is proposed provides level and smooth rate-distortion curve, and always surpass relevant JSVM result.The most important thing is that resultant enhance encoding performance changes little with basic QP value, this forms sharp contrast with corresponding JSVM result.
For the test result in Figure 21, the AVC low pass filter is used to produce low-resolution video, and does not omit the coding of lower passband image-region.Can find out that the result almost JSVM result with relevant is the same good.Because the AVC downsampling filter has very different frequency response characteristics with the low pass subband filter, be considered to rational with respect to the degradation of the correlated results among Fig. 5.
B. the quality graduated encoding with the combination graduated encoding
Front sub-band/wavelet intraframe video coding framework that specify, that proposed can be further expanded is used for quality/bit rate gradable video encoding application.The quality gradable bit streams of being made up of a base layer bit stream and one or more enhancement layer bit-stream is particularly useful for the different coding bit rate and on the heterogeneous networked environment, Video service is provided.The coding bit rate of compressed video signal can be through abandoning quality enhancement layer bit rate unit or grouping and be adapted to the restriction of transmission bandwidth neatly.
In one embodiment; Mass of foundation layer in the quality graduated encoding system that is proposed also comprises a plurality of resolution scalable layer, and its expression is according to the input video frame of the sub-band/wavelet conversion of gradable spatial coding method that describe, that proposed in the A part.By this way, when the resolution that reduces keeps the compatibility of basal layer and traditional non-graduated encoding, can be in subband be represented the basis of coding quality layers.Independent quality enhancement layer also can be represented by subband/wavelet coefficient, and can be encoded by frame texture encoder between aforesaid tradition stratum.Wherein, represent prediction signal between cambium layer from the subband of the rough coding of inferior low quality layer.
In Figure 22, further illustrate according to specific embodiment, be used for this method at the graduated encoding of two grades of three quality layers and sub-band division.As shown in, the mass of foundation layer comprises three resolution scalable layer, each is used to represent to come the sub-band coefficients of the same resolution-scale of comfortable rough credit rating.Each quality strengthens also uses thinner quantization step to encode from the encoding error of previous layer the incremental refinement of the subband of feasible rough coding.By this way, according to the quantity of the enhancement layer that comprises at last in the bit stream that in the end receives, can recover the video of coding with three different credit ratings from single gradable bit streams.
Referring to Figure 23, block diagram shows basis in the exemplary embodiment layering graduated encoding structure shown in Figure 22, quality graduated encoding system 2300.Usually, whole system is made up of a mass of foundation layer and two quality enhancement layer, is used for the quality gradable bit streams in the decoding of three different video credit ratings with foundation.The mass of foundation layer also comprises three resolution scalable layer, and is encoded through the gradable spatial coding method, shown in prior figures 5 in two-layer.Input video frame is at first handled by 2-D down-sampler 2305; On each Spatial Dimension, to produce the version of input video frame with the resolution that reduces; And the low-resolution frames of output is further by the 2-D down-sampling, to produce the lowest resolution version 2303 of input video frame.Lowest resolution version 2303 is comprised the Base layer encoder processing of layer interior frame texture encoder 2310.Frame texture encoder 2310 produces as being coupled to the base layer bit stream 2315 of the output of multiplexer 2320 in the layer.At each enhancement layer 2330 (shown in dashed boxes), Subband Analysis Filter group 2331 obtains the related versions of input video frame, and produces subband (small echo) coefficient.Interlayer frame texture encoder 2333 uses the information 2335 of comfortable anterior layer to remove interlayer redundancy, and produces the enhancement layer bit-stream 2338 as output, and the input subband that is used for presentation code representes 2332.Enhancement layer bit-stream 2338 also is coupled to multiplexer 2320.Multiplexer 2320 multiplexing base layer bit stream 2315 and enhancement layer bit-stream 2338, to produce gradable bit streams 2340, gradable bit streams 2340 transmits the needed coded message of video that is used at different resolution and credit rating recovery coding.Can understand, in having the embodiment of more enhancement layers, can use same enhancement layer coding method.Promptly; The Subband Analysis Filter group of each enhancement layer encoder is used to produce the subband of the specified resolution version of source frame of video and representes, and uses the sub-band coefficients of being come the expression that coding result produces by the information that provides at anterior layer at each enhancement layer by interlayer texture frame encoder.In the use of the embodiment shown in Figure 23 and at the similar parts of the parts shown in Fig. 5, but it is particularly suitable for application of quality graduated encoding and combination graduated encoding.The operation of these system units has been described in the A part.
Referring to Figure 24, flow chart 2400 show at least in part based on reference to the foregoing description of Figure 22 and 23, according to some steps of the quality gradable video encoding method that is used for the pressure source frame of video of specific embodiment.In step 2405, produce the minimum quality grade of appointment or the mass of foundation layer bit stream of coding bit rate through the coding source frame of video.In step 2410, produce one group of enhancement layer bit-stream of one group of cumulative credit rating or coding bit rate through the coding source frame of video.In group, an enhancement layer bit-stream possibly only arranged.For each enhancing, coding comprises: 1) through the Subband Analysis Filter group subband that the source frame of video is decomposed into the source frame of video is represented; 2) prediction signal between cambium layer, it is the expression of the recovery frame of video of time low quality layer; And, 3) through representing to produce enhancement layer bit-stream by interlayer frame texture encoder coding subband, this interlayer frame texture encoder also uses the inter-layer prediction signal to remove interlayer redundancy.In step 2415, use bit stream multiplexer to form gradable bit streams with base layer bit stream and one group of enhancement layer bit-stream.
Referring to Figure 25, flow chart 2500 show at least in part based on reference to the foregoing description of Figure 22 and 23, according to some steps of the quality scalable video coding/decoding method that is used for the decompress(ion) encoded video frame of specific embodiment.In step 2505, use the bit stream analysis device to extract the grouping that comprises the code coefficient relevant from gradable bit streams with desired resolution and/or credit rating.In step 2510, from the mass of foundation version of the packet recovery decoded video frames of the mass of foundation layer bit stream that extracted.In step 2515, recover the subband of one group of decoding of cumulative credit rating and represent, wherein, each subband of decoding that one grouping of the correspondence of one group of enhancement layer bit-stream being extracted through decoding recovers in this group is represented.For each enhancement layer bit-stream, decoding comprises: 1) prediction signal between cambium layer, and it is the expression of the recovery frame of video of time low quality layer; And, 2) grouping through the corresponding enhancement layer that extracted by interlayer frame texture decoder device decoding recovers subband and representes that this interlayer frame texture decoder device also uses the inter-layer prediction signal to remove interlayer redundancy.In step 2520, use the subband synthesis filter group to represent synthetic decoded video frames from subband in the decoding of last enhancement layer.In step 2525, can come to carry out according to the pixel value scope that pixel is represented to be adopted and cut out operation for the frame of decoding.
Because the quality enhancement layer of being represented by illustrated subband in Figure 22 is that resolution is gradable inherently, preceding method can also be applied to the combination graduated encoding.In this case, the sub-band/wavelet coefficient can also divide into groups according to sub-band division or resolution-scale, is encoded as independent bit stream groupings then.For example, in based on the preferred embodiment that H.264/AVC coding tools is set up, the subband macro block can be divided through sheet group mapping (slice group map), and it meets the sub-band division structure, and is represented by independent NAL unit.By this way, can be easily extract the coding subband of the given resolution level that helps to be concerned about, and resultant quality gradable bit streams still is that resolution is gradable from relevant NAL unit.We can not provide other spatial scalability with almost having performance loss; Therefore can come to select to realize gradable decoding at a plurality of different bit streams and resolution effectively through single gradable bit streams; The interior frame video coding system of this and traditional DPCM based on layering forms sharp contrast, and the interior frame video coding system of traditional DPCM based on layering only can provide different gradable decoded bits rate/resolution of smallest number to select usually.
More detailed, in the embodiment that sets up based on the MPEG-4AVC/H.264 coding tools, the sub-band/wavelet coded system that is proposed can be provided with operation at typical small echo threshold sampling.Therefore resultant system has the sum of the sampling of handling/encoding with identical being used to of quantity of source sampling, and carries out just as traditional single layer encoder is such, and has no compression and complexity overhead.Noteworthy also have, and when selecting inter-layer prediction mode I_BL uniquely for each macro block in sub-band zone, in fact is coded in the subband in such system through transform coding.This is because the I_BL macroblock coding is only carried out the refining of sampling of coding, does not carry out spatial prediction and do not relate to from adjacent coded sample.Therefore can select through transform coding means coding except all subbands the low-limit frequency subband of the compatible basal layer of MPEG-4AVC/AVC.By this way; Come to work through reusing existing MPEG-4AVC/H.264 coding tools with the Methods of Subband Filter Banks that increases; Can new inner frame coding method be provided to the MPEG-4AVC/H.264 standard; This method has the other spatial scalability and the benefit of other expectations mainly based on the transform coding example that substitutes, and is of value to gradable and traditional individual layer intraframe coding application.In addition, this new intra coding method does not cause the cost of traditional gradable spatial coding, and not with current MPEG-4AVC/H.264 frame in the hybrid coding drift, error code diffusion and the complex patterns that are associated select to handle.
In the quality graduated encoding system 2300 that in Figure 23, specializes; In its simplest form; It can comprise: the mass of foundation layer coder is used for producing the minimum quality grade of appointment or the mass of foundation layer bit stream of coding bit rate through the coding source frame of video; Enhancement layer encoder; Be used to produce one group of enhancement layer bit-stream of one group of cumulative credit rating or coding bit rate; Enhancement layer encoder comprises Subband Analysis Filter group and interlayer frame texture encoder; The Subband Analysis Filter group is used for by the Subband Analysis Filter group subband that the source frame of video is decomposed into the source frame of video being represented, interlayer frame texture encoder is used for through using the inter-layer prediction signal subband of encoding to represent to produce enhancement layer bit-stream, and interlayer frame texture encoder also comprises the inter-layer prediction device; Be used to form the inter-layer prediction signal, the inter-layer prediction signal is the expression of the recovery frame of video of time low quality layer; And bit stream multiplexer is used for forming gradable bit streams with mass of foundation layer bit stream and enhancement layer bit-stream.System 2300 is particularly suitable for providing effectively quality scalability and combination gradability.
Said method can be used for compressed image and frame of video etc.
In one arrangement, the filter in the Subband Analysis Filter group belongs to one of wavelet filter family and quadrature mirror filter (QMF) family.This provides the effective bank of filters that is used for the image/video compression applications.
In another embodiment, interlayer frame texture encoder comprises the piece transcriber.For example; In an embodiment; Can in regular turn subband be represented to be divided into a plurality of subbands that are used for non overlapping blocks representes; Also comprise by the piece subband of each non-overlapped piece of interlayer frame texture encoder coding and representing, and the encoding block subband is represented also to comprise: form the spatial prediction signal from the adjacent sub-bands coefficient that recovers; Between inter-layer prediction signal and spatial prediction signal, select prediction signal for each block adaptive ground; And, by conversion block encoder encodes predictive error signal, predictive error signal be the piece subband for each piece represent and selected prediction signal between poor.In this layout, this can allow for example in the quality graduated encoding is used, to use traditional video blocks coding tools to be used to compress sub-band coefficients.
In one embodiment, interlayer frame texture encoder is included in the enhancement layer frame inner encoder for definition in the scalable video expansion of MPEG-4 the 10th part A VC/H.264 standard, and for all macro blocks, is I_BL with Macroblock Mode Selection.Useful is that this embodiment and MPEG-4 the 10th part A VC/H.264 are compatible.In specific alternate embodiment, said method can also be applied to other the gradable video encoding standards early based on traditional layering DPCM DCT framework, for example MPEG-2,4 and version 2 H.263.Should be understood that said method also can have the application outside this specific criteria.Therefore, in one embodiment, need minimum modification or need not revise next and operating such.
In one arrangement, interlayer frame texture encoder comprises a layer interior frame texture encoder, frame texture encoder coding residual signal in the layer, residual signal be subband represent and the inter-layer prediction signal between poor.In this layout, like common commercialization, this embodiment can the single layer coding scheme realize.
In one embodiment, enhancement layer bit-stream comprises syntactic element, and therefore the quantity of the decomposition levels of each enhancement layer of syntactic element indication, can optimize the quantity of subband grade for each enhancement layer frame individually, to obtain best coding efficiency.
In one embodiment, each quality layer bitstreams also comprises one or more resolution scalable layer.Useful is that this can provide alternative bit stream arrangement, to be used for being coded in the useful quality scalable layer of application-specific.More detailed, the quality bit stream can be corresponding to the low-resolution layer of mass of foundation layer, and can with MPEG-1, MPEG-2, MPEG-4 and H.264/AVC one of standard is compatible substantially.
Also in one embodiment; Sheet group mapping according to definition in H.264/AVC comes the piece of further grouping sub-band coefficients; Sheet group mapping also meets sub-band division or the resolution-scale that subband is represented, and on the same group coefficient is not encoded into different bit stream groupings.This embodiment can be of value to the application in various standards.
As shown in Figure 25; One mass scalable video coding/decoding method; Be used for the encoded video frame decompress(ion) is condensed to decoded video frames, said method comprises: use the bit stream analysis device to extract and desired resolution and/or the relevant grouping of credit rating from gradable bit streams; Mass of foundation version from the packet recovery decoded video frames of the mass of foundation layer bit stream that extracted; Recovering the subband of one group of decoding of cumulative credit rating representes; Wherein, One grouping of the correspondence of the enhancement layer bit-stream of this group of being extracted through decoding recovers the subband of each decoding in this group and representes; Recover the subband of one group of decoding of cumulative credit rating and represent to comprise, form inter-layer prediction signal, and recover subband through interlayer frame texture decoder device decoding enhancement layer and represent as the expression of the frame of video of the recovery of time low quality layer for each enhancement layer bit-stream; Wherein, interlayer frame texture decoder device uses the inter-layer prediction signal to remove interlayer redundancy; Use the subband synthesis filter group from representing synthetic decoded video frames from the subband of decoding at last enhancement layer; And, operation is cut out in synthetic frame of video execution according to the pixel value scope.This method has use value in relevant standard.
In one embodiment; Said method can also comprise the bit stream analysis device, and it accepts the gradable bit streams as input, and produces output bit flow through the grouping of the irrelevant high-frequency sub-band of removal and the desired resolution of decoded video; Wherein, The input gradable bit streams comprises grouping, divides into groups to be used for representing the coding sub-band coefficients according to shine upon (slicedgroup map) marshalling in the burst group of H.264/AVC definition, and it also meets sub-band division or resolution-scale that subband is represented.This method has the application in relevant criterion, and has off-gauge application.
Bit stream analysis device according to specific embodiment is accepted the gradable bit streams as input; And the grouping through removing the high-frequency sub-band that has nothing to do with the desired resolution of decoded video produces output bit flow; Wherein, The input gradable bit streams comprises grouping, divides into groups to be used for representing the coding sub-band coefficients according to shine upon marshalling in the burst group of H.264/AVC definition, and it also meets sub-band division or resolution-scale that subband is represented.
Turn to now at the simulation result shown in Figure 26 and 27, realized above-mentioned ad hoc approach fully with reference to figure 22-25 based on SVC reference software JSVM version 9 (CVS label J SVM_8_9).CDF (Daubechies) 9/7 composite filter group is adopted the subband of composite coding to represent by the decoder that is proposed.Use the I_BL macro block mode to come to be coded in uniquely all subbands of enhancement layer.Coding experiment through a large amount of comes with respect to the JSVM software of original JSVM software evaluation based on the modification of the algorithm that is proposed.The cycle tests city, source (CITY) of 4CIF resolution, crowd (CREW), harbour (HARBOR) and Association football (SOCCER) are used and are used for emulation.Each cycle tests comprises 150 frames, and with 15 frames of per second (fps) by interior coding.Configuration file and encoder option identical is provided for producing the result of the JSVM of original JSVM and modification.In addition; We also use same JSVM software that the correlated results of single layer coding is provided; Wherein encoder option " FRExt " is enabled (in the 8x8 fallout predictor collection conversion is enabled with 8x8DCT), corresponding to the high standard of usage ratio transformation matrix not H.264/AVC in frame encode.
Figure 26 compares the JSVM-SBC that is proposed with the PSNR result for the SNR graduated encoding 4CIF sequence in four layers with reference to JSVM.Use CABAC entropy coding pattern to produce the result of JSVM-SBC and JSVM, wherein, enable encoder option " FRExt " for all layers.At each CGS layer quantization conversion coefficient, and from layer 0 to 3, the QP value is set to equal respectively 42,36,30 and 24 through fixing QP.In order further to compare with traditional non-graduated encoding, we also provide the correlated results of JSVM single layer coding, use " JSVM individual layer " indication in the accompanying drawings.As shown in Figure 26, for all test results, surpass original JSVM based on the algorithm that is proposed of transform coding means, and the improvement degree is along with number of layers improves.For coded sequence harbour and Association football, the PSNR result of the JSVM-SBC that is proposed is in fact very near corresponding individual layer result.
Figure 27 also use CABAC with the algorithm that is proposed with reference to JSVM for the coding rate performance of the CGS in four layers coding; Wherein, on the Windows mobile workstation of the RAM of IntelPentium M processor with 2.0GHz and 1.0GB, measure the scramble time.As shown in, relate to inner estimation mode judgement complex process the JSVM encoder than the subband coder that is proposed slowly many.Should be noted that this experiment only is intended to explain the speed advantage of the algorithm that is proposed.Not to the same JSVM basis of software optimal speed performance of the realization that is used for two kinds of methods.
Can understand; Said embodiments of the invention can be made up of one or more conventional processors and independent program stored instruction; Independent one or more processors of program stored commands for controlling, with specific non-processor circuit be implemented in combination these described embodiments of the invention some, great majority or repertoire.Therefore, these functions can be interpreted as the step of the method that is used to carry out video compression and decompression.Alternately; Can pass through state machine or in one or more application-specific integrated circuit (ASIC)s (ASIC), realize some or repertoire; Wherein state machine does not have the program stored instruction, and in one or more ASIC, some combinations of each function or particular functionality are implemented as customized logic.Certainly, can use the combination of these means.Therefore, the method and the parts of these functions have been described at this.Under those situation of the function that can use processor and institute's program stored to instruct to realize embodiments of the invention; Can understand; Be used to realize that a kind of means of such function are the media of storage institute program stored instruction, this medium is magnetic memory or the signal that transmits file.And; The expectation those of ordinary skill; Though possibly carry out the remarkable effort and the many design alternatives that for example drive by up duration, current techniques and economic consideration; But when by thought disclosed herein or principle guiding, can come easily to produce such software instruction and program and IC with minimum experiment.
In aforementioned specification, specific embodiment has been described.But those of ordinary skills understand, under the situation of the scope of the present invention that in the claim that does not depart from below, proposes, can carry out various modifications and change.Therefore, specification and accompanying drawing should be counted as illustrative rather than determinate implication, and all such modifications are intended to be included in the scope of the present invention.Benefit, advantage or for the solution of problem or can be so that any benefit, advantage or take place or characteristic key, needed or necessary or the element of become more outstanding any (a plurality of) element and be not appreciated that any or whole claims for the solution of problem.The present invention is limited by accompanying claims uniquely, and accompanying claims is included in all equivalents of any modification carried out during the application's the pending trial and those claims of being sent.
Provide summary of the present disclosure promptly to confirm the disclosed characteristic of present technique to allow the reader.Can understand that it is not used in scope or the implication of explaining or limiting claim.In addition, in aforementioned detailed description, can find out, in each embodiment, each characteristic is grouped in together, so that the disclosure is smooth.This open method is not interpreted as the following intention of reflection: embodiment required for protection need be than the more characteristic of the characteristic of in each claim, enumerating clearly.But, that kind of liking enclosed that claim reflected, theme of the present invention is to be less than whole characteristics of single the disclosed embodiments.Therefore, appended claim is merged in the detailed description at this, and each claim itself is as the theme that requires protection independently.