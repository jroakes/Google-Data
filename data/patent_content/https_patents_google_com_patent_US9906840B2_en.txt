US9906840B2 - System and method for obtaining information relating to video images - Google Patents
System and method for obtaining information relating to video images Download PDFInfo
- Publication number
- US9906840B2 US9906840B2 US15/284,145 US201615284145A US9906840B2 US 9906840 B2 US9906840 B2 US 9906840B2 US 201615284145 A US201615284145 A US 201615284145A US 9906840 B2 US9906840 B2 US 9906840B2
- Authority
- US
- United States
- Prior art keywords
- item
- media content
- data
- interest
- content item
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
Images
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/47—End-user applications
- H04N21/472—End-user interface for requesting content, additional data or services; End-user interface for interacting with content, e.g. for content reservation or setting reminders, for requesting event notification, for manipulating displayed content
- H04N21/4722—End-user interface for requesting content, additional data or services; End-user interface for interacting with content, e.g. for content reservation or setting reminders, for requesting event notification, for manipulating displayed content for requesting additional data associated with the content
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/70—Information retrieval; Database structures therefor; File system structures therefor of video data
- G06F16/78—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually
- G06F16/783—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using metadata automatically derived from the content
- G06F16/7837—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using metadata automatically derived from the content using objects detected or recognised in the video content
-
- G06F17/3079—
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F18/00—Pattern recognition
- G06F18/20—Analysing
- G06F18/22—Matching criteria, e.g. proximity measures
-
- G06K9/00442—
-
- G06K9/00718—
-
- G06K9/6215—
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V20/00—Scenes; Scene-specific elements
- G06V20/40—Scenes; Scene-specific elements in video content
- G06V20/41—Higher-level, semantic clustering, classification or understanding of video scenes, e.g. detection, labelling or Markovian modelling of sport events or news items
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/20—Servers specifically adapted for the distribution of content, e.g. VOD servers; Operations thereof
- H04N21/23—Processing of content or additional data; Elementary server operations; Server middleware
- H04N21/234—Processing of video elementary streams, e.g. splicing of video streams, manipulating MPEG-4 scene graphs
- H04N21/23418—Processing of video elementary streams, e.g. splicing of video streams, manipulating MPEG-4 scene graphs involving operations for analysing video streams, e.g. detecting features or characteristics
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/20—Servers specifically adapted for the distribution of content, e.g. VOD servers; Operations thereof
- H04N21/23—Processing of content or additional data; Elementary server operations; Server middleware
- H04N21/239—Interfacing the upstream path of the transmission network, e.g. prioritizing client content requests
- H04N21/2393—Interfacing the upstream path of the transmission network, e.g. prioritizing client content requests involving handling client requests
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/41—Structure of client; Structure of client peripherals
- H04N21/422—Input-only peripherals, i.e. input devices connected to specially adapted client devices, e.g. global positioning system [GPS]
- H04N21/42204—User interfaces specially adapted for controlling a client device through a remote control device; Remote control devices therefor
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/43—Processing of content or additional data, e.g. demultiplexing additional data from a digital video stream; Elementary client operations, e.g. monitoring of home network or synchronising decoder's clock; Client middleware
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/43—Processing of content or additional data, e.g. demultiplexing additional data from a digital video stream; Elementary client operations, e.g. monitoring of home network or synchronising decoder's clock; Client middleware
- H04N21/431—Generation of visual interfaces for content selection or interaction; Content or additional data rendering
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/43—Processing of content or additional data, e.g. demultiplexing additional data from a digital video stream; Elementary client operations, e.g. monitoring of home network or synchronising decoder's clock; Client middleware
- H04N21/433—Content storage operation, e.g. storage operation in response to a pause request, caching operations
- H04N21/4334—Recording operations
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/47—End-user applications
- H04N21/472—End-user interface for requesting content, additional data or services; End-user interface for interacting with content, e.g. for content reservation or setting reminders, for requesting event notification, for manipulating displayed content
- H04N21/47214—End-user interface for requesting content, additional data or services; End-user interface for interacting with content, e.g. for content reservation or setting reminders, for requesting event notification, for manipulating displayed content for content reservation or setting reminders; for requesting event notification, e.g. of sport results or stock market
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/47—End-user applications
- H04N21/472—End-user interface for requesting content, additional data or services; End-user interface for interacting with content, e.g. for content reservation or setting reminders, for requesting event notification, for manipulating displayed content
- H04N21/4722—End-user interface for requesting content, additional data or services; End-user interface for interacting with content, e.g. for content reservation or setting reminders, for requesting event notification, for manipulating displayed content for requesting additional data associated with the content
- H04N21/4725—End-user interface for requesting content, additional data or services; End-user interface for interacting with content, e.g. for content reservation or setting reminders, for requesting event notification, for manipulating displayed content for requesting additional data associated with the content using interactive regions of the image, e.g. hot spots
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/47—End-user applications
- H04N21/478—Supplemental services, e.g. displaying phone caller identification, shopping application
- H04N21/4782—Web browsing, e.g. WebTV
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/47—End-user applications
- H04N21/482—End-user interface for program selection
- H04N21/4828—End-user interface for program selection for searching program descriptors
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/47—End-user applications
- H04N21/488—Data services, e.g. news ticker
- H04N21/4882—Data services, e.g. news ticker for displaying messages, e.g. warnings, reminders
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/60—Network structure or processes for video distribution between server and client or between remote clients; Control signalling between clients, server and network components; Transmission of management data between server and client, e.g. sending from server to client commands for recording incoming content stream; Communication details between server and client
- H04N21/65—Transmission of management data between client and server
- H04N21/654—Transmission by server directed to the client
- H04N21/6543—Transmission by server directed to the client for forcing some client operations, e.g. recording
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/60—Network structure or processes for video distribution between server and client or between remote clients; Control signalling between clients, server and network components; Transmission of management data between server and client, e.g. sending from server to client commands for recording incoming content stream; Communication details between server and client
- H04N21/65—Transmission of management data between client and server
- H04N21/658—Transmission by the client directed to the server
- H04N21/6582—Data stored in the client, e.g. viewing habits, hardware capabilities, credit card number
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/80—Generation or processing of content or additional data by content creator independently of the distribution process; Content per se
- H04N21/83—Generation or processing of protective or descriptive data associated with content; Content structuring
- H04N21/84—Generation or processing of descriptive data, e.g. content descriptors
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/80—Generation or processing of content or additional data by content creator independently of the distribution process; Content per se
- H04N21/85—Assembly of content; Generation of multimedia applications
- H04N21/858—Linking data to content, e.g. by linking an URL to a video object, by creating a hotspot
- H04N21/8586—Linking data to content, e.g. by linking an URL to a video object, by creating a hotspot by using a URL
Definitions
- search engines may permit personal computers and the like to obtain different types of search results (e.g., links to web pages and images) and accommodate different data formats for queries (e.g., text queries and images captured by a cell phone camera).
- types of search results e.g., links to web pages and images
- data formats for queries e.g., text queries and images captured by a cell phone camera
- the remote device is a set top box.
- the first data comprises an identification of a second video different than the video containing the image, wherein visual characteristics of the object are visually similar to the visual characteristics of an object associated with the second video, and wherein the action comprises receiving the second video at the remote device.
- the second video is a television show and the action comprises recording the show at the remote device.
- the visual characteristics comprise the visual characteristics of a person appearing in both videos.
- the visual characteristics comprise text captured in the image
- identifying the first data comprises using character recognition to identify the characters of the text
- the first data is retrieved based on a query including the characters
- the action comprises displaying a webpage related to the object.
- the first data is used to form a query, and wherein the action is determined based on the type of a search result returned in response to the query.
- the action comprises displaying a web page when the type of search result identifies a webpage, and wherein the action comprises receiving a video when the type of search result identifies a video that is or will be accessible to the remote device.
- the means for transmitting an identification of the image comprises means for transmitting pixel data representing the image.
- the system and method may detect and recognize diverse objects in response to receiving a query in the form of an image (sometimes referred to herein as a “searched image”). For example, the system and method may use facial recognition to identify actors. The system and method may also use optical character recognition (OCR) to determine whether the colors of some of the image's individual pixels collectively have the characteristics of text, e.g., a processor may determine whether the image is displaying the name of a product or show. The system and method may further use image matching to identify products or other objects with similar shapes and colors to those captured in the image.
- OCR optical character recognition
- the template may include the extracted information of the image and a set of descriptors of all interest points in the image. Matching may be performed based on the image template, especially where the extracted information is more effective than raw image data when computing image similarity. Matching may be performed by a module having knowledge of the set of reference images (e.g., one or more training corpora). When given a searched image, the matcher retrieves and outputs reference images that are similar to the query. For each similar reference image, a match score may be provided to measure the similarity, which may be computed based on the number of matched descriptors. The matcher may also output the matched region and descriptors in both reference and searched images.
- the search results may include the reference image's metadata, which may be provided as a search result or used to obtain form a query and obtain other search results.
- the set top box may receive additional instructions that permit the device to process more image data.
- the set top box may download applications or modules that permit the set top box to detect and recognize additional objects. Downloaded applications may also include applications that perform new actions that may be sent by the server. In that regard, if the set top box receives an action that it does not recognize, it may request, receive and install an application from the server that is capable performing the action.
- systems and methods in accordance with aspects of the invention may include various types of sensors, communication devices, user interfaces, vehicle control systems, data values, data types and configurations.
- the systems and methods may be provided and received at different times (e.g., via different servers or databases) and by different entities (e.g., some values may be pre-suggested or provided from different sources).
Abstract
A system and method is provided where, in one aspect, a user signals that the user is interested in a particular image being displayed as part of a video, wherein objects in the image are detected and recognized, and wherein an action is taken based on information associated with the recognized objects. By way of example only, the actions may include recording a show (with or without a user's prior confirmation) or displaying information about a product in the image.
Description
This application is a continuation of U.S. patent application Ser. No. 14/966,955, filed Dec. 11, 2015, which is a continuation of U.S. patent application Ser. No. 13/801,843, filed Mar. 13, 2013, which are hereby incorporated by reference herein in their entireties.
Systems and methods for obtaining information relating to video images are provided.
Typical set top boxes are capable of displaying videos, such as but not limited to television shows. The videos may be obtained from various sources, such as receiving streaming video from a cable television company over a cable network, and such as downloading a video from a website for later viewing by wirelessly connecting to the Internet. Set top boxes often have relatively rudimentary search tools, such as allowing users to enter text for the purpose of finding and recording upcoming television shows.
This can be contrasted with Internet-based search engines that may permit personal computers and the like to obtain different types of search results (e.g., links to web pages and images) and accommodate different data formats for queries (e.g., text queries and images captured by a cell phone camera).
In accordance with various implementations of the disclosed subject matter, mechanisms for obtaining information relating to video images are provided.
In accordance with some implementations of the disclosed subject matter, a method is provided, the method comprising: receiving, from a remote device, image data representing an image from a video; identifying, using a processor, first data relating to an object captured in the image based on the visual characteristics of the object appearing in the image, wherein the first data comprises data that was not received from the remote device; determining, using a processor, an action to be performed by the remote device based on the first data; and transmitting, to the remote device, the action to be performed by the remote device.
In accordance with some implementations of the disclosed subject matter, a device is provided, the device comprising: a processor; a video output structured to output video to a display; a memory containing instructions executable by the processor; and a user interface; wherein the instructions comprise: providing video via the video output; receiving a request from the user interface indicating that a user is interested in an object appearing in the video; receiving an action to be taken by the device in response to the request, wherein the action is determined based on the visual characteristics of the image displayed to the user; and performing the action.
In accordance with some implementations of the disclosed subject matter, a system is provided, the system comprising: means for receiving, from a remote device, image data representing an image from a video; means for identifying first data relating to an object captured in the image based on the visual characteristics of the object appearing in the image, wherein the first data comprises data that was not received from the remote device; means for determining an action to be performed by the remote device based on the first data; and means for transmitting the action to be performed by the remote device.
In some implementations, the remote device is a set top box.
In some implementations, the first data comprises an identification of a second video different than the video containing the image, wherein visual characteristics of the object are visually similar to the visual characteristics of an object associated with the second video, and wherein the action comprises receiving the second video at the remote device.
In some implementations, the second video is a television show and the action comprises recording the show at the remote device.
In some implementations, the visual characteristics comprise the visual characteristics of a person appearing in both videos.
In some implementations, the visual characteristics comprise text captured in the image, and wherein identifying the first data comprises using character recognition to identify the characters of the text, and wherein the first data is retrieved based on a query including the characters.
In some implementations, the means for identifying the first data comprises means for identifying other images that are visually similar to the image received from the remote device, wherein the other images are associated with metadata, and wherein the first data is retrieved based on the metadata.
In some implementations, the other images comprise reference images of objects and the metadata comprises the name of the object.
In some implementations, the action comprises displaying a webpage related to the object.
In some implementations, the action comprises transmitting the URL of a webpage to be retrieved by the remote device.
In some implementations, the first data is used to form a query, and wherein the action is determined based on the type of a search result returned in response to the query.
In some implementations, the action comprises displaying a web page when the type of search result identifies a webpage, and wherein the action comprises receiving a video when the type of search result identifies a video that is or will be accessible to the remote device.
In accordance with some implementations of the disclosed subject matter, a method is provided, the method comprising: displaying a first video to a user; receiving a signal from a user interface; identifying an image contained in the first video based on the signal from the user interface; transmitting an identification of the image to a device over a network; receiving an identification of a second video based on the identification of the image; and displaying the second video.
In accordance with some implementations of the disclosed subject matter, a system is provided, the system comprising: means for displaying a first video to a user; means for receiving a signal from a user interface; means for identifying an image contained in the first video based on the signal from the user interface; means for transmitting an identification of the image to a device over a network; means for receiving an identification of a second video based on the identification of the image; and means for displaying the second video.
In some implementations, the means for transmitting an identification of the image comprises means for transmitting pixel data representing the image.
In some implementations, the second video is identified based on the image's visual similarity with other images, wherein non-image information that is associated with visually similar images is retrieved, and wherein the second video is identified based on the non-image information.
Various objects, features, and advantages of the disclosed subject matter can be more fully appreciated with reference to the following detailed description of the disclosed subject matter when considered in connection with the following drawing, in which like reference numerals identify like elements.
Mechanisms (which may include systems, methods, and media) for obtaining information relating to video images are provided.
In one aspect of the system and method, a set top box permits users to obtain more information about an image in a video they are watching. By way of example, if the user is watching a movie, the user may freeze the movie on a frame that shows an actor they find interesting and press a button to obtain more information. By way of further example, if the user is watching a commercial, the user may press a button when a picture of the product is being displayed.
In both examples, the image may be transmitted to a server and the server may execute a query based on the image data. The server may then transmit, in return, information about the image and suggest that the set top box perform a certain action based on the results of the query. Using the foregoing example of the actor, the server may send a list of upcoming shows starring the actor to the set top box (or send the actor's name for the set top box to search itself), and the set top box may record the shows in response. Using the foregoing example of the product, the server may suggest that the set top box download and display a webpage that the server selected as being of likely greatest interest to the user. In either case, the system and method may permit the set top box to perform an action of interest to the user based solely—from the user's perspective—an indication that the user sees something of interest in that particular frame of the video.
Turning to FIG. 1 , system 100 may comprise a device or collection of devices, such as but not limited to a server 110 containing a processor 120, memory 130 and other components typically present in general purpose computers, and a set top box 170 which also includes processor 180, memory 181 and other components typically present in set top boxes.
The instructions 131 may be any set of instructions to be executed directly (such as object code) or indirectly (such as scripts or collections of independent source code modules interpreted on demand) by the processor. For example, the instructions may be stored as computer code on a computer-readable medium. In that regard, the terms “instructions,” “programs” and “applications” may be used interchangeably herein. Functions, methods and routines of the instructions are explained in more detail below.
The data 135 may be retrieved, stored or modified by processor 120 in accordance with the instructions 131. For instance, although the system and method is not limited by any particular data structure, the data may be stored in computer registers, in a relational database as a table having a plurality of different fields and records, XML documents or flat files. The data may also be formatted in any computer-readable format. By further way of example only, image data may be stored as bitmaps comprised of grids of pixels that are stored in accordance with formats that are compressed or uncompressed, lossless (e.g., BMP) or lossy (e.g., JPEG), and bitmap or vector-based (e.g., SVG), as well as computer instructions for drawing graphics. The data may comprise any information sufficient to identify the relevant information, such as numbers, descriptive text, proprietary codes, references to data stored in other areas of the same memory or different memories (including other network locations) or information that is used by a function to calculate the relevant data.
The processor 120 may be any conventional processor, such as processors from Intel Corporation or Advanced Micro Devices. Alternatively, the processor may be a dedicated device such as an ASIC. Although FIG. 1 functionally illustrates the processor, memory, and other elements as being within the same block, those of ordinary skill in the art will understand that the processor and memory may actually comprise multiple processors and memories that may or may not be stored within the same physical housing. For example, rather than being stored in the same computer, processor 120 and memory 130 may be stored in separate servers or have various portions distributed among many servers.
The server 110 may be at one node of a network 195 and capable of directly and indirectly communicating with other nodes of the network such as client device 170. Network 195 and the server's communication with other devices, including computers, connected to the network may comprise and use various configurations and protocols including cellular networks (e.g., 4G LTE), other wireless networks (e.g., WiFi), the Internet, intranets, virtual private networks, local Ethernet networks, private networks using communication protocols proprietary to one or more companies, instant messaging, HTTP and SMTP, and various combinations of the foregoing. Although only a few devices are depicted in FIG. 1 , a typical system can include a large number of connected devices. Server 110 may also be structured to transmit queries to, and processing search results received from, search engine 115.
Set top box 170 may be similarly configured as described above in connection with server 110, e.g., it may include a processor 180 and memory 181. An end user 199 may communicate with set top box 170 via user interface 162, e.g., a remote control 161 that wirelessly transmits signals representing commands to the set top box. The system and method is not limited to any particular user interface.
The set top box may include a video output 165 that provides image data to be shown on an electronic display, e.g., television 160, a small LCD touch-screen, a monitor having a screen, a projector or any other electrical device that is operable to display information. In that regard, user 199 may control what is shown on television 160 by interacting with set top box 170. Set top box 170 may also include a network interface device for communicating with server 110 via network 195. In that regard, server 110 may display information to end user 199 on television 160 via network 195 and set top box 170. Set top box 170 may also include all of the components typically used in a set top box and connecting its various elements to one another.
Set top box 170 may receive video data from a video source for display to end users. For example, video source 150 may be a cable television head-end that distributes high-definition digital television video signals over local, wired cable television network 196 to set top box 170. The system and method, however, may accommodate a variety of image formats and delivery options. For instance, video source 150 may broadcast conventional analog video signals over the airwaves, which are then processed by the set top box. Source 150 may also send a sequence of bitmapped images in a proprietary format, or instructions for the rendering and animation of vector-based objects, over the same network 195 as server 110, e.g., the Internet.
The system and method may include other devices as well. By way of example only, instead of a set top box, the client device may be a cellphone, tablet or personal computer. Moreover, the components may be integrated into a television, wherein video output 165 provides the video signals to a display disposed in the same housing as the components described above in connection with set top box 170. Indeed, devices in accordance with the systems and methods described herein may comprise any device capable of processing instructions and transmitting data to and from humans, directly or indirectly, including general purpose computers.
In addition to the operations illustrated in FIGS. 4 and 5 , operations in accordance with the system and method will now be described. Various operations can be handled in a different order or simultaneously, and each operation may be composed of other operations.
Images may be sent to the set top box for display to the end user. By way of example, video source 150 may stream sequential frames of video to set top box 170 via cable television network 196. Set top box 170, in turn, may perform any necessary decryption, conversion or other decoding and output a video signal to television 160. Television 160 may then display the images of the video in sequence to end user 199.
A user may indicate that there is something of interest to the user in a particular image or sequence of images being displayed. For instance, an end user 199 may want to know more about a movie or a product in a commercial that the user is watching. The user may indicate such interest by pressing button 164 on remote control 161 or any other suitable user interface to pause the video at the of interest. The user may also rewind or fast forward until the desired portion of the video is displayed. Once television 160 displays the image of interest to the user, the user may then press the button 163 on remote control 161, which sends a signal to the set top box indicating the user's interest.
Upon receiving the user's request for more information, the system and method may perform a search based on the image then being displayed to the user. By way of example, set top box 170 may transmit, to server 110, compressed bitmapped image data that captures the video frame shown on television 160 at the time the user pressed button 163. Server 110 may provide the image data to search engine 115 as a query.
The system and method may detect and recognize diverse objects in response to receiving a query in the form of an image (sometimes referred to herein as a “searched image”). For example, the system and method may use facial recognition to identify actors. The system and method may also use optical character recognition (OCR) to determine whether the colors of some of the image's individual pixels collectively have the characteristics of text, e.g., a processor may determine whether the image is displaying the name of a product or show. The system and method may further use image matching to identify products or other objects with similar shapes and colors to those captured in the image. Just some of the diverse objects that may be detected and recognized by server 110 and search engine 115 may include actors, scenes from movies, books, DVDs, landmarks, barcodes, QR codes, logos, contact information, artwork, stores and other businesses, consumer and other products, text and buildings, as well as any other entity constituting visual indicia that may be used to obtain additional information that is not contained within the image data received from the set top box.
Image matching may be used to recognize a variety of objects. For instance, training corpora may be used where each training corpus contains a set of objects. For each object, there may be one or more images (containing the visual appearance of that object) and some metadata of the object (e.g., type, name, etc.). These images may be used as reference images 118. For each image, descriptors for image interest points may be extracted and an image template built. A descriptor may include information extracted from local pixels around an interest point, such as a point in the image having a clear definition (e.g., is mathematically well-founded), having a well-defined position in image space, having a local image structure that is rich in terms of local information contents, and that is stable under local and global perturbations in the image domain. The template may include the extracted information of the image and a set of descriptors of all interest points in the image. Matching may be performed based on the image template, especially where the extracted information is more effective than raw image data when computing image similarity. Matching may be performed by a module having knowledge of the set of reference images (e.g., one or more training corpora). When given a searched image, the matcher retrieves and outputs reference images that are similar to the query. For each similar reference image, a match score may be provided to measure the similarity, which may be computed based on the number of matched descriptors. The matcher may also output the matched region and descriptors in both reference and searched images. The search results may include the reference image's metadata, which may be provided as a search result or used to obtain form a query and obtain other search results.
In that regard, a processor may search and return information that is based on, but not contained within, the image data received from the remote device. For instance, server 110 may recognize that an item in the image is a product and subsequently obtain information about the product that is inherent to the item (such as its size or ingredients) or not inherent to the item (such as a popular web page describing the product). Similarly, if the queried image is matched to a reference image of an actor, then in addition or in lieu of returning the matched image, search engine 115 may also return the actor's name and use the actor's name to obtain still more search results. Thus, the image data may be used to retrieve other types of data, e.g., textual descriptions of shows, products and actors.
The results returned by the search engine may be ranked based on a variety of factors. For instance, the results may be ranked based on the similarity of the search result to the query, such as how well a returned image matches the searched image. The results may also be ranked based on information that is not specific to the query, such as the popularity of one website in the search result relative to other websites.
The results may also be filtered or ranked based on the fact that the device providing the searched image is a set top box. For instance, if the search engine extracts text from a searched image and the text corresponds with the name of a television show, the search results might include a link to the most popular website for the show, images corresponding with the show, and the date and time that the show is scheduled to be broadcast. When ranking the results, the server may factor in the type of device making the request. For example, if the name of the show is received as part of query entered in a web browser running on unknown device, the search engine may weigh web sites more heavily than images and show times, e.g., the highest ranked search result may be a link to the most popular website for the show. However, if the name of the show was derived from an image known to be provided by a set top box, the search engine may rank the next scheduled showing higher than a link to the most popular web site. Similarly, the search engine may tend to rank images of actors higher than images of unknown individuals even if the image of the unknown individual is more visually similar to the searched image than the actor. In addition or alternatively, the system and method may append search terms to the query that are particular to video entertainment. By way of example, if the system determined that the searched image contained the word “taxi” and no other text, server 110 may include the word “show” in the query, e.g., it may query “taxi show.” This can, for example, increase the chance that the top search result would refer to a show called Taxi instead of a list of taxi distributors. In that regard, the system and method permits the search engine to conduct more targeted searches when the searched image is received from a set top box instead of other devices.
The system and method may recommend actions for the set top box to take based on the search results. By way of example, if the searched image contained the name of a popular television show and the highest ranked search result is the next scheduled date and time that the show will be broadcast, server 110 may determine that the set top box should record the show the next time it is broadcast. On the other hand, if the searched image contained a picture of laundry detergent and the highest ranked search result is a product web site, the server may determine that the set top box should display the website to the user.
As noted above, one of the actions may comprise recording a show. For example, and as shown in FIG. 2 , in response to performing a query based on captured video frame 210, the highest ranked search result 210 may be a listing 211 taken from a television schedule, e.g., a television show. In response, server 110 may determine that the set top box should display information 221 such as the show's title and the date/time of its next airing. It may also recommend that the set top box perform an action 222 beyond the information to be displayed. By way of example, the server may instruct the set top box to record the show. If necessary, the server may also provide other information to the set top box to accomplish the task, such as specific recording instructions.
The information to be displayed to the user, as well as the action to be performed, may be provided to the set top box as a structured data. By way of example only, the server may transmit an XML data file 220 that includes the information to be displayed to the user in one node (e.g., its title and the date/time of its next airing in plain text) and instructions for recording the show in another node (e.g., channel, date, starting time, duration, etc.).
In response, the set top box may display the server's recommendation to the end user, e.g., the set top box may display message 231 on television 170 and await the user's instructions. If the user confirms that the show should be recorded, such as by pressing a particular button on the remote control, the set top box 170 may add the show to its schedule of recordings. Upon receiving the user's choice, the set top box may then resume displaying the video that was interrupted by the user's request for more information.
Another one of the actions may comprise providing information about a product. For example, and as shown in FIG. 3 , server 110 may have matched an object in the captured video frame 310 with a reference image of a product. After performing a query based on the product's name, the highest ranked search result 311 may have been a website related to the product. In response, the display node 322 of the display/action file 320 sent by server 110 to server 170 may include the name of the product and the reference image of the product. The action node 321 of the file may indicate that the set top box should download and display the information at the webpage, and provide the URL of the relevant page. (In one aspect, the server's provision of a URL without separately identifying a specific action may be interpreted as an instruction to download and display the information at the webpage.)
In response to receiving the display/action instructions, the set top box may display the server's recommendation to the end user, e.g., the information 331 displayed by television 170 may include the product name and picture. If the user confirms that the user would like to see the webpage, set top box 170 may (as shown in FIG. 1 ) access the webpage by directly downloading it from the applicable website 199 via network 195, or obtaining the website via server 110. Upon receiving the webpage, the set top box may then display it on television 170. In some aspects, the system and method may perform actions without waiting for user confirmation.
In that regard, the set top box may permit a user to obtain additional information about products shown on the screen without transmitting product-specific information (e.g., a UPC code or the like) to the server.
If the searched image includes an image of an actor, the system and method may take yet another action. For instance, server 110 may identify the name of an actor based on facial recognition. In response, the server may send a picture of the actor and a list of upcoming shows in which the actor will appear to the set top box for display to the user, and recommend that the set top box ask the user if he or she would like to record any of the shows.
Different types of search results and actions can be retrieved and recommended in response to a single image. By way of example, the server may detect and recognize that the frame includes both the face of an actor and the name of a movie. Based on the name of the movie, the display/action file may contain information about the movie, the start times of local theaters that are showing the movie, and a link to the website that ranked the highest in response to a query including the movie's name. Based on the actor's name, the display/action file may include a list of upcoming shows in which the actor will appear and a suggestion to record those shows. In response, the set top box may display all of the information and ask the user what the user would like to do, e.g., navigate to the movie's website, purchase tickets to the local theatre for one of the displayed start times, record one of the shows, etc.
In one aspect, the set top box may request information based not only on the user's selected image, but the images that were displayed shortly before or after the selected image. By way of example, if the set top box maintains a buffer that permits the user to rewind the video currently being displayed, the set top box may transmit the current frame as well as some of the frames in the buffer. The set top box may also transmit some subsequent frames from the video feed, e.g., the five frames before and after the paused frame. The transmission of multiple frames may permit the server to use and compare information from multiple frames to identify the object(s) in an image that are likely to be of greatest interest to the user. The transmission of multiple frames may also be conditional, e.g., a single frame is transmitted if the video was paused when the user requested more information, but multiple frames are transmitted if the video was playing when the user requested more information.
In some aspects, the set top box may identify, to the server, the searched image without transmitting the image data itself. For instance, when the user presses button 163, the set top box may send an identification of the specific frame to server 110 without sending pixel information, e.g., the set top box may transmit the time at which the frame was displayed, or the frame number, and an identification of the video (e.g., the name of the movie). Upon receiving the request, server 110 may access a copy of the video (e.g., from its own memory or by sending a request to video source 150), extract the image data associated with that frame, perform a search based on the image data, and transmit the results back to set top box 170.
As noted above, various elements of the system and method can be split between the set top box and computers in communication with the set top box. By way of example, the set top box 170 may be capable of recognizing show and movie titles without assistance of the server. Based on the resources available to set top box 170, the processor may also perform object detection and recognition of a subset of the object types that the server is capable of detecting and recognizing. For example, the processor may detect objects, extract visual characteristics relating to the objects it finds, and send those characteristics to server 110 for recognition. In that regard, the image data sent by the set top box may be more compressed and object-specific than sending the entire image.
Moreover, the set top box may receive additional instructions that permit the device to process more image data. For example, the set top box may download applications or modules that permit the set top box to detect and recognize additional objects. Downloaded applications may also include applications that perform new actions that may be sent by the server. In that regard, if the set top box receives an action that it does not recognize, it may request, receive and install an application from the server that is capable performing the action.
It will be further understood that the sample values, types and configurations of data described and shown in the figures are for the purposes of illustration only. In that regard, systems and methods in accordance with aspects of the invention may include various types of sensors, communication devices, user interfaces, vehicle control systems, data values, data types and configurations. The systems and methods may be provided and received at different times (e.g., via different servers or databases) and by different entities (e.g., some values may be pre-suggested or provided from different sources).
As these and other variations and combinations of the features discussed above can be utilized without departing from the systems and methods as defined by the claims, the foregoing description of exemplary implementations should be taken by way of illustration rather than by way of limitation of the invention as defined by the claims. It will also be understood that the provision of examples of the invention (as well as clauses phrased as “such as,” “e.g.”, “including” and the like) should not be interpreted as limiting the invention to the specific examples; rather, the examples are intended to illustrate only some of many possible aspects. Unless expressly stated to the contrary, every feature in a given implementation, alternative or example may be used in any other implementation, alternative or example herein.
Claims (24)
1. A method for presenting supplemental content, the method comprising:
receiving, using a hardware processor, a request regarding an item of interest that was presented in a media content item;
obtaining, using the hardware processor, a plurality of image data including a video frame of the media content item corresponding to a time of the received request and at least one of a preceding video frame presented before the video frame and a subsequent frame presented after the video frame;
comparing, using the hardware processor, the plurality of image data to identify the item of interest;
identifying, using the hardware processor, supplemental content that is associated with the item of interest by performing a search with a search query based on the item of interest and receiving supplemental content as search results responsive to the search query;
transmitting, using the hardware processor, a response to the request that includes the supplemental content corresponding to the item of interest identified in the media content item; and
causing, based on the transmitted response to the request, a computing device to present the supplemental content corresponding to the item of interest identified in the media content item and perform an action on the computing device in connection with the supplemental content.
2. The method of claim 1 , wherein the supplemental content includes a second media content item that is different than the media content item and wherein the method further comprises:
identifying first data relating to the item of interest based on visual characteristics of the determined item of interest, wherein the first data comprises information relating to the second media content item; and
determining a message to be displayed based on the first data and an action to be performed on the second media content item based on the first data.
3. The method of claim 2 , wherein transmitting the response further comprises transmitting structured data that comprises a first node that includes information relating to displaying the message and a second node that includes instructions for performing the action by the computing device, wherein the transmitted structured data causes the computing device to display the message relating to the second media content item and perform the action on the second media content item.
4. The method of claim 3 , wherein the action comprises displaying a webpage related to the item of interest and wherein the structured data includes a URL of the webpage.
5. The method of claim 2 , wherein the visual characteristics of the item of interest in the first media content item are similar to the visual characteristics of an object appearing in the second media content item.
6. The method of claim 2 , wherein the visual characteristics comprise text captured in the video frame of the media content item, wherein identifying the first data comprises using character recognition to identify the characters of the text, and wherein the first data is retrieved based on a query including the characters.
7. The method of claim 2 , wherein identifying the first data comprises identifying other images that are visually similar to the plurality of image data, wherein the other images are associated with metadata, and wherein the first data is retrieved based on the metadata.
8. The method of claim 2 , wherein the first data is used to form the search query that is performed on the item of interest to identify the supplemental content and wherein the action is determined based on a type of search result responsive to the search query.
9. A system for presenting supplemental content, the system comprising:
a hardware processor that:
receives a request regarding an item of interest that was presented in a media content item;
obtains a plurality of image data including a video frame of the media content item corresponding to a time of the received request and at least one of a preceding video frame presented before the video frame and a subsequent frame presented after the video frame;
compares the plurality of image data to identify the item of interest;
identifies supplemental content that is associated with the item of interest by performing a search with a search query based on the item of interest and receiving supplemental content as search results responsive to the search query;
transmits a response to the request that includes the supplemental content corresponding to the item of interest identified in the media content item; and
causes, based on the transmitted response to the request, a computing device to present the supplemental content corresponding to the item of interest identified in the media content item and perform an action on the computing device in connection with the supplemental content.
10. The system of claim 9 , wherein the supplemental content includes a second media content item that is different than the media content item and wherein the hardware processor is further configured to:
identify first data relating to the item of interest based on visual characteristics of the determined item of interest, wherein the first data comprises information relating to the second media content item; and
determine a message to be displayed based on the first data and an action to be performed on the second media content item based on the first data.
11. The system of claim 10 , wherein the hardware processor is further configured to transmit the response further comprises transmitting structured data that comprises a first node that includes information relating to displaying the message and a second node that includes instructions for performing the action by the computing device, wherein the transmitted structured data causes the computing device to display the message relating to the second media content item and perform the action on the second media content item.
12. The system of claim 11 , wherein the action comprises displaying a webpage related to the item of interest and wherein the structured data includes a URL of the webpage.
13. The system of claim 10 , wherein the visual characteristics of the item of interest in the first media content item are similar to the visual characteristics of an object appearing in the second media content item.
14. The system of claim 10 , wherein the visual characteristics comprise text captured in the video frame of the media content item, wherein identifying the first data comprises using character recognition to identify the characters of the text, and wherein the first data is retrieved based on a query including the characters.
15. The system of claim 10 , wherein identifying the first data comprises identifying other images that are visually similar to the plurality of image data, wherein the other images are associated with metadata, and wherein the first data is retrieved based on the metadata.
16. The system of claim 10 , wherein the first data is used to form the search query that is performed on the item of interest to identify the supplemental content and wherein the action is determined based on a type of search result responsive to the search query.
17. A non-transitory computer-readable medium containing computer-executable instructions that, when executed by a hardware processor, cause the hardware processor to perform a method for presenting supplemental content, the method comprising:
receiving a request regarding an item of interest that was presented in a media content item;
obtaining a plurality of image data including a video frame of the media content item corresponding to a time of the received request and at least one of a preceding video frame presented before the video frame and a subsequent frame presented after the video frame;
comparing the plurality of image data to identify the item of interest;
identifying supplemental content that is associated with the item of interest by performing a search with a search query based on the item of interest and receiving supplemental content as search results responsive to the search query;
transmitting a response to the request that includes the supplemental content corresponding to the item of interest identified in the media content item; and
causing, based on the transmitted response to the request, a computing device to present the supplemental content corresponding to the item of interest identified in the media content item and perform an action on the computing device in connection with the supplemental content.
18. The non-transitory computer-readable medium of claim 17 , wherein the supplemental content includes a second media content item that is different than the media content item and wherein the method further comprises:
identifying first data relating to the item of interest based on visual characteristics of the determined item of interest, wherein the first data comprises information relating to the second media content item; and
determining a message to be displayed based on the first data and an action to be performed on the second media content item based on the first data.
19. The non-transitory computer-readable medium of claim 18 , wherein transmitting the response further comprises transmitting structured data that comprises a first node that includes information relating to displaying the message and a second node that includes instructions for performing the action by the computing device, wherein the transmitted structured data causes the computing device to display the message relating to the second media content item and perform the action on the second media content item.
20. The non-transitory computer-readable medium of claim 19 , wherein the action comprises displaying a webpage related to the item of interest and wherein the structured data includes a URL of the webpage.
21. The non-transitory computer-readable medium of claim 18 , wherein the visual characteristics of the item of interest in the first media content item are similar to the visual characteristics of an object appearing in the second media content item.
22. The non-transitory computer-readable medium of claim 18 , wherein the visual characteristics comprise text captured in the video frame of the media content item, wherein identifying the first data comprises using character recognition to identify the characters of the text, and wherein the first data is retrieved based on a query including the characters.
23. The non-transitory computer-readable medium of claim 18 , wherein identifying the first data comprises identifying other images that are visually similar to the plurality of image data, wherein the other images are associated with metadata, and wherein the first data is retrieved based on the metadata.
24. The non-transitory computer-readable medium of claim 18 , wherein the first data is used to form the search query that is performed on the item of interest to identify the supplemental content and wherein the action is determined based on a type of search result responsive to the search query.
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US15/284,145 US9906840B2 (en) | 2013-03-13 | 2016-10-03 | System and method for obtaining information relating to video images |
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US13/801,843 US9258597B1 (en) | 2013-03-13 | 2013-03-13 | System and method for obtaining information relating to video images |
US14/966,955 US9462350B1 (en) | 2013-03-13 | 2015-12-11 | System and method for obtaining information relating to video images |
US15/284,145 US9906840B2 (en) | 2013-03-13 | 2016-10-03 | System and method for obtaining information relating to video images |
Related Parent Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US14/966,955 Continuation US9462350B1 (en) | 2013-03-13 | 2015-12-11 | System and method for obtaining information relating to video images |
Publications (2)
Publication Number | Publication Date |
---|---|
US20170026708A1 US20170026708A1 (en) | 2017-01-26 |
US9906840B2 true US9906840B2 (en) | 2018-02-27 |
Family
ID=55235743
Family Applications (3)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US13/801,843 Active US9258597B1 (en) | 2013-03-13 | 2013-03-13 | System and method for obtaining information relating to video images |
US14/966,955 Active US9462350B1 (en) | 2013-03-13 | 2015-12-11 | System and method for obtaining information relating to video images |
US15/284,145 Active US9906840B2 (en) | 2013-03-13 | 2016-10-03 | System and method for obtaining information relating to video images |
Family Applications Before (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US13/801,843 Active US9258597B1 (en) | 2013-03-13 | 2013-03-13 | System and method for obtaining information relating to video images |
US14/966,955 Active US9462350B1 (en) | 2013-03-13 | 2015-12-11 | System and method for obtaining information relating to video images |
Country Status (1)
Country | Link |
---|---|
US (3) | US9258597B1 (en) |
Families Citing this family (10)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP6224503B2 (en) * | 2014-04-02 | 2017-11-01 | 株式会社ソニー・インタラクティブエンタテインメント | Information processing apparatus, information processing system, and content image generation method |
US10657406B2 (en) | 2017-02-02 | 2020-05-19 | The Directv Group, Inc. | Optical character recognition text export from video program |
US10292045B2 (en) * | 2017-08-24 | 2019-05-14 | Nanning Fugui Precision Industrial Co., Ltd. | Information obtaining method and information obtaining device |
US10757483B2 (en) | 2017-10-26 | 2020-08-25 | Futurewei Technologies, Inc. | Method and apparatus for data tracking and presenting |
CN107920259A (en) * | 2017-10-31 | 2018-04-17 | 深信服科技股份有限公司 | Virtual platform video playing accelerated method, virtual machine server and storage medium |
CN108255922A (en) * | 2017-11-06 | 2018-07-06 | 优视科技有限公司 | Video frequency identifying method, equipment, client terminal device, electronic equipment and server |
US10477287B1 (en) | 2019-06-18 | 2019-11-12 | Neal C. Fairbanks | Method for providing additional information associated with an object visually present in media content |
CN112218000B (en) * | 2019-07-09 | 2023-06-16 | 西安诺瓦星云科技股份有限公司 | Multi-picture monitoring method, device and system |
US10887633B1 (en) * | 2020-02-19 | 2021-01-05 | Evercast, LLC | Real time remote video collaboration |
US11956518B2 (en) | 2020-11-23 | 2024-04-09 | Clicktivated Video, Inc. | System and method for creating interactive elements for objects contemporaneously displayed in live video |
Citations (52)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20020147984A1 (en) | 2000-11-07 | 2002-10-10 | Tomsen Mai-Lan | System and method for pre-caching supplemental content related to a television broadcast using unprompted, context-sensitive querying |
US20040104926A1 (en) | 2000-07-31 | 2004-06-03 | Murray James H. | Method of retieving information associated with an object present in a media stream |
US20060129908A1 (en) | 2003-01-28 | 2006-06-15 | Markel Steven O | On-content streaming media enhancement |
US20070124756A1 (en) | 2005-11-29 | 2007-05-31 | Google Inc. | Detecting Repeating Content in Broadcast Media |
US20070136773A1 (en) * | 2005-12-14 | 2007-06-14 | O'neil Douglas | Systems and methods for providing television services using implicit content to indicate the availability of additional content |
US20080089551A1 (en) * | 2006-10-16 | 2008-04-17 | Ashley Heather | Interactive TV data track synchronization system and method |
US20080098432A1 (en) | 2006-10-23 | 2008-04-24 | Hardacker Robert L | Metadata from image recognition |
US20080229363A1 (en) * | 2005-01-14 | 2008-09-18 | Koninklijke Philips Electronics, N.V. | Method and a System For Constructing Virtual Video Channel |
US20080226119A1 (en) | 2007-03-16 | 2008-09-18 | Brant Candelore | Content image search |
US20090276805A1 (en) * | 2008-05-03 | 2009-11-05 | Andrews Ii James K | Method and system for generation and playback of supplemented videos |
US20100082585A1 (en) | 2008-09-23 | 2010-04-01 | Disney Enterprises, Inc. | System and method for visual search in a video media player |
US20100121973A1 (en) | 2008-11-12 | 2010-05-13 | Yuliya Lobacheva | Augmentation of streaming media |
US20100287053A1 (en) | 2007-12-31 | 2010-11-11 | Ray Ganong | Method, system, and computer program for identification and sharing of digital images with face signatures |
US7840980B2 (en) | 2004-11-04 | 2010-11-23 | Koninklijke Philips Electronics N.V. | Incorporation of lead actor information for TV recommenders |
US20110078753A1 (en) | 2009-09-30 | 2011-03-31 | Disney Enterprises, Inc. | System and method for providing media content enhancement |
US20110103763A1 (en) | 2009-11-05 | 2011-05-05 | Cosmo Research Company Limited | System and method for identifying, providing, and presenting supplemental content on a mobile device |
US20110125735A1 (en) | 2009-08-07 | 2011-05-26 | David Petrou | Architecture for responding to a visual query |
US20110179357A1 (en) | 2010-01-15 | 2011-07-21 | Hulu Llc | Method and apparatus for providing supplemental video content for third party websites |
US20110246495A1 (en) | 2010-04-01 | 2011-10-06 | Sony Computer Entertainment Inc. | Media fingerprinting for social networking |
US20110247042A1 (en) | 2010-04-01 | 2011-10-06 | Sony Computer Entertainment Inc. | Media fingerprinting for content determination and retrieval |
US20110243449A1 (en) | 2010-03-31 | 2011-10-06 | Nokia Corporation | Method and apparatus for object identification within a media file using device identification |
US20110282906A1 (en) * | 2010-05-14 | 2011-11-17 | Rovi Technologies Corporation | Systems and methods for performing a search based on a media content snapshot image |
US8064516B2 (en) | 2005-06-02 | 2011-11-22 | Broadcom Corporation | Text recognition during video compression |
EP2388721A1 (en) | 2010-05-19 | 2011-11-23 | Google Inc. | Presenting mobile content based on programming context |
WO2012014130A1 (en) | 2010-07-26 | 2012-02-02 | Koninklijke Philips Electronics N.V. | Obtaining keywords for searching |
US20120078889A1 (en) | 2010-09-28 | 2012-03-29 | International Business Machines Corporation | Providing answers to questions using hypothesis pruning |
US20120096499A1 (en) | 2010-10-19 | 2012-04-19 | Charles Dasher | Apparatus and method for facilitating video-on-demand catalog search and content distribution |
US20120117057A1 (en) | 2010-11-05 | 2012-05-10 | Verizon Patent And Licensing Inc. | Searching recorded or viewed content |
US20120117584A1 (en) * | 2010-11-01 | 2012-05-10 | Gordon Donald F | Method and System for Presenting Additional Content at a Media System |
US8185543B1 (en) | 2004-11-10 | 2012-05-22 | Google Inc. | Video image-based querying for video content |
US8205223B2 (en) | 2000-04-12 | 2012-06-19 | Lg Electronics Inc. | Method and video device for accessing information |
US20120167144A1 (en) * | 2010-12-23 | 2012-06-28 | Eldon Technology Limited | Recognition of Images Within a Video Based on a Stored Representation |
US20120227074A1 (en) | 2011-03-01 | 2012-09-06 | Sony Corporation | Enhanced information for viewer-selected video object |
US20120240144A1 (en) | 2011-03-17 | 2012-09-20 | Anthony Rose | Content provision |
US20120291072A1 (en) | 2011-05-13 | 2012-11-15 | Kyle Maddison | System and Method for Enhancing User Search Results by Determining a Television Program Currently Being Displayed in Proximity to an Electronic Device |
US20120311641A1 (en) | 2008-02-26 | 2012-12-06 | Microsoft Corporation | Techniques to Consume Content and Metadata |
US20120311623A1 (en) | 2008-11-14 | 2012-12-06 | Digimarc Corp. | Methods and systems for obtaining still images corresponding to video |
US20130036442A1 (en) | 2011-08-05 | 2013-02-07 | Qualcomm Incorporated | System and method for visual selection of elements in video content |
US20130047178A1 (en) | 2011-08-21 | 2013-02-21 | Kyoungsoo Moon | Video display device, terminal device, and method thereof |
US8392951B2 (en) | 2010-01-26 | 2013-03-05 | Lg Electronics Inc. | Information providing apparatus and method thereof |
US20130058522A1 (en) | 2011-09-01 | 2013-03-07 | Gracenote, Inc. | Media source identification |
WO2013040533A1 (en) | 2011-09-16 | 2013-03-21 | Umami Co. | Second screen interactive platform |
US20130086105A1 (en) | 2011-10-03 | 2013-04-04 | Microsoft Corporation | Voice directed context sensitive visual search |
US20130104172A1 (en) | 2011-10-24 | 2013-04-25 | Eunjung Lee | Searching method and mobile device using the method |
US20130139209A1 (en) | 2011-11-28 | 2013-05-30 | Yahoo! Inc. | Context Relevant Interactive Television |
US20130174195A1 (en) * | 2012-01-04 | 2013-07-04 | Google Inc. | Systems and methods of image searching |
US8484017B1 (en) | 2012-09-10 | 2013-07-09 | Google Inc. | Identifying media content |
US20130179436A1 (en) | 2012-01-09 | 2013-07-11 | Samsung Electronics Co., Ltd. | Display apparatus, remote control apparatus, and searching methods thereof |
US20140253472A1 (en) * | 2013-03-11 | 2014-09-11 | General Instrument Corporation | Telestration system for command processing |
US20140255003A1 (en) * | 2013-03-05 | 2014-09-11 | Google Inc. | Surfacing information about items mentioned or presented in a film in association with viewing the film |
US8929657B2 (en) * | 2008-08-22 | 2015-01-06 | KyongHee Yi | System and method for indexing object in image |
US20150193433A1 (en) | 2011-08-26 | 2015-07-09 | Sean Dykeman | Third Party Content Provider Integrations |
-
2013
- 2013-03-13 US US13/801,843 patent/US9258597B1/en active Active
-
2015
- 2015-12-11 US US14/966,955 patent/US9462350B1/en active Active
-
2016
- 2016-10-03 US US15/284,145 patent/US9906840B2/en active Active
Patent Citations (55)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US8205223B2 (en) | 2000-04-12 | 2012-06-19 | Lg Electronics Inc. | Method and video device for accessing information |
US20040104926A1 (en) | 2000-07-31 | 2004-06-03 | Murray James H. | Method of retieving information associated with an object present in a media stream |
US20020147984A1 (en) | 2000-11-07 | 2002-10-10 | Tomsen Mai-Lan | System and method for pre-caching supplemental content related to a television broadcast using unprompted, context-sensitive querying |
US20060129908A1 (en) | 2003-01-28 | 2006-06-15 | Markel Steven O | On-content streaming media enhancement |
US7840980B2 (en) | 2004-11-04 | 2010-11-23 | Koninklijke Philips Electronics N.V. | Incorporation of lead actor information for TV recommenders |
US8185543B1 (en) | 2004-11-10 | 2012-05-22 | Google Inc. | Video image-based querying for video content |
US20080229363A1 (en) * | 2005-01-14 | 2008-09-18 | Koninklijke Philips Electronics, N.V. | Method and a System For Constructing Virtual Video Channel |
US8064516B2 (en) | 2005-06-02 | 2011-11-22 | Broadcom Corporation | Text recognition during video compression |
US20070124756A1 (en) | 2005-11-29 | 2007-05-31 | Google Inc. | Detecting Repeating Content in Broadcast Media |
US20070136773A1 (en) * | 2005-12-14 | 2007-06-14 | O'neil Douglas | Systems and methods for providing television services using implicit content to indicate the availability of additional content |
US20080089551A1 (en) * | 2006-10-16 | 2008-04-17 | Ashley Heather | Interactive TV data track synchronization system and method |
US20080098432A1 (en) | 2006-10-23 | 2008-04-24 | Hardacker Robert L | Metadata from image recognition |
US20080226119A1 (en) | 2007-03-16 | 2008-09-18 | Brant Candelore | Content image search |
US20100287053A1 (en) | 2007-12-31 | 2010-11-11 | Ray Ganong | Method, system, and computer program for identification and sharing of digital images with face signatures |
US20120311641A1 (en) | 2008-02-26 | 2012-12-06 | Microsoft Corporation | Techniques to Consume Content and Metadata |
US20120266197A1 (en) * | 2008-05-03 | 2012-10-18 | Andrews Ii James K | Method and system for generation and playback of supplemented videos |
US20090276805A1 (en) * | 2008-05-03 | 2009-11-05 | Andrews Ii James K | Method and system for generation and playback of supplemented videos |
US8929657B2 (en) * | 2008-08-22 | 2015-01-06 | KyongHee Yi | System and method for indexing object in image |
US20100082585A1 (en) | 2008-09-23 | 2010-04-01 | Disney Enterprises, Inc. | System and method for visual search in a video media player |
US20100121973A1 (en) | 2008-11-12 | 2010-05-13 | Yuliya Lobacheva | Augmentation of streaming media |
US20120311623A1 (en) | 2008-11-14 | 2012-12-06 | Digimarc Corp. | Methods and systems for obtaining still images corresponding to video |
US20110125735A1 (en) | 2009-08-07 | 2011-05-26 | David Petrou | Architecture for responding to a visual query |
US20110078753A1 (en) | 2009-09-30 | 2011-03-31 | Disney Enterprises, Inc. | System and method for providing media content enhancement |
US20110103763A1 (en) | 2009-11-05 | 2011-05-05 | Cosmo Research Company Limited | System and method for identifying, providing, and presenting supplemental content on a mobile device |
US20110179357A1 (en) | 2010-01-15 | 2011-07-21 | Hulu Llc | Method and apparatus for providing supplemental video content for third party websites |
US8392951B2 (en) | 2010-01-26 | 2013-03-05 | Lg Electronics Inc. | Information providing apparatus and method thereof |
US20110243449A1 (en) | 2010-03-31 | 2011-10-06 | Nokia Corporation | Method and apparatus for object identification within a media file using device identification |
US20110247042A1 (en) | 2010-04-01 | 2011-10-06 | Sony Computer Entertainment Inc. | Media fingerprinting for content determination and retrieval |
US20110246495A1 (en) | 2010-04-01 | 2011-10-06 | Sony Computer Entertainment Inc. | Media fingerprinting for social networking |
US20110282906A1 (en) * | 2010-05-14 | 2011-11-17 | Rovi Technologies Corporation | Systems and methods for performing a search based on a media content snapshot image |
EP2388721A1 (en) | 2010-05-19 | 2011-11-23 | Google Inc. | Presenting mobile content based on programming context |
US8694533B2 (en) | 2010-05-19 | 2014-04-08 | Google Inc. | Presenting mobile content based on programming context |
WO2012014130A1 (en) | 2010-07-26 | 2012-02-02 | Koninklijke Philips Electronics N.V. | Obtaining keywords for searching |
US20120078889A1 (en) | 2010-09-28 | 2012-03-29 | International Business Machines Corporation | Providing answers to questions using hypothesis pruning |
US20120096499A1 (en) | 2010-10-19 | 2012-04-19 | Charles Dasher | Apparatus and method for facilitating video-on-demand catalog search and content distribution |
US20120117584A1 (en) * | 2010-11-01 | 2012-05-10 | Gordon Donald F | Method and System for Presenting Additional Content at a Media System |
US20120117057A1 (en) | 2010-11-05 | 2012-05-10 | Verizon Patent And Licensing Inc. | Searching recorded or viewed content |
US20120167144A1 (en) * | 2010-12-23 | 2012-06-28 | Eldon Technology Limited | Recognition of Images Within a Video Based on a Stored Representation |
US20120227074A1 (en) | 2011-03-01 | 2012-09-06 | Sony Corporation | Enhanced information for viewer-selected video object |
US20120240144A1 (en) | 2011-03-17 | 2012-09-20 | Anthony Rose | Content provision |
US20120291072A1 (en) | 2011-05-13 | 2012-11-15 | Kyle Maddison | System and Method for Enhancing User Search Results by Determining a Television Program Currently Being Displayed in Proximity to an Electronic Device |
US20130036442A1 (en) | 2011-08-05 | 2013-02-07 | Qualcomm Incorporated | System and method for visual selection of elements in video content |
US20130047178A1 (en) | 2011-08-21 | 2013-02-21 | Kyoungsoo Moon | Video display device, terminal device, and method thereof |
US20150193433A1 (en) | 2011-08-26 | 2015-07-09 | Sean Dykeman | Third Party Content Provider Integrations |
US20130058522A1 (en) | 2011-09-01 | 2013-03-07 | Gracenote, Inc. | Media source identification |
WO2013040533A1 (en) | 2011-09-16 | 2013-03-21 | Umami Co. | Second screen interactive platform |
US20130111514A1 (en) | 2011-09-16 | 2013-05-02 | Umami Co. | Second screen interactive platform |
US20130086105A1 (en) | 2011-10-03 | 2013-04-04 | Microsoft Corporation | Voice directed context sensitive visual search |
US20130104172A1 (en) | 2011-10-24 | 2013-04-25 | Eunjung Lee | Searching method and mobile device using the method |
US20130139209A1 (en) | 2011-11-28 | 2013-05-30 | Yahoo! Inc. | Context Relevant Interactive Television |
US20130174195A1 (en) * | 2012-01-04 | 2013-07-04 | Google Inc. | Systems and methods of image searching |
US20130179436A1 (en) | 2012-01-09 | 2013-07-11 | Samsung Electronics Co., Ltd. | Display apparatus, remote control apparatus, and searching methods thereof |
US8484017B1 (en) | 2012-09-10 | 2013-07-09 | Google Inc. | Identifying media content |
US20140255003A1 (en) * | 2013-03-05 | 2014-09-11 | Google Inc. | Surfacing information about items mentioned or presented in a film in association with viewing the film |
US20140253472A1 (en) * | 2013-03-11 | 2014-09-11 | General Instrument Corporation | Telestration system for command processing |
Non-Patent Citations (41)
Title |
---|
International Preliminary Report on Patentability and Written Opinion dated Jul. 14, 2016 in International Patent Application No. PCT/US2014/072258. |
International Preliminary Report on Patentability and Written Opinion dated Sep. 24, 2015 in International Patent Application PCT/US2014/024627. |
International Preliminary Report on Patentability dated Sep. 24, 2015 in International Patent Application No. PCT/US2014/024255. |
International Search Report and Written Opinion of the International Search Authority dated Apr. 17, 2015 in International Patent Application No. PCT/US2014/072258. |
International Search Report and Written Opinion of the International Search Authority dated Jul. 24, 2014 in International Patent Application No. PCT/US2014/024627. |
International Search Report and Written Opinion of the International Search Authority dated Jul. 28, 2014 in International Patent Application No. PCT/US2014/024255. |
Notice of Allowance dated Apr. 17, 2015 in U.S. Appl. No. 13/827,413. |
Notice of Allowance dated Aug. 17, 2015 in U.S. Appl. No. 13/801,843. |
Notice of Allowance dated Jun. 5, 2015 in U.S. Appl. No. 13/826,910. |
Notice of Allowance dated Jun. 6, 2016 in U.S. Appl. No. 14/966,955. |
Notice of Allowance dated Mar. 9, 2017 in U.S. Appl. No. 13/834,394. |
Notice of Allowance dated Nov. 9, 2016 in U.S. Appl. No. 15/005,470. |
Office Action dated Apr. 13, 2017 in EP Patent Application No. 14725797.6. |
Office Action dated Apr. 24, 2014 in U.S. Appl. No. 13/801,843. |
Office Action dated Dec. 11, 2015 in U.S. Appl. No. 14/966,955. |
Office Action dated Dec. 9, 2014 in U.S. Appl. No. 13/827,413. |
Office Action dated Jan. 30, 2015 in U.S. Appl. No. 13/826,910. |
Office Action dated Jan. 5, 2016 in U.S. Appl. No. 13/826,910. |
Office Action dated Jul. 14, 2016 in U.S. Appl. No. 14/191,034. |
Office Action dated Jul. 27, 2016 in U.S. Appl. No. 15/005,470. |
Office Action dated Jul. 29, 2014 in U.S. Appl. No. 13/826,910. |
Office Action dated Jun. 2, 2017 in U.S. Appl. No. 14/191,034. |
Office Action dated Jun. 29, 2017 in U.S. Appl. No. 15/431,431. |
Office Action dated Jun. 6, 2016 in U.S. Appl. No. 14/966,955. |
Office Action dated Mar. 23, 2015 in U.S. Appl. No. 13/801,843. |
Office Action dated Mar. 25, 2015 in U.S. Appl. No. 13/834,394. |
Office Action dated Mar. 9, 2016 in U.S. Appl. No. 14/966,955. |
Office Action dated May 12, 2016 in U.S. Appl. No. 13/834,394. |
Office Action dated May 18, 2016 in U.S. Appl. No. 13/826,910. |
Office Action dated Oct. 19, 2016 in U.S. Appl. No. 13/834,394. |
Office Action dated Oct. 20, 2016 in U.S. Appl. No. 14/191,034. |
Office Action dated Sep. 11, 2015 in U.S. Appl. No. 13/834,394. |
Office Action dated Sep. 27, 2017 in U.S. Appl. No. 15/431,431. |
Office Action dated Sep. 6, 2017 in U.S. Appl. No. 14/191,034. |
U.S. Appl. No. 13/594,693, filed Aug. 24, 2012. |
U.S. Appl. No. 13/826,910, filed Mar. 14, 2013. |
U.S. Appl. No. 13/827,413, filed Mar. 14, 2013. |
U.S. Appl. No. 14/191,034, filed Feb. 26, 2014. |
U.S. Appl. No. 61/922,218, filed Dec. 31, 2013. |
YouTube, "Pharos Demonstration-Audiovisual Tunable Search-Part C", last updated Jan. 16, 2010, pp. 1, available at: https://www.youtube.com/watch?v=ZpxyNi6Ht50. |
YouTube, "Pharos Demonstration—Audiovisual Tunable Search—Part C", last updated Jan. 16, 2010, pp. 1, available at: https://www.youtube.com/watch?v=ZpxyNi6Ht50. |
Also Published As
Publication number | Publication date |
---|---|
US9258597B1 (en) | 2016-02-09 |
US9462350B1 (en) | 2016-10-04 |
US20170026708A1 (en) | 2017-01-26 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US9906840B2 (en) | System and method for obtaining information relating to video images | |
US11615136B2 (en) | System and method of identifying visual objects | |
US9495592B2 (en) | Image-based information providing device and method using object recognition | |
US20150082331A1 (en) | Methods for identifying video segments and displaying contextually targeted content on a connected television | |
US9881084B1 (en) | Image match based video search | |
US9465851B2 (en) | Search apparatus configured to utilize supplemental information to identify an index associated with a captured image, search method, and search system configured to perform the same | |
EP2999228B1 (en) | Mobile device, image reproducing device and server for providing relevant information about image captured by image reproducing device, and method thereof | |
US11630862B2 (en) | Multimedia focalization | |
CN103686344A (en) | Enhanced video system and method | |
US20130132996A1 (en) | System and method for displaying product information about advertisement on digital television, and recording medium thereof | |
CN111274449A (en) | Video playing method and device, electronic equipment and storage medium | |
CN110955799A (en) | Face recommendation movie and television method based on target detection |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044695/0115Effective date: 20170929 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 4TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1551); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 4 |