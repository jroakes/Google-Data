JP2021506008A - Decentralized identification in networked systems - Google Patents
Decentralized identification in networked systems Download PDFInfo
- Publication number
- JP2021506008A JP2021506008A JP2020531004A JP2020531004A JP2021506008A JP 2021506008 A JP2021506008 A JP 2021506008A JP 2020531004 A JP2020531004 A JP 2020531004A JP 2020531004 A JP2020531004 A JP 2020531004A JP 2021506008 A JP2021506008 A JP 2021506008A
- Authority
- JP
- Japan
- Prior art keywords
- computing device
- client computing
- audio
- model
- identification
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
Images
Classifications
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L17/00—Speaker identification or verification
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/60—Information retrieval; Database structures therefor; File system structures therefor of audio data
- G06F16/63—Querying
- G06F16/635—Filtering based on additional data, e.g. user or group profiles
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/30—Authentication, i.e. establishing the identity or authorisation of security principals
- G06F21/31—User authentication
- G06F21/32—User authentication using biometric data, e.g. fingerprints, iris scans or voiceprints
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/16—Sound input; Sound output
- G06F3/167—Audio in a user interface, e.g. using voice commands for navigating, audio feedback
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/46—Multiprogramming arrangements
- G06F9/50—Allocation of resources, e.g. of the central processing unit [CPU]
- G06F9/5005—Allocation of resources, e.g. of the central processing unit [CPU] to service a request
- G06F9/5027—Allocation of resources, e.g. of the central processing unit [CPU] to service a request the resource being a machine, e.g. CPUs, Servers, Terminals
- G06F9/5055—Allocation of resources, e.g. of the central processing unit [CPU] to service a request the resource being a machine, e.g. CPUs, Servers, Terminals considering software capabilities, i.e. software resources associated or available to the machine
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/22—Procedures used during a speech recognition process, e.g. man-machine dialogue
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/28—Constructional details of speech recognition systems
- G10L15/30—Distributed recognition, e.g. in client-server systems, for mobile phones or network applications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L63/00—Network architectures or network communication protocols for network security
- H04L63/08—Network architectures or network communication protocols for network security for authentication of entities
- H04L63/0861—Network architectures or network communication protocols for network security for authentication of entities using biometrical features, e.g. fingerprint, retina-scan
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L63/00—Network architectures or network communication protocols for network security
- H04L63/10—Network architectures or network communication protocols for network security for controlling access to devices or network resources
- H04L63/102—Entity profiles
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L63/00—Network architectures or network communication protocols for network security
- H04L63/10—Network architectures or network communication protocols for network security for controlling access to devices or network resources
- H04L63/107—Network architectures or network communication protocols for network security for controlling access to devices or network resources wherein the security policies are location-dependent, e.g. entities privileges depend on current location or allowing specific operations only from locally connected terminals
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L63/00—Network architectures or network communication protocols for network security
- H04L63/10—Network architectures or network communication protocols for network security for controlling access to devices or network resources
- H04L63/108—Network architectures or network communication protocols for network security for controlling access to devices or network resources when the policy decisions are valid for a limited amount of time
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L67/00—Network arrangements or protocols for supporting network services or applications
- H04L67/01—Protocols
- H04L67/12—Protocols specially adapted for proprietary or special-purpose networking environments, e.g. medical networks, sensor networks, networks in vehicles or remote metering networks
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L67/00—Network arrangements or protocols for supporting network services or applications
- H04L67/2866—Architectures; Arrangements
- H04L67/30—Profiles
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04W—WIRELESS COMMUNICATION NETWORKS
- H04W12/00—Security arrangements; Authentication; Protecting privacy or anonymity
- H04W12/06—Authentication
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04W—WIRELESS COMMUNICATION NETWORKS
- H04W12/00—Security arrangements; Authentication; Protecting privacy or anonymity
- H04W12/08—Access security
- H04W12/082—Access security using revocation of authorisation
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04W—WIRELESS COMMUNICATION NETWORKS
- H04W12/00—Security arrangements; Authentication; Protecting privacy or anonymity
- H04W12/60—Context-dependent security
- H04W12/61—Time-dependent
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04W—WIRELESS COMMUNICATION NETWORKS
- H04W12/00—Security arrangements; Authentication; Protecting privacy or anonymity
- H04W12/60—Context-dependent security
- H04W12/63—Location-dependent; Proximity-dependent
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04W—WIRELESS COMMUNICATION NETWORKS
- H04W12/00—Security arrangements; Authentication; Protecting privacy or anonymity
- H04W12/60—Context-dependent security
- H04W12/63—Location-dependent; Proximity-dependent
- H04W12/64—Location-dependent; Proximity-dependent using geofenced areas
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F2221/00—Indexing scheme relating to security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F2221/21—Indexing scheme relating to G06F21/00 and subgroups addressing additional information or applications relating to security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F2221/2111—Location-sensitive, e.g. geographical location, GPS
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/22—Procedures used during a speech recognition process, e.g. man-machine dialogue
- G10L2015/226—Procedures used during a speech recognition process, e.g. man-machine dialogue using non-speech characteristics
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/22—Procedures used during a speech recognition process, e.g. man-machine dialogue
- G10L2015/226—Procedures used during a speech recognition process, e.g. man-machine dialogue using non-speech characteristics
- G10L2015/227—Procedures used during a speech recognition process, e.g. man-machine dialogue using non-speech characteristics of the speaker; Human-factor methodology
Abstract
本開示は、概して、音声作動式のコンピュータネットワーク環境においてコンテンツをカスタマイズするためのデータ処理システムを対象とする。ユーザの同意の下に、データ処理システムは、たとえば、カスタマイズされたコンテンツの生成に使用される音声識別プロセスの正確さを高めることによって1つまたは複数のコンピュータネットワーク上の聴覚データパケットの送信の効率および効果を改善することができる。このソリューションは、生成するための計算負荷が高いより少ないオーディオ識別モデルを生成するが、正確な識別を行うことができる。The present disclosure is generally intended for data processing systems for customizing content in a voice-operated computer network environment. With the consent of the user, the data processing system can, for example, increase the accuracy of the speech recognition process used to generate customized content to increase the efficiency of sending auditory data packets over one or more computer networks. And the effect can be improved. This solution produces a less computationally intensive audio discriminative model to generate, but can provide accurate discriminatives.
Description
本開示は、概して、音声作動式のコンピュータネットワーク環境においてコンテンツをカスタマイズするためのデータ処理システムを対象とする。 The present disclosure is generally intended for data processing systems for customizing content in a voice-operated computer network environment.
コンピューティングデバイスの間のネットワークトラフィックデータのパケットに基づくまたはそれ以外の過大なネットワーク送信は、コンピューティングデバイスがネットワークトラフィックデータを適切に処理すること、ネットワークトラフィックデータに関連する動作を完了すること、またはネットワークトラフィックデータに適時応答することを妨げ得る。ネットワークトラフィックデータの過大な送信は、データのルーティングを複雑にするか、または応答するコンピューティングデバイスがそのコンピューティングデバイスの処理能力の限界にあるかもしくは限界を超えている場合に応答の品質を低下させる可能性もあり、それは、結果として非効率的な帯域幅の利用をもたらすことがある。 Excessive network transmission based on or otherwise excessive network traffic data between computing devices means that the computing device properly processes the network traffic data, completes operations related to the network traffic data, or It can prevent timely response to network traffic data. Excessive transmission of network traffic data complicates the routing of data or reduces the quality of the response when the responding computing device is at or exceeds the processing capacity of the computing device. It can also result in inefficient use of bandwidth.
本開示の少なくとも1つの態様によれば、音声作動式のシステムにおいてコンテンツをカスタマイズするためのシステムが、データ処理システムを含み得る。データ処理システムは、インターフェースを含み得る。インターフェースは、第1のクライアントコンピューティングデバイスの位置を受け取ることができる。第1のクライアントコンピューティングデバイスは、第1のオーディオ識別モデルに関連付けられ得る。インターフェースは、第2のクライアントコンピューティングデバイスからオーディオ入力信号を受け取ることができる。第2のクライアントコンピューティングデバイスは、第2のオーディオ識別モデルに関連付けられ得る。データ処理システムは、認証コンポーネントを含み得る。認証コンポーネントは、第1のクライアントコンピューティングデバイスの位置が第2のクライアントコンピューティングデバイスまで所定の距離以内にあると判定し得る。認証コンポーネントは、第1のクライアントコンピューティングデバイスの位置が第2のクライアントコンピューティングデバイスまで所定の距離以内にあるという判定に基づいて、第2のクライアントコンピューティングデバイスによって受け取られたオーディオ信号の処理のための第1のクライアントコンピューティングデバイスの第1のオーディオ識別モデルへのアクセスを提供することができる。認証コンポーネントは、第1のオーディオ識別モデルを使用して第1の識別スコアを生成し、第2のオーディオ識別モデルを使用して第2の識別スコアを生成することができる。認証コンポーネントは、第1の識別スコアおよび第2の識別スコアに基づいて複数の候補プロファイルからプロファイルを選択し得る。データ処理システムは、複数の候補プロファイルから選択されたプロファイルに基づいてデジタルコンポーネントを選択するためのコンテンツ選択コンポーネントを含み得る。データ処理システムのインターフェースは、オーディオ入力信号に応答して第2のクライアントコンピューティングデバイスにデジタルコンポーネントを送信することができる。 According to at least one aspect of the present disclosure, a system for customizing content in a voice-operated system may include a data processing system. The data processing system may include an interface. The interface can receive the location of the first client computing device. The first client computing device can be associated with the first audio discriminative model. The interface can receive audio input signals from a second client computing device. The second client computing device can be associated with a second audio discriminative model. The data processing system may include an authentication component. The authentication component may determine that the location of the first client computing device is within a predetermined distance to the second client computing device. The authentication component processes the audio signal received by the second client computing device based on the determination that the location of the first client computing device is within a predetermined distance to the second client computing device. It can provide access to a first audio identification model of a first client computing device for. The authentication component can use the first audio discriminative model to generate the first discriminative score and the second audio discriminative model to generate the second discriminative score. The authentication component may select a profile from multiple candidate profiles based on the first identification score and the second identification score. The data processing system may include a content selection component for selecting a digital component based on a profile selected from a plurality of candidate profiles. The interface of the data processing system can send digital components to the second client computing device in response to the audio input signal.
本開示の少なくとも1つの態様は、音声作動式のシステムにおいてコンテンツをカスタマイズするための方法に関する。方法は、第1のクライアントコンピューティングデバイスの位置を受け取るステップを含んでよい。第1のクライアントコンピューティングデバイスは、第1のオーディオ識別モデルに関連付けられてよい。方法は、第1のクライアントコンピューティングデバイスの位置が第2のクライアントコンピューティングデバイスまで所定の距離以内にあると判定するステップを含んでよい。第2のクライアントコンピューティングデバイスは、第2のオーディオ識別モデルに関連付けられてよい。方法は、第1のクライアントコンピューティングデバイスの位置が第2のクライアントコンピューティングデバイスまで所定の距離以内にあるという判定に基づいて、第2のクライアントコンピューティングデバイスによって受け取られたオーディオ信号の処理のための第1のクライアントコンピューティングデバイスの第1のオーディオ識別モデルへのアクセスを提供するステップを含んでよい。方法は、第2のクライアントコンピューティングデバイスからオーディオ入力信号を受け取るステップを含んでよい。方法は、第1のオーディオ識別モデルを使用して第1の識別スコアを生成し、第2のオーディオ識別モデルを使用して第2の識別スコアを生成するステップを含んでよい。方法は、第1の識別スコアおよび第2の識別スコアに基づいて複数の候補プロファイルからプロファイルを選択するステップを含んでよい。方法は、プロファイルに基づいてデジタルコンポーネントを選択するステップを含んでよい。方法は、第2のクライアントコンピューティングデバイスにデジタルコンポーネントを送信するステップを含んでよい。 At least one aspect of the present disclosure relates to a method for customizing content in a voice-operated system. The method may include the step of receiving the location of the first client computing device. The first client computing device may be associated with the first audio discriminative model. The method may include determining that the location of the first client computing device is within a predetermined distance to the second client computing device. The second client computing device may be associated with a second audio discriminative model. The method is for processing the audio signal received by the second client computing device based on the determination that the position of the first client computing device is within a predetermined distance to the second client computing device. It may include the step of providing access to the first audio identification model of the first client computing device of the. The method may include the step of receiving an audio input signal from a second client computing device. The method may include the step of using a first audio discriminative model to generate a first discriminative score and using a second audio discriminative model to generate a second discriminative score. The method may include selecting a profile from a plurality of candidate profiles based on a first identification score and a second identification score. The method may include the step of selecting digital components based on the profile. The method may include sending a digital component to a second client computing device.
本開示の少なくとも1つの態様によれば、音声作動式のシステムにおいてコンテンツをカスタマイズするための方法を実行するように構成されたデジタルアシスタントデバイスが、提供される。たとえば、デジタルアシスタントデバイスは、オーディオドライバと、トランスデューサと、入力オーディオ信号を検出するためのセンサと、プリプロセッサコンポーネントとを備え得る。プリプロセッサコンポーネントは、オーディオドライバ、トランスデューサ、およびセンサに結合され得る。プリプロセッサコンポーネントは、フィルタリングされた入力オーディオ信号を生成するために入力オーディオ信号をフィルタリングすることができる。プリプロセッサコンポーネントは、フィルタリングされた入力オーディオ信号をデータパケットに変換することができる。プリプロセッサコンポーネントは、データ処理システムにデータパケットを送信することができる。データ処理システムは、コンテンツセレクタコンポーネント、インターフェース、および認証コンポーネントを実行する1つまたは複数のプロセッサおよびメモリを備え得る。データ処理システムは、第1のクライアントコンピューティングデバイスの位置を受け取ることができる。第1のクライアントコンピューティングデバイスは、第1のオーディオ識別モデルに関連付けられ得る。データ処理システムは、第1のクライアントコンピューティングデバイスの位置がデジタルアシスタントデバイスまで所定の距離以内にあると判定することができる。データ処理システムは、第1のクライアントコンピューティングデバイスの位置がデジタルアシスタントデバイスまで所定の距離以内にあるという判定に基づいて、第1のクライアントコンピューティングデバイスの第1のオーディオ識別モデルへのアクセスをデジタルアシスタントデバイスに提供することができる。デジタルアシスタントデバイスは、第2のオーディオ識別モデルに関連付けられ得る。データ処理システムは、第1のオーディオ識別モデルを使用して第1の識別スコアを生成し、第2のオーディオ識別モデルを使用して第2の識別スコアを生成することができる。データ処理システムは、第1の識別スコアおよび第2の識別スコアに基づいて複数の候補プロファイルからプロファイルを選択することができる。データ処理システムは、複数の候補プロファイルから選択されたプロファイルに基づいてデジタルコンポーネントを選択することができる。データ処理システムは、オーディオ入力信号に応答して第2のクライアントコンピューティングデバイスにデジタルコンポーネントを送信することができる。 According to at least one aspect of the disclosure, a digital assistant device configured to perform a method for customizing content in a voice-operated system is provided. For example, a digital assistant device may include an audio driver, a transducer, a sensor for detecting an input audio signal, and a preprocessor component. Preprocessor components can be coupled to audio drivers, transducers, and sensors. The preprocessor component can filter the input audio signal to produce a filtered input audio signal. The preprocessor component can convert the filtered input audio signal into data packets. The preprocessor component can send data packets to the data processing system. The data processing system may include one or more processors and memory running content selector components, interfaces, and authentication components. The data processing system can receive the location of the first client computing device. The first client computing device can be associated with the first audio discriminative model. The data processing system can determine that the location of the first client computing device is within a predetermined distance to the digital assistant device. The data processing system digitally accesses the first audio identification model of the first client computing device based on the determination that the position of the first client computing device is within a predetermined distance to the digital assistant device. Can be provided to assistant devices. The digital assistant device can be associated with a second audio discriminative model. The data processing system can use the first audio discriminative model to generate the first discriminative score and the second audio discriminative model to generate the second discriminative score. The data processing system can select a profile from a plurality of candidate profiles based on the first identification score and the second identification score. The data processing system can select digital components based on a profile selected from a plurality of candidate profiles. The data processing system can send digital components to the second client computing device in response to the audio input signal.
これらのおよびその他の態様および実装が、下で詳細に検討される。上述の情報および下の詳細な説明は、様々な態様および実装の例示的な例を含み、主張される態様および実装の本質および特徴を理解するための概要または枠組みを提供する。図面は、様々な態様および実装を例示し、さらに理解させ、本明細書の一部に組み込まれ、本明細書の一部を構成する。 These and other aspects and implementations are discussed in detail below. The information above and the detailed description below include exemplary examples of various aspects and implementations and provide an overview or framework for understanding the essence and characteristics of the claimed aspects and implementations. The drawings exemplify, further understand, and incorporate, and constitute parts of this specification, various aspects and implementations.
添付の図面は、正しい縮尺で描かれるように意図されていない。様々な図面における同様の参照番号および参照指示は、同様の要素を示す。明瞭にする目的で、あらゆる図面においてあらゆるコンポーネントがラベル付けされるとは限らないことがある。 The attached drawings are not intended to be drawn to the correct scale. Similar reference numbers and reference instructions in various drawings indicate similar elements. Not all components may be labeled in every drawing for clarity purposes.
以下は、パケット化されたオーディオ信号の認証のための方法、装置、およびシステムに関連する様々な概念ならびにそれらの方法、装置、およびシステムの実装のより詳細な説明である。上で導入され、下でより詳細に検討される様々な概念は、多数の方法のいずれかで実装されてよい。 The following is a more detailed description of the various concepts associated with methods, devices, and systems for authenticating packetized audio signals and their implementation of the methods, devices, and systems. The various concepts introduced above and discussed in more detail below may be implemented in any of a number of ways.
本開示は、概して、音声作動式のコンピュータネットワーク環境においてパケット化されたオーディオ信号内のユーザのアイデンティティ(identity)を肯定的なユーザの同意の下に特定するかまたは検証するためのデータ処理システムを対象とする。データ処理システムは、その認証コンポーネントによって、効率、効果、およびユーザの同意の下にユーザを識別するかまたは検証するために必要とされるリソースを改善することができる。たとえば、認証コンポーネントは、オーディオ識別モデルが異なるクライアントコンピューティングデバイスの間で共有されるかまたは協力してアクセスされることを可能にし得る。オーディオ識別モデルの生成は、計算負荷が高くなり得る。オーディオ識別モデルが複数の異なるクライアントコンピューティングデバイスにおいて使用されることを可能にすることは、オーディオ識別モデルがシステム内の各クライアントコンピューティングデバイスに関して複数回生成されるのではなく1回だけ生成されるのでシステムの計算リソースを節約する。さらに、オーディオ識別モデルの訓練は、データ処理システムへのサンプルオーディオファイルのデータ送信を含み得る。生成されるオーディオ識別モデルの数を減らすことは、データ処理システムに送信されるサンプルオーディオファイルの量を減らし、システムの帯域幅などのネットワークリソースを節約する。 The present disclosure generally provides a data processing system for identifying or verifying a user's identity within a packetized audio signal in a voice-operated computer network environment with the consent of a positive user. set to target. The authentication component of a data processing system can improve efficiency, effectiveness, and the resources needed to identify or validate a user with the consent of the user. For example, authentication components can allow audio discriminative models to be shared or cooperatively accessed between different client computing devices. Generating an audio discriminative model can be computationally expensive. Allowing the audio discriminative model to be used on multiple different client computing devices means that the audio discriminative model is generated only once, rather than multiple times for each client computing device in the system. So save system computing resources. In addition, training the audio discriminative model may include sending data of sample audio files to a data processing system. Reducing the number of audio discriminative models generated reduces the amount of sample audio files sent to the data processing system and saves network resources such as system bandwidth.
データ処理システムは、より正確な識別を可能にするオーディオ識別モデルを生成することもできる。単一の物理的位置からのオーディオサンプルから生成されるオーディオ識別モデルは、異なる物理的位置からのオーディオサンプルを与えられるときに識別を行うのに不向きである可能性がある。たとえば、異なる位置の各々は、単一の位置のオーディオ識別モデルを異なる物理的位置からのオーディオサンプルにおける識別を行うのに不向きにし得る異なる環境雑音レベルまたはその他の形態の干渉を含み得る。異なるクライアントコンピューティングデバイスと共有されるとき、データ処理システムは、異なる物理的位置からのオーディオサンプルによってオーディオ識別モデルを更新することができ、それは、識別を行う際に比較的高い正確さを持ち得るより堅牢なオーディオ識別モデルをもたらすことができる。より正確な識別は、デジタルコンポーネントがデータ処理システムとクライアントコンピューティングデバイスとの間で(たとえば、複数回の送信の形態の)複数回の訂正を必要とするのではなく最初のプロセス中に正しくカスタマイズまたは選択され得るのでシステムリソースを節約することができる。加えて、異なる位置からのオーディオサンプルの使用は、オーディオサンプルが新しい要求の形態でデータ処理システムに既に供給されているので計算がいらない。たとえば、オーディオサンプルは、訓練オーディオサンプルに関してデータ処理システムによって成される余分なまたは追加の要求でない。訓練のための追加のオーディオサンプルを要求しなくてよいことは、ネットワークリソースの使用も削減する。 Data processing systems can also generate audio discrimination models that allow for more accurate identification. Audio discrimination models generated from audio samples from a single physical location can be unsuitable for discrimination given audio samples from different physical locations. For example, each of the different positions may contain different environmental noise levels or other forms of interference that may make the single position audio discriminative model unsuitable for making discrimination in audio samples from different physical positions. When shared with different client computing devices, the data processing system can update the audio identification model with audio samples from different physical locations, which can have relatively high accuracy in making the identification. It can provide a more robust audio identification model. More accurate identification is that the digital component is correctly customized during the initial process rather than requiring multiple corrections (for example, in the form of multiple transmissions) between the data processing system and the client computing device. Or it can be selected, which saves system resources. In addition, the use of audio samples from different locations is not computationally expensive as the audio samples are already supplied to the data processing system in the form of new requirements. For example, the audio sample is not an extra or additional request made by the data processing system for the training audio sample. Not having to request additional audio samples for training also reduces the use of network resources.
図1は、音声作動式のデータパケット(またはその他のプロトコル)に基づくコンピュータネットワーク環境においてパケット化されたオーディオ信号に応答してコンテンツをカスタマイズするための例示的なシステム100を示す。システム100は、少なくとも1つのデータ処理システム102を含み得る。データ処理システム102は、少なくとも1つのプロセッサを有する少なくとも1つのサーバを含み得る。たとえば、データ処理システム102は、少なくとも1つのデータセンターまたはサーバファーム内に置かれた複数のサーバを含み得る。データ処理システム102は、入力オーディオ信号から、要求および要求に関連するトリガキーワードを決定し得る。要求およびトリガに対するデータ処理システムの応答は、ユーザに依存し得る。たとえば、データ処理システム102は、どのユーザが入力オーディオ信号を与えたかに基づいて異なる応答を選択し得る。データ処理システム102は、音声認識を使用して、どのユーザが入力オーディオ信号を与えたかを判定し得る。データ処理システム102は、レンダリングされるときにオーディオ出力または音波を提供する1つまたは複数のオーディオファイルを含み得る1つまたは複数のデジタルコンポーネントによって要求に応答することができる。デジタルコンポーネントは、オーディオに基づくコンテンツに加えてその他のコンテンツフォーマット(たとえば、テキスト、動画、または画像フォーマットのコンテンツ)を含み得る。
FIG. 1 shows an
データ処理システム102は、複数の論理的にグループ分けされたサーバを含み、分散型コンピューティング技術を促進することができる。サーバの論理的グループは、データセンター、サーバファーム、またはマシンファームと呼ばれることがある。サーバは、地理的に散らされ得る。データセンターまたはマシンファームは、単一の主体によって管理されてもよく、またはマシンファームは、複数のマシンファームを含み得る。各マシンファーム内のサーバは、異種であることができる--サーバまたはマシンのうちの1つまたは複数が、1つまたは複数の種類のオペレーティングシステムプラットフォームに応じて動作することができる。データ処理システム102は、関連するストレージシステムと一緒に、たとえば、エンタープライズデータセンターに置かれた1つまたは複数の高密度ラックシステムに収容されるデータセンターのサーバを含み得る。このようにしてまとめられたサーバを有するデータ処理システム102は、サーバおよび高性能ストレージシステムを局所的な高性能ネットワーク上に置くことによってシステムの管理の容易性、データセキュリティ、システムの物理的セキュリティ、およびシステムの性能を改善し得る。サーバおよびストレージシステムを含み、それらを高度なシステム管理ツールに結合するデータ処理システム102のコンポーネントのすべてまたは一部の集中化は、電力および処理の要件を減らし、帯域幅の使用を削減する、サーバリソースのより効率的な使用を可能にする。
The
データ処理システム102は、少なくとも1つの自然言語プロセッサ(NLP)コンポーネント112、少なくとも1つのインターフェース110、少なくとも1つの認証コンポーネント114、少なくとも1つのコンテンツセレクタコンポーネント118、少なくとも1つのオーディオ信号ジェネレータコンポーネント120、少なくとも1つのダイレクトアクションアプリケーションプログラミングインターフェース(API)116、および少なくとも1つのデータリポジトリ122を含み得る。NLPコンポーネント112、インターフェース110、認証コンポーネント114、コンテンツセレクタコンポーネント118、オーディオ信号ジェネレータコンポーネント120、およびダイレクトアクションAPI 116は、少なくとも1つのコンピュータネットワーク105を介してデータリポジトリ122およびその他のコンピューティングデバイス(たとえば、クライアントコンピューティングデバイス104またはコンテンツプロバイダコンピューティングデバイス106)と通信するように構成された少なくとも1つの処理ユニット、サーバ、仮想サーバ、回路、エンジン、エージェント、器具、またはプログラマブル論理アレイなどのその他の論理デバイスをそれぞれ含み得る。ネットワーク105は、インターネット、ローカルエリアネットワーク、広域ネットワーク、メトロエリアネットワーク、またはその他のエリアネットワークなどのコンピュータネットワーク、イントラネット、衛星ネットワーク、音声またはデータモバイル電話通信ネットワークなどのその他のコンピュータネットワーク、およびそれらの組合せを含み得る。
The
ネットワーク105は、表示ネットワーク(display network)、たとえば、コンテンツ配置または検索エンジン結果システムに関連付けられるか、または第三者のデジタルコンポーネントをデジタルコンポーネント配置キャンペーン(digital component placement campaign)の一部として含むのにふさわしいインターネット上で利用可能な情報リソースのサブセットを含み得る。ネットワーク105は、クライアントコンピューティングデバイス104によって提示されるか、出力されるか、レンダリングされるか、または表示され得るウェブページ、ウェブサイト、ドメイン名、またはユニフォームリソースロケータなどの情報リソースにアクセスするためにデータ処理システム102によって使用され得る。たとえば、ネットワーク105を介して、クライアントコンピューティングデバイス104のユーザは、コンテンツプロバイダコンピューティングデバイス106によって提供される情報またはデータにアクセスすることができる。
ネットワーク105は、たとえば、ポイントツーポイントネットワーク、ブロードキャストネットワーク、広域ネットワーク、ローカルエリアネットワーク、電気通信ネットワーク、データ通信ネットワーク、コンピュータネットワーク、非同期転送モード(ATM)ネットワーク、同期光ネットワーク(SONET)ネットワーク、同期デジタルハイアラーキ(SDH: Synchronous Digital Hierarchy)ネットワーク、ワイヤレスネットワーク、または有線ネットワーク、およびそれらの組合せを含み得る。ネットワーク105は、赤外線チャネルまたは衛星帯域などのワイヤレスリンクを含み得る。ネットワーク105のトポロジーは、バス型、スター型、またはリング型ネットワークトポロジーを含むことがある。ネットワーク105は、アドバンストモバイル電話プロトコル(「AMPS: advanced mobile phone protocol」)、時分割多元接続(「TDMA」)、符号分割多元接続(「CDMA(登録商標)」)、移動体通信用グローバルシステム(「GSM(登録商標): global system for mobile communication」)、汎用パケット無線サービス(「GPRS: general packet radio services」)、またはユニバーサル移動体通信システム(「UMTS: universal mobile telecommunications system」)を含むモバイルデバイスの間で通信するために使用される任意の1つのプロトコルまたは複数のプロトコルを使用するモバイル電話ネットワークを含み得る。異なる種類のデータは、異なるプロトコルによって送信されてもよく、または同じ種類のデータが、異なるプロトコルによって送信されてもよい。
The
クライアントコンピューティングデバイス104およびコンテンツプロバイダコンピューティングデバイス106は、ネットワーク105を介して互いにまたはデータ処理システム102と通信するためのプロセッサを有するコンピューティングデバイスなどの少なくとも1つの論理デバイスをそれぞれ含み得る。クライアントコンピューティングデバイス104およびコンテンツプロバイダコンピューティングデバイス106は、少なくとも1つのサーバ、プロセッサ、もしくはメモリ、または少なくとも1つのデータセンターに置かれた複数の計算リソースもしくはサーバをそれぞれ含み得る。クライアントコンピューティングデバイス104およびコンテンツプロバイダコンピューティングデバイス106は、デスクトップコンピュータ、ラップトップ、タブレット、携帯情報端末、スマートフォン、ポータブルコンピュータ、シンクライアントコンピュータ、仮想サーバ、スピーカに基づくアシスタントデバイス、またはその他のコンピューティングデバイスなどの少なくとも1つのコンピューティングデバイスをそれぞれ含み得る。
The
クライアントコンピューティングデバイス104は、少なくとも1つのセンサ140、少なくとも1つのトランスデューサ142、少なくとも1つのオーディオドライバ144、少なくとも1つのスピーカ146、および少なくとも1つのプリプロセッサ148を含み得る。センサ140は、マイクロフォンまたはオーディオ入力センサを含み得る。センサ140は、GPSセンサ、近接センサ、環境光センサ、温度センサ、モーションセンサ、加速度計、またはジャイロスコープのうちの少なくとも1つをさらに含み得る。トランスデューサ142は、オーディオ入力を電子信号に変換し得る。オーディオドライバ144は、オーディオ入力を処理するかまたはオーディオ出力を提供するように、クライアントコンピューティングデバイス104のコンポーネントの中でもとりわけセンサ140、トランスデューサ142、またはオーディオドライバ144を制御するためにクライアントコンピューティングデバイス104の1つまたは複数のプロセッサによって実行されるスクリプトまたはプログラムを含み得る。スピーカ146は、オーディオ出力信号を送信(またはレンダリング)し得る。
The
プリプロセッサコンポーネント148は、オーディオドライバ144、トランスデューサ142、およびセンサ140と結合され得る。プリプロセッサコンポーネント148は、信号がデータ処理システム102に送信されるかまたはクライアントコンピューティングデバイス104のその他のコンポーネントによって処理される前に受け取られた信号に対する機能を実行する1つもしくは複数のプロセッサであり得るかまたはそのような1つもしくは複数のプロセッサを含み得る。たとえば、プリプロセッサコンポーネント148は、フィルタリングされた入力オーディオ信号を生成するためにトランスデューサ142によって検出された入力オーディオ信号(またはそれ以外の方法でクライアントコンピューティングデバイス104によって受け取られる入力オーディオ信号)をフィルタリングすることができる。プリプロセッサ148によるフィルタリングは、入力オーディオ信号内の雑音のフィルタリング(もしくは削減)、入力オーディオ信号内の所定の周波数の増幅、入力オーディオ信号内の所定の周波数の削減、または入力オーディオ信号のアップサンプリングもしくはダウンサンプリングを含み得る。プリプロセッサコンポーネント148は、フィルタリングされた入力オーディオ信号をデータパケットに変換し、データパケットをネットワーク105を介してデータ処理システム102に送信することができる。
The preprocessor component 148 can be combined with an audio driver 144, a transducer 142, and a
クライアントコンピューティングデバイス104は、(センサ140もしくはトランスデューサ142によって)音声の問い合わせをクライアントコンピューティングデバイス104にオーディオ入力として入力し、データ処理システム102(またはコンテンツプロバイダコンピューティングデバイス106)から提供され得るコンピュータによって生成された音声の形態のオーディオ出力を受け取るエンドユーザに関連付けられ得る。クライアントコンピューティングデバイス104は、スピーカ146からオーディオ出力を出力することができる。コンピュータによって生成された音声は、本物の人からの録音またはコンピュータによって生成された言葉を含み得る。
The
コンテンツプロバイダコンピューティングデバイス106は、クライアントコンピューティングデバイス104によって表示するためのオーディオに基づくデジタルコンポーネントをオーディオ出力デジタルコンポーネントとして提供することができる。デジタルコンポーネントは、「タクシーを呼びましょうか。」と述べる音声に基づくメッセージなどの物またはサービスの申し出を含み得る。たとえば、コンテンツプロバイダコンピューティングデバイス106は、音声に基づく問い合わせに応答して提供され得る一連のデジタルオーディオコンポーネントを記憶するためのメモリを含み得る。コンテンツプロバイダコンピューティングデバイス106は、オーディオに基づくデジタルコンポーネント(またはその他のデジタルコンポーネント)をデータ処理システム102に提供することもでき、データ処理システム102において、それらのオーディオに基づくデジタルコンポーネント(またはその他のデジタルコンポーネント)は、クライアントコンピューティングデバイス104に送信するためにデータリポジトリ122に記憶され得る。データ処理システム102は、デジタルオーディオコンポーネントを選択し、デジタルオーディオコンポーネントをクライアントコンピューティングデバイス104に提供する(または提供するようにコンテンツプロバイダコンピューティングデバイス106に命令する)ことができる。デジタルコンポーネントは、クライアントコンピューティングデバイス104のユーザを認証するために生成されるセキュリティの質問を含み得る。オーディオに基づくデジタルコンポーネントは、オーディオのみであることが可能であり、またはテキスト、画像、または動画データと組み合わされることが可能である。
The content
データリポジトリ122は、1つまたは複数のローカルまたは分散型データベースを含むことができ、データベース管理システムを含むことができる。データリポジトリ122は、コンピュータデータストレージまたはメモリを含むことができ、とりわけ、1つまたは複数のオーディオ識別モデル124(図1においてはAIMと略される)、プロファイル126、コンテンツデータ128、またはテンプレート130を記憶することができる。コンテンツデータ128は、デジタルコンポーネントまたは関連するメタデータと、クライアントコンピューティングデバイス104との1つまたは複数の通信セッションの一部であることが可能である入力オーディオメッセージとを含むことができる。テンプレート130は、クライアントコンピューティングデバイス104との通信において使用され得るデータ構造を含むことができる。テンプレート130は、データ処理システム102が、たとえば、コンテンツデータ128、デジタルコンポーネント、またはその他のデータによって満たすことができる1つまたは複数のプレースホルダを含み得る。
The
認証コンポーネント114は、オーディオ識別モデル124を使用して音声認識を実行する(たとえば、ユーザの同意の下に入力オーディオ信号に基づいて第2のユーザから第1のユーザを識別する)ことができる。オーディオ識別モデル124は、ユーザの同意の下に所与のユーザの音声の特徴を示すデータ構造を含み得る。たとえば、オーディオ識別モデル124は、ユーザの発話のスペクトログラムを含む声紋であることが可能である。オーディオ識別モデル124は、ユーザが話すときに使用する可能性がある周波数およびパターンを示し得る。認証コンポーネント114は、ユーザの検証のために(たとえば、ユーザに関連するオーディオ識別モデル124との入力信号の1対1のマッチングにおいて、ユーザが、ユーザが主張する人物であると判定するために)またはユーザの識別のために(たとえば、入力オーディオ信号をN個のオーディオ識別モデル124に通してどのオーディオ識別モデル124がユーザのものである可能性が最も高いかを判定することによって1対Nのマッチングにおいてユーザの同意の下にユーザを識別するために)オーディオ識別モデル124を使用することができる。
The authentication component 114 can use the
データ処理システム102は、ユーザが1つまたは複数のサンプル入力オーディオ信号を与えるように要求することによって所与のユーザに関してオーディオ識別モデル124を生成することができる。サンプル入力オーディオ信号は、テキストに依存しない(たとえば、ユーザがランダムなサンプルを与える)かまたはテキストに依存する(たとえば、ユーザが予め定義されたスクリプトを読むことによって入力オーディオ信号を生成する)ことが可能である。ユーザは、同意の下に、クライアントコンピューティングデバイス104を介してデータ処理システム102にサンプル入力オーディオ信号を与えることができる。生成されると、データ処理システム102は、サンプル入力信号を送信したクライアントコンピューティングデバイス104のインジケーションに関連してオーディオ識別モデル124をデータリポジトリ122に記憶することができる。一部の実装においては、ユーザが明示的な承認を与えるまで、認証コンポーネント114は、所与のクライアントコンピューティングデバイス104において受け取られたサンプル入力オーディオ信号を使用して生成されたオーディオ識別モデル124を用いて所与のクライアントコンピューティングデバイス104からの入力オーディオ信号を処理することのみが可能である。たとえば、明示的な承認がないと、認証コンポーネント114は、異なるユーザおよび異なるクライアントコンピューティングデバイス104からの入力オーディオサンプルを処理するために第1のユーザのオーディオ識別モデル124を使用しない。
The
データ処理システム102は、オーディオ識別モデル124の各々をプロファイル126に関連付けることができる。たとえば、オーディオ識別モデル124は、プロファイル126またはクライアントコンピューティングデバイス104に対応し得る。プロファイル126は、入力された問い合わせに応答して提供するデジタルコンポーネントを選択するときにデータ処理システム102が使用することができるポリシー、データ、デバイス情報、またはデータ構造を含み得る。たとえば、プロファイルは、デジタルコンポーネントの選択のためのプリファレンスまたは規則を含み得る。プロファイル126およびオーディオ識別モデル124は、データ処理システム102、クライアントコンピューティングデバイス104、またはそれら両方に記憶され得る。
The
データ処理システム102は、入力オーディオ信号をデータ処理システム102のインターフェース110に伝達し、出力オーディオ信号をレンダリングするようにクライアントコンピューティングデバイス104のコンポーネントを駆動するためのアプリなどの、クライアントコンピューティングデバイス104にインストールされたアプリケーション、スクリプト、またはプログラムを含むことができる。データ処理システム102は、入力オーディオ信号を含むかまたは識別するデータパケットまたはその他の信号を受け取ることができる。たとえば、データ処理システム102は、入力オーディオ信号を受け取るためにNLPコンポーネント112を実行するかまたは走らせることができる。トランスデューサ142またはセンサ140は、入力オーディオ信号を検出することができる。NLPコンポーネント112は、入力信号をオーディオ波形の記憶された代表的な組と比較し、最も近い一致を選択することによって入力オーディオ信号を認識されたテキストに変換するかまたは解析することができる。代表的な波形は、入力信号の大きな組全体で生成され得る。ユーザは、入力信号の一部を与えることができる。オーディオ信号が認識されたテキストに変換されると、NLPコンポーネント112は、テキストを、たとえば、学習フェーズによってシステム100が行うことができるアクションに関連付けられる言葉とマッチングし得る。トランスデューサ142、オーディオドライバ144、またはその他のコンポーネントを介して、クライアントコンピューティングデバイス104は、(たとえば、ネットワーク105を介して)入力オーディオ信号をデータ処理システム102に提供することができ、データ処理システム102において、入力オーディオ信号は、(たとえば、インターフェース110によって)受け取られ、NLPコンポーネント112に提供されるか、またはデータリポジトリ122にコンテンツデータ128として記憶され得る。
The
NLPコンポーネント112は、入力オーディオ信号を取得することができる。入力オーディオ信号から、NLPコンポーネント112は、少なくとも1つの要求または要求に対応する少なくとも1つのトリガキーワードを識別することができる。要求は、入力オーディオ信号の意図または主題を示すことができる。トリガキーワードは、行われる可能性が高いアクションの種類を示すことができる。たとえば、NLPコンポーネント112は、夜に食事会に参加し、映画を見るために家を出る少なくとも1つの要求を識別するために入力オーディオ信号を解析することができる。トリガキーワードは、行われるアクションを示す少なくとも1つの単語、語句、語根もしくは部分的な単語、または派生語を含み得る。たとえば、入力オーディオ信号からのトリガキーワード「go」または「to go to」は、輸送の必要性を示し得る。この例において、入力オーディオ信号(または識別された要求)は、輸送の意図を直接表さないが、トリガキーワードが、輸送が要求によって示される少なくとも1つのその他のアクションの補助的なアクションであることを示す。 The NLP component 112 can acquire the input audio signal. From the input audio signal, the NLP component 112 can identify at least one request or at least one trigger keyword corresponding to the request. The request can indicate the intent or subject of the input audio signal. Trigger keywords can indicate the types of actions that are likely to take place. For example, NLP component 112 can analyze the input audio signal to identify at least one request to attend a dinner at night and leave home to watch a movie. Trigger keywords can include at least one word, phrase, root or partial word, or derivative that indicates the action to be taken. For example, the trigger keyword "go" or "to go to" from the input audio signal may indicate the need for transport. In this example, the input audio signal (or identified request) does not directly represent the intent of transport, but the trigger keyword is that transport is an adjunct to at least one other action indicated by the request. Is shown.
コンテンツセレクタコンポーネント118は、データリポジトリ122からデジタルコンポーネントを取得することができ、デジタルコンポーネントは、コンテンツデータ128の一部として記憶され得る。コンテンツセレクタコンポーネント118は、たとえば、コンテンツデータ128からデジタルコンポーネントを選択するかまたはそうでなければ識別するためにデータリポジトリ122に問い合わせることができる。コンテンツ選択コンポーネント118は、入力された問い合わせに応答して、カスタムされたデジタルコンポーネントを選択または生成するために選択されたプロファイル126を使用することができる。コンテンツセレクタコンポーネント118は、コンテンツプロバイダコンピューティングデバイス106からデジタルコンポーネントを選択することもできる。たとえば、データ処理システム102から受け取られた問い合わせに応じて、コンテンツプロバイダコンピューティングデバイス106は、クライアントコンピューティングデバイス104による最終出力のためにデータ処理システム102(またはそのコンポーネント)にデジタルコンポーネントを提供することができる。
The content selector component 118 can retrieve the digital component from the
オーディオ信号ジェネレータコンポーネント120は、デジタルコンポーネントを含む出力信号を生成するかまたはそうでなければ取得することができる。たとえば、データ処理システム102は、オーディオ信号ジェネレータコンポーネントを実行してデジタルコンポーネントに対応する出力信号を生成または作成することができる。データ処理システム102のインターフェース110は、クライアントコンピューティングデバイス104にコンピュータネットワーク105を介して出力信号を含む1つまたは複数のデータパケットを提供または送信することができる。たとえば、データ処理システム102は、データリポジトリ122からまたはオーディオ信号ジェネレータコンポーネント120からクライアントコンピューティングデバイス104に出力信号を提供することができる。インターフェース110は、データ処理システム102がデータを受信し、送信することを可能にするネットワークポートデータポートまたはワイヤレス無線などのハードウェアインターフェースであることが可能である。インターフェース110は、グラフィックスに基づくことが可能である。たとえば、インターフェース110は、ユーザがデータを入力するかまたはそれ以外の方法でデータ処理システム102とインタラクションすることを可能にするグラフィカルユーザインターフェースであることが可能である。データ処理システム102は、クライアントコンピューティングデバイス104に出力信号を提供するようにコンテンツプロバイダコンピューティングデバイス106にデータパケットの送信によって命じることもできる。出力信号は、データ処理システム102(またはその他のコンピューティングデバイス)からクライアントコンピューティングデバイス104への1つもしくは複数のデータパケット(またはその他の通信プロトコル)として取得されるか、生成されるか、そのような1つもしくは複数のデータパケット(またはその他の通信プロトコル)に変換されるか、あるいはそのような1つもしくは複数のデータパケット(またはその他の通信プロトコル)として送信されることが可能である。
The audio signal generator component 120 can generate or otherwise obtain an output signal that includes a digital component. For example, the
コンテンツセレクタコンポーネント118は、リアルタイムのコンテンツ選択プロセスの一部として入力オーディオ信号のアクションのためのデジタルコンポーネントを選択することができる。たとえば、デジタルコンポーネントは、入力オーディオ信号に直接応答して対話式にオーディオ出力として送信するためにクライアントコンピューティングデバイスに提供され得る。デジタルコンポーネントを識別し、デジタルコンポーネントをクライアントコンピューティングデバイス104に提供するためのリアルタイムのコンテンツ選択プロセスは、入力オーディオ信号の時間から1分以内に行われ、リアルタイムと考えられ得る。
Content selector component 118 can select digital components for the action of the input audio signal as part of the real-time content selection process. For example, digital components may be provided to client computing devices for interactively transmitting as audio output in response to an input audio signal. The real-time content selection process for identifying the digital component and delivering the digital component to the
デジタルコンポーネントに対応する出力信号、たとえば、クライアントコンピューティングデバイス104にインターフェース110およびコンピュータネットワーク105を介して送信されたオーディオ信号ジェネレータコンポーネント120によって取得または生成された出力信号は、出力信号に対応する音波を生成するためにスピーカ146を駆動するためにクライアントコンピューティングデバイス104にオーディオドライバ144を実行させることができる。音波は、デジタルコンポーネントに対応する言葉を含み得る。
The output signal corresponding to the digital component, for example, the output signal acquired or generated by the audio signal generator component 120 transmitted through the interface 110 and the
データ処理システムのダイレクトアクションAPI 116は、トリガキーワードに基づいてアクションデータ構造を生成することができる。ダイレクトアクションAPI 116は、データ処理システム102によって決定されたようにエンドユーザの意図を満足させるために指定されたアクションを実行することができる。その入力において指定されたアクションに応じて、ダイレクトアクションAPI 116は、ユーザの要求を満たすために必要とされるパラメータを識別するコードまたはダイアログスクリプトを実行することができる。アクションデータ構造は、要求に応じて生成され得る。
The direct action API 116 of the data processing system can generate action data structures based on trigger keywords. The direct action API 116 can perform the specified action to satisfy the end user's intent as determined by the
ダイレクトアクションAPI 116は、データリポジトリ122からのコンテンツデータ128(またはパラメータ、ポリシー、もしくはデジタルコンポーネント)と、カーシェアサービスの車を予約するために位置、時間、ユーザアカウント、ロジスティクス(logistical)、またはその他の情報を決定するための、エンドユーザの同意の下にクライアントコンピューティングデバイス104から受け取られたデータとを取得することができる。コンテンツデータ128は、アクションデータ構造に含まれ得る。アクションデータ構造に含まれるコンテンツが認証のために使用されるエンドユーザデータを含むとき、データは、データリポジトリ122に記憶される前にハッシュ関数を通され得る。
Direct Action API 116 includes content data 128 (or parameters, policies, or digital components) from the
データ処理システム102は、認証コンポーネント114も含み得る。認証コンポーネント114は、入力オーディオ信号に基づいてユーザを認識または識別することができる。ユーザを識別または認識した後、認証コンポーネント114は、コンテンツセレクタコンポーネント118がデジタルコンポーネントの選択に使用することができるプロファイル126を選択し得る。
The
認証コンポーネント114は、異なるクライアントコンピューティングデバイス104がオーディオ識別モデル124を共有することを可能にし得る。たとえば、1つまたは複数のオーディオ識別モデル124が、クライアントコンピューティングデバイス104の各々のために生成され、そのクライアントコンピューティングデバイス104に関連付けられ得る。認証コンポーネント114は、オーディオ識別モデル124の各々をクライアントコンピューティングデバイス104の異なるユーザに関連付けることができる。オーディオ識別モデル124を共有しないと、所与のクライアントコンピューティングデバイス104は、そのクライアントコンピューティングデバイス104のオーディオ識別モデル124にのみアクセスすることができる可能性がある。たとえば、クライアントコンピューティングデバイス104は、それぞれのクライアントコンピューティングデバイス104からのオーディオデータを使用して生成されたオーディオ識別モデル124にアクセスすることができるが、異なるクライアントコンピューティングデバイス104からのオーディオデータを使用して生成されたオーディオ識別モデル124にアクセスすることはできない。
The authentication component 114 may allow different
オーディオ識別モデル124を共有することは、第2のクライアントコンピューティングデバイス104から受け取られた入力オーディオ信号を用いて第1のクライアントコンピューティングデバイス104のオーディオ識別モデル124を使用するためのアクセスを認証コンポーネント114に提供することを含み得る。共有することは、第1のユーザに関連するクライアントコンピューティングデバイス104に第2のユーザに関連するオーディオ識別モデル124へのアクセスを提供することを含み得る。たとえば、第1のユーザは、第1のおよび第2のクライアントコンピューティングデバイス104の登録されたユーザである可能性がある。第1のおよび第2のクライアントコンピューティングデバイス104は、それぞれのクライアントコンピューティングデバイス104のために共同でまたは別々にのどちらかで生成されるオーディオ識別モデル124にアクセスすることができる。共同のオーディオ識別モデル124は、第1のクライアントコンピューティングデバイス104と第2のクライアントコンピューティングデバイス104との両方(たとえば、2つ以上のクライアントコンピューティングデバイス104)からのオーディオ入力データ含む可能性があり、別々のオーディオ識別モデル124は、単一のクライアントコンピューティングデバイス104からのオーディオ入力データのみを含み得る。第2のユーザは、第3のおよび第4のクライアントコンピューティングデバイス104の登録されたユーザである可能性がある。この例においては、認証コンポーネント114が第1のユーザのオーディオ識別モデル124を第2のユーザと共有する場合、認証コンポーネント114は、第3のおよび第4のクライアントコンピューティングデバイス104によって受け取られた入力オーディオ信号を処理するために第1のおよび第2のクライアントコンピューティングデバイス104に関連するオーディオ識別モデル124を使用することができる。
Sharing the
オーディオ識別モデル124を共有することは、クライアントコンピューティングデバイス104に異なるクライアントコンピューティングデバイス104のオーディオ識別モデル124へのアクセスを提供する認証コンポーネント114のプロセスを含み得る(異なるクライアントコンピューティングデバイス104が異なるユーザに関連付けられることも、異なるユーザに関連付けられないこともがある)。たとえば、第1のクライアントコンピューティングデバイス104は、第1のオーディオ識別モデル124にアクセスすることができ、第2のクライアントコンピューティングデバイス104は、第2のオーディオ識別モデル124にアクセスすることができる。第1のオーディオ識別モデル124を第2のクライアントコンピューティングデバイス104と共有することは、第2のクライアントコンピューティングデバイス104が第1のオーディオ識別モデル124にアクセスすることを可能にし得る。オーディオ識別モデル124へのアクセスを提供することは、クライアントコンピューティングデバイス104にオーディオ識別モデル124への直接的なアクセスを提供すること(たとえば、オーディオ識別モデル124がクライアントコンピューティングデバイス104にダウンロードされるかもしくは送信される)またはオーディオ識別モデル124への間接的なアクセスを提供することを含み得る。たとえば、間接的なアクセスを提供するとき、共有されたオーディオ識別モデル124は、データリポジトリ122に残り得る(たとえば、オーディオ識別モデル124のコピーが、オーディオ識別モデル124が共有されるクライアントコンピューティングデバイス104に送信されない)。間接的なアクセスが提供されるこの例において、認証コンポーネント114は、オーディオ識別モデル124が共有されるクライアントコンピューティングデバイス104から受け取られた入力オーディオ信号の分析に共有されたオーディオ識別モデル124を使用することを認可される。
Sharing the
認証コンポーネント114は、第2のクライアントコンピューティングデバイス104に関連するユーザから明示的な承認を受け取った後にのみ第1のクライアントコンピューティングデバイス104に第2のクライアントコンピューティングデバイス104のオーディオ識別モデル124へのアクセスを提供することができる。たとえば、デフォルトで、クライアントコンピューティングデバイス104は、別のユーザまたはクライアントコンピューティングデバイス104に関連するオーディオ識別モデル124にアクセスすることができない。
The authentication component 114 goes to the first
ユーザは、オーディオ識別モデル124の共有を開始することができる。ユーザは、クライアントコンピューティングデバイス104を介して、データ処理システム102がユーザに関連するオーディオ識別モデル124へのアクセスを提供することを許されるクライアントコンピューティングデバイス104の識別子を追加することができる。たとえば、ユーザのクライアントコンピューティングデバイス104(たとえば、モバイルデバイス)によって実行されるグラフィカルユーザインターフェースを介して、ユーザは、友達のスピーカに基づくアシスタントデバイスのIDを入力する可能性がある。それから、認証コンポーネント114は、友達のスピーカに基づくアシスタントデバイスにユーザに関連するオーディオ識別モデル124のうちの1つまたは複数へのアクセスを提供することができる。
The user can start sharing the
認証コンポーネント114は、オーディオ識別モデル124の共有を開始することができる。認証コンポーネント114は、1つまたは複数のユーザまたはクライアントコンピューティングデバイス104の間の関連付けに基づいて共有を開始することができる。たとえば、ユーザを「家族グループ」またはその他のソーシャルグループに追加した後、認証コンポーネント114は、グループに追加されたユーザと1つまたは複数のオーディオ識別モデル124を共有するための許可をユーザに促すことができる。別の例において、認証コンポーネント114は、ユーザのクライアントコンピューティングデバイス104のうちの1つが別のクライアントコンピューティングデバイス104の所定の近さ、範囲、または距離以内にあるとき、1つまたは複数のオーディオ識別モデル124を共有するための許可をユーザに促すことができる。
Authentication component 114 can initiate sharing of audio
たとえば、クライアントコンピューティングデバイス104は、(ユーザから許可を受け取った後)データ処理システム102に位置情報を周期的に送信することができる。位置情報は、クライアントコンピューティングデバイス104によって(たとえば、セルラの三角測量または搭載されたGPS受信機によって)決定された物理的位置情報を含み得る。位置情報は、クライアントコンピューティングデバイス104の位置の近似値を含み得る。たとえば、Wi-Fiネットワーク名またはIPアドレスが、近似的または相対的位置情報を提供するように働き得る。
For example, the
認証コンポーネント114は、たとえば、インターフェース110を介してクライアントコンピューティングデバイス104の位置情報を受け取ることができる。認証コンポーネント114は、位置情報を送信したクライアントコンピューティングデバイス104をオーディオ識別モデル124と関連付けることができる。関連するオーディオ識別モデル124は、クライアントコンピューティングデバイス104上でもしくはクライアントコンピューティングデバイス104のためにまたは第2のクライアントコンピューティングデバイス104のために生成されたオーディオ識別モデル124であることが可能である。たとえば、位置情報を送信したクライアントコンピューティングデバイス104は、モバイルデバイスであることが可能である。関連するオーディオ識別モデル124は、モバイルデバイスのために生成されたオーディオ識別モデル124、または位置情報を送信したクライアントコンピューティングデバイス104とは異なる位置(たとえば、ユーザの家)に現在あるユーザのスピーカに基づくアシスタントデバイスのために生成されたオーディオ識別モデル124であることが可能である。
The authentication component 114 can receive the location information of the
認証コンポーネント114は、(位置情報を送信した)クライアントコンピューティングデバイス104の位置が第2のクライアントコンピューティングデバイス104まで所定の距離以内にあると判定し得る。所定の距離は、2つのクライアントコンピューティングデバイス104がそれぞれ同じ部屋、家、または建物の中にあるときに2つのクライアントコンピューティングデバイス104が所定の距離以内にあると認証コンポーネント114が判定するように、平均的な部屋、家、または建物のサイズ程度であることが可能である。2つのクライアントコンピューティングデバイス104が所定の距離以内にあると判定することは、2つのクライアントコンピューティングデバイス104の相対的位置に基づくことも可能である。たとえば、認証コンポーネント114は、2つのクライアントコンピューティングデバイス104が同じネットワーク(たとえば、Wi-Fiネットワーク)上にあるか、またはたとえば、アドホックWi-FiネットワークもしくはBluetooth(登録商標)接続によって互いに接続を確立したときに、2つのクライアントコンピューティングデバイス104が互いに相対的にごく近くにあると判定し得る。
The authentication component 114 may determine that the location of the client computing device 104 (which transmitted the location information) is within a predetermined distance to the second
最初に、認証コンポーネント114は、第2のクライアントコンピューティングデバイス104を、認証コンポーネント114が第1のクライアントコンピューティングデバイス104に関連付けるオーディオ識別モデル124と異なるオーディオ識別モデル124に関連付けることができる。
First, the authentication component 114 can associate the second
第1のクライアントコンピューティングデバイス104のオーディオ識別モデル124を第2のクライアントコンピューティングデバイス104と共有する前に、認証コンポーネント114は、認可の通知をインターフェース110を介して第1のクライアントコンピューティングデバイス104に送信し得る。認可の通知は、認証コンポーネント114が第1のクライアントコンピューティングデバイス104に関連する1つまたは複数のオーディオ識別モデル124を第2のクライアントコンピューティングデバイス104と共有するための許可を要求し得る。認証コンポーネント114は、第1のおよび第2のクライアントコンピューティングデバイス104が互いの所定の距離以内にあると認証コンポーネント114が判定することに基づいてインターフェース110を介して認可の通知を第1のクライアントコンピューティングデバイス104に送信し得る。認可の通知は、プッシュ通知、テキストメッセージ、電子メールメッセージ、アプリケーションの通知、またはその他の種類の電子的通信であることが可能である。ユーザが(第1のクライアントコンピューティングデバイス104またはその他のデバイスを介して)認証の通知を選択するか、確認するか、またはそれ以外の方法で認証の通知に応答するとき、第1のクライアントコンピューティングデバイス104は、認証コンポーネント114に承認メッセージを送信することができる。承認メッセージを受け取ることに応じて、認証コンポーネント114は、第1のクライアントコンピューティングデバイス104の1つまたは複数のオーディオ識別モデル124を第2のクライアントコンピューティングデバイス104に関連付けることができる。
Prior to sharing the audio
第1のクライアントコンピューティングデバイスのクライアントオーディオ識別モデル124を第2のクライアントコンピューティングデバイス104に関連付けることは、第1のクライアントデバイスの位置が第2のクライアントコンピューティングデバイスまで所定の距離以内にあるとの判定に基づいて、第1のクライアントコンピューティングデバイス104の1つまたは複数のオーディオ識別モデル124へのアクセスを第2のクライアントコンピューティングデバイス104に提供することを含み得る。たとえば、データ処理システム102は、各クライアントコンピューティングデバイス104がどのオーディオ識別モデル124にアクセスすることを許されるのかを示すデータ構造を保有し得る。オーディオ識別モデル124へのアクセスを提供することは、クライアントコンピューティングデバイス104がオーディオ識別モデル124に今アクセスすることができること(またはオーディオ識別モデル124がクライアントコンピューティングデバイス104からの入力オーディオ信号を分析するために使用され得ること)を示すためにテーブルに参照を追加することを含み得る。一部の実装において、オーディオ識別モデル124へのアクセスを提供することは、オーディオ識別モデル124を送信するかまたはそうでなければクライアントコンピューティングデバイス104もしくはクライアントコンピューティングデバイス104によってアクセスされ得るコンピュータ可読メモリに記憶することを含み得る。
Associating the client
認証コンポーネント114が第2のクライアントコンピューティングデバイス104に第1のクライアントコンピューティングデバイス104のオーディオ識別モデル124へのアクセスを提供すると、第2のクライアントコンピューティングデバイス104は、第2のクライアントコンピューティングデバイス104によって受け取られた入力オーディオ信号の話者を識別する際に第1のクライアントコンピューティングデバイスのオーディオ識別モデル124を使用することができる。クライアントコンピューティングデバイス104は、ローカルで判定を行うための認証コンポーネント114のインスタンスを実行することができ、またはデータ処理システムの認証コンポーネント114のインスタンスが、判定を行うことができる。
When the authentication component 114 provides the second
一例において、第2のクライアントコンピューティングデバイス104は、オーディオに基づく入力された問い合わせを検出することができるスピーカに基づくアシスタントデバイスであることが可能である。スピーカに基づくアシスタントデバイスは、オーディオに基づく入力された問い合わせを、プリプロセッサ148が処理し、入力オーディオ信号としてデータ処理システム102に送信することができる電子信号に変換することができる。データ処理システム102は、入力オーディオ信号に基づいてクライアントコンピューティングデバイス104にデジタルコンポーネントを提供することができる。データ処理システム102は、問い合わせを発話したユーザの識別情報に基づいてデジタルコンポーネントを選択することができる。認証コンポーネント114は、(共有されたオーディオ識別モデル124を含む)オーディオ識別モデル124を使用してどのユーザが問い合わせを発話したかを判定することができる。
In one example, the second
どのユーザが問い合わせを発話したかを判定するために、認証コンポーネント114は、オーディオ識別モデル124の各々を用いて入力オーディオ信号を処理して異なる識別スコアを生成し得る。認証コンポーネント114は、入力オーディオ信号またはその一部をオーディオ識別モデル124の各々への入力として使用し得る。たとえば、スピーカに基づくアシスタントデバイスは、スピーカに基づくアシスタントデバイスの所有者のための第1のオーディオ識別モデル124と、友達がスピーカに基づくアシスタントデバイスと現在共有している所有者の友達のための第2のオーディオ識別モデル124とを含み得る。入力オーディオ信号を受け取ることに応じて、認証コンポーネント114は、入力オーディオ信号を友達のオーディオ識別モデル124および所有者のオーディオ識別モデル124に入力することができる。オーディオ識別モデル124の各々は、それぞれのオーディオ識別モデル124の所有者が入力オーディオ信号を生成した尤度を示し得る0から1までの間の識別スコアを生成することができる。認証コンポーネント114は、入力オーディオ信号を受け取り、識別スコアを生成する隠れマルコフモデル、混合ガウスモデル、パターンマッチングアルゴリズム、またはニューラルネットワークを含み得る。
To determine which user uttered the query, the authentication component 114 may process the input audio signal with each of the audio
データ処理システム102は、異なるプロファイル126に関連してユーザまたはオーディオ識別モデル124の各々を記憶し得る。認証コンポーネント114は、異なる候補プロファイルからプロファイル126を選択し得る。候補プロファイルは、データ処理システム102にオーディオ入力ファイルを送信したクライアントコンピューティングデバイス104がアクセスすることができるプロファイル126の各々であることが可能である。上記の例において、候補プロファイルは、スピーカに基づくアシスタントデバイスの所有者および友達のプロファイル126である。
The
認証コンポーネント114は、オーディオ識別モデル124の各々を用いて入力オーディオ信号を処理することによって認証コンポーネント114が生成する識別スコアに基づいて候補プロファイルからプロファイル126を選択し得る。認証コンポーネント114は、問い合わせを発話したユーザのプロファイルである可能性が最も高いプロファイル126を選択するために識別スコアをランク付けすることができる。
Authentication component 114 may select
オーディオ識別モデル124の各々は、メタデータを含み得る。メタデータは、オーディオ識別モデル124の誤り率、オーディオ識別モデル124の生成に使用されたセンサの種類のインジケーション、オーディオ識別モデル124を生成するために使用されたデータの量のインジケーション、またはオーディオ識別モデル124の生成に使用されたセンサの数を含み得る。認証コンポーネント114は、プロファイルの選択または識別スコアのランク付けの基礎をオーディオ識別モデル124の各々に関するメタデータに置くことができる。
Each of the audio
たとえば、入力オーディオ信号が与えられると、第1のオーディオ識別モデル124は、識別スコア0.9を生成することができ、第2のオーディオ識別モデル124は、識別スコア0.87を生成することができる。第1のオーディオ識別モデル124は、65%の正確さを有することが可能であり、第2のオーディオ識別モデル124は、99%の正確さを有することが可能である。この例において、認証コンポーネント114は、第2のオーディオ識別モデル124が第1のオーディオ識別モデル124よりも高い正確さを有するので、たとえ第2のオーディオ識別モデル124がより低い識別スコアを生成したとしても第2のオーディオ識別モデル124に関連するプロファイルを選択し得る。
For example, given an input audio signal, the first audio
認証コンポーネント114は、共有されたオーディオ識別モデル124へのアクセスを無効にし得る。認証コンポーネント114は、ユーザによって明示されたとき、オーディオ識別モデル124へのアクセスを無効にし得る。たとえば、ユーザは、ユーザのオーディオ識別モデル124への1つまたは複数のクライアントコンピューティングデバイス104のアクセスを無効にするように認証コンポーネント114に命じる無効化メッセージをデータ処理システム102に送信し得る。
Authentication component 114 may disable access to the shared audio
認証コンポーネント114は、共有されたオーディオ識別モデル124へのアクセスを自動的に無効にし得る。無効化は、時間に基づくかまたは位置に基づくことが可能である。たとえば、認証コンポーネント114は、共有されたオーディオ識別モデル124へのアクセスが許された後約1時間から約6時間までの間、約1時間から約12時間までの間、約1時間から約18時間までの間、または約1時間から約24時間までの間に共有されたオーディオ識別モデル124へのアクセスを自動的に無効にし得る。
Authentication component 114 may automatically disable access to the shared audio
共有されたオーディオ識別モデル124の無効化は、位置に基づくことができる。たとえば、認証コンポーネント114は、第1のクライアントコンピューティングデバイス104のオーディオ識別モデル124のうちの1つを第2のクライアントコンピューティングデバイス104と共有する第1のクライアントコンピューティングデバイス104が第2のクライアントコンピューティングデバイス104の周りの所定の距離に存在したと判定し得る。第1のクライアントコンピューティングデバイス104が第2のクライアントコンピューティングデバイス104までの必要とされる距離以内にもはやないと判定するとき、認証コンポーネント114は、共有されたオーディオ識別モデル124への第2のクライアントコンピューティングデバイスのアクセスを無効にし得る。無効化は、自動であることが可能である。たとえば、ユーザは、無効化を承認する必要がない。
The invalidation of the shared audio
認証コンポーネント114は、オーディオ識別モデル124を合併または更新することができる。たとえば、オーディオ識別モデル124がクライアントコンピューティングデバイス104と共有されるとき、クライアントコンピューティングデバイス104は、共有されたオーディオ識別モデル124を使用して入力オーディオ信号を処理することができる。入力オーディオ信号が共有されたオーディオ識別モデル124の所有者による問い合わせを含むと認証コンポーネント114が判定するとき、認証コンポーネント114は、新しい入力オーディオ信号に基づいてオーディオ識別モデル124を更新することができる。
Authentication component 114 can merge or update audio
一部の実装においては、入力オーディオ信号が共有されたオーディオ識別モデル124の所有者による問い合わせを含むと認証コンポーネント114が判定するとき、認証コンポーネント114は、一時的なオーディオ識別モデル124を生成することができる。認証コンポーネント114は、クライアントコンピューティングデバイス104が共有されたオーディオ識別モデル124にアクセスすることができる間、到着する入力オーディオ信号の分析に一時的なオーディオ識別モデル124を使用することができる。
In some implementations, when the authentication component 114 determines that the input audio signal contains a query by the owner of the shared
認証コンポーネント114が共有されたオーディオ識別モデル124へのクライアントコンピューティングデバイスのアクセスを無効にするとき、認証コンポーネント114は、データリポジトリ122から一時的なオーディオ識別モデル124を破棄するか、消去するか、または取り除くことができる。認証コンポーネント114が共有されたオーディオ識別モデル124へのクライアントコンピューティングデバイスのアクセスを無効化するとき、認証コンポーネント114は、一時的なオーディオ識別モデル124を共有されたオーディオ識別モデル124に合併することができる(たとえば、認証コンポーネント114は、一時的なオーディオ識別モデル124からのデータによって共有されたオーディオ識別モデル124を更新することができる)。
When Authentication Component 114 disables access for client computing devices to the shared
図2は、音声作動式のシステムにおいてコンテンツをカスタマイズするための例示的な方法200の流れ図を示す。方法200は、位置情報を受け取ること(ACT 202)を含み得る。方法200は、位置が所定の範囲内にあると判定すること(ACT 204)を含み得る。方法200は、オーディオ識別モデルを提供すること(ACT 206)を含み得る。方法200は、入力オーディオ信号を受け取ること(ACT 208)を含み得る。方法200は、識別スコアを生成すること(ACT 210)を含み得る。方法200は、プロファイルを選択すること(ACT 212)を含み得る。方法200は、デジタルコンポーネントを選択すること(ACT 214)を含み得る。方法200は、デジタルコンポーネントを送信すること(ACT 216)を含み得る。
FIG. 2 shows a flow diagram of an
とりわけ、図2および図3を参照すると、方法200は、位置を受け取ること(ACT 202)を含み得る。図3は、第2のクライアントコンピューティングデバイス104(2)とオーディオ識別モデルを共有する第1のクライアントコンピューティングデバイス104(1)のブロック図を示す(第1のクライアントコンピューティングデバイス104(1)および第2のクライアントコンピューティングデバイス104(2)は、集合的にクライアントコンピューティングデバイス104と呼ばれ得る)。上述のように、方法200は、データ処理システム102が第1のクライアントコンピューティングデバイス104(1)の位置を受け取ることを含み得る。
In particular, with reference to FIGS. 2 and 3,
たとえば、クライアントコンピューティングデバイス104(1)は、第2のクライアントコンピューティングデバイス104(2)から離れた初期位置302を持ち得る。クライアントコンピューティングデバイス104(1)は、初期位置302とは異なる位置であり得る位置304に移動することが可能である。クライアントコンピューティングデバイス104(1)は、その位置をデータ処理システム102に周期的に送信することができる。クライアントコンピューティングデバイス104(1)がその位置または位置の近似値(たとえば、Wi-Fiネットワーク名)が変わると判定するとき、クライアントコンピューティングデバイス104(1)は、その位置をデータ処理システム102に送信することができる。
For example, the client computing device 104 (1) may have an
クライアントコンピューティングデバイス104(1)は、第1のオーディオ識別モデルに関連付けられ得る。たとえば、第1のクライアントコンピューティングデバイス104(1)は、対応する第1のオーディオ識別モデルを持ち得る。オーディオ識別モデルとのクライアントコンピューティングデバイス104(1)の関連付けは、オーディオ識別モデル(またはそのインジケーション)に関連してクライアントコンピューティングデバイス104(1)の識別子を記憶することを含み得る。たとえば、図3に示されるように、CCD(1) 306として示されるクライアントコンピューティングデバイス104(1)のインジケーションが、AIM(1) 308として示される第1のオーディオ識別モデルのインジケーションとともに(データリポジトリ122内の)データ構造に記憶される。AIM(1) 308とともにCCD(1) 306を記憶することは、クライアントコンピューティングデバイス104(1)がAIM(1) 308によって特定されるオーディオ識別モデル124にアクセスすることができることをデータ処理システム102(またはそのコンポーネント)に示し得る。
Client computing device 104 (1) may be associated with a first audio discriminative model. For example, the first client computing device 104 (1) may have a corresponding first audio discriminative model. The association of the client computing device 104 (1) with the audio discriminative model may include storing the identifier of the client computing device 104 (1) in relation to the audio discriminative model (or its indication). For example, as shown in Figure 3, the indication of the client computing device 104 (1), shown as CCD (1) 306, along with the indication of the first audio discriminative model, shown as AIM (1) 308 ( Stored in the data structure (in the data repository 122). Storing the CCD (1) 306 along with the AIM (1) 308 indicates that the client computing device 104 (1) can access the audio
方法200は、受け取られた位置が所定の範囲内にあると判定すること(ACT 204)を含み得る。所定の範囲は、クライアントコンピューティングデバイス104(2)の周りの所定の距離であることが可能である。たとえば、認証コンポーネント114は、クライアントコンピューティングデバイス104(1)がクライアントコンピューティングデバイス104(2)と同じ集合住宅内にあると判定し得る。
図3に示されるように、(所定の距離310とも呼ばれ得る)所定の範囲310は、クライアントコンピューティングデバイス104(2)の周りのジオフェンス312を定義する。範囲310は、所与のフィート数またはメートル数などの距離の設定された長さであることが可能である。範囲310は、近似されることも可能である。たとえば、ジオフェンス312は、クライアントコンピューティングデバイス104(1)およびクライアントコンピューティングデバイス104(2)が同じWi-Fiネットワーク上にあるときにクライアントコンピューティングデバイス104(1)がクライアントコンピューティングデバイス104(2)の範囲310内にあるようにWi-Fiネットワークによって定義される可能性がある。
As shown in FIG. 3, a predetermined range 310 (which may also be referred to as a predetermined distance 310) defines a
方法200は、クライアントコンピューティングデバイス104のオーディオ識別モデル124へのアクセスを提供すること(ACT 206)を含み得る。たとえば、認証コンポーネント114は、クライアントコンピューティングデバイス104(1)に対応するオーディオ識別モデル124などのクライアントコンピューティングデバイス104(1)の1つまたは複数のオーディオ識別モデル124へのアクセスをクライアントコンピューティングデバイス104(2)に提供することができる。クライアントコンピューティングデバイス104(1)にオーディオ識別モデル124へのアクセスを提供することは、クライアントコンピューティングデバイス104(1)が入力オーディオ信号を処理するために使用することができるオーディオ識別モデル124のコピーをクライアントコンピューティングデバイス104(1)に送信することを含み得る。オーディオ識別モデル124へのアクセスを提供することは、第1のクライアントデバイス104(1)の位置が第2のクライアントコンピューティングデバイス104(2)の所定の範囲310内にあるとの判定に基づいて、データ処理システム102内で第1のクライアントコンピューティングデバイス104(1)のオーディオ識別モデル124をクライアントコンピューティングデバイス104(2)に関連付けることを含み得る。この例において、オーディオ識別モデル124は、第1のクライアントコンピューティングデバイス104(1)に送信されない可能性があるが、クライアントコンピューティングデバイス104(1)がオーディオ識別モデル124にアクセスするかまたはそうでなければ使用することを認可されることを示すために、第1のクライアントコンピューティングデバイス104(1)のインジケーションが、オーディオ識別モデル124に関連して記憶される可能性がある。
たとえば、クライアントコンピューティングデバイス104(1)が位置302から位置304におよびジオフェンス312内に移動するとき、認証コンポーネント114は、クライアントコンピューティングデバイス104(1)に認可の通知を送信することができる。認可の通知は、クライアントコンピューティングデバイス104(1)のユーザからの、クライアントコンピューティングデバイス104(1)のオーディオ識別モデル124へのアクセスをクライアントコンピューティングデバイス104(2)に提供するための許可を要求し得る。許可を受け取る認証コンポーネント114は、クライアントコンピューティングデバイス104(1)のオーディオ識別モデル124へのアクセスをクライアントコンピューティングデバイス104(2)に提供することができる。
For example, when client computing device 104 (1) moves from
図3に示されるように、認証コンポーネント114は、クライアントコンピューティングデバイス104(2)がアクセスすることを認可されるオーディオ識別モデル124のリストにAIM(1) 308を追加することができる。たとえば、CCD(2) 314として示されるクライアントコンピューティングデバイス104(2)のインジケーションが、AIM(2) 316として示されるクライアントコンピューティングデバイス104(2)自体のオーディオ識別モデル124およびAIM(1) 308のインジケーションに関連して記憶される(またはそうでなければ対応する)。認証コンポーネント114は、AIM(n) 320として示されるオーディオ識別モデル124(n)のインジケーションに関連して記憶された、CCN(n) 318として示されるクライアントコンピューティングデバイス104(n)のインジケーションによって示される任意の数のクライアントコンピューティングデバイス104に関してこのプロセスを繰り返すことができる。
As shown in FIG. 3, the authentication component 114 can add the AIM (1) 308 to the list of audio
方法200は、入力オーディオ信号を受け取ること(ACT 208)を含み得る。データ処理システム102は、クライアントコンピューティングデバイス104(2)から入力オーディオ信号を受け取ることができる。ユーザは、クライアントコンピューティングデバイス104(2)に音声に基づく問い合わせを尋ねることができる。クライアントコンピューティングデバイス104(2)は、トランスデューサ142(たとえば、マイクロフォン)によって問い合わせを検出し、問い合わせを電子信号に変換することができる。プリプロセッサ148は、入力オーディオ信号をフィルタリングし、パケット化することができ、クライアントコンピューティングデバイス104(2)は、入力オーディオ信号をさらなる処理のためにデータ処理システム102に送信することができる。
NLPコンポーネント112は、入力オーディオ信号内の要求を識別するために入力オーディオ信号を解析することができる。要求に対するデータ処理システムの応答は、どのユーザが入力オーディオ信号を与えたかの識別に基づくことができる。たとえば、問い合わせ「オーケー、次の日程は何」は、ユーザの各々がそれらのユーザのそれぞれの日程に異なるイベントを有することが可能であるので、データ処理システム102が異なるユーザに異なる結果を提供し得るという点でユーザに依存する。認証コンポーネント114は、クライアントコンピューティングデバイス104(2)がアクセスすることができるオーディオ識別モデル124を使用してどのユーザがクライアントコンピューティングデバイス104(2)に問い合わせを発話したのかを決定することができる。
The NLP component 112 can parse the input audio signal to identify the requirements within the input audio signal. The response of the data processing system to the request can be based on the identification of which user provided the input audio signal. For example, the query "OK, what's next" allows the
方法200は、識別スコアを生成すること(ACT 210)を含み得る。認証コンポーネント114は、クライアントコンピューティングデバイス104(2)がアクセスすることができるオーディオ識別モデル124の各々に入力オーディオ信号を提供することができる。たとえば、図3を参照すると、クライアントコンピューティングデバイス104(2)が入力オーディオ信号を受け取り、入力オーディオ信号をデータ処理システム102に送信するとき、認証コンポーネント114は、AIM(2) 316およびAIM(1) 308によって示されるオーディオ識別モデル124に入力オーディオ信号を渡すことができる。この例に関して、認証コンポーネント114は、第1の識別スコアおよび第2の識別スコアを生成する。
方法200は、プロファイルを選択すること(ACT 212)を含み得る。たとえば、方法200は、複数の候補プロファイルからプロファイルを選択することを含み得る。各オーディオ識別モデル124は、プロファイルに関連付けられ得る。図3に示された例において、AIM(2) 316によって示されるオーディオ識別モデル124は、クライアントコンピューティングデバイス104(2)の所有者(または登録されたユーザ)のプロファイルに関連付けられ得る。AIM(1) 308によって示されるオーディオ識別モデル124は、クライアントコンピューティングデバイス104(1)の所有者(または登録されたユーザ)のプロファイルに関連付けられ得る。これらの2つのプロファイルは、集合的に候補プロファイルと呼ばれ得る。
認証コンポーネント114は、ACT 210の間に生成された識別スコアに基づいて選択を行うことができる。認証コンポーネント114は、識別スコアをランク付けし、最も高いスコアを有する識別スコアを選択し得る。認証コンポーネント114は、オーディオ識別モデルのメタデータの各々に基づいてランク付けまたは識別スコアを修正し得る。たとえば、認証コンポーネント114は、高い正確さを有するオーディオ識別モデル124と比較されるとき、低い正確さを有するオーディオ識別モデル124によって生成された識別スコアを低くし得る。
Authentication component 114 can make selections based on the identification score generated during
方法200は、デジタルコンポーネントを選択すること(ACT 214)を含み得る。認証コンポーネント114は、(ACT 212からの)選択されたプロファイルをコンテンツ選択コンポーネント118に提供し得る。コンテンツ選択コンポーネント118は、ACT 212の間に選択されたプロファイルを使用してまたはそのようなプロファイルに基づいてデジタルコンポーネントを選択することができる。たとえば、プロファイルは、プロファイルに関連するユーザに提供するデジタルコンポーネントを選択するためのプリファレンスまたは規則を含み得る。
方法200は、デジタルコンポーネントを送信すること(ACT 216)を含み得る。データ処理システム102は、インターフェース110を介して、クライアントコンピューティングデバイス104(2)(たとえば、入力オーディオ信号を供給したクライアントコンピューティングデバイス104)にデジタルコンポーネントを送信することができる。
方法200は、共有されたオーディオ識別モデル124へのアクセスを無効にすることをも含み得る。たとえば、クライアントコンピューティングデバイス104(1)がジオフェンス312(またはクライアントコンピューティングデバイス104(2)の大まかな近傍)によって定義されたエリアを離れるとき、クライアントコンピューティングデバイス104(1)は、更新された位置情報をデータ処理システム102に送信し得る。クライアントコンピューティングデバイス104(1)がクライアントコンピューティングデバイス104(2)の所定の範囲310内にもはやないと判定するとき、認証コンポーネント114は、クライアントコンピューティングデバイス104(2)に関連するオーディオ識別モデル124のリストからAIM(1) 308を抹消または削除し得る。無効化プロセスは、所定の量の時間の後に行われ得る。たとえば、タイムアウト期間が1日であり、1日後にクライアントコンピューティングデバイス104(1)がまだ所定の範囲内にある場合、認証コンポーネント114は、共有されたオーディオ識別モデル124へのアクセスを自動的に無効にし得る。共有されたオーディオ識別モデルへのアクセスの自動的な無効化は、ユーザのデータおよび共有されたオーディオ識別モデルのセキュリティを高める。
本開示の少なくとも1つの態様によれば、上の音声作動式のシステムにおいてコンテンツをカスタマイズするための方法を実行するように構成されたシステムが、提供される。たとえば、システムは、データ処理システムを含み得る。データ処理システムは、インターフェースを含み得る。インターフェースは、第1のクライアントコンピューティングデバイスの位置を受け取ることができる。第1のクライアントコンピューティングデバイスは、第1のオーディオ識別モデルに関連付けられ得る。インターフェースは、第2のクライアントコンピューティングデバイスからオーディオ入力信号を受け取ることができる。第2のクライアントコンピューティングデバイスは、第2のオーディオ識別モデルに関連付けられ得る。データ処理システムは、認証コンポーネントを含み得る。認証コンポーネントは、第1のクライアントコンピューティングデバイスの位置が第2のクライアントコンピューティングデバイスまで所定の距離以内にあると判定し得る。認証コンポーネントは、第1のクライアントコンピューティングデバイスの位置が第2のクライアントコンピューティングデバイスまで所定の距離以内にあるという判定に基づいて、第1のクライアントコンピューティングデバイスの第1のオーディオ識別モデルへのアクセスを第2のクライアントコンピューティングデバイスに提供することができる。認証コンポーネントは、第1のオーディオ識別モデルを使用して第1の識別スコアを生成し、第2のオーディオ識別モデルを使用して第2の識別スコアを生成することができる。認証コンポーネントは、第1の識別スコアおよび第2の識別スコアに基づいて複数の候補プロファイルからプロファイルを選択し得る。データ処理システムは、複数の候補プロファイルから選択されたプロファイルに基づいてデジタルコンポーネントを選択するためのコンテンツ選択コンポーネントを含み得る。データ処理システムのインターフェースは、オーディオ入力信号に応答して第2のクライアントコンピューティングデバイスにデジタルコンポーネントを送信することができる。 According to at least one aspect of the present disclosure, there is provided a system configured to perform a method for customizing content in the above voice actuated system. For example, the system may include a data processing system. The data processing system may include an interface. The interface can receive the location of the first client computing device. The first client computing device can be associated with the first audio discriminative model. The interface can receive audio input signals from a second client computing device. The second client computing device can be associated with a second audio discriminative model. The data processing system may include an authentication component. The authentication component may determine that the location of the first client computing device is within a predetermined distance to the second client computing device. The authentication component enters the first audio discriminative model of the first client computing device based on the determination that the location of the first client computing device is within a predetermined distance to the second client computing device. Access can be provided to a second client computing device. The authentication component can use the first audio discriminative model to generate the first discriminative score and the second audio discriminative model to generate the second discriminative score. The authentication component may select a profile from multiple candidate profiles based on the first identification score and the second identification score. The data processing system may include a content selection component for selecting a digital component based on a profile selected from a plurality of candidate profiles. The interface of the data processing system can send digital components to the second client computing device in response to the audio input signal.
インターフェースは、第1のクライアントコンピューティングデバイスの第2の位置を受け取る可能性がある。認証コンポーネントは、第1のクライアントコンピューティングデバイスの第2の位置が第2のクライアントコンピューティングデバイスまでの所定の距離の外にあると判定する可能性があり、第1のクライアントコンピューティングデバイスの第2の位置が所定の距離の外にあるとの判定に基づいて、第1のクライアントコンピューティングデバイスの第1のオーディオ識別モデルへの第2のクライアントコンピューティングデバイスのアクセスを無効にする可能性がある。認証コンポーネントは、第1のオーディオ識別モデルのメタデータおよび第2のオーディオ識別モデルのメタデータに基づいて第1の識別スコアおよび第2の識別スコアをランク付けする可能性がある。第1のオーディオ識別モデルのメタデータおよび第2のオーディオ識別モデルのメタデータは、誤り率、センサの種類のインジケーション、およびセンサの数のうちの少なくとも1つを含み得る。プロファイルは、第1のクライアントコンピューティングデバイスのユーザに関連付けられ得る。複数の候補プロファイルの各々は、それぞれのオーディオ識別モデルに関連付けられ得る。インターフェースは、第2のクライアントコンピューティングデバイスから第2のオーディオ入力信号を受け取る可能性がある。認証コンポーネントは、第1のオーディオ識別モデルに基づいて第3の識別スコアを生成し、第2のオーディオ識別モデルに基づいて第4の識別スコアを生成する可能性がある。認証コンポーネントは第3の識別スコアおよび第4の識別スコアのランク付けに基づいて第1のオーディオ識別モデルに関連するプロファイルを選択する可能性があり、第2のオーディオ入力信号に基づいて第1のオーディオ識別モデルを更新する可能性がある。追加的にまたは代替的に、認証コンポーネントは、第2のオーディオ入力信号に基づいて第3のオーディオ識別モデルを生成する可能性がある。インターフェースは、第1のクライアントコンピューティングデバイスの第2の位置を受け取る可能性がある。認証コンポーネントは、第1のクライアントコンピューティングデバイスの第2の位置が第2のクライアントコンピューティングデバイスまでの所定の距離の外にあると判定する可能性があり、第1のクライアントコンピューティングデバイスの第2の位置が第2のクライアントコンピューティングデバイスの所定の距離の外にあるとの判定に基づいて第1のオーディオ識別モデルと第3のオーディオ識別モデルとを合併する可能性がある。インターフェースは、第1のクライアントコンピューティングデバイスに認可の通知を送信する可能性がある。認証コンポーネントは、認可の通知に応答して第1のクライアントコンピューティングデバイスから承認メッセージを受け取ることに基づいて第1のクライアントコンピューティングデバイスの第1のオーディオ識別モデルを第2のクライアントコンピューティングデバイスに関連付ける可能性がある。
The interface may receive a second position on the first client computing device. The authentication component may determine that the second position of the first client computing device is outside the predetermined distance to the second client computing device, and the first of the first client computing devices. It is possible to invalidate the access of the second client computing device to the first audio identification model of the first client computing device based on the determination that the
図4は、例示的なコンピュータシステム400のブロック図である。コンピュータシステムまたはコンピューティングデバイス400は、システム100、またはデータ処理システム102などのそのシステム100のコンポーネントを含むかまたはそれらを実装するために使用され得る。コンピューティングシステム400は、情報を伝達するためのバス405またはその他の通信コンポーネントと、情報を処理するためのバス405に結合されたプロセッサ410または処理回路とを含む。また、コンピューティングシステム400は、情報を処理するためのバスに結合された1つまたは複数のプロセッサ410または処理回路を含み得る。コンピューティングシステム400は、情報およびプロセッサ410によって実行される命令を記憶するためのバス405に結合されたランダムアクセスメモリ(RAM)またはその他のダイナミックストレージデバイスなどのメインメモリ415も含む。メインメモリ415は、データリポジトリ122であるかまたはデータリポジトリ122を含み得る。メインメモリ415は、位置情報、一時的な変数、またはプロセッサ410による命令の実行中のその他の中間情報を記憶するためにも使用され得る。コンピューティングシステム400は、静的な情報およびプロセッサ410のための命令を記憶するためのバス405に結合された読み出し専用メモリ(ROM)420またはその他のスタティックストレージデバイスをさらに含み得る。ソリッドステートデバイス、磁気ディスク、または光ディスクなどのストレージデバイス425が、情報および命令を永続的に記憶するためにバス405に結合され得る。ストレージデバイス425は、データリポジトリ122を含むかまたはデータリポジトリ122の一部であることが可能である。
FIG. 4 is a block diagram of an
コンピューティングシステム400は、ユーザに対して情報を表示するための液晶ディスプレイまたはアクティブマトリックスディスプレイなどのディスプレイ435にバス405を介して結合される可能性がある。英数字およびその他のキーを含むキーボードなどの入力デバイス430が、プロセッサ410に情報およびコマンド選択を伝達するためにバス405に結合される可能性がある。入力デバイス430は、タッチスクリーンディスプレイ435を含み得る。入力デバイス430は、プロセッサ410に方向情報およびコマンド選択を伝達するためおよびディスプレイ435上でカーソルの動きを制御するためのマウス、トラックボール、またはカーソル方向キーなどのカーソルコントロールも含み得る。ディスプレイ435は、たとえば、図1のデータ処理システム102、クライアントコンピューティングデバイス104、またはその他のコンポーネントの一部であることが可能である。
The
本明細書において説明されるプロセス、システム、および方法は、メインメモリ415に含まれる命令の配列をプロセッサ410が実行することに応じてコンピューティングシステム400によって実施され得る。そのような命令は、ストレージデバイス425などの別のコンピュータ可読媒体からメインメモリ415に読み込まれ得る。メインメモリ415に含まれる命令の配列の実行は、コンピューティングシステム400に本明細書において説明される例示的なプロセスを実行させる。マルチプロセッシング配列の1つまたは複数のプロセッサも、メインメモリ415に含まれる命令を実行するために使用されてよい。配線による回路は、本明細書において説明されるシステムおよび方法と一緒にソフトウェア命令の代わりにまたはソフトウェア命令と組み合わせて使用され得る。本明細書において説明されるシステムおよび方法は、ハードウェア回路とソフトウェアとのいかなる特定の組合せにも限定されない。
The processes, systems, and methods described herein may be performed by the
例示的なコンピューティングシステムが図4に示されたが、本明細書に記載の動作を含む主題は、本明細書において開示された構造およびそれらの構造的均等物を含む、その他の種類のデジタル電子回路、またはコンピュータソフトウェア、ファームウェア、もしくはハードウェア、またはそれらのうちの1つもしくは複数の組合せで実装され得る。 An exemplary computing system is shown in FIG. 4, but the subject matter including the operations described herein includes other types of digital, including the structures disclosed herein and their structural equivalents. It can be implemented in electronic circuits, or computer software, firmware, or hardware, or a combination of one or more of them.
本明細書において検討されたシステムがユーザについての個人情報を収集するか、または個人情報を利用する可能性がある状況に関して、ユーザは、プログラムまたは特徴が個人情報(たとえば、ユーザのソーシャルネットワーク、ソーシャルなアクションもしくは活動、ユーザのプリファレンス、またはユーザの位置についての情報)を収集する可能性があるかどうかを制御するか、あるいはユーザにより関連性がある可能性があるコンテンツをコンテンツサーバもしくはその他のデータ処理システムから受け取るべきかどうかまたはどのようにして受け取るべきかを制御する機会を与えられる可能性がある。さらに、パラメータを生成するときに個人を識別することができる情報が削除されるように、特定のデータが、それが記憶されるかまたは使用される前に1つまたは複数の方法で匿名化される可能性がある。たとえば、ユーザのアイデンティティが、個人を識別することができる情報がユーザに関して決定され得ないように匿名化されることがあり、または(都市、郵便番号、もしくは州のレベルまでなど)位置情報が取得される場合に、ユーザの地理的位置が、ユーザの特定の位置が決定され得ないように一般化されることがある。したがって、ユーザは、情報がユーザについてどのように収集され、コンテンツサーバによって使用されるかを制御する可能性がある。 With respect to the circumstances in which the systems discussed herein may collect or use personal information about you, you may program or feature personal information (eg, your social network, social). Controls whether any action or activity, user preferences, or information about the user's location) may be collected, or content that may be more relevant to the user on a content server or other You may be given the opportunity to control whether or how you should receive it from your data processing system. In addition, certain data is anonymized in one or more ways before it is stored or used so that personally identifiable information is removed when generating parameters. There is a possibility that For example, a user's identity may be anonymized so that no personally identifiable information can be determined for the user, or location information is obtained (such as to the city, zip code, or state level). If so, the geographic location of the user may be generalized so that a particular location of the user cannot be determined. Therefore, the user may control how information is collected about the user and used by the content server.
本明細書に記載の主題および動作は、本明細書において開示された構造およびそれらの構造的均等物を含むデジタル電子回路、またはコンピュータソフトウェア、ファームウェア、もしくはハードウェア、またはそれらのうちの1つもしくは複数の組合せで実装され得る。本明細書に記載の主題は、1つまたは複数のコンピュータプログラム、たとえば、データ処理装置による実行のために、またはデータ処理装置の動作を制御するために1つまたは複数のコンピュータストレージ媒体上に符号化されたコンピュータプログラム命令の1つまたは複数の回路として実装され得る。代替的にまたは追加的に、プログラム命令は、データ処理装置による実行のために好適な受信機装置に送信するために情報を符号化するように生成される人為的に生成された伝播信号、たとえば、機械によって生成された電気的信号、光学的信号、または電磁的信号上に符号化され得る。コンピュータストレージ媒体は、コンピュータ可読ストレージデバイス、コンピュータ可読ストレージ基板、ランダムもしくはシリアルアクセスメモリアレイもしくはデバイス、またはそれらのうちの1つもしくは複数の組合せであるか、あるいはそれらに含まれることが可能である。コンピュータストレージ媒体は、伝播信号ではないが、人為的に生成された伝播信号に符号化されたコンピュータプログラム命令の送信元または送信先である可能性がある。コンピュータストレージ媒体は、1つまたは複数の別個のコンポーネントまたは媒体(たとえば、複数のCD、ディスク、もしくはその他のストレージデバイス)であるか、またはそれらに含まれることも可能である。本明細書に記載の動作は、1つもしくは複数のコンピュータ可読ストレージデバイスに記憶された、またはその他のソースから受け取られたデータに対してデータ処理装置によって実行される動作として実装され得る。 The subject matter and operation described herein are digital electronic circuits, including the structures disclosed herein and their structural equivalents, or computer software, firmware, or hardware, or one or one of them. It can be implemented in multiple combinations. The subject matter described herein is encoded on one or more computer programs, eg, for execution by a data processor or to control the operation of the data processor. It can be implemented as one or more circuits of computerized computer program instructions. Alternatively or additionally, the program instruction is an artificially generated propagating signal, eg, generated to encode information for transmission to a receiver device suitable for execution by a data processor. Can be encoded on an electrical, optical, or electromagnetic signal generated by a machine. The computer storage medium can be, or can be contained in, a computer-readable storage device, a computer-readable storage board, a random or serial access memory array or device, or a combination of one or more of them. The computer storage medium is not a propagated signal, but may be the source or destination of a computer program instruction encoded in an artificially generated propagated signal. The computer storage medium can be or can be contained in one or more separate components or media (eg, multiple CDs, disks, or other storage devices). The actions described herein can be implemented as actions performed by a data processor on data stored in one or more computer-readable storage devices or received from other sources.
用語「データ処理システム」、「コンピューティングデバイス」、「コンポーネント」、または「データ処理装置」は、例として、1つのプログラミング可能なプロセッサ、1台のコンピュータ、1つのシステムオンチップ、またはそれらの複数もしくは組合せを含む、データを処理するための様々な装置、デバイス、および機械を包含する。装置は、専用の論理回路、たとえば、FPGA(フィールドプログラマブルゲートアレイ)またはASIC(特定用途向け集積回路)を含み得る。装置は、ハードウェアに加えて、問題にしているコンピュータプログラムのための実行環境を作成するコード、たとえば、プロセッサのファームウェア、プロトコルスタック、データベース管理システム、オペレーティングシステム、クロスプラットフォームランタイム環境、仮想マシン、またはそれらのうちの1つもしくは複数の組合せを構成するコードも含み得る。装置および実行環境は、ウェブサービスインフラストラクチャ、分散コンピューティングインフラストラクチャ、およびグリッドコンピューティングインフラストラクチャなどの様々な異なるコンピューティングモデルインフラストラクチャを実現することができる。ダイレクトアクションAPI 116、コンテンツセレクタコンポーネント118、認証コンポーネント114、またはNLPコンポーネント112、およびその他のデータ処理システム102のコンポーネントは、1つまたは複数のデータ処理装置、システム、コンピューティングデバイス、またはプロセッサを含むかまたは共有し得る。
The terms "data processing system", "computing device", "component", or "data processing device" are, for example, one programmable processor, one computer, one system-on-chip, or multiple of them. Or include various devices, devices, and machines for processing data, including combinations. The device may include dedicated logic circuits, such as FPGAs (Field Programmable Gate Arrays) or ASICs (Application Specific Integrated Circuits). In addition to the hardware, the device creates code that creates an execution environment for the computer program in question, such as processor firmware, protocol stacks, database management systems, operating systems, cross-platform runtime environments, virtual machines, or It may also include code that constitutes one or more combinations of them. Equipment and execution environments can implement a variety of different computing model infrastructures such as web services infrastructure, distributed computing infrastructure, and grid computing infrastructure. Does the Direct Action API 116, Content Selector Component 118, Authentication Component 114, or NLP Component 112, and other
コンピュータプログラム(プログラム、ソフトウェア、ソフトウェアアプリケーション、アプリ、スクリプト、またはコードとしても知られる)は、コンパイラ型言語もしくはインタープリタ型言語、宣言型言語もしくは手続き型言語を含む任意の形態のプログラミング言語で記述可能であり、独立型プログラムとしての形態、またはモジュール、コンポーネント、サブルーチン、オブジェクト、もしくはコンピューティング環境での使用に好適なその他の単位としての形態を含む任意の形態で展開され得る。コンピュータプログラムは、ファイルシステム内のファイルに対応し得る。コンピュータプログラムは、その他のプログラムもしくはデータを保持するファイルの一部(たとえば、マークアップ言語のドキュメントに記憶された1つもしくは複数のスクリプト)、問題にしているプログラムに専用の単一のファイル、または複数の連携されたファイル(たとえば、1つもしくは複数のモジュール、サブプログラム、もしくはコードの一部を記憶するファイル)に記憶され得る。コンピュータプログラムは、1つのコンピュータ上で、または1つの場所に置かれるか、もしくは複数の場所に分散され、通信ネットワークによって相互に接続される複数のコンピュータ上で実行されるように展開され得る。 Computer programs (also known as programs, software, software applications, apps, scripts, or code) can be written in any form of programming language, including compiler or interpreter languages, declarative or procedural languages. It can be deployed in any form, including as a stand-alone program, or as a module, component, subroutine, object, or other unit suitable for use in a computing environment. The computer program may correspond to the files in the file system. A computer program may be some of the other programs or files that hold the data (for example, one or more scripts stored in a document in the markup language), a single file dedicated to the program in question, or It can be stored in multiple linked files (eg, a file that stores one or more modules, subprograms, or parts of code). Computer programs can be deployed on one computer, in one location, or distributed over multiple locations and run on multiple computers interconnected by communication networks.
本明細書に記載のプロセスおよび論理フローは、入力データに対して演算を行い、出力を生成することによってアクションを行うために1つまたは複数のコンピュータプログラム(たとえば、データ処理システム102のコンポーネント)を1つまたは複数のプログラミング可能なプロセッサが実行することによって実行され得る。また、プロセスおよび論理フローは、専用の論理回路、たとえば、FPGA(フィールドプログラマブルゲートアレイ)またはASIC(特定用途向け集積回路)によって実行されることが可能であり、さらに、装置は、それらの専用の論理回路として実装されることが可能である。コンピュータプログラム命令およびデータを記憶するのに適したデバイスは、例として、半導体メモリデバイス、たとえば、EPROM、EEPROM、およびフラッシュメモリデバイス、磁気ディスク、たとえば、内蔵ハードディスクまたはリムーバブルディスク、光磁気ディスク、ならびにCD-ROMディスクおよびDVD-ROMディスクを含む、すべての形態の不揮発性メモリ、媒体、およびメモリデバイスを含む。プロセッサおよびメモリは、専用論理回路によって補完され得るか、または専用論理回路に組み込まれ得る。 The processes and logical flows described herein use one or more computer programs (eg, components of data processing system 102) to perform operations on input data and perform actions by producing output. It can be done by running by one or more programmable processors. In addition, processes and logic flows can be executed by dedicated logic circuits, such as FPGAs (Field Programmable Gate Arrays) or ASICs (Application Specific Integrated Circuits), and the equipment is dedicated to them. It can be implemented as a logic circuit. Suitable devices for storing computer program instructions and data include, for example, semiconductor memory devices such as EPROM, EEPROM, and flash memory devices, magnetic disks such as internal hard disks or removable disks, magneto-optical disks, and CDs. -Includes all forms of non-volatile memory, media, and memory devices, including ROM disks and DVD-ROM disks. The processor and memory can be complemented by a dedicated logic circuit or incorporated into a dedicated logic circuit.
本明細書に記載の主題は、バックエンドコンポーネントを、たとえば、データサーバとして含むか、またはミドルウェアコンポーネント、たとえば、アプリケーションサーバを含むか、またはフロントエンドコンポーネント、たとえば、ユーザが本明細書に記載の主題の実装とインタラクションすることができるグラフィカルユーザインターフェースもしくはウェブブラウザを有するクライアントコンピュータを含むか、または1つもしくは複数のそのようなバックエンドコンポーネント、ミドルウェアコンポーネント、もしくはフロントエンドコンポーネントの組合せを含むコンピューティングシステムに実装され得る。システムのコンポーネントは、任意の形態または媒体のデジタルデータ通信、たとえば、通信ネットワークによって相互に接続されることが可能である。通信ネットワークの例は、ローカルエリアネットワーク(「LAN」)および広域ネットワーク(「WAN」)、インターネットワーク(たとえば、インターネット)、ならびにピアツーピアネットワーク(たとえば、アドホックピアツーピアネットワーク)を含む。 The subject matter described herein includes a backend component, eg, as a data server, or a middleware component, eg, an application server, or a frontend component, eg, a subject described herein by a user. In a computing system that includes a client computer with a graphical user interface or web browser that can interact with the implementation of, or that includes one or more such back-end, middleware, or front-end component combinations. Can be implemented. The components of the system can be interconnected by any form or medium of digital data communication, such as a communication network. Examples of communication networks include local area networks (“LAN”) and wide area networks (“WAN”), internetworks (eg, the Internet), and peer-to-peer networks (eg, ad hoc peer-to-peer networks).
本明細書において説明されたようなコンピューティングシステムは、クライアントおよびサーバを含み得る。クライアントおよびサーバは、概して互いに離れており、通常は通信ネットワーク(たとえば、ネットワーク105)を通じてインタラクションする。クライアントとサーバとの関係は、それぞれのコンピュータ上で実行されており、互いにクライアント-サーバの関係にあるコンピュータプログラムによって生じる。一部の実装において、サーバは、(たとえば、クライアントコンピューティングデバイスとインタラクションするユーザに対してデータを表示し、そのようなユーザからユーザ入力を受け取る目的で)クライアントコンピューティングデバイスにデータ(たとえば、デジタルコンポーネントを表すデータパケット)を送信する。クライアントコンピューティングデバイスにおいて生成されたデータ(たとえば、ユーザインタラクションの結果)が、サーバにおいてクライアントコンピューティングデバイスから受け取られ(たとえば、クライアントコンピューティングデバイス104またはコンテンツプロバイダコンピューティングデバイス106からデータ処理システム102によって受け取られ)得る。
Computing systems as described herein can include clients and servers. Clients and servers are generally separated from each other and typically interact through a communication network (eg, network 105). The client-server relationship runs on each computer and is caused by computer programs that have a client-server relationship with each other. In some implementations, the server displays data on the client computing device (for example, to display data to users interacting with the client computing device and receive user input from such users) to the client computing device (eg, digital). Data packet representing the component) is sent. The data generated by the client computing device (eg, the result of user interaction) is received by the
動作が特定の順序で図面に示されているが、そのような動作は、示された特定の順序でまたは逐次的順序で実行される必要があるわけではなく、すべての示された動作が、実行される必要があるわけではない。本明細書に記載のアクションは、異なる順序で実行され得る。 Although the actions are shown in the drawings in a particular order, such actions do not have to be performed in the particular order shown or in a sequential order, and all the shown actions, It doesn't have to be done. The actions described herein can be performed in a different order.
様々なシステムコンポーネントの分割は、すべての実装において分割を必要とするわけではなく、説明されたプログラムコンポーネントは、単一のハードウェアまたはソフトウェア製品に含まれ得る。たとえば、NLPコンポーネント112、コンテンツセレクタコンポーネント118、または認証コンポーネント114は、単一のコンポーネント、アプリ、プログラム、または1つもしくは複数の処理回路を有する論理デバイス、またはデータ処理システム102の1つもしくは複数のサーバの一部であることが可能である。
The splitting of various system components does not require splitting in all implementations, and the program components described may be contained in a single hardware or software product. For example, NLP component 112, content selector component 118, or authentication component 114 may be a single component, an app, a program, or a logical device with one or more processing circuits, or one or more of
今やいくつかの例示的な実装を説明したので、以上は例示的であり、限定的でなく、例として提示されたことは明らかである。特に、本明細書において提示された例の多くは方法の行為またはシステムの要素の特定の組合せを含むが、それらの行為およびそれらの要素は、同じ目的を達成するためにその他の方法で組み合わされてよい。1つの実装に関連して検討された行為、要素、および特徴は、その他の実装または実装の同様の役割から除外されるように意図されていない。 Now that we have described some exemplary implementations, it is clear that the above are exemplary, not limiting, and presented as examples. In particular, many of the examples presented herein include specific combinations of method actions or elements of the system, but those actions and those elements are combined in other ways to achieve the same purpose. You can. Actions, elements, and features considered in connection with one implementation are not intended to be excluded from other implementations or similar roles in implementations.
本明細書において使用された言葉遣いおよび用語は、説明を目的としており、限定と見なされるべきでない。本明細書における「〜を含む(including)」、「〜を含む(comprising)」、「〜を有する(having)」、「〜を含む(containing)」、「〜を含む(involving)」、「〜によって特徴付けられる(characterized by)」、「〜ことを特徴とする(characterized in that)」、およびそれらの変化形の使用は、その後に列挙された項目、それらの項目の均等物、および追加的な項目、ならびにその後に列挙された項目だけからなる代替的な実装を包含するように意図される。1つの実装において、本明細書に記載のシステムおよび方法は、説明された要素、行為、またはコンポーネントのうちの1つ、2つ以上のそれぞれの組合せ、またはすべてからなる。 The wording and terminology used herein is for explanatory purposes only and should not be considered limiting. "Including", "comprising", "having", "containing", "involving", "involving" in the present specification. The use of "characterized by", "characterized in that", and their variants are the items listed thereafter, their equivalents, and additions. It is intended to include alternative implementations consisting of only the items listed after that. In one implementation, the systems and methods described herein consist of one, a combination of two or more, or all of the elements, actions, or components described.
本明細書において単数形で言及されたシステムおよび方法の実装または要素または行為へのすべての言及は、複数のこれらの要素を含む実装も包含し得、本明細書における任意の実装、要素、または行為への複数形のすべての言及は、単一の要素のみを含む実装も包含し得る。単数形または複数形の言及は、今開示されたシステムもしくは方法、それらのコンポーネント、行為、または要素を単一のまたは複数の構成に限定するように意図されていない。任意の情報、行為、または要素に基づいている任意の行為または要素への言及は、行為または要素が任意の情報、行為、または要素に少なくとも部分的に基づく実装を含み得る。 All references to implementations or elements or actions of systems and methods referred to herein in the singular may also include implementations involving more than one of these elements, and any implementation, element, or element herein. All references to the act can also include implementations that contain only a single element. References to the singular or plural are not intended to limit the systems or methods currently disclosed, their components, actions, or elements to a single or plural configuration. References to any action or element that is based on any information, action, or element may include an implementation in which the action or element is at least partially based on any information, action, or element.
本明細書において開示された任意の実装は、任意のその他の実装または実施形態と組み合わされることがあり、「実装(an implementation)」、「一部の実装(some implementations)」、「1つの実装(one implementation)」などの言及は、必ずしも相互排他的ではなく、実装に関連して説明された特定の特徴、構造、または特色が少なくとも1つの実装または実施形態に含まれ得ることを示すように意図される。本明細書において使用されるそのような用語は、必ずしもすべてが同じ実装に言及しているとは限らない。任意の実装は、本明細書において開示された態様および実装に合致する任意の方法で包括的または排他的に任意のその他の実装と組み合わされ得る。 Any implementation disclosed herein may be combined with any other implementation or embodiment, "an implementation", "some implementations", "one implementation". References such as "one implementation" are not necessarily mutually exclusive, as they indicate that a particular feature, structure, or feature described in connection with an implementation may be included in at least one implementation or embodiment. Intended. Not all such terms as used herein refer to the same implementation. Any implementation may be comprehensively or exclusively combined with any other implementation in any manner that is consistent with the embodiments and implementations disclosed herein.
「または(or)」との言及は、「または(or)」を使用して記載された任意の項が、記載された項のうちの1つ、2つ以上、およびすべてのいずれかを示す可能性があるように包括的であると見なされ得る。たとえば、「『A』および『B』のうちの少なくとも一方」との言及は、「A」のみ、「B」のみ、および「A」と「B」との両方を含み得る。「〜を含む(comprising)」またはその他の非限定的用語(open terminology)と関連して使用されるそのような言及は、追加的な項を含み得る。 References to "or (or)" indicate that any term described using "or (or)" refers to one, two or more, or all of the described terms. It can be considered as inclusive as it may be. For example, the reference to "at least one of'A'and'B'" can include only "A", only "B", and both "A" and "B". Such references used in connection with "comprising" or other open terminology may include additional terms.
図面、詳細な説明、または任意の請求項の技術的な特徴が後に参照符号を付されている場合、参照符号は、図面、詳細な説明、および請求項を理解し易くするために含められた。したがって、参照符号があることもないことも、いかなる請求項の要素の範囲に対していかなる限定的な効果も持たない。 Where a drawing, detailed description, or technical feature of any claim is followed by a reference code, the reference code is included to make the drawing, detailed description, and claim easier to understand. .. Therefore, it has no reference code and has no limiting effect on the scope of any claim element.
本明細書に記載のシステムおよび方法は、それらの特徴を逸脱することなくその他の特定の形態で具現化され得る。上述の実装は、説明されたシステムおよび方法の限定ではなく、例示的である。したがって、本明細書に記載のシステムおよび方法の範囲は、上述の説明ではなく添付の請求項によって示され、請求項の均等の意味および範囲内に入る変更は、それに包含される。 The systems and methods described herein can be embodied in other particular forms without departing from their characteristics. The above implementation is exemplary, not limited to the systems and methods described. Accordingly, the scope of the systems and methods described herein is set forth in the appended claims rather than in the description above, and any modifications that fall within the equivalent meaning and scope of the claims are included therein.
100 システム
102 データ処理システム
104 クライアントコンピューティングデバイス
104(1) 第1のクライアントコンピューティングデバイス
104(2) 第2のクライアントコンピューティングデバイス
104(n) クライアントコンピューティングデバイス
105 コンピュータネットワーク
106 コンテンツプロバイダコンピューティングデバイス
110 インターフェース
112 自然言語プロセッサ(NLP)コンポーネント
114 認証コンポーネント
116 ダイレクトアクションアプリケーションプログラミングインターフェース(API)
118 コンテンツセレクタコンポーネント
120 オーディオ信号ジェネレータコンポーネント
122 データリポジトリ
124 オーディオ識別モデル
124(n) オーディオ識別モデル
126 プロファイル
128 コンテンツデータ
130 テンプレート
140 センサ
142 トランスデューサ
144 オーディオドライバ
146 スピーカ
148 プリプロセッサ
200 方法
302 初期位置
304 位置
306 CCD(1)
308 AIM(1)
310 範囲、距離
312 ジオフェンス
314 CCD(2)
316 AIM(2)
318 CCN(n)
320 AIM(n)
400 コンピュータシステム
405 バス
410 プロセッサ
415 メインメモリ
420 読み出し専用メモリ(ROM)
425 ストレージデバイス
430 入力デバイス
435 ディスプレイ
100 systems
102 Data processing system
104 Client Computing Device
104 (1) First client computing device
104 (2) Second client computing device
104 (n) Client Computing Device
105 Computer network
106 Content Provider Computing Device
110 interface
112 Natural Language Processor (NLP) Components
114 Authentication component
116 Direct Action Application Programming Interface (API)
118 Content Selector Component
120 Audio Signal Generator Component
122 Data repository
124 Audio Discriminative Model
124 (n) Audio Discriminative Model
126 Profile
128 content data
130 template
140 sensor
142 Transducer
144 Audio driver
146 speaker
148 preprocessor
200 ways
302 Initial position
304 position
306 CCD (1)
308 AIM (1)
310 range, distance
312 Geofence
314 CCD (2)
316 AIM (2)
318 CCN (n)
320 AIM (n)
400 computer system
405 bus
410 processor
415 main memory
420 Read-only memory (ROM)
425 Storage device
430 input device
435 display
Claims (20)
データ処理システムのインターフェースであって、
第1のクライアントコンピューティングデバイスの位置を受け取ることであって、前記第1のクライアントコンピューティングデバイスが、第1のオーディオ識別モデルに関連付けられる、ことと、
第2のクライアントコンピューティングデバイスから入力オーディオ信号を受け取ることであって、前記第2のクライアントコンピューティングデバイスが、第2のオーディオ識別モデルに関連付けられる、こととを行うためのデータ処理システムのインターフェースと、
認証コンポーネントであって、
前記第1のクライアントコンピューティングデバイスの前記位置が前記第2のクライアントコンピューティングデバイスまで所定の距離以内にあると判定し、
前記第1のクライアントコンピューティングデバイスの前記位置が前記第2のクライアントコンピューティングデバイスまで前記所定の距離以内にあるという判定に基づいて、前記第2のクライアントコンピューティングデバイスによって受け取られたオーディオ信号の処理のための前記第1のクライアントコンピューティングデバイスの前記第1のオーディオ識別モデルへのアクセスを提供し、
前記第1のオーディオ識別モデルを使用して第1の識別スコアを生成し、前記第2のオーディオ識別モデルを使用して第2の識別スコアを生成し、
前記第1の識別スコアおよび前記第2の識別スコアに基づいて複数の候補プロファイルからプロファイルを選択するために前記データ処理システムによって実行される認証コンポーネントと、
前記複数の候補プロファイルから選択された前記プロファイルに基づいてデジタルコンポーネントを選択するためのコンテンツ選択コンポーネントとを備え、
前記インターフェースが、前記入力オーディオ信号に応答して前記第2のクライアントコンピューティングデバイスに前記デジタルコンポーネントを送信する、
システム。 A system for customizing content in a voice-operated system
The interface of the data processing system
Receiving the location of the first client computing device, the first client computing device being associated with the first audio discriminative model.
With the interface of the data processing system for receiving the input audio signal from the second client computing device, that the second client computing device is associated with the second audio discriminative model. ,
Authentication component
It is determined that the position of the first client computing device is within a predetermined distance to the second client computing device.
Processing of the audio signal received by the second client computing device based on the determination that the position of the first client computing device is within the predetermined distance to the second client computing device. Provides access to the first audio identification model of the first client computing device for
The first audio discriminative model is used to generate a first discriminative score, and the second audio discriminative model is used to generate a second discriminative score.
An authentication component performed by the data processing system to select a profile from a plurality of candidate profiles based on the first identification score and the second identification score.
It includes a content selection component for selecting a digital component based on the profile selected from the plurality of candidate profiles.
The interface sends the digital component to the second client computing device in response to the input audio signal.
system.
前記第1のクライアントコンピューティングデバイスの前記第2の位置が前記第2のクライアントコンピューティングデバイスまでの前記所定の距離の外にあると判定し、前記第1のクライアントコンピューティングデバイスの前記第2の位置が前記所定の距離の外にあるとの判定に基づいて、前記第2のクライアントコンピューティングデバイスによって受け取られたオーディオ信号の処理のための前記第1のクライアントコンピューティングデバイスの前記第1のオーディオ識別モデルへのアクセスを無効にするための前記認証コンポーネントとを備える、
請求項1に記載のシステム。 With the interface for receiving the second position of the first client computing device,
It is determined that the second position of the first client computing device is outside the predetermined distance to the second client computing device, and the second position of the first client computing device is determined. The first audio of the first client computing device for processing an audio signal received by the second client computing device based on the determination that the position is outside the predetermined distance. With the authentication component for disabling access to the discriminative model,
The system according to claim 1.
請求項1または2に記載のシステム。 The authentication component for ranking the first identification score and the second identification score based on the metadata of the first audio identification model and the metadata of the second audio identification model.
The system according to claim 1 or 2.
請求項3に記載のシステム。 The metadata of the first audio discriminative model and the metadata of the second audio discriminative model include at least one of error rate, sensor type indication, and number of sensors.
The system according to claim 3.
請求項1から4のいずれか一項に記載のシステム。 The profile is associated with the user of the first client computing device.
The system according to any one of claims 1 to 4.
請求項1から5のいずれか一項に記載のシステム。 Each of the plurality of candidate profiles is associated with each audio discriminative model.
The system according to any one of claims 1 to 5.
前記第1のオーディオ識別モデルに基づいて第3の識別スコアを生成し、前記第2のオーディオ識別モデルに基づいて第4の識別スコアを生成し、前記第3の識別スコアおよび前記第4の識別スコアのランク付けに基づいて前記第1のオーディオ識別モデルに関連するプロファイルを選択し、前記第2のオーディオ入力信号に基づいて前記第1のオーディオ識別モデルを更新するための前記認証コンポーネントとを備える、
請求項1から6のいずれか一項に記載のシステム。 With the interface for receiving the second audio input signal from the second client computing device,
A third identification score is generated based on the first audio identification model, a fourth identification score is generated based on the second audio identification model, and the third identification score and the fourth identification are generated. It comprises the authentication component for selecting a profile associated with the first audio discriminative model based on score ranking and updating the first audio discriminative model based on the second audio input signal. ,
The system according to any one of claims 1 to 6.
前記第1のオーディオ識別モデルに基づいて第3の識別スコアを生成し、前記第2のオーディオ識別モデルに基づいて第4の識別スコアを生成し、前記第3の識別スコアおよび前記第4の識別スコアのランク付けに基づいて前記第1のオーディオ識別モデルに関連するプロファイルを選択し、前記第2のオーディオ入力信号に基づいて第3のオーディオ識別モデルを生成するための前記認証コンポーネントとを備える、
請求項1から6のいずれか一項に記載のシステム。 With the interface for receiving the second audio input signal from the second client computing device,
A third identification score is generated based on the first audio identification model, a fourth identification score is generated based on the second audio identification model, and the third identification score and the fourth identification are generated. It comprises the authentication component for selecting a profile associated with the first audio discriminative model based on score ranking and generating a third audio discriminative model based on the second audio input signal.
The system according to any one of claims 1 to 6.
前記第1のクライアントコンピューティングデバイスの前記第2の位置が前記第2のクライアントコンピューティングデバイスまでの前記所定の距離の外にあると判定し、前記第1のクライアントコンピューティングデバイスの前記第2の位置が前記第2のクライアントコンピューティングデバイスまでの前記所定の距離の外にあるとの判定に基づいて前記第1のオーディオ識別モデルと前記第3のオーディオ識別モデルとを合併するための前記認証コンポーネントとを備える、
請求項8に記載のシステム。 With the interface for receiving the second position of the first client computing device,
It is determined that the second position of the first client computing device is outside the predetermined distance to the second client computing device, and the second position of the first client computing device is determined. The authentication component for merging the first audio identification model and the third audio identification model based on the determination that the position is outside the predetermined distance to the second client computing device. With,
The system according to claim 8.
前記認可の通知に応答して前記第1のクライアントコンピューティングデバイスから承認メッセージを受け取ることに基づいて前記第1のクライアントコンピューティングデバイスの前記第1のオーディオ識別モデルを前記第2のクライアントコンピューティングデバイスに関連付けるための前記認証コンポーネントとを備える、
請求項1から9のいずれか一項に記載のシステム。 With the interface for sending authorization notifications to the first client computing device,
Based on receiving an authorization message from the first client computing device in response to the authorization notification, the first audio identification model of the first client computing device is adapted to the second client computing device. With the authentication component for associating with
The system according to any one of claims 1 to 9.
データ処理システムのインターフェースによって第1のクライアントコンピューティングデバイスの位置を受け取るステップであって、前記第1のクライアントコンピューティングデバイスが、第1のオーディオ識別モデルに関連付けられる、ステップと、
前記データ処理システムによって実行される認証コンポーネントによって、前記第1のクライアントコンピューティングデバイスの前記位置が第2のクライアントコンピューティングデバイスまで所定の距離以内にあると判定するステップであって、前記第2のクライアントコンピューティングデバイスが、第2のオーディオ識別モデルに関連付けられる、ステップと、
前記第1のクライアントコンピューティングデバイスの前記位置が前記第2のクライアントコンピューティングデバイスまで前記所定の距離以内にあるという判定に基づいて、前記第2のクライアントコンピューティングデバイスによって受け取られたオーディオ信号の処理のための前記第1のクライアントコンピューティングデバイスの前記第1のオーディオ識別モデルへのアクセスを提供するステップと、
前記インターフェースによって前記第2のクライアントコンピューティングデバイスから入力オーディオ信号を受け取るステップと、
前記認証コンポーネントによって、前記第1のオーディオ識別モデルに基づいて第1の識別スコアを生成し、前記第2のオーディオ識別モデルに基づいて第2の識別スコアを生成するステップと、
前記認証コンポーネントによって、前記第1の識別スコアおよび前記第2の識別スコアに基づいて複数の候補プロファイルからプロファイルを選択するステップと、
コンテンツ選択コンポーネントによって前記プロファイルに基づいてデジタルコンポーネントを選択するステップと、
前記インターフェースによって、前記入力オーディオ信号に応答して前記第2のクライアントコンピューティングデバイスに前記デジタルコンポーネントを送信するステップとを含む、
方法。 A way to customize content in a voice-operated system
A step of receiving the location of a first client computing device through an interface of a data processing system, wherein the first client computing device is associated with a first audio discriminative model.
The second step of determining that the position of the first client computing device is within a predetermined distance to the second client computing device by the authentication component performed by the data processing system. With the steps that the client computing device is associated with the second audio identification model,
Processing of the audio signal received by the second client computing device based on the determination that the position of the first client computing device is within the predetermined distance to the second client computing device. To provide access to the first audio identification model of the first client computing device for
The step of receiving an input audio signal from the second client computing device by the interface,
A step of generating a first identification score based on the first audio identification model and a second identification score based on the second audio identification model by the authentication component.
A step of selecting a profile from a plurality of candidate profiles based on the first identification score and the second identification score by the authentication component.
The step of selecting a digital component based on the profile by the content selection component, and
The interface comprises transmitting the digital component to the second client computing device in response to the input audio signal.
Method.
前記認証コンポーネントによって、前記第1のクライアントコンピューティングデバイスの前記第2の位置が前記第2のクライアントコンピューティングデバイスまでの前記所定の距離の外にあると判定するステップと、
前記認証コンポーネントによって、前記第1のクライアントコンピューティングデバイスの前記第2の位置が前記所定の距離の外にあるとの判定に基づいて、前記第2のクライアントコンピューティングデバイスによって受け取られたオーディオ信号の処理のための前記第1のクライアントコンピューティングデバイスの前記第1のオーディオ識別モデルへのアクセスを無効にするステップとを含む、
請求項11に記載の方法。 The step of receiving the second position of the first client computing device by the interface,
A step of determining that the second position of the first client computing device is outside the predetermined distance to the second client computing device by the authentication component.
Of the audio signal received by the second client computing device, based on the determination by the authentication component that the second position of the first client computing device is outside the predetermined distance. A step of disabling access to the first audio identification model of the first client computing device for processing.
The method of claim 11.
請求項11または12に記載の方法。 The authentication component comprises a step of ranking the first identification score and the second identification score based on the metadata of the first audio identification model and the metadata of the second audio identification model.
The method of claim 11 or 12.
請求項13に記載の方法。 The metadata of the first audio discriminative model and the metadata of the second audio discriminative model include at least one of error rate, sensor type indication, and number of sensors.
13. The method of claim 13.
前記認証コンポーネントによって、前記第1のオーディオ識別モデルに基づいて第3の識別スコアを生成し、前記第2のオーディオ識別モデルに基づいて第4の識別スコアを生成するステップと、
前記認証コンポーネントによって、前記第3の識別スコアおよび前記第4の識別スコアのランク付けに基づいて前記第1のオーディオ識別モデルに関連するプロファイルを選択するステップと、
前記認証コンポーネントによって前記第2のオーディオ入力信号に基づいて前記第1のオーディオ識別モデルを更新するステップとを含む、
請求項11から14のいずれか一項に記載の方法。 A step of receiving a second audio input signal from the second client computing device through the interface,
A step of generating a third discriminative score based on the first audio discriminative model and a fourth discriminative score based on the second audio discriminative model by the authentication component.
A step of selecting a profile associated with the first audio identification model based on the ranking of the third identification score and the fourth identification score by the authentication component.
The authentication component includes a step of updating the first audio identification model based on the second audio input signal.
The method according to any one of claims 11 to 14.
前記認証コンポーネントによって、前記第1のオーディオ識別モデルに基づいて第3の識別スコアを生成し、前記第2のオーディオ識別モデルに基づいて第4の識別スコアを生成するステップと、
前記認証コンポーネントによって、前記第3の識別スコアおよび前記第4の識別スコアのランク付けに基づいて前記第1のオーディオ識別モデルに関連するプロファイルを選択するステップと、
前記認証コンポーネントによって前記第2のオーディオ入力信号に基づいて第3のオーディオ識別モデルを生成するステップとを含む、
請求項11から14のいずれか一項に記載の方法。 A step of receiving a second audio input signal from the second client computing device through the interface,
A step of generating a third discriminative score based on the first audio discriminative model and a fourth discriminative score based on the second audio discriminative model by the authentication component.
A step of selecting a profile associated with the first audio identification model based on the ranking of the third identification score and the fourth identification score by the authentication component.
A step of generating a third audio identification model based on the second audio input signal by the authentication component.
The method according to any one of claims 11 to 14.
前記認証コンポーネントによって、前記第1のクライアントコンピューティングデバイスの前記第2の位置が前記第2のクライアントコンピューティングデバイスまでの前記所定の距離の外にあると判定するステップと、
前記認証コンポーネントによって、前記第1のクライアントコンピューティングデバイスの前記第2の位置が前記第2のクライアントコンピューティングデバイスまでの前記所定の距離の外にあるとの判定に基づいて前記第1のオーディオ識別モデルと前記第3のオーディオ識別モデルとを合併するステップとを含む、
請求項16に記載の方法。 The step of receiving the second position of the first client computing device by the interface,
A step of determining that the second position of the first client computing device is outside the predetermined distance to the second client computing device by the authentication component.
The authentication component determines that the second position of the first client computing device is outside the predetermined distance to the second client computing device, and the first audio identification. Including the step of merging the model with the third audio discriminative model.
The method of claim 16.
前記データ処理システムによって、前記認可の通知に応答して前記第1のクライアントコンピューティングデバイスから承認メッセージを受け取ることに基づいて前記第1のクライアントコンピューティングデバイスの前記第1のオーディオ識別モデルを前記第2のクライアントコンピューティングデバイスに関連付けるステップとを含む、
請求項11から17のいずれか一項に記載の方法。 The step of sending an authorization notification to the first client computing device through the interface,
The first audio discriminative model of the first client computing device is based on receiving an approval message from the first client computing device by the data processing system in response to the authorization notification. Including steps to associate with 2 client computing devices,
The method according to any one of claims 11 to 17.
トランスデューサと、
入力オーディオ信号を検出するためのセンサと、
前記オーディオドライバ、前記トランスデューサ、および前記センサに結合されたプリプロセッサコンポーネントとを備えた、
デジタルアシスタントデバイスであって、前記プリプロセッサコンポーネントが、
フィルタリングされた入力オーディオ信号を生成するために前記入力オーディオ信号をフィルタリングすることと、
前記フィルタリングされた入力オーディオ信号をデータパケットに変換することと、
コンテンツセレクタコンポーネント、インターフェース、および認証コンポーネントを実行する1つまたは複数のプロセッサおよびメモリを備えるデータ処理システムに前記データパケットを送信することとを行うためのものであり、前記データ処理システムが、
前記インターフェースによって、第1のクライアントコンピューティングデバイスの位置を受け取ることであって、前記第1のクライアントコンピューティングデバイスが、第1のオーディオ識別モデルに関連付けられる、ことと、
前記認証コンポーネントによって、前記第1のクライアントコンピューティングデバイスの前記位置が前記デジタルアシスタントデバイスまで所定の距離以内にあると判定することと、
前記認証コンポーネントによって、前記第1のクライアントコンピューティングデバイスの前記位置が前記デジタルアシスタントデバイスまで前記所定の距離以内にあるという判定に基づいて、前記第1のクライアントコンピューティングデバイスの前記第1のオーディオ識別モデルへのアクセスを前記デジタルアシスタントデバイスに提供することであって、前記デジタルアシスタントデバイスが、第2のオーディオ識別モデルに関連付けられる、ことと、
前記認証コンポーネントによって、前記第1のオーディオ識別モデルに基づいて第1の識別スコアを生成し、前記第2のオーディオ識別モデルに基づいて第2の識別スコアを生成することと、
前記認証コンポーネントによって、前記第1の識別スコアおよび前記第2の識別スコアに基づいて複数の候補プロファイルからプロファイルを選択することと、
前記コンテンツセレクタコンポーネントによって、前記複数の候補プロファイルから選択された前記プロファイルに基づいてデジタルコンポーネントを選択することと、
前記インターフェースによって、前記入力オーディオ信号に応答して前記トランスデューサに前記デジタルコンポーネントを送信することとを行うためのものである、
デジタルアシスタントデバイス。 With an audio driver
Transducer and
A sensor for detecting the input audio signal and
With the audio driver, the transducer, and a preprocessor component coupled to the sensor.
A digital assistant device in which the preprocessor component is
Filtering the input audio signal to generate a filtered input audio signal, and
Converting the filtered input audio signal into a data packet and
It is intended to send the data packet to and from a data processing system having one or more processors and memory running a content selector component, an interface, and an authentication component.
By receiving the location of the first client computing device by the interface, the first client computing device is associated with the first audio discriminative model.
The authentication component determines that the position of the first client computing device is within a predetermined distance to the digital assistant device.
The authentication component determines that the position of the first client computing device is within the predetermined distance to the digital assistant device, and the first audio identification of the first client computing device. To provide access to the model to the digital assistant device, that the digital assistant device is associated with a second audio identification model.
The authentication component generates a first discriminative score based on the first audio discriminative model and a second discriminative score based on the second audio discriminative model.
The authentication component selects a profile from a plurality of candidate profiles based on the first identification score and the second identification score.
The content selector component selects a digital component based on the profile selected from the plurality of candidate profiles.
The interface is for transmitting the digital component to the transducer in response to the input audio signal.
Digital assistant device.
前記データ処理システムに前記第2の入力オーディオ信号を送信するための前記プリプロセッサコンポーネントとを備え、
前記データ処理システムが、
前記認証コンポーネントによって、前記第1のクライアントコンピューティングデバイスの第2の位置が前記デジタルアシスタントデバイスまでの前記所定の距離の外にあると判定し、
前記認証コンポーネントによって、前記第1のクライアントコンピューティングデバイスの前記第2の位置が前記所定の距離の外にあるとの判定に基づいて、前記第1のクライアントコンピューティングデバイスの前記第1のオーディオ識別モデルへの前記デジタルアシスタントデバイスのアクセスを無効にするためのものである、
請求項19に記載のデバイス。 With the sensor for detecting the second input audio signal,
The data processing system includes the preprocessor component for transmitting the second input audio signal.
The data processing system
The authentication component determines that the second position of the first client computing device is outside the predetermined distance to the digital assistant device.
The authentication component determines that the second position of the first client computing device is outside the predetermined distance, and the first audio identification of the first client computing device. It is for disabling access of the digital assistant device to the model,
The device of claim 19.
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
JP2022076175A JP2022107616A (en) | 2017-12-08 | 2022-05-02 | Distributed identification in networked system |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
PCT/US2017/065460 WO2019112624A1 (en) | 2017-12-08 | 2017-12-08 | Distributed identification in networked system |
Related Child Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2022076175A Division JP2022107616A (en) | 2017-12-08 | 2022-05-02 | Distributed identification in networked system |
Publications (2)
Publication Number | Publication Date |
---|---|
JP2021506008A true JP2021506008A (en) | 2021-02-18 |
JP7071504B2 JP7071504B2 (en) | 2022-05-19 |
Family
ID=60943104
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2020531004A Active JP7071504B2 (en) | 2017-12-08 | 2017-12-08 | Distributed identification in networked systems |
JP2022076175A Pending JP2022107616A (en) | 2017-12-08 | 2022-05-02 | Distributed identification in networked system |
Family Applications After (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2022076175A Pending JP2022107616A (en) | 2017-12-08 | 2022-05-02 | Distributed identification in networked system |
Country Status (6)
Country | Link |
---|---|
US (3) | US10992684B2 (en) |
EP (2) | EP4181553A1 (en) |
JP (2) | JP7071504B2 (en) |
KR (2) | KR102392717B1 (en) |
CN (2) | CN111448549B (en) |
WO (1) | WO2019112624A1 (en) |
Families Citing this family (8)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10079024B1 (en) * | 2016-08-19 | 2018-09-18 | Amazon Technologies, Inc. | Detecting replay attacks in voice-based authentication |
CN109146450A (en) * | 2017-06-16 | 2019-01-04 | 阿里巴巴集团控股有限公司 | Method of payment, client, electronic equipment, storage medium and server |
GB2563952A (en) * | 2017-06-29 | 2019-01-02 | Cirrus Logic Int Semiconductor Ltd | Speaker identification |
KR102392717B1 (en) | 2017-12-08 | 2022-04-29 | 구글 엘엘씨 | Distributed identification of network systems |
US11798546B2 (en) | 2020-08-14 | 2023-10-24 | Google Llc | Transient personalization mode for guest users of an automated assistant |
US11749284B2 (en) * | 2020-11-13 | 2023-09-05 | Google Llc | Dynamically adapting on-device models, of grouped assistant devices, for cooperative processing of assistant requests |
US20220382842A1 (en) * | 2021-05-31 | 2022-12-01 | Electronics And Telecommunications Research Institute | Authentication electronic device based on biometric template and operating method thereof |
CN116346885B (en) * | 2023-05-24 | 2023-07-28 | 北京飞轮数据科技有限公司 | Identification information generation method, identification information generation device, electronic equipment and computer readable medium |
Citations (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20160019889A1 (en) * | 2014-07-18 | 2016-01-21 | Google Inc. | Speaker verification using co-location information |
US20170185669A1 (en) * | 2015-12-29 | 2017-06-29 | Futurewei Technologies, Inc. | System and Method for User-Behavior Based Content Recommendations |
Family Cites Families (28)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20170237801A1 (en) * | 2004-06-30 | 2017-08-17 | Google Inc. | Device configuration-based function delivery |
JP2006038955A (en) * | 2004-07-22 | 2006-02-09 | Docomo Engineering Tohoku Inc | Voiceprint recognition system |
US8214208B2 (en) * | 2006-09-28 | 2012-07-03 | Reqall, Inc. | Method and system for sharing portable voice profiles |
CN101673544B (en) * | 2009-10-10 | 2012-07-04 | 上海电虹软件有限公司 | Cross monitoring method and system based on voiceprint recognition and location tracking |
JP5757561B2 (en) * | 2011-03-04 | 2015-07-29 | Ｎｅｃカシオモバイルコミュニケーションズ株式会社 | Access permission system and access permission judgment method |
US9159324B2 (en) * | 2011-07-01 | 2015-10-13 | Qualcomm Incorporated | Identifying people that are proximate to a mobile device user via social graphs, speech models, and user context |
US9282096B2 (en) * | 2013-08-31 | 2016-03-08 | Steven Goldstein | Methods and systems for voice authentication service leveraging networking |
US10405163B2 (en) * | 2013-10-06 | 2019-09-03 | Staton Techiya, Llc | Methods and systems for establishing and maintaining presence information of neighboring bluetooth devices |
US20150162004A1 (en) * | 2013-12-09 | 2015-06-11 | Erwin Goesnar | Media content consumption with acoustic user identification |
US20150255068A1 (en) * | 2014-03-10 | 2015-09-10 | Microsoft Corporation | Speaker recognition including proactive voice model retrieval and sharing features |
US9710546B2 (en) * | 2014-03-28 | 2017-07-18 | Microsoft Technology Licensing, Llc | Explicit signals personalized search |
US9674700B2 (en) * | 2014-11-04 | 2017-06-06 | Qualcomm Incorporated | Distributing biometric authentication between devices in an ad hoc network |
WO2016095218A1 (en) * | 2014-12-19 | 2016-06-23 | Dolby Laboratories Licensing Corporation | Speaker identification using spatial information |
US9112849B1 (en) * | 2014-12-31 | 2015-08-18 | Spotify Ab | Methods and systems for dynamic creation of hotspots for media control |
US9979724B2 (en) * | 2015-02-06 | 2018-05-22 | NXT-ID, Inc. | Distributed method and system to improve collaborative services across multiple devices |
US9807610B2 (en) * | 2015-03-26 | 2017-10-31 | Intel Corporation | Method and apparatus for seamless out-of-band authentication |
US20170092278A1 (en) | 2015-09-30 | 2017-03-30 | Apple Inc. | Speaker recognition |
US9928840B2 (en) | 2015-10-16 | 2018-03-27 | Google Llc | Hotword recognition |
US9747926B2 (en) | 2015-10-16 | 2017-08-29 | Google Inc. | Hotword recognition |
US10691473B2 (en) | 2015-11-06 | 2020-06-23 | Apple Inc. | Intelligent automated assistant in a messaging environment |
US10192552B2 (en) | 2016-06-10 | 2019-01-29 | Apple Inc. | Digital assistant providing whispered speech |
EP4235645A3 (en) * | 2016-07-06 | 2023-10-04 | DRNC Holdings, Inc. | System and method for customizing smart home speech interfaces using personalized speech profiles |
US9892732B1 (en) * | 2016-08-12 | 2018-02-13 | Paypal, Inc. | Location based voice recognition system |
US10027662B1 (en) * | 2016-12-06 | 2018-07-17 | Amazon Technologies, Inc. | Dynamic user authentication |
US20190182176A1 (en) * | 2016-12-21 | 2019-06-13 | Facebook, Inc. | User Authentication with Voiceprints on Online Social Networks |
US10672402B2 (en) * | 2017-04-11 | 2020-06-02 | International Business Machines Corporation | Speech with context authenticator |
US10438594B2 (en) * | 2017-09-08 | 2019-10-08 | Amazon Technologies, Inc. | Administration of privileges by speech for voice assistant system |
KR102392717B1 (en) | 2017-12-08 | 2022-04-29 | 구글 엘엘씨 | Distributed identification of network systems |
-
2017
- 2017-12-08 KR KR1020207018444A patent/KR102392717B1/en active IP Right Grant
- 2017-12-08 WO PCT/US2017/065460 patent/WO2019112624A1/en unknown
- 2017-12-08 EP EP22216007.9A patent/EP4181553A1/en active Pending
- 2017-12-08 US US16/063,128 patent/US10992684B2/en active Active
- 2017-12-08 CN CN201780097541.2A patent/CN111448549B/en active Active
- 2017-12-08 EP EP17826345.5A patent/EP3707606B1/en active Active
- 2017-12-08 KR KR1020227014095A patent/KR102502617B1/en active IP Right Grant
- 2017-12-08 JP JP2020531004A patent/JP7071504B2/en active Active
- 2017-12-08 CN CN202410048448.4A patent/CN117879949A/en active Pending
-
2021
- 2021-04-22 US US17/237,573 patent/US11683320B2/en active Active
-
2022
- 2022-05-02 JP JP2022076175A patent/JP2022107616A/en active Pending
-
2023
- 2023-05-03 US US18/142,926 patent/US20230275902A1/en active Pending
Patent Citations (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20160019889A1 (en) * | 2014-07-18 | 2016-01-21 | Google Inc. | Speaker verification using co-location information |
US20170185669A1 (en) * | 2015-12-29 | 2017-06-29 | Futurewei Technologies, Inc. | System and Method for User-Behavior Based Content Recommendations |
Also Published As
Publication number | Publication date |
---|---|
JP7071504B2 (en) | 2022-05-19 |
WO2019112624A1 (en) | 2019-06-13 |
KR20220062420A (en) | 2022-05-16 |
US10992684B2 (en) | 2021-04-27 |
EP3707606B1 (en) | 2023-02-01 |
KR20200091895A (en) | 2020-07-31 |
JP2022107616A (en) | 2022-07-22 |
EP4181553A1 (en) | 2023-05-17 |
CN111448549A (en) | 2020-07-24 |
KR102502617B1 (en) | 2023-02-24 |
CN117879949A (en) | 2024-04-12 |
US20210243200A1 (en) | 2021-08-05 |
US20190182261A1 (en) | 2019-06-13 |
US11683320B2 (en) | 2023-06-20 |
US20230275902A1 (en) | 2023-08-31 |
EP3707606A1 (en) | 2020-09-16 |
CN111448549B (en) | 2024-01-23 |
KR102392717B1 (en) | 2022-04-29 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
JP7071504B2 (en) | Distributed identification in networked systems | |
KR102100976B1 (en) | Digital assistant processing with stack data structure background | |
US11508371B2 (en) | Digital assistant processing of stacked data structures | |
US11855988B2 (en) | Synchronizing access controls between computing devices | |
CN110637300B (en) | Delayed two-factor authentication in a networking environment | |
JP6995966B2 (en) | Digital assistant processing of stacked data structures | |
JP7262565B2 (en) | Delayed two-factor authentication in networked environments |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
A621 | Written request for application examination |
Free format text: JAPANESE INTERMEDIATE CODE: A621Effective date: 20200804 |
|
A977 | Report on retrieval |
Free format text: JAPANESE INTERMEDIATE CODE: A971007Effective date: 20210716 |
|
A131 | Notification of reasons for refusal |
Free format text: JAPANESE INTERMEDIATE CODE: A131Effective date: 20210816 |
|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20211109 |
|
TRDD | Decision of grant or rejection written | ||
A01 | Written decision to grant a patent or to grant a registration (utility model) |
Free format text: JAPANESE INTERMEDIATE CODE: A01Effective date: 20220404 |
|
A61 | First payment of annual fees (during grant procedure) |
Free format text: JAPANESE INTERMEDIATE CODE: A61Effective date: 20220506 |
|
R150 | Certificate of patent or registration of utility model |
Ref document number: 7071504Country of ref document: JPFree format text: JAPANESE INTERMEDIATE CODE: R150 |