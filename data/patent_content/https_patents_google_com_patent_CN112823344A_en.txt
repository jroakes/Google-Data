CN112823344A - Low latency differential access control in time series predictive systems - Google Patents
Low latency differential access control in time series predictive systems Download PDFInfo
- Publication number
- CN112823344A CN112823344A CN201980066158.XA CN201980066158A CN112823344A CN 112823344 A CN112823344 A CN 112823344A CN 201980066158 A CN201980066158 A CN 201980066158A CN 112823344 A CN112823344 A CN 112823344A
- Authority
- CN
- China
- Prior art keywords
- requestor
- server
- action
- query
- actions
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
Images
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L63/00—Network architectures or network communication protocols for network security
- H04L63/10—Network architectures or network communication protocols for network security for controlling access to devices or network resources
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/30—Information retrieval; Database structures therefor; File system structures therefor of unstructured textual data
- G06F16/33—Querying
- G06F16/332—Query formulation
- G06F16/3322—Query formulation using system suggestions
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/903—Querying
- G06F16/9032—Query formulation
- G06F16/90324—Query formulation using system suggestions
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/93—Document management systems
Abstract
Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, implement low latency differential access control in a distributed predictive system. One of the methods includes: one or more grant action types for the requestor are obtained from the authorization server by the root server. A plurality of predicted actions are obtained that each co-occur with the search parameter in at least one document. Any actions having an action type that is not one of the one or more permitted action types of the requestor are filtered from the plurality of predicted actions. One or more predicted actions having one of the permitted action types are provided to the requestor.
Description
Background
The present description relates to large-scale, low-latency distributed computer systems, and more particularly to searching large data sets using distributed computer systems to generate real-time predictions of time-dependent user actions.
A time series prediction system, or prediction system for short, is a distributed computer system that predicts user actions based on a large-scale aggregation of time series data. This allows time-dependent actions to be discovered in real time and ranked by likelihood. Such a prediction system may be used in a wide variety of practical applications. One example application is query suggestion. For example, given a previous query entered by a user of a search engine, the prediction system may predict the next query that the user would like to enter by finding and ranking a number of previous queries entered by other users that are temporally related to the previous query. For example, if the user types in the first query "newborn clothing," the prediction system may predict that the next query is likely "crib," since a large number of previous users have typed both queries in close temporal proximity. Thus, the system may provide "crib" as a query suggestion for a user who types "newborn clothing" as a query. Importantly, the prediction system can compute such predictions in an online manner and in real time, e.g., after receiving a query, and with no discernable delay from the user's perspective. As a result, very low latency is critical to the majority of the operation of real-time predictive systems.
In the present specification, time-series data refers to data indicating a specific action group of a single specific user that commonly occurs within a specific short period of time. The length of the short period of time is a parameter that the system can tune to and is typically on the order of minutes, hours or days, rather than months or years. The prediction system may associate data representing user actions of a single user that occur together over a particular time period in a number of different ways. For example, the system may generate a single document that includes data representing all actions that occur together within a single time period. These techniques also allow the prediction system to discover user actions that are time-dependent, without regard to the magnitude of the actions that actually occur.
To make such predictions in real-time, the prediction system may use a distributed computer system to query the inverted index in parallel. The inverted index associates each user action with a document having at least one instance of the user action. For example, the prediction system may be arranged in a tree-based hierarchy having a root server, a plurality of intermediate servers at one or more levels, and a plurality of leaf servers. This arrangement allows a set of index data to be searched in real time, which is important because the space of searchable parameters prevents the complete index from being pre-generated. In this context, a complete index would require that a publication list be generated for each possible value of each searchable reference parameter predicted by each possible request. In systems with very large data sets, it is not possible, or at least not feasible, to generate such a complete index.
Privacy and anonymity are other important aspects of the predictive system that searches for documents that each store time-related data for a single respective user. To ensure user privacy and anonymity, the prediction system may have a built-in privacy mechanism that ensures that a particular user action is returned only when the user action is performed by at least a threshold number of other users. In this specification, this threshold will be referred to as a privacy threshold. Thus, if the privacy threshold is 100 users, and if only 88 other users performed a particular action, the system will refuse to provide the particular action because the particular action fails to meet the privacy threshold. This mechanism prevents highly personalized user data from being revealed to other users. Suitable techniques for quickly calculating an estimated number of users for a particular action are described in commonly-owned U.S. patent application No.15/277,306 for "general purpose engine for predicting actions," which is incorporated herein by reference.
Large scale prediction systems present inherent scalability challenges, particularly when used in applications with very low latency requirements, such as providing online query suggestions. These scalability challenges grow as the organization and the amount of underlying data grows.
One particular scalability problem with large scale predictive systems is differential access control, which means that different groups or entities within an organization are given different rights to query or access underlying data. Even when a single organization has full control of all underlying data, allowing all internal teams to query all available data does not follow the least privileged principles.
However, performing differential access control on the underlying data itself may introduce unacceptable latency. For example, this may require all leaf servers to communicate with an external authorization system for each query or each document, or both. This is because the underlying security principles require that any membership or permission change to any recognized group or entity should be enforced as quickly as possible to prevent unauthorized access. Therefore, it is not possible to store the authorization information on the leaf server because such rights update will take a long time when there are thousands of leaf servers to update. However, having the leaf servers communicate with an external authorization system introduces unacceptable latency to the process, especially when thousands of leaf servers need to provide thousands of requests per second. For example, if there are 1000 leaf servers that need to analyze 1000 actions per query and provide 1000 requests per second, the authorization system itself would need to process 10 million requests per second, which is not feasible for real-time applications because it introduces unacceptable latency in the process.
Disclosure of Invention
This specification describes techniques for implementing low latency differential access control in a predictive system using typed time series data. Implementing differential access control means that the predictive system controls different access levels of different requesting entities or groups, whereas implementing them with low latency means that performing differential access control does not significantly reduce the latency of the predictive system.
Other embodiments of the present disclosure include methods, systems, and apparatus, including computer programs encoded on computer storage media, to implement low latency differential access control in a distributed predictive system. One of the methods includes: one or more grant action types for the requestor are obtained from the authorization server by the root server. A plurality of predicted actions are obtained that each co-occur with the search parameter in at least one document. Any actions having an action type that is not one of the one or more permitted action types of the requestor are filtered from the plurality of predicted actions. One or more predicted actions having one of the permitted action types are provided to the requestor.
Particular embodiments of the subject matter described in this specification can be implemented to realize one or more of the following advantages. The predictive system can perform differential access control on any number of entities or groups on an arbitrarily large data set without causing a significant reduction in system latency. Thus, differential access control is scalable to increase data sets and increase tissue size. The prediction system may also use caching to reduce latency in performing differential access control. Thus, even if hundreds or thousands of queries are serviced per second, providing differential access control has an almost immeasurable impact on system latency. The techniques described below also reduce storage redundancy by allowing the prediction system to maintain a single data set for all requesters without having to manage multiple redundant data sets for multiple groups.
The details of one or more embodiments of the subject matter of this specification are set forth in the accompanying drawings and the description below. Other features, aspects, and advantages of the subject matter will become apparent from the description, the drawings, and the claims.
Drawings
Fig. 1 is a diagram illustrating an example system.
FIG. 2 is a flow diagram of an example process for performing access control on action types by a prediction system.
Like reference numbers and designations in the various drawings indicate like elements.
Detailed Description
Fig. 1 is a diagram illustrating an example system 100. The system 100 includes an example search system 102, the example search system 102 being an example of a system that uses a prediction system 110 to make real-time predictions from typed time-series data. In this example, the search system 102 uses the prediction system 110 to predict the online video subsystem 122 and the search engine subsystem 124. However, the same techniques described below may also be used for other predictive systems that do not enhance the search capabilities described with respect to the search system 102.
In this specification, typed data means that some user actions belong to one action type of a plurality of different action types. For example, the prediction system may treat a query as one action type, a web page visit as another action type, and a video view as yet another action type. The action types need not be mutually exclusive. For example, accessing a web page with an embedded video may be viewed as both a web page access action and a video viewing action. Documents searched by predictive systems often have many different types of user actions. For example, a document may indicate that particular users all typed a query within a particular time period, then visited a website, and then viewed a video. Having different types of time-dependent actions allows the prediction system to perform aggregated cross-type prediction. Thus, for example, the prediction system may determine which queries a user is likely to type after viewing a particular video.
The prediction system may associate data representing user actions of a single user that occur together over a particular time period in a number of different ways. For example, the system may generate a single document that includes data representing all of the actions that occurred together during a single time period. The document may be a record in a database, a memory object, or an electronic document, which may, but need not, correspond to a file in a file system. In this specification, for the sake of brevity, documents will refer broadly to such associated data representing time-related user actions of a single user.
For the sake of brevity, this specification includes various examples describing operations performed on actions. Such examples should be understood as operating on data representing such user actions. For example, each different user action may be represented by a unique identifier. In addition, different actions performed by different users at different times may be considered the same action if they are mapped to the same unique identifier. For example, a first user submitting a query for "basketball" would be considered the same action as a second user who later submitted the same query.
The prediction system may use data representing many different types of user actions. In general, the actions may be data representing any suitable action performed by or on behalf of a user on any interactive system, such as a web search system, image search system, map system, email system, social networking system, blog system, shopping system, to name a few. The action may also represent an event related to the user, such as the receipt of an email message or a higher level task. The user action may be, for example, the submission of a particular query; selecting a particular search result or any search result in response to the particular query; access or long term access to a particular website, page or image; watching a video; submitting a request for directions to the sight spot of interest; receiving a message confirming a hotel, flight or restaurant reservation or confirming the purchase of a particular product or a certain product or a particular service or a certain service; or purchase a particular product or service.
For example, the document may include other information about each action, such as the location of the action, the time of day, day of week, date, or season. The location may be obtained from a location obtained from a user device used to interact with the interactive system, or from a service provider, e.g. a mobile telephone network, or may be inferred, e.g. from the IP address of the user device. The location may be recorded in a generalized form using identifiers of one or more quadrilaterals in a predetermined geographic grid.
In some cases, an action may be associated with an entity, particularly a person, place, thing, both tangible and intangible, of the real world. For example, the search system may determine that a particular query is for a particular city, and then the prediction system may associate a globally unique identifier for the city with the query in the document. Similarly, the shopping system or email system may determine that a user has purchased a particular product or service, associate it with a particular entity and a unique identifier of that product or service entity, and include this information in the corresponding activity record. Entities associated with a user's activities may be considered as potential interests of the user at the time of the activity.
In the fig. 1 example, video subsystem 122 is an online system that provides video to external user devices over a computer network, such as an intranet or the internet. For example, the external user device 160 may provide a request for the video URL 152 to the video subsystem 122. The video subsystem 122 may then use the requested video URL 152 to obtain a recommended video from the prediction system 110. The video subsystem 122 may then provide the requested video and one or more recommended videos 154 in response to receiving the video URL 152.
In this context, the recommended video may be a video that the prediction system 110 has determined is most likely to occur in a document with the requested video URL 152. As described above, a particular video co-occurring with the search parameters means that a single anonymous user has viewed both the video URL 152 and the co-occurring video at the same time for a particular period of time.
Thus, the video subsystem 122 may provide a query 132 to the root server 130, the query 132 specifying search parameters, the type of action requested, and optionally one or more conditions. In the example of fig. 1, the search parameter is a video URL 152 from the requesting user, and the requested action type is a video being viewed or an identifier representing the action type. In this example, query 132 also includes an optional condition that specifies that the search parameters and the requested action type must occur within one hour of each other in the base document.
In response to the query 132, the root server 130 broadcasts the query 132 to the plurality of leaf servers 120a through 120 n. In some implementations, the prediction system 110 also includes one or more levels of intermediate servers between the root server 130 and the leaf servers 120 a-120 n.
The leaf servers 120 a-120 n then search the corresponding index shard 105 to first identify the document having the requested video URL. Typically, the index shards 105 each store index documents. To perform parallel searches, the prediction system may store multiple shards of index data across multiple respective leaf servers, each shard being a portion of an entire data set. A shard may be one partition in a non-overlapping set of partitions, although a shard may also or alternatively be replicated among multiple servers. Each server in the system may have multiple replicas. Thus, the same shard of index data may be assigned to a pool of multiple leaf servers. Each pool of leaf servers handles queries for associated shards so that index data can be searched in parallel across shards.
The leaf servers 120 a-120 n then calculate scores for all other video viewing actions that occur in common in the document, and calculate a respective initial score for each of the commonly occurring video views based on the frequency with which each of the video views is observed to occur in the document in common with the requested video URL 152.
The leaf servers 120 a-120 n also calculate, for each co-occurring video, a metric of how many different users are represented by the co-occurring video. The prediction system 110 calculates a user count so that the root server 130 can ensure that any recommended video provided back to the end user is a video that meets the corresponding privacy threshold. Leaf servers 120a through 120n provide all co-occurring videos, scores, and user counts back to root server 130.
In a similar manner, the search engine subsystem 124 may also use the prediction system 110 to enhance the data it provides to the user. The two systems may use the same generic prediction system 110 even though the functionality of the search engine is very different from that of the video service subsystem.
The search engine subsystem 124 may thus receive the web query 156 from the external user device 162, and may respond to the web query 156 with search results and query suggestions 158.
To obtain query suggestions, the search engine subsystem may provide the query 134 to the root server 130. In this example, the query 134 has search parameters that specify the web query 156 received from the external user device 162. Query 134 also specifies the type of action requested, in this case other web queries. Thus, the query 134 requests from the prediction system 110 other web queries that are most likely to co-occur in the document with the web query 156 received from the external user device 162.
As illustrated in this example, the prediction system 110 computes predictions in real-time and on-line for a plurality of different requesting subsystems. In this context, computing predictions in real-time means that the end user will not observe significant delays due to computer processing limitations. In other words, the prediction may be calculated in milliseconds rather than seconds, minutes, or longer.
By having the root server perform authorization checking on the requested action type using the authorization server, the prediction system 110 can perform access control with minimal impact on latency. This reduces latency because many leaf servers 120 a-120 n do not need to perform authorization checks. Instead, root server 130 may perform a single authorization check for each query.
In addition, the root server 130 can perform very fast authorization checks by performing authorization by action type. In other words, authorization server 130 may map the requestor identifier to a set of permitted action types, and root server 130 responds to the requestor with only the predicted action having the permitted action type. The number of action types may be insignificant compared to the number of documents in the index shard 105. Thus, only a small amount of data needs to be transferred from authorization server 140 to root server 130.
In fig. 1, for example, the least privileged principle would specify that the video subsystem serving the recommended video need only access the action corresponding to the video viewing, and not other action types, such as query submission, selection of web search results, or request for driving directions, to name a few. Similarly, the search engine subsystem 124 would only need to access actions corresponding to the submitted query, and would not need to access other action types, such as video viewing. Root server 130 may efficiently perform such access control by controlling the types of actions allowed by each of the requesting subsystems using authorization server 140.
FIG. 2 is a flow diagram of an example process for performing access control on action types by a prediction system. For convenience, the process will be described as being performed by a system of one or more computers located in one or more locations and appropriately programmed according to the specification. Such as a suitably programmed predictive system. For example, the prediction system 110 of fig. 1 may perform an example process.
The system receives a query at a root server, the query specifying a token and, optionally, one or more requested action types (210). The action type is described as optional, as the system can use a default action type without specifying the action type, and simply return all available action types that meet the appropriate privacy threshold.
The token is a unique identifier of a searchable parameter in the inverted index. The token may be explicitly specified by the query itself, or implicitly specified by specifying the corresponding search parameters, which the root server may map to a particular token.
Each searchable parameter may specify any suitable attribute associated with the document. Thus, the inverted index may associate each unique token with each document having corresponding searchable parameters. For example, the token may correspond to a particular user action or attribute of a user associated with the document. For example, the token may represent a query of "green bay packers". The token may also represent location data, such as GPS coordinates or a name or identifier of a particular location or area, such as milwaukee, wisconsin. The token may also represent an attribute of the user, such as a user who has identified himself as a fan that likes or is a green bay packaging soccer team.
For example, the inverted index may thus have a unique token representing the query "green bay packer" and may associate all documents with which the user submitted the query "green bay packer" occurred with the unique token.
The system obtains the requestor's grant action type (220). The grant action type is the action type that is allowed to be returned for the requestor. Typically, the type of permitted action is based on the requesting entity or group that submitted the query. Thus, in some embodiments, each query is associated with a requestor identifier that uniquely distinguishes the entity or group from other entities or groups that submit queries.
To obtain the permit action type, the root server may send a request for the permit action type to an authorization server that maintains a mapping between the requestor identifier and the permit action type. For example, the root server may send a request to the authorization server specifying a requestor identifier "query-survey" for the internal team responsible for service query suggestions.
The authorization server may respond with zero or more grant action types for the requestor identifier. If the requestor has at least one permitted action type, then the root server may run a query. Conversely, if the requestor identifier does not permit the action type, the root server may refuse to perform the search or abort the search that is in progress. Additionally, the root server may also deny performing the search if the query specifies the requested action type and the authorization server indicates that the requested action type is not a permitted action type.
Alternatively, the root server may perform the search using the query while waiting for a response from the authorization server, because in systems designed for low latency, the query is typically executed faster than waiting for a response from the authorization server. The root server may then filter any action types that are not the requestor's allowed action types.
In some implementations, the permission action type is also based on a query flow identifier that distinguishes different applications of the same requestor. For example, a team with a requester identifier of "query-survey" may be responsible for query suggestions for video searches as well as query suggestions for image searches. In this case, the permitted action type for video search may be only a video search query, not an image search query. In contrast, the permitted action type for image search may be only an image search query, not a video search query. Thus, each query from the query suggestion team requesting a video search query may include a unique query stream identifier that indicates the intended application for the predicted video search query. Similarly, each query from the same query suggestion team requesting an image search query may include a different unique query stream identifier that indicates the application for the predicted image search query.
Thus, when a grant action type is requested from an authorization server, the root server may optionally specify a query flow identifier in addition to the requestor identifier.
The system may also reduce latency of grant checking by using a grant cache. The authorization cache maps the requestor identifier and optionally the query stream identifier to a permitted action type. Thus, upon receiving a request from an authorization server, the root server may add an entry to the authorization cache indicating that a particular requestor identifier, and optionally a query flow identifier, has been mapped to a particular set of action types by the authorization server.
The system may invalidate a cache entry in a number of different ways. For example, the system may use a lifetime-based eviction policy to periodically invalidate cache entries to facilitate full authorization checks with the authorization server. For example, entries in the authorization cache may be set to expire after a short period of time, such as 10 seconds, 30 seconds, 1 minute, or 10 minutes. In some embodiments, the expiration time is additional information provided by the authorization server. For example, the authorization server may return a shorter expiration time for more sensitive data. Alternatively or additionally, the system may use a default expiration time for the authorization cache, for example, when the authorization server does not provide an expiration time. Thus, if the lifetime of a cache entry is less than the expiration time, the system may determine that the cache entry is valid.
In some embodiments, the system caches entries at the user level. Thus, if requests from other users are received in the same request group of cache entries, the root server may still perform a full authentication check to ensure that the user is granted access to the requested action type.
The use of an authorization cache can significantly reduce latency compared to performing a full authorization check, with minimal risk of changes to the permissions. For example, if the root server responds to 1000 queries per second, and the default expiration time is 30 seconds, the root server will eventually service more than 30,000 requests without incurring a commensurate latency reduction due to authorization checks using caching.
The authorization server may also specify a sampling rate that represents the number of queries the root server must perform a full authorization check, regardless of the age of the entry in the authorization cache. In other words, the sampling rate indicates the maximum number of times an entry in the grant cache may be used for a particular requester.
The system optionally obtains a permission search token (230) for the requestor. In addition to the permit action type, the authorization server may also provide a permit search token for the requestor identifier and optionally also for the query flow identifier. Thus, if the provided search token is not among the permitted search tokens, the root server may refuse to provide any predicted actions, or refuse to provide a response altogether. For example, the system may restrict us-based teams to provide us-based locations as search tokens and may restrict european-based teams to provide european-based locations as search tokens.
The system optionally obtains one or more custom privacy thresholds (240). As described above, the privacy threshold is the minimum number of different users that the root server must have performed a particular action before returning the action in the response. Thus, the privacy threshold ensures that personalized privacy data is not revealed to other users.
The authorization server may use a default privacy threshold for all action types. Alternatively or additionally, the authorization server may maintain a different respective privacy threshold for each of the one or more action types.
In addition, the authorization server may use different privacy thresholds depending on the requestor, the query stream, or both. For example, the authorization server may maintain a mapping between each action type, requestor identifier, and optionally query stream identifier combination, and a corresponding privacy threshold. For example, the authorization server may map each query _ stream, action _ type, request _ id tuple to a particular privacy threshold for that tuple.
The root server may then perform a custom privacy threshold in determining which actions to return in response to the query.
The system returns an action (250) that allows the action type to satisfy the corresponding privacy threshold. As described above, the root server may optionally broadcast the search token to all leaf servers through one or more layers of intermediate servers. The leaf server may then use the inverted index to identify actions that occur in common in documents that have search parameters corresponding to the token.
To enforce restrictions on permitted action types, the root server may also specify to the leaf servers which action types are permitted, and the leaf servers may then enforce the restrictions by identifying only actions that belong to permitted action types.
Alternatively, the leaf server may simply return all actions with any action type, and the root server may perform filtering on the unapproved action types returned by the leaf server. This approach is generally faster because it requires the root server to convey less information to the leaf servers, and requires the leaf servers to perform simpler logic to identify the action.
The leaf server searches for a corresponding shard of the inverted index. For example, the inverted index may be arranged using a respective publication list for each uniquely identifiable search token. Each publication list of search tokens may include all documents with corresponding search parameters. The leaf server may identify a publication list of search tokens and scan the publication list to calculate a respective count of actions that commonly occur in the document and a respective user count for each action. If the query specifies the requested action type, the leaf server can only scan the publication list for documents having actions of the requested action type. The leaf server may then provide the discovered actions and the calculated counts to the next highest level server in the tree-based hierarchy, which may be an intermediate server or a root server.
The root server receives the co-occurring actions from the last stage of the leaf server or any intermediate server and a corresponding user count representing a metric of how many different users were performed for each action. In some embodiments, the system speeds up the calculation by calculating a lower limit on the user count rather than an exact value.
The root server may then calculate a score for the action and return a score distribution for the action having the permitted action type and satisfying the privacy threshold. In some implementations, the root server also enforces a score threshold by only returning actions that also have scores that satisfy the score threshold.
To further reduce latency, the root server may first filter the action types before computing the action scores. The root server may filter actions without a permitted action type based on the permitted action types received from the authorization server. For example, this may mean that the same document obtained for the same query may cause the root server to respond with different actions depending on the requestor. The root server may also filter actions for which there is no user count that meets the privacy threshold for the action. The root server may perform these filtering operations in any suitable order or concurrently.
To compute the score for an action, the root server may use statistics computed by the leaf servers and possibly aggregated intermediate servers. The leaf server may calculate a count of how many times each action was observed to have occurred with the reference parameter and how many times each action typically occurred. The root server may then aggregate these counts to compute a final corresponding score for each action.
In general, the score for an action given a search parameter represents the comparative prominence of the action that occurs in common in documents with the search parameter as compared to the action that occurs in any document. For example, the score of an action may represent the likelihood of an action occurring in an indexed document with the search parameter P (action | search _ parameter) compared to the general likelihood of an event occurring in all documents P (action). When the inference system stores event data in a document, the inference system may estimate P (action | search _ parameter) by dividing (1) the count of index documents that include a particular action and search parameters by (2) the count of index documents that include a particular action. The system may estimate p (action) by dividing (1) the document count including the action by (2) the count of indexed documents in the dataset. The root server may then calculate a final score S for the action:
S＝P(action|search_parameter)/P(action)。
the root server may rank the actions by the computed scores and may provide a ranked set of actions in response to the query. As described above, the disallowed action types and the action types that do not meet the privacy threshold have been filtered and are therefore not returned to the requestor.
Although the above techniques have been described in the context of differential privacy for low latency prediction systems, low latency differential privacy control may be applied using the same techniques to search within any system having document insights or content therein belonging to different respective entities, e.g., entities in an organization.
Embodiments of the subject matter and the functional operations described in this specification can be implemented in digital electronic circuitry, tangibly embodied computer software or firmware, computer hardware (including the structures disclosed in this specification and their structural equivalents), or combinations of one or more of them. Embodiments of the subject matter described in this specification can be implemented as one or more computer programs, i.e., one or more modules of computer program instructions encoded on a tangible, non-transitory storage medium for execution by, or to control the operation of, data processing apparatus. The computer storage medium may be a machine-readable storage device, a machine-readable storage substrate, a random or serial access memory device, or a combination of one or more of them. Alternatively or in addition, the program instructions may be encoded on an artificially generated propagated signal, e.g., a machine-generated electrical, optical, or electromagnetic signal, that is generated to encode information for transmission to suitable receiver apparatus for execution by a data processing apparatus.
The term "data processing apparatus" refers to data processing hardware and encompasses all kinds of apparatus, devices, and machines for processing data, including by way of example a programmable processor, a computer, or multiple processors or computers. The apparatus can also be, or include, special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit). The apparatus can optionally include, in addition to hardware, code that creates an execution environment for the computer program, e.g., code that constitutes processor firmware, a protocol stack, a database management system, an operating system, or a combination of one or more of them.
A computer program (which may also be referred to or described as a program, software application, app, module, software module, script, or code) can be written in any form of programming language, including compiled or interpreted languages or declarative or procedural languages, and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, or other unit suitable for use in a computing environment. A program may, but need not, correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data, such as in one or more scripts in a markup language document, in a single file dedicated to the program in question, or in multiple coordinated files, such as files that store one or more modules, sub programs, or portions of code. A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a data communication network.
That a system of one or more computers is configured to perform a particular operation or action means that the system has installed thereon software, firmware, hardware, or a combination thereof that, in operation, causes the system to perform the operation or action. That one or more computer programs are configured to perform particular operations or actions means that the one or more programs include instructions that, when executed by a data processing apparatus, cause the apparatus to perform the operations or actions.
As used in this specification, "engine" or "software engine" refers to a software-implemented input/output system that provides output that is different from input. The engine may be a coded block of functionality, such as a library, platform, software development kit ("SDK"), or object. Each engine may be implemented on any suitable type of computing device, such as a server, mobile phone, tablet computer, notebook computer, music player, e-book reader, laptop or desktop computer, PDA, smart phone, or other fixed or portable device, including one or more processors and computer-readable media. Additionally, two or more engines may be implemented on the same computing device or on different computing devices.
The processes and logic flows described in this specification can be performed by one or more programmable computers executing one or more computer programs to perform functions by operating on input data and generating output. The processes and logic flows can also be performed by, and in particular by, special purpose logic circuitry, e.g., an FPGA or an ASIC, or a combination of special purpose logic circuitry and one or more programmed computers.
A computer suitable for executing a computer program may be based on a general-purpose or special-purpose microprocessor or both or any other kind of central processing unit. Generally, a central processing unit will receive instructions and data from a read-only memory or a random access memory or both. The essential elements of a computer are a central processing unit for executing or executing instructions and one or more memory devices for storing instructions and data. The central processing unit and the memory can be supplemented by, or incorporated in, special purpose logic circuitry. Generally, a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks. However, a computer need not have such a device. Moreover, the computer may be embedded in another device, e.g., a mobile telephone, a Personal Digital Assistant (PDA), a mobile audio or video player, a game player, a Global Positioning System (GPS) receiver, or a portable storage device, such as a Universal Serial Bus (USB) flash drive, to name a few.
Computer readable media suitable for storing computer program instructions and data include all forms of non-volatile memory, media and memory devices, including by way of example semiconductor memory devices, e.g., EPROM, EEPROM, and flash memory devices; magnetic disks, such as internal hard disks or removable disks; magneto-optical disks; as well as CD-ROM discs and DVD-ROM discs.
To provide for interaction with a user, embodiments of the subject matter described in this specification can be implemented on a computer having: a display device for displaying information to a user, such as a CRT (cathode ray tube) or LCD (liquid crystal display) monitor; and a keyboard and a pointing device, such as a mouse, trackball, or presence-sensitive display or other surface through which a user may provide input to the computer. Other kinds of devices may also be used to provide for interaction with a user; for example, feedback provided to the user can be any form of sensory feedback, such as visual feedback, auditory feedback, or tactile feedback; and input from the user may be received in any form, including acoustic, speech, or tactile input. In addition, the computer may receive documents from a device used by the user by sending the documents to the device; the user is interacted with, for example, by sending a web page to a web browser on the user's device in response to a request received from the web browser. Moreover, a computer may interact with a user by sending a text message or other form of message to a personal device, such as a smartphone, running a messaging application and then receiving a response message from the user.
Embodiments of the subject matter described in this specification can be implemented in a computing system that includes a back-end component, e.g., as a data server, or that includes a middleware component, e.g., an application server, or that includes a front-end component, e.g., a client computer having a graphical user interface, a web browser, or an app through which a user can interact with an implementation of the subject matter described in this specification, or a computing system that includes any combination of one or more such back-end, middleware, or front-end components. The components of the system can be interconnected by any form or medium of digital data communication, e.g., a communication network. Examples of communication networks include a Local Area Network (LAN) and a Wide Area Network (WAN), such as the Internet.
The computing system may include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other. In some embodiments, the server transmits data, such as HTML pages, to the user device, for example to display data to a user interacting with the device and to receive user input from the user, the device acting as a client. Data generated at the user device, such as a result of the user interaction, may be received at the server from the device.
In addition to the above embodiments, the following embodiments are also innovative:
embodiment 1 is a method comprising:
receiving, by a root server of a predictive system, a query from a requestor specifying tokens corresponding to search parameters, the query being a request to the predictive system to compute user actions most likely to occur in conjunction with the search parameters in documents, each document including data representing actions performed by a single respective user during a particular time period;
obtaining, by the root server, one or more permitted action types for the requestor from the authorization server;
obtaining, by a root server, a plurality of predicted actions that each co-occur with search parameters in at least one document, comprising:
providing, by the root server, a token to each leaf server of the plurality of leaf servers,
searching, by each leaf server, documents assigned to the leaf server having search parameters corresponding to the token to determine one or more actions that occur with the search parameters in the documents having the search parameters, and
providing, by each leaf server, to a root server, one or more actions that occur together in a document having search parameters;
filtering any actions from the plurality of predicted actions that have an action type that is not one of the one or more permitted action types of the requestor; and
one or more predicted actions are provided to the requestor with one of the permitted action types in response to the query.
Embodiment 2 is the method of embodiment 1, wherein obtaining, by the root server, the plurality of predicted actions that each occur with the search parameter in the at least one document is performed at least partially concurrently with obtaining, from the authorization server, the one or more permitted action types for the requestor.
Embodiment 3 is the method of any of embodiments 1-2, wherein obtaining, by the root server, the one or more permitted action types for the requestor from the authorization server comprises:
maintaining, by the authorization server, a mapping between the requestor identifier and the permit action type; and
one or more permit action types are obtained by using the requestor identifier of the requestor as input to the mapping.
Embodiment 4 is the method of embodiment 3, wherein the mapping is further based on query flow identifiers of different applications that distinguish predicted actions of the same requestor.
Embodiment 5 is the method of any one of embodiments 1 to 4, further comprising:
receiving, by the root server, a second query from a second requestor specifying the type of action requested;
obtaining, by the root server, one or more permitted action types for the second requestor from the authorization server;
determining, by the root server, that the requested action type is not among the one or more permitted action types; and
in response, the predicted action is denied to be returned in response to the second query.
Embodiment 6 is the method of any one of embodiments 1 to 5, further comprising:
receiving, by the root server, a second query from a second requestor specifying the type of action requested;
obtaining, by the root server from the authorization server, an indication that the second requestor did not grant the type of action; and
in response, the predicted action is denied to be returned in response to the second query.
Embodiment 7 is the method of any one of embodiments 1 to 6, further comprising:
receiving, by the root server from the second requestor, a second query specifying a second token corresponding to the second search parameter;
obtaining, by the root server, one or more permission search tokens for the second requestor from the authorization server;
determining, by the root server, that the second token is not a permission search token for the second requestor; and
in response, the predicted action is denied to be returned in response to the second query.
Embodiment 8 is the method of any one of embodiments 1 to 7, further comprising:
receiving, by the root server, a second query;
determining, by the root server, that an entry in the authorization cache corresponding to the requestor of the second query is valid;
in response, the one or more permitted action types for the requestor of the second query are obtained from the authorization cache, through the root server, and not from the authorization server.
Embodiment 9 is the method of embodiment 8, wherein determining, by the root server, that the entry in the authorization cache corresponding to the requestor of the second query is valid comprises: it is determined that the entry is not greater than the threshold lifetime.
Embodiment 10 is the method of embodiment 8, wherein determining, by the root server, that the entry in the authorization cache corresponding to the requestor of the second query is valid comprises: it is determined that the under-sampled entry is not greater than the threshold lifetime.
Embodiment 11 is the method of any one of embodiments 1 to 10, further comprising:
obtaining, by a root server of a requestor, a requestor-specific privacy threshold; and
any actions having a respective user count that does not meet the requestor-specific privacy threshold are filtered from the plurality of predicted actions.
Embodiment 12 is the method of any of embodiments 1-11, wherein the one or more predicted actions returned to the first requestor includes a first predicted action having a first action type and a second predicted action having a second action type, wherein the first predicted action and the second predicted action occur in the same document, and further comprising:
receiving a second query from a second requestor specifying the same token;
determining that the first action type is not a permit action type for the second requestor and that the second action type is a permit action type for the second requestor; and
in response, only the second action type is provided to the second requestor.
Embodiment 13 is a system, comprising: one or more computers and one or more storage devices storing instructions that are operable, when executed by the one or more computers, to cause the one or more computers to perform the method of any of embodiments 1-12.
Embodiment 14 is a computer storage medium encoded with a computer program, the program comprising instructions operable, when executed by data processing apparatus, to cause the data processing apparatus to perform the method of any of embodiments 1 to 12.
While this specification contains many specific implementation details, these should not be construed as limitations on the scope of any invention or of what may be claimed, but rather as descriptions of features that may be specific to particular embodiments of particular inventions. Certain features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely, various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable subcombination. Moreover, although features may be described above as acting in certain combinations and even initially claimed as such, one or more features from a claimed combination can in some cases be excised from the combination, and the claimed combination may be directed to a subcombination or variation of a subcombination.
Similarly, while operations are depicted in the drawings in a particular order, this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order, or that all illustrated operations be performed, to achieve desirable results. In some cases, multitasking and parallel processing may be advantageous. Moreover, the separation of various system modules and components in the embodiments described above should not be understood as requiring such separation in all embodiments, and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.
Specific embodiments of the present subject matter have been described. Other embodiments are within the scope of the following claims. For example, the actions recited in the claims can be performed in a different order and still achieve desirable results. As one example, the processes depicted in the accompanying figures do not necessarily require the particular order shown, or sequential order, to achieve desirable results. In some cases, multitasking and parallel processing may be advantageous.
Claims (20)
1. A computer-implemented method, comprising:
receiving, by a root server of a prediction system from a requestor, a query specifying tokens corresponding to search parameters, the query being a request for the prediction system to calculate user actions that are most likely to occur in conjunction with the search parameters in documents, each document including data representing actions performed by a single respective user during a particular time period;
obtaining, by the root server, one or more permitted action types for the requestor from an authorization server;
obtaining, by the root server, a plurality of predicted actions that each co-occur with the search parameter in at least one document, comprising:
providing, by the root server, the token to each leaf server of a plurality of leaf servers,
searching, by each leaf server, documents assigned to the leaf server having the search parameter corresponding to the token to determine one or more actions that occur with the search parameter in the documents having the search parameter, and
providing, by each leaf server, the one or more actions that occur in common in documents having the search parameters to the root server;
filtering any actions from the plurality of predicted actions that have an action type that is not one of the one or more permitted action types of the requestor; and
providing one or more predicted actions with one of the permitted action types to the requestor in response to the query.
2. The method of claim 1, wherein obtaining, by the root server, the plurality of predicted actions that each occur with the search parameter in at least one document is performed at least partially concurrently with obtaining the one or more permitted action types of the requestor from the authorization server.
3. The method of claim 1, wherein obtaining, by the root server, the one or more permitted action types for the requestor from an authorization server comprises:
maintaining, by the authorization server, a mapping between requestor identifiers and permit action types; and
obtaining the one or more permit action types by using a requestor identifier of the requestor as input to the mapping.
4. The method of claim 3, wherein the mapping is further based on query flow identifiers that distinguish different applications of the predicted action for the same requestor.
5. The method of claim 1, further comprising:
receiving, by the root server, a second query from a second requestor specifying a type of action requested;
obtaining, by the root server, one or more permitted action types for the second requestor from the authorization server;
determining, by the root server, that the requested action type is not among the one or more permitted action types; and
in response, a predicted action is denied in response to the second query.
6. The method of claim 1, further comprising:
receiving, by the root server, a second query from a second requestor specifying a type of action requested;
obtaining, by the root server from the authorization server, an indication that the second requestor does not grant the type of action; and
in response, a predicted action is denied in response to the second query.
7. The method of claim 1, further comprising:
receiving, by the root server, a second query from a second requestor specifying a second token corresponding to a second search parameter;
obtaining, by the root server, one or more permission search tokens for the second requestor from the authorization server;
determining, by the root server, that the second token is not a permission search token for the second requestor; and
in response, a predicted action is denied in response to the second query.
8. The method of claim 1, further comprising:
receiving, by the root server, a second query;
determining, by the root server, that an entry in an authorization cache corresponding to a requestor of the second query is valid;
in response, one or more permitted action types of the requestor of the second query are obtained by the root server from the authorization cache instead of from the authorization server.
9. The method of claim 8, wherein determining, by the root server, that the entry in the authorization cache corresponding to the requestor of the second query is valid comprises: determining that the entry is not greater than a threshold lifetime.
10. The method of claim 8, wherein determining, by the root server, that the entry in the authorization cache corresponding to the requestor of the second query is valid comprises: determining that the sampling of the entry is not greater than a threshold lifetime.
11. The method of claim 1, further comprising:
obtaining, by the root server of the requestor, a requestor-specific privacy threshold; and
filtering any actions from the plurality of predicted actions that have a respective user count that does not meet the requestor-specific privacy threshold.
12. The method of claim 1, wherein the one or more predicted actions returned to the first requestor include a first predicted action having a first action type and a second predicted action having a second action type, wherein the first predicted action and the second predicted action occur in the same document, and further comprising:
receiving a second query from a second requestor specifying the same token;
determining that the first action type is not a permit action type for the second requester and that the second action type is a permit action type for the second requester; and
in response, only the second action type is provided to the second requestor.
13. A prediction system comprising a root server and a plurality of leaf servers, wherein each of the root server and the plurality of leaf servers are implemented on one or more respective computers of a plurality of computers, and wherein the system further comprises one or more storage devices storing instructions operable to, when executed by the plurality of computers implementing the root server and the plurality of leaf servers, cause the plurality of computers to perform operations comprising:
receiving, by a root server of the prediction system from a requestor, a query specifying tokens corresponding to search parameters, the query being a request for the prediction system to calculate user actions that are most likely to occur in conjunction with the search parameters in documents, each document including data representing actions performed by a single respective user during a particular time period;
obtaining, by the root server, one or more permitted action types for the requestor from an authorization server;
obtaining, by the root server, a plurality of predicted actions that each co-occur with the search parameter in at least one document, comprising:
providing, by the root server, the token to each leaf server of a plurality of leaf servers,
searching, by each leaf server, documents assigned to the leaf server having the search parameter corresponding to the token to determine one or more actions that occur with the search parameter in the documents having the search parameter, and
providing, by each leaf server, the one or more actions that occur in common in documents having the search parameters to the root server;
filtering any actions from the plurality of predicted actions that have an action type that is not one of the one or more permitted action types of the requestor; and
providing one or more predicted actions with one of the permitted action types to the requestor in response to the query.
14. The system of claim 13, wherein obtaining, by the root server, the plurality of predicted actions that each occur with the search parameter in at least one document is performed at least partially concurrently with obtaining the one or more permitted action types of the requestor from the authorization server.
15. The system of claim 13, wherein obtaining, by the root server, the one or more permitted action types for the requestor from an authorization server comprises:
maintaining, by the authorization server, a mapping between requestor identifiers and permit action types; and
obtaining the one or more permit action types by using a requestor identifier of the requestor as input to the mapping.
16. The system of claim 15, wherein the mapping is further based on query flow identifiers that distinguish different applications of the predicted action for the same requestor.
17. The system of claim 13, wherein the operations further comprise:
receiving, by the root server, a second query from a second requestor specifying a type of action requested;
obtaining, by the root server, one or more permitted action types for the second requestor from the authorization server;
determining, by the root server, that the requested action type is not among the one or more permitted action types; and
in response, a predicted action is denied in response to the second query.
18. The system of claim 13, wherein the operations further comprise:
receiving, by the root server, a second query from a second requestor specifying a type of action requested;
obtaining, by the root server from the authorization server, an indication that the second requestor does not grant the type of action; and
in response, a predicted action is denied in response to the second query.
19. The system of claim 13, wherein the operations further comprise:
receiving, by the root server, a second query from a second requestor specifying a second token corresponding to a second search parameter;
obtaining, by the root server, one or more permission search tokens for the second requestor from the authorization server;
determining, by the root server, that the second token is not a permission search token for the second requestor; and
in response, a predicted action is denied in response to the second query.
20. One or more non-transitory computer storage media encoded with computer program instructions that, when executed by one or more computers, cause the one or more computers to perform operations comprising:
receiving, by a root server of a prediction system from a requestor, a query specifying tokens corresponding to search parameters, the query being a request for the prediction system to calculate user actions that are most likely to occur in conjunction with the search parameters in documents, each document including data representing actions performed by a single respective user during a particular time period;
obtaining, by the root server, one or more permitted action types for the requestor from an authorization server;
obtaining, by the root server, a plurality of predicted actions that each co-occur with the search parameter in at least one document, including:
providing, by the root server, the token to each leaf server of a plurality of leaf servers,
searching, by each leaf server, documents assigned to the leaf server having the search parameter corresponding to the token to determine one or more actions that occur with the search parameter in the documents having the search parameter, and
providing, by each leaf server, the one or more actions that occur in common in documents having the search parameters to the root server;
filtering any actions from the plurality of predicted actions that have an action type that is not one of the one or more permitted action types of the requestor; and
providing one or more predicted actions with one of the permitted action types to the requestor in response to the query.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US16/124,586 US20200084213A1 (en) | 2018-09-07 | 2018-09-07 | Low-latency differential access controls in a time-series prediction system |
US16/124,586 | 2018-09-07 | ||
PCT/US2019/049909 WO2020051425A1 (en) | 2018-09-07 | 2019-09-06 | Low-latency differential access controls in a time-series prediction system |
Publications (1)
Publication Number | Publication Date |
---|---|
CN112823344A true CN112823344A (en) | 2021-05-18 |
Family
ID=68344970
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201980066158.XA Pending CN112823344A (en) | 2018-09-07 | 2019-09-06 | Low latency differential access control in time series predictive systems |
Country Status (4)
Country | Link |
---|---|
US (1) | US20200084213A1 (en) |
EP (1) | EP3847558A1 (en) |
CN (1) | CN112823344A (en) |
WO (1) | WO2020051425A1 (en) |
Families Citing this family (9)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11914592B2 (en) | 2018-02-27 | 2024-02-27 | Elasticsearch B.V. | Systems and methods for processing structured queries over clusters |
US11188531B2 (en) | 2018-02-27 | 2021-11-30 | Elasticsearch B.V. | Systems and methods for converting and resolving structured queries as search queries |
US11461270B2 (en) | 2018-10-31 | 2022-10-04 | Elasticsearch B.V. | Shard splitting |
US10997204B2 (en) | 2018-12-21 | 2021-05-04 | Elasticsearch B.V. | Cross cluster replication |
US11943295B2 (en) | 2019-04-09 | 2024-03-26 | Elasticsearch B.V. | Single bi-directional point of policy control, administration, interactive queries, and security protections |
US11431558B2 (en) | 2019-04-09 | 2022-08-30 | Elasticsearch B.V. | Data shipper agent management and configuration systems and methods |
US10891165B2 (en) * | 2019-04-12 | 2021-01-12 | Elasticsearch B.V. | Frozen indices |
US11182093B2 (en) | 2019-05-02 | 2021-11-23 | Elasticsearch B.V. | Index lifecycle management |
US11604674B2 (en) | 2020-09-04 | 2023-03-14 | Elasticsearch B.V. | Systems and methods for detecting and filtering function calls within processes for malware behavior |
Family Cites Families (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7630986B1 (en) * | 1999-10-27 | 2009-12-08 | Pinpoint, Incorporated | Secure data interchange |
US10169711B1 (en) * | 2013-06-27 | 2019-01-01 | Google Llc | Generalized engine for predicting actions |
US9361406B1 (en) * | 2013-12-27 | 2016-06-07 | Google Inc. | Query completions |
US20190058709A1 (en) * | 2017-08-16 | 2019-02-21 | Telefonaktiebolaget Lm Ericsson (Publ) | Tenant management method and system in a cloud computing environment |
RU2694001C2 (en) * | 2017-11-24 | 2019-07-08 | Общество С Ограниченной Ответственностью "Яндекс" | Method and system for creating a parameter of quality forecast for a forecasting model performed in a machine learning algorithm |
US11121919B2 (en) * | 2018-04-13 | 2021-09-14 | Vmware, Inc. | Methods and apparatus to determine a duration estimate and risk estimate of performing a maintenance operation in a networked computing environment |
-
2018
- 2018-09-07 US US16/124,586 patent/US20200084213A1/en not_active Abandoned
-
2019
- 2019-09-06 CN CN201980066158.XA patent/CN112823344A/en active Pending
- 2019-09-06 EP EP19794726.0A patent/EP3847558A1/en not_active Withdrawn
- 2019-09-06 WO PCT/US2019/049909 patent/WO2020051425A1/en unknown
Also Published As
Publication number | Publication date |
---|---|
EP3847558A1 (en) | 2021-07-14 |
WO2020051425A1 (en) | 2020-03-12 |
US20200084213A1 (en) | 2020-03-12 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN112823344A (en) | Low latency differential access control in time series predictive systems | |
US10157293B2 (en) | Approximate privacy indexing for search queries on online social networks | |
JP6803955B2 (en) | Latency reduction | |
US10282483B2 (en) | Client-side caching of search keywords for online social networks | |
US9460308B2 (en) | Multi-level privacy evaluation | |
US10176340B2 (en) | Abstracted graphs from social relationship graph | |
US11294911B2 (en) | Methods and systems for client side search ranking improvements | |
US20170083523A1 (en) | Granular Forward Indexes on Online Social Networks | |
US20170046390A1 (en) | Searching public posts on online social networks | |
US9684695B2 (en) | Ranking test framework for search results on an online social network | |
US20170277907A1 (en) | Abstracted Graphs from Social Relationship Graph | |
US20120197979A1 (en) | Web-wide content quality crowd sourcing | |
US11526773B1 (en) | Predicting accuracy of submitted data | |
KR20140038432A (en) | Predicting user navigation events | |
US10380124B2 (en) | Searching data sets | |
US9436742B1 (en) | Ranking search result documents based on user attributes | |
US10169711B1 (en) | Generalized engine for predicting actions | |
US20160140503A1 (en) | Database systems and methods for using credibility ratings of users to process online resumes in a social networking environment | |
US9922093B2 (en) | Managing presentation of online content | |
US9754036B1 (en) | Adapting third party applications | |
US20210126904A1 (en) | On-device privacy-preservation and personalization | |
US9152701B2 (en) | Query classification | |
US11100115B1 (en) | Infrastructure and method for generating search results | |
US11423034B1 (en) | Display of social content | |
KR101702767B1 (en) | System and method for searching document according to access right and type of document using bit |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination |