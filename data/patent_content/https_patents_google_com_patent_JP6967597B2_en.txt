JP6967597B2 - An image processor with a configurable number of active cores and an internal network that supports it - Google Patents
An image processor with a configurable number of active cores and an internal network that supports it Download PDFInfo
- Publication number
- JP6967597B2 JP6967597B2 JP2019543927A JP2019543927A JP6967597B2 JP 6967597 B2 JP6967597 B2 JP 6967597B2 JP 2019543927 A JP2019543927 A JP 2019543927A JP 2019543927 A JP2019543927 A JP 2019543927A JP 6967597 B2 JP6967597 B2 JP 6967597B2
- Authority
- JP
- Japan
- Prior art keywords
- processor
- instance
- program
- object code
- configuration
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F15/00—Digital computers in general; Data processing equipment in general
- G06F15/76—Architectures of general purpose stored program computers
- G06F15/80—Architectures of general purpose stored program computers comprising an array of processing units with common control, e.g. single instruction multiple data processors
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F1/00—Details not covered by groups G06F3/00 - G06F13/00 and G06F21/00
- G06F1/26—Power supply means, e.g. regulation thereof
- G06F1/32—Means for saving power
- G06F1/3203—Power management, i.e. event-based initiation of a power-saving mode
- G06F1/3234—Power saving characterised by the action undertaken
- G06F1/3243—Power saving in microcontroller unit
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F15/00—Digital computers in general; Data processing equipment in general
- G06F15/16—Combinations of two or more digital computers each having at least an arithmetic unit, a program unit and a register, e.g. for a simultaneous processing of several programs
- G06F15/163—Interprocessor communication
- G06F15/173—Interprocessor communication using an interconnection network, e.g. matrix, shuffle, pyramid, star, snowflake
- G06F15/17356—Indirect interconnection networks
- G06F15/17368—Indirect interconnection networks non hierarchical topologies
- G06F15/17375—One dimensional, e.g. linear array, ring
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F15/00—Digital computers in general; Data processing equipment in general
- G06F15/76—Architectures of general purpose stored program computers
- G06F15/80—Architectures of general purpose stored program computers comprising an array of processing units with common control, e.g. single instruction multiple data processors
- G06F15/8007—Architectures of general purpose stored program computers comprising an array of processing units with common control, e.g. single instruction multiple data processors single instruction multiple data [SIMD] multiprocessors
- G06F15/8023—Two dimensional arrays, e.g. mesh, torus
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T1/00—General purpose image data processing
- G06T1/20—Processor architectures; Processor configuration, e.g. pipelining
-
- Y—GENERAL TAGGING OF NEW TECHNOLOGICAL DEVELOPMENTS; GENERAL TAGGING OF CROSS-SECTIONAL TECHNOLOGIES SPANNING OVER SEVERAL SECTIONS OF THE IPC; TECHNICAL SUBJECTS COVERED BY FORMER USPC CROSS-REFERENCE ART COLLECTIONS [XRACs] AND DIGESTS
- Y02—TECHNOLOGIES OR APPLICATIONS FOR MITIGATION OR ADAPTATION AGAINST CLIMATE CHANGE
- Y02D—CLIMATE CHANGE MITIGATION TECHNOLOGIES IN INFORMATION AND COMMUNICATION TECHNOLOGIES [ICT], I.E. INFORMATION AND COMMUNICATION TECHNOLOGIES AIMING AT THE REDUCTION OF THEIR OWN ENERGY USE
- Y02D10/00—Energy efficient computing, e.g. low power processors, power management or thermal management
Description
発明の分野
本発明の分野は、全体的に、コンピューティングサイエンスに関し、より具体的には、設定可能な数のアクティブなコアを有する画像処理プロセッサおよびサポートする内部ネットワークに関する。
Field of Invention The field of invention is generally with respect to computing science, and more specifically with respect to image processors with a configurable number of active cores and supporting internal networks.
背景
画像処理には、通常、アレイに編成された画素値の処理が伴う。ここで、空間的に編成された２次元アレイは、画像の２次元の特性をキャプチャする（さらなる次元として、時間（たとえば、一続きの２次元画像）およびデータ型（たとえば、色）を含み得る）。通常のシナリオでは、配列された画素値は、静止画像または動きを撮影するための一続きのフレームを生成したカメラによって提供される。従来の画像処理プロセッサは、通常、両極端に分かれる。
Background image processing usually involves processing pixel values organized in an array. Here, the spatially organized two-dimensional array may include time (eg, a series of two-dimensional images) and data type (eg, color) as additional dimensions to capture the two-dimensional properties of the image. ). In a typical scenario, the arrayed pixel values are provided by the camera that generated a series of frames for capturing a still image or motion. Traditional image processors are usually divided into two extremes.
第１の極端な側面として、汎用プロセッサまたは汎用のようなプロセッサ（たとえば、ベクトル命令が強化された汎用プロセッサ）上で実行されるソフトウェアプログラムとして、画像処理タスクが実行される。第１の極端は、通常、高度の多目的アプリケーションソフトウェア開発プラットフォームを提供するが、細粒度のデータ構造を、関連するオーバーヘッド（たとえば、命令フェッチおよびデコード、オンチップデータおよびオフチップデータの処理、投機的実行）と組み合わせて利用することによって、最終的には、プログラムコードの実行時にデータの単位当たりに消費されるエネルギーの量が多くなってしまう。 As a first extreme aspect, an image processing task is performed as a software program running on a general purpose processor or a general purpose processor such as a general purpose processor (eg, a general purpose processor with enhanced vector instructions). The first extreme usually provides a highly versatile application software development platform, but with fine-grained data structures, associated overhead (eg instruction fetch and decode, on-chip and off-chip data processing, speculative). When used in combination with execution), the amount of energy consumed per unit of data when executing the program code will eventually increase.
正反対の第２の極端の側面として、より大きな単位のデータに、固定機能結線回路が適用される。カスタム設計された回路に直接適用される（細粒度とは対照的な）より大きな単位のデータを利用することによって、データの単位当たりの消費電力が大幅に抑えられる。しかしながら、カスタム設計された固定関数回路を利用することによって、一般に、プロセッサが実行できるタスクのセットが限られてしまう。このように、第２の極端な側面では、（第１の極端な側面に関連する）広く多目的なプログラミング環境がない。 As the opposite second extreme aspect, fixed function wiring circuits are applied to larger units of data. By utilizing larger units of data (as opposed to fine-grained) that are applied directly to custom-designed circuits, the power consumption per unit of data is significantly reduced. However, the use of custom-designed fixed-function circuits generally limits the set of tasks a processor can perform. Thus, in the second extreme aspect, there is no broad and versatile programming environment (related to the first extreme aspect).
高度の多目的アプリケーションソフトウェア開発機会およびデータの単位当たりの電力効率の向上を可能にするテクノロジープラットフォームが依然として望まれているが、いまだ解決策が見つかっていない。 Technology platforms that enable advanced multipurpose application software development opportunities and improved power efficiency per unit of data are still desired, but no solution has yet been found.
概要
方法を説明する。この方法は、プロセッサ上で実行するためのオブジェクトコードの第１インスタンスを構成するステップを含む。プロセッサは、複数のコアと、内部ネットワークとを有する。内部ネットワークは、第１の数のコアを通信可能に連結することを可能にする第１構成で構成される。また、方法は、プロセッサの第２インスタンス上で実行するためのオブジェクトコードの第２インスタンスを構成するステップを含む。プロセッサの第２インスタンスの内部ネットワークは、異なる数のコアを通信可能に連結することを可能にする第２構成で構成され、プロセッサおよびプロセッサの第２インスタンス上で同じ位置にあるコアは、第１構成および第２構成についてそれぞれ同じネットワークアドレスを有する。また、上記方法を可能にするように設計された内部ネットワークを有するプロセッサについても説明する。
Outline The method is explained. This method involves configuring a first instance of object code for execution on a processor. The processor has a plurality of cores and an internal network. The internal network consists of a first configuration that allows a first number of cores to be communicably linked. The method also includes configuring a second instance of object code for execution on the second instance of the processor. The internal network of the second instance of the processor consists of a second configuration that allows different numbers of cores to be communicatively linked, with the processor and the co-located cores on the second instance of the processor being the first. It has the same network address for each of the configuration and the second configuration. Also described will be a processor with an internal network designed to enable the above method.
以下の説明および添付の図面を用いて、本発明の実施形態を説明する。 Embodiments of the present invention will be described with reference to the following description and accompanying drawings.
詳細な説明
１．０ ユニークな画像処理プロセッサのアーキテクチャ
当技術分野において周知であるように、プログラムコードを実行するための基本的な回路構成は、実行ステージと、レジスタ空間とを含む。実行ステージは、命令を実行するための実行部を含んでいる。実行される命令のための入力オペランドがレジスタ空間から実行ステージに提供される。実行ステージが命令を実行することによって生成される結果は、レジスタ空間に書き戻される。
Detailed Description 1.0 Unique Image Processing Processor Architecture As is well known in the art, the basic circuit configuration for executing program code includes an execution stage and a register space. The execution stage contains an execution unit for executing an instruction. Input operands for the instructions to be executed are provided from the register space to the execution stage. The result produced by the execution stage executing the instruction is written back to the register space.
従来のプロセッサ上でのソフトウェアスレッドの実行には、実行ステージによる、一連の命令の順次実行が伴う。最も一般的には、１つの入力オペランドセットから１つの結果が生成されると言う意味では、演算は、「スカラー」である。しかしながら、「ベクトル」プロセッサの場合、実行ステージによる命令の実行によって、入力オペランドのベクトルから結果のベクトルが生成されることになる。 Execution of a software thread on a conventional processor involves the sequential execution of a series of instructions by the execution stage. Most commonly, an operation is a "scalar" in the sense that one result is produced from one set of input operands. However, in the case of a "vector" processor, the execution of an instruction by the execution stage results in the resulting vector being generated from the vector of the input operands.
図１は、２次元シフトレジスタアレイ１０２に連結された実行レーン（ｅｘｅｃｉｔｉｏｎ ｌａｎｅ）１０１のアレイを含むユニークな画像処理プロセッサのアーキテクチャ１００のハイレベルビューを示す図である。ここで、実行レーンアレイに含まれる各実行レーンは、プロセッサ１００がサポートする命令セットを実行するために必要な実行部を含んだ離散実行ステージとして見ることができる。様々な実施形態では、プロセッサが２次元ＳＩＭＤ（Ｓｉｎｇｌｅ Ｉｎｓｔｒｕｃｔｉｏｎ Ｍｕｌｔｉｐｌｅ Ｄａｔａ）プロセッサとして動作するよう、各実行レーンは、同じマシンサイクルで実行する同じ命令を受け付ける。
FIG. 1 shows a high-level view of
各実行レーンは、２次元シフトレジスタアレイ１０２内の対応する位置に専用のレジスタ空間を有する。たとえば、隅にある実行レーン１０３は、隅にあるシフトレジスタ位置１０４に専用のレジスタ空間を有し、隅にある実行レーン１０５は、隅にあるシフトレジスタ位置１０６に専用のレジスタ空間を有する。
Each execution lane has a dedicated register space at a corresponding position in the two-dimensional
これに加えて、前のマシンサイクル時に別の実行レーンのレジスタ空間にあった値を各実行レーンが自分のレジスタ空間から直接操作できるよう、シフトレジスタアレイ１０２はコンテンツをシフトさせることができる。たとえば、ａ＋１水平シフトによって、各実行レーンのレジスタ空間に、その左端の隣接するレジスタ空間から値を受け付けさせる。水平軸に沿って左右両方向に値をシフトさせ、垂直軸に沿って上下両方向に値をシフトさせることができる機能のおかげで、プロセッサは、画像データのステンシルを効率よく処理することができる。
In addition to this, the
ここで、当技術分野において周知であるように、ステンシルとは、基本的データ単位として利用される画像表面領域のスライスである。たとえば、出力画像の特定の画素位置の新しい値が、この特定の画素位置が中心にある入力画像の領域の画素値の平均として算出されてもよい。たとえば、ステンシルが縦に３画素、横に３画素の大きさを有している場合、特定の画素位置は、３×３画素アレイの中央の画素に対応してもよく、３×３画素アレイ内の９つすべての画素の平均が算出されてもよい。 Here, as is well known in the art, a stencil is a slice of an image surface region used as a basic data unit. For example, a new value for a particular pixel position in the output image may be calculated as the average of the pixel values in the region of the input image centered on this particular pixel position. For example, if the stencil has a size of 3 pixels vertically and 3 pixels horizontally, the particular pixel position may correspond to the central pixel of the 3x3 pixel array. The average of all nine pixels may be calculated.
図１のプロセッサ１００の様々な動作の実施形態によると、実行レーンアレイ１０１の各実行レーンは、出力画像の特定の位置の画素値を算出する役割を果たす。よって、上記３×３ステンシルを平均する例で引き続き説明すると、入力画素データ、およびシフトレジスタ内の８つのシフト演算からなる調整されたシフトシーケンスを初期ロードした後、実行レーンアレイに含まれる各実行レーンは、対応する画素位置についての平均を算出するのに必要な９つすべての画素値をローカルレジスタ空間に受け付けさせる。つまり、プロセッサは、たとえば、隣接する出力画像の画素位置の中心に存在する複数の重なり合うステンシルを同時に処理することができる。図１のプロセッサのアーキテクチャは、特に画像ステンシルの処理に長けているので、ステンシルプロセッサとも称され得る。
According to various operational embodiments of the
図２は、複数のステンシルプロセッサ２０２＿１〜２０２＿Ｎを有する画像処理プロセッサのアーキテクチャ２００の実施形態を示した図である。図２に見られるように、アーキテクチャ２００は、ネットワーク２０４（たとえば、オンチップスイッチネットワーク、オンチップリングネットワークまたはその他の種類のネットワークを含むＮＯＣ（Ｎｅｔｗｏｒｋ Ｏｎ Ｃｈｉｐ））を通して複数のステンシルプロセッサユニット２０２＿１〜２０２＿Ｎおよび対応するシート生成部２０３＿１〜２０３＿Ｎと互いに接続された複数のラインバッファ部２０１＿１〜２０１＿Ｍを含む。実施形態では、いずれのラインバッファ部２０１＿１〜２０１＿Ｍも、ネットワーク２０４を通していずれのシート生成部２０３＿１〜２０３＿Ｎおよび対応するステンシルプロセッサ２０２＿１〜２０２＿Ｎに接続してもよい。
FIG. 2 is a diagram showing an embodiment of
プログラムコードがコンパイルされ、対応するステンシルプロセッサ２０２上にロードされて、ソフトウェア開発者が以前に定義した画像処理演算が実行される（また、プログラムコードは、たとえば、設計および実装に応じて、ステンシルプロセッサの関連するシート生成部２０３にロードされてもよい）。このように、各ステンシルプロセッサ２０２＿１〜２０２＿Ｎは、処理コア、プロセッサコア、コアなどと、より一般的にみなされてもよく、画像処理プロセッサ全体は、マルチコア画像処理プロセッサとみなされてもよい。少なくともいくつかの例では、第１のパイプラインステージ用の第１カーネルプログラムを第１のステンシルプロセッサ２０２＿１にロードし、第２のパイプラインステージ用の第２のカーネルプログラムを第２のステンシルプロセッサ２０２＿２にロードするなどして画像処理パイプラインが実現されてもよく、たとえば、第１カーネルがパイプラインの第１のステージの関数を実行し、第２カーネルがパイプラインの第２のステージの関数を実行し、パイプラインのあるステージからパイプラインの次のステージに出力画像データを渡すためのさらなる制御フロー方法がインストールされる。
The program code is compiled and loaded onto the corresponding
その他の構成では、画像処理プロセッサは、同じカーネルプログラムコードを動作させる２つ以上のステンシルプロセッサ２０２＿１、２０２＿２を有する並列マシンとして実現されてもよい。たとえば、高密度かつ高データ転送速度の画像データストリームを、各々が同じ関数を実行する複数のステンシルプロセッサ間にフレームを分散させることによって処理してもよい。 In other configurations, the image processor may be implemented as a parallel machine with two or more stencil processors 202_1, 202_1 running the same kernel program code. For example, a high density, high data transfer rate image data stream may be processed by distributing frames among multiple stencil processors, each performing the same function.
さらに他の構成では、カーネルの本質的にいずれの有向非巡回グラフ（ＤＡＧ：Ｄｉｒｅｃｔｅｄ Ａｃｙｃｌｉｃ Ｇｒａｐｈ）も、それぞれのステンシルプロセッサを自身のプログラムコードのカーネルで構成し、ＤＡＧ設計において、あるカーネルからの出力画像を次のカーネルの入力に向けるよう適切な制御フローフックをハードウェアに構成することによって、画像処理プロセッサ上にロードされてもよい。 In yet other configurations, essentially any directed acyclic graph (DAG) in the kernel consists of each stencil processor in its own program code kernel, from one kernel in the DAG design. It may be loaded onto the image processing processor by configuring the hardware with appropriate control flow hooks to direct the output image to the input of the next kernel.
一般的なフローとして、画像データのフレームは、マクロ入出力部２０５によって受け付けられ、フレーム単位でラインバッファ部２０１のうちの１つ以上に渡される。特定のラインバッファ部は、画像データのそのフレームを、「ライングループ」と呼ばれる、画像データよりも小さな領域に解析し、その後、当該ライングループを、ネットワーク２０４を通して特定のシート生成部に渡す。完全または「でき上がった」１つのライングループは、たとえば、複数の連続した完全な行または列からなるフレームのデータで構成されてもよい（わかりやすくするために、本明細書では、主に、連続した行を例に用いる）。シート生成部は、さらに、画像データのライングループを、「シート」と呼ばれる、画像データのさらに小さな領域に解析し、このシートを対応するステンシルプロセッサに提示する。
As a general flow, a frame of image data is accepted by the macro input /
１つの入力を有する画像処理パイプラインまたはＤＡＧフローの場合、一般に、入力フレームは、同じラインバッファ部２０１＿１に向けられ、ラインバッファ部２０１＿１は、画像データをライングループに解析し、これらのライングループをシート生成部２０３＿１に向ける。シート生成部２０３＿１の対応するステンシルプロセッサ２０２＿１は、パイプライン／ＤＡＧにおいて第１カーネルのコードを実行している。ステンシルプロセッサ２０２＿１が処理するライングループに対する処理が完了すると、シート生成部２０３＿１は、出力ライングループを「下流」ラインバッファ部２０１＿２に送る（ユースケースによっては、出力ライングループは、入力ライングループを以前に送った同じラインバッファ部２０１＿１に送り返してもよい）。 In the case of an image processing pipeline or DAG flow with one input, the input frames are generally directed to the same line buffer section 201_1, which analyzes the image data into line groups and extracts these line groups. It faces the sheet generation unit 203_1. The corresponding stencil processor 202_1 of the sheet generator 203_1 is executing the code of the first kernel in the pipeline / DAG. When the processing for the line group processed by the stencil processor 202_1 is completed, the sheet generator 203_1 sends the output line group to the “downstream” line buffer unit 201_2 (in some use cases, the output line group previously sends the input line group). It may be sent back to the same line buffer unit 201_1 that was sent).
次に、自身の各々のその他のシート生成部およびステンシルプロセッサ（たとえば、シート生成部２０３＿２およびステンシルプロセッサ２０２＿２）上で実行されるパイプライン／ＤＡＧにおける次のステージ／演算を表す１つ以上の「コンシューマ」カーネルが、第１のステンシルプロセッサ２０２＿１によって生成された画像データを下流ラインバッファ部２０１＿２から受け取る。このように、第１のステンシルプロセッサ上で動作する「プロデューサ」カーネルが、第２のステンシルプロセッサ上で動作する「コンシューマ」カーネルに出力データを転送する。第２のステンシルプロセッサでは、コンシューマカーネルが、パイプラインまたはＤＡＧ全体の設計と整合性のあるプロデューサカーネルの後に次のタスクセットを実行する。 Next, one or more "consumers" representing the next stage / operation in the pipeline / DAG running on their respective other sheet generators and stencil processors (eg, sheet generator 203_2 and stencil processor 202_2). The kernel receives the image data generated by the first stencil processor 202_1 from the downstream line buffer unit 201_2. Thus, the "producer" kernel running on the first stencil processor transfers the output data to the "consumer" kernel running on the second stencil processor. In the second stencil processor, the consumer kernel performs the following task set after the producer kernel, which is consistent with the design of the pipeline or the entire DAG.
図１で上述したように、各ステンシルプロセッサ２０２＿１〜２０２＿Ｎは、画像データの複数の重なり合うステンシルを同時に処理するように設計されている。複数の重なり合うステンシルおよびステンシルプロセッサの内蔵ハードウェア処理能力によって、シートのサイズが効果的に決定される。ここでも、上述したように、任意のステンシルプロセッサ２０２＿１〜２０２＿Ｎ内で、実行レーンのアレイが一斉に動作し、複数の重なり合うステンシルで覆われた画像データ表面領域を同時に処理する。 As described above in FIG. 1, each stencil processor 202_1 to 202_N is designed to simultaneously process multiple overlapping stencils of image data. The built-in hardware processing power of multiple overlapping stencils and stencil processors effectively determines the size of the sheet. Again, as described above, within any stencil processor 202_1 to 202_N, the arrays of execution lanes operate in unison to simultaneously process image data surface areas covered by multiple overlapping stencils.
これに加えて、様々な実施形態では、ステンシルプロセッサ２０２の対応する（たとえば、ローカルの）シート生成部２０３によって、当該ステンシルプロセッサの２次元シフトレジスタアレイに画像データのシートがロードされる。シートおよび２次元シフトレジスタアレイ構造の使用によって、たとえば、実行レーンアレイによってその直後に大量のデータに対して直接実行される処理タスクを用いた１つのロード動作として当該データを大量のレジスタ空間に移動することによって、消費電力の改善が効果的に可能になると考えられている。これに加えて、実行レーンアレイおよび対応するレジスタアレイの使用によって、簡単にプログラム可能／構成可能なそれぞれ異なるステンシルサイズが可能になる。ラインバッファ部、シート生成部、およびステンシルプロセッサの動作について、より詳細を下記のセクション３．０でさらに説明する。
In addition to this, in various embodiments, the corresponding (eg, local) sheet generator 203 of the
図３は、図２の画像処理プロセッサの特定のハードウェア実装の実施形態をより詳細に示した図である。図３に見られるように、図２のネットワーク２０４は、ラインバッファ部３０１とシート生成部／ステンシルプロセッサコア３０２との各交点に４×４ネットワークノード３１４を有するリングトポロジー３０４で実現される。わかりやすくするために、図３は、ラインバッファ部３０１＿４とシート生成部／ステンシルプロセッサコア３０２＿４との間に存在するネットワークノード３１４のみをラベル付けしている。
FIG. 3 is a diagram showing in more detail an embodiment of a specific hardware implementation of the image processor of FIG. 2. As can be seen in FIG. 3, the
ここで、シート生成部／ステンシルプロセッサコア３０２＿１〜３０２＿８の各々がステンシルプロセッサおよび対応するシート生成部の両方を含んでいることが分かる。わかりやすくするために、以下、シート生成部／ステンシルプロセッサコア３０２＿１〜３０２＿８の各々を、単に、ステンシルプロセッサコアまたはコアと称す。８つのラインバッファ部３０１＿１〜３０１＿８および８つのコア３０２＿１〜４０２＿８を図３の特定の実施形態に図示しているが、異なる数のラインバッファ部および／またはコアを有する異なるアーキテクチャが可能であると理解すべきである。リングトポロジー以外のネットワークトポロジーも可能である。 Here, it can be seen that each of the sheet generator / stencil processor cores 302_1 to 302_8 includes both the stencil processor and the corresponding sheet generator. For the sake of clarity, each of the sheet generator / stencil processor cores 302_1 to 302_8 will be simply referred to as a stencil processor core or a core. Eight line buffers 301_1-301_8 and eight cores 302_1 to 402_8 are illustrated in the particular embodiment of FIG. 3, but it is understood that different architectures with different numbers of line buffers and / or cores are possible. Should. Network topologies other than ring topologies are also possible.
図３の画像処理プロセッサに関して、リングネットワーク３０４によって、（１）入出力部３０５が入力データを任意のラインバッファ部３０１＿１〜３０１＿８（または、任意のコア３０２＿１〜３０２＿８）に渡すことができ、（２）任意のラインバッファ部３０１＿１〜３０１＿８が任意のコア３０２＿１〜３０２＿８にライングループを転送することができ、（３）任意のコア３０２＿１〜３０２＿８がその出力データを任意のラインバッファ部３０１＿１〜３０１＿８に渡すことができ、（４）任意のラインバッファ部３０１＿１〜３０１＿８が、画像処理プロセッサの出力データを入出力部３０５に渡すことができる。このように、異なるソフトウェアカーネルをロードする豊富なオプションおよび内部ネットワーク構成が可能である。つまり、理論上は、プロセッサの様々なコア３０２上で実行される複数のカーネルから構成されるソフトウェアアプリケーションのいずれについても、任意のコアに任意のカーネルをロードすることができ、ラインバッファ部のいずれも、任意のコアに入出力データをソース入力し、任意のコアから入出力データをシンク出力するように構成できる。
With respect to the image processing processor of FIG. 3, the
図４は、図３の画像処理プロセッサ上にロードされ得る、例示的なアプリケーションソフトウェアプログラムまたはその一部を示した図である。図４に見られるように、プログラムコードを実行して入力画像データ４０１の１つ以上のフレームを処理し、何らかの全変換をこの入力画像データ４０１に対して実行してもよい。変換は、入力画像データ上でアプリケーションソフトウェア開発者が明示するうまく組み立てられたシーケンスで動作するプログラムコード４０２の１つ以上のカーネルの動作で実現される。
FIG. 4 is a diagram showing an exemplary application software program or a portion thereof that may be loaded onto the image processor of FIG. As can be seen in FIG. 4, the program code may be executed to process one or more frames of the
図４の例では、全変換は、まず、第１カーネルＫ１を用いて各入力画像を処理することによって生じる。次に、カーネルＫ１によって生成された出力画像は、カーネルＫ２によって処理される。次に、カーネルＫ２によって生成された出力画像の各々は、カーネルＫ３＿１またはＫ３＿２によって処理され、次に、カーネル（複数可）Ｋ３＿１／Ｋ３＿２によって生成された出力画像は、カーネルＫ４によって処理される。図３の特定の例では、カーネルＫ３＿１およびＫ３＿２は、たとえば、異なる画像処理演算を行う異なるカーネルであってもよい（たとえば、カーネルＫ３＿１は、第１の特定の種類の入力画像を処理し、カーネルＫ３＿２は、第２の異なる種類の入力画像を処理する）。 In the example of FIG. 4, the full transformation occurs by first processing each input image using the first kernel K1. Next, the output image generated by kernel K1 is processed by kernel K2. Next, each of the output images produced by kernel K2 is processed by kernel K3_1 or K3_2, and then the output images produced by kernel (s) K3_1 / K3_1 are processed by kernel K4. In the particular example of FIG. 3, kernels K3_1 and K3_1 may be, for example, different kernels performing different image processing operations (eg, kernel K3_1 processes a first particular type of input image and the kernel. K3_2 processes a second different type of input image).
わかりやすくするために、４つのカーネルＫ１〜Ｋ４のみを図示している。図３の画像処理プロセッサハードウェアアーキテクチャ実装を参照すると、各カーネルが異なるステンシルプロセッサ上で動作するという基本的な構成において、考えられるところでは、プロセッサのコア３０２のすべてが対応するカーネル（図４の４つのカーネルのフローは、図３のプロセッサのコアのうちの半数しか利用していない）を有する前に、カーネルＫ４からさらに４つのカーネルが生じてもよいことが分かる。
For clarity, only the four kernels K1 to K4 are shown. Referring to the image processing processor hardware architecture implementation of FIG. 3, in the basic configuration where each kernel runs on a different stencil processor, it is possible that all of the
２．０ 設定可能な数のコアを有する画像処理プロセッサ、およびサポートする内部ネットワーク
図５は、リングネットワークの実装形態およびネットワークリング上の各ノードに割り当てられる特定のアドレスをより詳細に示した、図３の画像処理プロセッサ５００の実施形態を示す図である。図５に見られるように、リングネットワークは、マルチプレクサのペア５０６＿１、５０６＿２、および５０６＿３を含み、異なる数のプロセッサのコア５０２＿１〜５０２＿８を使用可能にしている。ここで、画像処理プロセッサ５００は、たとえば、異なるネットワーク構成（たとえば、後述する構成のうちのいずれか／すべて）のうちの特定の１つのネットワーク構成を実施または実現するようにマルチプレクサのチャネル選択値を判断する構成レジスタ空間（図５において図示せず）を含んでもよい。図５に見られるように、マルチプレクサのペアのＡチャネルが選択された場合、リングは、引き続き前進して次のプロセッサコアのペアにつながる。対照的に、マルチプレクサのペアのＢチャネルが選択された場合、リングは、次のプロセッサコアのペアを遮断するよう、「短絡する」。
2.0 Image processor with a configurable number of cores, and supported internal networks Figure 5 shows in more detail the implementation of the ring network and the specific addresses assigned to each node on the network ring. It is a figure which shows the embodiment of the
図６ａ〜図６ｄは、図５の画像処理プロセッサを用いて実現可能な異なるリングネットワークおよび異なる数のアクティブなプロセッサコア構成を示す図である。 6a-6d show different ring networks and different numbers of active processor core configurations feasible with the image processor of FIG.
図６ａは、マルチプレクサのペア５０６＿１のＢチャネルが選択された構成に対応し、この選択によって、ノード１（処理コア５０２＿１のリング上の位置に対応する）とノード２（処理コア５０２＿２のリング上の位置に対応する）との間で直接の論理接続が効果的に形成される。図５および図６ａに見られるように、マルチプレクサのペア５０６＿１のＢチャネルを選択することによって、処理コア５０２＿３、５０２＿５、５０２＿７、５０２＿８、５０２＿６、および５０２＿４がリングネットワークから効果的に遮断される。このように、リングネットワークは、入出力部５０５と、処理コア５０２＿１および５０２＿２とだけを連結する。この特定の構成は、たとえば、画像処理プロセッサ５００上で実行するアプリケーションソフトウェアプログラムが１つまたは２つのカーネルしか含まない場合に選択されてもよい。この場合、２つ以下の処理コアが有効化される（コア５０２＿１およびコア５０２＿２）。その他のコア５０２＿３、５０２＿５、５０２＿７、５０２＿８、５０２＿６、および５０２＿４を、たとえば、非アクティブな低電力状態にして、画像処理プロセッサの全体の消費電力を下げてもよい。
FIG. 6a corresponds to a configuration in which the B channel of the multiplexer pair 506_1 is selected, and by this selection node 1 (corresponding to a position on the ring of processing core 502_1) and node 2 (on the ring of processing core 502_1). A direct logical connection is effectively formed with (corresponding to the position). As seen in FIGS. 5 and 6a, selecting the B channel of the multiplexer pair 506_1 effectively blocks the processing cores 502_3, 502_5, 502_7, 502_8, 502_6, and 502_4 from the ring network. In this way, the ring network connects only the input /
図６ｂは、マルチプレクサのペア５０６＿１のＡチャネルが選択され、かつ、マルチプレクサのペア５０６＿２のＢチャネルが選択された構成に対応する。この特定のマルチプレクサ構成によって、コア５０２＿１と５０２＿２とを連結するだけでなく、コア５０２＿３と５０２＿４とも連結するよう、リングが図６ａの構成よりも広がる。ここで、ノード３（処理コア５０２＿３のリング上の位置に対応する）とノード４（処理コア５０２＿４のリング上の位置に対応する）との間に直接の論理接続が形成される。図５および図６ｂに見られるように、マルチプレクサのペア５０６＿１のＡチャネルおよびマルチプレクサのペア５０６＿２のＢチャネルの選択によって、処理コア５０２＿５、５０２＿７、５０２＿８、および５０２＿６がリングネットワークから効果的に遮断される。このように、リングネットワークは、入出力部５０５と、処理コア５０２＿１、５０２＿２、５０２＿３、および５０２＿４とだけを連結する。
FIG. 6b corresponds to a configuration in which the A channel of the multiplexer pair 506_1 is selected and the B channel of the multiplexer pair 506_1 is selected. With this particular multiplexer configuration, the ring is wider than the configuration of FIG. 6a so that not only the cores 502_1 and 502_2 are connected, but also the cores 502_3 and 502_4. Here, a direct logical connection is formed between the node 3 (corresponding to the position on the ring of the processing core 502_3) and the node 4 (corresponding to the position on the ring of the processing core 502_4). As seen in FIGS. 5 and 6b, the selection of the A channel of the multiplexer pair 506_1 and the B channel of the multiplexer pair 506_2 effectively blocks the processing cores 502_5, 502_7, 502_8, and 502_6 from the ring network. .. In this way, the ring network connects only the input /
この特定の構成は、たとえば、画像処理プロセッサ５００上で実行するアプリケーションソフトウェアプログラムが３つまたは４つのカーネルしか含まない場合に選択されてもよい。この場合、４つ以下の処理コアが有効化される（コア５０２＿１、５０２＿２、５０２＿３、および５０２＿４）。その他のコア５０２＿５、５０２＿７、５０２＿８、および５０２＿６を、たとえば、非アクティブな低電力状態にして、画像処理プロセッサの全体の消費電力を下げてもよい。
This particular configuration may be selected, for example, if the application software program running on the
図６ｃは、マルチプレクサのペア５０６＿１および５０６＿２のＡチャネルが選択され、かつ、マルチプレクサのペア５０６＿３のＢチャネルが選択された構成に対応する。この特定のマルチプレクサ構成によって、コア５０２＿１と、５０２＿２と、５０２＿３と、５０２＿４とを連結するだけでなく、コア５０２＿５と５０２＿６とを連結するよう、リングが図６ｂの構成よりも広がる。ここで、ノード５（処理コア５０２＿５のリング上の位置に対応する）とノード６（処理コア５０２＿６のリング上の位置に対応する）との間に直接の論理接続が形成される。図５および図６ｃに見られるように、マルチプレクサのペア５０６＿１および５０６＿２のＡチャネルならびにマルチプレクサのペア５０６＿３のＢチャネルの選択によって、処理コア５０２＿７および５０２＿８がリングネットワークから効果的に遮断される。このように、リングネットワークは、入出力部５０５と、処理コア５０２＿１、５０２＿２、５０２＿３、５０２＿４、５０２＿５、および５０２＿６とを連結する。
FIG. 6c corresponds to a configuration in which the A channel of the multiplexer pair 506_1 and 506_2 is selected and the B channel of the multiplexer pair 506_3 is selected. With this particular multiplexer configuration, the ring extends beyond the configuration of FIG. 6b to connect cores 502_1, 502_2, 502_3, and 502_4, as well as cores 502_5 and 502_6. Here, a direct logical connection is formed between the node 5 (corresponding to the position on the ring of the processing core 502_5) and the node 6 (corresponding to the position on the ring of the processing core 502_6). As seen in FIGS. 5 and 6c, the selection of the A channel of the multiplexer pairs 506_1 and 506_2 and the B channel of the multiplexer pair 506_3 effectively blocks the processing cores 502_7 and 502_8 from the ring network. In this way, the ring network connects the input /
この特定の構成は、たとえば、画像処理プロセッサ５００上で実行するアプリケーションソフトウェアプログラムが５つまたは６つのカーネルのみを含む場合に選択されてもよい。この場合、６つ以下の処理コアが有効化される（コア５０２＿１、５０２＿２、５０２＿３、５０２＿４、５０２＿５、および５０２＿６）。その他のコア５０２＿７および５０２＿８を、たとえば、非アクティブな低電力状態にして、画像処理プロセッサの全体の消費電力を下げてもよい。
This particular configuration may be selected, for example, if the application software program running on the
図６ｄは、マルチプレクサのペア５０６＿１、５０６＿２、および５０６＿３のＡチャネルが選択された構成に対応する。この特定のマルチプレクサ構成によって、入出力部５０５とコア５０２＿１、５０２＿２、５０２＿３、５０２＿４、５０２＿５、５０２＿６、５０２＿７、および５０２＿８のすべてとを連結するよう、リングが図６ｂの構成よりも広がる。ここで、ノード７（処理コア５０２＿７のリング上の位置に対応する）とノード８（処理コア５０２＿８のリング上の位置に対応する）との間の結線接続によって、リングの右端が形成される。この特定の構成は、たとえば、画像処理プロセッサ５００上で実行するアプリケーションソフトウェアプログラムが７つまたは８つのカーネルを含む場合に選択されてもよい。
FIG. 6d corresponds to a configuration in which the A channels of the multiplexer pairs 506_1, 506_2, and 506_3 are selected. With this particular multiplexer configuration, the ring extends beyond the configuration of FIG. 6b to connect the input /
図５のプロセッサのネットワークリング設計の別の関連する特徴として、異なるネットワークノードに対するアドレス値の割り当ての一意の取り決めがある。ここで、図３を再び少し参照すると、図３のプロセッサ３００は、例によってリングを囲むようにノードに一続きの番号を付けていることが分かる。しかしながら、図５のリングネットワーク上のネットワークアドレスの割り当ては、図３の従来手法とは異なり、いずれのアクティブなネットワーク構成上の数値アドレスも、リング上で有効になるように設定されるコアの数に関係なく、途切れず連続したままである。
Another related feature of the processor network ring design of FIG. 5 is a unique arrangement of address value assignments to different network nodes. Now, with a little reference to FIG. 3, it can be seen that the
つまり、図６ａの構成が選択された場合、リング上のアクティブな数値アドレスは、アドレス０、１、および２を含む。対照的に、図６ｂの構成が選択された場合、リング上のアクティブな数値アドレスは、アドレス０、１、２、３、および４を含む。さらに、図６ｃの構成が選択された場合、リング上のアクティブな数値アドレスは、アドレス０、１、２、３、４、５、および６を含む。最後に、図６ｄの構成が選択された場合、リング上のアクティブな数値アドレスは、アドレス０、１、２、３、４、５、６、７、および８を含む。
That is, when the configuration of FIG. 6a is selected, the active numeric addresses on the ring include
このようにネットワークアドレスを取り決めることは、アプリケーションソフトウェアソースコードを複数の異なる最下位のオブジェクトコード（バイナリコードとも称する）のインスタンスに再コンパイルすることを、たとえ設定された異なる数のアクティブなプロセッサコアおよび対応して異なる基礎となるリングネットワーク構成を有する異なるソフトウェアアプリケーション間でこのような最下位のコードが再利用されている場合でも、回避するのに役立ち得る。ここで、様々な環境において、たとえば、実際のハードウェアプロセッサ内の任意のコアに理論上マッピングできる論理アドレスを用いて、通信の宛先であるカーネルをアプリケーションソフトウェアプログラムのソースコードレベルで識別する。しかしながら、ソースコードが下位のオブジェクトまたはバイナリコードにコンパイルされた場合、論理アドレスは、プロセッサ上の特定のハードウェアコアのＩＤに変換される（すなわち、リングネットワーク上の特定のアドレスのうちの１つ）。 Arranging network addresses in this way recompiles the application software source code into instances of multiple different bottom-level object codes (also known as binary code), even if it is configured with a different number of active processor cores and Even if such bottom-level code is reused between different software applications that have correspondingly different underlying ring network configurations, it can help to avoid it. Here, in various environments, for example, a kernel that is a communication destination is identified at the source code level of an application software program by using a logical address that can theoretically be mapped to any core in an actual hardware processor. However, when the source code is compiled into subordinate objects or binary code, the logical address is translated into the ID of a particular hardware core on the processor (ie, one of a particular address on the ring network). ).
たとえば、入出力部が入力データをカーネルＫ１に送り、カーネルＫ１がその出力データをカーネルＫ２に送る、２つのカーネルＫ１およびＫ２を使用するアプリケーションソフトウェアプログラムを考える。ソースコードを下位のオブジェクトコードにコンパイルした後、カーネルＫ１がとりわけコア５０２＿１上で実行するように割り当てられ、カーネルＫ２がとりわけコア５０２＿２上で実行するように割り当てられると想定する。このように、いずれのオブジェクトコードの通信も、カーネルＫ１に送られる通信用の１というネットワークアドレスを含み、カーネルＫ２に送られる通信用の２というネットワークアドレス含むことになる。
For example, consider an application software program that uses two kernels K1 and K2, where the input / output unit sends input data to kernel K1 and kernel K1 sends its output data to kernel K2. After compiling the source code into lower object code, it is assumed that kernel K1 is specifically assigned to run on core 502_1 and kernel K2 is specifically assigned to run on core 502_1. As described above, the communication of any object code includes the
リング周りのネットワークノードアドレス割り当てのユニークな取り決めによって、最下位のプログラムコードのこの特定のインスタンスは、図６ａの２つのコアプロセッサ構成上で動作可能なだけでなく、図６ｂ、図６ｃ、および図６ｄのその他のプロセッサコア構成の各々でも動作可能である。このように、カーネルＫ１およびＫ２を含むアプリケーションソフトウェアプログラムのソースコードがそれぞれ異なるオブジェクトコードインスタンスに再コンパイルされる必要がないので、アプリケーションソフトウェアプログラムは、画像処理プロセッサ構成６ａ、６ｂ、６ｄ、６ｅのうちの異なる構成上で実行することを目的とされる。再コンパイルする必要がなくなるので、アプリケーションソフトウェア開発および／または構築の効率向上が可能になる。 Due to the unique arrangement of network node addressing around the ring, this particular instance of the lowest-level program code can operate on the two core processor configurations of Figure 6a, as well as Figure 6b, Figure 6c, and Figure. It can also operate with each of the other processor core configurations of 6d. Thus, since the source code of the application software program including kernels K1 and K2 does not need to be recompiled into different object code instances, the application software program is included in the image processing processor configurations 6a, 6b, 6d, 6e. Intended to run on different configurations. Since there is no need to recompile, it is possible to improve the efficiency of application software development and / or construction.
つまり、オブジェクトコードレベルでのプログラムコードの再利用をさらに容易に実現し、および／または、オブジェクトコードのインスタンスをより大きなオブジェクトコードアプリケーションにプラグ可能なコンポーネントとして使用してアプリケーションソフトウェアの構築をオブジェクトコードレベルで達成することができる。前述のカーネルＫ１およびＫ２を有するアプリケーションソフトウェアプログラムが処理ＯＰ１を実行する例を考える。ＯＰ１は、スタンドアロンプログラムとしてだけでなく、たとえば、自身の一意の処理タスクを有するその他のいくつかの処理の前に実行されるフロントエンドの処理として有意に使用される。わかりやすくするために、次のその他３つの処理が存在すると想定する。（１）２つのカーネルを用いて実施されるＯＰ２（たとえば、Ｋ３およびＫ４）、（２）３つのカーネル（たとえば、Ｋ３、Ｋ４、およびＫ５）を用いて実施されるＯＰ３、および（３）５つのカーネル（たとえば、Ｋ３、Ｋ４、Ｋ５、Ｋ６、およびＫ７）を用いて実施されるＯＰ４。 That is, it makes it easier to reuse program code at the object code level, and / or uses object code instances as pluggable components into larger object code applications to build application software at the object code level. Can be achieved with. Consider an example in which the application software program having the kernels K1 and K2 described above executes the process OP1. OP1 is significantly used not only as a stand-alone program, but also, for example, as a front-end process that is executed before some other process that has its own unique processing task. For the sake of clarity, it is assumed that the following three other processes exist. (1) OP2 implemented with two kernels (eg, K3 and K4), (2) OP3 implemented with three kernels (eg, K3, K4, and K5), and (3) 5. OP4 implemented with one kernel (eg, K3, K4, K5, K6, and K7).
ここで、フロントエンドの処理ＯＰ１がオブジェクトコードインスタンスにコンパイルされ、カーネルＫ２がその出力データを（たとえば、ネットワークノード０の入出力部５０５ではなく）ネットワークノード３のコア５０２＿３に送るアプリケーションソフトウェア開発環境を考える。これに加えて、後続の処理ＯＰ２、ＯＰ３、およびＯＰ４が、以下のようにオブジェクトコードインスタンスにコンパイルされると想定する。（１）ＯＰ２、ＯＰ３、およびＯＰ４の第１（入力、Ｋ３）カーネルおよび第２（Ｋ４）カーネルがコア５０２＿３および５０２＿４上でそれぞれ動作し、（２）ＯＰ３およびＯＰ４の第３（Ｋ５）カーネルがコア５０２＿５上で動作し、（３）ＯＰ４の第４（Ｋ６）カーネルおよび第５（Ｋ７）カーネルがコア５０２＿６および５０２＿７上でそれぞれ動作する。
Here, the front-end processing OP1 is compiled into an object code instance, and the kernel K2 sends the output data to the core 502_3 of the network node 3 (for example, not the input /
この場合、コンパイルされたフロントエンドのＯＰ１インスタンスは、コンパイルされたＯＰ２、ＯＰ３、およびＯＰ３のオブジェクトコードインスタンスのそれぞれのうちのいずれかとそのままオブジェクトコードレベルで組み合わされ得、次の３つの別個のすぐに実行可能なアプリケーションソフトウェアプログラムが作成される。（１）ＯＰ１＋ＯＰ２に対応する第１のアプリケーションソフトウェアプログラム、（２）ＯＰ１＋ＯＰ３に対応する第２のアプリケーションソフトウェアプログラム、および（３）ＯＰ１＋ＯＰ４に対応する第３のアプリケーションソフトウェアプログラム。 In this case, the compiled front-end OP1 instance can be combined as-is at the object code level with any one of the compiled OP2, OP3, and OP3 object code instances, and the following three separate immediate An executable application software program is created. (1) a first application software program corresponding to OP1 + OP2, (2) a second application software program corresponding to OP1 + OP3, and (3) a third application software program corresponding to OP1 + OP4.
ここで、ＯＰ１のオブジェクトコードインスタンスをＯＰ２、ＯＰ３、およびＯＰ４オブジェクトコードインスタンスの各々と別個に組み合わせて３つの異なるオブジェクトコードレベルのアプリケーションを作成することができるだけでなく、４つのコアを用いる第１のアプリケーションソフトウェアプログラム（ＯＰ１＋ＯＰ２）を図６ｂのプロセッサ構成で動作するように構成でき、５つのコアを用いる第２のアプリケーションソフトウェアプログラム（ＯＰ１＋ＯＰ３）を図６ｃのプロセッサ構成で動作するように構成でき、７つのコアを用いる第３のアプリケーションソフトウェアプログラム（ＯＰ１＋ＯＰ４）を図６ｄのプロセッサ構成で動作するように構成できることが分かる。 Here, not only can the object code instance of OP1 be combined separately with each of the OP2, OP3, and OP4 object code instances to create three different object code level applications, but the first with four cores. The application software program (OP1 + OP2) can be configured to operate in the processor configuration of FIG. 6b, and the second application software program (OP1 + OP3) using five cores can be configured to operate in the processor configuration of FIG. 6c, seven. It can be seen that a third application software program (OP1 + OP4) using the core can be configured to operate with the processor configuration of FIG. 6d.
よって、ＯＰ１のオブジェクトコードインスタンスを他のオブジェクトコードインスタンスと組み合わせてより大きな作業オブジェクトコードレベルのアプリケーションを作成できるだけでなく、異なるアプリケーションをもたらす組合せが、異なる数のアクティブなハードウェアコアおよび対応して異なる内部リングネットワーク構成を有する異なるプロセッサ構成を必要とすることになったとしても、ＯＰ１のオブジェクトコードインスタンスをこのように組み合わせることができる。つまり、異なるプロセッサ構成間でプロセッサ内の内部ネットワークが異なっていても、対象ハードウェアプロセッサに含まれるアクティブなコアの構成／数とは無関係なオブジェクトコードレベルでプログラムコード構築を達成することができる。 Thus, not only can OP1 object code instances be combined with other object code instances to create larger working object code level applications, but the combinations that result in different applications are different with different numbers of active hardware cores and correspondingly different. The object code instances of OP1 can be combined in this way, even if different processor configurations with internal ring network configurations are required. That is, even if the internal network in the processor is different between different processor configurations, the program code construction can be achieved at the object code level regardless of the configuration / number of active cores included in the target hardware processor.
さらには、抽象的なカーネル識別子をオブジェクトコードレベルで使用することで、任意のオブジェクトコードプログラムをより大きなオブジェクトコードレベル構築に容易にプラグインでき、かつ、異なるプロセッサコア上で実行するように構成することができる。たとえば、以下のように想定する。コンパイルされた上述のＯＰ３のオブジェクトコードインスタンスが（１）その第１カーネル（上述したＫ３）を入力変数＝ＢＡＳＥを用いて識別し、（２）その第２カーネル（上述したＫ４）を識別子＝ＢＡＳＥ＋１を用いて識別し、（３）その第３カーネル（上述したＫ５）を識別子＝ＢＡＳＥ＋２を用いて識別する。この場合、上述した第２（ＯＰ１＋ＯＰ３）アプリケーションと合わせて利用するためのＯＰ３のオブジェクトコードの構成は、ＢＡＳＥ＝３と設定することによって簡単明瞭になる。
Furthermore, by using abstract kernel identifiers at the object code level, any object code program can be easily plugged into larger object code level construction and configured to run on different processor cores. be able to. For example, assume the following. The compiled object code instance of OP3 described above (1) identifies its first kernel (K3 described above) using the input variable = BASE, and (2) identifies its second kernel (K4 described above) as an identifier =
また、単に、ＢＡＳＥ＝１と設定することによって、ＯＰ３オブジェクトコードの同一インスタンスをスタンドアロン動作に容易に再利用することができる。その後、ＯＰ３の第１カーネルをコア５０２＿１上で実行させ、その第２コアを正しいカーネルを用いてコア５０２＿２上で動作させて、ネットワークリング上でカーネルを通信する。よって、入力変数／構成情報（ＢＡＳＥ）の単純な変更によって、（上述した第２アプリケーション（ＯＰ１＋ＯＰ３）用に）オブジェクトコードレベルのＯＰ３の同一インスタンスを図６ｃのプロセッサ構成で容易に動作させる、または、図６ａのプロセッサ構成でスタンドアロンアプリケーションとして動作させることができる。 Further, by simply setting BASE = 1, the same instance of the OP3 object code can be easily reused for stand-alone operation. The first kernel of OP3 is then run on core 502_1, the second core is run on core 502_1 with the correct kernel, and the kernels are communicated over the network ring. Thus, a simple change in input variable / configuration information (BASE) can easily make the same instance of OP3 at the object code level (for the second application (OP1 + OP3) described above) work with the processor configuration of FIG. 6c, or It can be operated as a stand-alone application with the processor configuration of FIG. 6a.
このように、オブジェクトレベルプログラム内のそれぞれ異なるカーネルをそれらのネットワークアドレスのオフセットで識別することで、オブジェクトレベルプログラムの同一インスタンスをそれぞれ異なるプロセッサ構成に容易にマッピングすることができる。なぜならば、プロセッサ構成が異なるとリング上のノード数も変化するが、プロセッサのネットワークリング上の一意のアドレス指定パターンがこれらのオフセットの意味を本質的に保存するからである。このように、多くの状況において、たとえば、各プログラムの関数を新しく使用する度に、または、異なる基礎となるプロセッサ構成ごとに同じソースコードレベルからオブジェクトコードの新しいインスタンスをコンパイルするのではなく、プログラムのオブジェクトコードインスタンスが作成されると、その同一コピーは、多くの異なるアプリケーションおよび対応する構成のために「プラグイン」として再利用することができる。 Thus, by identifying different kernels in an object-level program by their network address offsets, the same instance of the object-level program can be easily mapped to different processor configurations. This is because different processor configurations also change the number of nodes on the ring, but the unique addressing pattern on the processor's network ring essentially preserves the meaning of these offsets. Thus, in many situations, for example, instead of compiling a new instance of object code from the same source code level each time a new function in each program is used, or for different underlying processor configurations, the program Once an object code instance of is created, the same copy can be reused as a "plug-in" for many different applications and corresponding configurations.
また、オブジェクトコードインスタンスをより大きなオブジェクトコード構築にプラグインするための機能は、入力ストリームの送信元アドレスおよび／または出力ストリームの宛先アドレスがそれぞれの入力変数としてオブジェクトコードレベルで指定される場合、向上する。たとえば、ここでもＯＰ３を例として用いると、上述した第２（ＯＰ１＋ＯＰ３）アプリケーションにＯＰ３を利用し、ＢＡＳＥ＝３である場合、ＯＰ３のための入力データの送信元を識別するさらなる入力変数ＩＮをＩＮ＝２と設定してもよい（コア５０２＿２上で実行されるＯＰ１のＫ２は、ＯＰ１＋ＯＰ３アプリケーション用のその入力データをＯＰ３に送る）。ＯＰ３がその出力情報を送信する先を識別する宛先を別の変数ＯＵＴを用いて指定してもよく、ＯＵＴ＝０と設定される（その出力データをＯＰ１＋ＯＰ３アプリケーションで使用する場合、ＯＰ３は、入出力部５０５に送る）。上述したように、これらの設定では、ＯＰ３のオブジェクトコードインスタンスは、図６ｃの構成に設定されたプロセッサを有するＯＰ１＋ＯＰ２アプリケーション内で動作することができる。 Also, the ability to plug an object code instance into a larger object code construction is improved if the source address of the input stream and / or the destination address of the output stream is specified at the object code level as their respective input variables. do. For example, if OP3 is also used as an example here, OP3 is used for the above-mentioned second (OP1 + OP3) application, and when BASE = 3, an additional input variable IN that identifies the source of the input data for OP3 is IN. You may set = 2 (K2 of OP1 running on core 502_2 sends its input data for OP1 + OP3 application to OP3). The destination that identifies the destination to which OP3 sends the output information may be specified using another variable OUT, and OUT = 0 is set (when the output data is used in the OP1 + OP3 application, OP3 is input. (Send to output unit 505). As mentioned above, with these settings, the object code instance of OP3 can operate within the OP1 + OP2 application with the processor set in the configuration of FIG. 6c.
ＯＰ３オブジェクトコードの同じインスタンスのコピーをスタンドアロン動作に再利用するためには、入力構成情報は、ＩＮ＝ＯＵＴ＝０およびＢＡＳＥ＝１）と設定するだけでよい。この構成では、ＯＰ３がその入力データを入出力部５０５から受け付け、その出力データを入出力部５０５に送ることになる。また、この構成では、ＯＰ３インスタンスは、図６ａのプロセッサ構成で動作することができる。このように、ＯＰ３コードの同一インスタンスは、異なる内部ネットワークリング構成を含む基礎となるプロセッサ構成とは本質的に無関係である。
In order to reuse a copy of the same instance of the OP3 object code for stand-alone operation, the input configuration information need only be set to IN = OUT = 0 and BASE = 1). In this configuration, OP3 receives the input data from the input /
よって、アプリケーションソフトウェア開発環境全体は、利用／再利用されることの多い基本の処理関数を実行するように書かれたより細い粒度のアプリケーションソフトウェアプログラムのソースコードレベルでの開発を含み得る。より細い粒度のソースコードアプリケーションは、それぞれのオブジェクトコードインスタンスにコンパイルされる。次に、オブジェクトコードインスタンスは、必要であればコピーされ、他のオブジェクトコードインスタンスのコピーと組み合わされてより大きく、かつ、より包括的かつ実行可能なオブジェクトコードレベルのアプリケーションを形成する。 Thus, the entire application software development environment may include the development of finer-grained application software programs written to perform basic processing functions that are often used / reused at the source code level. Finer-grained source code applications are compiled into their respective object code instances. Object code instances are then copied, if necessary, and combined with copies of other object code instances to form larger, more comprehensive, and executable object code level applications.
それぞれ異なるハードウェアプラットフォームが異なる数のコアを有して存在する場合、さらなる効率化を実現できる。ここで、図６ａ〜図６ｄに関連した上記説明は、８コアープラットフォームが２つ、４つ、６つ、または８つのアクティブなコアを有して構成され得る、８つのコアを有する１つのハードウェアプラットフォームを対象としていた。ここでも、たとえば、２つのカーネルのオブジェクトコードレベルプログラム（たとえば、ＯＰ１）は、ＯＰ１プログラムの新しいオブジェクトコードインスタンスを再コンパイルしなくても、これらの構成のうちのいずれの構成上でも動作し得ることを示した。 Further efficiency can be achieved if different hardware platforms exist with different numbers of cores. Here, the above description related to FIGS. 6a-6d is one hardware with eight cores, the eight core platform may be configured with two, four, six, or eight active cores. It was targeted at the hardware platform. Again, for example, two kernel object code level programs (eg OP1) can work on any of these configurations without having to recompile a new object code instance of the OP1 program. showed that.
この汎用性は、さらには、たとえば、次から構成されるプロダクトラインにも及び得る。（１）２つのアクティブなコアからなる１つの構成をサポートする、２つのコアのみから構成される第１のハードウェアプラットフォーム、（２）２つのアクティブなコアからなる第１構成と４つのアクティブなコアからなる第２構成とをサポートする、４つのコアから構成される第２のハードウェアプラットフォーム、（３）２つのコアをサポートする第１構成と、４つのコアをサポートする第２構成と、６つのコアをサポートする第３構成とをサポートする、６つのコアから構成される第３のハードウェアプラットフォーム、および（４）図６ａ〜図６ｄで上述した４つの異なる構成をサポートする、８つのコアから構成される第４のハードウェアプラットフォーム。 This versatility can even extend to, for example, a product line consisting of: (1) a first hardware platform consisting of only two cores, supporting one configuration consisting of two active cores, (2) a first configuration consisting of two active cores and four active cores. A second hardware platform consisting of four cores that supports a second configuration consisting of cores, (3) a first configuration that supports two cores, and a second configuration that supports four cores. A third hardware platform consisting of six cores, supporting a third configuration that supports six cores, and (4) eight different configurations described above in FIGS. 6a-6d. A fourth hardware platform consisting of cores.
２つのカーネルを用いるオブジェクトコードレベルプログラムＯＰ１は、上記（４）のハードウェアプラットフォームの４つの構成の各々の上で動作可能であると詳細に上述した。しかしながら、上記（１）、（２）、および（３）のハードウェアプラットフォームがネットワークノードを本明細書に記載のように列挙するように設計されている場合、上記（４）のハードウェアプラットフォームの４つの構成すべての上で動作可能なオブジェクトコードレベルプログラムＯＰ１は、次のいずれの構成上でも動作可能になる。（ｉ）上記（３）のハードウェアプラットフォームの３つの異なる構成、（ｉｉ）上記（２）のハードウェアプラットフォームの２つの異なる構成、および（ｉｉｉ）上記（１）のハードウェアプラットフォーム。このように、コードの再利用機能は、同じハードウェアプラットフォームのそれぞれ異なる構成だけでなく、それぞれ異なるハードウェアプラットフォームのそれぞれ異なる構成にも及ぶ。上述したように、コードは、スタンドアロンであり得、他のオブジェクトコードレベルプログラムと組み合わされていることもあり得る。 It has been described in detail above that the object code level program OP1 using two kernels can operate on each of the four configurations of the hardware platform of (4) above. However, if the hardware platforms of (1), (2), and (3) above are designed to enumerate network nodes as described herein, then of the hardware platform of (4) above. The object code level program OP1 that can operate on all four configurations can operate on any of the following configurations. (I) Three different configurations of the hardware platform of (3) above, (ii) two different configurations of the hardware platform of (2) above, and (iii) the hardware platform of (1) above. Thus, code reuse capabilities extend not only to different configurations of the same hardware platform, but also to different configurations of different hardware platforms. As mentioned above, the code can be stand-alone and can be combined with other object code-level programs.
図７は、上述した方法を示す図である。図７に見られるように、この方法は、プロセッサ上で実行するためのオブジェクトコードの第１インスタンスを構成するステップを含み、プロセッサは、複数のコアと、内部ネットワークとを有し、内部ネットワークは、第１の数のコアを通信可能に連結することを可能にする第１構成で構成されている（７０１）。また、方法は、プロセッサの第２インスタンス上で実行するためのオブジェクトコードの第２インスタンスを構成するステップも含み、プロセッサの第２インスタンスの個々の内部ネットワークは、異なる数のコアを通信可能に連結することを可能にする第２構成で構成され、プロセッサおよびプロセッサの第２インスタンス上で同じ位置にあるコアは、第１構成および第２構成のそれぞれに対して同じネットワークアドレスを有する（７０２）。 FIG. 7 is a diagram showing the above-mentioned method. As can be seen in FIG. 7, this method comprises the steps of forming a first instance of object code for execution on a processor, where the processor has multiple cores and an internal network, where the internal network is , A first configuration that allows a first number of cores to be communicably linked (701). The method also includes the steps of configuring a second instance of object code to run on the second instance of the processor, where the individual internal networks of the second instance of the processor are communicably linked to different numbers of cores. A second configuration that allows the processor and cores co-located on the second instance of the processor have the same network address for each of the first and second configurations (702).
上述した発想は図５の特定のプロセッサに限定されないことを認識することが適切である。ここで、たとえば、異なる数の処理コア、さらには、異なる種類の内部ネットワークトポロジーを有する他のプロセッサが本明細書に記載の教示を利用してもよい。つまり、他のネットワークトポロジー（たとえば、交換接続ネットワーク）が異なる内部ネットワーク構成間で送信元ノード／宛先ノードの物理アドレスを保持するように設計されてもよく、および／または当該異なる内部ネットワーク構成間で物理アドレスを途切れず連続したままにしてもよい。 It is appropriate to recognize that the ideas described above are not limited to the particular processor of FIG. Here, for example, different numbers of processing cores, as well as other processors with different types of internal network topologies, may utilize the teachings described herein. That is, other network topologies (eg, switched network) may be designed to hold the physical address of the source node / destination node between different internal network configurations and / or between the different internal network configurations. The physical address may remain continuous without interruption.
３．０ 画像処理プロセッサ実装の実施形態
図８ａ〜図８ｅ〜図１２は、上述した画像処理プロセッサおよび関連するステンシルプロセッサの様々な実施形態のより詳細な動作および設計を提供する図である。ライングループをステンシルプロセッサの関連するシート生成部にラインバッファ部が送るという図２の説明を思い返すと、図８ａ〜図８ｅは、ラインバッファ部２０１の解析アクティビティ、シート生成部２０３の細粒度の解析アクティビティ、およびシート生成部２０３に連結されるステンシルプロセッサ７０２のステンシル処理アクティビティの実施形態をハイレベルで示す図である。
3.0 Embodiments of an image processor implementation FIGS. 8a-8e-12 are diagrams that provide more detailed operation and design of various embodiments of the image processor and related stencil processors described above. Recalling the explanation of FIG. 2 that the line buffer unit sends the line group to the related sheet generation unit of the stencil processor, FIGS. 8a to 8e show the analysis activity of the
図８ａは、画像データ８０１の入力フレームの実施形態を示した図である。また、図８ａは、ステンシルプロセッサが処理するように設計された、３つの重なり合うステンシル８０２（各々の寸法は、３画素×３画素である）の輪郭も示している。各ステンシルが出力画像データを生成する出力画素を、黒い実線で強調表示している。わかりやすくするために、３つの重なり合うステンシル８０２は、垂直方向にのみ重なり合うよう示されている。ステンシルプロセッサは、実際には、垂直方向および水平方向の両方に重なり合うステンシルを有するように設計されてもよいことを認識することが適切である。
FIG. 8a is a diagram showing an embodiment of an input frame of image data 801. FIG. 8a also shows the contours of three overlapping stencils 802 (each dimension is 3 pixels x 3 pixels) designed to be processed by the stencil processor. The output pixels for which each stencil produces output image data are highlighted with a solid black line. For clarity, the three overlapping
ステンシルプロセッサ内でステンシル８０２が縦に重なり合っているために、図８ａに見られるように、フレーム内に１つのステンシルプロセッサが処理できる幅広い帯状の画像データが存在する。より詳細は以下に説明するが、実施形態では、ステンシルプロセッサは、重なり合うステンシル内のデータを、画像データの端から端まで左から右へ処理する（次に、上から下の順に、次のラインセットに対して繰り返す）。よって、ステンシルプロセッサがこの動作で前進を続けると黒い実線の出力画素ブロックの数が水平右方向に増える。上述したように、ラインバッファ部２０１は、ステンシルプロセッサが今後の多くの周期数にわたって処理するのに十分な受信フレームからの入力画像データのライングループを、解析する役割を果たす。ライングループの例を、影付き領域８０３として示している。実施形態では、ラインバッファ部２０１は、シート生成部にライングループを送信／シート生成部からライングループを受信するためのそれぞれ異なる力学を理解できる。たとえば、「グループ全体」と称するあるモードによると、画像データの完全な全幅のラインがラインバッファ部とシート生成部との間で渡される。「実質上縦長」と称する第２モードによると、最初に１つのライングループが全幅の行のサブセットとともに渡される。その後、残りの行がより小さい（全幅未満の）一部として順番に渡される。
Due to the vertical overlap of the
入力画像データのライングループ８０３がラインバッファ部によって規定されてシート生成部に渡されると、シート生成部は、さらに、このライングループを、ステンシルプロセッサのハードウェア制約により正確に適合するより細かいシートに解析する。より具体的には、より詳細は以下にさらに説明するが、実施形態では、各ステンシルプロセッサは、２次元シフトレジスタアレイから構成される。２次元シフトレジスタアレイは、本質的に、画像データを実行レーンのアレイの「下」にシフトさせる。シフトパターンは、各実行レーンに、レーン自身の個々のステンシル内のデータを処理させる（つまり、各実行レーンは、自身の情報のステンシルを処理し、そのステンシルの出力を生成する）。実施形態では、シートは、２次元シフトレジスタアレイを「埋める」または２次元シフトレジスタアレイにロードされる入力画像データの表面領域である。
When the
より詳細はさらに後述するが、様々な実施形態では、実際には、任意の周期でシフトさせることができる２次元レジスタデータから構成されるレイヤは、複数ある。便宜上、本明細書のほとんどでは、単に、用語「２次元シフトレジスタ」などを用いて、シフトさせることができる２次元レジスタデータから構成される１つ以上のこのようなレイヤを有する構造を指す。 Although more details will be described later, in various embodiments, there are actually a plurality of layers composed of two-dimensional register data that can be shifted at an arbitrary cycle. For convenience, most of this specification simply refers to a structure having one or more such layers composed of two-dimensional register data that can be shifted, using the term "two-dimensional shift register" or the like.
よって、図８ｂに見られるように、シート生成部は、ライングループ８０３からの最初のシート８０４を解析し、ステンシルプロセッサに提供する（ここで、データのシートは、参照番号８０４で全体的に識別される陰影領域に対応する）。図８ｃおよび図８ｄに見られるように、ステンシルプロセッサは、重なり合うステンシル８０２を入力画像データのシートの左から右へ効果的に移動することによってシートを処理する。図８ｄの時点では、シート内のデータから出力値を算出できる画素数はなくなっている（他の画素位置はシート内の情報から決定される出力値を有し得るものはない）。わかりやすくするために、画像の境界領域は無視している。
Thus, as seen in FIG. 8b, the sheet generator analyzes the
図８ｅに見られるように、次に、シート生成部は、ステンシルプロセッサに引き続き処理させるために次のシート８０５を提供する。なお、次のシートに対する処理を開始するときのステンシルの初期位置は、第１シートの画素数がなくなっている箇所から右隣に進んだ場所である（すでに図８ｄで示したように）ことが分かる。新しいシート８０５では、ステンシルプロセッサが第１シートの処理と同じ方法でこの新しいシートを処理するにつれて、ステンシルは、右に移動し続けるだけである。 As seen in FIG. 8e, the sheet generator then provides the next sheet 805 for the stencil processor to continue processing. The initial position of the stencil when starting the processing for the next sheet may be the position advanced to the right from the place where the number of pixels of the first sheet is exhausted (as already shown in FIG. 8d). I understand. In the new sheet 805, the stencil only keeps moving to the right as the stencil processor processes the new sheet in the same way as it does for the first sheet.
なお、出力画素位置を囲むステンシルの境界領域のために、第１シート８０４のデータと第２シート８０５のデータとの間に重なりがある。この重なりは、シート生成部が重なり合うデータを２回再送信するだけで処理できる。別の実装形態では、次のシートをステンシルプロセッサに送るために、シート生成部は、新しいデータをステンシルプロセッサに送るだけであってもよく、ステンシルプロセッサは、重なり合うデータを前のシートから再利用する。
It should be noted that there is an overlap between the data of the
図９は、ステンシルプロセッサのアーキテクチャ９００の実施形態を示す図である。図９に見られるように、ステンシルプロセッサは、データ演算部９０１と、スカラープロセッサ９０２および関連するメモリ９０３と、入出力部９０４とを備える。データ演算部９０１は、実行レーン９０５のアレイと、２次元シフトアレイ構造９０６と、アレイの特定の行または列に対応付けられた別個のＲＡＭ９０７とを含む。
FIG. 9 is a diagram showing an embodiment of
入出力部９０４は、シート生成部から受け付けたデータの「入力」シートをデータ演算部９０１にロードして、ステンシルプロセッサからのデータの「出力」シートをシート生成部に格納する役割を果たす。実施形態では、シートデータをデータ演算部９０１にロードすることは、受け付けたシートを画像データの行／列に解析し、画像データの行／列を２次元シフトレジスタ構造９０６または実行レーンアレイ（より詳細は後述する）の行／列のＲＡＭ９０７のそれぞれにロードすることを伴う。シートがメモリ９０７に最初にロードされた場合、実行レーンアレイ９０５内の個々の実行レーンは、適宜、シートデータをＲＡＭ９０７から２次元シフトレジスタ構造９０６にロードしてもよい（たとえば、シートのデータの処理をする直前のロード命令として）。データのシートのレジスタ構造９０６へのロードが完了すると（シート生成部から直接であろうと、メモリ９０７からであろうと）、実行レーンアレイ９０５に含まれる実行レーンが当該データを処理し、最終的には、仕上がったデータをシートとしてシート生成部またはＲＡＭ９０７に直接「書き戻す」。後者の場合、入出力部９０４がデータをＲＡＭ９０７からフェッチして出力シートを形成し、その後、出力シートはシート生成部に転送される。
The input /
スカラープロセッサ９０２は、プログラムコントローラ９０９を含む。プログラムコントローラ９０９は、ステンシルプロセッサのプログラムコードの命令をスカラーメモリ９０３から読み出し、実行レーンアレイ９０５に含まれる実行レーンにこの命令を発行する。実施形態では、１つの同じ命令がアレイ９０５内のすべての実行レーンに一斉送信され、データ演算部９０１がＳＩＭＤのような動作を行う。実施形態では、スカラーメモリ９０３から読み出されて実行レーンアレイ９０５の実行レーンに発行される命令の命令フォーマットは、命令あたり２つ以上のオペコードを含むＶＬＩＷ（Ｖｅｒｙ−Ｌｏｎｇ−Ｉｎｓｔｒｕｃｔｉｏｎ−Ｗｏｒｄ）型フォーマットを含む。さらなる実施形態では、ＶＬＩＷフォーマットは、（後述するが、実施形態では、２つ以上の従来のＡＬＵ演算を指定し得る）各実行レーンのＡＬＵによって実行される数学関数を指示するＡＬＵオペコード、および（特定の実行レーンまたは特定の実行レーンセットのメモリ操作を指示する）メモリオペコードの両方を含む。
The scalar processor 902 includes a
用語「実行レーン」とは、１つの命令を実行可能な１つ以上の実行部からなるセットを指す（たとえば、命令を実行できる論理回路）。しかしながら、実行レーンは、様々な実施形態では、ただの実行部ではなく、よりプロセッサのような機能を含み得る。たとえば、１つ以上の実行部以外に、実行レーンは、受け付けた命令をデコードする論理回路、または、よりＭＩＭＤのような設計の場合、命令をフェッチおよびデコードする論理回路を含んでもよい。ＭＩＭＤのような手法に関しては、本明細書では集中プログラム制御手法について詳細を説明したが、様々な別の実施形態では、より分散した手法が実施されてもよい（アレイ９０５の各実行レーン内にプログラムコードとプログラムコントローラとを含むなど）。 The term "execution lane" refers to a set of one or more execution units capable of executing an instruction (eg, a logic circuit capable of executing an instruction). However, the execution lane may include more processor-like functions than just an execution unit in various embodiments. For example, in addition to one or more execution units, the execution lane may include a logic circuit that decodes the accepted instruction, or, in the case of a more MIMD-like design, a logic circuit that fetches and decodes the instruction. For techniques such as MIMD, centralized program control techniques have been described in detail herein, but in various other embodiments, more distributed techniques may be implemented (within each execution lane of array 905). Includes program code and program controller, etc.).
実行レーンアレイ９０５と、プログラムコントローラ９０９と、２次元シフトレジスタ構造９０６とを組み合わせることによって、広範囲のプログラム可能な機能のための広く受け容れられる／構成可能なハードウェアプラットフォームがもたらされる。たとえば、個々の実行レーンが広く多様な機能を実行でき、かつ、任意の出力アレイ位置に近接した入力画像データに容易にアクセスできるならば、アプリケーションソフトウェア開発者は、広範囲にわたる異なる機能能力および寸法（たとえば、ステンシルサイズ）を有するカーネルをプログラミングすることができる。
The combination of the execution lane array 905, the
実行レーンアレイ９０５によって処理されている画像データ用のデータストアとして機能すること以外に、ＲＡＭ９０７は、１つ以上のルックアップテーブルを保持してもよい。様々な実施形態では、１つ以上のスカラールックアップテーブルもスカラーメモリ９０３内でインスタンス化されてもよい。
In addition to acting as a data store for the image data being processed by the execution lane array 905, the
スカラー検索では、同じインデックスからの同じルックアップテーブルからの同じデータ値を実行レーンアレイ９０５内の実行レーンの各々に渡すことを伴う。様々な実施形態では、スカラープロセッサによって行われるスカラールックアップテーブルの検索動作を指示するスカラーオペコードも含むよう、上述したＶＬＩＷ命令フォーマットが拡大される。オペコードとともに使用するために指定されるインデックスは、即値オペランドであってもよく、または、他のデータ記憶位置からフェッチされてもよい。いずれにせよ、実施形態では、スカラーメモリ内のスカラールックアップテーブルの検索は、本質的に、同じクロック周期の間に実行レーンアレイ９０５内のすべての実行レーンに同じデータ値を一斉送信することを伴う。ルックアップテーブルの使用および操作のより詳細は、以下でさらに説明する。 A scalar search involves passing the same data values from the same lookup table from the same index to each of the execution lanes in the execution lane array 905. In various embodiments, the VLIW instruction format described above is extended to include scalar opcodes that direct the scalar lookup table lookup operation performed by the scalar processor. The index specified for use with the opcode may be an immediate operand or may be fetched from another data storage location. In any case, in the embodiment, the search for the scalar look-up table in the scalar memory essentially broadcasts the same data value to all the execution lanes in the execution lane array 905 during the same clock period. Accompany. More details on using and operating look-up tables are given below.
図９ｂは、上述したＶＬＩＷ命令語の実施形態（複数可）を要約した図である。図９ｂに見られるように、ＶＬＩＷ命令語フォーマットは、次の３つの別個の命令に対するフィールドを含む。（１）スカラープロセッサによって実行されるスカラー命令９５１、（２）実行レーンアレイ内のそれぞれのＡＬＵによってＳＩＭＤ式で一斉送信および実行されるＡＬＵ命令９５２、（３）部分ＳＩＭＤ式で一斉送信および実行されるメモリ命令９５３（たとえば、実行レーンアレイの同じ行にある実行レーンが同じＲＡＭを共有する場合、異なる行の各々からの１つの実行レーンが実際に命令を実行する（メモリ命令９５３のフォーマットは、各行のどの実行レーンが命令を実行するのかを識別するオペランドを含んでもよい）。
FIG. 9b is a diagram summarizing the embodiment (s) of the above-mentioned VLIW instruction word. As can be seen in FIG. 9b, the VLIW instruction word format includes fields for three separate instructions: (1)
１つ以上の即値オペランド用のフィールド９５４も含まれていてもよい。命令９５１、９５２、９５３のうちのいずれがどの即値オペランド情報を使用するかは、命令フォーマットで識別されてもよい。また、命令９５１、９５２、９５３の各々は、自身の入力オペランドおよび結果情報も含む（たとえば、ＡＬＵ演算のためのローカルレジスタ、ならびにメモリアクセス命令のためのローカルレジスタおよびメモリアドレス）。実施形態では、スカラー命令９５１は、実行レーンアレイ内の実行レーンがその他２つの命令９５２、９５３を実行する前に、スカラープロセッサによって実行される。つまり、ＶＬＩＷ語の実行は、スカラー命令９５１が実行される第１周期を含み、その次にその他の命令９５２、９５３が実行され得る第２周期を含む（なお、様々な実施形態では、命令９５２および９５３は、並列で実行されてもよい）。
実施形態では、スカラープロセッサによって実行されるスカラー命令は、データ演算部のメモリまたは２Ｄシフトレジスタからシートをロードする／データ演算部のメモリまたは２Ｄシフトレジスタにシートを格納するためにシート生成部に発行されるコマンドを含む。ここで、シート生成部の動作は、ラインバッファ部の動作、または、スカラープロセッサが発行したコマンドをシート生成部が完了させるのにかかる周期の数を実行時前に理解することを防ぐその他の変数によって異なり得る。このように、実施形態では、シート生成部に発行されるコマンドにスカラー命令９５１が対応するまたはスカラー命令９５１がコマンドをシート生成部に対して発行させるＶＬＩＷ語は、いずれも、その他の２つの命令フィールド９５２、９５３にＮＯＯＰ（ｎｏ−ｏｐｅｒａｔｉｏｎ）命令も含む。次に、シート生成部がデータ演算部へのロード／データ演算部からの格納を完了するまで、プログラムコードは、命令フィールド９５２、９５３のＮＯＯＰ命令のループに入る。ここで、シート生成部にコマンドを発行すると、スカラープロセッサは、コマンドが完了するとシート生成部がリセットするインターロックレジスタのビットを設定してもよい。ＮＯＯＰループの間、スカラープロセッサは、インターロックビットのビットを監視する。シート生成部がそのコマンドを完了したことをスカラープロセッサが検出すると、通常の実行が再び開始される。
In an embodiment, a scalar instruction executed by a scalar processor is issued to a sheet generator to load a sheet from the memory of the data arithmetic unit or the 2D shift register / to store the sheet in the memory of the data arithmetic unit or the 2D shift register. Includes commands to be done. Here, the behavior of the sheet generator is the behavior of the line buffer, or any other variable that prevents the sheet generator from understanding the number of cycles it takes to complete a command issued by the scalar processor before runtime. Can vary depending on. As described above, in the embodiment, the VLIW word corresponding to the command issued to the sheet generation unit by the
図１０は、データ演算コンポーネント１００１の実施形態を示す図である。図１０に見られるように、データ演算コンポーネント１００１は、２次元シフトレジスタアレイ構造１００６の「上方」に論理的に位置する実行レーンのアレイ１００５を含む。上述したように、様々な実施形態では、シート生成部が提供する画像データのシートが２次元シフトレジスタ１００６にロードされる。次に、実行レーンがレジスタ構造１００６からのシートデータを処理する。
FIG. 10 is a diagram showing an embodiment of the
実行レーンアレイ１００５およびシフトレジスタ構造１００６は、互いに対して定位置に固定されている。しかしながら、シフトレジスタアレイ１００６内のデータは、効果的かつ調整された方法でシフトし、実行レーンアレイに含まれる各実行レーンにデータ内の異なるステンシルを処理させる。このように、各実行レーンは、生成された出力シートに含まれる異なる画素の出力画像値を判断する。図１０のアーキテクチャから、実行レーンアレイ１００５が上下に隣接する実行レーンおよび左右に隣接する実行レーンを含むので、重なり合うステンシルは、縦方向だけでなく、横方向にも配置されていることは明らかである。 The execution lane array 1005 and the shift register structure 1006 are fixed in place with respect to each other. However, the data in the shift register array 1006 shifts in an effective and coordinated manner, causing each execution lane contained in the execution lane array to process a different stencil in the data. In this way, each execution lane determines the output image values of the different pixels included in the generated output sheet. From the architecture of FIG. 10, it is clear that the overlapping stencils are located not only vertically but also horizontally, as the execution lane array 1005 includes execution lanes that are vertically adjacent and execution lanes that are adjacent to the left and right. be.
データ演算部１００１のいくつかの注目すべきアーキテクチャ上の特徴として、シフトレジスタ構造１００６の寸法は、実行レーンアレイ１００５よりも広い。つまり、実行レーンアレイ１００５の外側にレジスタ１００９の「ハロー（ｈａｌｏ）」が存在する。ハロー１００９は、実行レーンアレイの２つの側面に存在するように図示されているが、実装によっては、ハローは、実行レーンアレイ１００５のより少ない（１つ）またはより多い（３つまたは４つの）側面に存在してもよい。ハロー１００５は、実行レーン１００５の「下」をデータがシフトすると実行レーンアレイ１００５の境界の外側にこぼれ出るデータの「スピルオーバ」空間を提供する役割を果たす。簡単な例として、ステンシルの左端の画素が処理されると、実行レーンアレイ１００５の右端の中心にある５×５ステンシルは、さらに右側に４つのハローレジスタ位置を必要とすることになる。図をわかりやすくするために、図１０は、標準的な実施形態において、いずれの側面（右、下）のレジスタも横接続および縦接続の両方を有し得るとき、ハローの右側のレジスタを横方向にのみシフト接続していると示し、ハローの下側のレジスタを縦方向にのみシフト接続していると示している。様々な実施形態では、ハロー領域は、画像処理命令を実行するための対応する実行レーン論理を含まない（たとえば、ＡＬＵは存在しない）。しかしながら、個々のハローレジスタ位置がメモリから個々にデータをロードし、データをメモリに格納できるよう、個々のメモリアクセスユニット（Ｍ）がハロー領域位置の各々に存在する。
As some notable architectural features of the
アレイの各行および／または各列、またはそれらの一部に連結されたさらなるスピルオーバ空間がＲＡＭ１００７によって提供される（たとえば、行方向に４つの実行レーン、列方向に２つの実行レーンにまたがる実行レーンアレイの「領域」に１つのＲＡＭが割り当てられてもよい）。わかりやすくするために、残りの明細書では、主に、行ベースおよび／または列ベースの割り当て方式について言及する）。ここで、実行レーンのカーネル動作は、２次元シフトレジスタアレイ１００６の外側の画素値を処理する必要がある場合、（いくつかの画像処理ルーチンが必要とし得る）、画像データの面は、たとえば、ハロー領域１００９からＲＡＭ１００７にさらにこぼれ出る（スピルオーバする）ことができる。たとえば、実行レーンアレイの右端の実行レーンの右側に４つのストレージ要素のみから構成されるハロー領域をハードウェアが含む、６×６ステンシルを考える。この場合、ステンシルを完全に処理するためには、データは、さらに右にシフトされてハロー１００９の右端からはみ出る必要がある。ハロー領域１００９の外にシフトされるデータは、その後、ＲＡＭ１００７にこぼれ出る。ＲＡＭ１００７および図９のステンシルプロセッサのその他の適用例をさらに以下に説明する。
Additional spillover space connected to each row and / or column of the array, or parts thereof, is provided by RAM 1007 (eg, an execution lane array that spans four execution lanes in the row direction and two execution lanes in the column direction). One RAM may be allocated to the "area" of). For clarity, the rest of the specification primarily refers to row-based and / or column-based allocation schemes). Here, if the kernel operation of the execution lane needs to process the pixel values outside the two-dimensional shift register array 1006 (which may be required by some image processing routines), the surface of the image data may be, for example, Further spills (spill over) from the
図１１ａ〜図１１ｋは、上述したように実行レーンアレイの「下」の２次元シフトレジスタアレイ内で画像データがシフトされる方法の例を説明する図である。図１１ａに見られるように、２次元シフトアレイのデータコンテンツが第１アレイ１１０７に図示され、実行レーンアレイがフレーム１１０５によって図示されている。また、実行レーンアレイ内の２つの隣接する実行レーン１１１０を簡略化して図示している。この単純化した図示１１１０では、各実行レーンは、シフトレジスタからデータを受け付ける、（たとえば、周期間の累算器として動作するための）ＡＬＵ出力からデータを受け付ける、または、出力データを出力先に書き込むことができるレジスタＲ１を含む。
11a-11k are diagrams illustrating an example of how the image data is shifted in the "bottom" two-dimensional shift register array of the execution lane array as described above. As seen in FIG. 11a, the data content of the two-dimensional shift array is illustrated in the first array 1107 and the execution lane array is illustrated by the frame 1105. Also, two
また、各実行レーンは、その「下」に、ローカルレジスタＲ２において、利用可能なコンテンツを２次元シフトアレイに有する。よって、Ｒ１は、実行レーンの物理レジスタであるのに対して、Ｒ２は、２次元シフトレジスタアレイの物理レジスタである。実行レーンは、Ｒ１および／またはＲ２が提供するオペランドを処理できるＡＬＵを含む。より詳細はさらに後述するが、実施形態では、シフトレジスタは、実際には、アレイ位置当たり複数のストレージ／レジスタ要素（の「深度」）を有して実装されるがシフトアクティビティは、ストレージ要素の１つの面に限られる（たとえば、ストレージ要素の１つの面のみが周期ごとにシフトできる）。図１１ａ〜１１ｋは、これらの深度がより深いレジスタ位置のうちの１つを、それぞれの実行レーンからの結果Ｘを格納するのに用いられているものとして図示している。図をわかりやすくするために、深度がより深い結果レジスタは、対応するレジスタＲ２の下ではなく、横に並べて図示されている。 Also, each execution lane has content available in the local register R2 "below" it in a two-dimensional shift array. Therefore, R1 is the physical register of the execution lane, while R2 is the physical register of the two-dimensional shift register array. The execution lane contains an ALU capable of processing the operands provided by R1 and / or R2. More details will be given later, but in embodiments, shift registers are actually implemented with multiple storage / register elements (“depths”) per array position, whereas shift activity is a storage element. Limited to one face (for example, only one face of the storage element can shift per period). FIGS. 11a-11k illustrate one of these deeper register positions as being used to store the result X from each execution lane. For the sake of clarity, the deeper result registers are shown side by side rather than under the corresponding register R2.
図１１ａ〜１１ｋは、実行レーンアレイ内に図示された実行レーン位置１１１１のペアと中央位置が揃えられた２つのステンシルの算出に焦点を当てている。図をわかりやすくするために、実行レーン１１１０のペアは、実際には下記の例によると縦方向に隣接している場合に、横方向に隣接していると図示されている。
FIGS. 11a-11k focus on the calculation of two stencils aligned with the pair of
最初に、図１１ａに見られるように、実行レーンは、その中央のステンシル位置の中心に位置決めされる。図１１ｂは、両方の実行レーンによって実行されるオブジェクトコードを示す図である。図１１ｂに見られるように、両方の実行レーンのプログラムコードによって、シフトレジスタアレイ内のデータは、位置を下に１つシフトし、位置を右に１つシフトさせられる。これによって、両方の実行レーンがそれぞれのステンシルの左上隅に揃えられる。次に、プログラムコードは、（Ｒ２において）それぞれの位置にあるデータをＲ１にロードさせる。 First, as seen in FIG. 11a, the execution lane is positioned at the center of its central stencil position. FIG. 11b is a diagram showing object code executed by both execution lanes. As can be seen in FIG. 11b, the program code in both execution lanes causes the data in the shift register array to shift its position down by one and its position by one to the right. This aligns both run lanes in the upper left corner of each stencil. The program code then loads the data at each position (in R2) into R1.
図１１ｃに見られるように、次に、プログラムコードは、実行レーンのペアに、シフトレジスタアレイ内のデータを１単位だけ左にシフトさせ、これによって、各実行レーンのそれぞれの位置の右にある値が、各実行レーンの位置にシフトされる。次に、（Ｒ２における）実行レーンの位置までシフトされた新しい値がＲ１の値（前の値）に加算される。その結果がＲ１に書き込まれる。図１１ｄに見られるように、図１１ｃで説明したのと同じ処理が繰り返され、これによって、結果Ｒ１は、ここで、上部実行レーンにおいて値Ａ＋Ｂ＋Ｃを含み、下部実行レーンにおいてＦ＋Ｇ＋Ｈを含む。この時点で、両方の実行レーンは、それぞれのステンシルの上側の行を処理済みである。なお、データは、実行レーンアレイの左側のハロー領域（左側に存在する場合）にこぼれ出るが、ハロー領域が実行レーンアレイの左側に存在しない場合はＲＡＭにこぼれ出る。 As can be seen in FIG. 11c, the program code then shifts the data in the shift register array to the left by one unit to the pair of execution lanes, thereby to the right of each position in each execution lane. The value is shifted to the position of each run lane. Next, the new value shifted to the position of the execution lane (in R2) is added to the value of R1 (previous value). The result is written in R1. As seen in FIG. 11d, the same process as described in FIG. 11c is repeated, whereby the result R1 contains the values A + B + C in the upper execution lane and F + G + H in the lower execution lane. At this point, both run lanes have processed the upper row of their respective stencils. Note that the data spills into the halo area on the left side of the execution lane array (if it exists on the left side), but spills into the RAM if the halo area does not exist on the left side of the execution lane array.
図１１ｅに見られるように、次に、プログラムコードは、シフトレジスタアレイ内のデータを１単位だけ上にシフトさせ、これによって、両方の実行レーンがそれぞれのステンシルの中央行の右端に揃えられる。両方の実行レーンのレジスタＲ１は、現在、ステンシルの最上行および中央行の右端の値の総和を含む。図１１ｆおよび図１１ｇは、両方の実行レーンのステンシルの中央行を左方向に移動する続きの進行を説明する図である。図１１ｇの処理の終わりに両方の実行レーンがそれぞれのステンシル最上行および中央行の値の総和を含むよう、累積加算が続く。 As can be seen in FIG. 11e, the program code then shifts the data in the shift register array up by one unit, thereby aligning both execution lanes to the right edge of the center row of each stencil. Register R1 in both execution lanes currently contains the sum of the rightmost values in the top and center rows of the stencil. 11f and 11g are diagrams illustrating a continuation of the movement to the left in the center row of the stencils of both execution lanes. Cumulative addition is followed so that at the end of the process of FIG. 11g, both execution lanes contain the sum of the values in the top and center rows of their respective stencil.
図１１ｈは、各実行レーンを対応するステンシルの最下行に揃えるための別のシフトを示す図である。図１１ｉおよび図１１ｊは、両方の実行レーンのステンシルに対する処理を完了するための、続きのシフト処理を示す図である。図１１ｋは、データ配列において各実行レーンをその正しい位置に揃えて結果をそこに書き込むためのさらなるシフト処理を示す図である。 FIG. 11h is a diagram showing another shift for aligning each execution lane to the bottom row of the corresponding stencil. 11i and 11j are diagrams showing subsequent shift processing to complete processing for stencils in both execution lanes. FIG. 11k is a diagram showing further shift processing for aligning each execution lane to its correct position in the data array and writing the result there.
なお、図１１ａ〜図１１ｋの例では、シフト演算用のオブジェクトコードは、（Ｘ，Ｙ）座標で表されるシフトの方向および大きさを識別する命令フォーマットを含んでもよい。たとえば、位置を１つ上にシフトさせるためのオブジェクトコードは、ＳＨＩＦＴ０、＋１というオブジェクトコードで表されてもよい。別の例として、位置を右に１つシフトすることは、ＳＨＩＦＴ＋１、０というオブジェクトコードで表現されてもよい。また、様々な実施形態では、より大きなシフトも、オブジェクトコード（たとえば、ＳＨＩＦＴ０、＋２）で指定されてもよい。ここで、２Ｄシフトレジスタハードウェアが周期あたり位置１つ分のシフトしかサポートしない場合、命令は、マシンによって、複数周期の実行を必要とすると解釈されてもよく、または、周期あたり位置２つ分以上のシフトをサポートするよう２Ｄシフトレジスタハードウェアが設計されてもよい。後者の実施形態をより詳細にさらに後述する。 In the example of FIGS. 11a to 11k, the object code for the shift operation may include an instruction format for identifying the direction and magnitude of the shift represented by the (X, Y) coordinates. For example, the object code for shifting the position up by one may be represented by the object code SHIFT0, +1. As another example, shifting the position by one to the right may be represented by the object code SHIFT + 1,0. Also, in various embodiments, larger shifts may also be specified in the object code (eg, SHIFT0, +2). Here, if the 2D shift register hardware supports only one position shift per cycle, the instruction may be interpreted by the machine as requiring execution of multiple cycles, or two positions per cycle. 2D shift register hardware may be designed to support these shifts. The latter embodiment will be described in more detail later.
図１２は、実行レーンおよび対応するシフトレジスタ構造（ハロー領域のレジスタは、対応する実行レーンを含まないが、様々な実施形態のメモリを含む）の単位セルをより詳細に示す別の図である。実行レーン、および実行レーンアレイの各位置に対応付けられたレジスタ空間は、実施形態では、図１２に見られる回路を実行レーンアレイの各ノードにおいてインスタンス化することによって実現される。図１２に見られるように、単位セルは、４つのレジスタＲ２〜Ｒ５から構成されるレジスタファイル１２０２に連結された実行レーン１２０１を含む。いずれの周期の間も、実行レーン１２０１は、レジスタＲ１〜Ｒ５のうちのいずれかから読み出されたり、書き込まれたりしてもよい。２つの入力オペランドを必要とする命令については、実行レーンは、両方のオペランドをＲ１〜Ｒ５のうちのいずれかから取り出してもよい。
FIG. 12 is another diagram showing in more detail the unit cells of the execution lane and the corresponding shift register structure (registers in the halo region do not include the corresponding execution lane but include memory of various embodiments). .. The register space associated with each position of the execution lane and the execution lane array is realized in the embodiment by instantiating the circuit seen in FIG. 12 at each node of the execution lane array. As can be seen in FIG. 12, the unit cell includes an
実施形態では、２次元シフトレジスタ構造は、１つの周期の間、レジスタＲ２〜Ｒ４のうちのいずれか１つ（のみ）のコンテンツを出力マルチプレクサ１２０３を通してその隣接するレジスタのレジスタファイルのうちの１つにシフト「アウト」させ、隣接するレジスタ間のシフトが同じ方向になるよう、レジスタＲ２〜Ｒ４のうちのいずれか１つ（のみ）のコンテンツを対応するレジスタファイルから入力マルチプレクサ１２０４を通してシフト「イン」されるコンテンツと置き換えることによって実現される（たとえば、すべての実行レーンが左にシフトする、すべての実行レーンが右にシフトする、など）。同じレジスタのコンテンツがシフトアウトされて、同じ周期上でシフトされるコンテンツと置き換えられることは一般的であり得るが、マルチプレクサ配列１２０３、１２０４は、同じ周期の間、同じレジスタファイル内で異なるシフト元および異なるシフト対象のレジスタを可能にする。
In an embodiment, the two-dimensional shift register structure transfers the contents of any one (only) of registers R2 to R4 through the
図１２に示すように、シフトシーケンスの間、実行レーンは、そのレジスタファイル１２０２からその左隣、右隣、上隣、および下隣の各々にコンテンツをシフトアウトすることになることが分かる。同じシフトシーケンスと連動して、実行レーンは、そのレジスタファイルに左隣、右隣、上隣、および下隣のうちの特定のレジスタファイルからコンテンツをシフトする。ここでも、シフトアウトする対象およびシフトインする元は、すべての実行レーンについて同じシフト方向に一致しなければならない（たとえば、右隣にシフトアウトする場合、シフトインは左隣からでなければならない）。
As shown in FIG. 12, it can be seen that during the shift sequence, the execution lane will shift out content from its
一実施形態において、周期あたり実行レーン１つにつき１つのレジスタのコンテンツのみをシフトさせることが可能であるが、その他の実施形態は、２つ以上のレジスタのコンテンツをシフトイン／アウトさせることが可能であってもよい。たとえば、図１２に見られるマルチプレクサ回路１２０３、１２０４の第２インスタンスが図１２の設計に組み込まれている場合、同じ周期で２つのレジスタのコンテンツをシフトアウト／インしてもよい。当然、周期ごとに１つのレジスタのコンテンツのみをシフトさせることができる実施形態では、数値演算間のシフトのためにより多くのクロック周期を消費することによって複数のレジスタからのシフトが数値演算間で生じてもよい（たとえば、数値演算間の２つのシフト演算を消費することによって２つのレジスタのコンテンツが当該数値演算間でシフトされてもよい）。
In one embodiment, it is possible to shift only the contents of one register per execution lane per cycle, while in other embodiments it is possible to shift in / out the contents of two or more registers. May be. For example, if a second instance of the
なお、シフトシーケンス時に実行レーンのレジスタファイルのすべてのコンテンツよりも少ない数のコンテンツがシフトアウトされた場合、各実行レーンのシフトアウトされなかったレジスタのコンテンツは、所定の位置に留まっている（シフトしない）ことが分かる。このように、シフトインされたコンテンツに置き換えられないシフトされなかったコンテンツは、いずれも、シフト周期にわたって、実行レーンにローカルに留まる。各実行レーンに見られるメモリユニット（「Ｍ」）を使用して、実行レーンアレイ内の実行レーンの行および／または列に対応付けられたランダムアクセスメモリ空間からデータをロード／またはそれに格納する。ここで、Ｍユニットは、標準Ｍユニットとして機能し、標準Ｍユニットは、実行レーン自体のレジスタ空間からロード／またはそれに格納できないデータをロード／格納するために利用される場合が多い。様々な実施形態では、Ｍユニットの主な動作は、ローカルレジスタからのデータをメモリに書き込み、メモリからデータを読み出してローカルレジスタに書き込むことである。 If a smaller number of contents than all the contents of the register file of the execution lane are shifted out during the shift sequence, the contents of the unshifted registers of each execution lane remain in a predetermined position (shift). I don't know). Thus, any unshifted content that is not replaced by shifted-in content remains local to the execution lane over the shift cycle. The memory unit (“M”) found in each run lane is used to load / or store data from the random access memory space associated with the rows and / or columns of the run lanes in the run lane array. Here, the M unit functions as a standard M unit, and the standard M unit is often used to load / store data that cannot be loaded / or stored in the register space of the execution lane itself. In various embodiments, the main operation of the M unit is to write data from the local register to memory, read data from memory and write to the local register.
ハードウェア実行レーン１２０１のＡＬＵ装置がサポートするＩＳＡオペコードに関して、様々な実施形態では、ハードウェアＡＬＵがサポートする数値演算オペコードは、（たとえば、ＡＤＤ、ＳＵＢ、ＭＯＶ、ＭＵＬ、ＭＡＤ、ＡＢＳ、ＤＩＶ、ＳＨＬ、ＳＨＲ、ＭＩＮ／ＭＡＸ、ＳＥＬ、ＡＮＤ、ＯＲ、ＸＯＲ、ＮＯＴ）を含む。先ほど記載したように、実行レーン１２０１によって、関連するＲＡＭからデータをフェッチ／当該ＲＡＭにデータを格納するためのメモリアクセス命令が実行され得る。これに加えて、ハードウェア実行レーン１２０１は、２次元シフトレジスタ構造内でデータをシフトさせるためのシフト演算命令（右、左、上、下）をサポートする。上述したように、プログラム制御命令は、主に、ステンシルプロセッサのスカラープロセッサによって実行される。
With respect to the ISA opcodes supported by the ALU device in the
４．０ 実装の実施形態
上述した様々な画像処理プロセッサのアーキテクチャの特徴は、必ずしも従来の意味での画像処理に限られないため、画像処理プロセッサを新たに特徴付け得る（または、させ得ない）その他のアプリケーションに適用してもよいことを指摘することが適切である。たとえば、上述した様々な画像処理プロセッサのアーキテクチャの特徴のうちのいずれかが、実際のカメラ画像の処理とは対照的に、アニメーションの作成ならびに／または生成および／もしくは描画に使用される場合、画像処理プロセッサは、ＧＰＵ（Ｇｒａｐｈｉｃｓ Ｐｒｏｃｅｓｓｉｎｇ Ｕｎｉｔ）として特徴付けられてもよい。これに加えて、上述した画像処理プロセッサアーキテクチャの特徴を、映像処理、ビジョンプロセッシング、画像認識および／または機械学習など、その他の技術用途に適用してもよい。このように適用すると、画像処理プロセッサは、（たとえば、コプロセッサとして）、（たとえば、コンピューティングシステムのＣＰＵ：Ｃｅｎｔｒａｌ Ｐｒｏｃｅｓｓｉｎｇ Ｕｎｉｔまたはその一部である）より汎用的なプロセッサと統合されてもよく、または、コンピューティングシステム内のスタンドアロン型のプロセッサであってもよい。
4.0 Implementation Embodiments The image processing processors may (or cannot) be newly characterized because the architectural features of the various image processing processors described above are not necessarily limited to image processing in the conventional sense. It is appropriate to point out that it may be applied to other applications. For example, if any of the architectural features of the various image processing processors described above are used to create and / or generate and / or draw an animation, as opposed to processing the actual camera image, the image. The processing processor may be characterized as a GPU (Graphics Processing Unit). In addition, the features of the image processing processor architecture described above may be applied to other technical applications such as video processing, vision processing, image recognition and / or machine learning. When applied in this way, the image processor (eg, as a coprocessor) may be integrated with a more general purpose processor (eg, CPU of a computing system: Central Processing Unit or part thereof). Alternatively, it may be a stand-alone processor in a computing system.
上述したハードウェア設計の実施形態は、半導体チップ内に実施されてもよく、および／または、最終的に半導体製造プロセスに向けての回路設計の記述として実施されてもよい。後者の場合、このような回路記述は、（たとえば、ＶＨＤＬまたはＶｅｒｉｌｏｇ）レジスタ転送レベル（ＲＴＬ：Ｒｅｇｉｓｔｅｒ Ｔｒａｎｓｆｅｒ Ｌｅｖｅｌ）回路記述、ゲートレベル回路記述、トランジスタレベル回路記述もしくはマスク記述、またはそれらの様々な組合せなどの形態をとり得る。回路記述は、通常、コンピュータ読み取り可能な記憶媒体（ＣＤ−ＲＯＭまたはその他の種類のストレージ技術など）上に実施される。 The hardware design embodiment described above may be implemented in a semiconductor chip and / or may finally be implemented as a description of a circuit design for a semiconductor manufacturing process. In the latter case, such circuit descriptions are (eg, VHDL or Verilog) register transfer level (RTL: Register Transfer Level) circuit descriptions, gate level circuit descriptions, transistor level circuit descriptions or mask descriptions, or various combinations thereof. It can take the form of. The circuit description is usually carried out on a computer-readable storage medium (such as a CD-ROM or other type of storage technology).
先のセクションから、後述する画像処理プロセッサをコンピュータシステム上のハードウェアで（たとえば、ハンドヘルド端末のカメラからのデータを処理するハンドヘルド端末のＳＯＣ（Ｓｙｓｔｅｍ Ｏｎ Ｃｈｉｐ）の一部として）実施してもよいことを認識することが適切である。なお、画像処理プロセッサがハードウェア回路として実施された場合、画像処理プロセッサによって処理される画像データをカメラから直接受け付けてもよいことが分かる。ここで、画像処理プロセッサは、単品カメラの一部、またはカメラを内蔵したコンピューティングシステムの一部であってもよい。後者の場合、カメラからまたはコンピューティングシステムのシステムメモリから画像データを直接受け付けてもよい（たとえば、カメラは、その画像データを、画像処理プロセッサではなくシステムメモリに送る）。また、先のセクションに記載の特徴の多くは、（アニメーションを描画する）ＧＰＵに適用可能である。 From the previous section, the image processor described below may be implemented in hardware on a computer system (eg, as part of a system on chip (SOC) of a handheld terminal that processes data from the camera of the handheld terminal). It is appropriate to recognize that. When the image processor is implemented as a hardware circuit, it can be seen that the image data processed by the image processor may be directly received from the camera. Here, the image processing processor may be a part of a single camera or a part of a computing system having a built-in camera. In the latter case, the image data may be received directly from the camera or from the system memory of the computing system (for example, the camera sends the image data to the system memory instead of the image processing processor). Also, many of the features described in the previous section are applicable to GPUs (drawing animations).
図１３は、コンピューティングシステムの例示的な図である。上述したコンピューティングシステムの構成要素のうちの多くは、内蔵カメラおよび関連する画像処理プロセッサ（たとえば、スマートフォンまたはタブレットコンピュータなどのハンドヘルド端末）を有するコンピューティングシステムに適用可能である。当業者は、これら２つの違いを容易に明確にするであろう。これに加えて、図１３のコンピューティングシステムは、ワークステーションまたはスーパーコンピュータなどの高性能なコンピューティングシステムの多くの特徴も含んでいる。 FIG. 13 is an exemplary diagram of a computing system. Many of the components of the computing system described above are applicable to computing systems with built-in cameras and associated image processing processors (eg, handheld terminals such as smartphones or tablet computers). Those skilled in the art will easily clarify the difference between the two. In addition to this, the computing system of FIG. 13 also includes many features of a high performance computing system such as a workstation or supercomputer.
図１３に見られるように、基本的なコンピューティングシステムは、ＣＰＵ１３０１（たとえば、マルチコアプロセッサまたはアプリケーションプロセッサ上に配置された複数の汎用処理コア１３１５＿１〜１３１５＿Ｎおよびメインメモリコントローラ１３１７を含んでもよい）と、システムメモリ１３０２と、ディスプレイ１３０３（たとえば、タッチスクリーン、フラットパネル）と、ローカル有線ポイントツーポイントリンク（たとえば、ＵＳＢ）インタフェース１３０４と、様々なネットワーク入出力機能部１３０５（Ｅｔｈｅｒｎｅｔ（登録商標）インタフェースおよび／またはセルラーモデムサブシステムなど）と、無線ローカルエリアネットワーク（たとえば、ＷｉＦｉ）インタフェース１３０６と、無線ポイントツーポイントリンク（たとえば、Ｂｌｕｅｔｏｏｔｈ（登録商標））インタフェース１３０７およびＧＰＳ（Ｇｌｏｂａｌ Ｐｏｓｉｔｉｏｎｉｎｇ Ｓｙｓｔｅｍ）インタフェース１３０８と、様々なセンサ１３０９＿１〜１３０９＿Ｎと、１つ以上のカメラ１３１０と、バッテリー１３１１と、電力管理制御部１３１２と、スピーカ／マイクロフォン１３１３と、オーディオコーダ／デコーダ１３１４とを含んでもよい。
As seen in FIG. 13, a basic computing system may include a CPU 1301 (eg, a plurality of general purpose processing cores 1315_1 to 1315_N and a
アプリケーションプロセッサまたはマルチコアプロセッサ１３５０は、そのＣＰＵ１２０１内に１つ以上の汎用処理コア１３１５を含み、１つ以上のＧＰＵ１３１６、メモリ管理機能部１３１７（たとえば、メモリコントローラ）、入出力制御機能部１３１８、および画像処理部１３１９を含んでもよい。汎用処理コア１３１５は、通常、コンピューティングシステムのオペレーティングシステムおよびアプリケーションソフトウェアを実行する。ＧＰＵ１３１６は、通常、グラフィックスを多く使う機能を実行して、たとえば、ディスプレイ１３０３上に提示されるグラフィックス情報を生成する。メモリ制御機能部１３１７は、システムメモリ１３０２とインタフェース接続され、システムメモリ１３０２にデータを書き込む／システムメモリ１３０２からデータを読み出す。電力管理制御部１３１２は、一般に、システム１３００の消費電力を制御する。
The application processor or
画像処理部１３１９は、先のセクションで詳細に上述した画像処理部の実施形態のいずれかに従って実現されてもよい。これに加えて、またはこれと組み合わせて、ＩＰＵ１３１９がＧＰＵ１３１６およびＣＰＵ１３０１のいずれかまたは両方に、そのコプロセッサとして連結されてもよい。これに加えて、様々な実施形態では、ＧＰＵ１３１６は、詳細に上述した画像処理プロセッサの特徴のいずれかを有して実現されてもよい。画像処理部１３１９は、詳細に上述したようなアプリケーションソフトウェアを有して構成されてもよい。これに加えて、図１３のコンピューティングシステムなどのコンピューティングシステムは、プログラムコードを実行して、上述したアプリケーションソフトウェア開発を実施してもよい。
The
タッチスクリーンディスプレイ１３０３、通信インタフェース１３０４〜１３０７、ＧＰＳインタフェース１３０８、センサ１３０９、カメラ１３１０、およびスピーカ／マイクロフォンコーデック１３１３、１３１４の各々は、すべて、内蔵型周辺機器（たとえば、１つ以上のカメラ１３１０）も適宜備えたコンピュータシステム全体に対する様々な形態のＩ／Ｏ（入力部および／または出力部）として見ることができる。実装形態によっては、これらのＩ／Ｏコンポーネントのうちの様々なＩ／Ｏコンポーネントがアプリケーションプロセッサ／マルチコアプロセッサ１３５０上に集積されてもよく、ダイからずれて配置、またはアプリケーションプロセッサ／マルチコアプロセッサ１３５０のパッケージの外に配置されてもよい。
Each of the
実施形態では、１つ以上のカメラ１３１０は、カメラと視野に存在するオブジェクトとの間の奥行きを測定可能な深度カメラを含む。アプリケーションプロセッサまたはその他のプロセッサの汎用ＣＰＵコア（または、プログラムコードを実行するための命令実行パイプラインを有するその他の機能ブロック）上で実行されるアプリケーションソフトウェア、オペレーティングシステムソフトウェア、デバイスドライバソフトウェア、および／またはファームウェアが、上述した機能のいずれかを実行してもよい。
In embodiments, the one or
本発明の実施形態は、上述した様々な処理を含んでもよい。処理は、機械によって実行可能な命令に含まれてもよい。命令を用いて、汎用プロセッサまたは特定用途向けプロセッサに特定の処理を実行させることができる。これに代えて、これらの処理は、処理を実行するための結線ロジックおよび／またはプログラム可能なロジックを含んだ専用のハードウェア部品によって実行されてもよく、プログラムを組み込まれたコンピュータ構成要素とカスタムハードウェア部品との任意の組み合わせによって実行されてもよい。 Embodiments of the present invention may include the various treatments described above. The processing may be included in the instructions that can be executed by the machine. Instructions can be used to cause a general purpose processor or a special purpose processor to perform a particular process. Alternatively, these processes may be performed by dedicated hardware components that include wiring logic and / or programmable logic to perform the processes, with embedded computer components and custom programs. It may be performed in any combination with hardware components.
また、本発明の要素は、機械によって実行可能な命令を格納するための機械読み取り可能な媒体として提供されてもよい。機械読み取り可能な媒体は、フロッピー（登録商標）ディスク、光ディスク、ＣＤ−ＲＯＭ、および光磁気ディスク、ＦＬＡＳＨメモリ、ＲＯＭ、ＲＡＭ、ＥＰＲＯＭ、ＥＥＰＲＯＭ、磁気カードまたは光カード、電子命令を格納するのに適した伝播媒体またはその他の種類の媒体／機械読み取り可能な媒体などがあり得るが、これらに限定されない。たとえば、本発明は、コンピュータプログラムとしてダウンロードされてもよく、コンピュータプログラムは、搬送波またはその他の伝播媒体に含んだデータ信号として、通信リンク（たとえば、モデムまたはネットワーク接続）を介してリモートコンピュータ（たとえば、サーバ）から要求元コンピュータ（たとえば、クライアント）に転送され得る。 The elements of the invention may also be provided as machine readable media for storing machine-executable instructions. Machine-readable media are suitable for storing floppy (registered trademark) disks, optical disks, CD-ROMs, and magneto-optical disks, FLASH memory, ROM, RAM, EPROM, EEPROM, magnetic or optical cards, and electronic instructions. There may be, but are not limited to, propagation media or other types of media / machine readable media. For example, the invention may be downloaded as a computer program, which may be a remote computer (eg, a modem or network connection) over a communication link (eg, a modem or network connection) as a data signal contained in a carrier or other propagation medium. It can be transferred from the server) to the requesting computer (eg client).
上記の明細書において、具体的、例示的な実施形態を用いて本発明を説明したが、特許請求の範囲に記載の本発明のより広義の趣旨および範囲から逸脱することなく、様々な変形、変更を行ってもよいことは明らかであろう。したがって、明細書および図面は、厳密ではなく、例示的であるとみなされるべきである。 Although the present invention has been described in the above specification using specific and exemplary embodiments, various modifications, without departing from the broader intent and scope of the invention described in the claims. It will be clear that changes may be made. Therefore, the specification and drawings should be considered as exemplary rather than rigorous.
以下に、いくつかの例を記載する。
（例１）画像処理プロセッサであって、
複数の処理コアと、
処理コア間で連結されたリングネットワークとを備え、リングネットワークは、処理コアの第１セットを連結する第１構成と、処理コアの第１セットおよび処理コアの第２セットを連結する第２構成とを提供し、第１構成および第２構成は、連続するシーケンスで各処理コアにネットワークアドレスを割り当て、第１構成および第２構成は、処理コアの第１セットに含まれる各処理コアに同一のネットワークアドレスを割り当て、リングを囲むように処理コアに割り当てられるネットワークアドレスは、連続するシーケンスとは異なる、画像処理プロセッサ。
Below are some examples.
(Example 1) An image processor
With multiple processing cores
It comprises a ring network connected between processing cores, the ring network having a first configuration connecting a first set of processing cores and a second configuration connecting a first set of processing cores and a second set of processing cores. The first configuration and the second configuration assign a network address to each processing core in a continuous sequence, and the first configuration and the second configuration are the same for each processing core included in the first set of processing cores. The network address assigned to the processing core to surround the ring is different from the continuous sequence, the image processing processor.
（例２）画像処理プロセッサは、第１構成および第２構成を設定するためのレジスタ空間を備える、例１に記載のプロセッサ。 (Example 2) The processor according to Example 1, wherein the image processing processor includes a register space for setting a first configuration and a second configuration.
（例３）リングネットワークは、マルチプレクサのセットの第１チャネルの選択によって、リング上のさらなるノードを含めることをリングネットワークに許可させ、マルチプレクサのセットの第２チャネルの選択によって、さらなるノードをリングネットワークに排除させるよう、マルチプレクサのセットを含む、例１または２に記載のプロセッサ。 (Example 3) The ring network allows the ring network to include additional nodes on the ring by selecting the first channel of the set of multiplexers, and the ring network by selecting the second channel of the set of multiplexers. The processor according to Example 1 or 2, comprising a set of multiplexers to be eliminated.
（例４）マルチプレクサのセットは、マルチプレクサのペアを含む、例３に記載のプロセッサ。 (Example 4) The processor according to Example 3, wherein the set of multiplexers includes a pair of multiplexers.
（例５）処理コアは、プログラムコードを実行する、先行する例のうちの少なくとも１つに記載のプロセッサ。 (Example 5) The processing core is the processor according to at least one of the preceding examples that executes the program code.
（例６）処理コアは、各々、実行レーンアレイと２次元シフトレジスタアレイとを備える、先行する例のうちの少なくとも１つに記載のプロセッサ。 (Example 6) The processor according to at least one of the preceding examples, wherein each processing core comprises an execution lane array and a two-dimensional shift register array.
（例７）画像処理プロセッサのアーキテクチャは、少なくとも１つのラインバッファ、少なくとも１つのシート生成部、および／または少なくとも１つのステンシル生成部を備える、先行する例のうちの少なくとも１つに記載のプロセッサ。 (Example 7) The processor according to at least one of the preceding examples, wherein the architecture of the image processing processor comprises at least one line buffer, at least one sheet generator, and / or at least one stencil generator.
（例８）ステンシル、特に、重なり合うステンシルを処理するように構成される、先行する例のうちの少なくとも１つに記載のプロセッサ。 Example 8 The processor according to at least one of the preceding examples configured to handle stencils, in particular overlapping stencils.
（例９）実行レーンアレイよりも幅広い次元を有する、特に、実行レーンアレイの外側にレジスタが存在するシフトレジスタ構造を含むデータ演算部上で動作するように構成される、先行する例のうちの少なくとも１つに記載のプロセッサ。 (Example 9) Among the preceding examples, which have a wider dimension than the execution lane array, in particular, are configured to operate on a data arithmetic unit including a shift register structure in which registers are located outside the execution lane array. At least one of the processors described.
（例１０）プログラムコードを含む非一時的な機械読み取り可能な記憶媒体であって、プログラムコードは、コンピューティングシステムによって処理されると、方法を実行させ、方法は、
プロセッサ上で実行するためのオブジェクトコードの第１インスタンスを構成するステップを含み、プロセッサは、複数のコアと内部ネットワークとを有し、内部ネットワークは、第１の数のコアを通信可能に連結することを可能にする第１構成で構成され、方法は、さらに、
プロセッサの第２インスタンス上で実行するためのオブジェクトコードの第２インスタンスを構成するステップを含み、プロセッサの第２インスタンスの内部ネットワークは、異なる数のコアを通信可能に連結することを可能にする第２構成で構成され、プロセッサおよびプロセッサの第２インスタンス上で同じ位置にあるコアは、第１構成および第２構成に対して同じネットワークアドレスを有する、非一時的な機械読み取り可能な記憶媒体。
(Example 10) A non-temporary machine-readable storage medium containing a program code that, when processed by a computing system, causes the method to be executed and the method is:
It comprises the steps of forming a first instance of object code for execution on a processor, the processor having multiple cores and an internal network, the internal network communicating a first number of cores. The method consists of a first configuration that allows for further
A second instance of the processor, including steps to configure a second instance of object code to run on the second instance of the processor, allows the internal network of the second instance of the processor to communicatively connect different numbers of cores. A non-temporary machine-readable storage medium consisting of two configurations, the processor and the co-located core on the second instance of the processor, having the same network address for the first configuration and the second configuration.
（例１１）オブジェクトコードの第１インスタンスおよびオブジェクトコードの第２インスタンスは、プロセッサおよびプロセッサの第２インスタンスのそれぞれ異なるコア上で実行される、例１０に記載の非一時的な機械読み取り可能な媒体。 (Example 11) The non-transitory machine-readable medium according to Example 10, wherein the first instance of the object code and the second instance of the object code are executed on different cores of the processor and the second instance of the processor. ..
（例１２）オブジェクトコードの第１インスタンスおよび第２インスタンスは、それぞれ異なるコアをベースアドレスからのオフセットとしてアドレス指定する、例１０または１１に記載の非一時的な機械読み取り可能な媒体。 (Example 12) The non-temporary machine-readable medium according to Example 10 or 11, wherein the first instance and the second instance of the object code address different cores as offsets from the base address.
（例１３）オブジェクトコードの第１インスタンスおよび第２インスタンスを構成するステップは、第１インスタンスおよび第２インスタンスにそれぞれ異なるベースアドレスを設定するステップを含む、例１０〜１２のうちの少なくとも１つに記載の非一時的な機械読み取り可能な媒体。 (Example 13) The step of configuring the first instance and the second instance of the object code includes at least one of Examples 10 to 12 including a step of setting different base addresses for the first instance and the second instance. The non-temporary machine-readable medium described.
（例１４）オブジェクトコードの第１インスタンスおよび第２インスタンスのうちの一方は、より大きなアプリケーション内のコードのより小さいコンポーネントとして個々のプロセッサ上で実行され、より大きなアプリケーションは、別のプログラムのオブジェクトコードインスタンスをオブジェクトコードの第１インスタンスおよび第２インスタンスのうちの一方と組み合わせることによって構成される、例１０〜１３のうちの少なくとも１つに記載の非一時的な機械読み取り可能な媒体。 (Example 14) One of the first and second instances of object code runs on an individual processor as a smaller component of the code in a larger application, and the larger application is the object code of another program. The non-temporary machine-readable medium according to at least one of Examples 10 to 13, which is configured by combining an instance with one of a first instance and a second instance of an object code.
（例１５）オブジェクトコードの第１インスタンスおよび第２インスタンスのうちの他方は、スタンドアロンアプリケーションとして個々のプロセッサ上で実行される、例１０〜１４のうちの少なくとも１つに記載の非一時的な機械読み取り可能な媒体。 (Example 15) The non-temporary machine according to at least one of Examples 10 to 14, wherein the other of the first instance and the second instance of the object code is executed on an individual processor as a stand-alone application. Readable medium.
（例１６）方法は、
プロセッサとは異なる数のコアを有する別のプロセッサ上で実行するためのオブジェクトコードの第３インスタンスを構成するステップをさらに含む、例１０〜１５のうちの少なくとも１つに記載の非一時的な機械読み取り可能な媒体。
(Example 16) The method is
The non-temporary machine according to at least one of Examples 10-15, further comprising a step of configuring a third instance of object code for execution on another processor having a different number of cores than the processor. Readable medium.
（例１７）方法は、少なくとも１つのラインバッファ、少なくとも１つのシート生成部、および／または少なくとも１つのステンシル生成部から構成される画像処理プロセッサのアーキテクチャ上で動作する、例１０〜１６のうちの少なくとも１つに記載の非一時的な機械読み取り可能な媒体。 Example 17 Of Examples 10-16, the method operates on an image processor architecture consisting of at least one line buffer, at least one sheet generator, and / or at least one stencil generator. A non-temporary machine-readable medium according to at least one.
（例１８）ステンシル、特に、重なり合うステンシルを処理するように構成される、例１０〜１７のうちの少なくとも１つに記載の非一時的な機械読み取り可能な媒体。 (Example 18) The non-temporary machine-readable medium according to at least one of Examples 10 to 17, configured to process stencils, in particular overlapping stencils.
（例１９）実行レーンアレイよりも幅広い次元を有する、特に、実行レーンアレイの外側にレジスタが存在するシフトレジスタ構造を含むデータ演算部上で動作するように構成される、例１０〜１８のうちの少なくとも１つに記載の非一時的な機械読み取り可能な媒体。 (Example 19) Of Examples 10 to 18, which have a wider dimension than the execution lane array, in particular, are configured to operate on a data calculation unit including a shift register structure in which a register exists outside the execution lane array. A non-temporary machine-readable medium according to at least one of the above.
（例２０）コンピューティングシステムであって、
複数の処理コアと、
システムメモリと、
システムメモリと複数の処理コアとの間に配置されたシステムメモリコントローラと、
プログラムコードを含んだ非一時的な機械読み取り可能な記憶媒体とを備え、プログラムコードは、コンピューティングシステムによって処理されると、方法を実行させ、方法は、
プロセッサ上で実行するためのオブジェクトコードの第１インスタンスを構成するステップを含み、プロセッサは、複数のコアと内部ネットワークとを有し、内部ネットワークは、第１の数のコアを通信可能に連結することを可能にする第１構成で構成され、方法は、さらに、
プロセッサの第２インスタンス上で実行するためのオブジェクトコードの第２インスタンスを構成するステップをさらに含み、プロセッサの第２インスタンスの内部ネットワークは、異なる数のコアを通信可能に連結することを可能にする第２構成で構成され、プロセッサおよびプロセッサの第２インスタンス上で同じ位置にあるコアは、第１構成および第２構成のそれぞれに対して同じネットワークアドレスを有する、コンピューティングシステム。
(Example 20) A computing system
With multiple processing cores
With system memory
A system memory controller located between the system memory and multiple processing cores,
It features a non-temporary machine-readable storage medium containing the program code, and when the program code is processed by the computing system, the method is executed and the method is performed.
It comprises the steps of forming a first instance of object code for execution on a processor, the processor having multiple cores and an internal network, the internal network communicating a first number of cores. The method consists of a first configuration that allows for further
Further including steps to configure a second instance of object code to run on a second instance of the processor, the internal network of the second instance of the processor allows different numbers of cores to be communicably linked. A computing system consisting of a second configuration and co-located on a processor and a second instance of the processor having the same network address for each of the first and second configurations.
（例２１）オブジェクトコードの第１インスタンスおよびオブジェクトコードの第２インスタンスは、プロセッサおよびプロセッサの第２インスタンスのそれぞれ異なるコア上で実行される、例２０に記載のコンピューティングシステム。 21. The computing system of Example 20, wherein the first instance of the object code and the second instance of the object code run on different cores of the processor and the second instance of the processor.
（例２２）オブジェクトコードの第１インスタンスおよび第２インスタンスは、それぞれ異なるコアをベースアドレスからのオフセットとしてアドレス指定する、例２０または２１に記載のコンピューティングシステム。 (Example 22) The computing system according to Example 20 or 21, wherein the first instance and the second instance of the object code address different cores as offsets from the base address.
（例２３）オブジェクトコードの第１インスタンスおよび第２インスタンスを構成するステップは、第１インスタンスおよび第２インスタンスにそれぞれ異なるベースアドレスを設定するステップを含む、例２０〜２２のうちの少なくとも１つに記載のコンピューティングシステム。 (Example 23) The step of configuring the first instance and the second instance of the object code includes at least one of Examples 20 to 22 including a step of setting different base addresses for the first instance and the second instance. Described computing system.
（例２４）オブジェクトコードの第１インスタンスおよび第２インスタンスのうちの一方は、より大きなアプリケーション内のコードのより小さいコンポーネントとして、個々のプロセッサ上で実行され、より大きなアプリケーションは、別のプログラムのオブジェクトコードインスタンスをオブジェクトコードの第１インスタンスおよび第２インスタンスのうちの一方と組み合わせることによって構成される、例２０〜２３のうちの少なくとも１つに記載のコンピューティングシステム。 (Example 24) One of the first and second instances of object code runs on an individual processor as a smaller component of the code in a larger application, and the larger application is an object of another program. The computing system according to any one of Examples 20-23, wherein the code instance is configured by combining one of a first instance and a second instance of object code.
（例２５）オブジェクトコードの第１インスタンスおよび第２インスタンスのうちの他方は、スタンドアロンアプリケーションとして個々のプロセッサ上で実行される、例２０〜２４のうちの少なくとも１つに記載のコンピューティングシステム。 (Example 25) The computing system according to at least one of Examples 20 to 24, wherein the other of the first instance and the second instance of the object code is executed on an individual processor as a stand-alone application.
（例２６）プロセッサおよびプロセッサの第２インスタンスは、画像処理プロセッサである、例２０〜２５のうちの少なくとも１つに記載のコンピューティングシステム。 (Example 26) The computing system according to at least one of Examples 20 to 25, wherein the processor and a second instance of the processor are image processing processors.
（例２７）少なくとも１つのラインバッファ、少なくとも１つのシート生成部、および／または少なくとも１つのステンシル生成部を含むアーキテクチャを有する画像処理プロセッサを備える、例２０〜２６のうちの少なくとも１つに記載のコンピューティングシステム。 27. The embodiment of at least one of Examples 20-26 comprising an image processor having an architecture comprising at least one line buffer, at least one sheet generator, and / or at least one stencil generator. Computing system.
（例２８）ステンシル、特に、重なり合うステンシルを処理するように構成される、例２０〜２７のうちの少なくとも１つに記載のコンピューティングシステム。 (Example 28) The computing system according to at least one of Examples 20-27, which is configured to handle stencils, in particular overlapping stencils.
（例２９）実行レーンアレイよりも幅広い次元を有する、特に、実行レーンアレイの外側にレジスタが存在するシフトレジスタ構造を含むデータ演算部を備える、例２０〜１８のうちの少なくとも１つに記載の非一時的な機械読み取り可能な媒体。 (Example 29) The invention according to at least one of Examples 20 to 18, which includes a data calculation unit having a wider dimension than the execution lane array, particularly including a shift register structure in which a register exists outside the execution lane array. Non-temporary machine-readable medium.
Claims (31)
プログラムコードを実行するように構成された複数の処理コアと、
処理コア間で連結されたリングネットワークとを備え、前記リングネットワークは、前記処理コアの第１セットを連結する第１構成と、前記処理コアの前記第１セットおよび前記処理コアの第２セットを連結する第２構成とを提供し、前記第１構成および前記第２構成は、連続するシーケンスで各処理コアにネットワークアドレスを割り当て、前記第１構成および前記第２構成は、前記処理コアの第１セットに含まれる各処理コアに同一のネットワークアドレスを割り当て、前記リングネットワークを囲むように前記処理コアに割り当てられる前記ネットワークアドレスは、前記連続するシーケンスとは異なり、
前記第１構成において、前記複数の処理コアは、第１プログラムのオブジェクトコードを実行し、
前記第２構成において、前記複数の処理コアは、前記第１プログラムを含む第２プログラムのオブジェクトコードを実行し、
前記第２プログラムのオブジェクトコードは、前記第１プログラムのオブジェクトコードのコピーを含む、画像処理プロセッサ。 An image processor
With multiple processing cores configured to execute program code,
The ring network comprises a ring network connected between the processing cores, and the ring network includes a first configuration for connecting the first set of the processing cores, and the first set of the processing cores and the second set of the processing cores. A second configuration to be concatenated is provided, the first configuration and the second configuration assign a network address to each processing core in a continuous sequence, and the first configuration and the second configuration are the first of the processing cores. assigning identical network address to each processing core included in a set, the network address assigned to the processing core to surround the ring network Unlike sequence said consecutive,
In the first configuration, the plurality of processing cores execute the object code of the first program.
In the second configuration, the plurality of processing cores execute the object code of the second program including the first program.
The object code of the second program is an image processing processor including a copy of the object code of the first program.
第１プログラムをプロセッサの第１構成上で実行するためのオブジェクトコードの第１インスタンスを前記第１プログラムをコンパイルすることによって構成するステップを含み、前記プロセッサは、複数のコアと内部ネットワークとを有し、前記プロセッサの前記第１構成の前記内部ネットワークは、第１の数の前記コアを通信可能に連結することを可能にするように構成され、前記方法は、さらに、
前記第１プログラムを含む第２プログラムを前記プロセッサの第２構成上で実行するための前記オブジェクトコードの第２インスタンスを前記第１インスタンスのコピーを利用して構成するステップを含み、前記プロセッサの前記第２構成の前記内部ネットワークは、第２の数のコアを通信可能に連結することを可能にするように構成され、前記プロセッサの前記第１構成および前記プロセッサの前記第２構成上で同じ位置にあるコアは、同じネットワークアドレスを有する、プログラム。 A program that includes program code that, when processed by a computing system, causes the method to be executed.
The processor comprises a step of configuring a first instance of object code for executing a first program on a first configuration of a processor by compiling the first program , the processor having a plurality of cores and an internal network. and, wherein the first configuration wherein the internal network of the processor is configured to allow coupling communicatively first the core number, the method further,
A step of configuring a second instance of the object code for executing a second program including the first program on a second configuration of the processor using a copy of the first instance , said to the processor. The internal network of the second configuration is configured to allow a second number of cores to be communicably linked and at the same location on the first configuration of the processor and the second configuration of the processor. core has the same network address in the program.
前記プロセッサとは異なる数のコアを有する別のプロセッサ上で実行するための前記オブジェクトコードの第３インスタンスを構成するステップをさらに含む、請求項１０〜１５のいずれか１項に記載のプログラム。 The method is
The program according to any one of claims 10 to 15, further comprising a step of forming a third instance of the object code for execution on another processor having a different number of cores than the processor.
プロセッサと、
システムメモリと、
前記システムメモリと前記プロセッサとの間に配置されたシステムメモリコントローラと、
プログラムコードを含んだ非一時的な機械読み取り可能な記憶媒体とを備え、前記プログラムコードは、前記コンピューティングシステムによって処理されると、方法を実行させ、前記方法は、
第１プログラムを前記プロセッサの第１構成上で実行するためのオブジェクトコードの第１インスタンスを前記第１プログラムをコンパイルすることによって構成するステップを含み、前記プロセッサは、複数のコアと内部ネットワークとを有し、前記プロセッサの前記第１構成の前記内部ネットワークは、第１の数の前記コアを通信可能に連結することを可能にするように構成され、前記方法は、さらに、
前記第１プログラムを含む第２プログラムを前記プロセッサの第２構成上で実行するための前記オブジェクトコードの第２インスタンスを前記第１インスタンスのコピーを利用して構成するステップをさらに含み、前記プロセッサの前記第２構成の前記内部ネットワークは、第２の数のコアを通信可能に連結することを可能にするように構成され、前記プロセッサの前記第１構成および前記プロセッサの前記第２構成上で同じ位置にあるコアは、同じネットワークアドレスを有する、コンピューティングシステム。 It ’s a computing system,
With the processor
With system memory
A system memory controller arranged between the system memory and the processor,
It comprises a non-temporary machine-readable storage medium containing the program code, which, when processed by the computing system, causes the method to be executed.
The processor comprises a step of configuring a first instance of object code for executing a first program on the first configuration of the processor by compiling the first program , the processor having a plurality of cores and an internal network. has the first configuration said internal network of the processor is configured to allow coupling communicatively first the core number, the method further,
A step of configuring a second instance of the object code for executing a second program including the first program on a second configuration of the processor using a copy of the first instance of the processor. the internal network of the second configuration is configured to allow the communicatively connecting the second number of cores, the same on the second configuration of the first configuration and the processor of the processor core in the position has the same network address, the computing system.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US15/594,502 | 2017-05-12 | ||
US15/594,502 US10789202B2 (en) | 2017-05-12 | 2017-05-12 | Image processor with configurable number of active cores and supporting internal network |
PCT/US2018/013582 WO2018208339A1 (en) | 2017-05-12 | 2018-01-12 | Image processor with configurable number of active cores and supporting internal network |
Publications (2)
Publication Number | Publication Date |
---|---|
JP2020519979A JP2020519979A (en) | 2020-07-02 |
JP6967597B2 true JP6967597B2 (en) | 2021-11-17 |
Family
ID=61132915
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2019543927A Active JP6967597B2 (en) | 2017-05-12 | 2018-01-12 | An image processor with a configurable number of active cores and an internal network that supports it |
Country Status (7)
Country | Link |
---|---|
US (1) | US10789202B2 (en) |
EP (1) | EP3622370A1 (en) |
JP (1) | JP6967597B2 (en) |
KR (1) | KR102235056B1 (en) |
CN (1) | CN110300944B (en) |
TW (2) | TWI735971B (en) |
WO (1) | WO2018208339A1 (en) |
Families Citing this family (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10489878B2 (en) * | 2017-05-15 | 2019-11-26 | Google Llc | Configurable and programmable image processor unit |
US11074213B2 (en) * | 2019-06-29 | 2021-07-27 | Intel Corporation | Apparatuses, methods, and systems for vector processor architecture having an array of identical circuit blocks |
CN110597755B (en) * | 2019-08-02 | 2024-01-09 | 北京多思安全芯片科技有限公司 | Recombination configuration method of safety processor |
CN113222126B (en) * | 2020-01-21 | 2022-01-28 | 上海商汤智能科技有限公司 | Data processing device and artificial intelligence chip |
CN113342719B (en) * | 2021-06-30 | 2022-12-13 | 珠海一微半导体股份有限公司 | Operation acceleration unit and operation method thereof |
Family Cites Families (15)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US1400962A (en) * | 1920-03-09 | 1921-12-20 | Roy E Leonard | Process of and apparatus for drilling oil-wells |
JP2900359B2 (en) * | 1986-10-30 | 1999-06-02 | 株式会社日立製作所 | Multiprocessor system |
CA2101848A1 (en) * | 1991-02-06 | 1992-08-07 | Robert Walsh | Disk drive array memory system using nonuniform disk drives |
JPH06290159A (en) * | 1993-03-30 | 1994-10-18 | Agency Of Ind Science & Technol | Process assigning method for parallel computers |
JP3290798B2 (en) * | 1994-03-14 | 2002-06-10 | 富士通株式会社 | Parallel computer |
US20030033374A1 (en) * | 2001-07-24 | 2003-02-13 | Condor Engineering, Inc. | Method and system for implementing a communications core on a single programmable device |
JP2004252508A (en) * | 2003-02-18 | 2004-09-09 | Nec Corp | Method for converting software program for single processor into software program for multiprocessor |
JP2006093937A (en) * | 2004-09-22 | 2006-04-06 | Canon Inc | Photoelectric fusion circuit |
US7941698B1 (en) * | 2008-04-30 | 2011-05-10 | Hewlett-Packard Development Company, L.P. | Selective availability in processor systems |
JP2012252490A (en) * | 2011-06-02 | 2012-12-20 | Renesas Electronics Corp | Multiprocessor and image processing system using the same |
WO2013105931A1 (en) | 2012-01-10 | 2013-07-18 | Intel Corporation | Router parking in power-efficient interconnect architectures |
US9514563B2 (en) | 2013-08-30 | 2016-12-06 | Arm Limited | Graphics processing systems |
WO2015163897A1 (en) | 2014-04-24 | 2015-10-29 | Empire Technology Development Llc | Core prioritization for heterogeneous on-chip networks |
US9769356B2 (en) * | 2015-04-23 | 2017-09-19 | Google Inc. | Two dimensional shift array for image processor |
US10291813B2 (en) | 2015-04-23 | 2019-05-14 | Google Llc | Sheet generator for image processor |
-
2017
- 2017-05-12 US US15/594,502 patent/US10789202B2/en active Active
-
2018
- 2018-01-12 KR KR1020197023971A patent/KR102235056B1/en active IP Right Grant
- 2018-01-12 EP EP18702599.4A patent/EP3622370A1/en not_active Withdrawn
- 2018-01-12 WO PCT/US2018/013582 patent/WO2018208339A1/en active Application Filing
- 2018-01-12 CN CN201880011667.8A patent/CN110300944B/en active Active
- 2018-01-12 JP JP2019543927A patent/JP6967597B2/en active Active
- 2018-02-08 TW TW108136896A patent/TWI735971B/en active
- 2018-02-08 TW TW107104426A patent/TWI676150B/en active
Also Published As
Publication number | Publication date |
---|---|
TW201947524A (en) | 2019-12-16 |
TWI735971B (en) | 2021-08-11 |
TWI676150B (en) | 2019-11-01 |
CN110300944B (en) | 2023-05-16 |
US20180329864A1 (en) | 2018-11-15 |
KR20190107101A (en) | 2019-09-18 |
US10789202B2 (en) | 2020-09-29 |
WO2018208339A1 (en) | 2018-11-15 |
JP2020519979A (en) | 2020-07-02 |
CN110300944A (en) | 2019-10-01 |
EP3622370A1 (en) | 2020-03-18 |
KR102235056B1 (en) | 2021-04-01 |
TW201901612A (en) | 2019-01-01 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
JP7202987B2 (en) | Architecture for High Performance, Power Efficient, Programmable Image Processing | |
JP6967570B2 (en) | Energy efficient processor core architecture for image processors | |
JP6858239B2 (en) | Compiler techniques for mapping program code to high-performance, power-efficient, programmable image processing hardware platforms | |
JP6793228B2 (en) | Sheet generator for image processor | |
JP6793162B2 (en) | Line buffer unit for image processor | |
JP6967597B2 (en) | An image processor with a configurable number of active cores and an internal network that supports it | |
JP6764904B2 (en) | 2D shift array for image processors | |
CN107533750B (en) | Virtual image processor, and method and system for processing image data thereon | |
JP7208920B2 (en) | Determination of memory allocation per line buffer unit | |
JP6775088B2 (en) | Program code variants to improve image processor runtime efficiency | |
TWI752343B (en) | Execution unit circuits, image processors, and methods for performing a sum of absolute difference computation | |
TWI694412B (en) | Configuration of application software on multi-core image processor | |
JP6750022B2 (en) | Macro I/O unit for image processor |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20191125 |
|
A621 | Written request for application examination |
Free format text: JAPANESE INTERMEDIATE CODE: A621Effective date: 20191125 |
|
A977 | Report on retrieval |
Free format text: JAPANESE INTERMEDIATE CODE: A971007Effective date: 20201216 |
|
A131 | Notification of reasons for refusal |
Free format text: JAPANESE INTERMEDIATE CODE: A131Effective date: 20210126 |
|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20210421 |
|
TRDD | Decision of grant or rejection written | ||
A01 | Written decision to grant a patent or to grant a registration (utility model) |
Free format text: JAPANESE INTERMEDIATE CODE: A01Effective date: 20210928 |
|
A61 | First payment of annual fees (during grant procedure) |
Free format text: JAPANESE INTERMEDIATE CODE: A61Effective date: 20211025 |
|
R150 | Certificate of patent or registration of utility model |
Ref document number: 6967597Country of ref document: JPFree format text: JAPANESE INTERMEDIATE CODE: R150 |