CN117280341A - In-situ sparse matrix expansion - Google Patents
In-situ sparse matrix expansion Download PDFInfo
- Publication number
- CN117280341A CN117280341A CN202280033990.1A CN202280033990A CN117280341A CN 117280341 A CN117280341 A CN 117280341A CN 202280033990 A CN202280033990 A CN 202280033990A CN 117280341 A CN117280341 A CN 117280341A
- Authority
- CN
- China
- Prior art keywords
- cell
- array
- matrix
- zero
- input value
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
- 239000011159 matrix material Substances 0.000 title claims abstract description 220
- 238000011065 in-situ storage Methods 0.000 title description 2
- 238000000034 method Methods 0.000 claims abstract description 52
- 230000004044 response Effects 0.000 claims description 7
- 238000004590 computer program Methods 0.000 abstract description 13
- 238000003860 storage Methods 0.000 abstract description 11
- 210000004027 cell Anatomy 0.000 description 224
- 238000004364 calculation method Methods 0.000 description 32
- 238000013528 artificial neural network Methods 0.000 description 18
- 230000004913 activation Effects 0.000 description 16
- 230000008569 process Effects 0.000 description 9
- 238000004891 communication Methods 0.000 description 7
- 230000009471 action Effects 0.000 description 6
- 230000009467 reduction Effects 0.000 description 5
- 238000003491 array Methods 0.000 description 3
- 230000008901 benefit Effects 0.000 description 3
- 238000002347 injection Methods 0.000 description 3
- 239000007924 injection Substances 0.000 description 3
- 230000003993 interaction Effects 0.000 description 3
- 238000007781 pre-processing Methods 0.000 description 3
- 210000004460 N cell Anatomy 0.000 description 2
- 230000006870 function Effects 0.000 description 2
- 230000003287 optical effect Effects 0.000 description 2
- 238000013515 script Methods 0.000 description 2
- 238000000926 separation method Methods 0.000 description 2
- 230000005540 biological transmission Effects 0.000 description 1
- 230000008878 coupling Effects 0.000 description 1
- 238000010168 coupling process Methods 0.000 description 1
- 238000005859 coupling reaction Methods 0.000 description 1
- 239000004973 liquid crystal related substance Substances 0.000 description 1
- 230000007246 mechanism Effects 0.000 description 1
- 230000000644 propagated effect Effects 0.000 description 1
- 239000004065 semiconductor Substances 0.000 description 1
- 230000001953 sensory effect Effects 0.000 description 1
- 239000000758 substrate Substances 0.000 description 1
- 230000000007 visual effect Effects 0.000 description 1
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F17/00—Digital computing or data processing equipment or methods, specially adapted for specific functions
- G06F17/10—Complex mathematical operations
- G06F17/16—Matrix or vector computation, e.g. matrix-matrix or matrix-vector multiplication, matrix factorization
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F5/00—Methods or arrangements for data conversion without changing the order or content of the data handled
- G06F5/06—Methods or arrangements for data conversion without changing the order or content of the data handled for changing the speed of data flow, i.e. speed regularising or timing, e.g. delay lines, FIFO buffers; over- or underrun control therefor
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F7/00—Methods or arrangements for processing data by operating upon the order or content of the data handled
- G06F7/38—Methods or arrangements for performing computations using exclusively denominational number representation, e.g. using binary, ternary, decimal representation
- G06F7/48—Methods or arrangements for performing computations using exclusively denominational number representation, e.g. using binary, ternary, decimal representation using non-contact-making devices, e.g. tube, solid state device; using unspecified devices
- G06F7/50—Adding; Subtracting
- G06F7/501—Half or full adders, i.e. basic adder cells for one denomination
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F7/00—Methods or arrangements for processing data by operating upon the order or content of the data handled
- G06F7/38—Methods or arrangements for performing computations using exclusively denominational number representation, e.g. using binary, ternary, decimal representation
- G06F7/48—Methods or arrangements for performing computations using exclusively denominational number representation, e.g. using binary, ternary, decimal representation using non-contact-making devices, e.g. tube, solid state device; using unspecified devices
- G06F7/52—Multiplying; Dividing
- G06F7/523—Multiplying only
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/06—Physical realisation, i.e. hardware implementation of neural networks, neurons or parts of neurons
- G06N3/063—Physical realisation, i.e. hardware implementation of neural networks, neurons or parts of neurons using electronic means
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
Abstract
Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for loading a matrix into a circuit having an array of mxn cells. One of these methods includes: receiving a plurality of non-zero input values from a first input matrix; receiving index metadata indicating, for each non-zero input value of a plurality of input values, into which cell of an mxn cell of the array the non-zero input value should be loaded; transmitting the non-zero input value and index metadata to the mxn cell; and at a particular cell of the mxn cells in the array: receiving a specific non-zero input value and corresponding index metadata; and determining whether to store the particular non-zero input value in the cell or shift the particular non-zero input value to another cell based on the corresponding index metadata for the particular non-zero input value.
Description
Cross Reference to Related Applications
The present application claims the benefit of priority from U.S. application Ser. No.17/368,374 filed on 7/6 of 2021, the entire contents of which are incorporated herein by reference.
Technical Field
Background
This specification relates generally to processing matrices using circuitry.
Disclosure of Invention
According to one innovative aspect of the subject matter described in this specification, a computing system can increase the throughput of loading an input matrix into a matrix multiplication unit by increasing the rate at which values from the input matrix are loaded into a cell array in the matrix multiplication unit. For example, the matrix processor may be part of a dedicated hardware circuit that trains the neural network, calculates the neural network inference, or both.
One way to increase throughput is to increase the rate at which matrices, particularly sparse matrices, are loaded into a cell array. A sparse matrix is a matrix with many elements having "null" values, i.e., zero values. For example, if more than half of the matrix's values are empty, the matrix may be considered sparse.
In general, one innovative aspect of the subject matter described in this specification can be embodied in methods that include actions performed by a hardware device that includes circuitry for an array having mxn cells, the actions including: receiving, at hardware circuitry, a plurality of non-zero input values from a first input matrix to be multiplied with a second input matrix using an array, the first input matrix comprising the plurality of non-zero input values and the plurality of zero input values; receiving, at hardware circuitry, index metadata indicating, for each non-zero input value of a plurality of input values, into which cell of an mxn cell in the array the non-zero input value should be loaded; transmitting the non-zero input values and index metadata to the mxn cells using hardware circuitry; and at a particular cell of the mxn cells in the array: receiving a particular non-zero input value and corresponding index metadata for the particular non-zero input value; and determining whether to store the particular non-zero input value in the cell for performing the multiplication or shift the particular non-zero input value to another cell according to corresponding index metadata of the particular non-zero input value, wherein M and N are positive integers greater than 1.
Implementations can include one or more of the following features. The method may further comprise: at a particular cell of the mxn cells in the array and prior to sending the non-zero input value and index metadata to the mxn cell: zero input values are automatically loaded into the cells. Transmitting the non-zero weight input values and index metadata to the mxn cells may include transmitting the non-zero weight input values along a first dimension of an array having mxn cells. The first dimension of the array may include a vertical dimension of the array; and transmitting the non-zero weight input and index metadata to the mxn cell along the first dimension of the array may include transmitting the non-zero weight input and index metadata starting from a top edge of the array. The first dimension of the array may include a horizontal dimension of the array; and transmitting the non-zero weight input and index metadata to the mxn cell along the first dimension of the array may include transmitting the non-zero weight input and index metadata starting from a left edge of the array. The index metadata may include an absolute fixed length row index for each non-zero input value. The index metadata may include a run-length encoded row index for each non-zero input value. The index metadata may include a bitmap of locations of non-zero input values in M x N cells of the array. The hardware device may further include a comparator for each of the mxn cells of the array, the comparator configured to compare (i) index metadata for each non-zero input value with (ii) an index for the cell, the index indicating a location of the cell in the mxn cell along a first dimension of the array. The plurality of input values may be in a Compressed Sparse Column (CSC) matrix format. The hardware device may further include a first-in first-out (FIFO) register for each of the mxn cells of the array, and wherein loading the respective non-zero input value into the cell may include queuing the respective non-zero input value into the FIFO register associated with the cell. The method may further include, for each cell in the array storing a particular non-zero input value: receiving, using hardware circuitry, a second input value from the second input matrix; and determining a corresponding multiplication product using hardware circuitry based on the particular non-zero input value and the second input value. The non-zero input value may be shifted by one cell per clock cycle. The method may further comprise: determining that the first input matrix includes columns having only zero input values; and in response, adding sign bits for each zero input value to the index defined by the corresponding index metadata.
Other implementations of this and other aspects include corresponding systems, apparatuses, and computer programs configured to perform the actions of the methods and encoded on computer storage devices. The system of one or more computers may be configured by software, firmware, hardware or a combination thereof installed on the system such that, in operation, the system performs these actions. The one or more computer programs may be configured with instructions that, when executed by the data processing apparatus, cause the apparatus to perform the actions.
Particular embodiments of the subject matter described in this specification can be implemented to realize one or more of the following advantages. The present specification describes a matrix multiplication unit that can load an input matrix to be multiplied with another matrix (or vector) in significantly fewer clock cycles than conventional matrix multiplication units. In particular, a matrix multiplication unit with a comparator for each cell of the array may load only non-zero input values (i.e. elements from the input matrix having non-zero values) instead of all obtained input values including zero input values into the respective cell of the array. The dedicated hardware circuit may then effectively load the input values into the array of matrix multiplication units by expanding the matrix inside the matrix multiplication units (e.g. not outside the matrix multiplication units and in a separate processing unit, or at the boundaries of the matrix multiplication units), thereby enabling the hardware circuit to perform matrix operations more effectively. This may save time required to load input values to the matrix multiplication unit, for example in terms of the total number of clock cycles required to load input values to respective cells of the array by coupling external memory units to the input value loading lines of each cell. This may also allow for better utilization of memory capacity, bandwidth, or hardware circuitry, thereby further improving performance.
The details of one or more embodiments of the subject matter in this specification are set forth in the accompanying drawings and the description below. Other features, aspects, and advantages of the subject matter will become apparent from the detailed description, the drawings, and the claims.
Drawings
Fig. 1 shows an exemplary architecture including a matrix computing unit.
Fig. 2 shows an exemplary architecture of cells within a two-dimensional array of matrix computing units.
Fig. 3 shows an exemplary illustration of different index metadata.
Fig. 4 is a flowchart illustrating an example of a process for loading a matrix into a matrix calculation unit.
Fig. 5 shows an exemplary illustration of preprocessing a matrix to be loaded into a matrix calculation unit.
Fig. 6A to 6B show an exemplary illustration of loading a matrix into a matrix calculation unit.
Like reference numbers and designations in the various drawings indicate like elements.
Detailed Description
In general, data may be represented in the form of a matrix, and a computing system may manipulate the data by performing matrix operations. The matrix may be a one-dimensional vector or a multi-dimensional matrix. The matrix may be represented by a data structure such as a database table or variable. A sparse matrix is a matrix with many elements having "null" values, i.e., zero values. For example, if more than half of the matrix's values are empty, the matrix may be considered sparse.
Fig. 1 shows an exemplary architecture 100 including a matrix computing unit. The matrix computing unit is a two-dimensional array 106. The array 106 includes a plurality of cells, for example, cells 114, 116, and 118. In some implementations, the first dimension of the array 106 is a vertical dimension corresponding to a row of cells, and the second dimension of the array 106 is a horizontal dimension corresponding to a column of cells. The array 106 may have more rows than columns, more columns than rows, or an equal number of columns and rows.
In some implementations, the matrix computing unit may, for example, include additional circuitry within each cell of the two-dimensional array of cells 106, each configured to process data.
As one example, the matrix computing unit may be part of a dedicated hardware circuit that trains the neural network, computes the neural network inference, or both, and the matrix computing unit may be a matrix multiplying unit that performs a matrix multiplication operation between two matrices. That is, by using multiplication and summation circuitry within cells of array 106, and by working with additional components of hardware circuitry, which may include, for example, scalar processing units and vector processing units, and associated scalar memory and vector memory, matrix computing units may be used to perform mathematical operations, such as multiplication and addition, in a neural network.
As another example, the matrix computing unit may be a cross-channel unit configured to move data between different channels of the plurality of channels. As used herein, a channel generally corresponds to an area, section, or portion of an exemplary hardware circuit that may include computing/data processing resources of the hardware circuit. For example, the cross-channel unit may be a transpose unit, a reduction unit, or a permutation unit. The transpose unit may perform a transpose operation of the matrix. That is, the transpose unit can receive numbers in one dimension (e.g., along a given row) and transpose them such that the numbers across the channels are transposed with the numbers in another dimension (e.g., along a given column). The reduction or permutation unit may solve the problem of cross-channel communication by supporting various operations such as permutation, channel rotation, rotation permutation, channel reduction, permutation channel reduction, and segment permutation channel reduction.
As another example, the matrix calculation unit may be an arithmetic unit that performs operations such as square root, logarithm, and reciprocal by a table-driven function approximation. For example, the arithmetic unit may perform a multi-entry, multi-port table lookup, e.g., 128-entry, 128-port table lookup, per clock cycle. Further, in this example, the arithmetic unit may bridge a larger table by using zero thermal encoding, and may bridge more ports by replaying the input values loaded into the arithmetic unit. Zero-hot encoding is an extension to one-hot encoding, where the initial state vector is zero, for example: [ 0] 0; 0.1; 0.1; 1 0 0].
As yet another example, the matrix calculation unit may be a tensor unit that may compress or inject the padding data into the tensor, thereby providing additional memory savings while still supporting efficient matrix calculation. Tensors are typically multidimensional arrays of index values or other values, such as strings, having a particular order corresponding to the dimensions of the array. For example, the scalar value is a 0 th order tensor, the numeric vector is a 1 st order tensor, and the matrix is a 2 nd order tensor.
More details regarding the functionality of these exemplary hardware components, such as scalar or vector processing units and extended vector units, can be found in U.S. patent No.10,621,269B2 entitled "PERFORMING MATRIX MULTIPLICATION IN HARDWARE (performing matrix multiplication in hardware)", filed on 5.17.2018 and granted 14.2020, which is incorporated herein by reference.
Typically, at least a portion of the matrix needs to be preloaded into the matrix calculation unit before starting a series of matrix operations such as matrix-matrix multiplication or vector-matrix multiplication. In the above example, the matrix calculation unit may increase the throughput of the hardware circuit by increasing the rate at which input values are loaded into the matrix calculation unit, thereby enabling the hardware circuit to more efficiently perform matrix calculations, such as calculations for processing neural networks.
Loading the matrix into the matrix calculation unit typically involves shifting input values from the matrix in one dimension, e.g., left to right, or top to bottom, throughout the array 106, e.g., according to host interface control signals. For example, within one clock cycle, the input value at cell 114 may be shifted to a register at cell 116 to the right of cell 114. Similarly, the input value at cell 114 may be shifted to a register at cell 118 below cell 114.
As shown, each cell of the two-dimensional array of cells 106 is associated with a comparator unit, such as comparator unit 115, 117, or 119. Each cell may be connected to an associated comparator unit, for example using wires. The comparator unit comprises hardware circuitry for comparing two input numbers, e.g. digits or binary numbers, to determine whether one input number is equal to, smaller than or larger than the other input number. For example, the comparator unit (e.g., comparator unit 115) may be a multi-bit binary comparator configured to determine equality between two multi-bit binary numbers, e.g., four-bit, seven-bit, or eight-bit binary numbers. As will be described further below, the matrix calculation unit utilizes comparator units to improve the efficiency of loading data into the cell array 106, for example, before matrix operations begin.
In some implementations, the register at each cell of the two-dimensional array of cells 106 may be a first-in-first-out (FIFO) register, and loading the respective non-zero input value into the cell includes queuing the respective non-zero input value into the FIFO register associated with the cell. Similarly, offloading the respective non-zero input values from the cells includes dequeuing the respective non-zero input values from FIFO registers associated with the cells.
In some implementations, each cell of the two-dimensional array of cells 106 may include a plurality of registers, each register operable to store a different input value, such as a weight input or an activation input value. The registers in the same cell may be of the same type, e.g. FIFO registers, or may be of different types.
The matrix may be transferred to the matrix calculation unit by a bus connected to the matrix calculation unit through a source bus and then loaded into registers so that matrix operations may begin. For example, the matrix may be transferred from a memory unit or memory buffer of the system, which may be located outside the circuit.
In some implementations, the matrix is received in a compressed format, such as a Compressed Sparse Row (CSR) format or a Compressed Sparse Column (CSC) format, which typically uses a linear (i.e., one-dimensional) array to store information about the matrix. When represented in such a compressed format, the data describing the matrix typically includes associated index metadata that indicates, for each non-zero element (or entry) within the matrix (hereinafter referred to as a "non-zero input value"), the corresponding location of the non-zero input value in the original matrix. The index metadata further indicates into which cell of the two-dimensional array of cells the non-zero input value should be loaded.
Let a be an mxn matrix with e non-zero input values. Let Av, ac and Ar be three one-dimensional arrays of lengths e, e and (m+1), respectively. In CSR format, A is encoded as < Av, ac, ar >, wherein:
the value array Av holds the values of all non-zero input values in a in line order,
the array of values Ac holds columns of all non-zero input values in a in row order,
the row index array Ar holds an index of the first non-zero input value of each row in A in Av, where the last element in the Ar array is the total number of elements in the Av array.
For example, the following 4×4 matrix
May be encoded in CSR format as < av= [1,0.5,0.5,0.5,0.5,1], ac= [3,0,3,0,1,2], ar= [0,1,3,5,6] >.
In this and other examples described below, rows and columns are indexed, where the index starts at zero, increasing for columns from left to right and rows from top to bottom of the matrix. Thus, the matrix a above has an index of rows and columns from 0 to 3.
The matrix may also be encoded in a Compressed Sparse Column (CSC) format, which is commonly referred to as the CSR "transpose". Let a be an mxn sparse matrix with e non-zero input values. Let A ' v, A ' c and A ' r be three one-dimensional arrays of lengths e, e and (n+1), respectively. In CSC format, a is encoded as < a ' v, a ' r, a ' c >, wherein:
The value array a' v holds the values of all non-zero input values in a in column order,
the row array a' r holds the rows of all non-zero input values in a in column order,
the column index array A 'c holds an index of the first non-zero input value of each column in A' v, where the last element in the A 'c array is the total number of elements in the A' v array.
The same 4 x 4 matrix as previously shown
Can be encoded in CSC format as: < a ' v= [0.5,0.5,0.5,1,1,0.5], a ' r= [1,2,2,3,0,1], a ' c= [0,2,3,4,6 >.
Thus, the row and column index information contained in the CSR or CSC representation of the matrix corresponds to the associated metadata of the matrix that indicates, for each non-zero input value of the plurality of input values, into which cell of the two-dimensional array of cells the non-zero input value should be loaded.
Index metadata associated with a matrix may be pre-generated and received by the system along with the matrix or generated instantaneously from the received matrix by different components of the system (e.g., metadata generation units). Similarly, index metadata may be transferred from a memory unit or memory buffer to a matrix computation unit through additional buses (or wires) and may be shifted along one dimension along the entire array 106, e.g., left to right, or top to bottom, along with input values from the matrix. For example, within one clock cycle, index metadata describing the input value at cell 114 may be shifted to comparator unit 117 associated with cell 116 (to the right of cell 114). Similarly, index metadata describing the input value at cell 114 may be shifted to comparator unit 119 associated with cell 118 (below cell 114). Exemplary index metadata and loading of a matrix into a matrix calculation unit by using the index metadata will be further described below.
In the example shown in fig. 1, the matrix calculation unit is a matrix multiplication unit, wherein the input value extractor interface 108 sends the input values of the first input matrix and the associated index metadata of the first input matrix to the columns of the array 106, and the value loader 112 sends the input values of the second input matrix and the associated index metadata of the second input matrix to the rows of the array 106. However, in some other implementations, the input values of the first input matrix are transmitted to the rows of the array 106 and the input values of the second input matrix are transmitted to the columns of the array 106.
For example, the input values of the first input matrix may correspond to weight input values and the input values of the second input matrix may correspond to input activation values, wherein the weight input values and the input activation values are associated with layers in the multi-layer neural network that may be used to calculate the inference.
For example, given an input, the neural network may calculate an inference of the input. The neural network computes this inference by processing the input of each layer of the neural network. In particular, the layers of the neural network are arranged in a sequence, each layer having a respective set of weights. Each layer receives an input and processes the input according to the set of weights for that layer to produce an output. Thus, to calculate an inference from a received input, the neural network receives the input and processes it through each neural network layer in the sequence to produce an inference, with the output from one neural network layer being provided as input to the next neural network layer. The data input to a neural network layer, such as an input to a neural network or an output from a layer below the layer in a sequence to a neural network layer, may be referred to as an activation input to the layer.
The input value extractor interface 108 of fig. 1 may receive input values and associated index metadata from a memory unit, such as a dynamic memory. The input value extractor interface 108 may send the corresponding input values to different topmost cells of the array 106, for example, by using data lines. The input value extractor interface 108 may send the associated input values to different topmost cells of the array 106, for example, by using additional data lines or reusing the same data line. The topmost cell may be a cell along the topmost row of the array 106. For example, the input value extractor interface 208 may send input values to the cells 114 and 116.
The value loader 112 of fig. 1 may receive input values and associated index metadata from a store buffer, such as a unified buffer. Each value loader 112 may send a corresponding input value to a different leftmost cell of the array 106. The leftmost cell may be a cell along the leftmost column of the array 106. For example, the value loader 112 corresponding to the cell 114 may send an input value to the cell 114.
However, when the size of the matrix is too large, the amount of time it takes to inject the entire matrix (i.e., all input values of the matrix) into the matrix calculation unit may be long. Thus, in order to efficiently inject a matrix into the matrix computing unit, i.e. reduce the number of cycles that the injection port at the top of the matrix computing unit operates to inject the matrix, the matrix computing unit utilizes a comparator unit to determine, for example, at a particular cell of the two-dimensional cell array 106 of the matrix computing unit, whether the index metadata associated with the input value shifted to the particular cell matches the positioning index of the particular cell in the two-dimensional array. In response to a positive determination, the matrix calculation unit then stores the input values at registers of the particular cells for later use in performing matrix operations. Alternatively, in response to a negative determination, the system shifts the input value instead of storing to an adjacent cell of the particular cell.
In this way the number of clock cycles required to inject the entire matrix is reduced from approximately the dimension of the (square) matrix to approximately the number of non-zero values in the columns (or rows) of the matrix with the most non-zero values. When the matrix is a sparse matrix, the number of clock cycles required may be reduced by an order of magnitude or more. This may also make it easier to inject dense matrices, i.e. matrices with more non-zero input values than zero input values. To use the same mechanism to inject a dense matrix, a counter may be placed at the top edge to add an index to each input value that passes through the top edge.
Fig. 2 illustrates an exemplary architecture 200 of cells within a two-dimensional array of matrix computing units. In the example of fig. 2, the matrix calculation unit is depicted as a matrix multiplication unit having a two-dimensional array wired to perform a matrix multiplication operation, e.g., multiplying a 128 element vector by a 128 x 128 matrix.
The cell may include an activation register 206 that stores an activation input. Depending on the location of the cell within the array, the activation register may receive an activation input from a left adjacent cell (i.e., an adjacent cell to the left of a given cell) or from a memory buffer. The cell may include two weight path registers 212A-B, each of which may receive a weight input and transmit the weight input to the weight register 202. The weight register 202 may then store the weight input based on the control signal. For example, the weight input may be shifted from the top adjacent cell or from the weight extractor interface to the weight path register, depending on the cell's position within the array. The cell may also include a summing register 204. The summing register 204 may store the accumulated value from the top adjacent cell. The weight register 202, the summation register 204, the activation register 206, and the weight path registers 212A-B may be registers configured to store a particular size of value, such as a floating point value in a particular format.
Multiplication circuitry 208 may be used to multiply the weight input from weight register 202 with the activation input from activation register 206. Multiplication circuitry 208 may output the product to summation circuitry 210. In some implementations, the input and output values of the multiplication circuitry 208 may have different sizes and/or formats.
Summing circuitry 210 may sum the product and the accumulated value from summing register 204 to produce a new accumulated value. Summing circuitry 210 may then send the new accumulated value to another summing register located in the bottom adjacent cell. The new accumulated value may be used as an operand for the summation in the bottom neighbor cell. Summing circuitry 210 may also accept the value from summing register 204 and send the value from summing register 204 to the bottom neighbor cell without summing the value from summing register 204 with the product from multiplication circuitry 208. In some implementations, the input values of summing circuitry 210 may have different sizes and/or formats. In some implementations, some of the input and output values of summing circuitry 210 may have different sizes and/or formats.
The cells may also shift the weight input and the activation input to neighboring cells for processing. For example, the weight path register 212B may send the weight input to another weight register in the bottom neighbor cell. The activation register 206 may send the activation input to another activation register in the right adjacent cell. Thus, in subsequent clock cycles, both the weight input and the activation input may be reused by other cells in the array.
Notably, the cell also includes a comparator unit 214. The comparator unit may determine the equality between the two input values. For example, the comparator unit 214 may compare the index 216 defined by the index metadata associated with the weight input transmitted from the weight path register 212A with the positioning index of the cells in the two-dimensional array. As another example, the comparator unit 214 may compare the index 218 defined by the index metadata associated with the weight input transmitted from the weight path register 212B with the positioning index of the cells in the two-dimensional array. The comparator unit may send a control signal to the weight register 202 based on the result of the comparison, for example by using a wire. In particular, the control signals generated by the comparator unit 214 may adjust the disposition of the weights input by the cells, i.e., whether the adjusting cells should store the weight inputs at the weight register 202 for operation by the multiplication circuitry 208 (in the case of equality) or shift the weight inputs to neighboring cells every clock cycle (in the case of inequality).
Index metadata may generally be created and maintained in any of a variety of ways. Several examples of index metadata are described next.
Fig. 3 shows an exemplary illustration of different index metadata.
The original matrix in the example of fig. 3 has a plurality of non-zero input values and a plurality of zero input values. Each of the plurality of non-zero input values and the plurality of zero input values reside at a different location in the original matrix, as shown at 302 and 304, respectively.
In one example, the index metadata may include a bitmap index, as shown at 306. For example, the index metadata may include a bitmap referencing respective locations of non-zero input values of the original matrix.
In another example, the index metadata may include an absolute fixed length row index, as shown at 308. For example, for each non-zero input value of the matrix, the absolute fixed length index may be a column or row index of absolute fixed length, i.e. a reference original matrix.
In another example, as shown at 310, the index metadata may include a run-length coded index (run-length encoded index). For example, for each non-zero input value of the matrix, the run-length encoded index may be a run-length encoded column or row index, i.e. a reference original matrix. Run-length encoding is a technique that allows index metadata to be stored using variable length data fields and thus provides more storage savings.
In these examples, the index metadata generally indicates or otherwise specifies into which cell of the two-dimensional array of cells each non-zero input value should be loaded. In addition, the index metadata may further indicate whether the input values included in the matrix are non-zero values. For example, the index metadata may include additional sign bits that are pre-added to the original unsigned index for each zero input value, such that zero input values are not loaded into the array because the negative index does not match the locating index of any cell within the array.
By loading the matrix into a two-dimensional array of matrix calculation units while utilizing a comparator unit to determine whether there is a match between the index metadata associated with each non-zero input value of the matrix and the positioning index of a particular cell in the two-dimensional array, the matrix calculation units may reduce the amount of time spent loading because the entire matrix including any zero input values no longer needs to be loaded into the matrix calculation units. Instead, only a relatively small set of non-zero input values in the matrix need be loaded. This matrix loading process will be described in more detail below.
Fig. 4 is a flowchart 400 illustrating an example of a process for loading a matrix into a matrix calculation unit. For convenience, the method 400 will be described with reference to a system having one or more circuits. For example, referring to fig. 1, the system may include a matrix computing unit configured as a two-dimensional array comprising a plurality of cells physically or logically arranged in M rows and N columns, where M and N are positive integers greater than 1.
The system receives a plurality of non-zero input values at hardware circuitry from a first input matrix to be multiplied with a second input matrix using an array (402). The first input matrix may be a matrix comprising a plurality of non-zero input values and a plurality of zero input values. The second input matrix may similarly include a plurality of non-zero input values and a plurality of zero input values, and may have the same or different dimensions as the first matrix.
The system receives index metadata at hardware circuitry indicating, for each non-zero input value of a plurality of input values, into which cell of an mxn cell of the array the non-zero input value should be loaded (404). Index metadata may be represented in the form of an absolute fixed length line index, a run length coded line index, or a bitmap index, to name a few examples. In other words, the system may receive an absolute fixed length row index, a run length coded row index, or a bitmap index, each of which specifies positioning information for non-zero input values referencing the original matrix. In some implementations, the system may receive index metadata and a first input matrix, for example, from a memory unit or a memory buffer of the system. For example, the first input matrix may be received in a Compressed Sparse Row (CSR) format or a Compressed Sparse Column (CSC) format, wherein row and column index information of non-zero input values in the first input matrix corresponds to associated index metadata.
In other implementations, the system may generate index metadata from the received first input matrix on-the-fly. That is, the system preprocesses the first input matrix, for example, by using a metadata generation unit of the system, before loading the first input matrix into a matrix calculation unit and using it to perform mathematical operations such as multiplication and addition.
Fig. 5 shows an exemplary illustration of preprocessing a matrix to be loaded into a matrix calculation unit.
As shown, the first matrix is a 6 x 6 matrix 510. Matrix 510 has a plurality of non-zero input values, such as input value 522, and a plurality of zero input values, such as input value 526.
Preprocessing the matrix involves first deleting all zero input values, e.g., input value 522, from the input matrix 510, and then compressing the remaining input values, e.g., input value 522, of the input matrix 510 along one dimension, e.g., the vertical dimension. To compress along the vertical dimension, the system may assign a corresponding row index tag to each non-zero input value, and then compress the non-zero input values along the vertical dimension, i.e., at each column. For example, in the first (leftmost) column, the system may assign a "0" tag 532 to the input value 522 and a "3" tag 542 to the input value 532, indicating that the input values 522 and 532 are located in the first (topmost) and fourth rows of the matrix, respectively, and then compress the tag data into the list of the first column. In this way, the system obtains a representation of the original matrix 510 in a Compressed Sparse Column (CSC) format, as shown in the exemplary illustration 550.
The system sends the non-zero input values and index metadata to an array of mxn cells using hardware circuitry (406).
Typically, the system sends non-zero input values and index metadata along one dimension of the array, e.g., left to right, or top to bottom. For example, when loading a matrix that represents an encoding with CSCs, the system may send corresponding input values to different topmost cells of the array, i.e., cells along the topmost row of the array. As another example, when loading a matrix encoded in CSR representation, the system may send the corresponding input values to different leftmost cells of the array, i.e., cells along the leftmost column of the array.
Fig. 6A-B show an exemplary illustration of loading a matrix into a matrix computing unit having a 6 x 6 cell array. As described above with reference to fig. 5, the non-zero input values of the matrix and associated row index metadata may be sent to cells at different columns of the array before matrix operations begin. Furthermore, the injection of non-zero input values within each column may be independent of the other columns. That is, in the case of sending input values down a column to a cell, there is no need for cross-column communication. Thus, the injection of input values across different columns need not start at the same time—they may be staggered in the order in which the input values reach the top edge of the matrix computation unit, thereby facilitating flexible timing, such as systolic array timing.
For example, at 610, the system sends data comprising a first set of two non-zero input values and their associated row indices "0" and "3" to a first column of the array. The system sends data comprising a second set of two non-zero input values and their associated row indices "1" and "4" to a second column of the array. The system sends data containing a third set including a single non-zero input value and its associated row index "4" to a third column of the array. The system does not send data to the fourth column of the array. The system sends data comprising a fifth set and a sixth set each comprising a single non-zero input value and its associated row index "2" to the fifth and sixth columns of the array, respectively. After each clock cycle, the non-zero input value and its associated row index metadata may be shifted by one cell in one dimension, e.g., top-to-bottom. Although a system has been described in which input values are sent to columns of an array, in some implementations, input values are sent to rows of an array.
Then, at each of some or all of the mxn cells (hereinafter "particular cells") in the array, the system utilizes a comparator unit associated with the particular cell to determine whether the particular non-zero input value should be stored at the particular cell or shifted to a neighboring cell of the particular cell. In some implementations, the system may do so at each of all mxn cells in the array. However, in other implementations, the system can only do so in some mxn cells in the array, e.g., in each of all but the bottommost cells in the array, provided that any input values that have not reached their destination will be loaded into the cells along the bottommost row.
In more detail, the system receives a particular non-zero input value and corresponding index metadata for the particular non-zero input value at a particular cell of the mxn cells in the array (408).
As described above, a particular cell may include a register, such as a FIFO register, that stores input values. Depending on the location of the cell within the array, the register may receive an input value from a top adjacent cell or from an input value extractor interface. Alternatively, the register may receive input values from a left adjacent cell, i.e. the adjacent cell to the left of a given cell, or from a value loader, again depending on the location of the cell within the array.
At a particular cell of the mxn cells in the array and according to the corresponding index metadata for the particular non-zero input value, the system determines whether to store the particular non-zero input value at that cell for performing the multiplication or shift the particular non-zero input value to another cell (410).
For example, in a first clock cycle ("clock cycle 0") 620, the array has a "3" inside the upper left corner cell. "3" represents a non-zero input value stored in a cell marked with a row index of "3". The array also has non-zero input values labeled "4", "2" and "2", which are stored in the second, third, fifth and sixth cells, respectively, of the first row (top-most) of the array. Based on the corresponding index metadata associated with the non-zero input values, the system determines that none of the non-zero input values has reached its destination cell. For example, in the upper left cell, the system compares the row index "3" associated with the non-zero input value with the row index "0" of the upper left cell using the comparator of that cell and determines that the indices are not equal to each other.
At the next clock cycle ("clock cycle 1") 630, the non-zero input values labeled with row indices "3", "4", "2", and "2" are shifted down to the corresponding cells below the cells in the first row, and another non-zero input value labeled with index "0" from the matrix is loaded into the upper left corner cell, and the non-zero input value labeled with index "1" from the matrix is loaded into the topmost cell of the second column.
At the top left cell 632, the system determines that the non-zero input value marked with a row index of "0" has reached the destination cell, i.e., after comparing the row index, i.e., indicating a "0" for the first row, with the location index of the top left cell 632, indicating that the cell 632 is in the first row of the array, using a comparator unit at cell 632 and determining that there is a match.
At a third clock cycle ("clock cycle 2") 640, the remaining non-zero input values that have not been in place are shifted again. For each of the remaining non-zero input values that have not been in place, the associated metadata indicating to which cell in the array the non-zero input value should be loaded is also shifted along with the non-zero input value. In the first column, the non-zero input value marked with a row index of "3" is shifted down from its position stored in the previous cycle to the third cell, while the non-zero input value marked with a row index of "0" remains in its position stored in the previous cycle. In the second column, the non-zero input values marked with row indices "1" and "4" are shifted down by one cell from their positions stored in the previous cycle, respectively. Similarly, in the third, fifth and sixth columns, the non-zero input values marked with row indices "4", "2" and "2" are shifted down to the cells along the third row, respectively.
At cell 642, the system determines that the non-zero input value marked with a row index of "1" has reached the destination cell, i.e., after comparing the corresponding row index, i.e., "1" indicating the second row, with the location index of cell 642, indicating that cell 642 is in the second row of the array, using a comparator unit at the cell and determining that there is a match. Similarly, at cells 644 and 646, the system determines that the input value marked with a row index of "2" has reached the destination cell, respectively.
In a fourth clock cycle ("clock cycle 3") 650, the non-zero input values that have not been in place are shifted again. In the first column, the non-zero input value marked with a row index of "3" is shifted down again from its position stored in the previous cycle to the fourth cell. In the second column, the non-zero input value marked with a row index of "4" is shifted down from its position stored in the previous cycle to the fourth cell, while the non-zero input value marked with a row index of "1" remains in its position stored in the previous cycle. In the third column, the non-zero input value marked with a row index of "4" is shifted down one cell to the fourth cell. In the fifth and sixth columns, the non-zero input values marked with a row index of "2" remain in their stored positions in the previous cycle.
At cell 652, the system determines that the input value marked with a row index of "3" has reached the destination cell, i.e., after comparing the corresponding row index, i.e., "3" indicating the fourth row, with the location index of cell 652, indicating that cell 652 is in the fourth row of the array, using a comparator unit at the cell, and determining that there is a match.
At a fifth clock cycle ("clock cycle 4") 660, the non-zero input values that have not been in place are shifted again. In the second and third columns, the input values marked with a row index of "4" are shifted down again by one cell from their position stored in the previous cycle.
At cells 662 and 664, the system determines that the input value marked with a row index of "4" has reached its destination cell, i.e., after comparing the corresponding row index, i.e., "4" indicating the fifth row, with the positioning index of cell 662, indicating that cell 662 is in the fifth row of the array, using a comparator unit at cell 662 and determining that there is a match.
In particular, after five clock cycles, and as shown in the exemplary illustration 660 of fig. 6B, all non-zero input values from the matrix have now reached their destination cells within the exemplary 6 x 6 cell array.
In some implementations, each cell within the array may be initialized to have a default value of zero (or null) before the first input matrix is loaded into the array. Once the non-zero input value is in place, i.e., when the array begins to operate on the first input matrix, each cell that does not have a non-zero input value may operate as if the zero input value had been loaded to it, e.g., based on a control signal stored in the cell that specifies that the index associated with any non-zero input value does not explicitly match its positioning index.
In some implementations, during or after loading the first input matrix into the matrix computing unit, the system may load the second input matrix into the matrix computing unit in a similar or different manner. At a particular cell of the matrix calculation unit, once it is determined, e.g., via control signals, that both the first input value and the second input value from the first input matrix and the second input matrix are in place, the system may perform the calculation using the first input value and the second input value stored within the cell, e.g., by using multiplication or addition circuitry within the cell. When performing the calculation, the system may use only non-zero input values from the first input matrix.
Although the examples of fig. 6A-6B depict loading the same matrix into the matrix calculation unit over multiple consecutive clock cycles, this is not required. In case a sequence of multiple independent matrices (i.e. independent matrices encoded in CSR or CSC format) is loaded to the matrix calculation unit, a different matrix may be used at each clock cycle. A single-hot matrix refers to a matrix in which each column (or row) has one and only one non-zero input value, e.g., 1, while the other input values are zero. This not only expands the flexibility of the matrix calculation unit, e.g. when configured as a matrix multiplication unit, but also enables permutation and table lookup functionality, e.g. when configured as a permutation unit or an arithmetic unit.
Embodiments of the subject matter and the functional operations described in this specification can be implemented in digital electronic circuitry, in tangibly embodied computer software or firmware, in computer hardware including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them. Embodiments of the subject matter described in this specification can be implemented as one or more computer programs, i.e., one or more modules of computer program instructions, encoded on a tangible, non-transitory storage medium for execution by, or to control the operation of, data processing apparatus. The computer storage medium may be a machine-readable storage device, a machine-readable storage substrate, a random or serial access memory device, or a combination of one or more of the foregoing. Alternatively or additionally, the program instructions may be encoded on an artificially-generated propagated signal, e.g., a machine-generated electrical, optical, or electromagnetic signal, that is generated to encode information for transmission to suitable receiver apparatus for execution by data processing apparatus.
The term "data processing apparatus" refers to data processing hardware and includes all kinds of apparatus, devices, and machines for processing data, including by way of example a programmable processor, a computer, or multiple processors or computers. The apparatus may also be or further comprise dedicated logic circuitry, such as an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit). In addition to hardware, the apparatus may optionally include code that creates an execution environment for the computer program, such as code that constitutes processor firmware, a protocol stack, a database management system, an operating system, or a combination of one or more of them.
A computer program, which may also be referred to or described as a program, software application, module, software module, script, or code, can be written in any form of programming language, including compiled or interpreted languages, or declarative or procedural languages; and it may be deployed in any form, including as a stand-alone program or as a module, component, subroutine, or other unit suitable for use in a computing environment. A program may, but need not, correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data, e.g., one or more scripts stored in a markup language document, in a single file dedicated to the program in question, or in multiple coordinated files, e.g., files that store portions of one or more modules, sub-programs, or code. A computer program can be deployed to be executed on one computer or on multiple computers at one site or distributed across multiple sites and interconnected by a data communication network.
The processes and logic flows described in this specification can be performed by one or more programmable computers executing one or more computer programs to perform functions by operating on input data and generating output. The processes and logic flows can also be performed by, or in combination with, special purpose logic circuitry, e.g., an FPGA or ASIC.
A computer adapted to execute a computer program may be based on a general purpose or special purpose microprocessor or both, or any other kind of central processing unit. Typically, the central processing unit will receive instructions and data from a read only memory or a random access memory or both. The essential elements of a computer are a central processing unit for executing or carrying out the instructions and one or more memory devices for storing instructions and data. The central processing unit and the memory may be supplemented by, or incorporated in, special purpose logic circuitry. Typically, a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks. However, the computer need not have such a device. In addition, the computer may be embedded in another device, such as a mobile phone, a Personal Digital Assistant (PDA), a mobile audio or video player, a game console, a Global Positioning System (GPS) receiver, or a portable storage device, such as a Universal Serial Bus (USB) flash drive, etc.
Computer readable media suitable for storing computer program instructions and data include all forms of non-volatile memory, media and memory devices, including by way of example: semiconductor memory devices such as EPROM, EEPROM, and flash memory devices; magnetic disks, such as internal hard disks or removable disks; magneto-optical disk; CD-ROM and DVD-ROM discs.
To provide for interaction with a user, embodiments of the subject matter described in this specification can be implemented on a computer having a display device, e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor, for displaying information to the user and a keyboard and a pointing device, e.g., a mouse or a trackball, by which the user can provide input to the computer. Other kinds of devices may also be used to provide for interaction with a user; for example, feedback provided to the user may be any form of sensory feedback, e.g., visual feedback, auditory feedback, or tactile feedback; and input from the user may be received in any form including acoustic, speech, or tactile input. Further, a computer may interact with a user by sending and receiving documents to and from devices used by the user; for example, by sending a web page to a web browser on the user device in response to a request received from the web browser. In addition, the computer may interact with the user by sending text messages or other forms of messages to a personal device, such as a smart phone running a messaging application, and receiving response messages from the user back.
Embodiments of the subject matter described in this specification can be implemented in a computing system that includes a back-end component, e.g., as a data server, or that includes a middleware component, e.g., an application server, or that includes a front-end component, e.g., a client computer having a graphical user interface, a web browser, or an application through which a user can interact with an implementation of the subject matter described in this specification, or any combination of one or more such back-end, middleware, or front-end components. The components of the system can be interconnected by any form or medium of digital data communication, e.g., a communication network. Examples of communication networks include Local Area Networks (LANs) and Wide Area Networks (WANs), such as the internet.
The computing system may include clients and servers. The client and server are typically remote from each other and typically interact through a communication network. The relationship between client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other. In some embodiments, the server transmits data, e.g., HTML pages, to the user device, e.g., in order to display the data to the user and receive user input from the user, the user interacting with the device acting as a client. Data generated at the user device (e.g., results of user interactions) may be received at the server from the device.
Embodiment 1 is a method performed by a hardware device including circuitry for an array having mxn cells, the method comprising:
receiving, at hardware circuitry, a plurality of non-zero input values from a first input matrix to be multiplied with a second input matrix using an array, the first input matrix comprising the plurality of non-zero input values and a plurality of zero input values;
receiving, at hardware circuitry, index metadata indicating, for each non-zero input value of a plurality of input values, into which cell of an mxn cell of an array the non-zero input value should be loaded;
transmitting the non-zero input values and index metadata to the mxn cells using hardware circuitry; and
at a particular cell of the mxn cells in the array:
receiving a specific non-zero input value and corresponding index metadata of the specific non-zero input value;
and
Based on the corresponding index metadata for the particular non-zero input value, a determination is made as to whether to store the particular non-zero input value at a cell for performing the multiplication or to shift the particular non-zero input value to another cell,
wherein M and N are positive integers greater than 1.
Embodiment 2 is the method of embodiment 1, further comprising, at a particular cell of the mxn cells in the array and prior to transmitting the non-zero input value and the index metadata to the mxn cell: zero input values are automatically loaded into the cell.
Embodiment 3 is the method of any one of embodiments 1-2, wherein transmitting the non-zero weight input values and index metadata to the mxn cells comprises transmitting the non-zero weight input values along a first dimension of an array having mxn cells.
Embodiment 4 is the method of any one of embodiments 1 to 3, wherein the first dimension of the array comprises a vertical dimension of the array; and is also provided with
Transmitting the non-zero weight input and index metadata to the mxn cell along the first dimension of the array includes transmitting the non-zero weight input and index metadata starting from a top edge of the array.
Embodiment 5 is the method of any one of embodiments 1 to 3, wherein the first dimension of the array comprises a horizontal dimension of the array; and is also provided with
Transmitting the non-zero weight input and index metadata to the mxn cell along the first dimension of the array includes transmitting the non-zero weight input and index metadata starting from a left edge of the array.
Embodiment 6 is the method of any one of embodiments 1 to 5, wherein the index metadata includes an absolute fixed length row index for each non-zero input value.
Embodiment 7 is the method of any one of embodiments 1 to 5, wherein the index metadata includes a run-length encoded row index for each non-zero input value.
Embodiment 8 is the method of any one of embodiments 1 to 5, wherein the index metadata includes a bitmap of locations of non-zero input values in M x N cells of the array.
Embodiment 9 is the method of any one of embodiments 1 to 8, wherein the hardware device further comprises a comparator for each of the mxn cells of the array, the comparator configured to compare (i) index metadata for each non-zero input value with (ii) an index for the cell, the index indicating a location of the cell in the mxn cell along a first dimension of the array.
Embodiment 10 is the method of any one of embodiments 1 to 9, wherein the plurality of input values are in a Compressed Sparse Column (CSC) matrix format.
Embodiment 11 is the method of any one of embodiments 1 to 10, wherein the hardware device further comprises a first-in-first-out (FIFO) register for each of the mxn cells of the array, and wherein loading the respective non-zero input values into the cells comprises queuing the respective non-zero input values into the FIFO registers associated with the cells.
Embodiment 12 is the method of any one of embodiments 1 to 10, further comprising, for each cell in the array storing a particular non-zero input value:
Receiving, using hardware circuitry, a second input value from the second input matrix; and
based on the particular non-zero input value and the second input value, hardware circuitry is used to determine a corresponding multiplication product.
Embodiment 13 is the method of any one of embodiments 1 to 12, wherein the non-zero input value is shifted by one cell per clock cycle.
Embodiment 14 is the method of any one of embodiments 1 to 13, further comprising:
determining that the first input matrix includes columns having only zero input values; and
in response, a sign bit is added for each zero input value to the index defined by the corresponding index metadata.
Embodiment 15 is a system comprising: one or more computers and one or more storage devices storing operational instructions that, when executed by the one or more computers, cause the one or more computers to perform the method of any one of embodiments 1 to 14.
Embodiment 16 is a computer storage medium encoded with a computer program comprising instructions operable, when executed by data processing apparatus, to cause the data processing apparatus to perform the method of any of embodiments 1 to 14.
While this specification contains many specific implementation details, these should not be construed as limitations on the scope of any invention or of what may be claimed, but rather as descriptions of features that may be specific to particular embodiments of particular inventions. Certain features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely, various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable subcombination. Furthermore, although features may be described above as acting in certain combinations and even initially claimed as such, one or more features from a claimed combination can in some cases be excised from the combination, and the claimed combination may be directed to a subcombination or variation of a subcombination.
Similarly, although operations are depicted in the drawings in a particular order, this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order, or that all illustrated operations be performed, to achieve desirable results. In some cases, multitasking and parallel processing may be advantageous. Moreover, the separation of various system modules and components in the embodiments described above should not be understood as requiring such separation in all embodiments, and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.
Specific embodiments of the subject matter have been described. Other embodiments are within the scope of the following claims. For example, the actions recited in the claims can be performed in a different order and still achieve desirable results. As one example, the processes depicted in the accompanying figures do not necessarily require the particular order shown, or sequential order, to achieve desirable results. In some cases, multitasking and parallel processing may be advantageous.
Claims (16)
1. A method performed by a hardware device comprising circuitry for an array of mxn cells, the method comprising:
receiving, at hardware circuitry, a plurality of non-zero input values from a first input matrix to be multiplied with a second input matrix using the array, the first input matrix comprising the plurality of non-zero input values and a plurality of zero input values;
receiving index metadata at the hardware circuitry, the index metadata indicating, for each non-zero input value of a plurality of input values, into which cell of the mxn cells in the array the non-zero input value should be loaded;
send the non-zero input value and the index metadata to the mxn cell using the hardware circuitry; and
At a particular cell of the mxn cells in the array:
receiving a specific non-zero input value and corresponding index metadata of the specific non-zero input value; and
determining, from the corresponding index metadata for the particular non-zero input value, whether to store the particular non-zero input value at the cell for performing multiplication or to shift the particular non-zero input value to another cell,
wherein M and N are positive integers greater than 1.
2. The method of claim 1, further comprising, at the particular one of the mxn cells in the array and prior to sending the non-zero input value and the index metadata to the mxn cell: zero input values are automatically loaded into the cells.
3. The method of any of claims 1-2, wherein transmitting non-zero weight input values and the index metadata to the mxn cell comprises: the non-zero weight input values are sent along a first dimension of the array having the mxn cells.
4. A method according to claim 3, wherein the first dimension of the array comprises a vertical dimension of the array; and is also provided with
Transmitting the non-zero weight input and the index metadata to the mxn cell along the first dimension of the array comprises: the non-zero weight input and the index metadata are sent starting from the top edge of the array.
5. A method according to claim 3, wherein the first dimension of the array comprises a horizontal dimension of the array; and
transmitting the non-zero weight input and the index metadata to the mxn cell along the first dimension of the array comprises: the non-zero weight input and the index metadata are sent starting from the left edge of the array.
6. The method of any of claims 1 to 5, wherein the index metadata comprises an absolute fixed length row index for each non-zero input value.
7. The method of any of claims 1 to 5, wherein the index metadata comprises a run-length encoded row index for each non-zero input value.
8. The method of any of claims 1-5, wherein the index metadata comprises a bitmap of locations of the non-zero input values in the mxn cells of the array.
9. The method of any of claims 1-8, wherein the hardware device further comprises a comparator for each of the mxn cells of the array, the comparator configured to compare (i) the index metadata for each non-zero input value with (ii) an index of the cell, the index of the cell indicating a location of the cell in the mxn cell along the first dimension of the array.
10. The method of any of claims 1 to 9, wherein the plurality of input values are in a Compressed Sparse Column (CSC) matrix format.
11. The method of any of claims 1-10, wherein the hardware device further comprises a first-in, first-out, FIFO, register for each of the mxn cells of the array, and wherein loading the respective non-zero input value into the cell comprises queuing the respective non-zero input value into the FIFO register associated with the cell.
12. The method of any of claims 1 to 11, further comprising, for each cell in the array storing a particular non-zero input value:
Receiving, using the hardware circuitry, a second input value from the second input matrix; and
based on the particular non-zero input value and the second input value, a corresponding multiplication product is determined using the hardware circuitry.
13. The method of any of claims 1 to 12, wherein the non-zero input value is shifted by one cell per clock cycle.
14. The method of any one of claims 1 to 13, further comprising:
determining that the first input matrix includes columns having only zero input values; and
in response, a sign bit is added for each zero input value to the index defined by the corresponding index metadata.
15. A system comprising one or more computers and a computer-readable medium coupled to the one or more computers and having instructions stored thereon that, when executed by the one or more computers, cause the one or more computers to perform the respective operations of any one of the methods of any one of the preceding claims.
16. A computer-readable medium having instructions stored thereon, which when executed by one or more computers, cause the one or more computers to perform the respective operations of any one of the methods of any one of the preceding claims.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US17/368,374 US20230010897A1 (en) | 2021-07-06 | 2021-07-06 | In situ sparse matrix expansion |
US17/368,374 | 2021-07-06 | ||
PCT/US2022/036258 WO2023283267A1 (en) | 2021-07-06 | 2022-07-06 | In situ sparse matrix expansion |
Publications (1)
Publication Number | Publication Date |
---|---|
CN117280341A true CN117280341A (en) | 2023-12-22 |
Family
ID=81307522
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202280033990.1A Pending CN117280341A (en) | 2021-07-06 | 2022-07-06 | In-situ sparse matrix expansion |
Country Status (5)
Country | Link |
---|---|
US (1) | US20230010897A1 (en) |
EP (1) | EP4116846A1 (en) |
KR (1) | KR20230162723A (en) |
CN (1) | CN117280341A (en) |
WO (1) | WO2023283267A1 (en) |
Family Cites Families (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10621269B2 (en) | 2017-05-17 | 2020-04-14 | Google Llc | Performing matrix multiplication in hardware |
US10599429B2 (en) * | 2018-06-08 | 2020-03-24 | Intel Corporation | Variable format, variable sparsity matrix multiplication instruction |
US20200226473A1 (en) * | 2019-01-15 | 2020-07-16 | BigStream Solutions, Inc. | Systems, apparatus, methods, and architectures for heterogeneous precision acceleration of quantized neural networks |
-
2021
- 2021-07-06 US US17/368,374 patent/US20230010897A1/en active Pending
-
2022
- 2022-04-12 EP EP22167898.0A patent/EP4116846A1/en active Pending
- 2022-07-06 WO PCT/US2022/036258 patent/WO2023283267A1/en active Application Filing
- 2022-07-06 CN CN202280033990.1A patent/CN117280341A/en active Pending
- 2022-07-06 KR KR1020237038775A patent/KR20230162723A/en unknown
Also Published As
Publication number | Publication date |
---|---|
US20230010897A1 (en) | 2023-01-12 |
EP4116846A1 (en) | 2023-01-11 |
WO2023283267A1 (en) | 2023-01-12 |
KR20230162723A (en) | 2023-11-28 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US10831862B2 (en) | Performing matrix multiplication in hardware | |
CN110622134B (en) | Special neural network training chip | |
CN109997132B (en) | Low-delay matrix multiplication component | |
US20180046897A1 (en) | Hardware accelerator for compressed rnn on fpga | |
CN111095241A (en) | Accelerated math engine | |
WO2022037257A1 (en) | Convolution calculation engine, artificial intelligence chip, and data processing method | |
US8756268B2 (en) | Montgomery multiplier having efficient hardware structure | |
EP1876523A1 (en) | Computation of A MOD (2^n - 1) | |
CN111313912B (en) | LDPC code encoder and encoding method | |
CN117280341A (en) | In-situ sparse matrix expansion | |
CN116301727A (en) | Data processing method and acceleration unit | |
CN111796797B (en) | Method and device for realizing loop polynomial multiplication calculation acceleration by using AI accelerator | |
CN115391727B (en) | Calculation method, device and equipment of neural network model and storage medium | |
CN111507178B (en) | Data processing optimization method and device, storage medium and computer equipment | |
CN115708090A (en) | Computing device, method, system, circuit, chip and equipment | |
WO2023224614A1 (en) | Exploiting data sparsity at a machine-learning hardware accelerator | |
KR20240057754A (en) | Memory device for in memory computin and method thereof |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination |