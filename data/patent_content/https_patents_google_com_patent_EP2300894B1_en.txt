EP2300894B1 - A web-based system for collaborative generation of interactive videos - Google Patents
A web-based system for collaborative generation of interactive videos Download PDFInfo
- Publication number
- EP2300894B1 EP2300894B1 EP09758919.6A EP09758919A EP2300894B1 EP 2300894 B1 EP2300894 B1 EP 2300894B1 EP 09758919 A EP09758919 A EP 09758919A EP 2300894 B1 EP2300894 B1 EP 2300894B1
- Authority
- EP
- European Patent Office
- Prior art keywords
- video
- annotation
- digital video
- user
- annotations
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0481—Interaction techniques based on graphical user interfaces [GUI] based on specific properties of the displayed interaction object or a metaphor-based environment, e.g. interaction with desktop elements like windows or icons, or assisted by a cursor's changing behaviour or appearance
- G06F3/0482—Interaction with lists of selectable items, e.g. menus
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/70—Information retrieval; Database structures therefor; File system structures therefor of video data
- G06F16/78—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually
- G06F16/7867—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using information manually generated, e.g. tags, keywords, comments, title and artist information, manually generated time, location and usage information, user ratings
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/20—Servers specifically adapted for the distribution of content, e.g. VOD servers; Operations thereof
- H04N21/25—Management operations performed by the server for facilitating the content distribution or administrating data related to end-users or client devices, e.g. end-user or client device authentication, learning user preferences for recommending movies
- H04N21/258—Client or end-user data management, e.g. managing client capabilities, user preferences or demographics, processing of multiple end-users preferences to derive collaborative data
- H04N21/25866—Management of end-user data
- H04N21/25875—Management of end-user data involving end-user authentication
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/20—Servers specifically adapted for the distribution of content, e.g. VOD servers; Operations thereof
- H04N21/27—Server based end-user applications
- H04N21/274—Storing end-user multimedia data in response to end-user request, e.g. network recorder
- H04N21/2743—Video hosting of uploaded data from client
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/45—Management operations performed by the client for facilitating the reception of or the interaction with the content or administrating data related to the end-user or to the client device itself, e.g. learning user preferences for recommending movies, resolving scheduling conflicts
- H04N21/454—Content or additional data filtering, e.g. blocking advertisements
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/47—End-user applications
- H04N21/472—End-user interface for requesting content, additional data or services; End-user interface for interacting with content, e.g. for content reservation or setting reminders, for requesting event notification, for manipulating displayed content
- H04N21/47205—End-user interface for requesting content, additional data or services; End-user interface for interacting with content, e.g. for content reservation or setting reminders, for requesting event notification, for manipulating displayed content for manipulating displayed content, e.g. interacting with MPEG-4 objects, editing locally
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/47—End-user applications
- H04N21/478—Supplemental services, e.g. displaying phone caller identification, shopping application
- H04N21/4781—Games
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/80—Generation or processing of content or additional data by content creator independently of the distribution process; Content per se
- H04N21/85—Assembly of content; Generation of multimedia applications
- H04N21/854—Content authoring
- H04N21/8541—Content authoring involving branching, e.g. to different story endings
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/80—Generation or processing of content or additional data by content creator independently of the distribution process; Content per se
- H04N21/85—Assembly of content; Generation of multimedia applications
- H04N21/858—Linking data to content, e.g. by linking an URL to a video object, by creating a hotspot
- H04N21/8583—Linking data to content, e.g. by linking an URL to a video object, by creating a hotspot by creating hot-spots
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N7/00—Television systems
- H04N7/16—Analogue secrecy systems; Analogue subscription systems
- H04N7/173—Analogue secrecy systems; Analogue subscription systems with two-way working, e.g. subscriber sending a programme selection signal
- H04N7/17309—Transmission or handling of upstream communications
- H04N7/17318—Direct or substantially direct transmission and handling of requests
-
- A—HUMAN NECESSITIES
- A63—SPORTS; GAMES; AMUSEMENTS
- A63F—CARD, BOARD, OR ROULETTE GAMES; INDOOR GAMES USING SMALL MOVING PLAYING BODIES; VIDEO GAMES; GAMES NOT OTHERWISE PROVIDED FOR
- A63F2300/00—Features of games using an electronically generated display having two or more dimensions, e.g. on a television screen, showing representations related to the game
- A63F2300/60—Methods for processing data by generating or executing the game program
- A63F2300/6009—Methods for processing data by generating or executing the game program for importing or creating game content, e.g. authoring tools during game development, adapting content to different platforms, use of a scripting language to create content
- A63F2300/6018—Methods for processing data by generating or executing the game program for importing or creating game content, e.g. authoring tools during game development, adapting content to different platforms, use of a scripting language to create content where the game content is authored by the player, e.g. level editor or by game device at runtime, e.g. level is created from music data on CD
-
- A—HUMAN NECESSITIES
- A63—SPORTS; GAMES; AMUSEMENTS
- A63F—CARD, BOARD, OR ROULETTE GAMES; INDOOR GAMES USING SMALL MOVING PLAYING BODIES; VIDEO GAMES; GAMES NOT OTHERWISE PROVIDED FOR
- A63F2300/00—Features of games using an electronically generated display having two or more dimensions, e.g. on a television screen, showing representations related to the game
- A63F2300/60—Methods for processing data by generating or executing the game program
- A63F2300/63—Methods for processing data by generating or executing the game program for controlling the execution of the game in time
- A63F2300/632—Methods for processing data by generating or executing the game program for controlling the execution of the game in time by branching, e.g. choosing one of several possible story developments at a given point in time
-
- A—HUMAN NECESSITIES
- A63—SPORTS; GAMES; AMUSEMENTS
- A63F—CARD, BOARD, OR ROULETTE GAMES; INDOOR GAMES USING SMALL MOVING PLAYING BODIES; VIDEO GAMES; GAMES NOT OTHERWISE PROVIDED FOR
- A63F2300/00—Features of games using an electronically generated display having two or more dimensions, e.g. on a television screen, showing representations related to the game
- A63F2300/60—Methods for processing data by generating or executing the game program
- A63F2300/69—Involving elements of the real world in the game world, e.g. measurement in live races, real video
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/20—Servers specifically adapted for the distribution of content, e.g. VOD servers; Operations thereof
- H04N21/25—Management operations performed by the server for facilitating the content distribution or administrating data related to end-users or client devices, e.g. end-user or client device authentication, learning user preferences for recommending movies
- H04N21/251—Learning process for intelligent management, e.g. learning user preferences for recommending movies
- H04N21/252—Processing of multiple end-users' preferences to derive collaborative data
Definitions
- the disclosed embodiments relate generally to the collaborative generation of interactive features for digital videos.
- US2007271331 proposes a system and method for creating a database of user media and associated user comments wherein the user's comments are collected, collated, stored, and made available to users through a Commenting Theater that allows for the simultaneous representation of and access to the entirety of an archived complex group conversation without reliance upon text.
- WO03019418 proposes a collaborative annotation system for facilitating annotations, such as commentaries, of time-based media, such as video.
- the system involves displaying and controlling the display of a time-based medium, and receiving and storing input for defining a location in the time-based medium.
- the system also involves receiving and storing an annotation relating to the context of the location, and performing and storing a valuation relating to the annotation.
- WO0120466 teaches tracking objects in a video and associating an animation to those objects using an authoring workstation.
- a computer-implemented method as set out in claim 1.
- a computer readable storage medium as set out in claim 15.
- the present invention includes systems and methods for adding and displaying interactive annotations for online hosted videos.
- a graphical annotation interface allows the creation of annotations and association of the annotations with a video.
- Annotations may be of different types and have different functionality, such as altering the appearance and/or behavior of an existing video, e.g. by supplementing it with text, allowing linking to other videos or web pages, or pausing playback of the video.
- Authentication of a user desiring to perform annotation of a video may be performed in various manners, such as by checking a uniform resource locator (URL) against an existing list, checking a user identifier against an access list, and the like.
- URL uniform resource locator
- a user is accorded the appropriate annotation abilities, such as full annotation, no annotation, or annotation restricted to a particular temporal or spatial portion of the video.
- FIG. 1 is a block diagram of a system architecture in accordance with one embodiment.
- a video hosting server 108 includes a front end server 124, a video server 126, a network interface 122, a video database 128, and a user database 140.
- Other conventional features, such as firewalls, load balancers, application servers, failover servers, site management tools, and so forth are not shown so as to more clearly illustrate the features of the system.
- Examples of a suitable video hosting server 108 for implementation of the system include the YouTubeTM and Google VideoTM websites; other video hosting sites are known as well, and can be adapted to operate according the teaching disclosed herein.
- website represents any system and method of providing content and is not intended to be limited to systems that support content provided via the Internet or the HTTP protocol.
- the various servers are conventionally implemented, whether as a single piece of software or hardware or as multiple pieces of software or hardware and can couple to the network 105 via the network interface 122.
- functions described in one embodiment as being performed on the server side can also be performed on the client side in other embodiments if appropriate.
- a client 130 executes a browser 132, and connects to the front end server 124 via a network 105, which is typically the Internet, but may also be any network, including but not limited to a LAN, a MAN, a WAN, a mobile, wired or wireless network, a private network, or a virtual private network. While only a single client 130 and browser 132 are shown, it is understood that very large numbers (e.g., millions) of clients are supported and can be in communication with the video hosting server 108 at any time.
- the client 130 may include a variety of different computing devices. Examples of client devices 130 are personal computers, digital assistants, personal digital assistants, cellular phones, mobile phones, smart phones or laptop computers. As will be obvious to one of ordinary skill in the art, the present invention is not limited to the devices listed above.
- the browser 132 includes an embedded video player 134 such as, for example, the FlashTM player from Adobe Systems, Inc. or any other player adapted for the video file formats used in the video hosting video hosting server 108.
- an embedded video player 134 such as, for example, the FlashTM player from Adobe Systems, Inc. or any other player adapted for the video file formats used in the video hosting video hosting server 108.
- a user can access a video from the video hosting server 108 by browsing a catalog of videos, conducting searches on keywords, reviewing play lists from other users or the system administrator (e.g., collections of videos forming channels), or viewing videos associated with a particular user group (e.g., communities).
- Video server 126 receives uploaded media content from content providers and allows content to be viewed by client 130.
- Content may be uploaded to video server 126 via the Internet from a personal computer, through a cellular network from a telephone or PDA, or by other means for transferring data over network 105 known to those of ordinary skill in the art.
- Content may be downloaded from video server 126 in a similar manner; in one embodiment media content is provided as a file download to a client 130; in an alternative embodiment, media content is streamed client 130.
- the means by which media content is received by video server 126 need not match the means by which it is delivered to client 130.
- a content provider may upload a video via a browser on a personal computer, whereas client 130 may view that video as a stream sent to a PDA.
- video server 126 may itself serve as the content provider. Communications between the client 130 and video hosting server 108, or between the other distinct units of FIG. 1 , may be encrypted or otherwise encoded.
- Users of clients 130 can also search for videos based on keywords, tags or other metadata. These requests are received as queries by the front end server 124 and provided to the video server 126, which is responsible for searching the video database 128 for videos that satisfy the user queries.
- the video server 126 supports searching on any fielded data for a video, including its title, description, tags, author, category and so forth.
- the uploaded content can include, for example, video, audio or a combination of video and audio.
- the uploaded content is processed and stored in the video database 128. This processing can include format conversion (transcoding), compression, metadata tagging, and other data processing.
- An uploaded content file is associated with the uploading user, and so the user's account record is updated in the user database 140 as needed.
- the uploaded content will be referred to a "videos", “video files”, or “video items”, but no limitation on the types of content that can be uploaded are intended by this terminology.
- Each uploaded video is assigned a video identifier when it is processed.
- the user database 140 is responsible for maintaining a record of all users viewing videos on the website. Each individual user is assigned a user ID (also referred to as a user identity). The user ID can be based on any identifying information, such as the user's IP address, user name, or the like. The user database may also contain information about the reputation of the user in both the video context, as well as through other applications, such as the use of email or text messaging. The user database may further contain information about membership in user groups, e.g. a group of users that can view the same annotations. The user database may further contain, for a given user, a list of identities of other users who are considered friends of the user. (The term "list”, as used herein for concepts such as lists of authorized users, URL lists, and the like, refers broadly to a set of elements, where the elements may or may not be ordered.)
- the video database 128 is used to store the received videos.
- the video database 128 stores video content and associated metadata, provided by their respective content owners.
- the video files have metadata associated with each file such as a video ID, artist, video title, label, genre, and time length.
- An annotation server 150 provides the ability to view and add annotations to videos in the video database 128.
- the annotation server 150 collects various annotations-such as text boxes, "thought bubbles", and the like-from uploads by a user or the owner of a video, from publishers, or as a result of video analysis techniques. It then stores these annotations within an annotation database 154.
- the annotation server 150 also provides to entities such as the client 130 or the video hosting server 108, for a given video, annotations stored within the annotation database 154 for that video.
- an annotation modifies the behavior of an otherwise non-interactive video, providing interactive overlays with which a user can interact, or altering the usual flow of playback of the video, for example.
- annotation server 150 is on a separate physical server from the video hosting server 108, although in other embodiments the annotation functionality is included within the video hosting server 108.
- the annotation database 154 maintains an association between each annotation and the appropriate portion of the annotated video.
- the annotation database 154 stores an identifier of the annotation type (e.g., a text box) along with any information associated with that type (e.g., a text caption), a time stamp(s) of the video to which the annotation applies (e.g., from time 01:05 to time 01:26), an identifier of the video which the annotation annotates, and an identifier of a user who submitted the annotation (e.g., a username).
- Some types of annotation may also be associated with a link to another web page, video, network object, or the like. Many other storage implementations for annotations would be equally possible to one of skill in the art.
- a video analysis module 152 can be used by the annotation server 150 to automatically generate annotations, or to suggest them to a user. This can entail techniques such as speech analysis, vision analysis (e.g., face detection, object recognition, and optical character recognition (OCR)), or crawling annotations explicitly or implicitly available.
- speech analysis e.g., speech analysis, vision analysis (e.g., face detection, object recognition, and optical character recognition (OCR)), or crawling annotations explicitly or implicitly available.
- vision analysis e.g., face detection, object recognition, and optical character recognition (OCR)
- OCR optical character recognition
- an authentication mechanism can be used to restrict annotations to only a subset of users.
- an authentication server 170 is provided to verify access by clients 130 to annotation functionality of the annotation server 150.
- authentication may be performed in a number of ways in different embodiments, such as using secret links, access control lists, user credibility scores, or permissions based on community moderation.
- a three-tiered permissions system is employed, with a first, lowest permission tier for users who can only view and interact with annotations of a video by clicking on links, a second, higher permission tier for those users who can add or modify their own annotations, and a third, highest permission tier for those users who can also modify and delete any annotations in the video.
- the use of secret links employs a URL list 171, which associates videos with a URL through which access to an annotation interface is obtained.
- the authentication server 170 is implemented as a component of video hosting server 108.
- FIG. 2 illustrates some different types of interactive annotations (hereinafter “annotations”) that may be added to a video, according to one embodiment.
- a main video area 202 displayed on the client 130 plays a video stored in the video database 128 and served to the client 130 by the video server 126. Playback can be controlled via, for example, a video controls area 204.
- three distinct annotations 205-215 have been added.
- Annotations 205 and 210 are text boxes and thought bubbles, which display static text.
- Annotation 215 is a spotlight that displays text, e.g. "What's behind the window?" in response to a user hovering the mouse within its boundaries.
- Any of these annotation types can have a time range during which it is active, e.g. from a time 0:15 to 0:36.
- the text box 205 could be set to appear 15 seconds into the playing of the video and disappear 21 seconds later, after a user has had a chance to read it.
- time stamps in URLs can be used to construct, for example, a branching series of pages, which can be used to create an interactive storyline within a single video. This allows, for example, rapid transfer to another video portion, without the delay entailed by obtaining a different video.
- an annotation can be displayed conditionally, for example if a user mouses over another annotation, when that other annotation is displayed either at the same time or a later time.
- Annotations may also be added to modify the playback of the video, rather than to present an interactive graphical interface.
- a pause annotation causes playback of the video to halt for a given time delay, including an unlimited time. This allows, for example, an arbitrary amount of time for users to make a choice before the video continues.
- time stamps in URLs as described above, one can modify the playback of a video so that, for example, clicking (or even positioning the mouse over) a door will seek to the portion of the video that displays the door opening and the room behind it. This can increase the level of interactivity in a video to a degree similar to that of a computer game.
- annotations could be used to implement an interactive game of "rock, paper, scissors", in which, for instance, clicking on an annotation corresponding to a "rock”, “paper”, or “scissors” choice leads to a separate video or portion of the same video depicting a tie, a win, or a loss, respectively, each outcome potentially leading to the display of additional annotations representing a second round of the game.
- the menu items could also be used to implement multi-perspective storylines, wherein clicking on the annotated face of an actor leads to seeing the remainder of the story from that actor's perspective.
- FIG. 3 depicts a user interface for manually creating the annotations of FIG. 2 , according to one embodiment.
- Annotation icons 302-305 correspond to four annotation types (speech bubbles, text boxes, spotlights, and pauses, respectively); selecting one of them and then clicking on the playing video creates an annotation of that type at the location and time corresponding to the click.
- the annotation then has default values, such as text captions, time ranges, boundaries, and associated URLs.
- editing regions 310, 305, and 315 correspond to displayed annotations 205, 210, and 215, respectively, and the contents thereof can be edited to change the values of the caption.
- Editing region 310 for example, comprises a text caption 310A, a time range 310B, and a link 310C.
- the link can be, for example, a page within the video service that denotes a watch page for a video or that denotes a channel displaying thumbnails for several related videos.
- the text caption 310A has been set to the value "Happy birthday mom" by the user, and the time range 310B is set to last from 0:00:03, fifth frame, to 0:00:13, third frame, and the link 310C does not yet have a specified value. Editing of annotations can also be accomplished graphically; for example, the boundary of callout 215 can be changed by dragging on the handles 215A associated with the boundaries.
- the video analysis module 152 of FIG. 1 can be used to automatically detect temporal and spatial locations to add annotations, to determine their associated values, and/or to control the behavior of existing annotations.
- face detection which can be used in the video of FIG. 3 to detect the face of the boy in the images as a human face and to suggest the creation of a text bubble in association therewith, or it could be used to automatically provide or suggest a caption describing the recognized face.
- Another example could include applying object recognition methods based on local descriptor matching.
- object recognition can identify instances of known textured objects, such as locations, buildings, books, CD covers, and the like.
- Example images for training recognition of such objects can be readily found in product / location catalogs which associate the product name with one or more images of the product).
- Recognized objects can then be associated with annotations, such as links presenting more information, e.g. from a given viewpoint.
- annotations such as links presenting more information, e.g. from a given viewpoint.
- events can be presented from a national perspective by using object recognition to identify objects associated with a certain nationality and presenting associated information, e.g. associating, with the Indian team members of a cricket match, a link to the next event that the team will be participating in.
- an athlete recognized using object recognition can be associated with a link or other annotation data that provides statistics, personal information, etc. on the athlete.
- a search index of a search engine such as GoogleTM or YouTubeTM
- a phrase describing that product could be executed against the search index and the top search result suggested as a link for the object (e.g., searching for the title of a recognized music CD and linking to a product search page corresponding to that title).
- Object recognition could further be used to identify locations of interest, and in combination with "geotagged" videos in which location information is embedded, videos related to the recognized location could be provided or suggested as links.
- FIG. 4 illustrates steps involved in adding annotations to videos, according to one embodiment.
- the client 130 requests a video from the video server 108 using the network 105.
- the front end server 124 of the video hosting server 108 receives the request and delegates to the video server 126, which obtains the video from the video database 128 and provides it 410 to the client 130.
- the video hosting server 108 then delegates to the annotation server 150 to provide the annotation user interface; in other embodiments, the video hosting server 108 requests the annotations for the video from the annotation server 150 and then itself provides the annotation user interface, providing any annotations created via the user interface to the annotation server for storage.
- the provided annotation user interface differs depending on the identity of the user doing the annotation.
- the determination of which type of annotation user interface to provide (e.g., that of the owner, of that of another user)-which can be used to control the degree to which annotation may be added-may involve the use of the authentication server 170, which authenticates 420 the user.
- the authentication server decides in different ways in different embodiments what access to annotations a given user has.
- the authentication server 170 only allows creation of annotations by the owner of the video.
- the authentication server 170 consults the user database 140 to determine the identity (e.g., the username) of the owner of the video and compares it to the identity of the currently active user. If the currently active user has no identity (e.g., is not signed in), or the identity does not match that of the owner of the video, then the ability to annotate is not provided.
- the owner of the video grants access to users by providing them with a special URL associated with that video.
- the owner interface 500 includes a URL area 520 that lists a URL associated with the video in the URL list 171. The owner may then copy this URL and distribute it as desired to other users who the owner wishes to have annotation abilities, e.g. by emailing the URL to friends, posting it on a web page available to friends, and the like. Then, when a user enters the URL, the authentication server 170 compares the URL to those in the URL list 171 for the given video; if the URL matches, then an annotation user interface is provided. In case the URL becomes too widely-distributed and an excessive number of unwanted annotations are being added to the video, the owner may use button 525 to disable the addition of further annotations, in which case the URL becomes invalid for purposes of further annotation.
- Data defining the collaborative region can then be stored, e.g., within the annotation database 154.
- other users determined to be collaborators of the video owner e.g., those considered “friends" of the user
- the access control lists need not be strictly predefined by the owner or other authorized users, but can be dynamically determined based on external factors.
- the lists could be based on credibility scores of the user (the credibility scores being calculated by, e.g., monitoring how many previous annotations by this contributor were deleted by content owners, or by community moderation actions such as users expressing approval or disapproval of the user's video ratings, such as via "thumbs-up” or “thumb-down” indicators) or of those considered friends of the user in the user database 140 (e.g., based on activities such as active email exchanging, or on explicit indications of friendship, such as adding someone to a "friends" list),.
- the annotation server 150 of FIG. 1 could be part of the video hosting server 108, a server on the same local network as the video hosting server, or on a remote network from the video hosting server.
- the authentication server 170 could be separate from the video hosting server, or could be a component thereof.
- some clients 130 could be configured not to communicate with the annotation server 150, or the annotation server 150 not to provide annotations to the client 130, in which case the client 130 obtains un-annotated video (e.g. clients in each country or language can have their own set of annotations).
- the client 130 can perform annotation offline, without a network connection to the annotation server 150, and later synchronize the annotations with the annotation server 150 when a network connection becomes available.
- the present invention also relates to an apparatus for performing the operations herein.
- This apparatus may be specially constructed for the required purposes, or it may comprise a general-purpose computer selectively activated or reconfigured by a computer program stored in the computer.
- a computer program may be stored in a computer readable storage medium, such as, but is not limited to, any type of disk including floppy disks, optical disks, CD-ROMs, magnetic-optical disks, read-only memories (ROMs), random access memories (RAMs), EPROMs, EEPROMs, magnetic or optical cards, application specific integrated circuits (ASICs), or any type of media suitable for storing electronic instructions, and each coupled to a computer system bus.
- the computers referred to in the specification may include a single processor or may be architectures employing multiple processor designs for increased computing capability.
Description
- The disclosed embodiments relate generally to the collaborative generation of interactive features for digital videos.
- Conventional web-based systems permitting the storage and display of digital videos typically only allow commenting on the video as a whole. In particular, if viewers wish to comment on or otherwise reference a particular portion of the video, they are obliged to explicitly describe the portion by text or time in the video and other indirect means. Conventional systems also have simplistic controls for annotating a video, to the extent that they allow such annotation at all. Rather, such systems either allow only the owner (e.g., a user who uploaded the video) to add annotations, or else allow all users to do so, without restrictions.
US2007271331 proposes a system and method for creating a database of user media and associated user comments wherein the user's comments are collected, collated, stored, and made available to users through a Commenting Theater that allows for the simultaneous representation of and access to the entirety of an archived complex group conversation without reliance upon text.
WO03019418 WO0120466 - According to a first aspect of the present invention, there is provided a computer-implemented method as set out in claim 1. According to a second aspect of the present invention, there is provided a computer readable storage medium as set out in claim 15. The present invention includes systems and methods for adding and displaying interactive annotations for online hosted videos. A graphical annotation interface allows the creation of annotations and association of the annotations with a video. Annotations may be of different types and have different functionality, such as altering the appearance and/or behavior of an existing video, e.g. by supplementing it with text, allowing linking to other videos or web pages, or pausing playback of the video.
- Authentication of a user desiring to perform annotation of a video may be performed in various manners, such as by checking a uniform resource locator (URL) against an existing list, checking a user identifier against an access list, and the like. As a result of authentication, a user is accorded the appropriate annotation abilities, such as full annotation, no annotation, or annotation restricted to a particular temporal or spatial portion of the video.
- The features and advantages described in this summary and the following detailed description are not all-inclusive. Many additional features and advantages will be apparent to one of ordinary skill in the art in view of the drawings, specification, and claims presented herein.
-
-
FIG. 1 is a block diagram of a system architecture for allowing annotation of online hosted videos, according to one embodiment. -
FIG. 2 illustrates different types of annotations that may be added to a video, according to one embodiment. -
FIG. 3 depicts a user interface for creating the annotations ofFIG. 2 , according to one embodiment. -
FIG. 4 illustrates the steps involved in adding annotations to videos, according to one embodiment. -
FIG. 5 illustrates an annotation interface allowing the addition of annotations and providing information on existing annotations, according to one embodiment. - The figures depict various embodiments of the present invention for purposes of illustration only. One skilled in the art will readily recognize from the following discussion that alternative embodiments of the structures and methods illustrated herein may be employed without departing from the principles of the invention described herein.
-
FIG. 1 is a block diagram of a system architecture in accordance with one embodiment. As illustrated inFIG. 1 , avideo hosting server 108 includes afront end server 124, avideo server 126, anetwork interface 122, avideo database 128, and auser database 140. Other conventional features, such as firewalls, load balancers, application servers, failover servers, site management tools, and so forth are not shown so as to more clearly illustrate the features of the system. Examples of a suitablevideo hosting server 108 for implementation of the system include the YouTube™ and Google Video™ websites; other video hosting sites are known as well, and can be adapted to operate according the teaching disclosed herein. It will be understood that the term "website" represents any system and method of providing content and is not intended to be limited to systems that support content provided via the Internet or the HTTP protocol. The various servers are conventionally implemented, whether as a single piece of software or hardware or as multiple pieces of software or hardware and can couple to thenetwork 105 via thenetwork interface 122. In general, functions described in one embodiment as being performed on the server side can also be performed on the client side in other embodiments if appropriate. - A
client 130 executes abrowser 132, and connects to thefront end server 124 via anetwork 105, which is typically the Internet, but may also be any network, including but not limited to a LAN, a MAN, a WAN, a mobile, wired or wireless network, a private network, or a virtual private network. While only asingle client 130 andbrowser 132 are shown, it is understood that very large numbers (e.g., millions) of clients are supported and can be in communication with thevideo hosting server 108 at any time. Theclient 130 may include a variety of different computing devices. Examples ofclient devices 130 are personal computers, digital assistants, personal digital assistants, cellular phones, mobile phones, smart phones or laptop computers. As will be obvious to one of ordinary skill in the art, the present invention is not limited to the devices listed above. - In some embodiments, the
browser 132 includes an embeddedvideo player 134 such as, for example, the Flash™ player from Adobe Systems, Inc. or any other player adapted for the video file formats used in the video hostingvideo hosting server 108. A user can access a video from thevideo hosting server 108 by browsing a catalog of videos, conducting searches on keywords, reviewing play lists from other users or the system administrator (e.g., collections of videos forming channels), or viewing videos associated with a particular user group (e.g., communities). -
Video server 126 receives uploaded media content from content providers and allows content to be viewed byclient 130. Content may be uploaded tovideo server 126 via the Internet from a personal computer, through a cellular network from a telephone or PDA, or by other means for transferring data overnetwork 105 known to those of ordinary skill in the art. Content may be downloaded fromvideo server 126 in a similar manner; in one embodiment media content is provided as a file download to aclient 130; in an alternative embodiment, media content is streamedclient 130. The means by which media content is received byvideo server 126 need not match the means by which it is delivered toclient 130. For example, a content provider may upload a video via a browser on a personal computer, whereasclient 130 may view that video as a stream sent to a PDA. Note also thatvideo server 126 may itself serve as the content provider. Communications between theclient 130 andvideo hosting server 108, or between the other distinct units ofFIG. 1 , may be encrypted or otherwise encoded. - Users of
clients 130 can also search for videos based on keywords, tags or other metadata. These requests are received as queries by thefront end server 124 and provided to thevideo server 126, which is responsible for searching thevideo database 128 for videos that satisfy the user queries. Thevideo server 126 supports searching on any fielded data for a video, including its title, description, tags, author, category and so forth. - Users of the
clients 130 andbrowser 132 can upload content to thevideo hosting server 108 vianetwork 105. The uploaded content can include, for example, video, audio or a combination of video and audio. The uploaded content is processed and stored in thevideo database 128. This processing can include format conversion (transcoding), compression, metadata tagging, and other data processing. An uploaded content file is associated with the uploading user, and so the user's account record is updated in theuser database 140 as needed. - For purposes of convenience and the description of one embodiment, the uploaded content will be referred to a "videos", "video files", or "video items", but no limitation on the types of content that can be uploaded are intended by this terminology. Each uploaded video is assigned a video identifier when it is processed.
- The
user database 140 is responsible for maintaining a record of all users viewing videos on the website. Each individual user is assigned a user ID (also referred to as a user identity). The user ID can be based on any identifying information, such as the user's IP address, user name, or the like. The user database may also contain information about the reputation of the user in both the video context, as well as through other applications, such as the use of email or text messaging. The user database may further contain information about membership in user groups, e.g. a group of users that can view the same annotations. The user database may further contain, for a given user, a list of identities of other users who are considered friends of the user. (The term "list", as used herein for concepts such as lists of authorized users, URL lists, and the like, refers broadly to a set of elements, where the elements may or may not be ordered.) - The
video database 128 is used to store the received videos. Thevideo database 128 stores video content and associated metadata, provided by their respective content owners. The video files have metadata associated with each file such as a video ID, artist, video title, label, genre, and time length. - An
annotation server 150 provides the ability to view and add annotations to videos in thevideo database 128. Theannotation server 150 collects various annotations-such as text boxes, "thought bubbles", and the like-from uploads by a user or the owner of a video, from publishers, or as a result of video analysis techniques. It then stores these annotations within anannotation database 154. Theannotation server 150 also provides to entities such as theclient 130 or thevideo hosting server 108, for a given video, annotations stored within theannotation database 154 for that video. Generally, an annotation modifies the behavior of an otherwise non-interactive video, providing interactive overlays with which a user can interact, or altering the usual flow of playback of the video, for example. Examples of interactive overlays include text boxes, thought bubbles, spotlights, hyperlinks, menus, polls, and the like, any of which can have an arbitrarily sophisticated user interface behavior. In one embodiment, theannotation server 150 is on a separate physical server from thevideo hosting server 108, although in other embodiments the annotation functionality is included within thevideo hosting server 108. - The
annotation database 154 maintains an association between each annotation and the appropriate portion of the annotated video. In one embodiment, for example, theannotation database 154 stores an identifier of the annotation type (e.g., a text box) along with any information associated with that type (e.g., a text caption), a time stamp(s) of the video to which the annotation applies (e.g., from time 01:05 to time 01:26), an identifier of the video which the annotation annotates, and an identifier of a user who submitted the annotation (e.g., a username). Some types of annotation may also be associated with a link to another web page, video, network object, or the like. Many other storage implementations for annotations would be equally possible to one of skill in the art. - A
video analysis module 152 can be used by theannotation server 150 to automatically generate annotations, or to suggest them to a user. This can entail techniques such as speech analysis, vision analysis (e.g., face detection, object recognition, and optical character recognition (OCR)), or crawling annotations explicitly or implicitly available. - Since annotation of videos may be accomplished from remote locations over the
network 105 by a variety of users, an authentication mechanism can be used to restrict annotations to only a subset of users. Thus, anauthentication server 170 is provided to verify access byclients 130 to annotation functionality of theannotation server 150. As described further below, authentication may be performed in a number of ways in different embodiments, such as using secret links, access control lists, user credibility scores, or permissions based on community moderation. In one embodiment, a three-tiered permissions system is employed, with a first, lowest permission tier for users who can only view and interact with annotations of a video by clicking on links, a second, higher permission tier for those users who can add or modify their own annotations, and a third, highest permission tier for those users who can also modify and delete any annotations in the video. The use of secret links employs aURL list 171, which associates videos with a URL through which access to an annotation interface is obtained. In one embodiment, theauthentication server 170 is implemented as a component ofvideo hosting server 108. -
FIG. 2 illustrates some different types of interactive annotations (hereinafter "annotations") that may be added to a video, according to one embodiment. Amain video area 202 displayed on theclient 130 plays a video stored in thevideo database 128 and served to theclient 130 by thevideo server 126. Playback can be controlled via, for example, a video controlsarea 204. In the illustrated example, three distinct annotations 205-215 have been added.Annotations Annotation 215 is a spotlight that displays text, e.g. "What's behind the window?" in response to a user hovering the mouse within its boundaries. Any of these annotation types can have a time range during which it is active, e.g. from a time 0:15 to 0:36. For example, thetext box 205 could be set to appear 15 seconds into the playing of the video and disappear 21 seconds later, after a user has had a chance to read it. - Any of these annotation types may also have arbitrarily sophisticated presentation, such as shape and text coloring and styling, or associated actions, such as displaying additional annotations or redirecting the user to a target web-based location such as a uniform resource locator (URL) upon being activated, such as by a mouse click, mouse over, press of a key corresponding to the annotation, or the like. The target location to which control is transferred could include an advertisement, or content including an advertisement. For example, clicking on
spotlight 215 could lead to a web page describing a particular product. The target location could also cause display of an object or scene taken from a different perspective, e.g. the back side of an object taken from a different camera angle. Additionally, the target location could have a link, button, or annotation that transfers control back to the original video, instead of to a different video. In one embodiment, control can be transferred back to a particular moment in the original video, e.g., as specified by a URL encoding the video identifier and a description of the moment in the video, such as "t=0:22", denoting a time 22 seconds into the video. Such uses of time stamps in URLs can be used to construct, for example, a branching series of pages, which can be used to create an interactive storyline within a single video. This allows, for example, rapid transfer to another video portion, without the delay entailed by obtaining a different video. In one embodiment, an annotation can be displayed conditionally, for example if a user mouses over another annotation, when that other annotation is displayed either at the same time or a later time. - Annotations may also be added to modify the playback of the video, rather than to present an interactive graphical interface. For example, a pause annotation causes playback of the video to halt for a given time delay, including an unlimited time. This allows, for example, an arbitrary amount of time for users to make a choice before the video continues. Using the time stamps in URLs as described above, one can modify the playback of a video so that, for example, clicking (or even positioning the mouse over) a door will seek to the portion of the video that displays the door opening and the room behind it. This can increase the level of interactivity in a video to a degree similar to that of a computer game.
- The use of various types of annotations can be used to modify standard linear video viewing in a number of different ways. They could be used to implement, for example, a menu-style interface, in which the video displays several choices via annotations with links to other pages, and then pauses the video to allow the user to select one of the choices. The menu items could be still annotations, animated video annotations, and the like, and could be displayed in a traditional list of items, as separate labeled visual objects, or in a variety of other manners. They could also be used to implement branching storylines, where clicking on one annotation leads to one continuation of the video, and clicking on a different annotation leads to a different continuation. For example, annotations could be used to implement an interactive game of "rock, paper, scissors", in which, for instance, clicking on an annotation corresponding to a "rock", "paper", or "scissors" choice leads to a separate video or portion of the same video depicting a tie, a win, or a loss, respectively, each outcome potentially leading to the display of additional annotations representing a second round of the game. The menu items could also be used to implement multi-perspective storylines, wherein clicking on the annotated face of an actor leads to seeing the remainder of the story from that actor's perspective.
-
FIG. 3 depicts a user interface for manually creating the annotations ofFIG. 2 , according to one embodiment. Annotation icons 302-305 correspond to four annotation types (speech bubbles, text boxes, spotlights, and pauses, respectively); selecting one of them and then clicking on the playing video creates an annotation of that type at the location and time corresponding to the click. The annotation then has default values, such as text captions, time ranges, boundaries, and associated URLs. InFIG. 3 , editingregions annotations region 310, for example, comprises atext caption 310A, atime range 310B, and alink 310C. The link can be, for example, a page within the video service that denotes a watch page for a video or that denotes a channel displaying thumbnails for several related videos. Thetext caption 310A has been set to the value "Happy birthday mom" by the user, and thetime range 310B is set to last from 0:00:03, fifth frame, to 0:00:13, third frame, and thelink 310C does not yet have a specified value. Editing of annotations can also be accomplished graphically; for example, the boundary ofcallout 215 can be changed by dragging on thehandles 215A associated with the boundaries. - As an alternative or addition to manually creating the annotations using the user interface of
FIG. 3 , thevideo analysis module 152 ofFIG. 1 can be used to automatically detect temporal and spatial locations to add annotations, to determine their associated values, and/or to control the behavior of existing annotations. - One example for such analysis is face detection, which can be used in the video of
FIG. 3 to detect the face of the boy in the images as a human face and to suggest the creation of a text bubble in association therewith, or it could be used to automatically provide or suggest a caption describing the recognized face. - Another example could include applying object recognition methods based on local descriptor matching. (See, for example, "A Performance Evaluation of Local Descriptors", Mikolajczyk, K.; Schmid, C., IEEE Transactions on Pattern Analysis and Machine Intelligence, Volume 27, Issue 10:1615 - 1630). Such object recognition can identify instances of known textured objects, such as locations, buildings, books, CD covers, and the like. (Example images for training recognition of such objects can be readily found in product / location catalogs which associate the product name with one or more images of the product). Once an object, such as the cover of a particular CD, is detected, the manual annotation process can be simplified by providing an educated guess regarding the object's spatial and temporal positioning.
- Recognized objects can then be associated with annotations, such as links presenting more information, e.g. from a given viewpoint. For example, events can be presented from a national perspective by using object recognition to identify objects associated with a certain nationality and presenting associated information, e.g. associating, with the Indian team members of a cricket match, a link to the next event that the team will be participating in. As another example, an athlete recognized using object recognition can be associated with a link or other annotation data that provides statistics, personal information, etc. on the athlete.
- Additionally, in conjunction with a search index of a search engine such as Google™ or YouTube™, if an object in a video is indeed recognized, then a phrase describing that product could be executed against the search index and the top search result suggested as a link for the object (e.g., searching for the title of a recognized music CD and linking to a product search page corresponding to that title).
- In one embodiment, an annotation link corresponds to a search query so that if a user clicks on the annotation, the user will see a search result page for the query. For example, a user may view all videos posted by a person in the video who has been identified by the user and whose name has been used as a search term. This type of annotation allows the results page to be up to date since a search on a search term associated with an annotation will not always yield the same results page.
- Object recognition could further be used to identify locations of interest, and in combination with "geotagged" videos in which location information is embedded, videos related to the recognized location could be provided or suggested as links.
- Object recognition could further be augmented by tracking the movement of the object across frames, thereby moving any associated annotations along with it. For example, if the boy moved his position in the various frames of the video, object recognition could be used to track the boy's face as he moves and to automatically reposition the
text bubble 210 near the detected face in each frame. This would be a type of annotation that moves within the frame in connection with an object in the frame. In the case of a Flash player, analysis of the video would preferably be done on the server while display of the annotation in different frame locations during video play would generally be achieved within the player as the object moves within the video. - Yet another type of analysis is optical character recognition (OCR), the details of which are known to one of skill in the art. For example, words on a billboard could be recognized using OCR and a corresponding textual caption automatically provided or suggested for the billboard.
-
FIG. 4 illustrates steps involved in adding annotations to videos, according to one embodiment. Theclient 130 requests a video from thevideo server 108 using thenetwork 105. Thefront end server 124 of thevideo hosting server 108 receives the request and delegates to thevideo server 126, which obtains the video from thevideo database 128 and provides it 410 to theclient 130. In one embodiment, thevideo hosting server 108 then delegates to theannotation server 150 to provide the annotation user interface; in other embodiments, thevideo hosting server 108 requests the annotations for the video from theannotation server 150 and then itself provides the annotation user interface, providing any annotations created via the user interface to the annotation server for storage. In one embodiment, the provided annotation user interface differs depending on the identity of the user doing the annotation. For example, if the annotating user is not the owner of the video (e.g., the one who submitted the video to the video hosting server 108), then the user could be provided an editing interface such as that already described inFIG. 3 . In some embodiments, only owners of a video or people specified by the owner may annotate a video. In some embodiments, only owners of a video or categories of people specified by the owner (e.g., people on the owners friends list) may annotate a video. In some embodiments, anyone may annotate a video. If the annotating user is the owner of the video, or some other user with similar privileges, then a more full-featured annotation interface such as that inFIG. 5 can be provided. -
FIG. 5 illustrates anannotation interface 500 that both allows the addition of annotations and also provides information on all existing annotations associated with the video. In some embodiments, only an owner may use such an interface. In other embodiments, a wider group of users may use such an interface. Avideo area 505 displays the video, and annotation editing controls 507 allow the addition of annotations to the video in a manner similar to that of controls 302-305 inFIG. 3 . Anannotation list 510 displays a list of all the annotations currently associated with a video, including the type, the associated textual caption, the time of the video to which the annotation applies, the user who submitted the annotation, and the like. Avisual timeline 515 graphically displays the time locations of the various annotations associated with the video. For example, amarker 516 indicates the location of a newly-added Pause annotation, and dragging themarker 516 changes the duration and/or time location of the pause. - Referring again to
FIG. 4 , the determination of which type of annotation user interface to provide (e.g., that of the owner, of that of another user)-which can be used to control the degree to which annotation may be added-may involve the use of theauthentication server 170, which authenticates 420 the user. The authentication server decides in different ways in different embodiments what access to annotations a given user has. In one embodiment, theauthentication server 170 only allows creation of annotations by the owner of the video. In this embodiment, theauthentication server 170 consults theuser database 140 to determine the identity (e.g., the username) of the owner of the video and compares it to the identity of the currently active user. If the currently active user has no identity (e.g., is not signed in), or the identity does not match that of the owner of the video, then the ability to annotate is not provided. - In another embodiment, the owner of the video grants access to users by providing them with a special URL associated with that video. For example, referring again to
FIG. 5 , theowner interface 500 includes aURL area 520 that lists a URL associated with the video in theURL list 171. The owner may then copy this URL and distribute it as desired to other users who the owner wishes to have annotation abilities, e.g. by emailing the URL to friends, posting it on a web page available to friends, and the like. Then, when a user enters the URL, theauthentication server 170 compares the URL to those in theURL list 171 for the given video; if the URL matches, then an annotation user interface is provided. In case the URL becomes too widely-distributed and an excessive number of unwanted annotations are being added to the video, the owner may usebutton 525 to disable the addition of further annotations, in which case the URL becomes invalid for purposes of further annotation. - In yet another embodiment, the owner may grant annotation permissions to particular users of the
video hosting server 108, e.g. by specifying a list of authorized usernames. The permissions can be to annotate, in which case any user on the list would be provided with an annotation interface when viewing that video. In another embodiment, the permissions are to suggest annotations, in which case the user interface would allow tentative annotations to be added but not actually displayed during playback until approved by the owner or other authorized user. The permissions could also be restricted to allowing annotation of particular temporal portions or physical areas of the video. This can be implemented by allowing the owner to define a "collaborative region" in his or her video using the same spatial and temporal controls provided by the annotations editor, such as by specifying a time range using controls such as thetime range control 310B ofFIG. 3 and an area by graphically selecting the region in thevideo area 202. Data defining the collaborative region can then be stored, e.g., within theannotation database 154. With the collaborative region defined, other users determined to be collaborators of the video owner (e.g., those considered "friends" of the user) are permitted to add annotations to the video, but only within the spatial and temporal extent of the specified collaborative region. - In yet another embodiment, the access control lists need not be strictly predefined by the owner or other authorized users, but can be dynamically determined based on external factors. For example, the lists could be based on credibility scores of the user (the credibility scores being calculated by, e.g., monitoring how many previous annotations by this contributor were deleted by content owners, or by community moderation actions such as users expressing approval or disapproval of the user's video ratings, such as via "thumbs-up" or "thumb-down" indicators) or of those considered friends of the user in the user database 140 (e.g., based on activities such as active email exchanging, or on explicit indications of friendship, such as adding someone to a "friends" list),.
- In still another embodiment, annotations are defined in a layered approach in which the creator of the annotation determines visibility of the annotation at video playback time. In this approach, different users or groups of users may freely define their own annotations, but the resulting annotations will only be visible to those users or groups when the video is played.
- After the
authorization server 170 has determined which annotation interface the user is authorized to see-such as the interfaces ofFIGS. 3 or5 , or a basic playback interface not allowing the creation of annotations-theannotation server 150 then provides 430 that annotation interface to the user, optionally along with any pre-existing annotations for that video. If the interface allows the creation of annotations, then the user uses the interface to specify the properties of the annotations. The results are then transmitted to thevideo database 128, e.g. in response to the user selecting the publishbutton 525 ofFIG. 5 after having specified the desired annotations, which then receives 440 and stores the annotations. - A similar process occurs when viewing an annotated video. First, the
client 130 requests a video from thevideo server 108 using thenetwork 105. Thefront end server 124 of thevideo hosting server 108 receives the request and delegates to thevideo server 126, which obtains the video from thevideo database 128. Thevideo hosting server 108 then obtains the appropriate annotations from theannotation database 154 of the annotation server, optionally subject to authentication of the user by theauthorization server 170. In one embodiment, the video hosting server obtains all the annotations for the video as the video is being loaded. In other embodiments, annotations are streamed as the video progresses, or are sent in several predefined chunks. - The annotations that are appropriate can vary in different embodiments. In one embodiment, all annotations are provided, regardless of the user's identity. In another embodiment in which layers are employed, only those annotations created by the user viewing the video, or by members of a group to which the user belongs, are provided. The
annotation server 150 may also convert the annotations to a suitable format for theparticular client 130 based on knowledge about the client; for example, a translation of the text of the annotation can be performed if the client is in a locale with a language different from that of the annotation, and annotations not supported by the client, such as animated video annotations for a simple client limited to text, can be suppressed. - With the proper set of annotations selected and suitably formatted, the
annotation server 150 then provides these annotations to theclient 130, which displays them in conjunction with the playing video, thus modifying the appearance and/or behavior of the video, e.g. using the types of annotations described above in conjunction withFIGS. 2 and3 . For example, if theclient 130 encounters any ofannotation types FIG. 2 , it will display textual labels in association with a portion of the video designated by the annotation. If an annotation has an associated hyperlink, then theclient 130 will display the hyperlink and will take an action, such as displaying a web page linked to by the hyperlink, within a web browser, e.g. a web browser window in which the video and annotations were currently presented. If the annotation is of the Pause type, and theclient 130 reaches the beginning of the time period to which the Pause annotation corresponds, then theclient 130 halts playback of the video for a period of time specified by the Pause annotation, and then resumes playback after the expiration of the specified period of time. - It is appreciated that the exact components and arrangement thereof, the order of operations, and other aspects of the above description are purely for purposes of example, and a wide variety of alternative component arrangements and operation orders would be equally possible to one of skill in the art. For example, the
annotation server 150 ofFIG. 1 could be part of thevideo hosting server 108, a server on the same local network as the video hosting server, or on a remote network from the video hosting server. As another example, theauthentication server 170 could be separate from the video hosting server, or could be a component thereof. Further, someclients 130 could be configured not to communicate with theannotation server 150, or theannotation server 150 not to provide annotations to theclient 130, in which case theclient 130 obtains un-annotated video (e.g. clients in each country or language can have their own set of annotations). In some embodiments, theclient 130 can perform annotation offline, without a network connection to theannotation server 150, and later synchronize the annotations with theannotation server 150 when a network connection becomes available. - Reference in the specification to "one embodiment" or to "an embodiment" means that a particular feature, structure, or characteristic described in connection with the embodiments is included in at least one embodiment of the invention. The appearances of the phrase "in one embodiment" in various places in the specification are not necessarily all referring to the same embodiment.
- It should be noted that the process steps and instructions of the present invention can be embodied in software, firmware or hardware, and when embodied in software, can be downloaded to reside on and be operated from different platforms used by a variety of operating systems.
- The present invention also relates to an apparatus for performing the operations herein. This apparatus may be specially constructed for the required purposes, or it may comprise a general-purpose computer selectively activated or reconfigured by a computer program stored in the computer. Such a computer program may be stored in a computer readable storage medium, such as, but is not limited to, any type of disk including floppy disks, optical disks, CD-ROMs, magnetic-optical disks, read-only memories (ROMs), random access memories (RAMs), EPROMs, EEPROMs, magnetic or optical cards, application specific integrated circuits (ASICs), or any type of media suitable for storing electronic instructions, and each coupled to a computer system bus. Furthermore, the computers referred to in the specification may include a single processor or may be architectures employing multiple processor designs for increased computing capability.
Claims (15)
- A computer-implemented method for annotating a digital video stored in a video repository, the method comprising:identifying a visual object displayed within the video using visual object recognition;determining whether a user, who did not contribute the digital video to the video repository, is authorized to annotate the digital video;responsive to the user being authorized to annotate the digital video, providing to the user a first web based user interface portion for annotating the digital video, the first web based user interface portion comprising visual representations of a plurality of different annotation types and a visual suggestion to annotate the visual object;responsive to receiving a user selection of one of the annotation types and approval of the suggestion of annotating the visual object, providing to the user a second web-based user interface portion comprising at least one input area for specifying a URL for a new annotation for the visual object, the URL encoding a time stamp of a moment within the digital video;tracking a spatial position of the visual object across frames of the video to identify a plurality of spatial positions of the visual object as the visual object moves within the video;receiving a request from the user via the second user interface portion to add an annotation of the selected type to the visual object, the request comprising a designation of the URL for the annotation; andadding the annotation to the digital video such that the annotation is displayed during playback of the digital video and moves responsive to the tracked plurality of spatial positions of the visual object, and such that selection of the annotation causes playback of the digital video at the moment in the digital video specified by the time stamp.
- The computer-implemented method of claim 1, wherein determining whether the user is authorized to annotate the digital video comprises comparing a URL associated with the user to a URL associated with the digital video.
- The computer-implemented method of claim 1, wherein determining whether the user is authorized to annotate the digital video comprises determining whether the user is on a list of users authorized to annotate the digital video.
- The computer-implemented method of claim 1, wherein determining whether the user is authorized to annotate the digital video comprises monitoring actions of a contributor of the digital video with respect to the user.
- The computer-implemented method of claim 1, wherein determining whether the user is authorized to annotate the digital video comprises monitoring actions of other users with respect to the user.
- The computer-implemented method of claim 1, further comprising determining whether the user is authorized to annotate a particular temporal or spatial portion of the digital video.
- The computer-implemented method of claim 1, wherein determining whether the user is authorized to annotate the digital video comprises determining whether an owner of the video has disabled annotation for the digial video.
- The computer-implemented method of claim 1, further comprising:receiving a request to add a pause annotation for a time within the digital video, the pause annotation causing playback of the digital video to halt when the time is reached; orcreating an annotation associated with a visual object of the digital video, the annotation having a graphical appearance that when selected displays information associated with the visual object.
- The computer-implemented method of claim 1, further comprising: responsive to receiving a request for the digital video from a client: providing annotations that are associated with the digital video and that can be displayed by the client.
- The computer-implemented method of claim 1, further comprising: responsive to receiving a request for the digital video from a client: altering annotations that are associated with the digital video to be displayed in a different locale from a locale in which they were created.
- The computer-implemented method of claim 1, further comprising:
responsive to receiving a request for the digital video from a viewer:identifying annotations associated with the video;filtering the identified annotations by the identity of the viewer, thereby producing a modified set of annotations; andproviding the modified set of annotations to the viewer. - The computer-implemented method of claim 1, further comprising:
responsive to receiving a request for the digital video from a viewer:identifying annotations associated with the digital video;filtering the identified annotations by the identity of a group of which the viewer is a member, thereby producing a modified set of annotations; andproviding the modified set of annotations to the viewer. - The computer-implemented method of claim 1, wherein the request to add the annotation incorporates annotation data derived from optical character recognition.
- The computer-implemented method of claim 1, wherein the request to add the annotation incorporates annotation data derived from image object recognition.
- A computer readable storage medium storing a computer program executable by a processor for annotating a digital video stored in a video repository, for performing the method according to any one of claims 1 to 14.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US5845908P | 2008-06-03 | 2008-06-03 | |
US12/388,365 US8566353B2 (en) | 2008-06-03 | 2009-02-18 | Web-based system for collaborative generation of interactive videos |
PCT/US2009/042919 WO2009148756A1 (en) | 2008-06-03 | 2009-05-05 | A web-based system for collaborative generation of interactive videos |
Publications (3)
Publication Number | Publication Date |
---|---|
EP2300894A1 EP2300894A1 (en) | 2011-03-30 |
EP2300894A4 EP2300894A4 (en) | 2015-03-11 |
EP2300894B1 true EP2300894B1 (en) | 2019-01-09 |
Family
ID=41379936
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
EP09758919.6A Active EP2300894B1 (en) | 2008-06-03 | 2009-05-05 | A web-based system for collaborative generation of interactive videos |
Country Status (5)
Country | Link |
---|---|
US (4) | US8566353B2 (en) |
EP (1) | EP2300894B1 (en) |
CN (1) | CN102084319B (en) |
CA (1) | CA2726777C (en) |
WO (1) | WO2009148756A1 (en) |
Families Citing this family (224)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US8341112B2 (en) * | 2006-05-19 | 2012-12-25 | Microsoft Corporation | Annotation by search |
US10796093B2 (en) | 2006-08-08 | 2020-10-06 | Elastic Minds, Llc | Automatic generation of statement-response sets from conversational text using natural language processing |
US7559017B2 (en) | 2006-12-22 | 2009-07-07 | Google Inc. | Annotation framework for video |
US20080317346A1 (en) * | 2007-06-21 | 2008-12-25 | Microsoft Corporation | Character and Object Recognition with a Mobile Photographic Device |
WO2009081273A2 (en) * | 2007-12-22 | 2009-07-02 | John Andrew Vasilakos | Method and system for awarding user points in response to user interest |
US8181197B2 (en) | 2008-02-06 | 2012-05-15 | Google Inc. | System and method for voting on popular video intervals |
US8112702B2 (en) | 2008-02-19 | 2012-02-07 | Google Inc. | Annotating video intervals |
US20090217196A1 (en) * | 2008-02-21 | 2009-08-27 | Globalenglish Corporation | Web-Based Tool for Collaborative, Social Learning |
US8612469B2 (en) * | 2008-02-21 | 2013-12-17 | Globalenglish Corporation | Network-accessible collaborative annotation tool |
US10091460B2 (en) * | 2008-03-31 | 2018-10-02 | Disney Enterprises, Inc. | Asynchronous online viewing party |
CA2651464C (en) * | 2008-04-30 | 2017-10-24 | Crim (Centre De Recherche Informatique De Montreal) | Method and apparatus for caption production |
US8566353B2 (en) | 2008-06-03 | 2013-10-22 | Google Inc. | Web-based system for collaborative generation of interactive videos |
WO2009149442A1 (en) * | 2008-06-06 | 2009-12-10 | Divx, Inc. | Systems and methods for font file optimization for multimedia files |
US8224843B2 (en) | 2008-08-12 | 2012-07-17 | Morphism Llc | Collaborative, incremental specification of identities |
US20100095211A1 (en) * | 2008-09-17 | 2010-04-15 | Seth Kenvin | Method and System for Annotative Multimedia |
US8209396B1 (en) | 2008-12-10 | 2012-06-26 | Howcast Media, Inc. | Video player |
US8826117B1 (en) | 2009-03-25 | 2014-09-02 | Google Inc. | Web-based system for video editing |
US8132200B1 (en) | 2009-03-30 | 2012-03-06 | Google Inc. | Intra-video ratings |
US8108403B2 (en) * | 2009-04-03 | 2012-01-31 | International Business Machines Corporation | User engagement during large file uploads |
US8554848B2 (en) * | 2009-04-16 | 2013-10-08 | At&T Intellectual Property 1, L.P. | Collective asynchronous media review |
US9190110B2 (en) | 2009-05-12 | 2015-11-17 | JBF Interlude 2009 LTD | System and method for assembling a recorded composition |
US20110010397A1 (en) * | 2009-07-13 | 2011-01-13 | Prateek Kathpal | Managing annotations decoupled from local or remote sources |
US20110035683A1 (en) * | 2009-08-07 | 2011-02-10 | Larry Stead | Method and apparatus for synchronous, collaborative media consumption |
US20110072047A1 (en) * | 2009-09-21 | 2011-03-24 | Microsoft Corporation | Interest Learning from an Image Collection for Advertising |
US8510656B2 (en) * | 2009-10-29 | 2013-08-13 | Margery Kravitz Schwarz | Interactive storybook system and method |
US8316303B2 (en) * | 2009-11-10 | 2012-11-20 | At&T Intellectual Property I, L.P. | Method and apparatus for presenting media programs |
US8387088B2 (en) * | 2009-11-13 | 2013-02-26 | At&T Intellectual Property I, Lp | Method and apparatus for presenting media programs |
WO2012142323A1 (en) | 2011-04-12 | 2012-10-18 | Captimo, Inc. | Method and system for gesture based searching |
US20110176788A1 (en) * | 2009-12-18 | 2011-07-21 | Bliss John Stuart | Method and System for Associating an Object to a Moment in Time in a Digital Video |
EP2343668B1 (en) * | 2010-01-08 | 2017-10-04 | Deutsche Telekom AG | A method and system of processing annotated multimedia documents using granular and hierarchical permissions |
US9563850B2 (en) * | 2010-01-13 | 2017-02-07 | Yahoo! Inc. | Method and interface for displaying locations associated with annotations |
US9477667B2 (en) * | 2010-01-14 | 2016-10-25 | Mobdub, Llc | Crowdsourced multi-media data relationships |
US8799493B1 (en) | 2010-02-01 | 2014-08-05 | Inkling Systems, Inc. | Object oriented interactions |
WO2011097405A1 (en) * | 2010-02-03 | 2011-08-11 | Nik Software, Inc. | Narrative-based media organizing system for converting digital media into personal story |
US11232458B2 (en) | 2010-02-17 | 2022-01-25 | JBF Interlude 2009 LTD | System and method for data mining within interactive multimedia |
US20110289411A1 (en) * | 2010-05-24 | 2011-11-24 | Samsung Electronics Co., Ltd. | Method and system for recording user interactions with a video sequence |
US9703782B2 (en) | 2010-05-28 | 2017-07-11 | Microsoft Technology Licensing, Llc | Associating media with metadata of near-duplicates |
US8903798B2 (en) * | 2010-05-28 | 2014-12-02 | Microsoft Corporation | Real-time annotation and enrichment of captured video |
EP2719099A4 (en) | 2010-07-14 | 2017-05-17 | RMZ Development, LLC | Media sharing community |
CN101950578B (en) * | 2010-09-21 | 2012-11-07 | 北京奇艺世纪科技有限公司 | Method and device for adding video information |
US20120072845A1 (en) * | 2010-09-21 | 2012-03-22 | Avaya Inc. | System and method for classifying live media tags into types |
US20120078899A1 (en) * | 2010-09-27 | 2012-03-29 | Fontana James A | Systems and methods for defining objects of interest in multimedia content |
EP2437512B1 (en) * | 2010-09-29 | 2013-08-21 | TeliaSonera AB | Social television service |
US8799774B2 (en) * | 2010-10-07 | 2014-08-05 | International Business Machines Corporation | Translatable annotated presentation of a computer program operation |
US8559682B2 (en) | 2010-11-09 | 2013-10-15 | Microsoft Corporation | Building a person profile database |
US9343110B2 (en) | 2010-11-23 | 2016-05-17 | Levels Beyond | Dynamic synchronization tool |
US8589423B2 (en) | 2011-01-18 | 2013-11-19 | Red 5 Studios, Inc. | Systems and methods for generating enhanced screenshots |
KR101781861B1 (en) * | 2011-04-04 | 2017-09-26 | 엘지전자 주식회사 | Image display device and method of displaying text in the same |
US9678992B2 (en) | 2011-05-18 | 2017-06-13 | Microsoft Technology Licensing, Llc | Text to image translation |
CN102802055B (en) * | 2011-05-25 | 2016-06-01 | 阿里巴巴集团控股有限公司 | A kind of data interactive method based on Online Video and device |
US8737820B2 (en) | 2011-06-17 | 2014-05-27 | Snapone, Inc. | Systems and methods for recording content within digital video |
CN102279879A (en) * | 2011-07-28 | 2011-12-14 | 深圳市网合科技股份有限公司 | Device and method for validating program source information |
US20130036355A1 (en) * | 2011-08-04 | 2013-02-07 | Bryan Barton | System and method for extending video player functionality |
US8793313B2 (en) | 2011-09-08 | 2014-07-29 | Red 5 Studios, Inc. | Systems, methods and media for distributing peer-to-peer communications |
US9354763B2 (en) * | 2011-09-26 | 2016-05-31 | The University Of North Carolina At Charlotte | Multi-modal collaborative web-based video annotation system |
US10079039B2 (en) | 2011-09-26 | 2018-09-18 | The University Of North Carolina At Charlotte | Multi-modal collaborative web-based video annotation system |
US9641790B2 (en) * | 2011-10-17 | 2017-05-02 | Microsoft Technology Licensing, Llc | Interactive video program providing linear viewing experience |
US20130097643A1 (en) * | 2011-10-17 | 2013-04-18 | Microsoft Corporation | Interactive video |
JP5439455B2 (en) * | 2011-10-21 | 2014-03-12 | 富士フイルム株式会社 | Electronic comic editing apparatus, method and program |
DE102011055653A1 (en) * | 2011-11-23 | 2013-05-23 | nrichcontent UG (haftungsbeschränkt) | Method and device for processing media data |
US20150128195A1 (en) * | 2011-12-29 | 2015-05-07 | Sony Computer Entertainment Inc. | Video reproduction system |
US10713709B2 (en) * | 2012-01-30 | 2020-07-14 | E2Interactive, Inc. | Personalized webpage gifting system |
US9239848B2 (en) | 2012-02-06 | 2016-01-19 | Microsoft Technology Licensing, Llc | System and method for semantically annotating images |
US9983759B1 (en) * | 2012-02-29 | 2018-05-29 | Google Llc | Method and system for sharing virtual collaboration objects |
CN103297840A (en) * | 2012-03-01 | 2013-09-11 | 阿里巴巴集团控股有限公司 | Additional information display method and system based on video moving focus |
US9258380B2 (en) | 2012-03-02 | 2016-02-09 | Realtek Semiconductor Corp. | Cross-platform multimedia interaction system with multiple displays and dynamically-configured hierarchical servers and related method, electronic device and computer program product |
US20140059418A1 (en) * | 2012-03-02 | 2014-02-27 | Realtek Semiconductor Corp. | Multimedia annotation editing system and related method and computer program product |
US20130238993A1 (en) * | 2012-03-12 | 2013-09-12 | Scool T.V. Ltd. | Apparatus and method for adding content using a media player |
US8789120B2 (en) * | 2012-03-21 | 2014-07-22 | Sony Corporation | Temporal video tagging and distribution |
CN103188573A (en) * | 2012-04-01 | 2013-07-03 | 上海锐开信息科技有限公司 | Display system with shopping chaining function |
US8682809B2 (en) | 2012-04-18 | 2014-03-25 | Scorpcast, Llc | System and methods for providing user generated video reviews |
US9832519B2 (en) | 2012-04-18 | 2017-11-28 | Scorpcast, Llc | Interactive video distribution system and video player utilizing a client server architecture |
US10277933B2 (en) * | 2012-04-27 | 2019-04-30 | Arris Enterprises Llc | Method and device for augmenting user-input information related to media content |
US9386357B2 (en) * | 2012-04-27 | 2016-07-05 | Arris Enterprises, Inc. | Display of presentation elements |
US10389779B2 (en) | 2012-04-27 | 2019-08-20 | Arris Enterprises Llc | Information processing |
US10225300B2 (en) | 2012-06-10 | 2019-03-05 | Apple Inc. | Unified playback position |
US20130339857A1 (en) * | 2012-06-15 | 2013-12-19 | The Mad Video, Inc. | Modular and Scalable Interactive Video Player |
US20130346888A1 (en) * | 2012-06-22 | 2013-12-26 | Microsoft Corporation | Exposing user interface elements on search engine homepages |
US8632411B1 (en) | 2012-06-28 | 2014-01-21 | Red 5 Studios, Inc. | Exchanging virtual rewards for computing resources |
US8628424B1 (en) | 2012-06-28 | 2014-01-14 | Red 5 Studios, Inc. | Interactive spectator features for gaming environments |
US8834268B2 (en) * | 2012-07-13 | 2014-09-16 | Red 5 Studios, Inc. | Peripheral device control and usage in a broadcaster mode for gaming environments |
CN103797783B (en) * | 2012-07-17 | 2017-09-29 | 松下知识产权经营株式会社 | Comment information generating means and comment information generation method |
US8795086B2 (en) | 2012-07-20 | 2014-08-05 | Red 5 Studios, Inc. | Referee mode within gaming environments |
US20140033040A1 (en) * | 2012-07-24 | 2014-01-30 | Apple Inc. | Portable device with capability for note taking while outputting content |
US8475284B1 (en) | 2012-07-31 | 2013-07-02 | Scott Rudi | Dynamic views within gaming environments |
US9767087B1 (en) | 2012-07-31 | 2017-09-19 | Google Inc. | Video annotation system |
US10152467B2 (en) | 2012-08-13 | 2018-12-11 | Google Llc | Managing a sharing of media content among client computers |
CN103632691B (en) * | 2012-08-21 | 2017-07-25 | 联想(北京)有限公司 | A kind of media file playing method and electronic equipment |
US9237386B2 (en) | 2012-08-31 | 2016-01-12 | Google Inc. | Aiding discovery of program content by providing deeplinks into most interesting moments via social media |
US20140063339A1 (en) * | 2012-09-04 | 2014-03-06 | Google Inc. | In Browser Muxing and Demuxing For Video Playback |
US20170024097A1 (en) * | 2012-09-13 | 2017-01-26 | Bravo Ideas Digital Co., Ltd. | Method and Host Server for Creating a Composite Media File |
US8595317B1 (en) | 2012-09-14 | 2013-11-26 | Geofeedr, Inc. | System and method for generating, accessing, and updating geofeeds |
US9009619B2 (en) | 2012-09-19 | 2015-04-14 | JBF Interlude 2009 Ltd—Israel | Progress bar for branched videos |
CN109583591A (en) * | 2012-09-20 | 2019-04-05 | 伊夫维泽德公司 | Method and system for simplified knowledge engineering |
US20140096018A1 (en) * | 2012-09-28 | 2014-04-03 | Interactive Memories, Inc. | Methods for Recognizing Digital Images of Persons known to a Customer Creating an Image-Based Project through an Electronic Interface |
US9143823B2 (en) * | 2012-10-01 | 2015-09-22 | Google Inc. | Providing suggestions for optimizing videos to video owners |
US9082092B1 (en) | 2012-10-01 | 2015-07-14 | Google Inc. | Interactive digital media items with multiple storylines |
US9684431B2 (en) * | 2012-10-19 | 2017-06-20 | Apple Inc. | Sharing media content |
US8639767B1 (en) | 2012-12-07 | 2014-01-28 | Geofeedr, Inc. | System and method for generating and managing geofeed-based alerts |
US8655983B1 (en) | 2012-12-07 | 2014-02-18 | Geofeedr, Inc. | System and method for location monitoring based on organized geofeeds |
US20140164887A1 (en) * | 2012-12-12 | 2014-06-12 | Microsoft Corporation | Embedded content presentation |
US8935713B1 (en) * | 2012-12-17 | 2015-01-13 | Tubular Labs, Inc. | Determining audience members associated with a set of videos |
US20140188815A1 (en) * | 2013-01-03 | 2014-07-03 | Amazon Technologies, Inc | Annotation of Resources in a Distributed Execution Environment |
US9401947B1 (en) * | 2013-02-08 | 2016-07-26 | Google Inc. | Methods, systems, and media for presenting comments based on correlation with content |
US20140258472A1 (en) * | 2013-03-06 | 2014-09-11 | Cbs Interactive Inc. | Video Annotation Navigation |
US8850531B1 (en) | 2013-03-07 | 2014-09-30 | Geofeedia, Inc. | System and method for targeted messaging, workflow management, and digital rights management for geofeeds |
US8612533B1 (en) | 2013-03-07 | 2013-12-17 | Geofeedr, Inc. | System and method for creating and managing geofeeds |
US9307353B2 (en) | 2013-03-07 | 2016-04-05 | Geofeedia, Inc. | System and method for differentially processing a location input for content providers that use different location input formats |
WO2014142805A1 (en) * | 2013-03-12 | 2014-09-18 | PEARISO, Christopher | System and methods for facilitating the development and management of creative assets |
US9179199B2 (en) * | 2013-03-14 | 2015-11-03 | Apple Inc. | Media playback across multiple devices |
US20140279994A1 (en) * | 2013-03-14 | 2014-09-18 | Microsoft Corporation | Tagging digital content with queries |
US9317600B2 (en) | 2013-03-15 | 2016-04-19 | Geofeedia, Inc. | View of a physical space augmented with social media content originating from a geo-location of the physical space |
US10135887B1 (en) * | 2013-03-15 | 2018-11-20 | Cox Communications, Inc | Shared multimedia annotations for group-distributed video content |
US10042505B1 (en) * | 2013-03-15 | 2018-08-07 | Google Llc | Methods, systems, and media for presenting annotations across multiple videos |
US8862589B2 (en) | 2013-03-15 | 2014-10-14 | Geofeedia, Inc. | System and method for predicting a geographic origin of content and accuracy of geotags related to content obtained from social media and other content providers |
US10061482B1 (en) * | 2013-03-15 | 2018-08-28 | Google Llc | Methods, systems, and media for presenting annotations across multiple videos |
US8849935B1 (en) | 2013-03-15 | 2014-09-30 | Geofeedia, Inc. | Systems and method for generating three-dimensional geofeeds, orientation-based geofeeds, and geofeeds based on ambient conditions based on content provided by social media content providers |
US9257148B2 (en) | 2013-03-15 | 2016-02-09 | JBF Interlude 2009 LTD | System and method for synchronization of selectably presentable media streams |
US10489501B2 (en) * | 2013-04-11 | 2019-11-26 | Google Llc | Systems and methods for displaying annotated video content by mobile computing devices |
JP6179889B2 (en) * | 2013-05-16 | 2017-08-16 | パナソニックＩｐマネジメント株式会社 | Comment information generation device and comment display device |
WO2014185991A1 (en) * | 2013-05-17 | 2014-11-20 | Thomson Licensing | Method and system for producing a personalized project repository for content creators |
US9946712B2 (en) * | 2013-06-13 | 2018-04-17 | Google Llc | Techniques for user identification of and translation of media |
US10001904B1 (en) * | 2013-06-26 | 2018-06-19 | R3 Collaboratives, Inc. | Categorized and tagged video annotation |
US20150082203A1 (en) * | 2013-07-08 | 2015-03-19 | Truestream Kk | Real-time analytics, collaboration, from multiple video sources |
JP5809207B2 (en) | 2013-07-30 | 2015-11-10 | グリー株式会社 | Message communication program, message communication method, and message communication system |
US10448119B2 (en) | 2013-08-30 | 2019-10-15 | JBF Interlude 2009 LTD | Methods and systems for unfolding video pre-roll |
US9516259B2 (en) * | 2013-10-22 | 2016-12-06 | Google Inc. | Capturing media content in accordance with a viewer expression |
US20150134668A1 (en) * | 2013-11-14 | 2015-05-14 | Dragan Popovich | Index of Video Objects |
GB2520334B (en) * | 2013-11-18 | 2015-11-25 | Helen Bradley Lennon | A video broadcast system and a method of disseminating video content |
KR101524379B1 (en) * | 2013-12-27 | 2015-06-04 | 인하대학교 산학협력단 | System and method for the caption replacement of the released video for the interactive service |
US9890089B2 (en) | 2014-03-11 | 2018-02-13 | General Electric Company | Compositions and methods for thermal spraying a hermetic rare earth environmental barrier coating |
US9792026B2 (en) | 2014-04-10 | 2017-10-17 | JBF Interlude 2009 LTD | Dynamic timeline for branched video |
US9653115B2 (en) | 2014-04-10 | 2017-05-16 | JBF Interlude 2009 LTD | Systems and methods for creating linear video from branched video |
WO2015161487A1 (en) * | 2014-04-24 | 2015-10-29 | Nokia Technologies Oy | Apparatus, method, and computer program product for video enhanced photo browsing |
CN103997691B (en) * | 2014-06-02 | 2016-01-13 | 合一网络技术(北京)有限公司 | The method and system of video interactive |
US10649634B2 (en) * | 2014-06-06 | 2020-05-12 | International Business Machines Corporation | Indexing and annotating a usability test recording |
EP3162080A1 (en) * | 2014-06-25 | 2017-05-03 | Thomson Licensing | Annotation method and corresponding device, computer program product and storage medium |
US9860578B2 (en) * | 2014-06-25 | 2018-01-02 | Google Inc. | Methods, systems, and media for recommending collaborators of media content based on authenticated media content input |
CN105306501A (en) * | 2014-06-26 | 2016-02-03 | 国际商业机器公司 | Method and system for performing interactive update on multimedia data |
JP6039613B2 (en) * | 2014-07-22 | 2016-12-07 | ヤフー株式会社 | Display program, terminal device, display method, and distribution device |
CN105373938A (en) * | 2014-08-27 | 2016-03-02 | 阿里巴巴集团控股有限公司 | Method for identifying commodity in video image and displaying information, device and system |
US10306319B2 (en) * | 2014-09-09 | 2019-05-28 | Google Llc | Collaboration between a broadcaster and an audience for a broadcast |
US9740793B2 (en) * | 2014-09-16 | 2017-08-22 | International Business Machines Corporation | Exposing fragment identifiers |
US9792957B2 (en) | 2014-10-08 | 2017-10-17 | JBF Interlude 2009 LTD | Systems and methods for dynamic video bookmarking |
US11412276B2 (en) | 2014-10-10 | 2022-08-09 | JBF Interlude 2009 LTD | Systems and methods for parallel track transitions |
US10140379B2 (en) | 2014-10-27 | 2018-11-27 | Chegg, Inc. | Automated lecture deconstruction |
CN105631914A (en) * | 2014-10-31 | 2016-06-01 | 鸿富锦精密工业(武汉)有限公司 | Comic creation system and method |
US10055473B2 (en) * | 2014-11-07 | 2018-08-21 | Core-Apps, Llc | Systems for allowing annotation in real time |
CN107005724B (en) | 2014-12-03 | 2020-09-18 | 索尼公司 | Information processing apparatus, information processing method, and program |
USD765672S1 (en) * | 2014-12-08 | 2016-09-06 | Kpmg Llp | Electronic device with portfolio risk view graphical user interface |
CN104469398B (en) * | 2014-12-09 | 2015-12-30 | 北京清源新创科技有限公司 | A kind of Internet video picture processing method and device |
US10773329B2 (en) | 2015-01-20 | 2020-09-15 | Illinois Tool Works Inc. | Multiple input welding vision system |
US10387834B2 (en) | 2015-01-21 | 2019-08-20 | Palantir Technologies Inc. | Systems and methods for accessing and storing snapshots of a remote application in a document |
WO2016144741A1 (en) | 2015-03-06 | 2016-09-15 | Illinois Tool Works Inc. | Sensor assisted head mounted displays for welding |
WO2016144744A1 (en) | 2015-03-09 | 2016-09-15 | Illinois Tool Works Inc. | Methods and apparatus to provide visual information associated with welding operations |
US9998510B2 (en) * | 2015-03-20 | 2018-06-12 | Walter Partos | Video-based social interaction system |
US9977242B2 (en) | 2015-03-26 | 2018-05-22 | Illinois Tool Works Inc. | Control of mediated reality welding system based on lighting conditions |
CN104811814B (en) | 2015-04-28 | 2019-01-29 | 腾讯科技（北京）有限公司 | Information processing method and system, client and server based on video playing |
US10582265B2 (en) | 2015-04-30 | 2020-03-03 | JBF Interlude 2009 LTD | Systems and methods for nonlinear video playback using linear real-time video players |
US10185464B2 (en) * | 2015-05-28 | 2019-01-22 | Microsoft Technology Licensing, Llc | Pausing transient user interface elements based on hover information |
CN104936034B (en) * | 2015-06-11 | 2019-07-05 | 三星电子（中国）研发中心 | Information input method and device based on video |
US10363632B2 (en) | 2015-06-24 | 2019-07-30 | Illinois Tool Works Inc. | Time of flight camera for welding machine vision |
US9485318B1 (en) | 2015-07-29 | 2016-11-01 | Geofeedia, Inc. | System and method for identifying influential social media and providing location-based alerts |
US10606941B2 (en) | 2015-08-10 | 2020-03-31 | Open Text Holdings, Inc. | Annotating documents on a mobile device |
US10460765B2 (en) | 2015-08-26 | 2019-10-29 | JBF Interlude 2009 LTD | Systems and methods for adaptive and responsive video |
EP3354015A1 (en) * | 2015-09-23 | 2018-08-01 | Edoardo Rizzi | Communication device and method |
CN105338419B (en) * | 2015-10-29 | 2018-07-31 | 网易传媒科技（北京）有限公司 | A kind of generation method and equipment of the subtitle collection of choice specimens |
US20170131851A1 (en) * | 2015-11-10 | 2017-05-11 | FLX Media, LLC | Integrated media display and content integration system |
US10140271B2 (en) | 2015-12-16 | 2018-11-27 | Telltale, Incorporated | Dynamic adaptation of a narrative across different types of digital media |
US11164548B2 (en) | 2015-12-22 | 2021-11-02 | JBF Interlude 2009 LTD | Intelligent buffering of large-scale video |
US11128853B2 (en) | 2015-12-22 | 2021-09-21 | JBF Interlude 2009 LTD | Seamless transitions in large-scale video |
US10089289B2 (en) | 2015-12-29 | 2018-10-02 | Palantir Technologies Inc. | Real-time document annotation |
US10068617B2 (en) * | 2016-02-10 | 2018-09-04 | Microsoft Technology Licensing, Llc | Adding content to a media timeline |
US10462202B2 (en) | 2016-03-30 | 2019-10-29 | JBF Interlude 2009 LTD | Media stream rate synchronization |
US10226703B2 (en) * | 2016-04-01 | 2019-03-12 | Activision Publishing, Inc. | System and method of generating and providing interactive annotation items based on triggering events in a video game |
US11856271B2 (en) | 2016-04-12 | 2023-12-26 | JBF Interlude 2009 LTD | Symbiotic interactive video |
CN105933650A (en) * | 2016-04-25 | 2016-09-07 | 北京旷视科技有限公司 | Video monitoring system and method |
CN105847995B (en) * | 2016-05-16 | 2020-07-28 | 上海幻电信息科技有限公司 | Method for jumping video position through barrage anchor point |
US9786027B1 (en) | 2016-06-16 | 2017-10-10 | Waygate, Inc. | Predictive bi-adaptive streaming of real-time interactive computer graphics content |
US10218760B2 (en) | 2016-06-22 | 2019-02-26 | JBF Interlude 2009 LTD | Dynamic summary generation for real-time switchable videos |
PL3288036T3 (en) * | 2016-08-22 | 2021-11-02 | Nokia Technologies Oy | An apparatus and associated methods |
US11050809B2 (en) | 2016-12-30 | 2021-06-29 | JBF Interlude 2009 LTD | Systems and methods for dynamic weighting of branched video paths |
JP6219548B1 (en) * | 2017-03-31 | 2017-10-25 | 株式会社ドワンゴ | Virtual processing server, virtual processing server control method, content distribution system, and terminal device application program |
WO2018183765A1 (en) | 2017-04-01 | 2018-10-04 | Projansky Daniel | System and method for creation and control of interactive user interfaces |
CN107340944B (en) * | 2017-05-19 | 2019-03-26 | 腾讯科技（深圳）有限公司 | The display methods and device of interface |
US10721503B2 (en) * | 2017-06-09 | 2020-07-21 | Sony Interactive Entertainment LLC | Systems and methods for operating a streaming service to provide community spaces for media content items |
US10805684B2 (en) * | 2017-06-21 | 2020-10-13 | mindHIVE Inc. | Systems and methods for creating and editing multi-component media |
US10299013B2 (en) * | 2017-08-01 | 2019-05-21 | Disney Enterprises, Inc. | Media content annotation |
US20190069006A1 (en) * | 2017-08-29 | 2019-02-28 | Western Digital Technologies, Inc. | Seeking in live-transcoded videos |
WO2019066678A1 (en) * | 2017-09-29 | 2019-04-04 | Ringcentral, Inc. (A Delaware Corporation) | Systems and methods for enabling participants in an audio or video conference session |
CN107948760B (en) * | 2017-11-30 | 2021-01-29 | 上海哔哩哔哩科技有限公司 | Bullet screen play control method, server and bullet screen play control system |
GB2569179A (en) * | 2017-12-08 | 2019-06-12 | John Acourt Christopher Osman | Method for editing digital image sequences |
US10257578B1 (en) | 2018-01-05 | 2019-04-09 | JBF Interlude 2009 LTD | Dynamic library display for interactive videos |
JP6908573B2 (en) * | 2018-02-06 | 2021-07-28 | グリー株式会社 | Game processing system, game processing method, and game processing program |
US10981067B2 (en) | 2018-02-06 | 2021-04-20 | Gree, Inc. | Game processing system, method of processing game, and storage medium storing program for processing game |
US11539992B2 (en) * | 2018-02-28 | 2022-12-27 | Google Llc | Auto-adjust playback speed and contextual information |
GB201804383D0 (en) | 2018-03-19 | 2018-05-02 | Microsoft Technology Licensing Llc | Multi-endpoint mixed reality meetings |
CN108737904B (en) * | 2018-04-13 | 2021-06-22 | 维沃移动通信有限公司 | Video data processing method and mobile terminal |
EP3564888A1 (en) * | 2018-05-04 | 2019-11-06 | Hotmart B.V. | Methods and systems for displaying a form associated with a video |
US11601721B2 (en) | 2018-06-04 | 2023-03-07 | JBF Interlude 2009 LTD | Interactive video dynamic adaptation and user profiling |
CN109068148A (en) * | 2018-09-03 | 2018-12-21 | 视联动力信息技术股份有限公司 | A kind of method and apparatus of video processing |
US11550951B2 (en) * | 2018-09-18 | 2023-01-10 | Inspired Patents, Llc | Interoperable digital social recorder of multi-threaded smart routed media |
CN109274999A (en) * | 2018-10-08 | 2019-01-25 | 腾讯科技（深圳）有限公司 | A kind of video playing control method, device, equipment and medium |
US11450233B2 (en) | 2019-02-19 | 2022-09-20 | Illinois Tool Works Inc. | Systems for simulating joining operations using mobile devices |
US11521512B2 (en) | 2019-02-19 | 2022-12-06 | Illinois Tool Works Inc. | Systems for simulating joining operations using mobile devices |
US10893339B2 (en) | 2019-02-26 | 2021-01-12 | Capital One Services, Llc | Platform to provide supplemental media content based on content of a media stream and a user accessing the media stream |
US11141656B1 (en) * | 2019-03-29 | 2021-10-12 | Amazon Technologies, Inc. | Interface with video playback |
US11490047B2 (en) | 2019-10-02 | 2022-11-01 | JBF Interlude 2009 LTD | Systems and methods for dynamically adjusting video aspect ratios |
US11620334B2 (en) | 2019-11-18 | 2023-04-04 | International Business Machines Corporation | Commercial video summaries using crowd annotation |
US11721231B2 (en) | 2019-11-25 | 2023-08-08 | Illinois Tool Works Inc. | Weld training simulations using mobile devices, modular workpieces, and simulated welding equipment |
US11322037B2 (en) | 2019-11-25 | 2022-05-03 | Illinois Tool Works Inc. | Weld training simulations using mobile devices, modular workpieces, and simulated welding equipment |
US11245961B2 (en) | 2020-02-18 | 2022-02-08 | JBF Interlude 2009 LTD | System and methods for detecting anomalous activities for interactive videos |
CN113282816A (en) * | 2020-02-20 | 2021-08-20 | 北京字节跳动网络技术有限公司 | Page operation processing method, device, equipment and storage medium |
US11200919B2 (en) | 2020-03-10 | 2021-12-14 | Sony Group Corporation | Providing a user interface for video annotation tools |
US11355158B2 (en) * | 2020-05-15 | 2022-06-07 | Genius Sports Ss, Llc | Asynchronous video collaboration |
JP7394143B2 (en) * | 2020-06-24 | 2023-12-07 | バイドゥ オンライン ネットワーク テクノロジー（ペキン） カンパニー リミテッド | Video material creation method and device, electronic equipment, computer-readable storage medium, and computer program |
CN112153439A (en) * | 2020-09-27 | 2020-12-29 | 北京字跳网络技术有限公司 | Interactive video processing method, device and equipment and readable storage medium |
JP7208695B2 (en) * | 2020-10-27 | 2023-01-19 | Ａｍａｔｅｌｕｓ株式会社 | Video distribution device, video distribution system, video distribution method, and program |
US11700426B2 (en) * | 2021-02-23 | 2023-07-11 | Firefly 14, Llc | Virtual platform for recording and displaying responses and reactions to audiovisual contents |
US11263385B1 (en) * | 2021-03-24 | 2022-03-01 | Ebay Inc. | Web browser extension for linking images to webpages |
US20220377413A1 (en) * | 2021-05-21 | 2022-11-24 | Rovi Guides, Inc. | Methods and systems for personalized content based on captured gestures |
US11882337B2 (en) | 2021-05-28 | 2024-01-23 | JBF Interlude 2009 LTD | Automated platform for generating interactive videos |
US11934477B2 (en) | 2021-09-24 | 2024-03-19 | JBF Interlude 2009 LTD | Video player integration within websites |
US11949923B1 (en) * | 2022-12-19 | 2024-04-02 | Adobe Inc. | Trigger based digital content caching |
Citations (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
WO2001020466A1 (en) * | 1999-09-15 | 2001-03-22 | Hotv Inc. | Method and apparatus for integrating animation in interactive video |
Family Cites Families (161)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
DE69222102T2 (en) | 1991-08-02 | 1998-03-26 | Grass Valley Group | Operator interface for video editing system for the display and interactive control of video material |
JPH05197573A (en) | 1991-08-26 | 1993-08-06 | Hewlett Packard Co <Hp> | Task controlling system with task oriented paradigm |
GB2270242A (en) | 1992-08-29 | 1994-03-02 | Ibm | A method of editing for an object oriented computer system |
US5339393A (en) | 1993-04-15 | 1994-08-16 | Sony Electronics, Inc. | Graphical user interface for displaying available source material for editing |
US5996121A (en) * | 1993-07-28 | 1999-12-07 | Harris; Eunice | Convertible coat |
US5664216A (en) | 1994-03-22 | 1997-09-02 | Blumenau; Trevor | Iconic audiovisual data editing environment |
US5465353A (en) * | 1994-04-01 | 1995-11-07 | Ricoh Company, Ltd. | Image matching and retrieval by multi-access redundant hashing |
US5600775A (en) | 1994-08-26 | 1997-02-04 | Emotion, Inc. | Method and apparatus for annotating full motion video and other indexed data structures |
US5812642A (en) | 1995-07-12 | 1998-09-22 | Leroy; David J. | Audience response monitor and analysis system and method |
US5708845A (en) * | 1995-09-29 | 1998-01-13 | Wistendahl; Douglass A. | System for mapping hot spots in media content for interactive digital media program |
US5966121A (en) * | 1995-10-12 | 1999-10-12 | Andersen Consulting Llp | Interactive hypervideo editing system and interface |
US5732184A (en) | 1995-10-20 | 1998-03-24 | Digital Processing Systems, Inc. | Video and audio cursor video editing system |
US6570587B1 (en) * | 1996-07-26 | 2003-05-27 | Veon Ltd. | System and method and linking information to a video |
US20030093790A1 (en) | 2000-03-28 | 2003-05-15 | Logan James D. | Audio and video program recording, editing and playback systems using metadata |
US20020120925A1 (en) | 2000-03-28 | 2002-08-29 | Logan James D. | Audio and video program recording, editing and playback systems using metadata |
US6956573B1 (en) | 1996-11-15 | 2005-10-18 | Sarnoff Corporation | Method and apparatus for efficiently representing storing and accessing video information |
US6006241A (en) | 1997-03-14 | 1999-12-21 | Microsoft Corporation | Production of a video stream with synchronized annotations over a computer network |
US6546405B2 (en) | 1997-10-23 | 2003-04-08 | Microsoft Corporation | Annotating temporally-dimensioned multimedia content |
US6792618B1 (en) | 1998-03-02 | 2004-09-14 | Lucent Technologies Inc. | Viewer customization of displayed programming based on transmitted URLs |
US6173287B1 (en) | 1998-03-11 | 2001-01-09 | Digital Equipment Corporation | Technique for ranking multimedia annotations of interest |
US6289346B1 (en) | 1998-03-12 | 2001-09-11 | At&T Corp. | Apparatus and method for a bookmarking system |
US6295092B1 (en) | 1998-07-30 | 2001-09-25 | Cbs Corporation | System for analyzing television programs |
US6144375A (en) | 1998-08-14 | 2000-11-07 | Praja Inc. | Multi-perspective viewer for content-based interactivity |
AU5926499A (en) * | 1998-09-15 | 2000-04-03 | Microsoft Corporation | Interactive playlist generation using annotations |
US6956593B1 (en) * | 1998-09-15 | 2005-10-18 | Microsoft Corporation | User interface for creating, viewing and temporally positioning annotations for media content |
US6357042B2 (en) | 1998-09-16 | 2002-03-12 | Anand Srinivasan | Method and apparatus for multiplexing separately-authored metadata for insertion into a video data stream |
US20020059218A1 (en) | 1999-01-26 | 2002-05-16 | Katherine Grace August | System and method for obtaining real time survey information for media programming using input device |
KR100326400B1 (en) * | 1999-05-19 | 2002-03-12 | 김광수 | Method for generating caption location information, method for searching thereby, and reproducing apparatus using the methods |
US6415438B1 (en) * | 1999-10-05 | 2002-07-02 | Webtv Networks, Inc. | Trigger having a time attribute |
US7367042B1 (en) | 2000-02-29 | 2008-04-29 | Goldpocket Interactive, Inc. | Method and apparatus for hyperlinking in a television broadcast |
US7055168B1 (en) | 2000-05-03 | 2006-05-30 | Sharp Laboratories Of America, Inc. | Method for interpreting and executing user preferences of audiovisual information |
US7548565B2 (en) | 2000-07-24 | 2009-06-16 | Vmark, Inc. | Method and apparatus for fast metadata generation, delivery and access for live broadcast program |
WO2002008948A2 (en) | 2000-07-24 | 2002-01-31 | Vivcom, Inc. | System and method for indexing, searching, identifying, and editing portions of electronic multimedia files |
JP2002163143A (en) * | 2000-07-28 | 2002-06-07 | Any One Wireless Co Ltd | Content reformatting system and its method for radio site |
US20020065678A1 (en) | 2000-08-25 | 2002-05-30 | Steven Peliotis | iSelect video |
EP1317857A1 (en) | 2000-08-30 | 2003-06-11 | Watchpoint Media Inc. | A method and apparatus for hyperlinking in a television broadcast |
US7207006B1 (en) * | 2000-09-01 | 2007-04-17 | International Business Machines Corporation | Run-time hypervideo hyperlink indicator options in hypervideo players |
ATE451691T1 (en) | 2000-09-08 | 2009-12-15 | Koninkl Philips Electronics Nv | DEVICE FOR REPRODUCING AN INFORMATION SIGNAL STORED ON A RECORDING MEDIUM |
US8020183B2 (en) | 2000-09-14 | 2011-09-13 | Sharp Laboratories Of America, Inc. | Audiovisual management system |
US6774908B2 (en) * | 2000-10-03 | 2004-08-10 | Creative Frontier Inc. | System and method for tracking an object in a video and linking information thereto |
US7254605B1 (en) | 2000-10-26 | 2007-08-07 | Austen Services Llc | Method of modulating the transmission frequency in a real time opinion research network |
US6457909B1 (en) * | 2000-12-22 | 2002-10-01 | Shulin Xu | Multi-purpose anchor bolt assembly |
US7032178B1 (en) | 2001-03-30 | 2006-04-18 | Gateway Inc. | Tagging content for different activities |
US7080139B1 (en) | 2001-04-24 | 2006-07-18 | Fatbubble, Inc | Method and apparatus for selectively sharing and passively tracking communication device experiences |
CN1332556A (en) * | 2001-04-27 | 2002-01-23 | 清华大学 | Channel transmission method for ground digital multimeldia television broadcast system |
US20040138946A1 (en) | 2001-05-04 | 2004-07-15 | Markus Stolze | Web page annotation systems |
US20020188630A1 (en) * | 2001-05-21 | 2002-12-12 | Autodesk, Inc. | Method and apparatus for annotating a sequence of frames |
WO2002101584A2 (en) | 2001-06-11 | 2002-12-19 | C-Burn Systems Ltd | Selecting tracks from a jukebox via a wireless communications device |
US20030126136A1 (en) | 2001-06-22 | 2003-07-03 | Nosa Omoigui | System and method for knowledge retrieval, management, delivery and presentation |
TW520602B (en) | 2001-06-28 | 2003-02-11 | Ulead Systems Inc | Device and method of editing video program |
US20030018668A1 (en) | 2001-07-20 | 2003-01-23 | International Business Machines Corporation | Enhanced transcoding of structured documents through use of annotation techniques |
WO2003019325A2 (en) | 2001-08-31 | 2003-03-06 | Kent Ridge Digital Labs | Time-based media navigation system |
US7343487B2 (en) | 2001-10-10 | 2008-03-11 | Nokia Corporation | Datacast distribution system |
US7203380B2 (en) | 2001-11-16 | 2007-04-10 | Fuji Xerox Co., Ltd. | Video production and compaction with collage picture frame user interface |
US7180623B2 (en) | 2001-12-03 | 2007-02-20 | Canon Kabushiki Kaisha | Method and apparatus for print error recovery |
US20030107592A1 (en) | 2001-12-11 | 2003-06-12 | Koninklijke Philips Electronics N.V. | System and method for retrieving information related to persons in video programs |
US20030112276A1 (en) | 2001-12-19 | 2003-06-19 | Clement Lau | User augmentation of content |
US7137062B2 (en) | 2001-12-28 | 2006-11-14 | International Business Machines Corporation | System and method for hierarchical segmentation with latent semantic indexing in scale space |
US20040205482A1 (en) | 2002-01-24 | 2004-10-14 | International Business Machines Corporation | Method and apparatus for active annotation of multimedia content |
US7424715B1 (en) * | 2002-01-28 | 2008-09-09 | Verint Americas Inc. | Method and system for presenting events associated with recorded data exchanged between a server and a user |
US6835311B2 (en) | 2002-01-31 | 2004-12-28 | Koslow Technologies Corporation | Microporous filter media, filtration systems containing same, and methods of making and using |
JP3982295B2 (en) | 2002-03-20 | 2007-09-26 | 日本電信電話株式会社 | Video comment input / display method and system, client device, video comment input / display program, and recording medium therefor |
US7243301B2 (en) * | 2002-04-10 | 2007-07-10 | Microsoft Corporation | Common annotation framework |
US6988245B2 (en) | 2002-06-18 | 2006-01-17 | Koninklijke Philips Electronics N.V. | System and method for providing videomarks for a video program |
IL150808A0 (en) * | 2002-07-18 | 2003-02-12 | Kipee Kids Interactive Product | Dvd games on a tv |
US7149755B2 (en) | 2002-07-29 | 2006-12-12 | Hewlett-Packard Development Company, Lp. | Presenting a collection of media objects |
US7257774B2 (en) | 2002-07-30 | 2007-08-14 | Fuji Xerox Co., Ltd. | Systems and methods for filtering and/or viewing collaborative indexes of recorded media |
WO2004055647A2 (en) | 2002-12-13 | 2004-07-01 | Applied Minds, Inc. | Meta-web |
US6993347B2 (en) | 2002-12-17 | 2006-01-31 | International Business Machines Corporation | Dynamic media interleaving |
US8307273B2 (en) | 2002-12-30 | 2012-11-06 | The Board Of Trustees Of The Leland Stanford Junior University | Methods and apparatus for interactive network sharing of digital video content |
US7823058B2 (en) | 2002-12-30 | 2010-10-26 | The Board Of Trustees Of The Leland Stanford Junior University | Methods and apparatus for interactive point-of-view authoring of digital video content |
US7131059B2 (en) | 2002-12-31 | 2006-10-31 | Hewlett-Packard Development Company, L.P. | Scalably presenting a collection of media objects |
US7383497B2 (en) | 2003-01-21 | 2008-06-03 | Microsoft Corporation | Random access editing of media |
US7904797B2 (en) | 2003-01-21 | 2011-03-08 | Microsoft Corporation | Rapid media group annotation |
US7739597B2 (en) | 2003-02-24 | 2010-06-15 | Microsoft Corporation | Interactive media frame display |
US20040181545A1 (en) | 2003-03-10 | 2004-09-16 | Yining Deng | Generating and rendering annotated video files |
US8392834B2 (en) * | 2003-04-09 | 2013-03-05 | Hewlett-Packard Development Company, L.P. | Systems and methods of authoring a multimedia file |
US20040205547A1 (en) | 2003-04-12 | 2004-10-14 | Feldt Kenneth Charles | Annotation process for message enabled digital content |
EP2594322A3 (en) * | 2003-06-02 | 2013-12-04 | Disney Enterprises, Inc. | System and method of interactive video playback |
US8321470B2 (en) | 2003-06-20 | 2012-11-27 | International Business Machines Corporation | Heterogeneous multi-level extendable indexing for general purpose annotation systems |
US7418656B1 (en) | 2003-10-03 | 2008-08-26 | Adobe Systems Incorporated | Dynamic annotations for electronics documents |
US20050097451A1 (en) * | 2003-11-03 | 2005-05-05 | Cormack Christopher J. | Annotating media content with user-specified information |
US7784069B2 (en) | 2003-12-01 | 2010-08-24 | International Business Machines Corporation | Selecting divergent storylines using branching techniques |
EP1704515A4 (en) | 2003-12-12 | 2008-05-07 | Medic4All A G | Method and system for providing medical assistance to a traveler |
IL159383A0 (en) * | 2003-12-16 | 2004-06-01 | Laryngoscope with time indicating means and method for use thereof | |
US20050203892A1 (en) | 2004-03-02 | 2005-09-15 | Jonathan Wesley | Dynamically integrating disparate systems and providing secure data sharing |
KR101222294B1 (en) | 2004-03-15 | 2013-01-15 | 야후! 인크. | Search systems and methods with integration of user annotations |
US7697026B2 (en) | 2004-03-16 | 2010-04-13 | 3Vr Security, Inc. | Pipeline architecture for analyzing multiple video streams |
JP2005352933A (en) | 2004-06-14 | 2005-12-22 | Fuji Xerox Co Ltd | Display arrangement, system, and display method |
US8438157B2 (en) | 2004-06-28 | 2013-05-07 | International Business Machines Corporation | System and method for previewing relevance of streaming data |
US20050289469A1 (en) * | 2004-06-28 | 2005-12-29 | Chandler Roger D | Context tagging apparatus, systems, and methods |
US20060059120A1 (en) | 2004-08-27 | 2006-03-16 | Ziyou Xiong | Identifying video highlights using audio-visual objects |
US20070118794A1 (en) | 2004-09-08 | 2007-05-24 | Josef Hollander | Shared annotation system and method |
US20060064733A1 (en) * | 2004-09-20 | 2006-03-23 | Norton Jeffrey R | Playing an audiovisual work with dynamic choosing |
EP1797722B1 (en) | 2004-10-05 | 2019-05-29 | Vectormax Corporation | Adaptive overlapped block matching for accurate motion compensation |
US7472341B2 (en) | 2004-11-08 | 2008-12-30 | International Business Machines Corporation | Multi-user, multi-timed collaborative annotation |
JP2006155384A (en) | 2004-11-30 | 2006-06-15 | Nippon Telegr & Teleph Corp <Ntt> | Video comment input/display method and device, program, and storage medium with program stored |
JP4353084B2 (en) | 2004-11-30 | 2009-10-28 | 日本電信電話株式会社 | Video reproduction method, apparatus and program |
JP4353083B2 (en) | 2004-11-30 | 2009-10-28 | 日本電信電話株式会社 | Inter-viewer communication method, apparatus and program |
US20060161838A1 (en) * | 2005-01-14 | 2006-07-20 | Ronald Nydam | Review of signature based content |
US9275052B2 (en) * | 2005-01-19 | 2016-03-01 | Amazon Technologies, Inc. | Providing annotations of a digital work |
US8131647B2 (en) * | 2005-01-19 | 2012-03-06 | Amazon Technologies, Inc. | Method and system for providing annotations of a digital work |
US20060218590A1 (en) | 2005-03-10 | 2006-09-28 | Sbc Knowledge Ventures, L.P. | System and method for displaying an electronic program guide |
US20060286536A1 (en) * | 2005-04-01 | 2006-12-21 | Sherman Mohler | System and method for regulating use of content and content styles in a distributed learning system |
US7769819B2 (en) | 2005-04-20 | 2010-08-03 | Videoegg, Inc. | Video editing with timeline representations |
US7636883B2 (en) | 2005-05-18 | 2009-12-22 | International Business Machines Corporation | User form based automated and guided data collection |
US20080005064A1 (en) | 2005-06-28 | 2008-01-03 | Yahoo! Inc. | Apparatus and method for content annotation and conditional annotation retrieval in a search context |
US8086605B2 (en) * | 2005-06-28 | 2011-12-27 | Yahoo! Inc. | Search engine with augmented relevance ranking by community participation |
CN101253777A (en) | 2005-07-01 | 2008-08-27 | 极速决件公司 | Method, apparatus and system for use in multimedia signal encoding |
KR20070004153A (en) | 2005-07-04 | 2007-01-09 | 주식회사 다음커뮤니케이션 | System of providing contents preferred by a user and method thereof, system of selecting contents preferred by a user and method thereof, and system of selecting contents preferred by a group of users and method thereof |
KR100690819B1 (en) | 2005-07-21 | 2007-03-09 | 엘지전자 주식회사 | Mobile terminal having bookmark function for contents service and operation method thereof |
EP1758398A1 (en) * | 2005-08-23 | 2007-02-28 | Syneola SA | Multilevel semiotic and fuzzy logic user and metadata interface means for interactive multimedia system having cognitive adaptive capability |
US8181201B2 (en) | 2005-08-30 | 2012-05-15 | Nds Limited | Enhanced electronic program guides |
US7644364B2 (en) | 2005-10-14 | 2010-01-05 | Microsoft Corporation | Photo and video collage effects |
JP2007151057A (en) | 2005-10-25 | 2007-06-14 | Dainippon Printing Co Ltd | Video content browsing system using evaluation comment information |
US8180826B2 (en) | 2005-10-31 | 2012-05-15 | Microsoft Corporation | Media sharing and authoring on the web |
US20070099684A1 (en) * | 2005-11-03 | 2007-05-03 | Evans Butterworth | System and method for implementing an interactive storyline |
JP2007142750A (en) | 2005-11-17 | 2007-06-07 | National Agency For The Advancement Of Sports & Health | Video image browsing system, computer terminal and program |
US7945653B2 (en) | 2006-10-11 | 2011-05-17 | Facebook, Inc. | Tagging digital media |
US7761436B2 (en) | 2006-01-03 | 2010-07-20 | Yahoo! Inc. | Apparatus and method for controlling content access based on shared annotations for annotated users in a folksonomy scheme |
WO2007082169A2 (en) | 2006-01-05 | 2007-07-19 | Eyespot Corporation | Automatic aggregation of content for use in an online video editing system |
US8214516B2 (en) | 2006-01-06 | 2012-07-03 | Google Inc. | Dynamic media serving infrastructure |
JP2007274090A (en) | 2006-03-30 | 2007-10-18 | Toshiba Corp | Content reproducing apparatus, method, and program |
WO2007115224A2 (en) | 2006-03-30 | 2007-10-11 | Sri International | Method and apparatus for annotating media streams |
US8701005B2 (en) | 2006-04-26 | 2014-04-15 | At&T Intellectual Property I, Lp | Methods, systems, and computer program products for managing video information |
US7954049B2 (en) | 2006-05-15 | 2011-05-31 | Microsoft Corporation | Annotating multimedia files along a timeline |
US20070271331A1 (en) | 2006-05-17 | 2007-11-22 | Steve Muth | System of archiving and repurposing a complex group conversation referencing networked media |
WO2007135688A2 (en) * | 2006-05-22 | 2007-11-29 | P.S.G Group | A method for interactive commenting on media files |
JP4769635B2 (en) | 2006-05-22 | 2011-09-07 | 日本電信電話株式会社 | Server apparatus and client apparatus and program thereof |
JP2007317123A (en) | 2006-05-29 | 2007-12-06 | Daisuke Yamamoto | Server for managing dynamic images |
US20080028323A1 (en) | 2006-07-27 | 2008-01-31 | Joshua Rosen | Method for Initiating and Launching Collaboration Sessions |
US20080028294A1 (en) | 2006-07-28 | 2008-01-31 | Blue Lava Technologies | Method and system for managing and maintaining multimedia content |
EP2051509B1 (en) | 2006-08-10 | 2016-07-27 | Panasonic Intellectual Property Management Co., Ltd. | Program recommendation system, program view terminal, program view program, program view method, program recommendation server, program recommendation program, and program recommendation method |
US7529797B2 (en) * | 2006-08-16 | 2009-05-05 | Tagged, Inc. | User created tags for online social networking |
US8850464B2 (en) | 2006-10-09 | 2014-09-30 | Verizon Patent And Licensing Inc. | Systems and methods for real-time interactive television polling |
US20080109841A1 (en) | 2006-10-23 | 2008-05-08 | Ashley Heather | Product information display and product linking |
US7559017B2 (en) | 2006-12-22 | 2009-07-07 | Google Inc. | Annotation framework for video |
WO2008086189A2 (en) | 2007-01-04 | 2008-07-17 | Wide Angle Llc | Relevancy rating of tags |
US7707162B2 (en) | 2007-01-08 | 2010-04-27 | International Business Machines Corporation | Method and apparatus for classifying multimedia artifacts using ontology selection and semantic classification |
US20080284910A1 (en) * | 2007-01-31 | 2008-11-20 | John Erskine | Text data for streaming video |
US7739304B2 (en) | 2007-02-08 | 2010-06-15 | Yahoo! Inc. | Context-based community-driven suggestions for media annotation |
KR101095562B1 (en) * | 2007-02-26 | 2011-12-19 | 삼성전자주식회사 | refrigerator |
US20080250331A1 (en) | 2007-04-04 | 2008-10-09 | Atul Tulshibagwale | Method and System of a Voting Based Wiki and Its Application to Internet Topic Directories |
US8744869B2 (en) | 2007-06-07 | 2014-06-03 | Agile Sports Technologies, Inc. | Interactive team portal system |
US8230458B2 (en) | 2007-06-29 | 2012-07-24 | At&T Intellectual Property I, L.P. | System and method of providing video content commentary |
JP2010541415A (en) | 2007-09-28 | 2010-12-24 | グレースノート インコーポレイテッド | Compositing multimedia event presentations |
US8640030B2 (en) * | 2007-10-07 | 2014-01-28 | Fall Front Wireless Ny, Llc | User interface for creating tags synchronized with a video playback |
US8209223B2 (en) * | 2007-11-30 | 2012-06-26 | Google Inc. | Video object tag creation and processing |
US8126882B2 (en) * | 2007-12-12 | 2012-02-28 | Google Inc. | Credibility of an author of online content |
US20090172745A1 (en) | 2007-12-28 | 2009-07-02 | Motorola, Inc. | Method and Apparatus Regarding Receipt of Audio-Visual Content Information and Use of Such Information to Automatically Infer a Relative Popularity of That Content |
US8181197B2 (en) | 2008-02-06 | 2012-05-15 | Google Inc. | System and method for voting on popular video intervals |
US8112702B2 (en) | 2008-02-19 | 2012-02-07 | Google Inc. | Annotating video intervals |
WO2009137368A2 (en) | 2008-05-03 | 2009-11-12 | Mobile Media Now, Inc. | Method and system for generation and playback of supplemented videos |
US8566353B2 (en) | 2008-06-03 | 2013-10-22 | Google Inc. | Web-based system for collaborative generation of interactive videos |
CA2727516A1 (en) | 2008-06-18 | 2009-12-23 | Political Media (Australia) Limited | Assessing digital content across a communications network |
US8839327B2 (en) | 2008-06-25 | 2014-09-16 | At&T Intellectual Property Ii, Lp | Method and apparatus for presenting media programs |
US8713618B1 (en) | 2008-11-06 | 2014-04-29 | Google Inc. | Segmenting video based on timestamps in comments |
US8554848B2 (en) * | 2009-04-16 | 2013-10-08 | At&T Intellectual Property 1, L.P. | Collective asynchronous media review |
US9357242B2 (en) * | 2011-06-10 | 2016-05-31 | Tata Consultancy Services Limited | Method and system for automatic tagging in television using crowd sourcing technique |
US20130238995A1 (en) * | 2012-03-12 | 2013-09-12 | sCoolTV, Inc | Apparatus and method for adding content using a media player |
KR102042265B1 (en) * | 2012-03-30 | 2019-11-08 | 엘지전자 주식회사 | Mobile terminal |
-
2009
- 2009-02-18 US US12/388,365 patent/US8566353B2/en active Active
- 2009-02-19 US US12/389,359 patent/US8826357B2/en active Active
- 2009-05-05 EP EP09758919.6A patent/EP2300894B1/en active Active
- 2009-05-05 WO PCT/US2009/042919 patent/WO2009148756A1/en active Application Filing
- 2009-05-05 CN CN2009801256718A patent/CN102084319B/en active Active
- 2009-05-05 CA CA2726777A patent/CA2726777C/en active Active
-
2013
- 2013-09-10 US US14/023,404 patent/US9684432B2/en active Active
- 2013-12-28 US US14/142,842 patent/US20140115476A1/en not_active Abandoned
Patent Citations (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
WO2001020466A1 (en) * | 1999-09-15 | 2001-03-22 | Hotv Inc. | Method and apparatus for integrating animation in interactive video |
Also Published As
Publication number | Publication date |
---|---|
CA2726777C (en) | 2014-09-30 |
CN102084319A (en) | 2011-06-01 |
CA2726777A1 (en) | 2009-12-10 |
US20090297118A1 (en) | 2009-12-03 |
US20140019862A1 (en) | 2014-01-16 |
WO2009148756A1 (en) | 2009-12-10 |
EP2300894A4 (en) | 2015-03-11 |
EP2300894A1 (en) | 2011-03-30 |
CN102084319B (en) | 2013-08-21 |
US20090300475A1 (en) | 2009-12-03 |
US9684432B2 (en) | 2017-06-20 |
US8566353B2 (en) | 2013-10-22 |
US20140115476A1 (en) | 2014-04-24 |
US8826357B2 (en) | 2014-09-02 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
EP2300894B1 (en) | A web-based system for collaborative generation of interactive videos | |
US11461380B2 (en) | System and method for tagging a region within a distributed video file | |
KR101557494B1 (en) | Annotating video intervals | |
US8826117B1 (en) | Web-based system for video editing | |
US9407974B2 (en) | Segmenting video based on timestamps in comments | |
US20140108932A1 (en) | Online search, storage, manipulation, and delivery of video content | |
US20080313570A1 (en) | Method and system for media landmark identification |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PUAI | Public reference made under article 153(3) epc to a published international application that has entered the european phase |
Free format text: ORIGINAL CODE: 0009012 |
|
17P | Request for examination filed |
Effective date: 20101217 |
|
AK | Designated contracting states |
Kind code of ref document: A1Designated state(s): AT BE BG CH CY CZ DE DK EE ES FI FR GB GR HR HU IE IS IT LI LT LU LV MC MK MT NL NO PL PT RO SE SI SK TR |
|
AX | Request for extension of the european patent |
Extension state: AL BA RS |
|
DAX | Request for extension of the european patent (deleted) | ||
A4 | Supplementary search report drawn up and despatched |
Effective date: 20150210 |
|
RIC1 | Information provided on ipc code assigned before grant |
Ipc: G06F 3/00 20060101AFI20150204BHEPIpc: G06F 17/30 20060101ALI20150204BHEPIpc: H04N 21/258 20110101ALI20150204BHEPIpc: H04N 21/454 20110101ALI20150204BHEPIpc: H04N 21/25 20110101ALN20150204BHEPIpc: H04N 21/2743 20110101ALI20150204BHEP |
|
RAP1 | Party data changed (applicant data changed or rights of an application transferred) |
Owner name: GOOGLE LLC |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: EXAMINATION IS IN PROGRESS |
|
17Q | First examination report despatched |
Effective date: 20180130 |
|
GRAJ | Information related to disapproval of communication of intention to grant by the applicant or resumption of examination proceedings by the epo deleted |
Free format text: ORIGINAL CODE: EPIDOSDIGR1 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: GRANT OF PATENT IS INTENDED |
|
GRAP | Despatch of communication of intention to grant a patent |
Free format text: ORIGINAL CODE: EPIDOSNIGR1 |
|
RIC1 | Information provided on ipc code assigned before grant |
Ipc: H04N 21/258 20110101ALI20180612BHEPIpc: G06F 17/30 20060101ALI20180612BHEPIpc: H04N 21/454 20110101ALI20180612BHEPIpc: H04N 21/2743 20110101ALI20180612BHEPIpc: G06F 3/00 20060101AFI20180612BHEPIpc: H04N 21/472 20110101ALI20180612BHEPIpc: H04N 21/858 20110101ALI20180612BHEPIpc: H04N 21/25 20110101ALN20180612BHEP |
|
INTG | Intention to grant announced |
Effective date: 20180717 |
|
GRAS | Grant fee paid |
Free format text: ORIGINAL CODE: EPIDOSNIGR3 |
|
GRAA | (expected) grant |
Free format text: ORIGINAL CODE: 0009210 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: THE PATENT HAS BEEN GRANTED |
|
AK | Designated contracting states |
Kind code of ref document: B1Designated state(s): AT BE BG CH CY CZ DE DK EE ES FI FR GB GR HR HU IE IS IT LI LT LU LV MC MK MT NL NO PL PT RO SE SI SK TR |
|
REG | Reference to a national code |
Ref country code: GBRef legal event code: FG4D |
|
REG | Reference to a national code |
Ref country code: CHRef legal event code: EPRef country code: ATRef legal event code: REFRef document number: 1088084Country of ref document: ATKind code of ref document: TEffective date: 20190115 |
|
REG | Reference to a national code |
Ref country code: DERef legal event code: R096Ref document number: 602009056632Country of ref document: DE |
|
REG | Reference to a national code |
Ref country code: IERef legal event code: FG4D |
|
REG | Reference to a national code |
Ref country code: NLRef legal event code: FP |
|
REG | Reference to a national code |
Ref country code: LTRef legal event code: MG4D |
|
PGFP | Annual fee paid to national office [announced via postgrant information from national office to epo] |
Ref country code: NLPayment date: 20190526Year of fee payment: 11 |
|
REG | Reference to a national code |
Ref country code: ATRef legal event code: MK05Ref document number: 1088084Country of ref document: ATKind code of ref document: TEffective date: 20190109 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: LTFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20190109Ref country code: PLFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20190109Ref country code: ESFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20190109Ref country code: FIFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20190109Ref country code: NOFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20190409Ref country code: SEFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20190109Ref country code: PTFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20190509 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: GRFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20190410Ref country code: LVFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20190109Ref country code: ISFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20190509Ref country code: BGFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20190409Ref country code: HRFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20190109 |
|
PGFP | Annual fee paid to national office [announced via postgrant information from national office to epo] |
Ref country code: FRPayment date: 20190527Year of fee payment: 11 |
|
REG | Reference to a national code |
Ref country code: DERef legal event code: R097Ref document number: 602009056632Country of ref document: DE |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: CZFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20190109Ref country code: ROFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20190109Ref country code: SKFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20190109Ref country code: ATFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20190109Ref country code: EEFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20190109Ref country code: ITFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20190109Ref country code: DKFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20190109 |
|
PLBE | No opposition filed within time limit |
Free format text: ORIGINAL CODE: 0009261 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: NO OPPOSITION FILED WITHIN TIME LIMIT |
|
26N | No opposition filed |
Effective date: 20191010 |
|
REG | Reference to a national code |
Ref country code: CHRef legal event code: PL |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: LIFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20190531Ref country code: MCFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20190109Ref country code: CHFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20190531 |
|
REG | Reference to a national code |
Ref country code: BERef legal event code: MMEffective date: 20190531 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: SIFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20190109Ref country code: LUFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20190505 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: TRFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20190109 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: IEFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20190505 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: BEFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20190531 |
|
REG | Reference to a national code |
Ref country code: NLRef legal event code: MMEffective date: 20200601 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: NLFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20200601 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: FRFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20200531 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: CYFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20190109 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: MTFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20190109Ref country code: HUFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMIT; INVALID AB INITIOEffective date: 20090505 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: MKFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20190109 |
|
P01 | Opt-out of the competence of the unified patent court (upc) registered |
Effective date: 20230506 |
|
PGFP | Annual fee paid to national office [announced via postgrant information from national office to epo] |
Ref country code: DEPayment date: 20230530Year of fee payment: 15 |
|
PGFP | Annual fee paid to national office [announced via postgrant information from national office to epo] |
Ref country code: GBPayment date: 20230529Year of fee payment: 15 |