EP3033699A1 - Searching and annotating within images - Google Patents
Searching and annotating within imagesInfo
- Publication number
- EP3033699A1 EP3033699A1 EP14836190.0A EP14836190A EP3033699A1 EP 3033699 A1 EP3033699 A1 EP 3033699A1 EP 14836190 A EP14836190 A EP 14836190A EP 3033699 A1 EP3033699 A1 EP 3033699A1
- Authority
- EP
- European Patent Office
- Prior art keywords
- image
- query
- result
- sub
- identifying
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Ceased
Links
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/50—Information retrieval; Database structures therefor; File system structures therefor of still image data
- G06F16/58—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually
- G06F16/583—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using metadata automatically derived from the content
- G06F16/5854—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using metadata automatically derived from the content using shape and object relationship
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/50—Information retrieval; Database structures therefor; File system structures therefor of still image data
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/50—Information retrieval; Database structures therefor; File system structures therefor of still image data
- G06F16/58—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually
- G06F16/583—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using metadata automatically derived from the content
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/95—Retrieval from the web
- G06F16/955—Retrieval from the web using information identifiers, e.g. uniform resource locators [URL]
- G06F16/9558—Details of hyperlinks; Management of linked annotations
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/10—Text processing
- G06F40/12—Use of codes for handling textual entities
- G06F40/134—Hyperlinking
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/10—Text processing
- G06F40/166—Editing, e.g. inserting or deleting
- G06F40/169—Annotation, e.g. comment data or footnotes
Definitions
- This specification relates to searching within images.
- Feature detection algorithms enable computing devices to identify visual features depicted in an image. Detection of visual features has led to developments in technology for identifying portions of images that include particular features. For example, optical character recognition techniques allow an image to be processed to identify alpha-numeric characters included in the image.
- Fig. 4 is a flow diagram of an example process for searching within an image.
- the image search system determines whether a portion of the query image matches, or is similar to, a result image identified by the image search system. For example, the image identified as relevant to the user's query for the particular candy bar can be compared to the image provided by the user device to determine if a portion of the image provided by the user device is similar to the relevant image.
- the image search system provides the user device with annotation data that causes the user device to display an annotation in the image originally submitted by the user device.
- the annotation specifies the portion of the image submitted by the user that is similar to the result image identified by the image search system.
- the image search system provides the user device with instructions to highlight that portion of the image, indicating to the user that the image of the grocery store shelf includes something similar to the particular candy bar specified by the user's query.
- FIG. 1 is a block diagram of an example environment 100 for searching within an image.
- a computer network 102 such as a local area network (LAN), wide area network (WAN), the Internet, or a combination thereof, connects publisher web sites 104, user devices 106, and the image search system 108.
- the online environment 100 may include many thousands of publisher web sites 104 and user devices 106.
- the image search engine 108 identifies images by crawling the publisher web sites 104 and indexing the image resources provided by the publisher web sites 104.
- the indexed and, optionally, cached copies of the image resources are stored in a data storage device, such as the image index 110.
- the image search results are ranked based on scores related to the image resources identified by the image search results, such as information retrieval ("IR") scores, and optionally a separate ranking of each image resource relative to other image resources (e.g., an authority score).
- the image search results may be ordered according to these scores and provided to the user device according to the order.
- the scores and/or rankings of image resources may also be stored in the image index 108 for various queries along with the corresponding indexed and/or cached image resources.
- the image search system 108 obtains a result image 208 from a particular corpus of images stored in the image index 110, or accesses a result image from data stored in the index 110 specifying a location of the result image.
- one corpus of images stored in the image index 110 may be manually ranked and/or scored by a machine and/or users for particular queries. The manual scores and rankings may be dependent upon user input. For example, users may be asked to select an image that identifies a particular object, such as "Crunchy Delight" candy bars.
- Users can rank and/or select one or more images that represent the product or query, "Crunchy Delight.”
- Example images might include images of the "Crunchy Delight” logo, images of a wrapped “Crunchy Delight” candy bar, and images of an unwrapped candy bar.
- users may specifically be asked to identify an image that best represents "Crunchy Delight” when viewed as a retail product.
- One or more of these manually scored/selected images can be stored in the image index 110 and associated with the query, "Crunchy Delight,” and later retrieved as result image(s) 208 responsive to the query "Crunchy Delight.”
- the image search system 108 determines whether an object 210 depicted in a sub- portion 212 of the query image 206 is similar to the result image 208. For example, if the result image 208 is an image of the "Crunchy Delight" logo, the image search system determines whether the query image 206 submitted by the user device 202 includes something similar to the "Crunchy Delight" logo.
- a "sub- portion" of an image is a portion of the image that is less than the entire image. For example, if an image is 1000x1000 pixels, any portion of the image less than 1000x1000 pixels is considered a sub-portion of the image, e.g., a 100x100 portion of the image.
- Object recognition processes can be used to identify specific objects in the images and perform local feature analysis of the sub-portions of the image in which the specific objects are located. If a measure of similarity meets a pre-determined threshold, the image search system 108 determines that the object depicted in the sub-portion of the query image 206 is similar to the result image 208.
- the pre-determined threshold can be set by a system administrator or be a machine- learned threshold. If no sub-portion of the query image 206 includes an object that is similar to the result image 208, another result image may be selected for comparison.
- result images 208 may be pre-processed, and data specifying visual features of the result images 208 may also be stored in the image index 110. This may reduce processing required by the image search system 108 to compare images.
- Many image comparison methods, processes, and techniques may be used to compare images. For example, optical character recognition may be used to identify text depicted in each image, so if a result image 208 includes a candy bar logo with the text, "Crunchy Delight," this text may be identified and compared to text identified in the query image 206.
- the image search system 108 In response to determining that an object 210 depicted in a sub-portion 212 of the query image 206 is similar to the result image 208, the image search system 108 provides annotation data 214 to the user device 202.
- the annotation data 214 causes the user device to display an annotation with the query image 206, and the annotation specifies the sub-portion 212 of the query image 206 that includes the object 210 that is similar to the result image 208. For example, the if the image search system 108 determines that an object included in the image of the grocery store shelf is similar to a logo found in a result image for the query, "Crunchy Delight," the image search system will send annotation data to the user device indicating the location of the object within the search image. Example annotations are described in further detail with respect to Fig. 3.
- the search system 108 can modify the query image 206 with the annotation data and the query image 206 can be sent back to the user device as annotated by the search system 110.
- the image search system 108 may annotate the query image 206 and provide the resulting combination of query image 206 plus annotation to the user device 202.
- the annotation data 214 does not include the query image 206, but includes instructions that cause the user device 202 to display an annotation with the query image 206.
- multiple similar objects may be identified within a single query image 206. For example, if multiple boxes or packages of the "Crunchy Delight" candy bar are on a grocery store shelf, the image search system 108 may identify each of them. In this situation, the annotation data 214 provided to the user device may specify each sub-portion of the query image 206 that includes a similar object separately, or the annotation data may specify a single sub-portion of the query image 206 that
- the image search system 108 may receive multiple query images 206 or a query video. When multiple query images are received, the image search system 108 may process each of them, e.g., in the manner described above, to identify one or more of the query images that include an object similar to a result image, and provide annotation data 214 specifying the location of the objects within one or more of the images that include the similar object. If a query video is provided, multiple query images or frames may be selected from the query video for processing.
- a user searching for "Crunchy Delight” candy bars in a grocery store may take a video of an entire grocery store aisle and submit it to the image search system 108 with the query, "Crunchy Delight.”
- the image search system 108 can select a number of video frames to analyze and compare to a result image 208 for the query, "Crunchy Delight,” and provide annotation data 214 to the user device 202 that causes the user device to display the video frame with an annotation identifying an object similar to the result image 208.
- Fig. 3 is an illustration of example annotations 300 displayed with images.
- the example annotations 300 each depict an example method of specifying a sub-portion of a query image that includes an object that is similar to a result image. Other methods may be used, and other information may be included in the annotation and/or annotation data.
- the example annotation of image 302 depicts a bounding box surrounding an object depicted in the image.
- the annotation data specifies the coordinates of a bounding box, e.g., x,y coordinates of four corners of a box, that surrounds the sub-portion of the query image 302 that includes an object that is identified as similar to the result image.
- the annotation itself is a visual depiction of a bounding box, which in this example image 302 is a box represented by a dashed line.
- the example annotation of image 304 depicts visual highlighting of a sub-portion of the image 304 that includes an object determined to be similar to a result image.
- the annotation data causes a user device to shade the portions of the image that do not include the object, making the object stand out to a user.
- the example annotation of image 306 depicts a bounding box surrounding an object depicted in the image along with a representation of the result image.
- the annotation data specifies the coordinates of a bounding box, e.g., x,y coordinates of four corners of a box, that surrounds the sub-portion of the query image 302 that includes an object that is identified as similar to the result image.
- the annotation itself is a visual depiction of a bounding box with an overlay depicting the result image.
- the overlay may include, for example, a thumbnail of the result image.
- the example annotation of image 308 depicts visual highlighting of a sub-portion of the image 304 that includes an object determined to be similar to a result image along with a representation of the result image.
- the annotation data causes a user device to shade the portions of the image that do not include the object, making the object stand out to a user.
- the annotation also includes an overlay depicting the result image, e.g., a thumbnail of the result image.
- a query image is received from a user device (404).
- the user searching for the widget in the hardware store might take a picture of the shelf of hardware with a smartphone and submit the picture to the image search system with the query, "widget.”
- a computer having a display device, e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor, for displaying information to the user and a keyboard and a pointing device, e.g., a mouse or a trackball, by which the user can provide input to the computer.
- a display device e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor
- a keyboard and a pointing device e.g., a mouse or a trackball
- Other kinds of devices can be used to provide for interaction with a user as well; for example, feedback provided to the user can be any form of sensory feedback, e.g., visual feedback, auditory feedback, or tactile feedback; and input from the user can be received in any form, including acoustic, speech, or tactile input.
- a computer can interact with a user by sending documents to and receiving documents from a device that is used by the user; for example, by sending web pages to
- the computing system can include users and servers.
- a user and server are generally remote from each other and typically interact through a communication network. The relationship of user and server arises by virtue of computer programs running on the respective computers and having a user-server relationship to each other.
- a server transmits data (e.g., an HTML page) to a user device (e.g., for purposes of displaying data to and receiving user input from a user interacting with the user device).
- Data generated at the user device e.g., a result of the user interaction
Abstract
Description
Claims
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US13/966,470 US9384213B2 (en) | 2013-08-14 | 2013-08-14 | Searching and annotating within images |
PCT/US2014/050846 WO2015023734A1 (en) | 2013-08-14 | 2014-08-13 | Searching and annotating within images |
Publications (2)
Publication Number | Publication Date |
---|---|
EP3033699A1 true EP3033699A1 (en) | 2016-06-22 |
EP3033699A4 EP3033699A4 (en) | 2017-03-01 |
Family
ID=52466521
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
EP14836190.0A Ceased EP3033699A4 (en) | 2013-08-14 | 2014-08-13 | Searching and annotating within images |
Country Status (4)
Country | Link |
---|---|
US (2) | US9384213B2 (en) |
EP (1) | EP3033699A4 (en) |
CN (2) | CN105637509B (en) |
WO (1) | WO2015023734A1 (en) |
Families Citing this family (10)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10853407B2 (en) * | 2013-09-05 | 2020-12-01 | Ebay, Inc. | Correlating image annotations with foreground features |
EP3191991B1 (en) * | 2014-09-10 | 2021-01-13 | Koninklijke Philips N.V. | Image report annotation identification |
US20160364374A1 (en) * | 2015-06-09 | 2016-12-15 | International Business Machines Corporation | Visual indication for images in a question-answering system |
US10152521B2 (en) * | 2016-06-22 | 2018-12-11 | Google Llc | Resource recommendations for a displayed resource |
CN107341185B (en) * | 2017-06-05 | 2020-12-04 | 北京小米移动软件有限公司 | Information display method and device |
CN110110189A (en) * | 2018-02-01 | 2019-08-09 | 北京京东尚科信息技术有限公司 | Method and apparatus for generating information |
TWI666595B (en) | 2018-02-26 | 2019-07-21 | 財團法人工業技術研究院 | System and method for object labeling |
JP2021068063A (en) * | 2019-10-18 | 2021-04-30 | 富士ゼロックス株式会社 | Query correction support system, search system, and program |
CN111597993B (en) * | 2020-05-15 | 2023-09-05 | 北京百度网讯科技有限公司 | Data processing method and device |
US11797504B2 (en) | 2021-11-04 | 2023-10-24 | Red Hat, Inc. | Converting computing infrastructure diagrams to searchable diagrams |
Family Cites Families (29)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6675174B1 (en) * | 2000-02-02 | 2004-01-06 | International Business Machines Corp. | System and method for measuring similarity between a set of known temporal media segments and a one or more temporal media streams |
US7046851B2 (en) | 2000-11-08 | 2006-05-16 | California Institute Of Technology | Image and video indexing scheme for content analysis |
US8341112B2 (en) * | 2006-05-19 | 2012-12-25 | Microsoft Corporation | Annotation by search |
US20080222120A1 (en) * | 2007-03-08 | 2008-09-11 | Nikolaos Georgis | System and method for video recommendation based on video frame features |
WO2008069791A1 (en) * | 2006-12-04 | 2008-06-12 | General Instrument Corporation | Method and apparatus for improving image retrieval and search using latent semantic indexing |
CN101211341A (en) * | 2006-12-29 | 2008-07-02 | 上海芯盛电子科技有限公司 | Image intelligent mode recognition and searching method |
US8180788B2 (en) | 2008-06-05 | 2012-05-15 | Enpulz, L.L.C. | Image search engine employing image correlation |
US8150170B2 (en) | 2008-05-30 | 2012-04-03 | Microsoft Corporation | Statistical approach to large-scale image annotation |
US7962500B2 (en) * | 2008-10-24 | 2011-06-14 | Yahoo! Inc. | Digital image retrieval by aggregating search results based on visual annotations |
CN101777064A (en) * | 2009-01-12 | 2010-07-14 | 鸿富锦精密工业（深圳）有限公司 | Image searching system and method |
US8254699B1 (en) | 2009-02-02 | 2012-08-28 | Google Inc. | Automatic large scale video object recognition |
US8429173B1 (en) | 2009-04-20 | 2013-04-23 | Google Inc. | Method, system, and computer readable medium for identifying result images based on an image query |
CN101571875A (en) * | 2009-05-05 | 2009-11-04 | 程治永 | Realization method of image searching system based on image recognition |
US9087059B2 (en) | 2009-08-07 | 2015-07-21 | Google Inc. | User interface for presenting search results for multiple regions of a visual query |
US20110082735A1 (en) * | 2009-10-06 | 2011-04-07 | Qualcomm Incorporated | Systems and methods for merchandising transactions via image matching in a content delivery system |
US8280881B1 (en) | 2009-10-29 | 2012-10-02 | Google Inc. | Similar search queries and images |
US20110128288A1 (en) * | 2009-12-02 | 2011-06-02 | David Petrou | Region of Interest Selector for Visual Queries |
JP5134664B2 (en) * | 2010-09-14 | 2013-01-30 | 株式会社東芝 | Annotation device |
US20120076297A1 (en) * | 2010-09-24 | 2012-03-29 | Hand Held Products, Inc. | Terminal for use in associating an annotation with an image |
US8788434B2 (en) | 2010-10-28 | 2014-07-22 | Google Inc. | Search with joint image-audio queries |
US20120117051A1 (en) | 2010-11-05 | 2012-05-10 | Microsoft Corporation | Multi-modal approach to search query input |
US9229956B2 (en) * | 2011-01-10 | 2016-01-05 | Microsoft Technology Licensing, Llc | Image retrieval using discriminative visual features |
US8706756B2 (en) * | 2011-05-11 | 2014-04-22 | Futurewei Technologies, Inc. | Method, system and apparatus of hybrid federated search |
US8755605B2 (en) | 2011-07-11 | 2014-06-17 | Futurewei Technologies, Inc. | System and method for compact descriptor for visual search |
US8533204B2 (en) | 2011-09-02 | 2013-09-10 | Xerox Corporation | Text-based searching of image data |
US9075825B2 (en) | 2011-09-26 | 2015-07-07 | The University Of Kansas | System and methods of integrating visual features with textual features for image searching |
US8880563B2 (en) * | 2012-09-21 | 2014-11-04 | Adobe Systems Incorporated | Image search by query object segmentation |
CN102968619B (en) * | 2012-11-13 | 2015-06-17 | 北京航空航天大学 | Recognition method for components of Chinese character pictures |
CN103164539B (en) * | 2013-04-15 | 2016-12-28 | 中国传媒大学 | A kind of combination user evaluates and the interactive image retrieval method of mark |
-
2013
- 2013-08-14 US US13/966,470 patent/US9384213B2/en active Active
-
2014
- 2014-08-13 WO PCT/US2014/050846 patent/WO2015023734A1/en active Application Filing
- 2014-08-13 EP EP14836190.0A patent/EP3033699A4/en not_active Ceased
- 2014-08-13 CN CN201480056395.5A patent/CN105637509B/en active Active
- 2014-08-13 CN CN201810262935.5A patent/CN108763244B/en active Active
-
2016
- 2016-06-28 US US15/195,667 patent/US10210181B2/en active Active
Also Published As
Publication number | Publication date |
---|---|
CN105637509A (en) | 2016-06-01 |
WO2015023734A1 (en) | 2015-02-19 |
CN105637509B (en) | 2018-04-20 |
US20150049091A1 (en) | 2015-02-19 |
US10210181B2 (en) | 2019-02-19 |
EP3033699A4 (en) | 2017-03-01 |
CN108763244B (en) | 2022-02-01 |
US20160328420A1 (en) | 2016-11-10 |
US9384213B2 (en) | 2016-07-05 |
CN108763244A (en) | 2018-11-06 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US10210181B2 (en) | Searching and annotating within images | |
US10592571B1 (en) | Query modification based on non-textual resource context | |
US9396413B2 (en) | Choosing image labels | |
US10503803B2 (en) | Animated snippets for search results | |
US8275771B1 (en) | Non-text content item search | |
US9460167B2 (en) | Transition from first search results environment to second search results environment | |
US20150370833A1 (en) | Visual refinements in image search | |
WO2012155012A1 (en) | Dynamic image display area and image display within web search results | |
US9158857B2 (en) | Identifying landing pages for images | |
US9916384B2 (en) | Related entities | |
US10691746B2 (en) | Images for query answers | |
EP3485394B1 (en) | Contextual based image search results | |
US9600579B2 (en) | Presenting search results for an Internet search request | |
US9811592B1 (en) | Query modification based on textual resource context | |
WO2015168583A1 (en) | Systems, methods, and computer-readable media for displaying content | |
US11720626B1 (en) | Image keywords | |
US9135313B2 (en) | Providing a search display environment on an online resource |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PUAI | Public reference made under article 153(3) epc to a published international application that has entered the european phase |
Free format text: ORIGINAL CODE: 0009012 |
|
17P | Request for examination filed |
Effective date: 20160314 |
|
AK | Designated contracting states |
Kind code of ref document: A1Designated state(s): AL AT BE BG CH CY CZ DE DK EE ES FI FR GB GR HR HU IE IS IT LI LT LU LV MC MK MT NL NO PL PT RO RS SE SI SK SM TR |
|
AX | Request for extension of the european patent |
Extension state: BA ME |
|
DAX | Request for extension of the european patent (deleted) | ||
A4 | Supplementary search report drawn up and despatched |
Effective date: 20170201 |
|
RIC1 | Information provided on ipc code assigned before grant |
Ipc: G06F 17/30 20060101AFI20170126BHEPIpc: G06F 17/24 20060101ALN20170126BHEPIpc: G06F 17/22 20060101ALN20170126BHEP |
|
RAP1 | Party data changed (applicant data changed or rights of an application transferred) |
Owner name: GOOGLE LLC |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: EXAMINATION IS IN PROGRESS |
|
17Q | First examination report despatched |
Effective date: 20180403 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: EXAMINATION IS IN PROGRESS |
|
APBK | Appeal reference recorded |
Free format text: ORIGINAL CODE: EPIDOSNREFNE |
|
APBN | Date of receipt of notice of appeal recorded |
Free format text: ORIGINAL CODE: EPIDOSNNOA2E |
|
APAF | Appeal reference modified |
Free format text: ORIGINAL CODE: EPIDOSCREFNE |
|
APBR | Date of receipt of statement of grounds of appeal recorded |
Free format text: ORIGINAL CODE: EPIDOSNNOA3E |
|
APBT | Appeal procedure closed |
Free format text: ORIGINAL CODE: EPIDOSNNOA9E |
|
REG | Reference to a national code |
Ref country code: DERef legal event code: R003 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: THE APPLICATION HAS BEEN REFUSED |
|
18R | Application refused |
Effective date: 20221123 |