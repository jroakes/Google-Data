US8340972B2 - Psychoacoustic method and system to impose a preferred talking rate through auditory feedback rate adjustment - Google Patents
Psychoacoustic method and system to impose a preferred talking rate through auditory feedback rate adjustment Download PDFInfo
- Publication number
- US8340972B2 US8340972B2 US10/607,760 US60776003A US8340972B2 US 8340972 B2 US8340972 B2 US 8340972B2 US 60776003 A US60776003 A US 60776003A US 8340972 B2 US8340972 B2 US 8340972B2
- Authority
- US
- United States
- Prior art keywords
- rate
- audio
- user
- handset
- speech
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active, expires
Links
- 238000000034 method Methods 0.000 title abstract description 82
- 238000004891 communication Methods 0.000 claims description 35
- 230000006870 function Effects 0.000 claims description 11
- 230000001360 synchronised effect Effects 0.000 claims description 9
- 238000001514 detection method Methods 0.000 claims description 5
- 238000009877 rendering Methods 0.000 claims description 2
- 238000007906 compression Methods 0.000 abstract description 62
- 230000006835 compression Effects 0.000 abstract description 61
- 230000008859 change Effects 0.000 abstract description 17
- 238000012545 processing Methods 0.000 abstract description 15
- 230000000694 effects Effects 0.000 abstract description 8
- 230000008713 feedback mechanism Effects 0.000 abstract description 6
- 238000003672 processing method Methods 0.000 abstract description 2
- 239000000872 buffer Substances 0.000 description 60
- 238000010586 diagram Methods 0.000 description 20
- 230000008569 process Effects 0.000 description 11
- 238000002156 mixing Methods 0.000 description 9
- 230000000875 corresponding effect Effects 0.000 description 7
- 238000004519 manufacturing process Methods 0.000 description 6
- 230000007423 decrease Effects 0.000 description 4
- 230000000994 depressogenic effect Effects 0.000 description 4
- 238000013461 design Methods 0.000 description 4
- 239000000203 mixture Substances 0.000 description 4
- 230000000737 periodic effect Effects 0.000 description 4
- 208000003028 Stuttering Diseases 0.000 description 3
- 230000007246 mechanism Effects 0.000 description 3
- 238000012986 modification Methods 0.000 description 3
- 230000004048 modification Effects 0.000 description 3
- 230000004044 response Effects 0.000 description 3
- 230000005236 sound signal Effects 0.000 description 3
- 239000002131 composite material Substances 0.000 description 2
- 238000004590 computer program Methods 0.000 description 2
- 230000003247 decreasing effect Effects 0.000 description 2
- 230000010354 integration Effects 0.000 description 2
- 239000002244 precipitate Substances 0.000 description 2
- 230000010076 replication Effects 0.000 description 2
- 230000002123 temporal effect Effects 0.000 description 2
- 230000001755 vocal effect Effects 0.000 description 2
- 230000003044 adaptive effect Effects 0.000 description 1
- 238000005311 autocorrelation function Methods 0.000 description 1
- 230000006399 behavior Effects 0.000 description 1
- 230000015572 biosynthetic process Effects 0.000 description 1
- 230000001413 cellular effect Effects 0.000 description 1
- 230000001276 controlling effect Effects 0.000 description 1
- 230000002596 correlated effect Effects 0.000 description 1
- 230000001419 dependent effect Effects 0.000 description 1
- 210000005069 ears Anatomy 0.000 description 1
- 238000005516 engineering process Methods 0.000 description 1
- 230000000763 evoking effect Effects 0.000 description 1
- 238000009472 formulation Methods 0.000 description 1
- 238000007429 general method Methods 0.000 description 1
- 239000004973 liquid crystal related substance Substances 0.000 description 1
- 230000001404 mediated effect Effects 0.000 description 1
- 210000003205 muscle Anatomy 0.000 description 1
- 230000003387 muscular Effects 0.000 description 1
- 239000002243 precursor Substances 0.000 description 1
- 238000003825 pressing Methods 0.000 description 1
- 230000004800 psychological effect Effects 0.000 description 1
- 238000011160 research Methods 0.000 description 1
- 230000000241 respiratory effect Effects 0.000 description 1
- 238000005070 sampling Methods 0.000 description 1
- 230000011218 segmentation Effects 0.000 description 1
- 230000001953 sensory effect Effects 0.000 description 1
- 238000000926 separation method Methods 0.000 description 1
- 230000003595 spectral effect Effects 0.000 description 1
- 238000001228 spectrum Methods 0.000 description 1
- 238000010561 standard procedure Methods 0.000 description 1
- 238000003860 storage Methods 0.000 description 1
- 238000003786 synthesis reaction Methods 0.000 description 1
- 238000012360 testing method Methods 0.000 description 1
- 230000009466 transformation Effects 0.000 description 1
- 238000000844 transformation Methods 0.000 description 1
- 230000007704 transition Effects 0.000 description 1
- 230000000007 visual effect Effects 0.000 description 1
Images
Classifications
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L21/00—Processing of the speech or voice signal to produce another audible or non-audible signal, e.g. visual or tactile, in order to modify its quality or its intelligibility
- G10L21/04—Time compression or expansion
Definitions
- the present invention generally relates to the field of telephony handsets, and more particularly relates to digital audio devices, such as telephony handsets and digital tape recorders, for adjusting the audio listening rates.
- a psychoacoustic principle of hearing and speech production is that an individual has a certain comfort rate at which they speak. This rate is also mediated by their own auditory system, i.e., a person talking hears themselves talking both internally and through their speech entering their ears. It is known in speech communication research that a talking individual establishes a speaking rate based on the hearing of his or her own speech which conforms to this internal comfort speaking rate. By adjusting the feedback speech rate between what the speaker is saying and what the speaker hears himself saying, it is possible to psychologically coerce the speaker to change their speaking rate.
- the Lombard effect in speech describes how people change their speech in noisy surroundings with the most obvious change to simply speak louder.
- the Lombard effect is one example of self-auditory feedback, which psychologically encourages a talker to speak louder than the level of the surrounding sounds they are hearing.
- the talker places emphasis on certain sections of the words to improve the discernibility and hence intelligibility of the speech. Consider when you speak to someone at a concert; you “pronounce” words differently. Many algorithms have tried to capture this behavior to improve the intelligibility of reproduced speech in voice communication systems. None have been able to do so yet.
- the psychological effect of hearing background noise while speaking is a feedback mechanism, which typically compels a person speaking to speak with different articulation.
- SOLA speech time compression/expansion in the present invention method as a means to alter a speaker's talking rate by adjusting the speech rate at which people hear their own voice.
- a person speaks at a certain comfort rate, which is established and maintained by their own auditory system's capability to hear their own voice as they speak i.e., it is a self-auditory feedback mechanism. Changing the rate at which a talker hears their own voice will accordingly change their talking rate.
- This effect is achieved in this invention by employing a real time processing method that temporarily adjusts the speech rate in an effort to impose this psychoacoustic condition which coerces the speaker into changing their talking rate.
- This invention permits users to adjust the comfort rate at which they normally speak or to adjust the rate at which others speak to them through the use of a speech processing device or system.
- FIG. 1 is a block diagram of a telephone handset according to the present invention.
- FIG. 2 is an exemplary user input interface for the electronic device of FIG. 1 according to the present invention.
- FIG. 3 is a series of time-based speech samples illustrating time compression and time expansion of an original speech signal according to the present invention.
- FIG. 4 is an over all flow diagram corresponding to the over all process of performing real-time SOLA operations in a single outbound circular audio buffer using modulo pointers as shown in FIGS. 4-19 , according to the present invention.
- FIG. 5 is a time-based speech sample in the circular audio output buffer illustrating frames, windows and pointers for SOLA compression and expansion operations, according to the present invention.
- FIG. 6 is a time-based speech sample in the circular audio output buffer illustrating frames, windows and pointers for SOLA operations for an expansion operation, according to the present invention.
- FIG. 7 is a time-based speech sample in the circular audio output buffer illustrating the resulting frames for SOLA compression and expansion operations.
- FIG. 8 is a state diagram illustrating the algorithm configurations for various rate selections, as discussed in the low-level design section, according to the present invention.
- FIG. 9 is a graph illustrating the first step of the SOLA method where a determination of the maximum correlation point of two speech frames is made, according to the present invention.
- FIG. 10 are two graphs illustrating the second step of the SOLA method where a new frame is to overlap with an old frame at the point of corresponding maximum correlation is illustrated, according to the present invention.
- FIG. 11 are three graphs illustrating the third step of the SOLA method where synchronized overlap and add is begun over SOLA region, according to the present invention.
- FIG. 12 shown is a graph of a composite speech signal for which subframes A 2 and B 1 have been blended into an AB subframe for speech compression, according to the present invention.
- FIG. 13 is a diagram of the pointers for the method outbound_sola_frame_ready( ) to check if adequate space exists, according to the present invention.
- FIG. 14 is a diagram of the pointers for the method update_sola_ptrs ( ) to update the sola pointers by a frame length for compression, according to the present invention.
- FIG. 15 is a diagram of the pointers for the method update_sola_ptrs ( ) to update the sola pointers by a frame length for expansion, according to the present invention.
- FIG. 16 is a diagram of the pointers for the method shift_blocks ( ), according to the present invention.
- FIG. 17 is a diagram of the pointers for the method shift_sola( ) according to the present invention.
- FIGS. 18 and 19 are high-level MATLAB code for caring out the SOLA operations, according to the present invention.
- FIG. 20 is a block diagram of an embodiment illustrating how loopback combined with SOLA processing is used to adjust speech rate, according to the present invention.
- the present invention permits a user to speed up and slow down speech without changing the speakers pitch. It is a user adjustable feature to change the voice playback rate to the listeners' preferred listening rate or comfort.
- the present invention permits the adjustment of audio playback rates directly on a device rendering the audio, such as a personal digital assistant, digital tape recorder, messaging service, telephone handset, or any other service where audio is played out through an output buffer when being converted by a D/A through a speaker.
- the audio adjustment in the present invention preserves the original pitch of the speaker's voice
- the present invention is compatible with existing hardware by performing transformations directly on the outbound audio buffer without the need of additional memory or the use of a lot of controller overhead.
- the present invention sets the loopback rate the speaker will hear based on their speaking rate.
- the present invention adaptively controls the playback rate to coerce the speaker to talk at a preset talking rate by evoking a psychological condition in the speaker or talker to speak at a preset rate. If the speaker is talking too fast, the speech is slowed down and fed back to the speaker or earpiece. When the speaker adapts to this slower rate, the feedback speed is realized and the feedback speech is set to normal.
- the adaptive control mechanism uses syllabic rate detection and time expansion to set the talkers speaking rate.
- the present invention describes a methodology to use a speech time compression and expansion device to alter the speaking/hearing rate balance of a talking individual.
- the present invention evokes a psychological condition on the talker which results in them slowing down their talking rate during a conversation.
- Two people are in a telephone conversation. Person A is listening to Person B talk. Person A is having difficulty understanding Person B since Person A feels Person B is talking too fast. This is a typical scenario for an elderly person such as person A who has difficulties in their temporal resolution of hearing. Person A would like to have the loopback speech of Person B's telephone slowed down such that Person B hears themselves talking slower.
- the loopback signal is the signal, which is looped back on the telephone to allow the person talking on the telephone to hear himself/herself talking.
- This is a standard feature on all phones and acts as a perceptual feedback mechanism to reassure the talker that their speech is being heard by the listener. In effect, it is a psychological cue letting the talker know that they are actually talking. Without a loopback signal, the talker does not feel certain that their speech is being sent to the listener and it creates tension in the conversation. For this reason all phones have a loopback signal, which simply passes speech back to the output speaker on the earpiece of the person speaking.
- the loopback rate can be 1) set by the listeners or 2) set by the talker.
- the speaker may realize they have a fast speaking rate and may selectively choose to have their own loopback rate preset to a slower speed.
- the listener is provided the option of adjusting the talker's loopback rate. This simply requires a digital message to be sent from one telephone to the other to change the rate when a button is depressed.
- An up-down button on the display allows either party to decrease the loopback speaking rate.
- a second button is used to select which telephone's loopback mode is adjusted, either the listener or the talker.
- the present invention provides a syllabic rate or word rate method to set the listeners preferred speaker listening rate.
- the syllabic rate describes the rate of speech by the number of syllables per unit time as a numeric value.
- the word rate describes how many words are spoken per unit time. For example, if a listener has a preferred hearing rate of N syllables (words) a minute where N is the number of syllables (words), and the present invention determines the current syllabic (words) rate as X syllables/minute, the present invention employs the time compression/expansion utility to change the speaking rate by a factor of N/X.
- the listener's preferred speaking rate is stored as a parameter value in the telephone as a custom profile for that user. Now, anyone who calls that user will have their loopback rate set to the listener's preferred listening rate.
- the present invention overcomes problems with the prior art by enabling users to adjust a preferred listening rate or loopback rate.
- the loopback rate in one embodiment is set by the listener and in another embodiment set by the speaker.
- the speaker may realize they have a fast speaking rate and may selectively choose to have their own loopback rate preset to a slower speed.
- the listener is provided the option of adjusting the speaker's loopback rate. This simply requires a message to be sent from one telephone to the other to change the rate when a button is depressed.
- An up-down button on the display allows either party to decrease the loopback speaking rate.
- a second button is used to select which telephone's loopback mode is adjusted, either the listener or the talker.
- a or an, as used herein, are defined as one or more than one.
- the term plurality, as used herein, is defined as two or more than two.
- the term another, as used herein, is defined as at least a second or more.
- the terms including and/or having, as used herein, are defined as comprising (i.e., open language).
- the term coupled, as used herein, is defined as connected, although not necessarily directly, and not necessarily mechanically.
- program, software application, and the like as used herein, are defined as a sequence of instructions designed for execution on a computer system.
- a program, computer program, or software application may include a subroutine, a function, a procedure, an object method, an object implementation, an executable application, an applet, a servlet, a source code, an object code, a shared library/dynamic load library and/or other sequence of instructions designed for execution on a computer system.
- the program may be stored or transferred through a computer readable medium such as a floppy disk, wireless interface or other storage medium.
- loopback rate refers to the rate at which audio is perceived back by a speaker and/or listener. In the present invention this is a selectable rate.
- SOLA is an acronym for Synchronized OverLap and Add refers to the algorithm and method implemented in a combination of hardware and software rate at which audio is perceived back by a speaker and/or listener. In the present invention this is a selectable rate.
- DSP Digital Signal Processor
- a frame is time interval equal to 20 ms, or 160 samples at an 8 kHz-sampling rate.
- Window is a portion of a frame, where one Frame may comprise one or more windows.
- Vocoder is a Method or algorithm for encoding and decoding speech samples to and from an efficient parametrization.
- FIG. 1 is a block diagram of a telephone handset 100 according to the present invention.
- the telephone handset 100 is an exemplary hardware platform for carrying out the present invention. It is important to note that other electronic devices such as digital tape recorders, personal digital assistances (PDAs) and other devices that play, transmit or broadcast recorded or a synthesized voice and the hardware platform of a telephone is only one embodiment in which the present invention is advantageously implemented. Further, the Telephone handset 100 may be included as part of other portable electronic devices including a wireless telephone, PDA, computer, electronic organizer, and other messaging device.
- PDAs personal digital assistances
- the telephone handset is wired or wireless and is implemented as one physical unit or in another embodiment dividend up into multiple units operating as one device for handling telephonic communications.
- the telephone handset 100 includes a controller 102 , a memory 104 , a non-volatile (program) memory 106 containing at least one application program 108 , a power source (not shown) through a power source interface 116 .
- the controller is any microcontroller, central processor, digital signal processor, or other unit.
- the telephone handset 100 transmits and receives signals for enabling a wired or wireless communication, such as a cellular telephone, in a manner well known to those of ordinary skill in the art.
- the controller 102 controls a radio frequency (RF) transmit/receive switch 118 that couples an RF signal from an antenna 122 through the RF transmit/receive (TX/RX) switch 118 to an RF receiver 114 , in a manner well known to those of ordinary skill in the art.
- the RF receiver 114 receives, converts, and demodulates the RF signal, and then provides a baseband signal, for example, to audio output module 128 and a transducer 130 , such as a speaker, in the telephone handset 100 to provide received audio to a user.
- the receiver operational sequence is under control of the controller 102 , in a manner well known to those of ordinary skill in the art.
- the controller 102 In a “transmit” mode, the controller 102 , for example, responding to a detection of a user input (such as a user pressing a button or switch on a user interface 112 of the device 100 ), controls the audio circuits and a microphone 126 through audio input module 124 , and the RF transmit/receive switch 118 to couple audio signals received from a microphone to transmitter circuits 120 and thereby the audio signals are modulated onto an RF signal and coupled to the antenna 122 through the RF TX/RX switch 118 to transmit a modulated RF signal into a wireless communication system (not shown).
- This transmit operation enables the user of the telephone handset 1100 to transmit, for example, audio communication into the wireless communication system in a manner well known to those of ordinary skill in the art.
- the controller 102 operates the RF transmitter 120 , RF receiver 114 , the RF TX/RN switch 118 , and the associated audio circuits (not shown), according to instructions stored in the program memory 110 .
- the controller 102 is communicatively coupled to a user input interface 107 (such as a key board, buttons, switches, and the like) for receiving user input from a user of the device 100 .
- a user input interface 107 such as a key board, buttons, switches, and the like
- the user input interface 107 in one embodiment is incorporated into the display 109 as “GUI (Graphical User Interface) Buttons” as known in the art.
- the user input interface 107 preferably comprises several keys (including function keys) for performing various functions in the device 100 .
- the user interface 107 includes a voice response system for providing and/or receiving responses from the device user.
- the user interface 108 includes one or more buttons used to generate a button press or a series of button presses such as received from a touch screen display or some other similar method of manual response initiated by the device user.
- the user input interface 107 couples data signals (to the controller 102 ) based on the keys depressed by the user.
- the controller 102 is responsive to the data signals thereby causing functions and features under control of the controller 102 to operate in the device 100 .
- the controller 102 is also communicatively coupled to a display 109 (such as a liquid crystal display) for displaying information to the user of the device 100 .
- the present invention can be realized in hardware, software, or a combination of hardware and software.
- the present invention can also be embedded in a computer program product, which comprises all the features enabling the implementation of the methods described herein, and which—when loaded in the device 100 —is able to carry out these methods.
- FIG. 2 is an exemplary user input interface 112 for the electronic device of FIG. 1 according to the present invention.
- a button implemented as part of the display or as a separate mechanical button for controlling the rate of compression and expansion of an audio wave file speed as further described below.
- the button in this example has two sets of positions for a possibility of four different types of control to an audio file being rendered.
- the first set of positions is speed up 202 and slow-down 204 , which control the compression and expansion of the audio wave file.
- the second set of positions is fast forward 206 and slow down 204 , which control the position in an audio file being played back such as a digital tape recorder or digital memo accessory to a telephone.
- the second set of buttons is shown only for completeness in implementing the present invention and only the first set of buttons 202 and 204 are needed to implement the invention.
- the present invention is implemented in a small memory footprint and low processor overhead in order to be compatible with currently available portable electronic devices.
- the controller 102 includes a couple of additional opcodes for particular speeds such as very slow (1.7 ⁇ original speed), slow (1.4 ⁇ original speed), fast (0.85 ⁇ original speed), and very fast (0.65 ⁇ original speed) requires a program memory space of about 620 bytes and a volatile memory size of about 13 bytes.
- the telephone handset 100 implements a wireless interface (not shown) and includes a Bluetooth wireless interface, a serial infrared communications interface (“SIR”), a Magic Beam interface and other low power small distance wireless communication interface solutions, as are well known to those of ordinary skill in the art.
- a wireless interface not shown
- SIR serial infrared communications interface
- Magic Beam interface and other low power small distance wireless communication interface solutions
- a syllable is defined as a unit of spoken language consisting of a single uninterrupted sound formed by a vowel, diphthong, or syllabic consonant alone, or by any of these sounds preceded, followed, or surrounded by one or more consonants.
- a diphthong is a complex speech sound or glide that begins with one vowel and gradually changes to another vowel within the same syllable. Every syllable begins with one consonant and has only one vowel. The number of syllables can be determined from a grammatical sentence by examining the text vowel content as follows:
- the number of vowels left is the same as the number of syllables. This is a general method of determining the number of syllables given the contextual representation of a speech sentence.
- the number of syllables that you hear when you pronounce a word is the same as the number of vowels sounds heard.
- the word “jane” has 2 vowels, but the “e” is silent leaving one vowel sound and one syllable.
- the word “ocean” has 3 vowels, but the “ea” is a diphthong, which counts as only one sound, so this word has only two vowels sounds and therefore, two syllables.
- Vowels consist of formant regions, which are high-energy peaks in the frequency spectrum. Vowels are characterized by their formant locations and bandwidths.
- the vowels are generally periodic in time, high in energy, and long in duration.
- vowel detection methods typically rely on a measure of periodicity such as pitch and/or energy.
- One such measure of periodicity is the zero crossing information, which is a measure of the spectral centroid of a signal.
- the dominant frequency principle shows that when a certain frequency band carries more power than other bands, it attracts the expected number of zero crossings per unit time.
- the zero crossing measure precipitates a measure of periodicity, which can be utilized in a voicing level decision.
- Pitch detection strategies can also elucidate the voicing level of speech.
- the autocorrelation function is a typically used in vocoder systems to obtain an estimate of the speech pitch.
- the autocorrelation reveals the degree of correlation in a signal and can be used with an iterative peak picking method to find the number of lags, which correspond to the maximum correlation.
- This lag value is a representative value of the speech pitch information and thus the level of tonality of voicing.
- any such method which precipitates a level of the speech voicing can be used to determine the syllabic rate.
- a measure which utilizes speech energy information, can be used for word segmentation to determine the speech word rate.
- the preferred speaking rate can also be applied with time-scale speech modification such as the Synchronized OverLap and Add (“SOLA”) method to text-to-speech message synthesis as further described below.
- Text-to-speech systems generate speech from text messages. Text messaging requires less bandwidth than voice.
- the speech rate of the text-to-speech device can be altered through time-scale modification given the synthesized speech rate and the preferred listening rate.
- the preferred speaking rate can also be applied to voice instruction systems such as voice reply navigation, tutorial Internet demos, and audio/visual follow-along graphical displays.
- FIG. 3 is a series of time-based speech samples illustrating time compression and time expansion of an original speech signal according to the present invention.
- Original speech signal 302 is illustrated as compressed in 304 and expanded in 306 . Notice that the over all shape of the speech signal is the same in each of the figures and just the horizontal time element is altered.
- This method uses a SOLA (Synchronized Overlap and Add) method to blend two frames of speech in the region of maximum correlation to produce a time compressed or expanded representation of two speech frames. Since the method operates on a frame-by-frame basis, the speech rate is dynamically changed as speech is being played out through the speaker. Frames are on the order of 20 to 30 ms.
- SOLA Synchronized Overlap and Add
- Time compression is a process, which blends periodic sections of the speech signal.
- the blending is a triangular overlap and add technique used to smooth out the shifted frame boundaries.
- Time expansion is essentially a process, which replicates and inserts sections of periodic speech and performs the same blending to smooth the transition regions.
- SOLA automatically operates on the voiced sections of speech such as the vowels. Vowels are known as the voiced regions since they are tonal due to the articulatory gestures involved in their creation.
- the vocal tract forms a cavity in which quasi-periodic pulses of air pass through and create the sound the present invention call speech.
- the vowels are periodic and provide the correlation necessary to achieve time compression and expansion with the SOLA method.
- FIG. 4 is an over all flow diagram corresponding to the over all process of performing real-time SOLA operations in a single outbound circular audio buffer using modulo pointers as shown in FIGS. 6-16 , according to the present invention. It is important to note the entire process occurs in the outbound audio buffer of an electronic device such as a limited space audio RAM buffer (not shown) in audio module 128 . This is important because the entire operation happens on the “fly” and while audio is played out a digital-to-analog converter (not shown) to a speaker 130 .
- the process begins on step 402 and proceeds directly to step 404 .
- two sub-windows A 2 502 and B 1 504 of FIG. 5 of an audio sample consisting of two frames (frame 1 506 , frame 2 508 ) are selected based upon from where in the buffer the current audio information is being read from and played through speaker 130 .
- the present invention integrates easily with outbound module audio buffers by:
- step 406 a test is made in step 406 whether the SOLA operation will be applied to compress (i.e. speed up) or expand (i.e. slow down) two adjacent windows of speech samples.
- the process continues in step 408 .
- the speech sample in A 2 oldwin 502 are copied and inserted in between oldwin A 2 and B 2 newin 508 as shown as A 2 oldwin 602 .
- the pointer for oldwin 510 is adjusted to point to the beginning of A 2 oldwin 602 . Therefore a duplicate 602 of window 502 now exists in the buffer.
- step 410 for both compression and expansion of the speech window (after a copy of the oldwin was inserted in step 408 for expansion).
- a cross correlation (oldwin, newin) is performed to determine position of maximum correlation.
- the oldwin is A 2 oldwin 602 as shown in FIG. 6 and for a compression the oldwin is A 2 oldwin 502 as shown in FIG. 5 .
- a real-time SOLA (Synchronized OverLap and Add) operation is performed where the data is written, using write pointer, into the audio output buffer at a position of maximum correlation and the process ends at step 416 .
- the output of the SOLA operation in place on the circular buffer is shown for compression in graph 702 and for expansion in graph 704 of FIG. 7 . Notice the SOLA region AB 712 looks a lot like the SOLA region AB 722 .
- the present invention uses FOUR rate adjustments used in the audio playback speed: Very slow ( ⁇ 1.7x), slow ( ⁇ 1.4x), fast ( ⁇ 0.8x) and very fast ( ⁇ 0.6x), where x describes the multiplicative change in time. So very slow means it plays it back 1.7 times as slow. These numbers are approximate rate changes, since the procedure is dependent on the speakers pitch. All four modes utilize the SOLA method. It is important to note that other number and rates of playback are within the true scope and spirit of the present invention. The different modes are selected by the state algorithm configuration which is one of two states: expansion or compression, and of one of two levels: half or full. In full compression, the SOLA blending is performed on every entrant (new) frame.
- FIG. 6 is a state diagram 600 illustrating the algorithm configurations for each of the four rate selections, which are discussed in further detailed in the section entitled “Detailed Overview Of SOLA Speech Time Compression” below.
- the following steps demonstrate the SOLA method to blend two frames of speech in the region of maximum correlation to produce a time-compressed representation of the two speech frames.
- the SOLA compression method is presented first since expansion is a simple extension of the compression method.
- the SOLA subroutine requires a new frame of speech passed each subroutine call for complete speech compression.
- the new speech frame is processed with the results of the previous speech frame.
- the processed speech remains on outbound audio buffer, such as in the audio output module 128 , or non-volatile memory 108 , and the pointers are then updated to denote this section as the previous speech frame for the next SOLA method call.
- a graph 900 as shown in FIG. 9 illustrates the first step of the SOLA method after pointers are correctly setup as shown in FIG. 4 .
- this step which is a graphic representation of step 410 , a determination of the maximum correlation point of two speech frames is made, according to the present invention. Illustrated is the maximum correlation point of two speech frames and return the highest correlation index of the crosscorrelation function 904 of oldwin A 2 502 (or in the case of expansion oldwin A 2 602 and it should be understood that the term oldwin can refer to either 502 or 602 depending on whether expansion or compression is being performed) and newin B 1 504 .
- Oldwin A 2 502 is the speech frame processed from the previous SOLA cycle.
- Newin B 1 504 is the current speech frame just placed on the outbound audio buffer.
- the determination of the maximum correlation is restricted to a correlation range 908 , which is exactly half the speech frame length. If the frame length is N samples 902 , the index-must fall between 0 and N/2 910 . This provides a maximum compression of two.
- a more sophisticated subsearch not utilized herein specifies the maximum correlation point within a range between samples of the pitch period. The crosscorrelation maximum is determined in real time, and so a determination of the maximum requires only a comparison of the last previous maximum. Only 1 data word x:acorrindex 906 is required for the entire process since each new speech frame has a new local maximum. The returned acorrindex 906 specifies the number of samples to left shift newin B 2 for maximum correlation before blending.
- FIG. 10 shown are two graphs 1002 and 1004 illustrating the second step of the SOLA method where a newin B 1 504 in frame 2 508 to overlap with newin A 1 602 in frame 1 506 at the point of corresponding maximum correlation is illustrated, according to the present invention.
- the position of newin 504 is to overlap with oldwin 502 at the point of corresponding maximum correlation.
- This point, x:rundindex 1 1008 is the subtraction of the correlation index (acorrindex 906 ) from the endpoint location of oldwin A 2 502 on the outbound audio buffer.
- the region between this point and the end of oldwin A 2 502 is the SOLA region 1010 .
- acorrindex 906 describes the number of samples to shift back newin 604 for maximum correlation. Accordingly, only the last acorrindex 906 samples of oldwin 602 will be used in the blending. Thus, the remaining samples of newin 604 (i.e., the frame length minus acorrindex 906 ) will need to be left shifted after SOLA processing to abut with the blended region.
- FIG. 11 is three graphs 1102 , 1104 , and 1106 illustrating the third step of the SOLA method where synchronized overlap and add is begun over SOLA region 1010 according to the present invention.
- a linear downramp 1108 is applied to a oldwin A 2 502
- a linear up ramp 1110 is applied to newin B 1 504 to blend the speech in this region.
- Blend speech fame 1112 in SOLA region 910 by applying a linear ramp to speech in SOLA region 910 and then adding the two signals together.
- FIG. 12 is a graph 1100 of a composite speech signal for which windows oldwin A 2 502 and newin B 1 502 have been blended into an AB subframe 1112 for speech compression, according to the present invention.
- the SOLA region, which was the overlapped speech region, is processed directly on the buffer.
- the remainder of newin B 1 504 must be shifted towards oldwin A 2 502 to append the unmodified data.
- Runindex 1 will now specify the beginning of oldwin 602 for the next SOLA cycle. Steps 1 to 4 are repeated and performed for each new frame of speech placed on the audio buffer. This is how time compressed speech is generated.
- the OB_Voice_Wptr is the main outbound buffer voice pointer that tells the codec where to read the next data samples to play out the speaker 130 .
- the OB_Voice_Wptr stands for OutBound (OB) and is a standard pointer to stream audio samples out similar to the InBound (IB) voice pointer for acquiring samples.
- IB InBound
- typically audio capturing/recording devices have an IB and OB pointer to direct a codec where to get/play audio samples.
- the present invention updates the OB pointer after the SOLA procedure since the audio data has been rearranged on the outbound audio buffer.
- the OB pointer By updating the OB pointer the continuity of the audio is preserved (i.e., the processed frames are congruent with neighbor frames). Accordingly, the OB pointer is re-positioned backward or forward in the module outbound audio buffer based on the SOLA processing performed. Specifically in the case of SOLA compression processing, audio samples are discarded and therefore the OB pointer is re-positioned backward in the outbound audio buffer. In the case of SOLA compression processing audio samples are being added through and therefore the OB pointer is re-positioned ahead a few samples. It is important to note that the OB pointer updates are included to process audio on an outbound audio buffer of fixed data length on a real time system.
- SOLA routines are all processed not in real-time on the outbound audio buffer but rather processed and buffered separately in additional memory space and not in the outbound audio buffer.
- the present invention is processing audio samples in the outbound audio buffer on a frame-by-frame basis in real time.
- the SOLA support routines in the next sections perform the ob_voice_buf_wptr updates.
- This section contains a general description of the low-level design function adjustment modes, which are specified by the implementation of the SOLA method as described in this section. The following functions are illustrated in the state diagram 600 of FIG. 6 .
- Outbound_sola_frame_ready( ) 402 This method checks to see if adequate space exists on the outbound voice_buffer for SOLA processing.
- the standard procedure for playback of digitized and/or recorded voice is to check if there are at least N samples of free space available to decode the vocoded speech where N is the speech frame length. If N samples are available, a call to the decoder is made and the samples are placed on the outbound buffer beginning at the ob_voice_buf_wptr.
- Incr_OB_Voice_Buf_Wptr After the data is placed, a call to Incr_OB_Voice_Buf_Wptr is made to update the write pointer by a frame length.
- the amount of available space is determined as the difference between the ob_voice_buf_wptr and the ob_voice_buf_rptr.
- the subroutine Outbound_Voice_Frame_Ready checks to ensure there is at least one frame of space available.
- the Outbound_Voice_Frame_Ready call is sufficient since no more data will be added to the voice buffer and the data is already available on the buffer for SOLA processing.
- frame duplication is necessary which requires more space on the outbound buffer.
- the frame duplication replicates 1 half frame for every speech frame. It is thus necessary to ensure that there are at least 1.5 frames of additional space on the outbound buffer before a call to SOLA is made.
- the present invention actually makes sure that there are at least 2 speech frames of space available.
- the call to Outbound_sola_Frame_Ready checks to see it at least 2 frames of speech data are available before any calls to SOLA are made.
- SOLA compression is unaffected so this method is used for both compression and expansion.
- Acorr( ) 402 , 422 The precursor method to SOLA is always a call to the crosscorrelation method for both speech time expansion and compression.
- the acorr method determines the maximum correlation lag index between the oldwin and newin speech frames. This lag index describes the number of samples to left shift the newin frame is to overlap with the oldwin frame.
- there is an crosscorrelation range to search for the lag which is 0 to N/2 for the two compression modes and 0 to N/4 for the two expansion modes, where N is the frame length. For compression, a larger search range provides maximal compression, and for expansion a smaller search range provides maximal expansion.
- the sola_enable_cf data word specifies the type of rate adjustment: (+2) full compression 412 , (+1) half compression, (+1) 404 , half expansion 418 , and ( ⁇ 2) full expansion 418 .
- These numeric values are to select the SOLA mode.
- a (+) value denotes compassion and a ( ⁇ ) value denotes expansion.
- the numeric vales of 1 and 2 are only to designate the mode level as half or full.
- the sola_enable_cf also sets the range for the crosscorrelation lag search on every call to the acorr method. Thus, compression and expansion levels can change the playback rate as speech is being played. If sola_enable_cf is positive the range 0 to N/2 is selected by a right shift of 1, and if sola_enable_cf is negative the range 0 to N/ 4 is selected by a right shift of 2 given the frame length N.
- FIG. 14 is a diagram of the pointers for the method update_sola_ptrs ( ) to update the sola pointers by a frame length for compression, according to the present invention.
- Update_sola_ptrs( ) 408 updates the SOLA pointers by a frame length as a simple way to reduce the compression level by a factor of two.
- the SOLA method itself updates the SOLA pointers after SOLA processing. In full compression, this means that the ob_voice_buf_wptr and sola_newin_ptr will be pointing to the same point after the SOLA call.
- the half-compression method only performs a SOLA operation on every other voice data ready call.
- the skipped Frame flag toggles states to signify when SOLA should be called as seen in the high-level design of FIG. 4 to make sure speech data is on the buffer.
- FIG. 15 is a diagram of the pointers for the method update_sola_ptrs( ) to update the sola pointers by a frame length for expansion, according to the present invention. The simplest way to do this is to increment the SOLA pointers by a half frame length after the call to the SOLA method. This is the exact same procedure as for the compression update, except it updates the pointers by a half frame length instead of a full frame length.
- FIG. 16 is a diagram of the pointers for the method shift_blocks ( ), according to the present invention.
- Shift Blocks( ) 420 The next two subroutines shift_blocks and shift_sola extend the sola speech compression method for speech expansion.
- the expansion method requires frame duplication followed by the sola method.
- Essentially expansion is compression of replicated speech frames.
- the replication provides the additional data for time expansion and the sola provides the blending to remove duplicate frame boundary discontinuities. It is necessary to shift all data above sola_newin_ptr up to ob_voice_buf_wptr. Then, the present invention replicates the half frame block just below sola_newin_ptr.
- IMPLEMENTATION set r 1 at ob_voice_buf_wptr set r 2 one half voice frame above ob_voice_buf_wptr. Then copy data from r 1 to r 2 by decreasing both pointers (r 1 -),(r 2 -). Stop when r 1 reaches the end of the frame to duplicate which is 1 ⁇ 2 frame below sola_oldwin_ptr. This is a total loop of: ob_voice_buf_wptr-sola_newin_ptr+N/2
- FIG. 17 is a diagram of the pointers for the method shift_sola ( ), according to the present invention.
- Shift Sola( ) 426 Sola only returns processed data between the sola_oldwin_ptr and sola_newin_ptr region. It is not aware of the location of the ob_voice_buf_wptr or the relation to other data on the outbound voice_buffer. It is thus necessary to shift back all data above sola_newin_ptr to the left by the shift back amount (acorrindex) after a call to sola. This is particularly important for the expansion mode since the ob_voice_buf_wptr and sola_newin_ptr will point to different places after each sola call.
- the Outbound_Sola_Frame_Ready routine checks to see whether there is sufficient room on the buffer for expansion and places data accordingly.
- the expansion rate determines the rate at which data is placed on the outbound buffer correlated with the ob_voice_buf_wptr as they are in compression.
- the sola_newin_ptr is aligned with the b_voice_buf_wtpr after each sola function call. This is not the case in expansion. It is thus necessary to shift back data on the outbound buffer between sola_newin_ptr and the ob_voice_buf_wtpr after each sola function call. This is the purpose of the shift_sola method.
- FIGS. 18 and 19 are high-level MatLab code for caring out the SOLA operations, according to the present invention.
- the high-level MatLab code (MATLAB is a registered trademark of Mathworks Inc.) is exemplary only for the SOLA operations and the implementation of modulo pointers for a limited buffer size and buffer updates must be added as shown above in FIGS. 4-17 .
- FIG. 20 shown is a block diagram of an embodiment illustrating how loopback combined with SOLA processing is used to adjust speech rate, according to the present invention, shown are two wireless telephone handsets 2002 and 2004 corresponding to exemplary hardware platform of FIG. 1 . Shown is the loopback path 2012 for Telephone Handset A 2002 and 2014 for Telephone Handset B 2004 .
- the loopback path is an audio path, known to those in the telephony art where a person such as User A (not shown) using Telephone Handset A, 2002 is able to hear through speaker 130 their own voice when spoken into microphone 124 . Loopback paths are widely used and deployed in a variety of telephony applications.
- the communications infrastructure is greatly simplified in the present invention because the details are not important to carrying out the invention.
- Audio path 2022 is shown from microphone 124 of Telephone Handset A 2002 through communications infrastructure ( 2030 to the speaker 130 of Telephone Handset B 2004 indicating that audio signals in the microphone 124 of Telephone Handset A 2002 besides being looped back 2012 is are also audible through speaker 130 of Telephone Handset B.
- audio through microphone 124 of wireless device 2004 is sent through communications infrastructure 2030 to speaker 130 of Telephone Handset A 2002 along with the loopback path 2014 .
- This diagram is greatly simplified showing a general communication infrastructure 2030 .
- the communications infrastructure 2030 in one preferred embodiment is wireless but any communications infrastructure including wire, wireless, broadcast, PSTN, satellite and Internet is within the true scope and spirit of the present invention.
- Telephone Handset A 2002 illustrated are two handsets, Telephone Handset A 2002 and Telephone Handset B.
- User A speaks her voice is audible through User B's Telephone Handset B through communication infra structure 2030 .
- User A hear her own voice through loopback 2012 .
- User B believes User A is speaking at too rapid a rate, User B using user interface 112 such as the button shown in FIG. 2 adjusts the loopback path of User A's Telephone Handset A.
- the loopback rate is altered using the real-time SOLAR method on the audio output buffer in audio module 128 .
- the only communication between the two telephone handsets 2002 and 2004 is a rate variable, which is inserted in the audio data being communicated between the telephone handsets.
- the selectable rate variable (a single bit or byte) sent from one telephone handset to the other to change the rate when a button 112 is depressed.
- the rate variable is in a message as a simple number or flag representing the percent change in either speed up or slow down of the loopback rate.
- the message is coupled to an up-down button on the display, and allows either party to decrease the loopback rate.
- a second button is used to select which telephone's loopback mode is adjusted, either the listener or the speaker (i.e. talker).
- the exact format of the rate variable is unimportant and is inserted dynamically which when received by a corresponding handset switches the SOLA rate as described above.
- the loopback rate is set by the listener (e.g. User B), in another embodiment it is set by the speaker (User A) using user interface 112 . It is important to note that the loopback rate may be physically adjusted in the listener's handset, the speaker's handset or in the communications infrastructure 2030 .
- the low processing overhead requirements of the present invention combined with the application of the SOLA technique directly in an audio output buffer while being played enables these different types of deployment.
- the speaker may realize they have a fast speaking rate and may selectively choose to have their own loopback rate preset to a slower speed.
- the present invention provides a syllabic rate or word rate method to set the listeners preferred speaker listening rate.
- the syllabic rate describes the rate of speech by the number of syllables per unit time as a numeric value.
- the word rate describes how many words are spoken per unit time. For example, if a listener has a preferred hearing rate of N syllables (words) a minute where N is the number of syllables (words), and the present invention determines the current syllabic (words) rate as X syllables/minute, the present invention employs the time compression/expansion utility to change the speaking rate by a factor of N/X.
- the listener's preferred speaking rate is stored as a parameter value in the telephone handset as a custom profile for that user. In this embodiment, anyone calling that user will have their loopback rate set to the listener's preferred listening rate.
- the present invention permits a user to speed up and slow down speech without changing the speaker's pitch. It is a user adjustable feature to change the spoken rate to the listeners' preferred listening rate or comfort. It can be included on the phone as a customer convenience feature without changing any characteristics of the speakers voice besides the speaking rate with soft key button combinations (in interconnect or normal). From the users perspective, it would seem only that the talker changed his speaking rate, and not that the speech was digitally altered in any way. The pitch and general prosody of the speaker are preserved. The following uses of the time expansion/compression feature are listed to compliment already existing technologies or applications in progress including messaging services, messaging applications and games, real-time feature to slow down the listening rate.
Abstract
Description
-
- keeping track of the pointers;
- determining if there is sufficient room for processing on the modulo audio buffer; and
- writing data on the modulo audio buffer which so as not to overwrite any previously processed audio set or currently being rendered through
audio output module 128speaker 130.
In the simplest embodiment of the present invention there are four pointers to the outbound audio buffer as follows: - 1. Read pointer—point from where in the circular audio buffer the samples are being read and played through
speaker 130. The position of this pointer is not adjusted in the present invention but rather the position of the read pointer moves modulo through the buffer playing out audio samples. - 2. Write pointer—point where updates to the audio buffer are written. This pointer is adjusted based on where in the buffer the SOLA operation is being performed
- 3. Oldwin pointer—pointer to the start of an old window in a frame
- 4. Newin pointer—pointer to the start of a new window in a frame immediately adjacent in time to the old window. The frame for the oldwin pointer and the new window pointer do not have to be the same frame but rather the frames only need to be adjacent in time.
It is important to note that the rate of expansion and compression cannot exceed the rate in which data is being written into the circular audio buffer. As long as there is sufficient space in the audio buffer, the number of frames and/or windows being processed at any given time can change. This enables Speed slow down and speed up as audio is being played out of the buffer in real-time.
-
- 1) User A speaking at N words/second.
- 2) User B wants User A to talk slower.
- 3) User B hits the slow down
button 112 on his Telephone Handset B for User A's loopback rate on herTelephone Handset A 2002. - 4) A message is sent to User A's
Telephone Handset A 2002. - 5) SOLA time expansion is invoked on
Telephone Handset A 2002. - 6) Speech is slowly slowed down on User As
loopback path 2012. - 7) User A begins to talk slower since she hears herself slower.
- 8) Control module measures speaking rate.
- 9) If desired rate reached (SOLA rate kept constant).
- 10) If desired rate exceeded (SOLA rate increased).
- 11) If desired rate under (SOLA rate decreased).
The present invention allows the speakers speech rate to be changed dynamically as the loopback rate is adjusted.
Claims (22)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US10/607,760 US8340972B2 (en) | 2003-06-27 | 2003-06-27 | Psychoacoustic method and system to impose a preferred talking rate through auditory feedback rate adjustment |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US10/607,760 US8340972B2 (en) | 2003-06-27 | 2003-06-27 | Psychoacoustic method and system to impose a preferred talking rate through auditory feedback rate adjustment |
Publications (2)
Publication Number | Publication Date |
---|---|
US20040267524A1 US20040267524A1 (en) | 2004-12-30 |
US8340972B2 true US8340972B2 (en) | 2012-12-25 |
Family
ID=33540370
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US10/607,760 Active 2029-11-19 US8340972B2 (en) | 2003-06-27 | 2003-06-27 | Psychoacoustic method and system to impose a preferred talking rate through auditory feedback rate adjustment |
Country Status (1)
Country | Link |
---|---|
US (1) | US8340972B2 (en) |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20150064666A1 (en) * | 2013-09-05 | 2015-03-05 | Korea Advanced Institute Of Science And Technology | Language delay treatment system and control method for the same |
Families Citing this family (8)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7509255B2 (en) * | 2003-10-03 | 2009-03-24 | Victor Company Of Japan, Limited | Apparatuses for adaptively controlling processing of speech signal and adaptively communicating speech in accordance with conditions of transmitting apparatus side and radio wave and methods thereof |
JP2014106247A (en) * | 2012-11-22 | 2014-06-09 | Fujitsu Ltd | Signal processing device, signal processing method, and signal processing program |
US20140257799A1 (en) * | 2013-03-08 | 2014-09-11 | Daniel Shepard | Shout mitigating communication device |
EP2899723A1 (en) * | 2013-12-16 | 2015-07-29 | Thomson Licensing | Method for accelerated restitution of audio content and associated device |
EP3327723A1 (en) * | 2016-11-24 | 2018-05-30 | Listen Up Technologies Ltd | Method for slowing down a speech in an input media content |
US10586079B2 (en) * | 2016-12-23 | 2020-03-10 | Soundhound, Inc. | Parametric adaptation of voice synthesis |
US10276185B1 (en) * | 2017-08-15 | 2019-04-30 | Amazon Technologies, Inc. | Adjusting speed of human speech playback |
DE102019213809B3 (en) * | 2019-09-11 | 2020-11-26 | Sivantos Pte. Ltd. | Method for operating a hearing aid and hearing aid |
Citations (19)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4550425A (en) * | 1982-09-20 | 1985-10-29 | Sperry Corporation | Speech sampling and companding device |
US5175769A (en) | 1991-07-23 | 1992-12-29 | Rolm Systems | Method for time-scale modification of signals |
US5611002A (en) | 1991-08-09 | 1997-03-11 | U.S. Philips Corporation | Method and apparatus for manipulating an input signal to form an output signal having a different length |
US5630013A (en) | 1993-01-25 | 1997-05-13 | Matsushita Electric Industrial Co., Ltd. | Method of and apparatus for performing time-scale modification of speech signals |
US5694521A (en) * | 1995-01-11 | 1997-12-02 | Rockwell International Corporation | Variable speed playback system |
US5717823A (en) * | 1994-04-14 | 1998-02-10 | Lucent Technologies Inc. | Speech-rate modification for linear-prediction based analysis-by-synthesis speech coders |
US5717818A (en) * | 1992-08-18 | 1998-02-10 | Hitachi, Ltd. | Audio signal storing apparatus having a function for converting speech speed |
US5806023A (en) | 1996-02-23 | 1998-09-08 | Motorola, Inc. | Method and apparatus for time-scale modification of a signal |
US5828995A (en) * | 1995-02-28 | 1998-10-27 | Motorola, Inc. | Method and apparatus for intelligible fast forward and reverse playback of time-scale compressed voice messages |
US5842172A (en) | 1995-04-21 | 1998-11-24 | Tensortech Corporation | Method and apparatus for modifying the play time of digital audio tracks |
US5893062A (en) | 1996-12-05 | 1999-04-06 | Interval Research Corporation | Variable rate video playback with synchronized audio |
US5920840A (en) | 1995-02-28 | 1999-07-06 | Motorola, Inc. | Communication system and method using a speaker dependent time-scaling technique |
US6173255B1 (en) | 1998-08-18 | 2001-01-09 | Lockheed Martin Corporation | Synchronized overlap add voice processing using windows and one bit correlators |
US6278387B1 (en) | 1999-09-28 | 2001-08-21 | Conexant Systems, Inc. | Audio encoder and decoder utilizing time scaling for variable playback |
WO2001074040A2 (en) | 2000-03-27 | 2001-10-04 | Soma Networks, Inc. | Voicemail for wireless systems |
WO2002009090A2 (en) | 2000-07-26 | 2002-01-31 | Ssi Corporation | Continuously variable time scale modification of digital audio signals |
US20020038209A1 (en) * | 2000-04-06 | 2002-03-28 | Telefonaktiebolaget Lm Ericsson (Publ) | Method of converting the speech rate of a speech signal, use of the method, and a device adapted therefor |
US20020052967A1 (en) | 1999-05-04 | 2002-05-02 | Goldhor Richard S. | Method and apparatus for providing continuous playback or distribution of audio and audio-visual streamed multimedia received over networks having non-deterministic delays |
US20040179676A1 (en) * | 1999-06-30 | 2004-09-16 | Kozo Okuda | Speech communication apparatus |
-
2003
- 2003-06-27 US US10/607,760 patent/US8340972B2/en active Active
Patent Citations (20)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4550425A (en) * | 1982-09-20 | 1985-10-29 | Sperry Corporation | Speech sampling and companding device |
US5175769A (en) | 1991-07-23 | 1992-12-29 | Rolm Systems | Method for time-scale modification of signals |
US5611002A (en) | 1991-08-09 | 1997-03-11 | U.S. Philips Corporation | Method and apparatus for manipulating an input signal to form an output signal having a different length |
US5717818A (en) * | 1992-08-18 | 1998-02-10 | Hitachi, Ltd. | Audio signal storing apparatus having a function for converting speech speed |
US5630013A (en) | 1993-01-25 | 1997-05-13 | Matsushita Electric Industrial Co., Ltd. | Method of and apparatus for performing time-scale modification of speech signals |
US5717823A (en) * | 1994-04-14 | 1998-02-10 | Lucent Technologies Inc. | Speech-rate modification for linear-prediction based analysis-by-synthesis speech coders |
US5694521A (en) * | 1995-01-11 | 1997-12-02 | Rockwell International Corporation | Variable speed playback system |
US5920840A (en) | 1995-02-28 | 1999-07-06 | Motorola, Inc. | Communication system and method using a speaker dependent time-scaling technique |
US5828995A (en) * | 1995-02-28 | 1998-10-27 | Motorola, Inc. | Method and apparatus for intelligible fast forward and reverse playback of time-scale compressed voice messages |
US5842172A (en) | 1995-04-21 | 1998-11-24 | Tensortech Corporation | Method and apparatus for modifying the play time of digital audio tracks |
US5806023A (en) | 1996-02-23 | 1998-09-08 | Motorola, Inc. | Method and apparatus for time-scale modification of a signal |
US5893062A (en) | 1996-12-05 | 1999-04-06 | Interval Research Corporation | Variable rate video playback with synchronized audio |
US6173255B1 (en) | 1998-08-18 | 2001-01-09 | Lockheed Martin Corporation | Synchronized overlap add voice processing using windows and one bit correlators |
US20020052967A1 (en) | 1999-05-04 | 2002-05-02 | Goldhor Richard S. | Method and apparatus for providing continuous playback or distribution of audio and audio-visual streamed multimedia received over networks having non-deterministic delays |
US20040179676A1 (en) * | 1999-06-30 | 2004-09-16 | Kozo Okuda | Speech communication apparatus |
US6278387B1 (en) | 1999-09-28 | 2001-08-21 | Conexant Systems, Inc. | Audio encoder and decoder utilizing time scaling for variable playback |
WO2001074040A2 (en) | 2000-03-27 | 2001-10-04 | Soma Networks, Inc. | Voicemail for wireless systems |
US20020038209A1 (en) * | 2000-04-06 | 2002-03-28 | Telefonaktiebolaget Lm Ericsson (Publ) | Method of converting the speech rate of a speech signal, use of the method, and a device adapted therefor |
WO2002009090A2 (en) | 2000-07-26 | 2002-01-31 | Ssi Corporation | Continuously variable time scale modification of digital audio signals |
US6718309B1 (en) * | 2000-07-26 | 2004-04-06 | Ssi Corporation | Continuously variable time scale modification of digital audio signals |
Non-Patent Citations (1)
Title |
---|
Nejime et al. "A Portable Digital Speech-Rate Converter for Hearing Impairment". IEEE Trans Rehabil Eng. 1996, pp. 73-83. * |
Cited By (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20150064666A1 (en) * | 2013-09-05 | 2015-03-05 | Korea Advanced Institute Of Science And Technology | Language delay treatment system and control method for the same |
US9875668B2 (en) * | 2013-09-05 | 2018-01-23 | Korea Advanced Institute Of Science & Technology (Kaist) | Language delay treatment system and control method for the same |
Also Published As
Publication number | Publication date |
---|---|
US20040267524A1 (en) | 2004-12-30 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US6999922B2 (en) | Synchronization and overlap method and system for single buffer speech compression and expansion | |
CA2372061C (en) | Real-time transcription correction system | |
US5765134A (en) | Method to electronically alter a speaker's emotional state and improve the performance of public speaking | |
US20150281853A1 (en) | Systems and methods for enhancing targeted audibility | |
JP2017538146A (en) | Systems, methods, and devices for intelligent speech recognition and processing | |
JP5326533B2 (en) | Voice processing apparatus and voice processing method | |
EP1814355A1 (en) | Acoustic adjustment device and acoustic adjustment method | |
Hirsch et al. | The simulation of realistic acoustic input scenarios for speech recognition systems. | |
US8340972B2 (en) | Psychoacoustic method and system to impose a preferred talking rate through auditory feedback rate adjustment | |
KR20060122854A (en) | System and method for audio signal processing | |
JP2008042787A (en) | Apparatus and method for adapting hearing | |
WO2014194273A2 (en) | Systems and methods for enhancing targeted audibility | |
JP3553828B2 (en) | Voice storage and playback method and voice storage and playback device | |
US20060088154A1 (en) | Telecommunication devices that adjust audio characteristics for elderly communicators | |
JP6904255B2 (en) | Information processing system and program | |
JP2012095047A (en) | Speech processing unit | |
JP3024099B2 (en) | Interactive communication device | |
JP2009027356A (en) | Communication device | |
KR100542976B1 (en) | A headphone apparatus with soft-sound funtion using prosody control of speech signal | |
KR100533217B1 (en) | A headphone apparatus with gentle function using signal processing for prosody control of speech signals | |
JP2012015853A (en) | Portable electronic apparatus | |
KR100460411B1 (en) | A Telephone Method with Soft Sound using Accent Control of Voice Signals | |
JPH10224898A (en) | Hearing aid | |
JP2007212967A (en) | Speaking speed converting device | |
JPH0698398A (en) | Non-voice section detecting/expanding device/method |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: MOTOROLA, INC., ILLINOISFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:BOILLOT, MARC ANDRE;HARRIS, JOHN GREGORY;REINKE, THOMAS LAWRENCE;REEL/FRAME:014246/0795;SIGNING DATES FROM 20030620 TO 20030626Owner name: MOTOROLA, INC., ILLINOISFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:BOILLOT, MARC ANDRE;HARRIS, JOHN GREGORY;REINKE, THOMAS LAWRENCE;SIGNING DATES FROM 20030620 TO 20030626;REEL/FRAME:014246/0795 |
|
AS | Assignment |
Owner name: MOTOROLA MOBILITY, INC, ILLINOISFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:MOTOROLA, INC;REEL/FRAME:025673/0558Effective date: 20100731 |
|
AS | Assignment |
Owner name: MOTOROLA MOBILITY LLC, ILLINOISFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:MOTOROLA MOBILITY, INC.;REEL/FRAME:028829/0856Effective date: 20120622 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
AS | Assignment |
Owner name: GOOGLE TECHNOLOGY HOLDINGS LLC, CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:MOTOROLA MOBILITY LLC;REEL/FRAME:034316/0001Effective date: 20141028 |
|
FPAY | Fee payment |
Year of fee payment: 4 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 8TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1552); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 8 |