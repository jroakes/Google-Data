CN108073680B - Generating presentation slides with refined content - Google Patents
Generating presentation slides with refined content Download PDFInfo
- Publication number
- CN108073680B CN108073680B CN201711108164.6A CN201711108164A CN108073680B CN 108073680 B CN108073680 B CN 108073680B CN 201711108164 A CN201711108164 A CN 201711108164A CN 108073680 B CN108073680 B CN 108073680B
- Authority
- CN
- China
- Prior art keywords
- content
- refined
- content items
- slide
- data
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/20—Natural language analysis
- G06F40/205—Parsing
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/20—Natural language analysis
- G06F40/258—Heading extraction; Automatic titling; Numbering
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/30—Information retrieval; Database structures therefor; File system structures therefor of unstructured textual data
- G06F16/34—Browsing; Visualisation therefor
- G06F16/345—Summarisation for human users
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/10—Text processing
- G06F40/103—Formatting, i.e. changing of presentation of documents
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/10—Text processing
- G06F40/103—Formatting, i.e. changing of presentation of documents
- G06F40/106—Display of layout of documents; Previewing
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/10—Text processing
- G06F40/12—Use of codes for handling textual entities
- G06F40/131—Fragmentation of text files, e.g. creating reusable text-blocks; Linking to fragments, e.g. using XInclude; Namespaces
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/10—Text processing
- G06F40/12—Use of codes for handling textual entities
- G06F40/151—Transformation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/10—Text processing
- G06F40/166—Editing, e.g. inserting or deleting
- G06F40/186—Templates
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N20/00—Machine learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/10—Text processing
- G06F40/166—Editing, e.g. inserting or deleting
- G06F40/177—Editing, e.g. inserting or deleting of tables; using ruled lines
Abstract
The application relates to generating presentation slides with refined content. One method comprises the following steps: the method includes receiving one or more data files as source material for slide generation, obtaining content from the one or more data files for slides in a slide presentation, identifying layout templates for the slides based on the content, and refining the content into refined content to generate a presentation visualization based on the refined content. The refined content comprises a subset of the content. The method also includes generating the slide based on the presentation visualization item and the layout template.
Description
Technical Field
Aspects and embodiments of the present disclosure relate to electronic documents, and more particularly, to generating presentation slides (presentation slides) with abstracted content.
Background
The set of presentation slides may include a set of presentation slides that may be displayed to one or more people to provide a visual illustration during a presentation. A presentation slide may refer to a display page that includes text, images, video, and/or audio for presentation to one or more people. For example, a presentation slide may include brief sentences or points to describe information to be conveyed by the presenter. To prepare a presentation slide set, a presenter may conduct research and collect one or more documents related to a presentation topic. The presenter can summarize the large amount of textual content from these documents into a short description or illustration in a presentation slide. In addition, the presenter may also design and arrange the layout and format of each slide, such as font size, color, background color, gist alignment, and/or animation configuration.
Disclosure of Invention
Aspects and embodiments of the present disclosure relate to generating slides with abstracted content for a slide presentation. One or more data files may be obtained as support material for slide generation. The content in one or more data files may be extracted automatically, or the user may select the desired content to be extracted for slide generation. A layout template may be identified and selected based on the type of content extracted. The extracted content may be refined into refined content to generate presentation visualizations such as lists (e.g., points), data charts, data tables, images, and so on based on the refined content. Presentation slides may then be generated based on the presentation visualization items and the layout template.
Drawings
Aspects and embodiments of the present disclosure will be understood more fully from the detailed description given below and from the accompanying drawings of various aspects and embodiments of the disclosure, which, however, should not be taken to limit the disclosure to the specific aspects or embodiments, but are for explanation and understanding only.
Fig. 1 illustrates an example of a system architecture for embodiments of the present disclosure.
FIG. 2 illustrates a flow diagram of aspects of a method for generating a slide show including refined content according to one embodiment of the present disclosure.
FIG. 3 shows an example slide presentation including a slide set generated from a data file in accordance with an illustrative embodiment.
Fig. 4 illustrates a flow diagram of a method for representing summary text in a list of slides according to one embodiment of the present disclosure.
FIG. 5 shows a more detailed example of slides in a slide presentation generated from a data file in accordance with an illustrative embodiment.
FIG. 6 shows an example of sending selected portions of content from a data file to a slide presentation in accordance with an illustrative embodiment.
FIG. 7 shows an example of receiving selected content and separating the selected content into separate slides in accordance with an illustrative embodiment.
FIG. 8 illustrates a flow diagram of an aspect of a method for representing images extracted from source material in a slide show and text associated with the images, according to one embodiment of the present disclosure.
FIG. 9 shows an example of representing an image extracted from source material in a slide and text associated with the image in accordance with an illustrative embodiment.
FIG. 10 illustrates a flow diagram of an aspect of a method for representing extracted range data in a data chart of a slide show according to one embodiment of the present disclosure.
FIG. 11 shows an example of data representing an extracted range in a data diagram of a slide show in accordance with an illustrative embodiment.
FIG. 12 shows an example of data representing different extracted ranges in data tables of different slides in accordance with an illustrative embodiment.
Fig. 13 illustrates a block diagram of an example computing system operating in accordance with one or more aspects of the present disclosure.
Detailed Description
In general, a user may perform many actions when parsing source content and creating a slide presentation. For example, a user may need to find and open each relevant data file for a particular topic. The user may need to parse a large portion of the source content and select a main point from the source content to include in the slide presentation. The user may need to copy many portions of the source content into individual slides of the slide presentation. In some cases, the user may select a larger portion of the content than is required to be included in the slide to adequately represent points, facts, statistics, perspectives, and the like.
In some cases, the processing speed of the computing device may be reduced due to the generation of slide presentations that include large amounts of content, and/or network bandwidth may be adversely affected when slide presentations that include large amounts of content are transmitted over a network to a user device. In addition, the user must define the structure of the presentation and create logical breakpoints for the slides in the presentation. In some cases, the user may create more slides than are required to adequately represent the presentation theme. A larger display document may result in an increase in the file size of the display document, which may adversely affect processing speed, network bandwidth, and the like. The user must also select a consistent and visually appealing design and apply it to each slide in the presentation. Thus, it should be appreciated that these actions may be tedious for the user and also not preferred for the performance of the computing device and/or network.
Aspects and embodiments of the present disclosure are directed to a collaborative document system that addresses at least these deficiencies and others by generating presentation slides with refinements for slide presentations. Embodiments disclosed herein may be applied to any suitable data file including any suitable content (e.g., text, data tables, images, audio, video, etc.) to generate slides for a slide presentation. For example, one such data file may include an electronic document uploaded by a user device or created using a collaborative document system.
An electronic document refers to media content used in electronic form. Media content may include text, data sheets, videos, images, graphics, slides, charts, software programming code, designs, lists, plans, blueprints, maps, and so forth. The electronic document may be stored in a cloud-based environment. Electronic documents that a user has access to and/or edits may be referred to herein as collaborative documents. Through the collaborative document, the user is able to see content changes (e.g., character by character) as other collaborators edit the document. Although in the remainder of this disclosure, a collaborative document system is described as implementing the disclosed techniques, it should be noted that any suitable system or application (e.g., a local application installed on a user device) may generate slides for a slide presentation based on content in one or more data files.
The collaborative document system may allow collaborative document owners to invite other users to join as collaborators on collaborative documents stored in a cloud-based environment. The collaboration document may be provided by one or more servers in the cloud-based environment to the collaborators' user devices. Each collaborator may be associated with a user type (e.g., editor, reviewer, viewer, etc.). Different views and capabilities may be provided to collaborators to edit, comment on, review, or simply view the collaborative document, depending on the user type. Once rights are granted to access the collaboration document, the collaborators may access the collaboration document to perform the operations permitted for their user type.
Using the collaborative document system, a user may create or open a collaborative document (e.g., in a web browser) and share the collaborative document with one or more collaborators. In some embodiments, the collaboration document may be a slide presentation that is automatically generated by the slide generation module based on the content of one or more data files. The slide generation module may receive as input one or more data files or selected contents of one or more data files and extract certain content from the data files or selected contents. The slide generation module may select one or more layout templates for one or more slides based on the type of content. For example, a layout template including a title may be selected for content that is a title in a data file, a layout template including a tile header may be selected for content that is a tile header in a data file, and/or a layout template including a title and a body text may be selected for content in a data file that includes text, data tables, images, and the like. Thus, in some embodiments, the format and style in the input data file may be maintained for the generated slides output by the slide generation module, as described further below.
In some implementations, the extracted content can be refined into refined content by the slide generation module. Refining may refer to reducing the extracted content from a first amount of content to a second, lesser amount of content. For example, refinement may refer to summarizing text included in the extracted content from a first number of sentences to a second number of sentences smaller than the first number of sentences. Refinements and generalizations are used interchangeably herein. In another example, refinement may refer to reducing the data tables in the extracted content to a selected data range that is a subset of the entire data table. Further, refinement may refer to identifying an image in the content and extracting the image from the content. Presentation visualizations including the refined content can be generated based on the type of refined content. For example, a presentation visualization including a list (e.g., a gist) may be generated for refinement having a text type, a presentation visualization including a data table, a data chart, or a data diagram may be generated for refinement including a data table, and/or a presentation visualization including an image may be generated for refinement including an image.
One example of how these techniques may be used may include situations where an employee wants to create a slide set for a "sales profile for a financial year". The employee may have a market report, a spreadsheet for sales data, documentation for new products, and the like. Employees may upload documents to the slide generation module for automatic content refinement and slide generation. The slide generation module may abstract several sentences from the market report for inclusion in the gist list in the first slide. The slide generation module may further refine the sales data from a data sheet of a spreadsheet of the sales data and select a data chart to visually show the sales data or a data sheet to illustrate the sales data in the second slide. The slide generation module may also extract an image of the product from the document of the new product and may refine text associated with the image of the product to generate a product introduction slide including the image and related text in the third slide.
The disclosed technology can improve processing speed by rendering content from a data file more efficiently by refining the content into reduced content. For example, in some implementations, the text in the data file may be summarized into a reduced set of sentences before being represented in a gist list in a slide. Refining the content reduces the file size of the slide presentation. Also, the techniques may determine logical breakpoints in the content based on headers, formats, size of the content, etc. to create an effective number of slides to adequately represent the presentation theme. Network bandwidth may be improved by sending slide presentations with reduced file sizes or more efficient numbers of slides over the network. The techniques may also base the structure of the slide presentation on the formatting of one or more data files and apply consistent themes/designs to the slides to enhance the graphical appearance of the slide presentation and maintain a common look and feel between the data files and the slide presentation. Moreover, by automatically reducing and refining content and automatically creating slides for the presentation topic, the disclosed techniques increase the reliability of the collaborative document system and reduce or eliminate the need to manually review the results of these techniques.
Fig. 1 is an example of a system architecture 100 for implementing the present disclosure. The system architecture 100 includes a cloud-based environment 110 connected to user devices 120A-120Z via a network 130. Although the system architecture 100 is described in the context of a cloud-based environment 110, which may enable communication between servers 112A-112Z in the cloud-based environment 110 and with user devices 120A-120Z over a network 130 to store and share data, it should be understood that the embodiments described herein may also be applied to locally interconnected systems. Cloud-based environment 110 refers to a collection of physical machines hosting applications (e.g., word processing applications, spreadsheet applications, slide presentation applications) that provide one or more services (e.g., word processing, spreadsheet processing, slide generation included in a slide display document) to a plurality of user devices 120A-120Z via network 130. The network 130 may be a public network (e.g., the internet), a private network (e.g., a Local Area Network (LAN) or a Wide Area Network (WAN)), or a combination thereof. The network 130 may include a wireless infrastructure that may be provided by one or more wireless communication systems, such as a wireless fidelity (WiFi) hotspot connected to the network 130 and/or a wireless carrier system that may be implemented using various data processing devices, communication towers, and the like. Additionally or alternatively, the network 130 may include a wired infrastructure (e.g., ethernet).
The cloud-based environment 110 may include one or more servers 112A-112Z, a training engine 115, and/or a data store 114. Training engine 115 and/or data store 114 may be separate from servers 112A-112Z and communicatively coupled to servers 112A-112Z or training engine 115 and/or data store 114 may be part of one or more of servers 112A-112Z. The data store 114 may store data files 116 that include content (e.g., text, data tables, images, video, audio, etc.). In one embodiment, the data file 116 may be any suitable data file including content uploaded by the user devices 120A-120Z to the cloud-based environment 110 or from a server within or outside the cloud-based environment 110. In another embodiment, the data file 116 may be a collaborative document shared with one or more users. The collaboration document may be a word processing document, a spreadsheet document, or any suitable electronic document that can be shared with the user (e.g., an electronic document that includes content such as text, data tables, videos, images, graphics, slides, charts, software programming code, designs, lists, plans, blueprints, maps, etc.).
The collaboration document may be created by an author, and the author may share the collaboration document with other users (e.g., collaborators). Sharing a collaboration document may refer to authorizing other users to access (view and/or edit) the collaboration document. Sharing the collaboration document may include informing other users of the collaboration document via a message (e.g., an email, a text message, etc.) that includes a link to the collaboration document. The level of permissions granted to each user may be based on the user type of each particular user. For example, a user with an editor user type can open a collaborative document and make changes directly to the collaborative document. Likewise, many collaborators may make changes to the content presented in the collaboration document.
The training engine 115 may include one or more processing devices, such as a computer, microprocessor, logic device, or other device or processor configured with hardware, firmware, and software to perform some embodiments described herein. The training engine 115 may include or have access to a set of training data files and a corresponding summary for each training data file that is used by the training engine 115 as training data to train the machine learning model 113 to perform the extraction-based summarization. Machine learning model 113 may refer to a model artifact created by training engine 115 using training inputs and corresponding target outputs. The training inputs may include the set of training data files, and the corresponding target outputs may include a summary of the respective training inputs. In some embodiments, the training data file and corresponding target output may include a particular format (e.g., a gist list). The machine learning model 113 may use the training inputs and target outputs to learn the features of words, phrases, or sentences in the text so that they are good candidates to be included in the summary (refinement). These features may include location in the text (e.g., the first sentence may be a subject sentence and provide a good overview of the passage, the first few sentences may be related, the last sentence may be a conclusion and related), frequent words or phrases, number of words in the sentence, etc. Once trained, the machine learning model 113 can be applied to a new data file 116 to obtain a summary (refinement) for the new data file 116. In some implementations, the refined content can be used to generate presentation visualization items for inclusion in the layout template for the new slide. In some implementations, the machine learning model 113 can learn the format of the text to output the refined content using a particular presentation visualization item (e.g., a list of points).
The servers 112A-112Z may be physical machines (e.g., server machines, desktop computers, etc.) that each include one or more processing devices communicatively coupled to memory devices and input/output (I/O) devices. A processing device may include a computer, microprocessor, logic device, or other device or processor configured with hardware, firmware, and software to perform some embodiments described herein. Each of the servers 112A-112Z may host a slide generation module (118A-118Z). The slide generation modules 118A-118Z may be implemented as computer instructions executable by one or more processing devices on each of the servers 112A-112Z. The slide generation modules 118A-118Z may generate a slide presentation 117 with slides having content abstracted from one or more data files 116 (e.g., collaborative documents). The user may manually identify one or more of the data files 116 as support material for slide generation modules 118A-118Z used to generate the slide presentation 117, or the user may identify particular content portions in one or more of the data files 116 as support material for the slide generation modules 118A-118Z to use to generate the slide presentation 117. The slide presentation 117 may be shared with one or more users and may be a collaborative document.
In some implementations, the slide generation modules 118A-118Z can identify layout templates for each slide in the slide presentation 117 based on the content. The various layout templates may include a "title" layout template for a title (title) of the presentation, a "section header" layout template for an intermediate header (header) (e.g., a header that is not associated with body content), a "title plus body" layout template for parent headers (parent headers) with associated body content (e.g., text, data, images, etc.), a "title plus body" layout template for body content without an associated parent header, and so forth. It should be understood that any suitable layout template may be used.
The slide generation modules 118A-118Z may refine the content into refined content to generate presentation visualizations based on the refined content. As described above, in one embodiment, the slide generation modules 118A-118Z may apply content as input to the machine learning model 113, the machine learning model 113 being trained to produce refined content as a target output. In one embodiment, the slide generation modules 118A-118Z may use one or more rules 119 that define heuristics for refining content. The rules 119 may be predefined by a developer. The rules 119 may be applied to content included in one or more data files 116 for which a slide presentation 117 is generated to refine the content.
For example, if the content is text, one rule 119 may define that the text to be included in a slide does not overflow the slide. In this case, the text may be refined into different subsets, and each subset may be contained in a different slide, so that the subset of text fits the different slide appropriately. The rules 119 may define that complete sentences or individual gist (bulletpoint) are not decomposed when text between slides is separated. Another rule 119 may be defined using a sentence for an outline based on the position of the sentence in the paragraph (e.g., the first sentence in a paragraph of text as an outline of a slide because the first sentence may be a subject sentence; or the last sentence in the paragraph as an outline because the last sentence may include a conclusion). Another rule 119 may define that frequently occurring words or phrases in the text body are to be refined and that a single sentence is included as a gist of a word or phrase that occurs frequently, while some other sentences having less frequently occurring words or phrases are to be ignored. Another rule 119 may define that the maximum number of sentences is refined for presentation in a slide show.
If the content is data in a data table, another rule 119 may define that certain column headers in the data table are identified and a range of data associated with those column headers is refined (e.g., for sales data, the rule 119 may define that the data range associated with the column header of "sales", "region", etc. is refined from the data table) while data in the data table associated with other column headers is ignored. In addition, the rules 119 may define that a range of data having a particular size is to be selected to be represented in the data table to properly fit within the slide so that the data table does not overflow the slide. In this case, the rules may define that another slide is created for the remaining data range not used in the first slide, and may define that the column headers from the data table in the first slide are reused in the data table of the second slide.
If the content is an image, another rule 119 may define extracting the image from the rest of the content and using the image as refined content. Another rule 119 may use a caption (caption) associated with an image to define the title of the slide including the image. Additionally, if an image does not have text to explain, the rules 119 may define the title of the slide including the image using the text closest to the image. Another rule 119 may be defined to include text surrounding the image in the comment sections (sites section) associated with the slide but not actually including the text in the slide itself.
The one or more rules 119 may also define which presentation visualization items to generate based at least on the type of content in the one or more data files 116. For example, if the content is text, the rules 119 may define generating a list (gist) as a presentation visualization; if the content is data, the rules 119 may define generating a data table or data chart as a presentation visualization; if the content is an image, the rules 119 may define generating a data chart as a presentation visualization, and so on. The rules 119 may define the inclusion of presentation visualization items in the body portion of the identified layout template for the content.
The slide generation modules 118A-118Z may generate presentation visualizations (e.g., gist lists, data charts, data tables, images, etc.) based on the refinement content. The slide generation modules 118A-118Z can generate a slide presentation 117 with one or more slides with or without presentation visualizations based on the layout template selected for a particular content. For example, a layout template for "title" may not include a presentation visualization item, but a layout template for "title plus body" may include a presentation visualization item.
One or more servers 112A-112Z may provide collaborative document environments 122A-122Z to user devices 120A-120Z. The servers 112A-112Z selected to provide the collaborative document environments 122A-122Z may be based on certain load balancing techniques, service level agreements, performance metrics, and the like. The collaborative document environments 122A-122Z may provide user interfaces 124A-124Z that display slide presentations 117 generated based on content in one or more data files 116. The collaborative document environments 122A-122Z may enable users using different user devices 120A-120Z to simultaneously access the slide presentation 117 to review, edit, view, and/or suggest changes to the slide presentation 117 in the respective user interfaces 124A-124Z. In one embodiment, the user interfaces 124A-124Z may be web pages rendered by a web browser and displayed on the user devices 120A-120Z in a web browser window. In another embodiment, the user interfaces 124A-124Z may be included in a stand-alone application that is downloaded to the user devices 120A-120Z and that is natively running on the user devices 120A-120Z.
User devices 120A-120Z may include one or more processing devices communicatively coupled to memory devices and I/O devices. The user devices 120A-120Z may be desktop computers, laptop computers, tablet computers, mobile phones (e.g., smartphones), or any suitable computing device. User devices 120A-120Z may include components such as input devices and output devices. The user may be authenticated by the servers 112A-112Z by using a username and password (or other identifying information) provided by the user via the user interfaces 124A-124Z so that the same user device 120A-120Z may be used by different users at different times. In some implementations, the slide generation modules 118A-118Z can be part of the user devices 120A-120Z. For example, in some implementations, the user devices 120A-120Z may have locally installed applications, including slide generation modules 118A-118Z for a user to access, view, edit, and/or automatically generate a slide presentation 117 with refined content.
FIG. 2 depicts a flow diagram of aspects of a method 200 for generating a slide including refined content according to one embodiment of the present disclosure. Each of the method 200 and its various functions, routines, subroutines, or operations may be performed by one or more processing devices of a computer device executing the method. In some embodiments, method 200 may be performed by a single processing thread. Alternatively, the method 200 may be performed by two or more processing threads, each thread performing one or more separate functions, routines, subroutines, or operations of the method. In an illustrative example, the processing threads implementing the method 200 may be synchronized (e.g., using semaphores, critical tiles, and/or other thread synchronization mechanisms). Alternatively, the processes implementing method 200 may be performed asynchronously with respect to each other.
For simplicity of explanation, the methodologies of the present disclosure are depicted as a series of acts. However, acts in accordance with this disclosure may occur in various orders and/or concurrently, and with other acts not presented and described herein. Moreover, not all illustrated acts may be required to implement a methodology in accordance with the disclosed subject matter. Further, those skilled in the art will understand and appreciate that the methodologies could alternatively be represented as a series of interrelated states via a state diagram or events. Additionally, it should be appreciated that the methodologies disclosed herein are capable of being stored on an article of manufacture to facilitate transporting and transferring such methodologies to computing devices. The term "article of manufacture" as used herein is intended to encompass a computer program accessible from any computer-readable device or storage media. In one embodiment, method 200 may be performed by one or more slide generation modules 118A-118Z executed by one or more processing devices of servers 112A-112Z in cloud-based environment 110. In some implementations, the method 200 may be performed by one or more processing devices of the user devices 120A-120Z executing the slide generation modules 118A-118Z.
The method 200 may begin at block 202. At block 202, the processing device may receive one or more data files 116 as source material for slide generation. In one embodiment, the one or more data files 116 may include collaborative documents (e.g., text documents, spreadsheet documents, etc.), non-collaborative documents (e.g., text documents, spreadsheet documents), saved web pages, database files, image files, video files, audio files, animated content, or any suitable media files. The data files 116 may include content, such as text, data tables, images, and so forth. The data files 116 may be uploaded to the cloud-based environment 110 or created using the collaborative document environment 122A and stored in the data store 114.
At block 204, the processing device may obtain the content of the slides for the slide presentation 117 from the one or more data files 116. The processing device may parse the data file 116 to identify content and automatically extract content including any applicable formatting (e.g., title, block header, parent header with body content, etc.) and styles, as described below with reference to fig. 4-5. In some embodiments, the user may select content (e.g., a paragraph of text, a spreadsheet, one or more images), and the processing device may obtain the user-selected content from one or more data files 116, as described below with reference to FIG. 6.
At block 206, the processing device may identify a layout template for the slide based on the content. As described above, the layout templates may include a "title" layout template for depicting a title of a presentation topic based on a title or top-level header in the content of the data file 116, a "block heading" layout template for depicting an intermediate header (e.g., a header that is not related to body content), a "title plus body" layout template for displaying body content (e.g., text, data, images, etc.) in a body portion of a slide and displaying a parent header associated with the body content as the slide title. In some cases, the slide generation modules 118A-118Z may identify the format of the content to identify an appropriate layout template. Thus, the formatting of the data files 116 may be maintained for the slide presentation 117.
For example, titles, headers, body content, etc. may be identified in the content by parsing the document and/or using metadata of the data file 116. If the content includes a title, a "title" layout template may be identified and the text of the title selected. If the content includes an intermediate header (e.g., a block header that is not related to the body content), a "block header" layout template can be identified and selected for the text of the particular intermediate header. If the content includes body content with an associated parent header, a "title plus body" layout template may be identified and selected, and once refined, the body content may be included in the body of the slide, and the text of the parent header may be included in the title of the slide. For example, if the content includes a parent header and associated text (e.g., gist), the text of the parent header may be extracted and set as the title of the slide, and the body of the slide may be specified after the text is refined. If the content includes body content without an associated parent header, a title may be automatically selected based on the body content. For example, the rules 119 may define certain keywords to search through content that may be selected and used as a title.
At block 208, the processing device may refine the content into refined content to generate a presentation visualization item based on the refined content. The processing device may apply the machine learning model 113 or the rules 119 to obtain the refined content. The refined content comprises a subset of the original content. The generated presentation visualization item may be based on application of one of the rules 119. For example, when the layout template is "title and body" and the content includes text with an associated parent header, the rules 119 may define a presentation visualization item that selects the gist list to be generated and the refined text is represented in the gist list in the body of the layout template, and the text of the parent header may be set to the title of the layout template for the slide.
In some embodiments, the original content may be refined by applying the machine learning model 113 to the original content. As described above, the machine learning model 113 may be trained to select certain features from the content (e.g., sentences in certain locations in a paragraph, frequently used words or phrases, etc.) and output refined content. In some implementations, the machine learning model 113 can output the refinement content using a particular presentation visualization item (e.g., a gist list). In some implementations, the one or more rules 119 can define which presentation visualization items to use to refine the content. For example, a gist list may be generated for an abstract content that includes text.
In some embodiments, the original content may be refined according to rules 119. For example, the rules 119 may define a subset (e.g., maximum number) of sentences to select from the content to refine the content for representation in a presentation visualization item (e.g., gist list). Rules 119 may also define which sentences to select based on their position in the passage (e.g., the first sentence in the passage, the first two or three (any number) sentences in the passage, the last sentence in the passage), based on frequently used words or phrases, etc. The rules 119 may also define a range of data to select from the data table when the content includes the data table, and may define presentation visualization items (e.g., data charts, data tables) to select to represent the range of data. For example, the rules 119 may define which column headers to search when selecting a range of data, and when a column header is found, the rules 119 may define a range of data associated with the column header to select. Further, when some column headers are found, there may be a mapping from the column headers to a particular data chart. For example, a column header for "sales" might be mapped to a bar graph. The rules 119 may also define how the image is extracted when the content includes the image (e.g., extracting the image as a single object without cropping the image).
At block 210, the processing device may generate slides based on the presentation visualization items and the layout template. For example, a slide with a "title and body" layout template may be generated, and a presentation visualization item including a gist list of refined sentences from the original text may be included in the body of the layout template, and text of a parent header associated with the refined sentences may be included in the title of the layout template for the slide. A default theme may be applied to each slide in the slide presentation 117 to provide a consistent and enhanced look and feel to the slide presentation 117. Once created, the user may configure a default theme and/or modify the theme of the slide presentation 117.
In some embodiments, the original content (e.g., a text passage or original data table) may be saved in a comment section (nodes section) of the slide that includes the corresponding refined content. The comment tile may provide further context to the presenter during the presentation. Additionally, in some embodiments, the processing device may receive user interactions with the generated slideshow. The processing device may use user interactions (e.g., any edits, modifications, reformats, etc.) to update or create new rules 119 that define heuristics on how subsequent slides are generated for a particular user. For example, a font type, font size or color, paragraph format, gist style, etc. preferred by a user may be captured for a particular layout template. As another example, if the user overwrites an automatically refined gist sentence in a slide, similar languages may also be stored and applied to other slides. Alternatively, the processing device may update (retrain) the machine learning model 113 based on user interaction.
In some implementations, participant feedback can be obtained to improve the slide presentation 117. For example, participant feedback may be provided via a rating system for the presentation. In some implementations, participant engagement and reaction data (e.g., where/which slides the user spends the most time, which slides the user has the most comments or messages on, etc.) may be recorded. The processing device may generate subsequent slides based on the participant's engagement and reaction data, including similar layout templates, refinements, designs/themes, styles, and the like.
In some embodiments, the processing device may obtain second content (e.g., text, data, images, etc.) from one or more data files 116 for a second slide of the slide presentation 117. The processing device may identify a second layout template for the second slide based on the second content. The second layout template may be different from the layout template selected for the first slide, depending on the type of the second content. The processing device may render the second content into second refined content to generate a second presentation visualization based on the second refined content. The machine learning model 113 or rules 119 may be applied to the second content to refine the second content. The second refined content may include a subset of the second content. The processing device may generate a second slide based on the second presentation visualization item and the second layout template. It should be understood that the process may continue to generate as many slides as appropriate until the contents of one or more data files 116 are included in the corresponding slides of the slide presentation 117.
FIG. 3 shows an example of a slide presentation 117 including a slide set generated from a data file 116 in accordance with an illustrative embodiment. As depicted, a collaborative document environment 122A is provided from the server 112A and displayed via the user interface 124A. The data file 116 is opened in a co-word processing application provided by the co-document environment 122A in the first browser window 300. It should be appreciated that the collaborative document environment 122A may be displayed in the user interface 124A of the native application on the first browser window 300 without the use of a browser. The depicted data file 116 includes text (e.g., title, section header, parent header with associated text, etc.).
The user may use the open data file 116 to access a file menu option ("Tools") and select an option (e.g., link) 302 ("Generation Slide Presentation") to Generate a Slide Presentation 117. Upon selection of option 302, the data files 116 may be received by the slide generation module 118A as slide-generated source material. Slide generation module 118A may obtain content from data file 116 by identifying and extracting the content. In some cases, the format of the content may be obtained. For example, the slide generation module 118A may determine formatting information associated with the content (e.g., title, tile header, parent header associated with the content, etc.). Slide generation module 118A can identify layout templates for various portions of text. For example, the portions may be determined based on formatting information.
Different layout templates may be selected for the respective sections. For example, for a portion of text having formatting information indicating that the text is a title, a "title" layout template may be selected, a "block heading" layout template may be selected for a portion of text having formatting information indicating that the text is a block heading (e.g., a title not associated with body content), a "title plus body" layout template may be selected for a portion of text having formatting information indicating that the text includes body text associated with a parent heading and a parent heading, and so forth. The slide generation module 118A can refine the content into refined content to generate presentation visualizations based on the refined content.
The slide generation module 118A may generate one or more slides to be included in the slide presentation 117 based on the layout template and/or the presentation visualization items. As depicted, the slide presentation 117 is displayed in a second browser window 304 that is separate from the collaborative word processing application displayed in the first browser window 300 by the collaborative slide show application. The slides in the slide presentation 117 with the "title plus body" layout template may include presentation visualizations that contain a list of refined text, as described in more detail below.
Fig. 4 depicts a flow diagram of aspects of a method 400 for representing summarized text in a list in a slide according to one embodiment of the present disclosure. The method 400 may be performed in the same or similar manner as described above with respect to the method 200. In one implementation, method 400 may be performed by one or more slide generation modules 118A-118Z executed by one or more processing devices of servers 112A-112Z in cloud-based environment 110. In some implementations, the method 400 may be performed by one or more processing devices of the user devices 120A-120Z executing the slide generation modules 118A-118Z.
Before the method 400 begins, the processing device may have received one or more data files 116 and extracted content from the one or more data files 116. Alternatively, the processing device may have received a selection of content from one or more data files 116 before the method 400 begins. The content may include text (e.g., one or more parent headers, paragraphs of text, or a gist that includes a sentence, etc.).
The method 400 may begin at block 402. At block 402, the processing device may extract text from content that includes a first set of sentences. The first set of sentences may be in the form of paragraphs or may be represented in a list (e.g., a gist list). At block 404, the processing device may summarize the first set of sentences into a second set of sentences as refined content. The second set of sentences may include fewer sentences than the first set of sentences. The summarization may be performed by applying the machine learning model 113 to the first set of sentences or by applying one or more rules 119 to the first set of sentences. At block 406, the processing device may generate a presentation visualization comprising a list (e.g., an outline) based on the second set of sentences. For example, each sentence in the second set of sentences can be represented as a separate entry (e.g., a gist) in a list.
FIG. 5 shows a more detailed example of slides 500, 502, 504 in a slide presentation 117 generated from a data file 116 in accordance with an illustrative embodiment. As depicted, the data file includes textual content formatted with a title ("Marketing Plan"), a block header ("objects") that is not related to the body content, and a parent header ("Personal objects" (market Director)) associated with the original body text 505. The original body text 505 includes two sentences ("Demote 20hours per month from month marketing subject matter)" and "Speak at 20events in FY 2013 (speaking in 20events in 2013) which are represented in the gist list.
Slide generation module 118A can receive data file 116, extract content, and generate slides 500, 502, and 504. Slide generation module 118A may identify layout templates for various portions of text in data file 116. For example, for the title ("marking Plan") section, the "title" layout template is selected and the text of the title section is set as the title in the layout template described in slide 500. The "tile header" layout template is selected for the tile header ("Goals") section and the text of the tile header is set as the header in the layout template described in 502. For a parent header ("Personal objects") and associated text portions, a "title plus body" layout template is identified, and the text of the parent header is set as the title of slide 504 and the associated text is set as the body of slide 504. Thus, each slide 500, 502, and 504 includes a different portion of text from the data file 116 and a different layout template. In this manner, the structure of the slide presentation 117 may be mapped to the format of the original data file 116.
As shown in slide 504, the rendered visualization 508 is used to generate a presentation visualization 506. In this example, the presentation visualization item 506 is a gist list, but it should be understood that any suitable list or presentation visualization item may be used. The presentation visualization item 506 is included in the body of the layout template. Refined text 508 may be generated by applying machine learning model 113 or rules 119 to the original body text 505. The refined text 508 includes a smaller number of sentences than the original body text 505.
FIG. 6 illustrates an example of how a portion of content may be selected to be sent from a data file 116 to a slide presentation 117 in accordance with an illustrative embodiment. As depicted, data file 116 is a collaborative word processing document displayed in a first browser window 300 of user interface 124A by a collaborative word processing application of collaborative document environment 122A. In some cases, the user may wish to create slides for only some of the content in the data file 116. Accordingly, the user may select (e.g., highlight) text portion 600. In the depicted example, the text portion 600 includes a first parent header ("Tactical Goals") and related body text (three sentences represented in the gist list), and a second parent header ("Strategic Goals") and related body text (three sentences). The options menu 602 may appear when the text portion 600 is selected or when input from an input peripheral is received (e.g., a mouse button is selected). From the options menu 602, the user may select an option (e.g., link) 604 ("Send to Slides"), and another options menu 606 may appear that includes the available slide presentations 117. The options menu 606 may also enable the user to create a new slide presentation 117 using the selected text portion 600. From the options menu 606, the user may select a link 608 to send the selected text portion 600 to the desired slide presentation 117 ("marking Plan").
Slide generation module 118A can receive the selected text portion 600 and can identify a layout template for text portion 600. In some embodiments, slide generation module 118A may determine that the formatting information for selected text portion 600 indicates that there are two different parent headers and two corresponding text bodies. Thus, slide generation module 118A may divide the single selection of text portion 600 into two slides.
For example, FIG. 7 illustrates an example of receiving selected content (text portion 600) and dividing the selected content into separate slides 700 and 702 in accordance with an illustrative embodiment. The parent header may be used as a logical break to divide the selected content into separate slides 700 and 702. The layout template for slide 700 may be "title plus body," with a parent header ("textual subjects") set to the title of slide 700 and body text associated with the parent header set to the body in slide 700. Likewise, the layout template for slide 702 may be "title plus body," with a parent header ("Stretegic Goals") set to the title of slide 702 and body text associated with the parent header set to the body in slide 702. More specifically, the body text may be refined into refined text 704 and 706 by applying the machine learning model 113 or rules 119, and presentation visualizations 708 and 710 (e.g., gist lists) may be generated based on the refined text 704 and 706. It should be appreciated that both refined text 704 and 706 include fewer sentences than their corresponding original text in the data file 116 in FIG. 6.
FIG. 8 depicts a flowchart of an aspect of a method for representing images and text associated with images extracted from source material in a slide show according to one embodiment of the present disclosure. Method 800 may be performed in the same or similar manner as described above with respect to method 200. In one implementation, method 800 may be performed by one or more slide generation modules 118A-118Z executed by one or more processing devices of servers 112A-112Z in cloud-based environment 110. In some implementations, the method 800 may be performed by one or more processing devices of the user devices 120A-120Z executing the slide generation modules 118A-118Z.
Before the method 800 begins, the processing device may have received one or more data files 116 and content extracted from the one or more data files 116. Alternatively, the processing device may have received a selection of content from one or more data files 116 before the method 800 begins. The content may include an image and text associated with the image.
The method 800 may begin at block 802. At block 802, the processing device may extract an image from the content as refined content. The image may be recognized by the processing device while the processing device is parsing the data file 116. One or more rules 119 defining how the image is to be extracted may be applied to the image. For example, the rules 119 may define that an image is to be extracted as a single object and should not be cropped. The rules 119 may also define how to resize the image to fit properly within the body of the layout template (e.g., "title plus body"). At block 804, the processing device may generate a presentation visualization including the image.
FIG. 9 shows an example of representing an image 900 extracted from a data file 116 in a slideshow 904 and text 902 associated with the image 900 in accordance with an illustrative embodiment. The depicted data file 116 includes various text 906 describing the image 900 and explanatory text 902 ("Product XYZ (Product XYZ)") associated with the image 900. The slide generation module 118A may identify and extract the image 900 from the data file 116 as the refinement, identifying a layout template ("title plus body") for the refinement. The slide generation module 118A can generate a presentation visualization item 908 that includes the extracted and resized image 900 according to the one or more rules 119. The presentation visualization item 908 may be included in the body of the layout template.
In some embodiments, some text in the data file 116 may be extracted and set as a title 910 for the slide 904 that includes the image 902. For example, as depicted, caption text 902 may be extracted and set as title 910 of slide 904. If no caption is present in the data file 116, one or more words, phrases or sentences of various text 906 describing the product may be extracted and set as the title 910 of the slide 904.
FIG. 10 depicts a flow diagram of aspects of a method 1000 for representing extracted range data in a data graph in a slide show according to one embodiment of the present disclosure. The method 1000 may be performed in the same or similar manner as described above with respect to the method 200. In one implementation, method 1000 may be performed by one or more slide generation modules 118A-118Z executed by one or more processing devices of servers 112A-112Z in cloud-based environment 110. In some implementations, the method 1000 may be performed by one or more processing devices of the user devices 120A-120Z executing the slide generation modules 118A-118Z.
Before the method 1000 begins, the processing device may have received one or more data files 116 and content extracted from the one or more data files 116. Alternatively, the processing device may receive a selection of content from one or more data files 116 before the method 400 begins. The content may include a data table containing data.
The method 1000 may begin at block 1002. At block 1002, the processing device may extract a data table from the content. At block 1004, the processing device may select a range of data from the data table as the refinement. One or more rules 119 may be applied to the data table of content to select the data range. One or more rules 119 may define which column header to search in the data table and, if found, the range of data to extract. The rules 119 may also define which data diagram to use based on a mapping between the data diagram and the identified column header, as shown in FIG. 11. The one or more rules 119 may also define a maximum number of rows that may be selected to fit within the data table in the slide, and a range of data may be selected accordingly. Any additional rows may be included in separate data tables in one or more other slides, as shown in FIG. 12. At block 1006, the processing device may generate a presentation visualization including a data chart based on the range of data.
FIG. 11 shows an example of data 1100 representing an extracted range in data chart 1102 in slide 1104, according to an illustrative embodiment. The depicted data file 116 includes a data table 1106. The slide generation module 118A may identify and extract the data table 1106 and apply one or more rules 119 to the data table 1106. The one or more rules 119 may define that a range of data 1100 associated with certain column headers (e.g., "Sales" and "Region") should be extracted. The defined topic header may relate to presenting one or more criteria (e.g., sales, finance, inventor, product, etc.) about the entity. The caption 1108 may also be associated with a data table 1106 in the data file 116. Slide generation module 118A may select data range 1100 from extracted data table 1106 as a refinement to generate a presentation visualization including data chart 1102 based on data range 1100. As depicted, the data chart includes the regions and sales data associated with each region. In one example, the bar graph is selected based on rules 119 defining a mapping between the bar graph and column headers (e.g., "Sales", "Region") associated with the Sales information. The presentation visualization items that comprise data diagram 1102 may be included in the body of the layout template ("title plus body") used to generate slide 1104.
In some embodiments, some text in data file 116 may be extracted and set as a title 1110 of a slide 1104 that includes data diagram 1102. For example, as depicted, caption 1108 can be extracted and set as title 1110 of slide 1104. If no caption is present in the data file 116, one or more words, phrases or sentences near the text of the data table 1106 in the data file 116 may be extracted and set as the title 1110 of the slide 904.
FIG. 12 shows an example of data 1202 and 1204 representing different extracted ranges in data tables 1206 and 1208 in different slides 1210 and 1212, according to an illustrative embodiment. The depicted data file 116 includes a data table 1214. Slide generation module 118A may identify and extract data table 1214 and apply one or more rules 119 to data table 1214. One or more rules 119 may define a maximum number of rows selected to fit in a slide. In the depicted example, the maximum number of rows is two, but it should be understood that any suitable number may be used. A first range of data 1202 is selected having two rows and a presentation visualization item is generated that includes a data table 1206 based on the first range of data 1202. A second range of data 1204 is selected having two rows and a presentation visualization item is generated including a data table 1208 based on the second range of data 1204. In other embodiments, the rules 119 may define a range of data to select from a data table based on a matching value for a particular column. For example, a data range including the "CA" value of the "Region" column may be selected as the first range of data 1202, and a data range including the "TX" value of the "Region" column may be selected as the second range of data 1204. The rules 119 may define that column headers are used for both data tables 1206 and 1208. The presentation visualization items, including data tables 1206 and 1208, may be included in the body of the layout template ("title plus body") for generating respective slides 1210 and 1212.
In some embodiments, some text in data file 116 may be extracted and set as headers 1216 and 1218 for slides 1210 and 1212, including data tables 1206 and 1208. For example, as depicted, caption text 1220 of data table 1214 in data file 116 may be extracted and set to headers 1216 and 1218 for slides 1210 and 1212. If no caption word is present in the data file 116, one or more words, phrases or sentences of text near the data table 1214 in the data file 116 may be extracted and set as the titles 1216 and 1218 of the slides 1210 and 1212.
Fig. 13 depicts a block diagram of an example computing system operating in accordance with one or more aspects of the present disclosure. In various illustrative examples, computer system 1300 may correspond to any computing device within system architecture 100 of fig. 1. In one embodiment, the computer system 1300 may be each of the servers 112A-112Z or the training engine 115. In another embodiment, computer system 1300 may be each of user devices 120A-120Z.
In some embodiments, computer system 1300 may be connected (e.g., via a network such as a Local Area Network (LAN), intranet, extranet, or the internet) to other computer systems. Computer system 1300 may operate in the capacity of a server or a client computer in a client-server environment, or as a peer computer in a peer-to-peer or distributed network environment. Computer system 1300 may be provided by a Personal Computer (PC), a tablet PC, a set-top box (STB), a Personal Digital Assistant (PDA), a cellular telephone, a web appliance, a server, a network router, switch or bridge, or any device capable of executing a set of instructions (sequential or otherwise) that specify actions to be taken by that device, and so forth. Furthermore, the term "computer" shall include any collection of computers that individually or jointly execute a set (or multiple sets) of instructions to perform any one or more of the methodologies discussed herein.
In a further aspect, computer system 1300 may include a processing device 1302, volatile memory 1304 (e.g., Random Access Memory (RAM)), non-volatile memory 1306 (e.g., read-only memory (ROM) or electrically erasable programmable ROM (eeprom)), and a data storage device 1316, which may communicate with each other via a bus 1308.
The processing device 1302 may be provided by one or more processors, such as a general-purpose processor (e.g., a Complex Instruction Set Computing (CISC) microprocessor, a Reduced Instruction Set Computing (RISC) microprocessor, a Very Long Instruction Word (VLIW) microprocessor, a microprocessor implementing other types of instruction sets, or a microprocessor implementing a combined type of instruction set) or a special-purpose processor (e.g., an Application Specific Integrated Circuit (ASIC), a Field Programmable Gate Array (FPGA), a Digital Signal Processor (DSP), or a network processor).
The computer system 1300 may also include a network interface device 1322. Computer system 1300 may also include a video display unit 1310 (e.g., an LCD), an alphanumeric input device 1312 (e.g., a keyboard), a cursor control device 1314 (e.g., a mouse), and a signal generation device 1320.
The data storage device 1316 may include a non-transitory computer-readable storage medium 1324 on which instructions 1326 encoding any one or more of the methods or functions described herein may be stored, including instructions implementing the slide generation module 118(118A-118Z) and/or the training engine 115 of fig. 1 for implementing any of the methods described herein.
The instructions 1326 may also reside, completely or partially, within the volatile memory 1304 and/or within the processing device 1302 during execution thereof by the computer system 1300, the volatile memory 1304 and the processing device 1302 thus also constituting machine-readable storage media.
While the computer-readable storage medium 1324 is shown in an illustrative example to be a single medium, the term "computer-readable storage medium" will include a single medium or multiple media (e.g., a centralized or distributed database, and/or associated caches and servers) that store the one or more sets of executable instructions. The term "computer-readable storage medium" shall also be taken to include any tangible medium that is capable of storing or encoding a set of instructions for execution by the computer that cause the computer to perform any one or more of the methodologies described herein. The term "computer readable storage medium" shall include, but not be limited to, solid-state memories, optical media, and magnetic media.
In the preceding description, numerous details have been set forth. However, it will be apparent to one of ordinary skill in the art having the benefit of the present disclosure that the present disclosure may be practiced without these specific details. In some instances, well-known structures and devices are shown in block diagram form, rather than in detail, in order to avoid obscuring the present disclosure.
Some portions of the detailed descriptions which follow are presented in terms of algorithms and symbolic representations of operations on data bits within a computer memory. These algorithmic descriptions and representations are the means used by those skilled in the data processing arts to most effectively convey the substance of their work to others skilled in the art. An algorithm is here, and generally, considered to be a self-consistent sequence of steps leading to a desired result. The steps are those requiring physical manipulations of physical quantities. Usually, though not necessarily, these quantities take the form of electrical or magnetic signals capable of being stored, transferred, combined, compared, and otherwise manipulated. It has proven convenient at times, principally for reasons of common usage, to refer to these signals as bits, values, elements, symbols, characters, terms, numbers, or the like.
It should be borne in mind, however, that all of these and similar terms are to be associated with the appropriate physical quantities and are merely convenient labels applied to these quantities. Unless specifically stated otherwise as apparent from the following discussions, it is appreciated that throughout the specification discussions utilizing terms such as "receiving," "displaying," "moving," "adjusting," "replacing," "determining," "playing," or the like, refer to the action and processes of a computer system, or similar electronic computing device, that manipulate and transform data represented as physical (e.g., electronic) quantities within the computer system's registers and memories into other physical quantities similarly represented as physical quantities within the computer system memories or registers or other such information storage, transmission or display devices.
For purposes of simplicity of explanation, the methodologies are depicted and described herein as a series of acts. However, acts in accordance with this disclosure may occur in various orders and/or concurrently, and with other acts not presented and described herein. Moreover, not all illustrated acts may be required to implement a methodology in accordance with the disclosed subject matter. Further, those skilled in the art will understand and appreciate that the methodologies could alternatively be represented as a series of interrelated states via one or more state diagrams or events. Moreover, it should be appreciated that the methodologies disclosed herein are capable of being stored on an article of manufacture to facilitate transporting and transferring such methodologies to computing devices. The term article of manufacture, as used herein, is intended to encompass a computer program accessible from any computer-readable device or storage media.
Certain embodiments of the present disclosure also relate to an apparatus for performing the operations herein. The apparatus may be constructed for the intended purpose or it may comprise a general purpose computer selectively activated or reconfigured by a computer program stored in the computer. Such a computer program may be stored in a computer readable storage medium, such as, but is not limited to, any type of disk including floppy disks, optical disks, CD-ROMs, and magnetic-optical disks, read-only memories (ROMs), Random Access Memories (RAMs), EPROMs, EEPROMs, magnetic or optical cards, or any type of media suitable for storing electronic instructions.
Reference throughout this specification to "one embodiment" or "an embodiment" means that a particular feature, structure, or characteristic described in connection with the embodiment is included in at least one embodiment. Thus, appearances of the phrases "in one embodiment" or "in an embodiment" in various places throughout this specification are not necessarily all referring to the same embodiment. In addition, the term "or" is intended to mean an inclusive "or" rather than an exclusive "or". Moreover, the word "example" or "exemplary" is used herein to mean serving as an example, instance, or illustration. Any aspect or design described herein as "exemplary" is not necessarily to be construed as preferred or advantageous over other aspects or designs. Rather, the words "example" or "exemplary" are used to present concepts in a concrete fashion.
It is to be understood that the above description is intended to be illustrative, and not restrictive. Many other embodiments will be apparent to those of skill in the art upon reading and understanding the above description. The scope of the disclosure should, therefore, be determined with reference to the appended claims, along with the full scope of equivalents to which such claims are entitled.
In addition to the above, a user may be provided with controls that allow the user to select whether and when the systems, programs, or features described herein are capable of collecting user information (e.g., information about the user's social network, social behavior or activity, expertise, the user's preferences, or the user's current location), and whether to send content or communications from a server to the user. In addition, certain data may be processed in one or more ways before it is stored or used, so that personally identifiable information may be removed. For example, the identity of the user may be processed such that personally identifiable information cannot be determined for the user, or the geographic location of the user may be generalized at the location where the location information is obtained (e.g., to a city, zip code, or state level) such that a particular location of the user cannot be determined. Thus, the user may have control over what information is collected about the user, how the information is used, and what information is provided to the user.
Claims (19)
1. A method for generating a presentation slide with refined content, comprising:
providing a user interface, UI, for presentation to a user, the UI displaying a data file having a plurality of content portions and a slide generation UI element that allows the user to request slide generation using the data file as source material;
receiving, via the UI, an indication of a user selection of a first content portion of the plurality of content portions;
receiving, via the UI, a user selection of the slide generation UI element;
identifying a plurality of logical breakpoints in the first content portion based on at least one of a format or a size of a plurality of content items of the first content portion;
determining a set of slides to include in the slide presentation based on the identified plurality of logical breakpoints;
identifying a layout template for each slide in the set of slides based on the content of the plurality of content items of the first content portion;
refining a plurality of content items of the first content portion into one or more refined content items to generate a presentation visualization item, wherein the one or more refined content items comprise a subset of the plurality of content items of the first content portion; and
generating the set of slides based on each identified layout template and the presentation visualization item, the presentation visualization item including at least one of a list, a data chart, a data table, or an image.
2. The method of claim 1, further comprising:
receiving an indication of another user selection of a second content portion of the plurality of content portions of the data file; and
refining a plurality of content items of the second content portion into one or more additional refined content items to generate a second presentation visualization item, wherein each of the one or more additional refined content items comprises a subset of the plurality of content items of the second content portion, and wherein at least one slide of the set of slides is further generated based on the second presentation visualization item.
3. The method of claim 1, wherein refining the plurality of content items of the first portion of content into the one or more refined content items includes applying one or more rules to the first portion of content, wherein the one or more rules define which content items of the first portion of content are to be used as the one or more refined content items based on a type of the first portion of content in the data file.
4. The method of claim 1, wherein refining the plurality of content items of the first content portion into the one or more refined content items comprises applying the first content portion as input to a machine learning model trained to produce the one or more refined content items as a target output.
5. The method of claim 1, wherein refining the plurality of content items of the first content portion into the one or more refined content items comprises:
extracting text comprising a first set of sentences from the first content portion; and
generalizing the first set of sentences into a second set of sentences as a refined content item, the second set of sentences including fewer sentences than the first set of sentences, wherein the generated presentation visualization item includes the list based on the second set of sentences.
6. The method of claim 1, wherein refining the plurality of content items of the first content portion into the one or more refined content items comprises:
extracting a data table from the first content portion; and
selecting a range of data from the data table as a refined content item,
wherein the generated presentation visualization item includes the data chart based on the range of data.
7. The method of claim 1, wherein refining the plurality of content items of the first content portion into the one or more refined content items comprises:
extracting an image from the first content portion as a refined content item,
wherein the presentation visualization item comprises the image.
8. The method of claim 1, further comprising:
receiving an interaction with the slideshow; and
the interactions are used to apply heuristic rules to subsequent slide generation.
9. The method of claim 1, wherein the data file comprises at least one of: text documents, database files, spreadsheets, data tables, video files, and image files.
10. The method of claim 1, further comprising:
setting a text of a parent header in the data file as a header of the corresponding layout template of the slide; and
setting the one or more refined content items that include text associated with the parent header as bodies of the layout template.
11. A non-transitory computer-readable storage medium storing instructions that, when executed by a processing device, cause the processing device to:
providing a user interface, UI, for presentation to a user, the UI displaying a data file having a plurality of content portions and a slide generation UI element allowing the user to request slide generation using the data file as source material;
receiving, via the UI, an indication of a user selection of a first content portion of the plurality of content portions;
receiving, via the UI, a user selection of the slide generation UI element;
identifying a plurality of logical breakpoints in the first content portion based on at least one of a format or a size of a plurality of content items of the first content portion;
determining a set of slides to include in the slide presentation based on the identified plurality of logical breakpoints;
identifying a layout template for each slide in the set of slides based on the content of the plurality of content items of the first content portion;
refining a plurality of content items of the first content portion into one or more refined content items to generate a presentation visualization item, wherein the one or more refined content items comprise a subset of the plurality of content items of the first content portion; and
generating the set of slides based on each identified layout template and the presentation visualization item, the presentation visualization item including at least one of a list, a data chart, a data table, or an image.
12. The computer-readable storage medium of claim 11, wherein to refine the plurality of content items of the first portion of content into one or more refined content items, the processing device applies one or more rules to the first portion of content, wherein the one or more rules define which content items of the first portion of content are to be used as the one or more refined content items based on a type of the first portion of content in the data file.
13. The computer-readable storage medium of claim 11, wherein to refine the plurality of content items of the first portion of content into the one or more refined content items, the processing device applies the first portion of content as input to a machine learning model that is trained to produce the one or more refined content items as a target output.
14. The computer-readable storage medium of claim 11, wherein to refine the plurality of content items of the first content portion into the one or more refined content items, the processing device is to:
extracting text comprising a first set of sentences from the first content portion;
generalizing the first set of sentences into a second set of sentences as a refined content item, the second set of sentences comprising fewer sentences than the first set of sentences, wherein the generated presentation visualization item comprises the list based on the second set of sentences.
15. The computer-readable storage medium of claim 11, wherein to refine the plurality of content items of the first content portion into the one or more refined content items, the processing device is to:
extracting a data table from the first content portion; and
selecting a range of data from the data table as a refined content item,
wherein the generated presentation visualization item includes the data chart based on the range of data.
16. The computer-readable storage medium of claim 11, wherein to refine the plurality of content items of the first content portion into the one or more refined content items, the processing device is to:
extracting an image from the content as the refined content; and
generating the presentation visualization item comprising the image.
17. A system, comprising:
a memory device to store instructions; and
a processing device coupled to the memory device, wherein execution of the instructions causes the processing device to:
providing a user interface, UI, for presentation to a user, the UI displaying a data file having a plurality of content portions and a slide generation UI element that allows the user to request slide generation using the data file as source material;
receiving, via the UI, an indication of a user selection of a first content portion of the plurality of content portions;
receiving, via the UI, a user selection of the slide generation UI element;
identifying a plurality of logical breakpoints in the first content portion based on at least one of a format or a size of a plurality of content items of the first content portion;
determining a set of slides to include in the slide presentation based on the identified plurality of logical breakpoints;
identifying a layout template for each slide in the set of slides based on the content of the plurality of content items of the first content portion;
refining a plurality of content items of the first content portion into one or more refined content items to generate a presentation visualization item, wherein the one or more refined content items comprise a subset of the plurality of content items of the first content portion; and
generating the set of slides based on each identified layout template and the presentation visualization item, the presentation visualization item including at least one of a list, a data chart, a data table, or an image.
18. The system of claim 17, wherein to refine the plurality of content items of the first content portion into the one or more refined content items, the processing device is to:
extracting text comprising a first set of sentences from the first content portion; and
generalizing the first set of sentences into a second set of sentences as refined content items, the second set of sentences comprising fewer sentences than the first set of sentences,
wherein the generated presentation visualization item includes the list based on the second set of sentences.
19. The system of claim 17, wherein to refine the plurality of content items of the first content portion into the one or more refined content items, the processing device is to:
extracting a data table from the first content portion; and
selecting a range of data from the data table as a refined content item; and
wherein the generated presentation visualization item includes the data chart based on the range of data.
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
CN202210602720.XA CN115203399A (en) | 2016-11-10 | 2017-11-10 | Generating presentation slides with refined content |
Applications Claiming Priority (4)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201662420263P | 2016-11-10 | 2016-11-10 | |
US62/420,263 | 2016-11-10 | ||
US15/807,431 US11481550B2 (en) | 2016-11-10 | 2017-11-08 | Generating presentation slides with distilled content |
US15/807,431 | 2017-11-08 |
Related Child Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202210602720.XA Division CN115203399A (en) | 2016-11-10 | 2017-11-10 | Generating presentation slides with refined content |
Publications (2)
Publication Number | Publication Date |
---|---|
CN108073680A CN108073680A (en) | 2018-05-25 |
CN108073680B true CN108073680B (en) | 2022-06-17 |
Family
ID=60473656
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202210602720.XA Pending CN115203399A (en) | 2016-11-10 | 2017-11-10 | Generating presentation slides with refined content |
CN201711108164.6A Active CN108073680B (en) | 2016-11-10 | 2017-11-10 | Generating presentation slides with refined content |
Family Applications Before (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202210602720.XA Pending CN115203399A (en) | 2016-11-10 | 2017-11-10 | Generating presentation slides with refined content |
Country Status (5)
Country | Link |
---|---|
US (2) | US11481550B2 (en) |
CN (2) | CN115203399A (en) |
DE (2) | DE102017126380A1 (en) |
GB (1) | GB2558400B (en) |
WO (1) | WO2018089685A1 (en) |
Families Citing this family (34)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9552376B2 (en) * | 2011-06-09 | 2017-01-24 | MemoryWeb, LLC | Method and apparatus for managing digital files |
US11960525B2 (en) * | 2016-12-28 | 2024-04-16 | Dropbox, Inc | Automatically formatting content items for presentation |
US11036914B2 (en) * | 2017-06-29 | 2021-06-15 | Salesforce.Com, Inc. | Automatic layout engine |
US11640419B2 (en) * | 2017-10-31 | 2023-05-02 | Primer Technologies, Inc. | Management of event summary types |
CN110634172A (en) * | 2018-06-25 | 2019-12-31 | 微软技术许可有限责任公司 | Generating slides for presentation |
US10776412B2 (en) * | 2018-07-11 | 2020-09-15 | EMC IP Holding Company LLC | Dynamic modification of information presentation and linkage based on usage patterns and sentiments |
CN109272778B (en) * | 2018-10-22 | 2020-07-24 | 广东精标科技股份有限公司 | Intelligent teaching system with AR function |
CN109493401B (en) * | 2018-10-23 | 2019-11-22 | 北京字节跳动网络技术有限公司 | PowerPoint generation method, device and electronic equipment |
EP3887923A4 (en) * | 2018-11-26 | 2022-08-31 | Photo Butler Inc. | Presentation file generation |
US11238215B2 (en) | 2018-12-04 | 2022-02-01 | Issuu, Inc. | Systems and methods for generating social assets from electronic publications |
CN109815448B (en) * | 2019-02-02 | 2024-02-27 | 天津字节跳动科技有限公司 | Slide generation method and device |
US20210133389A1 (en) | 2019-02-18 | 2021-05-06 | Pro Quick Draw LLC | Document transformation between program formats and templates system and method |
US11307732B1 (en) * | 2019-02-18 | 2022-04-19 | Pro Quick Draw LLC | Integrated method and system for creation of a diagram compilation book and exporting the book for use as content in a visual presentation tool |
US10614345B1 (en) * | 2019-04-12 | 2020-04-07 | Ernst & Young U.S. Llp | Machine learning based extraction of partition objects from electronic documents |
US11029819B2 (en) * | 2019-05-23 | 2021-06-08 | Microsoft Technology Licensing, Llc | Systems and methods for semi-automated data transformation and presentation of content through adapted user interface |
JP6898667B2 (en) * | 2019-06-24 | 2021-07-07 | 株式会社インタラクティブソリューションズ | Presentation management system |
US11113518B2 (en) | 2019-06-28 | 2021-09-07 | Eygs Llp | Apparatus and methods for extracting data from lineless tables using Delaunay triangulation and excess edge removal |
US11915465B2 (en) | 2019-08-21 | 2024-02-27 | Eygs Llp | Apparatus and methods for converting lineless tables into lined tables using generative adversarial networks |
US11501208B2 (en) * | 2019-10-02 | 2022-11-15 | Microsoft Technology Licensing, Llc | Rehearsal-based presentation assistance |
CN111047673A (en) * | 2019-12-09 | 2020-04-21 | 成都来画科技有限公司 | PPT file generation method and device based on hand-drawn video |
US11625934B2 (en) | 2020-02-04 | 2023-04-11 | Eygs Llp | Machine learning based end-to-end extraction of tables from electronic documents |
KR20210104247A (en) * | 2020-02-17 | 2021-08-25 | 한국과학기술원 | Method and Apparatus for Recommending PowerPoint |
US10885436B1 (en) * | 2020-05-07 | 2021-01-05 | Google Llc | Training text summarization neural networks with an extracted segments prediction objective |
US20210406471A1 (en) * | 2020-06-25 | 2021-12-30 | Seminal Ltd. | Methods and systems for abridging arrays of symbols |
LU101914B1 (en) * | 2020-07-10 | 2022-01-10 | Microsoft Technology Licensing Llc | Document conversion engine |
CN111930976A (en) * | 2020-07-16 | 2020-11-13 | 平安科技（深圳）有限公司 | Presentation generation method, device, equipment and storage medium |
CN112579727B (en) * | 2020-12-16 | 2022-03-22 | 北京百度网讯科技有限公司 | Document content extraction method and device, electronic equipment and storage medium |
CN113420042A (en) * | 2021-06-22 | 2021-09-21 | 平安养老保险股份有限公司 | Data statistics method, device, equipment and storage medium based on presentation |
US11423207B1 (en) * | 2021-06-23 | 2022-08-23 | Microsoft Technology Licensing, Llc | Machine learning-powered framework to transform overloaded text documents |
US20230041867A1 (en) * | 2021-07-28 | 2023-02-09 | 11089161 Canada Inc. (Dba: Looksgoodai) | Method and system for automatic formatting of presentation slides |
CN113553450B (en) * | 2021-08-03 | 2024-01-30 | 广东新学未科技有限公司 | Automatic generation method and device of PPT presentation, computing equipment and storage medium |
US20230205904A1 (en) * | 2021-12-29 | 2023-06-29 | Microsoft Technology Licensing, Llc | Enhanced security features for controlling access to shared content and private content of a shared document |
US11436773B1 (en) * | 2022-01-13 | 2022-09-06 | Capitol AI, Inc. | Modifying data visualizations to permit improved display of clustered data points |
US20230334237A1 (en) * | 2022-04-14 | 2023-10-19 | Sigma Computing, Inc. | Workbook template sharing |
Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7743331B1 (en) * | 2006-09-29 | 2010-06-22 | Adobe Systems Inc. | Viewing and modifying content slide navigation properties |
CN103718215A (en) * | 2011-07-05 | 2014-04-09 | 松下电器产业株式会社 | Presentation content generation device, presentation content generation method, presentation content generation program and integrated circuit |
CN105930471A (en) * | 2016-04-25 | 2016-09-07 | 上海交通大学 | Speech abstract generation method and apparatus |
Family Cites Families (33)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5867164A (en) | 1995-09-29 | 1999-02-02 | Apple Computer, Inc. | Interactive document summarization |
US6533822B2 (en) | 1998-01-30 | 2003-03-18 | Xerox Corporation | Creating summaries along with indicators, and automatically positioned tabs |
US6970859B1 (en) | 2000-03-23 | 2005-11-29 | Microsoft Corporation | Searching and sorting media clips having associated style and attributes |
US7152205B2 (en) | 2000-12-18 | 2006-12-19 | Siemens Corporate Research, Inc. | System for multimedia document and file processing and format conversion |
US7171619B1 (en) | 2001-07-05 | 2007-01-30 | Sun Microsystems, Inc. | Methods and apparatus for accessing document content |
US20040216149A1 (en) | 2002-07-16 | 2004-10-28 | Reitz Larry E. | Content exporting from one application to another |
US20040172584A1 (en) | 2003-02-28 | 2004-09-02 | Microsoft Corporation | Method and system for enhancing paste functionality of a computer software application |
US20050108619A1 (en) | 2003-11-14 | 2005-05-19 | Theall James D. | System and method for content management |
US7631254B2 (en) | 2004-05-17 | 2009-12-08 | Gordon Peter Layard | Automated e-learning and presentation authoring system |
US7703036B2 (en) | 2004-08-16 | 2010-04-20 | Microsoft Corporation | User interface for displaying selectable software functionality controls that are relevant to a selected object |
US8904269B2 (en) | 2005-11-04 | 2014-12-02 | International Business Machines Corporation | Creating accessible, translatable multimedia presentations |
US7788290B2 (en) | 2007-03-27 | 2010-08-31 | Microsoft Corporation | Automatic file conversion to a target format |
US20090150800A1 (en) | 2007-12-05 | 2009-06-11 | Glenn Wood | Apparatus, Method and Computer Program Product for Generating Debriefing Charts |
US8209632B2 (en) | 2010-01-26 | 2012-06-26 | Apple Inc. | Image mask interface |
US20110264705A1 (en) | 2010-04-22 | 2011-10-27 | Brandon Diamond | Method and system for interactive generation of presentations |
WO2012057891A1 (en) * | 2010-10-26 | 2012-05-03 | Hewlett-Packard Development Company, L.P. | Transformation of a document into interactive media content |
US20120192064A1 (en) | 2011-01-21 | 2012-07-26 | Oudi Antebi | Distributed document processing and management |
US9152616B2 (en) * | 2011-04-28 | 2015-10-06 | Flipboard, Inc. | Template-based page layout for web content |
US9135233B2 (en) * | 2011-10-13 | 2015-09-15 | Microsoft Technology Licensing, Llc | Suggesting alternate data mappings for charts |
US8990140B2 (en) | 2012-06-08 | 2015-03-24 | Microsoft Technology Licensing, Llc | Transforming data into consumable content |
US10289661B2 (en) * | 2012-09-12 | 2019-05-14 | Flipboard, Inc. | Generating a cover for a section of a digital magazine |
US9377933B2 (en) * | 2012-09-24 | 2016-06-28 | Facebook, Inc. | Displaying social networking system entity information via a timeline interface |
US20140157169A1 (en) | 2012-12-05 | 2014-06-05 | Microsoft Corporation | Clip board system with visual affordance |
US8504827B1 (en) | 2013-02-27 | 2013-08-06 | WebFilings LLC | Document server and client device document viewer and editor |
US10282075B2 (en) | 2013-06-24 | 2019-05-07 | Microsoft Technology Licensing, Llc | Automatic presentation of slide design suggestions |
US9483444B2 (en) * | 2013-07-09 | 2016-11-01 | Flipboard, Inc. | Dynamic layout engine for a digital magazine |
US9940099B2 (en) * | 2014-01-03 | 2018-04-10 | Oath Inc. | Systems and methods for content processing |
US10331620B2 (en) | 2015-11-24 | 2019-06-25 | International Business Machines Corporation | File generator |
US10152462B2 (en) * | 2016-03-08 | 2018-12-11 | Az, Llc | Automatic generation of documentary content |
US10460023B1 (en) * | 2016-03-10 | 2019-10-29 | Matthew Connell Shriver | Systems, methods, and computer readable media for creating slide presentations for an annotation set |
US20180130496A1 (en) * | 2016-11-08 | 2018-05-10 | Yen4Ken, Inc. | Method and system for auto-generation of sketch notes-based visual summary of multimedia content |
US10733372B2 (en) * | 2017-01-10 | 2020-08-04 | Microsoft Technology Licensing, Llc | Dynamic content generation |
GB201708762D0 (en) | 2017-06-01 | 2017-07-19 | Microsoft Technology Licensing Llc | Managing electronic slide decks |
-
2017
- 2017-11-08 US US15/807,431 patent/US11481550B2/en active Active
- 2017-11-09 WO PCT/US2017/060933 patent/WO2018089685A1/en active Application Filing
- 2017-11-10 DE DE102017126380.2A patent/DE102017126380A1/en active Pending
- 2017-11-10 CN CN202210602720.XA patent/CN115203399A/en active Pending
- 2017-11-10 DE DE202017106839.0U patent/DE202017106839U1/en active Active
- 2017-11-10 CN CN201711108164.6A patent/CN108073680B/en active Active
- 2017-11-10 GB GB1718646.1A patent/GB2558400B/en active Active
-
2022
- 2022-10-24 US US17/972,411 patent/US20230153523A1/en active Pending
Patent Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7743331B1 (en) * | 2006-09-29 | 2010-06-22 | Adobe Systems Inc. | Viewing and modifying content slide navigation properties |
CN103718215A (en) * | 2011-07-05 | 2014-04-09 | 松下电器产业株式会社 | Presentation content generation device, presentation content generation method, presentation content generation program and integrated circuit |
CN105930471A (en) * | 2016-04-25 | 2016-09-07 | 上海交通大学 | Speech abstract generation method and apparatus |
Non-Patent Citations (5)
Title |
---|
‘Auto-Presentation’: A Multi-Agent System for Building Automatic Multi-Modal Presentation of a Topic from World Wide Web Information;al masum s m et al.;《intelligent agent technology》;20050919;全文 * |
A Text Mining Approach to Generate Powerpoint Presentation Using Machine Learning Algorithm;B. Muthazhagan;《middle0east journal of scientific research》;20160801;全文 * |
Automatic Era: Presentation slides from Academic Paper;Anuja M;《 2016 International Conference on Automatic Control and Dynamic Optimization Techniques》;20160909;全文 * |
predicting chart types with machine learning-feature release-chartio community;none;《none》;20160606;全文 * |
slidesgen:automatic generation of presentation slides for technical paper using summarization;m sravanthi et al.;《proceedings of the twenty-second international flairs conference》;20090519;全文 * |
Also Published As
Publication number | Publication date |
---|---|
US20180129634A1 (en) | 2018-05-10 |
CN108073680A (en) | 2018-05-25 |
DE102017126380A1 (en) | 2018-05-17 |
CN115203399A (en) | 2022-10-18 |
GB2558400A (en) | 2018-07-11 |
WO2018089685A1 (en) | 2018-05-17 |
GB201718646D0 (en) | 2017-12-27 |
US11481550B2 (en) | 2022-10-25 |
GB2558400B (en) | 2020-11-04 |
DE202017106839U1 (en) | 2018-02-14 |
US20230153523A1 (en) | 2023-05-18 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN108073680B (en) | Generating presentation slides with refined content | |
US10936648B2 (en) | Generating slide presentations using a collaborative multi-content application | |
US9208216B2 (en) | Transforming data into consumable content | |
JP6293142B2 (en) | Creating variations when converting data to consumer content | |
US20140025650A1 (en) | Abstract relational model for transforming data into consumable content | |
US20140047332A1 (en) | E-reader systems | |
US20140164915A1 (en) | Conversion of non-book documents for consistency in e-reader experience | |
US20150178259A1 (en) | Annotation hint display | |
US8775385B2 (en) | Techniques to modify file descriptors for content files | |
US11829712B2 (en) | Management of presentation content including generation and rendering of a transparent glassboard representation | |
US9275476B1 (en) | Multi-way and multi-thread conversation system | |
US11762898B1 (en) | Generating and utilizing digital media clips based on contextual metadata from digital environments | |
US20230315972A1 (en) | Generating and utilizing digital media clips based on contextual metadata from digital environments | |
US20230315971A1 (en) | Generating and utilizing digital media clips based on contextual metadata from digital environments | |
US10627997B1 (en) | System and method for highlighting dependent slides while editing master slides of a presentation | |
WO2023191905A1 (en) | Generating and utilizing digital media clips based on contextual metadata from digital environments | |
CN117010337A (en) | Document processing method, device, terminal, medium and program product | |
Brunelle | Lab II–Prototype Product Specification Green Team Robert O’Donnell Old Dominion University CS411W |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
GR01 | Patent grant | ||
GR01 | Patent grant |