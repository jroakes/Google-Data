EP2898431A2 - System and method for camera photo analytics - Google Patents
System and method for camera photo analyticsInfo
- Publication number
- EP2898431A2 EP2898431A2 EP13838866.5A EP13838866A EP2898431A2 EP 2898431 A2 EP2898431 A2 EP 2898431A2 EP 13838866 A EP13838866 A EP 13838866A EP 2898431 A2 EP2898431 A2 EP 2898431A2
- Authority
- EP
- European Patent Office
- Prior art keywords
- photo
- photos
- information
- taken
- users
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Withdrawn
Links
- 238000000034 method Methods 0.000 title claims abstract description 33
- 230000006855 networking Effects 0.000 claims abstract description 27
- 238000004458 analytical method Methods 0.000 claims abstract description 11
- 238000004891 communication Methods 0.000 claims description 17
- 238000012805 post-processing Methods 0.000 claims description 5
- 230000001413 cellular effect Effects 0.000 claims 1
- 230000015654 memory Effects 0.000 description 18
- 238000010586 diagram Methods 0.000 description 16
- 230000003287 optical effect Effects 0.000 description 2
- 238000007557 optical granulometry Methods 0.000 description 2
- 230000008569 process Effects 0.000 description 2
- 230000001052 transient effect Effects 0.000 description 2
- HBBGRARXTFLTSG-UHFFFAOYSA-N Lithium ion Chemical compound [Li+] HBBGRARXTFLTSG-UHFFFAOYSA-N 0.000 description 1
- OJIJEKBXJYRIBZ-UHFFFAOYSA-N cadmium nickel Chemical compound [Ni].[Cd] OJIJEKBXJYRIBZ-UHFFFAOYSA-N 0.000 description 1
- 230000008859 change Effects 0.000 description 1
- 230000000694 effects Effects 0.000 description 1
- 230000001815 facial effect Effects 0.000 description 1
- 238000010191 image analysis Methods 0.000 description 1
- 230000003993 interaction Effects 0.000 description 1
- 230000002452 interceptive effect Effects 0.000 description 1
- 239000004973 liquid crystal related substance Substances 0.000 description 1
- 229910001416 lithium ion Inorganic materials 0.000 description 1
- 230000007774 longterm Effects 0.000 description 1
- 239000000463 material Substances 0.000 description 1
- 238000012986 modification Methods 0.000 description 1
- 230000004048 modification Effects 0.000 description 1
- 230000000644 propagated effect Effects 0.000 description 1
- 230000011514 reflex Effects 0.000 description 1
- 230000004044 response Effects 0.000 description 1
- 230000003068 static effect Effects 0.000 description 1
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/50—Information retrieval; Database structures therefor; File system structures therefor of still image data
- G06F16/58—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually
- G06F16/5866—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using information manually generated, e.g. tags, keywords, comments, manually generated location and time information
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/50—Information retrieval; Database structures therefor; File system structures therefor of still image data
- G06F16/58—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually
- G06F16/587—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using geographical or spatial information, e.g. location
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q30/00—Commerce
- G06Q30/02—Marketing; Price estimation or determination; Fundraising
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q50/00—Systems or methods specially adapted for specific business sectors, e.g. utilities or tourism
- G06Q50/01—Social networking
Definitions
- One embodiment provides a method for generating one or more statistics related to a photo.
- the method includes collecting information describing circumstances of an event resulting in creation of a first photo taken by a camera; associating the information with the first photo, wherein the information includes attributes of an image included in the first photo and the camera; analyzing the information with respect to social networking information stored in one or more databases; and identifying one or more other photos related to the first photo based on results of the analysis.
- Another embodiment includes a method for receiving one or more statistics related to a photo.
- the method includes: capturing a first photo with a camera; generating metadata corresponding to the first photo; transmitting the first photo and the metadata to a server that includes an analytics engine; and receiving, from the server, statistical information related to the first photo, wherein the statistical information is generated based on the analytics engine analyzing the first photo and the metadata with respect to social networking information stored in a database.
- Yet another embodiment includes a system for generating a statistic about a photo, comprising: one or more databases storing photos and social networking data; a mobile phone that includes a camera configured to take a first photo; a server in communication with the mobile phone via a data network configured to: receive the first photo taken by the camera; receive metadata corresponding to the first photo and device information corresponding to the mobile phone; analyze the first photo, the metadata, and the device information with respect to the social networking data stored in the one or more databases; and identify one or more photos related to the first photo based on analyzing the first photo, the metadata, and the device information.
- FIG. 1 is a block diagram of an example system for generating photo analytics, according to an example embodiment.
- FIG. 2 is a block diagram of the arrangement of components of a client device configured to receive photo analytics, according to one embodiment.
- FIG. 3 is a block diagram of example functional components for a client device, according to one embodiment.
- FIG. 4 is a flow diagram for generating one or more photo analytics, according to an example embodiment.
- FIG. 5 is a flow diagram for generating one or more photo recommendations, according to an example embodiment.
- FIG. 6 is a flow diagram for updating photo analytics settings, according to an example embodiment.
- FIGs. 7A-7B are conceptual diagrams illustrating a user interface for presenting one or more analytics about a photo, according to an example embodiment.
- FIGs. 8A-8B are conceptual diagrams illustrating a user interface for presenting one or more recommendations associated with a photo, according to an example embodiment.
- the present disclosure relates to making photo-taking a more interactive and social experience.
- a client device such as a mobile phone
- the photo and certain metadata about the photo is uploaded to a server.
- metadata include GPS (global positioning system) location information about where the photo is taken, orientation/directional information, camera make/model, orientation of the camera (i.e., horizontal/vertical), date/time of the photo, weather data (e.g.,
- a device identifier (ID) corresponding to the client device taking the photo is uploaded to the server.
- the device ID can be used to identify a user that captured the photo, where each device ID corresponds to a particular user.
- the server can also search a social network database for photos taken by friends of the user and/or other publicly- available photos that are related to the photo currently being taken by the client device.
- Examples of social networking information may include users that are friends with or in social networking circles with the user, what other pictures the related users have taken that are similar to the current photo being taken, what other photos did the related users take just before and just after the related photo, and user tags within the related photos, among others.
- the photo, the metadata, and the social information are analyzed by an analytics engine at the server.
- the server generates statistical information about the photo.
- the statistics are then communicated above to the user, in real-time.
- Examples of statistics include: how many other people have taken a photo in this location (and what were their demographics, age, gender, interests, etc.), which people in the user's circles or contacts lists have taken a photo in this location, if there are people in the user's circles that have taken photos here: who were they with, when were they here, what were their photos like (e.g., with an option to access the photos if they have been made public), what were other similar photo locations of people who took photos here (e.g., either all users or just people in the user's circles), what were the preferred camera settings of people who took a photo in this location, what was the preferred photo orientation of people who took a photo in this location, what was the most common time of day that users took a photo in this location, etc.
- the analytics engine may also provide the user with an option and/or
- the analytics engine may provide the user with instructions on how to take similar photos to those taken by others. For example, if many users have taken a photo from a location 500 feet further to the east from the current location and at a time when the sun was in a particular location in the sky, the analytics engine may provide the user with instructions on how to move to the particular location and how much time the user has to wait until the sun is in the same position as in the photos of the other users.
- users may have privacy settings/options of whether their photos should be included in the analysis performed by the analytics engine and/or which metadata about their photos should be included in the analysis performed by the analytics engine.
- the analytics engine is configured to filter out certain types of photos and not perform the analysis.
- the analytics engine may be configured to perform an analysis on photos taken when users are sightseeing or traveling and want to discover other photo locations, but the analytics engine may be configured not to perform an analysis when the user is just taking a casual picture, e.g., at a party or at a social event (i.e., user does not want to be inundated with a stream of statistics for every picture taken).
- FIG. 1 is a block diagram of an example system for generating photo analytics, according to an example embodiment.
- the system includes a client device 102, a data network 104, a server 106, a photo database 108, and social networking information 110.
- the client device 102 can be any type of computing device, including a personal computer, laptop computer, mobile phone with computing capabilities, or any other type of device capable of making a voice call.
- the client device 102 includes, among other things, camera hardware 118, device hardware 120, camera software or application 122, a device identifier (ID) 124, other application(s), a communications client, output devices (e.g., a display), and input devices (e.g., keyboard, mouse, touch screen), etc.
- a client device 202 may act as both an output device and an input device.
- the camera hardware 118 includes picture-taking components, such as a digital sensor, a lens, a flash, among others.
- Device hardware 120 includes components capable of detecting and/or measuring real-world phenomena at the client device, e.g., a GPS (global positioning system) module, an accelerometer, a compass, and/or a light intensity sensor.
- the camera software application 122 allows a user to capture a photo at the client device 102 using the camera hardware 118.
- the camera software application 122 can be implemented in the OS (operating system) of the client device 102 or as a stand-alone application installed on the client device 102.
- the device ID 124 is a unique identifier corresponding to the client device 102. In some embodiments, the device ID 124 also corresponds to a particular user.
- the data network 104 can be any type of communications network, including an Internet network (e.g., wide area network (WAN) or local area network (LAN)), wired or wireless network, or mobile phone data network, among others.
- the client device 102 is configured to communicate with a server 106 via the data network 104.
- the server 106 includes an analytics engine 116.
- the server 106 is in communication with a photo database 108 and social networking information 110.
- the photo database 108 can also communicate with a server that stores the social networking information 110.
- the photo database 108 stores photos 112 and metadata 114 corresponding to the photos.
- metadata 114 include: a GPS location of the photo, a direction (i.e., compass information) of the photo, a device ID of the device taking the photo, camera make and/or model of the photo, an orientation (i.e., horizontal, vertical) of the photo, a date and time of the photo, weather information (e.g., sunset/sunrise information at a particular location and time, direction of light, and/or weather conditions (e.g., sun, rain, snow, etc.)), filters applied to the photo, other post-processing performed on the photo, contrast, brightness, exposure level, incandescence, fluorescence, scene mode, whether flash was ON/OFF, a number of faces in the photo, a number of re-takes made of this photo, and/or a reference to one or more related photos.
- the client device 102 is configured to communicate with the photo database 108 via
- a photo can be captured at the client device 102 and uploaded to the photo database 108 via the data network 104.
- the photo is also transmitted to the server 106 that includes the analytics engine 116.
- the analytics engine 116 analyzes the photo, as well as one or more other photos in the photo database 108, and/or social networking information 1 10 to identify one or more statistics and/or analytical information corresponding to the photo.
- the statistics or analytical information are then aggregated and delivered to the client device 102 and displayed on the client device.
- the statistics or analytical information provide information about other users that have taken similar photos and/or recommendations of other photos and/or camera settings to be used by the client device 102 when taking photos.
- the server 106, photo database 108, and social networking information 110 comprise a single server.
- the server 106, photo database 108, and social networking information 110 can be physically separate machines or can be different processes running within the same physical machine.
- the user may set various privacy controls related to the storage of the photos 112 and/or metadata 114 in the photo database 108. Examples include anonymization of device identifiers and/or ability for a user to modify or delete which information related to the user's photos is available to the analytics engine 116.
- FIG. 2 is a block diagram of the arrangement of components of a client device 102 configured to receive photo analytics from a server, according to one embodiment.
- client device 102 includes camera hardware 118, device hardware 120, a processor 202, and memory 204, among other components (not shown).
- the device hardware 120 includes, for example, a GPS module 212, an accelerometer 214, a compass 216, and a light sensor 218.
- the memory 204 includes various applications that are executed by processor 202, including installed applications 210, an operating system 208, and camera software 122.
- installed applications 210 may be downloaded and installed from an applications store.
- the camera software 122 is configured to upload a photo captured by the camera hardware 118 and associated metadata to a photo database 108 and/or server 106.
- the analytics engine 116 on the server 106 is configured to access the photo and the metadata and perform analysis to identify one or more statistics, analytics, and/or recommendations related to the photo. The one or more statistics, analytics, and/or recommendations are then communicated from the server 106 to the camera software 122 and displayed on the client device 102.
- FIG. 3 is a block diagram of example functional components for a client device 302, according to one embodiment.
- client device 302 includes one or more processor(s) 311, memory 312, a network interface 313, one or more storage devices 314, a power source 315, output device(s) 360, and input device(s) 380.
- the client device 302 also includes an operating system 318 and a communications client 340 that are executable by the client.
- Each of components 311, 312, 313, 314, 315, 360, 380, 318, and 340 is interconnected physically, communicatively, and/or operatively for inter-component communications in any operative manner.
- processor(s) 311 are configured to implement functionality and/or process instructions for execution within client device 302.
- processor(s) 311 execute instructions stored in memory 312 or instructions stored on storage devices 314.
- Memory 312 which may be a non-transient, computer-readable storage medium, is configured to store information within client device 302 during operation.
- memory 312 includes a temporary memory, area for information not to be maintained when the client device 302 is turned OFF.
- temporary memory include volatile memories such as random access memories (RAM), dynamic random access memories (DRAM), and static random access memories (SRAM).
- RAM random access memories
- DRAM dynamic random access memories
- SRAM static random access memories
- Storage devices 314 also include one or more non-transient computer-readable storage media. Storage devices 314 are generally configured to store larger amounts of information than memory 312. Storage devices 314 may further be configured for long-term storage of information. In some examples, storage devices 314 include non- volatile storage elements. Non- limiting examples of non- volatile storage elements include magnetic hard disks, optical discs, floppy discs, flash memories, or forms of electrically programmable memories (EPROM) or electrically erasable and programmable (EEPROM) memories.
- EPROM electrically programmable memories
- EEPROM electrically erasable and programmable
- the client device 302 uses network interface 313 to communicate with external devices via one or more networks, such server 106 and/or photo database 108 shown in FIG. 1.
- Network interface 313 may be a network interface card, such as an Ethernet card, an optical transceiver, a radio frequency transceiver, or any other type of device that can send and receive information.
- Other non-limiting examples of network interfaces include wireless network interface, Bluetooth®, 3G and WiFi® radios in mobile computing devices, and USB (Universal Serial Bus).
- the client device 302 uses network interface 313 to wirelessly communicate with an external device, a mobile phone of another, or other networked computing device.
- the client device 302 includes one or more input devices 380.
- Input devices 380 are configured to receive input from a user through tactile, audio, video, or other sensing feedback.
- Non-limiting examples of input devices 380 include a presence-sensitive screen, a mouse, a keyboard, a voice responsive system, camera 302, a video recorder 304, a microphone 306, a GPS module 308, or any other type of device for detecting a command from a user or sensing the environment.
- a presence-sensitive screen includes a touch-sensitive screen.
- One or more output devices 360 are also included in client device 302.
- Output devices 360 are configured to provide output to a user using tactile, audio, and/or video stimuli.
- Output devices 360 may include a display screen (part of the presence-sensitive screen), a sound card, a video graphics adapter card, or any other type of device for converting a signal into an appropriate form understandable to humans or machines.
- output device 360 includes a speaker, a cathode ray tube (CRT) monitor, a liquid crystal display (LCD), or any other type of device that can generate intelligible output to a user.
- a device may act as both an input device and an output device.
- the client device 302 includes one or more power sources 315 to provide power to the client device 302.
- power sources 315 include single-use power sources, rechargeable power sources, and/or power sources developed from nickel- cadmium, lithium-ion, or other suitable material.
- the client device 302 includes an operating system 318, such as the Android® operating system.
- the operating system 318 controls operations of the components of the client device 302.
- the operating system 318 facilitates the interaction of communications client 340 with processors 31 1, memory 312, network interface 313, storage device(s) 314, input device 180, output device 160, and power source 315.
- the client device 302 includes communications client 340.
- Communications client 340 includes communications module 345.
- communications client 340 and communications module 345 includes program instructions and/or data that are executable by the client device 302.
- communications module 345 includes instructions causing the communications client 340 executing on the client device 302 to perform one or more of the operations and actions described in the present disclosure.
- communications client 340 and/or communications module 345 form a part of operating system 318 executing on the client device 302.
- FIG. 4 is a flow diagram for generating one or more photo analytics, according to an example embodiment.
- Persons skilled in the art will understand that even though the method 400 is described in conjunction with the systems of FIGs. 1-3, any system configured to perform the method stages is within the scope of embodiments of the disclosure.
- the method 400 begins at stage 402 where a server receives a photo taken by a client device.
- the client device is a mobile phone and the photo is stored in a photo database.
- the server receives photo metadata corresponding to the photo.
- metadata include GPS (global positioning system) location information about where the photo is taken, orientation/directional information, camera make/model, orientation of the camera (i.e., horizontal/vertical), date/time, weather data (e.g., sunset/sunrise info, direction of light, weather conditions), post-processing filters, contrast, brightness, flash ON/OFF, exposure level, number of faces in the photo, among others.
- the metadata corresponding to the photo is included as part of the same file as the image of the photo.
- the server receives device identification information (device ID) associated with the client device that captured the photo.
- device ID device identification information
- each client device is associated with a particular user.
- the server receives social networking information corresponding to the device ID.
- the social networking information provides a listing of other users with which the user/client device is associated, e.g., as “friends,” or “followers,” and/or as being within the same social "circle.”
- the server analyzes the photo, the photo metadata, the device ID, and the social networking information to identify one or more statistics about the photo.
- the analyzing may include performing facial recognition, landmark recognition, or any other image analysis on the photo. Furthermore, according to various embodiments, the analyzing may include analyzing determining how many other people have taken a photo in this location (and what were their demographics, age, gender, interests, etc.), which people in the user's social network or contacts list have taken a photo in this location, if there are people in the user's social network that have taken photos here: who were they with, when were they here, what were their photos like (option to access the photos if they have been made public), what were other similar photo locations of people who took photos here (either all users or just people in the user's circles), what were the preferred camera settings of people who took a photo in this location, what was the preferred photo orientation of people who took a photo in this location, what was the most common time of day that users took a photo in this location.
- users can set privacy settings that limit, restrict, or remove their photos and/or photo metadata from being shared with others and/or used by the analytics engine to perform photo analysis. For example, a first user may choose to only allow the analytics engine to use the first user's photos and metadata when analyzing photos of a second user, when the second user is directly connected to the first user.
- the metadata of the photos of the first user may be used by the analytics engine when analyzing all photos of other users, but the photos themselves of the first user may only be available to the analytics engine for photos taken by users that are directly connected to the first user.
- the server identifies statistical data related to the photo.
- the statistical data includes a numerical count or numerical percentage related to a parameter of the photo.
- the statistical data may indicate the number of users that have taken a photo in this location or the percentage of users that have taken a photo in this location in landscape orientation versus portrait orientation.
- certain photos taken by others may be taken into consideration when calculating the statistical data, although the photos themselves are not available to the user of the client device that has taken the photo being analyzed by the analytics engine.
- the server identifies other photos related to the photo.
- the other photos may be organized in groups, such as by same location, same location and orientation, same location but different orientation, etc.
- the other photos are available based permissions associated with the photos.
- some related photos may be available to the public at large (e.g., photos from professional photographers).
- the user of the client device may not have a social networking relationship with the user that created the publicly-accessible photo, yet the photo is still used by the analytics engine when the analytics engine performs an analysis.
- the server ranks the statistical data and groups of other photos based on weighting criteria. For example, statistical data and/or groups of other photos that are based on what the social networking friends of the user of the client device may be weighted higher than "universal" statistical data and/or groups of other photos (e.g., percentage of total number of photos taken at this location at this time of day).
- stage 416 is optional and is omitted.
- the server delivers the statistical data and the groups of other photos to the client device.
- the statistical data and the groups of other photos are delivered via a network to the camera software application executing on the client device.
- the camera software application is configured to cause the statistical data and the groups of other photos to be displayed in a user interface on the client device.
- a particular photo may be used in the calculation of statistics (i.e., stage 412) and/or related photo analysis (i.e., stage 414), the photo may not be available to the user of the client device based on certain permissions set by the user who captured the particular photo.
- FIG. 5 is a flow diagram for generating one or more photo recommendations, according to an example embodiment.
- Persons skilled in the art will understand that even though the method 500 is described in conjunction with the systems of FIGs. 1-3, any system configured to perform the method stages is within the scope of embodiments of the disclosure.
- the method 500 begins at stage 502 where a server receives a photo and metadata corresponding to the photo captured by a client device.
- a server receives social networking information related to the photo.
- stages 502 and 504 in FIG. 5 are substantially similar to stages 402/404 and 408 in FIG. 4, respectively.
- a server identifies one or more recommendations based on the photo, the metadata, and the social networking information.
- the server may identify that the many other users (i.e., 80% of users) have taken a photo at this location, but in a different orientation from the photo captured by the client device.
- the recommendation can then be provided to the client device as an alert or notification.
- a server provides instructions to the client device for how to take a photo based on the one or more recommendations. For example, if 75% of users have taken a photo of the same landmark, but from a location 500 feet to the east of the current location of the photo, the recommendation may include an indication that many other users (i.e., 75% of users) have taken a photo at a location 500 feet to the east. In some embodiments, the recommendation also includes instructions on how to perform and/or complete the recommendation. For example, the recommendation includes instructions on how to reach the location 500 feet to the east.
- FIG. 6 is a flow diagram for updating photo analytics settings, according to an example embodiment. Persons skilled in the art will understand that even though the method 600 is described in conjunction with the systems of FIGs. 1-3, any system configured to perform the method stages is within the scope of embodiments of the disclosure.
- the method 600 begins at stage 602 where a server receives sharing settings information associated with photo analytics.
- the sharing settings may identify which data and/or photos are to be used by the analytics engine when computing photo analytics for which other users' photos. Examples of settings include: which photos are to be shared with others, with which other users the photos are to be shared, which particular pieces of metadata are to be shared and with whom, etc.
- the server updates a sharing profile based on the sharing settings.
- each user is associated with a sharing profile that identifies which data and/or photos is to be used by the analytics engine when computing photo analytics.
- the sharing settings are not stored at the user-level, but rather on a photo-by- photo basis.
- the server analyzes photos in accordance with the sharing profile. As described, only the data and/or photos that are within the appropriate permissions are used by the server to perform the analysis. Moreover, the user can change their permissions at any time. The update is then propagated on the server.
- FIGs. 7A-7B are conceptual diagrams illustrating a user interface for presenting one or more analytics about a photo, according to an example embodiment.
- a client device can capture a photo of a scene when a user selects a "take photo" button 702 included in the camera software.
- the camera software transmits the photo and/or metadata corresponding to the photo to a server and/or photo database.
- the server performs photo analytics, in accordance with the description above, and returns photo analytics results to the client device.
- FIG. 7B is an example of a user interface of photo analytics results returned to the client device.
- icons 704A, 704B present statistics in the user interface.
- An icon 706 indicates that more statistics are available to be viewed (e.g., by scrolling down).
- a user of the client device can select on one of the icons 704, 704B to view more detailed
- FIGs. 8A-8B are conceptual diagrams illustrating a user interface for presenting one or more recommendations associated with a photo, according to an example embodiment.
- the user interface shown in FIG. 8A is presented after a user selects one of the statistics and/or results presented in FIG. 7B.
- the user interface indicates that 15 friends of the user have also taken a photo at the same location.
- Thumbnails 802 of the photos from the friends may also be displayed in the user interface.
- the client device displays the user interface shown in FIG. 8B.
- the user has selected the thumbnail labeled thumbnail "F.”
- a full-screen version of the photo is displayed in FIG. 8B.
- options I, II, III, and IV are displayed below the full-screen version of the photo.
- the options I-IV may correspond to recommendations to the user that are related to the selected photo labeled thumbnail "F.”
- option I may correspond to a recommendation to take a photo with same camera orientation setting as the photo labeled thumbnail "F”
- option II may correspond to a recommendation to take a photo with same contrast and brightness setting as the photo labeled thumbnail "F”
- option III may correspond to a link to view photos related to the photo labeled thumbnail "F”
- option IV may correspond to a link to view the other photos taken by the user who took the photo labeled thumbnail "F.”
- embodiments of the disclosure provide a system and method for providing camera photo analytics to a user. Since the analytics are provided to the user in real-time (i.e., immediately or shortly after the photo has been captured), the user is likely still at the location in which the photo was captured. The user can then determine which other photos to take, whether the photo should be re -taken, or learn other interesting things about the photos of others, making the overall picture-taking experience more enjoyable and worthwhile.
- the users may be provided with an opportunity to control whether programs or features collect personal information (e.g., information about a user's social network, social actions or activities, profession, a user's preferences, or a user's current location), or to control whether and/or how to retrieve content (i.e., recorded voicemails) from a content server (i.e., a voicemail server).
- personal information e.g., information about a user's social network, social actions or activities, profession, a user's preferences, or a user's current location
- content server i.e., a voicemail server
- certain data may be anonymized in one or more ways before it is stored or used, so that personally identifiable information is removed.
- a user's identity may be anonymized so that no personally identifiable information can be determined for the user, or a user's geographic location may be generalized where location information is obtained (such as, for example, to a city, ZIP code, or state level), so that a particular location of a user cannot be determined.
- location information such as, for example, to a city, ZIP code, or state level
- the user may have control over how information is collected about him or her and used by the systems discussed herein.
Abstract
Description
Claims
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US13/625,809 US20140089401A1 (en) | 2012-09-24 | 2012-09-24 | System and method for camera photo analytics |
PCT/US2013/051499 WO2014046778A2 (en) | 2012-09-24 | 2013-07-22 | System and method for camera photo analytics |
Publications (2)
Publication Number | Publication Date |
---|---|
EP2898431A2 true EP2898431A2 (en) | 2015-07-29 |
EP2898431A4 EP2898431A4 (en) | 2016-07-27 |
Family
ID=50339978
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
EP13838866.5A Withdrawn EP2898431A4 (en) | 2012-09-24 | 2013-07-22 | System and method for camera photo analytics |
Country Status (3)
Country | Link |
---|---|
US (1) | US20140089401A1 (en) |
EP (1) | EP2898431A4 (en) |
WO (1) | WO2014046778A2 (en) |
Families Citing this family (20)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9936143B2 (en) | 2007-10-31 | 2018-04-03 | Google Technology Holdings LLC | Imager module with electronic shutter |
US9230287B2 (en) * | 2012-08-21 | 2016-01-05 | Google Inc. | Real-time notifications and sharing of photos among users of a social network |
JP2014146989A (en) * | 2013-01-29 | 2014-08-14 | Sony Corp | Image pickup device, image pickup method, and image pickup program |
US11238056B2 (en) * | 2013-10-28 | 2022-02-01 | Microsoft Technology Licensing, Llc | Enhancing search results with social labels |
KR102146855B1 (en) * | 2013-12-30 | 2020-08-21 | 삼성전자주식회사 | Photographing apparatus and method for sharing setting values, and a sharing system |
US9813611B2 (en) * | 2014-05-21 | 2017-11-07 | Google Technology Holdings LLC | Enhanced image capture |
US9729784B2 (en) * | 2014-05-21 | 2017-08-08 | Google Technology Holdings LLC | Enhanced image capture |
US9628702B2 (en) | 2014-05-21 | 2017-04-18 | Google Technology Holdings LLC | Enhanced image capture |
US9774779B2 (en) | 2014-05-21 | 2017-09-26 | Google Technology Holdings LLC | Enhanced image capture |
US9413947B2 (en) | 2014-07-31 | 2016-08-09 | Google Technology Holdings LLC | Capturing images of active subjects according to activity profiles |
US9723200B2 (en) | 2014-10-15 | 2017-08-01 | Microsoft Technology Licensing, Llc | Camera capture recommendation for applications |
US11048855B2 (en) | 2015-02-11 | 2021-06-29 | Google Llc | Methods, systems, and media for modifying the presentation of contextually relevant documents in browser windows of a browsing application |
US10223459B2 (en) | 2015-02-11 | 2019-03-05 | Google Llc | Methods, systems, and media for personalizing computerized services based on mood and/or behavior information from multiple data sources |
US9769564B2 (en) | 2015-02-11 | 2017-09-19 | Google Inc. | Methods, systems, and media for ambient background noise modification based on mood and/or behavior information |
US11392580B2 (en) | 2015-02-11 | 2022-07-19 | Google Llc | Methods, systems, and media for recommending computerized services based on an animate object in the user's environment |
US10284537B2 (en) * | 2015-02-11 | 2019-05-07 | Google Llc | Methods, systems, and media for presenting information related to an event based on metadata |
US9986152B2 (en) | 2016-08-02 | 2018-05-29 | International Business Machines Corporation | Intelligently capturing digital images based on user preferences |
CN110162643B (en) * | 2018-09-13 | 2023-08-25 | 腾讯科技（深圳）有限公司 | Electronic album report generation method, device and storage medium |
US10924661B2 (en) | 2019-05-02 | 2021-02-16 | International Business Machines Corporation | Generating image capture configurations and compositions |
CN114511915B (en) * | 2022-04-19 | 2022-07-29 | 南昌大学 | Trusted certificate photo acquisition system and method based on mobile client |
Family Cites Families (8)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20100088128A1 (en) * | 2008-09-26 | 2010-04-08 | Deep Rock Drive Partners Inc. | Ticket scarcity management for interactive events |
US20110211737A1 (en) * | 2010-03-01 | 2011-09-01 | Microsoft Corporation | Event Matching in Social Networks |
US9465993B2 (en) * | 2010-03-01 | 2016-10-11 | Microsoft Technology Licensing, Llc | Ranking clusters based on facial image analysis |
US8332429B2 (en) * | 2010-06-22 | 2012-12-11 | Xerox Corporation | Photography assistant and method for assisting a user in photographing landmarks and scenes |
US8818049B2 (en) * | 2011-05-18 | 2014-08-26 | Google Inc. | Retrieving contact information based on image recognition searches |
US8625904B2 (en) * | 2011-08-30 | 2014-01-07 | Intellectual Ventures Fund 83 Llc | Detecting recurring themes in consumer image collections |
TWI534721B (en) * | 2011-10-19 | 2016-05-21 | 致伸科技股份有限公司 | Photo sharing system with face recognition function |
US8824751B2 (en) * | 2013-01-07 | 2014-09-02 | MTN Satellite Communications | Digital photograph group editing and access |
-
2012
- 2012-09-24 US US13/625,809 patent/US20140089401A1/en not_active Abandoned
-
2013
- 2013-07-22 WO PCT/US2013/051499 patent/WO2014046778A2/en active Application Filing
- 2013-07-22 EP EP13838866.5A patent/EP2898431A4/en not_active Withdrawn
Also Published As
Publication number | Publication date |
---|---|
WO2014046778A2 (en) | 2014-03-27 |
WO2014046778A3 (en) | 2015-07-16 |
EP2898431A4 (en) | 2016-07-27 |
US20140089401A1 (en) | 2014-03-27 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US20140089401A1 (en) | System and method for camera photo analytics | |
US11611846B2 (en) | Generation, curation, and presentation of media collections | |
US11637797B2 (en) | Automated image processing and content curation | |
US11171910B2 (en) | Social network status | |
US20230071099A1 (en) | Methods and systems for presentation of media collections with automated advertising | |
KR102355456B1 (en) | A system for tracking the engagement of media items | |
US11640625B2 (en) | Generation, curation, and presentation of media collections with automated advertising | |
US20200250870A1 (en) | Generation, curation, and presentation of media collections | |
US9338311B2 (en) | Image-related handling support system, information processing apparatus, and image-related handling support method | |
CN109074390B (en) | Method and system for generation, curation and presentation of media collections | |
EP3179408A2 (en) | Picture processing method and apparatus, computer program and recording medium | |
US20170118298A1 (en) | Method, device, and computer-readable medium for pushing information | |
CN103797493A (en) | Smart camera for sharing pictures automatically | |
US11430211B1 (en) | Method for creating and displaying social media content associated with real-world objects or phenomena using augmented reality | |
US20210224661A1 (en) | Machine learning modeling using social graph signals | |
WO2017084295A1 (en) | Automatic focusing method and device | |
KR20210107139A (en) | Deriving audiences through filter activity | |
CN104123339A (en) | Method and device for image management | |
CN108108461B (en) | Method and device for determining cover image | |
US20230146563A1 (en) | Automated image processing and insight presentation | |
CN112528185A (en) | Comment information display method and device, server and terminal | |
US20190082002A1 (en) | Media file sharing method, media file sharing device, and terminal | |
KR20170098113A (en) | Method for creating image group of electronic device and electronic device thereof | |
KR20190139500A (en) | Method of operating apparatus for providing webtoon and handheld terminal | |
KR20150125441A (en) | Apparatus and method for integrated management of data in mobile device, and the mobile device |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PUAI | Public reference made under article 153(3) epc to a published international application that has entered the european phase |
Free format text: ORIGINAL CODE: 0009012 |
|
17P | Request for examination filed |
Effective date: 20150430 |
|
AK | Designated contracting states |
Kind code of ref document: A2Designated state(s): AL AT BE BG CH CY CZ DE DK EE ES FI FR GB GR HR HU IE IS IT LI LT LU LV MC MK MT NL NO PL PT RO RS SE SI SK SM TR |
|
AX | Request for extension of the european patent |
Extension state: BA ME |
|
R17D | Deferred search report published (corrected) |
Effective date: 20150716 |
|
RIC1 | Information provided on ipc code assigned before grant |
Ipc: H04W 24/10 20090101ALI20160304BHEPIpc: G06K 9/20 20060101AFI20160304BHEPIpc: G06K 9/62 20060101ALI20160304BHEP |
|
DAX | Request for extension of the european patent (deleted) | ||
A4 | Supplementary search report drawn up and despatched |
Effective date: 20160629 |
|
RIC1 | Information provided on ipc code assigned before grant |
Ipc: G06F 17/30 20060101AFI20160623BHEP |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: THE APPLICATION IS DEEMED TO BE WITHDRAWN |
|
18D | Application deemed to be withdrawn |
Effective date: 20170201 |
|
P01 | Opt-out of the competence of the unified patent court (upc) registered |
Effective date: 20230519 |