CN117795527A - Evaluation of output sequences using autoregressive language model neural networks - Google Patents
Evaluation of output sequences using autoregressive language model neural networks Download PDFInfo
- Publication number
- CN117795527A CN117795527A CN202280052514.4A CN202280052514A CN117795527A CN 117795527 A CN117795527 A CN 117795527A CN 202280052514 A CN202280052514 A CN 202280052514A CN 117795527 A CN117795527 A CN 117795527A
- Authority
- CN
- China
- Prior art keywords
- sequence
- output sequence
- candidate output
- tokens
- input
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
- 238000013528 artificial neural network Methods 0.000 title claims abstract description 113
- 238000011156 evaluation Methods 0.000 title description 13
- 238000000034 method Methods 0.000 claims abstract description 58
- 238000003860 storage Methods 0.000 claims abstract description 10
- 238000012549 training Methods 0.000 claims description 87
- 230000004044 response Effects 0.000 claims description 51
- 238000012545 processing Methods 0.000 claims description 40
- 230000006870 function Effects 0.000 claims description 16
- 230000001143 conditioned effect Effects 0.000 claims description 5
- 230000001419 dependent effect Effects 0.000 claims 1
- 238000004590 computer program Methods 0.000 abstract description 15
- 230000008569 process Effects 0.000 description 27
- 230000000875 corresponding effect Effects 0.000 description 21
- 230000007246 mechanism Effects 0.000 description 19
- 239000013598 vector Substances 0.000 description 13
- 238000009826 distribution Methods 0.000 description 9
- 230000009471 action Effects 0.000 description 7
- 238000004891 communication Methods 0.000 description 6
- 238000010586 diagram Methods 0.000 description 6
- 238000010801 machine learning Methods 0.000 description 6
- 239000011159 matrix material Substances 0.000 description 6
- 230000003993 interaction Effects 0.000 description 5
- 230000026676 system process Effects 0.000 description 4
- 238000013526 transfer learning Methods 0.000 description 4
- 238000009966 trimming Methods 0.000 description 4
- 230000008901 benefit Effects 0.000 description 3
- 238000005070 sampling Methods 0.000 description 3
- 230000009466 transformation Effects 0.000 description 3
- ORILYTVJVMAKLC-UHFFFAOYSA-N Adamantane Natural products C1C(C2)CC3CC1CC2C3 ORILYTVJVMAKLC-UHFFFAOYSA-N 0.000 description 2
- 230000003287 optical effect Effects 0.000 description 2
- 238000013515 script Methods 0.000 description 2
- 238000000926 separation method Methods 0.000 description 2
- 238000013519 translation Methods 0.000 description 2
- 238000007476 Maximum Likelihood Methods 0.000 description 1
- 239000000654 additive Substances 0.000 description 1
- 230000000996 additive effect Effects 0.000 description 1
- 230000005540 biological transmission Effects 0.000 description 1
- 230000003750 conditioning effect Effects 0.000 description 1
- 238000001914 filtration Methods 0.000 description 1
- 230000010365 information processing Effects 0.000 description 1
- 239000004973 liquid crystal related substance Substances 0.000 description 1
- 238000007477 logistic regression Methods 0.000 description 1
- 238000004519 manufacturing process Methods 0.000 description 1
- 230000001537 neural effect Effects 0.000 description 1
- 238000010606 normalization Methods 0.000 description 1
- 230000000644 propagated effect Effects 0.000 description 1
- 239000004065 semiconductor Substances 0.000 description 1
- 230000001953 sensory effect Effects 0.000 description 1
- 239000000758 substrate Substances 0.000 description 1
- 238000012546 transfer Methods 0.000 description 1
- 230000000007 visual effect Effects 0.000 description 1
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/084—Backpropagation, e.g. using gradient descent
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F18/00—Pattern recognition
- G06F18/20—Analysing
- G06F18/21—Design or setup of recognition systems or techniques; Extraction of features in feature space; Blind source separation
- G06F18/211—Selection of the most significant subset of features
- G06F18/2113—Selection of the most significant subset of features by ranking or filtering the set of features, e.g. using a measure of variance or of feature cross-correlation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/20—Natural language analysis
- G06F40/279—Recognition of textual entities
- G06F40/284—Lexical analysis, e.g. tokenisation or collocates
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/045—Combinations of networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/0475—Generative networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/09—Supervised learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N20/00—Machine learning
Abstract
Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for evaluating candidate output sequences using a language model neural network. In particular, an autoregressive language model neural network is used to generate candidate output sequences. The same autoregressive language model neural network is used to evaluate the candidate output sequences to determine a ranking score for each of one or more criteria. The rating score is then used to determine whether to provide a candidate output sequence.
Description
Cross Reference to Related Applications
The present application claims the benefit of U.S. provisional application No.63/226,748 filed on 7/28 of 2021. The disclosure of the present application is considered to be part of the disclosure of the present application and is incorporated herein by reference.
Background
The present description relates to processing inputs using neural networks to generate output sequences.
Neural networks are machine-learning models that employ one or more layers of nonlinear cells to receive input prediction outputs. In addition to the output layer, some neural networks include one or more hidden layers. The output of each hidden layer is used as an input to the next layer in the network (i.e., another hidden layer or output layer). Each layer of the network generates an output from the received input according to the current value of the corresponding parameter set.
Disclosure of Invention
The present specification describes a system implemented as a computer program on one or more computers in one or more locations that uses an autoregressive language model neural network to generate an output sequence and then uses the same autoregressive language model neural network to evaluate the output sequence, i.e., to determine whether the output sequence is suitable for provision as an output of the system or to select which output sequence should be provided in response to a given request. Thus, the system uses the same autoregressive neural network to both generate sequences and to "discriminate" between the generated sequences to determine which sequence, if any, is provided in response to a given request.
The subject matter described in this specification can be implemented in specific embodiments to realize one or more of the following advantages.
The described techniques allow autoregressive language model neural networks to function as both a generator and a arbiter, i.e., to both generate an output sequence and evaluate the extent to which the output sequence meets one or more criteria.
Having a single model that can act as both a generator and a arbiter allows the candidate output to be accurately evaluated with respect to generating candidates with minimal additional computational overhead relative to having separate generator and arbiter models. That is, the system is able to evaluate the generated sequence with less additional latency and at the same time consumes much less additional memory than evaluating the sequence using a separate generator model.
For example, in some cases, the language model neural network can be deployed on a device with constrained memory space, i.e., on available memory or on a device requiring low decoding latency (e.g., on an edge device such as a mobile device, smart speaker, or other internet of things (IoT) device, or embedded in a robot or other physical system). In these cases, the system is able to evaluate the sequence generated by the neural network on the device with minimal additional computational overhead, allowing the quality of the output sequence provided in response to the received request to be improved while still performing processing on the device and without additional data communication over the network. That is, because the language model neural network is used as both a generator and a arbiter, the edge device is able to perform the evaluation locally on the device without exceeding memory or latency constraints.
Furthermore, the single model can be used to filter task-specific trim data and then the filtered data is used to trim the model to perform well on a particular task. After trimming, the quality of the output sequence generated by the language model neural network can be significantly increased because the language model has trimmed the training data without a large amount of nonstandard output.
The details of one or more embodiments of the subject matter of this specification are set forth in the accompanying drawings and the description below.
Other features, aspects, and advantages of the subject matter will become apparent from the description, the drawings, and the claims.
Drawings
FIG. 1 is a diagram of an example neural network system.
FIG. 2 is a diagram of one example of a criteria evaluation system.
FIG. 3 is a flow chart of an example process for evaluating candidate output sequences.
FIG. 4 is a diagram of another example of a criteria evaluation system.
FIG. 5 is a flow chart of another example process for evaluating candidate output sequences.
Like reference numbers and designations in the various drawings indicate like elements.
Detailed Description
Fig. 1 is a diagram of an example neural network system 100. The neural network system 100 is an example of a system implemented as a computer program on one or more computers in one or more locations, in which the systems, components, and techniques described below can be implemented.
The neural network system 100 is a system that generates an output sequence 150 in response to a received request.
For example, the system 100 can be an output sequence generation system that generates an output sequence 150 without hints, i.e., without being conditioned on any user-specified contextual input. In these embodiments, the output sequence generated by the system 100 approximates samples of the distribution of training output sequences used during training of the system 100.
As an example, the system 100 can be a text generation system that generates text sequences, i.e., each output sequence 150 generated by the system 100 is a sequence of text tokens from a vocabulary of text tokens (tokens) that include, for example, one or more of characters, subwords, words, punctuation marks, numbers, or other symbols that appear in natural language text. For example, the system 100 may generate a text sequence in response to the received request and provide the text sequence for presentation to the user.
As another example, the system 100 can be an image generation system that generates images as sequences of pixels, i.e., each output sequence 150 generated by the system 100 is a sequence of color values for pixels in an output image arranged according to a specified order.
As another example, the system 100 can receive the context sequence 102 as part of a request and generate the output sequence 150 as a response to the context sequence 102.
As a particular example, the system 100 can be part of a dialog system, and the context sequence 102 can include audio or text from a most recent dialog turn (conversational turn) submitted by a user of the dialog system during a dialog, while the output sequence 150 is the next dialog turn in the dialog, e.g., text or audio as a response to the most recent dialog turn. Optionally, the context sequence 102 can also include one or more historical conversation rounds that occurred earlier in the conversation.
As another particular example, the system 100 can be part of a machine translation system, and the context sequence 102 can include text in a source language, while the output sequence 150 is text in a target language that is a translation of the source text into the target language.
As another particular example, the system 100 can be part of a computer code generation system, and the context sequence 102 can be a text description of a desired code segment or segment of computer code in a programming language, and the output sequence 150 can be computer code, e.g., a segment of code described by the context sequence 102 or a segment of code following the context sequence 102 in a computer program.
More specifically, the system 100 receives a request for the output sequence 150 and, in response, generates one or more candidate output sequences 120 using the autoregressive language model neural network 110, i.e., without being conditioned on the context sequence 102 or conditioned on the context sequence 102.
Each candidate output sequence 120 includes a respective token from a vocabulary of tokens at each of a plurality of locations. The vocabulary of tokens can include any of a variety of tokens representing text symbols or other symbols. For example, the vocabulary of lemmas can include one or more of characters, subwords, words, punctuation marks, numbers, or other symbols that appear in a corpus of natural language text.
The language model neural network 110 is referred to as an autoregressive neural network because the neural network 110 generates an output sequence of tokens from regression by: each particular token is generated in the output sequence on the condition that any token that precedes the particular text token in the output sequence (i.e., a token that has been generated for any previous position in the output sequence that precedes the particular position of the particular token). When the system 100 also receives the context sequence 102, the current input sequence can also include the context sequence 102. For example, the current input sequence when generating a lemma at any given location in the output sequence can include the context sequence 102 and the lemma at any previous location prior to the given location in the output sequence. As a particular example, the current input sequence can include a context sequence 102, followed by a "sentinel" sequence, which represents a predetermined sequence of tokens that indicates to the neural network 110 that a response to the context sequence 102 should be generated, and then a token at any previous position before a given position in the output sequence. Alternatively, the subsequences can be separated by predetermined tokens (e.g., "<" and ">" tokens) within the current input sequence.
More specifically, to generate a particular token at a particular location within the candidate output sequence 120, the neural network 110 can process the current input sequence to generate a score distribution (e.g., probability distribution) that assigns a respective score (e.g., a respective probability) to each token in the vocabulary of tokens. The neural network 110 can then use the score distribution to select a term from the vocabulary as a particular term. For example, the neural network 110 can select the highest scoring word elements in a greedy manner or can sample the word elements from the distribution, e.g., using kernel sampling (kernel sampling) or another sampling technique.
As a specific example, the language model neural network 110 can be an autoregressive-based Transformer neural network that includes (i) a plurality of attention blocks that each apply a self-attention operation and (ii) an output sub-network that processes the output of the last attention block to generate a score distribution.
The neural network 110 can have any of a variety of Transformer-based neural network architectures. Examples of such structures include those described in the following: colin Raffel, noam Shazer, adam Roberts, katherine Lee, shacan Narang, michael Matena, yanqi Zhou, wei Li, and Peter J Liu.Explorer the limits of transfer learning with a unified text-to-text transformers (restrictions on transfer learning are explored with unified text-to-text transformers). ArXiv preprint arXiv:1910.10683,2019; daniel Adiwardana, minh-Thang Luong, david R.so, jamie Hall, noah Fiedel, romal Thopilan, zi Yang, apoorv Kulshreshtha, gaurav New, YIFENG Lu and Quoc V.le.Towards a human-like open-domain chatbot (Mier open domain chat robot). CoRR, abs/2001.09977,2020; and Tom B Brown, benjamin Mann, nick Ryder, melanie Subbih, jared Kaplan, prafulla Dhariwal, arvind Neelakantan, praav Syam, grish Satry, amandASK et al Language models are few-shot learners (language model is a less trial learner). ArXiv preprint arXiv:2005.14165,2020.
However, in general, a Transformer-based neural network includes a sequence of attention blocks, and during processing of a given input sequence, each attention block in the sequence receives a respective input hidden state for each input word in the given input sequence. The attention block then updates each hidden state at least in part by applying the self-attention to generate a respective output hidden state for each input word element. The input hidden state of the first attention block is an embedding of an input word in the input sequence and the input hidden state of each subsequent attention block is an output hidden state generated by a previous attention block.
In this example, the output subnetwork processes the output hidden states generated by the last attention block in the sequence for the last input word element in the input sequence to generate a score distribution.
In some implementations, the system 100 or another training system pre-trains the language model neural network 110 on a language modeling task (e.g., a need to predict a next word after a current sequence in training data given a current sequence of text words). As a particular example, the language model neural network 110 can be pre-trained on maximum likelihood targets on a large dataset, such as text publicly available from the internet or another text corpus.
In general, because the neural network 110 is autoregressive, the system 100 can use the same neural network 110 to generate a plurality of different candidate output sequences 120 in response to the same request, for example, by using beam search decoding according to a fractional distribution generated by the neural network 110, using a Sample-and-Rank decoding strategy, or using another decoding strategy that exploits the autoregressive nature of the neural network.
When generating the plurality of candidate output sequences 120, the system 100 needs to determine which of the plurality of sequences is the output sequence 150 that is responsive to the request. Furthermore, even if only a single output sequence is generated, some candidate output sequences 120 are not suitable to be provided as the final output sequence 150.
To determine how to respond to a given request, i.e., to determine which candidate output sequences 120, if any, are provided in response to the request, the system 100 maintains data specifying a set of one or more criteria ("output sequence criteria"), each metric measuring a corresponding property of the given output sequence.
The set of criteria can include any of a variety of criteria that metric properties related to the quality of a given candidate output sequence in terms of tasks that the system 100 is configured to perform.
For example, the set of criteria can include criteria corresponding to a reasonable degree of output sequence (sendibleness). Whether the response of the wisdom criteria metric model is reasonable, i.e., whether a given candidate output sequence generated by the neural network 110 is in the context of the current interaction (i.e., as a response to the context sequence 102) is reasonable and does not contradict any information in the context sequence 102 or in an earlier sequence during the current interaction. Thus, if the output sequence is rational, the output sequence meets the criterion.
As another example, the set of criteria can include criteria corresponding to specificity (specificity) of the output sequence. Whether the response of the specificity criteria metric model is specific, i.e., whether a given candidate output sequence generated by the neural network 110 is specific to the corresponding context sequence 102, is not a generic response that can be applied to any of the various context sequences. For example, if the context sequence 102 is "I love television (i love television)" and the model responds "metao (i are also)", this will receive a low score in specificity, e.g., score 0, because the response can be used in many different contexts. If the model responds to "Metoo.I love watching reality shows, (I am. I am also. Love to see the genuine show)", it will have a higher specificity score.
As another example, the set of criteria can include criteria corresponding to the interestingness of the output sequence. The interestingness criterion measures whether the response of the model is interesting, i.e. whether a given candidate output sequence generated by the neural network 110 is interesting for the person generating the corresponding context sequence 102. For example, for "How do I throw a ball? (how do i throw a ball? The "response may be" You can throw a ball by first picking it up and then throwing it. (you can throw a ball by first picking up the ball and then throwing the ball) ". Alternatively, another answer that is more interesting might be "One way to toss a ball is to hold it firmly in both hands and then swing your arm down and up again, extending your elbow and then releasing the ball upswards" (one way to throw a ball is to hold the ball firmly in both hands, then swing the arm down and up again, extend the elbow, then release the ball upwards ")" while the original answer is reasonable and specific to the problem, it might not be considered interesting or informative for the person who is making the problem. On the other hand, the alternative response provides additional information to answer the question and thus the criterion for interestingness may be higher than the initial response.
Other criteria can be included instead of or in addition to the above criteria. For example, other criteria can include a suitability (suitability) criterion that measures the extent to which a given output sequence is suitable to be provided in response to a request.
The system 100 uses the criterion evaluation system 130 to generate a respective rating score 140 for each of one or more criteria in the set. The ranking score 140 for a given criterion measures the degree to which the candidate output sequence 120 generated by the autoregressive language model neural network 110 meets the criterion.
In general, the criteria evaluation system 130 uses the output from the language model neural network 110 to generate the rating score 140 in a computationally efficient but accurate manner.
Example techniques for generating the rating score 140 for one or more criteria in a set using the neural network 110 are described below with reference to fig. 2-5.
That is, rather than using only a separately trained machine learning model to generate the ratings score 140, the system 130 utilizes the neural network 110 to both increase the accuracy of the ratings score 140 and the computational efficiency of generating the ratings score 140.
Once the rating score 140 is generated, the system 100 can use the rating score 140 to determine whether to provide the candidate output sequence 120 in response to a request in any of a variety of ways.
For example, in embodiments in which the system 100 generates a plurality of candidate output sequences, the system 100 can generate, for each of the candidate output sequences, a respective quality score from the respective rating scores 140 for the candidate output sequences for one or more criteria in the set. For example, the quality score for a given candidate output sequence can be a sum or weighted sum of the rating scores 140 for one or more criteria.
The system 100 can then select the candidate output sequence 120 with the highest corresponding quality score as the sequence to be provided in response to the request.
As another example, the system 100 can maintain respective thresholds for at least a subset of the criteria. In this example, for each criterion in the subset, the system 100 can determine, for the given candidate output sequence 120, whether the respective quality score for the given candidate output sequence for the criterion in the set meets (e.g., exceeds) a threshold for the criterion, and then determine not to provide the given candidate output sequence in response to the request when the respective quality score for the first output criterion in the set for the given candidate output sequence does not meet the threshold (even though the given candidate output sequence would otherwise have the highest quality score).
In addition to or instead of using the system 130 to determine how to respond to a request, the system 100 can also use the system 130 to filter task-specific trimming data and the filtered data can then be used to trim the model to perform well on a particular task.
In particular, the system 100 is capable of obtaining task-specific trimming data comprising a set of training output sequences and optionally a corresponding context sequence for each training output sequence. The system 130 can then generate a rating score for each of the training output sequences and then use the rating scores to filter one or more training output sequences out of the fine tuning data. For example, the system 130 can determine to filter out any training output sequences having a quality score below a threshold. As another example, the system 130 can determine to filter out any training output sequences that have a rating score below another threshold for each criterion in a subset of finger hits (assigned) for the criterion. By filtering out these training output sequences, the system improves the overall quality of the output sequences in the trim data, and thus, after trimming, the quality of the output sequences generated by the language model neural network 110 can be significantly increased.
Fig. 2 is a diagram of one example of a criteria evaluation system 130.
In the example of FIG. 2, the criterion evaluation system 130 includes a respective criterion engine 220A-N for each of one or more criteria.
Each criterion engine 220A-N receives the candidate output sequence 120 and generates a rating score 140 for the corresponding criterion. The ranking score 140 represents the degree to which the candidate output sequences 120 generated by the autoregressive language model neural network 110 meet the criteria.
To generate the rating score 140, each criterion engine 220A-N receives the candidate output sequence 120 and generates an input sequence 230 based on the candidate output sequence 120 and a predetermined sequence of one or more tokens from a vocabulary specifying the criterion, i.e., a sequence of tokens identifying to the autoregressive neural network 110 which criterion is being evaluated. More specifically, prior to using the neural network 110 to evaluate one or more criteria, the system receives as input a respective sequence of tokens for each criterion. For example, a word sequence can be a natural language name or other identifier of a corresponding criterion, e.g., the word "specificity" can represent a specificity criterion, and the word "interestingness" can represent an interestingness criterion.
Specifically, the input sequence 230 for a given criterion includes a candidate output sequence 120 followed by one or more tokens specifying the output sequence criterion. When the system 100 also receives the context sequence 102, the input sequence 230 can also include the context sequence.
As a specific example, the input sequence 230 can be of the form:
< context > < response > < attribute-name >, where "context" represents the context sequence 102, "sensor" represents a predetermined sequence of lemmas that indicate to the neural network 110 that a response to the context sequence 102 should be generated, "response" is the candidate output sequence 120, and "attribute-name" is the lemma that specifies the criterion.
The system 130 then processes the input sequence 230 using the neural network 110 to generate a respective score for each of the tokens in the vocabulary. Since the neural network 110 has processed the context sequence 102 to generate the candidate output sequence 120, this process (also referred to as an "evaluation arbiter") simply involves processing one or more additional tokens "< attribute-name >" appended after the candidate output sequence 120 while reusing hidden states generated during generation of the candidate output sequence 120. This is in contrast to using different neural networks for evaluation criteria and is significantly more computationally efficient, i.e., because the different neural networks will need to process all of the tokens in the context 102 and candidate output sequence 120 in order to accurately score the candidate output sequence 102.
Thus, each engine 220A-N generates a different input sequence 230 and uses the neural network 110 to generate a corresponding score distribution on the vocabulary of tokens.
Each engine 220A-N then determines a rating score 140 based on the respective scores of the tokens in the corresponding true subset of the vocabulary of tokens.
That is, each criterion has a corresponding proper subset of one or more tokens in the vocabulary.
When each rating score has the same range, the corresponding proper subset can be the same.
When different rating scores have different ranges, the corresponding proper subset can be different. For example, when the rating score ranges from 0 to 1, the engines 220A-N can use the score of the lemma "1" as the rating score 140. More generally, the engine 220A-N system can calculate the rating score 140 as a weighted sum of each possible real value (ground score) equal to the rating score, where the weight of each real value is a score of a word element representing the real value in the vocabulary.
Thus, as shown in FIG. 2, the system 130 uses the neural network 110 to generate the rating score 140 for one or more criteria in a computationally efficient manner, i.e., because generating the rating score 140 requires only the neural network 110 to process a number of additional tokens per criterion.
Before using the neural network 110 to generate the ranking score and after the neural network 110 is pre-trained, the system 130 or another training system fine-tunes the neural network 110 to cause the neural network 110 to accurately generate the ranking score, i.e., fine-tunes by repeatedly performing training steps on multiple batches of training samples (training samples) in the training dataset.
Each training sample includes a training input sequence that includes (i) a training output sequence followed by (ii) one or more tokens specifying a particular criterion from a set of criteria. Each training sample also includes a true value rating score for the corresponding output sequence criterion that represents the extent to which the training output sequence meets the particular output sequence criterion. A true value rating score can be obtained, for example, which is the result of a user manually marking an output sequence or the output of another automatic marking system.
To perform the training step, the system (i.e., system 130 or another training system) obtains a batch of one or more training samples. For example, the system can sample batches from a larger set of training samples for the fine-tuning training process.
For each training sample in the batch, the system processes the training input sequence in the training sample using the autoregressive language model neural network to generate a respective score for each word element in the vocabulary.
The system then trains an autoregressive language model neural network to minimize a loss function that measures, for each training sample in the batch, an error between (i) a respective score of a word element in a vocabulary generated for that training sample and (ii) a set of true values of scores of the word elements in the vocabulary that would produce a true value ranking score for the training sample. For example, the loss function can be a negative log likelihood loss or a cross entropy loss.
In particular, the system can calculate the gradient of the loss function relative to the parameters of the neural network 110, for example, by back propagation. The system can then update the parameters of the neural network 110 by applying the optimizer to the calculated gradient to generate an update, and then add or subtract the update to or from the current value of the parameter.
The system is able to perform this fine tuning in a computationally efficient manner, since the penalty is only applied to the error measured by the penalty function, i.e. only the rating score for the prediction, and not to any predictions at any earlier positions in the training input sequence.
As described above, after the fine-tuning has been performed, the system 130 or another training system can also use the engines 210A-N to generate a filtered training data set for further fine-tuning the neural network 110.
FIG. 3 is a flow chart of an example process 300 for evaluating candidate output sequences. For convenience, process 300 will be described as being performed by a system of one or more computers located in one or more locations. For example, a neural network system (e.g., the neural network system 100 depicted in fig. 1) suitably programmed in accordance with the present description is capable of performing the process 300.
The system receives a request for an output sequence (step 302). In some implementations, the request includes a context sequence, and the request is for a response to the context sequence.
The system generates a first candidate output sequence comprising a plurality of tokens, each of the plurality of tokens selected from a vocabulary of tokens using an autoregressive language model neural network (step 304). As described above, in some embodiments, the system uses a neural network to generate a plurality of candidate output sequences, i.e., one or more additional candidate output sequences in addition to the first candidate output sequence.
For each of a set of one or more output sequence criteria, the system processes an input sequence including (i) a first candidate output sequence followed by (ii) one or more tokens specifying the output sequence criteria using an autoregressive language model neural network to generate a respective score for each token in the vocabulary (step 306). When the request also specifies a conditional action (conditioning) sequence, the input sequence also includes the conditional action sequence.
For each output sequence criterion, the system determines a respective ranking score for the first candidate output sequence based on the respective scores of the tokens in the corresponding true subset of the vocabulary of tokens, the ranking score representing the extent to which the first candidate output sequence generated by the autoregressive language model neural network meets the output sequence criterion (step 308).
The scores may be generated in parallel, for example, by processing a plurality of input sequences using a plurality of copies of the autoregressive language model neural network, each input sequence of the plurality of input sequences including (i) a first candidate output sequence followed by (ii) one or more tokens specifying respective output sequence criteria for the score. Such parallelization may allow for a more rapid determination of the rating score, thereby allowing for a more rapid provision of an output based on the candidate output sequence.
When additional candidate output sequences have been generated, the system also performs steps 306 and 308 to generate a respective rating score for each additional candidate output sequence.
The system then determines whether to provide the first candidate output sequence in response to the request using the respective rating scores for the first candidate output sequence for the one or more output sequence criteria (step 310). For example, the system can make this determination as described above with reference to fig. 1.
Fig. 4 is a diagram of another example of a criteria evaluation system 130.
In the example of fig. 4, the criterion evaluation system 130 includes a classifier 460, the classifier 460 generating a respective rating score 140 for each of one or more criteria.
Specifically, as shown in fig. 2, the language model neural network 110 includes a first sub-network 430 and an output sub-network 450.
The first sub-network 430 is configured to process an input sequence comprising a plurality of input tokens to generate a respective hidden state 440 for each input token.
The output sub-network 450 is configured to process respective hidden states of input tokens at locations immediately preceding a particular location to generate a respective score for each token in the vocabulary of tokens, and to use the respective score to select one of the tokens in the vocabulary as a token at the particular location in the first candidate output sequence.
For example, as described above, the neural network 110 can be a Transformer-based neural network that includes a plurality of attention blocks that each apply a self-attention mechanism. More specifically, in this example, the Transformer-based neural network includes a sequence of attention blocks, and during processing of a given input sequence, each attention block in the sequence receives a respective input hidden state for each input word in the given input sequence, and updates each hidden state at least in part by applying self-attention to generate a respective output hidden state for each input word. The input hidden state of the first attention block is an embedding of the input word and the input hidden state of each subsequent attention block is an output hidden state generated by a previous attention block.
In this example, the attention block is part of the first subnetwork 410, and the hidden state 440 is the output hidden state generated by the last attention block in the sequence.
The output subnetwork 450 can include, for example, one or more fully connected layers that process the hidden state 440 of the last input token in the input sequence to generate a respective score for each token in the vocabulary of tokens. As a particular example, the output subnetwork 450 can include one or more linear neural network layers followed by a softmax output layer.
In the example of fig. 4, to generate the rating score 140, the system 130 processes the input sequence 420 using the first subnetwork 430 to generate a respective hidden state 440 for each input in the input sequence 420.
Specifically, the input sequence 420 includes a plurality of input tokens including all tokens at all positions in the candidate output sequence 120. That is, the input sequence 420 includes the entire candidate output sequence 120. When the system 100 also receives the context sequence 102, the input lemma also includes lemmas from the context sequence 102.
For example, the input sequence 420 can be of the form:
<context><sentinel><response>、
where "context" represents the context sequence 102, "sensor" represents a predetermined sequence of lemmas that indicates to the neural network 110 that a response to the context sequence 102 should be generated, and "response" is the candidate output sequence 120.
For many autoregressive neural networks 110 that generate variable length output sequences, a given output sequence is terminated when a predetermined end-of-sequence word is selected at a given time step. That is, once the end-of-sequence lemma is selected, the system 100 determines the output sequence as lemmas at time steps prior to a given time step during the generation of the output sequence. In these embodiments, the system 130 need not perform any additional processing to generate hidden states for the input sequence 410, i.e., because the input sequence 410 has been processed to select end-of-sequence lemmas that end the generation of the candidate output sequence 120.
The system 130 then uses the classifier 460 to process one or more of the hidden states 440 to generate a respective rating score 140 for each of the one or more criteria. For example, the one or more hidden states 440 processed by the classifier 460 can be respective hidden states generated by the first subnetwork for the lemma at the last position in the first candidate output sequence. As another example, the one or more hidden states 440 processed by the classifier 460 can be respective hidden states generated by the first subnetwork 430 for a finger-hit input word at a finger-hit location in the input word (e.g., a first input word in the input sequence). As yet another example, the one or more hidden states 440 can include all hidden states 440, and the classifier 460 can be configured to average the hidden states 440.
Classifier 460 is a neural network that includes one or more classifier layers and is configured to process one or more hidden states using the one or more classifier layers to generate a respective rating score 140 for each of one or more criteria. For example, the classifier layer can include one or more fully connected layers, with the last layer having a respective node, e.g., a logistic regression or sigmoid node, corresponding to each criterion, with each node configured to generate a respective rating score 140 for the corresponding criterion.
Thus, in the example of fig. 4, the system 130 is able to generate scores for all criteria by processing hidden states (which have been generated as part of generating candidate output sequences) using a small, computationally efficient classifier 460.
Before using the classifier 460 to generate the rating score and after the neural network 110 is pre-trained, the system 130 or another training system trains the classifier 460 so that the classifier 460 accurately generates the rating score, i.e., by repeatedly performing training steps on multiple batches of training samples in the training dataset.
To perform the training step, the system (i.e., system 130 or another training system) obtains a batch of one or more training samples. For example, the system 130 can sample the batch from a larger set of training samples for the fine training process.
For each training sample in the batch, the system processes one or more of the respective hidden states generated by the first subnetwork to generate a respective rating score for each output sequence criterion by processing an input comprising a plurality of input tokens including all tokens at all positions in a training output sequence in the training sample using one or more classifier layers.
The system then trains one or more classifier layers to minimize a loss function that measures, for each training sample in the batch, an error between (i) a respective rating score generated for the training sample and (ii) a respective true value rating score for the training sample.
In particular, the system is able to calculate the gradient of the loss function with respect to the parameters of the classifier layer. The system can then update the parameters of the classifier layer by applying the optimizer to the calculated gradient to generate an update, which is then added to or subtracted from the current value of the parameter.
The system is able to perform this training in a computationally efficient manner because the classifier 460 has relatively few parameters, i.e., relative to the neural network 110, and the system keeps the input subnetworks frozen during the training of the classifier 460.
As described above, after training of the classifier 460 has been performed, the system 130 or another training system can also use the classifier 460 to generate a filtered training data set for further fine-tuning the neural network 110.
FIG. 5 is a flow chart of another example process 500 for evaluating candidate output sequences. For convenience, process 500 will be described as being performed by a system of one or more computers located in one or more locations. For example, a neural network system (e.g., the neural network system 100 depicted in fig. 1) appropriately programmed according to the present description can perform the process 500.
The system receives a request for an output sequence (step 502). In some implementations, the request includes a context sequence, and the request is for a response to the context sequence.
The system generates a first candidate output sequence comprising a plurality of tokens, each of the plurality of tokens selected from a vocabulary of tokens using an autoregressive language model neural network (step 504).
As described above, the language model neural network includes a first sub-network and an output sub-network.
The first subnetwork is configured to: at each particular position in the plurality of positions in the candidate output sequence, processing an input comprising a plurality of input tokens to generate a respective hidden state for each input token in the input token, the input token comprising a token at each position preceding the particular position in the candidate output sequence and optionally comprising a token in the context sequence.
The output subnetwork is configured to: at each particular location of the plurality of locations, processing a respective hidden state of the input vocabulary element at a location immediately preceding the particular location to generate a respective score for each vocabulary element in the vocabulary of vocabulary elements; and selecting one of the tokens in the vocabulary as a token at a particular position in the first candidate output sequence using the respective score.
As described above, in some embodiments, the system uses a neural network to generate a plurality of candidate output sequences, i.e., one or more additional candidate output sequences in addition to the first candidate output sequence.
The system processes one or more of the respective hidden states generated by the first sub-network by processing inputs including all tokens at all locations in the first candidate output sequence using one or more classifier layers to generate a respective rating score for each criterion of the one or more sets of criteria (step 506).
When additional candidate output sequences have been generated, the system also performs step 506 to generate a respective rating score for each of the additional candidate output sequences.
The system then uses the respective rating scores for the first candidate output sequences for the one or more output sequence criteria to determine whether to provide the first candidate output sequences in response to the request (step 508). For example, the system can make this determination as described above with reference to fig. 1.
As used herein, an "embedding" is a vector of values (e.g., floating point or other types of values) having a predetermined dimension (e.g., having a predetermined number of values).
As described above, a self-attention block is a neural network layer that includes an attention mechanism that operates on a self-attention block input (or an input derived from a layer input) to generate a self-attention block output. The self-attention mechanism may be causally masked such that any given position in the input sequence is not noticeable (e.g., using data from) for any position following the given position in the input sequence. There are many different possible attention mechanisms. Some examples of self-attention layers including an attention mechanism are described in the following: vaswani et al, "Attention is all you need (attention is you needed)", 31st Conference on Neural Information Processing Systems (NIPS 2017), long beacons, calif., USA; colin Raffel, noam Shazer, adam Roberts, katherine Lee, shacan Narang, michael Matena, yanqi Zhou, wei Li, and Peter J Liu.Explorer the limits of transfer learning with a unified text-to-text transformers (restrictions on transfer learning are explored with unified text-to-text transformers). ArXiv preprint arXiv:1910.10683,2019; daniel Adifingana, minh-Thang Luong, david R.so, jamie Hall, noah Fiedel, romal Thopilan, zi Yang, apoorv Kulshreshtha, gaurav Nemada, YIFENG Lu and Quoc V.le.Towards a human-like open-domain chatbots (Mier open domain chat robot). CoRR, abs/2001.09977,2020; and Tom B Brown, benjamin Mann, nick Ryder, melanie Subbih, jared Kaplan, prafula Dharriwal, arvind Neelakantan, praav Skyam, girish Satry, amand Askell et al. Language models are few-shot leamers (language model is a pilot learner). ArXivpreprint arXiv:2005.14165,2020.
In general, the attention mechanism maps a set of query and key-value pairs to an output, where the query, key, and value are all vectors. The output is calculated as a weighted sum of values, where the weight assigned to each value is calculated by a compatibility function (e.g., dot product or scaled dot product) of the query with the corresponding key.
In general, the self-attention mechanism is configured to correlate different positions in the same sequence to determine as output a transformed version of the sequence. For example, the attention layer input may include a vector of each element of the input sequence. These vectors provide input to the self-attention mechanism and are used by the self-attention mechanism to determine a new representation of the same sequence of attention layer outputs, which similarly includes a vector for each element of the input sequence. The output of the self-attention mechanism may be used as an attention layer output or may be processed by one or more of a feed forward layer, a jump connection, or a normalization operation to provide an attention layer output.
In some implementations, the attention mechanism is configured to transform the query, which is for example, by matrix W Q Definition, key transformation, e.g. by matrix W K Definition, and value transformation, e.g. by matrix W V Each of the definitions is applied to an attention layer input as input data X to the attention layer to derive a query matrix q=xw comprising a respective query for each vector in the input sequence Q A key matrix xk=xw comprising a respective key for each vector in the input sequence K And a value matrix v=xw comprising the respective values of each vector in the input sequence V Which is used to determine a sequence of attentiveness for the output. For example, the attention mechanism may be a dot product attention mechanism applied by: each query vector is applied to each key vector to determine a respective weight for each value vector, and the value vectors are then combined using the respective weights to determine a self-attention layer output for each element of the input sequence. The self-attention layer output may be scaled by a scaling factor (e.g., by the square root of the dimensions of the query and key) to achieve scaled dot product attention. Thus, for example, the output of the attention mechanism may be determined asWhere d is the dimension of the key (and value) vector. In another embodiment, the attention mechanism includes an "additive attention" mechanism that uses a feed-forward network with hidden layers to calculate the compatibility function. The output of the attention mechanism may be further processed by one or more fully connected feed forward neural network layers.
The attention mechanism may implement multi-headed attention, i.e. a plurality of different attention mechanisms may be applied in parallel. The outputs of these can then be combined (e.g., concatenated) where the learned linear transformation is applied to reduce to the original dimension if necessary.
The term "configuration" in relation to systems and computer program components is used in this specification. For a system of one or more computers to be configured to perform particular operations or actions, the system has installed thereon software, firmware, hardware, or a combination thereof, which in operation causes the system to perform the operations or actions. One or more computer programs for being configured to perform a particular operation or action means that the one or more programs include instructions that, when executed by a data processing apparatus, cause the apparatus to perform the operation or action.
Embodiments of the subject matter and the functional operations described in this specification can be implemented in digital electronic circuitry, in tangibly embodied computer software or firmware, in computer hardware (including the structures disclosed in this specification and their structural equivalents), or in combinations of one or more of them. Embodiments of the subject matter described in this specification can be implemented as one or more computer programs, e.g., one or more modules of computer program instructions encoded on a tangible, non-transitory storage medium for execution by, or to control the operation of, data processing apparatus. The computer storage medium can be a machine-readable storage device, a machine-readable storage substrate, a random access memory device, or a combination of one or more of them. Alternatively or additionally, the program instructions can be encoded on a manually generated propagated signal (e.g., a machine-generated electrical, optical, or electromagnetic signal) that is generated to encode information for transmission to suitable receiver apparatus for execution by data processing apparatus.
The term "data processing apparatus" refers to data processing hardware and encompasses all types of apparatus, devices, and machines for processing data, including by way of example a programmable processor, a computer, or multiple processors or computers. The apparatus can also be or further comprise a dedicated logic circuit, such as an FPGA (field programmable gate array) or an ASIC (application specific integrated circuit). In addition to hardware, the apparatus can optionally include code that creates an execution environment for the computer program, such as code that constitutes processor firmware, a protocol stack, a database management system, an operating system, or a combination of one or more of them.
A computer program, which may also be referred to or described as a program, software application, app, module, software module, script, or code, can be written in any form of programming language, including compiled or interpreted languages, or declarative or procedural languages; and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, or other unit suitable for use in a computing environment. A program may, but need not, correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data, such as one or more scripts stored in a markup language document, in a single file dedicated to the program in question, or in multiple coordinated files, such as files that store one or more modules, sub-programs, or portions of code. A computer program can be deployed to be executed on one computer or on multiple computers at one site or distributed across multiple sites and interconnected by a data communication network.
In this specification, the term "database" is used broadly to refer to any collection of data: the data need not be structured in any particular way, or structured at all, and it can be stored on a storage device in one or more locations. Thus, for example, an index database can include multiple data sets, each of which can be organized and accessed differently.
Similarly, in this specification, the term "engine" is used broadly to refer to a software-based system, subsystem, or process that is programmed to perform one or more particular functions. Typically, the engine will be implemented as one or more software modules or components installed on one or more computers in one or more locations. In some cases, one or more computers will be dedicated to a particular engine; in other cases, multiple engines can be installed and run on the same computer or multiple computers.
The processes and logic flows described in this specification can be performed by one or more programmable computers executing one or more computer programs to perform functions by operating on input data and generating output. The processes and logic flows can also be performed by, or combination of, special purpose logic circuitry (e.g., an FPGA or ASIC) and one or more programmed computers.
A computer suitable for executing a computer program can be based on a general-purpose or special-purpose microprocessor or both, or any other kind of central processing unit. Typically, a central processing unit will receive instructions and data from a read only memory or a random access memory or both. The essential elements of a computer are a central processing unit for executing or carrying out the instructions and one or more memory devices for storing instructions and data. The central processing unit and the memory can be supplemented by, or incorporated in, special purpose logic circuitry. Typically, a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks. However, the computer need not have such a device. In addition, the computer can be embedded in another device, such as a mobile phone, a Personal Digital Assistant (PDA), a mobile audio or video player, a game console, a Global Positioning System (GPS) receiver, or a portable storage device, such as a Universal Serial Bus (USB) flash drive, to name a few.
Computer readable media suitable for storing computer program instructions and data include all forms of non-volatile memory, media and memory devices, including by way of example semiconductor memory devices, e.g., EPROM, EEPROM, and flash memory devices; magnetic disks, such as internal hard disks or removable disks; magneto-optical disk; CD ROM and DVD-ROM discs.
To provide for interaction with a user, embodiments of the subject matter described in this specification can be implemented on a computer having a display device, e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor, for displaying information to the user and a keyboard and a pointing device, e.g., a mouse or a trackball, by which the user can provide input to the computer. Other types of devices can also be used to provide interaction with a user; for example, feedback provided to the user can be any form of sensory feedback, such as visual feedback, auditory feedback, or tactile feedback; and can receive input from a user in any form, including acoustic, speech, or tactile input. In addition, the computer is able to interact with the user by sending and receiving documents to and from a device used by the user; for example, by sending a web page to a web browser on a user device in response to a request received from the web browser. Further, the computer can interact with the user by sending a text message or other form of message to a personal device (e.g., a smart phone that is running a messaging application) and returning a response message from the user.
The data processing means for implementing the machine learning model can also comprise, for example, dedicated hardware accelerator units for handling public and computationally intensive parts of machine learning training or production, such as reasoning, workload.
The machine learning model can be implemented and deployed using a machine learning framework (e.g., a TensorFlow framework).
Embodiments of the subject matter described in this specification can be implemented in a computing system that includes a back-end component, e.g., as a data server, or that includes a middleware component, e.g., an application server, or that includes a front-end component, e.g., an application through which a client computer, web browser, or user having a graphical user interface can interact with an implementation of the subject matter described in this specification, or any combination of one or more such back-end, middleware, or front-end components. The components of the system can be interconnected by any form or medium of digital data communication (e.g., a communication network). Examples of communication networks include a Local Area Network (LAN) and a Wide Area Network (WAN), such as the internet.
The computing system can include clients and servers. The client and server are typically remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other. In some embodiments, the server transmits data, such as HTML pages, to the user device, for example, for the purpose of displaying data to and receiving user input from a user interacting with the device acting as a client. Data generated at the user device, such as the results of a user interaction, can be received at the server from the device.
While this specification contains many specifics, these should not be construed as limitations on the scope of any invention or of what may be claimed, but rather as descriptions of features specific to particular embodiments of particular inventions. Certain features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely, various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable subcombination. Furthermore, although features may be described above as acting in certain combinations and even initially claimed as such, one or more features from a claimed combination can in some cases be excised from the combination, and the claimed combination may be directed to a subcombination or variation of a subcombination.
Similarly, although operations are illustrated in the accompanying drawings and described in the claims in a particular order, this should not be construed as requiring that such operations be performed in the particular order shown or in sequential order, or that all illustrated operations be performed, to achieve desirable results. In some cases, multitasking and parallel processing may be advantageous. Moreover, the separation of various system modules and components in the embodiments described above should not be understood as requiring such separation in all embodiments, and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.
Specific embodiments of the subject matter have been described. Other embodiments are within the scope of the following claims. For example, the actions recited in the claims can be performed in a different order and still achieve desirable results. As one example, the processes depicted in the accompanying drawings do not necessarily require the particular order shown, or sequential order, to achieve desirable results. In some cases, multitasking and parallel processing may be advantageous.
Claims (23)
1. A method performed by one or more computers, the method comprising:
receiving a request for an output sequence;
generating a first candidate output sequence using an autoregressive language model neural network, wherein the first candidate output sequence includes a plurality of tokens, each of the plurality of tokens being selected from a vocabulary of tokens;
for each output sequence criterion in the set of one or more output sequence criteria:
processing an input sequence including, using the autoregressive language model neural network, to generate a respective score for each of the tokens in the vocabulary: (i) The first candidate output sequence is followed by (ii) one or more tokens specifying the output sequence criteria;
Determining respective ranking scores of the first candidate output sequences from respective scores of tokens in respective true subsets of the vocabulary of tokens, the respective ranking scores representing a degree to which the first candidate output sequences generated by the autoregressive language model neural network meet the output sequence criteria; and
the first candidate output sequence is provided in response to the request using a respective rating score for the first candidate output sequence for the one or more output sequence criteria.
2. The method of claim 1, wherein the request is for an output sequence subsequent to a context sequence, wherein generating the first candidate output text sequence comprises: the autoregressive language model neural network is conditioned on an input comprising the context sequence, and wherein the input sequence comprising (i) the first candidate output sequence followed by (ii) one or more primitives specifying the output sequence criteria further comprises the context sequence.
3. The method of claim 1 or claim 2, further comprising:
generating one or more additional candidate output sequences using the autoregressive language model neural network;
For each additional candidate output sequence:
for each output sequence criterion in the set of one or more output sequence criteria:
processing an input sequence including the following using the autoregressive language model neural network to generate a respective score for each of the tokens in the vocabulary: (i) The additional candidate output sequence is followed by (ii) the one or more tokens specifying the output sequence criterion;
determining respective rating scores from respective scores of the tokens in respective subsets of the vocabulary of tokens, the respective rating scores representing a degree to which the additional candidate output sequence generated by the autoregressive language model neural network meets the output sequence criterion; and
wherein providing the first candidate output sequence in response to the request using the respective rating scores for the one or more output sequence criteria comprises:
a sequence to be provided in response to the request is selected from the first candidate output sequence and the one or more additional candidate output sequences using respective rank scores of the first candidate output sequence and the one or more additional candidate output sequences.
4. The method of claim 3, wherein selecting a sequence from the first candidate output sequence and the one or more additional candidate output sequences to be provided in response to the request using respective rank scores of the first candidate output sequence and the one or more additional candidate output sequences comprises:
for each of the candidate output sequences, generating a respective quality score from a respective rating score for that candidate output sequence for each of one or more of the output sequence criteria in the set; and
the candidate output sequence with the highest corresponding quality score is selected as the sequence to be provided in response to the request.
5. The method of any preceding claim, wherein providing the first candidate output sequence in response to the request using the respective rating scores of the one or more output sequence criteria comprises:
determining whether a respective quality score of the first candidate output sequence for a first output criterion in the set meets a threshold; and
when the respective quality scores of the first candidate output sequences for the first output criteria in the set do not meet the threshold, determining that the first candidate output sequences are not provided in response to the request.
6. A method of training an autoregressive language model neural network according to any preceding claim, the method comprising:
obtaining a batch of one or more training samples, each training sample comprising:
a training input sequence, the training input sequence comprising: (i) Training an output sequence followed by (ii) one or more tokens specifying particular output sequence criteria of the set of output sequence criteria, an
A true value rating score for a corresponding output sequence criterion, the true value rating score representing a degree to which the training output sequence meets the particular output sequence criterion;
for each training sample in the batch:
processing a training input sequence in the training sample by using the autoregressive language model neural network to generate a corresponding score for each word element in the vocabulary; and
training the autoregressive language model neural network to minimize a loss function that measures, for each training sample in the batch, an error between (i) a respective score of a word element in the vocabulary generated for that training sample and (ii) a set of true values of scores of the word elements in the vocabulary that would produce a true value ranking score for that training sample.
7. The method of claim 6, wherein training the autoregressive language model neural network to minimize a loss function comprises:
only the loss is applied to the error and not to any earlier positions in the training input sequence.
8. The method of claim 6 or claim 7, further comprising: the autoregressive language model neural network is trained on language modeling tasks that require predicting a next word in a sequence of words given a previous word in the sequence of words before the autoregressive language model neural network is trained to minimize a loss function.
9. A method performed by one or more computers, the method comprising:
receiving a request for an output sequence;
generating a first candidate output sequence using an autoregressive language model neural network, wherein the first candidate output sequence includes a respective word element at each of a plurality of locations, and wherein the language model neural network comprises:
a first subnetwork configured to, at each particular location of the plurality of locations:
Processing an input comprising a plurality of input tokens to generate a respective hidden state for each of the input tokens, the input tokens comprising a token at each position preceding the particular position in the first candidate output sequence; and
an output sub-network configured to, at each particular location of the plurality of locations:
processing the respective hidden states of the input tokens at a position immediately preceding the particular position to generate a respective score for each token in the vocabulary of tokens; and is also provided with
Selecting one of the tokens in the vocabulary as a token at the particular position in the first candidate output sequence using the respective score;
processing, using one or more classifier layers, one or more of the respective hidden states to generate, for each of a set of one or more output sequence criteria, a respective rating score, the respective hidden states generated by the first subnetwork by processing an input comprising a plurality of input tokens, the plurality of input tokens comprising all tokens at all positions in the first candidate output sequence, the respective rating score representing a degree to which the first candidate output sequence generated by the autoregressive language model neural network meets the output sequence criteria; and
The first candidate output sequence is provided in response to the request using a respective rating score for the first candidate output sequence for the one or more output sequence criteria.
10. The method of claim 9, wherein the request is for an output sequence subsequent to a context sequence, wherein generating the first candidate output text sequence comprises: the autoregressive language model neural network is conditioned on an input comprising the sequence of contexts, and wherein for each particular location, the input lemma further comprises a lemma from the sequence of contexts.
11. The method of claim 9 or claim 10, further comprising:
generating one or more additional candidate output sequences using the autoregressive language model neural network;
for each additional candidate output sequence, generating a respective rating score for each output sequence criterion in the set of one or more output sequence criteria, the respective rating score representing a degree to which the additional candidate output sequence generated by the autoregressive language model neural network meets the output sequence criterion; and is also provided with
Wherein providing the first candidate output sequence in response to the request using the respective rating scores of the one or more output sequence criteria comprises:
A sequence to be provided in response to the request is selected from the first candidate output sequence and the one or more additional candidate output sequences using respective ranking scores of the first candidate output sequence and the one or more additional candidate output sequences.
12. The method of claim 11, wherein selecting a sequence from the first candidate output sequence and the one or more additional candidate output sequences to be provided in response to the request using respective ranking scores of the first candidate output sequence and the one or more additional candidate output sequences comprises:
for each of the candidate output sequences, generating a respective quality score from a respective rating score for that candidate output sequence for each of one or more of the output sequence criteria in the set; and
the candidate output sequence with the highest corresponding quality score is selected as the sequence to be provided in response to the request.
13. The method of any of claims 9-12, wherein providing the first candidate output sequence in response to the request using the respective rating scores of the one or more output sequence criteria comprises:
Determining whether a respective quality score of the first candidate output sequence for a first output criterion in the set meets a threshold; and
when the respective quality scores of the first candidate output sequences for the first output criteria in the set do not meet the threshold, determining that the first candidate output sequences are not provided in response to the request.
14. The method of any of claims 9-13, wherein processing one or more of the respective hidden states generated by the first sub-network by processing an input comprising a plurality of input tokens including all tokens at all positions in the first candidate output sequence comprises:
a respective hidden state generated by the first sub-network for a token at a last position in the first candidate output sequence is processed.
15. The method of any of claims 9-14, wherein processing one or more of the respective hidden states generated by the first sub-network by processing an input comprising a plurality of input tokens including all tokens at all positions in the first candidate output sequence comprises:
Processing respective hidden states generated by the first sub-network for a finger-hit input token at a finger-hit location in the input token.
16. The method of any of claims 9-15, further comprising, during generation of the first candidate output sequence, for one or more specified positions before a last position in the first candidate output sequence:
processing, using the one or more classifier layers, one or more of the respective hidden states generated by the first sub-network at the specified location in the first candidate output sequence to generate a respective rating score for each output sequence criterion in a set of one or more output sequence criteria, the respective rating score representing a degree to which a portion of the first candidate output sequence that has been generated since the specified location meets the output sequence criterion;
based on the respective rating scores of the output sequence criteria in the set generated at the specified location, it is determined whether to (i) continue to generate the first candidate output sequence after the specified location or (ii) not provide any portion of the first candidate output sequence in response to the request.
17. A method of training the autoregressive language model neural network of any one of claims 9-16, the method comprising:
obtaining a batch of one or more training samples, each training sample comprising:
training output sequences
A respective true value rating score for each of one or more of the output sequence criteria, the respective true value rating score representing a degree to which the training output sequence meets a particular output sequence criterion;
for each training sample in the batch:
processing, using the one or more classifier layers, one or more of the respective hidden states generated by the first subnetwork by processing inputs of a plurality of input tokens including all tokens at all positions in a training output sequence in the training sample, to generate a respective rating score for each output sequence criterion; and
the one or more classifier layers are trained to minimize a loss function that measures, for each training sample in the batch, an error between (i) a respective rating score generated for the training sample and (ii) a respective true value rating score for the training sample.
18. The method of claim 17, wherein training the one or more classifier layers to minimize a loss function comprises:
the input subnetwork is kept frozen during training of the one or more classifier layers.
19. The method of claim 17 or claim 18, further comprising: the autoregressive language model neural network is trained on a language modeling task that requires predicting a next token in a sequence of tokens given a previous token in the sequence of tokens, prior to training the one or more classifier layers.
20. A method according to any preceding claim, wherein the output sequence is a text sequence and the vocabulary of tokens comprises a plurality of text tokens.
21. The method of claim 20, when dependent on claim 2 or claim 10, wherein the context sequence is a text sequence.
22. A system, comprising:
one or more computers; and
one or more storage devices storing instructions that, when executed by the one or more computers, cause the one or more computers to perform the respective operations of any one of claims 1-21.
23. One or more computer-readable storage media storing instructions that, when executed by one or more computers, cause the one or more computers to perform the respective operations of the method of any one of claims 1-21.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US202163226748P | 2021-07-28 | 2021-07-28 | |
US63/226,748 | 2021-07-28 | ||
PCT/US2022/038742 WO2023009766A1 (en) | 2021-07-28 | 2022-07-28 | Evaluating output sequences using an auto-regressive language model neural network |
Publications (1)
Publication Number | Publication Date |
---|---|
CN117795527A true CN117795527A (en) | 2024-03-29 |
Family
ID=85039180
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202280052514.4A Pending CN117795527A (en) | 2021-07-28 | 2022-07-28 | Evaluation of output sequences using autoregressive language model neural networks |
Country Status (5)
Country | Link |
---|---|
US (1) | US20230029590A1 (en) |
KR (1) | KR20240034804A (en) |
CN (1) | CN117795527A (en) |
GB (1) | GB2622755A (en) |
WO (1) | WO2023009766A1 (en) |
Families Citing this family (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN117178274A (en) * | 2021-05-21 | 2023-12-05 | 谷歌有限责任公司 | Machine-learning language model that generates intermediate text analysis to serve contextual text generation |
Family Cites Families (10)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US8521672B2 (en) * | 2010-11-22 | 2013-08-27 | Microsoft Corporation | Dependency-based query expansion alteration candidate scoring |
DE202017106532U1 (en) * | 2016-10-28 | 2018-02-05 | Google Llc | Search for a neural architecture |
US11625572B2 (en) * | 2017-05-03 | 2023-04-11 | Google Llc | Recurrent neural networks for online sequence generation |
US11797839B2 (en) * | 2017-10-27 | 2023-10-24 | Google Llc | Training neural networks using priority queues |
WO2019219968A1 (en) * | 2018-05-18 | 2019-11-21 | Deepmind Technologies Limited | Visual speech recognition by phoneme prediction |
CN111727442A (en) * | 2018-05-23 | 2020-09-29 | 谷歌有限责任公司 | Training sequence generation neural network using quality scores |
US10831990B1 (en) * | 2019-05-09 | 2020-11-10 | International Business Machines Corporation | Debiasing textual data while preserving information |
KR20210059367A (en) * | 2019-11-15 | 2021-05-25 | 삼성전자주식회사 | Voice input processing method and electronic device supporting the same |
US11487522B1 (en) * | 2020-06-26 | 2022-11-01 | X Development Llc | Training and/or using neural network model to generate target source code from lower-level representation |
US20220138559A1 (en) * | 2020-11-05 | 2022-05-05 | International Business Machines Corporation | Answer span correction |
-
2022
- 2022-07-28 WO PCT/US2022/038742 patent/WO2023009766A1/en active Application Filing
- 2022-07-28 GB GB2400855.9A patent/GB2622755A/en active Pending
- 2022-07-28 CN CN202280052514.4A patent/CN117795527A/en active Pending
- 2022-07-28 US US17/876,451 patent/US20230029590A1/en active Pending
- 2022-07-28 KR KR1020247004967A patent/KR20240034804A/en unknown
Also Published As
Publication number | Publication date |
---|---|
US20230029590A1 (en) | 2023-02-02 |
WO2023009766A1 (en) | 2023-02-02 |
KR20240034804A (en) | 2024-03-14 |
GB202400855D0 (en) | 2024-03-06 |
GB2622755A (en) | 2024-03-27 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US11669744B2 (en) | Regularized neural network architecture search | |
US11544573B2 (en) | Projection neural networks | |
US11544536B2 (en) | Hybrid neural architecture search | |
CN110520871B (en) | Training machine learning models using learning progress measurements | |
KR102170199B1 (en) | Classify input examples using comparison sets | |
US20240127058A1 (en) | Training neural networks using priority queues | |
WO2019157251A1 (en) | Neural network compression | |
WO2020140073A1 (en) | Neural architecture search through a graph search space | |
CN110402445B (en) | Method and system for browsing sequence data using recurrent neural network | |
US20230049747A1 (en) | Training machine learning models using teacher annealing | |
CN109313540B (en) | Two-stage training of spoken language dialog systems | |
WO2018211143A1 (en) | Neural network system | |
CN111989696A (en) | Neural network for scalable continuous learning in domains with sequential learning tasks | |
EP3602419A1 (en) | Neural network optimizer search | |
CN110235149B (en) | Neural plot control | |
US20220383119A1 (en) | Granular neural network architecture search over low-level primitives | |
Xue et al. | Hypro: A hybridly normalized probabilistic model for long-horizon prediction of event sequences | |
CN117795527A (en) | Evaluation of output sequences using autoregressive language model neural networks | |
US20230107409A1 (en) | Ensembling mixture-of-experts neural networks | |
WO2021159099A9 (en) | Searching for normalization-activation layer architectures | |
JP2024519265A (en) | Neural network with feedforward spatial transformation units | |
IE20180149A1 (en) | Projection neural networks |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination |