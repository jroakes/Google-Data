US9547711B1 - Shard data based on associated social relationship - Google Patents
Shard data based on associated social relationship Download PDFInfo
- Publication number
- US9547711B1 US9547711B1 US13/948,130 US201313948130A US9547711B1 US 9547711 B1 US9547711 B1 US 9547711B1 US 201313948130 A US201313948130 A US 201313948130A US 9547711 B1 US9547711 B1 US 9547711B1
- Authority
- US
- United States
- Prior art keywords
- content
- job
- types
- type
- processing
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Expired - Fee Related, expires
Links
Images
Classifications
-
- G06F17/30598—
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/28—Databases characterised by their database models, e.g. relational or object models
- G06F16/284—Relational databases
- G06F16/285—Clustering or classification
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/30—Information retrieval; Database structures therefor; File system structures therefor of unstructured textual data
- G06F16/35—Clustering; Classification
- G06F16/355—Class or cluster creation or modification
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/95—Retrieval from the web
- G06F16/951—Indexing; Web crawling techniques
-
- G06F17/3071—
-
- G06F17/30864—
Definitions
- the present disclosure relates to methods, systems and computer programs for sharding user data.
- Embodiments of the present disclosure define methods for sharding and distributing data obtained from a plurality of users of a social network so that such data can be accessed in a fast and efficient manner. It should be appreciated that the present disclosure can be implemented in numerous ways, e.g., a process, an apparatus, a system, or a method on a computer readable medium. Several embodiments of the present disclosure are described below.
- a method includes the following method operations: identifying a plurality of content types of content in the database of the social network, wherein members of the social network produce and request content from the database; identifying job types to be performed on each content type when requests from members of the social network are received; selecting a sharding process to use for each content type based on the job types to be performed on the content types; sharding the database into a first group of shards for content types having job types that are parallel processing efficient and into a second group of shards for content types that are linear processing efficient, the first and second group of shards define a multi-shard database; and servicing requests for content from the multi-shard database such that requests for content requiring parallel processing efficiency are provided data from the first group of shards and requests for content requiring linear processing efficiency are provided data from the second group of shards.
- the job type to be performed on a content type is selected from a plurality of possible job types that may operate on the content type.
- the selected job type for the content type has a statistical occurrence rate that is higher than the other job types within the plurality of job types.
- the job types to be performed on a content type is identified based on job processing characteristics associated with the job type.
- a set of pre-determined rules associate the processing characteristics of the job type to a sharding type.
- the first group of shards for job types that are parallel processing efficient are dispersed across a distributed network of processing machines.
- servicing the requests for content distributed across a network of processing machines includes engaging resources of select ones of the processing machines to process relevant content in parallel, wherein the requests include storage or retrieval of relevant content from the multi-shard database dispersed on the processing machines.
- the second group of shards for job types that are linear processing efficient are dispersed within a close cluster of processing machines that are situated in close processing proximity to one another.
- the dispersal of the second group of shards includes co-locating the shards in each processing machines of the close cluster.
- performance efficiency of each job type on the multi-shard database are monitored.
- content for the job type that was sharded and processed in accordance with the first sharding type are copied from the multi-shard database and are re-sharded in accordance with the second sharding type.
- the re-sharded content is used for servicing the requests for the job type that is to be performed on the content type.
- the content within the multi-shard database for the job type are replaced with the re-sharded content.
- the re-sharded content is discarded after completing servicing requests for content of the job type. In such embodiments, the re-sharded content do not replace the content for the job type in the multi-shard database.
- the pre-defined threshold value is a time-based value or a computation-based value.
- a method includes monitoring performance efficiency of each job type in a multi-shard database of a social network.
- the multi-shard database includes a plurality of content types of content generated and requested by members of the social network wherein one or more job types are performed on each content type.
- Content that was sharded for the job type in accordance with a first sharding type are copied from the multi-shard database.
- the copied content for the job type is sharded and processed in accordance with a second sharding type. Requests for content for the job type are serviced using the content from the second sharding type.
- the re-sharded content for the job type are synchronized with the content in the multi-shard database.
- FIG. 1 illustrates a simplified social network of users or entities for implementing embodiments of the disclosure, in accordance with embodiments of the present disclosure.
- FIG. 2 illustrates a data sharding process flow implemented in accordance with an embodiment of the invention.
- FIG. 3 illustrates an exemplary sharding logic used in sharding content of the social network database, in accordance with one embodiment of the invention.
- FIG. 4 illustrates exemplary method operations used for processing data obtained from a plurality of users in a social network, in accordance with an embodiment of the invention.
- FIG. 5 illustrates method operations for processing content of a social network using appropriate sharding type, in accordance with an alternate embodiment of the invention.
- FIG. 6 illustrates a basic infrastructure of a computing device used in processing data obtained from a plurality of users in a social network, in one embodiment of the invention.
- the following embodiments describe methods, computer programs, and systems for implementing data sharding mechanism to efficiently shard content generated and shared by users and entities within a social network. Users and entities generate and share content of different content types within the social network.
- the sharding mechanism identifies job types that are to be performed on different content types, determines the processing characteristics of the job types, shards the content in the social network database and distributes the sharded content for storage in accordance to the processing characteristics associated with each job type.
- the sharding mechanism will determine the processing characteristics of the job type, identify the relevant content and process the relevant content using resources of a network of processing machines.
- the sharding mechanism will identify the relevant content based on the processing characteristics associated with the job type, and process the relevant content using resources of one or select few processing machines.
- the data shards related to parallel processing and data shards related to linear processing together define a multi-shard database.
- any request for content from users are serviced using the shard data from the multi-shard database that was distributed in accordance to parallel processing or linear processing efficiencies.
- Sharding and distributing content based on performance efficiency of job types makes efficient use of resources of the respective processing machines enabling fast and efficient servicing of requests for content.
- the content for the social network is sharded and the sharded content is distributed in accordance to the processing characteristics of the job types that will most likely be performed on content types associated with the content.
- a job type based on its processing characteristics, will predict or suggest the look-up pattern or processing that will likely be performed on the content types of content stored for the social network.
- content associated with each content type can be processed by more than one job types based on the usage of content within the social network.
- the sharding mechanism may identify the job-type that has a higher statistical rate of occurrence for the content type within the social network and use the processing characteristics of the identified job-type when distributing the relevant sharded data for the content type. For example, if content for a particular content type are to be operated on by job types that are suited for parallel processing as well as by job types that are suited for linear processing, then the processing characteristics of the select one of the job type that is used more frequently for the content type is used when distributing the relevant sharded content.
- the select one of the job type may be suited for either parallel processing or linear processing.
- Content for the job types that are suited for parallel processing are distributed on a network of processing machines and the resources of the appropriate processing machines are engaged, in parallel, to process the content shards in response to a request for content.
- This form of dispersing across multiple processing machines and engaging distributed processing will result in faster processing of content while efficiently balancing the network load and the processing resources of the processing machines.
- sharded content for the job types that are suited for linear processing are distributed within one or a small cluster of processing machines that are in close processing proximity to one another.
- the sharded content may be co-located within the one or more processing machines in the cluster. This form of dispersing will result in considerable reduction in the round trip latency as the related content are located in processing proximity to the processor and to one another within the one or small cluster of processing machines so that the content can be processed quickly using the resources of the relevant processing machines in the cluster.
- Other advantages will become apparent to one skilled in the art after viewing the various embodiments.
- FIG. 1 illustrates an exemplary social graph 105 of users and/or entities within a social network.
- the social graph is depicted by nodes and edges, wherein each node represents an individual, entity, group or community of users (collectively termed “members”) and the edge between any two nodes represents the relationship between the members represented by the nodes.
- the strength of the edges is reflective of the level of interaction between the members represented in the nodes.
- the strength of the edges can also depend on frequency and depth of interaction between two nodes.
- the level, frequency, depth of interactions and the relationship may depend on characteristics of the members associated with the nodes, such as age, gender, race, interest, affiliations (political, religious, business, etc.), occupation, education, economic status, type of service sought and/or provided, type of communication, etc.
- the members of the social network generate different types of interactions and different types of contents 110 .
- Some exemplary interaction types may include communicative interactions 110 - a , people-to-people interactions 110 - b , entity-to-entity interactions 110 - c , entity-to-people interactions 110 - c , posts 110 - d , etc.
- information generated and exchanged by members within the social network span different content types, such as information, news, photographs, literary works, publications, music, art, opinions, ratings, images, videos, etc.
- the content types may be of different data types, such as audio 212 - a , images 212 - b , videos 212 - c , texts or links 212 - d , data 212 - e , or any other form of digital asset.
- the type and level of interactions amongst members determines the type of job that needs to be performed on the different content types and how the content of different content types is to be sharded and stored so as to be able to optimize processing of the content.
- the data to be sharded may not be associated with social interactions. In such embodiments, the data may be sharded in relation to a member's social data.
- attributes about a member such as age, name, gender, etc.
- attributes about a member are not really generated by a member nor are they social.
- sharding and distribution encompasses data related to members, such as members' attributes and other metadata, as well as social interactions data.
- FIG. 2 illustrates a simplified block diagram identifying different modules of a sharding mechanism used for processing different content types of content generated within the social network.
- the members interaction within the social network 210 result in the generation and exchange of a vast amount of content of different content types 212 - a through 212 - n .
- the content of different content types 212 - a through 212 - n are stored in the content database and made available to members of the social network.
- a plurality of content types may be of a particular data type.
- Each of the content types may be processed by one or more job types depending on how the content related to the content types are used within the social network.
- a sharding logic 220 is used for sharding the content within the content database 222 of the social network 210 .
- the sharding logic 220 interacts with the one or more content databases 222 in which different content types of content for the social network are maintained to determine type of processing that needs to be done on each of the different content types.
- content related to different content types for each data type may be maintained in distinct content databases. For example, content of different content types related to textual or link data types may be maintained in one content database, content of different content types related to image data types may be maintained in a second content database and so on.
- the sharding logic (otherwise termed “sharding mechanism”) 220 will determine the job types that may operate on the different content types of content maintained in the content database.
- the sharding logic interacts with a job type data store 224 to determine the different job types that are contained therein.
- the sharding logic examines processing characteristics of each of the job types maintained within the job type data store 224 to determine the processing mode that is suited for the job type.
- the sharding logic then shards the content in the content database for the social network and categorizes the relevant sharded content associated with each job type.
- the sharding logic 220 may identify sharded content that are to be mostly operated by job types suited for linear processing efficiency and categorize the content under linear processing shard data 228 .
- the sharding logic 220 may identify the sharded content that are to be mostly operated by job types that are suited for parallel processing efficiency and categorize the content under parallel processing shard data 226 .
- the sharded content may be tagged to identify the content as either parallel processing shard data 226 or linear processing shard data 228 depending on the job type that is to be operating on the content. The tag may serve two purposes.
- the tag may be used to identify the processing mode that is to be engaged in order to determine how the content of different content types is to be distributed.
- the tag may also be used to identify relevant content distributed across one, select few or a network of processing machines, in order to identify and retrieve relevant content for a particular job type when the job type executes and requests content.
- the tag information may be maintained at a master server for the social network and referenced to identify the relevant content for a job type.
- the linear processing shard data 228 and the parallel processing shard data together form the multi-shard database 230 .
- the sharding logic then distributes the sharded content related to the various job types over one or a small cluster or a network of processing machines based on the associated tags so that processing of the sharded content can make efficient use of the network and processing resources of the respective processing machines.
- the sharding logic when more than one job type can be performed on content of a particular content type stored in the content database of the social network, the sharding logic will look at the historical association of the job types to the particular content type to statistically determine the rate of occurrence of each job type's association to the particular content type. The sharding logic will then select the job type with a higher statistical occurrence rate over other available job types, for performing on the select content type. In some embodiments, in addition to or instead of looking at the historical association of the job types to the content type, the sharding logic may determine the performance characteristics of the job type to determine which processing efficiency mode is more suited for the job type and update the processing characteristics of the job type to reflect the same.
- historical association of a particular job type to a content type may indicate that the particular job type for processing the relevant content for the content type, is associated with linear processing efficiency.
- the performance characteristics for the job type may indicate that the linear processing is not best suited for processing the relevant content for this job type as processing of relevant content using the linear processing mode was taking too long.
- the sharding logic may adjust the processing characteristics of the job type to relate to a different mode of processing.
- the job type may be associated with parallel processing mode for the content type.
- the historical association of the job type to particular processing mode may be described by a set of pre-determined rules.
- the pre-determined rules map the job type to appropriate processing mode based on the processing characteristics of the job type. Some of the processing characteristics used in the mapping may include frequency of sharing of a content type, type and extent of sharing, amount of computation required for retrieving and presenting content, etc.
- the sharding logic uses the mapping defined in the pre-determined rules to associate a particular job type to a corresponding processing mode. The sharding logic then determines the particular job type that is to be performed on a content type and distributes the relevant sharded content for the particular content type in accordance to the processing mode mapped to the particular job type.
- the mapping of the processing mode to the job type may or may not be optimal for the job type. When it is determined that the processing mode associated with a job type is not optimal, an alternate processing mode may be associated with the job type.
- the sharding logic monitors the performance efficiency of the job type over a pre-defined period of time or over a pre-defined number of content requests, to determine if the job type is performing at or above a desired efficiency level.
- the desired efficiency level may be defined by a pre-defined threshold value. If the job type is not performing at the desired efficiency level, the processing mode for storing the sharded content for the job type needs to be re-associated with a different processing mode or the level of sharding or processing mode may need to be fine tuned.
- the processing mode as used in this application, is defined as a manner of processing the contents during for storage/retrieval.
- the processing mode for storing/retrieving includes parallel processing or linear processing.
- the sharding logic may distribute the sharded content related to the job type to a network of processing machines.
- the monitoring of performance efficiency for a job type may be done periodically or intermittently. The frequency of monitoring may be driven by the need or demand for relevant content for a particular job type within the social network.
- the job type in the event the performance efficiency of a particular job type falls below the pre-defined threshold value, the job type may be switched to a different processing mode than the one that the job type is currently associated with so that the relevant content for the content type can be processed by the job type using the different processing mode.
- the pre-defined threshold value may be a time-based value, computation-based value, other metric-based value or a combination thereof.
- the sharding of content may be fine-tuned. This might be the case when a particular job type is associated with parallel processing mode yet the performance efficiency falls below the pre-defined threshold value.
- the sharding logic may identify the relevant sharded content for the job type and adjust the sharding so that the relevant sharded content may be further sharded.
- the additional sharding will allow the sharded content to be distributed to additional processing machines so that retrieval of the relevant content can be done in a fast and efficient manner using the processing resources of the additional processing machines on which the relevant content shards are stored.
- the processing mode for the job type may be adjusted.
- the pre-defined rules may be updated to reflect the changed processing mode. The monitoring and tuning of the job type may continue till an optimal level of performance for the job type has been reached.
- FIG. 3 illustrates an exemplary processing of content of different content types through sharding logic module, in one embodiment.
- the processing of content begins when a request for storing or saving content generated by members of the social network, is received.
- the content generated by the members of the social network is stored in the content database 222 .
- the sharding logic analyzes the content stored within the content database 222 to identify the different content types.
- the content types depend on information generated and exchanged between members and may include information, news, photographs, literary works, music, art, opinions, ratings, images, videos, etc.
- the content associated with the content types may be of different data types, such as audio, images, graphics, videos, texts or links, data, or any other form of digital asset that can be generated, rendered and shared by members of the social network.
- Each content type may be processed by one or more job types. Processing characteristics of each job type available within the job type data store 224 predict or suggest the look-up pattern or the type and amount of processing that is to be performed on the content of particular content types that is mapped to the job type.
- a set of pre-determined processing rules 225 defined for the social network may be used to associate each job type to one of the two processing modes available within the sharding logic 220 based on the processing characteristics associated with the job type. For instance, the predetermined rules may associate a job type whose processing characteristics require parallel processing efficiency to the parallel processing mode 220 - a and associate a job type whose processing characteristics require linear processing efficiency to the linear process mode 220 - b.
- the sharding logic will shard the content in the content database. Based on the mapping defined by the pre-determined rules 225 for the job types, the sharding logic will trigger either the parallel processing mode 220 - a or the linear processing mode 220 - b during the storing of the sharded content for content types that are associated with different job types. Thus, depending on which processing mode is associated with a job type, the sharding logic may identify the shards of the content for the relevant content types as parallel processing shard (PPS) content 226 or linear processing shard (LPS) content 228 and tag them accordingly. For example, the sharding logic may tag the PPS content 226 for dispersed processing and the LPS content 228 for co-location processing. The PPS content 226 and the LPS content 228 together define the multi-shard database 230 .
- PPS parallel processing shard
- LPS linear processing shard
- the sharding logic will use the tags to disperse the sharded content to one or more processing machines.
- the sharding logic also retains the details of location of each of the content shards distributed over the processing machines by maintaining a mapping of each of the content shards' tags and the location where the respective content shards are stored so that retrieval of relevant content may be effectuated in an efficient manner.
- the PPS content 226 may be dispersed across a network of processing machines 230 - a and the LPS content 228 on a single processing machine or across a small cluster of processing machines 230 - b that are located in processing proximity to one another and the distribution location of both PPS content and LPS content may be maintained in a tag database (not shown).
- the network of processing machines 230 - a on which PPS content are dispersed may include a few to several hundreds to several thousands of processing machines located within a specific geo location or distributed across any geo location.
- the network of processing machines 230 - a are not restricted to few, several hundreds or several thousands of processing machines but may include fewer or lot more processing machines, depending on the amount of PPS content to be dispersed for the job type.
- the tag database is referenced to identify relevant content of content type that the job type is to operate on and the relevant content is retrieved from the location identified in the tag database.
- Dispersing of data shards across a network of processing machines allows the job type, mapped to PPS processing mode, to utilize the resources of the processing machines, in parallel, to service the request for the relevant content making optimal use of the resources while efficiently balancing the processing load across multiple machines.
- the LPS content dispersed within the single or a small cluster of processing machines 230 - b may be co-located within the single processing machine, co-located within same storage rack of the single processing machine, co-located within processing machines maintained in a single data center, co-located within storage racks of the processing machines in the single data center or co-located in storage racks of processing machines maintained in closely located data centers.
- the manner in which the LPS content is dispersed allows the job type, mapped to LPS processing mode to utilize the resources of single or small number of processing machines within the cluster to service the request resulting in substantial reduction of roundtrip latency between controller of the processing machines and the content shards.
- any requests for storage or saving of content generated or exchanged by members of the social network are entertained at the social network database 222 .
- Any requests for reading or processing of content are serviced using the respective content shards from one of the two shard data, PPS data 226 or LPS data 228 , within the multi-shard database 230 based on the processing mode mapped to the job type that is used for performing on the requested content.
- the processing mode mapped to each job type is not fixed but can be switched.
- the decision to switch the processing mode mapped to a particular job type may be accomplished by monitoring the job performance and evaluating the performance efficiency of the job.
- the job performance may be monitored periodically, intermittently, based on a trigger event, or based on a request or feedback from one or more members of the social network.
- the performance efficiency may be evaluated as a function of time-based metric, computation-based metric, any other metrics that can affect servicing of requests for content, or combinations thereof.
- the sharding logic may make the decision to switch the processing mode for the job type to improve the processing efficiency.
- the sharding logic when the decision to switch the processing mode for the job type has been made, the sharding logic will copy the relevant content for the job type from the multi-shard database and re-distribute to the processing machines based on the switched processing mode.
- the sharding logic may re-shard or additionally shard the relevant content copied from the multi-shard database and re-distribute the re-sharded content to a network of processing machines. For example, when the particular job type for performing on relevant content is associated with linear processing mode but is more suited for parallel processing mode, the sharding logic may switch the processing mode to parallel processing mode to take advantage of parallel processing.
- the processing of relevant content for the job type is accomplished using resources of the multiple processing machines. If, on the other hand, the job type was already mapped to the PPS processing mode, then the sharding logic may further tune the processing mode to improve the performance efficiency for the job type. This may entail the sharding logic to re-shard or additionally shard the sharded content and use additional processing machines for storing. The requests for relevant content associated with the job type is serviced using the re-sharded content.
- the re-sharded content may be discarded without updating the multi-shard database.
- the original mapping of the processing mode to the job type within the pre-determined rules is maintained and is not updated.
- the processing mode mapped to the job type for distribution of sharded content within the pre-determined rules 225 is updated so that future processing of relevant content for the job type is based on the switched processing mode.
- the re-sharded content is not discarded but is re-tagged and dispersed in accordance to the new tag. The re-sharded content replaces the relevant content of the multi-shard database for the job type so that current and future requests for the relevant content will now be serviced using the tags of the re-sharded content from the multi-shard database.
- FIG. 4 illustrates method operations for providing effective sharding of content in a social network, in one embodiment of the invention.
- the method begins by identifying different content types associated with content in a database of the social network, as illustrated in operation 410 .
- the content is produced and requested by members of the social network.
- the members may be individuals, entities, communities, groups, etc., that generate, request and exchange content of different content types.
- Content characteristics define the type of content. Some exemplary content types defined by content characteristics may include informative communication, news, research, stories, blogs, problems, problem resolutions, quotes, statistics, etc.
- the content types may be of different data types including audio, video, text, links, graphics, photos, images, data, etc.
- a job type to be performed on each content type is identified, as illustrated in operation 420 .
- the job type includes job characteristics that determine the type of processing that is scheduled to be performed on specific content types.
- a processing mode is selected, as illustrated in operation 430 .
- the processing mode may be selected from one of two modes—parallel processing mode or linear processing mode.
- the content from the content database are sharded by a sharding logic.
- the sharded content for content types with job types that are suited for parallel processing may be processed using parallel processing mode into first group of shards and sharded content for content types with job types that are suited for linear processing may be processed using the linear processing mode into second group of shards, as illustrated in operation 440 .
- the data shards from the first group and the second group together form the multi-shard content database.
- the method concludes with the requests for content from members of the social network being serviced from the multi-shard content database, as illustrated in operation 450 .
- Any requests for content for job type that require parallel processing efficiency are provided content from the first group of shards using the resources of selects ones of a network of processing machines and requests for content for job type that require linear processing efficiency are provided content from the second group of shards using the resource of a processing machine or select ones of processing machines within a small cluster that are in processing proximity to one another.
- content of specific content types may be processed by more than one job type.
- the sharding logic will determine the statistical occurrence rate of each job type for the content type and/or processing efficiency of each job type to determine which job type to associate with the content of the specific content type.
- the relevant content from either the first group or the second group of shards is used to service the requests.
- FIG. 5 illustrates a method for providing content in a social network, in an alternate embodiment of the invention.
- the method begins at operation 510 wherein performance efficiency of each job type in a multi-shard database within a social network, is monitored.
- the multi-shard database includes content generated and exchanged by members within the social network that have already been sharded and processed using either a parallel processing mode or linear processing mode depending on the job types that are to be performed for the content types of the content.
- the multi-shard database includes a first group of shards that are suited for parallel processing efficiency and a second group of shards that are suited for linear processing efficiency.
- the performance of each job type are monitored and performance efficiency of each job type is evaluated.
- the performance efficiency is evaluated as a function of a time-based metric, a computation-based metric or may be evaluated using any other metric-based function or combinations thereof.
- the time-based metric for the job type may identify the amount of time taken for the job type to service or process the request for content in the multi-shard database.
- Computation-based metric may determine the level of computation required for the job type to service the request. Some job types may involve light computation while other job types may involve heavy or intense computation.
- the performance efficiency value of each job type for the particular content type is compared against a pre-defined threshold value, as illustrated in operation 520 .
- the relevant content that was processed for the job type is copied from the multi-shard database, as illustrated in operation 530 .
- the relevant content for the job type may have been originally processed in accordance with a first processing mode.
- the copied content is re-processed in accordance with a second processing mode that is different from the first processing mode, as illustrated in operation 540 . This might also entail additional sharding of the relevant content to generate re-sharded content.
- the re-processed and/or re-sharded content is used to service any relevant content requests for the job type.
- the re-processed and/or re-sharded content may replace the relevant content in the multi-shard database.
- the re-sharded content may be used to service the requests for content for the job type and discarded after servicing the request. Further monitoring may be done for each job type in the multi-shard database and depending on further evaluation of performance efficiency, the mapping of the job type to the processing mode may be updated so that future requests for content are serviced in a fast and efficient manner.
- the various embodiments described above provide an improved way of partitioning content based on predictive look-up patterns established for each job type.
- job types that require computationally intensive processing such as requests for content related to social groups
- engaging PPS processing mode to store relevant sharded content within the social network database will be more beneficial.
- the relevant sharded content are distributed across a network of processing machines spread across any geo location. Such distribution leads to optimal use of the resources of the select ones of the processing machines, in parallel, effective load-balancing and optimal use of network resources to service the requests for content.
- LPS processing mode For job types that require computationally light processing, such as requests for content to determine popularity of a person, electronic mail groups, etc., LPS processing mode will be more appropriate as the relevant sharded content related to the LPS job types are co-located within a processing machine or co-located within a small cluster of processing machines that are in close processing proximity to one another. Such distribution within close cluster of processing machines will result in reduced round-trip latency between processing machines' controllers and the relevant content shards as the relevant content shards are located in close processing proximity to one another.
- FIG. 6 is a simplified schematic diagram of a computer system for implementing embodiments of the present disclosure. It should be appreciated that the methods described herein may be performed with a digital processing system, which in some embodiments may be a general-purpose computer system. Special purpose computers, which are designed or programmed to perform only one function, may be used in the alternative.
- the computing device 602 includes a processor 604 , which is coupled through a bus to memory 606 , permanent storage 608 , and Input/Output (I/O) interface 610 .
- processor 604 which is coupled through a bus to memory 606 , permanent storage 608 , and Input/Output (I/O) interface 610 .
- Permanent storage 608 represents a persistent data storage device, e.g., a hard drive or a USB drive, which may be local or remote.
- Network interface 612 provides connections via network 614 , allowing communications (wired or wireless) with other devices.
- processor 604 may be embodied in a general-purpose processor, a special purpose processor, or a specially programmed logic device.
- I/O interface 610 provides communication with different peripherals and is connected with processor 604 , memory 606 , and permanent storage 608 , through the bus.
- Sample peripherals include display 622 , keyboard 618 , mouse 620 , removable media device 616 , etc.
- Display 622 is configured to display the user interfaces described herein. Keyboard 618 , mouse 620 , removable media device 616 , and other peripherals are coupled to I/O interface 610 in order to exchange information with processor 604 . It should be appreciated that data to and from external devices may be communicated through I/O interface 610 . Embodiments of the disclosure can also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a wired or a wireless network.
- Embodiments of the present disclosure can be fabricated as computer readable code on a non-transitory computer readable storage medium.
- the non-transitory computer readable storage medium holds data which can be read by a computer system. Examples of the non-transitory computer readable storage medium include permanent storage 608 , network attached storage (NAS), read-only memory or random-access memory in memory module 606 , Compact Discs (CD), flash drives, hard drives, magnetic tapes, and other data storage devices.
- the non-transitory computer readable storage medium may be distributed over a network-coupled computer system so that the computer readable code is stored and executed in a distributed fashion.
- Some, or all operations of the method presented herein are executed through a processor. Additionally, although the method operations were described in a specific order, it should be understood that some operations may be performed in a different order, when the order of the operations do not affect the expected results. In addition, other operations may be included in the methods presented, and the operations may be performed by different entities in a distributed fashion, as long as the processing of the operations is performed in the desired way.
- Embodiments presented herein recite a device or apparatus.
- the apparatus may be specially constructed for the required purpose or may be a general purpose computer.
- the apparatus includes a processor capable of executing the program instructions of the computer programs presented herein.
- Network 614 can be, for example, the Internet.
- the Internet is interconnected with a plurality of devices, including cloud storage servers, cloud logic servers, user interface devices, etc.
- Some devices that can communicate with the Internet access services on various cloud logic servers and cloud storage can include, e.g., tablet computers, smart phones, laptops, desktop computers, television systems, and the like.
- the devices that can communicate with each other require at least a processor, and a display for presenting user interface views from selected programs and code that render the user interfaces.
- the user interface can be provided through keyboard entry, text entry, voice entry, gesture entry, and combinations thereof.
- the user interfaces can be presented in browsers of the various devices, can interpret HTML code, can render video, can communicate over the Internet by way of wireless communication, can render Flash video data, and the like. All of these devices, hardware embodiments, and code are configured for enabling the interfacing and interaction with the social network, and the users of the social network, and users on various websites connected to the Internet.
- the interaction, through social networks will enable electronic messaging regarding current information, shared interests, chat communication, video communication, and general posting, interests, and relationship management.
- a social network is a site that allows at least two people or entities to communicate with one another and share at least one piece of data.
Abstract
Description
Claims (20)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US13/948,130 US9547711B1 (en) | 2013-07-22 | 2013-07-22 | Shard data based on associated social relationship |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US13/948,130 US9547711B1 (en) | 2013-07-22 | 2013-07-22 | Shard data based on associated social relationship |
Publications (1)
Publication Number | Publication Date |
---|---|
US9547711B1 true US9547711B1 (en) | 2017-01-17 |
Family
ID=57748983
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US13/948,130 Expired - Fee Related US9547711B1 (en) | 2013-07-22 | 2013-07-22 | Shard data based on associated social relationship |
Country Status (1)
Country | Link |
---|---|
US (1) | US9547711B1 (en) |
Cited By (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20180075542A1 (en) * | 2016-09-12 | 2018-03-15 | International Business Machines Corporation | Spatio-temporal diffusion based risk assessment |
CN112559179A (en) * | 2020-12-15 | 2021-03-26 | 建信金融科技有限责任公司 | Job processing method and device |
Citations (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20120254175A1 (en) * | 2011-04-01 | 2012-10-04 | Eliot Horowitz | System and method for optimizing data migration in a partitioned database |
US20130290249A1 (en) * | 2010-12-23 | 2013-10-31 | Dwight Merriman | Large distributed database clustering systems and methods |
US20140108421A1 (en) * | 2012-10-04 | 2014-04-17 | Codefutures Corporation | Partitioning database data in a sharded database |
US20140156632A1 (en) * | 2012-11-30 | 2014-06-05 | Amazon Technologies, Inc. | System-wide query optimization |
US20150006482A1 (en) * | 2013-06-28 | 2015-01-01 | Oracle International Corporation | Naïve, client-side sharding with online addition of shards |
-
2013
- 2013-07-22 US US13/948,130 patent/US9547711B1/en not_active Expired - Fee Related
Patent Citations (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20130290249A1 (en) * | 2010-12-23 | 2013-10-31 | Dwight Merriman | Large distributed database clustering systems and methods |
US20120254175A1 (en) * | 2011-04-01 | 2012-10-04 | Eliot Horowitz | System and method for optimizing data migration in a partitioned database |
US20140108421A1 (en) * | 2012-10-04 | 2014-04-17 | Codefutures Corporation | Partitioning database data in a sharded database |
US20140156632A1 (en) * | 2012-11-30 | 2014-06-05 | Amazon Technologies, Inc. | System-wide query optimization |
US20150006482A1 (en) * | 2013-06-28 | 2015-01-01 | Oracle International Corporation | Naïve, client-side sharding with online addition of shards |
Cited By (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20180075542A1 (en) * | 2016-09-12 | 2018-03-15 | International Business Machines Corporation | Spatio-temporal diffusion based risk assessment |
CN112559179A (en) * | 2020-12-15 | 2021-03-26 | 建信金融科技有限责任公司 | Job processing method and device |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US11288282B2 (en) | Distributed database systems and methods with pluggable storage engines | |
US20190082005A1 (en) | Managed function execution for processing data streams in real time | |
US8949270B2 (en) | Methods and systems for processing social media data | |
US10210558B2 (en) | Complex service network ranking and clustering | |
US8554944B2 (en) | Mechanism for supporting user content feeds | |
US11868359B2 (en) | Dynamically assigning queries to secondary query processing resources | |
US9940169B2 (en) | Real-time partitioned processing streaming | |
US20190384845A1 (en) | Using computing resources to perform database queries according to a dynamically determined query size | |
US11727004B2 (en) | Context dependent execution time prediction for redirecting queries | |
KR20160065923A (en) | Systems and methods for mapping and routing based on clustering | |
CN109992715B (en) | Information display method, device, medium and computing equipment | |
CN113609374A (en) | Data processing method, device and equipment based on content push and storage medium | |
Cai et al. | DITIR: Distributed index for high throughput trajectory insertion and real-time temporal range query | |
US9547711B1 (en) | Shard data based on associated social relationship | |
Xia et al. | Optimizing an index with spatiotemporal patterns to support GEOSS Clearinghouse | |
Jowan et al. | Traditional RDBMS to NoSQL database: new era of databases for big data | |
US11829364B2 (en) | Making decisions for placing data in a multi-tenant cache | |
US11537616B1 (en) | Predicting query performance for prioritizing query execution | |
Hsu et al. | Effective memory reusability based on user distributions in a cloud architecture to support manufacturing ubiquitous computing | |
Charles et al. | Big data–concepts, analytics, architectures–overview | |
CN110764907A (en) | Cloud computing resource map construction method | |
Ganchev et al. | The creation of a data management platform for use in the UCWW | |
CN113515545B (en) | Data query method, device, system, electronic equipment and storage medium | |
CN113055476B (en) | Cluster type service system, method, medium and computing equipment | |
US10896193B2 (en) | Cache fetching of OLAP based data using client to client relationships and data encoding |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:BEE, GAVIN EDWARD;ACHARYA, ANISH;BARR, JOHN MATHIAS;REEL/FRAME:030851/0963Effective date: 20130709 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044097/0658Effective date: 20170929 |
|
FEPP | Fee payment procedure |
Free format text: MAINTENANCE FEE REMINDER MAILED (ORIGINAL EVENT CODE: REM.); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
LAPS | Lapse for failure to pay maintenance fees |
Free format text: PATENT EXPIRED FOR FAILURE TO PAY MAINTENANCE FEES (ORIGINAL EVENT CODE: EXP.); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
STCH | Information on status: patent discontinuation |
Free format text: PATENT EXPIRED DUE TO NONPAYMENT OF MAINTENANCE FEES UNDER 37 CFR 1.362 |
|
FP | Lapsed due to failure to pay maintenance fee |
Effective date: 20210117 |