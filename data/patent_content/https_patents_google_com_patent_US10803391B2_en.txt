US10803391B2 - Modeling personal entities on a mobile device using embeddings - Google Patents
Modeling personal entities on a mobile device using embeddings Download PDFInfo
- Publication number
- US10803391B2 US10803391B2 US14/812,877 US201514812877A US10803391B2 US 10803391 B2 US10803391 B2 US 10803391B2 US 201514812877 A US201514812877 A US 201514812877A US 10803391 B2 US10803391 B2 US 10803391B2
- Authority
- US
- United States
- Prior art keywords
- personal
- entity
- mobile device
- screen content
- personal entity
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active, expires
Links
- 238000000034 method Methods 0.000 claims abstract description 90
- 238000012549 training Methods 0.000 claims abstract description 54
- 230000015654 memory Effects 0.000 claims abstract description 50
- 230000009471 action Effects 0.000 claims description 10
- 230000007704 transition Effects 0.000 claims description 3
- 238000009877 rendering Methods 0.000 claims 2
- 230000008569 process Effects 0.000 description 57
- 238000001514 detection method Methods 0.000 description 26
- 238000004891 communication Methods 0.000 description 15
- 238000010586 diagram Methods 0.000 description 14
- 238000004590 computer program Methods 0.000 description 7
- 230000000694 effects Effects 0.000 description 6
- 230000003287 optical effect Effects 0.000 description 6
- 230000006870 function Effects 0.000 description 5
- 238000012545 processing Methods 0.000 description 5
- 230000008901 benefit Effects 0.000 description 4
- 238000010801 machine learning Methods 0.000 description 4
- 239000004065 semiconductor Substances 0.000 description 4
- 230000000737 periodic effect Effects 0.000 description 3
- 230000004044 response Effects 0.000 description 3
- 239000011435 rock Substances 0.000 description 3
- 239000000758 substrate Substances 0.000 description 3
- 239000013598 vector Substances 0.000 description 3
- 238000013528 artificial neural network Methods 0.000 description 2
- 238000007796 conventional method Methods 0.000 description 2
- 238000013500 data storage Methods 0.000 description 2
- 230000003993 interaction Effects 0.000 description 2
- 239000000463 material Substances 0.000 description 2
- 238000003058 natural language processing Methods 0.000 description 2
- 239000007787 solid Substances 0.000 description 2
- 238000012706 support-vector machine Methods 0.000 description 2
- 241000282372 Panthera onca Species 0.000 description 1
- 230000010267 cellular communication Effects 0.000 description 1
- 230000001413 cellular effect Effects 0.000 description 1
- 230000008859 change Effects 0.000 description 1
- 230000001419 dependent effect Effects 0.000 description 1
- 230000036541 health Effects 0.000 description 1
- 238000013507 mapping Methods 0.000 description 1
- 238000012986 modification Methods 0.000 description 1
- 230000004048 modification Effects 0.000 description 1
- 230000006855 networking Effects 0.000 description 1
- 230000000306 recurrent effect Effects 0.000 description 1
- 230000006403 short-term memory Effects 0.000 description 1
- 230000003068 static effect Effects 0.000 description 1
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/24—Querying
- G06F16/245—Query processing
- G06F16/2457—Query processing with adaptation to user needs
- G06F16/24578—Query processing with adaptation to user needs using ranking
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/30—Information retrieval; Database structures therefor; File system structures therefor of unstructured textual data
- G06F16/36—Creation of semantic tools, e.g. ontology or thesauri
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F18/00—Pattern recognition
- G06F18/20—Analysing
- G06F18/24—Classification techniques
- G06F18/241—Classification techniques relating to the classification model, e.g. parametric or non-parametric approaches
- G06F18/2413—Classification techniques relating to the classification model, e.g. parametric or non-parametric approaches based on distances to training or reference patterns
- G06F18/24147—Distances to closest patterns, e.g. nearest neighbour classification
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0481—Interaction techniques based on graphical user interfaces [GUI] based on specific properties of the displayed interaction object or a metaphor-based environment, e.g. interaction with desktop elements like windows or icons, or assisted by a cursor's changing behaviour or appearance
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/20—Natural language analysis
- G06F40/279—Recognition of textual entities
- G06F40/289—Phrasal analysis, e.g. finite state techniques or chunking
- G06F40/295—Named entity recognition
-
- G06K9/6276—
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N20/00—Machine learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/084—Backpropagation, e.g. using gradient descent
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N5/00—Computing arrangements using knowledge-based models
- G06N5/02—Knowledge representation; Symbolic representation
- G06N5/022—Knowledge engineering; Knowledge acquisition
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N5/00—Computing arrangements using knowledge-based models
- G06N5/04—Inference or reasoning models
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V10/00—Arrangements for image or video recognition or understanding
- G06V10/70—Arrangements for image or video recognition or understanding using pattern recognition or machine learning
- G06V10/764—Arrangements for image or video recognition or understanding using pattern recognition or machine learning using classification, e.g. of video objects
Definitions
- mobile devices such as smart phones, wearable devices, tablets, laptops, etc.
- the mobile device can build a much better user experience, for example by offering personalized predictions and assistance to the user.
- Part of understanding the content and interactions involves mapping entities recognized in the content of the device screen to entities in a knowledge base. While such public knowledge bases can be huge, they will lack many of the personal entities that a user often interacts with.
- Implementations detect and model personal entities in an embedding space.
- the embedding spaces are learned and adjusted over time, so that the embeddings become a representation of a user's personal knowledge base.
- the system can model entities in any content generated by a computing device, including screens on a mobile device, email messages in a user's account, updates and posts in a user's social media account, etc.
- detection of personal entities may be based on a user specifically identifying the entity (e.g., in the sender or recipient address of an email).
- the system may determine what text on a given screen likely constitutes an entity.
- the system may track the n-grams encountered across applications/screens and when a particular n-gram appears frequently the system may consider the n-gram a personal entity.
- the system may normalize the name for the entity, assign the entity a random set of feature vectors, and begin modeling the entity.
- the system may use a continuous bag of words (CBOW)-like training model where the system predicts a personal entity given a feature or a set of features.
- a feature can include other personal entities (e.g., from past and current screens), a public entity/topic, an application the entity most often appears in, etc.
- the system may train the model to predict one entity given another entity (e.g., Mary and Rob are both often included in the same email stream or football is commonly discussed in communications to John).
- a sliding window of captured screen content can be used to provide context for identifying and modeling the personal entities identified in the window.
- the system can be trained to predict personal sequences, such as the user typically reads email and then opens a news app.
- a computing device includes at least one processor and memory storing instructions that, when executed by the at least one processor, cause the computing device to perform operations.
- the operations may include identifying a personal entity in content generated for display on the mobile device, generating training examples for the personal entity from the content, and updating an embedding used to model the personal entity using the training examples.
- the personal entity may be personal to the user of the mobile device.
- the embedding may be used to make predictions regarding the personal entity.
- a method includes identifying a first personal entity in content generated for display on a computing device, the first personal entity being associated with an embedding in a personal knowledge base associated with a user of the computing device, predicting an association between the first personal entity and a second entity based on the embedding, and providing a recommendation related to the second entity, the recommendation to be displayed on the computing device.
- a computing system includes at least one processor, a display device, memory storing a personal knowledge base, the personal knowledge base modeling personal entities as embeddings and memory storing instructions that, when executed by the at least one processor, cause the computing system to perform operations.
- the operations may include identifying features in content generated for display on the display device, identifying a personal entity predicted by the features using an embedding for the personal entity in the personal knowledge base, and providing a recommendation related to the personal entity, the recommendation to be displayed on the display device.
- a computer program product embodied on a computer-readable storage device includes instructions that, when executed by at least one processor formed in a substrate, cause a computing device to perform any of the disclosed methods, operations, or processes.
- Another general aspect includes a system and/or a method for training a prediction model to model personal entities discovered in content generated for display on a computing device, substantially as shown in and/or described in connection with at least one of the figures, and as set forth more completely in the claims.
- the embedding for a personal entity accounts for context in that the model determines a particular entity is more likely when encountered in a particular application, when discussing a particular topic, or performing a particular activity, etc.
- One or more of the implementations of the subject matter described herein can be implemented so as to realize one or more of the following advantages.
- a modeling of personal entities e.g., a personal knowledge base
- the system can use it to predict words or phrases based on onscreen content, to identify circles or categories for the personal entities, to enhance on-device search with nearest neighbor retrieval, to personalize predictions (e.g., predict a recipient of a text message based on previous onscreen content, to bias entities related to a particular category when messaging a particular person, etc.), to personalize advertisements, etc.
- Using embeddings as a representation for personal entities means the system need not make decisions about relationships involving the entity, providing greater flexibility in use of the personal entities. Modeling each personal entity in an embedding space also enables any classifier to use the embeddings as features for a prediction task.
- FIG. 1 is a block diagram illustrating an example system in accordance with the disclosed subject matter.
- FIG. 2 illustrates a flow diagram of an example process for discovering and using personal entities to personalize a user experience, in accordance with the disclosed subject matter.
- FIG. 3 illustrates a flow diagram of an example process for modeling personal entities, in accordance with disclosed implementations.
- FIG. 4 illustrates a flow diagram of an example process for using modeled personal entities to customize a user experience, in accordance with disclosed implementations.
- FIG. 5 illustrates a flow diagram of another example process for using modeled personal entities to customize a user experience, in accordance with disclosed implementations.
- FIG. 6 illustrates a flow diagram of another example process for using modeled personal entities to customize a user experience, in accordance with disclosed implementations.
- FIG. 7 illustrates a flow diagram of another example process for using modeled personal entities to customize a user experience, in accordance with disclosed implementations.
- FIG. 8 shows an example of a computer device that can be used to implement the described techniques.
- FIG. 9 shows an example of a distributed computer device that can be used to implement the described techniques.
- FIG. 1 is a block diagram of a personal entity modeling system in accordance with an example implementation.
- the system 100 may be used to detect personal (e.g., non-public) entities in content generated for display on a computing device and to model the entities as embeddings used by a machine learning recommendation engine to personalize a user experience on the computing device. Personalizing the user experience can include predicting topics, words, or phrases, identifying clusters of related personal entities, targeted advertising, etc.
- the system 100 in FIG. 1 can be used by a client-server system, with some data processing or data storage occurring at a server 170 . However, other configurations and applications may be used. For example, the data processing and data storage can occur exclusively on the computing device 110 . In some implementations, a user of the computing device 110 may indicate that portions of the processing be performed at the server 170 . Thus, implementations are not limited to the exact configurations illustrated.
- the personal entity modeling system 100 may include a computing device 110 .
- Computing device 110 may be any mobile computing device, such as a smartphone or other handheld computing device, a tablet, a wearable computing device, etc., that operates in a closed mobile environment rather than a conventional open web-based environment.
- Computing device 110 may also be other types of personal electronic computing devices, such as a laptop or net-based computer, a desktop computer, a television with a processor, etc.
- Computing device 110 may be an example of computer device 800 or 850 , as depicted in FIG. 8 .
- Computing device 110 may be a computing device used by a single user, or can be a computing device shared by multiple users.
- Computing device 110 may include one or more processors formed in a substrate configured to execute one or more machine executable instructions or pieces of software, firmware, or a combination thereof.
- the processors can be semiconductor-based—that is, the processors can include semiconductor material that can perform digital logic.
- the computing device 110 may thus include one or more computer memories configured to store one or more pieces of data, either temporarily, permanently, semi-permanently, or a combination thereof.
- the computing device 110 may thus include applications 120 , which represent machine executable instructions in the form of software, firmware, or a combination thereof.
- the components identified in the applications 120 may be part of the operating system or may be applications developed to run using the operating system. In some implementations, applications 120 may be mobile applications.
- mobile applications operate in a closed environment, meaning that the user employs separate applications to perform activities conventionally performed in a web-based browser environment.
- a user of the computing device 110 can use a mobile application in applications 120 provided by bookit.com.
- Applications 120 may also include web applications, which may mirror the mobile application, e.g., providing the same or similar content as the mobile application.
- the applications 120 may include functions performed by an operating system of the computing device 110 .
- the applications 120 may include a screen content engine 122 , a personal entity detection engine 124 , a personal entity modeling engine 126 , and a recommendation engine 128 .
- one or more of these applications can be provided by the operating system (not shown) of the computing device 110 .
- one or more of these applications can be downloaded and installed by the user.
- the screen content engine 122 can include various functionalities.
- the screen content engine 122 may be configured to get textual information represented on the screen of the computing device from an application program interface (API).
- API application program interface
- the screen content engine 122 may be built into the operating system, which can determine the content of text fields displayed on the screen.
- the textual information may be considered screen captured content, and each call to the API or each time the content of text fields is determined may be considered a screen capture.
- the screen content engine 122 may be configured to capture the image displayed on the screen by copying or reading the contents of the device's frame buffer.
- the captured screen may be an image and may be referred to as a captured image.
- the screen content engine 122 may capture the screen at intervals.
- the interval can be small, for example every half second or every second.
- the screen content engine 122 may be configured to capture the screen every time a touch event occurs (e.g., every time the user touches the screen to scroll, zoom, click a link etc.), in response to an explicit user request or command, or when the device transitions from one mobile application to another mobile application.
- the screen content engine 122 may increase the interval at which a screen capture occurs when the screen does not change. In other words, when the screen is static, the screen content engine 122 may capture images less often.
- the screen content engine 122 may provide the captured content or screen images and metadata to a recognition engine, which may be part of the screen content engine 122 and located on the computing device 110 or a server, such as server 170 . If a screen capture image is provided to the recognition engine, the recognition engine may identify words, entities, logos, etc. in the content of the screen capture image. Thus, the recognition engine may generate recognized content, which can be from words as well as from images.
- the metadata may include the timestamp, the mobile device type, a mobile device identifier, the mobile application running when the content was captured, e.g., the application that rendered the content displayed on the screen, etc. In some implementations, the metadata may also include which applications are active, the location of the device, ambient light, motion of the device, etc.
- the system may use this additional device information to assist in content analysis (e.g., entity disambiguation), feature generation (e.g., determining context and environment associated with an entity), etc.
- the recognition engine may thus be configured to perform various types of recognition, such as character recognition, image recognition, logo recognition, etc., using conventional or later developed techniques.
- the computing device 110 may also include a personal entity detection engine 124 .
- the personal entity detection engine 124 may be configured to determine which entities recognized by the screen content engine 122 are potential personal entities.
- An entity may be may be a person, place, item, idea, topic, word, phrase, abstract concept, concrete element, other suitable thing, or any combination of these.
- Entities may be stored in a knowledge base, which stores not only entities but also information about entities.
- a knowledge base stores information about entities in the form of relationships between entities. For example, entities in a public knowledge base may be related to each other by labeled edges that represent relationships.
- a knowledge base such as public knowledge base 144 or public knowledge base 184 , may include public entities.
- a public entity is an entity that exists in a publically available knowledge base, such as knowledge base 184 .
- the public knowledge base may be generated from information available over the Internet and may be curated by a collection of users.
- Such public knowledge bases are large, sometimes including millions of entities.
- a personal entity is an entity that is relevant or interesting to the user of a computing device and does not exist in the public knowledge base. For example, a user may be interested in the actor Tom Hanks, but most public knowledge bases have an entity to represent Tom Hanks, so Tom Hanks is not a personal entity. In contrast, the user may text or refer to Tom Smith, a co-worker, often.
- the co-worker Tom Smith is likely a personal entity because the public knowledge base does not have an entity representing the co-worker, or may have an entity named Tom Smith but based on on-screen context the system may decide that the public Tom Smith is not the same as the entity referred to. Likewise, the user may be interested in rock hounding. Because rock hounding is a more specialized interest, the public knowledge base may not include an entity representing rock hounding. Such an entity may then be a personal entity for the user.
- the personal entity detection engine 124 may use fields with known entity types to identify potential personal entities. For example, in an email application or a contacts application, certain text fields are known to contain person entities, such as the to or cc fields of an email. Other fields may be known to include other entity types, such as an address or a phone number, etc. When an application is known to include such entity-typed fields, the personal entity detection engine 124 may use text in the entity-typed fields to identify potential personal entities. The personal entity detection engine 124 may also use other methods of identifying personal entities. For example, the system may use conventional entity identification methods to determine which recognized items are possible entities. Conventional methods involve natural language processing techniques to identify potential personal entities in the content.
- Natural language processing includes part-of-speech tagging, noun phrase identification, named entity recognition and type assignment, etc.
- the personal entity detection engine 124 may also track the occurrence of n-grams across applications. The personal entity detection engine 124 may look for n-grams that occur frequently in private content applications, like email, contacts, messaging, comments or posts on social media, etc. that do not occur with the same frequency in public content applications (e.g., news-feeds, reservation applications, games, etc.). The personal entity detection engine 124 may consider n-grams that occur more frequently in personal-content applications than in public-content applications to be personal entities.
- the personal entity detection engine 124 may verify whether the potential personal entities occur in a public knowledge base.
- the public knowledge base such as knowledge base 144 or 184
- the public knowledge base may include a text description or descriptions or keywords used to identify an entity as well as disambiguation data.
- the public knowledge base may also include other entities or words that co-occur with an entity to help determine the difference between two similarly named entities. If the personal entity detection engine 124 finds a match of the potential personal entity in the public knowledge base, the personal entity detection engine 124 may discard the entity. Otherwise, the entity may be considered a personal entity.
- the personal entity detection engine 124 may normalize the name of the entity and store the personal entity in a personal knowledge base 134 . The personal entity detection engine 124 may then provide the entity to the personal entity modeling engine 128 to learn an embedding for the personal entity.
- a personal entity may be assigned an initial embedding.
- the initial embedding may be random or based on an entity type of the personal entity, when known.
- the initial embedding may be stored with the entity name in a personal knowledge base 134 .
- the personal entity modeling engine 126 may then continuously train a prediction model, such as a word2vec system, to learn the proper embedding for the personal entity.
- the personal entity modeling engine 126 may use a continuous bag of words (CBOW)-like model that predicts a personal entity given a set of other personal entities.
- the other personal entities may occur on the current screen (e.g., the current screen capture) with the personal entity being modeled or in a window of past and/or future screen captures. The length of the window can be implementation dependent. This type of training clusters related personal entities together in the embedding space.
- the personal entity modeling engine 126 may train the prediction model to predict the personal entity given a set of public and personal entities that occur with the personal entity, either on the same screen (e.g. the same screen capture event) or in the window of screen capture events. In some implementations, the personal entity modeling engine 126 may be trained to predict structural properties of where and how the personal entity appears in the screen capture content. The structural properties can include font, formatting, or layout properties. This type of training clusters together personal entities appearing in the same context. In some implementations, the personal entity modeling engine 126 may predict a currently executing application, a next application, or a personal entity type given a particular personal entity. This type of training clusters together personal entities of the same type occurring in the same context in the embedding space.
- the personal entity modeling engine 126 may generate training examples that represent multiple prediction types (e.g., examples to predict structural properties and examples to predict the personal entity give other entities).
- the different types of training examples may be weighted to favor one type over another. For example, training examples predicting structure may be weighted less than training examples predicting the personal entity (or vice-versa). In such an implementation, the higher weighted examples contribute more to the resulting embedding.
- a prediction model such as personal entity modeling engine 126
- the prediction model can be trained to predict one entity given another entity, a particular mobile application, a set of other entities, a topic, a set of structural properties, etc.
- the personal entity modeling engine 126 has two modes, a training mode and an inference mode. In the training mode the personal entity detection engine 124 uses feature vectors generated from captured content, (e.g., content displayed on the computing device) as positive training examples for the prediction model.
- Training examples may be collected over time and used to update the embedding for the personal entity.
- the feature vectors may depend on what the model is being trained to predict (e.g., another entity, a topic, a set of entities, a mobile application, etc.).
- training examples for an entity may include what types of actions a user takes subsequent to display of the entity. For example, when a user switches from one mobile application to another mobile application, this context may be used to update the embedding for a personal entity appearing in the first mobile application. Thus, as a particular personal entity is encountered over time the embedding will more accurately reflect the context in which the entity appears and what contexts typically follow.
- the model may be used in the inference mode to personalize the user experience in various ways, depending on how the model has been trained.
- the screen content engine 122 can include an indexing engine configured to index the captured content.
- the index may also associate a screen capture image with the text, entities, images, logos, etc. identified in the image.
- the indexing engine may generate index entries (e.g., stored in screen capture index 146 ) for a captured image and captured content.
- the indexing engine may be on a server, such as server 170 , and the screen content engine 122 may provide the captured image and captured content to the server.
- the index may be an inverted index, where a key value (e.g., word, phrase, entity, image, logo, etc.) is associated with a list of images (e.g., copies of the captured screen images) that include the key value.
- a key value e.g., word, phrase, entity, image, logo, etc.
- the index may include metadata (e.g., where on the captured image the key value occurs, a rank for the key value for the image, etc.) associated with each captured image in the list.
- the index may also include a list of captured images indexed by a timestamp.
- the indexing engine may store the index in memory, for example in screen capture index 146 .
- the system may store the index in a user account on a server in addition to or instead of on the computing device 110 .
- the user of the computing device 110 may control when the screen content engine 122 is active. For example, the user may specify that the screen content engine 122 is active only when other specified applications 120 are running (e.g., only when in a social media mobile application).
- the user may also manually turn the screen content engine 122 on and off, for example via a settings application.
- the user may invoke the screen content engine 122 with a gesture or action.
- Disabling the screen content engine 122 may also disable the detection and modeling of personal entities in screen content described herein.
- the applications 120 may also include recommendation engine 128 .
- the recommendation engine 128 may use the personal entity modeling engine 126 and personal knowledge base 134 in an inference mode to provide personalized assistance to a user of the computing device 110 .
- Personalized assistance may include various techniques, depending on the implementation.
- the recommendation engine 128 may determine completions for input based on the context of the input.
- the recommendation engine 128 may identify clusters or groups of similar personal entities.
- the recommendation engine 128 may identify a group of personal entities that share an interest in football, a group of personal entities related to Mexican restaurants, a group of personal entities that share a context, e.g., meeting for lunch on Tuesdays, etc.
- the recommendation engine 128 can use the groups to suggest advertisements, additional email or text recipients, topics for discussion, people to share a current screen with, etc.
- the recommendation engine 128 may include a reconciliation process that suggests merging two personal entities when the embeddings of the two personal entities are close.
- the recommendation engine 128 may suggest merging or automatically perform the merging of two personal entities when the distance between the embeddings of the two personal entities is within a high threshold, e.g., representing a high degree of similarity.
- Merging personal entities in the personal knowledge base may enable a personal entity to be identified via various names.
- the recommendation engine 128 may suggest (or automatically perform) splitting one personal entity into two personal entities when an embedding is unstable or training examples for the personal entity are often in disagreement.
- the above personalization assistance scenarios are provided as examples only and implementations are not limited to the examples given.
- the computing device 110 may include data stores 130 , which are stored in the memory of the computing device 110 and used by the applications 120 .
- the data stores 130 may include a screen capture index 146 which includes items identified in the screen capture images, and a public knowledge base 144 .
- the public knowledge base 144 may be a graph-based data store that stores data and rules that describe knowledge about the data in a form that provides for deductive reasoning. For example, in a knowledge base, information may be stored about entities in the form of relationships to other entities.
- An entity may be may be a person, place, item, idea, topic, word, phrase, abstract concept, concrete element, other suitable thing, or any combination of these. Entities may be related to each other by labeled edges that represent relationships.
- the labeled edges may be directed or undirected.
- the entity representing the National Football League may be related to a Jaguar entity by a “has team” relationship.
- the public knowledge base 144 may be a subset of entities and relationships in a larger knowledge base 184 located at server 170 , especially if the large knowledge base 184 includes millions of entities and billions of relationships.
- the entities and relationships in the public knowledge base 144 may represent the most popular entities and relationships from knowledge base 184 , or may be selected based on user preferences. For example, if the user has a profile, entities and relationships may be selected for inclusion in public knowledge base 144 based on the profile or based on the types of entities frequently identified in the content of the screen capture images.
- the data stores 130 may include personal knowledge base 134 .
- Personal knowledge base 134 may be stored on a user device, such as computing device 110 and/or on a server 170 in an account associated with the user, such as personal knowledge base 182 .
- the personal knowledge base 134 (and personal knowledge base 182 ) may store one or more descriptions of the personal entity and an associated embedding for the personal entity.
- personal entities are represented by an embedding and identified by one or more textual descriptions.
- the textual descriptions may be normalized, e.g., removing capitalizations, etc.
- other information about the personal entity may also be stored in the personal knowledge base 134 .
- an email address, phone number, or social media identifier may be associated with the personal entity, which can assist the recommendation engine 128 .
- the recommendation engine 128 may use this additional information to automatically send an email, a text, or a post to the personal entity.
- the personal entity modeling system 100 may include a server 170 , which may be a computing device or devices that take the form of a number of different devices, for example a standard server, a group of such servers, or a rack server system.
- server 170 may be implemented in a distributed manner across multiple computing devices.
- server 170 may be implemented in a personal computer, for example a laptop computer.
- the server 170 may be an example of computer device 800 , as depicted in FIG. 8 , or computer device 900 , as depicted in FIG. 9 .
- Server 170 may include one or more processors formed in a substrate configured to execute one or more machine executable instructions or pieces of software, firmware, or a combination thereof.
- the processors can be semiconductor-based—that is, the processors can include semiconductor material that can perform digital logic.
- the server 170 can also include one or more computer memories.
- the memories for example, a main memory, may be configured to store one or more pieces of data, either temporarily, permanently, semi-permanently, or a combination thereof.
- the memories may include any type of storage device that stores information in a format that can be read and/or executed by the one or more processors.
- the memories may include volatile memory, non-volatile memory, or a combination thereof, and store modules or engines that, when executed by the one or more processors, perform certain operations.
- the modules may be stored in an external storage device and loaded into the memory of server 170 .
- the modules may perform one or more of the functions of the screen content engine 122 , the personal entity detection engine 124 , the personal entity modeling engine 126 , or the recommendation engine 128 .
- server 170 may store backup copies of one or more of the information files in data store 130 , may provide source data for one or more of the information files in data store 130 .
- server 170 may include screen content engine 172 , entity modeling engine 176 , and/or recommendation engine 178 .
- the screen content engine 172 may receive a screen capture image from the screen content engine 122 on computing device 110 and may perform the recognition to identify key items in the image.
- the screen content engine 172 may include components that analyze the screen content in a screen capture image and identify key items, such as words, entities, logos, etc., in the screen content.
- Identified entities may be entities that are in the public knowledge base 184 and/or in a personal knowledge base 182 associated with a user account.
- the screen content engine 172 can be configured to perform various types of recognition, such as character recognition, image recognition, logo recognition, etc., using conventional or later developed techniques.
- the screen content engine 172 may index the key items, as discussed above, storing the inverted index in screen capture index 186 .
- the screen capture index 186 is associated with a user of the computing device 110 .
- the screen content engine 172 may provide recognized items to the personal entity detection engine 124 on computing device 110 , or may provide recognized items to an entity modeling engine 176 .
- the entity modeling engine 176 may identify personal entities from the captured screen (or window of screens), as described above with regard to the personal entity detection engine 124 .
- the entity modeling engine 176 may also update the embedding of personal entities identified in the screen content, as described above with regard to the personal entity modeling engine 126 .
- the entity modeling engine 176 may perform one or more of the functions of the personal entity detection engine 124 or the personal entity modeling engine 126 .
- the entity modeling engine 176 may therefore update the personal knowledge base 134 or personal knowledge base 182 .
- the server 170 may store public knowledge base 184 .
- the public knowledge base 184 may be a large graph-based data store that stores data and rules that describe knowledge about the data in a form that provides for deductive reasoning. A knowledge base with a large number of entities and even a limited number of relationships may have billions of connections.
- knowledge base 184 may be stored in an external storage device accessible from server 170 and/or computing device 110 .
- the public knowledge base 184 may be distributed across multiple storage devices and/or multiple computing devices, for example multiple servers.
- the entities and relationships in the public knowledge base 184 may be searchable, e.g., via an index.
- the index may include text by which an entity has been referred to.
- reference to the knowledge base 184 may be understood to include an index that facilitates finding an entity using a text equivalent.
- the computing device 110 may be in communication with the server 170 and with other mobile devices over network 160 .
- Network 160 may be for example, the Internet, or the network 160 can be a wired or wireless local area network (LAN), wide area network (WAN), etc., implemented using, for example, gateway devices, bridges, switches, and/or so forth.
- Network 160 may also represent a cellular communications network.
- the server 170 may communicate with and transmit data to/from computing device 110 and computing device 110 may communicate with other mobile devices (not shown).
- the personal entity modeling system 100 represents one example configuration and implementations may incorporate other configurations. For example, some implementations may combine one or more of the components of the screen content engine 122 , the personal entity detection engine 124 , the personal entity modeling engine 126 , or the recommendation engine 128 into a single module or engine. Similarly, some implementations may combine one or more of the screen content engine 172 , the entity modeling engine 176 , or the recommendation engine 178 into a single module or application. As another example one or more of the data stores, such as the screen capture index 146 , the public knowledge base 144 , or the personal knowledge base 134 may be combined into a single data store or may distributed across multiple computing devices, or may be stored at the server 170 or another location specified by the user. Moreover, in certain embodiments aspects of the methods described herein may take place on the computing device 110 without communication with server 170 , such as for privacy, low latency, operation outside of network range, etc.
- the users may be provided with an opportunity to control whether programs or features collect the user information (e.g., information about a user's social network, social actions or activities, a user's preferences, or a user's current location), or to control whether and/or how to store screen capture images and content.
- the system may refrain from capturing content for certain applications, such as banking applications, health applications, or other similar applications or where capturing such content violates terms of service.
- the user may be provided with the opportunity to disable capturing screen content for specific applications or categories of applications.
- certain data may be treated in one or more ways before it is stored or used, so that personally identifiable information is removed.
- a user's identity may be treated so that no personally identifiable information can be determined for the user, or a user's geographic location may be generalized where location information is obtained (such as to a city, ZIP code, or state level), so that a particular location of a user cannot be determined.
- location information such as to a city, ZIP code, or state level
- the user may have control over how information is collected about the user and used by a mobile personal entity modeling system.
- FIG. 2 illustrates a flow diagram of an example process 200 for discovering and using personal entities to personalize a user experience, in accordance with the disclosed subject matter.
- Process 200 may be performed by a mobile personal entity modeling system, such as system 100 of FIG. 1 .
- Process 200 may be used to detect personal entities and model them as embeddings, which enables the system to personalize the user experience in various flexible ways.
- Process 200 may begin by detecting a personal entity in content generated for display on a computing device ( 205 ).
- the system may use screen capture images or API calls to obtain information displayed on the screen and perform recognition on the information, as discussed above with regard to FIG. 1 .
- the system may detect the personal entity based on association with a particular data field (e.g., a recipient address in an email application), based on frequent n-grams appearing in private-content applications, or based on conventional entity detection techniques for text and images.
- a personal entity may be an entity not found in a public knowledge base.
- the system may model the personal entity as an embedding ( 210 ). In some implementations, the system may only model personal entities that have been detected a minimum number of times. The modeling may begin with an initial embedding which is then modified by a machine learning prediction model based on examples provided to the model.
- the system may obtain screen information (e.g., from screen captures or API calls) on a periodic basis and provide the prediction model with the context in which the personal entity occurs as training examples.
- screen information e.g., from screen captures or API calls
- the context provided as training examples may depend on the implementation.
- the system may use the embedding for the personal entity to personalize the user experience ( 215 ).
- Sufficient training may be determined, for example, when the personal entity has been encountered a certain number of times, one an error rate for classifications involving the personal entity (on the training data) falls below a certain threshold, etc.
- Personalizing the user experience may include a variety of functionalities.
- the system may predict words or phrases based on content onscreen.
- the onscreen content can include both other personal entities and public entities.
- the system may use the embeddings to identify similar personal entities, such as personal entities that co-occur with a particular topic or event (e.g., an anime discussion, lunch during weekdays, or playing football).
- the system may use embeddings for a topic classifier, which can predict when a user might want to contact a particular person based on the onscreen context. For instance, the system may determine that as the user views information for a restaurant, the user typically dines with three personal entities and may suggest sharing the information for the restaurant or a reservation at the restaurant with the three personal entities.
- the system may determine the user is chatting with one or more personal entities and may suggest topics of discussion.
- the embeddings may indicate that a group of personal entities are mentioned often in the context of movies and when the user is chatting with one or more members of the group may suggest a new movie or a recent news item for an actor to discuss.
- the system may provide personalized advertising based on the embeddings. For instance, the system may provide an ad for a new movie for onscreen personal entities that the embeddings indicate co-occur in the context of movies.
- the system may use the embeddings for nearest neighbor retrieval in an on-device search.
- the system may provide nearest neighbor matches for the search to enhance the search results.
- FIG. 3 illustrates a flow diagram of an example process 300 for modeling personal entities, in accordance with disclosed implementations.
- Process 300 may be performed by a mobile personal entity modeling system, such as system 100 of FIG. 1 .
- Process 300 may be used to detect personal entities and model them as embeddings.
- Process 300 may begin by detecting a non-public entity in captured screen information ( 305 ).
- a non-public entity is an entity that does not exist in a public knowledge base, e.g., a public knowledge base accessed by the system. If the public knowledge base used by the system lacks the entity, it is a non-public entity.
- the non-public entity may be recognized in images as well as text.
- some images have an associated description and the description may be or include a description or other identifier for the non-public entity. Examples of this are images associated with a contact or images tagged to a social media user identifier.
- the system may determine whether the non-public entity is a personal entity ( 310 ). If the entity exists already in a personal knowledge base, such as personal knowledge base 134 of FIG. 1 , the entity is a personal entity ( 310 , Yes). If not ( 310 , No), the system may determine whether the non-public entity has been encountered frequently enough to be considered a personal entity ( 315 ). The frequency may depend on the method used to detect the entity.
- the frequency threshold may be implementation-specific as well as source-specific (e.g., different sources having differing thresholds). If the frequency threshold is not met ( 315 , No) the system may continue analyzing screen content to find other occurrences of the entity ( 305 ). If the frequency threshold is met ( 315 , Yes), the system may assign the entity an initial embedding ( 320 ). The initial embedding can be randomly assigned or a default assigned based on entity type.
- person entities may have a different initial embedding from address entities, topic entities, or phone number entities, etc.
- the initial embedding and the non-public entity are added to the personal knowledge base as part of step 320 , so that the system may begin modeling the personal entity as an embedding.
- the system may generate training examples for the personal entity from the captured screen information ( 325 ).
- the training examples may include various information detected from the screen capture information.
- the training examples may include other personal entities identified in the screen capture information, public entities identified in the screen capture information, a combination of public and personal entities identified in the screen capture information, structural properties, such as formatting and layout, of where and how the personal entity appears onscreen, metadata about the state of the computing device, metadata about the currently running application, etc.
- the training examples may be based on screen capture information for one screen.
- the training examples may be based on screen capture information from a window of past screens or past and future screens.
- the system may delay generating the training examples until a window of time has passed and may include screen capture events from the window of time to generate the training examples.
- some of the training examples may include actions taken by the user subsequent to the screen capture event where the personal entity was detected. For example, if the user often switches to a reservation application after discussing a particular topic (e.g., lunch), the system may include a training example that predicts the reservation application given the topic.
- the system may use the training examples to train the prediction model, thus updating the embedding for the personal entity ( 330 ).
- the system may perform process 300 on a continuous basis, so long as the user settings permit it, to refine the embedding for the entity. This allows the system may eventually use the embedding to provide personalized assistance based on the embedding when the personal entity is encountered in onscreen content or associated with onscreen content.
- FIG. 4 illustrates a flow diagram of an example process 400 for using modeled personal entities to customize a user experience, in accordance with disclosed implementations.
- the system may use the prediction model in various ways. One way may be to provide entities, both personal and private, as suggestions in an auto-completion operation.
- the trained prediction model may predict words or phrases based on other onscreen content. This differs from traditional auto-complete operations that use only what the user has already typed.
- a benefit of process 400 over conventional auto-complete operations is that process 400 can suggest the words or phrases even in the absence of any characters provided by the user. In other words, process 400 can provide a suggested entity upon determining that the user has placed a cursor in a text box, prior to the user entering any text.
- Process 400 may be executed by a mobile personal entity modeling system, such as system 100 of FIG. 1 .
- Process 400 is an example of using the embeddings to personalize a user experience, as described with regard to step 215 of FIG. 2 .
- Process 400 may be executed on a recurrent basis by the system—for example, when a user initially sends focus to an input control, such as a text box, the system may perform process 400 and provide a list of entities as suggested completions. If the user does not select one of the completions, the system may perform process 400 again after receiving input from the user, for example after each text input is received, using the text input to refine the entities suggested as completions.
- Process 400 begins by determining an input provided by a user ( 405 ).
- the actual input may be blank or null, representing an intention to provide input.
- an input control such as a placing a cursor in a text box
- the system may determine the user intends to provide an input and determine that the input is currently blank or null. If the user has provided any text, numbers or characters, via the input control the system may determine the input includes the provided text.
- the system may also determine content displayed by the computing device that is associated with the input. For example, the system may determine other entities displayed in the screen capture information associated with the input control, e.g., entities displayed on the current screen or entities displayed in a window that includes the current screen.
- the entities recognized in the screen capture information and metadata for the screen capture information are content associated with the input.
- the system may generate a set of features for the input based on the content ( 410 ).
- the features include the other entities and metadata about the current screen.
- features may include the executing application, where on the screen the input occurs, a type of entity typically associated with the input control (e.g., a person or a place), etc.
- the system may then determine completions for the input ( 415 ).
- the system may determine the completions using conventional methods (e.g., words known to start with the input provided by the user), as well as completions determined using the features and the prediction model.
- the system may provide the features to the prediction model, which may in turn provide some completions for the input based on the embeddings and features.
- the completions provided by the prediction model may be a personal entity, a group of personal entities, a public entity, a topic, etc. in the form of words or phrases that describe the entity or entities.
- the words may describe a category or topic that relates the group of entities.
- the words may describe an entity.
- the prediction model may provide only completions that meet a probability threshold. In other words, only the most probable completions, including people, places, topics, may be provided by the prediction model as completions.
- the system may rank the completions, the ranking accounting for a score determining by the prediction model based on the embeddings ( 420 ).
- the score may represent the probability that the completion is predicted based on the features provided.
- the rank for a completion provided by the prediction model may account for this score and a determination of how closely the words/phrases associated with the completion match the input provided thus far by the user. For example, when the input is null, the rank may rely solely on the probability score.
- the rank may be a combination of the probability score and a score reflecting how closely the words/phrases match the three characters. This allows the system to account for misspellings and typographical errors by the user. For example, a very highly probable predicted completion may still have a high rank even if only two of the first three characters in the description of the completion match the three characters provided by the user.
- the system may provide the highest ranked completions to the user as suggestions ( 425 ). This may allow the user to complete the input with fewer keystrokes. In some cases, the user may only need to place a cursor in a text box before selecting one of the predicted completions, thus avoiding any keystrokes at all.
- process 400 is an example of improving the user experience by providing personalized completions based on personal entities modeled as embeddings.
- FIG. 5 illustrates a flow diagram of another example process 500 for using modeled personal entities to customize a user experience, in accordance with disclosed implementations.
- Process 500 illustrates another way to use the prediction model to customize the user experience by providing a recommendation related to an interest associated with personal entities displayed on a current screen.
- a benefit of process 500 over conventional recommendation systems is that process 500 can suggest recommendations related to personal entities, not just public entities.
- Modeling personal entities has been a challenging problem because modeling entities typically requires a significant amount of input. For example, the curation of public knowledge bases has included hundreds of thousands of man-hours. This is not feasible on a personal level.
- knowledge bases typically include information about entities in the form of relationships between entities. This type of representation is also not feasible on a personal level.
- the personal knowledge base used in process 500 represents personal entities as embeddings, so that the user does not need to actively populate and train the knowledge base. Instead, the personal knowledge base takes advantage of a machine-learning prediction model.
- process 500 may be executed by a mobile personal entity modeling system, such as system 100 of FIG. 1 .
- Process 500 is an example of using the embeddings to personalize a user experience, as described with regard to step 215 of FIG. 2 .
- Process 500 may be executed on a continual basis by the system—for example, the system may perform process 500 on a periodic basis to display an advertisement related to the onscreen content or to suggest a topic of conversation in a personal communication type application.
- Process 500 begins by identifying a personal entity in content generated for display on a computing device ( 505 ).
- the content may be associated with a screen capture event or a window of screen capture events.
- the system may identify the personal entity using the recognition techniques described above with regard to the screen content engine 122 and personal entity detection engine 124 as well as step 205 of FIG. 2 and step 305 of FIG. 3 .
- the system may identify a second entity related to the personal entity using the embedding for the personal entity ( 510 ).
- the system may provide a prediction model with features generated from the screen capture content and the personal entity identified and the prediction model may predict a second entity based on the features and embedding for the personal entity.
- the second entity may be another personal entity or may be a public entity.
- the personal and public entities may represent people, places, contexts, topics, hobbies, activities, etc. often associated with the personal entity. For example, the system may determine that the personal entity Rob is often associated with discussions about football (likely a public entity, but possibly a personal entity). As another example, the system may determine that the personal entity Alice is often associated with a context, such as lunch at Uncle Joe's.
- a context can represent the time or location of an event.
- the system may then provide a recommendation related to the second entity and initiate display of the recommendation on the computing device ( 515 ).
- the recommendation can be an advertisement related to the second entity, a suggested topic of conversation related to the second entity, a circle of friends related to the second entity (e.g., a topic or interest), etc.
- the system may provide an advertisement for a new football movie or the details of an upcoming football game.
- the system may suggest adding Tom to the conversation with Rob, as Tom may be a second personal entity that is associated with football.
- the system may recommend making a reservation at Uncle Joes when the user is chatting with Alice about lunch.
- FIG. 6 illustrates a flow diagram of another example process 600 for using modeled personal entities to customize a user experience, in accordance with disclosed implementations.
- Process 600 illustrates another way to use the prediction model to customize the user experience by providing a recommendation related to a personal entity associated with a current screen.
- Process 600 may be executed by a mobile personal entity modeling system, such as system 100 of FIG. 1 .
- Process 600 is an example of using the embeddings to personalize a user experience, as described with regard to step 215 of FIG. 2 .
- Process 600 may be executed on a continual basis by the system—for example, the system may perform process 600 on a periodic basis to suggest a personal entity to include in a conversation, to share a screen or information on a screen with, or to include in a reservation, etc., based on public entities identified in the screen content.
- Process 600 begins by identifying features in content generated for display on a computing device ( 605 ).
- the content may be associated with a screen capture event or a window of screen capture events.
- the features may include public entities, a context, personal entities, etc.
- a context may represent the time and/or location of an event (e.g., dinner at Luigis). Entities, whether public or private, may represent people, places, topics, hobbies, activities, etc.
- the system may identify the features using the recognition techniques described above with regard to the screen content engine 122 and personal entity detection engine 124 as well as step 205 of FIG. 2 and step 305 of FIG. 3 .
- a window of screen capture information may be used as context for identifying the features in the content.
- the system may identify a personal entity predicted by the features using the embedding for the personal entity ( 610 ).
- the system may provide a prediction model with the features generated from the content and the prediction model may predict the personal entity based on the features.
- the personal entity may represent a person, topic, hobby, activity, etc., found in the personal knowledge base. For example, the system may determine that Alice is associated with Italian restaurants.
- the system may then provide a recommendation related to the personal entity and initiate display of the recommendation on the computing device ( 615 ).
- the recommendation can be an advertisement related to the interest, a suggested topic of conversation related to the interest, a circle of friends related to the interest, an action related to a context, etc.
- the system may recommend Rob and Tom as recipients.
- the system may suggest an action such as sharing the screen with Alice or including Alice in a calendar invite for lunch at Uncle Joe's.
- FIG. 7 illustrates a flow diagram of another example process 700 for using modeled personal entities to customize a user experience, in accordance with disclosed implementations.
- Process 700 illustrates another way to use the prediction model to customize an on-device search by finding related personal entities and including these in the search results provided to the user.
- Process 700 may be executed by a mobile personal entity modeling system, such as system 100 of FIG. 1 .
- Process 700 is an example of using the embeddings to personalize a user experience, as described with regard to step 215 of FIG. 2 .
- Process 700 may be initiated by the user, e.g., through an explicit search request, or by the system as the result of an implicit search request by request.
- Process 700 begins by receiving a query for an on-device search ( 705 ).
- the query may include a personal entity.
- the system may identify the personal entity in the query based on entity recognition techniques described above with regard to the screen content engine 122 and personal entity detection engine 124 as well as step 205 of FIG. 2 and step 305 of FIG. 3 .
- the system may determine a nearest neighbor to the personal entity based on the embeddings ( 710 ). In other words, the system may look for approximate matches to the personal entity based on similarity of the embeddings using conventional nearest neighbor techniques.
- the system may use the nearest neighbor and the personal entity to determine search results ( 715 ) and provide the search results to the user ( 720 ).
- the search results can be obtained from, for example, an index of screen captures or from a directory of files, etc.
- Process 700 then ends.
- the prediction model may include two personal entities, Bill and Jason.
- Bill and Jason may have very similar embeddings because both often appear in the same context (e.g., are included in the same calendar invites, are include in group text conversations, included in the same email, etc.).
- the system may also include conversations with Jason or pictures of Jason. This enables the system to provide search results that are similar to what the user asked for in the event that the user mistakenly thought the searched for conversation was associated with Rob and not Jason or that the sought for picture was labeled with Jason but not Rob.
- a user may search for “tennis” on the computing device.
- the system may use the prediction model to determine that a personal entity (or two or more personal entities) are related to tennis and return conversations with the personal entity in response to the query for tennis, even if the conversations do not include the term tennis.
- FIG. 8 shows an example of a generic computer device 800 , which may be operated as server 170 , and/or device 110 of FIG. 1 , which may be used with the techniques described here.
- Computing device 800 is intended to represent various example forms of computing devices, such as laptops, desktops, workstations, personal digital assistants, cellular telephones, smartphones, tablets, servers, and other computing devices, including wearable devices.
- the components shown here, their connections and relationships, and their functions, are meant to be examples only, and are not meant to limit implementations of the inventions described and/or claimed in this document.
- Computing device 800 includes a processor 802 , memory 804 , a storage device 806 , and expansion ports 810 connected via an interface 808 .
- computing device 800 may include transceiver 846 , communication interface 844 , and a GPS (Global Positioning System) receiver module 848 , among other components, connected via interface 808 .
- Device 800 may communicate wirelessly through communication interface 844 , which may include digital signal processing circuitry where necessary.
- Each of the components 802 , 804 , 806 , 808 , 810 , 840 , 844 , 846 , and 848 may be mounted on a common motherboard or in other manners as appropriate.
- the processor 802 can process instructions for execution within the computing device 800 , including instructions stored in the memory 804 or on the storage device 806 to display graphical information for a GUI on an external input/output device, such as display 816 .
- Display 816 may be a monitor or a flat touchscreen display.
- multiple processors and/or multiple buses may be used, as appropriate, along with multiple memories and types of memory.
- multiple computing devices 800 may be connected, with each device providing portions of the necessary operations (e.g., as a server bank, a group of blade servers, or a multi-processor system).
- the memory 804 stores information within the computing device 800 .
- the memory 804 is a volatile memory unit or units.
- the memory 804 is a non-volatile memory unit or units.
- the memory 804 may also be another form of computer-readable medium, such as a magnetic or optical disk.
- the memory 804 may include expansion memory provided through an expansion interface.
- the storage device 806 is capable of providing mass storage for the computing device 800 .
- the storage device 806 may be or include a computer-readable medium, such as a floppy disk device, a hard disk device, an optical disk device, or a tape device, a flash memory or other similar solid state memory device, or an array of devices, including devices in a storage area network or other configurations.
- a computer program product can be tangibly embodied in such a computer-readable medium.
- the computer program product may also include instructions that, when executed, perform one or more methods, such as those described above.
- the computer- or machine-readable medium is a storage device such as the memory 804 , the storage device 806 , or memory on processor 802 .
- the interface 808 may be a high speed controller that manages bandwidth-intensive operations for the computing device 800 or a low speed controller that manages lower bandwidth-intensive operations, or a combination of such controllers.
- An external interface 840 may be provided so as to enable near area communication of device 800 with other devices.
- controller 808 may be coupled to storage device 806 and expansion port 814 .
- the expansion port which may include various communication ports (e.g., USB, Bluetooth, Ethernet, wireless Ethernet) may be coupled to one or more input/output devices, such as a keyboard, a pointing device, a scanner, or a networking device such as a switch or router, e.g., through a network adapter.
- the computing device 800 may be implemented in a number of different forms, as shown in the figure. For example, it may be implemented as a standard server 830 , or multiple times in a group of such servers. It may also be implemented as part of a rack server system. In addition, it may be implemented in a computing device, such as a laptop computer 832 , personal computer 834 , or tablet/smart phone 836 . An entire system may be made up of multiple computing devices 800 communicating with each other. Other configurations are possible.
- FIG. 9 shows an example of a generic computer device 900 , which may be server 170 of FIG. 1 , which may be used with the techniques described here.
- Computing device 900 is intended to represent various example forms of large-scale data processing devices, such as servers, blade servers, datacenters, mainframes, and other large-scale computing devices.
- Computing device 900 may be a distributed system having multiple processors, possibly including network attached storage nodes, that are interconnected by one or more communication networks.
- the components shown here, their connections and relationships, and their functions, are meant to be examples only, and are not meant to limit implementations of the inventions described and/or claimed in this document.
- Distributed computing system 900 may include any number of computing devices 980 .
- Computing devices 980 may include a server or rack servers, mainframes, etc. communicating over a local or wide-area network, dedicated optical links, modems, bridges, routers, switches, wired or wireless networks, etc.
- each computing device may include multiple racks.
- computing device 980 a includes multiple racks 958 a - 958 n .
- Each rack may include one or more processors, such as processors 952 a - 952 n and 962 a - 962 n .
- the processors may include data processors, network attached storage devices, and other computer controlled devices.
- one processor may operate as a master processor and control the scheduling and data distribution tasks.
- Processors may be interconnected through one or more rack switches 958 , and one or more racks may be connected through switch 978 .
- Switch 978 may handle communications between multiple connected computing devices 900 .
- Each rack may include memory, such as memory 954 and memory 964 , and storage, such as 956 and 966 .
- Storage 956 and 966 may provide mass storage and may include volatile or non-volatile storage, such as network-attached disks, floppy disks, hard disks, optical disks, tapes, flash memory or other similar solid state memory devices, or an array of devices, including devices in a storage area network or other configurations.
- Storage 956 or 966 may be shared between multiple processors, multiple racks, or multiple computing devices and may include a computer-readable medium storing instructions executable by one or more of the processors.
- Memory 954 and 964 may include, e.g., volatile memory unit or units, a non-volatile memory unit or units, and/or other forms of computer-readable media, such as a magnetic or optical disks, flash memory, cache, Random Access Memory (RAM), Read Only Memory (ROM), and combinations thereof. Memory, such as memory 954 may also be shared between processors 952 a - 952 n . Data structures, such as an index, may be stored, for example, across storage 956 and memory 954 . Computing device 900 may include other components not shown, such as controllers, buses, input/output devices, communications modules, etc.
- An entire system such as system 100 , may be made up of multiple computing devices 900 communicating with each other.
- device 980 a may communicate with devices 980 b , 980 c , and 980 d , and these may collectively be known as system 100 .
- system 100 of FIG. 1 may include one or more computing devices 900 . Some of the computing devices may be located geographically close to each other, and others may be located geographically distant.
- the layout of system 900 is an example only and the system may take on other layouts or configurations.
- a mobile device comprises at least one processor and memory storing instructions that, when executed by the at least one processor, cause the mobile device to perform operations.
- the operations may include identifying a personal entity in content generated for display on the mobile device, generating training examples for the personal entity from the content, and updating an embedding used to model the personal entity using the training examples.
- the personal entity may be personal to the user of the mobile device.
- the embedding may be used to make predictions regarding the personal entity.
- the personal entity may be identified based on location in a sender or recipient field of a message.
- identifying the personal entity can include identifying an n-gram in the content and determining that a frequency of occurrence for the n-gram in private-content applications meets or exceeds a threshold.
- identifying the personal entity can include determining whether the personal entity is present in a personal knowledge base and assigning the personal entity an initial embedding when the personal entity does not exist in the personal knowledge base.
- the content is first content and the memory further stores instructions that cause the mobile device to identify input provided by a user of the mobile device, the input being associated with second content displayed on the mobile device, determine completions for the input, the completions including the personal entity based on the second content, rank the completions, the rank of the personal entity accounting for a score determined by the embedding for the personal entity given the second content, and provide highest ranked completions for display on the mobile device.
- generating the training examples include, for a set of other personal entities identified in the content, generating a prediction between the set and the personal entity.
- generating the training examples include, for public entities identified in the content, generating a prediction between the public entity and the personal entity.
- the personal entity is a first personal entity and generating the training examples include, for a second personal entity and a public entity identified in the content, generating a prediction between the second personal entity and the public entity and the first personal entity.
- the content generated for display includes content generated during a window of time.
- a method includes identifying a first personal entity in content generated for display on a computing device, the first personal entity being associated with an embedding in a personal knowledge base associated with a user of the computing device, predicting an association between the first personal entity and a second entity based on the embedding, and providing a recommendation related to the second entity, the recommendation to be displayed on the computing device.
- the recommendation may be an advertisement related to the second entity.
- the second entity represents a topic and recommendation is a third personal entity associated with the second entity.
- displaying the recommendation can include suggesting sharing the content with the third personal entity.
- the content may include a message and the recommendation can be an invitation for the third personal entity to view the message.
- the second entity may represent a context and displaying the recommendation can include suggesting an action that includes the first personal entity and the context.
- the context is a time and the action is a reservation related to the first personal entity.
- a computing system includes at least one processor, a display device, memory storing a personal knowledge base, the personal knowledge base modeling personal entities as embeddings and memory storing instructions that, when executed by the at least one processor, cause the computing system to perform operations.
- the operations may include identifying features in content generated for display on the display device, identifying a personal entity predicted by the features using an embedding for the personal entity in the personal knowledge base, and providing a recommendation related to the personal entity, the recommendation to be displayed on the display device.
- the recommendation may be an action involving the personal entity or a suggestion to share the content associated with a current screen with the personal entity.
- the content generated for display may be generated by a first application and the recommendation is a suggestion to open a second application.
- the second application may not be installed on the computing device and the suggestion may include installing the second application.
- the recommendation is a completion for an input control prior to receiving input from a user in the input control.
- Various implementations can include implementation in one or more computer programs that are executable and/or interpretable on a programmable system including at least one programmable processor, which may be special or general purpose, coupled to receive data and instructions from, and to transmit data and instructions to, a storage system, at least one input device, and at least one output device.
- a programmable processor which may be special or general purpose, coupled to receive data and instructions from, and to transmit data and instructions to, a storage system, at least one input device, and at least one output device.
- the systems and techniques described here can be implemented in a computing system that includes a back end component (e.g., as a data server), or that includes a middleware component (e.g., an application server), or that includes a front end component (e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the systems and techniques described here), or any combination of such back end, middleware, or front end components.
- the components of the system can be interconnected by any form or medium of digital data communication (e.g., a communication network). Examples of communication networks include a local area network (“LAN”), a wide area network (“WAN”), and the Internet.
- LAN local area network
- WAN wide area network
- the Internet the global information network
- the computing system can include clients and servers.
- a client and server are generally remote from each other and typically interact through a communication network.
- the relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other.
Abstract
Description
Claims (21)
Priority Applications (10)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/812,877 US10803391B2 (en) | 2015-07-29 | 2015-07-29 | Modeling personal entities on a mobile device using embeddings |
JP2017556890A JP6882988B2 (en) | 2015-07-29 | 2016-07-28 | Modeling personal entities |
GB1717801.3A GB2553994A (en) | 2015-07-29 | 2016-07-28 | Modeling personal entities |
DE112016003112.2T DE112016003112T5 (en) | 2015-07-29 | 2016-07-28 | Modeling personal entities |
RU2017137748A RU2017137748A (en) | 2015-07-29 | 2016-07-28 | MODELING PERSONAL OBJECTS |
EP16751408.2A EP3295329A1 (en) | 2015-07-29 | 2016-07-28 | Modeling personal entities |
KR1020197033842A KR102189854B1 (en) | 2015-07-29 | 2016-07-28 | Modeling personal entities |
PCT/US2016/044464 WO2017019861A1 (en) | 2015-07-29 | 2016-07-28 | Modeling personal entities |
CN201680025098.3A CN107851092B (en) | 2015-07-29 | 2016-07-28 | Personal entity modeling |
KR1020177031186A KR102048029B1 (en) | 2015-07-29 | 2016-07-28 | Model personal entities |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/812,877 US10803391B2 (en) | 2015-07-29 | 2015-07-29 | Modeling personal entities on a mobile device using embeddings |
Publications (2)
Publication Number | Publication Date |
---|---|
US20170032257A1 US20170032257A1 (en) | 2017-02-02 |
US10803391B2 true US10803391B2 (en) | 2020-10-13 |
Family
ID=56684743
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US14/812,877 Active 2038-10-23 US10803391B2 (en) | 2015-07-29 | 2015-07-29 | Modeling personal entities on a mobile device using embeddings |
Country Status (9)
Country | Link |
---|---|
US (1) | US10803391B2 (en) |
EP (1) | EP3295329A1 (en) |
JP (1) | JP6882988B2 (en) |
KR (2) | KR102048029B1 (en) |
CN (1) | CN107851092B (en) |
DE (1) | DE112016003112T5 (en) |
GB (1) | GB2553994A (en) |
RU (1) | RU2017137748A (en) |
WO (1) | WO2017019861A1 (en) |
Cited By (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20200142935A1 (en) * | 2018-11-05 | 2020-05-07 | Samsung Electronics Co., Ltd. | System and method for cross-domain recommendations |
CN113298253A (en) * | 2021-06-03 | 2021-08-24 | 清华大学 | Model training method, recognition method and device for named entity recognition |
Families Citing this family (67)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20140156901A1 (en) | 2005-10-26 | 2014-06-05 | Cortica Ltd. | Computing device, a system and a method for parallel processing of data streams |
US11604847B2 (en) | 2005-10-26 | 2023-03-14 | Cortica Ltd. | System and method for overlaying content on a multimedia content element based on user interest |
US20160085733A1 (en) | 2005-10-26 | 2016-03-24 | Cortica, Ltd. | System and method thereof for dynamically associating a link to an information resource with a multimedia content displayed in a web-page |
US11361014B2 (en) | 2005-10-26 | 2022-06-14 | Cortica Ltd. | System and method for completing a user profile |
US11403336B2 (en) | 2005-10-26 | 2022-08-02 | Cortica Ltd. | System and method for removing contextually identical multimedia content elements |
US9646005B2 (en) | 2005-10-26 | 2017-05-09 | Cortica, Ltd. | System and method for creating a database of multimedia content elements assigned to users |
US10848590B2 (en) | 2005-10-26 | 2020-11-24 | Cortica Ltd | System and method for determining a contextual insight and providing recommendations based thereon |
US8326775B2 (en) | 2005-10-26 | 2012-12-04 | Cortica Ltd. | Signature generation for multimedia deep-content-classification by a large-scale matching system and method thereof |
US10742340B2 (en) | 2005-10-26 | 2020-08-11 | Cortica Ltd. | System and method for identifying the context of multimedia content elements displayed in a web-page and providing contextual filters respective thereto |
US10949773B2 (en) | 2005-10-26 | 2021-03-16 | Cortica, Ltd. | System and methods thereof for recommending tags for multimedia content elements based on context |
US11620327B2 (en) | 2005-10-26 | 2023-04-04 | Cortica Ltd | System and method for determining a contextual insight and generating an interface with recommendations based thereon |
US11032017B2 (en) | 2005-10-26 | 2021-06-08 | Cortica, Ltd. | System and method for identifying the context of multimedia content elements |
US11019161B2 (en) | 2005-10-26 | 2021-05-25 | Cortica, Ltd. | System and method for profiling users interest based on multimedia content analysis |
US11386139B2 (en) | 2005-10-26 | 2022-07-12 | Cortica Ltd. | System and method for generating analytics for entities depicted in multimedia content |
US11216498B2 (en) | 2005-10-26 | 2022-01-04 | Cortica, Ltd. | System and method for generating signatures to three-dimensional multimedia data elements |
US20160321253A1 (en) | 2005-10-26 | 2016-11-03 | Cortica, Ltd. | System and method for providing recommendations based on user profiles |
US11537636B2 (en) | 2007-08-21 | 2022-12-27 | Cortica, Ltd. | System and method for using multimedia content as search queries |
US10803391B2 (en) | 2015-07-29 | 2020-10-13 | Google Llc | Modeling personal entities on a mobile device using embeddings |
US10241754B1 (en) * | 2015-09-29 | 2019-03-26 | Amazon Technologies, Inc. | Systems and methods for providing supplemental information with a response to a command |
US11195043B2 (en) | 2015-12-15 | 2021-12-07 | Cortica, Ltd. | System and method for determining common patterns in multimedia content elements based on key points |
US11037015B2 (en) | 2015-12-15 | 2021-06-15 | Cortica Ltd. | Identification of key points in multimedia data elements |
US11210583B2 (en) * | 2016-07-20 | 2021-12-28 | Apple Inc. | Using proxies to enable on-device machine learning |
US10841257B1 (en) * | 2016-10-25 | 2020-11-17 | Twitter, Inc. | Determining engagement scores for sub-categories in a digital domain by a computing system |
US11153234B2 (en) * | 2017-03-31 | 2021-10-19 | Microsoft Technology Licensing, Llc | Providing new recommendation in automated chatting |
US11074280B2 (en) | 2017-05-18 | 2021-07-27 | Aiqudo, Inc | Cluster based search and recommendation method to rapidly on-board commands in personal assistants |
WO2018214164A1 (en) * | 2017-05-26 | 2018-11-29 | Microsoft Technology Licensing, Llc | Recommending friends in automated chatting |
WO2019008581A1 (en) | 2017-07-05 | 2019-01-10 | Cortica Ltd. | Driving policies determination |
US11899707B2 (en) | 2017-07-09 | 2024-02-13 | Cortica Ltd. | Driving policies determination |
US11361383B1 (en) * | 2017-09-06 | 2022-06-14 | United Services Automobile Association (Usaa) | Simplified interactive user interface |
US11216745B2 (en) | 2017-11-07 | 2022-01-04 | Google Llc | Incognito mode for personalized machine-learned models |
US11422996B1 (en) * | 2018-04-26 | 2022-08-23 | Snap Inc. | Joint embedding content neural networks |
CN108959461B (en) * | 2018-06-15 | 2021-07-27 | 东南大学 | Entity linking method based on graph model |
US10887655B2 (en) * | 2018-06-27 | 2021-01-05 | Microsoft Technology Licensing, Llc | Cluster-based collaborative filtering |
US10846544B2 (en) | 2018-07-16 | 2020-11-24 | Cartica Ai Ltd. | Transportation prediction system and method |
US10706308B2 (en) * | 2018-08-07 | 2020-07-07 | Accenture Global Solutions Limited | Image processing for automated object identification |
US11613261B2 (en) | 2018-09-05 | 2023-03-28 | Autobrains Technologies Ltd | Generating a database and alerting about improperly driven vehicles |
US11526670B2 (en) * | 2018-09-28 | 2022-12-13 | The Mitre Corporation | Machine learning of colloquial place names |
US20200133308A1 (en) | 2018-10-18 | 2020-04-30 | Cartica Ai Ltd | Vehicle to vehicle (v2v) communication less truck platooning |
US10839694B2 (en) | 2018-10-18 | 2020-11-17 | Cartica Ai Ltd | Blind spot alert |
US10748038B1 (en) | 2019-03-31 | 2020-08-18 | Cortica Ltd. | Efficient calculation of a robust signature of a media unit |
US11270132B2 (en) | 2018-10-26 | 2022-03-08 | Cartica Ai Ltd | Vehicle to vehicle communication and signatures |
US11392738B2 (en) | 2018-10-26 | 2022-07-19 | Autobrains Technologies Ltd | Generating a simulation scenario |
US11904863B2 (en) | 2018-10-26 | 2024-02-20 | AutoBrains Technologies Ltd. | Passing a curve |
US10789535B2 (en) | 2018-11-26 | 2020-09-29 | Cartica Ai Ltd | Detection of road elements |
US11669431B2 (en) * | 2019-01-11 | 2023-06-06 | Google Llc | Analytics personalization framework |
CN109767301B (en) * | 2019-01-14 | 2021-05-07 | 北京大学 | Recommendation method and system, computer device and computer readable storage medium |
US11170647B2 (en) | 2019-02-07 | 2021-11-09 | Cartica Ai Ltd. | Detection of vacant parking spaces |
US11643005B2 (en) | 2019-02-27 | 2023-05-09 | Autobrains Technologies Ltd | Adjusting adjustable headlights of a vehicle |
US11285963B2 (en) | 2019-03-10 | 2022-03-29 | Cartica Ai Ltd. | Driver-based prediction of dangerous events |
US11694088B2 (en) | 2019-03-13 | 2023-07-04 | Cortica Ltd. | Method for object detection using knowledge distillation |
US11132548B2 (en) | 2019-03-20 | 2021-09-28 | Cortica Ltd. | Determining object information that does not explicitly appear in a media unit signature |
US11908242B2 (en) | 2019-03-31 | 2024-02-20 | Cortica Ltd. | Efficient calculation of a robust signature of a media unit |
US11222069B2 (en) | 2019-03-31 | 2022-01-11 | Cortica Ltd. | Low-power calculation of a signature of a media unit |
US10776669B1 (en) | 2019-03-31 | 2020-09-15 | Cortica Ltd. | Signature generation and object detection that refer to rare scenes |
US11397742B2 (en) | 2019-06-21 | 2022-07-26 | Microsoft Technology Licensing, Llc | Rescaling layer in neural network |
US11204968B2 (en) * | 2019-06-21 | 2021-12-21 | Microsoft Technology Licensing, Llc | Embedding layer in neural network for ranking candidates |
US11704292B2 (en) | 2019-09-26 | 2023-07-18 | Cortica Ltd. | System and method for enriching a concept database |
KR20210045891A (en) * | 2019-10-17 | 2021-04-27 | 삼성전자주식회사 | Electronic device and method for controlling and operating of screen capture |
US11593662B2 (en) | 2019-12-12 | 2023-02-28 | Autobrains Technologies Ltd | Unsupervised cluster generation |
US11590988B2 (en) | 2020-03-19 | 2023-02-28 | Autobrains Technologies Ltd | Predictive turning assistant |
US11827215B2 (en) | 2020-03-31 | 2023-11-28 | AutoBrains Technologies Ltd. | Method for training a driving related object detector |
US11347780B2 (en) * | 2020-04-30 | 2022-05-31 | Intuit Inc. | System and method for automatic suggestion and or correcting of search keywords |
US11321785B2 (en) | 2020-04-30 | 2022-05-03 | Intuit Inc. | System and method for providing global tag suggestions based on user information and transaction data |
CN111710011B (en) * | 2020-06-10 | 2021-06-25 | 广州梦映动漫网络科技有限公司 | Cartoon generation method and system, electronic device and medium |
US11687833B2 (en) * | 2020-08-27 | 2023-06-27 | Google Llc | Data management forecasting from distributed tracing |
US11790172B2 (en) * | 2020-09-18 | 2023-10-17 | Microsoft Technology Licensing, Llc | Systems and methods for identifying entities and constraints in natural language input |
US20230091581A1 (en) * | 2021-09-21 | 2023-03-23 | Bank Of America Corporation | Personal Data Discovery |
Citations (60)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
WO2003088080A1 (en) | 2002-04-05 | 2003-10-23 | At & T Corp. | Method and system for detecting and extracting named entities from spontaneous communications |
US20040058694A1 (en) * | 2000-12-08 | 2004-03-25 | Dennis Mendiola | Messaging system involving wireless communications and methods therefor |
US20060031310A1 (en) * | 2004-05-21 | 2006-02-09 | Lee Jacob J | Messaging protocol for processing messages with attachments |
US20060095653A1 (en) * | 2004-11-03 | 2006-05-04 | Fleming James S | Network of networks of associative memory networks for knowledge management |
US20060235873A1 (en) * | 2003-10-22 | 2006-10-19 | Jookster Networks, Inc. | Social network-based internet search engine |
US20070081197A1 (en) * | 2001-06-22 | 2007-04-12 | Nosa Omoigui | System and method for semantic knowledge retrieval, management, capture, sharing, discovery, delivery and presentation |
US20070168379A1 (en) * | 2006-01-17 | 2007-07-19 | Patel Sushma B | Method and apparatus for cataloging screen shots of a program |
US20080109714A1 (en) * | 2006-11-03 | 2008-05-08 | Sap Ag | Capturing screen information |
US20080120385A1 (en) * | 2006-11-17 | 2008-05-22 | Comverse Ltd. | Method and system for generating a referencing secondary electronic mail message from a primary electronic mail message |
WO2009052308A1 (en) | 2007-10-17 | 2009-04-23 | Roseman Neil S | Nlp-based content recommender |
US20090216696A1 (en) * | 2008-02-25 | 2009-08-27 | Downs Oliver B | Determining relevant information for domains of interest |
US20090282012A1 (en) * | 2008-05-05 | 2009-11-12 | Microsoft Corporation | Leveraging cross-document context to label entity |
US20100114561A1 (en) * | 2007-04-02 | 2010-05-06 | Syed Yasin | Latent metonymical analysis and indexing (lmai) |
US20100153324A1 (en) * | 2008-12-12 | 2010-06-17 | Downs Oliver B | Providing recommendations using information determined for domains of interest |
JP2010217973A (en) | 2009-03-13 | 2010-09-30 | Toshiba Corp | Member keyword relation display |
US20100293247A1 (en) * | 2009-05-18 | 2010-11-18 | Verizon Patent And Licensing Inc. | Application of social networking data |
US20110072052A1 (en) * | 2008-05-28 | 2011-03-24 | Aptima Inc. | Systems and methods for analyzing entity profiles |
US7917943B1 (en) * | 2006-12-01 | 2011-03-29 | Goodmail Systems, Inc. | E-mail Stamping with accredited entity name |
WO2012017787A1 (en) | 2010-08-06 | 2012-02-09 | 日本電気株式会社 | Communication assistance device, method of assisting communication, and computer readable recording medium |
US20120166182A1 (en) * | 2009-06-03 | 2012-06-28 | Ko David H | Autocompletion for Partially Entered Query |
US8326792B2 (en) | 2001-04-30 | 2012-12-04 | Theory Garden, LLC | Adaptive dynamic personal modeling system and method |
US20130060866A1 (en) * | 2011-09-07 | 2013-03-07 | Elwha LLC, a limited liability company of the State of Delaware | Computational systems and methods for identifying a communications partner |
US20130097269A1 (en) * | 2010-09-24 | 2013-04-18 | Yagi Corp. | Context-Sensitive Auto-Responder |
US20130110671A1 (en) * | 2011-06-22 | 2013-05-02 | Beau Gray | Methods and systems for online shopping incorporating dashboard features |
US20130346069A1 (en) * | 2012-06-15 | 2013-12-26 | Canon Kabushiki Kaisha | Method and apparatus for identifying a mentioned person in a dialog |
US20140006962A1 (en) * | 2012-06-28 | 2014-01-02 | Sap Ag | Consistent Interface for Document Output Request |
US20140032358A1 (en) * | 2012-07-25 | 2014-01-30 | Aro, Inc. | Sharing Recommendation Agents |
JP2014032434A (en) | 2012-08-01 | 2014-02-20 | Sony Corp | Information processing device, information processing method and information processing system |
US20140052540A1 (en) * | 2012-08-20 | 2014-02-20 | Giridhar Rajaram | Providing content using inferred topics extracted from communications in a social networking system |
US20140059130A1 (en) * | 2012-08-22 | 2014-02-27 | Mainsoft R&D Ltd. | System and method for updating connections in social networks |
JP2014048689A (en) | 2012-08-29 | 2014-03-17 | Konica Minolta Inc | Retrieval support system, retrieval support method, and computer program |
US20140095629A1 (en) * | 2012-10-02 | 2014-04-03 | Thinkpuddle Inc. | Systems and Methods for Organizing Events |
US8719191B2 (en) | 2010-03-01 | 2014-05-06 | International Business Machines Corporation | Training and verification using a correlated boosted entity model |
US20140181705A1 (en) * | 2012-12-21 | 2014-06-26 | International Business Machines Corporation | Automated screen captures |
US20140282136A1 (en) * | 2013-03-14 | 2014-09-18 | Microsoft Corporation | Query intent expression for search in an embedded application context |
US20140282081A1 (en) * | 2013-03-15 | 2014-09-18 | Sap Ag | Consistent Interface for Email Activity Business Object |
JP2014528112A (en) | 2011-07-29 | 2014-10-23 | マイクロソフト コーポレーション | Query suggestions run on social networks (powered) |
US20140324898A1 (en) * | 2013-04-24 | 2014-10-30 | Industrial Technology Research Institute | System and method for searching aliases associated with an entity |
US20150033150A1 (en) * | 2013-07-24 | 2015-01-29 | Lg Electronics Inc. | Digital device and control method thereof |
US8949358B2 (en) | 2012-10-25 | 2015-02-03 | Palo Alto Research Center Incorporated | Method and system for building an entity profile from email address and name information |
US20150046436A1 (en) * | 2013-08-07 | 2015-02-12 | Facebook, Inc. | Real-time trend detection in a social network |
US8983826B2 (en) | 2011-06-30 | 2015-03-17 | Palo Alto Research Center Incorporated | Method and system for extracting shadow entities from emails |
US20150088660A1 (en) * | 2013-09-25 | 2015-03-26 | MeetUsUp, Inc. | Device, System, and Method of Soliciting and Accepting Offers from Merchant Members of a Virtual Network |
CN104598617A (en) | 2015-01-30 | 2015-05-06 | 百度在线网络技术（北京）有限公司 | Method and device for displaying search results |
CN104636466A (en) | 2015-02-11 | 2015-05-20 | 中国科学院计算技术研究所 | Entity attribute extraction method and system oriented to open web page |
US9129227B1 (en) * | 2012-12-31 | 2015-09-08 | Google Inc. | Methods, systems, and media for recommending content items based on topics |
US20150256491A1 (en) * | 2014-03-04 | 2015-09-10 | Microsoft Corporation | Recipient suggestion system |
US20150269242A1 (en) * | 2014-03-20 | 2015-09-24 | Tata Consultancy Services Limited | Email analytics |
US20150331711A1 (en) * | 2014-05-19 | 2015-11-19 | Qualcomm Incorporated | Systems and methods for context-aware application control |
US9202203B2 (en) * | 2012-01-06 | 2015-12-01 | National Central University | Method for classifying email |
US20150347381A1 (en) * | 2014-05-30 | 2015-12-03 | Apple Inc. | Entropy-guided text prediction using combined word and character n-gram language models |
US20150370787A1 (en) * | 2014-06-18 | 2015-12-24 | Microsoft Corporation | Session Context Modeling For Conversational Understanding Systems |
US20160006730A1 (en) * | 2014-07-07 | 2016-01-07 | International Business Machines Corporation | Correlating cognitive biometrics for continuous identify verification |
US20160048760A1 (en) * | 2014-08-13 | 2016-02-18 | International Business Machines Corporation | Natural language management of online social network connections |
US20160055246A1 (en) * | 2014-08-21 | 2016-02-25 | Google Inc. | Providing automatic actions for mobile onscreen content |
US20160094654A1 (en) * | 2014-09-30 | 2016-03-31 | Google Inc. | Mobile application state identifier framework |
US20160110343A1 (en) * | 2014-10-21 | 2016-04-21 | At&T Intellectual Property I, L.P. | Unsupervised topic modeling for short texts |
US20160241493A1 (en) * | 2015-02-12 | 2016-08-18 | Google Inc. | Determining reply content for a reply to an electronic communication |
US20170004134A1 (en) * | 2015-07-03 | 2017-01-05 | Microsoft Technology Licensing, Llc | Asynchronous search query |
US20170032257A1 (en) | 2015-07-29 | 2017-02-02 | Google Inc. | Modeling personal entities |
Family Cites Families (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US8185492B2 (en) * | 2008-08-14 | 2012-05-22 | Google Inc. | Messaging application with multiple viewports for presenting messages in different orders |
KR101994987B1 (en) * | 2012-02-22 | 2019-09-30 | 구글 엘엘씨 | Related entities |
-
2015
- 2015-07-29 US US14/812,877 patent/US10803391B2/en active Active
-
2016
- 2016-07-28 EP EP16751408.2A patent/EP3295329A1/en not_active Withdrawn
- 2016-07-28 DE DE112016003112.2T patent/DE112016003112T5/en active Pending
- 2016-07-28 KR KR1020177031186A patent/KR102048029B1/en active IP Right Grant
- 2016-07-28 RU RU2017137748A patent/RU2017137748A/en not_active Application Discontinuation
- 2016-07-28 GB GB1717801.3A patent/GB2553994A/en not_active Withdrawn
- 2016-07-28 JP JP2017556890A patent/JP6882988B2/en active Active
- 2016-07-28 KR KR1020197033842A patent/KR102189854B1/en active IP Right Grant
- 2016-07-28 WO PCT/US2016/044464 patent/WO2017019861A1/en active Application Filing
- 2016-07-28 CN CN201680025098.3A patent/CN107851092B/en active Active
Patent Citations (63)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20040058694A1 (en) * | 2000-12-08 | 2004-03-25 | Dennis Mendiola | Messaging system involving wireless communications and methods therefor |
US8326792B2 (en) | 2001-04-30 | 2012-12-04 | Theory Garden, LLC | Adaptive dynamic personal modeling system and method |
US20070081197A1 (en) * | 2001-06-22 | 2007-04-12 | Nosa Omoigui | System and method for semantic knowledge retrieval, management, capture, sharing, discovery, delivery and presentation |
WO2003088080A1 (en) | 2002-04-05 | 2003-10-23 | At & T Corp. | Method and system for detecting and extracting named entities from spontaneous communications |
US20060235873A1 (en) * | 2003-10-22 | 2006-10-19 | Jookster Networks, Inc. | Social network-based internet search engine |
US20060031310A1 (en) * | 2004-05-21 | 2006-02-09 | Lee Jacob J | Messaging protocol for processing messages with attachments |
US20060095653A1 (en) * | 2004-11-03 | 2006-05-04 | Fleming James S | Network of networks of associative memory networks for knowledge management |
US20070168379A1 (en) * | 2006-01-17 | 2007-07-19 | Patel Sushma B | Method and apparatus for cataloging screen shots of a program |
US20080109714A1 (en) * | 2006-11-03 | 2008-05-08 | Sap Ag | Capturing screen information |
US20080120385A1 (en) * | 2006-11-17 | 2008-05-22 | Comverse Ltd. | Method and system for generating a referencing secondary electronic mail message from a primary electronic mail message |
US7917943B1 (en) * | 2006-12-01 | 2011-03-29 | Goodmail Systems, Inc. | E-mail Stamping with accredited entity name |
US20100114561A1 (en) * | 2007-04-02 | 2010-05-06 | Syed Yasin | Latent metonymical analysis and indexing (lmai) |
WO2009052308A1 (en) | 2007-10-17 | 2009-04-23 | Roseman Neil S | Nlp-based content recommender |
US20090150388A1 (en) | 2007-10-17 | 2009-06-11 | Neil Roseman | NLP-based content recommender |
US20140229467A1 (en) * | 2007-10-17 | 2014-08-14 | Vulcan Inc. | Nlp-based content recommender |
US20090216696A1 (en) * | 2008-02-25 | 2009-08-27 | Downs Oliver B | Determining relevant information for domains of interest |
US20090282012A1 (en) * | 2008-05-05 | 2009-11-12 | Microsoft Corporation | Leveraging cross-document context to label entity |
US20110072052A1 (en) * | 2008-05-28 | 2011-03-24 | Aptima Inc. | Systems and methods for analyzing entity profiles |
US20100153324A1 (en) * | 2008-12-12 | 2010-06-17 | Downs Oliver B | Providing recommendations using information determined for domains of interest |
JP2010217973A (en) | 2009-03-13 | 2010-09-30 | Toshiba Corp | Member keyword relation display |
US20100293247A1 (en) * | 2009-05-18 | 2010-11-18 | Verizon Patent And Licensing Inc. | Application of social networking data |
US20120166182A1 (en) * | 2009-06-03 | 2012-06-28 | Ko David H | Autocompletion for Partially Entered Query |
US8719191B2 (en) | 2010-03-01 | 2014-05-06 | International Business Machines Corporation | Training and verification using a correlated boosted entity model |
WO2012017787A1 (en) | 2010-08-06 | 2012-02-09 | 日本電気株式会社 | Communication assistance device, method of assisting communication, and computer readable recording medium |
US20130097269A1 (en) * | 2010-09-24 | 2013-04-18 | Yagi Corp. | Context-Sensitive Auto-Responder |
US20130110671A1 (en) * | 2011-06-22 | 2013-05-02 | Beau Gray | Methods and systems for online shopping incorporating dashboard features |
US8983826B2 (en) | 2011-06-30 | 2015-03-17 | Palo Alto Research Center Incorporated | Method and system for extracting shadow entities from emails |
JP2014528112A (en) | 2011-07-29 | 2014-10-23 | マイクロソフト コーポレーション | Query suggestions run on social networks (powered) |
US20130060866A1 (en) * | 2011-09-07 | 2013-03-07 | Elwha LLC, a limited liability company of the State of Delaware | Computational systems and methods for identifying a communications partner |
US9202203B2 (en) * | 2012-01-06 | 2015-12-01 | National Central University | Method for classifying email |
US20130346069A1 (en) * | 2012-06-15 | 2013-12-26 | Canon Kabushiki Kaisha | Method and apparatus for identifying a mentioned person in a dialog |
US20140006962A1 (en) * | 2012-06-28 | 2014-01-02 | Sap Ag | Consistent Interface for Document Output Request |
US20140032358A1 (en) * | 2012-07-25 | 2014-01-30 | Aro, Inc. | Sharing Recommendation Agents |
JP2014032434A (en) | 2012-08-01 | 2014-02-20 | Sony Corp | Information processing device, information processing method and information processing system |
US20140052540A1 (en) * | 2012-08-20 | 2014-02-20 | Giridhar Rajaram | Providing content using inferred topics extracted from communications in a social networking system |
US20140059130A1 (en) * | 2012-08-22 | 2014-02-27 | Mainsoft R&D Ltd. | System and method for updating connections in social networks |
JP5954053B2 (en) | 2012-08-29 | 2016-07-20 | コニカミノルタ株式会社 | Search support system, search support method, and computer program |
JP2014048689A (en) | 2012-08-29 | 2014-03-17 | Konica Minolta Inc | Retrieval support system, retrieval support method, and computer program |
US20140095629A1 (en) * | 2012-10-02 | 2014-04-03 | Thinkpuddle Inc. | Systems and Methods for Organizing Events |
US8949358B2 (en) | 2012-10-25 | 2015-02-03 | Palo Alto Research Center Incorporated | Method and system for building an entity profile from email address and name information |
US20140181705A1 (en) * | 2012-12-21 | 2014-06-26 | International Business Machines Corporation | Automated screen captures |
US9129227B1 (en) * | 2012-12-31 | 2015-09-08 | Google Inc. | Methods, systems, and media for recommending content items based on topics |
US20140282136A1 (en) * | 2013-03-14 | 2014-09-18 | Microsoft Corporation | Query intent expression for search in an embedded application context |
US20140282081A1 (en) * | 2013-03-15 | 2014-09-18 | Sap Ag | Consistent Interface for Email Activity Business Object |
US20140324898A1 (en) * | 2013-04-24 | 2014-10-30 | Industrial Technology Research Institute | System and method for searching aliases associated with an entity |
US20150033150A1 (en) * | 2013-07-24 | 2015-01-29 | Lg Electronics Inc. | Digital device and control method thereof |
US20150046436A1 (en) * | 2013-08-07 | 2015-02-12 | Facebook, Inc. | Real-time trend detection in a social network |
US20150088660A1 (en) * | 2013-09-25 | 2015-03-26 | MeetUsUp, Inc. | Device, System, and Method of Soliciting and Accepting Offers from Merchant Members of a Virtual Network |
US20150256491A1 (en) * | 2014-03-04 | 2015-09-10 | Microsoft Corporation | Recipient suggestion system |
US20150269242A1 (en) * | 2014-03-20 | 2015-09-24 | Tata Consultancy Services Limited | Email analytics |
US20150331711A1 (en) * | 2014-05-19 | 2015-11-19 | Qualcomm Incorporated | Systems and methods for context-aware application control |
US20150347381A1 (en) * | 2014-05-30 | 2015-12-03 | Apple Inc. | Entropy-guided text prediction using combined word and character n-gram language models |
US20150370787A1 (en) * | 2014-06-18 | 2015-12-24 | Microsoft Corporation | Session Context Modeling For Conversational Understanding Systems |
US20160006730A1 (en) * | 2014-07-07 | 2016-01-07 | International Business Machines Corporation | Correlating cognitive biometrics for continuous identify verification |
US20160048760A1 (en) * | 2014-08-13 | 2016-02-18 | International Business Machines Corporation | Natural language management of online social network connections |
US20160055246A1 (en) * | 2014-08-21 | 2016-02-25 | Google Inc. | Providing automatic actions for mobile onscreen content |
US20160094654A1 (en) * | 2014-09-30 | 2016-03-31 | Google Inc. | Mobile application state identifier framework |
US20160110343A1 (en) * | 2014-10-21 | 2016-04-21 | At&T Intellectual Property I, L.P. | Unsupervised topic modeling for short texts |
CN104598617A (en) | 2015-01-30 | 2015-05-06 | 百度在线网络技术（北京）有限公司 | Method and device for displaying search results |
CN104636466A (en) | 2015-02-11 | 2015-05-20 | 中国科学院计算技术研究所 | Entity attribute extraction method and system oriented to open web page |
US20160241493A1 (en) * | 2015-02-12 | 2016-08-18 | Google Inc. | Determining reply content for a reply to an electronic communication |
US20170004134A1 (en) * | 2015-07-03 | 2017-01-05 | Microsoft Technology Licensing, Llc | Asynchronous search query |
US20170032257A1 (en) | 2015-07-29 | 2017-02-02 | Google Inc. | Modeling personal entities |
Non-Patent Citations (24)
Title |
---|
Bogdanov, E. et al. (Apr. 2010). "Graaasp: a web 2.0 research platform for contextual recommendation with aggregated data". In CHI'10 Extended Abstracts on Human Factors in Computing Systems (pp. 3523-3528). ACM. (Year: 2010). * |
Chinese Patent Office; Office Action issued in Application No. 201680025098.3 dated Aug. 3, 2020. |
Collobert et al., "Natural Language Processing (Almost) from Scratch", Journal of Machine Learning Research, vol. 12, 2011, pp. 2493-2537. |
European Patent Office; Examination Report issued in Application No. 16751408.2 dated Mar. 21, 2019. |
European Patent Office; Summons in Application No. 16751408.2; 7 pages; dated Sep. 24, 2019. |
Fan, K. et al. (2014). "Unsupervised iterative manifold alignment via local feature histograms". IEEE Winter Conference on Applications of Computer Vision. IEEE, doi:http://dx.doi.org/10.1109/WACV.2014.6836051 (Year: 2014). * |
Fu, Z., et al. (Jun. 2015). "Zero-shot object recognition by semantic manifold distance". 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR): 2635-44;917. Jun. 7-12, 2015 IEEE. doi:http://dx.doi.org/10.1109/CVPR.2015.7298879 (Year: 2015). * |
Intellectual Property India; Office Action issue in Application No. 201747038439; 8 pages; dated Jun. 29, 2020. |
International Search Report and Written Opinion received for PCT Patent Application No. PCT/US2016/044464, dated Oct. 27, 2016, 13 pages. |
Japanese Patent Office; Office Action issued in Application No. 2017-556890 dated Dec. 17, 2018. |
Japanese Patent Office; Pre-Appeal Examination Report issued in Application No. 2017-556890, dated Sep. 17, 2019. |
Korean Patent Office; Notice of Allowance in Application No. 10-20177031186; 3 pages; dated Aug. 30, 2019. |
Mikolov et al., "Efficient Estimation of Word Representations in Vector Space", Sep. 7, 2013, pp. 1-12. |
Mikolov, T. et al. (2013). "Efficient Estimation of Word Representations in Vector Space". arXiv preprint arXiv:1301.3781 (Year: 2013). * |
Minkov et al., "Extracting Personal Names from Email: Applying Named Entity Recognition to Informal Text", Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing, Oct. 2005, pp. 443-450. |
Neelakantan, A. et al. (Apr. 25, 2015). "Learning dictionaries for named entity recognition using minimal supervision" [arXiv]. ArXiv, , 10 pp. Retrieved from arXiv:1504.06650v1 (Year: 2015). * |
Pan, S.J. et al. (2013). "Transfer joint embedding for cross-domain named entity recognition". ACM Transactions on Information Systems, 31(2), 7 (27 pp.). doi:http://dx.doi.org/10.1145/2457465.2457467 (Year: 2013). * |
Ramos, G.G.J. et al. (2015). "Embedded system for real-time person detecting in infrared images/videos using super-resolution and Haar-like feature techniques." 2015 12th International Conference on Electrical Engineering, Computing Science and Automatic Control (CCE). IEEE, Oct. 2015. (Year: 2015). * |
The Japanese Patent Office; Decision of Rejection issued in Application No. 2017-556890 dated Apr. 1, 2019. |
The Korean Intellectual Property Office; Office Action issued for Application No. 10-2019-7033842 dated Feb. 20, 2020 (72 Pages). |
The Korean Intellectual Property Office; Office Action issued in Application No. 10-2017-7031186 dated Jan. 31, 2019. |
Torki, M. et al. (2010). "Putting local features on a manifold". 2010 IEEE Conference on Computer Vision and Pattern Recognition (CVPR): 1743-50. IEEE. doi:http://dx.doi.org/10.1109/CVPR.2010.5539843 (Year: 2010). * |
Weston, J. et al. (2010). "Large scale image annotation: learning to rank with joint word-image ennbeddings". Machine Learning, vol. 81, Issue 1, pp. 21-35. First online Jul. 27, 2010. DOI: 10.1007/s10994-010-5198-3 (Year: 2010). * |
Xiong, H. (2009). "A unified framework for kernelization: The empirical kernel feature space". Proceedings of the 2009 Chinese Conference on Pattern Recognition. (CCPR 2009) and the First CJK Joint Workshop on Pattern Recognition (CJKPR): 5 . IEEE. doi:http://dx.doi.org/10.1109/CCPR.2009.5344130 (Year: 2009). * |
Cited By (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20200142935A1 (en) * | 2018-11-05 | 2020-05-07 | Samsung Electronics Co., Ltd. | System and method for cross-domain recommendations |
US11604844B2 (en) * | 2018-11-05 | 2023-03-14 | Samsung Electronics Co., Ltd. | System and method for cross-domain recommendations |
CN113298253A (en) * | 2021-06-03 | 2021-08-24 | 清华大学 | Model training method, recognition method and device for named entity recognition |
CN113298253B (en) * | 2021-06-03 | 2021-12-14 | 清华大学 | Model training method, recognition method and device for named entity recognition |
Also Published As
Publication number | Publication date |
---|---|
JP6882988B2 (en) | 2021-06-02 |
DE112016003112T5 (en) | 2018-04-12 |
GB201717801D0 (en) | 2017-12-13 |
KR20190130685A (en) | 2019-11-22 |
US20170032257A1 (en) | 2017-02-02 |
KR20170132271A (en) | 2017-12-01 |
JP2018523187A (en) | 2018-08-16 |
WO2017019861A1 (en) | 2017-02-02 |
EP3295329A1 (en) | 2018-03-21 |
CN107851092A (en) | 2018-03-27 |
KR102048029B1 (en) | 2019-11-22 |
KR102189854B1 (en) | 2020-12-11 |
RU2017137748A (en) | 2019-08-29 |
CN107851092B (en) | 2022-04-26 |
GB2553994A (en) | 2018-03-21 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US10803391B2 (en) | Modeling personal entities on a mobile device using embeddings | |
US11704136B1 (en) | Automatic reminders in a mobile environment | |
US11089457B2 (en) | Personalized entity repository | |
US9965559B2 (en) | Providing automatic actions for mobile onscreen content | |
US9183282B2 (en) | Methods and systems for inferring user attributes in a social networking system | |
US20180101540A1 (en) | Diversifying Media Search Results on Online Social Networks | |
AU2017324850A1 (en) | Similarity search using polysemous codes | |
US10540666B2 (en) | Method and system for updating an intent space and estimating intent based on an intent space | |
EP3306555A1 (en) | Diversifying media search results on online social networks | |
US10635661B2 (en) | Keyboard-based corrections for search queries on online social networks | |
CN110929122B (en) | Data processing method and device for data processing |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:SHARIFI, MATTHEW;PETROU, DAVID;KHAITAN, PRANAV;SIGNING DATES FROM 20150724 TO 20150727;REEL/FRAME:036215/0335 |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044129/0001Effective date: 20170929 |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: RESPONSE TO NON-FINAL OFFICE ACTION ENTERED AND FORWARDED TO EXAMINER |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: NON FINAL ACTION MAILED |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: RESPONSE TO NON-FINAL OFFICE ACTION ENTERED AND FORWARDED TO EXAMINER |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: FINAL REJECTION MAILED |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: DOCKETED NEW CASE - READY FOR EXAMINATION |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: AWAITING TC RESP., ISSUE FEE NOT PAID |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: PUBLICATIONS -- ISSUE FEE PAYMENT VERIFIED |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 4TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1551); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 4 |