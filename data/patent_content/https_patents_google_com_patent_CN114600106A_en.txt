CN114600106A - Embedded online federated learning - Google Patents
Embedded online federated learning Download PDFInfo
- Publication number
- CN114600106A CN114600106A CN201980101611.6A CN201980101611A CN114600106A CN 114600106 A CN114600106 A CN 114600106A CN 201980101611 A CN201980101611 A CN 201980101611A CN 114600106 A CN114600106 A CN 114600106A
- Authority
- CN
- China
- Prior art keywords
- computing device
- embedded
- client computing
- embedding
- user
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/60—Protecting data
- G06F21/62—Protecting access to data via a platform, e.g. using keys or access control rules
- G06F21/6218—Protecting access to data via a platform, e.g. using keys or access control rules to a system of files or objects, e.g. local or distributed file system or database
- G06F21/6245—Protecting personal data, e.g. for financial or medical purposes
- G06F21/6254—Protecting personal data, e.g. for financial or medical purposes by anonymising data, e.g. decorrelating personal data from the owner's identification
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N20/00—Machine learning
- G06N20/20—Ensemble learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/60—Protecting data
- G06F21/62—Protecting access to data via a platform, e.g. using keys or access control rules
- G06F21/6218—Protecting access to data via a platform, e.g. using keys or access control rules to a system of files or objects, e.g. local or distributed file system or database
- G06F21/6245—Protecting personal data, e.g. for financial or medical purposes
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/044—Recurrent networks, e.g. Hopfield networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/045—Combinations of networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
Abstract
The present disclosure provides for generating embeddings within a machine learning framework, such as a federated learning framework, in which a high-quality centralized model is trained with training data distributed over a large number of clients each having unreliable network connections and low computational power. In one example federated learning setting, in each of multiple rounds, each client independently updates the model based on its local data and transmits the updated model back to the server, with all client-side updates used to update the global model. The present disclosure provides systems and methods that may generate an embedding with local training data while protecting privacy of a user of a client device.
Description
Technical Field
The present disclosure relates generally to embedding of learning entities. More particularly, the present disclosure relates to privacy preserving federated learning techniques that enable the use of locally stored data to learn entity embeddings for extremely large vocabularies such as entities.
Background
Embedding has become common in a variety of machine learning problems and solutions. The term embedding may refer to a learned representation of an entity in a continuous number space, such as, for example, a vector of numbers (e.g., floating point numbers). In some cases, the embedding space is a low-dimensional space that enables encoding of information associated with the entity. By way of example, the embedding may represent or encode information regarding various characteristics, interests, behaviors of the various entities, and/or interactions between the various entities. By way of example, an entity may include a natural language element (such as a word), a content item (e.g., an image, a video, a web page, etc.), a product, a location, a business establishment, a user, and/or the like.
Embedding has broad applicability and, as one example usage, provides a signal for ranking and invoking results such as similarity searches between a query and a database. In particular, the geometry of the embedding space imbues the meaning that can be exploited: a distance between two embeddings of two entities (e.g., an L2 distance) may indicate a similarity between the two entities (e.g., a smaller distance indicates a greater similarity). Thus, in some cases, similar items can be found by clustering or nearest neighbor algorithms, and arithmetic in spatial geometry also allows for analog solution.
The embedding can be learned directly in unsupervised learning or indirectly as a byproduct of supervised learning. The information encoded in the embedding may be interpreted and utilized by a machine learning algorithm, and thus, the embedding may be associated with (e.g., considered as a subset of parameters of) the machine learning model.
Disclosure of Invention
Aspects and advantages of embodiments of the present disclosure will be set forth in part in the description which follows, or may be learned from the description, or may be learned by practice of the embodiments.
Various implementations of the present disclosure relate to using federated learning to provide for generating embeddings within a distributed environment in which a high-quality centralized model is trained with training data distributed over a large number of clients. The implementations described herein allow learning embedding in such an environment despite potentially unreliable network connectivity and low computing power of the client device. In an example federated learning setting, in each of multiple rounds, each client independently updates the model based on its local data and transmits the updated model back to the server, with all client-side updates used to update the global model. The present disclosure describes systems and methods that may generate embedding with local training data while protecting privacy of a user of a client device.
One example aspect of the present disclosure relates to a computer-implemented method for embedded federal learning. The method includes one or more federated learning iterations. The method includes collecting, by a client computing device, a local dataset identifying one or more positive entities, wherein the local dataset is stored locally by the client computing device. The method includes obtaining, by a client computing device and from a server computing device, global values for a subset of embeddings associated with a machine learning model, wherein the subset of embeddings includes one or more positive entity embeddings respectively associated with the one or more positive entities and one or more negative entity embeddings respectively associated with one or more negative entities not identified in the local dataset, and wherein the subset of embeddings includes a subset of an embedded vocabulary associated with the machine learning model. The method includes learning, by the client computing device and based at least in part on the local data set, one or more embedded update values in the embedded subset associated with the machine learning model. The method includes transmitting, by the client computing device, information describing one or more embedded update values in the embedded subset associated with the machine learning model to a server computing device.
Another example aspect of the present disclosure is directed to a computing system. The computing system includes one or more server computing devices configured to perform operations. The operations include maintaining a global version of a machine learning model that includes an embedded vocabulary. The operations include transmitting respective slices of the embedded vocabulary to respective client computing devices, each slice containing a respective subset of the embedded vocabulary. The operations include receiving, from the client computing device, respective updates to respective subsets of the embedded vocabulary. The operations include updating a global version of the machine learning model based on respective updates to respective subsets of the embedded vocabulary received from the client computing device.
Other aspects of the disclosure relate to various systems, apparatuses, non-transitory computer-readable media, user interfaces, and electronic devices.
These and other features, aspects, and advantages of various embodiments of the present disclosure will become better understood with reference to the following description and appended claims. The accompanying drawings, which are incorporated in and constitute a part of this specification, illustrate exemplary embodiments of the disclosure and together with the description, serve to explain the relevant principles.
Drawings
A detailed discussion of embodiments directed to one of ordinary skill in the art is set forth in the specification, which makes reference to the appended drawings, in which:
FIG. 1 depicts a block diagram of an example computing system that performs provisioning of large vocabulary embedded slices, according to an example embodiment of the present disclosure.
FIG. 2 depicts a block diagram of an example computing system for embedded federated learning in accordance with an example embodiment of the present disclosure.
Fig. 3A-3B depict an example machine learning model inference scheme that may be performed at a client device, according to an example embodiment of the present disclosure.
Fig. 4A-4D depict example machine learning model inference schemes that may be performed at a client device according to example embodiments of the present disclosure.
Fig. 5 depicts a flowchart of an example method of performing federated learning in accordance with an example embodiment of the present disclosure.
Fig. 6 depicts a flowchart of an example method of performing federated learning at a client device in accordance with an example embodiment of the present disclosure.
Reference numerals repeated across multiple figures are intended to identify the same features in various implementations.
Detailed Description
SUMMARY
In general, the present disclosure is directed to systems and methods for entity embedding that utilize a federated learning (fed learning) scheme to learn multiple entities in a privacy-preserving manner. In particular, at each of a number of federated learning iterations, each of the plurality of client computing devices may learn updated values for a subset of the embedding included in the embedded larger vocabulary associated with the machine learning model based on a respective set of locally stored data.
More particularly, as data sets grow larger and more distributed across many user devices, certain existing machine learning algorithms, which are generally only applicable to controlled environments (such as data centers) where data is properly distributed among machines and high throughput fiber optic networks are available, become infeasible.
Federated learning is a machine learning framework that enables training of high-quality centralized models based on training data distributed over a large number of client computing devices. The client may have low computing power and/or a slow/unstable connection to the network (e.g., mobile device). In some cases, federal learning may also be referred to as "federal optimization".
In some implementations, a system implementing federated learning may perform the following actions in each round of multi-round model optimization: selecting a set of one or more clients; each client in the set obtains information describing a global version of the model from the server; each client in the set updates the model based on its local data; the updated model or model update is sent by each client to the server; the server aggregates the updates (e.g., by calculating an average of the updates) and improves the global model; and the server redistributes the global model to all clients. Performing multiple rounds of the above-described actions iteratively improves the global model based on training data stored at the client device.
One aspect of the present disclosure relates to a slice-based embedded provisioning scheme for use within the federal learning framework. In particular, in some implementations, each client device receives only one or more embedded smaller "slices" from the embedded larger vocabulary from the server computing device at each learning iteration. Further, according to another aspect of the present disclosure, embedded slices may be provisioned in a manner that obfuscates which "members" of the slice are included in the local dataset and/or which "members" of the slice are updated based on the local dataset, thereby improving user privacy. Provisioning embedded finite slices in this manner allows for application of the federated learning scheme to embedded learning in contexts where it is not feasible or otherwise undesirable to transmit the entire embedded vocabulary at each learning iteration (e.g., due to the vocabulary including an extremely large number of embeddings).
Additional aspects of the present disclosure relate to user-embedded (e.g., jointly with updated embedding) learning for a particular user. The learned users can then be embedded (e.g., as context data) for further on-device reasoning. Further, in some implementations, parameter values for machine learning user embedding models may be learned in a federated learning scheme, all while keeping the particular user embedding private on the user's device.
More particularly, an embedded vocabulary (e.g., a total set of all the embedding associated with the machine learning solution) may be generated for and correspond to a set of entities. For certain entity types, the embedded vocabulary may be relatively manageable in data size (e.g., on the order of hundreds or thousands of embeddings). However, in other scenarios, the embedded vocabulary may be much larger in size. For example, the corresponding embedded vocabulary that includes each video contained on YouTube would be about a billion (and growing every day).
The size of these large vocabularies being embedded makes the native application of the federated learning framework to learning of such embedded vocabularies infeasible or otherwise suboptimal. In particular, transferring all (e.g., billions) of the inlays between the server and the client at each round of federal learning represents a significant communication bottleneck.
In view of this problem, one aspect of the present disclosure relates to a slice-based embedding provisioning scheme, in which each client device receives from a server computing device, at each learning iteration, only one or more smaller "slices" of an embedding from an embedded larger vocabulary.
More particularly, a client computing device may collect and locally store a data set that identifies one or more positive entities. As an example, the positive entity may be an entity with which the client computing device or a user of the client computing device interacts. As one example, the positive entity may be a client computing device or a location accessed or otherwise located by a user of the client computing device. As another example, the positive entity may be a content item (e.g., a video, a website, an advertisement, etc.) that the client computing device or a user of the client computing device accesses, loads, clicks on, views, or otherwise interacts with. As another example, the positive entity may be a product that the client computing device or a user of the client computing device purchases, orders, or otherwise expresses an approval. As yet another example, the positive entity may be a natural language unit (e.g., words, phonemes, etc.) used by the client computing device or a user of the client computing device (e.g., when communicating with other individuals and/or when performing searches for content such as web content). As another example, the positive entity may be unrelated to the particular user but may be an entity identified in some manner by data stored locally on the client device, regardless of any particular user.
In many cases, it is preferable for the user that this data set be stored locally only at the client computing device (e.g., rather than being transmitted to a central server or other device). To facilitate such local storage while still learning the large embedded vocabulary, the client computing device may only obtain a limited subset of the embedded vocabulary at each round of learning. In particular, a client computing device may obtain one or more positive entities and one or more negative entities to be used as part of a negative sampling scheme.
Thus, one possible implementation of the proposed embedded federal learning is to simply send the embedding of positive entities identified in the locally stored data and one or more negative entities that can be chosen, for example, generally randomly from a set of entities. The use of such a smaller embedding set represents an improvement over the transfer of the entire vocabulary of embedding at each iteration and, in fact, represents the ideal embedding set to be transmitted from a transfer cost perspective.
However, in some cases, the use of such smaller embedded sets may be improved to improve user privacy. In particular, such small embedded sets may reveal too much information about each user or client device. For example, a watcher may have the possibility to distinguish between positive entities (which are likely to be related) and negative entities (which may be randomly selected).
In view of the above, to avoid transmitting the entire vocabulary of the embedding, but to improve privacy associated with the transmitted embedded set, the embedding may be provisioned from the server to the client device in the embedded slice. For example, each slice representation of the embedding contains a subset of many embedded vocabularies (e.g., the number may be large enough that analysis of the embedding included in one or more slices provisioned to a particular client computing device does not overly reveal private information). Thus, when a client is provisioned with a slice of inlays, it will typically include both positive and negative inlays and it will be challenging for any watcher to distinguish between them (e.g., particularly when the positive and negative inlays contained in the slice are both related in some way or are all otherwise true-or negative-like).
More particularly, the embedded large vocabulary may be organized (e.g., partitioned) into multiple slices. Each slice may contain a number of embeddings (e.g., the number may be a hyper-parameter). At each learning iteration, the client computing device may provision each client computing device with a particular slice that includes one or more positive entities identified in data stored locally by such client computing device. The client computing device may use embedding included in slices that do not correspond to positive entities as a negative example. Additionally, in some implementations, one or more additional slices that do not contain any positive entities may be provisioned in order to provide further confusion as to the identity of the positive entities.
According to one aspect of the disclosure, in some implementations, the embedded vocabulary may be organized into slices based on semantic relevance or other forms of relevance (e.g., distance within the embedding space).
As one example, if the embedded vocabulary includes respective embeddings for multiple locations, similar locations may be included in the respective slices. For example, embedding for all locations in washington, kindo, etc. may be included in one slice, while embedding for all locations in washington, snojomish, etc. may be included in another slice. The division of locations into slices based on geographic relevance may be performed according to a number of different divisions, including based on political boundaries (e.g., county lines), based on inclusion in respective map tiles associated with geographic information systems, and/or other divisions.
As another example, if the embedded vocabulary includes respective embeddings for multiple movies, similar movies may be included in respective slices. For example, an embedding for all movies in the horror movie genre may be included in one slice, while an embedding for all movies included in the sports genre may be included in another slice, and so on. Other divisions are also possible (e.g., actors, director, settings, etc.). Further, while locations and movies are given as examples, other forms of entities may be grouped based on various other types of semantic features or relevance.
As yet another example, the embedded vocabulary may be partitioned into slices by applying a clustering algorithm to the embedding itself, resulting in a plurality of clusters that may be used to define the slices. The clusters may be overlapping or non-overlapping.
Thus, the embedding may be organized into various slices, which in some implementations include semantically related embedding. One benefit of using such slices is to protect the privacy of the local data used to update the global model parameters. For example, while it may be observed that the client device receives embedded slices for all locations in king county, the particular embedding/location within king county that is the positive entity of the client computing device is still highly confusing/undetectable.
In other words, in some implementations, the relationship between the embeddings distributed to the clients and the local data on the clients used to train the parameters can be obfuscated by distributing to each client a superset of the parameters that contains: parameters targeted to be updated using local data on the client; and additional parameters that are logically or semantically related to the target parameter but do not correspond to the positive entity.
After receiving the embedded slice from the server computing device, the client computing device may learn (e.g., by applying a gradient-based update technique such as random gradient descent (SGD), Adagrad, etc.) at least some of the embedded (e.g., positive and at least some negative embeddings included in the slice) update values based on the locally stored data. As one example, the skip-gram model or the bag of words model may be generalized to any form of entity, and the embedded update values may be learned using a log-likelihood approach.
In another aspect, the present disclosure relates to locally generating user embedding on client devices that provide a representation of characteristics of one or more users of a particular client device, optionally in cooperation with a global model trained through federal learning. As one example, user embedding as an input to a machine learning model can be learned jointly with the embedding. As another example, parameter values for a machine learning user embedding model can be learned jointly with embedding. Parameter values for machine learning user embedding models may be learned in a federated manner, but without transmitting the user embedding itself to the server. The learned user-embedding and/or user-embedding models can thereafter be used to perform improved on-device reasoning at the client computing device.
In contrast to previous work, implementations of the systems and methods of the present disclosure provide improved model generation and training while protecting client privacy. Traditionally, embedding trained at a central server is limited to access to the large amount of training data available locally on the client device, which in some examples is limited by connectivity between the client device and the server, sensitivity of the training data, and so forth. Embedding trained by implementations of the methods and systems of the present disclosure may advantageously benefit from access to local data on the client device, while further reducing the distribution and/or assimilation of sensitive information from the client device.
The system and method of the present disclosure provide a number of technical effects and benefits. For example, federal learning provides several advantages over performing learning at a centralized server. In one aspect, federal learning leverages the computing power of a large number of computing devices (e.g., user mobile devices) to improve the overall power of the interconnected computing systems formed thereby. As one example, the techniques described herein enable efficient training for machine learning embedding for performing computational tasks (e.g., image processing, computer vision tasks, sensor data processing tasks, audio processing tasks, text processing tasks, classification tasks, detection tasks, recognition tasks, data search tasks, etc.). Accordingly, the systems and methods of the present disclosure may improve the ability of computing systems including machine learning models to perform various practical applications, thereby improving the functioning of such computing systems.
Another benefit of federal learning is the ability to deliver training models and generate embeddings with reduced private information. Typically, the information of the model update is not more sensitive than the data itself. Thus, privacy sensitive user data remains at the user's computing device without being uploaded to the server. Instead, only less sensitive model updates are transmitted. In some implementations, server communication may also be guaranteed by cryptographic protocols or other differential privacy techniques. In further implementations, individual updates submitted by a client may not be maintained separately after aggregating a group or batch of client updates. In accordance with the present disclosure, privacy of federal learning may be further increased by selectively distributing model parameters to be updated by clients among a larger subset of the model parameters to obfuscate and/or embed model parameters updated by particular clients. In this manner, the particular embedding associated with the activity of the client device (e.g., when providing training data for updating the embedding) may not be directly traceable from the embedding profile of the server. By reducing the sensitivity of the information communicated, the computational requirements for encrypted communications are reduced, thereby increasing the efficiency of resource usage by other tasks of the computing device.
Among additional benefits, keeping the training data on the local device may permit more detailed and heterogeneous training data. Training data may be drawn from a variety of sources including text entry for various applications, voice commands and other audio input, user gestures, web page and/or application navigation and retrieval, and so forth to form a heterogeneous set. While such a diverse set of training data may improve the training of the model, the set may form a complete snapshot of the user's activities and reflect highly sensitive information. Advantageously, maintaining the training data locally permits the use of more heterogeneous training data while also limiting the transfer of sensitive information. In the same way, due to the sensitivity of the information, local training may access a more comprehensive and representative stream of user data (e.g., a complete location history rather than infrequent samples) than would otherwise be available. In some implementations, the depth and heterogeneity of the training data may also permit more adequate characterization of the embedding generated thereby and represent more diverse information about the embedding entities and/or interactions with entities across different domains.
In general, the above-described improvements in the details and diversity of the training data may enable more efficient and/or accurate embedding to be generated in fewer training iterations. Accuracy improvements may provide improvements in the ability of computing devices and systems to perform desired tasks at greater speed and efficiency. For example, a computing device performing embedded prediction, recognition, and/or classification tasks generated as disclosed herein may perform tasks satisfactorily after fewer training iterations at a lower computational resource cost. Additionally, in some embodiments, the accuracy of embedding may also enable a user of a computing device or system as disclosed herein to complete a particular task with less repetition, lower latency, and an improved user experience.
Among additional benefits, the methods and systems of the present disclosure, in one aspect, relate to joint learning/training of global embedding (e.g., embedding of entities that can be utilized/accessed by many clients) and local user embedding (e.g., embedding of characteristics of a particular client). The joint training of global embedding and user embedding may advantageously permit user embedding to be discovered and/or generated in advance without feature engineering, thereby reducing the manual and/or computational costs of generating user embedding and improving the functionality of machine learning systems relying thereon.
As another exemplary technical effect and benefit, the systems and methods of the present disclosure provide a slice-based provisioning scheme that enables embedded federated learning without requiring the transmission of the entire embedded vocabulary at each learning iteration, but without unduly compromising user privacy.
Examples of embodiments and implementations of the systems and methods of the present disclosure are discussed in the following sections.
Example apparatus and System
In some implementations, each of a number of client computing devices (shown as example devices 102a and 102 b) may collect local data (shown as locally stored data 108a and 108b as an example). The local data may include a sequence (e.g., a time series) or other descriptor of an entity and/or event. Thus, in one example, the locally stored data 108a can include data describing a sequence of entities. These entities identified by the locally stored data 108a may be referred to as positive entities of the client device 102 a. In some implementations, a respective timestamp may be included in the data 108a of each positive entity. In some implementations, only data samples collected within the nearest window of data may be used to update the model/embedding.
Examples of entities and events may include audio, text, photographic, or video graphical inputs or outputs of a client computing device, including inputs to and outputs from sensors within the device (e.g., sensors for tracking spatial position and translation, biometrics, and/or interacting with additional other devices). Additional or alternative entities may include products, locations, places of business, users, and/or the like. In some examples, the collected local data 108a may include a history of user interactions with the device 102a and applications stored, accessed, and/or executed thereon. The data 108a may be stored in a temporary or persistent storage medium on the client device 102 a.
The client device 102a may process the data 108a to learn embedding. Device 102a may obtain at least a subset of the current global embedding 106 for the one or more entities described by the stored data 108a (e.g., by retrieving the subset of global embedding 106 from repository or server 104). The current global embedding 106 may optionally be pre-trained according to embedding learning methods known in the art.
In some implementations, the population of global inlays 106 and/or the functionality of the client device 102a may be configured such that the client device 102a may obtain a full set of current inlays 106 for further learning of the inlays. Alternatively, the client device 102a may only obtain one or more subsets or slices of the population of inlays 106. As an example, as illustrated in fig. 1, client device 102a has obtained embedded slice 1, embedded slice 3, and embedded slice M. Likewise, client device 102b has obtained embedded slice 1 and embedded slice 4.
Each slice obtained by the client device 102a may include one or more of the embeddings associated with one or more positive entities described by the stored data 108a and/or one or more additional entities not described by the stored data 108a (e.g., which may be referred to as "negative entities" for the client device 102). Thus, in some implementations, the particular slices (e.g., slices 1, 3, and M) obtained by the client device 102a represent an embedded superset to be trained based on the stored data 108 a.
In some implementations, each slice may include a collection of similar data that may be requested through an identifier. The identifier may optionally be similar (but typically not identical) to the actual data being requested. In some examples, where the entire global model 106 is divided into subsets or slices, the union of slices is a vocabulary and each slice is a subset of the vocabulary.
In some implementations, the server 104 can provide the client (e.g., 102a) with a slice containing a set of inlays, each corresponding to an identifier submitted by the client. The identifier may be determined by the client 102a to obfuscate the identity of the desired embedding while still providing the server 104 with sufficient information to retrieve the slice containing the desired embedding.
The association between the embeddings in the set as indicated by the identifier may generally follow any scheme of relationship (e.g., logical relationship). Without limiting the relationships envisaged among the elements of the slice, the relationships may be determined with respect to: semantic hashing, social hashing, spatial grouping, temporal grouping (e.g., a set of entities created and/or time stamped at a certain time or within a certain time range), application grouping (e.g., an embedded set of tasks or task sequences performed within an application), and/or any implementation of an embedded logical subset. In some examples, the embedding may be assigned to the slice based on a calculation performed with the embedding (e.g., similarity search, clustering algorithm, ranking, etc.). The embedding may be dynamically reassigned to the slice as the embedding is updated. In some implementations, the embedding is distributed according to a sharding function or algorithm.
In one example, a map tile coverage of a geographic area is considered. An embedded slice may include the embedding of all entities included in or covered by one or more sets of map tiles (e.g., where tile data is embedded as a vector). In one example, a set of tiles may include all tiles that intersect a bounding box of arbitrary size around a given latitude and longitude. In other examples, a slice may be an embedding associated with an entity contained within a tile group associated with a specified geographic association (e.g., a measure of proximity).
In some implementations, the server 104 may accept a query for a slice index through a latitude and longitude (or other geographic identifier such as a zip code or area code) provided by the client and return an embedded slice or slices containing all tiles associated with intersections with a bounding box specified by the queried coordinates. The coordinates provided by the client may deviate from the actual tile coordinates expected by the client (e.g., based on the addition of aliasing noise) such that the bounding box includes many tiles surrounding the queried coordinates. For example, if the bounding box includes tiles that extend at least a distance D from the coordinates of the query set, the client may obfuscate its true desired coordinates by submitting the query set coordinates a distance D away from the true desired coordinates.
Once the subset of global inlays 106 is obtained by the client device 102a, the client device 102a may determine one or more updates to the one or more inlays in view of the local data 108 a. The local data 108a may form a set of ground truth training data for training the machine learning embedding. In some implementations, the ground truth training data includes ground truth input-output pairs for the machine learning model, and the actual input-output pairs of the machine learning model are compared to the ground truth to determine an error or loss. Updates to one or more parameters (e.g., embedding) of the machine learning model may then be calculated by the client device 102a based on the determined errors. In one example, a generalized implementation of the word2vec model may be used. For example, the update may be calculated according to the following equation
w(updated)＝w(old)-λcU (1)
Wherein w(old)Is the current embedding, w(updated)Is an embedded updated version based on an update item U, where U is determined by local data and learned by the client at a rate λcScaling (e.g., U may include a gradient of the objective function evaluated with the training data).
In some implementations, satisfactory convergence of machine learning embedding may be obtained without updating each embedding with each training iteration. In some examples, each training iteration includes computing updates for the target embedding and the set of negative examples. In some implementations, each round of training can be performed with the soft-max objective function in a manner similar to Skip-Gram training or bag-of-words training.
In general, negative examples may be obtained by the client device 102a in the same manner as slices. As one example, the negative examples may be randomly selected from a general population or vocabulary of the embedding 106. As another more efficient example, the negative examples may be negative embeddings included within a slice obtained by the client device 102a to access positive embeddings. For example, in some implementations, negative examples may be randomly selected from a slice that also contains the target embedding. Thus, the concept of slicing allows for efficient retrieval of negative examples with guaranteed privacy. In particular, each request for a slice may also contain negative examples from the training vocabulary, e.g., at a predetermined frequency.
In some implementations, the slices and/or negative examples obtained by the client device 102a are retrieved and updated in such a way as to obfuscate the target embedding desired by the client device 102a and associated with the local data 108a on the device 102 a.
After one or more update iterations have been completed on client device 102a, client device 102a may transmit information indicative of the update to server 104 for use in updating global embedding 106. Information indicating updates may be provided to server 104 for aggregation in a federated learning algorithm. For example, server 104 may execute a federated averaging algorithm. The federated averaging algorithm may aggregate individual updates (e.g., updated local embedded versions) from multiple clients to obtain updated global embedding 106.
In some implementations, the updated parameters are provided to the server by multiple clients, and the respective updated parameters are summed across the multiple clients. The sum of each updated parameter may then be divided by the corresponding sum of the weights for each parameter as provided by the client to form a weighted average updated parameter set. In some implementations, the updated parameters are provided to the server 104 by multiple clients, and the respective updated parameters scaled by their respective weights are summed across the multiple clients to provide a weighted average updated parameter set. In some examples, the weights may be related to the local training iteration number or period number, such that more widely trained updates contribute more to the updated parameter version. In some examples, the weights may include bitmasks that encode the observed entities in each training round (e.g., a bitmask may correspond to an index of embedded slices and/or negative examples provided to the client).
The information indicating the update may include an embedding of the update locally (e.g., the updated embedding or a difference between the updated embedding and a previous embedding). In some examples, the information indicative of the update may include an update term, a corresponding weight, and/or a corresponding learning rate, and the server may determine a corresponding embedded updated version accordingly. Communications between the server 104 and the client may be encrypted or otherwise made private.
The updates computed for the global machine learning model 106 may also incorporate variable learning rates. Generally, the learning rate scales to the magnitude of the update of the embedding calculation. In some examples, an algorithm or function is used to determine a learning rate that is inversely related (e.g., linearly or non-linearly related) to the frequency with which updates are calculated for embedding subject to the updates and/or that is inversely related to the frequency with which the training data represents the entity corresponding to embedding subject to the updates. Advantageously, the learning rate may be determined to improve learning for long tail embedding (e.g., embedding with a small amount of training data available as compared to the entire vocabulary of the embedding as a whole). For example, an AdaGrad model may be used to determine the learning rate.
In some implementations, a learning rate is determined for each embedding that is updated. In some implementations, a global update for a parameter can be calculated as
Wherein
Advantageously, it may be determined that the server learning rate adapts the learning rate of updates applied to the global parameter based on a frequency, e.g., a frequency of update embedding across a portion or all of the federated clients (which may be reflected in the retrieval count containing embedded slices in some implementations), and/or an amplitude, which is an amplitude of embedded gradient updates across the federated clients. For example, the learning rate may be calculated as
Wherein λiIs the ith insertion wiI is selected from a set of indices used for embedding within the vocabulary, η is the global learning rate, and
Information indicative of the update may be obfuscated in some implementations to increase privacy of activities surrounding the client device. In some examples, random noise may be added to all of the embedding and/or updating. Additionally or alternatively, a cryptographic protocol (e.g., a secure aggregation protocol) may be used. Advantageously, the updates provided for any negative examples may further obfuscate information about any target embedding.
In general, the client device may periodically or continuously compute local updates to the embedding. The server may also periodically or continuously compute global updates based on the provided client updates. In some implementations, learning for embedding includes online or continuous machine learning algorithms. For example, some implementations may continuously update the embedding within the vocabulary without having to cycle through training the entire vocabulary.
FIG. 1 depicts an example system 100 for training one or more global machine learning models 106 using respective training data 108a-b stored locally on a plurality of client devices 102 a-b. In addition to the above, the user may be provided with controls that allow the user to make selections as to whether and when the systems, programs, or features described herein are capable of collecting, storing, and/or using user information (e.g., training data 108) and whether to send content or communications from the server to the user. In addition, certain data may be processed in one or more ways before it is stored or used, so that personally identifiable information is removed. For example, the identity of the user may be treated such that personally identifiable information cannot be determined for the user, or the geographic location of the user may be generalized (such as to a city, zip code, or state level) with location information obtained such that a particular location of the user cannot be determined. Thus, the user may control how information is collected about the user, how information is used, and what information is provided to the user.
The client devices 102a-b may be configured to provide local updates to the server 104. As indicated above, the training data 108a-b may be privacy sensitive. In this manner, local updates may be performed and provided to the server 104 without compromising the privacy of the training data 108 a-b. For example, in such implementations, the training data 108a-b is not provided to the server 104. The local update does not include training data 108 a-b. In some implementations, one or more of encryption techniques, random noise techniques, and/or other security techniques may be added to the training process to obfuscate any reasonable information.
In some implementations, the server 104 may apply one or more scaling or other techniques to the local updates to determine the global updates. For example, a local stride may be applied to each client device 102, aggregation may be performed in proportion to various data partition sizes of the client devices 102, and/or one or more scaling factors may be applied to local and/or aggregate updates. It will be appreciated that various other techniques may be applied without departing from the scope of the present disclosure.
FIG. 2 depicts a more detailed component-level diagram of an example computing system 200 that may be used to implement the methods and systems of the present disclosure. The system 200 may be implemented using a client-server architecture that includes a server 210 in communication with one or more client devices 230 over a network 242. Accordingly, fig. 2 provides an example system 200 that may implement aspects illustrated by the system 100 of fig. 1.
The system 200 includes a server 210, such as a web server. Server 210 may be implemented using any suitable computing device. The server 210 may have one or more processors 212 and one or more memory devices 214. Server 210 may be implemented using a single server device or multiple server devices. In implementations using multiple devices, such multiple devices may operate according to a parallel computing architecture, a sequential computing architecture, or a combination thereof.
The server 210 may also include a network interface for communicating with one or more client devices 230 over a network 242. The network interface may include any suitable components for interfacing with one or more networks, including, for example, transmitters, receivers, ports, controllers, antennas, or other suitable components.
The one or more processors 212 may include any suitable processing device, such as a microprocessor, microcontroller, integrated circuit, logic device, or other suitable processing device. The one or more memory devices 214 may include one or more computer-readable media, including but not limited to non-transitory computer-readable media, RAM, ROM, hard drives, flash drives, or other memory devices. The one or more memory devices 214 may store information accessible by the one or more processors 212, including computer-readable instructions 216 that may be executed by the one or more processors 212.
The instructions 216 may be any set of instructions that, when executed by one or more processors 212, cause the one or more processors 212 to perform operations. For example, the instructions 216 may be executed by the one or more processors 212 to implement the global updater 220. Global updater 220 may be configured to receive one or more local updates and determine a global model based at least in part on the local updates.
As shown in fig. 2, the one or more memory devices 214 may also store data 218 that can be retrieved, manipulated, created, or stored by the one or more processors 212. Data 218 may include, for example, local updates, global parameters, and other data. The data 218 may be stored in one or more databases. The one or more databases may be connected to server 210 through a high bandwidth LAN or WAN, or may also be connected to server 210 through network 242. The one or more databases can be split such that they are located in multiple locations.
Similar to the server 210, the client device 230 may include one or more processors 232 and memory 234. The one or more processors 232 may include, for example, one or more Central Processing Units (CPUs), Graphics Processing Units (GPUs) dedicated to efficiently rendering images or performing other specialized calculations, Tensor Processing Units (TPUs), and/or other processing devices. The memory 234 may include one or more computer-readable media and may store information accessible by the one or more processors 232, including instructions 236 and data 238 that may be executed by the one or more processors 232.
The instructions 236 may include instructions for implementing a local updater configured to determine one or more local updates according to example aspects of the present disclosure. For example, the local updater may perform one or more training techniques, such as, for example, back-propagation of errors, to retrain or otherwise update the model based on locally stored training data. The local updater may be configured to perform structured updates, sketch updates, or other techniques. The local updater may be included in an application or may be included in an operating system of the device 230.
The data 238 may include one or more training data examples to be used in solving one or more optimization problems. The training data examples for each client device 230 may be unevenly distributed among the client devices such that no client device 230 includes a representative sample of the overall distribution of training data examples.
The data 238 may also include updated parameters to be transmitted to the server 210.
The client device 230 of fig. 2 may include various input/output devices for providing and receiving information from a user, such as a touch screen, a touch pad, data entry keys, a speaker, and/or a microphone suitable for voice recognition.
The network 242 may be any type of communication network, such as a local area network (e.g., an intranet), a wide area network (e.g., the Internet), a cellular network, or some combination thereof. The network 242 may also include a direct connection between the client device 230 and the server 210. In general, communications between server 210 and client device 230 may be carried via a network interface using any type of wired and/or wireless connection using various communication protocols (e.g., TCP/IP, HTTP, SMTP, FTP), encodings or formats (e.g., HTML, XML), and/or protection schemes (e.g., VPN, secure HTTP, SSL).
Example machine learning model
Fig. 3A and 3B illustrate example machine learning models using entity embedding. As shown in FIG. 3A, the machine learning model may receive as input a corresponding embedding of a sequence of positive entities 1 through J-1. Based on the respective embedding of the sequence of positive entities 1 to J-1, the machine learning model can predict the identity of positive entity J. Similarly, FIG. 3B illustrates a corresponding embedded alternative machine learning model that processes a sequence of positive entities 1 through J-1 according to a series of processing steps.
In some implementations, the output of each of the models shown in fig. 3A and 3B can be a respective probability or other matching metric for each possible entity. The highest probability or best match may be selected as the final output prediction.
Although the models illustrated in fig. 3A and 3B are unidirectional in nature (e.g., predicting entity J based on entities preceding entity J), the present disclosure is not limited to unidirectional models, but instead may be applied to bidirectional models, such as generalization of bag-of-words methods.
Fig. 3A and 3B illustrate machine learning models performing inference. During training, a loss function may be used to compare the prediction output by the model to ground truth answers (e.g., "correct" positive entities). The loss function can be propagated backwards to learn updates to the model parameters of the machine learning model and further to learn updates to the embedding itself (e.g., updates to the embedding of positive entities 1 through J-1). In some implementations, additional embeddings other than positive embeddings (e.g., one or more negative embeddings) may also be updated.
Updates to the model parameters of the machine learning model, and further updates to the embedding itself, may be communicated to a central server for aggregation to determine a global set of embedding and/or model parameters.
User embedding
In one aspect, the present disclosure relates to generating an embedding that digitally encodes information about a user of a client device. Strict client privacy issues may prevent user embedding from being leveraged by the federation or by the server. However, the representation of the user is valuable in a number of personal artificial intelligence and/or machine learning applications. The method and system according to the present disclosure may advantageously generate user embedding in conjunction with federal learning of embedding for other entities.
In some implementations, user embedding can be learned as a context of other entity embedding (e.g., data item embedding). The item embedding may be learned according to a federated learning approach as disclosed herein and may be iteratively updated with respect to the global item embedding set. User embedding can be learned jointly as a context of item embedding, and in some implementations, can be learned implicitly from local training data on the client device. In some implementations, items may be trained in a federated learning process to represent information and characteristics of entities that are consistent across a global model (e.g., and with respect to all its users), while user embedding indicates characteristics of a particular user and provides context to global model parameters to better adapt the global model to the particular user. In some implementations, when user embedding is learned jointly with federated learning of item embedding, the training impact of user embedding on updates to item embedding is averaged over the federated learning process, thereby permitting item embedding to converge globally while user embedding maintains the informational characteristics of a particular user.
In one example, user embedding may be learned that allows for prediction of a user's behavior and/or preferences (e.g., interaction with the next item in the sequence). In particular, user embedding and machine learning models (e.g., neural networks, such as Convolutional Neural Networks (CNNs)) may be jointly learned. Using federated learning, learning parameters of a model are shared between a server and multiple clients through a federated learning process as disclosed herein. The user embeddings produced jointly by this architecture can be saved locally. In another example, a straightforward approach would be to train embedding in conjunction with user interaction through a multi-tower approach. Another example may include using a sequence model (e.g., a long-short term memory or gated cyclic unit model) to generate locally-saved user-embedded vectors, while model weights would be shared with a central server for federated averaging.
In some implementations, user embedding may be used locally on a client device to improve the performance of globally trained embedding. For example, in a prediction task, a user-specific context vector may adapt global prediction based on the user's trait tendencies. For example, the global model may provide a prediction of items that may be of interest within the application, and the local user embedding may modify and/or enhance the prediction based on user-specific information. In this manner, user embedding can be used to enhance any number of machine learning algorithms (e.g., ranking, prediction, and/or embedding algorithms).
As one example, fig. 4A illustrates a machine learning model that is highly similar to the model illustrated in fig. 3A, except that the model illustrated in fig. 4A also receives as input a user embedding, where the user embedding is an embedding that encodes information describing the user of the particular client device for which inference/training is occurring. Likewise, fig. 4B illustrates a machine learning model that is highly similar to the model illustrated in fig. 3B, except that the model illustrated in fig. 4B also receives user embedding as input.
As another example, FIG. 4C illustrates a scheme in which user embedding is generated by a machine learning user embedding model based on a set of user data. For example, the user data may include user demographic data describing the user or user behavior and/or other information stored locally at the client device. Learning signals from predicted losses on the jth entity can be propagated back end-to-end to learn updates to parameters of the machine learning user embedded model. These parameters of (or updates to) the machine-learned user embedding model may be communicated to a central server so that a global user embedding model applicable to all users may be learned in a federated manner.
Again, the user may be provided with controls that enable the user to control whether certain forms of data are stored and, if so, how they are used. As described herein, user data and user embedding may never leave the user's device, but parameters of (or updates to) the user embedding model or other machine learning model (e.g., in the form of encryption and noise) may be provided to a central server for aggregation.
In some implementations, the machine-learned user embedding model and/or the resulting user embedding can be used to perform additional on-device reasoning for the user. For example, fig. 4D illustrates additional inference data flows that may be performed on the client device. User embedding generated by the user embedding model based on the user data may be provided as input (possibly as context for other input data) to the additional machine learning model. Additional machine learning models may generate additional user predictions. The additional user predictions may be any form of classification, recommendation, etc.
Example method
Fig. 5 depicts a flowchart of an example method (500) of determining a global model according to an example embodiment of the present disclosure. The method (500) may be implemented by one or more computing devices, such as one or more computing devices depicted in fig. 1 and/or fig. 2. In addition, fig. 5 depicts steps performed in a particular order for purposes of illustration and discussion. Using the disclosure provided herein, one of ordinary skill in the art will appreciate that the steps of any of the methods discussed herein may be adapted, rearranged, expanded, omitted, or modified in various ways without departing from the scope of the present disclosure.
At (502), the method (500) may include determining, by the client device, a local model based on the one or more local data examples. In particular, one or more data examples may be used to determine a local model for a loss function. For example, data examples may be generated by user interaction with a client device. In some implementations, the model may have been pre-trained prior to local training at (502). In some implementations, structured updates, sketch updates, or other techniques can be used at (502) to make the learned local model or local update communication efficient.
At (504), the method (500) may include providing, by the client device, the local model to the server, and at (506), the method (500) may include receiving, by the server, the local model. In some implementations, the local model or local update may be encoded or compressed before being sent to the server.
At (508), the method (500) may include determining, by the server, a global model based at least in part on the received local model. For example, a global model may be determined based at least in part on a plurality of local models provided by a plurality of client devices, each client device having a plurality of unevenly distributed data examples. In particular, data examples may be distributed among client devices such that no client device includes a representative sample of the overall distribution of data. Additionally, the number of client devices may exceed the number of data instances on any one client device.
In some implementations, the server can decode each received local model or local update as part of the aggregation process.
At (510), the method (500) may include providing a global model to each client device, and at (512), the method (500) may include receiving the global model.
At (515), the method (500) may include determining, by the client device, a local update. In particular implementations, the local update may be determined by retraining or otherwise updating the global model based on locally stored training data. In some implementations, structured updates, sketch updates, or other techniques can be used at (515) to make the learned local model or local update communication efficient.
In some implementations, the local update may be determined based at least in part on using one or more random updates or iterations. For example, the client device may randomly sample a partition of the data instance stored on the client device to determine the local update. In particular, a stochastic model descent technique may be used to determine a local update to determine a direction to adjust one or more parameters of the loss function.
In some implementations, the step size associated with the local update determination may be determined based at least in part on a plurality of data examples stored on the client device. In further implementations, the stochastic model may be scaled using a diagonal matrix or other scaling technique. In yet further implementations, the local update may be determined using a linear term that forces each client device to update the parameters of the loss function in the same direction.
At (516), the method (500) may include providing, by the client device, the local update to the server. In some implementations, the local model or local update may be encoded before being sent to the server.
At (518), the method (500) may include receiving, by the server, the local update. In particular, the server may receive a plurality of local updates from a plurality of client devices.
At (520), the method (500) may include determining the global model again. In particular, a global model may be determined based at least in part on the received local updates. For example, received local updates may be aggregated to determine a global model. The polymerization may be an additive polymerization and/or an average polymerization. In particular implementations, the aggregation of local updates may be proportional to the partition size of the data instance on the client device. In further embodiments, the aggregation of local updates may be scaled on a per coordinate basis.
Any number of iterations of local and global updates may be performed. That is, the method (500) may be performed iteratively to update the global model over time based on training data stored locally.
Fig. 6 depicts a flowchart of an example method of performing federated learning at a client device in accordance with an example embodiment of the present disclosure.
At (602), the method (600) may include collecting, by the client computing device, a local data set identifying one or more positive entities, wherein the local data set is stored locally by the client computing device.
At (604), the method (600) may include obtaining, by the client computing device and from a server computing device, global values for the embedded subset associated with the machine learning model. The subset of embeddings may include one or more positive entity embeddings respectively associated with the one or more positive entities and one or more negative entity embeddings respectively associated with one or more negative entities not identified in the local dataset. The embedded subset may be a subset of an embedded vocabulary associated with the machine learning model.
At (606), the method (600) may include learning, by the client computing device and based at least in part on the local dataset, one or more embedded update values in the embedded subset associated with the machine learning model.
At (608), the method (600) may include transmitting, by the client computing device, information describing one or more embedded update values of the embedded subset associated with the machine learning model to a server computing device.
In some implementations, obtaining, by the client computing device from the server computing device and at (604), the global values for the embedded subset associated with the machine learning model includes: requesting and receiving, by the client computing device and from the server computing device, a global value for the embedded subset that does not include the remainder of the embedded vocabulary associated with the machine learning model.
In some implementations, obtaining, by the client computing device from the server computing device and at (604), the global values for the embedded subset associated with the machine learning model includes: identifying, by the client computing device, one or more slices of the embedded vocabulary that include the one or more positive entities; and obtaining, by the client computing device and from the server computing device, one or more slices of the embedded vocabulary, wherein each of the one or more slices contains at least one of the one or more positive entities and at least one of the one or more negative entities.
In some implementations, each of the one or more slices includes a respective subset of the embedded vocabulary that has been grouped based on at least one of semantic similarity and semantic association.
In some implementations, the one or more slices of the vocabulary include one or more geographic slices of the location-embedded vocabulary. In some implementations, each geographic slice includes a respective subset of the inlays that correspond to locations within a common geographic area. In some implementations, the one or more slices correspond to one or more map tiles that cover respective portions of a map of the earth.
In some implementations, the one or more negative entities are identified by a similarity search with respect to the one or more positive entities.
In some implementations, the client computing device is associated with a particular user; and the method (600) further comprises: learning, by the client computing device and based at least in part on the local data set, a user embedding associated with a particular user of the client computing device; and embedding, by the client computing device, the user at the local storage at the client computing device.
In some implementations, the user embedding is learned jointly with the one or more embedded update values in the subset of embeddings associated with the machine learning model. In some implementations, the user embedding includes a context matrix within the machine learning model.
In some implementations, learning, by the client computing device and based at least in part on the local dataset, user embeddings associated with a particular user of the client computing device at (606) includes: learning, by the client computing device and based at least in part on the local data set, update parameter values for a machine-learned user-embedding model configured to generate user-embedding based on data describing the user.
In some implementations, the method (600) further includes: transmitting, by the client computing device to the server computing device, information describing updated parameter values for the machine-learned user-embedding model without transmitting the user-embedding.
In some implementations, the method (600) further includes: user embedding is used by a client computing device to perform on-device reasoning on the client device.
In some implementations, learning, by the client computing device and based at least in part on the local dataset, the one or more embedded update values in the embedded subset associated with the machine learning model at (606) includes: adapting, by the client computing device, a learning rate applied to the one or more updated values, the learning rate inversely related to a frequency with which the one or more updated values are updated.
In some implementations, learning, by the client computing device and based at least in part on the local dataset, the one or more embedded update values in the embedded subset associated with the machine learning model at (606) includes: one or more weights for respectively weighting the update values are determined by the client computing device.
In some implementations, additional methods performed at the server computing device can include determining, by the server computing device, one or more weights for weighting the update values, respectively.
Additional disclosure
The techniques discussed herein make reference to servers, databases, software applications, and other computer-based systems, as well as actions taken and information sent to and from such systems. The inherent flexibility of computer-based systems allows for a wide variety of possible configurations, combinations, and divisions between and among components to accomplish tasks and functionality. For example, the processes discussed herein may be implemented using a single device or component or multiple devices or components operating in conjunction. Databases and applications may be implemented on a single system or distributed across multiple systems. The distributed components may operate sequentially or in parallel.
While the present subject matter has been described in detail with respect to various specific example embodiments thereof, each example is provided by way of illustration, and not limitation, of the present disclosure. Alterations, permutations, and equivalents of such embodiments may readily occur to those skilled in the art upon a reading of the foregoing description. Accordingly, the subject disclosure does not preclude inclusion of such modifications, variations and/or additions to the present subject matter as would be readily apparent to one of ordinary skill in the art. For instance, features illustrated or described as part of one embodiment, can be used with another embodiment to yield a still further embodiment. Accordingly, the present disclosure is intended to cover such alternatives, modifications, and equivalents.
Claims (20)
1. A computer-implemented method for embedded federal learning, the method comprising:
for each of one or more federated learning iterations:
collecting, by a client computing device, a local dataset identifying one or more positive entities, wherein the local dataset is stored locally by the client computing device;
obtaining, by the client computing device and from a server computing device, global values for a subset of embeddings associated with a machine learning model, wherein the subset of embeddings includes one or more positive entity embeddings and one or more negative entity embeddings, wherein the one or more positive entity embeddings are respectively associated with the one or more positive entities and the one or more negative entity embeddings are respectively associated with one or more negative entities not identified in the local dataset, and wherein the subset of embeddings includes a subset of an embedded vocabulary associated with the machine learning model;
learning, by the client computing device and based at least in part on the local data set, one or more embedded update values in the embedded subset associated with the machine learning model; and
transmitting, by the client computing device to the server computing device, information describing the one or more embedded update values in the embedded subset associated with the machine learning model.
2. The computer-implemented method of claim 1, wherein obtaining, by the client computing device from the server computing device, the global values for the embedded subset associated with a machine learning model comprises:
requesting and receiving, by the client computing device and from the server computing device, a global value for an embedded subset that does not include a remainder of the embedded vocabulary associated with the machine learning model.
3. The computer-implemented method of any of the preceding claims, wherein obtaining, by the client computing device from the server computing device, the global values for the embedded subset associated with a machine learning model comprises:
identifying, by the client computing device, one or more slices of the embedded vocabulary that include the one or more positive entities; and
obtaining, by the client computing device and from the server computing device, the one or more slices of the embedded vocabulary, wherein each of the one or more slices contains at least one of the one or more positive entity embeddings and at least one of the one or more negative entity embeddings.
4. The computer-implemented method of claim 3, wherein each of the one or more slices comprises a respective subset of the embedded vocabulary that has been grouped based on at least one of semantic similarity and semantic association.
5. The computer-implemented method of claim 4, wherein:
the one or more slices of the embedded vocabulary include one or more geographic slices of a location-embedded vocabulary; and is
Each geographic slice includes a respective subset of the embeddings that correspond to locations within a common geographic area.
6. The computer-implemented method of claim 5, wherein the one or more slices correspond to one or more map tiles that cover respective portions of a map of the earth.
7. The computer-implemented method of any of the preceding claims, wherein the one or more negative entities are identified by a similarity search with respect to the one or more positive entities.
8. The computer-implemented method of any of the preceding claims, wherein:
the client computing device is associated with a particular user; and is
The method further comprises the following steps:
learning, by the client computing device and based at least in part on the local data set, a user embedding associated with the particular user of the client computing device; and
embedding, by the client computing device, the user at a local storage at the client computing device.
9. The computer-implemented method of claim 8, wherein the user embedding the updated values for the one or more of the subset of embeddings associated with the machine learning model are learned jointly.
10. The computer-implemented method of claim 8 or 9, wherein the user embedding comprises a context matrix within the machine learning model.
11. The computer-implemented method of any of claims 8-10, wherein learning, by the client computing device and based at least in part on the local dataset, the user embedding associated with the particular user of the client computing device comprises learning, by the client computing device and based at least in part on the local dataset, update parameter values for a machine-learned user embedding model configured to generate the user embedding based on data describing the user.
12. The computer-implemented method of claim 11, further comprising:
transmitting, by the client computing device to the server computing device, information describing the updated parameter values of the machine learning user embedding model without transmitting the user embedding.
13. The computer-implemented method of any of claims 8-12, further comprising:
performing, by the client computing device, on-device reasoning on the client computing device using the user embedding.
14. The computer-implemented method of any of the preceding claims, wherein learning, by the client computing device and based at least in part on the local dataset, the one or more embedded update values in the embedded subset associated with the machine learning model comprises:
adapting, by the client computing device, a learning rate applied to one or more of the update values, the learning rate inversely related to a frequency with which the one or more of the update values are updated.
15. The computer-implemented method of any of the preceding claims, wherein learning, by the client computing device and based at least in part on the local dataset, the one or more embedded update values in the embedded subset associated with the machine learning model comprises:
determining, by the client computing device, one or more weights for individually weighting the update values.
16. The computer-implemented method of any of the preceding claims, further comprising:
determining, by the server computing device, one or more weights for individually weighting the update values.
17. A client computing device configured to perform the method of any of claims 1-16.
18. A computing system, comprising:
one or more server computing devices configured to perform operations comprising:
maintaining a global version of a machine learning model containing an embedded vocabulary;
transmitting respective slices of the embedded vocabulary to respective client computing devices, each slice containing a respective subset of the embedded vocabulary;
receiving, from the client computing device, respective updates to the respective subsets of the embedded vocabulary; and
updating the global version of the machine learning model based on the respective updates to the respective subset of the embedded vocabulary received from the client computing device.
19. The computing system of claim 18, wherein the respective slice of the embedded vocabulary includes a respective geographic slice of the embedded vocabulary corresponding to a respective set of embeddings associated with entities included in a respective geographic region.
20. The computing system of claim 18 or 19 wherein the respective slice of the embedded vocabulary comprises a respective semantic slice of the embedded vocabulary corresponding to a respective set of embeddings associated with entities having shared semantic features.
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
PCT/US2019/057587 WO2021080577A1 (en) | 2019-10-23 | 2019-10-23 | Online federated learning of embeddings |
Publications (1)
Publication Number | Publication Date |
---|---|
CN114600106A true CN114600106A (en) | 2022-06-07 |
Family
ID=68583496
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201980101611.6A Pending CN114600106A (en) | 2019-10-23 | 2019-10-23 | Embedded online federated learning |
Country Status (4)
Country | Link |
---|---|
US (1) | US20220391778A1 (en) |
EP (1) | EP4049162A1 (en) |
CN (1) | CN114600106A (en) |
WO (1) | WO2021080577A1 (en) |
Families Citing this family (15)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11461593B2 (en) * | 2019-11-26 | 2022-10-04 | International Business Machines Corporation | Federated learning of clients |
US11909482B2 (en) * | 2020-08-18 | 2024-02-20 | Qualcomm Incorporated | Federated learning for client-specific neural network parameter generation for wireless communication |
CN113206855B (en) * | 2021-05-10 | 2022-10-28 | 中国工商银行股份有限公司 | Data access abnormity detection method and device, electronic equipment and storage medium |
JP7122432B1 (en) * | 2021-05-20 | 2022-08-19 | ヤフー株式会社 | Information processing device, information processing method and information processing program |
EP4105833A1 (en) * | 2021-06-17 | 2022-12-21 | Siemens Aktiengesellschaft | Central technical component for generating an aggregated up-dated machine learning parameter |
CN113516118B (en) * | 2021-07-29 | 2023-06-16 | 西北大学 | Multi-mode cultural resource processing method for joint embedding of images and texts |
WO2023022870A1 (en) * | 2021-08-18 | 2023-02-23 | Epiphany Systems, Inc. | Systems and methods for providing data privacy using federated learning |
WO2023112041A1 (en) * | 2021-12-14 | 2023-06-22 | Telefonaktiebolaget Lm Ericsson (Publ) | Enabling federated concept maps in logical architecture of data mesh |
EP4252153A1 (en) * | 2022-02-18 | 2023-10-04 | Google LLC | Privacy-enhanced training and deployment of machine learning models using client-side and server-side data |
EP4276707A1 (en) * | 2022-05-13 | 2023-11-15 | Siemens Aktiengesellschaft | Generating training data to train a machine learning model applied for controlling a production process |
WO2023229716A1 (en) * | 2022-05-26 | 2023-11-30 | Qualcomm Incorporated | Method of determining zone membership in zone-based federated learning |
US11968221B2 (en) * | 2022-06-27 | 2024-04-23 | International Business Machines Corporation | Dynamically federated data breach detection |
US20240119484A1 (en) * | 2022-10-05 | 2024-04-11 | Microsoft Technology Licensing, Llc | Privacy-preserving rules-based targeting using machine learning |
US20240119170A1 (en) * | 2022-10-06 | 2024-04-11 | Thales Dis Cpl Usa, Inc. | Machine learning (ml) model pipeline with obfuscation to protect sensitive data therein |
CN116361561A (en) * | 2023-05-30 | 2023-06-30 | 安徽省模式识别信息技术有限公司 | Distributed cross-border service recommendation method and system based on variational reasoning |
Family Cites Families (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10832165B2 (en) * | 2016-12-02 | 2020-11-10 | Facebook, Inc. | Systems and methods for online distributed embedding services |
US11475291B2 (en) * | 2017-12-27 | 2022-10-18 | X Development Llc | Sharing learned information among robots |
US11475350B2 (en) * | 2018-01-22 | 2022-10-18 | Google Llc | Training user-level differentially private machine-learned models |
-
2019
- 2019-10-23 US US17/770,919 patent/US20220391778A1/en active Pending
- 2019-10-23 CN CN201980101611.6A patent/CN114600106A/en active Pending
- 2019-10-23 WO PCT/US2019/057587 patent/WO2021080577A1/en unknown
- 2019-10-23 EP EP19805432.2A patent/EP4049162A1/en active Pending
Also Published As
Publication number | Publication date |
---|---|
WO2021080577A1 (en) | 2021-04-29 |
EP4049162A1 (en) | 2022-08-31 |
US20220391778A1 (en) | 2022-12-08 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN114600106A (en) | Embedded online federated learning | |
JP6901633B2 (en) | Capsule neural network | |
CN110796190B (en) | Exponential modeling with deep learning features | |
CN109902706B (en) | Recommendation method and device | |
US20220207399A1 (en) | Continuously learning, stable and robust online machine learning system | |
US11295171B2 (en) | Framework for training machine-learned models on extremely large datasets | |
CN109062962B (en) | Weather information fused gated cyclic neural network interest point recommendation method | |
US20200311613A1 (en) | Connecting machine learning methods through trainable tensor transformers | |
EP3494526A1 (en) | Assessing accuracy of a machine learning model | |
CN108431833A (en) | End-to-end depth collaborative filtering | |
CN109478254A (en) | Neural network is trained using composition gradient | |
US10592777B2 (en) | Systems and methods for slate optimization with recurrent neural networks | |
WO2022016556A1 (en) | Neural network distillation method and apparatus | |
CN111652378A (en) | Learning to select vocabulary of category features | |
CN110462638A (en) | Training neural network is sharpened using posteriority | |
EP3561735A1 (en) | Integrating deep learning into generalized additive mixed-effect (game) frameworks | |
CN114298122A (en) | Data classification method, device, equipment, storage medium and computer program product | |
Hartmann | Federated learning | |
KR102515168B1 (en) | Method, apparatus, and system for production optimization of ad contents | |
Song et al. | Coupled variational recurrent collaborative filtering | |
US20210326757A1 (en) | Federated Learning with Only Positive Labels | |
Cacciarelli et al. | Hidden dimensions of the data: Pca vs autoencoders | |
CN116089715A (en) | Sequence recommendation method based on personalized federal technology | |
CN116796038A (en) | Remote sensing data retrieval method, remote sensing data retrieval device, edge processing equipment and storage medium | |
CN114861671A (en) | Model training method and device, computer equipment and storage medium |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination |