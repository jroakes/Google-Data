US20060122957A1 - Method and system to detect e-mail spam using concept categorization of linked content - Google Patents
Method and system to detect e-mail spam using concept categorization of linked content Download PDFInfo
- Publication number
- US20060122957A1 US20060122957A1 US11/004,250 US425004A US2006122957A1 US 20060122957 A1 US20060122957 A1 US 20060122957A1 US 425004 A US425004 A US 425004A US 2006122957 A1 US2006122957 A1 US 2006122957A1
- Authority
- US
- United States
- Prior art keywords
- electronic message
- received information
- hyperlinks
- message
- received
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Abandoned
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q10/00—Administration; Management
- G06Q10/10—Office automation; Time management
- G06Q10/107—Computer-aided management of electronic mailing [e-mailing]
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L51/00—User-to-user messaging in packet-switching networks, transmitted according to store-and-forward or real-time protocols, e.g. e-mail
- H04L51/21—Monitoring or handling of messages
- H04L51/212—Monitoring or handling of messages using filtering or selective blocking
Definitions
- the disclosed embodiments relate generally to electronic message filters. More particularly, the disclosed embodiments relate to methods and systems to detect undesired electronic messages using concept categorization of linked content.
- e-mail also written as “email”
- e-mail has become an extremely popular communication channel for people to exchange information.
- an electronic message is received.
- One or more hyperlinks in the electronic message are identified and information corresponding to at least one of the hyperlinks is received. At least part of the received information is categorized based on semantic relationships in the received information. Based at least in part on the categorization, whether the electronic message meets predefined criteria associated with undesired messages is determined.
- FIG. 1 is a block diagram illustrating an exemplary distributed computer system according to an embodiment of the invention.
- FIG. 2 is a block diagram illustrating message server 102 in accordance with one embodiment of the present invention.
- FIG. 3 is a flowchart representing a method of detecting undesired electronic messages using concept categorization of linked content according to one embodiment.
- FIG. 1 is a block diagram illustrating an exemplary distributed computer system according to one embodiment of the invention.
- This system includes client computer 104 , sender computer 108 , web site 110 , message server 102 , and communication network(s) 106 for interconnecting these components.
- Client 104 includes graphical user interface (GUI) 112 .
- Sender computer 108 sends one or more electronic messages (e.g., e-mail) to client 104 via communications network(s) 106 and server 102 .
- Server 102 receives the electronic message and identifies one or more hyperlinks in the message to other URLs or network addresses, such as a URL or network address for web site 110 .
- GUI graphical user interface
- Server 102 requests and receives information (e.g., a web page or other content) corresponding to the URL or network address from web site 110 and categorizes the concepts in this information based on semantic relationships in the received information. Server 102 determines whether the message meets predefined criteria associated with undesired messages based at least in part on the categorization and filters the message accordingly. Client 104 receives filtered messages via communication network 106 from server 102 . GUI 112 displays the messages.
- information e.g., a web page or other content
- Server 102 determines whether the message meets predefined criteria associated with undesired messages based at least in part on the categorization and filters the message accordingly.
- Client 104 receives filtered messages via communication network 106 from server 102 .
- GUI 112 displays the messages.
- FIG. 2 is a block diagram illustrating message server 102 in accordance with one embodiment of the present invention.
- Server 102 typically includes one or more processing units (CPU's) 202 , one or more network or other communications interfaces 204 , memory 206 , and one or more communication buses 214 for interconnecting these components.
- Server 102 optionally may include a user interface 208 comprising a display device 210 and a keyboard 212 .
- Memory 206 may include high speed random access memory and may also include non-volatile memory, such as one or more magnetic disk storage devices.
- Memory 206 may optionally include one or more storage devices remotely located from the CPU(s) 202 .
- the memory 206 stores the following programs, modules and data structures, or a subset thereof:
- modules and applications corresponds to a set of instructions for performing a function described above.
- modules i.e., sets of instructions
- memory 206 may store a subset of the modules and data structures identified above.
- memory 206 may store additional modules and data structures not described above.
- FIG. 2 shows server 102 as a number of discrete items
- FIG. 2 is intended more as a functional description of the various features which may be present in server 102 rather than as a structural schematic of the embodiments described herein.
- items shown separately could be combined and some items could be separated.
- some items shown separately in FIG. 2 could be implemented on single servers and single items could be implemented by one or more servers.
- the actual number of servers in server 102 and how features are allocated among them will vary from one implementation to another, and may depend in part on the amount of data traffic that the system must handle during peak usage periods as well as during average usage periods.
- FIG. 3 is a flowchart representing a method of detecting undesired electronic messages using concept categorization of linked content according to one embodiment.
- the process shown in FIG. 3 is performed by message server 102 ( FIG. 1 ). It will be appreciated by those of ordinary skill in the art that one or more of the acts described may be performed by hardware, software, or a combination thereof, as may be embodied in one or more computing systems. In other embodiments, an analogous process can be performed by client 104 using components analogous to those shown for server 102 in FIG. 2 .
- Messaging application 220 receives an electronic message ( 302 ) from sender 108 that is being sent to client 104 .
- the electronic message is an e-mail message.
- Spam detection module 224 identifies one or more hyperlinks in the electronic message ( 304 ).
- Spam detection module 224 sends a request for the web page, file, or other information corresponding to the hyperlink(s).
- a web site e.g., 110
- the corresponding information can be substantially all of the information stored at the web site.
- Spam detection module 224 receives information corresponding to at least one of the hyperlinks in the electronic message ( 306 ).
- the received information comprises a web page corresponding to one of the identified hyperlinks.
- Categorization module 226 categorizes the concepts in at least part of the received information based on semantic relationships in the received information ( 308 ). In some embodiments, the categorizing is performed by determining a probability that a concept is part of the received information. In some embodiments, the categorizing is performed by determining respective probabilities that respective concepts are part of the received information and ranking the respective concepts according to those respective probabilities.
- a subset of conceptual categories such as the ones with the highest scores in the received information, are associated with the received message.
- spam detection module 224 determines whether the electronic message meets predefined criteria associated with undesired messages ( 310 ). In some embodiments, if the web page or other information has previously been received ( 306 ) and categorized ( 308 ) for a URL or network address, spam detection module 224 will use the information and/or categorization for that URL/network address that is stored in address database 230 to determine if the message is undesired.
- the categorizing associates a set of categories with the received information, and the determining is performed by generating a score, based on how well the categories match a predefined set of categories (e.g., categories associated with spam), and comparing the score with a threshold.
- the categorizing associates a set of categories with the received information, and the determining includes determining whether any of the N highest ranked categories of the associated categories are included in a predefined set of undesired categories, where N is a predefined number (e.g., a number between 1 and 10). For example, if concepts database 228 includes the concepts (clusters) listed in FIG. 16 of U.S. patent application Ser. No.
- the clusters “free sex porn pic movies xxx” and “nude naked pics pictures photos . . . ” may be predefined as undesirable categories.
- the categories associated with the received information can be compared to these two undesirable categories to determine how well the categories associated with the received information match the undesired categories.
- the comparison can be scored and compared to a threshold score. Alternatively, if any of the undesired concepts matches any of the N highest ranked categories in the received information, the message can be deemed to be undesirable.
- concept characterization is the sole basis for determining if the message is undesirable. For example, if the most probable concept contained in the received information, or in at least one part of the received information, is a concept previously categorized as undesirable, the message is deemed undesirable.
- concept characterization can be combined with other methods to determine if the message is undesirable in accordance with predefined criteria. These methods can examine other features in the message or the received information, such as the page layout (many spammers create new sites by copying one of their previously shut-down sites), the use of graphics, the existence of words like “buy now”, “enter here”, “porn” or “Viagra” that are disproportionate to spam sites, and/or the use of capitalized words.
- a message can be determined to be undesirable by looking at the domain registration information of the web sites associated with the hyperlinks in the message. This information can be determined by performing a who is lookup on the domain names that correspond to the hyperlinks. Domain name registration information of interest may include, without limitation, the contact and address information, and/or the expiration date of the domain name. Spammers typically register a site for just one year (the minimal duration permitted), so an expiration date corresponding to a one-year duration is often a sufficient criterion by itself to identify an undesired message.
- a list of addresses e.g., addresses to which the user has previously sent messages and/or addresses specified by the user
- messaging application 220 includes one or more filters 222 , which filter the message based on the determination of whether the electronic message meets predefined criteria associated with undesired messages ( 312 ). For messages that are determined to be undesirable, filtering can include not sending the message to client 104 , deleting the message, flagging the message as undesirable, or sending the message to a folder labeled as “spam,” “junk mail,” “unsolicited mail,” or other similar name for undesirable messages. In some embodiments, the filtering can be done by another computer, such as client 104 , rather than by server 102 . Messages that are not determined to be undesirable are sent to client 104 (e.g., to an inbox in a messaging application at client 104 ).
Abstract
A system and method for detecting undesired electronic messages (e.g., spam) using concept categorization of hyperlinks is disclosed. A server receives an electronic message and retrieves web pages that correspond to hyperlinks in the message. The server performs concept categorization on the retrieved web pages based on semantic relationships in the received information to determine whether the electronic message meets predefined criteria associated with undesired messages.
Description
- This application is related to U.S. patent application Ser. No. 10/676,571, filed Sep. 30, 2003, entitled “Method and Apparatus for Characterizing Documents Based on Clusters of Related Words,” which application is incorporated by reference herein in its entirety.
- The disclosed embodiments relate generally to electronic message filters. More particularly, the disclosed embodiments relate to methods and systems to detect undesired electronic messages using concept categorization of linked content.
- Every day, people send and receive millions of electronic messages, such as e-mail, over computer networks for business and leisure. Indeed, e-mail (also written as “email”) has become an extremely popular communication channel for people to exchange information.
- Unfortunately, the e-mail that a computer user receives frequently includes spam, unsolicited bulk mailings, junk mail, or other undesired messages. Numerous techniques have been developed to try to detect and filter out such messages, with limited success. Thus, it would be highly desirable to more efficiently detect undesired electronic messages.
- In one aspect of the invention, an electronic message is received. One or more hyperlinks in the electronic message are identified and information corresponding to at least one of the hyperlinks is received. At least part of the received information is categorized based on semantic relationships in the received information. Based at least in part on the categorization, whether the electronic message meets predefined criteria associated with undesired messages is determined.
- For a better understanding of the aforementioned aspect of the invention as well as additional aspects and embodiments thereof, reference should be made to the Description of Embodiments below, in conjunction with the following drawings in which like reference numerals refer to corresponding parts throughout the figures.
-
FIG. 1 is a block diagram illustrating an exemplary distributed computer system according to an embodiment of the invention. -
FIG. 2 is a block diagramillustrating message server 102 in accordance with one embodiment of the present invention. -
FIG. 3 is a flowchart representing a method of detecting undesired electronic messages using concept categorization of linked content according to one embodiment. - Methods and systems are described that show how to detect undesired electronic messages using concept categorization of linked content. Reference will be made to certain embodiments of the invention, examples of which are illustrated in the accompanying drawings. While the invention will be described in conjunction with the embodiments, it will be understood that it is not intended to limit the invention to these particular embodiments alone. On the contrary, the invention is intended to cover alternatives, modifications and equivalents that are within the spirit and scope of the invention as defined by the appended claims.
- Moreover, in the following description, numerous specific details are set forth to provide a thorough understanding of the present invention. However, it will be apparent to one of ordinary skill in the art that the invention may be practiced without these particular details. In other instances, methods, procedures, components, and networks that are well-known to those of ordinary skill in the art are not described in detail to avoid obscuring aspects of the present invention.
-
FIG. 1 is a block diagram illustrating an exemplary distributed computer system according to one embodiment of the invention. This system includesclient computer 104,sender computer 108,web site 110,message server 102, and communication network(s) 106 for interconnecting these components.Client 104 includes graphical user interface (GUI) 112. Sendercomputer 108 sends one or more electronic messages (e.g., e-mail) toclient 104 via communications network(s) 106 andserver 102.Server 102 receives the electronic message and identifies one or more hyperlinks in the message to other URLs or network addresses, such as a URL or network address forweb site 110.Server 102 requests and receives information (e.g., a web page or other content) corresponding to the URL or network address fromweb site 110 and categorizes the concepts in this information based on semantic relationships in the received information.Server 102 determines whether the message meets predefined criteria associated with undesired messages based at least in part on the categorization and filters the message accordingly.Client 104 receives filtered messages viacommunication network 106 fromserver 102. GUI 112 displays the messages. -
FIG. 2 is a block diagramillustrating message server 102 in accordance with one embodiment of the present invention.Server 102 typically includes one or more processing units (CPU's) 202, one or more network orother communications interfaces 204,memory 206, and one ormore communication buses 214 for interconnecting these components.Server 102 optionally may include auser interface 208 comprising adisplay device 210 and akeyboard 212.Memory 206 may include high speed random access memory and may also include non-volatile memory, such as one or more magnetic disk storage devices.Memory 206 may optionally include one or more storage devices remotely located from the CPU(s) 202. In some embodiments, thememory 206 stores the following programs, modules and data structures, or a subset thereof: -
- an
operating system 216 that includes procedures for handling various basic system services and for performing hardware dependent tasks; - a
network communication module 218 that is used for connectingserver 102 to other computers (e.g.,sender 108 and client 104) via one or more communication network interfaces 204 (wired or wireless), such as the Internet, other wide area networks, local area networks, metropolitan area networks, and so on; - a
messaging application 220 with one ormore filters 222 that receives, filters, and distributes electronic messages (e.g., fromsender 108 to client 104); - a
spam detection module 224 that identifies hyperlinks in the messages, requests and receives information (e.g., web pages or files) corresponding to the hyperlinks, and determines whether the message meets predefined criteria associated with undesired messages based at least in part on concept categorization of the received information; - a
concept categorization module 226 that categorizes at least part of the received information into concepts based on semantic relationships in the received information; - a
concepts database 228 that stores concepts (also called clusters because the concepts can be used to generate related words); and - an
address database 230 that stores the URLs and/or network addresses ofweb sites 110 and web pages that have previously been received and categorized, as well as the categorization results for these web sites and web pages.
- an
- Each of the above identified modules and applications corresponds to a set of instructions for performing a function described above. These modules (i.e., sets of instructions) need not be implemented as separate software programs, procedures or modules, and thus various subsets of these modules may be combined or otherwise re-arranged in various embodiments. In some embodiments,
memory 206 may store a subset of the modules and data structures identified above. Furthermore,memory 206 may store additional modules and data structures not described above. - Although
FIG. 2 showsserver 102 as a number of discrete items,FIG. 2 is intended more as a functional description of the various features which may be present inserver 102 rather than as a structural schematic of the embodiments described herein. In practice, and as recognized by those of ordinary skill in the art, items shown separately could be combined and some items could be separated. For example, some items shown separately inFIG. 2 could be implemented on single servers and single items could be implemented by one or more servers. The actual number of servers inserver 102 and how features are allocated among them will vary from one implementation to another, and may depend in part on the amount of data traffic that the system must handle during peak usage periods as well as during average usage periods. -
FIG. 3 is a flowchart representing a method of detecting undesired electronic messages using concept categorization of linked content according to one embodiment. The process shown inFIG. 3 is performed by message server 102 (FIG. 1 ). It will be appreciated by those of ordinary skill in the art that one or more of the acts described may be performed by hardware, software, or a combination thereof, as may be embodied in one or more computing systems. In other embodiments, an analogous process can be performed byclient 104 using components analogous to those shown forserver 102 inFIG. 2 . -
Messaging application 220 receives an electronic message (302) fromsender 108 that is being sent toclient 104. In some embodiments, the electronic message is an e-mail message. -
Spam detection module 224 identifies one or more hyperlinks in the electronic message (304). -
Spam detection module 224 sends a request for the web page, file, or other information corresponding to the hyperlink(s). A web site (e.g., 110) corresponding to the URL or network address in a given request receives the request and sends the corresponding information (i.e., the information stored at a location designated by the URL or network address) toserver 102. In some embodiments, the corresponding information can be substantially all of the information stored at the web site. -
Spam detection module 224 receives information corresponding to at least one of the hyperlinks in the electronic message (306). In some embodiments, the received information comprises a web page corresponding to one of the identified hyperlinks. -
Categorization module 226 categorizes the concepts in at least part of the received information based on semantic relationships in the received information (308). In some embodiments, the categorizing is performed by determining a probability that a concept is part of the received information. In some embodiments, the categorizing is performed by determining respective probabilities that respective concepts are part of the received information and ranking the respective concepts according to those respective probabilities. - In some embodiments, a subset of conceptual categories, such as the ones with the highest scores in the received information, are associated with the received message.
- Based at least in part on the concept categorization (308),
spam detection module 224 determines whether the electronic message meets predefined criteria associated with undesired messages (310). In some embodiments, if the web page or other information has previously been received (306) and categorized (308) for a URL or network address,spam detection module 224 will use the information and/or categorization for that URL/network address that is stored inaddress database 230 to determine if the message is undesired. - In some embodiments, the categorizing associates a set of categories with the received information, and the determining is performed by generating a score, based on how well the categories match a predefined set of categories (e.g., categories associated with spam), and comparing the score with a threshold. In some embodiments, the categorizing associates a set of categories with the received information, and the determining includes determining whether any of the N highest ranked categories of the associated categories are included in a predefined set of undesired categories, where N is a predefined number (e.g., a number between 1 and 10). For example, if
concepts database 228 includes the concepts (clusters) listed inFIG. 16 of U.S. patent application Ser. No. 10/676,571, the clusters “free sex porn pic movies xxx” and “nude naked pics pictures photos . . . ” may be predefined as undesirable categories. The categories associated with the received information can be compared to these two undesirable categories to determine how well the categories associated with the received information match the undesired categories. The comparison can be scored and compared to a threshold score. Alternatively, if any of the undesired concepts matches any of the N highest ranked categories in the received information, the message can be deemed to be undesirable. - In some embodiments, concept characterization is the sole basis for determining if the message is undesirable. For example, if the most probable concept contained in the received information, or in at least one part of the received information, is a concept previously categorized as undesirable, the message is deemed undesirable.
- In other embodiments, concept characterization can be combined with other methods to determine if the message is undesirable in accordance with predefined criteria. These methods can examine other features in the message or the received information, such as the page layout (many spammers create new sites by copying one of their previously shut-down sites), the use of graphics, the existence of words like “buy now”, “enter here”, “porn” or “Viagra” that are disproportionate to spam sites, and/or the use of capitalized words.
- In some embodiments, a message can be determined to be undesirable by looking at the domain registration information of the web sites associated with the hyperlinks in the message. This information can be determined by performing a who is lookup on the domain names that correspond to the hyperlinks. Domain name registration information of interest may include, without limitation, the contact and address information, and/or the expiration date of the domain name. Spammers typically register a site for just one year (the minimal duration permitted), so an expiration date corresponding to a one-year duration is often a sufficient criterion by itself to identify an undesired message.
- In some embodiments, there may also be rules that permit messages received from a list of addresses (e.g., addresses to which the user has previously sent messages and/or addresses specified by the user) to not be considered undesirable, even if links in those messages are suspect.
- In some embodiments,
messaging application 220 includes one ormore filters 222, which filter the message based on the determination of whether the electronic message meets predefined criteria associated with undesired messages (312). For messages that are determined to be undesirable, filtering can include not sending the message toclient 104, deleting the message, flagging the message as undesirable, or sending the message to a folder labeled as “spam,” “junk mail,” “unsolicited mail,” or other similar name for undesirable messages. In some embodiments, the filtering can be done by another computer, such asclient 104, rather than byserver 102. Messages that are not determined to be undesirable are sent to client 104 (e.g., to an inbox in a messaging application at client 104). - The foregoing description, for purpose of explanation, has been described with reference to specific embodiments. However, the illustrative discussions above are not intended to be exhaustive or to limit the invention to the precise forms disclosed. Many modifications and variations are possible in view of the above teachings. The embodiments were chosen and described in order to best explain the principles of the invention and its practical applications, to thereby enable others skilled in the art to best utilize the invention and various embodiments with various modifications as are suited to the particular use contemplated.
Claims (13)
1. A method, comprising:
a. receiving an e-mail message at a message server;
b. identifying one or more hyperlinks in the electronic message;
c. receiving a web page corresponding to one of the hyperlinks;
d. categorizing the received web page based on semantic relationships in the received web page; and
e. determining, based at least in part on the categorization of the received web page, whether the electronic message meets predefined criteria associated with undesired messages.
2. A method, comprising:
a. receiving an electronic message;
b. identifying one or more hyperlinks in the electronic message;
c. receiving information corresponding to at least one of the hyperlinks;
d. categorizing at least part of the received information based on semantic relationships in the received information; and
e. determining, based at least in part on the categorization of at least part of the received information, whether the electronic message meets predefined criteria associated with undesired messages.
3. The method of claim 2 , wherein the electronic message is an e-mail message.
4. The method of claim 2 , wherein the received information comprises a web page corresponding to one of the identified hyperlinks.
5. The method of claim 2 , wherein the categorizing is performed by determining a probability that a concept is part of the received information.
6. The method of claim 2 , wherein the categorizing is performed by determining respective probabilities that respective concepts are part of the received information.
7. The method of claim 6 , wherein the categorizing includes ranking the respective concepts according to the respective probabilities that the respective concepts are present in the received information.
8. The method of claim 2 , further comprising associating a subset of conceptual categories with the received message.
9. The method of claim 2 , wherein the categorizing associates a set of categories with the received information, and the determining is performed by generating a score, associated with how well the associated categories match a predefined set of categories, and comparing the score with a threshold.
10. A system comprising at least one server, wherein said at least one server is configured to:
a. receive an electronic message;
b. identify one or more hyperlinks in the electronic message;
c. receive information corresponding to at least one of the hyperlinks;
d. categorize at least part of the received information based on semantic relationships in the received information; and
e. determine, based at least in part on the categorization of at least part of the received information, whether the electronic message meets predefined criteria associated with undesired messages.
11. A machine readable medium having stored thereon data representing sequences of instructions, which when executed by a computer, cause the computer to:
a. receive an electronic message;
b. identify one or more hyperlinks in the electronic message;
c. receive information corresponding to at least one of the hyperlinks;
d. categorize at least part of the received information based on semantic relationships in the received information; and
e. determine, based at least in part on the categorization of at least part of the received information, whether the electronic message meets predefined criteria associated with undesired messages.
12. A system, comprising:
a. means for receiving an electronic message;
b. means for identifying one or more hyperlinks in the electronic message;
c. means for receiving information corresponding to at least one of the hyperlinks;
d. means for categorizing at least part of the received information based on semantic relationships in the received information; and
e. means for determining, based at least in part on the categorization of at least part of the received information, whether the electronic message meets predefined criteria associated with undesired messages.
13. A method, comprising:
a. receiving an electronic message;
b. identifying one or more hyperlinks in the electronic message;
c. receiving domain name registration information for at least one of the hyperlinks that includes an expiration date of the domain name; and
d. determining, based at least in part on the expiration date of the domain name, whether the electronic message meets predefined criteria associated with undesired messages.
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US11/004,250 US20060122957A1 (en) | 2004-12-03 | 2004-12-03 | Method and system to detect e-mail spam using concept categorization of linked content |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US11/004,250 US20060122957A1 (en) | 2004-12-03 | 2004-12-03 | Method and system to detect e-mail spam using concept categorization of linked content |
Publications (1)
Publication Number | Publication Date |
---|---|
US20060122957A1 true US20060122957A1 (en) | 2006-06-08 |
Family
ID=36575573
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US11/004,250 Abandoned US20060122957A1 (en) | 2004-12-03 | 2004-12-03 | Method and system to detect e-mail spam using concept categorization of linked content |
Country Status (1)
Country | Link |
---|---|
US (1) | US20060122957A1 (en) |
Cited By (19)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20070038616A1 (en) * | 2005-08-10 | 2007-02-15 | Guha Ramanathan V | Programmable search engine |
US20070038614A1 (en) * | 2005-08-10 | 2007-02-15 | Guha Ramanathan V | Generating and presenting advertisements based on context data for programmable search engines |
US20080208987A1 (en) * | 2007-02-26 | 2008-08-28 | Red Hat, Inc. | Graphical spam detection and filtering |
US20080275902A1 (en) * | 2007-05-04 | 2008-11-06 | Microsoft Corporation | Web page analysis using multiple graphs |
US20080275833A1 (en) * | 2007-05-04 | 2008-11-06 | Microsoft Corporation | Link spam detection using smooth classification function |
US20090222435A1 (en) * | 2008-03-03 | 2009-09-03 | Microsoft Corporation | Locally computable spam detection features and robust pagerank |
US7716199B2 (en) | 2005-08-10 | 2010-05-11 | Google Inc. | Aggregating context data for programmable search engines |
US20100154058A1 (en) * | 2007-01-09 | 2010-06-17 | Websense Hosted R&D Limited | Method and systems for collecting addresses for remotely accessible information sources |
US7743045B2 (en) | 2005-08-10 | 2010-06-22 | Google Inc. | Detecting spam related and biased contexts for programmable search engines |
US8244817B2 (en) | 2007-05-18 | 2012-08-14 | Websense U.K. Limited | Method and apparatus for electronic mail filtering |
US8615800B2 (en) | 2006-07-10 | 2013-12-24 | Websense, Inc. | System and method for analyzing web content |
US8838992B1 (en) * | 2011-04-28 | 2014-09-16 | Trend Micro Incorporated | Identification of normal scripts in computer systems |
US8978140B2 (en) | 2006-07-10 | 2015-03-10 | Websense, Inc. | System and method of analyzing web content |
US9015130B1 (en) * | 2008-03-25 | 2015-04-21 | Avaya Inc. | Automatic adjustment of email filters based on browser history and telecommunication records |
US9241259B2 (en) | 2012-11-30 | 2016-01-19 | Websense, Inc. | Method and apparatus for managing the transfer of sensitive information to mobile devices |
US9378282B2 (en) | 2008-06-30 | 2016-06-28 | Raytheon Company | System and method for dynamic and real-time categorization of webpages |
US9654495B2 (en) | 2006-12-01 | 2017-05-16 | Websense, Llc | System and method of analyzing web addresses |
US10169581B2 (en) | 2016-08-29 | 2019-01-01 | Trend Micro Incorporated | Detecting malicious code in sections of computer files |
US20190058771A1 (en) * | 2017-08-16 | 2019-02-21 | T-Mobile Usa, Inc. | Managing mobile notifications received via a wireless communication network |
Citations (12)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5659766A (en) * | 1994-09-16 | 1997-08-19 | Xerox Corporation | Method and apparatus for inferring the topical content of a document based upon its lexical content without supervision |
US6003027A (en) * | 1997-11-21 | 1999-12-14 | International Business Machines Corporation | System and method for determining confidence levels for the results of a categorization system |
US6453315B1 (en) * | 1999-09-22 | 2002-09-17 | Applied Semantics, Inc. | Meaning-based information organization and retrieval |
US6615242B1 (en) * | 1998-12-28 | 2003-09-02 | At&T Corp. | Automatic uniform resource locator-based message filter |
US20030182381A1 (en) * | 2002-03-22 | 2003-09-25 | Fujitsu Limited | Electronic mail delivery refusal method, electronic mail delivery refusal device and storage medium recording a program enabling a computer to execute the method |
US20040210639A1 (en) * | 2003-03-26 | 2004-10-21 | Roy Ben-Yoseph | Identifying and using identities deemed to be known to a user |
US6816857B1 (en) * | 1999-11-01 | 2004-11-09 | Applied Semantics, Inc. | Meaning-based advertising and document relevance determination |
US20040267886A1 (en) * | 2003-06-30 | 2004-12-30 | Malik Dale W. | Filtering email messages corresponding to undesirable domains |
US20050050222A1 (en) * | 2003-08-25 | 2005-03-03 | Microsoft Corporation | URL based filtering of electronic communications and web pages |
US20050071741A1 (en) * | 2003-09-30 | 2005-03-31 | Anurag Acharya | Information retrieval based on historical data |
US20060265498A1 (en) * | 2002-12-26 | 2006-11-23 | Yehuda Turgeman | Detection and prevention of spam |
US7231393B1 (en) * | 2003-09-30 | 2007-06-12 | Google, Inc. | Method and apparatus for learning a probabilistic generative model for text |
-
2004
- 2004-12-03 US US11/004,250 patent/US20060122957A1/en not_active Abandoned
Patent Citations (12)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5659766A (en) * | 1994-09-16 | 1997-08-19 | Xerox Corporation | Method and apparatus for inferring the topical content of a document based upon its lexical content without supervision |
US6003027A (en) * | 1997-11-21 | 1999-12-14 | International Business Machines Corporation | System and method for determining confidence levels for the results of a categorization system |
US6615242B1 (en) * | 1998-12-28 | 2003-09-02 | At&T Corp. | Automatic uniform resource locator-based message filter |
US6453315B1 (en) * | 1999-09-22 | 2002-09-17 | Applied Semantics, Inc. | Meaning-based information organization and retrieval |
US6816857B1 (en) * | 1999-11-01 | 2004-11-09 | Applied Semantics, Inc. | Meaning-based advertising and document relevance determination |
US20030182381A1 (en) * | 2002-03-22 | 2003-09-25 | Fujitsu Limited | Electronic mail delivery refusal method, electronic mail delivery refusal device and storage medium recording a program enabling a computer to execute the method |
US20060265498A1 (en) * | 2002-12-26 | 2006-11-23 | Yehuda Turgeman | Detection and prevention of spam |
US20040210639A1 (en) * | 2003-03-26 | 2004-10-21 | Roy Ben-Yoseph | Identifying and using identities deemed to be known to a user |
US20040267886A1 (en) * | 2003-06-30 | 2004-12-30 | Malik Dale W. | Filtering email messages corresponding to undesirable domains |
US20050050222A1 (en) * | 2003-08-25 | 2005-03-03 | Microsoft Corporation | URL based filtering of electronic communications and web pages |
US20050071741A1 (en) * | 2003-09-30 | 2005-03-31 | Anurag Acharya | Information retrieval based on historical data |
US7231393B1 (en) * | 2003-09-30 | 2007-06-12 | Google, Inc. | Method and apparatus for learning a probabilistic generative model for text |
Cited By (39)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9031937B2 (en) | 2005-08-10 | 2015-05-12 | Google Inc. | Programmable search engine |
US7743045B2 (en) | 2005-08-10 | 2010-06-22 | Google Inc. | Detecting spam related and biased contexts for programmable search engines |
US8452746B2 (en) | 2005-08-10 | 2013-05-28 | Google Inc. | Detecting spam search results for context processed search queries |
US8316040B2 (en) | 2005-08-10 | 2012-11-20 | Google Inc. | Programmable search engine |
US8756210B1 (en) | 2005-08-10 | 2014-06-17 | Google Inc. | Aggregating context data for programmable search engines |
US20070038616A1 (en) * | 2005-08-10 | 2007-02-15 | Guha Ramanathan V | Programmable search engine |
US7693830B2 (en) | 2005-08-10 | 2010-04-06 | Google Inc. | Programmable search engine |
US7716199B2 (en) | 2005-08-10 | 2010-05-11 | Google Inc. | Aggregating context data for programmable search engines |
US20070038614A1 (en) * | 2005-08-10 | 2007-02-15 | Guha Ramanathan V | Generating and presenting advertisements based on context data for programmable search engines |
US9680866B2 (en) | 2006-07-10 | 2017-06-13 | Websense, Llc | System and method for analyzing web content |
US9723018B2 (en) | 2006-07-10 | 2017-08-01 | Websense, Llc | System and method of analyzing web content |
US9003524B2 (en) | 2006-07-10 | 2015-04-07 | Websense, Inc. | System and method for analyzing web content |
US8615800B2 (en) | 2006-07-10 | 2013-12-24 | Websense, Inc. | System and method for analyzing web content |
US8978140B2 (en) | 2006-07-10 | 2015-03-10 | Websense, Inc. | System and method of analyzing web content |
US9654495B2 (en) | 2006-12-01 | 2017-05-16 | Websense, Llc | System and method of analyzing web addresses |
US20100154058A1 (en) * | 2007-01-09 | 2010-06-17 | Websense Hosted R&D Limited | Method and systems for collecting addresses for remotely accessible information sources |
US8881277B2 (en) * | 2007-01-09 | 2014-11-04 | Websense Hosted R&D Limited | Method and systems for collecting addresses for remotely accessible information sources |
US8291021B2 (en) * | 2007-02-26 | 2012-10-16 | Red Hat, Inc. | Graphical spam detection and filtering |
US20080208987A1 (en) * | 2007-02-26 | 2008-08-28 | Red Hat, Inc. | Graphical spam detection and filtering |
US7788254B2 (en) | 2007-05-04 | 2010-08-31 | Microsoft Corporation | Web page analysis using multiple graphs |
US8805754B2 (en) | 2007-05-04 | 2014-08-12 | Microsoft Corporation | Link spam detection using smooth classification function |
US20080275902A1 (en) * | 2007-05-04 | 2008-11-06 | Microsoft Corporation | Web page analysis using multiple graphs |
US20080275833A1 (en) * | 2007-05-04 | 2008-11-06 | Microsoft Corporation | Link spam detection using smooth classification function |
US8494998B2 (en) | 2007-05-04 | 2013-07-23 | Microsoft Corporation | Link spam detection using smooth classification function |
US7941391B2 (en) | 2007-05-04 | 2011-05-10 | Microsoft Corporation | Link spam detection using smooth classification function |
US9473439B2 (en) | 2007-05-18 | 2016-10-18 | Forcepoint Uk Limited | Method and apparatus for electronic mail filtering |
US8799388B2 (en) | 2007-05-18 | 2014-08-05 | Websense U.K. Limited | Method and apparatus for electronic mail filtering |
US8244817B2 (en) | 2007-05-18 | 2012-08-14 | Websense U.K. Limited | Method and apparatus for electronic mail filtering |
US20090222435A1 (en) * | 2008-03-03 | 2009-09-03 | Microsoft Corporation | Locally computable spam detection features and robust pagerank |
US8010482B2 (en) | 2008-03-03 | 2011-08-30 | Microsoft Corporation | Locally computable spam detection features and robust pagerank |
US9015130B1 (en) * | 2008-03-25 | 2015-04-21 | Avaya Inc. | Automatic adjustment of email filters based on browser history and telecommunication records |
US9378282B2 (en) | 2008-06-30 | 2016-06-28 | Raytheon Company | System and method for dynamic and real-time categorization of webpages |
US8838992B1 (en) * | 2011-04-28 | 2014-09-16 | Trend Micro Incorporated | Identification of normal scripts in computer systems |
US9241259B2 (en) | 2012-11-30 | 2016-01-19 | Websense, Inc. | Method and apparatus for managing the transfer of sensitive information to mobile devices |
US10135783B2 (en) | 2012-11-30 | 2018-11-20 | Forcepoint Llc | Method and apparatus for maintaining network communication during email data transfer |
US10169581B2 (en) | 2016-08-29 | 2019-01-01 | Trend Micro Incorporated | Detecting malicious code in sections of computer files |
US10834217B2 (en) * | 2017-08-16 | 2020-11-10 | T-Mobile Usa, Inc. | Managing mobile notifications received via a wireless communication network |
US20190058771A1 (en) * | 2017-08-16 | 2019-02-21 | T-Mobile Usa, Inc. | Managing mobile notifications received via a wireless communication network |
US11652902B2 (en) | 2017-08-16 | 2023-05-16 | T-Mobile Usa, Inc. | Managing mobile notifications received via a wireless communication network |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US20060122957A1 (en) | Method and system to detect e-mail spam using concept categorization of linked content | |
US7359941B2 (en) | Method and apparatus for filtering spam email | |
US7984029B2 (en) | Reliability of duplicate document detection algorithms | |
US8935348B2 (en) | Message classification using legitimate contact points | |
US6732149B1 (en) | System and method for hindering undesired transmission or receipt of electronic messages | |
US8108475B2 (en) | Methods and apparatus for categorizing failure messages that result from email messages | |
JP4799057B2 (en) | Incremental anti-spam lookup and update services | |
US8554847B2 (en) | Anti-spam profile clustering based on user behavior | |
US8095602B1 (en) | Spam whitelisting for recent sites | |
US6732157B1 (en) | Comprehensive anti-spam system, method, and computer program product for filtering unwanted e-mail messages | |
US8959159B2 (en) | Personalized email interactions applied to global filtering | |
US10826873B2 (en) | Classifying E-mail connections for policy enforcement | |
US20060259558A1 (en) | Method and program for handling spam emails | |
KR20050022284A (en) | Url based filtering of electronic communications and web pages | |
US7624274B1 (en) | Decreasing the fragility of duplicate document detecting algorithms | |
CN1774706A (en) | Framework to enable integration of anti-spam technologies | |
US20070011347A1 (en) | Method and apparatus for reducing spam on peer-to-peer networks | |
US9246860B2 (en) | System, method and computer program product for gathering information relating to electronic content utilizing a DNS server | |
US20060195542A1 (en) | Method and system for determining the probability of origin of an email | |
US20070233777A1 (en) | Methods, systems, and computer program products for dynamically classifying web pages | |
US20130247208A1 (en) | System, method, and computer program product for preventing data leakage utilizing a map of data | |
JPH11252158A (en) | Electronic mail information management method and device and storage medium recording electronic mail information management processing program | |
US8375089B2 (en) | Methods and systems for protecting E-mail addresses in publicly available network content | |
KR100480878B1 (en) | Method for preventing spam mail by using virtual mail address and system therefor | |
JP2002056001A (en) | Device for extracting expert and computer-readable recording medium with expert extraction program recorded thereon |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:CHEN, JOHNNY;REEL/FRAME:016065/0188Effective date: 20041202 |
|
STCB | Information on status: application discontinuation |
Free format text: ABANDONED -- FAILURE TO RESPOND TO AN OFFICE ACTION |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044142/0357Effective date: 20170929 |