US20130022108A1 - Quantization parameter derivation from qp predictor - Google Patents
Quantization parameter derivation from qp predictor Download PDFInfo
- Publication number
- US20130022108A1 US20130022108A1 US13/540,157 US201213540157A US2013022108A1 US 20130022108 A1 US20130022108 A1 US 20130022108A1 US 201213540157 A US201213540157 A US 201213540157A US 2013022108 A1 US2013022108 A1 US 2013022108A1
- Authority
- US
- United States
- Prior art keywords
- units
- quantization parameter
- video content
- quantization
- region
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Abandoned
Links
Images
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/169—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding
- H04N19/17—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding the unit being an image region, e.g. an object
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/102—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or selection affected or controlled by the adaptive coding
- H04N19/124—Quantisation
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/134—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or criterion affecting or controlling the adaptive coding
- H04N19/136—Incoming video signal characteristics or properties
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/134—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or criterion affecting or controlling the adaptive coding
- H04N19/157—Assigned coding mode, i.e. the coding mode being predefined or preselected to be further used for selection of another element or parameter
- H04N19/159—Prediction type, e.g. intra-frame, inter-frame or bidirectional frame prediction
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/46—Embedding additional information in the video signal during the compression process
- H04N19/463—Embedding additional information in the video signal during the compression process by compressing encoding parameters before transmission
Definitions
- Video compression systems employ block processing for most of the compression operations.
- a block is a group of neighboring pixels and may be treated as one coding unit in terms of the compression operations. Theoretically, a larger coding unit is preferred to take advantage of correlation among immediate neighboring pixels.
- Various video compression standards e.g., Motion Picture Expert Group (MPEG)-1, MPEG-2, and MPEG-4, use block sizes of 4 ⁇ 4, 8 ⁇ 8, and 16 ⁇ 16 (referred to as a macroblock (MB)).
- MPEG Motion Picture Expert Group
- MPEG-4 use block sizes of 4 ⁇ 4, 8 ⁇ 8, and 16 ⁇ 16 (referred to as a macroblock (MB)).
- High efficiency video coding is also a block-based hybrid spatial and temporal predictive coding scheme.
- HEVC partitions an input picture into square blocks referred to as largest coding units (LCUs) as shown in FIG. 1A .
- LCU largest coding units
- the LCU can be as large as 128 ⁇ 128 pixels.
- Each LCU can be partitioned into smaller square blocks called coding units (CUs).
- FIG. 1B shows an example of an LCU partition of CUs.
- An LCU 100 is first partitioned into four CUs 102 .
- Each CU 102 may also be further split into four smaller CUs 102 that are a quarter of the size of the CU 102 .
- CUs 102 - 1 , 102 - 3 , and 102 - 4 are a quarter of the size of LCU 100 . Further, a CU 102 - 2 has been split into four CUs 102 - 5 , 102 - 6 , 102 - 7 , and 102 - 8 .
- FIG. 1C shows a quadtree 104 of the LCU partition shown in FIG. 1B .
- Each node of quadtree 104 is assigned a flag of “1” if the node is further split into four sub-nodes and assigned a flag of “0” if the node is not split.
- the flag is called a split bit (e.g. 1 ) or stop bit (e.g., 0 ) and is coded in a compressed bitstream.
- a node 106 - 1 includes a flag “1” at a top CU level because LCU 100 is split into 4 CUs. At an intermediate CU level, the flags indicate whether a CU 102 is further split into four CUs 102 . In this case, a node 106 - 3 includes a flag of “1” because CU 102 - 2 has been split into four CUs 102 - 5 - 102 - 8 . Nodes 106 - 2 , 106 - 4 , and 106 - 5 include a flag of “0” because these CUs 102 are not split.
- Nodes 106 - 6 , 106 - 7 , 106 - 8 , and 106 - 9 are at a bottom CU level and hence, no flag bit of “0” or ‘1” is necessary for those nodes because corresponding CUs 102 - 5 - 102 - 8 are not split.
- the quadtree data representation for quadtree 104 shown in FIG. 1C may be represented by the binary data of “10100”, where each bit represents a node 106 of quadtree 104 .
- the binary data indicates the LCU partitioning to the encoder and decoder, and this binary data needs to be coded and transmitted as overhead.
- each CU may be associated with a quantization parameter.
- the quantization parameter regulates how much spatial detail is saved. When the quantization parameter is very small, almost all of the detail is retained. As the quantization parameter is increased, some of that detail is aggregated so that the bitrate drops resulting in some increase in distortion and some loss of quality.
- the quantization parameter needs to be signaled from an encoder to a decoder. In one example, every quantization parameter for every CU is signaled. This constitutes a lot of overhead.
- the differences in quantization parameters may also be sent.
- the encoder only sends the difference between a quantization parameter of a previously-coded CU and a quantization parameter for a current CU. Although the differences reduce the amount of overhead, the differences still need to be sent for every CU.
- a method for determining quantization parameters includes determining one or more first units of video content in a grouping of units and analyzing whether the one or more first units of video content in the grouping of units have all the coefficients for the video content that are zero. The method then determines whether a quantization parameter for one or more second units of video content different from the one or more first units of video content is to be used to derive the quantization parameter for the one or more first units of video content. When the quantization parameter for the one or more second units of video content is to be used, the quantization parameter for the one or more first units of video content is derived from the quantization parameter for the one or more second units of video content.
- a method for determining quantization parameters for one or more first units of video content in a grouping of units, the method comprising: determining, by a computing device, a quantization parameter for one or more second units of video content different from the one or more first units of video content; determining, by the computing device, the received quantization parameter is to be used to derive a quantization parameter for the one or more first units of video content, wherein the one or more first units of video content are in the grouping of units and have all the coefficients for the video content that are zero; and using, by the computing device, the derived quantization parameter in decoding the one or more first units of video content.
- a method for encoding video content includes receiving a unit of video content where the unit is partitioned into a grouping of blocks. Quantization parameters associated with the grouping of blocks are determined The method then determines a quantization parameter representation based on the quantization parameters and the grouping of blocks. When a node of the quantization parameter representation is associated with a block that is split into additional blocks, node information is set to indicate whether or not the additional blocks have a same quantization parameter. The method sends quantization information for the quantization parameters for the grouping of blocks based on the quantization parameter representation.
- a method for decoding video content includes: receiving a bitstream for a unit of video content, wherein the unit is partitioned into a grouping of blocks; determining, by a computing device, a quantization parameter representation based on a plurality of quantization parameters and the grouping of blocks, wherein when a node of the quantization parameter representation is associated with a block that is split into additional blocks, node information is set to indicate whether or not the additional blocks have a same quantization parameter; determining, by the computing device, a quantization parameter associated with a current block being decoded using the quantization parameter representation; and using the quantization parameter in a quantization step.
- FIG. 1A shows an example of a largest coding unit (LCU).
- LCU largest coding unit
- FIG. 1B shows an example of an LCU partition of coding units (CUs).
- FIG. 1C shows a quadtree of the LCU partition shown in FIG. 1B .
- FIG. 2 shows an example of a system for encoding and decoding video content according to one embodiment.
- FIG. 3 shows an example of a CU partition of the LCU according to one embodiment.
- FIG. 4 shows a quantization unit partition for the LCU according to one embodiment.
- FIG. 5A shows an example of a coding unit quadtree (CQT) according to one embodiment.
- FIG. 5B shows an example of a quantization unit quadtree (QQT) according to one embodiment.
- FIG. 6 shows a first scenario for the QQT according to one embodiment.
- FIG. 7 shows a second scenario for the QQT according to one embodiment.
- FIG. 8 shows an example of a third scenario for the QQT according to one embodiment.
- FIG. 9 depicts a fourth scenario for the QQT according to one embodiment.
- FIG. 10 shows a fifth example of the QQT according to one embodiment.
- FIG. 11 shows the scan order within an LCU according to one embodiment.
- FIG. 12 shows the five possible coded neighbor CUs for a current CU according to one embodiment.
- FIG. 13 depicts an example of a TU partitioning within an LCU.
- FIG. 14 depicts the following QP values are used according to one embodiment.
- FIG. 15 depicts the QP values that are used according to one embodiment.
- FIG. 16 depicts an example of a unit of video content being coded using QP adaptation according to one embodiment.
- FIG. 17 depicts a simplified flowchart for using a QQT at the encoder according to one embodiment.
- FIG. 18 depicts a simplified flowchart for using a QQT at the decoder according to one embodiment.
- FIG. 19A depicts an example of the encoder according to one embodiment.
- FIG. 19B depicts an example of the decoder according to one embodiment.
- FIG. 2 shows an example of a system for encoding and decoding video content according to one embodiment.
- the system includes an encoder 200 and a decoder 201 , both of which will be described in more detail below.
- a quantization parameter is allowed to vary from block to block, such as from coding unit (CU) to CU.
- CU coding unit
- QU quantization unit
- a quantization unit may cover multiple CUs.
- overhead in signaling between encoder 200 and decoder 201 may be saved by not sending information for quantization parameters for some blocks within a quantization unit.
- FIG. 3 shows an example of a CU partition of an LCU 300 according to one embodiment
- FIG. 4 shows a quantization unit partition for LCU 300 according to one embodiment.
- Some CUs may share the same quantization parameter. These CUs may be grouped into a quantization unit.
- coding units CU 1 , CU 2 , CU 3 , and CU 4 share the same quantization parameter Q 1 .
- the area covered by coding units CU 1 , CU 2 , CU 3 , and CU 4 is considered one quantization unit.
- the area covered by coding units CU 9 , CU 10 , CUM and CU 12 shares the same quantization parameter Q 6 and is therefore also considered one quantization unit.
- Coding units CU 8 and CU 13 do not share the same quantization parameter and are not associated with a quantization unit.
- coding unit CU 8 is associated with quantization parameter Q 5
- coding unit CU 13 is associated with quantization parameter Q 7 .
- the coding unit partition may be associated with a data structure that describes the partitioning.
- a coding unit quadtree CQT
- FIG. 5A shows an example of a CQT according to one embodiment.
- the CQT may be determined as described above with respect to FIG. 1C .
- a quantization unit quadtree (QQT) is used to represent the partitioning of quantization units.
- the QQT follows the coding unit quadtree. For example, as in the CQT, the QQT starts at the LCU level. If the CQT assigns a bit “ 1 ” at a node, then this means there are other blocks, such as four blocks, branched out from this node. Then, the QQT also needs to assign a bit, either “0” or “1”, at the node, indicating if the four blocks share the same quantization parameter or not.
- the QQT does not need to insert any bit at the node as there are no blocks branching out from the node.
- bit values of “1” and “0” are described, it will be understood that other information may be assigned to the quadtrees.
- a node 502 - 1 indicates the LCU is split into four CUs.
- nodes 502 - 2 and 502 - 3 indicate a corresponding CU is split into four CUs.
- nodes 502 - 2 and 502 - 4 correspond to coding units CU 1 -CU 7 .
- a node 502 - 4 indicates that another unit is split into four coding units.
- node 502 - 4 corresponds to coding units CU 1 -CU 4 .
- node 502 - 3 corresponds to coding units CU 9 -CU 12 .
- a bit is set to indicate whether the quantization parameter for the blocks branched out from that node are the same. For example, a bit is set at “0” if the quantization parameters for blocks branching out for that node are the same and set at “1” if the quantization parameters for the blocks are different.
- node 504 - 1 indicates that the quantization parameters are different for the four blocks branching out from node 504 - 1 .
- Node 504 - 2 is set at “1”, which indicates that the quantization parameters are also different.
- a node 504 - 3 is set at “0”, which indicates that coding units CU 1 -CU 4 have the same quantization parameter Q 1 . Also, a node 504 - 4 is set at “0” and this indicates that these coding units CU 9 -CU 12 share the same quantization parameter Q 6 .
- a QQT manager 204 - 1 in encoder 200 generates a QQT based on the quantization parameters for the coding units.
- QQT manager 204 then sends information for the QQT to decoder 201 .
- information for quantization parameters for some coding units might not have to be sent. For example, if a set of coding units have the same quantization parameter, then encoder 200 sends information for the quantization parameter for one coding unit in the quantization unit. Then, encoder 200 does not need to send the same information for the quantization parameter for the other coding units because the quantization parameter is the same.
- encoder 200 determines the QP differences, which are coded and transmitted instead of the quantization parameter. Using the QQT, certain differences may not have to be sent.
- a QQT manager 204 - 2 in decoder 201 receives the QQT and then interprets the QQT to determine quantization parameters for the coding units. For example, the quantization parameter is determined for a CU in a set of CUs. If the QQT indicates the set of CUs include the same quantization parameter, decoder 201 uses that quantization parameter in a quantization step for all the CUs.
- the QQT is overhead in that the QQT needs to be signaled from encoder 200 to decoder 201 . However, as discussed above, overhead may be saved because information for quantization parameters for each coding unit may not need to be sent.
- the following examples illustrate the possible scenarios in which the QQT may be coded depending on the QU partition within the LCU. Conventionally, the differences, dQ 1 , dQ 2 , dQ 3 , dQ 4 , dQ 5 , dQ 6 , dQ 7 , dQ 8 , dQ 9 , dQ 10 , dQ 11 , dQ 12 , and dQ 13 , are sent for all the CUs 1 - 13 , respectively.
- FIG. 6 shows a first scenario for the QQT according to one embodiment.
- the first scenario none of the four blocks branched out from nodes in the CQT share the same quantization parameter values. In this case, the differences for all of the CUs, CU 1 -CU 13 , need to be coded and transmitted. Additionally, the overhead for the QQT is 4 bits of “1111”.
- FIG. 7 shows a second scenario for the QQT according to one embodiment. If four blocks branched out from any node of the CQT share the same quantization parameter value, overhead may be saved. For example, if CU 1 , CU 2 , CU 3 , and CU 4 share the same quantization parameter, the bits for 3 QP differences, the differences dQ 2 , dQ 3 , and dQ 4 can be saved (i.e., these differences do not need to be sent).
- the overhead for the QQT is 4 bits of “1110”.
- FIG. 8 shows an example of a third scenario for the QQT according to one embodiment. If coding units CU 1 -CU 7 share the same quantization parameter, the bits for 6 quantization parameter differences, dQ 2 -dQ 7 , can be saved.
- the QQT overhead is 3 bits of “101”. Bits for blocks under a node 802 do not need to be sent because the “0” value indicates that the quantization parameters are the same for blocks branching out from node 802 . Even though a coding unit associated with a node 804 branches out to four more blocks, the “0” value at node 802 indicates that these four more blocks have the same quantization parameters and thus a bit of “0” does not need to be sent for node 804 .
- FIG. 9 depicts a fourth scenario for the QQT according to one embodiment. If CU 1 -CU 7 share the same quantization parameter, and CU 9 -CU 12 share another quantization parameter, the bits for 9 QP differences, dQ 2 -dQ 7 and dQ 10 -dQ 12 , can be saved.
- the QQT overhead is 3 bits of “100”.
- FIG. 10 shows a fifth example of the QQT according to one embodiment. If the quantization parameter is the same for all CUs, then only one difference, dQ 1 , needs to be coded and transmitted. The bits for 12 QP differences, dQ 2 -dQ 13 , are saved. The QQT overhead is now 1 bit of “0”.
- certain scenarios may save bits that need to be sent by not having the differences sent for certain blocks that have the same quantization parameter.
- the QQT is then used to determine which blocks have the same quantization parameter.
- quantization parameters are allowed to vary for a further partitioning, such as quantization parameters vary for a prediction unit (PU)
- an additional bit may be required to indicate if PUs within a CU share the same quantization parameter or not. If PUs within a current CU use the same quantization parameter, a bit “ 0 ” is assigned to the CU, and only one dQP needs to be coded and transmitted for the CU. Otherwise, if PUs within a current CU use different QPs, a bit “ 1 ” is assigned to the CU and one dQP is coded and transmitted for each of the PUs within the CU. If quantization parameters are allowed to vary for a further partitioning, such as quantization parameters vary for a transform unit (TU), an additional bit may be required to indicate if TUs within a PU share the same quantization parameter or not.
- TU transform unit
- Quantization parameters can be coded predictably. As described in FIG. 1 , all LCUs within a picture/slice are coded along a raster scan order, which is from left to right and top to bottom. Within an LCU, coding at each level of the CQT starts from the top-left quadrant, and is followed by the top-right quadrant, bottom-left quadrant and bottom-right quadrant. FIG. 11 shows the scan order within an LCU according to one embodiment.
- FIG. 12 shows the 5 possible coded neighbor CUs for a current CU according to one embodiment.
- the current CU is denoted as “X” as a CU X.
- the neighbor CUs are noted as CUs A, B, C, D, E.
- Q X is a quantization parameter for a current CU, CU X, and quantization parameters Q A , Q B , Q C , Q D , and Q E are the quantization parameters for coded neighbor CUs A, B, C, D, and E.
- the left-neighbor quantization parameter QA is a mean of quantization parameters of the left-neighbor CUs. The mean may be the average of the quantization parameters.
- the above-neighbor quantization parameter, Q B is the mean of the quantization parameters of the above-neighbor CUs.
- a coded LCU may maintain only one quantization parameter for quantization parameter prediction purposes, defined as a mean, media, mode, etc. of quantization parameters of all CUs within the LCU. For example, for current CU X, its left-neighbor CUs A and E are in the left LCU, both quantization parameters Q A and Q E are equal to the quantization parameter of left LCU Q left — LCU .
- ⁇ Q X Q X ⁇ Q X is coded.
- the prediction is the quantization parameter for one of the neighboring CUs.
- ⁇ Q X may be limited by a specific range and position. For example, ⁇ Q X can be limited to ⁇ 6, ⁇ 3, ⁇ 1, 0, 1, 3, 6 ⁇ , ⁇ 3, ⁇ 2, ⁇ 1, 0, 1, 2, ⁇ 3 ⁇ , or ⁇ 2, ⁇ 1, 0, 1, 2 ⁇ .
- the quantization prediction can be defined as the mean, media, mode, etc. of quantization parameters of all or some available coded neighbor CUs or the quantization parameter one specific neighbor. Availability of the neighbor can be defined as the neighbor with the same coding mode (intra, inter, skip). The following include different examples in which the quantization parameter prediction may be determined. It will be understood other examples may also be appreciated.
- Quantization parameters may change at a sub-tree block level.
- a CU may be various sizes, such as 64 ⁇ 64 and 32 ⁇ 32.
- quantization parameter adjustment at a CU or larger level may not be fast enough to respond to changes in content characteristics and buffer conditions.
- a 64 ⁇ 64 CU may select a 2N ⁇ N prediction unit (PU) type where the two PUs represent very different characteristics, such as one is on the edge of an object and the other is in the background.
- PU 2N ⁇ N prediction unit
- the quantization parameter can also be adapted to adjust to a compressed bitrate.
- This quantization parameter change inside the CU may be provided by allowing quantization parameters to be changed at a sub-CU level, such as at prediction unit (PU) or a transform unit (TU) level.
- a sub-CU level such as at prediction unit (PU) or a transform unit (TU) level.
- the TU/PU may be as small as a 4 ⁇ 4 block and 4 ⁇ 8 block, respectively, and constraints may need to be used for quantization parameter adjustment at the TU/PU level because excessive overhead may result.
- the overhead may result because of the signaling needed to send the changes for the quantization parameters for the TU/PU blocks.
- Overhead can also be saved by having decoder 201 implicitly determine the QP parameter.
- two constraints are applied that may keep quantization parameter differences overhead low.
- the first constraint and the second constraint may be used in combination or separately.
- the constraints may use a minimum size or dimension of QP adjustment parameter and a fixed quantization parameter per TU/PU size or area.
- the minimum size of QP adjustment parameter is a global parameter. This constraint limits the smallest area allowed for QP adjustment and it takes effect when TU/PU size or area is smaller than this parameter.
- equation (1) may be used:
- QP(m,n) is QP of a TU/PU size
- maximum, m and p are width of coding TU/PU and sub-CU area
- n and q are height of coding TU/PU and sub-CU area, respectively.
- minimum size or area of QP adjustment parameter is less than TU/PU size or area, that TU/PU can have its own QP.
- the second constraint sets all TUs/PUs of the same size or area within a same CU to use the same quantization parameter.
- the maximum number of differences that are required to be sent is reduced from a total number of sub-CUs within a CU to a number of TU/PU sizes or areas allowed.
- one quantization parameter for multiple TU/PU sizes or areas such as a quantization parameter QP_a for TU size 32 ⁇ 32 and 16 ⁇ 16, and QP_b for TU size 8 ⁇ 8 and 4 ⁇ 4 or QP_a for PU size 2N ⁇ 2N, and QP_b for PU size 2N ⁇ N, 2N ⁇ 0.5N, 0.5N ⁇ 2N, N ⁇ 2N.
- FIG. 13 depicts an example of a TU partitioning within an LCU.
- a sub-tree size of 64 ⁇ 64 is shown.
- four CUs 1302 - 1 , 1302 - 2 , 1302 - 3 , and 1302 - 4 of 32 ⁇ 32 are chosen in the sub-tree block.
- a top-left CU 1302 - 1 uses N ⁇ 2N PUs.
- a top-right CU 1302 - 2 uses N ⁇ N PUs and the remaining two CUs 1302 - 3 and 1302 - 4 use 2N ⁇ 2N PUs.
- Dashed lines indicate a TU boundary.
- the number in each of the blocks inside the sub-tree block denotes the processing order of each TU block. For example, a TU # 1 is processed first followed by a TU # 2 , etc.
- QP values that may be used.
- FIG. 14 depicts the following QP values are used according to one embodiment. Also, the following summarizes the QP values:
- A, B, C, D, E, F, G, H are QP value between 0 and 51
- FIG. 15 depicts the QP values that are used according to one embodiment. The following values are reproduced as follows:
- A, B, D, E, G, H are QP value between 0 and 51.
- Predictive coding may be used to code the quantization parameters.
- the difference between a current quantization parameter and a predictive quantization parameter, dQP is coded and sent in the bitstream.
- dQP predictive quantization parameter
- particular embodiments define the QP predictor to be the quantization parameter of the same TU size from the most-recently coded TU.
- the QP predictor is updated once per TU of a particular TU size.
- the dQP is computed for each TU size larger than the sub-CU. Only the dQP for a TU size that is present in the sub-CU and not equal to 0 is coded. Missing dQP information implies that the difference dQP for that TU size is 0.
- the dQP can be computed as follows:
- a relationship between different TU sizes can be defined at a global level, such as a slice or sequence level.
- This approach only requires that the dQP for each CU to determine the base quantization parameter.
- a QP predictor may be the base quantization parameter of the most recent re-coded CU of the same type, such as a CU coded in intra or inter mode.
- the quantization parameter for each TU size within a CU is then determined based on the quantization parameter relationship of that size relative to the base quantization parameter.
- Another possible solution is to use the average quantization parameter of TU blocks within the most-recently coded CU of the same type.
- the following equations specify an example of QP coding as described above:
- the dQP overhead is not present and is presumed to be 0 . That is, the quantization parameter of the same TU size from a CU neighbor indicated by a motion vector predictor index is used.
- Particular embodiments may always maintain the same quantization parameter of all TUs with the same TU size within a CU. That is, the quantization parameter of different TU sizes is independent of each other.
- a QP predictor of each TU size can be defined based on its associated CU.
- the TU size of the most-recently coded CU is used as an example of a QP predictor in that section.
- various other predictors can be used with the proposed adaptive QP algorithm in some predictor determination methods that are described below.
- One example to define a CU for the purpose of determining a QP predictor is to rely on adjacent CU neighbors. Different ways may be used to identify the exact CU neighbor, such as by explicitly signaling the exact CU neighbor in the bitstream or implicitly determining the exact CU neighbor based on available information at decoder 201 . In one example, an indexing scheme is used as the explicit signaling.
- One example of implicit signaling is to use a CU that is derived from the predictor motion vector index of the current CU. CUs of the same size from a co-located CU can be used as the reference TU in a current CU. For intra CUs, the CU that contains pixels used for intra prediction can also be used as reference for QP prediction. The TU of the same size as in the reference TU can be used as a reference for QP prediction.
- FIG. 16 depicts an example of video content 1650 being coded using QP adaptation according to one embodiment.
- Video content 1650 may include groupings of units (A-F) 1652 .
- the units may be multiple coding units (CUs), prediction units (PUs), or transform units (TU).
- the grouping of CUs may be an LCU.
- grouping of units E is partitioned into units E 0 -E 9 in a coding order.
- the units may be CUs, PUs or TUs.
- a current grouping of units may be divided into two regions.
- Region 1 includes all the units with coded block flags (cbf) equal to zero, along a coding order, but before the first unit with a non-zero cbf within the current grouping of units.
- Region 2 includes the first unit with a non-zero cbf and the rest of units along the coding order.
- units in a grouping of units 1652 may use a QP predictor for that grouping of units 1652 .
- units in grouping of units E may use the QP predictor for grouping of units E, which may be derived from QP of a coded unit or a grouping of coded units, such as a unit or a grouping of units most recently coded that is the same type as the grouping of units E. This may occur when some units, such as a first number of units in a coding order in grouping of units E, have all the coefficients equal to zero. For example, in FIG.
- units E 0 and E 1 form region # 1 and have the QP set to the QP predictor of the grouping of units E.
- Region # 2 is formed that includes the first coded unit in the grouping, unit E 2 , and the subsequent units E 3 -E 9 in grouping of units E.
- Region # 2 may have its own QP, which may be coded along with unit E 2 .
- the QP predictor of the grouping of units E is used for all the units in the grouping of units E.
- the QP for region # 1 may or may not need to be signalled. Two examples are shown as follows.
- a method for determining quantization parameters includes determining one or more first units of video content in a grouping of units.
- the first units may be CUs, TUs, or PUs.
- the first units may be in a first region.
- the method analyzes whether the one or more first units of video content have all of the coefficients for the video content that are zero.
- the method determines whether a quantization parameter for one or more second units of video content different from the one or more first units of video content is to be used to derive as the quantization parameter for the one or more first units of video content.
- the second units may be a neighboring unit or units to the first units in the first region.
- the quantization parameter for the one or more first units of video content is derived from the quantization parameter for the one or more second units of video content.
- the quantization parameter for the second units is used as the quantization parameter for the first units.
- a method for determining quantization parameters for one or more first units of video content in a grouping of units.
- the first units may be in a first region.
- the method determines a quantization parameter for one or more second units of video content different from the one or more first units of video content.
- the second units include a neighboring unit or neighboring grouping of units to the first units.
- the method determines whether the quantization parameter for the one or more second units of video content is to be used to derive a quantization parameter for the one or more first units of video content.
- the first units of video content have all the coefficients for the video content that are zero.
- the derived quantization parameter is used as the quantization parameter in decoding the one or more first units of video content.
- one or more third units of video content in a second region that have a beginning unit in a coding order among units of the one or more third units with coefficients for the video content that are non-zero are determined.
- the method may determine a second quantization parameter for the one or more third units.
- FIG. 17 depicts a simplified flowchart for using a QQT at encoder 200 according to one embodiment.
- a unit of video content is received.
- the unit may be an LCU being currently encoded.
- the LCU is partitioned into a plurality of blocks, such as CUs.
- quantization parameters associated with the plurality of blocks are determined For example, quantization parameters for each CU are determined
- a quantization parameter representation based on the quantization parameters and the partitions is determined For example the QQT is determined When a node of the QQT is associated with a block that is split into additional blocks in a corresponding CQT, information is set to indicate whether or not the additional blocks have a same quantization parameter.
- quantization parameters that do not need to be sent from encoder 200 to decoder 201 are determined
- encoder 200 sends the quantization parameter representation and information for the quantization parameters that do need to be sent to decoder 201 .
- Encoder 200 does not send information for the quantization parameters that do not need to be sent.
- FIG. 18 depicts a simplified flowchart for using a QQT at decoder 201 according to one embodiment.
- decoder 201 receives a bitstream for a unit of video content.
- the unit may be an LCU being currently decoded.
- the LCU is partitioned into a plurality of blocks, such as CUs.
- decoder 201 determines a block to decode.
- decoder 201 determines if information for the quantization parameter for the block was sent.
- the QQT is used to determine the quantization parameter from a block that has the same quantization parameter.
- decoder 201 determines that quantization parameter.
- FIG. 19A depicts an example of encoder 200 according to one embodiment. It will be understood that variations on the encoding process described will be appreciated by a person skilled in the art based on the disclosure and teachings herein.
- a spatial prediction block 1804 may include different spatial prediction directions per PU, such as horizontal, vertical, 45-degree diagonal, 135-degree diagonal, DC (flat averaging), and planar.
- a temporal prediction block 1806 performs temporal prediction through a motion estimation operation.
- the motion estimation operation searches for a best match prediction for the current PU over reference pictures.
- the best match prediction is described by a motion vector (MV) and associated reference picture (refldx).
- MV motion vector
- reffldx reference picture
- the motion vector and associated reference picture are included in the coded bitstream.
- Transform block 1806 performs a transform operation with the residual PU, e. Transform block 1806 outputs the residual PU in a transform domain, E.
- a quantizer 1808 then quantizes the transform coefficients of the residual PU, E.
- Quantizer 1808 converts the transform coefficients into a finite number of possible values.
- Entropy coding block 1810 entropy encodes the quantized coefficients, which results in final compression bits to be transmitted. Different entropy coding methods may be used, such as context-adaptive variable length coding (CAVLC) or context-adaptive binary arithmetic coding (CABAC).
- CAVLC context-adaptive variable length coding
- CABAC context-adaptive binary arithmetic coding
- a de-quantizer 1812 de-quantizes the quantized transform coefficients of the residual PU.
- De-quantizer 1812 then outputs the de-quantized transform coefficients of the residual PU, E′.
- An inverse transform block 1814 receives the de-quantized transform coefficients, which are then inverse transformed resulting in a reconstructed residual PU, e′.
- the reconstructed PU, e′ is then added to the corresponding prediction, x′, either spatial or temporal, to form the new reconstructed PU, x′′.
- a loop filter 1816 performs de-blocking on the reconstructed PU, x′′, to reduce blocking artifacts.
- loop filter 1816 may perform a sample adaptive offset process after the completion of the de-blocking filter process for the decoded picture, which compensates for a pixel value offset between reconstructed pixels and original pixels. Also, loop filter 1806 may perform adaptive loop filtering over the reconstructed PU, which minimizes coding distortion between the input and output pictures. Additionally, if the reconstructed pictures are reference pictures, the reference pictures are stored in a reference buffer 1818 for future temporal prediction.
- FIG. 19B depicts an example of decoder 201 according to one embodiment. It will be understood that variations on the decoding process described will be appreciated by a person skilled in the art based on the disclosure and teachings herein. Decoder 201 receives input bits from encoder 200 for encoded video content.
- An entropy decoding block 1830 performs entropy decoding on the input bitstream to generate quantized transform coefficients of a residual PU.
- a de-quantizer 1832 de-quantizes the quantized transform coefficients of the residual PU.
- De-quantizer 1832 then outputs the de-quantized transform coefficients of the residual PU, e′.
- An inverse transform block 1834 receives the de-quantized transform coefficients, which are then inverse transformed resulting in a reconstructed residual PU, e′.
- the reconstructed PU, e′ is then added to the corresponding prediction, x′, either spatial or temporal, to form the new reconstructed PU, x′′.
- a loop filter 1836 performs de-blocking on the reconstructed PU, x′′, to reduce blocking artifacts. Additionally, loop filter 1836 may perform a sample adaptive offset process after the completion of the de-blocking filter process for the decoded picture, which compensates for a pixel value offset between reconstructed pixels and original pixels. Also, loop filter 1836 may perform adaptive loop filtering over the reconstructed PU, which minimizes coding distortion between the input and output pictures. Additionally, if the reconstructed pictures are reference pictures, the reference pictures are stored in a reference buffer 1838 for future temporal prediction.
- the prediction PU, x′ is obtained through either spatial prediction or temporal prediction.
- a spatial prediction block 1840 may receive decoded spatial prediction directions per PU, such as horizontal, vertical, 45-degree diagonal, 135-degree diagonal, DC (flat averaging), and planar. The spatial prediction directions are used to determine the prediction PU, x′.
- a temporal prediction block 1842 performs temporal prediction through a motion estimation operation.
- a decoded motion vector is used to determine the prediction PU, x′. Interpolation may be used in the motion estimation operation.
- Particular embodiments may be implemented in a non-transitory computer-readable storage medium for use by or in connection with the instruction execution system, apparatus, system, or machine.
- the computer-readable storage medium contains instructions for controlling a computer system to perform a method described by particular embodiments.
- the instructions when executed by one or more computer processors, may be operable to perform that which is described in particular embodiments.
Abstract
Description
- The present application claims priority to:
- U.S. Provisional App. No. 61/503,597 for “Method for Quantization Quadtree for HEVC” filed Jun. 30, 2011;
- U.S. Provisional App. No. 61/503,566 for “Method for Adaptive QP Coding at Sub-CU Level” filed Jun. 30, 2011;
- U.S. Provisional App. No. 61/506,550 for “Predictive QP Coding at Sub-CU Level” filed Jul. 11, 2011;
- U.S. Provisional App. No. 61/511,013 for “Coding Delta QP at TU Block” filed Jul. 22, 2011;
- U.S. Provisional App. No. 61/538,293 for “QP Coding Methods for Sub-CU Level Adaptation” filed Sep. 23, 2011;
- U.S. Provisional App. No. 61/538,792 for “QP Coding in CU and TU” filed Sep. 23, 2011;
- U.S. Provisional App. No. 61/547,760 for “CU and TU Combined QP Coding with Maximum Depth Threshold Control” filed Oct. 5, 2011;
- U.S. Provisional App. No. 61/547,033 for “CU dQP syntax Change and Combing with TU dQP syntax” filed Oct. 13, 2011;
- U.S. Provisional App. No. 61/557,419 for “A proposal for the coding of TU Delta QP at the same TU Depth” filed Nov. 9, 2011;
- U.S. Provisional App. No. 61/558,417 for “QP Adaptation at Sub-CU level” filed Nov. 10, 2011; and
- U.S. Provisional App. No. 61/559,040 for “A Unified CU and TU QP Coding with Separable Depth Threshold Control” filed Nov. 11, 2011;
- U.S. Provisional App. No. 61/586,780 for “QP Adaptation at Sub-CU level in HEVC” filed Jan. 14, 2012; and
- U.S. Provisional App. No. 61/590,803 for “Syntax of QP Adaptation at Sub-CU level in HEVC” filed Jan. 25, 2012, the contents of all of which are incorporated herein by reference in their entirety.
- Video compression systems employ block processing for most of the compression operations. A block is a group of neighboring pixels and may be treated as one coding unit in terms of the compression operations. Theoretically, a larger coding unit is preferred to take advantage of correlation among immediate neighboring pixels. Various video compression standards, e.g., Motion Picture Expert Group (MPEG)-1, MPEG-2, and MPEG-4, use block sizes of 4×4, 8×8, and 16×16 (referred to as a macroblock (MB)).
- High efficiency video coding (HEVC) is also a block-based hybrid spatial and temporal predictive coding scheme. HEVC partitions an input picture into square blocks referred to as largest coding units (LCUs) as shown in
FIG. 1A . Unlike prior coding standards, the LCU can be as large as 128×128 pixels. Each LCU can be partitioned into smaller square blocks called coding units (CUs).FIG. 1B shows an example of an LCU partition of CUs. An LCU 100 is first partitioned into four CUs 102. Each CU 102 may also be further split into four smaller CUs 102 that are a quarter of the size of the CU 102. This partitioning process can be repeated based on certain criteria, such as limits to the number of times a CU can be partitioned may be imposed. As shown, CUs 102-1, 102-3, and 102-4 are a quarter of the size ofLCU 100. Further, a CU 102-2 has been split into four CUs 102-5, 102-6, 102-7, and 102-8. - A quadtree data representation is used to describe how an
LCU 100 is partitioned into CUs.FIG. 1C shows aquadtree 104 of the LCU partition shown inFIG. 1B . Each node ofquadtree 104 is assigned a flag of “1” if the node is further split into four sub-nodes and assigned a flag of “0” if the node is not split. The flag is called a split bit (e.g. 1) or stop bit (e.g., 0) and is coded in a compressed bitstream. - A node 106-1 includes a flag “1” at a top CU level because LCU 100 is split into 4 CUs. At an intermediate CU level, the flags indicate whether a CU 102 is further split into four CUs 102. In this case, a node 106-3 includes a flag of “1” because CU 102-2 has been split into four CUs 102-5-102-8. Nodes 106-2, 106-4, and 106-5 include a flag of “0” because these CUs 102 are not split. Nodes 106-6, 106-7, 106-8, and 106-9 are at a bottom CU level and hence, no flag bit of “0” or ‘1” is necessary for those nodes because corresponding CUs 102-5-102-8 are not split. The quadtree data representation for
quadtree 104 shown inFIG. 1C may be represented by the binary data of “10100”, where each bit represents a node 106 ofquadtree 104. The binary data indicates the LCU partitioning to the encoder and decoder, and this binary data needs to be coded and transmitted as overhead. - In some cases, each CU may be associated with a quantization parameter. The quantization parameter regulates how much spatial detail is saved. When the quantization parameter is very small, almost all of the detail is retained. As the quantization parameter is increased, some of that detail is aggregated so that the bitrate drops resulting in some increase in distortion and some loss of quality. The quantization parameter needs to be signaled from an encoder to a decoder. In one example, every quantization parameter for every CU is signaled. This constitutes a lot of overhead.
- The differences in quantization parameters may also be sent. The encoder only sends the difference between a quantization parameter of a previously-coded CU and a quantization parameter for a current CU. Although the differences reduce the amount of overhead, the differences still need to be sent for every CU.
- In one embodiment, a method for determining quantization parameters is provided. The method includes determining one or more first units of video content in a grouping of units and analyzing whether the one or more first units of video content in the grouping of units have all the coefficients for the video content that are zero. The method then determines whether a quantization parameter for one or more second units of video content different from the one or more first units of video content is to be used to derive the quantization parameter for the one or more first units of video content. When the quantization parameter for the one or more second units of video content is to be used, the quantization parameter for the one or more first units of video content is derived from the quantization parameter for the one or more second units of video content.
- In one embodiment, a method is provided for determining quantization parameters for one or more first units of video content in a grouping of units, the method comprising: determining, by a computing device, a quantization parameter for one or more second units of video content different from the one or more first units of video content; determining, by the computing device, the received quantization parameter is to be used to derive a quantization parameter for the one or more first units of video content, wherein the one or more first units of video content are in the grouping of units and have all the coefficients for the video content that are zero; and using, by the computing device, the derived quantization parameter in decoding the one or more first units of video content.
- In one embodiment, a method for encoding video content is provided. The method includes receiving a unit of video content where the unit is partitioned into a grouping of blocks. Quantization parameters associated with the grouping of blocks are determined The method then determines a quantization parameter representation based on the quantization parameters and the grouping of blocks. When a node of the quantization parameter representation is associated with a block that is split into additional blocks, node information is set to indicate whether or not the additional blocks have a same quantization parameter. The method sends quantization information for the quantization parameters for the grouping of blocks based on the quantization parameter representation.
- In one embodiment, a method for decoding video content includes: receiving a bitstream for a unit of video content, wherein the unit is partitioned into a grouping of blocks; determining, by a computing device, a quantization parameter representation based on a plurality of quantization parameters and the grouping of blocks, wherein when a node of the quantization parameter representation is associated with a block that is split into additional blocks, node information is set to indicate whether or not the additional blocks have a same quantization parameter; determining, by the computing device, a quantization parameter associated with a current block being decoded using the quantization parameter representation; and using the quantization parameter in a quantization step.
- The following detailed description and accompanying drawings provide a more detailed understanding of the nature and advantages of particular embodiments.
-
FIG. 1A shows an example of a largest coding unit (LCU). -
FIG. 1B shows an example of an LCU partition of coding units (CUs). -
FIG. 1C shows a quadtree of the LCU partition shown inFIG. 1B . -
FIG. 2 shows an example of a system for encoding and decoding video content according to one embodiment. -
FIG. 3 shows an example of a CU partition of the LCU according to one embodiment. -
FIG. 4 shows a quantization unit partition for the LCU according to one embodiment. -
FIG. 5A shows an example of a coding unit quadtree (CQT) according to one embodiment. -
FIG. 5B shows an example of a quantization unit quadtree (QQT) according to one embodiment. -
FIG. 6 shows a first scenario for the QQT according to one embodiment. -
FIG. 7 shows a second scenario for the QQT according to one embodiment. -
FIG. 8 shows an example of a third scenario for the QQT according to one embodiment. -
FIG. 9 depicts a fourth scenario for the QQT according to one embodiment. -
FIG. 10 shows a fifth example of the QQT according to one embodiment. -
FIG. 11 shows the scan order within an LCU according to one embodiment. -
FIG. 12 shows the five possible coded neighbor CUs for a current CU according to one embodiment. -
FIG. 13 depicts an example of a TU partitioning within an LCU. -
FIG. 14 depicts the following QP values are used according to one embodiment. -
FIG. 15 depicts the QP values that are used according to one embodiment. -
FIG. 16 depicts an example of a unit of video content being coded using QP adaptation according to one embodiment. -
FIG. 17 depicts a simplified flowchart for using a QQT at the encoder according to one embodiment. -
FIG. 18 depicts a simplified flowchart for using a QQT at the decoder according to one embodiment. -
FIG. 19A depicts an example of the encoder according to one embodiment. -
FIG. 19B depicts an example of the decoder according to one embodiment. - Described herein are techniques for a video compression system. In the following description, for purposes of explanation, numerous examples and specific details are set forth in order to provide a thorough understanding of particular embodiments. Particular embodiments as defined by the claims may include some or all of the features in these examples alone or in combination with other features described below, and may further include modifications and equivalents of the features and concepts described herein.
-
FIG. 2 shows an example of a system for encoding and decoding video content according to one embodiment. The system includes anencoder 200 and adecoder 201, both of which will be described in more detail below. - A quantization parameter (QP) is allowed to vary from block to block, such as from coding unit (CU) to CU. Particular embodiments use a quantization unit (QU) to represent an area with the same quantization parameter. For example, a quantization unit may cover multiple CUs. As will be discussed, below, overhead in signaling between
encoder 200 anddecoder 201 may be saved by not sending information for quantization parameters for some blocks within a quantization unit. -
FIG. 3 shows an example of a CU partition of anLCU 300 according to one embodiment andFIG. 4 shows a quantization unit partition forLCU 300 according to one embodiment. Some CUs may share the same quantization parameter. These CUs may be grouped into a quantization unit. For example, coding units CU1, CU2, CU3, and CU4 share the same quantization parameter Q1. In this case, the area covered by coding units CU1, CU2, CU3, and CU4 is considered one quantization unit. Also, the area covered by coding units CU9, CU10, CUM and CU12 shares the same quantization parameter Q6 and is therefore also considered one quantization unit. Coding units CU8 and CU13 do not share the same quantization parameter and are not associated with a quantization unit. In this case, coding unit CU8 is associated with quantization parameter Q5 and coding unit CU13 is associated with quantization parameter Q7. - The coding unit partition may be associated with a data structure that describes the partitioning. For example, a coding unit quadtree (CQT) can be generated based on the partitioning of CUs in the LCU.
FIG. 5A shows an example of a CQT according to one embodiment. The CQT may be determined as described above with respect toFIG. 1C . - In addition to the CQT, particular embodiments use another data structure, such as a quadtree representation, to describe the partitioning of the quantization units. For example, a quantization unit quadtree (QQT) is used to represent the partitioning of quantization units. The QQT follows the coding unit quadtree. For example, as in the CQT, the QQT starts at the LCU level. If the CQT assigns a bit “1” at a node, then this means there are other blocks, such as four blocks, branched out from this node. Then, the QQT also needs to assign a bit, either “0” or “1”, at the node, indicating if the four blocks share the same quantization parameter or not. Otherwise, if the CQT assigns a bit “0” at a node meaning there are no blocks branched out from this node, the QQT does not need to insert any bit at the node as there are no blocks branching out from the node. Although bit values of “1” and “0” are described, it will be understood that other information may be assigned to the quadtrees.
- Referring to
FIG. 5A , a node 502-1 indicates the LCU is split into four CUs. Also, nodes 502-2 and 502-3 indicate a corresponding CU is split into four CUs. For example, nodes 502-2 and 502-4 correspond to coding units CU1-CU7. A node 502-4 indicates that another unit is split into four coding units. For example, node 502-4 corresponds to coding units CU1-CU4. Also, node 502-3 corresponds to coding units CU9-CU12. - Referring to
FIG. 5B , for each node in the CQT in which nodes are split, a bit is set to indicate whether the quantization parameter for the blocks branched out from that node are the same. For example, a bit is set at “0” if the quantization parameters for blocks branching out for that node are the same and set at “1” if the quantization parameters for the blocks are different. In one example, node 504-1 indicates that the quantization parameters are different for the four blocks branching out from node 504-1. Node 504-2 is set at “1”, which indicates that the quantization parameters are also different. A node 504-3 is set at “0”, which indicates that coding units CU1-CU4 have the same quantization parameter Q1. Also, a node 504-4 is set at “0” and this indicates that these coding units CU9-CU12 share the same quantization parameter Q6. - Referring back to
FIG. 2 , a QQT manager 204-1 inencoder 200 generates a QQT based on the quantization parameters for the coding units. QQT manager 204 then sends information for the QQT todecoder 201. Because the QQT is sent, information for quantization parameters for some coding units might not have to be sent. For example, if a set of coding units have the same quantization parameter, then encoder 200 sends information for the quantization parameter for one coding unit in the quantization unit. Then,encoder 200 does not need to send the same information for the quantization parameter for the other coding units because the quantization parameter is the same. Rather, the QQT is used to determine that the same quantization parameter is applied to the set of coding units. In one embodiment,encoder 200 determines the QP differences, which are coded and transmitted instead of the quantization parameter. Using the QQT, certain differences may not have to be sent. - A QQT manager 204-2 in
decoder 201 receives the QQT and then interprets the QQT to determine quantization parameters for the coding units. For example, the quantization parameter is determined for a CU in a set of CUs. If the QQT indicates the set of CUs include the same quantization parameter,decoder 201 uses that quantization parameter in a quantization step for all the CUs. - The QQT is overhead in that the QQT needs to be signaled from
encoder 200 todecoder 201. However, as discussed above, overhead may be saved because information for quantization parameters for each coding unit may not need to be sent. The following examples illustrate the possible scenarios in which the QQT may be coded depending on the QU partition within the LCU. Conventionally, the differences, dQ1, dQ2, dQ3, dQ4, dQ5, dQ6, dQ7, dQ8, dQ9, dQ10, dQ11, dQ12, and dQ13, are sent for all the CUs 1-13, respectively.FIG. 6 shows a first scenario for the QQT according to one embodiment. In the first scenario, none of the four blocks branched out from nodes in the CQT share the same quantization parameter values. In this case, the differences for all of the CUs, CU1-CU13, need to be coded and transmitted. Additionally, the overhead for the QQT is 4 bits of “1111”. -
FIG. 7 shows a second scenario for the QQT according to one embodiment. If four blocks branched out from any node of the CQT share the same quantization parameter value, overhead may be saved. For example, if CU1, CU2, CU3, and CU4 share the same quantization parameter, the bits for 3 QP differences, the differences dQ2, dQ3, and dQ4 can be saved (i.e., these differences do not need to be sent). The overhead for the QQT is 4 bits of “1110”. -
FIG. 8 shows an example of a third scenario for the QQT according to one embodiment. If coding units CU1-CU7 share the same quantization parameter, the bits for 6 quantization parameter differences, dQ2-dQ7, can be saved. The QQT overhead is 3 bits of “101”. Bits for blocks under a node 802 do not need to be sent because the “0” value indicates that the quantization parameters are the same for blocks branching out from node 802. Even though a coding unit associated with a node 804 branches out to four more blocks, the “0” value at node 802 indicates that these four more blocks have the same quantization parameters and thus a bit of “0” does not need to be sent for node 804. -
FIG. 9 depicts a fourth scenario for the QQT according to one embodiment. If CU1-CU7 share the same quantization parameter, and CU9-CU12 share another quantization parameter, the bits for 9 QP differences, dQ2-dQ7 and dQ10-dQ12, can be saved. The QQT overhead is 3 bits of “100”. -
FIG. 10 shows a fifth example of the QQT according to one embodiment. If the quantization parameter is the same for all CUs, then only one difference, dQ1, needs to be coded and transmitted. The bits for 12 QP differences, dQ2-dQ13, are saved. The QQT overhead is now 1 bit of “0”. - Accordingly, using the QQT, certain scenarios may save bits that need to be sent by not having the differences sent for certain blocks that have the same quantization parameter. The QQT is then used to determine which blocks have the same quantization parameter.
- In one embodiment, if quantization parameters are allowed to vary for a further partitioning, such as quantization parameters vary for a prediction unit (PU), an additional bit may be required to indicate if PUs within a CU share the same quantization parameter or not. If PUs within a current CU use the same quantization parameter, a bit “0” is assigned to the CU, and only one dQP needs to be coded and transmitted for the CU. Otherwise, if PUs within a current CU use different QPs, a bit “1” is assigned to the CU and one dQP is coded and transmitted for each of the PUs within the CU. If quantization parameters are allowed to vary for a further partitioning, such as quantization parameters vary for a transform unit (TU), an additional bit may be required to indicate if TUs within a PU share the same quantization parameter or not.
- Quantization parameters can be coded predictably. As described in
FIG. 1 , all LCUs within a picture/slice are coded along a raster scan order, which is from left to right and top to bottom. Within an LCU, coding at each level of the CQT starts from the top-left quadrant, and is followed by the top-right quadrant, bottom-left quadrant and bottom-right quadrant.FIG. 11 shows the scan order within an LCU according to one embodiment. - With the above coding order, given a CU, there can be multiple coded neighbor CUs.
FIG. 12 shows the 5 possible coded neighbor CUs for a current CU according to one embodiment. The current CU is denoted as “X” as a CU X. The neighbor CUs are noted as CUs A, B, C, D, E. - In one embodiment, QX is a quantization parameter for a current CU, CU X, and quantization parameters QA, QB, QC, QD, and QE are the quantization parameters for coded neighbor CUs A, B, C, D, and E. If a current CU X has multiple left-neighbor CUs, the left-neighbor quantization parameter QA is a mean of quantization parameters of the left-neighbor CUs. The mean may be the average of the quantization parameters. If a current CU X has multiple above-neighbor CUs, the above-neighbor quantization parameter, QB, is the mean of the quantization parameters of the above-neighbor CUs.
- If the vertical size of a current CU X is smaller than its left-neighbor CU, then quantization parameter QA=quantization parameter QB. If the horizontal size of current CU X is smaller than its above-neighbor CU, then quantization parameter QB=quantization parameter QC. Additionally, to reduce a memory requirement, a coded LCU may maintain only one quantization parameter for quantization parameter prediction purposes, defined as a mean, media, mode, etc. of quantization parameters of all CUs within the LCU. For example, for current CU X, its left-neighbor CUs A and E are in the left LCU, both quantization parameters QA and QE are equal to the quantization parameter of left LCU Qleft
— LCU. - In one embodiment, for the current CU X, instead of a quantization parameter QX being sent, a difference between QX and its prediction
Q X is coded. That is, the difference quantization parameter, ΔQX=QX−Q X is coded. The prediction is the quantization parameter for one of the neighboring CUs. Additionally, for a smooth quality variation, ΔQX may be limited by a specific range and position. For example, ΔQX can be limited to {−6, −3, −1, 0, 1, 3, 6}, {−3, −2, −1, 0, 1, 2, −3}, or {−2, −1, 0, 1, 2}. - The quantization prediction can be defined as the mean, media, mode, etc. of quantization parameters of all or some available coded neighbor CUs or the quantization parameter one specific neighbor. Availability of the neighbor can be defined as the neighbor with the same coding mode (intra, inter, skip). The following include different examples in which the quantization parameter prediction may be determined. It will be understood other examples may also be appreciated.
-
- If 5 neighbor CUs are available,
-
Q X=Pred {QA, QB, QC, QD, QE}, -
- If CU C is not available,
-
Q X=Pred {QA , QB, QD, QE} -
- If CU E is not available,
-
Q X=Pred {QA, QB, QC, QD} -
- If CUs A, D and E are not available,
-
Q X=pred {QB, QC} -
- If CUs B, C and D are not available,
-
Q X=Pred {QA, QE} -
- In order to avoid store the coding information of above LCU rows, a CU at the top row of a LCU may not use quantization parameters of CUs above. In this case, only CUs A and E may be used, that is,
-
Q X=Pred {QA, QE} -
- If only three CUs are allowed, the options can be
-
Q X=Pred {QA, QB, QC} - or
-
Q X=Pred {QA, QB, QD} - or
-
Q X=Pred {QA, QB, QE} -
- If one of neighbor has the same code mode, such as intra, inter, as the current CU, but not other CUs, the quantization parameter of this same code mode neighbor is used as the quantization parameter for the current CU.
-
- In cases where QP per either PU or TU is allowed, the above discussions and definition for quantization parameter prediction are extended to either PU or TU.
- Quantization parameters may change at a sub-tree block level. A CU may be various sizes, such as 64×64 and 32×32. Hence, quantization parameter adjustment at a CU or larger level may not be fast enough to respond to changes in content characteristics and buffer conditions. For example, a 64×64 CU may select a 2N×N prediction unit (PU) type where the two PUs represent very different characteristics, such as one is on the edge of an object and the other is in the background. In this example, it may be beneficial to have the freedom to use different quantization parameters for different PUs. The quantization parameter can also be adapted to adjust to a compressed bitrate. This quantization parameter change inside the CU may be provided by allowing quantization parameters to be changed at a sub-CU level, such as at prediction unit (PU) or a transform unit (TU) level. However, the TU/PU may be as small as a 4×4 block and 4×8 block, respectively, and constraints may need to be used for quantization parameter adjustment at the TU/PU level because excessive overhead may result. The overhead may result because of the signaling needed to send the changes for the quantization parameters for the TU/PU blocks. Overhead can also be saved by having
decoder 201 implicitly determine the QP parameter. - In one embodiment, two constraints are applied that may keep quantization parameter differences overhead low. The first constraint and the second constraint may be used in combination or separately. For example, the constraints may use a minimum size or dimension of QP adjustment parameter and a fixed quantization parameter per TU/PU size or area. The minimum size of QP adjustment parameter is a global parameter. This constraint limits the smallest area allowed for QP adjustment and it takes effect when TU/PU size or area is smaller than this parameter. For example, the following equation (1) may be used:
-
QP(m,n)=QP(p,q) if m≦p and n≦q (1) - where QP(m,n) is QP of a TU/PU size, maximum, m and p are width of coding TU/PU and sub-CU area, and n and q are height of coding TU/PU and sub-CU area, respectively. In the case where minimum size or area of QP adjustment parameter is less than TU/PU size or area, that TU/PU can have its own QP.
- The second constraint sets all TUs/PUs of the same size or area within a same CU to use the same quantization parameter. Thus, the maximum number of differences that are required to be sent is reduced from a total number of sub-CUs within a CU to a number of TU/PU sizes or areas allowed. When this constraint is used with the first constraint, which requires all TUs/PUs of a size or area smaller than a sub-CU, if any, to employ the same quantization parameter, these constraints provide higher impact when CU size is large and sub-CU size is small. Also, it is possible to use one quantization parameter for multiple TU/PU sizes or areas, such as a quantization parameter QP_a for
TU size 32×32 and 16×16, and QP_b for TU size 8×8 and 4×4 or QP_a for PU size 2N×2N, and QP_b for PU size 2N×N, 2N×0.5N, 0.5N×2N, N×2N. -
FIG. 13 depicts an example of a TU partitioning within an LCU. A sub-tree size of 64×64 is shown. In this example, four CUs 1302-1, 1302-2, 1302-3, and 1302-4 of 32×32 are chosen in the sub-tree block. A top-left CU 1302-1 uses N×2N PUs. A top-right CU 1302-2 uses N×N PUs and the remaining two CUs 1302-3 and 1302-4 use 2N×2N PUs. - Dashed lines indicate a TU boundary. The number in each of the blocks inside the sub-tree block denotes the processing order of each TU block. For example, a
TU # 1 is processed first followed by aTU # 2, etc. The following describes examples for QP values that may be used. - In the case that a minimum size of QP adjustment parameter is 4×4,
FIG. 14 depicts the following QP values are used according to one embodiment. Also, the following summarizes the QP values: -
Q(1)=Q(2)=A,TU size 16×16 in the same top left CU -
Q(3)=Q(8)=Q(13)=Q(18)=B, TU size 8×8 in the same top left CU -
Q(4)=Q(5)=Q(6)=Q(7)= -
Q(9)=Q(10)=Q(11)=Q(12)= -
Q(14)=Q(15)=Q(16)=Q(17)= -
Q(19)=Q(20)=Q(21)=Q(22)=C,TU size 4×4 in the same top left CU -
Q(44)=D,TU size 16×16 in the same top right CU -
Q(27)=Q(32)=Q(33)=Q(34)= -
Q(35)=(Q36)=Q(41)=Q(42)=Q(43)=E, TU size 8x8 in the same top right CU -
Q(23)=Q(24)=Q(25)=Q(26)= -
Q(28)=Q(29)=Q(30)=Q(31)= -
Q(37)=Q(38)=Q(39)=Q(40)=F,TU size 4×4 in the same top right CU -
Q(45)=G,TU size 16×16 in the same top right CU -
Q(46)=H,TU size 16×16 in the same bottom right CU - where A, B, C, D, E, F, G, H are QP value between 0 and 51
- In the case that the minimum size of QP adjustment parameters 8×8,
FIG. 15 depicts the QP values that are used according to one embodiment. The following values are reproduced as follows: -
Q(3)=Q(8)=Q(13)=Q(18)=B, TU size 8×8 in the same top left CU -
Q(4)=Q(5)=Q(6)=Q(7)= -
Q(9)=Q(10)=Q(11)=Q(12)= -
Q(14)=Q(15)=Q(16)=Q(17)= -
Q(19)=Q(20)=Q(21)=Q(22)=B,TU size 4×4 in the same top left CU -
Q(44)=D,TU size 16×16 in the same top right CU -
Q(27)=Q(32)=Q(33)=Q(34)= -
Q(35)=(Q36)=Q(41)=Q(42)=Q(43)=E, TU size 8x8 in the same top right CU -
Q(23)=Q(24)=Q(25)=Q(26)= -
Q(28)=Q(29)=Q(30)=Q(31)= -
Q(37)=Q(38)=Q(39)=Q(40)=E,TU size 4×4 in the same top right CU -
Q(45)=G,TU size 16×16 in the same top right CU -
Q(46)=H,TU size 16×16 in the same bottom right CU - where A, B, D, E, G, H are QP value between 0 and 51.
- Predictive coding may be used to code the quantization parameters. The difference between a current quantization parameter and a predictive quantization parameter, dQP, is coded and sent in the bitstream. In one example, particular embodiments define the QP predictor to be the quantization parameter of the same TU size from the most-recently coded TU. The QP predictor is updated once per TU of a particular TU size. For each CU, the dQP is computed for each TU size larger than the sub-CU. Only the dQP for a TU size that is present in the sub-CU and not equal to 0 is coded. Missing dQP information implies that the difference dQP for that TU size is 0. Referring to
FIG. 14 , the dQP can be computed as follows: -
dQP(16×16)=D−A -
dQP(8×8)=E−B -
dQP(4×4)=F−C - To reduce overhead further, a relationship between different TU sizes can be defined at a global level, such as a slice or sequence level. This approach only requires that the dQP for each CU to determine the base quantization parameter. A QP predictor may be the base quantization parameter of the most recent re-coded CU of the same type, such as a CU coded in intra or inter mode. The quantization parameter for each TU size within a CU is then determined based on the quantization parameter relationship of that size relative to the base quantization parameter. Another possible solution is to use the average quantization parameter of TU blocks within the most-recently coded CU of the same type. The following equations specify an example of QP coding as described above:
-
QP(32,32)=QP(base)+a -
QP(16,16)=QP(base)+b -
QP(8,8)=QP(base)+c -
QP(4,4)=QP(base)+d -
dQP=QP(base)−QP_predictor (base) - In another example, such as in skipped mode or merge mode, the dQP overhead is not present and is presumed to be 0. That is, the quantization parameter of the same TU size from a CU neighbor indicated by a motion vector predictor index is used.
- Particular embodiments may always maintain the same quantization parameter of all TUs with the same TU size within a CU. That is, the quantization parameter of different TU sizes is independent of each other. Thus, a QP predictor of each TU size can be defined based on its associated CU. The TU size of the most-recently coded CU is used as an example of a QP predictor in that section. However, various other predictors can be used with the proposed adaptive QP algorithm in some predictor determination methods that are described below.
- One example to define a CU for the purpose of determining a QP predictor is to rely on adjacent CU neighbors. Different ways may be used to identify the exact CU neighbor, such as by explicitly signaling the exact CU neighbor in the bitstream or implicitly determining the exact CU neighbor based on available information at
decoder 201. In one example, an indexing scheme is used as the explicit signaling. One example of implicit signaling is to use a CU that is derived from the predictor motion vector index of the current CU. CUs of the same size from a co-located CU can be used as the reference TU in a current CU. For intra CUs, the CU that contains pixels used for intra prediction can also be used as reference for QP prediction. The TU of the same size as in the reference TU can be used as a reference for QP prediction. -
FIG. 16 depicts an example ofvideo content 1650 being coded using QP adaptation according to one embodiment.Video content 1650 may include groupings of units (A-F) 1652. For example, the units may be multiple coding units (CUs), prediction units (PUs), or transform units (TU). The grouping of CUs may be an LCU. As shown, grouping of units E is partitioned into units E0-E9 in a coding order. In one embodiment, the units may be CUs, PUs or TUs. - A current grouping of units may be divided into two regions.
Region 1 includes all the units with coded block flags (cbf) equal to zero, along a coding order, but before the first unit with a non-zero cbf within the current grouping of units.Region 2 includes the first unit with a non-zero cbf and the rest of units along the coding order. - In one embodiment, units in a grouping of
units 1652 may use a QP predictor for that grouping ofunits 1652. For example, units in grouping of units E may use the QP predictor for grouping of units E, which may be derived from QP of a coded unit or a grouping of coded units, such as a unit or a grouping of units most recently coded that is the same type as the grouping of units E. This may occur when some units, such as a first number of units in a coding order in grouping of units E, have all the coefficients equal to zero. For example, inFIG. 16 , if units E0 and E1 have cbfs equal to zero and unit E2 has a non-zero cbf, units E0 and E1form region # 1 and have the QP set to the QP predictor of the grouping of unitsE. Region # 2 is formed that includes the first coded unit in the grouping, unit E2, and the subsequent units E3-E9 in grouping of unitsE. Region # 2 may have its own QP, which may be coded along with unit E2. As seen, there are two QPs used for the grouping of units E in this example. However, other variations may exist, for examples, the QP predictor of the grouping of units E is used for all the units in the grouping of units E. - In one embodiment, the QP for
region # 1 may or may not need to be signalled. Two examples are shown as follows. - (1) If the QP for
region # 1 is not signalled, a derived QP may be used for all the units in region #1 (and in some cases region #2) in the grouping of units. The derived QP may be determined from neighboring units or neighboring groupings of units, such as from neighboring CUs or groupings of CUs. - (2) If the QP for
region 1 is signalled, it is only signalled once in the groupings of units. The QP information may be coded along with the first unit in the region. - In one embodiment, a method for determining quantization parameters is provided. The method includes determining one or more first units of video content in a grouping of units. The first units may be CUs, TUs, or PUs. The first units may be in a first region. The method analyzes whether the one or more first units of video content have all of the coefficients for the video content that are zero. The method then determines whether a quantization parameter for one or more second units of video content different from the one or more first units of video content is to be used to derive as the quantization parameter for the one or more first units of video content. The second units may be a neighboring unit or units to the first units in the first region. When the quantization parameter for the one or more second units of video content is to be used, the quantization parameter for the one or more first units of video content is derived from the quantization parameter for the one or more second units of video content. For example, the quantization parameter for the second units is used as the quantization parameter for the first units.
- In another embodiment, a method is provided for determining quantization parameters for one or more first units of video content in a grouping of units. The first units may be in a first region. The method determines a quantization parameter for one or more second units of video content different from the one or more first units of video content. For example, the second units include a neighboring unit or neighboring grouping of units to the first units. The method then determines whether the quantization parameter for the one or more second units of video content is to be used to derive a quantization parameter for the one or more first units of video content. The first units of video content have all the coefficients for the video content that are zero. Then, the derived quantization parameter is used as the quantization parameter in decoding the one or more first units of video content. Also, one or more third units of video content in a second region that have a beginning unit in a coding order among units of the one or more third units with coefficients for the video content that are non-zero are determined. The method may determine a second quantization parameter for the one or more third units.
-
FIG. 17 depicts a simplified flowchart for using a QQT atencoder 200 according to one embodiment. At 1602, a unit of video content is received. The unit may be an LCU being currently encoded. The LCU is partitioned into a plurality of blocks, such as CUs. At 1604, quantization parameters associated with the plurality of blocks are determined For example, quantization parameters for each CU are determined At 1606, a quantization parameter representation based on the quantization parameters and the partitions is determined For example the QQT is determined When a node of the QQT is associated with a block that is split into additional blocks in a corresponding CQT, information is set to indicate whether or not the additional blocks have a same quantization parameter. At 1608, quantization parameters that do not need to be sent fromencoder 200 todecoder 201 are determined At 1610,encoder 200 sends the quantization parameter representation and information for the quantization parameters that do need to be sent todecoder 201.Encoder 200 does not send information for the quantization parameters that do not need to be sent. -
FIG. 18 depicts a simplified flowchart for using a QQT atdecoder 201 according to one embodiment. At 1702,decoder 201 receives a bitstream for a unit of video content. The unit may be an LCU being currently decoded. The LCU is partitioned into a plurality of blocks, such as CUs. At 1704,decoder 201 determines a block to decode. At 1706,decoder 201 determines if information for the quantization parameter for the block was sent. At 1708, if the information was not sent, the QQT is used to determine the quantization parameter from a block that has the same quantization parameter. At 1710, if the quantization parameter was sent,decoder 201 determines that quantization parameter. - A general operation of an encoder and decoder will now be described.
FIG. 19A depicts an example ofencoder 200 according to one embodiment. It will be understood that variations on the encoding process described will be appreciated by a person skilled in the art based on the disclosure and teachings herein. - For a current PU, x, a prediction PU, x′, is obtained through either spatial prediction or temporal prediction. The prediction PU is then subtracted from the current PU, resulting in a residual PU, e. A
spatial prediction block 1804 may include different spatial prediction directions per PU, such as horizontal, vertical, 45-degree diagonal, 135-degree diagonal, DC (flat averaging), and planar. - A
temporal prediction block 1806 performs temporal prediction through a motion estimation operation. The motion estimation operation searches for a best match prediction for the current PU over reference pictures. The best match prediction is described by a motion vector (MV) and associated reference picture (refldx). The motion vector and associated reference picture are included in the coded bitstream. -
Transform block 1806 performs a transform operation with the residual PU, e.Transform block 1806 outputs the residual PU in a transform domain, E. - A
quantizer 1808 then quantizes the transform coefficients of the residual PU,E. Quantizer 1808 converts the transform coefficients into a finite number of possible values.Entropy coding block 1810 entropy encodes the quantized coefficients, which results in final compression bits to be transmitted. Different entropy coding methods may be used, such as context-adaptive variable length coding (CAVLC) or context-adaptive binary arithmetic coding (CABAC). - Also, in a decoding process within
encoder 200, a de-quantizer 1812 de-quantizes the quantized transform coefficients of the residual PU. De-quantizer 1812 then outputs the de-quantized transform coefficients of the residual PU, E′. Aninverse transform block 1814 receives the de-quantized transform coefficients, which are then inverse transformed resulting in a reconstructed residual PU, e′. The reconstructed PU, e′, is then added to the corresponding prediction, x′, either spatial or temporal, to form the new reconstructed PU, x″. Aloop filter 1816 performs de-blocking on the reconstructed PU, x″, to reduce blocking artifacts. Additionally,loop filter 1816 may perform a sample adaptive offset process after the completion of the de-blocking filter process for the decoded picture, which compensates for a pixel value offset between reconstructed pixels and original pixels. Also,loop filter 1806 may perform adaptive loop filtering over the reconstructed PU, which minimizes coding distortion between the input and output pictures. Additionally, if the reconstructed pictures are reference pictures, the reference pictures are stored in areference buffer 1818 for future temporal prediction. -
FIG. 19B depicts an example ofdecoder 201 according to one embodiment. It will be understood that variations on the decoding process described will be appreciated by a person skilled in the art based on the disclosure and teachings herein.Decoder 201 receives input bits fromencoder 200 for encoded video content. - An
entropy decoding block 1830 performs entropy decoding on the input bitstream to generate quantized transform coefficients of a residual PU. A de-quantizer 1832 de-quantizes the quantized transform coefficients of the residual PU. De-quantizer 1832 then outputs the de-quantized transform coefficients of the residual PU, e′. Aninverse transform block 1834 receives the de-quantized transform coefficients, which are then inverse transformed resulting in a reconstructed residual PU, e′. - The reconstructed PU, e′, is then added to the corresponding prediction, x′, either spatial or temporal, to form the new reconstructed PU, x″. A
loop filter 1836 performs de-blocking on the reconstructed PU, x″, to reduce blocking artifacts. Additionally,loop filter 1836 may perform a sample adaptive offset process after the completion of the de-blocking filter process for the decoded picture, which compensates for a pixel value offset between reconstructed pixels and original pixels. Also,loop filter 1836 may perform adaptive loop filtering over the reconstructed PU, which minimizes coding distortion between the input and output pictures. Additionally, if the reconstructed pictures are reference pictures, the reference pictures are stored in areference buffer 1838 for future temporal prediction. - The prediction PU, x′, is obtained through either spatial prediction or temporal prediction. A
spatial prediction block 1840 may receive decoded spatial prediction directions per PU, such as horizontal, vertical, 45-degree diagonal, 135-degree diagonal, DC (flat averaging), and planar. The spatial prediction directions are used to determine the prediction PU, x′. - A
temporal prediction block 1842 performs temporal prediction through a motion estimation operation. A decoded motion vector is used to determine the prediction PU, x′. Interpolation may be used in the motion estimation operation. - Particular embodiments may be implemented in a non-transitory computer-readable storage medium for use by or in connection with the instruction execution system, apparatus, system, or machine. The computer-readable storage medium contains instructions for controlling a computer system to perform a method described by particular embodiments. The instructions, when executed by one or more computer processors, may be operable to perform that which is described in particular embodiments.
- As used in the description herein and throughout the claims that follow, “a”, “an”, and “the” includes plural references unless the context clearly dictates otherwise. Also, as used in the description herein and throughout the claims that follow, the meaning of “in” includes “in” and “on” unless the context clearly dictates otherwise.
- The above description illustrates various embodiments along with examples of how aspects of particular embodiments may be implemented. The above examples and embodiments should not be deemed to be the only embodiments, and are presented to illustrate the flexibility and advantages of particular embodiments as defined by the following claims. Based on the above disclosure and the following claims, other arrangements, embodiments, implementations and equivalents may be employed without departing from the scope hereof as defined by the claims.
Claims (25)
Priority Applications (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
PCT/US2012/045299 WO2013032576A2 (en) | 2011-06-30 | 2012-07-02 | Quantization parameter derivation from qp predictor |
US13/540,157 US20130022108A1 (en) | 2011-06-30 | 2012-07-02 | Quantization parameter derivation from qp predictor |
Applications Claiming Priority (14)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201161503597P | 2011-06-30 | 2011-06-30 | |
US201161503566P | 2011-06-30 | 2011-06-30 | |
US201161506550P | 2011-07-11 | 2011-07-11 | |
US201161511013P | 2011-07-22 | 2011-07-22 | |
US201161538792P | 2011-09-23 | 2011-09-23 | |
US201161538293P | 2011-09-23 | 2011-09-23 | |
US201161547033P | 2011-10-13 | 2011-10-13 | |
US201161547760P | 2011-10-17 | 2011-10-17 | |
US201161557419P | 2011-11-09 | 2011-11-09 | |
US201161558417P | 2011-11-10 | 2011-11-10 | |
US201161559040P | 2011-11-11 | 2011-11-11 | |
US201261586780P | 2012-01-14 | 2012-01-14 | |
US201261590803P | 2012-01-25 | 2012-01-25 | |
US13/540,157 US20130022108A1 (en) | 2011-06-30 | 2012-07-02 | Quantization parameter derivation from qp predictor |
Publications (1)
Publication Number | Publication Date |
---|---|
US20130022108A1 true US20130022108A1 (en) | 2013-01-24 |
Family
ID=47555723
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US13/540,157 Abandoned US20130022108A1 (en) | 2011-06-30 | 2012-07-02 | Quantization parameter derivation from qp predictor |
Country Status (1)
Country | Link |
---|---|
US (1) | US20130022108A1 (en) |
Cited By (10)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20140140404A1 (en) * | 2011-08-17 | 2014-05-22 | Shan Liu | Method and apparatus for intra prediction using non-square blocks |
US20140286402A1 (en) * | 2011-12-13 | 2014-09-25 | JVC Kenwood Corporation | Moving picture coding device, moving picture coding method, and moving picture coding program, and moving picture decoding device, moving picture decoding method, and moving picture decoding program |
US20140286403A1 (en) * | 2011-12-21 | 2014-09-25 | JVC Kenwood Corporation | Moving picture coding device, moving picture coding method, and moving picture coding program, and moving picture decoding device, moving picture decoding method, and moving picture decoding program |
US9253483B2 (en) | 2012-09-25 | 2016-02-02 | Google Technology Holdings LLC | Signaling of scaling list |
US9510019B2 (en) | 2012-08-09 | 2016-11-29 | Google Inc. | Two-step quantization and coding method and apparatus |
WO2017065490A1 (en) * | 2015-10-13 | 2017-04-20 | 엘지전자(주) | Method for encoding/decoding image, and apparatus therefor |
US10136133B2 (en) | 2014-11-11 | 2018-11-20 | Dolby Laboratories Licensing Corporation | Rate control adaptation for high-dynamic range images |
US10531084B2 (en) * | 2015-06-15 | 2020-01-07 | Lg Electronics Inc. | Intra prediction mode based image processing method, and apparatus therefor |
US10547840B2 (en) * | 2010-06-10 | 2020-01-28 | Interdigital Vc Holdings, Inc. | Methods and apparatus for determining quantization parameter predictors from a plurality of neighboring quantization parameters |
US20210344922A1 (en) * | 2019-01-31 | 2021-11-04 | Beijing Bytedance Network Technology Co., Ltd. | Refined quantization steps in video coding |
Citations (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20120170648A1 (en) * | 2011-01-05 | 2012-07-05 | Qualcomm Incorporated | Frame splitting in video coding |
US20120177109A1 (en) * | 2009-09-10 | 2012-07-12 | Dolby Laboratories Licensing Corporation | Speedup Techniques for Rate Distortion Optimized Quantization |
US20120189052A1 (en) * | 2011-01-24 | 2012-07-26 | Qualcomm Incorporated | Signaling quantization parameter changes for coded units in high efficiency video coding (hevc) |
US20130259118A1 (en) * | 2011-04-21 | 2013-10-03 | Mediatek Inc. | Method and Apparatus for Improved In-Loop Filtering |
-
2012
- 2012-07-02 US US13/540,157 patent/US20130022108A1/en not_active Abandoned
Patent Citations (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20120177109A1 (en) * | 2009-09-10 | 2012-07-12 | Dolby Laboratories Licensing Corporation | Speedup Techniques for Rate Distortion Optimized Quantization |
US20120170648A1 (en) * | 2011-01-05 | 2012-07-05 | Qualcomm Incorporated | Frame splitting in video coding |
US20120189052A1 (en) * | 2011-01-24 | 2012-07-26 | Qualcomm Incorporated | Signaling quantization parameter changes for coded units in high efficiency video coding (hevc) |
US20130259118A1 (en) * | 2011-04-21 | 2013-10-03 | Mediatek Inc. | Method and Apparatus for Improved In-Loop Filtering |
Cited By (31)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11722669B2 (en) | 2010-06-10 | 2023-08-08 | Interdigital Vc Holdings, Inc. | Methods and apparatus for determining quantization parameter predictors from a plurality of neighboring quantization parameters |
US11381818B2 (en) | 2010-06-10 | 2022-07-05 | Interdigital Vc Holdings, Inc. | Methods and apparatus for determining quantization parameter predictors from a plurality of neighboring quantization parameters |
US10742981B2 (en) | 2010-06-10 | 2020-08-11 | Interdigital Vc Holdings, Inc. | Methods and apparatus for determining quantization parameter predictors from a plurality of neighboring quantization parameters |
US10547840B2 (en) * | 2010-06-10 | 2020-01-28 | Interdigital Vc Holdings, Inc. | Methods and apparatus for determining quantization parameter predictors from a plurality of neighboring quantization parameters |
US20140140404A1 (en) * | 2011-08-17 | 2014-05-22 | Shan Liu | Method and apparatus for intra prediction using non-square blocks |
US9769472B2 (en) * | 2011-08-17 | 2017-09-19 | Mediatek Singapore Pte. Ltd. | Method and apparatus for Intra prediction using non-square blocks |
US20170230657A1 (en) * | 2011-12-13 | 2017-08-10 | JVC Kenwood Corporation | Moving picture coding device, moving picture coding method, and moving picture coding program, and moving picture decoding device, moviing picture decoding method, and moving picture decoding program |
US9872025B2 (en) * | 2011-12-13 | 2018-01-16 | JVC Kenwood Corporation | Moving picture coding device, moving picture coding method, and moving picture coding program, and moving picture decoding device, moving picture decoding method, and moving picture decoding program |
US9667989B2 (en) * | 2011-12-13 | 2017-05-30 | JVC Kenwood Corporation | Moving picture coding device, moving picture coding method, and moving picture coding program, and moving picture decoding device, moving picture decoding method, and moving picture decoding program |
US20140286402A1 (en) * | 2011-12-13 | 2014-09-25 | JVC Kenwood Corporation | Moving picture coding device, moving picture coding method, and moving picture coding program, and moving picture decoding device, moving picture decoding method, and moving picture decoding program |
US20170230658A1 (en) * | 2011-12-13 | 2017-08-10 | JVC Kenwood Corporation | Moving picture coding device, moving picture coding method, and moving picture coding program, and moving picture decoding device, moving picture decoding method, and moving picture decoding program |
US20160295223A1 (en) * | 2011-12-13 | 2016-10-06 | JVC Kenwood Corporation | Moving picture coding device, moving picture coding method, and moving picture coding program, and moving picture decoding device, moviing picture decoding method, and moving picture decoding program |
US20170230659A1 (en) * | 2011-12-13 | 2017-08-10 | JVC Kenwood Corporation | Moving picture coding device, moving picture coding method, and moving picture coding program, and moving picture decoding device, moving picture decoding method, and moving picture decoding program |
US9661342B2 (en) * | 2011-12-13 | 2017-05-23 | JVC Kenwood Corporation | Moving picture coding device, moving picture coding method, and moving picture coding program, and moving picture decoding device, moving picture decoding method, and moving picture decoding program |
US9894363B2 (en) * | 2011-12-13 | 2018-02-13 | JVC Kenwood Corporation | Moving picture coding device, moving picture coding method, and moving picture coding program, and moving picture decoding device, moving picture decoding method, and moving picture decoding program |
US9877027B2 (en) * | 2011-12-13 | 2018-01-23 | JVC Kenwood Corporation | Moving picture coding device, moving picture coding method, and moving picture coding program, and moving picture decoding device, moviing picture decoding method, and moving picture decoding program |
US20170230664A1 (en) * | 2011-12-21 | 2017-08-10 | JVC Kenwood Corporation | Moving picture coding device, moving picture coding method, and moving picture coding program, and moving picture decoding device, moving picture decoding method, and moving picture decoding program |
US9936198B2 (en) * | 2011-12-21 | 2018-04-03 | JVC Kenwood Corporation | Moving picture coding device, moving picture coding method, and moving picture coding program, and moving picture decoding device, moving picture decoding method, and moving picture decoding program |
US9743089B1 (en) * | 2011-12-21 | 2017-08-22 | JVC Kenwood Corporation | Moving picture coding device, moving picture coding method, and moving picture coding program, and moving picture decoding device, moving picture decoding method, and moving picture decoding program |
US20170230663A1 (en) * | 2011-12-21 | 2017-08-10 | JVC Kenwood Corporation | Moving picture coding device, moving picture coding method, and moving picture coding program, and moving picture decoding device, moving picture decoding method, and moving picture decoding program |
US9894364B2 (en) * | 2011-12-21 | 2018-02-13 | JVC Kenwood Corporation | Moving picture coding device, moving picture coding method, and moving picture coding program, and moving picture decoding device, moving picture decoding method, and moving picture decoding program |
US9667986B2 (en) * | 2011-12-21 | 2017-05-30 | JVC Kenwood Corporation | Moving picture coding device, moving picture coding method, and moving picture coding program, and moving picture decoding device, moving picture decoding method, and moving picture decoding program |
US9900600B2 (en) * | 2011-12-21 | 2018-02-20 | JVC Kenwood Corporation | Moving picture coding device, moving picture coding method, and moving picture coding program, and moving picture decoding device, moving picture decoding method, and moving picture decoding program |
US20140286403A1 (en) * | 2011-12-21 | 2014-09-25 | JVC Kenwood Corporation | Moving picture coding device, moving picture coding method, and moving picture coding program, and moving picture decoding device, moving picture decoding method, and moving picture decoding program |
US20170230661A1 (en) * | 2011-12-21 | 2017-08-10 | JVC Kenwood Corporation | Moving picture coding device, moving picture coding method, and moving picture coding program, and moving picture decoding device, moving picture decoding method, and moving picture decoding program |
US9510019B2 (en) | 2012-08-09 | 2016-11-29 | Google Inc. | Two-step quantization and coding method and apparatus |
US9253483B2 (en) | 2012-09-25 | 2016-02-02 | Google Technology Holdings LLC | Signaling of scaling list |
US10136133B2 (en) | 2014-11-11 | 2018-11-20 | Dolby Laboratories Licensing Corporation | Rate control adaptation for high-dynamic range images |
US10531084B2 (en) * | 2015-06-15 | 2020-01-07 | Lg Electronics Inc. | Intra prediction mode based image processing method, and apparatus therefor |
WO2017065490A1 (en) * | 2015-10-13 | 2017-04-20 | 엘지전자(주) | Method for encoding/decoding image, and apparatus therefor |
US20210344922A1 (en) * | 2019-01-31 | 2021-11-04 | Beijing Bytedance Network Technology Co., Ltd. | Refined quantization steps in video coding |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US11064220B2 (en) | Method and apparatus of video data processing with restricted block size in video coding | |
US20130022108A1 (en) | Quantization parameter derivation from qp predictor | |
US9210425B2 (en) | Signaling of temporal motion vector predictor (MVP) flag for temporal prediction | |
US11438590B2 (en) | Methods and apparatuses of chroma quantization parameter derivation in video processing system | |
US9066104B2 (en) | Spatial block merge mode | |
US9210442B2 (en) | Efficient transform unit representation | |
US11051009B2 (en) | Video processing methods and apparatuses for processing video data coded in large size coding units | |
EP2742690B1 (en) | Residual tree structure of transform unit partitioning | |
US9838685B2 (en) | Method and apparatus for efficient slice header processing | |
US9300959B2 (en) | Implicit determination of collocated picture for temporal prediction | |
US9549177B2 (en) | Evaluation of signaling of collocated reference picture for temporal prediction | |
US11582461B2 (en) | Video encoding device, video decoding device, video encoding method, video decoding method, and program restricts inter-prediction unit partitions based on coding unit depth | |
WO2018119167A1 (en) | Constrained position dependent intra prediction combination (pdpc) | |
KR20160106021A (en) | Apparatus for decoding a moving picture | |
US20130051469A1 (en) | Method and apparatus for processing a video signal | |
US20140086311A1 (en) | Signaling of scaling list | |
US20140023142A1 (en) | Signaling of temporal motion vector predictor (mvp) enable flag | |
US20120328005A1 (en) | Construction of combined list using temporal distance | |
WO2013032576A2 (en) | Quantization parameter derivation from qp predictor | |
WO2014028631A1 (en) | Signaling of temporal motion vector predictor (mvp) enable flag |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GENERAL INSTRUMENT CORPORATION, PENNSYLVANIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:PANUSOPONE, KRIT;LUTHRA, AJAY K.;WANG, LIMIN;AND OTHERS;SIGNING DATES FROM 20120806 TO 20120815;REEL/FRAME:029100/0093 |
|
AS | Assignment |
Owner name: MOTOROLA MOBILITY LLC, ILLINOISFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:GENERAL INSTRUMENT HOLDINGS, INC.;REEL/FRAME:030866/0113Effective date: 20130528Owner name: GENERAL INSTRUMENT HOLDINGS, INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:GENERAL INSTRUMENT CORPORATION;REEL/FRAME:030764/0575Effective date: 20130415 |
|
AS | Assignment |
Owner name: GOOGLE TECHNOLOGY HOLDINGS LLC, CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:MOTOROLA MOBILITY LLC;REEL/FRAME:034274/0290Effective date: 20141028 |
|
STCB | Information on status: application discontinuation |
Free format text: ABANDONED -- FAILURE TO RESPOND TO AN OFFICE ACTION |