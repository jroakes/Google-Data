EP3158430A1 - Interface for multiple media applications - Google Patents
Interface for multiple media applicationsInfo
- Publication number
- EP3158430A1 EP3158430A1 EP15733034.1A EP15733034A EP3158430A1 EP 3158430 A1 EP3158430 A1 EP 3158430A1 EP 15733034 A EP15733034 A EP 15733034A EP 3158430 A1 EP3158430 A1 EP 3158430A1
- Authority
- EP
- European Patent Office
- Prior art keywords
- media application
- interface
- control
- media
- feature
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Withdrawn
Links
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0481—Interaction techniques based on graphical user interfaces [GUI] based on specific properties of the displayed interaction object or a metaphor-based environment, e.g. interaction with desktop elements like windows or icons, or assisted by a cursor's changing behaviour or appearance
- G06F3/0482—Interaction with lists of selectable items, e.g. menus
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0484—Interaction techniques based on graphical user interfaces [GUI] for the control of specific functions or operations, e.g. selecting or manipulating an object, an image or a displayed text element, setting a parameter value or selecting a range
- G06F3/04842—Selection of displayed objects or displayed text elements
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0484—Interaction techniques based on graphical user interfaces [GUI] for the control of specific functions or operations, e.g. selecting or manipulating an object, an image or a displayed text element, setting a parameter value or selecting a range
- G06F3/04847—Interaction techniques to control parameter settings, e.g. interaction with sliders or dials
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/44—Arrangements for executing specific programs
- G06F9/451—Execution arrangements for user interfaces
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/44—Arrangements for executing specific programs
- G06F9/451—Execution arrangements for user interfaces
- G06F9/452—Remote windowing, e.g. X-Window System, desktop virtualisation
Definitions
- Mobile computing devices such as smartphones, may be connected to suitable computing devices in a vehicle, such as a car.
- a car may have head unit with a large display that is capable of connecting to a smartphone via a wired or wireless connection. This may allow the smartphone access to other equipment within the vehicle, such as a stereo system that can be used for audio playback of media stored on the smartphone, or accessible through the smartphone.
- Applications running on the smartphone may be controlled using the vehicle's controls, such as a touchscreen on the display of the head unit.
- a smartphone application's user interface may not be suitable for use by a driver while the vehicle is in motion, as the positioning and size of the controls may be difficult. Some of the features of the smartphone application may also be unsafe to use regardless of the design of the user interface, such as, for example, features that require the user to type out messages or perform other actions that would be distracting for the driver of a vehicle.
- a list including a feature for a first media application may be received.
- the first media application may be run on a first computing device.
- a template user interface including a definition for a control may be received.
- the definition may include a position within a user interface for the control and a size of the control.
- a translated interface for the first media application may be generated by associating the control of the template user interface with the feature of the first media application.
- the translated interface may be displayed for the first media application on the display of a second computing device.
- a second list including a feature for a second media application may be received.
- the second media application may be run on the first computing device.
- the feature for the second media application may correspond to the feature for the first media application.
- the template user interface may be received.
- Generating the translated interface for the first media application may include associating the second control with the second feature of the first media application.
- FIG. 4 shows an example arrangement for an interface for multiple media
- FIGs. 5a, 5b, and 5c shows example displays for media applications for use with an interface for multiple media applications according to an implementation of the disclosed subject matter.
- FIG. 6 shows an example display for an interface for multiple media applications according to an implementation of the disclosed subject matter.
- FIG. 7 shows an example of a process for an interface for multiple media application according to an implementation of the disclosed subject matter.
- FIG. 9 shows a computer according to an embodiment of the disclosed subject matter.
- FIG. 10 shows a network configuration according to an embodiment of the disclosed subject matter.
- An interface for multiple media applications may allow the safe use of media applications on a mobile computing device in a vehicle such as a car, in conjunction with a vehicle-based computing device.
- a mobile computing device such as a smartphone or tablet, may include a number of media applications, including, for example, music players that playback locally and remotely stored music, subscription-based music players and Internet radio players.
- Each media application may have its own unique user interface to display on the user's mobile computing device, which may allow the user to interact with and control the media applications via a touchscreen on the mobile computing device.
- the user may connect the mobile computing device to a vehicle computing device, for example, the head unit of an audio/visual system in a car, for example, using a wired or wireless connection.
- the user may then use one of the media applications on the mobile computing device, for example, to playback music through the car stereo.
- the media application may expose, for example, through an Application Programming Interface (API), the various features of the media application and the data accessible by the media application.
- API Application Programming Interface
- the vehicle computing device may rank the features of the media application, which may include commands such as play, next track, previous track, and pause, and ranking inputs such as thumbs up and thumbs down.
- the vehicle computing device may then display, on a display that is part of the vehicle computing device, a user interface translated from a template user interface and the ranking of the features.
- the translated interface may include controls that allow the user to access certain features of the media application that are deemed safe to access while driving, while preventing access to other controls.
- the controls may be presented in a manner that makes them safer for a driver to use than the controls would be if they presented on the display of the vehicle computing device in the same manner as the controls are presented on the display of the mobile computing device by the media application.
- the template user interface may be used with any media application the user selects to use while the mobile computing device is connected to the vehicle computing device. This may allow for a standardized display for all media applications used through the vehicle computing device while still allowing the media applications to control media playback.
- a mobile computing device such as, for example, a smartphone or tablet, may include any number of different media applications. Different media applications may have access to different media items from different sources of media, and may have independent media databases stored on the mobile computing device.
- Media players may have access to media items stored in the local storage of the mobile computing device, media items stored in remote storage accessible by the mobile computing device, or access to media items through subscription services.
- Media items may include audio tracks, such as music tracks, and videos. For example, a user may install three separate music players on their smartphone. The first and second music player may detect music tracks stored in the local storage of the smartphone, and may build their own separate media databases.
- the second music player may also have access to music tracks stored by the user in a remote music track storage service, and may include these music tracks as part of its media database, though the tracks may not be part of the media database built by the first music player.
- the third music player may have access to music tracks through a subscription service, and may have no media database, or, if the service allows for local storage, a media database that includes only music tracks the user has stored locally from the subscription service. These locally stored subscription service music tracks may not appear in the media database for the first or second music player.
- the different media applications may also have different user interfaces.
- Each media application may have a different placements for common media application user interface controls, such as play and pause buttons, and may include their own unique controls, such as thumbs up and thumbs down controls, or other controls for rating media items, or controls for posting messages to social media services.
- a music player may include a next track, previous track, play, and pause buttons, for controlling playback of locally stored music tracks, while another music player may include only a play, pause, and next track buttons, for controlling playback of music tracks accessed through an Internet radio service which may not allow skipping back to the previous track.
- the mobile computing device with the media applications may be connected to a vehicle computing device, which may be, for example, a head unit in a car, truck, or other personal vehicle, or any other type of vehicle.
- vehicle computing device may include a display, which may be, for example, a touchscreen in the center console of the vehicle, and may be connected to the vehicle's stereo system, allowing for audio playback.
- the mobile computing device may be connected to the vehicle computing device in any suitable manner.
- a smartphone may be connected to a car head unit using a USB cable, a Bluetooth connection, a device-to-device WiFi connection, or to an in-vehicle Wireless LAN.
- a media application may be run on the mobile computing device while the mobile computing device is connected to the vehicle computing device.
- a user may use the controls for the vehicle computing device, such as a touchscreen display, to select and run a music player on a smartphone that is connected to the vehicle computing device with a USB cable.
- the media application may include an API that exposes the features of the media application and the data accessible by the media application to the vehicle computing device.
- the vehicle computing device may include a component, for example, a software application installed on the vehicle computing device or as part of the operating system of the vehicle computing device, which may access the API of the media application to receive a list of the features available in the application.
- the features may include, for example, controls used by the media application.
- the vehicle computing device may rank the features of the media application based on, for example, how safe the features are for use by a driver during operation of the vehicle. For example, a play button may be considered very safe and ranked high, while a button that allowed for posting to social media services may be considered unsafe, and ranked low.
- the common features may be displayed in the same location on the display of the vehicle computing device.
- no previous track button may be displayed.
- Certain low ranked features may also not have displayed controls.
- the second music player may include the feature of a button for posting to social media services.
- the vehicle computing device may rank the button low enough that the button may not be displayed on the display of the vehicle computing device.
- Unique features of media applications may also be displayed on the translated interface.
- a media application may include a bookmark button.
- the template user interface may include a location for a bookmark button, such that when a media application lists a bookmark button among its features, the bookmark button may be part of the translated interface displayed on the display of the vehicle computing device.
- the translated interface for a media application may be used to control the media application in a similar manner to using the media application's user interface on the mobile computing device.
- Commands issued through the translated interface for example, by the touching of buttons displayed on the touchscreen of the display of the vehicle computing display, may be sent to the media application running on the mobile computing device.
- the mobile computing device may respond to the commands as if they were issued through the user interface of the mobile computing device. For example, a user may press the play button on the display of the translated interface, which may result in the media application beginning or resuming playback of a media item.
- the media application may still have access to any media databases the media application has stored on the mobile computing device and to any local, remote, subscription based, or otherwise accessible media items that media application has access to when run on the mobile computing device.
- an Internet radio player may still have access to Internet radio stations
- a subscription music player may still access music tracks through the subscription service
- a local music player may still play local music tracks based on the media database for the local music player.
- Media items played back using a media application on a mobile computing connected to a vehicle computing device may be played through the audio/visual devices attached to the vehicle computing device.
- the user may use the translated interface to start playback of a music track using a media application on the mobile computing device.
- the music track may be played through the vehicle's stereo.
- the audio signal for the music track may be processed through the media application, by hardware and software for audio processing associated with the vehicle computing device and vehicle stereo, or both. This may allow for the use of equalizer settings in media application on mobile computing devices when using the media application to playback audio through the vehicle's stereo.
- the API for the media application may also expose data to the vehicle computing device.
- the API may be used by the vehicle computing device to media database data such as media libraries and playlists, metadata for media items, available Internet radio stations, and other data associated with media applications.
- This may allow the translated interface to display metadata, for example, artist, album, and track title for music being played back using a media application, and allow the user to browse and select media items in a manner appropriate to the media application.
- the user may use the translated interface to view available Internet radio stations when running an Internet radio music player on the mobile computing device, or browse a library of available music tracks when using a local music player on the mobile computing device.
- FIG. 1 shows an example system suitable for an interface for multiple media applications according to an implementation of the disclosed subject matter.
- a mobile computing device 100 may include media applications 110, 120 and 230, a wide area wireless interface 150, a local wireless interface 160, a wired interface 170, and a storage 140.
- the mobile computing device 100 may be any suitable device, such as, for example, a computer 20 as described in FIG. 9.
- the mobile computing device 100 may be a single computing device, or may include multiple connected computing devices, and may be, for example, a mobile computing device, such as a tablet, smartphone, or laptop.
- the media applications 110 and 120 may be used to playback media items 142 from the storage 140, and may build, store, and access the media databases 142 and 144, respectively, in the storage 140.
- the media applications 110, 120, and 130 may also include feature and data access 112, 122, and 132, which may be, for example, an API that may expose the features and data of the media applications 110, 120, and 130.
- the features may be, for example, the controls used to control each of the media applications 110, 120, and 130, such as, for example, previous track, next track, pause, and play buttons, scrub bars, bookmarks buttons, ratings buttons, and social media service buttons.
- the exposed data may be, for example, the media database 144 and 146, a media database of a subscription service, available Internet radio or video stations, playlists, and metadata associated with media items including the media items 142.
- the local wireless interface 160 may be any suitable combination of hardware and software on the mobile computing device 100 for connecting wirelessly to a local area network or other local device.
- the local wireless interface 160 may use a WiFi radio to connect to a router that has created a local area network, or to connect directly to another device, or may use a Bluetooth radio to connect directly to another device.
- the local wireless interface 160 may be used by the mobile computing device 100 to connect to another computing device, for example, a computing device in the head unit of a vehicle's audio/visual system.
- the mobile computing device 100 may establish a connection to the computing device in the head unit over Bluetooth.
- the wired interface 170 may be any suitable combination of hardware and software on the mobile computing device 100 for establishing a wired connection to a local area network or other local device.
- the wired interface 170 may use a USB connection to connect directly to another device.
- the wired interface 170 may be used by the mobile computing device 100 to connect to another computing device, for example, a computing device in the head unit of a vehicle's audio/visual system.
- the mobile computing device 100 may establish a connection to the computing device in the head unit using a USB cable.
- FIG. 2 shows an example system suitable for an interface for multiple media applications according to an implementation of the disclosed subject matter.
- a vehicle computing device 200 may include a vehicle interface translator 210, a display 220, a control interface 230, a local wireless interface 260, a wired interface 270, and a storage 240.
- the vehicle computing device 200 may be any suitable device, such as, for example, a computer 20 as described in FIG. 9.
- the vehicle computing device 200 may be a single computing device, or may include multiple connected computing devices, and may be, for example, part of the head unit of a vehicle's audio/visual system.
- the vehicle interface translator 210 may use a template user interface 242 from the storage 240 to generate a translated interface that may be displayed on the display 220.
- the vehicle interface translator 210 may be any suitable combination of hardware and software in the vehicle computing device 200 for accessing the features of media applications on a mobile computing device, for example, the media applications 110, 120, and 130, and using the template user interface 242 to generate a translated interface.
- the vehicle interface translator 210 may access the features through the feature and data access 112, 122, and 132, and may rank the features in order to generate the translated interface.
- the template user interface 242 may define locations, sizes, and positions, in a user interface for controls for common features of media applications.
- the translated interface may include controls for features of a specific media application in the locations, and with the size and shape, defined by the template user interface 242 for those controls.
- the display 220 may be any suitable hardware and software for a display device connected to the vehicle computing device 200.
- the display 220 may be a touchscreen display in the center console of a vehicle.
- the display 220 may be used to display the translated interface to the user, who may be the driver of the vehicle, and to receive input through a touchscreen interface.
- the control interface 230 may be, for example, the touchscreen interface of the display 220, and may also include hard and soft keys and other control devices inside the vehicle, such as, for example, play, pause, next track, and previous track buttons located on a steering wheel of the vehicle.
- the display 220 may be the display on the mobile computing device 100.
- the wired interface 270 may be any suitable combination of hardware and software on the vehicle computing device 200 for establishing a wired connection to a local area network or other local device.
- the wired interface 270 may use a USB connection to connect directly to another device.
- the wired interface 270 may be used by the vehicle computing device 200 to connect to another computing device, for example, the mobile computing device 100.
- a user may bring the mobile computing device 100 into a vehicle.
- a driver may carry their smartphone with them into their car.
- the mobile computing device 100 may establish a connection to the vehicle computing device 200 using, for example, the local wireless interface 160 of the mobile computing device 100 and local wireless interface 260 of the vehicle computing device 200.
- the driver's smartphone may connect via Bluetooth to the head unit of a vehicle.
- the vehicle computing device 200 may be used to select a media application, such as the media application 1 10, to run on the mobile computing device 100.
- the display 220 may display all available media applications 110, 120, and 130 on the mobile computing device 100, and the user may use the control interface 230 to select and run the media application 110.
- the vehicle interface translator 210 may use the feature and data access 112 to access the features of the media application 110.
- the features may include, for example, the various controls that would be used on the native user interface of the media application 110, such as previous track, next track, pause, and play buttons.
- the vehicle interface translator 210 may rank the features of the media application 110, for example, based on how the safe the features are for use by a user who is driving the vehicle.
- the vehicle interface translator 210 may receive the template user interface 242 from the storage 240, and combine the template user interface 242 with the ranked features to generate a translated interface.
- the translated interface may include the features of the media application 110 that were ranked highly, for example, deemed safe enough to be used while driving.
- a music player running on a smartphone may be controlled from the display of a vehicle's head unit without requiring that the user issue any commands through the touchscreen of the smartphone. This may allow for safer operation of the media application 110 by the driver of the vehicle, while not requiring that the vehicle computing device 200 implement any of the media access and playback functionality of the media application 110.
- the vehicle translator interface 210 may receive media database data from the media application 110, for display on the display 220.
- the vehicle translator interface 210 may receive, through feature and data access 112, metadata for a currently playing media item from the media items 142, taken from the media database 144.
- the vehicle translator interface 210 may also receive media library and playlist data taken from the media database 144, to be displayed on the display 220 using the translated interface. This may allow the translated interface to include any data about media items and media selection functionality that may be included in the media application 110, for example, allowing the user to browse through the media items 142 that are accessible to the media application 110 and select media items 142 for playback.
- a music player on a smartphone may have access to locally stored music tracks, and may have built a library from those music tracks.
- the translated interface may be used to browse the library built by smartphone, rather than having the vehicle computing device 200 build its own library from the music tracks stored on the smartphone.
- the translated interface may, though the vehicle translator 210, may allow for use of the media database 144 of the media application 110 as if the native user interface of the media application 110 were being used.
- the translated interface may use a different format, layout, or controls for accessing the media database 144 through the media application 110, as may be necessary to increase the safety of the use of the translated interface.
- the media application 110 may play back media items, for example, from the media items 142.
- the media items 142 that are played back may be output to the vehicle computing device 100, which may then output the media items 142 appropriately, for example, through the vehicle stereo.
- the media application 110 may handle any decoding and processing of the media items 142 necessary for playback, for example, converting encoded digital music into analog audio output.
- FIG. 4 shows an example arrangement for an interface for multiple media
- the vehicle interface translator 210 may be used with any media application on the mobile computing device 100, including, for example, the media application 130.
- the media application 130 may be, for example, a subscription music player.
- a user may bring their smartphone into their car, connect the smartphone to the vehicle head unit via Bluetooth, and use the display 220 and control interface 230 to run a subscription music player on the smartphone.
- the vehicle interface translator 210 may receive the features of the media application 130, rank the features, and generate a translated interface for the media application 130 using the template user interface 242. [44]
- the translated interface may be displayed on the display 220, and may include controls for the features of the media application 130.
- the user may use the control interface 230 to issue control commands to the media application 130, which may function as if the control commands were received through native user interface of the media application 130.
- the media application 130 may access media items and media database data through a subscription service, for example, a subscription music service, using the wide are wireless interface 150.
- the media database data received by the media application 130 from the subscription service through the wide are wireless interface 150 may be passed to the vehicle interface translator 210 and displayed using the translated interface. This may allow the user to control the media application 130 using the control interface 230 and display 220, accessing the data and media items available through the subscription service, and playing back the media items through, for example, the vehicle stereo, as if the user were using the native user interface of the media application 130.
- the vehicle computing device 200 may not need to be able to access the subscription service itself, as access may be handled through media application 130 on the mobile computing device 100.
- the media application 130 may have features in common with the media application
- the translated interface may include controls for these common features in the same location, having the same size and shape, as defined by the template user interface 242. This may allow for easier and safe control of both the media application 110 and the media application 130, as the driver of the vehicle may not have to adjust to different control locations on the display 220 when switching between the media application 110 and the media application 130. This may result in the driver needing to spend less time looking at the display 220 in order to operate a touchscreen interface to control either of the media application 110 and media application 130.
- the native user interface display 500 may include information area 502 and buttons that control the various features of the media application 110 such as previous track button 504, pause button 506, play button 508, next track button 510, and scrub bar 512.
- the information area 502 may be used to display information, such as, for example, library or playlist information from the media database 144, or metadata for a currently playing media item, such as a music track, from the media items 142.
- a native user interface display 520 may be displayed on a display of the mobile computing device 100 when, for example, the media application 120, which may be a music player for locally stored media items such as the media items 142 and remotely stored media items, for example, media items in cloud storage, is run.
- the native user interface display 520 may include information area 522 and buttons that control the various features of the media application 110 such as previous track button 524, pause button 526, play button 528, next track button 530, scrub bar 532, positive rating button 534, and negative rating button 536.
- the information area 522 may be used to display information, such as, for example, library or playlist information from the media database 146, or metadata for a currently playing media item, such as a music track, from the media items 142 or from the remote storage.
- the buttons for the native user interface display 520 may be arranged differently than those of the native user interface display 500 for the media application 110.
- a native user interface display 540 may be displayed on a display of the mobile computing device 100 when, for example, the media application 130, which may be a
- the native user interface display 540 may include information area 542 and buttons that control the various features of the media application 130 such as pause button 546, next track button 550, scrub bar 552, positive ranking button 554, negative ranking button 556, and social media service button 558.
- the pause button 546 may dynamically switch between pause and play functions depending on whether the current media item is playing or paused.
- the information area 552 may be used to display information, such as, for example, library or playlist information from the subscription music service, or metadata for a currently playing media item, such as a music track, received from the subscription music service.
- the native user interface display 540 may have buttons in different locations, and may have fewer or different buttons than, the native user interface displays 500 and 520.
- FIG. 6 shows an example display for an interface for multiple media applications according to an implementation of the disclosed subject matter.
- the template user interface 242 may be used to generate a translated interface display 600.
- the translated interface display 600 may include information area 602 and buttons that control the various features of a media application running on the mobile computing device 100 that is connected to the vehicle computing device 200, such as previous track button 604, pause button 606, play button 608, next track button 610, and scrub bar 612.
- the mobile computing device 100 may be connected to the vehicle computing device 200, and the media application 110 may be run on the mobile computing device 100.
- Selecting the previous track button 604 may cause the media application 110 to perform the same action, for example, skipping to the previous track, as the previous track button 504.
- the pause button 606, the play button 608, the next track button 610, and the scrub bar 612 may all be used to control the media application 110 in place of the pause button 506, the play button 508, the next track button 510, and the scrub bar 512.
- the user may switch to the media application 120.
- the vehicle interface translator
- the 210 may receive the features for the media application 120, and generate the translated interface based on a ranking of the features.
- the translated interface for the media application 120 may also use the translated interface display 600.
- the information area 602 may display the same data that would have been displayed in the information area 522. Selecting the previous track button 604, for example, touching the button on touchscreen control interface 230 for the display 220, may cause the media application 120 to perform the same action, for example, skipping to the previous track, as the previous track button 524.
- the pause button 606, the play button 608, the next track button 610, and the scrub bar 612 may all be used to control the media application 110 in place of the pause button 526, the play button 528, the next track button 530, and the scrub bar 532.
- the translated interface display 600 may additionally include, when generated from the features of the media application 120, positive ranking button 614 and negative ranking button 616, which may control the features normally controlled by positive ranking button 534 and negative ranking button 536.
- the common features between the media application 110 and the media application 120 may have controls in the same place on the translated interface display 600, even when the controls are in different locations between the native user interface display 500 and the native user interface display 520.
- the user may also switch to the media application 130.
- the vehicle interface translator 210 may receive the features for the media application 130, and generate the translated interface based on a ranking of the features.
- the translated interface for the media application 130 may also use the translated interface display 600.
- the information area 602 may display the same data that would have been displayed in the information area 542. Selecting the next track button 610, for example, touching the button on touchscreen control interface 230 for the display 220, may cause the media application 130 to perform the same action, for example, skipping to the next track, as the next track button 550.
- the pause button 606, the play button 608, the next track button 610, and the scrub bar 612 may all be used to control the media application 130 in place of the pause button 526, which may have the pause and play features split between the pause button 606 and the play button 608, the next track button 550, and the scrub bar 552.
- the translated interface display 600 may additionally include, when generated from the features of the media application 130, positive ranking button 614 and negative ranking button 616, which may control the features normally controlled by positive ranking button 554 and negative ranking button 556.
- the translated interface display 600 may not include a control for the feature controlled by the social media service button 558, as that feature may be deemed to unsafe to be used while driving, and may also not include a control for a previous track feature, and the media application 130 may not include that feature.
- the media application 130 may be an Internet radio service which not allow for skipping to a previous music track.
- the common features between any of the media application 110, the media application 120, and the media application 130 may have controls in the same place on the translated interface display 600, even when the controls are in different locations between the native user interface display 500, the native user interface display 520, and the native user interface display 540. This may allow for easier usage of any of the media applications 110, 120, and 130 by a driver using the control interface 230 and the display 220, and the driver does not have to relearn or adjust to changing position controls when switching between media applications running on the mobile computing device 100.
- FIG. 7 shows an example of a process for an interface for multiple media application according to an implementation of the disclosed subject matter.
- a feature list may be received.
- the vehicle interface translator 210 may receive a list of the features for the media application 110 using the feature and data access 112.
- a user may have taken a smartphone into a car, connected the smartphone to the car's head unit, and selected a music player to run on the smartphone.
- a translated interface may be generated using the template user interface and the feature ranks.
- the vehicle interface translator 210 may generate a translated interface, with the translated interface display 600, connecting the high ranked features for the media application 110 to the appropriate controls defined by the template user interface 242.
- Controls for features not used by the media application 110 may be omitted from the translated interface, and not appear on the translated interface display 600, as may controls for features that are ranked low because they were deemed unsafe, or controls for features for which there is no corresponding control defined in the template user interface 242, for example, due to the feature being uncommon or unsafe.
- the translated interface may be displayed.
- the translated interface may be displayed on the display 220 of the vehicle computing device 200, allowing the driver of the vehicle to control the media application 110 without having to look at or use the mobile computing device 100.
- the display 220 may, for example, display the translated interface display 600.
- the input may be translated to a control command.
- the vehicle interface translator 210 may translate the selection of the pause button 606 into a control command for the media application 110 that will activate the pause feature of the media application 110.
- control command may be sent.
- the control command may be sent from the vehicle computing device 200 to the mobile computing device 100, and to the media application 110 using the feature and data access 112, which may be accomplished through, for example, an API call.
- an updated feature state may be received.
- the pause command may result in the pausing of playback of the media item currently being played back using the media application 110.
- the translated interface display 600 may need to be updated, for example, to pause the motion of a position indicator on the scrub bar 612.
- the updated feature state may be received at the vehicle interface translator 210.
- the updated feature state may be displayed.
- translated interface display 600 as displayed on the display 220, may be updated to reflect an updated feature state, for example, pausing the position indicator in the scrub bar 612 to reflect the issuance of a pause command.
- FIG. 9 is an example computer system 20 suitable for implementing embodiments of the presently disclosed subject matter.
- the computer 20 includes a bus 21 which interconnects major components of the computer 20, such as one or more processors 24, memory 27 such as RAM, ROM, flash RAM, or the like, an input/output controller 28, and fixed storage 23 such as a hard drive, flash storage, SAN device, or the like.
- a user display such as a display screen via a display adapter
- user input interfaces such as controllers and associated user input devices
- keyboard, mouse, touchscreen, or the like and other components known in the art to use in or in conjunction with general-purpose computing systems.
- the bus 21 allows data communication between the central processor 24 and the memory 27.
- the RAM is generally the main memory into which the operating system and application programs are loaded.
- the ROM or flash memory can contain, among other code, the Basic Input-Output system (BIOS) which controls basic hardware operation such as the interaction with peripheral components.
- BIOS Basic Input-Output system
- Applications resident with the computer 20 are generally stored on and accessed via a computer readable medium, such as the fixed storage 23 and/or the memory 27, an optical drive, external storage mechanism, or the like.
- FIG. 10 shows an example arrangement according to an embodiment of the disclosed subject matter.
- One or more clients 10, 11, such as local computers, smart phones, tablet computing devices, remote services, and the like may connect to other devices via one or more networks 7.
- the network may be a local network, wide-area network, the Internet, or any other suitable communication network or networks, and may be implemented on any suitable platform including wired and/or wireless networks.
- the clients 10, 11 may communicate with one or more computer systems, such as processing units 14, databases 15, and user interface systems 13.
- clients 10, 11 may communicate with a user interface system 13, which may provide access to one or more other systems such as a database 15, a processing unit 14, or the like.
- the user interface 13 may be a user-accessible web page that provides data from one or more other computer systems.
- the user interface 13 may provide different interfaces to different clients, such as where a human-readable web page is provided to web browser clients 10, and a computer-readable API or other interface is provided to remote service clients 11.
- the user interface 13, database 15, and processing units 14 may be part of an integral system, or may include multiple computer systems communicating via a private network, the Internet, or any other suitable network.
- Processing units 14 may be, for example, part of a distributed system such as a cloud-based computing system, search engine, content delivery system, or the like, which may also include or communicate with a database 15 and/or user interface 13.
- an analysis system 5 may provide back-end processing, such as where stored or acquired data is pre-processed by the analysis system 5 before delivery to the processing unit 14, database 15, and/or user interface 13.
- a machine learning system 5 may provide various prediction models, data analysis, or the like to one or more other systems 13, 14, 15.
Abstract
Description
Claims
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/310,211 US20150370419A1 (en) | 2014-06-20 | 2014-06-20 | Interface for Multiple Media Applications |
PCT/US2015/036006 WO2015195647A1 (en) | 2014-06-20 | 2015-06-16 | Interface for multiple media applications |
Publications (1)
Publication Number | Publication Date |
---|---|
EP3158430A1 true EP3158430A1 (en) | 2017-04-26 |
Family
ID=53496960
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
EP15733034.1A Withdrawn EP3158430A1 (en) | 2014-06-20 | 2015-06-16 | Interface for multiple media applications |
Country Status (5)
Country | Link |
---|---|
US (1) | US20150370419A1 (en) |
EP (1) | EP3158430A1 (en) |
JP (1) | JP6487467B2 (en) |
CN (1) | CN107077344B (en) |
WO (1) | WO2015195647A1 (en) |
Families Citing this family (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20150370446A1 (en) * | 2014-06-20 | 2015-12-24 | Google Inc. | Application Specific User Interfaces |
US20150370461A1 (en) * | 2014-06-24 | 2015-12-24 | Google Inc. | Management of Media Player Functionality |
EP3262428A1 (en) * | 2015-02-23 | 2018-01-03 | GE Aviation Systems LLC | Method and apparatus for an electrical fault detecting system for a cable |
WO2018113977A1 (en) * | 2016-12-22 | 2018-06-28 | Volkswagen Aktiengesellschaft | User terminal, user interface, computer program product, signal sequence, means of transport, and method for setting up a user interface of a means of transport |
CN110188211B (en) * | 2019-04-25 | 2023-06-27 | 深圳市布谷鸟科技有限公司 | Method for rapidly loading multimedia application list in android vehicle-mounted system |
Family Cites Families (39)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7747782B2 (en) * | 2000-04-26 | 2010-06-29 | Novarra, Inc. | System and method for providing and displaying information content |
US20080022208A1 (en) * | 2006-07-18 | 2008-01-24 | Creative Technology Ltd | System and method for personalizing the user interface of audio rendering devices |
US8627218B2 (en) * | 2007-08-24 | 2014-01-07 | Creative Technology Ltd | Host implemented method for customising a secondary device |
US20140365895A1 (en) * | 2008-05-13 | 2014-12-11 | Apple Inc. | Device and method for generating user interfaces from a template |
US9870130B2 (en) * | 2008-05-13 | 2018-01-16 | Apple Inc. | Pushing a user interface to a remote device |
US20090284476A1 (en) * | 2008-05-13 | 2009-11-19 | Apple Inc. | Pushing a user interface to a remote device |
US20100293462A1 (en) * | 2008-05-13 | 2010-11-18 | Apple Inc. | Pushing a user interface to a remote device |
US20130275899A1 (en) * | 2010-01-18 | 2013-10-17 | Apple Inc. | Application Gateway for Providing Different User Interfaces for Limited Distraction and Non-Limited Distraction Contexts |
US20100008650A1 (en) * | 2008-07-10 | 2010-01-14 | Apple Inc. | Multi-model modes of one device |
US20100123834A1 (en) * | 2008-11-14 | 2010-05-20 | Apple Inc. | System and Method for Capturing Remote Control Device Command Signals |
WO2010106394A1 (en) * | 2009-03-16 | 2010-09-23 | Sony Ericsson Mobile Communications Ab | Personalized user interface based on picture analysis |
US8161384B2 (en) * | 2009-04-23 | 2012-04-17 | Hewlett-Packard Development Company, L.P. | Arranging graphic objects on a page with text |
US8942888B2 (en) * | 2009-10-15 | 2015-01-27 | Airbiquity Inc. | Extensible scheme for operating vehicle head unit as extended interface for mobile device |
US8838332B2 (en) * | 2009-10-15 | 2014-09-16 | Airbiquity Inc. | Centralized management of motor vehicle software applications and services |
US9002574B2 (en) * | 2009-10-15 | 2015-04-07 | Airbiquity Inc. | Mobile integration platform (MIP) integrated handset application proxy (HAP) |
WO2011091402A1 (en) * | 2010-01-25 | 2011-07-28 | Justin Mason | Voice electronic listening assistant |
US20110185390A1 (en) * | 2010-01-27 | 2011-07-28 | Robert Bosch Gmbh | Mobile phone integration into driver information systems |
US9841956B2 (en) * | 2011-01-31 | 2017-12-12 | Sap Se | User interface style guide compliance reporting |
US9632688B2 (en) * | 2011-03-31 | 2017-04-25 | France Telecom | Enhanced user interface to transfer media content |
CN103814588B (en) * | 2011-09-12 | 2018-06-19 | 爱尔比奎特公司 | The scalable approach that vehicle head unit is run as the expansion interface of mobile equipment |
US9104441B2 (en) * | 2011-09-30 | 2015-08-11 | Avaya Inc. | Context and application aware selectors |
US20130132848A1 (en) * | 2011-11-18 | 2013-05-23 | Apple Inc. | Application interaction via multiple user interfaces |
JP2013109549A (en) * | 2011-11-21 | 2013-06-06 | Alpine Electronics Inc | On-vehicle device and operation control method of external device connected to on-vehicle device |
US9244583B2 (en) * | 2011-12-09 | 2016-01-26 | Microsoft Technology Licensing, Llc | Adjusting user interface screen order and composition |
US10129324B2 (en) * | 2012-07-03 | 2018-11-13 | Google Llc | Contextual, two way remote control |
US20150220245A1 (en) * | 2012-08-27 | 2015-08-06 | Clear View Productions, Inc. | Branded computer devices and apparatus to connect user and enterprise |
US9917879B2 (en) * | 2012-10-13 | 2018-03-13 | Microsoft Technology Licensing, Llc | Remote interface templates |
US9266018B2 (en) * | 2012-11-08 | 2016-02-23 | Audible, Inc. | Customizable in-vehicle gaming system |
US10546010B2 (en) * | 2012-12-19 | 2020-01-28 | Oath Inc. | Method and system for storytelling on a computing device |
EP2936861B1 (en) * | 2012-12-20 | 2021-07-21 | Airbiquity, Inc. | Efficient headunit communication integration |
US9300779B2 (en) * | 2013-03-15 | 2016-03-29 | Blackberry Limited | Stateful integration of a vehicle information system user interface with mobile device operations |
US10251034B2 (en) * | 2013-03-15 | 2019-04-02 | Blackberry Limited | Propagation of application context between a mobile device and a vehicle information system |
US20140325374A1 (en) * | 2013-04-30 | 2014-10-30 | Microsoft Corporation | Cross-device user interface selection |
US9389759B2 (en) * | 2013-05-07 | 2016-07-12 | Axure Software Solutions, Inc. | Environment for responsive graphical designs |
US20140344682A1 (en) * | 2013-05-17 | 2014-11-20 | United Video Properties, Inc. | Methods and systems for customizing tactilely distinguishable inputs on a user input interface based on available functions |
US20150058728A1 (en) * | 2013-07-22 | 2015-02-26 | MS Technologies Corporation | Audio stream metadata integration and interaction |
US20150193090A1 (en) * | 2014-01-06 | 2015-07-09 | Ford Global Technologies, Llc | Method and system for application category user interface templates |
KR101550055B1 (en) * | 2014-03-18 | 2015-09-04 | 주식회사 오비고 | Method, apparatus and computer-readable recording media for prpviding application connector using template-based ui |
US20150370461A1 (en) * | 2014-06-24 | 2015-12-24 | Google Inc. | Management of Media Player Functionality |
-
2014
- 2014-06-20 US US14/310,211 patent/US20150370419A1/en not_active Abandoned
-
2015
- 2015-06-16 JP JP2016574124A patent/JP6487467B2/en active Active
- 2015-06-16 EP EP15733034.1A patent/EP3158430A1/en not_active Withdrawn
- 2015-06-16 CN CN201580033413.2A patent/CN107077344B/en active Active
- 2015-06-16 WO PCT/US2015/036006 patent/WO2015195647A1/en active Application Filing
Non-Patent Citations (2)
Title |
---|
None * |
See also references of WO2015195647A1 * |
Also Published As
Publication number | Publication date |
---|---|
JP2017520848A (en) | 2017-07-27 |
US20150370419A1 (en) | 2015-12-24 |
WO2015195647A1 (en) | 2015-12-23 |
JP6487467B2 (en) | 2019-03-20 |
CN107077344A (en) | 2017-08-18 |
CN107077344B (en) | 2023-11-28 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US20150370461A1 (en) | Management of Media Player Functionality | |
JP7080999B2 (en) | Search page Interaction methods, devices, terminals and storage media | |
CN107077344B (en) | Interface for multiple media applications | |
US11144274B2 (en) | Methods, systems, and media for providing a remote control interface | |
US20150370446A1 (en) | Application Specific User Interfaces | |
WO2020007012A1 (en) | Method and device for displaying search page, terminal, and storage medium | |
JP2022506929A (en) | Display page interaction control methods and devices | |
CN105138228A (en) | Display device and display method thereof | |
US20190034048A1 (en) | Unifying user-interface for multi-source media | |
GB2520266A (en) | Cursor-Based Character input interface | |
US9894401B2 (en) | Efficient frame rendering | |
KR20160130288A (en) | A lock screen method and mobile terminal | |
WO2018120492A1 (en) | Page processing method, mobile terminal, device and computer storage medium | |
US20140298414A1 (en) | Browsing remote content using a native user interface | |
KR20210068333A (en) | Method and device for guiding operation of application program, equipment and readable storage medium | |
CN104703013A (en) | Operation method and device for remote control for set top box | |
EP2985676A1 (en) | Television-and-computer all-in-one machine, method, and computer storage medium for performing remote control on external computer | |
US20150187186A1 (en) | Wifi Landing Page for Remote Control of Digital Signs | |
US8209444B2 (en) | Keyboards providing macro functions and macro function setting method using the same, and computer program products thereof | |
CN108763391A (en) | Questionnaire page surface treatment method and apparatus | |
CN106454463B (en) | Television-based control method and device | |
US20180024717A1 (en) | Playback of media content inline within a scrollable mixed multimedia display background | |
CN103093791A (en) | Network audio play system | |
CN105915984A (en) | Remote controller and WIFIMirocast conflict solving method and system | |
CN112399259A (en) | Progress bar control method of player |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: THE INTERNATIONAL PUBLICATION HAS BEEN MADE |
|
PUAI | Public reference made under article 153(3) epc to a published international application that has entered the european phase |
Free format text: ORIGINAL CODE: 0009012 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: REQUEST FOR EXAMINATION WAS MADE |
|
17P | Request for examination filed |
Effective date: 20170112 |
|
AK | Designated contracting states |
Kind code of ref document: A1Designated state(s): AL AT BE BG CH CY CZ DE DK EE ES FI FR GB GR HR HU IE IS IT LI LT LU LV MC MK MT NL NO PL PT RO RS SE SI SK SM TR |
|
AX | Request for extension of the european patent |
Extension state: BA ME |
|
DAV | Request for validation of the european patent (deleted) | ||
DAX | Request for extension of the european patent (deleted) | ||
RAP1 | Party data changed (applicant data changed or rights of an application transferred) |
Owner name: GOOGLE LLC |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: EXAMINATION IS IN PROGRESS |
|
17Q | First examination report despatched |
Effective date: 20180702 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: EXAMINATION IS IN PROGRESS |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: THE APPLICATION HAS BEEN WITHDRAWN |
|
18W | Application withdrawn |
Effective date: 20211108 |
|
P01 | Opt-out of the competence of the unified patent court (upc) registered |
Effective date: 20230519 |