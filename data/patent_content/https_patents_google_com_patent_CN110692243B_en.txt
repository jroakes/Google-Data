CN110692243B - Mixing of probabilities for entropy coding in video compression - Google Patents
Mixing of probabilities for entropy coding in video compression Download PDFInfo
- Publication number
- CN110692243B CN110692243B CN201880035871.3A CN201880035871A CN110692243B CN 110692243 B CN110692243 B CN 110692243B CN 201880035871 A CN201880035871 A CN 201880035871A CN 110692243 B CN110692243 B CN 110692243B
- Authority
- CN
- China
- Prior art keywords
- probability
- model
- coding
- symbol
- token
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
Images
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/102—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or selection affected or controlled by the adaptive coding
- H04N19/13—Adaptive entropy coding, e.g. adaptive variable length coding [AVLC] or context adaptive binary arithmetic coding [CABAC]
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/102—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or selection affected or controlled by the adaptive coding
- H04N19/117—Filters, e.g. for pre-processing or post-processing
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/102—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or selection affected or controlled by the adaptive coding
- H04N19/124—Quantisation
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/134—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or criterion affecting or controlling the adaptive coding
- H04N19/157—Assigned coding mode, i.e. the coding mode being predefined or preselected to be further used for selection of another element or parameter
- H04N19/159—Prediction type, e.g. intra-frame, inter-frame or bidirectional frame prediction
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/169—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding
- H04N19/17—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding the unit being an image region, e.g. an object
- H04N19/176—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding the unit being an image region, e.g. an object the region being a block, e.g. a macroblock
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/169—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding
- H04N19/18—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding the unit being a set of transform coefficients
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/189—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the adaptation method, adaptation tool or adaptation type used for the adaptive coding
- H04N19/196—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the adaptation method, adaptation tool or adaptation type used for the adaptive coding being specially adapted for the computation of encoding parameters, e.g. by averaging previously computed encoding parameters
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/42—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals characterised by implementation details or hardware specially adapted for video compression or decompression, e.g. dedicated software implementation
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/44—Decoders specially adapted therefor, e.g. video decoders which are asymmetric with respect to the encoder
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/80—Details of filtering operations specially adapted for video compression, e.g. for pixel interpolation
- H04N19/82—Details of filtering operations specially adapted for video compression, e.g. for pixel interpolation involving filtering within a prediction loop
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/90—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using coding techniques not provided for in groups H04N19/10-H04N19/85, e.g. fractals
- H04N19/91—Entropy coding, e.g. variable length coding [VLC] or arithmetic coding
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/90—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using coding techniques not provided for in groups H04N19/10-H04N19/85, e.g. fractals
- H04N19/96—Tree coding, e.g. quad-tree coding
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/102—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or selection affected or controlled by the adaptive coding
- H04N19/129—Scanning of coding units, e.g. zig-zag scan of transform coefficients or flexible macroblock ordering [FMO]
Abstract
Entropy coding and decoding of symbol sequences using probability mixing is disclosed. One method comprises the following steps: selecting a model comprising a first model and a second model for at least one symbol at a location in a plurality of symbols; determining a mixing probability using the first model and the second model; and coding the symbols using the mixed probabilities. Determining the mixing probability of the symbols comprises: determining a first conditional probability for the coded symbol using a first model; determining a second conditional probability for the coded symbol using a second model; and determining a mixing probability for the coded symbols using the first conditional probability and the second conditional probability. The first conditional probability is the conditional probability of the symbol for the case of a subsequence up to the position of the given sequence. The second conditional probability is the conditional probability of the symbol given the subsequence.
Description
Technical Field
The present disclosure relates to video compression, and more particularly, to the mixing of probabilities of entropy coding in video compression.
Background
A digital video stream may represent video using a series of frames or still images. Digital video may be used for a variety of applications including, for example, video conferencing, high definition video entertainment, video advertising, or sharing of user-generated video. Digital video streams may contain large amounts of data and consume a large amount of computing or communication resources of a computing device used to process, transmit, or store the video data. Various methods have been proposed to reduce the amount of data in a video stream, including compression and other encoding techniques.
Motion estimation and compensation based coding may be performed by decomposing a frame or picture into blocks predicted based on one or more prediction blocks of a reference frame. The difference between the block and the prediction block (i.e., residual error) is compressed and encoded in the bitstream. The decoder uses the difference and reference frames to reconstruct the frame or picture.
Disclosure of Invention
One aspect is a method for entropy coding a sequence of symbols, the method comprising: selecting a model comprising a first model and a second model for at least one symbol at a location in a plurality of symbols; determining a mixing probability using the first model and the second model; and the symbols are coded using the mixed probabilities. Determining the mixing probability of the symbols includes: determining a first conditional probability for the coded symbol using a first model; determining a second conditional probability for the coded symbol using a second model; and determining a mixing probability for the coded symbols using the first conditional probability and the second conditional probability. The first conditional probability is the conditional probability of the symbol for the case of a subsequence up to the position of the given sequence. The second conditional probability is the conditional probability of the symbol given the subsequence.
Another aspect is an apparatus for entropy coding a quantized transform block, the apparatus comprising a memory and a processor. The memory includes instructions executable by the processor to: selecting a probability distribution comprising the first probability distribution and the second probability distribution for coding tokens indicative of quantized transform coefficients of the quantized transform block; determining a mixed probability for the coded token using the first probability distribution and the second probability distribution; and codify the token using the mixed probabilities. The token is selected from an alphabet of tokens. The first probability distribution includes first probability values for tokens in a token alphabet. The second probability distribution includes second probability values for tokens in the token alphabet.
Another aspect is an apparatus for entropy decoding a sequence of symbols that includes a memory and a processor. The memory includes instructions executable by the processor to select a model including a first model and a second model, determine a mixing probability for a symbol at a location of a plurality of symbols using the first model and the second model, and decode the symbol from the compressed bitstream using the mixing probability.
These and other aspects of the disclosure are disclosed in the following detailed description of the embodiments, the appended claims and the accompanying drawings.
Drawings
The description herein makes reference to the accompanying drawings wherein like reference numerals refer to like parts throughout the several views.
Fig. 1 is a schematic diagram of a video encoding and decoding system.
Fig. 2 is a block diagram of an example of a computing device that may implement a transmitting station or a receiving station.
Fig. 3 is a diagram of a video stream to be encoded and subsequently decoded.
Fig. 4 is a block diagram of an encoder according to an embodiment of the present disclosure.
Fig. 5 is a block diagram of a decoder according to an embodiment of the present disclosure.
Fig. 6 is a diagram illustrating quantized transform coefficients according to an embodiment of the present invention.
FIG. 7 is a diagram of a coefficient token tree that may be used to entropy code blocks into a video bitstream, according to an embodiment of the present invention.
Fig. 8 is a diagram of an example of a tree for binarizing quantized transform coefficients according to an embodiment of the present disclosure.
Fig. 9 is a flow chart of a process for encoding a sequence of symbols according to an embodiment of the present invention.
Fig. 10 is a flowchart of a process for decoding a sequence of symbols according to an embodiment of the present invention.
FIG. 11 is a diagram of an example of a binary tree of conditional probabilities, according to an embodiment of the present invention.
FIG. 12 is a flow diagram of a process for entropy coding, according to an embodiment of the present disclosure.
FIG. 13 is a flow diagram of a process for estimating the cost of coding symbols in a non-binary alphabet according to an embodiment of the present disclosure.
Fig. 14 is a flowchart of a process for entropy coding a quantized transform block according to an embodiment of the present disclosure.
Detailed Description
As described above, the compression scheme associated with coding a video stream may include: the image is broken into blocks and a digital video output bitstream is generated by limiting information included in the digital video output using one or more techniques. The received encoded bitstream can be decoded to recreate the block and source images based on the constrained information. Encoding a video stream or a portion thereof (e.g., a frame or a block) may include using temporal or spatial similarities in the video stream to improve coding efficiency. For example, a current block of a video stream may be encoded based on identifying differences (residuals) between previously coded pixel values and those in the current block. In this way, only the residual and the parameters used to generate the residual need to be added to the encoded bitstream. The residual may be encoded using a lossy quantization step.
As described further below, the residual block may be in the pixel domain. The residual block may be transformed into the frequency domain, resulting in a transformed block of transform coefficients. The transform coefficients may be quantized to generate quantized transform blocks of quantized transform coefficients. The quantized coefficients may be entropy encoded and added to the encoded bitstream. The decoder may receive the encoded bitstream, entropy decode the quantized transform coefficients to reconstruct the original video frame.
Entropy coding is a technique for "lossless" coding that relies on a probabilistic model that models the distribution of values that occur in the coded video bitstream. Entropy coding can reduce the number of bits required to represent video data to near a theoretical minimum by using a probabilistic model based on measured or estimated value distributions. In practice, the actual reduction in the number of bits required to represent the video data may depend on the accuracy of the probability model, the number of bits used to perform the coding, and the computational accuracy of the fixed point arithmetic used to perform the coding.
In an encoded video bitstream, many bits are used in one of two cases: content prediction (e.g., inter mode/motion vector coding, intra prediction mode coding, etc.) or residual coding (e.g., transform coefficients). The encoder may use techniques to reduce the number of bits spent on coefficient coding. For example, a coefficient token tree (which may also be referred to as a binary token tree) specifies a range of values with a forward adaptive probability for each branch in this token tree. The token base value is subtracted from the value to be coded to form a residual, and then the block is coded with a fixed probability. Similar schemes with minor variations (including backward adaptation) are also possible. The adaptation technique may alter the probability model as the video stream is encoded to adapt to the changing characteristics of the data. In any case, the decoder is informed of or has available a probability model for encoding the entropy coded video bitstream in order to decode the video bitstream.
As described above, a sequence of symbols is typically entropy coded by: the probability p of a sequence is determined using a probability model, and then the sequence is mapped to a binary codeword using binary arithmetic coding at an encoder and decoded from the binary codeword at a decoder. The length (i.e., number of bits) of the codeword is represented by-log 2 (p) is given. The efficiency of entropy coding may be directly related to the probability model.
Given symbol x n Probability p (x) of the sequence of (2) n ) A good entropy coding engine (e.g., a well-designed binary arithmetic coding engine) can be based on the probability p (x) n ) Produce a length of-log 2 (p(x n ) ) a binary string. Since the length of a string is an integer, the length is-log 2 (p(x n ) "means a length of greater than-log 2 (p(x n ) ) the smallest integer of the binary string. Here, when referring to a sequence of symbols, the superscript i refers to a sequence having a length of i symbols, and the subscript i refers to the symbol at position i in the sequence. For example, x 5 Refers to five (5) symbolsSequence of numbers, e.g., 11010; and x 5 Refers to the symbol at the 5 th position, e.g., the last 0 in the sequence 11010. Thus, the sequence x n Can be expressed as x n ＝x 1 x 2 …x n 。
In some implementations, a symbol may refer to a token selected from a non-binary token alphabet that includes N tokens. Thus, a symbol (i.e., token) may have one of N values. The token may be a token used for coding and indicating the transform coefficients. In this case, the "symbol sequence x n "refer to token List x 1 ,x 2 ,...,x n For coding the transform coefficients at scan positions 1,2, · n, respectively, in scan order.
As used herein, a probability value (such as subsequence x) i Probability p (x) i ) May have a floating point representation or a fixed point representation. Thus, operations applied to these values may use floating point arithmetic or fixed point arithmetic.
Given two probabilities p 1 (x n ) And p 2 (x n ) So that p is 1 (x n )<p 2 (x n ) Probability p 1 (x n ) Resulting in no shorter than the probability p 2 (x n ) A code word of (1). That is, a smaller probability generally results in a longer codeword than a larger probability.
The underlying probability models that are played out of symbols in video coding are often unknown and/or may be too complex to fully describe. Therefore, designing a good model for entropy coding can be a challenging problem in video coding. For example, a model that works well for one sequence may not perform well for another sequence. That is, given a first model and a second model, some sequences may be better compressed using the first model, while other sequences may be better compressed using the second model.
In some video systems, the optimal model for the coding sequence may be coded (i.e., the signal in the coded bitstream). For example, given a sequence to be encoded, a video system may encode the sequence according to all or a subset of the available models, and then select the model that yields the best compression results. That is, the selection of a particular model among a set of more than one model of the sequence may be coded. In such systems, a secondary (two-pass) process may be performed implicitly or explicitly: the first time for determining the optimal model and the second time for encoding using the optimal model. In, for example, real-time applications and other delay-sensitive applications, a two-pass process may not be feasible.
As described above, multiple models (i.e., model 1.., M) may be used for entropy coding. To compress symbol sequences without losing information, arithmetic coding with a finite number of models can also progressively select the best one. This stems from the fact that: the log (i.e., logarithmic) function is a concave function, while the-log function is a convex function.
According to the preceding, and for a finite sequence x of length n n ＝x 1 x 2 …x n The inequality (1) is as follows:
in inequality (1), w k Weight factor, p, representing the kth model k (x n ) X given by the representation model k n The joint probability of (c). As mentioned above, given a probability p k (x n ) (i.e., sequence x) n Probability given by model k) and x n As input, the entropy coding engine may be to convert x n Mapping to a length approximately equal to-logp k (x n ) The binary code word of (c).
From inequality (1), a linear (i.e., weighted) sum of the probabilities of taking a usable model (i.e., a weighted sum) is derived
It can also be derived from equation (1) that it is more advantageous to mix the probabilities of the models 1,.. before entropy coding the symbols. That is, it may be more advantageous to mix the probabilities of multiple models prior to entropy coding than to select a model based on the probabilities and code the bit sequence separately using each model. Mixing different models may improve compression performance (i.e., reduce compression rate) and is no inferior to selecting and coding the optimal model and then coding the sequence using the selected model.
Probability p k (x n ) Is a sequence x n The joint probability of (c). I.e. given the sequence x n ＝x 1 x 2 …x n Joint probability p k (x n ) Is the first symbol x 1 The second symbol is x 2 ,.., and the nth symbol is x n The probability of (c). Due to joint coding x n Can result in significant delays in processing and can result in high computational complexity, and thus blending is of limited, if any, use in video coding.
The model as used herein may be lossless (entropy) coding or may be a parameter in lossless (entropy) coding. For the purposes of entropy coding, the model may be any parameter or method that affects the probability estimation. For example, the model may define probabilities used at interior nodes in the token tree to encode and decode decisions (e.g., as described below with respect to fig. 7). In this case, the two processes of learning the probability of the current frame can be simplified to a single process by mixing multiple models as described herein. In another example, the model may define some context derivation method. In this case, embodiments according to the present disclosure may be used to mix the coding probabilities generated by many such methods. In yet another example, the model may define a completely new lossless coding algorithm.
Embodiments in accordance with the present disclosure can efficiently mix multiple models for entropy coding in real-time or delay-sensitive applications including video coding to reduce the number of bits required to represent video data. The hybrid model may be used to encode any value that is coded using entropy coding. For example, two or more probability models may be mixed for entropy coding of quantized transform coefficients. Benefits of embodiments according to the present disclosure include 1) improved compression performance and 2) blending probabilities from multiple models in a single coding process that does not sacrifice compression performance or incur high computational costs.
The mixing for entropy coding in video compression is first described herein with reference to a system that may incorporate the present teachings.
Fig. 1 is a schematic diagram of a video encoding and decoding system 100. Transmitting station 102 may be, for example, a computer having an internal configuration such as the hardware depicted in fig. 2. However, other suitable implementations of transmitting station 102 are possible. For example, the processing of transmitting station 102 may be distributed among multiple devices.
Network 104 may connect transmitting station 102 and receiving station 106 to encode and decode video streams. In particular, a video stream may be encoded in transmitting station 102 and the encoded video stream may be decoded in receiving station 106. The network 104 may be, for example, the internet. Network 104 may also be a Local Area Network (LAN), Wide Area Network (WAN), Virtual Private Network (VPN), cellular telephone network, or any other means of transmitting a video stream from transmitting station 102 to receiving station 106 in this example.
In one example, the receiving station 106 may be a computer having an internal configuration such as the hardware depicted in fig. 2. However, other suitable implementations of the receiving station 106 are possible. For example, the processing of the receiving station 106 may be distributed among multiple devices.
Other implementations of the video encoding and decoding system 100 are possible. For example, one embodiment may omit network 104. In another embodiment, the video stream may be encoded and then stored for transmission to the receiving station 106 or any other device having memory at a later time. In one embodiment, receiving station 106 receives an encoded video stream (e.g., via network 104, a computer bus, and/or some communication path) and stores the video stream for later decoding. In an example embodiment, the real-time transport protocol (RTP) is used to transmit encoded video over the network 104. In another embodiment, transport protocols other than RTP may be used, such as hypertext transfer protocol (HTTP) -based video streaming protocol.
For example, when used in a videoconferencing system, transmitter station 102 and/or receiving station 106 may include the ability to encode and decode video streams as described below. For example, receiving station 106 may be a video conference participant that receives an encoded video bitstream from a video conference server (e.g., transmitting station 102) for decoding and viewing, and further encodes and transmits its own video bitstream to the video conference server for decoding and viewing by other participants.
Fig. 2 is a block diagram of an example of a computing device 200 that may implement a transmitting station or a receiving station. For example, computing device 200 may implement one or both of transmitting station 102 and receiving station 106 of fig. 1. Computing device 200 may be in the form of a computing system including multiple computing devices or may be in the form of a single computing device, such as a mobile phone, a tablet computer, a laptop computer, a notebook computer, a desktop computer, and the like.
The CPU202 in the computing device 200 may be a central processing unit. Alternatively, the CPU202 may be any other type of device or devices capable of manipulating or processing information now existing or later developed. Although the disclosed embodiments may be practiced with a single processor (e.g., CPU 202) as shown, multiple processors may be used to achieve speed and efficiency advantages.
In one implementation, the memory 204 in the computing device 200 may be a Read Only Memory (ROM) device or a Random Access Memory (RAM) device. Any other suitable type of storage device may be used for memory 204. The memory 204 may include code and data 206 that are accessed by the CPU202 using the bus 212. The memory 204 may further include an operating system 208 and application programs 210, the application programs 210 including at least one program that allows the CPU202 to perform the methods described herein. For example, the application programs 210 may include applications 1 through N, which also include a video coding application that performs the methods described herein. The computing device 200 may also include secondary storage 214, which may be, for example, a memory card for use with the mobile computing device 200. Since video communication sessions may contain a large amount of information, they may be stored in whole or in part in secondary storage 214 and loaded into memory 204 for processing as needed.
Computing device 200 may also include one or more output devices, such as a display 218. In one example, display 218 may be a touch sensitive display that combines the display with a touch sensitive element operable to sense touch input. A display 218 may be coupled to the CPU202 via the bus 212. Other output devices that allow a user to program or otherwise use computing device 200 may be provided in addition to or as an alternative to display 218. When the output device is or includes a display, then the display may be implemented in a variety of ways, including by a Liquid Crystal Display (LCD), a Cathode Ray Tube (CRT) display, or a Light Emitting Diode (LED) display (e.g., an organic LED (oled) display).
Computing device 200 may also include or be in communication with: an image sensing device 220, such as a camera or any other image sensing device 220 now existing or later developed, may sense images such as images of a user operating the computing device 200. The image sensing device 220 may be positioned such that it is directed toward a user operating the computing device 200. In one example, the position and optical axis of the image sensing device 220 may be configured such that the field of view includes an area directly adjacent to the display 218 and from which the display 218 is visible.
Computing device 200 may also include or be in communication with: a sound sensing device 222, such as a microphone or any other sound sensing device now existing or later developed that is capable of sensing sound in the vicinity of the computing device 200. The sound sensing device 222 can be positioned such that it is directed toward a user operating the computing device 200, and can be configured to receive sound, such as speech or other utterances, emitted by the user while the user is operating the computing device 200.
Although fig. 2 depicts the CPU202 and memory 204 of the computing device 200 as integrated into a single unit, other configurations may be utilized. The operations of CPU202 may be distributed across multiple machines (each machine having one or more processors) that may be coupled directly or across a local area network or other network. Memory 204 may be distributed across multiple machines, such as a network-based memory or memory in multiple machines that perform operations for computing device 200. Although described herein as a single bus, the bus 212 of the computing device 200 may be comprised of multiple buses. Further, secondary storage 214 may be directly coupled to other components of computing device 200, or may be accessed via a network, and may comprise a single integrated unit, such as a memory card, or multiple units, such as multiple memory cards. Thus, the computing device 200 may be implemented in a variety of configurations.
Fig. 3 is a diagram of an example of a video stream 300 to be encoded and subsequently decoded. The video stream 300 includes a video sequence 302. At the next level, the video sequence 302 includes a plurality of adjacent frames 304. Although three frames are depicted as adjacent frames 304, video sequence 302 may include any number of adjacent frames 304. The adjacent frames 304 may then be further subdivided into individual frames, such as frame 306. At the next level, the frame 306 may be divided into a series of segments 308 or planes. For example, the segment 308 may be a subset of frames that allow parallel processing. The segment 308 may also be a subset of a frame that may separate the video data into separate colors. For example, a frame 306 of color video data may include a luminance plane and two chrominance planes. The segments 308 may be sampled at different resolutions.
Regardless of whether frame 306 is divided into segments 308, frame 306 may be further subdivided into blocks 310, which may contain data corresponding to, for example, 16x16 pixels in frame 306. The block 310 may also be arranged to include data from one or more segments 308 of pixel data. The tiles 310 may also have any other suitable size, such as 4x4 pixels, 8x8 pixels, 16x8 pixels, 8x16 pixels, 16x16 pixels, or larger.
Fig. 4 is a block diagram of an encoder 400 according to an embodiment of the present disclosure. As described above, encoder 400 may be implemented in transmitting station 102, for example, by providing a computer software program stored in a memory, such as memory 204. The computer software program may include machine instructions that, when executed by a processor such as CPU202, cause transmitting station 102 to encode video data in the manner described herein. Encoder 400 may also be implemented as specialized hardware included in transmitting station 102, for example. The encoder 400 has the following stages to perform various functions in the forward path (shown by the solid connecting lines) to generate an encoded or compressed bitstream 420 using the video stream 300 as input: intra/inter prediction 402, transform 404, quantization 406, and entropy coding 408. The encoder 400 may also include a reconstruction path (illustrated by dashed connecting lines) to reconstruct the frame used to encode the future blocks. In fig. 4, the encoder 400 has the following stages to perform various functions in the reconstruction path: dequantization 410, inverse transformation 412, reconstruction 414, and loop filtering 416. Other structural variations of the encoder 400 may be used to encode the video stream 300.
When the video stream 300 is presented for encoding, the frames 306 may be processed in units of blocks. In intra/inter prediction 402, a block may be encoded using either intra prediction or inter prediction or a combination of both. In any case, a prediction block may be formed. In the case of intra prediction, all or part of a prediction block may be formed from previously encoded and reconstructed samples in the current frame. In the case of inter prediction, all or part of the prediction block may be formed from samples in one or more previously constructed reference frames determined using the motion vector.
Then, still referring to FIG. 4, the prediction block may be subtracted from the current block at intra/inter prediction 402 to generate a residual block (also referred to as a residual). Transform 404 transforms the residual into transform coefficients, e.g., in the frequency domain, using a block-based transform. Such block-based transforms include, for example, Discrete Cosine Transform (DCT) and Asymmetric Discrete Sine Transform (ADST). Other block-based transforms are also possible. Furthermore, a combination of different transforms may be applied to a single residual. In one example of the application of the transform, the DCT transforms the residual block to the frequency domain, where the transform coefficient values are based on spatial frequency. The lowest frequency (DC) coefficients are in the upper left corner of the matrix and the highest frequency coefficients are in the lower right corner of the matrix. It is noted that the size of the prediction block, and thus the size of the residual block, may be different from the size of the transform block. For example, a prediction block may be divided into smaller blocks to which separate transforms are applied.
Quantization 406 converts the transform coefficients into discrete quantum values, referred to as quantized transform coefficients, using quantizer values or quantization levels. For example, the transform coefficients may be divided by the quantizer values and truncated. The quantized transform coefficients are then entropy encoded by entropy encoding 408. Entropy coding may be performed using any number of techniques, including token trees and binary trees. The entropy coded coefficients are then output to the compressed bitstream 420 along with other information used to decode the block (which may include, for example, the type of prediction used, the transform type, the motion vector, and the quantizer value). The information for decoding the block may be entropy coded as a block, frame, slice, and/or section header within the compressed bitstream 420. The compressed bitstream 420 may also be referred to as an encoded video stream or an encoded video bitstream, and these terms may be used interchangeably herein.
The reconstruction path in fig. 4 (illustrated by the dashed connecting lines) may be used to ensure that the encoder 400 and decoder 500 (described below) use the same reference frames and blocks to decode the compressed bitstream 420. The reconstruction path performs functions similar to those occurring during the decoding process (described in more detail below), including dequantizing the quantized transform coefficients at dequantization 410 and inverse transforming the dequantized transform coefficients at inverse transform 412 to produce a block of derived residuals (also referred to as derived residuals). At reconstruction 414, the predicted block predicted at intra/inter prediction 402 may be added to the derived residual to create a reconstructed block. Loop filtering 416 may be applied to the reconstructed block to reduce distortion, such as blocking artifacts.
Other variations of the encoder 400 may be used to encode the compressed bitstream 420. For example, the non-transform based encoder 400 may quantize the residual signal directly for certain blocks or frames without the transform 404. In another embodiment, the encoder 400 may have the quantization 406 and the dequantization 410 combined into a single stage.
Fig. 5 is a block diagram of a decoder 500 according to an embodiment of the present disclosure. The decoder 500 may be implemented in the receiving station 106, for example, by providing a computer software program stored in the memory 204. The computer software program may include machine instructions that, when executed by a processor such as CPU202, cause receiving station 106 to decode video data in the manner described in fig. 8 and 9 below. Decoder 500 may also be implemented in hardware included in, for example, transmitting station 102 or receiving station 106. Similar to the reconstruction path of the encoder 400 discussed above, the decoder 500 in one example includes the following stages to perform various functions to generate the output video stream 516 from the compressed bitstream 420: entropy decoding 502, dequantization 504, inverse transformation 506, intra/inter prediction 508, reconstruction 510, loop filtering 512, and optional post filtering 514. Other structural variations of the decoder 500 may be used to decode the compressed bitstream 420. Loop filtering 512 may include deblocking filtering.
When the compressed bitstream 420 is provided for decoding, data elements within the compressed bitstream 420 may be decoded by the entropy decoding 502 to produce a set of quantized transform coefficients. Dequantization 504 dequantizes the quantized transform coefficients (e.g., by multiplying the quantized transform coefficients by quantizer values), and inverse transform 506 inverse transforms the dequantized transform coefficients using the selected transform type to produce a derived residual that may be identical to the derived residual created by inverse transform 412 in encoder 400. Using the header information decoded from the compressed bitstream 420, the decoder 500 may use intra/inter prediction 508 to create a prediction block that is identical to the prediction block created in the encoder 400, e.g., at the intra/inter prediction 402. At reconstruction 510, the prediction block may be added to the derived residual to create a reconstructed block. Loop filtering 512 may be applied to the reconstructed block to reduce blocking artifacts. In this way, the loop filter 512 may apply deblocking filtering. Other filtering may be applied to the reconstructed block. In one example, post-filtering 514 is applied to the reconstructed block to reduce the block distortion, and the result is output as output video stream 516. The output video stream 516 may also be referred to as a decoded video stream, and these terms will be used interchangeably herein.
Other variations of the decoder 500 may be used to decode the compressed bitstream 420. For example, the decoder 500 may produce the output video stream 516 without the post-filtering 514. In some embodiments of the decoder 500, post-filtering 514 is applied prior to loop filtering 512. Additionally or alternatively, the encoder 400 includes deblock filtering in addition to the loop filtering 416.
Fig. 6 is a diagram 600 illustrating quantized transform coefficients according to an embodiment of the present disclosure. The diagram 600 depicts a current block 620, a scan order 602, a quantized transform block 604, a non-zero diagram 606, an end-of-block diagram 622, and a token (sign) diagram 626. Current block 620 is shown as a 4x4 block. However, any block size is possible. For example, the current block may have a size (i.e., size) of 4 × 4, 8 × 8, 16 × 16, 32 × 32, or any other square or rectangular block size. The current block 620 may be a block of the current frame. In another example, the current frame may be divided into sections (such as section 308 of fig. 3) or blocks, etc., each comprising a set of blocks, where the current block is a block of the partition.
The quantized transform block 604 may be a block of a size similar to that of the current block 620. The quantized transform block 604 includes non-zero coefficients (e.g., coefficient 608) and zero coefficients (e.g., coefficient 610). As described above, the quantized transform block 604 contains quantized transform coefficients for a residual block corresponding to the current block 620. Also, as described above, the quantized transform coefficients are entropy coded by an entropy coding stage, such as entropy coding 408 of FIG. 4.
Entropy coding quantized transform coefficients may involve the selection of a context model (also referred to as a probabilistic context model, a probability model, a model, and a context) that provides an estimate of the conditional probability for coding the binary symbols of the binarized transform coefficients, as described below with respect to fig. 7. When entropy coding quantized transform coefficients, the additional information may be used as a context for selecting a context model. For example, the magnitude of previously coded transform coefficients may be used, at least in part, to determine a probability model.
To encode the transform block, the video coding system may traverse the transform block in scan order and encode (e.g., entropy encode) the quantized transform coefficients as they are traversed (i.e., accessed), respectively. The upper left corner of the transform block (also referred to as the DC coefficient) is traversed and coded first in a zig-zag scan order (e.g., scan order 602), and the next coefficient (i.e., the transform coefficient corresponding to the position labeled "1") is traversed and coded in scan order, and so on. Some quantized transform coefficients above and to the left of the current quantized transform coefficient (e.g., the transform coefficient to be encoded) are first traversed in a zig-zag scan order (i.e., scan order 602). Other scan orders are also possible. A one-dimensional structure (e.g., an array) of quantized transform coefficients may be generated by traversing a two-dimensional quantized transform block using a scan order.
In some examples, encoding the quantized transform block 604 may include determining a non-zero map 606, the non-zero map 606 indicating which quantized transform coefficients of the quantized transform block 604 are zero and which are non-zero. The non-zero coefficients and zero coefficients may be represented in the non-zero map by the values one (1) and zero (0), respectively. For example, non-zero map 606 includes a non-zero 607 at a cartesian position (0, 0) corresponding to coefficient 608 and a zero 608 at a cartesian position (2, 0) corresponding to coefficient 610.
In some examples, encoding the quantized transform block 604 may include generating and encoding an end of block map 622. The end-of-block diagram indicates whether the non-zero quantized transform coefficient of quantized transform block 604 is the last non-zero coefficient for a given scan order. If the non-zero coefficient is not the last non-zero coefficient in the transform block, the coefficient may be represented by a binary bit zero (0) in the end-of-block map. On the other hand, if the non-zero coefficient is the last non-zero coefficient in the transform block, the coefficient may be represented by a binary value of one (1) in the end-of-block diagram. For example, since the quantized transform coefficient corresponding to scan position 11 (i.e., the last non-zero quantized transform coefficient 628) is the last non-zero coefficient of the quantized transform block 604, it is indicated by a block end value 624 of one (1); all other non-zero transform coefficients are indicated with zeros.
In some examples, encoding quantized transform block 604 may include generating and encoding a logo 626. The beacon map 626 indicates which non-zero quantized transform coefficients of the quantized transform block 604 have positive values and which quantized transform coefficients have negative values. Transform coefficients that are indicated as zero in the symbol map are not required. The token map 626 illustrates a token map of the quantized transform block 604. In the symbol map, a negative quantized transform coefficient may be indicated by zero (0) and a positive quantized transform coefficient may be indicated by one (1).
Fig. 7 is a diagram of a coefficient token tree 700 that may be used to entropy code blocks into a video bitstream, according to an embodiment of the present disclosure. The coefficient token tree 700 is referred to as a binary tree because at each node of the tree, one of two branches must be taken (i.e., traversed). The coefficient token tree 700 includes a root node 701 and a node 703 corresponding to nodes labeled a and B, respectively.
As described above with respect to fig. 6, when an end of block (EOB) token is detected for a block, coding of coefficients in the current block may terminate, and the remaining coefficients in the block may be inferred to be zero. Thus, coding of the EOB position can be an essential part of the coefficients in a video coding system.
In some video coding systems, a binary decision determining whether the current token is equal to the EOB token for the current block is coded immediately after decoding the non-zero coefficients or at a first scan position (DC). In one example, for a transform block of size MxN, (where M represents the number of columns in the transform block and N represents the number of rows in the transform block), whether the current token is equal to the maximum number of codings of the EOB token is equal to MxN. M and N may take values such as values 2, 4, 8, 16, 32, and 64. As described below, the binary decision corresponds to the coding of a "1" bit, which corresponds to a decision to move from the root node 701 to the node 703 in the coefficient token tree 700. Here, "coding a bit" may mean output or generation of a bit representing a transform coefficient being coded in a codeword. Similarly, "decoding a bit" may mean reading (e.g., from an encoded bitstream) a bit of the codeword corresponding to the quantized transform coefficient being decoded, such that the bit corresponds to the branch being traversed in the coefficient token tree.
Using the coefficient token tree 700, a string of binary digits is generated for quantized coefficients (e.g., coefficients 608, 610 of fig. 6) of a quantized transform block, such as quantized transform block 604 of fig. 6.
In one example, the quantized coefficients in an NxN block (e.g., quantized transform block 604) are organized into a 1D (one-dimensional) array (here array u) following a prescribed scan order (e.g., scan order 602 of fig. 6). N may be 4, 8, 16, 32 or any other value. The quantized coefficients at the ith position of the 1D array may be referred to as u [ i ], where i is 0, …, N-1. The starting position of the last zero in u [ i ], …, u [ N × N-1] can be denoted eob. In case u N-1 is not zero eob may be set to a value N. That is, if the last coefficient of the 1D array u is not zero, eob may be set to the value N x N. Using the example of fig. 6, the 1D array u may have an entry u [ ] [ -6, 0, -1, 0, 2, 4, 1, 0, 1, 0, -1, 0. The value at each of u [ i ] is a quantized transform coefficient. The quantized transform coefficients of the 1D array u may also be referred to herein simply as "coefficients" or "transform coefficients". The coefficient at the position i-0 (i.e., u [0] ═ -6) corresponds to a DC coefficient. In this example, eob is equal to 12 because there are no non-zero coefficients after the zero coefficient at position 12 of the 1D array u.
To encode and decode the coefficients u [ i ], …, u [ N × N-1], a token t [ i ] is generated at each position of i < eob for i 0 to N × N-1. For i < eob, the token t [ i ] may indicate the size and/or size range of the corresponding quantized transform coefficient at u [ i ]. The TOKEN of quantized transform coefficients at EOB may be EOB TOKEN, which is a TOKEN indicating that 1D array u does not contain any non-zero coefficients after position EOB (inclusive). That is, t [ EOB ] ═ EOB _ TOKEN indicates the EOB position of the current block. Table I below provides a list of examples of TOKEN values other than EOB TOKEN and their corresponding names, according to embodiments of the present disclosure.
Token | Token name |
0 | ZERO_TOKEN |
1 | ONE_TOKEN |
2 | TWO_TOKEN |
3 | THREE_TOKEN |
4 | FOUR_TOKEN |
5 | DCT_VAL_CAT1(5,6) |
6 | DCT_VAL_CAT2(7-10) |
7 | DCT_VAL_CAT3(11-18) |
8 | DCT_VAL_CAT4(19-34) |
9 | DCT_VAL_CAT5(35-66) |
10 | DCT_VAL_CAT6(67-2048) |
In one example, the quantized coefficient values are taken as signed 12-bit integers. To represent the quantized coefficient values, the 12-bit signed value range may be divided into 11 TOKENs (TOKENs 0-10 in Table I) plus an end-of-block TOKEN (EOB _ TOKEN). To generate tokens representing quantized coefficient values, the coefficient token tree 700 may be traversed. The results of traversing the tree (i.e., the string of bits) may then be encoded by an encoder into a bitstream (such as bitstream 420 of fig. 4) as described with respect to entropy coding 408 of fig. 4.
Coefficient TOKEN tree 700 includes TOKENs EOB _ TOKEN (TOKEN 702), ZERO _ TOKEN (TOKEN 704), ONE _ TOKEN (TOKEN 706), TWO _ TOKEN (TOKEN 708), THEE _ TOKEN (TOKEN 710), FOUR _ TOKEN (TOKEN 712), CAT1 (TOKEN 714, DCT _ VAL _ CAT1 in Table I), CAT2 (TOKEN 716, DCT _ VAL _ CAT2 in Table I), CAT3 (TOKEN 718, DCT _ VAL _ CAT3 in Table I), CAT4 (TOKEN 720, DCT _ VAL _ CAT4 in Table I), CAT5 (TOKEN 722, DCT _ VAL _ CAT _ 5 in Table I), and CAT6 (TOKEN 724, DCT _ VAL _ CAT6 in Table I). As can be seen, the coefficient token tree maps a single quantized coefficient value to a single token, e.g., one of tokens 704, 706, 708, 710, and 712. Other tokens (e.g., tokens 714, 716, 718, 720722, and 724) represent ranges of quantized coefficient values. For example, a quantized transform coefficient having a value of 37 may be represented by the token DCT _ VAL _ CAT5, the token 722 in fig. 7.
The base value of a token is defined as the smallest number within its range. For example, token 720 has a base value of 19. Entropy coding identifies a token for each quantized coefficient, and if a token represents a range, a residual may be formed by subtracting a base value from the quantized coefficient. For example, a quantized transform coefficient having a value of 20 may be represented by including token 720 and residual value 1 (i.e., 20 minus 19) in the encoded video bitstream to allow a decoder to reconstruct the original quantized transform coefficient. The end of block token (i.e., token 702) signals that there are no other non-zero quantized coefficients remaining in the transformed block data.
To encode or decode the token t [ i ] by using a binary arithmetic coding engine (e.g., by entropy coding 408 of fig. 4), a coefficient token tree 700 may be used. The coefficient token tree 700 is traversed starting at the root node 701 (i.e., the node labeled a). Traversing the coefficient token tree generates a bit string (codeword) that will be encoded into the bitstream using, for example, binary arithmetic coding. The bit string represents the current coefficient (i.e., the quantized transform coefficient being encoded).
If the current coefficient is zero and the remaining transform coefficients no longer have non-zero values, a TOKEN 702 (i.e., EOB _ TOKEN) is added to the bitstream. This is the case, for example, for the transform coefficients at scan order position 12 of fig. 6. On the other hand, if the current coefficient is not zero, or if there is a non-zero value among any remaining coefficients of the current block, a "1" bit is added to the codeword and the traversal proceeds to node 703 (i.e., the node labeled B). At node B, the current coefficient is tested to see if it is equal to zero. If so, the left branch is taken so that a TOKEN 704 representing the value ZERO _ TOKEN and a bit of "0" are added to the codeword. If not, a bit of "1" is added to the codeword and the traversal proceeds to node C. At node C, the current coefficient is tested to see if it is greater than 1. If the current coefficient is equal to ONE (1), the left branch is taken and a TOKEN 706 representing the value ONE _ TOKEN is added to the bitstream (i.e., a "0" bit is added to the codeword). If the current coefficient is greater than one (1), then the traversal proceeds to node D to check the value of the current coefficient compared to the value of 4. If the current coefficient is less than or equal to 4, the traversal proceeds to node E and a "0" bit is added to the codeword. At node E, a test equal to the value "2" may be performed. If true, a token 706 representing a value of "2" is added to the bit stream (i.e., a bit of "0" is added to the codeword). Otherwise, at node F, the current coefficient is tested against the value "3" or the value "4" and a token 710 (i.e., adding bit "0" to the codeword) or a token 712 (i.e., adding bit "1" to the codeword) or the like is added to the bitstream as appropriate.
Essentially, a "0" bit is added to the codeword when traversing to the left child node, and a "1" bit is added to the codeword when traversing to the right child node. When decoding codewords from a compressed bitstream, the decoder proceeds with a similar process. The decoder reads a bit from the bitstream. If the bit is "1", the coefficient token tree is traversed to the right, and if the bit is "0", the tree is traversed to the left. The decoder then reads the next bit and repeats the process until the traversal of the tree reaches a leaf node (i.e., token). As one example, to encode the TOKEN t [ i ] ═ THREE _ TOKEN, the binary string 111010 is encoded starting from the root node (i.e., root node 701). As another example, decoding the codeword 11100 produces the TOKEN TWO TOKEN.
Note that the correspondence between the "0" and "1" bits of the left and right child nodes is merely a convention for describing the encoding and decoding process. In some embodiments, a different convention may be used, for example, in embodiments where a "1" corresponds to the left child node and a "0" corresponds to the right child node. The procedure described herein applies as long as both the encoder and decoder employ the same convention.
Since EOB _ TOKEN is only possible after non-zero coefficients, the decoder can conclude that the first bit must be 1 when u [ i-1] is zero (i.e., when the quantized transform coefficient at position i-1 of the 1D array u equals zero). The first bit must be 1 because in traversing the tree, for a transform coefficient (e.g., at zig-zag scan order position 2 of fig. 6) following a zero transform coefficient (e.g., at zig-zag scan order position 1 of fig. 6), the traversal must move from the root node 701 to the node 703.
In this way, the binary flag checkEob may be used to instruct the encoder and decoder to skip encoding and decoding the first bit from the root node in the coefficient token tree 700. In effect, when the binary flag checkEob is 0 (i.e., indicating that the root node should not be checked), the root node 701 of the coefficient token tree 700 is skipped and node 703 becomes the first node of the coefficient token tree 700 to be visited to traverse. That is, when skipping the root node 701, the encoder may skip encoding and the decoder may skip decoding and may infer the first bit of the encoded string (i.e., binary bit "1").
At the beginning of encoding or decoding a block, the binary flag checkEob may be initialized to 1 (i.e., indicating that the root node should be checked). The following steps illustrate an example process for decoding quantized transform coefficients in an nxn block.
In step 1, the binary flag checkEob is set to zero (i.e., checkEob ═ 0), and the index i is also set to zero (i.e., i ═ 0).
At step 2, (1) if the binary flag checkEob is equal to 1, the token t [ i ] is decoded by using the full coefficient token tree (i.e., starting at the root node 701 of the coefficient token tree 700); or (2) if checkEob is equal to 0, decode TOKEN t [ i ] using the partial tree (e.g., starting from node 703) in which EOB _ TOKEN is skipped.
In step 3, if the TOKEN t [ i ] ═ EOB _ TOKEN, the quantized transform coefficients u [ i ], …, u [ N × N-1] are all zero, and the decoding process terminates; otherwise, additional bits may be decoded and u [ i ] reconstructed if necessary (i.e., when t [ i ] is not equal to ZERO _ TOKEN).
At step 4, the binary flag checkEob is set to 1 if u [ i ] is equal to zero, otherwise the checkEob is set to 0. That is, the checkEob may be set to a value (u [ i ] | ═ 0).
At step 5, the index i is incremented (i.e., i ═ i + 1).
In step 6, steps 2-5 are repeated until all quantized transform coefficients have been decoded (i.e. until the index i ═ N × N) or until EOB TOKEN is decoded.
In step 2 above, decoding the token t [ i ] may comprise the steps of: determining a context ctx; determining a binary probability distribution (i.e., model) from the context ctx; and decoding a path from a root node to a leaf node of the coefficient token tree 700 using a boolean arithmetic code by using the determined probability distribution. The context ctx may be determined using a context derivation method. The context derivation method may determine the context ctx using one or more of the following: block size, plane type (i.e. luminance or chrominance), position i, and previously decoded token t [0], …, t [ i-1 ]. Other criteria may be used to determine the context ctx. The binary probability distribution may be determined for any internal node of the coefficient token tree 700, starting from the root node 701 when checkEOB is 1 or starting from node 703 when checkEOB is 0.
In some coding systems, the probability for encoding or decoding a token t [ i ] may be fixed and not fit into a picture (i.e., frame) given a context ctx. For example, the probability may be a default value defined for a given context ctx, or the probability may be coded (i.e., signaled) as part of the frame header of the frame. It may be expensive to code the probabilities for each context in a coded frame. In this way, the encoder can analyze for each context whether the associated probability of coding the context in the frame header is beneficial and signal its decision to the decoder by using a binary flag. Furthermore, prediction may be used to reduce cost (e.g., at a bit rate) for context coding probabilities, where the prediction may be derived from probabilities of the same context in previously decoded frames.
In some coding systems, instead of traversing a coefficient token tree, such as coefficient token tree 700, to code the transform coefficients, each token may be associated with a value that is coded. Thus, instead of coding binary symbols (i.e., selecting from the alphabet consisting of the symbols 0, 1), transform coefficients are coded using an alphabet of symbols that includes more than two symbols. In ONE example, the alphabet includes 12 symbols, namely { EOB _ TOKEN, ZERO _ TOKEN, ONE _ TOKEN, TWO _ TOKEN, THEE _ TOKEN, FOUR _ TOKEN, DCT _ VAL _ CAT1, DCT _ VAL _ CAT2, DCT _ VAL _ CAT3, DCT _ VAL _ CAT4, DCT _ VAL _ CAT5, DCT _ VAL _ CAT6 }. As such, the alphabet used to code the transform coefficients includes 12 symbols, which are also referred to as tokens. Other token alphabets containing more, fewer, or other tokens are possible. An alphabet that includes only the symbols 0, 1 is referred to herein as a binary alphabet. An alphabet comprising symbols other than the symbol 0, 1 and/or symbols other than the symbol 0, 1 is referred to herein as a non-binary alphabet. Each token may be associated with a value. In one example, the value of EOB _ TOKEN may be 255. Each of the other tokens may be associated with a different value.
Fig. 8 is a diagram of an example of a tree 800 for binarizing quantized transform coefficients according to an embodiment of the present disclosure. Tree 800 is a binary tree that may be used in some video coding systems to binarize quantized transform coefficients. The tree 800 may be used by a video coding system that encodes and decodes quantized transform coefficients using the steps of binarization, context modeling, and binary arithmetic coding. This process may be referred to as Context Adaptive Binary Arithmetic Coding (CABAC). For example, to code the quantized transform coefficients x, the coding system may perform the following steps. The quantized transform coefficient x may be any coefficient (e.g., coefficient 608) of the quantized transform block 604 of fig. 6.
In the binarization step, the coefficients x are first binarized into a binary string by using the tree 800. The binarization process may binarize unsigned values of the coefficient x. For example, to binarize coefficient 628 (i.e., value-1), value 1 is binarized. This results in traversing tree 800 and generating binary string 10. Each bit of the binary string 10 is called a bin.
In the context derivation step, for each bin to be coded, a context is derived. The context may be derived from information such as one or more of the following: block size, plane type (i.e., luma or chroma), block location of coefficient x, and previously decoded coefficients (e.g., adjacent coefficients to the left and/or above, if available). Other information may be used to derive the context.
In the binary arithmetic coding step, bins are coded into binary codewords together with probability values associated with the contexts, given the context, by using, for example, a binary arithmetic coding engine.
The step of coding the transform coefficients may include a step referred to as a context update. In the context update step, after coding the bin, the probability associated with the context is updated to reflect the value of the bin.
A mixture of probability models is now described for coding (i.e., encoding or decoding) a sequence x of length n n . For simplicity, two (2) models were used. However, the present disclosure is not so limited and any number of models may be mixed.
For sequence x n Any subsequence of length i (wherein 1. ltoreq. i.ltoreq.n), probability p k (x i ) Representing the estimation of a subsequence x by using a model k i Where k is 1, 2. For each model, a corresponding weighting factor w is used k Two models can be mixed using equation (2):
In the case of the equation (2),
In one example, and since it may not be known a priori which model should have priority, a simple mix may be used. For example, uniform weighting may be used. That is, the weighting factor w may be selected k So that w k 1/2. Thus, equation (2) can be rewritten as:
Probability of mixture
using the basic conditional probability formula P (a ∞ B) ═ P (a ≈ B)/P (B), where P (a ≈ B) is the probability that both events a and B occur, equation (4) may be rewritten as equation (5):
note that x i And x i-1 Mixed probability of both occurrence with x alone i Are equal because of the subsequence x i Containing a subsequence x i-1 And has the symbol x i 。
Equation (5) may be rewritten using equation (3). That is, each subsequence mixture probability (i.e., numerator and denominator) of equation (5) can be rewritten according to the model probability. Equation (5) can be rewritten as equation (6):
by multiplying the first and second quantities of equation (6) by a factor equal to one (1), respectively (i.e., respectively
equation (7) can be written as equation (8):
it is noted that p may be obtained as a result of encoding (and similarly decoding) of the sequence up to the ith symbol using model 1 and model 2, respectively 1 (x i |x i-1 ) And p 2 (x i |x i-1 ) The conditional probability of (2). That is, starting from the corresponding initial state, each model k can maintain and track the conditional probability p throughout the coding process k (x i |x i-1 ). For example, in the case of symbol x i After coding (e.g., encoding or decoding), the probability p can be updated k (x i |x i-1 ) To the next symbol x i+1 Obtaining p k (x i+1 |x i ). The same prescribed procedure can be used by the encoder and decoder to update the probabilities. The encoder and decoder may follow the same prescribed procedure to maintain and update the probability of model k. In some embodiments, symbol x is paired each time i Neither probability maintenance nor probability updating is performed when the coding is performed. Thus, the probability p k (x i |x i-1 ) May have the form p k (x i |c k,i ) Wherein, c k,i May be referred to as for x i A context for coding. Each model k may have a number from x i-1 And other information available to model k to derive a corresponding context c k,i The corresponding method. Probability p k (x i |c k,i ) Can be stored and saved in memory, where context c k,i May be used as an index for accessing memory. In an embodiment according to the present disclosure, conditional probabilities are mixed and then the mixed probabilities (i.e., the
In equation (8), w i,1 And w i,2 Are respectively equal to
When the joint distribution is mixed using equation (3), a uniform weighting factor (i.e., 1/2) is used. However, when the conditional probabilities are mixed (as shown in equation (8)), the weighting (i.e., w for the first model) i,1 And w for the second model i,2 ) May no longer be uniform. Weight w of conditional probability of the first model i,1 Equal to x given by the first model i-1 Is divided by x given by the first model i-1 And x given by the second model i-1 The sum of the joint probabilities of (c). For the weight w i,2 The same applies. In equation (8), for subsequence x i-1 The first model provides a first probability and the second model provides a second probability, and at a given x i-1 Time x i Is equal to each given probability of the first and second model divided by the sum of the joint probabilities given by the two models. That is, in the mixture of conditional probabilities, for example, if the first model is subsequence x i-1 Providing a higher probability, the first model will eventually have a higher weighting factor (i.e., weight w) than the second model i,1 )。
The joint probability being a real number, weight w i,1 And w i,2 The calculation of (c) involves a division of real numbers. Thus, the weight w i,1 And w i,2 Can be complex and expensive. It is desirable to approximate the weight w with a fixed-point representation i,1 And w i,2 So that for example the exact number of bits representing each weight can be known and so that division operations can be avoided.
As described aboveThere is a correlation and/or relationship between the probability of a codeword and the length (in bits) of the codeword generated using the probability of the codeword. I.e., from-log 2 (p) gives the length (i.e., the number of bits) of the codeword. The length of the codeword generated by each model can be used to approximate the weight w i,1 And w i,2 . That is, for k equal to 1,2, x may be encoded by using a model k i-1 Resulting codeword length in bits/ k (x i-1 ) To approximate-log (p) k (x i-1 )). Thus, the weight w can be approximated using equation (9) i,1 (and similarly, the weight w i,2 )：
When l is 2 (i-1) is equal to l 1 When (i-1), then w i,1 ＝w i,2 0.5. Suppose without loss of generality 1 (i-1) less than l 2 (i-1), then equation (9) may be eliminated by extending the denominator and then from the denominator and numerator
To determine the length l of a subsequence of length i from the model k k (x i ) A hypothetical encoding procedure may be used. The assumed encoding process is a process that performs the coding step but does not generate the actual codeword or output bits into the encoded bitstream. Since the aim is to estimate l k (x i ) (which in some applications is interpreted as a bit rate (or simply rate)), the hypothetical encoding process can therefore be considered or referred to as a rate estimation process. The hypothetical encoding process uses a probability model to calculate or estimate the codeword length of a sequence. The codeword length may be determined (i.e., measured) with or without generating a codeword. For example, at time instance i, sequence x is paired using a first model i--1 Coding is carried out to generate the length of l 1 (i-1) and generating a codeword of length l using the second model 2 (ii) the codeword of (i-1). In thatIn one example, multiple hypothetical encoders may be available and executed in parallel. For example, a standard velocity estimator for an arithmetic coder may be used for each model. Each velocity estimator may provide (or may be used to provide) an estimate of the codeword length produced by the encoder for the sub-sequence given the model.
Given two competing models at time instance i, if the first model provides fewer bits than the second model, then for up to position x i-1 The weight assigned to the first model (using equation 9) will be greater than the weight assigned to the second model. Finally (i.e., when mixed probability completion is used for sequence x n When encoded) the winning model (i.e., the model with the higher weight) is the model that produces fewer bits, which is the desired compression result.
Weight w i,1 The approximation is performed using powers of 2 (in equation (9)), so the calculation can be performed efficiently.
The weight w can be further simplified i,1 . The right side of equation (9) is of the form 1/(1-r), where,
Thus, w of equation (8) i,1 *p 1 (x i |x i-1 ) Can be rewritten as equation (11):
in the case of the equation (11),can be at p 1 (xi|xi -1 ) Efficient computation using shifts with fixed-point representation
The weight w may be calculated using equation (12) i,2 ：
The quantity w of equation (8) may be calculated using equation (13) i,2 *p 2 (x i |x i-1 )：
When p is equal to that in equation (11) 2 (x i |x i-1 ) With a fixed-point representation, the right side of equation (13) can be simplified by truncating the infinite sum to a finite sum.
As described above, the mixture of joint probabilities of the models may use a simple homogeneous mixture, as the models may not be known a priori to provide better compression. A uniform mixture of joint probabilities uses conditional probabilities and results in selection of a winning model (i.e., a model with higher weight).
Some video data may be non-stationary in frames/pictures. That is, the statistics of one transform block may be substantially different from, for example, the immediately subsequent transform block. In this way, a mixture of probability models can be used to adapt the probability distribution to the local statistics of the current transform block being coded. Using a mixture of probabilities to adapt to local statistics of a current block is referred to herein as a local mixture of transform blocks.
As described above, since the statistical information of the current block may be significantly different from that of the previous transform block, in case of the local blending of the transform blocks, the current block does not use the coding history of the previous transform block. In this way, the mixing of the probability models may start from the boundary of the current transform block.
Sub-sequence x of equation (2) when locally blending transform blocks i (i.e., for each i,
Fig. 9 is a flow diagram of a process 900 for encoding a sequence of symbols according to an embodiment of the present disclosure. Process 900 may receive a symbol sequence of size n. The sequence may be represented by x n And (4) showing. Receiving may mean generating, determining, or receiving in any manner. In one example, the sequence of symbols may represent quantized transform coefficients, such as the quantized transform coefficients received from quantization 406 of fig. 4 at entropy coding 408. In one example, the sequence of symbols may be a token, such as the token described with respect to fig. 7. In one example, the sequence of symbols may be binarized values, such as the binarized values described with respect to fig. 8. The symbol sequence may be any symbol sequence encoded based on a probability model.
Process 900 may be implemented in an encoder, such as encoder 400 of fig. 4. Process 900 may be implemented as a software program that may be executed by a computing device, such as transmitting station 102, for example. The software program may include machine-readable instructions that may be stored in a memory, such as memory 204 or secondary storage 214, and executed by a processor, such as CPU202, to cause a computing device to perform process 900. In at least some implementations, the process 900 can be performed in whole or in part by the entropy coding 408 of the encoder 400 of fig. 4.
Process 900 encodes symbol x using at least two probability models n The sequence of (a). The process 900 may use any number of probabilistic models. However, for simplicity, only two (2) models (i.e., a first model and a second model) are used to illustrate the process 900. The process 900 encodes each symbol of the sequence by mixing the probabilities of the first and second models.
At 902, the process 900 initializes a counter i to zero (0), the first subsequence length (i.e., the first length l) 1 ) Is initialized to 0 and the second subsequence length (i.e., second length l) 2 ) First stageThe onset is zero (0). Counter i for sequence x n Each symbol of (a). First length l 1 And a second length l 2 As described above. I.e. the first length l 1 And a second length l 2 May correspond to the lengths of codewords generated by the arithmetic coding engine using the first model and the second model, respectively.
At 904, process 900 calculates a conditional probability p as described above 1 (x i |x i-1 ) And p 2 (x i |x i-1 ). Conditional probability p 1 (x i |x i-1 ) Is in a given subsequence x i-1 (i.e. up to and including no symbol x) i Sub-sequence of (b) the conditional probability of the symbol at position i of the symbol sequence. For p 2 (x i |x i-1 ) The same is true.
At 906, process 900 computes symbol x i Mixed probability of (2)
At 910, the process 900 updates the first length/ 1 And a second length l 2 . As described above, a hypothetical arithmetic encoder may be used at 910. First length l 1 Is updated to be included in the pair symbol x i The additional codeword length (i.e., bits) added to the hypothetical codeword added by the first model when encoding is performed. Second length l 2 Is updated to include in the pair symbol x i Additional codeword lengths (i.e., bits) added to the hypothesized codewords added by the second model when encoding are performed. Process 900 uses l respectively 1 ＝l 1 -log(p 1 (x i |x i-1 ) ) and l 2 ＝l 2 -log(p 2 (x i |x i-1 ) To update the first length l 1 And a second length l 2 . In one embodiment, a value-log (p) may be calculated 1 (x i |x i-1 ) And-log (p) 2 (x i |x i-1 ) And/or approximated by using a look-up table (i.e., looking up in a look-up table). Note that the probability p 1 (x i |x i-1 ) And p 2 (x i |x i-1 ) Is a probability between zero (0) and one (1). Conditional probability p 1 (x i |x i-1 ) And p 2 (x i |x i-1 ) May be represented and/or approximated using a fixed-point representation, such as an 8-bit integer fixed-point representation. Thus, the-log (p) can be estimated by using a look-up table 1 (x i |x i-1 ) And-log (p) 2 (x i |x i-1 ) ) both. 8 bit integer (i.e. representing a probability value p) 1 (x i |x i-1 ) Or p 2 (x i |x i-1 ) May be used as an input (i.e., index) to the lookup table. Typically, the size of the lookup table depends on p 1 (x i |x i-1 ) And p 2 (x i |x i-1 ) The width of the fixed point representation of (a). That is, the larger the width, the estimated-log (p) 1 (x i |x i-1 ) And-log (p) 2 (x i |x i-1 ) The higher the accuracy.
At 912, the counter i is incremented to process the next symbol x i+1 . At 914, if all symbols have been processed (i.e., i ═ n +1), the process terminates. Otherwise, the process returns to 904 to process the next symbol.
Fig. 10 is a flow diagram of a process 1000 for decoding a sequence of symbols according to an embodiment of the present disclosure. Process 1000 may be implemented in a decoder, such as decoder 500. Process 1000 may be implemented by a receiving station. The process 900 may be implemented, for example, as a software program executable by a computing device. The software program may include machine-readable instructions that may be stored in a memory, such as the memory 204 or the secondary storage 214, and executed by a processor, such as the CPU202, to cause a computing device to perform the process 900. Process 900 may be implemented using dedicated hardware or firmware. Some computing devices may have multiple memories, multiple processors, or both. Different processors, memories, or both may be used to distribute the steps or operations of process 1000. Use of the singular form of the terms "processor" or "memory" encompasses a computing device having one processor or one memory as well as a device having multiple processors or multiple memories that may be used to perform some or all of the described steps.
Process 1000 may be used to decode a sequence of symbols from an encoded bitstream. For example, the process 1000 may receive an encoded bitstream, such as the compressed bitstream 420 of fig. 5. The process 1000 may include blocks similar to blocks 902-906 and 910-914 of the process 900. The description of the similar blocks is omitted. Instead of block 908, process 1000 includes block 1002. At 1002, process 1000 uses the calculated mixing conditional probability (i.e.,
In some implementations of processes 900 or 1000, block 906 may be performed every certain number of steps (e.g., S > 1) to further save (e.g., reduce) computational complexity or improve throughput. Throughput may be measured in terms of the number of symbols processed (coded or decoded) in one clock cycle. For example, when the number of steps S is 2, block 906 is only performed when i is odd or even, but not both. In another embodiment of process 900 or 1000, block 906 may be performed at a predefined subset of all possible indices of i.
The use of uniform weighting of the models is described above. However, embodiments in accordance with the present disclosure may use non-uniform a priori weights. In non-uniform weighting using M models, the weight w may be weighted k Is set to a value not equal to 1/M (i.e. w) k ≠1/M)。
For simplicity, the foregoing (e.g., processes 900 and 1000) describe the use of two models: a first model and a second model. However, embodiments in accordance with the present disclosure may be extended to any number of models. For example, for multiple models of M ≧ 2, and assume weighting factor w k Uniform (i.e. w) k 1/M), then the weight w i,k The approximation can be done using equation (14):
in the formula 14, l k (x i-1 ) Represents the codeword length in bits, which is the code of the subsequence x using the model k (1. ltoreq. k. ltoreq.M) i-1 And (6) obtaining the result.
In the description of FIGS. 9-10, and in the case of a codec that uses a binary tree to code transform coefficients or a codec that codes an alphabet of binary symbols, position i (i.e., x) i ) The symbols at (a) refer to symbols in the binary alphabet {0, 1 }. In the case of a codec that uses an alphabet of tokens (i.e., a non-binary alphabet) to code transform coefficients, the symbol at position i (i.e., x) i ) Refers to symbols from non-binary alphabet.
At 910 of FIGS. 9-10, a lookup table may be used to calculate the first length l 1 And a second length l 2 . In the general case, when using k models, the length l can be determined using a look-up table k (x i-1 ). In the case of non-binary alphabet tables, an additional step is required in order to use the look-up table. In the case of a binary alphabet, the probability distribution for the coded symbols 0, 1 may be represented as a single value. This is because, for example, there is a probability p of coding the binary symbol 0, and therefore the probability of coding the binary symbol 1 can be determined as (1-p). Thus, a probability value (or a fixed point representation thereof) may be used as an input for looking up a value in the look-up table.
In the case of a non-binary alphabet, the look-up table may be a multi-dimensional look-up table. For example, given a 12 symbol non-binary alphabet, a lookup in the lookup table requires 11 inputs.
In some implementations, such complex (i.e., multidimensional) lookup tables can be avoided by converting the probability distributions associated with non-binary alphabet symbols to binary distributions. The binary distribution may be represented as a binary tree. The conversion of the probability distribution of the non-binary alphabet into the binary tree may be implicit or explicit. For example, assume that the non-binary alphabet is a ternary alphabet (a, b, c) and that the non-binary probability distribution is given by a triplet (p _ a, p _ b, p _ c), wherein p _ a, p _ b and p _ c are positive real numbers, wherein p _ a + p _ b + p _ c ═ 1, and wherein p _ a, p _ b and p _ c correspond to the probabilities of symbol a, symbol b and symbol c, respectively. In the example of converting the probability distributions (p _ a, p _ b, p _ c) into binary distributions, the symbols b and c can be combined into a single symbol bc. In this way, a first binary distribution (p _ a, p _ b + p _ c) of (a, bc) is obtained. To further determine the symbol b or the symbol c from the combined symbol bc, a second binary distribution (p _ b/(p _ b + p _ c), p _ c/(p _ b + p _ c)) may be obtained. For any distribution defined on a non-binary alphabet, the above transformation can be applied repeatedly (or recursively) to obtain an equivalent sequence of binary distributions.
Any binary tree may be used. Using fig. 7 as an example, assuming that the probability distributions of coded tokens 702 and 704 are known given the context, a binary tree, such as coefficient token tree 700, may be derived such that each internal node of the tree corresponds to a binary decision (i.e., each internal node corresponds to a binary probability distribution).
The derived binary distribution of the internal nodes of the tree may be used as an input to a lookup table to determine the codeword length. For example, to estimate the cost of coding a token of a non-binary alphabet, the tree may be traversed from token up to the root. The probabilities encountered in the traversal (i.e., the probabilities of the interior nodes) may be summed (i.e., added) and the sum may be used as an input to a lookup table.
In some embodiments, the look-up table may be computed off-line and may be used by a codec when encoding and/or decoding. In some embodiments, the lookup table may be computed online. That is, the look-up table may be computed by the codec at the time of coding. In some implementations, the lookup table can be calculated (e.g., updated, recalculated, etc.) periodically. In some embodiments, the look-up table is recalculated if the alphabet size (i.e., the number of symbols in the alphabet) does not exceed a threshold number of symbols. The threshold number of symbols may be 12, 16, or any other threshold number.
Periodically calculating the look-up table may mean: the look-up table is computed at the beginning of a coding unit, super-block, transform block, or some other unit of video frame that estimates the cost of each symbol in the coding alphabet.
In equations 9-13, only the difference in codeword length is used. For example, the difference l is used in equation 10 1 (x i-1 )-l 2 (x i -1 ). Thus, it may not be necessary to maintain (e.g., track) a set of codeword length values, { l } for all models k k }. Thus, in some embodiments of 910 of FIGS. 9-10, storage requirements may be reduced by maintaining only codeword length differences. If K models are used, the differences associated with K-1 models will remain. For example, in the case of using two models k ∈ {1,2}, only l is used for mixing purposes 1 -l 2 (e.g., required). In addition, if the probability has a fixed-point representation, the length difference l can be stored with limited accuracy 1 -l 2 To reduce memory complexity.
In one example, where K (b) is used>2) In the case of two models, two steps can be used to reduce the sum of the codeword length l k The associated storage complexity. The first step is to select the model index j as any model index, which is a fixed number between 1 and K, where K is the number of models to mix (i.e., 1 ≦ j ≦ K). The second step is to calculate and store the length differences l for all but j, 1 ≦ K k -l j 。
In another embodiment, in the first step, j may be selected such that l is equal to or greater than 1 ≦ K ≦ K k ≥l j . That is, only non-negative differences (i.e., l) are stored k -l j Not less than 0). Due to the presence of { l k The index holding the minimum value in (j), which is { l }, can be changed, and thus, the index j can be held and/or updated k The index of the minimum value is kept. By storing only positive length differences, appends for storing sign bits (i.e., associated with negative values) may be saved (i.e., not used)And adding and storing.
FIG. 13 is a flow diagram of a process 1300 for estimating the cost of coding symbols in a non-binary alphabet according to an embodiment of the present disclosure.
At 1302, the process 1300 converts the probability distribution associated with the alphabet (i.e., the probability value associated with each symbol of the non-binary alphabet) into a binary distribution. In one example, a Probability Mass Function (PMF) may be converted to a binary distribution. In another example, a Cumulative Distribution Function (CDF) of the probability distribution may be converted to a binary distribution. As described above, the binary distribution is generated implicitly or explicitly by using the complete binary tree.
At 1304, process 1300 uses the binary distribution to estimate (i.e., look up) the codeword length (or a scaled version thereof) in bits. Block 1304 may be used by process 900 at 906. Block 1304 may be used by process 1000 at 906.
In the case of more than two (2) models being mixed, the conditional probability can be computed (i.e., determined, generated, etc.) using a binary tree. That is, the factor w of equation (8) may be recursively calculated using the above-described procedure i,k p k (x i |x i-1 ). Recursive computation means combining the probabilities of the two (2) models at a time to produce an intermediate conditional probability. The intermediate conditional probabilities are then combined two at a time. When the model number M is a power of 2 (i.e., M is 2) m ) In this case, the factor w of equation (8) may be recursively calculated by applying the above-described procedure on the complete binary tree (e.g., as described with respect to FIG. 11) i,k p k (x i |x i-1 )。
Fig. 11 is a diagram of an example of a binary tree 1100 of conditional probabilities, according to an embodiment of the present disclosure. In binary tree 1100, eight (8) models are mixed. The probabilities of the eight models are p _1 to p _ 8. Every two probabilities are mixed first. For example, as described above, probabilities 1102 and 1104 are blended to produce intermediate conditional probability 1106, which is then combined with intermediate conditional probability 1108 to produce intermediate conditional probability 1110, and so on until final conditional probability 1112 is calculated. The final conditional probabilities 1112 may be used for encoding and/or decoding. For example, the final conditional probabilities 1112 may be used at 908 of process 900 and/or 1002 of process 1000.
For example, the process described with reference to FIG. 11 may be used in situations where certain models are more useful than others. It may not be desirable to employ uniform weighting where certain models are known to be more useful than others. To assign more weight to a model, the model may be replicated in a tree.
Referring to fig. 11 as an example, models p _1, p _2,.., p _6 and p _8 may be different, and p _6 is known to be more useful than other models. Since p _6 is more useful, p _6 can be replicated in the tree: p _7 is a copy of p _ 6. Thus, a model with probability p _6 is assigned twice the weight in the mixture for entropy coding.
As another example, assume, for example, that there are two models, model A and model B, and that the prior weights for these two models are
In the above, a fixed source is described. Fixed source means for symbol x i Mixed usage of subsequence x i-1 To determine w i,k . In this way, the statistical data does not change in the source of the coding process. However, in cases where the source may be non-stationary, embodiments according to the present disclosure may adapt local statistics to obtain better compression performance using a sliding window. The sliding window of length L of a bit indicates the number of previous bits (i.e., the probability of the number of previous bits) used in the mixing process. That is, the sliding window represents the distance in the sequence to be remembered: only the symbols inside the sliding window are used to estimate the weighting factors. More specifically, onlyThe probability of those symbols within the sliding window is used to estimate the weighting factor.
Thus, instead of using
in step 1, initialize i to 1, l 1 ＝0、l 2 0. Step 1 may be as described with respect to 902 of fig. 9. In step 1, the process also initializes l 1,-L 0, and l 2,-L ＝0。
In step 2, the process calculates p from the first model and the second model 1 (x i |x i-L …x i-1 ) And p 2 (x i |x i-L …x i-1 )。
In step 4, the process is carried out by using
In step 5, the process will l 1 Is updated to 1 ＝l 1 -logp 1 (x i |x i-L …x i-1 ) And will l 2 Is updated to 2 ＝l 2 -logp 2 (x i |x i-L …x i-1 ). If the process is encoding/decoding outside the window (i.e., i>L), then the process will update L 1,-L ＝l 1,-L -logp 1 (x i-L |x i-2L …x i-L-1 ) And l 2,-L ＝l 2,-L -logp 2 (x i-L |x i-2L …x i-L-1 )。
In step 6, i is incremented by 1 (i.e., i ═ i + 1).
In step 7, the process repeats steps 2-6 until the sequence x is processed n I.e., i ═ n + 1).
In the above sliding window,/ 1 (x i-1 )-l 1 (x i-L-1 )＝l 1 -l 1,-L And l 2 (x i-1 )-l 2 (x i-L-1 )＝l 2 -l 2,-L . Thus, can be 1 (x i-1 )-l 1 (x i-L-1 ) Considered as a pair x by using the first model i-L …x i-1 The length of the codeword resulting from the coding. Can be mixed with 2 (x i-1 )-l 2 (x i-L-1 ) Considered by using the second model pair x i-L …x i-1 The length of the codeword resulting from the coding.
As described above, in the case of local blending for transform blocks, when a new transform block starts (i.e., when coding of the transform block starts), the codeword length { lk) may be paired for all models k } A reset is made so that all models can be considered equally at the beginning of coding a new (i.e. current) transform block. Thus, when the encoding of the current transform block is completed, the length l k Is reset to zero for the encoding of the next transform block.
In some embodiments, local blending may be applied to other coding units. For example, length l k May be reset at the beginning of the coding unit except for the transform block. For example, a coding unit may be a super block (e.g., a block of size 64 x 64). Thus, length l k May be reset at the beginning of the superblock. Length l k May be reset at the beginning of other sizes of coding units (e.g., 128 x 128).
In the case of the sliding window described above, the memory step size (i.e., length L) is fixed. In the case of local blending, the memory step is adapted to the size of the transform block. For example, the first transform block may be a 4 × 4 transform block, the second transform block may be a 16 × 16, and so on. Thus, the length l is after coding a different number of coefficients depending on the block size and/or the position of the last non-zero coefficient in the quantized transform block k Is reset.
Fig. 12 is a flow diagram of a process 1200 for entropy coding a sequence of symbols, according to an embodiment of the present disclosure. The sequence may be as above for sequence x n The method is as follows. The process 1200 may be implemented by an encoder or a decoder. When implemented by an encoder, "coding" refers to encoding in an encoded bitstream, such as compressed bitstream 420 of fig. 4. When implemented by a decoder, "coding" means decoding from an encoded bitstream, such as the compressed bitstream 420 of fig. 5.
When implemented by an encoder, process 1200 may receive a sequence of symbols from a quantization step, such as quantization 406 of fig. 4. In another example, process 1200 may receive values to be encoded (e.g., quantized transform coefficients) and generate a sequence of symbols from the received values. When implemented by a decoder, the decoder may receive a sequence of symbols in an encoded bitstream, such as compressed bitstream 420 of fig. 4.
At 1202, process 1200 selects a model to mix. The models may include a first model and a second model. As used in this disclosure, "selecting" means identifying, constructing, determining, specifying, or otherwise selecting in whatever manner.
For at least one symbol (e.g., x) i ) At the location of the symbol (e.g., i), the process 1200 executes the block including blocks 1204-1208 using the first model and the second model to determine the mixing probability. Block 1204-1208 may be performed for all symbols in the symbol sequence.
At 1204, the process 1200 determines a first conditional probability for the coded symbol using the first model. The first conditional probability is the conditional probability of a symbol given a subsequence of the sequence. In one example, a subsequence of a sequence may mean a subsequence x i-1 . In another example, where a sliding window is being used, a subsequence of the sequence consists of a predetermined number of symbols of the sequence before the position. The predetermined number of symbols may be as described with respect to the sliding window length L. Thus, a subsequence of a sequence may be subsequence x i-L …x i-1 . At 1206, the process 1200 determines a second conditional probability for coding the symbol using the second model. The second conditional probability is the conditional probability of the symbol given the subsequence, as described with respect to block 1204.
At 1208, process 1200 determines a mixing probability for the coded symbol using the first conditional probability and the second conditional probability. The mixing probability may be as described with respect to 906 of fig. 9. The first conditional probability and the second conditional probability may be combined using a linear combination using the first weight and the second weight. In one embodiment, at least a first weight may be determined (i.e., approximately determined) using hypothetical arithmetic coding to determine a length of a subsequence up to the symbol for the coded sequence. The first weight may be determined using the length. In one example, determining the weight (e.g., the first weight and/or the second weight) may include: a rate resulting from coding a sub-sequence of the sequence up to the symbol is determined and the determined rate is used to determine the first weight. In one example, a velocity estimator may be used to determine the velocity. In one example, the velocity estimator may be a hypothetical arithmetic encoder. In one example, determining the rate may include looking up a table (e.g., a lookup table) using the input as the probability value. That is, the probability values are used as inputs to the lookup table.
At 1210, process 1200 encodes the symbol using the hybrid probability, e.g., as described with respect to 908 (when implemented by an encoder) and 1002 (when implemented by a decoder).
In one embodiment of process 1200, the model may include a third model and a fourth model, and the first model is used to determine the mixed probability, the second model may include mixing the first model and the second model to generate a first intermediate conditional probability, mixing the third model and the fourth model to generate a second intermediate conditional probability, and mixing the first intermediate conditional probability and the second intermediate conditional probability to generate a conditional probability for coding the symbol. In one embodiment, the first model and the fourth model are the same model.
Fig. 14 is a flow diagram of a process 1400 for entropy coding a quantized transform block, according to an embodiment of the invention. Process 1400 encodes tokens indicating the quantized transform coefficients of the quantized transform block. As described above, a token may be selected from a non-binary alphabet of tokens. Process 1400 codes the transform coefficients as described above with respect to the local blending of transform blocks. In one embodiment, process 1400 may be repeated for tokens corresponding to quantized transform blocks up to an end-of-block token.
Process 1400 may be implemented by an encoder or a decoder. When implemented by an encoder, "coding" refers to encoding in an encoded bitstream, such as compressed bitstream 420 of fig. 4. When implemented by a decoder, "coding" means decoding from an encoded bitstream, such as the compressed bitstream 420 of fig. 5.
When implemented by an encoder, process 1400 may receive quantized transform blocks from a quantization step, such as quantization 406 of fig. 4. As shown in fig. 4, and may be implemented in part or in whole by entropy coding steps such as entropy coding 408. When implemented by a decoder, the decoder may receive quantized transform blocks in an encoded bitstream, such as compressed bitstream 420 of fig. 5, which may be implemented in part or in whole by an entropy decoding step, such as entropy decoding 502.
At 1402, process 1400 selects a probability distribution for coding tokens indicative of quantized transform coefficients of a quantized transform block. Two or more probability distributions may be selected. In one example, the probability distribution includes a first probability distribution and a second probability distribution. Each probability distribution provides a probability value (e.g., a first probability value and a second probability value) corresponding to a token of the alphabet. For example, if the non-binary alphabet comprises N (e.g., 16) symbols, the probability distribution may comprise N probability values.
At 1404, process 1400 determines a mixed probability for the coded token using the first probability distribution and the second probability distribution. The mixing probability may be determined as described above with respect to fig. 9-10. Determining the mixing probability may include: determining a first conditional probability for coding the token using the first probability distribution; determining a second conditional probability for coding the token using the second probability distribution; and determining a mixing probability using the first conditional probability and the second conditional probability. The first conditional probability may be a conditional probability of the token given a previously coded token of a quantized coded block. The second conditional probability may be the conditional probability of the token given a previously coded token of the quantized coded block.
In one embodiment, determining the mixed probability may further include combining the first conditional probability and the second conditional probability with a linear combination using the first weight and the second weight. The first weight may be based on a first length of a first codeword used to code a token corresponding to a previously coded token using a first conditional probability. The second weight may be based on a second length of a second codeword used to code tokens corresponding to previously coded tokens using a second conditional probability.
In one embodiment, the first weight and the second weight may be determined by: the method further includes converting the first probability distribution to a first binary distribution, converting the second probability distribution to a second binary distribution, determining the first length using the first binary distribution, and determining the second length using the second binary distribution.
In one embodiment, the first probability distribution may be an initial probability distribution for coding quantized transform coefficients of a quantized transform block. That is, the first probability distribution may be a probability distribution selected based on a context used to code the quantized transform coefficients. In one embodiment, the initial probabilities may be decoded from the encoded bitstream when implemented by a decoder.
The second probability distribution may be based on statistics of the coding units. In this way, the second probability distribution may be modified (e.g., updated) as the quantized coefficients are coded to reflect the actual statistics of the coded unit. The coding unit may be a quantized transform block. The coding unit may be a super block including a quantized transform block.
At 1406, process 1400 encodes the token using the mixed probabilities.
For simplicity of explanation, processes 900, 1000, 1200, 1300, and 1400 are respectively depicted and described as a series of blocks, steps, or operations. However, blocks, steps or operations in accordance with the present disclosure may occur in various orders and/or concurrently. In addition, other steps or operations not shown and described herein may be used. Moreover, not all illustrated steps or operations may be required to implement a technique in accordance with the disclosed subject matter.
A technique known as Context Tree Weighting (CTW) is one that uses a hybrid lossless data compression algorithm. For a binary sequence x of length n n Coding is carried out, and the CTW converts the probability function p (x) n ) Estimated to be 2 K Individual probability function p i (x n ) Each probability function is estimated by assuming a finite memory binary tree source and has the same weighting factor. Rather, embodiments according to the present disclosure may work with any model. Furthermore, the symbol-by-symbol weighting factor calculation described herein may approximate the probability of a subsequence using a length function, which is greatly simplified compared to existing solutions that maintain and calculate joint probabilities.
The above described aspects of encoding and decoding illustrate some encoding and decoding techniques. However, it should be understood that encoding and decoding, as those terms are used in the claims, may refer to compression, decompression, transformation, or any other processing or alteration of data.
The word "example" or "embodiment" is used herein to mean serving as an example, instance, or illustration. Any aspect or design described herein as "example" or "embodiment" is not necessarily to be construed as preferred or advantageous over other aspects or designs. Rather, use of the word "example" or "embodiment" is intended to present concepts in a concrete fashion. As used in this application, the term "or" is intended to mean an inclusive "or" rather than an exclusive "or". That is, unless specified otherwise, or clear from context, "X includes a or B" is intended to mean any of the natural inclusive permutations. That is, if X comprises A; x includes B; or X includes A and B, then "X includes A or B" is satisfied under any of the foregoing circumstances. In addition, the articles "a" and "an" as used in this application and the appended claims should generally be construed to mean "one or more" unless specified otherwise or clear from context to be directed to a singular form. Furthermore, throughout this disclosure, the use of the term "embodiment" or "one embodiment" throughout this disclosure is not intended to refer to the same embodiment or embodiment, unless so described.
Embodiments of transmitting station 102 and/or receiving station 106 (as well as algorithms, methods, instructions, etc. stored thereon and/or executed thereby, including by encoder 400 and decoder 500) may be implemented in hardware, software, or any combination thereof. The hardware may include, for example, a computer, an Intellectual Property (IP) core, an Application Specific Integrated Circuit (ASIC), a programmable logic array, an optical processor, a programmable logic controller, microcode, a microcontroller, a server, a microprocessor, a digital signal processor, or any other suitable circuit. In the claims, the term "processor" should be understood to include any of the foregoing hardware, alone or in combination. The terms "signal" and "data" are used interchangeably. Furthermore, portions of transmitting station 102 and receiving station 106 need not necessarily be implemented in the same manner.
Further, in an aspect, for example, transmitting station 102 or receiving station 106 may be implemented using a general purpose computer or a general purpose processor having a computer program that, when executed, performs any of the respective methods, algorithms, and/or instructions described herein. Additionally or alternatively, for example, a special purpose computer/processor may be utilized which may contain other hardware for performing any of the methods, algorithms, or instructions described herein.
Transmitter station 102 and receiver station 106 may be implemented on computers in a video conferencing system, for example. Alternatively, transmitting station 102 may be implemented on a server, and receiving station 106 may be implemented on a device separate from the server (e.g., a handheld communication device). In this case, transmitting station 102 may use encoder 400 to encode the content into an encoded video signal and transmit the encoded video signal to a communication device. In turn, the communication device may then decode the encoded video signal using the decoder 500. Alternatively, the communication device may decode content stored locally on the communication device, e.g., content not transmitted by transmitting station 102. Other transmitter station 102 and receiving station 106 implementations are available. For example, the receiving station 106 may be a substantially stationary personal computer rather than a portable communication device, and/or a device including the encoder 400 may also include the decoder 500.
Furthermore, all or portions of embodiments of the present disclosure may take the form of a computer program product accessible from, for example, a tangible computer-usable or computer-readable medium. A computer-usable or computer-readable medium may be, for example, any device that can tangibly contain, store, communicate, or transport the program for use by or in connection with any processor. The medium may be, for example, an electronic, magnetic, optical, electromagnetic, or semiconductor device. Other suitable media are also available.
The above-described embodiments, implementations, and aspects have been described to allow easy understanding of the present disclosure and do not limit the present disclosure. On the contrary, the disclosure is intended to cover various modifications and equivalent arrangements included within the scope of the appended claims, which scope is to be accorded the broadest interpretation so as to encompass all such modifications and equivalent structures as is permitted under the law.
Claims (18)
1. A method for entropy coding a sequence of symbols, comprising:
selecting a probabilistic model comprising a first probabilistic model and a second probabilistic model, the second probabilistic model being different from the first probabilistic model;
for each symbol of the sequence of symbols, determining a respective mixed probability of a subsequence of the sequence up to the symbol at position i of the sequence using the first and second probability models
Determining a first conditional probability p for coding the symbol at a location i using the first probability model 1 (x i |x i -1 ) The first conditional probability being that a previous symbol in the subsequence of the given sequence has a corresponding value x j Has a certain value x for the symbol at position i i Is determined by a conditional probability of, wherein j<i-1；
Determining a second conditional probability p for coding the symbol at location i using the second probability model 2 (x i |x i -1 ) Said second conditional probability being that said previous symbol in said subsequence of said given sequence has said corresponding value x j Has a certain value x for the symbol at position i i Is determined by a conditional probability of, wherein j<i-1; and
by using a first non-zero weight w according to 1,i And a second non-zero weight w 2,i To combine the first conditional probability and the second conditional probability to determine a code for coding the code location i using the first conditional probability and the second conditional probabilityThe respective mixed probabilities of the symbols:
each symbol is coded using the corresponding mixing probability.
2. The method of claim 1, wherein determining the mixing probability for coding the symbol at position i using the first conditional probability and the second conditional probability further comprises:
determining the first non-zero weight by:
determining a length of a first codeword using hypothetical arithmetic coding for coding a subsequence of the sequence up to but not including the symbol at position i using the first probability model;
determining a length of a second codeword using the hypothetical arithmetic coding for coding the subsequence of the sequence up to but not including the symbol at position i using the second probability model; and
determining the first non-zero weight using the length.
3. The method of claim 1, further comprising:
determining a rate resulting from coding a subsequence of the sequence up to but not including the symbol at position i using the first probability model; and
determining the first non-zero weight using the determined rate.
4. The method of claim 3, wherein determining the velocity comprises using a velocity estimator.
5. The method of claim 3, wherein determining the rate comprises:
the rate is looked up in a look-up table using the probability value as an input.
6. The method of claim 1, wherein:
determining the first conditional probability using the first probability model comprises mixing the first probability model and a third probability model to generate the first conditional probability; and
determining the second conditional probability using the second probability model includes mixing the second probability model and a fourth probability model to generate the second conditional probability.
7. The method of claim 6, wherein the first and fourth probabilistic models are a same probabilistic model.
8. The method of any of claims 1 to 7, wherein the sub-sequence of the sequence comprises all symbols of the sequence up to the position i.
9. The method according to any of claims 1 to 7, wherein the sub-sequence of the sequence consists of a predetermined number of symbols of the sequence preceding the position i.
10. A device for entropy coding a quantized transform block, the device comprising:
a memory; and
a processor, wherein the memory includes instructions executable by the processor to:
for each quantized transform coefficient in a scan order of the quantized transform block, selecting a probability model comprising a first probability model and a second probability model for coding a token, the token indicating the quantized transform coefficient, the second probability model being different from the first probability model, wherein i represents a position of a transform coefficient in the scan order of the quantized transform block, wherein,
the token is selected from an alphabet of tokens,
the first probability model comprises first probability values of tokens of the token alphabet, and
the second probability model comprises second probability values for the tokens of the token alphabet;
determining, using the first and second probability models, a mixture probability for coding the tokens by the probability of a token of the quantized transform block at position i in the scan order
Determining a first conditional probability p for coding the token using the first probability model 1 (x i |x i-1 ) The first conditional probability p 1 (x i |x i-1 ) Is that the previous transform coefficient at position j in the given scan order has a corresponding token value x j Wherein j is<i, the token has a certain value x i The conditional probability of (a); and
determining a second conditional probability p for coding the token using the second probability model 2 (x i |x i-1 ) Said second conditional probability p 2 (x i |x i-1 ) Is that the previous transform coefficient at position j in the scan order has a corresponding token value x j Wherein j is<i, the token has a certain value x i The conditional probability of (a); and
by using a first non-zero weight w according to 1,i And a second non-zero weight w 2,i To combine the first conditional probability and the second conditional probability to determine a respective mixed probability for coding the token using the first conditional probability and the second conditional probability
the token is coded using the respective mixed probabilities.
11. The apparatus of claim 10, wherein determining the mixing probability using the first conditional probability and the second conditional probability comprises performing the operations of:
combining the first conditional probability and the second conditional probability with the linear combination using the first non-zero weight and the second non-zero weight, wherein:
the first non-zero weight is based on a first length of a first codeword used to code tokens corresponding to the previous transform coefficients using the first conditional probability, and
the second non-zero weight is based on a second length of a second codeword used to code tokens corresponding to the previous transform coefficients using the second conditional probability.
12. The apparatus of claim 11, wherein the instructions further comprise instructions to:
determining the first length and the second length by:
converting the first probability model into a first distribution represented as a first binary tree;
converting the second probability model to a second distribution represented as a second binary tree;
determining the first length using the first distribution; and
determining the second length using the second distribution.
13. The apparatus of claim 10, wherein,
the first probability model is selected based on context for coding the quantized transform coefficients of the quantized transform block, and
the second probabilistic model is based on statistics of the coding units.
14. The apparatus of claim 13, wherein the coding unit is the quantized transform block or a super block comprising the quantized transform block.
15. An apparatus for entropy decoding a sequence of symbols, the apparatus comprising:
a memory; and
a processor, wherein the memory includes instructions executable by the processor to:
selecting a probabilistic model comprising a first probabilistic model and a second probabilistic model, the second probabilistic model being different from the first probabilistic model;
for each symbol in the sequence of symbols, determining a respective mixing probability using the first probability model and the second probability model by the mixing probability of a symbol at position i of the sequence being the probability of a subsequence of the sequence up to but not including the symbol at position i
Determining a first conditional probability p for coding the symbol at a location i using the first probability model 1 (x i |x i -1 ) The first conditional probability being that a previous symbol in a subsequence of the given sequence has a corresponding value x j Has a certain value x for the symbol at position i i Is determined, wherein j<i-1；
Determining a second probability model for coding the symbol at position i using the second probability modelTwo conditional probability p 2 (x i |x i -1 ) Said second conditional probability being that said previous symbol in said subsequence of said given sequence has said corresponding value x j Has a certain value x for the symbol at position i i Is determined by a conditional probability of, wherein j<i-1; and
by using a first non-zero weight w according to 1,i And a second non-zero weight w 2,i To determine the mixing probability for coding the symbol at position i using the first conditional probability and the second conditional probability:
decoding the symbol from the compressed bitstream using the mixing probability.
16. The apparatus of claim 15, wherein determining the mixing probability comprises:
combining the first conditional probability and the second conditional probability with the linear combination using the first non-zero weight and the second non-zero weight, wherein:
the first non-zero weight and a first length l of a codeword resulting from using the first probability model to decode the subsequence 1 Corresponding; and
the second non-zero weight and a second length l of the codeword resulting from using the second probability model to decode the subsequence 2 And correspondingly.
17. The apparatus of claim 16, wherein the first non-zero weight and the second non-zero weight are determined using a lookup table.
18. An apparatus, comprising:
a processor; and
a memory comprising instructions executable by the processor to implement the apparatus of any one of claims 10 to 17.
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
CN202210979148.9A CN115514978B (en) | 2017-08-29 | 2018-05-01 | Method and apparatus for mixing probabilities of entropy coding in video compression |
Applications Claiming Priority (5)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201762551341P | 2017-08-29 | 2017-08-29 | |
US62/551,341 | 2017-08-29 | ||
US15/824,058 | 2017-11-28 | ||
US15/824,058 US10448019B2 (en) | 2017-08-29 | 2017-11-28 | Using multiple probability models for entropy coding in video compression |
PCT/US2018/030355 WO2019045797A1 (en) | 2017-08-29 | 2018-05-01 | Mixing of probabilities for entropy coding in video compression |
Related Child Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202210979148.9A Division CN115514978B (en) | 2017-08-29 | 2018-05-01 | Method and apparatus for mixing probabilities of entropy coding in video compression |
Publications (2)
Publication Number | Publication Date |
---|---|
CN110692243A CN110692243A (en) | 2020-01-14 |
CN110692243B true CN110692243B (en) | 2022-08-23 |
Family
ID=65436426
Family Applications (3)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202210979148.9A Active CN115514978B (en) | 2017-08-29 | 2018-05-01 | Method and apparatus for mixing probabilities of entropy coding in video compression |
CN201880035871.3A Active CN110692243B (en) | 2017-08-29 | 2018-05-01 | Mixing of probabilities for entropy coding in video compression |
CN201880039455.0A Active CN110771171B (en) | 2017-08-29 | 2018-05-01 | Selective blending of probability distributions for entropy coding in video compression |
Family Applications Before (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202210979148.9A Active CN115514978B (en) | 2017-08-29 | 2018-05-01 | Method and apparatus for mixing probabilities of entropy coding in video compression |
Family Applications After (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201880039455.0A Active CN110771171B (en) | 2017-08-29 | 2018-05-01 | Selective blending of probability distributions for entropy coding in video compression |
Country Status (6)
Country | Link |
---|---|
US (5) | US10735736B2 (en) |
EP (2) | EP3677027B1 (en) |
JP (1) | JP6923677B2 (en) |
KR (1) | KR102314801B1 (en) |
CN (3) | CN115514978B (en) |
WO (2) | WO2019045798A1 (en) |
Families Citing this family (11)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10735736B2 (en) * | 2017-08-29 | 2020-08-04 | Google Llc | Selective mixing for entropy coding in video compression |
WO2019074744A1 (en) * | 2017-10-09 | 2019-04-18 | Fovia Inc. | Bit prediction method and system using a statistical model |
CN109788290A (en) * | 2017-11-13 | 2019-05-21 | 慧荣科技股份有限公司 | Image processor and the lossless image compressing method for utilizing intra prediction |
WO2019140083A1 (en) * | 2018-01-12 | 2019-07-18 | Futurewei Technologies, Inc. | Adaptive multi-hypothesis context-adaptive binary arithmetic coding (mcabac) |
US20230042018A1 (en) * | 2020-02-12 | 2023-02-09 | Google Llc | Multi-context entropy coding for compression of graphs |
EP4173292A4 (en) * | 2020-06-25 | 2024-03-27 | Ericsson Telefon Ab L M | Method and system for image compressing and coding with deep learning |
US11681508B2 (en) * | 2020-08-24 | 2023-06-20 | Cisco Technology, Inc. | Source code analysis to map analysis perspectives to events |
CN116982317A (en) * | 2021-03-17 | 2023-10-31 | Oppo广东移动通信有限公司 | Encoding and decoding method for coefficient, encoder, decoder and computer storage medium |
CN114039718B (en) * | 2021-10-18 | 2023-12-19 | 湖南遥昇通信技术有限公司 | Hash coding method and system of self-adaptive weighted probability model |
US11669281B1 (en) | 2021-11-19 | 2023-06-06 | Meta Platforms, Inc. | Count circuit for symbol statistics |
WO2023131250A1 (en) * | 2022-01-08 | 2023-07-13 | Beijing Bytedance Network Technology Co., Ltd. | Method, apparatus, and medium for video processing |
Citations (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN101282121A (en) * | 2007-04-05 | 2008-10-08 | 安凯（广州）软件技术有限公司 | Method for decoding Haffmann based on conditional probability |
CN102176750A (en) * | 2011-03-10 | 2011-09-07 | 西安电子科技大学 | High-performance adaptive binary arithmetic encoder |
CN102186087A (en) * | 2011-06-24 | 2011-09-14 | 哈尔滨工业大学 | Parallel non-zero coefficient context modeling method for binary arithmetic coding |
EP2945383A1 (en) * | 2014-05-14 | 2015-11-18 | BlackBerry Limited | Adaptive context initialization |
Family Cites Families (43)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5357250A (en) * | 1992-11-20 | 1994-10-18 | International Business Machines Corporation | Adaptive computation of symbol probabilities in n-ary strings |
JP2840589B2 (en) * | 1996-02-09 | 1998-12-24 | 富士通株式会社 | Data compression device and data decompression device |
JP2004505520A (en) * | 2000-07-25 | 2004-02-19 | コーニンクレッカ フィリップス エレクトロニクス エヌ ヴィ | Video coding method using wavelet decomposition |
US7599435B2 (en) * | 2004-01-30 | 2009-10-06 | Fraunhofer-Gesellschaft Zur Foerderung Der Angewandten Forschung E.V. | Video frame encoding and decoding |
US7397973B2 (en) * | 2004-02-27 | 2008-07-08 | Mediatek Inc. | Method for controlling interpolation direction and related device |
US20070071090A1 (en) * | 2005-06-21 | 2007-03-29 | National Chiao Tung University | Method for performing context adaptive binary arithmetic coding with stochastic bit reshuffling for fine granularity scalability |
US7599840B2 (en) | 2005-07-15 | 2009-10-06 | Microsoft Corporation | Selectively using multiple entropy models in adaptive coding and decoding |
GB0600141D0 (en) * | 2006-01-05 | 2006-02-15 | British Broadcasting Corp | Scalable coding of video signals |
KR100834757B1 (en) * | 2006-03-28 | 2008-06-05 | 삼성전자주식회사 | Method for enhancing entropy coding efficiency, video encoder and video decoder thereof |
US20070233477A1 (en) | 2006-03-30 | 2007-10-04 | Infima Ltd. | Lossless Data Compression Using Adaptive Context Modeling |
US8184712B2 (en) * | 2006-04-30 | 2012-05-22 | Hewlett-Packard Development Company, L.P. | Robust and efficient compression/decompression providing for adjustable division of computational complexity between encoding/compression and decoding/decompression |
US7233269B1 (en) * | 2006-06-30 | 2007-06-19 | International Business Machines Corporation | Method and apparatus for constructing efficient codes for Wyner-Ziv video compression systems |
KR100809301B1 (en) * | 2006-07-20 | 2008-03-04 | 삼성전자주식회사 | Method and apparatus for entropy encoding/decoding |
CN102752597A (en) * | 2006-08-28 | 2012-10-24 | 汤姆森许可贸易公司 | Method and apparatus for determining expected distortion in decoded video blocks |
US7783123B2 (en) * | 2006-09-25 | 2010-08-24 | Hewlett-Packard Development Company, L.P. | Method and system for denoising a noisy signal generated by an impulse channel |
JP2008242034A (en) * | 2007-03-27 | 2008-10-09 | Japan Aerospace Exploration Agency | Device and method for integrated encoding and decoding for performing data compression/expansion, encoding/decoding, and error control |
US8798137B2 (en) * | 2008-02-29 | 2014-08-05 | City University Of Hong Kong | Bit rate estimation in data or video compression |
US20110002554A1 (en) * | 2009-06-11 | 2011-01-06 | Motorola, Inc. | Digital image compression by residual decimation |
KR20190000920A (en) * | 2009-07-02 | 2019-01-03 | 톰슨 라이센싱 | Methods and apparatus for video encoding and decoding binary sets using adaptive tree selection |
US8699565B2 (en) * | 2009-08-27 | 2014-04-15 | Hewlett-Packard Development Company, L.P. | Method and system for mixed-resolution low-complexity information coding and a corresponding method and system for decoding coded information |
CN102598661B (en) * | 2009-11-02 | 2015-04-15 | 松下电器（美国）知识产权公司 | Image encoding method, image decoding method, image encoding device and image decoding device |
EP2362657B1 (en) * | 2010-02-18 | 2013-04-24 | Research In Motion Limited | Parallel entropy coding and decoding methods and devices |
US8487791B2 (en) | 2010-02-18 | 2013-07-16 | Research In Motion Limited | Parallel entropy coding and decoding methods and devices |
PL2559166T3 (en) * | 2010-04-13 | 2018-04-30 | Fraunhofer-Gesellschaft zur Förderung der angewandten Forschung e.V. | Probability interval partioning encoder and decoder |
US20110280314A1 (en) * | 2010-05-12 | 2011-11-17 | Texas Instruments Incorporated | Slice encoding and decoding processors, circuits, devices, systems and processes |
KR101682207B1 (en) * | 2010-08-23 | 2016-12-12 | 에스케이플래닛 주식회사 | Apparatus and method for decoding using joint tokenization and translation |
CA2822929C (en) | 2011-01-04 | 2016-07-12 | Research In Motion Limited | Coding of residual data in predictive compression |
US9164983B2 (en) * | 2011-05-27 | 2015-10-20 | Robert Bosch Gmbh | Broad-coverage normalization system for social media language |
GB2492394B (en) * | 2011-06-30 | 2014-11-05 | Canon Kk | Method of entropy encoding and decoding an image, and corresponding devices |
US10390046B2 (en) * | 2011-11-07 | 2019-08-20 | Qualcomm Incorporated | Coding significant coefficient information in transform skip mode |
US9088796B2 (en) * | 2011-11-07 | 2015-07-21 | Sharp Kabushiki Kaisha | Video decoder with enhanced CABAC decoding |
US20130121410A1 (en) * | 2011-11-14 | 2013-05-16 | Mediatek Inc. | Method and Apparatus of Video Encoding with Partitioned Bitstream |
US10085024B2 (en) * | 2012-04-13 | 2018-09-25 | Qualcomm Incorporated | Lookup table for rate distortion optimized quantization |
US9351003B2 (en) * | 2013-09-27 | 2016-05-24 | Apple Inc. | Context re-mapping in CABAC encoder |
US9179151B2 (en) * | 2013-10-18 | 2015-11-03 | Google Inc. | Spatial proximity context entropy coding |
JP6312312B2 (en) * | 2014-04-15 | 2018-04-18 | 日本放送協会 | Context model generation device, encoding device, and decoding device |
US9641854B2 (en) * | 2014-05-19 | 2017-05-02 | Mediatek Inc. | Count table maintenance apparatus for maintaining count table during processing of frame and related count table maintenance method |
WO2015184067A1 (en) * | 2014-05-28 | 2015-12-03 | Arris Enterprises, Inc. | Content aware scheduling in a hevc decoder operating on a multi-core processor platform |
US9918105B2 (en) * | 2014-10-07 | 2018-03-13 | Qualcomm Incorporated | Intra BC and inter unification |
US10142635B2 (en) * | 2015-12-18 | 2018-11-27 | Blackberry Limited | Adaptive binarizer selection for image and video coding |
US20170180757A1 (en) | 2015-12-18 | 2017-06-22 | Blackberry Limited | Binarizer selection for image and video coding |
CN106713935B (en) * | 2017-01-09 | 2019-06-11 | 杭州电子科技大学 | A kind of HEVC block division fast method based on Bayesian decision |
US10735736B2 (en) * | 2017-08-29 | 2020-08-04 | Google Llc | Selective mixing for entropy coding in video compression |
-
2017
- 2017-09-18 US US15/707,278 patent/US10735736B2/en active Active
- 2017-11-28 US US15/824,058 patent/US10448019B2/en active Active
-
2018
- 2018-05-01 EP EP18724765.5A patent/EP3677027B1/en active Active
- 2018-05-01 JP JP2019565808A patent/JP6923677B2/en active Active
- 2018-05-01 EP EP18725727.4A patent/EP3677035A1/en active Pending
- 2018-05-01 CN CN202210979148.9A patent/CN115514978B/en active Active
- 2018-05-01 KR KR1020197035900A patent/KR102314801B1/en active IP Right Grant
- 2018-05-01 CN CN201880035871.3A patent/CN110692243B/en active Active
- 2018-05-01 WO PCT/US2018/030357 patent/WO2019045798A1/en unknown
- 2018-05-01 CN CN201880039455.0A patent/CN110771171B/en active Active
- 2018-05-01 WO PCT/US2018/030355 patent/WO2019045797A1/en unknown
-
2019
- 2019-09-06 US US16/562,659 patent/US10645389B2/en active Active
-
2020
- 2020-03-31 US US16/835,379 patent/US10887595B2/en active Active
- 2020-12-29 US US17/136,200 patent/US11405618B2/en active Active
Patent Citations (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN101282121A (en) * | 2007-04-05 | 2008-10-08 | 安凯（广州）软件技术有限公司 | Method for decoding Haffmann based on conditional probability |
CN102176750A (en) * | 2011-03-10 | 2011-09-07 | 西安电子科技大学 | High-performance adaptive binary arithmetic encoder |
CN102186087A (en) * | 2011-06-24 | 2011-09-14 | 哈尔滨工业大学 | Parallel non-zero coefficient context modeling method for binary arithmetic coding |
EP2945383A1 (en) * | 2014-05-14 | 2015-11-18 | BlackBerry Limited | Adaptive context initialization |
Also Published As
Publication number | Publication date |
---|---|
US20210120249A1 (en) | 2021-04-22 |
US10887595B2 (en) | 2021-01-05 |
US20190068994A1 (en) | 2019-02-28 |
WO2019045797A1 (en) | 2019-03-07 |
KR102314801B1 (en) | 2021-10-18 |
US20200228804A1 (en) | 2020-07-16 |
CN110771171A (en) | 2020-02-07 |
CN110771171B (en) | 2022-09-06 |
WO2019045798A1 (en) | 2019-03-07 |
CN115514978B (en) | 2024-03-26 |
US10645389B2 (en) | 2020-05-05 |
US10448019B2 (en) | 2019-10-15 |
JP2020522182A (en) | 2020-07-27 |
EP3677027A1 (en) | 2020-07-08 |
JP6923677B2 (en) | 2021-08-25 |
CN110692243A (en) | 2020-01-14 |
US10735736B2 (en) | 2020-08-04 |
CN115514978A (en) | 2022-12-23 |
US11405618B2 (en) | 2022-08-02 |
EP3677035A1 (en) | 2020-07-08 |
US20190068970A1 (en) | 2019-02-28 |
EP3677027B1 (en) | 2023-11-08 |
KR20200003888A (en) | 2020-01-10 |
US20190394467A1 (en) | 2019-12-26 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN110692243B (en) | Mixing of probabilities for entropy coding in video compression | |
CN115604472B (en) | Method and apparatus for coding blocks of video data | |
CN110710217B (en) | Method and apparatus for coding last significant coefficient flag | |
CN110710208B (en) | Embedding information about EOB location | |
US20230007260A1 (en) | Probability Estimation for Video Coding |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
GR01 | Patent grant | ||
GR01 | Patent grant |