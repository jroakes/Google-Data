CN115380506A - Privacy-preserving activity aggregation mechanism - Google Patents
Privacy-preserving activity aggregation mechanism Download PDFInfo
- Publication number
- CN115380506A CN115380506A CN202180019433.XA CN202180019433A CN115380506A CN 115380506 A CN115380506 A CN 115380506A CN 202180019433 A CN202180019433 A CN 202180019433A CN 115380506 A CN115380506 A CN 115380506A
- Authority
- CN
- China
- Prior art keywords
- randomized group
- domain
- application
- randomized
- group
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/60—Protecting data
- G06F21/62—Protecting access to data via a platform, e.g. using keys or access control rules
- G06F21/6218—Protecting access to data via a platform, e.g. using keys or access control rules to a system of files or objects, e.g. local or distributed file system or database
- G06F21/6245—Protecting personal data, e.g. for financial or medical purposes
- G06F21/6263—Protecting personal data, e.g. for financial or medical purposes during internet communication, e.g. revealing personal data from cookies
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/30—Authentication, i.e. establishing the identity or authorisation of security principals
- G06F21/31—User authentication
- G06F21/33—User authentication using certificates
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/60—Protecting data
- G06F21/64—Protecting data integrity, e.g. using checksums, certificates or signatures
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L63/00—Network architectures or network communication protocols for network security
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L63/00—Network architectures or network communication protocols for network security
- H04L63/04—Network architectures or network communication protocols for network security for providing a confidential data exchange among entities communicating through data packet networks
- H04L63/0407—Network architectures or network communication protocols for network security for providing a confidential data exchange among entities communicating through data packet networks wherein the identity of one or more communicating identities is hidden
- H04L63/0421—Anonymous communication, i.e. the party's identifiers are hidden from the other party or parties, e.g. using an anonymizer
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L63/00—Network architectures or network communication protocols for network security
- H04L63/06—Network architectures or network communication protocols for network security for supporting key management in a packet data network
- H04L63/062—Network architectures or network communication protocols for network security for supporting key management in a packet data network for key distribution, e.g. centrally by trusted party
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L63/00—Network architectures or network communication protocols for network security
- H04L63/08—Network architectures or network communication protocols for network security for authentication of entities
- H04L63/0823—Network architectures or network communication protocols for network security for authentication of entities using certificates
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L63/00—Network architectures or network communication protocols for network security
- H04L63/14—Network architectures or network communication protocols for network security for detecting or protecting against malicious traffic
- H04L63/1408—Network architectures or network communication protocols for network security for detecting or protecting against malicious traffic by monitoring network traffic
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L67/00—Network arrangements or protocols for supporting network services or applications
- H04L67/50—Network services
- H04L67/535—Tracking the activity of the user
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L9/00—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols
- H04L9/08—Key distribution or management, e.g. generation, sharing or updating, of cryptographic keys or passwords
- H04L9/0816—Key establishment, i.e. cryptographic processes or cryptographic protocols whereby a shared secret becomes available to two or more parties, for subsequent use
- H04L9/0819—Key transport or distribution, i.e. key establishment techniques where one party creates or otherwise obtains a secret value, and securely transfers it to the other(s)
- H04L9/083—Key transport or distribution, i.e. key establishment techniques where one party creates or otherwise obtains a secret value, and securely transfers it to the other(s) involving central third party, e.g. key distribution center [KDC] or trusted third party [TTP]
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L9/00—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols
- H04L9/32—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols including means for verifying the identity or authority of a user of the system or for message authentication, e.g. authorization, entity authentication, data integrity or data verification, non-repudiation, key authentication or verification of credentials
- H04L9/3247—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols including means for verifying the identity or authority of a user of the system or for message authentication, e.g. authorization, entity authentication, data integrity or data verification, non-repudiation, key authentication or verification of credentials involving digital signatures
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L9/00—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols
- H04L9/32—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols including means for verifying the identity or authority of a user of the system or for message authentication, e.g. authorization, entity authentication, data integrity or data verification, non-repudiation, key authentication or verification of credentials
- H04L9/3263—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols including means for verifying the identity or authority of a user of the system or for message authentication, e.g. authorization, entity authentication, data integrity or data verification, non-repudiation, key authentication or verification of credentials involving certificates, e.g. public key certificate [PKC] or attribute certificate [AC]; Public key infrastructure [PKI] arrangements
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L9/00—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols
- H04L9/32—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols including means for verifying the identity or authority of a user of the system or for message authentication, e.g. authorization, entity authentication, data integrity or data verification, non-repudiation, key authentication or verification of credentials
- H04L9/3263—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols including means for verifying the identity or authority of a user of the system or for message authentication, e.g. authorization, entity authentication, data integrity or data verification, non-repudiation, key authentication or verification of credentials involving certificates, e.g. public key certificate [PKC] or attribute certificate [AC]; Public key infrastructure [PKI] arrangements
- H04L9/3268—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols including means for verifying the identity or authority of a user of the system or for message authentication, e.g. authorization, entity authentication, data integrity or data verification, non-repudiation, key authentication or verification of credentials involving certificates, e.g. public key certificate [PKC] or attribute certificate [AC]; Public key infrastructure [PKI] arrangements using certificate validation, registration, distribution or revocation, e.g. certificate revocation list [CRL]
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L9/00—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols
- H04L9/32—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols including means for verifying the identity or authority of a user of the system or for message authentication, e.g. authorization, entity authentication, data integrity or data verification, non-repudiation, key authentication or verification of credentials
- H04L9/3271—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols including means for verifying the identity or authority of a user of the system or for message authentication, e.g. authorization, entity authentication, data integrity or data verification, non-repudiation, key authentication or verification of credentials using challenge-response
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L9/00—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols
- H04L9/32—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols including means for verifying the identity or authority of a user of the system or for message authentication, e.g. authorization, entity authentication, data integrity or data verification, non-repudiation, key authentication or verification of credentials
- H04L9/3297—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols including means for verifying the identity or authority of a user of the system or for message authentication, e.g. authorization, entity authentication, data integrity or data verification, non-repudiation, key authentication or verification of credentials involving time stamps, e.g. generation of time stamps
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L2209/00—Additional information or applications relating to cryptographic mechanisms or cryptographic arrangements for secret or secure communication H04L9/00
- H04L2209/42—Anonymization, e.g. involving pseudonyms
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L2463/00—Additional details relating to network architectures or network communication protocols for network security covered by H04L63/00
- H04L2463/121—Timestamp
Abstract
The present disclosure relates to a method of network activity monitoring for privacy protection, comprising: receiving a request for digital content from a domain from an application on a user device of a user; assigning to the application at a first time a randomized group constructed based on a randomly selected identifier and a timestamp indicating a first time at which the randomized group was assigned to the application; and providing, to the application at the first time, (i) a digitally signed certificate corresponding to the randomly selected identifier and the timestamp and (ii) a unique public key and a corresponding unique private key associated with the certificate, wherein the randomly selected identifier is also assigned to at least a threshold number of other applications executing on other user devices within the predetermined time period that the randomized group is assigned to the application.
Description
Technical Field
The present specification relates to network activity aggregation, data processing, and protecting user privacy in an online environment. The enhancement of online user privacy has led many browser developers to change the way user data is processed. For example, some browsers no longer support certain types of cookies, but the abandonment of third party (3P) cookies may lead to fraud and abuse.
Background
Aggregated network activity allows a user's browsing experience to be personalized and content more relevant to the user can be delivered faster than without monitoring. However, existing mechanisms, such as cookies, can be linked to a single user and information about the user. Such accuracy can make users feel that they are too easily identified and their information is too easily compromised.
Disclosure of Invention
In general, one innovative aspect of the subject matter described in this specification can be embodiment in a method for privacy-preserving network activity monitoring, the method including: receiving a request for digital content from a domain from an application on a user device of a user; assigning to the application at a first time a randomized group constructed based on a randomly selected identifier and a timestamp indicating a first time at which the randomized group was assigned to the application; and providing, at a first time, to the application (i) a digitally signed certificate corresponding to the randomly selected identifier and the timestamp, and (ii) a unique public key and a corresponding unique private key associated with the certificate, wherein the randomly selected identifier is also assigned to at least a threshold number of other applications executing on other user devices within a predetermined time period in which the randomized group is assigned to the application.
In some embodiments, the method comprises: receiving a second request for digital content from the domain from the application; and providing, by the application, to the domain at a second time, a obfuscated identifier corresponding to the randomly selected identifier and a randomized group age bucket indicating an age range of cookies containing an age of the randomized group, wherein the age of the randomized group is calculated based on a difference between the second time and the first time.
In some embodiments, the method further comprises: detecting, by the domain based on the received randomized group age bucket, anomalous activity associated with the randomly selected identifier and at least one of: a number of interactions associated with the randomly selected identifier, a randomized group age distribution, and a probability distribution associated with a particular interaction and a particular time period.
In some embodiments, wherein assigning the randomized group to the application comprises: assigning, by the domain, the randomized group to the application, and wherein a randomly selected identifier is assigned to at least a threshold number of other applications, wherein the randomly selected identifier is a randomly generated identifier selected from two or more randomly generated identifiers, and wherein the unique public key is generated by the domain.
In some embodiments, assigning the randomized group to the browser comprises: assigning, by the central server, the randomized group to the application; wherein the randomly selected identifier is assigned to at least a threshold number of other applications, wherein the randomly selected identifier is a randomly generated identifier selected from two or more randomly generated identifiers, and wherein the unique public key is generated by the central server.
In some embodiments, the method comprises: providing, by an application, a request for digital content and a randomized group from a second domain different from the first domain; receiving, by the application from the second domain, an attestation request including a challenge in response to providing the request for the digital content from the second domain; and providing, by the application, the digitally signed certificate to the verification system, the digitally signed certificate triggering the verification system to (i) create a fuzzy certificate containing the randomly selected identifier, the randomized group age bucket, and the challenge, (ii) sign the fuzzy certificate, and (iii) provide the fuzzy certificate to the second domain, wherein the challenge is masked from the verification system using a blinding scheme.
In some embodiments, the method comprises: providing, by the application, the digitally signed certificate to the verification system; and verifying, by the verification system, that the randomized group is assigned to at least a threshold number of people.
Other embodiments of this aspect include corresponding systems, apparatus, and computer programs, encoded on computer storage devices, configured to perform the actions of the methods.
The subject matter described in this specification can be implemented in particular embodiments to realize one or more of the following advantages.
Digital component distribution systems historically included the use of user information (e.g., browsing information, interest group information, etc.) obtained from third-party cookies, which are cookies discarded on a client device by a different domain (e.g., eTLD + 1) than the domain of a web page rendered on the client device (e.g., the selection parameters generated and/or the selection parameters themselves). However, some browsers are blocking the use of third party cookies, making it more difficult to select and provide personalized digital components, which means that computing resources and bandwidth may be wasted by being selected and distributing content to the user that is not of interest to the user. In addition, functions that the computer system may have previously performed using third-party cookies can no longer be performed, resulting in a computer system that is less efficient and effective. To overcome this problem, privacy protection techniques can be used that can monitor, aggregate, and analyze network activity while hindering tracking of users and while preventing leakage of user information across computing systems. In other words, the techniques discussed herein are changing the way computing systems operate to overcome problems that arise when browsers do not support the use of third-party cookies.
The privacy-preserving monitoring mechanism described herein, a randomized group, provides network activity monitoring functionality. The randomized group includes an identifier and a timestamp. The identifier and timestamp combination cannot uniquely identify a particular browser or user device, but rather. However, timestamps can be obfuscated by generating age buckets to which the randomized groups belong and providing a combination of identifiers and age buckets, while still providing useful information. The identifier and age bucket combinations are assigned to at least a threshold number of unique browsers running on different user devices, thereby ensuring anonymity without sacrificing the statistical utility of the randomized group. Randomized groups can be used to generate statistics about group activity and other information while ensuring user anonymity. The users are randomly grouped into groups of size k so that the domain to which the randomized group applies is able to track the activity of the group, rather than any one user.
In addition, the randomized group can be used in the context of security of third parties, such as content providers and hosts, to detect fraudulent activity or collaborative abuse. For example, randomized groups allow existing anti-abuse techniques to combat participation in abuse. Participation in abuse can include actions such as click fraud, view count inflation, rating manipulations, ranking manipulations, and the like. The randomized groups can be used to detect suspicious network activity indicative of fraudulent use while providing the user with a particular level of privacy that the user has not previously obtained. For example, randomized groups can be used to provide k-anonymity guarantees to users. The k-anonymity guarantee ensures that at least k random users are associated with a single randomized group, which can be identified by a randomized group identifier and a timestamp. For example, the assurance of k-anonymity of the randomized group identifier of k =100 ensures that at least 100 random users are associated with the randomized group identifier, such that information associated with a particular randomized group is anonymized to some extent, while still facilitating applications such as statistical analysis and abuse detection.
The described monitoring mechanism, a randomized group, improves user experience and trust by providing privacy guarantees that can be verified externally by independent third parties. The described system can include one or more authentication servers that are independent of the source of the randomized group, such that the particular identities of the randomized group and the user remain hidden while allowing the authentication server to determine the statistical properties of the particular randomized group identifier. This allows users to confirm through independent sources that their anonymity is maintained and that privacy preserving systems are acting with commitments. A user who is able to verify privacy guarantees alone may feel more comfortable with a system using the described monitoring mechanism.
Furthermore, randomized groups may be used as an alternative in systems that use traditional network activity monitoring methods. For example, the randomized group can be used in existing systems with little adjustment required under certain conditions, allowing system designers to reuse existing infrastructure to provide relevant statistics about Web activity and perform security functions to protect third parties while improving user privacy.
The techniques discussed throughout this document can also be used to detect irregular activity (e.g., a network attack) and shut down irregular activity. For example, the techniques can detect network requests or traffic above a typical level and use this information to place further network requests or traffic or block further requests from the group of computing devices responsible for the high-level network requests or traffic. The techniques can also be used to detect overuse of particular computing resources and perform load balancing to increase the efficiency of the computer system.
Various features and advantages of the foregoing subject matter are described below with reference to the drawings. Additional features and advantages will be apparent from the subject matter described herein and the claims.
Drawings
FIG. 1 is a block diagram of a system in which a privacy preserving monitoring mechanism is implemented.
FIG. 2 is a data flow diagram of an example process for publishing and implementing a privacy-preserving monitoring mechanism.
FIG. 3A is a swim lane diagram illustrating an example process for publishing and implementing a privacy-preserving monitoring mechanism that is limited in scope to a single publishing domain.
FIG. 3B is a swim lane diagram illustrating an example process for publishing and implementing privacy-preserving monitoring mechanisms for use in network activities performed across different domains.
FIG. 4 is a flow diagram illustrating an example process for publishing and implementing a privacy-preserving monitoring mechanism.
FIG. 5 is a block diagram of an example computer system.
Like reference numbers and designations in the various drawings indicate like elements.
Detailed Description
In general, this document describes systems and techniques for ensuring a specified privacy level for users associated with a monitoring mechanism, randomized group, which also provides statistical tracking and abuse detection capabilities.
Fig. 1 is a block diagram of an environment 100 for data collection and analysis for privacy protection. The example environment 100 includes a network 102, such as a Local Area Network (LAN), a Wide Area Network (WAN), the Internet, or a combination thereof. Network 102 connects electronic document server 104 ("electronic document server"), user devices 106, digital component distribution system 110 (also referred to as DCDS 110), and one or more validation servers 130. The example environment 100 may include many different electronic document servers 104, user devices 106, authentication servers 130, and trusted domain servers 140. For ease of explanation, one trusted domain server 140 is shown.
The user device 106 is an electronic device capable of requesting and receiving resources (e.g., electronic documents) over the network 102. Example user devices 106 include personal computers, wearable devices, smart speakers, tablet devices, mobile communication devices (e.g., smart phones), smart appliances, and other devices capable of sending and receiving data over the network 102. In some implementations, the user device can include a speaker that outputs audible information to the user and a microphone that accepts audible input from the user (e.g., spoken input). The user device can also include a digital assistant that provides an interactive voice interface for submitting input and/or receiving output provided in response to the input. The user device can also include a display for presenting visual information (e.g., text, images, and/or video). The user device 106 typically includes a user application, such as a web browser, to facilitate sending and receiving data over the network 102, although a native application executed by the user device 106 can also facilitate sending and receiving data 102 over the network.
The user device 106 includes software 107. The software 107 can be, for example, a browser or an operating system. In some implementations, the software 107 allows a user to access information over a network, such as the network 102, retrieve information from a server, and display information on a display of the user device 106. In some embodiments, software 107 manages hardware and software resources of user device 106 and provides common services for other programs on user device 106. The software 107 can act as an intermediary between the program and the hardware of the user device 106.
The software 107 is specific to each user device 106. As described in detail below, the privacy-preserving data analysis and collection innovations provide resource-efficient and secure device-specific solutions.
An electronic document is data that presents a collection of content at a user device 106. Examples of electronic documents include web pages, word processing documents, portable Document Format (PDF) documents, images, videos, search result pages, and feed sources. Local applications (e.g., "apps"), such as applications installed on mobile, tablet, or desktop computing devices, are also examples of electronic documents. The electronic document server 104 is capable of providing an electronic document 105 ("electronic document") to a user device 106. For example, the electronic document server 104 can include a server hosting a publisher's website, such as a network domain (e.g., eTLD + 1). Each of the electronic document servers 104 can be a server within or associated with a separate domain (e.g., a different tld + 1).
In this example, the user device 106 can initiate a request for a given publisher web page, and the electronic document server 104 hosting the given publisher web page can respond to the request by sending machine hypertext markup language (HTML) code that initiates presentation of the given web page at the user device 106.
Electronic documents can include a variety of content. For example, the electronic document 105 can include static content (e.g., text or other specified content) that is within the electronic document itself and/or does not change over time. Electronic documents can also include dynamic content that may change over time or upon each request. For example, a publisher of a given electronic document can maintain a data source for populating portions of the electronic document. In this example, the given electronic document can include a tag or script that causes the user device 106 to request content from a data source when the given electronic document is processed (e.g., rendered or executed) by the user device 106. The user device 106 integrates content obtained from the data sources into the presentation of a given electronic document to create a composite electronic document that includes the content obtained from the data sources.
In some cases, a given electronic document can include a digital content tag or digital content script that references the DCDS 110. In these cases, the digital content tag or digital content script is executed by the user device 106 when a given electronic document is processed by the user device 106. Execution of the digital content tag or digital content script configures the user device 106 to generate a request 108 for digital content that is transmitted over the network 102 to the DCDS 110. For example, a digital content tag or digital content script can enable the user device 106 to generate a packetized data request including a header and payload data. The request 108 can include data, such as the name (or network location) of the server from which the digital content was requested, the name (or network location) of the requesting device (e.g., user device 106), and/or information that the DCDS 110 can use to select the digital content provided in response to the request. The request 108 is transmitted by the user device 106 to a server of the DCDS 110 over the network 102 (e.g., a telecommunications network).
The request 108 can include data specifying characteristics of the electronic document and the location where the digital content can be rendered. For example, data specifying a reference (e.g., a URL) to an electronic document (e.g., a web page) in which digital content is to be presented, available locations of the electronic document (e.g., a digital content slot) available for presenting the digital content, sizes of the available locations, locations of the available locations in the presentation of the electronic document, and/or media types eligible for presentation in those locations can be provided to the DCDS 110. Similarly, data specifying keywords designated for selection of electronic documents ("document keywords") or entities (e.g., people, places, or things) referenced by the electronic documents can also be included in the request 108 (e.g., as payload data) and provided to the DCDS 110 to facilitate identification of digital content items, such as electronic documents or digital components, that are eligible for presentation with the electronic documents.
The request 108 can also include data related to other information, such as information that the user has provided, geographic information indicating the state or region from which the request was submitted, or other information that provides context for the environment in which the digital content is to be displayed (e.g., the type of device, such as a mobile device or tablet device, that is to display the digital content). The user-provided information can include demographic data of the user device 106. For example, demographic information can include age, gender, geographic location, education level, marital status, household income, occupation, hobbies, social media data, and whether the user owns a particular project, among other characteristics.
Data specifying characteristics of the user device 106 can also be provided in the request 108, such as information identifying a model of the user device 106, a configuration of the user device 106, or a size (e.g., a physical size or resolution) of an electronic display (e.g., a touchscreen or desktop monitor) on which the electronic document is presented. The request 108 can be transmitted, for example, over a packetized network, and the request 108 itself can be formatted as packetized data with a header and payload data. The header can specify the destination of the packet, and the payload data can include any of the information discussed above.
In addition to privacy protection techniques discussed throughout this document, a user may be provided with controls that allow the user to select whether and when the systems, programs, or features described herein enable the collection of user information (e.g., information about the user's social network, social behaviors or activities, profession, user preferences, or the user's current location) and whether to send content or communications from a server to the user. In addition, certain data may be processed in one or more ways before it is stored or used, so that the personally identifiable information is deleted. For example, the identity of the user may be processed such that no personal identity information of the user can be determined, or the geographic location of the user may be generalized where location information is obtained (e.g., to a city, zip code, or state level) such that no particular location of the user can be determined. Thus, the user may have control over which information is collected about the user, how the information is used, and which information is provided to the user.
The DCDS 110 selects digital content to be presented with a given electronic document in response to receiving the request 108 and/or using information included in the request 108. In some implementations, the DCDS 110 is implemented in a distributed computing system that includes, for example, a server and a collection of multiple computing devices that are interconnected and that identify and distribute digital content in response to a request 108. The set of multiple computing devices operate together to identify a set of digital content that qualifies for presentation in an electronic document from a corpus of millions or more of available digital content. The millions or more of available digital content can be indexed, for example, in the digital component database 112. Each digital content index entry can reference corresponding digital content and/or include a distribution parameter (e.g., selection criteria) that adjusts the distribution of the corresponding digital content.
The identification of eligible digital content can be segmented into a plurality of tasks, which are then distributed among the computing devices within the set of the plurality of computing devices. For example, different computing devices can each analyze different portions of the digital component database 112 to identify various digital content having distribution parameters that match the information included in the request 108.
The DCDS 110 aggregates the results received from the set of multiple computing devices and uses information associated with the aggregated results to select one or more instances of digital content to be provided in response to the request 108. In turn, DCDS 110 may be capable of generating and transmitting reply data 114 (e.g., digital data representing a reply) over network 102, which reply data 114 enables user device 106 to integrate the set of selected digital content into a given electronic document such that the set of selected digital content is presented at the display of user device 106 along with the content of the electronic document.
The DCDS 110 can forward a request 108 from the software 107 of the user device 106 to a data source, such as the electronic document server 104, and can forward a reply 114 from the electronic document server 104 to the software 107 of the user device 106. For example, the DCDS 110 acts as an intermediary between the electronic document server 104 and the user device 106 and/or software 107 running on the user device 106.
A randomized group generator 121 (RCX generator) allows the electronic document server 104 to generate randomized groups, i.e., privacy preserving monitoring/aggregation mechanisms described herein. In this document, randomized group refers to a specific format of a privacy-preserving monitoring mechanism with a randomized group identifier and a randomized group timestamp. The randomized group is generated in response to an initial third party request from an application, such as software 107, or a device, such as user device 106, and includes an identifier (i.e., randomized group identifier) and a timestamp (i.e., randomized group timestamp). For example, the randomized group can be data represented by rcx (rcx.id, rcx.timestamp), where rcx represents the randomized group, rcx.id represents the randomized group identifier, and rcx.timestamp represents the timestamp. The randomized group is assigned to the software 107 or user device 106 from which the initial request was received. For simplicity of explanation, in this example, the randomized group is generated in response to an initial request from the browser 107. In other examples, the randomized group can be generated in response to an initial request from a particular user device 106.
Because randomization group generator 121 is associated with a particular domain, the randomization group generated by each generator 121 can be domain-wide, meaning that the randomization group data is used within the domain with which randomization group generator 121 and/or electronic document server 104 is associated, and the randomization group is not provided or shared with other domains or servers.
The initial request can be a request for an electronic document 105 from an electronic document server 104. The initial request can be a request for a content item from a third party server 150, the third party server 150 providing content, such as a digital component that can be provided for display with the content requested from the electronic document server 104.
The randomized group identifier is a randomly selected or constructed identifier that is also assigned to a plurality of other browsers 107 executing on other user devices 106 that have also provided initial requests to the electronic document server 104. For example, the randomized group identifier can be a randomly generated 64-bit identifier selected from a set of existing identifiers or created in response to an initial request from the browser 107. The number of other applications 107 to which the randomized group identifier is assigned is based on a predetermined threshold privacy level being guaranteed to the user. For example, the electronic document server 104 is able to achieve a guarantee of k-anonymity, which means that each randomized group identifier is assigned to at least k browsers 107 running on different user devices 106. Each electronic document server 104 can independently select a k to guarantee. In some examples, each electronic document server 104 guarantees the same level of k-anonymity.
The randomized group timestamp indicates the time at which the randomized group identifier was requested and/or assigned to the software 107 in response to the request 108. For example, the randomized group timestamp can indicate the time that the request 108 was received by the randomized group generator 121. In another example, the randomized group timestamp can indicate a time at which the randomized group identifier was selected in response to the request 108. In another example, the randomized group timestamp can indicate a time at which the randomized group identifier was assigned to software 107 in response to the request 108. One or more of these actions can be performed simultaneously, and thus the randomized group timestamp can represent the time at which one or more of these actions was performed. Because randomized group identifiers are assigned to at least k browsers 107 (i.e., 3000 different browsers 107 for k = 3000) for the purpose of maintaining k-anonymity, the combination of randomized group timestamp and randomized group identifier can serve as the unique identifier. To protect privacy when providing a randomized group, the randomized group generator 121 can also anonymize the randomized group timestamp, creating a parameter representing the age bucket to which the randomized group belongs. The age bucket represents a generalized range of age values within which the age of the randomized group falls, but cannot be used to uniquely identify the browser 107 to which the randomized group is assigned. For example, the randomized group generator 121 can determine the difference between the current time and the randomized group timestamp to determine the age of the randomized group. The randomization group generator 121 can then generate a value for the age bucket based on, for example, information such as the value of k and a range of ages or a predetermined range of ages required to maintain k-anonymity, among other parameters.
In addition to the randomization group comprising a randomization group identifier and a randomization group timestamp, the randomization group generator 121 also generates a certificate that can be used to prove the validity of the randomization group. For example, the randomized group generator 121 can generate a certificate containing a public verification key signed by the electronic document server 104. The electronic document server 104 is also capable of generating a public/private key pair. The certificate generation process and the verification process are described in more detail below.
A randomized group comprising both a randomized group identifier and a randomized group timestamp is a monitoring mechanism that allows for flexible privacy protection of anonymity as well as unique identification. As described in further detail below, the certificate can be used to uniquely identify the browser 107 when the browser 107 proves the validity of its randomized group. For example, the browser 107 can transmit the credentials provided by the randomization group generator 121 to the authentication system for authentication purposes.
In some implementations, the publishing domain or electronic document server 104 does not provide metadata other than the randomized group to be stored on the user device 106 on which the browser 107 is stored. This additional limitation further improves user privacy by reducing the amount of data collected and stored, eliminating the possibility of revealing certain types of user data that is not collected and therefore cannot be linked to a particular user or randomized group identifier.
The analyzer 123 analyzes the randomized group data to monitor user network activity. The analyzer 123 can receive the randomized group identifier and randomized group age data and a request for data from the electronic document server 104 associated with the analyzer 123 and perform a security function using the received randomized group identifier and randomized group age data. For example, the analyzer 123 can detect certain types of fraudulent activity or collaborative abuse of system or content from the electronic document server 104 based on the randomized group identifier and the randomized group age data. As illustrated in fig. 1, each electronic document server 104 can have a separate parser 123 tailored to its own needs. In some examples, the electronic document servers 104 can share a centralized analyzer 123, which can be implemented as a remote or separate analysis server or service.
The system 100 includes one or more third party independent authentication services that a user of the user device 106 or browser 107 can select to use. The third party independent verification service independently verifies the privacy attributes of the randomized group assigned by the publishing service, such as the electronic document server 104 as described above and the trusted domain server 140 as described below. The independent verification of the privacy attributes of the randomized groups is optional for the user and is described in more detail below.
The verification server 130 is a server independent of the electronic document server 104 that performs verification of the randomized group identifier and the statistical properties of the randomized group identifier and randomized group age parameter pair. The validation server 130 acts as a stand-alone server that does not publish the randomized group and does not participate in monitoring or otherwise interacting with a server, such as the electronic document server 104, that monitors and/or analyzes the randomized group data. Authentication server 130 allows a user to authenticate a publishing server, such as electronic document server 104, to maintain a guaranteed privacy level for a particular randomized group. By giving users an opportunity to verify through the standalone service that their privacy is being maintained by the participating publishing domains, the system 100 encourages user trust and improves user experience. In addition, this allows users to discern whether a particular publishing domain is compliant and to follow the responsibility of the publishing domain, thereby improving the experience of all users.
A randomized group generator 142 (RCX generator) is a generator that operates similarly to randomized group generator 121 described above, but is associated with trusted domain server 140 instead of an electronic document server.
Fig. 2 is a data flow diagram of an example process 200 for publishing and implementing a privacy-preserving monitoring mechanism. As described below, a domain that supports randomized groups needs to assign randomized groups to users in a manner that protects certain verifiable k-anonymity properties. The operations of process 200 can be implemented, for example, by electronic document server 104, user device 106, authentication server 130, trusted domain server 140, and/or third party server 150. The operations of process 200 can also be implemented as instructions stored on one or more computer-readable media, which may be non-transitory, and execution of the instructions by one or more data processing apparatus can cause the one or more data processing apparatus to perform the operations of process 200.
As discussed above with respect to fig. 1, the DCDS 110 may act as an intermediary, forwarding the request 108 from the user device 106 to the electronic document server 104, and forwarding the reply 114 from the electronic document server 104 to the user device 106. In this particular example, DCDS 110 may transfer data between user device 106 and electronic document server 104, but is not illustrated in the data flow.
The process 200 begins at stage A-1, where the user device 106 provides a request for content to the electronic document server 104. For example, the software 107 provides requests for content, such as a particular web page, to an electronic document server 104 associated with a particular network domain. In addition to web pages, software 107 can provide requests for third party content such as digital components. For example, software 107 can provide the request to third party server 140. The request in phase a-1 can be a request from the user device 106, the request being a request for content or a request for a digital component. The request can be provided to the electronic document server 104 or the third party server 140. In this particular example, the request labeled request 1 is provided to the electronic document server 104.
The process 200 continues at stage B, where the randomization group generator generates/constructs a randomization group 201 and assigns the randomization group to the requesting user device 106 or software 107 in response to receiving data indicative of request 1.
If system 100 uses a single central publishing entity, such as trusted domain server 140, randomization group generator 142 performs phase B by generating a randomization group in response to receiving data indicating request 1. If system 100 uses a separate publishing entity, such as electronic document server 104, randomization group generator 121 performs stage B by generating a randomization group in response to receiving data indicating request 1. In this particular example, phase B is described as being performed by the randomization group generator 121. In other examples and embodiments, phase B can be performed by randomization group generator 142 if, for example, system 100 uses a single central publishing entity, such as trusted domain server 140.
The concept of k-anonymity applied to randomized group identifiers ensures that each randomized group identifier is assigned to at least k browsers 107. For example, k different browsers 107 can be used as proxy metrics to guarantee k different devices 106 corresponding to k different users. Each publishing domain guarantees a specific k for its published randomized group, such that each randomized group identifier is assigned to at least k browsers 107 running on different user devices 106. To ensure this level of privacy, the publishing domain must track the number of each randomized group identifier that is published and associate the browser 107 with the particular randomized group identifier that has been assigned. During the assignment process, the browser 107 can be assigned to a cluster of browsers 107 assigned to a particular randomized group identifier. For example, the randomized group generator 121 can randomly assign the browser 107 from which request 1 was received to the cluster of browsers 107 associated with a particular randomized group identifier.
Each publishing domain performs an allocation process to provide an evenly distributed (or within a threshold of even distribution) allocation of identifiers. For example, the randomized group generator 121 can randomly assign the browser 107 to one of a set of randomized group identifiers that have been generated and associated with the browser 107. Randomization group generator 121 balances the number of different randomization group identifiers with the number of browsers to maintain its k-anonymity guarantees for users. For example, the randomization group generator 121 can balance the number of different randomization group identifiers assigned based on the number of current browsers 107 and the expectation of providing requests for content to the respective electronic document servers 104. In one example, randomization group generator 121 can generate or receive a threshold number of different randomization group identifiers based on the intended browser 107 providing the request for content to electronic document server 104, and can adjust the threshold number of different randomization group identifiers based on the actual current traffic from the different browsers 107 providing the request for content to electronic document server 104. For example, the randomized group generator 121 can increase the number of different randomized group identifiers associated with its domain based on an increase in the number of different browsers 107 or a rate of change in the number. In another example, in initialization of the system 100, the randomized group generator 121 can receive multiple requests from different browsers 107 running on separate user devices 106 and randomly assign clusters of k browsers 107 to particular randomized group identifiers to ensure k-anonymity.
To ensure k-anonymity, the domain must have enough traffic to make the statistical parameters meaningful and provide the anonymization effect such that a particular randomized group identifier is assigned to k different browsers running on different user devices. The system 100 can ensure that the system has sufficient traffic by setting and adjusting thresholds for network activity levels and that the domain maintains sufficient traffic to make the randomized group privacy attributes verifiable.
Once the randomized group is generated and assigned to the browser 107, the randomized group can have an expiration time. For example, the randomization group can expire after a predetermined period of time, or until the user resets or clears the randomization group. In some examples, the randomized group can expire after a time period specified by the user of the browser 107, a default setting of the browser 107, a publishing domain, a time period determined by the browser 107 based on the network activity of the user of the browser 107 and habits of the user or users having similar browsing habits to the user. For example, if a user regularly clears a randomization group associated with a distribution domain, the expiration period of the randomization group can be adjusted such that the randomization group is periodically cleared similar to a schedule typically used by users of the domain.
When the randomized group identifier assignment expires or is cleared, the randomized group generator 121 can reassign the randomized group identifier previously used. For example, the randomized group generator 121 can randomly assign a randomized group identifier to the browser 107 using a list of available randomized group identifiers (including previously expired randomized group identifiers), or randomly generate randomized group identifiers based on the needs of the system.
In some embodiments, the randomized group identifier can become "stale"; in other words, the number of users assigned to a particular randomized group identifier may decrease over time as a result of users resetting their randomized group or their randomized group expiring. Although a publishing domain such as the electronic document server 104 can guarantee k users when publishing the randomized group, the number of users behind the FC can be reduced due to the randomized group expiring or being reset. The system 100 can counteract this user reduction for each bucket by, for example, storing one or more additional states on the server that indicate a reclamation state with less than k users of randomized group identifiers/age buckets. In addition, the validation server 130 can also detect a lack of activity in a particular user bucket (i.e., a user bucket assigned to a particular randomized group identifier over a period of time). The authentication server 130 can also provide feedback to the browser 107 regarding the distribution of the randomized group identifier and can provide feedback to the randomized group generator 121.
In addition, the randomized group generator 121 generates a timestamp indicating the time at which the randomized group identifier was assigned or generated, as described above with respect to fig. 1. For example, upon receiving a request from software 107, the randomization group generator generates a randomization group time stamp. The timestamp indicates when the randomly selected identifier was assigned to the publishing domain that randomly assigned the randomized group to the user.
The user of browser 107 can reset the randomized group associated with their browser 107 at any time just as other monitoring mechanisms can be cleared and/or reset. When a user resets the randomized group published by the publishing domain associated with their browser 107, the next request sent from the browser 107 to the publishing domain, such as the electronic document server 104, is received as an initial request for which the randomized group is to be assigned to the browser 104.
In addition to the randomization group assigned to the browser 107, the randomization group generator 121 also generates a certificate containing the randomization group and a public/private key pair. This certificate provided by randomized group generator 121 contains identifiable information for browser 107, including a randomized group identifier and a randomized group timestamp. The randomization group generator 121 signs the certificate, which indicates the authenticity of the certificate and its distribution to the browser 107. The signed certificate is used for authentication purposes only, as described in further detail below, and is never transmitted to or accessible by domains other than the authentication server. The randomized group generator 121 uses a cryptographic algorithm to generate a public key that may be known to others and a private key that may never be known to anyone other than the browser 107. The public/private key pair is used to prove or prove the identity of the browser 107 that provided the signed certificate comprising the randomized group. In particular, the public key is provided to the requesting entity, and the browser 107 can cryptographically verify that it was assigned the certificate using the private key. In addition, the certificate can be encrypted using a public/private key pair.
The verification server 130 verifies that the signature on the certificate is valid. For example, if the example coolvideo optimization.com issues a certificate, the verification server 130 will retrieve the public key of the example coolvideo optimization.com and verify that the signature on the certificate is valid. For example, the key can be distributed by a technique such as Public Key Infrastructure (PKI), and the key need not be distributed by the electronic document server 104 associated with the randomized group generator 121 that generates the certificate. Authentication server 130 then generates a challenge and transmits the challenge to browser 107. For example, the challenge can be a random number or some variable known to the authentication server 130. The browser 107 can then sign the challenge using its private key and return the signature to the verification server 130. The verification server 130 can then verify that the signature is valid using the public verification key issued on the signed certificate.
The process 200 continues to stage C where the electronic document server 104 provides the randomized group, the signed certificate, the public/private key pair, and the response to the request to the browser 107. In some implementations, the electronic document server 104 provides each of the randomized group, the signed certificate, the public/private key pair, and the response to the request to the browser 107 simultaneously. In other embodiments, the electronic document server 104 provides one or more of the randomized group, the signed certificate, the public/private key pair, and the response to the request to the browser 107, respectively. In some embodiments, the private/public key pairs are distributed through standard techniques such as PKI. As described above, certain stages of the process 200 are performed by the electronic document server 104. For example, phase C may be performed by trusted domain server 140.
The process 200 continues to stage D where the browser 107 provides the subsequent request to the electronic document server 104 along with the randomized group data. The subsequent request can be identical in format to the initial request and is not required to provide any additional information indicating that the request follows the initial request. The browser 107 detects that the request is provided to the domain associated with the randomized group to which the browser 107 has been assigned and provides randomized group data, indicating to the electronic document server 104 that the request is a subsequent request. Randomizing the group data allows a domain associated with the electronic document server 104 to monitor activity of different browsers within the domain while protecting the privacy of the browser user to a greater extent than previously possible.
The browser 107 provides randomized group data including a randomized group identifier assigned to a domain associated with the electronic document server 104 and data representing a fuzzy age of the randomized group for the domain. In particular, the browser 107 generates a randomized group age bucket to be provided instead of randomizing the group timestamp to obscure the specific identity of the browser 107. For example, the browser 107 uses the function rcx. For example, the function can be a bucket function, such as log2 (currentTime-random co-timestamp), where currentTime represents the current time and random co-timestamp represents the randomized group timestamp.
Because the browser 107 provides subsequent requests to both the randomized group identifier and the randomized group timestamp, the publishing domain (in this example, the electronic document server 104 of the publishing domain) is responsible for ensuring that at least k users or user agents of the browser 107 are assigned to each pair of randomized group identifier and randomized group age bucket to satisfy their k-anonymity guarantees. In some embodiments, the publishing domain can guarantee different levels of k-anonymity with respect to the randomized group identifier and randomized group timestamp pair.
Optionally, the user of browser 107 can choose to verify the statistical and/or privacy attributes assigned to the randomized group of browser 107. Any third party of the publishing domain, such as the electronic document server 104 or trusted domain server 140, who is not the randomized group to be authenticated, can maintain the authentication server 130, and the user can choose to direct their browser 107 to any authentication server 130. In some implementations, the electronic document server 104 can maintain a verification server 130 to verify the statistical and/or privacy attributes of randomized groups published by other electronic document servers 104 associated with other domains. In some implementations, the browser 107 can automatically request authentication from the authentication server 130 without being instructed by the user. For example, the system 100 can require the participating browser 107 to periodically request authentication from a randomly selected qualified authentication server 130. In some implementations, the browser 107 does not request authentication unless instructed by the user.
Process 200 continues to stage E where software 107 provides the certificate to authentication server 130. For example, the browser 107 provides the certificate generated by the randomization group generator 121 in phase B to the authentication server 130. The browser 107 can also provide the public key to the authentication server for attestation purposes. In some embodiments, the browser 107 provides randomized group information, such as a randomized group identifier and a randomized group age bucket, rather than a certificate, that does not obscure the randomized group age.
The process 200 continues to stage F where the validation server 130 performs a validation process that validates the statistical and/or privacy attributes of the randomized group data provided by the browser 107.
The authentication server 130 authenticates that the set of randomized group identifiers that the authentication server 130 has access to is evenly distributed. For example, the authentication server 130 can use the certificate to determine a randomized group identifier and/or a randomized group age bucket. The authentication server 130 can then compare the randomized group identifier and/or randomized group age bucket to a list of randomized group identifiers and/or randomized group age buckets that the authentication server has access to determine whether the number of browsers running on different user devices assigned to each different randomized group identifier within an appropriate range is evenly distributed or evenly distributed within a threshold distance. As described above, the scope can be within a particular domain or globally within a network of participating domains. For example, the authentication server 130 can maintain a list of randomized group identifier and randomized group age bucket pairs that it receives from the browsers 107 participating in its authentication service. The validation server 130 can then determine whether the number of different browsers running on different user devices assigned to each different randomized group identifier within a particular age bucket and/or domain is normally distributed. In some implementations, the validation server 130 determines whether the number of different browsers running on different user devices assigned to each different randomized group identifier within a particular domain is normally distributed without the additional requirement of being in the same age bucket.
The browser 107 can automatically request authentication from an authentication service, such as the authentication server 130, at specific time intervals. For example, the browser 107 can request authentication from the authentication server 130 every week to ensure that the electronic document server 104 complies with its k-anonymity assurance responsibilities and to pass on the privacy level it promises to the user.
Optionally, during the content delivery process where the randomized group is global and not distributed by each domain, the electronic document server 104 from which the browser 107 requests content can include an attestation request in its response to the initial request from the browser 107.
Regardless of which domain the electronic document server 104 is associated with, the browser 107 provides such randomized groups to each electronic document server 104 upon each request. Using globally scoped randomized groups prevents malicious domain collusion from combining randomized groups across domains in a manner that creates more traceable entropy, reducing the risk of compromising user privacy due to collusion between domains. However, the globally scoped randomized groups are globally readable, which does not eliminate the possibility of abuse due to policies such as replay attacks. For example, a malicious actor could purchase traffic to a domain, obtain a randomized group (including a randomized group identifier and a randomized group timestamp), and then use the observed distribution to attack a different domain. Because the entity that generated the randomized group is separate and independent from the server from which the content was requested, such as the electronic document server 104 or the third party server 150, the server from which the content was requested will need to be able to perform an attestation step to verify that the browser 107 providing the randomized group identifier and randomized group timestamp has in fact been assigned a randomized group from a trusted server, such as the trusted domain server 140.
The attestation request can specify that the browser 107 should request the authentication server 130 to determine whether the randomized group identifier and randomized group age bucket provided to the electronic document server 104 with the browser 107 request for content are actually allocated to the browser 107 by a trusted server, such as the trusted domain server 140. For example, the electronic document server 104 can request that the authentication server 130 ask the browser 107 to prove its identity as the browser 107, and that the certificate and associated randomized group information are assigned to the browser 107 by a trusted server, such as the trusted domain server 140. The authentication server 130 can facilitate this attestation process by generating an anonymous certificate that is different from the certificate provided and signed by the randomized group generator 121, which attests that a particular certificate is assigned to a particular browser 107. This process is irrelevant, where the randomization group is local to each domain such that each domain issues a randomization group to browser 104, and thus will be able to determine whether browser 107 is the browser to which it has assigned the randomization group based on the signed certificate issued by randomization group generator 121. For example, if the randomized group generator 121 associated with the electronic document server 104 generated a randomized group, it would be able to verify its own signature on the certificate it received associated with the randomized group or using public key encryption by using a public/private key pair generated as described above with respect to phase B.
Com in one illustrative example, the user accesses the examplenews web site using the browser 107. The user reads an article linking to a specific video on the example video hosting platform. In this example, the browser 107 has previously been assigned a randomization group and a certificate from the trusted domain server 140, and thus the browser 107 sends a request for a specific video to an examplevideohostingplatform. In the request, the browser 107 includes its assigned randomized group identifier and randomized group age bucket.
Com may be done by requesting the browser 107 to prove its identity and forwarding the request to the authentication server 130, because the globally randomized group assigned by the trusted server to the browser 107 is not generated by the randomized group generator 121 associated with the electronic document server 104. The electronic document server 104 provides the secret X to the browser 107. The secret can have any value and can be, for example, a randomly generated 16-bit value. The browser 107 provides the secret X and the certificate provided by the randomization group generator 142 to the authentication server 130 to request the authentication server 130 to perform the attestation process. Browser 107 can mask the value of X from authentication server 130 to prevent secret X from being linked to browser 107. For example, the browser 107 can mask X from the authentication server 130 using a partial blinded signature scheme. The authentication server 130 then receives the browser 107's certificate and the blinded secret X and generates an anonymous certificate based on the certificate indicating the randomized group identifier and the randomized group age bucket. The authentication server 130 then signs this anonymous certificate and returns the signed, anonymous certificate and X to the electronic document server 104 that issued the attestation request. The electronic document server 104 can compare the randomized group information in the signed anonymous certificate from the authentication server 130 with the randomized group identifier and the randomized group age bucket that the electronic document server 104 received from the browser 107. If the information matches, the browser 107 has successfully proven its identity with the browser to which the trusted domain server 140 assigned the randomized group information provided to the electronic document server 104.
In some embodiments, a more robust authentication process can be performed if multiple authentication servers 130 cooperate and/or share resources. For example, the validation server 130 can determine whether the plurality of randomized group identifiers within a particular age bucket conform to a k-anonymity guarantee provided by the electronic document server 104, specified by the system 100 to be deemed conforming, etc., in the context of a larger population that better represents the overall population of participating browsers and domains. The total number of unique public keys that the authentication server 130 can use, for example, to provide the certificate received across each authentication server can be calculated, allowing the user to verify that there are approximately at least k users with the same randomized group identifier.
In another example embodiment, the electronic document server 104 can return a unique tracking URL to the browser 107 instead of the secret X. The browser 107 can then follow the unique tracking URL and issue a signed anonymous certificate from the validation server 130 to the destination at the unique tracking URL.
The independent authentication servers 130 can cooperate to represent that certain statistical properties of the entire population of randomized groups are met and privacy guarantees are maintained on a large scale. Due to the nature and size of the number of browsers running on different user devices representing different users, the validation server 130 provides a degree of protection in the form of a checkpoint that is difficult to spoof, rather than a formal proof of correctness or legitimacy.
In some examples, a malicious publisher can use a subset of the bits of the randomized group identifier to encode sensitive data about the user or otherwise embed information in a hidden manner. The system 100 can perform a consistency check at the bit level to check the randomized group identifiers and determine whether the randomized group identifiers are uniformly selected and distributed. For example, the validation server 130 can randomly generate a mask, perform a bitwise AND operation on all randomized group identifiers and re-aggregate. If the randomized group identifiers have been uniformly selected and assigned, the result should also be uniform. In some embodiments, the validation server 130 remembers the randomized group identifier that has been previously assigned for each user and tests bit-level correlations over time. In some embodiments, the validation server 130 performs a test to ensure that two or more browsers 107 running on different user devices 106 are not consistently assigned to the same randomized group identifier.
Process 200 continues to stage G where authentication server 130 provides the results of the authentication process to browser 107. The validation server 130 can provide the randomized group identifier and the statistical and/or privacy attributes of the randomized group age bucket to the browser 107 in unprocessed quantities. For example, the validation server 130 can provide the distribution of randomized group identifier assignments or the number of different randomized group browsers running on different user devices to the browser 107 associated with the randomized group identifier. The browser 107 can then compare the distribution of the unprocessed number of randomized group identifier assignments to a threshold deviation from a uniform distribution, or the number of different randomized group browsers running on different user devices of the browser 107 associated with a randomized group identifier to a threshold number k of different browsers running on different user devices that should be associated with a randomized group identifier, to ensure k-anonymity. When the one or more thresholds are not met, browser 107 can provide an indication to a user of browser 107. For example, if the number of different randomized group browsers running on different user devices than the browser 107 associated with the randomized group identifier does not meet the threshold number k of different browsers running on different user devices, the browser 107 can display a visual message, play audio, create a vibration, etc. to indicate to the user that the threshold is not met.
In addition to the advantage of providing a monitoring mechanism that provides independently verifiable privacy levels for users, the randomized groups also provide protection for the content provider and host of the system. One way of abuse in content distribution systems is by manipulating engagement statistics. For example, in a pay-per-interaction scheme (e.g., a pay-per-click system) a content provider can incentivize users to click on a particular content item to increase the payment required by the content provider. Additionally, on a video content platform, users may collude to coordinate the manipulation of video content recommendation systems by artificially increasing the popularity of certain videos by providing fraudulent perspectives. The randomized groups provide a monitoring mechanism that allows detection of such abuse.
From the user's perspective, the randomized groups function similar to traditional monitoring mechanisms, while providing a higher level of privacy. Thus, the described system of monitoring mechanisms for privacy protection requires little change to the user's experience, while improving their privacy and reducing the likelihood of the user's information being compromised.
The randomized group relies on using statistical parameters to guarantee user privacy and utilizes a greater amount of entropy for the purpose of performing abuse detection without violating user privacy. For k =1 in a k-anonymous context, the randomized group provides the same level of abuse detection as traditional tracking mechanisms (such as cookies). As k increases, the randomized groups provide a higher level of privacy for the user while still being useful for abuse detection. In addition, the randomized group does not need to discontinue trust in a first context, where the randomized group is locally scoped and limited for use only by the domain that issued the randomized group.
Once the browser 107 has provided the randomized group information to the electronic document server 104, the electronic document server 104 can perform security functions, such as statistical analysis, to detect abuse of the system 100. For example, when the randomization group is locally scoped for a particular domain and when the randomization group is globally scoped, each analyzer 123 of a particular electronic document server 104 can perform a statistical analysis specified by the electronic document server 104 associated with the analyzer 123.
The electronic document server 104 is able to protect its domain from participating in abuse in a way that protects the privacy of the user by using the described monitoring mechanism, i.e. the randomized group. Because the system guarantees anonymity of k, where k is adjustable, the use of randomized groups provides a system that provides continuous protection from participation in abuse, which is maintained above the current level of privacy protection possible.
The analyzer 123 of the electronic document server 104 monitors anonymous user network activity by using randomized group information and detects signs of participation in abuse or collusion based on statistical properties of the distribution of randomized group identifiers and activity associated with randomized group identifiers. For example, the analyzer 123 can detect statistically anomalous behavior, such as anomalous resource requests or anomalous activity from a group of users associated with a particular randomized group identifier and/or age bucket.
The number of clicks per randomized group identifier should be evenly distributed for a given participating domain. Inconsistent numbers of clicks can indicate anomalous activity. For example, a deviation greater than a threshold deviation in the number of clicks associated with the randomized group identifier, or a spike in activity (number or speed of deviation) over a period of time associated with one or more randomized groups can statistically indicate anomalous activity that can indicate abuse. For example, the analyzer 123 can determine statistical tests to verify statistically abnormal activities by measures such as risk ratios of the activities and their impact on domain resources compared to the risk and potential damage caused by malicious activities.
The analyzer 123 can compute the age distribution of the randomized group age bucket received in combination with the randomized group identifier and test for anomalies against, for example, a known global background distribution. For example, the analyzer 123 can detect that an amount of activity from a browser having a randomized group age bucket value below a threshold age value is equal to or below the threshold amount and determine that there is an abnormal amount of activity.
The analyzer 123 is able to detect a cooperative attack involving a group of malicious users by performing fraud detection using a masquerading-proof algorithm, using provable limits on undetectable fraud to provide an upper limit on fraud validity. For example, the analyzer 123 can limit the probability that two or more randomized group identifier/randomized group age bucket pairs visit the same set of longended websites within a certain time window. In another example, the analyzer 123 can build a bipartite graph between users and websites, and then attempt to find a bipartite graph corresponding to a cluster of users acting in a coordinated manner (a special type of bipartite graph in which each vertex of the first set is connected to each vertex of the second set).
The analyzer 123 can detect fraudulently created entropy for the purpose of tracking one or more users. For example, a malicious actor can attempt to assign a single browser 107 to a randomized group identifier, where the other k-1 browsers 107 are robots. However, the electronic document server 104 assigns randomized group identifiers to users in a random manner, and thus an attack of this nature would be difficult to implement without an attacker gaining access to the server. A malicious or compromised domain electronic document server 104 may be able to do this fraud for multiple users associated with the browser 107, but it is very difficult for a malicious domain to perform any meaningful scale of attack while evading detection by a separate authentication server, such as the authentication server 130. In addition to providing notifications of such randomized group identifier/age bucket pairs to electronic document servers 104 participating in a domain, such that the domain can prevent abuse from an identified randomized group identifier, such scale-up attacks can be effectively thwarted by: allowing verification server 130 to perform abuse detection and prevention allows verification server 130 to detect and block or delete randomized groups assigned to botnets for a period of time.
When the analyzer 123 detects statistically abnormal behavior, the analyzer 123 can set or adjust limits to prevent a particular user from requesting resources from a particular electronic document server 104 or generally for a period of time. For example, the analyzer 123 can detect that a particular randomized group identifier/randomized group age bucket pair is being provided to the electronic document server 104 and is associated with an abnormal amount of activity within the past five minutes, and stop the particular randomized group identifier/randomized group age bucket from requesting resources from the electronic document server 104. Accordingly, the system 100 can reduce the amount of resources used to facilitate fraudulent activities. However, when the randomized group is an independent, domain-wide randomized group, each authentication server 130 can only access the randomized group identifier and randomized group age bucket of users that have elected to use that particular authentication server 130 as their independent authentication service. In some embodiments, whether the randomized groups are domain-wide or global-wide, the authentication server 130 is joined and grouped with other authentication servers 130 to access a threshold number of randomized groups to provide statistically meaningful results to the browser 107.
When the randomized group is globally scoped, the analyzer 123 can communicate with the trusted domain server 140 to identify suspicious fraudulent or anomalous activity associated with the globally scoped randomized group identifier/randomized group age bucket pair, which can be communicated to other electronic document servers 104 to monitor and prevent abuse across participating domains.
Fig. 3A and 3B are swim lane diagrams illustrating example processes 300 and 350 for publishing and implementing a monitoring mechanism for privacy protection of network activities performed across different domains. The operations of processes 300 and 350 can be implemented, for example, by user device 106 and/or software 107, electronic document server 104, DCDS 110, authentication server 130, trusted domain server 140, and/or third party server 150. All of the processes 300 and 350 can also be implemented as instructions stored on one or more computer-readable media, which may be non-transitory, and execution of the instructions by one or more data processing apparatus can cause the one or more data processing apparatus to perform the operations of the processes 300 and 350.
Referring now to FIG. 3A, a process 300 begins at step 1, where an initial request from the software 107 is provided to the electronic document server 104. In some examples, the request can be forwarded to the electronic document server 104 through the DCDS 110, which DCDS 110 is not illustrated in FIG. 3A. Com can receive a request for an image from the browser 107, for example, associated with an ExampleImageHostingPlatform network domain. In this example, the browser 107 has not been assigned a randomized group from the electronic document server 104 of the exampleimagehosting platform, and thus the request is an initial request. In another example, if the browser 107 was previously assigned a randomized group from the electronic document server 104 of the exampleimagehosting platform, but the randomized group has expired or been cleared by the user of the browser 107, the request is also treated as an initial request.
The process 300 continues to step 2 where the electronic document server 104 generates a randomized group comprising a randomized group identifier, a randomized group timestamp, a signed certificate, and a public/private key pair, and assigns the randomized group to the software 107. For example, the randomization group generator 121 of the electronic document server 104 can generate a randomization group, a signed certificate, and a public/private key pair, and assign the randomization group to the browser 107, as described above with respect to fig. 2. As described above, the electronic document server 104 is associated with a particular network domain.
The process 300 continues to step 3, where the electronic document server 104 provides the software 107 with a reply with the requested content and the randomized group, including the randomized group identifier, the randomized group timestamp, the signed certificate, and the public/private key pair, as described above with respect to fig. 2. For example, the electronic document server 104 can transmit a response including the requested image, the randomized group, the signed certificate, and the public/private key pair to the browser 107.
The process 300 continues to step 4 where the software 107 provides a subsequent request to the electronic document server 104 that the electronic document server 104 has previously published the randomized group to the software 107. The software 107 includes a randomized group identifier and an age bucket with its request. Com, the electronic document server 104 for the domain example image hosting platform can receive a request for a second image from the browser 107 along with an assigned randomized group identifier and randomized group age bucket.
Optionally, the user of software 107 can select a verification server to independently verify the privacy and/or statistical properties of the randomized group identifier associated with software 107, as described with respect to steps 5, 6 and 7.
Optionally, the verification server 130 can also authenticate the provided certificate before performing the verification process to determine that the provided randomized group identifier is assigned to the software 107 that is providing the certificate. For example, the verification server 130 can use a public/private key pair to determine that the provided randomized group identifier is assigned to the browser 107 that is providing the certificate.
The process 300 continues to step 7, where the validation server 130 provides the results of the validation process to the software 107. For example, the validation server 130 can output the raw quantities or the results of the statistical analysis to the browser 107 and a comparison to a threshold to determine if statistically anomalous or fraudulent activity has been detected or if a guaranteed level of privacy is protected for the browser 107.
Referring now to fig. 3B, a process 350 for publishing and implementing a monitoring mechanism for privacy protection of network activities performed across different domains is performed by the central trusted domain server 140 instead of the separate electronic document server 104. The randomization group issued by the trusted domain server 140 is global in scope. The process 350 begins at step 1, where an initial request from the software 107 is provided to the electronic document server 104. In some examples, the request may be forwarded to the electronic document server 104 through the DCDS 110, which is not illustrated in fig. 3B.
The process 350 continues to step 2, where the electronic document server 104 forwards the requested information to the trusted domain server 140. For example, the electronic document server 104 can receive a request for several lines of text from its field, exemplarTextandImageHostingPlatform. In this example, the browser 107 has not been assigned a randomization group and does not provide the randomization group to the electronic document server 104, and thus the request is an initial request.
The process 350 continues with step 3, where the trusted domain server 140 generates a randomized group comprising a randomized group identifier, a randomized group timestamp, a certificate, and a public/private key pair, and assigns the randomized group to the software 107. For example, the randomization group generator 142 of the trusted domain server 140 can generate a randomization group, a signed certificate, and a public/private key pair, and assign the randomization group to the browser 107, as described above with respect to fig. 2. As described above, trusted domain server 140 is not associated with a particular network domain and generates a globally randomized group that can be used across different domains.
The process 350 continues to step 4A, where the electronic document server 104 provides a reply to the software 107. For example, the electronic document server 104 can transmit a response including the requested text to the browser 107.
The process 350 continues to step 4B, where the trusted domain server 140 provides the software 107 with a randomized group, including a randomized group identifier, a randomized group timestamp, a certificate, and a public/private key pair. For example, the trusted domain server 140 can send the randomized group, the signed certificate, and the public/private key pair to the browser 107.
In some embodiments, steps 4A and 4B occur simultaneously. In some embodiments, steps 4A and 4B occur asynchronously.
The process 350 continues to step 5 where the software 107 provides a subsequent request to the electronic document server 104. Because the trusted domain server 140 has assigned a globally randomized group to the software 107, the software 107 includes a randomized group identifier and an age bucket with its request to the electronic document server 104. Com, the electronic document server 104 for the domain exemplartextandImageHostingPlatform can receive a request for an image from the browser 107 along with an assigned randomized group identifier and randomized group age bucket.
Optionally, the user of the software 107 can select a verification server to independently verify the privacy and/or statistical properties of the randomized group identifier associated with the software 107, as described with respect to steps 6, 7 and 8.
The process 350 continues to step 7, where the authentication server 130 performs an authentication process based on the certificate. For example, the validation server 130 can perform a validation process based on the certificate to determine statistical and/or privacy-preserving attributes of the randomized group identifier provided in the certificate.
Optionally, the verification server 130 can also authenticate the provided certificate to determine that the provided randomized group identifier is assigned to the software providing the certificate 107 prior to performing the verification process. For example, the authentication server 130 can use a public/private key pair to determine that the provided randomized group identifier is assigned to the browser 107 that provided the certificate. This protocol prevents the authentication server 130 from considering statistics from the browser 107 with forged or stolen certificates, improving the stability of the collected statistical activity data and reducing the resources selected for fraudulent use.
FIG. 4 is a flow diagram illustrating an example process 400 for publication and implementing a privacy-preserving monitoring mechanism. The operations of process 400 can be implemented, for example, by user device 106 and/or software 107, electronic document server 104, DCDS 110, authentication server 130, trusted domain server 140, and/or third party server 150. Process 400 can also be implemented as instructions stored on one or more computer-readable media, which can be non-transitory, and execution of the instructions by one or more data processing apparatus can cause the one or more data processing apparatus to perform the operations of process 400.
The process 400 continues with assigning to the application at a first time a randomized group generated based on the randomly selected identifier and a timestamp indicating the first time at which the randomized group was assigned to the application (404). For example, the electronic document server 104 can assign a randomized group of local scopes associated with domains to the browser 107, as described above with respect to fig. 1, 2, and 3A. In another example, trusted domain server 140 can assign a globally scoped randomized group to browser 107 that can be used, as described above with respect to fig. 1, 2, and 3B.
In some implementations, the process 400 can include: a second request for digital content is received from the application from the domain, and a obfuscated identifier is generated by the application at a second time to the domain based on the randomly selected identifier and a randomized group age bucket indicating an age range of a cookie containing an age of the randomized group, wherein the age of the randomized group is calculated from a difference between the second time and the first time. For example, the browser 107 can compute a randomized group age bucket based on randomized groups and/or certificates provided by the electronic document server 104 or the trusted domain server 140, as described above with respect to fig. 1, 2, and 3A-3B. In some embodiments, the obfuscated identifier includes a randomly selected identifier and a randomized group age bucket. In some embodiments, the obfuscated identifier includes data and parameters derived from a randomly selected identifier and/or a randomized group age bucket. For example, the obfuscation identifier may include parameters derived by: apply a multiplier, add a constant, or apply some other set of operations to the randomly selected identifier and/or randomized group age bucket. The obfuscated identifier can also include data and parameters other than a randomly selected identifier and a randomized group age bucket.
In some implementations, assigning the randomized group to the application includes assigning the randomized group to the application by a domain, wherein the randomly selected identifier is assigned by the domain to at least a threshold number of other applications, wherein the randomly selected identifier is a randomly generated identifier selected from two or more randomly generated identifiers, and wherein the unique public key is generated by the domain. For example, the electronic document server 104 can generate and assign randomized groups to the browsers 107 and ensure that randomized group identifiers are assigned by the electronic document server 104 to at least k-1 other browsers 107, wherein the randomized group identifiers are selected among two or more randomly generated identifiers, and wherein the unique public key is generated by the electronic document server 104, as described above with respect to fig. 1, 2, and 3A.
In some implementations, the process 400 includes providing, by the application, the certificate to the authentication system, and authenticating, by the authentication system, that the randomized group is assigned to at least a threshold number of people. For example, the authentication server 130 can determine the statistical and/or privacy attributes of the randomized group indicated in the certificate, as described above with respect to fig. 1, 2, and 3A.
In some embodiments, assigning the randomized group to the application comprises assigning the randomized group to the application by the central server, wherein the randomly selected identifier is assigned to at least a threshold number of other applications, wherein the randomly selected identifier is a randomly generated identifier selected from two or more randomly generated identifiers, and wherein the unique public key is generated by the central server. For example, the trusted domain server 140 can generate and assign a randomized group to the browser 107 and ensure that randomized group identifiers are assigned to at least k-1 other browsers 107, wherein the randomized group identifier is selected from two or more randomly selected generated identifiers, and wherein the unique public key is generated by the trusted domain server 140, as described above with respect to fig. 1, 2, and 3B.
In some embodiments, process 400 includes: providing, by an application, a request for digital content and a randomized group from a second domain different from the first domain; receiving, by the application from the second domain, an attestation request including a challenge in response to providing the request for the digital content from the second domain; and providing, by the application, the certificate to the verification system, the certificate triggering to cause the verification system to (i) create a obfuscated certificate comprising the randomly selected identifier, the randomized group age bucket, and the challenge, (ii) sign the obfuscated certificate, and (iii) provide the obfuscated certificate to the second domain, wherein the challenge is masked from the verification server using a blinding scheme. For example, authentication server 130 can generate an anonymous credential based on the attestation request, as described above with respect to fig. 1, 2, and 3B.
In some implementations, the process 400 includes detecting, by the domain based on the received randomized group age bucket, anomalous activity associated with the randomly selected identifier and at least one of: a number of interactions associated with the randomly selected identifier, a randomized group age distribution, and a probability distribution associated with a particular interaction and a particular time period. For example, the analyzer 123 of the electronic server 103 can detect anomalous activity associated with the randomized group identifier and/or the randomized group identifier/age bucket pair, as described above with respect to fig. 1, 2, and 3A-3B.
The present technology thus allows for tracking internet activity (e.g., to help prevent abuse or fraud) while helping to improve individual user privacy. Using randomized group identifiers assigned to multiple users and age buckets rather than a specific timestamp means that individual users associated with a given randomized group cannot be identified. Thus improving the privacy of the user. At the same time, the use of randomized group identifier/age bucket pairs provides sufficient statistical information over time to identify anomalies on internet activity that potentially indicate fraud. Further, by using an authentication system and challenge issued by a third party domain, the third party domain can verify the authenticity of the randomized group without acquiring identifiable information about the individual user. The present technology thus provides a stable way of combating abusive or fraudulent internet activity while helping to improve the privacy of individual users.
FIG. 5 is a block diagram of an example computer system 500 that can be used to perform the operations described above. The system 500 includes a processor 510, a memory 520, a storage device 530, and an input/output device 540. Each of the components 510, 520, 530, and 540 can be interconnected, for example, using a system bus 550. Processor 510 is capable of processing instructions for execution within system 500. In some implementations, the processor 510 is a single-threaded processor. In another implementation, the processor 510 is a multi-threaded processor. The processor 510 is capable of processing instructions stored in the memory 520 or on the storage device 530.
The storage device 530 is capable of providing mass storage for the system 500. In some implementations, the storage device 530 is a computer-readable medium. In various different implementations, the storage device 530 can include, for example, a hard disk device, an optical disk device, a storage device shared by multiple computing devices (e.g., cloud storage devices) over a network, or some other mass storage device.
The input/output device 540 provides input/output operations for the system 500. In some implementations, the input/output device 540 can include one or more of a network interface device, such as an ethernet card, a serial communication device, such as an RS-232 port, and/or a wireless interface device, such as an 802.11 card. In another embodiment, the input/output devices can include driver devices configured to receive input data and transmit output data to external devices 560, e.g., a keyboard, a printer, and a display device. However, other implementations can also be used, such as mobile computing devices, mobile communication devices, set-top box television client devices, and so forth.
Although an example processing system has been described in fig. 4, implementations of the subject matter and the functional operations described in this specification can be implemented in other types of digital electronic circuitry, or in computer software, firmware, or hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them.
Embodiments of the subject matter and the operations described in this specification can be implemented in digital electronic circuitry, or in computer software, firmware, or hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them. Embodiments of the subject matter described in this specification can be implemented as one or more computer programs, i.e., one or more circuits of computer program instructions, encoded on one or more computer storage media for execution by, or to control the operation of, data processing apparatus. Alternatively or in addition, the program instructions can be encoded on an artificially generated propagated signal, e.g., a machine-generated electrical, optical, or electromagnetic signal, that is generated to encode information for transmission to suitable receiver apparatus for execution by a data processing apparatus. The computer storage medium can be or be included in a computer-readable storage device, a computer-readable storage substrate, a random or serial access memory array or device, or a combination of one or more of them. In addition, while a computer storage medium is not a propagated signal, a computer storage medium can be a source or destination of computer program instructions encoded in an artificially generated propagated signal. The computer storage media can also be or be included in one or more separate physical components or media (e.g., multiple CDs, disks, or other storage devices).
The operations described in this specification can be implemented as operations performed by data processing apparatus on data stored on one or more computer-readable storage devices or received from other sources.
The term "data processing apparatus" encompasses all kinds of apparatus, devices, and machines for processing data, including by way of example a programmable processor, a computer, a system on a chip, or a plurality or combination of the foregoing. The apparatus can comprise special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit). The apparatus can include, in addition to hardware, code that creates an execution environment for the computer program in question, e.g., code that constitutes processor firmware, a protocol stack, a database management system, an operating system, a cross-platform runtime environment, a virtual machine, or a combination of one or more of them. The apparatus and execution environment are capable of implementing a variety of different computing model infrastructures, such as web services, distributed computing and grid computing infrastructures.
A computer program (also known as a program, software application, script, or code) can be written in any form of programming language, including compiled or interpreted languages, declarative or procedural languages, and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, object, or other unit suitable for use in a computing environment. A computer program may, but need not, correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data (e.g., one or more scripts stored in a markup language document), in a single file dedicated to the program in question, or in multiple coordinated files (e.g., files that store one or more modules, sub programs, or portions of code). A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network.
The processes and logic flows described in this specification can be performed by one or more programmable processors executing one or more computer programs to perform actions by operating on input data and generating output. The processes and logic flows can also be performed by, and apparatus can also be implemented as, special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit).
Processors suitable for the execution of a computer program include, by way of example, both general and special purpose microprocessors. Generally, a processor will receive instructions and data from a read-only memory or a random access memory or both. The essential elements of a computer are a processor for performing actions in accordance with the instructions and one or more memory devices for storing instructions and data. Generally, a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks. However, a computer need not have such devices. Moreover, a computer can be embedded in another device, e.g., a mobile telephone, a Personal Digital Assistant (PDA), a mobile audio or video player, a game console, a Global Positioning System (GPS) receiver, or a portable storage device (e.g., a Universal Serial Bus (USB) flash drive), to name a few. Devices suitable for storing computer program instructions and data include all forms of non-volatile memory, media and memory devices, including by way of example semiconductor memory devices, e.g., EPROM, EEPROM, and flash memory devices; magnetic disks, e.g., internal hard disks or removable disks; a magneto-optical disk; and CD-ROM and DVD-ROM disks. The processor and the memory can be supplemented by, or incorporated in, special purpose logic circuitry.
To provide for interaction with a user, embodiments of the subject matter described in this specification can be implemented on a computer having: a display device, e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor, for displaying information to a user; and a keyboard and a pointing device, such as a mouse or a trackball, by which a user can provide input to the computer. Other kinds of devices can also be used to provide for interaction with a user; for example, feedback provided to the user can be any form of sensory feedback, e.g., visual feedback, auditory feedback, or tactile feedback; also, input from the user can be received in any form, including acoustic, speech, or tactile input. Additionally, the computer can interact with the user by: sending or receiving a document to or from a device used by a user; for example, a web page is sent to a web browser on a user's client device in response to a request received from the web browser.
Embodiments of the subject matter described in this specification can be implemented in a computing system that includes a back-end component, e.g., as a data server, or that includes a middleware component, e.g., an application server, or that includes a front-end component, e.g., a client computer having a graphical user interface or a Web browser, or any combination of one or more such back-end, middleware, or front-end components through which a user can interact with an implementation of the subject matter described in this specification. The components of the system can be interconnected by any form or medium of digital data communication, e.g., a communication network. Examples of communication networks include local area networks ("LANs") and wide area networks ("WANs"), internetworks (e.g., the internet), and peer-to-peer networks (e.g., ad hoc peer-to-peer networks).
The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other. In some embodiments, the server transmits data (e.g., HTML pages) to the client device (e.g., for the purpose of displaying data to and receiving user input from a user interacting with the client device). Data generated at the client device (e.g., a result of the user interaction) can be received at the server from the client device.
While this specification contains many specific implementation details, these should not be construed as limitations on the scope of any inventions or of what may be claimed, but rather as descriptions of features specific to particular embodiments of particular inventions. Certain features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely, various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable subcombination. Furthermore, although features may be described above as acting in certain combinations and even initially claimed as such, one or more features from a claimed combination can in some cases be excised from the combination, and the claimed combination may be directed to a subcombination or variation of a subcombination.
Similarly, while operations are depicted in the drawings in a particular order, this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order, or that all illustrated operations be performed, to achieve desirable results. In some cases, multitasking and parallel processing may be advantageous. Moreover, the separation of various system components in the embodiments described above should not be understood as requiring such separation in all embodiments, and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.
Thus, particular embodiments of the subject matter have been described. Other embodiments are within the scope of the following claims. In some cases, the actions recited in the claims can be performed in a different order and still achieve desirable results. In addition, the processes depicted in the accompanying figures do not necessarily require the particular order shown, or sequential order, to achieve desirable results. In some embodiments, multitasking and parallel processing may be advantageous.
Claims (20)
1. A method for privacy-preserving network activity monitoring, comprising:
receiving a request for digital content from a domain from an application on a user device of a user;
assigning a randomization group to the application at a first time, the randomization group constructed based on a randomly selected identifier and a timestamp indicating the first time at which the randomization group was assigned to the application; and
providing to the application at the first time (i) a digitally signed certificate corresponding to the randomly selected identifier and the timestamp, and (ii) a unique public key and a corresponding unique private key associated with the certificate,
wherein the randomly selected identifier is also allocated to at least a threshold number of other applications executing on other user devices within a predetermined time period of allocating the randomized group to the application.
2. The method of claim 1, further comprising:
receiving a second request for digital content from the domain from the application; and
providing, by the application, a obfuscated identifier corresponding to the randomly selected identifier and a randomized group age bucket indicating an age range of cookies containing an age of the randomized group to the domain at a second time,
wherein the age of the randomized group is calculated based on a difference between the second time and the first time.
3. The method of claim 1 or 2, wherein allocating a randomized group to the application comprises:
assigning, by the domain, the randomized group to the application, an
Wherein the randomly selected identifiers are assigned to the at least a threshold number of other applications,
wherein the randomly selected identifier is a randomly generated identifier selected from two or more randomly generated identifiers, and
wherein the unique public key is generated by the domain.
4. The method of claim 1 or 2, wherein assigning a randomized group to the browser comprises:
assigning, by a central server, the randomized group to the application;
wherein the randomly selected identifiers are assigned to the at least a threshold number of other applications,
wherein the randomly selected identifier is a randomly generated identifier selected from two or more randomly generated identifiers, and
wherein the unique public key is generated by the central server.
5. The method of any preceding claim, further comprising:
providing, by the application, a request for digital content and the randomized group from a second domain different from the first domain;
receiving, by the application from the second domain, an attestation request including a challenge in response to providing the request for digital content from the second domain; and
providing, by the application, the digitally signed certificate to a verification system, the digitally signed certificate triggering the verification system to (i) create a obfuscated certificate including the randomly selected identifier, the randomized group age bucket, and the challenge, (ii) sign the obfuscated certificate, and (iii) provide the obfuscated certificate to the second domain,
wherein the challenge is masked from the verification system using a blinding scheme.
6. The method of any preceding claim, further comprising:
providing, by the application, the digitally signed certificate to a verification system; and
verifying, by the verification system, that the randomized group is assigned to at least a threshold number of people.
7. The method of claim 2, further comprising:
detecting, by the domain based on the received randomized group age bucket, anomalous activity associated with the randomly selected identifier and at least one of: a number of interactions associated with the randomly selected identifier, a randomized group age distribution, and a probability distribution associated with a particular interaction and a particular time period.
8. A system, comprising:
one or more processors; and
one or more memory elements comprising instructions that, when executed, cause the one or more processors to perform operations comprising:
receiving a request for digital content from a domain from an application on a user device of a user;
assigning a randomization group to the application at a first time, the randomization group constructed based on a randomly selected identifier and a timestamp indicating the first time at which the randomization group was assigned to the application; and
providing to the application at the first time (i) a digitally signed certificate corresponding to the randomly selected identifier and the timestamp, and (ii) a unique public key and a corresponding unique private key associated with the certificate,
wherein the randomly selected identifier is also allocated to at least a threshold number of other applications executing on other user devices within a predetermined time period of allocating the randomized group to the application.
9. The system of claim 8, the operations further comprising:
receiving a second request for digital content from the domain from the application; and
providing, by the application, to the domain at a second time, a obfuscated identifier corresponding to the randomly selected identifier and a randomized group age bucket indicating an age range of cookies containing an age of the randomized group,
wherein the age of the randomized group is calculated based on a difference between the second time and the first time.
10. The system of claim 8 or 9, wherein assigning a randomized group to the application comprises:
assigning, by the domain, the randomized group to the application, an
Wherein the randomly selected identifiers are assigned to the at least a threshold number of other applications,
wherein the randomly selected identifier is a randomly generated identifier selected from two or more randomly generated identifiers, and
wherein the unique public key is generated by the domain.
11. The system of claim 8 or 9, wherein assigning a randomized group to the browser comprises:
assigning, by a central server, the randomized group to the application;
wherein the randomly selected identifiers are assigned to the at least a threshold number of other applications,
wherein the randomly selected identifier is a randomly generated identifier selected from two or more randomly generated identifiers, and
wherein the unique public key is generated by the central server.
12. The system of any preceding claim, the operations further comprising:
providing, by the application, a request for digital content and the randomized group from a second domain different from the first domain;
receiving, by the application from the second domain, an attestation request including a challenge in response to providing the request for digital content from the second domain; and
providing, by the application, the digitally signed certificate to a verification system, the digitally signed certificate triggering the verification system to (i) create a fuzzy certificate including the randomly selected identifier, the randomized group age bucket, and the challenge, (ii) sign the fuzzy certificate, and (iii) provide the fuzzy certificate to the second domain,
wherein the challenge is masked from the verification system using a blinding scheme.
13. The system of any preceding claim, the operations further comprising:
providing, by the application, the digitally signed certificate to a verification system; and
verifying, by the verification system, that the randomized group is assigned to at least a threshold number of people.
14. The system of claim 9, the operations further comprising:
detecting, by the domain based on the received randomized group age bucket, anomalous activity associated with the randomly selected identifier and at least one of: a number of interactions associated with the randomly selected identifier, a randomized group age distribution, and a probability distribution associated with a particular interaction and a particular time period.
15. A non-transitory computer storage medium encoded with instructions that, when executed by a distributed computing system, cause the distributed computing system to perform operations comprising:
receiving a request for digital content from a domain from an application on a user device of a user;
assigning a randomization group to the application at a first time, the randomization group constructed based on a randomly selected identifier and a timestamp indicating the first time at which the randomization group was assigned to the application; and
providing, to the application at the first time, (i) a digitally signed certificate corresponding to the randomly selected identifier and the timestamp, and (ii) a unique public key and a corresponding unique private key associated with the certificate,
wherein the randomly selected identifier is also allocated to at least a threshold number of other applications executing on other user devices within a predetermined time period of allocating the randomized group to the application.
16. The non-transitory computer storage medium of claim 15, the operations further comprising:
receiving a second request for digital content from the domain from the application; and
providing, by the application, to the domain at a second time, a obfuscated identifier corresponding to the randomly selected identifier and a randomized group age bucket indicating an age range of cookies containing an age of the randomized group,
wherein the age of the randomized group is calculated based on a difference between the second time and the first time.
17. The non-transitory computer storage medium of claim 15 or 16, wherein assigning a randomized group to the application comprises:
assigning, by the domain, the randomized group to the application, an
Wherein the randomly selected identifiers are assigned to the at least a threshold number of other applications,
wherein the randomly selected identifier is a randomly generated identifier selected from two or more randomly generated identifiers, and
wherein the unique public key is generated by the domain.
18. The non-transitory computer storage medium of claim 15 or 16, wherein assigning a randomized group to the browser comprises:
assigning, by a central server, the randomized group to the application;
wherein the randomly selected identifiers are assigned to the at least a threshold number of other applications,
wherein the randomly selected identifier is a randomly generated identifier selected from two or more randomly generated identifiers, and
wherein the unique public key is generated by the central server.
19. The non-transitory computer storage medium of any preceding claim, the operations further comprising:
providing, by the application, a request for digital content and the randomized group from a second domain different from the first domain;
receiving, by the application from the second domain, an attestation request including a challenge in response to providing the request for digital content from the second domain; and
providing, by the application, the digitally signed certificate to a verification system, the digitally signed certificate triggering the verification system to (i) create a obfuscated certificate including the randomly selected identifier, the randomized group age bucket, and the challenge, (ii) sign the obfuscated certificate, and (iii) provide the obfuscated certificate to the second domain,
wherein the challenge is masked from the verification system using a blinding scheme.
20. The system of any of the preceding claims, the operations further comprising:
providing, by the application, the digitally signed certificate to a verification system; and
verifying, by the verification system, that the randomized group is assigned to at least a threshold number of people.
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
PCT/US2021/020694 WO2022186831A1 (en) | 2021-03-03 | 2021-03-03 | Privacy-preserving activity aggregation mechanism |
Publications (1)
Publication Number | Publication Date |
---|---|
CN115380506A true CN115380506A (en) | 2022-11-22 |
Family
ID=75223443
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202180019433.XA Pending CN115380506A (en) | 2021-03-03 | 2021-03-03 | Privacy-preserving activity aggregation mechanism |
Country Status (6)
Country | Link |
---|---|
US (1) | US20230163978A1 (en) |
EP (1) | EP4094402A1 (en) |
JP (1) | JP7475472B2 (en) |
KR (1) | KR20220137955A (en) |
CN (1) | CN115380506A (en) |
WO (1) | WO2022186831A1 (en) |
Families Citing this family (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11888825B1 (en) * | 2021-08-09 | 2024-01-30 | Google Llc | Privacy preserving user group expansion |
Family Cites Families (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
GB2380368B (en) * | 2001-09-27 | 2005-06-22 | Ibm | A method and system for communication via a computer network |
US9009258B2 (en) | 2012-03-06 | 2015-04-14 | Google Inc. | Providing content to a user across multiple devices |
US10445769B2 (en) | 2013-12-24 | 2019-10-15 | Google Llc | Systems and methods for audience measurement |
US10771265B2 (en) * | 2017-09-21 | 2020-09-08 | Lg Electronics, Inc. | Cryptographic methods and systems for managing digital certificates with linkage values |
EP3900300A1 (en) * | 2019-08-13 | 2021-10-27 | Google LLC | Securing browser cookies |
-
2021
- 2021-03-03 WO PCT/US2021/020694 patent/WO2022186831A1/en unknown
- 2021-03-03 CN CN202180019433.XA patent/CN115380506A/en active Pending
- 2021-03-03 US US17/798,604 patent/US20230163978A1/en active Pending
- 2021-03-03 EP EP21714510.1A patent/EP4094402A1/en active Pending
- 2021-03-03 JP JP2022554359A patent/JP7475472B2/en active Active
- 2021-03-03 KR KR1020227030754A patent/KR20220137955A/en unknown
Also Published As
Publication number | Publication date |
---|---|
JP7475472B2 (en) | 2024-04-26 |
JP2023524360A (en) | 2023-06-12 |
US20230163978A1 (en) | 2023-05-25 |
WO2022186831A1 (en) | 2022-09-09 |
KR20220137955A (en) | 2022-10-12 |
EP4094402A1 (en) | 2022-11-30 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
KR102219277B1 (en) | System and method for controlling the delivery of authenticated content | |
JP7376727B2 (en) | Verifying cryptographically secure requests | |
CN113015974A (en) | Verifiable consent for privacy protection | |
US11949688B2 (en) | Securing browser cookies | |
CN114731273A (en) | Cryptographically secure data protection | |
US11831651B2 (en) | Preventing data manipulation and protecting user privacy in determining accurate location event measurements | |
JP2023096089A (en) | Pseudonym event certification by group signature | |
JP7475472B2 (en) | A privacy-preserving activity aggregation mechanism | |
KR102639228B1 (en) | Anonymous event proof | |
JP7157258B2 (en) | Fraud Prevention in Aggregated Network Measurements | |
EP4042665B1 (en) | Preventing data manipulation in telecommunication network measurements | |
CN116034596A (en) | Anonymous authentication with token redemption |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination |