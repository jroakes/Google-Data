CN112823345A - Ranking image search results using machine learning models - Google Patents
Ranking image search results using machine learning models Download PDFInfo
- Publication number
- CN112823345A CN112823345A CN201980066763.7A CN201980066763A CN112823345A CN 112823345 A CN112823345 A CN 112823345A CN 201980066763 A CN201980066763 A CN 201980066763A CN 112823345 A CN112823345 A CN 112823345A
- Authority
- CN
- China
- Prior art keywords
- image search
- image
- search results
- ranking
- features
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/903—Querying
- G06F16/90335—Query processing
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/50—Information retrieval; Database structures therefor; File system structures therefor of still image data
- G06F16/53—Querying
- G06F16/538—Presentation of query results
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/50—Information retrieval; Database structures therefor; File system structures therefor of still image data
- G06F16/58—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually
- G06F16/583—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using metadata automatically derived from the content
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/95—Retrieval from the web
- G06F16/953—Querying, e.g. by the use of web search engines
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/084—Backpropagation, e.g. using gradient descent
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N20/00—Machine learning
- G06N20/20—Ensemble learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N5/00—Computing arrangements using knowledge-based models
- G06N5/01—Dynamic search techniques; Heuristics; Dynamic trees; Branch-and-bound
Abstract
Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for ranking image search results using a machine learning model. In one aspect, a method comprises: receiving an image search query from a user device; obtaining a plurality of candidate image search results; for each of the candidate image search results: processing (i) features of the image search query and (ii) features of a respective image identified by the candidate image search result using an image search result ranking machine learning model to generate a relevance score that measures the relevance of the candidate image search result to the image search query; ranking the candidate image search results based on the relevance scores; generating an image search result presentation; and providing the image search results for presentation by the user device.
Description
Cross Reference to Related Applications
This application claims priority to U.S. patent application No. 16/263,398 filed on 31/2019, which claims priority to U.S. provisional application No. 62/783,134 filed on 20/12/2018. The disclosure of the prior application is considered part of the disclosure of the present application and is incorporated by reference into the disclosure of the present application.
Background
This specification relates generally to ranking (rank) image search results.
Online search engines typically rank resources (e.g., images) in response to a received search query to present search results that identify the resources that are responsive to the search query. Search engines typically present search results in a rank-defined order. The search engine may rank the resources based on various factors, i.e., based on various search engine ranking signals, and using various ranking techniques.
Some conventional image search engines (i.e., search engines configured to identify images on a landing page (e.g., on a web page of the Internet) in response to received search queries) generate separate (separate) signals from i) features of the images and ii) features of the landing page, and then combine the separate signals according to the same fixed weighting scheme for each received search query.
Disclosure of Invention
This specification describes techniques for generating relevance values for image-landing page pairs and ranking image search results based on relevance scores for corresponding image search queries.
In one aspect, an image search query is received from a user device; obtaining a plurality of candidate image search results for the image search query, each candidate image search result identifying a respective image and a respective landing page for the respective image; for each of the candidate image search results: processing (i) features of the image search query, (ii) features of respective images identified by the candidate image search results, and (iii) features of respective landing pages identified by the candidate image search results using the trained image search result ranking machine learning model to generate a relevance score that measures a relevance of the candidate image search results to the image search query; ranking the candidate image search results based on the relevance scores generated by the image search result ranking machine learning model; generating an image search result presentation showing candidate image search results ranked according to the ranking; and providing the image search results for presentation by the user device. Other embodiments of this aspect include corresponding computer systems, apparatus, and computer programs recorded on one or more computer storage devices, each configured to perform the actions of the methods. For a system of one or more computers to be configured to perform a particular operation or action, it is meant that the system has installed thereon software, firmware, hardware, or a combination thereof that in operation causes the system to perform the operation or action. For one or more computer programs to be configured to perform particular operations or actions, it is meant that the one or more programs include instructions that, when executed by a data processing apparatus, cause the apparatus to perform the operations or actions.
The subject matter described in this specification can be implemented in particular embodiments to realize one or more of the following advantages. Ranking pairs of image search queries based on relevance scores generated by a machine learning model improves relevance of image search results responsive to the image search queries. Unlike conventional methods of ranking resources, the machine learning model receives a single input that includes features of an image identified by a given image search result, features of a landing page, and features of an image search query, and predicts the relevance of the image search result to the received query. This allows the machine learning model to give higher weight to landing page features or image features in a query-specific manner, thereby improving the quality of the image search results returned to the user. In particular, by using the described machine learning model, the described image search engine does not apply the same fixed weighting scheme to landing page features and image features for each received query, and instead combines landing page features and image features in a query-dependent manner.
Further, the trained machine learning model can easily and optimally adjust the weights assigned to the various features based on changes in the initial signal distribution or additional features. Conventionally, a great deal of engineering work is required to adjust the weights of a conventional manual tuning model based on changes in the initial signal distribution. However, it is significantly easier to adjust the weights of the trained machine learning model based on changes in the signal distribution, thereby improving the ease of maintenance of the image search engine. Furthermore, if a new feature is added, the manual tuning function adjusts the function for the new feature, i.e. the loss function, independently of the goal, while keeping the existing feature function constant. Without adjusting the existing feature functions with respect to the new features, the model becomes less ideal (less optimal) with respect to the final goal. However, if new features are added, the trained machine learning model may automatically adjust the feature weights. The machine learning model may include the new features and rebalance all of its existing weights appropriately to optimize against the final goal. Accordingly, the accuracy, efficiency, and maintenance of the image search engine may be improved.
The details of one or more embodiments of the subject matter of this specification are set forth in the accompanying drawings and the description below. Other features, aspects, and advantages of the subject matter will become apparent from the description, the drawings, and the claims.
Drawings
FIG. 1A is a block diagram of an example search system.
FIG. 1B is a block diagram of an example search system for generating a relevance (relevance) score from an image, a landing page, and query features.
FIG. 2 is a flow diagram of an example process for generating image search results from an image search query submitted by a user.
FIG. 3 is a flow diagram of an example process for training a machine learning model to generate relevance scores for image-landing page pairs for an image search query.
Like reference numbers and designations in the various drawings indicate like elements.
Detailed Description
FIG. 1A illustrates an example image search system 114. The image search system 114 is an example of an information retrieval (retrieval) system in which the systems, components, and techniques described below may be implemented.
The user 102 may interact with the image search system 114 through the user device 104. For example, the user device 104 may be a computer coupled to the image search system 114 through a data communication network 112 (e.g., a Local Area Network (LAN) or a Wide Area Network (WAN), such as the internet or a combination of networks). In some cases, the image search system 114 may be implemented on the user device 104, for example, if the user has installed an application on the user device 104 that performs the search. The user device 104 will typically include a memory, such as Random Access Memory (RAM)106, for storing instructions and data, and a processor 108 for executing the stored instructions. The memory may include read-only memory and writable memory.
The image search system 114 is configured to search a collection of images. Typically, the images in the collection are images found on web pages on the internet or a private network (e.g., an Intranet). The web page on which the image is found (i.e., the web page in which the image is included) will be referred to as a landing page for the image in this specification.
The user 102 may submit a search query 110 to the image search system 114 using the user device 104. When the user 102 submits the search query 110, the search query 110 is sent to the image search system 114 over the network 112.
When the image search system 114 receives the search query 110, the search engine 130 within the image search system 114 identifies image-landing page pairs that satisfy the search query 110, and responds to the query 110 by generating search results 128 that each identify a corresponding image-landing page pair that satisfies the search query 110. Each image-landing page pair includes an image and a landing page on which the image is found. For example, the image search results may include a lower resolution version of the image or crop (crop) from the image and data identifying the landing page, e.g., a resource locator of the landing page, a title of the landing page, or other identifying information. The image search system 114 sends the search results 128 to the user device 104 over the network 112 for presentation to the user 102, i.e., in a form that can be presented to the user 102.
The search engine 130 may include an index engine 132 and a ranking engine 134. The indexing engine 132 indexes (index) the image-landing page pairs and adds the indexed image-landing page pairs to the index database 122. That is, the index database 122 includes data identifying images, and a corresponding landing page for each image.
The index database 122 also associates image-landing page pairs with: (i) features of an image search query; (ii) features of the image, i.e., features that characterize the image; and (iii) characteristics of the landing page, i.e., characteristics that characterize the landing page. Examples of the features of the images and landing pages will be described in more detail below. Optionally, the index database 122 also associates indexed image-landing page pairs in the set of image-landing pairs with values of image search engine ranking signals for the indexed image-landing page pairs. The ranking engine 134 uses each image search engine ranking signal in ranking image-landing page pairs in response to a received search query.
The ranking engine 134 generates respective ranking scores for image-landing page pairs indexed in the index database 122 based on values of image search engine ranking signals (e.g., signals accessed from the index database 122 or signals calculated at query time) for the image-landing page pairs, and ranks the image-landing page pairs based on the respective ranking scores. The ranking score for a given image-landing page pair reflects the relevance of the image-landing page pair to the received search query 110, the quality of the given image-landing page pair, or both.
The image search engine 130 may use the machine learning model 150 to rank image-landing page pairs in response to received search queries.
The machine learning model 150 is a machine learning model configured to receive inputs and generate relevance scores that measure the relevance of candidate image search results to an image search query, the inputs including: (i) features of an image search query; (ii) a characteristic of the image; and (iii) a characteristic of a landing page of the image. Once the machine learning model 150 generates the relevance scores for the image-landing page pairs, the ranking engine 134 may then use the relevance scores to generate ranking scores for the image-landing page pairs in response to the received search query.
In some implementations, the ranking engine 134 generates an initial ranking score for each of the plurality of image-landing page pairs using the signals in the index database 122. The ranking engine 134 may then select a number of the highest scoring image-landing page pairs for processing by the machine learning model 150. The ranking engine 134 may then rank the candidate image-landing page pairs based on the relevance scores generated by the machine learning model 150, or adjust the initial ranking scores of the candidate image-landing page pairs using the relevance scores as an additional signal.
The machine learning model 150 may be any of a variety of machine learning models. For example, the machine learning model 150 may be a deep machine learning model, e.g., a neural network including multiple layers of nonlinear operation. As another example, the machine learning models may be different types of machine learning models, such as generalized linear models (generalized linear models), random forests, decision tree models, and so forth.
Ranking image-landing page pairs using a machine learning model will be described in more detail below with reference to fig. 2 and 3.
To train the machine learning model 150 such that the relevance scores for image-landing page pairs in the index database 122 can be accurately generated using the machine learning model 150, the image search system 114 includes a training engine 160. The training engine 160 trains the machine learning model 150 on training data generated using image-landing page pairs that have been associated with a true (ground true) or known value of the relevance score. Training the machine learning model will be described in more detail below with reference to fig. 3.
FIG. 1B illustrates an example of a machine learning model 136 that generates relevance scores 180 for particular image search results from images, landing pages, and query features.
In the example of FIG. 1B, a user submits an image search query 170. The system generates image query features 172 based on the image search query 170 submitted by the user. An example of query features 172 is described below with reference to FIG. 2.
The system also generates or obtains landing page features 174 for the landing page identified by the particular image search result and image features 176 for the image identified by the particular image search result. Examples of landing page features 174 and image features 176 are described below with reference to FIG. 2. The system then provides query features 172, landing page features 174, and image features 176 as input to the machine learning model 136.
In particular, the machine learning model 136 receives a single input that includes features of the image search query, features of the landing page, and features of the image, and predicts the relevance of a particular image search result to the user image query 170, i.e., a relevance score 180. This allows the machine learning model to give higher weight to landing page features 174, image features 176, or image search query features 172 in a query-specific manner, thereby improving the quality of the image search results returned to the user.
FIG. 2 is a flow diagram of an example process for generating image search results from an image search query submitted by a user. For convenience, process 200 is described as being performed by a system of one or more computers located at one or more locations. For example, an image search system suitably programmed in accordance with the subject specification, such as image search system 114 of FIG. 1A, may perform process 200.
The image search system receives an image search query from a user device (step 202). In some cases, the image search query is submitted through a dedicated image search interface provided by the image search system, i.e., a user interface for submitting the image search query. In other cases, the search query is submitted via a general purpose (generic) internet search interface, and the image search results are displayed along with other types of search results (i.e., search results that identify other types of content available on the internet) in response to the image search query.
Upon receiving the image search query, the image search system identifies an initial image-landing page pair that satisfies the image search query (step 204). For example, the system may identify an initial image-landing page pair from pairs indexed in a search engine index database based on signals measuring the quality of the pair, the relevance of the pair to a search query, or both.
For each pair, the system identifies (i) features of the image search query, (ii) features of the image, and (iii) features of the landing page (step 206). This may come from an index database, or may come from other data maintained by the system that associates images and landing pages with corresponding features.
For example, the features of the image may include vectors representing the content of the image. The image is processed through an embedded neural network, and a vector representing the image can be obtained. Alternatively, the vector may be generated by other image processing techniques for feature extraction. Example feature extraction techniques include edge, corner, bump, and blob (blob) detection. As another example, the feature vectors may include vectors generated using shape extraction techniques (e.g., thresholding, template matching, etc.). Alternatively or additionally to the feature vector, when the machine learning model is a neural network, the features may comprise pixel data of the image.
Examples of features extracted from a landing page include: date of first crawl (crawl) or update of the page, data characterizing the author of the landing page, language of the landing page, characteristics of the domain to which the landing page belongs, keywords representing the content of the landing page, characteristics of the links to the image and the landing page (e.g., anchor text or source page of the links), characteristics describing the context of the image in the landing page, and so forth.
Examples of features extracted from the landing page that describe the context of the image in the landing page include data characterizing the position of the image within the landing page, the saliency of the image on the landing page (science), textual descriptions of the image on the landing page, and so forth. The location of the image within the landing page can be accurately found (pin-point) using a pixel-based geometric location in the horizontal and vertical dimensions, a length (e.g., in inches) based on the user device in the horizontal and vertical dimensions, an XPATH-like identifier based on the HTML/XML DOM, a CSS-based selector, and the like. The prominence of an image on a landing page may be measured using the relative sizes of the images displayed on the generic device and the specific user device. The textual description of the image on the landing page may include a substitute text label for the image, text surrounding the image, and the like.
Examples of characteristics of an image search query may include the language of the search query, some or all of the terms in the search query, the time at which the search query was submitted, the location at which the search query was submitted, data characterizing the user device from which the query was received, and so forth.
These features may be classified or represented discretely. Furthermore, additional relevant features may be created by pre-existing features. For example, the system may create a relationship between one or more features by a combination of addition, multiplication, or other mathematical operations.
For each image-landing page pair, the system processes the features using an image search result ranking machine learning model to generate a relevance score output (step 208). The relevance score measures the relevance of the candidate image search result to the image search query. In one example, the relevance score of a candidate image search result measures the likelihood that a user submitting a search query will click on or otherwise interact with the search result. A higher relevance score indicates that the user submitting the search query will consider the candidate image search more relevant and click on it. In another example, the relevance score of a candidate image search result may be a prediction of a score that would be produced by a human rater to measure the quality of the results of the image search query. Training the machine learning model to generate an accurate relevance score is described below with reference to fig. 3.
As described above, the ranking machine learning model may be any of a variety of machine learning models.
The system ranks the image search results based on the relevance scores for the respective image search result-landing page pairs (step 210).
In some implementations, the system ranks the image search results in order based on relevance scores, i.e., search results with higher relevance scores are higher in the ranking.
In some other implementations, the system adjusts the initial ranking score of the image search results based on the relevance score, i.e., to promote (promote) search results with higher relevance scores, demote (demote) search results with lower relevance scores, or both. For example, the system may use the relevance scores of the search results to determine a modification factor (modification factor) for each search result. The system may then apply a correction factor to the initial ranking score of the search result, for example, by adding the correction factor to the initial ranking score, or multiplying the initial ranking score by the correction factor, to generate a final ranking score and then rank the initial search result in accordance with the final ranking score.
The system generates an image search result presentation showing the image search results according to the rankings (step 212), and provides the image search result presentation for presentation by sending the search result presentation to a user device from which the image search query was received in a form capable of presentation to the user via a network (step 214).
Fig. 3 is a flow diagram of an example process 300 for training a ranking machine learning model. For convenience, process 300 is described as being performed by a system of one or more computers located at one or more locations. For example, an image search system suitably programmed in accordance with the subject specification, such as the image search system 114 of FIG. 1A, may perform the process 300.
The system receives a set of training image search queries and, for each training image search query, trains image search results for the query that are each associated with a true relevance score (step 302). A true relevance score is a relevance score that the machine learning model should generate for an image search result. For example, when the relevance score measures a likelihood that a user will select a search result in response to a given search query, each true value relevance score may identify whether the user submitting the given search query actually selected an image search result, or a proportion of the number of times the user submitting the given search query actually selected an image search result. As another example, when the relevance score generated by the model is a prediction of the score that would be assigned to an image search result by a person, the true value relevance score is the actual score assigned to the search result by the human rater.
For each of the training image search queries, the system generates features for each associated image-landing page pair (step 304).
For each pair, the system identifies (i) features of the image search query, (ii) features of the image, and (iii) features of the landing page. Extracting, generating, and selecting features may occur prior to training or using the machine learning model. Examples of features are described above with reference to fig. 2.
The ranking engine trains a ranking machine learning model by, for each image search query, processing (i) features of the image search query, (ii) features of the respective image identified by the candidate image search results, and (iii) features of the respective landing page identified by the candidate image search results and respective true value associations that measure the association of the candidate image search results with the image search query (step 306).
The system trains the machine learning model in a manner appropriate to the type of machine learning model used to minimize the loss function. For example, if the model is a neural network, the system may train the neural network model to determine trained weight values for the neural network from the initial weight values by: the neural network training process is repeatedly performed to compute a gradient of the loss function with respect to the weights, e.g., using back propagation, and updates to the weights are determined from the gradient, e.g., using update rules corresponding to the neural network training process.
The system may use any of a variety of loss functions in training the machine learning model.
Examples of loss functions that may be used to train the model include pairwise (pairwise) loss, pointwise (pointwise) loss, and list (listwise) loss functions.
The pairwise loss function evaluates two input image search results. Pairwise penalties attempt to minimize inversion or incorrect estimation of the relevance ordering of pairs compared to the true value. That is, when a pairwise loss function is used, the model is trained to generate scores for pairs of search results such that the model assigns higher relevance scores to search results having higher true relevance scores. In each training step, the system processes features of each image search result of a pair of image search results using a machine learning model to generate respective predicted relevance scores for the two search results of the pair. Thereafter, when the ordering of the relevance of the pair by the predicted relevance score does not match the ordering of the relevance of the pair by the true relevance score, the system adjusts the weight of the machine learning model to penalize (penalize) the model.
The point-by-point loss function evaluates a single search image result. That is, when using a point-by-point loss function, the model is trained to generate scores for search results that match the truth scores. In each training step, the system processes features of a single image search result using a machine learning model to generate a predicted relevance score for the image search result. The system then adjusts the weights of the machine learning model to penalize the model for the deviation between the predicted relevance score and the true relevance score.
The list loss function evaluates the list of image search results to find the best relevancy ranking, i.e., the relevancy ranking that matches the ranking of the search results by a true relevancy score. That is, in each training step, the system processes the features of each search result in the search result list using a machine learning model to generate a respective predicted relevance score for each search result. Then, when the ranking of the search results by the predicted relevance score deviates from the ranking of the search results by the true relevance score, the system adjusts the weight values of the models to penalize the models.
The term "configured" is used in this specification in connection with system and computer program components. For a system of one or more computers to be configured to perform a particular operation or action, it is meant that the system has installed thereon software, firmware, hardware, or a combination thereof that in operation causes the system to perform the operation or action. For one or more computer programs to be configured to perform particular operations or actions, it is meant that the one or more programs include instructions that, when executed by a data processing apparatus, cause the apparatus to perform the operations or actions.
Embodiments of the subject matter and the functional operations described in this specification can be implemented in digital electronic circuitry, tangibly embodied in computer software or firmware, computer hardware, including the structures disclosed in this specification and their structural equivalents, or in one or more of them. Embodiments of the subject matter described in this specification can be implemented as one or more computer programs, i.e., one or more modules of computer program instructions encoded on a tangible, non-transitory storage medium for execution by, or to control the operation of, data processing apparatus. The computer storage medium may be a machine-readable storage device, a machine-readable storage substrate, a random or serial access memory device, or a combination of one or more of them. Alternatively or additionally, the program instructions may be encoded on an artificially generated propagated signal, e.g., a machine-generated electrical, optical, or electromagnetic signal, that is generated to encode information for transmission to suitable receiver apparatus for execution by the data processing apparatus.
The term "data processing apparatus" refers to data processing hardware and includes various devices, apparatus, and machines for processing data, including by way of example a programmable processor, a computer, or multiple processors or computers. An apparatus may also be, or further comprise, special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit). The apparatus can optionally include, in addition to hardware, code that creates an execution environment for the computer program, e.g., code that constitutes processor firmware, a protocol stack, a database management system, an operating system, or a combination of one or more of them.
A computer program, which may also be referred to or described as a program, software application, App (application), module, software module, script, or code, can be written in any form of programming language, including compiled or interpreted languages, or declarative or procedural languages; and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, or other unit suitable for use in a computing environment. A program may, but need not, correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data, such as in one or more scripts in a markup language document, in a single file dedicated to the program in question, or in multiple coordinated files, such as files that store one or more modules, sub programs, or portions of code. A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a data communication network.
In this specification, the term "database" is used broadly to refer to any collection of data: the data need not be structured in any particular way or at all, and the data may be stored in storage at one or more locations. Thus, for example, an index database may include multiple data sets, each of which may be organized and accessed differently.
Similarly, in this specification, the term "engine" is used broadly to refer to a software-based system, subsystem, or process that is programmed to perform one or more particular functions. Typically, the engine will be implemented as one or more software modules or components installed on one or more computers at one or more locations. In some cases, one or more computers will be dedicated to a particular engine; in other cases, multiple engines may be installed and run on the same computer or computers.
The processes and logic flows described in this specification can be performed by one or more programmable computers executing one or more computer programs to perform functions by operating on input data and generating output. The processes and logic flows can also be performed by, and in combination with, special purpose logic circuitry, e.g., an FPGA or an ASIC.
A computer adapted to execute a computer program may be based on a general purpose or special purpose microprocessor or both, or on any other type of central processing unit. Generally, a central processing unit will receive instructions and data from a read-only memory or a random access memory or both. The essential elements of a computer are a central processing unit for executing or executing instructions and one or more memory devices for storing instructions and data. The central processing unit and the memory can be supplemented by, or incorporated in, special purpose logic circuitry. Generally, a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks. However, a computer need not have such devices. Further, the computer may be embedded in another device, e.g., to name a few: a mobile phone, a Personal Digital Assistant (PDA), a mobile audio or video player, a game console, a Global Positioning System (GPS) receiver, or a portable storage device, such as a Universal Serial Bus (USB) flash drive.
Computer-readable media suitable for storing computer program instructions and data include all forms of non-volatile memory, media and memory devices, including by way of example semiconductor memory devices, e.g., EPROM, EEPROM, and flash memory devices; magnetic disks, such as internal hard disks or removable disks; magneto-optical disks; and CD ROM and DVD-ROM disks.
To provide for interaction with a user, embodiments of the subject matter described in this specification can be implemented on a computer having a display device, e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor, for displaying information to the user and a keyboard and a pointing device, e.g., a mouse or a trackball, by which the user can provide input to the computer. Other types of devices may also be used to provide for interaction with a user; for example, feedback provided to the user can be any form of sensory feedback, such as visual feedback, auditory feedback, or tactile feedback; and input from the user, including acoustic, speech, or tactile input, may be received in any form. Further, the computer may interact with the user by sending documents to and receiving documents from the device used by the user; for example, by sending a web page to a web browser on the user device in response to a request received from the web browser. In addition, the computer may interact with the user by sending text messages or other forms of messages to a personal device, such as a smartphone running a messaging application, and receiving response messages from the user in return.
The data processing apparatus for implementing the machine learning model may further comprise, for example, a dedicated hardware accelerator unit for processing the common and computationally intensive parts of the machine learning training or production, i.e. reasoning, workload.
The machine learning model may be implemented and deployed using a machine learning framework, such as a TensorFlow framework, a Microsoft Cognitive Toolkit framework, an Apache Singa framework, or an Apache MXNet framework.
Embodiments of the subject matter described in this specification can be implemented in a computing system that includes a back-end component, e.g., as a data server, or that includes a middleware component, e.g., an application server, or that includes a front-end component, e.g., a client computer having a graphical user interface, a web browser, or an app through which a user can interact with an implementation of the subject matter described in this specification, or any combination of one or more such back-end, middleware, or front-end components. The components of the system can be interconnected by any form or medium of digital data communication, e.g., a communication network. Examples of communication networks include a Local Area Network (LAN) and a Wide Area Network (WAN), such as the Internet.
The computing system may include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other. In some embodiments, the server sends data (e.g., HTML pages) to the user device, e.g., for displaying the data to a user interacting with the device acting as a client, and receives user input from the user. Data generated at the user device, e.g., a result of the user interaction, may be received at the server from the device.
While this specification contains many specific implementation details, these should not be construed as limitations on the scope of any inventions or of what may be claimed, but rather as descriptions of features that may be specific to particular embodiments of particular inventions. Certain features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely, various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable subcombination. Furthermore, although features may be described above as acting in certain combinations and even initially claimed as such, one or more features from a claimed combination can in some cases be excised from the combination, and the claimed combination may be directed to a subcombination or variation of a subcombination.
Similarly, while operations are depicted in the drawings and are set forth in the claims in a particular order, this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order, or that all illustrated operations be performed, to achieve desirable results. In some cases, multitasking and parallel processing may be advantageous. Moreover, the separation of various system modules and components in the embodiments described above should not be understood as requiring such separation in all embodiments, and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.
Specific embodiments of the subject matter have been described. Other embodiments are within the scope of the following claims. For example, the actions recited in the claims can be performed in a different order and still achieve desirable results. As one example, the processes depicted in the accompanying figures do not necessarily require the particular order shown, or sequential order, to achieve desirable results. In some cases, multitasking and parallel processing may be advantageous.
Claims (12)
1. A method, comprising:
receiving an image search query from a user device;
obtaining a plurality of candidate image search results for the image search query, each candidate image search result identifying a respective image and a respective landing page for the respective image;
for each of the candidate image search results:
processing, using a trained image search result ranking machine learning model, (i) features of respective images identified by the candidate image search results, and (ii) features of respective landing pages identified by the candidate image search results, to generate relevance scores that measure relevance of the candidate image search results to the image search query by combining, in a query-dependent manner, the features of the respective images identified by the candidate image search results with the features of the respective landing pages identified by the candidate image search results based on the features of the image search query;
ranking the candidate image search results based on the relevance scores generated by the image search result ranking machine learning model;
generating an image search result presentation, wherein the image search result presentation displays candidate image search results which are ranked according to the ranking; and
image search results are provided for presentation by a user device.
2. The method of claim 1, wherein the candidate image search results are ranked according to an initial ranking, and wherein ranking the candidate image search results based on relevance scores generated by the image search result ranking machine learning model comprises:
the initial ranking is adjusted based on relevance scores generated by the image search result ranking machine learning model.
3. The method of any of claims 1 or 2, wherein the characteristic of the image search query comprises text of the image search query.
4. A method as claimed in any preceding claim, wherein the features of the image comprise one or more of: pixel data of an image, or embedding of an image.
5. A method as claimed in any preceding claim, wherein the characteristics of the landing page include one or more of: text from the landing page, a title of the landing page, or a resource locator of the landing page.
6. The method of any preceding claim, wherein the characteristics of the landing page include characteristics characterizing the freshness of the landing page.
7. The method of any preceding claim, wherein the image search result ranking machine learning model is a neural network.
8. The method of any preceding claim, further comprising:
generating a plurality of training examples; and
an image search result ranking machine learning model is trained on training examples.
9. The method of claim 8, wherein each training example includes a training query, a pair of training image search results, and a label characterizing a relative relevance of the pair of training image search results to the query, and wherein training the image search result ranking model includes training the image search result ranking model on the training examples to minimize a pairwise loss function.
10. The method of claim 8, wherein each training example includes a training query, a training image search result, and a target relevance score, and wherein training the image search result ranking model includes training the image search result ranking model on the training examples to generate a relevance score that matches the target relevance score.
11. A system comprising one or more computers and one or more storage devices storing instructions that, when executed by the one or more computers, cause the one or more computers to perform the respective operations of the method of any preceding claim.
12. One or more non-transitory computer-readable storage media storing instructions that, when executed by one or more computers, cause the one or more computers to perform the respective operations of the methods of any of claims 1 to 10.
Applications Claiming Priority (5)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201862783134P | 2018-12-20 | 2018-12-20 | |
US62/783,134 | 2018-12-20 | ||
US16/263,398 US20200201915A1 (en) | 2018-12-20 | 2019-01-31 | Ranking image search results using machine learning models |
US16/263,398 | 2019-01-31 | ||
PCT/US2019/068135 WO2020132623A1 (en) | 2018-12-20 | 2019-12-20 | Ranking image search results using machine learning models |
Publications (1)
Publication Number | Publication Date |
---|---|
CN112823345A true CN112823345A (en) | 2021-05-18 |
Family
ID=71097411
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201980066763.7A Pending CN112823345A (en) | 2018-12-20 | 2019-12-20 | Ranking image search results using machine learning models |
Country Status (3)
Country | Link |
---|---|
US (1) | US20200201915A1 (en) |
CN (1) | CN112823345A (en) |
WO (1) | WO2020132623A1 (en) |
Families Citing this family (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP2022519367A (en) * | 2019-02-05 | 2022-03-23 | グーグル エルエルシー | Understanding-based identification of educational content for multiple content types |
US10972802B1 (en) | 2019-09-26 | 2021-04-06 | Dish Network L.L.C. | Methods and systems for implementing an elastic cloud based voice search using a third-party search provider |
US11475018B2 (en) * | 2020-01-22 | 2022-10-18 | Salesforce.Com, Inc. | Determining user and data record relationships based on vector space embeddings |
US11715023B2 (en) * | 2020-07-21 | 2023-08-01 | Bayerische Motoren Werke Aktiengesellschaft | Methods and apparatuses for training one or more model parameters of a predictive parking difficulty model |
CN112417287A (en) * | 2020-11-24 | 2021-02-26 | 乐聚(深圳)机器人技术有限公司 | Building block searching method, model training method, device, equipment and storage medium |
US11734376B2 (en) * | 2020-12-30 | 2023-08-22 | Yandex Europe Ag | Method and server for ranking digital documents in response to a query |
CN114077682B (en) * | 2022-01-19 | 2022-04-29 | 广州拟实网络科技有限公司 | Intelligent recognition matching processing method and system for image retrieval and storage medium |
Family Cites Families (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10324993B2 (en) * | 2016-12-05 | 2019-06-18 | Google Llc | Predicting a search engine ranking signal value |
-
2019
- 2019-01-31 US US16/263,398 patent/US20200201915A1/en not_active Abandoned
- 2019-12-20 CN CN201980066763.7A patent/CN112823345A/en active Pending
- 2019-12-20 WO PCT/US2019/068135 patent/WO2020132623A1/en active Application Filing
Also Published As
Publication number | Publication date |
---|---|
US20200201915A1 (en) | 2020-06-25 |
WO2020132623A1 (en) | 2020-06-25 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US10387437B2 (en) | Query rewriting using session information | |
CN112823345A (en) | Ranking image search results using machine learning models | |
US11782998B2 (en) | Embedding based retrieval for image search | |
US9177046B2 (en) | Refining image relevance models | |
US10102482B2 (en) | Factorized models | |
US10410060B2 (en) | Generating synthesis videos | |
US8832096B1 (en) | Query-dependent image similarity | |
RU2691840C1 (en) | Search result filters from resource content | |
US8515212B1 (en) | Image relevance model | |
CN110023928B (en) | Predictive search engine ranking signal values | |
US9940367B1 (en) | Scoring candidate answer passages | |
US20200250538A1 (en) | Training image and text embedding models | |
US10019513B1 (en) | Weighted answer terms for scoring answer passages | |
US20160378863A1 (en) | Selecting representative video frames for videos | |
US20230205813A1 (en) | Training Image and Text Embedding Models | |
US10180964B1 (en) | Candidate answer passages | |
US10565265B2 (en) | Accounting for positional bias in a document retrieval system using machine learning | |
US20200372076A1 (en) | Learning to select vocabularies for categorical features | |
US9218366B1 (en) | Query image model | |
US20150169633A1 (en) | Ranking over hashes | |
CN107408125B (en) | Image for query answers | |
US8676812B1 (en) | Dynamic weighting of indicator values for item scoring | |
US20190332682A1 (en) | Automated selection of search ranker |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination |