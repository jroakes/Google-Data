JP6859433B2 - Function assignment for virtual controller - Google Patents
Function assignment for virtual controller Download PDFInfo
- Publication number
- JP6859433B2 JP6859433B2 JP2019520892A JP2019520892A JP6859433B2 JP 6859433 B2 JP6859433 B2 JP 6859433B2 JP 2019520892 A JP2019520892 A JP 2019520892A JP 2019520892 A JP2019520892 A JP 2019520892A JP 6859433 B2 JP6859433 B2 JP 6859433B2
- Authority
- JP
- Japan
- Prior art keywords
- controller
- virtual
- physical
- function
- controllers
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
- 230000006870 function Effects 0.000 claims description 140
- 238000000034 method Methods 0.000 claims description 54
- 238000001514 detection method Methods 0.000 claims description 23
- 238000004590 computer program Methods 0.000 claims description 16
- 230000004044 response Effects 0.000 claims description 10
- 230000015654 memory Effects 0.000 description 35
- 238000004891 communication Methods 0.000 description 18
- 230000033001 locomotion Effects 0.000 description 18
- 238000010586 diagram Methods 0.000 description 10
- 230000003993 interaction Effects 0.000 description 6
- 238000010422 painting Methods 0.000 description 6
- 230000003287 optical effect Effects 0.000 description 4
- 210000004247 hand Anatomy 0.000 description 3
- 239000003973 paint Substances 0.000 description 3
- 230000000007 visual effect Effects 0.000 description 3
- 240000007320 Pinus strobus Species 0.000 description 2
- 230000009471 action Effects 0.000 description 2
- 238000005516 engineering process Methods 0.000 description 2
- 210000003811 finger Anatomy 0.000 description 2
- 239000004973 liquid crystal related substance Substances 0.000 description 2
- 230000008569 process Effects 0.000 description 2
- 238000012545 processing Methods 0.000 description 2
- 239000004065 semiconductor Substances 0.000 description 2
- 241000870659 Crassula perfoliata var. minor Species 0.000 description 1
- 241000699666 Mus <mouse, genus> Species 0.000 description 1
- 241000699670 Mus sp. Species 0.000 description 1
- 230000003213 activating effect Effects 0.000 description 1
- 230000004913 activation Effects 0.000 description 1
- 230000000712 assembly Effects 0.000 description 1
- 238000000429 assembly Methods 0.000 description 1
- 230000006399 behavior Effects 0.000 description 1
- 230000005540 biological transmission Effects 0.000 description 1
- 230000004397 blinking Effects 0.000 description 1
- 239000000969 carrier Substances 0.000 description 1
- 230000008859 change Effects 0.000 description 1
- 230000008878 coupling Effects 0.000 description 1
- 238000010168 coupling process Methods 0.000 description 1
- 238000005859 coupling reaction Methods 0.000 description 1
- 210000004932 little finger Anatomy 0.000 description 1
- 230000004048 modification Effects 0.000 description 1
- 238000012986 modification Methods 0.000 description 1
- 230000006855 networking Effects 0.000 description 1
- 230000007935 neutral effect Effects 0.000 description 1
- 230000001953 sensory effect Effects 0.000 description 1
- 239000007787 solid Substances 0.000 description 1
- 230000001502 supplementing effect Effects 0.000 description 1
- 239000010409 thin film Substances 0.000 description 1
- 210000003813 thumb Anatomy 0.000 description 1
- 238000013519 translation Methods 0.000 description 1
- 230000014616 translation Effects 0.000 description 1
- 230000001960 triggered effect Effects 0.000 description 1
- 230000004382 visual function Effects 0.000 description 1
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/017—Gesture based interaction, e.g. based on a set of recognized hand gestures
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/011—Arrangements for interaction with the human body, e.g. for user immersion in virtual reality
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/016—Input arrangements with force or tactile feedback as computer generated output to the user
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/03—Arrangements for converting the position or the displacement of a member into a coded form
- G06F3/033—Pointing devices displaced or positioned by the user, e.g. mice, trackballs, pens or joysticks; Accessories therefor
- G06F3/0346—Pointing devices displaced or positioned by the user, e.g. mice, trackballs, pens or joysticks; Accessories therefor with detection of the device orientation or free movement in a 3D space, e.g. 3D mice, 6-DOF [six degrees of freedom] pointers using gyroscopes, accelerometers or tilt-sensors
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/03—Arrangements for converting the position or the displacement of a member into a coded form
- G06F3/033—Pointing devices displaced or positioned by the user, e.g. mice, trackballs, pens or joysticks; Accessories therefor
- G06F3/038—Control and interface arrangements therefor, e.g. drivers or device-embedded control circuitry
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0487—Interaction techniques based on graphical user interfaces [GUI] using specific features provided by the input device, e.g. functions controlled by the rotation of a mouse with dual sensing arrangements, or of the nature of the input device, e.g. tap gestures based on pressure sensed by a digitiser
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T19/00—Manipulating 3D models or images for computer graphics
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F2203/00—Indexing scheme relating to G06F3/00 - G06F3/048
- G06F2203/038—Indexing scheme relating to G06F3/038
- G06F2203/0382—Plural input, i.e. interface arrangements in which a plurality of input device of the same type are in communication with a PC
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/011—Arrangements for interaction with the human body, e.g. for user immersion in virtual reality
- G06F3/012—Head tracking input arrangements
Description
関連の出願の相互参照
本特許出願は、２０１７年１月１９日に出願された「仮想コントローラのための機能割当て」と題された米国仮特許出願第６２／４４８，１７２号の優先権を主張する、２０１７年１０月２６日に出願された「仮想コントローラのための機能割当て」と題された米国特許出願第１５／７９４，２６５号の継続出願であって、その優先権を主張するものであり、その開示が本明細書に引用により援用される。
Cross-reference to related applications This patent application claims the priority of US Provisional Patent Application No. 62 / 448,172 entitled "Functional Assignment for Virtual Controllers" filed January 19, 2017. This is a continuation application of US Patent Application No. 15 / 794,265 entitled "Functional Assignment for Virtual Controllers" filed on October 26, 2017, claiming its priority. Yes, the disclosure is incorporated herein by reference.
また、本特許出願は、２０１７年１月１９日に出願された米国仮特許出願第６２／４４８，１７２号の優先権を主張するものであり、その開示が本明細書に引用により援用される。 In addition, this patent application claims the priority of US Provisional Patent Application No. 62 / 448,172 filed on January 19, 2017, the disclosure of which is incorporated herein by reference. ..
技術分野
本特許明細書は一般に、１つ以上の仮想コントローラのための機能割当てに関する。
Technical Fields The present patent specification generally relates to function assignments for one or more virtual controllers.
背景
仮想現実（ＶＲ）プログラムの中には、ユーザが操作してＶＲプログラムのアスペクトを制御可能な１つ以上の物理的なコントローラを使用するものがある。異なる機能をコントローラに割当てることができ、これによって、ユーザは、左右の手をそれぞれ用いて異なるタスクを実行できる。しかしながら、ユーザは、システムが割当てた手と反対側の手を使用したい場合がある。とりわけ、設定が変更可能になるまではユーザは「誤った」手を用いてプログラムと相互作用しなければならない場合、このような変更を行うためには、ユーザは、煩雑なことがあるＶＲプログラムの設定メニューを検索する必要がある。ユーザの好みにかかわらず、物理的に同一のコントローラを使用して起動時に機能を割り当て可能なシステムもあれば、左手または右手用の物理的に異なるコントローラを有し、ユーザが物理的なコントローラを切替えることによって再割当てを行うことが困難、または不可能なシステムもある。
Background Some virtual reality (VR) programs use one or more physical controllers that can be manipulated by the user to control the aspects of the VR program. Different functions can be assigned to the controller, which allows the user to perform different tasks with their left and right hands. However, the user may want to use the hand opposite to the hand assigned by the system. Especially if the user has to interact with the program with "wrong" hands until the settings can be changed, the user can be cumbersome to make such changes in the VR program. You need to search the settings menu for. Some systems allow you to assign functions at boot time using the same physically controller, regardless of user preference, while others have physically different controllers for the left or right hand, allowing the user to have a physical controller. Some systems make it difficult or impossible to reallocate by switching.
概要
第１の態様では、方法は：コンピュータシステムにおいて、仮想コントローラを物理的なコントローラと対応付けることと；第１の機能を仮想コントローラに割当てて、物理的なコントローラを用いて第１の機能の性能を提供することと；物理的なコントローラを用いて行われたジェスチャを検出することと；ジェスチャの検出に応じて、仮想コントローラから第１の機能の割当てを解除する、または、第２の機能を仮想コントローラに割当てることとを備える。
Overview In the first aspect, the method is: in a computer system, associating a virtual controller with a physical controller; assigning the first function to the virtual controller and using the physical controller to perform the first function. To detect gestures made using a physical controller; to deallocate the first function from the virtual controller, or to release a second function, depending on the detection of the gesture. It has to be assigned to a virtual controller.
一般的に、本明細書で説明する物理的なコントローラおよび他の物理的なコントローラは、手持ち式のコントローラである、ユーザの手で持つためのコントローラであり得る。物理的なコントローラは、たとえばコントローラの平行移動および／または回転運動によって、および／または、ボタン、スイッチ、検出器、およびコントローラ上にまたはコントローラによって設けられた他の制御要素の使用によって、ユーザがコンピュータシステムに入力を行うことができるように適合されていることが一般的である。そのため、本特許明細書で説明する仮想コントローラおよび他の仮想コントローラは、物理的なコントローラのユーザに対して提示される仮想現実空間において提示される仮想または論理的コントローラであり得る。仮想空間における仮想コントローラの位置および／または移動は、一般的に、物理的なコントローラの位置および／または移動に対応し得る、または応答し得る。本特許明細書で説明するジェスチャおよび他のジェスチャは、一般的に、物理的なコントローラの、したがって一般に仮想空間における仮想コントローラの特定の平行運動および／または回転運動および／または軌跡によって提供され得る。 In general, the physical controller and other physical controllers described herein can be handheld controllers, controllers for the user to hold. The physical controller can be computerized by the user, for example, by parallel movement and / or rotational movement of the controller, and / or by the use of buttons, switches, detectors, and other control elements on or provided by the controller. It is generally adapted to allow input to the system. As such, the virtual controller and other virtual controllers described herein can be virtual or logical controllers presented in the virtual reality space presented to the user of the physical controller. The position and / or movement of the virtual controller in the virtual space may generally correspond to or respond to the position and / or movement of the physical controller. The gestures and other gestures described herein may be provided by specific translations and / or rotational movements and / or trajectories of the physical controller, and thus generally the virtual controller in virtual space.
実施形態例は、以下の特徴のいずれかまたは全てを含み得る。
仮想コントローラが第１の仮想コントローラとして定義され、物理的なコントローラが第１の物理的なコントローラとして定義される場合、方法は、コンピュータシステムにおける第２の仮想コントローラを第２の物理的なコントローラと対応付けることと、第２の機能を第２の仮想コントローラに割当てることとを備え得る。ジェスチャの検出に応じて、第１の機能は第１の仮想コントローラからの割当てを解除され第２の仮想コントローラに割当てられ得、第２の機能は第２の仮想コントローラからの割当てを解除され第１の仮想コントローラに割当てられ得る。
Examples of embodiments may include any or all of the following features:
If the virtual controller is defined as the first virtual controller and the physical controller is defined as the first physical controller, the method is to make the second virtual controller in the computer system the second physical controller. It may include associating and assigning a second function to a second virtual controller. Depending on the gesture detection, the first function can be deallocated from the first virtual controller and assigned to the second virtual controller, and the second function can be deallocated from the second virtual controller and assigned to the second virtual controller. Can be assigned to one virtual controller.
第１の機能は、仮想ペインティングプログラムにおいてブラシ機能を含み得、第２の機能は、仮想ペインティングプログラムにおいてパレット機能を含み得、ジェスチャの検出は、仮想ペインティングプログラムにおいてブラシ機能およびパレット機能のスワッピングを引き起こす。 The first function may include the brush function in the virtual painting program, the second function may include the palette function in the virtual painting program, and the gesture detection may include the brush function and the palette function in the virtual painting program. Causes swapping.
ジェスチャは、第１および第２の物理的なコントローラを用いてなされ得る。たとえば、ジェスチャは、第１および第２の物理的なコントローラが互いに近づけられその後互いに遠ざけられること、または、第１および第２の物理的なコントローラのそれぞれの端部が互いに近づけられその後互いに遠ざけられることを含み得る。 Gestures can be made using first and second physical controllers. For example, a gesture is that the first and second physical controllers are brought closer to each other and then moved away from each other, or the ends of the first and second physical controllers are moved closer to each other and then away from each other. Can include that.
第１および第２の物理的なコントローラのそれぞれの端部は、第１および第２の物理的なコントローラのそれぞれの底端部であり得る。たとえば、各コントローラは、ニュートラルポジションで通常の手持ち使用において方向付けられている場合、上端部および底端部を有していると定義され得る。たとえば、上端部はユーザの親指および人差し指により近く、底端部はユーザの小指により近い。 Each end of the first and second physical controllers can be the bottom end of each of the first and second physical controllers. For example, each controller may be defined as having an top edge and a bottom edge when oriented in normal handheld use in the neutral position. For example, the top edge is closer to the user's thumb and index finger, and the bottom edge is closer to the user's little finger.
第１および第２の物理的なコントローラは、互いに同一であり得る、または、実質的に同じであり得る。 The first and second physical controllers can be the same or substantially the same as each other.
この方法はさらに、コンピュータシステムにおけるデフォルトとして、ジェスチャの検出に応じて、仮想コントローラからの第１の機能の割当ての解除、または、第２の機能の仮想コントローラとの対応付けを記憶することを備え得る。 This method further comprises, as a default in the computer system, allocating the first function from the virtual controller or storing the association with the virtual controller of the second function in response to the detection of the gesture. obtain.
仮想コントローラは、コンピュータシステムによって生成された仮想空間において定義され得、第１の機能はジェスチャの検出に応じて仮想コントローラからの割当てを解除される。この方法はさらに、仮想空間においてポイントを定義することと、ジェスチャの検出に応じて第１の機能をポイントと対応付けることとを備える。第２の機能は、ジェスチャの検出が検出される前に、仮想コントローラに既に割当てられ得る。 The virtual controller can be defined in the virtual space generated by the computer system, and the first function is deallocated from the virtual controller in response to the detection of the gesture. The method further comprises defining points in virtual space and associating a first function with points in response to gesture detection. The second function can already be assigned to the virtual controller before the gesture detection is detected.
また、これに関連して、仮想コントローラは第１の仮想コントローラとして定義され得、物理的なコントローラは第１の物理的なコントローラとして定義され得る。この方法はさらに、コンピュータシステムにおける第２の仮想コントローラを第２の物理的なコントローラと対応付けることと；第２の機能を第２の仮想コントローラに割当てることとを備える。 Also, in this context, the virtual controller can be defined as the first virtual controller and the physical controller can be defined as the first physical controller. The method further comprises associating a second virtual controller in a computer system with a second physical controller; assigning a second function to the second virtual controller.
この方法はさらに、第２の機能を第１の仮想コントローラにも割当てることを備え得る。たとえば、第１の機能は仮想ペインティングプログラムにおいてパレット機能を含み得、第２の機能は仮想ペインティングプログラムにおいてブラシ機能を含み、第１の仮想コントローラからの第１の機能の割当ての解除によって、第１および第２の物理的なコントローラの双方を使用して仮想ペインティングプログラムにおいてブラシ機能を実行可能である。 The method may further comprise assigning a second function to a first virtual controller as well. For example, the first function may include a palette function in a virtual painting program, the second function may include a brush function in a virtual painting program, and by unassigning the first function from the first virtual controller. Both the first and second physical controllers can be used to perform brush functions in a virtual painting program.
上述で説明され以下でより詳細に論じられるさまざまな態様において、ジェスチャは、たとえば、物理的なコントローラ上に位置し得るセンサを用いて検出され得る。説明される方法はさらに、センサによって生成されたセンサデータから、物理的なコントローラに関する速度および位置情報を推定することを備え得る、および／または、センサデータから物理的なコントローラについての方位データを推定することを備え得る。 In various aspects described above and discussed in more detail below, gestures can be detected, for example, using sensors that can be located on a physical controller. The method described may further comprise estimating velocity and position information about the physical controller from the sensor data generated by the sensor and / or estimating orientation data about the physical controller from the sensor data. Can be prepared to do.
本発明はまた、説明される方法の実行のために、コンピュータプログラムコードを保持する１つ以上のコンピュータ可読媒体を提供する。たとえば、本発明は、非一時的な記憶媒体において有形に具現化されたコンピュータプログラム製品を提供する。コンピュータプログラム製品は、実行されると、プロセッサに：コンピュータシステムにおいて、仮想コントローラを物理的なコントローラと対応付けることと；第１の機能を仮想コントローラに割当てて、物理的なコントローラを用いて第１の機能の性能を提供することと；物理的なコントローラを用いて行われたジェスチャを検出することと；ジェスチャの検出に応じて、仮想コントローラから第１の機能の割当てを解除する、または、第２の機能を仮想コントローラに割当てることとを含む操作を行わせる命令を含む。 The present invention also provides one or more computer-readable media holding computer program code for performing the methods described. For example, the present invention provides a computer program product that is tangibly embodied in a non-temporary storage medium. When a computer program product is executed, it tells the processor: in a computer system, associating a virtual controller with a physical controller; assigning a first function to the virtual controller and using the physical controller for the first To provide the performance of a function; to detect a gesture made using a physical controller; to deallocate the first function from the virtual controller or to have a second function in response to the detection of the gesture. Includes instructions to perform operations, including assigning the functions of to a virtual controller.
本発明はまた、説明される方法の実行のために配置された装置を提供する。たとえば、本発明は：プロセッサと；非一時的な記憶媒体において有形に具現化されたコンピュータプログラム製品とを備えるシステムを提供する。コンピュータプログラム製品は、実行されると、プロセッサに：コンピュータシステムにおいて、仮想コントローラを物理的なコントローラと対応付けることと；第１の機能を仮想コントローラに割当てて、物理的なコントローラを用いて第１の機能の性能を提供することと；物理的なコントローラを用いて行われたジェスチャを検出することと；ジェスチャの検出に応じて、仮想コントローラから第１の機能の割当てを解除する、または、仮想コントローラに第２の機能を割当てることとを含む操作を行わせる命令を含む。 The present invention also provides a device arranged for performing the methods described. For example, the present invention provides a system comprising: a processor and a computer program product tangibly embodied in a non-temporary storage medium. When a computer program product is executed, it tells the processor: in a computer system, associating a virtual controller with a physical controller; assigning a first function to the virtual controller and using the physical controller for the first To provide the performance of a function; to detect gestures made using a physical controller; to deallocate the first function from the virtual controller or to virtual controller in response to the detection of the gesture. Includes instructions to perform operations, including assigning a second function to.
このようなシステムは、関連する方法を実現するために必要とされる１つ以上の物理的なコントローラも備え得る。 Such a system may also include one or more physical controllers required to implement the relevant methods.
さまざまな図における同様の参照符号は、同様の要素を示す。
詳細な説明
本特許明細書は、仮想コントローラのための機能割当ての例について説明する。従来、仮想現実（ＶＲ）アプリケーションを使用している、または使用しようとしている人は、ＶＲシステムの２つ以上の物理的なコントローラ間で、少なくとも１つの機能の再割当てまたは再対応付けが可能である。いくつかの実施形態では、人は、あらかじめ定義されたジェスチャを実行して、再割当てまたは再対応付けを開始可能である。たとえば、人は、物理的なコントローラのそれぞれの端部を互いに近づけ、その後互いに遠ざけて、１つ（または複数）の機能を再割当てしなければならないという意図の信号を送ることができる。これは、たとえばメニューシステムを検索するよりも、コントローラ間でＶＲ機能の再割当てを行うより簡単で、より早く、および／または、より直感的な方法であり得る。
Similar reference symbols in the various figures indicate similar elements.
Detailed Description This patent specification describes an example of function assignment for a virtual controller. Traditionally, anyone using or attempting to use a virtual reality (VR) application can reassign or reassign at least one feature between two or more physical controllers in a VR system. is there. In some embodiments, a person can perform a predefined gesture to initiate reassignment or reassociation. For example, a person can signal the intention that the ends of a physical controller must be brought closer to each other and then away from each other to reassign one (or more) function. This can be an easier, faster, and / or more intuitive way to reassign VR functionality between controllers, for example, than searching for a menu system.
図１Ａ〜図１Ｂは、仮想コントローラのための機能割当ての例を示す図である。ここで、仮想コントローラは、ＶＲプログラムによって生成される仮想空間１００に示されている。たとえば、仮想空間１００は、ＶＲプログラムに接続されたＶＲヘッドセット（たとえば、ヘッドマウントディスプレイ）を着用した人が見ることができる。ここで、１つ以上の制御装置１０４を有する仮想コントローラ１０２は、仮想空間１００において見ることができる。たとえば、１つ（または複数）の制御装置１０４は、対応する物理的なコントローラ（図示せず）上でアクセス可能な物理的制御装置に対応可能である。仮想コントローラ１０２の形状は、物理的なコントローラの形状に対応、または類似し得る。同様に、１つ以上の制御装置１０８を有する他の仮想コントローラ１０６も仮想空間１００に示されている。
1A to 1B are diagrams showing an example of function allocation for a virtual controller. Here, the virtual controller is shown in the
ＶＲプログラムを操作する人はそれぞれの手に物理的なコントローラの各々を持つことができる。たとえば、仮想コントローラ１０２のための物理的なコントローラを右手に持ち、仮想コントローラ１０６のための物理的なコントローラを左手に持つ。他の例として、コントローラは、人の体のある部分に取り付け可能である。コントローラは、その位置、速度および／または方位について追跡可能である。人が手または体の他の部分を使用して１つ（または複数）のコントローラを移動させるとき、仮想コントローラ１０２および／または１０６は、それに応じて仮想空間１００内で移動可能である。
The person operating the VR program can hold each of the physical controllers in each hand. For example, the physical controller for the
この例では、仮想空間１００はＶＲプログラム内のペインティング環境と対応付けられている。図１Ａでは、仮想コントローラ１０２は、それ自体に割当てられたブラシ機能を有する。たとえば、仮想コントローラ１０２上の先端部１１０は、当該コントローラのためにブラシ機能が利用可能であることを示す。人は仮想コントローラ１０２に対応する物理的なコントローラを移動させることによって、仮想空間１００内にブラシストロークを生成することができる。たとえば、ここでは、ブラシストローク１１２は、仮想コントローラ１０２を用いて仮想空間１００内に生成されている。
In this example, the
さらに、仮想コントローラ１０６は、それ自体に割当てられたＶＲプログラムの他の機能を有する。ここでは、仮想ツールボックス１１４が、仮想コントローラ１０６を少なくとも部分的に取り囲むように、仮想空間１００内に模式的に示されている。たとえば、仮想ツールボックス１１４は、それ自体が割当てられた仮想コントローラ、ここでは仮想コントローラ１０６に対して固定可能であり、それによって、仮想ツールボックス１１４は、当該仮想コントローラと共に仮想空間１００内で移動する。仮想ツールボックス１１４は、利用可能な１つ以上の仮想機能を含み得る。
In addition, the
ここで、仮想ツールボックス１１４上のホイール１１６は、ペインティング環境のブラシ機能のためのパレットに対応する。したがって、ホイール１１６は、ペインティング環境において１つ以上のパレット機能のために使用可能である。たとえば、先端部１１０をホイール１１６の選択された部分に接触させて特定の色、テクスチャ、パターン、および／または他のペイント特徴をペイントブラシに割当てることが可能である。たとえば、ブラシストローク１１２の１つ以上の特徴は、ホイール１１６を使用して制御可能である。１つ以上の他の機能を、ツールボックス１１４と対応付けることが可能である。ここでは、機能１１８が模式的に示されている。これらは、ペインティング環境の他の機能、たとえば、異なるマーク付け実行（ペンなど）の選択および／または現在のマーク付け実行（濃さなど）のあるアスペクトの変更などに関連し得る。
Here, the
いくつかの実施形態例では、仮想コントローラ１０２は、現在支配的なコントローラであると考えることができる。なぜなら、仮想空間１００にマーク付けを行うという比較的要求がより厳しい操作のために使用されるからである。これに対して、仮想コントローラ１０６は、現在非支配的なコントローラであると考えることができる。なぜなら、その目的は主に、仮想コントローラ１０２によって使用されるべき１つ以上のツールを提供すること、および／または、仮想コントローラ１０２の機能を増大させることであり得るからである。
In some embodiments, the
ＶＲプログラムは、仮想空間１００内で機能の割当ておよび／または機能の割当ての解除を行う１つ以上の方法を提供可能である。いくつかの実施形態例では、スワッピング機能１２０によって模式的に示されるように、仮想コントローラ１０２と１０６との間で機能をスワップ可能である。たとえば、これは、ユーザが手で物理的なコントローラを物理的に切替えることを必要とせずに、一方の手から他方の手に支配的なコントローラを切替えるために使用可能である。スワッピング機能１２０は、仮想コントローラ１０２および／または１０６に対応する物理的なコントローラの１つ以上を用いて、あらかじめ定義されたジェスチャを行うことによって引き起こされ得る。
The VR program can provide one or more methods for assigning and / or deallocating functions within the
人がそのようなあらかじめ定義されたジェスチャを実行し、システムがこれをスワッピング機能１２０を起動する信号と解釈したとする。図１Ｂは、スワッピング機能１２０を実行後の仮想空間１００の例を示す図である。仮想コントローラ１０２および１０６は、ジェスチャが行われる前ではなく行われた後に異なる位置になり得る例もあるが、現在、ほぼ図１Ａのような位置にある。しかしながら、ＶＲプログラム内の機能は、ジェスチャに応じて再割当てされている。たとえば、先端部１１０はもはや仮想コントローラ１０２には割当てられておらず、仮想コントローラ１０６に現在割当てられている。同様に、ツールボックス１１４およびそれと対応付けられたツールはもはや仮想コントローラ１０６に割当てられておらず、仮想コントローラ１０２に現在割当てられている。マーク付け実行として定義されたときに仮想コントローラ１０２を用いて生成されたブラシストローク１１２が、依然として仮想空間１００で可視状態である。人はそこで、マーク付け実行として、仮想コントローラ１０６を用いて仮想空間１００に１つ以上のマーク付けを行うことが可能である。たとえば、人は、仮想コントローラ１０６を用いて他のブラシストローク１２２を生成可能である。これに対して、仮想コントローラ１０２は、ホイール１１６、１つ（または複数）の機能１１８、および／または仮想ツールボックス１１４と対応付けられた他の機能のために現在使用可能である。
Suppose a person performs such a predefined gesture and the system interprets it as a signal that activates the
スワッピング機能１２０は、仮想空間１００内で機能の割当てまたは機能の割当ての解除を行う便利な方法を提供可能である。たとえば、人がＶＲプログラムを起動すると図１Ａの構成が割当てられると仮定する。すなわち、ブラシ機能が、右側の物理的なコントローラを用いた起動に現在利用可能である。これはデフォルト設定であってもよい、または、起動されると主装置（たとえば、ＶＲプログラムを実行するコンピュータ筐体）に対する物理的なコントローラの空間位置に基づいていてもよい。さらに、人が右手ではなく左手を使用したペイントを好むと仮定する。そのため、人は、スワッピング機能１２０を起動して仮想コントローラ１０２から仮想コントローラ１０６へブラシ機能を便利に再割当て可能である（左手を用いて作動される）、かつ、残りの機能を仮想コントローラ１０２に再割当て可能である（右手を用いて作動される）。このスワッピング（または他の再割当てもしくは割当て解除）がシステムによって行われると、その結果として生じる１つ（または複数）の割当てを、ＶＲプログラムのためにデフォルトとして記憶可能である。たとえば、同じユーザが次にＶＲプログラムを起動すると、図１Ｂに示すように割当てが行われ得る。１つ以上の機能の割当てまたは再割当ては、行われなくてもよい、または逆でもよい。たとえば、ユーザがあらかじめ定義されたジェスチャ（または他のジェスチャ）を再度行うと、システムは過去に行われた割当てを取り消してもよい、または逆にしてもよい。
The
すなわち、コンピュータシステムにおいて、仮想コントローラを物理的なコントローラと対応付けることを備える方法を行うことができる。たとえば、仮想コントローラ１０２を、ユーザが右手に持つ物理的なコントローラ（図示せず）と対応付けることができる。この方法は、第１の機能を仮想コントローラに割当てて、物理的なコントローラを用いて第１の機能の性能を与えることを備え得る。たとえば、先端部１１０によって例示されるブラシ機能を、仮想コントローラ１０２に割当てることができる。この方法は、物理的なコントローラを用いて行われるジェスチャを検出することを備え得る。たとえば、ユーザは、あらかじめ定義されたジェスチャを行ってスワッピング機能１２０を起動可能である。この方法は、ジェスチャの検出に応じて、仮想コントローラから第１の機能の割当てを解除すること、または、第２の機能を仮想コントローラに割当てることを備え得る。たとえば、仮想コントローラ１０２から先端部１１０の割当てを解除可能である。他の例として、仮想ツールボックス１１４を仮想コントローラ１０２に割当て可能である。
That is, in a computer system, a method including associating a virtual controller with a physical controller can be performed. For example, the
図２Ａ〜図２Ｆは、仮想コントローラのための機能割当ての他の例を示す図である。ここでは、仮想コントローラ２００および２０２が仮想空間２０４において示されている。たとえば、仮想空間２０４を、ＶＲヘッドセットを用いてまたは他の方法で眺めることができる。現在、仮想コントローラ２０２は、「Ｄ」というラベルによって示されるように、支配的なコントローラである。このラベルは、ここでは例示のために用いられており、仮想空間２０４において可視である必要はない。支配的なコントローラとして定義されたことにより、少なくとも１つの機能が仮想コントローラ２０２に割当て可能である。
2A-2F are diagrams showing other examples of function assignments for virtual controllers. Here, the
ユーザが左側のコントローラから右側のコントローラへ優勢を切替えたいと思っていると仮定する。ユーザは、仮想コントローラ２００および２０２と対応付けられた物理的なコントローラ（図示せず）のうちの１つ以上を用いて、あらかじめ定義されたジェスチャを行うことが可能である。図２Ａの矢印２０６は、ユーザがここで仮想コントローラ２００および２０２を相互に離し始めたことを示す。
Suppose the user wants to switch the dominance from the controller on the left to the controller on the right. The user can make predefined gestures using one or more of the physical controllers (not shown) associated with the
図２Ｂでは、それぞれの矢印２０８は、ユーザが仮想コントローラ２００および２０２を反対方向に向けたことを示す。たとえば、仮想コントローラ２００および２０２のそれぞれの端部２１０は、現在向かい合っている。任意の端部を使用可能であり、このような端部はコントローラの上端部および／または底端部を含むが、これに限定されるわけではない。
In FIG. 2B, the
図２Ｃでは、それぞれの矢印２１２は、ユーザが仮想コントローラ２００および２０２を互いに向けて、ここでは実質的に水平に移動させることを示す。これは、仮想コントローラ２００および２０２のそれぞれの端部２１０が相互に接触するまで、またはほぼ接触するまで行うことができる。いくつかの実施形態例では、動きは、仮想コントローラ２００および２０２が最初に少なくとも最小距離だけ離された場合に認識可能であり、その後、これらの装置の互いに向かう動きが開始される。たとえば、これによって、ユーザが意図せずにジェスチャを行うことを避けることができる。
In FIG. 2C, each
図２Ｄでは、矢印２１４は、ユーザがその後仮想コントローラ２００および２０２を互いに遠ざけることを示す。いくつかの実施形態例では、これは、図２Ｃの互いに近づけられる態様の方向とは実質的に反対方向に行うことができる。いくつかの実施形態例では、仮想コントローラ２００および２０２が少なくとも最小距離だけ遠ざけられると、動きを認識可能である。たとえば、これによって、ユーザが意図せずにジェスチャを行うことを避けることができる。
In FIG. 2D,
矢印２０６、２０８、２１２および／または２１４によって示される動きは、システムによって、仮想コントローラ２００および２０２のうちの１つ以上に対する機能の割当ておよび／または機能の割当て解除と対応付けられた、あらかじめ定義されたジェスチャのユーザによる意図された行為であると解釈可能である。たとえば、ジェスチャは、仮想コントローラ２００および２０２と対応付けられた物理的なコントローラが互いに近づけられその後互いに遠ざけられることを含み得る。他の例として、ジェスチャは、物理的なコントローラのそれぞれの端部が互いに近づけられその後互いに遠ざけられることを含み得る。そのような１つ（または複数）のジェスチャの検出に応じて、システムは割当て／割当て解除を行い得る。
The movements indicated by the
たとえば、優勢をある仮想コントローラから他の仮想コントローラへと切替えることができる。図２Ｅは、仮想コントローラ２００が現在支配的なコントローラであることを示す。これに対して、仮想コントローラ２０２は、もはや支配的なコントローラではない。たとえば、これは、人が１つ以上のＶＲプログラムにおいて仮想コントローラの利き手を切替える便利な方法であり得る。
For example, the dominance can be switched from one virtual controller to another. FIG. 2E shows that the
図２Ｆは、それぞれの矢印２１６によって示されるように、ユーザが仮想コントローラ２００および２０２をより直立のまたは前方の方位に向けることを示す図である。いくつかの実施形態例では、これにより、ユーザが１つ（または複数）の仮想コントローラに割当てられた１つ以上の機能の実行を開始するために、１つ（または複数）の仮想コントローラを適切な位置に設けうる。たとえば、ユーザは現在支配的な仮想コントローラ２００を用いて仮想空間２０４において１つ以上の機能を実行可能である。
FIG. 2F is a diagram showing the user pointing the
少なくとも１つの物理的なコントローラを用いたジェスチャの性能は、１つ以上の方法で検出可能である。物理的なコントローラ上にまたはこの内部に、および／または、物理的なコントローラの位置および移動を検出可能な他の場所に配置可能なセンサを使用可能である。たとえば、システムの他のコンポーネントは、１つ（または複数）の物理的なコントローラの位置、速度、および／または方位を検出できるように、１つ（または複数）のセンサを含み得る。 Gesture performance with at least one physical controller can be detected in one or more ways. Sensors that can be placed on or within the physical controller and / or elsewhere where the physical controller's position and movement can be detected are available. For example, other components of the system may include one (or more) sensors so that they can detect the position, speed, and / or orientation of one (or more) physical controllers.
いくつかの実施形態例では、仮想空間２０４ならびに仮想コントローラ２００および２０２を生成するＶＲシステムは、ユーザに提示されるように各フレームが仮想空間の瞬間に対応するフレームに基づいて、動作可能である。フレームごとに、１つ以上の物理的なコントローラの位置をシステムによって決定可能である。物理的なコントローラが移動中の場合、その位置は、あるフレームから次のフレームへと変化し得る。そのようなフレームデータに基づいて、システムは、物理的なコントローラについての１つ以上の特徴を決定可能である。たとえば、物理的なコントローラの速度および位置は、２つ以上のフレームにわたるセンサデータから推定可能である。他の例として、物理的なコントローラの方位（その端部が指し示す方位など）を、センサデータから推定可能である。たとえば、そのような速度、位置および／または方向情報を使用してジェスチャを検出可能であり、これらは例示されたものを含むが、上述の例示に限定されるわけではない。
In some embodiments, the VR system that produces the
図３は、システム３００の例を示す図である。ここでは、システム３００は、ＶＲ機能を生成するＶＲシステムである。すなわち、たとえばユーザがＶＲヘッドセットおよび１つ以上の物理的なコントローラを使用して相互作用するように、ＶＲシステム３００を使用して１つ以上のＶＲアプリケーションを実行可能である。特に、ＶＲシステム３００は、１つ以上のＶＲ空間３０２を生成可能である。たとえば、仮想空間１００（図１Ａ〜図１Ｂ）および／または仮想空間２０４（図２Ａ〜図２Ｆ）を生成可能である。
FIG. 3 is a diagram showing an example of the
ここでは、ＶＲシステム３００は、その内部に定義された複数のＶＲ機能３０４を有する。ある機能は、ＶＲプログラムによって提供されるべきタイプの機能と関連し得る。グラフィックスまたは他のビジュアルアートに関連するＶＲプログラムでは、ＶＲ機能３０４はブラシ機能およびパレット機能を含み得るが、これら２つはただの例に過ぎない。
Here, the
また、ＶＲシステム３００は、その内部に定義された複数のＶＲコントローラ３０６を有し得る。いくつかの実施形態例では、仮想コントローラ３０６のうちの１つ以上は、ユーザがＶＲコントローラ３０６を操作可能な物理的なコントローラに視覚的に類似している。たとえば、ＶＲコントローラ３０６は、仮想コントローラ１０２および１０６（図１Ａ〜図１Ｂ）および／または仮想コントローラ２００および２０２（図２Ａ〜図２Ｆ）を含み得る。ＶＲ機能３０４は、割当て機能３０８によって、ＶＲコントローラ３０６のそれぞれに割当てられる。たとえば、ＶＲコントローラ３０６のうちの１つは、ＶＲ機能３０４のうちの１つ以上をそれ自体に割当て可能である。ＶＲ機能３０４は、（たとえば、図１Ａの仮想コントローラ１０２上の先端部１１０のように）対応するＶＲコントローラ３０６の視覚的な機能として示すことができる。割当ては、ユーザによって、および／または、システムによって変更可能である。たとえば、ユーザは、あらかじめ定義されたジェスチャを実行して仮想コントローラに関連するスワッピング機能を起動することができる。スワッピング機能は、割当て機能３０８の一部である。
Further, the
ＶＲシステム３００は、複数の物理的なコントローラ３１０を含み得る。いくつかの実施形態例では、物理的なコントローラは、位置、速度および／または方位の観点から１つ以上の点においてＶＲシステムによって追跡される物理的なデバイスであるが、これに限定されるわけではない。たとえば、物理的なコントローラ３１０は、仮想コントローラ１０２および１０６（図１Ａ〜図１Ｂ）ならびに／または仮想コントローラ２００および２０２（図２Ａ〜図２Ｆ）を操作するために使用される物理的なコントローラを含み得る。ＶＲコントローラ３０６は、対応付け機能３１２によって物理的なコントローラ３１０のそれぞれと対応付けられる。たとえば、ＶＲコントローラ３０６のうちの１つが物理的なコントローラ３１０のうちの１つ以上と対応付けられ得る。その後物理的なコントローラ３１０を使用して、それ自体が対応付けられたＶＲコントローラ３０６を操作可能である。この対応付けは、ユーザおよび／またはシステムによって変更可能である。
The
物理的なコントローラ３１０は、基本的に互いに同一であり得る。たとえば、各コントローラは他の物理的なコントローラと実質的に同じハードウェア構成（たとえば、その電子機器回路および外観の要素）を有し得、生成された信号（たとえば、固有の識別子）のいくつかの特徴によって区別可能である。他の実施形態例では、物理的なコントローラ３１０のうちの２つ以上は互いにいくつかの物理的な相違を有し得る。たとえば、ある物理的なコントローラ３１０は、右手で持たれるように構成された外観要素を有し得、他の物理的なコントローラ３１０は、左手で持たれるように構成された外観要素を有し得る。
The
検出システム３１４を使用可能である。検出システム３１４は、ＶＲシステム３００および／または物理的なコントローラ３１０の一部であり得る、または、他のユニットと相互作用する別のコンポーネントであり得るが、これは単なる例に過ぎない。検出システム３１４は、１つ以上のセンサ３１６を使用して物理的なコントローラ３１０のうちの少なくとも１つに関するいくつかの特徴を決定することに基づいている。この決定は、検出システム３１４と物理的なコントローラ３１０との間の結合３１８を用いて模式的に示されている。たとえば、１つ（または複数）のセンサ３１６は物理的なコントローラ３１０の上にまたはこの内部に位置決め可能であり、その位置、速度および／または方向を反映する信号を生成可能である。他の例として、１つ（または複数）のセンサ３１６は、ユーザがＶＲシステム３００を使用している空間内で（たとえば、室内で）位置決め可能であり、１つまたは複数の態様で１つ（または複数）の物理的なコントローラ３１０の特徴を検出可能である。センサは、１つ以上の好適なセンシング技術を用いて動作可能である。たとえば、光学、オーディオ、電磁気信号または他の形態の通信を使用可能であるが、これらに限定されるわけではない。
A
検出システム３１４は、１つ（または複数）の物理的なコントローラ３１０に関するセンサデータに基づいて１つ以上の信号を生成可能である。いくつかの実施形態例では、位置、速度、および／または方位の推定を行うことができる。たとえば、この推定は、検出システム３１４によって行うことが可能であり、信号３２０によって割当て機能３０８に与えることが可能である。他の例として、信号３２０は１つ（または複数）の物理的なコントローラ３１０に関する生センサデータを含み、ＶＲシステム３００は、（たとえば、割当て機能３０８によって）１つまたは複数のタイプの推定を行うことが可能である。したがって、ＶＲコントローラ３０６のうちの少なくとも１つに対する仮想機能３０４のうちの１つ以上の割当てを、信号３２０に基づいて更新可能である。
The
図４〜図５は、方法４００および５００の例を示す図である。これらの方法は、ＶＲシステム３００（図３）を含むコンピュータシステムにおいて実行可能であるが、これに限定されるわけではない。いくつかの実施形態例では、非一時的な記憶媒体に有形に記憶可能なコンピュータプログラム製品に命令が記憶されている。命令は、実行されると、プロセッサに方法４００および／または５００の動作を行わせことができる。１つ以上の追加のステップが行われてもよく、または行われるステップの数はより少なくてもよい。他の例として、２つ以上の動作を異なる順番で行うことができる。
4 to 5 are diagrams showing examples of
方法４００から始め、４１０において、仮想コントローラがコンピュータシステム内の物理的なコントローラと対応付けられる。４２０において、第１の機能が仮想コントローラに割当てられる。この割当てにより、物理的なコントローラを使用して第１の機能の性能が与えられる。４３０において、物理的なコントローラを用いて行われたジェスチャが検出される。４４０において、ジェスチャの検出に応じて、第１の機能は仮想コントローラから割当てを解除される、または、第２の機能が仮想コントローラに割当てられる。
Starting with
次に方法５００に進み、５１０において、センサデータを受信可能である。このセンサデータは、１つ以上の物理的なコントローラと関連し得る。５２０において、１つ（または複数）の物理的なコントローラに関する速度データをセンサデータから推定可能である。５３０において、１つ（または複数）の物理的なコントローラに関する位置データをセンサデータから推定可能である。５４０において、１つ（または複数）の物理的なコントローラに関する方位データをセンサデータから推定可能である。５５０において、１つ（または複数）の物理的なコントローラを用いてなされた１つ以上のジェスチャを検出可能である。これは図２Ａ〜図２Ｆにおいて例示されたジェスチャを含み得るが、これらに限定されるわけではない。
Next, the process proceeds to
図６Ａ〜図６Ｃは、仮想コントローラのための機能割当ての他の例を示す図である。ここでは、仮想空間６００は現在、仮想コントローラ６０２を含む。仮想コントローラ６０２を、物理的なコントローラ（図示せず）を用いて操作可能である。仮想コントローラ６０２は、それ自体に割当てられた１つ以上の機能を有しており、それらの機能のうちの一部は、仮想空間６００において可視であるグリッド６０４によって模式的に示されている。たとえば、グリッド６０４は、ユーザが物理的なコントローラを用いて仮想コントローラ６０２を操作することによって現在行うことが可能な少なくとも１つの機能を示す。ここで、ユーザが仮想コントローラ６０２からグリッド６０４によって示される１つ（または複数）の機能を一時的に取り除こうとしていると仮定する。この目的のために、ユーザは、仮想空間６００において定義されるポイント６０６を使用可能である。
6A-6C are diagrams showing other examples of function assignments for virtual controllers. Here, the
いくつかの実施形態例では、ユーザは、仮想コントローラ６０２の少なくとも物理的なコントローラを用いて、あらかじめ定義されたジェスチャを行い得る。ジェスチャが行われたとシステムが認識すると、システムは代わりに、仮想コントローラ６０２の１つ以上の機能をポイント６０６に割当て可能である。図６Ｂは、グリッド６０４が仮想コントローラ６０２に現在割当てられているのではなく仮想空間６００内のポイント６０６に現在割当てられていることを示す。この動作は、たとえば、ユーザがあらかじめ定義されたジェスチャを再度行うと元に戻せる。
In some embodiments, the user may make a predefined gesture using at least the physical controller of the
仮想コントローラ６０２に割当てられた１つ以上の機能は、グリッド６０４が仮想コントローラ６０２からの割当てを解除された後も留まることが可能である。ここで、仮想コントローラ６０２には依然として先端部６０８が設けられている。先端部６０８は、グリッド６０４の割当て解除の前に仮想コントローラ６０２に割当てておくこともできる。たとえば、ペインティングを特徴とするＶＲプログラムにおいて、先端部６０８は、たとえばブラシ機能によって、仮想コントローラ６０２を用いてペイント（描画）する能力を模式的に示し得る。したがって、ユーザは、システムが仮想コントローラ６０２から他の１つ（または複数）の機能の割当てを解除した後も、仮想コントローラ６０２を使用してペイントまたは描画する能力を依然として有しうる。これによって、実用的な柔軟性がもたらされ得る。たとえば、図６Ｃは、システムが、仮想コントローラ６０２を操作するものではなく、他の物理的なコントローラを使用して操作される他の仮想コントローラ６１０を有し得ることを示す図である。仮想コントローラ６１０は、それ自体の対応する先端部６１２を有し得る。したがって、ユーザは現在、仮想空間６００における仮想ペインティングのために、仮想コントローラ６０２および６１０のいずれか、または仮想コントローラ６０２および６１０の双方を同時に使用可能である。どこかの時点で、グリッド６０４の１つ（または複数）の機能を使用するために、ユーザは、必要とされるジェスチャを行ってポイント６０６から１つ（または複数の）機能の割当てを解除可能であり、代わりに、１つ（または複数）の機能を仮想コントローラ６０２および６１０のうちの少なくとも１つに割当てることが可能である。
One or more functions assigned to the
図７は、ここで説明する技術を実現するために使用可能なコンピュータデバイス およびモバイルコンピュータデバイスの例を示す図である。図７は、ここで説明する技術と共に使用可能な、汎用コンピュータデバイス７００および汎用モバイルコンピュータデバイス７５０の例を示す図である。コンピューティングデバイス７００は、様々な形式のデジタルコンピュータ、たとえば、ラップトップ、デスクトップ、タブレット、ワークステーション、パーソナルデジタルアシスタント、テレビ、サーバ、ブレードサーバ、メインフレーム、および他の好適なコンピューティングデバイスを表すように意図されている。コンピューティングデバイス７５０は、様々な形式のモバイルデバイス、たとえば、パーソナルデジタルアシスタント、携帯電話、スマートフォン、および他の類似のコンピューティングデバイスを表すように意図されている。ここで示すコンポーネント、これらの接続および関係、ならびにこれらの機能は、例示に過ぎないことが意図されており、本特許明細書で説明される発明および／または請求項の実施を限定するように意図されたものではない。
FIG. 7 is a diagram showing examples of computer devices and mobile computer devices that can be used to realize the techniques described herein. FIG. 7 is a diagram illustrating an example of a general
コンピューティングデバイス７００は、プロセッサ７０２、メモリ７０４、記憶装置７０６、メモリ７０４と高速拡張ポート７１０とに接続する高速インターフェース７０８、および低速バス７１４と記憶装置７０６とに接続する低速インターフェース７１２を備える。プロセッサ７０２は、半導体を利用したプロセッサであり得る。メモリ７０４は、半導体を利用したメモリであり得る。コンポーネント７０２、７０４、７０６、７０８、７１０、および７１２の各々は、さまざまなバスを用いて相互接続されており、共通のマザーボードにまたは他の好適な態様で必要に応じて搭載可能である。プロセッサ７０２は、コンピューティングデバイス７００内での実行のための命令を処理し得る。これらの命令は、高速インターフェース７０８に接続されたディスプレイ７１６などの、外部入出力デバイス上のＧＵＩのために図形情報を表示するようにメモリ７０４または記憶装置７０６に記憶された命令を含む。他の実施形態例では、複数のプロセッサおよび／または複数のバスは、必要に応じて、複数のメモリおよび複数のタイプのメモリと共に使用可能である。また、複数のコンピューティングデバイス７００は、必要な動作の一部を提供する各デバイスと接続され得る（たとえば、サーババンク、ブレードサーバのグループ、またはマルチプロセッサシステムとして）。
The
メモリ７０４は、コンピューティングデバイス７００内の情報を記憶する。ある実施形態例では、メモリ７０４は、１つまたは複数の揮発性メモリユニットである。他の実施形態例では、メモリ７０４は、１つまたは複数の不揮発性メモリユニットである。また、メモリ７０４は、磁気ディスクまたは光学ディスクなど、他の形式のコンピュータ可読媒体であり得る。
The
記憶装置７０６は、コンピューティングデバイス７００のために大容量記憶装置を提供可能である。ある実施形態例では、記憶装置７０６は、フロッピー（登録商標）ディスクデバイス、ハードディスクデバイス、光学ディスクデバイス、またはテープデバイス、フラッシュメモリもしくは他の類似の固体状態記憶装置デバイス、またはストレージエリアネットワークもしくは他の構成におけるデバイスを含むデバイスの配列であり得る、またはこれらを含み得る。コンピュータプログラム製品は、情報担体において有形に具現化可能である。また、コンピュータプログラム製品は、実行されると上述のような１つ以上の方法を行う命令も含み得る。情報担体は、メモリ７０４、記憶装置７０６、またはプロセッサ７０２上のメモリなど、コンピュータ可読媒体またはマシン可読媒体である。
The
高速コントローラ７０８はコンピューティングデバイス７００のための帯域幅集中操作を処理する一方で、低速コントローラ７１２は、より低い帯域幅集中操作を処理する。機能のこのような割当ては、例示にすぎない。ある実施形態例では、高速コントローラ７０８は、メモリ７０４、ディスプレイ７１６（たとえば、グラフィックプロセッサまたはアクセラレータを介して）、および、さまざまな拡張カード（図示せず）を受け付け可能な高速拡張ポート７１０に接続される。本実施形態例では、低速コントローラ７１２は、記憶装置７０６および低速拡張ポート７１４に接続される。さまざまな通信ポート（たとえば、ＵＳＢ、ブルートゥース（登録商標）、イーサネット（登録商標）、無線イーサネット）を含み得る低速拡張ポートは、たとえばネットワークアダプタを介して、キーボード、ポインティングデバイス、スキャナなどの１つ以上の入出力デバイス、または、スイッチもしくはルータなどのネットワーキングデバイスに接続可能である。
The high-
コンピューティングデバイス７００は、図に示すように、多くの異なる形式で実現可能である。たとえば、標準的なサーバ７２０として、またはそのようなサーバのグループにおいて何度も実現可能である。また、ラックサーバシステム７２４の一部としても実現可能である。さらに、ラップトップコンピュータ７２２などのパーソナルコンピュータにおいて実現可能である。代替的に、コンピューティングデバイス７００からのコンポーネントは、デバイス７５０などのモバイルデバイス（図示せず）における他のコンポーネントと組み合わせ得る。このようなデバイスの各々は、コンピューティングデバイス７００、７５０のうちの１つ以上を含み得、システム全体を、互いに通信する複数のコンピューティングデバイス７００、７５０で構成し得る。
The
コンピューティングデバイス７５０は、他のコンポーネントのうち、プロセッサ７５２、メモリ７６４、ディスプレイ７５４などの入出力デバイス、通信インターフェース７６６、およびトランシーバ７６８を含む。また、デバイス７５０には、追加のストレージを提供するために、マイクロドライブまたは他のデバイスなどの記憶デバイスが設けられ得る。コンポーネント７５０、７５２、７６４、７５４、７６６、および７６８の各々は、さまざまなバスを用いて相互接続され、これらのコンポーネントのうちの複数は、共通のマザーボードにまたは必要に応じて他の態様で搭載され得る。
The
プロセッサ７５２は、メモリ７６４に記憶された命令を含む、コンピューティングデバイス７５０内の命令を実行可能である。プロセッサは、別々の複数のアナログおよびデジタルプロセッサを含むチップのチップセットとして実現可能である。プロセッサは、たとえば、ユーザインターフェース、デバイス７５０によって実行されるアプリアケーション、およびデバイス７５０による無線通信の制御など、デバイス７５０の他のコンポーネントの協調をもたらし得る。
プロセッサ７５２は、ディスプレイ７５４に接続された制御インターフェース７５８およびディスプレイインターフェース７５６を介してユーザと通信可能である。ディスプレイ７５４は、たとえば、ＴＦＴ ＬＣＤ（薄膜トランジスタ液晶ディスプレイ）もしくはＯＥＬＤ（有機発光ダイオード）ディスプレイ、または他の好適なディスプレイ技術であり得る。ディスプレイインターフェース７５６は、ディスプレイ７５４を駆動してユーザにグラフィカル情報および他の情報を提示するための好適な回路を含み得る。制御インターフェース７５８は、ユーザからのコマンドを受信し得、プロセッサ７５２に送信するためにコマンドを変換し得る。さらに、外部インターフェース７６２は、デバイス７５０の他のデバイスとの近距離通信が可能になるように、プロセッサ７５２との通信において提供され得る。外部インターフェース７６２は、たとえば、いくつかの実施形態例では有線通信を提供し得る、または他の実施形態例では無線通信を提供し得る、かつ、複数のインターフェースも使用し得る。
The
メモリ７６４は、コンピューティングデバイス７５０内の情報を記憶する。メモリ７６４は、１つもしくは複数のコンピュータ可読媒体、１つもしくは複数の揮発性メモリユニット、または１つもしくは複数の不揮発性メモリユニットのうちの１つまたは複数として実現可能である。また、拡張メモリ７７４を、拡張インターフェース７７２を通じてデバイス７５０に設ける、および接続することが可能であり、このインターフェースは、たとえば、ＳＩＭＭ（シングルインラインメモリモジュール）カードインターフェースを含み得る。このような拡張メモリ７７４は、デバイス７５０のために追加の記憶空間を提供し得る、または、デバイス７５０のためにアプリケーションまたは他の情報を記憶し得る。具体的に、拡張メモリ７７４は、上述の処理の実行または補足を行う命令を含み得、セキュアな情報も含み得る。そのため、たとえば、拡張メモリ７７４はデバイス７５０のためのセキュリティーモジュールとして提供可能であり、デバイス７５０のセキュアな使用を許可する命令でプログラム可能である。さらに、セキュアなアプリケーションは、追加の情報と共にＳＩＭＭカードを介して提供され得、たとえば、ハッキング不可能な態様でＳＩＭＭカードに識別情報を置く。
メモリは、たとえば、以下で説明するように、フラッシュメモリおよび／またはＮＶＲＡＭメモリを含み得る。一実施形態例では、コンピュータプログラム製品は、情報担体において有形に具現化される。コンピュータプログラム製品は、実行されると、上述のような１つまたは複数の方法を行う命令を含む。情報担体は、たとえばトランシーバ７６８もしくは外部インターフェース７６２を介して受信可能なメモリ７６４、拡張メモリ７７４、またはプロセッサ７５２上のメモリなどの、コンピュータ可読媒体またはマシン可読媒体である。
The memory may include, for example, flash memory and / or NVRAM memory as described below. In one embodiment, the computer program product is tangibly embodied in an information carrier. Computer program products include instructions that, when executed, perform one or more of the methods described above. The information carrier is a computer-readable or machine-readable medium, such as
デバイス７５０は、必要に応じてデジタル信号処理回路を含み得る通信インターフェース７６６を介して無線通信可能である。通信インターフェース７６６は、とりわけ、ＧＳＭ（登録商標）音声電話、ＳＭＳ、ＥＭＳもしくはＭＭＳメッセージング、ＣＤＭＡ、ＴＤＭＡ、ＰＤＣ、ＷＣＤＭＡ（登録商標）、ＣＤＭＡ２０００、またはＧＰＲＳなどの、さまざまなモードまたはプロトコールで通信を提供し得る。このような通信は、たとえば、無線周波トランシーバ７６８を通じて発生し得る。さらに、近距離通信は、ブルートゥース、ＷｉＦｉまたは他のそのようなトランシーバ（図示せず）を使用することによって発生し得る。さらに、ＧＰＳ（全地球測位システム）レシーバモジュール７７０は、追加のナビゲーション関連無線データおよび位置関連無線データをデバイス７５０に提供し得る。これらの情報は、デバイス７５０上で実行されているアプリケーションによって必要に応じて使用され得る。
The
デバイス７５０は、ユーザからの音声情報を受信して利用可能なデジタル情報に変換し得るオーディオコーデック７６０を用いて、可聴的に通信することも可能である。同様に、オーディオコーデック７６０は、たとえばデバイス７５０のハンドセットにおいてスピーカを通して、ユーザのために可聴音を生成することも可能である。このような音は、電話音声コールからの音を含み得る、記録された音（たとえば、ボイスメッセージ、ミュージックファイルなど）を含み得る、および、デバイス７５０上で動作するアプリケーションによって生成された音も含み得る。
The
コンピューティングデバイス７５０は、図に示すように、複数の異なる形式で実現可能である。たとえば、携帯電話７８０として実現可能である。また、スマートフォン７８２、パーソナルデジタルアシスタント、または他の類似のモバイルデバイスの一部としても実現可能である。
The
ユーザは、追跡されたコントローラ７８４を用いてコンピューティングデバイスと相互作用可能である。いくつかの実施形態例では、コントローラ７８４は、手、足、頭および／または胴体などのユーザの体の移動を追跡可能であり、追跡された動きに対応する入力を生成することも可能である。入力は、たとえば３次元など、動きの１つ以上の次元で移動に対応し得る。たとえば、追跡されたコントローラは、ＶＲアプリケーションにおいて１つ以上の仮想コントローラと対応付けられた、ＶＲアプリケーション用の物理的なコントローラであり得る。他の例として、コントローラ７８４は、データグローブを含み得る。
The user can interact with the computing device using the tracked
ここで説明するシステムおよび技術のさまざまな実施形態例は、デジタル電子回路、集積回路、特別に設計されたＡＳＩＣｓ（特定用途向け集積回路）、コンピュータハードウェア、ファームウェア、ソフトウェア、および／またはこれらの組合せで実現可能である。これらのさまざまな実施形態例は、特定のまたは一般の目的でもよい、記憶システムとの間でデータおよび命令を送受信するように接続された少なくとも１つのプログラム可能なプロセッサ、少なくとも１つの入力デバイス、ならびに少なくとも１つの出力デバイスを含むプログラム可能なシステム上で実行可能なおよび／または解釈可能な１つ以上のコンピュータプログラムにおける実施形態例を含み得る。 Various embodiments of the systems and techniques described herein include digital electronic circuits, integrated circuits, specially designed ASICs (application-specific integrated circuits), computer hardware, firmware, software, and / or combinations thereof. It is feasible with. These various embodiments may include at least one programmable processor, at least one input device, and at least one input device connected to send and receive data and instructions to and from a storage system, which may be for specific or general purposes. It may include embodiments in one or more computer programs that are executable and / or interpretable on a programmable system that includes at least one output device.
これらのコンピュータプログラム（プログラム、ソフトウェア、ソフトウェアアプリケーションまたはコードとしても知られている）は、プログラム可能なプロセッサのための機械命令を含み、ハイレベル手順のおよび／またはオブジェクト指向のプログラミング言語および／またはアセンブリ／機械言語で実現可能である。ここで使用されているように、「機械可読媒体」「コンピュータ可読媒体」という用語は、機械可読信号として機械命令を受信する機械可読媒体を含むプログラム可能なプロセッサに機械命令および／またはデータを提供するために使用される任意のコンピュータプログラム製品、装置および／またはデバイス（たとえば、磁気ディスク、光学ディスク、メモリ、プログラム可能論理デバイス（ＰＬＤｓ））を表す。「機械可読信号」という用語は、プログラム可能なプロセッサに機械命令および／またはデータを提供するために使用される信号を表す。 These computer programs (also known as programs, software, software applications or code) include machine instructions for programmable processors, high-level procedural and / or object-oriented programming languages and / or assemblies. / It can be realized in a machine language. As used herein, the terms "machine-readable medium" and "computer-readable medium" provide machine instructions and / or data to a programmable processor that includes a machine-readable medium that receives machine instructions as a machine-readable signal. Represents any computer program product, device and / or device (eg, magnetic disk, optical disk, memory, programmable logical devices (PLDs)) used to. The term "machine readable signal" refers to a signal used to provide machine instructions and / or data to a programmable processor.
ユーザとの相互作用を提供するために、ここで説明されるシステムおよび技術は、情報をユーザに表示するためのディスプレイデバイス（たとえば、ＣＲＴ（陰極線管）またはＬＣＤ（液晶ディスプレイ）モニタ）、ユーザが入力をコンピュータに提供可能なキーボードおよびポインティングデバイス（たとえば、マウスまたはトラックボール）を有するコンピュータ上で実現可能である。他の種類のデバイスを使用してユーザとの相互作用を提供することも可能である。たとえば、ユーザに提供されるフィードバックはいかなる形式の感覚フィードバック（たとえば、視覚的なフィードバック、聴覚的なフィードバック、または触覚的なフィードバック）でもよい、かつ、ユーザからの入力は、聴覚的な入力、音声入力、または触覚的な入力を含むいかなる形式でも受信可能である。 To provide user interaction, the systems and techniques described herein include display devices for displaying information to the user (eg, CRT (cathode tube) or LCD (liquid crystal display) monitor), where the user It is feasible on a computer having a keyboard and pointing device (eg, a mouse or trackball) that can provide input to the computer. It is also possible to use other types of devices to provide user interaction. For example, the feedback provided to the user may be any form of sensory feedback (eg, visual feedback, auditory feedback, or tactile feedback), and the user input may be auditory input, audio. It can be received in any format, including input or tactile input.
ここで説明されるシステムおよび技術は、バックエンドコンポーネント（たとえば、データサーバ）を含む、または、ミドルウェアコンポーネント（たとえば、アプリケーションサーバ）を含む、またはフロントエンドコンポーネント（たとえば、それを通じて、ユーザがここで説明されるシステムおよび技術の実現と相互作用可能なグラフィカルユーザインターフェースまたはウェブブラウザを有するクライアントコンピュータ）を含むコンピューティングシステムにおいて実現可能である。システムのコンポーネントは、デジタルデータ通信（たとえば、通信ネットワーク）のいかなる形式でもまたは媒体によっても相互接続可能である。通信ネットワークの例としては、ローカルエリアネットワーク（「ＬＡＮ」）、ワイドエリアネットワーク（「ＷＡＮ」）、およびインターネットが挙げられる。 The systems and techniques described herein include back-end components (eg, data servers), or include middleware components (eg, application servers), or front-end components (eg, through which users describe here. It is feasible in computing systems including client computers with graphical user interfaces or web browsers that can interact with the realization of the systems and technologies to be implemented. The components of the system can be interconnected in any form or medium of digital data communication (eg, communication networks). Examples of communication networks include local area networks (“LAN”), wide area networks (“WAN”), and the Internet.
コンピューティングシステムは、クライアントおよびサーバを含み得る。クライアントおよびサーバは、通常互いに離れており、通信ネットワークを介して相互接続することが一般的である。クライアントとサーバとの関係は、それぞれのコンピュータ上で実行され相互にクライアント−サーバ関係を有するコンピュータプログラムによって生じる。 Computing systems can include clients and servers. Clients and servers are usually separated from each other and are typically interconnected via a communication network. The client-server relationship arises from computer programs that run on their respective computers and have a client-server relationship with each other.
いくつかの実施形態例では、図７に示すコンピューティングデバイスは、仮想現実（ＶＲヘッドセット７８５）と相互作用するセンサを含み得る。たとえば、コンピューティングデバイス７５０または図７に示す他のコンピューティングデバイスに含まれる１つ以上のセンサは、入力をＶＲヘッドセット７８５へ、または一般に、入力をＶＲ空間へ提供可能である。センサは、タッチスクリーン、加速度計、ジャイロスコープ、圧力センサ、生体認証センサ、温度センサ、湿度センサ、および環境光センサを含み得るが、これらに限定されるわけではない。コンピューティングデバイス７５０は、これらのセンサを用いてＶＲ空間内のコンピューティングデバイスの絶対位置および／または検出された回転を求めることができ、これはその後、ＶＲ空間への入力として使用可能である。たとえば、コンピューティングデバイス７５０は、コントローラ、レーザーポインタ、キーボード、武器など、仮想オブジェクトとしてＶＲ空間に組込むことができる。ＶＲ空間に組込まれると、ユーザによるコンピューティングデバイス／仮想オブジェクトの位置決めによって、ユーザは、コンピューティングデバイスを位置決めして、ＶＲ空間内で特定の態様で仮想オブジェクトを眺めることができる。たとえば、仮想オブジェクトがレーザポインタを表す場合、ユーザは、それがあたかも実際のレーザポインタであるかのようにコンピューティングデバイスを操作可能である。ユーザは、コンピューティングデバイスを、たとえば左右、上下、円形に移動させることが可能であり、レーザプリンタを使用する態様と類似の態様でデバイスを使用可能である。
In some embodiments, the computing device shown in FIG. 7 may include a sensor that interacts with virtual reality (VR headset 785). For example, one or more sensors included in the
いくつかの実施形態例では、コンピューティングデバイス７５０に備えられる、またはこれに接続する１つ以上の入力デバイスを、ＶＲ空間への入力として使用可能である。入力デバイスは、タッチスクリーン、キーボード、１つ以上のボタン、トラックパッド、ポインティングデバイス、マウス、トラックボール、ジョイスティック、カメラ、マイク、入力機能を有するイヤホンもしくはイヤーバッド、ゲームコントローラ、または他の接続可能な入力デバイスを含み得るが、これらに限定されるわけではない。コンピューティングデバイスがＶＲ空間に組込まれるとコンピューティングデバイス７５０に含まれる入力デバイスと相互作用するユーザは、ＶＲ空間において特定のアクションを発生させ得る。
In some embodiments, one or more input devices provided or connected to the
いくつかの実施形態例では、コンピューティングデバイス７５０のタッチスクリーンは、ＶＲ空間内のタッチパッドとして提供され得る。ユーザは、コンピューティングデバイス７５０のタッチスクリーンと相互作用可能である。たとえばＶＲヘッドセット７８５において、相互作用は、ＶＲ空間のタッチパッドにおいて提供される動きとして提供される。提供される動きは、ＶＲ空間のオブジェクトを制御可能である。
In some embodiments, the touch screen of the
いくつかの実施形態例では、コンピューティングデバイス７５０に含まれる１つ以上の出力デバイスは、ＶＲ空間のＶＲヘッドセット７８５のユーザへ出力および／またはフィードバックを提供可能である。出力およびフィードバックは、視覚的、触覚的、可聴的であり得る。出力および／またはフィードバックは、振動、１つ以上のライトまたはストロボのオンオフまたは点滅および／またはフラッシュ、警告音の再生、チャイムの鳴動、歌の再生、および音声ファイルの再生を含み得るが、これらに限定されるわけではない。出力デバイスは、振動モータ、振動コイル、圧電素子、静電素子、発光ダイオード（ＬＥＤｓ）、ストロボ、およびスピーカを含み得るが、これらに限定されるわけではない。
In some embodiments, one or more output devices included in the
いくつかの実施形態例では、コンピューティングデバイス７５０は、コンピュータによって生成された３Ｄ環境における他のオブジェクトとして表示され得る。ユーザによるコンピューティングデバイス７５０との相互作用（たとえば、回転、揺れ、タッチスクリーンとの接触、タッチスクリーンを横断する指のスワイプ）は、ＶＲ空間におけるオブジェクトとの相互作用として解釈可能である。ＶＲ空間におけるレーザポインタの例では、コンピューティングデバイス７５０は、コンピュータによって生成される３Ｄ環境における仮想レーザーポインタとして表示される。ユーザがコンピューティングデバイス７５０を操作すると、ＶＲ空間におけるユーザは、レーザポインタの移動が見える。ユーザは、コンピューティングデバイス７５０上のまたはＶＲヘッドセット７８５上のＶＲ空間におけるコンピューティングデバイス７５０との相互作用からフィードバックを受信する。
In some embodiments, the
複数の実施形態について説明を行ったが、本発明の精神および範囲内でさまざまな修正が可能であることが理解されるであろう。 Although a plurality of embodiments have been described, it will be appreciated that various modifications are possible within the spirit and scope of the invention.
さらに、図面に示される論理の流れは、望ましい結果を得るために、図示された特定の順序または順番を必要とするものではない。さらに、上述の流れに他のステップを設けることが可能である、または、上述の流れからステップを削除することが可能である、および、説明されたシステムに他のコンポーネントを追加可能である、または、説明されたシステムからコンポーネントを削除可能である。そのため、他の実施形態は、以下の特許請求の範囲内である。 Moreover, the logic flow shown in the drawings does not require the particular order or order shown to obtain the desired result. In addition, other steps can be added to the above flow, or steps can be removed from the above flow, and other components can be added to the described system, or , It is possible to remove components from the described system. Therefore, other embodiments are within the scope of the following claims.
Claims (21)
第１の機能を前記第１の仮想コントローラに割当てて、前記１以上の物理的なコントローラを用いて前記第１の機能の性能を提供することと、
前記コンピュータシステムにおいて、第２の仮想コントローラを前記１以上の物理的なコントローラに対応付けることと、
第２の機能を前記第２の仮想コントローラに割り当てることと、
前記１以上の物理的なコントローラを用いて行われたジェスチャを検出することと、
前記ジェスチャの検出に応じて、前記第１の仮想コントローラから前記第１の機能の割当てを解除して前記第２の仮想コントローラに割り当て、かつ、前記第２の仮想コントローラから前記第２の機能の割り当てを解除して前記第１の仮想コントローラに割り当てることとを備える、方法。 In a computer system, associating a first virtual controller with one or more physical controllers
Assigning the first function to the first virtual controller and using the one or more physical controllers to provide the performance of the first function.
In the computer system, associating the second virtual controller with the one or more physical controllers
Assigning the second function to the second virtual controller and
Detecting gestures made using one or more physical controllers,
In response to the detection of the gesture, the first function is released from the first virtual controller and assigned to the second virtual controller, and the second virtual controller is assigned to the second function. A method comprising deallocating and assigning to the first virtual controller.
前記１以上の物理的なコントローラを用いて前記第１の仮想コントローラを対応付けることは、前記第１の物理的なコントローラを用いて前記第１の仮想コントローラに対応付けることを含み、
前記１以上の物理的なコントローラを用いて前記第２の仮想コントローラを対応付けることは、前記第２の物理的なコントローラを用いて前記第２の仮想コントローラを対応付けることを含む、請求項１または請求項２に記載の方法。 The one or more physical controllers include a first physical controller and a second physical controller.
Associating the first virtual controller with the one or more physical controllers includes associating the first virtual controller with the first physical controller.
Claim 1 or claim that associating the second virtual controller with one or more physical controllers comprises associating the second virtual controller with the second physical controller. Item 2. The method according to item 2.
第１の機能を前記第１の仮想コントローラに割当てて、前記１以上の物理的なコントローラを用いて前記第１の機能の性能を提供することと、
前記１以上の物理的なコントローラを用いて行われたジェスチャを検出することと、
前記ジェスチャの検出に応じて、前記第１の仮想コントローラから前記第１の機能の割当てを解除することと、を備え、
前記第１の仮想コントローラは前記コンピュータシステムによって生成された仮想空間において定義され、
前記仮想空間においてポイントを定義することと、前記ジェスチャの検出に応じて、前記第１の機能を前記ポイントと対応付けることとをさらに備える、方法。 In a computer system, associating a first virtual controller with one or more physical controllers
Assigning the first function to the first virtual controller and using the one or more physical controllers to provide the performance of the first function.
Detecting gestures made using one or more physical controllers,
In response to the detection of the gesture, the first function is released from the first virtual controller.
The first virtual controller is defined in the virtual space generated by the computer system.
A method further comprising defining a point in the virtual space and associating the first function with the point in response to the detection of the gesture.
前記１以上の物理的なコントローラを用いて前記第１の仮想コントローラと対応付けることは、前記第１の物理的なコントローラを用いて前記第１の仮想コントローラと対応付けることを含み、
前記方法はさらに、
前記コンピュータシステムにおける第２の仮想コントローラを前記第２の物理的なコントローラと対応付けることと、
第２の機能を前記第２の仮想コントローラに割当てることとを備える、請求項１０または請求項１１に記載の方法。 The one or more physical controllers include a first physical controller and a second physical controller.
Associating with the first virtual controller using the one or more physical controllers includes associating with the first virtual controller using the first physical controller.
The method further
Associating the second virtual controller in the computer system with the second physical controller
10. The method of claim 10, comprising assigning a second function to the second virtual controller.
前記第１の物理的なコントローラと前記第２の物理的なコントローラの一方は、右手で持たれるように構成された外観要素を有し、
前記第１の物理的なコントローラと前記第２の物理的なコントローラの他方は、左手で持たれるように構成された外観要素を有する、請求項１に記載の方法。 The one or more physical controllers include a first physical controller and a second physical controller.
One of the first physical controller and the second physical controller has an appearance element configured to be held by the right hand.
The method of claim 1, wherein the other of the first physical controller and the second physical controller has an appearance element configured to be held by the left hand.
実行されると前記プロセッサに請求項１〜請求項１９のいずれか１項に記載の操作を行わせる命令を含む、非一時的な記憶媒体において有形に具現化されたコンピュータプログラム製品とを備える、システム。 With the processor
Includes a computer program product tangibly embodied in a non-temporary storage medium, comprising an instruction that causes the processor to perform the operation according to any one of claims 1 to 19, when executed. system.
Applications Claiming Priority (5)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201762448172P | 2017-01-19 | 2017-01-19 | |
US62/448,172 | 2017-01-19 | ||
US15/794,265 | 2017-10-26 | ||
US15/794,265 US10459519B2 (en) | 2017-01-19 | 2017-10-26 | Function allocation for virtual controller |
PCT/US2017/059029 WO2018136126A1 (en) | 2017-01-19 | 2017-10-30 | Function allocation for virtual controller |
Publications (2)
Publication Number | Publication Date |
---|---|
JP2020500356A JP2020500356A (en) | 2020-01-09 |
JP6859433B2 true JP6859433B2 (en) | 2021-04-14 |
Family
ID=62838710
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2019520892A Active JP6859433B2 (en) | 2017-01-19 | 2017-10-30 | Function assignment for virtual controller |
Country Status (6)
Country | Link |
---|---|
US (1) | US10459519B2 (en) |
EP (1) | EP3571571B1 (en) |
JP (1) | JP6859433B2 (en) |
KR (1) | KR102290933B1 (en) |
CN (1) | CN109716267B (en) |
WO (1) | WO2018136126A1 (en) |
Families Citing this family (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
KR102065421B1 (en) * | 2017-08-10 | 2020-01-13 | 엘지전자 주식회사 | Mobile device and method of providing a controller for virtual reality device |
US11861136B1 (en) * | 2017-09-29 | 2024-01-02 | Apple Inc. | Systems, methods, and graphical user interfaces for interacting with virtual reality environments |
US10824244B2 (en) * | 2018-11-19 | 2020-11-03 | Facebook Technologies, Llc | Systems and methods for transitioning between modes of tracking real-world objects for artificial reality interfaces |
Family Cites Families (31)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20060097453A1 (en) | 2002-12-04 | 2006-05-11 | Philip Feldman | Game controller with force sensing input devices and method of measuring applied forces to game controller input devices to interact with a gaming application |
US20070155589A1 (en) | 2002-12-04 | 2007-07-05 | Philip Feldman | Method and Apparatus for Operatively Controlling a Virtual Reality Scenario with an Isometric Exercise System |
JP2006350838A (en) | 2005-06-17 | 2006-12-28 | Fujitsu Ltd | Information processing apparatus and program |
JP5204381B2 (en) * | 2006-05-01 | 2013-06-05 | 任天堂株式会社 | GAME PROGRAM, GAME DEVICE, GAME SYSTEM, AND GAME PROCESSING METHOD |
US7701439B2 (en) | 2006-07-13 | 2010-04-20 | Northrop Grumman Corporation | Gesture recognition simulation system and method |
JP2010245796A (en) * | 2009-04-06 | 2010-10-28 | Sony Corp | Video display and method, video display system, and program |
EP3320875A1 (en) * | 2009-11-13 | 2018-05-16 | Intuitive Surgical Operations Inc. | Apparatus for hand gesture control in a minimally invasive surgical system |
US8217997B2 (en) * | 2010-03-16 | 2012-07-10 | Interphase Corporation | Interactive display system |
JP5531750B2 (en) * | 2010-04-16 | 2014-06-25 | ソニー株式会社 | Information processing apparatus, information processing method, program, and information processing system |
US20110276891A1 (en) * | 2010-05-06 | 2011-11-10 | Marc Ecko | Virtual art environment |
US9411509B2 (en) * | 2010-12-29 | 2016-08-09 | Microsoft Technology Licensing, Llc | Virtual controller for touch display |
US20130265240A1 (en) * | 2012-04-06 | 2013-10-10 | At&T Intellectual Property I, Lp | Method and apparatus for presenting a virtual touchscreen |
US9254437B2 (en) | 2012-04-25 | 2016-02-09 | Electronic Entertainment Design And Research | Interactive gaming analysis systems and methods |
US9041622B2 (en) * | 2012-06-12 | 2015-05-26 | Microsoft Technology Licensing, Llc | Controlling a virtual object with a real controller device |
CN104813258B (en) * | 2012-11-22 | 2017-11-10 | 夏普株式会社 | Data input device |
US11826636B2 (en) * | 2013-07-12 | 2023-11-28 | Chris Argiro | Depth sensing module and mobile device including the same |
CN103442244A (en) | 2013-08-30 | 2013-12-11 | 北京京东方光电科技有限公司 | 3D glasses, 3D display system and 3D display method |
JP2015114836A (en) * | 2013-12-11 | 2015-06-22 | キヤノン株式会社 | Image processing device, tactile control method, and program |
US9937415B1 (en) * | 2013-12-17 | 2018-04-10 | Amazon Technologies, Inc. | Virtual controller for touchscreen |
FR3016451B1 (en) * | 2014-01-10 | 2017-06-23 | Inria Inst Nat De Rech En Informatique Et En Automatique | INTERACTION SYSTEM WITH VIRTUAL OBJECTS |
US20170036386A1 (en) * | 2014-04-03 | 2017-02-09 | Macro Technology Ltd. | Co-extrusion die with rectangular feed channel |
US9696813B2 (en) * | 2015-05-27 | 2017-07-04 | Hsien-Hsiang Chiu | Gesture interface robot |
US10019059B2 (en) * | 2014-08-22 | 2018-07-10 | Sony Interactive Entertainment Inc. | Glove interface object |
US10286308B2 (en) * | 2014-11-10 | 2019-05-14 | Valve Corporation | Controller visualization in virtual and augmented reality environments |
WO2016094568A1 (en) * | 2014-12-10 | 2016-06-16 | Sixense Entertainment, Inc. | System and method for assisting a user in remaining in a selected area while the user is in a virtual reality environment |
CN107710009B (en) * | 2015-02-27 | 2021-06-29 | 威尔乌集团 | Controller visualization in virtual and augmented reality environments |
US10102674B2 (en) | 2015-03-09 | 2018-10-16 | Google Llc | Virtual reality headset connected to a mobile computing device |
WO2017082457A1 (en) * | 2015-11-11 | 2017-05-18 | 엘지전자 주식회사 | Hmd and method for controlling same |
CN105892675A (en) | 2016-04-26 | 2016-08-24 | 乐视控股（北京）有限公司 | Handle-based method, device and system for controlling virtual reality headset |
US20170329440A1 (en) * | 2016-05-12 | 2017-11-16 | Cirque Corporation | Controller premonition using capacitive sensing |
CN106325735A (en) * | 2016-07-19 | 2017-01-11 | 钟林 | Method and device for operating video games by bearing gesture touch |
-
2017
- 2017-10-26 US US15/794,265 patent/US10459519B2/en active Active
- 2017-10-30 KR KR1020197012238A patent/KR102290933B1/en active IP Right Grant
- 2017-10-30 JP JP2019520892A patent/JP6859433B2/en active Active
- 2017-10-30 CN CN201780057985.3A patent/CN109716267B/en active Active
- 2017-10-30 WO PCT/US2017/059029 patent/WO2018136126A1/en unknown
- 2017-10-30 EP EP17893280.2A patent/EP3571571B1/en active Active
Also Published As
Publication number | Publication date |
---|---|
US20180203502A1 (en) | 2018-07-19 |
JP2020500356A (en) | 2020-01-09 |
KR20190059946A (en) | 2019-05-31 |
EP3571571A1 (en) | 2019-11-27 |
WO2018136126A1 (en) | 2018-07-26 |
EP3571571B1 (en) | 2023-10-25 |
US10459519B2 (en) | 2019-10-29 |
CN109716267B (en) | 2022-11-29 |
CN109716267A (en) | 2019-05-03 |
KR102290933B1 (en) | 2021-08-19 |
EP3571571A4 (en) | 2020-11-04 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
JP6895390B2 (en) | A system for tracking handheld electronics in virtual reality | |
US10339723B2 (en) | Generating virtual notation surfaces with gestures in an augmented and/or virtual reality environment | |
US10782793B2 (en) | Context-sensitive hand interaction | |
CN109074154B (en) | Hovering touch input compensation in augmented and/or virtual reality | |
CN107533373B (en) | Input via context-sensitive collision of hands with objects in virtual reality | |
KR102233807B1 (en) | Input Controller Stabilization Technique for Virtual Reality System | |
EP3234742A2 (en) | Methods and apparatus for high intuitive human-computer interface | |
JP2023526270A (en) | Low-power semi-passive relative 6-DOF tracking | |
JP7030854B2 (en) | Tracking the location and orientation of virtual controllers in a virtual reality system | |
JP6859433B2 (en) | Function assignment for virtual controller | |
CN111373349B (en) | Method, apparatus and storage medium for navigating in augmented reality environment | |
JP7252252B2 (en) | Initiate modal control based on hand position | |
US10665067B2 (en) | Systems and methods for integrating haptics overlay in augmented reality |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20190418 |
|
A621 | Written request for application examination |
Free format text: JAPANESE INTERMEDIATE CODE: A621Effective date: 20190418 |
|
A977 | Report on retrieval |
Free format text: JAPANESE INTERMEDIATE CODE: A971007Effective date: 20200526 |
|
A131 | Notification of reasons for refusal |
Free format text: JAPANESE INTERMEDIATE CODE: A131Effective date: 20200616 |
|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20200908 |
|
A131 | Notification of reasons for refusal |
Free format text: JAPANESE INTERMEDIATE CODE: A131Effective date: 20201104 |
|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20210120 |
|
TRDD | Decision of grant or rejection written | ||
A01 | Written decision to grant a patent or to grant a registration (utility model) |
Free format text: JAPANESE INTERMEDIATE CODE: A01Effective date: 20210224 |
|
A61 | First payment of annual fees (during grant procedure) |
Free format text: JAPANESE INTERMEDIATE CODE: A61Effective date: 20210325 |
|
R150 | Certificate of patent or registration of utility model |
Ref document number: 6859433Country of ref document: JPFree format text: JAPANESE INTERMEDIATE CODE: R150 |
|
R250 | Receipt of annual fees |
Free format text: JAPANESE INTERMEDIATE CODE: R250 |