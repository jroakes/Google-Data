JP2022521960A - Variable endpoint user interface rendering - Google Patents
Variable endpoint user interface rendering Download PDFInfo
- Publication number
- JP2022521960A JP2022521960A JP2021549677A JP2021549677A JP2022521960A JP 2022521960 A JP2022521960 A JP 2022521960A JP 2021549677 A JP2021549677 A JP 2021549677A JP 2021549677 A JP2021549677 A JP 2021549677A JP 2022521960 A JP2022521960 A JP 2022521960A
- Authority
- JP
- Japan
- Prior art keywords
- rendering
- control component
- endpoint device
- resolution
- component
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
Images
Classifications
-
- A—HUMAN NECESSITIES
- A63—SPORTS; GAMES; AMUSEMENTS
- A63F—CARD, BOARD, OR ROULETTE GAMES; INDOOR GAMES USING SMALL MOVING PLAYING BODIES; VIDEO GAMES; GAMES NOT OTHERWISE PROVIDED FOR
- A63F13/00—Video games, i.e. games using an electronically generated display having two or more dimensions
- A63F13/50—Controlling the output signals based on the game progress
- A63F13/53—Controlling the output signals based on the game progress involving additional visual information provided to the game scene, e.g. by overlay to simulate a head-up display [HUD] or displaying a laser sight in a shooting game
- A63F13/537—Controlling the output signals based on the game progress involving additional visual information provided to the game scene, e.g. by overlay to simulate a head-up display [HUD] or displaying a laser sight in a shooting game using indicators, e.g. showing the condition of a game character on screen
-
- A—HUMAN NECESSITIES
- A63—SPORTS; GAMES; AMUSEMENTS
- A63F—CARD, BOARD, OR ROULETTE GAMES; INDOOR GAMES USING SMALL MOVING PLAYING BODIES; VIDEO GAMES; GAMES NOT OTHERWISE PROVIDED FOR
- A63F13/00—Video games, i.e. games using an electronically generated display having two or more dimensions
- A63F13/30—Interconnection arrangements between game servers and game devices; Interconnection arrangements between game devices; Interconnection arrangements between game servers
- A63F13/32—Interconnection arrangements between game servers and game devices; Interconnection arrangements between game devices; Interconnection arrangements between game servers using local area network [LAN] connections
-
- A—HUMAN NECESSITIES
- A63—SPORTS; GAMES; AMUSEMENTS
- A63F—CARD, BOARD, OR ROULETTE GAMES; INDOOR GAMES USING SMALL MOVING PLAYING BODIES; VIDEO GAMES; GAMES NOT OTHERWISE PROVIDED FOR
- A63F13/00—Video games, i.e. games using an electronically generated display having two or more dimensions
- A63F13/30—Interconnection arrangements between game servers and game devices; Interconnection arrangements between game devices; Interconnection arrangements between game servers
- A63F13/35—Details of game servers
- A63F13/355—Performing operations on behalf of clients with restricted processing capabilities, e.g. servers transform changing game scene into an MPEG-stream for transmitting to a mobile phone or a thin client
-
- A—HUMAN NECESSITIES
- A63—SPORTS; GAMES; AMUSEMENTS
- A63F—CARD, BOARD, OR ROULETTE GAMES; INDOOR GAMES USING SMALL MOVING PLAYING BODIES; VIDEO GAMES; GAMES NOT OTHERWISE PROVIDED FOR
- A63F13/00—Video games, i.e. games using an electronically generated display having two or more dimensions
- A63F13/50—Controlling the output signals based on the game progress
- A63F13/52—Controlling the output signals based on the game progress involving aspects of the displayed game scene
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/44—Arrangements for executing specific programs
- G06F9/451—Execution arrangements for user interfaces
- G06F9/452—Remote windowing, e.g. X-Window System, desktop virtualisation
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/20—Servers specifically adapted for the distribution of content, e.g. VOD servers; Operations thereof
- H04N21/23—Processing of content or additional data; Elementary server operations; Server middleware
- H04N21/234—Processing of video elementary streams, e.g. splicing of video streams, manipulating MPEG-4 scene graphs
- H04N21/2343—Processing of video elementary streams, e.g. splicing of video streams, manipulating MPEG-4 scene graphs involving reformatting operations of video signals for distribution or compliance with end-user requests or end-user device requirements
- H04N21/234363—Processing of video elementary streams, e.g. splicing of video streams, manipulating MPEG-4 scene graphs involving reformatting operations of video signals for distribution or compliance with end-user requests or end-user device requirements by altering the spatial resolution, e.g. for clients with a lower screen resolution
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/20—Servers specifically adapted for the distribution of content, e.g. VOD servers; Operations thereof
- H04N21/23—Processing of content or additional data; Elementary server operations; Server middleware
- H04N21/234—Processing of video elementary streams, e.g. splicing of video streams, manipulating MPEG-4 scene graphs
- H04N21/2343—Processing of video elementary streams, e.g. splicing of video streams, manipulating MPEG-4 scene graphs involving reformatting operations of video signals for distribution or compliance with end-user requests or end-user device requirements
- H04N21/23439—Processing of video elementary streams, e.g. splicing of video streams, manipulating MPEG-4 scene graphs involving reformatting operations of video signals for distribution or compliance with end-user requests or end-user device requirements for generating different versions
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/20—Servers specifically adapted for the distribution of content, e.g. VOD servers; Operations thereof
- H04N21/23—Processing of content or additional data; Elementary server operations; Server middleware
- H04N21/236—Assembling of a multiplex stream, e.g. transport stream, by combining a video stream with other content or additional data, e.g. inserting a URL [Uniform Resource Locator] into a video stream, multiplexing software data into a video stream; Remultiplexing of multiplex streams; Insertion of stuffing bits into the multiplex stream, e.g. to obtain a constant bit-rate; Assembling of a packetised elementary stream
- H04N21/23614—Multiplexing of additional data and video streams
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/43—Processing of content or additional data, e.g. demultiplexing additional data from a digital video stream; Elementary client operations, e.g. monitoring of home network or synchronising decoder's clock; Client middleware
- H04N21/431—Generation of visual interfaces for content selection or interaction; Content or additional data rendering
- H04N21/4312—Generation of visual interfaces for content selection or interaction; Content or additional data rendering involving specific graphical features, e.g. screen layout, special fonts or colors, blinking icons, highlights or animations
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/43—Processing of content or additional data, e.g. demultiplexing additional data from a digital video stream; Elementary client operations, e.g. monitoring of home network or synchronising decoder's clock; Client middleware
- H04N21/431—Generation of visual interfaces for content selection or interaction; Content or additional data rendering
- H04N21/4318—Generation of visual interfaces for content selection or interaction; Content or additional data rendering by altering the content in the rendering process, e.g. blanking, blurring or masking an image region
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/47—End-user applications
- H04N21/478—Supplemental services, e.g. displaying phone caller identification, shopping application
- H04N21/4781—Games
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/60—Network structure or processes for video distribution between server and client or between remote clients; Control signalling between clients, server and network components; Transmission of management data between server and client, e.g. sending from server to client commands for recording incoming content stream; Communication details between server and client
- H04N21/61—Network physical structure; Signal processing
- H04N21/6106—Network physical structure; Signal processing specially adapted to the downstream path of the transmission network
- H04N21/6125—Network physical structure; Signal processing specially adapted to the downstream path of the transmission network involving transmission via Internet
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/60—Network structure or processes for video distribution between server and client or between remote clients; Control signalling between clients, server and network components; Transmission of management data between server and client, e.g. sending from server to client commands for recording incoming content stream; Communication details between server and client
- H04N21/65—Transmission of management data between client and server
- H04N21/654—Transmission by server directed to the client
- H04N21/6547—Transmission by server directed to the client comprising parameters, e.g. for client setup
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/80—Generation or processing of content or additional data by content creator independently of the distribution process; Content per se
- H04N21/81—Monomedia components thereof
- H04N21/8166—Monomedia components thereof involving executable data, e.g. software
- H04N21/8173—End-user applications, e.g. Web browser, game
Abstract
複合ユーザインターフェース(UI)の異なるコンポーネントをレンダリングするための方法およびシステムが、本明細書で説明される。処理デバイスは、1つまたは複数のビデオコンテンツコンポーネントおよび1つまたは複数のUIコントロールコンポーネントを含む複合UIを介して提示されるべきメディアアイテムを求めるユーザ要求を受信する。処理デバイスは、ビデオコンテンツコンポーネントのレンダリングを生成し、ビデオコンテンツコンポーネントのレンダリングを含む第1のストリームをエンドポイントデバイスへ送信し、第1のストリームは第1の解像度に符号化され、ビデオコンテンツコンポーネントのレンダリングは、エンドポイントデバイスにおいてUIコントロールコンポーネントのレンダリングとマージされて複合UIになることになり、複合UIは第2の解像度を有する。Methods and systems for rendering different components of a composite user interface (UI) are described herein. The processing device receives a user request for a media item to be presented via a composite UI that contains one or more video content components and one or more UI control components. The processing device produces a rendering of the video content component and sends a first stream containing the rendering of the video content component to the endpoint device, the first stream being encoded at the first resolution and of the video content component. The rendering will be merged with the rendering of the UI control component on the endpoint device into a composite UI, which has a second resolution.
Description
本開示の態様は、一般に、ユーザインターフェースレンダリングに関し、より詳細には、複合ユーザインターフェース(combined user interface)の異なるコンポーネントを別個にレンダリングすることに関する。 Aspects of the present disclosure generally relate to user interface rendering, and more particularly to rendering different components of a combined user interface separately.
ストリーミングされるコンテンツが、ユーザインターフェース(UI)を介してユーザデバイス上で提示され得る。UIは、ビデオコンテンツコンポーネントおよびUIコントロールコンポーネントを含んでよい。たとえば、オンラインゲーム用のUIは、ゲームのライブコンテンツを提示するゲームプレーコンポーネント、およびゲームについての情報を提示し、かつゲームの視聴者および/または参加者がゲームと対話することを可能にする制御を行う、ゲームコントロールコンポーネントを含んでよい。 Content to be streamed can be presented on the user device via a user interface (UI). The UI may include video content components and UI control components. For example, a UI for an online game is a gameplay component that presents live content for the game, and controls that present information about the game and allow viewers and / or participants of the game to interact with the game. May include a game control component that does.
一般に、ストリーミングされるコンテンツUIのビデオコンテンツコンポーネントおよびUIコントロールコンポーネントが、サーバにおいて一緒にレンダリングされて1つのビデオストリームを作成し、1つのビデオストリームは、次いで、1つの解像度で符号化されユーザデバイスへ送信される。符号化のために使用される解像度は、通常、ユーザデバイスによってサポートされる最大解像度(たとえば、4096×4096)である。 In general, the video content component and UI control component of the streamed content UI are rendered together on the server to create a video stream, which is then encoded at one resolution to the user device. Will be sent. The resolution used for encoding is typically the maximum resolution supported by the user device (eg, 4096 x 4096).
本開示のいくつかの態様の基本的理解を与えるために、以下の発明の概要は本開示の簡略化された概要である。本概要は、本開示の広範な概要ではない。本開示の重要または主要な要素を識別することも、本開示の特定の実施形態のいかなる範囲または請求項のいかなる範囲を定めることも、意図されない。その唯一の目的は、後で提示されるもっと詳細な説明への前置きとして、簡略化された形態で本開示のいくつかの概念を提示することである。 In order to give a basic understanding of some aspects of the present disclosure, the following outline of the invention is a simplified summary of the present disclosure. This overview is not an extensive overview of this disclosure. It is not intended to identify any material or key element of this disclosure or to define any scope of any particular embodiment or claim of this disclosure. Its sole purpose is to present some of the concepts of the present disclosure in simplified form as a prelude to the more detailed description presented later.
本開示のいくつかの態様によれば、1つまたは複数のビデオコンテンツコンポーネントおよび1つまたは複数のユーザインターフェース(UI)コントロールコンポーネントを含む複合UIを介して提示されるべきメディアアイテムを求めるユーザ要求を、サーバにおいて受信するステップと、ビデオコンテンツコンポーネントのレンダリングを生成するステップと、ビデオコンテンツコンポーネントのレンダリングを含む第1のストリームをエンドポイントデバイスへ送信するステップとを含み、第1のストリームは第1の解像度に符号化され、ビデオコンテンツコンポーネントのレンダリングは、エンドポイントデバイスにおいてUIコントロールコンポーネントのレンダリングとマージされて複合UIになることになり、複合UIは第2の解像度を有する、方法が提供される。 According to some aspects of the disclosure, a user request for a media item to be presented via a composite UI that includes one or more video content components and one or more user interface (UI) control components. The first stream is the first stream, which includes a step of receiving at the server, a step of generating a rendering of the video content component, and a step of sending a first stream containing the rendering of the video content component to the endpoint device. Encoded to resolution, the rendering of the video content component will be merged with the rendering of the UI control component on the endpoint device into a composite UI, providing a way for the composite UI to have a second resolution.
本開示の他の態様によれば、1つまたは複数のビデオコンテンツコンポーネントおよび1つまたは複数のユーザインターフェース(UI)コントロールコンポーネントを含む複合UIを介して提示されるべきメディアアイテムを求めるユーザ要求を、サーバにおいて受信するステップと、ビデオコンテンツコンポーネントのレンダリングを生成するステップと、ビデオコンテンツコンポーネントのレンダリングを含む第1のストリームをエンドポイントデバイスへ送信するステップであって、第1のストリームが第1の解像度に符号化される、ステップと、UIコントロールコンポーネントのレンダリングをサーバにおいて生成すべきかそれともエンドポイントデバイスにおいて生成すべきかを決定するステップと、UIコントロールコンポーネントのレンダリングをエンドポイントデバイスにおいて生成すべきという決定に応答して、UIコントロールコンポーネントをレンダリングするためのコマンドのセットを、ネットワークを介してエンドポイントデバイスへ送信するステップであって、UIコントロールコンポーネントのレンダリングが第1の解像度または第2の解像度を有する、ステップと、UIコントロールコンポーネントのレンダリングをサーバにおいて生成すべきという決定に応答して、UIコントロールコンポーネントのレンダリングを生成するために、UIコントロールコンポーネントをレンダリングするためのコマンドのセットをサーバにおいて実行し、UIコントロールコンポーネントのレンダリングを含む第2のストリームをエンドポイントデバイスへ送信するステップとを含む、方法が提供される。 According to another aspect of the disclosure, a user request for a media item to be presented via a composite UI that includes one or more video content components and one or more user interface (UI) control components. A step to receive at the server, a step to generate a rendering of the video content component, and a step to send a first stream containing the rendering of the video content component to the endpoint device, where the first stream has the first resolution. Encoded in, the steps that determine whether the UI control component rendering should be generated on the server or the endpoint device, and the decision that the UI control component rendering should be generated on the endpoint device. In response, the step of sending a set of commands to render the UI control component over the network to the endpoint device, where the UI control component rendering has a first or second resolution. In response to the steps and the decision that the rendering of the UI control component should be generated on the server, to generate the rendering of the UI control component, run a set of commands on the server to render the UI control component and the UI. A method is provided that includes a step of sending a second stream, including the rendering of the control component, to the endpoint device.
任意選択で、方法は、UIコントロールコンポーネントのレンダリングを生成するためのコマンドのセットをサーバにおいて実行するステップと、UIコントロールコンポーネントのレンダリングを含む第2のストリームをエンドポイントデバイスへ送信するステップとを含んでよく、第2のストリームは第2の解像度に符号化される。方法は、エンドポイントデバイスにおいて第2の解像度でUIコントロールコンポーネントのレンダリングを生成するために、UIコントロールコンポーネントをレンダリングするためのコマンドのセットをエンドポイントデバイスへ送信するステップを含んでよい。方法は、UIコントロールコンポーネントのレンダリングをサーバにおいて生成すべきかそれともエンドポイントデバイスにおいて生成すべきかを決定するステップと、UIコントロールコンポーネントのレンダリングをエンドポイントデバイスにおいて生成すべきという決定に応答して、UIコントロールコンポーネントをレンダリングするためのコマンドのセットを、ネットワークを介してエンドポイントデバイスへ送信するステップであって、UIコントロールコンポーネントのレンダリングが第2の解像度を有する、ステップと、UIコントロールコンポーネントのレンダリングをサーバにおいて生成すべきという決定に応答して、UIコントロールコンポーネントのレンダリングを生成するために、UIコントロールコンポーネントをレンダリングするためのコマンドのセットをサーバにおいて実行し、UIコントロールコンポーネントのレンダリングを含む第2のストリームをエンドポイントデバイスへ送信するステップとを含んでよい。第2の解像度は第1の解像度よりも高くてよく、ビデオコンテンツコンポーネントのレンダリングは、エンドポイントデバイスにおいてUIコントロールコンポーネントの第2の解像度に整合するように修正されてよい。コマンドのセットをサーバにおいて実行すべきかそれともエンドポイントデバイスにおいて実行すべきかという決定は、エンドポイントデバイスのハードウェア能力、エンドポイントデバイスの解像度、複合UIの目標解像度、サーバのレンダリング能力、またはネットワーク上で利用可能な帯域幅のうちの少なくとも1つに基づいてよい。複合UIは、ビデオコンテンツコンポーネントを介してオンラインゲームを提示してよく、UIコントロールコンポーネントを介してゲームについての情報を提示するとともにゲームに関するユーザ入力を受信してよい。 Optionally, the method involves running a set of commands on the server to generate a rendering of the UI control component and sending a second stream containing the rendering of the UI control component to the endpoint device. The second stream is encoded at the second resolution. The method may include sending a set of commands for rendering the UI control component to the endpoint device in order to generate a rendering of the UI control component at a second resolution on the endpoint device. The method responds to the step of deciding whether the UI control component rendering should be generated on the server or on the endpoint device, and in response to the decision that the UI control component rendering should be generated on the endpoint device. The step of sending a set of commands to render the component to the endpoint device over the network, where the rendering of the UI control component has a second resolution, and the rendering of the UI control component at the server. In response to the decision to generate, to generate a rendering of the UI control component, run a set of commands on the server to render the UI control component and a second stream containing the rendering of the UI control component. It may include a step of sending to the endpoint device. The second resolution may be higher than the first resolution and the rendering of the video content component may be modified to match the second resolution of the UI control component on the endpoint device. The decision whether to run a set of commands on a server or an endpoint device can be made on the hardware capabilities of the endpoint device, the resolution of the endpoint device, the target resolution of the composite UI, the rendering capabilities of the server, or on the network. It may be based on at least one of the available bandwidth. The composite UI may present an online game via a video content component, present information about the game through a UI control component, and receive user input about the game.
本開示のいくつかの態様によれば、メモリおよびメモリに結合された処理デバイスを含むシステムが提供される。処理デバイスは、1つまたは複数のビデオコンテンツコンポーネントおよび1つまたは複数のUIコントロールコンポーネントを含む複合UIを介して提示されるべきメディアアイテムを求めるユーザ要求を受信することと、ビデオコンテンツコンポーネントのレンダリングを生成することと、ビデオコンテンツコンポーネントのレンダリングを含む第1のストリームをエンドポイントデバイスへ送信することとを行うように構成され、第1のストリームは第1の解像度に符号化され、ビデオコンテンツコンポーネントのレンダリングは、エンドポイントデバイスにおいてUIコントロールコンポーネントのレンダリングとマージされて複合UIになることになり、複合UIは第2の解像度を有する。 According to some aspects of the present disclosure, a system comprising a memory and a processing device coupled to the memory is provided. The processing device receives a user request for a media item to be presented via a composite UI that contains one or more video content components and one or more UI control components, and renders the video content component. It is configured to generate and send a first stream containing the rendering of the video content component to the endpoint device, the first stream being encoded at the first resolution and of the video content component. The rendering will be merged with the rendering of the UI control component on the endpoint device into a composite UI, which has a second resolution.
本開示の他の態様によれば、メモリおよびメモリに結合された処理デバイスを含むシステムが提供される。処理デバイスは、1つまたは複数のビデオコンテンツコンポーネントおよび1つまたは複数のユーザインターフェース(UI)コントロールコンポーネントを含む複合UIを介して提示されるべきメディアアイテムを求めるユーザ要求を受信することと、ビデオコンテンツコンポーネントのレンダリングを生成することと、ビデオコンテンツコンポーネントのレンダリングを含む第1のストリームをエンドポイントデバイスへ送信することであって、第1のストリームが第1の解像度に符号化される、ことと、UIコントロールコンポーネントのレンダリングをサーバにおいて生成すべきかそれともエンドポイントデバイスにおいて生成すべきかを決定することと、UIコントロールコンポーネントのレンダリングをエンドポイントデバイスにおいて生成すべきという決定に応答して、UIコントロールコンポーネントをレンダリングするためのコマンドのセットを、ネットワークを介してエンドポイントデバイスへ送信することであって、UIコントロールコンポーネントのレンダリングが第1の解像度または第2の解像度を有する、ことと、UIコントロールコンポーネントのレンダリングをサーバにおいて生成すべきという決定に応答して、UIコントロールコンポーネントのレンダリングを生成するために、UIコントロールコンポーネントをレンダリングするためのコマンドのセットをサーバにおいて実行し、UIコントロールコンポーネントのレンダリングを含む第2のストリームをエンドポイントデバイスへ送信することとを行うように構成される。 According to another aspect of the present disclosure, a system comprising a memory and a processing device coupled to the memory is provided. The processing device receives a user request for a media item to be presented via a composite UI that includes one or more video content components and one or more user interface (UI) control components, and video content. Generating a rendering of the component and sending a first stream containing the rendering of the video content component to the endpoint device, where the first stream is encoded to the first resolution. Rendering the UI control component in response to the decision to generate the UI control component rendering on the server or the endpoint device and the UI control component rendering on the endpoint device. Sending a set of commands over the network to the endpoint device, that the rendering of the UI control component has a first or second resolution, and that the rendering of the UI control component In response to the decision to generate on the server, to generate a rendering of the UI control component, run a set of commands on the server to render the UI control component, including rendering the UI control component. It is configured to send a stream to an endpoint device.
本開示のいくつかの態様によれば、処理デバイスによって実行されたとき、上記で説明した方法を処理デバイスに実行させる命令を含むコンピュータ可読媒体が提供される。 According to some aspects of the present disclosure, there is provided a computer-readable medium containing instructions that, when performed by the processing device, cause the processing device to perform the methods described above.
本開示の任意の態様に従って上記で、または任意の特定の実施形態に関して以下に規定される、個々の特徴および/または特徴の組合せは、任意の他の態様または実施形態において、別個にまたは個々にのいずれかで、単独でまたは規定された任意の他の特徴と組み合わせて、利用されてよい。さらに、本開示は、方法に関して本明細書で説明する任意の機能を実行するように構成された装置、および/あるいは本明細書で説明する任意の装置機能を使用または制作し使用または製造する方法を、包含するものとする。 The individual features and / or combinations of features set forth above in accordance with any aspect of the present disclosure or with respect to any particular embodiment are separately or individually in any other aspect or embodiment. It may be utilized alone or in combination with any other specified feature. Further, the present disclosure is a method of using, producing, using or manufacturing an apparatus configured to perform any of the functions described herein with respect to a method and / or any of the equipment functions described herein. Shall be included.
本開示は添付図面の図の中で限定としてではなく例として図示され、同様の参照は類似の要素を示す。本開示における「ある(an)」または「1つの(one)」実施形態への異なる参照が、必ずしも同じ実施形態を有するとは限らず、そのような参照が少なくとも1つを意味することに留意されたい。 The present disclosure is illustrated as an example, not by limitation, in the figures of the accompanying drawings, similar references indicate similar elements. Note that different references to "an" or "one" embodiments in the present disclosure do not necessarily have the same embodiment, and such references mean at least one. I want to be.
以下の開示は、本開示のいくつかの実施形態の良好な理解を与えるために、特定のシステム、構成要素、方法などの例などの数多くの具体的な詳細を記載する。しかしながら、本開示の少なくともいくつかの実施形態がこれらの具体的な詳細なしに実践され得ることが、当業者にとって明らかとなろう。他の事例では、よく知られている構成要素または方法は、詳細には説明されず、または本開示を不必要に不明瞭にすることを避けるために、簡単なブロック図フォーマットで提示される。したがって、記載される具体的な詳細は例にすぎない。特定の実装形態は、これらの例示的な詳細から変わることがあり、やはり本開示の範囲内であることが企図されることがある。 The following disclosures describe a number of specific details, such as examples of specific systems, components, methods, etc., to give a good understanding of some embodiments of the present disclosure. However, it will be apparent to those skilled in the art that at least some embodiments of the present disclosure can be practiced without these specific details. In other cases, well-known components or methods are not described in detail or are presented in a simple block diagram format to avoid unnecessarily obscuring the present disclosure. Therefore, the specific details given are merely examples. Certain implementations may vary from these exemplary details and may also be contemplated as being within the scope of the present disclosure.
本開示の実装形態によって対処される技術的問題とは、コンテンツをエンドポイントデバイスへストリーミングすることが、大量のネットワーク帯域幅を必要とし得ることである。たとえば、コンテンツが、4K解像度を有するエンドポイントデバイスへのストリーミングである場合、ユーザのためのコンテンツのくっきりした表示を保証するのに十分に高い解像度でコンテンツストリームを送信するために、大量のネットワーク帯域幅が使用され得る。コンテンツがもっと低い解像度でエンドポイントデバイスへ送信される場合、ストリーミングされるコンテンツの部分はくっきりしていない場合があり、ユーザは視聴する体験を十分に享受しない場合がある。したがって、解像度とネットワーク上での需要(たとえば、必要とされる帯域幅)との間の歩み寄りを達成することが必要とされ得る。 A technical problem addressed by the implementations of the present disclosure is that streaming content to endpoint devices can require large amounts of network bandwidth. For example, if the content is streamed to an endpoint device with 4K resolution, then a large amount of network bandwidth to send the content stream at a resolution high enough to ensure a crisp display of the content for the user. Width can be used. If the content is sent to the endpoint device at a lower resolution, the portion of the content that is streamed may not be crisp and the user may not fully enjoy the viewing experience. Therefore, it may be necessary to achieve a compromise between resolution and demand on the network (eg, required bandwidth).
ストリーミングされるコンテンツは、複数のコンポーネント(異なるタイプのUIコンポーネント)を含み得るUIを介して提示されてよい。複数のコンポーネントは、それらのコンポーネントのユーザの知覚が異なることがあるので、ユーザのためのコンテンツ全体のくっきりした表示を保証するために同じ解像度でストリーミングされる必要がなくてよい。たとえば、ユーザは、エンドポイントデバイスへストリーミングされるオンラインゲームを見物しかつ/またはそれに参加することを希望する場合がある。オンラインゲームは、ビデオコンテンツコンポーネントおよびUIコントロールコンポーネントを含んでよい。ユーザは、ビデオコンテンツコンポーネントなどのいくつかのコンポーネントが、より低い解像度でストリーミングされることに気づかない場合があるが、その人は、UIコントロールコンポーネントなどの他のコンポーネントが、より低い解像度でストリーミングされることに気づくことができることになる。しかしながら、従来はビデオコンテンツコンポーネントおよびUIコントロールコンポーネントが、一緒にレンダリングされて1つのビデオストリームを作成し、1つのビデオストリームは、次いで、1つの表示解像度で符号化されエンドポイントデバイスへ送信される。この限定は、コンテンツのくっきりした表示をユーザが享受するのに必要とされるよりも高い解像度でビデオコンテンツコンポーネントが符号化される結果となる。したがって、大量のネットワーク帯域幅が浪費され、解像度がより高いコンテンツを処理するために使用される計算リソースおよび電力も同様である。この問題への1つの代替策は、もっと低い解像度にコンテンツストリームを符号化して、ネットワーク帯域幅、計算リソース、および電力コストを節約することである。しかしながら、ユーザは低解像度のUIコントロールコンポーネントに気づくことができるので、ユーザはゲームを行う体験を十分に享受しない場合がある。 Content to be streamed may be presented via a UI that may contain multiple components (different types of UI components). Multiple components may differ in the user's perception of those components, so they do not have to be streamed at the same resolution to ensure a crisp display of the entire content for the user. For example, a user may wish to see and / or participate in an online game streamed to an endpoint device. Online games may include video content components and UI control components. The user may not be aware that some components, such as the video content component, are streamed at a lower resolution, but that person may not be aware that other components, such as the UI control component, are streamed at a lower resolution. You will be able to notice that. However, traditionally, the video content component and the UI control component are rendered together to create a video stream, which is then encoded at one display resolution and sent to the endpoint device. This limitation results in the video content component being encoded at a higher resolution than is required for the user to enjoy a crisp display of the content. Therefore, a large amount of network bandwidth is wasted, as is the computational resources and power used to process higher resolution content. One alternative to this problem is to encode the content stream to a lower resolution, saving network bandwidth, computational resources, and power costs. However, the user may not fully enjoy the experience of playing the game because the user may be aware of the low resolution UI control components.
追加として、UIコントロールコンポーネントは、ビデオコンテンツコンポーネントよりも低い頻度で更新および/または変更されてよい。しかしながら、ビデオコンテンツコンポーネントおよびUIコントロールコンポーネントは、従来、一緒にレンダリングされるので、UIコントロールコンポーネントは、複合UIビデオストリームの作成において不必要に再レンダリングされることがある。このことも、大量のネットワーク帯域幅および/または計算リソースが浪費される結果となる。 In addition, the UI control component may be updated and / or modified less frequently than the video content component. However, since the video content component and the UI control component are traditionally rendered together, the UI control component may be unnecessarily re-rendered in the creation of a composite UI video stream. This also results in a large amount of network bandwidth and / or computational resources being wasted.
したがって、UIコントロールコンポーネントとは別個にビデオコンテンツコンポーネントをストリーミングし、ビデオコンテンツコンポーネントおよびUIコントロールコンポーネントをどこでおよび/またはどのようにレンダリングすべきかを決定するために、本開示の実装形態が提供される。サーバは、エンドポイントデバイスのハードウェア能力、エンドポイントデバイスの最大解像度、複合UIの目標解像度、サーバのレンダリング能力、およびネットワーク上で利用可能な帯域幅のうちの少なくとも1つに基づいて、この決定を行ってよい。これらの要因に基づいて、サーバは、ビデオコンテンツコンポーネントおよびUIコントロールコンポーネントを、(1)サーバにおいて一緒にレンダリングすべきか、(2)UIコントロールコンポーネントがより高い表示解像度に符号化されて、サーバにおいて別個にレンダリングすべきか、それとも(3)ビデオコンテンツコンポーネントがサーバにおいてレンダリングされ、かつUIコントロールコンポーネントがエンドポイントデバイスにおいてレンダリングされて、別個にレンダリングすべきかを、決定し得る。 Accordingly, implementations of the present disclosure are provided to stream the video content component separately from the UI control component and to determine where and / or how the video content component and the UI control component should be rendered. The server makes this decision based on at least one of the hardware capabilities of the endpoint device, the maximum resolution of the endpoint device, the target resolution of the composite UI, the rendering capabilities of the server, and the bandwidth available on the network. May be done. Based on these factors, the server should either (1) render the video content component and the UI control component together on the server, or (2) the UI control component is encoded to a higher display resolution and is separate on the server. It can be decided whether it should be rendered to (3) the video content component is rendered on the server and the UI control component is rendered on the endpoint device and rendered separately.
したがって、技術的効果は、ビデオコンテンツコンポーネントおよびUIコントロールコンポーネントを別個にストリーミングすることと、ユーザがコンテンツストリーミング体験を十分に享受することを可能にするように適切な解像度を使用することとを含んでよい。たとえば、オンラインゲームをストリーミングするようにユーザが要求する場合、UIコントロールコンポーネントは、より高い解像度を使用してストリーミングされてよく、UIコントロールコンポーネントのくっきりした表示をユーザに与えるが、ビデオコンテンツコンポーネントは、ユーザが気づくことにならないか、または少なくとも気づく可能性が低い、より低い解像度を使用してストリーミングされてよい。異なるコンポーネントを適切な解像度でストリーミングすることによって、コンテンツをユーザへストリーミングする際に、より少ないネットワーク帯域幅しか必要とされず、レンダリングされるコンテンツを処理する際に、より少ない計算リソースおよび電力しか必要とされない。したがって、解像度とネットワーク上の需要との間の歩み寄りが緩和され得る。 Therefore, the technical benefits include streaming the video content component and UI control component separately and using the appropriate resolution to allow the user to fully enjoy the content streaming experience. good. For example, if a user requests to stream an online game, the UI control component may be streamed using a higher resolution, giving the user a crisp view of the UI control component, while the video content component It may be streamed using a lower resolution that the user will not notice, or at least is unlikely to notice. By streaming different components at the appropriate resolution, less network bandwidth is required to stream the content to the user, and less computational resources and power are required to process the rendered content. Is not considered. Therefore, the compromise between resolution and demand on the network can be mitigated.
エンドポイントデバイスにおいてUI制御コマンドをレンダリングするためのコマンドのストリームを送信することは、UI制御コマンドのレンダリングを送信するよりも少ない帯域幅しか必要としないので、UIコントロールコンポーネントがエンドポイントデバイス上でレンダリングされる場合、帯域幅使用量がさらに低減される。加えて、UIコントロールコンポーネントへの変更が、通常は現在の技術によって必要とされることになるように往復してサーバへ送信される必要がないので、やはり帯域幅使用量が低減される。エンドポイントデバイスがレンダリングコマンドのセットを含む場合、エンドポイントデバイスは、デバイス上でユーザのためのUIコントロールコンポーネントをどのくらい頻繁に変更すべきかについて決定を行うことができる。 Sending a stream of commands to render a UI control command on an endpoint device requires less bandwidth than sending a render of a UI control command, so the UI control component renders on the endpoint device. If so, bandwidth usage is further reduced. In addition, bandwidth usage is also reduced because changes to UI control components do not have to be sent back and forth to the server as would normally be required by current technology. If the endpoint device contains a set of rendering commands, the endpoint device can make decisions about how often the UI control component for the user should change on the device.
図1は、本開示の実装形態による、異なるコンポーネントを有する複合ユーザインターフェースを提供するためのシステムアーキテクチャ100の一例を示す。システムアーキテクチャ100は、エンドポイントデバイス110A～110Z、1つまたは複数のネットワーク105、1つまたは複数のサーバ106、1つまたは複数の電子デバイス170、および1つまたは複数のプラットフォーム(たとえば、コンテンツ共有プラットフォーム120、推奨プラットフォーム157、広告プラットフォーム165、モバイルプラットフォーム150、ソーシャルネットワークプラットフォーム160、検索プラットフォーム145、コンテンツプロバイダプラットフォーム195、および協調プラットフォーム155)を含む。プラットフォームは、(ラックマウントサーバ、ルータコンピュータ、サーバコンピュータ、パーソナルコンピュータ、メインフレームコンピュータ、ラップトップコンピュータ、タブレットコンピュータ、デスクトップコンピュータなどの)1つまたは複数のコンピューティングデバイス、および1つまたは複数のデータストア(たとえば、ハードディスク、メモリ、およびデータベース)を含むことができ、1つまたは複数のネットワーク105に結合されてよい。
FIG. 1 shows an example of a
1つまたは複数のネットワーク105は、1つまたは複数のパブリックネットワーク(たとえば、インターネット)、1つまたは複数のプライベートネットワーク(たとえば、ローカルエリアネットワーク(LAN)または1つもしくは複数のワイドエリアネットワーク(WAN))、1つまたは複数の有線ネットワーク(たとえば、Ethernetネットワーク)、1つまたは複数のワイヤレスネットワーク(たとえば、802.11ネットワークまたはWi-Fiネットワーク)、1つまたは複数のセルラーネットワーク(たとえば、ロングタームエボリューション(LTE)ネットワーク)、ルータ、ハブ、スイッチ、サーバコンピュータ、および/あるいはそれらの組合せを含むことができる。一実装形態では、アーキテクチャ100のいくつかのコンポーネントは互いに直接接続されていない。一実装形態では、アーキテクチャ100は別個のネットワーク105を含む。
One or more networks 105 may be one or more public networks (eg, the Internet), one or more private networks (for example, local area networks (LAN) or one or more wide area networks (WAN)). ), One or more wired networks (for example, Ethernet networks), one or more wireless networks (for example, 802.11 or Wi-Fi networks), one or more cellular networks (for example, Long Term Evolution (LTE)). ) Networks), routers, hubs, switches, server computers, and / or combinations thereof. In one implementation, some components of
1つまたは複数のデータストア(図示せず)は、メモリ(たとえば、ランダムアクセスメモリ)、キャッシュ、ドライブ(たとえば、ハードドライブ)、フラッシュドライブなどの中に存在することができ、1つまたは複数のデータベースシステム、1つまたは複数のファイルシステム、あるいはデータを記憶することが可能な別のタイプの構成要素またはデバイスの一部であり得る。1つまたは複数のデータストアは、やはり複数のコンピューティングデバイス(たとえば、複数のサーバコンピュータ)に広がることもある複数の記憶構成要素(たとえば、複数のドライブまたは複数のデータベース)を含むことができる。データストアは、データを記憶することが可能な永続記憶装置であり得る。永続記憶装置は、ローカル記憶ユニットもしくはリモート記憶ユニット、電子記憶ユニット(メインメモリ)、または類似の記憶ユニットであり得る。永続記憶装置は、モノリシックデバイス、またはデバイスの分散されたセットであり得る。本明細書で使用する「セット」は、任意の正の整数個の項目を指す。 One or more data stores (not shown) can reside in memory (eg, random access memory), caches, drives (eg, hard drives), flash drives, etc., and one or more. It can be part of a database system, one or more file systems, or another type of component or device capable of storing data. One or more data stores can contain multiple storage components (eg, multiple drives or multiple databases) that may also spread to multiple computing devices (eg, multiple server computers). A data store can be a permanent storage device capable of storing data. Persistent storage can be local or remote storage, electronic storage (main memory), or similar storage units. Persistent storage can be a monolithic device, or a distributed set of devices. As used herein, "set" refers to any positive integer number of items.
コンテンツアイテム121(たとえば、メディアコンテンツアイテム)は、1つまたは複数のデータストア上に記憶され得る。データストアは、1つまたは複数のプラットフォームの一部であり得る。コンテンツアイテム121の例は、それらに限定されないが、デジタルビデオ、デジタルムービー、アニメーション画像、デジタル写真、デジタル音楽、デジタルオーディオ、デジタルビデオゲーム、協調メディアコンテンツ提示、ウェブサイトコンテンツ、ソーシャルメディア更新、電子ブック(eブック)、電子雑誌、デジタル新聞、デジタルオーディオブック、電子ジャーナル、ウェブブログ、リアルシンプルシンジケーション(RSS:real simple syndication)フィード、電子漫画雑誌、ソフトウェアアプリケーションなどを含むことができる。コンテンツアイテム121はメディアアイテムとも呼ばれる。コンテンツアイテム121は、事前記録されてよく、またはライブストリーミングであってもよい。簡潔および簡略のために、本明細書全体にわたってコンテンツアイテム121の一例としてオンラインビデオゲーム(以下でゲームとも呼ばれる)が使用され得る。 Content item 121 (eg, media content item) can be stored on one or more data stores. The data store can be part of one or more platforms. Examples of content item 121 are, but are not limited to, digital videos, digital movies, animated images, digital photos, digital music, digital audio, digital video games, collaborative media content presentations, website content, social media updates, ebooks. It can include (ebooks), e-magazines, digital newspapers, digital audio books, e-journals, web blogs, real simple syndication (RSS) feeds, e-manga magazines, software applications, and more. Content item 121 is also called a media item. Content item 121 may be pre-recorded or livestreamed. For brevity and brevity, online video games (also referred to herein as games) may be used as an example of Content Item 121 throughout the specification.
コンテンツアイテム121は、コンテンツプロバイダによって提供され得る。コンテンツプロバイダは、ユーザ、会社、団体などであり得る。コンテンツプロバイダは、ビデオゲームであるコンテンツアイテム121を提供することができる。たとえば、コンテンツアイテム121は、ゲーム発行者によって提供されるビデオゲームであってよい。別の例では、コンテンツアイテム121は、メディアコンテンツプロバイダによって提供される協調メディアコンテンツ提示であってよい。 Content item 121 may be provided by the content provider. Content providers can be users, companies, organizations, and so on. The content provider can provide content item 121, which is a video game. For example, content item 121 may be a video game provided by the game publisher. In another example, the content item 121 may be a collaborative media content presentation provided by a media content provider.
エンドポイントデバイス110A～110Zは、テレビ、スマートフォン、セルラー電話、携帯情報端末(PDA)、ポータブルメディアプレーヤ、ネットブック、ラップトップコンピュータ、電子ブックリーダー、タブレットコンピュータ、デスクトップコンピュータ、セットトップボックス、ゲーム機などの、デバイスを含むことができる。 Endpoint devices 110A-110Z include TVs, smartphones, cellular phones, personal digital assistants (PDAs), portable media players, netbooks, laptop computers, e-book readers, tablet computers, desktop computers, set-top boxes, game consoles, etc. Can include devices.
個々のエンドポイントデバイス110A～110Zは、通信アプリケーション115を含むことができる。コンテンツアイテム121は、通信アプリケーション115、インターネットなどを介して、消費され得る。本明細書で使用する「メディア」、「メディアアイテム」、「オンラインメディアアイテム」、「デジタルメディア」、「デジタルメディアアイテム」、「コンテンツ」、「メディアコンテンツアイテム」、および「コンテンツアイテム」は、コンテンツアイテムを提示するように構成されたソフトウェア、ファームウェア、またはハードウェアを使用して実行またはロードされ得る、電子ファイルを含むことができる。一実装形態では、通信アプリケーション115は、ユーザが、プラットフォーム(たとえば、コンテンツ共有プラットフォーム120、推奨プラットフォーム157、広告プラットフォーム165、モバイルプラットフォーム150、ソーシャルネットワークプラットフォーム160、検索プラットフォーム145、協調プラットフォーム155、およびコンテンツプロバイダプラットフォーム195)、ならびに/またはプラットフォームおよび/もしくはネットワークの組合せを介して、コンテンツアイテム121(たとえば、ゲーム)を作成すること、送ること、および受け取ることを可能にするアプリケーションであってよい。
The individual endpoint devices 110A-110Z can include the
たとえば、通信アプリケーション115は、コンテンツプロバイダの、ソーシャルネットワーキングアプリケーション、ビデオ共有アプリケーション、ビデオストリーミングアプリケーション、ビデオゲームストリーミングアプリケーション、ビデオオンデマンドアプリケーション、写真共有アプリケーション、チャットアプリケーション、モバイルアプリケーション、またはそのようなアプリケーションの任意の組合せであってよい。エンドポイントデバイス110A～110Zの中の通信アプリケーション115は、1つまたは複数のコンテンツアイテム121(たとえば、ゲーム)を1人または複数のユーザにレンダリングすること、表示すること、および/または提示することができる。たとえば、通信アプリケーション115は、ビデオコンテンツを受信および/または再生するために、エンドポイントデバイス110A～110Z上で表示されるべき1つまたは複数のユーザインターフェース(たとえば、グラフィカルユーザインターフェース)を提供することができる。
For example, the
一実装形態では、通信アプリケーション115は、検索コンポーネント114およびコンテンツビューア113を含んでよく、仮想キーボードを介してメディアコンテンツアイテムを求めて検索するために使用され得るとともに、ユーザインターフェース116のコンテンツビューア113部分の中でコンテンツアイテム121を再生し得る、ユーザインターフェース116を提供し得る。コンテンツビューア113は、コンテンツアイテム121(たとえば、ビデオゲーム)を1人または複数のユーザにレンダリング、表示、および/または提示し得る。一実装形態では、コンテンツビューア113は、アプリケーション(たとえば、通信アプリケーション115)の中に埋め込まれる。別の実装形態では、コンテンツビューア113は、ユーザが、ビデオ、画像、文書(たとえば、ウェブページ)などのコンテンツアイテム121を消費(たとえば、再生、表示)することを可能にする通信アプリケーション115などの、スタンドアロンアプリケーション(たとえば、モバイルアプリケーション、デスクトップアプリケーション、ゲーム機アプリケーション、テレビアプリケーションなど)であってよい。たとえば、コンテンツビューア113は、プラットフォームのウェブサーバによってサービスされるコンテンツ(たとえば、ハイパーテキストマークアップ言語(HTML)ページ、デジタルメディアアイテムなどの、ウェブページ)にアクセスすること、それらを取り出すこと、提示すること、および/またはナビゲートすることができる、ウェブブラウザであってよい。別の例では、コンテンツビューア113は、文書(たとえば、ユーザインターフェース116(ウェブページ))の中に埋め込まれている、埋込み型メディアプレーヤ(たとえば、Flash(登録商標)プレーヤまたはHTML5プレーヤ)を表示し得る。
In one implementation, the
コンテンツビューア113は、サーバおよび/またはプラットフォームによってエンドポイントデバイス110A～110Zに提供され得る。たとえば、コンテンツビューア113は、コンテンツ共有プラットフォーム120またはコンテンツプロバイダプラットフォーム195によって提供されるユーザインターフェース116(たとえば、文書(ウェブページ)、またはスタンドアロンアプリケーションのスクリーン)の中に埋め込まれている、埋込み型メディアプレーヤであってよい。別の例では、コンテンツビューア113は、プラットフォーム(たとえば、コンテンツ共有プラットフォーム120、推奨プラットフォーム157、広告プラットフォーム165、モバイルプラットフォーム150、ソーシャルネットワークプラットフォーム160、検索プラットフォーム145、協調プラットフォーム155、およびコンテンツプロバイダプラットフォーム195)からダウンロードされるアプリケーションであってよい。別の例では、コンテンツビューア113は、エンドポイントデバイス110A～110Z上に事前インストールされるスタンドアロンアプリケーションであってよい。
電子デバイス170は、方向キー入力をエンドポイントデバイス110A～110Zに通信することが可能な任意の好適な電子デバイスであってよい。たとえば、電子デバイス170は、リモートコントローラ、ゲームコントローラ、スマートフォン、タブレットなどを含んでよい。電子デバイス170は、上、下、左、右、および入力(選択)に対応するキーを含む、物理的または仮想的な方向パッド(「Dパッド」)175を含んでよい。電子デバイス170は、ユーザがキーのうちの1つもしくは複数または方向パッド175を押すと、キー入力選択を受信し得る。電子デバイス170は、検索コンポーネント114を動作させている1つまたは複数のプロセッサによる処理のために、キー入力をエンドポイントデバイス110A～110Zへ送信し得る。
The electronic device 170 may be any suitable electronic device capable of communicating directional key inputs to the endpoint devices 110A-110Z. For example, the electronic device 170 may include a remote controller, a game controller, a smartphone, a tablet, and the like. The electronic device 170 may include a physical or virtual directional pad (“D pad”) 175 that includes keys for up, down, left, right, and input (selection). The electronic device 170 may receive a key input selection when the user presses one or more of the keys or the directional pad 175. Electronic device 170 may send keystrokes to endpoint devices 110A-110Z for processing by one or more processors running
いくつかの実施形態では、エンドポイントデバイス110A～110Zは、1つまたは複数のデータストアを含むことができる。この例では、データストアは、複合UIをレンダリングするためのコマンドを含んでよい。コマンドは、ビデオコンテンツコンポーネントおよびUIコントロールコンポーネントをレンダリングするための命令を含むことができる。一実装形態では、コマンドはUIコントロールコンポーネントをレンダリングするための命令を含んでよく、ビデオコンテンツコンポーネントは(たとえば、サードパーティを通じて)他の場所でレンダリングされてよい。UIコントロールコンポーネントをレンダリングするためのコマンドは、コマンドがUIコントロールコンポーネントをレンダリングすることになるという明示的な表示を含んでよい。開発者および/または発行者は、コマンドを作成するとき、コマンドがUIコントロールコンポーネントをレンダリングすることになることを明示的に示してよい。 In some embodiments, the endpoint devices 110A-110Z can include one or more data stores. In this example, the data store may contain commands for rendering the composite UI. The command can include instructions for rendering the video content component and the UI control component. In one implementation, the command may include instructions for rendering the UI control component, and the video content component may be rendered elsewhere (eg, through a third party). The command for rendering the UI control component may include an explicit indication that the command will render the UI control component. Developers and / or publishers may explicitly indicate when creating a command that the command will render a UI control component.
1つまたは複数のサーバ106は、ラックマウントサーバ、ルータコンピュータ、サーバコンピュータ、パーソナルコンピュータ、メインフレームコンピュータ、ラップトップコンピュータ、タブレットコンピュータ、デスクトップコンピュータなどの、コンピューティングデバイスを含んでよく、1つまたは複数のネットワーク105に結合されてよい。1つまたは複数のサーバ106は、独立したデバイス、またはプラットフォーム(たとえば、コンテンツ共有プラットフォーム120、推奨プラットフォーム157、広告プラットフォーム165、モバイルプラットフォーム150、ソーシャルネットワークプラットフォーム160、検索プラットフォーム145、コンテンツプロバイダプラットフォーム195、および協調プラットフォーム155)のうちのいずれかの一部であってよい。サーバ106は、レンダリングコンポーネント122を含んでよい。レンダリングコンポーネント122は、エンドポイントデバイス110A～110Z上でのユーザへの提示のためにUIコントロールコンポーネントがどこでレンダリングされることになるのかを決定し得る。エンドポイントデバイス110A～110Z上でコンテンツアイテムにアクセスするユーザは、コンテンツアイテムにアクセスするための要求を送信してよい。要求は、エンドポイントデバイスの能力に関する情報を含んでよい。たとえば、要求は、1つもしくは複数のビデオストリームを表示するための、エンドポイントデバイスの能力に関する情報、および/またはユーザに提示されるコンテンツアイテムが符号化され得る先の最大解像度に関する情報を含んでよい。レンダリングコンポーネント122は、要求の中に含まれる情報を分析してよく、UIコントロールコンポーネントのレンダリングをサーバ106において生成すべきかそれともエンドポイントデバイス110A～110Zにおいて生成すべきかを決定し得る。レンダリングコンポーネント122が、UIコントロールコンポーネントをサーバ106においてレンダリングすべきと決定する場合、レンダリングコンポーネント122は、UIコントロールコンポーネントをビデオコンテンツコンポーネントのレンダリングとともにレンダリングすべきか、それともビデオコンテンツコンポーネントのレンダリングとは別個にレンダリングすべきかを、さらに決定し得る。
One or more servers 106 may include computing devices such as rack mount servers, router computers, server computers, personal computers, mainframe computers, laptop computers, tablet computers, desktop computers, etc., and one or more. May be coupled to network 105 of. One or more servers 106 may be independent devices or platforms (eg,
コンテンツプロバイダプラットフォーム195は、サービスプロバイダのサービスを提供することができる。たとえば、コンテンツプロバイダは、ユーザがコンテンツプロバイダプラットフォーム195を介してエンドポイントデバイス110A～110Z上でオンラインビデオゲームと対話するために、通信アプリケーションを介してオンラインビデオゲームを作り出す、ビデオゲームストリーミングサービスプロバイダであってよい。別の例では、コンテンツプロバイダは、ユーザがコンテンツプロバイダプラットフォーム195を介してエンドポイントデバイス110A～110Z上で、ビデオ、TVショー、ビデオクリップ、オーディオ、オーディオクリップ、およびムービーを再生するために、通信アプリケーション115を介してメディアストリーミングサービスを作り出す、ビデオストリーミングサービスプロバイダであってよい。 The content provider platform 195 can provide the services of the service provider. For example, a content provider is a video game streaming service provider that creates online video games via communication applications for users to interact with online video games on endpoint devices 110A-110Z via content provider platform 195. It's okay. In another example, the content provider is a communication application for users to play videos, TV shows, video clips, audio, audio clips, and movies on endpoint devices 110A-110Z via the content provider platform 195. It may be a video streaming service provider that creates media streaming services via 115.
ソーシャルネットワークプラットフォーム160は、オンラインソーシャルネットワーキングサービスを提供することができる。ソーシャルネットワーキングプラットフォーム160は、ユーザがプロファイルを作成するとともに彼らのプロファイルを用いてアクティビティを実行するために、通信アプリケーション115を提供することができる。アクティビティは、プロファイルを更新すること、他のユーザとメッセージを交換すること、ステータス更新、写真、ビデオなどを評価(たとえば、いいね(like)、コメント、共有、推奨)すること、および他のユーザアクティビティの通知を受信することを含むことができる。
Social network platform 160 can provide online social networking services. The social networking platform 160 can provide a
モバイルプラットフォーム150は、ユーザが、1つまたは複数のモバイルデバイス(たとえば、電話、タブレットコンピュータ、ラップトップコンピュータ、ウェアラブルコンピューティングデバイスなど)および/または任意の他の好適なデバイスを使用して、情報に接続すること、情報を共有すること、および/または互いに対話することを可能にするために使用され得る。たとえば、モバイルプラットフォーム150は、電話通信、ショートメッセージサービス(SMS)メッセージング、マルチメディアメッセージサービス(MMS)メッセージング、テキストチャット、および/またはユーザ間での任意の他の通信を可能にし得る。モバイルプラットフォーム150は、ビデオメッセージング、ビデオチャット、および/またはビデオ会議を介したユーザ通信をサポートすることができる。
The
協調プラットフォーム155は、たとえば、ストリーミングビデオまたはボイスオーバーIP(VoIP)技術、セルラー技術、LANおよび/またはWAN技術を使用して、(たとえば、デバイス110A～110Zのユーザ間の)ビデオチャット、ビデオメッセージング、ならびにオーディオおよび/またはビデオ会議などの、協調サービスを可能にすることができ、個人の娯楽、ビジネス、教育、または学究的に指向された対話のために使用され得る。
推奨プラットフォーム157は、コンテンツ推奨(たとえば、記事、ビデオ、投稿、ニュース、ゲームなど)を生成および提供するために使用され得る。
検索プラットフォーム145は、ユーザが1つもしくは複数のデータストア106および/または1つもしくは複数のプラットフォームに照会するとともに照会結果を受け取ることを可能にするために使用され得る。 Search platform 145 may be used to allow a user to query and / or receive query results from one or more data stores 106 and / or one or more platforms.
広告プラットフォーム165は、ビデオ広告を提供するために使用され得る。
コンテンツ共有プラットフォーム120は、1人もしくは複数のユーザにコンテンツアイテム121へのアクセスを提供し、かつ/または1人もしくは複数のユーザにコンテンツアイテム121を提供するために使用され得る。たとえば、コンテンツ共有プラットフォーム120は、ユーザが、コンテンツアイテム121を消費、アップロード、ダウンロード、および/または検索することを可能にし得る。別の例では、コンテンツ共有プラットフォーム120は、ユーザが、コンテンツアイテム121に対して、(「いいね」)に賛成する、(「ひどいね(dislike)」)に反対する、推奨する、共有する、格付けする、かつ/またはコメントするなどの、コンテンツアイテム121を評価することを可能にし得る。別の例では、コンテンツ共有プラットフォーム120は、ユーザがコンテンツアイテム121を編集することを可能にし得る。コンテンツ共有プラットフォームはまた、たとえば、エンドポイントデバイス110A～110Zを介した、コンテンツアイテム121へのアクセスを1人もしくは複数のユーザに提供するために使用され得る、ウェブサイト(たとえば、1つまたは複数のウェブページ)および/または1つもしくは複数のアプリケーション(たとえば、通信アプリケーション115)を含むことができる。コンテンツ共有プラットフォーム120は、コンテンツアイテム121へのアクセスを提供する任意のタイプのコンテンツ配信ネットワークを含むことができる。
The
コンテンツ共有プラットフォーム120は、複数のチャネル(たとえば、チャネルA125～チャネルZ129)を含むことができる。チャネルとは、共通のソースから利用可能なデータコンテンツ、または共通の話題もしくはテーマを有するデータコンテンツであり得る。データコンテンツは、ユーザによって選ばれたデジタルコンテンツ、ユーザによって利用可能にされたデジタルコンテンツ、ユーザによってアップロードされたデジタルコンテンツ、コンテンツプロバイダによって選ばれたデジタルコンテンツ、放送事業者によって選ばれたデジタルコンテンツなどであり得る。たとえば、チャネルA125はビデオYおよびZを含んでよい。チャネルは、チャネル上でアクションを実行できるユーザである所有者に関連付けられ得る。データコンテンツは、1つまたは複数のコンテンツアイテム121であり得る。チャネルの中のデータコンテンツは、事前記録することができるか、またはライブストリーミングであり得る。コンテンツ共有プラットフォームの一実装形態としてチャネルが説明されるが、本開示の実装形態は、チャネルモデルを介してコンテンツアイテム121を提供するコンテンツ共有プラットフォームに限定されない。
The
図2～図4は、本開示の様々な態様による、複合ユーザインターフェースをエンドポイントデバイスに提供する例示的な方法を示す。説明を簡単にするために、方法は一連の行為として図示および説明される。しかしながら、本開示による行為は、様々な順序で、かつ/または並行して、また本明細書で提示および説明されない他の行為とともに、行うことができる。さらに、すべてが図示されるとは限らない行為が、開示する主題による方法を実施するために必要とされることがある。加えて、方法が、代替として、状態図またはイベントを介して相互に関係する一連の状態として表すことができることを、当業者は理解および諒解されよう。追加として、本明細書で開示する方法が、そのような方法をコンピューティングデバイスに輸送および伝達することを容易にするために、製造品上に記憶されることが可能であることを諒解されたい。本明細書で使用する製造品という用語は、任意のコンピュータ可読デバイスまたは記憶媒体からアクセス可能なコンピュータプログラムを包含するものとする。 2-4 show exemplary methods of providing a composite user interface to an endpoint device in various aspects of the present disclosure. For simplicity of explanation, the method is illustrated and described as a series of actions. However, the acts of the present disclosure may be performed in various order and / or in parallel and with other acts not presented and described herein. In addition, actions that are not all illustrated may be required to implement the method according to the subject of disclosure. In addition, one of ordinary skill in the art will understand and understand that the method can, as an alternative, be represented as a series of interrelated states via a phase diagram or event. In addition, it should be appreciated that the methods disclosed herein can be stored on the manufactured product to facilitate transport and transmission of such methods to computing devices. .. As used herein, the term manufactured product shall include computer programs accessible from any computer-readable device or storage medium.
その上、様々な行為がそれぞれのシステム図に関して上記で詳細に説明されている。以前の図におけるそのような行為の詳細な説明が、以下の方法に従って実施可能であり得ること、および実施可能であることを意図することを、諒解されたい。 Moreover, various actions are described in detail above for each system diagram. Please understand that the detailed description of such an act in the previous figure may and is intended to be feasible in accordance with the following methods.
方法は、ハードウェア(回路構成、専用論理など)、ソフトウェア(たとえば、処理デバイス上で動作させられる命令)、またはそれらの組合せを含み得る、処理論理によって実行され得る。いくつかの実施形態では、本方法の一部または全部の動作は、図1のサーバ106によって実行されてよい。 The method can be performed by processing logic, which may include hardware (circuit configurations, dedicated logic, etc.), software (eg, instructions operated on the processing device), or a combination thereof. In some embodiments, some or all of the operations of the method may be performed by server 106 of FIG.
図2を参照すると、フロー図が、本開示のいくつかの態様による、複合ユーザインターフェースをエンドポイントデバイスに提供するための例示的な方法200を示す。ブロック210において、ユーザインターフェースを介して提示されるべきメディアアイテムを求めて、ユーザ要求が受信され得る。ユーザ要求は、メディアアイテムがその上で提示されることになるエンドポイントデバイスに関する情報を含んでよい。一実装形態では、ユーザ要求は、エンドポイントデバイスの能力に関する情報を含んでよい。たとえば、ユーザ要求は、1つまたは複数のビデオストリームを表示するための、エンドポイントデバイスの能力に関する情報を含んでよい。ユーザ要求は、エンドポイントデバイスによってサポートされるような、ユーザに提示されるべきメディアアイテムを符号化するために使用され得る最大解像度に関する情報を、さらに含んでよい。
Referring to FIG. 2, a flow diagram illustrates an
ユーザインターフェースを介して提示されるべきメディアアイテムを求めるユーザ要求に応答して、サーバは、ユーザインターフェースが1つまたは複数のビデオコンテンツコンポーネントおよび1つまたは複数のUIコントロールコンポーネントを含む複合ユーザインターフェースであることを決定し得る。ビデオコンテンツコンポーネントは、ビデオ(たとえば、ライブビデオ、以前にアップロードされたビデオ、3Dビデオなど)の再生を行うことができる。UIコントロールコンポーネントは、ビデオについての情報(たとえば、ビデオのタイトル、ビデオの現在再生されている部分のサブタイトル、ビデオの現在再生されている部分に対する解説など)を提示することができ、ユーザが、ビデオに関する入力を提供すること(たとえば、ビデオの1つもしくは複数の後続の部分に対するコンテンツの変更、またはビデオの1つもしくは複数の後続の部分の再生のシーケンスにおける変更をもたらし得る、データを入力すること、関連する地理的ロケーションについての情報または描写される登場人物もしくは対象物についての情報などの、ビデオの現在再生されている部分についての情報を要求することなど)を、可能にすることができる。一実装形態では、要求されるメディアアイテムは、エンドポイントデバイスへストリーミングされるべきオンラインゲームであってよい。そのような実装形態では、ビデオコンテンツコンポーネントは、ゲームプレーコンポーネント(ゲームワールドコンポーネントとも呼ばれる)を含んでよく、UIコントロールコンポーネントは、ゲームまたはゲームの中の登場人物についての情報(たとえば、ゲームのタイトル、ゲームの現在再生されている部分のサブタイトル、ゲームの現在再生されている部分に対する解説など)を提示するゲームUIコンポーネントを含んでよく、ユーザが、ゲームに関する入力を提供すること(たとえば、ゲームの1つもしくは複数の後続の部分に対する登場人物もしくはアクションの変更、または後続のゲームプレーのシーケンスにおける変更をもたらし得る、データを入力すること、関連する地理的ロケーションについての情報または描写される登場人物もしくは対象物についての情報などの、ゲームプレーの現在再生されている部分についての情報を要求することなど)を、可能にし得る。 In response to a user request for a media item to be presented through the user interface, the server is a composite user interface whose user interface contains one or more video content components and one or more UI control components. You can decide that. The video content component can play video (for example, live video, previously uploaded video, 3D video, etc.). The UI control component can provide information about the video (for example, the title of the video, the subtitle of the currently playing part of the video, a description of the currently playing part of the video, etc.) so that the user can present the video. To provide input for (for example, inputting data that may result in content changes to one or more subsequent parts of the video, or changes in the playback sequence of one or more subsequent parts of the video. , Requesting information about the currently playing part of the video, such as information about the relevant geographic location or information about the characters or objects depicted). In one implementation, the required media item may be an online game to be streamed to an endpoint device. In such an implementation, the video content component may include a gameplay component (also known as a game world component), and the UI control component may be information about the game or characters in the game (eg, the title of the game, etc.). It may include a game UI component that presents a subtitle of the currently playing part of the game, a commentary on the currently playing part of the game, etc., and allows the user to provide input about the game (eg, 1 of the game). Entering data, information or portrayed characters or objects about relevant geographic locations that may result in changes in characters or actions for one or more subsequent parts, or changes in subsequent gameplay sequences. Requesting information about the currently playing part of the gameplay, such as information about things) may be possible.
ユーザインターフェースがビデオコンテンツコンポーネントおよびUIコントロールコンポーネントを含む複合ユーザインターフェースであることを決定すると、サーバは、UIコントロールコンポーネントのレンダリングとは別個に、ビデオコンテンツコンポーネントのレンダリングを生成し得る。サーバは、複合ユーザインターフェースを介して提示されるべきである、要求されるメディアアイテムごとにそうしてよく、または代替として、サーバは、(たとえば、図4に関して以下でより詳細に説明するように、要求の中に含まれる情報に基づいて)そうすべきかどうかについての決定を行ってよい。 If the user interface is determined to be a composite user interface that includes a video content component and a UI control component, the server may generate a rendering of the video content component separately from the rendering of the UI control component. The server should be presented via a composite user interface, either for each requested media item, or as an alternative, the server (eg, as described in more detail below with respect to FIG. 4). You may make a decision as to whether or not to do so (based on the information contained in the request).
ブロック220において、ビデオコンテンツコンポーネントのレンダリングが生成され得る。ビデオコンテンツコンポーネントのレンダリングは、グラフィックスをレンダリングするためのメカニズムを使用して生成されてよい。一実装形態では、ビデオコンテンツコンポーネントのレンダリングは、グラフィックス処理ユニット(GPU)上でのグラフィックスレンダリングパイプラインにおける動作を実行することによって生成されてよい。別の実装形態では、ビデオコンテンツコンポーネントのレンダリングは、中央処理ユニット(CPU)上またはグラフィックスレンダリングユニット(レンダ出力ユニットとも呼ばれる)上でのソフトウェアレンダリングパイプラインにおける動作を実行することによって生成されてよい。さらに別の実装形態では、ビデオコンテンツコンポーネントのレンダリングは、レンダリングを生成するためにアクセラレータと通信するグラフィックスアプリケーションプログラミングインターフェース(API)を呼び出すことによって開始されてよい。 At block 220, a rendering of the video content component may be generated. Rendering of video content components may be generated using a mechanism for rendering graphics. In one implementation, the rendering of the video content component may be generated by performing operations in the graphics rendering pipeline on the graphics processing unit (GPU). In another embodiment, the rendering of the video content component may be generated by performing operations in the software rendering pipeline on a central processing unit (CPU) or a graphics rendering unit (also known as a render output unit). .. In yet another implementation, rendering of the video content component may be initiated by calling a graphics application programming interface (API) that communicates with the accelerator to generate the rendering.
複合UIのUIコントロールコンポーネントのレンダリングを生成するために、サーバは、UIコントロールコンポーネントをレンダリングするためのコマンドのセットを識別する。そのようなコマンドは、(たとえば、ソフトウェア開発者またはビデオコンテンツ発行者によって)あらかじめ提供されてよく、サーバによってアクセス可能なデータストアの中に記憶されてよい。ブロック230において、UIコントロールコンポーネントのレンダリングを生成するために、コマンドの上記のセットが実行され得る。一実装形態では、UIコントロールコンポーネントのレンダリングを生成するためのコマンドのセットは、複合UIが開発されるときにソフトウェア開発者によって明示的に指定されてよい。別の実装形態では、コマンドのセットは、サードパーティから受信されてよく、サードパーティは、コマンドのセットをUIコントロールコンポーネントのレンダリングを生成するためのコマンドとして明示的に指定してよい。さらに別の実装形態では、コマンドのセットは、複数のサードパーティから受信されるコマンドの複数のセットから構成され得る。そのような実装形態では、サードパーティは、コマンドのセットをUIコントロールコンポーネントの一部分のレンダリングを生成するためのコマンドとして明示的に示してよい。
To generate a rendering of a UI control component for a composite UI, the server identifies a set of commands for rendering the UI control component. Such commands may be provided in advance (eg, by a software developer or video content publisher) and may be stored in a data store accessible by the server. At
ブロック240において、ビデオコンテンツコンポーネントのレンダリングを含む第1のストリーム、およびUIコントロールコンポーネントのレンダリングを含む第2のストリームが、エンドポイントデバイスへ送信され得る。一実装形態では、第1のストリームおよび第2のストリームは、異なる表示解像度に符号化され得る。詳細には、第2のストリームは、第1のストリームよりも高い表示解像度に符号化され得る。たとえば、第2のストリームは、エンドポイントデバイスによってサポートされる最大解像度に符号化されてよく、第1のストリームは、エンドポイントデバイスによってサポートされる最大解像度よりも低い解像度に符号化されてよい。 At block 240, a first stream containing the rendering of the video content component and a second stream containing the rendering of the UI control component may be sent to the endpoint device. In one implementation, the first stream and the second stream may be encoded at different display resolutions. In particular, the second stream may be encoded at a higher display resolution than the first stream. For example, the second stream may be encoded at the maximum resolution supported by the endpoint device, and the first stream may be encoded at a resolution lower than the maximum resolution supported by the endpoint device.
エンドポイントデバイスは、第1のストリームおよび第2のストリームを受信し得る。エンドポイントデバイスは、第2のストリームが第1のストリームよりも高い解像度に符号化されていることを決定してよく、第2のストリームの解像度に整合するように(たとえば、第1のストリームの元のサンプルの間に0値サンプルを挿入してサンプリングレートを高くすることによって)、第1のストリームに対してアップサンプリング技法を使用してよい。エンドポイントデバイスは、第1のストリームおよび第2のストリームをユーザに提示し得る。一実装形態では、エンドポイントデバイスは、第1のストリームと第2のストリームとが1つのメディアアイテムとしてユーザに提示されるように、第1のストリームにオーバーレイするものとして第2のストリームを提示し得る。 The endpoint device may receive a first stream and a second stream. The endpoint device may determine that the second stream is encoded at a higher resolution than the first stream so that it matches the resolution of the second stream (eg, of the first stream). You may use the upsampling technique for the first stream (by inserting a 0-value sample between the original samples to increase the sampling rate). The endpoint device may present the first stream and the second stream to the user. In one implementation, the endpoint device presents the second stream as an overlay on the first stream so that the first stream and the second stream are presented to the user as one media item. obtain.
図3は、本開示のいくつかの態様による、複合ユーザインターフェースをエンドポイントデバイスに提供するための別の例示的な方法のフロー図を示す。ブロック310において、ユーザインターフェースを介して提示されるべきメディアアイテムを求めて、ユーザ要求が受信され得る。ブロック310は、図2のブロック210と類似であってよい。
FIG. 3 shows a flow diagram of another exemplary method for providing a composite user interface to an endpoint device, according to some aspects of the present disclosure. At
ユーザインターフェースを介して提示されるべきメディアアイテムを求めるユーザ要求に応答して、サーバは、ユーザインターフェースが1つまたは複数のビデオコンテンツコンポーネントおよび1つまたは複数のUIコントロールコンポーネントを含む複合ユーザインターフェースであることを決定し得る。ユーザインターフェースがビデオコンテンツコンポーネントおよびUIコントロールコンポーネントを含む複合ユーザインターフェースであることを決定すると、サーバは、ビデオコンテンツコンポーネントのレンダリングを生成してよく、(UIコントロールコンポーネントをレンダリングするためのコマンドのセットをエンドポイントデバイスに提供することによって)UIコントロールコンポーネントのレンダリングを生成するようにエンドポイントデバイスに命令し得る。サーバは、複合ユーザインターフェースを介して提示されるべきである、要求されるメディアアイテムごとにそうしてよく、または代替として、サーバは、(たとえば、図4に関して以下でより詳細に説明するように、要求の中に含まれる情報に基づいて)そうすべきかどうかについての決定を行ってよい。 In response to a user request for a media item to be presented through the user interface, the server is a composite user interface whose user interface contains one or more video content components and one or more UI control components. You can decide that. If the user interface determines that it is a composite user interface that includes a video content component and a UI control component, the server may generate a rendering of the video content component (ends a set of commands for rendering the UI control component). You can instruct the endpoint device to generate a rendering of the UI control component (by providing it to the point device). The server should be presented via a composite user interface, either for each requested media item, or as an alternative, the server (eg, as described in more detail below with respect to FIG. 4). You may make a decision as to whether or not to do so (based on the information contained in the request).
ブロック320において、図2に関して上記でより詳細に説明したように、ビデオコンテンツコンポーネントのレンダリングが生成され得る。 At block 320, rendering of the video content component may be generated, as described in more detail above with respect to FIG.
ブロック330において、ビデオコンテンツコンポーネントのレンダリングを含む第1のストリームが、エンドポイントデバイスへ送信され得る。一実装形態では、第1のストリームは、エンドポイントデバイスによってサポートされる最大解像度よりも低い解像度に符号化されてよい。代替として、第1のストリームは、エンドポイントデバイスによってサポートされる最大解像度に符号化されてよい。 At block 330, a first stream containing the rendering of the video content component may be sent to the endpoint device. In one implementation, the first stream may be encoded at a resolution lower than the maximum resolution supported by the endpoint device. Alternatively, the first stream may be encoded to the maximum resolution supported by the endpoint device.
ブロック340において、第1のビデオストリームのビデオコンテンツコンポーネントに関連するUIコントロールコンポーネントをレンダリングするために、コマンドのセットがエンドポイントデバイスへ送信され得る。一実装形態では、UIコントロールコンポーネントのレンダリングを生成するためのコマンドのセットは、複合UIが開発されるときに開発者によって明示的に示されてよい。別の実装形態では、コマンドのセットは、サードパーティから受信されてよく、サードパーティは、コマンドのセットをUIコントロールコンポーネントのレンダリングを生成するためのコマンドとして明示的に指定してよい。さらに別の実装形態では、コマンドのセットは、複数のサードパーティから受信されるコマンドの複数のセットから構成され得る。そのような実装形態では、サードパーティは、コマンドのセットをUIコントロールコンポーネントの一部分のレンダリングを生成するためのコマンドとして明示的に示してよい。 At block 340, a set of commands may be sent to the endpoint device to render the UI control component associated with the video content component of the first video stream. In one implementation, the set of commands for generating the rendering of the UI control component may be explicitly shown by the developer when the composite UI is developed. In another implementation, the set of commands may be received from a third party, who may explicitly specify the set of commands as commands to generate a rendering of the UI control component. In yet another implementation, a set of commands may consist of multiple sets of commands received from multiple third parties. In such an implementation, the third party may explicitly present the set of commands as commands to generate a rendering of a portion of the UI control component.
一実装形態では、UIコントロールコンポーネントをレンダリングするためのコマンドの第2のセットが、UIコントロールコンポーネントをレンダリングするためのコマンドの初期セットに基づいて生成され得る。コマンドの第2のセットは、UIコントロールコンポーネントをレンダリングするための高レベル命令を含んでよい。たとえば、コマンドの第2のセットは、UIコントロールコンポーネントをレンダリングするための高レベル命令を含んでよいが、コマンドの初期セットは、実際にUIコントロールコンポーネントをレンダリングするのに必要とされる情報を有する特定の命令を含んでよい。一実装形態では、コマンドの初期セットの代わりに、コマンドの第2のセットがエンドポイントデバイスへ送信されてよい。コマンドの第2のセットを使用して、エンドポイントデバイスは、どんなタイプのUI制御がUIの中に含められるべきかを決定することができ、レンダリングを生成するためのこの特定のタイプのUI制御に対して、局所的に記憶された命令を使用することができる。 In one implementation, a second set of commands for rendering the UI control component may be generated based on the initial set of commands for rendering the UI control component. The second set of commands may contain high-level instructions for rendering UI control components. For example, a second set of commands may contain high-level instructions for rendering a UI control component, while an initial set of commands may contain the information needed to actually render the UI control component. It may contain specific instructions. In one implementation, a second set of commands may be sent to the endpoint device instead of the initial set of commands. Using a second set of commands, the endpoint device can determine what type of UI control should be included in the UI, and this particular type of UI control to generate the rendering. You can use locally stored commands for.
エンドポイントデバイスは、第1のストリーム、およびUIコントロールコンポーネントのレンダリングを生成するためのコマンドのセットを受信し得る。エンドポイントデバイスは、コマンドの受信されたセットを実行してよく、UIコントロールコンポーネントのレンダリングを生成し得る。一実装形態では、エンドポイントデバイスは、第1のストリームがエンドポイントデバイスの最大解像度に整合するようにアップサンプリング技法を使用してよい。代替として、第1のストリームは、UIコントロールコンポーネントをレンダリングするために使用される同じ解像度に符号化されてよく、コマンドを送信することはUIコントロールコンポーネントのレンダリングを送信することよりも少ない帯域幅および計算リソースしか必要としないので、そのことは帯域幅使用量の観点からやはり利点であることになる。 The endpoint device may receive a first stream, and a set of commands to generate a rendering of the UI control component. The endpoint device may execute the received set of commands and may produce a rendering of the UI control component. In one implementation, the endpoint device may use an upsampling technique so that the first stream matches the maximum resolution of the endpoint device. Alternatively, the first stream may be encoded at the same resolution used to render the UI control component, sending commands with less bandwidth and sending a render of the UI control component. That would still be an advantage in terms of bandwidth usage, as it requires only computational resources.
エンドポイントデバイスは、第1のストリームおよびUIコントロールコンポーネントのレンダリングをユーザに提示し得る。たとえば、エンドポイントデバイスは、第1のストリームとUIコントロールコンポーネントとが1つのメディアアイテムとしてユーザに提示されるように、第1のストリームにオーバーレイするものとしてUIコントロールコンポーネントのレンダリングを提示し得る。 The endpoint device may present the user with a rendering of the first stream and UI control components. For example, an endpoint device may present a rendering of the UI control component as an overlay on the first stream, just as the first stream and the UI control component are presented to the user as a single media item.
図4は、本開示のいくつかの態様による、複合ユーザインターフェースをエンドポイントデバイスに提供するためのさらに別の例示的な方法のフロー図を示す。ブロック410において、複合ユーザインターフェースを介して提示されるべきメディアアイテムを求めて、ユーザ要求が受信され得る。複合ユーザインターフェースは、1つまたは複数のビデオコンテンツコンポーネントおよび1つまたは複数のUIコントロールコンポーネントを含んでよい。一実装形態では、要求されるメディアアイテムは、エンドポイントデバイスへストリーミングされるべきゲームであってよい。そのような実装形態では、ビデオコンテンツコンポーネントは、ゲームコンポーネント(ゲームワールドコンポーネントとも呼ばれる)を含んでよく、UIコントロールコンポーネントは、ゲームUIコンポーネントを含んでよい。一実装形態では、UIコントロールコンポーネントを介してユーザ入力が受信され得る。 FIG. 4 shows a flow diagram of yet another exemplary method for providing a composite user interface to an endpoint device, according to some aspects of the disclosure. At block 410, a user request may be received asking for a media item to be presented via a composite user interface. A composite user interface may include one or more video content components and one or more UI control components. In one implementation, the required media item may be a game that should be streamed to an endpoint device. In such an implementation, the video content component may include a game component (also referred to as a game world component) and the UI control component may include a game UI component. In one implementation, user input may be received via the UI control component.
ユーザ要求は、メディアアイテムがその上で提示されることになるエンドポイントデバイスに関する情報を含んでよい。一実装形態では、ユーザ要求は、エンドポイントデバイスの能力に関する情報を含んでよい。たとえば、ユーザ要求は、1つまたは複数のビデオストリームを表示するための、エンドポイントデバイスの能力に関する情報を含んでよい。ユーザ要求は、ユーザに提示されるメディアアイテムが符号化され得る先の最大解像度に関する情報をさらに含んでよい。 The user request may include information about the endpoint device on which the media item will be presented. In one implementation, the user request may include information about the capabilities of the endpoint device. For example, the user request may include information about the ability of the endpoint device to display one or more video streams. The user request may further include information about the maximum resolution at which the media item presented to the user can be encoded.
ブロック415において、UIコントロールコンポーネントのレンダリングをサーバにおいて(たとえば、図1を参照しながら説明したプラットフォームにおいて)生成すべきか、それともエンドポイントデバイスにおいて生成すべきかが、決定され得る。一実装形態では、UIコントロールコンポーネントのレンダリングを生成すべきかどうかという決定は、エンドポイントデバイスのハードウェア能力、エンドポイントデバイスの解像度、複合UIの目標解像度、サーバのレンダリング能力、またはネットワーク(たとえば、図1のネットワーク105)上で利用可能な帯域幅のうちの少なくとも1つに基づいてよい。 At block 415, it can be determined whether the rendering of the UI control component should be generated on the server (eg, on the platform described with reference to Figure 1) or on the endpoint device. In one implementation, the decision whether to generate a rendering of a UI control component is the hardware capability of the endpoint device, the resolution of the endpoint device, the target resolution of the composite UI, the rendering capability of the server, or the network (eg, diagram). It may be based on at least one of the bandwidths available on one network 105).
一実装形態では、UIコントロールコンポーネントのレンダリングをサーバにおいて生成すべきかどうかが決定され得る。たとえば、エンドポイントデバイスが低い処理能力を有する場合、UIコントロールコンポーネントのレンダリングをサーバにおいて生成すべきと決定されてよい。UIコントロールコンポーネントのレンダリングをサーバにおいて生成すべきと決定される場合、方法400はブロック420に進んでよい。
In one implementation, it may be determined whether the rendering of the UI control component should be generated on the server. For example, if the endpoint device has low processing power, it may be determined that the rendering of the UI control component should be generated on the server. If it is determined that the rendering of the UI control component should be generated on the server,
ブロック420において、UIコントロールコンポーネントのレンダリングをビデオコンテンツコンポーネントのレンダリングと一緒に生成すべきかどうかが決定され得る。一実装形態では、UIコントロールコンポーネントのレンダリングをビデオコンテンツコンポーネントのレンダリングと一緒に生成すべきと決定され得る。たとえば、エンドポイントデバイスが、一度に1つのビデオストリームをユーザに表示することが可能である場合、UIコントロールコンポーネントのレンダリングをビデオコンテンツコンポーネントのレンダリングと一緒に生成すべきと決定されてよい。別の例では、エンドポイントデバイスが低い最大解像度を有する場合、UIコントロールコンポーネントのレンダリングをビデオコンテンツコンポーネントのレンダリングと一緒に生成すべきと決定されてよい。 At block 420, it may be determined whether the rendering of the UI control component should be generated along with the rendering of the video content component. In one implementation, it may be determined that the rendering of the UI control component should be generated along with the rendering of the video content component. For example, if the endpoint device is capable of displaying one video stream to the user at a time, it may be determined that the rendering of the UI control component should be generated along with the rendering of the video content component. In another example, if the endpoint device has a low maximum resolution, it may be determined that the rendering of the UI control component should be generated along with the rendering of the video content component.
UIコントロールコンポーネントのレンダリングをビデオコンテンツコンポーネントのレンダリングと一緒に生成すべきと決定される場合、方法400はブロック425に進んでよい。ブロック425において、ビデオコンテンツコンポーネントおよびUIコントロールコンポーネントのレンダリングが、複合UIのレンダリングとして生成され得る。一実装形態では、図2を参照しながら上記で説明したように、複合UIのレンダリングは、グラフィックスをレンダリングするために使用される任意の方法を通じて生成されてよい。別の実装形態では、図2を参照しながら上記で説明したように、複合UIのレンダリングは、GPU上でのグラフィックスレンダリングパイプラインにおいて実行される動作によって生成されてよい。さらに別の実装形態では、図2を参照しながら上記で説明したように、複合UIのレンダリングは、CPU上またはグラフィックスレンダリングユニット上でのソフトウェアレンダリングパイプラインにおいて実行される動作によって生成されてよい。さらに別の実装形態では、図2を参照しながら上記で説明したように、複合UIは、グラフィックスAPIを使用してレンダリングされてよい。
If it is determined that the rendering of the UI control component should be generated along with the rendering of the video content component,
ブロック430において、第1のストリームがエンドポイントデバイスへ送信され得る。第1のストリームは、ブロック425において生成された複合UIのレンダリングを含んでよい。エンドポイントデバイスは、第1のストリームをユーザに提示し得る。 At block 430, a first stream may be sent to the endpoint device. The first stream may contain a rendering of the composite UI generated in block 425. The endpoint device may present the first stream to the user.
一実装形態では、ビデオコンテンツコンポーネントのレンダリングとは別個にUIコントロールコンポーネントのレンダリングを生成すべきと決定され得る。たとえば、エンドポイントデバイスが同時に複数のビデオストリームをユーザに表示することが可能である場合、ビデオコントロールコンポーネントのレンダリングとは別個にUIコントロールコンポーネントのレンダリングを生成すべきと決定されてよい。別の例では、エンドポイントデバイスが提示することが可能な最大解像度におけるビデオコンテンツコンポーネントおよびUIコントロールコンポーネントのレンダリングを含む、単一のストリームを送信するための大量のネットワーク帯域幅がない場合、ビデオコントロールコンポーネントのレンダリングとは別個にUIコントロールコンポーネントのレンダリングを生成すべきと決定されてよい。 In one implementation, it may be determined that the rendering of the UI control component should be generated separately from the rendering of the video content component. For example, if the endpoint device is capable of displaying multiple video streams to the user at the same time, it may be determined that the rendering of the UI control component should be generated separately from the rendering of the video control component. In another example, if you do not have a large amount of network bandwidth to send a single stream, including rendering of video content and UI control components at the maximum resolution that the endpoint device can present, video control It may be decided that the rendering of the UI control component should be generated separately from the rendering of the component.
ブロック420において、ビデオコンテンツコンポーネントのレンダリングとは別個にUIコントロールコンポーネントのレンダリングを生成すべきと決定される場合、方法400はブロック435に進んでよい。ブロック435において、図2を参照しながら上記で説明したように、ビデオコンテンツコンポーネントのレンダリングが生成され得る。ビデオコンテンツコンポーネントのレンダリングは、第1のビデオストリームの中に含められてよい。一実装形態では、第1のビデオストリームは、エンドポイントデバイスが提示することが可能な最大解像度よりも低い解像度に符号化され得る。
If at block 420 it is determined that the rendering of the UI control component should be generated separately from the rendering of the video content component,
ブロック440において、図2を参照しながら上記で説明したように、UIコントロールコンポーネントのレンダリングを生成するために、コマンドのセットが実行され得る。 At block 440, a set of commands may be executed to generate a rendering of the UI control component, as described above with reference to FIG.
UIコントロールコンポーネントのレンダリングは、第2のストリームの中に含められてよい。一実装形態では、第2のストリームは、エンドポイントが提示することが可能な最大解像度に符号化され得る。一実装形態では、第2のストリームは、第1のストリームの解像度よりも高い解像度に符号化され得る。 The rendering of the UI control component may be included in the second stream. In one implementation, the second stream may be encoded to the maximum resolution that the endpoint can present. In one implementation, the second stream may be encoded at a higher resolution than the resolution of the first stream.
ブロック445において、第1のストリームおよび第2のストリームがエンドポイントデバイスへ送信され得る。第1のストリームは、ビデオコンテンツコンポーネントのレンダリングを含んでよい。第2のストリームは、UIコントロールコンポーネントのレンダリングを含んでよい。 At block 445, a first stream and a second stream may be sent to the endpoint device. The first stream may include rendering of the video content component. The second stream may contain a rendering of the UI control component.
エンドポイントデバイスは、第1のストリームおよび第2のストリームを受信し得る。エンドポイントデバイスは、第2のストリームが第1のストリームよりも高い表示解像度に符号化されていることを決定し得る。一実装形態では、エンドポイントデバイスは、第1のストリームが第2のストリームの解像度に整合するようにアップサンプリング技法を使用してよい。エンドポイントデバイスは、第1のストリームおよび第2のストリームをユーザに提示し得る。一実装形態では、エンドポイントデバイスは、第1のストリームと第2のストリームとが1つのメディアアイテムとしてユーザに提示されるように、第1のストリームにオーバーレイするものとして第2のストリームを提示し得る。 The endpoint device may receive a first stream and a second stream. The endpoint device may determine that the second stream is encoded at a higher display resolution than the first stream. In one implementation, the endpoint device may use upsampling techniques so that the first stream matches the resolution of the second stream. The endpoint device may present the first stream and the second stream to the user. In one implementation, the endpoint device presents the second stream as an overlay on the first stream so that the first stream and the second stream are presented to the user as one media item. obtain.
一実装形態では、UIコントロールコンポーネントのレンダリングをエンドポイントデバイスにおいて生成すべきと決定され得る。たとえば、エンドポイントデバイスが高い処理能力を有する場合、UIコントロールコンポーネントのレンダリングをエンドポイントデバイスにおいて生成すべきと決定されてよい。 In one implementation, it may be determined that the rendering of the UI control component should be generated on the endpoint device. For example, if the endpoint device has high processing power, it may be determined that the rendering of the UI control component should be generated on the endpoint device.
ブロック415において、UIコントロールコンポーネントのレンダリングをエンドポイントデバイスにおいて生成すべきと決定される場合、方法400はブロック450に進んでよい。ブロック450において、図2を参照しながら上記で説明したように、ビデオコンテンツコンポーネントのレンダリングが生成され得る。ビデオコンテンツコンポーネントのレンダリングは、第1のストリームの中に含められてよい。一実装形態では、第1のストリームは、エンドポイントデバイスが提示することが可能な最大解像度よりも低い解像度に符号化され得る。別の実装形態では、第1のストリームは、エンドポイントデバイスが提示することが可能な最大解像度に符号化され得る。
If at block 415 it is determined that the rendering of the UI control component should be generated on the endpoint device,
一実装形態では、UIコントロールコンポーネントをレンダリングするためのコマンドの第2のセットが、UIコントロールコンポーネントをレンダリングするためのコマンドの初期セットに基づいて生成され得る。コマンドの第2のセットは、図3を参照しながら上記で説明したように、UIコントロールコンポーネントをレンダリングするための高レベル命令を含んでよい。一実装形態では、コマンドの初期セットの代わりに、コマンドの第2のセットがエンドポイントデバイスへ送信されてよい。 In one implementation, a second set of commands for rendering the UI control component may be generated based on the initial set of commands for rendering the UI control component. The second set of commands may contain high-level instructions for rendering UI control components, as described above with reference to Figure 3. In one implementation, a second set of commands may be sent to the endpoint device instead of the initial set of commands.
ブロック455において、第1のストリームがエンドポイントデバイスへ送信され得る。第1のストリームは、ビデオコンテンツコンポーネントのレンダリングを含んでよい。たとえば、エンドポイントデバイスによってサポートされる最大解像度でレンダリングするために、コマンドのセットもエンドポイントデバイスへ送信され得る。コマンドのセットは、UIコントロールコンポーネントをレンダリングするためのコマンドのセットであってよい。一実装形態では、エンドポイントデバイスは、第1のストリームがエンドポイントデバイスの最大解像度に整合するようにアップサンプリング技法を使用してよい。エンドポイントデバイスは、第1のストリームおよびUIコントロールコンポーネントのレンダリングをユーザに提示し得る。たとえば、エンドポイントデバイスは、第1のストリームとUIコントロールコンポーネントとが1つのメディアアイテムとしてユーザに提示されるように、第1のストリームにオーバーレイするものとしてUIコントロールコンポーネントのレンダリングを提示し得る。 At block 455, the first stream may be sent to the endpoint device. The first stream may include rendering of the video content component. For example, a set of commands may also be sent to the endpoint device to render at the maximum resolution supported by the endpoint device. A set of commands may be a set of commands for rendering a UI control component. In one implementation, the endpoint device may use an upsampling technique so that the first stream matches the maximum resolution of the endpoint device. The endpoint device may present the user with a rendering of the first stream and UI control components. For example, an endpoint device may present a rendering of the UI control component as an overlay on the first stream, just as the first stream and the UI control component are presented to the user as a single media item.
図5は、本開示の1つまたは複数の態様に従って動作するコンピューティングデバイスの例示的なブロック図を示す。コンピュータシステム500は、図1の中のサーバ106またはエンドポイントデバイス110A～110Zであり得る。マシンは、エンドポイントサーバネットワーク環境におけるサーバもしくはエンドポイントマシンの能力において、またはピアツーピア(または分散)ネットワーク環境におけるピアマシンとして、動作することができる。マシンは、テレビ、パーソナルコンピュータ(PC)、タブレットPC、セットトップボックス(STB)、携帯情報端末(PDA)、セルラー電話、ウェブアプライアンス、サーバ、ネットワークルータ、スイッチもしくはブリッジ、またはそのマシンによってとられるべきアクションを指定する(連続的な、または別様の)命令のセットを実行することが可能な任意のマシンであり得る。さらに、単一のマシンしか図示されていないが、「マシン」という用語はまた、本明細書で説明する方法のうちのいずれか1つまたは複数を実行するための命令のセット(または複数のセット)を個々にまたは一緒に実行する、マシンの任意の集合を含むように理解されるものとする。
FIG. 5 shows an exemplary block diagram of a computing device operating in accordance with one or more aspects of the present disclosure. The
例示的なコンピュータシステム500は、処理デバイス(プロセッサ)502、メインメモリ504(たとえば、読取り専用メモリ(ROM)、フラッシュメモリ、同期DRAM(SDRAM)、ダブルデータレート(DDR SDRAM)、またはDRAM(RDRAM)などのダイナミックランダムアクセスメモリ(DRAM)など)、スタティックメモリ506(たとえば、フラッシュメモリ、スタティックランダムアクセスメモリ(SRAM)など)、およびデータ記憶デバイス518を含み、それらはバス540を介して互いに通信する。
An
プロセッサ(処理デバイス)502は、マイクロプロセッサ、中央処理ユニットなどの、1つまたは複数の汎用処理デバイスを表す。より詳細には、プロセッサ502は、複合命令セットコンピューティング(CISC)マイクロプロセッサ、縮小命令セットコンピューティング(RISC)マイクロプロセッサ、超長命令語(VLIW)マイクロプロセッサ、または他の命令セットを実施するプロセッサもしくは命令セットの組合せを実施するプロセッサであり得る。プロセッサ502はまた、特定用途向け集積回路(ASIC)、フィールドプログラマブルゲートアレイ(FPGA)、デジタル信号プロセッサ(DSP)、ネットワークプロセッサなどの、1つまたは複数の専用処理デバイスであり得る。プロセッサ502は、本明細書で説明する動作を実行するために、(たとえば、レンダリングコンポーネント122または通信アプリケーション115の)命令505を実行するように構成される。
Processor (processing device) 502 represents one or more general purpose processing devices such as microprocessors, central processing units, and the like. More specifically, the
コンピュータシステム500は、ネットワークインターフェースデバイス508をさらに含むことができる。コンピュータシステム500はまた、ビデオディスプレイユニット510(たとえば、液晶ディスプレイ(LCD)または陰極線管(CRT))、入力デバイス512(たとえば、キーボード、および英数字キーボード、動き感知入力デバイス、タッチスクリーン)、カーソル制御デバイス514(たとえば、マウス)、および信号生成デバイス520(たとえば、スピーカー)を含むことができる。
The
データ記憶デバイス518は、本明細書で説明する方法または機能のうちのいずれか1つまたは複数を具現化する(たとえば、レンダリングコンポーネント122または通信アプリケーション115の)命令505の1つまたは複数のセットがその上に記憶される非一時的機械可読記憶媒体524(同様にコンピュータ可読記憶媒体)を含むことができる。命令はまた、コンピュータシステム500による命令の実行中、メインメモリ504内および/またはプロセッサ502内に、完全にまたは少なくとも部分的に常駐することができ、メインメモリ504およびプロセッサ502も機械可読記憶媒体を構成する。命令はさらに、ネットワークインターフェースデバイス508を経由してネットワーク530を介して送信または受信され得る。
The
一実装形態では、命令505は、ビデオコンテンツコンポーネントおよび/またはUIコントロールコンポーネントをレンダリングするための命令を含む。コンピュータ可読記憶媒体524(機械可読記憶媒体)は、単一の媒体であるように例示的な実装形態の中に示されるが、「コンピュータ可読記憶媒体」および「機械可読記憶媒体」という用語は、命令の1つまたは複数のセットを記憶する単一の媒体または複数の媒体(たとえば、集中型もしくは分散型のデータベース、ならびに/または関連するキャッシュおよびサーバ)を含むものと理解されるべきである。「コンピュータ可読記憶媒体」および「機械可読記憶媒体」という用語はまた、機械による実行のための命令のセットを記憶すること、符号化すること、または搬送することが可能であり、かつ本開示の方法のうちのいずれか1つまたは複数を機械に実行させる、任意の媒体を含むものと理解されるものとする。「コンピュータ可読記憶媒体」および「機械可読記憶媒体」という用語は、したがって、限定はしないが、ソリッドステートメモリ、光媒体、および磁気媒体を含むものと理解されるものとする。
In one implementation,
本明細書全体にわたる「一実装形態(one implementation)」または「実装形態(an implementation)」への言及は、実装形態に関して説明される特定の特徴、構造、または特性が少なくとも1つの実装形態の中に含まれることを意味する。したがって、本明細書全体にわたる様々な場所における「一実装形態では」または「実装形態では」という句の出現は、事情に応じて同じ実装形態を参照することができるが、必ずしもそうとは限らない。さらに、特定の特徴、構造、または特性は、1つまたは複数の実装形態において任意の好適な方式で組み合わせられてよい。 References to "one implementation" or "an implementation" throughout this specification are within at least one implementation of a particular feature, structure, or characteristic described with respect to the implementation. Means to be included in. Therefore, the appearance of the phrase "in one implementation" or "in implementation" in various places throughout the specification may refer to the same implementation as appropriate, but not always. .. In addition, specific features, structures, or properties may be combined in any suitable manner in one or more implementations.
「含む(includes)」、「含むこと(including)」、「有する(has)」、「含む(contains)」という用語、それらの変形、および他の類似の語が、発明を実施するための形態または特許請求の範囲のいずれかの中で使用される限りにおいて、これらの用語は、いかなる追加または他の要素も排除することなく開放移行語として、「備えること(comprising)」という用語と同様に包括的であるものとする。 The terms "includes", "including", "has", "contains", variants thereof, and other similar terms are embodiments for carrying out the invention. Or, as far as it is used in any of the claims, these terms, as well as the term "comprising", as an open transition term without excluding any additions or other elements. It shall be comprehensive.
本出願で使用する「構成要素」、「モジュール」、「システム」などという用語は、概して、コンピュータ関連エンティティ、すなわち、ハードウェア(たとえば、回路)、ソフトウェア、ハードウェアとソフトウェアとの組合せのいずれか、または1つもしくは複数の特定の機能を有する動作可能な機械に関係するエンティティを指すものとする。たとえば、構成要素とは、限定はしないが、プロセッサ(たとえば、デジタル信号プロセッサ)上で動作するプロセス、プロセッサ、オブジェクト、実行ファイル、実行スレッド、プログラム、および/またはコンピュータであってよい。例として、コントローラ上で動作するアプリケーションとコントローラの両方が構成要素であり得る。1つまたは複数の構成要素は、プロセス内および/または実行スレッド内に存在してよく、構成要素は、1つのコンピュータ上に局在化されてよく、かつ/または2つ以上のコンピュータ間で分散されてよい。さらに、「デバイス」は、特別に設計されたハードウェア、特定の機能(たとえば、関心ポイントおよび/またはデスクリプタを生成すること)をハードウェアが実行することを可能にするソフトウェアがその上で実行することによって特殊化された、一般化ハードウェア、コンピュータ可読媒体上のソフトウェア、またはそれらの組合せの形態になることができる。 As used in this application, the terms "component", "module", "system", etc. are generally any of the computer-related entities, namely hardware (eg, circuits), software, or a combination of hardware and software. , Or an entity related to an operable machine with one or more specific functions. For example, a component may be, but is not limited to, a process, processor, object, executable, thread of execution, program, and / or computer running on a processor (eg, a digital signal processor). As an example, both the application running on the controller and the controller can be components. One or more components may exist within a process and / or threads of execution, the components may be localized on one computer, and / or distributed among two or more computers. May be done. In addition, a "device" is run on it by specially designed hardware, software that allows the hardware to perform certain functions (eg, to generate points of interest and / or descriptors). It can be in the form of specialized, generalized hardware, software on computer-readable media, or a combination thereof.
上述のシステム、回路、モジュールなどは、いくつかの構成要素および/またはブロックの間の相互作用に関して説明されている。そのようなシステム、回路、構成要素、ブロックなどが、それらの構成要素、または指定の下位構成要素、指定の構成要素もしくは下位構成要素のうちのいくつか、および/または追加の構成要素を含むことができ、また上記のものの様々な並べ替えおよび組合せによることが諒解され得る。下位構成要素はまた、親構成要素内に含まれるのではなく(階層的)、他の構成要素に通信可能に結合された構成要素として実装され得る。追加として、1つまたは複数の構成要素が、集約機能を提供する単一の構成要素に組み合わせられてよいこと、またはいくつかの別個の下位構成要素に分割されてよいこと、および管理レイヤなどの任意の1つまたは複数の中間層が、統合機能を提供するためにそのような下位構成要素に通信可能に結合するために提供されてよいことに、留意されたい。本明細書で説明する任意の構成要素はまた、特に本明細書で説明しないが当業者によって知られている1つまたは複数の他の構成要素と相互作用し得る。 The systems, circuits, modules, etc. described above are described with respect to the interactions between several components and / or blocks. Such systems, circuits, components, blocks, etc. include those components, or specified subcomponents, some of the specified or subordinate components, and / or additional components. It can also be understood that there are various sorts and combinations of the above. Subcomponents can also be implemented as components communicably coupled to other components rather than being contained within the parent component (hierarchically). In addition, one or more components may be combined into a single component that provides aggregate functionality, or may be subdivided into several separate subcomponents, and management layers, etc. Note that any one or more intermediate layers may be provided to communicatively connect to such subcomponents to provide integration capabilities. Any component described herein may also interact with one or more other components not specifically described herein but known by those of skill in the art.
その上、「例(example)」または「例示的(exemplary)」という語は、例、事例、または例示として働くことを意味するように、本明細書で使用される。「例示的」として本明細書で説明する任意の態様または設計は、必ずしも他の態様または設計よりも好ましいかまたは好都合であるものとして解釈されることになるとは限らない。むしろ、「例」または「例示的」という語の使用は、概念を具体的に提示することを意図する。本出願で使用する「または(or)」という用語は、排他的な「または」ではなく包括的な「または」を意味するものとする。すなわち、別段に規定されていない限り、または文脈から明瞭でない限り、「XはAまたはBを採用する」とは、自然包括的並べ替えのうちのいずれかを意味するものとする。すなわち、XがAを採用し、XがBを採用し、またはXがAとBの両方を採用する場合、上記の事例のうちのいずれの下でも「XはAまたはBを採用する」が満たされる。加えて、本出願および添付の特許請求の範囲で使用する「a」および「an」という冠詞は、概して、別段に規定されていない限り、または単数形を対象とすることが文脈から明瞭でない限り、「1つまたは複数の」を意味するものと解釈されるべきである。 Moreover, the terms "example" or "exemplary" are used herein to mean serve as an example, case, or example. Any aspect or design described herein as "exemplary" will not necessarily be construed as preferred or favorable over other aspects or designs. Rather, the use of the word "example" or "exemplary" is intended to present the concept concretely. The term "or" as used in this application shall mean a comprehensive "or" rather than an exclusive "or". That is, unless otherwise specified or unclear from the context, "X adopts A or B" shall mean any of the natural inclusive sorts. That is, if X adopts A, X adopts B, or X adopts both A and B, then under any of the above cases, "X adopts A or B" It is filled. In addition, the articles "a" and "an" used in this application and the appended claims are generally not otherwise specified or unless it is clear from the context that they are intended for the singular. , Should be interpreted to mean "one or more".
100 システムアーキテクチャ
105 ネットワーク
106 サーバ、データストア
110 エンドポイントデバイス
113 コンテンツビューア
114 検索コンポーネント
115 通信アプリケーション
116 ユーザインターフェース
120 コンテンツ共有プラットフォーム
121 コンテンツアイテム、コンテンツ
122 レンダリングコンポーネント
125 チャネルA
129 チャネルZ
145 検索プラットフォーム
150 モバイルプラットフォーム
155 協調プラットフォーム
157 推奨プラットフォーム
160 ソーシャルネットワークプラットフォーム
165 広告プラットフォーム
170 電子デバイス
175 方向パッド(Dパッド)
195 コンテンツプロバイダプラットフォーム
500 コンピュータシステム
502 処理デバイス、プロセッサ
504 メインメモリ
505 命令
506 スタティックメモリ
508 ネットワークインターフェースデバイス
510 ビデオディスプレイユニット
512 入力デバイス
514 カーソル制御デバイス
518 データ記憶デバイス
520 信号生成デバイス
524 非一時的機械可読記憶媒体、コンピュータ可読記憶媒体
530 ネットワーク
540 バス
100 system architecture
105 network
106 server, data store
110 endpoint device
113 Content Viewer
114 Search component
115 Communication application
116 User interface
120 Content Sharing Platform
121 Content Items, Content
122 Rendering component
125 channel A
129 Channel Z
145 Search platform
150 mobile platform
155 Collaborative platform
157 Recommended platform
160 social network platform
165 Advertising Platform
170 Electronic device
175 Directional pad (D pad)
195 Content Provider Platform
500 computer system
502 Processing device, processor
504 main memory
505 instructions
506 static memory
508 network interface device
510 video display unit
512 input device
514 Cursor control device
518 Data storage device
520 Signal generation device
524 Non-temporary machine-readable storage media, computer-readable storage media
530 network
540 bus
Claims (20)
前記ビデオコンテンツコンポーネントのレンダリングを生成するステップと、
前記ビデオコンテンツコンポーネントの前記レンダリングを含む第1のストリームをエンドポイントデバイスへ送信するステップと
を含み、前記第1のストリームが第1の解像度に符号化され、前記ビデオコンテンツコンポーネントの前記レンダリングが、前記エンドポイントデバイスにおいて前記UIコントロールコンポーネントのレンダリングとマージされて前記複合UIになることになり、前記複合UIが第2の解像度を有する、
方法。 A step in which the server receives a user request for a media item to be presented via a composite UI that includes one or more video content components and one or more user interface (UI) control components.
The steps to generate the rendering of the video content component,
The first stream is encoded to a first resolution and the rendering of the video content component comprises sending a first stream containing the rendering of the video content component to the endpoint device. In the endpoint device, the rendering of the UI control component will be merged into the composite UI, which has a second resolution.
Method.
前記UIコントロールコンポーネントの前記レンダリングを含む第2のストリームを前記エンドポイントデバイスへ送信するステップと
をさらに含み、前記第2のストリームが前記第2の解像度に符号化される、
請求項1に記載の方法。 A step of executing a set of commands on the server to generate the rendering of the UI control component, and
Further including the step of transmitting the second stream including the rendering of the UI control component to the endpoint device, the second stream is encoded to the second resolution.
The method according to claim 1.
前記UIコントロールコンポーネントの前記レンダリングを前記エンドポイントデバイスにおいて生成すべきという決定に応答して、前記UIコントロールコンポーネントをレンダリングするためのコマンドのセットを、ネットワークを介して前記エンドポイントデバイスへ送信するステップであって、前記UIコントロールコンポーネントの前記レンダリングが前記第1の解像度または前記第2の解像度を有する、ステップと、
前記UIコントロールコンポーネントの前記レンダリングを前記サーバにおいて生成すべきという決定に応答して、
前記UIコントロールコンポーネントの前記レンダリングを生成するために、前記UIコントロールコンポーネントをレンダリングするためのコマンドの前記セットを前記サーバにおいて実行し、
前記UIコントロールコンポーネントの前記レンダリングを含む第2のストリームを前記エンドポイントデバイスへ送信するステップと
をさらに含む、請求項1に記載の方法。 Steps to determine whether the rendering of the UI control component should be generated on the server or on the endpoint device.
In response to the decision that the rendering of the UI control component should be generated on the endpoint device, in the step of sending a set of commands for rendering the UI control component to the endpoint device over the network. The step and the step in which the rendering of the UI control component has the first resolution or the second resolution.
In response to the decision that the rendering of the UI control component should be generated on the server
To generate the rendering of the UI control component, execute the set of commands for rendering the UI control component on the server.
The method of claim 1, further comprising sending a second stream containing said rendering of the UI control component to said endpoint device.
前記メモリに結合された処理デバイスと
を備え、前記処理デバイスが、
1つまたは複数のビデオコンテンツコンポーネントおよび1つまたは複数のユーザインターフェース(UI)コントロールコンポーネントを含む複合UIを介して提示されるべきメディアアイテムを求めるユーザ要求を受信することと、
前記ビデオコンテンツコンポーネントのレンダリングを生成することと、
前記ビデオコンテンツコンポーネントの前記レンダリングを含む第1のストリームをエンドポイントデバイスへ送信することと
を行い、前記第1のストリームが第1の解像度に符号化され、前記ビデオコンテンツコンポーネントの前記レンダリングが、前記エンドポイントデバイスにおいて前記UIコントロールコンポーネントのレンダリングとマージされて前記複合UIになることになり、前記複合UIが第2の解像度を有する、
システム。 With memory
The processing device includes a processing device coupled to the memory.
Receiving a user request for a media item to be presented via a composite UI that includes one or more video content components and one or more user interface (UI) control components.
Generating the rendering of the video content component and
The first stream containing the rendering of the video content component is transmitted to the endpoint device, the first stream is encoded to the first resolution, and the rendering of the video content component is said. In the endpoint device, the rendering of the UI control component will be merged into the composite UI, which has a second resolution.
system.
前記UIコントロールコンポーネントの前記レンダリングを生成するためのコマンドのセットを実行することと、
前記UIコントロールコンポーネントの前記レンダリングを含む第2のストリームを前記エンドポイントデバイスへ送信することと
をさらに行い、前記第2のストリームが前記第2の解像度に符号化される、
請求項8に記載のシステム。 The processing device
To execute the set of commands to generate the rendering of the UI control component,
A second stream containing the rendering of the UI control component is further transmitted to the endpoint device, and the second stream is encoded to the second resolution.
The system according to claim 8.
前記エンドポイントデバイスにおいて前記第2の解像度で前記UIコントロールコンポーネントの前記レンダリングを生成するために、前記UIコントロールコンポーネントをレンダリングするためのコマンドのセットを前記エンドポイントデバイスへ送信することをさらに行う、請求項8に記載のシステム。 The processing device
Claimed to further send a set of commands for rendering the UI control component to the endpoint device in order to generate the rendering of the UI control component at the second resolution in the endpoint device. The system described in Section 8.
前記UIコントロールコンポーネントのレンダリングをサーバにおいて生成すべきかそれとも前記エンドポイントデバイスにおいて生成すべきかを決定することと、
前記UIコントロールコンポーネントの前記レンダリングを前記エンドポイントデバイスにおいて生成すべきという決定に応答して、前記UIコントロールコンポーネントをレンダリングするためのコマンドのセットを、ネットワークを介して前記エンドポイントデバイスへ送信することであって、前記UIコントロールコンポーネントの前記レンダリングが前記第1の解像度または前記第2の解像度を有する、送信することと、
前記UIコントロールコンポーネントの前記レンダリングを前記サーバにおいて生成すべきという決定に応答して、
前記UIコントロールコンポーネントの前記レンダリングを生成するために、前記UIコントロールコンポーネントをレンダリングするためのコマンドの前記セットを実行し、
前記UIコントロールコンポーネントの前記レンダリングを含む第2のストリームを前記エンドポイントデバイスへ送信することと
をさらに行う、請求項8に記載のシステム。 The processing device
Determining whether the rendering of the UI control component should be generated on the server or on the endpoint device.
By sending a set of commands for rendering the UI control component to the endpoint device over the network in response to the decision that the rendering of the UI control component should be generated on the endpoint device. And that the rendering of the UI control component has said first resolution or said second resolution, and
In response to the decision that the rendering of the UI control component should be generated on the server
To generate the rendering of the UI control component, execute the set of commands for rendering the UI control component.
The system of claim 8, further comprising sending a second stream containing said rendering of the UI control component to said endpoint device.
1つまたは複数のビデオコンテンツコンポーネントおよび1つまたは複数のユーザインターフェース(UI)コントロールコンポーネントを含む複合UIを介して提示されるべきメディアアイテムを求めるユーザ要求を、サーバにおいて受信することと、
前記ビデオコンテンツコンポーネントのレンダリングを生成することと、
前記ビデオコンテンツコンポーネントの前記レンダリングを含む第1のストリームをエンドポイントデバイスへ送信することと
を含み、前記第1のストリームが第1の解像度に符号化され、前記ビデオコンテンツコンポーネントの前記レンダリングが、前記エンドポイントデバイスにおいて前記UIコントロールコンポーネントのレンダリングとマージされて前記複合UIになることになり、前記複合UIが第2の解像度を有する、
非一時的コンピュータ可読記憶媒体。 A non-temporary computer-readable storage medium that stores instructions that cause the processing device to perform an operation when executed by the processing device.
Receiving a user request on the server for a media item to be presented via a composite UI that includes one or more video content components and one or more user interface (UI) control components.
Generating the rendering of the video content component and
Containing the transmission of a first stream containing said rendering of the video content component to the endpoint device, the first stream is encoded to a first resolution and the rendering of said video content component is said to be said. In the endpoint device, the rendering of the UI control component will be merged into the composite UI, which has a second resolution.
Non-temporary computer-readable storage medium.
前記UIコントロールコンポーネントの前記レンダリングを生成するためのコマンドのセットを前記サーバにおいて実行することと、
前記UIコントロールコンポーネントの前記レンダリングを含む第2のストリームを前記エンドポイントデバイスへ送信することと
をさらに含み、前記第2のストリームが前記第2の解像度に符号化される、
請求項15に記載の非一時的コンピュータ可読記憶媒体。 The above operation
To execute the set of commands to generate the rendering of the UI control component on the server.
Further including sending a second stream containing the rendering of the UI control component to the endpoint device, the second stream is encoded to the second resolution.
The non-temporary computer-readable storage medium of claim 15.
前記UIコントロールコンポーネントのレンダリングを前記サーバにおいて生成すべきかそれとも前記エンドポイントデバイスにおいて生成すべきかを決定することと、
前記UIコントロールコンポーネントの前記レンダリングを前記エンドポイントデバイスにおいて生成すべきという決定に応答して、前記UIコントロールコンポーネントをレンダリングするためのコマンドのセットを、ネットワークを介して前記エンドポイントデバイスへ送信することであって、前記UIコントロールコンポーネントの前記レンダリングが前記第1の解像度または前記第2の解像度を有する、送信することと、
前記UIコントロールコンポーネントの前記レンダリングを前記サーバにおいて生成すべきという決定に応答して、
前記UIコントロールコンポーネントの前記レンダリングを生成するために、前記UIコントロールコンポーネントをレンダリングするためのコマンドの前記セットを前記サーバにおいて実行し、
前記UIコントロールコンポーネントの前記レンダリングを含む第2のストリームを前記エンドポイントデバイスへ送信することと
をさらに含む、
請求項15に記載の非一時的コンピュータ可読記憶媒体。 The above operation
Determining whether the rendering of the UI control component should be generated on the server or on the endpoint device.
By sending a set of commands for rendering the UI control component to the endpoint device over the network in response to the decision that the rendering of the UI control component should be generated on the endpoint device. And that the rendering of the UI control component has said first resolution or said second resolution, and
In response to the decision that the rendering of the UI control component should be generated on the server
To generate the rendering of the UI control component, execute the set of commands for rendering the UI control component on the server.
Further comprising sending a second stream containing the rendering of the UI control component to the endpoint device.
The non-temporary computer-readable storage medium of claim 15.
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
PCT/US2019/019440 WO2020176070A1 (en) | 2019-02-25 | 2019-02-25 | Variable end-point user interface rendering |
Publications (2)
Publication Number | Publication Date |
---|---|
JP2022521960A true JP2022521960A (en) | 2022-04-13 |
JP7179194B2 JP7179194B2 (en) | 2022-11-28 |
Family
ID=65724564
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2021549677A Active JP7179194B2 (en) | 2019-02-25 | 2019-02-25 | Variable endpoint user interface rendering |
Country Status (6)
Country | Link |
---|---|
US (1) | US20220134227A1 (en) |
EP (1) | EP3918807A1 (en) |
JP (1) | JP7179194B2 (en) |
KR (2) | KR102571776B1 (en) |
CN (1) | CN113455008B (en) |
WO (1) | WO2020176070A1 (en) |
Families Citing this family (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN112604277B (en) * | 2020-12-29 | 2021-08-31 | 广州银汉科技有限公司 | GUI quick repeated engraving production method based on mobile phone game |
KR102369891B1 (en) | 2021-09-24 | 2022-03-02 | 김상우 | Snowboard deck |
Citations (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20130204927A1 (en) * | 2012-02-08 | 2013-08-08 | Vmware, Inc. | Video stream management for remote graphical user interfaces |
EP2713625A1 (en) * | 2012-09-28 | 2014-04-02 | Orange | Method and system for providing multimedia content, corresponding virtual machine, servers, communication terminal and computer program |
US20140289627A1 (en) * | 2013-03-15 | 2014-09-25 | Activevideo Networks, Inc. | Multiple-Mode System and Method for Providing User Selectable Video Content |
JP2016530778A (en) * | 2013-07-17 | 2016-09-29 | ヴィジブル ワールド インコーポレイテッド | System and method for content presentation management |
JP2018514013A (en) * | 2015-03-06 | 2018-05-31 | ソニー インタラクティブ エンタテインメント アメリカ リミテッド ライアビリテイ カンパニー | Dynamic adjustment of cloud game data stream and network characteristics to output devices |
JP2018533288A (en) * | 2015-09-23 | 2018-11-08 | ロヴィ ガイズ， インコーポレイテッド | System and method for detecting events in a program from multiple channels |
Family Cites Families (23)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
KR20020064888A (en) * | 1999-10-22 | 2002-08-10 | 액티브스카이 인코포레이티드 | An object oriented video system |
US6577311B1 (en) * | 1999-12-16 | 2003-06-10 | Picture Iq Corporation | Techniques for automatically providing a high-resolution rendering of a low resolution digital image in a distributed network |
US7522664B1 (en) * | 2003-09-10 | 2009-04-21 | Krishnamurthy Bhaskar | Remote live video inspection |
EP1929405A4 (en) * | 2006-01-13 | 2009-09-16 | Yahoo Inc | Method and system for recording edits to media content |
US8506402B2 (en) * | 2009-06-01 | 2013-08-13 | Sony Computer Entertainment America Llc | Game execution environments |
US20120110628A1 (en) * | 2010-10-27 | 2012-05-03 | Candelore Brant L | Storage of Adaptive Streamed Content |
US9013510B2 (en) * | 2011-07-29 | 2015-04-21 | Google Inc. | Systems and methods for rendering user interface elements in accordance with a device type |
GB2496015B (en) * | 2012-09-05 | 2013-09-11 | Imagination Tech Ltd | Pixel buffering |
US9717982B2 (en) * | 2012-12-21 | 2017-08-01 | Microsoft Technology Licensing, Llc | Client rendering of latency sensitive game features |
CA2917719C (en) * | 2013-07-11 | 2021-12-14 | Dejero Labs Inc. | Systems and methods for transmission of data streams |
US20150181152A1 (en) * | 2013-12-20 | 2015-06-25 | Skylight Healthcare Corporation | Systems, devices and methods for interactive and bidirectional message overlay on a communications signal |
US11537777B2 (en) * | 2014-09-25 | 2022-12-27 | Huawei Technologies Co., Ltd. | Server for providing a graphical user interface to a client and a client |
US20160182594A1 (en) * | 2014-12-19 | 2016-06-23 | Cable Television Laboratories, Inc. | Adaptive streaming |
US9538139B2 (en) * | 2015-04-24 | 2017-01-03 | Avaya Inc. | Multi-stream video switching with selective optimized composite |
US11388455B2 (en) * | 2016-06-02 | 2022-07-12 | Multimo, Llc | Method and apparatus for morphing multiple video streams into single video stream |
US9736442B1 (en) * | 2016-08-29 | 2017-08-15 | Christie Digital Systems Usa, Inc. | Device, system and method for content-adaptive resolution-enhancement |
US10311548B2 (en) * | 2017-09-05 | 2019-06-04 | Microsoft Technology Licensing, Llc | Scaling render targets to a higher rendering resolution to display higher quality video frames |
US11014010B2 (en) * | 2017-10-20 | 2021-05-25 | Microsoft Technology Licensing, Llc | State management of dynamic properties |
US20230262234A1 (en) * | 2018-02-20 | 2023-08-17 | Arlo Technologies, Inc. | Transcoding in security camera camera applications |
US11012694B2 (en) * | 2018-05-01 | 2021-05-18 | Nvidia Corporation | Dynamically shifting video rendering tasks between a server and a client |
US11612812B1 (en) * | 2021-06-29 | 2023-03-28 | Amazon Technologies, Inc. | Video game streaming with dynamic range conversion |
US11617946B1 (en) * | 2021-06-29 | 2023-04-04 | Amazon Technologies, Inc. | Video game streaming with dynamic range conversion |
WO2023060056A2 (en) * | 2021-10-08 | 2023-04-13 | Objectvideo Labs, Llc | Spatial motion attention for intelligent video analytics |
-
2019
- 2019-02-25 WO PCT/US2019/019440 patent/WO2020176070A1/en unknown
- 2019-02-25 JP JP2021549677A patent/JP7179194B2/en active Active
- 2019-02-25 US US17/433,973 patent/US20220134227A1/en active Pending
- 2019-02-25 KR KR1020217030285A patent/KR102571776B1/en active IP Right Grant
- 2019-02-25 CN CN201980092552.0A patent/CN113455008B/en active Active
- 2019-02-25 KR KR1020237028725A patent/KR20230128408A/en not_active Application Discontinuation
- 2019-02-25 EP EP19710246.0A patent/EP3918807A1/en active Pending
Patent Citations (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20130204927A1 (en) * | 2012-02-08 | 2013-08-08 | Vmware, Inc. | Video stream management for remote graphical user interfaces |
EP2713625A1 (en) * | 2012-09-28 | 2014-04-02 | Orange | Method and system for providing multimedia content, corresponding virtual machine, servers, communication terminal and computer program |
US20140289627A1 (en) * | 2013-03-15 | 2014-09-25 | Activevideo Networks, Inc. | Multiple-Mode System and Method for Providing User Selectable Video Content |
JP2016530778A (en) * | 2013-07-17 | 2016-09-29 | ヴィジブル ワールド インコーポレイテッド | System and method for content presentation management |
JP2018514013A (en) * | 2015-03-06 | 2018-05-31 | ソニー インタラクティブ エンタテインメント アメリカ リミテッド ライアビリテイ カンパニー | Dynamic adjustment of cloud game data stream and network characteristics to output devices |
JP2018533288A (en) * | 2015-09-23 | 2018-11-08 | ロヴィ ガイズ， インコーポレイテッド | System and method for detecting events in a program from multiple channels |
Non-Patent Citations (1)
Title |
---|
IVAN SLIVAR; ZVONIMIR DRAGOZET; LEA SKORIN-KAPOV: "User customization of the GamingAnywhere Android mobile client interface", 2015 INTERNATIONAL WORKSHOP ON NETWORK AND SYSTEMS SUPPORT FOR GAMES (NETGAMES), JPN6022043215, 3 December 2015 (2015-12-03), US, ISSN: 0004896818 * |
Also Published As
Publication number | Publication date |
---|---|
KR20210126753A (en) | 2021-10-20 |
CN113455008B (en) | 2024-04-09 |
KR102571776B1 (en) | 2023-08-29 |
CN113455008A (en) | 2021-09-28 |
US20220134227A1 (en) | 2022-05-05 |
KR20230128408A (en) | 2023-09-04 |
EP3918807A1 (en) | 2021-12-08 |
JP7179194B2 (en) | 2022-11-28 |
WO2020176070A1 (en) | 2020-09-03 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US20200162413A1 (en) | Low-friction, instant, private, personalized video sharing widget | |
JP7230158B2 (en) | Dynamic custom interstitial transition video for video streaming services | |
US10567829B2 (en) | Dynamically adjustable electronic program guide | |
AU2015259748B2 (en) | Soliciting and creating collaborative content items | |
JP2018125891A (en) | Background processing for media application | |
US20190018572A1 (en) | Content item players with voice-over on top of existing media functionality | |
JP2024056704A (en) | Dynamic integration of customized supplemental media content | |
JP7179194B2 (en) | Variable endpoint user interface rendering | |
CN109565616B (en) | Interactive video multi-screen experience on mobile phones | |
US20160371737A1 (en) | Personalized and contextual notifications of content releases | |
US10924441B1 (en) | Dynamically generating video context | |
US10333871B1 (en) | Logged-out conversation invitations | |
US10127312B1 (en) | Mutable list resilient index for canonical addresses of variable playlists | |
KR20240064003A (en) | Dynamic integration of customized supplemental media content |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
A529 | Written submission of copy of amendment under article 34 pct |
Free format text: JAPANESE INTERMEDIATE CODE: A529Effective date: 20211013 |
|
A621 | Written request for application examination |
Free format text: JAPANESE INTERMEDIATE CODE: A621Effective date: 20211013 |
|
A977 | Report on retrieval |
Free format text: JAPANESE INTERMEDIATE CODE: A971007Effective date: 20220929 |
|
TRDD | Decision of grant or rejection written | ||
A01 | Written decision to grant a patent or to grant a registration (utility model) |
Free format text: JAPANESE INTERMEDIATE CODE: A01Effective date: 20221017 |
|
A61 | First payment of annual fees (during grant procedure) |
Free format text: JAPANESE INTERMEDIATE CODE: A61Effective date: 20221115 |
|
R150 | Certificate of patent or registration of utility model |
Ref document number: 7179194Country of ref document: JPFree format text: JAPANESE INTERMEDIATE CODE: R150 |