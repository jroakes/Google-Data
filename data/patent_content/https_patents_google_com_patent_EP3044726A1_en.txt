EP3044726A1 - Landmark identification from point cloud generated from geographic imagery data - Google Patents
Landmark identification from point cloud generated from geographic imagery dataInfo
- Publication number
- EP3044726A1 EP3044726A1 EP14758748.9A EP14758748A EP3044726A1 EP 3044726 A1 EP3044726 A1 EP 3044726A1 EP 14758748 A EP14758748 A EP 14758748A EP 3044726 A1 EP3044726 A1 EP 3044726A1
- Authority
- EP
- European Patent Office
- Prior art keywords
- data points
- data
- geographic
- landmark
- subset
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
- 238000000034 method Methods 0.000 claims abstract description 52
- 238000001914 filtration Methods 0.000 claims description 4
- 238000009877 rendering Methods 0.000 claims description 3
- 238000010276 construction Methods 0.000 claims description 2
- 238000012545 processing Methods 0.000 description 8
- 238000004891 communication Methods 0.000 description 4
- 238000010586 diagram Methods 0.000 description 4
- 238000013507 mapping Methods 0.000 description 4
- 238000012986 modification Methods 0.000 description 3
- 230000004048 modification Effects 0.000 description 3
- 238000001514 detection method Methods 0.000 description 2
- 238000005516 engineering process Methods 0.000 description 2
- 230000008569 process Effects 0.000 description 2
- 238000007619 statistical method Methods 0.000 description 2
- 230000000007 visual effect Effects 0.000 description 2
- 238000007792 addition Methods 0.000 description 1
- 230000004075 alteration Effects 0.000 description 1
- 238000004590 computer program Methods 0.000 description 1
- 230000001276 controlling effect Effects 0.000 description 1
- 230000002596 correlated effect Effects 0.000 description 1
- 238000013479 data entry Methods 0.000 description 1
- 238000011161 development Methods 0.000 description 1
- 230000000694 effects Effects 0.000 description 1
- 230000006870 function Effects 0.000 description 1
- 230000002452 interceptive effect Effects 0.000 description 1
- 230000003287 optical effect Effects 0.000 description 1
- 238000005096 rolling process Methods 0.000 description 1
Classifications
-
- G—PHYSICS
- G01—MEASURING; TESTING
- G01V—GEOPHYSICS; GRAVITATIONAL MEASUREMENTS; DETECTING MASSES OR OBJECTS; TAGS
- G01V11/00—Prospecting or detecting by methods combining techniques covered by two or more of main groups G01V1/00 - G01V9/00
-
- G—PHYSICS
- G01—MEASURING; TESTING
- G01C—MEASURING DISTANCES, LEVELS OR BEARINGS; SURVEYING; NAVIGATION; GYROSCOPIC INSTRUMENTS; PHOTOGRAMMETRY OR VIDEOGRAMMETRY
- G01C21/00—Navigation; Navigational instruments not provided for in groups G01C1/00 - G01C19/00
- G01C21/26—Navigation; Navigational instruments not provided for in groups G01C1/00 - G01C19/00 specially adapted for navigation in a road network
- G01C21/34—Route searching; Route guidance
- G01C21/36—Input/output arrangements for on-board computers
- G01C21/3626—Details of the output of route guidance instructions
- G01C21/3644—Landmark guidance, e.g. using POIs or conspicuous other objects
-
- G—PHYSICS
- G01—MEASURING; TESTING
- G01C—MEASURING DISTANCES, LEVELS OR BEARINGS; SURVEYING; NAVIGATION; GYROSCOPIC INSTRUMENTS; PHOTOGRAMMETRY OR VIDEOGRAMMETRY
- G01C21/00—Navigation; Navigational instruments not provided for in groups G01C1/00 - G01C19/00
- G01C21/005—Navigation; Navigational instruments not provided for in groups G01C1/00 - G01C19/00 with correlation of navigation data from several sources, e.g. map or contour matching
-
- G—PHYSICS
- G01—MEASURING; TESTING
- G01C—MEASURING DISTANCES, LEVELS OR BEARINGS; SURVEYING; NAVIGATION; GYROSCOPIC INSTRUMENTS; PHOTOGRAMMETRY OR VIDEOGRAMMETRY
- G01C21/00—Navigation; Navigational instruments not provided for in groups G01C1/00 - G01C19/00
- G01C21/26—Navigation; Navigational instruments not provided for in groups G01C1/00 - G01C19/00 specially adapted for navigation in a road network
- G01C21/34—Route searching; Route guidance
- G01C21/36—Input/output arrangements for on-board computers
- G01C21/3691—Retrieval, searching and output of information related to real-time traffic, weather, or environmental conditions
- G01C21/3694—Output thereof on a road map
-
- G—PHYSICS
- G01—MEASURING; TESTING
- G01C—MEASURING DISTANCES, LEVELS OR BEARINGS; SURVEYING; NAVIGATION; GYROSCOPIC INSTRUMENTS; PHOTOGRAMMETRY OR VIDEOGRAMMETRY
- G01C21/00—Navigation; Navigational instruments not provided for in groups G01C1/00 - G01C19/00
- G01C21/38—Electronic maps specially adapted for navigation; Updating thereof
- G01C21/3804—Creation or updating of map data
- G01C21/3807—Creation or updating of map data characterised by the type of data
- G01C21/3811—Point data, e.g. Point of Interest [POI]
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F17/00—Digital computing or data processing equipment or methods, specially adapted for specific functions
- G06F17/40—Data acquisition and logging
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T17/00—Three dimensional [3D] modelling, e.g. data description of 3D objects
- G06T17/05—Geographic models
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T7/00—Image analysis
- G06T7/70—Determining position or orientation of objects or cameras
- G06T7/73—Determining position or orientation of objects or cameras using feature-based methods
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V20/00—Scenes; Scene-specific elements
- G06V20/10—Terrestrial scenes
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V20/00—Scenes; Scene-specific elements
- G06V20/20—Scenes; Scene-specific elements in augmented reality scenes
-
- G—PHYSICS
- G01—MEASURING; TESTING
- G01D—MEASURING NOT SPECIALLY ADAPTED FOR A SPECIFIC VARIABLE; ARRANGEMENTS FOR MEASURING TWO OR MORE VARIABLES NOT COVERED IN A SINGLE OTHER SUBCLASS; TARIFF METERING APPARATUS; MEASURING OR TESTING NOT OTHERWISE PROVIDED FOR
- G01D21/00—Measuring or testing not otherwise provided for
-
- G—PHYSICS
- G16—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR SPECIFIC APPLICATION FIELDS
- G16Z—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR SPECIFIC APPLICATION FIELDS, NOT OTHERWISE PROVIDED FOR
- G16Z99/00—Subject matter not provided for in other main groups of this subclass
Definitions
- the present disclosure relates generally to geographic information systems, and more particularly to identifying prominent landmarks from geographic imagery data.
- Geographic information systems provide for the archiving, retrieving, and manipulating of data that has been stored and indexed according to geographic coordinates of its elements.
- a geographic information system generally includes a variety of data types, including imagery, maps, tables, vector data (e.g. vector representations of roads, parcels, buildings, etc.), three-dimensional models and other data. Improvements in computer processing power and broadband technology have led to the development of interactive geographic information systems that allow for the navigating and displaying of geographic imagery, such as map imagery, satellite imagery, aerial imagery, street level imagery, three- dimensional models, and other geographic imagery.
- the identification of prominent landmarks in geographic information systems can be used for a variety of purposes. For instance, prominent or highly visible landmarks can be identified for use in providing travel directions. As another example, vector-style maps can use the visual prominence of a landmark to determine whether to render certain landmarks in an emphasized style relative to other landmarks. As yet another example, visual prominence of structures can also be used to identify landmarks that merit the creation of a three- dimensional model representing the landmark in the geographic information system.
- One example aspect of the present disclosure is directed to a computer- implemented method implemented by one or more computing devices for identifying prominent landmarks in a geographic area.
- the method includes accessing, by the one or more computing devices, geographic imagery data captured from one or more cameras from a perspective at or near ground level and generating, by the one or more computing devices, a point cloud based at least in part on the geographic imagery data.
- the point cloud includes a plurality of data points. Each of the plurality of data points is associated with a tracked feature in the geographic imagery data.
- the method further includes identifying, by the one or more computing devices, a subset of data points in the point cloud. Each data point in the subset is located at least a threshold distance away from one or more camera perspectives associated with the geographic imagery data.
- the method further includes matching, by the one or more computing devices, one or more data points in the subset with a landmark.
- FIG. 1 depicts a geographic information system according to an embodiment of the present disclosure
- FIG. 2 depicts a flow diagram of a method for identifying prominent landmarks according to an embodiment of the present disclosure
- FIG. 3 depicts geographic imagery data captured from a perspective at or near ground level according to an embodiment of the present disclosure
- FIG. 4 depicts a point cloud generated from geographic imagery data according to an embodiment of the present disclosure
- FIG. 5 depicts a representation of the identification of a subset of data points in a point cloud that are located at least a threshold distance from a camera perspective according to an embodiment of the present disclosure
- FIG. 6 depicts clustering of data points into point clusters according to an embodiment of the present disclosure
- FIG. 7 depicts a flow diagram of a method for prioritizing prominent landmarks according to an embodiment of the present disclosure
- FIG. 8 depicts a two-dimensional representation of a viewshed according to an embodiment of the present disclosure
- FIG. 9 depicts a user interface providing travel directions based at least in part on an identified landmark according to an embodiment of the present disclosure.
- FIG. 10 depicts a computing environment for identifying prominent landmarks according to an embodiment of the present disclosure.
- example aspects of the present disclosure are directed to systems and methods for identifying prominent landmarks in a geographic area. More particularly, geographic imagery data, such as geographic images captured by a camera from a perspective at or near ground level, can be analyzed to identify prominent landmarks depicted in the geographic imagery data. Landmarks that are visible from multiple camera perspectives and that are visible from greater distances relative to one or more camera perspectives can be identified as prominent landmarks in a geographic area.
- a geographic information system can use the prominent landmarks for a variety of purposes, such as for use in providing travel directions, for rendering landmarks in an emphasized style, and/or for constructing or displaying a three-dimensional model of the landmark.
- the geographic imagery data can be processed to identify a point cloud of features depicted in the geographic imagery data.
- a structure-from-motion technique is used to generate the point cloud.
- the structure-from-motion technique tracks features depicted in the geographic imagery from multiple different camera perspectives and determines the position (e.g. a geographic position) of the tracked features relative to a reference.
- the point cloud can include a plurality of data points. Each data point can include position information (e.g. latitude, longitude, altitude coordinates, distance to a camera, etc.) and a color or pixel value for the data point.
- the generation of the point cloud depends on tracked feature points being visible from multiple perspectives.
- the identified features in the point cloud are therefore distinctive enough to stand out from multiple perspectives.
- the point cloud can be filtered to identify a subset of data points in the point cloud that are located a threshold distance (e.g. 0.5 km to 2 km) away from one or more camera perspectives associated with the geographic imagery data.
- a threshold distance e.g. 0.5 km to 2 km
- each of the data points in the subset can be a threshold distance from a camera perspective associated with one of the images/views in the geographic imagery data.
- the data points in the subset can be matched with known landmarks and other points of interest.
- the position information associated with the data points can be correlated with position information for known landmarks and other points of interest to match the data points with the landmarks.
- a rudimentary clustering of the data points into point clusters can be performed to facilitate matching of the data points to landmarks and other points of interest.
- the landmarks and other points of interest matched with the data points in the subset can be identified as prominent landmarks in the geographic area.
- Identifying features using geographic imagery data that includes images captured by a camera from a perspective at or near ground level can focus on landmarks that are typically visible to individuals as they navigate or otherwise view a particular geographic area.
- landmarks identified from geographic imagery data can be biased towards points that are more distant from a camera perspective and therefore observable by individuals for a longer time.
- the points are distinctive enough to register between nearby view
- the identified landmarks can be suitable for many applications in a geographic information system.
- the identified landmarks can be useful in providing travel directions to a user.
- a score can be determined for the identified landmarks based on the visibility of the identified landmarks.
- the score can be used to prioritize the landmarks in the geographic information system.
- a viewshed can be determined for one or more of the data points or point clusters in the subset.
- the viewshed for a data point in the subset can be the set of points from which the particular data point or point cluster is visible.
- the viewshed can include the set of camera perspectives associated with the geographic imagery data that view the data point or point cluster.
- Statistical analysis can be performed on the viewshed to determine a score for a landmark matched with the data point.
- the score for the landmark can be determined based at least in part on other suitable factors, such as a landmark ranking for the landmark in a geographic information system. In this way, the score can distinguish between highly visible famous landmarks (e.g. a stadium) from other highly visible landmarks (e.g. a radio tower).
- FIG. 1 depicts a geographic information system 100 according to an embodiment of the present disclosure.
- the geographic information system 100 can provide for the archiving, retrieving, and manipulation of geospatial data that has been indexed and stored according to geographic coordinates, such as latitude, longitude, and altitude coordinates, associated with the geospatial data.
- the system 100 can combine satellite imagery, photographs, maps, three-dimensional models, vector data and other geographic data, and search capability so as to enable a user to view imagery of a geographic area and related geographic information (e.g., locales such as islands and cities; and points of interest such as local restaurants, hospitals, parks, hotels, and schools).
- the system further allows the user to conduct local searches and to get travel directions to a location or between two or more locations.
- Results can be displayed in a two-dimensional (2D), two-and-half dimensional (2.5D), or three-dimensional (3D) representation of the area of interest.
- the user can pan, tilt, zoom, and rotate the view to navigate a representation of the area of
- the geographic information system 100 can include a client- server architecture, where the server system 110 communicates with one or more clients 130 via a network 140.
- the network 140 can include any suitable combination of wired or wireless networks, such as the Internet. Although two clients 130 are illustrated in FIG. 1, any number of clients 130 can be connected to the server system 110 over the network 140.
- the present disclosure is discussed with reference to a client-server architecture, the inherent flexibility of computer-based systems allows for a great variety of possible configurations, combinations, and divisions of tasks and functionality between and among the components of the system 100. For instance, the systems and methods discussed herein can be implemented using a single computing device or across multiple computing devices in a parallel or distributed computing system.
- the server system 110 can include one or more computing devices that can include one or more processors and memory.
- the memory can store computer-readable instructions that when executed cause the one or more processers to perform operations.
- the server system 110 can include or can be in communication with one or more databases 125.
- the one or more databases 125 can store geospatial data to be served or provided to the client 130 over the network 140.
- the one or more databases 125 can include image data (e.g.
- the one or more databases 125 can also store information relative to prominent landmarks (e.g. scores and other data) identified according to example aspects of the present disclosure.
- Geospatial data can be stored in one or more databases 125 or in some other storage facility accessible to server system 110.
- the server system 110 can be configured to receive requests for geographic information, and respond to those requests, via the network 140.
- the server system 110 encodes the geographic information in one or more data files and provides the files to the requestor.
- the server system 110 can implement a landmark identification module 120.
- the landmark identification module 120 can be configured to analyze geographic imagery data to identify prominent landmarks according to example aspects of the present disclosure. Information associated with the prominent landmarks can be used for a variety of purposes, such as for prioritizing landmarks, for providing travel directions, for selecting landmarks for construction of a three-dimensional model, and/or for other purposes.
- the client 130 can include one or more computing devices, such as a desktop, laptop, personal digital assistant (PDA), smartphone, tablet, a navigation system, a handheld GPS system, a wearable computing device, a display coupled to one or more processors, or other suitable computing device.
- the client 130 can include one or more processors and memory.
- the memory can store computer-readable instructions that when executed cause the one or more processors to perform operations.
- the client 130 can implement a mapping application 132 that allows a user to interact with the geographic information system 100.
- the mapping application 132 can allow a user to request maps or other geographic imagery, request travel directions, navigate geographic imagery, perform data searches and/or perform other functions.
- the mapping application 132 can implement or can be implemented in
- modules and components may be included in the system 100 and that illustrated system components may be rearranged.
- the one or more databases 125 can be integrated into the server system 110.
- Other configurations will be apparent in light of this disclosure, and the present disclosure is not intended to be limited to any particular one. Any number of modules can be programmed or otherwise configured to carry out the functionality described herein.
- FIG. 2 depicts a flow diagram of a computer-implemented method (200) for identification of landmarks according to an embodiment of the present disclosure.
- the method (200) can be implemented by one or more computing devices, such as one or more of the computing devices depicted in FIG. 10.
- FIG. 2 depicts steps performed in a particular order for purposes of illustration and discussion. Those of ordinary skill in the art, using the disclosures provided herein, will understand that various steps of any of the methods discussed in the present disclosure can be omitted, rearranged, combined and/or adapted in various ways.
- the method includes accessing geographic imagery data.
- geographic imagery data stored in one or more computer-readable media can be accessed.
- the geographic imagery data can include images of one or more geographic areas of interest from a variety of different camera perspectives.
- a camera perspective refers to a location of a camera that captures the imagery.
- the geographic imagery data can include images of a geographic area captured by a camera from camera perspectives at or near ground level (e.g. within 20 feet of the ground level), such as street level imagery.
- ground level imagery e.g. within 20 feet of the ground level
- the images can depict non-street areas such as trails and building interiors.
- the geographic imagery data can be captured using any suitable image capture device.
- street level imagery can be captured by a digital camera mounted on top of a vehicle, from a camera angle pointing roughly parallel to the ground, and/or from a camera position at or below the legal limit for vehicle heights (e.g. 7-14 feet).
- Panoramic street level imagery can be created by stitching together the plurality of images taken from different camera perspectives.
- the geographic imagery data can be captured using a rolling shutter technique.
- the geographic imagery data can be stored in one or more computer-readable media as a set of pixels associated with color and brightness values.
- FIG. 3 depicts example geographic imagery data 300 captured by one or more cameras from a perspective at or near ground level that can be accessed according to an embodiment of the present disclosure.
- the geographic imagery data 300 includes a portion of a panoramic image of a geographic area from a single camera perspective.
- the geographic imagery data 300 can include different views of the geographic area (not illustrated) from one or more other camera perspectives.
- the geographic imagery data 300 can depict various landmarks and other points of interest that are visible from a particular camera perspective.
- the geographic imagery data 300 can depict landmark 305, which is visible from the particular camera perspective associated with the geographic imagery data 300.
- the accessed geographic imagery data can include representations of a geographic area from many different camera perspectives.
- the geographic imagery data can include a plurality of different street level images captured from different camera
- different features in the geographic imagery data can be depicted at different locations relative to the different camera perspectives.
- the tracking of these features in the geographic imagery data can be used to identify position information for the features. As will be discussed in more detail below, this position information can be used to identify prominent landmarks in a geographic area.
- the geographic imagery data can be processed to generate a point cloud.
- the point cloud can include a plurality of data points. Each data point can correspond to a tracked feature in the geographic imagery data. Each data point can provide a three-dimensional position of the feature as well as a color or other pixel value associated with the tracked feature.
- a structure-from-motion technique can be used to generate the point cloud.
- the structure-from-motion technique can identify a plurality of features (e.g. building corners with high image gradients) using a suitable feature detection image processing technique.
- the feature detection image processing technique can identify features associated with high image gradients (e.g. in terms of color and/or brightness) in the geographic imagery data.
- the detected features can be tracked across many different camera perspectives in the geographic imagery data.
- the three- dimensional position relative to some reference of the features can be determined. For instance the latitude, longitude, and altitude of the features and/or distance to the camera perspective can be determined from the geographic imagery data.
- the three-dimensional position information can be used to generate the point cloud of data points.
- the camera pose (e.g. position and orientation) of the geographic imagery data for the multiple different camera perspectives can also be determined using structure-from-motion techniques.
- FIG. 4 depicts an example point cloud 310 that can be generated from the geographic imagery data 300 of FIG. 3.
- the point cloud 310 of FIG. 4 includes a plurality of data points associated with different three-dimensional positions in the geographic area depicted in the geographic imagery data 300.
- Each data point corresponds to a feature tracked in the geographic imagery data.
- data point 312 can correspond to a feature tracked across multiple different camera perspectives in the geographic imagery data.
- the data points in the point cloud 310 can be representative of distinctive features visible from multiple different camera perspective in the geographic imagery data.
- a subset of the data points in the point cloud can be identified.
- Each of the data points in the subset can be located a threshold distance away from one or more camera perspectives in the geographic imagery data. For instance, the distance of each data point to one or more camera perspectives that view the data point can be determined. The data point can be selected for inclusion in the subset if one or more of these distances is greater than the threshold distance.
- the threshold distance can be set to any suitable value. For instance, in a particular embodiment, the threshold distance can be in the range of 0.5 km to 2 km.
- FIG. 5 depicts a representation of an example identification of a subset of data points in a point cloud that are located a threshold distance from a camera perspective according to an embodiment of the present disclosure.
- structure-from- techniques can be used to generate a point cloud 330 from geographic imagery data.
- the geographic imagery data can include imagery captured from a camera perspective 338.
- the point cloud 330 includes data points 332 that are within a threshold distance 335 of the camera perspective 338 and data points 334 that are located greater than the threshold distance 335 from the camera perspective.
- the data points 334 can be identified for inclusion in the subset. Certain of the data points 332 may be located greater than a threshold distance from a different camera perspective (not illustrated). Such data points can also be identified for inclusion in the subset. Data points that are not located greater than a threshold distance from any camera perspective can be excluded from the subset.
- the data points can be required to be located at least a threshold distance from multiple camera perspectives to be included in the subset.
- the data points can be required to be viewed from a variety of different view angles to be included in the subset.
- statistical analysis of viewsheds associated with the data points can be performed to determine whether to include the data points in the subset.
- the viewshed of a data point includes the set of points in the geographic area that view the data point. An example viewshed associated with a data point will be discussed in more detail below with reference to FIG. 8.
- the method can optionally include clustering of the data points in the subset into one or more point clusters as shown at (208) of FIG. 2. Any suitable clustering technique can be used to cluster the data points. For instance, data points located spatially adjacent to one another and having similar pixel values can be clustered into a point cluster.
- FIG. 6 depicts a subset of data points 340 that have been clustered into point clusters 342, 344, and 346. The clustering of the data points into point clusters can facilitate matching of the data points in the subset with landmarks.
- the method includes matching one or more of the data points in the subset (or point clusters if clustering of the data points is performed) with known landmarks in the geographic area.
- the known landmarks can be determined from a database of landmarks and other points of interest in a particular geographic area.
- the database can include information associated with the landmarks and other points of interest, such as geographic position of the landmarks, appearance of the landmarks, size of the landmarks, historical information, and other information.
- the one or more data points in the subset can be matched to the landmarks based at least in part on the information in the database. For instance, the position of a data point or point cluster in the subset can be determined to correspond with the position of a particular landmark as specified in the database.
- the data point can be matched to the landmark sharing the same or similar position.
- FIG. 6 depicts a point cluster 344 having a plurality of data points. Each of these data points can be associated with geographic position information. This geographic position information can be compared to the known geographic positions of landmarks in the geographic area as specified, for instance, in a database.
- the landmark 305 depicted in FIG. 3 can be associated with a geographic position that corresponds to the geographic positions of one or more of the data points in the point cluster 344 of FIG. 6.
- the point cluster 344 including its data points, can be matched with the landmark 305 depicted in FIG. 3.
- Other suitable techniques can be used to match the data points with landmarks without deviating from the scope of the present disclosure.
- the landmarks matched with the one or more data points in the subset can be identified as prominent landmarks in a geographic information system as shown at (212) of FIG. 2.
- the identified prominent landmarks can then be used by a geographic information system for a variety of purposes as will be discussed in further detail below.
- An example aspect of the present disclosure is directed to prioritizing prominent landmarks in a geographic information system. It can be desirable to downselect and/or further refine the set of identified prominent landmarks to identify the most prominently visible landmarks in a geographic area. According to aspects of the present disclosure, a score can be computed for the prominent landmarks based on their visibility and other factors. The landmarks can be prioritized relative to other landmarks in the geographic information system based on the scores.
- FIG. 7 depicts a flow diagram of a computer-implemented method (400) for prioritizing landmarks according to an embodiment of the present disclosure.
- the method (400) can be implemented by one or more computing devices, such as one or more of the computing devices depicted in FIG. 10.
- the method can include identifying prominent landmarks. For instance, prominent landmarks can be identified using the computer-implemented method (200) depicted in FIG. 2.
- a point cloud can be generated from geographic imagery data and landmarks can be matched to particular data points in the point cloud.
- a viewshed is determined for a data point in the point cloud.
- the viewshed of a data point can be a set of points in the geographic area that can view the data point.
- the viewshed can be approximated as the set of camera perspectives associated with the geographic imagery data that view the data point. In this way, the computation of the viewshed can be comparatively cheap when compared to determining viewsheds based on a full three-dimensional determination of visibility.
- FIG. 8 depicts a two-dimensional representation of a viewshed 420 for a data point 410 according to an example embodiment of the present disclosure.
- viewshed 420 can be the set of points in a geographic area that view the data point 410.
- the viewshed 420 can be approximated as the set of camera perspectives 422 associated with the geographic imagery data that view the data point 410.
- a score for a landmark matched to the data point is determined based at least in part on the viewshed.
- Statistics can be calculated with regard to the set of camera perspectives in the viewshed to assess the visibility of the landmark. For instance, the score can be determined based on the number of camera perspectives that view the data point.
- geometric properties of the viewshed e.g. area, distance of data point from centroid, etc. can be used to determine the score for the landmark.
- the score for the landmark can be determined based at least in part on other factors associated with the landmark in the geographic information system.
- the geographic information system can establish a landmark ranking independent of the visibility of the landmark to determine display priority and for other purposes in the geographic information system.
- This landmark ranking can be based on factors such as size, historical data, popularity, relevance to search queries, etc.
- the landmark ranking can be used to determine the score for the identified prominent landmarks. In this way, famous highly visible landmarks can receive higher scores than less-famous but highly visible landmarks.
- the landmarks can be prioritized in the geographic information system based at least in part on the scores. For instance, the landmark rankings of landmarks in the geographic information system can be adjusted to favor landmarks with higher scores. In this way, the scores associated with the identified landmarks can enrich the data associated with the geographic information system.
- the landmarks identified according to example aspects of the present disclosure can be used by a geographic information system for a variety of purposes.
- the prominent landmarks can be used in conjunction with providing travel directions.
- the geographic information system can refer to a particular prominent landmark when providing travel directions a user. Because the prominent landmarks can be identified based on data points that are visible from multiple different perspectives and from greater distances, the prominent landmarks can be particularly suitable for navigating a user through a geographic area because of the enhanced visibility of the landmark.
- FIG. 9 depicts a user interface 500 for a geographic information system according to an embodiment of the present disclosure.
- the user interface 500 can be presented on the display 510 of a computing device.
- the user interface can present geographic imagery 512 of a geographic area in a viewport.
- the geographic imagery 512 can include travel directions 516 indicating a preferred route for navigation between an origin and a destination.
- the user interface 500 can also present a navigation recommendation 518 to the user.
- the navigation recommendation can recommend to the user to turn left at a particular landmark.
- recommendation 518 can be a prominent landmark identified according to example aspects of the present disclosure.
- the landmark 515 selected to be rendered in an emphasized style can be a prominent landmark identified according to example aspects of the present disclosure.
- the prominent landmarks can be used to identify landmarks for constructing a three-dimensional model.
- Certain geographic information system can provide three-dimensional models of various landmarks and terrain in a geographic area. Three-dimensional models can sometimes be time intensive and/or computationally expensive to generate and/or display.
- Prominent landmarks identified according to example aspects of the present disclosure can be selected for creation and/or display of a three-dimensional model to enhance the appearance of the geographic imagery.
- FIG. 10 depicts a computing system 600 that can be used to implement the methods and systems for identifying and prioritizing prominent landmarks according to example aspects of the present disclosure.
- the system 600 is implemented using a client- server architecture that includes a server 610 that communicates with one or more client devices 630 over a network 640.
- the system 600 can be implemented using other suitable architectures, such as a single computing device.
- the system 600 includes a server 610, such as a web server.
- the server 610 can host a geographic information system.
- the server 610 can be implemented using any suitable computing device(s).
- the server 610 can have one or more processors 612 and a memory 614.
- the server 610 can also include a network interface used to communicate with one or more client devices 630 over a network 640.
- the network interface can include any suitable components for interfacing with one more networks, including for example, transmitters, receivers, ports, controllers, antennas, or other suitable components.
- the one or more processors 612 can include any suitable processing device, such as a microprocessor, microcontroller, integrated circuit, or other suitable processing device.
- the memory 614 can include any suitable computer-readable medium or media, including, but not limited to, non-transitory computer-readable media, RAM, ROM, hard drives, flash drives, or other memory devices.
- the memory 614 can store information accessible by the one or more processors 612, including instructions 616 that can be executed by the one or more processors 612.
- the instructions 616 can be any set of instructions that when executed by the one or more processors 612, cause the one or more processors 612 to provide desired functionality.
- the instructions 616 can be executed by the one or more processors 612 to implement a structure-from-motion (SFM) module 620, a filtering module 622, a matching module 624, a viewshed module 626, a ranking module 628 and/or other suitable modules.
- SFM structure-from-motion
- the SFM module 620 can be configured to process geographic imagery data captured from one or more cameras to generate a point cloud including a plurality of data points.
- the filtering module 622 can be configured to identify a subset of data points in the point cloud located at least a threshold distance away from one or more camera perspectives associated with the geographic imagery data.
- the matching module 624 can be configured to match one or more data points in the subset with a landmark.
- the viewshed module 626 can be configured to determine a viewshed for one or more data points in the subset.
- the ranking module 628 can be configured to determine a score for a landmark based at least in part on the viewshed of a data point associated with the landmark.
- module refers to computer logic utilized to provide desired functionality.
- a module can be implemented in hardware, application specific circuits, firmware and/or software controlling a general purpose processor.
- the modules are program code files stored on the storage device, loaded into memory and executed by a processor or can be provided from computer program products, for example computer executable instructions, that are stored in a tangible computer-readable storage medium such as RAM, hard disk or optical or magnetic media.
- any suitable programming language or platform can be used to implement the module.
- Memory 614 can also include data 618 that can be retrieved, manipulated, created, or stored by the one or more processor 612.
- the data 618 can include geographic data such as landmark data and geographic imagery data.
- the data 618 can be stored in one or more databases.
- the one or more databases can be connected to the server 610 by a high bandwidth LAN or WAN, or can also be connected to server 610 through network 640.
- the one or more databases can be split up so that they are located in multiple locales.
- the server 610 can exchange data with one or more client devices 630 over the network 640. Although two client devices 630 are illustrated in FIG. 10, any number of client devices 630 can be connected to the server 610 over the network 640.
- the client devices 630 can be any suitable type of computing device, such as a general purpose computer, special purpose computer, laptop, desktop, mobile device, smartphone, tablet, wearable computing device, a display with one or more processors, or other suitable computing device.
- a client device 630 can include one or more processor(s) 632 and a memory 634.
- the one or more processor(s) 632 can include one or more central processing units (CPUs), graphics processing units (GPUs) dedicated to efficiently rendering images, and or other processing devices.
- the memory 634 can store information accessible by the one or more processors 632, including instructions 636 that can be executed by the one or more processors 632 and data 638. For instance, the memory 634 can store instructions 636 for implementing a user interface and a mapping application for a geographic
- the client device 630 can include various input/output devices for providing and receiving information from a user, such as a touch screen, touch pad, data entry keys, speakers, and/or a microphone suitable for voice recognition.
- the client device 630 can have a display 635 for presenting geographic imagery of a geographic area to a user.
- the client device 630 can also include a network interface used to communicate with one or more remote computing devices (e.g. server 610) over the network 640.
- the network interface can include any suitable components for interfacing with one more networks, including for example, transmitters, receivers, ports, controllers, antennas, or other suitable components.
- the network 640 can be any type of communications network, such as a local area network (e.g. intranet), wide area network (e.g. Internet), or some combination thereof.
- the network 640 can also include a direct connection between a client device 630 and the server 610.
- communication between the server 610 and a client device 630 can be carried via network interface using any type of wired and/or wireless connection, using a variety of communication protocols (e.g. TCP/IP, HTTP, SMTP, FTP), encodings or formats (e.g. HTML, XML), and/or protection schemes (e.g. VPN, secure HTTP, SSL).
- server processes discussed herein may be implemented using a single server or multiple servers working in combination.
- Databases and applications may be implemented on a single system or distributed across multiple systems. Distributed components may operate sequentially or in parallel.
Abstract
Description
Claims
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/021,222 US9625612B2 (en) | 2013-09-09 | 2013-09-09 | Landmark identification from point cloud generated from geographic imagery data |
PCT/US2014/051188 WO2015034650A1 (en) | 2013-09-09 | 2014-08-15 | Landmark identification from point cloud generated from geographic imagery data |
Publications (1)
Publication Number | Publication Date |
---|---|
EP3044726A1 true EP3044726A1 (en) | 2016-07-20 |
Family
ID=51483675
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
EP14758748.9A Pending EP3044726A1 (en) | 2013-09-09 | 2014-08-15 | Landmark identification from point cloud generated from geographic imagery data |
Country Status (4)
Country | Link |
---|---|
US (2) | US9625612B2 (en) |
EP (1) | EP3044726A1 (en) |
DE (1) | DE202014010927U1 (en) |
WO (1) | WO2015034650A1 (en) |
Families Citing this family (16)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
WO2014145405A2 (en) * | 2013-03-15 | 2014-09-18 | Gaiter Felix R | Three-dimensional layered map |
US9360338B2 (en) * | 2014-07-16 | 2016-06-07 | International Business Machines Corporation | Presenting the viewability of a point of interest on a map |
US9787557B2 (en) | 2015-04-28 | 2017-10-10 | Google Inc. | Determining semantic place names from location reports |
US10410412B2 (en) * | 2015-05-29 | 2019-09-10 | Hover Inc. | Real-time processing of captured building imagery |
CN107766367B (en) * | 2016-08-18 | 2021-09-07 | 北京四维图新科技股份有限公司 | Automatic checking method and device for data matching |
US10255720B1 (en) * | 2016-10-13 | 2019-04-09 | Bentley Systems, Incorporated | Hybrid mesh from 2.5D and 3D point data |
WO2019079211A1 (en) * | 2017-10-19 | 2019-04-25 | DeepMap Inc. | Lidar to camera calibration for generating high definition maps |
CN108648272A (en) * | 2018-04-28 | 2018-10-12 | 上海激点信息科技有限公司 | Three-dimensional live acquires modeling method, readable storage medium storing program for executing and device |
EP3610225B1 (en) * | 2018-06-22 | 2022-03-02 | Beijing Didi Infinity Technology and Development Co., Ltd. | Systems and methods for updating highly automated driving maps |
US10955256B2 (en) * | 2018-10-26 | 2021-03-23 | Here Global B.V. | Mapping system and method for applying texture to visual representations of buildings |
US20210270618A1 (en) * | 2018-12-17 | 2021-09-02 | Google Llc | Discovery and Evaluation of Meeting Locations Using Image Content Analysis |
JP6745465B1 (en) * | 2019-03-06 | 2020-08-26 | パナソニックＩｐマネジメント株式会社 | Vehicle and camera module |
KR20220012212A (en) * | 2019-05-24 | 2022-02-03 | 구글 엘엘씨 | Interactive landmark-based positioning |
US20220138451A1 (en) * | 2020-10-30 | 2022-05-05 | Here Global B.V. | System and method for importance ranking for collections of top-down and terrestrial images |
CN112711987B (en) * | 2020-12-11 | 2022-04-29 | 国网电力科学研究院武汉南瑞有限责任公司 | Double-laser-radar electric power tower three-dimensional point cloud enhancement system and method |
US20220295040A1 (en) * | 2021-03-11 | 2022-09-15 | Quintar, Inc. | Augmented reality system with remote presentation including 3d graphics extending beyond frame |
Family Cites Families (10)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7356164B2 (en) * | 2003-05-30 | 2008-04-08 | Lucent Technologies Inc. | Method and apparatus for finding feature correspondences between images captured in real-world environments |
US7933897B2 (en) | 2005-10-12 | 2011-04-26 | Google Inc. | Entity display priority in a distributed geographic information system |
US7912637B2 (en) | 2007-06-25 | 2011-03-22 | Microsoft Corporation | Landmark-based routing |
US8364398B2 (en) | 2009-08-28 | 2013-01-29 | Navteq B.V. | Method of operating a navigation system to provide route guidance |
US8463543B2 (en) | 2010-02-05 | 2013-06-11 | Apple Inc. | Schematic maps |
US20130035853A1 (en) | 2011-08-03 | 2013-02-07 | Google Inc. | Prominence-Based Generation and Rendering of Map Features |
CN103959308B (en) | 2011-08-31 | 2017-09-19 | Metaio有限公司 | The method that characteristics of image is matched with fixed reference feature |
US8848983B1 (en) | 2012-05-31 | 2014-09-30 | Google Inc. | System and method for ranking geographic features using viewshed analysis |
GB2506338A (en) * | 2012-07-30 | 2014-04-02 | Sony Comp Entertainment Europe | A method of localisation and mapping |
US8805091B1 (en) * | 2012-08-17 | 2014-08-12 | Google Inc. | Incremental image processing pipeline for matching multiple photos based on image overlap |
-
2013
- 2013-09-09 US US14/021,222 patent/US9625612B2/en active Active
-
2014
- 2014-08-15 DE DE202014010927.3U patent/DE202014010927U1/en active Active
- 2014-08-15 WO PCT/US2014/051188 patent/WO2015034650A1/en active Application Filing
- 2014-08-15 EP EP14758748.9A patent/EP3044726A1/en active Pending
-
2017
- 2017-04-17 US US15/488,540 patent/US20170219370A1/en not_active Abandoned
Non-Patent Citations (2)
Title |
---|
None * |
See also references of WO2015034650A1 * |
Also Published As
Publication number | Publication date |
---|---|
WO2015034650A1 (en) | 2015-03-12 |
US9625612B2 (en) | 2017-04-18 |
US20170219370A1 (en) | 2017-08-03 |
DE202014010927U1 (en) | 2017-01-19 |
US20150073711A1 (en) | 2015-03-12 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US9625612B2 (en) | Landmark identification from point cloud generated from geographic imagery data | |
US11783543B2 (en) | Method and system for displaying and navigating an optimal multi-dimensional building model | |
EP3134829B1 (en) | Selecting time-distributed panoramic images for display | |
EP2541201B1 (en) | Map view | |
US10191635B1 (en) | System and method of generating a view for a point of interest | |
US10950040B2 (en) | Labeling for three-dimensional occluded shapes | |
US10018480B2 (en) | Point of interest selection based on a user request | |
US20180005425A1 (en) | System and Method for Displaying Geographic Imagery | |
US11140510B2 (en) | Contextual map view | |
US20170039450A1 (en) | Identifying Entities to be Investigated Using Storefront Recognition | |
US11402232B2 (en) | Off-viewport location indications for digital mapping | |
US20150128089A1 (en) | Scale Sensitive Treatment of Features in a Geographic Information System | |
CN112105892A (en) | Identifying map features using motion data and bin data | |
JP7267409B2 (en) | Method and device for navigating two or more users to a meeting point | |
WO2018080422A1 (en) | Point of interest selection based on a user request | |
US9188444B2 (en) | 3D object positioning in street view | |
US20170200396A1 (en) | Crowdsourcing User Generated Content Using Accessibility Enhancements | |
US9196151B2 (en) | Encoding location-based reminders |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PUAI | Public reference made under article 153(3) epc to a published international application that has entered the european phase |
Free format text: ORIGINAL CODE: 0009012 |
|
17P | Request for examination filed |
Effective date: 20160222 |
|
AK | Designated contracting states |
Kind code of ref document: A1Designated state(s): AL AT BE BG CH CY CZ DE DK EE ES FI FR GB GR HR HU IE IS IT LI LT LU LV MC MK MT NL NO PL PT RO RS SE SI SK SM TR |
|
AX | Request for extension of the european patent |
Extension state: BA ME |
|
DAX | Request for extension of the european patent (deleted) | ||
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: EXAMINATION IS IN PROGRESS |
|
17Q | First examination report despatched |
Effective date: 20171004 |
|
RAP1 | Party data changed (applicant data changed or rights of an application transferred) |
Owner name: GOOGLE LLC |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: EXAMINATION IS IN PROGRESS |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: EXAMINATION IS IN PROGRESS |
|
REG | Reference to a national code |
Ref country code: DERef legal event code: R079Ref document number: 602014090210Country of ref document: DEFree format text: PREVIOUS MAIN CLASS: G06K0009000000Ipc: G06T0007730000Ref country code: DERef legal event code: R079Free format text: PREVIOUS MAIN CLASS: G06K0009000000Ipc: G06T0007730000 |
|
GRAP | Despatch of communication of intention to grant a patent |
Free format text: ORIGINAL CODE: EPIDOSNIGR1 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: GRANT OF PATENT IS INTENDED |
|
RIC1 | Information provided on ipc code assigned before grant |
Ipc: G06F 17/40 20060101ALI20231128BHEPIpc: G01C 21/36 20060101ALI20231128BHEPIpc: G01C 21/00 20060101ALI20231128BHEPIpc: G06V 20/10 20220101ALI20231128BHEPIpc: G06T 7/73 20170101AFI20231128BHEP |
|
INTG | Intention to grant announced |
Effective date: 20231212 |
|
GRAS | Grant fee paid |
Free format text: ORIGINAL CODE: EPIDOSNIGR3 |
|
GRAA | (expected) grant |
Free format text: ORIGINAL CODE: 0009210 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: THE PATENT HAS BEEN GRANTED |
|
P01 | Opt-out of the competence of the unified patent court (upc) registered |
Effective date: 20240316 |