CN105814556A - Context sensitive input tools - Google Patents
Context sensitive input tools Download PDFInfo
- Publication number
- CN105814556A CN105814556A CN201380079899.4A CN201380079899A CN105814556A CN 105814556 A CN105814556 A CN 105814556A CN 201380079899 A CN201380079899 A CN 201380079899A CN 105814556 A CN105814556 A CN 105814556A
- Authority
- CN
- China
- Prior art keywords
- candidate
- input
- described input
- computing equipment
- text
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/10—Text processing
- G06F40/166—Editing, e.g. inserting or deleting
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0481—Interaction techniques based on graphical user interfaces [GUI] based on specific properties of the displayed interaction object or a metaphor-based environment, e.g. interaction with desktop elements like windows or icons, or assisted by a cursor's changing behaviour or appearance
- G06F3/0482—Interaction with lists of selectable items, e.g. menus
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0484—Interaction techniques based on graphical user interfaces [GUI] for the control of specific functions or operations, e.g. selecting or manipulating an object, an image or a displayed text element, setting a parameter value or selecting a range
- G06F3/04842—Selection of displayed objects or displayed text elements
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/20—Natural language analysis
- G06F40/232—Orthographic correction, e.g. spell checking or vowelisation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/20—Natural language analysis
- G06F40/237—Lexical tools
- G06F40/242—Dictionaries
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/20—Natural language analysis
- G06F40/263—Language identification
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/20—Natural language analysis
- G06F40/274—Converting codes to words; Guess-ahead of partial word inputs
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/30—Semantic analysis
Abstract
A computer-implemented method can include receiving an input from a user. The input can include one or more characters in a first script representative of text in a particular language. The input can be received in association with a document. The method can include determining a context of the input based on one or more semantic topics of the document associated with the input. One or more candidates for the input can be determined based on (i) the input, (ii) the context of the input, and (iii) a language model. The candidates can include one or more characters in a second script representative of the text in the particular language. The language model can express a probability of occurrence of the one or more candidates in the particular language. The method can further include outputting a list of the one or more candidates for display to the user.
Description
Technical field
It relates to the text input of computing equipment, more specifically, it relates to utilize the linguistic context of input to help user to enter text into the technology of computing equipment.
Background technology
Background description in this offer is the purpose of the context for the general description disclosure.For the degree described by this background section, the work of currently known inventor and cannot additionally be proved each side of prior art in description when submitting, both indefinite impliedly it is not recognized as the prior art relative to the disclosure yet.
User can by coming to provide text input to computing equipment with one or more peripheral hardwares of such as keyboard, keypad or touch display alternately.In some instances, user can utilize the Input Method Editor (" IME ") of the expression of the text of text and the second word receiving the first word (script).Merely illustrative, user may want to by using Latin or Rome keyboard, for instance by inputting the pinyin representation of text, the Chinese text of input chinese character.Alternatively or additionally, computing equipment can pass through advise candidate word or input the candidate of same text with text, is sometimes referred to as " automatically corrigendum " and/or " being automatically performed " is functional, it is simple to the text input of user.These examples each in, computing equipment attempt determine that user is just intended to input what text.Expectation is increased this accuracy determined and speed.
Summary of the invention
In certain embodiments, a kind of computer implemented method is disclosed.The computing equipment place that the method can include having one or more processor receives input from user.This input include representing the text of language-specific with one or more characters of the first word.Additionally, this input can be received explicitly with document.The method can also include at computing equipment place, based on the linguistic context determining input with the one or more semantic topics inputting the document being associated.Additionally, the method can include at computing equipment place, linguistic context and (iii) language model of inputting based on (i) input, (ii) determine the one or more candidates for inputting.These candidates can include representing the text of language-specific with one or more characters of the second word.Language model represents the probability that one or more candidate occurs in language-specific.The method can farther include to export the inventory of one or more candidates to be shown to user from computing equipment.
In certain embodiments, the linguistic context of input can be determined by the text of document.Additionally, the method can further include at computing equipment place, determine the probability of each candidate of one or more candidate based on the linguistic context inputted and language model.The probability of each particular candidate represents the likelihood of the described input with the second word based on this particular candidate.The rank order of one or more candidate can be determined based on determined probability, and rank order output inventory can be pressed.
In various embodiments, it is determined that the one or more candidates for inputting can include: at computing equipment place, the linguistic context based on input retrieves the dictionary specific to theme；And at computing equipment place, this input was compared with the entry being somebody's turn to do specific to the dictionary of theme.Additionally or alternati, determine that the one or more candidates for this input can include at computing equipment place, utilizing this input and language model to generate (i) for probability for each candidate of one or more candidates of one or more candidates of this input and (ii), the probability for each particular candidate represents this input with the second word based on this particular candidate；And at computing equipment place, utilize the linguistic context of this input to adjust the probability of each candidate for one or more candidates.The probability of each particular candidate can represent the likelihood of the described input with the second word based on this particular candidate.
Document can be Email, and the linguistic context of input determined by the text of previous typing from Email.Additionally, document can be webpage, and determine the linguistic context of input from the text of webpage.In certain embodiments, the first word and the second word are same text.Additionally, the method can also include at computing equipment place, receive from selection to particular candidate of the list of one or more candidates；And at computing equipment place, carry out more newly inputted linguistic context based on selected particular candidate.
In some embodiments of the disclosure, describe a kind of computer system.This computer system can include one or more processor and the non-emporary computer-readable medium of storage instruction, and described instruction makes computer system perform operation when executed by one or more processors.The operation that can be performed by computer system can include any one or more of the aforesaid operations about disclosed computer implemented method.
From detailed description provided below, the other suitable application area of the disclosure will become clear from.It will be appreciated that, detailed description and object lesson are only intended to example purpose and are not intended to restriction the scope of the present disclosure.
Accompanying drawing explanation
From the detailed description and the accompanying drawings, the disclosure be will be more fully understood, wherein:
Fig. 1 illustrates the user of some realizations according to the disclosure and the mutual of Example Computing Device；
Fig. 2 is the functional block diagram of the computing equipment of Fig. 1 of some realizations according to the disclosure；
Fig. 3 is the mutual functional block diagram of user and another Example Computing Device of some realizations according to the disclosure；And
Fig. 4 is the flow chart of the example technique helping user to provide text to input computing equipment of some realizations according to the disclosure.
Detailed description of the invention
User can input text to computing equipment, for instance, in order to Email or other electronic informations and webpage mutual (input search inquiry, offer " user comment ") or typesetting newspaper article, books or research paper are provided.In some cases, computing equipment can provide a user with the help of input text.
As it has been described above, Input Method Editor (" IME ") can be offered help to hope with the user of the first word input text different from providing the user with selective word.Such as, user, possibly also with phonetic IME, utilizes Latin keyboard to input the Chinese text of chinese character.Additionally, computing equipment can include corrigendum and/or the auto-complete function automatically that provide a user with candidate's (word/syllable/phrase etc.) based on incorrect and/or part input.
It relates to utilize the linguistic context of input to help the technology of user input text.The linguistic context of input and language model can increase the accuracy and speed of the aid of computing equipment to determine, based on this input, the text that user wants.
With reference now to Fig. 1, it is shown that Example Computing Device 100.Computing equipment 100 is shown as mobile equipment (such as mobile phone, panel computer or " flat board mobile phone " computer), recognizes that term " computing equipment " can include comprising any type of computer or the computer system of the one or more processors for performing instruction although, it should.Merely illustrative, computing equipment can adopt desk computer, laptop computer, mobile equipment (such as mobile phone, panel computer, flat board mobile phone and head-wearing type computer) and server or other Distributed Computer Systems and these exemplary computer device two or more performing to operate that work together.
Shown computing equipment 100 includes display 104, all as directed touch displays.Computing equipment 100 can include physical keyboard (not shown) additionally or alternati.Touch display 104 can show information to user 108 and receive input from user 108.Can providing " soft " keyboard 114 on display 104, user 108 can pass through soft keyboard 114 provides text to input.Shown keyboard is to provide Latin alphabet character and the Latin keyboard of other inputs option (numeral, space bar, symbol etc.).User 108 can use one or more finger 112, inputs text via touch display 104 and/or keyboard 114 to computing equipment 100.
With reference now to Fig. 2, it is shown that the functional block diagram of Example Computing Device 100.Computing equipment 100 can include processor 200 and communication equipment 204.Term " processor " refers to single processor and operates the two or more processors of such as parallel or distributed architecture together to perform the operation of computing equipment 100 as used herein.Computing equipment 100 can farther include language model 208 and context model 212.Although be shown as and be described as the independent assembly of computing equipment 100 at this, but in language model 208 and context model 212 one or both can be realized by processor 200.It will be appreciated that computing equipment 100 can include unshowned other computation module, such as memorizer, speaker, one or more buttons etc. in fig. 2.
Processor 200 controls the major part operation of computing equipment 100.Such as, processor 200 can perform task, such as, but not limited to loading/control the operating system of computing equipment 100, loading/configuration for the messaging parameter of communication equipment 204, control IME parameter and control memorizer storage/retrieval operation, for instance be used for loading various parameter.Additionally, processor 200 can control and the communication of user 108 via the touch display 104 of computing equipment 100.
Processor 200 via touch display 104, can provide various kinds of characters input structure for user 108.Such as, processor 200 can provide the form of as directed standard Latin " QWERTY " keyboard for user 108.Alternatively, processor 200 can provide standard 12 bond structure for user 108, also referred to as based on the T9 charcter topology inputted, or other keyboard structures.
Processor 200 such as, can receive input via the character input structure provided from user 108.But, processor 200 can also provide various IME, for instance phonetic IME, it is allowed to user 108 enters text into computing equipment 100 with the first word to obtain the text with different literals.Therefore, processor 200 can also pass through to change with different literals, for instance with the user version of Pinyin Input, and the input received from user 108 converts to one or more required word, for instance, Chinese character.Such as, when explaining user version input (being described in more detail below), processor 200 can be worked in coordination with context model 212 and be used language model 208 together.
Communication equipment 204 controls the communication between computing equipment 100 and other equipment/networks.Merely illustrative, communication equipment 204 can provide the communication between computing equipment 100 and other computing equipments and/or the Internet that are associated.Computing equipment 100 generally can via three kinds of telecommunication medias: the such as computing network 250 of the Internet (hereinafter, " network 250 "), mobile telephone network 254 communicate with one or more in satellite network 258.Other telecommunication medias can also be realized.For example, it is possible to communication equipment 204 to be configured to wired and wireless network connection, for instance radio frequency (RF) communicates.
With reference now to Fig. 3, it is shown that for providing another Example Computing Device 160 of context-sensitive input tool to user 108.Computing equipment 160 communicates with the computing equipment 180 of user 108 via network 250 (such as the Internet).Computing equipment 180 is illustrated as desk computer, it is appreciated that computing equipment 180 can be any computer or computer system, and all computing equipments 100 as shown in figs. 1-2.Additionally, in the context of operation, computing equipment 160 is described as server, but computing equipment 160 also can be computer or the computer system of any other type.
Similar with above-mentioned computing equipment 100, computing equipment 160 can include processor 300 and the communication equipment 304 that can operate in the way of similar with above-mentioned processor 200 and communication equipment 204 respectively.Computing equipment 160 can farther include language model 308 and the context model 312 that can operate in the way of similar with above-mentioned language model 308 and context model 312 respectively.Although additionally, it will be appreciated that the independent assembly being shown and described as computing equipment 160, but in language model 308 and context model 312 one or both can be realized by processor 300.Computing equipment 160 can communicate with the computing equipment 180 of user 108 via network 250.
Can pass through individually or cooperate any one execution technology described herein of the computing equipment 100,160,180 of work.But, for simplicity, following description will be primarily referred to as the various operations of computing equipment 100.It will be appreciated that can by one or more personal modules (such as processor 200 or communication equipment 204) of computing equipment 100,160 or 180 and/or its personal module, or the combination of these elements performs operation.
As it has been described above, user 108 can provide input via one or more input equipments of such as display 104, soft keyboard 114, physical keyboard (not shown) or mike (not shown) to computing equipment 100.Input can be input through keyboard, handwritten stroke or person's handwriting (for hand-written to text function) or phonetic entry (user speech text function), although also can utilize the input of other forms.Input can include the one or more characters (or part of character) representing the first word of the text of language-specific.Merely illustrative, when phonetic IME, the text that user 108 is provided that the text representing Chinese, inputs with latin text.
Computing equipment 100 directly (such as from the user 108 mutual with computing equipment 100), or (such as, computing equipment 160 can receive input via another computing equipment 100,180) can receive input from user 108 indirectly.Input can be received explicitly with document.Document can be any text entry will add input, includes but not limited to Email or other electronic informations, webpage and the document that can be created/editd by user 108.Other kinds of document includes the e-mail thread that such as user 108 replies, and be already sent to the expection recipient of electronic information that created by user 108 or receive from it one or more before electronic informations.
In order to provide text input auxiliary, computing equipment 100 such as can determine the linguistic context of input based on one or more language schemes of the document being associated with input.Expectability be input to the text of document at least with the semanteme of document or theme a little relation.Thus, the linguistic context of input is selectively act as assisting in the signal of the one or more candidates (character, word, phrase etc.) for inputting.Merely illustrative, if document describes war or the fight of army, and user 108 provides input text " piece ", then as candidate options, word " peace " is supplied to user 108 and is advantageous for.In this example embodiment, candidate " peace " automatically corrects functional example, because being " piece " of user 108 spelling correction inputted.
The use of the linguistic context of input described herein is different from the utilization of language model 208,308.Language model 208,308 can represent, with language-specific, the probability that one or more token (such as word) occurs.Such as, language model 208,308 can describe the probability of given a series of customizing messages occurred after front input token.Generally relevant with n-gram description language model, n-gram refers to based on previous (n-1) token, the probability (n=1 is Uni-Gram, and n=2 is two-dimensional grammar model etc.) of particular token.Compared with language model 208,308, the context model 212, the 312 relatively long distance relation to describe between token can be utilized.Merely illustrative, with reference to the example of above-mentioned " war " and " piece/peace ", if in front n the token in document, it does not have token " war ", any relation that then n-gram language model 208,308 will not catch between described " war " and " piece/peace ".But, if these tokens are relevant with identical semantic topic, then it is utilized to determine this relation that the context model 212,312 of the linguistic context (one or more semantic topics of the document such as, being associated) of input can catch between " war " and " piece/peace " with input.
As it has been described above, the linguistic context of input can be determined based on one or more semantic topics of the document being associated with input.Semantic topic is the set of the relevant theme of the text (word, phrase etc.) with document or concept.The semantic analysis of text of document can be performed to extract semantic topic.
In some embodiments of the disclosure, can pass through to perform implicit semantic analysis, the distribution of implicit Di Li Cray, repeat the combination of soft maximization model, deep Boltzman machine or these (or other) technology, extract semantic topic from document.Additionally or alternatively, to the document as webpage, semantic topic can be extracted based on the keyword being associated with webpage.To other kinds of document, semantic topic can based on before being currently entered by the text of user's typing.It will be appreciated that in addition to such a technique or as an alternative, it is possible to use determine the other technologies of the linguistic context of input.
Can be created by computing equipment 100 and utilize context model 212 to determine the linguistic context of input.Merely illustrative, can by utilizing the training data of labelling to infer the supervision machine learning algorithm generation context model 212 of the relation between document and semantic topic.Alternatively, by the combination without supervision machine learning algorithm, semi-supervised learning algorithm or all three algorithm, context model 212 can be generated.
Under each situation, context model 212 can include the context identifier for each known text element (word, phrase etc.).Context model 212 farther includes multiple semantic topic and the score of each known text element relevant with each semantic topic.Each score represents the dependency between the relative semantic topic of text element, for instance, the probability that particular text element is relevant to certain semantic theme.Context model 212 can be used for identifying semantic topic and score based on the context identifier of particular document, as described in more fully below.
The linguistic context of input can be determined by the text element (word, phrase etc.) of the document that the input identified with receive is associated.The each context identifier for these text elements can be determined from context model 212.Based on a determination that context identifier, can determine that each semantic topic of the text element of the identification for document and score.Can determine which semantic topic or which semantic topic are possibly used for the document in conjunction with score.Context model 212 can based on the dependency between text element and the semantic topic determined, it is determined that the probability that other text element (such as input) occurs.Probability of occurrence can be utilized to identify the possible candidate of the input for user in conjunction with language model 208.
Additionally, computing equipment 100 can determine that the probability of each candidate of the candidate for one or more identifications.Probability for particular candidate can represent, based on this particular candidate, the likelihood inputted.Probability can based on the linguistic context from context model 212 and the input of language model 208.
As it has been described above, context model 212 and language model 208 are all provided that the probability for particular candidate.In certain embodiments, can be combined to determine each combined probability for one or more candidates from each each probability of language model 208 and context model 212.Based on following equation, particular candidate can be determined the combination from language model 208 and the probability of context model 212:
P (w | history)=Plangmod(w|history)α* Pcntxtmod(w|history)(1-α), (1)
Wherein, w is particular candidate, history be candidate based on information (such as, can be known n-gram to language model 208, history, and to context model 212, history can be the linguistic context of input), and P (w | history) it is combined probability, Plangmod(w | history) originates from the probability of language model, Pcntxtmod(w | history) originates from the probability of context model, and α determines that to provide the parameter of the best coupling of training data.In certain embodiments, α is selected as being equal to 0.3, but can utilize other values.Combined probability can be utilized such as to determine the rank order of one or more candidate.
In certain embodiments, computing equipment 100 can utilize input and language model 208 to generate the one or more candidates for this input and the probability for each candidate.Then, computing equipment 100 can utilize the linguistic context that (from context model 212) inputs to adjust the probability for each candidate, for instance, it is determined by the combined probability for each candidate.By this way, utilize the linguistic context of input to assist in most probable candidate, rather than assist in possible candidate.
In certain embodiments, the linguistic context of input can be utilized to retrieve the dictionary of particular topic.The dictionary of particular topic is the inventory of the text element (word, phrase etc.) being associated with certain semantic theme.The dictionary of particular topic can include non-existent unique words in standard language model 208.Once it is determined that the linguistic context of input, the dictionary of the corresponding particular topic of the semantic topic of identification with document can be retrieved.Then, the one or more candidates for this input can be determined by inputting compare with the entry of the dictionary of particular topic.
Once it is determined that one or more candidates, computing equipment 100 just can input the inventory (or subset of one or more candidate) of one or more candidate to be shown to user 108.To the computing equipment 100 including display 104, the inventory of output candidate can include display candidate.To computing equipment 160, the inventory of output candidate can include the inventory of candidate is supplied to another computing equipment 100,180 to be shown by another computing equipment 100,180.In certain embodiments, can by the rank order output candidate list such as determined based on combinations thereof probability.
Once candidate list exports user 108, user 108 can select that particular candidate, for the expression of the intended input of user 108.Computing equipment 100 can receive the selection of particular candidate to include in a document.Additionally, computing equipment 100 can based on the particular candidate selected, more newly inputted linguistic context.That is, once user 108 is chosen for the particular candidate included in a document, that particular candidate just becomes a part for document.Then, it is determined that include now the linguistic context of the document of the renewal of the candidate of selection and for determining one or more candidates of another input for user 108.
With reference now to Fig. 4, it is illustrated that be adapted to assist in the example technique 400 that user 108 provides text to input to computing equipment 100.Perform although depicted as by computing equipment 100, but it should be appreciated that can by one or more specific components (such as processor 200 or communication equipment 204) of computing equipment 100, computing equipment 160 or 180 and/or the combination of its specific part or these elements perform operation.Additionally, can pass through to include (i) one or more processor；And the computer system of (ii) non-emporary computer-readable medium of storing instruction realizes technology 400, described instruction makes the operation of this computer system execution technology 400 when executed by one or more processors.
404, computing equipment 100 receives input from user 108.Input can include the one or more characters representing the first word of the text of language-specific.Input is received by user 108 additionally, can be associated with the document just created/editd.408, computing equipment 100 can determine the linguistic context of input based on one or more semantic topics of the document being associated with input.With above-mentioned either type, context model 212 cause document (such as, the text of document) can be utilized to determine the linguistic context of input.
412, can determine that the one or more candidates for this input.Can input based on (i), linguistic context that (ii) inputs and (iii) language model 208 determine one or more candidate.As it has been described above, language model 208 can represent the probability of occurrence of one or more candidates in language-specific.Candidate can include the one or more characters representing the second word of the text of language-specific.When computing equipment 100 provides corrigendum and/or auto-complete function automatically, the first word and the second word can be identical.Thering is provided IME functional (only IME or combination are automatically corrected and/or be automatically performed) at computing equipment 100, the first word and the second word can be different.Merely illustrative, user 108 is provided that the input of the Latin alphabet is to utilize phonetic IME to input with chinese character Chinese text.
416, the linguistic context that can input based on (from context model 212) and language model 208, it is determined that the probability of each candidate of one or more candidates.420, can determine that the rank order of candidate.Rank order can based on the probability for each candidate.424, the inventory of one or more candidate can be exported to be shown to user 108.In certain embodiments, this inventory can be exported by 420 rank order determined.428, can receive from the selection to particular candidate of the inventory of one or more candidates.Based on the particular candidate selected, 432, linguistic context that can be more newly inputted.Then, technology 400 can terminate or return to 404, for one or more other circulations.
There is provided example embodiment so that the disclosure will be more thorough and to those skilled in the art's comprehensive representation the scope of the present disclosure.Embodiment of the disclosure to thoroughly understand, elaborate many details, for instance the specifically example of assembly, apparatus and method.For the common field technique personnel of ability it will be apparent that these details need not be adopted, and example embodiment can be embodied in many different forms, and it should not be construed as the restriction to disclosure scope.In some example embodiments, known method, known apparatus structure and known technology it are not described in detail.
Term as used herein is merely for the purpose describing concrete example embodiment, and is not intended to limit." one ", " one " and " described " of singulative as used in this article, beyond unless the context clearly, it will be appreciated that for also including plural form.Term "and/or" includes any of one or more associated listed item or its all combinations.Term " includes ", " comprising ", " containing " and " having " are inclusives, and it is indicated above the feature described in existing, entirety, step, operation, key element, assembly and/or its combination, but does not preclude the presence or addition of one or more further feature, entirety, step, operation, key element, assembly and/or its combination.Unless indicated execution sequence especially, otherwise approach described herein step, process and operation should not be construed as and be necessarily required to them and perform with particular order that is discussed or that illustrate.It is also to be understood that additional or substituting step can be adopted.
Although term first, second, third, etc. can being used in the present invention to describe various key element, assembly, region, layer and/or segmentation, but these key elements, assembly, region, layer and/or segmentation should not being limited by these terms.These terms can only be used for a key element, assembly, region, layer or segmentation and another region, layer or segmentation are made a distinction.Unless clearly indicated within a context, time otherwise used herein, the term such as " first ", " second " and other numerical terms does not imply that order or sequence.Therefore, when without departing substantially from the instruction of exemplary embodiment, the first element discussed below, assembly, region, layer or segmentation can be referred to as the second key element, assembly, region, layer or segmentation.
As used herein, term module or equipment may refer to following every in a part or include following every: special IC (ASIC), electronic circuit, combinational logic circuit, field programmable gate array (FPGA)；Perform the processor (shared, special or group) of code；Or the process performed by the distributed network of the processor in the cluster networked or data center and memorizer, other suitable assembly that described function is provided；Or the some or all combination in such as above-mentioned in SOC(system on a chip).Term module or equipment can include memorizer (shared, special or group), this memorizer storage code performed by one or more processors.
Term code such as above-mentioned use can include software, firmware, bytecode and/or microcode, and may refer to program, routine, function, class and/or object.Term as used above is shared and is referred to that some codes or whole code from multiple modules can use single (sharing) processor to perform.Additionally, some codes or all codes from multiple modules can be stored by single (sharing) memorizer.Term group as used above refers to that some codes or whole code from individual module can use one group of processor to perform.Additionally, some codes or whole code from individual module can use storage stack to store.
Technology described herein can be realized by the one or more computer programs performed by one or more processors.Computer program includes the executable instruction of processor being stored on non-transient state tangible computer computer-readable recording medium.Computer program can also include the data of storage.The non-limiting example of non-transient state tangible computer computer-readable recording medium includes nonvolatile memory, magnetic memory and optical memory.
Some parts described above presents technology described herein in the algorithm and symbol expression of the operation to information.These arthmetic statements and expression are that the those of ordinary skill of data processing field for effectively conveying to the mode of other those of ordinary skill of this area by the essence of its work.These operations functionally and being in logic described should be understood to be realized by computer program.Also, it has proven that when without loss of generality, it is convenient when referring to the layout of these operations by module title or function title.
Unless stated otherwise, otherwise from the discussion above in can substantially arrive and find out, it should be understood that, in entire disclosure, using action and process that term is handled with the computer system of transform data or similar computing electronics as the discussion of " process " or " computing " or " calculating " or " determination " or " display " etc. refers to, described data are shown in physics (electronics) amount in computer system memory or depositor or other this information storage unit.
Some aspect of described technology includes the process step and the instruction that are described herein as in the form of an algorithm.It should be noted, described process step and instruction can be implemented in the way of software, firmware or hardware, and when in time implementing in the way of software, described process step and instruction can be downloaded to reside in the different platform used by real-time network operating system, and are operated from described platform.
The disclosure further relates to perform the device of operation herein.This device can for required purpose special configuration, or it can include the general purpose computer that optionally started by the computer program being stored in the computer-readable medium that can be accessed by computer or reconfigured.This computer program can be stored in tangible computer readable storage medium storing program for executing, such as but not limited to including floppy disk, CD, CD-ROM, any kind of dish of magneto-optic disk, read only memory (ROM), random access memory (RAM), EPROM, EEPROM, magnetic card or optical card, special IC (ASICs), flash memory or being suitable to the medium of any other type of storage e-command, every kind of medium is couple to computer system bus.Additionally, the computer mentioned in this specification can include the framework that single processor can be maybe the multiple processors design adopted to improve computing capability.
Algorithm presented herein is not relevant to any certain computer or miscellaneous equipment in itself with operation.Various general-purpose systems can with use together with the program of teaching herein, or may certify that structure more specialized apparatus be easily to carry out required method step.Structure needed for these systems multiple and what equivalent modifications will be apparent to those skilled in the art.It addition, do not describe the disclosure with reference to any concrete programming language.It should be understood that the instruction that various programming language can be used to realize the disclosure as described herein, and the reference to language-specific is to provide for the exploitativeness of the open disclosure and the optimal mode of the disclosure.
The disclosure is very suitable for the miscellaneous computer network system in numerous topological structure.In this area, the configuration of catenet and management include the storage device and the computer that are couple to different computer and storage device in the network service by such as the Internet.
In order to the purpose of illustration and description provides the description above to embodiment.But it is not intended to the exhaustive or restriction disclosure.Even if not specifically shown or described, but the key element of specific embodiment or feature are generally not limited to this specific embodiment, but in where applicable is interchangeable and can be used to the embodiment selected.Identical mode also can be varied in many ways.These modification are not to be regarded as a departure from the present invention, and all these changes all should be included in the scope of the present disclosure.
Claims (20)
1. a computer implemented method, including:
At the computing equipment place with one or more processor, receive input from user, described input include representing the text of language-specific with one or more characters of the first word, described input and document are received explicitly；
At described computing equipment place, based on one or more semantic topics of the described document being associated with described input, it is determined that the linguistic context of described input；
At described computing equipment place, the one or more candidates for described input are determined based on input (i) described, the linguistic context of (ii) described input and (iii) language model, described candidate include representing the described text of described language-specific with one or more characters of the second word, described language model represents the probability that the one or more candidate occurs in described language-specific；And
The inventory of the one or more candidate is exported to be shown to described user from described computing equipment.
2. computer implemented method as claimed in claim 1, wherein, the text that the linguistic context of described input is from described document is determined.
3. computer implemented method as claimed in claim 1, farther include: at described computing equipment place, determine the probability of each candidate of the one or more candidate based on the linguistic context of described input and described language model, the probability of each particular candidate represents the likelihood of the described input with described second word based on this particular candidate.
4. computer implemented method as claimed in claim 3, farther includes: at described computing equipment place, determine the rank order of the one or more candidate based on determined probability, and wherein, described inventory exports by described rank order.
5. computer implemented method as claimed in claim 1, wherein it is determined that the one or more candidate for described input includes:
At described computing equipment place, the linguistic context based on described input retrieves the dictionary specific to theme；And
At described computing equipment place, described input and described entry in the dictionary of theme are compared.
6. computer implemented method as claimed in claim 1, wherein it is determined that the one or more candidate for described input includes:
At described computing equipment place, described input and described language model is utilized to generate (i) the one or more candidate for described input, and (ii) is for the probability of each candidate of the one or more candidate, represent the likelihood of the described input with described second word based on described particular candidate for the probability of each particular candidate；And
At described computing equipment place, the linguistic context of described input is utilized to adjust the probability of each candidate for the one or more candidate.
7. computer implemented method as claimed in claim 1, wherein, described document is Email, and the linguistic context of described input is that the text of previous typing is determined from described Email.
8. computer implemented method as claimed in claim 1, wherein, described document is webpage, and the linguistic context of described input is that the text from described webpage is determined.
9. computer implemented method as claimed in claim 1, wherein, described first word and the second word are same text.
10. computer implemented method as claimed in claim 1, farther includes:
At described computing equipment place, receive from selection to particular candidate of the list of one or more candidates；And
At described computing equipment place, update the linguistic context of described input based on selected particular candidate.
11. a computer system, including:
One or more processors；And
The non-emporary computer-readable medium of storage instruction, described instruction makes described computer system perform to include following every operation when being performed by the one or more processor:
Receiving input from user, described input includes the one or more characters with the first word, and described first word represents the text of language-specific, and described input and document are received explicitly；
One or more semantic topics based on the described document being associated with described input, it is determined that the linguistic context of described input；
The one or more candidates for described input are determined based on input (i) described, the linguistic context of (ii) described input and (iii) language model, described candidate include representing the text of described language-specific with one or more characters of the second word, described language model represents the probability that the one or more candidate occurs in described language-specific；And
Export the inventory of the one or more candidate to be shown to user.
12. computer system as claimed in claim 11, wherein, the text that the linguistic context of described input is from described document is determined.
13. computer system as claimed in claim 11, wherein, described operation farther includes: determine the probability of each candidate of the one or more candidate based on the linguistic context of described input and described language model, and the probability of each particular candidate represents the likelihood of the described input with described second word based on this particular candidate.
14. computer system as claimed in claim 13, wherein, described operation farther includes: determine the rank order of the one or more candidate based on determined probability, and wherein, described inventory exports by described rank order.
15. computer system as claimed in claim 11, wherein it is determined that the one or more candidate for described input includes:
Linguistic context based on described input retrieves the dictionary specific to theme；And
Described input and described entry in the dictionary of theme are compared.
16. computer system as claimed in claim 11, wherein it is determined that the one or more candidate for described input includes:
Described input and described language model is utilized to generate (i) the one or more candidate for described input, and (ii) is for the probability of each candidate of the one or more candidate, represent the likelihood of the described input with the second word based on this particular candidate for the probability of each particular candidate；And
The linguistic context utilizing described input adjusts the probability of each candidate for the one or more candidate.
17. computer system as claimed in claim 11, wherein, described document is Email, and the linguistic context of described input is that the text of previous typing is determined from described Email.
18. computer system as claimed in claim 11, wherein, described document is webpage, and the linguistic context of described input is that the text from described webpage is determined.
19. computer system as claimed in claim 11, wherein, described first word and the second word are same text.
20. computer system as claimed in claim 11, wherein, described operation farther includes:
Receive from selection to particular candidate of the list of one or more candidates；And
The linguistic context of described input is updated based on selected particular candidate.
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
PCT/CN2013/084289 WO2015042819A1 (en) | 2013-09-26 | 2013-09-26 | Context sensitive input tools |
Publications (2)
Publication Number | Publication Date |
---|---|
CN105814556A true CN105814556A (en) | 2016-07-27 |
CN105814556B CN105814556B (en) | 2019-09-13 |
Family
ID=52741775
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201380079899.4A Active CN105814556B (en) | 2013-09-26 | 2013-09-26 | The input tool of context-sensitive |
Country Status (3)
Country | Link |
---|---|
US (1) | US20160239470A1 (en) |
CN (1) | CN105814556B (en) |
WO (1) | WO2015042819A1 (en) |
Cited By (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN106383590A (en) * | 2016-09-06 | 2017-02-08 | 珠海格力电器股份有限公司 | Intelligent input method and apparatus |
CN109933785A (en) * | 2019-02-03 | 2019-06-25 | 北京百度网讯科技有限公司 | Method, apparatus, equipment and medium for entity associated |
CN111125509A (en) * | 2018-10-31 | 2020-05-08 | 微软技术许可有限责任公司 | Language classification system |
CN111989741A (en) * | 2018-03-26 | 2020-11-24 | 美的集团股份有限公司 | Voice-based user interface with dynamically switchable endpoints |
CN113534973A (en) * | 2020-04-16 | 2021-10-22 | 北京搜狗科技发展有限公司 | Input method, input device and input device |
Families Citing this family (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN108536859A (en) * | 2018-04-18 | 2018-09-14 | 北京小度信息科技有限公司 | Content authentication method, apparatus, electronic equipment and computer readable storage medium |
US20220164537A1 (en) * | 2020-11-23 | 2022-05-26 | Optum Technology, Inc. | Natural language processing techniques for sequential topic modeling |
US11481547B2 (en) * | 2021-01-06 | 2022-10-25 | Tencent America LLC | Framework for chinese text error identification and correction |
CN112818663A (en) * | 2021-01-15 | 2021-05-18 | 北京有竹居网络技术有限公司 | Processing method for language model, text generation method, text generation device and medium |
Citations (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN1387650A (en) * | 1999-11-05 | 2002-12-25 | 微软公司 | Language input architecture for converting one text form to another text form with minimized typographical errors and conversion errors |
CN101334704A (en) * | 2008-06-27 | 2008-12-31 | 中国科学院软件研究所 | Multichannel Chinese input method facing to mobile equipment |
CN101639830A (en) * | 2009-09-08 | 2010-02-03 | 西安交通大学 | Chinese term automatic correction method in input process |
CN101681229A (en) * | 2007-04-26 | 2010-03-24 | 株式会社爱可信 | Input candidate providing device, input candidate providing system, input candidate providing method, and input candidate providing program |
CN102439542A (en) * | 2009-03-30 | 2012-05-02 | 触摸式有限公司 | Text input system and method of electronic device |
JP2013045413A (en) * | 2011-08-26 | 2013-03-04 | Fujitsu Frontech Ltd | Input candidate display method and program |
Family Cites Families (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7165019B1 (en) * | 1999-11-05 | 2007-01-16 | Microsoft Corporation | Language input architecture for converting one text form to another text form with modeless entry |
US10191654B2 (en) * | 2009-03-30 | 2019-01-29 | Touchtype Limited | System and method for inputting text into electronic devices |
US9189472B2 (en) * | 2009-03-30 | 2015-11-17 | Touchtype Limited | System and method for inputting text into small screen devices |
US9424246B2 (en) * | 2009-03-30 | 2016-08-23 | Touchtype Ltd. | System and method for inputting text into electronic devices |
GB201003628D0 (en) * | 2010-03-04 | 2010-04-21 | Touchtype Ltd | System and method for inputting text into electronic devices |
-
2013
- 2013-09-26 CN CN201380079899.4A patent/CN105814556B/en active Active
- 2013-09-26 US US15/024,610 patent/US20160239470A1/en not_active Abandoned
- 2013-09-26 WO PCT/CN2013/084289 patent/WO2015042819A1/en active Application Filing
Patent Citations (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN1387650A (en) * | 1999-11-05 | 2002-12-25 | 微软公司 | Language input architecture for converting one text form to another text form with minimized typographical errors and conversion errors |
CN101681229A (en) * | 2007-04-26 | 2010-03-24 | 株式会社爱可信 | Input candidate providing device, input candidate providing system, input candidate providing method, and input candidate providing program |
CN101334704A (en) * | 2008-06-27 | 2008-12-31 | 中国科学院软件研究所 | Multichannel Chinese input method facing to mobile equipment |
CN102439542A (en) * | 2009-03-30 | 2012-05-02 | 触摸式有限公司 | Text input system and method of electronic device |
CN101639830A (en) * | 2009-09-08 | 2010-02-03 | 西安交通大学 | Chinese term automatic correction method in input process |
JP2013045413A (en) * | 2011-08-26 | 2013-03-04 | Fujitsu Frontech Ltd | Input candidate display method and program |
Cited By (8)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN106383590A (en) * | 2016-09-06 | 2017-02-08 | 珠海格力电器股份有限公司 | Intelligent input method and apparatus |
CN111989741A (en) * | 2018-03-26 | 2020-11-24 | 美的集团股份有限公司 | Voice-based user interface with dynamically switchable endpoints |
CN111989741B (en) * | 2018-03-26 | 2023-11-21 | 美的集团股份有限公司 | Speech-based user interface with dynamically switchable endpoints |
CN111125509A (en) * | 2018-10-31 | 2020-05-08 | 微软技术许可有限责任公司 | Language classification system |
CN111125509B (en) * | 2018-10-31 | 2024-04-26 | 微软技术许可有限责任公司 | Language classification system |
CN109933785A (en) * | 2019-02-03 | 2019-06-25 | 北京百度网讯科技有限公司 | Method, apparatus, equipment and medium for entity associated |
CN109933785B (en) * | 2019-02-03 | 2023-06-20 | 北京百度网讯科技有限公司 | Method, apparatus, device and medium for entity association |
CN113534973A (en) * | 2020-04-16 | 2021-10-22 | 北京搜狗科技发展有限公司 | Input method, input device and input device |
Also Published As
Publication number | Publication date |
---|---|
WO2015042819A1 (en) | 2015-04-02 |
US20160239470A1 (en) | 2016-08-18 |
CN105814556B (en) | 2019-09-13 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN105814556A (en) | Context sensitive input tools | |
KR102596446B1 (en) | Modality learning on mobile devices | |
US9508028B2 (en) | Converting text strings into number strings, such as via a touchscreen input | |
CN106202059B (en) | Machine translation method and machine translation device | |
JP5362095B2 (en) | Input method editor | |
US9824085B2 (en) | Personal language model for input method editor | |
US8812302B2 (en) | Techniques for inserting diacritical marks to text input via a user device | |
CN101785000B (en) | Word probability determination method and system | |
US20170046330A1 (en) | Context specific language model for input method editor | |
KR20100015958A (en) | Multi-mode input method editor | |
US10325018B2 (en) | Techniques for scheduling language models and character recognition models for handwriting inputs | |
CN101815996A (en) | Detect name entities and neologisms | |
CN103558908A (en) | Techniques for assisting a user in the textual input of names of entities to a user device in multiple different languages | |
US8806384B2 (en) | Keyboard gestures for character string replacement | |
KR101509727B1 (en) | Apparatus for creating alignment corpus based on unsupervised alignment and method thereof, and apparatus for performing morphological analysis of non-canonical text using the alignment corpus and method thereof | |
Haque et al. | Automated word prediction in bangla language using stochastic language models | |
US10152473B2 (en) | English input method and input device | |
WO2020178856A1 (en) | A chatbot system using asynchronous dialog state machine | |
CN110837730B (en) | Method and device for determining unknown entity vocabulary | |
CN111176456B (en) | Input method editor for inputting geographic location names | |
US20130289975A1 (en) | Electronic device and method for a bidirectional context-based text disambiguation | |
CN115035890B (en) | Training method and device of voice recognition model, electronic equipment and storage medium | |
US10789410B1 (en) | Identification of source languages for terms | |
US9176948B2 (en) | Client/server-based statistical phrase distribution display and associated text entry technique | |
US11934779B2 (en) | Information processing device, information processing method, and program |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
C06 | Publication | ||
PB01 | Publication | ||
C10 | Entry into substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
CB02 | Change of applicant information |
Address after: American CaliforniaApplicant after: Google limited liability companyAddress before: American CaliforniaApplicant before: Google Inc. |
|
CB02 | Change of applicant information | ||
GR01 | Patent grant | ||
GR01 | Patent grant |