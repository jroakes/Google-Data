CN110168606A - Composograph is generated from physical item - Google Patents
Composograph is generated from physical item Download PDFInfo
- Publication number
- CN110168606A CN110168606A CN201680083169.5A CN201680083169A CN110168606A CN 110168606 A CN110168606 A CN 110168606A CN 201680083169 A CN201680083169 A CN 201680083169A CN 110168606 A CN110168606 A CN 110168606A
- Authority
- CN
- China
- Prior art keywords
- image
- pixel value
- camera
- subsequent
- physical item
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N1/00—Scanning, transmission or reproduction of documents or the like, e.g. facsimile transmission; Details thereof
- H04N1/00127—Connection or combination of a still picture apparatus with another apparatus, e.g. for storage, processing or transmission of still picture signals or of information associated with a still picture
- H04N1/00132—Connection or combination of a still picture apparatus with another apparatus, e.g. for storage, processing or transmission of still picture signals or of information associated with a still picture in a digital photofinishing system, i.e. a system where digital photographic images undergo typical photofinishing processing, e.g. printing ordering
- H04N1/00183—Photography assistance, e.g. displaying suggestions to the user
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N9/00—Details of colour television systems
- H04N9/64—Circuits for processing colour signals
- H04N9/74—Circuits for processing colour signals for obtaining special effects
- H04N9/76—Circuits for processing colour signals for obtaining special effects for mixing of colour signals
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T7/00—Image analysis
- G06T7/10—Segmentation; Edge detection
- G06T7/11—Region-based segmentation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T7/00—Image analysis
- G06T7/10—Segmentation; Edge detection
- G06T7/13—Edge detection
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N23/00—Cameras or camera modules comprising electronic image sensors; Control thereof
- H04N23/10—Cameras or camera modules comprising electronic image sensors; Control thereof for generating image signals from different wavelengths
- H04N23/12—Cameras or camera modules comprising electronic image sensors; Control thereof for generating image signals from different wavelengths with one sensor only
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N23/00—Cameras or camera modules comprising electronic image sensors; Control thereof
- H04N23/60—Control of cameras or camera modules
- H04N23/63—Control of cameras or camera modules by using electronic viewfinders
- H04N23/631—Graphical user interfaces [GUI] specially adapted for controlling image capture or setting capture parameters
- H04N23/632—Graphical user interfaces [GUI] specially adapted for controlling image capture or setting capture parameters for displaying or modifying preview images prior to image capturing, e.g. variety of image resolutions or capturing parameters
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N23/00—Cameras or camera modules comprising electronic image sensors; Control thereof
- H04N23/60—Control of cameras or camera modules
- H04N23/63—Control of cameras or camera modules by using electronic viewfinders
- H04N23/633—Control of cameras or camera modules by using electronic viewfinders for displaying additional information relating to control or operation of the camera
- H04N23/635—Region indicators; Field of view indicators
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N23/00—Cameras or camera modules comprising electronic image sensors; Control thereof
- H04N23/60—Control of cameras or camera modules
- H04N23/64—Computer-aided capture of images, e.g. transfer from script file into camera, check of taken image quality, advice or proposal for image composition or decision on when to take image
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N23/00—Cameras or camera modules comprising electronic image sensors; Control thereof
- H04N23/60—Control of cameras or camera modules
- H04N23/698—Control of cameras or camera modules for achieving an enlarged field of view, e.g. panoramic image capture
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N23/00—Cameras or camera modules comprising electronic image sensors; Control thereof
- H04N23/70—Circuitry for compensating brightness variation in the scene
- H04N23/743—Bracketing, i.e. taking a series of images with varying exposure conditions
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N23/00—Cameras or camera modules comprising electronic image sensors; Control thereof
- H04N23/80—Camera processing pipelines; Components thereof
- H04N23/84—Camera processing pipelines; Components thereof for processing colour signals
- H04N23/88—Camera processing pipelines; Components thereof for processing colour signals for colour balance, e.g. white-balance circuits or colour temperature control
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N5/00—Details of television systems
- H04N5/222—Studio circuitry; Studio devices; Studio equipment
- H04N5/262—Studio circuits, e.g. for mixing, switching-over, change of character of image, other special effects ; Cameras specially adapted for the electronic generation of special effects
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T2207/00—Indexing scheme for image analysis or image enhancement
- G06T2207/10—Image acquisition modality
- G06T2207/10024—Color image
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N23/00—Cameras or camera modules comprising electronic image sensors; Control thereof
- H04N23/60—Control of cameras or camera modules
- H04N23/68—Control of cameras or camera modules for stable pick-up of the scene, e.g. compensating for camera body vibrations
- H04N23/682—Vibration or motion blur correction
- H04N23/683—Vibration or motion blur correction performed by a processor, e.g. controlling the readout of an image memory
Abstract
A method of computer implementation, the first image including capturing physical item with camera in first camera position, based on the first image, detection with the associated boundary of physical item, generate include multiple objects superimposed layer, multiple objects be located at within the associated more than one boundary of physical item, with the subsequent image of camera capture physical item, each subsequent image wherein is captured in corresponding subsequent camera position, and during capturing subsequent image, display includes the image preview of superimposed layer.This method further comprises the corresponding relationship established between the pixel of the first image and the pixel of each subsequent image, and generates the composograph of physical item, and wherein each pixel value of composograph is the respective pixel value based on the first image and subsequent image.
Description
Cross reference to related applications
This application claims the U.S. of entitled " generating electronic image from entity object " for submitting on June 8th, 2016 is interim
Patent application No.62/347,572 priority are combined entire contents herein by quoting.
Background technique
People often possess the entity photo for commemorating the critical event in their lives.Entity photo is converted into electronic edition
Originally it may be advantageous.For example, because people may lose entity photo or entity photo and can be damaged, entity
Photo is delicate.People, which may prefer to them, can share, searches for and be organized into the electronic edition of electron album
This.However, it may be difficult to which entity photo is converted to attracting image.
When capturing the image of entity photo with camera, light may be reflected by entity photo, and may include with image
The mode of dazzle is captured by a camera.Due to the relative position of light source, entity photo and camera, in fact it could happen that dazzle.Dazzle is also
It may be caused by using flash of light during image capture.Because lacking image detail in the part for having dazzle, dazzle quilt
It is interpreted as low-quality image.For example, Fig. 1 illustrates how due to the light source of eminence on entity photo when capture and
Conversion image 100 is caused to may include dazzle 101.
Background description provided herein is the background in order to which the disclosure is substantially presented.In this background technology part
The work for the inventor of the degree of description currently signed and submit when may be not additionally as the prior art
The aspect of specification both ambiguously or was not impliedly recognized as the prior art for being directed to the disclosure.
Summary of the invention
Embodiment relates generally to generate the computer implemented method of composograph.This method is included in first camera position
Set the first image with camera capture physical item.This method further comprises detection and the associated boundary of the physical item.
This method further comprises generating superimposed layer based on the first image, and the superimposed layer includes being located at and the physical item
Multiple objects within the associated more than one boundary.This method further comprises capturing the entity with the camera
The subsequent image of article, wherein capturing each subsequent image in corresponding subsequent camera position.This method further comprises catching
During obtaining the subsequent image, display includes the image preview of the superimposed layer.As the camera is mobile, the multiple object
It is kept fixed in the superimposed layer.In response to capturing the subsequent image of predetermined quantity in each corresponding subsequent camera position,
Update the attribute of an object in the multiple object.The attribute for updating the multiple object corresponds to the complete of capture
At.This method further comprises the corresponding relationship established between the pixel of the first image and the pixel of each subsequent image.The party
Method further comprises the composograph for generating the physical item, wherein each pixel value of the composograph is based on institute
State the corresponding pixel value of the first image and the subsequent image.
In some embodiments, superimposed layer further comprises graticule, which moves in response to mobile camera, and
It is Chong Die with object in response at least part graticule and capture subsequent image.In some embodiments, the superimposed layer is into one
Step includes arrow, and the arrow is directed toward the direction of the mobile graticule.In some embodiments, in response to the first image
Size be more than predetermined threshold, the superimposed layer is partitioned into multiple portions, and by each object in the multiple object
It is placed on the center of various pieces.In some embodiments, in response to the detection with the first image it is associated at least one set
Certainty value is more than threshold confidence value, and the superimposed layer is partitioned into multiple portions, and by each of the multiple object
Object is placed on the center of various pieces.In some embodiments, attribute is color, and updates the institute of the multiple object
Stating color there is the instruction completed.In some embodiments, in response to updating the object in the multiple object
The attribute, remove the object from the superimposed layer.In some embodiments, each pixel value of the composograph
It is the minimum value in the corresponding pixel value of the first image and the subsequent image.In some embodiments, raw
At each pixel value that the composograph further comprises for the composograph, Selection experiment pixel value, and will be described
Test pixel value is compared with the surrounding pixel values of pixel, is existed with each surrounding pixel values confirmed in the surrounding pixel values
Within the threshold difference of the test pixel value, the pixel surrounds the pixel corresponding to the pixel value.In some embodiments
In, it is more than the threshold value in response to the difference between a surrounding pixel values in the test pixel value and the surrounding pixel values
The test pixel value is revised as within the threshold difference by difference.
In some embodiments, system includes that more than one processor and storage are executed by more than one processor
The memory of the instruction instruction include: to show the first image, and color addition layer with the first image of camera capture physical item
On the first part of the first image, capture the more than one subsequent image of physical item, wherein with camera relative to
Physical item is mobile and captures each subsequent image, during capturing each subsequent image, shows the first image, and color addition
Layer on the second part of the first image, wherein second part include first part and based on camera mobile determination it is attached
Add part, establishes the correspondence between the pixel of each subsequent image in the pixel and more than one subsequent image of the first image
Relationship, and the composograph of physical item is generated, wherein each pixel value of composograph is based on the first image and one
The respective pixel value of above subsequent image.
In some embodiments, which further comprises that the first image is converted to pre-set aspect ratio, in response to
One image be inverted and it is at least one of lateral by the first amending image be face-up, and correct using white balance the
The ingredient of one image.In some embodiments, the superimposed layer further comprises target, and the target is placed as instruction and moves
Move the direction of the camera.In some embodiments, the target is moved as the camera is mobile.
In some embodiments, this method may include with camera capture first camera position physical item the
The means of one image.This method may further include the means of detection with the associated boundary of the physical item.This method can
To further comprise the means for generating superimposed layer based on the first image, the superimposed layer includes being located at and the physical item
Multiple objects within the associated more than one boundary.This method may further include described in camera capture
The means of the subsequent image of physical item, wherein capturing each subsequent image in respective subsequent camera position.This method can be with
It further comprise during capturing the subsequent image, display includes the means of the image preview of the superimposed layer.With described
Camera is mobile, and the multiple object is kept fixed in the superimposed layer.In response to pre- in respective subsequent camera position capture
The subsequent image of fixed number amount updates the color of an object in the multiple object.Update the color pair of the multiple object
It should be in the completion of capture.This method may further include between the pixel for establishing the first image and the pixel of each subsequent image
Corresponding relationship means.This method may further include the means for generating the composograph of the physical item, wherein institute
The each pixel value for stating composograph is the corresponding pixel value based on the first image and the subsequent image.
System and method as described below advantageously solve the dazzle and puppet generated by the image of capture physical item
The problem of picture.In addition, system and method as described below can reduce or eliminate fuzzy, when fuzzy image from capture, shakes
Dynamic hand.
The system and method that the technical advantage of the application is discussed further below generate user interface, which mentions for user
For capturing the guidance of image, this leads to the composograph for generating high-quality.For example, user interface provides physical item and capture figure
The instruction of optimum distance between the mobile device of picture.In addition, user interface provides the instruction of the direction of adjustment mobile device, with
It causes for example by the way that mobile device to be placed in parallel to the plane of physical item, captured image does not have trapezoidal pseudomorphism.
In addition, by the game of creation capture image, system and method avoid providing for user on how to capture entity
The complicated instruction of the image of article.User interface guidance user horizontally and vertically moves the mobile device, to capture
Subsequent image.For example, user can enjoy mobile mobile device, to cover the dot in superimposed layer with graticule.Show at another
In example, user can enjoy mobile mobile device, so that appearing to paint color onto image.In the same of capture image
When, user interface also guides user slowly to move the mobile device, with the image for preventing capture fuzzy.
Another technical advantage is that system and method eliminate dazzle and pseudomorphism by generating composograph.Such as pass through
Relative to the mobile camera of physical item, from the multiple images of different camera position capture physical items.Captured image is by group
It closes, and selects pixel value from captured image, to reduce or eliminate dazzle.Composograph includes the image from actual acquisition
Determining pixel value, and the pixel value not with may itself include the adjacent pixel values of dazzle it is approximate.
Another technical advantage is can to carry out image capture with any lighting condition, and do not need specified light source
Configuration, camera and physical item.In addition, system and method can be carried out by mobile device, rather than carried out by special equipment, it is all
Such as flat bed scanner.
Detailed description of the invention
By way of example rather than the disclosure is illustrated by the figure in limitation attached drawing, in the accompanying drawings, identical reference number
For element as referenced classes.
Fig. 1 illustrates the graphical representations of the photo of the prior art.
Fig. 2 illustrates the block diagram that the example system of composograph is generated according to the slave physical item of some embodiments.
Fig. 3 illustrates the box that the EXEMPLARY COMPUTING DEVICE of composograph is generated according to the slave physical item of some embodiments
Figure.
Fig. 4 A illustrates the graphical representation of the image comprising four dots, in the quadrant that four each leisures of dot detect.
Fig. 4 B illustrates the graphical representation of the mobile device of display superimposed layer and longitudinal image.
Fig. 4 C illustrates the graphical representation of the mobile device of display superimposed layer and askew image.
Fig. 4 D illustrates the graphical representation of the mobile device of display superimposed layer and small image.
Fig. 4 E illustrates the graphical representation of display superimposed layer and the mobile device without image.
Fig. 4 F illustrates the graphical representation of the mobile device of display superimposed layer and angled image.
Fig. 4 G illustrates the graphical representation of the mobile device of display superimposed layer and landscape images.
Fig. 5 A illustrates the graphical representation of the mobile device of display superimposed layer, and there are four object and graticules for superimposed layer tool.
Fig. 5 B illustrates display graticule around the graphical representation of the mobile device of the superimposed layer of the first object.
Fig. 5 C illustrates display graticule around the graphical representation of the mobile device of the superimposed layer of the second object.
Fig. 5 D illustrates display graticule around the graphical representation of the mobile device of the superimposed layer of third object.
Fig. 5 E illustrates display graticule around the graphical representation of the mobile device of the superimposed layer of the 4th object.
Fig. 5 F illustrates the graphical representation for the mobile device that display capture processing is completed.
Fig. 6 A illustrates the shifting of the color addition layer being shown on the first part of image according to some embodiments
The graphical representation of dynamic device.
Fig. 6 B illustrates the example user according to the color addition layer of some embodiments on the second part of image
The graphical representation at interface.
Fig. 6 C illustrates the example user interface according to the color addition layer of some embodiments on all images
Graphical representation.
Fig. 7 illustrates the flow chart that the exemplary method of composograph is generated according to the slave physical item of some embodiments.
Fig. 8 illustrates the stream that another exemplary method of composograph is generated according to the slave physical item of some embodiments
Cheng Tu.
Specific embodiment
In some embodiments, the first image of camera capture physical item.For example, the physical item is photo.With
The associated boundary of the physical item is detected.For example, photo general shape is as rectangle, and boundary may be rectangle.It can be with
Superimposed layer is generated based on the first image, which includes object and graticule, and wherein the object is located at and the physical objects
Within the associated boundary of product.For example, the first image includes positioned at four blue dots at the edge of rectangle and the graticule at center.
The subsequent image of physical item is captured, wherein capturing each subsequent image using corresponding subsequent camera position.
For example, user may tilt and rotary camera, subsequent image is captured at different angles.During the capture of subsequent image,
Display includes the image preview of superimposed layer.As camera is mobile, multiple objects are still secured in the superimposed layer.Graticule in response to
It moves camera and moves.It is be overlapped with one in object in response at least part graticule and capture subsequent image.For example, user
Can move camera to the lower left corner object.
In response to the capture of the subsequent image of the predetermined quantity in each corresponding subsequent camera position, the category of upgating object
Property.For example, blue dot changes into grey dot.In response to mpving wire until the attribute of multiple objects is updated, capture
It completes to occur.For example, graticule is moved to second object in the lower right corner by user from the first object, the of the upper right corner is then moved to
Three objects then move to the 4th object in the upper left corner.Once all objects change into grey, capture is just completed.One
In a little embodiments, after the color of object is updated, the instruction of completion occurs.For example, showing the green of hook-type symbol
Circle.
Example system
Fig. 2 illustrates the block diagram for generating the example system 200 of composograph.The system 200 of diagram includes media services
Device 111, mobile device 115a, 115n and network 105.User 125a, 125n can with respective mobile device 115a,
115n association.In some embodiments, system 200 may include other servers or device that Fig. 1 is not shown.In Fig. 1
In remaining figure, letter after reference number, such as " 115a " indicate the reference to the element with particular reference number.This
The reference number of letter, such as " 115 " are not followed in text, indicate the embodiment for undertaking the element of that reference number
General reference.
In the illustrated embodiment, the entity of system 200 is communicatively coupled via network 105.Network 105 can be
It is common type, wired or wireless, and can have numerous different configurations, comprising star like arrangement, token ring configuration or
Other configurations.In addition, network 105 may include local area network (LAN), wide area network (WAN) (for example, internet), and/or multiple dresses
Set the data path for other interconnection that can be communicated by it.In some embodiments, network 105 can be peer-to-peer network
Network.Network 105 can also be coupled to a part of telecommunicatio network or a part including telecommunicatio network, telecommunication
A part of net is used to send data with a variety of different communication protocols.In some embodiments, network 105 includes for sending out
Send and receive dataCommunication network,Or honeycomb communicating network, send and receive data include via
Short message service (SMS), multimedia messaging service (MMS), Hypertext Transmission Protocol (HTTP), immediate data connection, electronics
Mail etc..Although practical Fig. 1 illustrates a network 105 for being couple to mobile device 115 and media server 111
Upper more than one network 105 can be coupled to these entities.
Media server 111 may include processor, memory and network communications capability.In some embodiments, media
Server 111 is hardware server.Media server 111 is communicatively coupled to network 105 via signal wire 102.Signal wire
102 can be wired connection, such as Ethernet, coaxial cable, fiber optic cables etc., or can be wireless connection, such as Or other wireless technologys.In some embodiments, media server 111 is sent via network 105
Data give more than one mobile device 115a, 115n, and receive data from more than one 115a, 115n.Media server
111 may include media application 103a and database 199.
Media application 103a can be the code and routine program for being operable as generating composograph.In some embodiments
In, hardware can be used to realize media application 103a, which includes field programmable gate array (FPGA) or dedicated collection
At circuit (ASIC).In some instances, the combination of hardware and software can be used to realize media application 103a.
Database 199 can store by giving birth to associated 125 captured image of user of mobile device 115 and from the image
At composograph.In some embodiments, database 199 can store the conjunction generated independent of mobile device 115
At image.Database 199 can also store and the associated social network data of user 125, the user preference of user 125 etc..
Mobile device 115 can be the computing device including memory, hardware processor and camera.For example, mobile device
It may include tablet computer, mobile phone, wearable device, the display of wear-type, mobile E-mail device, portable game
Gaming machine, portable music player, reading device or other electronic devices for being able to access that network 105.
In the illustrated embodiment, mobile device 115a is coupled to network 105 via signal wire 108, and mobile
Device 115n is coupled to network 105 via signal wire 110.Signal wire 108 and 110 can be wired connection, such as Ethernet,
Coaxial cable, fiber optic cables etc., or can be wireless connection, such as Or other wireless technologys.
Mobile device 115a, 115n are respectively by user 125,125n access.Mobile device 115a, 115n in Fig. 1 is used for example.Although
Fig. 1 illustrates two mobile devices 115a and 115n, but the disclosure suitable for being with more than one mobile device 115
System structure.
In some embodiments, user apparatus 115 can be the shifting in the wearable device for including the wearing of user 125
Dynamic device.For example, mobile device 115 is included as a part of clip (for example, watchband), a part of jewellery or one
A part of pair of glasses.In another example, mobile device 115 can be smartwatch.User 125 can be from user 125
The display of the device of wearing checks the image from media application 103.For example, user 125 can be in smartwatch or intelligence
Image can be checked on the display of watchband.
In some instances, media application 103b can be stored on mobile device 115a.Media application 103 can wrap
The media for including the thin-client media application 103b being stored on mobile device 115a and being stored on media server 111 are answered
Use 103a.For example, the media application 103b being stored on mobile device 115a can be captured to be sent to and is stored in media services
The image of media application 103a on device 111, in media application 103a, composograph is generated from the image.Media application
Composograph can be transmitted to media application 103b by 103a, for being shown in mobile device 115a.In another example,
Composograph can be generated in the media application 103b being stored on mobile device 115a, and the composograph is transmitted to and is stored in
Media application 103a on media server 111.The media application 103a being stored on media server 111 may include and deposit
Store up the identical component of media application 103b or different components stored on mobile device 115a.
The system and method discussed herein can collect or using the personal information about user (for example, number of users
According to, the information of the social networks about user, the position of user, the biological information of user, activity and the demographics letter of user
Breath, media server storage and analysis video) situation in, provided for user control whether collection information, whether store individual
Information, whether using personal information, whether analyze video and how to collect, store and using the information about user machine
Meeting.That is, only receiving the express authorization that does so from relevant user, system and method discussed here just collect,
Store, and/or use userspersonal information.For example, for user provide to program or characteristic whether collect with specific user or
The control of the related user information of person's other users related with the program or feature.Each use of personal information will be collected
Family, which is presented with, allows to control the more than one option that information related with that user is collected, in order to provide whether letter is collected
Breath and to collect information which part license or authorization.For example, one can be provided for user by communication network
Above this control option.In addition, some data before by storage or use, can be located in a manner of more than one
It manages, to remove personal identifiable information.As an example, the identity information of user can be processed, for example, by hideing
Name can be determined without personal identifiable information from video.As another example, the geographical location of user can be general
It includes as biggish region, so that the specific position of user cannot be determined.
EXEMPLARY COMPUTING DEVICE
Fig. 3 illustrates the block diagram for generating the EXEMPLARY COMPUTING DEVICE 300 of composograph.Computing device 300 can be media
Server 111 or mobile device 115.Computing device 300 can be processor 235, memory 237, communication unit 239, display
Device 241, camera 243, sensor 245 and storage device 247.There may be additional components or some previous components can
It is omitted with the type according to computing device 300.For example, being calculated if computing device 300 is media server 111
Device 300 can not include display 241, camera 243 or sensor 245.Media application 103 can be stored in memory
In 237.In the embodiment that computing device 300 is wearable device, computing device 300 can not include storage device 247.
In some embodiments, computing device 300 may include the other component that do not list here, for example, battery etc..It calculates
The component of device 300 can be communicatively coupled by bus 220.
Processor 235 includes being calculated and being provided instructions to the arithmetic logic unit of display device, microprocessor, general
Controller or some other processor arrays.Processor 235 handles data, and may include various computing architectures, various
Computing architecture includes that Complex Instruction Set Computer (CISC) framework, Reduced Instruction Set Computer (RISC) framework or realization refer to
Enable the combined framework of collection.Although Fig. 2 includes single processor 235, it may include multiple processors 235.Other processing
Device, operating system, sensor, display and physical configuration may belong to the computing device 300.Processor 235 is via signal wire
222 are coupled to bus 220, for communicating with other component.
Memory 237 stores the instruction and/or data that can be executed by processor 235.Instruction may include is retouched here
The code for the technology stated.Memory 237 can be dynamic random access memory (DRAM) device, static random access memory
(static RAM) or some other storage devices.In some embodiments, memory 237 further include such as (SRAM) device or
The nonvolatile memory of person's flash memory or similar permanent storage and medium, similar permanent storage and medium
Including hard disk drive, compact disc read-only memory (CD-ROM) device, DVD-ROM device, DVD-RAM device, DVD-RW device,
Flash memory device or some other high-capacity storages for storing information in a manner of more permanent.Memory 237 includes
It is operable as executing the code and routine program of media application 103, will be described in further detail below.Memory 237 is via signal
Line 224 is coupled to bus 220, for communicating with other component.
According to the stored place of media application 103, communication unit 239 transfers data to mobile device 115 and media clothes
At least one of business device 111, and data are received from least one of mobile device 115 and media server 111.One
In a little embodiments, communication unit 239 includes directly being physically connected to network 105 or the port of another communication channel.Example
Such as, according to the stored place of media application 103, communication unit 239 include for mobile device 115 or media server
The universal serial bus (USB) of 111 wire communications, secure digital (SD), 5 class cables (CAT-5) or similar port.?
In some embodiments, communication unit 239 includes being taken using more than one wireless communications method and mobile device 115, media
The wireless transceiver for device 111 or other communication channels exchange data of being engaged in, more than one wireless communications method include
IEEE802.11, IEEE802.16,Or another suitable wireless communications method.Communication unit 239 is by via letter
Number line 226 is couple to bus 220, for communicating with other component.
In some embodiments, communication unit 239 includes for sending and receiving number by honeycomb communicating network
According to cellular communication transceiver, sending and receiving data includes via short message service (SMS), multimedia messaging service
(MMS), the electronics of Hypertext Transmission Protocol (HTTP), immediate data connection, Email or another suitable type is logical
Letter.In some embodiments, communication unit 239 includes cable port and wireless transceiver.Use computer network with standard network protocol, communication
Unit 239 also provides other traditional connections to network 105, for the distribution of file and/or media object, standard network association
View includes but is not limited to User Datagram Protocol (UDP), TCP/IP, HTTP, HTTP safety (HTTPS), simple mail transmission association
Discuss (SMTP), SPDY, the quick internet UDP connection (QUIC) etc..
Display 241 may include the hardware for being operable as showing from the received graph data of media application 103.For example,
Display 241 can render figure to show superimposed layer and resulting composograph.Display 241 is via signal wire 228
It is coupled to bus 220, for communicating with other component.
Camera 243 may include the hardware for being operable as the image of capture physical item.For example, camera 243 may include
Lens, sensor and image-signal processor.Lens can capture optical imagery.Optical imagery can be converted to electricity by sensor
Signal.Image-signal processor can carry out demosaicing to the electric signal, to determine pixel color and control image effect,
It is such as automatic to focus, exposure and white balance.The image can be sent to media application 103 or storage device by camera 243
247.Camera 243 can be coupled to bus 220 via signal wire 230.
Sensor 245 may include the hardware for being operable as determining the change in location of mobile device 115.For example, sensor
245 may include measurement along x, the motion sensor of the acceleration and rotary force of y and z-axis, such as accelerometer and gyroscope.
Sensor 245 can also include the position sensor of the physical location of measurement mobile device 115, such as towards sensor and magnetic force
Meter.Sensor 245 is coupled to bus 220 via signal wire 232, for communicating with other component.
Storage device 247 can be the non-transitorycomputer readable storage medium of storing data, which provides here
The function of description.In the embodiment that computing device 300 is media server 111, storage device 247 be may include in Fig. 1
Database 199.Storage device 247 can be DRAM device, SRAM device, flash memory or some other storage devices.One
In a little embodiments, storage device 247 further includes Nonvolatile memory or similar permanent storage and medium, including hard
Disk drive, CD-ROM device, DVD-ROM device, DVD-RAM device, DVD-RW device, flash memory device or for forever
Long mode stores some other high-capacity storages of information.Storage device 247 is coupled to bus via signal wire 234
220, for being communicated with other component.
Media application 103 may include trapping module 202, subscriber interface module 204 and synthesis module 206.
Trapping module 202 handles 243 captured image of camera.In some embodiments, trapping module 202 includes processing
One group of instruction of the executable processing image of device 235.In some embodiments, image processing module 202 is stored in calculating
In the memory 237 of device 300, and it can access and execute with device 235 processed.
Trapping module 202 receives the first image of the physical item in first camera position from camera 243.For example, packet
Mobile device 115 is placed on physical item by the user for including the mobile device 115 of camera 243, and selects capture first
The option of image.Physical item for example may include photo, billboard, document, restaurant menu etc..
Trapping module 202 can carry out the processing of the first image.For example, trapping module 202 can trim the first image or
Person modifies the first image, to be suitble to specific aspect ratio.Vertical-horizontal proportion such as may include 1:1,4:3,16:9 etc..Trapping module
202 directions (for example, inverted, lateral etc.) that can identify the first image, and the first image is turned to and is just faced
On.Trapping module 202 can correct the ingredient of the first image using white balance.
The detection of trapping module 202 and the associated boundary of physical item.For example, trapping module 202 can determine the physical objects
Product have the rectangular shape with four edges circle.Other shapes are possible.For example, physical item can have the shape of triangle
Shape, square shape is round, ellipse, diamond shape etc..Subscriber interface module 204 may include on how to move
Device 115 is placed on the user instruction on physical item.For example, the instruction may include following text: " placing your photo
Four all angles are seen." this can help trapping module 202 to detect boundary.
Trapping module 202 indicates that the subscriber interface module 204 display has the superimposed layer of object, which is located at and entity
Within the boundary of item associations.In some embodiments, the first image segmentation is become multiple portions by trapping module 202, and
And the display of indicative user interface module 204 has the superimposed layer of object, center of each object a part.For example, photo
It can be divided into quadrant, each quadrant may include the dot at the center in each quadrant.In another example,
One image can be divided into the part of different numbers, and such as five parts or triangular shaped physical item can be with
It is divided into three parts of different shapes etc..Fig. 4 A is illustrated comprising four dots 405a, 405b, 405c, 405d
The graphical representation 400 of image, in quadrant 410a, 410b, 410c, 410d that each leisure of these dots detects.Object can wrap
A variety of different shapes are included, such as round, oval, square, rectangle, parallelogram etc..
Trapping module 202 can determine the size of the first image.In some embodiments, trapping module 202 can incite somebody to action
First image is sized to the ratio of the area of the screen of mobile device 115.If the size of the first image is more than predetermined
Threshold value, then trapping module 202 can show superimposed layer with indicative user interface module 204, which is divided into multiple
Part, an object are in the center of a part.If the size of the first image is not above predetermined threshold, mould is captured
Block 202 can include the superimposed layer with default objects, all dots in this way of default objects with indicative user interface module 204.This is silent
Recognizing object can not be aligned with the partitioning portion of the first image, but can help that user's positioning mobile device 115 is guided to catch
Subsequent image is obtained, for creating composograph.In some embodiments, if default objects are resulted in including irrelevant contents
Composograph, all subsequent backgrounds of physical item in this way of irrelevant contents, then subscriber interface module 204 may include for cutting
Fall the trimming option of the irrelevant contents.
Trapping module 202 can distribute and the associated confidence value of the detection of the first image.Confidence value can reflect reality
The confidence level of the detection on the boundary of body article.If the confidence value is more than predetermined threshold, trapping module 202 can be indicated
Subscriber interface module 204 shows that superimposed layer, the superimposed layer are divided into multiple portions, and an object is in a part
The heart.If the confidence value is not above threshold confidence value, trapping module 202 can be with indicative user interface module 204
Including the superimposed layer with default objects.In some embodiments, the superimposed layer can size based on the first image and
Combination with the associated confidence value of the first image is divided into multiple portions.
In some embodiments, which includes graticule.Graticule can in the form of various shape, however, the graticule quilt
Display is used as profile.The graticule can be kept fixed size, but regardless of the size of the object in superimposed layer.In some instances,
Graticule is moved in response to the mobile mobile device 115 of user.Mpving wire is so that some or all graticules and an object weight
It folds so that mobile device 115 captures subsequent image.For example, the case where the first image is divided into four quadrants, mobile mark
Line is to Chong Die with four dots, and as a result four subsequent images are captured by mobile device 115.As mobile device 115 is moved,
Object can fixation position (for example, display image relative to physical item) still in superimposed layer.The size of object can
To change according to the distance between mobile device 115 and physical item.For example, the size of object can be with mobile device
115 move closer to physical item and increase, and have guiding mostly close to physical item to serve as mobile device 115.If with
User compares mobile device 115 further away from physical item, guides user that mobile device 115 is moved closer to reality
Body article advantageously ensures that image is high-quality.
Fig. 4 B illustrates the graphical representation 425 of the mobile device of display superimposed layer 426 and image.In this illustration, it marks
Line 427 is comprised in the center of superimposed layer 426, as starting point.Once capturing the first image, subscriber interface module 204 is just aobvious
Show the image preview including the superimposed layer.Mobile mobile device 428 makes graticule 427 mobile.While graticule 427 is mobile,
Object 429a, 429b, 429c and 429d are remained stationary.As a result, graticule 427 can be moved to and surround or overlapping object
429a, 429b, 429c and 429d.
In some embodiments, once graticule 427 surround object 429 or Chong Die with object 429, the graticule 427 just by
It is illustrated as rotating frame, which progressively changes color, catches to illustrate mobile device 115 in each corresponding subsequent camera position
Time quantum needed for obtaining the subsequent image of predetermined quantity.For example, being located at each corresponding subsequent camera position in mobile device 115
Meanwhile camera 243 can capture the subsequent image of high-quality for each quadrant.In some embodiments, camera 243 can be caught
Subsequent image is obtained, until the event other than the subsequent image of capture predetermined quantity.For example, camera 243 can capture it is subsequent
Image is associated with the merit scores for being more than predetermined value until trapping module 202 determines subsequent image, has already passed through predetermined time amount
Etc..
While camera 243 captures the subsequent image of predetermined quantity, graticule 427 can be switched to from complete white contours
A part of white contours change into blue (or another color), and it is straight progressively to become more blues in a clockwise direction
Instruction is received from camera 243 to predetermined time amount, the subsequent image for capturing predetermined quantity or trapping module 202 is had already passed through
The signal of subsequent image is captured.In some embodiments, once capture subsequent image, graticule 427 are surrounded or be overlapped
The attribute of object 429 just change.For example, object can change color, object can glisten or object can change ruler
It is very little.When the attribute of object changes, it can issue the signal that the capture of corresponding part is completed.For example, in figure 4b, graticule
427 are used for the subsequent image of first quartile around the first object 429a until capturing, and the color of object 429a changes from grey
Become blue.In some embodiments, before camera 243 is over capture subsequent image or multiple subsequent images,
In the case that the mobile camera 243 of user is far from physical item, trapping module 202 can be with indicative user interface module 204 by graticule
White is remained, as corresponding objects, capture needs the instruction being repeated.In some embodiments, if user does not have
Have mobile camera 243 with using graticule around an object exceeding predetermined time amount, such as 10 seconds, then capture can be cancelled,
And 202 indicative user interface module 204 of trapping module displays for a user the instruction for restarting capture.For example, the instruction can
To include: that " scanning is cancelled.Mobile circle is completed to scan next time to dot."
In some embodiments, the object in superimposed layer is parallel to the boundary detected.Therefore, if physical item with
Certain angle is captured, then the object in superimposed layer can be shown at the same angle.It is folded for example, Fig. 4 C illustrates display
Add the graphical representation 430 of the mobile device 433 of layer and askew image.Because changing ruler in size of the object 432 based on image
While very little, graticule 431 is fixed dimension, so for user to provide image too small for the size difference between graticule 431 and object 432
And the visual indicators to be moved to closer to photo of mobile device 433.
In some embodiments, it if trapping module 202 determines that the size of image is not above predetermined threshold, catches
Default objects can be shown with indicative user interface module 204 and/or omit graticule from superimposed layer by obtaining module 202.For example, Fig. 4 D schemes
The graphical representation 440 of the mobile device 441 of display superimposed layer and small image 442 is shown.Because the size of image is not above pre-
Threshold value is determined, so object 443 is default objects.Default objects are not or not the center of each quadrant, however, mobile device 115 is still
The first image and subsequent image can be captured.In another example, Fig. 4 E illustrates display superimposed layer and the shifting without image
The graphical representation 450 of dynamic device 451.In this illustration, even if being detected without image, trapping module 202 also indicates that use
The display of family interface module 204 has the superimposed layer of object 452.
In some embodiments, the object in superimposed layer can change shape as mobile device 115 is mobile.The shape
Shape may be used as giving the movement of the user of mobile device 115 indicator of the mobile device 115 to obtain optimized image.Some
In embodiment, if mobile device 115 is tiled relative to physical item more than 20 degree, the instruction of trapping module 202 is used
Family interface module 204 shows default objects.
Fig. 4 F illustrates the graphical representation 460 of the mobile device 461 of display superimposed layer and angled image.At this
In a example, mobile device 461 is angled relative to photo.Object 462a, 462b in superimposed layer top form ellipse
Circle, to indicate that mobile device 461 will be inclined by, so that mobile device 461 be made to be parallel to photo.Object in superimposed layer bottom
463a, 463b form the ellipse closer to circle, as long as to indicate that 115 bottom position of mobile device should be by slightly inclination
It is parallel to the photo.
The detection of trapping module 202 has the boundary of the physical item of different shape and direction.For example, Fig. 4 G illustrates display
The graphical representation 470 of the mobile device 471 of superimposed layer and landscape images.Trapping module 202 identifies the rectangular shape of image
Quadrant, and four objects 472 are generated, four objects 472 are each located on the center of each quadrant.
In some embodiments, 202 indicative user interface module 204 of trapping module generates superimposed layer, and the superimposed layer is first
It is first displayed on a part of image, and more next with the movement of mobile device 115 and the capture subsequent image of camera 243
Image is covered more.For example, superimposed layer can be color addition layer, and the processing can be presented as game, at this
User moves the mobile device 115 as spraying physical item in game.It is discussed in greater detail below with reference to Fig. 6 A-6C
These embodiments.
Subscriber interface module 204 generates user interface.In some embodiments, subscriber interface module 204 include can be by
Processor 235 is executed to generate one group of instruction of user interface.In some embodiments, subscriber interface module 204 is stored
In the memory 237 of computing device 300, and it can access and execute with device 235 processed.
In some embodiments, subscriber interface module 204 receives the instruction for generating user interface from trapping module 202,
The user interface includes superimposed layer, which includes object, the object be located at associated one of the image of physical item with
On boundary within.As camera 243 captures the subsequent image of physical item, wherein being captured using corresponding subsequent camera position
Each subsequent image, the display of subscriber interface module 204 include the image preview of superimposed layer.As camera is mobile, multiple objects are still
It is so fixed in the superimposed layer.In response to the subsequent image in each corresponding subsequent camera position capture predetermined quantity, user
Interface module 204 can such as change the color of object with the attribute of upgating object, so that object glistens, change the size of object
Etc..Subscriber interface module 204 can continue to update the attribute of subsequent object, and until all objects are updated, this corresponds to
The completion of capture.In some embodiments, subscriber interface module 204 also generates the graticule of a part as superimposed layer, and
And display graticule is moved in response to the movement of mobile device 115.In this illustration, graticule around object or with object weight
After folded, the color of object is updated, and is occurred in the subsequent image of each corresponding subsequent camera position capture predetermined quantity.
The first image and subsequent image are captured until the processing of completion is shown in Fig. 5 A-5F, it is discussed more thoroughly below
Fig. 5 A illustrates the graphical representation 500 of the mobile device 501 for the superimposed layer being shown on the first image, superimposed layer
There are four object 502a, 502b, 502c, 502d and graticules 503 for tool.In this illustration, trapping module 202 detects four sides
Boundary and by the first image segmentation become quadrant.202 indicative user interface module 204 of trapping module generates the use including superimposed layer
Family interface, the superimposed layer include four objects 502a, 502b, 502c, 502d, these objects are each comfortable or close to quadrant
Center.202 indicative user interface module 204 of trapping module includes graticule 503.Because mobile device 501 be parallel to photo and
Distance picture is not far, so graticule 503 is greater than object 502, as a result capture is the first image and subsequent image of high quality image.
Superimposed layer further includes arrow 504, and arrow 504 is directed toward the direction of mpving wire.In this illustration, arrow 504 is directed toward superimposed layer
The lower left corner in the first object 502a.User interface further includes stopping icon 505, and the stopping icon 505 is in response to user's
It selects and stopping processing.For example, screen in the position for stopping icon 505 is touched by user to select to stop icon 505, it can be with
Interrupt processing or fully stopping processing.Stop icon 505 and is maintained at the fixation position within user interface.
Fig. 5 B illustrates display graticule around the shifting of the first object 502a or the superimposed layer Chong Die with the first object 502a
The graphical representation 510 of dynamic device 501.In this illustration, once graticule 503 surrounds the first object 502a, the first object 502a
Size be just amplified, provide the graticule 503 with the user for mobile mobile device 501 and be recognized as around the first object 502
Instruction.In addition, subscriber interface module 204 updates the first object 502a and graticule 503 is different color, it is such as blue, with
The subsequent image or multiple subsequent images for indicating lower left quadrant have been captured.
Fig. 5 C illustrates the graphical representation of the mobile device 501 of the superimposed layer of second object 502b of the display encirclement of graticule 503
520.In this illustration, because having captured the subsequent image or multiple subsequent images of the first object respective quadrants,
The first object is removed from superimposed layer.504 Arch Bridges 503 of the arrow next object to be surrounded, next object is third pair
As 502c.Fig. 5 D illustrates display graticule around the graphical representation 530 of the mobile device 501 of the superimposed layer of third object 502c.
Fig. 5 E illustrates display graticule around the graphical representation 540 of the mobile device 501 of the superimposed layer of the 4th object 502d.
Fig. 5 F illustrates the graphical representation 550 for the mobile device 501 that display capture processing is completed.In this illustration, it uses
The completion of the form of hook-type symbol icon 551 of family interface module 204 indicates to replace the 4th object.Other completion instructions are can
With, the upward icon of such as thumb, green, smiling face etc..Subscriber interface module 204 is with the circular icon of such as green circle
Another of 552 form completes instruction to replace stopping icon.In this illustration, synthesis module 206 generates composograph
And subscriber interface module 204 shows that composograph icon 553, the composograph icon 553 show that composograph is generated, and
And (for example, by storing) is available in mobile device 501.For example, composograph can be stored in camera film, image
Within library, camera applications etc..
In some embodiments, subscriber interface module 204 shows the first image, color addition layer in the first image the
On a part.For example, subscriber interface module 204 generates user interface, the user interface is including the first image and first
The color addition layer of the bottom (or top, middle part etc.) of image.Color can be any color, such as blue, and black is green
Color etc..The first image and subsequent image are captured until the processing of completion is shown in Fig. 6 A-6C, is begged for more thoroughly below
By.
Fig. 6 A is gone to, the figure of the mobile device 601 for the color addition layer being shown on the first part of image is illustrated
Shape indicates 600.In this illustration, color addition layer includes about 40% image.The top of color addition layer arc 602
It delineates.In this illustration, color addition layer includes the target 604 that can be moved as mobile device 601 moves.For example,
If user moves up mobile device 601, target 604 can be moved up.In some embodiments, target 604
It is placed with the direction that the mobile mobile device 601 is indicated for user.For example, target 604 can be placement in this illustration
Indicate that mobile device 601 should be moved upward as user.
The more than one subsequent image of physical item can be captured, wherein as camera 243 is relative to physical item
It moves and captures each subsequent image.For example, user can from left to right, up and down or any other direction mobile move
Dynamic device 115.In some embodiments, the mobile mobile device 115 of user, as user sprays on physical item
Like that.In some embodiments, the mobile mobile device 115 of user, to capture mobile target.For example, color addition layer can be with
Icon including object, such as honeybee, and the mobile mobile device 115 of user is to capture the honeybee.Subscriber interface module 204 can
To modify the position of honeybee, to ensure that mobile device 115 is mobile in a manner of capturing subsequent image, subsequent image includes different
Rotation and inclination, reflect to avoid dazzle or light.
During capturing each subsequent image, the first image can be shown as color addition layer the second of the first image
On part.Second part may include first part and based on camera movement and the extention of determination.Fig. 6 B is gone to,
Illustrate the graphical representation 650 of the color addition layer on the second part of image.In this illustration, color addition layer covers
It covers about 90% image and is delineated with arc 652.User may use the fortune from left to right of mobile device 601
It moves as the first image colorant.
Fig. 6 C is gone to, the graphical representation 675 of example user interface of the color addition layer on all images is illustrated.?
In this example, in the case where the first image of color addition layer covering about 100%, color addition layer can indicate user
The spray treatment is completed.
In some embodiments, subscriber interface module 204 generates the user interface including option, which is used for from conjunction
Electron album is generated at image.For example, the processing for generating composograph for the old photo of a box can be used in user.User interface mould
Option can be generated in block 204, which is used to composograph being combined into different photograph albums, adds a tile to each synthesis
Image is agreed to once user with regard to other users in tag image etc..Subscriber interface module 204 can also generate option, should
Option is used for Edit and Compose image, and trimming modifies the appearance of composograph (for example, changing color saturation, exposure etc.
Deng), using filter etc..
Synthesis module 206 generates composograph.In some embodiments, synthesis module 206 include can be by processor 235
It executes to generate one group of instruction of composograph.In some embodiments, synthesis module 206 is stored in computing device 300
Memory 237 in, and can with device 235 processed access and execute.
Synthesis module 206 establishes the corresponding relationship between the pixel of the first image and the pixel of each subsequent image.Synthesis
Homography can be used to determine the first image and how relevant subsequent image is in module 206.For example, synthesis module 206 can
To generate homography matrix based on the rotation peace in-migration between image.Light stream can be used to determine by phase in synthesis module 206
Apparent motion caused by relative motion between machine 243 and physical item (apparent motion).For example, in capture first
During image and subsequent image, light stream is can be used to determine in media application 103, when camera 243 captures two images, is moved
It appears between two images.Synthesis module 206 can be used light stream and the dazzle on image be identified as movable part.
Synthesis module 206 can be used image registration and the pixel from the first image and subsequent image be converted into list
A coordinate system.For example, synthesis module 206 can generate coordinate system, the coordinate system based on the first image and subsequent image
Map the position of each pixel.Synthesis module 206 can for each location of pixels compared pixels value, and based on it is different because
Pixel value of the element selection for the location of pixels.For example, synthesis module 206 can determine that some pixel values indicate dazzle.As a result,
Because other pixel values or multiple pixel values may indicate dazzle, synthesis module 206 be can choose and most deep picture
The corresponding pixel value of element, rather than the pixel value of the color below dazzle.In another example, synthesis module 206 may be really
It is fixed that dazzle is indicated for no one of the pixel value of specific pixel location pixel value.As a result, synthesis module 206 can choose table
Show the pixel value of brightest pixel, so that more details from physical item are expressed in the composite image.In some implementations
In mode, synthesis module 206 can choose pixel value to make the fuzzy minimum as caused by the hand capture image rocked.
The composograph of physical item can be generated in synthesis module 206, wherein pair based on the first image and subsequent image
The pixel value answered selects each pixel value of composograph.In some embodiments, synthesis module 206 uses sensor number
According to keeping the first image and subsequent image aligned with each other, to identify the position of pixel.For example, synthesis module 206 is from mobile device
245 receiving sensor data of sensor in 115, such as sensing data from gyroscope, accelerometer etc., to determine
The position of mobile device 115 during capture and image is aligned using sensing data.In some embodiments, it is based on
The segmentation of image is aligned image.In some embodiments, synthesis module 206 is aligned the first figure using the boundary detected
Picture and subsequent image.
Synthesis module 206 avoids dazzle by selecting the minimum value of corresponding pixel value in some embodiments.Its
His option is possible, such as progress statistical measures, which includes the average value or acquisition pixel value for seeking pixel value
Intermediate value.
In some embodiments, synthesis module 206 can further pass through Selection experiment pixel value and will test picture
The pixel value of plain value and each surrounding is compared to select each pixel value to confirm that pixel value is in mutual threshold difference
Within.If test pixel value and more than one surrounding pixel values differ by more than threshold difference, synthesis module 206 can be selected
Select the different pixel values within threshold difference.This may insure that pixel value does not include outlier pixel values.
Synthesis module 206 can combine the pixel value of each position in the first image and subsequent image, to form composite diagram
Picture.Composograph can be stored as the data file of picture format, such as PNG, PG, GIF etc. by synthesis module 206.One
In a little embodiments, after generating composograph, synthesis module 206 abandons the first image and subsequent image.In some implementations
In mode, the first image and subsequent image are stored in mobile device 115 or media server 101 by synthesis module 206.
Example concept film
In some embodiments, media application 103 is from the media product concept film with user-association.Media application
103 can identify that the image and/or video with user-association, the image and/or video are associated with specific concept.For example, once
User agrees to that media application 103 can identify that single child continues a period of time, such as continues 5 years images and/or views
Frequently.The concept can be " their fast growths ", and image and video can be organized sequentially in time, to show child year
Age increases.Media application 103 can generate film from the image and/or video, and add music to film.For example, media
Film can be generated using 103, which changes between image and/or video, and such as based on the beat of music, with sound
It is happy to synchronize.Media application 103 can choose it is lyric and correspond to the pass viewing child's age increase and the feeling music aroused,
It is such as designed to pull the lyric song of heartstrings.
In another example, which can be " summer smile " and about last day summer, once user is same
Meaning, the image and/or video that media application 103 can select people to smile from nearest trimestral image and/or video.
For the conceptual choice music can be traditionally with summer associated song.
Example media sharer
In some embodiments, media application 103 can be used family and be easier shared media.Media application 103 can be with
Generate user interface, multiple media items which provides the media of user for user and selection is shared with other users
Purpose option.In some embodiments, media application 103 can provide indicator on each media item, and user can be with
The indicator is selected to indicate shared hope.For example, the indicator can be circle or box, and media application 103
Media item can be selected to add hook-type symbol by touching screen in response to user.
In some embodiments, media application 103 can be provided for user in a plurality of ways share media item or
The option of multiple media items, multiple modes include different type application.For example, media application 103 can provide choosing for user
, with create be sent to another person link, generate can be shared with another person shared photo album, addition media item or
The multiple media items of person to previously existing shared photo album or with more than one messaging application, confusion (messing)
Using, chat application, e-mail applications, cloud computing storage, map application, the shared media item of text editing application etc. or
The multiple media items of person.In some embodiments, media application 103 can frequency of use based on user, another person
Frequency of use etc. carrys out the shared mode of suggestion.In some embodiments, in the case where user selects messaging application,
Media application 103 can provide the instruction of user list and the availability of these users.
In some embodiments, media application 103 can provide addition text to media item or multiple for user
The option of media item, such as title.In some embodiments, media application 103 can provide for user makes emoticon
With media item or the associated option of multiple media items.In some embodiments, when media item or multiple media
When project is delivered to a people, media application 103 can show an emoticon for being deformed into another emoticon.Example
Such as, when first user's title is " so excellent！！！In addition to there is no crossing such case" when, media application 103 can be with
Title is shown as " so excellent！！！, smiling face's emoticon is deformed into sad face emoticon, then shows that title " removes
, there is no crossing such case ".
In some embodiments, media application 103 can be provided with neighbouring people and/or in the place of different regions,
The people in such as cities and towns, country etc. shares the option of media.In some embodiments, media application 103 can provide offline
The option of shared media.For example, media application 103 can save media to backup of memory, and share the matchmaker via SMS
Body.
In some embodiments, once user agree to, media application 103 can carry out in the picture Object identifying and
The identification of people.Once user agrees to, media application 103 can be searched with providing for user based on object, people, place, thing etc.
The option of rope user media.In some embodiments, by providing example image for user, media application 103 can be use
Family provides the option for searching for different types of thing in the picture.
In some embodiments, media application 103 may include image assistant, and image assistant detection is captured by user
Image the problem of.Such as image may be over-exposed, fuzzy etc..Media application can provide editor's figure for user
The option of picture, the option is for example included in Fig. 4.In some embodiments, media application 103 provides suggestion for user, should
It is recommended that all images in this way are fuzzy or user is shooting and the prompting of user's similar image of captured image.Some
In embodiment, media application 103 automatically corrects image for user.
In some embodiments, media application 103 is provided from the option for generating photo book with the media of user-association.
Exemplary method
Fig. 7 illustrates the process that the exemplary method 700 of composograph is generated according to the slave physical item of some embodiments
Figure.This method 700 is carried out by the media application 103 being stored on computing device 300, all mobile devices in this way of computing device 300
115, media server 111 or be a part of mobile device 115 and a part of media server 111.
In box 702, the first image of physical item is captured using camera 243.Camera 243 is the one of computing device 300
Part.Physical item is, for example, photo.
In box 704, identification and the associated boundary of the physical item.For example, computing device 300 identifies four sides of photo
Edge.
In box 706, it is based on the first image, generates superimposed layer, which includes being located at and physical item associated one
Multiple objects within a above boundary.For example, photo is partitioned into quadrant by media application 103, and there are four generations
The superimposed layer of object, the center within each comfortable quadrant of four objects.
In box 708, the subsequent image of physical item is captured with camera 243, wherein utilizing corresponding subsequent camera position
Capture each subsequent image.For example, media application 103 determines the movement of camera 243 whenever capturing subsequent image.In box
710, during capturing subsequent image, show image preview, which includes superimposed layer, wherein as camera 243 moves
Dynamic, multiple objects are kept fixed in superimposed layer, in response to the subsequent figure in corresponding subsequent camera position capture predetermined quantity
Picture, updates the attribute of an object in multiple objects, and the attribute for updating multiple objects corresponds to capture and completes.For example, with
User move camera 243 in a particular manner, corresponding object in four objects changes color, until subsequent object has been caught
It obtains.In some embodiments, superimposed layer includes the graticule mobile when camera 243 is mobile, and the graticule is moved to and encloses
Around or the multiple objects of overlapping in each object at least part, until subsequent image has been captured, and and the result is that catch
Obtain completion.
In box 712, the corresponding relationship between the pixel of the first image and the pixel of subsequent image is established.For example, media
The all pixels of the specific location in first image and the second image are compared using 103.In box 714, generate real
The composograph of body article, wherein each pixel value of composograph is the corresponding picture based on the first image and subsequent image
Element value.Such as media application 103 is that the composograph of that specific position selects the minimum value of respective pixel value.
Fig. 8 illustrates another exemplary method 800 that composograph is generated according to the slave physical item of some embodiments
Flow chart.This method 800 is carried out by the media application 103 being stored on computing device 300, all shiftings in this way of computing device 300
Dynamic device 115, media server 111 or be a part of mobile device 115 and a part of media server 111.
In box 802, with the first image of camera capture physical item.In box 804, the first image is shown, and colored
Superimposed layer is on the first part of image.It can be captured in the more than one subsequent image of box 806, physical item,
Wherein each subsequent image is captured relative to physical item movement with camera 243.It is each subsequent capturing in box 808
During image, the first image is shown as color addition layer on the second part of the first image, and wherein second part includes
First part and based on camera movement and the extention of determination.In box 810, establish the first image pixel and one with
On subsequent image in each subsequent image pixel between corresponding relationship.In box 812, the conjunction of physical item is generated
At image, wherein based on each of the corresponding pixel value of the first image and more than one subsequent image selection composograph
Pixel value.
In the above description, in order to illustrate elaborating numerous details in order to provide the thorough understanding to specification.So
And it should be apparent to those skilled in the art that the disclosure can also be implemented in the case where without these details.?
In some cases, construction and device is shown in block diagram form, in order to avoid make to describe unclear.For example, above can be with Primary Reference
User interface and special hardware describe embodiment.However, embodiment can be adapted for can receive data and order
Any kind of computing device, and provide service any peripheral unit.
" some embodiments " of specification reference either " some examples " means together with embodiment or example
Special characteristic, structure or the feature of description can be included at least one embodiment of description.In specification differently
The phrase " in some embodiments " just occurred is not necessarily all referring to identical embodiment.
The some parts of the above specific embodiment are according to the operation for the data bit within computer storage
Algorithm and symbol indicate to present.These calculate description and indicate to be that the personnel that those are good at data processing technique use
Means, so that the essence of their work is most effectively communicated to other those skilled in the art.Here algorithm is usual
The step of being considered as the orderly order for leading to expected result.Step is the physical manipulation that those need physical quantity.In general, so
And not necessarily, this tittle using can by storage, transmission, combine, compare and other manipulate electronics or magnetic data
Form.Sometimes it has been proved to be convenient, mainly for public purpose, has quoted these data as bit, value, element, symbol
Number, character, project, quantity etc..
Undertaken however, being contemplated that, all these and similar item will with register appropriate, and
Only it is suitable for the convenient label of this tittle.It is it will be apparent that can from following discussion unless in addition specifically stating
Run through the specification to understand, with including " processing " either " calculating " either " operation " either " determination " or " display " etc.
The discussion of term refer to the computer equipment perhaps movement of similar computing electronics and processing computer equipment or class
It is represented as what the physics (electronics) within the register and memory of computer system was measured like computing electronics manipulation, and will
The data are converted to other data, other data are equally represented as computer system memory or register or other are this
Physical quantity within information-storing device, transmission or display device.
The embodiment of specification can also relate to a processor, which carries out one of process as described above
Above step.Processor, which can be, to be selectively activated or is reconfigured by the computer program of storage in a computer
Dedicated processor.This computer program can be stored in permanent computer readable storage medium storing program for executing, and permanent computer can
Storage medium is read to include but is not limited to any kind of disk or be suitable for storing any kind of medium of e-command, it is any
The disk of type includes floppy disk, CD, ROM, CD-ROM, disk, RAM, EPROM, EEPROM, magnetic card or light-card including has
The flash memory of the USB key of nonvolatile memory, is respectively coupled to computer system bus.
Specification can be contained firmly using some whole hardware realizations, some whole software realizations or some embodiments
The form of both part and software element.In some embodiments, specification implemented in software, software are including but not limited to solid
Part, resident software, microcoding etc..
In addition, explanation can using can from computer available or computer-readable medium access computer program
The form of product, computer is available or computer-readable medium passes through or together with computer or any instruction execution
System provides the program code for using.It is available in order to illustrate, computer or computer-readable medium can be and appoint
What equipment, any equipment can include to store, communicate, transmission by or together with instruction execution system, device, or
Person conveys the program for using.
Be suitable for store or execute program code data processing system will include via system bus by directly or
It is indirectly coupled at least one processor of memory element.Memory element may include during the actual execution of program code
The speed buffering of adopted local memory, mass storage and at least some program codes of offer temporarily stored is deposited
Reservoir, must be from the number of mass storage retrieval coding during execution to reduce.
In the situation that system discussed above collects personal information, system provides a chance for user to control program
Either whether characteristic collects user information (for example, about user social contact network, social movement or activity, occupation, Yong Huai
The information of good perhaps user current location) or control whether and/or how from may with user more related server
Reception content.In addition, some data is before by storage or use, and it can be processed in a manner of more than one, to go
Except personal identifiable information.For example, can handle the identity of user, so as to for the user, no personal identifiable letter
Breath can be determined, and the geographical location (such as city, postcode or state rank) for either obtaining the user of location information can
To be summarized, to determine the specific position of user.Therefore, user can control how to collect information about user with
And server how use information.
Claims (20)
1. a kind of method characterized by comprising
The first image of physical item is captured with camera in first camera position；
Detection and the associated boundary of the physical item；
Based on the first image, generate superimposed layer, the superimposed layer include be located at associated one of the physical item with
On the boundary within multiple objects；
The subsequent image of the physical item is captured with the camera, wherein each subsequent in corresponding subsequent camera position capture
Image；
During capturing the subsequent image, display includes the image preview of the superimposed layer, in which:
As the camera is mobile, the multiple object is kept fixed in the superimposed layer,
In response to the subsequent image in each corresponding subsequent camera position capture predetermined quantity, update in the multiple object
The attribute of one object；And
The attribute for updating the multiple object corresponds to the completion of capture；
Establish the corresponding relationship between the pixel of the first image and the pixel of each subsequent image；And
Generate the composograph of the physical item, wherein each pixel value of the composograph is based on first figure
The corresponding pixel value of picture and the subsequent image.
2. the method as described in claim 1, which is characterized in that
The superimposed layer further comprises graticule,
The graticule is moved in response to the movement camera；And
It is Chong Die with the object in response at least part of the graticule and capture the subsequent image.
3. the method as described in claim 1, which is characterized in that
Size in response to the first image is more than predetermined threshold, and the superimposed layer is partitioned into multiple portions, and by institute
State the center that each object in multiple objects is placed on corresponding part.
4. the method as described in claim 1, which is characterized in that
It is more than threshold confidence value in response at least one associated confidence value of the detection with the first image, it will be described folded
Add layer to be partitioned into multiple portions, and each object in the multiple object is placed on to the center of corresponding part.
5. the method as described in claim 1, which is characterized in that
The attribute is color；And
There is the instruction completed in the color for updating the multiple object.
6. the method as described in claim 1, which is characterized in that
In response to updating the attribute of the object in the multiple object, the object is removed from the superimposed layer.
7. the method as described in claim 1, which is characterized in that each pixel value of the composograph is the first image
With the minimum value in the corresponding pixel value of the subsequent image.
8. the method as described in claim 1, which is characterized in that
Generating the composograph further comprises, be the composograph each pixel value, Selection experiment pixel value, and
The test pixel value is compared with the surrounding pixel values of multiple pixels, to confirm each week in the surrounding pixel values
Pixel value is enclosed within the threshold difference of the test pixel value, and the multiple pixel surrounds the pixel corresponding to pixel value.
9. method according to any one of claims 8, which is characterized in that
It is more than the threshold in response to the difference between a surrounding pixel values in the test pixel value and the surrounding pixel values
The test pixel value is revised as within the threshold difference by value difference.
10. a kind of non-transitory computer-readable medium with instruction, when described instruction is executed by more than one computer
When one above computer is operated, which is characterized in that the operation includes:
With the first image of camera capture physical item；
Detection and the associated boundary of the physical item；
Based on the first image, superimposed layer is generated, the superimposed layer includes graticule and is located at associated with the physical item
Multiple objects within the more than one boundary；
The subsequent image of the physical item is captured with the camera, wherein each subsequent in corresponding subsequent camera position capture
Image；
During capturing the subsequent image, the first image with the superimposed layer is provided, wherein
As the camera is mobile, the multiple object is kept fixed in the superimposed layer,
The graticule is moved in response to the movement camera,
It is Chong Die with an object in the multiple object in response at least part graticule and capture the subsequent image,
In response to the subsequent image in corresponding subsequent camera position capture predetermined quantity, the object is updated, and
In response to the movement camera until the multiple object is updated, the completion of capture occurs；
Establish the corresponding relationship between the pixel of the first image and the pixel of each subsequent image；And
Generate the composograph of the physical item, wherein each pixel value of the composograph is based on first figure
The corresponding pixel value of picture and the subsequent image.
11. computer-readable medium as claimed in claim 10, it is characterised in that:
Updating the object includes the color for updating the object；And
There is the instruction completed in the color for updating the multiple object.
12. computer-readable medium as claimed in claim 10, which is characterized in that the superimposed layer further comprises arrow,
The arrow is directed toward the direction of the mobile graticule.
13. computer-readable medium as claimed in claim 10, which is characterized in that each pixel value of the composograph is
Minimum value in the corresponding pixel value of the first image and the subsequent image.
14. computer-readable medium as claimed in claim 10, which is characterized in that
Generating the composograph further comprises, be the composograph each pixel value, Selection experiment pixel value, and
The test pixel value is compared with the surrounding pixel values of multiple pixels, to confirm each week in the surrounding pixel values
Pixel value is enclosed within the threshold difference of the test pixel value, and the multiple pixel surrounds the pixel corresponding to pixel value.
15. computer-readable medium as claimed in claim 14, which is characterized in that
It is more than the threshold in response to the difference between a surrounding pixel values in the test pixel value and the surrounding pixel values
The test pixel value is revised as so that one in modified test pixel value and the surrounding pixel values by value difference
Difference between surrounding pixel values is no more than the threshold difference.
16. a kind of system, characterized by comprising:
More than one processor；And
Memory, the instruction that the memory storage is executed by one above processor, described instruction include:
With the first image of camera capture physical item；
Show the first image, and color addition layer is on the first part of the first image；
The more than one subsequent image of the physical item is captured, wherein as the camera is moved relative to the physical item
It moves and captures each subsequent image；
During capturing each subsequent image, the first image is shown, and the color addition layer is in first figure
On the second part of picture, wherein the second part include the first part and based on the camera movement and determination
Extention；
It establishes between the pixel of the first image and the pixel of each subsequent image in one above subsequent image
Corresponding relationship；And
Generate the composograph of the physical item, wherein each pixel value of the composograph is based on first figure
The corresponding pixel value of picture and one above subsequent image.
17. system as claimed in claim 16, which is characterized in that instructions further include:
The first image is converted into pre-set aspect ratio；
It is to be inverted and at least one of lateral in response to the first image, the first image is revised as face-up；
And
The composition of the first image is corrected using white balance.
18. system as claimed in claim 16, which is characterized in that each pixel value of the composograph is first figure
Minimum value in the corresponding pixel value of picture and the subsequent image.
19. system as claimed in claim 16, which is characterized in that the superimposed layer further comprises target, the target quilt
It is placed as the direction of the mobile camera of instruction.
20. system as claimed in claim 19, which is characterized in that the target is moved as the camera is mobile.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201662347572P | 2016-06-08 | 2016-06-08 | |
US62/347,572 | 2016-06-08 | ||
PCT/US2016/061848 WO2017213685A1 (en) | 2016-06-08 | 2016-11-14 | Generating a composite image from a physical item |
Publications (2)
Publication Number | Publication Date |
---|---|
CN110168606A true CN110168606A (en) | 2019-08-23 |
CN110168606B CN110168606B (en) | 2023-09-26 |
Family
ID=57396856
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201680083169.5A Active CN110168606B (en) | 2016-06-08 | 2016-11-14 | Method and system for generating composite image of physical object |
Country Status (4)
Country | Link |
---|---|
US (2) | US10257485B2 (en) |
EP (2) | EP4358531A2 (en) |
CN (1) | CN110168606B (en) |
WO (1) | WO2017213685A1 (en) |
Families Citing this family (12)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10867328B2 (en) * | 2016-05-03 | 2020-12-15 | Yembo, Inc. | Systems and methods for providing AI-based cost estimates for services |
EP4358531A2 (en) * | 2016-06-08 | 2024-04-24 | Google LLC | Generating a composite image from a physical item |
US10675955B2 (en) | 2016-11-14 | 2020-06-09 | Google Llc | Adaptive glare removal and/or color correction |
US10733469B2 (en) * | 2017-12-29 | 2020-08-04 | Idemia Identity & Security USA LLC | Capturing digital images of documents |
GB201812446D0 (en) | 2018-07-31 | 2018-09-12 | Barco Nv | Method and system for mapping the non-uniformity of an image sensor |
US11665312B1 (en) * | 2018-12-27 | 2023-05-30 | Snap Inc. | Video reformatting recommendation |
US10887542B1 (en) * | 2018-12-27 | 2021-01-05 | Snap Inc. | Video reformatting system |
US20210291435A1 (en) * | 2020-03-19 | 2021-09-23 | Ricoh Company, Ltd. | Measuring apparatus, movable apparatus, robot, electronic device, fabricating apparatus, and measuring method |
US11539647B1 (en) | 2020-06-17 | 2022-12-27 | Meta Platforms, Inc. | Message thread media gallery |
US20220012870A1 (en) * | 2020-07-10 | 2022-01-13 | Eric Breiding | Generating menu insights |
US11831931B2 (en) | 2021-04-14 | 2023-11-28 | Microsoft Technology Licensing, Llc | Systems and methods for generating high-resolution video or animated surface meshes from low-resolution images |
US11849220B2 (en) * | 2021-04-14 | 2023-12-19 | Microsoft Technology Licensing, Llc | Systems and methods for generating depth information from low-resolution images |
Citations (22)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
WO1999038121A1 (en) * | 1998-01-27 | 1999-07-29 | Sensar, Inc. | Method and apparatus for removal of bright or dark spots by the fusion of multiple images |
US6088612A (en) * | 1997-04-04 | 2000-07-11 | Medtech Research Corporation | Method and apparatus for reflective glare removal in digital photography useful in cervical cancer detection |
US20060098112A1 (en) * | 2004-11-05 | 2006-05-11 | Kelly Douglas J | Digital camera having system for digital image composition and related method |
CN101867720A (en) * | 2009-04-17 | 2010-10-20 | 索尼公司 | Generate in the camera of the synthetic panoramic picture of high-quality |
US20110312374A1 (en) * | 2010-06-18 | 2011-12-22 | Microsoft Corporation | Mobile and server-side computational photography |
CN103069454A (en) * | 2010-07-05 | 2013-04-24 | 苹果公司 | Capturing and rendering high dynamic ranges images |
CN103534726A (en) * | 2011-05-17 | 2014-01-22 | 苹果公司 | Positional sensor-assisted image registration for panoramic photography |
JP2014039170A (en) * | 2012-08-16 | 2014-02-27 | Sony Corp | Image processing device, image processing method, and program |
WO2014033886A1 (en) * | 2012-08-30 | 2014-03-06 | 富士通株式会社 | Image processing apparatus, image processing method, and program |
US20140118483A1 (en) * | 2012-10-29 | 2014-05-01 | Google Inc. | Smart targets facilitating the capture of contiguous images |
CN103988503A (en) * | 2011-12-12 | 2014-08-13 | 英特尔公司 | Scene segmentation using pre-capture image motion |
CN104040576A (en) * | 2011-12-14 | 2014-09-10 | 电子湾有限公司 | Multiple-angle imagery of physical objects |
CN104115185A (en) * | 2011-10-19 | 2014-10-22 | 泰坦公司 | Computing systems and methods for electronically indicating the acceptability of a product |
US20140327940A1 (en) * | 2013-05-03 | 2014-11-06 | Kofax, Inc. | Systems and methods for detecting and classifying objects in video captured using mobile devices |
CN104284064A (en) * | 2013-07-05 | 2015-01-14 | 三星电子株式会社 | Method and apparatus for previewing a dual-shot image |
US8937646B1 (en) * | 2011-10-05 | 2015-01-20 | Amazon Technologies, Inc. | Stereo imaging using disparate imaging devices |
US20150054975A1 (en) * | 2013-08-21 | 2015-02-26 | Xerox Corporation | Automatic mobile photo capture using video analysis |
CN104662589A (en) * | 2012-08-21 | 2015-05-27 | 派力肯影像公司 | Systems and methods for parallax detection and correction in images captured using array cameras |
US20150288874A1 (en) * | 2012-10-23 | 2015-10-08 | Ishay Sivan | Real time assessment of picture quality |
CN105283884A (en) * | 2013-03-13 | 2016-01-27 | 柯法克斯公司 | Classifying objects in digital images captured using mobile devices |
CN105408936A (en) * | 2013-07-26 | 2016-03-16 | 高通股份有限公司 | System and method of correcting image artifacts |
US9325861B1 (en) * | 2012-10-26 | 2016-04-26 | Google Inc. | Method, system, and computer program product for providing a target user interface for capturing panoramic images |
Family Cites Families (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7346184B1 (en) | 2000-05-02 | 2008-03-18 | Digimarc Corporation | Processing methods combining multiple frames of image data |
KR101723642B1 (en) * | 2011-01-31 | 2017-04-19 | 삼성전자주식회사 | Photographing apparatus for photographing a panorama image and method thereof |
US9270885B2 (en) | 2012-10-26 | 2016-02-23 | Google Inc. | Method, system, and computer program product for gamifying the process of obtaining panoramic images |
US8805125B1 (en) | 2013-06-28 | 2014-08-12 | Google Inc. | Comparing extracted card data using continuous scanning |
EP3089102B1 (en) | 2013-12-03 | 2019-02-20 | ML Netherlands C.V. | User feedback for real-time checking and improving quality of scanned image |
US9626589B1 (en) * | 2015-01-19 | 2017-04-18 | Ricoh Co., Ltd. | Preview image acquisition user interface for linear panoramic image stitching |
EP4358531A2 (en) * | 2016-06-08 | 2024-04-24 | Google LLC | Generating a composite image from a physical item |
-
2016
- 2016-11-14 EP EP24162634.0A patent/EP4358531A2/en active Pending
- 2016-11-14 CN CN201680083169.5A patent/CN110168606B/en active Active
- 2016-11-14 WO PCT/US2016/061848 patent/WO2017213685A1/en active Search and Examination
- 2016-11-14 US US15/350,840 patent/US10257485B2/en active Active
- 2016-11-14 EP EP16801683.0A patent/EP3610452B1/en active Active
-
2019
- 2019-04-03 US US16/374,647 patent/US10531061B2/en active Active
Patent Citations (22)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6088612A (en) * | 1997-04-04 | 2000-07-11 | Medtech Research Corporation | Method and apparatus for reflective glare removal in digital photography useful in cervical cancer detection |
WO1999038121A1 (en) * | 1998-01-27 | 1999-07-29 | Sensar, Inc. | Method and apparatus for removal of bright or dark spots by the fusion of multiple images |
US20060098112A1 (en) * | 2004-11-05 | 2006-05-11 | Kelly Douglas J | Digital camera having system for digital image composition and related method |
CN101867720A (en) * | 2009-04-17 | 2010-10-20 | 索尼公司 | Generate in the camera of the synthetic panoramic picture of high-quality |
US20110312374A1 (en) * | 2010-06-18 | 2011-12-22 | Microsoft Corporation | Mobile and server-side computational photography |
CN103069454A (en) * | 2010-07-05 | 2013-04-24 | 苹果公司 | Capturing and rendering high dynamic ranges images |
CN103534726A (en) * | 2011-05-17 | 2014-01-22 | 苹果公司 | Positional sensor-assisted image registration for panoramic photography |
US8937646B1 (en) * | 2011-10-05 | 2015-01-20 | Amazon Technologies, Inc. | Stereo imaging using disparate imaging devices |
CN104115185A (en) * | 2011-10-19 | 2014-10-22 | 泰坦公司 | Computing systems and methods for electronically indicating the acceptability of a product |
CN103988503A (en) * | 2011-12-12 | 2014-08-13 | 英特尔公司 | Scene segmentation using pre-capture image motion |
CN104040576A (en) * | 2011-12-14 | 2014-09-10 | 电子湾有限公司 | Multiple-angle imagery of physical objects |
JP2014039170A (en) * | 2012-08-16 | 2014-02-27 | Sony Corp | Image processing device, image processing method, and program |
CN104662589A (en) * | 2012-08-21 | 2015-05-27 | 派力肯影像公司 | Systems and methods for parallax detection and correction in images captured using array cameras |
WO2014033886A1 (en) * | 2012-08-30 | 2014-03-06 | 富士通株式会社 | Image processing apparatus, image processing method, and program |
US20150288874A1 (en) * | 2012-10-23 | 2015-10-08 | Ishay Sivan | Real time assessment of picture quality |
US9325861B1 (en) * | 2012-10-26 | 2016-04-26 | Google Inc. | Method, system, and computer program product for providing a target user interface for capturing panoramic images |
US20140118483A1 (en) * | 2012-10-29 | 2014-05-01 | Google Inc. | Smart targets facilitating the capture of contiguous images |
CN105283884A (en) * | 2013-03-13 | 2016-01-27 | 柯法克斯公司 | Classifying objects in digital images captured using mobile devices |
US20140327940A1 (en) * | 2013-05-03 | 2014-11-06 | Kofax, Inc. | Systems and methods for detecting and classifying objects in video captured using mobile devices |
CN104284064A (en) * | 2013-07-05 | 2015-01-14 | 三星电子株式会社 | Method and apparatus for previewing a dual-shot image |
CN105408936A (en) * | 2013-07-26 | 2016-03-16 | 高通股份有限公司 | System and method of correcting image artifacts |
US20150054975A1 (en) * | 2013-08-21 | 2015-02-26 | Xerox Corporation | Automatic mobile photo capture using video analysis |
Non-Patent Citations (2)
Title |
---|
石跃祥;B.BENHABIB;蔡自兴;: "基于内容的图像检索在智能监控系统中的应用", 计算机工程, no. 10 * |
邹云海;关蒲骏;杨波;龚启勇;幸浩洋;: "基于FPGA与投影算法的快速眼动跟踪系统实现", 四川大学学报(工程科学版), no. 03 * |
Also Published As
Publication number | Publication date |
---|---|
US20170359560A1 (en) | 2017-12-14 |
WO2017213685A1 (en) | 2017-12-14 |
CN110168606B (en) | 2023-09-26 |
EP3610452A1 (en) | 2020-02-19 |
EP4358531A2 (en) | 2024-04-24 |
US10531061B2 (en) | 2020-01-07 |
US10257485B2 (en) | 2019-04-09 |
EP3610452B1 (en) | 2024-04-24 |
US20190230330A1 (en) | 2019-07-25 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN110168606A (en) | Composograph is generated from physical item | |
US11455093B2 (en) | Capturing and sending multimedia as electronic messages | |
CN105809620B (en) | Preview image for linear Panorama Mosaic obtains user interface | |
KR102516541B1 (en) | Image segmentation and modification of a video stream | |
US9639940B2 (en) | Imaging apparatus and methods for generating a guide display showing a photographing technique for approximating a composition of a subject image to that of a sample image | |
US9665986B2 (en) | Systems and methods for an augmented reality platform | |
CN106575354A (en) | Virtualization of tangible interface objects | |
US11430211B1 (en) | Method for creating and displaying social media content associated with real-world objects or phenomena using augmented reality | |
US10685680B2 (en) | Generating videos of media items associated with a user | |
TW201535233A (en) | Note capture and recognition with manual assist | |
JP2014038429A (en) | Image processor, image processing method and image processing program | |
JP5735861B2 (en) | Image display program, image display apparatus, image display method, image display system, marker | |
US11049303B2 (en) | Imaging apparatus, and operation program and operation method for imaging apparatus | |
JP2015142320A (en) | Imaging printing system, server system and program | |
JP6395965B1 (en) | Recipe submission support server, recipe submission support method, recipe submission support program, and recipe submission support system | |
JP5958047B2 (en) | PHOTOGRAPHIC GAME DEVICE, IMAGE GENERATION METHOD, AND IMAGE GENERATION PROGRAM | |
KR101907297B1 (en) | System for producing game by using paper design | |
JP2019200642A (en) | Image collection generation program, information processor, and image collection generation method | |
US20210158595A1 (en) | Information processing apparatus, information processing method, and information processing system | |
JP7472681B2 (en) | Information processing device, program, and information processing method |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
GR01 | Patent grant | ||
GR01 | Patent grant |